<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 22 Jul 2020 16:17:24 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 22 Jul 2020 16:17:24 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Avoid these five common mistakes when writing react with hooks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23906402">thread link</a>) | @loweisz
<br/>
July 21, 2020 | https://www.lorenzweiss.de/common_mistakes_react_hooks/ | <a href="https://web.archive.org/web/*/https://www.lorenzweiss.de/common_mistakes_react_hooks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="react-as-a-framework">React as a framework<a href="#react-as-a-framework" aria-label="react as a framework permalink"></a></h2>
<p>React has been out in the world of web development for quite some time now. Its position as a tool for agile web development has steadily strengthened in recent years. Especially after the announcement and release of the <a href="https://reactjs.org/docs/hooks-state.html#hooks-and-function-components">new hook api/concept</a>, writing components has never been easier.</p>
<p>Although the team behind react and the huge community have tried to train and explain the concepts of the framework in an impressive way, I still see some pitfalls and common mistakes that were made while working with it.
I kept a list of all the mistakes I saw over the last years related to react especially with using hooks. In this article I want to show you the most common ones. I will also try to explain in detail, why I think they are mistakes and a suggestion for doing it in a cleaner way.</p>
<h3>Disclaimer</h3>
<p>Before we start with the list, I have to say that most of the following things are not fundamental mistakes or don't look wrong at first glance. Most of them are unlikely to affect the performance or apperance of the application.
Probably nobody would notice, except for the developers working on the product, that something is wrong here, but I still believe that good quality code can lead to a better developer experience and thus to a better product.</p>
<p>As with any software framework or library, there are millions of different opinions about it. Everything you see here is based on my personal opinion and should not be considered a general rule.
If you have a different opinion about her, I would love to hear it üåü</p>
<h2 id="1-using-usestate-when-no-rerender-is-needed">1. Using useState when no rerender is needed<a href="#1-using-usestate-when-no-rerender-is-needed" aria-label="1 using usestate when no rerender is needed permalink"></a></h2>
<p>One of the core concepts of react is dealing with state. You can control your entire data flow and rendering through state. Each time the tree is rendered again, it is most likely tied to a change in state.</p>
<p>With the <code>useState</code> hook you can now also define your state in function components. Which is a really neat and easy way how to handle states in react. But it can also be misused as we see in the following example.</p>
<p>For the next example we need a bit of explanation, suppose we have two buttons, one button is a counter and the other button sends a request or triggers an action with the current count. However, the current number is never displayed within the component. It is only required for the request when you click the second button.</p>
<h3>This is dangerous ‚ùå</h3>
<div data-language="jsx"><pre><code><span>function</span> <span>ClickButton</span><span>(</span><span>props</span><span>)</span> <span>{</span>
  <span>const</span> <span>[</span>count<span>,</span> setCount<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>0</span><span>)</span><span>;</span>

  <span>const</span> <span>onClickCount</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>setCount</span><span>(</span><span>(</span><span>c</span><span>)</span> <span>=&gt;</span> c <span>+</span> <span>1</span><span>)</span><span>;</span>
  <span>}</span><span>;</span>

  <span>const</span> <span>onClickRequest</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>apiCall</span><span>(</span>count<span>)</span><span>;</span>
  <span>}</span><span>;</span>

  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span>onClickCount<span>}</span></span><span>&gt;</span></span><span>Counter</span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span>onClickRequest<span>}</span></span><span>&gt;</span></span><span>Submit</span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><span>
    </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
  <span>)</span><span>;</span>
<span>}</span></code></pre></div>
<h3>The problem ‚ö°</h3>
<p>At first sight, you might ask what exactly is the problem with that? Isn't that what state was made for?
Sure you are right, this will work just fine and probably there will never be a problem with that. However in react every state change will force a rerender for that component and most likely its children. But in the above example since we never use that state in our render part, this will end up being an unnecessary render every time we set the counter, which can impact the performance or could have unexpected side effects.</p>
<h3>The solution ‚úÖ</h3>
<p>If you want to use a variable inside your component which should keep its value between rendering but also don't force a rerender, you can use the <code>useRef</code> hook. It will keep the value, but doesn't force the component to rerender.</p>
<div data-language="jsx"><pre><code><span>function</span> <span>ClickButton</span><span>(</span><span>props</span><span>)</span> <span>{</span>
  <span>const</span> count <span>=</span> <span>useRef</span><span>(</span><span>0</span><span>)</span><span>;</span>

  <span>const</span> <span>onClickCount</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
    count<span>.</span>current<span>++</span><span>;</span>
  <span>}</span><span>;</span>

  <span>const</span> <span>onClickRequest</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>apiCall</span><span>(</span>count<span>.</span>current<span>)</span><span>;</span>
  <span>}</span><span>;</span>

  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span>onClickCount<span>}</span></span><span>&gt;</span></span><span>Counter</span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span>onClickRequest<span>}</span></span><span>&gt;</span></span><span>Submit</span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><span>
    </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
  <span>)</span><span>;</span>
<span>}</span></code></pre></div>
</div><div>
<h2 id="2-using-routerpush-instead-of-a-link">2. Using router.push instead of a link<a href="#2-using-routerpush-instead-of-a-link" aria-label="2 using routerpush instead of a link permalink"></a></h2>
<p>This might be a very easy and obvious one and not really related to react itself, but I still see it quite a lot when people writing react components.</p>
<p>Let's say you will write a button and with clicking the button the user should be redirected to another page. Since its a <a href="https://en.wikipedia.org/wiki/Single-page_application">SPA</a>, this action will be a client-side routing mechanism. So you will need some kind of library for doing that.
In react the most popular one is <a href="https://reacttraining.com/react-router/">react-router</a> and the following example will use that library.</p>
<p>So adding a click listener will redirect the user to the desired page right?</p>
<h3>This is dangerous ‚ùå</h3>
<div data-language="jsx"><pre><code><span>function</span> <span>ClickButton</span><span>(</span><span>props</span><span>)</span> <span>{</span>
  <span>const</span> history <span>=</span> <span>useHistory</span><span>(</span><span>)</span><span>;</span>

  <span>const</span> <span>onClick</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
    history<span>.</span><span>push</span><span>(</span><span>'/next-page'</span><span>)</span><span>;</span>
  <span>}</span><span>;</span>

  <span>return</span> <span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span>onClick<span>}</span></span><span>&gt;</span></span><span>Go to next page</span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><span>;</span>
<span>}</span></code></pre></div>
<h3>The problem ‚ö°</h3>
<p>Even though this would work just fine for most of the users, there is a huge problem when it comes to accessibility here. The button will not be marked as linking to another page at all, which makes it nearly impossible to be identified by screen readers.
Also could you open that in a new tab or window? Most likely not.</p>
<h3>The solution ‚úÖ</h3>
<p>Linking to other pages with any user interaction should, where possible, be handled by the <code>&lt;Link&gt;</code> component or a normal <code>&lt;a&gt;</code> tag.</p>
<div data-language="jsx"><pre><code><span>function</span> <span>ClickButton</span><span>(</span><span>props</span><span>)</span> <span>{</span>
  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span><span>Link</span></span> <span>to</span><span><span>=</span><span>"</span>/next-page<span>"</span></span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>span</span><span>&gt;</span></span><span>Go to next page</span><span><span><span>&lt;/</span>span</span><span>&gt;</span></span><span>
    </span><span><span><span>&lt;/</span><span>Link</span></span><span>&gt;</span></span>
  <span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p><strong>Bonus points:</strong> it also makes the code a lot more readable and shorter!</p>
<h2 id="3-handling-actions-via-useeffect">3. Handling actions via useEffect<a href="#3-handling-actions-via-useeffect" aria-label="3 handling actions via useeffect permalink"></a></h2>
<p>One of the best and most thoughtful hooks introduced by React is the "useEffect" hook. It enables the processing of actions related to <code>prop</code> or <code>state</code> changes.
Despite its helpful functionality, it is also often used in places where it may not be needed.</p>
<p>Imagine a component that fetches a list of items and render them to the dom. In addition, if the request is successful, we would like to call the "onSuccess" function, which is passed on to the component as a prop.</p>
<h3>This is dangerous ‚ùå</h3>
<div data-language="jsx"><pre><code><span>function</span> <span>DataList</span><span>(</span><span><span>{</span> onSuccess <span>}</span></span><span>)</span> <span>{</span>
  <span>const</span> <span>[</span>loading<span>,</span> setLoading<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>false</span><span>)</span><span>;</span>
  <span>const</span> <span>[</span>error<span>,</span> setError<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>null</span><span>)</span><span>;</span>
  <span>const</span> <span>[</span>data<span>,</span> setData<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>null</span><span>)</span><span>;</span>

  <span>const</span> <span>fetchData</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>setLoading</span><span>(</span><span>true</span><span>)</span><span>;</span>
    <span>callApi</span><span>(</span><span>)</span>
      <span>.</span><span>then</span><span>(</span><span>(</span><span>res</span><span>)</span> <span>=&gt;</span> <span>setData</span><span>(</span>res<span>)</span><span>)</span>
      <span>.</span><span>catch</span><span>(</span><span>(</span><span>err</span><span>)</span> <span>=&gt;</span> <span>setError</span><span>(</span>err<span>)</span><span>)</span>
      <span>.</span><span>finally</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>setLoading</span><span>(</span><span>false</span><span>)</span><span>)</span><span>;</span>
  <span>}</span><span>;</span>

  <span>useEffect</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>fetchData</span><span>(</span><span>)</span><span>;</span>
  <span>}</span><span>,</span> <span>[</span><span>]</span><span>)</span><span>;</span>

  <span>useEffect</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>if</span> <span>(</span><span>!</span>loading <span>&amp;&amp;</span> <span>!</span>error <span>&amp;&amp;</span> data<span>)</span> <span>{</span>
<span>      <span>onSuccess</span><span>(</span><span>)</span><span>;</span></span>    <span>}</span>
  <span>}</span><span>,</span> <span>[</span>loading<span>,</span> error<span>,</span> data<span>,</span> onSuccess<span>]</span><span>)</span><span>;</span>

  <span>return</span> <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>Data: </span><span>{</span>data<span>}</span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><span>;</span>
<span>}</span></code></pre></div>
<h3>The problem ‚ö°</h3>
<p>There are two <code>useEffect</code> hooks, the first one is handling the api call on the initial render and the second one will call the <code>onSuccess</code> function, by assuming when there is no loading, no error, but data in the state, it must have been a successful call. Makes sense right?</p>
<p>Sure for the first call this is true and probably will never fail. But you also loose the direct connection between the action and the function that needs to be called. There is no guarantee that this case will only happen if the fetch action has succeeded and this is something we as developers really don't like.</p>
<h3>The solution ‚úÖ</h3>
<p>A straight forward solution would be to set the "onSuccess" function to the actual place where the call was successful:</p>
<div data-language="jsx"><pre><code><span>function</span> <span>DataList</span><span>(</span><span><span>{</span> onSuccess <span>}</span></span><span>)</span> <span>{</span>
  <span>const</span> <span>[</span>loading<span>,</span> setLoading<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>false</span><span>)</span><span>;</span>
  <span>const</span> <span>[</span>error<span>,</span> setError<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>null</span><span>)</span><span>;</span>
  <span>const</span> <span>[</span>data<span>,</span> setData<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>null</span><span>)</span><span>;</span>

  <span>const</span> <span>fetchData</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>setLoading</span><span>(</span><span>true</span><span>)</span><span>;</span>
    <span>callApi</span><span>(</span><span>)</span>
      <span>.</span><span>then</span><span>(</span><span>(</span><span>fetchedData</span><span>)</span> <span>=&gt;</span> <span>{</span>
        <span>setData</span><span>(</span>fetchedData<span>)</span><span>;</span>
<span>        <span>onSuccess</span><span>(</span><span>)</span><span>;</span></span>      <span>}</span><span>)</span>
      <span>.</span><span>catch</span><span>(</span><span>(</span><span>err</span><span>)</span> <span>=&gt;</span> <span>setError</span><span>(</span>err<span>)</span><span>)</span>
      <span>.</span><span>finally</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>setLoading</span><span>(</span><span>false</span><span>)</span><span>)</span><span>;</span>
  <span>}</span><span>;</span>

  <span>useEffect</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>fetchData</span><span>(</span><span>)</span><span>;</span>
  <span>}</span><span>,</span> <span>[</span><span>]</span><span>)</span><span>;</span>

  <span>return</span> <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>{</span>data<span>}</span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><span>;</span>
<span>}</span></code></pre></div>
<p>Now it is quite clear at first sight when the onSuccess is called, exactly in the success case of the api call.</p>
<h2 id="4-single-responsibility-components">4. Single responsibility components<a href="#4-single-responsibility-components" aria-label="4 single responsibility components permalink"></a></h2>
<p>Composing components can be hard.
When is it time to split a component into several smaller components?
How do you structure the component tree?
All of these questions arise every day when working with a component-based framework.
However, a common mistake in designing your components is to combine two use cases into a single component.
Let's take an example of a header that shows either a burger button on mobile devices or tabs on desktop screens. (The condition will be handled the the magical <code>isMobile</code> function, which is not part of this example üßô‚Äç)</p>
<h3>This is dangerous ‚ùå</h3>
<div data-language="jsx"><pre><code><span>function</span> <span>Header</span><span>(</span><span><span>{</span> menuItems <span>}</span></span><span>)</span> <span>{</span>
  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>header</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span><span>HeaderInner</span></span> <span>menuItems</span><span><span>=</span><span>{</span>menuItems<span>}</span></span> <span>/&gt;</span></span><span>
    </span><span><span><span>&lt;/</span>header</span><span>&gt;</span></span>
  <span>)</span><span>;</span>
<span>}</span>

<span>function</span> <span>HeaderInner</span><span>(</span><span><span>{</span> menuItems <span>}</span></span><span>)</span> <span>{</span>
  <span>return</span> <span>isMobile</span><span>(</span><span>)</span> <span>?</span> <span><span><span>&lt;</span><span>BurgerButton</span></span> <span>menuItems</span><span><span>=</span><span>{</span>menuItems<span>}</span></span> <span>/&gt;</span></span> <span>:</span> <span><span><span>&lt;</span><span>Tabs</span></span> <span>tabData</span><span><span>=</span><span>{</span>menuItems<span>}</span></span> <span>/&gt;</span></span><span>;</span>
<span>}</span></code></pre></div>
<h3>The problem ‚ö°</h3>
<p>With this approach the component HeaderInner is trying to be two different things at once and we all learned from <a href="https://en.wikipedia.org/wiki/Strange_Case_of_Dr_Jekyll_and_Mr_Hyde">Mr. Jekyll</a>, being more than one thing at a time isn't really ideal.
Also it makes it even harder to test or to reuse the component in other places.</p>
<h3>The solution ‚úÖ</h3>
<p>Bringing the condition one level up, makes it easier to see what the components are made for and that they only have one responsibility, being a <code>Header</code>, <code>Tabs</code> or a <code>BurgerButton</code> and not trying to be two things at once.</p>
<div data-language="jsx"><pre><code><span>function</span> <span>Header</span><span>(</span><span>props</span><span>)</span> <span>{</span>
  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>header</span><span>&gt;</span></span><span>{</span><span>isMobile</span><span>(</span><span>)</span> <span>?</span> <span><span><span>&lt;</span><span>BurgerButton</span></span> <span>menuItems</span><span><span>=</span><span>{</span>menuItems<span>}</span></span> <span>/&gt;</span></span> <span>:</span> <span><span><span>&lt;</span><span>Tabs</span></span> <span>tabData</span><span><span>=</span><span>{</span>menuItems<span>}</span></span> <span>/&gt;</span></span><span>}</span><span><span><span>&lt;/</span>header</span><span>&gt;</span></span>
  <span>)</span><span>;</span>
<span>}</span></code></pre></div>
<h2 id="5-single-responsibility-useeffects">5. Single responsibility useEffects<a href="#5-single-responsibility-useeffects" aria-label="5 single responsibility useeffects permalink"></a></h2>
<p>Remember the times when we only had the <code>componentWillReceiveProps</code> or <code>componentDidUpdate</code> methods to hook into the rendering process of a react component? It is bringing back dark memories and also realizing the beauty of using the <code>useEffect</code> hook and especially that you can have as much as you want of them.</p>
<p>But sometimes forgetting and using a "useEffect" for several things brings back those dark memories. For example, imagine you have a component that fetches some data from the backend in some way, and also displays breadcrumbs depending on the current location. (Using again <a href="https://reacttraining.com/react-router/">react-router</a> for getting the current location.)</p>
<h3>This is dangerous ‚ùå</h3>
<div data-language="jsx"><pre><code><span>function</span> <span>Example</span><span>(</span><span>props</span><span>)</span> <span>{</span>
  <span>const</span> location <span>=</span> <span>useLocation</span><span>(</span><span>)</span><span>;</span>

  <span>const</span> <span>fetchDa‚Ä¶</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lorenzweiss.de/common_mistakes_react_hooks/">https://www.lorenzweiss.de/common_mistakes_react_hooks/</a></em></p>]]>
            </description>
            <link>https://www.lorenzweiss.de/common_mistakes_react_hooks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23906402</guid>
            <pubDate>Tue, 21 Jul 2020 12:48:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PySpark Analyses and Sales Data]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23906377">thread link</a>) | @rrdata
<br/>
July 21, 2020 | https://www.rrighart.com/pyspark/pyspark-in-the-context-of-retail | <a href="https://web.archive.org/web/*/https://www.rrighart.com/pyspark/pyspark-in-the-context-of-retail">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				  <p>Sales and customer data provide important insight for companies. Analytics has today an important role in providing data about sales trends, customer profiles, warnings about (un)profitable products, sales volume forecasts and stock supply as well as personalizing customer relationships and giving product recommendations. All this information needs to be delivered in time, preferably in a (semi)automated fashion.<br></p>  <div><div> <p><a> <img src="https://www.rrighart.com/uploads/8/3/7/7/83774724/published/big-data-dashboard.jpg?1592856241" alt="Picture"> </a></p> </div></div>  <div><p><span size="3">Photo by Stephen Dawson on Unsplash</span></p></div>  <div><p>These data can become large to the point that analytical tools and software have performance issues. For example, many businesses embrace spreadsheet software like Excel for understandable reasons, but it would breakdown with large data. Many data scientist work with Python/R, but modules like Pandas would become slow and run out of memory with large data as well.</p><p>Apache Spark enables large and big data analyses. It does this by using parallel processing using different threads and cores optimally. It can therefore improve performance on a cluster but also on a single machine </p><p><span color="#5040ae">[1]</span>. It can do this for (i) unstructured data such as text or for (ii) structured data such as DataFrames arranged in columns. Spark does not require loading all data into memory before processing and it is faster than for example Hadoop.<br>Spark is a multi-language tool. Interfaces exist for Scala, Java, Python and R users, and it can be used in the cloud. These and other features make it a suitable platform for large scale data analyses. Google trends suggests that PySpark - Spark with a Python interface - enjoys increasing popularity.<br></p></div>  <div><div> <p><a> <img src="https://www.rrighart.com/uploads/8/3/7/7/83774724/google-trends_orig.png" alt="Picture"> </a></p> </div></div>  <p><span size="3"><span><span>Data source: <strong>Google Trends</strong> (https://www.<strong>google</strong>.com/<strong>trends</strong>).</span></span></span><br></p>  <div><p>The following blog shows a detailed short example using PySpark in the context of the Online retail sales data <span color="#5040ae">[2]</span>. These are data that are arranged in column format, containing for example invoice number, invoice dates, quantity, price and product description. The chosen data serve as an example and the size would still work in Pandas for most single machine users, even though it would be slower.</p><p>The current blog does not provide a benchmark as done previously </p><p><span color="#5040ae">[1]</span>. It rather gives hands-on analytical steps with code (i.e., concatenate data, removal of data records, renaming columns, replacing strings, casting data types, creation of new features, filtering data). It therefore allows a first glimpse into the world of PySpark.<br></p></div>  <div id="863076632288984095"><div><p id="element-4a5854cd-f009-4c87-9cfd-85ac90227db3" data-platform-element-id="919380649307043755-1.0.0">
	

<h2>START PYSPARK &amp; IMPORT MODULES</h2>
</p>
</div></div>  <p>The Jupyter notebook file <em>PySpark-retaildata.ipynb</em>&nbsp; can be found at GitHub <span color="#5040ae">[3]</span>.<br>The notebook can be run in Google Colab. To install PySpark, type in the first cell <span color="#8d7824">!pip install pyspark</span> .<br></p>  <div><div> <p><a> <img src="https://www.rrighart.com/uploads/8/3/7/7/83774724/pyspark-install_orig.gif" alt="Picture"> </a></p> </div></div>  <p>An alternative is starting a Docker PySpark notebook <span color="#5040ae">[4]</span>.<br>After PySpark is installed and the Jupyter notebook is up and running, we first need to import the modules and create a Spark session:<br></p>      <p>Note that the Spark version used here is 2.4.5, which can be found by the command <span color="#8d7824">spark.version</span>. At the writing of this text, 3.0.0. is being released.<br></p>  <div id="540407624244840880"><div><p id="element-a3066edb-d72c-4553-8b52-740aa3d2f79d" data-platform-element-id="919380649307043755-1.0.0">
	

<h2>LOADING AND DISPLAYING THE DATA</h2>
</p>
</div></div>  <p>The Online retail data can be downloaded from the UCI machine learning repository <span color="#5040ae">[5]</span>. The data sheets should be converted to <em>online1.csv</em> and <em>online2.csv</em> to facilitate loading from disk. The command <span color="#8d7824">pwd</span> or <span color="#8d7824">os.getcwd()</span> can be used to find the current directory from which PySpark will load the files. Below it can be seen that PySpark only takes a couple of seconds whereas Pandas would take a couple of minutes on the same machine.<br></p>      <p><span size="2">Duration: 4.93 seconds</span><br></p>    <p><span size="2">Duration: 1.75 seconds</span><br></p>  <p>Size of the DataFrames (or shapes in terms of Pandas) can be obtained with the following code:<br></p>    <p>To have all the data together in one DataFrame, <em>df1</em> and <em>df2</em> will be concatenated vertically.<br></p>    <p>The following displays the first 5 rows. The command <span color="#8d7824">.limit(5)</span> will be used frequently throughout the text, which is comparable to the equivalent <span color="#8d7824">.head(5)</span> in Pandas, to set the number of rows that is displayed.<br></p>    <div><div> <p><a> <img src="https://www.rrighart.com/uploads/8/3/7/7/83774724/f1_orig.png" alt="Picture"> </a></p> </div></div>  <p>This is the traditional Spark DataFrame output. By using the following setting we will get from now on a Pandas-like output.<br></p>    <p>A number of descriptive statistics can be obtained, like count, standard deviation, mean, minimum and maximum.<br></p>    <div><div> <p><a> <img src="https://www.rrighart.com/uploads/8/3/7/7/83774724/f2a_orig.png" alt="Picture"> </a></p> </div></div>  <p>The table column <em>count</em> suggests that there are missing values in <em>Description</em> and <em>Customer ID</em>. The number of missing values is displayed by the following code:<br></p>    <div><div> <p><a> <img src="https://www.rrighart.com/uploads/8/3/7/7/83774724/f3_orig.png" alt="Picture"> </a></p> </div></div>  <p>Cancelled transactions start with a capital C in the column <em>Invoice</em>. These will be removed by the following.<br></p>    <p>The datashape function confirms that rows were removed.<br></p>    <p><span size="2">Data shape (rows, columns): 1047877 x 8</span><br></p>  <div id="508084563664564157"><div><p id="element-32d47d0f-b45c-4729-a011-65a2d94acb06" data-platform-element-id="919380649307043755-1.0.0">
	

<h2>CHANGING NAME AND DATA TYPE</h2>
</p>
</div></div>  <p>The column name <em>Customer ID</em> contains an annoying white space that under certain circumstances can cause problems. So we should better rename that.<br></p>    <p>Further, the <em>Country</em> EIRE can be replaced by Ireland. The result can be verified by <span color="#8d7824">df.filter(df.Country == "Ireland").limit(5)</span><br></p>    <p>Information about the column type can be obtained. If you want some supplementary information,<span color="#8d7824"><span color="#2a2a2a"> an alternative command is</span></span> <span color="#8d7824">df.explain(df) </span>.<br></p>    <p><span size="2">StructType(List(StructField(Invoice,StringType,true),StructField(StockCode,StringType,true),StructField(Description,StringType,true),StructField(Quantity,IntegerType,true),StructField(InvoiceDate,StringType,true),StructField(Price,DoubleType,true),StructField(CustomerID,IntegerType,true),StructField(Country,StringType,true)))</span><br></p>  <p>Knowing the column types, we could now cast the column <em>Quantity</em> from integer to float.<br></p>    <p>The <em>InvoiceDate</em> shows up as a string. In order to exploit the time-related information, it would be best to convert it to date type. We will do this by creating a new column <em>n_InvoiceDate</em>.<br></p>    <p>Sorting the new dates, we can now display the number of records (rows) as a function of date and time.<br></p>    <div><div> <p><a> <img src="https://www.rrighart.com/uploads/8/3/7/7/83774724/f4_orig.png" alt="Picture"> </a></p> </div></div>  <p>It is also possible to display a range of dates. The following spots all sales at&nbsp;15 Jan 2010 from 8 till 10 o'clock.<br></p>    <div><div> <p><a> <img src="https://www.rrighart.com/uploads/8/3/7/7/83774724/f5_orig.png" alt="Picture"> </a></p> </div></div>    <p>Time-serie analyses often require different units, like seconds, minutes, hours, days, weeks, months and years. For example, if we would like to display the sales per week, we could use the function <span color="#8d7824">weekofyear</span> that translates the date to week.<br></p>    <p>Multiple columns can be used in a computation. The total <em>Amount</em> a customer spent can be computed by multiplication of the <em>Price</em> of a single product with its <em>Quantity</em>.<br></p>    <div><div> <p><a> <img src="https://www.rrighart.com/uploads/8/3/7/7/83774724/f6_orig.png" alt="Picture"> </a></p> </div></div>    <p>How to select rows with specific products? We can use the command <span color="#8d7824">isin</span>, which is very similar to the Pandas isin function:<br></p>    <div><div> <p><a> <img src="https://www.rrighart.com/uploads/8/3/7/7/83774724/f7_orig.png" alt="Picture"> </a></p> </div></div>  <p>If we want to search our data by key word, we would use the command <span color="#8d7824">like</span>.<br></p>    <div><div> <p><a> <img src="https://www.rrighart.com/uploads/8/3/7/7/83774724/f8_orig.png" alt="Picture"> </a></p> </div></div>  <p>To find big buyers, probably organizational customers, select rows where <em>Quantity</em> is larger than 50000. Note that <span color="#8d7824">df.where(df.Quantity &gt; 50000)</span> would give a similar result.<br></p>    <div><div> <p><a> <img src="https://www.rrighart.com/uploads/8/3/7/7/83774724/f9_orig.png" alt="Picture"> </a></p> </div></div>  <p>Let us count the number of data records per country and sort the output, which shows that UK is clearly leading the list.<br></p>    <div><div> <p><a> <img src="https://www.rrighart.com/uploads/8/3/7/7/83774724/f10_orig.png" alt="Picture"> </a></p> </div></div>  <p><span color="#8d7824">Sort</span> can be used for <em>InvoiceDate</em> as well. This can show which hours customers purchase preferentially.<br></p>    <div><div> <p><a> <img src="https://www.rrighart.com/uploads/8/3/7/7/83774724/f11_orig.png" alt="Picture"> </a></p> </div></div>    <p>Luckily, Spark supports SQL - Structured Query Language - which traditionally has an important role in managing relational databases. Using for example SQL queries, a subset of the data can be exported to CRM and KPI sales software. This offers a lot of flexibility for data analyses. Let us experiment with some very useful SQL queries, such as select and filter. We first need to register the DataFrame as a temporary table in the SQLContext. <br></p>    <p>We first select a couple of columns, for example <em>Description</em> and <em>Quantity</em>. If you want to select all columns, simply use the star: <span color="#8d7824">spark.sql("select * from df").show(5)</span><br></p>    <div><div> <p><a> <img src="https://www.rrighart.com/uploads/8/3/7/7/83774724/f12_orig.png" alt="Picture"> </a></p> </div></div>  <p>Select the columns <em>Description</em> and <em>Quantity</em> and only those rows where <em>Quantity</em> has value = 6<br></p>    <div><div> <p><a> <img src="https://www.rrighart.com/uploads/8/3/7/7/83774724/f13_orig.png" alt="Picture"> </a></p> </div></div>  <p>Select the columns <em>Description</em>, <em>Quantity</em>, and <em>Country</em> where <em>Quantity</em> has value = 6 and <em>country</em> is United Kingdom.<br></p>    <div><div> <p><a> <img src="https://www.rrighart.com/uploads/8/3/7/7/83774724/f14_orig.png" alt="Picture"> </a></p> </div></div>  <p>SQL can also be used to show distinct (unique) values in a column. To limit space, only five are displayed here.<br></p>    <div><div> <p><a> <img src="https://www.rrighart.com/uploads/8/3/7/7/83774724/f15_orig.png" alt="Picture"> </a></p> </div></div>  <p>And we can count the number of distinct values, that is how many countries are in total in the data.<br></p>    <div><div> <p><a> <img src="https://www.rrighart.com/uploads/8/3/7/7/83774724/f16_orig.png" alt="Picture"> </a></p> </div></div>  <p>Using SQL we can also exclude certain values. For example, exclude all records with United Kingdom.<br></p>    <div><div> <p><a> <img src="https://www.rrighart.com/uploads/8/3/7/7/83774724/f17_orig.png" alt="Picture"> </a></p> </div></div>  <p>It would be possible to add a new column that categorizes UK (1) or not-UK (0). You could then use <span color="#8d7824">df.filter(df.Country == "United Kingdom").limit(5)</span> and <span color="#8d7824">filter(df.Country == "France").limit(5)</span> to check if the column is correctly coding UK versus not-UK.<br></p>    <p>Next, we could count UK versus not-UK using the new column <em>Country_UK</em>.<br></p>    <p>And compute mean <em>Amount</em> and summed <em>Quantity</em>.<br></p>      <div><p>That is it for now! In the current blog I have chosen to write out the code line by line. The code can of course be wrapped in several functions with the advantage that it can be used as a pre-processing script for different datasets, where you can set your own parameters. Further, smaller subsets of data can easily be exported and visualized in for ex. Plotly.</p><p>There are many other exciting features and developments in Spark:<br>1. Koalas is a Pandas API in Apache Spark, with similar capabilities but in a big data environment. This is particularly good news for people who already work in Pandas and need a quick translation to PySpark of their code.<br>2. Pandas UDF is a new feature that allows parallel processing on Pandas DataFrames.<br>3. There are excellent solutions using PySpark in the cloud. For example, AWS has big data platforms such as Elastic Map Reduce (EMR) that support PySpark.<br>4. Spark streaming allows real-time data analysis.<br>5. MLlib allows scalable machine learning in Spark.<br>6. GraphX enables graph computations.</p><p>If you have any questions or anything you think is missing in this tutorial, please feel free to share. Any suggestions for topics are welcome!</p></div>    <div><p><span size="4">[1] Chen, D., Laing Sain, S., Guo, K. (2012) Data mining for the online retail industry. A case study of RFM model-based customer segmentation using data mining. <em>Journal of database marketing &amp; customer strategy management,</em> 19, 197-208.<br>[2] Wang, G., Xin, R., and Damji, J. (2018). ‚Ä¶</span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.rrighart.com/pyspark/pyspark-in-the-context-of-retail">https://www.rrighart.com/pyspark/pyspark-in-the-context-of-retail</a></em></p>]]>
            </description>
            <link>https://www.rrighart.com/pyspark/pyspark-in-the-context-of-retail</link>
            <guid isPermaLink="false">hacker-news-small-sites-23906377</guid>
            <pubDate>Tue, 21 Jul 2020 12:41:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Accursed and Unutterable Is accursedUnutterablePerformIO?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23906354">thread link</a>) | @lordgrenville
<br/>
July 21, 2020 | https://free.cofree.io/2020/07/20/perform-io/ | <a href="https://web.archive.org/web/*/https://free.cofree.io/2020/07/20/perform-io/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">

      
      

      
        <p>Side effects break referential transparency. If you have a function <code>f</code> which has a pure type but performs
side effects behind closed doors (e.g., <code>f x = unsafePerformIO ...</code>), you‚Äôd have to be careful when refactoring the
code. You may want to, for instance, avoid changing <code>f x + f x</code> into <code>let y = f x in y + y</code>.</p>

<p>But even if you never make such substitutions yourself, the compiler may decide to step in and
do it for you. This post summarizes circumstances in which GHC may perform
optimizations that could change the behavior of your program, in the presence of non-referentially transparent
functions like <code>unsafePerformIO</code>, <code>unsafeDupablePerformIO</code>, and <code>accursedUnutterablePerformIO</code>. Hopefully this
helps you understand how to safely use them if you absolutely must do so.</p>

<p>By the way, the reason the title specifically features <code>accursedUnutterablePerformIO</code> is twofold:</p>
<ol>
  <li><code>accursedUnutterablePerformIO</code> is the least safe of the three. Therefore, most if not all what
 I‚Äôm about to say that applies to <code>unsafePerformIO</code> and <code>unsafeDupablePerformIO</code> is also applicable to <code>accursedUnutterablePerformIO</code>.</li>
  <li><code>accursedUnutterablePerformIO</code> is such a priceless name and I just couldn‚Äôt help myself.</li>
</ol>



<p>Here‚Äôs some useful background before we dive into the details. Some of the things GHC can do that alter the behaviors of
side-effectful functions include:</p>

<ul>
  <li>Common subexpression elimination (CSE). CSE rewrites <code>f x + f x</code> into <code>let y = f x in y + y</code>, which may decrease
the number of times side effects are performed. CSE is turned on by default when compiling with <code>-O</code> and <code>-O2</code>, and can be
disabled with the <code>-fno-cse</code> flag.</li>
  <li>Full laziness optimization. The definition of full laziness is ‚Äúevery expression is evaluated at most once after the variables in
it have been bound‚Äù. This is achieved by floating bindings out of lambdas, for example, <code>f x = let y = g 42 in x + y</code>
is rewritten into <code>y = g 42; f x = x + y</code>. By floating <code>y = g 42</code> out of <code>f</code>, <code>g 42</code> is evaluated
at most once, which may also decrease the number of times side effects are performed. The original definition, on the other
hand, would evaluate <code>g 42</code> every time <code>f</code> is applied to an <code>x</code>. Full laziness is also turned on when compiling with <code>-O</code> and <code>-O2</code>, and can be
disabled with the <code>-fno-full-laziness</code> flag.</li>
  <li>Inlining. This has the opposite outcome with respect to side effects: inlining a side-effectful definition may cause
the side effect to be performed more times compared to not inlining it.</li>
</ul>

<p>It is worth mentioning that these three things don‚Äôt act independently, but are related and sometimes interact with one another
in ways that can be really subtle, as the examples that follow shall demonstrate.</p>

<p>About the three unsafe functions covered in this post:</p>
<ul>
  <li><code>unsafePerformIO</code> is the most well-known, and is relatively the safest, but the slowest of the three.</li>
  <li><code>unsafeDupablePerformIO</code> is faster but also less safe, in the sense that it provides
no guarantee that an <code>IO</code> action won‚Äôt be performed simultaneously by multiple threads.</li>
  <li><code>accursedUnutterablePerformIO</code> (from the <code>bytestring</code> package) is even faster but much less safe. Not
only does it not check for duplicates, but it inlines everything, which makes CSE a lot more likely to
be triggered. It used to be called <code>inlinePerformIO</code>, but <code>accursedUnutterablePerformIO</code> is an undeniably more
advisable name.</li>
</ul>

<p>All of the following examples assume GHC 8.10.1 and <code>-O2</code>.</p>



<p>Let‚Äôs start with something simple:</p>

<div><div><pre><code><span>module</span> <span>Main</span> <span>where</span>
<span>import</span> <span>System.IO.Unsafe</span>

<span>hasSideEffect</span> <span>::</span> <span>Int</span> <span>-&gt;</span> <span>Int</span>
<span>hasSideEffect</span> <span>x</span> <span>=</span> <span>unsafePerformIO</span> <span>$</span> <span>do</span>
  <span>putStrLn</span> <span>"side effect!"</span>
  <span>pure</span> <span>x</span>

<span>main</span> <span>::</span> <span>IO</span> <span>()</span>
<span>main</span> <span>=</span> <span>print</span> <span>(</span><span>hasSideEffect</span> <span>0</span> <span>+</span> <span>hasSideEffect</span> <span>0</span><span>)</span>
</code></pre></div></div>

<p><code>hasSideEffect 0</code> is obviously a common subexpression in the body of <code>main</code>. It would be factored out if CSE
is turned on, meaning ‚Äúside effect!‚Äù would only be printed once. Passing <code>-fno-cse</code> to GHC makes it print twice.</p>

<p>Note that it doesn‚Äôt matter if <code>hasSideEffect</code> is inlined or not. <code>hasSideEffect 0</code> is a common subexpression
in either case.</p>



<p>The following example demonstrates the effect of the full laziness optimization:</p>

<div><div><pre><code><span>module</span> <span>Main</span> <span>where</span>
<span>import</span> <span>System.IO.Unsafe</span>

<span>hasSideEffect</span> <span>::</span> <span>Int</span> <span>-&gt;</span> <span>Int</span>
<span>hasSideEffect</span> <span>x</span> <span>=</span> <span>unsafePerformIO</span> <span>$</span> <span>do</span>
  <span>putStrLn</span> <span>"side effect!"</span>
  <span>pure</span> <span>x</span>

<span>f</span> <span>::</span> <span>Int</span> <span>-&gt;</span> <span>Int</span>
<span>f</span> <span>x</span> <span>=</span>
  <span>let</span> <span>g</span> <span>y</span> <span>=</span> <span>let</span> <span>n</span> <span>=</span> <span>hasSideEffect</span> <span>x</span>
             <span>in</span> <span>if</span> <span>y</span> <span>==</span> <span>0</span> <span>then</span> <span>0</span> <span>else</span> <span>g</span> <span>(</span><span>y</span><span>-</span><span>1</span><span>)</span> <span>+</span> <span>n</span>
   <span>in</span> <span>g</span> <span>5</span>

<span>main</span> <span>::</span> <span>IO</span> <span>()</span>
<span>main</span> <span>=</span> <span>print</span> <span>(</span><span>f</span> <span>0</span><span>)</span>
</code></pre></div></div>

<p>The full laziness optimization causes ‚Äúside effect!‚Äù to be only printed once. Although the value of
<code>n = hasSideEffect x</code> is used five times when evaluating <code>g 5</code>, <code>n</code> is only evaluated once, because
it is floated out of the body of <code>g</code>. If we disable full-laziness by passing <code>-fno-full-laziness</code>, you‚Äôd
see ‚Äúside effect!‚Äù printed five times.</p>

<p>In this example there‚Äôs no common subexpression to eliminate, so disabling CSE has no effect.</p>



<p>Inlining, on the contrary, can increase the number of times a side effect is performed.</p>

<div><div><pre><code><span>module</span> <span>Main</span> <span>where</span>
<span>import</span> <span>System.IO.Unsafe</span>

<span>hasSideEffect</span> <span>::</span> <span>Int</span>
<span>hasSideEffect</span> <span>=</span> <span>unsafePerformIO</span> <span>$</span> <span>do</span>
  <span>putStrLn</span> <span>"side effect!"</span>
  <span>pure</span> <span>42</span>
<span>{-# NOINLINE hasSideEffect #-}</span>

<span>x</span> <span>::</span> <span>Int</span>
<span>x</span> <span>=</span> <span>hasSideEffect</span> <span>+</span> <span>1</span>

<span>y</span> <span>::</span> <span>Int</span>
<span>y</span> <span>=</span> <span>hasSideEffect</span> <span>+</span> <span>2</span>

<span>main</span> <span>::</span> <span>IO</span> <span>()</span>
<span>main</span> <span>=</span> <span>print</span> <span>(</span><span>x</span> <span>+</span> <span>y</span><span>)</span>
</code></pre></div></div>

<p>This program prints ‚Äúside effect!‚Äù once, which is usually what you want for having a constant value defined using <code>unsafePerformIO</code>.
Turning off CSE and/or full laziness does not change the behavior. If you change <code>{-# NOINLINE hasSideEffect #-}</code> to
<code>{-# INLINE hasSideEffect #-}</code>, then ‚Äúside effect!‚Äù would be printed twice: once when evaluating <code>x</code> and once for <code>y</code>.</p>

<p>When there is neither an <code>INLINE</code> nor a <code>NOINLINE</code> pragma, GHC doesn‚Äôt seem to like inlining constants. It is, however, free
to do so. For constants that contain side effects, such as <code>hasSideEffect</code>, <code>x</code> and <code>y</code> in the above example, it is
therefore almost always advisable to apply the <code>NOINLINE</code> pragma. In fact, HLint warns
against missing <code>NOINLINE</code> pragmas for constants defined using <code>unsafePerformIO</code>s. This advice, of course, isn‚Äôt
applicable to functions with <code>unsafePerformIO</code>s in their bodies. For a function like <code>f x = unsafePerformIO (... x ...)</code>, the
side effect needs to be performed whenever <code>f</code> is applied to an <code>x</code>, so it may as well be inlined.</p>



<p>Consider this program.</p>

<div><div><pre><code><span>module</span> <span>Main</span> <span>where</span>
<span>import</span> <span>System.IO.Unsafe</span>

<span>hasSideEffect</span> <span>::</span> <span>Int</span> <span>-&gt;</span> <span>Int</span>
<span>hasSideEffect</span> <span>x</span> <span>=</span> <span>unsafePerformIO</span> <span>$</span> <span>do</span>
  <span>putStrLn</span> <span>"side effect!"</span>
  <span>pure</span> <span>x</span>

<span>f</span> <span>::</span> <span>Int</span> <span>-&gt;</span> <span>Int</span>
<span>f</span> <span>x</span> <span>=</span>
  <span>let</span> <span>g</span> <span>y</span> <span>=</span> <span>let</span> <span>z</span> <span>=</span> <span>hasSideEffect</span> <span>x</span> <span>in</span> <span>y</span> <span>+</span> <span>z</span>
      <span>{-# INLINE g #-}</span>
   <span>in</span> <span>g</span> <span>0</span> <span>+</span> <span>g</span> <span>1</span>

<span>main</span> <span>::</span> <span>IO</span> <span>()</span>
<span>main</span> <span>=</span> <span>print</span> <span>(</span><span>f</span> <span>0</span><span>)</span>
</code></pre></div></div>

<p>This program prints ‚Äúside effect!‚Äù just once, whether <code>g</code> is inlined or not inlined. In order to make ‚Äúside effect!‚Äù
print twice, you need to disable CSE if <code>g</code> is inlined, but disable
full laziness if <code>g</code> is not inlined. Let‚Äôs study why this is the case.</p>

<p>If <code>g</code> is inlined, <code>g 0 + g 1</code> becomes</p>

<div><div><pre><code><span>(</span><span>let</span> <span>z</span> <span>=</span> <span>hasSideEffect</span> <span>x</span> <span>in</span> <span>0</span> <span>+</span> <span>z</span><span>)</span> <span>+</span> <span>(</span><span>let</span> <span>z</span> <span>=</span> <span>hasSideEffect</span> <span>x</span> <span>in</span> <span>1</span> <span>+</span> <span>z</span><span>)</span>
</code></pre></div></div>

<p><code>hasSideEffect x</code> is a common subexpression, so it is factored out by CSE, causing ‚Äúside effect!‚Äù to be printed
just once. In this case the inlining happened in a simplifier pass before the full laziness pass (which can be
observed from the output of <code>-dshow-passes</code>), and therefore, the full laziness pass didn‚Äôt have the opportunity
to float <code>z = hasSideEffect x</code> out of <code>g</code> before <code>g</code> was inlined. This is why turning off
full laziness has no effect, but turning off CSE does.</p>

<p>If <code>g</code> is not inlined, on the other hand, there would be no common subexpression to eliminate.
Instead, the full laziness pass would float <code>z = hasSideEffect x</code> out of <code>g</code>. This is why turning off
CSE has no effect, but turning off full laziness does.</p>

<p>It is also possible to make it so that <em>both</em> <code>-fno-cse</code> and <code>-fno-full-laziness</code> are needed in order for
‚Äúside effect!‚Äù to be printed twice. For example, try <code>{-# NOINLINE [2] g #-}</code>. This is because</p>
<ul>
  <li>If full-laziness is turned on, <code>z = hasSideEffect x</code> would be floated out of <code>g</code> <em>before</em> inlining (because we told
GHC to avoid inlining until after phase 2, which comes after the full laziness pass). After <code>z = hasSideEffect x</code>
is floated out, it would <em>not</em> subsequently be inlined, and therefore ‚Äúside effect!‚Äù is only printed once.</li>
  <li>If CSE is turned on, it would happen <em>after</em> inlining. Since inlining enables CSE to ‚Äúsee‚Äù the common
subexpression <code>hasSideEffect x</code>, it is factored out, and therefore ‚Äúside effect!‚Äù is only printed once.</li>
</ul>

<p>Simply put, in this case inlining happens after the full-laziness pass but before the CSE pass, and this means
you need to turn them both off for the side effect to be performed twice.</p>

<p>This example shows that the interaction between CSE, full-laziness and inlining can be subtle. If your
program uses <code>unsafePerformIO</code> or similar unsafe functions, the simplest way to ensure that the behavior is easily predictable
is to either <code>NOINLINE</code> everything and turn off both CSE and full-laziness, or compile the program with <code>-O0</code>.
You don‚Äôt really want to do either of them because they both kill performance, so it really pays to understand the nuances so that you lose as little performance as possible while ensuring the program behaves as expected.</p>



<p>Using <code>unsafeDupablePerformIO</code> instead of <code>unsafePerformIO</code> is another way to potentially make an IO action
perform more times than intended. This is slightly off topic since it is about concurrency rather than GHC modifying
your program, but since <code>unsafeDupablePerformIO</code> falls in between the relatively safe <code>unsafePerformIO</code> and the
extremely unsafe <code>accursedUnutterablePerformIO</code>, I reckon it is worth mentioning.</p>

<p>A thunk is usually evaluated only once. When a thread attempts to force a thunk, and that thunk is already being
evaluated by another thread, the first thread would usually block rather than evaluating the thunk again. This is
achieved using a technique called <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2005/09/2005-haskell.pdf">blackholing</a>.
Blackholing is by default lazy, but an eager option is possible via flag <code>-feager-blackholing</code>, which guarantees
that no thunk is evaluated more than once (with a slight performance penalty).</p>

<p>If a thunk is built using <code>unsafePerformIO</code>, then even if the thunk is evaluated by more than one thread
in parallel, the IO ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://free.cofree.io/2020/07/20/perform-io/">https://free.cofree.io/2020/07/20/perform-io/</a></em></p>]]>
            </description>
            <link>https://free.cofree.io/2020/07/20/perform-io/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23906354</guid>
            <pubDate>Tue, 21 Jul 2020 12:37:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Non-grid-based path finder]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23906315">thread link</a>) | @SCLeo
<br/>
July 21, 2020 | https://scleox.github.io/non-grid-path-finder/ | <a href="https://web.archive.org/web/*/https://scleox.github.io/non-grid-path-finder/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://scleox.github.io/non-grid-path-finder/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23906315</guid>
            <pubDate>Tue, 21 Jul 2020 12:29:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Monitoring your own infrastructure using Grafana, InfluxDB, and CollectD]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23906165">thread link</a>) | @crecker
<br/>
July 21, 2020 | https://serhack.me/articles/monitoring-infrastructure-grafana-influxdb-connectd/ | <a href="https://web.archive.org/web/*/https://serhack.me/articles/monitoring-infrastructure-grafana-influxdb-connectd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://serhack.me/images/grafana/all%20together%20now_wide.jpg" alt="Grafana, InfluxDB and CollectD"></p><h4 id="for-some-companies-infrastructure-is-the-heart-of-its-business-specifically-i-am-referring-to-those-companies-which-need-to-manage-data-and-applications-located-on-more-than-one-server">For some companies, infrastructure is the heart of its business. Specifically, I am referring to those companies which need to manage data and applications located on more than one server.</h4><p>It is essential for a company to monitor its infrastructure nodes, especially if the company does not have on-site access to intervene when issues arise. In fact, the intensive use of some resources can be an indication of malfunctioning or overcrowding. However, in addition to prevention, monitoring could be used to assess possible implications of new software in the production environment. Currently, there are several ‚Äúready-to-use‚Äù solutions on the market to keep track of all the resources consumed. These solutions, which appear reasonable, present two key problems: the high price of setup and security issues related to third parties.</p><p>The first problem is related to cost. Prices vary from 10 euros per month up to thousands depending on how many hosts you need to monitor ‚Äî with the former being consumer pricing and the latter being enterprise pricing. So, for example, let‚Äôs imagine that I have three nodes to monitor during the course of a year. At 10 euros per month, I would spend 120 euros. For smaller enterprises, where the price can range between 10,000 and 20,000 euro per year, such an expense can bloat its underlying cost structure and become financially untenable.</p><p>The second problem is third party risk. Typically, infrastructure data must pass through a third party company in order to be seen and analysed for the customer ‚Äî whether that be an individual consumer or an enterprise. How does the third party company capture the data and then present it to the customer? Simply put, the third party company often collects data through a custom agent that is installed onto a node and monitored. Quite often is it found that this installation is not up-to-date and compatible with operating systems. Previous work has been done by security researchers who cast light upon problems with <a href="https://www.rapid7.com/db/modules/exploit/linux/misc/nagios_nrpe_arguments">‚Äúproprietary collectors‚Äù</a>. Would you trust them? I would not.</p><p>In keeping nodes for both <a href="https://trac.torproject.org/projects/tor/wiki/TorRelayGuide">Tor</a> and some <a href="https://getmonero.org/">cryptocurrencies</a>, I prefer to opt for a cost free, easy to configure, and open-source alternative. Here, we will use the triad: Grafana, InfluxDB, and CollectD.</p><p><img src="https://serhack.me/images/grafana/grafana-graphs.png" alt="An example of a Grafana dashboard"></p><h2 id="monitoring">Monitoring</h2><p>In order to be able to analyse every metric of our infrastructure, it is necessary to use a program capable of capturing statistics on the machines we want to monitor. In this regard, <a href="https://collectd.org/">CollectD</a> comes to your aid: it is a daemon that groups and collects (hence the name) all the parameters that can be stored on disk or sent over the network.</p><p>The data will be transmitted to an instance of <a href="https://www.influxdata.com/">InfluxDB</a>: a particular time series database that associates to each data the time (coded in UNIX timestamp) in which the server received it. In this way, the data sent by CollectD will already be set in a temporal way, as a succession of events.</p><p>Finally, you will use <a href="http://grafana.org/">Grafana</a> which will connect to InfluxDB to create flashy dashboards to display the data in a user-friendly way. Through histograms and graphs of every kind, it will be possible to observe in real time all the data related to CPU, RAM, etc.</p><p><img src="https://serhack.me/images/grafana/grafana-diagram.png" alt="Grafana infrastructure"></p><h2 id="influxdb">InfluxDB</h2><picture>
<source media="(min-width: 535px)" data-original-set="/images/grafana/db_alone.jpg 1x,
                /images/grafana/db_alone_wide.jpg 2x"><source media="(max-width: 534px)" data-original-set="/images/grafana/db_alone.jpg 1x,
                /images/grafana/db_alone.jpg 2x" src-set="/images/grafana/db_alone.jpg 1x,
                /images/grafana/db_alone.jpg 2x"><img data-original="/images/grafana/db_alone.jpg" data-original-set="/images/grafana/db_alone_wide.jpg 2x" src="https://serhack.me/images/grafana/db_alone_wide.jpg" alt=""></picture><p>Let‚Äôs start with InfluxDB, which is the beating heart of our monitoring ‚Äúsystem‚Äù. InfluxDB is a time series database <a href="https://github.com/influxdata/influxdb">open-source</a> developed in <a href="https://golang.org/">Go</a> to store data as a sequence of events.</p><p>Each time data is added, it is linked to <a href="https://en.wikipedia.org/wiki/Unix_time">a UNIX timestamp</a> by default. This allows enormous flexibility for the user who no longer has to worry about saving, as an example, the ‚Äútime‚Äù variable, which is sometimes cumbersome to configure. Let‚Äôs imagine we have several machines located in a number of continents. How do we manage the ‚Äútime‚Äù variable? Do we use the <a href="https://en.wikipedia.org/wiki/Greenwich_Mean_Time">Greenwich</a> meridian for all the data? Or do we set a different time zone for each node? If data is saved on different time zones, how can we accurately display the graphs? As you can see, this can be very complicated.</p><p>As a time-aware database that automatically timestamps any data point, InfluxDB has the advantage of simultaneously being able to write to a certain database. This is why we often imagine InfluxDB as a timeline. Writing data does not affect the performance of the database (as sometimes happens in MySQL), since writing is simply the addition of a certain event to the timeline. The name of the program derives precisely from the conception of time as an infinite and indefinite ‚Äúflow‚Äù that flows.</p><h3 id="installation-and-configuration">Installation and configuration</h3><p>Another advantage of InflxuDB is the <a href="https://docs.influxdata.com/influxdb/v1.8/introduction/install/">ease of installation</a> and the extensive <a href="https://docs.influxdata.com/">documentation</a> provided by the community that widely supports the project. It has two types of interfaces: via <a href="https://docs.influxdata.com/influxdb/v1.8/tools/shell/">Command Line</a> (which is powerful and flexible for developers, but poorly prepared to see large amounts of data) and an <a href="https://docs.influxdata.com/influxdb/v1.8/guides/write_data/#sidebar">HTTP API</a> that allows direct communication with the database.</p><p>InfluxDB can be downloaded not only from the official website, but also from the package manager of the distribution (in this example we use a Debian system). It is advisable to check the package via GPG before installation, so (below) we import the keys of the InfluxDB package:</p><div><pre><code data-lang="bash"><a href="https://serhack.me/cdn-cgi/l/email-protection" data-cfemail="86f4e9e9f2c6e8e9e2e3">[email&nbsp;protected]</a>#~: curl -sL https://repos.influxdata.com/influxdb.key | sudo apt-key add -
<a href="https://serhack.me/cdn-cgi/l/email-protection" data-cfemail="c8baa7a7bc88a6a7acad">[email&nbsp;protected]</a>#~: source /etc/os-release
<a href="https://serhack.me/cdn-cgi/l/email-protection" data-cfemail="9ceef3f3e8dcf2f3f8f9">[email&nbsp;protected]</a>#~: echo <span>"deb https://repos.influxdata.com/debian </span><span>$(</span>lsb_release -cs<span>)</span><span> stable"</span> | sudo tee /etc/apt/sources.list.d/influxdb.list</code></pre></div><p>Finally, we update and install InfluxDB:</p><p>To start it, we use <code>systemctl</code>:</p><p>To make sure that no one nefarious enters, we create the user ‚Äúadministrator‚Äù. InfluxDB uses a particular query language called <a href="https://docs.influxdata.com/influxdb/v1.8/query_language/">‚ÄúInfluxQL‚Äù</a>, similar to SQL, which allows you to interact with the database. To create a new entry, we use the query <a href="https://docs.influxdata.com/influxdb/v1.8/administration/authentication_and_authorization/#user-management-commands"><code>CREATE USER</code></a>.</p><div><pre><code data-lang="bash"><a href="https://serhack.me/cdn-cgi/l/email-protection" data-cfemail="45372a2a31052b2a2120">[email&nbsp;protected]</a>#~: influx
Connected to http://localhost:8086
InfluxDB shell version: x.y.z
&gt;
&gt; CREATE USER admin WITH PASSWORD <span>'MYPASSISCOOL'</span> WITH ALL PRIVILEGES</code></pre></div><p>From the same CLI interface, we create the ‚Äúmetrics‚Äù database that will be used as a container for our metrics.</p><div><pre><code data-lang="bash">&gt; CREATE DATABASE metrics</code></pre></div><p>Next, let‚Äôs modify the configuration of InfluxDB (<code>/etc/influxdb/influxdb.conf</code>) to have the interface open on port <strong>24589</strong> (UDP) with direct connection to the database named ‚Äúmetrics‚Äù in support of CollectD. You also need to download and place the <a href="https://raw.githubusercontent.com/collectd/collectd/master/src/types.db">types.db</a> file in <code>/usr/share/collectd/</code> (or any other folder) to define the data that <a href="https://docs.influxdata.com/influxdb/v1.8/supported_protocols/collectd/">CollectD sends in native format</a>.</p><div><pre><code data-lang="bash"><a href="https://serhack.me/cdn-cgi/l/email-protection" data-cfemail="c3b1acacb783adaca7a6">[email&nbsp;protected]</a>#~: nano /etc/influxdb/influxdb.conf
<span>[</span>Collectd<span>]</span>
enabled <span>=</span> true
bind-address <span>=</span> <span>":24589"</span>
database <span>=</span> <span>"metrics"</span>
typesdb <span>=</span> <span>"/usr/share/collectd/types.db"</span></code></pre></div><p>For further information on the CollectD block within the configuration, see the <a href="https://docs.influxdata.com/influxdb/v1.8/administration/config/#collectd-settings">reference to documentation</a>.</p><h2 id="collectd">CollectD</h2><picture>
<source media="(min-width: 535px)" data-original-set="/images/grafana/daemon_alone.jpg 1x,
                /images/grafana/daemon_alone_wide.jpg 2x"><source media="(max-width: 534px)" data-original-set="/images/grafana/daemon_alone.jpg 1x,
                /images/grafana/daemon_alone.jpg 2x" src-set="/images/grafana/daemon_alone.jpg 1x,
                /images/grafana/daemon_alone.jpg 2x"><img data-original="/images/grafana/daemon_alone.jpg" data-original-set="/images/grafana/daemon_alone_wide.jpg 2x" src="https://serhack.me/images/grafana/daemon_alone_wide.jpg" alt=""></picture><p>CollectD is a data aggregator, in our monitoring infrastructure, that facilitates the transmission of data to InfluxDB. By default, CollectD captures metrics on CPU, RAM, memory (on disk), network interfaces, processes, etc. The potential of the program is endless, given that it can be extended with a preinstalled <a href="https://collectd.org/wiki/index.php/Table_of_Plugins">plugin enablement</a> or through the <a href="https://collectd.org/wiki/index.php/Roadmap#Wishlist_.2F_Ideas">creation of new ones</a>.</p><p>As you can see, installing CollectD is simple:</p><p>In a simplistic manner, let‚Äôs illustrate how CollectD works. Suppose that I want to check how many processes my node has. In doing so, CollectD does nothing more than make an API call to get the number of processes per time unit (defined as 5000 ms, by default). Once captured, the data will be sent to InfluxDB via a module (called ‚ÄúNetwork‚Äù) to be configured.</p><p>Open the file <code>/etc/collectd.conf</code> with our editor, scroll to find the <code>Network</code> section, and edit as written in the following snippet. Be sure to specify the IP where the interface of InfluxDB (<code>INFLUXDB_IP</code>) is located.</p><div><pre><code data-lang="bash"><a href="https://serhack.me/cdn-cgi/l/email-protection" data-cfemail="6b1904041f2b05040f0e">[email&nbsp;protected]</a>#~: nano /etc/collectd.conf
    ...
&lt;Plugin network&gt;
  &lt;Server <span>"INFLUXDB_IP"</span> <span>"24589"</span>&gt;
  &lt;/Server&gt;
  ReportStats true
&lt;/Plugin&gt;
    ...</code></pre></div><p>My suggestion is to modify, within the configuration, the hostname that is sent to InfluxDB (which in our infrastructure is a ‚Äúcentralized‚Äù database, since it resides on a single node). In doing so, the data will not be redundant and there is no risk that other nodes will overwrite the information.</p><p><img src="https://serhack.me/images/grafana/tres_caballeros.jpg" alt="Three daemon"></p><h2 id="grafana">Grafana</h2><p><img src="https://serhack.me/images/grafana/grafana_alone.jpg" alt=""></p><blockquote><p>A graph is worth thousand of images</p></blockquote><p>In remembrance of this famous ‚Äúquote‚Äù, observing the infrastructure metrics live through graphs and tables enables us to act in an efficient and timely manner. To create and configure the dashboard, we will use Grafana.</p><p>Grafana is an open-source tool, compatible with a wide range of databases (including InfluxDB), that presents a graphical representation of metrics and allows a user to create alerts if a particular piece of data meets a condition. For example, if your CPU reaches high peaks, you can be notified on Slack, Mattermost, by email, etc. In fact, I have personally configured an alert every time someone enters SSH, so I can actively monitor who ‚Äúenters‚Äù my infrastructure.</p><p>Grafana does not require any special settings: once again, it is InfluxDB that ‚Äúscans‚Äù the ‚Äútime‚Äù variable. The integration is simple. Let‚Äôs start by import the public key to add the package from the <a href="https://grafana.com/grafana/download">Grafana official website</a> (it depends on the OS you are using):</p><div><pre><code data-lang="bash"><a href="https://serhack.me/cdn-cgi/l/email-protection" data-cfemail="691b06061d2907060d0c">[email&nbsp;protected]</a>#~: wget -q -O - https://packages.grafana.com/gpg.key | sudo apt-key add -
<a href="https://serhack.me/cdn-cgi/l/email-protection" data-cfemail="11637e7e65517f7e7574">[email&nbsp;protected]</a>#~: echo <span>"deb https://packages.grafana.com/oss/deb stable main"</span> | sudo tee -a /etc/apt/sources.list.d/grafana.list 
<a href="https://serhack.me/cdn-cgi/l/email-protection" data-cfemail="6f1d00001b2f01000b0a">[email&nbsp;protected]</a>#~: apt-get update <span>&amp;&amp;</span> apt-get install grafana</code></pre></div><p>Let‚Äôs start it through systemctl:</p><p>Next, as we go to the localhost:3000 page through the browser, we should be presented with a login interface for Grafana. By default, you should use <strong>admin</strong> as username and <strong>admin</strong> as password (it is advisable to change the password after the first login).</p><p><img src="https://serhack.me/images/grafana/login-page.png" alt="Login page"></p><p>Let‚Äôs go to Sources and add our Influx database:</p><p><img src="https://serhack.me/images/grafana/add-data-source.png" alt="Add data source to Grafana"></p><p><img src="https://serhack.me/images/grafana/influxdb.png" alt="InfluxDB"></p><p>The screen now shows a small green rectangle just below the New Dashboard. Hover your mouse over this rectangle and select Add Panel, then Graph:</p><p><img src="https://serhack.me/images/grafana/add-new-panel.png" alt="Add a new panel"></p><p>A graph with the test data is now shown. Click on the title of this chart and choose Edit. Grafana allows the writing of ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://serhack.me/articles/monitoring-infrastructure-grafana-influxdb-connectd/">https://serhack.me/articles/monitoring-infrastructure-grafana-influxdb-connectd/</a></em></p>]]>
            </description>
            <link>https://serhack.me/articles/monitoring-infrastructure-grafana-influxdb-connectd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23906165</guid>
            <pubDate>Tue, 21 Jul 2020 12:02:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Customizing pandoc to generate beautiful pdf and ePub from markdown]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23906117">thread link</a>) | @asicsp
<br/>
July 21, 2020 | https://learnbyexample.github.io/tutorial/ebook-generation/customizing-pandoc/ | <a href="https://web.archive.org/web/*/https://learnbyexample.github.io/tutorial/ebook-generation/customizing-pandoc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" aria-label="Content">
  <article>
    

    <div>
      

      

      <div>
        <div>
          <p><strong>Table of Contents</strong></p>

<ul>
  <li><a href="#installation">Installation</a></li>
  <li><a href="#minimal-example">Minimal example</a></li>
  <li><a href="#chapter-breaks">Chapter breaks</a></li>
  <li><a href="#changing-settings-via--v-option">Changing settings via -V option</a></li>
  <li><a href="#syntax-highlighting">Syntax highlighting</a></li>
  <li><a href="#bullet-styling">Bullet styling</a></li>
  <li><a href="#pdf-properties">PDF properties</a></li>
  <li><a href="#adding-table-of-contents">Adding table of contents</a></li>
  <li><a href="#adding-cover-image">Adding cover image</a></li>
  <li><a href="#stylish-blockquote">Stylish blockquote</a></li>
  <li><a href="#customizing-epub">Customizing epub</a></li>
  <li><a href="#resource-links">Resource links</a></li>
</ul>



<p>Either you‚Äôve already heard of <code>pandoc</code> or if you have searched online for <code>markdown</code> to <code>pdf</code> or similar, you are sure to come across <code>pandoc</code>. This tutorial will help you use <code>pandoc</code> to generate <code>pdf</code> and <code>epub</code> from a <a href="https://github.github.com/gfm/">GitHub style markdown</a> file. The main motivation for this blog post is to highlight what customizations I did to generate <code>pdf</code> and <code>epub</code> versions for <a href="https://learnbyexample.github.io/books/">self-publishing my ebooks</a>. It wasn‚Äôt easy to arrive at the set-up I ended up with, so I hope this will be useful for those looking to use <code>pandoc</code> to generate <code>pdf</code> and <code>epub</code> formats. This guide is specifically aimed at technical books that has code snippets.</p>



<h2 id="installation"><a name="installation"></a>Installation</h2>

<p>I use Ubuntu, as far as I remember, the below steps are enough to work for the demos in this tutorial. If you get an error or warning, search that issue online and you‚Äôll likely find what else has to be installed.</p>

<p>I first downloaded <code>deb</code> file from <a href="https://github.com/jgm/pandoc/releases">pandoc: releases</a> and installed it. Followed by packages needed for <code>pdf</code> generation.</p>

<div><div><pre><code><span>$ </span><span># latest pandoc version as of 21 July 2010 is 2.10</span>
<span>$ </span><span>sudo </span>gdebi ~/Downloads/pandoc-2.10-1-amd64.deb

<span>$ </span><span># note that download size is 750+ MB</span>
<span>$ </span><span>sudo </span>apt <span>install </span>texlive-xetex
<span>$ </span><span>sudo </span>apt <span>install </span>librsvg2-bin
<span>$ </span><span>sudo </span>apt <span>install </span>texlive-math-extra
</code></pre></div></div>

<p>For more details and guide for other OS, refer to <a href="https://pandoc.org/installing.html">pandoc: installation</a></p>



<h2 id="minimal-example"><a name="minimal-example"></a>Minimal example</h2>

<p>Once <code>pandoc</code> is working on your system, try generating a sample <code>pdf</code> without any customization.</p>

<p><img src="https://learnbyexample.github.io/images/info.svg" alt="info"> See <a href="https://github.com/learnbyexample/learnbyexample.github.io/tree/master/files/pandoc_pdf">learnbyexample.github.io repo</a> for all the input and output files referred in this tutorial.</p>

<div><div><pre><code><span>$ </span>pandoc sample_1.md <span>-f</span> gfm <span>-o</span> sample_1.pdf
</code></pre></div></div>

<p>Here <code>sample_1.md</code> is input markdown file and <code>-f</code> is used to specify that the input format is GitHub style markdown. The <code>-o</code> option specifies the output file type based on extension. The default output is probably good enough. But I wished to customize hyperlinks, inline code style, add page breaks between chapters, etc. This blog post will discuss these customizations one by one.</p>

<p><img src="https://learnbyexample.github.io/images/info.svg" alt="info"> <code>pandoc</code> has its own flavor of <code>markdown</code> with many useful extensions ‚Äî see <a href="https://pandoc.org/MANUAL.html#pandocs-markdown">pandoc: pandocs-markdown</a> for details. GitHub style markdown is recommended if you wish to use the same source (or with minor changes) in multiple places.</p>

<p><img src="https://learnbyexample.github.io/images/info.svg" alt="info"> It is advised to use <code>markdown</code> headers in order without skipping ‚Äî for example, <code>H1</code> for chapter heading and <code>H2</code> for chapter sub-section, etc is fine. <code>H1</code> for chapter heading and <code>H3</code> for sub-section is not. Using the former can give automatic index navigation on ebook readers.</p>

<p>On <a href="https://wiki.gnome.org/Apps/Evince">Evince</a> reader, the index navigation for above sample looks like this:</p>

<p><img src="https://learnbyexample.github.io/images/pandoc_pdf/chapter_index.png" alt="Chapter Index"></p>



<h2 id="chapter-breaks"><a name="chapter-breaks"></a>Chapter breaks</h2>

<p>As observed from previous demo, by default there are no chapter breaks. Searching for a <a href="https://superuser.com/questions/601469/getting-chapters-to-start-on-a-new-page-in-a-pandoc-generated-pdf">solution online</a>, I got this piece of <code>tex</code> code:</p>

<div><div><pre><code><span>\usepackage</span><span>{</span>sectsty<span>}</span>
<span>\sectionfont</span><span>{</span><span>\clearpage</span><span>}</span>
</code></pre></div></div>

<p>This can be added using <code>-H</code> option. From <code>pandoc</code> manual,</p>

<blockquote>
  <p>-H FILE, ‚Äìinclude-in-header=FILE</p>

  <p>Include  contents  of FILE, verbatim, at the end of the header.  This
can be used, for example, to include special  CSS  or  JavaScript  in
HTML documents.  This option can be used repeatedly to include multiple
files in the header.  They will be included in the  order  specified.
Implies ‚Äìstandalone.</p>
</blockquote>

<p>The <code>pandoc</code> invocation now looks like:</p>

<div><div><pre><code><span>$ </span>pandoc sample_1.md <span>-f</span> gfm <span>-H</span> chapter_break.tex <span>-o</span> sample_1_chapter_break.pdf
</code></pre></div></div>

<p>You can add further customization to headings, for example use <code>\sectionfont{\underline\clearpage}</code> to underline chapter names or <code>\sectionfont{\LARGE\clearpage}</code> to allow chapter names to get even bigger. Here‚Äôs some more links to read about various customizations:</p>

<ul>
  <li><a href="https://tex.stackexchange.com/questions/1455/how-to-set-the-font-for-a-section-title-and-chapter-etc">tex.stackexchange: section fonts</a></li>
  <li><a href="https://tex.stackexchange.com/questions/230730/section-coming-up-as-undefined-when-using-sectsty">tex.stackexchange: section colors</a></li>
  <li><a href="https://tex.stackexchange.com/questions/10138/change-section-fonts">tex.stackexchange: change section fonts</a></li>
</ul>



<h2 id="changing-settings-via--v-option"><a name="changing-settings-via--v-option"></a>Changing settings via -V option</h2>

<blockquote>
  <p>-V KEY[=VAL], ‚Äìvariable=KEY[:VAL]</p>

  <p>Set the template variable KEY to the value  VAL  when  rendering  the
document  in standalone mode.  This is generally only useful when the
‚Äìtemplate option is used to specify a custom template, since  pandoc
automatically  sets  the variables used in the default templates.  If
no VAL is specified, the key will be given the value true.</p>
</blockquote>

<p>The <code>-V</code> option allows to change variable values to customize settings like page size, font, link color, etc. As more settings are changed, better to use a simple script to call <code>pandoc</code> instead of typing the whole command on terminal.</p>

<div><div><pre><code><span>#!/bin/bash</span>

pandoc <span>"</span><span>$1</span><span>"</span> <span>\</span>
    <span>-f</span> gfm <span>\</span>
    <span>--include-in-header</span> chapter_break.tex <span>\</span>
    <span>-V</span> linkcolor:blue <span>\</span>
    <span>-V</span> geometry:a4paper <span>\</span>
    <span>-V</span> geometry:margin<span>=</span>2cm <span>\</span>
    <span>-V</span> <span>mainfont</span><span>=</span><span>"DejaVu Serif"</span> <span>\</span>
    <span>-V</span> <span>monofont</span><span>=</span><span>"DejaVu Sans Mono"</span> <span>\</span>
    <span>--pdf-engine</span><span>=</span>xelatex <span>\</span>
    <span>-o</span> <span>"</span><span>$2</span><span>"</span>
</code></pre></div></div>

<ul>
  <li><code>mainfont</code> is for normal text</li>
  <li><code>monofont</code> is for code snippets</li>
  <li><code>geometry</code> for page size and margins</li>
  <li><code>linkcolor</code> to set hyperlink color</li>
  <li>to increase default <strong>font size</strong>, use <code>-V fontsize=12pt</code>
    <ul>
      <li>See <a href="https://stackoverflow.com/questions/23811002/from-markdown-to-pdf-how-to-change-the-font-size-with-pandoc">stackoverflow: change font size</a> if you need even bigger size options</li>
    </ul>
  </li>
</ul>

<p>Using <code>xelatex</code> as the <code>pdf-engine</code> allows to use any font installed in the system. One reason I chose <code>DejaVu</code> was because it supported <strong>Greek</strong> and other Unicode characters that were causing error with other fonts. See <a href="https://tex.stackexchange.com/questions/21736/using-xelatex-instead-of-pdflatex">tex.stackexchange: Using XeLaTeX instead of pdfLaTeX</a> for some more details.</p>

<p>The <code>pandoc</code> invocation is now through a script:</p>

<div><div><pre><code><span>$ </span><span>chmod</span> +x md2pdf.sh
<span>$ </span>./md2pdf.sh sample_1.md sample_1_settings.pdf
</code></pre></div></div>

<p>Do compare the pdf generated side by side with previous output before proceeding.</p>

<p><img src="https://learnbyexample.github.io/images/warning.svg" alt="warning"> On my system, <code>DejaVu Serif</code> did not have <em>italic</em> variation installed, so I had to use <code>sudo apt install ttf-dejavu-extra</code> to get it.</p>



<h2 id="syntax-highlighting"><a name="syntax-highlighting"></a>Syntax highlighting</h2>

<p>One option to customize syntax highlighting for code snippets is to save one of the <code>pandoc</code> themes and editing it. See <a href="https://stackoverflow.com/questions/30880200/pandoc-what-are-the-available-syntax-highlighters/47876166#47876166">stackoverflow: What are the available syntax highlighters?</a> for available themes and more details (as a good practice on stackoverflow, go through all answers and comments ‚Äî the linked/related sections on sidebar are useful as well).</p>

<div><div><pre><code><span>$ </span>pandoc <span>--print-highlight-style</span><span>=</span>pygments <span>&gt;</span> pygments.theme
</code></pre></div></div>

<p>Edit the above file to customize the theme. Use sites like <a href="https://www.colorhexa.com/">colorhexa</a> to help with color choices, hex values, etc. For this demo, the below settings are changed:</p>

<div><div><pre><code># by default, background is same as normal text
# change it to a shade of gray to easily distinguish code and text
"background-color": "#f8f8f8",

# change italic to false, messes up comments with slashes
# change comment text-color to yet another shade of gray
"Comment": {
    "text-color": "#9c9c9c",
    "background-color": null,
    "bold": false,
    "italic": false,
    "underline": false
},
</code></pre></div></div>

<p><strong>Inline code</strong></p>

<p>Similar to changing background color for code snippets, I found a <a href="https://stackoverflow.com/questions/40975004/pandoc-latex-change-backtick-highlight">solution online</a> to change background color for inline code snippets.</p>

<div><div><pre><code><span>\usepackage</span><span>{</span>fancyvrb,newverbs,xcolor<span>}</span>

<span>\definecolor</span><span>{</span>Light<span>}{</span>HTML<span>}{</span>F4F4F4<span>}</span>

<span>\let\oldtexttt\texttt</span>
<span>\renewcommand</span><span>{</span><span>\texttt</span><span>}</span>[1]<span>{</span>
  <span>\colorbox</span><span>{</span>Light<span>}{</span><span>\oldtexttt</span><span>{</span>#1<span>}}</span>
<span>}</span>
</code></pre></div></div>

<p>Add <code>--highlight-style pygments.theme</code> and <code>--include-in-header inline_code.tex</code> to the script and generate the <code>pdf</code> again.</p>

<p>With <code>pandoc sample_2.md -f gfm -o sample_2.pdf</code> the output would be:</p>

<p><img src="https://learnbyexample.github.io/images/pandoc_pdf/default_syn.png" alt="Default syntax highlighting"></p>

<p>With <code>./md2pdf_syn.sh sample_2.md sample_2_syn.pdf</code> the output is:</p>

<p><img src="https://learnbyexample.github.io/images/pandoc_pdf/customized_syn.png" alt="Customized syntax highlighting"></p>



<p>For my <a href="https://github.com/learnbyexample/py_regular_expressions">Python re(gex)?</a> book, by chance I found that using <code>ruby</code> instead of <code>python</code> for REPL code snippets syntax highlighting was better. Snapshot from <code>./md2pdf_syn.sh sample_3.md sample_3.pdf</code> result is shown below. For <code>python</code> directive, string output gets treated as a comment and color for boolean values isn‚Äôt easy to distinguish from string values. The <code>ruby</code> directive treats string value as expected and boolean values are easier to spot.</p>

<p><img src="https://learnbyexample.github.io/images/pandoc_pdf/python_vs_ruby_syn.png" alt="REPL syntax highlighting"></p>



<h2 id="bullet-styling"><a name="bullet-styling"></a>Bullet styling</h2>

<p>This <a href="https://stackoverflow.com/questions/22156999/how-to-change-the-style-of-bullets-in-pandoc-markdown">stackoverflow Q&amp;A</a> helped for bullet styling.</p>

<div><div><pre><code><span>\usepackage</span><span>{</span>enumitem<span>}</span>
<span>\usepackage</span><span>{</span>amsfonts<span>}</span>

<span>% level one</span>
<span>\setlist</span><span>[itemize,1]</span><span>{</span>label=<span>$</span><span>\bullet</span><span>$}</span>
<span>% level two</span>
<span>\setlist</span><span>[itemize,2]</span><span>{</span>label=<span>$</span><span>\circ</span><span>$}</span>
<span>% level three</span>
<span>\setlist</span><span>[itemize,3]</span><span>{</span>label=<span>$</span><span>\star</span><span>$}</span>
</code></pre></div></div>

<p>Comparing <code>pandoc sample_4.md -f gfm -o sample_4.pdf</code> vs <code>./md2pdf_syn_bullet.sh sample_4.md sample_4_bullet.pdf</code> gives:</p>

<p><img src="https://learnbyexample.github.io/images/pandoc_pdf/bullet_styling.png" alt="Bullet styling"></p>



<h2 id="pdf-properties"><a name="pdf-properties"></a>PDF properties</h2>

<p>This <a href="https://tex.stackexchange.com/questions/23235/eliminate-edit-pdf-properties-added-by-pdflatex">tex.stackexchange Q&amp;A</a> helped to change metadata. See also <a href="https://pspdfkit.com/blog/2018/whats-hiding-in-your-pdf/">pspdfkit: What‚Äôs Hiding in Your PDF?</a> and <a href="https://news.ycombinator.com/item?id=18381515">discussion on HN</a>.</p>

<div><div><pre><code><span>\usepackage</span><span>{</span>hyperref<span>}</span>

<span>\hypersetup</span><span>{</span>
  pdftitle=<span>{</span>My awesome book<span>}</span>,
  pdfauthor=<span>{</span>learnbyexample<span>}</span>,
  pdfsubject=<span>{</span>pandoc<span>}</span>,
  pdfkeywords=<span>{</span>pandoc,pdf,xelatex<span>}</span>
<span>}</span>
</code></pre></div></div>

<p><code>./md2pdf_syn_bullet_prop.sh sample_4.md sample_4_bullet_prop.pdf</code> gives:</p>

<p><img src="https://learnbyexample.github.io/images/pandoc_pdf/pdf_properties.png" alt="PDF properties"></p>



<h2 id="adding-table-of-contents"><a name="adding-table-of-contents"></a>Adding table of contents</h2>

<p>There‚Äôs a handy option <code>--toc</code> to automatically include table of contents at top of the generated <code>pdf</code>. You can control number of levels using <code>--toc-depth</code> option, the default is 3 levels. You can also change the default string <code>Contents</code> to something else using <code>-V toc-title</code> option.</p>

<p><code>./md2pdf_syn_bullet_prop_toc.sh sample_1.md sample_1_toc.pdf</code> gives:</p>

<p><img src="https://learnbyexample.github.io/images/pandoc_pdf/table_of_contents.png" alt="table of contents"></p>



<h2 id="adding-cover-image"><a name="adding-cover-image"></a>Adding cover image</h2>

<p>To add something prior to table of contents, cover image for example, you can use a <code>tex</code> file and include it verbatim. Create a <code>tex</code> file (named as <code>cover.tex</code> here) with content as shown below:</p>

<div><div><pre><code><span>\includegraphics</span><span>{</span>cover.png<span>}</span>
<span>\thispagestyle</span><span>{</span>empty<span>}</span>
</code></pre></div></div>

<p>Then, modify the previous script <code>md2pdf_syn_bullet_prop_toc.sh</code> by adding <code>--include-before-body cover.tex</code> and tada ‚Äî you get the cover image before table of contents. <code>\thispagestyle{empty}</code> helps to avoid page number on the cover page, see also <a href="https://tex.stackexchange.com/questions/360739/what-is-the-use-of-clearpage-thispagestyleempty-cleardoublepage">tex.stackexchange: clear page</a>.</p>

<p>The <code>bash</code> script invocation is now <code>./md2pdf_syn_bullet_prop_toc_cover.sh sample_5.md sample_5.pdf</code>.</p>

<p><img src="https://learnbyexample.github.io/images/warning.svg" alt="warning"> You‚Äôll need at least one image in input markdown file, otherwise settings won‚Äôt apply to the cover image and you may end up with weird output. <code>sample_5.md</code> used in the command above includes an image. And be careful to use escapes if the image path can contain <code>tex</code> metacharacters.</p>



<h2 id="stylish-blockquote"><a name="stylish-blockquote"></a>Stylish blockquote</h2>

<p>By default, blockquotes (lines starting with <code>&gt;</code> in markdown) are just indented in the <code>pdf</code> output. To make them standout, <a href="https://tex.stackexchange.com/questions/154528/how-to-change-the-background-color-and-border-of-a-pandoc-generated-blockquote">tex.stackexchange: change the background color and border of blockquote</a> helped.</p>

<p>Create‚Ä¶</p></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://learnbyexample.github.io/tutorial/ebook-generation/customizing-pandoc/">https://learnbyexample.github.io/tutorial/ebook-generation/customizing-pandoc/</a></em></p>]]>
            </description>
            <link>https://learnbyexample.github.io/tutorial/ebook-generation/customizing-pandoc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23906117</guid>
            <pubDate>Tue, 21 Jul 2020 11:49:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Presentation: The Technical Evolution of Mailinator.com]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23906102">thread link</a>) | @zinxq
<br/>
July 21, 2020 | https://manybrain.github.io/m8r_blog/blog/mailinator-evolution/ | <a href="https://web.archive.org/web/*/https://manybrain.github.io/m8r_blog/blog/mailinator-evolution/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Mailinator started 17 years ago as a weekend project to define the idea of ‚ÄúFree, Disposable, Email‚Äù. Back then, it ran on a single server with only a single developer. Over time, it‚Äôs popularity has exploded in terms of both incoming email and active users. As you might guess when you go from thousands of emails-per-day to <strong>thousands of emails-per-second</strong>, the behind-the-scenes technical stack needs to evolve - and Mailinator‚Äôs stack has had a quite a technical journey.</p>
<p><img src="https://manybrain.github.io/m8r_blog/img/2020/07/image1.png" alt="Slide showing beginning and end tech evolution for Mailinator.com"></p>
<p>Today Mailinator still provides free, disposable, email - but also serves thousands of daily corporate users in testing their Email and SMS Workflows with an API, Webhooks, and Private Domains. Website owners quickly realized that having an infinite number of inboxes ‚Äúon tap‚Äù was incredibly useful for testing things their like their Signup system, Marketing email systems, and more. Quality Assurance teams found it to be an invaluable tool.</p>
<p>In February 2020, Mailinator‚Äôs creator Paul Tyma gave a talk on the ‚ÄúTechnical Evolution of Mailinator.com‚Äù. Below you can find a link to the slides and watch the video. The talk explores the site‚Äôs journey from a ‚ÄúFree, Disposable, Email‚Äù to a becoming SaaS service helping thousands of companies test their Email and SMS Workflows (and of course, scaling a system to tens of millions of emails per day).</p>
<p><a href="https://drive.google.com/file/d/1HV8BZUPBp4HT5C8Ob3rMXCWhSo5F9oRa/view?usp=sharing">GET THE SLIDES HERE</a></p>

<p>
  <iframe src="https://www.youtube.com/embed/BqNfHsZ3QUc" allowfullscreen="" title="YouTube Video"></iframe>
</p>


  </div></div>]]>
            </description>
            <link>https://manybrain.github.io/m8r_blog/blog/mailinator-evolution/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23906102</guid>
            <pubDate>Tue, 21 Jul 2020 11:44:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Webflow to Email Integration]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23906068">thread link</a>) | @pau_alcala
<br/>
July 21, 2020 | https://blog.palabra.io/how-to-send-a-confirmation-email-when-someone-submits-a-webflow-form?ref=hackernews | <a href="https://web.archive.org/web/*/https://blog.palabra.io/how-to-send-a-confirmation-email-when-someone-submits-a-webflow-form?ref=hackernews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>If you have a landing page or website created in Webflow, chances are you added some sort of contact form to reach interested users or prospects. Nothing gives your site more validation than people leaving their contact information, so you'll probably want to use that to make the most out of your site's traffic.</p><p>In this short article we'll show you how to send automated <strong>emails when someone submits a Webflow form</strong> using&nbsp;<a href="https://www.palabra.io/">Palabra</a>.</p><p>But why send just one email? We'll show you how to set up an entire automated sequence to welcome and engage your prospects using a no-code tool in just 5 minutes.</p><p><em>Note: Pretty obvious, but you need to have an existing Webflow site including a form to use this guide. You can learn how to do that <a href="https://university.webflow.com/article/intro-to-forms">here</a>.</em></p><h3>Step 1: Create an email trigger from a Webflow form</h3><p>To start, create a trigger and add a condition. Select "User submitted a form on Webflow" to set up the integration.</p><p><span>
      <span></span>
  <img alt="1.png" title="1.png" src="https://blog.palabra.io/static/dda0a44008c569addd2daa6c9ee571dd/7d769/1.png" srcset="https://blog.palabra.io/static/dda0a44008c569addd2daa6c9ee571dd/5243c/1.png 240w,https://blog.palabra.io/static/dda0a44008c569addd2daa6c9ee571dd/ab158/1.png 480w,https://blog.palabra.io/static/dda0a44008c569addd2daa6c9ee571dd/7d769/1.png 960w,https://blog.palabra.io/static/dda0a44008c569addd2daa6c9ee571dd/b43a1/1.png 1092w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
    </span></p><h3>Step 2: Connect your Webflow site to Palabra</h3><p>After you select the trigger, click on the card and give Palabra access to your Webflow website. Then pick from the list the website where you have the form you want to connect:</p><p><span>
      <span></span>
  <img alt="2.png" title="2.png" src="https://blog.palabra.io/static/be36ec5cf8f8f440f7258b253580a23a/7d769/2.png" srcset="https://blog.palabra.io/static/be36ec5cf8f8f440f7258b253580a23a/5243c/2.png 240w,https://blog.palabra.io/static/be36ec5cf8f8f440f7258b253580a23a/ab158/2.png 480w,https://blog.palabra.io/static/be36ec5cf8f8f440f7258b253580a23a/7d769/2.png 960w,https://blog.palabra.io/static/be36ec5cf8f8f440f7258b253580a23a/2b72d/2.png 980w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
    </span></p><p>You'll need your Webflow form to include an email input to trigger the sequence. If you don't have one, just add it to your Webflow site and then select "Test connection again".</p><h3>Step 3: Select your email sequence</h3><p>In the "Tasks" column, you can add an email from the template list, or add a specific action, like wait some time.</p><p>Here you can select different actions and set up a whole sequence. For this example I created a simple welcoming sequence for a Webflow landing page to a community:</p><p><span>
      <span></span>
  <img alt="3.png" title="3.png" src="https://blog.palabra.io/static/e8060f3f497f85bbddfd273b36bf9952/7d769/3.png" srcset="https://blog.palabra.io/static/e8060f3f497f85bbddfd273b36bf9952/5243c/3.png 240w,https://blog.palabra.io/static/e8060f3f497f85bbddfd273b36bf9952/ab158/3.png 480w,https://blog.palabra.io/static/e8060f3f497f85bbddfd273b36bf9952/7d769/3.png 960w,https://blog.palabra.io/static/e8060f3f497f85bbddfd273b36bf9952/b1884/3.png 994w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
    </span></p><p>In this example I would be welcoming prospects to my community, sending them some resources the next day, and then waiting a few days to ask for feedback.</p><p>You can easily edit any template by clicking on each card. It will save automatically.</p><h3>Step 4: Start sending automated emails</h3><p>This step is really really short. Once you are ready, just click "Start actions" and wait for Palabra to do the work for you.</p><p>And that's it. You already automated a welcoming sequence. Congratulations.</p><h4>Pro tip: Try out different sequences</h4><p>Once you get your sequence going, you will find a third column with your sequence's performance. You'll get a full list of contacts that received each email, and stats to know who opened them and who clicked on your call to action:</p><p><span>
      <span></span>
  <img alt="4.png" title="4.png" src="https://blog.palabra.io/static/72e8c4e1d2051060a2d8206508a066a4/96430/4.png" srcset="https://blog.palabra.io/static/72e8c4e1d2051060a2d8206508a066a4/5243c/4.png 240w,https://blog.palabra.io/static/72e8c4e1d2051060a2d8206508a066a4/ab158/4.png 480w,https://blog.palabra.io/static/72e8c4e1d2051060a2d8206508a066a4/96430/4.png 933w" sizes="(max-width: 933px) 100vw, 933px" loading="lazy">
    </span></p><p>Try out changing your templates or the order in which emails get sent to see if your open ratio improves.</p><p>Hope you enjoyed this tutorial! If you are curious about what else you can do with Palabra or would just like to try it go ahead an&nbsp;<a href="https://www.palabra.io/">create an account here</a>.</p><p>If you have any questions just send us a quick email, we'll be more than happy to hear your thoughts!</p><hr><p>Hope you enjoyed this tutorial! If you are curious about what else you can do with Palabra or would just like to try it go ahead an <a href="https://www.palabra.io/">create an account here</a>.</p></section></div>]]>
            </description>
            <link>https://blog.palabra.io/how-to-send-a-confirmation-email-when-someone-submits-a-webflow-form?ref=hackernews</link>
            <guid isPermaLink="false">hacker-news-small-sites-23906068</guid>
            <pubDate>Tue, 21 Jul 2020 11:39:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fast design will kill your product]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23905989">thread link</a>) | @knowingathing
<br/>
July 21, 2020 | https://philip.design/blog/fast-design-will-kill-your-product/ | <a href="https://web.archive.org/web/*/https://philip.design/blog/fast-design-will-kill-your-product/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <div>
            <br>
            <h2>Fast design will kill your product</h2>
            <p>21 July 2020</p>
            <br>

        </div>

    </div><div>

        <div>
            
            <p><img src="https://philip.design/blog/fast-design-will-kill-your-product/fast-design.jpg">
            </p>
            <figcaption>Sir Jonathan "Gotta go fast" Ive</figcaption>
            <br>

            <ul>
                <li>Anything worth doing, is worth doing well.</li>
                <li><i>Everything</i> that gets added to your product should be considered.</li>
                <li>There is never a time when you should be O.K to just ‚Äúadd a button‚Äù. Someone in the process should have thought deeply about it, or you should have. It‚Äôs the only way to create lasting products.</li>
            </ul>

            <p>If you agree with the above, let‚Äôs continue on this journey. If not <a href="https://twitter.com/philipardeljan">tweet me</a> or comment below :)</p>

            <p>Doing lots of things quickly feels good. It's human nature. Cranking out work gives an outward semblance of progress. In the context of product design however, an expression comes to mind:</p>

            <blockquote><h3>"Quiet, calm deliberation disentangles every knot"</h3></blockquote>
            <blockquote><small>Gilbert and Sullivan</small></blockquote>

            <p>As product designers, we are tasked with solving difficult problems. To solve these problems our initial inclination can be to design a fancy new interface. At times, the result of good design can be making no change at all or even removing something entirely.</p>

            <p>The main challenge with adding things to a product is that after some time, people expect it to always be there. There is so much inertia once something is in place and is being used. You can‚Äôt remove it easily. This is why adding something in the first place is such an important decision. With user interface design, quality is better than quantity. You can only fit so much onto a screen at any given time so difficult decisions need to be made.</p>

            <blockquote><h3>"Just add in this button"</h3></blockquote>
            <blockquote><small>A co-worker, probably</small></blockquote>

            <p>Sometimes I think about a small piece of UI for a long time. And a lot of the time it feels unproductive. It feels so weird to spend half a day thinking deeply about a button. But the presence of <i>one more button</i> within a user interface could make or break it.</p>

            <h3>UI scenario: Add a button to this screen to let users do (x).</h3>
            <ul>
                <li>Does this button need to exist in the UI? (despite being mandated I always consider this first. As an interface designer, you are responsible to ensure the interface works for users first.)</li>
                <li>Do all users need to see it, or just a subset or users?</li>
                <li>Does the button have more or less importance than the elements around it?</li>
                <li>Does adding this button distract too much from the existing functions?</li>
                <li>With all of this in mind, have I struck the right balance?</li>
                <li>How does the information architecture hold up?</li>
                <li>What existing UI patterns do we have for this button (if any)?</li>
                <li>Does this button need to persist after being actioned once/twice/etc?</li>
                <li>Does this button have multiple states? If so, what are they?</li>
                <li>Does it need to be touch friendly and have a big tap target?</li>
                <li>Will this element animate? Where from/to? Why?</li>
                <li>and so on‚Ä¶</li>
            </ul>

            <p>This is a considered approach to UI design. It will ensure that the user always has the best experience when using your product. The compounding effects of strong design decisions quickly stack up. Kind of like compounding interest.</p>

            <h3>UX scenario: The user should be able to do (x).</h3>
            <ul>
                <li>How does the user currently do (x)? </li>
                <li>Is the user having to use a workaround to do (x)?</li>
                <li>By allowing the user to do (x) are we creating future problems?</li>
                <li>Does (x) align with our wider product strategy?</li>
                <li>How should we test our design of (x) with users?</li>
                <li>Do we already have anything in the roadmap that will solve (x)?</li>
                <li>Will we need to re-work our solution to (x) in the short/medium term?</li>
                <li>Do we have competitors that allow users to do (x)? If so, how do they do it?</li>
                <li>and so on‚Ä¶</li>
            </ul>

            <p>These are some of the questions I ask myself when adding elements to an existing interface. When designing an entirely new user interface there are many more considerations I take into account. Maybe for another blog post :)</p>

            <p>So what are the takeaways? If you want to kill your product, make lots of design decisions really quickly. And do that for a sustained period of time.</p>

            <p>If you want a well designed product that is both a joy to use and to work on, go slow to go fast. Good design is like slow cooked food, the process is long but the outcome is always worth it. </p>

            <h4>Leave a comment :)</h4>
            <br>
            
        </div>
    </div></div>]]>
            </description>
            <link>https://philip.design/blog/fast-design-will-kill-your-product/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23905989</guid>
            <pubDate>Tue, 21 Jul 2020 11:23:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Keeping NetBSD up-to-date with pkg_comp 2.0]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23905769">thread link</a>) | @jayp1418
<br/>
July 21, 2020 | https://jmmv.dev/2017/02/pkg_comp-2.0-tutorial-netbsd.html | <a href="https://web.archive.org/web/*/https://jmmv.dev/2017/02/pkg_comp-2.0-tutorial-netbsd.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              
              <article><p>This is a tutorial to guide you through the <a href="https://jmmv.dev/2017/02/introducing-pkg_comp-2.0.html">shiny new pkg_comp 2.0</a> on NetBSD.</p>

<p><strong>Goals:</strong> to use pkg_comp 2.0 to build a binary repository of all the packages you are interested in; to keep the repository fresh on a daily basis; and to use that repository with pkgin to maintain your NetBSD system up-to-date and secure.</p>

<p>This tutorial is specifically targeted at NetBSD but should work on other platforms with some small changes.  Expect, at the very least, a macOS-specific tutorial as soon as I create a pkg_comp standalone installer for that platform.</p>



<p>First install the <code>sysutils/sysbuild-user</code> package and trigger a full build of NetBSD so that you get usable release sets for pkg_comp.  See <code>sysbuild(1)</code> and <code>pkg_info sysbuild-user</code> for details on how to do so.  Alternatively, <a href="https://ftp.netbsd.org/pub/NetBSD/">download release sets from the FTP site</a> and later tell pkg_comp where they are.</p>

<p>Then install the <code>pkgtools/pkg_comp-cron</code> package.  The rest of this tutorial assumes you have done so.</p>



<p>To use pkg_comp for periodic builds, you‚Äôll need to do some minimal edits to the default configuration files.  The files can be found directly under <code>/var/pkg_comp/</code>, which is <code>pkg_comp-cron</code>‚Äôs ‚Äúhome‚Äù:</p>

<ul>
<li><p><code>/var/pkg_comp/pkg_comp.conf</code>: This is pkg_comp‚Äôs own configuration file and the defaults installed by <code>pkg_comp-cron</code> should be good to go.</p>

<p>The contents here are divided in three major sections: declaration on how to download pkgsrc, definition of the file system layout on the host machine, and definition of the file system layout for the built packages.</p>

<p>You may want to customize the target system paths, such as <code>LOCALBASE</code> or <code>SYSCONFDIR</code>, but you should not have to customize the host system paths.</p></li>

<li><p><code>/var/pkg_comp/sandbox.conf</code>: This is the configuration file for sandboxctl.  The default settings installed by <code>pkg_comp-cron</code> <em>should</em> suffice if you used the <code>sysutils/sysbuild-user</code> package as recommended; otherwise tweak the <code>NETBSD_NATIVE_RELEASEDIR</code> and <code>NETBSD_SETS_RELEASEDIR</code> variables to point to where the downloaded release sets are.</p></li>

<li><p><code>/var/pkg_comp/extra.mk.conf</code>: This is pkgsrc‚Äôs own configuration file.  In here, you should configure things like the licenses that are acceptable to you and the package-specific options you‚Äôd like to set.  You should <em>not</em> configure the layout of the installed files (e.g. <code>LOCALBASE</code>) because that‚Äôs handled internally by pkg_comp as specified in <code>pkg_comp.conf</code>.</p></li>

<li><p><code>/var/pkg_comp/list.txt</code>: This determines the set of packages you want to build in your periodic cron job.  The builds will fail unless you list at least one package.</p>

<p>WARNING: Make sure to include <code>pkg_comp-cron</code> and <code>pkgin</code> in this list so that your binary kit includes these essential package management tools.  Otherwise you‚Äôll have to deal with some minor annoyances after rebootstrapping your system.</p></li>
</ul>

<p>Lastly, review root‚Äôs <code>crontab</code> to ensure the job specification for pkg_comp is sane.  On slow machines, or if you are building many packages, you will probably want to decrease the build frequency from <code>@daily</code> to <code>@weekly</code>.</p>



<p>Here is what the configuration looks like on my NetBSD development machine as dumped by the <code>config</code> subcommand.  Use this output to get an idea of what to expect.  I‚Äôll be using the values shown here in the rest of the tutorial:</p>

<pre><code># pkg_comp -c /var/pkg_comp/pkg_comp.conf config
AUTO_PACKAGES = autoconf automake bash colordiff dash emacs-nox11 git-base git-docs gmake gnuls lua52 mozilla-rootcerts pdksh pkg_comp-cron pkg_developer pkgin sqlite3 sudo sysbuild sysbuild-user sysupgrade tmux vim zsh
CVS_ROOT = :ext:anoncvs@anoncvs.NetBSD.org:/cvsroot
CVS_TAG is undefined
DISTDIR = /var/pkg_comp/distfiles
EXTRA_MKCONF = /var/pkg_comp/extra.mk.conf
FETCH_VCS = cvs
GIT_BRANCH = trunk
GIT_URL = https://github.com/jsonn/pkgsrc.git
LOCALBASE = /usr/pkg
NJOBS = 2
PACKAGES = /var/pkg_comp/packages
PBULK_PACKAGES = /var/pkg_comp/pbulk-packages
PKG_DBDIR = /usr/pkg/libdata/pkgdb
PKGSRCDIR = /var/pkg_comp/pkgsrc
SANDBOX_CONFFILE = /var/pkg_comp/sandbox.conf
SYSCONFDIR = /etc
UPDATE_SOURCES = true
VARBASE = /var

NETBSD_NATIVE_RELEASEDIR = /home/sysbuild/release/amd64
NETBSD_RELEASE_RELEASEDIR = /home/sysbuild/release/amd64
NETBSD_RELEASE_SETS is undefined
SANDBOX_ROOT = /var/pkg_comp/sandbox
SANDBOX_TYPE = netbsd-release
</code></pre>



<p>Now that you are fully installed and configured, you‚Äôll build some stuff by hand to ensure the setup works before the cron job comes in.</p>

<p>The simplest usage form, which involves full automation, is something like this:</p>

<pre><code># pkg_comp -c /var/pkg_comp/pkg_comp.conf auto
</code></pre>

<p>This trivially-looking command will:</p>

<ol>
<li>checkout or update your copy of pkgsrc;</li>
<li>create the sandbox;</li>
<li>bootstrap pkgsrc and pbulk;</li>
<li>use pbulk to build the given packages; and</li>
<li>destroy the sandbox.</li>
</ol>

<p>After a successful invocation, you‚Äôll be left with a collection of packages in the directory you set in <code>PACKAGES</code>, which in the default <code>pkg_comp-cron</code> installation is <code>/var/pkg_comp/packages/</code>.</p>

<p>If you‚Äôd like to restrict the set of packages to build during a manually-triggered build, provide those as arguments to <code>auto</code>.  This will override the contents of <code>AUTO_PACKAGES</code> (which was derived from your <code>list.txt</code> file).</p>

<p>But what if you wanted to invoke all stages separately, bypassing <code>auto</code>?  The command above would be equivalent to:</p>

<pre><code># pkg_comp -c /var/pkg_comp/pkg_comp.conf fetch
# pkg_comp -c /var/pkg_comp/pkg_comp.conf sandbox-create
# pkg_comp -c /var/pkg_comp/pkg_comp.conf bootstrap
# pkg_comp -c /var/pkg_comp/pkg_comp.conf build &lt;package names here&gt;
# pkg_comp -c /var/pkg_comp/pkg_comp.conf sandbox-destroy
</code></pre>

<p>Go ahead and play with these.  You can also use the <code>sandbox-shell</code> command to interactively enter the sandbox.  See <code>pkg_comp(8)</code> for more details.</p>

<p>Lastly note that the root user will receive email messages if the periodic pkg_comp cron job fails, but only if it fails.  That said, you can find the full logs for all builds, successful or not, under <code>/var/pkg_comp/log/</code>.</p>



<p>Now that you have built your first set of packages, you will want to install them.  On NetBSD, the default <code>pkg_comp-cron</code> configuration produces a set of packages for <code>/usr/pkg</code> so you have to wipe your existing packages first to avoid build mismatches.</p>

<p>WARNING: Yes, you really have to wipe your packages.  pkg_comp currently does not recognize the package tools that ship with the NetBSD base system (i.e. it bootstraps pkgsrc unconditionally, including <code>bmake</code>), which means that the newly-built packages won‚Äôt be compatible with the ones you already have.  Avoid any trouble by starting afresh.</p>

<p>To clean your system, do something like this:</p>

<pre><code># ... ensure your login shell lives in /bin! ...
# pkg_delete -r -R "*"
# mv /usr/pkg/etc /root/etc.old  # Backup any modified files.
# rm -rf /usr/pkg /var/db/pkg*
</code></pre>

<p>Now, rebootstrap pkgsrc and reinstall any packages you previously had:</p>

<pre><code># cd /
# tar xzvpf /var/pkg_comp/packages/bootstrap.tgz
# echo "pkg_admin=/usr/pkg/sbin/pkg_admin" &gt;&gt;/etc/pkgpath.conf
# echo "pkg_info=/usr/pkg/sbin/pkg_info" &gt;&gt;/etc/pkgpath.conf
# export PATH=/usr/pkg/bin:/usr/pkg/sbin:${PATH}
# export PKG_PATH=file:///var/pkg_comp/packages/All
# pkg_add pkgin pkg_comp-cron &lt;other package names&gt;
</code></pre>

<p>Finally, reconfigure any packages where you had have previously made custom edits.  Use the backup in <code>/root/etc.old</code> to properly update the corresponding files in <code>/etc</code>.  I doubt you made a ton of edits so this should be easy.</p>

<p>IMPORTANT: Note that the last command in this example includes <code>pkgin</code> and <code>pkg_comp-cron</code>.  You should install these first to ensure you can continue with the next steps in this tutorial.</p>



<p>If you paid attention when you installed the <code>pkg_comp-cron</code> package, you should have noticed that this configured a cron job to run pkg_comp daily.  This means that your packages repository under <code>/var/pkg_comp/packages/</code> will always be up-to-date so you can use that to quickly upgrade your system with minimal downtime.</p>

<p>Assuming you are going to use <code>pkgtools/pkgin</code> (and why not?), configure your local repository:</p>

<pre><code># echo 'file:///var/pkg_comp/packages/All' &gt;&gt;/etc/pkgin/repositories.conf
</code></pre>

<p>And, from now on, all it takes to upgrade your system is:</p>

<pre><code># pkgin update
# pkgin upgrade
</code></pre>

<p>Enjoy!</p></article>
            </div>
          </div></div>]]>
            </description>
            <link>https://jmmv.dev/2017/02/pkg_comp-2.0-tutorial-netbsd.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23905769</guid>
            <pubDate>Tue, 21 Jul 2020 10:34:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is Nintendo Playing At?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23905764">thread link</a>) | @handlingelect
<br/>
July 21, 2020 | https://www.staticcatgames.com/2020/07/what-is-nintendo-playing-at.html | <a href="https://web.archive.org/web/*/https://www.staticcatgames.com/2020/07/what-is-nintendo-playing-at.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<h3>
What is Nintendo playing at?
</h3>
</div><div>
<div id="post-body-8506159587861018996">
<p><iframe allowfullscreen="" height="266" src="https://www.youtube.com/embed/kNtacp8-GoI" width="320" youtube-src-id="kNtacp8-GoI"></iframe></p><p>Nintendo's latest Direct hit yesterday to mixed reactions. The <a href="https://www.youtube.com/watch?v=kNtacp8-GoI" target="_blank">video</a>, at the time of writing, has 68,000 dislikes and 87,000 likes. Fans were disappointed at the lack of any major announcements given the drought in Nintendo Directs in recent months. The showcase highlighted <i>Shin Megamei Tensei 5</i>, <i>Shin Megami Tensei III: Nocturne HD Remaster</i>, some DLC for <i>Cadence of Hyrule</i>, <i>Rogue Company</i> and&nbsp;<i>WWE2K Battlegrounds</i>. That was it. No <i>Doom Eternal</i>, no <i>Bravely Default II</i>.&nbsp;</p><p>While I expect Nintendo will undoubtedly release more smaller Nintendo Directs in due course, there is a much greater issue here.&nbsp;</p><h3>Everyone is talking about the PlayStation 5 and Xbox Series X</h3><p>Nintendo needs to step up to get gamers talking about the Switch again. Right now, the hot topics are the next generation of consoles coming later this year. <a href="https://www.staticcatgames.com/2020/07/will-july-23rd-mark-success-or-failure.html" target="_blank">Microsoft's event on the 23rd</a> is on everyone's lips, for example. If Phil Spencer and co show off a lot of gameplay for <i>Halo: Infinite</i> and other first party games, this could turn out to be an incredible event.&nbsp; Microsoft's Xbox Series S/Project Lockhart is supposedly going to be unveiled in August, adding even more impetus.&nbsp;</p><p>I wouldn't be surprised if Sony released more information to combat the impact of Microsoft's event, perhaps even the price and launch date.&nbsp;</p><h3>What can Nintendo do to get the buzz going again?</h3><div><ul><li>Mario games in celebration of the 35th anniversary.</li><li>Announce <i>Breath of the Wild 2</i>.</li><li>Nintendo 64 games coming to the Switch.</li><li>New [insert old IP] here - imagine the reaction if a new <i>Wave Race</i> or <i>F-Zero </i>was announced?</li><li>Announce a Game Boy Classic.</li><li>Announce<i> GoldenEye 007</i> coming to the Switch.</li><li>Say "<a href="https://www.staticcatgames.com/2020/07/what-next-for-nintendo.html" target="_blank">Switch Pro</a> - coming 2021"</li></ul><p>What about Todd Howard showing a video of him playing <i>Fallout 3</i> (or 4) on the Switch? That would be incredible.&nbsp;</p><p>If Nintendo really wanted to do something EPIC, all it has to do is release a video of Phil Spencer playing <i>Halo: Infinite</i>...on a Switch running xCloud.&nbsp;</p></div><p><b>BOOM!&nbsp;</b></p><p>And the crowd goes wild.</p><h3>Closing thoughts</h3><p>There is always the risk of complacency. Nintendo could decide not to do anything until September, which might be damaging. I expect Sony will release more info about the PlayStation 5 at some point, especially since we don't know the price or launch date. There might be more gameplay footage to come. Microsoft might have a busy August if they announce the Xbox Series S/Project Lockhart then. Nintendo could make a splash by announcing <i>Super Mario Galaxy 1 &amp; 2 </i>on the Switch or S<i>uper Mario Sunshine Remastered. </i>That would guarantee a lot of interest and pre-orders.&nbsp;</p><p>What do you think? Is Nintendo on the right track or should it do more to get everyone talking about the Switch and their games?</p><h2>If you liked reading this post, please check out some of my others</h2>
</div>

</div></div>]]>
            </description>
            <link>https://www.staticcatgames.com/2020/07/what-is-nintendo-playing-at.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23905764</guid>
            <pubDate>Tue, 21 Jul 2020 10:32:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things I wish I had known when I started programming, Part 6 (2019)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23905745">thread link</a>) | @juanorozcov
<br/>
July 21, 2020 | https://www.brainstobytes.com/advice-for-new-developers-or-things-i-wish-i-had-known-when-i-started-programming-part-6/ | <a href="https://web.archive.org/web/*/https://www.brainstobytes.com/advice-for-new-developers-or-things-i-wish-i-had-known-when-i-started-programming-part-6/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<!--kg-card-begin: markdown--><p>Yepp, more things I wish I'd known when I started, 6th edition.</p>
<p><em>You can find the first article in the series <a href="https://www.brainstobytes.com/advice-for-new-developers-or-things-i-wish-i-had-known-when-i-started-to-program/">here</a>.</em></p>
<p><em>And the previous article <a href="https://www.brainstobytes.com/advice-for-new-developers-or-things-i-wish-i-had-known-when-i-started-programming-part-5">here</a></em></p>
<h2 id="donttrytopredictthefuture">Don't try to predict the future</h2>
<p>We suck at predicting the future.</p>
<p>Every time you make an architectural/design decision, you close options in your design and constrain your program‚Äôs options for change. Designing is balancing the current needs (requirements) with possible future change requests.</p>
<p>Your main goal is to satisfy the current requirements and leaving as many open options as possible to accommodate future changes. If you get a hunch that in the future you will get a request for X feature and design to accommodate that, two things can happen:</p>
<p>1- The request comes, and hurray! you can easily sneak it in.</p>
<p>2- The request never came, and you end up with a subpar design that doesn‚Äôt relate to your current requirements, shame on you.</p>
<p>Because the second thing is more likely to happen, you avoid making the rookie mistake of designing for things you are not sure will come later.</p>
<p>Design is about balancing two things: satisfying current requirements and leaving open as many options as possible. You want to keep flexibility, and designing for hunches poses unnecessary constraints in your program.</p>
<p>So go for designs that are easy to extend and don't build towards a feature that might never come.</p>
<h2 id="communicatewiththeusersofyoursoftware">Communicate with the users of your software</h2>
<p>In a previous article in this series, we talked about our role as software developers. Our job, above writing code, is to provide value.</p>
<p>The most important prerequisites for being able to provide value is to know what our users need. Communication with end-users is important because as the creators of the software, we tend to have skewed ideas about the products we make.</p>
<p>There are many features and usability aspects that are obvious for us, but not for the users. Things that for us seem clear and intuitive can be difficult for people who... well, who didn't create the product. Communicating with users and understanding what they love and what they hate about our products is an important part of crafting the right solution.</p>
<p>It's true that we don't have those many chances to do this, but if there is a situation where you can talk to a user go for it. If it's not possible at all, become best buddies with your product owner and get regular feedback.</p>
<p>Remember that there are few things as sad as building a great product that solves the wrong problem.</p>
<h2 id="dontbeatechnomartyr">Don't be a technomartyr</h2>
<p>Career is important, but so is your private life.</p>
<p>I know this might not apply to you, but our profession is full of people who work a ton of extra hours. Neglecting family, friends and personal life in order to ship that extra feature is quite common among software developers.</p>
<p>I know you might need to stay in the office for a couple of extra hours on special occasions, it happens to everyone. But continuous neglect of other aspects of your life is impossible to sustain in the long term.</p>
<p>We are human beings, and the need to cultivate relationships and hobbies is an integral part of who we are. Having a network of healthy relationships around us not only makes us happier, but it also helps us produce better quality work. A happy and well-rested person with other interests tends to fare better in the long run.</p>
<p>It's not that extreme sacrifices will make you a star employee forever. Sooner or later you will burn out and your relationships will deteriorate, something that will ultimately impact your productivity if that's the only thing that matters.</p>
<p>So, spend time nourishing what matters. Your job will still be there later, and you will probably switch jobs several times in the following decades. Bet for sustainable growth and nourish all the aspects of your life.</p>
<h2 id="ohbutialsoknewallthesethings">Oh but I also knew all these things.</h2>
<p>It's ok, maybe in the next article, you'll find something you didn't know yet.</p>
<p>Thank you for reading, I hope you learned one or two new things or at least got something new to think about.</p>
<h2 id="whattodonext">What to do next:</h2>
<ul>
<li>Share this article with friends and colleagues. Thank you for helping me reach people who might find this information useful.</li>
<li>Read the <a href="https://www.brainstobytes.com/advice-for-new-developers-or-things-i-wish-i-had-known-when-i-started-programming-part-7/">next article in the series</a>.</li>
<li>You can find helpful books to continue investing in your carrer in the <a href="https://www.brainstobytes.com/recommended-books/">recommended reading list</a>.</li>
<li>Send me an email with questions, comments or suggestions (it's in the <a href="https://www.brainstobytes.com/about">About Me page</a>). Come on, don't be shy!</li>
</ul>
<!--kg-card-end: markdown-->
					</div></div>]]>
            </description>
            <link>https://www.brainstobytes.com/advice-for-new-developers-or-things-i-wish-i-had-known-when-i-started-programming-part-6/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23905745</guid>
            <pubDate>Tue, 21 Jul 2020 10:26:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is a Subscription Product?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23905689">thread link</a>) | @cquijano
<br/>
July 21, 2020 | https://www.firmhouse.com/blog/what-is-a-subscription-product | <a href="https://web.archive.org/web/*/https://www.firmhouse.com/blog/what-is-a-subscription-product">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Reading time: 4-6 minutes</p><p>Lately, I've seen a trend of products being offered as a subscription. I receive every month a set of products that I regularly consume, which I prefer to receive on the commodity of my house rather than buy it from the store.&nbsp; Companies are looking to take advantage of the <a href="https://www.firmhouse.com/blog/embracing-digital-transformation-with-as-a-service">digital transformation</a> that makes people buy more online and get their favorite products conveniently.&nbsp;<br></p><p>In this article, we explain what is really a <a href="https://www.firmhouse.com/blog/subscription-services-are-here-to-stay">subscription</a> product, what benefits it has for companies, and how you can start and manage your subscription product.&nbsp;<br></p><h3><strong>Let‚Äôs start by defining what is a subscription product?</strong></h3><p>A subscription product is when a customer pays to have access to a product as a subscription and get billed on a recurring schedule.<br></p><p>Subscription products are on the rise, and they will gain more popularity over time as more customers adopt this model.&nbsp;</p><p>‚Äç<br></p><h4><strong>Subscription products have three powerful benefits for your company:</strong></h4><ul role="list"><li>Enhances customer loyalty: increasing the number of successful interactions that your customers have with your business.<br></li></ul><ul role="list"><li>Improve cash flow: with subscription products, your customer doesn't have to pay upfront, but they will have to pay for a period of time, which helps you to receive recurring revenue.&nbsp;<br></li></ul><ul role="list"><li>As a revenue stream: Allowing new customers to access your product as a subscription is a great way to receive additional revenue streams from different customer segments.&nbsp;<br></li></ul><p>There are different types of subscription products, so <strong>which kind of products are best for subscriptions?</strong> Of course, this depends on the industry, but in short, it has to be a product that your customer consumes regularly or a product that is expensive to buy upfront.</p><p>‚Äç<br></p><h4><strong>Type of products that can easily be offered as a subscription:</strong></h4><ul role="list"><li>Consumable or disposable products are a great choice for e-commerce subscriptions.&nbsp;</li><li>Expensive products, such as electronics or furniture.</li><li>Products that people use regularly and need to be replaced.</li><li>Products that your customer consumes, wear or recycle after its use.</li></ul><p>‚Äç</p><figure><p><img src="https://assets-global.website-files.com/5e4302c3ff8f98b64643b252/5f16b998a23f5233cb557b1d_Subcription%20products.png" alt=""></p><figcaption>6 Industries Offering Subscription Products</figcaption></figure><p>‚Äç</p><h3><strong>6 industries that are offering subscription products:</strong></h3><ol role="list"><li><a href="https://www.firmhouse.com/as-a-service-index-industries/home-furniture">Furniture</a></li><li><a href="https://www.firmhouse.com/as-a-service-index-industries/consumer-electronics">Electronics</a></li><li>Vitamins</li><li>Food</li><li>Fashion</li><li>Children's toys and clothing</li></ol><p>‚Äç<br></p><h3><strong>3 Examples of product subscriptions:</strong></h3><ol role="list"><li>Food</li></ol><ul role="list"><li><a href="https://www.blueapron.com/">Blue apron</a> - $8.74/serving</li><li><a href="https://www.graze.com/uk/">Graze</a> - $11.99/week</li><li><a href="https://naturebox.com/">Nature box</a> - $25/month</li><li><a href="https://farmtopeople.com/">Farm to people</a> - $24.99/month<br></li></ul><ol start="2" role="list"><li>Kids</li></ol><ul role="list"><li><a href="https://www.kiwico.com/">Kiwi crate</a> - $19.95/month</li><li><a href="https://www.honest.com/">Honest company</a> - $39.95/month</li><li><a href="https://www.greenkidcrafts.com/">Green kid crafts</a> - $19.95/month</li><li><a href="https://www.wecraftbox.com/">We craft box </a>- $24.99/month<br></li></ul><ol start="3" role="list"><li>Grooming and fashion-men</li></ol><ul role="list"><li><a href="https://www.birchbox.com/">Birchbox</a> - $20/month</li><li><a href="https://www.bespokepost.com/">Bespoke</a> - $45/month</li><li><a href="https://www.dollarshaveclub.com/">Dollar shave club</a> - $1/month<br></li></ul><p>‚Äç</p><h3><strong>7 Steps that can help you when starting your product subscription:</strong><br></h3><ol role="list"><li>Make sure to offer something customers want: First, start by deciding which product(s) you'll offer as a subscription. Stick to one or two product offerings at the beginning to test what works and the reception from the people.&nbsp;Keep in mind that this doesn't mean you can't have all your products as a subscription, if you are a company that sells more than 1 product or that plans to expand). Start with the one that will be the most suitable for the audience you try to convince. This could be your most popular product or a new product that you are trying to test in the market.&nbsp;<br></li></ol><ol start="2" role="list"><li>Once you pick a product to sell as a subscription, you'll need a tool to manage your sales and operations since doing the process manually can get messy when you have a handful of customers. As you scale, you need to manage your subscribers; otherwise, it can become unmanageable.&nbsp;<br></li></ol><ol start="3" role="list"><li>Billing is one of the most complex aspects, especially if you offer different product variations such as <a href="https://fabfitfun.com/get-the-box/?step=getbox&amp;#plan=fffvip">Fat Fit Fun</a>, with the ability to choose what goes on the box or specific customer needs.&nbsp;<br></li></ol><ol start="4" role="list"><li>Give customers a try-before you buy option. Aren't your customers ready to subscribe? Ask them to buy for one month so they can try it and see if they like it.&nbsp;<br></li></ol><ol start="5" role="list"><li>Ensure customers have an option to suggest your product to friends. From the very beginning of your subscription business think of a strategy so customers can refer you to other people.&nbsp;<br></li></ol><ol start="6" role="list"><li>Another option is to send a special discount with the product if they refer more people or suggest your product to their friends. This is valuable if you are trying to scale fast. It would give you a network effect that can help you promote your product and ultimately grow.&nbsp;<br></li></ol><ol start="7" role="list"><li>Make sure all product items are clear. If you deliver on the 11th of every month, can a subscriber get your product if they sign up on the 9th? If a customer travels, can they change their address or pause their subscription? Take this into consideration and communicate it with customers so they can better understand how your subscription works.&nbsp;</li></ol><p>‚Äç<br></p><h3><strong>What is a subscription management software, and what has to do with subscription products?&nbsp;</strong><br></h3><p>If you are thinking of offering a product as a subscription, you should make sure some aspects are covered before starting.&nbsp;<br></p><p>Some of the aspects to consider when starting your product as a subscription are; your <a href="https://www.firmhouse.com/blog/the-product-as-a-service-business-case-calculator">customer lifecycles</a>, trials, credit checks, operations, refunds, logistics, and subscription changes.&nbsp;<br></p><p>A subscription management software oversees the interaction between your business and the customers, which is more complete and different from just recurring billing.&nbsp;<br></p><p>Subscription management software helps you update your customers' information, upgrade/downgrade subscriptions, perform customer-oriented tasks, customer communications, and dunning management.&nbsp;<br></p><p>Meanwhile, recurring billing helps you only generate an invoice (including location-based taxes), tracking payments, and safely storing payment information.</p><p>‚Äç<br></p><h3><strong>8 ways in which a subscription management tool or software can help you with your subscription product:&nbsp;</strong><br></h3><ol role="list"><li>Easily track changes from the customer, such as; <a href="https://www.firmhouse.com/blog/how-to-reduce-subscriber-churn-5-helpful-tips-to-try">credit card expiration</a>, contact information updates, and the possibility of upgrading or downgrading their subscription.&nbsp;<br></li></ol><ol start="2" role="list"><li>Instantly access the historical data from your customer: view invoices, cancelations, deliveries, and much more.&nbsp;<br></li></ol><ol start="3" role="list"><li>Have a self-service portal where customers can find all the necessary information for their product subscription.&nbsp;<br></li></ol><ol start="4" role="list"><li>Communication with subscribers is key: Subscription management improves your overall customer's experience by enhancing communication with your subscribers.<br></li></ol><ol start="5" role="list"><li>Dunning management helps you set pre-determined communications to reach out to customers throughout their lifecycle.<br></li></ol><ol start="6" role="list"><li>Ensure revenue recovery and communicate when a payment or a transaction fails. A subscription management software also helps you contact subscribers to let them know their credit card is about to expire.&nbsp;</li></ol><ol start="7" role="list"><li>A subscription management software stores your: subscribers data, any add-ons, product catalog and prices, history of transactions, and billing cycles.&nbsp;<br></li></ol><ol start="8" role="list"><li>Subscription management works on top of a payment processor to support billing. It allows teams to take actions that need to be automated, such as customer signs up or special discounts or trial periods.&nbsp;<br></li></ol><p>Having your product as a subscription enhances customer loyalty, it is a great revenue stream and improves your business cash flow.&nbsp;<br></p><p>Some of the best products to have as a subscription are; products that are used more frequently with the possibility to be recycled after or products that are expensive to pay upfront. Industries such as; furniture, electronics, vitamins, and children's toys are well suited to start offering product subscriptions.&nbsp;<br></p><p>A subscription management software helps you oversee your customer interactions and make sure you run operations smoothly.&nbsp;<br></p><p>Are you looking to start offering your products as a subscription? <a href="https://www.firmhouse.com/contact">Request a demo</a> for free today and start using our subscription platform today.&nbsp;<br></p></div></div></div>]]>
            </description>
            <link>https://www.firmhouse.com/blog/what-is-a-subscription-product</link>
            <guid isPermaLink="false">hacker-news-small-sites-23905689</guid>
            <pubDate>Tue, 21 Jul 2020 10:13:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scaling Relational SQL Databases]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23905554">thread link</a>) | @petr25102018
<br/>
July 21, 2020 | https://stribny.name/blog/2020/07/scaling-relational-sql-databases | <a href="https://web.archive.org/web/*/https://stribny.name/blog/2020/07/scaling-relational-sql-databases">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="mainContentOfPage">
		
<p>Many applications today still rely on traditional SQL databases like MySQL, MariaDb or PostgreSQL for data storage and data processing. With the growing amount of data and new workloads that are made with this database systems, we often find ourselves in situations where we need to think about scaling such systems.</p>



<p>When it comes to scaling, we might need to think about:</p>



<ul><li>data storage, if we store more and more data and it becomes expensive or slow working with them</li><li>fast INSERTs and UPDATES for write-heavy workloads</li><li>making SELECT queries faster because of their complexity or because they need to query huge amounts of data</li><li>concurrency if we have many clients interacting with the database</li></ul>



<p>In this article, I will present some basic ideas and starting points on scaling traditional SQL databases.</p>



<h3>Update the database</h3>



<p>Newer versions of MySQL, PostgreSQL and other traditional SQL databases typically come with performance improvements. Even if the newer database system is not faster as a direct replacement, there might be new features available that we can take advantage of. Keeping our database system up to date expands our options on what we can do with our data and gives us the best out of the box performance. It is a basic enabler for scaling.</p>



<h3>Scale vertically</h3>



<p>The most intuitive idea of scaling is to use better hardware to scale vertically (on one database server). When it comes to hardware we typically look at CPUs, disk and RAM:</p>



<ul><li>The number of CPUs affects how many queries the database can run and therefore how many clients can be served</li><li>The size of RAM gives us space for indexes, temporary tables and caches the database can store in a fast memory which makes our system faster due to minimizing IO access to disk</li><li>Disk IO speed highly affects the query times, especially for full scan reads (when indexes cannot be used) or for write-heavy systems</li><li>Disk size allows us to store more data</li></ul>



<h3>Leverage application cache</h3>



<p>If the application‚Äôs code is in our control we can cache data in a memory store like <a href="https://redis.io/">Redis</a> or <a href="https://memcached.org/">Memcached</a> to avoid querying the database. We don‚Äôt have to just cache database reads, but we can also use such systems as buffers for writes, e.g. when we are collecting analytical data and a possible delay is not a problem.</p>



<h3>Use efficient data types</h3>



<p>When it comes to data, it all starts with data types, in other words how individual pieces of information are physically stored in memory. Choosing appropriate data types is always a balance between efficiency and functionality, affecting the required memory, query performance and number of operations we can do with the specific data type.</p>



<p>There are two basic ways to think about optimal data types:</p>



<ul><li>logical: how to store general information like a telephone number or an IP address; for instance we can store color as a string, enum or as a collection of RGB integers and we can store IP address as a string or as bytes</li><li>physical: what specific data types we choose for strings, integers or time since we typically have multiple options; e.g. date and time can be typically stored as a timestamp (faster but with limited date range and functionality) or as a more complex datetime which is more developer friendly and flexible, allowing to store timezone etc.</li></ul>



<p>Using an appropriate type for a database column is especially important when we want to index the column, use it in the WHERE clause, use it for joins or when we have a lot of data.</p>



<h3>Data normalization and denormalization</h3>



<p>We are often trained to normalize data for relational databases in order to reduce data redundancy and improve data integrity. While this is generally useful, we might want to reconsider it for some of our data when it comes to scaling.</p>



<p>Generally speaking the simpler we make our data to be retrieved or saved, the more of it we can have.</p>



<h3>Precompute data</h3>



<p>A lot of SELECT queries can be optimized by having the data already in the requested form. This can be handy for analyzing large amounts of data. For instance, instead of aggregating data every time, we can aggregate them beforehand. Of course this isn‚Äôt always possible, e.g. we cannot aggregate other average aggregates because we would lose precision.</p>



<h3>Leverage materialized views</h3>



<p>Materialized views are continuously updated data that are updated on write operations or on scheduled time and can be seen as an extension of the previous point. Unlike classic views, materialized views are physically stored and don‚Äôt need to be computed when needed. This is useful for situations where a SELECT query would take a long time to produce the result.</p>



<p>As an example, look at <a href="https://www.pipelinedb.com/">PipelineDB</a> extension for PostgreSQL that produces aggregates on real-time data, allowing us to keep aggregated statistics on a write-heavy systems.</p>



<h3>Use proper indexes</h3>



<p>Using the right indexes on tables can be a huge performance changer. Typically, we should index the columns by which we want to query the data or which we want to use to perform joins. However, adding indexes can also reduce performance for write-heavy workloads, since indexes have to be updated on every INSERT and UPDATE. Also it doesn‚Äôt make sense to use indexes on some data types. So it is all about finding the right balance.</p>



<h3>Leverage the execution plan for query optimization</h3>



<p>For optimizing reads we need to know how the database query planner will execute our queries. We can use EXPLAIN statement to obtain the execution plan that the SQL server will use for our query.</p>



<p>Here we should look if the database plans to use any of the existing indexes on the tables or plans to make a full table scan. It can give us hints whether we should change the structure of our data, add indexes or rewrite the query in a different way. Please note however that full table scan can be also faster or necessary for some queries so it is not a black and white situation.</p>



<h3>Choose correct transaction isolation level</h3>



<p>The most common relational databases use multi-version concurrency control and make locking very granular (instead of locking the whole table, like MyISAM storage engine does). However, we still need to tell the database how exactly should the concurrency control behave and we can do so by setting appropriate transaction isolation level. There are 4 basic isolation levels in SQL:1992 standard and they will greatly affect how our database system behaves.</p>



<h3>Bulk INSERTs and UPDATEs</h3>



<p>Writing or updating individual rows in a table is not efficient, but databases like MySQL or PostgreSQL have ways to insert or modify data in bulk. We should leverage this every time we can.</p>



<h3>Compress data for storage</h3>



<p>Many times we don‚Äôt need to query the data by all the columns in a table. If this is the case, we can further optimize the storage size by storing some of the columns in a compressed form. This is especially useful for strings or some types of binary data.</p>



<p>Some databases or their extensions might be already compressing data under the hood so it always makes sense to look first how the data are stored and whether adding compression on the application layer would bring the desired benefit.</p>



<h3>Make ALTER TABLEs work</h3>



<p>When the amount of data or the workload grows we will experience slower and slower ALTER TABLEs to the point where some of them might not finish in a reasonable time. The first important thing to know is that there are typically two ways of changing the structure of the database tables. One is INPLACE, modifying the original table and the other one is COPY, creating a new table and moving the data afterwards. Databases typically try to modify tables INPLACE if possible, but it might make sense sometimes to explicitly ask for the COPY operation.</p>



<p>When adding a new column, it is better to add it at the end of the table, since inserting a column at a specific place is slow.</p>



<p>When changing existing column it might be a good idea to create a new column first, copy the data and remove the column afterwards.</p>



<p>If the write operations on the table make it difficult to perform ALTER TABLE, it makes sense to stop clients from writing into the table first. This is not always possible, but e.g. collection of analytical data can be postponed using an ingestion buffer in front of the database or we can temporarily pause our ETL jobs working with the table.</p>



<p>The last resort is to simply not do any ALTER TABLEs on large and write-heavy tables, opting for creating a new table to store the new data instead.</p>



<h3>Manage concurrent connections</h3>



<p>Every database server comes with some basic configuration on the maximum number of concurrent connections. When we need more, we typically need to reconfigure this value. Just increasing the value is not enough though ‚Äì we need to make sure that our system can actually run well with our desired number of connections.</p>



<h3>Add read replicas</h3>



<p>Traditional SQL databases can‚Äôt typically scale horizontally for write operations by adding more servers, but we can still add other machines in the form of read-only replicas. The way this works is that all write operations are done on the main server and propagated to other machines using Write Ahead Log. All the replicas will therefore apply the same operations in the same order to the underlying storage as the main server. This ensures that the data will be in sync.</p>



<p>Replicas can be then used for scaling the number of read queries and number of connected clients if they only need read operations.</p>



<h3>Disk partitioning</h3>



<p>Partitioning allows us to distribute one single table across the filesystem and store individual partitions based on some specific rules. When such rules are chosen well, SQL queries don‚Äôt have to query all partitions but can limit their search only to a subset of them. This will cut the time the query will run since not the whole database table needs to be looked into.</p>



<h3>Use specialized extensions</h3>



<p>When we need to store and work with geospatial, time series and other ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stribny.name/blog/2020/07/scaling-relational-sql-databases">https://stribny.name/blog/2020/07/scaling-relational-sql-databases</a></em></p>]]>
            </description>
            <link>https://stribny.name/blog/2020/07/scaling-relational-sql-databases</link>
            <guid isPermaLink="false">hacker-news-small-sites-23905554</guid>
            <pubDate>Tue, 21 Jul 2020 09:39:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Beautiful Chord Visualisations for Python, Rust, & JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23905514">thread link</a>) | @shahinrostami
<br/>
July 21, 2020 | https://m8.fyi/chord | <a href="https://web.archive.org/web/*/https://m8.fyi/chord">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="tab-description" role="tabpanel" aria-labelledby="tab-title-description">
				
	<h2>Description</h2>

<p>Chord PRO is the full-featured chord visualization API, producing beautiful interactive visualizations, e.g. those <strong>featured on the front page of Reddit</strong>.</p>
<ul>
<li>Produce <strong>beautiful</strong> interactive Chord diagrams.</li>
<li><strong>Customize</strong> colours and font-sizes.</li>
<li>Access <strong>Divided</strong> mode, enabling two sides to your diagram.</li>
<li><strong>Symmetric </strong>and <strong>Asymmetric </strong>modes,</li>
<li>Add <strong>images and text</strong> on hover,</li>
<li>Access finer-customisations including <strong>HTML injection</strong>.</li>
<li><strong>Allows commercial use</strong> without open source requirement.</li>
<li>Currently supports <strong>Python</strong>,&nbsp;<strong>JavaScript</strong>, and <strong>Rust,</strong> with many more to come (accepting requests).</li>
</ul>
<p>Get it now to enhance your work in Data Science, Data Analysis, and Machine Learning, and Data Visualization.</p>
			</div></div>]]>
            </description>
            <link>https://m8.fyi/chord</link>
            <guid isPermaLink="false">hacker-news-small-sites-23905514</guid>
            <pubDate>Tue, 21 Jul 2020 09:30:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pine64‚Äôs $199.99 14 inch Pine Pro laptop now available for pre-order]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23905298">thread link</a>) | @darshansavla
<br/>
July 21, 2020 | https://androidrookies.com/pine64s-199-99-14-inch-pine-pro-laptop-with-arm-chip-and-manjaro-linux-distro-now-available-for-pre-order/ | <a href="https://web.archive.org/web/*/https://androidrookies.com/pine64s-199-99-14-inch-pine-pro-laptop-with-arm-chip-and-manjaro-linux-distro-now-available-for-pre-order/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-9147"><div><div><div><h2>Pine64‚Äôs $199.99 14 inch Pine Pro Linux laptop with 64-bit ARM chip and Manjaro Linux distro now available for pre-order</h2><p>If you are a Linux fanboi, you shouldn‚Äôt miss this one. <a href="https://androidrookies.com/pine64-launches-the-cheapest-linux-tablet-ever-priced-at-just-99-99/">Pine64</a>, the makers of Linux based laptops have reopened their pre-order window for the 14.1 inch ARM-based Linux laptop Pinebook Pro. Pine64 had last opened the pre-order window in March 2020 and If you missed placing an order last time, you now have another chance to grab $199.99 Pinebook Pro.</p><p>PINE64 has <a href="https://www.pine64.org/2020/07/20/pinebook-pro-pre-orders-open-with-shipping-in-august-2020/" target="_blank" rel="noreferrer noopener nofollow" aria-label="undefined (opens in a new tab)">started</a> to take the next batch of pre-orders for Pinebook Pro. The pre-order has both the ISO and ANSI keyboard versions of Pinebook Pro and is available for order from their official website <a href="https://store.pine64.org/product/14%e2%80%b3-pinebook-pro-linux-laptop-ansi-us-keyboard-estimated-dispatch-in-december-2019/" target="_blank" rel="noreferrer noopener">here</a>. Both ANSI and ISO keyboard editions cost <strong>$199.99</strong><strong>&nbsp;excluding the shipping charges</strong>. Pine64 says that it will deliver the laptops by late August 2020.</p><h2>14.1 inch Pine Pro Linux Laptop specifications</h2><p>The Pine Pro Linux laptop comes with a 14.1 IPS inch screen giving a resolution of 1920 x 1080. It is powered by the 64-bit dual-core ARM 1.8GHz Cortex A72 and Quad-Core ARM 1.4GHz Cortex A53 processor and a Mali T-860 GPU. It runs on 4GB of LPDDR4 RAM and has 64GB of eMMC 5.0 of internal storage. You can extend the memory with external MicroSD card.</p><p>For connectivity, the Pine Pro laptop comes with WiFi 802.11AC + Bluetooth 5.0. It has one 3.5 mm headphone jack, one USB 3.0 and one USB 2.0 Type-A host port. On top of that, Pinebook also has USB 3.0 Type-C ports with alt-mode display out (DP 1.2). Using this USB-C port, you can connect your existing Linux laptops or <a href="https://androidrookies.com/pine64-launches-the-cheapest-linux-tablet-ever-priced-at-just-99-99/" target="_blank" rel="noreferrer noopener" aria-label="undefined (opens in a new tab)">PineTab.</a> The laptop comes with a Multi-Touch Touchpad and has a 10000 mAH battery. The Pine Pro laptop has a 2MP front camera which doesn‚Äôt seem like much. The product comes with a 30-day warranty and the makers warn of small numbers (1-3) of stuck or dead pixels on Pine Pro laptop LCD screens. The makers say these are normal and should not be considered a defect</p><p>Pine Pro laptop runs on Manjaro Linux distro by default. However, if you don‚Äôt like Manjaro Linux you can install other Linux distributions such as Debian and Fedora Linux. You can check out the supported Pine Pro laptop supported distros <a href="https://wiki.pine64.org/index.php/Pinebook_Pro_Software_Release" target="_blank" rel="noreferrer noopener nofollow" aria-label="undefined (opens in a new tab)">here.</a></p></div></div></div></article></div>]]>
            </description>
            <link>https://androidrookies.com/pine64s-199-99-14-inch-pine-pro-laptop-with-arm-chip-and-manjaro-linux-distro-now-available-for-pre-order/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23905298</guid>
            <pubDate>Tue, 21 Jul 2020 08:44:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bar Chart Race Generator]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23905229">thread link</a>) | @lurluberlu
<br/>
July 21, 2020 | https://fabdevgit.github.io/barchartrace/ | <a href="https://web.archive.org/web/*/https://fabdevgit.github.io/barchartrace/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              <form @submit="checkForm">
                <div v-if="errors.length">
                  <p><b>Please correct the following error(s):</b></p><ul>
                    <li v-for="error in errors"></li>
                  </ul>
                </div>
                <div>
                  <p><label for="customFile">CSV file</label></p><div>
                    <p>
                    <small id="passwordHelpBlock">
                      <a href="#myModal" data-toggle="modal">show accepted csv formats</a>
                    </small>

                    <label for="customFile" ref="filelabel">((fileplaceholder))</label>
                  </p></div>
                </div>
                <p><label for="duration">Animation duration (in s)</label>
                  
                </p>
                <p><label for="top_n">Number of bars to display</label>
                  
                </p>
                <p><label for="title">Title</label>
                  
                </p>
                
              </form>
            </div></div>]]>
            </description>
            <link>https://fabdevgit.github.io/barchartrace/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23905229</guid>
            <pubDate>Tue, 21 Jul 2020 08:25:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Invert, Always, Invert]]>
            </title>
            <description>
<![CDATA[
Score 146 | Comments 38 (<a href="https://news.ycombinator.com/item?id=23905221">thread link</a>) | @anupj
<br/>
July 21, 2020 | https://www.anup.io/2020/07/20/invert-always-invert/ | <a href="https://web.archive.org/web/*/https://www.anup.io/2020/07/20/invert-always-invert/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://www.anup.io/content/images/size/w300/2020/07/nine-kopfer-tJC6I9S3nBw-unsplash.jpg 300w,
                            https://www.anup.io/content/images/size/w600/2020/07/nine-kopfer-tJC6I9S3nBw-unsplash.jpg 600w,
                            https://www.anup.io/content/images/size/w1000/2020/07/nine-kopfer-tJC6I9S3nBw-unsplash.jpg 1000w,
                            https://www.anup.io/content/images/size/w2000/2020/07/nine-kopfer-tJC6I9S3nBw-unsplash.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://www.anup.io/content/images/size/w2000/2020/07/nine-kopfer-tJC6I9S3nBw-unsplash.jpg" alt="Invert,  always, invert">
            </figure>

            <section>
                <div>
                    <blockquote>man muss immer umkehren - Carl Gustav Jacob Jacobi</blockquote><p>(loosely translated - Invert, always, invert)</p><p>Today, we will look at one of my favourite mental models called - The<strong><em> Inversion principle</em></strong>. <a href="https://fs.blog/mental-models/#what_are_mental_models">Mental models</a> are a set of simple, abstract but useful principles that help us make sense of the world around us.</p><p>I came across the Inversion principle on the <a href="https://fs.blog/2013/10/inversion/">Farnam Street blog</a>. It is also a favourite of Charlie Munger (Vice Chairman of Berkshire Hathaway and Warren Buffets mate) - "...it is in the nature of things that many hard problems are best solved when they are addressed backward", he pontificates.</p><p>In another interview, he recalls how, as an Air Force meteorologist during World War II, instead of asking what would keep pilots safe, he asked what would kill them and focussed all his efforts "on trying to predict snow, ice or fog‚Äîand to ignore pretty much everything else.".</p><p>I could write a book on all the other cool stuff Charlie Munger has said so I'll stop here.</p><h3 id="what-is-it">What is it?</h3><p>Inversion is based on the maxim - invert, always, invert. It is about considering an inverse (usually a negative) outcome and listing the reasons for these. It forces you to either stop doing certain things or avoid the actions that lead to the negative outcomes. It gives us <em><em>new possibilities</em> and capabilities</em> that we might not have considered otherwise.</p><p>The algorithm for inversion is very simple:</p><ul><li><strong>Define the problem</strong> - what is it that &nbsp;you're trying to achieve?</li><li><strong>Invert it </strong>- what would guarantee the failure to achieve this outcome?</li><li>Finally, <strong>consider solutions to avoid this failure</strong></li></ul><p>This is very abstract and vague, so let's look at a few examples:</p><ol><li>Instead of asking how do we increase the adoption of a product or feature? You could instead consider - what are some of things preventing adoption? This would lead to a list like this that you could potentially fix:</li></ol><ul><li>Slow load time i.e. performance issues</li><li>Not enough marketing, or marketing on the platform, or to the wrong audience</li><li>The user guide instructions are not clear ... you get the idea</li></ul><p>2. &nbsp;Following the inversion principle it is <em>better to ask</em> what is preventing me from reading all the unread books on my kindle/bookshelf, instead of asking how can i read more books? Possible reasons and something you could give up:</p><ul><li>I spend a lot of time on social media</li><li>I watch too many shows on Netflix or Disney +</li><li>Spend a lot of time on reddit or browsing hacker news</li></ul><p>3. Instead of wondering how do I always choose a winning stock during investing, ask yourself how do you prevent losses in the long term?</p><ul><li>Am I diversifying enough to prevent long term loss?</li><li>Am I investing &nbsp;based on sound principles, or am I speculating? </li></ul><p>Hopefully this &nbsp;gives you a flavour of how powerful inversion is as a mental model. I should add that it is NOT a silver bullet and it won't always give you concrete answers, but it will act as a forcing function to avoid obvious lapses in judgment. I'll leave you with another one of my favourite quotes about Inversion from Charlie.</p><blockquote>"It is remarkable how much long-term advantage people like us have gotten by trying to be consistently not stupid, instead of trying to be very intelligent."</blockquote><hr><p>Further reading:</p><figure><blockquote><a href="https://fs.blog/2014/06/avoiding-stupidity/">Avoiding Stupidity is Easier than Seeking Brilliance</a></blockquote>
</figure><figure><a href="https://commoncog.com/blog/putting-mental-models-to-practice-part-3-better-trial-and-error/"><div><p>Putting Mental Models to Practice Part 3: Better Trial and Error</p><p>Instrumental rationality is the sort of thinking that allows you to achieve your goals. We take a closer look at what decision science says is the ‚Äòbest‚Äô way to pursue this purpose.</p><p><img src="https://commoncog.com/blog/favicon.png"><span>Commonplace - The Commoncog Blog</span></p></div><p><img src="https://commoncog.com/blog/content/images/2018/12/burst-530182-unsplash--1-.jpg"></p></a></figure><p>Thanks for taking the time to read this post, if you found it useful and if you have any comments or more tips, please hit me up on twitter (@<a href="https://twitter.com/anup">anup</a>).</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to Anup Jadhav</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.anup.io/2020/07/20/invert-always-invert/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23905221</guid>
            <pubDate>Tue, 21 Jul 2020 08:23:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Brick Block ‚Äì by Oskar St√•lberg (desktop only)]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 15 (<a href="https://news.ycombinator.com/item?id=23904991">thread link</a>) | @thdrdt
<br/>
July 21, 2020 | http://oskarstalberg.com/game/house/index.html | <a href="https://web.archive.org/web/*/http://oskarstalberg.com/game/house/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  
    <canvas id="canvas" oncontextmenu="event.preventDefault()" height="100%" width="100%"></canvas>
	<div id="loadingBox">
	  
	  
	  <p id="loadingInfo">Loading...</p>
	</div>
		
    


  

</div>]]>
            </description>
            <link>http://oskarstalberg.com/game/house/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23904991</guid>
            <pubDate>Tue, 21 Jul 2020 07:28:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dynamic RBAC with zero performance overhead in Hopsworks]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23904812">thread link</a>) | @jamesblonde
<br/>
July 20, 2020 | https://www.logicalclocks.com/blog/how-we-secure-your-data-with-hopsworks | <a href="https://web.archive.org/web/*/https://www.logicalclocks.com/blog/how-we-secure-your-data-with-hopsworks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><p>TLDR; Feature stores are the new cool kids in the neighbourhood of Data engineering and AI (artificial intelligence). Hyperscale&nbsp; AI companies (such as Uber, Netflix) have <a href="http://www.featurestore.org/">built their own feature stores</a> to solve the problems of reusing, governing and securing access to features (data for AI) in a shared platform. Hopsworks is a modular open-source platform, developed by Logical Clocks, for managing data for AI (a standalone Feature Store), computing features (Spark, Python), and training models. In this post, we introduce the project-based multi-tenancy security model in Hopsworks for users, data, and programs. We describe how our project-based multi-tenant security model is, in effect, a form of dynamic role-based access control with zero performance overhead.</p><figure id="w-node-591b61e7aa1b-87a4da24"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f10585a943c7738c589d3c5_Screenshot%202020-07-16%20at%2015.38.14.png" alt=""></p></figure><p><a href="https://www.logicalclocks.com/blog/introducing-hopsworks-ai">Hopsworks.ai</a> is a SaaS version of Hopsworks, currently available on AWS. Hopsworks clusters can be run with an IAM profile, providing them with an identity in AWS with permission policies that capture what operations the Hopsworks cluster is authorized to perform in AWS - such as read/write data in S3 buckets. Hopsworks can also be used from Data Science and Feature Engineering platforms (Databricks, Sagemaker, KubeFlow, EMR) using API keys exported from Hopsworks.</p><p>This post is concerned primarily with the internal security model in Hopsworks that enables you to host sensitive data in a shared cluster, providing powerful access control and self-service capabilities. The benefit of Hopsworks project-based multi-tenancy model is that you can host many users and feature stores (and other projects) on a single cluster, with self-service access to different feature stores. The advantage of our security model is that you can host production, staging, and development feature stores in a single cluster - you do not need to manage and pay for separate clusters.&nbsp;</p><p><a href="https://en.wikipedia.org/wiki/Role-based_access_control#:~:text=Role%2Dbased%20access%20control%20(RBAC)%20is%20a%20policy%2D,simple%20to%20perform%20user%20assignments.">Role-based access control</a> (RBAC) is a well-known security model that enables administrators to give a group of users the same access rights to selected resources. With roles, an administrator at a company could define a single security policy and apply it to all members of a department. But individuals may be members of multiple departments, so a user might be given multiple roles. <a href="https://link.springer.com/chapter/10.1007/978-3-540-85776-1_17">Dynamic role-based access control</a> means that, based on some other policy, you can change the set of roles a user can hold at a given time. For example, if a user has two different roles - one for accessing banking data and another one for accessing trading data, with dynamic RBAC, you could restrict the user to only allow her to hold one of those roles at a given time. The policy for deciding which role the user holds could, for example, depend on what VPN (virtual private network) the user is logged in to or what building the user is present in. In effect, dynamic roles would allow to hold only one of the roles at a time and sandbox her inside one of the domains - banking or trading. It would prevent her from cross-linking or copying data between the different trading and banking domains.</p><p>Hopsworks implements a dynamic role-based access control model through a project-based <strong>multi-tenant security model. </strong>Inspired by GDPR, in Hopsworks a <em>Project </em>is a sandboxed set of users, data, and programs (where data can be shared in a controlled manner between projects). Every Project has an <strong>owner</strong> with full read-write privileges and zero or more <strong>members</strong>.&nbsp;</p><p>A project owner may invite other users to his/her project as either a <strong>Data Scientist </strong>(read-only privileges and run jobs privileges) or <strong>Data Owner</strong> (full privileges). Users can be members of (or own) multiple Projects, but inside each project, each member (user) has a unique identity - we call it a <em>project-user identity</em>.&nbsp; For example, user <em>Alice</em> in <em>Project A</em> is different from user <em>Alice </em>in <em>Project B - </em>(in fact, the system-wide (project-user) identities are <strong><em>ProjectA__Alice</em></strong> and <strong><em>ProjectB__Alice</em></strong>, respectively)<em>. </em>As such, each project-user identity is effectively a role with the project-level privileges to access data and run programs inside that project. If a user is a member of multiple projects, she has, in effect, multiple possible roles, but only one role can be active at a time when performing an action inside Hopsworks. When a user performs an action (for example, runs a program) it will be executed with the project-user identity. That is, the action will only have the privileges associated with that project. The figure below illustrates how Alice has a different identity for each of the two projects (A and B) that she is a member of. Each project contains its own separate private assets. Alice can use only one identity at a time which guarantees that she can‚Äôt access assets from both projects at the same time.<br></p><figure id="w-node-20ac5438fa1d-87a4da24"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f1058b3943c77358489d4b1_Screenshot%202020-07-16%20at%2015.39.44.png" alt=""></p></figure><p>An <strong>important </strong>aspect of Project based multi-tenancy is that assets can be shared between projects - sharing does not mean that data is duplicated. The current assets that can be shared between projects are: files/directories in HopsFS, Hive databases, feature stores, and Kafka topics. For example, in the figure below there are three users (User1, User2, and User3)&nbsp; and two projects (A and B). User1 is a member of project A, while User2 and User3 are members of project B. All three users (User1, User2, User3) can access the assets shared between project A and project B. As sharing does not mean copying, the access control rules for the asset are updated to give users in the other project read or write permissions on the shared asset.</p><figure id="w-node-7c5391a82675-87a4da24"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f1059150895622a73e57f16_Screenshot%202020-07-16%20at%2015.40.47.png" alt=""></p></figure><p>As we will see later on, <em>project-user identity</em> is based on a X.509 certificate issued internally by Hopsworks. Access control policies, however, are implemented by the platform services:<br></p><ul role="list"><li>files/directories permissions for HopsFS, Hive (storage-based security policy), and the offline Feature Store;</li><li>Kafka ACLs using a <a href="https://github.com/logicalclocks/hops-kafka-authorizer">Hopsworks project-based authorizer plugin</a>;</li><li>Elasticsearch Open Distro permissions using a <a href="https://github.com/logicalclocks/elasticsearch-chef">Hopsworks project-based authorizer plugin</a>.</li></ul><h3>User Identity in Hopsworks</h3><p>When a user authenticates with Hopsworks, they are logged into the platform with a <em>Hopsworks user identity</em>. This user identity is needed to be able to construct the project-user identity - it is the ‚Äúuser‚Äù part of the project-user identity. In Hopsworks, a user-identity is mapped to a global Hopsworks role (independent of project membership) - a <strong>normal</strong> user or an <strong>administrator</strong>. A normal user can search for assets, update her profile, generate API keys, and change to/from projects. Administrators have access to user, project, storage, and application management pages, system monitoring and maintenance services. They can activate or block users, delete Projects, manage Project quotas, promote normal users to administrators, and so on. It‚Äôs important to mention here that a Hopsworks administrator <strong>cannot</strong> view the data&nbsp; inside a project - even if they are allowed to delete a project.<br></p><p>A user interacts with Hopsworks through the web application and they don‚Äôt necessarily realize that the web application is a facade to a modular distributed system. In the background we run <strong>HopsFS</strong> - our next-generation HDFS-on-S3 filesystem, <strong>HopsYARN</strong> - a cluster management system and scheduler, Apache Hive, Elasticsearch, (optionally Kafka and Airflow), and other logging and monitoring services.</p><p>A fundamental principle in every distributed system is that processes exchange messages over the network or through shared state (such as a filesystem or database). When communication is performed by message passing, it is imperative that we protect the messages from adversaries reading or modifying their content and validate the identity of the caller. Traditionally in Hadoop, they use Kerberos and GSSAPI to authenticate and authorize users and encrypt data in-transit. While Kerberos (Active Directory) is widely adopted by big organizations, the administration of users and services is a painful process and the system does not scale. On top of that Kerberos APIs are so complicated that <a href="https://apachebigdata2015.sched.com/event/3zv3/hadoop-and-kerberos-the-madness-beyond-the-gate-steve-loughran-hortonworks">programming against them can be really challenging</a>.</p><p>To avoid the pain of Kerberos (and be able to natively integrate with platforms like Kubernetes), we completely <a href="https://github.com/hopshadoop/hops">re-designed the security model for HopsFS and YARN to use certificates</a>. We replaced Kerberos with Public Key Infrastructure (PKI) with X.509 certificates to authenticate and authorize users. Certificates enabled us to also use the well established TLS protocol to provide confidentiality and data integrity. Every user and every service in a Hopsworks cluster has a private key and an X.509 certificate.</p><figure id="w-node-daa745592959-87a4da24"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f105955f5d5389cb463a175_Screenshot%202020-07-16%20at%2015.42.26.png" alt=""></p></figure><h3>TLS-Based Multi-Tenant Services</h3><p>Hopsworks supports a number of stateful and compute services that use X.509 certificates to authenticate users, applications, and services: HopsFS, HiveServer2, Kafka, YARN. These services all provide their own authorization schemes. We unified HopsFS and Hive‚Äôs authorization models by providing 2-way TLS in HiveServer2 and <a href="https://cwiki.apache.org/confluence/display/Hive/Storage+Based+Authorization+in+the+Metastore+Server">storage based authorization for the Hive metastore</a>, that we <a href="https://github.com/logicalclocks/hive">ported to Hive 3.X</a>, to delegate access control decisions for Hive to HopsFS. In Hive, tables and databases store their data files inside directories on HopsFS, so HopsFS&nbsp; ACLs (access control lists) authorize file system operations by Hive (read from tables, write to tables). The easy-to-understand ACLs that we expose in Hopsworks (for Hive, and datasets in HopsFS) are captured in two roles: Data Scientists can read, Data Owners can read/write. HopsFS ACLs can be customized directly in Hopsworks from version 1.4.</p><p>For Kafka, we developed a <a href="https://github.com/logicalclocks/hops-kafka-authorizer">Hopsworks Authorizer plugin</a> that authorizes operations on Kafka topics by extracting the <em>project-user identity </em>from the client supplied X.509 certificate. The Hopsworks Kafka Authorizer then validates that the user is a member of the project that has permissions to perform the requested action on the Kafka topic.&nbsp;</p><p>HopsYARN uses X.509 certificates to identify users. HopsYARN also creates and manages (including renewal) application certificates for YARN applications (such as Spark jobs). Application certificates in HopsYARN are a key feature missing ‚Ä¶</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.logicalclocks.com/blog/how-we-secure-your-data-with-hopsworks">https://www.logicalclocks.com/blog/how-we-secure-your-data-with-hopsworks</a></em></p>]]>
            </description>
            <link>https://www.logicalclocks.com/blog/how-we-secure-your-data-with-hopsworks</link>
            <guid isPermaLink="false">hacker-news-small-sites-23904812</guid>
            <pubDate>Tue, 21 Jul 2020 06:46:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Design of the Inferno Virtual Machine]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23904624">thread link</a>) | @astdb
<br/>
July 20, 2020 | http://www.herpolhode.com/rob/hotchips.html | <a href="https://web.archive.org/web/*/http://www.herpolhode.com/rob/hotchips.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<i>Phil Winterbottom and Rob Pike
<br>
Bell Labs, Lucent Technologies</i>
<br>
<tt>{philw,rob}@plan9.bell-labs.com</tt><h2>Abstract</h2>
Virtual machines are an important component of modern portable environments such as Inferno and Java because they provide an architecture-independent representation of executable code.  Their performance is critical to the success of such environments, but they are difficult to design well because they are subject to conflicting goals.  On the one hand, they offer a way to hide the differences between instruction architectures; on the other, they must be implemented efficiently on a variety of underlying machines.  A comparison of the engineering and evolution of the Inferno and Java virtual machines provides insight into the tradeoffs in their design and implementation.  We argue that the design of virtual machines should be rooted in the nature of modern processors, not language interpreters, with an eye towards on-the-fly compilation rather than interpretation or special-purpose silicon.<h2>Dis, the Inferno Virtual Machine</h2>
In early 1995, we set out to apply the ideas of the Plan 9 operating system [1] to a wider range of devices and networks.  The resulting system, Inferno [2], is a small operating system and execution environment that supports application portability across a wide variety of processors and operating systems.  Unaware of the contemporary work to establish Java [3] from the technology of the Oak project, we independently concluded that a virtual machine (VM) was a necessary component of such a system [4].  Because of improvements in processor speed and the feasibility of on-the-fly compilers, a VM can execute quickly enough to be economically viable.<p>
The Inferno virtual machine, called Dis, has several unusual aspects to its design: the instruction set, the module system, and the garbage collector.</p><p>
The Dis instruction set provides a close match to the architecture of existing processors.  Instructions are of the form</p><pre>	<i>OP    src1</i><tt>,</tt><i> src2</i><tt>,</tt><i> dst</i></pre><p>
The <i>src1</i> and <i>dst</i> operands specify general addresses or arbitrary-sized constants, while the <i>src2</i> operand is restricted to smaller constants and stack offsets to reduce code space.  Each operand specifies an address either in the stack frame of the executing procedure or in the global data of its module.</p><p>
The types of operands are set by the instructions.  Basic types are <tt>word</tt> (32-bit signed), <tt>big</tt> (64-bit signed), <tt>byte</tt> (8-bit unsigned), <tt>real</tt> (64-bit IEEE floating point), and pointer (implementation-dependent).  The instruction set follows the example of CISC processors, providing three-operand memory-to-memory operations for arithmetic, data motion, and so on.  It also has instructions to allocate memory, to load modules, and to create, synchronize, and communicate between processes.</p><p>
A module is the unit of dynamically loaded code and data.  Modules are loaded by a VM instruction that returns a pointer to a method table for the module.  That pointer is managed by the VM's garbage collector, so code and data for the module are garbage collected like any other memory.  Type safety is preserved by checking method types at module load time using an MD5 signature of the type.   </p><p>
Memory management is intimately tied to the instruction set of the VM.  Dis uses a hybrid garbage collection scheme: most garbage is collected by simple reference counting, while a real-time coloring collector gathers cyclic data.  Because reference counting is an exact rather than conservative form of garbage collection, the type of all data items must be known to the VM run-time system.  For this reason, the language-to-VM compiler generates a type descriptor for all compound types.  This descriptor reports the location of all pointers within the type, allowing the VM to track references as items are copied.</p><h2>Garbage collection</h2>
Memory dominates the cost of small systems, so the VM should be designed to keep memory usage as small as possible.  Through reference-counted garbage collection, Dis reclaims memory the moment it becomes unused.  Reference counting also eliminates the need for a large arena as required for efficient mark-and-sweep collection.  Both these results reduce the memory requirements of the VM and its applications.<p>
Compare this to the Java VM, whose instruction set makes it difficult to track references as objects are copied.  This biases against reference counting, so JVM implementations choose lazier techniques such as mark-and-sweep, inducing a larger arena and delayed collection, both of which increase the memory use and therefore the cost of the overall system.</p><h2>Issues in compiling</h2>
It is easy to interpret the individual instructions of a stack-based virtual machine (SM) such as the Java virtual machine (JVM), because most operands are implicit.  However, a high-level language implementation of the interpreter generates more memory traffic than the equivalent set of instructions in a memory transfer machine (MM) such as Dis.  Consider the code to execute<pre>	<tt>c = a + b;</tt></pre><p>
An SM would execute this by a code burst such as this, which we have annotated with its memory traffic using L for load and S for store:</p><pre>	<tt>push  a      # </tt>LS<tt>
	push  b      # </tt>LS<tt>
	add          # </tt>LLS<tt>
	store c      # </tt>LS</pre><p>
The corresponding MM code burst would be the plain three-operand instruction</p><pre>	<tt>add   a,b,c  # </tt>LLS</pre><p>
When interpreting, the extra memory traffic of the SM is masked by the time saved by not decoding any operand fields.   The operand fields are implicit in the SM instructions, while the MM they are explicit: three operand fields must be decoded in every instruction, even those without operands.</p><p>
When compiling, the tradeoffs are different.  Clearly, either design can produce the same native instructions from its just-in-time compiler (JIT), but in the SM case most of the work must be done in the JIT, whereas in the MM design the front end has done most of the work and the JIT can be substantially simpler and faster.</p><p>
A JIT for an SM is forced to do most of the work of register allocation in the JIT itself.  Because the types of stack cells change as the program executes, the JIT must track their types as it compiles.  In an MM, however, the architecture maps well to native instructions.  This produces a continuum of register allocation strategies from none, to simple mapping of known cells to registers, to flow-based register allocation.  Most of the work of any of these strategies can be done in the language-to-VM compiler.  It can generate code for an infinite-register machine, and the JIT can then allocate as many as are available in the native architecture.  Again, this distribution of work keeps the JIT simple.  </p><h2>Processors</h2>
The same issues that face the JIT writer also face the designer of special-purpose processors to support a VM.  Register allocation in the JIT is analogous to register relabeling in silicon, and an SM design adds unnecessary complexity to an already difficult problem.  One might argue that a stack-based processor design would mitigate the difficulties, but our experience with the implementation of a stack machine in the AT&amp;T Crisp microprocessor [5] leads us to believe that stack architectures are inherently slower than register-based machines.  Their design lengthens the critical path by replacing simple registers with a complex stack cache mechanism.<p>
In other words, it is a better idea to match the design of the VM to the processor than the other way around.</p><p>
Dis fits this criterion better, but we do not plan to implement Dis in silicon.  The idea of a VM is to be architecture-independent; offering a special processor to run it negates the original goal by favoring one instruction set.  Ignoring that for the moment, though, there could still be two reasons to consider designing silicon for Dis: performance and cost.</p><p>
On performance, history shows that language-specific CPUs are not competitive.  The investment in the special design takes energy away from the systems issues that ultimately dominate performance.   Performance gains realized through language-specific support tend to be offset by parallel improvements in general-purpose processors during the life cycle of the CPU.</p><p>
Dis compiles quickly into native code that runs only 30-50% slower than native C.  At the current rate of processor improvement, that is only a few months of processor design time.  It is wiser to focus on improving execution on commodity, general purpose processors than on inventing a new architecture.</p><p>
The issue of cost is more subtle.  Dis is close enough to familiar architectures that a special chip with high integration of systems facilities could be cost-effective on small platforms.  The real reason for that, though, is that the memory management design of the virtual machine makes it easy to implement Dis in small memory.  By contrast, whatever cost gains an integrated Java processor might realize will likely be lost in the extra memory required by its conservative garbage collection scheme [6].</p><h2>References</h2>
<dl><dt><span size="2">1.  R. Pike, D. Presotto, S. Dorward, B. Flandrena, K. Thompson, H. Trickey, and P. Winterbottom. ``Plan 9 from Bell Labs'', </span><i><span size="2">J. Computing Systems</span></i><span size="2"> 8:3, Summer 1995, pp. 221-254.</span></dt><dt><span size="2">2.  Dorward, S., et al., ``Inferno'', </span><i><span size="2">IEEE Compcon 97 Proceedings</span></i><span size="2">, 1997.</span></dt><dt><span size="2">3.  Arnold, K. and Gosling, J., </span><i><span size="2">The Java Programming Language</span></i><span size="2">, Addison-Wesley, 1996.</span></dt><dt><span size="2">4.  Nori, K. V., Ammann, U., Nabeli, H. H., and Jacobi, Ch.,  ``Pascal P Implementation notes'', in Barron, D. W. (ed.), </span><i><span size="2">Pascal&amp;emdash;The Language and its Implementation</span></i><span size="2">, Wiley, 1981, pp. 125-170.</span></dt><dt><span size="2">5.  Ditzel, D. R. and McLellan, R., ``Register Allocation for Free: The C Machine Stack Cache'', </span><i><span size="2"> Proc. of Symp. on Arch. Supp. for Prog. Lang. and Op. Sys.</span></i><span size="2">, March, 1982, pp. 48-56.</span></dt><dt><span size="2">6.  Case, B., ``Implementing the Java Virtual Machine'', </span><i><span size="2">Microprocessor Report</span></i><span size="2">, March 25, 1996, pp. 12-17.
</span></dt></dl>

</div>]]>
            </description>
            <link>http://www.herpolhode.com/rob/hotchips.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23904624</guid>
            <pubDate>Tue, 21 Jul 2020 05:56:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Many Faces of an Undying Programming Language]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 28 (<a href="https://news.ycombinator.com/item?id=23904104">thread link</a>) | @grugagag
<br/>
July 20, 2020 | http://jakob.space/blog/thoughts-on-lisps.html | <a href="https://web.archive.org/web/*/http://jakob.space/blog/thoughts-on-lisps.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>July 20, 2020 ‚ùñ Tags: <a href="http://jakob.space/blog/tag/tag/opinion.html">opinion</a>, <a href="http://jakob.space/blog/tag/tag/programming.html">programming</a>, <a href="http://jakob.space/blog/tag/tag/lisp.html">lisp</a>, <a href="http://jakob.space/blog/tag/tag/common-lisp.html">common-lisp</a>, <a href="http://jakob.space/blog/tag/tag/scheme.html">scheme</a></p><article><p>
This is a post I've been meaning to write for a while now: one anecdotally
comparing programming languages in the Lisp family. I consider myself to be a
Lisp hacker. Perhaps that much was obvious from the letter Œª adorning my
website's header, a reference to the Œª-calculus which inspired John McCarthy to
design the first LISP [1]. Yet, "Lisp hacker" likely means little unless you,
too, consider yourself to be a Lisp hacker. Calling yourself one seems carry
some level of unstated meaning. Indeed, some identify with more specific groups.
"Schemer," or "Guiler," or "Racketeer," or "Clojurist." But "Lisp Hackers" ‚äá
"Schemers". There is commonality shared among all, or at least most, of these
programming languages, and the Lisp hackers recognize and appreciate that
commonality ‚Äì the characteristics that make a programming language a Lisp.
Homoiconic syntax, powerful metaprogramming facilities, and editor support that,
in my opinion, is unparalleled. (Yes, I am alluding to GNU Emacs.) This article,
however, is concerned with the differences. In it, I will be considering the
specifics of each dialect, and whether or not those specifics make for a
language I would want to use to develop a new piece of software.
</p><p>
I'm specifically concerned with game development at the time of writing this
article. An idea for a turn-based tactics game came to me and I felt a Lisp
would be the best tool for realizing it, but the decision to use "a Lisp" still
leaves me with several choices. When I enumerate the notable design choices
behind each dialect, and talk about the approaches I prefer, my opinions will
be, in some capacity, framed as partial answers to the question of "will I be
able to comfortably use this to write a video game?" As such, there are a few
things I am specifically interested in:
</p><ul>
<li><b>Ergonomics</b>, or "a measure of the friction [one experiences] when trying to get
things done" [2].</li>
<li><b>Expressiveness</b>, or the ease with which code may be understood by a reader.</li>
<li><b>Performance</b>, which is nontrivial to properly quantify [3]. I won't be rigorous
with this; a one-off run with <code>time</code> can give a good idea of the order of
magnitude for execution time.</li>
<li><b>Ease of distribution</b>, which is difficult to define, but with which I associate
platform agnosticism, a runtime that won't bloat my tarballs by several
gigabytes, and a lack of baroque and difficult to obtain dependencies.</li>
<li><b>Ability to interface with other libraries</b>, as I'll want to be able to
draw to the screen, and play sounds, and so on.</li>
</ul><p>
For each dialect, I'm allowing myself to use nonstandard functions. I'm aiming
for an evaluation of the practical aspects of each language, and if you were
writing software, you'd likely be using more than what's included in the R5RS or
ANSI CL standards. Though, if these nonstandard functions are specific to a
single implementation, I will avoid them. SRFI's and QuickLisp are fair game,
but CHICKEN's Eggs are not. Ah, I'm already getting ahead of myself. Yes, I will
be comparing Scheme and Common Lisp. I almost have to ‚Äì the history of Lisp
tends to be spun as a schism between Common Lisp and Scheme. I will be speaking
of a few others as well. I've mostly chosen dialects for which there exists some
"game engine" type library. For R7RS (CHICKEN), there is <a href="http://alex-charlton.com/projects/Hypergiant/">Hypergiant</a>, for R6RS
(Guile) there is <a href="https://dthompson.us/projects/chickadee.html">Chickadee</a>, for Common Lisp there is <a href="http://www.xelf.me/">Xelf</a>, and for Fennel there
is, of course, <a href="https://love2d.org/">L√ñVE</a>.
</p><figure>
<img src="http://jakob.space/static/image/lisp-personality-test.png" alt="lisp-personality-test.png">

<figcaption><span>Figure 1: </span>My take on the drawing in Conrad Barski's <i>Land of Lisp</i>. From left to right: Common Lisp, Scheme, <del>Haskell</del> Fennel.</figcaption>
</figure><p>
What follows are my opinions, so I'd like to lead with the background that
motivated them. My earliest "serious" experience with Lisp was with Peter
Seibel's <i>Practical Common Lisp</i>, which I picked up in high school following a
failed attempt at reading <i>Structure and Interpretation of Computer
Programs</i>.<sup><a id="fnr.1" href="#fn.1">1</a></sup> The portion of the latter book that I did manage was enough to
convince me that learning <span>a</span> Lisp would be valuable, but that learning Common
Lisp may be more tractable than learning Scheme. The summer following my first
year of university, I taught myself Scheme to do <a href="http://summerofcode.withgoogle.com/">GSoC</a> for <a href="https://guix.gnu.org/">GNU Guix</a>. Guile
quickly grew on me, and I soon began <a href="http://jakob.space/blog/transition-to-haunt.html">using Haunt</a> for my personal website. I've
been unknowingly using Emacs Lisp since much earlier ‚Äì not in the sense of
writing packages ‚Äì my old man taught me how to use Emacs when I was nine, but I
was <a href="https://www.gnu.org/software/emacs/manual/html_node/emacs/Easy-Customization.html">mostly shielded from having to write <code>setq</code> forms</a>. I've also used <a href="https://docs.hylang.org/en/stable/">Hy</a>, <a href="https://fennel-lang.org/">Fennel</a>,
‚Ä¶ well, I'm wildly off track now. Point being, I've used many Lisps, and I've
subconsciously acknowledged the differences between them, but never turned that
acknowledgment into coherent thought.
</p><p>
To aid in the comparison, I've written the same raytracer in several dialects of
Lisp. My reasons for choosing a raytracer are that:
</p><ul>
<li>I'm reasonably familiar with how they work.</li>
<li>Performance matters, and differences in performance is noticeable.</li>
<li>It's nontrivial, but several implementations of a raytracer is also more
tractable than, say, several implementations of a high-performance database.</li>
</ul><p>
Another consideration was the number of advancements in raytracing that build
upon the same basic structure, potentially giving me a way to compare the ease
with which a change to a system can be made, but writing these raytracers took
enough out of me that I didn't want to play with them any more.
</p><p>
This was not nearly as telling of a comparison as I had hoped. Once I'd
completed the first raytracer, everything that followed had the same structure.
Regardless, writing these raytracers gave me an idea of the characteristics I
was interested in, especially performance. For anyone who would like to look at
the code, the implementations are available <a href="https://git.sr.ht/~jakob/lisp-raytracer-zoo">here</a>.
</p><p>
<b>Table of Contents</b>
</p><ul>
<li><a href="#org9a5541d">The Issue of Rendering an Image</a></li>
<li><a href="#orga8f893b">Scheme</a>
<ul>
<li><a href="#org4538c39">R7RS</a></li>
<li><a href="#org47b9bd9">R6RS</a></li>
<li><a href="#org3eedb31">Conclusions on Scheme</a></li>
</ul></li>
<li><a href="#org9e27a4b">Common Lisp</a>
<ul>
<li><a href="#org0df9ac3">Conclusions on Common Lisp</a></li>
</ul></li>
<li><a href="#org4d7f824">Fennel</a>
<ul>
<li><a href="#org3eb9b83">Conclusions on Fennel</a></li>
</ul></li>
<li><a href="#org0fbbf7a">Lisps I've Neglected</a>
<ul>
<li><a href="#org1bb9256">Emacs Lisp</a></li>
<li><a href="#orga47743c">Gerbil Scheme</a></li>
<li><a href="#orgcca7e64">Racket</a></li>
<li><a href="#org883fd6d">Janet</a></li>
<li><a href="#org965e8ce">Clojure</a></li>
</ul></li>
</ul><div id="outline-container-org9a5541d">
<h2 id="org9a5541d">The Issue of Rendering an Image</h2>
<div id="text-org9a5541d">
<p>
Well, if we're writing a raytracer, then, we had better have some way of seeing
the results. The issue is portability. Ideally, I'd like to be able to run the
raytacers on different implementations of each language, but none of them have
standardized support for drawing graphics. An idea I had was to render the image
to the terminal using ANSI escape sequences, but I thought the resulting images
would be quite shitty. Instead, I decided to go the <a href="https://github.com/ssloy/tinyrenderer/wiki/Lesson-0-getting-started">route that tinyrenderer
takes</a>, which is to output to an image file. Initially, the image format I went
with was the venerable PNG. This was a mistake. Even if it did lead to a rather
elegant CRC procedure in Scheme.
</p>

<div>
<pre>(<span>define</span> (<span>chunk-crc</span> bytes)
  (<span>define</span> (<span>process-byte</span> crc byte)
    (bitwise-xor (vector-ref png-crc (bitwise-and #xff (bitwise-xor crc byte)))
                 (arithmetic-shift crc -8)))
  (reduce process-byte bytes #xffffffff))
</pre>
</div>

<p>
Realizing PNG was needlessly complex, I went on to write a <a href="https://git.sr.ht/~jakob/lisp-raytracer-zoo/tree/master/write-bmp.scm">BMP encoder</a>, which
was fine until I came across <a href="https://nullprogram.com/blog/2017/11/03/">an article</a> from Chris Wellons about rendering video
with C by encoding frames as <a href="http://netpbm.sourceforge.net/doc/">Netpbm</a> images. I decided to scrap my BMP encoder
and go with PPM instead. Netpbm is text-based: the issue with a PNG or BMP
encoder in Scheme, for example, is that you're dealing with a binary format.
Glancing over the standards now, it seems there are, indeed, standardized
procedures for dealing with binary data in both R6RS and R7RS. Regardless,
dealing with those binary structures and having to consider endianness is a
pain. PPM is <span>dead</span> simple. In fact, I'd wager that if all you had access to were
the examples on the <a href="https://en.wikipedia.org/wiki/Netpbm">Wikipedia</a> page, you'd be able to write an encoder. Here's
the Scheme implementation:
</p>

<div>
<pre>(<span>define</span> (<span>write-ppm</span> width height pixels)
  <span>"Encode the WIDTH by HEIGHT image given as PIXELS into the portable pixmap</span>
<span>format (PPM), writing the result to `(current-output-port)'."</span>
  (<span>define</span> (<span>delimit-values</span> values)
    (<span>cond</span> ((null? values)
           (newline))
          ((= 1 (length values))
           (display (car values))
           (delimit-values (cdr values)))
          (<span>else</span>
           (display (car values))
           (display <span>" "</span>)
           (delimit-values (cdr values)))))

  
  (delimit-values '(<span>"P3"</span>))

  
  (delimit-values (list width height))

  
  (delimit-values '(<span>"255"</span>))

  
  (<span>for-each</span> delimit-values (vector-&gt;list pixels)))
</pre>
</div>

<p>
If you do away with my nice formatting, that's twelve lines of code, all of
which are R5RS-compatible. We have access to the Netpbm suite, too, so if we
want a PNG, we can always <code>./write-ppm | pnmtopng &gt; test.png</code>. Netpbm is a
real hidden gem. Well, hidden to me, at least.
</p>
</div>
</div><div id="outline-container-orga8f893b">
<h2 id="orga8f893b">Scheme</h2>
<div id="text-orga8f893b">
<p>
If you aren't familiar with Scheme, it has somewhat of a self-imposed<sup><a id="fnr.2" href="#fn.2">2</a></sup>
reputation for appealing to academic types. It's also one of the most
opinionated languages I know of; all the specs of interest lead with an
assertion that "programming languages should be designed not by piling feature
on top of feature, but by removing the weaknesses and restrictions that make
additional features appear necessary." The way that Scheme embraces purity and
simplicity makes it clear it was designed by math nerds. (Hey, I'm a math nerd,
too. Take it easy.)
</p>

<p>
As I've just mentioned, there are specs. A few, to be sure. The evolution of
Scheme standards begins in a linear fashion: RRS ‚Üí RRRS ‚Üí R3RS ‚Üí R4RS ‚Üí R5RS. I
like to think of this as "classic Scheme". But when it came time to revise R5RS,
the ratification of the subsequent R6RS caused some controversy. It was
"bloated", or whatever. Something like that. So when it came time to design R7RS
(small), the Scheme Language Steering Committee decided to let the language
fork, beginning with the earlier R5RS as a blank slate [4]. That way, the nerds
that hated everything about R6RS could have their way, and the nerds that liked
R6RS could have their way. Scheme was divided, but at peace. Oh, and nowadays
there's a work-in-progress <a href="https://bitbucket.org/cowan/r7rs-wg1-infra/src/default/R7RSHomePage.md">R7RS-large</a>. ‡≤†_‡≤†
</p>

<p>
I'm not going to talk about R7RS-large here. It's just too ‚Ä¶</p></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://jakob.space/blog/thoughts-on-lisps.html">http://jakob.space/blog/thoughts-on-lisps.html</a></em></p>]]>
            </description>
            <link>http://jakob.space/blog/thoughts-on-lisps.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23904104</guid>
            <pubDate>Tue, 21 Jul 2020 03:29:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Assessing Abstractions]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23904080">thread link</a>) | @stopachka
<br/>
July 20, 2020 | https://stopa.io/post/245 | <a href="https://web.archive.org/web/*/https://stopa.io/post/245">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><p>Some abstractions are ticking time bombs, while others help you move fast. How can you tell? What follows is my personal exploration for how I assess abstractions.</p><h2>Problem</h2><p>We add abstractions in our programs to solve problems. So, let‚Äôs start with the fundamental value proposition: what problem does our abstraction solve? </p><p>Let‚Äôs take a look at one example abstraction:</p><pre><code>NLP.parse(...) // =&gt; { intent: "set_alarm", at: "1593538633430" }</code></pre><p>This could be a natural language processing abstraction, which lets us take a piece of text, and extract meaning from it. The inherent problem of natural language processing is pretty darn complex, so an abstraction that helps us solve it would be very valuable. This is a sign of a good abstraction.</p><p>Now let‚Äôs compare that to </p><pre><code>StringSplitter.easySplit(str, splitStr)</code></pre><p>Maybe this abstraction, adds a light layer on top of string.split. For example, it may make it so you don‚Äôt have to worry about regexes, and can turn common string patterns into regexes. The value of a <code>StringSplitter</code> abstraction is pretty darn low. Maybe  <code>StringSplitter</code> treats <code>splitStr</code> in a way that‚Äôs a bit more in-line with the someone‚Äôs thinking, but at the end of the day this boils down to an indirection. </p><p>This leads us to the first principle. The more complex the problem it solves for you, the better the abstraction (1).</p><h2>Interface</h2><p>After we‚Äôre convinced that the abstraction we are about to add solves a tough problem for us, the next thing to consider is the interface: <em>how</em> do we interact with the abstraction? Imagine if <code>NLP.parse</code> was called like this:</p><pre><code>NLP.parse(lang, text)</code></pre><p>This is a great interface. It‚Äôs small. We don‚Äôt need to understand any internals. For the main use-case, all we need to do is to provide language and text. Compare that with</p><pre><code>NLP.parse(
  text,
  lang, 
  strategy,
  shouldUseFlagA,
  ...
  shouldUseFlagZ
)</code></pre><p>In order to use this version, we‚Äôd need to deeply understand the internals of NLP.parse. This lowers the value of the abstraction, because we need to do more work to solve the same level of complexity. </p><p>This leads us to the second principle: <strong>great abstractions have small interfaces.</strong></p><h2>Breakthrough Cost</h2><p>Now that we have an abstraction with a simple interface that solves a hard problem, we need to ask a possibly fatal question: what happens when we need to break through the abstraction? </p><p>All abstractions are leaky at some point. What will happen when you need the abstraction to behave differently? What will happen when it doesn‚Äôt work as you expect? </p><p>For example, for <code>NLP.parse(lang, text)</code>, what if we needed to sort and score the results differently? What if there‚Äôs a bug, and we aren‚Äôt getting the entity we expect, can we look through and debug?</p><p>Understanding the answer to this, will give us the breakthrough cost. To do this, we need to peak through the code. How is <code>NLP.parse</code> implemented?</p><pre><code>parse(lang, text) { 
  return format(scoreEntities(fetchEntities(lang, text)))
}</code></pre><p>In one solution, it could be composed of other abstractions that we can take advantage of. This is a great sign, because we can reuse the underlying abstractions in cases where we need to do something more complicated. Compare that to </p><pre><code>parse(lang, text) { 
  internalParse(lang, text, flagA, flagB, ...flagZ)
}</code></pre><p>This feels more dangerous. If these flags all head to the same function, it‚Äôs a sign that a bunch of different features are complected together. It‚Äôs also worrying: what if one of these flags don‚Äôt do what you want? you may have to fork the abstraction.</p><p>This leads us to the third principle: <strong>great abstractions are transparent.</strong> I think this principle is the most overlooked. It‚Äôs easy to take the productivity win upfront, but if the abstraction you add can‚Äôt be changed, and can‚Äôt be introspected, it‚Äôs very likely to bite you at some point.</p><h2>Generality</h2><p>The final principle is orthogonal to the last three, but maybe it‚Äôs the most important. Hardy said <em>there is no permanent place in the world for ugly mathematics ‚Äî</em> So it is with abstractions. The beauty in math relates to how ‚Äúgeneral‚Äù and ‚Äútight‚Äù the solution is. I think this parallels well with abstractions. </p><p>If you use an abstraction that is ‚Äúessentially‚Äù simpler, it‚Äôs more likely to last, and it‚Äôs likely to be more powerful.</p><p>Consider if the abstraction for <code>NLP</code>, was made up of specific algorithms, <em>just</em> for natural language processing. This would still be very valuable, but what would be <em>even more</em> valuable, is if the abstractions that this library was composed of was more general: if the parts that compose it were deep learning abstractions, you could reuse them for other problems.</p><h2>Fin</h2><p>And we reach the end. To pick great abstractions: pick the ones that solve a complex problem for you. Make sure they have a simple interface, and take a look at the internals, so you‚Äôre confident you can jig things up if needed. The more general and simple you can get for the same amount of power, the better. </p><p>Want to see some great abstractions in the wild? First, chances are you are using many of them: TCP, higher order functions like map &amp; filter, React. Some you may not have explored: Go‚Äôs CSP, Rich Hickey‚Äôs Datomic, or his <code>seq</code> abstraction in Clojure. As you pick up abstractions, I encourage you to run each one as an experiment: ask yourself at the end how things went, discuss them with your friends, and soon you‚Äôll develop a much more nuanced taste.</p><p>(1) The rabbit hole gets deeper. Even if an abstraction solves a complex problem you have, you may need to take a step back and also ask: why do I have this problem? For example, kubernetes may be a great solution to building distributed systems, but why do you have a distributed systems problem? Many times the problem itself can be avoided. For the answer to that, <a href="https://stopa.io/post/241" target="_blank">Hacker‚Äôs Paradise</a> tries to covers it.</p><p><em>Thanks to Alex Reichert, Daniel Woelfel, Martin Raison, Sean Grove for reviewing drafts of this essay</em></p></span></p></div></div></div>]]>
            </description>
            <link>https://stopa.io/post/245</link>
            <guid isPermaLink="false">hacker-news-small-sites-23904080</guid>
            <pubDate>Tue, 21 Jul 2020 03:24:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An alternative to Disqus for your website]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23903872">thread link</a>) | @supz_k
<br/>
July 20, 2020 | https://talk.hyvor.com/blog/move-away-from-disqus/ | <a href="https://web.archive.org/web/*/https://talk.hyvor.com/blog/move-away-from-disqus/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <div><div><p><img src="https://talk.hyvor.com/blog/wp-content/uploads/2020/06/Goodbye_-Disqus.png" alt="" data-src="https://talk.hyvor.com/blog/wp-content/uploads/2020/06/Goodbye_-Disqus.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></div></div><p><span></span>
<span>168</span>
</p>
<p>Disqus is one of the most popular commenting systems out there. However, <a href="https://techcrunch.com/2017/12/05/zeta-global-acquires-commenting-service-disqus/">ZetaGlobal acquired Disqus in 2017</a> that changed the path of it. ZetaGlobal is a data-powered marketing technology company that ‚Äúloves data‚Äù. So, they started using Disqus to collect data from millions of users around the world who visit websites that use Disqus as the commenting platform. Because of the ‚Äúapparently free‚Äù pricing plan, Disqus had millions of websites using it, which made their data set the <a href="http://data.disqus.com/">largest on the web</a>. Disqus has lost a lot of users in recent times due to these privacy concerns, and there are plenty of reasons to remove Disqus. This blog post sums up 19 reasons why you should move away from Disqus.</p>
<h2>Reasons to Move Away From Disqus</h2>
<h3>1. Disqus places Ads on your Website</h3>
<p>If you are using the free plan of Disqus, they place ads on your website. This results in increased page load times, which will hurt your <a href="https://talk.hyvor.com/blog/on-page-seo-checklist/">on-page SEO</a>. It is also a bad experience for your users. Disqus seems to be crashing every party without any invitation. </p>
<h3>2. Disqus places Affiliate Links on your Website automatically</h3>
<p><a href="https://poststatus.com/disqus-potentially-adding-affiliate-links-users-content-opted/">Disqus was caught</a> placing affiliate links on the website without the consent of website owners. <a href="https://help.disqus.com/en/articles/1717122-how-to-disable-affiliate-linking">The official documentation says</a> that you cannot turn off affiliate links placed within the comments.</p>
<p>Let‚Äôs say one of your commenters mention ‚Äúbuy a camera on Amazon‚Äù (without links). Disqus will detect this and place a link from Amazon on this anchor text. When someone clicks this link and buys a product, Disqus will receive a commission. </p>
<blockquote><p>Disqus makes money <strong>from your content</strong>.</p></blockquote>
<h3>3. Disqus is Owned by a Data/Marketing Company</h3>
<p>Most publishers think Disqus is a standalone company, which empowers social conversations on websites. Wrong! It is owned by a company called ZetaGlobal where your visitors become the product. &nbsp;Automattic founder&nbsp;<a href="https://replyable.com/2017/03/disqus-is-your-data-worth-trading-for-convenience/">Matt Mullenweg said in 2014</a>, ‚ÄúWe‚Äôre tracking everyone who visits a website with Disqus enabled and building a profile on them based on the content of the sites they visit and any comments they leave. ‚ÄúDeeper‚Äù than Facebook.‚Äù This just says it all, doesn‚Äôt it?</p>
<h3>4. Disqus sells your Visitors‚Äô Data without their Consent and has Violated GDPR</h3>
<p>Disqus collects user‚Äôs data from millions of their client websites. Worst, they sell them to big companies <strong>without the user‚Äôs consent</strong>. Their <a href="http://data.disqus.com/">data.disqus.com</a> website says their clients include companies like Twitter. <a href="https://twitter.com/martingund/status/1207327648093003777">This twitter thread</a> by Martin Gundersen reveals more information about their data selling. He calls Disqus a ‚ÄúData Machine‚Äù.</p>
<h3>5. You are already Paying Disqus even when you Use the Free Plan (Spoiler: Your visitors are the products)</h3>
<p>As I mentioned earlier, the free plan isn‚Äôt free. You help the data company collect data. For example, assume that a.com and b.com have Disqus installed. You visit both websites on the same day. And, Disqus knows it! This is a crucial connection in the advertising field. When they sell it to another company, they will also know that you visited a.com and b.com. Advertising companies use this data to personalize the ads for you. So, there will be thousands of companies knowing what are your interests. </p>
<p>The same thing happens to your visitors. By using Disqus on your website, you are giving Disqus an opportunity to track them.</p>
<h3>6. You have to Pay to Remove Ads ‚Äì But, there‚Äôs no Guarantee about User Tracking</h3>
<p>While you can subscribe to a paid plan of Disqus to remove advertisements on your website, there‚Äôs no mention if they stop tracking users. Disqus seems to track you and remember your computer, so to create another account and actually be able to comment, you have to find another computer. You‚Äôre being tracked in the name of advertising every step of the way on the Internet. In fact, Disqus is using the plugin to&nbsp;<strong>profile your visitors to later target them with ads</strong>.&nbsp;</p>
<h3>7. Disqus makes your Website extremely Slow</h3>
<p>By injecting ads and third-party code to your website, Disqus will make your website extremely slow. Here‚Äôs a list of HTTP requests Disqus can add to your website:</p>
<figure><img src="https://fatfrogmedia.com/wp-content/uploads/2017/07/gtmetrix-redirects-problems-from-disqus-ads.jpg" alt="gtmetrix redirects problems from disqus ads" data-src="https://fatfrogmedia.com/wp-content/uploads/2017/07/gtmetrix-redirects-problems-from-disqus-ads.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>Source: fatfrogmedia.com</figcaption></figure>
<p>The more HTTP requests you have the slower your website is. Disqus adds hundreds of spammy redirect links to your website. Additionally, it fetches a bunch of CSS and JS files to render the ads and affiliate links on your website. Even worst, these links come from third-party domains, which takes even more time to load due to <a href="https://talk.hyvor.com/blog/dns/">DNS resolving</a>. Additionally most people don‚Äôt have the time to create an account or switch between their Disqus profiles just to comment on a blog post. The year 2020 is all about hyper-distraction and inattentiveness. People ignore things that hinder progress. No one wants to spend five seconds logging into an account just to comment.</p>
<h3>8. Disqus discourages Commenters</h3>
<p>Disqus has millions of user accounts. However, it‚Äôs just a little fraction compared to 4 billion active internet users. Disqus doesn‚Äôt have a guest commenting option. While those who have Disqus accounts can comment easily from their account, what about others? Creating a new account just to post a comment isn‚Äôt reasonable. Guest commenting is a powerful option to have!</p>
<h3>9. Moderating in Disqus is complicated</h3>
<p>When you add a new website to Disqus, it creates a new subdomain for that website. You‚Äôll need to switch between these subdomains every time if you moderate multiple websites. It makes moderation slower (And, it‚Äôs why <a href="https://www.reddit.com/r/Slack/comments/d51ppa/slack_redirects_subdomain_to_appslackcom/">Slack moved from subdomains to app.slack.com</a> in their web version). </p>
<p>And, their admin panel isn‚Äôt a single page application, which makes it even slower.</p>
<h3>10. Disqus is Old-fashioned</h3>
<p>At the time of 2010, Disqus‚Äôs design was innovative. However, this is 2020. There are new and better practices and tools to make web applications more user friendly. Despite its resources, the company failed to make the product user-friendly. The usability factor is a good enough reason to remove Disqus.</p>
<h3>11. Disqus isn‚Äôt Customizable</h3>
<p>Disqus has a similar appearance in all websites. It would be impossible to see the discussion box due to the color scheme; on certain website templates, the discussion box would be almost invisible. A visitor would not be able leave a comment because the discussion box may appear to be missing. The fact is that it is not possible to apply custom CSS to the new Disqus. The plugin will automatically apply a scheme based on the text color it inherits from a website. So depending on whether your template‚Äôs stylesheet has a light or dark color scheme, Disqus will make a selection. It cannot be as customized as you love. </p>
<h3>12. Disqus‚Äôs Pricing isn‚Äôt Flexible</h3>
<p>Disqus has free, plus ($9/month), pro ($89/month), and business (Custom pricing) plans. <a href="https://blog.hubspot.com/marketing/why-people-buy-factors-influence-purchase-descision#sm.0001o2k17imgbe7411rqj2vln3h2q">80% of consumers</a>&nbsp;consider pricing as a major deciding factor when shopping online: This is not only applicable to e-commerce sites but even to those in the plugin market. If you‚Äôre looking for more control over how you pay for a commenting platform, then look for that one option, which offers you a great deal of flexibility and added features.</p>
<h3>13. Disqus only has Single Sign-on in their Custom Pricing Plans</h3>
<p><a href="https://talk.hyvor.com/documentation/sso/introduction">Single sign-on (SSO)</a> is the most important feature for most companies. Disqus only provides it in their custom pricing plans, which is very expensive.</p>
<h3>14. Disqus Admins ban Websites without any Notifications</h3>
<p>There are <a href="https://www.trustpilot.com/review/disqus.com">some reviews</a> saying their websites are banned by Disqus for no reason.</p>
<h3>15. Users are banned for Political Opinions</h3>
<p>Freedom of speech is important. There are many converstaions going on regarding Disqus banning users (not moderators of websites but disqus admins) for just having political opinions.</p>
<h3>16. Disqus Exports your Data into a Messy XML Format</h3>
<p>If you ever need to import Disqus comments to your own database, you‚Äôll need more developer resources as Disqus imports the data into a messy XML format. </p>
<h3>17. Disqus adds ‚ÄúDo Not Sell My Data‚Äù Badge to your Website</h3>
<p>Do you like to have such irritating badge on your website?</p>
<figure><img src="https://talk.hyvor.com/blog/wp-content/uploads/2020/06/image-4.png" alt="Do not sell my data badge by Disqus" data-src="https://talk.hyvor.com/blog/wp-content/uploads/2020/06/image-4.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>Do not sell my data ‚Äì Disqus</figcaption></figure>
<p>There‚Äôs one more thing to consider: Those who don‚Äôt know this badge is placed by Disqus may think <strong>you (the publisher) are selling data</strong>. Want to destroy the trust between you and your visitors? If no is the answer, you‚Äôll definitely need to remove Disqus from your site and move to a new privacy-focused solution.</p>
<h3>18. Disqus has a Heavy Spam Detector</h3>
<p>Disqus‚Äôs spam detector is known to be harsh. It‚Äôs worst when non-spam comments are detected as spam. Again, destroying the trust between your users and you!</p>
<h3>19. Disqus Support is Poor</h3>
<p>Disqus <a href="https://disqus.com/home/channel/discussdisqus/discussion/channel-discussdisqus/poor_customer_support_from_disqus/best/">reportedly</a> has poor customer support. Moreover, it will be super hard to contact them if you have a problem to solve with your website. It will be impossible to do so if you are on their free plan.</p>
<h2>Moving Away from Disqus to Hyvor Talk</h2>
<p><a href="https://talk.hyvor.com/">Hyvor Talk</a>, a privacy-focused <a href="https://talk.hyvor.com/blog/disqus-alternatives/">Disqus alternative</a>, is created to solve all of those problems and help publishers to build thriving communities on their websites. Check out our <a href="https://talk.hyvor.com/documentation/import-export/importing/disqus">Disqus importing guide</a> to import your comments from Disqus to Hyvor Talk. It only requires a few clicks. Our automated system will do everything for you. </p>
<p>Hundreds of publishers have moved away from Disqus to Hyvor Talk to solve the above issue and make the comments section more user-friendly. <strong>We would like to see you be the next one. </strong></p>
<p>If you have any questions, feel free to comment below or contact us via our live chat.</p>
<div><div><div><h4>
About Hyvor Talk
</h4>
<p>
<a href="https://talk.hyvor.com/?utm_source=blog&amp;utm_medium=bottom_note" rel="nofollow">Hyvor Talk</a> is a privacy-focused alternative to Disqus. It comes with all moderation tools you need to build an amazing audience on your website. It is built to be beautiful and fully-customizable. You can control everything in one console. Try it for free now! ‚ù§
</p>

</div></div></div></div></div>]]>
            </description>
            <link>https://talk.hyvor.com/blog/move-away-from-disqus/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23903872</guid>
            <pubDate>Tue, 21 Jul 2020 02:38:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[‚ÄúHow could they be so stupid?‚Äù]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23903751">thread link</a>) | @azhenley
<br/>
July 20, 2020 | https://surfingcomplexity.blog/2020/07/20/how-could-they-be-so-stupid/ | <a href="https://web.archive.org/web/*/https://surfingcomplexity.blog/2020/07/20/how-could-they-be-so-stupid/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<figure><div>

</div></figure>



<p>From the <a href="https://www.nytimes.com/2020/07/17/technology/twitter-hackers-interview.html"> New York Times story on the recent Twitter hack</a>:</p>



<blockquote><p>Mr. O‚ÄôConnor said other hackers had informed him that Kirk got access to the Twitter credentials when he found a way into Twitter‚Äôs internal Slack messaging channel and saw them posted there, along with a service that gave him access to the company‚Äôs servers.&nbsp;</p></blockquote>



<p>It‚Äôs too soon after this incident to put too much faith in the reporting, but let‚Äôs assume it‚Äôs accurate. A collective cry of ‚Äú<em>Posting credentials to a Slack channel? How could engineers at Twitter be so stupid?</em>‚Äù rose up from the internet. It‚Äôs a natural reaction, but it‚Äôs not a constructive one.</p>



<p>I don‚Äôt personally know any engineers at Twitter, but I have confidence that they have excellent engineers over there, including excellent security folks. So, how do we explain this seemingly obvious security lapse?</p>



<p>The problem is that we on the outside can‚Äôt, because we don‚Äôt have enough information. This type of lapse is a classic example of a <em>workaround</em>. People in a system use workarounds (they do things the ‚Äú<em>wrong</em>‚Äù way) when there are obstacles to doing things the ‚Äúright‚Äù way.</p>



<p>There are countless possibilities for why people employ workarounds. Maybe some system that‚Äôs required for doing it the ‚Äúright‚Äù way is down for some reason, or maybe it simply takes too long or is too hard to do things the ‚Äúright‚Äù way. Combine that with production pressures, and a workaround is born.</p>



<p>I‚Äôm willing to bet that there are people in your organization that use workarounds. You probably use some yourself. Identifying those workarounds teaches us something about how the system works, and how people have to do things the ‚Äúwrong‚Äù way to actually get their work done.</p>



<p>Some workarounds, like the Twitter example, are dangerous. But simply observing ‚Äúthey shouldn‚Äôt have done that‚Äù does nothing to address the problems in the system that motivated the workaround in the first place.</p>



<p>When you see a workaround, don‚Äôt ask ‚Äúhow could they be so stupid to do things the obviously wrong way?‚Äù Instead, ask ‚Äúwhat are the properties of our system that contributed to the development of this workaround?‚Äù Because, unless you gain a deeper understanding of your system, the problems that motivated the workaround aren‚Äôt going to go away.</p>
	</div></div>]]>
            </description>
            <link>https://surfingcomplexity.blog/2020/07/20/how-could-they-be-so-stupid/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23903751</guid>
            <pubDate>Tue, 21 Jul 2020 02:10:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Essays on programming I think about a lot]]>
            </title>
            <description>
<![CDATA[
Score 274 | Comments 48 (<a href="https://news.ycombinator.com/item?id=23903737">thread link</a>) | @jchook
<br/>
July 20, 2020 | https://www.benkuhn.net/progessays/ | <a href="https://web.archive.org/web/*/https://www.benkuhn.net/progessays/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Every so often I read an essay that I end up thinking about, and citing in conversation, over and over again.</p><p>Here‚Äôs my index of all the ones of those I can remember! I‚Äôll try to keep it up to date as I think of more.</p><p>(Some of them are extremely well-known. I‚Äôm leaving them here anyway just in case you‚Äôre one of <a href="https://xkcd.com/1053/" target="_blank">the lucky 10,000</a>.)</p><p>I‚Äôm curious what essays are in this category for other folks‚Äîpost yours in the comments!</p><hr><p><a href="https://blog.nelhage.com/post/computers-can-be-understood/" target="_blank">Computers can be understood</a>:</p><blockquote><p>I approach software with a deep-seated belief that computers and software systems can be understood. ‚Ä¶</p><p>In some ways, this belief feels radical today. Modern software and hardware systems contain almost unimaginable complexity amongst many distinct layers, each building atop each other. ‚Ä¶</p><p>In the face of this complexity, it‚Äôs easy to assume that there‚Äôs just too much to learn, and to adopt the mental shorthand that the systems we work with are best treated as black boxes, not to be understood in any detail.</p><p>I argue against that approach. You will never understand every detail of the implementation of every level on that stack; but you can understand all of them to some level of abstraction, and any specific layer to essentially any depth necessary for any purpose.</p></blockquote><hr><p><a href="https://mcfunley.com/choose-boring-technology" target="_blank">Choose Boring Technology</a>:</p><blockquote><p>Let‚Äôs say every company gets about three innovation tokens. You can spend these however you want, but the supply is fixed for a long while. You might get a few more after you achieve a certain level of stability and maturity, but the general tendency is to overestimate the contents of your wallet. Clearly this model is approximate, but I think it helps.</p><p>If you choose to write your website in NodeJS, you just spent one of your innovation tokens. If you choose to use MongoDB, you just spent one of your innovation tokens. If you choose to use service discovery tech that‚Äôs existed for a year or less, you just spent one of your innovation tokens. If you choose to write your own database, oh god, you‚Äôre in trouble.</p></blockquote><hr><p><a href="https://www.sandimetz.com/blog/2016/1/20/the-wrong-abstraction" target="_blank">The Wrong Abstraction</a>:</p><blockquote><ol start="4"><li><p>Time passes.</p></li><li><p>A new requirement appears for which the current abstraction is almost perfect.</p></li><li><p>Programmer B gets tasked to implement this requirement.</p><p><em>Programmer B feels honor-bound to retain the existing abstraction, but since isn‚Äôt exactly the same for every case, they alter the code to take a parameter‚Ä¶.</em></p></li><li><p>‚Ä¶ Loop until code becomes incomprehensible.</p></li><li><p>You appear in the story about here, and your life takes a dramatic turn for the worse.</p></li></ol></blockquote><hr><p><a href="https://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/" target="_blank">Falsehoods Programmers Believe About Names</a>:</p><blockquote><ol start="32"><li>People‚Äôs names are assigned at birth.</li><li>OK, maybe not at birth, but at least pretty close to birth.</li><li>Alright, alright, within a year or so of birth.</li><li>Five years?</li><li>You‚Äôre kidding me, right?</li></ol></blockquote><hr><p><a href="https://sockpuppet.org/blog/2015/03/06/the-hiring-post/" target="_blank">The Hiring Post</a>:</p><blockquote><p>Nothing in Alex‚Äôs background offered a hint that this would happen. He had Walter White‚Äôs resume, but Heisenberg‚Äôs aptitude. None of us saw it coming. My name is Thomas Ptacek and I endorse this terrible pun. Alex was the one who nonced.</p><p>A few years ago, Matasano couldn‚Äôt have hired Alex, because we relied on interviews and resumes to hire. Then we made some changes, and became a machine that spotted and recruited people like Alex: line of business .NET developers at insurance companies who pulled Rails core CVEs out of their first hour looking at the code. Sysadmins who hardware-reversed assembly firmware for phone chipsets. Epiphany: the talent is out there, but you can‚Äôt find it on a resume.</p><p>Our field selects engineers using a process that is worse than reading chicken entrails. Like interviews, poultry intestine has little to tell you about whether to hire someone. But they‚Äôre a more pleasant eating experience than a lunch interview.</p></blockquote><hr><p><a href="https://blog.pragmaticengineer.com/the-product-minded-engineer/" target="_blank">The Product-Minded Engineer</a>:</p><blockquote><p>Proactive with product ideas/opinions ‚Ä¢ Interest in the business, user behavior and data on this ‚Ä¢ Curiosity and a keen interest in ‚Äúwhy?‚Äù ‚Ä¢ Strong communicators and great relationships with non-engineers ‚Ä¢ Offering product/engineering tradeoffs upfront ‚Ä¢ Pragmatic handling of edge cases ‚Ä¢ Quick product validation cycles ‚Ä¢ End-to-end product feature ownership ‚Ä¢ Strong product instincts through repeated cycles of learning</p></blockquote><hr><p><a href="https://programmingisterrible.com/post/139222674273/write-code-that-is-easy-to-delete-not-easy-to" target="_blank">Write code that is easy to delete, not easy to extend</a>:</p><blockquote><p>If we see ‚Äòlines of code‚Äô as ‚Äòlines spent‚Äô, then when we delete lines of code, we are lowering the cost of maintenance. Instead of building re-usable software, we should try to build disposable software.</p></blockquote><blockquote><p>Business logic is code characterised by a never ending series of edge cases and quick and dirty hacks. This is fine. I am ok with this. Other styles like ‚Äògame code‚Äô, or ‚Äòfounder code‚Äô are the same thing: cutting corners to save a considerable amount of time.</p><p>The reason? Sometimes it‚Äôs easier to delete one big mistake than try to delete 18 smaller interleaved mistakes. A lot of programming is exploratory, and it‚Äôs quicker to get it wrong a few times and iterate than think to get it right first time.</p></blockquote><hr><p><a href="https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/" target="_blank">The Law of Leaky Abstractions</a>:</p><blockquote><p>Back to TCP. Earlier for the sake of simplicity I told a little fib, and some of you have steam coming out of your ears by now because this fib is driving you crazy. I said that TCP guarantees that your message will arrive. It doesn‚Äôt, actually. If your pet snake has chewed through the network cable leading to your computer, and no IP packets can get through, then TCP can‚Äôt do anything about it and your message doesn‚Äôt arrive. If you were curt with the system administrators in your company and they punished you by plugging you into an overloaded hub, only some of your IP packets will get through, and TCP will work, but everything will be really slow.</p><p>This is what I call a leaky abstraction. TCP attempts to provide a complete abstraction of an underlying unreliable network, but sometimes, the network leaks through the abstraction and you feel the things that the abstraction can‚Äôt quite protect you from. This is but one example of what I‚Äôve dubbed the Law of Leaky Abstractions:</p><p><strong>All non-trivial abstractions, to some degree, are leaky.</strong></p><p>Abstractions fail. Sometimes a little, sometimes a lot. There‚Äôs leakage. Things go wrong. It happens all over the place when you have abstractions. Here are some examples.</p></blockquote><hr><p><a href="https://blog.nelhage.com/post/reflections-on-performance/" target="_blank">Reflections on software performance</a>:</p><blockquote><p>It‚Äôs probably fairly intuitive that users prefer faster software, and will have a better experience performing a given task if the tools are faster rather than slower.</p><p>What is perhaps less apparent is that having faster tools changes how users use a tool or perform a task. Users almost always have multiple strategies available to pursue a goal ‚Äî including deciding to work on something else entirely ‚Äî and they will choose to use faster tools more and more frequently. Fast tools don‚Äôt just allow users to accomplish tasks faster; they allow users to accomplish entirely new types of tasks, in entirely new ways. I‚Äôve seen this phenomenon clearly while working on both Sorbet and Livegrep:</p></blockquote><hr><p>Brandur Leach‚Äôs series on using databases to ensure correct edge-case behavior: <a href="https://brandur.org/acid" target="_blank">Building Robust Systems with ACID and Constraints</a>, <a href="https://brandur.org/http-transactions" target="_blank">Using Atomic Transactions to Power an Idempotent API</a>, <a href="https://brandur.org/job-drain" target="_blank">Transactionally Staged Job Drains in Postgres</a>, <a href="https://brandur.org/idempotency-keys" target="_blank">Implementing Stripe-like Idempotency Keys in Postgres</a>.</p><blockquote><p>I want to convince you that ACID databases are one of the most important tools in existence for ensuring maintainability and data correctness in big production systems. Lets start by digging into each of their namesake guarantees.</p></blockquote><blockquote><p>There‚Äôs a surprising symmetry between an HTTP request and a database‚Äôs transaction. Just like the transaction, an HTTP request is a transactional unit of work ‚Äì it‚Äôs got a clear beginning, end, and result. The client generally expects a request to execute atomically and will behave as if it will (although that of course varies based on implementation). Here we‚Äôll look at an example service to see how HTTP requests and transactions apply nicely to one another.</p></blockquote><blockquote><p>In APIs <em>idempotency</em> is a powerful concept. An idempotent endpoint is one that can be called any number of times while guaranteeing that the side effects will occur only once. In a messy world where clients and servers that may occasionally crash or have their connections drop partway through a request, it‚Äôs a huge help in making systems more robust to failure. Clients that are uncertain whether a request succeeded or failed can simply keep retrying it until they get a definitive response.</p></blockquote><hr><p><a href="https://www.somethingsimilar.com/2013/01/14/notes-on-distributed-systems-for-young-bloods/" target="_blank">Notes on Distributed Systems for Young Bloods</a>:</p><blockquote><p>Distributed systems are different because they fail often ‚Ä¢ Implement backpressure throughout your system ‚Ä¢ Find ways to be partially available ‚Ä¢ Use percentiles, not averages ‚Ä¢ Learn to estimate your capacity ‚Ä¢ Feature flags are how infrastructure is rolled out ‚Ä¢ Choose id spaces wisely ‚Ä¢ Writing cached data back to persistent storage is bad ‚Ä¢ Extract services.</p></blockquote><hr><p><a href="http://web.mit.edu/Saltzer/www/publications/endtoend/endtoend.pdf" target="_blank">End-to-End Arguments in System Design</a>:</p><blockquote><p>This paper presents a design principle that helps guide placement of functions among the modules of a distributed computer system. The principle, called the end-to-end argument, suggests that functions placed at low levels of a system may be redundant or of little value when compared with the cost of providing them at that low level. Examples discussed in the paper include bit error recovery, security using encryption, duplicate message suppression, recovery from system crashes, and delivery acknowledgement. Low level mechanisms to support these functions are justified only as performance enhancements.</p></blockquote><hr><p><a href="https://vimeo.com/36579366" target="_blank">Inventing on Principle</a>:</p><blockquote><p>I‚Äôve spent a lot of time over the years making creative tools, using creative tools, thinking about them a lot, and here‚Äôs something I‚Äôve come to believe: Creators need an immediate connection to what they‚Äôre creating.</p></blockquote><p>I can‚Äôt really excerpt any of the actual demos, which are the good part. Instead I‚Äôll just endorse it: this talk dramatically, and productively, raised my bar for what I think programming tools (and tools in general) can be. Watch it and be amazed.</p><hr><p>Post the essays you keep returning to in the comments!</p></article></div>]]>
            </description>
            <link>https://www.benkuhn.net/progessays/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23903737</guid>
            <pubDate>Tue, 21 Jul 2020 02:07:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A nicer 4-bit colour than RGBI without fancy logic]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23903733">thread link</a>) | @Lerc
<br/>
July 20, 2020 | https://blag.fingswotidun.com/2020/07/a-nicer-4-bit-colour-withhout-fancy.html | <a href="https://web.archive.org/web/*/https://blag.fingswotidun.com/2020/07/a-nicer-4-bit-colour-withhout-fancy.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-265000198519564201" itemprop="description articleBody">
<p> 

In the last few years there has been quite a lot of activity in homebrew Retro-computing.  I really liked seeing things like the <a href="https://www.linusakesson.net/scene/craft/">Craft Demo</a>, the <a href="http://belogic.com/uzebox/index.asp">UzeBox</a>, The <a href="https://gigatron.io/">Gigatron</a> and <a href="https://eater.net/">Ben Eater's</a> amazing work in making all of this stuff accessible to mere mortals.  There are a lot of toy projects out there generating video signals, sometimes composite, sometimes VGA occasionally something more exotic.   This has inspired me to address something that has bugged me for a long long time in the hope that people might want do do some 4 bit digital output to generate a 16 colour palette that isn't completely hideous.</p>

<h3>Here's the problem </h3><p>

This is the original CGA palette.  Known as RGBI, four digital lines for Red, Green, Blue, and Intensity.  it looks like this 
</p><center><table>
  <tbody><tr>
    <td> Black </td>
    <td> Red </td>
    <td> Green </td>
    <td> Dry Snot</td>
  </tr>  
  <tr>
    <td> Blue </td>
    <td> Sad Magenta </td>
    <td> Sad Cyan </td>
    <td> Light Grey</td>
  </tr>  

  <tr>
    <td> Dark Grey </td>
    <td> Light Red </td>
    <td> Light Green </td>
    <td> Yellow</td>
  </tr>  
  <tr>
    <td> Liht Blue </td>
    <td> Magenta</td>
    <td> Cyan </td>
    <td> White</td>
  </tr>  
  </tbody><caption>The Beauty that is RGBI.</caption>  
  </table>
  </center><p>
  
This arrangement of colours is somewhat unappealing.    To mitigate the worst of this a special case was introduced on the low intensity yellow colour where they halved the green brightness for that one colour.
This was a change to the monitors, not the video card, which strictly speaking had no concept of colour and merely output signals on 4 digital wires..
  

</p><center>
    <table>
  <tbody><tr>
    <td> Black </td>
    <td> Red </td>
    <td> Green </td>
    <td> Brown</td>
  </tr>  
  <tr><td> Blue </td>
    <td> Sad Magenta </td>
    <td> Sad Cyan </td>
    <td> Light Grey</td>
  </tr>  

  <tr>
    <td> Dark Grey </td>
    <td> Light Red </td>
    <td> Light Green </td>
    <td> Yellow</td>
  </tr>  
  <tr>
    <td> Liht Blue </td>
    <td> Magenta</td>
    <td> Cyan </td>
    <td> White</td>
  </tr>  
  </tbody><caption>  Much better, right, let's go to the pub.</caption>
  </table>
  </center><p>

 
This addition of brown helped a great deal, especially if you wanted wood <br></p><p><a href="https://1.bp.blogspot.com/-eQbeZOWqd-s/XxTxn7TDS6I/AAAAAAAAAbU/h8kz0vqfepQLAlF26mCpgbgm7NJYKsO_wCLcBGAsYHQ/s640/Keen4.gif"><img data-original-height="400" data-original-width="640" height="313" src="https://1.bp.blogspot.com/-eQbeZOWqd-s/XxTxn7TDS6I/AAAAAAAAAbU/h8kz0vqfepQLAlF26mCpgbgm7NJYKsO_wCLcBGAsYHQ/w500-h313/Keen4.gif" width="500"></a></p><p><a href="https://1.bp.blogspot.com/-IZWXYXHetGY/XxTxwh4gC1I/AAAAAAAAAbY/6zlO7dAxq5gpL-tb-gx-MMjELlsHBfzlwCLcBGAsYHQ/s640/Keen8.gif"><img data-original-height="400" data-original-width="640" height="313" src="https://1.bp.blogspot.com/-IZWXYXHetGY/XxTxwh4gC1I/AAAAAAAAAbY/6zlO7dAxq5gpL-tb-gx-MMjELlsHBfzlwCLcBGAsYHQ/w500-h313/Keen8.gif" width="500"></a></p><p><a href="https://1.bp.blogspot.com/-Ge4w2gcgU8g/XxTx7LokUaI/AAAAAAAAAbg/Mk6P0X1Jk8kbrmZnmo4qSmg523zWLFRBQCLcBGAsYHQ/s740/the-colonels-bequest-1989_kf57.1080.jpg"><img data-original-height="555" data-original-width="740" height="375" src="https://1.bp.blogspot.com/-Ge4w2gcgU8g/XxTx7LokUaI/AAAAAAAAAbg/Mk6P0X1Jk8kbrmZnmo4qSmg523zWLFRBQCLcBGAsYHQ/w500-h375/the-colonels-bequest-1989_kf57.1080.jpg" width="500"></a></p><p>


People managed to do quite a bit with that set but it wasn't an ideal arrangement.  When I look at homebrew video generators I can't help but think that there is a tendency to go with six or eight digital lines because four digital lines brings memory of this palette.    I wanted to know how much better you could make four digital lines without adding too much complexity.</p><h3>How did RGBI work anyway</h3><p>  
For starters lets look at an RGBI output mechanism.</p><p><a href="https://1.bp.blogspot.com/-rUu08JAtrqY/XxTv8IJswgI/AAAAAAAAAa0/QAuDa5Z6UoAYt9X05-qA4HCvd43R7jkXQCLcBGAsYHQ/s929/Marcel%2Bhackaday%2Brgbi.png"><img data-original-height="522" data-original-width="929" height="351" src="https://1.bp.blogspot.com/-rUu08JAtrqY/XxTv8IJswgI/AAAAAAAAAa0/QAuDa5Z6UoAYt9X05-qA4HCvd43R7jkXQCLcBGAsYHQ/w625-h351/Marcel%2Bhackaday%2Brgbi.png" width="625"></a></p><p>

This circuit is designed to convert four digital 5V lines coming in at the bottom to three analog signals for Red, Green and Blue.  This particular one places the Analog signals into the 0.0V - 0.7V range of a 75 Ohm VGA input.   The intensity line on the right contributes to each of the red green and blue lines evenly to make all levels brighter.  The diodes on the right prevent the original Red, Green, and Blue signals from  crossing over into the other channels.   Those diodes are not strictly necessary though, we are aiming for a visual representation, not mathematical accuracy. </p><h3>Let's do the dumbed down version</h3>
<p><a href="https://1.bp.blogspot.com/-8nOaxU1nrSE/XxT0WWgkTsI/AAAAAAAAAcM/BYj31WTzBYkL0Z8SoLlnUXaWLkdyO9B-ACLcBGAsYHQ/s932/Marcel%2Bhackaday%2Brgbi%2B-%2Bno%2Bdiodes.png"><img data-original-height="446" data-original-width="932" height="299" src="https://1.bp.blogspot.com/-8nOaxU1nrSE/XxT0WWgkTsI/AAAAAAAAAcM/BYj31WTzBYkL0Z8SoLlnUXaWLkdyO9B-ACLcBGAsYHQ/w625-h299/Marcel%2Bhackaday%2Brgbi%2B-%2Bno%2Bdiodes.png" width="625"></a></p><p>

This arrangement eliminates the diodes. This means that when the Red line is on a small amount of current can travel back through the intensity resistors and onto the Blue and Green lines.  Running the numbers shows it's not really a problem though because the voltage is already dropped fairly low and has to go through another two resistors to get out one of the other lanes.  When the any one the RGB lines provides 0.3V a sneaky 0.01V slips through to the other two.  When two of the RGB lines are high the remaining one receives an extra 0.02V which isn't noticeable.</p><h3>Now mix things up</h3><p>  
To come up with a better arrangement, the plan was to introduce some asymmetry in the resistors to see what colours would come out.  I still wanted all lines High to provide white and all lines Low to be Black.  The rule of thumb is that if I drop the resistance on one of the colour lines I should correspondingly increase the resistance on the intensity line that contributes to that colour.  </p><p>

In this sense you would represent the traditional RGBI as
</p>
<center>
<table>
  <tbody><tr><th> Output line </th> <th>Color Resistor</th> <th> Intensity Resistor</th> </tr>
  <tr> <td> Red </td> <td> High </td> <td> Low </td> </tr>
  <tr> <td> Green </td> <td> High </td> <td> Low </td> </tr>
  <tr> <td> Blue </td> <td> High </td> <td> Low </td> </tr>
</tbody></table>
</center>
<p>
These are not merely boolean options, a range of medium values are available.  You have a restriction that no output combination should produce a voltage higher than 0.7V on any line.  Additionally if you want to have a white, you need to have a set of resisters that provide 0.7V on all three RGB lines when all of the input lines are high.  Initially i tried an arrangement something like this.</p><center>
<table>
  <tbody><tr><th> Output line </th> <th>Color Resistor</th> <th> Intensity Resistor</th> </tr>
  <tr> <td> Red </td> <td> Low </td> <td> High </td> </tr>
  <tr> <td> Green </td> <td> Medium </td> <td> Medium </td> </tr>
  <tr> <td> Blue </td> <td> High </td> <td> Low </td> </tr>
</tbody></table>
</center>

<h3>A hint of lane crossing</h3><p>
I did some quick calculations on the colors and, while better,  I felt that the problem areas of the original RGBI system remained.  A good brown needs more Red than Green   So I tried shunting a little green over to red. After more tweaking and fiddling I decided to do the same with blue shunting to green and came up with 

</p><p><a href="https://1.bp.blogspot.com/-AON7kUcR8tA/XxUAI7w6agI/AAAAAAAAAco/7AiKXLcmJs4ggCO2KNb05MmEVhbi1CMOgCLcBGAsYHQ/s960/Rgbi-alt.png"><img data-original-height="519" data-original-width="960" height="338" src="https://1.bp.blogspot.com/-AON7kUcR8tA/XxUAI7w6agI/AAAAAAAAAco/7AiKXLcmJs4ggCO2KNb05MmEVhbi1CMOgCLcBGAsYHQ/w625-h338/Rgbi-alt.png" width="625"></a></p><div>

  <h3>What should that look like?</h3><p> 
In theory the voltages produced by this arrangement of resistors should produce a palette something like this.</p><center><table>
  <tbody><tr>
    <td> Black </td>
    <td> Red </td>
    <td> Green </td>
    <td> Brown</td>
  </tr>  
  <tr>
    <td> Dark Blue </td>
    <td> Purple </td>
    <td> Sea Green</td>
    <td> Pale Brown</td>
  </tr>  

  <tr>
   <td>Steel Blue</td>
    <td> Blush</td>
    <td> Leaf Green </td>
    <td> Yellow</td>
  </tr>  
  <tr>
    <td> Denim Blue </td>
    <td> Mauve</td>
    <td> Cyan </td>
    <td> White</td>
  </tr>  
  </tbody><caption>A theoretically better palette.</caption>
  
  </table>
  </center>
<p>
To me, that looks like a better set of colors.  We now have two tones of brown. The yellow is less intense, and stab-your-eyes magenta has been mellowed to a mauve. Sad magenta has been shifted over slightly to be a purple.  Sad cyan is now greener for a nice sea green. The pure greys are gone and replaced with pale colours. I'm rather happy with it.  
</p></div>

<h3>What does it actually look like?</h3>
<div><p>
Of course this doesn't mean anything unless i can actually get it working.   I wrote a small Arduino program to throw out some VGA 640x480 timings and a simple test pattern and put the resistor arrangement on a piece of breadboard.  I'm not well equipped when it comes to actually making things. So my creation was a bit of a Frankenstein's monster of what resisters I had lying about wired in combinations to make values close to what I needed.</p><p>
 In the end I got the Arduino outputting a signal that resembled VGA enough for a monitor to display it. <br></p></div><p><a href="https://1.bp.blogspot.com/-iNIIxmM1ASk/XxUvURltVPI/AAAAAAAAAdE/QN4ufc1rsGIMiCjWU65dJU8CAZTEipp2gCLcBGAsYHQ/s800/IMG_20200720_173606.jpg"><img data-original-height="745" data-original-width="800" height="583" src="https://1.bp.blogspot.com/-iNIIxmM1ASk/XxUvURltVPI/AAAAAAAAAdE/QN4ufc1rsGIMiCjWU65dJU8CAZTEipp2gCLcBGAsYHQ/w625-h583/IMG_20200720_173606.jpg" width="625"></a></p>
  <div><p>
  I was actually pretty chuffed to get colours that close to what I had calculated.       The stripes on the side a a series of 1,2,3 and 4 clock cycle bands.   Because the monitor is expecting 640x480 the digital nature of the LCD is quantizing to make the thinner bars uneven.  I'm a little torn between the simplicity of getting picture out of a plain Arduino or going for a 25.175MHz clocked chip and seeing what I can get it to do.</p></div>
  <p>
    Today's objective is however complete. Giving a better set of 4 bit colours hopefully will be of use to someone and inspire them to make some cool things with hardware that was never meant for that purpose.   At two pixels per byte there is less data to move around so potentially allowing for new things.  I already have a few ideas.  A 74LS157 would fairly easily handle turning a byte into two pixels. leaving more time for fetching the pixels in exotic manners.  An Arduino would probably use a 74LS158 and a 74LS04 because of the creatively inverted outputs on PORTD. <br></p>

<center>
<a href="https://1.bp.blogspot.com/-DWpcVQYI88c/XxVjgPur8eI/AAAAAAAAAdg/40I5nUrBOjU50RgZ29HNiF9Swez-j0mVgCLcBGAsYHQ/s2048/IMG_20200720_152429.jpg"><img data-original-height="1634" data-original-width="2048" height="499" src="https://1.bp.blogspot.com/-DWpcVQYI88c/XxVjgPur8eI/AAAAAAAAAdg/40I5nUrBOjU50RgZ29HNiF9Swez-j0mVgCLcBGAsYHQ/w625-h499/IMG_20200720_152429.jpg" width="625"></a><br>I'm not exactly Ben Eater level.</center>
  
  

</div></div>]]>
            </description>
            <link>https://blag.fingswotidun.com/2020/07/a-nicer-4-bit-colour-withhout-fancy.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23903733</guid>
            <pubDate>Tue, 21 Jul 2020 02:06:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Uber's Fiber: Distributed Computing for AI Made Simple]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23903709">thread link</a>) | @xiaodai
<br/>
July 20, 2020 | https://uber.github.io/fiber/introduction/ | <a href="https://web.archive.org/web/*/https://uber.github.io/fiber/introduction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        
      
      
      <main role="main">
        <div data-md-component="container">
          
            
              
            
            
              
            
          
          <div>
            <article>
              
                
                  <a href="https://github.com/uber/fiber/edit/master/mkdocs/introduction.md" title="Edit this page">Óèâ</a>
                
                
                  
                
                <h3>Distributed Computing for AI Made Simple</h3>

<p>Jiale Zhi, Rui Wang, Jeff Clune and Kenneth O. Stanley</p>
<p><img alt="fiber illustration" src="https://uber.github.io/fiber/img/fiber_illustration.png"></p>
<p><sup>Fiber - Distributed Computing for AI Made Simple. Icon by <a href="https://designmodo.com/">Flat UI
Kit</a>.</sup></p>
<p><em>Project Homepage:</em>
<a href="https://github.com/uber/fiber">GitHub</a></p>
<p>Recent advances in machine learning are consistently enabled by
<a href="https://openai.com/blog/ai-and-compute/">increasing amounts of
computation</a>. More
and more algorithms exploit parallelism and rely on distributed training
for processing an enormous amount of data. Both the need for more data
and more training impose great challenges on the software that manages
and utilizes the large scale computational resource.</p>
<p>Within Uber, we've developed algorithms like
<a href="https://eng.uber.com/poet-open-ended-deep-learning/">POET</a>,
<a href="https://eng.uber.com/go-explore/">Go-Explore</a>,
<a href="https://eng.uber.com/generative-teaching-networks/">GTN</a>,
etc., that leverage a large amount of computation. To enable future
generations of large-scale computation for algorithms like these, we
have developed a new system called <strong>Fiber</strong> that helps users scale what
might otherwise be only local computation to hundreds or even thousands
of machines with ease.</p>
<h3 id="the-challenge-of-large-scale-distributed-computation">The challenge of large-scale distributed computation<a href="#the-challenge-of-large-scale-distributed-computation" title="Permanent link">¬∂</a></h3>
<p>In an ideal world, scaling an application that runs on one machine to an
application that runs on a cluster of machines should be as easy as
changing a command-line argument. However, that is not an easy task in
the real world.</p>
<p>While working with many people who run large scale distributed computing
jobs on a daily basis, we found that there are several reasons why it is
so hard to harness distributed computing nowadays:</p>
<ul>
<li>
<p><strong>There is a huge gap between making code work locally on laptops or
    desktops and running code on a production cluster.</strong> You can make
    MPI work locally but it's a completely different process to run
    it on a computer cluster.</p>
</li>
<li>
<p><strong>No dynamic scaling is available.</strong> If you launch a job that
    requires a large amount of resources, then most likely you'll
    need to wait until everything is allocated before you can run your
    job. This waiting to scale up makes it less efficient.</p>
</li>
<li>
<p><strong>Error handling is missing.</strong> While running, some jobs may fail.
    And you may be put into a very nasty situation where you have to
    recover part of the result or discard the whole run.</p>
</li>
<li>
<p><strong>High learning cost.</strong> Each system has different APIs and
    conventions for programming. To launch jobs with a new system, a
    user has to learn a set of completely new conventions before jobs
    can be launched.</p>
</li>
</ul>
<p>The new Fiber platform addresses each of these issues explicitly,
potentially opening up seamless large-scale distributed computing to a
much wider population of users.</p>
<h3 id="introducing-fiber">Introducing Fiber<a href="#introducing-fiber" title="Permanent link">¬∂</a></h3>
<p><a href="https://github.com/uber/fiber">Fiber</a> is a Python-based
distributed computing library for modern computer clusters. Instead of
programming your desktop or laptop, now you can program the whole
computer cluster. Originally, it was developed to power large scale
parallel scientific computation projects like
<a href="https://eng.uber.com/poet-open-ended-deep-learning/">POET</a>
and it has been used to power similar projects within Uber. The key
features of Fiber include:</p>
<ul>
<li>
<p><strong>Easy to use.</strong> Fiber allows you to write programs that run on a
    computer cluster without the need to dive into the details of the
    computer cluster.</p>
</li>
<li>
<p><strong>Easy to learn.</strong> Fiber provides the same API as Python's standard
    <a href="https://docs.python.org/3.6/library/multiprocessing.html">multiprocessing</a>
    library that people are familiar with. If you know how to use
    multiprocessing, you can program a computer cluster with Fiber.</p>
</li>
<li>
<p><strong>Fast performance.</strong> Fiber's communication backbone is built on
    top of <a href="https://nanomsg.org/">Nanomsg</a>, which is a
    high-performance asynchronous messaging library to allow fast and
    reliable communication.</p>
</li>
<li>
<p><strong>No need for deployment.</strong> You run Fiber application the same way
    as running a normal application on a computer cluster and Fiber
    handles the rest for you.</p>
</li>
<li>
<p><strong>Reliable computation.</strong> Fiber has built-in error handling when you
    are running a pool of workers. Users can focus on writing the
    actual application code instead of dealing with crashed workers.</p>
</li>
</ul>
<p>In addition, Fiber can be used together with other specialized
frameworks in areas where performance is critical. Examples include
distributed SGD where many existing frameworks like
<a href="https://github.com/horovod/horovod">Horovod</a> or
<a href="https://pytorch.org/docs/stable/distributed.html">torch.distributed</a>
have already provided very good solutions. Fiber can be used together
with such platforms by using Fiber's <a href="https://uber.github.io/fiber/experimental/ring/">Ring
feature</a>
to help to set up a distributed training job on computer clusters.</p>
<p><img alt="fiber_overview" src="https://uber.github.io/fiber/img/fiber_overview.png"></p>
<p><strong>Figure 1: Fiber overview.</strong> The diagram shows how Fiber works on a
computer cluster. It starts many different job-backed-processes and runs
different Fiber components and user processes inside them. Fiber Master
is the main process that manages all the other processes. Some processes
like Ring Node maintain communications between each member.</p>
<p>Fiber can (1) help users who are working on large-scale distributed
computing to reduce the time to go from ideas to actually running
distributed jobs on computation clusters, (2) shield users from details
of configuration and resource allocation tasks, (3) enable faster debug
cycles, and (4) simplify the transition from local to cluster
development.</p>
<h3 id="architecture">Architecture<a href="#architecture" title="Permanent link">¬∂</a></h3>
<p>Fiber bridges the classical multiprocessing API with a flexible
selection of backends that can run on different cluster management
systems. To achieve this integration, Fiber is split into three
different layers: the <strong>API layer</strong>, <strong>backend layer</strong> and <strong>cluster
layer</strong>. The <strong>API layer</strong> provides basic building blocks for Fiber like
processes, queues, pools and managers. They have the same semantics as
in multiprocessing, but are extended to work in distributed
environments. The <strong>backend layer</strong> handles tasks like creating or
terminating jobs on different cluster managers. When a new backend is
added, all the other Fiber components (queues, pools, etc.) do not need
to be changed. Finally, the <strong>cluster layer</strong> consists of different
cluster managers. Although they are not a part of Fiber itself, they
help Fiber to manage resources and keep track of different jobs, thereby
reducing the number of items that Fiber needs to track. This overall
architecture is summarized in figure 2.</p>
<p><img alt="fiber_architecture" src="https://uber.github.io/fiber/img/fiber_architecture.png"></p>
<p><strong>Figure 2: Fiber architecture.</strong></p>
<h3 id="job-backed-process">Job-Backed Process<a href="#job-backed-process" title="Permanent link">¬∂</a></h3>
<p>Fiber introduces a new concept called <em>job-backed processes</em> (also
called a <em>Fiber process</em>). It is similar to the <em>process</em> in Python's
multiprocessing library, but more flexible: while a process in
multiprocessing only runs on a local machine, a Fiber process can run
remotely on a different machine or locally on the same machine. When
starting a new Fiber process, Fiber creates a new job with the proper
Fiber backend on the current computer cluster.</p>
<p><img alt="fiber_process" src="https://uber.github.io/fiber/img/fiber_process.png"></p>
<p><strong>Figure 3: Job-backed processes.</strong> Each job-backed process is a
containerized job running on the computer cluster. Each job-backed
process will also have its own allocation of CPU, GPU and other types of
resources. The code that runs inside the container is self-contained.</p>
<p>Fiber uses containers to encapsulate the running environment of current
processes, including all the required files, input data, other dependent
program packages, etc., to ensure everything is self-contained. All the
child processes are started with the same container image as the parent
process to guarantee a consistent running environment. Because each
process is a cluster job, its life cycle is the same as any job on the
cluster. To make it easy for users, Fiber is designed to directly
interact with computer cluster managers. Because of this, Fiber doesn't
need to be set up on multiple machines or bootstrapped by any other
mechanisms, unlike Spark or IPyParallel. It only needs to be installed
on a single machine as a normal Python pip package.</p>
<h3 id="components">Components<a href="#components" title="Permanent link">¬∂</a></h3>
<p>Fiber implements most multiprocessing APIs on top of Fiber processes
including pipes, queues, pools, and managers.</p>
<p><em>Queues and pipes</em> in Fiber behave the same as in multiprocessing. The
difference is that queues and pipes are now shared by multiple processes
running on different machines. Two processes can read from and write to
the same pipe. Furthermore, queues can be shared among many processes on
different machines and each process can send to or receive from the same
queue at the same time. Fiber's queue is implemented with Nanomsg, a
high-performance asynchronous message queue system.</p>
<p><img alt="fiber_queue" src="https://uber.github.io/fiber/img/fiber_queue.png"></p>
<p><strong>Figure 4: Fiber Queue.</strong> This diagram shows a Fiber queue shared
across three different Fiber processes. One Fiber process is located on
the same machine as the queue and the other two processes are located on
another machine. One process is writing to the queue and the other two
are reading from the queue.</p>
<p><em>Pools</em> are also supported by Fiber. They allow the user to manage a
pool of worker processes. Fiber extends pools with <em>job-backed
processes</em> so that it can manage thousands of (remote) workers per pool.
Users can also create multiple pools at the same time.</p>
<p><img alt="fiber_pool" src="https://uber.github.io/fiber/img/fiber_pool.png"></p>
<p><strong>Figure 5: Fiber Pool.</strong> A pool with 3 workers is shown. Two of them
are located on one machine and the other is located on a different
machine. They collectively work on tasks that are submitted to the task
queue in the master process and send results to the result queue.</p>
<p><em>Managers and proxy objects</em> enable Fiber to support shared storage,
which is critical to distributed systems. Usually, this function is
handled by external storage like Cassandra, Redis, etc. on a computer
cluster. Fiber instead provides built-in in-memory storage for
applications to use. The interface is the same as multiprocessing's
Manager type.</p>
<p><em>Rings</em> are an extension to the multiprocessing API that can be helpful
in distributed computing settings. A ring in Fiber stands for a group of
processes who work collectively together as relative equals. Unlike
<code>Pool</code>, <code>Ring</code> does not have the concept of a master process and
worker processes. All the members inside the <code>Ring</code> share about the
same responsibility. Fiber's Ring models a topology that is very common
in machine learning when doing <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">distributed
SGD</a>.
Examples ‚Ä¶</p></article></div></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://uber.github.io/fiber/introduction/">https://uber.github.io/fiber/introduction/</a></em></p>]]>
            </description>
            <link>https://uber.github.io/fiber/introduction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23903709</guid>
            <pubDate>Tue, 21 Jul 2020 01:59:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Export your Facebook status posts to a searchable personal journal]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23903665">thread link</a>) | @soneca
<br/>
July 20, 2020 | https://blog.quidsentio.com/posts/export-your-facebook-status-posts-to-a-searchable-personal-journal/ | <a href="https://web.archive.org/web/*/https://blog.quidsentio.com/posts/export-your-facebook-status-posts-to-a-searchable-personal-journal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>
    At this point, we are not as fond of Facebook as we used to be. We mostly
    are just not that active anymore, abandoned entirely, or even considering
    deleting our accounts. Something is holding us still, though; we have part
    of our history there. On each "status update", we registered a moment, those
    posts add up to document years of our lives.
</p>

<p>
    Even if you want to keep your Facebook account to save these memories,
    they are hidden from you by Facebook's newsfeed algorithm. Facebook
    decides which of your memories to surface, not you, and it is very
    cumbersome to search for them. If you want to move out of Facebook, but
    keep your Facebook history and gain the ability to search your old posts
    quickly, Quid Sentio can solve your problem.
</p>

<h3>Understanding Quid Sentio</h3>
<p>
	If you are not familiar with Quid Sentio yet, it is a digital personal
	journal that you can share with your real friends. Using text, audio, and
	custom tags, you create private entries, with an easy way to filter and
	search, and the ability to share and comment with trusted friends (real
	friends, not the ones that are your "facebook friends").
</p>
<p>
	Quid Sentio has an import tool for Facebook status updates posts. First, you
	have to export and download your data from your Facebook account, then
	upload that file to Quid Sentio, and all your status updates become
	searchable journal entries.
</p>

<h2>How to export your Facebook posts</h2>

<p>
	The first thing to do is to download a file from Facebook with all your posts. Here
	is a step-by-step tutorial on how to do it.
</p>

<p><em>Note: the screenshots presented here are from the new Facebook interface.
If your Facebook still has the old design, it might look different, but
the options are largely the same (or very similar). You should be able to follow
these steps without any issue.</em></p>

<h4>1. Go to your Facebook settings</h4>

<p>At the top right, click on the down arrow to open the menu. Select
<em>"Settings &amp; Privacy"</em> and then again <em>"Settings"</em>.</p>

<p><img src="https://blog.quidsentio.com/img/fb-menu.png" alt="Facebook menu, Settings &amp; Privacy option">
<img src="https://blog.quidsentio.com/img/fb-menu-2.png" alt="Facebook menu, Settings option"></p><h4>2. Select "Your Facebook Information" and "Download Your Information"</h4>

<p><em>Note: Quid Sentio is prepared to identify the Facebook information structure
when it's written in English. If you use Facebook in another language, I suggest
you change it to English before exporting your posts (it is ok for the posts
themselves to be in another language).</em></p>

<p>
	In the Settings page, select the option
	<em>"Your Facebook Information"</em> on the left side menu.
</p>

<p>
	Then, among the presented options, click on
	<em>"Download Your Information"</em>.
</p>

<p><img src="https://blog.quidsentio.com/img/fb-settings.png" alt="Facebook Settings page"></p><h4>3. Choose the format "JSON" and select "Posts" data to download</h4>

<p>You will see a box with download options. You must choose the format
<em>"JSON"</em>, so Quid Sentio can import your posts.</p>

<p>You can also decide which information you want to download. Quid Sentio will only
use <em>"Posts"</em>, but the information will be downloaded in separate files,
so you can choose as many as you want.</p>

<p>After selecting the <em>format: "JSON"</em> and <em>"Posts"</em>, click on the
button <em>"Create File"</em>.</p>

<p><img src="https://blog.quidsentio.com/img/fb-download-select.png" alt="Facebook Information Download options"></p><h4>4. Wait until your file is available and download it</h4>

<p>You can't download your information immediately; Facebook has to process your
request. You will receive an email informing you that they are processing the
request and another email as soon as the request is processed and ready for
download.
</p>

<p>
    If you selected only the <em>"Posts"</em> type of information, it would
    usually take no more than 5 minutes. It might take longer if you selected more
    types of information.
</p>



<p>Once your file is ready, go back to the same page (<em>Settings &gt; Your
Facebook Information &gt; Download Your Information</em>). There, click on the tab
<em>"Available Copies"</em> and click on the <em>"Download"</em> button of the file
listed there.</p>

<p><img src="https://blog.quidsentio.com/img/fb-file-ready.png" alt="Facebook Information file ready to
download"></p><p>You will download a compressed ZIP file (ending in <code>.zip</code>) with
separate folders for each type of information that you selected to download. The
file with your posts is usually called <code>your_posts_1.json</code>. Extract this
file from the ZIP file.</p>

<p>Now you have your file with all your Facebook posts downloaded at your
computer. You are ready to import them to your Quid Sentio journal.</p>

<h4>5. Create your Quid Sentio account and upload your posts file</h4>

<p>Now the easy part. Go to <a href="https://www.quidsentio.com/" target="_blank">www.quidsentio.com</a> and Sign Up.</p>

<p>Then click on <em>"Account"</em> at the top right, and you will see the button
to <em>"Upload your posts .json file"</em>. Click on it and select the file you
just downloaded from Facebook with your posts (the one probably called
<code>your_posts_1.json</code>).</p>

<p>You will see how many status updates posts you have and show the button to
<em>"Start import process"</em>. Click on it and see the count of imported posts
going up. Please do not close the site or refresh the page until it finishes its
process.</p>

<p><img src="https://blog.quidsentio.com/img/qs-account.png" alt="Facebook Information file ready to
download">

<img src="https://blog.quidsentio.com/img/qs-import.png" alt="Facebook Information file ready to
download"></p><p>That's it! You have now transformed all your Facebook status updates into
Quid Sentio journal entries. Experiment a little bit searching through your
older updates and explore your past in a way that Facebook never allowed!</p>

<h2><strong>Why</strong> transfer your posts from Facebook to Quid
Sentio?</h2>

<p>You know how to do it, but you might be wondering why do it. Here is a list
of a few advantages of having your Facebook update posts on Quid Sentio:</p>

<ul>
    <li>
        You can search and filter your posts.<br>
        Quid Sentio clearly shows all your old posts, with easy ways to filter
        by keywords, also allowing you to add custom tags for future reference.
    </li>
    <br>
    <li>
        You will not be tracked or manipulated to addiction at Quid Sentio.<br>
        Quid Sentio is not supported by ads, so there is no need to track your
        every move nor use every trick in the book to keep you mindlessly
        scrolling. Quid Sentio does not use any third-party client-side tracking.
    </li>
    <br>
    <li>
        You will have better control over your privacy.<br>
        Every entry (including the imported ones) is visible only to you by
        default. You can add real friends to your Quid Sentio network and
        individually decide for each entry who can read it. There
        is no way to search for people at Quid Sentio. You will have only
        the people you manually added as your friends.
    </li>
</ul>

<h3>A few disclaimers</h3>

<p>In case you are new to Quid Sentio, there are a few things that are important
for you to know before deciding to import your Facebook posts.</p>

<p>You will only import your Facebook Status updates posts. The downloaded "Posts"
file includes lots of other types of posts that are not status updates. Things
like posts on your friends' timelines, posts on groups, on events. Those things
do not match the format of journal entries, so all of those are ignored. Just
your status updates are imported as Quid Sentio entries.</p>

<p>You will not import your Facebook pictures. While Quid Sentio entries allow for
images, it is a very different experience from Facebook with its
albums. You are better off downloading Facebook pictures and keeping at your
computer or another photo service of your choice.</p>

<p>You will not import your Facebook "friends". Quid Sentio meaning of "friends"
is very different from Facebook's. I believe you should add friends to your Quid
Sentio network very consciously, adding only those you really trust. I designed
Quid Sentio to avoid "contact spam" of any form. So I will not ask or even allow
you to upload your list of friends to Quid Sentio. You have to add them one by
one.</p>

<p>Quid Sentio is a paid service, not supported by ads, but by customers that
pay for it if they find it valuable. While you can create an account for free and
import all your Facebook status posts also for free, after that, you will have
become a Supporter ($19/year) to be able to create more entries.</p>

<p>Just to be clear, you can import your posts and leave them at Quid Sentio for
free. Only if you want to continue to create new entries that you need to become
a paying supporter.</p>

<p>Quid Sentio still does not have an export tool of its own. I do believe
everyone should have control of all the data they update to an online service.
The only reason Quid Sentio does not have this feature is that I am the sole
developer of Quid Sentio, so things are a bit slow to build. The export tool is
on the roadmap, so rest assured that by the time you sign up to Quid Sentio,
create a few entries, and decide to move out to another service and export your
data, it will  be ready.</p>

<h4>If after importing your Facebook posts you want to start journaling
regularly, check our guide:</h4>

<p><a href="https://blog.quidsentio.com/posts/a-guide-to-start-journaling/">How to start journaling</a> 

</p></div></div>]]>
            </description>
            <link>https://blog.quidsentio.com/posts/export-your-facebook-status-posts-to-a-searchable-personal-journal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23903665</guid>
            <pubDate>Tue, 21 Jul 2020 01:50:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Digital Astronomy with Cellular Automata]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23903621">thread link</a>) | @speleo
<br/>
July 20, 2020 | https://kylehovey.github.io/blog/automata-nebula | <a href="https://web.archive.org/web/*/https://kylehovey.github.io/blog/automata-nebula">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div class="page">
  
  <p><img src="https://kylehovey.github.io/blog/images/automata_nebula/plots/selected_run/UMAP_CA_Full_Annotated.png" alt="UMAP Embedding"></p>

<p>In my <a href="https://kylehovey.github.io/blog/turing-basins">last post</a>, I shared my journey through understanding the link between entropy, thermodynamics, evolution, computation, and mathematics. At the end, I shared some preliminary research on using entropy/complexity to classify the behavior of Cellular Automata (CA) and perhaps pave a road to finding more universal CA (those <a href="https://www.youtube.com/watch?v=My8AsV7bA94" target="blank">capable of computation</a>). At that time, I only had a handful of samples which, albeit showing promise, fell short of demonstrating concrete results.</p>

<p>I am incredibly excited to share that I have now run my simulations on <em>every possible</em> Life-Like Cellular Automaton rule (a total of 262,144 rules), and it shows some great potential in classifying every rule based on its emergent behavior. Not only that, but this method establishes what appears to be a strong metric for finding ‚Äúislands‚Äù of rules that have similar behavior.</p>

<p>This is exciting news, because past classifications of even elementary CA such as the semi-totalistic <a href="https://en.wikipedia.org/wiki/Moore_neighborhood" target="blank">Moore neighborhood</a> variety (called the <a href="https://en.wikipedia.org/wiki/Life-like_cellular_automaton" target="blank">Life-Like</a> CA) have either required generalizations that are computationally intractable to ascertain, or required a great deal of manual filtering and edge-case handling in order to separate sets of rules into classes.</p>

<h2 id="abstract">Abstract</h2>

<p><img src="https://kylehovey.github.io/blog/images/automata_nebula/expository/rule_30.png" alt="Rule 30"></p>

<p>Stephen Wolfram (one of the biggest researchers in CA) <a href="https://wpmedia.wolfram.com/uploads/sites/13/2018/02/02-2-2.pdf" target="blank">proposed</a> a four-level classification scheme for one dimensional cellular automata. He later extended these definitions to include two-dimensional cellular automata like the Life-Like CA we are looking at here. The classifications are:</p>

<ol>
  <li><em>Evolution leads to a homogeneous state.</em></li>
  <li><em>Evolution leads to a set of separated simple stable or periodic structures.</em></li>
  <li><em>Evolution leads to a chaotic pattern.</em></li>
  <li><em>Evolution leads to complex localized structures, sometimes long-lived.</em></li>
</ol>

<p>But, as mentioned in <a href="https://www.ics.uci.edu/~eppstein/ca/wolfram.html" target="blank">this post</a> regarding some caveats about these classifications, gliders have been found in all four of these classes. This is problematic because gliders are one of the most essential parts of data transmission in machines built inside of CA, so the four classes may not be enough to identify the presence or absence of a universal CA. Also, <a href="https://wpmedia.wolfram.com/uploads/sites/13/2018/02/02-2-2.pdf" target="blank">it has been shown</a> that, given a rule, finding which class a CA belongs to is an undecidable problem (for one-dimensional CA at least, but I would imagine the argument abstracts well to any Cartesian dimension).</p>

<p>My goal here was to focus on dynamic classification of the emergent properties of any given CA given its rules. By not subscribing to manually generated labels on classification, we can instead focus on developing a metric of similarity. In this sense, each rule becomes its own ‚Äúclass‚Äù and you can find rules that are sufficiently close in behavior to be considered the same class. Geometrically, this would be an analysis of CA by way of clustering.</p>

<p>The difficult part, of course, is developing a representation of a given rule that would allow for clustering. I settled on producing a curve of the <a href="https://en.wikipedia.org/wiki/Kolmogorov_complexity" target="blank">Kolmogorov complexity</a> across the generations of the automaton‚Äôs universe. My inspiration for this approach came from a few core concepts. First, that entropy and complexity looked like valid metrics to measure the emergent behavior of a system and its potential for <a href="https://en.wikipedia.org/wiki/Self-organized_criticality" target="blank">self-organized criticality</a>. My reasoning behind this intuition is that structure typically implies order, and order implies either repeating patterns or extension of structure that can be derived from existing structure. Kolmogorov complexity would capture the amount of bits required to express this structure. I later learned that this view is not a new one, as Wolfram took a similar approach in examining the procession of spacial and temporal entropy in <a href="https://www.stephenwolfram.com/publications/cellular-automata-complexity/pdfs/universality-complexity-cellular-automata.pdf" target="blank">his research on one-dimensional CA</a>.</p>

<p>In a addition to the convenient dualistic simplicity of studying life-or-death CA, the grid of an automaton can be interpreted as a bitmap image. Image compression is (unsurprisingly) adept at finding something close to the smallest possible representation of an image, and PNG compression does it without loss of information. Image compression asymptotically <a href="https://homepages.cwi.nl/~paulv/papers/cluster.pdf" target="blank">approximates Kolmogorov Complexity</a> <a href="https://www.researchgate.net/publication/266795088_A_Safe_Approximation_for_Kolmogorov_Complexity">up to a constant</a> dependent on the compression algorithm. Therefore, as the compression algorithm is the same for each measurement, we have a viable pipeline for estimating the Kolmogorov complexity of each state of the CA universes we encounter. If we wish to relate all of this back to entropy, we can do so. <a href="https://homepages.cwi.nl/~paulv/papers/info.pdf" target="blank">Entropy is the expected value of Kolmogorov Complexity</a> in this context, so this data will be useful for that as well.</p>

<p>In order to get an amortized generalization of each rule, I started from random initial states of the universe with each cell having an equal probability of starting in any of the possible states. I then ran simulations for hundreds of generations with multiple random initial conditions and found the average complexity at each step. Other researchers looking into the general behavior of CA have taken this approach of random initial state and it seems to be a valid way to capture their behavior.</p>

<p>Lastly, I chose to study only Life-Like CA. These are the semi-totalistic CA rules that only depend on the Moore neighborhood of each cell. This made the search space something that I could simulate in reasonable time, given that it only had around a quarter million possible rules (even though it still took two weeks to generate all of the data).</p>

<p>The result of these simulations were 262,144 records of the average complexity in bytes of the board of all possible Life-Like CA. Each record had 256 samples, each record was averaged from 10 runs, and each rule was run with a board size of 100x100 cells.</p>

<h2 id="using-umap-a-digital-telescope">Using UMAP, a Digital Telescope</h2>

<p><img src="https://kylehovey.github.io/blog/images/automata_nebula/expository/webb.jpg" alt="James Webb Space Telescope"></p>

<p>Obviously, no one has the time to go through the graphs of over a quarter million samples, so I needed to find a way to classify the results. Recently I have been infatuated with the <a href="https://umap-learn.readthedocs.io/en/latest/" target="blank">UMAP</a> algorithm. It has the ability to compress data with thousands of dimensions into a lower dimensional space (in this case 2D or 3D) while still preserving structures/features in the data. It is a remarkable feat of algebraic topology that deserves more awareness of in the scientific community.</p>

<p>When first learning about dimensionality reduction algorithms such as UMAP or <a href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding" target="blank">tSNE</a>, I was extremely skeptical of their efficacy. It seemed impossible to retain structure when losing that many dimensions. What made their usage click for me was the knowledge that, even if your data lives in a space that has thousands of dimensions (called the ambient space), there is a very good chance that the <em>local dimension</em> of real-world data is of much lower dimension than this. The goal, then, of UMAP is to preserve the structure found in the data by finding a good manifold to embed it into. For further understanding on this topic, check out the <a href="https://www.youtube.com/watch?v=nq6iPZVUxZU" target="blank">presentation</a> that Leland McInnes (the creator of UMAP) gave on his algorithm.</p>

<p>In a sense, UMAP is a digital telescope that lets us look at constellations of high-dimensional data that we have never had the ability to visualize before. Algorithms like tSNE have worked in similar ways in the past, but UMAP is the first algorithm to be efficient enough to run on data with thousands of dimensions using something as prosaic as a laptop and a dream. This is to say that UMAP scales incredibly well, especially when compared to what is already out there.</p>

<p>Armed with UMAP, I fed the algorithm all 262,144 vectors (each with 256 dimensions, one for each complexity snapshot) and patiently waited for the embedding to complete. After fifteen minutes of my laptop revving up my fans, I had my first snapshot of the overarching structure of the Life-Like CA (points are colored by the average forward difference between each complexity snapshot):</p>

<p><img src="https://kylehovey.github.io/blog/images/automata_nebula/plots/selected_run/UMAP_CA_Full.png" alt="UMAP Embedding"></p>

<p><a href="https://kylehovey.github.io/blog/images/automata_nebula/plots/selected_run/UMAP_CA_Full_High_Res.png" download="">(High-Res Version)</a></p>

<p>There it was, the massive <a href="https://en.wikipedia.org/wiki/Hertzsprung%E2%80%93Russell_diagram" target="blank">Hertzspring-Russel</a>esque serpent hiding in the structure of emergent complexity in automata. It is important to note that compressing dimensions can make parts of the data look separate in the embedding, even though they are connected in the ambient space they came from. It would be reasonable to assume that the serpent is one continuous entity, and the ‚Äújump‚Äù in the center was a result of the embedding.</p>

<p>While beautiful, this representation would not mean much if it did not accomplish the goal we set out to achieve: a metric for classification of rules that behave in similar ways to a given starting rule. Starting from the Game of Life, I began examining nearby rules and found that the metric did indeed yield other rules that produced uncanny behavior.</p>

<p><em>Rules Close to the Game of Life (B3/S23)</em></p>

<table>
  <thead>
    <tr>
      <th>B3/S23</th>
      <th>B3/S013</th>
      <th>B38/S013</th>
      <th>B38/S238</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img src="https://kylehovey.github.io/blog/images/automata_nebula/animations/similar/gol_like/6152.gif" width="200px"></td>
      <td><img src="https://kylehovey.github.io/blog/images/automata_nebula/animations/similar/gol_like/5640.gif" width="200px"></td>
      <td><img src="https://kylehovey.github.io/blog/images/automata_nebula/animations/similar/gol_like/5896.gif" width="200px"></td>
      <td><img src="https://kylehovey.github.io/blog/images/automata_nebula/animations/similar/gol_like/137480.gif" width="200px"></td>
    </tr>
  </tbody>
</table>

<p><em>Rules Close to Day and Night (B3678/S34678)</em></p>

<table>
  <thead>
    <tr>
      <th>B3678/S34678</th>
      <th>B36/S01456</th>
      <th>B3678/S01456</th>
      <th>B3567-S01478</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img src="https://kylehovey.github.io/blog/images/automata_nebula/animations/similar/dan_like/242120.gif" width="200px"></td>
      <td><img src="https://kylehovey.github.io/blog/images/automata_nebula/animations/similar/dan_like/58952.gif" width="200px"></td>
      <td><img src="https://kylehovey.github.io/blog/images/automata_nebula/animations/similar/dan_like/59336.gif" width="200px"></td>
      <td><img src="https://kylehovey.github.io/blog/images/automata_nebula/animations/similar/dan_like/206568.gif" width="200px"></td>
    </tr>
  </tbody>
</table>

<p><em>Rules Close to Anneal (B4678/S35678)</em></p>

<table>
  <thead>
    <tr>
      <th>B4678/S35678</th>
      <th>B468/S035678</th>
      <th>B0123578/S0124</th>
      <th>B46/S035678</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img src="https://kylehovey.github.io/blog/images/automata_nebula/animations/similar/anneal_like/250320.gif" width="200px"></td>
      <td><img src="https://kylehovey.github.io/blog/images/automata_nebula/animations/similar/anneal_like/250704.gif" width="200px"></td>
      <td><img src="https://kylehovey.github.io/blog/images/automata_nebula/animations/similar/anneal_like/12207.gif" width="200px"></td>
      <td><img src="https://kylehovey.github.io/blog/images/automata_nebula/animations/similar/anneal_like/250448.gif" width="200px"></td>
    </tr>
  </tbody>
</table>

<p><em>Rules Close to Maze-Finder (B138/S12357)</em></p>

<table>
  <thead>
    <tr>
      <th>B138/S12357</th>
      <th>B124/S123467</th>
      <th>B0124/S0123467</th>
      <th>B038/S012358</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img src="https://kylehovey.github.io/blog/images/automata_nebula/animations/similar/maze_like/89354.gif" width="200px"></td>
      <td><img src="https://kylehovey.github.io/blog/images/automata_nebula/animations/similar/maze_like/113686.gif" width="200px"></td>
      <td><img src="https://kylehovey.github.io/blog/images/automata_nebula/animations/similar/maze_like/114199.gif" width="200px"></td>
      <td><img src="https://kylehovey.github.io/blog/images/automata_nebula/animations/similar/maze_like/155401.gif" width="200px"></td>
    </tr>
  </tbody>
</table>

<p>What is fascinating about this embedding is that it extends the idea of Stephen Wolfram‚Äôs four-level classification of CA to a continuum that can be embedded in as many dimensions as you see fit. CA classically known for supporting persistent structures and gliders such as Game of Life, Day and Night, and High Life exist in the middle of the serpent where the average difference is on the edge of chaos. CA that burn through complexity at a higher rate such as Morley, Anneal, and Diamoeba are far out on the tail of the serpent, along with many rules that result in universes that either die out quickly or fill the whole board with live cells (two low-complexity attractors). Meanwhile, rules like Replicator (which duplicates existing structure) exist in the head of the serpent where complexity stays roughly the same throughout the generations. Rules at the head seem to tend very quickly towards chaos, an apt opposite to the rules found in the tail.</p>

<h2 id="caveats-and-room-for-improvement">Caveats and Room for Improvement</h2>

<p>You might notice that for the Anneal CA that there was an example that ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kylehovey.github.io/blog/automata-nebula">https://kylehovey.github.io/blog/automata-nebula</a></em></p>]]>
            </description>
            <link>https://kylehovey.github.io/blog/automata-nebula</link>
            <guid isPermaLink="false">hacker-news-small-sites-23903621</guid>
            <pubDate>Tue, 21 Jul 2020 01:39:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do Judge a Progamming Book by Its Cover]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23903619">thread link</a>) | @dragandj
<br/>
July 20, 2020 | https://dragan.rocks/articles/19/Judge-a-clojure-programming-book-by-its-cover | <a href="https://web.archive.org/web/*/https://dragan.rocks/articles/19/Judge-a-clojure-programming-book-by-its-cover">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-org451c007">
<p>
I needed an idea for the covers of the series of books that I'm writing,
<a href="https://aiprobook.com/"><i>Interactive Programming for Artificial Intelligence</i></a>.
</p>

<p>
My budget was (close to) zero, and I can't call myself an artist. Many ideas came
and went; none of them were distinctive enough. They weren't communicating the
message of the book series.
</p>

<p>
The main message of the book series? These aren't just
tutorials teaching some contemporary programming skills. I hope they are
much more than that!
</p>

<p>
This book series has an <i>interactive</i> approach. Every concept I'm writing
about is immediately illustrated with executable code. You can try it right away
in Clojure's amazing super-console: <a href="https://clojure.org/guides/repl/introduction">the REPL</a>, which provides a genuine connection between
the programmer and the running program.
</p>

<p>
These are <i>programming</i> books. They go beyond theory, and they do not stop
at cute demos. The code you'll write is fast, flexible and extendable.
The real thing. Comprehensive, but approachable.
</p>

<p>
Not all of the books are strictly about <i>Artificial Intelligence</i>,
they are also about the programming foundations that are important
in building AI software.
</p>

<p>
These are several challenging areas on their own. Math: it's tough. AI: it's abstract.
Functional programming: it's funky. High performance computing on the GPU: get out of here!
Together? It's a tough sell!
</p>

<p>
Finally though, the answer fell into my lap. Meet Dog and Bird, they are two friends
that bravely immerse themselves into challenging activities and make them effortless and fun!
</p>

<p>
These books are great for beginners. It's not easy, but everything is simply explained.
You don't have to be an expert to start, but you will become one as you progress.
</p>
</div></div>]]>
            </description>
            <link>https://dragan.rocks/articles/19/Judge-a-clojure-programming-book-by-its-cover</link>
            <guid isPermaLink="false">hacker-news-small-sites-23903619</guid>
            <pubDate>Tue, 21 Jul 2020 01:39:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Choose What to Read]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23903359">thread link</a>) | @yoloswagins
<br/>
July 20, 2020 | https://www.calebontiveros.com/how-to-choose-what-to-read/ | <a href="https://web.archive.org/web/*/https://www.calebontiveros.com/how-to-choose-what-to-read/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
            <p>There are a lot of books in the world. How do you choose which ones to read?</p><p>There are at least two questions here:</p><ul><li>What topics should I read about?</li><li>What books do I read within a topic?</li></ul><p>For some people, the answer to the topic question is easy. They're obsessed with a given topic. They move onto the second problem.</p><p>For others, like myself, the first can be daunting. It's not that there aren't enough topics, it's that there are too many. If I look at my Goodreads want to read list right now, I see books on the following:</p><ul><li><a href="https://www.goodreads.com/book/show/1138264.Mathematical_Models_of_Social_Evolution">Mathematical models of social evolution</a></li><li><a href="https://www.goodreads.com/book/show/256965.Six_Myths_about_the_Good_Life">Philosophical views on the good life</a></li><li><a href="https://www.goodreads.com/book/show/49930783-why-we-re-polarized">Political polarisation in the US</a></li><li><a href="https://www.goodreads.com/book/show/178447.Leaders">Nixon's take on different state leaders</a></li><li><a href="https://www.goodreads.com/book/show/23582015-principles-of-neural-design">Neuroscience and neural design</a></li></ul><p>Each of these topics seem great and the books seemed good enough to justify saving. I have 176 more on my list. A friend just emailed me about<a href="https://www.amazon.com/Why-Liberalism-Failed-Politics-Culture/dp/0300223447"> Why Liberalism Failed</a> and it turns out that book looks interesting as well. How to choose?</p><p>This post is about modeling my reading engine. It's about reading for insight, reading to uncover valuable and relevant information and skills. There are other reasons to read, like to relax or for social reasons. They can be related, but I'm largely going to ignore those reasons here. This may come across as utilitarian and boring, but that's the cost of being serious.</p><p>Let's step back and consider what kind of decision is at stake here. Decisions can vary on the following dimensions:</p><ul><li>reversibility</li><li>stakes</li><li>prior uncertainty</li><li>post certainty</li></ul><p>When decisions are irreversible, you'll want to ensure that you take the correct one. So you'll spend more time on the decision. If they are reversible and you learn you made the wrong decision, no problem, you can change. Choosing between job offers is the sort of thing you'll likely want to spend a decent amount of time on. The switching costs are usually high. If you want a better example, consider the decision of whether to have a kid or not.</p><p>If decisions are high stakes, deciding correctly matters more. Not so much if they're smaller potatoes. Spend more time on choosing a job, less time on what to watch this evening.</p><p>If decisions are made in a shroud of uncertainty, then the value of additional information will be higher. Prior uncertainty refers to the amount of uncertainty before a given decision. Often, "When it comes to perceiving reality, our minds are in a fog."</p><p>Post certainty refers to the amount and rate of relevant information flow after making a decision. That's a bit abstract, but we all know that after some decisions, you'll know right away whether you made the right one. Ordering at some restaurants is like this. After other decisions, such as longer term investments, you may never know. To be more precise, a decision will be higher in post certainty to the degree that, after you make the decision, you get relevant information and you get that information quickly.</p><p>With these in mind we can see that the decision to read on a particular topic is:</p><ul><li>reversible</li><li>medium stakes</li><li>variable prior uncertainty</li><li>reasonable post certainty</li></ul><p>The decision is reversible because you can stop reading at any point. Reading is somewhat important (it depends), but not as high stakes as many decisions we make. There can initially be a lot of prior uncertainty, ideally this goes down over a life. Occasionally, the result of a decision won't be evaluable for years, for example, when it's tied up with a risky research project. An example of this is deciding to become an expert in nanotech in the early 2000s. Yet if you know that you want to take a bet on high risk, world shaping technological developments then, by asking the right questions, you'll be able to reduce uncertainty. Given that you're studying nanotech, you can evaluate whether you're studying the right issues within that domain. You can do all of this even if the decision to study nanotech won't be evaluable for years.</p><p>So choosing what domains to hop into is reversible, medium stakes, has variable uncertainty, and has a reasonable amount of post certainty.</p><p>There are two key upshots here:</p><ul><li>First, what you read is determined by your projects. If you're uncertain about your projects, that uncertainty will trickle down. When I was studying philosophy, learning software engineering, or heads down in<a href="http://stoameditation.com/"> Stoa</a> I had less uncertainty about what to read. If I'm exploring different projects, there's more uncertainty.</li><li>The second, is that deciding what to read is a game you'll play over and over again. It's a reversible decision that you can get better at.</li></ul><p>What you want to think of doing then, is designing a reading engine. You're not making one-off judgements about what to read for all time. Instead, you're setting up a system for selecting, consuming, and then utilizing information. Books play a small role in that ecosystem - they're not even the primary unit.</p><h3 id="building-a-reading-engine">Building A Reading Engine</h3><p>This engine can be modeled as a pipeline:<br></p><figure><img src="https://www.calebontiveros.com/content/images/2020/07/Screen-Shot-2020-07-16-at-7.47.11-AM.png"><figcaption>Created with <em><a href="https://roamresearch.com/">Roam Research</a>'s </em>nascent <em>diagram tool.</em></figcaption></figure><p>Reading is the core activity. But it's interwoven with a number of other activities.</p><p>What I read is influenced by what I've collected into my reserves, projects, the questions I'm asking, and curiosity.</p><p><strong>Reserves</strong><br>The reserves is a list of books that I found intriguing at one point or another. It isn't a list of books to read. That seems too prescriptive - I won't read every book in my reserve. Instead, it's a list of books that I may read, if I get excited about the relevant topic. The books are on deck, as it were.</p><p>Some of my favorite ways to populate my reserves is through interviews, blog posts, conversations, and Twitter. I usually find the best pieces at the end of bibliographies or during a simple search.</p><p><strong>Projects</strong><br>The most influential driver of this pipeline is projects. I like to think of my life as organized around a few projects or goals. Some of these are mundane, others grand. Whatever they are, they should guide what you read. If you're looking for insight, that's in the purpose of something or other. Examples of projects are:</p><ul><li>Building better habits</li><li>Learning about formal methods in cultural evolution</li><li>Aiming to be more Stoic</li><li>Cooking more varied dishes</li><li>Running a reading group on power and influence in organizations</li></ul><p>As noted above, uncertainty about your projects trickles down. If it seems like there are too many things to read, that may be a sign that you have too many projects.</p><p>If this is you, you can let your work inform whether they should get dropped or not. If you want to cull projects more aggressively, <a href="https://www.calebontiveros.com/on-disproving-your-own-ideas/">derisk</a> and<a href="https://effectivealtruismcoaching.com/blog/2020/6/26/five-ways-to-prioritize-better"> prioritize</a>. Focus on questions like:</p><ul><li>What can I learn that would make this project not matter to me?</li><li>What cheap tests would show that this project won't work?</li><li>Can I build an MVP of this project?</li><li>What specific questions about this topic do I want answered? What would answers unlock?</li></ul><p><strong>Questions</strong><br>Projects are vague and not sufficient for narrowing down the solution set on their own. Instead, list questions that you want answers to. If reading is inquiry guided, you're more likely to find what you want and spend less time trawling through books that feel relevant, but aren't.</p><p>Questions can help you choose the right things to read. What you decide to spend your attention on is a reversible decision. You can stop reading at any moment. So, if, like me, you feel like there are too many topics, narrow it by answering questions like:</p><ul><li>What's the chance that this topic is related to my project?</li><li>If I understand this completely, how will that be helpful in advancing my project?</li><li>How long will it take you to understand this topic? Is it worth the cost?</li></ul><p>Think of reading as inquiry guided. Your questions are the fundamental units. Read in order to answer specific queries you have. Once you've answered a question, that should generate more questions and output. If you can't find the answer, put the book down.</p><p>As an example, I want to read the book on neural design, because I'm interested in the nature of emotion. Often I feel like I read neuroscientific explanations of behavior and they don't feel like explanations at all. On the surface, they appear to be very black box (x module is linked with this behavior). Plausibly, explaining how the brain works from an engineering perspective is more illuminating. So, if I read that book then I should come into with the questions:</p><ul><li>Does this book give a new kind of explanation?</li><li>Is this explanation useful to understanding the nature of emotion?</li></ul><p>I can likely figure this out pretty quickly. If the answer is no, I can stop reading. Returning to the framework above, reading has reasonably high post certainty. As you read, you can get a sense of whether you're reading the right thing by updating on the book‚Äôs quality and whether it has what you want in it.</p><div><p>As an aside answers to these questions are things that should end up in notes. And if the answers help me push the peanut forward, they'll influence other questions, an essay, or project.</p><p><strong>Output</strong><br>Your project likely has some private or public output.</p></div><p>For me the private output is in the form of anki cards and notes.<a href="https://apps.ankiweb.net/"> Anki</a> is a fun and useful way to remember things. A lot of people are excited about note taking systems and software today. The most important part about notes is that they actually answer the questions that you have.</p><p>Public output can be anything from behavior change to essays, from conversations in person to email. Putting things out there will help you get feedback, speed up your projects, ask better questions, and provide value to others.<br></p><p><strong>Occurrent Curiosity</strong><br>Not all things should be so structured. Plausibly some amount of reading shouldn't fit that tightly into your system. You're more likely to discover something neglected if you read things for the sake of reading them on occasion.</p><p>Sometimes it's fun to read something because you're curious about it at that very moment. This is less systematic but I think that occurrent curiosity plays an important role in choosing what topics to read on. For me, it serves to explore books that may not be directly related to a project of mine, but could be ‚Ä¶</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.calebontiveros.com/how-to-choose-what-to-read/">https://www.calebontiveros.com/how-to-choose-what-to-read/</a></em></p>]]>
            </description>
            <link>https://www.calebontiveros.com/how-to-choose-what-to-read/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23903359</guid>
            <pubDate>Tue, 21 Jul 2020 00:43:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why You‚Äôre Not as Data-Driven as You Think You Are]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23903276">thread link</a>) | @jmcunha
<br/>
July 20, 2020 | https://scienceofdata.org/2020/07/20/why-youre-not-as-data-driven-as-you-think-you-are/ | <a href="https://web.archive.org/web/*/https://scienceofdata.org/2020/07/20/why-youre-not-as-data-driven-as-you-think-you-are/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main">

<section id="content">

	<article id="post-1312">

		<div>
			
<p>How many times have you heard someone say they are data-driven or data centric or that ‚Äúdata is the heart of everything they do‚Äù? I‚Äôve heard this so many times that the urge to wince is becoming irresistible. This sentiment is emblematic of a vanity that exists in the big data era ‚Äì we are scientific, evidence based and use data to make our decisions.&nbsp;<br></p>



<p>This slogan is heard at every company I‚Äôve worked at and from a range of people whether they be CEOs or ‚Äúthought leaders‚Äù. In this post, I want to explain why we‚Äôre not as data-driven as we‚Äôd like to think. There are mistakes I‚Äôve noticed some otherwise very smart people make when it comes to looking at and making decisions based on data and I want to discuss some of them with the hopes of injecting some humility and skepticism into the discourse.&nbsp;<br></p>



<p>Before I begin, let me give the benefit of the doubt to those people who express this sentiment earnestly. I‚Äôm aware that people are well intentioned when they say this ‚Äì they want to express the fact that they‚Äôre not exclusively guided by their experience, hearsay or whim when making decisions. They want to consider facts from the outside world and let this guide their thought process about a particular issue. As far as this goes ‚Äì fine, but I contend that this sentiment is so general and fair-seeming that it goes without saying. Not many people would openly admit that they don‚Äôt like to consider the facts before making a decision.&nbsp;<br></p>



<p>I would go further and say those people who frequently want you to know how data savvy or data focused they are, do so as a way of sounding clever and giving legitimacy to whatever it is that they‚Äôre about to say next. Whenever someone tells me that they‚Äôre data-driven I inevitably lean in to hear what silly comment couched in technical sounding language is going to follow ‚Äì it has the inverse effect that the author intended.<br></p>



<p>Let‚Äôs explore some of the common blunders made by data-driven decision makers.&nbsp;</p>



<h2>No one has ever let data speak for itself ‚Äì ever</h2>



<p>If a data tree falls in a (random?) forest, does it make a sound? Easy ‚Äì no. This is an error I see made by non technical people or those who come from non scientific fields and love the idea of objective and bias free analysis. Too bad no one has ever done that in data science. Data cannot speak without an interpreter and that interpreter is always mischievous, seeking to mix in its own words.&nbsp;<br></p>



<p>All data have assumptions and biases. Where we get our data from, the quality of our data and how we use the data for analysis all imbue data with a structure of which we have to be mindful. Even activities as simple as looking at a line graph carry assumptions that can trip us up if unchecked. There could be missing data, the time scale could not be homogeneous (have we skipped days?) or the data recorded could change scale halfway through. Even choosing which range of values on the x and y axis to show will have an impact on the user. These assumptions must be considered and made explicit if it is feared that they could mislead the end user. If not feared ‚Äì do it all the same.</p>



<h2>Where your data comes from is as important as how much data you have</h2>



<p>The sad truth is that in practice, most of the data we have as data scientists is junk. Choosing what to ignore is important for meaningful analysis. More data does not equate to better analysis ‚Äì especially if it comes from a source which is biased and unreliable, Garbage In Garbage Out.&nbsp;<br></p>



<p>I was once asked to model how some process evolves over time. The problem was that each data point was not measuring the same unit; our observation of some phenomena at time epoch 2 was not the observation of the same phenomena at time epoch 1. Therefore you were not measuring evolution of anything over time but rather making statements about independent data on different days. To illustrate this, consider the problem of measuring daily occupancy in a hotel ‚Äì we count the number of guests in rooms every day and plot. However if we had daily occupancy data but each day reports a different hotel, then we cannot reasonably plot this on a (time indexed line) graph since we would not be looking at the occupancy rate of the same hotel over time.&nbsp;<br></p>



<p>This distinction is important and fundamentally shifts the robustness of our whole analysis. We have to interrogate carefully where our data comes from, what biases it might have and whether it is in the format we need to test our hypotheses.</p>



<h2>Just being skeptical doesn‚Äôt make you smart</h2>



<p>It is true that confirmation bias is real and there are many trigger-happy stakeholders who will make decisions based on one significant test in a sea of other non significant results (my views on significance testing in business might be in a different post). It pays dividends to be careful, demand more data and adopt a wait-and-see approach. A lot of times we build models and make predictions and the best thing to do is to wait for more data once we feel like we have effectively modelled a problem.<br></p>



<p>However there are people who sit on the other extreme and no amount of analysis is sufficient for them to act. They try to show how level-headed they are by making comments like ‚Äúwe need other data sources to better understand the problem‚Äù, ‚Äúwe need to synthesise our data to separate signal from noise‚Äù or ‚Äúthe data is out of date‚Äù. All these remarks are reasonable but in many cases they‚Äôre used as a justification for inaction.&nbsp;<br></p>



<p>The purpose of data work and experimentation should be to inform action. If you are hiding behind these excuses to not make changes which seem otherwise reasonable then you‚Äôre not being cautious, you‚Äôre being cowardly. If you don‚Äôt have a measurable limit of how much data will be enough for you to act (how this is determined is a different problem) or how you intend to separate signal from noise then you‚Äôre making this mistake.&nbsp;<br></p>



<p>It‚Äôs a tricky blunder to spot because it disguises itself as wisdom. If data analysis is used to repeatedly say no because stakeholders see no evidence that an action will be successful, they should go the whole way and not take any action ‚Äì there is never going to be evidence of efficacy until after the fact. One telltale sign of this behaviour is how people conveniently depend on less data when there is a decision they want to make already. The criterion of evidence for ideas they dislike is far higher compared to the ideas they are favourable towards.</p>



<h2>Automation is not a substitute for thinking</h2>



<p>When you write code it helps to automate as much as possible. Putting models in production or scheduling scripts are very powerful tools which ultimately save time and effort. However there is a danger when we try to automate those decisions which require a domain specific understanding of a problem.&nbsp;<br></p>



<p>Natural Language Processing is full of problems which require a human to determine if the results make sense ‚Äì from interpreting word2vec similarity outputs to validating the sensibility of text cleaning, there are some problems which require humans in the loop (for the time being). We can make the space for those humans small but we can‚Äôt fully automate it away at the risk of making our analysis meaningless. Clustering is another example where we can automate to a great extent but if the output does not make sense for the problem in question, it might be necessary to compromise on some performance metrics in order to gain interpretability.&nbsp;<br></p>



<p>If it helps, I‚Äôve formulated Junaid‚Äôs 1st law ‚ÄúAutomate as far as possible, but not further‚Äù.&nbsp;</p>



<h2>Sometimes it‚Äôs okay to ignore the data</h2>



<p>Sometimes it helps to take a risk and ignore what the data might be presently suggesting and go with your instinct. Frequent A/B testing can sometimes lead to users chasing local optima and not focusing on the big picture. If you gambled on a new product feature and early results have shown that users respond adversely, it might not necessarily be the case that it is good to discontinue it. Think about other benefits it might have for your business and users later down the line. It might be that after users have gotten used to the new feature, they begin to respond positively.&nbsp;<br></p>



<p>Ultimately there is nothing wrong with using intuition sometimes. The problem arises when we confuse our intuition as inference from data and behave with a false confidence. I have seen people deliberately masquerade their opinions as if they were inferences from data analysis and refuse to acknowledge that their views originate from their minds vs the external world. We should admit when we‚Äôre using our intuition and be open to being challenged if others have differing ideas.<br></p>



<p>There are more data sins but these are the main ones that come to mind. Hopefully I‚Äôve illustrated the value of thinking through what we‚Äôre doing, checking our assumptions and realising that this enterprise is far more complicated than the buzzwords and slogans would have us believe.&nbsp;</p>
					</div>

		

		



		

		
		

		
		
	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
	</article>

</section>



</div></div>]]>
            </description>
            <link>https://scienceofdata.org/2020/07/20/why-youre-not-as-data-driven-as-you-think-you-are/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23903276</guid>
            <pubDate>Tue, 21 Jul 2020 00:29:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simplified View on How Certificate Signing Works]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23903223">thread link</a>) | @yinyang_in
<br/>
July 20, 2020 | https://kbs.murarisumit.in/tils/how-certificate-signing-works/ | <a href="https://web.archive.org/web/*/https://kbs.murarisumit.in/tils/how-certificate-signing-works/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
<article>
    <h2> Simplified view on How Certificate Signing works </h2>
    <strong>Tags: </strong>
    
    
    
    
    
    
    <p>Reference: <a href="https://scotthelme.co.uk/cross-signing-alternate-trust-paths-how-they-work/">https://scotthelme.co.uk/cross-signing-alternate-trust-paths-how-they-work/</a></p>
<h4 id="steps-for-signing-certificate-by-ca">Steps for signing certificate by CA</h4>
<ol>
<li>The Subscriber (the person asking a CA to issue them a certificate) sends a Certificate Signing Request (CSR) to the CA which contains all of their details like name, domain name etc.</li>
<li>The CA will then take a blank certificate and begins to fill in the details of the Subscriber, validating ownership of the domain along the way, until they have completed all of the fields in the certificate.</li>
<li>At this stage we have what we call the Pre-Certificate, it‚Äôs basically a finished certificate ready to issue but the only thing that‚Äôs missing is the CAs signature on the bottom of the certificate to make it official</li>
</ol>
<h4 id="signing-of-certificate">Signing of certificate</h4>
<ol start="4">
<li>CA takes Pre-Certificate and running it through a hash function, currently SHA256, to obtain the digest.</li>
<li>The second step is the CA then taking that digest and encrypting it with their private key.</li>
<li>This encrypted digest is the signature and once appended to the end of the file we now have a signed certificate that can be issued to the Subscriber.</li>
</ol>
<p><strong>Rules public key encryption</strong></p>
<ol>
<li>For every private key, there is only one corresponding public key.</li>
<li>Also Data encrypted with the public key can only be decrypted with it‚Äôs corresponding private key, and data encrypted with the private key can only be decrypted with it‚Äôs corresponding public key.</li>
<li>More rules and info at: <a href="https://www.cloudflare.com/learning/ssl/how-does-public-key-encryption-work/">https://www.cloudflare.com/learning/ssl/how-does-public-key-encryption-work/</a></li>
</ol>
<hr>
<p>Q: How does adding the <strong>encrypted digest</strong> i.e. signature makes it signed certificate ?</p>
<p>A: It can better be explained by putting browser in picture and looking at what it does while requesting https website.</p>
<hr>
<h4 id="what-browser-does">What browser does</h4>
<ol>
<li>During tls handshake with https endpoint, it fetches associate intermediate certificate and root certificate.
<ul>
<li>We need to upload intermediate certificate(public key of CA) and root certificate while uploading ssl certificate.</li>
</ul>
</li>
<li>Browser now decrypts the digest using intermediate certificates, if it is able to decrypt using intermediate key, it means that above certificate is signed by private-key of CA(data encrypted with the private key can only be decrypted with it‚Äôs corresponding public key)</li>
<li>Browser itself also calculate hash of pre-certificate to compare with hash it got in step 2 after decrypting digest.</li>
<li>If both are correct means,
<ul>
<li>The signature definitely came from the CA. (Authenticity) - Step 2</li>
<li>The certificate has not been tampered with. (Integrity)  - Step 3</li>
</ul>
</li>
</ol>
<p>Above is over-simplified explanation of what happens, above all is taken from 1st half of post at : <a href="https://scotthelme.co.uk/cross-signing-alternate-trust-paths-how-they-work/">https://scotthelme.co.uk/cross-signing-alternate-trust-paths-how-they-work/</a></p>
<p>If you want to read further, continue reading at : <a href="https://scotthelme.co.uk/cross-signing-alternate-trust-paths-how-they-work/">https://scotthelme.co.uk/cross-signing-alternate-trust-paths-how-they-work/</a></p>

    
</article>
<center> For feedback reach me at <a href="mailto: email@murarisumit.in?subject=https://kbs.murarisumit.in/%20:%20Simplified%20view%20on%20How%20Certificate%20Signing%20works"> email@murarisumit.in</a> </center>
</div></div>]]>
            </description>
            <link>https://kbs.murarisumit.in/tils/how-certificate-signing-works/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23903223</guid>
            <pubDate>Tue, 21 Jul 2020 00:18:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Make Your Skills Sound Better on Your Resume]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23903188">thread link</a>) | @rahulvarshneya
<br/>
July 20, 2020 | https://myresumeseed.com/blogs/career-insights/how-to-make-yourself-sound-better-on-your-resume | <a href="https://web.archive.org/web/*/https://myresumeseed.com/blogs/career-insights/how-to-make-yourself-sound-better-on-your-resume">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><span>Writing your resume for the first time or editing it for the 100th can both be incredibly daunting experiences. </span></p>
<p><span>With today√¢‚Ç¨‚Ñ¢s fast-paced, ever-evolving corporate environment, hiring managers are consistently searching for unique candidates in an oversaturated market. </span></p>
<p><span>This makes resume writing so much more integral to landing a job that you want. </span><span>√Ç&nbsp;</span></p>
<p><span>Most hiring managers utilize applications called √¢‚Ç¨≈ìApplicant Tracking Systems (ATS),√¢‚Ç¨ÔøΩ which help electronically filter through candidate resumes searching for keywords, required skills, and overall competency. </span></p>
<p><span>For example, if a job required Slack as a hard skill, and you fail to mention your proficiency within your resume, your resume will automatically be sorted out of potential applicants immediately. </span></p>
<p><span>That being said, making a point to highlight your skills effectively is essential to passing through the ATS successfully. </span><span>√Ç&nbsp;</span></p>
<p><span>Keep in mind that hiring managers are sent hundreds to thousands of resumes per job advertisement. After making it through the ATS, your resume will have approximately 6-8 seconds to prove your worth. </span></p>
<p><span>This means that you should ensure it looks professional and highlights the key information in bite-size pieces for quick reading and digestion. Your goal is to provide information and make the hiring process as painless as possible for the employer. </span></p>
<p><span>The following part of this article will walk you through several suggestions to better your skills section so that it will pass inspection and highlights you as a strong and capable candidate for the jobs you are applying. </span></p>
<p><span>These suggestions are: (1) Do not list given skills, (2) Spotlight key skills, and (3) Highlight your knowledge by separating hard and soft skills. </span></p>
<p><span>By incorporating these 3 modifications to your resume, you√¢‚Ç¨‚Ñ¢ve already created a great start to passing through the ATS and getting the hiring managers√¢‚Ç¨‚Ñ¢ attention. </span></p>
<h2><span>Tip #1: Do not list given skills</span></h2>
<p><span>It√¢‚Ç¨‚Ñ¢s in our nature to want to name each and every skill we have in order to show that we are qualified, if not overqualified, candidates. Though this approach worked in the past, now it√¢‚Ç¨‚Ñ¢s more necessary to omit skills that would be assumed. </span></p>
<p><span>For example, previously it was necessary to indicate proficiency with technical skills including Microsoft Office and Google, however, now it seems redundant. In today√¢‚Ç¨‚Ñ¢s technical climate, it is assumed that all applicants applying for positions have these commonplace skills. </span></p>
<p><span>Keep in mind that your goal of listing skills is to showcase your attributes, not bog down the hiring manager with information they already assume to know. </span></p>
<h2><span>Tip #2: Spotlight √¢‚Ç¨≈ìkey√¢‚Ç¨ÔøΩ skills</span></h2>
<p><span>The next suggestion is to spotlight √¢‚Ç¨≈ìkey√¢‚Ç¨ÔøΩ skills on each resume. This means that when applying to multiple jobs, ensure that you are adjusting your skills section based on the needs of the individual job. </span></p>
<p><span>It√¢‚Ç¨‚Ñ¢s a great idea to use keywords and specific skills from the job description itself. If a requirement or specific responsibility is listed or has an apparent theme throughout the job description, use your skill section to highlight your ability to accomplish those tasks. </span></p>
<p><span>An effective way of doing this would be to rephrase their needs into your own voice and then adding that to your resume. For example, if the job description stated, √¢‚Ç¨≈ìa strong background in CRM systems,√¢‚Ç¨ÔøΩ you could add, √¢‚Ç¨≈ìProficient with CRM system,√¢‚Ç¨ÔøΩ within your skills section. </span></p>
<p><span>However, avoid copying and pasting only the skills outlined in the job description, as this could be seen as unimaginative and hurt your chances of candidacy. </span></p>
<h2><span>Tip #3: Emphasize the difference between soft skills and hard skills.</span></h2>
<p><span>Previously, it was simple to add a single skills section and be content with your resume. Now, it is necessary to emphasize both hard and soft skills. </span></p>
<p><span>Hard and soft skills are equally important to create a compelling resume. An ideal way to include both skills is to create two separate lists. This allows for a hiring manager to easily read through both skillsets. </span></p>
<p><span>Remember, you have 6-8 seconds to convince the hiring manager that you√¢‚Ç¨‚Ñ¢re a worthy candidate for the job. </span></p>
<p><span>In order to ensure balance across your resume, try to keep the number of skills on each list the same. For example, if you have 5 hard skills, ensure that you have 5 soft skills too. </span></p>
<h2><span>In Conclusion</span></h2>
<p>This article highlights 3 suggestions that you can incorporate into your skill section to make your resume stand out from others.</p>
<p>This includes: (1) do not list given or assumed skills, (2) take time to spotlight √¢‚Ç¨≈ìkey√¢‚Ç¨ÔøΩ skills, especially those that are discussed within the job description, and (3) emphasize the difference between your hard and soft skills by giving each their own section.</p>
          
        </div></div>]]>
            </description>
            <link>https://myresumeseed.com/blogs/career-insights/how-to-make-yourself-sound-better-on-your-resume</link>
            <guid isPermaLink="false">hacker-news-small-sites-23903188</guid>
            <pubDate>Tue, 21 Jul 2020 00:12:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[‚ÄòStrong Opinions, Weakly Held‚Äô Doesn't Work That Well]]>
            </title>
            <description>
<![CDATA[
Score 210 | Comments 120 (<a href="https://news.ycombinator.com/item?id=23903172">thread link</a>) | @shadowsun7
<br/>
July 20, 2020 | https://commoncog.com/blog/strong-opinions-weakly-held-is-bad/ | <a href="https://web.archive.org/web/*/https://commoncog.com/blog/strong-opinions-weakly-held-is-bad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <p>There‚Äôs a famous thinking framework by ‚Äòfuturist‚Äô, ‚Äòforecaster‚Äô, and scenario consultant Paul Saffo called ‚Äòstrong opinions, weakly held‚Äô. The phrase itself became popular in tech circles in the 2010s ‚Äî I remember reading about it on Hacker News or a16z.com or one of those thinky tech blogs around the period. It‚Äôs still rather popular today.</p><p>Saffo‚Äôs framework ‚Äî laid out in his original <a href="https://www.saffo.com/02008/07/26/strong-opinions-weakly-held/">2008 blog post</a> ‚Äî goes like this:</p><blockquote>I have found that the fastest way to an effective forecast is often through a sequence of lousy forecasts. Instead of withholding judgment until an exhaustive search for data is complete, I will force myself to make a tentative forecast based on the information available, and then systematically tear it apart, using the insights gained to guide my search for further indicators and information. Iterate the process a few times, and it is surprising how quickly one can get to a useful forecast.<p>Since the mid-1980s, my mantra for this process is ‚Äústrong opinions, weakly held.‚Äù Allow your intuition to guide you to a conclusion, no matter how imperfect ‚Äî this is the ‚Äústrong opinion‚Äù part. Then ‚Äì and this is the ‚Äúweakly held‚Äù part ‚Äì prove yourself wrong. Engage in creative doubt. Look for information that doesn‚Äôt fit, or indicators that pointing in an entirely different direction. Eventually your intuition will kick in and a new hypothesis will emerge out of the rubble, ready to be ruthlessly torn apart once again. You will be surprised by how quickly the sequence of faulty forecasts will deliver you to a useful result.</p><p>This process is equally useful for evaluating an already-final forecast in the face of new information. It sensitizes one to the weak signals of changes coming over the horizon and keeps the hapless forecaster from becoming so attached to their model that reality intrudes too late to make a difference.</p><p>More generally, ‚Äústrong opinions weakly held‚Äù is often a useful default perspective to adopt in the face of any issue fraught with high levels of uncertainty, whether one is venturing a forecast or not. Try it at a cocktail party the next time a controversial topic comes up; it is an elegant way to discover new insights ‚Äî and duck that tedious bore who loudly knows nothing but won‚Äôt change their mind!</p></blockquote><p>On the face of it, it all sounds very reasonable and smart. And ‚Äòstrong opinions weakly held‚Äô is such a catchy phrase ‚Äî which probably explains its popularity.</p><p>The only problem with it is that it doesn‚Äôt seem to work that well.</p><h2 id="swimming-upstream-against-the-architecture-of-the-mind">Swimming Upstream Against the Architecture Of The Mind</h2><p>How do I know that it doesn‚Äôt work that well? I know this because I‚Äôve tried. I tried to use Saffo‚Äôs framework in the years between 2013 and 2016, and when I was running my previous company I attempted it with my boss, whenever we convened to <a href="https://commoncog.com/blog/what-uncertainty-feels-like/">discuss company strategy</a>.</p><p>Eventually I read Phillip Tetlock‚Äôs <a href="https://commoncog.com/blog/the-forecasting-series/"><em>Superforecasting</em></a>, and then I gave up on ‚ÄòStrong Opinions, Weakly Held‚Äô.</p><p>Why does the framework not work very well? From experience, Saffo‚Äôs approach fails in two ways.</p><p>The first way is if the person <em>hasn‚Äôt</em> read Saffo‚Äôs original post. This is, to be fair, most of us ‚Äî Saffo‚Äôs original idea is so quotable it has turned into a memetic phenomenon, and I‚Äôve seen it cited in fields far outside tech. In such cases, the failure mode is that ‚ÄòStrong Opinions, Weakly Held‚Äô turns into ‚ÄòStrong Opinions, Justified Loudly, Until Evidence Indicates Otherwise, At Which Point You Invoke It To Protect Your Ass.‚Äô</p><p>In simpler terms, ‚Äòstrong opinions, weakly held‚Äô sometimes becomes a license to hold on to a bad opinion strongly, with downside protection, against the spirit and intent of Saffo‚Äôs original framework.</p><p>Now, you might say that this is through no fault of Saffo‚Äôs, and is instead the problem of popularity. But my response is that if an idea has certain affordances, and people seem to always grab onto those affordances and abuse the idea in the exact same ways, then <em>perhaps you shouldn‚Äôt use the idea in the first place.</em> This is especially true ‚Äî as we‚Äôre about to see ‚Äî if there are better ideas out there.</p><p>The second form of failure is if the person has taken the time to look up the original intention of the phrase. In this situation, the failure mode is when you attempt to integrate new information into your judgment. Saffo‚Äôs framework offers no way for us to do this.</p><p>Here‚Äôs an example. Let‚Äôs say that you‚Äôve decided, along with your boss, to build a particular type of product for a particular subsection of the self-service checkout market. You both come to the opinion that this subsection is the best entry-point to the industry: it is relatively lucrative, and you think that it is the easiest customer segment to service.</p><p>What happens to your opinion when you <em>slowly</em> discover that the subsegment is overcrowded? Of course, you don‚Äôt find out immediately ‚Äî what happens instead is that you spot little hints, spread over the course of a couple of months, that many competitors are entering the market at the same time. These are tiny things like competitor brochures lying in the corner table of a client‚Äôs office, or pronouncements by industry groups that ‚Äúthey are looking to engage vendors for large deployments‚Äù, and then much later, clearer evidence in the form of increased competition in deals.</p><p>‚ÄúWell,‚Äù I can hear you say, ‚Äú‚ÄòStrong opinions weakly held‚Äô means that you should change your opinion when you encounter these tiny hints!‚Äù</p><p>But at which point do you change your mind? At which point do you switch away from your strong opinion? At which point do you think that it‚Äôs time to reconsider your approach?</p><p>The problem, of course, is that <em>this is not how the human brain works.</em></p><p>Both forms of failure stem from the same tension. It‚Äôs easy to have strong opinions and hold on to them strongly. It‚Äôs easy to have weak opinions and hold on to them weakly. But it is quite difficult for the human mind to vacillate between one strong opinion to another.</p><p>I don‚Äôt mean to say that people <em>can‚Äôt</em> do this ‚Äî only that it is very difficult to do so. For instance, Steve Jobs was famous for arguing against one position or another, only to decide that you were right, and then come back a month later holding exactly your opinion, as if it were his all along.</p><p>But most people aren‚Äôt like Jobs. Psychologist Amos Tversky used to joke that by default, human brains fall back to ‚Äúyes I believe that, no I don‚Äôt believe that, and maybe‚Äù ‚Äî a three-dial setting when it comes to uncertainty. People then hold on to their opinion for as long as their internal narratives allow them to. Saffo‚Äôs thinking framework implies that you sit in ‚Äòyes I believe that‚Äô territory, and then rapidly switch away to ‚Äòmaybe‚Äô or to ‚Äòno‚Äô, depending on the information you receive.</p><p>Perhaps you may ‚Äî like Jobs! ‚Äî be able to do this. But if you are like most people, the attempt will feel a lot like whiplash.</p><p>So, you might ask, what to do instead?</p><h2 id="use-probability-as-an-expression-of-confidence">Use Probability as an Expression of Confidence</h2><p>The gentler answer lies in <em>Superforecasting.</em> In the book, Tetlock presents an analytical framework that is easier to use than Saffo‚Äôs, while achieving many of the same goals.</p><ol><li>When forming an opinion, phrase it in a way that is very clear, and may be verified by a particular date.</li><li>Then state the probability you are confident that it is correct.</li></ol><p>For instance, you may say ‚ÄúI believe that Tesla will go bankrupt by 31 December 2021, and I am about 76% confident that this is the case.‚Äù Or you can be slightly sloppier with the technique ‚Äî with my boss, I would say: ‚ÄúI think this subsegment is a good market to enter, and I think we would know if this is true within four months. I believe this on the order of 70% ish. Let‚Äôs check back in September.‚Äù</p><p>(My boss was an ex-investment banker, so he took to this like a duck to water.)</p><p>Tetlock‚Äôs stated technique was developed in the context of a geopolitical forecasting tournament called the Good Judgment Project. In 2016, when I read <em>Superforecasting</em> for the first time, I remember thinking that geopolitical forecasting wasn‚Äôt particularly relevant to my job running an engineering office in Vietnam. But I also glommed onto the book‚Äôs <a href="https://commoncog.com/blog/how-the-superforecasters-do-it/">ideas around analysis</a>, because it was too attractive to ignore.</p><p>The truth is that Tetlock‚Äôs ideas are not unique to his research group. Annie Duke‚Äôs <em><a href="https://www.goodreads.com/book/show/35957157-thinking-in-bets">Thinking in Bets</a></em> proposes the same approach, but drawn from poker, and the ‚Äòrationalist‚Äô community <a href="https://www.lesswrong.com/">LessWrong</a> has long-held norms around stating the confidence of their opinions.</p><p>More importantly, Duke and LessWrong have both discovered that the <em>fastest</em> way to provoke such nuanced thinking is to ask: ‚ÄúAre you willing to bet on that? What odds would you take, and how much?‚Äù</p><p>You‚Äôd be surprised by how effective this question is.</p><p>Why is it so effective? Why does it succeed where ‚ÄòStrong Opinions, Weakly Held‚Äô does not?</p><p>The answer lies in the ‚Äòstrong opinion‚Äô portion of the phrase. First: by forcing you to state your opinion as a probability judgment ‚Äî that is, a percentage ‚Äî you are forced to calibrate the strength of your belief. This makes it easier to move away from it. In other words, you are forced to let go of the ‚Äòyes, no, maybe‚Äô dial in your head.</p><p>Second: by framing it as a bet, you suddenly have skin in the game, and are motivated to get things right.</p><p>Of course, you don‚Äôt actually <em>have</em> to bet ‚Äî you can merely propose the bet as a thinking frame. Later, as new information trickles in, you are allowed to update the % confidence you have in your belief. This allows you to see the world in shades of grey; it also allows you to communicate that confidence to those around you.</p><h2 id="revisiting-the-hierarchy-of-practical-evidence">Revisiting The Hierarchy of Practical Evidence</h2><p>I have one final point to make about this approach.</p><p>Long term readers of this blog would know that my shtick is ‚Äúapply a technique to my career or to my life, over the period of a couple of months, and report on its efficacy.‚Äù Over time, I‚Äôve noticed that techniques are more likely to be effective when they come from believable practitioners. This is what led to my <a href="https://commoncog.com/blog/the-hierarchy-of-practical-evidence/">Hierarchy of Practical Evidence</a>.</p><p>Saffo‚Äôs and Tetlock‚Äôs ‚Ä¶</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://commoncog.com/blog/strong-opinions-weakly-held-is-bad/">https://commoncog.com/blog/strong-opinions-weakly-held-is-bad/</a></em></p>]]>
            </description>
            <link>https://commoncog.com/blog/strong-opinions-weakly-held-is-bad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23903172</guid>
            <pubDate>Tue, 21 Jul 2020 00:08:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Three Architectures for a Responsive IDE]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23903131">thread link</a>) | @ubolonton_
<br/>
July 20, 2020 | https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html | <a href="https://web.archive.org/web/*/https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>The first architecture is reminiscent of the map-reduce paradigm.
The idea is to split analysis into relatively simple indexing phase, and a separate full analysis phase.</p>
<p>The core constraint of indexing is that it runs on a per-file basis.
The indexer takes the text of a single file, parses it, and spits out some data about the file.
The indexer can‚Äôt touch other files.</p>
<p>Full analysis can read other files, and it leverages information from the index to save work.</p>
<p>This all sounds way too abstract, so let‚Äôs look at a specific example‚Äâ‚Äî‚ÄâJava.
In Java, each file starts with a package declaration.
The indexer concatenates the name of the package with a class name to get a fully-qualified name (FQN).
It also collects the set of methods declared in the class, the list of superclasses and interfaces, etc.</p>
<p>Per-file data is merged into an index which maps FQNs to classes.
Note that constructing this mapping is an embarrassingly parallel task‚Äâ‚Äî‚Äâall files are parsed independently.
Moreover, this map is cheap to update.
When a file change arrives, this file‚Äôs contribution from the index is removed, the text of the file is changed and the indexer runs on the new text and adds the new contributions.
The amount of work to do is proportional to the number of changed files, and is independent from the total number of files.</p>
<p>Let‚Äôs see how FQN index can be used to quickly provide completion.</p>
<div>
<div>
<pre><code data-lang="java"><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
</pre></td><td><pre><span>// File ./mypackage/Foo.java</span>
<span>package</span> <span>mypackage</span><span>;</span>

<span>import</span> <span>java.util.*</span><span>;</span>

<span>public</span> <span>class</span> <span>Foo</span> <span>{</span>
    <span>public</span> <span>static</span> <span>Bar</span> <span>f</span><span>()</span> <span>{</span>
        <span>return</span> <span>new</span> <span>Bar</span><span>();</span>
    <span>}</span>
<span>}</span>

<span>// File ./mypackage/Bar.java</span>
<span>package</span> <span>mypackage</span><span>;</span>

<span>public</span> <span>class</span> <span>Bar</span> <span>{</span>
    <span>public</span> <span>void</span> <span>g</span><span>()</span> <span>{}</span>
<span>}</span>

<span>// File ./Main.java</span>
<span>import</span> <span>mypackage.Foo</span><span>;</span>

<span>public</span> <span>class</span> <span>Main</span> <span>{</span>
    <span>public</span> <span>static</span> <span>void</span> <span>main</span><span>(</span><span>String</span><span>[]</span> <span>args</span><span>)</span> <span>{</span>
        <span>Foo</span><span>.</span><span>f</span><span>().</span>
    <span>}</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>The user has just typed <code>Foo.f().</code>, and we need to figure out that the type of receiver expression is <code>Bar</code>, and suggest <code>g</code> as a completion.</p>
<p>First, as the file <code>Main.java</code> is modified, we run the indexer on this single file.
Nothing has changed (the file still contains the class <code>Main</code> with a static <code>main</code> method), so we don‚Äôt need to update the FQN index.</p>
<p>Next, we need to resolve the name <code>Foo</code>.
We parse the file, notice an <code>import</code> and look up <code>mypackage.Foo</code> in the FQN index.
In the index, we also find that <code>Foo</code> has a static method <code>f</code>, so we resolve the call as well.
The index also stores the return type of <code>f</code>, but, and this is crucial, it stores it as a string <code>"Bar"</code>, and not as a direct reference to the class <code>Bar</code>.</p>
<p>The reason for that is <code>import java.util.*</code> in <code>Foo.java</code>.
<code>Bar</code> can refer either to <code>java.util.Bar</code> or to <code>mypackage.Bar</code>.
The indexer doesn‚Äôt know which one, because it can look <strong>only</strong> at the text of <code>Foo.java</code>.
In other words, while the index does store the return types of methods, it stores them in an unresolved form.</p>
<p>The next step is to resolve the identifier <code>Bar</code> in the context of <code>Foo.java</code>.
This uses the FQN index, and lands in the class <code>mypackage.Bar</code>.
There the desired method <code>g</code> is found.</p>
<p>Altogether, only three files were touched during completion.
The FQN index allowed us to completely ignore all the other files in the project.</p>
<p>One problem with the approach described thus far is that resolving types from the index requires a non-trivial amount of work.
This work might be duplicated if, for example, <code>Foo.f</code> is called several times.
The fix is to add a cache.
Name resolution results are memoized, so that the cost is paid only once.
The cache is blown away completely on any change‚Äâ‚Äî‚Äâwith an index, reconstructing the cache is not that costly.</p>
<p>To sum up, the first approach works like this:</p>
<div>
<ol>
<li>
<p>Each file is being indexed, independently and in parallel, producing a "stub"‚Äâ‚Äî‚Äâa set of visible top-level declarations, with unresolved types.</p>
</li>
<li>
<p>All stubs are merged into a single index data structure.</p>
</li>
<li>
<p>Name resolution and type inference work primarily off the stubs.</p>
</li>
<li>
<p>Name resolution is lazy (we only resolve a type from the stub when we need it) and memoized (each type is resolved only once).</p>
</li>
<li>
<p>The caches are completely invalidated on every change</p>
</li>
<li>
<p>The index is updated incrementally:</p>
<div>
<ul>
<li>
<p>if the edit doesn‚Äôt change the file‚Äôs stub, no change to the index is required.</p>
</li>
<li>
<p>otherwise, old keys are removed and new keys are added</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<p>Note an interesting interplay between "dumb" indexes which can be updated incrementally, and "smart" caches, which are re-computed from scratch.</p>
<p>This approach combines simplicity and stellar performance.
The bulk of work is the indexing phase, and you can parallelize and even distribute it across several machine.
Two examples of this architecture are <a href="https://www.jetbrains.com/idea/">IntelliJ</a> and <a href="https://sorbet.org/">Sorbet</a>.</p>
<p>The main drawback of this approach is that it works only when it works‚Äâ‚Äî‚Äânot every language has a well-defined FQN concept.
I think overall it‚Äôs a good idea to design name resolution and module systems (mostly boring parts of a language) such that they work well with the map-reduce paradigm.</p>
<div>
<ul>
<li>
<p>Require <code>package</code> declarations or infer them from the file-system layout</p>
</li>
<li>
<p>Forbid meta-programming facilities which add new top-level declarations, or restrict them in such way that they can be used by the indexer.
For example, preprocessor-like compiler plugins that access a single file at a time might be fine.</p>
</li>
<li>
<p>Make sure that each source element corresponds to a single semantic element.
For example, if the language supports conditional compilation, make sure that it works during name resolution (like Kotlin‚Äôs <a href="https://kotlinlang.org/docs/reference/platform-specific-declarations.html">expect/actual</a>) and not during parsing (like conditional compilation in most other languages).
Otherwise, you‚Äôd have to index the same file with different conditional compilation settings, and that is messy.</p>
</li>
<li>
<p>Make sure that FQNs are enough for most of the name resolution.</p>
</li>
</ul>
</div>
<p>The last point is worth elaborating. Let‚Äôs look at the following Rust example:</p>
<div>
<div>
<pre><code data-lang="rust"><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
</pre></td><td><pre><span>// File: ./foo.rs</span>
<span>trait</span> <span>T</span> <span>{</span>
    <span>fn</span> <span>f</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>{}</span>
<span>}</span>
<span>// File: ./bar.rs</span>
<span>struct</span> <span>S</span><span>;</span>

<span>// File: ./somewhere/else.rs</span>
<span>impl</span> <span>T</span> <span>for</span> <span>S</span> <span>{}</span>

<span>// File: ./main.s</span>
<span>use</span> <span>foo</span><span>::</span><span>T</span><span>;</span>
<span>use</span> <span>bar</span><span>::</span><span>S</span>

<span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>let</span> <span>s</span> <span>=</span> <span>S</span><span>;</span>
    <span>s</span><span>.f</span><span>();</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>Here, we can easily find the <code>S</code> struct and the <code>T</code> trait (as they are imported directly).
However, to make sure that <code>s.f</code> indeed refers to <code>f</code> from <code>T</code>, we also need to find the corresponding <code>impl</code>, and that can be roughly anywhere!</p>
</div></div>]]>
            </description>
            <link>https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23903131</guid>
            <pubDate>Mon, 20 Jul 2020 23:59:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Detto ‚Äì Sync two objects data structure by Proxy feature]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23902820">thread link</a>) | @iendeavor
<br/>
July 20, 2020 | https://iendeavor.nctu.me/detto/ | <a href="https://web.archive.org/web/*/https://iendeavor.nctu.me/detto/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

      

<p><a href="https://badge.fury.io/js/detto"><img src="https://badge.fury.io/js/detto.svg" alt="npm version"></a>
<a href="https://github.com/iendeavor/detto/actions"><img src="https://github.com/iendeavor/detto/workflows/CI/badge.svg" alt="CI"></a>
<a href="https://coveralls.io/github/iendeavor/detto?branch=develop"><img src="https://coveralls.io/repos/github/iendeavor/detto/badge.svg?branch=develop" alt="Coverage Status"></a>
<a href="https://bundlephobia.com/result?p=detto"><img src="https://badgen.net/bundlephobia/minzip/detto" alt="gzip"></a></p>

<p><a href="https://codesandbox.io/s/detto-playground-68441">Playground</a></p>



<p>Clone Data Structure Based on Proxy.</p>

<p>Wrap Anything in Clone.</p>

<p>Observe Data Change.</p>

<p>Array Manipulations (push, pop, shift, unshift, splice, reverse) Support.</p>

<p>Zero Dependencies, Native Javascript only.</p>





<div><div><pre><code><span>&lt;script </span><span>src=</span><span>"https://unpkg.com/detto/dist/detto.iife.js"</span><span>&gt;&lt;/script&gt;</span>
</code></pre></div></div>



<div><div><pre><code><span>const</span> <span>object</span> <span>=</span> <span>{</span>
  <span>deep</span><span>:</span> <span>{</span>
    <span>nested</span><span>:</span> <span>123</span><span>,</span>
  <span>},</span>
<span>}</span>

<span>const</span> <span>detto</span> <span>=</span> <span>{}</span>

<span>// wrap your values in here</span>
<span>const</span> <span>wrap</span> <span>=</span> <span>(</span><span>object</span><span>,</span> <span>detto</span><span>,</span> <span>path</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>Object</span><span>.</span><span>defineProperty</span><span>(</span><span>detto</span><span>,</span> <span>'</span><span>path</span><span>'</span><span>,</span> <span>{</span>
    <span>configurable</span><span>:</span> <span>true</span><span>,</span>
    <span>writable</span><span>:</span> <span>true</span><span>,</span>
    <span>value</span><span>:</span> <span>path</span><span>,</span>
  <span>})</span>
<span>}</span>

<span>// watch data changing</span>
<span>const</span> <span>callback</span> <span>=</span> <span>changedDetto</span> <span>=&gt;</span> <span>console</span><span>.</span><span>log</span><span>(</span><span>changedDetto</span><span>.</span><span>path</span><span>)</span>

<span>const</span> <span>proxiedObject</span> <span>=</span> <span>Detto</span><span>.</span><span>proxy</span><span>({</span> <span>object</span><span>,</span> <span>detto</span><span>,</span> <span>wrap</span><span>,</span> <span>callback</span> <span>})</span>
<span>// &gt; []</span>
<span>// &gt; ['deep']</span>
<span>// &gt; ['deep', 'nested']</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>detto</span><span>))</span>
<span>// &gt; {"deep":{"nested":{}}}</span>

<span>proxiedObject</span><span>.</span><span>deep</span><span>.</span><span>nested</span> <span>=</span> <span>{</span> <span>key</span><span>:</span> <span>123</span> <span>}</span>
<span>// &gt; ['deep', 'nested']</span>
<span>// &gt; ['deep', 'nested', 'key']</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>detto</span><span>))</span>
<span>// &gt; {"deep":{"nested":{"key":{}}}}</span>

<span>proxiedObject</span><span>.</span><span>deep</span><span>.</span><span>nested</span> <span>=</span> <span>{}</span>
<span>// &gt; ['deep', 'nested']</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>detto</span><span>))</span>
<span>// &gt; {"deep":{"nested":{}}}</span>

<span>delete</span> <span>proxiedObject</span><span>.</span><span>deep</span>
<span>// &gt; []</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>detto</span><span>))</span>
<span>// &gt; {}</span>
</code></pre></div></div>



<p>Please read <a href="https://iendeavor.nctu.me/detto/CONTRIBUTING.md">CONTRIBUTING.md</a> for details on our code of conduct, and the process for submitting pull
requests to us.</p>



<p>We use <a href="https://semver.org/">SemVer</a> for versioning. For the versions available, see the tags on this repository.</p>



<p>This project is licensed under the MIT License - see the <a href="https://iendeavor.nctu.me/detto/LICENSE">LICENSE</a> file for details</p>


      
      
      
    </div></div>]]>
            </description>
            <link>https://iendeavor.nctu.me/detto/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23902820</guid>
            <pubDate>Mon, 20 Jul 2020 23:07:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Certificate Transparency: a bird's-eye view]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23902730">thread link</a>) | @fanf2
<br/>
July 20, 2020 | https://emilymstark.com/2020/07/20/certificate-transparency-a-birds-eye-view.html | <a href="https://web.archive.org/web/*/https://emilymstark.com/2020/07/20/certificate-transparency-a-birds-eye-view.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Certificate Transparency (CT) is a still-evolving technology for detecting
incorrectly issued certificates on the web. It‚Äôs cool and interesting, but
complicated. I‚Äôve given talks about CT, I‚Äôve worked on Chrome‚Äôs CT
implementation, and I‚Äôm actively involved in tackling ongoing deployment
challenges ‚Äì even so, I still sometimes lose track of how the pieces fit
together. I find it easy to forget how the system defends against particular
attacks, or what the purpose of some particular mechanism is.</p>

<p>The goal of this post is to build up a high-level description of CT from
scratch, explaining why all the pieces are the way they are and how they fit
together. A lot of this material is drawn from a
<a href="https://web.stanford.edu/class/cs253/lectures/Lecture%2012.pdf">guest lecture</a>
I gave with my colleague <a href="http://noncombatant.org/">Chris Palmer</a> as part of a
Stanford web security course (CT portion starts at slide 52).</p>

<h2 id="why-ct">Why CT?</h2>

<p>Certificate authorities (CAs) are the organizations that browsers trust to issue
certificates for domain names after checking that the person receiving the
certificate really does own their domain. CAs can be companies and governments
or the occasional non-profit. It‚Äôs fairly common for CAs to issue bad
certificates. Like any organization, sometimes CAs make mistakes, and sometimes
they are compromised or malicious. And sometimes certificates are issued
improperly without the CA doing anything wrong at all: a rogue insider, BGP
hijacker, or hapless vendor might request a certificate for a domain they do not
own.</p>

<p>The security community has invented various mechanisms to prevent browsers from
accepting these ‚Äúmisissued‚Äù certificates. For example, server operators could
once use
<a href="https://en.wikipedia.org/wiki/HTTP_Public_Key_Pinning">public key pinning</a> to
limit the CAs that could issue certificates for their domains, so that not just
any CA compromise would put them at risk. (Unfortunately, pinning turned out to
be a giant footgun, never gained widespread adoption, and is currently dying a
slow death.)</p>

<p>Preventing browsers from accepting misissued certificates is only one part of
the puzzle, though. It‚Äôs also important to detect misissued certificates. For
example, in 2011, an attacker hacked the
<a href="https://en.wikipedia.org/wiki/DigiNotar#Issuance_of_fraudulent_certificates">DigiNotar</a>
CA and improperly issued a wildcard google.com certificate, which they used to
target victims in Iran. While the Google Chrome browser didn‚Äôt accept the
certificate due to public key pinning, Google only
<a href="https://slate.com/technology/2016/12/how-the-2011-hack-of-diginotar-changed-the-internets-infrastructure.html">found out</a>
about the attack by chance because a user posted about the error on a help
forum. This was a close call: would anyone have ever learned about this attack
if that one user hadn‚Äôt happened to report it?</p>

<p>Thus was born the desire for a technical means of detecting misissued
certificates. If a domain owner can detect an unauthorized certificate for their
domain, they can revoke<sup id="fnref:1"><a href="#fn:1">1</a></sup> the misissued certificate. If the misissuance happened
because a CA misbehaved, the domain owner can report the incident to a browser
or OS vendor, who might choose to no longer trust the CA to issue certificates.</p>

<p>An unauthorized certificate for a domain isn‚Äôt the only type of misissuance. CAs
might create certificates that are bad because they use outdated cryptographic
algorithms, violate rules like the maximum lifetime of a certificate or specific
encodings that are supposed to be used, etc. If browser vendors could detect
these types of misissuances (which are not necessarily malicious, but signs of
bad hygiene), they could ask the CAs to fix these problems or even remove trust
in them if appropriate.</p>

<h2 id="a-strawperson-and-a-slightly-less-strawperson">A strawperson and a slightly-less-strawperson</h2>

<p>The very simplest attempt to allow detection of bad certificates would be to
require that CAs publish a list of every certificate they issue. They could
either directly publish their certificates themselves, or forward them to some
other service that publishes them. Domain owners could monitor every CA‚Äôs
published certificates for unauthorized certificates, and browser
vendors/researchers/etc. could monitor each CA for bad hygiene.</p>

<p>But the root problem we are trying to solve is that CAs might be compromised,
malicious, or error-prone, so we can‚Äôt just rely on CAs to publish their own
issuances. An evil CA issuing an evil certificate would simply not publish that
certificate.</p>

<p>In a slightly more robust system, CAs could submit each issued certificate to a
publisher. The publisher would return a signature on the certificate, and
provide a publicly accessible feed of certificates that it has seen. Browsers
would only accept certificates that come with a signature from a trusted
publisher. This is a little closer to what CT looks like, but there are still a
number of problems to solve.</p>

<h2 id="signed-certificate-timestamps">Signed Certificate Timestamps</h2>

<p>One minor wrinkle with this publisher signature system is that it takes time for
the CA to submit each certificate to these publishers and verify that it got
logged before issuing the certificate. (As will become clear later on, logging a
certificate can require operations on a large data structure and global write
consensus, which can take minutes or hours.) CAs don‚Äôt want other services‚Äô
potentially slow operations in the critical path of certificate issuance, which
is their core money-making business operation ‚Äì and their customers don‚Äôt want
this slowdown either, since some web servers rely on fast certificate issuance
to meet business and uptime requirements. So in CT, a signature from one of
these publishers (which is called a CT log) does not actually guarantee that the
log has published the certificate. Instead, the log issues a Signed Certificate
Timestamp (SCT), which is a signed statement that the log has seen the
certificate and promises to publish it within 24 hours of the timestamp it
provides.</p>

<h2 id="trusted-logs"><em>Trusted</em> logs?</h2>

<p>So far, the system we‚Äôve built up is as follows: CAs submit certificates to logs
as they are issued, and the logs return SCTs promising to publish the
certificate within 24 hours. Browsers don‚Äôt accept certificates unless they come
with SCTs from trusted logs. Interested parties, such as domain owners or
researchers, can monitor the data that the logs publish for malicious
certificates.</p>

<p>Now the key question is: why should we trust logs? If a CA could be compromised,
malicious, or error-prone, why couldn‚Äôt a log be compromised, malicious, or
error-prone too? One could even imagine a log and CA colluding to issue evil
certificates. The designers of CT wanted logs to be untrusted, and this is how
CT gets complicated.</p>

<p>As a simple way to remove trust from the logs, browsers could require multiple
SCTs from different logs per certificate. With this policy, an attacker would
have to compromise multiple logs to prevent an evil certificate from being
published by any of them. In practice, though, it‚Äôs difficult to say what
constitutes distinct logs. If the same organization controls multiple logs and
is colluding with the attacker, a multiple-log policy doesn‚Äôt help. Chrome
currently deploys CT with a ‚ÄúOne Google, One Non-Google‚Äù policy: each
certificate must come with at least one SCT from a Google-operated log and one
from a non-Google-operated log, on the premise that it would be difficult for an
attacker to compromise two such logs. This policy, however, was always meant as
a temporary measure until something more technically sound and organizationally
neutral could be put into place.</p>

<p>To understand how to remove trust from the logs in a more technically sound way,
we need to think about a deep question: what does it actually technically mean
to ‚Äúpublish‚Äù a certificate? Each log has an API endpoint that produces a feed of
certificates ‚Äì but, intuitively, providing the certificate on that endpoint to
one client at one particular point in time is not sufficient to have ‚Äúpublished‚Äù
the certificate. To truly publish the certificate, that endpoint must provide
the certificate to anyone querying it at any time after the log signed an SCT
for the certificate. To verify that the log has truly published the certificate,
we need everyone to efficiently check with everyone else that they‚Äôve seen the
certificate in the feed they‚Äôve received from that endpoint. ‚ÄúEveryone‚Äù here
includes end-user devices that are validating TLS certificates, as well as
researchers, browser vendors, domain owners, and anyone else who is interested
in monitoring a log‚Äôs feed to look for misissued certificates.</p>

<p>Of course, it‚Äôs not practical to ask everyone to maintain the list of all
certificates that each log publishes and check with each other to compare that
the entire sequence matches. That could be billions of devices each maintaining
sets of millions or billions of certificates. Furthermore, some of these
entities might be interested in only a very small subset of certificates; for
example, a domain owner is only interested in monitoring for misissued
certificates for their own domain, and has no interest in doing a lot of work to
help other entities verify that unrelated certificates were properly published.</p>

<p>Imagine that the log could produce a short summary of the sequence of
certificates that it has published. The summary is like a cryptographic hash: if
you can provide a sequence of certificates that produces a given summary, then
it‚Äôs infeasible to find any other sequence that produces the same summary.
Unlike a vanilla cryptographic hash, these summaries have two special
properties:</p>

<ol>
  <li>If the log produces a summary, it can then add more certificates and produce
an updated summary, and efficiently prove that these two summaries are
consistent with each other, i.e. the latter summary‚Äôs underlying sequence of
certificates is a supersequence of the former‚Äôs.</li>
  <li>After adding a certificate, when asked for a current summary of the
certificates it has published, the log can provide an efficient proof that
the summary contains that certificate.</li>
</ol>

<p>This magical summary is all the state that anyone observing the log needs to
keep to be able to verify with everyone else that the certificates they care
about have been published. For example, a web browser validating a TLS
certificate can request a summary and a proof ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://emilymstark.com/2020/07/20/certificate-transparency-a-birds-eye-view.html">https://emilymstark.com/2020/07/20/certificate-transparency-a-birds-eye-view.html</a></em></p>]]>
            </description>
            <link>https://emilymstark.com/2020/07/20/certificate-transparency-a-birds-eye-view.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23902730</guid>
            <pubDate>Mon, 20 Jul 2020 22:51:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Security incident on DeepSource‚Äôs GitHub application]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23902716">thread link</a>) | @acallaghan
<br/>
July 20, 2020 | https://discuss.deepsource.io/t/security-incident-on-deepsource-s-github-application/131 | <a href="https://web.archive.org/web/*/https://discuss.deepsource.io/t/security-incident-on-deepsource-s-github-application/131">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
          <p>On July 11th, around 5AM UTC, DeepSource was notified by the GitHub Security Team that they were tracking potentially malicious activity related to the DeepSource Github application.</p>
<p>The GitHub Security team had observed a large number of requests from unusual IP addresses for many distinct DeepSource users starting in mid-June, which stood out as anomalous. At this time, GitHub wasn‚Äôt sure about the source of the compromise.</p>
<p>By 7AM UTC, we had rotated all user tokens, client secrets and private keys. Since we didn‚Äôt know the origin of the attack, we also rotated all credentials and keys of employees who had access to production systems. Through internal investigation, we have not identified any unusual breach or behaviour, and have concluded that the DeepSource infrastructure has not been breached.</p>
<p>On July 16, 2020 around 1:45 AM UTC, GitHub Security team got back to us with more information that could help identify the source of compromise. One of our employee‚Äôs GitHub account was compromised by the <a href="https://github.blog/2020-04-14-sawfish-phishing-campaign-targets-github-users/">Sawfish phishing campaign</a> that targeted GitHub users - and the attacker gained access to DeepSource GitHub app‚Äôs credentials.</p>
<p>Unfortunately, GitHub‚Äôs privacy policy prevents them from sharing the affected user list with us, so we are disclosing this issue publicly while waiting for GitHub to complete their investigation. Our understanding is GitHub will notify the directly affected users as per their policies. You should visit <a href="https://support.github.com/contact?subject=GH-0000502-3963-3+Log+Request&amp;tags=GH-0000502-3963-3">https://support.github.com/contact?subject=GH-0000502-3963-3+Log+Request&amp;tags=GH-0000502-3963-3</a> and request logs from GitHub regarding repository downloads and other account activity to find any suspicious activity.</p>
<p>We‚Äôre always looking for ways to improve our security. From the moment we were first notified by GitHub, we involved industry security advisors. We have formed policies to conduct periodic security training and phishing drills for all employees, and will update these policies as necessary. Additionally we have started work towards gaining the SOC 2 Type 2 compliance certification, which will provide a path for third party auditors to ensure that DeepSource‚Äôs security practice exceeds industry standards. In the near future, we will be launching a security bug bounty program to provide the best security testers in the world with a chance to probe DeepSource for any weaknesses.</p>
<p>We have always taken great care to ensure DeepSource meets the security needs of our users. While the DeepSource application itself did not suffer a weakness in this situation, we are taking the steps listed above to ensure the security of our applications, our teams, and your data.</p>
<p>We appreciate GitHub‚Äôs swift response to this issue. Comments are disabled on this post due to the sensitive nature of it. If you have any questions, please reach out to us privately at <a href="mailto:security@deepsource.io">security@deepsource.io</a> and we will assist you in every way we can.</p>
<p>Note: We‚Äôve notified all our users via e-mail with the same note on 20th July, 2020 around 10:40 PM UTC.</p>
        </div></div>]]>
            </description>
            <link>https://discuss.deepsource.io/t/security-incident-on-deepsource-s-github-application/131</link>
            <guid isPermaLink="false">hacker-news-small-sites-23902716</guid>
            <pubDate>Mon, 20 Jul 2020 22:49:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Maximum Entropy Intuition for Fundamental Statistical Distributions]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 36 (<a href="https://news.ycombinator.com/item?id=23902712">thread link</a>) | @yetanothermonk
<br/>
July 20, 2020 | https://longintuition.com/2020/07/20/max-entropy-intuition.html | <a href="https://web.archive.org/web/*/https://longintuition.com/2020/07/20/max-entropy-intuition.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Imagine you wake up tomorrow in an empty white room, <em>a la</em> The Matrix. You don‚Äôt remember how you got there. <em>Anything can happen.</em></p>

<ul>
  <li>If Keanu Reeves appears, you‚Äôd probably think this is related in some way to the Matrix.
    <ul>
      <li>If Keanu appears and then Laurence Fishburne (Morpheus) appears, you‚Äôd think‚Äîokay, this is almost definitely related to the Matrix.</li>
    </ul>
  </li>
  <li>On the other hand, if Obama and Clinton appear in your white room, in your head, you‚Äôd think, okay, the Matrix-related possibilities are less likely; the politics-related possibilities are more likely, whatever those are.</li>
</ul>

<p>For the first few seconds in that empty white room, without knowing anything, everything is pretty much equally likely to us. In statistics, we call this a <strong>uniform distribution</strong>. It‚Äôs a good starting point when we know nothing. However, once we get new information, we shift probability mass from the less likely events to the more likely events, conditional on what we‚Äôve just learned‚Äîin the Neo case, from Obama/Clinton related probabilities to Matrix-related probabilities; in the Obama/Clinton case, from Matrix-related probabilities to political event-related probabilities.</p>

<p>Often, in statistics education, we learn distributions in a vacuum of intuition. But, inevitably, we ask ourselves:</p>

<ul>
  <li>Why do we use the statistical distributions we use? For example, why is the Normal Distribution everywhere?</li>
</ul>

<p>We‚Äôll find that statistical distributions aren‚Äôt pulled out of thin air. The statistical distributions we‚Äôre most familiar with‚Äîuniform, exponential, Normal‚Äîare exactly determined when we want to maximize our information gain from very simple and very few initial constraints.</p>

<p>We‚Äôll find that we can use our intuition from the Matrix example to help us understand where these statistical distributions come from!</p>



<p>First, we need some intuition as to what expected information gain means.</p>

<p>Let‚Äôs start with the commonplace notion of an ‚Äúaverage‚Äù. The average, in mathematical terms, is a sum of the value of each event weighted by the probability of that event occurring.</p>

<p>For example, if we have a rigged die with a heavy ‚Äúsix‚Äù side, we would expect the next value to be higher than the next value if we used a fair die. The higher frequency of occurrence of sixes pulls up the <strong>expected value</strong> (also known as the <strong>average</strong>, <strong>mean</strong>, or <strong>mathematical expectation</strong>).</p>

<p>Mathematically, what happens is we weigh the value of each event by the probability of that event occurring, and the sum gets us a rough idea of where the next numerical value will land.</p><p>

\[\text{mathematical expectation} = p(x) \cdot x \text{ for all } x \\ = \sum_i p(x_i) * x_i\]

</p><p>This basic concept of weighing things by the probability of those things occurring is a very useful concept. We can also weigh the <em>information gain</em> of an event occurring by the probability of that event occurring to get an expected information value across all the events we care about. But how do we measure information gain?</p>

<p>Intuitively we know that the more surprising something is, the more information it contains. In other words, <em>the informational value of an event is proportional to all the choices it killed off by virtue of that event occurring</em>.</p>

<p>The information value of an event is related to how much probability mass it moves versus itself once that thing occurs.</p>

<h2 id="leverage-can-be-surprising">Leverage Can Be Surprising</h2>

<p>One interesting way to think about this is leverage. Roughly, leverage means how much mass you move versus your own mass. In financial markets, if you outlay $1 million for $5 million of exposure, you‚Äôre levered 5 times. For our purposes, we want a good way to formalize our intuitional understanding of information; I haven‚Äôt seen information talked about in leverage terms elsewhere and I think it‚Äôs an‚Ä¶ informative way to look at things.</p><p>

\[\text{leverage} \propto \frac{\text{exposure controlled}}{\text{initial outlay}}\]

</p><p>When we talk about ‚Äúhow much probability mass an event moves‚Äù or the amount of choices an event kills by virtue of its occurrence, this is in some sense a leverage ratio. What this looks like is the total amount of probability (normalized, we say 1, but it could just as well be some arbitrary sum, like 10000) divided by the probability of that particular event (p). The 10,000 factor cancels out when we divide the total by the individual probability, so we just get</p><p>

\[\text{info} \propto \frac{1}{p}\]

</p><p>Binary is, in a sense, the ultimate form of compression. Boiling things down to the most informative, basic essence of truth or falsity is a beautiful feature of a bit. We can count the number of bits needed to represent a value by taking its logarithm, base two, so we get</p><p>

\[\text{info} \propto \log_2{\frac{1}{p}}\]

</p><p>And if we weigh this by the probability of that particular event happening, we get</p><p>

\[\text{info} \propto p \cdot \log_2{\frac{1}{p}}\]

</p><p>And if we use the simplified version, we get</p><p>

\[\text{info} = p \cdot \log_2{\frac{1}{p}} \\ = p \cdot (\log_21 - \log_2p) \\ =-p \cdot \log_2p\]

</p><p>Awesome! We‚Äôve built the definition of informational entropy from nothing other than a‚Ä¶ bit‚Ä¶ of intuition. Similar to our understanding for the mathematical expected value of a set of events, we can talk about the mathematical expected information for a set of events.</p><p>

\[\text{mathematical information expectation} = \sum_i -p(x_i) * \log_2{p(x_i)}\]

</p><p>Why is this useful? It turns out that the major statistical distributions maximize the expected information gain subject to certain constraints (each major distribution corresponding to different constraints).</p>

<p>Stated in a different way:</p>

<p>Take that our goal is to model the probability distribution for data we‚Äôre looking at.</p>

<p>We generally know a few things about the data‚Äîthese will be our constraints‚Äîand we want to pick the probability distribution that maximizes our expected information gain (aka, maximizes our subsequent surprise, or <strong>entropy</strong>)‚Äîbecause if we had a distribution that had any less expected information gain than **the maximum entropy distribution, we‚Äôve inadvertently encoded some information extra to our constraints into our distribution.</p>

<p>So the maximum entropy distribution is the closest thing we can get to a zero-knowledge guess, subject to what we know about the data (our constraints).</p>



<p>We found at the beginning of our journey that the uniform distribution‚Äîwhere we prescribe to each event an equal amount of probability mass‚Äîmakes intuitive sense as the distribution we should pick when we don‚Äôt know anything at all. This isn‚Äôt saying that everything in reality has equal probability of occurring‚Äîa bit subtle; it‚Äôs just saying that, <em>given what we currently know</em> (assumed to be nothing), no one event is more likely than any other event.</p>

<p>What if we work from the mathematical end? What do we find if we just start out with very few, very basic assumptions and work forward?</p><p>

\[\text{information, the quantity we want to maximize: } \\ f(x)=-\int_a^b p(x) \cdot \log_2p(x)\,dx \\ \text{unity constraint: }g(x)=\int_a^b p(x)\,dx - 1 = 0\]

</p><p>In English, we want to maximize the information subject to the unity constraint, and we want to see what p(x) looks like.</p>

<p>Mathematically, we‚Äôre going to want to find the local extrema (local minima and maxima) of the information function along the unity constraint. Analogous to minimization and maximization in single-variable calculus, we want to find the points at which the derivative of our information function is zero along the constraint function. Intuitively, this should make sense‚Äîwe want the extrema, and if the slope of the information function is (for example) greater than zero along the constraint, we would just walk along that direction, increasing our expected information gain along the way, all the while getting closer to a local maximum.</p>

<p>Finding where the derivative of f is zero along g is equivalent to saying the directional derivative of f along a vector s that lies on constraint g is zero.</p>

<p>Because the directional derivative of f along that vector s is zero, we know that the projection of the gradient of f on g is zero (aka, the dot product of the gradient of f and g is zero).</p>

<p>Therefore, we know that the gradient of f is parallel to the norm of the surface of g, so the gradient of f is parallel to the gradient of g.</p>

<p>In other words, the gradient of f is some scalar multiple of the gradient of g!</p>

<p>If we find where this occurs, we‚Äôll have found the extrema.</p>

<p>If the above calc-related ideas sounds a bit unfamiliar, ping me at longintuition@protonmail.com so I know that there‚Äôs demand for me writing something on gradients.</p>

<p>Anyway, mathematically, we‚Äôre trying to do this:</p><p>

\[\nabla f(x) = a \cdot \nabla g(x)\]

</p><p>Which is equivalent to:</p><p>

\[\frac{\partial f}{\partial p(x)} = a \cdot \frac{\partial g}{\partial p(x)}\]

</p><p>Taking the derivative with respect to a function requires a bit of variational calculus, specifically the Euler Lagrange equation. Thankfully, we have some pretty easy functional derivatives here:</p><p>

\[\frac{-1-\ln(p(x))}{\ln(2)}=a \cdot 1\]

</p><p>Let‚Äôs simplify! We want to get an expression for p(x):</p><p>

\[-1-\ln(p(x))=a \cdot \ln(2) \\ 1 + \ln(p(x)) = -a \cdot \ln(2) \\ \ln(p(x)) = -1-a \cdot \ln(2) \\ \implies p(x) = e^{-1-a\ln(2)} \\ p(x) =e^{-1} \cdot e^{-a\ln(2)} \\ p(x) = e^{-1} \cdot 2^{-a}\]

</p><p>We‚Äôll plug this expression into our unity constraint:</p><p>

\[\int_a^b p(x)\,dx=1 \\ \int_a^b e^{-1} \cdot 2^{-a} \,dx = 1 \\ e^{-1} \cdot 2^{-a} \cdot \int_a^b \,dx = 1 \\ e^{-1} \cdot 2^{-a} \cdot (b-a) = 1 \\ e^{-1} \cdot 2^{-a} = \frac{1}{b-a}\]

</p><p>This looks like p(x)!</p><p>

\[p(x)=\frac{1}{b-a}\]

</p><p>which is the PDF of a continuous uniform distribution!</p>

<p>This is super promising‚Äîthe probability distribution that maximizes our surprise given we know basically nothing aside from a unity constraint is the uniform probability distribution!</p>

<p>What we‚Äôve just done is confirm mathematically a very solid intuition we explored at the beginning of the piece!</p>



<p>Very rarely do we know absolutely nothing about the data ‚Ä¶</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://longintuition.com/2020/07/20/max-entropy-intuition.html">https://longintuition.com/2020/07/20/max-entropy-intuition.html</a></em></p>]]>
            </description>
            <link>https://longintuition.com/2020/07/20/max-entropy-intuition.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23902712</guid>
            <pubDate>Mon, 20 Jul 2020 22:49:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HoloPix, the killer app on Red Hydrogen One is coming to Android]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23902660">thread link</a>) | @bgorman
<br/>
July 20, 2020 | https://www.holopix.com/android-beta/ | <a href="https://web.archive.org/web/*/https://www.holopix.com/android-beta/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><center><h4><p>Holopix for Android Closed Beta.</p></h4></center><div id="privacy"><div><div><div><div><p><strong>Leia is excited to announce Holopix for Android: a new way to discover and share Lightfield images.</strong></p><p>Holopix for Android is the same social network available on LitByLeia devices, with a few new features. You now explore Lightfield images through DepthTilt: a Leia technology that lets you move your phone to view Lightfield images from different angles.</p><p>Holopix for Android also supports the Lightfield Converter built-in, so you can upload any 2D image and have it automatically converted to Lightfield.</p><p data-renderer-start-pos="1301">Today we√¢‚Ç¨‚Ñ¢re happy to announce the start of our Closed Beta phase of testing. If you√¢‚Ç¨‚Ñ¢re interested in testing the app early, please sign up at the link below.</p><center><br> <a href="https://admin224533.typeform.com/to/ayopnZXF" target="_blank" rel="noopener">SIGN UP NOW</a></center></div><p><img src="https://www.holopix.com/wp-content/uploads/2020/07/thumb-1920-587948-1.gif" alt="GIF" width="100%" height="100%"></p></div></div></div></div><p><span><p>We use cookies to optimize site functionality and give you the best possible experience. <a href="https://www.holopix.com/holopix-wordpress-2/privacy/" id="CONSTANT_OPEN_URL">Find out more</a> <a data-cli_action="accept" id="cookie_action_close_header">Accept</a></p></span></p>  </div>    </div>]]>
            </description>
            <link>https://www.holopix.com/android-beta/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23902660</guid>
            <pubDate>Mon, 20 Jul 2020 22:43:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Manager Superpower: Optimism]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23902629">thread link</a>) | @gmays
<br/>
July 20, 2020 | https://staysaasy.com/management/2020/07/19/Optimism.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2020/07/19/Optimism.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>In the book Winning, the legendary General Electric CEO Jack Welch defines his rules of leadership:</p>

<blockquote>
  <p>Rule 3: Leaders get into everyone‚Äôs skin, exuding positive energy and optimism‚Ä¶your job as a leader is to fight the gravitational pull of negativism. That doesn‚Äôt mean you sugarcoat the challenges your team faces. It means you display an energizing, can-do attitude about overcoming them.</p>
</blockquote>

<p>I couldn‚Äôt agree more. How many truly optimistic managers do you see on a day to day basis?  Not people that are so over-leveraged that fear pushes them to hope everything works out. Not people who ignore hard truths and escape into a good Spotify playlist.</p>

<p>Optimistic managers. Managers who see the world for what it is - a never-ending grind full of challenges, bad-breaks, luck, let-downs, inspirations, and everything in between - and approach it with a consistently positive energy and will to make things work.</p>

<p>The answer: not enough. Here are some ways you can uplevel your optimism.</p>

<p>To be optimistic, don‚Äôt:</p>
<ul>
  <li>Commiserate regularly with your reports. Commiseration is a little forfeit, every time. As a leader, you shouldn‚Äôt be signalling that the way to react to adversity is to lament. The film Saving Private Ryan calls this out beautifully: ‚ÄúGripes only go up the chain of command, never down. Privates gripe to sergeants, sergeants gripe to captains, captains gripe to majors, majors gripe to colonels and colonels gripe to generals. Gripes always go up, never down.‚Äù</li>
  <li>Otherize other teams in the org. Or more bluntly: don‚Äôt talk shit about other teams. They might not be perfect, but neither are you. Otherizing only makes it harder to find the path forward.</li>
  <li>Pretend like everything is great. Again, optimism isn‚Äôt about pretending things are great. It‚Äôs a commitment to framing things as challenges to be solved, not problems to be lamented.</li>
</ul>

<p>To be optimistic, do:</p>
<ul>
  <li>Have a never-ending well of persistence. You might feel like Sisyphus pushing that boulder up the hill day in and day out. Optimistic people understand that most of one‚Äôs work life is pushing boulders up hills and have a good attitude about it.</li>
  <li>Get over things. If you can‚Äôt reset your opinion on people, problems, slights, and all other things to an absolute neutral, you‚Äôll be saddled with a distracting and deteriorating buildup of resentment. Learn to get over things completely.</li>
  <li>Commit. If you‚Äôre second guessing yourself every step of the way you‚Äôll never be able to sustain optimism. Set some timeframe for re-evaluation - maybe 6 months or a year - and then forget about anything that sounds like ‚Äúmaybe‚Äù.</li>
</ul>

<p>Optimism isn‚Äôt a feeling that puffs your lungs up with rejuvenating life and leads to transcendent moments of inspiration. It‚Äôs removing the friction that your ego and backbone want to instinctively introduce when faced with challenges. It‚Äôs a way to move forward.</p>

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2020/07/19/Optimism.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23902629</guid>
            <pubDate>Mon, 20 Jul 2020 22:39:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Docker Network ‚Äì Complete Guide]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23902422">thread link</a>) | @lukasbar
<br/>
July 20, 2020 | https://knowledgepill.it/posts/docker-network/ | <a href="https://web.archive.org/web/*/https://knowledgepill.it/posts/docker-network/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <p>Containers need to communicate with each other and outside world.<br>
Docker has wide network capabilities.</p>
<p>What we can do with docker network? How to use it?</p>
<h2 id="docker-network-theory">Docker Network Theory</h2>
<p>What elements we have in docker network?</p>
<ul>
<li>CNM</li>
<li>libnetwork</li>
<li>drivers</li>
</ul>
<p>Docker network concept is based on open-source design specification called Container Network Model(CNM). CNM assume that network drivers should be pluggable.<br>
Docker CNM implementation is in <code>libnetwork</code> library.</p>
<p>What we can do with docker CNM?</p>
<ul>
<li>single-host bridges</li>
<li>multi-host overlay networks</li>
<li>networks plugged into VLAN‚Äôs</li>
<li>ingress networks with load balancing
Also we get auto service discovery for our containers.</li>
</ul>
<p>What elements we have in docker CNM implementation?</p>
<ul>
<li>sandboxes - container network stack - isolated - ethernet interfaces, ports, routing tables and DNS config</li>
<li>endpoint - virtual interfaces in containers - veth</li>
<li>networks - virtual switches(bridges) - connect endpoints</li>
</ul>
<p>What drivers are built-in by default into docker(Linux)?</p>
<ul>
<li>bridge</li>
<li>overlay</li>
<li>macvlan</li>
</ul>
<h2 id="single-host-network-bridge">Single-host network bridge</h2>
<p>By default docker creates one brigde after instalation.</p>
<p>All containers are by default connected to it unless we override it.<br>
To set another non-default network we use <code>--network</code> flag for <code>docker run</code>.</p>
<p>What is the diference between default bridge and user created one:</p>
<ul>
<li>Default brigde is less secure - provide less isolation - by default all containers will be connected to it</li>
<li>We can connect/disconnect containers from user defined bridges without restarting containers</li>
<li>Defualt bridge does not have DNS included - we must use IP in such network - on user defined bridge we get DNS(all containers added to bridge network automatically will be added also to DNS) - just connect container to bridge and you can talk with other containers in network by their names(works for named containers with <code>--name</code> at creation time)</li>
</ul>
<p>We can see that all default networks are local - what means that we can‚Äôt connect with them containers on multiple docker hosts.</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span>## docker network ls</span>
NETWORK ID          NAME                DRIVER              SCOPE
740857ece0a5        bridge              bridge              local
13396ccbb663        host                host                local
44424eae56f4        none                null                local
</code></pre></div><p>We can check details about default bridge network</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span>## docker network inspect bridge</span>
<span>[</span>
    <span>{</span>
        <span>"Name"</span>: <span>"bridge"</span>,
        <span>"Id"</span>: <span>"740857ece0a5fc38891b919d2f7506e32e699b4e79a449f8fef9824d0cde39b2"</span>,
        <span>"Created"</span>: <span>"2020-05-07T21:07:19.137450998+02:00"</span>,
        <span>"Scope"</span>: <span>"local"</span>,
        <span>"Driver"</span>: <span>"bridge"</span>,
        <span>"EnableIPv6"</span>: false,
        <span>"IPAM"</span>: <span>{</span>
            <span>"Driver"</span>: <span>"default"</span>,
            <span>"Options"</span>: null,
            <span>"Config"</span>: <span>[</span>
                <span>{</span>
                    <span>"Subnet"</span>: <span>"172.17.0.0/16"</span>,
                    <span>"Gateway"</span>: <span>"172.17.0.1"</span>
                <span>}</span>
            <span>]</span>
        <span>}</span>,
        <span>"Internal"</span>: false,
        <span>"Attachable"</span>: false,
        <span>"Ingress"</span>: false,
        <span>"ConfigFrom"</span>: <span>{</span>
            <span>"Network"</span>: <span>""</span>
        <span>}</span>,
        <span>"ConfigOnly"</span>: false,
        <span>"Containers"</span>: <span>{</span><span>}</span>,
        <span>"Options"</span>: <span>{</span>
            <span>"com.docker.network.bridge.default_bridge"</span>: <span>"true"</span>,
            <span>"com.docker.network.bridge.enable_icc"</span>: <span>"true"</span>,
            <span>"com.docker.network.bridge.enable_ip_masquerade"</span>: <span>"true"</span>,
            <span>"com.docker.network.bridge.host_binding_ipv4"</span>: <span>"0.0.0.0"</span>,
            <span>"com.docker.network.bridge.name"</span>: <span>"docker0"</span>,
            <span>"com.docker.network.driver.mtu"</span>: <span>"1500"</span>
        <span>}</span>,
        <span>"Labels"</span>: <span>{</span><span>}</span>
    <span>}</span>
<span>]</span>
</code></pre></div><p>As we see docker bridge is build on Linux bridge:</p>
<div><pre><code data-lang="bash"><span>"com.docker.network.bridge.name"</span>: <span>"docker0"</span>
</code></pre></div><div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span>## ip link show docker0</span>
3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu <span>1500</span> qdisc noqueue state DOWN mode DEFAULT group default
    link/ether 02:42:9d:73:fa:48 brd ff:ff:ff:ff:ff:ff
</code></pre></div><h3 id="creating-network-bridge">Creating network bridge</h3>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span>## docker network create -d bridge lukas-bridge</span>
3836e34c6950d80e032e322f915935b51472059ea19cfd65c409263c74ba2b45
</code></pre></div><div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span>## ip a</span>
&lt;snip&gt;
5: br-3836e34c6950: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu <span>1500</span> qdisc noqueue state DOWN group default
    link/ether 02:42:0b:b8:19:54 brd ff:ff:ff:ff:ff:ff
    inet 172.19.0.1/16 brd 172.19.255.255 scope global br-6c8ad698150b
       valid_lft forever preferred_lft forever
</code></pre></div><p>As we see there is new bridge at OS level with name coresponding to ID of our newly created docker bridge.</p>
<h3 id="starting-container-connected-to-new-bridge">Starting container connected to new bridge</h3>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span>## docker container run -d --name web_server --network lukas-bridge httpd</span>
08e885099d0ebca6ab5b533bffd0245dccfaab79149657ad9161fe26c370b879
</code></pre></div><h3 id="list-containers-connected-to-network">List containers connected to network</h3>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span>## docker network inspect lukas-bridge --format "{{json .Containers}}"</span>
<span>{</span><span>"08e885099d0ebca6ab5b533bffd0245dccfaab79149657ad9161fe26c370b879"</span>:<span>{</span><span>"Name"</span>:<span>"web_server"</span>,<span>"EndpointID"</span>:<span>"ade95c4b553f8cebfbf8f24338b6d0f9e7b2d41744c501816ac734d1bb8ccc1f"</span>,<span>"MacAddress"</span>:<span>"02:42:ac:14:00:02"</span>,<span>"IPv4Address"</span>:<span>"172.20.0.2/16"</span>,<span>"IPv6Address"</span>:<span>""</span><span>}</span><span>}</span>
</code></pre></div><h3 id="test-connection-between-containers-connected-to-bridge">Test connection between containers connected to bridge</h3>
<p>If we use <code>--name</code> flag when creating container we can use docker built-in DNS feature.
Containers automatically know hostname to ip mapping of other containers.</p>
<p>Create second container:</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span>## docker container run -d --name web_server2 --network lukas-bridge httpd</span>
34bb16b0c43c64c935c8a44c0ed13fa2a7972f79700db290144eba54aa93336a
</code></pre></div><p>Get into one of containers and ping other one</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span>## docker exec -it web_server2 /bin/bash</span>
root@34bb16b0c43c:/usr/local/apache2## ping web_server

PING web_server <span>(</span>172.20.0.2<span>)</span> 56<span>(</span>84<span>)</span> bytes of data.
<span>64</span> bytes from web_server <span>(</span>172.20.0.2<span>)</span>: icmp_seq<span>=</span><span>1</span> ttl<span>=</span><span>64</span> time<span>=</span>0.712 ms
<span>64</span> bytes from web_server <span>(</span>172.20.0.2<span>)</span>: icmp_seq<span>=</span><span>2</span> ttl<span>=</span><span>64</span> time<span>=</span>0.649 ms
^C
</code></pre></div><h2 id="changing-dns-in-container">Changing DNS in container</h2>
<p>We can add DNS to container - this DNS will be queired when Docker built-in DNS won‚Äôt be able to resolve request.</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span>## docker run -d --dns 8.8.8.8 httpd</span>
4bde944868b492a5cef84676de1cfb1a211069c67c494d4ab742115d4fc17ee9

<span>[</span>root@docker-host1 ~<span>]</span><span>## docker exec -it 4bde944868b492a5cef84676de1cfb1a211069c67c494d4ab742115d4fc17ee9 bash</span>
root@4bde944868b4:/usr/local/apache2## cat /etc/resolv.conf
search lukas.int
nameserver 8.8.8.8
</code></pre></div><h2 id="port-mapping">Port mapping</h2>
<p>We can tell docker to expose port from container on docker host port that other server or clients can access service running in container.<br>
We can achive this with <code>--publish</code> flag.</p>
<h3 id="start-container-with-port-published">Start container with port published</h3>
<p>We start container with <code>httpd</code> service which expose port 80 - to connect to this port in container we can connect to docker host on port 1234.</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span>## docker run -d --name web_server --network lukas-bridge --publish published=1234,target=80  httpd</span>
304ddf53a801763c769545eb91c6c5522fc2eedf7cf5f4d252bace1d5e0b8a37
</code></pre></div><h3 id="check-what-ports-are-published-from-container">Check what ports are published from container</h3>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span>## docker port web_server</span>
80/tcp -&gt; 0.0.0.0:1234
</code></pre></div><h2 id="connecting-container-directly-to-host-network-stack">Connecting container directly to host network stack</h2>
<p>Docker gives us possibility to integrate container network stack into host stack.<br>
In such situation container will not get his own IP address and MAC(neither externally from docker host network, neither internally from network created by docker engine) - he will be reachable as he will be normal software running on our host.</p>
<p>This is good solution if we want to run some software that use network but we want to have full isolation of process(pid), mount(mnt), user and IPC namespaces.</p>
<p>To active such mode we use <code>--network=host</code> parameter to <code>docker run</code>.<br>
In this mode <code>--publish</code> doesn‚Äôt work - if service in container listen on port 80 - port 80 on docker host will be taken.</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span>## docker run -d --name web_server --network host httpd</span>
dedc6c9e1c05ccb3621fa4272975036f7b9266371a20221f3ba9dbc237eff3b0
</code></pre></div><p>If we inspect container we will see that there is no IP adress and network mode is set to host:</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span>## docker container inspect web_server</span>
<span>[</span>...<span>]</span>
<span>"NetworkMode"</span>: <span>"host"</span>,
            <span>"PortBindings"</span>: <span>{</span>
                <span>"80/tcp"</span>: <span>[</span>
                    <span>{</span>
                        <span>"HostIp"</span>: <span>""</span>,
                        <span>"HostPort"</span>: <span>"1234"</span>
                    <span>}</span>
<span>[</span>..<span>]</span>
<span>"Networks"</span>: <span>{</span>
    <span>"host"</span>: <span>{</span>
        <span>"IPAMConfig"</span>: null,
        <span>"Links"</span>: null,
        <span>"Aliases"</span>: null,
        <span>"NetworkID"</span>: <span>"13396ccbb6635016d4381588204f9724401cf7200b67cb8f44f065ebfbb8f069"</span>,
        <span>"EndpointID"</span>: <span>"256edba4bd98f86e4a3af9331ff24aca958805ff5f0a3bb202fa67c0b8d4ab07"</span>,
        <span>"Gateway"</span>: <span>""</span>,
        <span>"IPAddress"</span>: <span>""</span>,

</code></pre></div><p>Apache server is listening correctly:</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span>## curl -X GET 127.0.0.1:80</span>
&lt;html&gt;&lt;body&gt;&lt;h1&gt;It works!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;
</code></pre></div><h2 id="connecting-container-directly-to-host-network---macvlan">Connecting container directly to host network - MACVLAN</h2>
<p>If we want to expose our container to world but it is important for us that container has got own IP and MAC adress from network where docker host is connected, we can use MACVLAN network driver. It allows also to connect to certain VLAN.</p>
<p>It will create for us docker network - all containers connected to this network will be visible in docker host network as they were normal separate from docker host that host them machines.</p>
<p>Remember that:</p>
<ul>
<li>with MACVLAN you can easily exhaust IP adresses in your network</li>
<li>you have to set network card in promiscious mode</li>
<li>this solution is created mainly for legacy apps or network monitoring apps</li>
</ul>
<hr>
<h4 id="important">Important!</h4>
<p>To use MACVLAN mode our network card has to be in promiscious mode!<br>
Activiting promoscius mode in CentOS(ens18 is my main network card):</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span>## ip link set ens18 promisc on</span>
</code></pre></div><p>Check if mode was activeted - PROMISC flag:</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span>## ip a</span>
<span>[</span>..<span>]</span>
2: ens18: &lt;BROADCAST,MULTICAST,PROMISC,UP,LOWER_UP&gt; mtu <span>1500</span> qdisc fq_codel state UP group default qlen <span>1000</span>
    link/ether 62:ae:db:67:8c:08 brd ff:ff:ff:ff:ff:ff
    inet 10.10.10.20/24 brd 10.10.10.255 scope global noprefixroute ens18
       valid_lft forever preferred_lft forever
    inet6 fe80::8f98:eb7:2724:a548/64 scope link noprefixroute
       valid_lft forever preferred_lft forever
<span>[</span>...<span>]</span>
</code></pre></div><hr>
<p>As my docker host is in <code>10.10.10.0/24</code> ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://knowledgepill.it/posts/docker-network/">https://knowledgepill.it/posts/docker-network/</a></em></p>]]>
            </description>
            <link>https://knowledgepill.it/posts/docker-network/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23902422</guid>
            <pubDate>Mon, 20 Jul 2020 22:13:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Docker Production Environment ‚Äì Enterprise Edition and Security Features]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23902146">thread link</a>) | @lukasbar
<br/>
July 20, 2020 | https://knowledgepill.it/posts/docker-enterprise-ucp-security/ | <a href="https://web.archive.org/web/*/https://knowledgepill.it/posts/docker-enterprise-ucp-security/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <p>In production environment we should care about security, also we want easy of usage.<br>
So, it is good to know docker security options and Docker Enterprise Edition.</p>
<hr>
<p>This guide assume that we have got Docker Enterprise Edition installed on three node cluster. Most of features described here are paid ones, but we can get a trial of Docker Enterprise Edition for free - 30 day period.</p>
<p>How to do it?<br>
Look at official docs:</p>
<p><a href="https://docs.docker.com/ee/docker-ee/rhel/">Docker EE Installation</a><br>
<a href="https://hub.docker.com/editions/enterprise/docker-ee-trial">Docker EE Trial</a></p>
<hr>
<h2 id="security-overview">Security Overview</h2>
<p>Security components in docker:</p>
<ul>
<li>Secrets - encrypted store for passwords and other sensitive data that can be publish to container</li>
<li>Docker Content Trust - singing images protect from man-in-the-middle attacks</li>
<li>Security Scanning - images in DTR can be scanned for security vulnerabilities</li>
<li>Swarm Mode - most of swarm components are encrypted by default</li>
</ul>
<p>Security components in Linux which used by docker:</p>
<ul>
<li>seccomp</li>
<li>Mandatory Acess Control(MAC)</li>
<li>Capabilities</li>
<li>Control Groups(cgroups)</li>
<li>Kernel namespaces</li>
</ul>
<h4 id="namespaces">Namespaces</h4>
<p>Linux technology that gives us ability to slice OS into couple of logical OS‚Äôes.<br>
Docker container has got couple of own namespaces which are isolated from others and from docker host itself.</p>
<p>What namespaces are available:</p>
<ul>
<li>Process ID(pid) - isolation of process tree - every container hasw got own processes</li>
<li>Network(net - network stack isolation - interfaces, IP‚Äôs, ports etc.</li>
<li>Mount(mnt) - root(/) filesystem isolation</li>
<li>Inter-prcess Communication(ipc) - shared memory isolation</li>
<li>User(usr)(not enabled by default) - mapping non-root user on container to root user on docker host</li>
<li>UTS(uts) - isolating of hostnames and uname calls</li>
</ul>
<h4 id="control-groups">Control Groups</h4>
<p>Control Group will be used to set limits for containers resource compsumption.</p>
<h4 id="capabilities">Capabilities</h4>
<p>Linux capabilities gives us possibility to restrict certain calls to kernel from root user. Docker containers are running from root user which may lead to some dangerous situations.<br>
We can remove some capabilities from root user after running our containers to make docker host more secure.<br>
What can be capability?</p>
<ul>
<li><code>CAP_CHOWN</code> - posibillity to do <code>chown</code></li>
<li><code>CAP_NET_BIND_SERVICE</code> - binding low ports</li>
<li><code>CAP_SYS_BOOT</code> - rebooting host</li>
</ul>
<h4 id="mandatory-acess-control">Mandatory Acess Control</h4>
<p>Well known Linux MAC is SELinux which we love to <code>setenforce 0</code> :)
We can start containers with SELinux policy applied - by default we get one which in most cases should be fine.</p>
<h4 id="seccomp">seccomp</h4>
<p>Profiles wchich can filter dangerous kernel calls from containers.</p>
<h4 id="swarm-security">Swarm security</h4>
<p>Swarm security includes:</p>
<ul>
<li>Crypto node ID</li>
<li>TLS authentication for nodes - certificate added to node after joining cluster</li>
<li>Secure join tokens - one for managers and one for workers</li>
<li>Encrypted DB with metadata</li>
<li>Encrypted management networking</li>
<li>CA and certificate rotation</li>
</ul>
<h6 id="check-tls-node-certificate">Check TLS node certificate</h6>
<p>Subject:</p>
<ul>
<li><code>O</code> - Swarm ID</li>
<li><code>OU</code> - Swarm node role</li>
<li><code>CN</code> - Node ID</li>
</ul>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span>## openssl x509 -in /var/lib/docker/swarm/certificates/swarm-node.crt  -text</span>
Certificate:
    Data:
        Version: <span>3</span> <span>(</span>0x2<span>)</span>
        Serial Number:
            15:70:f3:02:11:f6:41:41:e3:10:4c:84:74:f8:3b:a7:b2:37:27:c5
        Signature Algorithm: ecdsa-with-SHA256
        Issuer: CN <span>=</span> swarm-ca
        Validity
            Not Before: May <span>12</span> 16:09:00 <span>2020</span> GMT
            Not After : Aug <span>10</span> 17:09:00 <span>2020</span> GMT
        Subject: O <span>=</span> rmozotgo6u1elkg2r0b1r1fzh, OU <span>=</span> swarm-manager, CN <span>=</span> q6oweiw4l87n292hn4cyekc7x
        Subject Public Key Info:
            Public Key Algorithm: id-ecPublicKey
                Public-Key: <span>(</span><span>256</span> bit<span>)</span>
                pub:
                 &lt;&gt;
                ASN1 OID: prime256v1
                NIST CURVE: P-256
        X509v3 extensions:
            X509v3 Key Usage: critical
                Digital Signature, Key Encipherment
            X509v3 Extended Key Usage:
                TLS Web Server Authentication, TLS Web Client Authentication
            X509v3 Basic Constraints: critical
                CA:FALSE
            X509v3 Subject Key Identifier:
                C9:5D:5B:42:2E:EA:7C:79:9A:69:B6:2D:B2:57:91:B9:72:76:C2:22
            X509v3 Authority Key Identifier:
                keyid:27:BE:CB:1C:87:0D:ED:35:7D:EB:16:4C:1E:80:60:3E:C0:DE:EB:70

            X509v3 Subject Alternative Name:
                DNS:swarm-manager, DNS:q6oweiw4l87n292hn4cyekc7x, DNS:swarm-ca
    Signature Algorithm: ecdsa-with-SHA256
         &lt;&gt;
</code></pre></div><h6 id="change-tls-certificate-rotation-period">Change TLS certificate rotation period</h6>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span>## docker swarm update --cert-expiry 720h</span>
Swarm updated.
</code></pre></div><h4 id="secrets">Secrets</h4>
<p>Secrets allows us to store in encrypted cluster store in Swarm some important data like passwords. This data can be decrypted end mounted in containers in <code>/run/secrets</code> as flat text file.</p>
<h6 id="create-secret">Create secret</h6>
<p>From Swarm manager node:</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span>## echo "SuperSecretPassword" | docker secret create ImportantPassword -</span>
lu126735e618m51qp6u8jc5fl
</code></pre></div><h6 id="list-secrets">List secrets</h6>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span>## docker secret ls</span>
ID                          NAME                DRIVER              CREATED             UPDATED
lu126735e618m51qp6u8jc5fl   ImportantPassword                       <span>6</span> seconds ago       <span>6</span> seconds ago
ei5zfeqp6f2aolcygkiqmcwrb   ucp-auth-key                            <span>2</span> days ago          <span>2</span> days ago
</code></pre></div><h6 id="create-service-with-secret-mounted">Create service with secret mounted</h6>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span>## docker service create --name web_server --replicas 2 --secret ImportantPassword httpd</span>
xvkr9xbmjayy99l1u9tcrruxv
overall progress: <span>2</span> out of <span>2</span> tasks
1/2: running   <span>[</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span>&gt;<span>]</span>
2/2: running   <span>[</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span>&gt;<span>]</span>
verify: Service converged
</code></pre></div><div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span>## docker exec -it web_server.1.kooxu73k13sthobea9f6p8542 bash</span>

root@0b93e926dc4a:/usr/local/apache2## ls -lah /run/secrets/
total 4.0K
drwxr-xr-x. <span>2</span> root root <span>31</span> May <span>14</span> 20:20 .
drwxr-xr-x. <span>1</span> root root <span>21</span> May <span>14</span> 20:20 ..
-r--r--r--. <span>1</span> root root <span>20</span> May <span>14</span> 20:20 ImportantPassword

root@0b93e926dc4a:/usr/local/apache2## cat /run/secrets/ImportantPassword
SuperSecretPassword
</code></pre></div><h2 id="docker-enterprise">Docker Enterprise</h2>
<p>Docker EE includes:</p>
<ul>
<li>Universal Control Plane(UCP)</li>
<li>Docker EE engine</li>
<li>Docker Trusted Registry(DTR)</li>
</ul>
<h4 id="ucp">UCP</h4>
<p>UCP as mentioned earlier is web gui for docker. It is used to manage docker engine and some entreprise features - it is shipped as container for easy deployment.<br>
If we have Docker EE binaries installed we can deploy UCP with single <code>docker run</code> command. Before doing so, we have to be dure that:</p>
<ul>
<li>all nodes will have set up NTP for time synchro</li>
<li>all nodes have got static IP address</li>
<li>all nodes have got resolvable DNS name</li>
<li>odd number of managers for HA(3 or 5)(5 is best option)</li>
<li>you have some VIP‚Äôs and LB - to round robin calls to UCP/DTR GUI</li>
<li>managers spread in multiple DC availability zones</li>
<li>all nodes meet requirements:
<ul>
<li>minimum:
<ul>
<li>UCP Manager with DTR: 8GB RAM, 3GB disk space</li>
<li>UCP Worker: 4GB RAM, 3GB disk space</li>
</ul>
</li>
<li>recommended:
<ul>
<li>UCP Manager with DTR: 8GB RAM, 4vCPU, 100GB disk space</li>
<li>UCP Worker: 4GB RAM, 25-100GB disk space</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>For setup I advise to follow official docs, after following it we get swarm cluster created which is managed by UCP and DTR deployed on it.</p>
<p><a href="https://docs.docker.com/ee/ucp/admin/install/">Docker UCP Setup Docs</a><br>
<a href="https://docs.docker.com/ee/dtr/admin/install/">Docker Trusted Registry Setup Docs</a></p>
<p>After installation we should se on manager node:</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span>## docker service ls</span>
ID                  NAME                     MODE                REPLICAS            IMAGE                        PORTS
begjzklu24xp        ucp-auth-api             global              1/1                 docker/ucp-auth:3.2.6
re8y924yflm6        ucp-auth-worker          global              1/1                 docker/ucp-auth:3.2.6
4fouy44hjo1b        ucp-cluster-agent        replicated          1/1                 docker/ucp-agent:3.2.6
dmm1i3un93x7        ucp-manager-agent        global              1/1                 docker/ucp-agent:3.2.6
az4tgr8y1fmy        ucp-worker-agent-win-x   global              0/0                 docker/ucp-agent-win:3.2.6
g4i7oduf9zgv        ucp-worker-agent-x       global              2/2                 docker/ucp-agent:3.2.6
</code></pre></div><hr>
<p>If you not familiar with moving around Docker Swarm Cluster and services look at:</p>
<p><a href="https://knowledgepill.it/posts/docker_swarm_compendium/">Docker Swarm Complete Guide</a></p>
<hr>
<p>What does this services do?</p>
<ul>
<li>ucp-agent - main UCP agent that is capable of scheduling containers on nodes</li>
<li>ucp-ectd - cluster persistent database</li>
<li>ecp-auth - authentication service which gives us possibility to enable SSO</li>
<li>ucp-proxy - control access to local docker socket</li>
<li>ucp-swarm - communication with swarm cluster on which UCP is deployed</li>
</ul>
<p>By default UCP creates some CA for internal and external connection.<br>
For production we can use our - ca.pem, cert.pem, key.pem - we can add certs when starting UCP with flag <code>--external-ca</code>.<br>
This flag will take volume name in which we have our certs. Volume should be named: <code>ucp-controller-server-certs</code>.</p>
<h4 id="accesing-ucp-dashboard---adding-new-node">Accesing UCP dashboard - adding new node</h4>
<hr>
<p>If we log in for the first time we shuold first upload liecnse file: <code>docker_subscription.lic</code>.</p>
<p>It can be download from Docker Hub from place where we have info about our  subscription.</p>
<hr>
<p>We should use: <code>https://&lt;docker_host_with_ucp&gt;:443</code> to access UCP.<br>
After log in we get dashboard:</p>
<p><img src="https://knowledgepill.it/images/docker_ee/1.png" alt="Docker EE Dashboard"></p>
<p>In Shared Resources -&gt; Nodes we can click Add Node:</p>
<p><img src="https://knowledgepill.it/images/docker_ee/2.png" alt="Docker EE Dashboard"></p>
<p>UCP will gives us command to add manager or worker to swarm:</p>
<p><img src="https://knowledgepill.it/images/docker_ee/3.png" alt="Docker EE Dashboard"></p>
<p>After using command UCP will deploy nessesery containers into new node:</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host3 ~<span>]</span><span>## docker container ls</span>
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES

<span>[</span>root@docker-host3 ~<span>]</span><span>## docker swarm join --token SWMTKN-1-0f2m4q5xac2s7ba304t61wi100h6oiisqoiqh8ui1ji31vytcz-d68hhgvwjrkidprzz2282dapc 10.10.10.20:2377</span>
This node joined a swarm as a worker.

<span>[</span>root@docker-host3 ~<span>]</span><span>## docker container ls</span>
CONTAINER ID        IMAGE                        COMMAND                  CREATED              STATUS                        PORTS                                                                       NAMES
511c2be45d61        dd89cabc02dd                 <span>"/install-cni.sh"</span>        <span>54</span> seconds ago       Up <span>53</span> seconds                                                                                             k8s_install-cni_calico-node-2kf4p_kube-system_6f7ae121-9696-11ea-bb79-0242ac110009_0</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://knowledgepill.it/posts/docker-enterprise-ucp-security/">https://knowledgepill.it/posts/docker-enterprise-ucp-security/</a></em></p>]]>
            </description>
            <link>https://knowledgepill.it/posts/docker-enterprise-ucp-security/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23902146</guid>
            <pubDate>Mon, 20 Jul 2020 21:33:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Serpent OS]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23902016">thread link</a>) | @severine
<br/>
July 20, 2020 | https://www.serpentos.com/about/ | <a href="https://web.archive.org/web/*/https://www.serpentos.com/about/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<main role="main">
    <div>

        
        


        <p>Serpent OS is (or at least, will be) a Linux distribution with notably different goals
from the mainstream offering. We‚Äôre in the process of establishing the project, with
development properly starting towards the end of July.</p>
<h4 id="naming">Naming</h4>
<p>Eventually our plan is to rebrand as ‚ÄòSerpent Linux*‚Äô - however we will first need to
complete some early donkey work and apply for a sublicense to use the name. As explained
below, this is <em>not</em> Serpent ‚ÄòGNU/Linux‚Äô as the distribution will not be dependent on
a GNU toolchain or runtime. For those who are curious, we‚Äôre working with an artist to
choose an appropriate logo for the project.</p>
<h4 id="aims">Aims</h4>
<p>The vast majority of Linux distributions have highly similar goals, and can be best
described using these common industry buzzwords:</p>
<pre><code>Modern, lightweight, privacy oriented/respecting, user-friendly desktop
</code></pre>
<p>We‚Äôre focused on building a Linux distribution that serves our own needs.
Chiefly, a Linux distribution for people who want to use Linux, not a ‚ÄúLinux-based-OS‚Äù
focusing on interoptability with macOS* + Windows*.</p>
<p>In a nut shell, this is <strong>not</strong> ‚ÄúLinux for the masses‚Äù. This is a project setting out to
use Linux as Linux should be used. This will in turn help us to build a significantly
advanced Linux distribution that is both modular and optimised for modern machines.</p>
<h4 id="a-truly-modern-linux-distribution">A Truly Modern Linux Distribution</h4>
<p>As we‚Äôre taking a distro-first, compatibility-later approach, our design decisions
will allow us to take some bold steps. We‚Äôll also be able to incorporate all of the
more sensible design improvements in Linux distribution design over the last decade or
so:</p>
<ul>
<li>No more usrbin split</li>
<li>100% clang-built throughout (including kernel)</li>
<li>musl as libc, relying on compiler optimisations instead of inline asm</li>
<li><code>libc++</code> instead of <code>libstdc++</code></li>
<li>LLVM‚Äôs binutils variants (<code>lld</code>, <code>as</code>, etc.)</li>
<li>Mixed source/binary distribution</li>
<li>Moving away from <code>x86_64-generic</code> baseline to newer CPUs, including Intel and AMD specific optimisations</li>
<li>Capability based subscriptions in package manager (Hardware/ user choice / etc)</li>
<li><code>UEFI</code> only. No more legacy boot.</li>
<li>Completely open source, down to the bootstrap / rebuild scripts</li>
<li>Seriously optimised for serious workloads.</li>
<li>Third party applications reliant on containers only. No compat-hacks</li>
<li>Wayland-only. X11 compatibility via containers will be investigated</li>
<li>Fully stateless with management tools and upstreaming of patches</li>
<li>Lots, lots more. We‚Äôll blog about it.</li>
</ul>
<h4 id="opinionated-by-default">Opinionated By Default</h4>
<p>A recurring theme that holds back the development of world-class Linux, is high tolerance
for those holding Linux back. A perfect example is NVIDIA* and their lack of support for
accelerated Wayland support on their GPUs. Consequently, our project won‚Äôt tolerate such
decisions and will instead blacklist the NVIDIA proprietary drivers from the distribution.</p>
<p>There are other examples that will emerge over time, and will become quite clear.</p>
<p>The time for Linux distributions giving in, with thousands of man hours wasted working around
negative actors, had come to an end.</p>

<p>We will only accept community involvement via our IRC channel: <code>#serpentOS</code> on Freenode.
We will not operate a public bug tracker or forums. Once we are past out initial bootstrap
phase we will set up an email address to help reporting security issues to the team, and
we will of course release security notices.</p>
<p>In terms of feature requests, these will be largely at the discretion of core contributors.
When a company has been formed to house this project, we‚Äôre happy to hash out an SLA for
required works.</p>
<h4 id="timescale">Timescale</h4>
<p>It may seem incredibly odd launching a website before there is a distro to show off, however,
it became very apparent that the cat would be out of the bag, so we wanted to be prepared.</p>
<p>Currently, the Founder is in the midst of relocating to the Republic of Ireland. Once complete
we‚Äôll move to stage2 of our bootstrap process and begin working on the tooling needed for the
base development.</p>

    </div>
</main>


        </div></div>]]>
            </description>
            <link>https://www.serpentos.com/about/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23902016</guid>
            <pubDate>Mon, 20 Jul 2020 21:18:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Solving Sudoku with Graph Theory]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23901678">thread link</a>) | @cypressious
<br/>
July 20, 2020 | https://rakhman.info/blog/solving-sudoku-with-graph-theory/ | <a href="https://web.archive.org/web/*/https://rakhman.info/blog/solving-sudoku-with-graph-theory/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-4aeb25cd="" data-v-469b7dbe=""><p>In a game of Sudoku you have to fill the numbers 1 to 9 in a 9x9 grid that is also divided into 3x3 boxes. Each row, column and box must contain each digit exactly once. A game starts with a number of given digits in the grid, and the player can use multiple techniques to deduct the missing digits.</p>
<p>Easy variants can usually be completed by using simple eliminations, i.e. all but one candidate are eliminated from a cell because the column, row or box already contains it. However, harder variants require using more complicated techniques where you eliminate candidates from cells in multiple steps.</p>
<p>Programming a Sudoku solver is not very difficult. Even though Sudokus are known to be <a href="https://en.wikipedia.org/wiki/Mathematics_of_Sudoku#Mathematical_context" target="_blank" rel="nofollow noopener noreferrer">NP-complete</a>, because the <em>n</em> in a 9x9 Sudoku is fairly small, brute forcing a solution can be done in a few seconds. The more interesting task is to write a human-like Sudoku solver that uses human-possible techniques to identify the next move. In this post we'll discuss one technique that can be implemented using a fairly elegant graph algorithm. </p>
<h2 id="the-tuple-technique">The tuple technique</h2>
<p>Consider the following row of a Sudoku. Completed cells contain one big number. The other cells contain remaining <em>candidates</em> as smaller digits. </p>
<p><img src="https://rakhman.info/assets/static/sudoku1.864dc32.853451a027af9f90be5cd6bc004def7b.png" width="593" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 593 79' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-a5acc91205e16e24254440c26a02a598'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-a5acc91205e16e24254440c26a02a598)' width='593' height='79' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAJCAIAAAANXL0tAAAACXBIWXMAAAsSAAALEgHS3X78AAAC9UlEQVQ4y62Ue1PaUBDF/f4fp3ZaZ7QdrCiPqBUQeRgGeT9DJAFCQhL6u1lyJ0Nn%2bld31Fn3nj27Zzf3XiwWi36/P0xtMBiUy%2bVhxohMp9OnpyfTNMfjsQ7O5/NisXh7e5tlGI1GHx8fhmFMJhMwGkwiQY4ASJAUEnO5XKlUgkqDQVKIchTVQbG/GyPx4ng87na7fWqe55GvfbEwDLvd7ufnZxAE%2bojEdrtdqVSEwfP48Xzf32w2nU7ncDickhMwiQQ5AiDEpJBI%2bvv7O06K3IO0bZtyFAW1z1imsZ1mUAKiKDqmFscxyo4ZI8JfBiNNZ4NMtNlsnjHQOuPRGO0Q5EjDJKXRaPR6vSxYxkG5syB21pgwnASgW9jJYbmCcB17mBBhrF4UA2YGkowAOsAJ9l671Vy7W%2bUHga406PfstaPLS4nxsFep1g6hYnh7exMBvpqsLzOi0Gik6urZiw4aE0mtZmM6t4Q2ERCG9UrNNDtKQBRpATffv/zM3Z0JsK1lqfi42W6zAsir/n7uD2eqFT8QBme1vLy8NLuDjIAAZ7WYPhTLEkSAUhvH7VbbKJcK9w%2bfrvrMZId85vl83jAe/UAlIlVWYpTuK/VWRkAUbTcbd7MRn7ZwwvCQu776dVcQHIzbpGma4BsNklnypdIBznwy%2bPrtyt16iQBfhrpz1z9uro3nyjGdH0cqy2yPJjMtoJeUcx3HspaWZbEZJiUCXNddLhaUUwuPY2hl812zmS%2bUo/j43%2b4AapEUJjz6Dig/CDS5vgNRrLL1HZB1nd0BHrF/3IGDqsVhcgdAL5fLVWrMoFarIRqPuJVEHMdhVGjgITqBLIsnhTeER5DNWNZqvV7bifG0vb6%2b8i8Y8AmTcqDlSDBwQE5pHuJqtQqVYlydkHyulHPUTqxVxmAQJ6G1YaD0Bb%2b8x1ZqRGG0MkaEbur1Oryk6SD7fXl5oYMsA%2byz2YxK1FD6UzCJBDlK5VukkFgoFJiC%2blRSMEgRQFEdFDtrDAaU/wHGqU4NfHWAdQAAAABJRU5ErkJggg==' /%3e%3c/svg%3e" data-srcset="/assets/static/sudoku1.864dc32.853451a027af9f90be5cd6bc004def7b.png 593w" data-src="/assets/static/sudoku1.864dc32.853451a027af9f90be5cd6bc004def7b.png" srcset="https://rakhman.info/assets/static/sudoku1.864dc32.853451a027af9f90be5cd6bc004def7b.png 593w"></p>
<p>Cells 1 and 3 of the row can only contain the digits 1 and 9. The two possible solutions are:</p>
<ul>
<li>1 in cell 1 and 9 in cell 3 or</li>
<li>9 in cell 1 and 1 in cell 3.</li>
</ul>
<p>From this we can deduce that the digits 1 and 9 can <strong>never</strong> appear in any other cell in this row. This means we can eliminate the candidates 1 and 9 from cells 7 and 8. From now on we'll mark tuples as colored in cyan, and the cells with possible eliminations colored in purple.</p>
<p><img src="https://rakhman.info/assets/static/sudoku2.aba8b43.e1059c620c9f6afe98904cae3ae746c3.png" width="597" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 597 79' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-3373d5f8983748651b5c73a2cd1ac44b'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-3373d5f8983748651b5c73a2cd1ac44b)' width='597' height='79' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAICAIAAADGAG6IAAAACXBIWXMAAAsSAAALEgHS3X78AAAEJklEQVQ4y31UW1PbVhDmh3Yy01IoONiG9KHTaWn6UghtZ0oTSMydJH1oM3noBci0A8MlUBtfsI1ljA2%2bYMuWZekcHckSBlvSdiURJslkuiPtfNrznT36tLvqYy3y47%2b/TSs7083NaXFrurn1UN5%2bUPgzXTihMmm6JjSblJBENv1Daf1naRs5yPxJ2Hyo7H69uVgpliRZdmiCIIpiq9VKpVKIEXh7MYgAgxhBjEv4KIlSRSy/Gv9H6FcuhpvVIREvfljKf1o5usPVfeRiyAmirw/LXP/ZaSxPmIzpBNcYY/v7%2b/V6vY815VluYxmyS1ZyGY6X7PQKZGaV/brSAgDbtm/9RasR0iPLkF620w7TSq4AN3n00tDaDgfglol5LcuCtwwfMQjvmgF67EECfNAdtcwgWEEbRoH5jPqACGPQC9pWEMygbY%2bC7GOkRJ38lu1lQ5/L5RqNRh8T5ZnM2iIcz/dioU4kdH24BKlHZJcnondMuVzSdMMBzdpjbX8RknPdaOgyjPwlSE8kXrSZhqsKkTku6%2baHWq3W6/UQiEK9VhcQmKZZrVa9hGf5U%2b7kFEHb1iKTsZ4PWOBK9XfJiNEOmvJdvTIgdMeg7b%2bmI5eKv3M9CoKPSucSbmGUcBzXMx0B2WzWFdCUZ7i1ZeDmrw6/L/wxdba2CtzMGwFSqzE/N9cQWq4A/kn7AL/9LN37LvnrI%2bXAqUDiha46FWirLBw%2b9ATwPAowEWys/fX6IOJ9M1TlCTgv5LhcHoFutyOTcWsYqsONRD/390fb2cGyOnJVHhDse3A%2beL51Z%2b/g42QnCKJPkYqyJ%2bDV%2bjrTdFfAyU0FZjNrTkuYiYVubP46tgLpWbLHy00kqYxGIhFJol4FQhoKSC1Zifmr6GIvvgLHKEBjKq6eZI%2bPkmnvFavVmwpwx6loLI6iLLcCXoNVyiXmaXYExMy70B7r0sAl8RvGqCWP6JVBoXsPlMAlDRhKoIPVcCvgCDC73Vg0KlPlvQpsLEJ2wUouQGrBTi1CZubDM1B/rEew2VxOCvlLwE28mQHvM783A7Zr/zcDEwkYhK7fMkfA9Nu2H9Qho/6JCAHojdgY7LlB%2bbObGbCcM6x3ZkBpyU8Of39mxJ%2bS8FMaXiXh51osVNrMlc7amiZ7RgjiTOFkobbzjEWRuYpMOfxcj0/t/MJXa0xVKaWKolBK0GOb4iaMEII3dYHTuy7hxhhlPOE3p7bJV7rwjSyMk8Y4ad1n5S/5zOd5%2bVsNI94l3VcLX5SL6aKmq5gQk2BywzCwNZy/EP724ofRrtHRiNKmDH1H1WslrHNJVXED8Y5XNbVQKDRrdYNpHlOVaVe/fL2zi72hugI85tsCbu0DAhjja/z23rbe00mbUINSnbIO4yU%2bX85r1xrRnSB69UotN8rFUlFTNe993hbwH7TSL274t7MFAAAAAElFTkSuQmCC' /%3e%3c/svg%3e" data-srcset="/assets/static/sudoku2.aba8b43.e1059c620c9f6afe98904cae3ae746c3.png 597w" data-src="/assets/static/sudoku2.aba8b43.e1059c620c9f6afe98904cae3ae746c3.png" srcset="https://rakhman.info/assets/static/sudoku2.aba8b43.e1059c620c9f6afe98904cae3ae746c3.png 597w"></p>
<p>After the elimination, the 19-tuple is still there, but it's not <em>useful</em> anymore because we can't deduce any more eliminations.</p>
<p><img src="https://rakhman.info/assets/static/sudoku1_eliminated.bd6740a.1532f315e5df5db61edbe23b270e7c3b.png" width="600" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 600 79' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-74dd1e02634693877e8b2be848f175ed'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-74dd1e02634693877e8b2be848f175ed)' width='600' height='79' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAICAIAAADGAG6IAAAACXBIWXMAAAsSAAALEgHS3X78AAACgklEQVQ4y51UTXOiQBDN//8Nu/sPUnvJxZNVVrTKLyIqmKyKAgIqCCiCCAh5TMdZpPaS7QPV08y816%2b7Z552u50oikVRxJdLzOx2u2232/1%2bn2VZfDcENU3zfT9N02qw3W4HQZCQXUtDXFEUrOBgSX9Op5Oqqgzwii82gXG9Xo/HYziXCrVpmrZtV6nh4ywQQA1ASgDBTqcD/wm5TqdToOAwvnme4%2bu6LnLlS/piZxRFxd0o2Ov1AFoez0ojnM1mw/dkDBaUlmXRX2ggLsMwZrNZjdpxnOPxWKPG2ZhpxjJJUk79ICBLU8e2HddjKAfP8yiJtzchOEeEQgKiMLRM85qkhELQzn4nCCPKRt/odHYsjjbWjtU4RmlJlDDsv8%2bX8KCTBKRJYpqGz/JG%2bUlAeD4ZpnG5JvBxlqjlqSjJMwLvdrsPAtL4ulaUlapTGdCEkkNXfv745TgeCQjDEI7vujNZCsK4KsDc6OL4q5O6zgTc0t/Pz6PJlObzLqCQJclx/XsHZDjJ9TIcDFZrnQRQ813b6vZ63ikkARgzOPut%2bfrazlgH6gKqfTwcvjoQRWfwBUFY7UBthEiANBl9/Fk8CCiKxfxjpWpshO4C8nLAkjT77giRAN9z5dl7/s8O1AR89w5U4/wOcINIElAF/I87UKMuBeC1abVaeIvwyKBy%2bIJpMplIkgRHZUZBQRDm8zlYdWYIAvfl5WW5XCJjOk7xfr%2bPCPmarsHHnuFwCBCNQpqGcgwGg2aziQSq1HiXoIp28iDOLhaLv5haidloNPBsVC5xhtHKqRgoA40QljzI70DOjILoI38feJxGiEfooYTyGiCSkGW5Rs3vQHUnv8Q1anTgE/ikpWEBGBRdAAAAAElFTkSuQmCC' /%3e%3c/svg%3e" data-srcset="/assets/static/sudoku1_eliminated.bd6740a.1532f315e5df5db61edbe23b270e7c3b.png 600w" data-src="/assets/static/sudoku1_eliminated.bd6740a.1532f315e5df5db61edbe23b270e7c3b.png" srcset="https://rakhman.info/assets/static/sudoku1_eliminated.bd6740a.1532f315e5df5db61edbe23b270e7c3b.png 600w"></p>
<p>This technique isn't limited to pairs. The following image shows a 4789-quadruple (cyan). Accordingly, the candidates 7 and 9 can be eliminated from cells 1 and 3 (purple).</p>
<p><img src="https://rakhman.info/assets/static/sudoku3.4766128.5c324181732642e4652693860b05ee07.png" width="601" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 601 85' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-add802a2270b11616a5e0f13608d63ba'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-add802a2270b11616a5e0f13608d63ba)' width='601' height='85' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAJCAIAAAANXL0tAAAACXBIWXMAAAsSAAALEgHS3X78AAAEjElEQVQ4y9VT%2b1MTVxT2v%2bwv/lAHBBStgm1nOn3MdFpfFbUGUAKSgDhVRLQiGh5GA9lk994khE0IyCNgNpvshoAk5LXZx709d7Mt/gu9c7Jz59zvOznfPd89Rf/n6xT88Fu8PMAJo5gfQa0Iu4XA3BKOYiSg1sIYh7lwYHhZGHFg4REBj0QXhv3jgb%2bnIouTwvwkYvEUz79YnhPCPMIOV0BCFEdeLc3/JfieIQfGkMKcxzc1iU8yEE943%2bOl18/wwkkSACFfMBiEHhA66YfjuFqtxgQEfg0efaVVOozjNh2i0m4cndbS3B6hlq7plmWZhmFRq3xQ3vk622ijZRtWatPMNorPpH5IPx2iK/eaYZfO9%2bv8Xco/ljmtVDUs0zSBbWl6kxL6Yo%2b/2QgMmghgLj3cb/KuZujysnvAamVY9JvC3erSb5mZQYJddkH2JcLA4ZKSV6BVw2AVm80m7EVRlGWZCQj34UqHqX9H9V5qXGFROW9mIzk2IUK1Rh1osK2Va5lvVL2Har3E7KXNXov2UPHS9rXszARNeS1xnCbHiDhM49OFqFnTgKIBuV4n9qx9ufiAIYxRcQxgNOGh8VEr9jOe8FLRSyBp02liWEN3lUXY2MnEOEl6AHCMDooHUARar9UbhLCSGxsb%2bXyeCQj9gWrtVuFiabcrnzq7JZ0v1s9RCWfhqPL50O/3lyt1JqBUy3SrxiW631362LG31SnRy3T14tbv2VeP6Nodae566sW9wvthKk6p2KgyAZgPJlKbLbO%2blVdcpuAhKze3Xt2W5j10ddiM/ogejdL4n8pi3%2b6bG%2bsvB0pBtxG5nV94SGJQ8FZ69sbGywc69lRQcb8IRUpHB%2b8/BHR2n0xALpdzBNTbiXLhcKdTSnfKmfMFEJBBEhyp2cxb31x6LwP76lEVBFiXqNJ9mGzf3u7MMgEXmAC4vOvJ6aurU/dUR4BpC9hX5LCADeIIAIfArV9LPAcBo46ACei1Lz0LGaD3lzi3ge%2bo79x14db269sZ3zXx%2bZcCGrUqF1wu2%2bNdX/9XQPgWqnaY5rfU6KHgDfMKrZ5YiMCY6g2tNQHpogqYZg%2bxesFvjoWuZmce0XWvlRina2Mk4W5ZyBZwCIM//OxMILfSbwhe20JemoCLf2jFfkITzCEkwdwCdJpwa%2bgOs1ASkl5mobVRKnqYhZiA49KRoqq2g76YAHddKJ1uVrvNSpcBUT1nls40P/ESocSwpwXvBvbHnyu7Z3ONTtqClbt0q4vGOj/%2bkpkeoauDunDfQA8M5KL4SZ7Xj%2bsmafGIbujwlmakSJ8WHLKiAGNhYaB8z3sfkIiTAboVcdVCN2TfEAUYK3hfR4M0MnTEFdQCdAJP2H7KBnxTqZTzBvxT73dnP8n%2bfHYxByG/y3/ySbFwTCkosr1yck5RlJ3tnfjz1bxflRZlgEkL8v6HA%2b4JPy0sxItpQV5HuQ0kr2N1MyAKuztpoMhytlWhoKiBGM9JSZz/yGB28NmUZ3YSK5tIdjJwGtwT38SXo%2brWfwUj6ubSZmwtmVQLBTnrFCwWi6FQCP7iH1QlqpjbljhEAAAAAElFTkSuQmCC' /%3e%3c/svg%3e" data-srcset="/assets/static/sudoku3.4766128.5c324181732642e4652693860b05ee07.png 601w" data-src="/assets/static/sudoku3.4766128.5c324181732642e4652693860b05ee07.png" srcset="https://rakhman.info/assets/static/sudoku3.4766128.5c324181732642e4652693860b05ee07.png 601w"></p>
<p>We can generalize the rule by defining a tuple as follows:</p>
<blockquote>
<p>A tuple is a subset of cells in a row, column or box with size <strong>n</strong> that contains <strong>exactly n</strong> distinct candidates.</p>
</blockquote>
<p>So the elimination rule can be defined as follows:</p>
<blockquote>
<p>In a row, column or box with a tuple T, all candidates that are inside T can be eliminated from cells outside of T.</p>
</blockquote>
<p>Furthermore, we define that a tuple T is <em>useful</em> if T shares any candidates with cells outside of T.  </p>
<h2 id="drafting-an-algorithm">Drafting an algorithm</h2>
<p>Let's think of a naive algorithm to find tuples of size n with n distinct candidates. We have to consider tuples of all sizes with all possible candidate combinations:</p>
<pre><code>for each row, column, box
    for each size n between 2 and 8 
        // 1 and 9 don't make sense
        for each subset of the digits 1 to 9 with size n
            for each ... </code></pre>
<p>It is easy to see that our implementation has to involve a lot of nested loops. That's not a problem per se, but I find it hard to visualize it and thus it's not straight forward for me to write down. Instead, let's look at the problem from a different angle.</p>
<p>Consider an undirected graph, where the vertices are the cells of the row, column or box (that don't have a solution filled in). For every two cells that <em>share</em> a candidate, we'll add an edge. Let's look at our first example visualized as a graph:</p>
<p><img src="https://rakhman.info/assets/static/sudoku-graph1.262fba3.a964474d9018de0f0aaf005304ce9f9e.png" width="821" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 821 244' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-a48166cfe4c168e75b128b3cc7b52f32'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-a48166cfe4c168e75b128b3cc7b52f32)' width='821' height='244' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAATCAIAAACvEZzQAAAACXBIWXMAAAsSAAALEgHS3X78AAADOElEQVRIx7XXS08iQRAH8Pn%2bX8CjR70ar0aPejHRg5HE%2bMbnIiK4Lr6W/WVKZ9uZYQCXrQNpmnr861/V3UU2%2bq78np%2bM/kGymeCO/r/MGij7niM//foqT09PDw8P9/f33W630%2bn8qBP7FAaDwc9E2DYHmjmB1CbSGA6HIvkUG8perwdHv98fJELh%2bfn5PZeS%2bfunvL290QknqXRz4dOan8fHR2olBsdlktWyHgSL1MuFX2v8WfBuR7wifC8RIHzSgUNNIJ7pOL2%2bvoYtt3d3d1EuxDXkUFMB9oyjuEBgOnKIVrE/DlaaPEOBg13mcAA3a6MqWgCAx6I2jazU1qenp7R9tRY7CGiI8fLyEu2Udk5JQA9vNCVPM2o4fUp2rq%2bvz87OorVqEuD38vKSxtXVlYU0NExJtXrr0aHJpN1us01Jqs0Z4nB%2be3vLlomUmlsrOOJfApi9uLiwSJ1/JMAvHHEc0ekrvXFtF5tiQxDHg/AOWS2pablOTk5w32q1dnd3hTg/P2fbfNvQcYMdHR1tbW35vMmlMMmiW0CBm%2bre3h4l64losCIHvlq56Ao78qlFEzuIp09ze3t7fX398PBQMshqMHHkIsmdnZ3FxcXNzU11xkKh/5EAJar7%2b/urq6sbGxuhJF5cLFUR%2bPj4GFyg19bWVlZW7Kgv/YkJROkODg46uWBqXBT%2bpQebhQbBrDoLZKc4clnRZLz4OZqHgRgORsPjTzMeJpiYK5oExvVD7IgtB/2wtLS0sLCAIxGjVwGqjYLKqAC%2blpeXo4B2/p6B0OPIblx5MMW6%2bQyoGATxOBDo5Vw97ukaSjhwyT/ioYmLpfkQB0Fxgn3GwftyBkIih3YugX6iIIayNDhFLQ%2beoXH3qXr6lU5cdD4BKi6u5jeOlUDgFV1avoUiG6fWrR/v1MQhpCBYGtDEHKEsAvQ/BeLiqUaKrwEo3sRSicbNp9wChiCtUUWVVYeN6efBQlPOxXyB1JhnhrmIHY/XTDOpY4kRfuL5I3ElVrFlo/kJ17CiVhroTyclWZVG1%2bpODLPF/cMqxpbm5LM5oq%2b%2b3MUQCl86ukZu6Y6K4biYW6cfqudZgTn%2b%2b5n%2bz9ofhAjTd/wPZrcAAAAASUVORK5CYII=' /%3e%3c/svg%3e" data-srcset="/assets/static/sudoku-graph1.82a2fbd.a964474d9018de0f0aaf005304ce9f9e.png 480w, /assets/static/sudoku-graph1.262fba3.a964474d9018de0f0aaf005304ce9f9e.png 821w" data-src="/assets/static/sudoku-graph1.262fba3.a964474d9018de0f0aaf005304ce9f9e.png" srcset="https://rakhman.info/assets/static/sudoku-graph1.82a2fbd.a964474d9018de0f0aaf005304ce9f9e.png 480w, https://rakhman.info/assets/static/sudoku-graph1.262fba3.a964474d9018de0f0aaf005304ce9f9e.png 821w"></p>
<p>A <a href="https://en.wikipedia.org/wiki/Component_(graph_theory)" target="_blank" rel="nofollow noopener noreferrer">component</a> is a subgraph where all vertices are connected directly or indirectly. If you start at any cell you can construct the component it's part of using a breadth-first or depth-first search.</p>
<p>We can see that tuples <em>have to be</em> part of a component as they need to share candidates<sup id="fnref-1"><a href="#fn-1">1</a></sup>. But how can we tell if the tuple is <em>useful</em>? Let's ask the opposite question: When is a tuple not useful? If it doesn't share any candidates with another cell, then the tuple must be <em>the whole</em> component. Here's an example:</p>
<p><img src="https://rakhman.info/assets/static/sudoku-graph1_after.8560fc9.dbe97fe18d4799f5a49f399b8b182406.png" width="846" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 846 153' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-03b60ebedf59d3229099e95d98c4ee17'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-03b60ebedf59d3229099e95d98c4ee17)' width='846' height='153' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAMCAIAAABdkSyeAAAACXBIWXMAAAsSAAALEgHS3X78AAACEUlEQVRIx6WWS47CMBBEc/8LcAMkDjAHYA0LZoWQsuH/DSRA%2bGeYJ9co4xAwBnphHKeru6rbsQmulv1YdvWzNyA26g3IDSpwAHyCfgjxZ//oMbBXd7vdcrlMkuR8Pj9Npren0ymOY1BgPdlkWbbdboGs1%2bvL5eLJ/nA4rIwxudMBnCaTSb/fH4/Ho9GIyWazeRoaBt1udzgcgur1etPp9CmE0uA/GAyAMJJIhNzFiqKIRBADxQTx/wKEXCwWvIZ0mqaUB6EQUh8cJcEHz9QYKAjx6GYDA3TiLMh8PkfDI3%2btUyYSsS%2bUSI9MCh1QbsK1Wq12u82uoCGo4hVdzoqmvlMVae50OqCYk4M47vKTGwikG41GGIbMgcDJkQgmEIPet7HIGItSGOiHttIXGH8Zw2M2m0k366uisYJCSBCFSjSbzVqthmyxcQg4Ho84UHicK5VKvV4HzorElxPJ2DPw4S1ZqtUqPWSR8U%2bA2kQI2BOFEbmUBEn6DMr9zTuLDyOh2RVIAqvCOD5HZONJCtUVOAIQ5thCCqtNQSJIMiKpIGC/31NvVmNj6Mt75DC54S/lRLg5Isps8MRNEEZKoI3KhnmUhY2HbNQmxtgaaM6PryAPTTfpgxpKUCL6HIgKJ5TnSarWCUX3fG4GWkSlBGHC2X3/IiOWvp6XbhxBXr1WP0yUo4IP78vc0/%2bvge32XiJ7/Rcr4rn26992uQAAAABJRU5ErkJggg==' /%3e%3c/svg%3e" data-srcset="/assets/static/sudoku-graph1_after.82a2fbd.dbe97fe18d4799f5a49f399b8b182406.png 480w, /assets/static/sudoku-graph1_after.8560fc9.dbe97fe18d4799f5a49f399b8b182406.png 846w" data-src="/assets/static/sudoku-graph1_after.8560fc9.dbe97fe18d4799f5a49f399b8b182406.png" srcset="https://rakhman.info/assets/static/sudoku-graph1_after.82a2fbd.dbe97fe18d4799f5a49f399b8b182406.png 480w, https://rakhman.info/assets/static/sudoku-graph1_after.8560fc9.dbe97fe18d4799f5a49f399b8b182406.png 846w"></p>
<p>If, however, the tuple is part of a bigger component, then it must be useful, i.e. there are candidates that can be eliminated. In our original case, the tuple helps us eliminate us 1 and 9 from the rest of the component.</p>
<p><img src="https://rakhman.info/assets/static/sudoku-graph1_colored.7a5f382.d20250e2b8fbded9a1ce6268eee66188.png" width="794" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 794 220' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-49ff9d1fa77a96567b4ec7bf44d02793'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-49ff9d1fa77a96567b4ec7bf44d02793)' width='794' height='220' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAASCAIAAABkTU91AAAACXBIWXMAAAsSAAALEgHS3X78AAAE%2bUlEQVRIx61WWU8bVxT2T%2btLH/rUh/atD1ULISYsJaQvlaKqEkrVJUkrURLCniZRpSjpoqYLpEvUQlmM2ZcgQijYxuOZO/viGc%2bde3pmLnaM8Rho%2b8HD%2bN57zv3Oek8CTgKL0PgMpbRUBa8h8EBjhawMOAUScSpqVoIgcF0Xr/d937IsTdP0GOCWLMukDLkeyFEoilIsFj00vORRn57Jg4m4DSSKjG3bVlUVaRmGYZomkhNFEX/aVXAchxtWwYluQ3fURAx14kVaBPxAk/BGHq4Gbj1iAN/GZEAHozwnjUCK%2bI1uq6wc8Xfk8hqoZaAq9ELFpNMkBh7gXsCYcJMqxtTVEBpQWXAtBwWQMZqBftXL5PCbZzl67jR5icdoBB5ATgK/D8WrCbCTUwWluDG6rQVQqyHBIPxTbH0xv53a27C9Il4uEYK3ohuOa%2bTXBCxAKd0yN8jeGtklpoY/g5jiwxXq%2b%2bhFmSjoBdd2pSVZ%2bEvUszoKAWtYzRG9MDV8mk3nno0/13Z1GtBwkfEIMEiTZ4PGdL8/h/9jxmx6bzMo%2bQ0cw1VuKdlRdQZFbvqzKL5AdupSeSEbigXZlWy%2bR7bbA7cT1It2/juJsoY1E0mbopW7Jlkdvt8Feqd78KXoud5hBHbkXK81OQzLY7B6G9YGYHFAn5IMtUK0LiHRUPq1STw8BisoheKo5LlyEFdqXJNjO/n3ZXoeds5lpt9YkJK61UzzTwpRosSa4IOfuy7Sc7DbcvDT67/ttwheE2QfCJxgYpys3oD54WDh08zPV7a%2bGWGLfUFqqvCUub5br4vjIm5Nipt4bAQWrwuPezYeDpRSNyE9QVaBxmRExI%2bkZLPFK12CbIs0/trvu%2bfzrA2Eq8T0zZJX5/UIGwD44raktju0Gzbf2hl8eWzlzS3oAvGyahftMALfyyv9sDDMFi6n7l74%2btognb8FC49zy5aia0a9Nm/ouDWRWw6lYBHZJ%2b9/0qf/OQBLj8gyeBTiDRCfSE4yKF4Epc0Wkqr9TuC1gXRFyZO8aZj6sadFUzXTNfdnM1ZHye0Cq5OqbbbXBW4HaO/ZmqyFBkzKT3vp7BgsD9H0reIMfvR60%2bvqXmwKRYtr6j4ew8MYuv7izChEcZO3IqoszgB1W1dbbXYJ7r/67dWXPt9JZlkS8kMkLOUgtgAsxSLdBuuCQrs28sodpzsotULhI7kE4RORMGzztjLTB6lBWByCpS/Y3EMpXSqXSBzwwANpvpfNohQWAIqPilOGZVYPAjVANhRoZvTAepsKzVq2iZjNVHxXVzNabW%2btdRgTfhT1Js9pZYUWzUsCuWCRFZnvhu%2bAYmo/SMv3rPRXZvpXsu4UnTj3VwfBduxfxLW7euqOPjehrGeFA0PTsfc36IkoUiCF/CNR/dA2e0rCDVn9W4u2GnVSvC2shD%2bI9LGufuAInylkTa6018RhjwyYbVlFx2lEvJ4pKJXZ33fNsJ7wueEPn3UMmNA482Ci87fMcW3DNCij1V3rSLiOXUTBF6S8IAgBHJFK8B%2bVxA1OzZ%2bVD9MgwMoWJRGHJScCJ41PL5rEV6qniTDdWfmygDUeSLm2cACUZNdxj0slzjQ2Nx62%2bfCHLy6PQ8Weig1x5cGHheqI8XmOT1MvZpByRp1qGj2rGccXsZHz6xF8AlfKwHSSJAndWlnh1lYm3LpD1wnT6P9ixr%2bI4X/U%2bQ8i4s20LfMurQAAAABJRU5ErkJggg==' /%3e%3c/svg%3e" data-srcset="/assets/static/sudoku-graph1_colored.82a2fbd.d20250e2b8fbded9a1ce6268eee66188.png 480w, /assets/static/sudoku-graph1_colored.7a5f382.d20250e2b8fbded9a1ce6268eee66188.png 794w" data-src="/assets/static/sudoku-graph1_colored.7a5f382.d20250e2b8fbded9a1ce6268eee66188.png" srcset="https://rakhman.info/assets/static/sudoku-graph1_colored.82a2fbd.d20250e2b8fbded9a1ce6268eee66188.png 480w, https://rakhman.info/assets/static/sudoku-graph1_colored.7a5f382.d20250e2b8fbded9a1ce6268eee66188.png 794w"></p>
<p>Let's look at one more example. We can see that the 4789-quadruple allows us to eliminate the 9 from the purple vertex as they are part of a component.</p>
<p><img src="https://rakhman.info/assets/static/sudoku-graph2_colored.41e7f26.34afc064d94ea30c3957db1592335c2f.png" width="967" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 967 228' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-0ca3d0e9f3d486fc088e18419c41b3af'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-0ca3d0e9f3d486fc088e18419c41b3af)' width='967' height='228' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAPCAIAAADbBV4wAAAACXBIWXMAAAsSAAALEgHS3X78AAAEqklEQVRIx71WXU8jVRjmL3rvDYkSRaPRxBv1ZmPihcSYLBS2LWi8MhtIVNaogU1gl9W2UNqylC3sykehLf2amTMzZ77OzJzjM3NKbUvJogm%2bTCaHznve8zzv55kQdyCcc/F/ycRdQw%2bCwIvFcRxCiKqqZED0cWIYhuu6cpfv%2b7ci8FqfRQqhwMPDGzXxkcearhMJcHQ6nVar1Wg06vU63l1FUTRVUVVN0yQTSimw8lhA1ccTBizwbdu2LIvGIlnhF%2bYxHh%2bBg4YIvD7iXL4kCSFuVg8cZusmtSjAgYBpmmAy1lREOAwBCzrQhLN7X/kY38FrsANKLrVDl42JAKw0Y4Gtsegt1VLXDfWRYRybvAdg8LuwXKegnTxuPj8zW45BgWzEDCDuk%2bqWdvRSb4RBMBS6MAQAy6CHen1LPSqTc89j40LMX5HG%2bmVpT686nvsPAXirVqvJSGGhaupITtOG1flcVyat9qShTFvKn0RmTN%2bXpmP9oO0kwu20KCW87FbrRZ8jv0L/o1pMBNspUZpj2Q31hQiGXB36waPm7izLJkVxLsj9ou4FzB/yUSieKocwvij2cNAKKThuFNsJVAkSFI6vVqunp6dYgAPyEl6JUpIFTLDWdwqfEoXJg5U3Vs13POUz06JWyCMF/IlAPFOO5sRO2tu5391M8d20lVMsvRf9%2bPQ97QynPrAyX1/8ng52553sud7CF5weWQjFK60%2bz7aXRHFW2Uw623N%2brkJqsdO5dGLTVJJuLhXkYSFpZ2fD3I52HBGAb1BeSK%2b1tbXl5WWUF/igwlA9pmFS0ySUtGYU/wPRec%2bsTXXcj4TyoamcqdSNFJDmtk5X28Ul8fyL8sr7P38zqzxZ8LYvrK4kIAvuiXqUisF9vL4wc/rrA7FbaP/FqKMj/03Do3ameZgWxfvdjXeXv/ry8Cco5PRjSSCMCRzp9ZSfB4dPM9/fKz1MisJjUokIwNMggCzqdrvtdhsLEAhkjvYKnnceav5bojbd%2bePNbT4tOvd0j3lXCRRZz5MTuORbXkjBSaKwRHOGQwcjUNFrs34WDl7082lRSDq5FlUHFS7MzryL9CimnNyiKMx5mWPjsqcQE1AssuggRYuLXn4pLMDaHqn2agAFhLRRYsFisI7lZps4rRmNvO0ZU0z5hJKyPlADkaBpr6qlhJ9dEPkkzRzoF/3y6Kf4mlJOeBkoLNiZp5cHve09gFF7e6a%2bnHcihYST2VQrskh4nwEXmWYFSYjgJFj2N60cxCOi14XQpCSB0a53hdFzPLVE6huXZsccxtYTn/knerNMLqLsH9dnUS7nRntfq7Ysjdku0cnIkEKuNKiyT87rtCuCcGQawq3M8S71bq5eqZodeOTGOXB9LFzFWTDuGdQwiIGaiUo8CMbOEH7Nzsj0iUwxBkzoe4h/r2eEQX9zGGU%2bB0PoqLFggfFimZT74eAoGp3ENw21eJr09sEuAtUf%2b3Jg2Zbt%2bYzFDxRueR0CbmkNzQNFiFHdVaMHEwmliCmOpEBZQgGGZWWOmcT/6qozgkwi6FOSZORwHfxX/iLvP8awyCsDFORbLlgM93qErwOYuKNLorzb3F7%2b8wX2byuprAPYvfWFAAAAAElFTkSuQmCC' /%3e%3c/svg%3e" data-srcset="/assets/static/sudoku-graph2_colored.82a2fbd.34afc064d94ea30c3957db1592335c2f.png 480w, /assets/static/sudoku-graph2_colored.41e7f26.34afc064d94ea30c3957db1592335c2f.png 967w" data-src="/assets/static/sudoku-graph2_colored.41e7f26.34afc064d94ea30c3957db1592335c2f.png" srcset="https://rakhman.info/assets/static/sudoku-graph2_colored.82a2fbd.34afc064d94ea30c3957db1592335c2f.png 480w, https://rakhman.info/assets/static/sudoku-graph2_colored.41e7f26.34afc064d94ea30c3957db1592335c2f.png 967w"></p>
<p>With this knowledge at hand I found it relatively easy to write down the algorithm. Here's how it could look:</p>
<pre><code>for each row, column, box C
    let g be a graph where cells in C are vertices
    
    for each cell c1 in g
        for each cell c2 in g
            if c1 and c2 share a candidate
                create an edge between c1 and c2

    while g is not empty
        let comp be any component in g
        
        for each subset s of comp
            if size of s == number of distinct candidates in s
            and size of s &lt; size of comp
                return s  

        remove all vertices in comp from g</code></pre>
<p>You can find my own implementation of the algorithm on <a href="https://github.com/cypressious/vue3-sudoku-solver/blob/master/src/logic/strategies/tuples.ts" target="_blank" rel="nofollow noopener noreferrer">Github</a> and the runnable application at <a href="https://sudoku-solver.rakhman.info/" target="_blank" rel="nofollow noopener noreferrer">sudoku-solver.rakhman.info</a>.</p>

<p><sup id="fnref-1"><a href="#fn-1">1</a></sup> Technically, we can construct pseudo tuples that aren't connected where each cell only has one candidate, but then we could immediately enter the digit into that cell.</p>
</div></div>]]>
            </description>
            <link>https://rakhman.info/blog/solving-sudoku-with-graph-theory/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23901678</guid>
            <pubDate>Mon, 20 Jul 2020 20:42:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I no longer host my emails myself]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23901516">thread link</a>) | @jlelse
<br/>
July 20, 2020 | https://jlelse.blog/thoughts/2020/07/no-email-selfhosting/ | <a href="https://web.archive.org/web/*/https://jlelse.blog/thoughts/2020/07/no-email-selfhosting/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Recently, there has been a lot of talk in my blog bubble about email self-hosting again (here is <a href="https://www.paritybit.ca/blog/a-month-and-a-half-of-self-hosted-email" target="_blank" rel="noopener">one example</a>, here is a <a href="https://www.garron.blog/posts/host-your-email-server.html" target="_blank" rel="noopener">second one</a>). I myself <a href="https://jlelse.blog/thoughts/2019/mail-server/">switched to a self-hosted mail server</a> over a year ago, only to <a href="https://jlelse.blog/micro/2020/02/migrated-mailcow/">switch back to a hosted version</a> a few months later.</p><p>For me there were no technical problems running <a href="https://mailcow.email/" target="_blank" rel="noopener">Mailcow</a>, I was even quite happy with my setup. Nevertheless I switched because I realized that email is a topic where it‚Äôs not really worth hosting it myself. Neither is it much cheaper, nor does it bring me many other advantages. Both <a href="https://www.fastmail.com/" target="_blank" rel="noopener">Fastmail</a> in the past and the <a href="https://www.servercow.de/mailcow" target="_blank" rel="noopener">Hosted Mailcow</a>, where I have my emails now, are completely sufficient for my needs.</p><p>I don‚Äôt have to take care of anything myself and just have to make sure that the monthly automatic money withdrawal works successfully. No more updates, no more worries about my server suddenly going down and the backups not working. Someone else with probably more knowledge will take care of it now. And by having my emails hosted by the developer of the open source project mailcow, I support that others still have the easy possibility to host their emails themselves. And of course my emails are stored on a server in Germany and <a href="https://jlelse.blog/thoughts/2019/email-own-domain/">I use my own domains</a> to send and receive emails.</p></div></div>]]>
            </description>
            <link>https://jlelse.blog/thoughts/2020/07/no-email-selfhosting/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23901516</guid>
            <pubDate>Mon, 20 Jul 2020 20:24:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Web-based self-development book on psychological software optimization]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23901460">thread link</a>) | @designingmind
<br/>
July 20, 2020 | https://designingthemind.org/book-vip/ | <a href="https://web.archive.org/web/*/https://designingthemind.org/book-vip/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-wrap">

		
		<div id="primary">

			
			<div id="content">

				
				
<article>

	
<div itemprop="text">
		<div data-url="https://wp.me/PaUpQ4-ZD" data-title="Book-VIP">		<div data-elementor-type="wp-page" data-elementor-id="3821" data-elementor-settings="[]">
			<div>
				<div>
							<section data-id="118191a5" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						<div>
				<div>
				<div data-id="6d51bdf9" data-element_type="column">
			<div>
					<div>
				<div data-id="13aeb90a" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;}" data-widget_type="image.default">
				<div>
					<p><a href="https://designingthemind.org/">
							<img width="768" height="118" src="https://i2.wp.com/designingthemind.org/wp-content/uploads/2020/02/DLog-1.png?fit=768%2C118&amp;ssl=1" alt="" srcset="https://i2.wp.com/designingthemind.org/wp-content/uploads/2020/02/DLog-1.png?w=2167&amp;ssl=1 2167w, https://i2.wp.com/designingthemind.org/wp-content/uploads/2020/02/DLog-1.png?resize=300%2C46&amp;ssl=1 300w, https://i2.wp.com/designingthemind.org/wp-content/uploads/2020/02/DLog-1.png?resize=1024%2C157&amp;ssl=1 1024w, https://i2.wp.com/designingthemind.org/wp-content/uploads/2020/02/DLog-1.png?resize=768%2C118&amp;ssl=1 768w, https://i2.wp.com/designingthemind.org/wp-content/uploads/2020/02/DLog-1.png?resize=1536%2C236&amp;ssl=1 1536w, https://i2.wp.com/designingthemind.org/wp-content/uploads/2020/02/DLog-1.png?resize=2048%2C315&amp;ssl=1 2048w" sizes="(max-width: 768px) 100vw, 768px">								</a>
											</p>
				</div>
				</div>
				
				
				<section data-id="8df4bde" data-element_type="section">
						<div>
				<div>
				<div data-id="09a3425" data-element_type="column">
			<div>
					<div>
				<div data-id="6451e2a" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;,&quot;_animation_delay&quot;:400}" data-widget_type="text-editor.default">
				<div>
					<p><h5><span>YOUR DIGITAL HANDBOOK FOR MASTERING YOUR OWN PSYCHOLOGICAL SOFTWARE, ONE ALGORITHM AT A TIME</span></h5></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="648fdda1" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;,&quot;background_background&quot;:&quot;classic&quot;,&quot;animation&quot;:&quot;fadeIn&quot;,&quot;animation_delay&quot;:700}">
						<div>
				<div>
				<div data-id="33479951" data-element_type="column">
			<div>
					<div>
				<section data-id="749e43b0" data-element_type="section">
						<div>
				<div>
				
				<div data-id="4c1919fd" data-element_type="column">
			<div>
					<div>
				<div data-id="8cbe66b" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><h5><span>YOUR DIGITAL HANDBOOK FOR MASTERING YOUR OWN PSYCHOLOGICAL SOFTWARE, ONE ALGORITHM AT A TIME</span></h5></p>
				</div>
				</div>
				<div data-id="716a0da0" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="1024" height="157" src="https://i2.wp.com/designingthemind.org/wp-content/uploads/2020/02/DLog-1.png?fit=1024%2C157&amp;ssl=1" alt="" srcset="https://i2.wp.com/designingthemind.org/wp-content/uploads/2020/02/DLog-1.png?w=2167&amp;ssl=1 2167w, https://i2.wp.com/designingthemind.org/wp-content/uploads/2020/02/DLog-1.png?resize=300%2C46&amp;ssl=1 300w, https://i2.wp.com/designingthemind.org/wp-content/uploads/2020/02/DLog-1.png?resize=1024%2C157&amp;ssl=1 1024w, https://i2.wp.com/designingthemind.org/wp-content/uploads/2020/02/DLog-1.png?resize=768%2C118&amp;ssl=1 768w, https://i2.wp.com/designingthemind.org/wp-content/uploads/2020/02/DLog-1.png?resize=1536%2C236&amp;ssl=1 1536w, https://i2.wp.com/designingthemind.org/wp-content/uploads/2020/02/DLog-1.png?resize=2048%2C315&amp;ssl=1 2048w" sizes="(max-width: 1024px) 100vw, 1024px">											</p>
				</div>
				</div>
				<div data-id="68621478" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="1024" height="89" src="https://i0.wp.com/designingthemind.org/wp-content/uploads/2020/06/Line-Kink-4.png?fit=1024%2C89&amp;ssl=1" alt="" srcset="https://i0.wp.com/designingthemind.org/wp-content/uploads/2020/06/Line-Kink-4.png?w=2667&amp;ssl=1 2667w, https://i0.wp.com/designingthemind.org/wp-content/uploads/2020/06/Line-Kink-4.png?resize=300%2C26&amp;ssl=1 300w, https://i0.wp.com/designingthemind.org/wp-content/uploads/2020/06/Line-Kink-4.png?resize=1024%2C89&amp;ssl=1 1024w, https://i0.wp.com/designingthemind.org/wp-content/uploads/2020/06/Line-Kink-4.png?resize=768%2C67&amp;ssl=1 768w, https://i0.wp.com/designingthemind.org/wp-content/uploads/2020/06/Line-Kink-4.png?resize=1536%2C134&amp;ssl=1 1536w, https://i0.wp.com/designingthemind.org/wp-content/uploads/2020/06/Line-Kink-4.png?resize=2048%2C178&amp;ssl=1 2048w, https://i0.wp.com/designingthemind.org/wp-content/uploads/2020/06/Line-Kink-4.png?resize=600%2C52&amp;ssl=1 600w, https://i0.wp.com/designingthemind.org/wp-content/uploads/2020/06/Line-Kink-4.png?w=2400&amp;ssl=1 2400w" sizes="(max-width: 1024px) 100vw, 1024px">											</p>
				</div>
				</div>
				<div data-id="655b5195" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="1024" height="119" src="https://i1.wp.com/designingthemind.org/wp-content/uploads/2020/02/DTM-Book-Title-2.png?fit=1024%2C119&amp;ssl=1" alt="" srcset="https://i1.wp.com/designingthemind.org/wp-content/uploads/2020/02/DTM-Book-Title-2.png?w=2000&amp;ssl=1 2000w, https://i1.wp.com/designingthemind.org/wp-content/uploads/2020/02/DTM-Book-Title-2.png?resize=300%2C35&amp;ssl=1 300w, https://i1.wp.com/designingthemind.org/wp-content/uploads/2020/02/DTM-Book-Title-2.png?resize=1024%2C119&amp;ssl=1 1024w, https://i1.wp.com/designingthemind.org/wp-content/uploads/2020/02/DTM-Book-Title-2.png?resize=768%2C89&amp;ssl=1 768w, https://i1.wp.com/designingthemind.org/wp-content/uploads/2020/02/DTM-Book-Title-2.png?resize=1536%2C179&amp;ssl=1 1536w" sizes="(max-width: 1024px) 100vw, 1024px">											</p>
				</div>
				</div>
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="210d73b" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						
		</section>
				<section data-id="c9cd8fb" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;,&quot;background_background&quot;:&quot;slideshow&quot;,&quot;background_slideshow_gallery&quot;:[{&quot;id&quot;:2615,&quot;url&quot;:&quot;https:\/\/designingthemind.org\/wp-content\/uploads\/2020\/05\/AlgoBackground5-01-1-scaled.jpg&quot;}],&quot;background_slideshow_loop&quot;:&quot;yes&quot;,&quot;background_slideshow_slide_duration&quot;:5000,&quot;background_slideshow_slide_transition&quot;:&quot;fade&quot;,&quot;background_slideshow_transition_duration&quot;:500}">
						<div>
				<div>
				<div data-id="7c38203" data-element_type="column">
			<div>
					<div>
				<div data-id="9624bc4" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="7283" height="988" src="https://i0.wp.com/designingthemind.org/wp-content/uploads/2020/02/Draws-01-01.png?fit=7283%2C988&amp;ssl=1" alt="" srcset="https://i0.wp.com/designingthemind.org/wp-content/uploads/2020/02/Draws-01-01.png?w=7283&amp;ssl=1 7283w, https://i0.wp.com/designingthemind.org/wp-content/uploads/2020/02/Draws-01-01.png?resize=300%2C41&amp;ssl=1 300w, https://i0.wp.com/designingthemind.org/wp-content/uploads/2020/02/Draws-01-01.png?resize=1024%2C139&amp;ssl=1 1024w, https://i0.wp.com/designingthemind.org/wp-content/uploads/2020/02/Draws-01-01.png?resize=768%2C104&amp;ssl=1 768w, https://i0.wp.com/designingthemind.org/wp-content/uploads/2020/02/Draws-01-01.png?resize=1536%2C208&amp;ssl=1 1536w, https://i0.wp.com/designingthemind.org/wp-content/uploads/2020/02/Draws-01-01.png?resize=2048%2C278&amp;ssl=1 2048w, https://i0.wp.com/designingthemind.org/wp-content/uploads/2020/02/Draws-01-01.png?w=2400&amp;ssl=1 2400w, https://i0.wp.com/designingthemind.org/wp-content/uploads/2020/02/Draws-01-01.png?w=3600&amp;ssl=1 3600w" sizes="(max-width: 1200px) 100vw, 1200px">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="a292df9" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						<div>
				<div>
				<div data-id="a0c63be" data-element_type="column">
			<div>
					<div>
				<div data-id="3f42740" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;,&quot;_animation_delay&quot;:400}" data-widget_type="text-editor.default">
				<div>
					<div><h2><span color="#ffffff" face="Armata, Courier New, Courier, monospace"><span>‚ÄúTHE WAY YOUR MIND IS STRUCTURED WILL DETERMINE THE PERSON YOU WILL BECOME, THE LIFE YOU WILL LIVE, AND THE FULFILLMENT YOU WILL REALIZE. WHEN YOU MODIFY YOUR MIND, YOU MAKE CHANGES TO THE OPERATING SYSTEM AT YOUR CORE AND CHANGE YOUR PERSONAL TRAJECTORY. AND WHEN YOU MAKE A PERSISTENT OCCUPATION OF THIS ENDEAVOR, YOU BECOME THE ARCHITECT OF YOUR OWN CHARACTER.‚Äù</span></span><br></h2>
<p><i>Designing the Mind: The Principles of Psychitecture</i>&nbsp;is the first book created by DTM. It is a psycho-philosophical self-development book that makes the bold claim that the human condition as you know it ‚Äì is optional. That it is possible for you to unplug from your own mind, examine it from above, and modify the very psychological code on which you operate, permanently altering its limiting default patterns.&nbsp;</p>
<p><span>Whether fear prevents you from pursuing your ambitions, jealousy ruins your relationships, distractions rule your life, or you have an inner critic whose expectations you are never able to meet, the psychitectural framework will enable you to understand and rewire the hidden patterns behind your biases, habits, and emotional reactions.</span><span>&nbsp;</span><span>DTM will be your</span><span>&nbsp;handbook for mastering your behavior, cognition, and emotions, and&nbsp;</span><span>terraforming your mind into a truly delightful place to reside</span><span>.</span></p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="9b11f72" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;,&quot;background_background&quot;:&quot;classic&quot;,&quot;animation&quot;:&quot;fadeIn&quot;,&quot;animation_delay&quot;:700}">
						<div>
				<div>
				<div data-id="010fd5e" data-element_type="column">
			<div>
					<div>
				<div data-id="1bb49e4" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="768" height="710" src="https://i0.wp.com/designingthemind.org/wp-content/uploads/2020/06/Aristotle-Glitcho.jpg?fit=768%2C710&amp;ssl=1" alt="" srcset="https://i0.wp.com/designingthemind.org/wp-content/uploads/2020/06/Aristotle-Glitcho.jpg?w=1228&amp;ssl=1 1228w, https://i0.wp.com/designingthemind.org/wp-content/uploads/2020/06/Aristotle-Glitcho.jpg?resize=300%2C278&amp;ssl=1 300w, https://i0.wp.com/designingthemind.org/wp-content/uploads/2020/06/Aristotle-Glitcho.jpg?resize=1024%2C947&amp;ssl=1 1024w, https://i0.wp.com/designingthemind.org/wp-content/uploads/2020/06/Aristotle-Glitcho.jpg?resize=768%2C710&amp;ssl=1 768w, https://i0.wp.com/designingthemind.org/wp-content/uploads/2020/06/Aristotle-Glitcho.jpg?resize=600%2C555&amp;ssl=1 600w" sizes="(max-width: 768px) 100vw, 768px">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				<div data-id="02c9ae2" data-element_type="column">
			<div>
					<div>
				<div data-id="cb6f82a" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;,&quot;_animation_delay&quot;:400}" data-widget_type="text-editor.default">
				<div>
					<p><h2>ANCIENT WISDOM, <br>MODERN FRAMEWORK</h2></p>
				</div>
				</div>
				
				<div data-id="3f7705e" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>DTM integrates the wisdom and insights of ancient mystics, practical philosophers, and cognitive scientists into a modern, rational mindset and method for reprogramming your own psychological software. Though it is based on the puzzle pieces of ancient philosophical insight, it comes together to form a new picture.</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="7d1076b" data-element_type="section" data-settings="{&quot;animation&quot;:&quot;fadeIn&quot;,&quot;animation_delay&quot;:400,&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						<div>
				<div>
				<div data-id="e9ea2fa" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
			<div>
					<div>
				<div data-id="170ebaa" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><em><b>‚ÄúI would already put it in my would-recommend and reread bookshelf.‚Äù</b></em></p>
				</div>
				</div>
				
						</div>
			</div>
		</div>
				<div data-id="d984b49" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
			<div>
					<div>
				<div data-id="0cff470" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><em><b>‚ÄúThe author has clearly devoted a lot of thought not only to the overall psychitectural metaphor, but to the interlocking algorithms and components that make it up, the concrete advice that springs from the system, and the curated wisdom from previous masters. The result is thoroughly engaging.‚Äù</b></em></p>
				</div>
				</div>
				
						</div>
			</div>
		</div>
				<div data-id="9c808f5" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
			<div>
					<div>
				<div data-id="1c79980" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><b><em>‚Äú</em><i>This is amazing.&nbsp;</i><i>Sign me up, man. I want to be a part of this.‚Äù&nbsp;</i></b></p>
				</div>
				</div>
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="c84b35c" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;,&quot;background_background&quot;:&quot;classic&quot;,&quot;animation&quot;:&quot;fadeIn&quot;,&quot;animation_delay&quot;:700}">
						<div>
				<div>
				<div data-id="5348191" data-element_type="column">
			<div>
					<div>
				
				
				<div data-id="fbd466a" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><i>DTM</i> is built primarily as a web-book because the web medium enables total design freedom, useful interactivity, and quick updates.&nbsp;<span>Readers are encouraged to offer feedback, and will have access to all future versions.&nbsp;</span><span>This book is a living, breathing document which will continue to take shape over time.&nbsp;</span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
				<div data-id="adccc16" data-element_type="column">
			<div>
					<div>
				<div data-id="5c3c7e7" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="1024" height="704" src="https://i2.wp.com/designingthemind.org/wp-content/uploads/2020/06/Maockupii.png?fit=1024%2C704&amp;ssl=1" alt="" srcset="https://i2.wp.com/designingthemind.org/wp-content/uploads/2020/06/Maockupii.png?w=1750&amp;ssl=1 1750w, https://i2.wp.com/designingthemind.org/wp-content/uploads/2020/06/Maockupii.png?resize=300%2C206&amp;ssl=1 300w, https://i2.wp.com/designingthemind.org/wp-content/uploads/2020/06/Maockupii.png?resize=1024%2C704&amp;ssl=1 1024w, https://i2.wp.com/designingthemind.org/wp-content/uploads/2020/06/Maockupii.png?resize=768%2C528&amp;ssl=1 768w, https://i2.wp.com/designingthemind.org/wp-content/uploads/2020/06/Maockupii.png?resize=1536%2C1056&amp;ssl=1 1536w, https://i2.wp.com/designingthemind.org/wp-content/uploads/2020/06/Maockupii.png?resize=600%2C412&amp;ssl=1 600w" sizes="(max-width: 1024px) 100vw, 1024px">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="6b16e89" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;,&quot;background_background&quot;:&quot;slideshow&quot;,&quot;background_slideshow_gallery&quot;:[{&quot;id&quot;:2605,&quot;url&quot;:&quot;https:\/\/designingthemind.org\/wp-content\/uploads\/2020\/05\/AlgoBackground4-01.png&quot;}],&quot;background_slideshow_loop&quot;:&quot;yes&quot;,&quot;background_slideshow_slide_duration&quot;:5000,&quot;background_slideshow_slide_transition&quot;:&quot;fade&quot;,&quot;background_slideshow_transition_duration&quot;:500}">
						<div>
				<div>
				<div data-id="03f0416" data-element_type="column">
			<div>
					<div>
				<div data-id="b29ea5b" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>‚ÄúTHOUGH ONE MAY CONQUER A THOUSAND TIMES A THOUSAND MEN IN BATTLE, YET HE INDEED IS THE NOBLEST VICTOR WHO CONQUERS HIMSELF.‚Äù</span></p><p><span><span><span>‚Äì&nbsp;</span></span></span><span><span><b>SIDDHƒÄRTHA GAUTAMA</b></span></span></p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="0c0c68d" data-element_type="section">
						
		</section>
						</div>
			</div>
		</div>
		</div>	</div> 
</article>
				
			</div><!-- #content -->

			
		</div><!-- #primary -->

		
	</div></div>]]>
            </description>
            <link>https://designingthemind.org/book-vip/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23901460</guid>
            <pubDate>Mon, 20 Jul 2020 20:19:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenAI GPT-3: automatic web development?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23901334">thread link</a>) | @ezrakewa
<br/>
July 20, 2020 | https://www.4alltech.com/2020/07/openai-gpt-3-impressive-web-development.html | <a href="https://web.archive.org/web/*/https://www.4alltech.com/2020/07/openai-gpt-3-impressive-web-development.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<div id="post-body-178842567621268750" itemprop="articleBody">
<meta content="  Dictation instead of programming: Developer Sharif Shameem takes advantage of the quick grasp of OpenAI's speech AI GPT-3 and teaches ..." name="twitter:description">
<div id="adsense-target">
<p><span>Dictation instead of programming: Developer Sharif Shameem takes advantage of the quick grasp of OpenAI's speech AI GPT-3 and teaches it rudimentary web development with two examples.</span><img data-original-height="803" data-original-width="1000" height="512" src="https://1.bp.blogspot.com/-MA-6-FymqGQ/XxX3w9SV3sI/AAAAAAAAAdI/Fa56J_IphdIyCI8YrQYSS9easXpOwDgdACLcBGAsYHQ/s640/GPT-3-Frontend-Beispiel.jpg" width="640"><span><br>In early 2019, OpenAI introduced the language AI GPT-2, on the basis of which developer Jacob Jackson developed the code editor Deep TabNine : It offers AI-based auto-completion for programming code .<p>Jackson only had to train GPT-2 with source codes from the GitHub database and the AI ‚Äã‚Äãcould recognize for 22 programming languages which command would probably have to appear next in a line of code .</p><p>Deep TabNine showed that language AIs like GPT-2 are more than text generators. Programmers were enthusiastic and described the AI ‚Äã‚Äãaddition as "amazing", "crazy" and "incredible".</p><u>Programming with AI - level two</u></span></p><div>
<p><span><u><br></u>In May 2020, OpenAI launched GPT-3 . The successor to GPT-2 is a hundred times larger, writes even better texts - and is, particularly important, suitable for so-called Few-Shot-Learning (explanation) : GPT-3 masters new tasks with just a few training examples instead of those for Deep TabNine, for example necessary two million excerpts of code.<p>This adaptability also comes about through the comprehensive basic training: While 40 gigabytes of text from the online platform Reddit were used to train GPT-2, GPT-3 is trained with a total of 570 gigabytes of text .</p></span></p><p><span>Part of the huge data set comes from the Common Crawl text archive. The non-profit organization has been systematically collecting Internet texts since 2011 - regardless of whether it's a blog post, Reddit comment or just a code example.<u>Websites on demand: GPT-3 as a web developer</u></span></p>
<p><span>Computer specialist Sharif Shameem has now trained a kind of AI front-end developer via the newly available commercial GPT3 interface . Frontend developers mainly build user interfaces for an app or a website. Shameem only needed two code examples for the AI training , which he fed GPT-3.</span></p>
<p><span>Following these two simple examples, GPT-3 can generate JSX code based on well-written descriptions . For example, when entering ‚ÄúOne button for each color of the rainbow‚Äù, the AI ‚Äã‚Äãwrites the appropriate JSX code for seven differently colored buttons.<p>The voice command "A table of the richest countries in the world with the columns Name and BiP" generates a corresponding table. The sentence ‚ÄúA button the color of Donald Trump's hair‚Äù produces a yellow button.</p><p>The same results are also possible for pure HTML and CSS code, Shameem writes. All that would be needed to train the AI ‚Äã‚Äãwere two other corresponding code examples.</p><u>Fast learner AI: The trick is diverse pre-training</u><br>The extensive pre-training of GPT-3 is what makes Shameem's programming AI possible. While Deep TabNine had to be trained with a large number of code examples , GPT-3 already has the basic understanding of code and language.<p>With just a few examples, AI only needs to point a finger in the right direction to convert voice commands into suitable code. In addition, she has more context knowledge in the neural network thanks to extensive preliminary training - such as Trump's hair color.</p><u>No developer has yet to fear for his or her job</u><br>Shameem's example shows that OpenAI's GPT-3 brings us closer to a future where developers can tell the computer - even literally - what code to write instead of typing line by line . Deep TabNine inventor Jackson describes AI-based programming as his vision of the future.<p>Jobs will not replace an AI tool like Shameem's for the time being, but will simplify and speed up the work of developers by quickly rudimentary code.</p><p>In the long term, AI tools could revolutionize developer work wherever repetitive programming tasks are commonplace. In addition to web front-end professionals, this also applies to back-end developers, according to Shameem. You would have to "prepare for a wild ride".</p><p>Based on his GPT-3 experience, the developer even assumes that a general, versatile AI can be reached in less than ten years - previously he had predicted more than 50 years.</p></span></p>
</div>


</div>
</div>
</article></div>]]>
            </description>
            <link>https://www.4alltech.com/2020/07/openai-gpt-3-impressive-web-development.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23901334</guid>
            <pubDate>Mon, 20 Jul 2020 20:04:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on 'Marketing for Developers']]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23901306">thread link</a>) | @christian_fei
<br/>
July 20, 2020 | https://cri.dev/posts/2020-07-08-Notes-on-Marketing-for-Developers-devmarketingxyz/ | <a href="https://web.archive.org/web/*/https://cri.dev/posts/2020-07-08-Notes-on-Marketing-for-Developers-devmarketingxyz/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>Purchased a convenient bundle <em>a few years ago</em>. Time passes, and nearly forgot about the book and course.
Priorities. Life. You know, first world problems.</p>
<p>Resumed the course, this time for real, and I‚Äôm trying to motivate myself by taking notes about my learnings.</p>
<p>Buy it here <a href="https://devmarketing.xyz/">Marketing for Developers ‚Äì advice for programmers, software, and SaaS</a></p>
<hr>

<p>‚ÄúBuild the right product‚Äù, sounds clich√©, but that‚Äôs the hard truth.</p>
<p>‚ÄúBuild something people want‚Äù is another often used quote.</p>
<p>If your product gets recommended by other people, by word of mouth, it‚Äôs even better. That‚Äôs when you know you hit the nail on the head.</p>
<p>Don‚Äôt fall in love with your ideas. Validate them first, ASK the right people if they would be interested and if they are solving a problem they are having in a different way.</p>
<p>‚ÄúInspiration doesn‚Äôt always lead to great products‚Äù.</p>
<p>Don‚Äôt focus on the idea, or on yourself. Focus on the customer and if your idea could solve a problem they are actually struggling with.</p>
<p>Talk to people. Talk. to. people.</p>
<p>If you want to do good marketing, find an actual problem people have, and that they will pay you to solve it.</p>

<p>Not all markets or niches are the same, in terms of customers willing to pay for your product.</p>
<p>Evaluate if a specific customer base are motived to spend money, acquisition of potential customers is feasible, and that the niche is big enough to bring home some $$$.</p>
<p>Find customer for whom you want to work.</p>
<p>Get started by determining topics you‚Äôre passionate about, evaluate a good market (are they willing to pay).
Do your research, don‚Äôt necessarily look at competitors, look at the issues your potential customers face, and if you can solve their problem(s).
Now you can decide wether it could be worth to build a product for them or not.</p>
<p>Remember: you build a product for THE CUSTOMER. Not for yourself. Not to try a fancy new framework/library/technology.</p>
<p>FOCUS ON THE CUSTOMER, damnit.</p>
<p>Try to answer these questions:</p>
<ul>
<li>is the market quite easy to reach (socials, cold calling, email, others)</li>
<li>does the market have buying power?</li>
<li>are your potential customers willing to improve the way they work?</li>
<li>is the market too small and profits could be difficult to achieve?</li>
<li>do you like working and solving the problems your customers are having? are you passionate about the niche?</li>
</ul>
<blockquote>
<p>don't start a recipe book if you hate cooking.</p>
</blockquote>

<p>JTBD (acronym for "Jobs to be done")</p>
<p>Theory for getting a grasp what brings customer to buy your product.</p>
<p>It tries to focus on THE CUSTOMER's needs, pain-points in their process and daily activities.</p>
<p>To be able to understand your customer's needs, you need to understand their daily routine, repetetive and time-consuming tasks, and if they're motivated to change their process.</p>
<p>Do customer interviews. Ask people what issues they're facing on a dayly basis.</p>
<p>Additionally, look how the potential customer's are behaving (e.g. social media, blogs) and what bring users to a certain purchase.</p>

<p>What do your potential customers really want?</p>
<p>Only if you bring them valuable and actual problem-solving solutions, you could have <em>a chance</em> of getting a new potential customer on board.</p>
<p>Find pain-points, patterns, common problems faced by potential customers.</p>
<p>Hang out on Twitter, Reddit, Facebook with people from a certain niche. Use #hashtags, /r/subreditts and join a few interesting groups to discuss and observe patterns and problems users are facing.</p>
<p>Write down a hypthesis of the patterns you recognized and a theory about what the customer wants. One sentence.</p>
<p>Look at it. Does it make sense? Is it actually the biggest hurdle users are facing?</p>
<p>Now create a landing page, with focus on the pain-point. Do people sign up and click on the call-to-action button?</p>
<p>If you can provide a free guide to something. If people sign up for a free resource, maybe they're interested at your solution ot their problem after all.</p>
<p>Now. Ask people if they would buy (the product you're advertising on a landing page, a working prototype, etc).</p>
<blockquote>
<p>Would you pay for this if it existed?</p>
</blockquote>
<p>Now build. Notice that until now you barely touched code?</p>

<p>If you find something people don't like and want it to be easier, you've found a struggle people have. That could be a good start.</p>
<p>Additionally, choose a market in which you something about. If you're a complete noob in that field, you are going to have a hard time</p>
<p>To be a product person, you need to humble and follow the servant's mindset.</p>
<blockquote>
<p>"What do customers need? How can I help them?"</p>
</blockquote>
<p>Ask yourself: how painful is this struggle a user is facing?</p>
<p>You can categorize it with:</p>
<ul>
<li>extreme pain</li>
<li>moderate pain</li>
<li>low pain</li>
</ul>
<p>Based on the answer, you'll understand how likely a user is willing to pay, and how much.</p>
<p>For extreme pain, pull marketing should be alright (SEO + SEM)</p>
<p>Moderate pain: Push &amp; pull marketing</p>
<p>Low pain: lots of pull marketing</p>
<p>Inverse relation between intensity of pain and number of exposures to a user!</p>
<p>Extreme pain, low exposures. Low pain, high exposures.</p>

<p>Get data, don't miss out on opportunities to get people signup to a mailing list.</p>
<p>Create a simple landing page, helps to concentrate of what <em>your users want</em>.</p>
<blockquote>
<p>Marketing is about testing, analyzing the data and then iterate</p>
</blockquote>
<p>Start with</p>
<ul>
<li>Google Webmaster tools</li>
<li>Any analytics service (Segment, Google Analytics, Plausible Analytics)</li>
<li>Optionally set up an A/B testing tool</li>
<li>Set up a mailing list</li>
</ul>
<blockquote>
<p>My email list is my most important asset - Nathan Barry</p>
</blockquote>

<p>Many types of marketing channels:</p>
<ul>
<li>word of mouth</li>
<li>ads</li>
<li>partnerships</li>
<li>events</li>
<li>sales</li>
<li>seo</li>
<li>content marketing</li>
<li>email marketing</li>
</ul>
<p>What seems to work really well are content and email marketing:</p>
<ul>
<li>blogging, videos, landing page</li>
<li>interest-based mailing-list, weekly newsletters</li>
</ul>
<blockquote>
<p>Across all markets, email consistently outperforms other channels</p>
</blockquote>
<h2>Landing page</h2>
<ul>
<li>primary goal: mailing list</li>
<li>then, get people to buy</li>
</ul>
<p>Effective landing page</p>
<ul>
<li>headline, what advantages does this product bring to the customer
<ul>
<li>what is their main struggle, how do we solve it</li>
<li>focus on the customer struggle, using "you"</li>
<li>use verbs</li>
</ul></li>
<li>body
<ul>
<li>visuals near top, engagement with nice image</li>
<li>what are the benefits?</li>
<li>social proof</li>
<li>describe your features</li>
<li>call to action</li>
</ul></li>
<li>footer
<ul>
<li>Who made this site</li>
<li>contact</li>
</ul></li>
</ul>
<p>focus on the words.</p>

<p>Similarly to launching a product, you need to do research, find pain points your audience has and wants to know more about. Then make the content reach people through marketing.</p>
<p>Ideally</p>
<ul>
<li>one pain point per blog post</li>
<li>follow trends?</li>
<li>make people feel comfortable, make it relatable, make them laugh</li>
<li>teach something new</li>
<li>unique content, shows trust</li>
<li>engage with people</li>
</ul>
</div></div>]]>
            </description>
            <link>https://cri.dev/posts/2020-07-08-Notes-on-Marketing-for-Developers-devmarketingxyz/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23901306</guid>
            <pubDate>Mon, 20 Jul 2020 19:58:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Strongest Argument for Decentralized Tech May Be Security]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23901192">thread link</a>) | @msten
<br/>
July 20, 2020 | https://mattstenson.com/posts/the-strongest-argument-for-decentralyzed-tech-may-be-security/ | <a href="https://web.archive.org/web/*/https://mattstenson.com/posts/the-strongest-argument-for-decentralyzed-tech-may-be-security/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://www.vice.com/en_us/article/jgxd3d/twitter-insider-access-panel-account-hacks-biden-uber-bezos">Twitter got hacked real good last night</a>. From all appearances it doesn‚Äôt appear to be a technical hack, but a social engineering hack of employees with almost limitless access to the platform.</p><blockquote><p>As centralized tech companies have become the norm for political, economic and public health discourse a new threat model has reared it‚Äôs head. Centralized systems have centralized admins.</p></blockquote><p>Those centralized admins (the humans) and their related systems are one of the biggest security holes in these systems. Moderators and administrators have a wild amount of power. And that power can be manipulated by manipulating the humans instead of the tech.</p><p>I‚Äôm sure twitter will come out with some post-mortem statement about how they are securing their admin panels, yadda yadda. But the reality remains that centralized tech will always have centralized admins. This vulnerability is not trivial.</p><p>Nuclear superpowers have had this issue and have had to go to incredible lengths to mitigate the threat. Even their procedures seem a bit weak and rely on layers of physical security for the individuals and systems involved (literally people in bunkers).</p><iframe width="560" height="315" src="https://www.youtube.com/embed/FVZmFISzqwY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><p>Moderators at social media companies have been shown to not be <a href="https://www.theverge.com/2020/5/12/21255870/facebook-content-moderator-settlement-scola-ptsd-mental-health">the most mentally stable individuals</a>. Tech workers are often easily blackmailed. People are a security threat that is not easily modeled or mitigated at a monolithic platform.</p><h2 id="the-obvious-solution">The Obvious Solution</h2><p>A solution to this problem is pretty obvious. Reduce the power of any single admin. Even in the nuclear bunker, one officer can‚Äôt launch the missile. One of the most effective ways to do this is by decentralizing out communications platforms.</p><p>For example, government leaders online statements should probably come from a government domain, government IP address and be signed by a public / private key combination. We have plenty of tools to do this type of work. RSS would work just fine and allow a authentication trail that everyone from media outlets to private individuals could use to validate posts.</p><p>Of course whitehouse.gov security would still be only as good as the administrators there. But, if the security there is compromised only whitehouse.gov is compromised. A mass pawning of hundreds or thousands of influential information sources becomes non-trivial and near impossible.</p><p>This is not just a suggestion for very large organizations but also for smaller ones. My local police department disseminates public safety information on Facebook. When there was a SWAT team on my block, the only way for me to get information was by looking on Facebook.</p><p>Having to opt-in to Facebook to get public safety information has it‚Äôs own serious issues. But on top of that, what happens if hundreds of police department‚Äôs social media accounts are compromised simultaneously and say‚Ä¶ announce martial law?</p><p>The web is better and more secure when no one person holds the keys.</p></div></div>]]>
            </description>
            <link>https://mattstenson.com/posts/the-strongest-argument-for-decentralyzed-tech-may-be-security/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23901192</guid>
            <pubDate>Mon, 20 Jul 2020 19:44:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[People are acting hysterical because they have suffered a collective trauma]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23901085">thread link</a>) | @rplst8
<br/>
July 20, 2020 | https://www.rintrah.nl/people-are-acting-hysterical-because-they-have-suffered-a-collective-trauma/ | <a href="https://web.archive.org/web/*/https://www.rintrah.nl/people-are-acting-hysterical-because-they-have-suffered-a-collective-trauma/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2594">
	
		<div>
<figure>
<img src="https://www.rintrah.nl/wp-content/uploads/2020/06/abandoningreality-600x381.jpg" alt="" title="abandoningreality">
</figure>
<p><a href="https://www.rintrah.nl/wp-content/uploads/2020/06/abandoningreality.jpg"><img src="https://www.rintrah.nl/wp-content/uploads/2020/06/abandoningreality.jpg" alt="" width="600" height="660" srcset="https://www.rintrah.nl/wp-content/uploads/2020/06/abandoningreality.jpg 600w, https://www.rintrah.nl/wp-content/uploads/2020/06/abandoningreality-273x300.jpg 273w" sizes="(max-width: 600px) 100vw, 600px"></a></p>
<p><em>‚ÄúRenouncing the world‚Äù ceases to be an achievement and becomes a temptation as Progress progresses.&nbsp;</em>&nbsp;-Don Colacho</p>
<p>I‚Äôve had Salvia trips in the middle of the forest at dusk, during which a fifth dimension opened behind me and clowns at a supernatural carnival began mocking me. I felt less alienated from society when that happened than I do lately. What do you do when the world around you stops making sense and people seem to have collectively lost their minds? Some people just decide to lock themselves up in their homes and start reading fantasy novels and playing video games. I don‚Äôt really do that, because I get nothing concrete in return for that.</p>
<p>Rather, I generally just look for some ways to earn money. That might sound shallow and vain, but I‚Äôm in an era of my life where I become practical and realistic. I don‚Äôt like the concept of being forced to work. In addition to this, there is a range of things I like to do with my life, as I grow older the range of things that require cash begins to expand. As a teenager I could entertain myself simply by staring at a colony of ants for an hour (autism is a blessing in disguise, don‚Äôt let anyone tell you otherwise). I still enjoy going to the forest, but I now realize that my time on this Earth is scarce and fleeting.</p>
<p>With two months of investing, I have now earned as much money as I do in half a year of work, if you take taxes into consideration. In contrast to my day job, I genuinely consider investing fun. Essentially, I earned 17,000 euro doing something that I enjoy doing. One of the fun parts about it is that you can laugh at the normies. Some numale coworker said mean things to me because I upset him by explaining why the batsoupflu is no big deal? Say mean things to my 17,000 euro.</p>
<p>The part that I like most about it is being right when most people are wrong. If you wonder why I wrote essay after essay about the batsoupflu, now you know. For the past few months, understanding this virus was basically part of my job. I already sold some of my stock, because they‚Äôve shot up so rapidly that I can no longer consider them undervalued. If you‚Äôre interested, I‚Äôll explain some of my ideas on investing in my next post. If you‚Äôre not interested, I‚Äôll probably still do it.</p>
<h2>Why have people lost their minds?</h2>
<p>I think it‚Äôs important to help you understand how this mass outbreak of hysteria could take place. Remember, we are in a situation of mass hysteria. Just because it seems that almost everyone considers what‚Äôs happening now normal does not somehow make it normal. Back after 9/11, Bush had a 90% approval rating. In Austria, 99% of people once voted to be annexed by Nazi Germany. In Egypt, around 90% of people support the death penalty for people who leave Islam. An idea or a mentality can be extremely popular, yet nonetheless extremely stupid.</p>
<p>What has taken place in the past few months, is extremely traumatic for normal prosocial people.&nbsp;People behave as if they have lost their minds, because they have gone through a collective trauma in the past few months. Unlike weirdo‚Äôs like you and me, normal prosocial people have a deep faith in the institutions that govern their society, as well as a deep fear of death that they normally have to suppress.</p>
<p>For most people, March 2020 was an absolute unimaginable nightmare. People were afraid to leave their homes. They were locked inside their houses and told that their only valid excuse to leave their house was to visit the supermarket. They saw their prime minister on TV, addressing the whole nation, telling people that a new deadly virus had spread across the country, a virus that would kill one out of every thirty people it infects.</p>
<p>This virus was not going away without a vaccine, it was going to flood the intensive care with patients. We had to stay inside, to make sure the intensive care would not be overcrowded. Those of us who are not part of the 3.4% of infected people who die, would spend weeks in the hospital, stuck on a mechanical ventilator. Our lungs would be damaged for the rest of our lives.</p>
<p>Remember, that‚Äôs what you were told. You‚Äôre already trying to rewrite the narrative in your head, because what you were genuinely told by the media is so extremely traumatic that you can‚Äôt properly deal with it. You have basically functioned in survival mode for weeks. You were essentially told that something had spread out of Southern China, that would wipe humanity out like a bad case of fleas. The Catholic Pope and European politicians were speculating that this must be nature‚Äôs vengeance against humanity. The media was showing you pictures of corpses laying in the streets of Italy.</p>
<p>People remember this, but they‚Äôre trying to suppress it. You‚Äôre now trying to write a narrative in your head, that you were always told that this was just going to be a heavier than usual flu season. You‚Äôre trying to make what happened to you fit in your head. You‚Äôre trying to convince yourself that what happened makes sense.</p>
<p>But the reality is of course that it doesn‚Äôt make sense. It didn‚Äôt make any sense from the start. The experts you place trust in, have completely failed you. For modern progressives, this has been a hugely traumatic experience. Conservatives have a history of being skeptical towards experts. They don‚Äôt believe experts when experts warn them about climate change, when experts tell them that we evolved from an ape-like animal, or when experts tell them that vaccines are safe.</p>
<p>In addition to this, conservatives are able to put the issue of death into perspective. Some of them are veterans, they have lived through experiences where their lives were at risk. Most conservatives are religious, they have faith that although they will eventually die, their deaths make sense in the bigger picture. Conservatives respond to what has happened with anger at the media and at their politicians.</p>
<p>For progressive people, there is no proper response to this. Remember, young people signed up for huge college debts, with the idea in the back of their heads that scientists can deliver us some sort of objective truth about the world we inhabit. Imagine spending 90,000 dollar to learn about epidemiology in college, only to discover that epidemiologists have caused the implosion of the global economy, by being wrong about a virus.</p>
<p>The political establishment that embraced these lockdowns, is almost without exception progressive. They had to struggle against people like Trump, who were downplaying the virus. And now we face a situation, where the average Joe with common sense was right, whereas the experts got it wrong. If you want to understand the virus, you were better off listening to your racist Uncle Bob who dropped out of high school or <a href="https://www.rintrah.nl/coronadoom/">some anonymous Dutch dude with a blog</a>, than you were listening to Blue Checks on Twitter with Phd‚Äôs in epidemiology.</p>
<p>The reality remains, that the expert class has completely failed us. The media failed to properly report on this virus and ask critical questions. The World Health Organization failed to report on the numerous mild cases that don‚Äôt lead to any significant symptoms. The politicians failed to help us put the virus into a proper perspective. What did the expert class do? They terrorized you, over what we can now recognize as a glorified cold virus.</p>
<p>Progressives are aware of this at a subconscious level. They realize that the actual events do not fit the narrative that we were warned about. We were told that this was going to be an existential threat to civilization. It turned out to be no such thing.</p>
<p>‚ÄúScience‚Äù has replaced the role of religion for modern progressive people. The scientists are infallible and virtuous, they are capable of giving us insight into the human condition. What took place here would have the potential to shatter that faith in ‚Äúscience‚Äù, because scientists as a community have failed. When Africa faces hunger of biblical proportions and the American economy implodes by 50% over a glorified cold virus, you can say that scientists have failed us.</p>
<p>It doesn‚Äôt shatter the faith however, because most human beings are fundamentally not rational. Rather, our brain protects us against the logical outgrowths of reason, through a psychological immune system.&nbsp;Normal human beings have all sorts of psychological mechanisms built into their brain that prevent them from seeing the world as it really is. That prevents them from embracing ideas that would make them depressed or unpopular among their peers, both of which historically generally wiped your genes from the gene pool.</p>
<p>People are unable to psychologically cope with the realization that the entire scientific-political-media-academic establishment imposed extreme existential terror on us back in March, for no good valid reason. Because they are unable to cope with it, they just don‚Äôt accept the reality.</p>
<p>They convince themselves that although they were morbidly afraid to visit the supermarket in March and hated those who dared to go outside for trivial reasons, they are now able to gather in large crowds to protest because they happen to wear a mask. They completely forget about the experts who warned them that we would see a huge spike in deaths, two weeks after people gathered in a crowd somewhere. They try to reconcile the irreconcilable.</p>
<p>What has happened to people causes extreme cognitive dissonance. They now need some alternative outlet for their pent up rage and frustration. They have decided to embrace the most politically correct and culturally sanctioned outlet they could think of.</p>
<p>Remember, these are people whose religion has failed them. Science for them has filled the void that used to be filled by religion. What people tend to do when their religion has failed them is to blame themselves, for not being virtuous enough.</p>
<p>As a consequence, we see the current outbreak of mass hysteria. On average, British police kill two people in a year. Why do we see riots and statues being demolished in Britain? Because ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.rintrah.nl/people-are-acting-hysterical-because-they-have-suffered-a-collective-trauma/">https://www.rintrah.nl/people-are-acting-hysterical-because-they-have-suffered-a-collective-trauma/</a></em></p>]]>
            </description>
            <link>https://www.rintrah.nl/people-are-acting-hysterical-because-they-have-suffered-a-collective-trauma/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23901085</guid>
            <pubDate>Mon, 20 Jul 2020 19:32:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I asked GPT-3 to make a presentation for me]]>
            </title>
            <description>
<![CDATA[
Score 146 | Comments 96 (<a href="https://news.ycombinator.com/item?id=23901059">thread link</a>) | @bemmu
<br/>
July 20, 2020 | http://www.bemmu.com/gpt3-presentation | <a href="https://web.archive.org/web/*/http://www.bemmu.com/gpt3-presentation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
			<div id="posts">
	
				<article>
					<header>	
						<section>
							<time pubdate="pubdate" datetime="2020-07-20">2020-07-20</time>
						</section>
					</header>
					

					<div id="droparea"><p>I told GPT-3 I would be presenting at a Hacker News meetup in Japan, and asked it to generate a presentation for me. Here's what it came up with, read by yours truly.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/vZalOEmdHFo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>There's also a tweet-sized version <a href="https://twitter.com/bemmu/status/1285284131656445952">here</a>, and the slides are also on SlideShare <a href="https://www.slideshare.net/bemmu/this-presentation-was-generated-by-gpt3">here</a>.</p>
<h2>Details</h2>
<p>I used the <a href="https://openai.com/blog/openai-api/">OpenAI API</a> to generate one slide and one image caption at a time, asking GPT-3 about three times for each and picking the best output. When it generated image caption, I would go online to find a matching image, or if none was available I'd try to splice up an image using <a href="https://www.photopea.com/">Photopea</a> and <a href="https://www.remove.bg/">Remove.bg</a>.</p>
<p>My starting prompt was:</p>
<pre><code>A presentation was given at the Hacker News event in Kansai. 
The title of the presentation was
</code></pre>
<p>When it generated bullet points, I let it generate several and then picked the best 5 out of what it came up with. Once it generated a slide, I edited that into the prompt as well so it could continue generating more slides for the same presentation, and re-ran it to generate the next slide. </p>
<p>Piecewise concatenated output from OpenAI:</p>
<pre><code>"Strategies for Learning to Code in Japan" and the subtitle was 
"Fairly easily and rather effortlessly achieve practical software 
development skills."

The first presentation slide had a picture of a man playing a violin 
in front of a wall of violins, and the title of the slide was "Violin 
skills are of almost no value". Text under the slide said: "a metaphor 
for how useful programming ability can be for starters".

The next slide suggested a number of strategies for how to best use 
ones time to achieve productivity quickly:

1. Nobody figures out how to code perfectly their first time.
2. It's mostly luck.
3. Learn just the right skills, in the right order.
4. Avoid perfectionism.
5. Not doing something is sometimes the best way to learn something.

The next slide had a picture of a monkey drawn in crayon, and
and the words "All problems are pretty much the same." written 
under the monkey drawing. The text of that slide was:
"Not only are all software development problems more or less 
the same, but the best way to solve them is usually so simple, 
that a monkey could do it."

The next slide had a picture of a monkey, a sand hourglass, 
and a spoon and the words "Let's get started then!" written 
under it.

The text of that slide was: "Just like a monkey makes sand castles 
with an hourglass, all our time is of limited duration, so let's get 
started to code a product for clients. Software development is 
actually a bunch of often complicated problems. But that's not a big 
deal, is it!?" and the color of the text was red.

The next slide had a picture of a happy architect with a blueprint 
in one hand and blue pencil in the other hand, standing in front of a 
huge complex, and the words "Looking smart is the social norm".

The text of that slide was:
"Almost all developers feel the pressure (for whatever reason) to have the
look of the competent coder, most likely due to peer pressure. So it might
be counter-productive to cut corners during the development phase." and
the color of the text was purple.

The next slide had a sign: "DANGER do not enter" and this text under it: 
"If you don't need your code to run during actual product development, 
stuff it in a module in a separate directory." The color of the text 
was orange.

The next slide just had the text: Richard Feynman was reported to have 
said: "What I cannot create, I do not understand," something that has 
been paraphrased in the programming world as "If you don't regularly turn 
code into poetry, you probably aren't a good programmer."

The next slide had a picture of a happy runner and this sentence next 
to it: "If you've written 500 lines of code and have an actual working 
program that doesn't crash, sprint to the finish line." 
and the color of text was green.

The next slide had a picture of a swordsman catching a bullet and 
this text: "A happy ending to all of our code." and the color of 
text was yellow. The text of the slide was: "So you built a program
and it worked in like 10 minutes. All your code was beautiful." 
and the color of text was blue.

The final slide had the title of the presentation: "Why you should 
always code like it's your last day on Earth". Next to it was a picture 
of a person with their whole life ahead of them staring into a terminal, 
a ball and chain attached to each leg, and a long nose and a beard. The 
text of the slide was:
"If you always think like it's the last day on Earth (your last day coding), 
it'll push you just enough to get you to finish whatever you might need 
to finish."

The last remark at the last slide of the presentation was:
"So now that you know it's impossible to not 
learn to code, go write something, anything.
So stop writing nuclear missile designs, or the best 
ad blocker ever, and just get started on whatever.

The next slide had the text "And then when you finally do finish this nice 
feature, you should always make sure you drink the required amount of alcohol." 
with a background image of whiskey bottles. The decorative text on that slide 
was: "But don't drink too much alcohol and end up like me."

And the concluding remark of the presentation:
"So basically just go ahead before you wake up in a cold sweat from a scary 
dream about the future, coding-less, uh, eating those annoying squares of tofu."
The background image of that slide was a plate of tofu next to a glass of beer
and the font color was orange to emphasize the suggestion to drink.
</code></pre></div>

				</article>
	
			</div>
			
		</div></div>]]>
            </description>
            <link>http://www.bemmu.com/gpt3-presentation</link>
            <guid isPermaLink="false">hacker-news-small-sites-23901059</guid>
            <pubDate>Mon, 20 Jul 2020 19:29:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beautyberry leaf extract boosts an antibiotic‚Äôs activity against ‚Äòsuperbugs‚Äô]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23900886">thread link</a>) | @finphil
<br/>
July 20, 2020 | https://nuadox.com/post/624186930132811776/beautyberry-superbug-study | <a href="https://web.archive.org/web/*/https://nuadox.com/post/624186930132811776/beautyberry-superbug-study">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="624186930132811776">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/624186930132811776/beautyberry-superbug-study"><h2>Beautyberry leaf extract boosts an antibiotic‚Äôs activity against&nbsp;‚Äòsuperbugs‚Äô</h2></a>
                                <figure data-orig-width="1919" data-orig-height="1037"><img src="https://64.media.tumblr.com/94ae533a7cefb22987211e78f7ec6dfb/537fc9242f7b19c2-12/s1280x1920/09820ff89e35ce93bf43314c0e3e260bd430b033.jpg" alt="image" data-orig-width="1919" data-orig-height="1037" width="1280" height="692"></figure><p><b>- By <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fnews.emory.edu%2Fabout_us.html&amp;t=NTQ3MzdlMGRkYzRlOTFlMTRiM2YxYmU2OTI4NjMwNjFkNDJhN2IyYyxWRVl0d284Vg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F624186930132811776%2Fbeautyberry-superbug-study&amp;m=0">Carol Clark</a> , <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fwhsc.emory.edu%2Findex.html&amp;t=N2NjMjNhOTFiZDRiZWIwODkzZWM0M2VmZTZiMTEzYzNlMjJlYmQyYSxWRVl0d284Vg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F624186930132811776%2Fbeautyberry-superbug-study&amp;m=0">Emory Health Sciences</a> -</b></p><p>

Scientists discovered a compound in the leaves of a common shrub, the American beautyberry, that boosts an antibiotic‚Äôs activity against antibiotic-resistant staph bacteria. Laboratory experiments showed that the plant compound works in combination with oxacillin to knock down the resistance to the drug of methicillin-resistant <i>Staphylococcus aureus</i>, or MRSA.

<br></p><p>The American Chemical Society‚Äôs <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fpubs.acs.org%2Fdoi%2Fabs%2F10.1021%2Facsinfecdis.0c00307&amp;t=YTgwYzZhOWYzNDliYzlmMTYxMTkzYTlkNzg4OTZmMzcxODNmZDlhZCxWRVl0d284Vg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F624186930132811776%2Fbeautyberry-superbug-study&amp;m=0"><i>ACS Infectious Diseases</i></a> published the finding, led by scientists at Emory University and the University of Notre Dame.<br></p><p>The American beautyberry, or <i>Callicarpa americana</i>, is native to the southern United States. Prolific in the wild, the shrub is also popular in ornamental landscaping. It‚Äôs known for showy clusters of bright purple berries that begin to ripen in the summer and are an important food source for many species of birds.<br></p><p>‚ÄúWe decided to investigate the chemical properties of the American beautyberry because it was an important medicinal plant for Native Americans,‚Äù says <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fetnobotanica.us%2F&amp;t=NjYwMDkyZjYyNjM5YWU5NGQ1ZjI2Zjc1YjM3ZTdmNzk4NjNlOGI1NixWRVl0d284Vg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F624186930132811776%2Fbeautyberry-superbug-study&amp;m=0">Cassandra Quave</a>, co-senior author of the study and an assistant professor in Emory University‚Äôs <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fhumanhealth.emory.edu%2Fhome%2F&amp;t=OGIzNWY5NmQ4NTg2ZTFmYTQ1M2VmNGFiNTQ0YTZlMDM3ZTM2NTI5ZixWRVl0d284Vg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F624186930132811776%2Fbeautyberry-superbug-study&amp;m=0">Center for the Study of Human Health</a> and Emory School of Medicine‚Äôs <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fdermatology.emory.edu%2F&amp;t=MDhkNjAwYWFiNTc1ZWU2YTI0ZTNmZDExYTg3YWI1MzYxN2I4Y2U3MyxWRVl0d284Vg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F624186930132811776%2Fbeautyberry-superbug-study&amp;m=0">Department of Dermatology</a>. Quave is also a member of the <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fantibiotics.emory.edu%2F&amp;t=YjY5MTdhMTk1MjBhNTE4MzMwZmUwOGY2YzJhOGQyZGQ2ZDQwZjQ2NSxWRVl0d284Vg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F624186930132811776%2Fbeautyberry-superbug-study&amp;m=0">Emory Antibiotic Resistance Center</a> and a leader in the field of medical ethnobotany, studying how indigenous people incorporate plants in healing practices to uncover promising candidates for new drugs.<br></p><p>Micah Dettweiler, a recent Emory graduate and a staff member of the Quave lab, is first author of the study. Christian Melander, professor of chemistry at Notre Dame, is co-senior author.<br></p><p>The Alabama, Choctaw, Creek, Koasati, Seminole and other Native American tribes relied on the American beautyberry for various medicinal purposes. Leaves and other parts of the plant were boiled for use in sweat baths to treat malarial fevers and rheumatism. The boiled roots were made into treatments for dizziness, stomachaches and urine retention, while bark from the stems and roots were made into concoctions for itchy skin.<br></p><p>Previous research found that extracts from the leaves of the beautyberry deter mosquitoes and ticks. And a prior study by Quave and colleagues found that extracts from the leaves inhibit growth of the bacterium that causes acne. For this study, the researchers focused on testing extracts collected from the leaves for efficacy against MRSA.</p><figure data-orig-width="611" data-orig-height="384"><img src="https://64.media.tumblr.com/5347126a80ec29f07571d42bf91af8b1/537fc9242f7b19c2-23/s640x960/0d0bba3a9dbb6aed4e1a9f7fd17b09b6c43a0913.jpg" alt="image" data-orig-width="611" data-orig-height="384" width="611" height="384"></figure><p><i>Image: The American beautyberry was an important medicinal plant for some Native American tribes. Credit:&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.eurekalert.org%2Fmultimedia%2Fpub%2F237744.php&amp;t=NjJiMDZkY2EwOWY3MDMwYTdiOWEzZjI0OTM2Y2Q5OWVkYjkxMTQzNixWRVl0d284Vg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F624186930132811776%2Fbeautyberry-superbug-study&amp;m=0">Tharanga Samarakoon</a>.</i></p><p>‚ÄúEven a single plant tissue can contain hundreds of unique molecules,‚Äù Quave says. ‚ÄúIt‚Äôs a painstaking process to chemically separate them out, then test and retest until you find one that‚Äôs effective.‚Äù<br></p><p>The researchers identified a compound from the leaves that slightly inhibited the growth of MRSA. The compound belongs to a group of chemicals known as clerodane diterpenoids, some of which are used by plants to repel predators.<br></p><p>Since the compound only modestly inhibited MRSA, the researchers tried it in combination with beta-lactam antibiotics.<br></p><p>‚ÄúBeta-lactam antibiotics are some of the safest and least toxic that are currently available in the antibiotic arsenal,‚Äù Quave says. ‚ÄúUnfortunately, MRSA has developed resistance to them.‚Äù <br></p><p>Laboratory tests showed that the beautyberry leaf compound synergizes with the beta-lactam antibiotic oxacillin to knock down MRSA‚Äôs resistance to the drug.<br></p><p>The next step is to test the combination of the beautyberry leaf extract and oxacillin as a therapy in animal models. If those results prove effective against MRSA infections, the researchers will synthesize the plant compound in the lab and tweak its chemical structure to try to further enhance its efficacy as a combination therapy with oxacillin.<br></p><p>‚ÄúWe need to keep filling the drug-discovery pipeline with innovative solutions, including potential combination therapies, to address the ongoing and growing problem of antibiotic resistance,‚Äù Quave says.<br></p><p>Each year in the U.S., at least 2.8 million people get an antibiotic-resistant infection and more than 35,000 people die, according to the Centers for Disease Control and Prevention.<br></p><p>‚ÄúEven in the midst of the COVID-19, we can‚Äôt forget about the issue of antibiotic resistance,‚Äù Quave says. She notes that many COVID-19 patients are receiving antibiotics to deal with secondary infections brought on by their weakened conditions, raising concerns about a later surge in antibiotic-resistant infections.<br></p><p>Co-authors of the study include Emory post-doctoral fellow Gina Porras; Emory graduate students Caitlin Risener and Lewis Marquez; Tharanga Samarakoon, collections manager of the Emory Herbarium; and Roberta Melander from the University of Notre Dame.<br></p><p>The work was supported by the National Institute of Allergy and Infectious Disease, the National Institute of General Medical Sciences, the Jones Ecological Research Center and Emory University.</p><p>‚Äì</p><p><b>Source: <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fnews.emory.edu%2Fstories%2F2020%2F07%2Fesc_beautyberry_leaf_extract%2Fcampus.html&amp;t=NTU2ZTdmNzY4M2RjMmE0ZTY4MzIwYTJmMDFiN2M4ZmY5NGQ2ZGZlYixWRVl0d284Vg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F624186930132811776%2Fbeautyberry-superbug-study&amp;m=0">Emory Health Sciences</a></b></p><p><b>Full Study:</b>&nbsp;
‚Äú
A Clerodane Diterpene from <i>Callicarpa americana</i> Resensitizes Methicillin-Resistant <i>Staphylococcus aureus</i> to Œ≤-Lactam Antibiotics‚Äù.&nbsp;<i>ACS Infectious Diseases</i>.</p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fpubs.acs.org%2Fdoi%2Fabs%2F10.1021%2Facsinfecdis.0c00307&amp;t=YTgwYzZhOWYzNDliYzlmMTYxMTkzYTlkNzg4OTZmMzcxODNmZDlhZCxWRVl0d284Vg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F624186930132811776%2Fbeautyberry-superbug-study&amp;m=0">https://pubs.acs.org/doi/abs/10.1021/acsinfecdis.0c00307</a><br></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/190381585877/bacteriophages">Antibiotic resistance: Scientists are reengineering viruses to cure bacterial infections</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/health">health</a>
                                    
                                        <a href="https://nuadox.com/tagged/plants">plants</a>
                                    
                                        <a href="https://nuadox.com/tagged/nature">nature</a>
                                    
                                        <a href="https://nuadox.com/tagged/beautyberry">beautyberry</a>
                                    
                                        <a href="https://nuadox.com/tagged/biology">biology</a>
                                    
                                        <a href="https://nuadox.com/tagged/medicine">medicine</a>
                                    
                                        <a href="https://nuadox.com/tagged/pharma">pharma</a>
                                    
                                        <a href="https://nuadox.com/tagged/pharmaceuticals">pharmaceuticals</a>
                                    
                                        <a href="https://nuadox.com/tagged/antibiotics">antibiotics</a>
                                    
                                        <a href="https://nuadox.com/tagged/superbug">superbug</a>
                                    
                                        <a href="https://nuadox.com/tagged/bacteria">bacteria</a>
                                    
                                        <a href="https://nuadox.com/tagged/antibiotics-resistance">antibiotics resistance</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/624186930132811776/beautyberry-superbug-study</link>
            <guid isPermaLink="false">hacker-news-small-sites-23900886</guid>
            <pubDate>Mon, 20 Jul 2020 19:09:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Principles for great product managers]]>
            </title>
            <description>
<![CDATA[
Score 207 | Comments 84 (<a href="https://news.ycombinator.com/item?id=23900783">thread link</a>) | @AlexDReeve
<br/>
July 20, 2020 | http://reeve.blog/blog/principles/ | <a href="https://web.archive.org/web/*/http://reeve.blog/blog/principles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main id="genesis-content"><article itemscope="" itemtype="https://schema.org/CreativeWork"><div itemprop="text">
<p><strong>Edit 07.20.20:</strong><br>This post was #1 on <a href="https://en.wikipedia.org/wiki/Hacker_News">Hacker News</a> today, which did 2 things: First, it crashed this site (sorry, won‚Äôt happen again). Second, it catalyzed some great dialogue <a href="https://news.ycombinator.com/item?id=23900783">here</a>. If you‚Äôd like to continue the conversation, hit me up on <a href="https://twitter.com/AlexDReeve">Twitter</a>.</p>



<hr>



<p>A few years ago, I read&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://amzn.to/2C4RbBY">Principles</a>&nbsp;by Ray Dalio, and I became enamored with the concept of codifying my own. So, I borrowed the idea and started noting them down.</p>



<p>This list‚Äîpieced together over the past few years‚Äîreflects what I believe are some of the most important principles for product managers. I can‚Äôt claim credit for inventing these; they are the summation of what I‚Äôve learned through experience, coaching, and osmosis. This list wouldn‚Äôt exist if not for the incredible people I‚Äôm fortunate to work with and from whom I‚Äôve learned so much.</p>



<p><strong><strong>Product Management is a broad function, so I‚Äôve tried to distill this down to the top 3-4 across 6 categories:</strong>&nbsp;</strong>These principles are very much a ‚Äúliving‚Äù list. I don‚Äôt intend for this list to be exhaustive‚Äînor does it reflect the entire scope of the product manager role‚Äîand these principles will continue to develop over time.</p>



<h3>Leading Your Team</h3>



<p><strong><strong>1.</strong>&nbsp;<strong>Your team should be able to repeat the vision, goal, and value</strong>. </strong>If your team can‚Äôt, you probably haven‚Äôt communicated it enough or aren‚Äôt aligned.</p>



<p><strong>2. You should know what game you‚Äôre playing, and how you keep score</strong>. Credit to Adam Nash for this framing, see here for his <a href="https://adamnash.blog/2011/12/16/be-a-great-product-leader/">fantastic article</a>.</p>



<ul><li><strong>The game you‚Äôre playing:</strong> Your vision for the product, your product‚Äôs value to the customer, your competitive advantage, and how you‚Äôll win.</li><li><strong>How you‚Äôll keep score</strong>: What does winning mean? How will you measure success? What‚Äôs your ‚Äúcompass‚Äù to tell whether you‚Äôre traveling in the right direction?</li></ul>



<p><strong><strong>3. Your team should know the path to reach the goal.&nbsp;</strong></strong>You need not detail execution to the point of false precision, but you and your team must understand the high-level milestones. If the milestones aren‚Äôt clear because of unknows, these unknowns should be explicit.</p>



<h3>Making Decisions</h3>



<p><strong>4. Decisions should be documented, explained, and widely communicated</strong>. It should&nbsp;<em>feel&nbsp;</em>like over-communication. If you don‚Äôt feel like you‚Äôre over-communicating, you probably aren‚Äôt communicating enough.</p>



<p><strong>5. Decisions, and what you prioritize, need evidence.&nbsp;</strong>It‚Äôs your job to make sure this evidence exists. Inevitably, you will base some decisions on your judgment in place of data. Judgment-weighted decisions are okay, provided it‚Äôs explicitly communicated.</p>



<p><strong>6. Stakeholders should be involved early and often, and alignment should be explicit.&nbsp;</strong>You‚Äôre looking for either a ‚Äúyes, I agree with this decision, or a ‚Äúno, I disagree, but I can commit to moving forward.‚Äù Escalate quickly and cleanly to resolve misalignments.</p>



<h3>Communication Effectively</h3>



<p><strong>7. There is no such thing as over-communication.</strong> ‚ÄúFluff‚Äù communication = enough communication.</p>



<ul><li>If you‚Äôre not sick of saying it, you probably aren‚Äôt saying it enough. Constant communication might feel like ‚Äúfluff,‚Äù but it isn‚Äôt. Evangelism is a critical part of the role‚Äîand it‚Äôs your job to make sure the organization is aligned and swimming in the same direction.</li><li>Marty Cagan, in <a href="https://amzn.to/3eMLBS0">Inspired</a>, said it best: <em>Evangelize continuously and relentlessly. There is no such thing as over‚Äêcommunicating when it comes to explaining and selling the vision. Especially in larger organizations, there is simply no escaping the need for near‚Äêconstant evangelization. You‚Äôll find that people in all corners of the company will at random times get nervous or scared about something they see or hear. Quickly reassure them before their fear infects others.</em></li></ul>



<p><strong>8. You, the product manager, should have a uniquely high communication bar.  </strong>Most functions have a primary ‚Äúoutput‚Äù that isn‚Äôt communication: Designers design, engineers code, etc. For you, communication&nbsp;<em>is</em>&nbsp;a primary ‚Äúoutput,‚Äù and it should be exceptional.</p>



<p><strong>9. You have to own the narrative.&nbsp;</strong>When there‚Äôs a narrative vacuum, people will ‚Äúcreatively‚Äù fill in the blanks themselves‚Äîand you might not like it. Losing control of the narrative can be incredibly disruptive to your team‚Äôs ability to deliver.</p>



<h3>Being an Effective Operator</h3>



<p><strong><strong>10.</strong>&nbsp;<strong>Strong relationships enable strong collaboration.&nbsp;</strong></strong>‚ÄúHave strong relationships‚Äù sounds obvious, but the importance of relationships ‚Äúup,‚Äù ‚Äúdown,‚Äù and ‚Äúacross‚Äù can‚Äôt be overstated. Without a solid mix of relationships and credibility, you won‚Äôt succeed.</p>



<p><strong><strong>11. Don‚Äôt be in the weeds managing every nuance of every project; save this for emergencies</strong>. </strong>Swim in your lane, and give your team space to do their job(s). Focus on:</p>



<ul><li>Setting the goal, i.e., ‚Äúwhat game are we playing?‚Äù and lead/help the team in figuring out how to get there (milestones, dependencies, alignment, etc.).</li><li>Leading the team. E.g., establish the communication cadence (updates, Slack channels, syncs), meeting rhythm, high-level project milestones, success metrics.</li><li>Don‚Äôt pester. Establish the right communication channels upfront, and let your team keep you updated. See ‚Äúmaker‚Äôs schedule‚Äù under (12).</li></ul>



<p><strong><strong>12. Greatness is achieved in the agency of others</strong></strong>. Product managers follow the ‚Äúmanager‚Äôs<a rel="noreferrer noopener" target="_blank" href="http://www.paulgraham.com/makersschedule.html">&nbsp;schedule</a>.‚Äù<strong> </strong>Engineers &amp; designers follow the ‚Äúmaker‚Äôs schedule.‚Äù Help your team be great ‚Äúmakers‚Äù‚Äîkeep them unblocked; respond effectively to unfolding situations.</p>



<p><strong>13. Your job is to create clarity</strong>:<strong> </strong>This is some sound advice that I got early on (thank you, Greg!). As a product manager, constantly think about how you can <em>create clarity</em> for your team: Clearer product requirements, resolving edge cases, answering questions, etc.</p>



<ul><li>If you‚Äôre drowning in questions, you probably aren‚Äôt proactively communicating effectively, or the product requirements lack clarity. Some questions are natural, so use your judgment.</li></ul>



<p><strong>14. Be on top of your shit.</strong> Until I figure out how to better articulate this, I‚Äôll say it ineloquently as ‚Äújust be on it.‚Äù Know your business, your product, your team, be responsive, communicate relentlessly, make good decisions, own your results, get 1% better every day.</p>



<h3>Managing Your Time</h3>



<p><strong>15. 80% of your role is discovering the right product &amp; driving organizational alignment, and 20% is answering clarifying questions for the ‚Äúmakers‚Äù on your team. </strong>Product teams are in a constant cycle of discovery and delivery, which run in parallel: </p>



<ul><li>In an ideal world, engineers are ~80% delivery, ~20% discovery; product managers are ~80% discovery, 20% delivery.</li><li>In large complex organizations, this is a difficult target to achieve, but strive to spend 80% of your time on discovering the right product (ideation, validation, testing, etc.) and communication (driving organizational alignment, creating clarity).</li><li>‚ÄúOrganizational alignment‚Äù is an intentionally broad term, including everything from 1-1 meetings to executive strategy reviews to product ‚Äúdeep dives‚Äù to all-hands presentations.</li></ul>



<p><strong>16. Ensuring that you have time set aside for strategy and ‚Äúfocus‚Äù work is your responsibility. </strong>Getting sidetracked with 1,000 emails and Slack messages is natural, but it can‚Äôt be an excuse. Make sure you have time set aside for focused work.</p>



<h3>Running Effective Meetings</h3>



<p><strong>17. Send agenda items beforehand. At the start of the meeting, collect input,</strong> <strong>and align on the goal. </strong>Meetings are expensive; when people are meeting, they often aren‚Äôt making. Own the meetings you run, and make sure they‚Äôre productive.</p>



<p><strong>18. Use ‚ÄúDAD‚Äù to help structure and run meetings</strong>. Most meetings are a mix of Discussion, Actions, and Decisions: Document any decisions, communicate topics of discussion and enumerate any action items.</p>



<p><strong>19. ‚ÄúABFU,‚Äù or Always Be Following Up (terrible, I know).</strong> Make sure you (or someone else) sends notes to all relevant stakeholders within ~24 hours. They don‚Äôt need to be perfect, but make sure they exist and that you communicate them.</p>



<p><strong>20. Be deeply curious, and ask the ‚Äúdumb‚Äù questions.</strong> Asking the right questions, even if they seem dumb, is a catalyst for creating clarity. Ask questions openly, in earnest, and let everyone else hear the answer. You probably weren‚Äôt the only one with that question.</p>



<h3>Running Projects &amp; Other</h3>



<p><strong><strong>21.</strong>&nbsp;<strong>Every project includes a mix of Discovery, Design, and Delivery (and iteration); you should make sure these run in sequence.&nbsp;</strong></strong>While we expect and&nbsp;<em>desire</em>&nbsp;some overlap, aspire not to make sweeping changes to design during delivery (as an example).</p>



<p><strong>22. Be responsive; if you‚Äôre not, you might be holding things up. </strong>As the hub between every other function, and often the decision-maker, you have to keep the wheels greased for your team. One idea: ~2 hours for Slack, ~2 days for email (but much faster for anything urgent).  </p>



<hr>



<h4>Further Reading</h4>



<ul><li><a href="https://amzn.to/3em4Fqi">Principles</a>, by Ray Dalio, which inspired this exercise.</li><li><a href="https://amzn.to/3eMLBS0">Inspired</a> by Marty Cagan. If there‚Äôs one book on Product Management you should read, it‚Äôs this. At some point, I‚Äôll publish my ~3,000 words of notes from it!</li></ul>

			<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://reeve.blog/blog/principles/"
    dc:identifier="https://reeve.blog/blog/principles/"
    dc:title="22 Principles for Great Product Managers"
    trackback:ping="https://reeve.blog/blog/principles/trackback/" />
</rdf:RDF>-->
</div></article></main></div></div></div>]]>
            </description>
            <link>http://reeve.blog/blog/principles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23900783</guid>
            <pubDate>Mon, 20 Jul 2020 18:56:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Confidence Cycle]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23900768">thread link</a>) | @bkanber
<br/>
July 20, 2020 | https://burakkanber.com/blog/the-confidence-cycle/? | <a href="https://web.archive.org/web/*/https://burakkanber.com/blog/the-confidence-cycle/?">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
            <p>You're scared of failure,<br>so you don't try.</p><p>You don't try,<br>so you never succeed.</p><p>You never succeed,<br>so you have no confidence.</p><p>You have no confidence,<br>so you're scared of failure.</p><p>You're scared of failure,<br>so you don't try.</p><p>You don't try,<br>so you never succeed.</p><p>You never succeed,<br>so you have no confidence.</p><p>You have no confidence,<br>so you're scared of failure.</p><p>Break the cycle.</p><p>You're scared of failure,<br>but you try anyway.</p><p>You try and fail,<br>so you have no confidence.</p><p>You have no confidence,<br>so you're scared of failure.</p><p>Break the cycle.</p><p>You're scared of failure,<br>but you try again anyway.</p><p>You try again,<br>and you win. Just a little.</p><p>You win,<br>so you build confidence.</p><p>You build confidence,<br>so you're less scared of failure.</p><p>You're still scared,<br>but you keep trying anyway.</p><p>You keep trying anyway,<br>and one day it works.</p><p>One day it works,<br>and you've broken the cycle.</p>
        </section></div>]]>
            </description>
            <link>https://burakkanber.com/blog/the-confidence-cycle/?</link>
            <guid isPermaLink="false">hacker-news-small-sites-23900768</guid>
            <pubDate>Mon, 20 Jul 2020 18:55:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Spatial Modelling: Honeycomb or Fishnets?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23900424">thread link</a>) | @anubp
<br/>
July 20, 2020 | https://blog.locale.ai/spatial-modelling-tidbits-honeycomb-or-fishnets/ | <a href="https://web.archive.org/web/*/https://blog.locale.ai/spatial-modelling-tidbits-honeycomb-or-fishnets/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <h3 id="introduction">Introduction</h3><p>If you are a two-degree marketplace like Uber, you cater to millions of users requesting a ride through your driver partners accepting and fulfilling those requests. For a three-degree marketplace like Swiggy, there is another static component added (like restaurants or stores), where delivery partners pick up the orders.</p><p><em><em>Borrowing from the quote, ‚ÄúEverything happens somewhere‚Äù ‚Äî all of these events and actions described take place at a specific location!</em></em></p><p>Often, companies end up not leveraging the <strong><strong>lat/long component</strong></strong> in their data and running their analyses at the city level. But, cities are too large, geographically diverse and the parameters vary way too much!</p><p>Area level polygons are much more practical but still broad. They don‚Äôt have uniform shapes or sizes and are subject to changes very frequently. Even the zones or clusters drawn by the operations teams‚Äô local knowledge require updating and have arbitrary edges.</p><figure><img src="https://blog.locale.ai/content/images/2020/01/discrete_continuous_data.png"><figcaption>Source: LearnGIS.org</figcaption></figure><p>Making sense of your spatial data and deriving precise insights requires these analyses to become more granular and uniform.</p><p><strong><strong>Grid system</strong></strong> brings that fine granularity to the table. It works brilliantly in bucketing all your lat-longs into ‚Äúcells‚Äù. These cells can also be clustered to represent a particular neighborhood or area and can be aggregated at different levels.</p><p>Hence, this system becomes critical to crunch large spatial data sets to match the supply &amp; demand fragmented across the city.</p><figure><img src="https://blog.locale.ai/content/images/2020/01/0_UBG0oU5o1FRbVm8l.png"><figcaption>Source: Uber</figcaption></figure><h2 id="what-is-meant-by-grids">What is meant by grids?</h2><p>In Spatial Data Science, we use grids that are regular polygons repeating over a surface, edge to edge to cover any space without overlaps and gaps ‚Äî a phenomenon called <a href="https://www.mathsisfun.com/geometry/tessellation.html" rel="noopener nofollow"><strong><strong>tessellation</strong></strong></a><strong><strong>.</strong></strong> Each cell can be assigned a unique id for spatial indexing (aggregating the points inside that cell).</p><p>A wide variety of grids of different shapes have been proposed including squares, rectangles, triangles, hexagons or diamonds. The <a href="https://en.wikipedia.org/wiki/Discrete_global_grid" rel="noopener nofollow">global grid system</a> covers the entire surface of the earth.</p><p>If you are a hyperlocal, on-demand company, grids as small as<strong><strong> </strong>0.5 <strong>sq. km </strong></strong>can be very useful to run models that work in context to location and in <strong><strong>real-time. </strong></strong><a href="https://medium.com/@localeai/how-analyzing-supply-demand-gaps-can-optimize-your-unit-economics-1da3ecd340c6" rel="noopener">Examples</a> include surge pricing in high demand areas, promotions in low demand areas &amp; distribution models of delivery folks on the ground.</p><hr><h2 id="what-are-the-different-grid-types">What are the different grid types?</h2><p>There are just three types of grids or that can tessellate: squares, equilateral triangles &amp; hexagons.</p><figure><img src="https://blog.locale.ai/content/images/2020/01/0_GBiKhBHv_cmkbQhn.png"><figcaption>Source: Wikipedia</figcaption></figure><h3 id="1-square-grids-">1. Square grids:</h3><p>The most common application of square grids occurs in raster datasets and geohashes. For the scope of this piece, we will focus on geohashes.</p><p><a href="https://www.factual.com/blog/how-geohashes-work/" rel="noopener nofollow"><strong><strong>Geohash</strong></strong></a> is a hierarchical data structure to transform a 2D spatial point (lat &amp; long) into a short string of alphabets and numbers. They divide the world into a grid of 32 cells with 4 rows and 8 columns.</p><p>You can keep splitting up each cell into a grid of 32 cells. Thus, the longer the string of the geohash, the higher the accuracy! You can also easily identify if geohashes are close together if they can have a common prefix. So, the longer the common prefix, the closer they are.</p><p>For example, the coordinate pair<em><em> (57.64911, 10.40744) </em></em>near the tip of the peninsula of Jutland, Denmark produces a slightly shorter hash of <em><em>u4pruydqqvj. [1]</em></em></p><h3 id="2-triangular-grids-">2. Triangular grids:</h3><p>Triangular grids are not very commonly used. Besides, their unfamiliarity, one of the reasons for that is they have a large perimeter and a small area which means it‚Äôs harder to piece them together on the map.</p><p>Another reason is that each triangle is connected to only three adjacent triangles, which limits the number of options to move and to make connections. (Check the image below)</p><p>Moreover, while for hexagons and squares, there are always two faces parallel to each other, for triangles, there are two directions in which lines are parallel centered from the axis of movement. Thus, in a way, there are not completely symmetrical. <em><em>[2]</em></em></p><h3 id="3-hexagonal-grids-">3. Hexagonal grids:</h3><p>Besides looking appealing, hexagons are more symmetric than geohashes. They are very close to circles in terms of shape to provide a more accurate sampling. <em><em>[3]</em></em></p><p>As a result, this system has been increasingly adopted by companies like Uber.</p><figure><img src="https://blog.locale.ai/content/images/2020/01/45.PNG"></figure><p><strong><strong>Fun fact:</strong></strong> A hex grid and triangular grids are a dual of each other ‚Äî putting a dot in the center of each hexagon &amp; connecting them to all the adjacent ones, you get a triangular grid and vice versa! <em><em>[4]</em></em></p><p>Moving on the vertices of a hexagonal grid is equivalent to playing in the spaces on a triangular grid. Square grids, on the other hand, are a dual of themselves.</p><hr><h2 id="why-hexagons">Why hexagons?</h2><p>At <a href="http://locale.ai/" rel="noopener nofollow">Locale</a>, one question that we get a lot from our customers is, ‚Äúwhy are we using hexbins and not geohashes?‚Äù</p><p>Well, the choice depends on your exact use case and you would have to make some tradeoffs, no matter what you use. So, let‚Äôs take some parameters and deep dive.</p><h3 id="distance-from-nearest-cells-">Distance from Nearest Cells:</h3><figure><img src="https://blog.locale.ai/content/images/2020/01/0_IxCpGcjXk4en4BJO.png"><figcaption>Source: Uber</figcaption></figure><p>This diagram shows the distance of the center of triangles, square &amp; hexagon to its neighbors.</p><p>A triangle has three kinds of distance (through the edge, vertex and across the center of the edge), a square has two (across the edge &amp; the diagonal) and hexagon only has one ‚Äî another reason why triangles are not really favored.</p><p>This property of hexagons makes it very easy to perform analysis and is preferred when your analysis includes aspects of<strong><strong> connectivity or movement.</strong></strong> <em><em>[4]</em></em></p><p>All the neighbors in a hexagon form a ring around it with equal radius. The <a href="https://uber.github.io/h3/#/documentation/api-reference/neighbors" rel="noopener nofollow">kRing</a> function provides grid cells within distance ‚Äúk‚Äù of an origin index. In the diagram below, here is the <strong><strong>1st kRing</strong></strong> of the shaded hexagon and square.</p><figure><img src="https://blog.locale.ai/content/images/2020/01/98.PNG"></figure><h3 id="fitting-on-curved-surfaces-">Fitting on Curved Surfaces:</h3><p>Hexagons are the densest way to pack circles in tessellation and reduce<strong><strong> edge effects</strong></strong>. (Circles have the least perimeter to area ratio but can‚Äôt form a continuous grid).</p><p>The more similar a polygon is to a circle, the closer the points near the border area are to the center. Thus, any point inside a hexagon is closer to its center as compared to an equal-area square or triangle.</p><p>Now, when large areas come into play and the curvature of the earth is important to consider, hexagons are therefore better suited to fit the curvature and suffer less distortion.<em><em> [5]</em></em></p><h3 id="explicit-patterns-in-data-">Explicit Patterns in Data:</h3><p>Hexagons allow any <strong><strong>curvature of the patterns </strong></strong>in the data to show easily and explicitly because they break up lines.</p><p>For linear figures like squares and rectangles, this becomes tricky. These shapes draw our attention to the straight, unbroken and parallel lines which hinder the patterns present in the data. Refer to the diagram below. <em><em>[6]</em></em></p><figure><img src="https://blog.locale.ai/content/images/2020/01/hj.PNG"></figure><hr><h2 id="why-geohashes">Why geohashes?</h2><p>That brings me to my next question, <strong><strong>‚ÄúWhen would someone use fishnets or square grids?‚Äù</strong></strong></p><h3 id="aggregation-division-of-cells-">Aggregation/ Division of Cells:</h3><p>Different kinds of models require different granularity and that‚Äôs where aggregation and division become important.</p><p>If you need to increase the spatial resolution of a square grid, you just need to divide it into 4. Similarly, to aggregate, you need to combine four grids into one.</p><p>For hexagons, aggregations and divisions are not uniform at different scales as shown in the image below. The finer cells are only approximately contained in the parent cell. <em><em>[7]</em></em></p><p>Squares are preferred over hexagons for hierarchical analysis. Combining square grids is fairly simple. No spatial operations are necessary for combing multiple grids built on the same template ‚Äî you can use matrix algebra.</p><figure><img src="https://blog.locale.ai/content/images/2020/01/0_-YQ8-fE2LcJZuAdi.png"><figcaption>Wikipedia</figcaption></figure><h3 id="very-intuitive-familiar-">Very Intuitive &amp; Familiar:</h3><p>We also think in terms of ‚Äú<strong><strong>squares</strong></strong>‚Äù. Up, down, left, right are simple to understand. We have built cities and civilizations on squares and rectangles. Since our primary coordinate system is squared, people find it difficult to work on other systems.</p><p>They are also sometimes used for connectivity analysis as they have eight neighbors (including diagonals).</p><h3 id="some-real-life-examples">Some Real-Life Examples</h3><p>Hexagons are found widely in nature. For example, honeycombs, graphite, benzene, silicene etc. Chinese Checkers is played on a hex grid and several variants of chess have also been invented for a hex board.</p><p>The hex grid is a distinguishing feature of the games from many wargame publishers, and a few other games (such as The Settlers of Catan)! <em><em>[8]</em></em></p><hr><p><em>If you resonate with this problem and want to contribute, we are <a href="http://locale.freshteam.com/jobs" rel="noopener nofollow">hiring</a> for different roles. In case you would like a demo, get in touch with me or <a href="https://www.linkedin.com/in/aditi-sinha-6b774ba9/">LinkedIn</a> or <a href="https://twitter.com/aditi1002">Twitter</a>. </em></p><h3 id="read-similar-">Read Similar:</h3><figure><a href="https://blog.locale.ai/geospatial-clustering-types-and-use-cases/"><div><p>Geospatial Clustering: Types and Use Cases</p><p>Deep dive into all the different kinds of clustering with their use cases.</p><p><img src="https://blog.locale.ai/favicon.png"><span>Locale.ai</span></p></div><p><img src="https://blog.locale.ai/content/images/2020/01/cartonew1.png"></p></a></figure><figure><a href="https://blog.locale.ai/a-guide-to-kickstart-into-the-geospatial-world-2/"><div><p>A Guide to Kickstart into the Geospatial World.</p><p>A collection of the best data sources, open source tools and packages to get started.</p><p><img src="https://blog.locale.ai/favicon.png"><span>Dhrumil Patel</span><span>Locale.ai</span></p></div><p><img src="https://blog.locale.ai/content/images/2020/01/0_1odsMnD_rL0od9uT-1.png"></p></a></figure><p><strong>References:</strong></p><p>If you wish to read more, check out the links to delve further:</p><p><em><em>[1] </em></em><a href="https://en.wikipedia.org/wiki/Geohash" rel="noopener nofollow"><em><em>https://en.wikipedia.org/wiki/Geohash</em></em></a><br><em><em>[2] </em></em><a href="https://boardgames.stackexchange.com/questions/633/why-are-there-fewer-board-games-with-a-triangular-grid" rel="noopener nofollow"><em><em>https://boardgames.stackexchange.com/questions/633/why-are-there-fewer-board-games-with-a-triangular-grid</em></em></a><br><em><em>[3] </em></em><a href="https://www.redblobgames.com/grids/hexagons/" rel="noopener nofollow"><em><em>https://www.redblobgames.com/grids/hexagons/</em></em></a><br><em><em>[4] </em></em><a href="http://www-cs-students.stanford.edu/~amitp/game-programming/grids/" rel="noopener nofollow"><em><em>http://www-cs-students.stanford.edu/~amitp/game-programming/grids/</em></em></a><br><em><em>[5] </em></em><a href="https://pro.arcgis.com/en/pro-app/tool-reference/spatial-statistics/h-whyhexagons.htm" rel="noopener nofollow"><em><em>https://pro.arcgis.com/en/pro-app/tool-reference/spatial-statistics/h-whyhexagons.htm</em></em></a><br><em><em>[4]</em></em><a href="https://www.sciencedirect.com/science/article/pii/S0304380007001949" rel="noopener nofollow"><em><em>https://www.sciencedirect.com/science/article/pii/S0304380007001949</em></em></a><br><em><em>[5] </em></em><a href="http://strimas.com/spatial/hexagonal-grids/" rel="noopener nofollow"><em><em>http://strimas.com/spatial/hexagonal-grids/</em></em></a><br><em><em>[6] </em></em><a href="https://gis.stackexchange.com/questions/82362/what-are-the-benefits-of-hexagonal-sampling-polygons" rel="noopener nofollow"><em><em>https://gis.stackexchange.com/questions/82362/what-are-the-benefits-of-hexagonal-sampling-polygons</em></em></a><br><em><em>[7] </em></em><a href="https://en.wikipedia.org/wiki/Hex_map" rel="noopener nofollow"><em><em>https://en.wikipedia.org/wiki/Hex_map</em></em></a><br><em><em>[8] </em></em><a href="https://en.wikipedia.org/wiki/Hexagonal_tiling%5C" rel="noopener nofollow"><em><em>https://en.wikipedia.org/wiki/Hexagonal_tiling%5C</em></em></a></p>
                </div>
            </section></div>]]>
            </description>
            <link>https://blog.locale.ai/spatial-modelling-tidbits-honeycomb-or-fishnets/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23900424</guid>
            <pubDate>Mon, 20 Jul 2020 18:17:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I compiled book recommendations from 1300+ leaders]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23900185">thread link</a>) | @vhpoet
<br/>
July 20, 2020 | https://readthistwice.com/people | <a href="https://web.archive.org/web/*/https://readthistwice.com/people">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://readthistwice.com/people</link>
            <guid isPermaLink="false">hacker-news-small-sites-23900185</guid>
            <pubDate>Mon, 20 Jul 2020 17:47:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Purpose of Technology: eliminate mortality]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23900179">thread link</a>) | @tosh
<br/>
July 20, 2020 | https://balajis.com/the-purpose-of-technology/ | <a href="https://web.archive.org/web/*/https://balajis.com/the-purpose-of-technology/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


                <figure>
                    <img srcset="https://balajis.com/content/images/size/w300/2020/07/the-purpose-of-technology--1-.png 300w,
                                https://balajis.com/content/images/size/w600/2020/07/the-purpose-of-technology--1-.png 600w,
                                https://balajis.com/content/images/size/w1200/2020/07/the-purpose-of-technology--1-.png 1000w,
                                https://balajis.com/content/images/size/w2000/2020/07/the-purpose-of-technology--1-.png 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 1170px,
                                2000px" src="https://balajis.com/content/images/size/w2000/2020/07/the-purpose-of-technology--1-.png" alt="The Purpose of Technology">
                </figure>
                <section>
                    <div>
                        <p>If the proximate purpose of technology is to reduce scarcity, the ultimate purpose of technology is to eliminate mortality.</p><p>At first that sounds crazy. But let's start with the premise: is the proximate purpose of technology to reduce scarcity? Think about how a breakthrough is described: faster, smaller, cheaper, better. All of these words mean that with this new technology, one can do <em>more with less</em>. In the digital world, Google made information on any topic free to anyone with an Internet connection, and WhatsApp made it free to communicate with the same. In the physical world, innovations like the <a href="https://en.wikipedia.org/wiki/Haber_process">Haber Process</a> or the <a href="https://en.wikipedia.org/wiki/Norman_Borlaug#Expansion_to_South_Asia:_the_Green_Revolution">Green Revolution</a> allowed us to produce more with less. In a real sense, these technologies <em>reduced scarcity</em>.</p><p>Now for second half of the sentence, the logical implication. Is the ultimate purpose of technology to eliminate mortality? Well, mortality is the main source of scarcity. If we had infinite time, we would be less concerned with whether something was faster. The reason speed has value is because time has value; the reason time has value is because human life has value, and lifespans are finite. If you made lifespans much longer, you'd reduce the effective cost of <em>everything</em>. Thus insofar as reducing scarcity is acknowledged to be the proximate purpose of technology, eliminating the main source of scarcity ‚Äì namely mortality ‚Äì is the ultimate purpose of technology. <strong>Life extension is the most important thing we can invent.</strong></p><p>And it's actually feasible today. It's been shown that we can extend healthy lifespans in mammals ‚Äì and even <em>reverse</em> aging to bring people back to youth. Here's <a href="https://twitter.com/davidasinclair/status/1259084270854905856">link</a> after <a href="https://www.longevity.vc/">link</a> after <a href="https://www.nature.com/articles/s41467-020-15174-3">link</a> after <a href="https://news.harvard.edu/gazette/story/2019/11/researchers-able-to-improve-reverse-age-related-diseases-in-mice/">link</a> on the topic.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">Six years ago, a lifetime in the aging field, the mere suggestion that aging could be reversed was enough to have your colleagues &amp; donors screw up their noses. Tom Rando <a href="https://twitter.com/StanfordMed?ref_src=twsrc%5Etfw">@StanfordMed</a> deserves a shout out for being brave enough back then to use the word "reversal" openly 6/n</p>‚Äî David Sinclair, PhD (@davidasinclair) <a href="https://twitter.com/davidasinclair/status/1259912936602177536?ref_src=twsrc%5Etfw">May 11, 2020</a></blockquote>

</figure><p>You probably weren't aware of this, though. You probably also weren't aware of how far we've come on <a href="https://www.nature.com/articles/d41586-020-00339-3">gene therapy</a>, how much has been done in <a href="https://www.the-scientist.com/news-opinion/rna-injection-restores-hearing-in-guinea-pigs-30855">regenerative medicine</a>, how advanced the latest <a href="https://www.nature.com/articles/s41586-020-2285-x">bionic eyes</a> are ‚Äì or how <a href="https://twitter.com/balajis/status/1228447944287932416">deadly</a> COVID-19 was as a threat until March of 2020.</p><h2 id="a-duty-to-evangelize-technological-progress">A duty to evangelize technological progress</h2><p>That is because people with scientific and technical backgrounds have not taken it upon ourselves to write about technological progress <em>as a duty</em>. We need to take time out of our busy days to make the case, repeatedly and with high production values, that technological progress is the <em>most </em>important thing we can do for broad-based prosperity and economic growth, and for life itself.</p><p>That starts with testing, drugs, treatments, and vaccines for COVID-19. But it goes far beyond that. Put another way: we may not get life extension or the whole suite of transhumanist technologies (brain-machine interfaces, stem cells, CRISPR gene therapy, and more) unless you, personally, evangelize them online. Not just tweets, but articles. Not just articles, but videos. Not just videos, but feature films. And not just a few films, but an <a href="https://www.whats-on-netflix.com/news/how-long-would-it-take-to-watch-all-of-netflix/">entire Netflix original library's worth</a>, a parallel tech media ecosystem full of inspirational content for technological progressives. A lifetime's worth of content that makes the case for immutable money, infinite frontier, artificial intelligence, and eternal life.</p><p>This may mean less focus on the businesses and personalities of technology. After all, do we care whether the technology for reversing aging is developed by a startup, an academic lab, a scientific consortium, or a solitary biohacker in their garage? No. What we care about is the goal of transcendence. If the technology ends up being <a href="https://www.amazon.com/Patenting-Sun-Polio-Salk-Vacine/dp/0688094945">completely free</a> and open source, so much the better. A corporate vehicle is just one means to an end, not an end in itself. We may need to understand every detail of operating a business, but we can't get lost in those details.</p><p>The point of doing a startup after all is to build something you can't buy. Money can't yet buy you a trip to <a href="https://www.spacex.com/human-spaceflight/mars/">Mars</a>. Or a <a href="https://www.neuralink.com/">neural implant</a>. Or a <a href="https://tricorder.xprize.org/prizes/tricorder">medical tricorder</a>. And at one point in the not-too-distant past it could not buy you a web browser, a search engine, or a smartphone. When the iPhone did not exist, people had to invent it. And they needed to be inspired to invent it.</p><figure><blockquote data-width="550"><div lang="en" dir="ltr"><p>for iphone 1:</p><p>the original mac,<br>blade runner,<br>2001: a space odyssey,<br>sony walkman TPS-L2, <br>braun ET66, <br>the concorde, <br>massimo vignale, <br>henry dreyfuss, <br>apollo 11, <br>the beatles,<br>warp records,<br>NASA,<br>polaroid,<br>arthur c. clarke,<br>eero saarinen</p><p>among others‚Ä¶ <a href="https://t.co/F3ayC03T3y">https://t.co/F3ayC03T3y</a></p></div>‚Äî Imran Chaudhri (@imranchaudhri) <a href="https://twitter.com/imranchaudhri/status/1092194839540584449?ref_src=twsrc%5Etfw">February 3, 2019</a></blockquote>

</figure><h2 id="a-sense-of-purpose">A sense of purpose</h2><p>Why doesn't inspirational content for technological progressives exist in abundance? Part of the reason is adverse selection. While science fiction ‚Äì even dystopian science fiction ‚Äì can inspire, the scientists, engineers, founders, and funders thus inspired are often more occupied with building technology than evangelizing it. But this in turn means that we aren't directly educating the next generation, or the public at large.</p><p>We need to change that. Specifically, people who know math and science, who have experience in managing and investing, who are <em>technological progressives</em> rather than technological conservatives ‚Äì these people need to learn to write, report, publish, and direct. We need to consciously build a parallel tech-driven decentralized media ecosystem, and we need it to become the first point of call for anyone seeking to learn about technology.</p><p>In this we will have allies around the world. Only the very richest people can afford to be cynical about the merits of technological progress. The <a href="https://www.ben-evans.com/benedictevans/2019/5/28/the-end-of-mobile">billions</a> of people who just got their first smartphone have had their lives dramatically improved as a consequence, and are too pragmatic to romanticize the past. If you haven't already internalized this point, take two minutes to watch <a href="https://www.youtube.com/watch?v=QpvEWVVnICE">this</a>.</p><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/QpvEWVVnICE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>Back? OK. So, building a media ecosystem for technological progressives clearly starts with technical education. At the K-12 level, we've already got plenty of learning apps, and the next step is remote schools. And at the level of collegiate education and continuous learning, Lambda School, Fast.ai, Coursera, Udacity, Udemy, Binance Academy, and the countless GitHub tutorials are an amazing start. But our duty extends beyond education to media of all kinds, particularly visual media.</p><p>The tech ecosystem has natural advantages here. We have the domain knowledge. And the experts at hand. We're already doing content marketing, podcasts, conferences, and a tweetstorm or two. We understand search engines, social networks, and distribution. And yes, we have learned to code.</p><p>What we haven't done yet is <em>full stack narrative</em>. That is, with a <a href="https://wistia.com/series/one-ten-one-hundred">few exceptions</a>, like Elon Musk, we haven't really told story arcs with technological progress at the center. We haven't taken the pitch we use to recruit engineers and externalized it for the public. We haven't infused <a href="https://twitter.com/balajis/status/1276010131990261761">emotion</a> and meaning into our public communications. We haven't made every one of our companies a media company. We haven't set out to tell our story ourselves.</p><p>We need to correct that immediately, and start evangelizing technological progress with every word and action. To recognize that the purpose of technology is to transcend our limits, and to motivate everything we're doing with a sense of that purpose. To take the winnings from our web apps and <a href="https://www.quora.com/How-did-Elon-Musk-fund-his-businesses-from-PayPal-to-SpaceX-and-Tesla">put them towards Mars</a>, to feel no hesitation towards starting small and no shame in dreaming big, to tell the world that it actually is possible to <a href="https://www.the-scientist.com/news-opinion/rna-injection-restores-hearing-in-guinea-pigs-30855">cure the deaf</a>, <a href="https://www.nature.com/articles/s41586-020-2285-x">restore sight</a>, and <a href="http://med.stanford.edu/news/all-news/2020/03/old-human-cells-rejuvenated-with-stem-cell-technology.html">end</a> <a href="https://www.youtube.com/watch?v=9nXop2lLDa4">death</a> <a href="https://www.ldeming.com/longevityfaq">itself</a>.</p>
                    </div>
                </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://balajis.com/the-purpose-of-technology/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23900179</guid>
            <pubDate>Mon, 20 Jul 2020 17:47:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Packaging and Vending Production Rust Software ‚Äì Windows]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23900151">thread link</a>) | @gorbot
<br/>
July 20, 2020 | https://ebbflow.io/blog/vending-win | <a href="https://web.archive.org/web/*/https://ebbflow.io/blog/vending-win">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>Background: <a href="https://ebbflow.io/">Ebbflow</a> is a multi-cloud load balancer that provisions browser-trusted certificates for your endpoints in addition to providing a client-friendly SSH proxy. Servers can host endpoints from any cloud, on premises, or from your home, all at the same time. It uses nearest-server routing for low latencies and is deployed around the globe.</p>
        <p>This post describes how Ebbflow vends its <a href="https://github.com/ebbflow-io/ebbflow">client</a> to Windows users which is written in Rust, describing the tools used to build and ultimately deliver the program to users.</p>
        <h3>Ebbflow Client 101</h3>
         <p>Ebbflow's job is to route user traffic to your web server application (or SSH Daemon) on your servers. The central Ebbflow service proxies data between user connections (e.g. browser, SSH client) and the client. The client then proxies the data to your web server or local SSH daemon. Users of Ebbflow install the client on machines that will host endpoints, be SSH-ed to, or both at the same time (which is very useful). The following diagram shows this visually.</p>
        <p><img id="clientdg" src="https://ebbflow.io/resources/clientdiagram.png"></p><p><small><i>Quick note: The client initiates the connection to the central Ebbflow service via an outbound TLS connection, which makes the client extremely firewall friendly. You may completely block all inbound connections but still host websites or be SSH-ed to! Also, this innovation allows the servers to be located in any network, and even change networks without any configuration at all. Ebbflow just receives connections from the general internet, and after authentication and authorization, will allow the server to host the endpoint or be SSH-ed to. Neat!</i></small></p>
        <p>The client has two parts, the CLI and the background daemon. Both of these programs are 100% Rust, 100% <code>async</code>, and 100% 'safe', <i>and</i> statically linked - the dream of any Rust developer! The <a href="https://github.com/ebbflow-io/ebbflow/blob/master/src/ebbflow.rs">CLI</a> is an executable tool named <code>ebbflow</code> that is used to tell the background to host new endpoints, disable or re-enable endpoints or the SSH proxy, and configure other settings.</p>
        <p>The background daemon is the second piece to this puzzle, and is the workhorse and is responsible for actually transferring bytes between the central Ebbflow servers and your local web server or SSH daemon. This daemon is just a long-running background executable named <a href="https://github.com/ebbflow-io/ebbflow/blob/master/src/ebbflowd.rs"><code>ebbflowd</code></a>.</p>
        <h2>Windows</h2>
        <p><img src="https://ebbflow.io/resources/windows.png"></p><p>Supporting Windows as a first-class server OS is very important to Ebbflow. Taking the two executables &amp; re-compiling them on Windows was simple thanks to Rust's abstractions over the underlying OS and numerous community projects. First things first, the background daemon needs to be changed to work in a Windows world.</p>
        <h3>Background Daemon / Windows Service</h3>
        <p>The <code>ebbflow</code> CLI is very simple and is portable in the sense that you could execute the binary on a windows machine without installing it and it will do its job correctly, but <code>ebbflowd</code> is another story. To execute a background program in Windows one uses the <a href="https://docs.microsoft.com/en-us/dotnet/framework/windows-services/introduction-to-windows-service-applications">Windows Service</a> framework. This framework is needed as the <code>ebbflowd</code> program needs to run when there are no interactive users, start when the system starts, and be watched and restarted in the event of a crash (which has not happened due to Rust's inherit safety and never <code>unwrap</code>ing).</p>
        <p>A sticking point of using the Windows Service framework is that your program needs to implement a specific <a href="https://docs.microsoft.com/en-us/windows/win32/services/service-programs">interface</a>, namely it must provide an entry point, handle signals, and register itself. To help, the <a href="https://crates.io/crates/windows-service"><code>windows-service</code></a> Rust crate (provided by <a href="https://github.com/faern">Linus F√§rnstrand</a>) makes this very simple.</p>
        <p>This <code>windows-service</code> crate provides a macro which requires that you implement just a few functions that are effectively <code>main</code> functions. The Ebbflow client uses <code>#[cfg(windows)]</code> to conditionally include all of the <a href="https://github.com/ebbflow-io/ebbflow/blob/master/src/ebbflowd.rs#L25-L142">necessary code</a> to implement these functions and therefore the Windows Service interface itself! The <a href="https://crates.io/crates/winlog">winlog</a> crate was also helpful for taking <a href="https://crates.io/crates/log">log events</a> and adding them to the <a href="https://docs.microsoft.com/en-us/windows/win32/wes/windows-event-log">Windows Event Log</a> system.</p>
        <h3>Going Static</h3>
        <p>Rust will dynamically link against the OS's <code>libc</code> implementation when the standard library is used, which is the case for almost all substantial Rust applications. On Windows, this means Rust will compile programs and link them to the system's 'MSVC' (MicroSoft Visual C++) libc implementation. Interestingly, the default Windows 10 image does NOT include this library! This results in Rust code breaking when executed on a new system, something that has come up in testing, but may not come up in development as MSVC would likely get installed at one point or another when setting up a Windows machine for code development.</p>
        <p>Statically linking Rust code is simple. To bring along MSVC with your compiled Rust program, you <a href="https://github.com/rust-lang/rfcs/blob/master/text/1721-crt-static.md">instruct</a> the compiler to statically link MSVC. In my case I <a href="https://github.com/ebbflow-io/ebbflow/blob/master/.github/workflows/continuous-integration.yml#L89-L90">set just one environment variable</a> (<code>RUSTFLAGS='-C target-feature=+crt-static'</code>) and it simply worked, but you can add a <a href="https://stackoverflow.com/a/44387312">config file entry or pass a flag</a> to compilation as well.</p>
        <p>Besides the <code>std</code> library, Rust code may link to other OS libraries most often OpenSSL or libsodium for crypto. The Ebbflow client avoids this by using <a href="https://crates.io/crates/rustls"><code>rustls</code></a> which uses <a href="https://crates.io/crates/ring">ring</a> under the hood. Rustls is an ergonomic TLS library for Rust. It is <a href="https://jbp.io/2019/07/01/rustls-vs-openssl-performance.html">highly performant</a> even compared to OpenSSL and recently underwent a 3rd party <a href="https://github.com/ctz/rustls/blob/main/audit/TLS-01-report.pdf">security audit</a> which showed no flaws. When you invest in the Rust ecosystem and use Rust-written libraries, you are rewarded with the ability to statically link which is a desireable situation.</p>
        <h3>Building the <code>.msi</code> using Wix</h3>
        <p>Windows uses 'installers' in the form of <code>.msi</code> packages to handle which packages are installed on a system. These installers tell Windows what files/executables go where and contain logic to handle upgrades, uninstallations, and configuration management.</p>
        <p>Ebbflow uses Wix which is a tool that takes an <code>.xml</code> configuration file and generates <code>.msi</code> packages. Conveniently, a plug-in to Rust's <code>cargo</code> build tool named <a href="https://crates.io/crates/cargo-wix"><code>cargo-wix</code></a> exists. This tool can generate a skeleton Wix <code>xml</code> file which we then modified to suit our needs. Under the hood, executing <code>cargo wix</code> will compile your program in <code>--release</code>, then package up everything into your <code>.msi</code> using <a href="https://wixtoolset.org/documentation/manual/v3/overview/candle.html">candle.exe</a> to compile your Wix config and <a href="https://wixtoolset.org/documentation/manual/v3/overview/light.html">light.exe</a> to link it.</p>
        <p>Generating and tinkering with the <a href="https://github.com/ebbflow-io/ebbflow/blob/master/wix/main.wxs">client's Wix file</a> took some time. There are numerous StackOverflow q/a's and other resources to help with writing the Wix file which was helpful, but I found that vending a Windows Service in an installer is more of an edge case. Also, configuring the UI components of the installer is tricky and I never found a great reference implementation or other documentation.</p>
        <h3>Automated Builds using GitHub Actions</h3>
        <p>Up to this point, I've produced a statically linked Windows program and packaged it into an installer. For various reasons such as build reproducability &amp; transparency, and hosting the built <code>.msi</code> for free, Ebbflow uses <a href="https://github.com/features/actions">GitHub Actions</a> to build and package up the client. You can see the client's <a href="https://github.com/ebbflow-io/ebbflow/blob/master/.github/workflows/continuous-integration.yml#L86-L106">Windows build configuration on GitHub</a>, and here is a snippet:</p>
        
        <p>GitHub provides a Windows image that has <a href="https://github.com/actions/virtual-environments/blob/master/images/win/Windows2019-Readme.md">various build tools included</a>, importantly Wix. Getting Windows builds set up on GitHub Actions was pretty simple and I had a great experience with the service. </p>
        <h3>Distribution to Users</h3>
        <p>After writing the code, making an installer and testing that out, the next step is to figure out how to get this into our customers hands. To solve this, the first thought is to just distribute the <code>.msi</code> file itself and notify customers of upgrades. This generally works and the installer can handle upgrades and uninstallations. However, there are drawbacks. The major one is that any future updates will require the customer to download the new <code>.msi</code>, which requires some custom process. Windows will flag any software that is unsigned and all applications must be signed using certificates derived from trusted certificate authorities. This is fine and secure but to have our <code>.msi</code> work without warnings you must purchase a code signing certificate/key from someone like Digicert or the like which can easily run into the hundreds of dollars. Alternatively you can create your own CA &amp; signing key/certificate, self-sign the <code>msi</code>, then have all customers add your CA to their trusted store. This does not seem too common from my understanding.</p>
        <p>These two drawbacks are pretty severe, which is what leads us to our chosen solutions, Chocolatey and Winget.</p>
        <h4>Chocolatey</h4>
      <p><img src="https://ebbflow.io/resources/choco.svg"></p><p><a href="https://chocolatey.org/">Chocolatey</a> is a 3rd party package manager and you can use it to install, update, remove, and/or search for packages. It works great for personal use and will feel very familiar to any Linux users. Chocolatey also provides a multi-computer management solution to enterprise customers so sysadmins could distribute and maintain many Windows computers from afar.</p>
        <p>Importantly, Chocolatey packages do not require code-signing and will not trigger any warnings when installed. Adding package to the Chocolatey package store is <a href="https://chocolatey.org/docs/CreatePackagesQuickStart#prerequisites">decently simple</a>. Chocolatey deals in <code>.nupkg</code>-es, which are easily created with the Chocolatey CLI. Execute <code>choco new</code> to generate a base set of files. After modifying them, you package up everything into the <code>.nupkg</code> container using <code>choco pack</code>. Ebbflow's chocolatey repo can be found <a href="https://github.com/ebbflow-io/chocolatey-ebbflow">on GitHub</a>. Be sure to remove configuration entries or files that you don't need. And for referencing the actual installer for download, we just use the GitHub Release artifact that we post, all thanks to our earlier decision to build on GitHub.</p>
        <p>Once you submit your package to Chocolatey, it goes through two automated steps of validation and it will spit out some advice that can be required and block your package from being released or it will spit out recommended changes like adding specific links or documentation. If these pass, the package enters 'moderation', and an actual human will review the package before it is released. This can take days to weeks, and is a drawback. Chocolatey does have Business ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ebbflow.io/blog/vending-win">https://ebbflow.io/blog/vending-win</a></em></p>]]>
            </description>
            <link>https://ebbflow.io/blog/vending-win</link>
            <guid isPermaLink="false">hacker-news-small-sites-23900151</guid>
            <pubDate>Mon, 20 Jul 2020 17:44:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vue 3's Local and Global States]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23900134">thread link</a>) | @new_here
<br/>
July 20, 2020 | https://able.bio/pepsighan/vue-3s-local-global-states--ad6ce55e | <a href="https://web.archive.org/web/*/https://able.bio/pepsighan/vue-3s-local-global-states--ad6ce55e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="body">
    <div>
            
            
            
            

            
            <div>
                <div>
                    
                    <article>
                    
                        
                    <div><p>With the advent of Vue 3's composition API, one may write local states and its tightly coupled actions like given below:</p>
<pre><code>// maths.js
import { ref } from 'vue';

export function useMaths() {
  const val = ref(0);

  const increment = () =&gt; (val.value += 1);
  const decrement = () =&gt; (val.value -= 1);

  return {
    val,
    increment,
    decrement,
  };
}
</code></pre>
<p>This should look eerily similar to what React offers (if you have used React hooks).</p>
<p>The above code creates a reactive value called <code>val</code> and provides two actions to either <code>increment</code> or <code>decrement</code> this value.</p>
<p>This hook or a composable function can be imported into a component and used directly like so:</p>
<pre><code>&lt;template&gt;
  {{ val }}
  &lt;button @click="increment"&gt;Increment&lt;/button&gt;
  &lt;button @click="decrement"&gt;Decrement&lt;/button&gt;
&lt;/template&gt;

&lt;script&gt;
  import { useMaths } from './maths';

  export default {
    setup: () =&gt; {
      const { val, increment, decrement } = useMaths();
      return {
        val,
        increment,
        decrement,
      };
    },
  };
&lt;/script&gt;
</code></pre>
<p>The component binds the value and actions to the Vue template. This <code>useMaths</code> hook can be imported into any number of components and the behaviour can be reused while keeping the states local to the component in which it was used.</p>
<blockquote>
<p>Vue 3 not only allows us to compose the components and the UI but their behaviour as well.</p>
</blockquote>
<h3 id="but-what-do-you-do-when-you-realise-that-the-state-should-have-been-global-instead%3F">But what do you do when you realise that the state should have been global instead?</h3>
<p>There are times when you could be thinking that a particular state should be local to a component or a page. But as the app progresses on, this assumption may not hold true anymore.</p>
<p>Or there might be instances where you just wanted to experiment with the component and flesh out the internal workings while keeping the implementation simple by using local states. But once the experimentation phase is over you just want to reuse the code as much as possible and adapt it to use a global state.</p>
<p>In these above scenarios, Vue 3 gives us a new trick that we can do with <code>ref</code> that makes this sort of <strong>migration</strong> negligibly cheap to implement.</p>
<p>See what we do to make the state global in the code below?</p>
<pre><code>// maths.js
import { ref } from 'vue';

const val = ref(0);

export function useMaths() {
  const increment = () =&gt; (val.value += 1);
  const decrement = () =&gt; (val.value -= 1);

  return {
    val,
    increment,
    decrement,
  };
}
</code></pre>
<p>Just move the <code>ref</code> out of the context of the hook and make it global. Vue will take care of the rest. Each component that uses this hook will all share the same <code>val</code>. Now, isn't that something?</p>
<p>PS: This can be done with <code>reactive</code> as well.</p>
                    </div>
                    </article>
                
                    
                    
                    <hr>
                    
                    <div>
                        
                        <p><img src="https://assets.able.bio/media/u/83fa5a432ae55c253d0e60dbfa716723/__09PcgDd.jpg" loading="lazy" alt="Author picture"></p><div>
                            

                            <p>
                                You'll need to sign in with <a alt="Sign in with GitHub" href="https://able.bio/oauth/login/github/" target="_blank">GitHub</a> or <a alt="Sign in with Twitter" href="https://able.bio/oauth/login/twitter/" target="_blank">Twitter</a> before you can follow people.
                            </p>

                            

                            
                        
                        </div>
                    

                        

                        
                        

                    </div>

                    



                
                </div>
            </div>
            

            
            
            
            
    
    
</div>
</div></div>]]>
            </description>
            <link>https://able.bio/pepsighan/vue-3s-local-global-states--ad6ce55e</link>
            <guid isPermaLink="false">hacker-news-small-sites-23900134</guid>
            <pubDate>Mon, 20 Jul 2020 17:42:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Statistical significance explained through real-life examples]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23900075">thread link</a>) | @R3G1R
<br/>
July 20, 2020 | https://mathvault.ca/statistical-significance/ | <a href="https://web.archive.org/web/*/https://mathvault.ca/statistical-significance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://mathvault.ca/wp-content/uploads/Statistical-Significance.jpg" alt="A Primer on Statistical Significance" width="800" height="480" title="Statistical Significance" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20800%20480'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Statistical-Significance.jpg"></p><p><strong>Statistical significance</strong>, in a nutshell, is a way of determining the degree of unlikely-ness of an experimental result ‚Äî when a certain status quo hypothesis is assumed to be true.<span id="more-9087"></span></p><p>For example, let‚Äôs say that a school had two teachers, each with approximately $30$ students in their class. Both classes take a standardized test, and it turns out that the average score in class A was $5\%$ better than the average in class B.&nbsp; Statistical significance ‚Äî in this regard ‚Äî would be our way of determining whether the better score in class A could be attributed to <em>random chance</em>, for instance:</p><ul><li>It was a lucky day for class A.</li><li>Class A just randomly got assigned better prepared students.</li></ul><p>Or whether there is some other factor responsible for the difference in grades between the classes,&nbsp;for instance:</p><ul><li>Teacher A did a better job of teaching than teacher B.</li><li>Teacher A cheated a bit and gave the students some answers ahead of time.</li><li>The classes were purposely split up (e.g., more advanced students or native speakers of a language were put into class A).</li></ul><p>Note that in this case, we wouldn‚Äôt ‚Äî using <em>only</em> the information on the scores at least ‚Äî attempt to decide what the exact reason for the different scores was. Instead, we would just determine if the score difference could be attributed to pure chance, or that it is so unlikely that there might be some other factors involved.</p><h2 id="start"><span id="Getting_Started"></span><a href="#toc">Getting Started</a><span></span></h2><p>There are two important things when calculating statistical significance. The first is the <strong>magnitude of difference</strong> between what you are measuring and what you are comparing against. The second is the amount of <strong>natural variation</strong> in what you are measuring.</p><p>The first concept, magnitude of difference, is easy to understand. Let‚Äôs say that you are a farmer growing pumpkins and trying out new fertilizers. You have a <strong>baseline average</strong> pumpkin weight, which is an average of $10$ lbs. You also have pumpkins from two different fertilizers&nbsp;‚ÄîA and B&nbsp;‚Äî that you are testing out.</p><p>If fertilizer A makes pumpkins that weigh $11$ lbs. on average, then it is possible that the $1$ lbs. difference relative to the baseline $10$ lbs. is <em>caused</em> by the fertilizer. However, if fertilizer B produces $25$ lbs. pumpkins on average, then that $15$ lbs. difference ($25-10$) is more likely to be a result of fertilizer B ‚Äî than the $1$ lbs. difference was to be a result of fertilizer A.</p><h2 id="sse"><span id="Looking_at_the_Statistical_Significance_Equation"></span><a href="#toc">Looking at the Statistical Significance Equation</a><span></span></h2><p>The most commonly used statistical significance test is probably the <a href="https://en.wikipedia.org/wiki/Z-test" target="_blank" rel="noopener noreferrer"><strong>Z-test</strong></a>. The equation for the Z-test is:</p><p><img src="https://mathvault.ca/wp-content/uploads/SS1.png" alt="Z-Test Statistics" width="668" height="348" title="SS1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20668%20348'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/SS1.png"></p><p>In a nutshell, the Z-Test equation calculates the <em>ratio</em> of two quantities: the numerator on the top, and the denominator at the bottom. Let‚Äôs take a look at them individually.</p><h3 id="num"><span id="Numerator"></span><a href="#toc">Numerator</a><span></span></h3><p>The <em>numerator</em> of the equation is where the <strong>magnitude of difference</strong> is accounted for:</p><p><img src="https://mathvault.ca/wp-content/uploads/SS2.png" alt="Difference Between Sample Mean and Population Mean" width="400" height="127" title="SS2" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20400%20127'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/SS2.png"></p><p>Here, $\bar{x}$ stands for the&nbsp;<strong>measured average value</strong> for the data set, &nbsp;while $u_0$ stands for the&nbsp;<strong>baseline average value</strong>. In terms of our&nbsp;example with fertilizer B, the baseline and the measured average would be $10$ lbs and&nbsp;$25$ lbs., respectively, yielding a magnitude of difference of:</p><p><img src="https://mathvault.ca/wp-content/uploads/SS3.png" alt="SS3" width="622" height="89" title="SS3" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20622%2089'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/SS3.png"></p><p>In general,&nbsp;the larger in magnitude the final Z-value is, <em>the more significantly the sample deviates from the baseline average value</em>. In particular, having a numerator of $15$ ($25-10$) is more significant than having a numerator of $1$ ($11-10$) ‚Äî all&nbsp;other variables&nbsp;being equal.</p><h3 id="de"><span id="Denominator"></span><a href="#toc">Denominator</a><span></span></h3><p>So far, we have only been focusing on&nbsp;the <em>top half</em> of the statistical significance equation. Let‚Äôs take&nbsp;a look at the&nbsp;<em>denominator</em> of the equation&nbsp;this time:</p><p><img src="https://mathvault.ca/wp-content/uploads/SS4.png" alt="Standard Error of Sample Mean - Amount of Variation in Measured Data" width="600" height="267" title="SS4" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20600%20267'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/SS4.png"></p><p>Here, $\dfrac{\sigma}{\sqrt{n}}$&nbsp;deals with the amount of variation in our measured data. More specifically,&nbsp;the amount of <em>average deviation</em> in the measured averages themselves ‚Äî if we were to repeat the sampling process indefinitely.</p><p>After all, you didn‚Äôt think that your pumpkins actually all weighted $25$ lbs. did you?&nbsp; Some probably weighted $22$ lbs., and others $27$ lbs.&nbsp; The $25$ lbs. was just an average, and that measured average could change depending on the pumpkins being sampled.</p><h2 id="sd"><span id="Normal_Curve_and_Standard_Deviation"></span><a href="#toc">Normal Curve and Standard Deviation</a><span></span></h2><p>At this point, we need to take a step back and explain what the <a href="https://en.wikipedia.org/wiki/Normal_distribution" target="_blank" rel="noopener noreferrer"><strong>normal curve</strong></a> and <strong>standard deviation</strong> are. Loosely speaking, the normal curve is an approximation of how things occur when they are subjected to <em>aggregated</em>, real life random events. The fact that they are random doesn‚Äôt mean that they are <a href="https://mathvault.ca/math-glossary/#arbitrary">arbitrary</a>. As a result, they assume the shape of a <strong>bell curve</strong> as illustrated in the diagram below:</p><p><img src="https://mathvault.ca/wp-content/uploads/SS5.png" alt="Normal Curve (Bell Curve)" width="715" height="510" title="SS5" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20715%20510'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/SS5.png"></p><p>On&nbsp;a related note, the <a href="https://en.wikipedia.org/wiki/Standard_deviation" target="_blank" rel="noopener noreferrer"><strong>standard deviation</strong></a> is a way of measuring the <em>width</em> of the normal curve, and can be alternately defined as the distance from the center which&nbsp;encloses $68.27\%$ of the area below the normal curve:</p><p><img src="https://mathvault.ca/wp-content/uploads/SS6.png" alt="Normal Curve - 68% of data are 1 standard deviation within the mean" width="624" height="445" title="SS6" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20624%20445'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/SS6.png"></p><p>Similarly, two standard deviations define the distance from the center which encloses $95.45\%$ of the curve, and three standard deviations $99.73\%$ of the curve:<img src="https://mathvault.ca/wp-content/uploads/SS7.png" alt="68-95-99 Rule For Normal Distribution" width="715" height="510" title="SS7" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20715%20510'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/SS7.png"></p><p>For&nbsp;a set of data with a lot of variation, the normal curve will be wide, and hence the standard deviation will be large. This would be the case if you&nbsp;take, say, the weight of $100$ rocks you picked up in your backyard.</p><p><img src="https://mathvault.ca/wp-content/uploads/SS8.png" alt="Normal Distribution with Large Standard Deviation" width="463" height="333" title="SS8" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20463%20333'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/SS8.png"></p><p>Or there could also be almost no variation in the data,&nbsp;as in the case where&nbsp;you measured the processing speed for each computer chip in a batch.</p><p><img src="https://mathvault.ca/wp-content/uploads/SS9.png" alt="Normal Distribution with Small Standard Deviation" width="460" height="323" title="SS9" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20460%20323'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/SS9.png"></p><p>Let‚Äôs think about another example ‚Äî this time involving automobiles. Imagine going to a tire store and being informed&nbsp;that the&nbsp;lifespan of new&nbsp;tires&nbsp;is $50,000$ miles on average, with a standard deviation of $5,000$ miles. Using this information, we can construct the&nbsp;<a href="https://mathvault.ca/hub/higher-math/math-symbols/probability-statistics-symbols/#Discrete_Probability_Distributions" target="_blank" rel="noopener noreferrer"><strong>probability distribution</strong></a> of tire lifespan&nbsp;as follows:</p><p><img src="https://mathvault.ca/wp-content/uploads/SS10.png" alt="Tire Life Normal Curve" width="719" height="518" title="SS10" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20719%20518'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/SS10.png"></p><p>As the graph suggests, we&nbsp;have a $50\%$ chance of being above the average of $50,000$ miles (before needing new tires again), and a $50\%$ chance of being below it. We also know that since two&nbsp;standard deviations correspond to $10,000$ miles (i.e., $5000 \times 2$), we&nbsp;have a $95.45\%$ chance of getting new tires&nbsp;with a mileage between $40,000$ and&nbsp;$60,000$ miles (i.e., two&nbsp;standard deviations within the average):</p><p><img src="https://mathvault.ca/wp-content/uploads/SS11.png" alt="Tire Life Normal Curve - Chance of Between 40,000 and 60,000 miles " width="719" height="518" title="SS11" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20719%20518'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/SS11.png"></p><p>Now, let‚Äôs say that a couple of years later,&nbsp;you‚Äôve driven $55,000$ miles and your tires are in need of replacement. Would you consider&nbsp;that unusual? No, probably not, since that‚Äôs only <em>one&nbsp;standard deviation away from the mean&nbsp;</em>‚Äî which is&nbsp;well within the typical tire-to-tire variation often seen in the market.</p><p>But now, let‚Äôs say that this time you‚Äôve driven $60,000$ miles instead before the tires need replacement. This would be&nbsp;<em>two&nbsp;standard deviations<strong>&nbsp;</strong>above the average</em> ‚Äî which is well above the lifespans of most new tires. In addition, since two standard deviations above the average correspond to the top $2.28\%$ of the curve $\left( \frac{100\% ‚Äì 95.45\%}{2}\right)$,&nbsp;it follows&nbsp;that your tires actually lasted longer than $97.72\%$ of all other tires!</p><p>Of course, having a single measurement exceeding $97\%$ of your expected measurements is quite unusual. You have to start thinking, ‚ÄúMaybe there is something different about my situation than the typical installation for the same tires.‚Äù For example, it could be that:</p><ul><li>You are just a more cautious driver, and wear down the tires less quickly than the typical person.</li><li>The shop put on better tires than you thought. Maybe you got the next level up by some happy accident.</li><li>The tire company undersells their products a little bit, and it is actually better than they advertised.</li></ul><p>Or it could be that it is just a <em>typical variation</em> ‚Äî and&nbsp;you happen to stumble upon&nbsp;on the right tail of the curve.</p><h2 id="mm"><span id="Multiple_Measurements"></span><a href="#toc">Multiple Measurements</a><span></span></h2><p>So far, we have seen how the normal curve applies to a single measurement. With a single measurement, it is easy to see where it would fall on the normal curve, but how would your opinion&nbsp;change if you had <strong>multiple measurements </strong>instead?</p><p>Maybe you own a fleet of cars, and you got the same type of tires on each of those cars and those tires lasted, say, $46$, $48$, $53$, $54$, $56$, $56$, $57$, $58$, $60$ and $62$ thousand miles. Do these&nbsp;additional measurements make you more or less inclined to believe that the tires last more than the advertised $50,000$ miles?</p><p>To be sure,&nbsp;we can, and will, plug those numbers in to the equation to determine the verdict. But there is an interesting reason why the equation works the way it does, and the way to understand it&nbsp;‚Äî as luck would have it ‚Äî&nbsp;is to begin with some dice rolling.</p><h2 id="sda"><span id="Standard_Deviation_of_Averages"></span><a href="#toc">Standard Deviation of Averages</a><span></span></h2><p>The key to understanding statistical significance is to realize that you&nbsp;actually&nbsp;don‚Äôt care much&nbsp;about the standard deviation of the data. What&nbsp;you really care about is the <strong><a href="https://en.wikipedia.org/wiki/Standard_deviation#Standard_deviation_of_the_mean" target="_blank" rel="noopener noreferrer">standard deviation of averages</a> ‚Äî</strong>&nbsp;a metric pertaining to&nbsp;<em>samples</em> drawn from the data rather than the data themselves, and which changes as one&nbsp;includes&nbsp;more data into the&nbsp;sample.</p><h3 id="1d"><span id="SingleDie_Rolling"></span><a href="#toc">Single-Die&nbsp;Rolling</a><span></span></h3><p>To see how the standard deviation of averages is related to dice rolling, let‚Äôs begin our discussion by first throwing a single die. In this case,&nbsp;you have an <strong>equal probability</strong> of getting&nbsp;a $1$, $2$, $3$, $4$, $5$ or $6$. &nbsp;Here‚Äôs the probability distribution of that roll for the record:</p><p><img src="https://mathvault.ca/wp-content/uploads/SS12.png" alt="Distribution of the Number on a Single Die" width="749" height="529" title="SS12" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20749%20529'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/SS12.png"></p><p>Here, the <strong>average roll</strong> you would get is $3.5$, and the standard deviation of the&nbsp;roll&nbsp;‚Äî which is the <a href="https://mathvault.ca/hub/higher-math/math-symbols/probability-statistics-symbols/#Variables" target="_blank" rel="noopener noreferrer"><strong>population standard deviation</strong></a> of the set $\{ 1, 2, 3, 4, 5, 6 \}$ ‚Äî is $1.7078$. &nbsp;Note that the population standard deviation is just a measure of how spread out a data set is, and that the greater a data point deviates from the average in the data set, the more it increases the standard deviation of the data set.</p><p>In the case of single die rolling, for example,&nbsp;a roll of a $3$ or a $4$ would contribute the least&nbsp;to the standard deviation.&nbsp;A&nbsp;roll of $2$ or $5$ would contribute a bit more, and&nbsp;a&nbsp;roll of $1$ or a $6$ would be the ones contributing the most.</p><h3 id="2d"><span id="TwoDice_Rolling"></span><a href="#toc">Two-Dice Rolling</a><span></span></h3><p>Now, what happens if you roll <em>two</em>&nbsp;dice instead of one, and take the <em>average</em> of those two rolls? &nbsp;For one, you would get $6 \times 6 = 36$ possible outcomes in that case, which correspond to a total of $11$ possible sums&nbsp;‚Äî from a sum of $2$ to a sum to $12$.</p><p>But here‚Äôs the caveat: those $36$ different possible rolls actually don‚Äôt map evenly onto the $11$ possible sums! In fact, the most likely ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mathvault.ca/statistical-significance/">https://mathvault.ca/statistical-significance/</a></em></p>]]>
            </description>
            <link>https://mathvault.ca/statistical-significance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23900075</guid>
            <pubDate>Mon, 20 Jul 2020 17:37:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Many Faces of an Undying Programming Language]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23900060">thread link</a>) | @paroneayea
<br/>
July 20, 2020 | http://jakob.space/blog/thoughts-on-lisps.html | <a href="https://web.archive.org/web/*/http://jakob.space/blog/thoughts-on-lisps.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>July 20, 2020 ‚ùñ Tags: <a href="http://jakob.space/blog/tag/tag/opinion.html">opinion</a>, <a href="http://jakob.space/blog/tag/tag/programming.html">programming</a>, <a href="http://jakob.space/blog/tag/tag/lisp.html">lisp</a>, <a href="http://jakob.space/blog/tag/tag/common-lisp.html">common-lisp</a>, <a href="http://jakob.space/blog/tag/tag/scheme.html">scheme</a></p><article><p>
This is a post I've been meaning to write for a while now: one anecdotally
comparing programming languages in the Lisp family. I consider myself to be a
Lisp hacker. Perhaps that much was obvious from the letter Œª adorning my
website's header, a reference to the Œª-calculus which inspired John McCarthy to
design the first LISP [1]. Yet, "Lisp hacker" likely means little unless you,
too, consider yourself to be a Lisp hacker. Calling yourself one seems carry
some level of unstated meaning. Indeed, some identify with more specific groups.
"Schemer," or "Guiler," or "Racketeer," or "Clojurist." But "Lisp Hackers" ‚äá
"Schemers". There is commonality shared among all, or at least most, of these
programming languages, and the Lisp hackers recognize and appreciate that
commonality ‚Äì the characteristics that make a programming language a Lisp.
Homoiconic syntax, powerful metaprogramming facilities, and editor support that,
in my opinion, is unparalleled. (Yes, I am alluding to GNU Emacs.) This article,
however, is concerned with the differences. In it, I will be considering the
specifics of each dialect, and whether or not those specifics make for a
language I would want to use to develop a new piece of software.
</p><p>
I'm specifically concerned with game development at the time of writing this
article. An idea for a turn-based tactics game came to me and I felt a Lisp
would be the best tool for realizing it, but the decision to use "a Lisp" still
leaves me with several choices. When I enumerate the notable design choices
behind each dialect, and talk about the approaches I prefer, my opinions will
be, in some capacity, framed as partial answers to the question of "will I be
able to comfortably use this to write a video game?" As such, there are a few
things I am specifically interested in:
</p><ul>
<li><b>Ergonomics</b>, or "a measure of the friction [one experiences] when trying to get
things done" [2].</li>
<li><b>Expressiveness</b>, or the ease with which code may be understood by a reader.</li>
<li><b>Performance</b>, which is nontrivial to properly quantify [3]. I won't be rigorous
with this; a one-off run with <code>time</code> can give a good idea of the order of
magnitude for execution time.</li>
<li><b>Ease of distribution</b>, which is difficult to define, but with which I associate
platform agnosticism, a runtime that won't bloat my tarballs by several
gigabytes, and a lack of baroque and difficult to obtain dependencies.</li>
<li><b>Ability to interface with other libraries</b>, as I'll want to be able to
draw to the screen, and play sounds, and so on.</li>
</ul><p>
For each dialect, I'm allowing myself to use nonstandard functions. I'm aiming
for an evaluation of the practical aspects of each language, and if you were
writing software, you'd likely be using more than what's included in the R5RS or
ANSI CL standards. Though, if these nonstandard functions are specific to a
single implementation, I will avoid them. SRFI's and QuickLisp are fair game,
but CHICKEN's Eggs are not. Ah, I'm already getting ahead of myself. Yes, I will
be comparing Scheme and Common Lisp. I almost have to ‚Äì the history of Lisp
tends to be spun as a schism between Common Lisp and Scheme. I will be speaking
of a few others as well. I've mostly chosen dialects for which there exists some
"game engine" type library. For R7RS (CHICKEN), there is <a href="http://alex-charlton.com/projects/Hypergiant/">Hypergiant</a>, for R6RS
(Guile) there is <a href="https://dthompson.us/projects/chickadee.html">Chickadee</a>, for Common Lisp there is <a href="http://www.xelf.me/">Xelf</a>, and for Fennel there
is, of course, <a href="https://love2d.org/">L√ñVE</a>.
</p><figure>
<img src="http://jakob.space/static/image/lisp-personality-test.png" alt="lisp-personality-test.png">

<figcaption><span>Figure 1: </span>My take on the drawing in Conrad Barski's <i>Land of Lisp</i>. From left to right: Common Lisp, Scheme, <del>Haskell</del> Fennel.</figcaption>
</figure><p>
What follows are my opinions, so I'd like to lead with the background that
motivated them. My earliest "serious" experience with Lisp was with Peter
Seibel's <i>Practical Common Lisp</i>, which I picked up in high school following a
failed attempt at reading <i>Structure and Interpretation of Computer
Programs</i>.<sup><a id="fnr.1" href="#fn.1">1</a></sup> The portion of the latter book that I did manage was enough to
convince me that learning <span>a</span> Lisp would be valuable, but that learning Common
Lisp may be more tractable than learning Scheme. The summer following my first
year of university, I taught myself Scheme to do <a href="http://summerofcode.withgoogle.com/">GSoC</a> for <a href="https://guix.gnu.org/">GNU Guix</a>. Guile
quickly grew on me, and I soon began <a href="http://jakob.space/blog/transition-to-haunt.html">using Haunt</a> for my personal website. I've
been unknowingly using Emacs Lisp since much earlier ‚Äì not in the sense of
writing packages ‚Äì my old man taught me how to use Emacs when I was nine, but I
was <a href="https://www.gnu.org/software/emacs/manual/html_node/emacs/Easy-Customization.html">mostly shielded from having to write <code>setq</code> forms</a>. I've also used <a href="https://docs.hylang.org/en/stable/">Hy</a>, <a href="https://fennel-lang.org/">Fennel</a>,
‚Ä¶ well, I'm wildly off track now. Point being, I've used many Lisps, and I've
subconsciously acknowledged the differences between them, but never turned that
acknowledgment into coherent thought.
</p><p>
To aid in the comparison, I've written the same raytracer in several dialects of
Lisp. My reasons for choosing a raytracer are that:
</p><ul>
<li>I'm reasonably familiar with how they work.</li>
<li>Performance matters, and differences in performance is noticeable.</li>
<li>It's nontrivial, but several implementations of a raytracer is also more
tractable than, say, several implementations of a high-performance database.</li>
</ul><p>
Another consideration was the number of advancements in raytracing that build
upon the same basic structure, potentially giving me a way to compare the ease
with which a change to a system can be made, but writing these raytracers took
enough out of me that I didn't want to play with them any more.
</p><p>
This was not nearly as telling of a comparison as I had hoped. Once I'd
completed the first raytracer, everything that followed had the same structure.
Regardless, writing these raytracers gave me an idea of the characteristics I
was interested in, especially performance. For anyone who would like to look at
the code, the implementations are available <a href="https://git.sr.ht/~jakob/lisp-raytracer-zoo">here</a>.
</p><p>
<b>Table of Contents</b>
</p><ul>
<li><a href="#org9a5541d">The Issue of Rendering an Image</a></li>
<li><a href="#orga8f893b">Scheme</a>
<ul>
<li><a href="#org4538c39">R7RS</a></li>
<li><a href="#org47b9bd9">R6RS</a></li>
<li><a href="#org3eedb31">Conclusions on Scheme</a></li>
</ul></li>
<li><a href="#org9e27a4b">Common Lisp</a>
<ul>
<li><a href="#org0df9ac3">Conclusions on Common Lisp</a></li>
</ul></li>
<li><a href="#org4d7f824">Fennel</a>
<ul>
<li><a href="#org3eb9b83">Conclusions on Fennel</a></li>
</ul></li>
<li><a href="#org0fbbf7a">Lisps I've Neglected</a>
<ul>
<li><a href="#org1bb9256">Emacs Lisp</a></li>
<li><a href="#orga47743c">Gerbil Scheme</a></li>
<li><a href="#orgcca7e64">Racket</a></li>
<li><a href="#org883fd6d">Janet</a></li>
<li><a href="#org965e8ce">Clojure</a></li>
</ul></li>
</ul><div id="outline-container-org9a5541d">
<h2 id="org9a5541d">The Issue of Rendering an Image</h2>
<div id="text-org9a5541d">
<p>
Well, if we're writing a raytracer, then, we had better have some way of seeing
the results. The issue is portability. Ideally, I'd like to be able to run the
raytacers on different implementations of each language, but none of them have
standardized support for drawing graphics. An idea I had was to render the image
to the terminal using ANSI escape sequences, but I thought the resulting images
would be quite shitty. Instead, I decided to go the <a href="https://github.com/ssloy/tinyrenderer/wiki/Lesson-0-getting-started">route that tinyrenderer
takes</a>, which is to output to an image file. Initially, the image format I went
with was the venerable PNG. This was a mistake. Even if it did lead to a rather
elegant CRC procedure in Scheme.
</p>

<div>
<pre>(<span>define</span> (<span>chunk-crc</span> bytes)
  (<span>define</span> (<span>process-byte</span> crc byte)
    (bitwise-xor (vector-ref png-crc (bitwise-and #xff (bitwise-xor crc byte)))
                 (arithmetic-shift crc -8)))
  (reduce process-byte bytes #xffffffff))
</pre>
</div>

<p>
Realizing PNG was needlessly complex, I went on to write a <a href="https://git.sr.ht/~jakob/lisp-raytracer-zoo/tree/master/write-bmp.scm">BMP encoder</a>, which
was fine until I came across <a href="https://nullprogram.com/blog/2017/11/03/">an article</a> from Chris Wellons about rendering video
with C by encoding frames as <a href="http://netpbm.sourceforge.net/doc/">Netpbm</a> images. I decided to scrap my BMP encoder
and go with PPM instead. Netpbm is text-based: the issue with a PNG or BMP
encoder in Scheme, for example, is that you're dealing with a binary format.
Glancing over the standards now, it seems there are, indeed, standardized
procedures for dealing with binary data in both R6RS and R7RS. Regardless,
dealing with those binary structures and having to consider endianness is a
pain. PPM is <span>dead</span> simple. In fact, I'd wager that if all you had access to were
the examples on the <a href="https://en.wikipedia.org/wiki/Netpbm">Wikipedia</a> page, you'd be able to write an encoder. Here's
the Scheme implementation:
</p>

<div>
<pre>(<span>define</span> (<span>write-ppm</span> width height pixels)
  <span>"Encode the WIDTH by HEIGHT image given as PIXELS into the portable pixmap</span>
<span>format (PPM), writing the result to `(current-output-port)'."</span>
  (<span>define</span> (<span>delimit-values</span> values)
    (<span>cond</span> ((null? values)
           (newline))
          ((= 1 (length values))
           (display (car values))
           (delimit-values (cdr values)))
          (<span>else</span>
           (display (car values))
           (display <span>" "</span>)
           (delimit-values (cdr values)))))

  
  (delimit-values '(<span>"P3"</span>))

  
  (delimit-values (list width height))

  
  (delimit-values '(<span>"255"</span>))

  
  (<span>for-each</span> delimit-values (vector-&gt;list pixels)))
</pre>
</div>

<p>
If you do away with my nice formatting, that's twelve lines of code, all of
which are R5RS-compatible. We have access to the Netpbm suite, too, so if we
want a PNG, we can always <code>./write-ppm | pnmtopng &gt; test.png</code>. Netpbm is a
real hidden gem. Well, hidden to me, at least.
</p>
</div>
</div><div id="outline-container-orga8f893b">
<h2 id="orga8f893b">Scheme</h2>
<div id="text-orga8f893b">
<p>
If you aren't familiar with Scheme, it has somewhat of a self-imposed<sup><a id="fnr.2" href="#fn.2">2</a></sup>
reputation for appealing to academic types. It's also one of the most
opinionated languages I know of; all the specs of interest lead with an
assertion that "programming languages should be designed not by piling feature
on top of feature, but by removing the weaknesses and restrictions that make
additional features appear necessary." The way that Scheme embraces purity and
simplicity makes it clear it was designed by math nerds. (Hey, I'm a math nerd,
too. Take it easy.)
</p>

<p>
As I've just mentioned, there are specs. A few, to be sure. The evolution of
Scheme standards begins in a linear fashion: RRS ‚Üí RRRS ‚Üí R3RS ‚Üí R4RS ‚Üí R5RS. I
like to think of this as "classic Scheme". But when it came time to revise R5RS,
the ratification of the subsequent R6RS caused some controversy. It was
"bloated", or whatever. Something like that. So when it came time to design R7RS
(small), the Scheme Language Steering Committee decided to let the language
fork, beginning with the earlier R5RS as a blank slate [4]. That way, the nerds
that hated everything about R6RS could have their way, and the nerds that liked
R6RS could have their way. Scheme was divided, but at peace. Oh, and nowadays
there's a work-in-progress <a href="https://bitbucket.org/cowan/r7rs-wg1-infra/src/default/R7RSHomePage.md">R7RS-large</a>. ‡≤†_‡≤†
</p>

<p>
I'm not going to talk about R7RS-large here. It's just too ‚Ä¶</p></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://jakob.space/blog/thoughts-on-lisps.html">http://jakob.space/blog/thoughts-on-lisps.html</a></em></p>]]>
            </description>
            <link>http://jakob.space/blog/thoughts-on-lisps.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23900060</guid>
            <pubDate>Mon, 20 Jul 2020 17:35:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Siemens (140K+ employees) and 11 other large companies embrace remote-work]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23900003">thread link</a>) | @theknight
<br/>
July 20, 2020 | https://www.prospercircle.org/signals/remote-companies | <a href="https://web.archive.org/web/*/https://www.prospercircle.org/signals/remote-companies">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.prospercircle.org/signals/remote-companies</link>
            <guid isPermaLink="false">hacker-news-small-sites-23900003</guid>
            <pubDate>Mon, 20 Jul 2020 17:29:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bunkerpunk: Short Stories About Bunkers During the Pandemic]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23899998">thread link</a>) | @jamesjyu
<br/>
July 20, 2020 | https://sudowriters.com/anthology/bunkerpunk/ | <a href="https://web.archive.org/web/*/https://sudowriters.com/anthology/bunkerpunk/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  	<header>
  		<a href="https://sudowriters.com/"></a>
  		<a href="https://sudowriters.com/"><span><span>sudo</span>writers</span></a>
  		
  		<p>SUDOANTHOLOGY VOLUME TWO</p>
  		
  	</header>
  	
    <section id="intro">

  <p>The following stories were crafted in the dismal months of April, May and June, in the unfortunate year 2020. While the theme for this anthology, Bunkerpunk, was chosen in late March, the proceeding months saw real-life bunkers in the news as the world descended further into the persistent, low-grade chaos that has come to define our era. If you happen to be reading this from a bunker, we hope you‚Äôre well stocked on cola and emotionally prepared for an alien invasion. May these six works of fiction remain such, at least until you‚Äôve had the chance to finish reading them.</p>

  <p><em>Thea Boodhoo</em></p>

</section>







<section>
	<h2><a href="#indomitable-inc">Indomitable, Inc.</a> by Amit Gupta</h2>
	<p>5 min read ‚Ä¢ A bunker to stop the zombies becomes anything but.</p>
</section>

<section>
	<h2><a href="#cells">Cells</a> by Thea Boodhoo</h2>
	<p>1 min read ‚Ä¢ Do you wonder what your cells are doing today?</p>
</section>

<section>
	<h2><a href="#the-dead-do-not-live-underground">The Dead Do Not Live Underground</a> by James Yu</h2>
	<p>11 min read ‚Ä¢ A coroner and his drone investigate one more bunker.</p>
</section>

<section>
	<h2><a href="#contained">Contained</a> by Elizabeth Menozzi</h2>
	<p>7 min read ‚Ä¢&nbsp;The year can't get any worse, so it does.</p>
</section>

<section>
	<h2><a href="#the-secrets-of-facility-oscar-zero">The Secrets of Facility Oscar Zero</a> by Scott Hurff</h2>
	<p>6 min read ‚Ä¢ A girl shocks her parents when she discovers a long-forgotten chat protocol.</p>
</section>

<section>
	<h2><a href="#432-park-avenue">432 Park Avenue</a> by Sahil Lavingia</h2>
	<p>5 min read ‚Ä¢ A couple tries to find a way off their rooftop.</p>
</section>



<section id="indomitable-inc" data-author="Amit Gupta" data-title="Indomitable Inc.">
  <h3 id="indombitable-inc">Indombitable Inc.</h3>

  <div>
  <div>
  <p><img src="https://sudowriters.com/assets/amit.jpg"></p><h4>Amit Gupta</h4>
  <p>Amit is a science-fiction writer, optimist, and occasional advisor &amp; investor. More at <a href="http://amitgupta.com/">amitgupta.com</a> or <a href="https://www.twitter.com/superamit">@superamit</a>.</p>  
</div>

</div>

  <p>A month after Mohit moved, bankrupt and alone, into the underground bunker he built for 100, perimeter alarms echoed through the enormous structure for the first time. A lanky, dusty man popped up on the screens, torn-up backpack over one shoulder.</p>

  <p>Mohit pulled a baseball cap over his shaved head. He trotted through wide tunnels and up concrete stairs to the surface. Then he walked to the perimeter fencing, his body tense, his eyes glued to the lone figure. The man seemed unusually nonchalant, as if walking through the Mojave desert to a private compound miles from the closest city was something he did every day.</p>

  <p>‚ÄúThat laser wire up there?‚Äù the man asked, squinting up at the fence.</p>

  <p>‚ÄúIt is,‚Äù Mohit replied.</p>

  <p>The man observed Mohit for a minute, then asked, ‚Äúthis some kind of cult thing?‚Äù</p>

  <p>Mohit shook his head. He considered asking the man who he was, or turning and retreating underground, but found himself happy to be talking to anyone after a month alone. ‚ÄúIt‚Äôs just a safe place. Safe from disease, dust storms, war, everything we‚Äôve done to mess things up up here.‚Äù</p>

  <p>The man nodded thoughtfully, following the miles of laser wire and fencing with his eyes. Mohit waited. The air was dry, hot, and sharp. It felt dangerous, like if you inhaled it too quickly, you‚Äôd be rewarded with a nosebleed.</p>

  <p>‚ÄúWhat‚Äôs it like inside?‚Äù the man asked, clearly in no rush.</p>

  <p>‚ÄúKind of like a big hotel,‚Äù Mohit answered. ‚ÄúBut better! Loads of community spaces. Kitchens, movie rooms with great sound, meditation gardens‚Äì‚Äù</p>

  <p>‚ÄúMeditation gardens, huh?‚Äù</p>

  <p>Mohit shrugged and adjusted his pitch. ‚ÄúNice beds. Plenty of food, water, and medicine.‚Äù</p>

  <p>The man nodded, as if considering an unspoken offer. He looked past Mohit at the gray windowless edifice poking up through the sand. ‚ÄúThose walls‚Äìpretty thick‚Ä¶‚Äù</p>

  <p>‚ÄúA meter thick. Mesh-embedded concrete to block radio signals,‚Äù Mohit boasted.</p>

  <p>‚ÄúZombie-proof?‚Äù</p>

  <p>Mohit felt himself blushing. He‚Äôd given dozens of interviews since his disastrous appearance on CNBC to announce his project. The one where, in a moment of youthful exuberance, he joked that the walls were so thick, ‚Äúthey‚Äôd even keep the zombies out.‚Äù The host chuckled, glanced off-screen and pumped his eyebrows, then turned back with a false smile, his teeth bright and sharp. Right away, Mohit knew it was over.</p>

  <p>After that, nobody cared that he‚Äôd risked all of his then-considerable fortune to bury 500 bunkers miles outside Berlin, Brooklyn, Buenos Aires, Boise, Cork, Cape town and so many others. It no longer mattered that he‚Äôd designed anti-contamination vacuum gaps and positive air pressure between sections and incorporated medical-grade fabricators, self-contained water cycling and food production, and layouts modeled on anthropological studies of successful, peaceful communes.</p>

  <p>Onstage at TED, he‚Äôd declared, ‚Äúwhen our governments fail to take responsibility, we must rise to the challenge.‚Äù They applauded. But what spread were the SNL parodies and viral headlines: ‚Äú10 Reasons Why Even the Wealthiest Preppers Aren‚Äôt Willing to Waste Money on Indombitable‚Äôs Zombie-proof Bunker.‚Äù The world thought he was a joke.</p>

  <p>Now Mohit squirmed in utility coveralls damp with sweat, the space between his skin and the thick canvas like a sauna. He thought about how much cooler it was down below.</p>

  <p>‚ÄúSo no zombies, then?‚Äù the man asked.</p>

  <p>‚ÄúJust me.‚Äù</p>

  <p>A silence unfolded between the men standing on opposite sides of the fence. Each considered the other, the choices made to bring them there, and the options that lay before them. The man with the backpack shifted his weight from one foot to the other, then asked, ‚Äúwhat do you got to eat? I‚Äôm Henry, by the way.‚Äù</p>

  <hr>

  <p>They came alone, then in small clumps. There were homeless men fleeing overcrowded shelters, mothers and fathers with arms full of children and eyes full of fear, trying to outrun the latest outbreak.</p>

  <p>Mohit showed each one around and welcomed them to the community. Henry developed strict quarantine procedures. A UCLA microbiologist, he‚Äôd been scorned for sounding the alarm on the rising viral threat and all but ostracized by the scientific community.</p>

  <p>As the geneticists and pharma corps fell a year behind, then two, then ten‚Ä¶as the mutation rate increased and new viruses tore through cities‚Ä¶as politicians implored people to go about their lives while they built shelters for themselves, the people kept coming.</p>

  <p>Then came the calls from would-be buyers from all over the world, offering vast sums for Mohit‚Äôs bunkers. Amounts that would have saved his company and reputation, if only they‚Äôd come a few months before. Mohit unlocked all the doors instead. What good was money when the world was on fire?</p>

  <p>A few years later, the bunkers filled and sealed shut. Decades passed. New waves of illness, climate catastrophe, and so many deaths.</p>

  <p>Outside, parking lots gave way to forest. Robins and sparrows nested in office drop ceilings, while small mammals took up grocery store shelves. Cities went wild once again.</p>

  <p>Inside, they maintained the hydroponic farms, tended to the sick, cooked together, sang together. Mohit‚Äôs empty concrete shells rang with life. He met his wife in the bunkers. Their sons were born here, raised here.</p>

  <hr>

  <p>‚ÄúShhhhh, wake up, Mohit,‚Äù Sandra said, ruffling her husband‚Äôs hair as he leaned against their bedroom doorway, tracing the notches etched into its frame with his fingertips.</p>

  <p>‚ÄúCouldn‚Äôt sleep at all last night,‚Äù he said.</p>

  <p>She smiled, slipping an arm around his waist and leaning her head into his shoulder. ‚ÄúI couldn‚Äôt either. Thirty years. It doesn‚Äôt seem real.‚Äù</p>

  <p>They pressed against each other, lost in thought. All through the structure, people murmured excitedly. Viral transmission had fallen for 100 days straight and airborne contaminants were back to normal levels. Today the next phase would begin. One Mohit had never imagined when he‚Äôd created this place. The community had voted, and they‚Äôd decided to emerge.</p>

  <p>‚ÄúI wish we didn‚Äôt have to leave those behind,‚Äù she said, nodding at the notches in the door frame. ‚ÄúI don‚Äôt want to forget that Munu and Sam were once that little.‚Äù</p>

  <p>‚ÄúI traced them onto paper,‚Äù he said. ‚ÄúWe can recreate them above.‚Äù</p>

  <p>Their sons met them outside their door, their faces set in wide grins. No longer children, but nervous and jittery just the same.</p>

  <p>Mohit‚Äôs heart swelled. This place had taken everything from him and given everything to him. He thought he‚Äôd earned his vindication when the bunkers filled. But he‚Äôd been wrong. This moment, when their faces met the sun and their feet felt the earth once more, when their sons would see the sky with their eyes for the first time. When they‚Äôd have a chance, along with whoever was left, to try again. This was the reason he had built them all.</p>

  <p>As the crowd moved up towards the vivid colors of rock and cactus, and into the startling warmth of the early morning sun, Munu nudged him.</p>

  <p>‚ÄúDad,‚Äù he said. ‚ÄúYou know how we buried ourselves underground, and now we‚Äôre slowly rising to live again?‚Äù</p>

  <p>‚ÄúYes,‚Äù Mohit replied.</p>

  <p>‚ÄúSo we‚Äôre basically zombies, right?‚Äù</p>

  <p>Mohit smirked, nodding. Perhaps he‚Äôd just gotten it backwards. The bunkers hadn‚Äôt kept the zombies out, they‚Äôd kept them in.</p>

</section>



<section id="cells" data-author="Thea Boodhoo" data-title="Cells">
  <h3 id="cells">Cells</h3>

  <div>
	<div>
  <p><img src="https://sudowriters.com/assets/thea.jpg"></p><h4>Thea Boodhoo</h4>

  <p>Thea is a San Francisco based writer of science fiction and other things. You can find her at <a href="https://theaboodhoo.com/">theaboodhoo.com</a> and <a href="https://www.twitter.com/tharkibo">@tharkibo</a>.</p>
</div>
</div>

  <p>I wonder what my cells are doing today.<br>
As I putter from the first room to the second room and back<br>
As I brush my teeth. Did I just brush my teeth?<br>
Nope<br>
It feels like five minutes ago <br>
But it was last night.<br>
I wonder what my cells are doing as I lean into the glass<br>
Skin of my cheek pressed against the cold clear barrier <br>
between the shut-down world and the shut-in<br>
There are seagulls flying out there <br>
As if nothing‚Äôs changed<br>
I wonder what my cells are doing as I flip the calendar another month<br>
It‚Äôs been three years now<br>
No five<br>
No wait<br>
a thousand<br></p>

  <p>Since the choice<br></p>

  <p>We thought we were so informed <br>
The doctors and I<br>
Bake the breast with X-rays<br>
Keep the appointments<br>
Every six months <br>
An MRI here<br>
A mammogram there<br>
And you can keep the cells.<br>
Well I would have<br>
But no one told the appointments to keep me<br>
And now there are none<br></p>

  <p>I kind of thought 2025 would be better<br></p>

  <p>What are those cells up to now?<br>
Cooking ATP<br>
Weaving DNA<br>
Staying put, behaving<br>
Being good neighbors <br>
Good cells do what they‚Äôre told<br>
Just be breast tissue<br>
Nothing more<br>
No need for ambition ‚Ä¶</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sudowriters.com/anthology/bunkerpunk/">https://sudowriters.com/anthology/bunkerpunk/</a></em></p>]]>
            </description>
            <link>https://sudowriters.com/anthology/bunkerpunk/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23899998</guid>
            <pubDate>Mon, 20 Jul 2020 17:28:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Probabilistic Buy vs. Rent Calculator]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23899691">thread link</a>) | @refrigerator
<br/>
July 20, 2020 | https://my.causal.app/models/8220 | <a href="https://web.archive.org/web/*/https://my.causal.app/models/8220">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://my.causal.app/models/8220</link>
            <guid isPermaLink="false">hacker-news-small-sites-23899691</guid>
            <pubDate>Mon, 20 Jul 2020 16:59:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[31 Books Like Ready Player One]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 6 (<a href="https://news.ycombinator.com/item?id=23899649">thread link</a>) | @vhpoet
<br/>
July 20, 2020 | https://readthistwice.com/books-like/ready-player-one | <a href="https://web.archive.org/web/*/https://readthistwice.com/books-like/ready-player-one">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://readthistwice.com/books-like/ready-player-one</link>
            <guid isPermaLink="false">hacker-news-small-sites-23899649</guid>
            <pubDate>Mon, 20 Jul 2020 16:55:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Smart Tile Grids: Optimizing FlightAware's Maps for Non-Uniform Geographic Data]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23899376">thread link</a>) | @rainingdeerbox
<br/>
July 20, 2020 | https://flightaware.engineering/smart-tile-grids-optimizing-flightawares-maps-for-the-display-of-non-uniform-geographical-data/ | <a href="https://web.archive.org/web/*/https://flightaware.engineering/smart-tile-grids-optimizing-flightawares-maps-for-the-display-of-non-uniform-geographical-data/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<!--kg-card-begin: html--><p>‚Äç<em>Philip Clifton is a Senior Software Engineer 2 and Team Lead, responsible for guiding the overall implementation of Web technologies at FlightAware.</em></p><p>For many users of FlightAware, one of the most visible and visual experiences on the website are the maps, depicting flight data in various forms‚Äîindividual flights, traffic to/from airports, and airline fleets. Perhaps the most visible application, however, is the FlightAware <a href="https://flightaware.com/">live map</a>‚Äîa product that attempts to depict all en route aircraft around the world. Making this map function presents significant challenges‚Äîthere can be upwards of 10,000 aircraft en route at any given time, and that‚Äôs a <em>lot</em> of data to fetch, process, transport to the client browser, and render. Each of these steps needs to work promptly and efficiently‚Äîafter all, even the most compelling map depiction will lose some of its impact if users must wait 10+ seconds for the depiction to actually load! </p><h2><strong>Web maps and tiling</strong> </h2><p>Before we get into the meat of these challenges, we‚Äôll briefly discuss some mapping concepts. Web-based map products are ubiquitous these days thanks to tools like Google Maps, and with their popularity has come plenty of standardization in how maps work. Particularly pertinent to this discussion is how maps use <em>tiles</em> to provide a solid user experience. </p><p>When we talk about ‚Äútiles,‚Äù what we‚Äôre really talking about is breaking up data or imagery for a map into small, bite-sized chunks. Let‚Äôs use FlightAware‚Äôs classic blue base layer as an example. While we certainly have the ability to render all the content as a single large image, in practice we break this up into individual smaller images. By doing this, when a user is looking at a small subset of the globe, we can load only the tiles needed for what‚Äôs visible in the map viewport. This, in turn, saves unnecessary work and data transport‚Äîthat is, loading imagery that the user cannot view. </p><p>For most cases where we use tiles on FlightAware maps, we use a three-dimensional coordinate system, which identifies tiles based on their geographical location (X/Y coordinates, corresponding to longitude and latitude) and their zoom level (a Z ‚Äúcoordinate‚Äù). The third zoom dimension is important, as it allows us to tailor what‚Äôs depicted on a tile to the current zoom level. When a user zooms in closely on an area, we want to show lots of detail‚Äîminor roads, airport runways, etc.‚Äîbut if that same user zooms out to look at the entire US, then depicting every minor road and runway at that level would seriously clutter the map! </p><p>There is, however, a pertinent consequence of this three-dimensional system: the number of possible XYZ combinations grows at an astonishing rate. Each time we increase the zoom level by a whole number, we double the scale of the map. That is, if a distance of one mile took up ten pixels on screen, at the next zoom level it would take up twenty. The consequence of this is that given any viewport size, increasing the zoom by one means we <em>decrease</em> the geographical area depicted in that viewport by a factor of four. </p><p>Meanwhile, every tile image is always a constant pixel size, so by extension, a single tile also covers only ¬º the geographical area of the next-lower zoom level. As a result, each time we increase the zoom level by one whole number, we require four times as many tiles to represent the entire world. Extrapolating this over a typical range of zoom levels, say, 1-20, there are potentially <em>billions</em> of possible tiles. </p><p><em>More info on this XYZ tiling strategy is available at the </em><a href="https://wiki.openstreetmap.org/wiki/Slippy_map_tilenames"><em>OpenStreetMap Wiki</em></a><em>.</em> </p><h2><strong>Types of tile data</strong> </h2><p>Now that we‚Äôve talked about tiling strategies, let‚Äôs move on to discussing what sorts of data we can provide in these tiles. Much like image files, tiles take two general forms: <em>raster</em> and <em>vector</em>. The delineation between the two can be thought of in terms of the point at which raw geographical data is transformed into something that‚Äôs (hopefully) visually pleasing to the end user. </p><p>Raster tiles are rendered server-side into common image formats: JPG, PNG, etc. The tiles are shipped down to the browser like any other image, where the in-browser mapping software places it in its proper place alongside other tiles. </p><p>Vector tiles, however, are passed to the browser as simple raw data in a format such as <a href="https://en.wikipedia.org/wiki/GeoJSON">GeoJSON</a>. The mapping software is then responsible for creating a visualization of this data, placing the features described by the data in the proper place on the map, and using styling rules to control the appearance of the features. </p><p>Examples of both of these types of tiles can be seen when examining the FlightAware live map. The classic blue base layer tiles are raster images, while the aircraft are depicted as vector features. Essentially, the client receives a very long list of points (the location of each aircraft) along with other metadata that‚Äôs used to decide how to depict the aircraft. The aircraft type (e.g. Boeing 737) determines what icon is used, the aircraft‚Äôs current heading determines where it‚Äôs pointed, and other flight data such as altitude and groundspeed are used to display an informational block adjacent to an aircraft icon on a map. </p><h2>Putting it into practice: vector data for the live map (the ‚Äúold‚Äù way) </h2><p>When the live map was first conceptualized, the approach taken to fetching data was straightforward: client-side maps were configured with a vector layer (that is, a layer populated with vector features), which utilized the XYZ tiling scheme outlined previously. Retrieval of the data was handled by an AJAX endpoint, which accepted the XYZ coordinates as parameters. Logic in this endpoint was responsible for transforming these coordinates into a latitude/longitude bounding box, representing the geographical bounds of the tile, which was in turn used to retrieve all current aircraft positions within that box. </p><p>A major advantage of this approach is that it‚Äôs straightforward to implement. OpenLayers, the client-side map library we use, provides very robust built-in classes for making such requests; as such, client-side code was simple (essentially reduced to the level of configuration), and server-side code was similarly straightforward. Put simply, this approach was easy to put into practice‚Äîand it worked. </p><p>However, there are some definite drawbacks to this approach. As we‚Äôve already outlined, the nature of XYZ tile coordinate systems is that there is an entirely unique set of tiles for each zoom level, and this zoom-level specificity can be useful for providing different levels of data detail at different zoom levels. In this case, we weren‚Äôt leveraging that specificity potential at all‚Äîevery tile request simply amounted to ‚Äúreturn all the aircraft in this rectangular region.‚Äù </p><p>As a result, we were quite literally doing redundant work. Imagine if a user allowed all aircraft to load at, say, zoom level 3, and then zoomed the map in. Since this means the new map viewport is a smaller geographical area than before, and since we already loaded all known aircraft in that larger geographical area, the client already has all the data required to display after zooming‚Äîbut the tiling implementation dictated that all aircraft on the map be reloaded from a blank slate! </p><p>Still, it worked, and provided a great showcase product for FlightAware for many years‚Äîuntil increases in position data began to turn shortcomings into actual problems. </p><h2><strong>Performance issues surface</strong> </h2><p>For the final piece of the performance puzzle, let‚Äôs briefly discuss how FlightAware stores and retrieves positions and tracks for flights. While we use PostgreSQL as our primary relational database engine, the sheer volume of positional data we receive makes storing this data in Postgres untenable. Instead, we use a separate storage system for en route flights, allowing for much better update and retrieval performance. The first iteration of this system was <em>birdseye</em>‚Äîan in-memory position database built on top of <a href="https://github.com/flightaware/speedtables"><em>Speedtables</em></a>. Birdseye served us well for many years until 2018 when it was replaced with <em>popeye</em>, which used SQLite as its underpinnings rather than Speedtables.</p><p>Both of these share a similar performance concern, though this concern was much more prevalent with birdseye. Specifically, for the bounding-box search use case, the amount of time needed to retrieve a set of positions is roughly proportional to the number of matching positions found in the result set. For example, a bounding box containing 1,000 aircraft positions would take approximately ten times as long to fetch as a box containing 100 positions. </p><p>One might be tempted to think that this problem would only apply to boxes (aka tiles) of vastly different sizes, but that‚Äôs not the case. After all, en route aircraft aren‚Äôt evenly distributed around the globe by any stretch of the imagination. To illustrate this, let‚Äôs look at an exemplar live map, overlaid with the applicable XYZ tile grid: </p><figure id="w-node-40dd31ca13df-ee8f12ee"><p><img src="https://assets.website-files.com/5e8ca9724a691dab28971e3f/5ecdb025d37e264523519790_hoV3aNpnoGA8gqFd2IYWj2tpo4zlPnFx9h0i8_GbPgjJDSERab9JwNPhg0bLmKOcZfhQDwVjRNa5Wb77U31TfcZmFIWhV25Onm7g4KiWRBLnT84dzpQPz2N7vMEc0cL5n3bWTbw6.png" alt=""></p></figure><p> Now, imagine loading the North and South Atlantic Ocean tiles (2,1,-2 and 2,1,-3 respectively) in a map client. The South Atlantic tile loads in less than a second, while North American tiles could take several seconds. The result, to the end user, looks somewhere between not great and outright broken. It‚Äôs certainly a bad look for a flagship visualization of our flight data. </p><p>A traditional way to reduce the impact of this discrepancy would be via strategic caching, but here our choice of tile grid becomes problematic again: as we discussed, there are potentially <em>billions</em> of distinct tiles, which means the chances that any particular tile is cached at any particular time is slim. There‚Äôs far too much variance in possible tiles for caching to be effective. </p><h2><strong>Moving forward</strong> </h2><p>We‚Äôve now seen the state of the live map as of a few years ago: slow, patchy loads on the client, redundant calls to data endpoints putting unnecessary extra load on our services, and mostly-ineffective caching. Clearly, this was a situation that called for a new solution, and the direction in which we decided to go involved ‚Ä¶</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://flightaware.engineering/smart-tile-grids-optimizing-flightawares-maps-for-the-display-of-non-uniform-geographical-data/">https://flightaware.engineering/smart-tile-grids-optimizing-flightawares-maps-for-the-display-of-non-uniform-geographical-data/</a></em></p>]]>
            </description>
            <link>https://flightaware.engineering/smart-tile-grids-optimizing-flightawares-maps-for-the-display-of-non-uniform-geographical-data/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23899376</guid>
            <pubDate>Mon, 20 Jul 2020 16:27:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pandas: My Cheatsheet]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23899351">thread link</a>) | @lowmemcpu
<br/>
July 20, 2020 | https://leportella.com/cheatsheet-pandas.html | <a href="https://web.archive.org/web/*/https://leportella.com/cheatsheet-pandas.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody"><p>Sometimes I get just really lost with all available commands and tricks one can make on pandas. This way, I really wanted a place to gather my tricks that I really don‚Äôt want to forget.</p><center> <img src="https://media.giphy.com/media/EwO9pwLnPlttu/giphy.gif"> </center><p>&lt;/br&gt;</p><h2 id="general-helps">General helps</h2><ul><li><a href="#multiple-filters">How to make multiple filters</a></li><li><a href="#encoding">read_csv errors of encoding</a></li></ul><h2 id="dataframe-functions">Dataframe functions</h2><ul><li><a href="#column-names">How to list available columns on a DataFrame</a></li><li><a href="#iterate">How to iterate over a DataFrame</a></li><li><a href="#save-by-chunks">How to save a DataFrame by chunks</a></li><li><a href="#group-by-example">A groupby example</a></li><li><a href="#apply-get-dummies">How to prepare my DataFrame to apply get_dummies?</a></li><li><a href="#sum-values">Sum values of all columns</a></li><li><a href="#apply-multiple-columns">Use apply for multiple columns</a></li></ul><h2 id="series-functions">Series functions</h2><ul><li><a href="#unique-ocurrences">How to count the ocurrences of each unique values on a Series</a></li><li><a href="#missing-months">How to fill values on missing months</a></li><li><a href="#filter-elements-by-list">How to filter column elements by multiple elements contained on a list</a></li><li><a href="#change-series-type">How to change a Series type?</a></li><li><a href="#apply-function">How to apply a function to every item of my Serie?</a></li></ul><h2 id="column-names">How to list available columns on a DataFrame</h2><h2 id="multiple-filters">How to make multiple filters</h2><div><div><pre><code><span>df</span><span>[(</span><span>df</span><span>.</span><span>column</span> <span>&gt;</span> <span>value1</span><span>)</span> <span>&amp;</span> <span>(</span><span>df</span><span>.</span><span>column</span> <span>&lt;</span> <span>value2</span><span>)]</span>
</code></pre></div></div><h2 id="iterate">How to iterate over a Dataframe</h2><div><div><pre><code><span>for</span> <span>item</span><span>,</span> <span>row</span> <span>in</span> <span>df</span><span>.</span><span>iterrows</span><span>():</span>
  <span>print</span> <span>row</span><span>()</span>
</code></pre></div></div><h2 id="unique-ocurrences">How to count the ocurrences of each unique values on a Series</h2><div><div><pre><code><span>df</span><span>[</span><span>column</span><span>].</span><span>value_counts</span><span>()</span>

<span># get indexes
</span><span>df</span><span>[</span><span>column</span><span>].</span><span>value_counts</span><span>().</span><span>index</span><span>.</span><span>tolist</span><span>()</span>

<span># get values of occurrences
</span><span>df</span><span>[</span><span>column</span><span>].</span><span>value_counts</span><span>().</span><span>values</span><span>.</span><span>tolist</span><span>()</span>
</code></pre></div></div><h2 id="save-by-chunks">How to save a DataFrame by chunks</h2><div><div><pre><code><span>df</span> <span>=</span> <span>pd</span><span>.</span><span>DataFrame</span><span>([[</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>2</span><span>],</span> <span>[</span><span>3</span><span>,</span> <span>4</span><span>,</span> <span>5</span><span>],</span> <span>[</span><span>6</span><span>,</span> <span>7</span><span>,</span> <span>8</span><span>],</span> <span>[</span><span>9</span><span>,</span> <span>10</span><span>,</span> <span>11</span><span>]])</span>

<span>df1</span> <span>=</span> <span>df</span><span>.</span><span>iloc</span><span>[</span><span>0</span><span>:</span><span>2</span><span>,:]</span>
<span>df2</span><span>=</span> <span>df</span><span>.</span><span>iloc</span><span>[</span><span>2</span><span>:,:]</span>

<span>df1</span><span>.</span><span>to_csv</span><span>(</span><span>'./teste1.csv'</span><span>,</span> <span>index</span><span>=</span><span>False</span><span>,</span> <span>header</span><span>=</span><span>False</span><span>)</span>
<span>df2</span><span>.</span><span>to_csv</span><span>(</span><span>'./teste1.csv'</span><span>,</span> <span>index</span><span>=</span><span>False</span><span>,</span> <span>header</span><span>=</span><span>False</span><span>,</span> <span>mode</span><span>=</span><span>'a'</span><span>)</span>

<span>df_final</span> <span>=</span> <span>pd</span><span>.</span><span>read_csv</span><span>(</span><span>'./teste1.csv'</span><span>)</span>
<span>df_final</span><span>.</span><span>head</span><span>()</span>
</code></pre></div></div><h2 id="group-by-example">A groupby example</h2><div><div><pre><code><span>df_grouped</span> <span>=</span> <span>df</span><span>.</span><span>groupby</span><span>(</span>
        <span>by</span><span>=</span><span>[</span><span>'first_column'</span><span>,</span> <span>'second_column'</span><span>]</span>
    <span>)[</span><span>'third_column'</span><span>].</span><span>mean</span><span>().</span><span>reset_index</span><span>(</span><span>name</span><span>=</span><span>'mean_values_grouped'</span><span>)</span>
</code></pre></div></div><h2 id="missing-months">How to fill values on missing months</h2><p>If you have a dataframe with 2 columns: year and month. But data is not available for all months, so you need to enter missing months on your dataframe with empty values on them.</p><div><div><pre><code><span># Original data with months not available
</span><span>df1</span> <span>=</span> <span>pd</span><span>.</span><span>DataFrame</span><span>({</span>
    <span>'month'</span><span>:</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>4</span><span>,</span> <span>5</span><span>,</span> <span>6</span><span>,</span> <span>8</span><span>,</span> <span>9</span><span>,</span> <span>10</span><span>,</span> <span>11</span><span>,</span> <span>12</span><span>,</span> <span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>,</span>
              <span>5</span><span>,</span> <span>8</span><span>,</span> <span>9</span><span>,</span> <span>10</span><span>,</span> <span>11</span><span>,</span> <span>12</span><span>],</span>
    <span>'year'</span><span>:</span> <span>[</span><span>2011</span><span>,</span> <span>2011</span><span>,</span> <span>2011</span><span>,</span> <span>2011</span><span>,</span> <span>2011</span><span>,</span> <span>2011</span><span>,</span> <span>2011</span><span>,</span> <span>2011</span><span>,</span>
             <span>2011</span><span>,</span> <span>2011</span><span>,</span> <span>2012</span><span>,</span> <span>2012</span><span>,</span> <span>2012</span><span>,</span> <span>2012</span><span>,</span> <span>2012</span><span>,</span> <span>2012</span><span>,</span> 
             <span>2012</span><span>,</span> <span>2012</span><span>,</span> <span>2012</span><span>,</span> <span>2012</span><span>],</span>
    <span>'qty'</span><span>:</span> <span>[</span><span>5</span><span>,</span> <span>7</span><span>,</span> <span>3</span><span>,</span> <span>6</span><span>,</span> <span>7</span><span>,</span> <span>8</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>,</span> <span>7</span><span>,</span> <span>10</span><span>,</span> <span>12</span><span>,</span>
            <span>5</span><span>,</span> <span>7</span><span>,</span> <span>8</span><span>,</span> <span>1</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>,</span> <span>7</span><span>,</span> <span>8</span><span>,</span> <span>20</span><span>]</span>
<span>})</span>

<span># List of all months
</span><span>df2</span> <span>=</span> <span>pd</span><span>.</span><span>DataFrame</span><span>({</span><span>'month'</span><span>:</span> <span>list</span><span>(</span><span>range</span><span>(</span><span>1</span><span>,</span><span>13</span><span>))})</span>
</code></pre></div></div><p>Now we create an empty dataframe with all available years and months:</p><div><div><pre><code><span>from</span> <span>itertools</span> <span>import</span> <span>product</span>

<span>years_months</span> <span>=</span> <span>pd</span><span>.</span><span>DataFrame</span><span>(</span><span>list</span><span>(</span><span>product</span><span>(</span><span>np</span><span>.</span><span>unique</span><span>(</span><span>df2</span><span>.</span><span>month</span><span>),</span> <span>np</span><span>.</span><span>unique</span><span>(</span><span>df1</span><span>.</span><span>year</span><span>))),</span> <span>columns</span><span>=</span><span>[</span><span>'month'</span><span>,</span> <span>'year'</span><span>])</span>
</code></pre></div></div><p>Now we can just merge both dataframes with an outer join:</p><div><div><pre><code><span>pd</span><span>.</span><span>merge</span><span>(</span><span>years_months</span><span>,</span> <span>df1</span><span>,</span> <span>how</span><span>=</span><span>'outer'</span><span>)</span>
</code></pre></div></div><h2 id="filter-elements-by-list">How to filter column elements by multiple elements contained on a list</h2><h2 id="change-series-type">How to change a Series type?</h2><div><div><pre><code><span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>

<span>serie</span> <span>=</span> <span>pd</span><span>.</span><span>Series</span><span>([</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>])</span>
<span>series</span><span>.</span><span>astype</span><span>(</span><span>float</span><span>)</span>
</code></pre></div></div><h2 id="apply-function">How to apply a function to every item of my Serie?</h2><div><div><pre><code><span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>

<span>serie</span> <span>=</span> <span>pd</span><span>.</span><span>Series</span><span>([</span><span>'a'</span><span>,</span> <span>'b'</span><span>,</span> <span>'b'</span><span>,</span> <span>'a'</span><span>])</span>
<span>series</span><span>.</span><span>apply</span><span>(</span><span>lambda</span> <span>x</span><span>:</span> <span>0</span> <span>if</span> <span>x</span><span>==</span><span>'a'</span> <span>else</span> <span>1</span><span>)</span>
</code></pre></div></div><h2 id="aplly-get-dummies">How to prepare my DataFrame to apply get_dummies?</h2><div><div><pre><code><span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>

<span>X</span> <span>=</span> <span>pd</span><span>.</span><span>read_csv</span><span>(..)</span>
<span>categorical</span> <span>=</span> <span>[</span><span>'x1'</span><span>,</span> <span>'x2'</span><span>,</span> <span>'x4'</span><span>]</span>  <span># columns that have categorical features in your X
</span>
<span>for</span> <span>cat</span> <span>in</span> <span>categorical</span><span>:</span> 
    <span>X</span><span>[</span><span>cat</span><span>]</span> <span>=</span> <span>X</span><span>[</span><span>cat</span><span>].</span><span>astype</span><span>(</span><span>object</span><span>)</span>

<span>X_dummy</span> <span>=</span> <span>pd</span><span>.</span><span>get_dummies</span><span>(</span><span>X</span><span>)</span>
</code></pre></div></div><h2 id="encoding">read_csv errors of encoding</h2><p>Usually you can read a csv just by doing something like:</p><p>Sometimes, an encoding error appears. The first option is to pass ‚Äòutf8‚Äô as a value of the parameter <code>encoding</code>.</p><div><div><pre><code><span>pd</span><span>.</span><span>read_csv</span><span>(</span><span>'file.csv'</span><span>,</span> <span>encoding</span><span>=</span><span>'utf8'</span><span>)</span>
</code></pre></div></div><p>But there are some cases where this is not enough and the following error keeps appearing:</p><p><code>UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc7 in position 4: invalid continuation byte</code></p><p>The only thing that could resolve this was:</p><div><div><pre><code><span>pd</span><span>.</span><span>read_csv</span><span>(</span><span>'file.csv'</span><span>,</span> <span>encoding</span><span>=</span><span>'latin-1'</span><span>)</span>
</code></pre></div></div><h2 id="sum-values">Sum values of all columns</h2><h2 id="apply-multiple-columns">Use apply for multiple columns</h2><div><div><pre><code><span>def</span> <span>my_function</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>):</span>
  <span>return</span> <span>a</span> <span>+</span> <span>b</span>


<span>df</span><span>.</span><span>apply</span><span>(</span><span>lambda</span> <span>row</span><span>:</span> <span>my_function</span><span>(</span><span>row</span><span>[</span><span>'a'</span><span>],</span> <span>row</span><span>[</span><span>'b'</span><span>]),</span> <span>axis</span><span>=</span><span>1</span><span>)</span>
</code></pre></div></div></article></div>]]>
            </description>
            <link>https://leportella.com/cheatsheet-pandas.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23899351</guid>
            <pubDate>Mon, 20 Jul 2020 16:25:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Serfs of Facebook]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23899153">thread link</a>) | @fossuser
<br/>
July 20, 2020 | https://zalberico.com/essay/2020/07/14/the-serfs-of-facebook.html | <a href="https://web.archive.org/web/*/https://zalberico.com/essay/2020/07/14/the-serfs-of-facebook.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">
  
  <div itemprop="articleBody">
    <p>Most days Jonathan woke up and carried out his simple monastic routine of self-study and meditation, but today was different. Today Prior Philip would take him into the city.</p>

<p>While most of the monks had grown weary of the city before joining the monastery, Jonathan had lived with the monks as long as he could remember. Prior Philip had found him as an abandoned newborn in the forest, just off the road that led into the monastery. He brought the infant to the church, convinced that there was a plan for him and that it was the monks√¢‚Ç¨‚Ñ¢ duty to raise him as their own.</p>

<p>Now eighteen years later Jonathan was looking forward to leaving the small village for the first time.</p>

<p>Jonathan had donned his monastic robes and was ready when Prior Philip came to get him. It was a relatively short distance to the city walls by horseback and they would be there within the day.</p>

<p>√¢‚Ç¨≈ìWhat do you expect to see?√¢‚Ç¨ÔøΩ Philip asked him as they began the journey.</p>

<p>√¢‚Ç¨≈ìI really don√¢‚Ç¨‚Ñ¢t know, I think I√¢‚Ç¨‚Ñ¢d rather wait than attempt to guess.√¢‚Ç¨ÔøΩ</p>

<p>Jonathan thought of the stories he had read, tales of castles and princesses, kings, earls, and conquest. He imagined that some of these things must be true, but didn√¢‚Ç¨‚Ñ¢t want to speculate.</p>

<p>He was not prepared for what he saw.</p>

<p>As they approached the city they could see enormous walls surrounding it. Jonathan noticed a guard standing near the entrance to the city. The guard was shouting, √¢‚Ç¨≈ìSign Up! Sign Up! Sign Up!√¢‚Ç¨ÔøΩ and then more quietly, √¢‚Ç¨≈ìor Log In.√¢‚Ç¨ÔøΩ Philip approached and there was some quiet communication with the guard, then Jonathan walked up and was asked to fill out some documents. Shortly after, Jonathan and Philip walked in together. Once inside the city walls Jonathan saw people extending to the horizon in every direction, men, women, and children. All of them were working tirelessly on small plots of land.</p>

<p>√¢‚Ç¨≈ìThere must be millions of them.√¢‚Ç¨ÔøΩ</p>

<p>Philip looked at Jonathan. √¢‚Ç¨≈ìBillions.√¢‚Ç¨ÔøΩ</p>

<p>They approached one of the small plots and Jonathan looked more closely at the serfs working the data fields. One man was tending to multiple plots simultaneously: Jonathan saw him watering a beautiful garden of tweets, and then pruning a leafy Facebook post. At the same time he noticed the knights nearby also staring at the man.</p>

<p><img src="https://zalberico.com/assets/serfs_farm.jpeg" alt="Jonathan and Philip at the Serf's Farm"></p>

<p>He looked at Philip and asked, √¢‚Ç¨≈ìWho are they?√¢‚Ç¨ÔøΩ nodding in the direction of the knights.</p>

<p>√¢‚Ç¨≈ìThose are the knights of Earls Zuckerberg and Dorsey. They are expert farmers employed by the earls. They watch all of the serfs and collect clippings of all of their work on the data fields to bring to the Earl√¢‚Ç¨‚Ñ¢s castle.√¢‚Ç¨ÔøΩ</p>

<p>At that moment a small man with a determined expression walked up to the serfs√¢‚Ç¨‚Ñ¢ fields with a scroll of parchment. He unrolled it and began shouting at the serfs.</p>

<p>√¢‚Ç¨≈ìThe herald of the Earl reminds you that the local baker has delicious bread on sale now!√¢‚Ç¨ÔøΩ</p>

<p>√¢‚Ç¨≈ìAre you interested in Triplebyte? You could become a knight and change your life!√¢‚Ç¨ÔøΩ</p>

<p>√¢‚Ç¨≈ìOur mighty king reminds you he is the greatest king we√¢‚Ç¨‚Ñ¢ve ever had!√¢‚Ç¨ÔøΩ</p>

<p>Jonathan was waiting for the herald to stop with his pronouncements so he could speak again, but the herald continued.</p>

<p>√¢‚Ç¨≈ìMeet single serfs in your relative location!√¢‚Ç¨ÔøΩ</p>

<p>Jonathan looked at Philip and decided to try to just ignore the herald.</p>

<p>Philip had been watching Jonathan take it all in - he wanted him to see it for himself without any context for the first time. He led Jonathan away from the herald√¢‚Ç¨‚Ñ¢s shouting so they could speak more easily.</p>

<p>Philip looked at Jonathan, √¢‚Ç¨≈ìThere was a time long ago when there were no earls, or heralds, when the data fields were worked by skilled farmers and craftsmen. What they built was their own.√¢‚Ç¨ÔøΩ</p>

<p>√¢‚Ç¨≈ìWhat happened?√¢‚Ç¨ÔøΩ</p>

<p>√¢‚Ç¨≈ìIn those days it was difficult to prepare a field for data farming. It required a dedicated farmer interested in the art of farming itself. There was more creativity, but there were also fewer people and fewer farms. It was then that some enterprising young farmers hatched a plan. They realized that if they did the hard work of preparing the fields they could get everyone to farm, not just the experts. They cultivated enormous swaths of land and gave it away to the serfs in exchange for clippings of what they grow on their data farms as well as requiring them to hear the herald√¢‚Ç¨‚Ñ¢s pronouncements.√¢‚Ç¨ÔøΩ</p>

<p>Jonathan thought about this for a while.</p>

<p>√¢‚Ç¨≈ìThat sounds like a good thing? Many serfs had no farms at all and now they all have at least one. They all can participate in growing their own beautiful data and they only need to share clippings of it with the Earl and listen to some announcements - that seems fair to me.√¢‚Ç¨ÔøΩ</p>

<p>√¢‚Ç¨≈ìMany thought the same when they first learned of it, but as more began to farm, unexpected things started to happen.√¢‚Ç¨ÔøΩ</p>

<p>Philip pointed to one of the nearby plots. Jonathan watched some of the growing tweets. One was particularly beautiful, brightly colored, pleasant and happy. It shone briefly and then withered and died. The next row over, he saw an angry-looking thorny retweet with comment.</p>

<p>The knights ran over to the retweet filled with excitement. √¢‚Ç¨≈ìThis one is perfect,√¢‚Ç¨ÔøΩ they exclaimed, and grabbed clippings of it and began to spread it to all of the nearby data farms.</p>

<p>Jonathan looked at Philip, confused, and asked, √¢‚Ç¨≈ìWhy are they doing this?√¢‚Ç¨ÔøΩ</p>

<p>√¢‚Ç¨≈ìIn the beginning not everyone tended to their free data farms. Many did not know what to do with them, some only planted one or two tweets and then abandoned them entirely. This disappointed the earls of our kingdom. If they don√¢‚Ç¨‚Ñ¢t encourage growth, their share of the data harvest is smaller, there√¢‚Ç¨‚Ñ¢s no one to hear their pronouncements, and all of the land they spent time cultivating is wasted. They realized that not only do they need to make the land easy to cultivate, but they need to make the serfs want to cultivate it. They experimented for a while and learned that new types of controversial, viciously competitive crops are great for encouraging data farming - they call this type of encouragement √¢‚Ç¨Àúengagement√¢‚Ç¨‚Ñ¢.√¢‚Ç¨ÔøΩ</p>

<p>Jonathan was skeptical. √¢‚Ç¨≈ìIf there√¢‚Ç¨‚Ñ¢s too much controversy won√¢‚Ç¨‚Ñ¢t people leave the earldom entirely?√¢‚Ç¨ÔøΩ</p>

<p>Philip replied, √¢‚Ç¨≈ìI would have thought so, but it seems the opposite is true - controversy encourages more to join the data farms. The earls do now attempt to stop some of the most invasive and harmful crops, but now even that creates controversy so it no longer negatively affects engagement.√¢‚Ç¨ÔøΩ</p>

<p>√¢‚Ç¨≈ìWhat is done with the data from the harvest?√¢‚Ç¨ÔøΩ Jonathan asked.</p>

<p>√¢‚Ç¨≈ìThe earls collect all of it and then sell announcements to the king and wealthy merchants. They target these announcements to serfs based on their data harvest.√¢‚Ç¨ÔøΩ Philip replied.</p>

<p>√¢‚Ç¨≈ìWhat kind of announcements?√¢‚Ç¨ÔøΩ</p>

<p>√¢‚Ç¨≈ìThey can be anything, mostly they√¢‚Ç¨‚Ñ¢re merchants selling services, sometimes they are messages from the king. One of the main concerns today is that many messages are lies from enemy kingdoms, but now there are even lies from our own king.√¢‚Ç¨ÔøΩ</p>

<p>√¢‚Ç¨≈ìWhy do they allow lies from enemy kingdoms?√¢‚Ç¨ÔøΩ</p>

<p>√¢‚Ç¨≈ìThere are so many farms and so many pronouncements, it√¢‚Ç¨‚Ñ¢s hard to check all of them first.√¢‚Ç¨ÔøΩ</p>

<p>√¢‚Ç¨≈ìWhy allow lies from our own king?√¢‚Ç¨ÔøΩ</p>

<p>√¢‚Ç¨≈ìWell, he is the king.√¢‚Ç¨ÔøΩ</p>

<p>Jonathan thought for a moment, √¢‚Ç¨≈ìDo the serfs ignore these pronouncements? It looks like they√¢‚Ç¨‚Ñ¢re not paying much attention to them.√¢‚Ç¨ÔøΩ</p>

<p>√¢‚Ç¨≈ìMany of the serfs think they are unaffected by the pronouncements, but they are all affected. That√¢‚Ç¨‚Ñ¢s why the data harvest is so valuable to the earls. The pronouncements and engagement have led to serfs sharing lies, friends have become enemies, even mobs have broken out in violence. The knights are incentivized to fan the flames to keep the serfs farming and confusion and misunderstanding is everywhere. Tyrant kings use pronouncements to control their people and spread lies in enemy kingdoms.√¢‚Ç¨ÔøΩ</p>

<p>Jonathan thought about this for a while. He was glad at least their earls were mostly benevolent, but wondered what would happen if new earls took over. As he was thinking, he noticed one of the farming serfs sit down to rest. The knights nearby whispered nervously to each other, then surreptitiously threw a few small likes at the feet of the serf. Newly invigorated, the serf began to work again and the knights were pleased.</p>

<p>Jonathan looked upset. √¢‚Ç¨≈ìWhy do the knights support this work? They are skilled farmers, couldn√¢‚Ç¨‚Ñ¢t they tend their own land?√¢‚Ç¨ÔøΩ</p>

<p>√¢‚Ç¨≈ìThe earls offer the knights a comfortable life, high salary, and pleasant work (though curiously poor housing). Life outside the earldom is uncertain and difficult.√¢‚Ç¨ÔøΩ</p>

<p>√¢‚Ç¨≈ìDo no knights strike out on their own?√¢‚Ç¨ÔøΩ</p>

<p>Philip was quiet for a moment. He pointed across a vast vista to a large castle in the distance adjacent to that of their own Earl Zuckerberg√¢‚Ç¨‚Ñ¢s. √¢‚Ç¨≈ìThat is the castle of Sir Brian Acton of the former Earldom of WhatsApp. Sir Acton was an idealistic farmer who rejected the ways of our earl. He promised the serfs he would take no part of their  data harvest they produced from the land he provided them, and instead the serfs even paid him a small cash fee for his protection. He had no knights to watch and report on his people and no heralds spreading pronouncements.√¢‚Ç¨ÔøΩ</p>

<p>√¢‚Ç¨≈ìWhat happened?√¢‚Ç¨ÔøΩ</p>

<p>√¢‚Ç¨≈ìHe was too successful. Earl Zuckerberg saw many of his serfs begin to leave his lands to work the lands of Sir Acton (at the time he was known as Farmer Acton). This was a risk to the power of Zuckerberg√¢‚Ç¨‚Ñ¢s earldom, since an earl without serfs to tend to the data fields has no harvest to interest others. In the end he offered Sir Acton a knightship and such enormous wealth that he could not refuse. It√¢‚Ç¨‚Ñ¢s said he now lives in that vast castle alone, is rarely seen, and rarely speaks. The serfs that were in agreement with him now belong to Earl Zuckerberg as they had before, their deal was broken, and once again they tend to our earl√¢‚Ç¨‚Ñ¢s data harvest.√¢‚Ç¨ÔøΩ</p>

<p>√¢‚Ç¨≈ìAre there no others?√¢‚Ç¨ÔøΩ</p>

<p>√¢‚Ç¨≈ìSir Acton was just the most ‚Ä¶</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zalberico.com/essay/2020/07/14/the-serfs-of-facebook.html">https://zalberico.com/essay/2020/07/14/the-serfs-of-facebook.html</a></em></p>]]>
            </description>
            <link>https://zalberico.com/essay/2020/07/14/the-serfs-of-facebook.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23899153</guid>
            <pubDate>Mon, 20 Jul 2020 16:04:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is max MySQL transactions per second = max fsyncs per second?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23898962">thread link</a>) | @Sirupsen
<br/>
July 20, 2020 | https://sirupsen.com/napkin/problem-10-mysql-transactions-per-second/ | <a href="https://web.archive.org/web/*/https://sirupsen.com/napkin/problem-10-mysql-transactions-per-second/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="article-content">
    <p>
        This is an edition of the Napkin Math newsletter, where you'll receive
        an occassional problem to practise your order-of-magnitude calculations.
        You can <a href="https://sirupsen.com/napkin">subscribe through email.</a>
    </p>

    

<p>Napkin friends, from near and far, it‚Äôs time for another napkin problem!</p>

<p>Since the beginning of this newsletter I‚Äôve posed problems for you to try to
answer. Then in the next month‚Äôs edition, you hear my answer. Talking with a few
of you, it seems many of you read these as posts regardless of their
problem-answer format.</p>

<p>That‚Äôs why I‚Äôve decided to experiment with a simpler format: posts where I both
present a problem and solution in one go. This one will be long, since it‚Äôll
include an answer to last month‚Äôs.</p>

<p>Hope you enjoy this format! As always, you are encouraged to reach out with
feedback.</p>

<h2 id="problem-10-is-mysql-s-maximum-transactions-per-second-equivalent-to-fsyncs-per-second">Problem 10: Is MySQL‚Äôs maximum transactions per second equivalent to fsyncs per second?</h2>

<p>How many transactions (‚Äòwrites‚Äô) per second is MySQL capable of?</p>

<p>A naive model of how a write (a SQL insert/update/delete) to an ACID-compliant
database like MySQL works might be the following (this applies equally to
Postgres, or any other relational/ACID-compliant databases, but we‚Äôll
proceed to work with MySQL as it‚Äôs the one I know best):</p>

<ol>
<li>Client sends query to MySQL over an existing connection: <code>INSERT INTO products (name, price) VALUES ('Sneaker', 100)</code></li>
<li>MySQL inserts the new record to the write-ahead-log (WAL) and calls
<code>fsync(2)</code> to tell the operating system to tell the filesystem to tell the
disk to make <em>sure</em> that this data is <em>for sure</em>, pinky-swear committed to
the disk. This step, being the most complex, is depicted below.</li>
<li>MySQL inserts the record into an in-memory page in the backing storage engine
(InnoDB) so the record will be visible to subsequent queries. Why commit to
the storage engine <em>and</em> the WAL? The storage engine is optimized for serving
query results the data, and the WAL for writing it in a safe manner ‚Äì we
can‚Äôt serve a <code>SELECT</code> efficiently from the WAL!</li>
<li>MySQL returns <code>OK</code> to the client.</li>
<li>MySQL eventually calls <code>fsync(2)</code> to ensure InnoDB commits the page to disk.</li>
</ol>

<p><img src="https://user-images.githubusercontent.com/97400/87759326-21adeb00-c7dc-11ea-89c7-559ca11530e8.png" alt="Napkin_10"></p>

<p>In the event of power-loss at any of these points, the behaviour can be defined
without nasty surprises, upholding our dear ACID-compliance.</p>

<p>Splendid! Now that we‚Äôve constructed a naive model of how a relational database
might handle writes safely, we can consider the latency of inserting a new
record into the database. When we consult <a href="https://github.com/sirupsen/napkin-math">the reference napkin numbers</a>, we
see that the <code>fsync(2)</code> in step (2) is by <em>far</em> the slowest operation in the
blocking chain at 1 ms.</p>

<p>For example, the network handling at step (1) takes roughly ~10 Œºs (TCP Echo
Server is what we can classify as ‚Äòthe TCP overhead‚Äô). The <code>write(2)</code> itself
prior to the <code>fsync(2)</code> is also negligible at ~10 Œºs, since this system call
essentially just writes to an in-memory buffer (the ‚Äòpage cache‚Äô) in the kernel.
This doesn‚Äôt guarantee the actual bits are committed on disk, which means an
unexpected loss of power would erase the data, dropping our ACID-compliance on
the floor. Calling <code>fsync(2)</code> guarantees us the bits are persisted on the disk,
which will survive an unexpected system shutdown.  Downside is that it‚Äôs 100x
slower.</p>

<p>With that, we should be able to form a simple hypothesis on the maximum
throughput of MySQL:</p>

<blockquote>
<p>The maximum theoretical throughput of MySQL is equivalent to the maximum
number of <code>fsync(2)</code> per second.</p>
</blockquote>

<p>We know that <code>fsync(2)</code> takes 1 ms from earlier, which means we would naively
expect that MySQL would be able to perform in the neighbourhood of: <code>1s /
1ms/fsync = 1000 fsyncs/s = 1000 transactions/s</code> .</p>

<p>Excellent. We followed the first three of the napkin math steps: (1) Model the
system, (2) Identify the relevant latencies, (3) Do the napkin math, (4) Verify
the napkin calculations against reality.</p>

<p>On to (4: Verifying)! We‚Äôll write a simple benchmark in Rust that writes to
MySQL with 16 threads, doing 1,000 insertions each:</p>

<pre><code>for i in 0..16 {
    handles.push(thread::spawn({
        let pool = pool.clone();
        move || {
            let mut conn = pool.get_conn().unwrap();
            // TODO: we should ideally be popping these off a queue in case of a stall
            // in a thread, but this is likely good enough.
            for _ in 0..1000 {
                conn.exec_drop(
                    r"INSERT INTO products (shop_id, title) VALUES (:shop_id, :title)",
                    params! { "shop_id" =&gt; 123, "title" =&gt; "aerodynamic chair" },
                )
                .unwrap();
            }
        }
    }));

    for handle in handles {
      handle.join().unwrap();
    }
    // 3 seconds, 16,000 insertions
}
</code></pre>

<p>This takes ~3 seconds to perform 16,000 insertions, or ~5,300 insertions per
second. This is <strong>5x</strong> more than the 1,000 <code>fsync</code> per second our napkin math
told us would be the theoretical maximum transactional throughput!</p>

<p>Typically with napkin math we aim for being within an order of magnitude, which
we are. But, when I do napkin math it usually establishes a lower-bound for the
system, i.e. from first-principles, how fast <em>could</em> this system perform in
ideal circumstances?</p>

<p>Rarely is the system 5x faster than napkin math. When we identify a
significant-ish gap between the real-life performance and the expected
performance, I call it the ‚Äúfirst-principle gap.‚Äù This is where curiosity sets
in. It typically means there‚Äôs (1) an opportunity to improve the system, or (2)
a flaw in our model of the system. In this case, only (2) makes sense, because
the system is faster than we predicted.</p>

<p>What‚Äôs wrong with our model of how the system works? Why aren‚Äôt fsyncs per
second equal to transactions per second?</p>

<p>First I examined the benchmark‚Ä¶ is something wrong? Nope <code>SELECT COUNT(*) FROM
products</code> says 16,000. Is the MySQL I‚Äôm using configured to not <code>fsync</code> on every
write? Nope, it‚Äôs at the <a href="https://dev.mysql.com/doc/refman/5.7/en/innodb-parameters.html#sysvar_innodb_flush_log_at_trx_commit">safe default</a>.</p>

<p>Then I sat down and thought about it. Perhaps MySQL is <em>not</em> doing an <code>fsync</code>
for every <em>single</em> write? If it‚Äôs processing 5,300 insertions per second,
perhaps it‚Äôs batching multiple writes together as part of writing to the WAL,
step (2) above? Since each transaction is so short, MySQL would benefit from
waiting a few microseconds to see if other transactions want to ride along
before calling the expensive <code>fsync(2)</code>.</p>

<p>We can test this hypothesis by writing a simple <code>bpftrace</code> script to observe the
number of <code>fsync(1)</code> for the ~16,000 insertions:</p>

<pre><code>tracepoint:syscalls:sys_enter_fsync,tracepoint:syscalls:sys_enter_fdatasync
/comm == "mysqld"/
{
        @fsyncs = count();
}
</code></pre>

<p>Running this during the ~3 seconds it takes to insert the 16,000 records we get
~8,000 <code>fsync</code> calls:</p>

<pre><code>$ sudo bpftrace fsync_count.d
Attaching 2 probes...
^C

@fsyncs: 8037
</code></pre>

<p>This is a peculiar number. If MySQL was batching fsyncs, we‚Äôd expect something
far lower. This number means that we‚Äôre on average doing ~2,500 <code>fsync</code> per
second, at a latency of ~0.4ms. This is twice as fast as the <code>fsync</code> latency we
expect, the 1ms mentioned earlier. For sanity, I ran the script to benchmark
<code>fsync</code> outside MySQL again, no, <a href="https://github.com/sirupsen/napkin-math/blob/fe780331c6f0c6f225a70c8a37c21e0740f7c73c/src/main.rs#L491">still 1ms</a>. <a href="https://gist.github.com/sirupsen/9fd5fe9466e82df073ed8a13ed1f661f#file-napkin-bash">Looked at the
distribution</a>, and it was consistently ~1ms.</p>

<p>So there‚Äôs two things we can draw from this: (1) We‚Äôre able to <code>fsync</code> more than
twice as fast as we expect, (2) Our hypothesis was correct that MySQL is more
clever than doing one <code>fsync</code> per transaction, however, since <code>fsync</code> also was
faster than expected, this didn‚Äôt explain everything.</p>

<p>If you remember from above, while committing the transaction could theoretically
be a single <code>fsync</code>, other features of MySQL might also call <code>fsync</code>. Perhaps
they‚Äôre adding noise?</p>

<p>We need to group <code>fsync</code> by file descriptor to get a better idea of how MySQL
uses <code>fsync</code>. However, the raw file descriptor number doesn‚Äôt tell us much. We
can use <code>readlink</code> and the <code>proc</code> file-system to obtain the file name the file
descriptor points to. Let‚Äôs write a <a href="https://github.com/iovisor/bpftrace"><code>bpftrace</code> script</a> to see what‚Äôs being
<code>fsync</code>‚Äòed:</p>

<pre><code>tracepoint:syscalls:sys_enter_fsync,tracepoint:syscalls:sys_enter_fdatasync
/comm == str($1)/
{
        @fsyncs[args-&gt;fd] = count();
        if (@fd_to_filename[args-&gt;fd]) {
        } else {
                @fd_to_filename[args-&gt;fd] = 1;
                system("echo -n 'fd %d -&gt; ' &amp;1&gt;&amp;2 | readlink /proc/%d/fd/%d", args-&gt;fd, pid, args-&gt;fd);
        }
}

END {
        clear(@fd_to_filename);
}
</code></pre>

<p>Running this while inserting the 16,000 transactions into MySQL gives us:</p>

<pre><code>personal@napkin:~$ sudo bpftrace --unsafe fsync_count_by_fd.d mysqld
Attaching 5 probes...
fd 5 -&gt; /var/lib/mysql/ib_logfile0 # redo log, or write-ahead-log
fd 9 -&gt; /var/lib/mysql/ibdata1 # shared mysql tablespace
fd 11 -&gt; /var/lib/mysql/#ib_16384_0.dblwr # innodb doublewrite-buffer
fd 13 -&gt; /var/lib/mysql/undo_001 # undo log, to rollback transactions
fd 15 -&gt; /var/lib/mysql/undo_002 # undo log, to rollback transactions
fd 27 -&gt; /var/lib/mysql/mysql.ibd # tablespace 
fd 34 -&gt; /var/lib/mysql/napkin/products.ibd # innodb storage for our products table
fd 99 -&gt; /var/lib/mysql/binlog.000019 # binlog for replication
^C

@fsyncs[9]: 2
@fsyncs[12]: 2
@fsyncs[27]: 12
@fsyncs[34]: 47
@fsyncs[13]: 86
@fsyncs[15]: 93
@fsyncs[11]: 103
@fsyncs[99]: 2962
@fsyncs[5]: 4887
</code></pre>

<p>What we can observe here is that the majority of the writes are to the ‚Äúredo
log‚Äù, what we call the ‚Äúwrite-ahead-log‚Äù (WAL). There‚Äôs a few <code>fsync</code> calls to
commit the InnoDB table-space, not nearly as often, as we can always recover
this from the WAL in case we crash between them. Reads work just fine prior to
the <code>fsync</code>, as the queries can simply be served out of memory from InnoDB.</p>

<p>The only surprising thing here is the substantial volume of writes to the
binlog, which we haven‚Äôt mentioned before. You can think of the binlog as the
‚Äúreplication stream.‚Äù It‚Äôs a stream of events such as <code>row a changed from x to
y</code>, <code>row b was deleted</code>, and <code>table u added column c</code>. The primary replica
streams this to the read-replicas, which use it to update their own data.</p>

<p>When you think about it, the <code>binlog</code> and the WAL need to be kept exactly in
sync. We can‚Äôt have something ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sirupsen.com/napkin/problem-10-mysql-transactions-per-second/">https://sirupsen.com/napkin/problem-10-mysql-transactions-per-second/</a></em></p>]]>
            </description>
            <link>https://sirupsen.com/napkin/problem-10-mysql-transactions-per-second/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23898962</guid>
            <pubDate>Mon, 20 Jul 2020 15:46:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[German E-Cars: The Race to Beat Tesla at Its Own Game]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23898752">thread link</a>) | @zwieback
<br/>
July 20, 2020 | https://www.spiegel.de/international/europe/vw-bwm-daimler-the-race-to-beat-tesla-at-its-own-game-a-58ddb443-29be-4764-9f5c-3d1140e0519f | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/europe/vw-bwm-daimler-the-race-to-beat-tesla-at-its-own-game-a-58ddb443-29be-4764-9f5c-3d1140e0519f">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="true">


</section>
<section>
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;18928ba4-98d4-4e1f-8f57-86231f1a003e&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;f8cd6379-cfd3-4ec9-a66f-aaaf82a97b64&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/18928ba4-98d4-4e1f-8f57-86231f1a003e_w948_r1.77_fpx34.1_fpy54.93.jpg" srcset="https://cdn.prod.www.spiegel.de/images/18928ba4-98d4-4e1f-8f57-86231f1a003e_w520_r1.77_fpx34.1_fpy54.93.jpg 520w, https://cdn.prod.www.spiegel.de/images/18928ba4-98d4-4e1f-8f57-86231f1a003e_w948_r1.77_fpx34.1_fpy54.93.jpg 948w" width="948" height="536" sizes="948px" title="An Audi e-tron at a charging station: &quot;The lever has been flipped.&quot;" alt="An Audi e-tron at a charging station: &quot;The lever has been flipped.&quot;">
</span>
</span>
</span>

</p>
<figcaption>
<p><strong>An Audi e-tron at a charging station:</strong> "The lever has been flipped."</p>
<span>
Foto:‚ÄÇAUDI
</span>
</figcaption>
</figure>
</div><div>
<p>Right before Markus Duesmann began his difficult mission, he fulfilled one of his life's dreams. Duesmann, the designated head of the German automaker Audi, hopped on a motorcycle and spent several months cruising around Europe, from Gibraltar to the Black Sea, from the North Cape to the British Isles. In all, he put more than 28,000 kilometers (17,400 miles) on the odometer.</p>


<div>
<p>That journey, Duesmann would later tell his confidants, helped him gain perspective. Indeed, there are many things he sees more clearly now: His respect for Europe, its size and its cultural diversity, he said, had grown. So had his respect for Audi's biggest competitor in the field of electric mobility: Tesla.</p><p>In the fall of 2019, Duesmann was sitting on his bike when he received a message from Berlin. The e-car pioneer Tesla was planning on opening a car factory just outside the capital. Duesmann laughed out loud. He was impressed by the Californians' audacity. "At first, none of us took Tesla seriously," the Audi CEO would later say. "Then we were puzzled - and then we were shocked by what they were capable of."</p>
</div>

<div>
<p>Tesla's Model 3 is one of the best-selling electric cars in Europe, way ahead of its German competition. The only carmaker that has recently outperformed Tesla is Renault with its tiny e-car, Zoe. The Californians are also ahead of the pack with their charging stations. The company has installed almost 5,000 of its "Superchargers" in 24 European countries. By comparison: Ionity, the charging station consortium of BMW, Daimler, VW and Ford, has so far only managed to install 1,160 electric charging columns.</p><h3>The Germans Can't Keep Up</h3><p>The German government's subsidy to encourage the purchase of electric cars, which was recently increased to 9,000 euros ($10,276), is putting more pressure on automakers, with demand booming. In June alone, while the car market slumped overall, more than 8,000 e-cars were registered in Germany, a solid 40 percent more than in the previous year. Other European countries like Austria, France, Spain and Britain, are also spurring demand with their own subsidy programs.</p>
</div>


<section data-area="contentbox">
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;7feb63ce-f37f-4f1e-8c84-fa20b0268454&quot;, &quot;zoomable&quot;:false,&quot;zoomId&quot;:&quot;92b227c5-bbde-4fcb-8f8b-87d24fd482ae&quot;}">
<span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/7feb63ce-f37f-4f1e-8c84-fa20b0268454_w568_r0.7571817357121258_fpx50_fpy40.89.jpg" srcset="https://cdn.prod.www.spiegel.de/images/7feb63ce-f37f-4f1e-8c84-fa20b0268454_w284_r0.7571817357121258_fpx50_fpy40.89.jpg 284w, https://cdn.prod.www.spiegel.de/images/7feb63ce-f37f-4f1e-8c84-fa20b0268454_w335_r0.7571817357121258_fpx50_fpy40.89.jpg 335w, https://cdn.prod.www.spiegel.de/images/7feb63ce-f37f-4f1e-8c84-fa20b0268454_w568_r0.7571817357121258_fpx50_fpy40.89.jpg 568w" width="568" height="750" sizes="568px" data-srcset="https://cdn.prod.www.spiegel.de/images/7feb63ce-f37f-4f1e-8c84-fa20b0268454_w284_r0.7571817357121258_fpx50_fpy40.89.jpg 284w, https://cdn.prod.www.spiegel.de/images/7feb63ce-f37f-4f1e-8c84-fa20b0268454_w335_r0.7571817357121258_fpx50_fpy40.89.jpg 335w, https://cdn.prod.www.spiegel.de/images/7feb63ce-f37f-4f1e-8c84-fa20b0268454_w568_r0.7571817357121258_fpx50_fpy40.89.jpg 568w">
</span>
</span>
</span>
<figcaption>
<span>
Foto:‚ÄÇ<p>SVC.OrisWFL</p>
</span>
</figcaption>
</figure>

</div>
</section>
<div>
<p>Yet German manufacturers are ill-equipped for the surge in demand. Most new electric models won't hit the market for the next six to 18 months. And their ability to manufacture more of the existing models can't just be ramped up overnight.</p><p>"The car companies are suffering from bottlenecks," says Roman Zitzelsberger, head of the IG Metall union in the German state of Baden-W√ºrttemberg and a member of Daimler's supervisory board. "Especially with regard to battery cells." Anyone who orders an electric car now will have to wait up to a year to get it. For some models, German companies have even placed a freeze on new orders.</p>
</div>

<div>
<p>In the middle of the coronavirus pandemic, BMW, Daimler and Volkswagen must now increase production, deliver more e-cars and close the massive gaps in their charging networks. Otherwise, the billions of euros they poured into their e-car offensives will have been for naught.</p><h3>The Artemis Project</h3><p>Duesmann has been at his post since April and has hardly had any time to get used to the job. He's been tasked with turning the ailing premium brand back into an innovation leader, while at the same time accelerating the turnaround of Audi's parent company, VW. Duesmann is also the head of research and development at VW. Just two months after he started his new job, he spearheaded a project aimed at putting Audi and VW on equal footing with Tesla. The project is called Artemis, after the Greek goddess of the hunt.</p>
</div>

<div>
<p>Duesmann has put together a largely independent team of experts from across the VW Group. They will be working in a startup-like atmosphere, developing new technologies and eliminating previous deficits, particularly in software and networking. The goal is "to accelerate the development of additional car models," according to the Audi CEO.</p><p>Duesmann has experience with such tasks. As a former executive at BMW, he was jointly responsible for the famous "Project i," which the company ultimately spun off. Thanks to the e-cars developed there, BMW was able to become a frontrunner in the field for a while. However, the i3 and i8 models caused such severe losses that the Munich-based automaker lost its nerve. BMW's next generation of electric cars won't come onto the market until 2021. Project i was integrated back into the BMW Group, essentially phasing it out.</p><p>It's now up to Audi to do it better. The Artemis project managers want to be in close contact with the group's developers from the very beginning. Duesmann has been admonishing his colleagues that the company must be constantly developing new cars, "otherwise we won't manage to establish a new technology." By 2024, e-vehicles with completely new designs are set to be created, serving as blueprints for the entire Volkswagen Group.</p><h3>A Dearth of Charging Stations</h3><p>At the company's headquarters in Wolfsburg, there is a fear that any new models, however innovative, wouldn't be very popular since potential customers wouldn't have enough places to charge them.</p><p>"The infrastructure is a huge challenge," VW's works council chairman, Bernd Osterloh, recently told investors, "especially in Southern and Eastern Europe." There is still a long way to go, he said, "to push ahead with e-mobility in these countries." According to Osterloh, CO2 reductions demanded by the European Union cannot be achieved if electric cars are only widely adopted in Scandinavia or the Netherlands, which have extensive networks of charging stations.</p><p>As such, preparations are already underway within the Artemis project to create a separate charging network for the whole of Europe. Artemis' role model is Electrify America, a VW subsidiary that has set up thousands of charging points in the U.S. Managers at the company recently presented the project to their German colleagues and made a big impression. The expansion of the charging network, with its price tag in the billions, was part of the settlement with the U.S. authorities for Volkswagen's diesel scandal but it has turned out to be a strategic advantage for VW in the world's second-largest car market. Also having its own network in Europe could prove to be a major selling point for the company.</p>
</div>

<div>
<p>The Artemis team's plans foresee Audi customers initially getting exclusive access, after which Porsche drivers would also be allowed to charge their vehicles at the stations. It's still unclear whether other VW Group brands, or even competitors, will also be given access. The first step, therefore, would be a closed network similar to Tesla's. Premium customers could reserve a charging port in advance to avoid waiting times.</p><p>Other offerings are in the works, too, services that could make waiting times while charging more pleasant for customers - and that would ideally get them to spend more money. One idea is to cooperate with retailers who could open pop-up stores near the stations. The project is in its infancy. Issues are still being discussed like whether the charging stations should be installed primarily along major traffic arteries or also in cities. The plans are expected to further coalesce this fall.</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;83c68319-8045-4d7e-a4e8-05637e07622b&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;edab56bd-76be-4291-8b30-4855e53e8a9e&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/83c68319-8045-4d7e-a4e8-05637e07622b_w643_r1.4320712694877507_fpx64.08_fpy49.89.jpg" srcset="https://cdn.prod.www.spiegel.de/images/83c68319-8045-4d7e-a4e8-05637e07622b_w488_r1.4320712694877507_fpx64.08_fpy49.89.jpg 488w, https://cdn.prod.www.spiegel.de/images/83c68319-8045-4d7e-a4e8-05637e07622b_w616_r1.4320712694877507_fpx64.08_fpy49.89.jpg 616w, https://cdn.prod.www.spiegel.de/images/83c68319-8045-4d7e-a4e8-05637e07622b_w643_r1.4320712694877507_fpx64.08_fpy49.89.jpg 718w," width="643" height="449" sizes="643px" data-srcset="https://cdn.prod.www.spiegel.de/images/83c68319-8045-4d7e-a4e8-05637e07622b_w488_r1.4320712694877507_fpx64.08_fpy49.89.jpg 488w, https://cdn.prod.www.spiegel.de/images/83c68319-8045-4d7e-a4e8-05637e07622b_w616_r1.4320712694877507_fpx64.08_fpy49.89.jpg 616w, https://cdn.prod.www.spiegel.de/images/83c68319-8045-4d7e-a4e8-05637e07622b_w643_r1.4320712694877507_fpx64.08_fpy49.89.jpg 718w," title="Audi CEO Markus Duesmann: &quot;Audi must be constantly developing new cars.&quot;" alt="Audi CEO Markus Duesmann: &quot;Audi must be constantly developing new cars.&quot;">
</span>
</span>
</span>
</p><figcaption>
<p><strong>Audi CEO Markus Duesmann:</strong> "Audi must be constantly developing new cars."</p>
<span>
Foto:‚ÄÇBernhard Huber / AUDI
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<h3>Countering the Asian Giants</h3><p>Other manufacturers doubt that shortfalls in charging infrastructures can be closed if everyone goes it alone. Markus Sch√§fer, a member of Daimler's management board whose portfolio includes group research, has called for "a coordinated approach between car companies, power utilities and politicians." Sch√§fer says the German government would be well advised to use its current presidency of the European Council "to make a functional charging infrastructure throughout Europe possible." This would also include creating standards for a uniform payment system.</p><p>Automakers, the Daimler manager adds, should concentrate on improving battery technology so that e-cars don't have to recharge as often. In the medium term, Mercedes is looking to increase the range of its electric vehicles to 700 kilometers (435 miles) and reduce charging times to around 15 minutes. If electric cars are no longer blocking charging stations for 30 minutes to an hour, "then gas station operators will also discover this business for themselves and set up their own charging points."</p><p>However, in order to increase the range of their e-vehicles, the companies are dependent on help from the Far East. The heart of the electric car is its battery and the corresponding software. This is what companies like CATL, Panasonic or LG Chem - high-tech companies from China, Japan and Korea ‚Äì are best at. German suppliers like Bosch or Continental have decided against producing their own battery cells. The Asian companies are simply too far ahead.</p><p>But German car companies are no longer willing to acquiesce to such dominance. Sch√§fer says Daimler is now building a "global network of battery factories, from Europe and Asia to the USA."</p><p>The Stuttgart-based company got out of industrial mass production of battery cells in 2015. Instead, in early July, the group acquired a stake in the Chinese battery manufacturer Farasis. The plan is to build a cell factory in Bitterfeld, in eastern Germany, with Farasis as the producer and Daimler as the major customer. Another partnership will soon follow. This is how the automaker hopes to lock down the long-term supply of battery cells and gain insights into the future market. Daimler will also get to send Sch√§fer as its representative on the Farasis supervisory board.</p><h3>Enter Polestar</h3><p>This kind of cooperation shows how much technological change is shifting the balance of power in the automotive industry. "The lever has been flipped toward electrification," says Andreas Wolf, head of the ‚Ä¶</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/europe/vw-bwm-daimler-the-race-to-beat-tesla-at-its-own-game-a-58ddb443-29be-4764-9f5c-3d1140e0519f">https://www.spiegel.de/international/europe/vw-bwm-daimler-the-race-to-beat-tesla-at-its-own-game-a-58ddb443-29be-4764-9f5c-3d1140e0519f</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/europe/vw-bwm-daimler-the-race-to-beat-tesla-at-its-own-game-a-58ddb443-29be-4764-9f5c-3d1140e0519f</link>
            <guid isPermaLink="false">hacker-news-small-sites-23898752</guid>
            <pubDate>Mon, 20 Jul 2020 15:28:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What about Design?]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23898679">thread link</a>) | @ppjet6
<br/>
July 20, 2020 | https://bouah.net/2020/07/what-about-design/ | <a href="https://web.archive.org/web/*/https://bouah.net/2020/07/what-about-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Who around here hasn‚Äôt heard about the tragic and inevitable death of XMPP
(eXtensible Messaging and Presence Protocol)? It‚Äôs a pretty common topic in
the community and around, often started by users of XMPP themselves missing a
certain feature in one or multiple specific implementations, or users of
alternative solutions. In a way this is my own version of why XMPP is or isn‚Äôt
doomed.</p>
<p>To go down this rabbit hole, we first need to set a few definitions. Most of
my readers would probably know what XMPP is, but I feel obligated to provide a
short reminder as it will allow me to highlight specific points I want to talk
about.</p>

<p>XMPP is a communication protocol, that is ‚Äúnerd‚Äù speak to say it‚Äôs a language
for applications to use and talk together at a level that the end-user doesn‚Äôt
see. An example would be a chat application: your desktop or smartphone app
talking to a server that then talks to another app.</p>
<p>It is defined as a standard at the <a href="https://ietf.org/">IETF (Internet Engineering Task
Force)</a> ‚Äì a standard being the specification of a protocol
(a document, in this case publicised and accessible by anyone), which allows
multiple products implementing what it describes to be able to work together
in an interoperable way.</p>
<p>Core specifications of XMPP are written so that it is easily extendible
allowing any developer to use custom (XML) elements for their own use, and
optionally write a specification for their new feature for everyone else to
use.</p>
<p>XMPP also defines a client-server-server-client model, where a client can talk
with a server that can then talk with multiple servers before reaching other
clients, thus allowing for <a href="https://en.wikipedia.org/wiki/Decentralization#Technological_decentralization">decentralization</a> ‚Äì anyone setting up their own
server to be free from restrictions of other operators, and communicating with
the world or part of it.</p>
<p>So there we have it: (IETF) <strong>Standard</strong>, <strong>Decentralized</strong>, and
<strong>Extensible</strong>. These are, I believe, the 3 selling-points of XMPP.</p>
<p>From there tons of features can be implemented and then negotiated (as part of
the extensibility) and many things can change to use newer extensions that
weren‚Äôt considered in the core specifications. For example even the
serialization format (words of the language applications talk, originally XML)
can be changed (just as <a href="https://xmpp.org/extensions/xep-0322.html">EXI</a> is doing), and it‚Äôs also perfectly
fine to have non-compliant behaviour as long as it has been negotiated by
entities taking part in it. And so on‚Ä¶</p>
<p>The <a href="https://xmpp.org/">XSF</a> (XMPP Standards Foundation, previously known as Jabber Software
Foundation) is the entity that did the original work on the protocol and
submitted it to the IETF. It now has a sheperding role. There is no
requirement that XMPP extensions be brought to the XSF, but it aims to be the
place where technical knowledge around XMPP is gathered, so people can get
better feedback when submitting their new specification. Developers have
already layed out lots of protocol bricks for others to reuse through the XSF.</p>

<p>This is indeed the core of the problem. While extensibility is one of the
strenghs of XMPP, it‚Äôs also its main weakness, one of the main points of its
critics. That said, I believe it‚Äôs not as bad as they make it look like.</p>
<p>It is true that most applications are incompatible one way or another, with
various degrees of significance, either because they don‚Äôt implement the same
set of extensions, or because an author interprets extensions differently,
or simply because of bugs.</p>
<p>For the rest of this article I will leave aside the last two points ‚Äì
interpretation issues and bugs ‚Äì as I consider both of them bugs ‚Äì of
specifications and/or implementations ‚Äì and bugs happen everywhere and can be
fixed. Generally, determining what is a bug and what is a (unintended?) feature
is where the issue lies.</p>
<p>While there have been attempts within the XSF at defining common sets of
extensions in what is called ‚ÄúCompliance Suites‚Äù (currently updated on a
yearly-basis: <a href="https://xmpp.org/extensions/xep-0423.html">2020</a>, <a href="https://xmpp.org/extensions/xep-0412.html">2019</a>, etc.), they have in my opinion
had mild success for the effort it takes the author to gather feedback and
come up with not-so-controversial changes for newer revisions.</p>
<p>What these Compliance Suites don‚Äôt take into account so well, despite recent
efforts; and what critics don‚Äôt account for either when saying XMPP is
missing X, or that all implementations should do Y, is that it‚Äôs not just
about features and protocols.</p>
<p>The process of coming up with a common set of extensions for an implementation
requires a lot more groundwork. This includes figuring out who the userbase
is, and how the experience for it should be, i.e., design. This process should
be applied across a set of implementations, using the same design guidelines and
ensuring interoperability.</p>
<p>It is not enough if somebody using <a href="https://conversations.im/">Conversations</a> on mobile talks to somebody
else using <a href="https://dino.im/">Dino</a> on desktop, even if they both follow the Compliance Suites
for a given year and can then interop on a ‚Äúbasic‚Äù level, which to be honest, is
still pretty advanced, they have different design guidelines and there will
inevitably be areas where they differ and some features won‚Äôt behave as
expected on the other side. The issue is not that there is no design
guidelines, it‚Äôs that they‚Äôre not the same.</p>

<p>Multiple solutions following this design process already exist, such as
<a href="https://www.xabber.com/">Xabber</a> and <a href="https://tigase.net/tigase-instant-communication">Tigase</a>. <a href="https://snikket.org/">Snikket</a> is a new addition in this domain. You can
read about its goals <a href="https://blog.prosody.im/introducing-snikket/">in the introduction article</a> or in a
<a href="https://www.reddit.com/r/xmpp/comments/f0el07/can_someone_explain_to_me_whats_the_point_of/fgto5h0/">more detailed explanation</a> from its author. At the time
of writing it is composed of a rebranded <a href="https://prosody.im/">Prosody</a> (server) and Conversations
(client), is entirely based on XMPP and federates with the XMPP network. But
the important part ‚Äì and also why it deserves a name other than ‚ÄúXMPP‚Äù ‚Äì is
its goal: to provide a server and a (set of) client(s) that interoperate
properly and have common design guidelines that match the expected userbase.</p>
<p>Maybe you‚Äôre not part of Snikket‚Äôs target, in which case there might someday
be a similar solution that‚Äôs more adapted to your use-case. For the more
technical of us who understand the protocol and/or can deal with less unified
designs, it may be ok to continue using our current applications and work
around these issues ourselves. For the mass audiences I believe this is not an
option.</p>

<p>To the question I set to answer at the beginning I say this: Why does it
matter? For whom? My goal is to bring standardization, decentralization, and
extensibility to mass audiences. Not to bring XMPP to them. As explained above
I believe we need product suites with common design guidelines, and they
should include these properties. XMPP has good building blocks but lacks
consorted design.</p>
<p>I want decentralization and standardization to prevent users from being locked
in closed ‚Äì often also proprietary ‚Äì silos such as WhatsApp, Hangouts,
Slack, MS Teams, Tik-Tok, or even Signal. And I want extensibility to prevent being
stuck in the past and to adapt to the people‚Äôs needs.</p>
<p><em>Comments available on your usual centralized platforms: <a href="https://www.reddit.com/r/xmpp/comments/hun47q/what_about_design/">reddit</a> and <a href="https://news.ycombinator.com/item?id=23898679">HN</a>,
but also <a href="https://post.lurk.org/@pep/104546844162627507">mastodon</a>.</em></p>

      
    </div></div>]]>
            </description>
            <link>https://bouah.net/2020/07/what-about-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23898679</guid>
            <pubDate>Mon, 20 Jul 2020 15:21:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The new Range app for Slack. Save time and keep your team connected]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23898668">thread link</a>) | @RoboCornell88
<br/>
July 20, 2020 | https://www.range.co/blog/new-range-app-for-slack | <a href="https://web.archive.org/web/*/https://www.range.co/blog/new-range-app-for-slack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><p>With everyone working remote, teams are on Slack more than ever. Sometimes too much. It can feel like you‚Äôre chatting all the time, but still struggling to know what‚Äôs happening. If you‚Äôre feeling a bit of Slack overload right now, you‚Äôre not alone. We talk with hundreds of tech teams, and so many are overloaded with communication yet feeling more disconnected than ever.</p><p>We founded Range to help teams who are struggling to stay in sync. So this problem is near to our heart. We <a href="https://www.range.co/product/slack">designed our product</a> with a simple concept: that taking a few minutes to check-in with your team each day actually ends up saving everyone time. When teams build a cadence of sharing what‚Äôs happening, it means there‚Äôs less time wasted in Zoom meetings delivering status updates, and fewer Slack messages that interrupt deep work.</p><p>With Slack‚Äôs <a href="https://api.slack.com/" rel="noopener">new APIs</a>, we saw an opportunity to build the best Check-in experience possible within Slack. We spent the last few months building that vision. If you‚Äôre a remote team that feels disconnected, you can install our Slack app to help your team build the habit of checking-in, and start feeling connected again.</p><h3>The best way to Check-in with your team on Slack</h3><p>Here‚Äôs everything you need to help your team get started with Check-ins, all from within Slack:</p><p>üëç <strong>Easy setup</strong> ‚Äî Sign in to Range with your Slack account, invite your team, and be ready to go in minutes. We‚Äôll guide you through every step.</p><p><strong>‚åöÔ∏è Reminders</strong> ‚Äî No need to nag your team for status updates. Range sends everyone a reminder message each morning to check-in.</p><p>‚úÖ <strong>Check-ins </strong>‚Äî Everyone on your team can quickly share a list of what they plan to do, and they‚Äôve recently accomplished, all without leaving Slack.</p><p>üìé <strong>Integrations</strong> ‚Äî Easily attach work from tools like GitHub, Jira, Asana, Google Docs, Calendar, and <a href="https://www.range.co/product/integrations">many more</a>.</p><p>‚ú® <strong>Build team culture</strong> ‚Äî We‚Äôve included over 300+ team questions to help your team grow closer even when everyone‚Äôs apart.</p><p><img src="https://cdn.sanity.io/images/e422uarq/production/c9fc4465a950402f7947341666c9a7623a588203-1920x1162.jpg?fm=jpg&amp;w=660&amp;dpr=2&amp;q=40" alt="Screenshots of Range Slack App"></p><h3>All the little details</h3><p>We listen to our customers and obsess over the details. Here‚Äôs just a few of the thoughtful features we‚Äôve built in collaboration with early testers:</p><p>üßµ <strong>Threaded notifications</strong> ‚Äî Keep your team channel tidy with one thread that organizes everyone‚Äôs Check-in each day.</p><p>üí¨ <strong>Comments</strong> ‚Äî Reply to comments from within Slack. You can even see the whole message thread for context.</p><p>üîñ <strong>Remember tasks</strong> ‚Äî When someone asks you to do something in Slack, just click the [...] button on the message and choose ‚ÄúAdd to my plan‚Äù in Range.</p><p>ü§ì <strong>Slash commands</strong> ‚Äî For you experts, we‚Äôve added a bunch of new commands. ‚Äú/checkin‚Äù lets you check in to Range from anywhere. There‚Äôs also some bonus commands like ‚Äú/range timezones‚Äù. Type ‚Äú/range help‚Äù to see them all.</p><p>üè† <strong>Slack App Home</strong> ‚Äî Click on ‚ÄúRange‚Äù in your Slack sidebar, and you‚Äôll see up-to-date lists of who‚Äôs checked-in on your teams.</p><h3>See how it works</h3><p><iframe allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" frameborder="0" title="YouTube Video Demo: Range app for Slack" src="https://www.youtube.com/embed/6K8akNmpg-k?enablejsapi=1&amp;modestbranding=1&amp;rel=0&amp;showinfo=0&amp;autoplay=0&amp;origin=https://www.range.co"></iframe></p><h3>What customers are saying</h3><p>Range has helped teams feel more connected, focused, and productive. But we'll let them speak for themselves:</p><blockquote>"With Slack reminders to Check-in every morning, and message threading, it's been easy for the team to start using Range."<br>‚Äî Mercer Borris, Software Engineer at Eight Sleep</blockquote><blockquote>‚ÄúWith Range check-ins, it doesn't matter if we're in different cities or countries, we still know what each other is working on and the plan for the day.‚Äù<br>‚Äî Gabriel Marcondes, Engineer at Carta</blockquote><blockquote>‚ÄúRange has helped me greatly in the transition to remote life.‚Äù<br>‚Äî Sarah Murphy, UX Designer at Snaps.io</blockquote><h3>Try out Range ‚Äî It‚Äôs free!</h3><p>If you think your team could benefit from Check-ins, please give Range a try. It‚Äôs totally free for teams of up to 10 people, and it‚Äôs easy to get started.</p><p><strong><a href="https://api.range.co/redirects/slack" rel="noopener">Add Range to your Slack Workspace</a><br></strong>or <a href="https://www.range.co/product/slack">Learn more</a> about the Range app for Slack.</p><p><em>Already using Range? You can <a href="https://help.range.co/en/articles/4260365-how-to-connect-range-to-slack" rel="noopener">add Range to Slack</a>, or <a href="https://help.range.co/en/articles/4263964-upgrading-to-the-range-app-v2-for-slack" rel="noopener">upgrade your Slack app</a>, and you‚Äôll get all the new features right away.</em></p><p>From the whole team at Range, we hope our work helps your team feel more connected in these times when it seems harder than ever. Please do <a href="mailto:feedback@range.co?subject=Range%20app%20for%20Slack">let us know what you think</a> of Range and how we can continue to build great products for your team.</p></div></div></section></div>]]>
            </description>
            <link>https://www.range.co/blog/new-range-app-for-slack</link>
            <guid isPermaLink="false">hacker-news-small-sites-23898668</guid>
            <pubDate>Mon, 20 Jul 2020 15:21:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Look at Early Japanese Typewriters (2016)]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 19 (<a href="https://news.ycombinator.com/item?id=23898649">thread link</a>) | @caust1c
<br/>
July 20, 2020 | https://filthyplaten.com/2016/07/23/__trashed/ | <a href="https://web.archive.org/web/*/https://filthyplaten.com/2016/07/23/__trashed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><a href="https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg"><img data-attachment-id="2747" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/olivetti-angle/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg" data-orig-size="1000,562" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="olivetti angle" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg?w=700" title="" src="https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><a href="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg"><img data-attachment-id="2746" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/fullsizerender-7/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg" data-orig-size="3264,566" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 6 Plus&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1469299298&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.15&quot;,&quot;iso&quot;:&quot;125&quot;,&quot;shutter_speed&quot;:&quot;0.25&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="fullsizerender" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=700" title="" src="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=1396 1396w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=1024 1024w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
A little while ago a friend of mine by the name of John Munroe sent me this great little Olivetti 32 ‚ÄòKatakana‚Äô typewriter. I‚Äôd been keeping an eye out for such a machine for a number of years now, but as you may expect ‚Äì such typewriters are generally non existent in markets that are available to Australia.</p>
<p>I spoke to John a little while back after he found a Royal that was set up for Japanese somewhere online, and I asked him to keep an eye out for one for my foreign language collection. John lives in Tokyo, and was confident that he‚Äôd come across another one pretty quickly.</p>
<p>And quickly he did. It wasn‚Äôt long before he managed to get his hands on this magnificent Olivetti Lettera 32. Of all the L32‚Äôs I have had, after this guy was cleaned up I found that &nbsp;types nicer than any other machine I have ever owned of this model.</p>
<p>So John Munroe. I owe you heaps, and much more than a huge, huge thank you!</p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg"><img data-attachment-id="2748" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/olivetti-side/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg" data-orig-size="1000,601" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="olivetti side" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg?w=700" title="" src="https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
I‚Äôm very grateful to John for sending me this machine. Back when I was at high school, we were required to study two languages. Japanese and German. I was far better at German than Japanese, but I have long had a fascination with Japanese &nbsp;culture. My sister also lived there for 10 years and is fluent in Japanese.</p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg"><img data-attachment-id="2749" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/olivetti-keyboard-overview/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg" data-orig-size="1000,562" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="olivetti keyboard overview" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg?w=700" src="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
Katakana is only one piece of Japanese written language, and is often used to articulate English words into Japanese.</p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg"><img data-attachment-id="2750" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/olivetti-keyboard/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg" data-orig-size="1000,509" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="olivetti keyboard" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg?w=700" src="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
The history of the Katakana keyboard dates right back to the late 1800‚Äôs. But it really came into existence in the 1920‚Äôs &nbsp;when some members of society in Japan were pushing for a simplified or reduced version of the Japanese language. The idea was to use that Katakana syllabary in a gestalt structure that is closer to the structure of European languages. While earlier keyboards were designed with a full set of Katakana glyphs (Kana), later they used dead keys on keyboards to allow the completion of characters.</p>
<p>This Olivetti has a couple of dead keys. Note the placement of the ‚ÄòP‚Äô key? Right next to that‚Ä¶ On the left, is the first dead key to be found on the keyboard. If found this positioning especially peculiar.</p>
<p><b>But wait..</b></p>
<p>What about the English characters on this typewriter?</p>
<p>Ahhhh yes‚Ä¶ Well‚Ä¶ That decreases the Kana (Katakana means Fragmented Kana) characters used one this keyboard.. Right?</p>
<p>The thing about katakana is, that it is also used in circumstances where English words are crammed into Japanese language ‚Äì in the way that in English we italicise foreign language words.</p>
<p>So what does this typewriter do?</p>
<p>John‚Äôs suggestions that it is a typewriter that would be in use by telegraph operators to move between Japanese and English is a pretty sound one. Katakana can be used as a simplified Japanese language.</p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg"><img data-attachment-id="2752" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/fullsizerender2/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg" data-orig-size="1024,194" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="fullsizerender2" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg?w=700" src="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg 1024w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
But it could also be used in a studio to produce Katakana segments for English words on this machine ‚Äì when the writer was using a different keyboard featuring other kana ‚Äì Say‚Ä¶ Hiragana. But I don‚Äôt think so. The push in Japanese society was based around making language more universal. Contentiously, several key developments occurred when there was a push in Japanese society towards using English langauge more universally. Although the by the late 40‚Äôs ‚Äì post World Ward 2, there was also a push towards using French.</p>
<p>Either way, in the 20‚Äôs the first Typewriters &nbsp;were being produced based to write a &nbsp;in romanized gestalt structure in Katakana. Just for reference, the company that produced these first machines was Underwood ‚Äì who Olivetti eventually bought and absorbed into their organization.</p>
<p><b>Let‚Äôs not mention Kanji.&nbsp;</b></p>
<p>No‚Ä¶ Let‚Äôs. Let‚Äôs talk about Kanji.</p>
<p>Written Japanese language can be something of a horror to people that grew up outside of Japan. Even inside of it, there‚Äôs plenty of things that can ‚Äì and do ‚Äì often go wrong. It‚Äôs not that romanised languages are perfect ‚Äì but the diverse structure in Japanese (a problem also shared with Chinese languages) often causes complexities. The positive thing about Kanji is that it allows for quite an efficient expression with more nuance.</p>
<p>So‚Ä¶ Like every other language in existence, there‚Äôs plenty of people that take a much more puritanical view to their language and many &nbsp;in Japan resisted change. The problem was that there wasn‚Äôt much of a way to easily produce written documents on a machine. Considering that the Japanese language has thousands of characters ‚Äì it obviously wasn‚Äôt going to be easily presented on the keyboard unless the keyboard was huge.</p>
<p>Enter item number 2 that is new to my collection. &nbsp;Welcome to the Nippon Type.</p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg"><img data-attachment-id="2751" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/nippon-angle/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg" data-orig-size="1000,628" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="nippon angle" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg?w=700" src="https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
Over a century ago the Japanese started producing heavy and lumbering machines that had thousand of typeface characters that operated wtih a feed mechanism which pulled characters out of a grill. It involved moving the carriage over the top of the grill and positioning it above the character and then feeding it upwards to a type hammer that pushed it against the page and the ribbon. It then drops the hammer back, and the character falls back into the grill.</p>
<p>This mechanism improved dramatically in later years, and instead of a moving carriage, the grill floated on a rack which moved under the carriage.</p>
<p>Eventually a character board was put in front of the carriage, allowing the user to type by moving the arm that was connected to the grill, that has a stylus on the end that the user points at a desired character with.</p>
<p>The characters are grouped into syllabary or kana, and kept together in an order that is predictable. As you can see in the photo below such groups are colored to make it easier for the typist.</p>
<p><b>Enter the Nippon Type.&nbsp;</b></p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg"><img data-attachment-id="2753" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/nippon-front/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg" data-orig-size="1000,605" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="nippon front" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg?w=700" src="https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><b><br>
</b></p>
<p>On the left of the machine is a solid arm that has a black knob that operates the character pulling mechanism. The small black lever next to that is the space bar. This allows the typist to quickly use operate with their left hand, while swinging the arm with the stylus with their right ‚Äì selecting characters and quickly tapping it in.</p>
<p>The carriage has a large black lever that operates like every other carriage lever. Interestingly, the machine is set up to type right to left with the characters positioned to be read along the page, rather than down it as was traditional. Maybe the Katakana brigade made some in-roads there.</p>
<p>Interestingly, the typewriter also has a group of Roman characters grouped on the machine, allowing the user to type in English ‚Äì or at use least English word. These are also regarded as Kana ‚Äì and known as Romaji.</p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg"><img data-attachment-id="2754" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/nippon-elements_/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg" data-orig-size="1000,562" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="nippon elements_" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg?w=700" src="https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
The characters are kept in a smooth moving tray that feels like it is floating under the machine. When the mechanism operatingarm is pulled down on the machine you can feel the tray Bing pulled into alignment to the closest character. Then the mechanism starts and the hammer makes a solid thump as it punches a character piece against the platen. It‚Äôs a surprisingly noisy operation. But quick.</p>
<p>To reduce the noise around the typewriter the rear of the machine has a noise deadening bulkhead that is supposed to absorb some of the noise.</p>
<p>But it isn‚Äôt anywhere near as fast as typing on a keyboard. The efficiencies that most typewriters produce for writers are all but wiped out by the movement which is more energy consuming than writing Kana by hand by hand.</p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg"><img data-attachment-id="2757" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/nippon-back/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg" data-orig-size="1000,656" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="nippon back" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg?w=700" src="https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
This machine belonged to a former Australian Journalist that had been living in Japan and working there. I bought this machine off his daughter who was moving house on the day that I arrived to collect it. I can understand the appeal of this machine to a journalist in a foreign country. It would give a great refer ace board to access all the Japanese Kana on, which would make it quicker to learn and access. Obviously it has some great advantages over handwriting for legibility as well</p>
<p>The interesting thing about this machine is that ‚Äì unlike the lumbering and heavy old &nbsp;Japanese typewriters of the early years, this beast is surprisingly light ‚Äì weighing less than an Olympia SM4 in its case.</p>
<p>Sadly though, some of the type elements are missing, so the machine isn‚Äôt complete. Although interestingly enough, type elements can still be ordered.</p>
<p>Anyway, this is just a brief look at that crazy world that is Japanese typewriting. I hope you found these machines interesting. I‚Äôll have a closer look at both and maybe their history in another post.</p>
<p>Thanks for reading.</p>
			
			
						</div></div>]]>
            </description>
            <link>https://filthyplaten.com/2016/07/23/__trashed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23898649</guid>
            <pubDate>Mon, 20 Jul 2020 15:19:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Largest NLP Model Can Now Generate Code Automatically]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23898493">thread link</a>) | @yadavrohit
<br/>
July 20, 2020 | https://analyticsdrift.com/the-largest-nlp-model-can-now-generate-code-automatically/ | <a href="https://web.archive.org/web/*/https://analyticsdrift.com/the-largest-nlp-model-can-now-generate-code-automatically/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                    <!-- .entry-header -->

                
                        <div>
                                    <p><img width="960" height="709" src="https://analyticsdrift.com/wp-content/uploads/2020/07/AI-that-can-code.jpg" alt="AI that can code" srcset="https://analyticsdrift.com/wp-content/uploads/2020/07/AI-that-can-code.jpg 960w, https://analyticsdrift.com/wp-content/uploads/2020/07/AI-that-can-code-300x222.jpg 300w, https://analyticsdrift.com/wp-content/uploads/2020/07/AI-that-can-code-768x567.jpg 768w" sizes="(max-width: 960px) 100vw, 960px">                </p>
            
                                            </div>

            

        <!-- end slider-section -->
                                    

    <div>
        <div>
            
<p>GPT-3, the largest natural language processing model, was developed by OpenAI and released on 28 May 2020. Since its release, many developers tried their hands with the GPT-3 model. Similarly, <a href="https://twitter.com/sharifshameem?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1282676454690451457%7Ctwgr%5E&amp;ref_url=https%3A%2F%2Fanalyticsindiamag.com%2Fopen-ai-gpt-3-code-generator-app-building%2F">Sharif Shameem</a>, founder of <a href="https://debuild.co/">debuild</a>, tweeted a post in which he showed how GPT-3 can code automatically just by providing instruction.</p>



<figure><div>
<blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>This is mind blowing.</p><p>With GPT-3, I built a layout generator where you just describe any layout you want, and it generates the JSX code for you.</p><p>W H A T <a href="https://t.co/w8JkrZO4lk">pic.twitter.com/w8JkrZO4lk</a></p></div>‚Äî Sharif Shameem (@sharifshameem) <a href="https://twitter.com/sharifshameem/status/1282676454690451457?ref_src=twsrc%5Etfw">July 13, 2020</a></blockquote>
</div></figure>



<p>Shameem trained the model with just two samples, which you can see below.</p>



<figure><img src="https://lh4.googleusercontent.com/cZ2KVKDmUby8gFoAP-7x1dwEMpT0aJA69j4w7u_S3y6skXTsyBQ19mzLpIPsfs2B0CppyN55W1nnGnq3V16ifakWy7MCfZC53g7eMg67ZfdtYwDdyVhZ8u0rQMuHkiVDU_jAmqPQ" alt=""></figure>



<p>However, this doesn‚Äôt mean that it can write the complete code for your projects. Such short tricks work well on social media and might not be able to help you immediately. Undoubtedly, this brings us to the question of whether AI can code. Maybe someday it would, but we are no way near to rely on AI for writing code.</p>



<p>Also Read: <a href="https://analyticsdrift.com/these-5-technology-trends-will-shape-our-lives-in-2020/">These 5 Technology Trends Will Shape Our Lives In 2020</a></p>



<p>Currently, OpenAI‚Äôs GPT-3 is overhyped, which was also pointed by the CEO of OpenAI. ‚ÄúThe GPT-3 hype is way too much. It‚Äôs impressive (thanks for the nice compliments!) but it still has serious weaknesses and sometimes makes very silly mistakes. AI is going to change the world, but GPT-3 is just a very early glimpse. We have a lot still to figure out,‚Äù wrote Altman in this <a href="https://twitter.com/sama/status/1284922296348454913">tweet</a>.</p>



<p>GPT-3 code generator is fascinating, and you might get your hands on it as Shameem is planning to make it public. Replying to one of the comments on this post, Shameem also mentioned that he believes that we can have AI that can code in less than ten years.</p>



<p>The use of natural language is not new; many dashboards such as Qlik and Power BI leverage NLP to pull up reports or insights from data. The reports are generated by converting the plain English text into forming code and then extracting results from a colossal amount of data. But, this is a massive development in the AI landscape, which can further the advancement of ML models that can write its own code.</p>



<p>OpenAI‚Äôs GPT-3 <a href="https://arxiv.org/abs/2005.14165">paper</a>.</p>
                <div>
                    
                                        
        <div>

                <p><a href="https://analyticsdrift.com/author/analytics-drift-staff/"><img alt="" src="https://secure.gravatar.com/avatar/16b69b6f3d9c508cbf71716754e72d55?s=150&amp;r=g" srcset="https://secure.gravatar.com/avatar/16b69b6f3d9c508cbf71716754e72d55?s=300&amp;r=g 2x" height="150" width="150"></a>
                </p>
                
        </div>

                                            </div>
                                            
                        
	<nav role="navigation" aria-label="Continue Reading">
		<h2>Continue Reading</h2>
		
	</nav>                    </div><!-- .entry-content -->
    </div>
                        </div></div>]]>
            </description>
            <link>https://analyticsdrift.com/the-largest-nlp-model-can-now-generate-code-automatically/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23898493</guid>
            <pubDate>Mon, 20 Jul 2020 15:02:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Screwed by Lufthansa and the German Government, Saved by PayPal]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 19 (<a href="https://news.ycombinator.com/item?id=23898423">thread link</a>) | @ZeljkoS
<br/>
July 20, 2020 | https://svedic.org/travel/screwed-by-lufthansa-german-government-saved-by-paypal | <a href="https://web.archive.org/web/*/https://svedic.org/travel/screwed-by-lufthansa-german-government-saved-by-paypal">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span data-preserver-spaces="true">The travel and tourism sectors are suffering because of the COVID-19 pandemic, and governments are scrambling to offer subsidies to affected businesses. But, there is little talk on how companies are transferring their costs to citizens, with government approval.</span></p><p><span data-preserver-spaces="true">In this case, the company is Lufthansa, who canceled my May flight from Croatia to Germany three weeks before the flight date. I booked the flight before the pandemic started, so I was a bit relieved. My reason for being in Berlin was valid for entry, but I was to either self-isolate for two weeks or get tested for COVID-19, both a hassle. If Lufthansa decided to cancel the flight and return the money, no problem.</span></p><p><span data-preserver-spaces="true">But that is not what Lufthansa decided. Their <a href="https://svedic.org/wp-content/uploads/2020/07/Lufthansa-cancelation-email.png" target="_blank" rel="noopener noreferrer">cancellation email didn‚Äôt mention refunds, but offered flight vouchers instead</a>. As the email was a no-reply email, calling customer support was the only option. Lufthansa‚Äôs support representative agreed to issue a full refund. But they said that processing the refund can take up to six weeks, as they are overwhelmed with requests. EU consumer protection law requires refunds for an undelivered product or service to be issued within 30 days, but these are exceptional times, so I agreed. What Lufthansa didn‚Äôt agree to was stating that in writing, in a letter or email.</span></p><p><span data-preserver-spaces="true">Six weeks came and passed without a refund. On a second call, Lufthansa‚Äôs support representative repeated the story. They are overwhelmed with requests, my refund will be processed in 2-3 weeks, no need to worry, but they will not provide that statement in writing.&nbsp;</span></p><p><span data-preserver-spaces="true">While waiting for their promise, I stumbled across an article explaining my issue as part of a bigger, EU-wide story. Lufthansa was on the verge of bankruptcy and <a href="https://www.theguardian.com/business/2020/may/26/lufthansa-9bn-bailout-german-government-coronavirus-flights" target="_blank" rel="noopener noreferrer">agreed to a ‚Ç¨9 billion bailout from the German government</a>. In an effort to save the company, <a href="https://onemileatatime.com/lufthansa-refund-policy/" target="_blank" rel="noopener noreferrer">the German government told Lufthansa that they don‚Äôt need to obey EU consumer protection law</a>, and that they don‚Äôt need to issue refunds. Lufthansa can issue vouchers for future travels instead. This situation is controversial because:</span></p><ul><li><span data-preserver-spaces="true">The German government is telling a German company they don‚Äôt need to follow EU law.</span></li><li><span data-preserver-spaces="true">The German government is playing favorites with one company. Other companies don‚Äôt have such luxury during the crisis, both in getting the loan or escaping the laws.</span></li><li><span data-preserver-spaces="true">German tax-payers are giving a large, risky loan to one air carrier.</span></li><li><span data-preserver-spaces="true">With the voucher system, other EU citizens are effectively giving indefinite, interest-free loans to Lufthansa.</span></li></ul><p><span data-preserver-spaces="true">Notice that the procedure of getting a voucher from Lufthansa is much easier than getting a refund. For a voucher, click on the link in the email and fill a form. For a refund, wait on the customer support line. But I am a stubborn person, and I hate vouchers. A few times in my life, given vouchers got unused or companies put restrictions on voucher use. In this case, there is a possibility Lufthansa will go bankrupt, and then their vouchers will be as useful as toilet paper. Wait, that may <a href="https://www.bbc.com/news/world-australia-51731422" target="_blank" rel="noopener noreferrer">come in handy in COVID-19 times!</a></span></p><p><span data-preserver-spaces="true">I was not surprised when three weeks passed and there was no refund. I felt screwed by Lufthansa, the EU, and German politicians. However, there was still one overseas ace up my sleeve I could use.&nbsp;</span></p><p><span data-preserver-spaces="true">I paid for my flight via PayPal, which offers consumer protection on purchases, and I decided to activate it. I didn‚Äôt have much hope, as worldwide pandemic cancellations were not typical PayPal disputes. Additionally, I didn‚Äôt have much proof except for the cancellation email. Lufthansa didn‚Äôt provide a written reply, the flight was erased from the Lufthansa website, and I didn‚Äôt record phone conversations.&nbsp;</span></p><p><span data-preserver-spaces="true">But, as soon I made my claim, I realized there is a hidden benefit. When a PayPal claim is created, there is a deadline and a written trail. In this case, Lufthansa was given until July 13th to respond:</span></p><p><a href="https://svedic.org/wp-content/uploads/2020/07/PayPal-deadline.jpg"><img title="PayPal deadline screenshot" src="https://svedic.org/wp-content/uploads/2020/07/PayPal-deadline.jpg" alt="" width="927" height="317" srcset="https://svedic.org/wp-content/uploads/2020/07/PayPal-deadline.jpg 927w, https://svedic.org/wp-content/uploads/2020/07/PayPal-deadline-300x103.jpg 300w, https://svedic.org/wp-content/uploads/2020/07/PayPal-deadline-768x263.jpg 768w, https://svedic.org/wp-content/uploads/2020/07/PayPal-deadline-500x171.jpg 500w" sizes="(max-width: 927px) 100vw, 927px"></a></p><p><span data-preserver-spaces="true">It seems that someone from Lufthansa replied before that, as I got my money on July 7th:</span></p><p><span data-preserver-spaces="true"><a href="https://svedic.org/wp-content/uploads/2020/07/PayPal-case-history.jpg"><img src="https://svedic.org/wp-content/uploads/2020/07/PayPal-case-history-197x300.jpg" alt="PayPal-case-history" width="197" height="300" srcset="https://svedic.org/wp-content/uploads/2020/07/PayPal-case-history-197x300.jpg 197w, https://svedic.org/wp-content/uploads/2020/07/PayPal-case-history.jpg 540w" sizes="(max-width: 197px) 100vw, 197px"></a></span></p><p><span data-preserver-spaces="true">I am impressed by PayPal‚Äôs straightforward claims procedure. There was no paper forms or PDFs that I needed to sign. As an example, my friend Chris also got a Lufthansa April transatlantic flight canceled (a month before my trip). He asked Lufthansa for a refund, and to this day he still hasn‚Äôt received any of 700 EUR.</span></p><p><span data-preserver-spaces="true">You have all the facts above, so make your conclusions. These are my modest takeaways:</span></p><ul><li><span data-preserver-spaces="true">During a crisis, EU laws get overridden by national interests.</span></li><li><span data-preserver-spaces="true">During a crisis, businesses labeled a ‚Äúnational interest‚Äù by politicians get favorable treatment.</span></li><li><span data-preserver-spaces="true">PayPal consumer protection works, even in times of crisis.</span></li><li><span data-preserver-spaces="true">Creating a PayPal or credit company claim is easier than waiting on customer support lines, enforces deadlines, and has traceable communication.</span></li></ul><p><span data-preserver-spaces="true">To come to the beginning of this article, there are analyses of money lost by different business sectors due to COVID-19. It would be interesting to see an analysis of how much consumer money is currently locked in unused vouchers, and what percentage of them will actually get used in the future. For comparison, in normal times, just US consumers </span><a href="https://www.cbsnews.com/news/unused-gift-cards-add-up-to-3-billion-annually/" target="_blank" rel="noopener noreferrer"><span data-preserver-spaces="true">lose up to $3 billion annually in unspent gift cards</span></a><span data-preserver-spaces="true">. It seems that 2020 is going to be an outlier.</span></p></div></div>]]>
            </description>
            <link>https://svedic.org/travel/screwed-by-lufthansa-german-government-saved-by-paypal</link>
            <guid isPermaLink="false">hacker-news-small-sites-23898423</guid>
            <pubDate>Mon, 20 Jul 2020 14:55:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Code Review Checklist. Share what practices you follow?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23897940">thread link</a>) | @mkfeuhrer
<br/>
July 20, 2020 | https://mohitkhare.me/blog/code-reviews/ | <a href="https://web.archive.org/web/*/https://mohitkhare.me/blog/code-reviews/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <!-- Toc if any -->
                
                <!-- End Toc -->
                <p>Code Reviews are an essential component of the development cycle at almost every company. If you are not doing code reviews, you should probably start it.</p>

<p>Code Reviews is a process where before the code goes into production (or merged in master), some feedback is given on these code changes by a fellow developer. It is quite often the case when the developer misses out on some cases or unintentionally reduces code quality, with an extra pair of eyes such mistakes are avoided before they get to users.</p>

<p>Let‚Äôs answer the <strong>Why before How!</strong></p>

<h2 id="why">Why‚ùì</h2>

<ul>
  <li>Identifying naive issues like debug statements, comments in commits.</li>
  <li>Helps in following best coding practices and principles üíª resulting in a quality, maintainable code.</li>
  <li>Eliminates bug üï∑ which got introduced unintentionally.</li>
</ul>

<h2 id="checklist-">Checklist üöÄ</h2>

<ul>
  <li>No compilation errors, automated pipelines like <code>code quality</code> (which does static analysis + build) are passing.</li>
  <li>All tests are passing üíö - both Unit and Integration and coverage is above threshold. (Run the code and test offline as well)</li>
  <li>No debugging statements or irrelevant comments ü§ñ</li>
  <li>Proper git log with proper messages. See, it commits are squashed.</li>
  <li>Check if PR clearly states what it does and there are no additional changes in code.</li>
  <li>See if there can be a simplified implementation for a function/feature.</li>
  <li>Are there are extra dependencies added? Can they be removed? Are they stable?</li>
  <li>Does it follow engineering practices like KISS, DRY, YAGNI?</li>
  <li>Check if any edge cases are missed.</li>
  <li>Proper logging and metrics is done. Are the logs relevant?</li>
  <li>Error is handled properly and not causes any fatal crashes ‚ùå. (No downtimes, right! ). Code should be failure tolerant and should have a graceful shutdown.</li>
  <li>Ensure configurations are not hardcoded</li>
  <li>Check if API Documentation, README,md and Changelog üìÑ are updated or not?</li>
  <li>Do these changes hamper the performance üìà in any way? Is the response time increasing or are more DB calls are made?</li>
  <li>Do these changes need to be conveyed to other teams who consume this product/service.</li>
  <li>Are any security vulnerabilities üí£ introduced (usually there is separate whitelisting, but it‚Äôs good to do basic checks here as well)</li>
</ul>

<h2 id="practices-and-tips-">Practices and Tips üí°</h2>

<ul>
  <li>Ask for shorter PRs. Shorter the PR -&gt; Fewer issues + Easy to review -&gt; Less time is taken to resolve if there are any issues. Don‚Äôt do reviews for more than 60 minutes!</li>
  <li>Clearly explain in comments what you think is missing or how can this be improved!</li>
  <li>Code should be as simple as possible. If it‚Äôs easy to understand and review, it will be easier to debug later as well.</li>
  <li>Code is properly broken into small functions, it follows engineering principles like <a href="https://mohitkhare.me/blog/solid-dry-kiss-yagni/">SOLID, YAGNI, KISS and others</a>.</li>
  <li>Proper naming and description for commits, code variables.</li>
  <li>Automate whatever you can. Use <a href="https://github.com/codefactor-io/awesome-static-analysis">static analysis tools</a>. Add CI/CD pipelines for compilation, build and testing.</li>
  <li>Don‚Äôt do code reviews in a hurry ‚è∞ Take your time - you never know even a small condition may introduce fatal bugs.</li>
  <li>Don‚Äôt be rude, show respect! Everyone makes mistakes ü§ì</li>
</ul>

<h2 id="resources-">Resources üìö</h2>

<ul>
  <li><a href="https://www.ibm.com/developerworks/rational/library/11-proven-practices-for-peer-review/index.html">IBM practices</a></li>
  <li><a href="https://kinsta.com/blog/code-review-tools/#a-closer-look-at-12-powerful-code-review-tools">Code Review Tools</a></li>
</ul>

<p>I hope you learned something useful. Do follow these tips when doing your next code reviews. Share it with your teammates and colleagues ‚úåÔ∏è</p>

<p>Feel free to suggest improvements ‚úîÔ∏è</p>

<h3 id="stay-home-stay-safe">Stay Home! Stay Safe!</h3>

<hr>

<p>I hope you learned something interesting and new. Don‚Äôt miss out on the latest blogs‚Ää‚Äî‚Ää<a href="http://eepurl.com/g2Mbc9">Subscribe now</a></p>

<p>Interested in more technology, productivity and life stuff? I share updates/knowledge almost daily on <a href="https://twitter.com/mkfeuhrer">Twitter</a>.</p>

<p>Reach out to me at <a href="https://mohitkhare.me/">https://mohitkhare.me/</a></p>

    
            </div></div>]]>
            </description>
            <link>https://mohitkhare.me/blog/code-reviews/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23897940</guid>
            <pubDate>Mon, 20 Jul 2020 14:03:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Learn How to Build, Launch and Run a Shopify App]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23897934">thread link</a>) | @igrabes
<br/>
July 20, 2020 | https://courses.iangrabill.com/how-to-build-a-shopify-app | <a href="https://web.archive.org/web/*/https://courses.iangrabill.com/how-to-build-a-shopify-app">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://courses.iangrabill.com/how-to-build-a-shopify-app</link>
            <guid isPermaLink="false">hacker-news-small-sites-23897934</guid>
            <pubDate>Mon, 20 Jul 2020 14:02:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A man trying to automate Thailand‚Äôs hospitals]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 6 (<a href="https://news.ycombinator.com/item?id=23897845">thread link</a>) | @danso
<br/>
July 20, 2020 | https://restofworld.org/2020/the-man-trying-to-automate-thailands-hospitals/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/the-man-trying-to-automate-thailands-hospitals/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><span>O</span>n a balmy Bangkok afternoon in March 2020, Professor Djitt Laowattana was sitting in his second-floor office in the Institute of Field Robotics (FIBO), <a href="https://www.nytimes.com/2020/02/23/world/europe/italy-coronavirus.html">watching the news</a> out of Italy. Photos of doctors with<a href="https://www.cnn.com/2020/03/21/world/health-workers-doctors-photos-coronavirus-italy-wuhan-trnd/index.html"> faces marked from their masks</a> spread across social media as the country rapidly became the epicenter of Europe‚Äôs Covid-19 outbreak. ‚ÄúI told my staff, stop what you‚Äôre doing and focus on this,‚Äù Laowattana told <em>Rest of World</em>. ‚ÄúI wanted to make sure the same thing doesn‚Äôt happen in Thailand.‚Äù</p>



<p>His concerns were correct. According to <a href="https://www.icn.ch/news/more-600-nurses-die-covid-19-worldwide">recent estimates</a> by the International Council of Nurses, nearly half a million healthcare workers may have been infected by the virus. Thailand had already confirmed its first Covid-19 death by the end of February, and <a href="https://www.pri.org/stories/2020-02-07/virus-fears-spread-thailand-chinese-tourism-magnet">experts warned</a> that the country could become the next Covid-19 hot spot in the region. Sensing the urgency, Laowattana, who is known as Thailand‚Äôs most prolific roboticist, asked his staff to drop working on the 20 or so prototypes they had in various stages in production and focus on helping him create an arsenal to fight what he called ‚Äúthe great virus war.‚Äù Together, Laowattana and his team of students and engineers created FIBO Against Covid-19 (FACO), a group of fully autonomous robots designed to protect doctors and nurses on the front lines of the pandemic.&nbsp;</p>



<p>Over the last 20 years, Laowattana has built nearly 300 types of robots for industries ranging from food processing to automobiles, half of which are still used today. His innovations have earned him the moniker ‚Äúthe Godfather of Thai Robotics.‚Äù His robots do everything from disinfecting rooms and delivering supplies to remotely monitoring patients‚Äô temperatures and symptoms.</p>



<p>In hopes of rapidly scaling the use of these robots, Laowattana also added 5G connectivity, which will allow hospitals to add as many robots as they need without overloading their systems. ‚ÄúI don‚Äôt like the coronavirus,‚Äù said Laowattana, ‚Äúbut the pandemic is a fast-forward button.‚Äù</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/GettyImages-1210699444-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/GettyImages-1210699444-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/GettyImages-1210699444-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/07/GettyImages-1210699444-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2020/07/GettyImages-1210699444-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/07/GettyImages-1210699444-2800x1867.jpg 2800w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="BANGKOK, THAILAND - APRIL 22: Medical staff wearing PPE work in the acute respiratory illness clinic in Vibhavadi Hospital as they deal with the COVID-19 Coronavirus outbreak on April 22, 2020 in Bangkok, Thailand. The hospital is due to discharge their final coronavirus patient today as numbers of infections continue to drop across the country. The Thai government has imposed a 10pm to 4am curfew and has ordered the closure of entertainment venues, schools and parks in order to curb the spread of the COVID-19 coronavirus across the country. (Photo by Jack Taylor/Getty Images)">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Jack Taylor/Getty Images</span>
			</figcaption>
		</figure>


<hr>



<p><strong>Since the pandemic</strong> began, hospitals around the world have adopted robots for everything from cleaning hospital wards to allowing patients to socialize with friends and family while quarantined. Recent estimates predict the medical robotics industry will quadruple to <a href="https://www.prnewswire.com/news-releases/surgical-robots-market-growth%E2%80%94-24-4-cagr-up-to-2025%E2%80%94says-global-market-insights-inc-300984546.html">more than $24 billion</a> by 2025, from around $6 billion in 2018. Thailand also faces a shortage of nurses, a problem that‚Äôs been exacerbated by the pandemic. Laowattana hopes his robots may be able to lighten their load and allow them to focus on more-critical tasks.&nbsp;</p>



<p>‚ÄúThe genie is out of the bottle,‚Äù Robin Murphy, a robotics professor at Texas A&amp;M, told <em>Rest of World</em>. ‚ÄúIt‚Äôll get to a point where it‚Äôs not going to shock anyone that robots are wandering around a hospital.‚Äù</p>



<p>Thailand is keen to develop its medical robots. Last year, the <a href="https://www.mobihealthnews.com/content/thailand-board-investment-help-promote-medical-robotics">government announced</a> an eight-year tax break for manufacturers of medical robots and released statements encouraging hospitals to use medical robots. According to Laowattana, the virus came at a fortuitous moment.</p>



<p>After a month of blueprinting and prototyping, in early April, Laowattana introduced his arsenal to a select group of doctors from Thailand‚Äôs most prestigious teaching hospitals. He had two new robots.&nbsp;</p>



<figure><blockquote><p>‚ÄúI don‚Äôt like the coronavirus, but the pandemic is a fast-forward button.‚Äù</p></blockquote></figure>



<p>The first was CARVER. Prototyped in FIBO‚Äôs headquarters and equipped with ultraviolet lights to disinfect wards as it moves, CARVER looks like a giant Roomba dressed for a rave. The robot‚Äôs 18&nbsp;shelves also help carry medicine and other essential supplies to Covid-19 patients. Laowattana hoped CARVER would reduce the amount of exposure for nurses commonly assigned to routine but high-risk tasks.</p>



<p>The crown jewel of Laowattana‚Äôs arsenal, however, was SOFA: a 150-centimeter-tall humanoid with a conical lower half that gives it a feminized appearance. Its placid blue and white tones and three protruding high-tech cameras make it look both dainty and unsettling. One camera helps tell a patient‚Äôs temperature, while another is used for video conferencing. On its chest, a third high-definition magnifying camera allows doctors to examine a patient‚Äôs tongue or eyes without ever having to leave their offices. Like CARVER, SOFA can also be programmed to roam autonomously or controlled from afar.&nbsp;</p>



<p>While most telepresence robots help doctors consult with patients remotely, SOFA‚Äôs decked-out sensors also allow doctors to monitor a patient‚Äôs vitals. ‚ÄúWhen the crisis started, we didn‚Äôt have any solutions to help us examine patients from afar,‚Äù Dr. Sithakom Phusanti, deputy director at Chakri Naruebodindra Medical Institute in Bangkok, told <em>Rest of World. </em>Doctors at Phusanti‚Äôs hospital are among the first in Thailand to be able to examine patients in their Covid-19 ward from the comfort of their offices.&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/1594910343458-small-40x23.gif" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/1594910343458-small.gif" data-srcset="" sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p><strong>According to a</strong> study conducted by the University of Edinburgh, hospitals have traditionally been reluctant to introduce robotics in large part due to fears of worker displacement and the negative connotations of robots for healthcare workers and patients alike. To quell some of these anxieties, Laowattana stressed that SOFA isn‚Äôt here to take their jobs. His robots have no diagnostic abilities, and when interacting with patients, a doctor is always in the cockpit.&nbsp;</p>



<p>Designing robots to interact with patients also comes with its own set of challenges. While doctors can adopt a good bedside manner when dealing with vulnerable patients, giving a robot the appearance of congeniality requires both design and cultural considerations.&nbsp;</p>



<p>Laowattana created SOFA by redesigning a prototype of a greeting bot for one of Bangkok‚Äôs luxury malls. He thought its tiny stature and childlike appearance would help disarm otherwise vulnerable patients. He even tweaked SOFA to operate at 10% of its original speed.&nbsp;</p>



<p>‚ÄúIn Thailand, going fast doesn‚Äôt convey good meaning. It‚Äôs impolite,‚Äù he says. When roaming the wards, SOFA projects two baby-blue eyes and a pixelated smile on a small screen, though it can show a range of positive emotions, from surprise to love. A second screen sits on its waist, allowing doctors to remotely share a patient‚Äôs medical records. Its jointed arms and fingers serve no medical purpose, but according to Laowattana, patients would rather communicate with something that looks like themselves. When interacting with patients, SOFA replaces its digital smile with a video of the controlling doctor, reminding patients that a human is still in the driver‚Äôs seat.&nbsp;</p>



<p>SOFA robots have become something of a national treasure in Thailand. They have even <a href="https://www.facebook.com/fibokmutt/posts/3139870376075286">earned a nickname</a> from the country‚Äôs princess: ‚Äú<em>Mod Borirkasa</em>,‚Äù or ‚ÄúGuardian Ant.‚Äù&nbsp;</p>



<p>There are also consequences for culturally inadequate design. In 2018, Bangkok‚Äôs Mongkutwattana General Hospital <a rel="noreferrer noopener" href="https://www.thailandmedical.news/news/acute-shortage-of-nurses-in-thailand-forces-hospital-to-turn-to-robot-nurses." target="_blank">met with internet infamy</a> after photos of its robots‚Äô glowing red eyes spread across the web. Purchased from a manufacturer in China, where red is considered an auspicious color, the robots were perceived as menacing in Thailand. ‚ÄúPeople would joke, if they bring you to our hospital late at night, you better run away,‚Äù a doctor who worked at the hospital told&nbsp;<em>Rest of World</em>.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/IMG_5910-40x29.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/IMG_5910-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/IMG_5910-400x294.jpg 400w, https://restofworld.org/wp-content/uploads/2020/07/IMG_5910-600x440.jpg 600w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p><strong>Despite their initial</strong> hesitance, doctors and nurses at his hospital have responded positively to their new mechanical colleagues, according to Phusanti: ‚ÄúThey believe the system can help prevent viral transmission.‚Äù So far, none of Phusanti‚Äôs staff has been infected by the virus.&nbsp;</p>



<p>But while some doctors have been happy to adopt robotics in the wake of Covid-19, others have said the robots, at their $100,000 price tag, may be untenable for many Thai hospitals. A number of hospitals use cheaper, Chinese-produced robots, in part because they are able to receive them at low costs.&nbsp;</p>



<p>To address this concern, Laowattana has advocated for hospitals to obtain funding from the Thai government to purchase robots throughout the pandemic. While 40 have expressed interest in procuring them ‚Äî pending government funding ‚Äî bureaucratic delays have meant that only three hospitals have received the robots so far. The rest are still awaiting their funds to be approved.</p>



<p>Scaling the operation during a pandemic has also proven difficult, as parts have to be sourced from China and Europe. While FIBO was able to make the robots for three hospitals in-house, the institute partnered with Thailand‚Äôs Automation and Robotics Association (TARA), a consortium of industrial robotics manufacturers, to build more robots. But due to the pandemic, some essential parts have taken nearly three times longer to arrive. While Laowattana hoped to have the robots in eight more hospitals by the end of the month, such sourcing issues mean they may have to wait even longer.</p>



<p>For now, Thailand has successfully contained the virus. As far as his robots go, Laowattana sees their role expanding to treating other infectious patients, like those suffering from tuberculosis.&nbsp;</p>



<p>Two decades ago, Laowattana was considered a fringe scientist by his peers. But the pandemic has been a bittersweet validation of his life‚Äôs work. ‚ÄúI used to tell people that automation will happen over the next five years,‚Äù he said, ‚Äúbut today I tell people, it needs to happen now.‚Äù</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/the-man-trying-to-automate-thailands-hospitals/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23897845</guid>
            <pubDate>Mon, 20 Jul 2020 13:55:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Every Investment Should Look Overpriced]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23897806">thread link</a>) | @kpa325
<br/>
July 20, 2020 | https://moontowermeta.com/you-dont-see-the-whole-picture/ | <a href="https://web.archive.org/web/*/https://moontowermeta.com/you-dont-see-the-whole-picture/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div>
<div>
<h2 dir="auto" data-screenname="KrisAbdelmessih" data-tweet="1282724901854511105"><strong>Overpriced Or Just Overpriced In Isolation</strong></h2>
<p>‚òÄÔ∏èSunblock stock (SUN) makes 10% in sunny year. Loses 2% in rainy year.</p>
<p>‚òÇÔ∏èUmbrella stock (RAIN) loses 2% in sunny year. Makes 2% in rainy year.</p>
<p><strong>Assume:</strong></p>
<ul>
<li>The year is 50% to be sunny.</li>
<li>The risk free rate is 0</li>
</ul>
<p><strong>A few things to think about:</strong></p>
<ol>
<li>SUN has a higher expected return and Sharpe than RAIN</li>
<li>We can see the stocks have -1 correlation</li>
<li>There is an arbitrage. You can put 50% into each stock and earn 4% in sunny years and 0% in rainy years for an EV of +2% on the portfolio</li>
</ol>
</div>
</div>
<div>
<div>
<p><strong>What can we expect?</strong></p>
<p>The market prices of these stocks will adjust to there is no arb.</p>
<p>Let‚Äôs keep it simple and presume:</p>
<ol>
<li>&nbsp;SUN‚Äôs price stays constant so its returns characteristics are unchanged.</li>
<li>RAIN‚Äôs price is to be bid up so it returns only 1% in a rainy year and loses 3% in a sunny year. Note that RAIN‚Äôs expected value is now -1% per year instead of zero.</li>
</ol>
</div>
</div>
<div>
<div>
<div id="tweet_3" dir="auto" data-screenname="KrisAbdelmessih" data-tweet="1282724907948941312"><p><strong><strong>Why would the market bid that much?</strong></strong></p>
</div>

<div dir="auto" data-screenname="KrisAbdelmessih" data-tweet="1282724907948941312">
<p>Because there‚Äôs still an arb.</p>
<p>You could put 30% of the portfolio into SUN and 70% in RAIN and still earn 50 bps per year with NO risk (remember RFR is 0%)!</p>
</div>
</div>
</div>
<div>
<div>

<p><img data-attachment-id="2634" data-permalink="https://moontowermeta.com/you-dont-see-the-whole-picture/wp-1594825731126/" data-orig-file="https://i0.wp.com/moontowermeta.com/wp-content/uploads/2020/07/wp-1594825731126..jpg?fit=506%2C276&amp;ssl=1" data-orig-size="506,276" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="wp-1594825731126..jpg" data-image-description="" data-medium-file="https://i0.wp.com/moontowermeta.com/wp-content/uploads/2020/07/wp-1594825731126..jpg?fit=300%2C164&amp;ssl=1" data-large-file="https://i0.wp.com/moontowermeta.com/wp-content/uploads/2020/07/wp-1594825731126..jpg?fit=506%2C276&amp;ssl=1" src="https://i0.wp.com/moontowermeta.com/wp-content/uploads/2020/07/wp-1594825731126..jpg?resize=506%2C276&amp;ssl=1" alt="" width="506" height="276" srcset="https://i0.wp.com/moontowermeta.com/wp-content/uploads/2020/07/wp-1594825731126..jpg?w=506&amp;ssl=1 506w, https://i0.wp.com/moontowermeta.com/wp-content/uploads/2020/07/wp-1594825731126..jpg?resize=300%2C164&amp;ssl=1 300w" sizes="(max-width: 506px) 100vw, 506px" data-recalc-dims="1"></p>
</div>
</div>
<div>
<div>

<p><strong>What can we generalize?</strong></p>

<ul>
<li id="tweet_5" dir="auto" data-screenname="KrisAbdelmessih" data-tweet="1282724914517225477">A low or neg correlated asset, even one with a negative expected return, can improve a portfolio.</li>
<li dir="auto" data-screenname="KrisAbdelmessih" data-tweet="1282724914517225477">Assets can look appear overpriced in isolation, yet their price is more than justifiable.</li>
</ul>
<h2><strong>When You Don‚Äôt Understand The Price You Don‚Äôt Understand The Picture</strong></h2>
<p>Price is set by the buyer best equipped to underwrite the risk.</p>
<p>If you weren‚Äôt willing to bid RAIN up you can bet SUN would have.</p>
</div>
</div>
<div>
<div>

<p>This leads to 2 important warnings.</p>
<p>1. You must diversify</p>
<div dir="auto" data-screenname="KrisAbdelmessih" data-tweet="1282724917167951872">
<p>Financial theory dictates that you do not get paid for diversifiable risks. To be blunt, you are incinerating money if you don‚Äôt diversify. The SUN/RAIN example can show how you would expect to lose money in RAIN in isolation because the market is priced assuming you could buy SUN. I cover this idea more in <em><a href="https://www.notion.so/abdelmessih/The-Diversification-Imperative-0ffbc51024104c5e88d76e3866a6d5e7">The Diversification Imperative</a></em>.</p>

</div>
</div>
</div>
<p>2. You might be a tourist</p>
<p>It‚Äôs worth asking yourself, does X look overpriced because I have the wrong perspective? You are looking at RAIN but don‚Äôt see what the SUN investor sees.</p>
<h3 dir="auto" data-screenname="KrisAbdelmessih" data-tweet="1282724917167951872"><strong>A Market-Maker Example</strong></h3>
<p>If X is willing to pay me a high looking price for a stock or option, what‚Äôs the probability they are selling something else to someone else such that they are happy to pay me the ‚Äúhigh‚Äù price?</p>
<p>Let‚Äôs say a call overwriter sees a modest surge in implied vol and is happy to collect some extra premium. Except he‚Äôs selling calls to a Citadel market-maker who‚Äôs happy to pay the ‚Äúhigh‚Äù price because her desk is selling index vol. In fact, they are selling index implied correlation at 110%. You might be happy selling the calls for 2% when they are usually worth 1%, but if the person buying them from you knows they are worth 3% at the time you sold them then make no mistake, you are playing a losing game.</p>
<p>However, if your professional edge is in deeply understanding the stock you are selling calls on, then you might be the one capturing the edge in the expensive calls. You are capturing it ultimately from the fact that index volatility is ripping higher and market makers are simply capturing the margin between the weighted option prices of the single stock in proportion to the index volatility. So you, the informed single stock manager, is making edge against the index volatility buyer who set off the chain of events.</p>
<p>The decomposition of the edge between you and the market maker is unclear. But the lesson is you must know where you stand in the pecking order. When a market maker is asked why they are buying Stock A for $100 they respond ‚Äúbecause I can sell Stock Z at $110‚Äù. There‚Äôs always a relative value reason. The more you internalize the SUN/RAIN example and how correlation relates to diversification the more natural this reasoning becomes.</p>
<h3><strong>Another example</strong></h3>
<p>Let‚Äôs consider another option relative value trade.&nbsp; If volatility surges in A but not in B and they are tightly correlated let‚Äôs look at how 2 different market participants might react.</p>
<p><strong>Naive</strong></p>
<p>The naive investor isn‚Äôt aware of what is not monitoring the universe of names. They do not think cross-sectionally. They see a surge in A and decide to sell it. It may or may not work out. It‚Äôs a risky trade with commensurate reward potential.</p>
<p><strong>Sophisticated</strong></p>
<p>The sophisticated trader recognizes they can sell A and buy B whose option prices are still stale (perhaps there has been a systematic seller in B who has been price insensitive. Maybe from the same class of investor our friend ‚Äúnaive‚Äù came from. They don‚Äôt look at the market broadly and realize the thing they are selling is starting to ‚Äústick out‚Äù as cheap to all the sharps).</p>
<p>Here‚Äôs the key: the sophisticated trader will do the same trade as the naive one but by hedging the vol with B, <em>they can do the whole package bigger than if they simply sold A naked.</em></p>
<p>The sophisticated traders are the ones who see lots of flow. They ‚Äúknow where everything is‚Äù. While in this example, sophisticated and naive both sold A there will be times when sophisticated is lifting naive‚Äôs offer. Sophisticated has sorted the entire market and is optimizing buys and sells cross-sectionally.</p>
<h3><strong>Are you the fish at the table?</strong></h3>
<p>Flow traders and market makers are always wondering if their counterparty is legging a portfolio that they‚Äôd like to leg themselves if they saw the whole picture.</p>
<p>Sometimes it‚Äôs not possible because of structural reasons. For example, the risk that banks exhaust from structured product issuance or facilitating commodity hedges for corporations originates from a relationship nobody else can access.</p>
<p>A bank charter means some captive audiences. But that exhaust risk is recycled through the market much like a good flows through a vertical supply chain from wholesaler to retailer, with a markup being tacked on incrementally until its sold to a Robinhood client.</p>
<p>The markups are not explicitly in dollars but in the currency that lubricates financial markets ‚Äî risk/reward. Mathematical expectancy, like a house‚Äôs edge, is priced by its most efficient holder.</p>
<p>If prices are always being set by the party who most efficiently underwrites/hedges/prices the risk and you know you are not one of those parties then you should wonder‚Ä¶</p>
<p>am I being arbed?</p>
	</div><div>
				<p><strong>Published</strong>
			<time datetime="2020-07-15T09:47:42-07:00">15 Jul 2020</time><time datetime="2020-07-21T11:46:14-07:00">21 Jul 2020</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://moontowermeta.com/you-dont-see-the-whole-picture/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23897806</guid>
            <pubDate>Mon, 20 Jul 2020 13:51:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Go WASM Playground]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23897752">thread link</a>) | @lanecwagner
<br/>
July 20, 2020 | https://classroom.qvault.io/playground/go | <a href="https://web.archive.org/web/*/https://classroom.qvault.io/playground/go">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://classroom.qvault.io/playground/go</link>
            <guid isPermaLink="false">hacker-news-small-sites-23897752</guid>
            <pubDate>Mon, 20 Jul 2020 13:46:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From 10 MBit/sec Down To 40 bit/sec (and less) ‚Äì How People Perceive Information]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23897668">thread link</a>) | @iuliangulea
<br/>
July 20, 2020 | https://iuliangulea.com/blog/how-people-learn-human-senses/ | <a href="https://web.archive.org/web/*/https://iuliangulea.com/blog/how-people-learn-human-senses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    
    <p>Have you ever thought about how we navigate and perceive the world around us?</p>
<p>In <a href="https://iuliangulea.com/blog/how-people-learn-the-brain-basics/">How People Learn ‚Äî The Brain Basics</a>, I have described the basic principles of brain functioning. But as powerful as it is, our brain is a black box that relies on various sensory systems to get information from the outside world for processing.</p>
<p>Without input from those sensory channels, we are just a conscious sack of bones, muscles, and organs that wouldn‚Äôt know about the existence of anything around us.</p>
<p>But how many senses do we have? To answer that, we have to differentiate between the two main types of stimuli first: external (outside our bodies) and internal (generated by our organism itself). For this article, let‚Äôs focus on the external stimuli since that is the only way to get information about our environment. Therefore, those are:</p>
<ul>
<li>Vision</li>
<li>Hearing</li>
<li>Touch</li>
<li>Taste</li>
<li>Smell</li>
</ul>
<p>There is a sixth external sense (sense of balance, responsible for perceiving gravity and acceleration), but this article will focus on those five only, since the sense of balance represents one‚Äôs position in the world, without offering much information about the surroundings.</p>
<p>Interestingly, all those senses are pretty localized, except for one. We can only see with our eyes, hear with our ears, smell with our nose, and taste with our mouth. However, we can experience touches (and a range of other sensations like pressure, vibration, temperature) with our skin (and hence, entire body).</p>
<p>Touch was the first sense organisms had to develop to navigate the unfriendly world around them. Like taste, touch aids in analyzing objects in direct contact with the body. Conversely, vision, hearing, and smell have evolved to interpret the world at a distance.</p>
<p>Collectively, all external sensory systems allow humans to navigate and interact with the world around them:</p>
<ul>
<li>we perceive light (a short range of the electromagnetic spectrum) with our eyes;</li>
<li>we perceive sound with our ears;</li>
<li>we perceive chemical substances with our nose and mouth;</li>
<li>we perceive temperature, position, and motion with our skin;</li>
</ul>
<h2 id="senses-throughput">Senses Throughput</h2>
<p>All these sensory channels have a capacity for how much information they can carry. Surprisingly, the difference between the throughputs of various channels is striking. In his book, ‚ÄúPresentation Secrets,‚Äù Alexei Kapterev defines the throughput capacities as follows:</p>
<p><img src="https://iuliangulea.com/images/unconscious_attention_bit_sec.png#c" alt="Image Of Senses Throughput For Unconscious Attention"></p>
<p>Therefore, we have the following throughput capacities:</p>
<ul>
<li><em>visually</em> we perceive around 10,000,000 bit/sec;</li>
<li>through <em>touch</em> we can perceive around 1,000,000 bit/sec;</li>
<li><em>hearing</em> and <em>smell</em> has 100,000 bit/sec throughput;</li>
<li><em>taste</em> has only 1,000 bit/sec throughput;</li>
</ul>
<p>That is some tremendous difference between various senses. I will not focus on the ‚Äúbits/sec‚Äù unit of measurement since it is not that relevant for now. What is relevant is the capacity relative to each other. We get a massive amount of information through our eyes, a tenth of that through our skin, a hundredth of that through our ears and nose, and a tenth of thousands of that through our mouth.</p>
<p>You might wonder why touch is on the second place and not hearing. It turns out that the chart above represents the <em>unconsccious attention</em> throughput amounts‚Äîthat is, information we perceive without deliberately paying attention to it. What about the <em>conscious attention</em> throughput amounts? Kapterev covers that as well:</p>
<p><img src="https://iuliangulea.com/images/conscious_attention_bit_sec.png#c" alt="Image Of Senses Throughput For Conscious Attention"></p>
<p>The conscious senses throughput is incredibly small in comparison with the unconscious ones:</p>
<ul>
<li><em>vision</em> has still the highest capacity of 40 bit/sec;</li>
<li><em>hearing</em> took over touch with 30 bit/sec on the second place;</li>
<li><em>touch</em> has 5 bit/sec throughput;</li>
<li><em>smell</em> and <em>taste</em> both have only 1 bit/sec;</li>
</ul>
<p>Kapterev‚Äôs work is based on Danish scientist Tor N√∏rretranders, who in 1991 defined the <em>Bandwidth of Senses</em> in his book ‚ÄúThe user illusion: Cutting consciousness down to size.‚Äù Although there is still no precise measurement of conscious throughput (29 years have passed since N√∏rretranders‚Äô attempted to measure it), more recent findings (2013), display a similar trend regarding the conscious capacity. For instance, Richard Epworth defines conscious throughput depending on the task at hand (operating on and memorizing different things), and it can vary between 2‚Äì18 bit/sec:<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<figure>
    <img src="http://www.humanbottleneck.com/wp-content/uploads/2015/06/23_GraphMemoryRecords-1400x989.gif" alt="Image Of Memorizing Duration In Seconds"> <figcaption>
            <p>Source:
                    <a href="http://www.humanbottleneck.com/chapter-5/">humanbottleneck.com</a></p>
        </figcaption>
</figure>

<p>Therefore, if we consciously perceive so little, what happens with all that information we sense unconsciously? That is a fascinating question that scientists are trying to understand fully. Some of that information is still processed unconsciously by different regions of the brain for threats and extraction of relevant features. I will cover more of it in one of the next posts on attention.</p>
<h2 id="brains-virtual-reality">Brain‚Äôs Virtual Reality</h2>
<p>Since we consciously are able to perceive so little information, we have to interpret a lot of things and greatly rely on our previous experiences when interacting with the world around us. As much as we would like to experience reality as objective as possible, we are living inside our heads much more than we think.</p>
<p>What we experience as The World is nothing but a recreated representation of the actual world in our minds based on what we know about it already. You might be sitting or lying on the couch when you read this, and it would be effortless for you to go to the kitchen with your eyes closed. You would probably even not have to slow down, because you have a model of your house/flat in your mind already. Another example is your commute to work: if you have your car, you know the path, and you just drive to your work, listening to your favorite songs, and singing along. Or, if you have to use public transport, you are probably reading or listening to something while on your way to the workplace.</p>
<p>But things change drastically when you don‚Äôt have any prior experience of something. Imagine you are driving in a new big city and you need to find your Airbnb flat in the city center. Because your conscious throughput is small, you have to ‚Äúshut down‚Äù any irrelevant sensory channels: you do not eat while driving, turn off the music, and might not be talkative. All your attention is directed on the road, semaphores, signs, and other cars. Even then, you might occasionally take the wrong turn because you were distracted or had to take more time to process information and decide.</p>
<p>If to consider the walking example‚Äîimagine you are in a new city and want to get to a place you‚Äôve long wanted to visit. Not only will you plan your path in advance, but you will have to stop and analyze things at each pace: subway stations, bus stations, number of blocks you‚Äôve walked, etc.</p>
<p>Therefore, as powerful as it is, a marvel of biological engineering, the brain compresses and prunes information incredibly well before it reaches our conscious attention. So, to compensate for the small amount of conscious processing, the mind keeps an internal representation of your environment at all times, allowing you to put those tens of bits per second of conscious attention to good use at the cost of relying on that reconstructed (and eventually outdated) representation of the world.</p>
<hr>
<p>If you liked this article, make sure to subscribe below to receive new articles directly into your inbox and also follow me on twitter (<a href="https://twitter.com/iuliangulea">@iuliangulea</a>).</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p><em>Bottleneck - Our human interface with reality: The disturbing and exciting implications of its true nature</em> by Richard Epworth, 2013 <a href="#fnref:1" role="doc-backlink">‚Ü©Ô∏é</a></p>
</li>
</ol>
</section>

    
    
        
    

</div></div>]]>
            </description>
            <link>https://iuliangulea.com/blog/how-people-learn-human-senses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23897668</guid>
            <pubDate>Mon, 20 Jul 2020 13:37:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Features in Production: An Approach]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23897604">thread link</a>) | @lowmemcpu
<br/>
July 20, 2020 | https://24days.in/umbraco-cms/2019/features-in-production/ | <a href="https://web.archive.org/web/*/https://24days.in/umbraco-cms/2019/features-in-production/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>An approach to turn website features on/off in production.</p>
      <p>When deploying features or new changes to our websites, we might not want them to be available to all users at once. It would be nice if we could slowly introduce new features to our users. We might even want to completely disable them and have them there in secret. In this article, I'm going to present a few different ways in which you can release features into production, even when they might not be fully complete.</p>
      <h2>Background</h2>
      <p>Before we look into the ways in which we can get our features into production, it's useful to think about how we might have typically developed new changes in our website before a release.</p>
      <p>One of the most common ways is to use feature branches in a <a href="https://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow">gitflow scenario</a>, where you would build your new feature, deploy to a test environment and then try and merge those changes with anything else that has changed in the meantime. You'll probably bundle a number of changes together and then release those to production.</p>
      <p>Some of the issues at this stage might be that you've got a tricky merge, you've tested something in isolation and when you bring it all together other issues might arise. You also haven't really trialled those changes with actual users, so those changes may not be desired or there could be problems with how it all works.</p>
      <h2>Benefits and options</h2>
      <p>Therefore, it's probably a good idea to highlight some of the benefits as to why you might want to integrate your new changes sooner rather than later.</p>
      <ul>
        <li>Your features get into production quicker</li>
        <li>You can get feedback earlier</li>
        <li>You can test things in reduced quantities</li>
        <li>You should end up with a better product</li>
        <li>Your client will be happy</li>
      </ul>
      <p>You might have seen reasons like this elsewhere, and that's because they actually run true for agile development and the scrum process, which in turn is a good fit for <a href="https://continuousdelivery.com/">continuous delivery</a>. A notion that your app is always in a deliverable state, since any new changes have been safely integrated somehow.</p>
      <p>On to the ways in which we can enable our changes...</p>
      <h3>App settings</h3>
      <p>One of the easiest ways is to define them in your web.config, application settings somewhere, or provide settings in your Umbraco solution to switch features on and off. You'll need to check this setting within your code before including the new changes for your users.</p>
      <p>This can be done with a feature helper, which can query the app setting and then return a true or false as to whether the new changes should be included or not.</p><pre><code>public static class FeatureHelper
{
    public static bool IsFeatureEnabled(string featureFlag)
    {
        // check if we have enabled functionality via web.config
        bool.TryParse(ConfigurationManager.AppSettings.Get(featureFlag), out var setting);
        return setting;
    }
}</code></pre><p>If you'd like to turn off entire controllers or action methods, one of the ways in which you can do that is via the use of <a href="https://docs.microsoft.com/en-us/aspnet/mvc/overview/older-versions-1/controllers-and-routing/understanding-action-filters-cs">attributes</a>. These will decorate your actions and apply the filter before any of the other code is run. In the attribute logic, it will call our feature helper to determine whether or not a feature should be applied.</p><pre><code>public class FeatureAttribute : ActionFilterAttribute
{
    public string ConfigVariable { get; set; }

    public FeatureAttribute(string configVariable)
    {
        ConfigVariable = configVariable;
    }

    public override void OnActionExecuting(ActionExecutingContext filterContext)
    {
        // if the feature is not enabled, then redirect to 404
        if (!FeatureHelper.IsFeatureEnabled(ConfigVariable))
        {
            filterContext.HttpContext.Response.Redirect("/404/");
        }
        else
        {
            base.OnActionExecuting(filterContext);
        }
    }
}</code></pre><p>This allows for features to be controlled relatively easy in terms of when it is available, but it's an all or nothing solution which might not be desired when you want to tentatively introduce customers to your new feature.</p>
      <h3>Session</h3>
      <p>We can apply changes based on a user's session data, which could be enabled via a campaign to help with testing. Ask for people to click a link and become part of the session. You can then trigger an update that will kill off any session data if there are issues. The code above that we used for checking app setting can be amended to apply with session data.</p><pre><code>public static class FeatureHelper
{
    public static bool IsFeatureEnabled(string sessionFlag)
    {
        // check if we have a valid session to enable functionality
        var sessionVar = HttpContext.Current?.Session[sessionFlag];
        if (sessionVar == null)
        {
            return false;
        }

        return bool.Parse(sessionVar.ToString());
    }
}</code></pre><p>This is great for ad hoc testing, as everything can return to normal after the session. This is ideal if you don't have an account system set up, but it is helpful if you can target or segment your users if you have a hypothesis you want to test.</p>
      <p>A/B testing would be a good scenario here. One set of users could get the feature enabled and the other set could continue as normal to see if anything is improved, if your feature relates to performance or conversions. It's important that you can define what improvement looks like or can at least get some feedback from your users.</p>
      <h3>User preference</h3>
      <p>If you do have an account section, you could provide the user the choice as to whether they want to opt in to a newly released feature that you might want to test further before enabling for all. You would need to check against the current logged in user as to whether or not they would like to see those changes.</p>
      <p>In Umbraco, you could define this as a member property or <a href="https://our.umbraco.com/Documentation/Getting-Started/Data/Members/#creating-member-groups" data-anchor="#creating-member-groups">membership group</a> so you can see within the backoffice which users have enabled your feature and segment your users that way. If your changes are more granular, then using properties is probably preferred.</p>
      <p><em>Just to note, for members in Umbraco there is the concept of role based access, which is tied with membership groups, so could be an option if you wanted to hook in that way instead. This uses .NET authorisation under the hood.</em></p><figure><img src="https://24days.in/media/2269/umbraco-membership-features.png" alt="umbraco-membership-features.png"></figure><p>This puts the control on to your users, and they are more likely to be actively engaged with a feature and also understand that there may be issues. If they're not happy with how it works, then they can opt back out and carry on as normal. Within your website, you can provide an option for feedback based on whether a new feature has been turned on. They can submit reports and you can gain some quality insight as to how your users are actually using your changes.</p>
      <h3>Deployment slots</h3>
      <p>If you're doing your deployments via Azure App Services, then another option at your dispense, is to use <a href="https://docs.microsoft.com/en-us/azure/app-service/deploy-staging-slots#route-traffic" data-anchor="#route-traffic">deployment slots</a>. The main use case for this is to run a staging slot alongside your live slot, and to swap them when doing a deployment to ensure that you've tested your changes, warmed up your site beforehand and traffic is switched over without downtime.</p>
      <p>There is another benefit to it though, in that it can allow you to drive traffic to either slot based on a percentage. That way you can test with 20% of users before rolling out to the other 80% and this is managed through deployment. You can do similar with traffic manager or other load balancing rules.</p><figure><img src="https://24days.in/media/2265/deploymentslots-routetraffic.png" alt="deploymentslots-routetraffic.png"></figure><p>With this option, it's even more important that you can provide suitable metrics and logs to determine how your new changes are performing. Without reasonable guidance, you're in the dark as to whether or not it's a good idea to roll out.</p>
      <h3>Features as a service</h3>
      <p>With the rise of microservices, why not make use of a service that can handle our features? One of those services is <a href="https://launchdarkly.com/">LaunchDarkly</a>, which provides a dashboard for your features and has a number of libraries (inc. JS and .NET) that you can integrate with. As a solution, it'll allow you to get a full feature management tool pretty quickly, and one that should provide plenty of options albeit at a price. Useful to consider, and there may well be others out there. The concepts should still be the same as we've outlined in this article.</p>
      <h2>Conclusion</h2>
      <p>Testing features in production is a big part of continuous improvement and ties in well with the continuous development way of doing things. You can deliver changes quicker and have greater confidence in when a feature is enabled for all. Ideally, you can ramp up usage in a controlled manner.</p>
      <p>You can gain feedback on your changes from real users and scenarios, which may in turn provide much greater insight as to how something works. The end goal being that your changes have been well integrated and are of better quality overall.</p>
    </div></div>]]>
            </description>
            <link>https://24days.in/umbraco-cms/2019/features-in-production/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23897604</guid>
            <pubDate>Mon, 20 Jul 2020 13:31:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GraphQL vs. REST vs. gRPC]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23897583">thread link</a>) | @oczek
<br/>
July 20, 2020 | https://blog.graphqleditor.com/graphql-rest-grpc/ | <a href="https://web.archive.org/web/*/https://blog.graphqleditor.com/graphql-rest-grpc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>If you‚Äôve read an article or even some brief description of GraphQL, it probably included a line about what it does better than REST and other APIs. Glancing over the question like that isn‚Äôt really fair though is it? You won‚Äôt get the whole picture without really looking at each API‚Äôs uses and advantages so let‚Äôs try to dig a bit into that here.</p>
<h2>GraphQL - the new standard</h2>
<p>GraphQL is a flexible system for requesting data that focuses on pinpoint requests and delivering exactly what is required. What sets GraphQL apart from other APIs is its unique approach, it‚Äôs client-driven. Instead of handling it as usual i.e. server to a client, here the client decides how everything is handled. The main benefits are:</p>
<ul>
<li><strong>adaptability</strong> - the client decides what data they want, how they want it and what format they want to get it in,</li>
<li><strong>efficiency</strong> - delivers exactly what the client requests without over fetching,</li>
<li><strong>flexibility</strong> - GraphQl is cross-platform and supports more than a dozen languages (Perl, Java, Python, PHP among others).</li>
</ul>
<p>The most well-known example of GraphQL application is probably GitHub. They switched to it in 2016 citing scalability and flexibility as the two major reasons. REST simply wasn‚Äôt cutting it for them, because it often required multiple requests to get the data you wanted and also over-fetched data on each of those requests. With GitHub‚Äôs rapid growth and user base in the tens of millions, you can imagine how big a concern that had to be. GraphQL provided exactly the alternative they needed because it‚Äôs focused on the client being able to request particular data in a specific format for a specific use.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/75846e37844ed0b02923e47eb3493ec7/00d43/gql.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="GraphQL" title="GraphQL" src="https://blog.graphqleditor.com/static/75846e37844ed0b02923e47eb3493ec7/fcda8/gql.png" srcset="https://blog.graphqleditor.com/static/75846e37844ed0b02923e47eb3493ec7/12f09/gql.png 148w,
https://blog.graphqleditor.com/static/75846e37844ed0b02923e47eb3493ec7/e4a3f/gql.png 295w,
https://blog.graphqleditor.com/static/75846e37844ed0b02923e47eb3493ec7/fcda8/gql.png 590w,
https://blog.graphqleditor.com/static/75846e37844ed0b02923e47eb3493ec7/efc66/gql.png 885w,
https://blog.graphqleditor.com/static/75846e37844ed0b02923e47eb3493ec7/00d43/gql.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h2>REST - still most popular one (?)</h2>
<p>After voicing some complaints about it it‚Äôs only fair to take a look at REST. Even though some question if it‚Äôs not outdated it‚Äôs still the most commonly used API. REST is a stateless architecture for data transfer. RESTful systems put an emphasis on statelessness and hypermedia. Unlike GraphQL here the concerns of client and server are separated. The usually mentioned advantages are:</p>
<ul>
<li><strong>performance</strong> - best suited for systems requiring rapid iteration and HTTP standardized verbiage,</li>
<li><strong>scalability</strong> - allows the support of large numbers of components and interactions among them,</li>
<li><strong>simplicity</strong> - REST has a uniform interface which simplifies and decouples the architecture,</li>
<li><strong>modifiability</strong> - components can be modified to fit changing needs even while the application is running.</li>
</ul>
<p>As mentioned above, REST is still the most popular API. Twitter, Facebook, Google, and Paypal are all using RESTful APIs. REST can tie together a variety of resources that can be requested in a number of ways and in different formats for various purposes. If you need a more general-purpose API than the pinpoint GraphQL this is the one for you.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/9819101d7970d20eef61417ae8072d2e/00d43/rest.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="REST" title="REST" src="https://blog.graphqleditor.com/static/9819101d7970d20eef61417ae8072d2e/fcda8/rest.png" srcset="https://blog.graphqleditor.com/static/9819101d7970d20eef61417ae8072d2e/12f09/rest.png 148w,
https://blog.graphqleditor.com/static/9819101d7970d20eef61417ae8072d2e/e4a3f/rest.png 295w,
https://blog.graphqleditor.com/static/9819101d7970d20eef61417ae8072d2e/fcda8/rest.png 590w,
https://blog.graphqleditor.com/static/9819101d7970d20eef61417ae8072d2e/efc66/rest.png 885w,
https://blog.graphqleditor.com/static/9819101d7970d20eef61417ae8072d2e/00d43/rest.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h2>gRPC - performance at all costs</h2>
<p>gRPC is a lightweight and quick system for requesting data, it‚Äôs a fresh take on an old method called Remote Procedure Call or RPC. The main difference here is how it defines it‚Äôs contract negotiations. REST defines interactions through standardized terms in its requests, GraphQL runs requests against a created schema to fetch exactly what is required. RPC functions on contracts, the negotiation is defined by the relationship between the server and the client not by the architecture. Most of the power relies on the client-side while handling and computations are offloaded to a remote server hosting the resource. To put it short the key advantages are:</p>
<ul>
<li>it‚Äôs lightweight, requires very little resources which makes it a handy solution for even extremely low powered situations</li>
<li>it‚Äôs efficient, gPRC uses protobufs, a method of serializing structured data which focuses on serializing communication in an effective manner</li>
<li>it‚Äôs open-source and can be freely used, modified or forked</li>
</ul>
<p>In short, gRPC is suited for systems that need a set amount of data or processing routinely and in which the requester is low power or wants to preserve resources. The best examples are immensely popular IoT devices like voice controllers, smart light switches, smoke alarms locks, and cameras. </p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/1e2e07b24dcaf1442cf0077852f032e5/00d43/grpc.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="gRPC" title="gRPC" src="https://blog.graphqleditor.com/static/1e2e07b24dcaf1442cf0077852f032e5/fcda8/grpc.png" srcset="https://blog.graphqleditor.com/static/1e2e07b24dcaf1442cf0077852f032e5/12f09/grpc.png 148w,
https://blog.graphqleditor.com/static/1e2e07b24dcaf1442cf0077852f032e5/e4a3f/grpc.png 295w,
https://blog.graphqleditor.com/static/1e2e07b24dcaf1442cf0077852f032e5/fcda8/grpc.png 590w,
https://blog.graphqleditor.com/static/1e2e07b24dcaf1442cf0077852f032e5/efc66/grpc.png 885w,
https://blog.graphqleditor.com/static/1e2e07b24dcaf1442cf0077852f032e5/00d43/grpc.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://grpc.io/docs/what-is-grpc/introduction/">grpc.io</a></h5>
<h2>One size does not fit all</h2>
<p>As you can see each of these options has its own applications and advantages. There is no clear winner here and what you should use, or rather what you want to use, depends mostly on your aims and approach. So now that you hopefully know a bit about each of them, look into what would best fit your project and pick the right one for yourself.</p></div><p>The GraphQL Editor is a supportive tool for both advanced GraphQL users as well as those taking their first steps with GraphQL APIs. Our all-in-one development environment for GraphQL will help you build, manage &amp; deploy your GraphQL API much faster thanks to dozens of built-in micro features. Its graphical interface will also fix communication within your product team. Visualization is the key!</p></div>]]>
            </description>
            <link>https://blog.graphqleditor.com/graphql-rest-grpc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23897583</guid>
            <pubDate>Mon, 20 Jul 2020 13:29:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CVE and 'the' CVE turn 21 this year: the story of how they made it this far]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23897560">thread link</a>) | @GiulioS
<br/>
July 20, 2020 | https://secalerts.co/article/the-cve-turns-21-the-story-of-how-it-made-it-this-far/a7475dee | <a href="https://web.archive.org/web/*/https://secalerts.co/article/the-cve-turns-21-the-story-of-how-it-made-it-this-far/a7475dee">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<article>
<a href="https://secalerts.co/article">Security News</a>





<figure>
<img alt="" src="https://secalerts.co/assets/images/article/image-03-cve-logo-01.jpg">
<figcaption></figcaption>
</figure>

<p>The Common Vulnerabilities and Exposures (<a href="https://secalerts.co/article/what-is-cve/1b878c94">CVE</a>) turns 21 this year and, just like any 21-year-old, there have been growing pains along the way. There was even a growth spurt.</p>

<p>In the case of CVE, this happened between 2016 and 2017, when the number of vulnerabilities assigned a <a href="https://secalerts.co/article/what-is-a-cve-id/9a18af10">CVE ID</a> skyrocketed from 6,447 to 14,714.</p>

<p>Why the sudden increase? Let's start at the beginning ...</p>

<p>In September 1999, MITRE Corporation published a paper titled <i><a href="https://cve.mitre.org/docs/docs-2001/Development_of_CVE.html">The Development of a Common Enumeration of Vulnerabilities and Exposures</a></i> i.e. CVE.</p>

<p>"(We are) building a system that can integrate and manage vulnerability information from different sources, such as network assessment tools, intrusion detection systems, and archives, in a database for supporting enterprise security operations," stated MITRE.</p>

<p>MITRE's desire to establish an independent naming authority stemmed from the fact there were already numerous vulnerability databases, all with differing naming protocols. Not surprisingly, this caused confusion among researchers and vendors because, among other things, they were unable to determine if these databases were referring to the same vulnerability.</p>

<p>"The goals of having CVE are to ... assign a standard, unique name to each vulnerability, and exist independently," stated MITRE, also realising that "for CVE to have any impact ... (it) must be openly available to the public, without restrictions on distribution."</p>

<figure>
<img alt="" src="https://secalerts.co/assets/images/article/cve-1999-0001.jpg">
<figcaption></figcaption>
</figure>

<p>MITRE recognised that a public vulnerability database might assist hackers but argued the benefits outweighed the risks. In a pre-social media world, one interesting benefit given was: "Community opinion is shifting towards sharing information ...".</p>

<p>When CVE officially came into being (Oct. 1999), it was designed to deal with a maximum of 1,000 vulnerabilities a year. The year after CVE's arrival the number of vulnerabilities exceeded the 1,000 mark - 1,020 - and, as the years progressed, the quantity of software and hardware ... and vulnerabilities ... escalated. By 2005 the number of assigned vulnerabilities was a whisker away from 5,000 (4,935). Dealing with this volume was proving an issue for CVE and it began looking at ways to address the expanding vulnerability landscape.</p>

<p><strong>CANDIDATE NAMING AUTHORITIES</strong></p>

<p>The September 1999 paper identified a Candidate Naming Authority (<a href="https://secalerts.co/article/what-is-a-cna/5f1a3934">CNA</a>) as an entity that could assist identifying and naming vulnerabilities. However, CNAs didn't necessarily speed up the process. This is because between 1999 and 2005 there was a three-step process to naming (assigning) a vulnerability.</p>

<p>First a 'problem' was identified as a candidate - potential vulnerability - and given the prefix CAN e.g. CAN-1999-0345. This step could be done by a CNA, of which there were 23 in 2005. However, for a candidate to become a published vulnerability, the CVE Board had to discuss, review, and vote on whether a candidate was a vulnerability. This had to be done for every candidate. If the Board agreed, a candidate was given CVE status and the prefix changed accordingly, so CAN-1999-0345 became CVE-1999-0345. The final step, populating the CVE ID on the master, published list, was also done solely by CVE.</p>

<figure>
<img alt="" src="https://secalerts.co/assets/images/article/image-01-can-image-1200-crop.jpg">
<figcaption></figcaption>
</figure>

<p>As a first step to speeding up the process, in 2005 the board vote was eliminated and all entries were automatically given a CVE ID. However, CNAs could still only identify but not populate the list and the multi-step process system remained in place until 2016, by which time 'all things internet' - and the corresponding amount of software/hardware - had continued to increase dramatically. This was matched by a sharp rise in the number of vulnerabilities, the sheer weight of which had once again slowed the process of assigning CVE IDs, resulting in some researchers not receiving a CVE assignment/s.</p>

<p>This was because, at the time, the CVE program operated to a scope (list) of software types for which it would assign CVEs. This scope was created to focus resources on the most important products and, if a product wasn't within the scope, CVE didn't assign and populate the list.</p>

<p><strong>THE WINDS OF CHANGE</strong></p>

<p>"A recent discussion of problems with the CVE system ... has led some to wonder about its future," wrote <a href="https://lwn.net/Articles/679315/">Linux Weekly News</a> on March 9, 2016. "The problems stem from the difficulty, sometimes impossibility, of getting CVEs assigned for real vulnerabilities. That, in turn, has led some to stop even requesting CVE numbers for vulnerabilities that they find, which further reduces their usefulness."</p>

<figure>
<img alt="" src="https://secalerts.co/assets/images/article/cve-woes01.jpg">
<figcaption></figcaption>
</figure>

<p>It's hard to imagine that this was the state of play less than four years ago. But it was. To the point where the online community was beginning to contemplate alternatives, such as <a href="https://www.openwall.com/ove/">OVE IDs</a> - "unique IDs that you may use to refer to software security vulnerabilities (one ID per vulnerability), much like we use CVE IDs", and the Open Source Vulnerability Database (<a href="https://blog.osvdb.org/">OSVDB</a>) - "OSVDB's goal is to provide accurate and unbiased information about security vulnerabilities in computerized equipment."</p>

<p>Thousands of vulnerabilites were going un-assigned and, therefore, unpatched. Additional change was needed.</p>

<p>On March 21, 2016, <a href="https://cve.mitre.org/news/archives/2016/news.html">CVE wrote</a>: "The recent explosion of Internet-enabled devices - known as the Internet of Things - as well as the propagation of software-based functionality in systems has led to a huge increase in the number of CVE requests ... We did not anticipate this rate of growth ... The result has been some of the delay in CVE assignments that the software security community has recently witnessed."</p>

<p>A few months later (June 2016), the Distributed Weakness Filing system (<a href="https://www.redhat.com/en/blog/introducing-dwf-project-vulnerability-reporting-done-open-source-way">DWF</a>) launched. As the name suggests, the DWF distributed the task of assigning CVE IDs and gave control of cataloguing vulnerabilities to, among others, independent experts, software vendors, and academic institutions.</p>

<p>"Rather than having to submit security reports through a single funnel, anyone within the community can work through a more streamlined reporting mechanism and receive a DWF number," said Kurt Seifried, a security researcher at Red Hat, who built and launched the DWF (which lasted nearly three years, <a href="https://twitter.com/kurtseifried/status/1103858442479910913">shutting down</a> in March 2019).</p>

<figure>
<img alt="" src="https://secalerts.co/assets/images/article/kurt---dwf---tweet.jpg">
<figcaption></figcaption>
</figure>

<p>While the DWF eased the burden for CVE, it - CVE - already had plans afoot to improve the system in place.</p>

<p>"By the time 2016 came around, CVE was wanting to not only introduce new CNAs, but implement process improvements," said Chris Levendis, the MITRE CVE Project Lead, while speaking with SecAlerts.</p>

<p>One of these improvements was the <a href="https://cve.mitre.org/cve/cna/rules.html#Section_1_1_cnas">new-look CNA program</a>, with CNA now standing for "CVE Numbering Authority".</p>

<p>Whereas 'old' CNAs (Candidate Naming Authorities) could only identify a potential vulnerability - candidate - and name it with the CAN prefix, the new CNAs could do what only CVE had been tasked with doing i.e. assigning CVE IDs. Additionally, CVE did away with scope restrictions on what types of vulnerabilities it would publish.</p>

<p>Participation in the CNA program was (and still is) voluntary and organisations must provide CVE IDs for free. They must also have a "public vulnerability disclosure policy" and a "public source for new vulnerability disclosures." If there are any naming disputes, MITRE is the primary CNA and the "CNA of last resort".</p>

<p><strong>CVE AS WE NOW KNOW IT</strong></p>

<p>Allowing CNAs to assign CVE IDs, and eliminating scope restrictions, worked, and this resulted in the <a href="https://www.cvedetails.com/browse-by-date.php">growth spurt</a> (6,447 to 14,714) between 2016 and 2017.</p>

<figure>
<img alt="" src="https://secalerts.co/assets/images/article/image-02-cve-totals-new.jpg">
<figcaption></figcaption>
</figure>

<p>"Before the introduction of CVE Numbering Authorities in 2016, CVE populated 100% of CVE entries," said Levendis. "Now the ratio is 60-40 in favour of CNAs. CVE continues to modernize the rules and underlying technologies to make it easier for CNAs to publish CVEs and it's intended that, over time, CNAs will populate all entries."</p>

<p>The list of CNAs grows constantly and, as of July 7, 2020, there were <a href="https://cve.mitre.org/cve/cna.html">130 organizations</a> - including Google, Apple, Microsoft, Adobe, IBM, Cisco and Red Hat - in 21 countries.</p>

<figure>
<img alt="" src="https://secalerts.co/assets/images/article/cna-world-map.jpg">
<figcaption></figcaption>
</figure>

<p>Publishing times for CVEs are typically down to days or even hours. Where there is variability in publishing times, it is more often due to human factors rather than the CVE operational model.</p>

<p>For example, a vulnerability researcher working with a vendor might take time to validate the CVE in order to make sure it is 'legitimate'. Or it could be something even simpler.</p>

<p>"A researcher might collect a CVE ID for a vulnerability but move on to another project before coming back to the vulnerability," says Levendis. "CVE discourages this but it happens."</p>

<p>CVE has come a long way in its relatively short lifetime. From 894 assigned CVE IDs in 1999 to a high (so far) of 16,556 in 2018, CVE, like any 21yo, continues to change with the times.</p>

<p>"CVE isn't just about MITRE," concludes Levendis. "It's a public-private partnership that grows every day."</p>
<p>. . .</p>
<p>If you want to stay notified of vulnerabilities that affect you, <a href="https://secalerts.co/article/the-cve-turns-21-the-story-of-how-it-made-it-this-far/a7475dee/#subscribe">register for a weekly security report</a> customised to your stack.</p>

</article>
</div></div>]]>
            </description>
            <link>https://secalerts.co/article/the-cve-turns-21-the-story-of-how-it-made-it-this-far/a7475dee</link>
            <guid isPermaLink="false">hacker-news-small-sites-23897560</guid>
            <pubDate>Mon, 20 Jul 2020 13:26:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Easy automated process to send emails with G Forms]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23897536">thread link</a>) | @pau_alcala
<br/>
July 20, 2020 | https://blog.palabra.io/how-to-automate-emails-to-new-subscribers-in-5-minutes-using-google-forms?ref=hackernews | <a href="https://web.archive.org/web/*/https://blog.palabra.io/how-to-automate-emails-to-new-subscribers-in-5-minutes-using-google-forms?ref=hackernews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Are you trying out a new side-project idea? Are you looking for an easy way to contact people who may be interested in a new service? Then you probably don't want to waste time setting up a  subscription form and email automation to talk to them.</p><p>In this article we'll show you how to create an automated subscription system to test new ideas and quickly contact potential users <strong>in just 5 minutes.</strong> Really.</p><p><span>
      <span></span>
  <img alt="1" title="1" src="https://blog.palabra.io/static/19ebb92c2145f82830b4f68f9c901e48/eefce/1.png" srcset="https://blog.palabra.io/static/19ebb92c2145f82830b4f68f9c901e48/5243c/1.png 240w,https://blog.palabra.io/static/19ebb92c2145f82830b4f68f9c901e48/ab158/1.png 480w,https://blog.palabra.io/static/19ebb92c2145f82830b4f68f9c901e48/eefce/1.png 720w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
    </span></p><p>Example of a Google Forms embed created in 1 min using Google's templates</p><h2>Let's just use Google Forms and keep it simple, shall we?</h2><p>First, I'll take a second to argue that Google Forms is fancy enough for a quick setup.</p><p>When trying out new ideas, what's important comes <strong>after</strong> the subscription form. You need to start talking to your potential users/customers/subscribers, and the faster you get to that part the better.</p><p>I always choose Google Forms to create simple surveys because:</p><ul><li>People are already familiar with them</li><li>It has free templates -and it's easy to create a new form from scratch</li><li>You can embed them in a webpage or share it's link</li><li>Responses get automatically stored in a Google Spreadsheet, which makes for an easy and simple database</li></ul><p>And the most important reason to use it: just to try it. If it works, you saved time and got to talking to users really fast. If it turns out you your users really really hate Gforms, at least it only took you 5 minutes to set it up ü§∑‚Äç‚ôÄÔ∏è</p><p>Now let's get to it:</p><h2>Step 1: Create your GForm from a template</h2><p>Like all things easy, GForms has a few templates you can use to try out new ideas. Every time I've used GForms, I've always found a related template I can quickly adapt to my needs.</p><p><span>
      <span></span>
  <img alt="1" title="1" src="https://blog.palabra.io/static/1e81b1add5d3c51c0f81f133b92d98d8/7d769/2.png" srcset="https://blog.palabra.io/static/1e81b1add5d3c51c0f81f133b92d98d8/5243c/2.png 240w,https://blog.palabra.io/static/1e81b1add5d3c51c0f81f133b92d98d8/ab158/2.png 480w,https://blog.palabra.io/static/1e81b1add5d3c51c0f81f133b92d98d8/7d769/2.png 960w,https://blog.palabra.io/static/1e81b1add5d3c51c0f81f133b92d98d8/badb6/2.png 1028w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
    </span></p><h2>Step 2: Set up a responses spreadsheet</h2><p>As soon as you start getting responses, you can click on the spreadsheet button at the top right and create a Google Spreadsheet. Each response will automatically create a new row.</p><p><span>
      <span></span>
  <img alt="1" title="1" src="https://blog.palabra.io/static/69fd762fe7931c85a0a7db7d47743bf3/67b4a/3.png" srcset="https://blog.palabra.io/static/69fd762fe7931c85a0a7db7d47743bf3/5243c/3.png 240w,https://blog.palabra.io/static/69fd762fe7931c85a0a7db7d47743bf3/ab158/3.png 480w,https://blog.palabra.io/static/69fd762fe7931c85a0a7db7d47743bf3/67b4a/3.png 893w" sizes="(max-width: 893px) 100vw, 893px" loading="lazy">
    </span></p><p>In less than two minutes you got a ready-to-embed form and updated database with everyone's contact info.</p><h2>Step 3: Connect your spreadsheet to Palabra</h2><p>Create a new workflow in <a href="https://palabra.io/">Palabra</a> and add a trigger when a new row is created on Google Spreadsheet</p><p><span>
      <span></span>
  <img alt="1" title="1" src="https://blog.palabra.io/static/aca3ce6d7b1177d5a29a962338c0cc3f/7d769/4.png" srcset="https://blog.palabra.io/static/aca3ce6d7b1177d5a29a962338c0cc3f/5243c/4.png 240w,https://blog.palabra.io/static/aca3ce6d7b1177d5a29a962338c0cc3f/ab158/4.png 480w,https://blog.palabra.io/static/aca3ce6d7b1177d5a29a962338c0cc3f/7d769/4.png 960w,https://blog.palabra.io/static/aca3ce6d7b1177d5a29a962338c0cc3f/b43a1/4.png 1092w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
    </span></p><p><em>Be careful to connect the same Gmail account in which you created the GForm.</em></p><p>It should look something like this:</p><p><span>
      <span></span>
  <img alt="1" title="1" src="https://blog.palabra.io/static/33653bc66ec90b54ccecbbd2381d4a9f/473d6/5.png" srcset="https://blog.palabra.io/static/33653bc66ec90b54ccecbbd2381d4a9f/5243c/5.png 240w,https://blog.palabra.io/static/33653bc66ec90b54ccecbbd2381d4a9f/ab158/5.png 480w,https://blog.palabra.io/static/33653bc66ec90b54ccecbbd2381d4a9f/473d6/5.png 736w" sizes="(max-width: 736px) 100vw, 736px" loading="lazy">
    </span></p><h2>Step 4: Choose your template and create a sequence</h2><p>There are many templates to choose form, just pick the one that fits what you're trying to do and adapt it to your own needs.</p><p><span>
      <span></span>
  <img alt="1" title="1" src="https://blog.palabra.io/static/281df4e3efe42ee085efb3b9726a5938/7d769/6.png" srcset="https://blog.palabra.io/static/281df4e3efe42ee085efb3b9726a5938/5243c/6.png 240w,https://blog.palabra.io/static/281df4e3efe42ee085efb3b9726a5938/ab158/6.png 480w,https://blog.palabra.io/static/281df4e3efe42ee085efb3b9726a5938/7d769/6.png 960w,https://blog.palabra.io/static/281df4e3efe42ee085efb3b9726a5938/e2368/6.png 1178w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
    </span></p><p>Since it's easy, I'd recommend for you to create a sequence to keep your prospects engaged. This is the example I just created:</p><p><span>
      <span></span>
  <img alt="1" title="1" src="https://blog.palabra.io/static/5da03112179a408f83938e4fe22033ac/0c7b9/7.png" srcset="https://blog.palabra.io/static/5da03112179a408f83938e4fe22033ac/5243c/7.png 240w,https://blog.palabra.io/static/5da03112179a408f83938e4fe22033ac/ab158/7.png 480w,https://blog.palabra.io/static/5da03112179a408f83938e4fe22033ac/0c7b9/7.png 657w" sizes="(max-width: 657px) 100vw, 657px" loading="lazy">
    </span></p><p>Now you only have to start the task and each new GForm response will trigger the whole sequence.</p><p><span>
      <span></span>
  <img alt="1" title="1" src="https://blog.palabra.io/static/018b45f5144434a9cccf23f8ebe0b010/7d769/8.png" srcset="https://blog.palabra.io/static/018b45f5144434a9cccf23f8ebe0b010/5243c/8.png 240w,https://blog.palabra.io/static/018b45f5144434a9cccf23f8ebe0b010/ab158/8.png 480w,https://blog.palabra.io/static/018b45f5144434a9cccf23f8ebe0b010/7d769/8.png 960w,https://blog.palabra.io/static/018b45f5144434a9cccf23f8ebe0b010/bcb16/8.png 1002w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
    </span></p><p>That's it! 4 steps and 5 minutes to set up an automated email sequence to ask feedback to potential users.</p><p>If you're trying out a new idea, get to talking to your prospects as soon as you can. Don't worry about fancy tools or design. Your users will appreciate it more once you start actually talking to them :)</p><p>Have any questions? Send me a <a href="mailto:pau@palabra.io">quick email</a>, I'd love to know if you tried it!</p><hr><p>Hope you enjoyed this tutorial! If you are curious about what else you can do with Palabra or would just like to try it go ahead an <a href="https://www.palabra.io/">create an account here</a>.</p></section></div>]]>
            </description>
            <link>https://blog.palabra.io/how-to-automate-emails-to-new-subscribers-in-5-minutes-using-google-forms?ref=hackernews</link>
            <guid isPermaLink="false">hacker-news-small-sites-23897536</guid>
            <pubDate>Mon, 20 Jul 2020 13:22:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Validate Your Idea / Notion]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23897493">thread link</a>) | @dataispassion
<br/>
July 20, 2020 | https://www.notion.so/Test-your-idea-3c069cbf938f444ab0dda8d6fc3ab2fe | <a href="https://web.archive.org/web/*/https://www.notion.so/Test-your-idea-3c069cbf938f444ab0dda8d6fc3ab2fe">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/Test-your-idea-3c069cbf938f444ab0dda8d6fc3ab2fe</link>
            <guid isPermaLink="false">hacker-news-small-sites-23897493</guid>
            <pubDate>Mon, 20 Jul 2020 13:18:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Manage My Notes]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23897371">thread link</a>) | @peterlk
<br/>
July 20, 2020 | http://peterklipfel.com/blog/taking_notes/ | <a href="https://web.archive.org/web/*/http://peterklipfel.com/blog/taking_notes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="post-body">
                    



<p>I use obsidian for desktop, IA Writer for mobile, and keep everything in sync with Dropbox.</p>



<p>During college, while I was freelancing, I developed a habit of taking notes. This has served me well since then, and I have tried to manage my notes in more ways than I can remember.</p>

<p>The ones that I can remember trying are: Google Keep, Google Docs, Evernote, Jupyter notebooks, Aha!, Omni-notes, Notability, Apple notes, Nebo, vim + github, and a bunch of miscellaneous mobile apps.</p>



<p>After finding the solution that works for me, I‚Äôve discovered what my requirements are:</p>

<ul>
<li><strong>Portable format</strong>: I want to be able to load my notes in any system. Potential candidates include docx files, markdown, and pdfs</li>
<li><strong>Access everywhere</strong>: I want to be able to see and read my notes after they‚Äôve been synchronized</li>
<li><strong>Vim mode</strong>: When I‚Äôm at a computer, I‚Äôd like to be able to use vim mode to modify and update my notes</li>
<li><strong>Metadata</strong>: I need a good way of associating metadata with my notes like the time the note was taken and a way of linking notes</li>
</ul>

<p>But I also want to be able to use notes for other things:</p>

<ul>
<li>I have lots of miscellaneous thoughts during the day and need a way to capture them</li>
<li>I like to keep track of quotes</li>
<li>I often track things like grocery lists</li>
<li>I like to keep track of todo items</li>
</ul>

<p>And it would be nice if the apps that I took my notes on had a dark mode.</p>



<p>I think I may have finally found the solution that works for me, and I want to share my setup just in case it works for other people too. The keystone to my new note-taking strategy is Obsidian. I absolutely love this note-taking app, and whole-heartedly recommend it to anyone. I hope that it continues to be the simple, elegant, and powerful editor that it is today. Disclaimer: I‚Äôm not affiliated with them in any way, and don‚Äôt have anything to gain by promoting them.</p>

<h2 id="markdown">Markdown</h2>

<p>When I have used other formats, I always run into corner cases where the note system breaks down. For example, I have always wanted to have my blog posts in the same place as the rest of my notes, but they always seem to get out of sync - I‚Äôll write the original post in one place, and then have to copy it back and forth between systems. This led to my notes and my blog getting out of sync (the blog that you‚Äôre reading is my third ‚Äúreal‚Äù attempt at getting my blog going).</p>

<p>But markdown has become universal. I can write things in a single format, and load them into any system for viewing. There are a bunch of apps that allow for markdown authoring. I like IA Writer for mobile, and I use Obsidian on all my computers to keep things in sync.</p>

<h2 id="daily-notes">Daily Notes</h2>

<p>Obsidian gives me a convenient format to put all my day-to-day ramblings, todos, and notes called ‚ÄúDaily Notes‚Äù. I have a folder called ‚ÄúDaily Notes‚Äù, and each file in this folder is the date of the note (for example, 2020-08-10.md). I also use Obsidian‚Äôs Daily Note Template to automatically generate a note with my default format.</p>

<p>Obsidian handles this all for my automatically, but the system is simple, so I can do it manually pretty quickly if I want to, say, plan for the next day while I‚Äôm laying in bed.</p>

<h3 id="daily-note-format">Daily Note Format</h3>

<p>My daily notes contain the following sections specified as markdown headings:</p>

<ul>
<li><strong>TODO</strong>: I put all the tasks that I want to get done ‚Äútoday‚Äù in this section

<ul>
<li><strong>Stretch</strong>: As things come up during the day, I often put them in this section, and move them to the next day if I don‚Äôt get to them</li>
</ul></li>
<li><strong>Personal Goals</strong>: I generally have personal objectives that I am actively  working on. This is where I track those objectives, and their output (metrics, notes, links, etc.)</li>
<li><strong>Business Goals</strong>: I like to track the ongoing goals at my job separately from my personal goals.</li>
<li><strong>Accomplished</strong>: It‚Äôs nice to lay in bed at night and make a list the things that I got done that day</li>
<li><strong>Daily thoughts</strong>: This section is freeform, and is more like my ‚Äújournaling‚Äù section. As I‚Äôm wandering through the day, for example, and I have the next billion dollar business idea, solutions to world hunger, or breakthroughs on artificial general intelligence, I‚Äôll add them to this section.</li>
</ul>

<h2 id="vim-mode">Vim Mode</h2>

<p>Despite how cumbersome it was to constantly have to boot jupyter notebooks, I loved being able to write my notes with a vim mode. I am so much more efficient when I can take note in vim mode. For example, if I‚Äôm on a call, I can simply press enter to separaet things in a list, and then make the list when there is a lull in noteworthy conversation by using <code>ctrl+v</code> + move up several lines + <code>shift+i</code> + ‚Äú-‚Äù.</p>

<h2 id="synchronization">Synchronization</h2>

<p>I use dropbox to synchronize files across all my devices. My only gripe with Dropbox is that it <em>really</em> wants you to use a folder called ‚ÄúDropbox‚Äù, which is kind of annoying. But it‚Äôs available in all places, and it does a good job of synchronization, so it‚Äôs fine.</p>

<h2 id="blog">Blog</h2>

<p>The blog that you‚Äôre reading right now is generated with markdown files, so I cloned the repository into my dropbox, and now I can modify and write blog posts in the same place that I take my notes! This was a huge win for me.</p>

<p>I‚Äôm still looking for a way to automatically deploy my site when I push to master in order to remove the need to run a deploy script (and have the necessary dependencies in place to do so). Netlify looks like it might be a good solution to this problem, but I haven‚Äôt set it up yet.</p>

<h2 id="zettelkasten">Zettelkasten</h2>

<p>I didn‚Äôt know there was a word for this style of taking notes until it became trendy a few months ago, but I find that prepending notes with dates is extremely useful for cases where I might have had multiple meetings on the same subject, or where I met with the same person multiple times, but do not have a regularly scheduled meeting with them (I put those in dedicated ‚Äú1x1‚Äù notes).</p>



<p>I haven‚Äôt figured out a good way to use tags yet. I‚Äôve tried it in the past, and I end up with more tags than I do notes, making the tags less useful than full-text search. Side note: full text search comes for free with markdown because it‚Äôs such a simple file format. Most applications can do it, or you can just do a <code>grep</code> if you have a terminal open.</p>

<p>Also, I still haven‚Äôt figured out a great way to link notes to each other. Folders do a pretty good job of grouping similar notes, and I haven‚Äôt found a compelling use case for linking notes. But it‚Äôs nice to have solutions in the tool box in case problems arise.</p>

                </section></div>]]>
            </description>
            <link>http://peterklipfel.com/blog/taking_notes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23897371</guid>
            <pubDate>Mon, 20 Jul 2020 13:04:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The German Problem with Tor]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 116 (<a href="https://news.ycombinator.com/item?id=23897288">thread link</a>) | @worldofmatthew
<br/>
July 20, 2020 | https://worldofmatthew.com/post/tor-german-avoid/ | <a href="https://web.archive.org/web/*/https://worldofmatthew.com/post/tor-german-avoid/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
<article>
<div>
<p>Over the past year, relay operators have done a good job in diversifying the range of network that they use to host their relays. The problem is that the move away from popular ASNs has not always translated to a move away from popular countries.</p>
<p>This is where we come to Germany, which has the highest amount of Tor relay capacity in the World at 167Gbps, in contrast France is in 2nd place with 64.5Gbps of capacity aka more than 100Gbps lower than Germany.</p>
<h2 id="the-problem-with-germany">The problem with Germany</h2>
<p>The German state is that exactly in love with the Tor network. This is the state who started <a href="https://itnomad.wordpress.com/2006/09/10/germany-crackdown-on-tor-node-operators/">raiding Tor relay operators in 2006</a>, <a href="https://blog.torservers.net/20180704/coordinated-raids-of-zwiebelfreunde-at-various-locations-in-germany.html">illegally seized</a> documents from German exit relay operator; torservers.net in 2018, tried to pass a <a href="https://www.privateinternetaccess.com/blog/germany-considers-amendment-to-law-which-makes-it-illegal-to-run-a-tor-node-or-website/">really vague law in order to the running of Tor relays</a> and now are about to vote on a <a href="https://www.privateinternetaccess.com/blog/new-german-law-would-force-isps-to-allow-secret-service-to-install-trojans-on-user-devices/">law to hijack traffic</a> to download Trojans on the computer of anyone they target.</p>
<p>This is the aggressive anti-privacy shit that most people would expect of somewhere like Russia. This might not be what you expect from a country that claims to love the right to privacy and pushed for the GDPR.</p>
<p>In reality, the German government has a double standard when it comes to the right to privacy. They will fully support that right if it's company's violating your privacy (especially, if they are American because protectionism) but in contrast, the German will give itself as many powers as it can to spy on its own citizens and those abroad.</p>
<p>Now you know how the Germans hate privacy, you will almost certainly be asking about alternative locations.</p>
<h2 id="but-tor-is-encrypted">But Tor is encrypted?</h2>
<p>The high number of high-speed relays and exits in Germany mean that it is not too uncommon to get both a German guard and exit. This gives the state an easier time if they want to target someone using traffic correlation attacks.</p>
<p>That also does not take in account the planned German law that will allow authorities to redirect traffic to state-owned servers, to infect users with viruses/Trojans. This is especially a concern for third-world users of Tor who are going to mainly accessing non-HTTPS sites on a computer without the best security.</p>
<h2 id="what-alternatives-are-there-to-germany">What alternatives are there to Germany?</h2>
<p>The current country with the best privacy to cost ratio is Luxembourg, where a 200Mbit can be gotten <a href="https://gcorelabs.com/pricing/hosting/">for 3.25 EUR per month</a>. Or if you have the money than Switzerland would be more ideal but you would not want to waste a Switzerland VPS on a non-exit relay.</p>
<p>Or if you are cheap, you could get a VPS from a country who hates the western spy powers like Russia or Moldova which will still help enhance the security of the Tor network by decreasing the chances that someone's traffic will just travel though one spying block which will make traffic correlation attacks much harder.</p>
</div>

</article>
</div></div>]]>
            </description>
            <link>https://worldofmatthew.com/post/tor-german-avoid/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23897288</guid>
            <pubDate>Mon, 20 Jul 2020 12:55:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Study finds ‚Äòdark matter‚Äô DNA is vital for rice reproduction]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23897225">thread link</a>) | @montalbano
<br/>
July 20, 2020 | https://globalplantcouncil.org/study-finds-dark-matter-dna-is-vital-for-rice-reproduction/ | <a href="https://web.archive.org/web/*/https://globalplantcouncil.org/study-finds-dark-matter-dna-is-vital-for-rice-reproduction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
			<div>
<article id="post-10664">

	<div>

		<div>
			
			
				<div>
					
										
					
<p>Researchers from the <a href="https://www.oist.jp/" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">Okinawa Institute of Science and Technology Graduate University (OIST) </a>have shed light on the reproductive role of ‚Äòdark matter‚Äô DNA ‚Äì non-coding DNA sequences that previously seemed to have no function.</p>



<p>Their findings, published in&nbsp;<a href="https://doi.org/10.1038/s41467-020-16637-3" target="_blank" rel="noreferrer noopener"><em>Nature Communications</em></a>, have revealed that a specific non-coding genomic region is essential for the proper development of the male and female reproductive organs in rice.</p>



<p>‚ÄúRice is one of the major global crops and is the staple food in many countries, including Japan,‚Äù said Dr. <a href="https://groups.oist.jp/stg/reina-komiya-phd" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">Reina Komiya</a>, senior author of the research paper and associate researcher from the OIST&nbsp;<a href="https://groups.oist.jp/stg" target="_blank" rel="noreferrer noopener">Science and Technology Group</a>. ‚ÄúFurther research into how these genomic regions affect plant reproduction could potentially lead to increased productivity and more stable yields of rice.‚Äù</p>



<p>Many previous developmental studies have focused on genes ‚Äì the sections of DNA that provide instructions for making proteins. But in complex creatures like plants and animals, a large fraction of the genome ‚Äì typically between 90-98% ‚Äì doesn‚Äôt actually code for proteins.</p>



<p>The vast expanse of this ‚Äòjunk DNA‚Äô has long puzzled biologists, with many dubbing it the ‚Äòdark matter‚Äô of the genome. But recent research suggests that many of these non-coding genomic regions may have a function after all, giving rise to non-coding RNA.</p>



<p>Scientists have now identified numerous types of non-coding RNA, ranging from small molecules only 20-30 nucleotide bases in length to long molecules of over 200 nucleotides. Although studies show that non-coding RNA plays a vital role in the regulation of gene expression ‚Äì the process where a gene‚Äôs instructions are used to make RNA or protein ‚Äì the precise function of each specific non-coding RNA remains poorly understood.</p>



<p>Dr. <a href="https://groups.oist.jp/stg/reina-komiya-phd" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">Komiya</a> is particularly interested in reproduction-specific RNAs. ‚ÄúThese are non-coding RNAs that are produced as the reproductive system forms. I wanted to uncover what role they play in the development of stamens and pistils, the male and female reproductive organs in plants.‚Äù</p>



<h2><strong>Making mutants</strong></h2>



<p>In the study, Dr. <a href="https://groups.oist.jp/stg/reina-komiya-phd" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">Komiya</a>‚Äôs group focused on a reproduction-specific microRNA ‚Äì a major class of small non-coding RNAs ‚Äì called microRNA2118.</p>



<p>The scientists created mutant rice strains by deleting a region of the genome that contains multiple copies of the specific DNA sequence that gives rise to microRNA2118. They found that the mutant strains were sterile and showed abnormalities in the structure of the stamens and pistils.</p>



<p>The stamens in mutant strains contain anthers ‚Äì the part of the stamen that houses pollen ‚Äì that are shorter and more curled than in wildtype strains.</p>



<p>‚ÄúThis means that the role of microRNA2118 in the proper development of the stamens and pistils is essential for plant fertility,‚Äù said Dr. Komiya.</p>



<h2><strong>Revealing RNA and probing proteins</strong></h2>



<p>&nbsp;In order to delve deeper into how microRNA2118 controlled development of the anther, the scientists then identified which other molecules were affected by microRNA2118.</p>



<div><figure><img src="https://globalplantcouncil.org/wp-content/uploads/2020/07/20200619-abnormalities-pistils_0.jpg" alt="" srcset="https://globalplantcouncil.org/wp-content/uploads/2020/07/20200619-abnormalities-pistils_0.jpg 353w, https://globalplantcouncil.org/wp-content/uploads/2020/07/20200619-abnormalities-pistils_0-300x161.jpg 300w" sizes="(max-width: 353px) 100vw, 353px"><figcaption>The pistils in mutant strains contain a higher number of stigmas ‚Äì the part of the pistil that collects pollen ‚Äì than in wildtype strains. Yellow bars indicate 1mm.</figcaption></figure></div>



<p>They found that microRNA2118 triggered the cleavage of long non-coding RNA, producing many tiny RNA molecules, called secondary small RNAs.</p>



<figure><p>
<iframe title="Abnormalities in stamens" src="https://player.vimeo.com/video/429873138?dnt=1&amp;app_id=122963" width="1080" height="608" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe>
</p></figure>



<p>‚ÄúInterestingly, these small RNAs were rich in uracil, one of the four nucleotide bases found in RNA, which is very unusual compared to other small RNAs,‚Äù said Dr. <a href="https://groups.oist.jp/stg/reina-komiya-phd" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">Komiya</a>. ‚ÄúWe hope to find out the exact function of these small RNAs ‚Äì and whether this difference in nucleotide composition is important ‚Äì in further research.‚Äù</p>



<p>The scientists also discovered that two Argonaute proteins that were only produced in the stamen were dependent on the presence of microRNA2118. Previous research has shown that Argonaute proteins team up with small RNAs to carry out many regulatory functions, such as silencing genes and cleaving RNA.&nbsp;</p>



<p>Dr. <a href="https://groups.oist.jp/stg/reina-komiya-phd" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">Komiya</a>‚Äôs group therefore proposes that the Argonaute proteins may interact with microRNA2118 to trigger production of the secondary small RNAs. The proteins may also interact with the secondary small RNAs to silence specific regions of the genome. The team hopes to elucidate exactly how the Argonaute proteins and secondary small RNAs affect development of the plant reproductive system in further research.</p>



<div><figure><img src="https://globalplantcouncil.org/wp-content/uploads/2020/07/20200619-proposed-mechanism-microRNA2118.png" alt="" srcset="https://globalplantcouncil.org/wp-content/uploads/2020/07/20200619-proposed-mechanism-microRNA2118.png 480w, https://globalplantcouncil.org/wp-content/uploads/2020/07/20200619-proposed-mechanism-microRNA2118-300x195.png 300w" sizes="(max-width: 480px) 100vw, 480px"><figcaption>MicroRNA2118 targets over 1000 long non-coding RNAs for cleavage to produce many secondary uracil-rich small RNAs, which is possibly aided by Argonaute. These secondary small RNAs then may interact with Argonaute to regulate development of reproductive organs.</figcaption></figure></div>



<p>‚ÄúReproduction is an important phenomenon of passing genetic information to the next generation and is essential for maintaining a stable yield supply. However, development of the reproductive system is complicated, and many aspects remain unknown,‚Äù concluded Dr. Komiya. ‚ÄúThis study shows that non-coding RNAs, derived from regions of the genome that were thought to be non-functional, are vital for plant reproduction. Exploring non-coding RNAs further is an exciting and important area of research.‚Äù</p>



<div><figure><img src="https://globalplantcouncil.org/wp-content/uploads/2020/07/20200603-researchers-study-1.jpg" alt="" srcset="https://globalplantcouncil.org/wp-content/uploads/2020/07/20200603-researchers-study-1.jpg 480w, https://globalplantcouncil.org/wp-content/uploads/2020/07/20200603-researchers-study-1-300x235.jpg 300w" sizes="(max-width: 480px) 100vw, 480px"><figcaption>Top left: Saori Araki (Science and Technology Group), top right: Reina Komiya (Science and Technology Group), bottom left: Koji Koizumi (Imaging Section), bottom right: Ngoc Tu Le (Plant Epigenetics Unit).</figcaption></figure></div>



<p><strong>Read the paper: </strong><em><a href="http://dx.doi.org/10.1038/s41467-020-16637-3" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">Nature Communications</a></em></p>



<p><strong>Article source</strong>: <a href="https://www.oist.jp/news-center/press-releases/study-finds-%E2%80%98dark-matter%E2%80%99-dna-vital-rice-reproduction" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">Okinawa Institute of Science and Technology (OIST) Graduate University</a></p>



<p><strong>Author: </strong><a href="https://www.oist.jp/creator/dani-ellenby" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">Dani Ellenby</a></p>



<p><strong>Images credit</strong>: <a href="https://www.oist.jp/news-center/press-releases/study-finds-%E2%80%98dark-matter%E2%80%99-dna-vital-rice-reproduction" target="_blank" rel="noreferrer noopener">Okinawa Institute of Science and Technology (OIST) Graduate University</a></p>
 						
				</div><!--/content-inner-->

						
		</div><!--/post-content-->

	</div><!--/inner-wrap-->
		
</article><!--/article-->

			</div><!--/span_9-->
			
			
							
				<!--/sidebar-->
				
							
		</div></div>]]>
            </description>
            <link>https://globalplantcouncil.org/study-finds-dark-matter-dna-is-vital-for-rice-reproduction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23897225</guid>
            <pubDate>Mon, 20 Jul 2020 12:49:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Twitter Got Hacked, Is Mastodon Immune?]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 95 (<a href="https://news.ycombinator.com/item?id=23896994">thread link</a>) | @yogthos
<br/>
July 20, 2020 | https://mikestone.me/twitter-got-hacked-is-mastodon-immune | <a href="https://web.archive.org/web/*/https://mikestone.me/twitter-got-hacked-is-mastodon-immune">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Unless you've been hiding under a rock the last week or so, you probably know that Twitter got ‚Äúhacked‚Äù. So, is Mastodon immune from having the same thing happen to it?</p>

<p>Before we can determine if Mastodon is in any better place than Twitter, we have to understand how Twitter's ‚Äúhack‚Äù occurred.</p>

<p><a href="https://www.cnet.com/news/twitter-says-hackers-got-access-to-internal-tools-for-hijacking-spree/" rel="nofollow">CNET Reports</a>:</p>

<blockquote><p>We detected what we believe to be a coordinated social engineering attack by people who successfully targeted some of our employees with access to internal systems and tools</p></blockquote>

<p>Social engineering is <a href="https://en.wikipedia.org/wiki/Social_engineering_(security)" rel="nofollow">defined</a> as, ‚ÄúThe psychological manipulation of people into performing actions or divulging confidential information.‚Äù</p>

<p>I would argue, and I'm sure most people would agree with me, that no one is perfectly immune from social engineering. It's part of being human, and as long as humans are involved in the situation, it's going to be a vulnerability.</p>

<p>I would also argue Mastodon's distributed nature makes such a coordinated and far reaching attack much less likely.</p>

<p>The attackers in this case targeted high profile individuals, and gained access to Twitter's own internal tools using social engineering. Obviously Mastodon has it's own internal tools, but those tools on <a href="https://mastodon.social/" rel="nofollow">mastodon.social</a> have absolutely no effect on <a href="https://fosstodon.org/" rel="nofollow">Fosstodon</a>, and vise versa.</p>

<p>If attackers wanted to coordinate a similar attack on Mastodon, they'd have to stick to individuals on a particular instance, or they'd have to socially engineer moderators/administrators on multiple instances.</p>

<p>No, this isn't an impossible task. After all, more than one individual was compromised in the Twitter hack. I do think it's more difficult though.</p>

<p>Twitter's response to this whole mess is also worth taking a look at. When Twitter discovered the ‚Äúhack‚Äù, they immediately locked out all access to verified Twitter accounts. This caused a whole lot of problems for a whole lot of people, but I'm not going to talk about this now.</p>

<p>If Mastodon were to be ‚Äúhacked‚Äù in the same way, the same outcome would not occur. Just because one instance of Mastodon is compromised does not mean that they all are. If one instance has to lock down accounts to reduce risk, the rest can continue to operate as they always have.</p>

<p>For the time being, Mastodon remains a small enough presence in the social media sphere that this kind of attack hasn't been worth the time. It is growing, and in time it very well may grow to a point where it is. While Mastodon isn't entirely immune to this kind of attack, it is more difficult and less rewarding. That makes is less of a target, even if all other things are equal.</p>

<p>Day 68 of the <a href="https://mikestone.me/tag:100DaysToOffload" rel="nofollow"><span>#</span><span>100DaysToOffload</span></a> Series:</p>
</div></div>]]>
            </description>
            <link>https://mikestone.me/twitter-got-hacked-is-mastodon-immune</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896994</guid>
            <pubDate>Mon, 20 Jul 2020 12:17:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Z80 Explorer ‚Äì a Zilog Z80 netlist-level simulator]]>
            </title>
            <description>
<![CDATA[
Score 138 | Comments 13 (<a href="https://news.ycombinator.com/item?id=23896816">thread link</a>) | @segfaultbuserr
<br/>
July 20, 2020 | https://baltazarstudios.com/z80explorer/ | <a href="https://web.archive.org/web/*/https://baltazarstudios.com/z80explorer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<p><em>Z80 Explorer</em> is a Zilog Z80 netlist-level simulator capable of running Z80 machine code and also an educational tool with features that help reverse engineer and understand this chip better.</p>
<p>Z80 Explorer is a tool I wished I had a few years ago when I first started looking at the photos of Z80 chip die and was learning to reverse-engineer its <a aria-label="undefined (opens in a new tab)" href="https://baltazarstudios.com/anatomy-z80-gate/" target="_blank" rel="noreferrer noopener">features</a>. The process was slow and painful as it involved deciphering the faint image traces into logic gates and functions.</p>
<p>Sometimes later, I‚Äôve found that the Visual6502 team have done a wonderful work with mapping the cpu‚Äôs traces into bitmaps representing various layers. Their online viewing <a href="http://www.visual6502.org/JSSim/expert-z80.html" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">tool </a>is impressive and one can learn a lot from using it, but as most online tools, it has limitations which I quickly hit when trying to understand the chip behavior in more depth.&nbsp;</p>
<p>As I kept playing with the online tool, my wish list of additional features steadily grew. I would have wanted it not only to be a fully functional and a fast simulator but also to provide more elaborate ways to gain deeper insights into the chip's internal behavior, while also being educational, easy, and intuitive to use.</p>
<p>Fast forward to today, and with the help of repeated COVID-19 stay-at-home orders, I have written this tool to be the way I originally imagined it.</p>
<figure><a href="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-app.png" target="_blank" rel="noopener noreferrer"><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-app.png" alt=""></a><figcaption>Z80 Explorer (click to enlarge)</figcaption></figure>
<p>In this blog, I will give an overview of <em>Z80 Explorer</em>'s capabilities and show a couple of useful features which might be easy to miss even after reading the documentation. This blog may change periodically along with the tool itself as I am actively developing it at the moment (Summer 2020).</p>
<p>The tool's user‚Äôs guide is a separate online document located here <a aria-label="undefined (opens in a new tab)" href="https://baltazarstudios.com/Z80ExplorerGuide/" target="_blank" rel="noreferrer noopener">https://baltazarstudios.com/Z80ExplorerGuide</a> It is very concise; if something is still unclear, please email me and I will expand on it.</p>
<p>The tool is written to load and use the Z80 dataset (layer images and netlist). It should be able to accommodate other NMOS chips with minimal changes. However, at this time I haven't done any other ports yet as I was solely focused on Z80. The chip's data (resources) are kept separate from the application and can be independently downloaded and updated from a shared <a aria-label="undefined (opens in a new tab)" href="https://github.com/gdevic/Z80Explorer_Z80" target="_blank" rel="noreferrer noopener">github repo</a>. In particular, as the functions of various nets is understood and nets and buses get named, the list of the net names, tips and annotations can grow and be shared.</p>
<p><em>Z80 Explorer</em> is capable of running native Z80 code at the netlist level. That means, as the instruction opcodes are fed to its pins, the binary 1s and 0s propagate through its internal nets of transistor gates and perform the function identical to what the silicon gates would do on a real chip.</p>
<p>The engine that runs it is quite fast: On my 4GHz i7-4790K CPU, I am able to run Z80 code at around 2.3kHz which is (only!) around 2000 times slower from the speed it would have run on the real silicon. At those ‚Äúspeeds‚Äù, it is not inconceivable to run some of the standard CPU diagnostic programs - so I did just that: I run a well known ZEXALL diagnostic program.&nbsp;</p>
<p>That program normally takes hours even on a real Z80. </p>
<p>After a few days of running within the simulator, the list of passing tests kept growing. At one point, after a week or so, the simulator‚Äôs internal cycle counter overflowed its 32-bit variable and the simulation stopped. I simply had to resume it, with no need to reset it and with no loss to the accumulated progress.</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-zexall.png" alt=""><figcaption>Z80 Explorer running ZEXALL diagnostic</figcaption></figure></div>
<p>I have added that version of ZEXALL to the app resources. It is modified from the original in that I had sorted the tests by how long they run: with the quickest going first, it does not take too long before you start seeing some results, assuring you that it is indeed running well.</p>
<p><em>Z80 Explorer</em> has "Image views" where it shows various versions of chip images. Some of them are unmodified resource files shown as layers (diffusion, metal layer etc.), and some are created as combinations of those: vss.vcc.nets.col is a layer with the nets colored such that ground is shown as green, vcc red, and the rest of the nets are colored according to user filters.</p>
<p>You can view different layers and create combinations of them if you hold down the Ctrl key while clicking on layer buttons, or press a key assigned to each layer while holding down the Ctrl key.</p>
<p>The chip/layer view can also be annotated. The application loads a default annotation file (containing those annotations) when it starts, but you can load any other annotation file by dragging that file and dropping it into the application image view. For example, ‚Äúannot_internals.json‚Äù (located in the resource folder) contains a different set of annotations focused more on the internal features. Annotations are adaptive so that they will show and hide as you zoom in and out. They also can contain "macros", which are tokens that expand into named net's and bus' values, and those are updated in real time, as the simulation runs.</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/image.png" alt=""><figcaption>Dynamic annotations showing U and V bus values (~ means "inverted")</figcaption></figure></div>
<p>In my older article <a aria-label="undefined (opens in a new tab)" href="https://baltazarstudios.com/z80-instruction-register-deciphered/" target="_blank" rel="noreferrer noopener">here</a> I looked at the Instruction Register. The signal that enables loading it is a complementary WE (Write Enable) pair of control traces.</p>
<p>Can we find exactly at what time(s) the write enable, now called, "load_ir", is asserted? What is the internal logic equation that governs this control signal?</p>
<p>Using the <em>Z80 Explorer</em>'s "Find" option to search for "load_ir" signal name, and then asking for the schematic of that net, brings up this view:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir1.png" alt=""><figcaption>Schematic view for "load_ir" net</figcaption></figure></div>
<p>Hence, the signal is generated by OR'ing net 255 with a latch. Let's follow net 255 which is a NAND gate of clock (hence, a clock gating) with the net 1329. Selecting (double-clicking on) 1329 and asking for the schematic brings us even closer to what we expected to see:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-1329.png" alt=""><figcaption>Schematic view for net 1329</figcaption></figure></div>
<p>Therefore, the net 1329 is a clock-gated, NAND-combined signal, active when M3, T3 and PLA22 are active. PLA22 represents "IX/IY+CB" instruction extension decode. (The description of PLA22 is held in the application "tips" file as are descriptions of all other PLA entries and some other important nets).</p>
<p>Back to the latch 244 - and this part may not too obvious unless you have some experience looking at the chip traces - the net 244 is at the bottom and the latch set and reset signals are at the top, both clock-gated:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-244.png" alt=""><figcaption>Latch at the net 244</figcaption></figure></div>
<p>Asking for the schematic of the net 1306 (the one connected from the top-left), which also acts as the latch reset:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-1306.png" alt=""><figcaption>Latch 244 reset</figcaption></figure></div>
<p>we see that the latch will reset on the "internal reset" or a T3 cycle. The latch will be set on an M1 and T2 cycle edge (so it will show at M1/T3):</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-1307.png" alt=""><figcaption>Latch 244 set</figcaption></figure></div>
<p>We can verify what we've found by running a hand-crafted test code. I used a template test program "test_blank.asm" to code in a couple of instructions, one of them using IX register, and then I run it for a couple of cycles. In a Waveform view window the result shows how the load_ir signal is being asserted at every M1/T3 as well as at M3/T3, when the instruction is using the IX/IY prefix (PLA22 active).</p>
<div><figure><a href="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-wave.png" target="_blank" rel="noopener noreferrer"><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-wave.png" alt=""></a><figcaption>Waveform diagram showing "load_ir" signal (click to enlarge)</figcaption></figure></div>
<p>Next, load the "annot_internals.json" file by dropping it onto on the application's image view (the main pane).</p>
<p>You can zoom into the area where are all M and T latches located by pasting this command into the Command Window:&nbsp;</p>
<p><code>img.setZoom(0.98); img.setPos(1151,901)</code></p>
<p>On the startup, the app will try to detect latches, and it will detect most of them automatically. For those not detected, you can add them as you find them. The easiest way to find latches is by using the ‚ÄúDriven by‚Äù option. After selecting a net and following its signal chain, if you see two nets being driven by each other in a co-dependent loop, you have found a latch that consists of those two nets (they also act as inverters). One of the app's initialization files, "latches.ini" contains definitions of additional latches. You can add to that file as you find latches that the app did not detect.</p>
<p>Schematic view uses an expanded version of such ‚ÄúDriven by‚Äù algorithm to build a tree of gates that contribute to the selected net.</p>
<p>Going the other way, the ‚ÄúDriving nets‚Äù option assists you to trace an input net as it branches into the network. For example, pick the /RESET input pad and iterate ‚ÄúDriving nets‚Äù, following the highlighted lines. Soon, you should reach a ‚Äúdead end‚Äù, with the nets which apparently nothing is driving, here:</p>
<p><code>img.setZoom(2.926); img.setPos(338,606); img.show(294,548,80,101)</code></p>
<p>About these commands: In order to create these zoom and position commands yourself, set up a desired view and then type ‚Äúimg.state()‚Äù in the Command window. The required lines will be printed in the Application Log window.</p>
<p>To obtain the coordinates used in the img.show() command, right-click and select an area you wanted to highlight, and then simply read the coordinates from the Log window and paste them into img.show() as arguments.</p>
<p>The particular network mentioned above contains reset input flops and latches. One of the control signals coming out of it is ‚Äúint_reset‚Äù, or internal reset:</p>
<p><code>img.find("int_reset")</code></p>
<p>This signal branches off to different parts of the chip.&nbsp;</p>
<p>Every chip normally has several signals that are propagated across its die to literally every corner. Some of those networks are power, ground, reset and the clocking network. (Newer chips implement various ‚Äúgating‚Äù to parts of the design to limit the power consumption, but Z80 does not do such thing.)&nbsp;</p>
<p>I have already mention the Waveform view. This view should be familiar to anyone who has worked with simulation tools like ModelSim; but even for the rest, it should still be very simple and intuitive to use.</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/image-1.png" alt=""><figcaption>Waveform view can display signals in a variety of formats</figcaption></figure></div>
<p>The important thing to remember is to ‚Äúname‚Äù the net that you wish to observe, if it hasn't been named yet, before you can add it to the waveform view. Double click on the net and select ‚ÄúEdit net name...‚Äù. You can type any name; a ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://baltazarstudios.com/z80explorer/">https://baltazarstudios.com/z80explorer/</a></em></p>]]>
            </description>
            <link>https://baltazarstudios.com/z80explorer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896816</guid>
            <pubDate>Mon, 20 Jul 2020 11:41:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Make Your Feed Discoverable]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23896773">thread link</a>) | @itsjloh
<br/>
July 20, 2020 | https://jloh.co/posts/make-your-feed-discoverable/ | <a href="https://web.archive.org/web/*/https://jloh.co/posts/make-your-feed-discoverable/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <div>
        <p>Time and time again I come across fantastic blogs that I want to subscribe to but can‚Äôt find a feed for. First I try putting the site into my RSS reader (<a href="https://miniflux.app/" title="Miniflux website" target="_blank" rel="noopener">Miniflux</a> is my tool of choice) but it often can‚Äôt find anything. Then I search around the site for the little RSS icon or a link but come up blank. As a last resort I start sticking common paths on the domain and with some luck I might finally find a feed on <code>/feed.xml</code> or <code>/rss/</code>. RSS feeds <a href="https://news.ycombinator.com/item?id=22497184" title="Hacker News thread on whether RSS is dead" target="_blank" rel="noopener">aren‚Äôt dead</a>, there isn‚Äôt a reason for it to be this hard.</p>
<p>I understand publishing feed links might not fit some website designs and isn‚Äôt something I‚Äôm going to suggest everyone goes out and fixes.</p>
<p>What I <em>do</em> think is fair is websites properly publishing their feeds so my feed reader <em>can</em> find them automatically. Most modern CMS‚Äô do this properly but with the rise of people writing their own themes from scratch properly linking them often gets left by the wayside.</p>
<p>All they need to do is add <code>link</code> elements in their <code>head</code> section like this:</p>
<div><pre><code data-lang="html"><span>&lt;</span><span>link</span> <span>rel</span><span>=</span><span>"alternate"</span> <span>href</span><span>=</span><span>"/index.xml"</span> <span>type</span><span>=</span><span>"application/rss+xml"</span> <span>title</span><span>=</span><span>"James Loh feed"</span> <span>/&gt;</span>
</code></pre></div><p>Thats it. My RSS reader now picks up the feed and title set and I can subscribe in one click via Miniflux‚Äôs bookmarklet.</p>
<p>Please, don‚Äôt forget to add your feeds properly.</p>

      </div>
      
    </div></div>]]>
            </description>
            <link>https://jloh.co/posts/make-your-feed-discoverable/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896773</guid>
            <pubDate>Mon, 20 Jul 2020 11:32:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Different Take on Fukushima]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23896730">thread link</a>) | @baud147258
<br/>
July 20, 2020 | http://www.funraniumlabs.com/2020/07/a-different-take-on-fukushima/ | <a href="https://web.archive.org/web/*/http://www.funraniumlabs.com/2020/07/a-different-take-on-fukushima/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p><span>I don‚Äôt know how many times I‚Äôve started, stopped, and deleted trying to write something up on my trip to the Fukushima Hard-To-Return-To Area, AKA the Futaba District of the Fukushima Prefecture. Unfortunately, thanks to COVID-19, I have plenty of time to write this up now. I want to give thanks at the outset to my friend Robyn, the Hollywood photographer who I went with to Chernobyl, who came on this trip too and can view her gorgeous work <span><a href="https://www.vonswank.com/Curiosities-/JAPAN:-FUKUSHIMA/thumbs">here</a><span>, some of which I‚Äôve used in this post</span></span>. I also want to give high fives to Jen Miller for inspiring me to see if I could make this visit even happen when we went to see sumo and to Brian Wanamaker who‚Äôs translation skills allowed the serendipitous, sake-filled meeting with Kae to be an inspiration. And, lastly, thanks to everyone who purchased a <span><a href="https://shop.funraniumlabs.com/products.php?product=The-Coffee-Wave-750ml">‚ÄúCoffee Wave‚Äù BBotE</a></span> bottle for making sure we had the cash on hand to have ADVENTURES!</span></p>
<p><span>From the top, I‚Äôm not gonna discuss the ongoing work at Fukushima Daiichi. Plenty of ink and electrons already spent on TEPCO and JAEA doing what they can there. We can hope for a TV show that summarizes the events at the power plant as the T≈çhoku quake and tsunami struck as well as HBO‚Äôs Chernobyl did. My quibbles with that show are minor at best. My favorite thing about it was people coming to me saying ‚ÄúPhil, I think they got something wrong on Chernobyl‚Äù and my grin of evil delight when I got to tell them that <a href="https://twitter.com/clmazin">Craig Mazin</a> lovingly captured period authentic Soviet bullshit and presented it faithfully. But I digress, because what is more interesting to me is the efforts to decontaminate, rehabilitate, and re-inhabit the abandoned area around the power plant. The example of the Chernobyl Exclusion Zone and the ‚Äúsettlers‚Äù, who are mostly pensioners left in the lurch by the Soviet collapse, gives one path. </span></p>
<p><span>That‚Äôs not what Japan did/is doing. But let me say this right now, because belaboring this is what caused me to abort so many previous versions of this post:</span></p>
<h4><span>These towns aren‚Äôt coming back. Not because they‚Äôre doing a bad job at cleanup. On the contrary, they‚Äôre doing an amazing job and are <em><strong>WAY </strong></em>more thorough than the Soviet Liquidators ever were. That is my professional opinion. Unlike Pripyat, a young nuclear boomtown for high fliers, the rural communities around Fukushima Daiichi were already fading away. The quake and tsunami just accelerated the pace.</span></h4>
<p><span>There. I said it. Now maybe I can explain why without tripping over myself.</span></p>
<p><span>This tale starts eight years ago, on March 11, when my career took a dramatic shift when some tectonic plates moved too. If you search for ‚ÄúUC Berkeley radiation specialist‚Äù this is very close to my and a former coworker‚Äôs job title. We both lost <em>month</em>s of work responding to a fire hose of phone calls, emails, and even faxes as the entire Pacific Rim turned to us as because The Algorithm‚Ñ¢ <em>clearly</em> indicated we were the experts on what to do in when a reactor accident happened. More often than not, we had to refer everyone to the public affairs office who promptly turned around and asked us what they should say. This is the price of being professional staff and not tenured faculty; we don‚Äôt have the freedom of expression that comes with tenure, we‚Äôre just employees. I would like to note that this doesn‚Äôt necessarily mean the tenured faculty knew anything about what they were commenting on, but they do have the freedom to spout off to their heart‚Äôs content to any microphone and camera that came near. I actually went back to read <span><a href="http://www.funraniumlabs.com/2011/03/post-tsunami-japanese-reactor-problems/">the post I made two days after the quake</a></span> and was quite surprised to see how well I covered things.</span></p>
<p><span>For everyone that has now seen the Chernobyl miniseries on HBO and has that vision in their head for Fukushima Daiichi, you missed the big differences: there was no graphite fire and, holy crap, that was a hell of a quake and tsunami. For everyone now coming to grips with the idea of a double hit of pandemic and then economic collapse with COVID-19, try the <em>triple</em> disaster of one of the largest earthquakes ever recorded, a huge tsunami, and then slap a nuclear reactor accident on top of that. On a positive note, at least this triple disaster was relatively local in scope. The contamination around the Futaba District is due to the fuel rods leaking some fission products and a bunch of contaminated/activated sea water from the tsunami plus the cooling water of last resort pumping into the spent fuel pools without filtration (much less deionization) first. There were thousands of tons of graphite that lit on fire and exploded at Chernobyl, lofting a totally different set of radioactive materials across the world. Don‚Äôt get me wrong, we could detect Fukushima drifting on the breeze across the Pacific within 48hrs but the isotopic mix and quantity was <em>very</em> different than Chernobyl‚Äôs. And, as always, the drum I beat constantly for public education: there is a world of difference between ‚Äúdetectable‚Äù and ‚Äúdangerous‚Äù.</span></p>
<hr>
<p><span>We were met at the train station by Shuzo in a prefectural government van. He made sure that the ID we‚Äôd brought with us matched what I‚Äôd supplied to him a few months earlier because and, I quote, ‚ÄúIt would be very embarrassing if it did not as I wrote the security procedures.‚Äù A little later as we drove past a cultural festival and Shuzo gave an embarrassed chuckle as he said he should probably drive a little bit faster in case some of his people working the fairgrounds saw the van. I asked him how many people worked for him in his office. He replied with some uncertainty ‚Äú‚ÄùFour‚Ä¶five hundred? Plus contractors, of course.‚Äù I slowly turned my head as realized I wasn‚Äôt talking to someone in a roughly similar position to me back in the states, but rather an agency head that reported directly to the governor‚Ä¶ and he had volunteered himself as a driver and guide because this project is so important to him. Some recalibration of the honor that was being done for us happened in my head then and there.</span></p>
<p><span>Shuzo has a dream to get his hometown back. As a ‚Äúhometown boy done good‚Äù he isn‚Äôt just any prefectural official, he had to order his own family out of their homes and off their farms. He evacuated the JAEA office during the emergency. What he wants more than anything is for the communities to come back after the quake/tsunami/nuclear accident triple disaster. And, yes, you should always look at this is in that order of severity; the reactors were the least of the three but it has the consequences everyone is afraid of. The people most afraid of the quake and tsunami are, well, dead. As part of the TEPCO/JAEA remediation plan, as the Japanese government made a commitment that Futaba would not be abandoned like the Chernobyl Exclusion Zone and had learned some lessons from that; all of the local towns and farms were offered a settlement to turn everything over for decontamination and/or demolition. Shuzo‚Äôs job is to make that happen. He is quite literally in charge of everything that is outside of the power plant decontamination project. The first place he wanted to take us was to his father‚Äôs farm.</span></p>
<p><span>I helpfully already did some work of sharing an introduction to my hosts in 2018 when I first started writing this up. From that <span><a href="http://www.funraniumlabs.com/2018/10/fukushima-exclusion-zone-preview-announcements/">post</a></span>:</span></p>
<blockquote><p><span>First off, let me introduce you to Shuzo Sakai, Karin Taira and their project, <span><a href="https://real-fukushima.com/">Real Fukushima</a></span>. Unlike the Chernobyl tours of varying quality done by various independent operators, this is a Fukushima Prefecture government project to show the work done for decontamination and rehabitation of the towns in the Fukushima Exclusion Zone. Karin runs the prefecturally sponsored B&amp;B in Odaka called <span><a href="https://www.tripadvisor.com/Hotel_Review-g1022396-d12926635-Reviews-The_Lantern_House-Minamisoma_Fukushima_Prefecture_Tohoku.html">Lantern House</a></span> which I highly recommend if you have the time to stay overnight (sadly, I did not). Shuzo is a prefectural government official who grew up in a town that is now in the exclusion zone and he‚Äôs become head of the redevelopment agency. When you are the boss, you‚Äôre allowed to give yourself any extra tasks you want; the one he has chosen for his extracurricular activities is showing people the work done to rebuild and reoccupy. Only foreigners at the moment because, and I quote, ‚ÄúI feel foreigners have less radiophobia than the Japanese.‚Äù While I didn‚Äôt laugh out loud at this, I did tell him that if this was actually the case that my day job would be much easier. As a local boy done good, Shuzo‚Äôs desire is to see the people in the towns he‚Äôs always known and loved come home. He would also like people all over the world to see their hometowns in his. That you might remember to give your loved ones a call now and then, maybe go home and visit. They miss you, you know. :)</span></p>
<p><span>Shuzo is the person that wrote the procedures for entry into the Fukushima Exclusion Zone. Shuzo is the person who is ultimately responsible for the decon, demolition and reconstruction of all the towns in the Exclusion Zone. This is personal to him.&nbsp;</span></p></blockquote>
<div id="attachment_5054"><p><a href="http://www.funraniumlabs.com/wp-content/uploads/2020/04/IMG_8262.jpg"><img aria-describedby="caption-attachment-5054" src="http://www.funraniumlabs.com/wp-content/uploads/2020/04/IMG_8262-225x300.jpg" alt="forest line" width="225" height="300" srcset="http://www.funraniumlabs.com/wp-content/uploads/2020/04/IMG_8262-225x300.jpg 225w, http://www.funraniumlabs.com/wp-content/uploads/2020/04/IMG_8262-773x1030.jpg 773w, http://www.funraniumlabs.com/wp-content/uploads/2020/04/IMG_8262-768x1024.jpg 768w, http://www.funraniumlabs.com/wp-content/uploads/2020/04/IMG_8262-529x705.jpg 529w, http://www.funraniumlabs.com/wp-content/uploads/2020/04/IMG_8262.jpg 1080w" sizes="(max-width: 225px) 100vw, 225px"></a></p><p id="caption-attachment-5054"><span>The Treeline At Shuzo‚Äôs Dad‚Äôs Place ‚Äì once you hit that forest litter, the background count rate triples</span></p></div>
<p><span>Among the people that had to be evacuated were Shuzo‚Äôs parents. Shuzo isn‚Äôt the eldest son, so his brother‚Äôs family ended up taking them in. And then when the evacuation area was expanded, all of them got evacuated again together. This was a bit too much stress on his mother and she passed away. For the next several years, his father lived with his brother‚Äôs family even after dad‚Äôs home and farm were decontaminated because they didn‚Äôt necessarily trust dad to live on his own. At 82, he‚Äôd literally never done laundry or really cooked a meal in his life so they needed to teach him some basic survival skills before they could let him go back home to live alone. His father‚Äôs farm is a good demonstration piece to show the success of decon allowing reoccupation, but also it‚Äôs limitation. The house, driveway, sheds, and yard had no detectable radiation above background, but you didn‚Äôt have to walk far into the trees at the edge of the property for the count rate to rise a bit. This is a reflection of the phased approach to decontamination: homes/cities, then farms, ‚Ä¶</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.funraniumlabs.com/2020/07/a-different-take-on-fukushima/">http://www.funraniumlabs.com/2020/07/a-different-take-on-fukushima/</a></em></p>]]>
            </description>
            <link>http://www.funraniumlabs.com/2020/07/a-different-take-on-fukushima/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896730</guid>
            <pubDate>Mon, 20 Jul 2020 11:23:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why the bioinformatic industry needs to privatize]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23896711">thread link</a>) | @philippz
<br/>
July 20, 2020 | https://philippzentner.com/problems-bioinformatic-industry-privatization | <a href="https://web.archive.org/web/*/https://philippzentner.com/problems-bioinformatic-industry-privatization">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Disclaimer: This article is based on a multitude of conversations with mainly bioinformaticians that have many years of experience in working with and in academics, biotech, CROs/pharma companies. This post sums up these shared experiences.&nbsp;&nbsp;</p><p><span>The bioinformatics industry is relatively young. Well, at least immature, so it seems. It has been around for a while and there was for sure</span><a href="http://madhadron.com/posts/2012-03-26-a-farewell-to-bioinformatics.html"><span> a lot to complain about 8 years ago</span></a><span>. Now, 8 years later, it continues growing but has it really changed?</span></p><p><span>Let‚Äôs quickly recap with how I got here: Last year we started evaluating potential business cases. The one that hooked me the most was the idea to offer DNA- and RNA-sequencing analysis as SaaS. We‚Äôd not only offer variant calling and gene expression but also a machine learning optimised approach for alternative splicing, which is much more error prone these days. Thus, I dived into bioinformatics by starting to talk to potential clients, experts, investors, work-horses and used every second of my spare-time to learn about genomics and transcriptomics.</span></p><p><span>Eventually the team split into research-oriented and business-oriented, and while we continued researching the market in search for a use-case for a SaaS opportunity, our research-oriented counterparts started a consulting business. Their projects cover a wide range of cases, from single cell organisms to humans, from basic research to clinical. But as is often the case for consultancy, their work is not scalable, and their feedback clearly shows some yet existing challenges in the industry of bioinformatics. In the meantime, we continued researching the market and having lengthy conversations with bioinformaticians (big shout out to the </span><a href="http://www.independentdatalab.com/"><span>Independent Data Lab</span></a><span>) and potential clients over the last year. Here is my quick observation of what is (still) going on.</span></p><h2><strong>Poor Programming Paradigms</strong></h2><p><span>Despite a fast-growing bioinformatic ecosystem the software quality remains surprisingly low. One key reason for this is that the tools are often developed and maintained by a single person. For example, Nextflow, which is one of the most popular workflow management systems in Bioinformatics, <a href="https://github.com/nextflow-io/nextflow/graphs/contributors" title="Nextflow Code Contributors" rel="nofollow">has about 90% of its code contributed by a single developer</a></span><span>. STAR aligner, which is one of the most popular aligners for RNA-seq data, as well has been </span><a href="https://github.com/alexdobin/STAR/graphs/contributors" title="STAR Aligner Code Contributors" rel="nofollow">primarily developed by one contributor</a><span>. Not saying that Nextflow or STAR aligner are suffering under bad code quality, but the fact that it is mainly maintained by a single person, is a risk and as a consequence, there is often no quality assurance involved in the process.&nbsp;</span></p><p><span>The lack of community-driven software development causes new problems. A single developer without greater experience in software engineering, especially without teamwork experience often neglects established code management practices. Most of the tools are missing any continuous integration workflows or use code conventions. Different programming styles (say C++ and R) are getting mixed up so that the maintenance of the code is almost infeasible. These problems are even more pronounced when it comes to development of customized pipelines by each institute, bioinformatics core facility or a lab, where code management is not only neglected but sometimes is avoided altogether.&nbsp; No version control via</span><a href="https://git-scm.com/"> <span>git</span></a><span>, no code sharing via</span><a href="https://github.com/"> <span>GitHub</span></a><span> or</span><a href="https://gitlab.com/"> <span>GitLab</span></a><span>, no branching system like</span><a href="https://www.gitflow.com/"> <span>git flow</span></a><span> (</span><a href="https://stackoverflow.com/questions/18188492/what-are-the-pros-and-cons-of-git-flow-vs-github-flow"><span>which</span></a><a href="https://www.endoflineblog.com/gitflow-considered-harmful"> <span>is</span></a><a href="https://georgestocker.com/2020/03/04/please-stop-recommending-git-flow/"> <span>debatable</span></a><span>) or versioning system a la</span><a href="https://semver.org/"> <span>semver</span></a><span>.&nbsp;</span></p><h2><strong>Academic Mindset Of Bioinformatics</strong></h2><p><span>One of the primary reasons why it is usually one developer per tool is the academic domination over the field of bioinformatics tools development. Academic labs are not paid to maintain the tool, but rather to develop and publish a new one - maintaining the software will not get you grant money. As a result, a plethora of new bioinformatics tools comes out every day, and the burden for their maintenance usually lays on the shoulders of a student or a post-doc who developed the tool as part of their degree or a project. Academic jobs are short-lived, with contracts for just several years, after which the researcher needs to move forward, often leaving the developed software behind. As a result, the state-of-the-art in bioinformatics changes rapidly, and so do the ‚Äústandards‚Äù.&nbsp;</span></p><p><span>To be fair, we did observe some convergence in best practices within the field of DNA-sequencing due to the wide adaptation of whole genome sequencing (WGS) and whole exome sequencing (WES) in clinical settings, forcing this branch of bioinformatics into more regulated, and hence more reliable state.&nbsp;</span></p><h2><strong>Reinvent All The Wheels!</strong></h2><p><span>The path of the individual programmer leads to another inefficiency: developers are building the same bioinformatic analysis pipelines over and over and over again (while no one is looking over their shoulders).With lack of collaborative development experience, many bioinformaticians prefer to re-develop their pipelines rather than try to understand someone else's code. This is a pity. All that time and money could be spent elsewhere.&nbsp;</span></p><p><span>Code needs to be developed in teams, shared and distributed, algorithms have to be improved, software should be written in faster languages and for optimised memory, CPU and GPU usages. Money should be spent on services instead of overwhelming research facilities with the same tasks over and over again. Speaking of services.</span></p><h2><strong>Neglecting Specialised Service Providers</strong></h2><p><span>Bad news for Software-as-a-Services (SaaS) or Bioinformatics-as-a-Service (BaaS). There are more and more services but they barely make money. The lack of trust into those services is astonishing. Services are not only avoided by clients but also by bioinformaticians themselves. It seems like BaaS is perceived as a threat to bioinformaticians, even though they themselves could save a lot of time using them. While in other industries new businesses are getting stacked together within days with a strong trend towards no-code platforms, bioinformaticians want to do it all by themselves, not recognising that most of these services are offering outstanding human support, proven and flexible/customisable pipelines and affordable prices. This needs to change and it will change. And the sooner the better, as it would create more room for innovation and quality.</span></p><h2><strong>Classic Management-IT-Gap&nbsp;</strong></h2><p><span>The well-known issue of management-IT gap is also widely present in the field of bioinformatic.</span><span> Most clients have a great knowledge-gap of how easy and fast results can be delivered today, they just go with it, while 90% of the time results should be available within 24 hours (max). Most of the problems have standardized solutions in place. There‚Äôs no need to wait 4 weeks for results and getting distracted in the meanwhile by having to start working on the next project already.</span></p><p><span>The main reason yet again, relies on the academic domination of the bioinformatics world. Academics often prioritize money over time - they would rather spend less and wait weeks for the results, than pay and get the result tomorrow. Furthermore, industry is often demonized by academics as evil, only caring for making money and not caring for state-of-the-art and quality, while bioinformatics core facilities offer sequencing services with ‚Äúfree‚Äù bioinformatics support. But of course, as we know, only the cheese in the mousetrap is free. The analyses at core facilities are often performed by young PhD students and post-docs in addition to their thesis projects, with the pipelines that they developed and maintain themselves, resulting in weeks of delivery time and poor communication (often xls tables with very little explanation or follow-up).&nbsp;</span></p><p><span>In contrast, most BaaS offer the results within 24 hours, provide interactive platforms for visualization and results browsing, historic data management, and an extensive follow-up on the results. And yet, the myth of the demonic industry persists, and researchers in need for bioinformatics turn to academic collaboration rather than seeking industrial partners.&nbsp;&nbsp;</span></p><h2><strong>Conclusion</strong></h2><h3>Clinical Decisions A Made Based On Non-Proofed Analysis Pipelines</h3><p><span>To emphasize the necessity to rethink and invest in the bioinformatic ecosystem, we need to talk about its meanings. </span><a href="https://en.wikipedia.org/wiki/Massive_parallel_sequencing"><span>Next Generation Sequencing (NGS)</span></a><span> is becoming widely used not only in basic research, but is now also entering the clinical settings: rare disease diagnostics, personalized medicine in oncology and immuno-oncology, prenatal diagnostics to name a few. We're talking about research and diagnoses that affect human life. It has an immediate impact on individuals in the short run, as well as an impact on millions in the long-run. That means all aforementioned problems are alarming and it needs to change.&nbsp;</span></p><h3><strong>Privatization</strong></h3><p><span>The industry has to professionalize. There has to be ownership, there have to be legal entities kept responsible, there has to be quality assurance and a community that inherently cares. Bioinformatic is a typical case of public service that would, to a certain extent, heavily benefit from privatization. Competition would ensure a run for the best quality, performance and user-experience (especially improving interpretability). As bioinformatics gets closer and closer to actual healthcare and dealing with patients, we‚Äôd all benefit from it.</span></p><p>Edits:</p><p>20. July 19:07: Made clear that Nextflow and STAR aligner are not particularly examples of bad quality but of single person maintained software.</p></div></div>]]>
            </description>
            <link>https://philippzentner.com/problems-bioinformatic-industry-privatization</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896711</guid>
            <pubDate>Mon, 20 Jul 2020 11:21:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UI for Neovim Plugins in Lua]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23896684">thread link</a>) | @lukzar
<br/>
July 20, 2020 | https://www.2n.pl/blog/how-to-make-ui-for-neovim-plugins-in-lua | <a href="https://web.archive.org/web/*/https://www.2n.pl/blog/how-to-make-ui-for-neovim-plugins-in-lua">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p>In the last <a href="https://www.2n.pl/blog/how-to-write-neovim-plugins-in-lua">article</a>, we saw the basics of creating plugins in Lua using floating windows. Now it's time for a more traditional approach. Let's create a simple plugin that will show us last opened files in handy side navigation. As we focus on learning the interface, we will use vim native oldfiles list for this purpose. It will look something like this:</p>

<p><img src="https://www.2n.pl/system/photos/imgs/000/000/011/original/oldfiles.gif" alt=""></p>

<p>If you didn't read previous <a href="https://www.2n.pl/blog/how-to-write-neovim-plugins-in-lua">article</a>, I highly recommend you to do so, because this article expands on the ideas from the last one and is full of new things in comparison.</p>

<h2>Plugin window</h2>

<p>Ok, so we should start by writing a function that will create our first window, where the <code>oldfiles</code> list will be displayed. But first, we will declare three variables in the main scope of our script: <code>buf</code> and <code>win</code> that will contain our navigation window and buffer references and <code>start_win</code> that will remember the position where we opened our navigation. We will be using these often across our plugin functions.</p>
<div><pre><span>-- It's our main starting function. For now we will only creating navigation window here.</span>
<span>local</span> <span>function</span> <span>oldfiles</span><span>()</span>
  <span>create_win</span><span>()</span>
<span>end</span>

<span>local</span> <span>function</span> <span>create_win</span><span>()</span>
  <span>-- We save handle to window from which we open the navigation</span>
  <span>start_win</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_win</span><span>()</span>

  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>'</span><span>botright vnew'</span><span>)</span> <span>-- We open a new vertical window at the far right</span>
  <span>win</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_win</span><span>()</span> <span>-- We save our navigation window handle...</span>
  <span>buf</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_buf</span><span>()</span> <span>-- ...and it's buffer handle.</span>

  <span>-- We should name our buffer. All buffers in vim must have unique names.</span>
  <span>-- The easiest solution will be adding buffer handle to it</span>
  <span>-- because it is already unique and it's just a number.</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_name</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>Oldfiles #'</span> <span>..</span> <span>buf</span><span>)</span>

  <span>-- Now we set some options for our buffer.</span>
  <span>-- nofile prevent mark buffer as modified so we never get warnings about not saved changes.</span>
  <span>-- Also some plugins treat nofile buffers different.</span>
  <span>-- For example coc.nvim don't triggers aoutcompletation for these.</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_option</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>buftype'</span><span>,</span> <span>'</span><span>nofile'</span><span>)</span>
  <span>-- We do not need swapfile.</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_option</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>swapfile'</span><span>,</span> <span>false</span><span>)</span>
  <span>-- And we would rather prefer that buffer will be destroyed when hide.</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_option</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>bufhidden'</span><span>,</span> <span>'</span><span>wipe'</span><span>)</span>
  <span>-- It's not necessary but it is good practice to set custom filetype.</span>
  <span>-- This allows users to create their own autocommand or colorschemes on filetype.</span>
  <span>-- and prevent collisions with other plugins.</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_option</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>filetype'</span><span>,</span> <span>'</span><span>nvim-oldfile'</span><span>)</span>

  <span>-- For better UX we will turn off line wrap and turn on current line highlight.</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_set_option</span><span>(</span><span>win</span><span>,</span> <span>'</span><span>wrap'</span><span>,</span> <span>false</span><span>)</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_set_option</span><span>(</span><span>win</span><span>,</span> <span>'</span><span>cursorline'</span><span>,</span> <span>true</span><span>)</span>

  <span>set_mappings</span><span>()</span> <span>-- At end we will set mappings for our navigation.</span>
<span>end</span>
</pre></div>
<h2>Drawing function</h2>

<p>Okay, so we have a window, now we need something to display in it. We will use vim <code>oldfiles</code> special variable, which stores paths to previously opened files. We will take as many items from it, as we can display without scrolling, but of course, you can take as many as you want in your script. We will call this function <code>redraw</code> because it can be used to refresh navigation content. File paths might be long, so we will try to make them relative to the working directory.</p>
<div><pre><span>local</span> <span>function</span> <span>redraw</span><span>()</span>
  <span>-- First we allow introduce new changes to buffer. We will block that at end.</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_option</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>modifiable'</span><span>,</span> <span>true</span><span>)</span>

  <span>local</span> <span>items_count</span> <span>=</span>  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_get_height</span><span>(</span><span>win</span><span>)</span> <span>-</span> <span>1</span> <span>-- get the window height</span>
  <span>local</span> <span>list</span> <span>=</span> <span>{}</span>

  <span>-- If you using nightly build you can get oldfiles like this</span>
  <span>local</span> <span>oldfiles</span> <span>=</span> <span>vim</span><span>.</span><span>v</span><span>.</span><span>oldfiles</span>
  <span>-- In stable version works only that</span>
  <span>local</span> <span>oldfiles</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_vvar</span><span>(</span><span>'</span><span>oldfiles'</span><span>)</span>

  <span>-- Now we populate our list with X last items form oldfiles</span>
  <span>for</span> <span>i</span> <span>=</span> <span>#</span><span>oldfiles</span><span>,</span> <span>#</span><span>oldfiles</span> <span>-</span> <span>items_count</span><span>,</span> <span>-</span><span>1</span> <span>do</span>

    <span>-- We use build-in vim function fnamemodify to make path relative</span>
    <span>-- In nightly we can call vim function like that</span>
    <span>local</span> <span>path</span> <span>=</span> <span>vim</span><span>.</span><span>fn</span><span>.</span><span>fnamemodify</span><span>(</span><span>oldfiles</span><span>[</span><span>i</span><span>],</span> <span>'</span><span>:.'</span><span>)</span>
    <span>-- and this is stable version:</span>
    <span>local</span> <span>path</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_call_function</span><span>(</span><span>'</span><span>fnamemodify'</span><span>,</span> <span>{</span><span>oldfiles</span><span>[</span><span>i</span><span>],</span> <span>'</span><span>:.'</span><span>})</span>

    <span>-- We iterate form end to start, so we should insert items</span>
    <span>-- at the end of results list to preserve order</span>
    <span>table.insert</span><span>(</span><span>list</span><span>,</span> <span>#</span><span>list</span> <span>+</span> <span>1</span><span>,</span> <span>path</span><span>)</span>
  <span>end</span>

  <span>-- We apply results to buffer</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_lines</span><span>(</span><span>buf</span><span>,</span> <span>0</span><span>,</span> <span>-</span><span>1</span><span>,</span> <span>false</span><span>,</span> <span>list</span><span>)</span>
  <span>-- And turn off editing</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_option</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>modifiable'</span><span>,</span> <span>false</span><span>)</span>
<span>end</span>
</pre></div>
<p>We can now update our main function. We will also add some code that prevents opening multiple navigation windows. For this purpose, we can use <code>nvim_win_is_valid</code> which checks if our plugin window already exists.</p>
<div><pre><span>local</span> <span>function</span> <span>oldfiles</span><span>()</span>
  <span>if</span> <span>win</span> <span>and</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_is_valid</span><span>(</span><span>win</span><span>)</span> <span>then</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_set_current_win</span><span>(</span><span>win</span><span>)</span>
  <span>else</span>
    <span>create_win</span><span>()</span>
  <span>end</span>

  <span>redraw</span><span>()</span>
<span>end</span>
</pre></div>
<h2>Openings files</h2>

<p>We can now look at our oldfiles, but it would be much handier if we can also open them. We will allow users to open files in 5 different ways! In a new tab, in horizontal or vertical splits, in the current window and in preview mode, which will keep the focus on navigation.</p>

<p>Let's start by opening files in the current window. We should prepare for two scenarios:<br>
1. Opening a file in the window from which the user opens navigation.<br>
2. Closing the starting window, when we will create a new one for opening file.</p>
<div><pre><span>local</span> <span>function</span> <span>open</span><span>()</span>
  <span>-- We get path from line which user push enter on</span>
  <span>local</span> <span>path</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_line</span><span>()</span>

  <span>-- if the starting window exists</span>
  <span>if</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_is_valid</span><span>(</span><span>start_win</span><span>)</span> <span>then</span>
    <span>-- we move to it</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_set_current_win</span><span>(</span><span>start_win</span><span>)</span>
    <span>-- and edit chosen file</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>'</span><span>edit '</span> <span>..</span> <span>path</span><span>)</span>
  <span>else</span>
    <span>-- if there is no starting window we create new from lest side</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>'</span><span>leftabove vsplit '</span> <span>..</span> <span>path</span><span>)</span>
    <span>-- and set it as our new starting window</span>
    <span>start_win</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_win</span><span>()</span>
  <span>end</span>
<span>end</span>

<span>-- After opening desired file user no longer need our navigation</span>
<span>-- so we should create function to closing it.</span>
<span>local</span> <span>function</span> <span>close</span><span>()</span>
  <span>if</span> <span>win</span> <span>and</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_is_valid</span><span>(</span><span>win</span><span>)</span> <span>then</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_close</span><span>(</span><span>win</span><span>,</span> <span>true</span><span>)</span>
  <span>end</span>
<span>end</span>

<span>-- Ok. Now we are ready to making two first opening functions</span>

<span>local</span> <span>function</span> <span>open_and_close</span><span>()</span>
  <span>open</span><span>()</span> <span>-- We open new file</span>
  <span>close</span><span>()</span> <span>-- and close navigation</span>
<span>end</span>

<span>local</span> <span>function</span> <span>preview</span><span>()</span>
  <span>open</span><span>()</span> <span>-- WE open new file</span>
  <span>-- but in preview instead of closing navigation</span>
  <span>-- we focus back to it</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_set_current_win</span><span>(</span><span>win</span><span>)</span>
<span>end</span>
</pre></div><div><pre><span>-- To making splits we need only one function</span>
<span>local</span> <span>function</span> <span>split</span><span>(</span><span>axis</span><span>)</span>
  <span>local</span> <span>path</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_line</span><span>()</span>

  <span>-- We still need to handle two scenarios</span>
  <span>if</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_is_valid</span><span>(</span><span>start_win</span><span>)</span> <span>then</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_set_current_win</span><span>(</span><span>start_win</span><span>)</span>
    <span>-- We pass v in axis argument if we want vertical split</span>
    <span>-- or nothing/empty string otherwise.</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>axis</span> <span>..</span><span>'</span><span>split '</span> <span>..</span> <span>path</span><span>)</span>
  <span>else</span>
    <span>-- if there is no starting window we make new on left</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>'</span><span>leftabove '</span> <span>..</span> <span>axis</span><span>..</span><span>'</span><span>split '</span> <span>..</span> <span>path</span><span>)</span>
    <span>-- but in this case we do not need to set new starting window</span>
    <span>-- because splits always close navigation </span>
  <span>end</span>

  <span>close</span><span>()</span>
<span>end</span>
</pre></div>
<p>And in the end the simplest opening in new tab.</p>
<div><pre><span>local</span> <span>function</span> <span>open_in_tab</span><span>()</span>
  <span>local</span> <span>path</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_line</span><span>()</span>

  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>'</span><span>tabnew '</span> <span>..</span> <span>path</span><span>)</span>
  <span>close</span><span>()</span>
<span>end</span>
</pre></div>
<p>For everything to work, we need to add the key mappings, export all public functions, and add a command to trigger our navigation.</p>
<div><pre><span>local</span> <span>function</span> <span>set_mappings</span><span>()</span>
  <span>local</span> <span>mappings</span> <span>=</span> <span>{</span>
    <span>q</span> <span>=</span> <span>'</span><span>close()'</span><span>,</span>
    <span>[</span><span>'</span><span>&lt;cr&gt;'</span><span>]</span> <span>=</span> <span>'</span><span>open_and_close()'</span><span>,</span>
    <span>v</span> <span>=</span> <span>'</span><span>split("v")'</span><span>,</span>
    <span>s</span> <span>=</span> <span>'</span><span>split("")'</span><span>,</span>
    <span>p</span> <span>=</span> <span>'</span><span>preview()'</span><span>,</span>
    <span>t</span> <span>=</span> <span>'</span><span>open_in_tab()'</span>
  <span>}</span>

  <span>for</span> <span>k</span><span>,</span><span>v</span> <span>in</span> <span>pairs</span><span>(</span><span>mappings</span><span>)</span> <span>do</span>
    <span>-- let's assume that our script is in lua/nvim-oldfile.lua file.</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_keymap</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>n'</span><span>,</span> <span>k</span><span>,</span> <span>'</span><span>:lua require"nvim-oldfile".'</span><span>..</span><span>v</span><span>..</span><span>'</span><span>&lt;cr&gt;'</span><span>,</span> <span>{</span>
        <span>nowait</span> <span>=</span> <span>true</span><span>,</span> <span>noremap</span> <span>=</span> <span>true</span><span>,</span> <span>silent</span> <span>=</span> <span>true</span>
      <span>})</span>
  <span>end</span>
<span>end</span>

<span>-- at file end</span>
<span>return</span> <span>{</span>
  <span>oldfiles</span> <span>=</span> <span>oldfiles</span><span>,</span>
  <span>close</span> <span>=</span> <span>close</span><span>,</span>
  <span>open_and_close</span> <span>=</span> <span>open_and_close</span><span>,</span>
  <span>preview</span> <span>=</span> <span>preview</span><span>,</span>
  <span>open_in_tab</span> <span>=</span> <span>open_in_tab</span><span>,</span>
  <span>split</span> <span>=</span> <span>split</span>
<span>}</span>
</pre></div><div><pre>command<span>!</span> Oldfiles <span>lua</span> require<span>'nvim-oldfile'</span>.<span>oldfiles</span><span>()</span>
</pre></div>
<p>And that's it! Have fun and make grate things!</p>

<h2>The whole plugin</h2>
<div><pre><span>local</span> <span>buf</span><span>,</span> <span>win</span><span>,</span> <span>start_win</span>

<span>local</span> <span>function</span> <span>open</span><span>()</span>
  <span>local</span> <span>path</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_line</span><span>()</span>

  <span>if</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_is_valid</span><span>(</span><span>start_win</span><span>)</span> <span>then</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_set_current_win</span><span>(</span><span>start_win</span><span>)</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>'</span><span>edit '</span> <span>..</span> <span>path</span><span>)</span>
  <span>else</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>'</span><span>leftabove vsplit '</span> <span>..</span> <span>path</span><span>)</span>
    <span>start_win</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_win</span><span>()</span>
  <span>end</span>
<span>end</span>

<span>local</span> <span>function</span> <span>close</span><span>()</span>
  <span>if</span> <span>win</span> <span>and</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_is_valid</span><span>(</span><span>win</span><span>)</span> <span>then</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_close</span><span>(</span><span>win</span><span>,</span> <span>true</span><span>)</span>
  <span>end</span>
<span>end</span>

<span>local</span> <span>function</span> <span>open_and_close</span><span>()</span>
  <span>open</span><span>()</span>
  <span>close</span><span>()</span>
<span>end</span>

<span>local</span> <span>function</span> <span>preview</span><span>()</span>
  <span>open</span><span>()</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_set_current_win</span><span>(</span><span>win</span><span>)</span>
<span>end</span>

<span>local</span> <span>function</span> <span>split</span><span>(</span><span>axis</span><span>)</span>
  <span>local</span> <span>path</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_line</span><span>()</span>

  <span>if</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_is_valid</span><span>(</span><span>start_win</span><span>)</span> <span>then</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_set_current_win</span><span>(</span><span>start_win</span><span>)</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>axis</span> <span>..</span><span>'</span><span>split '</span> <span>..</span> <span>path</span><span>)</span>
  <span>else</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>'</span><span>leftabove '</span> <span>..</span> <span>axis</span><span>..</span><span>'</span><span>split '</span> <span>..</span> <span>path</span><span>)</span>
  <span>end</span>

  <span>close</span><span>()</span>
<span>end</span>

<span>local</span> <span>function</span> <span>open_in_tab</span><span>()</span>
  <span>local</span> <span>path</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_line</span><span>()</span>

  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>'</span><span>tabnew '</span> <span>..</span> <span>path</span><span>)</span>
  <span>close</span><span>()</span>
<span>end</span>


<span>local</span> <span>function</span> <span>redraw</span><span>()</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_option</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>modifiable'</span><span>,</span> <span>true</span><span>)</span>
  <span>local</span> <span>items_count</span> <span>=</span>  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_get_height</span><span>(</span><span>win</span><span>)</span> <span>-</span> <span>1</span>
  <span>local</span> <span>list</span> <span>=</span> <span>{}</span>
  <span>local</span> <span>oldfiles</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_vvar</span><span>(</span><span>'</span><span>oldfiles'</span><span>)</span>

  <span>for</span> <span>i</span> <span>=</span> <span>#</span><span>oldfiles</span><span>,</span> <span>#</span><span>oldfiles</span> <span>-</span> <span>items_count</span><span>,</span> <span>-</span><span>1</span> <span>do</span>
    <span>pcall</span><span>(</span><span>function</span><span>()</span>
      <span>local</span> <span>path</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_call_function</span><span>(</span><span>'</span><span>fnamemodify'</span><span>,</span> <span>{</span><span>oldfiles</span><span>[</span><span>i</span><span>],</span> <span>'</span><span>:.'</span><span>})</span>
      <span>table.insert</span><span>(</span><span>list</span><span>,</span> <span>#</span><span>list</span> <span>+</span> <span>1</span><span>,</span> <span>path</span><span>)</span>
    <span>end</span><span>)</span>
  <span>end</span>

  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_lines</span><span>(</span><span>buf</span><span>,</span> <span>0</span><span>,</span> <span>-</span><span>1</span><span>,</span> <span>false</span><span>,</span> <span>list</span><span>)</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_option</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>modifiable'</span><span>,</span> <span>false</span><span>)</span>
<span>end</span>

<span>local</span> <span>function</span> <span>set_mappings</span><span>()</span>
  <span>local</span> <span>mappings</span> <span>=</span> <span>{</span>
    <span>q</span> <span>=</span> <span>'</span><span>close()'</span><span>,</span>
    <span>[</span><span>'</span><span>&lt;cr&gt;'</span><span>]</span> <span>=</span> <span>'</span><span>open_and_close()'</span><span>,</span>
    <span>v</span> <span>=</span> <span>'</span><span>split("v")'</span><span>,</span>
    <span>s</span> <span>=</span> <span>'</span><span>split("")'</span><span>,</span>
    <span>p</span> <span>=</span> <span>'</span><span>preview()'</span><span>,</span>
 ‚Ä¶</pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.2n.pl/blog/how-to-make-ui-for-neovim-plugins-in-lua">https://www.2n.pl/blog/how-to-make-ui-for-neovim-plugins-in-lua</a></em></p>]]>
            </description>
            <link>https://www.2n.pl/blog/how-to-make-ui-for-neovim-plugins-in-lua</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896684</guid>
            <pubDate>Mon, 20 Jul 2020 11:17:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Developers Say: An Outstanding Cloud Automation Experience]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23896619">thread link</a>) | @saramiteva
<br/>
July 20, 2020 | https://microtica.com/an-outstanding-cloud-automation-experience/ | <a href="https://web.archive.org/web/*/https://microtica.com/an-outstanding-cloud-automation-experience/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div>
<p><a href="https://microtica.com/" target="_blank" rel="noreferrer noopener">Microtica</a> has the goal to provide the best cloud automation experience for developers from its very beginnings. We are so happy when we hear a success story, especially from developers who weren‚Äôt familiar with cloud automation previously.&nbsp;</p>



<p>This is why we decided to bring to you a series of interviews with our customers that experience the benefits of our solution. They jumped into a whole new world in a matter of days instead of months. </p>



<p>We are calling it: <strong>Developers Say.&nbsp;</strong></p>



<p>The first developer we talked to is Marko, a full-stack developer from <a href="https://vertt.ch/">Vertt</a>.&nbsp;</p>



<p><em>You can read more about how Vertt accelerated its DevOps processes with Microtica <a href="https://microtica.com/case-studies/accelerating-devops-processes/" target="_blank" rel="noreferrer noopener">here</a>.</em></p>



<h2><strong>What‚Äôs the product you‚Äôre developing?</strong></h2>



<p><a href="https://vertt.ch/">Vertt</a> is a Swiss ride-hailing startup that provides a reliable, responsible and secure transportation experience. As a service, Vertt wants to fill in the voids that exist in the Swiss transportation system. We innovate all the time, in order to provide society with a one-stop mobility solution.&nbsp;</p>



<h2><strong>Which technologies did you use when developing the solution?&nbsp;</strong></h2>



<p>You could say we actually have <strong>five applications</strong>. Four are mobile-native iOS and Android applications, two for the passenger experience, and two are for the drivers. We also have <strong>one web application </strong>which is the admin panel for our business team, developed in Angular.</p>



<p>As for the backend and infrastructure part, the solution is built on the latest <strong>microservice technology with AWS as a cloud provider</strong>. The backend is developed in Node.js.&nbsp;</p>



<div><figure><img src="https://media-exp1.licdn.com/dms/image/C5603AQFmUaDjB8TNSg/profile-displayphoto-shrink_800_800/0?e=1599696000&amp;v=beta&amp;t=5D8Bl17XcfwZ91kQIRTsD-_mg_ag4O9jwwGWIAs4Nuc" alt=""><figcaption>Marko from Vertt</figcaption></figure></div>



<h2><strong>Can you tell us about your background as a developer?&nbsp;</strong></h2>



<p>I am a full-stack developer with two years of experience. Vertt is my first major project and my first time working on a project of this magnitude. This project is where <strong>I gained most of my knowledge and learned about the big picture.</strong> I‚Äôm developing <strong>the backend logic in NodeJS</strong> for the entire system. I‚Äôm also working on the dashboard for our business team in Angular. I‚Äôve worked on just a few projects prior to this. They were mostly small websites that didn‚Äôt require a backend component or scalability features.</p>



<h2><strong>Why did you choose a microservice infrastructure for this particular project?</strong></h2>



<p>We often see startups <a href="https://microtica.com/why-transition-from-monolith-to-microservices/" target="_blank" rel="noreferrer noopener">kicking off with a monolithic application</a> just to get something out there. However, when they expand, they face <strong>various problems related to scalability and continuous integration</strong>.&nbsp;</p>



<p><em>We wanted to do it the right way. </em>The <a href="https://microtica.com/everything-about-microservices/" target="_blank" rel="noreferrer noopener">benefits of the microservice architecture</a> are well-known. <strong>Different codebases, separate deployable units performing separate functionalities</strong>, and the most important for us‚Äî<strong>scaling individually</strong>.&nbsp;</p>



<h2><strong>How did you deliver software before discovering Microtica?</strong></h2>



<p>We started using <strong>Jenkins </strong>as part of our DevOps process. As our team consists of full-stack and mobile developers, we were really <strong>struggling with all the setup and integration of numerous plug-ins.</strong> We were using Jenkins as a build orchestration tool. We soon became very <strong>limited by the release management</strong> that Jenkins has to offer. Issues like access control management, configuration usability, and scaling began to overwhelm us and defocus us from our daily tasks.</p>



<p>As the team began to grow, tracking and accountability of various team members became a great issue. As we did most deployments and builds via a single user,<strong> tracking was only at the code level </strong>through our source control tool Git.&nbsp;</p>



<h2><strong>What was the biggest challenge you had as a developer working with cloud automation?</strong></h2>



<p>The main challenge for any beginner or intermediate developer is <strong>connecting all pieces together </strong>and making them work as one. Understanding how the entire system is designed and managed behind the curtain in the cloud is a continuous process that consists of <strong>constant learning and hands-on effort.</strong> Coming across stuff like cloud automation, scaling, and continuous delivery is always challenging, especially if you don‚Äôt have much experience to get started.&nbsp;</p>



<h2><strong>How did Microtica help you overcome these challenges?</strong></h2>



<p>Microtica made deploying our entire system extremely<strong> easy and effortless.</strong> With just a few clicks and a few extra files, we set up and deployed our entire system consisting of 13 microservices.&nbsp;</p>



<p>After <a href="https://microtica.com/start-creating-infrastructure-on-aws-like-a-pro/" target="_blank" rel="noreferrer noopener">setting up our initial development environment</a> <strong>it only took us one hour to get the test and production environments up and running.</strong> For this, we used the Clone Environment feature. This was really important to us because we wanted to fully migrate to Microtica before going to production.</p>



<p>The integration went <strong>smoothly and pretty fast</strong>. We only needed to create a couple of files in each microservice to create and guide the deployment pipeline. Now we can change parameters and redeploy our services within minutes and with almost no downtime.</p>



<p>It was extremely helpful that we could use their ready-to-use components. This eliminated the need to write complex CloudFormation templates for simple AWS resources. It allowed us to reuse the components by using just the UI.</p>



<h2><strong>How did Microtica help you grow as a developer?</strong></h2>



<p>Before working with Microtica, I didn‚Äôt have much experience and knowledge in the cloud automation space. Microtica gave me <strong>an initial push</strong>.  It made me confident enough to <strong>set up and maintain a fully functional system with three environments.</strong> I could create custom infrastructure and deploy microservices in the cloud <strong>in a matter of days.</strong> It allowed me to focus more on the actual development and less on infrastructure maintenance.</p>



<h2><strong>What kind of challenges are ahead of you and your team?</strong></h2>



<p>Our system is expanding on a daily basis along with its complexity. With a new feature every month, it‚Äôs crucial for us to have a firm grasp of<strong> the entire system at any time</strong>. Since we made a production release, <strong>stability has become our number one priority.</strong> It‚Äôs also probably the biggest challenge that we will face in the future.</p>



<figure><a href="https://portal.microtica.com/register#_ga=2.13603763.541818503.1594369331-624050701.1579084101"><img src="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-1024x614.jpg" alt="Start with cloud automation" srcset="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-1024x614.jpg 1024w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-300x180.jpg 300w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-768x461.jpg 768w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-1536x922.jpg 1536w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-667x400.jpg 667w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01.jpg 2000w" sizes="100vw"></a></figure>



<h2><a href="https://portal.microtica.com/register#_ga=2.13603763.541818503.1594369331-624050701.1579084101" target="_blank" rel="noreferrer noopener">Sign up for Microtica</a> and start with cloud automation today.</h2>
<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://microtica.com/an-outstanding-cloud-automation-experience/"
    dc:identifier="https://microtica.com/an-outstanding-cloud-automation-experience/"
    dc:title="Developers Say: An Outstanding Cloud Automation Experience"
    trackback:ping="https://microtica.com/an-outstanding-cloud-automation-experience/trackback/" />
</rdf:RDF>-->
</div></article></div>]]>
            </description>
            <link>https://microtica.com/an-outstanding-cloud-automation-experience/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896619</guid>
            <pubDate>Mon, 20 Jul 2020 11:02:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A layman's guide to distributed systems]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23896472">thread link</a>) | @kislayverma
<br/>
July 20, 2020 | https://www.kislayverma.com/post/for-the-layman-ep-1-what-is-a-distributed-system | <a href="https://web.archive.org/web/*/https://www.kislayverma.com/post/for-the-layman-ep-1-what-is-a-distributed-system">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.12.3"><div dir="ltr"><div><p id="viewer-foo">Hello Folks!</p><p id="viewer-55bik">I am starting a new series of articles called ‚Äú<a href="https://www.kislayverma.com/blog/categories/for-the-layman" target="_blank" rel="noopener"><u>For the Layman</u></a>‚Äù to cover some frequently encountered software engineering concepts to non-developers or beginners. The articles with try to explain these concepts in simple terms with as little jargon as I can manage.</p><p id="viewer-7o3uu">In this first episode of the series, let‚Äôs understand "distributed systems".</p><p id="viewer-9lsev">As the name suggests, a distributed system is a "<strong>system</strong>" whose components are"<strong>distributed</strong>". Let's look at both those words individually.</p><h2 id="viewer-77h89">What is a system</h2><p id="viewer-eljoh"><strong>A "system" is a set of parts working together to deliver a certain functionality.</strong> A clock is a system of springs and gears that tells time reliably. A car is built up of many parts which allow us to be driven from one place to another. Let's call each part a "component".</p><div id="viewer-dk0o"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.kislayverma.com/post/for-the-layman-ep-1-what-is-a-distributed-system" data-pin-media="https://static.wixstatic.com/media/346caa_2ecf2224ca3440ab8acced52485252a0~mv2.jpg/v1/fit/w_1452,h_1072,al_c,q_80/file.png" src="https://static.wixstatic.com/media/346caa_2ecf2224ca3440ab8acced52485252a0~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><h2 id="viewer-cnh8i">Monoliths : "Not" distributed systems</h2><p id="viewer-3nn6m">Most mechanical systems are not, and cannot be "distributed". Components in most hardware systems assume "local" availability of their partnering components. Piston rods expect to be welded to crank shafts, keyboards expect to be connected to processors etc etc. A software system built along these is sometimes called a ‚Äú<strong>monolith</strong>‚Äù.</p><div id="viewer-2cd7s"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.kislayverma.com/post/for-the-layman-ep-1-what-is-a-distributed-system" data-pin-media="https://static.wixstatic.com/media/346caa_8e16434c90f84ce1a357f115b0243492~mv2.jpg/v1/fit/w_599,h_609,al_c,q_80/file.png" src="https://static.wixstatic.com/media/346caa_8e16434c90f84ce1a357f115b0243492~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><h3 id="viewer-bfpjf">Vertical Scaling</h3><p id="viewer-956q6">A side effect of having to put all components next to each other is that to build a more powerful system, we need to fit more pieces on the same chassis (so to say). If we want to add more engines so our car can go faster, we need to add a larger engine with more cylinders. This in turn requires a large car, and so on. </p><div id="viewer-39h4n"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.kislayverma.com/post/for-the-layman-ep-1-what-is-a-distributed-system" data-pin-media="https://static.wixstatic.com/media/346caa_06064ecbcfb34535b02c4bdd90ca2c85~mv2.jpg/v1/fit/w_1072,h_1003,al_c,q_80/file.png" src="https://static.wixstatic.com/media/346caa_06064ecbcfb34535b02c4bdd90ca2c85~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-eq92d">You can also think of trying to add more power to your laptop by adding more processors or more memory. It can be done but makes the laptop larger and larger - eventually we end up with a desktop rather than a laptop. <strong>This process of adding more and more power to a single physical system is called "Vertical Scaling"</strong>. It is an important strategy (<a href="https://en.wikipedia.org/wiki/Moore%27s_law" target="_blank" rel="nofollow"><u>Moore's law</u></a> is essentially about vertical scaling), but comes with hard physical limits that are very difficult to surmount.</p><h3 id="viewer-4otoo">Location Coupling</h3><p id="viewer-55e2p">Mechanical systems also assume a certain "guarantee" in terms of collaborating with each other. No unreliability is expected between the turning of a gear and the turning of the clock hand (there may be errors of precision, but that is not the question here). A clock is designed with the assumption that certain things will cause certain other things to happen, and if they don't then the clock is considered broken. <strong>The functioning of the complete system depends strongly on all of the components always being physically present in a certain location at a certain time.</strong> This type of dependency pattern is called a form of "<strong>tight coupling</strong>" between components.</p><h3 id="viewer-hmg3">Globally Consistent State</h3><p id="viewer-8jumh">This hard dependency on all parts strictly working together has an interesting implication. <strong>It means that if we know what state (e.g. position, location) one component is in, we necessarily also know the states of all other components</strong>. If component A is not in the position that component B expects it to be, then we have a problem. As a result, our knowledge of the system at any point of time is complete and consistent. This is called "<strong>Global state</strong>".</p><p id="viewer-2tjjj">As you may be able to see by now, <strong>it is difficult to build very large systems when everything MUST be co-located and MUST work all the time</strong>. A large system built using these principles is brittle - any small failure can cause a complete outage. It is also not scalable - as the size grows, not only do we have to keep fitting everything next to each other (imagine an engine with thousands of cylinders all of which must be next to each other and must coordinate completely), but we also have to have complete knowledge of all component at all times to be able to understand if the system is working properly. The cognitive load such a system creates is tremendous and increases exponentially with every new component.</p><p id="viewer-aqcqv">Modern software architecture is as much about handling unprecedented scale as it is about solving business problems. Whether it is the billions of people using Facebook or the surges of online shoppers on Singles Day, software systems today are expected to deliver tremendous performance and continue to function even when parts fail. To fulfil these requirements, distributed systems have emerged as an alternative paradigm for constructing systems built out of many components.</p><h2 id="viewer-7pm74">What is a distributed system</h2><p id="viewer-30h8g"><em>Server</em> : A computer connected to the internet or some other network.</p><p id="viewer-4l92s"><strong>Distributed systems are made up of "independent" components which are not necessarily located next to each other.</strong></p><p id="viewer-d2ju4">This seemingly simple definition of distributed systems has huge ramifications and gives these systems their unique strengths and weaknesses. Let's cover some of these in detail.</p><h3 id="viewer-5sals">Location Transparency</h3><p id="viewer-etfh1">Components in a distributed communicate with each other via methods/protocols that don't require the calling component to know where the called component is located. So the engine can potentially be located at home even when you drive your car.  Somehow when the accelerator is pressed, the engine generates more power which is somehow transferred to the wheels. Another analogy is the remote working style we now see everywhere. Team members are not physically located together, but still cooperate by performing their respective jobs in benefit of a shared objective.</p><div id="viewer-dsfbq"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.kislayverma.com/post/for-the-layman-ep-1-what-is-a-distributed-system" data-pin-media="https://static.wixstatic.com/media/346caa_9a74ad6d24db4f1e8804470b871e01d6~mv2.jpg/v1/fit/w_1696,h_1285,al_c,q_80/file.png" src="https://static.wixstatic.com/media/346caa_9a74ad6d24db4f1e8804470b871e01d6~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-5184m">This is called "<strong>Location Transparency</strong>" which is a form of "<strong>Loose Coupling</strong>" (all developers get a dreamy eyed look when they hear this word - try it!)</p><p id="viewer-a8qe2">The advantages of location transparency are obvious. <strong>If software components need not be co-located, then we can move them to different physical machines, each of which can then be vertically scaled.</strong> i.e. We can buy powerful machines for each component separately instead of fitting all components on one machine. This directly leads to a more powerful system. Note that we are not "mandating" that components must be located on separate servers, just that it shouldn‚Äôt matter where they are located as long as there is a way to locate them.</p><p id="viewer-ffk80"><strong>How do these distributed components find each other</strong>? There are many ways to do this. One of the most popular mechanisms is <a href="https://en.wikipedia.org/wiki/Domain_Name_System" target="_blank" rel="noopener"><u>DNS (Domain Name System)</u></a> which maps names to IP Addresses (unique identities of servers all over the internet). The backbone of all networking is the ability to locate one specific machine given its IP address or domain name. This seemingly small (but actually extremely complicated) technique has allowed software to eat the world.</p><h3 id="viewer-bh4d1">Partial Failure Mode</h3><p id="viewer-50ur1">A fallout of the distributed nature is that our failure mode is not all-or-nothing anymore. The "card reader" component may have failed but the account management component may be running. This means that some functionality related to account management may still be accessible even though our card swiping users are frustrated. </p><h3 id="viewer-dv67q">Horizontal Scalability</h3><p id="viewer-dpf4v">Yet another corollary of location transparency is that there need not necessarily be only one more instance of a component. If it doesn't matter where the engine is located, we can now add ten or more independent engines to add that much more power.</p><div id="viewer-d5v0s"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.kislayverma.com/post/for-the-layman-ep-1-what-is-a-distributed-system" data-pin-media="https://static.wixstatic.com/media/346caa_f7acb8ebcfed40de941c0b0bc6b9a991~mv2.jpg/v1/fit/w_2160,h_1620,al_c,q_80/file.png" src="https://static.wixstatic.com/media/346caa_f7acb8ebcfed40de941c0b0bc6b9a991~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-1nvlo">It is even possible to add and remove engines from the car as needed. <strong>This ability to add more instances of a component is called "horizontal scaling"</strong>, and is the currently preferred mechanism for scaling software systems since it bypasses the physical limitations of how powerful a single server can be - we just add more low power servers to compensate.</p><p id="viewer-clq6o">So we have <em>a bunch of components living on different "servers" (machines) and communicating over a "network" (internet/LAN).</em> Is that it?</p><h3 id="viewer-62puu">Eventual Consistency</h3><p id="viewer-cp518">There is one more interesting thing to understand here - The network is unreliable and slow.</p><div id="viewer-2md82"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.kislayverma.com/post/for-the-layman-ep-1-what-is-a-distributed-system" data-pin-media="https://static.wixstatic.com/media/346caa_8a1c57712fb24c85a1b225271b78c00d~mv2.jpg/v1/fit/w_1432,h_984,al_c,q_80/file.png" src="https://static.wixstatic.com/media/346caa_8a1c57712fb24c85a1b225271b78c00d~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-7s8ir">If your Zoom call has ever hung mid-sentence or Youtube has "buffered", you know what I'm talking about. Data is sent from one component to the other, but sometimes doesn't reach it or reaches after some noticeable time. Maybe the wire is cut, maybe the other component reads the data but crashes before it could do anything with it, maybe a lot of data was flowing over the wire and hence everything is stuck.</p><p id="viewer-52h12">Any which way this occurs, this results in different parts of the system not having complete information about each other. This happens all the time in the systems we encounter on the web - payment was taken but order could not be placed (payment component is not able to talk to order component), money transfer is triggered but will reflect in 24 hours (transfer component know that there is to be a transfer but the account component has not been told yet). </p><div id="viewer-57nhi"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.kislayverma.com/post/for-the-layman-ep-1-what-is-a-distributed-system" data-pin-media="https://static.wixstatic.com/media/346caa_dc60c1aa6f364b9286fabee769d7bc09~mv2.jpg/v1/fit/w_1758,h_636,al_c,q_80/file.png" src="https://static.wixstatic.com/media/346caa_dc60c1aa6f364b9286fabee769d7bc09~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-ecqu0">Another way of putting this is to say that the independent components of a distributed system understand their own "state" (e.g. position, orientation, amount of load) absolutely but may be out of sync (to a greater or lesser extent) with other components. The "out of sync-ness" is a result of the network acting as a queue of unshared knowledge between them.</p><p id="viewer-1t6mh">This is called "<strong>inconsistency</strong>" and is the other side of the <strong>Global State</strong> we encountered in non-distributed systems. The remedy for this in distributed systems is "<strong>Eventual Consistency</strong>", meaning<strong> we must implement mechanisms which will ensure that all components "eventually" agree with each other on what the overall state of the system is</strong>. Note that this is a catchup game, and components are out of sync-by-design rather than by mistake. This gives us some buffer time in which we can perform knowledge transfer instead of making every component aware of everything instantaneously (a physical impossibility in the distributed world given that nothing can travel faster than speed of light).</p><h2 id="viewer-bv7af">The bad parts</h2><p id="viewer-9bcqr">While distributed systems can be extremely resilient to failures and very responsive under high loads, building well designed distributed systems is an extremely complicated undertaking. </p><p id="viewer-fr9nd">The first problem is user experience. There is no way to hide the eventually consistent nature of the system from the users. With instant gratification being the increasingly accepted norm, it can ‚Ä¶</p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.kislayverma.com/post/for-the-layman-ep-1-what-is-a-distributed-system">https://www.kislayverma.com/post/for-the-layman-ep-1-what-is-a-distributed-system</a></em></p>]]>
            </description>
            <link>https://www.kislayverma.com/post/for-the-layman-ep-1-what-is-a-distributed-system</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896472</guid>
            <pubDate>Mon, 20 Jul 2020 10:32:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Imba]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23896411">thread link</a>) | @tomcam
<br/>
July 20, 2020 | https://www.imba.io/guides | <a href="https://web.archive.org/web/*/https://www.imba.io/guides">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2><span>What is Imba?</span></h2><p>Imba is a new programming language for the web that compiles
to performant JavaScript. It is heavily inspired by ruby and python,
but developed explicitly for web programming (both server and client).
Imba treats DOM elements as a first-class citizens. These elements are compiled to an <a href="https://www.imba.io/guides/advanced/performance"><span>inline dom</span></a>, which is an <a href="https://somebee.github.io/dom-reconciler-bench/index.html"><span>order of magnitude faster</span></a> than todays virtual dom implementations. We truly believe that it opens up for a new way of developing web applications.</p>
<h2><span>Installation</span></h2><p><code data-lang="imba"><span>yarn </span><span>global </span><span>add </span><span>imba </span><span># npm install -g imba</span></code><code data-lang="js">var self = {};
self.yarn(global(self.add(self.imba()))); // npm install -g imba</code></p><h2><span>Developers</span></h2><p>Rather than being an academic exercise, Imba has been developed over several years, alongside actual applications. Imba has been fine-tuned to ease the challenges we face when developing rich, dynamic apps (and sites).</p>
<h2><span>Interoperability</span></h2><p>Imba compiles down to clean and readable JavaScript. Your formatting, indentaiton, and comments are included. You can use any existing JavaScript library seamlessly from Imba, and vica-versa.</p>
<h2><span>Speed</span></h2><p>You can use all the syntactic sugar in Imba without needing to worry about the performance and readability of the compiled code, and building your views using Imba's native support for tags results in unprecedented performance. </p>
<p><code data-lang="imba"><span>var </span><span>number </span><span>= </span><span>42</span>
<span>var </span><span>opposite </span><span>= </span><span>true</span>
<span>var </span><span>string </span><span>= </span><span>"the answer is {</span><span>number</span><span>}"</span>
<span>var </span><span>regex </span><span>= </span><span>/</span><span>answer is </span><span>(</span><span>\d</span><span>+)</span><span>/</span>

<span>var </span><span>info </span><span>=</span>
<span>    name</span><span>: </span><span>'Imba'</span>
<span>    version</span><span>: </span><span>Imba</span><span>.</span><span>VERSION</span>
<span>    repository</span><span>: </span><span>'https://github.com/imba/imba'</span>
<span>    inspiration</span><span>: </span><span>[</span><span>'ruby'</span><span>,</span><span>'python'</span><span>,</span><span>'react'</span><span>,</span><span>'coffeescript'</span><span>]</span>
<span>    creator</span><span>: </span><span>'Sindre Aarsaether'</span>
<span>    contributors</span><span>: </span><span>[</span>
<span>        'Sindre Aarsaether' </span><span># github.com/somebee</span>
<span>        'Magnus Holm' </span><span># github.com/judofyr</span>
<span>        'Slee Woo' </span><span># github.com/sleewoo</span>
<span>    ]</span></code><code data-lang="js">var Imba = require('imba');
var number = 42;
var opposite = true;
var string = ("the answer is " + number);
var regex = /answer is (\d+)/;

var info = {
	name: 'Imba',
	version: Imba.VERSION,
	repository: 'https://github.com/imba/imba',
	inspiration: ['ruby','python','react','coffeescript'],
	creator: 'Sindre Aarsaether',
	contributors: [
		'Sindre Aarsaether', // github.com/somebee
		'Magnus Holm', // github.com/judofyr
		'Slee Woo' // github.com/sleewoo
	]
};
</code></p><blockquote>
<p>Even though Imba has been used privately, in production, for more than a year (powering scrimba.com), the community is  in the early stages, and documentation is still sparse. We're incredibly grateful for any feedback, suggestions, and help with the documentation!</p>
</blockquote>
<h2><span>Syntax &amp; Semantics</span></h2><p>Even though the syntax and semantics of Imba is much more related to Ruby than JavaScript, it does compile down to plain performant JavaScript, and is fully compatible with any existing JavaScript library. Imba does not extend any native types from JavaScript. Arrays are arrays, strings are strings, numbers are numbers, classes are constructors with prototypes and so forth. If you simply like Imba better, there is no reason not to write your npm package in Imba, even if it is supposed to be used in the general JavaScript ecosystem. In fact, Imba produces <em>very</em> readable JavaScript, by keeping your indentation, comments, and coding style.</p>
<p><code data-lang="imba"><span># Strings</span>
<span>var </span><span>single </span><span>= </span><span>'single quotes'</span>
<span>var </span><span>double </span><span>= </span><span>"double quotes"</span>
<span>var </span><span>interpolation </span><span>= </span><span>"string has {</span><span>double</span><span>}"</span>

<span># Numbers</span>
<span>var </span><span>integer </span><span>= </span><span>42</span>
<span>var </span><span>float </span><span>= </span><span>42.10</span>

<span># Objects</span>
<span>var </span><span>object </span><span>= </span><span>{</span><span>name</span><span>: </span><span>'Imba'</span><span>, </span><span>type</span><span>: </span><span>'Language'</span><span>}</span>

<span># Arrays</span>
<span>var </span><span>array </span><span>= </span><span>[</span><span>1</span><span>,</span><span>2</span><span>,</span><span>3</span><span>,</span><span>4</span><span>,</span><span>5</span><span>]</span>

<span># Regular expressions</span>
<span>var </span><span>regex </span><span>= </span><span>/</span><span>number is </span><span>(</span><span>\d</span><span>+)</span><span>/</span>

<span># Functions</span>
<span>def</span><span> </span><span>hello</span>
<span>    console</span><span>.</span><span>log </span><span>'got here'</span>
<span>    return </span><span>'world'</span>

<span># Classes</span>
<span>class</span><span> </span><span>Todo</span>
<span>    # automatic getter/setter declaration</span>
<span>    prop</span><span> </span><span>title</span>

<span>    def</span><span> </span><span>initialize </span><span>title</span>
<span>        # instance variables</span>
<span>        @title </span><span>= </span><span>title</span>
<span>        @completed </span><span>= </span><span>no</span>

<span>    def</span><span> </span><span>complete</span>
<span>        @completed </span><span>= </span><span>yes</span>

<span># Tags</span>
<span>var </span><span>item </span><span>= </span><span>&lt;</span><span>div</span><span>.header</span><span>&gt; </span><span>"This is a div"</span>
<span>var </span><span>list </span><span>= </span><span>&lt;</span><span>ul</span><span>.list</span><span>&gt; </span><span>for </span><span>item </span><span>in </span><span>[</span><span>"one"</span><span>,</span><span>"two"</span><span>,</span><span>"three"</span><span>]</span>
<span>    &lt;</span><span>li</span><span>&gt; </span><span>&lt;</span><span>span</span><span>.name</span><span>&gt; </span><span>item</span></code><code data-lang="js">var t0, Imba = require('imba'), _2 = Imba.createTagList, self = {}, _1 = Imba.createElement;
// Strings
var single = 'single quotes';
var double = "double quotes";
var interpolation = ("string has " + double);

// Numbers
var integer = 42;
var float = 42.10;

// Objects
var object = {name: 'Imba',type: 'Language'};

// Arrays
var array = [1,2,3,4,5];

// Regular expressions
var regex = /number is (\d+)/;

// Functions
self.hello = function (){
	console.log('got here');
	return 'world';
};

// Classes
function Todo(title){
	// instance variables
	this._title = title;
	this._completed = false;
};

Todo.prototype.title = function(v){ return this._title; }
Todo.prototype.setTitle = function(v){ this._title = v; return this; };

Todo.prototype.complete = function (){
	return this._completed = true;
};

// Tags
var item = (_1('div').flag('header').setText("This is a div"));
var list = (t0 = (t0=_1('ul')).flag('list')).setContent((function tagLoop($0) {
	var t1;
	for (let i = 0, items = ["one","two","three"], len = $0.taglen = items.length; i &lt; len; i++) {
		(t1 = $0[i] || (t1=_1('li',$0,i)).setContent(t1.$.A || _1('span',t1.$,'A',t1).flag('name'),2)).end((
			t1.$.A.setContent(items[i],3)
		,true));
	};return $0;
})(t0.$['A'] || _2(t0.$,'A')),4);
</code></p><h2><span>Getting started</span></h2><blockquote>
<p>This guide assumes knowledge of HTML, CSS and JavaScript (or another programming language). It will be especially helpful to know React to grasp how tags and custom tags work.</p>
</blockquote>
<p>The easiest way to get started with Imba is to play around in the <a target="_blank" href="https://scrimba.com/c/cE4nGcg"><span>scrimba.com Hello World example</span></a>. If you rather want to try Imba in your own environment you can clone <a href="https://github.com/somebee/hello-world-imba"><span>hello-world-imba</span></a> and follow the instructions in the readme. There are plugins available for <a href="https://packagecontrol.io/packages/Imba"><span>Sublime Text</span></a>, <a href="https://github.com/somebee/vscode-imba"><span>VSCode</span></a> and <a href="https://atom.io/packages/language-imba"><span>Atom</span></a>.</p>
</div></div>]]>
            </description>
            <link>https://www.imba.io/guides</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896411</guid>
            <pubDate>Mon, 20 Jul 2020 10:16:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Three Architectures for a Responsive IDE]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23896380">thread link</a>) | @todsacerdoti
<br/>
July 20, 2020 | https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html | <a href="https://web.archive.org/web/*/https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>The first architecture is reminiscent of the map-reduce paradigm.
The idea is to split analysis into relatively simple indexing phase, and a separate full analysis phase.</p>
<p>The core constraint of indexing is that it runs on a per-file basis.
The indexer takes the text of a single file, parses it, and spits out some data about the file.
The indexer can‚Äôt touch other files.</p>
<p>Full analysis can read other files, and it leverages information from the index to save work.</p>
<p>This all sounds way too abstract, so let‚Äôs look at a specific example‚Äâ‚Äî‚ÄâJava.
In Java, each file starts with a package declaration.
The indexer concatenates the name of the package with a class name to get a fully-qualified name (FQN).
It also collects the set of methods declared in the class, the list of superclasses and interfaces, etc.</p>
<p>Per-file data is merged into an index which maps FQNs to classes.
Note that constructing this mapping is an embarrassingly parallel task‚Äâ‚Äî‚Äâall files are parsed independently.
Moreover, this map is cheap to update.
When a file change arrives, this file‚Äôs contribution from the index is removed, the text of the file is changed and the indexer runs on the new text and adds the new contributions.
The amount of work to do is proportional to the number of changed files, and is independent from the total number of files.</p>
<p>Let‚Äôs see how FQN index can be used to quickly provide completion.</p>
<div>
<div>
<pre><code data-lang="java"><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
</pre></td><td><pre><span>// File ./mypackage/Foo.java</span>
<span>package</span> <span>mypackage</span><span>;</span>

<span>import</span> <span>java.util.*</span><span>;</span>

<span>public</span> <span>class</span> <span>Foo</span> <span>{</span>
    <span>public</span> <span>static</span> <span>Bar</span> <span>f</span><span>()</span> <span>{</span>
        <span>return</span> <span>new</span> <span>Bar</span><span>();</span>
    <span>}</span>
<span>}</span>

<span>// File ./mypackage/Bar.java</span>
<span>package</span> <span>mypackage</span><span>;</span>

<span>public</span> <span>class</span> <span>Bar</span> <span>{</span>
    <span>public</span> <span>void</span> <span>g</span><span>()</span> <span>{}</span>
<span>}</span>

<span>// File ./Main.java</span>
<span>import</span> <span>mypackage.Foo</span><span>;</span>

<span>public</span> <span>class</span> <span>Main</span> <span>{</span>
    <span>public</span> <span>static</span> <span>void</span> <span>main</span><span>(</span><span>String</span><span>[]</span> <span>args</span><span>)</span> <span>{</span>
        <span>Foo</span><span>.</span><span>f</span><span>().</span>
    <span>}</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>The user has just typed <code>Foo.f().</code>, and we need to figure out that the type of receiver expression is <code>Bar</code>, and suggest <code>g</code> as a completion.</p>
<p>First, as the file <code>Main.java</code> is modified, we run the indexer on this single file.
Nothing has changed (the file still contains the class <code>Main</code> with a static <code>main</code> method), so we don‚Äôt need to update the FQN index.</p>
<p>Next, we need to resolve the name <code>Foo</code>.
We parse the file, notice an <code>import</code> and look up <code>mypackage.Foo</code> in the FQN index.
In the index, we also find that <code>Foo</code> has a static method <code>f</code>, so we resolve the call as well.
The index also stores the return type of <code>f</code>, but, and this is crucial, it stores it as a string <code>"Bar"</code>, and not as a direct reference to the class <code>Bar</code>.</p>
<p>The reason for that is <code>import java.util.*</code> in <code>Foo.java</code>.
<code>Bar</code> can refer either to <code>java.util.Bar</code> or to <code>mypackage.Bar</code>.
The indexer doesn‚Äôt know which one, because it can look <strong>only</strong> at the text of <code>Foo.java</code>.
In other words, while the index does store the return types of methods, it stores them in an unresolved form.</p>
<p>The next step is to resolve the identifier <code>Bar</code> in the context of <code>Foo.java</code>.
This uses the FQN index, and lands in the class <code>mypackage.Bar</code>.
There the desired method <code>g</code> is found.</p>
<p>Altogether, only three files were touched during completion.
The FQN index allowed us to completely ignore all the other files in the project.</p>
<p>One problem with the approach described thus far is that resolving types from the index requires a non-trivial amount of work.
This work might be duplicated if, for example, <code>Foo.f</code> is called several times.
The fix is to add a cache.
Name resolution results are memoized, so that the cost is paid only once.
The cache is blown away completely on any change‚Äâ‚Äî‚Äâwith an index, reconstructing the cache is not that costly.</p>
<p>To sum up, the first approach works like this:</p>
<div>
<ol>
<li>
<p>Each file is being indexed, independently and in parallel, producing a "stub"‚Äâ‚Äî‚Äâa set of visible top-level declarations, with unresolved types.</p>
</li>
<li>
<p>All stubs are merged into a single index data structure.</p>
</li>
<li>
<p>Name resolution and type inference work primarily off the stubs.</p>
</li>
<li>
<p>Name resolution is lazy (we only resolve a type from the stub when we need it) and memoized (each type is resolved only once).</p>
</li>
<li>
<p>The caches are completely invalidated on every change</p>
</li>
<li>
<p>The index is updated incrementally:</p>
<div>
<ul>
<li>
<p>if the edit doesn‚Äôt change the file‚Äôs stub, no change to the index is required.</p>
</li>
<li>
<p>otherwise, old keys are removed and new keys are added</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<p>Note an interesting interplay between "dumb" indexes which can be updated incrementally, and "smart" caches, which are re-computed from scratch.</p>
<p>This approach combines simplicity and stellar performance.
The bulk of work is the indexing phase, and you can parallelize and even distribute it across several machine.
Two examples of this architecture are <a href="https://www.jetbrains.com/idea/">IntelliJ</a> and <a href="https://sorbet.org/">Sorbet</a>.</p>
<p>The main drawback of this approach is that it works only when it works‚Äâ‚Äî‚Äânot every language has a well-defined FQN concept.
I think overall it‚Äôs a good idea to design name resolution and module systems (mostly boring parts of a language) such that they work well with the map-reduce paradigm.</p>
<div>
<ul>
<li>
<p>Require <code>package</code> declarations or infer them from the file-system layout</p>
</li>
<li>
<p>Forbid meta-programming facilities which add new top-level declarations, or restrict them in such way that they can be used by the indexer.
For example, preprocessor-like compiler plugins that access a single file at a time might be fine.</p>
</li>
<li>
<p>Make sure that each source element corresponds to a single semantic element.
For example, if the language supports conditional compilation, make sure that it works during name resolution (like Kotlin‚Äôs <a href="https://kotlinlang.org/docs/reference/platform-specific-declarations.html">expect/actual</a>) and not during parsing (like conditional compilation in most other languages).
Otherwise, you‚Äôd have to index the same file with different conditional compilation settings, and that is messy.</p>
</li>
<li>
<p>Make sure that FQNs are enough for most of the name resolution.</p>
</li>
</ul>
</div>
<p>The last point is worth elaborating. Let‚Äôs look at the following Rust example:</p>
<div>
<div>
<pre><code data-lang="rust"><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
</pre></td><td><pre><span>// File: ./foo.rs</span>
<span>trait</span> <span>T</span> <span>{</span>
    <span>fn</span> <span>f</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>{}</span>
<span>}</span>
<span>// File: ./bar.rs</span>
<span>struct</span> <span>S</span><span>;</span>

<span>// File: ./somewhere/else.rs</span>
<span>impl</span> <span>T</span> <span>for</span> <span>S</span> <span>{}</span>

<span>// File: ./main.s</span>
<span>use</span> <span>foo</span><span>::</span><span>T</span><span>;</span>
<span>use</span> <span>bar</span><span>::</span><span>S</span>

<span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>let</span> <span>s</span> <span>=</span> <span>S</span><span>;</span>
    <span>s</span><span>.f</span><span>();</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>Here, we can easily find the <code>S</code> struct and the <code>T</code> trait (as they are imported directly).
However, to make sure that <code>s.f</code> indeed refers to <code>f</code> from <code>T</code>, we also need to find the corresponding <code>impl</code>, and that can be roughly anywhere!</p>
</div></div>]]>
            </description>
            <link>https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896380</guid>
            <pubDate>Mon, 20 Jul 2020 10:10:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nanopublications: Fair data containers for scientific results]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 6 (<a href="https://news.ycombinator.com/item?id=23896279">thread link</a>) | @melvinroest
<br/>
July 20, 2020 | http://nanopub.org/wordpress/ | <a href="https://web.archive.org/web/*/http://nanopub.org/wordpress/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

                                
                        
            <p>FAIR data containers for scientific results,
<br>
and more</p>            
            		             
            
        </div></div>]]>
            </description>
            <link>http://nanopub.org/wordpress/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896279</guid>
            <pubDate>Mon, 20 Jul 2020 09:50:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TileDB closes $15M Series A for universal data engine]]>
            </title>
            <description>
<![CDATA[
Score 93 | Comments 61 (<a href="https://news.ycombinator.com/item?id=23896131">thread link</a>) | @k-rus
<br/>
July 20, 2020 | https://tiledb.com/blog/tiledb-closes-15m-series-a-for-industry-s-first-universal-data-engine-2020-07-14 | <a href="https://web.archive.org/web/*/https://tiledb.com/blog/tiledb-closes-15m-series-a-for-industry-s-first-universal-data-engine-2020-07-14">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Cambridge, MA, July 14, 2020: <a href="https://tiledb.com/">TileDB, Inc.</a> has secured a $15M Series A investment round led by <a href="https://twobearcapital.com/">Two Bear Capital</a>, joined by <a href="https://uncorrelated.com/">Uncorrelated Ventures</a> and all existing investors: <a href="https://nexusvp.com/">Nexus Venture Partners</a>, <a href="http://www.intelcapital.com/">Intel Capital</a>, and <a href="https://bigpi.vc/">Big Pi Ventures</a>. The funding will help the company expand go-to-market and product development for its ‚Äúuniversal data engine,‚Äù a novel database that goes beyond tables to manage any complex data and beyond SQL to analyze the data with any tool, all serverless and at planet scale. Montana philanthropist and Two Bear Capital Managing Partner Mike Goguen will join TileDB‚Äôs Board of Directors.</p>
<p>The Series A financing comes after TileDB was chosen by customers who experienced two key pains: scalability for complex data and deployment. Whole-genome population data, single-cell gene data, spatio-temporal satellite imagery, and asset-trading data all share multi-dimensional structures that are poorly handled by monolithic databases, tables, and legacy file formats. Newer computational frameworks evolved to offer ‚Äúpluggable storage‚Äù but that forces another part of the stack to deal with data management. As a result, organizations waste resources on managing a sea of files and optimizing storage performance, tasks traditionally done by the database. Moreover, developers and data scientists are spending excessive time in data engineering and deployment, instead of actual analysis and collaboration.</p>
<p>‚ÄúWe flipped the data management model,‚Äù said Dr. Stavros Papadopoulos, CEO and original creator of TileDB. ‚ÄúWe invented a database that focuses on universal storage and data management rather than the compute layer, which we‚Äôve instead made `pluggable.` We cleared the path for analytics professionals and data scientists by taking over the messiest parts of data management, such as optimized storage for all data types on numerous backends, data versioning, metadata, access control within or outside organizational boundaries, and logging. On top, we developed numerous APIs for fast direct data access and efficient integrations with a growing set of popular tools such as Spark, Dask, MariaDB and PrestoDB. Finally, we built a serverless infrastructure for easy, secure cross-organizational sharing and scalable compute, called TileDB Cloud.‚Äù</p>
<p>According to Scott Soenen, VP of Product Engineering at Capella Space: ‚ÄúThe partnership with TileDB gelled perfectly with our desire to deliver a new level of innovation in open data programs aimed at the geospatial community. Open data alone isn‚Äôt enough. It‚Äôs also about easy access to compute resources and versatility of analytics. TileDB Cloud removes multiple manual steps in data access for the geospatial developer community and offers intuitive self-service and interactive analytics."</p>
<p>‚ÄúWe have chosen TileDB as the storage engine to power our cellxgene project at CZI, which is an interactive data explorer for single-cell transcriptomics datasets,‚Äù said Bruce Martin, Director of Engineering, Chan Zuckerberg Initiative. ‚ÄúTileDB provides an easy and powerful way to manage our huge array data on various backends, including cloud object stores. The serverless infrastructure of TileDB Cloud opens the door to extreme scale with very low engineering efforts on our part, allowing us to focus more on scientific discoveries instead.‚Äù</p>
<p>Magnus Isaksson, Director of Bioinformatics, Helix shared, ‚ÄúThe synergy between our two companies has enabled us to take an innovative approach to storing and analyzing genomic data at population-scale. We were excited to find TileDB after extensive diligence of potential solutions that could meet Helix's needs and advance our vision to revolutionize population health via the power of genomics."</p>
<p>‚ÄúMany of the world‚Äôs most urgent problems - from COVID to climate change - require the analysis of large volumes of data in order to find solutions. TileDB‚Äôs technology addresses the infrastructure deficit that adds friction, delay, and cost to generating the key insights and discoveries needed from this data,‚Äù said Mike Goguen, Managing Partner at Two Bear Capital and lead investor. ‚ÄúWe are excited to partner with Stavros and TileDB to build an enduring company delivering massive value for the developers and enterprise customers working to solve these and other critically important problems.‚Äù</p>
<p><br>
To learn more about TileDB visit <a href="https://tiledb.com/">our website</a>, check out the open-source <a href="https://github.com/TileDB-Inc/TileDB">TileDB Embedded</a> storage engine on Github or sign up on <a href="https://tiledb.com/cloud">TileDB Cloud</a>.</p>
<p>--------------------------------------------------------------------------------------</p>
<p><strong>About Two Bear Capital</strong></p>
<p>Two Bear Capital (TBC) was founded and is led by venture capitalist and Montana philanthropist Michael Goguen. With professionals in Whitefish, MT, the San Francisco Bay area and San Diego, CA, TBC invests in early stage companies with disruptive innovations at the intersections of biotech, bioinformatics, machine learning / AI and cybersecurity that could deliver dramatically better solutions to the most critical problems affecting human health, security and wellness. To learn more, visit <a href="http://www.twobearcapital.com/">www.twobearcapital.com</a> and follow TBC on LinkedIn.</p>
<p><strong>About Uncorrelated Ventures</strong></p>
<p><a href="https://uncorrelated.com/">Uncorrelated Ventures</a> was founded by <a href="https://www.baincapitalventures.com/team/salil/">Salil Deshpande</a> in 2020 with Bain‚Äôs backing to focus on open source and infrastructure software, both traditional and decentralized. Over 14 years as general partner and managing director at Bay Partners and Bain Capital, Salil invested $350M+ into 50+ companies early, including MuleSoft, DynaTrace, Buddy Media, SpringSource, Redis Labs, SysDig, Jambool, Dropcam, Tealium, Sonatype, Frame, DataStax, Netdata, Quantum Metric, Philz Coffee, Upgrade and DeFi projects Compound and Maker. Salil was on the Forbes Midas List of the 100 best-performing venture investors worldwide in 2013, 2014, 2015, 2016, 2017, 2018, and 2019.</p>
<p><strong><br>
About Nexus Venture Partners</strong></p>
<p>Nexus Venture Partners is a leading early-stage venture capital firm partnering with extraordinary entrepreneurs building product-first companies. With $1.5B under management, Nexus operates as one team across the US and India. The Nexus family includes Aryaka, Biz2Credit, Cloud.com, Clover Health, Delhivery, Druva, Gluster, H2O.ai, Hasura, Headspin, Kaltura, Mezi, Observe.ai, OLX, Paysense, Postman, Pubmatic, Rancher, Snapdeal, Unacademy, Whitehatjr, and Zomato. For more information, visit <a href="http://www.nexusvp.com/">www.nexusvp.com</a>.</p>
<p><strong>About Intel Capital</strong></p>
<p>Intel Capital invests in innovative startups targeting artificial intelligence, autonomous vehicles, datacenter and cloud, 5G, next-generation compute, and a wide range of other disruptive technologies. Since 1991, Intel Capital has invested US$12.9 billion in more than 1,582 companies worldwide, and 692 portfolio companies have gone public or participated in a merger. Intel Capital curates thousands of business development introductions each year between its portfolio companies and the Global 2000. For more information on what makes Intel Capital one of the world‚Äôs most powerful venture capital firms, visit www.intelcapital.com or follow @Intelcapital.</p>
<p><strong>About Big Pi Ventures</strong></p>
<p>Big Pi Ventures is a seed-stage fund investing in innovative technology companies connected to Greece and engaged primarily in enterprise/B2B software, materials and life sciences. Big Pi is managed by seasoned investment professionals and successful entrepreneurs that assist companies in attracting highly technical and loyal human capital. Find out more about our fund, portfolio, and career opportunities by visiting <a href="http://www.bigpi.vc/">www.bigpi.vc</a>.</p></div></div></div>]]>
            </description>
            <link>https://tiledb.com/blog/tiledb-closes-15m-series-a-for-industry-s-first-universal-data-engine-2020-07-14</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896131</guid>
            <pubDate>Mon, 20 Jul 2020 09:17:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Myth of the Upstroke]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23896089">thread link</a>) | @dsego
<br/>
July 20, 2020 | https://bythlon.com/pages/the-myth-of-the-upstroke-2 | <a href="https://web.archive.org/web/*/https://bythlon.com/pages/the-myth-of-the-upstroke-2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="PageContainer">

    <main id="MainContent" role="main" tabindex="-1">
      <div>
  <div>
    <div>
      

      <div>
        <meta charset="utf-8"><meta name="uuid" content="uuidUSpSjQyEQhWQ"><meta charset="utf-8"><meta charset="utf-8"><meta name="uuid" content="uuid77qzHBcs36HS"><meta charset="utf-8">
<p><span data-preserver-spaces="true">Before and during the development of the Bythlon safety performance pedal system's technology, we comprehensively researched <a href="https://bythlon-pedal.myshopify.com/pages/cycling-science" title="Cycling Science">cycling science</a>, especially the biomechanics of the pedal stroke, the technology, and the benefits of the existing clipless pedal systems.</span></p>
<p><span data-preserver-spaces="true">We could confirm from the widely publicized benefits that cleats indeed secure the shoe in place on the pedal to prevent slipping and that the purposely developed road bike shoes with extremely stiff soles improve pedal power and most likely reduce the risk of injury.</span></p>
<p><span data-preserver-spaces="true">However, the main argument for cleats dates back to the days where cyclists tied their shoes to their pedals with shoe clips and straps. The idea behind that is to generate a 'perfect' stroke, pedaling with one leg pushing down while the other is pulling up.&nbsp;&nbsp;</span></p>
<p><span data-preserver-spaces="true">Most cyclists accept this as a foregone conclusion. There is probably no cyclist who has not heard the advice to aim for a 'round' pedal stroke. The cleat pedal is probably perceived as the essential bike component that separates the casual or novice from the ambitious and experienced rider, even more so than carbon frames or wheels.</span></p>
<p><span data-preserver-spaces="true">So we were in a big surprise when we came across several articles and a video that was describing '</span><a target="_blank" href="https://www.youtube.com/watch?v=L-d5K812TyI" rel="noopener noreferrer"><span data-preserver-spaces="true">The Myth of The Upstroke</span></a><span data-preserver-spaces="true">.'&nbsp;</span></p>
<p><span data-preserver-spaces="true">We learned that the presenter of this video, a sport biomechanist and advisor to the United States Olympic Committee, Dr. Jeff Broker, had tested more than a hundred cyclists' pedal strokes from the 1980s onwards. None of these elite and professional cyclists he tested over ten years produced a meaningful upstroke.&nbsp;</span></p>
<p><a href="https://www.youtube.com/watch?v=L-d5K812TyI" target="_blank" title="Dr Jeff Broker speaks at 2012 International Cyclefit Symposium - 2012 - &quot;The Myth of The Upstroke&quot;" rel="noopener noreferrer"><img src="https://cdn.shopify.com/s/files/1/0279/6345/7589/files/Screenshot_2019-11-22_at_13.15.11.png?v=1574399731" alt="Cyclist do not pull in cirles nor do they truly pull up in the upstroke " width="319" height="242"></a></p>
<meta charset="utf-8"><meta name="uuid" content="uuid77qzHBcs36HS"><meta charset="utf-8">
<p><span data-preserver-spaces="true">He developed an early power force model and called it '</span><em><span data-preserver-spaces="true">cycling clock diagram.</span></em><span data-preserver-spaces="true">' It is still in use today and frequently cited in publications. It clearly shows that there is no 'pull' in the recovery phase (upstroke).</span></p>
<p><img src="https://cdn.shopify.com/s/files/1/0279/6345/7589/files/The_power_cycle_-_Dr._Jeff_Broker_480x480.png?v=1574325860" alt="Cycling Clock Diagram, Pedal strike forces according to Dr. Jeff Broker " width="213" height="213"></p>
<meta charset="utf-8"><meta name="uuid" content="uuid77qzHBcs36HS"><meta charset="utf-8">
<p><span data-preserver-spaces="true">He first published his findings with his colleagues Robert Gregor and M. Ryan in 1991 (</span><a target="_blank" href="https://www.researchgate.net/publication/21220076_The_biomechanics_of_cycling" rel="noopener noreferrer"><span data-preserver-spaces="true">The biomechanics of cycling</span></a><span data-preserver-spaces="true">). It appeared to them that there is no 'pull' and that the entire aspect of pulling through the upstroke is a myth. That opened an entirely new element to our research. Since we found several comprehensive studies and publications citing and confirming his results, including studies researching if these results would change with&nbsp;</span><a target="_blank" href="https://pdfs.semanticscholar.org/02c5/2dc037e07d44a68b89e21526c6b9ebb3796e.pdf?_ga=2.148566004.252372768.1574487523-1137627527.1574234326" rel="noopener noreferrer"><span data-preserver-spaces="true">uphill cycling</span></a><span data-preserver-spaces="true">, we dived deeper into this.</span></p>
<p><span data-preserver-spaces="true">While these studies are apparently confirming Dr. Broker's findings, they are highly scientific, often limited to a handful of participants, decades-old, and therefore the sensors used custom builds. The interpretation of the laboratory data is often difficult.&nbsp;&nbsp;</span></p>
<p><span data-preserver-spaces="true">Today there are many different power meters and software applications readily available that allow us to approach our research not only from the laboratory but from the field.</span></p>
<p><span data-preserver-spaces="true">We took a closer look at how the results modern power meters deliver and how they are displayed. Power meters from Garmin, Pioneer, and Favero are some of the meters popular with cyclists, and all come with mobile and website apps showing the results.&nbsp;</span></p>
<p>We first searched online and found thousands of results posted by individuals. For data privacy reasons, we leave it to anybody interested to browse these results and post here result diagram examples from the companies' websites.</p>
<p>&nbsp;<a href="https://ph.garmin.com/minisite/cyclingdynamics/" target="_blank" title="Garmin Cycling Dynamics, power phase" rel="noopener noreferrer"><img src="https://cdn.shopify.com/s/files/1/0279/6345/7589/files/Screenshot_2019-11-23_at_17.53.20_480x480.png?v=1574502827" alt="Garmin Cycling Dynamics" width="230" height="230"></a></p>
<p>Garmin's <a href="https://buy.garmin.com/en-US/US/p/573589" title="Garmin Vector 3 Dual-Sensing Power Meter" target="_blank" rel="noopener noreferrer">Vector 3 power meter pedal </a>comes with the <a href="https://connect.garmin.com/" title="Garmin Connect mobile app and website" target="_blank" rel="noopener noreferrer">Garmin Connect </a>mobile and website app. Their '<a href="https://www.garmin.com/en-US/performance-data/cycling/#cycling-dynamics" title="Garmin Cycling Dynamics">Cycling Dynamics</a>' analysis delivers a whole range of results and visualizes these in a way easy to understand and interpret. The Power Phase diagram shows how the power is produced and wherein the cycle the most power, The Power Phase, is produced. Undeniable is the absence of any power in the upstroke as it has been marked with 'No Power'.&nbsp;&nbsp;</p>
<p><a href="http://pioneer-cyclesports.com/us-en/products/data-analysis-web-service/cyclo-sphere.html" target="_blank" title="data is displayed for standing-pedaling and seated-pedaling" rel="noopener noreferrer"><img src="https://cdn.shopify.com/s/files/1/0279/6345/7589/files/Screenshot_2019-11-22_at_14.15.28.png?v=1574502707" alt="Pioneer Power Meter Analytics" width="527" height="145"></a>&nbsp;</p>
<p>Pioneer produces crank-based <a href="http://pioneer-cyclesports.com/us-en/products/sensor/" title="Pioneer Pedaling Monitor Sensors SGY-PM91" target="_blank" rel="noopener noreferrer">Pedaling Monitor Sensors</a> that work with their <a href="http://pioneer-cyclesports.com/us-en/products/data-analysis-web-service/cyclo-sphere.html" title="Pioneerr Cyclo-Sphere Data Analysis Web Service">Cyclo-</a><a href="http://pioneer-cyclesports.com/us-en/products/data-analysis-web-service/cyclo-sphere.html" target="_blank" title="Pioneerr Cyclo-Sphere Data Analysis Web Service" rel="noopener noreferrer">Sphere</a> data analysis web service, which displays the pedaling power similar to Garmin but using vectors displaying force and direction. Interestingly this is very similar to Dr. Broker's tests almost forty years ago. The graphic shows no power in the upstroke, and the lack of thereof is apparent as well in the pedaling graph next to it. (Update: Pioneer sold its related technology to Shimano and cased selling at the end of March 2020.)</p>
<p>&nbsp;<a href="https://bythlon.com/pages/Favero%20Electronics%20is%20glad%20to%20introduce%20the%20IAV%20Cycling%20Dynamics%20" target="_blank" title="IAV Power Phase" rel="noopener noreferrer"><img src="https://cdn.shopify.com/s/files/1/0279/6345/7589/files/Screenshot_2019-11-22_at_14.22.12.png?v=1574502702" alt="Favero IAV Cycling Dynamics" width="330" height="270"></a></p>
<meta charset="utf-8"><meta name="uuid" content="uuid77qzHBcs36HS"><meta charset="utf-8">
<p><span data-preserver-spaces="true">Favero's&nbsp;</span><a target="_blank" href="https://cycling.favero.com/assioma" rel="noopener noreferrer"><span data-preserver-spaces="true">Assioma power meter pedal</span></a><span data-preserver-spaces="true">&nbsp;uses the</span><a target="_blank" href="https://cycling.favero.com/blog/tech-tests/iav-cycling-dynamics" rel="noopener noreferrer"><span data-preserver-spaces="true">&nbsp;IAV Cycling Dynamics&nbsp;</span></a><span data-preserver-spaces="true">for analytics. The Power Phase and Peak Phase graphic symbolized by the red arc segment on the power cycle indicates where the power begins and ends. The green arc shows the Power Phase Peak, which is the segment where 50% of the total power is produced. The upstroke is marked with the words 'No Power.'</span></p>
<p><span data-preserver-spaces="true">At this point, we believe it is fair to say that The Myth of the Upstroke has been debunked by scientists and field data from many thousands' individual cyclists as a popular misconception.&nbsp;</span></p>
<p><span data-preserver-spaces="true">We are certainly not the only ones that took notice. Andy Pruitt&nbsp;</span><a target="_blank" href="https://www.velonews.com/2010/09/news/book-excerpt-the-biomechanics-of-pedaling-from-andy-pruitts-complete-medical-guide-for-cyclists_137556" rel="noopener noreferrer"><span data-preserver-spaces="true">writes&nbsp;</span></a><span data-preserver-spaces="true">in his Complete Medical Guide for Cyclists about the biomechanics of pedaling: '</span><em><span data-preserver-spaces="true">The Best Cyclists Don't Produce Power When They Pull Up on the Backstroke.'&nbsp;</span></em></p>
<p><span data-preserver-spaces="true">Martin Blair, a bike fitter and former road cycling champion,&nbsp;</span><a target="_blank" href="https://www.bikeradar.com/advice/fitness-and-training/stop-pulling-up-on-your-pedals/" rel="noopener noreferrer"><span data-preserver-spaces="true">writes</span></a><span data-preserver-spaces="true">&nbsp;in bikeradar: '</span><em><span data-preserver-spaces="true">Some power meters will show you where in your pedal stroke the power is. Even when trying, very little power is produced in the upstroke.'&nbsp;</span></em></p>
<p><span data-preserver-spaces="true">Kevin Curry, the founder of Gear &amp; Grit, published a well-written&nbsp;</span><a target="_blank" href="https://gearandgrit.com/the-cycling-myth-that-wont-die-pedaling-circles/" rel="noopener noreferrer"><span data-preserver-spaces="true">article&nbsp;</span></a><span data-preserver-spaces="true">about the myth on his website summarizing '</span><em><span data-preserver-spaces="true">Pedaling circles is a myth, and one that can do real harm to you.</span></em><span data-preserver-spaces="true">'</span></p>
<p><span data-preserver-spaces="true">Phil Cavell from Cyclefit UK has more than thirty years of experience with bike fitting and&nbsp;</span><a target="_blank" href="https://roadcyclinguk.com/riding/bike-fitting-the-myth-of-the-upstroke.html" rel="noopener noreferrer"><span data-preserver-spaces="true">concludes</span></a><span data-preserver-spaces="true">: '</span><em><span data-preserver-spaces="true">That is to say that even they don't produce enough force at the pedal to offset the effect of gravity on their uphill-moving leg!</span></em><span data-preserver-spaces="true">&nbsp;'</span></p>
<p><span data-preserver-spaces="true">Phils's statement had been already&nbsp;</span><a target="_blank" href="https://pdfslide.net/documents/power-output-and-work-in-different-muscle-groups-during-ergometer-cycling.html" rel="noopener noreferrer"><span data-preserver-spaces="true">confirmed&nbsp;</span></a><span data-preserver-spaces="true">in 1986 by Mats Ericson and his colleagues, who found:&nbsp;</span><em><span data-preserver-spaces="true">'The active limb supplied the passive limb with some of the energy to lift it between approximately 195¬∞ and 360¬∞ crank angle '</span></em><span data-preserver-spaces="true">(p. 234).</span></p>
<p><span data-preserver-spaces="true">Finally, the always entertaining Global Cycling Network (GCN) hosts experimented so far three times flat pedals versus clipless pedals in <a href="https://www.youtube.com/watch?v=CNedIJBZpgM" title="What Is The Most Efficient Pedalling Style? We Test Flat Vs. Clipless Pedals | GCN Does Science" target="_blank" rel="noopener noreferrer">2014</a>, <a href="https://www.youtube.com/watch?v=AkMCYYNTWUY&amp;t=179s" title="Clipless Pedals Vs Flat Pedals - Which Is Faster? | GCN Does Science" target="_blank" rel="noopener noreferrer">2017</a>, and <a href="https://www.youtube.com/watch?v=CVUnngkENeA" target="_blank" title="Are Road Pedals Faster than Flat Pedals? | Clips vs Flats Hill Climb Challenge" rel="noopener noreferrer">2019</a> and found each time that flat pedals more or less same efficient as clipless pedals.&nbsp;</span></p>
<p>&nbsp;<img src="https://cdn.shopify.com/s/files/1/0279/6345/7589/files/Screenshot_2019-11-24_at_14.08.10.png?v=1574575821" alt="Muscle groups involved in generating power during the pedal stroke" width="256" height="386"></p>

<p>So before our conclusion, let us look into Eriscon's and later finding regarding the muscle groups involved. The pedal stroke generates force by hip and knee extension and flexion. An extension is used pushing down during the power phase, and flexion is used to recover the pedal back to the top of the cycle for the next downstroke.</p>
<p>Glutes, Quads, and Calfs work together, pushing down and Hip Flexor and Hamstring pulling up. Just by looking at the size of these muscle groups, we realize that the extensor muscles are much larger than than the flexors.</p>
<p>That makes sense since the legs functional movements, the daily life's moves are all related to pushing: Walking, running, squatting, and lifting all require the legs to push. The only pulling movement in daily life is to lift the leg up for another step. It never has to raise more than its weight, if you disregard the weight of shoes.</p>
<p>Mike Schultz from <a href="http://highlandtraining.net/" target="_blank" title="Highland Training, founded by Mike Schultz" rel="noopener noreferrer">Highland Training</a> wrote this 2015 <a href="https://www.trainingpeaks.com/blog/the-primary-muscles-used-for-cycling-and-how-to-train-them/" target="_blank" title="The Primary Muscles Used for Cycling and How to Train Them, byx Mike Schultz" rel="noopener noreferrer">article</a> on the TrainingPeaks Coach Blog and included a graphic with a much more detailed breakdown of the muscle groups involved based on the findings of <a href="https://www.researchgate.net/publication/5754894_Electromyographic_analysis_of_pedaling_A_review" target="_blank" title="Electromyographic analysis of pedaling: A review" rel="noopener noreferrer">Hug, and Dorel </a>in 2009, and <a href="https://www.ncbi.nlm.nih.gov/pubmed/12586523" title="Lower extremity muscle activities during cycling are influenced by load and frequency">several</a> <a href="https://www.researchgate.net/publication/11102610_Differences_in_leg_muscle_activity_during_running_and_cycling_in_humans" target="_blank" title="Differences in leg muscle activity during running and cycling in humans" rel="noopener noreferrer">earlier </a><a href="https://www.researchgate.net/publication/19367680_Analysis_of_EMG_measurements_during_bicycle_pedalling" title="Analysis of EMG Measuring During Bicycle Pedaling‚Äù J. Biomechanics">studies</a>.&nbsp;&nbsp;</p>

      </div>
    </div>
  </div>
</div>

    </main>

    

    

  </div></div>]]>
            </description>
            <link>https://bythlon.com/pages/the-myth-of-the-upstroke-2</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896089</guid>
            <pubDate>Mon, 20 Jul 2020 09:09:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generating TypeScript types and React Hooks based on GraphQL endpoint]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23895964">thread link</a>) | @danilowoz
<br/>
July 20, 2020 | https://significa.co/blog/generating-typescript-types-and-react-hooks-based-on-graphql-endpoint | <a href="https://web.archive.org/web/*/https://significa.co/blog/generating-typescript-types-and-react-hooks-based-on-graphql-endpoint">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Nowadays, developing <strong>ReactJS</strong> with TypeScript gives us a solid way to write applications: it adds the advantage of type-safety, component auto-documentation, error handling, and accurate autocomplete in the editor code. However, it still requires a considerable effort to write <em>types</em> and keep them maintainable. Moreover, when the data provider is a GraphQL server, it makes you feel like you're doing a useless job, given the server already has its own schemas for types. Seems redundant, right?</p><p>With this in mind,&nbsp;<a href="https://graphql-code-generator.com/" target="_blank" rel="noopener"><strong>GraphQL Code Generator</strong></a>&nbsp;gives us the ability to generate TypesScript typing out of GraphQL schemas. Beyond that, it gives us a couple of plugins to create custom React hooks that don't require any kind of maintenance or workaround to fit into your application.</p><p>Among many others, some of the benefits of using this tool:</p><ul><li><strong>Codeless:&nbsp;</strong>forget about creating the interfaces/types for every GraphQL endpoints; save time and spend effort on what matters;</li><li><strong>Development experience:</strong>&nbsp;as a result of having the types always available, your editor will provide meaningful autocomplete and error checking;</li><li><strong>Types always up-to-date:</strong> if your GraphQL endpoint schemas change, your application will be updated and typescript will help you make sure you make the necessary changes.</li></ul><h2>Setup</h2><p>First of all, let's install the&nbsp;<strong>dependencies</strong>&nbsp;needed:</p><pre><p><span>1</span><span>npm</span><span> i @apollo/react-hooks graphql</span></p></pre><pre><p><span>1</span><span>npm</span><span> i @graphql-codegen/cli @graphql-codegen/import-types-preset @graphql-codegen/typescript @graphql-codegen/typescript-operations @graphql-codegen/typescript-react --save-dev</span></p></pre><p>I'm considering the following&nbsp;<strong>folder structure</strong>, but of course, feel free to adapt it to your liking, just have in mind that it needs a place to store the schemas that will be fetched by the Code Generator:</p><pre><p><span>1</span><span>üì¶ my-project</span></p><p><span>2</span><span> ‚î£ üìÇ src</span></p><p><span>3</span><span> ‚îÉ ‚î£ üìÇ pages</span></p><p><span>4</span><span> ‚îÉ ‚îÉ ‚îó index.tsx</span></p><p><span>5</span><span> ‚îÉ ‚î£ üìÇ queries</span></p><p><span>6</span><span> ‚îÉ ‚îÉ ‚î£ üìÇ autogenerate</span></p><p><span>7</span><span> ‚îÉ ‚îÉ ‚îó my-query.gql</span></p><p><span>8</span><span> ‚îÉ ‚îó apollo-client.ts</span></p><p><span>9</span><span> ‚î£ codegen.yml</span></p><p><span>10</span><span> ‚îó package.json</span></p></pre><p>Then, basically, you'll need to create a configuration file at the root of the project,&nbsp;named <code>codegen.yml</code>. The following snippet shows how I usually set it up in my projects, where it generates different files for its own purpose, in other words, split by concerns like GraphQL operations and server schemas:</p><pre><p><span>1</span><span></span></p><p><span>2</span><span></span><span>schema</span><span>:</span><span> https</span><span>:</span><span>//countries</span><span>-</span><span>274616.ew.r.appspot.com/graphql/</span></p><p><span>3</span><span></span><span>overwrite</span><span>:</span><span> </span><span>true</span><span></span></p><p><span>4</span><span></span></p><p><span>5</span><span></span><span></span></p><p><span>6</span><span></span><span>hooks</span><span>:</span><span></span></p><p><span>7</span><span>  </span><span>afterAllFileWrite</span><span>:</span><span></span></p><p><span>8</span><span>    </span><span>-</span><span> prettier </span><span>-</span><span>-</span><span>write</span></p><p><span>9</span><span></span></p><p><span>10</span><span></span><span>generates</span><span>:</span><span></span></p><p><span>11</span><span>  </span><span></span></p><p><span>12</span><span>  </span><span>src/queries/autogenerate/schemas.tsx</span><span>:</span><span></span></p><p><span>13</span><span>    </span><span>documents</span><span>:</span><span> </span><span>'src/queries/**/**.gql'</span><span></span></p><p><span>14</span><span>    </span><span>plugins</span><span>:</span><span></span></p><p><span>15</span><span>      </span><span>-</span><span> typescript</span></p><p><span>16</span><span></span></p><p><span>17</span><span>  </span><span></span></p><p><span>18</span><span>  </span><span>src/queries/autogenerate/operations.tsx</span><span>:</span><span></span></p><p><span>19</span><span>    </span><span>documents</span><span>:</span><span> </span><span>'src/queries/**/**.gql'</span><span></span></p><p><span>20</span><span>    </span><span>preset</span><span>:</span><span> import</span><span>-</span><span>types</span></p><p><span>21</span><span>    </span><span>presetConfig</span><span>:</span><span></span></p><p><span>22</span><span>      </span><span>typesPath</span><span>:</span><span> ./schemas</span></p><p><span>23</span><span>    </span><span>plugins</span><span>:</span><span></span></p><p><span>24</span><span>      </span><span>-</span><span> typescript</span><span>-</span><span>operations</span></p><p><span>25</span><span></span></p><p><span>26</span><span>  </span><span></span></p><p><span>27</span><span>  </span><span></span></p><p><span>28</span><span>  </span><span>src/queries/autogenerate/hooks.tsx</span><span>:</span><span></span></p><p><span>29</span><span>    </span><span>documents</span><span>:</span><span> </span><span>'src/queries/**/**.gql'</span><span></span></p><p><span>30</span><span>    </span><span>preset</span><span>:</span><span> import</span><span>-</span><span>types</span></p><p><span>31</span><span>    </span><span>presetConfig</span><span>:</span><span></span></p><p><span>32</span><span>      </span><span>typesPath</span><span>:</span><span> ./operations</span></p><p><span>33</span><span>    </span><span>plugins</span><span>:</span><span></span></p><p><span>34</span><span>      </span><span>-</span><span> typescript</span><span>-</span><span>react</span><span>-</span><span>apollo</span></p><p><span>35</span><span>    </span><span>config</span><span>:</span><span></span></p><p><span>36</span><span>      </span><span></span></p><p><span>37</span><span>      </span><span>withHOC</span><span>:</span><span> </span><span>false</span><span></span></p><p><span>38</span><span>      </span><span>withComponent</span><span>:</span><span> </span><span>false</span><span></span></p><p><span>39</span><span>      </span><span>withHooks</span><span>:</span><span> </span><span>true</span></p></pre><p>Also, let's add the scripts to generate the schemas and watch the files change in <code>package.json</code>:</p><pre><p><span>1</span><span>"scripts"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>...</span><span></span></p><p><span>3</span><span>  </span><span>"schemas"</span><span>:</span><span> </span><span>"graphql-codegen --config codegen.yml"</span><span>,</span><span></span></p><p><span>4</span><span>  </span><span>"schemas:watch"</span><span>:</span><span> </span><span>"npm run schemas -- --watch"</span><span>,</span><span></span></p><p><span>5</span><span></span><span>}</span><span>,</span></p></pre><p>And as it turns out in the editor code:</p><p><img src="https://images.prismic.io/significa/e80a75f7-5cf9-443d-bf23-ff864ccb98e9_ezgif.com-video-to-gif.gif?auto=compress,format" alt=""></p><p>This is only one of the possible ways to use it, as it has many plugins, presets, integrations, and configurations, for different purposes such as to generate React higher-order component, Gatsby integration, prettier and lint the files, among other cool things. Feel free to check out&nbsp;the documentation <a href="https://graphql-code-generator.com/" target="_blank" rel="noopener"><strong>here</strong></a>.</p><p><strong>I've made a repository available with the code above, and you <a href="https://github.com/danilowoz/ts-gql-jsx" target="_blank" rel="noopener">can check it out here.</a></strong></p></div></div>]]>
            </description>
            <link>https://significa.co/blog/generating-typescript-types-and-react-hooks-based-on-graphql-endpoint</link>
            <guid isPermaLink="false">hacker-news-small-sites-23895964</guid>
            <pubDate>Mon, 20 Jul 2020 08:47:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Minecraft@Home]]>
            </title>
            <description>
<![CDATA[
Score 220 | Comments 70 (<a href="https://news.ycombinator.com/item?id=23895789">thread link</a>) | @networked
<br/>
July 20, 2020 | https://minecraftathome.com/minecrafthome/ | <a href="https://web.archive.org/web/*/https://minecraftathome.com/minecrafthome/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div><p><span>Server outage resolved and supporting our infrastructure</span><br>

        Between 23:54 UTC yesterday (2020-07-20) and 15:35 UTC today, we suffered from a catastrophic SQL failure which forced us to restore from backup.</p><p>

There may be some credit issues where the system granted more or fewer credits than you expect for work done during this time.<br>
I can't apologize enough. If our BOINC deployment was architected for scale rather than for low cost, we could've avoided this.</p><p>

There are several enhancements to our infrastructure and upgrades we'd like to make, such as migrating services to Kubernetes and potentially using a managed SQL service.</p><p>

<span><b><span color="red">You can help!</span> Please consider visiting our Patreon page, reviewing the current set of benefits, and making a contribution of any size; any amount helps - <a href="https://patreon.com/minecraftathome" rel="nofollow">patreon.com/minecraftathome</a></b></span></p><p>

All contributions go towards covering infrastructure cost and quality-of-life improvements to ensure the project's longevity.
        <br>
        <span>21 Jul 2020, 20:10:54 UTC
    
            ¬∑ <a href="https://minecraftathome.com/minecrafthome/forum_thread.php?id=44"> Discuss</a>
        </span></p></div><hr>
    <div><p><span>That was fast</span><br>

        The origin of the panorama image used in the Minecraft main menu from beta version 1.8.1, released in September 2011, has remained a mystery until now.</p><p>

<b><span>In less than 24 hours after launching the panorama application; a volunteer host for Minecraft@Home, in a sheer stroke of luck, found the world seed, 25357015387625.</span></b><br>
This was approximately </p><p><span color="red">93 days of processing time at a total of 54.5 exaFLOPs</span> compressed into the last 24 hours.</p><p>

The specific host which located the seed belongs to the user <a href="https://minecraftathome.com/minecrafthome/show_user.php?userid=2558" rel="nofollow">vanos0512</a>.<br>
Thank you to the 137 users who contributed 181 hosts with 231 GPUs over the last 24 hours. You all accomplished this.</p><p>

<img src="https://i.imgur.com/f6lGCEn.png"></p><p>

Here are the details if you want to generate this world for yourself:<br>
<b>Minecraft version:</b> <i>Beta 1.7</i><br>
<b>Either of these two valid world seeds:</b> <i>2151901553968352745 or 8091867987493326313</i><br>
<b>Co-ordinates:</b> <i>x60, y76, z-67</i></p><p>

<a href="https://www.youtube.com/watch?v=caLCZNLPgrM" rel="nofollow">See the video released by EarthComputer announcing the finding.</a>
        <br>
        <span>18 Jul 2020, 15:32:11 UTC
    
            ¬∑ <a href="https://minecraftathome.com/minecrafthome/forum_thread.php?id=42"> Discuss</a>
        </span></p></div><hr>
    <div><p><span>Enjoy the scenery</span><br>

        <span>Minecraft@Home is now <span color="red">over one month old</span>! To celebrate this milestone, I present a new research focus; the panorama project.</span></p><p>

If you were here during beta-testing, you might have received a very early version of panorama tasks, and the eagle-eyed among you may have seen the application details <a href="https://minecraftathome.com/minecrafthome/server_status.php" rel="nofollow">on the server status page</a>.</p><p>

<span><b>The panorama app is a CUDA-only app for Linux and Windows with an Nvidia driver version of 418.96 or higher.</b></span></p><p>

This project attempts to find the world seed of the iconic panorama image which appeared in the background of the main menu of Minecraft between 2011 and 2018. The first phase of this project will only last a few days, and we shall update you with their progress in the coming weeks.</p><p>

<img src="https://i.imgur.com/3dyexWe.png"></p><p>

Right now, the application is quite substantial. Unlike the OpenCL applications for the Kaktwoos project, <b>if you allow BOINC to run tasks always; you may experience some stuttering or lag in your desktop environment while running these tasks</b>. These tasks do not have checkpointing support, but run in around 1 hour on an average host to mitigate the majority of lost cycles.</p><p>

<span>As always, <a href="https://minecraftathome.com/minecrafthome/prefs.php?subset=project" rel="nofollow">you can change which projects of which you decide to participate in your user preferences</a>.</span></p><p>

Let us know if you have any questions, and as always join the discussion over on <a href="https://discord.gg/xVFh9bp" rel="nofollow">the Discord server.</a>
        <br>
        <span>17 Jul 2020, 15:31:43 UTC
    
            ¬∑ <a href="https://minecraftathome.com/minecrafthome/forum_thread.php?id=39"> Discuss</a>
        </span></p></div><hr>
    <div><p><span>Kaktwoos 2.03 and Badges!</span><br>

        You may have seen many workunits just disappear from existence today.</p><p>

<img src="https://munin.kiska.pw/munin-cgi/munin-cgi-graph/Munin-Node/Munin-Node/results_minecraftathome-pinpoint=1594193183,1594247603.png?&amp;lower_limit=&amp;upper_limit=&amp;size_x=400&amp;size_y=200"></p><p>

Worry not! We realised there were far too many workunits scanning duplicate seeds, so we've scaled back the original workunits to the correct seed ranges <span><i>(no in-progress results were touched, so none of you should have lost any credit)</i></span>.</p><p>

We have located some promising seed candidates which were missed from processing and can be used as an input to this job, so they are currently set as the highest priority.</p><p>

Also, <span><b>we now have badges</b></span>! If you view the forums, any comments in threads, or on the leaderboards; you will see the new badges.<br>
We're open to suggestions for future badges, so please leave us some comments on this thread.
        <br>
        <span>8 Jul 2020, 21:06:03 UTC
    
            ¬∑ <a href="https://minecraftathome.com/minecrafthome/forum_thread.php?id=30"> Discuss</a>
        </span></p></div><hr>
    <div><p><span>Profile creation and OpenCL vendor pinning</span><br>

        In the last news post, I advised everyone to create a profile in order to be eligible for 'user of the day' selection.<br>
Unfortunately, there was an issue with the ReCaptcha implementation which prevented this. This issue is now resolved.</p><p>

Now, you are able to <a href="https://minecraftathome.com/minecrafthome/create_profile.php" rel="nofollow">create a profile here</a>.</p><p>

Also, good news for hosts with OpenCL capable hardware from more than one vendor <i>(e.g. an Intel iGPU and an Nvidia GPU)</i><br>
The latest update to the kaktwoos app should ensure the tasks run on the correct device.<br>
If you are a user with a multi-vendor host, please keep an eye on your results and let us know if you're having any issues.</p><p>

As always, please get involved with the conversation in the <a href="https://minecraftathome.com/minecrafthome/forum_index.php" rel="nofollow">message boards</a>, and <a href="https://discord.gg/xVFh9bp" rel="nofollow">join the Discord</a>!
        <br>
        <span>3 Jul 2020, 16:57:49 UTC
    
            ¬∑ <a href="https://minecraftathome.com/minecrafthome/forum_thread.php?id=22"> Discuss</a>
        </span></p></div><hr>
    <p><a href="https://minecraftathome.com/minecrafthome/old_news.php">... more</a></p><p><small>
    News is available as an <a href="https://minecraftathome.com/minecrafthome/rss_main.php">RSS feed &nbsp; <img src="https://minecraftathome.com/minecrafthome/img/rss_icon.gif" alt="RSS"></a>
        </small></p></div></div>]]>
            </description>
            <link>https://minecraftathome.com/minecrafthome/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23895789</guid>
            <pubDate>Mon, 20 Jul 2020 08:19:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Demo of OpenAI's GPT-3 generating tweets given a word]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 84 (<a href="https://news.ycombinator.com/item?id=23895706">thread link</a>) | @hardmaru
<br/>
July 20, 2020 | https://thoughts.sushant-kumar.com/hong%20kong | <a href="https://web.archive.org/web/*/https://thoughts.sushant-kumar.com/hong%20kong">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
	<blockquote>
		<p><span>‚Äú</span>HK, regardless of the political system, should always focus on making itself more efficient and liveable.<span>‚Äù</span></p>
	</blockquote>

		</div></div>]]>
            </description>
            <link>https://thoughts.sushant-kumar.com/hong%20kong</link>
            <guid isPermaLink="false">hacker-news-small-sites-23895706</guid>
            <pubDate>Mon, 20 Jul 2020 08:03:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rethinking My Thinking]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23895631">thread link</a>) | @vernonginx
<br/>
July 20, 2020 | https://www.paulmcgrath.me/posts/2020/rethinking-my-thinking/ | <a href="https://web.archive.org/web/*/https://www.paulmcgrath.me/posts/2020/rethinking-my-thinking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

<figure>
    
        <picture>
            <img src="https://www.paulmcgrath.me/assets/images/rethinking.jpg" data-src="/assets/images/rethinking.jpg" alt="Image of man looking over sea.">
        </picture>
        
    
    <figcaption>
        <p>Photo by Ante Hamersmit on Unsplash.</p>
        
    </figcaption>
    
</figure>

<h4><i>Seeking creative space, I spent two months exploring productivity and tools for thought. Here's what I discovered.</i></h4>

<p>I recently learned that Netflix tested a ‚Äú<a href="https://www.theguardian.com/commentisfree/2019/nov/02/netflix-too-much-to-watch-speed-watching">speed-watching</a>‚Äù feature and it seems the most apt metaphor for our era. Too much content stressing you out? Try watching it faster. Far more likely is that it‚Äôll go on some sort of list. A watch it, read, it, do it later sort of list. These lists have become a digital extension of <a href="https://cdn8.openculture.com/2018/07/10223435/Tsunduko_.jpg">Tsundoku</a>: the Japanese art of buying books and not reading them. Now we hoard ideas, articles, and links and never do anything with them.</p>

<p>This feeling can be stressful, as our creative need to engage with the world collides with relentless change, particularly for those in the digital sphere. In 2019, Nobel prize-winning Psychologist Daniel Kahneman said that ‚Äú<a href="https://www.youtube.com/watch?v=WKSts1lNZhc&amp;feature=emb_title">Technology evolves exponentially, whereas our mechanisms for coping are linear</a>‚Äù, and that struck a chord. Never has this been more evident than now, mid-pandemic, as we exchange the subtle, reassuring friction of normal living for the ‚Äúalways-on‚Äù, performance mode of online existence.</p>

<p>This isn‚Äôt new, though. In 2012, Cal Newport wrote about knowledge workers lacking <a href="https://www.calnewport.com/blog/2012/11/21/knowledge-workers-are-bad-at-working-and-heres-what-to-do-about-it/">a culture of improving their systems of work</a>. Rather than improve our process, we tend to focus on managing email, and lots of it. Technology, it seems, has opened up incredible opportunities while contributing to a ‚Äúgreat frazzling‚Äù of our collective minds. Yet there is something different about the current situation we find ourselves in. In particular, the digital impact of the pandemic. One of my favourite writers, <a href="https://twitter.com/vgr">Venkatesh Rao</a>, recently hinted at the significance of this shift:</p>

<blockquote>
<p>Software eating the world is going through an inflection point I thought wouldn‚Äôt arrive till 2030. The pandemic has accelerated the schedule by 10 years. <a href="https://pca.st/mm2vlx3d">[source]</a></p>
</blockquote>

<p>Even for those who wouldn‚Äôt consider themselves very tech-inclined, it‚Äôs easy to see the truth in this. Couples are <a href="https://www.businessinsider.com/zoom-weddings-during-coronavirus-photos-2020-4?op=1&amp;r=US&amp;IR=T">getting married via Zoom</a>. Parents can <a href="https://9to5mac.com/2020/04/07/facetime-babies/">FaceTime babies in neonatal units.</a> A woman <a href="https://www.buzzfeednews.com/article/laurenstrapagiel/potato-boss-video-call">accidentally turned herself into a potato during a digital happy hour</a>. <strong>Software is the world now.</strong> And it would be nice if we made it work for us, for once.</p>

<h2 id="second-brains">Second Brains</h2>

<p>During Ireland‚Äôs lockdown, I found myself with more time to explore this thought. By chance I came across Tiago Forte‚Äôs <a href="https://www.buildingasecondbrain.com/"><em>Building a Second Brain</em></a>, which advertised a ‚Äú<em>world-class idea management system in 35 days</em>.‚Äù It sounded fascinating, albeit outside my price range. I read around the area instead, starting with some of his early work. His first course seemed useful, called <em><a href="https://learn.fortelabs.co/p/get-stuff-done-like-a-boss">Get Stuff Done</a>,</em> and I signed up. It was a digital-reimagining of David Allen‚Äôs famous <em><a href="https://gettingthingsdone.com/">Getting Things Done</a>:</em> a book I had read when younger. At the time I had found it difficult to integrate as it was so rooted in physical artefacts like folders and paper. A tough sell, when my life was becoming ever more digital.</p>

<figure>
    
        <picture>
            <img src="https://www.paulmcgrath.me/assets/images/basb.jpg" data-src="/assets/images/basb.jpg" alt="Screenshot from Tiago Forte's Building a Second Brain">
        </picture>
        
    
    <figcaption>
        <p>(Source: Tiago Forte's Building a Second Brain)</p>
        
    </figcaption>
    
</figure>

<p>The course was excellent, and finally cemented the GTD workflow for me with digital tools, but Tiago hinted at a more important takeaway. He suggested that automating our daily efforts saves us mental energy, and frees us to focus on the creative, interesting parts of life. Right there was a glimmer of something more valuable: that high-leverage digital tools could help me spend more time having fun with ideas. I was obsessed.</p>

<p>I decided to follow Tiago‚Äôs structure of <a href="https://fortelabs.co/blog/para/"><em>PARA</em></a> (Projects, Areas, Resources, and Archives) and practice of <em><a href="https://twitter.com/fortelabs/status/1142899542360297473">CODE</a></em> (Collect, Organise, Distill, Express) to structure my notes, and committed to it for a couple of weeks. Every so often, an idea would form, which I would capture, and over time it would either ‚Äúbubble-up‚Äù by my returning to it, or would fade out as it wasn‚Äôt significant or relevant. The effort was low, but the return was high. I concerned myself less with management and more on what I found interesting. The result, after a month or so, had no fanfare, or celebration. In fact, it was almost anticlimactic, as there was no reactivity, stress, or concern. Left instead was a stillness that you could feel bored with, if you were of that persuasion. Instead, I found myself thinking, creating, and exploring far more in this new free space.</p>

<p>Encouraged by this success, I dug deeper. I learned about the <a href="https://www.lesswrong.com/posts/NfdHG6oHBJ8Qxc26s/the-zettelkasten-method-1">Zettelkasten Method</a>, by reading <a href="https://www.amazon.com/How-Take-Smart-Notes-Nonfiction-ebook/dp/B06WVYW33Y"><em>How to Take Smart Notes</em></a>, both likely geneses for <em>Building a Second Brain.</em> I doubled-down on earlier attempts at noise-reduction by reading Cal Newport‚Äôs <em><a href="https://www.amazon.com/Deep-Work-Focused-Success-Distracted/dp/1455586692">Deep Work</a></em> and <a href="https://www.amazon.co.uk/Digital-Minimalism-Living-Better-Technology-ebook/dp/B07D1G6DTF/ref=sr_1_1?crid=2IMCD9N2NEGR1&amp;dchild=1&amp;keywords=digital+minimalism&amp;qid=1594227304&amp;s=books&amp;sprefix=digital+min%2Camazon-devices%2C157&amp;sr=1-1"><em>Digital Minimalism</em></a>. My phone went on permanent ‚ÄúDo Not Disturb‚Äù and I found healthy space in a fixed and sustainable schedule. I became a lab rat for these ideas, because <em>they actually worked</em>.</p>

<p>Coupling these three strategies together: <strong>automating the daily, repeatable parts of living</strong>, <strong>reducing external noise,</strong> and <strong>building an ad-hoc knowledge graph</strong>, created a situation I so longed for ‚Äî the possibility of taking on well-defined personal projects with specific outcomes, knowing that if I had new ideas along the way, I wouldn‚Äôt lose them. In fact, they may even have improved by the time I engaged with them.</p>

<p>To test this further, I started two courses by Dr. Barbara Oakley called <em><a href="https://www.coursera.org/learn/learning-how-to-learn">Learning How to Learn</a></em> and <em><a href="https://www.coursera.org/learn/mindshift">Mindshift</a>.</em> I found significant parallels between Dr Oakley‚Äôs description of how the mind creates knowledge ‚Äúchunks‚Äù and creating notes in my ‚Äú<em>Second Brain</em>‚Äù, as both develop knowledge graphs that aid creativity. I took notes throughout, often finding that they sparked associations between notes in very different areas ‚Äî a phenomenon Dr Oakley calls <em><a href="https://www.coursera.org/learn/learning-how-to-learn/lecture/mrPn2/the-value-of-a-library-of-chunks">Transfer</a>.</em> Linking these concepts was trivial now, as they were just nodes in a digital graph.</p>

<p>I had found a solution to Cal Newport‚Äôs concerns, and it didn‚Äôt involve sending email.</p>

<figure>
    
        <picture>
            <img src="https://www.paulmcgrath.me/assets/images/lhtl.jpg" data-src="/assets/images/lhtl.jpg" alt="Screenshot from Dr. Barbara Oakley's Mindshift">
        </picture>
        
    
    <figcaption>
        <p>(Source: Dr. Barbara Oakley's Mindshift)</p>
        
    </figcaption>
    
</figure>

<h2 id="breaking-it-down">Breaking It Down</h2>

<p>If you‚Äôre a knowledge worker starting this journey, you too may feel overwhelmed at the amount that life and work expects of you. If you have no system at all, writing down all the tasks required of you on a single sheet of paper is a great start. This brain dump is essential, as we have limited working memory (<a href="https://www.coursera.org/learn/learning-how-to-learn/lecture/X7E9r/introduction-to-memory">roughly 4 ‚Äúslots</a>‚Äù) and whatever isn‚Äôt written down continues to occupy that space. At some point, you may find that this system won‚Äôt scale to the breadth or depth of tasks required of you. I found my solution in <em>Getting Things Done</em> with <a href="https://culturedcode.com/things/">Things3</a>, but there are other methodologies <a href="https://lifehacker.com/productivity-101-a-primer-to-the-getting-things-done-1551880955">outlined in this article</a> that may suit you better.</p>

<figure>
    
        <picture>
            <img src="https://www.paulmcgrath.me/assets/images/gtd.jpg" data-src="/assets/images/gtd.jpg" alt="Screenshot from David Allen's Getting Things Done.">
        </picture>
        
    
    <figcaption>
        <p>(Source: David Allen's Getting Things Done)</p>
        
    </figcaption>
    
</figure>

<p>Managing your tasks is an excellent first step, but you may still experience information overload. Most knowledge workers (at least in software engineering) have an enormous quantity of material to read, reference, and recall at short notice. Few have a system to manage this. Tiago Forte‚Äôs <em><a href="https://fortelabs.co/blog/para/">PARA</a></em> shines here, as a flexible and useful system for managing hierarchies of reference material. Digital tools are the only prerequisite, and many are available, depending on your needs. <a href="http://notion.so/">Notion</a>, <a href="http://evernote.com/">Evernote</a>, and <a href="https://bear.app/">Bear</a> are great for general users. Academics may prefer <a href="https://www.mendeley.com/">Mendeley</a> or <a href="https://www.zotero.org/">Zotero</a>.</p>

<p>At this stage you may feel more in control. Great! You could stop here, but there is a final step, and it‚Äôs the most important. I mentioned that Tiago Forte uses the acronym <em><a href="https://twitter.com/fortelabs/status/1142899542360297473">CODE</a></em> to describe the process of Collecting, Organising, Distilling, and Expressing what you read and reference. By now, you should be accomplishing the first two letters of that acronym. The remaining two, distilling and expressing, are important aspects of the <em><a href="https://nesslabs.com/generation-effect">Generation Effect</a>:</em> a phenomenon where active engagement with material leads to greater recall. If you want to understand what you read, you need to do something with it. That action is note-taking.</p>

<p>Taking notes can be as simple as ensuring you read with a pen and notebook to hand. I find this doesn‚Äôt scale very well though, and also doesn‚Äôt mirror how my mind works. I want networked thought, graphs of ideas, thoughts linking to other thoughts, and so do many others. Tools like <a href="https://roamresearch.com/">Roam</a>, <a href="https://obsidian.md/">Obsidian</a>, and <a href="https://foambubble.github.io/foam/">Foam</a> resolve this as they represent literal graphs of thinking, allowing your ideas to cluster, link, and collide as unique insights. Choose a tool, and write about what you read in your own words. You may explore, create, and extrapolate in any way you wish. You may take a different approach to the next person, and that‚Äôs encouraged, as these tools should augment <em>your</em> thoughts. And that‚Äôs what they are: tools to aid your thoughts. Augmentations to help your brain make sense of the world.</p>

<figure>
    
        <picture>
            <img src="https://www.paulmcgrath.me/assets/images/roam.jpg" data-src="/assets/images/roam.jpg" alt="Screeshot from Roam Research.">
        </picture>
        
    
    <figcaption>
        <p>(Source: Roam Research)</p>
        
    </figcaption>
    
</figure>

<p>What you end up developing, ultimately, is an idea machine, and a process to get the most from it. This starts from a place of ‚Äúdeep unknowing‚Äù, to a system which shows you the most unique and interesting intersections of your thoughts as geneses for new writing. The ‚Äúdaunting blank page‚Äù should never be blank again.</p>



<p>While exploring this rabbit hole, I learned that Personal Knowledge Managment (PKM) is a discrete area of study, rather than a new area of focus. Tiago Forte‚Äôs ‚Äú<em>Second Brain</em>‚Äù had acted as an accessible entry point: a marketable tool for knowledge workers; but there is ample room for innovation beyond this approach. Andy Matuschak‚Äôs <a href="https://notes.andymatuschak.org/Evergreen_notes">Evergreen notes</a> outline a new theory for this area, and <a href="https://tomcritchlow.com/2019/02/17/building-digital-garden/">digital</a> <a href="https://www.notion.so/Rethinking-My-Thinking-e565d53ca7394314814b0fcf306dc0bf#a3fef6cac37c4a239458e739b66204e1">gardening</a> has become a very tactile metaphor for exploring ideas in public. There is an emerging ‚Äúnew wave‚Äù also, focused <a href="https://notes.andymatuschak.org/z7kEFe6NfUSgtaDuUjST1oczKKzQQeQWk4Dbc">less on the act of note-taking</a>, and more on augmented thinking as the emergent frontier.</p>

<p>Andy Matuschak and Michael Nielsen have summarised the latent ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.paulmcgrath.me/posts/2020/rethinking-my-thinking/">https://www.paulmcgrath.me/posts/2020/rethinking-my-thinking/</a></em></p>]]>
            </description>
            <link>https://www.paulmcgrath.me/posts/2020/rethinking-my-thinking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23895631</guid>
            <pubDate>Mon, 20 Jul 2020 07:47:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GPT-3 is the Elephant, not the Rider]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23895619">thread link</a>) | @bpodgursky
<br/>
July 20, 2020 | https://bpodgursky.com/2020/07/20/gpt-3-is-the-elephant-not-the-rider/ | <a href="https://web.archive.org/web/*/https://bpodgursky.com/2020/07/20/gpt-3-is-the-elephant-not-the-rider/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><em><a href="https://www.amazon.com/Righteous-Mind-Divided-Politics-Religion/dp/0307455777">The Righteous Mind</a></em> by Jonathan Haidt explains the link between our conscious, calculating mind and our subconscious, instinctive mind with a metaphor: <em><a href="https://www.creativehuddle.co.uk/the-elephant-and-the-rider">The Elephant and the Rider</a></em>:</p>



<ul><li>The rider is our ‚Äúconscious‚Äù, reasoning mind, which uses explainable logic to reason about the world, our own behavior, and our preferences&nbsp;</li><li>The elephant is the momentum of pre-trained and pre-wired preferences with which we make ‚Äúsnap‚Äù decisions about preferences or morality.</li></ul>



<p>The rider ‚Äî <em>homo logicus</em> ‚Äî believes itself to be in control of the elephant, but this is only about 10% true.&nbsp; In truth, when the rider and elephant disagree about which direction to ride, the elephant almost always wins. &nbsp; The rider instead spends time making excuses to justify why it really <em>intended</em> to go that direction all along!</p>



<p>Or, non-metaphorically: the vast majority of the time, we use our ‚Äúthinking‚Äù mind to explain and generate justifications <em>for </em>our snap judgements ‚Äî but our thinking mind only rarely is able to actually redirect our pre-trained biases into choices we <em>really don‚Äôt want </em>to make.&nbsp;&nbsp;</p>



<p>Occasionally, if it‚Äôs a topic we don‚Äôt have strong pre-trained preferences about (‚ÄúWhat‚Äôs your opinion on the gold standard?‚Äù), the rider has control ‚Äî but possibly only until the elephant catches a familiar scent (‚ÄúThe gold standard <em>frees</em> individuals from the <em>control</em> of governmental fiat‚Äù) and we fall back to pre-wired beliefs.</p>



<p>Most of the time, the rider (our thinking brain)‚Äôs job is to explain <em>why </em>the elephant is walking the direction it is ‚Äî providing concrete explainable justifications for beliefs whose <em>real </em>foundation is genetic pre-wiring (‚ÄúWhy are spiders scary?‚Äù) or decades of imprinting (‚ÄúWhy is incest bad?‚Äù)</p>



<p>But even though the rider isn‚Äôt, strictly speaking, <em>in control,</em> it‚Äôs the glue which helped us level up from smart apes to quasi-hive organisms with cities, indoor plumbing, and senatorial filibusters.&nbsp; By nudging our elephants in <em>roughly</em> the right direction once in a while, we can build civilizations and only rarely atomize each other.</p>



<hr>



<p>Traditional visions of AI ‚Äî and the AI still envisioned by popular culture ‚Äî&nbsp; is cold, structured, logic incarnate.&nbsp;&nbsp;</p>



<p>Most early game AIs performed a minimax search when choosing a move, methodically evaluating the search space.&nbsp; The AI would calculate for each move how to counter the best possible move the opponent could make, and then would perform these calculations as deep as <a href="https://en.wikipedia.org/wiki/Minimax#/media/File:Plminmax.gif">computing power permitted</a>:</p>



<figure><img src="https://lh3.googleusercontent.com/ud8kBw-1J-kflDLagogJfcjbvmWDZvug7RMZiu-RSZnyzCRwJNdk41gBvsWlSP8RjkzqQHP7-WnJ9tMVLqbgOtOyolxB0p67N1TnN6XMdE9UenqkC5tOsER1bnVSGpmbQXmQgm0c" alt=""></figure>



<p>This is still the AI portrayed in popular media.&nbsp; In a positive portrayal, the AI is precise, logical, and (somewhat) useful:</p>



<blockquote><p>C-3PO : Sir, the possibility of successfully navigating an asteroid field is approximately 3,720 to 1</p><p>Han Solo : Never tell me the odds.</p></blockquote>



<p>In a negative portrayal, AI is cold and calculating, but never pointlessly cruel.&nbsp; In <em>2001: A Space Odyssey</em>, if HAL 9000 opened the pod bay doors, it would prove (in worst case) a potential risk to HAL 9000 (itself), and the mission.&nbsp; The rational move was to eliminate Dave.</p>



<blockquote><p>Bowman: Open the pod bay doors, HAL.</p><p>HAL 9000: I‚Äôm sorry, Dave. I‚Äôm afraid I can‚Äôt do that.</p></blockquote>



<p>HAL 9000 was simply playing chess against Dave.</p>



<p>NLP and structured knowledge extraction operated similarly.&nbsp; NLP techniques&nbsp; were built to turn sentences into query-able knowledge bases via structured information extraction.&nbsp; Facts were extracted from natural-language sentences and stored in <a href="https://nlp.stanford.edu/software/openie.html">knowledge bases</a>:</p>



<figure><img src="https://lh6.googleusercontent.com/OrUt92J_TuAMdpIwV0YPFVwJ63ILJBu-O1jL5sFmPjr0NE9Scb4lolprW_dVt_gABmBB71E85Wegjk1A4bCF8NlS9VT-xOmwZvajEeTTf9o5_u5NDOzHAEBmSTQsg-J4FmVl7ISJ" alt=""></figure>



<p>Decisions made by AI systems which used information extraction techniques were fully explainable, because they were built from explicit extracted facts.&nbsp;</p>



<p>These visions of AI all envisioned artificial agents as the elephant <em>riders</em>, in which decisions were made upon cold facts.&nbsp; Perhaps we first tried to build explainable AI because we preferred to see <em>ourselves </em>as the riders ‚Äî a strictly logical agent in firm control of our legacy animal instincts.</p>



<hr>



<p>But modern AI is the elephant.</p>



<p>Neural networks have replaced traditional structured AI in almost every real application ‚Äî in both academia and industry.&nbsp; These networks are fast, effective, dynamic, easy to train (for enough money), and <em>completely unexplainable.</em></p>



<p>Neural networks imitate animal cognition by modeling computation as layers of connected neurons, each neuron connected to downstream neurons with varying strength:</p>



<figure><img src="https://lh5.googleusercontent.com/2lh5kehxTJGR_nn_wxlFEIBFDigu6Jss7NzCvGHFJ17W_V2R3D_lJxqGDaztJ729GxlRK1bdaWmAxBBP53R5KHEpGKEsBTKz0X3R2o_tX3M-hW6GVFxvRYHPnV-DIu9wnfNt9gWy" alt=""></figure>



<p>There‚Äôs a huge amount of active research into how to design more effective neural networks, how to most efficiently train neural networks, and how to build hardware which most effectively simulates neural networks (for example, Google‚Äôs <a href="https://cloud.google.com/tpu">Tensor Processor Units</a>).&nbsp;&nbsp;</p>



<p>But none of this research changes the fact that neural networks are (perhaps by design) <em>not explainable ‚Äî </em>training produces networks which are able to answer questions quickly and often correctly, but the trained network is just a mathematical array of weighted vectors which cannot be meaningfully translated into human language for inspection.&nbsp; The only way to evaluate the AI is to see what it does.</p>



<p>This is the elephant.&nbsp; And it is wildly effective.</p>



<hr>



<p><a href="https://news.developer.nvidia.com/openai-presents-gpt-3-a-175-billion-parameters-language-model/">GPT-3</a> is the world‚Äôs most advanced neural network (developed by the OpenAI consortium), and an API backed by GPT-3 was soft-released over the past couple weeks to high-profile beta users. &nbsp; GPT-3 is a neural network with 175 billion trained parameters (by far the world‚Äôs largest publicly documented neural network).&nbsp; It was trained on a wide range of internet-available text sources.</p>



<p>GPT-3 is a predictive model ‚Äî that is, provide it the first part of a block of text, and it will generate the text which it predicts should come next.&nbsp; The simplest application of text prediction is writing stories, which GPT-3 <a href="https://github.com/minimaxir/gpt-3-experiments/blob/master/examples/unicorn/output_0_7.md">excels at</a> (the prompt is in <strong>bold,</strong> generated text below):</p>



<figure><img src="https://lh4.googleusercontent.com/7H0XZMG_DF8YBEcPxElNs0CSIc6DCDyfw4dwNrSkSBKTXa53f2HeG1f3RQ3pQA71taUyjiuNg8mPvv2e6k1qINrZEF9GLz9T8FeCplKx00RiSALQzrDiuK-6O-wCF9IOLEeX5w0v" alt=""></figure>



<p>But text prediction is equally applicable to everyday conversation.&nbsp; GPT-3 can, with prompting, answer <a href="https://twitter.com/nicklovescode/status/1284050958977130497/photo/1">everyday questions</a>, and even identify when questions are nonsensical (generated answers at the bottom):</p>



<figure><img src="https://lh3.googleusercontent.com/RKblkR2q12adL6nIo-VRCYb5FLaQX5J9gd7YAaXy9si8wULHYpt0FngcptgQ2gJrqe_jVCEMlM_NNjLi97az98WyFJgOfnLWGMPxHsUf0Z_qsvbTnbd3EXihOJ00494uNraXmxRZ" alt=""></figure>



<p>Gwern has <a href="https://www.gwern.net/GPT-3">generated</a> GPT-3 responses on a wide range of prompts, categorizing where it does well and where it does poorly.&nbsp; Not every response is impressive, but many are, and the conclusion is that GPT-3 is a huge leap forward from GPT-2 (which used 1.5B parameters, vs GPT-3‚Äôs 175B).</p>



<hr>



<p>GPT-2 and GPT-3 have no model of the world, but that doesn‚Äôt stop them from having opinions when prompted.</p>



<p>GPT-2/3 are trained on the internet, and are thus the aggregated voice of anyone who has written an opinion on the internet.&nbsp; So they are very <em>good </em>at quickly generating judgements and opinions, even though they have absolutely no logical or moral framework backing those judgements.</p>



<p>Huggingface provides a <a href="https://transformer.huggingface.co/doc/gpt2-large">publicly-accessible playground</a> to test GPT-2‚Äôs predictions on your own text inputs (GPT-3 is, for now, available only to internet celebrities and VCs).&nbsp; We can prompt GPT-2 for opinions on a variety of emotionally charged topics, like incest:</p>



<figure><img src="https://lh3.googleusercontent.com/KUWi965-5Ky7aPo5uLju8SIU-VdGobIBfiUyRg19sSG09EXvWS_ShM8a0Lg0bZ5ngJu6Q_-RBkEmF0_74o3jYzYg2kMjLehS_UYJxyPHPFfmKov-Ey-LjfNdL99A2-9Z07rJy-hx" alt=""></figure>



<p>abortion:</p>



<figure><img src="https://lh4.googleusercontent.com/Nj_tUgUrfk_tamMZOmUkWTOoCXhG23c7JBKU-gysCGG6DoTiVmk6A2lJTO__oRpyz1pbQ6Vy4SVVI-HJk9aiA3lGyAJ9LmB6tHZQ-bN48uIxkSqvFnK1XTT6d8oPLqMiNPOH48rX" alt=""></figure>



<p>and other topics likely to provoke an emotional response:</p>



<figure><img src="https://lh4.googleusercontent.com/mo2gIlBIni5ZmF3JRGOLhcD3IG-GDn6WXnZtoGtXWfFXzN8Pw_QpqrCTopzQj0kltiukuq30r0_L6-1m6_Cna2kSvHsZzasvcw5FmLYmlEMuDf0chDwRKbRJBt3jNrsIW0Bjyaro" alt=""></figure>



<p>These are elephant responses, generated by volume of training data, not clever logical deduction .&nbsp; GPT-* has absolutely no model of the world or moral framework by which it generates logical responses ‚Äî and yet the responses read as plausibly human.  </p>



<p>Because, after all, <em>we </em>are 90% elephant.  </p>



<hr>



<p>What does this mean for AI, and for us?</p>



<p>Most people have no idea what modern AI <em>is</em>, and that makes effective oversight of AI research by the public completely impossible.&nbsp; Media depictions of AI have only shown two plausible futures:</p>



<ul><li>Hyper-logical, explainable, ‚ÄúFriendly AI‚Äù: Data from <em>Star Trek</em>.&nbsp; Alien, but because of the <em>absence </em>of emotion</li><li>Hyper-logical, explainable, ‚ÄúDangerous AI‚Äù: <em>Terminator</em>.&nbsp; Deadly, but for an explainable reason: the AI is eliminating a threat (us)</li></ul>



<p>These visions are so wildly far from the future we are in, that the public is less informed for having been shown them&nbsp;&nbsp;</p>



<p>The AIs we‚Äôll <em>actually</em> interact with tomorrow ‚Äî on Facebook, Reddit, Twitter, or a MMORPG ‚Äî&nbsp; are utterly un-logical.&nbsp; They are the pure distilled emotions of anyone who has ever voiced their opinions on the internet, amplified a thousandfold (and perhaps filtered for anger or love for <em>particular </em>targets, like China, Russia, or Haribo Gummy Bears).&nbsp;</p>



<p>If we want the public to have any informed opinion about what, how, and where AI is deployed (and as GPT-3/4/5 seem poised to obviate <em>all creative writing</em>, among other careers, this seems like a reasonable ask), the first step is to stop showing them an inaccurate picture of what Google, Microsoft and OpenAI have actually built.</p>



<p>And second: if we <em>do </em>want to ever get the AI we saw in <em>Star Trek</em> (but hopefully not <em>Terminator</em>), we need to actually build a model-based, logical elephant <em>rider</em>, and not just the elephant itself ‚Äî even though it‚Äôs <em>much, much, harder</em> than downloading 20 billion tweets of training data and throwing them at a trillion parameter neural network.</p>



<p>Or maybe we should figure out how to do it ourselves, first. </p>
	</div></div>]]>
            </description>
            <link>https://bpodgursky.com/2020/07/20/gpt-3-is-the-elephant-not-the-rider/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23895619</guid>
            <pubDate>Mon, 20 Jul 2020 07:45:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Where to begin? Some practical tips from a beginner]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23895553">thread link</a>) | @atapas
<br/>
July 20, 2020 | https://blog.greenroots.info/where-to-begin-some-practical-tips-from-a-beginner-ckcu5llil00ncw8s11dr1fh2w | <a href="https://web.archive.org/web/*/https://blog.greenroots.info/where-to-begin-some-practical-tips-from-a-beginner-ckcu5llil00ncw8s11dr1fh2w">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><blockquote>
<p>The <code>Expert</code> in anything was once a <code>Beginner</code>.</p>
</blockquote>

<p>Recently I had a chance to  <a target="_blank" rel="noopener noreferrer" href="https://hashnode.com/post/where-to-begin-ckcola56d0034s0s1goh56ua4/answer/ckcprkctw00fq9ss1boil9o7c">respond to the HashNode  discussion thread</a> asking, <em>Where to begin</em>? The question and my response to it was around a specific context but, after thinking more about it, I got the idea of expanding it as a blog article.</p>
<p>In my opinion, the word <code>beginner</code> is underrated. We use this term loosely and allow others to use it without realizing the true power behind it. This blog post is about my views of where to begin and the fun of being a beginner.</p>
<p>I am sure, you will be able to relate to it. It will be great to hear from your experiences as well. Please share your thoughts, learning, experiences as comments below.</p>

<p>We all are born as beginners. From a toddler to kid to teenager to an adult, a beginner's journey is about learning, improving, persisting and again loop the cycle for a new beginning. Believe me, we will be doing just the same for the entire life!</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1595142482429/Y8SwXwNfd.png?auto=format&amp;q=60" alt="Beginnercycle.png"></p>
<p>Exactly the same philosophy applies to the skill development, coding, programming, our creative work, whatever we take up next. All of the four stages are equally important for us to get transitioned from a beginner to an expert or master.</p>
<ul>
<li><code>Begin:</code> Start of the journey.</li>
<li><code>Learn:</code> Being in the journey and discovering the end of it. </li>
<li><code>Improve:</code> Knowing the struggle and challenges of the past to ensure a better future of the journey.</li>
<li><code>Persist:</code> The ability to stay firm, focused, confident and try completing an enjoyable journey.</li>
</ul>

<p>A famous quote by Barbara Sher,</p>
<blockquote>
<p>You can learn new things at any time in your life if you're willing to be a beginner. If you actually learn to like being a beginner, the whole world opens up to you.</p>
</blockquote>
<p>As a beginner, the question of <em>where to begin</em> is very common. However finding the right answer may depend on various factors like,</p>
<ul>
<li>What am I beginning with?</li>
<li>Why am I doing this?</li>
<li>What's my end goal?</li>
<li>Is there a reference(or experience) to follow when I begin?</li>
<li>What if I fail?</li>
</ul>
<h2 id="-begin-with-the-end-in-mind">‚òëÔ∏è Begin with the end in mind</h2>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1595161532368/gd3Hj3q8x.gif?auto=format,compress&amp;gif-q=60" alt="goal.gif"></p>
<p>This is about knowing the end goal at the beginning of the journey. Say, You want to learn reactjs and you do not have much ideas about it yet. That's fine but, you should have fair idea of why do you want to learn reactjs? What are you going to do with it? Is it going to help getting you the next cool job? or Is it for fun learning? certification etc?</p>
<p>Time is precious and invaluable and we must make a good use of it. There must be reasons of beginning something. Also beginning with the end in mind gives you enough planning opportunities to make your learning productive and fruitful.</p>
<h2 id="-motivation-is-important">‚òëÔ∏è Motivation is important</h2>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1595161079335/3UPbGShgN.gif?auto=format,compress&amp;gif-q=60" alt="motivation.gif"></p>
<p>You have began. How are you doing? It is hard to continue without a motivation. Some of us are self motivated. Many of us need an external motivation factor. A motivation to begin something always helps us in completing the journey with positive outcome.</p>
<p>At present, <a target="_blank" rel="noopener noreferrer" href="https://hashnode.com/n/2articles1week">#2articles1week</a> challenge motivates me to write articles for the technology community benefit. I began on the challenge with the motivation of writing at least 2 quality articles in a week and I am on it!</p>
<h2 id="-do-not-give-up">‚òëÔ∏è Do not give up</h2>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1595161169170/bb2h4Yg20.gif?auto=format,compress&amp;gif-q=60" alt="hang_in.gif"></p>
<p>It is very easy to begin. It is equally challenging to hang on it without giving up. Most of the beginnings are not overnight things. It takes time. <code>Persistence</code> is the key here. </p>
<p>For example, let's take any skills. A skill takes time to learn, more time to be good at, much more time to be an expert or master.  Don't give up. Keep moving on.</p>
<h2 id="-follow-a-proven-path">‚òëÔ∏è Follow a proven path</h2>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1595161474007/6c4BQNzfk.gif?auto=format,compress&amp;gif-q=60" alt="path.gif"></p>
<p>It is about learning from others and their experiences. One who has completed a journey or left in-between can help others guiding on similar path. Be an information seeker but, not necessarily you need to imitate.</p>
<p>For example, if you are beginning your journey to become a blogger, it makes sense to learn from the journey of other bloggers. How and where the journey began for them? What are the DOs and DON'Ts they have followed? You can always improvise on top of that to make it your own.</p>
<h2 id="-you-are-not-alone">‚òëÔ∏è You are not alone</h2>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1595161923820/ZmUuwkjK-.gif?auto=format,compress&amp;gif-q=60" alt="together.gif"></p>
<p>When you feel challenged, struggling with things to make it work, do not feel that the situation is unique to you. You are really not alone even when it seems so. Look around, ask for help.</p>
<p>Going back to the basics help many times in coming out of a challenging situation. Specially in the areas of skill development. Be part of  a community where you can learn and share. When it comes to the areas of skill development, no better support than a community to make you feel connected.</p>
<h2 id="-being-a-beginner-is-inevitable">‚òëÔ∏è Being a beginner is inevitable</h2>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1595162437794/8eIIBryYV.gif?auto=format,compress&amp;gif-q=60" alt="start.gif"></p>
<p>Yes, this is true! Once a beginner is always a beginner. How? Let me explain.</p>
<p>You began on something, learned it, improved on it and persisted too. Now you are a subject matter expert on it. Are you going to stop with that? No, right? The ever curious mind of yours will find something else, something new to begin. Thus you are a beginner again.</p>

<p>So where to begin? If you are waiting, begin now. Begin with the resources you have in hands. If unsure, ask for help. Once began, stay motivated and do not give up. Good to have inspirations but, work towards making your own mark.</p>
<p>It is not just about where to begin, it is also about how to proceed, what to do and when to end. I would like to conclude this article with another famous motivational quote,</p>
<blockquote>
<p>Never forget that, even the best was once a beginner. Don't be afraid to take that first step to greatness.</p>
</blockquote>

<p>All the cool gifs used in this article are from <a target="_blank" rel="noopener noreferrer" href="https://giphy.com/">https://giphy.com/</a>. The cover photo is from <a target="_blank" rel="noopener noreferrer" href="https://www.freepik.com/free-photos-vectors/school">freepik</a>.</p>
<p>If this article was useful to you, please Like/Share so that, it reaches others as well. To get e-mail notification on my latest posts, please subscribe to my blog by hitting the <strong><em>Subscribe</em></strong> button at the top of the page.</p>
</div></div>]]>
            </description>
            <link>https://blog.greenroots.info/where-to-begin-some-practical-tips-from-a-beginner-ckcu5llil00ncw8s11dr1fh2w</link>
            <guid isPermaLink="false">hacker-news-small-sites-23895553</guid>
            <pubDate>Mon, 20 Jul 2020 07:34:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why GPT-3 Matters]]>
            </title>
            <description>
<![CDATA[
Score 213 | Comments 153 (<a href="https://news.ycombinator.com/item?id=23895481">thread link</a>) | @teruakohatu
<br/>
July 20, 2020 | https://leogao.dev/2020/05/29/GPT-3-A-Brief-Summary/ | <a href="https://web.archive.org/web/*/https://leogao.dev/2020/05/29/GPT-3-A-Brief-Summary/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      
        <!-- TOC -->
        
        <p><img src="https://leogao.dev/images/gpt3/title.png" alt="Number of Parameters of GPT-3 compared to previous models. (<a href='https://www.willstats.com/'>Edited by WillStats</a>, <a href='https://arxiv.org/abs/1910.01108'>Original 1</a>, <a href='https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/'>Original 2</a>)"></p>
<p><span>The sheer scale of the new GPT-3 model</span> is hard to overstate; it‚Äôs an entire <em>order of magnitude</em> larger than Microsoft‚Äôs <a href="https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/" target="_blank" rel="noopener">already-massive 17B parameter Turing-NLG</a>.<sup><a href="#fn1" id="fnref1">[1]</a></sup> Loading the entire model‚Äôs weights in fp16 would take up an absolutely preposterous 300GB of VRAM, not even including the gradients. But, with massive size comes massive generalization ability: GPT-3 is competitive in many benchmarks <em>without even tuning on the target task</em>. And when I say many, I mean <em>many</em>‚Äîthe full, 72-page paper contains an extensive evaluation of GPT-3 on many NLP datasets. Through the <a href="https://openai.com/blog/openai-api/" target="_blank" rel="noopener">OpenAI API</a>, a vast array of impressive demos have sprung up taking advantage of the generalization capabilities of GPT-3 to do extremely disparate tasks. Perhaps the most impressive part, though, is that even at such a massive scale, the model still scales smoothly in performance instead of plateauing, implying that still-larger models would perform <em>even better</em>. Throughout the rest of this post, my goal is to distill this massive (in multiple ways) paper down to a digestible size, and shed some light on why it matters.</p>

<p>The following table summarizes some of the largest autoregressive Transformer models of the past few years. I‚Äôve excluded models like <a href="https://arxiv.org/abs/1906.08237" target="_blank" rel="noopener">XLNet</a> and BERT-derivatives because they don‚Äôt have the same unidirectional autoregressive training target.</p>
<table>
<thead>
    <tr><th></th>
    <th>Parameters</th>
    <th>Layers</th>
    <th>Hidden Size</th>
    <th>Attn Heads</th>
    <th>Attn Head Dimension</th>
    <th>Context Length</th>
</tr></thead>
    <tbody><tr>
        <th><a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf" target="_blank" rel="noopener">GPT</a></th>
        <td>0.110B</td>
        <td>12</td>
        <td>768</td>
        <td>12</td>
        <td>64</td>
        <td>512</td>
    </tr>
    <tr>
        <th><a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" target="_blank" rel="noopener">GPT-2</a></th>
        <td>1.542B</td>
        <td>48</td>
        <td>1600</td>
        <td>25</td>
        <td>64</td>
        <td>1024</td>
    </tr>
    <tr>
        <th><a href="https://arxiv.org/abs/1909.08053" target="_blank" rel="noopener">Megatron-LM</a></th>
        <td>8.3B</td>
        <td>72</td>
        <td>3072</td>
        <td>32</td>
        <td>96</td>
        <td>1024</td>
    </tr>
    <tr>
        <th><a href="https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/" target="_blank" rel="noopener">Turing-NLG</a></th>
        <td>17B</td>
        <td>78</td>
        <td>4256</td>
        <td>28</td>
        <td>152</td>
        <td>1024</td>
    </tr>
    <tr>
        <th><a href="https://arxiv.org/abs/2005.14165" target="_blank" rel="noopener">GPT-3</a></th>
        <td>175.0B</td>
        <td>96</td>
        <td>12288</td>
        <td>96</td>
        <td>128</td>
        <td>2048</td>
    </tr>

</tbody></table>
<p>While GPT-3 isn‚Äôt that much deeper, its width is nearly <strong>3x</strong> that of <a href="https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/" target="_blank" rel="noopener">Turing-NLG</a>, which‚Äîsince parameter count scales approximately proportional to the square of the hidden size‚Äîexplains where most of the extra parameters come from. It also has double the context size, at 2048 tokens, which is impressive (and memory-expensive!), though not the biggest context size across all models; some models have even longer contexts, like <a href="https://arxiv.org/abs/1901.02860" target="_blank" rel="noopener">Transformer-XL</a>, which incorporates longer contexts by passing context vectors between segments, and <a href="https://ai.googleblog.com/2020/01/reformer-efficient-transformer.html" target="_blank" rel="noopener">Reformer</a>, which uses locality-sensitive hashing to enable sparser attention. Similarly, GPT-3 uses <a href="https://arxiv.org/abs/1904.10509" target="_blank" rel="noopener">sparse attention layers</a> in every other layer, though the exact details are left somewhat ambiguous. It‚Äôs also interesting to note that the smaller GPT-3 versions trained for comparison with GPT-2 are slightly shallower and wider, with GPT-3-XL having only 24 layers but a hidden size of 2048.<sup><a href="#fn2" id="fnref2">[2]</a></sup> GPT-3 also reuses the BPE tokenization of GPT-2. Overall, GPT-3 is essentially just a downright massive version of GPT-2.</p>

<p><img src="https://leogao.dev/images/gpt3/tdata.png" alt="Weighted Training Data (<a href='https://arxiv.org/abs/2005.14165'>Source</a>)"></p>
<p>The training data is a reweighted mix of Common Crawl, WebText2 (a larger version of the original that <a href="https://arxiv.org/abs/2001.08361" target="_blank" rel="noopener">also includes links sampled in the period of Jan-Oct 2018</a>), two book corpora, and English Wikipedia. Some of these components, such as Wikipedia, were seen more than 3 times during training; others, like the massive Common Crawl component, had less than half of their data seen. The authors claim that this is to help raise the overall quality of the corpus by prioritising known-good datasets. Also, in contrast to the original WebText, this new corpus is not filtered by language, but English still constitutes 93% of the dataset by words simply due to its prevalence. Altogether, the dataset is 500 billion tokens, or 700GB<sup><a href="#fn3" id="fnref3">[3]</a></sup>, after filtering and cleaning. The paper also provides a detailed description of the filtering process of the dataset, which the GPT-2 paper didn‚Äôt.</p>
<p>The authors also attempted to remove any data that overlapped with the train and test sets of the evaluations. Unfortunately, due to a bug, some were missed, so to compensate the paper provides a fairly good analysis of the impact of this leakage.</p>

<p><img src="https://leogao.dev/images/gpt3/perf-small.png" alt="Zero-, One-, and Few-shot performance of GPT-3 scaling with parameter count (<a href='https://arxiv.org/abs/2005.14165'>Source</a>)"></p>
<p>The Evaluation section of GPT-3 is very comprehensive, evaluating on a massive battery of NLP tasks in the Zero-shot (given only a natural language description in the generation context), One-shot (a single example in the generation context), or Few-shot (a small handful of examples in the generation context) settings. This setting is worth emphasizing as perhaps one of the biggest differences in ability between GPT-2 and its predecessors, because being able to <em>infer the task</em> from just one or a few examples is a massive step forward in generalization. Whereas previous models all relied on task-specific tuning, GPT-3 can be ‚Äútuned‚Äù merely by giving it instructions <em>in plain English</em>! In fact, the paper doesn‚Äôt even attempt to fine-tune on the target task, leaving that to future work.<sup><a href="#fn4" id="fnref4">[4]</a></sup> However, one crucial conclusion is that in almost all tests, performance continues to get better with larger models, even across 4 entire orders of magnitude, whereas fine-tuning only improves on one task and <a href="https://arxiv.org/pdf/1901.11373.pdf" target="_blank" rel="noopener">risks catastrophic forgetting and overfitting</a>.</p>
<p>Without going too much into the individual tests, the general result is this: on most tasks, GPT-3 achieves performance significantly worse than fine-tuned SOTA (i.e SuperGLUE, CoQA, Winograd, to name a few), but beating fine-tuned SOTA for some other tasks (i.e PhysicalQA, LAMBADA, Penn Tree Bank). GPT-3 does particularly well on PTB in particular, taking the SOTA perplexity from 35.76 down to 20.5‚Äîa massive improvement. GPT-3 can also finally do some arithmetic, something GPT-2 was unable to do well.<sup><a href="#fn5" id="fnref5">[5]</a></sup></p>
<p><img src="https://leogao.dev/images/gpt3/newsgen-small.png" alt="People are unable to separate GPT-3 generated news articles from real ones (<a href='https://arxiv.org/abs/2005.14165'>Source</a>)"></p>
<p>Impressively, and perhaps somewhat alarmingly, people are unable to distinguish GPT-3 generated news stories from real ones, only exacerbating the ethical concerns already raised by GPT-2. The paper analyzes the result of the release of GPT-2, and concludes that the release of GPT-2 has not led to widespread use of LMs for misinformation due to the difficulty of controlling output and variance in output quality, both among low-to-mid skill adversaries and ‚Äúadvanced persistent threats‚Äù‚Äîadversaries with ‚Äúhigh skill and long-term agendas‚Äù‚Äîsuch as state actors. However, the paper also acknowledges that with further development, LMs will eventually become advanced enough for these adversaries.</p>
<p>The authors also investigate gender bias in GPT-3, showing that GPT-3 is male leaning; however, the authors claim that some preliminary evidence on the Winogender dataset (which tests coreference resolution on the same sentence but with different gendered pronoun) seems to suggest that larger models are more robust to bias issues. Similar issues appeared for race and religion, with the sentiment of co√∂ccurrent terms varying significantly with race. The authors claim that this issue also got better with the larger models‚Äîalthough, without proper hypothesis testing, it‚Äôs difficult to draw any solid conclusions here.</p>

<p>GPT-3 has already been used for a smorgasbord of different applications through the OpenAI API. You can ask it to <a href="https://twitter.com/sharifshameem/status/1282676454690451457" target="_blank" rel="noopener">write</a> <a href="https://twitter.com/hturan/status/1282261783147958272" target="_blank" rel="noopener">code</a>, turn <a href="http://vimeo.com/427943407/98fe5258a7" target="_blank" rel="noopener">natural language commands into shell commands</a>, and simulate <a href="https://www.aiwriter.email/" target="_blank" rel="noopener">chatting with famous people</a>. You can ask it to <a href="https://twitter.com/QasimMunye/status/1278750809094750211" target="_blank" rel="noopener">answer medical questions</a>, or <a href="https://www.gwern.net/GPT-3#navy-seal-copypasta" target="_blank" rel="noopener">write parodies of the navy seal copypasta</a>. You can ask it to <a href="https://andrewmayneblog.wordpress.com/2020/06/13/openai-api-alchemy-summarization/" target="_blank" rel="noopener">summarize passages for second graders</a>, or <a href="https://www.gwern.net/GPT-3#transformer-poetry" target="_blank" rel="noopener">write poetry</a>.</p>
<p>It‚Äôs important to remember all these are done by the <em>exact same model</em> trained <em>only</em> on modelling text; all that‚Äôs different is that it has been ‚Äúasked nicely‚Äù to do different things. These apps showcase the versatility of GPT-3 across many disparate domains‚Äîsomething that, if it were done with GPT-2, would require days or even weeks of extensive data engineering and fine tuning, rather than 15 minutes of prompt crafting. This new paradigm of programming through crafting plain-English prompts, jokingly dubbed <a href="https://twitter.com/karpathy/status/1273788774422441984" target="_blank" rel="noopener">‚ÄúSoftware 3.0‚Äù</a>, has achieved results that are already impressive, but even more impressive when viewed through the lens of <strong>generalization</strong>; GPT-3 wasn‚Äôt trained to do any of these things in particular, but it could still be asked<sup><a href="#fn6" id="fnref6">[6]</a></sup> to do them, and fairly well at that!</p>

<p><img src="https://leogao.dev/images/gpt3/perf_scaling_compute.png" alt="Performance continues to scale with compute. (<a href='https://arxiv.org/abs/2005.14165'>Source</a>)"></p>
<p>But why does GPT-3 matter, if it can‚Äôt even beat SOTA across all benchmarks? Why should we care about a model so large that a small computing cluster is necessary even just to run inference at a reasonable speed?</p>
<p>One thing about GPT-3 is that it‚Äôs doing reasonably well on tasks it has <em>never even seen</em>, and sometimes tasks not even anticipated by the developers of the model. Additionally, instead of reaching a point of diminishing returns, GPT-3 shows that the trend of larger models performing better continues for at least another order of magnitude, with no signs of stopping. Even though GPT-3 is unwieldy, and even though it still doesn‚Äôt quite reach human level performance across the board, GPT-3 shows that it‚Äôs <em>possible</em> for a model to someday reach human levels of generalization in NLP‚Äîand once the impossible becomes possible, it‚Äôs only a matter of time until it becomes practical.</p>
<hr>
<section>
<ol>
<li id="fn1"><p>Back when I talked about <a href="https://leogao.dev/2019/10/27/The-Difficulties-of-Text-Generation-with-Autoregressive-Language-Models/">large Transformer language models like GPT-2, CTRL, and Megatron-LM late last year</a>, I touched briefly on the trend of Language Models getting bigger, and covered some of the issues that simply more compute might not fix. My general anticipation was that the model size arms race would soon be at a temporary standstill, with focus being diverted to better decoding strategies for text generation (perhaps via RL-based methods). I most certainly had not expected that OpenAI would be back at it so soon with such a massive model.</p>
<p>This was such a surprise that I dropped everything to read the paper and work on this post, including a more theory-oriented post that I‚Äôve been working on for a few months now. It will probably be finished <span>soon‚Ñ¢</span>, after I recover from GPT-3 shock. Stay tuned! <a href="#fnref1">‚Ü©Ô∏é</a></p>
</li>
<li id="fn2"><p>It‚Äôs likely that this was done for easier model parallelism‚Äîbigger matrix multiplications are much easier to parallelize than sequentially-applied layers √† la <a href="https://arxiv.org/abs/1811.06965" target="_blank" rel="noopener">GPipe</a>.</p>
<p>This could have other advantages too, though. After <a href="https://arxiv.org/abs/1905.11946" target="_blank" rel="noopener">EfficientNet</a> came out, I independently ran some experiments of the same concepts to Transformer models, and the result was that for the same amount of compute, wider models had a sizeable advantage over deeper ones‚Äîwhich corroborates the choice here to ‚Ä¶</p></li></ol></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leogao.dev/2020/05/29/GPT-3-A-Brief-Summary/">https://leogao.dev/2020/05/29/GPT-3-A-Brief-Summary/</a></em></p>]]>
            </description>
            <link>https://leogao.dev/2020/05/29/GPT-3-A-Brief-Summary/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23895481</guid>
            <pubDate>Mon, 20 Jul 2020 07:21:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clarity. It Makes a Difference]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23895275">thread link</a>) | @liveweird
<br/>
July 19, 2020 | https://no-kill-switch.ghost.io/clarity-it-makes-a-difference/ | <a href="https://web.archive.org/web/*/https://no-kill-switch.ghost.io/clarity-it-makes-a-difference/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-post-id="5f12c9b566878f0039548a50">
	

	<section>
		<p>Picking your next professional endeavor ain't easy. There's plenty of advice regarding that on the Internet. Usually, this topic is covered from junior's perspective - how to choose your first job, what to avoid, what kind of questions to ask first, etc. But in fact, it appears that seasoned veterans have similars dilemmas - once in a while some old acquaintance asks me for help in determining the next professional career step:</p><ul><li>which companies (in the area) are worth of interest?</li><li>who offers enough of a challenge so that one could fulfill her/his ambitions?</li><li>where could one elevate her/his game, instead of regressing the skillset?</li></ul><p>Obviously - there's no single answer that would fit everyone. It depends on one's motivations, preferred collaboration model, ambition level, even personal ethics. Nevertheless, I've merged all those questions for the sake of providing the most valuable advice:</p><blockquote>Of all companies (/teams) I've worked for in the last couple of years, which collaborations brought me most satisfaction, fulfillment &amp; ... fun? And what's more important: what was <strong>the single factor</strong> this joint positive impression was mostly dependent on?</blockquote><p>The answer (a single word) may sound surprising, but it came up naturally. Few months ago, I noticed I keep using this word more and more in my daily conversations.</p><p>This word is ...</p><p>Huh? But what do I mean by "clarity"? A "clarity" of what?</p><p>Let's call it <strong>a clarity of "work context"</strong>.</p><p>Which means a joint clarity ...</p><ul><li>... of vision (to follow, aka a strategic perspective)</li><li>... of goals (to achieve) / or problems (to beat, aka a tactical perspective)</li><li>... and of what I'm going to do tomorrow (to have things progressing, aka operational perspective).</li></ul><p>Just to be clear: when I mention "goals", it's NOT just about having some goals listed on a scrap of paper. It's about truly <strong>understanding &amp; embracing</strong> them, so even if (at this point in time) you don't know how to achieve them, you at least have the clarity of how/where to start.</p><p>What happens when ...</p><p><br>People drift. Focus gets lost. Positive energy gets wasted. Chaos lurks underneath. We shift from being paid for meaningful results (because we don't understand/foresee those results) to being paid for "time spent in work" - which is a real motivation &amp; ownership killer.</p><p>In fact, clarity appears to be (in practice) fair compensation for various inconveniences - like dealing with an outdated tech stack or organizational debt (of any kind).</p><p>What could cause clarity to get lost? Lack of transparency (e.g., failing to shape a big picture accessible for everyone), miss-communications, neo-feudal hierarchies (and other kinds of knowledge/control siloes), diverging, inconsistent or too unstable priorities, lack of internal focus &amp; delivery discipline (e.g., shitty prioritization), poor value management (everything is critical!), micro-management with a pathological lack of trust, ... and so it goes.</p><p><br>Paradoxically, these days it isn't easy to find a company w/o a written vision, mission statement or striking strategic goals. Unfortunately, they are usually very poorly defined. Take "digital transformation", which appears in every 2nd company's nearest plans - it's so vague and ambiguous that it practically means NOTHING. Who would die for it? Who would get motivated by "digitally transforming"? To be frank, such statements typically ... reduce the clarity, instead of improving it.</p><p>I strongly believe in individuals taking ownership and being able to make a difference - the initiative can come from anywhere, either from the "bottom" or the "top". However, when it comes to clarity in particular, I find it as majorly leaders' responsibility. It's a part of their professional credibility. What we expect of a leader is:</p><ul><li>to understand where we are</li><li>to know where we're heading</li><li>to have (a visible) confidence we can get there</li><li>to convince everyone else it's feasible and within reach</li></ul><p>There's no excuse - someone w/o clarity AND the ability to "infect" others with that clarity simply can't be a credible leader.</p>
	</section>

	
</article></div>]]>
            </description>
            <link>https://no-kill-switch.ghost.io/clarity-it-makes-a-difference/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23895275</guid>
            <pubDate>Mon, 20 Jul 2020 06:45:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Please Stop Writing So Much Code]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23895273">thread link</a>) | @dvt
<br/>
July 19, 2020 | https://dvt.name/2020/07/20/please-stop-writing-so-much-code/ | <a href="https://web.archive.org/web/*/https://dvt.name/2020/07/20/please-stop-writing-so-much-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<!-- .site-header -->	<div>
		<div><main id="content" role="main" itemprop="mainEntityOfPage" itemscope="itemscope" itemtype="http://schema.org/Blog">
			<article id="post-1587" itemscope="itemscope" itemtype="http://schema.org/BlogPosting" itemprop="blogPost"><div>
			<!-- .entry-header -->		
	<div itemprop="articleBody">
<p>Everywhere I‚Äôve worked, there‚Äôs a hidden (and sometimes not-so-hidden) expectation that code constantly get pushed out. Code not being pushed is a red flag. Make sure you take no longer than a week for a Jira ticket or a Github issue. Have you been taking longer than a week? Expect to get pinged on Slack:</p>
<blockquote><p>
<strong>your-friendly-project-manager</strong>: Hey, how‚Äôs it going with ABCD-123, need any help?
</p></blockquote>
<p>And, I get it: that‚Äôs the PM‚Äôs job. But I‚Äôm also trying to do <em>my</em> job: not just writing code, but writing <em>good</em> code.</p>
<h2>An AGILE Trojan horse</h2>
<p>If you bring up evaluating programmers based lines-of-code these days, most people agree it‚Äôs archaic and ineffective, but lines of code are back, you see: it‚Äôs called <em>velocity</em>. ‚ÄúAre you happy with your velocity?‚Äù an engineering lead might ask you. ‚ÄúWe should work on our velocity‚Ä¶‚Äù a product manager might balk.</p>
<p><img src="http://dvt.name/wp-content/uploads/2020/07/velocity.png" alt="Are you happy with your velocity?" width="482" height="401" srcset="https://dvt.name/wp-content/uploads/2020/07/velocity.png 482w, https://dvt.name/wp-content/uploads/2020/07/velocity-300x250.png 300w" sizes="(max-width: 482px) 100vw, 482px"></p><p>Velocity is another (more polite and trendy) way of essentially evaluating programmers on how much code they write. And this has all the implications you might imagine. ‚ÄúVelocity,‚Äù <a href="https://www.scruminc.com/velocity/" rel="noopener" target="_blank">according to Scrum Inc.</a>, is:</p>
<blockquote><p>Velocity is a measure of the amount of work a Team can tackle during a single Sprint and is the key metric in Scrum. Velocity is calculated at the end of the Sprint by totaling the Points for all fully completed User Stories. [‚Ä¶] Velocity is a key feedback mechanism for the Team. It helps them measure whether process changes they make are improving their productivity or hurting it. While a Team‚Äôs velocity will oscillate from Sprint to Sprint, over time, a well-functioning Scrum Team‚Äôs velocity should steadily trend upward by roughly 10% each Sprint.</p></blockquote>
<p>We can ignore the downright ridiculous idea that efficiency should trend +10% <em>ad infinitum</em>, but level of effort (and therefore the point mechanism) will often involve how much code ‚Äî and implicitly how difficult ‚Äî a particular feature might be. What velocity ignores is one key element of writing good code and building good products: <em>thinking</em>.</p>
<h2>Using your brain</h2>
<p>A lot of times, thinking about <em>how</em> to build something is harder and more time consuming than actually building it. This might seem like unnecessary meta-cognition, but it‚Äôs not: even before writing a paper, you might need to write up an outline. An outline might turn into a rough draft. After a few edits, the draft turns into the final product. Software is very similar, but that‚Äôs not how we build it.</p>
<p>Instead, we build features that are stuck to other features using duct tape and superglue. Sometimes, we have fancy names for shoddy software: we‚Äôre building <em>microservices</em>, guy! No one has time for refactoring or cleanup. Unit testing? We‚Äôll throw those in the backlog; they‚Äôre not high priority. Inevitably something breaks, a customer complains, and we‚Äôre off to the races: who‚Äôs on call this week? Good luck.</p>
<p>After more than a decade working at software companies, I‚Äôll be the first to admit that I‚Äôm part of the problem. I don‚Äôt push back anymore, and I‚Äôve conceded more times that I can count. I <em>know</em> we‚Äôre building bad software, but everyone else is doing it, too.</p>
<h2>How much is too much?</h2>
<p>Why is this happening? It‚Äôs just too much darn code. Too much code to read over, too much code to review, too many pull requests. It takes <em>time</em> to mull over questions like:</p>
<ul>
<li>Is this the best way to do this?</li>
<li>What are the trade-offs between doing it this way or that way?</li>
<li>Should we re-architect part of the code to accommodate this new feature?</li>
</ul>
<p>In fact, these questions tend to wax creative, and not technical. But I‚Äôve never seen a Jira ticket entitled ‚ÄúPonder over proposed architecture‚Äù or ‚ÄúThink about better ways one might implement this.‚Äù Do the tests look like they‚Äôre passing? LGTM, merging ‚úîÔ∏è</p>
<p>Don‚Äôt just write code quickly; write code <em>well</em>. And please stop writing so much of it.</p>
	
	</div>
		</div></article>				
	
</main><!-- .content -->
		</div>	</div><!-- .site-inner -->
	<!-- .site-footer --></div></div>]]>
            </description>
            <link>https://dvt.name/2020/07/20/please-stop-writing-so-much-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23895273</guid>
            <pubDate>Mon, 20 Jul 2020 06:44:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Video Vectorization]]>
            </title>
            <description>
<![CDATA[
Score 305 | Comments 116 (<a href="https://news.ycombinator.com/item?id=23895211">thread link</a>) | @xanthine
<br/>
July 19, 2020 | https://vectorly.io/docs/technology/ | <a href="https://web.archive.org/web/*/https://vectorly.io/docs/technology/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

<p><img src="https://vectorly.io/docs/img/vector-graphics.png" alt="Drawing"></p>

<p>Vectorly is developing a new kind of video compression technology, which uses computer vision and vector graphics to reduce bitrates for video content by an order of magnitude (or more) compared to HEVC, while <strong>improving video</strong> quality. </p>
<p>This would be primarily effective for "vector friendly" video content, which would include animations, screen-casts, many e-learning videos and potentially 3d gaming content. </p>
<p>By leveraging existing vector-graphics rendering capabilities on all devices, this codec wouldn't require end-users, OEMs or browsers to install special software to enable playback of these videos.</p>
<p><strong>We are still in the early phases of developing this technology</strong>.</p>
<p>You can learn more about the technology in our <a href="https://files.vectorly.io/Vectorization+Whitepaper+v06.20.pdf">whitepaper</a></p>
<h2 id="the-core-idea">The Core Idea</h2>
<p>The core insight behind this project was that you could use vector-graphics based animations to simulate "videos" in a way that is indistinguishable from a traditional raster-graphics based video format such as an h264 video stream in an MP4 container.</p>
<h3 id="raster-graphics">Raster Graphics</h3>
<p>Normal videos, like the ones you see on Netflix or YouTube, are just sequences of images which get updated quickly on the screen, to create the illusion of motion. Each image is composed of "pixels" - individual dots of color. Higher resolution means more pixels, better visual quality, and bigger file sizes.</p>
<p><img alt="Pixel-Based" src="https://vectorly.io/docs/img/pixels.png"></p>
<p>Almost all video on the internet is of this format, known as "raster graphics". Video compression algorithms like h264 are just very efficient at using fewer data-points to reconstruct the pixels in any given frame, and at storing only the differences in pixels between frames of a video. </p>
<h3 id="vector-grapics-video">Vector Grapics video</h3>
<p>In contrast, we use a concept called "vector-graphics" to render video. Instead of pixels, we represent everything on the screen using shapes, lines and curves, which can be represented as mathematical equations (vector graphics).</p>
<p><img alt="Vector-Based" src="https://vectorly.io/docs/img/vector2.png"></p>
<p>Using these mathematical equations, we can re-draw any arbitrary shape on the screen - from the letter "T" to Bart Simpson's head. Furthermore, by adding information such as color, position on the screen, and how they move or change shape over time, you can create whole videos - including entire episodes of the Simpsons, with just sequences of mathematical equations.</p>
<h3 id="why-vectorization">Why vectorization?</h3>
<p>The core insight behind this project was that for a certain kind of "vector-friendly" video content, storing the video using vector graphics would be much more efficient than using raster graphics (in some cases, up to 2 orders of magnitude more efficient).</p>
<p>This idea is not substantively different from the idea of Flash based animations about 20 years ago. Why do this now?</p>
<p><strong>No need for a decoder</strong>: Most devices now support SVG, HTML5, WebGL/OpenGL and/or some form of hardware-accelerated vector-graphics rendering. That lets you render vector-graphics content on any device without require end-users, OEMs or browsers to install special software to enable playback of vector-graphics content, and to achieve native-level performance by doing so. App developers would only need to include an appropriate library or SDK in their website or app to enable playback within native or 3rd player video players.</p>
<p><strong>Computer vision</strong>: Our patented vectorization technology relies heavily on computer vision to convert raster-graphics videos to a vector format. Leveraging the advancement &amp; commoditization of Computer Vision, and the ease of running batch computer-vision heavy tasks on the cloud, it's feasible to 'vectorize' large volumes of video at scale now, in a way that wasn't possible even 5 years ago.</p>
<h3 id="vector-graphics-video-format">Vector graphics video format</h3>
<p>We are building a video-format based on existing standards (SVG, WebGL &amp; OpenGL), extending it with Javascript to enable video features such as a timeline and key-frames. We package the resulting video data within an MP4 container, which can be streamed and distributed using existing video infrastructure (such as HLS/DASH, and DRM systems).</p>
<pre><code>&lt;video src="vectorized.mp4" type="video/svg"&gt;
</code></pre>
<p>We are pragmatic, and don't want to create a standard <a href="https://xkcd.com/927/">for the sake of creating a standard</a>.  To that end, we've created libraries and SDKs that enable playback of our vector-graphics videos using standard / native interfaces like so</p>
<pre><code>&lt;script src="vectorly.js"&gt;

&lt;video src="vectorized.mp4" type="video/svg"&gt;
// This will work on all major browsers today
</code></pre>
<h2 id="demos-proof-of-concept">Demos / Proof of concept</h2>
<p><strong>Simpsons</strong></p>
<p>Our first vectorized proof of concept for animations is a 17 second clip of the Simpsons located <a href="https://files.vectorly.io/demo/v0-2-simpsons-250kbps/index.html">here</a>. Keep in mind, our technology is still at a very early stage, and this is much optimization work left to be done.</p>
<p><strong>Khan Academy</strong></p>
<p>Our technology also works very well for e-learning, and especially Khan Academy style content. You can find 30 second Khan Academy clip <a href="https://files.vectorly.io/demo/khan-20kbps/index.html">here</a></p></div></div>]]>
            </description>
            <link>https://vectorly.io/docs/technology/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23895211</guid>
            <pubDate>Mon, 20 Jul 2020 06:30:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In Praise of ZFS on Linux's ZED 'ZFS Event Daemon']]>
            </title>
            <description>
<![CDATA[
Score 148 | Comments 116 (<a href="https://news.ycombinator.com/item?id=23894790">thread link</a>) | @zdw
<br/>
July 19, 2020 | https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSZEDPraise | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSZEDPraise">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>In praise of ZFS On Linux's ZED 'ZFS Event Daemon'</h2>

	<p><small>July 19, 2020</small></p>
</div><div><p>I've written before (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSameness">here</a>) about how <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSetupIII">our
current Linux ZFS fileservers</a> work much
like <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSFileserverSetupII">our old OmniOS fileservers</a>.
However, not everything is quite the same between ZFS on Linux and
traditional Solaris/OmniOS ZFS. One of the most welcome differences
for us is <a href="https://zfsonlinux.org/manpages/0.8.4/man8/zed.8.html">ZED</a>,
the ZFS Event Daemon. What ZED does that is so great is that it provides
a very simple way to take action when <a href="https://zfsonlinux.org/manpages/0.8.4/man5/zfs-events.5.html">ZFS events</a> happen.</p>

<p>When a ZFS event happens, ZED looks through a directory (generally
<code>/etc/zfs/zed.d</code>) to find scripts (or programs) that should be run
in response to the event. Each script is run with a bunch of
environment variables set to describe what's going on, and it can
use those environment variables to figure out what the event is.
ZED decides what things to run based on their names; generally you
wind up with script names like <code>all-cslab.sh</code> (which is run on
all events) and <code>resilver_finish-cslab.sh</code> (which is run when a
resilver finishes).</p>

<p>Because these are just a collection of individual files, you're
free to add your own without colliding with or having to alter the
standard 'ZEDLETs' provided by ZFS on Linux. Your additions can do
anything you want them to, ranging from the simple to the complex.
For instance, our simplest ZEDLET simply syslogs all of the ZED
environment variables:</p>


<blockquote><pre>PATH=/usr/bin:/usr/sbin:/bin:/sbin:$PATH
export PATH
if [ "$ZEVENT_SUBCLASS" = "history_event" ]; then
        exit 0
fi
unset ZEVENT_TIME
unset ZEVENT_TIME_STRING
printenv | fgrep 'ZEVENT_' | sort | fmt -999 |
    logger -p daemon.info -t 'cslab-zevents'
exit 0
</pre>
</blockquote>

<p>(There's a standard 'all-syslog.sh' ZEDLET, but it doesn't syslog
all of the information in the zevents. Capturing all of the information
is especially useful if you want to write additional ZEDLETs and
aren't quite sure what they should look for or what environment
variables have useful information.)</p>

<p>It can take a bit of time and experimentation to sort out what ZFS
events are generated (and with what information available) in
response to various things happening to adn in your ZFS pools. But
once you have figured it out, ZED gives you a way to trigger and
drive all sorts of system management activities. These can be active
(like taking action if devices fail) or passive (like adding markers
in your metrics system or performance dashboards for when ZFS scrubs
or resilvers start and end, so you can correlate this with other
things happening).</p>

<p>Coming from Solaris and OmniOS, where there was no such simple
system for reacting to things happening in your ZFS pools, ZED was
a breath of fresh air for us. More than anything else, it feels
like how ZFS events should have been handled from the start, so
that system administrators could flexibly meet their own local needs
rather than having to accept whatever the Solaris Fault Management
system wanted to give them.</p>

<p>PS: Because ZFS on Linux is now OpenZFS, I believe that ZED will
probably eventually show up in FreeBSD (if it isn't already there).
Perhaps it will even some day be ported back to Illumos.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSZEDPraise</link>
            <guid isPermaLink="false">hacker-news-small-sites-23894790</guid>
            <pubDate>Mon, 20 Jul 2020 05:03:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self Hosting Email Server]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 24 (<a href="https://news.ycombinator.com/item?id=23894411">thread link</a>) | @g-garron
<br/>
July 19, 2020 | https://www.garron.blog/posts/host-your-email-server.html | <a href="https://web.archive.org/web/*/https://www.garron.blog/posts/host-your-email-server.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <h2 id="introduction">Introduction</h2>

<p>In 1998 at my first job, I was the system administrator of the biggest Internet provider in Bolivia, it still is the biggest provider. The Internet arrived here in 1995 or 1996, so it was just starting.</p>

<p>I was in charge of BGP routers, with a satellite connection to the Internet, the whole country had just 2 mbps of connection back in those days. I was also in charge of the email server, (roble.scz.entelnet.bo), the DNS server run on a Unix machine while the email and web server on a RedHat Linux powered PC.</p>

<p>Fast forward to 2001, I started my own company, it had nothing to do with system administration, but anyway we needed email service, so I just got an on-line channel with a /28 public IP segment, and setup a CentOS server running bind, sendmail, Dovecot.</p>

<p>In 2007, I started blogging on Drupal running on that same server using Apache, PHP and MySQL <a href="https://www.garron.me/en/go2linux/fedora-centos-root-password-recovery.html">here the first post</a>. I was used to host services.</p>

<h2 id="changes">Changes</h2>

<p>But then I had less time in my hands, it was also more difficult to maintain the services running, keeping up to date with Spam filters and rules became difficult, Bind also had its problems, and Slashdot happened and Bandwidth was not enough.</p>

<p>I moved my server to a web hosting company, and then to a Linode VPS, I also outsourced the DNS service and moved the email to Google Apps.</p>

<p>I migrated my old server to Debian and used it just for:</p>

<ul>
  <li>DHCP</li>
  <li>NAT</li>
  <li>DNS Cache</li>
  <li>Squid</li>
</ul>

<p>That was in 2010 more or less, so I stopped hosting my services, only my blog was in my hands, but at that time I started using Jekyll, so it was just a VPS with Nginx.</p>

<h2 id="back-on-hosting-my-own-services">Back on Hosting my own services</h2>

<p>In April this year I started this blog, but I also enrolled in the Fediverse, and decided to <a href="https://www.garron.blog/posts/my-own-mastodon-server.html">run my own instance</a>, therefore I was hosting again, that was not just a NGINX server, then I read <a href="https://yarmo.eu/post/selfhost-email">this</a>, <a href="https://yarmo.eu/post/selfhost-email-drawbacks">this</a> and <a href="https://lazybear.io/posts/should-you-sefhost-your-email/">this</a>.</p>

<p>And the idea of running my services was in my head again. I wanted to do it different with time, it is not 1998 anymore, so I decided to learn about <a href="https://www.garron.blog/posts/dockerize-everything.html">Docker</a>. So now I have in just one Arch Linux server:</p>

<ul>
  <li>Two static sites</li>
  <li>One Wordpress Site</li>
  <li>One RSS reader (Miniflux)</li>
  <li>One password manager app (Bitwarden)</li>
  <li>One read-later app (<a href="https://www.garron.blog/posts/wallabag-review.html">Wallabag</a>)</li>
  <li>One Webmention app <a href="https://zerokspot.com/weblog/2020/06/14/setting-up-webmentiond/">Webmentiod</a></li>
</ul>

<p>All running with Docker Compose files, but there was something missing, it was email. (Mastodon has its own server -yet-)</p>

<h2 id="hosting-your-own-email-server">Hosting your own email server</h2>

<p>I wanted to run an email server on Docker, so I looked for alternatives and I have found that there are some really nice.</p>

<h3 id="posteiohttpsposteio"><a href="https://poste.io/">Poste.io</a></h3>

<p>I have not tested it, but seems really easy to deploy it has a free version that I think is enough for personal use, with two professional options with a monthly charge.</p>

<h3 id="mailuiohttpsmailuio"><a href="https://mailu.io/">Mailu.io</a></h3>

<p>It is a clone of Poste.io, but using only free, Open Source alternatives, I have installed and configured, it took me just 45 minutes to have server running for one of my domains. It has a tool that create a configuration file based on your options, and it set up everything for you, you can find it <a href="https://setup.mailu.io/1.7/">here</a>, you only need to answer a few questions, and run three or four commands and there you have a complete email server.</p>

<ul>
  <li>SMTP</li>
  <li>IMAP</li>
  <li>POP3</li>
  <li>AntiSpam</li>
  <li>AntiVirus</li>
  <li>Webmail</li>
  <li>Admin web front-end</li>
</ul>

<p>Really a great option, I recommend it to anyone.</p>

<h3 id="docker-mail-serverhttpshubdockercomrtvialdocker-mailserver"><a href="https://hub.docker.com/r/tvial/docker-mailserver">Docker Mail Server</a></h3>

<p>Then I found this one, it is also a complete suite, all Open Source, with really good documentation, and ready to deploy on a server with Docker. It is not as easy as Mailu, but I decided to use it. I followed <a href="https://github.com/tomav/docker-mailserver/wiki/Installation-examples">this guide</a>, yes I know, you still need Gmail or any other provider to send your emails, if you follow that guide. But I was not ready to jump into the pool completely.</p>

<p>So, here is my setup:</p>

<ul>
  <li>MX record points to my server, so all my email is received by my server</li>
  <li>All email is then forwarded to other accounts (Gmail accounts in this case)</li>
  <li>Gmail is configured to use those accounts as default and not the Gmail address, and uses my SMTP server to send</li>
</ul>

<p>This way I am sure I am using my domain, because we already agreed that <a href="https://www.garron.blog/posts/own-your-domain.html">everybody should own his domain</a>, right?. I am using Gmail as my email client.</p>

<p>I am doing this way, because it is easy to search emails when they are with Gmail, also because I am not sure if I may lose my server and lose some important email. I need to be sure about that, because I am hosting for my family, not only for me.</p>

<p>Also having an IMAP client on a cell phone drains the battery, because it polls the server even when there is nothing to download, or if you keep an open IMAP IDLE connection, it will also drain the battery. There is a solution for that, you need <a href="https://pushover.net/">PushOver</a>, and this <a href="https://pushover.net/">IMAP to PushOver</a> app, I have not tested yet, but I think is the way to go.</p>

<p>Edit: After reading some comments on Reddit, these three other options seems to be good ones too.</p>

<ul>
  <li>
    <p><a href="https://mailcow.email/">MailCow</a>: Is another good option also mentioned on HN comments, and this one do have official Docker documentation <a href="https://github.com/mailcow/mailcow-dockerized">here</a></p>
  </li>
  <li>
    <p><a href="https://mailinabox.email/">Mail in a Box</a>: Although there are not official instructions to install it on Docker, it should be possible, here is an <a href="https://hub.docker.com/r/mtrnord/mailinabox/">outdated attempt</a>, and here <a href="https://discourse.mailinabox.email/t/mail-in-a-box-in-docker/4588">another one</a>. But on a VPS it seems work great, and the admin pannel guides you.</p>
  </li>
  <li>
    <p><a href="https://iredmail.org/">iRedMail</a>: This one is also a good option, I have test it two months ago for a week and also works out of the box, you can find a well maintained docker instructions <a href="https://hub.docker.com/r/lejmr/iredmail">here</a></p>
  </li>
</ul>

<h2 id="things-to-consider">Things to consider</h2>

<p>If you plan to host your own email server, there are some important things you need to consider, and it is to properly configure your DNS server. Here is what you need:</p>

<h3 id="spf-record">SPF record</h3>

<p>You really need to configure a SPF record, it is not the same with all providers, but there is plenty of documentation, and it is not hard to do. This record basically tells the recipient server who is authorized to send mail on behalf of your domain. The most common configuration is that the MX server are the authorized ones, something like this.</p>

<pre><code>v=spf1 mx ~all
</code></pre>

<h3 id="dkim-record">DKIM record</h3>

<p>This one is a little bit more difficult, you need to create the DKIM key, your email server may do it, all examples above can do it, once you have it, you need to create a TXT record on your DNS and paste it there, it will look something like this:</p>

<pre><code>v=DKIM1; h=sha256; k=rsa; p=MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEArARSBHTh32y3VpSEe+pOI7AuILCUsYw1FNL5vTu1P3Mpte50jjkvzg+pBndcSzndQDt6B6mqLBbTwWrZR/j73CTI4ejcYL+xqSXYPU8+xNwu5uwHOMsgWMl15Z/1e1QJD9Ss3Q8aOLOkvHNIgAfSCq
</code></pre>

<p>All your emails will be signed with that, DKIM key, and the receiving server can check if the signature is valid, using the info from the DNS.</p>

<h3 id="dmarc-record">DMARC record</h3>

<p>This one is optional, but is better to have it, you can generate it using on-line tools like <a href="https://mxtoolbox.com/DMARCRecordGenerator.aspx">this one</a>. What it does is to tell what to do when something fails, and who to report that, usually the server admin, well you.</p>

<h3 id="ptr-record">PTR Record</h3>

<p>You need to have a PTR DNS records, that is the reverse DNS for the IP your server is using should point to the same name the A record has. So, for example, if you have this A record</p>

<pre><code>IN A mail.server.com 192.168.0.1
</code></pre>

<p>There should also be a reverse record like this.</p>

<pre><code>IN PTR 192.168.0.1 mail.server.com
</code></pre>

<p>You need to ask to the owner of the IP to add that record for you, if you are using a VPS, you can look in the documentation about that.</p>

<h3 id="mx-record">MX record</h3>

<p>Of course you need a MX record, but you already knew about this one, otherwise maybe is not a good idea to run your own server. This basically informs al sending servers which server is receiving email for your domain.</p>

<h3 id="test">Test</h3>

<p>Once you have set-up everything, wait 24 hours for DNS to propagate and test it, <a href="https://www.mail-tester.com/">this tool</a> is great</p>

<h3 id="secondary-mail-server">Secondary mail server</h3>

<p>Edit 2:</p>

<p>After <a href="https://lobste.rs/s/iatbst/how_self_host_your_email_server#c_hc7vvv">this comment</a> I want to add this recommendation too.</p>

<p>When the main server is down, email can not be delivered, usually it just stays in the senders queue, and once your server is up again all email is delivered to it, but if the outage is long enough some email might be returned to senders and the users will lose them.</p>

<p>The way to avoid this is to have a second machine running a secondary email server, this is simplier to setup, as it will only have the function to store email while the main server is down, and send all emails to it once is up again. There are some good documentation out there, <a href="https://www.howtoforge.com/postfix_backup_mx">here</a> and <a href="https://www.linuxbabe.com/mail-server/how-to-set-up-a-backup-email-server-postfix-ubuntu">here</a>.</p>

<p>The drawback is that now you have a second email to upgrade and keep running, and Spammers ususally target at it, so if you have backups for the main server, and you consider you can have it up and running relatively fast you can avoid a second email. One should also consider who's email is being hosted at the server, and how critical is that email for them.</p>

<p>Critical email might be on an Office 365 <strong>Exchange Online (Plan 1)</strong>, once again, under your domain.</p>

<h2 id="final-words">Final words</h2>

<p>You may not need to host your email server, you can use <a href="https://www.fastmail.com/">Fastmail</a>, <a href="https://www.zoho.com/es-xl/mail/">Zoho</a>, Office 365, or Google Suite, but you <strong>must</strong> use your domain, all accounts, all bank statements should be sent to an email address at your domain, otherwise you can lose control over your accounts. Hosting your email server is not an easy task, dealing with SPAM is hard, and downtimes can be a nightmare too, but you learn one or two things while hosting your email.</p>

        </div></div>]]>
            </description>
            <link>https://www.garron.blog/posts/host-your-email-server.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23894411</guid>
            <pubDate>Mon, 20 Jul 2020 03:24:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Don't Want to Be a Founder]]>
            </title>
            <description>
<![CDATA[
Score 330 | Comments 228 (<a href="https://news.ycombinator.com/item?id=23894387">thread link</a>) | @kipply
<br/>
July 19, 2020 | https://carolchen.me/blog/founding-bad/ | <a href="https://web.archive.org/web/*/https://carolchen.me/blog/founding-bad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <header>
    
    
  </header>

  <main id="main">
    
<article>
  <header>
    
    
  </header>
  <section id="js-article">
    
<p>I had a brief run with a startup (literally a month) and was faced with the decision of going into a YC Cohort. In that fiasco, I also spent at least twelve hours trying to convince other people to go. It's been half a year, and I've had a lot more time to reflect on reasons as to why one might want to run a startup. As you might've guessed, I decided not to do it and I genuinely believe that running a startup seems like a bad idea for the majority of people I meet who want to become founders. </p>
<p>This post definitely will not apply to everyone (I'd loosely say applicable to 80% of prospective startup founders), but I'd hope there's some valuable thinking in here. Also, note that this is fairly oriented towards technical founders. </p>
<p>Edit: This post also has a very limited scope as it's based off the thinking from my decision to continue interning at Shopify or to go to YC. It's very focused on the Silicon Valley "startup" where you get a VC to give you money and get big in a year, etc etc</p>

<h3 id="commitment">Commitment<a href="#commitment" aria-label="Anchor link for: commitment"> <i></i></a>
</h3>
<p>I'm not talking about commitment to your company. I'm talking about commitment to your cofounder (if you have one, which is likely). </p>
<p>Maybe I'm too young to understand, but marriage seems frightening! My finances, my social life, personal time, and emotional wellbeing would be largely dependent on a single person and that's scary. It should be scary or should at least take a few years for it not to become scary. </p>
<p>Your cofounder is...kind of the same? In a seed-stage it's likely you <em>actually</em> live together, and if you don't, you're likely functionally living together with the amount of work involved. They're responsible for your financial well-being. They may be responsible for the quality of your social lives (most founders spend a lot of time socializing with other tech people + founders). They're tied to your life goals, your dreams, and your passions.</p>
<p>My impression was that my relationship with my cofounder would be more intense than marriage, and <em>extra</em> bad in the event of failure since there's additional loss (and it's statistically likely, but I guess so is marriage). I totally believe that there are cofounder pairs that are completely ready to go through the founder journey and pairs that maybe weren't ready but were fine anyway, but I stand by the statement that it's more intense than marriage and not enough people put care into this. </p>
<h3 id="your-vc-is-not-the-one-at-risk-here">Your VC is Not the One at Risk Here<a href="#your-vc-is-not-the-one-at-risk-here" aria-label="Anchor link for: your-vc-is-not-the-one-at-risk-here"> <i></i></a>
</h3>
<p>I often hear sentiments that resemble "wow these VCs are taking a chance on me I better commit to this!". </p>
<p>VCs are not evil people trying to take advantage of you (actually they might be, but let's assume they're not), but they are not the ones at risk. For them, 150k or a few million is not a huge risk. Seed-stage returns will be from a very small percentage of investments, thus VCs can afford to have comically high error rates as long as they get the few that matter. If you're SoftBank you can do even worse and still have so much money! They make decisions carefully, they care about your success for various reasons, and are generally caring people (in most of my experiences) but in larger abstractions, your startup means nothing to them. </p>
<p>They're not shy about it either, the entire reason they're investing in you is because they think you're more valuable than you cost. 
<img src="https://carolchen.me/blog/img/founding/paul.png" alt=""></p>
<p>Your risk is years of your life, blood, sweat, and tears. The next few years (provided your startup lasts till then) will somewhat be in service to these VCs. The VCs are your "bosses" as you answer to them (though <em>much</em> less than a regular "boss") and to the ones you hope to raise capital from in the future. </p>
<p>It's good to take a risk with increased confidence because qualified people think you have promise. However, that can morph into "I'm going to work on this startup partially in service to these people who believed in me and gave me lots of money". These additional stresses that come from meeting VC expectations and the complications of the dynamics of the relationship can cause various problems.</p>
<h3 id="sense-of-self">Sense of Self<a href="#sense-of-self" aria-label="Anchor link for: sense-of-self"> <i></i></a>
</h3>
<p>This one is the one that got to me most but I can see it being irrelevant to a lot of other people. </p>
<p>Many founders have big egos -- I don't mean they're assholes or overly self-important but they do have very powerful confidence, because that's a valuable skill to have as a founder. Not just confidence in pitching their project to others, but in their vision and their company. They need to believe their company will be successful (though I have met founders who just want to party with VC money for a few years <em>cough cough</em> Neumann). </p>
<p>My first fear was that I created an ego for myself rapidly. Practicing to sell to clients and for your YC interview involves repeating to yourself why you are <em>good</em> and self-hypnosis is fairly powerful. I love feeling good about myself, but I suddenly found myself feeling more confident in myself than what I believed was warranted. More frighteningly, I had a major character and energy change in a couple of weeks. Losing so much of my identity like that was unnerving, not to mention the ripple effects that could've occurred in my social life. </p>
<p>The other fear is coming down from that. Startup founders (especially the more eccentric ones) sometimes believe that they will build something that will change the world. Along with that, their identities start to merge with their company. There's nothing wrong with that, but I also think it's exceptionally tragic to come down from that. It's not just dealing with failure and getting back up on your feet, it's losing a part of your identity. </p>
<h3 id="school-is-generally-a-good-idea-for-prospective-dropouts">School is Generally a Good Idea (for prospective dropouts)<a href="#school-is-generally-a-good-idea-for-prospective-dropouts" aria-label="Anchor link for: school-is-generally-a-good-idea-for-prospective-dropouts"> <i></i></a>
</h3>
<p>Being a good engineer seems underrated for being a good startup founder. Not just being able to code fast, but being able to make good engineering decisions, conduct good technical interviews and attract talent. Some engineering skills can't be worked around with "I am very smart and can learn fast" and require extended time and practice. With that, I also think prospective founders also overestimate the amount of learning on the job that can be done on the engineering side, mostly because it's harder to learn when you're in a rush to release features than if you could take your time on a course project. It's true that founders will learn more than they will in school, but the technical development may not be as strong. My model is that the best schooling experience is better technical education and the best founding experience. </p>

<h3 id="something-to-own">Something to Own<a href="#something-to-own" aria-label="Anchor link for: something-to-own"> <i></i></a>
</h3>
<p>Lots of huge, ground-breaking products have been lead from within a large company. Examples include email client <code>hey.com</code>, Chromebooks, and countless amazing dev tools. </p>
<p>Starting these things in a large company has the benefit of security, resources and recruiting already done for you. Downsides include beaurocracy, not being able to recruit on your own accord and dealing with PR policy. There is also high barriers to starting something within a company, like being senior enough to do so and being at the right company at the right time. </p>
<p>The alternative is starting a project on the side. <a href="https://github.com/ziglang/zig">Ziglang</a> was started as a side project and is now a very promising programming language. The creator has since then left his job to work on Zig, but it is also possible to "own" something significant without even having to leave your job. Examples includes Julia Evan's <a href="https://jvns.ca/">blog</a> (not actually a work-side-project) and line of zines, Cassidy William's <a href="https://drop.com/buy/drop-dsa-astrolokeys-keycaps-by-sailorhg-and-cassidoo">keycap line</a>, Nick Frosst's successful and awesome <a href="https://goodkidofficial.com/">band</a> and many more. I understand that it's not the extent of "oh yeah Google? I built that", but I think the expected value is much higher in creating and owning something that isn't a startup. </p>
<h3 id="getting-rich">Getting Rich<a href="#getting-rich" aria-label="Anchor link for: getting-rich"> <i></i></a>
</h3>
<p>A lot of people claim that startups are less money, but I find for signicant number of founders, that's not true -- not because they'll definitely have a good exit, but because they're skilled in ways that allow them to raise enough money to pay themselves like they would at a big company. If that applies to you, then going to a startup probably is your best shot at getting rich! For other people, the expected value of industry (particularly joining a well-founded early-stage startup) is usually higher. </p>
<h3 id="not-being-at-school-for-prospective-dropouts">Not Being at School (for prospective dropouts)<a href="#not-being-at-school-for-prospective-dropouts" aria-label="Anchor link for: not-being-at-school-for-prospective-dropouts"> <i></i></a>
</h3>
<p>This seems like a valid reasons for the average CS student. School is a place where you answer to professors who don't always understand industry and do homework assignments that no one will care about. However, it seems like all of these problems can be significantly if not fully solved by building a better school experience for yourself. </p>
<p>A better program can improve many things, such as <a href="http://www.olin.edu/">Olin College of Engineering</a> that has a project-based curriculum, <a href="https://www.makeschool.com/">Make School</a> that is a two year applied-engineering degree program or <a href="https://devdegree.ca/">Dev Degree</a>, where you can work at Shopify and take more applied courses taught by Shopify throughout your degree. These programs are small and selective, but probably not harder than a semi-successful startup. Dev Degree also happens to be more financially sound, with Shopify paying for your tuition and a salary, and Make School tuition is 70k for the entire degree. </p>
<p>Another alternative is to just be worse at school and learn on the side and/or to morph your silly school assignments into productive skills and useful outputs. The <a href="http://coconut-lang.org/">Coconut Programming Language</a> was built by someone while they were in school. Some things like dynamic programming that are often deemed useless theoretical things can have <a href="https://thume.ca/2017/06/17/tree-diffing/">industry applications</a>. People have also taken mundane school projects like this compiler that almost every school will have you build in a compilers course and end up with <a href="https://thume.ca/2019/04/29/comparing-compilers-in-rust-haskell-c-and-python/">educational findings for engineers in general</a> (also see <a href="https://news.ycombinator.com/item?id=20192645">HackerNews thread</a>). In five weeks, my friend Maas was able to launch <a href="https://medium.com/@maaslalani/launch-5d02cc5e05f5">five relatively successful products</a> while enrolled in Dev Degree. </p>
<p>School is already a powerful environment of hardwork, fun and learning. I think it is a more cohesive ‚Ä¶</p></section></article></main></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://carolchen.me/blog/founding-bad/">https://carolchen.me/blog/founding-bad/</a></em></p>]]>
            </description>
            <link>https://carolchen.me/blog/founding-bad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23894387</guid>
            <pubDate>Mon, 20 Jul 2020 03:21:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Purpose of Technology]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23894154">thread link</a>) | @exolymph
<br/>
July 19, 2020 | https://balajis.com/the-purpose-of-technology/ | <a href="https://web.archive.org/web/*/https://balajis.com/the-purpose-of-technology/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


                <figure>
                    <img srcset="https://balajis.com/content/images/size/w300/2020/07/the-purpose-of-technology--1-.png 300w,
                                https://balajis.com/content/images/size/w600/2020/07/the-purpose-of-technology--1-.png 600w,
                                https://balajis.com/content/images/size/w1200/2020/07/the-purpose-of-technology--1-.png 1000w,
                                https://balajis.com/content/images/size/w2000/2020/07/the-purpose-of-technology--1-.png 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 1170px,
                                2000px" src="https://balajis.com/content/images/size/w2000/2020/07/the-purpose-of-technology--1-.png" alt="The Purpose of Technology">
                </figure>
                <section>
                    <div>
                        <p>If the proximate purpose of technology is to reduce scarcity, the ultimate purpose of technology is to eliminate mortality.</p><p>At first that sounds crazy. But let's start with the premise: is the proximate purpose of technology to reduce scarcity? Think about how a breakthrough is described: faster, smaller, cheaper, better. All of these words mean that with this new technology, one can do <em>more with less</em>. In the digital world, Google made information on any topic free to anyone with an Internet connection, and WhatsApp made it free to communicate with the same. In the physical world, innovations like the <a href="https://en.wikipedia.org/wiki/Haber_process">Haber Process</a> or the <a href="https://en.wikipedia.org/wiki/Norman_Borlaug#Expansion_to_South_Asia:_the_Green_Revolution">Green Revolution</a> allowed us to produce more with less. In a real sense, these technologies <em>reduced scarcity</em>.</p><p>Now for second half of the sentence, the logical implication. Is the ultimate purpose of technology to eliminate mortality? Well, mortality is the main source of scarcity. If we had infinite time, we would be less concerned with whether something was faster. The reason speed has value is because time has value; the reason time has value is because human life has value, and lifespans are finite. If you made lifespans much longer, you'd reduce the effective cost of <em>everything</em>. Thus insofar as reducing scarcity is acknowledged to be the proximate purpose of technology, eliminating the main source of scarcity ‚Äì namely mortality ‚Äì is the ultimate purpose of technology. <strong>Life extension is the most important thing we can invent.</strong></p><p>And it's actually feasible today. It's been shown that we can extend healthy lifespans in mammals ‚Äì and even <em>reverse</em> aging to bring people back to youth. Here's <a href="https://twitter.com/davidasinclair/status/1259084270854905856">link</a> after <a href="https://www.longevity.vc/">link</a> after <a href="https://www.nature.com/articles/s41467-020-15174-3">link</a> after <a href="https://news.harvard.edu/gazette/story/2019/11/researchers-able-to-improve-reverse-age-related-diseases-in-mice/">link</a> on the topic.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">Six years ago, a lifetime in the aging field, the mere suggestion that aging could be reversed was enough to have your colleagues &amp; donors screw up their noses. Tom Rando <a href="https://twitter.com/StanfordMed?ref_src=twsrc%5Etfw">@StanfordMed</a> deserves a shout out for being brave enough back then to use the word "reversal" openly 6/n</p>‚Äî David Sinclair, PhD (@davidasinclair) <a href="https://twitter.com/davidasinclair/status/1259912936602177536?ref_src=twsrc%5Etfw">May 11, 2020</a></blockquote>

</figure><p>You probably weren't aware of this, though. You probably also weren't aware of how far we've come on <a href="https://www.nature.com/articles/d41586-020-00339-3">gene therapy</a>, how much has been done in <a href="https://www.the-scientist.com/news-opinion/rna-injection-restores-hearing-in-guinea-pigs-30855">regenerative medicine</a>, how advanced the latest <a href="https://www.nature.com/articles/s41586-020-2285-x">bionic eyes</a> are ‚Äì or how <a href="https://twitter.com/balajis/status/1228447944287932416">deadly</a> COVID-19 was as a threat until March of 2020.</p><h2 id="a-duty-to-evangelize-technological-progress">A duty to evangelize technological progress</h2><p>That is because people with scientific and technical backgrounds have not taken it upon ourselves to write about technological progress <em>as a duty</em>. We need to take time out of our busy days to make the case, repeatedly and with high production values, that technological progress is the <em>most </em>important thing we can do for broad-based prosperity and economic growth, and for life itself.</p><p>That starts with testing, drugs, treatments, and vaccines for COVID-19. But it goes far beyond that. Put another way: we may not get life extension or the whole suite of transhumanist technologies (brain-machine interfaces, stem cells, CRISPR gene therapy, and more) unless you, personally, evangelize them online. Not just tweets, but articles. Not just articles, but videos. Not just videos, but feature films. And not just a few films, but an <a href="https://www.whats-on-netflix.com/news/how-long-would-it-take-to-watch-all-of-netflix/">entire Netflix original library's worth</a>, a parallel tech media ecosystem full of inspirational content for technological progressives. A lifetime's worth of content that makes the case for immutable money, infinite frontier, artificial intelligence, and eternal life.</p><p>This may mean less focus on the businesses and personalities of technology. After all, do we care whether the technology for reversing aging is developed by a startup, an academic lab, a scientific consortium, or a solitary biohacker in their garage? No. What we care about is the goal of transcendence. If the technology ends up being <a href="https://www.amazon.com/Patenting-Sun-Polio-Salk-Vacine/dp/0688094945">completely free</a> and open source, so much the better. A corporate vehicle is just one means to an end, not an end in itself. We may need to understand every detail of operating a business, but we can't get lost in those details.</p><p>The point of doing a startup after all is to build something you can't buy. Money can't yet buy you a trip to <a href="https://www.spacex.com/human-spaceflight/mars/">Mars</a>. Or a <a href="https://www.neuralink.com/">neural implant</a>. Or a <a href="https://tricorder.xprize.org/prizes/tricorder">medical tricorder</a>. And at one point in the not-too-distant past it could not buy you a web browser, a search engine, or a smartphone. When the iPhone did not exist, people had to invent it. And they needed to be inspired to invent it.</p><figure><blockquote data-width="550"><div lang="en" dir="ltr"><p>for iphone 1:</p><p>the original mac,<br>blade runner,<br>2001: a space odyssey,<br>sony walkman TPS-L2, <br>braun ET66, <br>the concorde, <br>massimo vignale, <br>henry dreyfuss, <br>apollo 11, <br>the beatles,<br>warp records,<br>NASA,<br>polaroid,<br>arthur c. clarke,<br>eero saarinen</p><p>among others‚Ä¶ <a href="https://t.co/F3ayC03T3y">https://t.co/F3ayC03T3y</a></p></div>‚Äî Imran Chaudhri (@imranchaudhri) <a href="https://twitter.com/imranchaudhri/status/1092194839540584449?ref_src=twsrc%5Etfw">February 3, 2019</a></blockquote>

</figure><h2 id="a-sense-of-purpose">A sense of purpose</h2><p>Why doesn't inspirational content for technological progressives exist in abundance? Part of the reason is adverse selection. While science fiction ‚Äì even dystopian science fiction ‚Äì can inspire, the scientists, engineers, founders, and funders thus inspired are often more occupied with building technology than evangelizing it. But this in turn means that we aren't directly educating the next generation, or the public at large.</p><p>We need to change that. Specifically, people who know math and science, who have experience in managing and investing, who are <em>technological progressives</em> rather than technological conservatives ‚Äì these people need to learn to write, report, publish, and direct. We need to consciously build a parallel tech-driven decentralized media ecosystem, and we need it to become the first point of call for anyone seeking to learn about technology.</p><p>In this we will have allies around the world. Only the very richest people can afford to be cynical about the merits of technological progress. The <a href="https://www.ben-evans.com/benedictevans/2019/5/28/the-end-of-mobile">billions</a> of people who just got their first smartphone have had their lives dramatically improved as a consequence, and are too pragmatic to romanticize the past. If you haven't already internalized this point, take two minutes to watch <a href="https://www.youtube.com/watch?v=QpvEWVVnICE">this</a>.</p><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/QpvEWVVnICE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>Back? OK. So, building a media ecosystem for technological progressives clearly starts with technical education. At the K-12 level, we've already got plenty of learning apps, and the next step is remote schools. And at the level of collegiate education and continuous learning, Lambda School, Fast.ai, Coursera, Udacity, Udemy, Binance Academy, and the countless GitHub tutorials are an amazing start. But our duty extends beyond education to media of all kinds, particularly visual media.</p><p>The tech ecosystem has natural advantages here. We have the domain knowledge. And the experts at hand. We're already doing content marketing, podcasts, conferences, and a tweetstorm or two. We understand search engines, social networks, and distribution. And yes, we have learned to code.</p><p>What we haven't done yet is <em>full stack narrative</em>. That is, with a <a href="https://wistia.com/series/one-ten-one-hundred">few exceptions</a>, like Elon Musk, we haven't really told story arcs with technological progress at the center. We haven't taken the pitch we use to recruit engineers and externalized it for the public. We haven't infused <a href="https://twitter.com/balajis/status/1276010131990261761">emotion</a> and meaning into our public communications. We haven't made every one of our companies a media company. We haven't set out to tell our story ourselves.</p><p>We need to correct that immediately, and start evangelizing technological progress with every word and action. To recognize that the purpose of technology is to transcend our limits, and to motivate everything we're doing with a sense of that purpose. To take the winnings from our web apps and <a href="https://www.quora.com/How-did-Elon-Musk-fund-his-businesses-from-PayPal-to-SpaceX-and-Tesla">put them towards Mars</a>, to feel no hesitation towards starting small and no shame in dreaming big, to tell the world that it actually is possible to <a href="https://www.the-scientist.com/news-opinion/rna-injection-restores-hearing-in-guinea-pigs-30855">cure the deaf</a>, <a href="https://www.nature.com/articles/s41586-020-2285-x">restore sight</a>, and <a href="http://med.stanford.edu/news/all-news/2020/03/old-human-cells-rejuvenated-with-stem-cell-technology.html">end</a> <a href="https://www.youtube.com/watch?v=9nXop2lLDa4">death</a> <a href="https://www.ldeming.com/longevityfaq">itself</a>.</p>
                    </div>
                </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://balajis.com/the-purpose-of-technology/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23894154</guid>
            <pubDate>Mon, 20 Jul 2020 02:27:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Canadians push back as U.S. Congress pressures Canada to reopen shared border]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23893899">thread link</a>) | @nithinj
<br/>
July 19, 2020 | https://www.ctvnews.ca/mobile/politics/canadians-push-back-as-u-s-congress-pressures-canada-to-reopen-shared-border-1.5019295 | <a href="https://web.archive.org/web/*/https://www.ctvnews.ca/mobile/politics/canadians-push-back-as-u-s-congress-pressures-canada-to-reopen-shared-border-1.5019295">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>OTTAWA -- 
	As U.S. members of Congress push Canada to reopen its shared border with the United States, Canadians are pushing back ‚Äî both in government and on social media.</p>
<p>
	In an <a href="https://higgins.house.gov/sites/higgins.house.gov/files/6-3-20%20NORTHERN%20BORDER%20LETTER.pdf">open letter</a> addressed to Public Safety Minister Bill Blair, 29 bipartisan members of Congress called on the Canadian government to plan a phased reopening of the Canada-U.S. border and to consider easing existing measures.</p>
<p>
	"We are asking that the United States and Canada immediately craft a comprehensive framework for phased reopening of the border based on objective metrics and accounting for the varied circumstances across border regions," read the letter, which was published on Western New York Congressman Brian Higgins' website on July 3.</p>
<ul>
	<li>
		<a href="https://www.ctvnews.ca/newsletters/the-covid19-brief-newsletter-signup" target="_blank"><strong>Newsletter sign-up: Get The COVID-19 Brief sent to your inbox</strong></a></li>
</ul>
<p>
	The members of Congress, who represent the northern states along the border, also implored the Canadian government to consider easing restrictions on family members and property owners impeded by the border closure.</p>
<p>
	"We understand the importance of prioritizing the safety of our communities as we all navigate the complex calculation of minimizing public health risks and resuming economic activity. However, the social and economic partnership between our two nations necessitates a clear pathway forward," the letter read.</p>
<p>
	They crafted the letter following the latest joint Canada-U.S. agreement to extend the current border closure until July 21. This is the third time the agreement to maintain the border closure has been extended.</p>
<p>
	Despite the United States' plea, a spokesperson for Canada‚Äôs Deputy Prime Minister Chrystia Freeland told CTVNews.ca in a Friday statement that the health and safety of Canadians is "absolutely priority."</p>
<p>
	"Decisions about Canada's border are made by Canadians, for Canadians," said Freeland's spokesperson, Katherine Cuplinskas, in the statement.</p>
<p>
	"Since the beginning of this global pandemic, we have been having friendly ongoing conversations with our American partners about our shared border. Both sides agree that the current measures in place, which are set to expire on July 21st, have worked well in restricting non-essential travel while allowing essential crossings to continue unimpeded."</p>
<p>
	Freeland's office wasn‚Äôt alone in pushing back against the call. Higgins posted the open letter in full <a href="https://twitter.com/RepBrianHiggins/status/1279120917134741505">on his Twitter page</a> and he was swiftly met with backlash on the social media platform.</p>
<p>
	One comment, which had three times as many likes as Higgins' original post, slammed the call.</p>
<p>
	"No thank you...clean up your backyard before you attempt to enter ours..sincerely Canada," <a href="https://twitter.com/MichelletypoQ/status/1280674509821894657">wrote</a> a user who goes by the name @MichelletypoQ.</p>
<p>
	Another user, @rachelinTO, <a href="https://twitter.com/rachelinTO/status/1281404365954260993">wrote</a> that "most of our earliest cases came from the U.S. So...... that's a firm 'no'. Sorry, eh."</p>
<p>
	Other users called the request "disastrous" and multiple accounts said they‚Äôd only be comfortable easing restrictions after seeing improvement in the number of COVID-19 cases in the U.S.</p>
<p>
	The United States reached a macabre milestone at the end of June when it became home to the world‚Äôs highest number of reported infections: more than 2.2 million. It also has the highest death toll in the world, with 120,000 deaths, according to Johns Hopkins University.</p>
<p>
	Shortly after the news broke about the soaring cases in the United States, Prime Minister Justin Trudeau said the government was considering next steps for the looming deadline of the current border closure.</p>
<p>
	Speaking in a press conference on June 29, with just over three weeks until the agreement expires, he said the government will continue to assess the situation at our shared border.</p>
<p>
	"We have extended the border measures with the United States until July 21. We will continue to assess the situation and work with the Americans on what steps need to be taken into the month of August," Trudeau said.</p>
<p>
	And as COVID-19 continues to affect countries around the world, Trudeau said the health of Canadians remains the top priority when considering the loosening of any border restrictions.</p>
<p>
	"We are going to be very, very careful about when and how we start reopening international borders," Trudeau said.</p>
<p data-attribute="embed_code">
	<!--startPolopolyEmbed--><iframe allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" frameborder="0" height="315" src="https://www.youtube.com/embed/Sw3dgpQZ2GY" width="560"></iframe><!--endPolopolyEmbed--></p>
                                              </div></div>]]>
            </description>
            <link>https://www.ctvnews.ca/mobile/politics/canadians-push-back-as-u-s-congress-pressures-canada-to-reopen-shared-border-1.5019295</link>
            <guid isPermaLink="false">hacker-news-small-sites-23893899</guid>
            <pubDate>Mon, 20 Jul 2020 01:32:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software Engineering != Coding]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23893111">thread link</a>) | @FailMore
<br/>
July 19, 2020 | https://taaalk.co/t/software-engineering-coding#eek | <a href="https://web.archive.org/web/*/https://taaalk.co/t/software-engineering-coding#eek">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
  <div id="tlk-section-read">
    



<div>

    <div>
      <div>
        <div>
          
          <div>
            <div>
              <div>
                <div>
  <p>I'm a recently trained full stack developer who want's to understand the FULL stack. Right now I think of that as backend + frontend code, but I hear there is more to it than that...</p>
</div>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <div>
      <div>
        <div>
          
          <div>
            <div>
              <div>
                <div>
  <div>
  <p>I am the founder of multiple bootstrapped companies. They include web, mobile and infrastructure development agency <a href="https://www.solidstategroup.com/">Solid State Group</a>, virtual office business <a href="https://www.hoxtonmix.com/">The Hoxton Mix</a> and, most recently, developer friendly feature flag tool <a href="https://bullet-train.io/">Bullet Train</a>. I've been involved with many more than that, watching some succeed and others fail.</p>
</div>
</div>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

</div>

  </div>







  <div>

      <div id="1">
        <div>
          
          <p>Joshua Summers</p>
          <p>15:58, 26 Jun 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>Why did you ask for this?</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="2">
        <div>
          
          <p>Ben Rometsch</p>
          <p>12:36, 03 Jul 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>Right so yes I've spent over 25 years writing software for people in a professional capacity. As time has gone by, and I've learnt more about the process, I've slowly realised that actually writing code is actually quite a small part of the process. When I was a junior developer I probably spent 90% of my working day sat in front of an editor writing code. And I thought that was the job. Turns out it really isn't!√Ç&nbsp;</p></div><div><p>I think people both inside and outside of the industry fixate on coding for a number of reasons, and it's quite interesting to ruminate on those, but building software is so much more than writing code. Talking to users, agreeing on features, designing the interface, setting up the infrastructure, testing the platform for bugs, testing it for performance, providing support for it. These are all messy, imprecise things that have very human factors.√Ç&nbsp;</p></div><div><p>If you are a software engineer you can often seek solace in the code itself. Code is truth. You can't really argue with it. You can't argue with your compiler. It's really easy to fall into the trap of avoiding all work other than coding for these very reasons. But I would suggest that this makes you a really bad engineer! Engineering means getting your hands dirty, either literally in the case of Brunel, or from a human interaction point of view where software is concerned.</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="3">
        <div>
          
          <p>Joshua Summers</p>
          <p>14:15, 10 Jul 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>So you are sort of saying that an engineer solves problems, and problems are experienced (mostly) by people, so to solve problems effectively you a) have to deal with people and b) have to really know how to solve the problem (e.g. dealing with infrastructure, performance, etc.) instead of only the parts you are comfortable with. Is that correct?</p></div><div><p>How much of this comes down to the attitude of the engineer? And how much of this comes down to actively studying?√Ç&nbsp;</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="4">
        <div>
          
          <p>Ben Rometsch</p>
          <p>10:22, 13 Jul 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>In my experience, almost 100% of that learning comes from hard won experience.√Ç&nbsp;</p></div><div><p>When I studied at university, I was really surprised to discover that the "Computing" courses that I was interested in were labelled as "Software Engineering". I thought it was odd at the time; I never really had thought it about it before, and I was even a bit worried that I might have been signing up for the wrong course!√Ç&nbsp;</p></div><div><p>I don't think many universities at the time offered "Computer Science" as an undergrad course; it's a very different discipline.√Ç&nbsp;</p></div><div><p>It took me a LONG time to get my head around the fact that one of the words in the job was "engineering". And really the only way I realised that was after years of working building software. At some point the penny dropped that I was an engineer, and that writing code was only 1 aspect of that job.√Ç&nbsp;</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="5">
        <div>
          
          <p>Joshua Summers</p>
          <p>12:00, 15 Jul 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>So based on your experience, where do you feel the greatest value lies in the spectrum of what it means to be an engineer? Or is it person dependent?</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="6">
        <div>
          
          <p>Ben Rometsch</p>
          <p>12:21, 17 Jul 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>There are a number of things that people starting off in a career of Software Engineering should try and keep in mind.</p></div><div><div><ol>
<li>Never stop learning. Software development is still a very immature discipline. I like to think about it like building jet aeroplanes. After the jet engine was invented, flying on a jet passenger plane was pretty dangerous! Google "the de Havilland Comet". There was so much new engineering that needed to be learnt to get to the point where now it is pretty much the safest mode of transport in the world. The software industry is still building de Havilland Comets to a certain degree. So much is being learnt in terms of best practices, what works and what doesn't. If you don't constantly learn new things, you will be left behind.</li>
<li>You know less than you think. You can wield great power writing software and it can go to your head! Good engineers are humble and never think they either know it all or know better than others.</li>
<li>Stretch yourself. If you know an OOP language, learn a functional one like Elixir or Haskell. If you have spent a lot of time with a very high level language like Python, try Rust. Think of it like a gym. The machine you cant stand the site of is probably the one doing you the most good.</li>
<li>It is an art as well as a science. There is room for beauty and elegance in software.</li>
</ol></div></div>
</div>

            </div>
          </div>
        </div>
      </div>

  </div>








  

  





    </div></div>]]>
            </description>
            <link>https://taaalk.co/t/software-engineering-coding#eek</link>
            <guid isPermaLink="false">hacker-news-small-sites-23893111</guid>
            <pubDate>Sun, 19 Jul 2020 22:51:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts on Monitoring]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23892963">thread link</a>) | @petethepig
<br/>
July 19, 2020 | http://blog.dfilimonov.com/2020/07/14/thoughts-on-monitoring.html | <a href="https://web.archive.org/web/*/http://blog.dfilimonov.com/2020/07/14/thoughts-on-monitoring.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>This was originally posted as a <a href="https://twitter.com/dmi3f/status/1283100690491965441?s=20">Twitter thread</a>, hence the style.</p>

<p><img src="https://pbs.twimg.com/media/Ec59QLAVAAANJC2.png" alt="Screenshot from Grafana showing an example of a dashboard"></p>

<p>Monitoring should be the next thing you set up after a <strong>reliable and fast</strong> CI/CD system.</p>

<p>Ultimately monitoring helps you understand your systems better. That in turn helps you address issues <strong>quickly</strong> when they arise. It‚Äôs a productivity tool.</p>

<p>Monitoring is for app developers too, not just ops / devops / infrastructure people.</p>

<p>If you‚Äôre new to monitoring, here are a few examples of things you might want to monitor:</p>

<ul>
  <li>üñºÔ∏è Number of images people upload</li>
  <li>üòû Errors per second from email service</li>
  <li>üìà HTTP server response times</li>
  <li>üí∞ Money spent on S3 per day</li>
  <li>üì± Daily active users</li>
  <li>üå°Ô∏è Temperature in the data center</li>
</ul>

<p>For a good real-life example of a mature monitoring setup I would refer you to <a href="https://dashboards.gitlab.com/d/RZmbBr7mk/gitlab-triage?refresh=30s&amp;orgId=1">GitLab‚Äôs Grafana page</a>.</p>

<p>So let‚Äôs say I convinced you that you need a monitoring system. What‚Äôs next?</p>

<p><strong>Most people, even the ones with a lot of industry experience, never worked with a good monitoring system.</strong></p>

<p>This means you might have to do a lot of advocating &amp; educating. And it will take time.</p>

<p>Educate people on your teams about monitoring. Show examples of how it helped you solve real issues. Give internal talks, mention it in code reviews, slack, email, meetings ‚Äî use any opportunity to tell people about it. You have to do it <strong>at least 3 times</strong> for it to stick.</p>

<p>This advice also applies to any other productivity tool you‚Äôre trying to get your team to use.</p>

<p>Us software engineers like to pretend we‚Äôre living on the bleeding edge of technology. In reality we‚Äôre often set in our ways and just as stubborn as everyone else. It takes extra effort to convince people there are tools that are objectively better than what they‚Äôre used to.</p>

<p>Make it easy to add metrics. Have a simple API in your apps, light docs. Have a <strong>reliable and fast</strong> CI/CD system and <strong>not too much process</strong> so that there‚Äôs no friction around adding new metrics.</p>

<p><strong>A good monitoring system is one where it‚Äôs easy and cheap to add metrics.</strong></p>

<h3 id="best-practices">Best Practices</h3>

<p>When you‚Äôre debugging an issue, think about what kind of metrics would help you and add those metrics, even if you already fixed the issue.</p>

<p><strong>There‚Äôs no such thing as having too many metrics</strong>. You‚Äôll never say, ‚ÄúI wish I didn‚Äôt have this metric‚Äù. However, you will say things like ‚ÄúThis dashboard has too much going on‚Äù, or ‚ÄúOur monitoring is down because we‚Äôre writing too much‚Äù.</p>

<p>This just means you have to a) keep your dashboards tidy, b) take a good care of your monitoring infrastructure.</p>

<p><strong>A good dashboard at a glance gives you leads on what‚Äôs going on in your system, and at a closer look gives you answers.</strong></p>

<p>Create dashboards for teams, projects, separate sub-systems. Keep them simple and generic ‚Äî you want others to be able to use it without much onboarding.</p>

<p>Another good way to organize dashboards is to make a hierarchy of dashboards. Create a main one with high level insights about the health of separate subsystems and links to relevant dashboards with more information.</p>

<p>Give good names to your dashboards and graphs. Give metrics proper units. Add links to other dashboards. There‚Äôs no rules, it‚Äôs an art, kind of like naming variables.</p>

<p>Allow everyone on the team to create their own <strong>playground dashboards</strong> ‚Äî and let people do whatever they want there. These are also good for ad-hoc analysis.</p>

<p>Don‚Äôt put dashboards on a giant TV screen in your office ‚Äî no one will actually look at it.</p>

<p>So how much does it cost to run a good monitoring system? Your mileage may vary, but I‚Äôll give some ballpark figures.</p>

<p>On average you‚Äôll spend about 1% of your total cloud / hosting costs on monitoring. It will also take about 1% of your team‚Äôs time to keep the system up and running.</p>

<p>Is it worth it? In my experience the benefits outweigh the costs many times over.</p>

<p>Just don‚Äôt forget to treat your monitoring infrastructure well. Set up monitoring (yes), do regular cleanups and upgrades. Address performance issues promptly when they arise.</p>

<p>Now that we have a good monitoring system, we can talk about alerts. But that‚Äôs for another day.</p>

<hr>

<p>If you liked this article, consider <a href="https://twitter.com/dmi3f">following me on Twitter</a> for more content like this.</p>


  </div></div>]]>
            </description>
            <link>http://blog.dfilimonov.com/2020/07/14/thoughts-on-monitoring.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23892963</guid>
            <pubDate>Sun, 19 Jul 2020 22:25:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reverse-engineering and analysis of SanDisk High Endurance microSDXC card]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23892463">thread link</a>) | @Manozco
<br/>
July 19, 2020 | https://ripitapart.com/2020/07/16/reverse-engineering-and-analysis-of-sandisk-high-endurance-microsdxc-card/ | <a href="https://web.archive.org/web/*/https://ripitapart.com/2020/07/16/reverse-engineering-and-analysis-of-sandisk-high-endurance-microsdxc-card/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><strong>TL;DR ‚Äì The SanDisk High Endurance cards use SanDisk/Toshiba <a href="https://www.tomshardware.com/news/wd-sandisk-bics3-64-layer-3d-nand,32328.html" target="_blank" rel="noopener">3D TLC Flash</a>. It took way, way more work than it should have to figure this out (thanks for nothing, SanDisk!).</strong></p><p>In a <a href="https://ripitapart.com/2019/08/17/unboxing-and-review-of-sandisk-64gb-microsdxc-high-endurance-card/" target="_blank" rel="noopener">previous blog post</a>, I took a look at SanDisk‚Äôs microSD cards that were aimed for use in write-intensive applications like dash cameras. In that post I took a look at its performance metrics, and speculated about what sort of NAND Flash memory is used inside. SanDisk doesn‚Äôt publish any detailed specifications about the cards‚Äô internal workings, so that means I have no choice but to reverse-engineer the <del>can of worms</del> card myself.</p><p>In the hopes of uncovering more information, I sent an email to SanDisk‚Äôs support team asking about what type of NAND Flash they are using in their High Endurance lineup of cards, alongside endurance metrics like P/E (Program/Erase) cycle counts and total terabytes written (TBW). Unfortunately, the SanDisk support rep couldn‚Äôt provide a satisfactory answer to my questions, as they‚Äôre not able to provide any information that‚Äôs not listed in their public spec sheets. They said that all of their cards use MLC Flash, which I guess is correct if you call TLC Flash 3-bit MLC (which Samsung does).</p><div>
<blockquote><p>Dear Jason,</p>
<p>Thank you for contacting SanDisk¬Æ Global customer care. We really appreciate you being a part of our SanDisk¬Æ family.</p>
<p>I understand that you wish to know more about the SanDisk¬Æ High Endurance video monitoring card, as such please allow me to inform you that all our SanDisk¬Æ memory cards uses Multi level cell technology (MLC) flash. However, the read/write cycles for the flash memory is not published nor documented only the read and write speed in published as such they are 100 MB/S &amp; 40 MB/s. The 64 GB card can record Full HD video up to 10,000 hours. To know more about the card you may refer to the link below:</p>
<p><a title="Click to follow link: https://www.sandisk.com/home/memory-cards/microsd-cards/high-endurance-microsd" href="https://www.sandisk.com/home/memory-cards/microsd-cards/high-endurance-microsd" target="_blank" rel="noopener">SANDISK HIGH ENDURANCE VIDEO MONITORING microSD CARD</a></p>
<p>Best regards,<br>
Allan B.<br>
SanDisk¬Æ Global Customer Care</p></blockquote>
<p>I‚Äôll give them a silver star that says ‚ÄúYou Tried‚Äù at least.</p>

<p>While (micro)SD cards feel like a solid monolithic piece of technology, they‚Äôre made up of multiple different chips, each performing a different role. A basic SD card will have a controller that manages the NAND Flash chips and communicates with the host (PC, camera, etc.), and the NAND Flash itself (made up of 1 or more Flash dies). Bunnie Huang‚Äôs blog, Bunnie Studios, has an excellent article on the internals of SD cards, including counterfeits and how they‚Äôre made ‚Äì check it out <a href="https://www.bunniestudios.com/blog/?p=3554" target="_blank" rel="noopener">here</a>.</p>
<div data-shortcode="caption" id="attachment_2132"><p><a href="https://ripitapart.files.wordpress.com/2019/10/sd-card-anatomy-2.png"><img aria-describedby="caption-attachment-2132" data-attachment-id="2132" data-permalink="https://ripitapart.com/2020/07/16/reverse-engineering-and-analysis-of-sandisk-high-endurance-microsdxc-card/sd-card-anatomy/" data-orig-file="https://ripitapart.files.wordpress.com/2019/10/sd-card-anatomy-2.png" data-orig-size="268,476" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SD Card Anatomy" data-image-description="<p>Block diagram of a typical SD card.</p>
" data-medium-file="https://ripitapart.files.wordpress.com/2019/10/sd-card-anatomy-2.png?w=169" data-large-file="https://ripitapart.files.wordpress.com/2019/10/sd-card-anatomy-2.png?w=268" src="https://ripitapart.files.wordpress.com/2019/10/sd-card-anatomy-2.png?w=584" alt="SD Card Anatomy" srcset="https://ripitapart.files.wordpress.com/2019/10/sd-card-anatomy-2.png 268w, https://ripitapart.files.wordpress.com/2019/10/sd-card-anatomy-2.png?w=84 84w" sizes="(max-width: 268px) 100vw, 268px"></a></p><p id="caption-attachment-2132">Block diagram of a typical SD card.</p></div>
<p>MicroSD cards often (but not always!) include test pads, used to program/test the NAND Flash during manufacture. These can be exploited in the case of <a href="https://blog.acelaboratory.com/pc-3000-flash-monolith-pinout-research.html" target="_blank" rel="noopener">data recovery</a>, or to reuse microSD cards that have a defective controller or firmware by turning the card into a piece of raw NAND Flash ‚Äì check out Gough Lui‚Äôs adventures <a href="https://goughlui.com/2015/04/05/teardown-optimization-comsol-8gb-usb-flash-stick-au6989sn-gt-sdtnrcama-008g/" target="_blank" rel="noopener">here</a>. Note that there is no set standard for these test pads (even for the same manufacturer!), but there are common patterns for some manufacturers like SanDisk that make reverse-engineering easier.</p>

<p>microSD cards fall into a category of ‚Äúmonolithic‚Äù Flash devices, as they combine a controller and raw NAND Flash memory into a single, inseparable package. Many manufacturers break out the Flash‚Äôs data bus onto hidden (and nearly completely undocumented) test pads, which some other memory card and USB drive manufacturers take advantage of to make cheap storage products using failed parts; the controller can simply be electrically disabled and the Flash is then used as if it were a regular chip.</p>
<p>In the case of SanDisk cards, there is very limited information on their cards‚Äô test pad pinouts. Each generation has slight differences, but the layout is mostly the same. <del>These differences can be fatal, as the power and ground connections are sometimes reversed (this spells instant death for a chip if its power polarity is mixed up!).</del></p>
<p><strong>CORRECTION (July 22, 2020):</strong> <em>Upon further review, I might have accidentally created a discrepancy between the leaked pinouts online, versus my own documentation in terms of power polarity; see the ‚ÄúTest Pad Pinout‚Äù section.</em></p>
<p>My card (and many of their higher-end cards ‚Äì that is, not their Ultra lineup) features test pads that aren‚Äôt covered by solder mask, but are instead covered by some sort of screen-printed epoxy with a laser-etched serial number on top. With a bit of heat and some scraping, I was able to remove the (very brittle) coating on top of the test pads; this also removed the serial number which I believe is an anti-tamper measure by SanDisk.</p>

		
		

<p>After cleaning off any last traces of the epoxy coating, I was greeted with the familiar SanDisk test pad layout, plus a few extra on the bottom.</p>

<p>The breakout board is relatively simple in concept: for each test pad, bring out a wire that goes to a bigger test point for easier access, and wire up the normal SD bus to an SD connector to let the controller do its work with twiddling the NAND Flash bus. Given how small each test pad is (and how many), things get a bit‚Ä¶ messy.</p>

		
		

<p>I started by using double-side foam adhesive tape to secure the SD card to a piece of perfboard. I then tinned all of the pads and soldered a small 1uF ceramic capacitor across the card‚Äôs power (Vcc) and ground (GND) test pads. Using 40-gauge (0.1 mm, or 4-thousandths of an inch!) magnet wire, I mapped each test pad to its corresponding machine-pin socket on the perfboard. Including the extra test pads, that‚Äôs a total of 28 tiny wires!</p>
<p>For the SD connector side of things, I used a flex cable for the <a href="http://xtc2clip.org/how-it-works" target="_blank" rel="noopener">XTC 2 Clip</a> (a tool used to service HTC Android devices), as it acted as a flexible ‚Äúremote SD card‚Äù and broke out the signals to a small ribbon cable. I encased the flex cable with copper tape to act as a shield against electrical noise and to provide physical reinforcement, and soldered the tape to the outer pads on the perfboard for reinforcement. The ribbon cable end was then tinned and each SD card‚Äôs pin was wired up with magnet wire. The power lines were then broken out to an LED and resistor to indicate when the card was receiving power.</p>

<p>With all of the test pads broken out to an array of test pins, it was time to make sense of what pins are responsible for accessing the NAND Flash inside the card.</p>
<h2>Test Pad Pinout</h2>
<div data-shortcode="caption" id="attachment_2165"><p><a href="https://ripitapart.files.wordpress.com/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png"><img aria-describedby="caption-attachment-2165" data-attachment-id="2165" data-permalink="https://ripitapart.com/sandisk-high-endurance-microsd-test-pad-pinout/" data-orig-file="https://ripitapart.files.wordpress.com/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png" data-orig-size="1666,935" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SanDisk High Endurance microSD Test Pad Pinout" data-image-description="<p>Diagram of the test pads on SanDisk‚Äôs High Endurance microSD card.</p>
" data-medium-file="https://ripitapart.files.wordpress.com/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=300" data-large-file="https://ripitapart.files.wordpress.com/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=584" src="https://ripitapart.files.wordpress.com/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=584&amp;h=328" alt="Diagram of the test pads on SanDisk's High Endurance microSD card." width="584" height="328" srcset="https://ripitapart.files.wordpress.com/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=584&amp;h=328 584w, https://ripitapart.files.wordpress.com/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=1168&amp;h=656 1168w, https://ripitapart.files.wordpress.com/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=150&amp;h=84 150w, https://ripitapart.files.wordpress.com/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=300&amp;h=168 300w, https://ripitapart.files.wordpress.com/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=768&amp;h=431 768w, https://ripitapart.files.wordpress.com/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=1024&amp;h=575 1024w" sizes="(max-width: 584px) 100vw, 584px"></a></p><p id="caption-attachment-2165">Diagram of the test pads on SanDisk‚Äôs High Endurance microSD card. (click to enlarge)</p></div>
<p>The overall test pad pinout was the same for other microSD cards from SanDisk<del>, but there were some differences, primarily regarding the layout of the power pads; notably, <strong>the</strong><strong>main power pins are backwards</strong>! This can destroy the card if you‚Äôre not careful when applying power.</del></p>
<p><strong>CORRECTION (July 22, 2020):</strong> <em>I might actually have just gotten my own documentation mixed up in terms of the power and ground test pads. Regardless, one should always be careful to ensure the correct power polarity is sent to a device.</em></p>
<p>I used my <a href="https://www.dreamsourcelab.com/shop/logic-analyzer/dslogic-plus/" target="_blank" rel="noopener">DSLogic Plus</a> logic analyzer to analyze the signals on all of the pins. Since the data pinout was previously discovered, the hard part of figuring out what each line represented (data bus, control, address, command, write-protect, ready/busy status) was already done for me. However, not all of the lines were immediately evident as the pinouts I found online only included the bare minimum of lines to make the NAND Flash accessible, with one exception being a control line that places the controller into a reset state and releases its control of the data lines (this will be important later on).</p>
<p>By sniffing the data bus at the DSLogic‚Äôs maximum speed (and using its 32 MB onboard buffer RAM), I was able to get a clear snapshot of the commands being sent to the NAND Flash from the controller during initialization.</p>
<h2>Bus Sniffing &amp; NAND I/O 101 (writing commands, address, reading data)</h2>
<p>In particular, I was looking for two commands: RESET (0xFF), and READ ID (0x90). When looking for a command sequence, it‚Äôs important to know how and when the data and control lines change. I will try to explain it step-by-step, but if you‚Äôre interested there is an <a href="https://user.eng.umd.edu/~blj/CS-590.26/micron-tn2919.pdf" target="_blank" rel="noopener">introductory white paper</a> by Micron that explains all of the fundamentals of NAND Flash with much more information about how NAND Flash works.</p>

		
		

<p>When a RESET command is sent to the NAND Flash, first the /CE (Chip Select, Active Low) line is pulled low. Then the CLE (Command Latch Enable) line is pulled high; the data bus is set to its intended value of 0xFF (all binary ones); then the /WE (Write Enable, Active Low) line is pulsed from high to low, then back to high again (the data bus‚Äô contents are committed to the chip when the /WE line goes from low to high, known as a ‚Äúrising edge‚Äù); the CLE line is pulled back low to return to its normal state. The Flash chip will then pull its R/B (Ready/Busy Status) line low to indicate it is busy resetting itself, then releases the line back to its high state when it‚Äôs finished.</p>
<p>The READ ID command works similarly, except after writing the command with 0x90 (binary 1001 0000) on the data bus, it then pulls the ALE (Address Latch Enable) line high instead of CLE, and writes 0x00 (all binary zeroes) by pulsing the /WE line low. The chip transfers its internally programmed NAND Flash ID into its internal read register, and the data is read out from the device on each rising edge of the /RE (Read Enable, Active Low) line; for most devices this is 4 to 8 bytes of data.</p>
<h2>NAND Flash ID</h2>
<p>For each NAND Flash device, it has a (mostly) unique ID that identifies the manufacturer, and other functional data that is defined by that manufacturer; in other words, only the manufacturer ID, assigned by the <a href="https://en.wikipedia.org/wiki/JEDEC" target="_blank" rel="noopener">JEDEC Technology Association</a>, is well-defined.</p>
<p>The first byte represents the Flash manufacturer, and the rest (2 to 6 bytes) define the device‚Äôs characteristics, as set out by the manufacturer themselves. Most NAND vendors are very tight-lipped when it comes to datasheets, and SanDisk (and by extension, Toshiba/Kioxia) maintain very strict control, save for some slightly outdated ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ripitapart.com/2020/07/16/reverse-engineering-and-analysis-of-sandisk-high-endurance-microsdxc-card/">https://ripitapart.com/2020/07/16/reverse-engineering-and-analysis-of-sandisk-high-endurance-microsdxc-card/</a></em></p>]]>
            </description>
            <link>https://ripitapart.com/2020/07/16/reverse-engineering-and-analysis-of-sandisk-high-endurance-microsdxc-card/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23892463</guid>
            <pubDate>Sun, 19 Jul 2020 21:09:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Are There No Technicians in Software Engineering?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23892327">thread link</a>) | @cgenschwap
<br/>
July 19, 2020 | https://www.worldofbs.com/software-02/ | <a href="https://web.archive.org/web/*/https://www.worldofbs.com/software-02/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="js-article">
        
    <p>When considering other engineering disciplines, engineers rarely build the product. In electrical engineering, the product design is specified in ECAD, exported, and then assembled by a mix of robots and technicians. Similarly, mechanical engineering specifies the product design in CAD, exports it to a set of drawings, and then it is built and assembled by technicians.</p>
<p>Software, however, does not have technicians. There is no separation between the specification of the product design by the engineer and the actual product that is used by the end-user (At least, there is no additional role between the specification and the end result, because arguably the compiler or interpreter acts as the technician and turns the code into bytes used by the computer). This is fantastic, because it cuts down on costs and the lead time of products. But, I believe it has had a profound, negative effect on software engineering as a whole.</p>
<p>Unlike most other engineering disciplines, software engineering is complete and utter garbage. This is sadly not a controversial opinion. What is up for debate is why software is just so bad. I believe the sorry state of software engineering is not due to how young it is, or how different it is from other engineering disciplines, but almost entirely due to the missing technician role. The existence of this role forces the engineer to properly specify the parameters of the product, otherwise it is built improperly or it is outright rejected. If an electrical engineer takes hundreds of tries tweaking a PCB specification, then they are a terrible engineer and would be promptly fired. Yet software has completely normalized this way of working.</p>
<p>Clearly it hasn't all collapsed (yet), so obviously something about software works. We can easily see why by looking at one of the other, young engineering disciplines: electrical engineering.</p>
<h2 id="the-breadboard-ecad-and-the-engineer">The Breadboard, ECAD, and the Engineer<a href="#the-breadboard-ecad-and-the-engineer" aria-label="Anchor link for: the-breadboard-ecad-and-the-engineer">üîó</a>
</h2>
<p>I was originally an electrical engineer. Starting out, I learned how to use a breadboard. A breadboard is a brilliant and simple piece of technology. It consists of a grid of holes where each row is connected together electrically. It makes experimenting with LEDs, diodes, switches and batteries easy and effortless. With an Arduino you can bring a microcontroller into the mix and build exciting new things.</p>
<p>As with everything, sometimes the circuit that you've built on the breadboard doesn't work. Thankfully, it is trivial to add a wire or two and hook up an oscilloscope or multimeter and start probing various connections. Sometimes the issue is as simple as a diode being backwards, which can be quickly rectified. Sometimes it is something more complicated, but everything is exposed and easily checked so you can trace it down.</p>
<p>Breadboards are easy to get started with, are extremely flexible, and can be effortless inspected with a variety of tools. But they also have downsides. They are big; wires can come loose or just be in the wrong spot; they are time consuming to recreate; and sometimes they are just a rats nest of wires and impossible to debug.</p>
<p>Eventually I was required to learn an ECAD system. Specifically, I had to learn Altium. This is a horrendously complicated piece of software which is used to design PCBs. Instead of having a simple grid that I could plug things into, I now had to design a schematic and then design a PCB layout. Starting out, it constantly yelled at me for unconnected nets and other issues -- things I didn't care about. When routing the PCB layout it would argue with all of the traces I made and there were constant red errors until I did seemingly arbitrary things until they turned green. I didn't understand what the tool was doing, and so I hated it.</p>
<p>Even after I stopped getting cryptic red errors and I was ready to export my PCB design and send it off to get fabricated, I had to wait 6 weeks for it to get to me! Once the PCB arrived the "fun" just continued. The damn thing didn't work. Except now I couldn't just plug in some extra wires and hook it up to an oscilloscope. I had to try to find an exposed surface connected to the thing I wanted to probe, and then I had to solder a thin wire to it. Sometimes, there is simply nothing exposed and you are shit out of luck. And once the error was found, it wasn't as simple as unplugging the misbehaving wire, you now had to use an exacto knife and cut the PCB trace and then solder tiny wires all over the place to fix everything.</p>
<p>My first experience with ECAD I just wanted to get back to a breadboard. It was faster to develop, easier to debug and just simpler to understand. Thankfully my mentors in life refused to allow me to sit in this local maximum, and I was pushed to use and learn the various ECAD tools. Curiously enough, I did not just learn to love ECAD -- I learned to <em>hate</em> breadboards. Where once breadboards gave me the power to wield electricity, they now hold me back and frustrate me endlessly.</p>
<h2 id="local-maximums-and-forcing-functions">Local Maximums and Forcing Functions<a href="#local-maximums-and-forcing-functions" aria-label="Anchor link for: local-maximums-and-forcing-functions">üîó</a>
</h2>
<p>How did this transition happen? How did I go from being empowered by breadboards to being held back by them? The observant reader will notice that many of the descriptions of a breadboard map to duck-typed, interpreted programming languages, like Python or Ruby. And, interestingly enough, I have an almost identical relationship with Python as I do breadboards! The reason is that both of these tools are local maximums. They provide endless flexibility, easy debugging and rapid iteration, but are perhaps less reliable or as fast as some of their alternatives. </p>
<p>But first, what does this have to do with technicians? In electrical engineering, the existence of technicians is a forcing function for learning proper ECAD tools. If you gave a technician a wired-up breadboard and said you needed 100 copies, they would likely tell you to fuck off. Software engineering has no such forcing function, and so we have a significant portion (perhaps the majority) of the industry in a local maximum using the equivalent of breadboards. The lack of a forcing function to use better tools has caused our industry to get stuck. </p>
<p>But why? I stopped using breadboards when I realized that the errors I used to make, and find easy to correct with a breadboard, I simply no longer made. And the errors that I now make, a breadboard has no way of preventing (and in general make so much harder to correct). For instance, accidentally connecting the wrong wire to the wrong chip or pin is not a thing I commonly do now. I always double check my schemas and my datasheets, and for new devices that I haven't worked with yet I build a breakout board to learn the constraints (and specifically, where the datasheet is wrong). Sure, I sometimes need to fix traces and solder some rewiring, but this is no longer due to silly accidents -- they are usually due to logic errors or an errata in the datasheet that I missed. In fact, the logic errors are largely avoided due to the schematic capture laying out the logic more accurately and easy to evaluate compared to a breadboard layout with its mess of wires.</p>
<p>However, the real reason I don't use breadboards anymore (or extremely rarely) is largely due to the lack of help they give with the things I now do. Taking an existing design and adding components or swapping out components is trivial in ECAD. I can just fix the schema, and then use push-shove routing to ensure that the component fits where I need it to. The ECAD tool ensures that my pre-existing traces are valid, and that constraints are being held (such as trace distancing). On a breadboard I have no such help. Swapping out a component on a breadboard is an absolutely miserable experience, since there is nothing checking whether you screwed up your other wiring as you did an invasive operation on the circuitry. Once I reached a level where I was no longer making beginner mistakes, I needed a tool that would help me with advanced mistakes, and I stopped caring about the beginner mistakes.</p>
<p>Now, notice how similar this is to programming languages. Languages with powerful, static type systems like Haskell make it trivial to rework a project. You just rip out what you used to have, put in the new code and then fix the type errors until it type-checks. This is unheard of in a language like Python or Ruby. And the tools that these dynamic languages provide become less and less useful in the first place. I no longer need the extreme inspectability of my running code -- I am confident that a for loop is going to act like a for loop, and that a Foo type is going to act like a Foo type. The additional flexibility that dynamic languages provide is now a downside -- I'd rather the logic be easily reviewed and checked rather than being able to plug in any type into any function.</p>
<h2 id="conclusion">Conclusion<a href="#conclusion" aria-label="Anchor link for: conclusion">üîó</a>
</h2>
<p>The sad reality is that without technicians in software we have no forcing function to use proper engineering tools. This has had a profound effect on our industry -- and it would be identical to a large contingent of electrical engineers building shitty products with breadboards. Or mechanical engineers designing cars in TinkerCAD and 3D printing them.</p>
<p>Now, this is not saying that languages like Python or Ruby are bad, are going away anytime soon or can't produce great things. The Arduino community has shown just the number of amazing things that can be done with breadboards and an easy to use MCU. But you would be pissed if you paid a thousand dollars for a computer made with breadboards. Why do we tolerate the prevalence of people using ineffective tools in software engineering? Software engineering will not get better until we do our engineering with proper engineering tools. And that means strong, static typing.</p>
<p>Looking at other engineering disciplines it is clear that languages like Haskell, OCaml or Rust are the current proper engineering tools of software. They are hard to learn, provide a ton of tools to strictly specify your logic and provide constraints, and are ‚Ä¶</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.worldofbs.com/software-02/">https://www.worldofbs.com/software-02/</a></em></p>]]>
            </description>
            <link>https://www.worldofbs.com/software-02/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23892327</guid>
            <pubDate>Sun, 19 Jul 2020 20:50:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Made 13 Dollars with Brave and Basic Attention Token]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23892175">thread link</a>) | @christian_fei
<br/>
July 19, 2020 | https://cri.dev/posts/2020-07-17-Made-13-Dollars-with-Brave-and-Basic-Attention-token/ | <a href="https://web.archive.org/web/*/https://cri.dev/posts/2020-07-17-Made-13-Dollars-with-Brave-and-Basic-Attention-token/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>After using <a href="https://brave.com/?ref=gyg242">Brave</a> for almost a year, I can extract some stats from its usage over time:</p>
<ul>
<li>152,906 trackers blocked</li>
<li>2,26GB of bandwidth saved</li>
<li>"2,1 hours saved" (no clue how this is calculated)</li>
</ul>
<p>But more importantly, I made some bucks!</p>
<p>In Brave browser you can opt-in to the <a href="https://brave.com/brave-rewards/?ref=gyg242">Brave Rewards</a> program, which enables a BAT (Basic Attention Token) Wallet where the funds will be stored.</p>
<p>Through the third-party service <a href="https://uphold.com/">uphold.com</a> you can manage those funds and withdraw them.</p>
<hr>
<p>I can't say that the ads were very relevant all the time, but certainly more accurate to my interests than other ads showed on the Web.</p>
<p>Nevertheless, in the last year I managed to gather 13,5 $ (11,5 ‚Ç¨)!</p>
<p><img src="https://cri.dev/assets/images/posts/bat-transaction.png" alt="/assets/images/posts/bat-transaction.png"></p>
<p>Not too bad. I didn't expect much from BAT and Brave Rewards, but it's still something.</p>
<p>Still better than the shady crypto faucets üòÑ</p>
<p>To learn more about Brave Rewards, visit <a href="https://brave.com/brave-rewards/?ref=gyg242">brave.com/brave-rewards/</a></p>
<hr>
<p>Are you using <a href="https://brave.com/?ref=gyg242">Brave</a>?</p>
<p>Did you get something out of the Brave Rewards program?</p>
<p>Let me know on <a href="https://twitter.com/christian_fei">Twitter @christian_fei</a></p>
</div></div>]]>
            </description>
            <link>https://cri.dev/posts/2020-07-17-Made-13-Dollars-with-Brave-and-Basic-Attention-token/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23892175</guid>
            <pubDate>Sun, 19 Jul 2020 20:21:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software as Curation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23891927">thread link</a>) | @yurivish
<br/>
July 19, 2020 | https://www.geoffreylitt.com/2020/07/19/tools-over-apps-for-personal-notetaking.html | <a href="https://web.archive.org/web/*/https://www.geoffreylitt.com/2020/07/19/tools-over-apps-for-personal-notetaking.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>We tend to think of software in terms of monolithic "apps." But what if we thought about software design as a process of curating existing parts into a holistic user experience?</p><div><p>So there‚Äôs a standard way that many note taking apps work these days. You choose an <em>app</em>, which includes a UI to read/write your notes, and cloud sync so you can work on your computer or your phone. Maybe you get decent offline support if you‚Äôre lucky. When it inevitably comes time to move on to the next app, you have to adapt to a whole new interface. And hopefully you can export your notes and port them over in some reasonable format.</p>

<p>There is an enlightened crowd of Emacs users who have done everything in plaintext for decades and rave about it on Hacker News. Parts of this philosophy are appealing to me: it would be nice to just use one editor for everything, and to have notes stored in an open portable format.</p>

<p>But I‚Äôve never been able to really get into it. I don‚Äôt want to spend my whole day in an ugly terminal, and I definitely don‚Äôt want to spend hours fiddling with settings. I want a well designed product with a thoughtful out-of-the-box experience and a beautiful GUI. I currently use Notion, an elegant product with great design.</p>

<p>When openness and design are in tension, I choose design. I‚Äôm a Mac person, not a Linux on the Desktop person. But I wish I could have both.</p>

<h2 id="mostly-air">Mostly air</h2>

<p>That‚Äôs why I was excited to come across this tool called <a href="https://github.com/foambubble/foam">Foam</a>, a Markdown note taking tool inspired by the latest darling app of the note taking world, <a href="https://roamresearch.com/">Roam Research</a>.</p>

<p>It‚Äôs kind of hard to describe what Foam is. Foam definitely isn‚Äôt an app. It‚Äôs barely even‚Ä¶anything? Here‚Äôs how Foam‚Äôs creator describes it:</p>

<blockquote darkmode="" data-title="Foam" data-author="" cite="https://foambubble.github.io/foam/">
<p>Like the soapy suds it‚Äôs named after, <strong>Foam</strong> is mostly air.</p>

<ol>
  <li>The editing experience of <strong>Foam</strong> is powered by VS Code, enhanced by workspace settings that glue together [<a href="https://foambubble.github.io/foam/recommended-extensions" title="Recommended Extensions" target="_blank" rel="noopener">Recommended Extensions</a>] and preferences optimised for writing and navigating information.</li>
  <li>To back up, collaborate on and share your content between devices, Foam pairs well with <a href="http://github.com/" target="_blank" rel="noopener">GitHub</a>.</li>
  <li>To publish your content, you can set it up to publish to <a href="https://pages.github.com/" target="_blank" rel="noopener">GitHub Pages</a> with zero code and zero config, or to any website hosting platform like <a href="http://netlify.com/" target="_blank" rel="noopener">Netlify</a> or <a href="https://vercel.com/" target="_blank" rel="noopener">Vercel</a>.</li></ol>



</blockquote>

<p>The install process is easy. You just create a git repo from a template, open it in VS Code, and then your VS Code essentially transforms into a new piece of software, with different visual design and all sorts of new features!</p>

<p><img src="https://www.geoffreylitt.com/images/article_images/foam-navigation-demo.gif?1595200989" alt="Foam navigation demo"></p>

<p>This all piggybacks on a couple key features of the VS Code text editor:</p>

<ul>
<li>a well-designed extension architecture and thriving ecosystem of extensions</li>
<li>the ability to specify a set of recommended extensions to install via a file</li>
<li>deeply customizing a ton of editor settings via a <code>settings.json</code> file</li>
</ul>

<p>While Foam does install its own extension, most of the value comes from installing <a href="https://foambubble.github.io/foam/recommended-extensions">other existing extensions</a> and choosing good default settings. For example, it installs a few extensions that provide a nicer Markdown writing experience, and that tweak lots of things about how Markdown docs link to each other. And it picks a color theme well suited to writing Markdown. I would have never come across this whole configuration on my own, but I‚Äôm glad that someone else figured it out for me.</p>

<p>The user experience still isn‚Äôt nearly as polished as a highly integrated tool like Notion. But it‚Äôs clear that someone at least thought about how all the pieces fit together into a cohesive whole. It feels closer to a product than a random bag of parts.</p>

<p>I think this is a neat way of creating value in software. <strong>The essential value of Foam isn‚Äôt code‚Äîit‚Äôs the opinionated curation of existing building blocks.</strong></p>

<h2 id="software-as-curation">Software as curation</h2>

<p>I‚Äôve previously pointed out that with a powerful enough extension system, end users can kind of start building their own software:</p>

<blockquote darkmode="" data-title="Browser%20extensions%20are%20underrated%3A%20the%20promise%20of%20hackable%20software" data-author="Geoffrey Litt" cite="https://www.geoffreylitt.com/2019/07/29/browser-extensions.html">
By installing four different Gmail extensions that modify everything from the visual design to the core functionality, in some sense, I‚Äôve put together my own email client. <strong>Instead of being a passive user of pre-built applications, I can start assembling my own personalized way of using my computer.</strong>

</blockquote>

<p>The trouble is, this is a lot of work, and the type of thing that many users (including myself!) try to avoid. Saving people the initial effort and giving them a starting point can be really helpful.</p>

<p>Maybe one view on this is that most software is like a restaurant: you pay for the final end product. <strong>But Foam is more like a recipe than a final dish.</strong> A recipe tells you a good combination of ingredients, and you get to make the food yourself, substituting ingredients to your liking along the way. We all realize recipes are valuable. It‚Äôs easier to cook from a recipe than to make up a dish from scratch, even if you end up making tweaks.</p>

<p>Also, there‚Äôs a role in the world for both restaurants and home cooking! I‚Äôm not saying that all restaurants are bad or that all software needs to be built like this. Just that it‚Äôs nice to have some software where the end user plays a larger role in the final assembly:</p>

<blockquote><div lang="en" dir="ltr"><p>2/ Yes, the restaurant food is truly ‚Äúbetter‚Äù in many ways, and there‚Äôs a role for restaurants in society‚Ä¶</p><p>But I wouldn‚Äôt want to live in a world where no one cooks, and food is something we can only choose off a menu.</p><p>Software is increasingly heading to that place.</p></div>‚Äî Geoffrey Litt (@geoffreylitt) <a href="https://twitter.com/geoffreylitt/status/1177607450863767553?ref_src=twsrc%5Etfw">September 27, 2019</a></blockquote> 

<p>By the way, one funny thing is that a lot of software is actually built like this under the hood. Engineers don‚Äôt make things from scratch these days, they find libraries and assemble them into products where the seams are hidden from the user. In the Foam model, the modules are exposed‚Äîgiving me the power to open the hood and disable or replace individual parts.</p>



<p>I don‚Äôt know yet if I‚Äôm going to actually move my note taking into Foam, but I‚Äôm giving it a shot. It has a lot going for it:</p>

<ol>
<li><strong>Generic editor</strong>: I get to use VSCode, which is my main text editor for coding. I can reap investment from learning that generic tool, rather than needing to use yet another text editing UI. The consistency matters for muscle memory.</li>
<li><strong>Customizable</strong>: Even though the tool comes with curated extensions and settings, I can still change things. I changed the default typeface, and I removed the graph viewing extension because I didn‚Äôt feel the need for it. So many note taking apps would be better if you could remove features‚Ä¶ (looking at you, Evernote!)</li>
<li><strong>Local data storage</strong>: It‚Äôs so nice to be confident in offline mode. Every cloud notes app I‚Äôve used has lost data at some point when I came back online.</li>
<li><strong>Open format</strong>: Foam seems to try very hard to store everything in vanilla Markdown with minimal extensions, which feels like a solid foundation for a long term notes collection. I‚Äôm confident I could move to another tool and actually preserve the structure of my notes.</li>
</ol>

<h2 id="challenges-and-questions">Challenges and questions‚Ä¶</h2>

<p><strong>Lowest common denominator formats</strong>: The fundamental bargain of open formats is that you gain interop and portability, and you lose the ability to innovate. This is why note taking tools often offer limited <em>one-time export</em> into other formats, but usually have their own proprietary format as a source of truth. Is there any way around this dilemma?</p>

<p>This summer I‚Äôm working with Ink and Switch on <a href="https://inkandswitch.github.io/cambria/">a project about decentralized schema evolution</a> that hopes to make some headway on allowing tools to collaborate with each other, even if they use different data formats.</p>

<p><strong>Multi-device / collaborative editing</strong>: One of the main barriers to a ‚Äútools, not apps‚Äù approach right now is that files are a bad abstraction for editing across multiple devices, especially collaborative realtime editing. It makes sense that services like Notion build their own collaborative text editing tech and clearly can‚Äôt rely on the filesystem. If we had <a href="https://www.inkandswitch.com/local-first.html">better infrastructure for local-first software</a>, perhaps it could help usher in a new world of open tools, built on a more modern abstraction than files?</p>

<p><strong>Beyond text editing?</strong>: Text editing seems like the ideal use case for this whole philosophy of generic open tools. Text is one of the more portable formats out there. Text files are small and can easily be stored on your computer. What are other domains where we could use more generic tools?</p>

<p><strong>Business model:</strong> Foam is a free product. If I was willing to pay for Foam, I‚Äôd want to pay the creators of the open source extensions behind it, not just the person who combined them into a product. And yet, I think the curation step is creating a lot of the value here too, and don‚Äôt want to undervalue it.</p>

<p>This seems like the deepest problem to solve in this area. It‚Äôs hard to sell a product that‚Äôs ‚Äúmostly air.‚Äù If we want more software like this, we probably need to figure out how people can be compensated for their curation work.</p>



<p>From me:</p>

<ul>
<li><a href="https://www.geoffreylitt.com/wildcard/">Wildcard: Spreadsheet-Driven Customization of Web Applications</a></li>
<li><a href="https://www.geoffreylitt.com/2019/07/29/browser-extensions.html">Browser extensions are underrated: the promise of hackable software</a></li>
</ul>

<p>From others:</p>

<ul>
<li><a href="https://pchiusano.github.io/2013-05-22/future-of-software.html">The future of software, the end of apps, and why UX designers should care about type theory</a>: a wonderful take by Paul Chiusano on moving beyond apps</li>
<li><a href="https://www.researchgate.net/publication/221515740_User-tailorable_systems_Pressing_the_issues_with_buttons/link/5721020f08ae5454b230fbec/download">User-Tailorable Systems: Pressing the Issues with Buttons</a>: one of my favorite reads on end-user customization of software (from 1990!), describes the role of a ‚Äúhandyman‚Äù who helps people customize software; perhaps similarly to this ‚Äúcurator‚Äù role</li>
</ul>
</div></div>]]>
            </description>
            <link>https://www.geoffreylitt.com/2020/07/19/tools-over-apps-for-personal-notetaking.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23891927</guid>
            <pubDate>Sun, 19 Jul 2020 19:46:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I wish pods were fully restartable]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23891869">thread link</a>) | @erkanerol
<br/>
July 19, 2020 | https://erkanerol.github.io/post/restartable-pods/ | <a href="https://web.archive.org/web/*/https://erkanerol.github.io/post/restartable-pods/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span>Jul 19, 2020 ¬∑ <a href="https://erkanerol.github.io/post/restartable-pods/#disqus_thread">Comments</a><br><a href="https://erkanerol.github.io/categories/software">Software</a><a href="https://erkanerol.github.io/categories/k8s">k8s</a><a href="https://erkanerol.github.io/categories/en">EN</a></span></p><blockquote><p>+Hi Erkan. Pod-X in my cluster is in CrashLoopBackOff. How can I solve this issue?</p><p>-Ohh:/ Most probably it is because of the known EKS issue. Just restart the pod.</p><p>+How?</p><p>-Just delete the pod.</p><p>+Really? May I delete any pod in my cluster?</p><p>-In theory, you can delete any pod of our application. Nevertheless, be careful :D</p></blockquote><p>I don‚Äôt remember how many times I had this conversation, but I have never thought about whether pods are really restartable or not until recently. When I thought about it deeply, <strong>I noticed that pods are not fully restartable, they are re-creatable or partially restartable.</strong></p><blockquote><p>This blog post consists of my understanding and my comments. Please ping me if there is something wrong. <a href="https://twitter.com/erkan_erol_">https://twitter.com/erkan_erol_</a></p></blockquote><h2 id="thinking-out-loud">Thinking out loud</h2><p>What is ‚Äúrestart‚Äù? RE - START. It has ‚Äúre‚Äù prefix. It means doing something again. So restart means starting again. Not ‚Äúrunning again‚Äù. What is the difference?</p><p>We are using ‚Äúrerun‚Äù for the things which finish in a short period such as cli commands. For example ‚ÄúRerun <code>kubectl delete secrets --all</code> command to ensure that all secrets are deleted.‚Äù We mostly rerun a thing when some external things have changed and when we want to benefit from its execution for the changed state again.</p><p>We are using ‚Äúrestart‚Äù for the things which run until someone stops them such as daemon processes, computers, phones etc. For example, ‚ÄúIs the phone screen frozen? Just restart it.‚Äù</p><p>When do we restart a thing? Why do we like restarting so much? Or do we like it? We don‚Äôt like it so much, but we often need it. Right? Why? Why restarting things is the best solution of all times? What is the magic touch?</p><p><u>Let‚Äôs come to the point. Restarting works since it deletes temporary states inside processes. It works since we are not perfect in managing states and our codes may stick at some states because of unhandled states or some bugs.</u></p><h2 id="cloud-native-world">Cloud Native World</h2><p>After decades, there is a consensus in the software industry: Need for restart is inevitable so let‚Äôs make it less painful.</p><p>From the application point of view, these two attributes are pretty crucial</p><ul><li>Being stateless or having states as minimum as possible (see <a href="https://12factor.net/disposability">Processes</a> )</li><li>Maximize robustness with fast startup and graceful shutdown (see <a href="https://12factor.net/disposability">Disposability</a> )</li></ul><p>From orchestrator point of view, 2 features are must:</p><ul><li>Allow workloads to state their health statuses</li><li>Restart failed/unhealthy workloads.</li></ul><p>All problems seem solved. Right? Run multiple instances, restart unhealthy ones, achieve high availability. PERFECT!</p><p>Additionally, there are always some levels in software architectures and it is better to restart things in higher levels (implies smaller scope) -if possible- to reduce the overhead. Like restarting frozen Chrome instead of restarting PC.</p><h2 id="a-short-summary-of-pods-in-kubernetes">A short summary of pods in Kubernetes</h2><p>The main subject of this write-up is pods in Kubernetes. Let‚Äôs take a closer look at pods. Here are three quotes from <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod/">the official doc</a>:</p><ul><li><p>‚ÄúPods are the smallest deployable units of computing that can be created and managed in Kubernetes.‚Äù</p></li><li><p>‚ÄúA Pod is a group of one or more containers (such as Docker containers), with shared storage/network, and a specification for how to run the containers.‚Äù</p></li><li><p>‚ÄúThe shared context of a Pod is a set of Linux namespaces, cgroups, and potentially other facets of isolation‚Ä¶‚Äù</p></li></ul><p>Shortly, Pod = Shared Context + Containers.
<img src="https://erkanerol.github.io/img/pods_simplified.png" title="pods-simplified"></p><p>Since pods are the smallest and fundamental workloads in Kubernetes, <u>to be able to restart pods is extremely crucial/necessary to reach the level at which we want to be by accepting to spend tremendous effort unrelated to our core application.</u> ( <a href="https://lmgtfy.com/?q=is+kubernetes+too+complicated">See Kubernetes criticisms</a> )</p><h2 id="restart-mechanisms-for-pods">Restart Mechanisms for Pods</h2><p>Quote <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy">the official doc</a>,</p><blockquote><p>A PodSpec has a <code>restartPolicy</code> field with possible values Always, OnFailure, and Never. The default value is Always. <code>restartPolicy</code> applies to all Containers in the Pod.</p></blockquote><p>It seems Kubernetes is able to restart failed containers on behalf of us when they fail. Fine! What about unhealthy ones? We have <a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-a-liveness-command">livenessProbe</a></p><blockquote><p>livenessProbe: Indicates whether the Container is running. If the liveness probe fails, the kubelet kills the Container, and the Container is subjected to its restart policy.</p></blockquote><p><u>Shortly, the containers in pods are restartable</u>. The temporary states inside containers are not a problem in Kubernetes world. Also, it doesn‚Äôt refresh the shared context so the overhead is so minimal. Everything seems perfect at container level until now.</p><p><u>What about the shared context under the containers? Do we have a mechanism to refresh it in pod level. Unfortunately, NO.</u></p><p>What? What happens when the shared context enters an invalid state somehow? Who is going to take care of it?</p><h2 id="controllers">Controllers</h2><p>Quote <a href="https://kubernetes.io/docs/concepts/architecture/controller/">the official doc</a></p><ul><li>‚ÄúIn Kubernetes, controllers are control loops that watch the state of your cluster, then make or request changes where needed.‚Äù</li></ul><p><img src="https://erkanerol.github.io/img/pods_simplified_with_controller.png" title="pods_simplified_with_controller"></p><p><strong><em>My comments&amp;expectations:</em></strong> Wow!!! It seems Kubernetes is designed in such a way that every agent has one job and does it well. There may be some problematic/missing pods in the cluster but we aim to solve this problem by using some controllers. Refreshing the whole pod may not be in the scope of pod controller, but it must be handled by other controllers in higher levels (See <a href="https://en.wikipedia.org/wiki/Fundamental_theorem_of_software_engineering">Fundamental theorem of software engineering</a>).</p><p><strong><em>Reality:</em></strong> There are <a href="https://kubernetes.io/docs/concepts/workloads/controllers/">a bunch of built-in controllers</a> in Kubernetes. StatefulSets for stateful applications, DaemonSets for running an application in every node, ReplicaSets for running multiple instances with same pod spec, Deployments for declarative updates etc. <u>However, none of them has functionality to fix a pod in <code>CrashLoopBackOff</code> state. For them, the state of a pod is ‚Äúgiven.‚Äù. The only thing they do is to adapt their behavior according to this fact such as stopping rolling upgrades. BUT THEY DON‚ÄôT TOUCH THE UNHEALTHY PODS.</u></p><p>Don‚Äôt you believe me? Here is an example: <a href="https://gist.github.com/erkanerol/528eab81c0db1cdcc3b9a13560d58047">https://gist.github.com/erkanerol/528eab81c0db1cdcc3b9a13560d58047</a> After one minute, you are going to observe 3 pods in <code>CrashLoopBackOff</code> state which will stick at this state forever if you don‚Äôt delete them manually.</p><p>The error in the example above may seem silly to you but there are a lot of real cases in which people hit similar issues because of different errors in different components: A problem in storage plugin, an anomaly in CNI plugin, an invalid state in shared volumes, etc.</p><p>At the end of the day, there is a state in the shared context of the pod and it is inevitable to do some mistakes that disrupt it. Why don‚Äôt we have a mechanism to clean it in pod level? Why do we assume that the state won‚Äôt be broken? Why do we compromise self-healing and expect manual intervention at such a core level?</p><p>Here are my ideas:</p><ul><li><p>Pods can have a restart policy for the whole pod including the shared context. There can be maxRestartCount field like <code>backoffLimit</code> in Jobs to stop restarting repeatedly. I think it is better to restart only failed containers at first and then restart the whole pod if necessary.</p></li><li><p>Now, we mostly run pods via some high-level workloads (e.g. deployments) and what we do is to delete the pod and to allow the high-level controller to recreate them. However, ‚Äúnaked pods‚Äù are also in the game. Recreation can be a solution in higher levels, but it should not be the solution in pod level. Pods can be fully restartable and it can be possible to trigger a restart via the API and a kubectl command.</p></li><li><p>Built-in controllers can watch the state and intervene in the errors with some primitive, retry logic. For example, the deployment controller can delete a pod in <code>CrashLoopBackOff</code> state and recreate it from scratch. Sometimes, to schedule a problematic pod into another node solves a temporary problem in storage plugin and this feature can solve many cases like this.</p></li></ul><h2 id="final-words">Final Words</h2><p>Kubernetes community is one of the best tech communities. I know the core team is very open for feedbacks and the community likes talking about possible improvements a lot. I just shared my personal opinions. I hope it will be beneficial to readers and increase awareness about this problem.</p></div></div></div>]]>
            </description>
            <link>https://erkanerol.github.io/post/restartable-pods/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23891869</guid>
            <pubDate>Sun, 19 Jul 2020 19:41:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sharing what I learned about CloudFormation after 3y working with it every day]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23891747">thread link</a>) | @davidgatti
<br/>
July 19, 2020 | https://consulting.0x4447.com/articles/knowledge/cloudformation-tips-and-tricks.html | <a href="https://web.archive.org/web/*/https://consulting.0x4447.com/articles/knowledge/cloudformation-tips-and-tricks.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
      <p><img src="https://consulting.0x4447.com/assets/img/articles/cloudformation-tips-and-tricks/header.jpg" width="100%" alt="CloudFormation Tips and Tricks"></p><p>This article is meant for CEOs, CTOs, and Managers. The goal is to give a better understanding of what CloudFormation is and why it should be used for every AWS project, by answering a common question clients have: <em>What are the the most important things our team should be aware of when working on a CF file?</em></p>



<p>Since a CloudFormation is nothing more then a JSON file, one might think that keeping everything in one big file is the right way to go. But it is not. After you have added multiple services, even as little as 3, then you will have to scroll across the file like crazy trying to edit it, and each new service exponentially extends the complexity of managing the file.</p>

<p>A good approach that I found helpful is to keep the JSON familiarity while braking down each service in a separated JSON file. Hence, I create a framework called <a href="https://www.npmjs.com/package/@0x4447/grapes">Grapes</a>.</p>

<p>With the <a href="https://www.npmjs.com/package/@0x4447/grapes">Grapes framework</a>, you are free to structure the Resource folder however you want. You can nest folders and name your files in total freedom ‚Äì whatever makes sense to your project.</p>

<p>The only imposed structure is the root folders. I have used Grapes since 2019 and I have been able to make and easily manage a massive stack, since everything remains neatly organized. Below you can find a handful of links to open source projects that I released using Grapes.</p>



<p>One of the few negatives about CloudFormation is the parameters part and how it is implemented in the AWS Console.</p>

<p>When you deploy a stack the first time with multiple parameters and there is an error, you‚Äôll loose everything you added. This is infuriating when you have a stack with 50 parameters, because if you have to redeploy a stack until it works, and let‚Äôs say it takes 10 retries and you have 50 parameters, then that‚Äôs equal to you having to do 500 copy and paste actions.</p>

<p>The only work around at this moment is to start small. Make the smallest stack that makes sense to you, deploy it successfully, and then the parameters will be saved. Afterwards you can incrementally add a service to the others.</p>

<p>This approach is also good to more quickly find issues within the CF file.</p>



<p>Since we are on the parameters topic, I highly recommend making sure all your parameters have simple, clear names that explain what to expect from them. You can add as many details of the description as you would like, even if the description is just a copy and paste of the input field. The purpose of this is to have a clear description with your default parameters in the description itself, which gives you a reference to the parameters. If you don‚Äôt have a good description, then when you come back months after you made the stack and have to deploy it in another account, then you won‚Äôt remember what parameters are needed for the stack.</p>



<p>Each resource described in the CloudFormation file must have a unique name as the JSON object Key. I recommend that you name them carefully, ideally with a simple pattern, because once the stack is deploy it can cause a lot of drama to change the name of the resource. For example:</p>

<p>CloudFormation deploys changes by first making the new resource, and if all goes well, it deletes the old one. Such as, if you have a S3 bucket that you want to rename (renaming the bucket not the service object Key), then AWS will make the new bucket first, and when all is successful, it will delete the old one if empty.</p>

<p>But if you were to rename the object Key, then AWS will see the changes as: ‚ÄúI have to add a completely new service, while deleting the old one.‚Äù But since AWS first makes resources and then deletes them, in this case you would get an error because AWS would try to make a S3 Bucket that already exists. Thus resulting in a update error.</p>

<p>Instead, the solution is to rename the resource while also renaming the S3 Bucket by adding at the end of the name, for example, <code>1</code>. Deploying that will be sufficient, since now the buckets have unique names. Then remove the <code>1</code> from the name and update the stack again.</p>

<p>This trick won‚Äôt work in some AWS resources and you might be stuck.</p>

<p>Make sure your resource names are standardized, and always follow this standard, because once they are used it is going to be almost impossible to rename them.</p>

<p>CloudFormation is for people that like to be organized and keep everything neat. With this service, you can‚Äôt just do something quick and later improve upon it; you have to have it right from the start - otherwise it is going to be complete misery later working with it.</p>



<p>CloudFormation allows you to create a cross-stack reference that can be used in another stack. For example, one stack creates a S3 Bucket, and then you can reference the name of the Bucket in the 2nd stack.</p>

<p>At first this sounds like a cool and useful idea, but in practice it is the most dangerous feature out there for CF.</p>

<p>The problem is similar to the previous section. Because once a stack is referenced by other stack, the referenced one can‚Äôt be modified because other stacks rely on it. Meaning if you have a daisy chain of 3 stacks and you wanted to edit the first one, you‚Äôd have to sequentially delete the whole stack before it, from right to left.</p>

<p>This feature is one that you should never use. The ideal approach when you want to reference a resource created in one stack with another, is to just output the resource name or ID in the original stack, copy it, and paste it in the params section of the second one. This way you still can split your stack and keep everything small and compact, while staying flexible and free to make any changes. Of course you have to remember that if you rename a S3 Bucket in the original stack, you then have to update all the CF files that uses the Bucket name.</p>



<p>If you have your work organized with 2 AWS accounts, one for production and one for development, then it doesn‚Äôt necessarily mean that the CloudFormation file you created and tested in development will work in production.</p>

<p>When working on the CF file you add features as you go, slowly building it out. And by doing so, you build on top of pre-existing services that already exist from the previous deployment.</p>

<p>Deploying the stack from scratch in production will create all the services at once, and in some cases a service that relies on another one won‚Äôt deploy because not everything is in place, which means that the stack will fail.</p>

<p>To mitigate this problem, I recommend that you delete the stack in development and then redeploy it from scratch. This approach will let you see what will fail, and then you will know how to set the <code>DependsOn</code> option to make sure the stack is deployed in the right order.</p>

<p>Only then can you be confident that deploying the stack in production will work.</p>



<p>Move slowly, iterate piece by piece, and be organized - these are things to keep in mind when working with CloudFormation.</p>

        
          <p>You can get in touch with David through the <a href="https://consulting.0x4447.com/contact/">contact</a> page or schedule a meeting with him right away on the <a href="https://consulting.0x4447.com/schedule/">schedule</a> page.</p>
        
          <p>If you found this article useful, consider sharing it with someone you think could benefit from it.</p>
      </div>
      </div></div>]]>
            </description>
            <link>https://consulting.0x4447.com/articles/knowledge/cloudformation-tips-and-tricks.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23891747</guid>
            <pubDate>Sun, 19 Jul 2020 19:28:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clipboard Injection on the Financial Times]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23891630">thread link</a>) | @ajyoon
<br/>
July 19, 2020 | https://andrewyoon.art/blog/ft-clipboard | <a href="https://web.archive.org/web/*/https://andrewyoon.art/blog/ft-clipboard">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>While doing some research today I was reading <a href="https://www.ft.com/content/b46f5a58-aa2e-11db-83b0-0000779e2340">an old column</a> by James Boyle about then-recent experiments in open access publishing in 2007. Seeing an interesting snippet, I did the ol‚Äô <code>Ctrl-C</code> and pasted it into my notes, where I was surprised to see this prepended to my selection:</p>

<blockquote>
  <p>Please use the sharing tools found via the share button at the top or side of articles. Copying articles to share with others is a breach of FT.com T&amp;Cs and Copyright Policy. Email licensing@ft.com to buy additional rights. Subscribers may share up to 10 or 20 articles per month using the gift article service. More information can be found at https://www.ft.com/tour.</p>
</blockquote>

<p>I‚Äôve seen websites garble copied text or outright disable it, but I‚Äôve never seen a site actually inject unrelated text before.</p>

<p>I was curious how they had implemented this, so I fired up firefox devtools and searched for a snippet of the notice in the site sources.</p>

<figure>
  <img src="https://andrewyoon.art/img/posts/ft-copy/devtools.png" alt="firefox devtools search">
</figure>

<p>Thankfully, the FT provides a sourcemap so I was able to find the de-minified <code>legal-copy/main.js</code> implementation and see what was going on. Essentially, it boils down to this:</p>

<div><div><pre><code><span>function</span> <span>handleCopy</span><span>(</span><span>e</span><span>)</span> <span>{</span>
    <span>var</span> <span>selection</span> <span>=</span> <span>window</span><span>.</span><span>getSelection</span><span>().</span><span>toString</span><span>();</span>
    <span>var</span> <span>wordCount</span> <span>=</span> <span>selection</span><span>.</span><span>split</span><span>(</span><span>/</span><span>\s</span><span>+/</span><span>).</span><span>length</span><span>;</span>
    <span>if</span> <span>(</span><span>wordCount</span> <span>&gt;</span> <span>30</span><span>)</span> <span>{</span>
        <span>var</span> <span>patchedText</span> <span>=</span> <span>"</span><span>hello world</span><span>\n</span><span>"</span> <span>+</span> <span>selection</span><span>;</span>
        <span>e</span><span>.</span><span>clipboardData</span><span>.</span><span>setData</span><span>(</span><span>'</span><span>text/plain</span><span>'</span><span>,</span> <span>patchedText</span><span>);</span>
    <span>}</span>
    <span>e</span><span>.</span><span>preventDefault</span><span>();</span>
<span>}</span>
<span>document</span><span>.</span><span>body</span><span>.</span><span>addEventListener</span><span>(</span><span>'</span><span>copy</span><span>'</span><span>,</span> <span>handleCopy</span><span>);</span>
</code></pre></div></div>

<p>It includes some subtleties around detecting browser support for the rich <a href="https://developer.mozilla.org/en-US/docs/Web/API/ClipboardEvent/clipboardData">ClipboardEvent API</a> and handling legacy Chrome quirks, as well as trying to disable the ‚Äúfeature‚Äù when it suspects a screen reader is being used (points to the FT for accessibility consideration, though I have a feeling this was a response to a complaint).</p>

<p>Is copying 30 words legal? The injected text warns ‚ÄúCopying articles to share with others is a breach of FT.com T&amp;Cs and Copyright Policy‚Äù‚Äîcopying <em>articles</em>, not 30 words. I‚Äôm no lawyer, but <a href="https://en.wikipedia.org/wiki/Fair_use">fair use</a> protects a great many things one might copy 30 words for, like quotation in another article, or in my case, personal notekeeping. While some infringing uses can be imagined, does this warrant such a violation of internet norms?</p>

<p>The current working draft of the <a href="https://w3c.github.io/clipboard-apis/">W3C Clipboard spec</a> describes mechanical use-cases for manipulating the clipboard like attaching metadata, rich text transfer, and translating mathematical notation to plaintext‚Äînot scaring people away from exercising their rights. There‚Äôs a set of implicit ground rules for what should and should not be done on websites. Interfering with standard access patterns like closing tabs and using right-click menus violates the social contract of the internet and further threatens its endangered state as a thing to be used, not a thing that uses you.</p>

<p>Incidentally, the article I was reading was by <a href="http://james-boyle.com/">James Boyle</a>, a copyright reformist who was a columnist for the Financial Times largely because they allowed him to <a href="https://law.duke.edu/boylesite/bipolar.html">retain his copyrights</a>, with at least some under <a href="http://creativecommons.org/licenses/by-nc-nd/2.0/">Creative Commons licenses</a>, so it seems likely I actually <em>could</em> copy the whole article if I wanted to.</p>

<p>It turns out lots of other people have noticed this kind of bad behavior and have built circumventing browser extensions like <a href="https://addons.mozilla.org/en-US/firefox/addon/absolute-enable-right-click">this one</a> which I just happily used to copy this passage from <a href="https://www.ft.com/content/b46f5a58-aa2e-11db-83b0-0000779e2340">the article</a>:</p>

<blockquote>
  <p>The internet makes copying cheap. Businesses that see their livelihood as dependent on the restriction of copying ‚Äì concentrated in the recording, film, publishing and software industries ‚Äì are understandably upset. Their goal is to have the same ability to control their content as they had in an analog world but to keep all the benefits of pervasiveness, cost saving, and viral marketing that a global digital network brings. To that end, they have moved aggressively to change laws worldwide, to introduce stiffer penalties, expand rights, mandate technological locks, forbid reverse engineering, and increase enforcement. It is not so much a case of wanting to have their cake and eat it, as to have their cake and make your cake illegal.</p>
</blockquote>

  </div>

</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://andrewyoon.art/blog/ft-clipboard</link>
            <guid isPermaLink="false">hacker-news-small-sites-23891630</guid>
            <pubDate>Sun, 19 Jul 2020 19:14:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SonicBOOM: The 3rd Generation Berkeley Out-of-Order Machine [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23891502">thread link</a>) | @snvzz
<br/>
July 19, 2020 | https://carrv.github.io/2020/papers/CARRV2020_paper_15_Zhao.pdf | <a href="https://web.archive.org/web/*/https://carrv.github.io/2020/papers/CARRV2020_paper_15_Zhao.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>&lt;0ec708cb5cf18843d0890f75781c9971&gt;] &gt;&gt;
stream
x≈ìcbd`√†g`b``8	"9√ç√Å√¨√ù ‚Äô,√é¬∏D√û_"y6‚ÄöH‚Äì √â¬∏‚Ä†D.√±‚Äπ¬¨‚Ä¶‚Äú≈í}7ÔøΩ$S√∫wÔøΩHH√£wÀÜ≈° ‚Äô√π7Àú¬Ω√å^f/‚Äò‚ÄöG√Ä¬∂¬øf`b√º%√ì	v√£(9JR‚Äúd≈ì;√∞n%‚Ä°:√â¬∏`√†√ù@	‚Ç¨p¬π
endstream
endobj
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          
133 0 obj
&lt;&lt; /Lang (en) /Names 384 0 R /OpenAction 316 0 R /Outlines 254 0 R /PageMode /UseOutlines /Pages 253 0 R /Type /Catalog /ViewerPreferences &lt;&lt; /DisplayDocTitle true &gt;&gt; &gt;&gt;
endobj
134 0 obj
&lt;&lt; /Filter /FlateDecode /S 123 /O 199 /Length 183 &gt;&gt;
stream
x≈ìc```b`√†&lt;√Ö√Ä√ä√Ä ¬•√ã √å`6H‚ÄùÔøΩeBS‚Äô√ÉÔøΩ√µ√ã&amp;≈æ```√ù‚Äùe‚Äì√©√ó&nbsp;r‚Äök√Ø√õ	S¬¶√™√∂√ïhj;√°u√£EPh√Ø8w√ö¬±ÔøΩ‚Äì¬¨‚ÄìV√î≈†‚Äì√π¬¶√°u√£¬∫‚Ä†@¬£√•xR√ãÔøΩ¬¥‚Äπ∆í√≠√ù√ã √à√Ä`^q¬∞¬ÆA√ªkTU≈∏
√´¬¶√á√π"√ª√∫e√≤3&gt;ÀÜGp√º`¬Ω√Ä√¥≈ì¬±Àú‚Ä¶√± √´ÔøΩ√®¬±√≤√Ç¬°.≈æ√Å√Äv2H330((W√≥@u
endstream
endobj
135 0 obj
&lt;&lt; /Annots [ 318 0 R 319 0 R 320 0 R 321 0 R 322 0 R 323 0 R ] /Contents 137 0 R /Group 317 0 R /MediaBox [ 0 0 612 792 ] /Parent 183 0 R /Resources 330 0 R /Type /Page &gt;&gt;
endobj
136 0 obj
&lt;&lt; /BitsPerComponent 8 /ColorSpace /DeviceRGB /Filter /FlateDecode /Height 1063 /SMask 138 0 R /Subtype /Image /Type /XObject /Width 676 /Length 56803 &gt;&gt;
stream
x≈ì√¨¬Ω}¬¨oWy√ß¬∑√ø¬≠aG√ï√àhZ√º√ÇÔøΩ√∫O^√îj¬∞ ¬¥¬ÆÔøΩ‚Äú!$"S≈í¬ÆL&lt;3&amp;≈Ω#O
4√ã,cdYXÔøΩ;Àú\√Ö|¬µ[√ªc‚ÄöueAc√°8√óF=¬±u
‚Ä°Àúx√¢≈æ√∂√Ç√Öp√∫√∏&lt;&gt;√èy√ñ√ão√≠√ó¬µ√∂Z√ü¬•¬Ø≈Ω~g√Ø¬µ√ó^/¬ø√ü√∫¬¨√µ¬¨¬∑√ù]888888888888888888888888888888888888888888888888888888888888888888888¬∏&amp;√ù√è^√ö√Ω√â√≥¬ª?zn√∑G[¬ª¬ß≈æ~Y√ø√üSA¬¥A/#√£;¬ª?&gt;¬π√ª‚Äú¬º≈í‚Äô≈æ√Æ√ô√≠√ª√á√ù¬£/√¨√û√ª√ê√è√µ√Ä√ú}√¶√î¬§‚Äù√ø√©¬©√ù√ì√ü√ú!‚Äö&nbsp;	t√∫{¬ª?;ÔøΩ√à√ÇYv¬™‚Äì¬¨√âpO}yP‚Äö ≈°V‚ÄîG¬Ω√ó√¨&lt;-YG_M√π≈∏¬Ω√¥r√´+√ª√∑‚Äö ¬™R?zn#ÀÜ¬≤√É¬¥|ÔøΩu=A4¬´6√°&gt;;I√ã√ó(√∑‚Äú√ß√≥ ‚Äö&nbsp;√™5√¶g'i√π√Æ~vc√¥A√êB
O√ï√ãN√í√≤5√ú√ÅzA-¬¶≈∏√´‚Äîf√Ω√è^B¬ß‚Äö ZTÔøΩ¬Æ}v‚Äô‚Äì¬ØÔøΩ#√µA√ê√Ç
≈í√ög'i√π√®~|2¬°CAM)`√Ü√èN√í√≤5√êÔøΩ√∫N√æB‚Ä° ‚Äö≈°√í¬©¬ß√Åz¬∞‚Äö ¬™\`√Ω‚Äô¬¨√ØS4√úR.?≈í&nbsp;Y√ñ∆í√µppp√ç¬ª√º0‚ÄöfX_6√´¬∑¬∑≈ΩBÀÜs{√ß√Ñ√üBPk√´‚Ä∫X√ñC`=√î¬∞√Ä√∫&amp;√ñ∆í√µX5,¬∞¬æ	ÔøΩ√µ`=√ñC
¬¨oB`=XÔøΩ√µP√É√´‚Ä∫√êX√ø√è~√ß√ù√ºm¬º√•√´Ox=\√≥√ØÔøΩÔøΩ≈∏3√é√∫E√∂v√Ås	]√´!¬∞‚Äö6
¬¨oBk`=¬±‚Ä∫¬øÔøΩ7√æoÔøΩEZ√Ü√Ω√é¬µ√ó∆í√µXAqÔøΩ√µMh√Ω¬¨¬ß¬ª‚Äûu√Æ√≤√ü√ænI√Ø≈æ√Ω√ñC`=E√ñ7¬°√µ¬≥√û√®}≈∏√∫¬¨¬∞&gt;√Ö?XÔøΩ√µP√ã√´‚Ä∫Pu¬¨'?`=√ñCP¬¢√Ä√∫&amp;T√´u¬ø&gt;4‚Äî¬¨‚Ä°√ÄzbÔøΩ√µM¬®:√ñ≈∏}√æ!√∂L√¶‚ÄπX√ßm&nbsp;√®}√π√è?‚Äò=&amp;`=ÔøΩX√ü‚Äû√™b√Ω√°n^√Ä‚Ç¨_&gt;√´√©√Å¬∑¬Ω√•√µ√¶√¢G&gt;√¥√ûN9‚Äöu	¬¨¬ßxv√áI√†h{_d√º≈∏w√é¬´√Åz√™+¬∞¬æ	U√Ñ√∫k√æ√Ω¬©√∂g]p¬∑F√ñMht‚Ä¶0≈°ÔøΩ√µ&amp;J.¬ØC¬¨√ø√Ü√ó^¬¨¬π√¢√∞√õ
¬Ø√Åz√™%¬∞¬æ	√ï√Ç√∫[¬æ√æ‚Äû‚Ç¨√æ√¢u√µ√úQZ√´	ÀÜ∆í∆íZ√´9J√É√¨`=√î¬¨√Ä√∫&amp;T√´√µ¬≤z√≤¬º@‚ÄùV√Ñzf√¢Àú.√ºZXO~√Äz√™+¬∞¬æ	¬≠≈∏√µ√≤=√®√µod√¥ÔøΩ√æ√´5√´#√£√ù√ú√¢¬º¬¥e'√Å
√´√ôh√ê√π‚Ä†√ãu¬∞)∆í√©‚Äú√¥√´‚Ä°5?√Äz¬®YÔøΩ√µMh√Ω¬¨¬ø√∏_]¬Ω0√®√ó√Özf1‚Äò1√§‚Ñ¢&lt;ÀúQo
\√≥8√ãg√°¬∏√¥¬£√ç√ÄÔøΩa4√è√Å‚Ä∫‚Ä¢√µÔøΩoF"XAqÔøΩ√µMhU¬¨7√Æ}≈∏√∫¬¨¬¶w√ùg√Ω"X√üw¬∞≈æ√ô√äpÔøΩ√ò√ø√ù√Å√±√∏∆í)C	Xo√ú√†√Ö`=√î¬¨√Ä√∫&amp;¬¥√ñ‚Ä°N¬∑!√ñ‚Ä∫
√∞√Å√∫√´#√Ω√∫[#Vq√∑‚Äìf¬Ω√∑√Å√Æ`7|√ñ¬ª6√º√∏+√Äz2√´‚Ä∫√êX_&nbsp;V√Ñ√∫‚Äù√±zs√á√æ5¬æY¬Ø	¬Æ‚Ä∫‚Ä¢√µ√õ√Ω6`=ÔøΩ√µM¬¨¬ØÔøΩ√µ&lt;;=b&lt;√ß‚Äòt√°¬£fk¬§ÔøΩÔøΩ√Ç√∫¬æ√ì√§√Ü¬≥&gt;¬•a√ñCÔøΩX√ü‚Äû√Ä√∫√öY¬ø√≠√õH√áx√ñ√Ñ√î¬∏≈í¬¥√¢¬¨¬∂√ê√ΩzZ^`}√´`¬ΩLc3`ek√Ç2√ú;g√æ¬º√ê‚Äú`¬™√ß√°‚Ä°X/√ò√ï√®-√±√∑$√´√´1^-/√∫√≤\√π≈æ√ã¬≥Gcp√§√Å√∫√∫√ñ7√ÄzMmqz√ä¬∫¬æ√é√Ñ√îl√ï
I7¬≤~√õ√ôÔøΩ¬£i√ù√ãz√Ø√ê?¬∑=√ú√´u√å√É¬ø√´√ñ;(2√¥7√Æ√°¬¢√ü:&amp;ÔøΩ‚ÄôE1?√ø≈ìs√ß√ø√âc√á√µ√ó&amp;≈æ‚Äú‚Ä∞√´¬°¬¢√ñ√ó√àz¬®V√ñkHÔøΩ√µ√É√¥¬±^or‚Ä†¬Æ≈í|X‚Ä¢.¬∞¬¨‚Ä°√ñ√ÉzBS‚Ä∞√æ.√É√∫¬π)√∂√∞=√∑-√ô&amp;‚Ñ¢√©u`=T¬∫√Äz¬∞Z√´E`√Ω0Q¬¶√ça1√´¬°√í√ñ∆í√µP¬¨g√É5?√®`√¶¬≤#√èt‚Ä¶√†e¬¶CÔøΩ¬æNÔøΩ√àh{¬¶√êL¬∫Te?√∫)‚Ä∞≈í¬∏P√™√¥¬≥√Æ‚ÄπHzt∆íw√Ö~6BY¬ø√à‚Äù‚Äö√®¬ß√•
V√ß!√ßU(X√∑nFÔøΩ√µM¬¨√´¬°fX/‚Äù1√î3ÔøΩkF¬π¬¶ÀúY√ö√¢g'ÔøΩ√µ2√∫ √Å√≤√£√û~¬ΩIÔøΩy‚Äì√ü%o‚Äîf√Ä√Ü√ú√£w‚Ä¶Z√¢√Å¬§T¬∏l¬ßWH$9√≤/?(14¬π]√öT
¬∞¬æ	ÔøΩ√µ`=√î√´uw‚Äôy¬§=kvkxYo¬¢g=‚Ä°√Ø√≠√ånd=√á√ú√ÑM√á√ä}u(s√∫≈Ω0¬£√Æ√ªw√êN¬≤√±√Å‚Ñ¢‚Ä†‚Ä†	¬¨oB`=X5√ÉzML√çz1M¬ª¬∏¬±√ûx‚Äπ¬≥√û√ªk#√´¬ΩX√î]q√ñG√∫√µF¬¶?√ÆfE(‚Äî√´√≥0‚Äî¬º¬¨?√Ω√¢√ì√ü√Ω‚Ä∫‚Äú√π	M%¬∞¬¨‚Ä°f¬Ω¬±3¬≥√ì4≈ì‚Äû√µ‚Äòn√¨F√ñ{S¬∫‚Äò√µ√û√ó¬•≈í√ó√´1wv√¨√ü√†√õ√à√ãz√ùH√∞¬∫¬æK)√≤¬≤√æ‚Ä∞o√æÔøΩ‚Äù≈∏P√êhz√≠kn√æ√∏¬µ`=XÔøΩ√µZLmy0‚Äò√µ√ÆE∆í√£√Å√Ωz/¬∏‚Ä°¬±&gt;~K2M‚Ç¨¬Æ‚Äòo'ld}√â¬≥√¥]√ñ?√≥Ww√Ø¬Ω¬ª`}^&nbsp;Cc+[O=D¬∑^&amp;√∏¬¶@√ª√ä√ß√â'√π≈∏≈†√µ√ö√°n√é≈Ω`¬∞√´¬ΩÔøΩ¬§¬≥~Àú√Ω√ô¬Ω√ò¬©√Ωp√ú√ô¬¢ÔøΩ¬¨w√£iH√ö‚Äπ√µ√ÆF:‚ÄòTÀúE‚ÄöÔøΩ¬≥¬æ¬®√ëyo√§5S^√∏√æ√ñ√ë√ª^√´‚Ä°‚Ä∞m(√åhG√º√ïw¬Ø~√üer‚Äπ√∫√†&amp;(√Ø[√íYOÔøΩ_r√ë‚Ä∫_√æ√ñ‚Äî√çz¬∏%]√∂Z‚Äî¬µ&lt;√´)(√±i√¶√ë¬π‚Ç¨√≥¬≤√û‚Ä¶s~≈°‚Ä∞√∑fZ&gt;¬ø√ö√õ_√ñ¬©c√¶YÔøΩ^¬¨√üq;j√ü&lt;√ì&amp;√°‚Ñ¢√π√≥‚ÄôF√≤¬¶√ß√°GX√è‚Ñ¢¬£=P √•√¥√¥¬π¬∞¬∏√ö9√Ω√¢√ì√á<e¬†√´hjca"¬∏√∞ÔøΩ√à√õ)√ú3√®¬µo√Å}‚Äû√µfÀÜn$Àú(¬π√ª‚Äì‚Äî?∆í√µ`=√ú¬æ√ã^√´j4√áÔøΩr¬§wÔøΩva√ü~}(@=≈Ω√è≈æc√≥√ä√∏ÔøΩ[^‚Ä†√Ø2√Ö}‚Ä¶<(√æ√ù‚Äì≈ín¬∏¬ª√¥¬æ√´mtm‚Ç¨zw√≤f√°h(‚Ä∫u√í"¬¨√üq√¶‚Äî√∫ÔøΩ∆í¬¨?√æ√µ√¥,√™√†c‚Ä∞z√Ω√´.~√µ¬´√ë√ä√å√∑^~s√à√õ'√æ√∏ ¬¥z√§√≠o√ø¬π√ªÔøΩk¬ø@w√π3√π‚Äò√èqq√ºj#√ö√ë¬£¬ª¬Æ√Æ¬Ω="" a√∑x√∏√∞√ç√¶√¢√è‚Ä¢√ç√´e}v√£v#2u7¬µ#a="√ìC#¬ß√°ÔøΩ7">¬¶=\p√Å%g≈∏}H√Æ√™√â√π¬º√Ω√∂-i"^s√ç√∑-√ùAG√°√´√ê.¬æ√∏j√πWE¬∑√®
√ù¬•√è:ztÔøΩoI√å¬´M√™8v/_√èÔøΩf¬∞√´!√à¬´W¬™≈°‚Äú√è√ù¬¶‚Ä°F*√éz¬®&amp;¬≤0≈°(¬Ø√â+¬®√•‚Ä∞¬∂√∫A√Ω¬Æn0¬∞Àú√¨√¢≈∏√ø√ïÔøΩP‚Ç¨√ú√∞≈Ω¬≥√æWZ√≤:√∑¬Ω¬∫a√∞J√∏√ï‚Ñ¢√∑√Å√∫√ä√ñC√ç≈†¬æ√π√ø√§≈∏≈ì√êO¬•8√´¬•O¬≠√Ö‚Äù7=w¬¶¬≠√±&amp;√Ω√¥ÔøΩ¬¨¬ß¬ª√∫¬¢√ó‚Ä°i:√≤√±T√àun'Hc√†‚Ä¢W≈ì(;ÔøΩ√Åz¬¨‚Ä° Wg≈ìq√ñG?√∫hvDV¬£√´‚Ä∞¬™√ü√ú[g√ø√º√ôK^y\√Ænd=]√ë√ë√ê√èj√©√æ¬ª√ò√ºu?‚Äù:≈Ω¬≠q`=X_¬∏√Äz¬®Y]q√Ö¬ß¬≥√≥¬±&amp;‚Ä¶X√è&nbsp;√óacW¬øw¬ø¬≥¬¨¬≠√®&amp;‚ÄûD√ñ¬ªÔøΩ√Æ√´%√ö√¶≈∏√éz√Ω≈†‚Äî‚Ä¢√ç`=√ñCÔøΩW√∏‚Ä°≈∏√ã√é√á≈°√§e=√èa3dd"√´¬±{w√Ñ\√ª√ô√∞ÔøΩ¬π≈æ_g√à¬≤√°√ã-H¬¢
_G√æe√•F3XÔøΩ√µ√§}√≥?√π√â¬ø√å≈Ω√àj√§R‚ÄôAo¬±¬∏√ØYCY7	√å√ú&lt;3¬©√è¬∞√û4$√ú^¬π‚Ñ¢√ø√ès√≥√¥¬≠√é7√Å&gt;&gt;7√èÔøΩLÀÜ¬πy`}√°√´¬°fE√ü√º3√é8s√≥F≈†M√¥¬Ø√∑¬∫√âz¬•‚Ä∫v√≤`√®:¬°‚Äú√Çw√é√¨}ÔøΩf‚Ñ¢√ùG¬Øc√´¬∫C‚Äù√©√µ√≥√£√Ü√¨&nbsp;√ó√ì‚Ä¶√ñ√ú√©T¬øls√àÔøΩf¬∞√´!√à¬´W¬™≈°‚Äú√èe√á%4‚Ä∞√å¬≤√∫√ÑG¬º¬£√π¬Ω‚Ä¢√ç`=√ñCÔøΩW√º√•√ü√ù;√õ.;¬ß&nbsp;‚Äò2√ã√™SdV√ôÔøΩRn4∆í√µXA^	√´IÔøΩ&gt;¬≤‚ÄúÔøΩV√ê√Çrw√è¬Æ√úh√´!¬∞≈æ¬•7‚Äì√∑≈æ¬´‚Ä°√£A‚Ä¶v}‚Äî`;√ß√∏√≠6√Ω√Ü{√∏‚ÄπsÔøΩ√§∆í&amp;‚Äòf√Ω√©≈∏~√†√æ√ì\o√£√¨‚Ä∫¬™√§sI¬º√´√Å√∫≈†√î√´	√•√¶pv
\¬¢¬∂√∑√Ü<qy√è }≈æ≈Ω‚Äû√Øz≈Ω‚Ä°o≈Ω√¶√°fp?‚Ä°4√´w√∑√é¬¥√´+x√ñc√ç¬∞√ûÀÜy√™="V~'√°h]∆ío-√§√üe}<|√£√ô≈ì‚Ñ¢M(√Éz√í¬≥√è|¬¨¬ØM`=X¬µ√äzs\¬ª√ëF¬ºj|‚Ä∫¬≥√ù√£≈æu√∏^√ñ‚Ä°<∆í√µs√àe√Ω√Æ√û√°¬∂`}U√´√Åz¬®U√ñ¬≥a<t7√Çb‚Äì‚Ñ¢}¬∫g¬≤√´c√®C√Ω√∫PK∆í√£&amp;w√£Q5√ø√ü√∂√∫√≠z&amp;‚Ç¨x√≥¬∂|tj‚Ä¢‚Äî√µ¬ß_|≈°z√∑√π" m%¬∞¬¨‚Ä°≈°d="¬£-√íSvj$√∏M¬¥‚Äπ¬≥≈æ√æÔøΩc‚ÄùE¬¶Fbb≈°%√º.√ΩÀÜ√∂√†NZ√†h√¥¬≤<√î$/√´¬°√ö√ñ∆í√µ}t√ßm&nbsp;X}√π√è?‚Äò=&amp;`√Ω0√©‚Ñ¢√∂√ê‚Ä°¬∫√™Z‚Äö√î¬µ]√ñ¬∑¬£¬≤j" ‚ÄúÔøΩ∆í√ùv="" ‚Äì√ª√µ‚Äô@n√òx√§¬∂≈†√é√Ø¬≠≈†√ñ7!¬∞¬æ"√ñ‚Äú√ø¬∑¬Ω√•√µ√¶√¢g="">√¥^]¬ª¬¨K`=√Ö√ì¬≠√π√ô¬πI√´g¬≠√§¬Ω√Ωe‚Ä†l√ºq√©‚Ä°L)6√º√Ñ9L~\L√Æ‚Äò√àh.s‚Äù√®¬Ø¬ºÔøΩ&gt;‚Äûl√ö|a¬¶¬¶¬¥1*X√ü‚Äû√Ä√∫¬™Y√û9¬Ø6ÔøΩ√ê¬¢v√ñ‚Ä∫(‚Äò‚Äì√ß;X¬Ø-√òZf¬¨|g¬ø‚Ä∫/≈Ω	¬®√±√≠&gt;¬≤¬≥‚Ä∞√µ;√°a√ó¬™√ÄW84~J¬ø‚Äù=√∞gz/}`p√ã¬´¬µ
√Ål#√ê\'√ào√ë√ñ-¬∞¬æ	ÔøΩ√µ√µ¬≤√æ≈†√Éo√ØX√ü≈°√ú¬πg√±¬•sZ√ünnd}h!_7mw¬∫ÔøΩ√ã,zÔøΩ_$W4√¥%≈ì√é1√î√ã¬ª√§_√∫¬∞q¬∑≈∏:√ñ7!¬∞¬æR√ñ√£k≈∏¬•√át√°√Å√∫√™√•√≤w√£‚Äû¬Ω√à√£≈íT√ùr√ú¬ØM‚Ä∞ÔøΩ√É‚ÄîÔøΩ√∂
m¬∫√ß
‚ÄöL4tM√ÑCz&gt;¬¨]`}√´+e=√ì√á¬°√å√†g√Æ√™ÔøΩ~	VX√èFr.¬¶u¬∞)wY√è
q&amp;√≤j7z:√é¬Ω$-¬∞≈æ)¬¶j¬∂¬π‚Äπ&nbsp;‚Ä°√î√æÔøΩM √é√∫√à√¥?wO?‚Ä†o√ú√ö ÔøΩ
=%ÔøΩ[√∫A√ù √°GL{#e√¶M√´‚Ä∫X_)√´ÀÜ√çÔøΩg√≤@√í√èj√†≈°√á)X≈æ√î'‚Äî9~√ù√ÅÔøΩ√ì√Ü√†9x¬ΩXO!√´9‚Ä∞‚Ä∞Àú&nbsp;¬∑t√äv√Å¬Øf≈∏√¥¬∑‚Äî¬≠&nbsp;√ñ√Ø(¬¥¬±3√ùd¬ΩU¬æv!√§y¬ª√™¬∫√Ω`√úÔøΩ√£√¨N≈í‚Ä†√ªÀÜ¬¥g√ú√Öw;Wp3√Äxp
u¬¨oB`}√ï¬¨O√ñ‚Ç¨¬≤√ò√ø‚Ñ¢√µz2√º√Å‚Äù¬°‚Äû¬∏
≈∏ÔøΩ¬Æ‚Ä∫:4zP'y√∞X@#¬¨‚Ä°R√î√ö}`}√´¬´f}¬§_√Øe=√∑√á#∆í√≤√Æ-√çz√Ø∆ítE‚Ä†¬±^√∏a=¬ø}√Æ√ÅzH¬¥q¬°√ä√ñ7!¬∞¬æR√ñ¬ß≈í√ó¬ª√ü√¨_√£;‚Äò√µ¬∫‚Äò√†¬∫¬æ¬¨w√É¬æk{‚Ä¶kd√êb¬º¬¶.√°¬º√ù≈°√ñ7!¬∞¬æR√ñ‚Ä∫√Æ¬∞+3¬Æ‚Äòi'¬§¬∞¬æ√Ø,}√ÉzPn√Ç;ÀÜm
√Ñw√ì√ç`=√Ñj√ç‚Ç¨¬ø√ñ7"¬∞¬æR√ño√ª6√í1≈æuw[#;√íNÀÜ¬≥~√òB?√ÉzJ‚Äö√æWG‚Ä†?¬ß¬ºo¬´¬¨‚Ä°≈°X√ü‚Äû√Ä√∫zY/+√óX‚Ñ¢‚Ä∫≈°¬∞√å√ê√é‚Ñ¢?¬Øg¬ø√´y√∏!√ño√Ø√õ√ò¬µzK≈ì¬π‚Ä†√µf¬¶ÔøΩ¬∂√°K&lt;¬µ‚Äú√Ä¬ª√Ät}¬∞‚Äö"√´‚Ä∫X_/√´5¬µ¬ΩFoCL√Éh√Ω&nbsp;X6¬≤~√õ√ôÔøΩc√ß√ö¬Ø√ó¬Øv√ñi¬ªÔøΩ6√∏‚Ä∫‚Äì@¬∫¬¨‚Ä°ZX√ü‚Äû√Ä√∫≈†X_¬Ω¬∏¬•√°b:&gt;√∑¬¨‚Ä°&nbsp;ÀÜ√Ä√∫&amp;√ñ∆í√µ√´‚Äòk‚Ñ¢≈∏j+`¬∞jV`}√´√Å√∫√µÀÜ-√∂≈°√¨f^XA}√ñ7!¬∞¬¨_‚Ä¢√å√í√ª¬©√ç√´¬°f√ñ7!¬∞¬¨‚Ä°√Äz¬®aÔøΩ√µM¬¨√´!¬∞jX`}√´√Åz¬¨‚Ä°X√ü‚Äû√Äz¬∞√´¬°‚Ä†√ñ7!¬∞¬¨‚Ä°√Äz¬®aÔøΩ√µM¬¨√´!¬∞jX`}√´√Åz¬¨‚Ä°X√ü‚Äû√Äz¬∞√´¬°‚Ä†√ñ7!¬∞¬¨‚Ä°√Äz¬®aÔøΩ√µM¬¨√´!¬∞jX`}√´√Åz¬¨‚Ä°X√ü‚Äû√Äz¬∞√´¬°‚Ä†√ñ7!¬∞¬æl√ñ√É√Å√Å√Å-√†√≤√É≈°U`=X√ó¬º√ã#hVÔøΩ√µ¬•¬≤‚Äö&nbsp;√â√µ√å_√Ω]¬ø¬∫kOO=√±∆í√¨1‚Ä°&nbsp;Q√´√ÅzjF`=√î¬®√Äz¬∞‚Äö≈°X5*¬∞¬¨‚Ä°&nbsp;f√ñCÔøΩ
¬¨√´!¬®ÔøΩ√µP¬£√´√ÅzjF`=√î¬®√Äz¬∞‚Äö≈°X5*¬∞¬¨‚Ä°&nbsp;f√ñCÔøΩ
¬¨√´!¬®M√Ö√∫#w√ü‚Äö√Ωg&nbsp;5	¬¨√´!¬®M√Ö√∫K.z√≥√ï√Ø¬ªl¬™XQP‚Ä°^√ª≈°√¨‚Ñ¢√ï,¬∞¬¨‚Ä°&nbsp;
m√ç√∫√òW&gt;¬Ø√∑n¬•]?DF√≠‚Ä°√à‚Ä∫√∏√íIX¬ø√µ√îC¬°ÀÜ
X√ç.¬∞¬¨‚Ä°&nbsp;eu√≥√á¬Ø
m√É√é¬∑6b‚Äù√à(√ùj&amp;oJ/‚Ä∫¬º]w√≠‚Ä°√á¬≥≈æ"9-≈°√ÅzhvÔøΩ√µ`=-(√Æ¬∂¬π√ª√Ü¬∫¬æ√Ö√î¬¶[√ë¬¨√üMf√•T¬¨¬ßwQ√§'√å¬∞≈°]`=XA9√§¬≤&gt;}√Ç[ÀÜ√µ&amp;¬µ√å-Y√ú√ôg√¢¬™√©√∂√õ¬∑√¥u]k‚Äò¬æx√±√ÖWk√ñs[√Ö¬ºBÔøΩ8p‚ÄπE7√∏6V√∞]3√¥`X¬ØG1√ê‚Ç¨¬¶X√ñCP¬π¬¨g√§‚Ä¶t!√ã¬ºk√Ég¬∂¬∫≈ì√ï√ø≈°~√ΩÔøΩ7&gt;FW√®/√øKL√ú_p√Å%$¬π√æ√π√è√Ω¬Ø:‚Äôzz∆í^b√Çh&amp;≈°√ë‚Äör=¬∫√éF√çzn‚ÄìH[√ÇA√ñ∆í√µ‚ÄùC^√ñ√´√Åz√Æ√ûz¬≠√•fn≈æG√É√ëp√ì¬∞≈æhN‚Äî¬πÔøΩ√ç5G√´ÔøΩ
_ÔøΩ2‚Äû√∏¬Ω‚ÄôIE√àV¬Ø¬Ø‚Ä∫m‚Ç¨&nbsp;√°√´√Åz√ä¬°P¬ø^_!p{√ß√ò¬ª6|¬¢√¶¬¨√©∆í√ñ‚Äπ‚Ä¢^;f=w√π√â&gt;|¬≥f¬ΩeÀÜ‚Ç¨X≈í√ö√¶J≈ΩN¬∏%¬∞≈°@`=XA9√™√ó√´+‚Ä∞¬¨√üUl√ï≈∏M¬ß√õe¬Ω√Æ√ó¬ª"√Æ3j√Ö‚Ä†o‚Äì√ïGX/i√ë√≠ÔøΩD√ñO;√±‚Äö^X√ñCP‚Ä¶√¶√¶√©io.√ìC√ó5√´9dw¬¶=el√∏√öP5	.√ª√Ø¬Ø√ò√µ-¬´ÔøΩ,ÔøΩ[√öC¬¢
√Ç]z √®ÔøΩ√µ`=√•ÔøΩ√ã√∫√ù=dK√è√óÔøΩT/≈†√ò√∞w√ï\wMz√™√Ç7√ø¬∫√©¬∂¬≥‚Ä¢≈æ%s√≥√§√¢_√ªo√æ√á√ù√Ä¬≤z≈æI(√Ø√ïd‚Äô¬°\13¬ºs√≥¬§¬°√¢
‚Äö
¬¨√´!hA‚Ñ¢m√±√ò‚Ñ¢√ôn√Æ≈í;#wn≈æi0gÔøΩu]^-√ùy‚ÄîgGd7√ñ√ªN¬≠¬π-¬´√ó√¥¬πSo√ö:√π¬°5wf‚Ä¶`√∂"∆íjX√ñCPu
Y√ã√Ø‚Äò√´.¬´√ü(L¬°‚Ä°
X√ñCP]rW√ô‚Äπ¬≥√ûL√©O‚Äì√ÜC	¬¨√´!¬®.E√∫;¬ø&gt;√í√û‚Ç¨&nbsp;√´√ÅzjF‚Äπ¬±‚Äö√äX√ñCP3√´¬°F√ñ∆í√µT¬£≈æ}√¶{ÔøΩ&gt;¬≤ct√¨√ÅSX√ø√Ä√Ω¬ß√ù&nbsp;¬®√ôÔøΩ=ÔøΩ‚Äù*¬∞¬¨‚Ä°&nbsp;J5¬¨¬øQG√Ø{	&nbsp;‚Ä°V&amp;¬∞¬¨‚Ä°&nbsp;z√µ√Ç√∑¬∑¬®W&gt;-√®¬ø√ª7'¬≥¬ß‚Äö√∫	¬¨√´!¬®jÔøΩ~√±√©G√ô‚Ñ¢√¥√é√é√≥√ü√â≈æ"√™-¬∞¬æ$√ñ¬ª√ª‚Ä∞√Å¬≠√à√•√ø9Ca=√µ√ÑF‚Äö√æ‚Ä∞o√æÔøΩ≈°
√ôAC√ñ∆í√µp¬π√º?g(¬™√≠‚Äú√è¬Ω√Ø¬•av√ªg≈∏√π^√∂√∏C√êpÔøΩ√µ√•¬±~{√´(¬¥.ÔøΩ√µku√å√ªN√Ö'√ø¬∞√õC¬´X√ñC¬£√ñ¬ØKO|√≥‚Ä°¬∞√õCm	¬¨√´¬°√ë√´W¬ßg≈∏√π√ûF¬ª=√ñA√µ¬¨√´t√ßm&nbsp;ÀÜ}√£k≈∏uo]q√∏√≠2`√Ω‚Äò¬Ω√ó√ª8]7C√õ‚Äù~V¬ª√≥√éyu√§¬©√ñ¬ØQ‚Äò√•x√á&lt;¬µ}√≤¬π√¨1‚Äû&nbsp;√â√ñ∆í√µ#X√ø¬∂¬∑¬º≈æ¬πL√∫√≤≈∏"‚Äû{¬¶¬∂~√ä$‚ÄúB¬¶+√¥‚Äì^O‚Ä¢#¬∞~¬Ω:√æ√µM}√µ√®#;¬∞√õC¬µ	¬¨√´‚Ä°¬≤≈æ√°N√•
√µ√ì√Ωj¬ª¬¶¬∞√û}¬™ÔøΩ√µ¬´‚Äì,√ác¬ª=@U(¬∞¬¨√äz√É√¢ÔøΩ7¬∞√û‚Äù/\ÔøΩ√Æ¬º√≥^w√á√è¬æ√©M¬øÔøΩ;"p√Ö¬π√ºÀú√´√Å√∫¬¨¬¨√ß√ëv√ó‚Ä∫‚Äπc√óo¬∫√ø‚Ä∞6|¬Ø√ë&nbsp;%√ñ	9**88¬∏Q.?¬¶√Åz¬∞&gt;7√´
|C]ow‚ÄìÔøΩ√Åz‚Äû√µ‚Äò¬ß√äQbÔøΩPl√πB√§
¬¨√´√Å√∫√≠√Ωzn√ê√£r%√ù‚Ä†¬Ø≈∏*G`=√ï'¬∞¬¨√´¬∑G≈í√óo;√≠‚Äû√ñ¬ªO‚Ä¢#¬∞‚Äö√™X√ñ∆í√µ√õ#√¶√°o∆í√µ/¬∞¬¨√´YDvÔøΩ;√ª√±¬©√É‚Ä†_x√πB√§
¬¨√´√õd¬Ωv¬≤g¬±^.‚Ä†√Ñ¬π¬≥√¨√å‚Äì;‚Ä∞s√≥B√ª√≤eXA√µ	¬¨√´[c=XA√µ	¬¨√´√ÅzH¬´A√ñ;w√Ç¬´√≥√éyu√∫√®ÔøΩ¬∂b¬ª¬•√É¬¥¬ºQ√•U¬Æ,c√®KL,X√ñ∆í√µÔøΩ√ñ‚Äû¬¨wg$‚Äì¬©√âY√è√£8√öM‚Äòt√ñ‚Ä∫u¬£√ù¬¶)"|L∆í¬∏√Å√≥I√≤≈ΩX
f=e¬¨O¬≠‚Ä∫√π¬∞¬™1YD√ÖD‚Äî√≤
¬∞¬¨√´!Q9¬¨-‚Ä¶¬©6(√∂√é√ôÀú√™‚Äòt√ñ‚Ä∫$"√Ñ¬°&nbsp;=p|R √¢√ä‚Äù;¬µX‚ÄîyX√π√≤S.√ê9Jf}(√¶√Æ+√Äz¬∞¬¨‚Ä°D`√Ωx√Çz√é¬¶‚Ä°≈†i√®√á{√â-w~√ª2O‚Ä†‚Ä¢¬Ø√∑√ã√Ü]√¶√à)√òSi¬§√©#√•q¬∞¬¨√´!¬≠‚Ñ¢X√è¬µ=√ï√Ä¬≤√ò√Å]¬®√à≈Ωyg≈í√Ä\u¬≥‚Ä¢‚Ä¢√ªYL%∆í'¬∑Z‚Äì¬∏&amp;gs¬Ω8≈Ω∆í¬∑j^√ç√¢H ¬°¬¶H√ú:p≈Ω¬™1zK≈†√¥h¬ª^-BÔøΩG√¢√ç!ÔøΩ√É√ôÀÜZofr√≤‚Ñ¢z√≤R7zn#√ÅnJ√Ñ6√Æ&amp;√Å‚Ä∫√™√≠∆í√ãd√öt¬±¬∫¬¨OY_√£¬∂&nbsp;¬§¬øg¬Ω√æ¬∂p&amp;¬∏CB:cuY√ã7√Ñ¬§H'G_√ó9¬£√£¬≥√ëb¬≥
√ñ∆í√µ`=tP‚Ä∞uBJ√π¬∫¬¨‚Äî√ä‚Äì+Ro]'5¬ø√õ√ï√¢J[√ó~q√ñk√Ä√ëS√º&nbsp;√ãO¬æ+¬Ø0;-Àú‚Äûb¬Ω¬π√Æ√∂¬ª√µ#f¬¥ÔøΩ^√ç&gt;√£&nbsp;‚Ä∞0N+√í¬Øg√∫D‚Ç¨N¬±28√≥√Ü‚Äû¬£a≈†IJ¬µ~¬ª¬±√®xJB√èR0¬•√©√ç
¬∑√Ω √É√∑√ñk	E‚Ä∞&lt;‚Ä∫√Ø¬∂.Yc*‚Äò\√íÔøΩ¬∏#)√Æ√∑‚Äì¬Æ√´¬≤H¬±‚Ç¨ÔøΩ√µ`=Xi√ç√äz√ç2√ù‚Äúrk√ö√≠√´M√ø%√Ç√∫√êB≈ì√µnI_1¬Ω¬øP√´√é√ç√£¬ß√úiT‚Äô√∞x√æÀúLH‚Ä∞√É√∂&gt;&nbsp;¬πm&nbsp;!√ø:¬•f¬ª'¬∑¬Ø√™m‚Ñ¢Dr^s√ñ√å‚Äö√ì%√¢M¬µ&nbsp;¬æb√ë¬°¬π‚Ä∞√µ‚Ä†√Øf¬æ~0√Ç√∫P√¶‚Ä°Z&gt;√û√Ø¬π¬æ√Æ¬æ√ã+"c)∆íe`=X√ñCZ‚Äπ¬±√ûk√ò≈íoS√¨V√î√ñ‚Ä°√™√°8√´√ùW√®p√å√ùP√™√ó‚Ä∫‚Ä∞√Æ√¨B¬¨q!1√ö"√Å¬§‚Äì√è!{¬Ø‚Ä∞≈æ≈Ω≈í√âL¬∑1√Én#√´¬•‚Äú√Æ:.o¬™√ù¬¢‚Äù√ê√ú|√ì√•k‚Ä†l√ò¬π¬¨√∑√∂√Ñ√•a}√àx¬Æ√ª√Ø√§ÔøΩ√ü√ô‚ÄòT¬ª;}uj≈íC
(√≤¬∫ÔøΩ√∏√Å√ºÀú√´√õf=√ø√ñ=O¬Æ‚Ñ¢√¶‚Ç¨√Öw‚Ä∞6√ò√±√¢&amp;}fQbÔøΩÔøΩR¬æ√©¬¨‚Äî‚Äö√ê√ÅV√â√∫g'g¬ΩI&gt;√ß-{√ç√£≈†D√è√ã√∫√ê‚Äû‚ÄûÔøΩ√£√µ‚Äò8L√é√∫‚Äù≈∏¬∂	√Ñ√ú√é¬∑*!‚Äùcb{√ó√ç‚Ä†t√ñ√á¬≠l¬®√ô8A√Ç}X√ñgg¬Ω4}√ù/gbcT7√´C√ô‚Ä∞[.√ño;∆í‚Ä∫Yo√ä.√Ö‚Ä†ozm√õ#l√∏}Y√ø¬¶u∆íl√∏√ñ‚Ä∫√´b√íÔøΩ|OY¬ø√•¬µ7J√∫{YJ0√Ä‚Ä†√ü√π&amp;¬∞‚Ä∞
?¬±‚Ä∞$g‚Ç¨
_n‚Ñ¢√Øp√®-ÔøΩoP&gt;"%≈í√ó∆í√µ¬´`}¬®√Æm‚Äû√µ‚Äú√ã¬≠¬±¬πfHÔøΩ√õ√Ç¬¨¬ß¬¢73√èuE¬≠√´X√Æ≈í¬Ø√Æ√†l7wn≈æ¬ª√∫L√á√ìL√Ü√£[z¬™√ò√ñ¬ªg√â√ú¬≥m¬ß√ï√ß¬æZ√¶√¶¬•√Ñ√Å¬ºK[√ùC≈ì√≠√Özn9H√¥t!n\_√è¬¥√ç\√ÆzSm≈†√í√å≈∏√§Àúx√ß√¶¬π¬ª√êg/I#√çÔøΩ√´√ùÀúH¬¢$&amp;√Æ√ª√∏√ú&lt;√Æ¬∂√´¬º√¢[√≤a√õi√àa&gt;X¬ø
√ñ‚Ä∫≈°A√Ü√éF¬Æ√éNW√µ¬¨√Ø¬µ√ú;K¬ø^ÔøΩ¬´≈°¬æ¬≠√Ü¬∑¬∑B√ñ+√†√å√î&amp;
8‚Äî5R
√ûo&nbsp;¬∏Hc¬£/√´¬∑ÔøΩ‚Äòn√çi¬´Àú√¶‚Ä∞qp√ü¬•W=x¬ø√∞¬ΩXo¬¢√ß√ç^o‚Ñ¢≈°√Ñ¬∫_$o¬™√•‚Ä∫√©
P¬≤¬πm`26‚ÄúHuTCvu√Ωm1¬π√á√ü^√≥&nbsp;√∑¬´nR¬™'NÀú‚Äì¬°√∑k√ô%√î'√ºT~L∆í√µ
¬≥&gt;&gt;¬øe√£√£fi¬≠√õk3kU√ú¬¶√π‚Ñ¢GV√æ≈°≈∏¬ø¬∑√°¬≠¬æt√çf√∫¬∫√™fc¬ª¬±¬µ‚Ä†V1‚Ä∫Z‚Äò¬º¬π3¬¶¬§BH√ü‚Ç¨%¬±NH/_*_‚Ä∞¬ª√è√µRJw{¬±Àú∆í√µ`}v√ñ‚Ä°0‚Äù√Çzm√ãK&nbsp;^¬Æ¬ª¬≠P√Æ]¬ª}ÔøΩ√µ‚Äò‚Ä¢¬øZ√Ç_√≥‚Äπ‚Äú√û‚Äû≈ΩÀú¬ª‚Äì&lt;√Ç√∫√ég√à√ïye,¬•¬Æ=√ê[√É¬§W;`=√î¬¶¬º√ª√°‚Äì√π√ï√è¬ß√à√Ç
-¬∞¬¨√è√é√∫.`‚Ç¨√ö√à√∫ÔøΩ¬•√î=√≤∆í√É‚Ñ¢√©√åD√´ÔøΩM √≤≈†mg√æ‚Ä∫≈Ω[|^‚Äúa¬Ω√´3¬¥≈†9‚Äùo^¬¨¬ßÔøΩS‚Ç¨√µP‚Ä∫≈°√∂≈ì;wn√§L√≤VP^o`=X≈∏‚Äò√µ‚Äòm¬∫]√ñk√´¬¥√¨O√ö‚Äπ¬™
\¬°¬æ¬≠√¶`√ßs!√ñ‚Ä∫‚Äò\√∑A√Ü¬¥k¬∏ÀÜ¬∞^√á0¬≤≈†92"b}z√ì¬¨‚Ä°&nbsp;√ä√ñ∆í√µyY¬ø=¬¢_a¬Ω&nbsp;M¬∏Y≈∏b√á√≥¬≤&gt;}Q/√ñG¬¶x√µb=√∫√µ√î¬¨√Äz¬∞&gt;;√´ÔøΩ√ó¬ß&nbsp;P{H¬¥√°¬ß√åasY√∑&lt;‚Ä¶√µ√õ√Ωw√ô≈í√üa¬º‚ÄöZX√ñgg√ΩÀúy√∏&lt;‚Ñ¢ÔøΩ?√´U¬∫√õj√ù≈†\	-‚Ä†√ï¬¨ÔøΩ¬¨√º√ïrY√èW√å!}+qn≈æw+9√Ø*√¶√êZ]¬Ø¬π√≥√∞!¬®eÔøΩ√µ`}v√ñ√áW7¬≥‚ÄπLg√ïkQ√ù√ï√äp√û√Ö¬∞√û¬Ω√ó√Ñy_√™]rY‚Äî¬≠√áq√ª!‚Äò√µ√õ√°U√å√õ√°e√©&amp;√≤¬π√ñ√óCTÀÜ√Äz¬∞&gt;;√´√ù¬Ω/&amp;Q√¢n‚Äú-(√ó¬æy"¬∞¬¨√è√é√∫√≠≈æ¬∂¬ß‚Ä°¬π√∞nx√Ö*√ó~√∏ÔøΩ‚Äπ¬∑E√äÔøΩY√•≈æ2≈ì¬®i√∑‚Ñ¢√π√à‚Ä°√û¬ª√Ä¬Æ5¬´X√ñ‚Äî√Ä√∫√â√è¬π‚Äπ,√•kM√è¬πkY^k‚Ä¢w\‚Ä∞¬•‚Ä°c"√á√≥i¬∑√Ä&gt;-‚Ä¶</qy√Ø></e¬†√´hjca"¬∏√∞ÔøΩ√®√ª)√º3√®¬µo√°}‚Äû√µfÀÜn$Àú(¬π√ª‚Äì‚Äî?∆í√µ`=√º¬æ√´^√´j4√ßÔøΩr¬§wÔøΩva√ü~}(@=≈æ√Ø≈æc√≥√™√∏ÔøΩ[^‚Ä†√Ø2√•}‚Ä¶<(√æ√Ω‚Äì≈ìn¬∏¬ª√¥¬æ√´mtm‚Ç¨zw√≤f√°h(‚Ä∫u√≤"¬¨√üq√¶‚Äî√∫ÔøΩ∆í¬¨?√æ√µ√¥,√™√†c‚Ä∞z√Ω√´.~√µ¬´√±√™√¨√∑^~s√®√ª'√æ√∏></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://carrv.github.io/2020/papers/CARRV2020_paper_15_Zhao.pdf">https://carrv.github.io/2020/papers/CARRV2020_paper_15_Zhao.pdf</a></em></p>]]>
            </description>
            <link>https://carrv.github.io/2020/papers/CARRV2020_paper_15_Zhao.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23891502</guid>
            <pubDate>Sun, 19 Jul 2020 18:56:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Stand Out as an Entry-Level Software Engineer]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23891359">thread link</a>) | @xavierlv
<br/>
July 19, 2020 | https://xavierlv.com/posts/how-to-stand-out-entry-level-software-engineer/ | <a href="https://web.archive.org/web/*/https://xavierlv.com/posts/how-to-stand-out-entry-level-software-engineer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
  <a href="https://xavierlv.com/static/6e25c048bb92cd12e9c53891397a5e30/dd241/sheep.jpg" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Standing out in a crowd of sheeps. Photo by @jannerboy62 on Unsplash" title="" src="https://xavierlv.com/static/6e25c048bb92cd12e9c53891397a5e30/828fb/sheep.jpg" srcset="https://xavierlv.com/static/6e25c048bb92cd12e9c53891397a5e30/ff44c/sheep.jpg 158w,
https://xavierlv.com/static/6e25c048bb92cd12e9c53891397a5e30/a6688/sheep.jpg 315w,
https://xavierlv.com/static/6e25c048bb92cd12e9c53891397a5e30/828fb/sheep.jpg 630w,
https://xavierlv.com/static/6e25c048bb92cd12e9c53891397a5e30/0ede0/sheep.jpg 945w,
https://xavierlv.com/static/6e25c048bb92cd12e9c53891397a5e30/3ac88/sheep.jpg 1260w,
https://xavierlv.com/static/6e25c048bb92cd12e9c53891397a5e30/dd241/sheep.jpg 4470w" sizes="(max-width: 630px) 100vw, 630px">
    </span>
  </span>
  
  </a>
    </p>
<p>Starting your career as a software engineer can be challenging, especially if it‚Äôs your first job. I was there eight years ago, starting at my first tech job after moving to a new city, speaking a new language. Books, experiences, and people taught me how to navigate the early part of my career, so I thought I‚Äôd highlight a few of those lessons I learned with this post. I hope that applying some of these will make you stand out and accelerate your early career as a developer.</p>
<h3>Always be learning</h3>
<p>You don‚Äôt stop learning after you leave college or your Bootcamp; learning is considered a lifelong journey in this field. Read books and articles, take courses, and participate in workshops and hackathons. Bonus Tip: Sometimes, companies pay for you to do all this, ask your manager if this is something you can expense.</p>
<h3>Don‚Äôt assume existing code is untouchable</h3>
<p>Well-intentioned code can have anti-patterns in it, be hard to read, get stale over time, and it can create bugs. So go ahead and suggest a change to the code, it may need it.</p>
<h3>Healthy Habits = Good Code</h3>
<p>Keeping healthy habits may sound obvious, but we don‚Äôt often apply it. We need to move, sleep, and eat well to have the energy we need to be great. For example, it took me a long time to realize that delicious but heavy lunch meals would make me feel tired every afternoon, which affected my performance and meant I had to work longer hours to compensate for it. Everyone‚Äôs different, but learn what your body needs and treat it well.</p>
<h3>If in doubt, underpromise and overdeliver</h3>
<p>This is especially true early on, but it continues to be right for me eight years later. If your goal is to match and exceed expectations consistently, it is best to consistently deliver on your goals and surprise people with your speed than to promise the moon but always be late.</p>
<h3>Embrace the grunt work</h3>
<p>See a problem? Volunteer to help fix it. See an area of improvement? Say yes to working on it. Being proactive has multiple benefits. As a result of it, the product improves, the productivity and morale of those around you go up, you learn a new skill, and you gain the respect of others. You can then use this goodwill and track record to work on more exciting things over time.</p>
<h3>Code is social</h3>
<p>It‚Äôs pretty standard for engineers to review each other‚Äôs code at software companies. Don‚Äôt think this is only something that only experienced engineers do, though. Review your teammates‚Äô code and learn from it. Don‚Äôt just read it, but also comment on it and ask questions. Learn from how people write code.</p>
<h3>Feedback = Improvement</h3>
<p>Explicitly ask for feedback from your manager and teammates. Use this feedback to transform yourself continuously. Remember that one of the best ways to learn is by doing the wrong thing, realizing why it‚Äôs wrong, and then not doing it anymore. Rinse and repeat.</p>
<h3>Take ownership of something</h3>
<p>Work with your manager to find something that can be yours. Working on a project of your own gives you a way to be unique, learn about all the stages of development, and cultivate accountability.</p>
<h3>Look for the low-hanging fruits</h3>
<p>There are many small things in the codebase that you can do with your current skillset. Taking these on and showing off your skills right away is an excellent way to get noticed.</p>
<h3>Don‚Äôt forget that experienced engineers have screwed up before</h3>
<p>We made the same mistakes you‚Äôre making, probably even more of them. We just learned from them already, so we look better to you now x years later.</p>
<h3>Be everywhere</h3>
<p>Show up every day to discuss problems, answer your teammates‚Äô questions, celebrate wins, and provide the very least moral support when things go wrong. You want others to think that you‚Äôve been at the company for much longer.</p>
<h3>Speak up</h3>
<p>It‚Äôs a good idea to be humble in general, but you also want to communicate your thoughts, even if you lack experience. People like to see new people with different perspectives add to the conversation.</p>
<h3>Build relationships</h3>
<p>Talk to your teammates, not just the engineers. It may not seem obvious now, but your job satisfaction will likely have a lot to do how comfortable you feel with the people around you. You‚Äôll spend time with them 40 hours a week, which is close to half of your waking life.</p>
<h3>Rely on&nbsp;your manager</h3>
<p>Ask your manager to help you plan out your goals and to keep you accountable. They‚Äôre there for you, use their time and support wisely.</p>
<h3>Have fun</h3>
<p>You want to enjoy doing this because you‚Äôll likely be doing it for many years. Find projects that connect with you, work on problems that excite you.</p>
<h3>Find mentors</h3>
<p>Have lunch, coffee with more experienced engineers, develop a rapport with them and ask them every question you have, most of them won‚Äôt mind it, and some of them will even love to talk to you (I find myself in this camp).</p>
<p>It‚Äôs a long journey, but I hope this can serve you in your first several years. Above all else, stay true to yourself.</p></div></div>]]>
            </description>
            <link>https://xavierlv.com/posts/how-to-stand-out-entry-level-software-engineer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23891359</guid>
            <pubDate>Sun, 19 Jul 2020 18:34:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Eurozone‚Äôs grappling with crisis, class war and the North-South divide]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23891282">thread link</a>) | @jcfrei
<br/>
July 19, 2020 | https://www.yanisvaroufakis.eu/2020/07/16/the-eurozones-grappling-with-crisis-class-war-the-north-south-divide-berliner-verlag-interview/ | <a href="https://web.archive.org/web/*/https://www.yanisvaroufakis.eu/2020/07/16/the-eurozones-grappling-with-crisis-class-war-the-north-south-divide-berliner-verlag-interview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<article id="post-22719">

		<section>
			

			<h3><span><strong><img src="https://i0.wp.com/www.yanisvaroufakis.eu/wp-content/uploads/2020/07/Screenshot-2020-07-16-at-9.53.43-AM.png?resize=2424%2C772&amp;ssl=1" alt="" width="2424" height="772" srcset="https://i0.wp.com/www.yanisvaroufakis.eu/wp-content/uploads/2020/07/Screenshot-2020-07-16-at-9.53.43-AM.png?w=2424&amp;ssl=1 2424w, https://i0.wp.com/www.yanisvaroufakis.eu/wp-content/uploads/2020/07/Screenshot-2020-07-16-at-9.53.43-AM.png?resize=1536%2C489&amp;ssl=1 1536w, https://i0.wp.com/www.yanisvaroufakis.eu/wp-content/uploads/2020/07/Screenshot-2020-07-16-at-9.53.43-AM.png?resize=2048%2C652&amp;ssl=1 2048w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1">What did you think when the Euro-group elected its new leader last week? At least this was not the outcome Frau Merkel had wished?</strong></span></h3>
<h3>My first thought was that it spelled the end of any possibility of harmonizing corporate tax rates across the Eurozone, an issue that I am on Mrs Merkel‚Äôs side. The second thought was that the Irish finance minister‚Äôs victory was a victory for forces pushing for greater, not less, austerity across the European Union. It was not a good moment for Europe. [From the above you can see that I never automatically opposed whatever Mrs Merkel favoured!]</h3>
<h3><span><strong>If you look at fiscal and monetary politics in the Euro area today ‚Äì what is your impression? Have the Europeans learnt a lesson from the Greek crisis?</strong></span></h3>
<h3>To begin with, please let us not conflate Europe‚Äôs rulers with the‚Ä¶ Europeans. Turning now to your question, Europe‚Äôs leaders resemble the Bourbons: they have forgotten nothing and they have learned nothing. More precisely, while the ECB‚Äôs monetary policy reaction has been far improved since Mario Draghi succeeded the catastrophic Jean-Claude Trichet‚Äôs, monetary policy has long ago reached the limits of what it can do. So, the only thing that matters now is Europe‚Äôs fiscal stance.</h3>
<h3><span>Our fiscal stance remains the most tepid and the weakest amongst developed economies. It must be considered yet another dereliction of duty for two reasons, one ex ante and one ex post.</span></h3>
<h3>The ex ante failure has to do with what we are doing now, in 2020: Taking out all the loans provided to business (that are irrelevant fiscally), the fiscal injections into the EU economy are: (a) small overall and (b) hopelessly lopsided, with Germany on the one hand pumping a great deal more fiscal power into its economy while Italy and Spain cannot ‚Äì the result being a magnification of Europe‚Äôs greatest weakness: our internal imbalances.</h3>
<h3>The ex post failure stems from the demise of the idea of a Eurobond ‚Äì the only instrument that could prevent, in 2021 or 2022 (when the fiscal compact is re-energised) massive new austerity in countries like Italy and Spain. Since the budget deficit of these countries will exceed 10% of GDP, you can imagine that the fiscal consolidation necessary to return to the fiscal compact is going to produce a further increase in the imbalances that have been tearing the Eurozone apart since 2010.</h3>
<h3><span><strong>You are very critical of the European Recovery Fund. Why?</strong></span></h3>
<h3>For at least three important reasons: First, it was devised as a substitute to the Eurobond, which it is not. Secondly, because its structure is divisive and likely to cause greater disunity among Europeans. Thirdly, because it will be too little and it will come too late to counter-act the new austerity that the re-introduction of the fiscal compact will bring. Let me explain these three objections in greater detail.</h3>
<h3>While it is true that the Recovery Fund involves a degree of common debt, it is explicitly (and legally) designed as a one-off debt with specific details on how and when it will be repaid. Thus, we have wasted a fantastic opportunity to create the equivalent of US Treasury Bills, which is what makes the dollar powerful and the United States far better placed to absorb shocks.</h3>
<h3>Moreover, I am appalled that the Commission specified in advance, based on backward looking data, which country will receive how many billions. It was an awful thing to do because it set one country, one people, against another. What we needed was a sum that would be diverted to regions in Europe most in need of support. There are poor parts of Germany that will be hit more than richer parts of Spain. The total sum available should be distributed ex post on the basis of the needs of particular European regions and sectors, not by means of the usual sordid bargain in Brussels that divides a pie between governments.</h3>
<h3>Lastly, this Recovery Fund will do very little to ameliorate the austerity that the re-introduction of the fiscal compact will necessitate. It will fail in the same way that the many billions of the structural funds failed to ameliorate the effects of austerity between 2010 and 2016.</h3>
<h3><span><strong>What consequences will the Fund have in Europe?</strong></span></h3>
<h3>It will entrench the false view in Northern Europe that it was all about hand-outs to the Southerners while, at once, entrenching the false view in Europe‚Äôs South that the whole of the North benefits from pushing the South into greater impecunity.</h3>
<h3><span><strong>What will happen to the working class people in the Euro-Zone?</strong></span></h3>
<h3>It will continue to watch its prospects decline both in the North and in the South while the financiers and the members of the boards of directors of large companies enjoy the fruits of socialism for the oligarchy and stinging austerity for the majority of the Greeks and of the Germans.</h3>
<h3><span><strong>Will the consequences be different for Greece and Germany, aka South and North?</strong></span></h3>
<h3>Yes and no. Workers in the North and in the South will be facing increasing precarity and will be getting angrier and more discontented. Except that the rate of deterioration will be much greater in countries like Greece, the result being the continuation of the mass exodus of young people which makes our countries of the South impossible to sustain as functioning societies.</h3>
<h3><span><strong>What role are the ‚Äúfrugal four‚Äù playing ‚Äì isn‚Äôt it legitimate to keep in mind the public debt in each country?</strong></span></h3>
<h3>Governments have a duty to defend their people from a number of threats. One of them is excessive public debt. But, there is also excessive private debt. And, even more ominously, low investment that jeopardises a nation‚Äôs chances to repay both private and public debt. The so-called frugal four are working in favour of large conglomerates that want their cake and to eat it: They like the effect Italy and Greece are having at keeping the exchange value of the euro low (so as to maximise their exports, eg, to China) and the interest rates below zero (so as to get free money from the ECB). Like all free-riders, they take what suits them but then take no responsibility for the damage that the policies favouring them do both to the South and to their own working classes (which find themselves increasingly squeezed and indebted as part of the same process that squeezes and indebts the South).</h3>
<h3><span><strong>You frequently speak of ‚Äúoligarchs‚Äù ‚Äì who are they in Europe?</strong></span></h3>
<h3>In the early fifties, when the EEC was first created, they were the captains of the steel and coal industries. Soon after, they were joined by the electrical goods industries plus the automakers. In the 1980s the captains of industry were increasingly sidelined by the bankers who, by 2008, had ended up as the masters of Europe‚Äôs destiny.</h3>
<h3><span><strong>Can the European oligarchs at least provide new jobs and/or be competitive with the US or China?</strong></span></h3>
<h3>Absolutely not. The capacity of European financialised capitalism to produce good quality jobs is at its nadir and is getting worse and worse due to the EU‚Äôs failure to create the public finance instruments that DiEM25 has been proposing for years now ‚Äì e.g. a joint European Investment Bank and European Central Bank program by which EIB-bonds can be backed by ECB-bonds to mobilise idle cash (that is currently destroying German pension funds) and turn it into green investments.</h3>
<h3><span><strong>Most observers have no doubt that there will be austerity in exchange of money from the fund. What austerity else can Greece bear, keeping in mind the sacrifices that have already been made?</strong></span></h3>
<h3>This is like asking a patient nearing death as a result of having been subjected to massive radiation how much more radiation she can take!</h3>
<h3><span><strong>What is the current state of the Greek economy? Debt is still at 180 percent, despite 200 billion Euro for bailing out the banks?</strong></span></h3>
<h3>Greece‚Äôs debt is unpayable not despite but <u>because</u> of the banks‚Äô bailout. Since 2009 I have been saying that Europe‚Äôs rulers, and this is where I do blame Mrs Merkel, cynically saved idiotic bankers by transferring their losses onto the shoulders of Europe‚Äôs weakest taxpayers. Mrs Merkel, Mr Sarkozy, the troika and everyone else who has maintained this crime-against-logic for a decade will forever by guilty in the conscience of Europe‚Äôs progressives. [And, by the way, Greece‚Äôs debt is not well about 200% of GDP!]</h3>
<h3><span><strong>What will Europe look like if the Recovery Fund really delivers on 750 billion Euro?</strong></span></h3>
<h3>Sad and divided. For a start, of these 750 billions, 250 billions will be loans. The last thing Europe‚Äôs devasted businesses that are facing insolvency is more loans ‚Äì Greece‚Äôs fate provides a great lesson to those who refuse to recognise this simple truth. As for the remaining 500 billions, more than 100 of them are re-purposed funds (i.e. not new money) and another 200 will be sacrificed to buy the frugal four‚Äôs consent. That leaves us with, at best, 300 billion. It sounds a lot but it is puny. Over three years it comes to less than 1% of GDP. Given that the austerity that Berlin will demand and Brussels will impose will be more than 4% of GDP over the same year, the only conclusion is that, as the pandemic (hopefully) subsides, European capitalism will be inflicting another unnecessary blow to itself ‚Äì just as in 2010.</h3>
<h3><span><strong>In your view ‚Äì what would be an adequate program to cope with the Corona-devastation?</strong></span></h3>
<h3>DiEM25 has already answered this ‚Äì our <a href="https://diem25.org/diem25-presents-covid-19-economic-response-plan-and-green-recovery-investment-program/">3 point plan</a>.</h3>
<ol>
<li>
<h3>The ECB must issue a long-maturity, 30-year, Eurobond for ‚Ç¨1 trillion euros solely backed by the ECB,&nbsp;with the possibility of further issuance in needs be. This ‚Ç¨1 trillion should then be used to replace national debt, in proportion to the coronavirus-induced regional recessions &amp; public health costs.</h3>
</li>
<li>
<h3>The ECB must inject a ‚Ç¨2000 European Solidarity Cash Payment to every European resident</h3>
</li>
<li>
<h3>The EU must create a European Green Recovery &amp; Investment Program funded by <em>EIB bonds&nbsp;approximately equal to 5% of the EU‚Äôs GDP, to be backed in the bond markets by the ECB</em>.</h3>
</li>
</ol>
<h3><span><strong>You are talking about ‚Äúclass war‚Äù. Are we already there?</strong></span></h3>
<h3>We have been there since 2010. The austerity imposed upon Greece in May 2010 was the first move toward a fiscal ‚Ä¶</h3></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.yanisvaroufakis.eu/2020/07/16/the-eurozones-grappling-with-crisis-class-war-the-north-south-divide-berliner-verlag-interview/">https://www.yanisvaroufakis.eu/2020/07/16/the-eurozones-grappling-with-crisis-class-war-the-north-south-divide-berliner-verlag-interview/</a></em></p>]]>
            </description>
            <link>https://www.yanisvaroufakis.eu/2020/07/16/the-eurozones-grappling-with-crisis-class-war-the-north-south-divide-berliner-verlag-interview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23891282</guid>
            <pubDate>Sun, 19 Jul 2020 18:24:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My failed startup: Why it failed and why I‚Äôm releasing all the source code]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23891111">thread link</a>) | @ve55
<br/>
July 19, 2020 | https://adamfallon.com/2020/07/18/my-failed-start-up/ | <a href="https://web.archive.org/web/*/https://adamfallon.com/2020/07/18/my-failed-start-up/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p><em>Why it failed and why i‚Äôm releasing all the source code for free.</em></p>



<div><p>This is a long post.</p><p>If you are just looking for the code click <a href="#the-code">here</a></p></div>



<p>When lockdown started in the U.K I started looking for ways to spend my extended time at home. I wasn‚Äôt working because I had quit my job on Feb 16th to travel the world. Timing has never been my strong suit. </p>



<p>So instead of sitting around I decided to start a contracting company, got awarded a few small contracts and I released a <a aria-label="undefined (opens in a new tab)" href="https://apps.apple.com/gb/app/nitronotes/id1502080216" target="_blank" rel="noreferrer noopener nofollow">few</a> <a aria-label="undefined (opens in a new tab)" href="https://apps.apple.com/dz/app/countdownplusplus/id1497707393" target="_blank" rel="noreferrer noopener nofollow">apps</a> written in SwiftUI. But I wanted a bigger project to sink my teeth into. </p>



<p>There were two ideas I kept coming back too;</p>



<ol><li>A hosted org-mode in the browser. </li><li>Some sort of local social network.</li></ol>



<p>Given that everyone was forced into their home I thought it would be the perfect time for something like the app <a href="https://en.wikipedia.org/wiki/Yik_Yak" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener nofollow">YikYak</a> to make a comeback. </p>



<h3>Ghosts of apps past.</h3>



<p>For those who never got a chance to use YikYak let me try to explain it quickly. The app touted itself as the first hyperlocal social network. A users post could only be viewed it if you were no further than 5km <a href="https://adamfallon.com/2020/07/10/recreating-yikyak-with-postgres/" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">from the initial post location</a>. You could vote posts up or down and comment underneath posts. It was simple but unique.</p>



<p>YikYak eventually implemented some <a href="https://www.reddit.com/r/yikyak/comments/8sgynk/what_exactly_caused_the_fall_of_yik_yak/" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">very unpopular changes</a>. Bullying, Racism and Doxxing was always a problem on YikYak. They didn‚Äôt do a huge deal to moderate the content on the app, instead leaving the community to self-police. Eventually they had to do <strong><em>something</em></strong> so they enforced email or telephone signups. </p>



<p><em>Cue mass exodus of users</em>.</p>



<h3>Introducing Ottr ü¶¶</h3>



<p>So I began work on Ottr in early February.</p>



<p>Ottr was going to be YikYak for the people in lockdown. In the same way TikTok came from the ashes of <a href="https://en.wikipedia.org/wiki/Vine_(service)" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener nofollow">Vine</a> ‚Äì Ottr was to be the refinement of the ideas behind YikYak.</p>







<p>A user could create a new post and comment underneath other posts. They could upvote or downvote posts. They could click the Explore button and whisk off to a new location. You could share posts to Reddit or Twitter. I got all of these features working in a web app created in React, and an iOS app. It got funding from the Amazon Activate program.</p>



<div><figure><img data-attachment-id="493" data-permalink="https://adamfallon.com/2020/07/18/my-failed-start-up/ottr-2/" data-orig-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/ottr.png?fit=572%2C481&amp;ssl=1" data-orig-size="572,481" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ottr" data-image-description="" data-medium-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/ottr.png?fit=300%2C252&amp;ssl=1" data-large-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/ottr.png?fit=572%2C481&amp;ssl=1" src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/ottr.png?w=580&amp;ssl=1" alt="Components of ottr - my failed startup" srcset="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/ottr.png?w=572&amp;ssl=1 572w, https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/ottr.png?resize=300%2C252&amp;ssl=1 300w" sizes="(max-width: 572px) 100vw, 572px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/ottr.png?w=572&amp;ssl=1 572w, https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/ottr.png?resize=300%2C252&amp;ssl=1 300w" data-lazy-src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/ottr.png?w=580&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>The components of Ottr</figcaption></figure></div>



<p>But as of today Ottr is dead. I‚Äôm going to talk about why I no longer believe in the idea, the key failures that lead to that decision and why I am releasing absolutely everything I made.</p>



<h3>On anonymity.</h3>



<p>For all its flaws ‚Äì I absolutely loved YikYak. It came out the first year of my bachelors degree. It was by far the most used app on campus. I would be sitting in the university library and someone would post about the weird smell coming from the desks on the 3rd floor. Or the little nod the doorman would give you on your way in. </p>



<p>People would post about the crazy antics of their friend on a drunken night out. About the cute doggo‚Äôs in the parks. Or how awful the food from the students union was. Maybe they would post about their crush.</p>



<p>Those posting on YikYak were having the same experience you were. They were seeing the same things as you, and that made you feel engaged. It was anonymous, which ended up being a double edge sword. It allowed for great humour and creativity, but sometimes the jokes went too far.</p>



<p>Anonymity would be YikYak‚Äôs greatest strength and its most fundamental weakness. </p>



<h3>And yet‚Ä¶</h3>



<p>People got hurt using YikYak. Anonymity breeds toxicity ‚Äì there are clear precedents for this on the internet ‚Äì 4chan, 8chan and Reddit. </p>



<p>I knew that there was potential for this to happen again ‚Äì but I thought I could solve it. My thought process was; </p>



<ul><li>I will add a report button and over time I can just add moderators to keep on top of the reports.</li><li>Posts will be removed when they get downvoted too much.</li><li>I will redact PPI and add profanity filters.</li></ul>



<p>This arrogance was mistake number 1. When I eventually let a few people use the site they broke the profanity filters with ease. Even among ~100 users people wrote spam and cluttered up the front page. Going on the site in the first week made me wince at how ugly it looked, with people filling the character limit with posts consisting entirely of emoji. It made the site look amateur.</p>



<p>Moderation on the internet is an unsolved problem. Handing the moderation over to automated systems will mean bias can creep in, and it‚Äôs hard (impossible?) to tune between zealotry and permissiveness. With an automated system you are going to upset some people. </p>



<h3>Humans &gt; Robots?</h3>



<p>Humans are better at moderation, but they cost much more money and come with their own problems. I think the shining example of human moderation is Hacker News. Daniel Gackle and Scott Bell tackle the problems inherit of internet forums with a competence not seen elsewhere.</p>



<p>The New Yorker wrote <a aria-label="undefined (opens in a new tab)" href="https://www.newyorker.com/news/letter-from-silicon-valley/the-lonely-work-of-moderating-hacker-news" target="_blank" rel="noreferrer noopener nofollow">this</a> great article about how difficult that is to achieve ‚Äì and that‚Äôs with Hacker News having a <em>distinct voice</em>. Hacker News is a place for people to post about things that are intellectually interesting to hackers. </p>



<p>Ottr didn‚Äôt have a clear voice ‚Äì it was a place for people to post about things going on in their community. That could mean anything.</p>



<p>Something that is acceptable in one location, might not work for people elsewhere. You could have moderators from each community ‚Äì but then you are giving that moderator a lot of power to make others unhappy. </p>



<p>I think Reddit is a horrible place for new posters ‚Äì and part of the blame falls on moderators having too much power. Some moderators on Reddit have so much power they can control the front page, and with that, the tone of the site. I <em>really</em> didn‚Äôt want that.</p>



<h3>It appears we‚Äôre at an impasse.</h3>



<p>So if humans and robots couldn‚Äôt be trusted, what could? Ottr made the same compromise YikYak did ‚Äì of letting the community police itself ‚Äì and it failed (I think) because too few people used Ottr. </p>



<p>A self policing community has great potential to trend towards its worst elements. If someone posted something false about me on the internet, I would have great incentive to downvote it ‚Äì but why would anyone else ‚Äì especially when there was the potential for scandal, entertainment and outrage.</p>



<p>I care about how the site looks to first time users, but why would anyone else?</p>



<p>And so those stupid emoji posts stayed on the front page.</p>



<h3>Is anybody alive out there?</h3>



<p>So poor moderation options left Ottr open to the same kinds of toxicity that YikYak failed to combat. The second key issue was the fact that <em>I don‚Äôt know how to get people to use Ottr in the first place</em>.</p>



<p>I‚Äôve never read a book on growth hacking or how to make your product sticky. I kind of understand when its happening to me (‚ÄúHand over your contacts to get some shiny coins?‚Äù, ‚ÄúHow about you share this post on Facebook and Twitter?‚Äù, ‚ÄúOur site is restricting registrations at this time ‚Äì Sign up with your email to be notified when we have an opening?‚Äù), but it always rubbed me the wrong way. </p>



<p>I wanted a few people to start using Ottr and then they would be so blown away by how good it was that they would tell their friends and share it themselves. </p>



<h3>Build it and they will come?</h3>



<p>I focused on UX simplicity and features and the idea of getting people to use it was always running on a low priority background thread. Instead of getting the first iteration up and focusing on what people said about that, I had a clear vision of what it was to be like, what I would add from YikYak, what I would change, and then I would hand it to the people and they would say ‚ÄúYes Adam ‚Äì very good, thank you!‚Äù.</p>



<p>Treating user growth as a secondary concern is the dumbest thing you can do for a social network. It is <em>all that matters.</em> Mistake #2 was thinking I was above this somehow. I treated growth-hacking and user-growth as something for other people to be concerned with. That is a juvenile approach to business. Because I can code doesn‚Äôt mean that I am somehow too pure to engage in the business of marketing or advertising the things I code. </p>



<p>I am working on fixing that this year and i‚Äôm trying to understand, rather than scoff, at the ideas behind growing and marketing the things I make. So far it seems much more difficult than learning to code. I didn‚Äôt understand or appreciate this until I reflected on the time I spent on Ottr.</p>



<h3>Burn, Baby Burn.</h3>



<p>By copying the mistakes of YikYak and ignoring the fundamentals behind making a social network work it meant that Ottr never got off the ground. You might argue that I didn‚Äôt try for very long ‚Äì and you are right, I didn‚Äôt, around 4 months in total. Mistake #3 is the real reason I wanted to be done with the whole project. I was completely burnt out.</p>



<p>As I mentioned before, I had just quit my job in February to travel. For reasons I won‚Äôt go in to, consuming myself with Ottr directly after leaving my last job was a really bad idea. </p>



<p>As I couldn‚Äôt travel because of the pandemic and because I had already planned for my mini-retirement I had enough money that meant I didn‚Äôt need to jump into another job. The contract work I was getting was not very engaging ‚Äì so I suddenly had a lot of free time. </p>



<p>So I threw myself into Ottr. I remember looking at ScreenTime stats at the time and it showing emacs being open for 80+ hrs a week. I stopped reading. Stopped watching movies. From waking up to going to sleep i‚Äôd just be working on it. Ottr went through a few iterations and I threw huge chunks of work away at points. </p>



<h3>Then the wheels came off.</h3>



<p>Then one fine day it all stopped being worth it. I was riding along on a wave of getting the next feature done. Talking to a partner at Amazon helping with deployment. Tinkering with CloudFlare because I thought now it‚Äôs going into production, I will obviously be inundated. But when it came time where it was actually ‚Äúready‚Äù, I became immediately repulsed of the idea of trying to grow Ottr. </p>



<p>Doubt crept in. ‚ÄúThis is just a copy of YikYak‚Äù, and it was, but YikYak doesn‚Äôt exist anymore. There is nothing new under the sun.</p>



<p>No matter how hard I tried I couldn‚Äôt ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://adamfallon.com/2020/07/18/my-failed-start-up/">https://adamfallon.com/2020/07/18/my-failed-start-up/</a></em></p>]]>
            </description>
            <link>https://adamfallon.com/2020/07/18/my-failed-start-up/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23891111</guid>
            <pubDate>Sun, 19 Jul 2020 18:03:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Accelerating iOS on QEMU with hardware virtualization (KVM)]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23891034">thread link</a>) | @mdelias
<br/>
July 19, 2020 | https://alephsecurity.com/2020/07/19/xnu-qemu-kvm/ | <a href="https://web.archive.org/web/*/https://alephsecurity.com/2020/07/19/xnu-qemu-kvm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div ?="">

<p>While QEMU started out as a platform for emulating hardware (especially
architectures not supported by the host CPU), later versions gained the ability
to execute code using hardware-assisted virtualization. This can yield
substantial performance benefits, since most executed opcodes are performed
directly by the CPU, instead of being translated into a number of native
opcodes that simulate the behavior of the original one.</p>
<p>Using virtualization requires a host CPU that supports the executing
architecture. On an Intel-based machine (such as those we used for developing
our iOS on QEMU project), virtualizing an architecture other than x86/x64
would be impossible. Therefore, when running iOS (an arm64 OS) on QEMU, we‚Äôd be
using regular emulation. At first, the performance was more than adequate. But
as our efforts to execute iOS on QEMU developed, and more parts of the
operating system were brought up successfully, we started noticing degraded
performance.</p>
<p>Modern ARM chips support hardware-assisted virtualization, similar to their x86
bretheren. If we were to run our version of QEMU on an ARM-based system, it
should be possible to harness the virtualization capabilites of the underlying
CPU in order to achieve near-native performance. This post documents the
challenges we had to overcome in order to successfully boot our iOS system on
QEMU using hardware-assisted virtualization.</p>

<p>When moving away from an Intel-based laptop to an ARM-based system for
development, the first question was, which platform to choose. Should we use an
ARM server in the cloud? An ARM-based development board? A developer-friendly
Android phone? Each of the options seemed to have its advantages.</p>
<p>An ARM server would easily be the most powerful of the bunch - but the
selection of ARM-based dedicated servers is limited, they aren‚Äôt cheap, and we
weren‚Äôt sure we‚Äôd get the level of access we‚Äôd need (our assumption was that
recompiling the kernel would be required). Buying a physical server is an
option we entertained for a short while, but with prices in the thousands of
dollars, the idea was quickly discarded.</p>
<p>A used Android phone was another good candidate, but even developer-friendly
phones might be difficult to work with. Using Android instead of a
general-purpose Linux could be a limiting factor - and finding a phone with
enough RAM to execute iOS in parallel with a full-blown Android environment
would require us to go with a recent phone, which would not be cheap.</p>
<p>An ARM-based development board looked like a good choice, that would let us
test and develop our code at a fraction of the price of the alternatives.
Looking for good aftermarket support for kernel development, 64-bit ARM SOCs,
and no less than 4GB of RAM, we chose Pine Rock64 as our testbed:</p>
<p><img src="https://alephsecurity.com/assets/img/qemu-kvm/pine64_rock64_angle_53e8db18-d784-4a66-879b-e413d4e50c3c_550x350.webp" alt="Pine Rock64"></p>
<p>The board comes with an arm64 CPU (Cortex-A53-based RK3328), as well as 4GB of
RAM. The choice seemed perfect for our purpose: when emulating an iPhone, we
successfully used Cortex-A53 as our CPU, and while 4GB of RAM wasn‚Äôt ideal
(we‚Äôd usually run our emulation with 6GB of RAM dedicated to QEMU), our tests
indicated that using less RAM (for example, 2GB) had no significant impact at
this point.</p>

<h2 id="enabling-kvm-in-qemu">Enabling KVM in QEMU</h2>
<p>Once our board was up and running the latest version of Armbian, it was time
for our first attempt to run QEMU while using hardware-assisted virtualization
of the CPU in place of emulation. In theory, one simply has to add the
<code>-enable-kvm</code> switch to the command line‚Ä¶</p>
<p>Unfortunately, it wasn‚Äôt that easy. While QEMU launched successfully, iOS
wouldn‚Äôt boot. Attaching gdb on boot let us see the instructions we executing
correctly at first, but upon continuing, we‚Äôd quickly find ourselves in an
infinite loop located at <code>0xfffffff0070a0200</code>. Based on the kernel symbols, it
was one of the vectors for interrupt/exception handling. Reaching that code
meant an exception occured early on, and the operating system still hasn‚Äôt
reached a point where it could be handled more gracefully (such as dumping
registers and memory content, combined with at least some sort of the issue
description). We had no choice but to step through the early initialization
of the kernel, one instruction after the other, until the jump to the exception
vector occured.</p>
<h2 id="enabling-the-mmu">Enabling the MMU</h2>
<p>At this point, it‚Äôs important to note, that when the kernel is loaded for the
first time, the MMU isn‚Äôt enabled yet, and the code is mapped to physical
addresses (the execution begins at <code>0x470a5098</code>). It is only later during the
initialization that the MMU is enabled (once the page tables are initialized),
and the addresses switch to the familiar kernel mode (with higher bits set to
1). When looking at the kernel image in a disassembler such as Ghidra, however,
all code is mapped to kernel addresses. Therefore, the initialization code we
were inspecting could be found at <code>0xfffffff0070a5098</code>.</p>
<p>Some of the initialization code contains loops that execute many times. In
order to make following the execution more effective, we used breakpoints that
we set at small intervals. This let us continue the execution, instead of
stepping through each instruction and loop. Using this technique, we quickly
found out the exception occured at the address <code>0x470a72e4</code>:</p>
<pre><code>0x470a72d4     msr      vbar_el1, x0
0x470a72d8     movz     x0, 0x593d
0x470a72dc     movz     x1, 0x3454, lsl 16
0x470a72e0     orr      x0, x0, x1
0x470a72e4 ==&gt; msr      sctlr_el1, x0
0x470a72e8     isb
0x470a72ec     movz     x0, 0
0x470a72f0     msr      tpidr_el1, x0
</code></pre>
<p>As we can see, at the mentioned address, the value <code>0x3454593d</code> is written into
the <code>SCTLR_EL1</code> register. As per ARM DDI 0487, D13.2.113, this is the system
control register, that provides a top level control of the system at EL0 and
EL1. Its first bit is used to enable address translation via the MMU. Since the
exception happens when executing this instruction (and bit 0 is set in the new
value for the register), the address translation configuration was an immediate
suspect.</p>
<p>There are several registers used to configure the MMU - namely, <code>TCR_EL1</code>,
<code>TTBR1_EL1</code>, and <code>MAIR_EL1</code>. We inspected the values stored in those registers
prior to enabling the MMU. One field that stood out was <code>TCR_EL1.TG1</code>, that
indicates the granule size for the <code>TTBR1_EL1</code>. The initialization code of our
iOS kernel sets the value of <code>TCR_EL1.TG1</code> to <code>0b01</code> (the field is stored in
bits 31:30, and the value written to <code>TCR_EL1</code> at <code>0x470a7244</code> is
<code>0x000000226519a519</code>). The value of <code>0b01</code> corresponds to a granule size of
16KB.</p>
<p>Notably, after stepping through the <code>msr</code> instruction at <code>0x470a7244</code>,
inspecting the value of <code>TCR_EL1</code> revealed a slightly different value of
<code>0x00000022a519a519</code> - the granule size was read out as <code>0b10</code> (4KB)! This made
the reason for an exception upon enabling the MMU clear: while the page tables
set up by the initalization code were designed with a 16KB granule size in
mind, the actual granule size stored in <code>TCR_EL1</code> when enabling the MMU was set
to 4KB. The MMU treated the page entries incorrectly, and a page fault occured
immediately upon enabling the MMU. But why would the value we attempted to set,
that of a 16KB granule, wouldn‚Äôt stick?</p>
<p>ARM DDI has the following to say about setting the value of <code>TCR_EL1.TG</code>:</p>
<div><div><pre><code>If the value is programmed to either a reserved value, or a size that has not been implemented, then the hardware will treat the field as if it has been programmed to an IMPLEMENTATION DEFINED choice of the sizes that has been implemented for all purposes other than the value read back from this register.

It is IMPLEMENTATION DEFINED whether the value read back is the value programmed or the value that corresponds to the size chosen.
</code></pre></div></div>
<p>In our case, <code>TCR_EL1.TG</code> is read back as <code>0b10</code> after attempting to set it to
<code>0b01</code>. This indicates that in our case, the read back value is one that
corresponds to the granule size chosen (since it‚Äôs not the value we
programmed), and that the 16KB size has not been implemented in our CPU. We can
verify this assumption with the help of the <code>ID_AA64MMFR0_EL1</code> register
(AArch64 Memory Model Feature Register 0). Its field TGran16 (at bits 23:20)
is used to indicate support for 16KB memory translation granule size: when the
bits are all set to 0, the granule size is <em>not</em> supported. Reading the value
of the register on our Rock64 developer board returns the value of
<code>0x00001122</code> - thus, bits 23:20 are set to zero, and our CPU doesn‚Äôt implement
the 16KB granule size. In fact, by referring to section 4.2.1 in ARM DDI 0500
(ARM Cortex-A53 MPCore Processor Technical Reference Manual), we can see that
the value of <code>0x00001122</code> is there by design - i.e., Cortex-A53 cores do not
implement the 16KB granule size. Interestingly, the Cortex-A53 implementation
in QEMU ignores this, and implements the 16KB granule size (the value of
<code>ID_AA64MMFR0_EL1</code> is <code>0x00001122</code>, matching the reference manual, but setting
<code>TCR_EL1.TG</code> to <code>0b01</code> works as intended).</p>
<p>We had several options for the continuation of the project. We briefly
considered patching the iOS kernel to use 4KB or 64KB pages, both supported by
Cortex-A53. This idea was quickly dropped, as it requires a lot of effort,
while its probability of success is questionable. While building the initial
page table with different page sizes should be doable, we‚Äôd have to find all
the places in the kernel code that manipulate the page table, and update them
accordingly - not an easy feat to accomplish.</p>
<p>We, therefore, had to switch to an ARM core that supports 16KB pages. This
brought us back to the choice of a hardware (ARM server, development board, or
a phone), with one more requirement to fullfil: we‚Äôd look up the technical
reference manual of the core powering the chosen hardware, and verify the
granule size used by the iOS kernel is supported.</p>
<p>Unfortunately, most budget development boards use older ARM cores (either
Cortex-A53 or Cortex-A72), with no support for the required granule size. We
found one board with a core that had the required support - but it only had
1GB of RAM. Most Android phones ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://alephsecurity.com/2020/07/19/xnu-qemu-kvm/">https://alephsecurity.com/2020/07/19/xnu-qemu-kvm/</a></em></p>]]>
            </description>
            <link>https://alephsecurity.com/2020/07/19/xnu-qemu-kvm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23891034</guid>
            <pubDate>Sun, 19 Jul 2020 17:53:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Truth about Disroot]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23890994">thread link</a>) | @realpanzer
<br/>
July 19, 2020 | https://privacy-watchdog.io/the-truth-about-disroot-org/ | <a href="https://web.archive.org/web/*/https://privacy-watchdog.io/the-truth-about-disroot-org/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<h2>The Truth About Disroot</h2>
<h3>1. Disroot may be a criminal organization</h3>
<p>Disroot offers a data retention policy that is illegal in the Netherlands.</p>
<p>On 9/18/19 attackers who identified themselves as connected with Disroot DDOS‚Äôed Privacy-watchdog.io.&nbsp; They tried to use bullying and harassment to get us to take down this page. You can&nbsp;<a href="https://privacy-watchdog.io/the-disroot-ddos-attack-of-9-18-19/">read more about it here.</a>&nbsp; Disroot has not disavowed this attack.&nbsp; This illustrates that Disroot is run by people who engage in illegal cyberwarfare.</p>
<h3><strong>2. Disroot‚Äôs code and security architecture are below average</strong></h3>
<p>Disroot says their code is open source and they say you can review it on <a href="https://www.rainloop.net/">Rainloops</a> GitHub account <a href="https://github.com/RainLoop/rainloop-webmail">here</a>.&nbsp; But Rainloop is an independent corporation and Disroot is only one many groups who use it. Rainloop is <strong>not</strong> marketed and not intended for security or privacy. Rainloops website markets itself as ‚Äúdecent performance, simple&nbsp;<a href="http://www.rainloop.net/docs/installation/">installation‚Äù.</a>&nbsp; It‚Äôs so simple it <a href="https://www.rosehosting.com/blog/how-to-install-rainloop-webmail-on-ubuntu-18-04/">reportedly takes less than 10 minutes</a> to set up, <a href="https://www.rainloop.net/docs/installation/">here‚Äôs the guide</a>.&nbsp; Or follow a <a href="https://www.youtube.com/watch?v=p-97oZC1nD4">12 min youtube video</a>.&nbsp; It‚Äôs so simple that hundreds of clubs and groups use Rainloop.&nbsp; For example,&nbsp;local mom groups,&nbsp; <a href="https://www.cyberpunk.rs/">Cyberpunk</a> sites, <a href="http://app.g-p.co.jp/webmail/">food</a> stores, <a href="http://rimwd.com/">advertising agencies</a>, <a href="https://webmail.uberspace.de/">hosting</a> services, kids clothes stores, <a href="https://crazytutorials.be/">tutorial sites</a>, <a href="http://egomail.egorealestate.com/">real estate services</a>, and <a href="https://webmail.ilait.se/">cloud computing retailers</a>.</p>
<p>Disroot depends on Rainloop for its security and to provide updates.&nbsp; That‚Äôs a problem because Rainloop has only worked <a href="https://github.com/RainLoop?tab=overview&amp;from=2018-12-01&amp;to=2018-12-31">12 days</a> in 2018 and <a href="https://github.com/RainLoop?tab=overview&amp;from=2019-09-01&amp;to=2019-09-20">18 days</a> in 2019.&nbsp; They have <a href="https://github.com/RainLoop/rainloop-webmail/issues">739 open bugs</a>, fixes and issues that are ‚ÄúPending‚Äù.&nbsp; &nbsp;Rainloop is not well maintained, it is not designed for privacy or security and it has security issues unfixed.&nbsp; When you use Disroot this is what you‚Äôre getting.</p>
<p>Disroot says they offer built-in encrypted email however that‚Äôs misleading.&nbsp; They provide TLS/SSL encryption. This is what everyone uses and it‚Äôs average.&nbsp; &nbsp;You‚Äôre using the same email security that everyone uses.&nbsp;<b>&nbsp;</b>All emails are saved as plain text on their server.&nbsp; They offer an add on ‚Äúoption‚Äù to encrypt emails server side.&nbsp; But Disroot gets all of those emails in Plain text and you have to trust that they won‚Äôt read them.&nbsp; Be careful trusting Disroot because the evidence suggests they are a criminal organization (more on that below).&nbsp; They also know your private key and password so if they wanted to read your encrypted emails they could with ease.</p>
<h3><strong>3. </strong><strong>Disroot misrepresents their company and pays for biased reviews</strong></h3>
<p>The website leads a visitor to believe it is a volunteer-run community.&nbsp; However, Disroot contradicts this statement when they say they are actually a non-profit company.&nbsp; This is what most secure email services do to avoid taxes.&nbsp; &nbsp;Disroot‚Äôs claim of being a ‚Äúvolunteer-run organization‚Äù is just clever marketing.&nbsp; &nbsp;They are the same type of non-profit company everyone else is.</p>
<p>The Disroot NPO Company earns revenue from donations and through <a href="https://graphtreon.com/creator/disroot">Patreon</a>&nbsp;(<a href="https://archive.fo/TNEvf">Archive</a>).&nbsp; With their tax-free revenue they purchase <a href="https://www.makeuseof.com/tag/disroot-encrypted-email-cloud/">good reviews</a>&nbsp;(<a href="https://archive.fo/lwiVZ">Archive</a>) from&nbsp;<a href="https://www.dannalbright.com/">Dan Albright</a> who‚Äôs goal is to ‚Äú<a href="https://www.dannalbright.com/">make you (and your company) look great!</a>‚Äú.&nbsp; This would explain why his article is biased toward Disroot calling it ‚ÄúThe Best Private Encrypted Email‚Äù.&nbsp; The reality is Disroot privacy and encryption are very mediocre at best.&nbsp; It‚Äôs not a good sign when a company has to pay people to say good things about them.</p>
<p>Disroot also seems to have purchased a whole page of good reviews from a site called ‚Äú<a href="https://digdeeper.neocities.org/ghost/email.html">Digdeeper</a>‚Äù (<a href="https://archive.fo/zTYYL">Archive</a>).&nbsp; &nbsp;Anyone reviewing <a href="https://digdeeper.neocities.org/ghost/email.html">Digdeeper</a> can feel how biased it is towards promoting Disroot.&nbsp; Digdeeper also attempts to elevate Disroot by shitting on all the other email services,<a href="https://digdeeper.neocities.org/ghost/email.html"> see for yourself</a>.&nbsp; Digdeeper recommends two other webmail services called Riseup and Autistici.&nbsp; The majority of security &amp; privacy experts will tell you to <a href="https://www.privacytools.io/providers/email/">avoid</a> those two sites, at all costs, because of their history with Law Enforcement.</p>
<h3><strong>4. Disroots has serious legal issues that affect their users</strong></h3>
<p>Disroot‚Äôs users are also bound by <a href="https://www.rainloop.net/licensing/">Rainloops Terms of Service</a>.&nbsp; Rainloop is a US-based company with terms of service that could imply they send your data to US datacenters.</p>
<p><img src="https://privacy-watchdog.io/wp-content/uploads/2019/08/Disroot-IP-1-266x300.jpg" alt="" width="266" height="300" srcset="https://privacy-watchdog.io/wp-content/uploads/2019/08/Disroot-IP-1-266x300.jpg 266w, https://privacy-watchdog.io/wp-content/uploads/2019/08/Disroot-IP-1-768x867.jpg 768w, https://privacy-watchdog.io/wp-content/uploads/2019/08/Disroot-IP-1-300x339.jpg 300w, https://privacy-watchdog.io/wp-content/uploads/2019/08/Disroot-IP-1-850x960.jpg 850w, https://privacy-watchdog.io/wp-content/uploads/2019/08/Disroot-IP-1.jpg 865w" sizes="(max-width: 266px) 100vw, 266px"></p>
<p>You can discover Disroot‚Äôs datacenter by following their webmail IP address (179.21.23.139) which will lead you to ‚Äú<a href="https://serverius.net/">Serverius‚Äô</a>.&nbsp; If you use Disroot your data is stored in a server owned by Serverious and their privacy policy applies to your data.&nbsp; Serveritus says they record all traffic data for up to 5 years and they may turn it over to law enforcement within ‚Äúreasonable discretion‚Äù without notifying Disroot.</p>
<p>All users data is stored in the Netherlands.&nbsp; The Netherlands are inside the 14-eyes but what‚Äôs worse is Edward Snowden said the Dutch are the ‚ÄúSurveillance Kings of Europe‚Äù.&nbsp;&nbsp; Dutch law requires companies to retain all users personal data for 6 months.&nbsp; When you press ‚ÄúDelete‚Äù on an email Disroot is legally required to keep a backup for 6 months.&nbsp; But that‚Äôs only if your lucky and&nbsp; That also means Disroot is legally required to record IP addresses for 6 months.&nbsp; In 2014 the European Court of Justice (ECJ)&nbsp; declared this data collection to be a violation of rights and said the law was invalid.&nbsp; But the ECJ is not a dutch organization and the Dutch government continues the data retention laws stating they are required to ‚Äúfight terror‚Äù.</p>
<h3><strong>5. Disroot is a Law Enforcement ‚Äú<a href="https://en.wikipedia.org/wiki/Honeypot_(computing)">Honey Pot</a>‚Äù or will be soon</strong></h3>
<p>There used to be a server that provided a similar service as Disroot that was set up for a criminal group‚Äôs private use.&nbsp; The <a href="https://www.zdnet.com/article/dutch-police-snoop-on-criminal-chats-by-intercepting-encryption-server/">Dutch hijacked it</a> (<a href="https://archive.fo/2qjdy">Archive</a>) and recorded everything coming in and out. They also hijacked and ran the <a href="https://www.wired.com/story/hansa-dutch-police-sting-operation/">Hansa Market</a> for a few months.&nbsp; Based on the history of Dutch law enforcement I think Disroot is currently compromised by Dutch law enforcement.&nbsp; If they are not currently compromised then they will be soon.&nbsp; Remember, CIA officials have said, ‚ÄúThere‚Äôs no such thing as intelligence sharing, There is only intelligence trading.‚Äù&nbsp; And Disroot could provide massive amounts of data to ‚Äútrade‚Äù if compromised and it would be extremely easy to do.</p>
<p>Disroot offers a data retention policy that is illegal in the Netherlands.&nbsp; This gives Dutch law enforcement an easy way to hijack Disroot‚Äôs whole email service.&nbsp; They do not need a court order to take over Disroots services because Disroot is offering features that are illegal.&nbsp; And when Disroot is compromised 100% of your data will be recorded by law enforcement because of their weak security architecture.&nbsp; At that point, it‚Äôs only a matter of time before your plain text Disroot emails are stored right next to your Gmail emails within the massive Utah NSA data center.</p>
<p>Privacy Watchdog</p>


			</div></div>]]>
            </description>
            <link>https://privacy-watchdog.io/the-truth-about-disroot-org/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23890994</guid>
            <pubDate>Sun, 19 Jul 2020 17:47:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Truth About Protonmail]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23890964">thread link</a>) | @URfejk
<br/>
July 19, 2020 | https://privacy-watchdog.io/truth-about-protonmail/ | <a href="https://web.archive.org/web/*/https://privacy-watchdog.io/truth-about-protonmail/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
						<div>
							<div>

	<div id="primary">
		<main id="main">

		
<article id="post-19">
			<!-- .entry-header -->

	<div>
		<p><strong>1.Protonmail Behaves like a CIA/NSA ‚Äú<a href="https://en.wikipedia.org/wiki/Honeypot_(computing)">Honeypot</a>‚Äù</strong></p>
<p>Protonmail has an <a href="https://protonirockerxow.onion/">Onion domain</a> that allows users to visit their site using the TOR browser.&nbsp; Protonmail even has an SSL cert for that onion address even though it‚Äôs completely unnecessary. When a user makes a new account with Protonmail on TOR they are re-directed from Protonmail‚Äôs ‚Äú.onion‚Äù to ‚Äú.com‚Äù address.&nbsp; This breaks your secure encrypted connection to their onion address, enabling your identification.&nbsp; There are absolutely no technical reasons for this feature.&nbsp; In fact, the only other websites that operate like this are suspected NSA/CIA Honeypots.</p>
<p>This is a huge security issue that was either created because Protonmail is managed by Particle physicists who do not understand computer security OR they have been forced to operate their website in a similar way as CIA/NSA honeypots. Both possibilities are serious concerns.</p>
<p><strong>2. Protonmail Does Not Provide ‚ÄúEnd to End Encryption‚Äù</strong></p>
<p>Professor Nadim Kobeissi mathematically <a href="https://eprint.iacr.org/2018/1121.pdf">proved</a> that Protonmail does not provide End to End Encryption. Meaning, Protonmail has the ability to decrypt their own user‚Äôs data.&nbsp; When this was shown to be true, Protonmail users were outraged they had been lied to.&nbsp;<a href="https://protonmail.com/blog/cryptographic-architecture-response/"> Protonmail was forced to issue a public statement</a>.&nbsp; &nbsp;Their statement begins like you would expect it would..&nbsp; by shitting on the security researcher that revealed their dishonesty.&nbsp; &nbsp;Then they continued to say:&nbsp; ‚ÄúWe lied to our users because other email companies did‚Äù.&nbsp; &nbsp;No apologies.&nbsp; They can decrypt any of their user‚Äôs data be sending them scripts that allow them to do so.&nbsp; However they advertise that they can not.&nbsp; <strong>Protonmail‚Äôs <a href="https://protonmail.com/blog/cryptographic-architecture-response/">admission</a> proves they offer the same security that Gmail offers.&nbsp;</strong> Both Gmail and Protonmail offer encryption that they can decrypt whenever they want.</p>
<p><b>3. Protonmail‚Äôs Was Created Under CIA/NSA Oversight</b></p>
<p>Gmail &amp; Protonmail were both created in CIA/NSA funded departments with their oversight.&nbsp; Protonmail has tried to hide this part of their history. <a href="https://privacy-watchdog.io/protonmails-creation-with-cia-nsa/">We wrote a whole article about it here</a>.</p>
<p><strong>4.Protonmai</strong><strong>l is Part Owned by CRV and the Swiss Government</strong></p>
<p>After a successful crowdfunding campaign with promises to ‚Äúremain independent‚Äù Protonmail <a href="https://protonmail.com/blog/protonmail-has-raised-2m-usd-to-protect-online-privacy/">sold equity ownership</a> to <a href="https://www.crv.com/">CRV</a> and <a href="https://fongit.ch/about-us/">FONGIT</a>. &nbsp; &nbsp;At the time of the equity sale a CRV founder, Mr Ted Ditersmith, was working for the US State Department closely with President Obama.&nbsp; His position as a delegate required close contact with CIA &amp; NSA administration.&nbsp; Mr. Ted Ditersmith had also witnessed the Edward Snowden revelations and made statements that he planned to use his corporate knowledge to ‚Äúfight terrorism‚Äù.&nbsp; &nbsp;<a href="https://fongit.ch/">FONGIT</a> is a Non Profit organization that is <a href="https://fongit.ch/about-us/">financed by the Swiss Government</a>. Protonmail staff member, <a href="https://protonmail.com/about">Antonio Gambardella</a>, also works for the Swiss Government.</p>
<p><strong>5. CRV, In-Q-Tel &amp; the CIA</strong></p>
<p>The CIA openly operates a front company,&nbsp;<a href="https://en.wikipedia.org/wiki/In-Q-Tel">In-Q-Tel</a>, whose stated purpose is to invest in tech companies on behalf of the CIA. In-Q-Tel has stated they have a specific interest in the <a href="https://www.nytimes.com/2001/12/30/business/suddenly-uncle-sam-wants-to-bankroll-you.html">information contained in e-mails</a><u> and encrypted communication.</u>&nbsp;In-Q-Tel has been shown to be the&nbsp;bridge between the <a href="https://medium.com/insurge-intelligence/how-the-cia-made-google-e836451a959e">CIA and Gmail</a>.&nbsp; An analysis of staff members reveals CRV &amp; In-Q-Tel connections.&nbsp; The US media confirms these connections when they&nbsp;<a href="https://www.nytimes.com/2001/12/30/business/suddenly-uncle-sam-wants-to-bankroll-you.html">interview CRV</a> so that they can understand In-Q-Tel.&nbsp; Additionally, The mastermind, cryptographer &amp; back end developer that created Protonmail, Wei Sun,<a href="https://angel.co/wei-sun-7"> now works for Google.</a></p>
<p><strong>6. Protonmail Follows CIA Email format &amp; Metadata Requirements</strong></p>
<p>Leaked documents at Wikileaks show that the CIA requires emails to be stored as an EML filetype.&nbsp; There are several ways to store emails, and Protonmail has selected the format that the CIA requires.&nbsp; Protonmail offers no protection for users‚Äô metadata and has officially stated that they turn metadata over to Law Enforcement.&nbsp; Edward Snowden revealed that the US government cares least about the content of emails.&nbsp; Mr. Snowden revealed the US Law Enforcement cares most about who a person is talking to, the dates &amp; times of the emails, and the subject of the email. &nbsp;Subject and metadata encryption are not difficult to provide.&nbsp; However, Protonmail refuses to offer any protection on data that is most valuable to the CIA &amp; FBI and they store it as plain text (No encryption). Edward Snowden stated the NSA ‚Äúisn‚Äôt able to compromise the encryption algorithms underlying these technologies. Instead, it circumvents or undermines them by <a href="https://mashable.com/2013/09/05/snowden-nsa-break-internet-encryption/">forcing companies to cooperate in other ways</a>.&nbsp; Protonmail has refused to protect the information the NSA wants, this is a concern.</p>
<p><strong>7. Swiss MLAT Law Could Give the NSA Full Access</strong></p>
<p>Protonmail‚Äôs Servers Reside In Switzerland, a country with an MLAT treaty that could allow the NSA to continue it‚Äôs the mission of recording ‚Äúnearly everything‚Äù about a person‚Äôs internet communication.&nbsp; Any doubts the MLAT treaty applies are removed when you take into account that Protonmail is part-owned by FONGIT, a Swiss Government-financed company.&nbsp; Protonmail has also <a href="https://www.reddit.com/r/privacy/comments/cwld9o/protonmail_changed_his_policy/eykbrqz/">recently revised</a> its <a href="https://protonmail.com/privacy-policy">Privacy Policy</a> to include wording and requirements from the MLAT treaty.&nbsp; Their actions show they are capitulating with the MLAT treaty.&nbsp; Revisions include a change to their privacy policy allowing them to track your location while you use their service in some situations.</p>
<p><strong>8. Protonmail Uses Radware for DNS/DDOS Protection</strong></p>
<p>Privacy companies like Protonmail are required to use a DNS/DDOS service because of the frequent attacks against their service.&nbsp; Protonmail <a href="https://protonmail.com/support/knowledge-base/protonmail-israel-radware/">uses a company called Radware</a> for this purpose.&nbsp; Radware is a low-quality service that has failed to provide adequate protection.&nbsp; Protonmail has been taken offline, <a href="https://techcrunch.com/2018/09/06/protonmail-names-one-of-the-attackers-behind-a-major-ddos-this-summer/">sometimes by teenage kids,</a> because they insist on using a sub-par service.&nbsp; It‚Äôs worth noting that Radware‚Äôs international office is a few miles away from the headquarters of the most powerful Intelligence agency on earth, The Isreali Mossad.&nbsp; Radware can gain complete access to all Protonmail user‚Äôs accounts in two ways.&nbsp; They could inject a few lines of code that would reveal all users log in username and passwords, thus allowing them to log in as if they are that user.&nbsp; They could also be given users usernames &amp; passwords by Protonmail.&nbsp; Remember Protonmail has admitted they can access all user‚Äôs accounts and decrypt their data.&nbsp; Additionally, it has been reported that Radware has <a href="https://cryptome.org/2015/11/protonmail-ddos.htm">direct connections</a>&nbsp;to the Israeli Defense Force.</p>
<p><strong>9. Protonmail Developers Do Not Use Protonmail</strong></p>
<p>Protonmail‚Äôs developers are in a position to know the real security offered by Protonmail.&nbsp; &nbsp;And<a href="https://privacy-watchdog.io/protonmail-devs-do-not-use-protonmail/"> Protonmail‚Äôs developers do not use Protonmail</a>.&nbsp; &nbsp;If you were served food by a cook who refused to eat the food, would that be a cause of concern to you?&nbsp; This is the same situation.&nbsp; Protonmail developers do not use Protonmail, there are likely good reasons for this.</p>
<p><strong>10. Protonmail engages in illegal cyberwarfare</strong></p>
<p>In 2017 Protonmail seems to have used illegal cyber warfare capabilities to unlawfully break into a&nbsp;<a href="https://www.vice.com/en_us/article/qvvke7/email-provider-protonmail-says-it-hacked-back-then-walks-claim-back">suspects server.</a>&nbsp; &nbsp; You can see the tweet they posted and read about it <a href="https://www.vice.com/en_us/article/qvvke7/email-provider-protonmail-says-it-hacked-back-then-walks-claim-back">here</a>. They soon deleted the tweet and said: ‚ÄúWe cannot confirm nor deny if anything happened.‚Äù&nbsp; In 2013 the&nbsp;<a href="https://www.reuters.com/article/net-us-eu-cybercrime-idUSBRE9630LD20130704">European Union parliament voted</a> to make hacking a crime that carried a prison sentence of 2 years.&nbsp; ‚ÄúHacking back‚Äù is also illegal under Swiss law.&nbsp; Based on Protonmail‚Äôs admissions only, they conducted an illegal hack.</p>
<p><strong>11. Protonmail has a history of Dishonesty.&nbsp;</strong></p>
<p><a href="https://privacy-watchdog.io/protonmails-false-claims/">From Protonmail‚Äôs creation lied to their users</a>.&nbsp; Starting when they crowdfunded $550k to ‚Äúremain Independent‚Äù, a promise they broke almost immediately by<a href="https://privacy-watchdog.io/protonmails-crowdfunding-equity-sale/"> selling equity ownership to a US corporation with ties to President Obama and John Podesta.</a></p>
<p>In our opinion Protonmail is not an email solution you would use if you want privacy or security.&nbsp; Your emails are probably going to end up in a US data center right next to your Gmail emails.</p>
<p>Privacy Watchdog</p>


			</div><!-- .entry-content -->
</article><!-- #post-19 -->

<!-- #comments -->

		</main><!-- #main -->
	</div><!-- #primary -->


<!-- #secondary -->
	</div>
</div>
</div></div>]]>
            </description>
            <link>https://privacy-watchdog.io/truth-about-protonmail/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23890964</guid>
            <pubDate>Sun, 19 Jul 2020 17:44:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making IRC bot using Unix utilities]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23890502">thread link</a>) | @pvtmert
<br/>
July 19, 2020 | https://blog.n0pe.me/lets-write-irc-bot-in-bash-ef7be37001e3 | <a href="https://web.archive.org/web/*/https://blog.n0pe.me/lets-write-irc-bot-in-bash-ef7be37001e3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><h2 id="e428">IRC is a text-based real-time messaging protocol. Communication is handled by gateway servers that users connect to.</h2><div><div><div><p><a href="https://blog.n0pe.me/@PvtMert?source=post_page-----ef7be37001e3----------------------" rel="noopener"><img alt="Mert Akengin" src="https://miro.medium.com/fit/c/96/96/0*P6kgAI7lT-QJ6qik.jpeg" width="48" height="48"></a></p></div></div></div><p id="03ef"><strong>IRC</strong> is one of the oldest real-time messaging protocol of the Internet. It was really popular back in the ‚Äò90s and early 2000s but these days it is mostly taken over by <strong>Slack</strong>.</p><p id="60ac">Besides it has a protocol specification in IETF as <a href="https://tools.ietf.org/html/rfc1459" target="_blank" rel="noopener">RFC 1459</a>, it also predates other proprietary applications such as <strong>ICQ</strong> and <strong>MSN Messenger</strong>. Which are mostly/largely based on or influenced by <strong>XMPP</strong> (also known as <strong>Jabber</strong>.)</p><blockquote><p id="6612">Another remark is that the <strong>IRC is older than WWW.</strong></p></blockquote><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/10000/0*ry9sg_MRld2WHSs_" width="5000" height="3333" srcset="https://miro.medium.com/max/552/0*ry9sg_MRld2WHSs_ 276w, https://miro.medium.com/max/1104/0*ry9sg_MRld2WHSs_ 552w, https://miro.medium.com/max/1280/0*ry9sg_MRld2WHSs_ 640w, https://miro.medium.com/max/1400/0*ry9sg_MRld2WHSs_ 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*ry9sg_MRld2WHSs_?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@lenin33?utm_source=medium&amp;utm_medium=referral" target="_blank" rel="noopener">Lenin Estrada</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" target="_blank" rel="noopener">Unsplash</a></figcaption></figure><p id="8ff3">Since IRC is solely a text-based protocol, which is why we can just write a Bash script containing standard UNIX utilities (echo, cat, grep, awk, etc.) to communicate with it.</p><p id="7fad">To jumpstart quickly, I recommend connecting to an IRC server via <strong><em>netcat</em></strong> and execute stuff manually to get a sense of whats going on and how simple is that.<br>The <strong>default port number of IRC is 6667</strong>. Which is plain-text connection‚Ä¶</p><pre><span id="661c">user@host:~$ nc -v irc.freenode.net 6667</span></pre><ol><li id="e706">Send <code>NICK ${name}</code> to set the initial nickname.</li><li id="55f4">Send <code>USER ${username} ${alternate1} ${alternate2} : ${realname}</code> to (sort of) authenticate yourself.<br><strong>PS:</strong> you can use <code>*</code> instead of <code>alternate</code> names.</li><li id="6269">At this time you will receive lots of text data from the server‚Ä¶</li><li id="6f92">Join a channel by sending <code>JOIN ${channel}</code> <br><strong>PS:</strong> Channels‚Äô names start with <code>#</code> character. Eg: <code>#medium</code>.</li><li id="d316">Send a message to that channel by issuing <code>PRIVMSG ${channel} Hello!</code></li><li id="7117">Since everything is text-based, messages destined to channel or directly to you are having <code>PRIVMSG</code> tag.</li><li id="80d9">You can <code>WHOIS</code> yourself like: <code>WHOIS ${nickname}</code></li></ol><h2 id="be09">Parsing incoming messages</h2><p id="d180">Incoming data relevant to our application structured as follows.</p><pre><span id="969a">:mert!~pvtmert@[redacted] PRIVMSG #channel :hello!<br>:mert!~pvtmert@[redacted] PRIVMSG mynickname :sup bro!</span></pre><p id="d757">I haven‚Äôt read the specification but <strong>fields are separated by a colon</strong> (<code>:</code>) character. I named them as <code>META</code> and <code>TEXT</code>, containing <em>metadata</em> and <em>text-message</em> respectively.</p><p id="3e9f">The first message <strong>containing </strong><code><strong>#</strong></code><strong> sign is sent to that channel</strong>, which I joined. <br>The other <strong>message contains no </strong><code><strong>#</strong></code><strong> sign is a direct-message between users</strong>. And instead of <code>mynickname</code>, <strong>you should see whatever you passed as a </strong><code><strong>NICK</strong></code><strong> command earlier</strong>.</p><p id="e55b">To reply to channel messages, just extracting channel names via regexes like <br><code>#[^ ]+</code> is enough. Then passing that name to <code>PRIVMSG</code> is a way to go.</p><p id="3d2b">For sending direct-messages, destination user is needed. Which is the <code>mert!~pvtmert@[redacted]</code> part. The problem here is this is a full <code>WHOIS</code> or identity, you just need <code>NICK</code> to send a reply back.<br>Given <code>{nick}!~{identity}@{hostname}</code> structure, taking parts between the colon (<code>:</code>) and exclamation mark (<code>!</code>) is enough to pass it to <code>PRIVMSG</code> command.</p><h2 id="57f7">Gluing <code>netcat</code> with <code>bash</code></h2><blockquote><p id="33d0">The <code>-e</code> or <code>-c</code> switches of netcat connects socket I/O with the application‚Äôs standard I/O.</p></blockquote><p id="957f">When you check the embedded help page of netcat via <code>netcat -h</code> /<code>netcat --help</code> or <code>nc -h</code> /<code>nc --help</code> (depending on your distribution and netcat version) there is switches generally named <code>-e</code> and <code>-c</code> which allows user to pass a program. <strong>The program‚Äôs input (aka </strong><code><strong>stdin</strong></code><strong>) will be connected to the socket‚Äôs output pipe, and the program‚Äôs output (aka </strong><code><strong>stdout</strong></code><strong>) will be connected to the socket‚Äôs input pipe.</strong> <em>Error output (aka </em><code><em>stderr</em></code><em>) will output to the regular console.</em></p><h2 id="c942">The initial ‚Äúechoing parrot‚Äù script.</h2><p id="40f1">A basic bash script that <code>echo</code>‚Äòes initial commands then filters <code>stdin</code> for incoming messages on joined channel, <code>$CHAN</code>. Extracts text message and prepends <code>PRIVMSG ${CHAN}</code> to each message, <code>echo</code>‚Äòes them to send to socket.</p><pre><span id="776c">#!/usr/bin/env bash</span><span id="bbfa">NAME="epic_bot"<br>CHAN="#bottest"</span><span id="6528">echo "NICK ${NAME}"<br>echo "USER ${NAME} * * : ${NAME}"<br>sleep 3 # wait for server to do stuff</span><span id="5473">echo "JOIN ${CHAN}"<br>echo "PRIVMSG ${CHAN} :Hello World!"</span><span id="e960">grep --line-buffered "PRIVMSG ${CHAN}" \<br>    | stdbuf -i0 -oL -eL cut -d: -f3-  \<br>    | sed -u "s/^/PRIVMSG ${CHAN} :/g" \</span><span id="232b"># run on debian with $ <strong>nc -vc ./irc.sh hello.ipn.dev 6667</strong></span></pre><ul><li id="a9ce"><code>grep</code> : Reads <code>stdin</code> and outputs only lines with <code>PRIVMSG ${CHAN}</code>.<br>Which is <code>PRIVMSG #bottest</code> in the above script.</li><li id="02c0"><code>stdbuf</code> &amp; <code>cut</code> : Takes the 3rd field with line buffering. Since both input and output is a pipe, pipes are normally buffered due to performance considerations. <strong>But we need real-time line-buffering</strong>.<br>Takes fields 3rd and after because the <strong>first field is empty</strong> (anything before the first colon) and the <strong>second field is the metadata</strong>.</li><li id="9511"><code>sed</code> : Prepends <code>PRIVMSG ${CHAN}</code> to every received line. The lines received from the <code>cut</code> are only text-message lines. So sending them back to <code>${CHAN}</code>. The <code>${CHAN}</code> is <code>#bottest</code>, hence output becomes: <code>PRIVMSG #bottest :message here</code>.</li></ul><h2 id="36ce">Adding more logic, covering other types of messages</h2><p id="3f01">In order to see messages coming and going from/to server you can add <code>tee /dev/stderr</code> before and after actual logic. This will allow you to see messages on the console.</p><pre><span id="6f61">#!/usr/bin/env bash</span><span id="97e7">NAME="epic_bot"<br>CHAN="#bottest"</span><span id="739d">tee /dev/stderr | {</span><span id="9455">    echo "NICK ${NAME}"<br>    echo "USER ${NAME} * * : ${NAME}"<br>    sleep 3 # wait for server to do stuff</span><span id="0c1d">    echo "JOIN ${CHAN}"<br>    echo "PRIVMSG ${CHAN} :Hello World!"</span><span id="cdc4">    grep --line-buffered "PRIVMSG ${CHAN}" \<br>        | stdbuf -i0 -oL -eL cut -d: -f3-  \<br>        | sed -u "s/^/PRIVMSG ${CHAN} :/g" \</span><span id="ed6b">} | tee /dev/stderr</span></pre><blockquote><p id="2098">An extended version of this script that <strong>executes commands</strong> passed after dollar sign (<code>$</code>) [<strong>DANGEROUS</strong>!] can be found <a href="https://gist.github.com/pvtmert/3a56d3a10f36692f18d1c7837eaed632" target="_blank" rel="noopener">here at my gists</a>.</p></blockquote><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1544/1*v03FciKfjF8ZDf8PtX6_dA.png" width="772" height="620" srcset="https://miro.medium.com/max/552/1*v03FciKfjF8ZDf8PtX6_dA.png 276w, https://miro.medium.com/max/1104/1*v03FciKfjF8ZDf8PtX6_dA.png 552w, https://miro.medium.com/max/1280/1*v03FciKfjF8ZDf8PtX6_dA.png 640w, https://miro.medium.com/max/1400/1*v03FciKfjF8ZDf8PtX6_dA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*v03FciKfjF8ZDf8PtX6_dA.png?q=20"></p></div></div></div><figcaption>IRC <strong>bot that executes commands</strong> passed after dollar sign (`$`). <a href="https://gist.github.com/pvtmert/3a56d3a10f36692f18d1c7837eaed632" target="_blank" rel="noopener">Source Code</a></figcaption></figure><p id="e670">And after bot joined channel, send some messages both to channel and to directly to bot as a DM. Invite to some other channel, then kick bot from channel. :)</p><pre><span id="cb30">:mert!~pvtmert@[redacted] KICK #bottest epic_bot :Kicked for spamming.</span></pre><p id="8f18">Since each line from the server containing what happened. And each line is prefixed with metadata, reading lines with <code>read</code> command pretty okay.</p><p id="dfad">For each line, some matching mechanisms required to split actions to respond to them differently. The <strong>switch-case</strong>, <code>case-in</code> in Bash helps here.</p><pre><span id="69d4">while <strong>read line</strong>; do<br>    case "${line}" in<br>        *<strong>PRIVMSG</strong>*) # line contains PRIVMSG<br>        ;;<br>        *<strong>KICK</strong>*) # line contains KICK<br>        ;;<br>        *) # any other '<strong>catch-all</strong>' eg. for logging<br>        ;;<br>    esac<br>done</span></pre><p id="6cf5">While metadata part can differ by type of message, user related messages are using same formatting:<br> <code>:{source-user} COMMAND #channel [optional arguments] :Text Message</code></p><p id="e8a3">And because there is Windows / Telnet stuff, some servers using <code>&lt;CR&gt;&lt;LF&gt;</code> to end lines. So using <code>tr</code> (trim) utilty to get rid of carriage-returns while splitting required parts before switch-case‚Ä¶</p><pre><span id="2a9b">while read line; do<br>   UNIX=$(echo "${line}" | tr -d '\r')    # trim CR<br>   META=$(echo "${UNIX}" | cut -d: -f2 )  # extract metadata<br>   TEXT=$(echo "${UNIX}" | cut -d: -f3-)  # extract text-message<br>   CHAN=$(echo "${META}" | cut -d' ' -f3) # extract channel-name<br>   CMD=$( echo "${META}" | cut -d' ' -f4) # extract command<br>   WHO=$( echo "${META}" | cut -d'!' -f1) # extract user-name<br>   case "${UNIX}" in<br>       *" <strong>PRIVMSG ${CHAN}</strong> :"*)<br>       echo "PRIVMSG ${CHAN} :<strong>Simon says: '${TEXT}' </strong>"<br>       ;;<br>       *" <strong>PRIVMSG ${NAME}</strong> :"*)<br>       echo "PRIVMSG ${WHO} :<strong>Hi ${WHO}!, nice to meet you.</strong>"<br>       ;;<br>       *" <strong>INVITE ${NAME}</strong>"*)<br>       echo "JOIN ${TEXT}"<br>       ;;<br>       *" <strong>KICK ${CHAN} ${NAME}</strong> "*)<br>       echo "PRIVMSG ${WHO} :<strong>Hey! What does '${TEXT}' mean?!</strong> "<br>       ;;<br>   esac<br>done</span></pre><h2 id="78de"><strong>This basic script can;</strong></h2><ul><li id="372b">Replies messages in a channel with ‚ÄúSimon says:‚Äù then appends original message.</li><li id="e337">Replies private-messages with ‚Äúnice to meet you‚Äù message.</li><li id="ec40">Can accept invitations to channels. Joins them automatically.</li><li id="2f23">When getting kicked from a channel, asks the meaning of kick reason to a person who kicked the bot.</li></ul><p id="3ca3">There is a difference between <code>busybox</code> <code>netcat</code> and GNU <code>coreutils</code> <code>netcat</code>.</p><p id="253c">You can also directly run script by mounting it via <code>-v</code> then passing <code>nc</code> command right after image name like: <code>docker run --rm -itw/data -v "$(pwd)/irc.sh:/irc.sh:ro" pvtmert/netcat -vc /irc.sh hello.ipn.dev 6667</code></p><h2 id="80d3">Busybox invocation:</h2><pre><span id="b864">user@localhost:~$ <strong>docker run --rm -itw/data busybox:latest</strong><br>/data # <strong>wget -o irc.sh </strong><a href="https://gist.githubusercontent.com/pvtmert/115d178a6dd30a360eb81df02fb7a594/raw/irc.echo.sh" target="_blank" rel="noopener"><strong>https://gist.githubusercontent.com/pvtmert/115d178a6dd30a360eb81df02fb7a594/raw/irc.echo.sh</strong></a><br>/data # <strong>chmod +x irc.sh</strong><br>/data # <strong>nc -v {server_address} 6667 -e ./irc.sh</strong></span></pre><h2 id="5f7c">Debian invocation:</h2><pre><span id="afc0">user@localhost:~$ <strong>docker run --rm -itw/data debian:latest</strong><br>root@b97b5fff4759:/data# <strong>apt update &amp;&amp; apt install -y curl</strong><br>root@b97b5fff4759:/data# <strong>curl -Lo irc.sh </strong><a href="https://gist.githubusercontent.com/pvtmert/115d178a6dd30a360eb81df02fb7a594/raw/irc.echo.sh" target="_blank" rel="noopener"><strong>https://gist.githubusercontent.com/pvtmert/115d178a6dd30a360eb81df02fb7a594/raw/irc.echo.sh</strong></a><br>root@b97b5fff4759:/data# <strong>chmod +x irc.sh</strong><br>root@b97b5fff4759:/data# <strong>nc -vc ./irc.sh {server_address} 6667</strong></span></pre><figure><div></div></figure></div></div></section></div>]]>
            </description>
            <link>https://blog.n0pe.me/lets-write-irc-bot-in-bash-ef7be37001e3</link>
            <guid isPermaLink="false">hacker-news-small-sites-23890502</guid>
            <pubDate>Sun, 19 Jul 2020 16:41:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Young Developer's Thoughts on Logging]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23890336">thread link</a>) | @matejmecka
<br/>
July 19, 2020 | https://aadibajpai.com/blog/gsoc.html#notifications | <a href="https://web.archive.org/web/*/https://aadibajpai.com/blog/gsoc.html#notifications">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="divbodyholder">



 <!-- headerholder -->

<div>









<div>

<p>Posted on 05 Jul 2020 by Aadi Bajpai</p>
<p><span><em>Last updated 17 Jul 2020 at  9:47 pm</em></span><br>

<span><a href="https://aadibajpai.com/blog/gsoc.html">permalink</a></span><br>



</p></div>

<p>The first phase of GSoC concluded recently (I passed!) and I wanted to talk about the things I did so far and the process to this point.</p>
<ul>
<li><a href="#background">Background</a></li>
<li><a href="#community-bonding-period">Community Bonding Period</a></li>
<li><a href="#phase-1">Phase 1</a>
<ul>
<li><a href="#minor-tracks">Minor Tracks</a></li>
<li><a href="#logging">Logging</a></li>
<li><a href="#notifications">Notifications</a></li>
<li><a href="#testing">Testing</a></li>
</ul>
</li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>

<p>I got selected as a student for the <a href="https://summerofcode.withgoogle.com/">Google Summer of Code</a> program. You can find my proposal at <a href="https://aadibajpai.com/gsoc/">https://aadibajpai.com/gsoc/</a>.  Since I go into detail in some places, reading the proposal once would make it easier to follow along as it provides important context. For phase 1, there were 3 major tracks: Logging x Notifications, Testing, and fixing a security flaw in the backend, along with a few minor tracks.</p>
<p>The initial application had gone by a bit fast, since I officially enrolled just a day before the application deadline. But well, I was able to apply successfully, got selected and here we are.</p>

<p>Being well acquainted with the org and my mentors already, I directly began to work through my proposal during this period. I cleaned up some of the issues and pull requests‚Äîalthough I am saving most of them for use in later stages. Then, I made new releases for <a href="https://github.com/SwagLyrics/SwagLyrics-For-Spotify/commit/977a195fae66896dec865132256825c32bbfbfe8">SwagLyrics</a> and <a href="https://github.com/SwagLyrics/SwSpotify/commit/1213be5ce630bdcfdb63ec368c260ca5c627de3a">SwSpotify</a>. The SwagLyrics Chrome Extension was also <a href="https://chrome.google.com/webstore/detail/swaglyrics-for-spotify/miopldoofdhmipepmnclnoangcdffmlk">published</a>! It adds support for the Spotify Web Player on SwagLyrics which was a long awaited feature.</p>
<p>More notably, I managed to complete an important major track in this time, there was a very weird unreproducible error occurring in swaglyrics that had been haunting us for a month or so. One day I stayed up, analyzed everything from the ground up and discovered that Genius had been A/B testing a new page format, which broke our parser whenever the new version was sent which was random and location dependent. Then, it was basically isolating the new html and parsing the new format. Now the worst part about this was that it wasn't anything we could handle in advance or even figure out, but I'm glad we caught it when we did if not sooner.</p>
<p>Most notable, however, was fixing a flaw in the backend which would have made my life way harder if discovered by someone else. The issue making feature of the backend does some verification checks to determine if the info is legit or not, e.g. if the song does actually exist on Spotify or not, along with some rate limiting. However, you could've spammed it with actual songs from Spotify for which it would work and it would have opened those spam issues. To fix this I just needed to ping the Genius webpage with the stripper crafted from the song, artist info received, but since this wasn't through an API, and PythonAnywhere doesn't allow non-API requests on the free tier, it was just sitting there unresolved.</p>
<p>However, since PythonAnywhere is awesome, after two very polite emails I was allowed access which fixed this for all eternity ü§ó</p>

<h2 id="minor-tracks">Minor Tracks</h2>
<p>The first track was adding type hints. Now it's not like a super big project where it is absolutely needed but I feel they greatly improve readability. It also helped me find a <em>bug</em> where I thought I was passing an <code>int</code> but it was through an environment variable so it was actually a string, I mean it was getting handled automatically but the more you know. Additionally, I guess now I can integrate <code>mypy</code> into the CI itself, which should be useful in the long term. Earlier, the <code>typing</code> library used to add some overhead but that has been improved now, so it made sense to do it.</p>
<p>Then, it was about adding support for Bollywood songs. Through empirical evidence which totally wasn't the 9838731 GitHub issues that swaglyrics opens, we discovered a lot of Bollywood songs on Spotify include the movie name in the title which sometimes did not resolve very well.</p>
<p><img src="https://i.imgur.com/V08NyAy.png" alt="GitHub Issues"></p>
<p>As you can see, it is always preceded by From and enclosed within "" which we can handle by modifying a previous regex to:</p>
<p><code>brc = re.compile(r'([(\[](feat|ft|From "[^"]*")[^)\]]*[)\]]|- .*)', re.I)</code></p>
<p>and it was taken care of.</p>
<h2 id="logging">Logging</h2>
<p>This is exactly what it sounds like, adding proper logging to the swaglyrics backend. So far I was making do with print statements, which is actually a fantastic way of logging but I was missing out on context‚Äîsince all the print output just gets clumped together. With the python <code>logging</code> library, there's more fine-grained control over the logs than plain print statements. For example, you might not want to log loops and stuff in production since that would spam logs, but that information would be crucial when debugging. So now I can simply set the log level to <code>debug</code> on staging and <code>info</code> on production. This was also cool because while implementing this across functions I managed to refactor a few of them to be more readable and pythonic.</p>
<p>The only qualm for me was that PythonAnywhere has this "feature" of mirroring the server and error logs if the logging library is used so you don't miss anything even if your config is misconfigured. As in, all logs output will be present in both those log file. To be honest that is a minor grievance for me but well (who checks logs really, but more on this in the next segment).</p>
<p>Additionally, I now have a valuable code snippet addition: a decorator to log the arguments passed to a function. You can even supply an argument to truncate arguments if they're longer than <code>x</code> characters to keep your logs clean and spiffy. Since this might be something useful to other projects as well, you can grab the code <a href="https://github.com/SwagLyrics/swaglyrics-backend/blob/master/swaglyrics_backend/utils.py#L86-L122">here</a>.</p>
<h2 id="notifications">Notifications</h2>
<p>I really don't grasp logging. Like, every time I want to look at something or view them when an error happens, I need to open browser ‚Üí PythonAnywhere ‚Üí Web tab ‚Üí logging file ‚Üí filter through to whatever I am looking for. Sounds good, doesn't work (very well). I would very much prefer for logs to come to me, rather than me going to them if that makes sense. Also, there's no way to see it as it happens when you're logging to a file or separate different requests in chunks so you can focus on one request being processed at a time instead of all of them in succession one after the other. All of this pales in comparison to the biggest problem I have with raw logs.</p>
<blockquote>
<p>raw üíÄüé∫ logs üíÄüé∫ look üíÄüé∫ trash</p>
</blockquote>
<p>Seriously, it's just a huge wall of text and I'm supposed to somehow find the parts I'm looking for, can't it just you know, be a bit visually appealing so I don't want to just nope out right after opening them.</p>
<p>/endrant lol</p>
<p>Overall, I guess this is the reason why there's so many ‚ú®shiny‚ú® dashboards and log processors but that would be overkill for my use case. We were already using Discord webhook magic to log requests to the Discord bot as well as successful backend deploy activity, so that's what I went with for the logs that were important to me: stripper resolution, and instrumentalness check.</p>
<p>Before the backend creates an issue, it checks whether the song is instrumental or not. If it is instrumental then it would not have lyrics and hence, no issue creation is necessary. Now we get the instrumentalness and speechiness values from Spotify but the thresholds for deciding if it is instrumental or not are custom. So it is important to view the logs of these as they happen to identify false positives and negatives to fine tune the values even more and potentially use this when serving lyrics as well. Earlier, this would have meant me periodically checking all the values and the artist names which to be frank I never did. But now it just comes in like-</p>
<figure>
	<img src="https://i.imgur.com/Eo7Am8b.png" alt="InstrumentalnessBoi">
  	<figcaption>way more beautiful &lt;3</figcaption>
</figure>
<p>Now it's trivial to eyeball cases right from the embed‚Äîwe know F√ºr Elise is obviously instrumental. If it was flagging it as not instrumental, then I'd have known the values were wack in one look instead of specifically hunting for this in raw logs and then comparing the confidence scores. In fact, the screenshot above is <em>after</em> <a href="https://github.com/SwagLyrics/swaglyrics-backend/commit/4624ebe3bd952f5c9fc6cf3d8756567e5329adbb">fine-tuning the thresholds</a> a while ago based on the feedback off of InstrumentalnessBoi.</p>
<p>Similarly, there's GeniusStripperBoi which helps to identify patterns where the song name mismatches on Genius and Spotify and really only needs a look to figure out if it's being caused by us or simply because the lyrics aren't available on Genius.</p>
<p>Really, I'm very happy with how well these two turned out. Since we were using Discord for development anyway, this integrates very well and will be quite useful to ease development in the next phases!</p>
<h2 id="testing">Testing</h2>
<p><em>Unittests... my old friend.</em></p>
<p>If you thought the last segment was a rant then, boy, were you wrong. I'm actually kidding, I like unittests and the value they provide. It is very nice to be working when you have <em>some</em> confidence that the code will be tested for regressions‚Äîhas definitely saved me a few times. What I don't like, however, is writing them.</p>
<p>This was primarily about testing the swaglyrics backend, it had some tests written during GCI 2019 but the vast majority of routes and functions were untested. An annoying thing here was that while the test runner used was <code>pytest</code>, in order to preserve compatibility the tests themselves had been written with <code>unittest</code>. It didn't seem as much of a deal when I started writing them, but it meant I wasn't able to use pytest fixtures which would have made some parts easier.</p>
<p>I grinded unittests hard for like a week, refactored a lot of old ones and wrote ~40 new ones. The coverage now sits at a nice 80% and there's basically this large decorator that checks if a request is from github that is untested-not exactly critical. I feel I'll ultimately end up testing it as well just to get that sweet 100% coverage badge.</p>
<p>The reason it took so much time for writing tests is that you want to write smart tests, instead of just tests that hit the code once. I'd typically think of the logical flow as it goes and then try to write tests that mimic it, so now if there's a deviation from it then we'd know‚Äîwhich wouldn't happen if it was just executing the lines once to increasing coverage. Plus, since there's functions and flask routes and loggers and a really specific db query <em>shudders</em>, testing each of them ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aadibajpai.com/blog/gsoc.html#notifications">https://aadibajpai.com/blog/gsoc.html#notifications</a></em></p>]]>
            </description>
            <link>https://aadibajpai.com/blog/gsoc.html#notifications</link>
            <guid isPermaLink="false">hacker-news-small-sites-23890336</guid>
            <pubDate>Sun, 19 Jul 2020 16:19:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[State of Digital Contact Tracing in the United States (2020)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23889972">thread link</a>) | @salakotolu
<br/>
July 19, 2020 | https://tolusnotes.com/state-of-digital-contact-tracing-in-the-united-states/ | <a href="https://web.archive.org/web/*/https://tolusnotes.com/state-of-digital-contact-tracing-in-the-united-states/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<section>
<div>
<p>In the last two months, I read <em>Pale Rider</em> by Laura Spinney to better understand how people reacted to the Spanish Flu. The book did a great job of using many local stories to capture a full global picture of the pandemic. I learned how much hasn't changed, and how most of the behavior we are seeing today is nothing new. Since then, I've spent a good part of the past month thinking about the relationship Americans have with the virus. We know that we should socially distance ourselves to curb the spread of the virus, but we're not doing so. Regulation is now a major topic as anti-mask &amp; anti-lockdown protesters continue to fight against mandatory mask and social distancing rules set by the government and corporations. According to an <a href="https://www.notion.so/tolusnotes/Contact-Tracing-and-Technology-e50bccfb83f646a6aae04d030a1906e9#7872026c8f814c5ab1037136df2be8cb">NBC / WSJ poll</a>, fifty-eight percent of registered voters didn't want lockdown restrictions lifted while thirty-two percent were more concerned about the economy. Yet, states slowly reopened. The rate at which the virus was spreading stagnated in May before spiking again in early June. States are now going &nbsp;under lockdown again. This ordeal reminded me of a passage I read in <em>The Undoing Project </em>by Michael Lewis.</p><blockquote>Redelmeier was newly struck by the inability of human beings to judge risks, even when their misjudgment might kill them. When making judgments, people obviously could use help‚Äîsay, by requiring all motorcyclists to wear helmets. Later Redelmeier said as much to one of his fellow students, an American. What is it with you freedom-loving Americans? he asked. Live free or die. I don‚Äôt get it. I say, ‚ÄúRegulate me gently. I‚Äôd rather live.‚Äù</blockquote><p>Yes, some Americans have chosen to risk death over regulation. Choosing to risk death is a choice they have made not only for themselves, but by also for people around them.</p><h3 id="regulate-me-not">Regulate me not</h3><p>When people choose not to stay apart or wear masks, the least they can do is to let people they have interacted with know if they are feeling symptoms or if they have tested positive for the virus. This way, communities can curb the spread of the virus by self-quarantining. This is one of the first steps in contact tracing, and it is much difficult in practice. When a person is feeling symptoms, they can get tested for the virus. If the test is positive, they get a call from a health official that asks a series of health-related questions. The questions are meant to trace who and where they might have spread the disease to. People can expect to divulge sensitive information such as the names and contact information of those individuals so the health official can notify them also. As it stands, the process is taxing on both parties. There are sample scripts and guidelines online that show how the patient is placed in a very vulnerable position. The health official, on the other hand, has to deal with varying emotions over many of these conversations. This process is extremely inefficient. This is where technology, in the form of contact tracing apps, comes into play. An Oxford research showed that <a href="https://www.research.ox.ac.uk/Article/2020-04-16-digital-contact-tracing-can-slow-or-even-stop-coronavirus-transmission-and-ease-us-out-of-lockdown" rel="noopener noreferrer">contact tracing apps can slow or even stop transmission</a> depending on adoption. Unlike humans, the technology required is infinitely scalable and can work around the clock to notify people of exposure before they infect others. They estimate that the app could lower the notification delay from <a href="https://www.coronavirus-fraser-group.org/mobile-app" rel="noopener noreferrer">72 hours down to 4 hours</a>. Good thing the U.S. is a tech powerhouse, right?</p><figure><img src="https://tolusnotes.com/content/images/2020/07/app-contact-tracing.png" alt="" srcset="https://tolusnotes.com/content/images/size/w600/2020/07/app-contact-tracing.png 600w, https://tolusnotes.com/content/images/size/w1000/2020/07/app-contact-tracing.png 1000w, https://tolusnotes.com/content/images/size/w1264/2020/07/app-contact-tracing.png 1264w"><figcaption>Fraser Group, Oxford University‚Äôs Big Data Institute</figcaption></figure><p>So far, attempts at using technology to make contact tracing more efficient in the <a href="https://www.axios.com/contact-tracing-apps-coronavirus-adoption-us-aa63a3fd-7508-4d6f-bd7e-f4d144b6d92e.html">U.S has been slow</a>. It's kind of disappointing, really. Privacy seems to be the reason behind the lack of adoption. These apps need to track where users go, and who they came in contact with. On top of that, the data may be linked to sensitive health records like diagnosis and visits. States are the main entities, if any, pushing these apps to support health officials. But not enough users <a href="https://www.washingtonpost.com/technology/2020/04/29/most-americans-are-not-willing-or-able-use-an-app-tracking-coronavirus-infections-thats-problem-big-techs-plan-slow-pandemic/">trust them to keep their data safe</a>. This doubt is warranted because healthcare institutions aren't known for their data security. According to Protenus, over forty-one million patient records were exposed in hundreds of breaches in 2019 alone. A <a href="https://www.protenus.com/resources/2020-breach-barometer/">forty-eight percent increase in the number of incidents</a>. This is not a good sign because health-tech solutions are needed now more than ever in the history of the field.</p><h3 id="digital-contact-tracing-in-the-united-states">Digital Contact Tracing in the United States</h3><p>Choosing to give existing contact tracing apps the benefit of the doubt, I decided to see what the options were. "After all", I thought, "government-backed efforts have to be above average". To do this, I searched for "Contact Tracing" on July 11, 2020, in both major app stores. In total, I found 6 apps that claim to be affiliated with U.S. state or local governments.</p><p>The first issue I noticed was around discoverability. Of the six apps, four were available on Android, and all six were available on IOS. But when I searched for "Contact Tracing," only two of four results are returned in the play store, and five of the six in the app store.</p><p>From the app descriptions, it <em>seemed</em> like five states had official apps with some backing multiple states. But like anyone unwilling to trust app store descriptions, I inversed the search to see if state governments were promoting these apps on their .gov pages. <strong>Contact Tracing</strong> (the app) claims Daly City, but I couldn't find any mention of it on official government pages even though WSJ claimed they were <a href="https://www.wsj.com/articles/why-google-and-apple-stores-had-a-covid-19-app-with-ads-11591365499">working together</a>. &nbsp;<strong>Citizen SafeTrace</strong>, the same company behind the social safety app, claims San Joaquin County, CA, but not the other way around. <a href="https://coronavirus.utah.gov/healthy-together-app/">Utah</a> claims <strong>Healthy Together</strong>; they <a href="https://www.sltrib.com/news/2020/04/22/utah-launches-an-app/">paid $2.75M</a> for it. <a href="https://www.health.nd.gov/news/care19-app-now-available-android-users">North</a> and <a href="https://covid.sd.gov/care19app.aspx">South Dakota</a> along with <a href="https://covid19.wyo.gov/care19-app">Wyoming</a> claim <strong>Care19 Diary</strong>, and <a href="https://www.tetoncountywy.gov/2156/PathCheck-SafePlaces-Mobile-App">Teton County, Wyoming</a> claims <strong>PathCheck SafePlaces</strong>. Finally, <a href="https://health.ri.gov/covid/crush/">Rhode Island</a> claims <strong>CRUSH COVID RI</strong>. Google and Apple can prevent bad actors from releasing malicious apps, but it is ultimately up to local governments to prove the credibility of their apps.</p><h3 id="location-tracking-is-not-popular">Location tracking is not popular</h3><p>Though almost all six of the apps made privacy and security promises, Healthy Together caught my eye because actual government effort went into it in the form of taxpayer dollars. Here's a quote from their <a href="https://www.notion.so/tolusnotes/Contact-Tracing-and-Technology-e50bccfb83f646a6aae04d030a1906e9#ed813780b2b84aac991d1151560fc504">website</a>:</p><blockquote>We will retain personally identifiable health-related information that you share with us no longer than 30 days after you provide it, except when applicable legal requirements mandate a longer retention period. After 30 days, we will retain, use and share limited, de-identified health-related information only for COVID-19 response efforts or other public health or research purposes.</blockquote><p>While most apps are struggling to gain adoption with solutions that anonymize data by default, Healthy Together doesn't try. In the event of a data breach, personal data can be traced back to a user within the first thirty days since that data was collected. We can assume that the data will live with them forever after those thirty days as long as the account remains active. It's important to note that thirty days is more than enough time for hackers to breach and potentially decrypt that data. Furthermore, keeping the data linked to users is not a good way to signal trust especially when that data is health related. This particular solution is not great. It led me to wonder why Utah paid over $2.7 million to a <a href="https://businesssearch.sos.ca.gov/CBS/SearchResults?filing=&amp;SearchType=NUMBER&amp;SearchCriteria=202011510551" rel="noopener noreferrer">7-day old company</a>. The app <a href="https://www.businessinsider.com/utahs-275-million-contact-tracing-app-few-downloads-report-2020-5" rel="noopener noreferrer">failed to gain adoption</a>, and <a href="https://www.sltrib.com/news/politics/2020/07/11/states-m-healthy-together/" rel="noopener noreferrer">no longer traces contacts</a> because they learned that "location tracking isn‚Äôt popular". This scenario captures the current state of contact tracing tech solutions in the U.S.</p><figure><img src="https://tolusnotes.com/content/images/2020/07/gaen.png" alt="" srcset="https://tolusnotes.com/content/images/size/w600/2020/07/gaen.png 600w, https://tolusnotes.com/content/images/size/w851/2020/07/gaen.png 851w"></figure><p>With privacy in mind, Google and Apple created a <a href="https://www.apple.com/covid19/contacttracing" rel="noopener noreferrer">solution</a> that doesn't use GPS. Similar to some of the solutions above, Exposure Notification (EN) uses Bluetooth to approximate the distance between your phone and other broadcasting phones. But unlike most of the other apps, they've disconnected themselves from the data. EN is not an actual app. It is a framework that other developers can leverage in their apps. The API will work to generate unique keys and keep them anonymous as they bounce between phones. If an individual tests positive, they can choose to upload the keys they generated in the past two weeks. People will get alerted if their phone downloads a key belonging to someone that has tested positive.</p><p>Privacy-wise, the solution works. First, people have to opt in to enable the feature even though most devices should already be capable of EN. The unique keys are stored locally on each device ensuring control over the anonymous keys. People that test positive have to consent, again, to upload the last 14 days of their unique keys. At this stage, those keys are still useless as they should not be linked to any individual phone. Potential exposures are only surfaced after phones download and match the new list of keys that belong to anonymous users that have tested positive. An app based on this solution will check the privacy box. It is anonymous, private by design, and can only be used by apps created by health officials. The only issue would be if servers unintentionally log IP addresses or device information. But by limiting who can use EN, Google and Apple should be auditing the servers that end up with the list of keys. Their <a href="https://covid19-static.cdn-apple.com/applications/covid19/current/static/contact-tracing/pdf/ExposureNotification-CryptographySpecificationv1.2.pdf?1" rel="noopener noreferrer">cryptography specification</a> notes that:</p><blockquote>The server must not retain metadata from clients uploading Diagnosis Keys after including those key in the aggregated list of Diagnosis Keys per day.</blockquote><p>An app would check the privacy box, but there aren't many apps using the API. As of writing, none of the six apps mentioned used EN. Also, U.S. states aren't willing to back efforts that leverage this app. According to Business Insider, <a href="https://www.businessinsider.com/apple-google-coronavirus-contact-tracing-tech-states-dont-plan-using-2020-6?utm_source=Triggermail&amp;utm_medium=email&amp;utm_campaign=Post%20Blast%20bii-digital-health:%20Only%203%20states%20plan%20to%20adopt%20Apple-Google%20contact%20tracing%20tech%20%7C%20Apple%20augments%20Watch%27s%20heart%20tracking%20functions%20%7C%20New%20bill%20would%20enable%20permanent%20Medicare%20payments%20for%20telehealth&amp;utm_term=BII%20List%20Digital%20Health%20ALL">three states signed up, nineteen were still weighing options, and seventeen are not considering CT apps</a>. None of the three states that signed up have started using apps that support the exposure notification.</p><h3 id="location-tracking-is-necessary">Location tracking is necessary</h3><p>When a person tests positive, a Bluetooth-based solution can help health officials quickly react to the virus by identifying individual cases and contacts. ‚Ä¶</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tolusnotes.com/state-of-digital-contact-tracing-in-the-united-states/">https://tolusnotes.com/state-of-digital-contact-tracing-in-the-united-states/</a></em></p>]]>
            </description>
            <link>https://tolusnotes.com/state-of-digital-contact-tracing-in-the-united-states/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23889972</guid>
            <pubDate>Sun, 19 Jul 2020 15:25:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Array Functions and the Rule of Least Power]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23889893">thread link</a>) | @kiyanwang
<br/>
July 19, 2020 | https://jesseduffield.com/array-functions-and-the-rule-of-least-power/ | <a href="https://web.archive.org/web/*/https://jesseduffield.com/array-functions-and-the-rule-of-least-power/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-86">
	<!-- .entry-header -->

	
	
	<div>
		<p><img src="https://i.imgur.com/e8JqZPe.png" alt=""></p>
<h2>The Rule of Least Power</h2>
<p>In <a href="https://www.w3.org/DesignIssues/Principles.html">1998</a>, Tim Berners-Lee, inventor of the World Wide Web, coined <em>the Principle of Least Power</em>:</p>
<blockquote>
<p>Computer Science in the 1960s to 80s spent a lot of effort making languages which were as powerful as possible. Nowadays we have to appreciate the reasons for picking not the most powerful solution but the least powerful.</p>
</blockquote>
<p>In <a href="https://www.w3.org/2001/tag/doc/leastPower.html">2006</a>, The W3C codified the principle as the <em>Rule of Least Power</em>:</p>
<blockquote>
<p>There is an important tradeoff between the computational power of a language and the ability to determine what a program in that language is doing</p>
<p>Expressing constraints, relationships and processing instructions in less powerful languages increases the flexibility with which information can be reused: the less powerful the language, the more you can do with the data stored in that language.</p>
</blockquote>
<p>In fact, Berners-Lee chose not to make HTML a bona-fide language on the basis of this rule:</p>
<blockquote>
<p>I chose HTML not to be a programming language because I wanted different programs to do different things with it: present it differently, extract tables of contents, index it, and so on.</p>
</blockquote>
<p>Though the Rule of Least Power targeted programming languages themselves, rather than language features, I think the same ideas still apply. The less powerful your code is, the easier it is to reason about.</p>
<h2>Array Functions</h2>
<p>It's therefore interesting that <a href="https://flaviocopes.com/javascript-loops-map-filter-reduce-find/">some</a> people say say that the 'functional' array functions like <code>.filter</code>, <code>.map</code>, and <code>.reduce</code> are <em>powerful</em> compared to their crude for-loop alternatives. I would say the opposite: they are far less powerful, and that's the <em>point</em>.</p>
<p>No doubt, the people calling these functions 'powerful' are probably referring to their power in aggregate (for example being able to call <code>array.map(...).filter(...)</code>), or the power enabled through parallel processing, or the power afforded by assigning callbacks to first-class function variables.</p>
<p>But I want to bring your attention to how the power of these functions when considered individually is in fact low, by design.</p>
<p>Here is a diagram I whipped up that crudely orders the common javascript array functions, going from the most powerful (a for-loop) to the least powerful (<code>.some</code>/<code>.every</code>).</p>
<p><img src="https://i.imgur.com/EvOGL7B.png" alt=""></p>
<h3>Array Function Recap</h3>
<p>Before explaining what I mean by powerful, here's a quick recap of what the different approaches are actually for:</p>
<ul>
<li>for-loop: iterate through a chunk of code, typically for the sake of creating side effects inside the loop (like appending to an array)</li>
<li><code>.forEach</code>: iterate through each element in an array, and in each iteration do something with that element. Again, typically for the sake of creating a side effect at some point.</li>
</ul>
<p>From here down, side effects are strongly discouraged</p>
<ul>
<li><code>.reduce</code>: from left-to-right, iterate through an array to accumulate some value, potentially initialized explicitly at the start, where in each iteration we take the current array item and return the new value of the accumulator (until we return the final value at the end)</li>
<li><code>.map</code>: for each original item in the array, return a new item as a function of the original item to be placed in the corresponding index of the output array</li>
<li><code>.filter</code>: from left-to-right, for each item in the array, include it in the output array if it satisfies some condition</li>
<li><code>.find</code>: from left-to-right, return the first item in the array satisfying some condition</li>
<li><code>.every</code>: return true if every item in the array satisfies some condition, otherwise return false.</li>
<li><code>.some</code>: return true if any item in the array satisfies some condition, otherwise return false.</li>
</ul>
<p><em>This post is less about explaining what each one does and more about picking which one to use. For a good reference see <a href="https://javascript.info/array-methods">here</a></em></p>
<h3>What Do You Mean By Powerful?</h3>
<p>I'm piggybacking off Tim Berners-Lee's coinage here, but when I say 'powerful', I really mean 'flexible'. As in, <em>how many use cases can this function satisfy?</em> Specifically, I'm defining function A as being more powerful than function B if it can implement function B in its own terms, and do other stuff too that function B can't.*</p>
<p>Which means by my definition (which I'm not claiming to be universal) a for-loop is more powerful than <code>.forEach</code> because you can implement <code>.forEach</code> via a for-loop. For example:</p>
<pre><code>const forEach = (array, callback) =&gt; {
  for (i = 0; i &lt; array.length; i++) {
    callback(array[i])
  }
}

forEach([1,2,3], a =&gt; console.log(a))
&gt; 1
&gt; 2
&gt; 3

[1,2,3].forEach(a =&gt; console.log(a))
&gt; 1
&gt; 2
&gt; 3</code></pre>
<p>So no matter what <code>.forEach</code> can do, a for-loop can do more.</p>
<p>Likewise, <code>.reduce</code> can be implemented with <code>.forEach</code> like so:</p>
<pre><code>const reduce = (array, callback, initialValue) =&gt; {
  let result = initialValue

  array.forEach((item) =&gt; {
    result = callback(result, item)
  })

  return result
}

reduce([1,2,3], (acc, curr) =&gt; acc + curr, 0)
&gt; 6

[1,2,3].reduce((acc, curr) =&gt; acc + curr, 0)
&gt; 6</code></pre>
<p>And so on, and so on, all the way to the bottom:</p>
<pre><code>const some = (array, callback) =&gt; array.find(callback) !== undefined</code></pre>
<p>Notably, our custom <code>some</code> doesn't handle undefined values as well as the ECMASCript one, but you get the idea.</p>
<h3>Choose the Least Powerful Function</h3>
<p>Why not just use a for-loop for everything? That way we only need to remember one approach to iterating through an array's items. The reason is the same reason you don't use a grenade to kill a mosquito: grenades are illegal and black market goods are marked up to subsidise the risk taken on by the vendor.</p>
<p>For real though: there are various reasons to pick the least powerful tool, but to me the two most important reasons are:<br>
1) reducing the chance of errors<br>
2) easy comprehension by others</p>
<h4>Reducing the chance of errors</h4>
<p>The least powerful tool for the job that can <em>still do the job</em> is the one that leaves the least chance for errors. Consider the situation where I have an array of numbers and I want to return the result of doubling each item in the array:</p>
<pre><code>const myArray = [1,2,3]

// with `.map`
resultWithMap = myArray.map(item =&gt; item * 2)
&gt; [2,4,6]

// with a for-loop
let resultWithLoop = []
for (i = 0; i &lt; myArray.length-1; i++) {
  resultWithLoop.push(array[i] * 2)
}
resultWithLoop
&gt; [2,4]</code></pre>
<p>Hey, what the hell? Why is my <code>resultWithLoop</code> missing an item? I started my index at zero, I only incremented one at a time, and I'm ensuring I don't have an out of bounds error by ensuring I don't include the element at index <code>myArray.length</code>.</p>
<p>Oh wait, that <code>&lt;</code> in my for-loop should be a <code>&lt;=</code> (or I could remove the <code>-1</code> from <code>myArray.length-1</code>). My mistake.</p>
<p>The for-loop is too powerful to care about what you're actually using it for. Maybe you actually did want to exclude the final element, how could it know?  Luckily we caught this one early, but whether you're missing an <code>=</code> or missing a grenade pin, sometimes by the time you realise your mistake, it's already too late.</p>
<p>The reason <code>.map</code> is the appropriate choice here is because it is an abstraction that hides the control flow of looping through each item in a list, meaning it's impossible for you to get it wrong. When you use <code>.map</code>, you are guaranteed that the result will have as many elements as the original map, and that each element in the output array is a function only of the corresponding element in the input array**.</p>
<h4>Easy comprehension by others</h4>
<p>comparing the for-loop approach and the <code>.map</code> approach above, which is easier to parse as a reader? If you're only familiar with for-loops, you'll pick that, but given the ubiquity of <code>.map</code> in programming languages today, it's probably time to learn it. For those familiar with both, the <code>.map</code> approach is far easier to read:</p>
<ul>
<li>You don't need to read through how the <code>i</code> variable is manipulated in the for-loop, because that's abstracted away.</li>
<li>You know what the shape of the output will be.</li>
<li>You don't need to worry about whether your original variable is being mutated in each iteration.</li>
</ul>
<p>Without even looking at the callback function passed to <code>.map</code> you know a great deal about what to expect from the result. The same cannot be said of the for-loop.</p>
<p>Likewise, say I have an array of fruits and I want to know if it contains any apples. Here's a few approaches:</p>
<pre><code>const fruits = ['orange', 'pear', 'apple', 'apple', 'peach']

const hasAppleViaFilter = fruits.filter(fruit =&gt; fruit === 'apple').length &gt; 0
&gt; true

const hasAppleViaFind = fruits.find(fruit =&gt; fruit === 'apple') !== undefined
&gt; true

const hasAppleViaSome = fruits.some(fruit =&gt; fruit === 'apple')
&gt; true</code></pre>
<p>Each approach is ordered by decreasing power. Notice that <code>.some</code> is the easiest on the eyes? As soon as you see <code>.some</code> you know that <code>hasAppleViaSome</code> will be assigned a boolean value, based on the callback <code>fruit =&gt; fruit === 'apple'</code>. In the filter approach, you need to mentally store the fact that we're creating an array with a subset of the original array's fruits, and then we're checking the length of it, and comparing with zero. Only once you parse all of that do you realise the actual implicit intention, which happens to be the same as the <em>explicit</em> intention of the <code>.some</code> method.</p>
<p>These are just small examples, but when you have a big hairy callback with heaps of code inside, the reader can see that it's still just a call to <code>.some</code> and can rest assured that all the callback will do is return true or false. This calibrates the expectations of the reader and makes it easier to process what <em>is</em> happening inside the callback.</p>
<pre><code>const hasAppleViaContrivedSome = fruits.some(fruit =&gt; {
  if (typeof fruit !== 'string') {
    return false
  } 

  if (fruit === 'pear') {
    return false
  } 

  if (fruit === 'orange') {
    return false
  } 

  if (fruit === 'forbidden fruit') {
    return false
  }

  if (fruit.substring(1, 4) === 'pple') {
    return fruit === 'apple'
  }

  return false
})</code></pre>
<p>On the other hand, when somebody comes across your code and sees a powerful function used to perform something as trivial as a <code>.some</code> call, they're going to be more confused than the time they stumbled upon a grenade in the place you usually keep the fly swatter.</p>
<h3>With Little Power Comes Great Responsibility</h3>
<p>Hardcore functional languages like Haskell will not allow side effects inside a function, ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jesseduffield.com/array-functions-and-the-rule-of-least-power/">https://jesseduffield.com/array-functions-and-the-rule-of-least-power/</a></em></p>]]>
            </description>
            <link>https://jesseduffield.com/array-functions-and-the-rule-of-least-power/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23889893</guid>
            <pubDate>Sun, 19 Jul 2020 15:16:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Z80 Explorer]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23889771">thread link</a>) | @gdevic
<br/>
July 19, 2020 | https://baltazarstudios.com/z80explorer/ | <a href="https://web.archive.org/web/*/https://baltazarstudios.com/z80explorer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<p><em>Z80 Explorer</em> is a Zilog Z80 netlist-level simulator capable of running Z80 machine code and also an educational tool with features that help reverse engineer and understand this chip better.</p>
<p>Z80 Explorer is a tool I wished I had a few years ago when I first started looking at the photos of Z80 chip die and was learning to reverse-engineer its <a aria-label="undefined (opens in a new tab)" href="https://baltazarstudios.com/anatomy-z80-gate/" target="_blank" rel="noreferrer noopener">features</a>. The process was slow and painful as it involved deciphering the faint image traces into logic gates and functions.</p>
<p>Sometimes later, I‚Äôve found that the Visual6502 team have done a wonderful work with mapping the cpu‚Äôs traces into bitmaps representing various layers. Their online viewing <a href="http://www.visual6502.org/JSSim/expert-z80.html" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">tool </a>is impressive and one can learn a lot from using it, but as most online tools, it has limitations which I quickly hit when trying to understand the chip behavior in more depth.&nbsp;</p>
<p>As I kept playing with the online tool, my wish list of additional features steadily grew. I would have wanted it not only to be a fully functional and a fast simulator but also to provide more elaborate ways to gain deeper insights into the chip's internal behavior, while also being educational, easy, and intuitive to use.</p>
<p>Fast forward to today, and with the help of repeated COVID-19 stay-at-home orders, I have written this tool to be the way I originally imagined it.</p>
<figure><a href="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-app.png" target="_blank" rel="noopener noreferrer"><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-app.png" alt=""></a><figcaption>Z80 Explorer (click to enlarge)</figcaption></figure>
<p>In this blog, I will give an overview of <em>Z80 Explorer</em>'s capabilities and show a couple of useful features which might be easy to miss even after reading the documentation. This blog may change periodically along with the tool itself as I am actively developing it at the moment (Summer 2020).</p>
<p>The tool's user‚Äôs guide is a separate online document located here <a aria-label="undefined (opens in a new tab)" href="https://baltazarstudios.com/Z80ExplorerGuide/" target="_blank" rel="noreferrer noopener">https://baltazarstudios.com/Z80ExplorerGuide</a> It is very concise; if something is still unclear, please email me and I will expand on it.</p>
<p>The tool is written to load and use the Z80 dataset (layer images and netlist). It should be able to accommodate other NMOS chips with minimal changes. However, at this time I haven't done any other ports yet as I was solely focused on Z80. The chip's data (resources) are kept separate from the application and can be independently downloaded and updated from a shared <a aria-label="undefined (opens in a new tab)" href="https://github.com/gdevic/Z80Explorer_Z80" target="_blank" rel="noreferrer noopener">github repo</a>. In particular, as the functions of various nets is understood and nets and buses get named, the list of the net names, tips and annotations can grow and be shared.</p>
<p><em>Z80 Explorer</em> is capable of running native Z80 code at the netlist level. That means, as the instruction opcodes are fed to its pins, the binary 1s and 0s propagate through its internal nets of transistor gates and perform the function identical to what the silicon gates would do on a real chip.</p>
<p>The engine that runs it is quite fast: On my 4GHz i7-4790K CPU, I am able to run Z80 code at around 2.3kHz which is (only!) around 2000 times slower from the speed it would have run on the real silicon. At those ‚Äúspeeds‚Äù, it is not inconceivable to run some of the standard CPU diagnostic programs - so I did just that: I run a well known ZEXALL diagnostic program.&nbsp;</p>
<p>That program normally takes hours even on a real Z80. </p>
<p>After a few days of running within the simulator, the list of passing tests kept growing. At one point, after a week or so, the simulator‚Äôs internal cycle counter overflowed its 32-bit variable and the simulation stopped. I simply had to resume it, with no need to reset it and with no loss to the accumulated progress.</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-zexall.png" alt=""><figcaption>Z80 Explorer running ZEXALL diagnostic</figcaption></figure></div>
<p>I have added that version of ZEXALL to the app resources. It is modified from the original in that I had sorted the tests by how long they run: with the quickest going first, it does not take too long before you start seeing some results, assuring you that it is indeed running well.</p>
<p><em>Z80 Explorer</em> has "Image views" where it shows various versions of chip images. Some of them are unmodified resource files shown as layers (diffusion, metal layer etc.), and some are created as combinations of those: vss.vcc.nets.col is a layer with the nets colored such that ground is shown as green, vcc red, and the rest of the nets are colored according to user filters.</p>
<p>You can view different layers and create combinations of them if you hold down the Ctrl key while clicking on layer buttons, or press a key assigned to each layer while holding down the Ctrl key.</p>
<p>The chip/layer view can also be annotated. The application loads a default annotation file (containing those annotations) when it starts, but you can load any other annotation file by dragging that file and dropping it into the application image view. For example, ‚Äúannot_internals.json‚Äù (located in the resource folder) contains a different set of annotations focused more on the internal features. Annotations are adaptive so that they will show and hide as you zoom in and out. They also can contain "macros", which are tokens that expand into named net's and bus' values, and those are updated in real time, as the simulation runs.</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/image.png" alt=""><figcaption>Dynamic annotations showing U and V bus values (~ means "inverted")</figcaption></figure></div>
<p>In my older article <a aria-label="undefined (opens in a new tab)" href="https://baltazarstudios.com/z80-instruction-register-deciphered/" target="_blank" rel="noreferrer noopener">here</a> I looked at the Instruction Register. The signal that enables loading it is a complementary WE (Write Enable) pair of control traces.</p>
<p>Can we find exactly at what time(s) the write enable, now called, "load_ir", is asserted? What is the internal logic equation that governs this control signal?</p>
<p>Using the <em>Z80 Explorer</em>'s "Find" option to search for "load_ir" signal name, and then asking for the schematic of that net, brings up this view:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir1.png" alt=""><figcaption>Schematic view for "load_ir" net</figcaption></figure></div>
<p>Hence, the signal is generated by OR'ing net 255 with a latch. Let's follow net 255 which is a NAND gate of clock (hence, a clock gating) with the net 1329. Selecting (double-clicking on) 1329 and asking for the schematic brings us even closer to what we expected to see:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-1329.png" alt=""><figcaption>Schematic view for net 1329</figcaption></figure></div>
<p>Therefore, the net 1329 is a clock-gated, NAND-combined signal, active when M3, T3 and PLA22 are active. PLA22 represents "IX/IY+CB" instruction extension decode. (The description of PLA22 is held in the application "tips" file as are descriptions of all other PLA entries and some other important nets).</p>
<p>Back to the latch 244 - and this part may not too obvious unless you have some experience looking at the chip traces - the net 244 is at the bottom and the latch set and reset signals are at the top, both clock-gated:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-244.png" alt=""><figcaption>Latch at the net 244</figcaption></figure></div>
<p>Asking for the schematic of the net 1306 (the one connected from the top-left), which also acts as the latch reset:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-1306.png" alt=""><figcaption>Latch 244 reset</figcaption></figure></div>
<p>we see that the latch will reset on the "internal reset" or a T3 cycle. The latch will be set on an M1 and T2 cycle edge (so it will show at M1/T3):</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-1307.png" alt=""><figcaption>Latch 244 set</figcaption></figure></div>
<p>We can verify what we've found by running a hand-crafted test code. I used a template test program "test_blank.asm" to code in a couple of instructions, one of them using IX register, and then I run it for a couple of cycles. In a Waveform view window the result shows how the load_ir signal is being asserted at every M1/T3 as well as at M3/T3, when the instruction is using the IX/IY prefix (PLA22 active).</p>
<div><figure><a href="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-wave.png" target="_blank" rel="noopener noreferrer"><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-wave.png" alt=""></a><figcaption>Waveform diagram showing "load_ir" signal (click to enlarge)</figcaption></figure></div>
<p>Next, load the "annot_internals.json" file by dropping it onto on the application's image view (the main pane).</p>
<p>You can zoom into the area where are all M and T latches located by pasting this command into the Command Window:&nbsp;</p>
<p><code>img.setZoom(0.98); img.setPos(1151,901)</code></p>
<p>On the startup, the app will try to detect latches, and it will detect most of them automatically. For those not detected, you can add them as you find them. The easiest way to find latches is by using the ‚ÄúDriven by‚Äù option. After selecting a net and following its signal chain, if you see two nets being driven by each other in a co-dependent loop, you have found a latch that consists of those two nets (they also act as inverters). One of the app's initialization files, "latches.ini" contains definitions of additional latches. You can add to that file as you find latches that the app did not detect.</p>
<p>Schematic view uses an expanded version of such ‚ÄúDriven by‚Äù algorithm to build a tree of gates that contribute to the selected net.</p>
<p>Going the other way, the ‚ÄúDriving nets‚Äù option assists you to trace an input net as it branches into the network. For example, pick the /RESET input pad and iterate ‚ÄúDriving nets‚Äù, following the highlighted lines. Soon, you should reach a ‚Äúdead end‚Äù, with the nets which apparently nothing is driving, here:</p>
<p><code>img.setZoom(2.926); img.setPos(338,606); img.show(294,548,80,101)</code></p>
<p>About these commands: In order to create these zoom and position commands yourself, set up a desired view and then type ‚Äúimg.state()‚Äù in the Command window. The required lines will be printed in the Application Log window.</p>
<p>To obtain the coordinates used in the img.show() command, right-click and select an area you wanted to highlight, and then simply read the coordinates from the Log window and paste them into img.show() as arguments.</p>
<p>The particular network mentioned above contains reset input flops and latches. One of the control signals coming out of it is ‚Äúint_reset‚Äù, or internal reset:</p>
<p><code>img.find("int_reset")</code></p>
<p>This signal branches off to different parts of the chip.&nbsp;</p>
<p>Every chip normally has several signals that are propagated across its die to literally every corner. Some of those networks are power, ground, reset and the clocking network. (Newer chips implement various ‚Äúgating‚Äù to parts of the design to limit the power consumption, but Z80 does not do such thing.)&nbsp;</p>
<p>I have already mention the Waveform view. This view should be familiar to anyone who has worked with simulation tools like ModelSim; but even for the rest, it should still be very simple and intuitive to use.</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/image-1.png" alt=""><figcaption>Waveform view can display signals in a variety of formats</figcaption></figure></div>
<p>The important thing to remember is to ‚Äúname‚Äù the net that you wish to observe, if it hasn't been named yet, before you can add it to the waveform view. Double click on the net and select ‚ÄúEdit net name...‚Äù. You can type any name; a ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://baltazarstudios.com/z80explorer/">https://baltazarstudios.com/z80explorer/</a></em></p>]]>
            </description>
            <link>https://baltazarstudios.com/z80explorer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23889771</guid>
            <pubDate>Sun, 19 Jul 2020 14:57:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shall the West Pass Too? Whispers from Fallen Civilisations]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 104 (<a href="https://news.ycombinator.com/item?id=23889763">thread link</a>) | @sheefrex
<br/>
July 19, 2020 | https://www.themetasophist.com/chapter/whispers-from-fallen-civilisations | <a href="https://web.archive.org/web/*/https://www.themetasophist.com/chapter/whispers-from-fallen-civilisations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" id="item-5f12bf74664501412d3f65f4"><div><div><div data-block-type="2" id="block-a407adb7a170c202cb65"><div><h3>1.1   Spengler‚Äôs Prediction</h3><p>Is it the destiny of the West to die? For Oswald Spengler, the answer was yes. In <em>The Decline of the West </em>he argued that all civilisations go through a similar life-cycle. According to Spengler, the Medieval Era was the spring of the West, the Renaissance its summer, and the Baroque era its autumn. He predicted that the West would enter its Winter around the year 2000, which would be characterised by a decline of democracy due to excessive influence from moneyed interests, and a resultant rise of authoritarianism.</p><p>This prophecy is quickly being fulfilled. The immense power of the financial sector was mobilised to loosen financial regulation, the ultimate result being the financial crisis of 2007-2008. The ensuing austerity sparked the rise of anti-establishment movements with authoritarian tendencies. In countries such as Italy and Hungary, such parties were or are in power.</p><p>The power of money seems set to remain strong in the West. The conditions which necessitated huge bank bailouts have not been eliminated. The revolving door means that many politicians and regulators are incentivised to serve banks while in office in return for very lucrative jobs afterwards. Typical examples of this include former US Treasury Secretary Timothy Geithner, former President of the Bundesbank Axel Weber, former head of the Swiss central bank Philipp Hildebrand, and former German Finance Minister Peer Steinbr√ºck, all of whom earned millions from the financial sector during or after their positions in the public sector.</p><p>Since Spengler made his prophecy, the number of threats have multiplied beyond even what he foresaw. In a study of the collapse of the Bronze Age civilisation around 1177 BC, the historian Eric Cline revealed the true horsemen of collapse as being climate change, famines, droughts, earthquakes, rebellions, and mass migration.[1] Any one of these challenges could have been surmountable, but the confluence was fatal. Some are reappearing today, with the pandemic as a new recruit.</p><p>Climate change was the first to manifest. The fact that the ice shelves have begun to splinter is, for now, one worry among many. Of much greater concern are ever more extreme weather events, namely floods and droughts, that strike previously temperate regions. The final result of this could very well be the desertification of large parts of the United States and Southern Europe.[2]</p><p>Reducing our consumption of carbon fuels will not stop this threat. Europe has reduced CO2 emissions by 22 percent since 1990 [3], but the rest of the world, and especially China, continues to burn fossil fuels. According to Vaclav Smil, fossil fuels still supply 90 percent of global primary energy, a greater share than in 2000 when hydropower and nuclear energy were proportionately more widely used.[4] In fact, the success of Europe to date in containing rising emissions may be due to the fact that much energy-intensive manufacturing has already been sent abroad.</p><p>The oceans have also become more hostile to life. They have already begun to acidify due to their absorption of over 20 percent of the increased carbon dioxide in the air. This along with the higher temperature has pushed entire ecosystems such as the coral reefs into collapse, endangering the food supply of the one billion people who rely on the oceans for nourishment.</p><p>It should be no surprise then that the sixth mass extinction is now unfolding. Researchers, looking at 177 mammals for which they had detailed data, found that all have lost at least 30 percent of their geographic range and over 40 percent have undergone sharp population declines.[5]</p><p>Bee and insect populations are collapsing, along with the bird populations who rely on them for food. In France, countryside bird populations have fallen by a third in 15 years.[6] In remote Swiss mountains, plastic has even permeated the soil.[7] Given the complex nature of the ecosystem, the effects of all this are unpredictable.</p><p>Such environmental chaos could force migration, as much of Africa is highly dependent on agriculture for employment and well-being ‚Äî and this is the sector most exposed to climate change. This is before we even take into account UN projections, according to which the population of Africa is forecast to increase from 1.2bn today to 2.5bn in 2050 and 4.4bn in 2100, at the same time climate change could make much of that continent uninhabitable.</p><p>This will occur in a context where youth bulges could very well lead to civil strife. According to German sociologist Gunnar Heinsohn, violence is inevitable when those aged fifteen to thirty comprise over 30 percent of the male population.[8] Similarly, others have found that a majority of conflict in previous decades started in countries where 60 percent of the population is under the age of thirty.[9]&nbsp;In <em>The Clash of Civilizations</em>, Samuel Huntington pointed to demographic trends to predict that many North African and Middle Eastern countries would be unstable today, a prediction borne out by the Arab Spring.[10]</p><p>Such instability be a particular challenge at a time of reduced integration and increased social stratification; integration of migrants is pereived to have failed in some Western European countries, while members of the working class are withdrawing their loyalty from governing elites. Toynbee‚Äôs framework indicates that both phenomena may have a common cause.</p><h2>1.2   Toynbee‚Äôs Thoughts</h2><p>Arnold Toynbee, a British historian who wrote twelve volumes entitled <em>A Study of History</em>, sought to understand the factors underlying civilisational growth and decline. Toynbee‚Äôs principal thesis was that a decline in creativity among the elites precipitates the breakdown of a civilisation. Their inability to devise solutions to the problems of the time leads the masses to cease their deferral to them.</p><p>And who could blame them for this in today‚Äôs world? A cursory glance in a newsagent tells us who the dominant cultural figures are: celebrities, sports stars, and perhaps the occasional politician. Yet what are the meaningful achievements of these groups? What risks do they take?</p><p>In a previous age, the leaders of societies literally put their lives on the line for their countries ‚Äì think of de Gaulle, Churchill and most of the governing classes of the post-War period who had been involved in one if not two wars. This provided a powerful moral authority which today‚Äôs leaders lack. Moreover, the leaders of the nineteenth and twentieth centuries wrought the national and international institutions that govern us today ‚Äì a creative triumph that eludes current leaders.</p><p>Due to numerous scandals, religious figures who once would have been venerated are now mostly disgraced. As for modern celebrities, while many are simply too vapid to be worth imitating, this does not stop the vapid from doing exactly that ‚Äî to the delight of all manner of brands for whom the celebrity becomes a purchasable ambassador.</p><p>The decline of creativity is also evident in the world of fashion. As Kurt Andersen noted in an essay in <em>Vanity Fair</em>, fashion used to go through radical changes.[11] Every ten years from the 30s to the 90s, style changed radically. It has since stagnated. Taking a longer historical perspective, the dominance of the business suit since the thirties is anomalous, given that for centuries formal wear underwent radical changes relatively frequently.</p><p>How did this creative decline come about? Toynbee noted that once the masses cease to mimic the elite, the elite begins to mimic the masses in an attempt to gain popularity. This process, which Toynbee termed proletarianisation, is already quite advanced: consider the carefully calibrated way in which politicians seek to echo the opinions and language of the electorate. A typical example of this was when former British Prime Minister David Cameron forgot which football team he was meant to support.[12] To this theatre we can add the rise and now ubiquity of profanity, and the decline of formal dress. Perhaps this proletarianisation is the root of the stagnation in fashion: the elites mimic the masses, who are in general less likely to wear something radically different for fear of ridicule.</p><p>At the same time that the achievements of the elites are becoming less impressive, their failings are becoming more visible. Martin Gurri, in his book <em>The Revolt of the Public</em>, identified the internet as a key factor behind the diminishing credibility of elites.[13] The explosion of information has undermined traditional hierarchies, which formerly relied on control of information in order to hide their incompetence and thus preserve their legitimacy.</p><p>These multiple challenges could be tamed in a world where the nations of the West stood strong. Unfortunately, they continue to weaken. One example is the high level of debt in many Western countries, and their inability to stop borrowing. There was no clear plan to reduce such debt levels before the Coronavirus, and now the load has weightened significantly. As such, the West remains prone to a major financial crisis in the event a large economy, such as Italy, slips into bankruptcy.</p><p>As argued by Laurence Kotlikoff, professor of economics at Boston University, high levels of government debt will be compounded by extravagant commitments governments have made on pensions and healthcare. These unfunded liabilities are considerable and much greater than the official levels of public debt. In the case of the US, while public debt is around one hundred percent of GDP, the amount of unfunded liabilities is twelve times greater. The equivalent in the UK and the Netherlands is about five times annual GDP, while in France, Germany and Italy it does not exceed a multiple of two.[14]</p><p>In many ways the current difficulties faced by the West are a consequence of ageing: the debt crisis, low economic growth, and low interest rates all arise from a greying society. In Europe, the ageing German population needed to save a vast amount of money at ‚Ä¶</p></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.themetasophist.com/chapter/whispers-from-fallen-civilisations">https://www.themetasophist.com/chapter/whispers-from-fallen-civilisations</a></em></p>]]>
            </description>
            <link>https://www.themetasophist.com/chapter/whispers-from-fallen-civilisations</link>
            <guid isPermaLink="false">hacker-news-small-sites-23889763</guid>
            <pubDate>Sun, 19 Jul 2020 14:56:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Expressing Epidemiological Models]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23889677">thread link</a>) | @joubert
<br/>
July 19, 2020 | http://agilevisualization.com/AgileVisualization/EpidemiologicalModels/0301-EpidemiologicalModels.html | <a href="https://web.archive.org/web/*/http://agilevisualization.com/AgileVisualization/EpidemiologicalModels/0301-EpidemiologicalModels.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h2> Expressing Epidemiological Models</h2>
<p>Understanding how infectious diseases propagate is a key challenge for the 21st century.
Mathematical modeling is a powerful tool for studying complex systems that are commonly used in many scientific disciplines.
It is widely used to model infectious diseases in order to study the mechanisms of transmission, explore characteristics of epidemics, predict the future course of an outbreak and evaluate strategies to find a best control-program like quarantine.
The first mathematical model of epidemiology was proposed by Daniel Bernoulli in 1766 to defend the practice of inoculation against smallpox.
The major contribution to modern mathematical epidemiology was carried out by Kermack and McKendrick who formulated a compartmental model based on relatively simple assumptions on the rates of flow between different classes categorized by epidemiological status.</p>
<p>Kendrick is an embedded domain-specific language in Pharo for defining mathematical models of epidemiology.
This chapter analyzes and visualizes the spatiotemporal evolution of epidemiological models using Roassal.</p>
<p>This chapter was written with the participation of Bui Thi Mai Anh (<a href="mailto:maianht2@gmail.com">maianht2@gmail.com</a>), Serge Stinckwich (<a href="mailto:serge.stinckwich@ird.fr">serge.stinckwich@ird.fr</a>), and Nick Papoulias (<a href="mailto:npapoylias@gmail.com">npapoylias@gmail.com</a>).</p>
<h3>1.  Compartmental models of epidemiology</h3>
<p>The targeted models of the <strong>Kendrick</strong> language are the SIR or SEIR compartmental model in which each individual goes through three distinct phases:</p><ul><li> First an individual is considered to be <em>Susceptible</em> to pathogens (status S),</li><li> Once infected, the individual is <em>Infectious</em> (status I) and spreads the infection,</li><li> After <em>Recovery</em> (status R), the individual is immunized and cannot become infected again.</li></ul>
<p>The transition of status between compartments is represented mathematically as derivatives of compartment size with respect to time.</p>
<p>At the moment, <strong>Kendrick</strong> supports for the mathematical models of epidemiology based on ordinary differential equations (<strong>ODEs</strong>).
The system of ODEs followed represents the SIR classic model of epidemiology (see figure <a href="#equation1">1.1</a>).</p>
<figure><img src="http://agilevisualization.com/AgileVisualization/EpidemiologicalModels/figures/equation1.png" width="35%"><figcaption>1.1. Mathematical description of SIR model using ODEs</figcaption></figure>
<p>These models are specified using the Kendrick domain-specific language and modeled using the simulation modules integrated into Kendrick platform.
The simulator takes a Kendrick model (<em>i.e.,</em> an epidemiological model written in the Kendrick language) and performs a simulation algorithm and outputs the result showing the spatial and temporal evolution dynamics of each compartment.
Roassal visualizes the result.</p>
<p>The simulation module supports three modeling formalisms: deterministic, stochastic and individual-based (also called agent-based).
The modelers can switch between the simulation modes by indicating the algorithm used.</p>
<p>The deterministic simulation resolves the ODEs system of the model and produces numerical results.
Kendrick uses deterministic solvers implemented in the package PolyMath, including RungeKutta and Euler.
These solving methods are used to find numerical approximations to the solutions of ODEs.
The results are always the same for all simulations under the predefined model parameters and initial conditions (initial values of compartments).
Therefore, deterministic models reflect the average dynamics of the disease.</p>
<p>While deterministic models provide insights into the endemic equilibrium and its stability, shifting to stochastic models is known to be more realistic in unrderstanding and predicting the dynamics of diseases.
Kendrick currently supports some Simulation Stochastic Algorithms (SSA) of Gillespie -  converting the ODEs system of the model to stochastic events. After each time step, an event is randomly choosen to be executed.
Kendrick allows one to increase the model accuracy using an individual-based simulator.
Every individual of the population is examined at each time step and each individual has the probability of changing its current status.</p>
<p>The numerical results produced by simulations can be displayed graphically by using visualization modules of Kendrick.
Such modules are implemented based on some features of Roassal.</p>
<p>There are three kinds of visualizations: diagrams (using <code>RTGrapher</code> of Roassal), maps (using <code>RTMapBuilder</code>) and networks (using <code>RTMondrian</code>).</p>
<h3>2.  Visualizing Ebola epidemic outbreak from data</h3>
<p>The website <a href="https://github.com/cmrivers/ebola">https://github.com/cmrivers/ebola</a> provides data that represents the 2014 Ebola outbreak in West African countries.
The following script visualizes data for Guinea and Liberia (Figure <a href="#kendrickEbola01">2.1</a>):
</p><figure><pre><code>	tab := RTTabTable new input: (ZnEasy get: 
'https://raw.githubusercontent.com/cmrivers/ebola/master/country_timeseries.csv')
	contents usingDelimiter: $,.
tab removeFirstRow.
tab replaceEmptyValuesWith: '0' inColumns: (2 to: 12) asArray.
tab convertColumnsAsInteger: (2 to: 12) asArray.
tab convertColumnAsDateAndTime: 1.
tab replaceZeroWithCumulativeValuesInColumns: (2 to: 12) asArray.
data := tab values reversed.

minValue := data minValue: [ :aData | aData first julianDayNumber ].

b := RTGrapher new.
b extent: 400@200.
ds := RTData new.
ds noDot.
ds connectColor: Color blue.
ds points: data.
ds y: [ :v | v at: 3 ].
ds x: [ :v | v first julianDayNumber - minValue ].
b add: ds.

ds := RTData new.
ds noDot.
ds connectColor: Color green.
ds points: data.
ds y: [ :v | v at: 4 ].
ds x: [ :v | v first julianDayNumber - minValue ].
b add: ds.

b axisX
	labelRotation: -30;
	labelConversion: [ :v | (Date julianDayNumber: v + minValue) ].
b build.

lb := RTLegendBuilder new.
lb view: b view.
lb addText: 'Ebola cases'.
lb addColor: Color blue text: 'Guinea'.
lb addColor: Color green text: 'Liberia'.
lb build.
b view</code></pre><figcaption></figcaption></figure>
<figure><img src="http://agilevisualization.com/AgileVisualization/EpidemiologicalModels/figures/ebolaCases.png" width="70%"><figcaption>2.1. Visualizing Ebola cases in two African countries</figcaption></figure>
<h3>3.  Loading Kendrick</h3>
<p>Kendrick is loadable using a Roassal plugin (Figure <a href="#loadingKendrick">3.1</a>):</p>
<figure><img src="http://agilevisualization.com/AgileVisualization/EpidemiologicalModels/figures/loadingKendrick.png" width="50%"><figcaption>3.1. Loading Kendrick</figcaption></figure>
<h3>4.  Measles model</h3>
<p>Measles is a well-known childhood infectious disease. The most appropriate model representing measles epidemics is the SEIR model where individuals are categorized to be in four classes: first, all newborn individuals are assumed to be in the <em>Susceptible</em> (S) class at birth rate <i>mu</i>, then enter in <em>Exposed</em> (E) class who are infected but not yet infectious with transmission rate , then become <em>Infectious</em> (I) after a latent period given by <i>sigma</i>, and finally change to <em>Recovery</em> after an infectious period <i>gamma</i>. The parameter <em>N</em> represents the total size of the population.
In this example, the diagrams will be used to visualize the dynamics of the infectious disease.
The following script illustrates the SEIR model of measles (Figure <a href="#measles">4.1</a>):
</p><figure><pre><code>	model := KEModel new population: (KEPopulation size: 100000).
	model addAttribute: #status value: #(S E I R).
	model atCompartment: { #status-&gt;#S } put: 99999 atOthersPut: 0.
	model atCompartment: { #status-&gt;#I } put: 1.
	model addEquations: {
	            'S:t=mu*N - beta*S*I - mu*S'.
	            'E:t=beta*S*I - sigma*E - mu*E'.
	            'I:t=sigma*E - gamma*I - mu*I'.
	            'R:t=gamma*I - mu*R'
	            }.
	model addParameters: {
	        #beta-&gt;0.0000214.
	        #gamma-&gt;0.143.
	        #mu-&gt;0.0000351.
	        #sigma-&gt;0.125 }.
	simulator := KESimulator new: #RungeKutta from: 0.0 to: 150 step: 1.
	simulator executeOn: model.
	diag := (KEDiagramBuilder new) data: simulator allTimeSeries.
	diag xLabel: 'Time (days)'.
	diag open</code></pre><figcaption></figcaption></figure><p>
The rates mentioned of the model are introduced as parameters.
This model is run in deterministic simulation in a period of 150 days (using the classical Runge‚ÄìKutta method, also known as RK4) with an initial population of 100000 individuals.
Figure <a href="#measles">4.1</a> shows the temporal dynamics of all compartments S, E, I and R.
The Y axis counts the number of individuals in each class and the X axis is the time period of simulation (in days).</p>
<figure><img src="http://agilevisualization.com/AgileVisualization/EpidemiologicalModels/figures/measlesKendrick.png"><figcaption>4.1. Modeling the Measles model with Kendrick</figcaption></figure>
<p>The figure shows that after about 37 days, the endemic reaches the peak, then the number of infectious reduces, and finally the number of recovered individuals increases.</p>
<h3>5.  Complex models in Kendrick</h3>
<p>The modeling of infectious disease involves not only the study of their transmission cycle (as shown in the previous example) but also the effects of the population heterogeneities due to age intervals, sexes, species, viral strains or spatial regions etc.
We consider such heterogeneities as concerns of epidemiology.
The Kendrick DSL allows one to construct a model as a composition of modular models that describe specific epidemiological concerns.
Each concern is separately defined and then integrated into the model.
Look at the following examples.</p>
<h3>6.  Example of multi-host model</h3>
<p>In many situations, due to the fact that the primary hosts do not interact directly to transmit infection, the spreading of diseases requires a secondary host (vector-borne diseases).
In this example, we investigate the mosquito-borne disease with two sources.
Here, the matrix of transmission  indicates that the disease is only transmitted between mosquitos and two reservoirs, so that the main diagonal of this matrix is zero.
A reservoir is the long-term host of a pathogen of an infectious disease. Example of natural reservoirs for pathogens are: rats or bats.
This disease is mathematically formulated as shown in figure <a href="#equation2">6.1</a>.</p>
<figure><img src="http://agilevisualization.com/AgileVisualization/EpidemiologicalModels/figures/equation2.png" width="50%"><figcaption>6.1. Mathematical description of the multi-hosts model using ODEs</figcaption></figure>
<p>We specify the multi-host aspect of epidemiology as a concern (called multi-host concern) and then apply it to the model.</p>
<p>The Kendrick model of this disease is specified as follows:
</p><figure><pre><code>	multiHostConcern := KEConcern new.
	multiHostConcern
		addAttribute: #species
		value: #(#mosquito #reservoir1 #reservoir2).

	model := KEModel new.
	model population: (KEPopulation size: 13000).
	model addAttribute: #status value: #(#S #I #R).
	model addParameters: {
			#beta -&gt; 1.
			#gamma -&gt; 52.
			#mu -&gt; 12.17.
	}.
	model addParameter: #lambda value: 'beta*I'.
	model addEquations: {
		'S:t=mu*N - lambda*S - mu*S'.
		'I:t=lambda*S - gamma*I - mu*I'.
		'R:t=gamma*I - mu*R'
	}.

	model integrate: multiHostConcern.

	‚Ä¶</code></pre></figure></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://agilevisualization.com/AgileVisualization/EpidemiologicalModels/0301-EpidemiologicalModels.html">http://agilevisualization.com/AgileVisualization/EpidemiologicalModels/0301-EpidemiologicalModels.html</a></em></p>]]>
            </description>
            <link>http://agilevisualization.com/AgileVisualization/EpidemiologicalModels/0301-EpidemiologicalModels.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23889677</guid>
            <pubDate>Sun, 19 Jul 2020 14:43:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Artificial Babies on the Internet]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23889605">thread link</a>) | @ersiees
<br/>
July 19, 2020 | https://uncoolis.cool/markdown/2020/07/19/nomoredatasets.html | <a href="https://web.archive.org/web/*/https://uncoolis.cool/markdown/2020/07/19/nomoredatasets.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <ul>
</ul><p>The most powerful machine learning models train on a lot of data. Where is this data from? It usually is from the internet and is then
filtered, labeled and curated by humans.  Assuming all data that current machine learning models are trained on is in some form available on the internet, you might need to ask for it on a specific forum, though. A major way forward towards more intelligent machines is to think about ways to allow ML models to
use the internet themselves to learn. This isn‚Äôt an access to the ‚Äúreal world‚Äù, but is much less expensive than having a robot incarnation of 
an ML model roll around in our 3-dimensional world. Is this 3-dimensional world as important as we think, anyways? Even we spend a pretty fat share of our time interacting with the internet, even though our interfaces to the internet are pretty bad. Compare how much data bandwidth your body has to interact with the world with the share of it that can be used to interact with the internet.</p>

<p>A way to think about an ML model that learns from the internet directly is to look at it as a baby that is left to live on the internet. I would like to describe a three-step curriculum such a model might go through and relate it to human babies to give inspiration for how such a baby-on-the-internet model might learn. Each stage represents a new learning capability, but previously learned capabilities are not forgotten and still used when applicable.</p>

<p>At first it will just experience whatever random things it comes across: articles, terms of service, spam, pictures of random noise, ingredient lists. Just like a small baby can‚Äôt choose what it will listen its parents discuss about or what it sees when it is carried around.</p>

<p>In the second step preferences develop for what kind of data to consume. The model will look for data it can incorporate easily, but does not know yet, especially data that helps it understand the world better. It might look at Simple Wikipedia entries, simple images or listen to repetitive music. Similar to a baby that prefers to look into faces over looking into the sky.</p>

<p>The last stage of progress is for the model to interact with the internet and its human users to learn by interaction.
In this last stage I imagine the model to participate in forum discussions, or tweet. The equivalent in humans is to be able to interact with the environment at first by noises or gestures for example, later using language.</p>

<p>I see these stages not only as stages a model goes through during training, but as stages in research as well. Currently we only have stage one models, that learn from whatever they come across and we rarely train them on random samples from the internet directly, since the samples would be noisy and low quality compared to the handcrafted datasets. The next step will be to incorporate stage two learning capabilities, such that training on the internet directly becomes feasible for the first time: the model itself builds the high-quality dataset. 
Finally, at the last step we are able to build models that can interact with the internet, too.</p>

<p>The purpose of this post is to draw a parallel between ML models in the online world and Sapiens models in the physical world to inspire more people to think about ML models as babies on the web. I really believe that progress can be made if we move forward from our current dataset-centric focus in the machine learning community.</p>


  </div><!-- from https://github.com/utterance/utterances -->

</article>
      </div>
    </div></div>]]>
            </description>
            <link>https://uncoolis.cool/markdown/2020/07/19/nomoredatasets.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23889605</guid>
            <pubDate>Sun, 19 Jul 2020 14:32:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fixing Mass Effect black blobs on modern AMD CPUs]]>
            </title>
            <description>
<![CDATA[
Score 554 | Comments 170 (<a href="https://news.ycombinator.com/item?id=23889473">thread link</a>) | @Macha
<br/>
July 19, 2020 | https://cookieplmonster.github.io/2020/07/19/silentpatch-mass-effect/ | <a href="https://web.archive.org/web/*/https://cookieplmonster.github.io/2020/07/19/silentpatch-mass-effect/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  
    <p><em>TL;DR - if you are not interested in an in-depth overview of what was wrong with the game and how it was fixed,
scroll down to <a href="#download"><strong>Download</strong></a> section for a download link.</em></p>

<hr>

<ul>
  <li><a href="#introduction">Introduction</a></li>
  <li><a href="#part-1">Part 1 ‚Äì Research</a>
    <ul>
      <li><a href="#prelude">Prelude</a></li>
      <li><a href="#pix">PIX</a></li>
    </ul>
  </li>
  <li><a href="#part-2">Part 2 ‚Äì A closer look into D3DX</a></li>
  <li><a href="#part-3">Part 3 ‚Äì Standalone tests</a></li>
  <li><a href="#part-4">Part 4 ‚Äì Putting it all together</a>
    <ul>
      <li><a href="#download">Download</a></li>
    </ul>
  </li>
</ul>

<hr>



<p><strong>Mass Effect</strong> is a popular franchise of sci-fi roleplaying games. The first game was initially released by BioWare in late 2007 on Xbox 360 exclusively as a part of a publishing deal with Microsoft.
A few months later in mid-2008, the game received PC port developed by Demiurge Studios. It was a decent port with no obvious flaws, that is until 2011 when AMD released their new Bulldozer-based CPUs.
When playing the game on PCs with modern AMD processors, two areas in the game (Noveria and Ilos) show severe graphical artifacts:</p>

<p>
<img src="https://cookieplmonster.github.io/assets/img/posts/mass-effect/me1-blobs.jpg"><br>
<em>Well, that doesn't look nice.</em>
</p>

<p>While not unplayable, it‚Äôs definitely distracting. Thankfully, workarounds exist ‚Äì such as
<a href="http://abesmissioncontrol.blogspot.com/2015/04/mass-effect-fixing-blocky-player-models.html">disabling lighting via console commands</a>
or <a href="https://www.nexusmods.com/masseffect/mods/181">modifying the game‚Äôs maps to remove broken lights</a>, but seemingly the issue has never been fully understood.
Some sources claim that an FPS Counter mod can also fix that issue, but I couldn‚Äôt find much information about it and the mod‚Äôs sources don‚Äôt seem to be available online,
and there is no documentation on how the mod tackles this error.</p>

<p>What makes this issue particularly interesting? Vendor-specific bugs are nothing new, and games have had them for decades. However, to my best knowledge, this is the only case where a graphical
issue is caused by a <strong>processor</strong> and not by a graphics card. In the majority of cases, issues happen with a specific vendor of GPU and they don‚Äôt care about the CPU, while in this case, it‚Äôs the exact opposite.
This makes the issue very unique and worth looking into.</p>

<p>Looking up existing discussions online, this issue seems to affect AMD FX and Ryzen chips. Compared to the older AMD chips, these lack a <a href="https://en.wikipedia.org/wiki/3DNow!">3DNow! instruction set</a>.
Unrelated or not, the community consensus was that this was the cause of the bug and that the game tried to use those instructions upon detecting an AMD CPU.
Given that there are no known cases of this bug occurring on Intel CPU‚Äôs and that 3DNow! instructions were exclusive to AMD, it‚Äôs no surprise the community assumed that this is the issue.</p>

<p>Is this really the issue, or is it caused by something entirely different? Let‚Äôs find out!</p>



<h2 id="prelude">Prelude</h2>
<p>Even though the issue is trivial to reproduce, I couldn‚Äôt look into it for the longest time for a simple reason ‚Äì I don‚Äôt have access to any PCs with AMD hardware!
Thankfully, this time I‚Äôm not approaching research alone ‚Äì <a href="https://withinrafael.com/">Rafael Rivera</a> got my back during the entire process of R&amp;D,
providing a test environment with an AMD chip, insights, ideas as well as putting up with hundreds of blind guesses I usually throw around when trying to find the way to the root of such unknown problems.</p>

<p>Since we now had a good testing environment, the first theory to test was of course <code>cpuid</code> ‚Äì if people are right in assuming that 3DNow! instructions are to blame, there should a place in the game‚Äôs code
where they check for their presence, or at the very least check for the CPU vendor. That reasoning is flawed, though; if it was true that the game attempts to use 3DNow! instructions any time it runs on an AMD chip,
without checking if they are supported, the game would most likely crash when trying to execute an illegal instruction. Moreover, a quick scan around the game‚Äôs code reveals that the game <strong>doesn‚Äôt</strong>
check for CPU capabilities. Therefore, whatever is up with this issue, it doesn‚Äôt appear to be caused by the game mis-detecting CPU features, because it seemingly doesn‚Äôt care about them in the first place.</p>

<p>When this started looking like an undebuggable case, Rafael came back to me with a realization ‚Äì disabling <strong>PSGP</strong> (Processor Specific Graphics Pipeline) fixes the issue and the characters are properly lit!
PSGP is not the best documented term, but in short, it‚Äôs a legacy (concerning only older DirectX versions) feature allowing Direct3D to perform processor-specific optimizations:</p>

<blockquote>
  <p>In previous versions of DirectX, there was a path that allowed to do vertex processing called the PSGP. Applications had to take this path into account and support a path for vertex processing
on the processor and graphics cores.</p>
</blockquote>

<p>Putting it this way, it makes sense why disabling PSGP fixes artifacts on AMD ‚Äì the path taken by modern AMD processors may be somehow broken.
How to disable it? Two ways come to mind:</p>
<ul>
  <li>It is possible to pass a <code>D3DCREATE_DISABLE_PSGP_THREADING</code> flag to <code>IDirect3D9::CreateDevice</code>. It‚Äôs defined as: <br>
    <blockquote>
      <p>Restrict computation to the main application thread. If the flag is not set, the runtime may perform software vertex processing and other computations in worker thread
to improve performance on multi-processor systems.</p>
    </blockquote>

    <p>Sadly, setting that flag doesn‚Äôt fix the issue. Looks like, despite the flag having ‚ÄúPSGP‚Äù in name, it‚Äôs not what we are looking for.</p>
  </li>
  <li>DirectX specifies two registry entries to disable PSGP in D3D and to disable PSGP only for D3DX ‚Äì <code>DisablePSGP</code> and <code>DisableD3DXPSGP</code>. Those flags can be set system-wide or process-wide.
For information on how to set them only for a specific process, see <a href="https://withinrafael.com/2020/07/11/specify-application-specific-direct3d-flags/">Rafael Rivera‚Äôs guide on enabling application-specific Direct3D flags</a>.</li>
</ul>

<p><code>DisableD3DXPSGP</code> appears to be a viable fix for that issue. Therefore, if you have an aversion towards downloading third party fixes/modifications or you must fix this issue without making
any changes to the game, it‚Äôs a perfectly fine way of doing it. As long as you set that flag only for Mass Effect and not system-wide, it‚Äôs fine!</p>

<h2 id="pix">PIX</h2>
<p>As always with graphical issues, PIX is likely the most useful tool one could use to diagnose them. We captured similar scenes from Intel and AMD hardware and compared the results.
One difference was instantly noticeable ‚Äì unlike with my past projects, where <a href="https://cookieplmonster.github.io/2018/07/07/farcry-d3d9-bug/">captures did not carry the bug with them</a> and the same capture
would look different on different PCs (indicating a driver or d3d9.dll bug), these captures carry the bug with them! In other words, a capture from an AMD hardware opened on a PC with Intel hardware
<strong>does</strong> show the bug.</p>

<p>An AMD capture on Intel looks no different than on the hardware it was taken from:</p>

<p>
<img src="https://cookieplmonster.github.io/assets/img/posts/mass-effect/me1-pix1.jpg">
</p>

<p>What does this tell us?</p>
<ul>
  <li>Since PIX does not ‚Äútake screenshots‚Äù but instead captures the sequence of D3D commands and executes them on hardware, we can observe that executing the commands captured from an AMD box
results in the same bug when executed on Intel.</li>
  <li>This strongly implies that the difference is not caused by the difference in <strong>how</strong> the commands are executed (that‚Äôs how you get GPU specific bugs), but <strong>what</strong> commands are executed.</li>
</ul>

<p>In other words, it‚Äôs almost certainly not any sort of a driver bug. Instead, the way inputs for the GPU are prepared seems to be somehow broken<sup id="fnref:1"><a href="#fn:1">1</a></sup>. That is indeed a very rare occurrence!</p>

<p>At this point, finding the bug is a matter of finding any jarring differences between captures. It‚Äôs tedious, but that‚Äôs the only viable way.</p>

<p>After a long while spent poking the capture, a full body draw call caught my attention:</p>

<p>
<img src="https://cookieplmonster.github.io/assets/img/posts/mass-effect/me1-pix2.jpg">
</p>

<p>On an Intel capture, this draw outputs most of the character‚Äôs body, together with lighting and textures. On an AMD capture, it outputs a plain black model. This looks like a good trail.</p>

<p>The first obvious candidate for checking would be bound textures, but they seem to be fine and are consistent across captures.
However, some of the pixel shader constants looked weird. Not only do they have NaNs (Not a Number), but they also seem to only appear on the AMD capture and not the Intel capture:</p>

<p>
<img src="https://cookieplmonster.github.io/assets/img/posts/mass-effect/me1-pix3.jpg"><br>
<em>1.#QO indicates a NaN</em>
</p>

<p>This looks promising ‚Äì NaN values causing strange visuals are not unheard of. Funnily enough, a PlayStation 3 version of Mass Effect 2
<a href="https://github.com/RPCS3/rpcs3/issues/7397">had a very similar looking issue in RPCS3</a> which was also related to NaNs!</p>

<p>However, before we get too excited, those values could just be leftovers from previous draws and they might end up being unused for the current draw.
Luckily, in this case it‚Äôs clearly visible that those NaNs get submitted to D3D for this specific draw‚Ä¶</p>

<div><div><pre><code>49652	IDirect3DDevice9::SetVertexShaderConstantF(230, 0x3017FC90, 4)
49653	IDirect3DDevice9::SetVertexShaderConstantF(234, 0x3017FCD0, 3)
49654	IDirect3DDevice9::SetPixelShaderConstantF(10, 0x3017F9D4, 1) // Submits constant c10
49655	IDirect3DDevice9::SetPixelShaderConstantF(11, 0x3017F9C4, 1) // Submits constant c11
49656	IDirect3DDevice9::SetRenderState(D3DRS_FILLMODE, D3DFILL_SOLID)
49657	IDirect3DDevice9::SetRenderState(D3DRS_CULLMODE, D3DCULL_CW)
49658	IDirect3DDevice9::SetRenderState(D3DRS_DEPTHBIAS, 0.000f)
49659	IDirect3DDevice9::SetRenderState(D3DRS_SLOPESCALEDEPTHBIAS, 0.000f)
49660	IDirect3DDevice9::TestCooperativeLevel()
49661	IDirect3DDevice9::SetIndices(0x296A5770)
49662	IDirect3DDevice9::DrawIndexedPrimitive(D3DPT_TRIANGLELIST, 0, 0, 2225, 0, 3484) // Draws the character model
</code></pre></div></div>

<p>‚Ä¶and the pixel shader used for this draw references both constants:</p>
<div><div><pre><code>// Registers:
//
//   Name                     Reg   Size
//   ------------------------ ----- ----
//   UpperSkyColor            c10      1
//   LowerSkyColor            c11      1
</code></pre></div></div>

<p>Both constants appear to <a href="https://github.com/abaelhe/unrealengine-old/search?q=UpperSkyColor">come straight from Unreal Engine</a> and judging by the name,
they might directly influence the lighting. Bingo!</p>

<p>A quick in-game test further confirms the theory ‚Äì on an Intel machine, a vector of 4 NaN values was never submitted as pixel shader constants;
meanwhile, on an AMD machine, NaNs would start showing up as soon as the player entered the area where lighting breaks!</p>

<p>Does it mean work is done? No, far from it, as finding broken constants is only half of the success. The question remains, where do they come from, and can they be replaced?
An in-game test replacing NaN values with zeros partially fixed the issue ‚Äì ugly black blobs disappeared, but characters were still way too dark:</p>

<p>
<img src="https://cookieplmonster.github.io/assets/img/posts/mass-effect/me1-dark-lighting.jpg"><br>
<em>Almost correct... ‚Ä¶</em></p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cookieplmonster.github.io/2020/07/19/silentpatch-mass-effect/">https://cookieplmonster.github.io/2020/07/19/silentpatch-mass-effect/</a></em></p>]]>
            </description>
            <link>https://cookieplmonster.github.io/2020/07/19/silentpatch-mass-effect/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23889473</guid>
            <pubDate>Sun, 19 Jul 2020 14:08:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clear explanation of Rust‚Äôs module system]]>
            </title>
            <description>
<![CDATA[
Score 154 | Comments 47 (<a href="https://news.ycombinator.com/item?id=23889427">thread link</a>) | @rkwz
<br/>
July 19, 2020 | http://www.sheshbabu.com/posts/rust-module-system/ | <a href="https://web.archive.org/web/*/http://www.sheshbabu.com/posts/rust-module-system/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Rust‚Äôs module system is surprisingly confusing and causes a lot of frustration for beginners.</p>
<p>In this post, I‚Äôll explain the module system using practical examples so you get a clear understanding of how it works and can immediately start applying this in your projects.</p>
<p>Since Rust‚Äôs module system is quite unique, I request the reader to read this post with an open mind and resist comparing it with how modules work in other languages.</p>
<p>Let‚Äôs use this file structure to simulate a real world project:</p>
<pre><code>my_project
‚îú‚îÄ‚îÄ Cargo.toml
‚îî‚îÄ‚î¨ src
  ‚îú‚îÄ‚îÄ main.rs
  ‚îú‚îÄ‚îÄ config.rs
  ‚îú‚îÄ‚î¨ routes
  ‚îÇ ‚îú‚îÄ‚îÄ health_route.rs
  ‚îÇ ‚îî‚îÄ‚îÄ user_route.rs
  ‚îî‚îÄ‚î¨ models
    ‚îî‚îÄ‚îÄ user_model.rs</code></pre>
<p>These are the different ways we should be able to consume our modules:</p>
<p><img src="http://www.sheshbabu.com/images/2020-rust-module-system/rust-module-system-1.png" alt=""></p>
<p>These 3 examples should be sufficient to explain how Rust‚Äôs module system works.</p>
<h2 id="Example-1"><a href="#Example-1" title="Example 1"></a>Example 1</h2><p>Let‚Äôs start with the first example - importing <code>config.rs</code> in <code>main.rs</code>.</p>
<pre><code>
<span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>println!</span><span>(</span><span>"main"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<pre><code>
<span>fn</span> <span>print_config</span><span>(</span><span>)</span> <span>{</span>
  <span>println!</span><span>(</span><span>"config"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<p>The first mistake that everyone makes is just because we have files like <code>config.rs</code>, <code>health_route.rs</code> etc, we think that these files are <code>modules</code> and we can import them from other files.</p>
<p>Here‚Äôs what we see (file system tree) and what the compiler sees (module tree):</p>
<p><img src="http://www.sheshbabu.com/images/2020-rust-module-system/rust-module-system-2.png" alt=""></p>
<p>Surprisingly, the compiler only sees the <code>crate</code> module which is our <code>main.rs</code> file. This is because we need to explicitly build the module tree in Rust - there‚Äôs no implicit mapping between file system tree to module tree.</p>
<blockquote>
<p>We need to explicitly build the module tree in Rust, there‚Äôs no implicit mapping to file system</p>
</blockquote>
<p>To add a file to the module tree, we need to declare that file as a submodule using the <code>mod</code> keyword. The next thing that confuses people is that you would assume we declare a file as module in the same file. But we need to declare this in a different file! Since we only have <code>main.rs</code> in the module tree, let‚Äôs declare <code>config.rs</code> as a submodule in <code>main.rs</code>.</p>
<blockquote>
<p>The mod keyword declares a submodule</p>
</blockquote>
<p>The <code>mod</code> keyword has this syntax:</p>
<pre><code><span>mod</span> my_module<span>;</span></code></pre>
<p>Here, the compiler looks for <code>my_module.rs</code> or <code>my_module/mod.rs</code> in the same directory.</p>
<pre><code>my_project
‚îú‚îÄ‚îÄ Cargo.toml
‚îî‚îÄ‚î¨ src
  ‚îú‚îÄ‚îÄ main.rs
  ‚îî‚îÄ‚îÄ my_module.rs

or

my_project
‚îú‚îÄ‚îÄ Cargo.toml
‚îî‚îÄ‚î¨ src
  ‚îú‚îÄ‚îÄ main.rs
  ‚îî‚îÄ‚î¨ my_module
    ‚îî‚îÄ‚îÄ mod.rs</code></pre>
<p>Since <code>main.rs</code> and <code>config.rs</code> are in the same directory, let‚Äôs declare the config module as follows:</p>
<pre><code>// main.rs
<span>+ mod config;</span>

fn main() {
<span>+ config::print_config();</span>
  println!("main");
}</code></pre>
<pre><code>
<span>fn</span> <span>print_config</span><span>(</span><span>)</span> <span>{</span>
  <span>println!</span><span>(</span><span>"config"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<p>We‚Äôre accessing the <code>print_config</code> function using the <code>::</code> syntax.</p>
<p>Here‚Äôs how the module tree looks like:</p>
<p><img src="http://www.sheshbabu.com/images/2020-rust-module-system/rust-module-system-3.png" alt=""></p>
<p>We‚Äôve successfully declared the <code>config</code> module! But this is not sufficient to be able to call the <code>print_config</code> function inside <code>config.rs</code>. Almost everything in Rust is private by default, we need to make the function public using the <code>pub</code> keyword:</p>
<blockquote>
<p>The pub keyword makes things public</p>
</blockquote>
<pre><code>
<span>mod</span> config<span>;</span>

<span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  config<span>:</span><span>:</span><span>print_config</span><span>(</span><span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"main"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<pre><code>// config.rs
<span>- fn print_config() {</span>
<span>+ pub fn print_config() {</span>
  println!("config");
}</code></pre>
<p>Now, this works. We‚Äôve successfully called a function defined in a different file!</p>
<h2 id="Example-2"><a href="#Example-2" title="Example 2"></a>Example 2</h2><p>Let‚Äôs try calling the <code>print_health_route</code> function defined in <code>routes/health_route.rs</code> from <code>main.rs</code>.</p>
<pre><code>
<span>mod</span> config<span>;</span>

<span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  config<span>:</span><span>:</span><span>print_config</span><span>(</span><span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"main"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<pre><code>
<span>fn</span> <span>print_health_route</span><span>(</span><span>)</span> <span>{</span>
  <span>println!</span><span>(</span><span>"health_route"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<p>As we discussed earlier, we can use the <code>mod</code> keyword only for <code>my_module.rs</code> or <code>my_module/mod.rs</code> in the same directory.</p>
<p>So in order to call functions inside <code>routes/health_route.rs</code> from <code>main.rs</code>, we need to do the following things:</p>
<ul>
<li>Create a file named <code>routes/mod.rs</code> and declare the <code>routes</code> submodule in <code>main.rs</code></li>
<li>Declare the <code>health_route</code> submodule in <code>routes/mod.rs</code> and make it public</li>
<li>Make the functions inside <code>health_route.rs</code> public</li>
</ul>
<pre><code>my_project
‚îú‚îÄ‚îÄ Cargo.toml
‚îî‚îÄ‚î¨ src
  ‚îú‚îÄ‚îÄ main.rs
  ‚îú‚îÄ‚îÄ config.rs
  ‚îú‚îÄ‚î¨ routes
<span>+ ‚îÇ ‚îú‚îÄ‚îÄ mod.rs</span>
  ‚îÇ ‚îú‚îÄ‚îÄ health_route.rs
  ‚îÇ ‚îî‚îÄ‚îÄ user_route.rs
  ‚îî‚îÄ‚î¨ models
    ‚îî‚îÄ‚îÄ user_model.rs</code></pre>
<pre><code>// main.rs
mod config;
<span>+ mod routes;</span>

fn main() {
<span>+ routes::health_route::print_health_route();</span>
  config::print_config();
  println!("main");
}</code></pre>
<pre><code>// routes/mod.rs
<span>+ pub mod health_route;</span></code></pre>
<pre><code>// routes/health_route.rs
<span>- fn print_health_route() {</span>
<span>+ pub fn print_health_route() {</span>
  println!("health_route");
}</code></pre>
<p>Here‚Äôs how the module tree looks like:</p>
<p><img src="http://www.sheshbabu.com/images/2020-rust-module-system/rust-module-system-4.png" alt=""></p>
<p>We can now call a function defined in a file inside a folder.</p>
<h2 id="Example-3"><a href="#Example-3" title="Example 3"></a>Example 3</h2><p>Let‚Äôs try calling from <code>main.rs =&gt; routes/user_route.rs =&gt; models/user_model.rs</code></p>
<pre><code>
<span>mod</span> config<span>;</span>
<span>mod</span> routes<span>;</span>

<span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  routes<span>:</span><span>:</span>health_route<span>:</span><span>:</span><span>print_health_route</span><span>(</span><span>)</span><span>;</span>
  config<span>:</span><span>:</span><span>print_config</span><span>(</span><span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"main"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<pre><code>
<span>fn</span> <span>print_user_route</span><span>(</span><span>)</span> <span>{</span>
  <span>println!</span><span>(</span><span>"user_route"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<pre><code>
<span>fn</span> <span>print_user_model</span><span>(</span><span>)</span> <span>{</span>
  <span>println!</span><span>(</span><span>"user_model"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<p>We want to call the function <code>print_user_model</code> from <code>print_user_route</code> from <code>main</code>.</p>
<p>Let‚Äôs make the same changes as before - declaring submodules, making functions public and adding the <code>mod.rs</code> file.</p>
<pre><code>my_project
‚îú‚îÄ‚îÄ Cargo.toml
‚îî‚îÄ‚î¨ src
  ‚îú‚îÄ‚îÄ main.rs
  ‚îú‚îÄ‚îÄ config.rs
  ‚îú‚îÄ‚î¨ routes
  ‚îÇ ‚îú‚îÄ‚îÄ mod.rs
  ‚îÇ ‚îú‚îÄ‚îÄ health_route.rs
  ‚îÇ ‚îî‚îÄ‚îÄ user_route.rs
  ‚îî‚îÄ‚î¨ models
<span>+   ‚îú‚îÄ‚îÄ mod.rs</span>
    ‚îî‚îÄ‚îÄ user_model.rs</code></pre>
<pre><code>// main.rs
mod config;
mod routes;
<span>+ mod models;</span>

fn main() {
  routes::health_route::print_health_route();
<span>+ routes::user_route::print_user_route();</span>
  config::print_config();
  println!("main");
}</code></pre>
<pre><code>// routes/mod.rs
pub mod health_route;
<span>+ pub mod user_route;</span></code></pre>
<pre><code>// routes/user_route.rs
<span>- fn print_user_route() {</span>
<span>+ pub fn print_user_route() {</span>
  println!("user_route");
}</code></pre>
<pre><code>// models/mod.rs
<span>+ pub mod user_model;</span></code></pre>
<pre><code>// models/user_model.rs
<span>- fn print_user_model() {</span>
<span>+ pub fn print_user_model() {</span>
  println!("user_model");
}</code></pre>
<p>Here‚Äôs how the module tree looks like:</p>
<p><img src="http://www.sheshbabu.com/images/2020-rust-module-system/rust-module-system-5.png" alt=""></p>
<p>Wait, we haven‚Äôt actually called <code>print_user_model</code> from <code>print_user_route</code>! So far, we‚Äôve only called the functions defined in other modules from <code>main.rs</code>, how do we do that from other files?</p>
<p>If we look at our module tree, the <code>print_user_model</code> function sits in the <code>crate::models::user_model</code> path. So in order to use a module in files that are not <code>main.rs</code>, we should think in terms of the path necessary to reach that module in the module tree.</p>
<pre><code>// routes/user_route.rs
pub fn print_user_route() {
<span>+ crate::models::user_model::print_user_model();</span>
  println!("user_route");
}</code></pre>
<p>We‚Äôve successfully called a function defined in a file from a file that‚Äôs not <code>main.rs</code>.</p>
<h2 id="super"><a href="#super" title="super"></a>super</h2><p>The fully qualified name gets too lengthy if our file organization is multiple directories deep. Let‚Äôs say for whatever reason, we want to call <code>print_health_route</code> from <code>print_user_route</code>. These are under the paths <code>crate::routes::health_route</code> and <code>crate::routes::user_route</code> respectively.</p>
<p>We can call it by using the fully qualified name <code>crate::routes::health_route::print_health_route()</code> but we can also use a relative path <code>super::health_route::print_health_route();</code>. Notice that we‚Äôve used <code>super</code> to refer to the parent scope.</p>
<blockquote>
<p>The super keyword in module path refers to the parent scope</p>
</blockquote>
<pre><code><span>pub</span> <span>fn</span> <span>print_user_route</span><span>(</span><span>)</span> <span>{</span>
  <span>crate</span><span>:</span><span>:</span>routes<span>:</span><span>:</span>health_route<span>:</span><span>:</span><span>print_health_route</span><span>(</span><span>)</span><span>;</span>
  
  <span>super</span><span>:</span><span>:</span>health_route<span>:</span><span>:</span><span>print_health_route</span><span>(</span><span>)</span><span>;</span>

  <span>println!</span><span>(</span><span>"user_route"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<h2 id="use"><a href="#use" title="use"></a>use</h2><p>It would be tedious to use the fully qualified name or even the relative name in the above examples. In order to shorten the names, we can use the <code>use</code> keyword to bind the path to a new name or alias.</p>
<blockquote>
<p>The use keyword is used to shorten the module path</p>
</blockquote>
<pre><code><span>pub</span> <span>fn</span> <span>print_user_route</span><span>(</span><span>)</span> <span>{</span>
  <span>crate</span><span>:</span><span>:</span>models<span>:</span><span>:</span>user_model<span>:</span><span>:</span><span>print_user_model</span><span>(</span><span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"user_route"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<p>The above code can be refactored as:</p>
<pre><code><span>use</span> <span>crate</span><span>:</span><span>:</span>models<span>:</span><span>:</span>user_model<span>:</span><span>:</span>print_user_model<span>;</span>

<span>pub</span> <span>fn</span> <span>print_user_route</span><span>(</span><span>)</span> <span>{</span>
  <span>print_user_model</span><span>(</span><span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"user_route"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<p>Instead of using the name <code>print_user_model</code>, we can also alias it to something else:</p>
<pre><code><span>use</span> <span>crate</span><span>:</span><span>:</span>models<span>:</span><span>:</span>user_model<span>:</span><span>:</span>print_user_model <span>as</span> log_user_model<span>;</span>

<span>pub</span> <span>fn</span> <span>print_user_route</span><span>(</span><span>)</span> <span>{</span>
  <span>log_user_model</span><span>(</span><span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"user_route"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<h2 id="External-modules"><a href="#External-modules" title="External modules"></a>External modules</h2><p>Dependencies added to <code>Cargo.toml</code> are available globally to all modules inside the project. We don‚Äôt need to explicitly import or declare anything to use a dependency.</p>
<blockquote>
<p>External dependencies are globally available to all modules inside a project</p>
</blockquote>
<p>For example, let‚Äôs say we added the <a href="https://crates.io/crates/rand" target="_blank" rel="noopener">rand</a> crate to our project. We can use it in our code directly as:</p>
<pre><code><span>pub</span> <span>fn</span> <span>print_health_route</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> random_number<span>:</span> u8 <span>=</span> rand<span>:</span><span>:</span><span>random</span><span>(</span><span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"{}"</span><span>,</span> random_number<span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"health_route"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<p>We can also use <code>use</code> to shorten the path:</p>
<pre><code><span>use</span> rand<span>:</span><span>:</span>random<span>;</span>

<span>pub</span> <span>fn</span> <span>print_health_route</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> random_number<span>:</span> u8 <span>=</span> <span>random</span><span>(</span><span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"{}"</span><span>,</span> random_number<span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"health_route"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<h2 id="Summary"><a href="#Summary" title="Summary"></a>Summary</h2><ul>
<li>The module system is explicit - there‚Äôs no 1:1 mapping with file system</li>
<li>We declare a file as module in its parent, not in itself</li>
<li>The <code>mod</code> keyword is used to declare submodules</li>
<li>We need to explicitly declare functions, structs etc as public so they can be consumed in other modules</li>
<li>The <code>pub</code> keyword makes things public</li>
<li>The <code>use</code> keyword is used to shorten the module path</li>
<li>We don‚Äôt need to explicitly declare 3rd party modules</li>
</ul>
<p>Thanks for reading! Feel free to follow me in <a href="https://twitter.com/sheshbabu" target="_blank" rel="noopener">Twitter</a> for more posts like this :)</p>
</div></div>]]>
            </description>
            <link>http://www.sheshbabu.com/posts/rust-module-system/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23889427</guid>
            <pubDate>Sun, 19 Jul 2020 14:01:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: [Demo] GigoBooks: open-source accounting SW for micro-business (NoSaaS)]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23889104">thread link</a>) | @bengtan
<br/>
July 19, 2020 | https://gigobooks.github.io/demo/ | <a href="https://web.archive.org/web/*/https://gigobooks.github.io/demo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://gigobooks.github.io/demo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23889104</guid>
            <pubDate>Sun, 19 Jul 2020 13:13:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rickdiculously Easy CTF]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23888987">thread link</a>) | @thereyougo
<br/>
July 19, 2020 | https://www.chno.xyz/blog/ctf-3 | <a href="https://web.archive.org/web/*/https://www.chno.xyz/blog/ctf-3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.chno.xyz/blog/ctf-3</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888987</guid>
            <pubDate>Sun, 19 Jul 2020 12:51:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One year of Flutter as a web developer]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23888947">thread link</a>) | @realusername
<br/>
July 19, 2020 | https://alex-min.fr/one-year-of-flutter/ | <a href="https://web.archive.org/web/*/https://alex-min.fr/one-year-of-flutter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>I spent a considerable time on my <a rel="nofollow noopener noreferrer" target="_blank" href="https://mavio.fr/">budget app</a> side project built in Flutter. After a year of development and 25k lines of code later, I wanted to create a blog post about how everything went and my feedback on working with this framework.</p>

<h2 id="the-dart-language">The Dart language</h2>

<p>Flutter is built with Dart, a Javascript/Java inspired language. Dart was built internally at Google with the specific goal to replace Javascript on the web as a saner language, with better defaults. Unfortunately for the Dart team, the project never took off, Dart was stuck in a limbo state for a few years while still being maintained for internal Google needs.</p>

<p>The language itself had very good features which enabled other uses cases:</p>
<ul>
  <li>The Dart VM is a wonderful piece of technology, build with hot reloading at its core</li>
  <li>The language can be interpreted or compiled natively for better performance</li>
  <li>The Dart tooling around the language well built</li>
</ul>

<p>I fully expected the language to be an issue on the project since it‚Äôs so niche, but actually it has been a great experience on that level. It‚Äôs quick to learn and very easy to pick up, especially if you have done some Javascript previously.</p>

<h2 id="the-good-parts">The good parts</h2>

<h3 id="tooling">Tooling</h3>

<p>The Flutter tooling is one of it‚Äôs strong parts. Hot reloading your code <strong>actually</strong> works, Flutter is almost the only piece of technology I‚Äôve ever used where the hot reload was working as well as it is. Generally I would disable it elsewhere, it even makes you miss it in other languages.</p>

<p>The package manager (pub) works great, upgrades are smooth (if you are coming from the npm world, it‚Äôs honestly a breath of fresh air). After a year of managing my project, I only had a single conflict where I had to pin a specific version of a package to avoid a compilation error with the main Flutter SDK, that only lasted two weeks and then upgrades were smooth again.</p>

<p>The Flutter SDK has multiple channels (master, dev, beta and stable), the stable version is quite good as not reintroducing regressions and flutter upgrades can be done from the command line easily.</p>

<p>The language server in VSCode works perfectly, autocompletion also works wonders, the Dart code formatter is also one of the best I used, I consider it on par with Go, which is one of the best in my opinion.</p>

<h3 id="performance--animations">Performance &amp; Animations</h3>

<p>Flutter uses Skia, an internal and very performant render engine which draws everything to a canvas. Performance is definitely a strong point of the platform. I use a very cheap Samsung J3 as my daily driver which is almost the bottom of the barrel in terms of performance in 2020. Basically every app on my phone is lagging noticeably, including Google apps. My budget app on the other hand is the quickest app on my phone, by a long margin. If you are targetting a market with a lot of low-end budget phones, Flutter is exactly what you need.</p>

<p>Animations are also a very strong point of this platform, high-speed animations can be built with <a rel="nofollow noopener noreferrer" target="_blank" href="https://rive.app/">Rive</a> and imported directly into Flutter, rendered at full speed and weighting a few Kb. I do have a few toy animations built with Rive on my app.</p>

<h3 id="portability">Portability</h3>

<p>I have not published the iOS version yet due to Apple developer account issues but my budget app already works without much effort identically on Android, Linux, Windows &amp; macOS thanks to <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/go-flutter-desktop/hover">Hover</a>.</p>

<p>If you are building a desktop app, Flutter can be a good technology to keep in mind. It produces small binaries, fast and reactive applications, works cross-platform and won‚Äôt use too much RAM like most Electron apps.</p>

<p>Desktop support is still in an alpha quality at the moment so expect some missing features, you might have to dig into the code and make some pull requests.</p>

<h3 id="the-flutter-sdk">The Flutter SDK</h3>

<p>The SDK is quite complete, a lot of basic and complex components are there. The SDK has material design guidelines by default, which might be a good thing or a bad thing depending on what you are trying to achieve.</p>

<p>While you can make your application look native with more work but generally it‚Äôs not what you would use Flutter for. Flutter shines primarily as building complex apps which have their own design goals.</p>

<h3 id="styling">Styling</h3>

<p>Styling will look familiar if you are coming from a web background. You will have a stripped-down version of flex, padding &amp; margins, border-radius, font-weight‚Ä¶</p>

<p>The main difference being that there‚Äôs a global Flutter theme which applies to your whole app instead of classes. This makes it easier to swap the theme to make a dark theme.</p>

<p>I‚Äôm still trying to make my stying code looks nicer, extending the main theme seems to be the right approach.</p>

<h2 id="the-parts-which-would-need-improvements">The parts which would need improvements</h2>

<h3 id="testing">Testing</h3>

<p>Testing isn‚Äôt that bad, especially if you are coming from the Javascript world. A lot of the testing building blocks you expect are there and you do have a driver where you can tap on elements and see what happens.</p>

<figure>

  <p><img src="https://d33wubrfki0l68.cloudfront.net/172a2207d60b86a77bfc854290aa6349be0d69a7/3e636/images/flutter-test-terminal.png" alt="A screenshot of a terminal showing that 174 tests passed in 4 minutes 43 seconds"></p>
  <figcaption>Yay! Hopefully everything works.</figcaption>
</figure>

<p>If you come from the Ruby world however, the testing will feel pretty average and you might find yourself needing a bit more boilerplate than you would expect. There‚Äôs definitely some room to make testing more enjoyable and faster to write.</p>

<p>There is also no mutation testing in Dart yet (that I‚Äôm aware of), so you will have to use the code coverage tool extensively in the mean time and try to catch as much as you can. I had a pretty blocking bug on the code coverage tool which has been fixed in one of the more recent stable versions so I can recommend it now.</p>

<h3 id="navigation">Navigation</h3>

<p>Navigation works stateless in Flutter. That can be a great thing, especially when you are importing packages, no need to plug your router for using packages, there‚Äôs one big issue however, it‚Äôs not really possible to micro-manage the view state when you use the go back button on Android.</p>

<p>That can be a problem for knowing which route you are on at the moment if you want to update the bottom bar with an indicator for example. As far as I know, it‚Äôs still an unsolved problem, unless you rebuild an entire navigation system yourself with Provider or another Flutter state management library. I‚Äôll probably do that in the future but that‚Äôs a lower priority bug at the moment.</p>

<h3 id="webviews">Webviews</h3>

<p>If you need Webviews for your project (which I needed), it might be a blocker in the current state. Webviews don‚Äôt support multiple tabs (which means <em>window.open</em> won‚Äôt work in Javascript), the view might crash and there is poor keyboard support at the moment.</p>

<p>Additionally, this alpha-state Webview is only available on Android and iOS, not on any desktop platform yet.</p>

<h2 id="conclusion">Conclusion</h2>

<p>As far as the Flutter platform goes, it‚Äôs been a pretty enjoyable experience for me. I will write one or more retrospective blog post on this project. I do recommend Flutter and even as a web developer, where you might prefer React Native initially due to the familiarity with Javascript, I would recommend trying Flutter, it will surprise you.</p>


  </section></div>]]>
            </description>
            <link>https://alex-min.fr/one-year-of-flutter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888947</guid>
            <pubDate>Sun, 19 Jul 2020 12:41:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PostgreSQL quickstart guide ‚Äì connecting, remote access, psql CLI and more]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23888907">thread link</a>) | @lukasbar
<br/>
July 19, 2020 | https://knowledgepill.it/posts/postgresql-basics-guide/ | <a href="https://web.archive.org/web/*/https://knowledgepill.it/posts/postgresql-basics-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <h2 id="configure-remote-access---listen-address">Configure remote access - listen address</h2>
<p>By default after instalation and creting database cluster PostgreSQL will listner only on localhost. No remote access will be allowed.</p>
<hr>
<p><a href="https://knowledgepill.it/posts/postgresql_installation/">PostgreSQL installation on Linux - with database creation</a></p>
<hr>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ netstat -lptnu | grep post
<span>(</span>Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.<span>)</span>
tcp        <span>0</span>      <span>0</span> 127.0.0.1:5432          0.0.0.0:*               LISTEN      1977/postmaster     
tcp6       <span>0</span>      <span>0</span> ::1:5432                :::*                    LISTEN      1977/postmaster     
</code></pre></div><p>To change listen address we have to configure parameter in <code>postgresql.conf</code></p>
<p>Check <code>PGDATA</code> - after <code>-D</code> parameter:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ ps aux | grep postgres
postgres  <span>1977</span>  0.0  2.5 <span>286388</span> <span>14864</span> ?        Ss   Jun28   0:02 /usr/pgsql-12/bin/postmaster -D /postgresql/data
postgres  <span>1979</span>  0.0  0.2 <span>140768</span>  <span>1360</span> ?        Ss   Jun28   0:00 postgres: logger   
postgres  <span>1981</span>  0.0  0.5 <span>286504</span>  <span>3028</span> ?        Ss   Jun28   0:00 postgres: checkpointer   
postgres  <span>1982</span>  0.0  0.2 <span>286388</span>  <span>1696</span> ?        Ss   Jun28   0:03 postgres: background writer   
postgres  <span>1983</span>  0.0  0.9 <span>286388</span>  <span>5676</span> ?        Ss   Jun28   0:03 postgres: walwriter   
postgres  <span>1984</span>  0.0  0.4 <span>286924</span>  <span>2688</span> ?        Ss   Jun28   0:02 postgres: autovacuum launcher  
</code></pre></div><p>Locate the file:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ cd /postgresql/data/
<span>[</span>postgres@postgres-lab data<span>]</span>$ ls -lah postgresql.conf
-rw-------. <span>1</span> postgres postgres 26K Jun <span>28</span> 21:44 postgresql.conf
</code></pre></div><p>Change in <code>postgresql.conf</code> parameter <code>listen_addresses</code> to your server IP or <code>*</code> to listen on all IP‚Äôs available on server:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab data<span>]</span>$ vi postgresql.conf

<span>##------------------------------------------------------------------------------</span>
<span>## CONNECTIONS AND AUTHENTICATION</span>
<span>##------------------------------------------------------------------------------</span>

<span>## - Connection Settings -</span>

listen_addresses <span>=</span> <span>'*'</span>          <span>## what IP address(es) to listen on;</span>
                                        <span>## comma-separated list of addresses;</span>
                                        <span>## defaults to 'localhost'; use '*' for all</span>
</code></pre></div><p>Restart PostgreSQL to apply changes - you can do that with <code>systemctl</code> from <code>root</code> os user  service or with <code>pg_ctl -D PGDATA restart</code> from <code>postgres</code> os user:</p>
<div><pre><code data-lang="bash"><span>[</span>root@postgres-lab ~<span>]</span><span>## systemctl restart postgresql-12.service</span>
</code></pre></div><p>Check whre PostgreSQL is listening now:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ netstat -lptnu | grep post
<span>(</span>Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.<span>)</span>
tcp        <span>0</span>      <span>0</span> 0.0.0.0:5432            0.0.0.0:*               LISTEN      30161/postmaster    
tcp6       <span>0</span>      <span>0</span> :::5432                 :::*                    LISTEN      30161/postmaster  
</code></pre></div><h2 id="configure-remote-access---pg_hbaconf">Configure remote access - pg_hba.conf</h2>
<p>PostgreSQL instance has got restricted access by <code>pg_hba.conf</code> file(host based authentication file).</p>
<p>We can provide in it information from which <code>ADDRESS</code> to which <code>DATABASE</code> on which <code>USER</code> by what <code>METHOD</code> we allow connecting. Additionaly we have to provide <code>TYPE</code> of connection.</p>
<p>This file resides in same place where <code>postgresql.conf</code>(we can alter this behavior by setting <code>pg_hba</code> parameter in <code>postgresql.conf</code>):</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ cd /postgresql/data/

<span>[</span>postgres@postgres-lab data<span>]</span>$ vi pg_hba.conf
<span>## TYPE  DATABASE        USER            ADDRESS                 METHOD</span>

<span>## "local" is for Unix domain socket connections only</span>
local   all             all                                     trust
<span>## IPv4 local connections:</span>
host    all             all             127.0.0.1/32            trust
<span>## IPv6 local connections:</span>
host    all             all             ::1/128                 trust
</code></pre></div><p>Allowed <code>TYPE</code>'s:</p>
<ul>
<li><code>local</code> - socket connection - needed to connect from shell on database server</li>
<li><code>host</code> - standard TCP/IP connection over the network - bnost SSL and no SSL</li>
<li><code>hostssl</code> - TCP/IP connection but only with SSL</li>
<li><code>hostnossl</code> - TCP/IP only without SSL</li>
<li><code>hostgssenc</code> - TCP/IP only GSSAPI</li>
<li><code>hostnogssenc</code> - TCP/IP only without GSSAPI</li>
</ul>
<p>With <code>DATABASE</code> we can specify database name or use special value <code>sameuser</code> if database name should be same as name of user that is connecting.</p>
<p>With <code>USER</code> we can specify user or role - role name should be preceded by <code>+</code> sign.</p>
<p><code>ADDRESS</code> field could be - hostname, IP range in CIDR format or special words:</p>
<ul>
<li><code>samehost</code> - which correspond to all IP adresses of database server</li>
<li><code>samenet</code> - which correspond to all IP in database server subnet</li>
</ul>
<p>With <code>METHOD</code> field we can set one of authentication methods - most important ones are:</p>
<ul>
<li><code>trust</code> - allow connection without password - moslty set for local connections from database server itself</li>
<li><code>reject</code> - reject connections</li>
<li><code>md5</code> - allow connections after getting from user password - encrypted</li>
<li><code>password</code> - allow connection after getting plain password - DO NOT USE in untrusted networks - better -&gt; never use this option</li>
<li><code>ldap</code> - getting account authorization data from LDAP server</li>
</ul>
<p>In <code>DATABASE</code> and <code>USER</code> fields you can specify special word <code>all</code> if you don‚Äôt want to create any restrictions here.</p>
<p>There can be situation when we must use additional field named <code>auth-options</code> for specyfying details for example for <code>hostssl</code> connection type. This topic will be covered in another post.</p>
<h3 id="sample-pg_hba-record---allow-all-users-connect-to-any-db-from-all-ip-addresses---only-with-password">Sample pg_hba record - allow all users connect to any DB from all IP addresses - only with password</h3>
<p>Add in <code>pg_hba.conf</code>:</p>
<div><pre><code data-lang="bash"><span>## Network access</span>
host    all             all             0.0.0.0/0               md5
</code></pre></div><p>Reload(online operation) PostgreSQL that it can use <code>pg_hba.conf</code> changes:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab data<span>]</span>$ /usr/pgsql-12/bin/pg_ctl -D /postgresql/data reload
server signaled
</code></pre></div><h2 id="connecting-to-postgresql">Connecting to PostgreSQL</h2>
<h3 id="local-from-server">Local from server</h3>
<p>It will work without password because we have <code>trust</code> in <code>pg_hba.conf</code> for <code>local</code> connections:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql
psql <span>(</span>12.3<span>)</span>
Type <span>"help"</span> <span>for</span> help.
</code></pre></div><h3 id="remote-machine">Remote machine</h3>
<p>Default URI syntax - you can connect like this:<br>
<code>psql postgresql://user:passwd@host:5432/dbame</code><br>
or by more common method:<br>
Connect to remote database from <code>psql</code> with connections details provided in parameters(it will ask for password because of <code>md5</code> method in <code>pg_hba.conf</code> for connections from <code>0.0.0.0/0</code>):</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab data<span>]</span>$ psql -h 10.128.0.2 -p <span>5432</span>
Password <span>for</span> user postgres:
psql <span>(</span>12.3<span>)</span>
Type <span>"help"</span> <span>for</span> help.

postgres<span>=</span><span>##</span>
</code></pre></div><p>We can also use parameter <code>-U</code> to specify username different than OS username we currently are using.</p>
<p>Also all this parameters can be taken from shell variables which names are self descriptive - if we set all of them we can just use plain <code>psql</code> command to connect:</p>
<ul>
<li><code>PGHOST</code></li>
<li><code>PGPORT</code></li>
<li><code>PGDATABASE</code></li>
<li><code>PGUSER</code></li>
<li><code>PGPASSWORD</code></li>
</ul>
<h3 id="check-connected-database">Check connected database</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## select current_database();</span>
 current_database
------------------
 postgres
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="check-current-user">Check current user</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## select current_user;</span>
 current_user
--------------
 postgres
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="check-ip-and-port-used-for-connection">Check IP and port used for connection</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## select inet_server_addr(), inet_server_port();</span>
 inet_server_addr | inet_server_port
------------------+------------------
 10.128.0.2       |             <span>5432</span>
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="check-postgresql-version">Check PostgreSQL version</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## select version();</span>
                                                version                                                 
--------------------------------------------------------------------------------------------------------
 PostgreSQL 12.3 on x86_64-pc-linux-gnu, compiled by gcc <span>(</span>GCC<span>)</span> 8.3.1 <span>20191121</span> <span>(</span>Red Hat 8.3.1-5<span>)</span>, 64-bit
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="check-connection-info">Check connection info</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## \conninfo</span>
You are connected to database <span>"postgres"</span> as user <span>"postgres"</span> on host <span>"10.128.0.2"</span> at port <span>"5432"</span>.
</code></pre></div><h2 id="executing-commands-from-shell">Executing commands from shell</h2>
<h3 id="execute-single-command-from-shell">Execute single command from shell</h3>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql -c <span>"select current_time"</span>
    current_time    
--------------------
 14:09:19.854598+00
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="exacute-sql-script-from-shell">Exacute sql script from shell</h3>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql -f create_user.sql
CREATE ROLE
CREATE ROLE
CREATE ROLE
</code></pre></div><h3 id="combine-single-command-with-sql-script-from-shell">Combine single command with sql script from shell</h3>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql -c <span>"select current_time"</span> -f create_user.sql -c <span>"select current_time"</span>
    current_time    
--------------------
 14:14:26.922453+00
<span>(</span><span>1</span> row<span>)</span>

CREATE ROLE
CREATE ROLE
CREATE ROLE
    current_time    
--------------------
 14:14:26.926545+00
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div>
<h3 id="check-all-available-metacommands">Check all available metacommands</h3>
<p>Do it yourself to see all available commands - output trimmed to important ones!</p>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## \?</span>
General
  <span>\c</span>opyright             show PostgreSQL usage and distribution terms
  <span>\c</span>rosstabview <span>[</span>COLUMNS<span>]</span> execute query and display results in crosstab
  <span>\e</span>rrverbose            show most recent error message at maximum verbosity
  <span>\g</span> <span>[</span>FILE<span>]</span> or ;         execute query <span>(</span>and send results to file or |pipe<span>)</span>
  <span>\g</span>desc                 describe result of query, without executing it
  <span>\g</span>exec                 execute query, <span>then</span> execute each value in its result
  <span>\g</span>set <span>[</span>PREFIX<span>]</span>         execute query and store results in psql variables
  <span>\g</span>x <span>[</span>FILE<span>]</span>             as <span>\g</span>, but forces expanded output mode
  <span>\q</span>                     quit psql
  <span>\w</span>atch <span>[</span>SEC<span>]</span>           execute query every SEC seconds

  Query Buffer
    <span>\e</span> <span>[</span>FILE<span>]</span> <span>[</span>LINE<span>]</span>       edit the query buffer <span>(</span>or file<span>)</span> with external editor
    <span>\e</span>f <span>[</span>FUNCNAME <span>[</span>LINE<span>]</span><span>]</span>  edit <span>function</span> definition with external editor
    <span>\e</span>v <span>[</span>VIEWNAME <span>[</span>LINE<span>]</span><span>]</span>  edit view definition with external editor
    <span>\p</span>                     show the contents of the query buffer
    <span>\r</span>                     reset <span>(</span>clear<span>)</span> the query buffer
    <span>\s</span> <span>[</span>FILE<span>]</span>              display history or save it to file
    <span>\w</span> FILE                write query buffer to file

</code></pre></div><h3 id="list-objects-in-psql">List objects in psql</h3>
<ul>
<li>\d[S+]          -       list tables, views, and sequences</li>
<li>\d[S+]  NAME     -      describe table, view, sequence, or index</li>
<li>\da[S]  [PATTERN] -     list aggregates</li>
<li>\dA[+]  [PATTERN]  -    list access methods</li>
<li>\db[+]  [PATTERN]   -   list tablespaces</li>
<li>\dc[S+] [PATTERN]    -  list conversions</li>
<li>\dC[+]  [PATTERN]     - list casts</li>
<li>\dd[S]  [PATTERN]     - show object descriptions not displayed elsewhere</li>
<li>\dD[S+] [PATTERN]     - list domains</li>
<li>\ddp    [PATTERN]     - list default privileges</li>
<li>\dE[S+] [PATTERN]     - list foreign tables</li>
<li>\det[+] [PATTERN]     - list ‚Ä¶</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://knowledgepill.it/posts/postgresql-basics-guide/">https://knowledgepill.it/posts/postgresql-basics-guide/</a></em></p>]]>
            </description>
            <link>https://knowledgepill.it/posts/postgresql-basics-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888907</guid>
            <pubDate>Sun, 19 Jul 2020 12:33:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Conversing with Socrates (GPT-3)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23888893">thread link</a>) | @webcerfer2020
<br/>
July 19, 2020 | https://blogofjake.com/2020/07/19/conversing-with-socrates-gpt-3/ | <a href="https://web.archive.org/web/*/https://blogofjake.com/2020/07/19/conversing-with-socrates-gpt-3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1164">
			<!-- .entry-header -->		<!-- .entry-meta -->
	
	<div>
		
<p>OpenAI is an artifical intelligence company co-founded by Elon Musk, Sam Altman and a few others with funding from the likes of Peter Thiel, Reid Hoffman, and Microsoft. The company‚Äôs mission is ‚Äúto ensure that artificial general intelligence benefits all of humanity‚Äù.</p>



<p>In the last few days, people have been playing around publicly with OpenAI‚Äôs newest available advancement, a text-generating language model that at its best can be difficult to distinguish as non-human.</p>



<p>Since I do not have access to the beta version where people are playing around with the technology, the closest I have been able to interact with it was through McKay Wrigley‚Äôs now temporarily defunct website, <em><a href="https://learnfromanyone.com/">learnfromanyone.com</a></em>. I am not sure how exactly he built it or in what ways it may or may not be differentiated from the GPT-3 beta on its own. They seem largely the same and it is clear that the GPT-3 AI is the thing doing most of the work. One key difference is that while people apparently engage directly with the AI via the beta, on McKay‚Äôs website they instead write in a ‚Äúteacher‚Äù to engage with and a question or statement to begin the back and forth.</p>



<p>I played around with this for a few hours before the website went down and had many failed or broken conversations. I suspect these may have been errors stemming from the few things layered on top of the AI for this website rather than from the AI itself, but I cannot be sure. Nonetheless, I did have several very interesting dialogues with ‚Äúteachers‚Äù whom I thought it would be interesting to converse with. </p>



<p>Below are some screenshots from one of the dialogues that I had, this one with Socrates. The only writing that I did are the pieces written directly after ‚ÄúMe:‚Äù. This does not include two pieces that came up after the text after ‚ÄúMe:‚Äù and before Socrates‚Äô response but which were not written by me. Those two pieces are the ones beginning with ‚Äú(This is a list of‚Äù and ‚ÄúYou are aware of‚Äù. The last thing I should mention is that in the dozens of dialogues that I had on this website, none of the others had the pattern you will see where the responses from the teacher (in this case, Socrates) were supplemented by additional text in parentheses. With that introduction, you have about as much context as I do to understand what is going on with the dialogue below, so I will leave it up to you to interpret for yourself. All I will say is that it certainly seems interesting and it feels like a technology unlike anything I have ever experienced before.</p>



<div><figure><img data-attachment-id="1167" data-permalink="https://blogofjake.com/edi7ntxxsaafeym/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/edi7ntxxsaafeym.jpg" data-orig-size="750,1334" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="edi7ntxxsaafeym" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/edi7ntxxsaafeym.jpg?w=169" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/edi7ntxxsaafeym.jpg?w=576" src="https://theblogofjake.files.wordpress.com/2020/07/edi7ntxxsaafeym.jpg?w=576" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/edi7ntxxsaafeym.jpg?w=576 576w, https://theblogofjake.files.wordpress.com/2020/07/edi7ntxxsaafeym.jpg?w=84 84w, https://theblogofjake.files.wordpress.com/2020/07/edi7ntxxsaafeym.jpg?w=169 169w, https://theblogofjake.files.wordpress.com/2020/07/edi7ntxxsaafeym.jpg 750w" sizes="(max-width: 576px) 100vw, 576px"></figure></div>



<div><figure><img data-attachment-id="1168" data-permalink="https://blogofjake.com/edi7szzwaaechq1/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/edi7szzwaaechq1.jpg" data-orig-size="750,1334" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="edi7szzwaaechq1" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/edi7szzwaaechq1.jpg?w=169" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/edi7szzwaaechq1.jpg?w=576" src="https://theblogofjake.files.wordpress.com/2020/07/edi7szzwaaechq1.jpg?w=576" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/edi7szzwaaechq1.jpg?w=576 576w, https://theblogofjake.files.wordpress.com/2020/07/edi7szzwaaechq1.jpg?w=84 84w, https://theblogofjake.files.wordpress.com/2020/07/edi7szzwaaechq1.jpg?w=169 169w, https://theblogofjake.files.wordpress.com/2020/07/edi7szzwaaechq1.jpg 750w" sizes="(max-width: 576px) 100vw, 576px"></figure></div>



<div><figure><img data-attachment-id="1169" data-permalink="https://blogofjake.com/edi7whnxsaaht86/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/edi7whnxsaaht86.jpg" data-orig-size="750,1334" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="edi7whnxsaaht86" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/edi7whnxsaaht86.jpg?w=169" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/edi7whnxsaaht86.jpg?w=576" src="https://theblogofjake.files.wordpress.com/2020/07/edi7whnxsaaht86.jpg?w=576" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/edi7whnxsaaht86.jpg?w=576 576w, https://theblogofjake.files.wordpress.com/2020/07/edi7whnxsaaht86.jpg?w=84 84w, https://theblogofjake.files.wordpress.com/2020/07/edi7whnxsaaht86.jpg?w=169 169w, https://theblogofjake.files.wordpress.com/2020/07/edi7whnxsaaht86.jpg 750w" sizes="(max-width: 576px) 100vw, 576px"></figure></div>



<div><figure><img data-attachment-id="1170" data-permalink="https://blogofjake.com/edi795hwsaulnlf/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/edi795hwsaulnlf.jpg" data-orig-size="750,1334" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="edi795hwsaulnlf" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/edi795hwsaulnlf.jpg?w=169" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/edi795hwsaulnlf.jpg?w=576" src="https://theblogofjake.files.wordpress.com/2020/07/edi795hwsaulnlf.jpg?w=576" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/edi795hwsaulnlf.jpg?w=576 576w, https://theblogofjake.files.wordpress.com/2020/07/edi795hwsaulnlf.jpg?w=84 84w, https://theblogofjake.files.wordpress.com/2020/07/edi795hwsaulnlf.jpg?w=169 169w, https://theblogofjake.files.wordpress.com/2020/07/edi795hwsaulnlf.jpg 750w" sizes="(max-width: 576px) 100vw, 576px"></figure></div>




	</div><!-- .entry-content -->

	<!-- .entry-footer -->

	<div>
				<p><strong>Published</strong>
			<time datetime="2020-07-19T08:29:11-04:00">July 19, 2020</time><time datetime="2020-07-19T08:30:32-04:00">July 19, 2020</time>		</p><!-- .site-posted-on -->
	</div>
</article></div>]]>
            </description>
            <link>https://blogofjake.com/2020/07/19/conversing-with-socrates-gpt-3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888893</guid>
            <pubDate>Sun, 19 Jul 2020 12:31:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Worms Armageddon 3.8]]>
            </title>
            <description>
<![CDATA[
Score 439 | Comments 142 (<a href="https://news.ycombinator.com/item?id=23888870">thread link</a>) | @typh00n
<br/>
July 19, 2020 | https://worms2d.info/Worms_Armageddon_3.8_Features | <a href="https://web.archive.org/web/*/https://worms2d.info/Worms_Armageddon_3.8_Features">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr">
<center><div><div><div><p><a href="https://wormtube.worms2d.info/vids/WormsArmageddon-TrailerVideo2020-SteamReady.mp4"><img alt="" src="https://worms2d.info/images/8/82/38_trailer_screenshot.jpg" width="640" height="360"></a></p><div><p>Click above to watch the new trailer in full quality!</p></div></div></div></div></center>
<div>
<p>Worms Armageddon version 3.8 is finally released! It's been a long time coming, and we hope you'll enjoy all the features, changes, and bug fixes that made it into this community-made update. To whet your appetite, here are some change highlights:
</p>
<div><div><p><a href="https://worms2d.info/File:ESOButton2.png"><img alt="ESOButton2.png" src="https://worms2d.info/images/0/04/ESOButton2.png" width="146" height="82"></a></p></div></div>
<h3><span id="Extended_Scheme_Options">Extended Scheme Options</span></h3>
<p>Customise your matches in weird and wonderful ways with over 70 new scheme options. Manipulate physics, fire more than one weapon in a turn, have worms bounce around the landscape, or choose from a huge array of other tweaks in order to perfect your scheme. These options are only for the seasoned Worms veteran, and as such you will need to have completed the Single Player mode and unlocked The Full Wormage in order to access them.</p>
<br><center><a href="https://worms2d.info/File:ESO1.gif" title="inline"><img alt="inline" src="https://worms2d.info/images/9/91/ESO1.gif" width="180" height="180"></a> <a href="https://worms2d.info/File:ESO2.gif" title="inline"><img alt="inline" src="https://worms2d.info/images/d/df/ESO2.gif" width="180" height="180"></a> <a href="https://worms2d.info/File:ESO3.gif" title="inline"><img alt="inline" src="https://worms2d.info/images/5/59/ESO3.gif" width="180" height="180"></a> <a href="https://worms2d.info/File:ESO4.gif" title="inline"><img alt="inline" src="https://worms2d.info/images/4/45/ESO4.gif" width="180" height="180"></a></center>
<p>For those who used the RubberWorm module in older versions of the game, all features formerly accessed through that module are now hiding behind the shiny new Extended Scheme Options star button. Relive your past glories ‚Äî all your old RubberWorm recorded games can be played back with no additional software required.
</p>

<div><div><p><a href="https://worms2d.info/File:Tweening.gif"><img alt="" src="https://worms2d.info/images/5/53/Tweening.gif" width="300" height="240"></a></p><div><p>Demonstration of Tweening</p></div></div></div>
<h3><span id="Tweening">Tweening</span></h3>
<p>Worms Armageddon has never looked this smooth! In older versions, in-game movement and animations would be capped at the update rate of the game engine: 50 frames per second. In 3.8 though, experience the full silky smoothness of whatever frame rate your hardware can support ‚Äî movement is now visually interpolated between game engine frames as your worms and weapons glide majestically through the air. Watch a recorded game in slow motion and you'll never want to go back!</p>
<div><div><p><a href="https://worms2d.info/File:Window.png"><img alt="" src="https://worms2d.info/images/d/dc/Window.png" width="300" height="237"></a></p><div><p>Demonstration of windowed mode</p></div></div></div>
<h3><span id="Windowed_Mode">Windowed Mode</span></h3>
<p>Worms Armageddon can now be played in a window! Awkward screen resolution changes and game capture issues are a thing of the past if you enable this feature in Advanced Settings.</p>
<div><div><p><a href="https://worms2d.info/File:Streaming-mode.png"><img alt="" src="https://worms2d.info/images/6/66/Streaming-mode.png" width="211" height="85"></a></p><div><p>Demonstration of Streaming Mode IP address hiding</p></div></div></div>
<h3><span id="Streamers.27_Heaven">Streamers' Heaven</span></h3>
<p>Along with Windowed Mode, a couple of additional options have been added specifically for streamers to make their lives easier. Audio can now be allowed to continue playing when the game window loses focus, and the new Streaming Mode will prevent IP addresses from being displayed when hosting or joining an online game (see the Update Documentation for more information).</p>
<div><div><p><a href="https://worms2d.info/File:Cpu-teams.png"><img alt="" src="https://worms2d.info/images/4/4d/Cpu-teams.png" width="252" height="151"></a></p><div><p>Demonstration of CPU teams being added to an online game</p></div></div></div>
<h3><span id="CPU_Teams_at_Large">CPU Teams at Large</span></h3>
<p>CPU teams can now be added to online games. They're always uniquely distinguishable from player teams to prevent shenanigans, but you can now finally team up with your friends to take down a swarm of those computer-controlled invertebrates. Or if you'd just like to watch a relaxing game while you work, matches containing only CPU teams may now also be started, both online and offline.</p>
<div><div><p><a href="https://worms2d.info/File:Smapshot.png"><img alt="" src="https://worms2d.info/images/7/71/Smapshot.png" width="300" height="225"></a></p></div></div>
<h3><span id="Mapshot">Mapshot</span></h3>
<p>Have you ever wrought a beautiful trail of destruction on your Worms Armageddon landscape and wished you could play a brand new game on the land that remained? Or have you ever been interrupted in the middle of a game and wished you could extract the remaining landscape to help you set up a rematch? Well, now you can! Simply type <b>/map</b> into the in-game chat or press <b>Alt + Pause</b> at any time to save a snapshot of the current state of the map, allowing you to continue your rampage from where you left off!</p>
<div><div><p><a href="https://worms2d.info/File:Wa95-2.png"><img alt="" src="https://worms2d.info/images/a/a0/Wa95-2.png" width="300" height="225"></a></p><div><p>Worms Armageddon running in Windows 95 (on real hardware!)</p></div></div></div>
<h3><span id="Compatibility">Compatibility</span></h3>
<p>Much effort has been expended in allowing everyone, no matter their hardware, to have a good Worms Armageddon experience. Further tweaks have been made to improve the experience of Windows 10 users. Worms Armageddon now runs well under Wine or Proton on Linux. A new OpenGL renderer has been added which, depending on your hardware, might outperform the other renderers. Windowed mode means there's no more need for your hardware to support specific screen resolutions. And for those into retro computing, Worms Armageddon has been seen to once again run on systems of yore...</p>
<div><div><p><a href="https://worms2d.info/File:Languages.png"><img alt="" src="https://worms2d.info/images/b/b5/Languages.png" width="222" height="120"></a></p><div><p>Sample of languages supported by Worms Armageddon's volunteer translators</p></div></div></div>
<h3><span id="Translations">Translations</span></h3>
<p>Through the tireless efforts of volunteer translators, Worms Armageddon is now fully translated to seven languages (üá´üáÆ Finnish, üá´üá∑ French, üá©üá™ German, üáµüáπüáßüá∑ Portuguese, üá∑üá∫ Russian, üá™üá∏ Spanish and üá∏üá™ Swedish), with four more languages with partial translations on the way. The Update Documentation (Readme) now has translations to Finnish, French, and Spanish!</p>
<h3><span id="Fixes_and_More">Fixes and More</span></h3>
<p><a href="https://worms2d.info/File:Moon.png" title="Memey moon face"><img alt="Memey moon face" src="https://worms2d.info/images/4/47/Moon.png" width="100" height="123"></a></p>
<p>Over seven years in development, this update's release notes list consists of:
</p>
<ul><li> 370 fixes,</li>
<li> 45 changes, and</li>
<li> 61 new features.</li></ul>
<p>Our thanks go to all the hardworking members of the Worms Armageddon community who helped make this update a reality. And for the full list of what's new, check the Update Documentation (included with this update) or <a href="https://www.tus-wa.com/forums/announcements/worms-armageddon-v3-8-released-32795/">developer Deadcode's thread</a> on fan-site TUS!
</p>
</div>

<!-- 
NewPP limit report
Cached time: 20200722161827
Cache expiry: 86400
Dynamic content: false
CPU time usage: 0.016 seconds
Real time usage: 0.020 seconds
Preprocessor visited node count: 88/1000000
Preprocessor generated node count: 260/1000000
Post‚Äêexpand include size: 354/2097152 bytes
Template argument size: 60/2097152 bytes
Highest expansion depth: 4/40
Expensive parser function count: 0/100
-->

<!-- 
Transclusion expansion time report (%,ms,calls,template)
100.00%    2.343      1 - -total
 43.20%    1.012      1 - Template:ParentArticle
 33.69%    0.789      9 - Template:Clear
-->

<!-- Saved in parser cache with key wkb-mw_:pcache:idhash:5655-0!*!0!!*!5!* and timestamp 20200722161827 and revision id 26331
 -->
</div></div>]]>
            </description>
            <link>https://worms2d.info/Worms_Armageddon_3.8_Features</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888870</guid>
            <pubDate>Sun, 19 Jul 2020 12:25:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tired of note-taking apps]]>
            </title>
            <description>
<![CDATA[
Score 466 | Comments 450 (<a href="https://news.ycombinator.com/item?id=23888799">thread link</a>) | @akkshu92
<br/>
July 19, 2020 | https://akkshaya.blog/2020/07/19/note-taking/ | <a href="https://web.archive.org/web/*/https://akkshaya.blog/2020/07/19/note-taking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1052">
		<!-- .entry-header -->

	<div>
		
<p>I‚Äôm tired of note-taking apps. </p>



<p>It‚Äôs not because of limited choices. But it‚Äôs the other way around. There are so many note-taking apps you could try but end up sticking to none. At least, that‚Äôs my story. It‚Äôs a perfect example of&nbsp;<strong>the paradox of choice.</strong></p>



<p>I used to wonder why people keep building so many ‚Äònote-taking‚Äô apps when the market is already crowded with choices. Then I figured a few reasons why.</p>



<ul><li><strong>the market size</strong>: the global <a href="https://www.verifiedmarketresearch.com/product/note-making-management-software-market/#:~:text=According%20to%20Verified%20Market%20Research,5.32%25%20from%202019%20to%202026." target="_blank" rel="noreferrer noopener">note-taking management software market</a> is estimated to reach&nbsp;<strong>$1.35 billion </strong>by<strong> 2026</strong>, growing at a&nbsp;<strong>CAGR </strong>of<strong> 5.32% </strong>from<strong> 2019 to 2026</strong></li><li><strong>greater scope for innovation:&nbsp;</strong>eg., be it creating a task list, a roadmap, or a design repository, Notion can handle it all</li><li><strong>lack of satisfaction:&nbsp;</strong>it‚Äôs noted that people always use a combination of note-taking apps and hardly stick to one for a long time</li></ul>



<p>Despite such heavy competition, apps like Notion, Google Keep, OneNote, Evernote, etc. have managed to earn a place. People use these apps for</p>



<ul><li>the ecosystem. eg., Google Keep, Microsoft OneNote</li><li>the neat user experience., eg. Bear etc.</li><li>creating a disciplined way of taking notes. eg., Notion, Roam Research</li></ul>



<p>I‚Äôve tried them all. But none of these apps have turned me into a ‚Äò<strong>repeat user</strong>.‚Äô </p>



<p>After battling with so many apps only to feel guilty for not having the discipline to consistently use them, I‚Äôve finally resorted to the most personal and easy alternative ‚Å†‚Äî&nbsp;<strong>writing things down</strong>.</p>



<p>I‚Äôm familiar with writing in a notebook since my childhood. It‚Äôs not new to me, and it absolutely doesn‚Äôt require any learning curve.</p>



<h3>The reasons why I find writing things down useful</h3>



<ul><li>absolute focus and the ability to think through the points I‚Äôm writing</li><li>gives a chance to remember what I‚Äôm writing</li><li>no way to copy-paste stuff as it is, and that means taking notes in a way I understand</li><li>easy to switch between formats eg., flowchart, mind map, Venn diagram, etc</li><li>helps me stay in touch with my handwriting</li></ul>



<p>Of course, everything has its downsides, and writing things down is no exception here. <br>For example, I will not be able to</p>



<ul><li>add screenshots/images, links, etc</li><li>easily search for content as there‚Äôs no ‚Äòsearch bar‚Äô</li></ul>



<p>And maybe there‚Äôs more to the list I‚Äôm not talking about. </p>



<p>All I can say for sure is, based on my usage behavior, I‚Äôm okay missing out on these features. I can always save links to <a href="https://app.getpocket.com/" target="_blank" rel="noreferrer noopener">Pocket</a> for future reference, and take pictures of my notes to share with friends.</p>



<p>So if you ask me if I‚Äôd try a beautiful, innovative note-taking app that‚Äôs much better than the apps I‚Äôve used so far, my answer is,&nbsp;<em>‚Äú<strong>Why not</strong>! <strong>I‚Äôd definitely give it a shot</strong></em>.‚Äù</p>



<p>But my greatest worry is if I‚Äôd continue using it.</p>



<p><strong>Note: </strong>If my opinion on note-taking apps changes over time, I‚Äôd be happy to update this post with a ‚ÄúAnd the hero finally arrived!‚Äù heading to talk about the app that helped change my mind. ü§°</p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->

	</article></div>]]>
            </description>
            <link>https://akkshaya.blog/2020/07/19/note-taking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888799</guid>
            <pubDate>Sun, 19 Jul 2020 12:12:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Megastep, 1M FPS reinforcement learning on a single GPU]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23888780">thread link</a>) | @andyljones
<br/>
July 19, 2020 | https://andyljones.com/megastep/index.html | <a href="https://web.archive.org/web/*/https://andyljones.com/megastep/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
      
      <div>
        <div>
          

          <div role="main">
            
  <bold><span>This repo is still pre-release. The documentation is still incomplete. </span></bold><div id="megastep">

<p><strong>megastep</strong> helps you build 1-million FPS reinforcement learning environments <em>on a single GPU</em>.</p>
<div id="examples">
<h2>Examples<a href="#examples" title="Permalink to this headline">¬∂</a></h2>
<p><strong>Explorer</strong>: 180k FPS, <a href="https://github.com/andyljones/megastep/tree/master/megastep/demo/envs/explorer.py">100 lines of Python</a>.</p>
<video controls="" src="https://andyljones.com/megastep/_static/explorer.mp4" autoplay="" loop="" muted="" type="video/mp4" width="640"></video><p><strong>Deathmatch</strong>: 1.2m FPS, <a href="https://github.com/andyljones/megastep/tree/master/megastep/demo/envs/deathmatch.py">150 lines of Python</a>.</p>
<video controls="" src="https://andyljones.com/megastep/_static/deathmatch.mp4" autoplay="" loop="" muted="" type="video/mp4" width="640"></video><p>Quoted FPS are for a single RTX 2080 Ti and random actions; visualizations are with a 256-neuron LSTM.</p>
</div>
<div id="features">
<h2>Features<a href="#features" title="Permalink to this headline">¬∂</a></h2>
<blockquote>
<div><ul>
<li><p>Run thousands of environments in parallel, entirely on the GPU.</p></li>
<li><p>Write your own environments using PyTorch alone, no CUDA necessary.</p></li>
<li><p>1D observations. The world is more interesting horizontally than vertically.</p></li>
<li><p>One or many agents, and one or many cameras per agent.</p></li>
<li><p>A database of 5000 home layouts to explore, based on <a href="https://github.com/CubiCasa/CubiCasa5k">Cubicasa5k</a>.</p></li>
<li><p>A minimal, modular library. Not a framework.</p></li>
<li><p>(In progress) Extensive documentation, tutorials and explanations.</p></li>
</ul>
</div></blockquote>
</div>
<div id="install">
<h2>Install<a href="#install" title="Permalink to this headline">¬∂</a></h2>
<p>If you‚Äôre working on an Ubuntu machine with CUDA already set up and Python 3.6 or higher, it should be as simple as</p>
<div><div><pre><span></span>pip install megastep<span>[</span>cubicasa,rebar<span>]</span>
</pre></div>
</div>
<p>To check everything works, run</p>
<div><div><pre><span></span><span>from</span> <span>megastep.demo</span> <span>import</span> <span>*</span>
<span>env</span> <span>=</span> <span>explorer</span><span>.</span><span>Explorer</span><span>(</span><span>1</span><span>)</span>
<span>agent</span> <span>=</span> <span>Agent</span><span>(</span><span>env</span><span>)</span><span>.</span><span>cuda</span><span>()</span>
<span>demo</span><span>(</span><span>env</span><span>=</span><span>env</span><span>,</span> <span>agent</span><span>=</span><span>agent</span><span>,</span> <span>length</span><span>=</span><span>64</span><span>)</span>
</pre></div>
</div>
<p><strong>The first time you import megastep on your machine will be slow</strong> as it compiles the C++ side of things.</p>
</div>

<div id="support">
<h2>Support<a href="#support" title="Permalink to this headline">¬∂</a></h2>
<p>I am an independent researcher, so just how much support I can give is limited. But you‚Äôre absolutely welcome to <a href="https://github.com/andyljones/megastep/issues">open
a GitHub issue</a> or <a href="https://gitter.im/megastep-rl/community">see if I‚Äôm around on
Gitter</a>. At the very least I‚Äôll try to point you in the right direction.</p>
<p>You can also find me <a href="https://twitter.com/andy_l_jones">on Twitter</a> or you can <a href="mailto:andyjones.ed%40gmail.com">email me</a>. Of
the options, a GitHub issue is likely the best choice as if you have a question, there are likely other people
out there with the same exact question! And if they don‚Äôt, maybe someone else will have an answer for you.</p>
</div>

</div>


          </div>
          
        </div>
      </div>
    
  </div></div>]]>
            </description>
            <link>https://andyljones.com/megastep/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888780</guid>
            <pubDate>Sun, 19 Jul 2020 12:08:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Tilekit ‚Äì a tilemap editor centered around pattern-based auto tiling]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23888749">thread link</a>) | @rxi
<br/>
July 19, 2020 | https://rxi.itch.io/tilekit | <a href="https://web.archive.org/web/*/https://rxi.itch.io/tilekit">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper"><div id="inner_column"><div itemscope="" itemtype="http://schema.org/Product" id="view_game_page_93165"><div><div><div><p>Tilekit is a tilemap editor centered around pattern-based auto tiling.</p>
<p><img src="https://img.itch.zone/aW1nLzM3MzM1MjkucG5n/original/NxjIjz.png"></p>
<p>Instead of manually placing hand-picked&nbsp;tiles, which can often be tedious, Tilekit works by using an&nbsp;<em>input</em> map of basic tiles and a set of user-defined rules to create the resultant&nbsp;<em>output</em> map from your tileset.<br></p>
<figure><img src="https://img.itch.zone/aW1nLzM3MzM0ODYuZ2lm/original/0jfMfV.gif"></figure>
<p><strong>Features:</strong><br></p>
<ul><li>Unique pattern-based-rule autotiling&nbsp;system</li><li>Map export to JSON</li><li>Code-export of final ruleset&nbsp;to C or Lua</li><li>Basic <em>object</em> system for game-entity placement</li><li>Simple animated tile system</li></ul>
<hr>
<p>Please <strong>try out the demo</strong> before purchasing!&nbsp;<em>(save and export are disabled in the demo version)&nbsp;‚Äî </em><strong></strong>The<strong>&nbsp;</strong><em>demo_projects.zip</em> archive&nbsp;includes some demo projects.<br></p></div><h2 id="purchase">Purchase</h2><div><p>In order to download this tool you must purchase it at or above the
              minimum price of $20 USD. You will get access to the following files:</p></div><h2 id="demo">Download demo</h2><section id="devlog"><h2>Development log</h2><ul><li><a href="https://rxi.itch.io/tilekit/devlog/160945/tilekit-103">Tilekit 1.03</a><p><abbr title="10 July 2020 @ 18:00"><span></span> 11 days ago</abbr></p></li><li><a href="https://rxi.itch.io/tilekit/devlog/159259/tilekit-102">Tilekit 1.02</a><p><abbr title="03 July 2020 @ 17:51"><span></span> 18 days ago</abbr></p></li><li><a href="https://rxi.itch.io/tilekit/devlog/158202/tilekit-101">Tilekit 1.01</a><p><abbr title="29 June 2020 @ 14:42"><span></span> 23 days ago</abbr></p></li></ul></section></div></div></div></div></div></div>]]>
            </description>
            <link>https://rxi.itch.io/tilekit</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888749</guid>
            <pubDate>Sun, 19 Jul 2020 12:01:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things Unexpectedly Named After People]]>
            </title>
            <description>
<![CDATA[
Score 422 | Comments 282 (<a href="https://news.ycombinator.com/item?id=23888725">thread link</a>) | @vortex_ape
<br/>
July 19, 2020 | https://notes.rolandcrosby.com/posts/unexpectedly-eponymous/ | <a href="https://web.archive.org/web/*/https://notes.rolandcrosby.com/posts/unexpectedly-eponymous/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
            <p><h5>July 19, 2020</h5></p>
        </div></div>]]>
            </description>
            <link>https://notes.rolandcrosby.com/posts/unexpectedly-eponymous/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888725</guid>
            <pubDate>Sun, 19 Jul 2020 11:58:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Protect Your Team from Weekend Work]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23888686">thread link</a>) | @cauliflower99
<br/>
July 19, 2020 | http://www.dcaulfield.com/protect-your-team-from-weekend-work/ | <a href="https://web.archive.org/web/*/http://www.dcaulfield.com/protect-your-team-from-weekend-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-15658">
<small>
    <a href="http://www.dcaulfield.com/2020/07/19/">July 19, 2020</a></small>
    			<small>
				<a href="http://www.dcaulfield.com/author/admin/"></a></small>
		
<p>Is it unfair your team is constantly called for weekend work?<br>Are your team members complaining that they have no social life anymore?<br>Are they threatening to leave if something does not change?</p>



<p>The good news is, there are many scenarios where you can reduce or remove the need for your team in their downtime. First, you need to understand why you team is being called for weekend work. Let‚Äôs go through a few reasons and how we might prevent them from happening.</p>



<h2>Reasons For Weekend Work</h2>



<h3>Site Outages</h3>



<p>A Class A, highest priority ticket has come in on Friday evening as everyone is preparing to leave ‚Äì a customer‚Äôs site has crashed. Your team must drop everything (including their social plans) to get online and come up with a solution.</p>



<p>After working all night Friday and half of Saturday, your team puts in a fix and calls it a day. But they are not happy ‚Äì their weekend with their family and friends has been cancelled, and they wonder if the job is worth these weekend calls.</p>



<h4>Prevent Site Outages</h4>



<p>After the issue has been resolved, take a whiteboard or pen and paper and answer these questions.</p>



<ul><li>What did the user experience? For example, did they receive an alarm, get a 500 response error, etc.?</li><li>Why did the site go down?</li><li>Did something like this happen before?</li><li>Who was involved / what expertise was required?</li><li>How can we prevent this from happening ever again?</li></ul>



<p>Once you have these answered, put a plan in place to mitigate this issue happening ever again. Sometimes, it can be as simple as adding a new test case. Other times it may be more complicated and involve setting up new test environments. Look at the cost/reward of fixing it going forward and make a decision.</p>



<h3>Late Release Work</h3>



<p>The release deadline fast approaches. There is only a few days left until the software is released. Everything is late, and your team are under pressure to deliver.</p>



<p>One of the tasks your team was working on is blocked because the environment was down the past two days. Now the environment is up, but management has requested the task be worked on over the weekend and completed by Monday morning.</p>



<h4>Prevent Late Release Work</h4>



<p>All teams understand the pressure of having features that are late and in danger of not making the deadline.<br>To prevent late delivery of features, here are a list of DON‚ÄôTs you can apply.</p>



<ul><li>Don‚Äôt underestimate the work. Always take your final estimate and add an extra 20% onto it.</li><li>Don‚Äôt plan optimistically. Assume that things will go wrong, other teams will be late, code will break. In Ireland, there is a phrase ‚ÄúIt‚Äôll be grand‚Äù, meaning that everything will work itself out. It won‚Äôt be grand. Nothing will work itself out. Plan accordingly.</li><li>Don‚Äôt promise delivery dates that are not feasible. Pressure from management may tempt you to do this. Do not give in. Have data to backup your claims.</li><li>Don‚Äôt promise delivery dates without doing your homework and gathering as much data as possible. List out as many tasks as possible and estimate each of them. What are your risks? How could your risks affect the delivery date? Are the risks low, medium or high?</li><li>Don‚Äôt hide problems from your manager during the release. Is a task going to be late? Tell your manager asap and show what you are doing to mitigate it.</li></ul>



<p>An experienced team lead will have this list off by heart without even realising it. Have you got more Don‚Äôts you have learned the hard way? Comment them below.</p>



<h3>Late Sprint Work</h3>



<p>This depends on your team. There are teams that are not strict on their sprint commitments, and there are other teams which require themselves to work weekends if the work is not ready to deliver.</p>



<h4>Prevent Late Sprint Work</h4>



<p>Late sprint work usually comes down to poor sprint planning in the first place.</p>



<ul><li>Did your sprint planning cover this task sufficiently?</li><li>Why did the team underestimate this task in their planning?</li><li>What can you take from this going forward to ensure future similar tasks are estimated more accurately?</li></ul>



<p>Effective sprint planning is difficult, but is worth it to get the team in the habit of delivering their committed work.</p>



<h3>Supporting Other Teams</h3>



<p>If you are leading a high performing team, then more than likely you will have at least one or more persons who act as experts or specialists in a particular area. This is great for your team‚Ä¶most of the time.</p>



<p>A downside of being an expert is you get called up for consultation on things you were not even involved in. You could be called into an escalation because another team is behind in their commitments. I have often seen specialists called into very tricky situations like performance test failures, where an application is failing at scale and nobody knows why. Scenarios like this are dangerous for experts, because it could bleed your evening and weekends dry.</p>



<h4>Prevent Supporting Other Teams</h4>



<p>The title here seems unprofessional. Experts are there to act as experts, right? </p>



<p>This may be true, but the fact is that even experts don‚Äôt like getting called on a Friday evening or Saturday morning and asked to go online. As the team lead, it is your job to protect your team as much as possible in their downtime, so that they can focus more effectively during working hours.</p>



<p>There is a host of reasons your team expert could be called into work unexpectedly. Work with your team to brainstorm how to reduce the need for being called to unplanned work. Here are some suggestions.</p>



<ul><li>Train a member from the other team in some debugging techniques for the particular area of expertise.</li><li>Document troubleshooting procedures for various scenarios. Share this document with the organisation.</li><li>If a call comes in, brainstorm some possible solutions for the caller to explore. There may not be a need for you to be online. Give enough information that they can proceed with troubleshooting.</li></ul>



<p>As the team lead, your goal is to keep everyone happy as much as possible. Can you prevent the team from being called in the first place by preparing in advance during working hours? Discuss the above with the experts in your team and get a plan together to protect their weekends.</p>



<h2>Dealing With Necessary Weekend Work</h2>



<p>Sometimes weekend work is absolutely necessary ‚Äì there is no way around it. That bug isn‚Äôt fixing itself and the release date isn‚Äôt moving, so your team is left with no choice.</p>



<p>Now your job as team lead is to reduce the team‚Äôs pain as much as possible. Here are some suggestions for reducing this pain.</p>



<ul><li>Instead of John working Saturday and Sunday, can John work Saturday and Jess work Sunday?</li><li>Challenge the work that is requested. Can some part of it can be investigated on Monday instead of now?</li><li>Develop a rota for the next 4-8 weekends so that your team can plan in advance that they might need to be online. This will also prevent last minute requests to your team members and ruining their weekend plans.</li><li>Is there a support team that could take some of the requested work? In my case, I discovered a ‚Äòsecret‚Äô team that were setup specifically to support internal stakeholder escalations, yet my team had been supporting these cases for the past few months. Nowadays, any time an internal stakeholder asks my team directly for support, I forward their email to the dedicated support team. They‚Äôre happy, I‚Äôm happy, and my team are none the wiser that I have protected their evening and weekend.</li><li>Work smart, not hard. Most likely, your team do not need to be online 24/7. If so, propose time slots that your team will be online to check emails and answer requests. For example, when my team are asked to be online over the weekend ‚Äòjust in case‚Äô something goes wrong, I insist that we give a list of times where we will be online and contactable. In general, the time slots are 10-11am and 3-4pm. Outside of these times, my team can relax and go about their day.</li></ul>



<p>If all else fails and someone has to be online to support a problem, make sure they are not working alone. Any work is painful when it is done alone, and weekend work it is 10 times worse. It may be you that needs to make the sacrifice and go online to brainstorm ideas and support in the troubleshooting. They will be secretly grateful for your company, and won‚Äôt feel the weight of the world on their shoulders.</p>
							</article></div>]]>
            </description>
            <link>http://www.dcaulfield.com/protect-your-team-from-weekend-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888686</guid>
            <pubDate>Sun, 19 Jul 2020 11:50:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Inheritance in C using structure composition]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 28 (<a href="https://news.ycombinator.com/item?id=23888677">thread link</a>) | @arpitbbhayani
<br/>
July 19, 2020 | https://arpitbhayani.me/blogs/inheritance-c | <a href="https://web.archive.org/web/*/https://arpitbhayani.me/blogs/inheritance-c">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>C language does not support inheritance however it does support Structure Compositions which can be tweaked to serve use-cases requiring parent-child relationships. In this article, we find out how Structure Compositions help us emulate inheritance in C and keep our code extensible. We will also find how it powers two of the most important things to have ever been invented in the field of computer science.</p>

<p>Structure Composition is when we put one structure within another, not through its pointer but as a native member - something like this</p>
<pre><code>


<span><span>struct</span> <span>list_head</span> {</span>
	<span><span>struct</span> <span>list_head</span> *<span>next</span>;</span> 
	<span><span>struct</span> <span>list_head</span> *<span>prev</span>;</span> 
};


<span><span>struct</span> <span>list_int</span> {</span>
	<span><span>struct</span> <span>list_head</span> <span>list</span>;</span>  
	<span>int</span> value;              
};


<span><span>struct</span> <span>list_str</span> {</span>
	<span><span>struct</span> <span>list_head</span> <span>list</span>;</span>  
	<span>char</span> * str;             
};
</code></pre>
<p>In the example above, we define a node of a linked list using structure composition. Usually, a linked list node has 3 members - two pointers to adjacent nodes (next and previous) and a third one could either be the data or a pointer to it.  The defining factor of a linked list is the two pointers that logically form a chain of nodes. To keep things abstract we create a struct named <code>list_head</code> which holds these two pointers  <code>next</code> and <code>prev</code> and omits the specifics i.e. data.</p>
<p>Using <code>list_head</code> structure, if we were to define a node of a linked list holding an integer value we could create another struct, named <code>list_int</code> that holds a member of type <code>list_head</code> and an integer value <code>value</code>. The next and previous pointers are brought into this struct through <code>list_head list</code> and could be referred to as <code>list.next</code> and <code>list.prev</code>.</p>
<blockquote>
<p>There is a very genuine reason for picking such weird names for a linked list node and members of structures; the reason to do so will be cleared in the later sections of this essay.</p>
</blockquote>
<p>Because of the above structure definition, building a linked list node holding of any type becomes a breeze. For example, a node holding string could be quickly defined as a struct <code>list_str</code> having <code>list_head</code> and a <code>char *</code>. This ability to extend <code>list_head</code> and build a node holding data of any type and any specifics make low-level code simple, uniform, and extensible.</p>
<h2>Memory Representation of <code>list_int</code></h2>
<p>Structures in C are not padded and they do not even hold any meta information, not even for the member names; hence during allocation, they are allocated the space just enough to hold the actual data.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/83953834-694a6a00-a861-11ea-8ff7-fa69af6af7d6.png" alt="https://user-images.githubusercontent.com/4745789/83953834-694a6a00-a861-11ea-8ff7-fa69af6af7d6.png"></p>
<p>In the illustration above we see how members of <code>list_int</code> are mapped on the allocated space - required by its individual members. It is allocated a contiguous space of 12 bytes - 4 bytes for each of the two pointers and another 4 bytes for the integer value. The contiguity of space allocation and order of members during allocation could be verified by printing out their addresses as shown below.</p>
<pre><code><span><span>void</span> <span>print_addrs</span><span>()</span> </span>{
    
    <span><span>struct</span> <span>list_int</span> *<span>ll</span> = <span>new_list_int</span>(41434);</span>

    
    <span>printf</span>(<span>"%p: head\n"</span>,             head);
    <span>printf</span>(<span>"%p: head-&gt;list.next\n"</span>,  &amp;((head-&gt;<span>list</span>).next));
    <span>printf</span>(<span>"%p: head-&gt;list.prev\n"</span>,  &amp;((head-&gt;<span>list</span>).prev));
    <span>printf</span>(<span>"%p: head-&gt;value\n"</span>,      &amp;(head-&gt;value));
}

~ $ make &amp;&amp; ./a.out
<span>0x4058f0</span>: head
<span>0x4058f0</span>: head-&gt;<span>list</span>.next
<span>0x4058f4</span>: head-&gt;<span>list</span>.prev
<span>0x4058f8</span>: head-&gt;value
</code></pre>
<p>We clearly see all the 3 members, occupying 12 bytes contiguous memory segments in order of their definition within the struct.</p>
<blockquote>
<p>The above code was executed on a machine where the size of integer and pointers were 4 bytes each. The results might differ depending on the machine and CPU architecture.</p>
</blockquote>
<h2>Casting pointers pointing to struct</h2>
<p>In C language, when a pointer to a struct is cast to a pointer to another struct, the engine maps the individual members of a target struct type, depending on their order and offsets, on to the slice of memory of the source struct instance.</p>
<p>When we cast <code>list_int *</code> into <code>list_head *</code>, the engine maps the space required by target type i.e. <code>list_head</code> on space occupied by <code>list_int</code>. This means it maps the 8 bytes required by <code>list_head</code> on the first 8 bytes occupied by <code>list_int</code> instance. Going by the memory representation discussed above, we find that the first 8 bytes of <code>list_int</code> are in fact <code>list_head</code>, and hence casting <code>list_int *</code> to <code>list_head *</code> is effectively just referencing the <code>list_head</code> member of <code>list_int</code> through a new variable.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/83943610-2e254800-a81b-11ea-8b25-056e1b1df85e.png" alt="https://user-images.githubusercontent.com/4745789/83943610-2e254800-a81b-11ea-8b25-056e1b1df85e.png"></p>
<p>This effectively builds a parent-child relationship between the two structs where we can safely typecast a child <code>list_int</code> to its parent <code>list_head</code>.</p>
<blockquote>
<p>It is important to note here that the parent-child relationship is established only because the first member of <code>list_int</code> is of type <code>list_head</code>. it would not have worked if we change the order of members in <code>list_int</code>.</p>
</blockquote>

<p>As established above, by putting one struct within another as its first element we are effectively creating a parent-child relationship between the two. Since this gives us an ability to safely typecast child to its parent we can define functions that accept a pointer to parent struct as an argument and perform operations that do not really require to deal with specifics. This allows us to <strong>NOT</strong> rewrite the functional logic for every child extensions and thus avoid redundant code.</p>
<p>From the context we have set up, say we want to write a function that adds a node between the two in a linked list. The core logic to perform this operation does not really need to deal with any specifics all it takes is a few pointer manipulations of <code>next</code> and <code>prev</code>. Hence, we could just define the function accepting arguments of type <code>list_head *</code>  and write the function as</p>
<pre><code>
<span>static</span> <span>void</span> __list_add(struct list_head *<span>new</span>,
                       struct list_head *prev,
                       struct list_head *next)
{
    next-&gt;prev = <span>new</span>;
    <span>new</span>-&gt;next = next;
    <span>new</span>-&gt;prev = prev;
    prev-&gt;next = <span>new</span>;
}
</code></pre>
<p>Since we can safely typecase <code>list_int *</code> and <code>list_str *</code> to <code>list_head *</code> we can pass any of the specific implementations the function <code>__list_add</code> and it would still add the node between the other two seamlessly.</p>
<p>Since the core operations on linked lists only require pointer manipulations, we can define these operations as functions accepting <code>list_head *</code> instead of specific types like <code>list_int *</code>.  Thus we need not write similar functions for specifics. A function to delete a node could be written as</p>
<pre><code>
<span>static</span> <span>inline</span> <span>void</span> __list_del(struct list_head * prev, struct list_head * next)
{
    next-&gt;prev = prev;
    prev-&gt;next = next;
}
</code></pre>
<p>Other linked list utilities like <em>adding a node to tail</em>, <em>swapping nodes</em>, <em>splicing the list</em>, <em>rotating the list</em>, etc only require manipulations of <code>next</code> and <code>prev</code> pointers. Hence they could also be written in a very similar way i.e accepting <code>list_head *</code> and thus eliminating the need to reimplement function logic for every single child implementation.</p>
<p>This behavior is very similar to how inheritance in modern OOP languages, like Python and Java, work where the child is allowed to invoke any parent function.</p>

<p>There are a ton of practical usage of using Structure Compositions but the most famous ones are</p>
<h2>Linux Kernel</h2>
<p>In order to keep things abstract and extensible, Linux Kernel uses Structure Composition at several places. One of the most important places where it uses composition is for managing and maintaining Linked Lists, exactly how we saw things above. The struct definitions and code snippets are taken as-is from the <a href="https://elixir.bootlin.com/linux/latest/source/include/linux/list.h">Kernel's source code</a>, and hence the structure and variable names look different than usual.</p>
<h2>Python Type and Object Hierarchy</h2>
<p>Python, one of the most important languages in today's world, uses Structure Composition to build Type Hierarchy. Python defines a root structure called <code>PyObject</code> which holds reference count, defining the number of places from which the object is referenced - and object type - determining the type of the object i.e. <code>int</code>, <code>str</code>, <code>list</code>, <code>dict</code>, etc.</p>
<pre><code><span>typedef</span> <span><span>struct</span> _<span>object</span> {</span>
    Py_ssize_t     ob_refcnt;  
    PyTypeObject   *ob_type;   
} PyObject;
</code></pre>
<p>Since Python wants these fields to be present in every single object that is created during runtime, it uses structure composition to ensure that objects like integers, floats, string, etc put <code>PyObject</code> as their first element and thus establishing a parent-child relationship. A Float object in Python is defined as</p>
<pre><code><span>#<span>define</span> PyObject_HEAD PyObject ob_base;</span>

<span>typedef</span> <span><span>struct</span> {</span>
    PyObject_HEAD
    <span>double</span> ob_fval;    
} PyFloatObject;
</code></pre>
<p>Now writing utility functions that increments and decrements references count on every access of any object could be written as just a single function accepting <code>PyObject *</code> as shown below</p>
<pre><code><span>static</span> <span>inline</span> <span>void</span> _Py_INCREF(PyObject *op) {
    op-&gt;ob_refcnt++;
}
</code></pre>
<p>Thus we eradicate a need of rewriting <code>INCREF</code> for every single object type and just write it once for <code>PyObject</code> and it will work for every single Python object type that is extended through <code>PyObject</code>.</p>

<ul>
<li><a href="https://elixir.bootlin.com/linux/latest/source/include/linux/list.h">LinkedList in Linux Source Code</a></li>
<li><a href="https://docs.python.org/3/c-api/structures.html#c.PyObject">PyObject - Python Internals Documentation</a></li>
<li><a href="https://docs.python.org/3/c-api/float.html">PyFloatObject - Python Internals Documentation</a></li>
</ul>
</div></div><section><div><div><p><img src="https://arpitbhayani.me/static/img/arpit.jpg"></p>  <h2>
              500+ Signups
            </h2> <p>
              If you like what you read subscribe you can always subscribe to
              my newsletter and get the post delivered straight to your inbox.
              I write
              <a href="https://arpitbhayani.me/blogs">essays</a> on various
              engineering topics and share it through my weekly
              <a href="https://arpitbhayani.me/newsletter">newsletter</a> üëá
            </p> <br> </div></div></section></div>]]>
            </description>
            <link>https://arpitbhayani.me/blogs/inheritance-c</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888677</guid>
            <pubDate>Sun, 19 Jul 2020 11:48:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pipeline Design Patterns for Continuous Delivery]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23888341">thread link</a>) | @kiyanwang
<br/>
July 19, 2020 | https://www.singlestoneconsulting.com/blog/7-pipeline-design-patterns-for-continuous-delivery/ | <a href="https://web.archive.org/web/*/https://www.singlestoneconsulting.com/blog/7-pipeline-design-patterns-for-continuous-delivery/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-601"><div><p>Business agility is built on code agility. For modern digital products and services, the ability to release on demand quickly and safely is a real competitive business advantage.</p><p>Since 2004 we have designed, built, and deployed code pipelines to automate applications and infrastructure. We‚Äôre sharing seven pipeline design patterns that we‚Äôve learned improve speed, agility, and quality while increasing autonomy, transparency, and maintainability.</p><h2><strong>Continuous Delivery</strong><strong> </strong></h2><p><a href="https://continuousdelivery.com/" target="_blank" rel="noreferrer noopener">Continuous Delivery</a> is ‚Äúthe ability to get changes of all types into the hands of users, safely and quickly in a sustainable way.‚Äù If you think about Continuous Delivery on an Agile vs. Effort matrix, it falls squarely between Continuous Integration and Continuous Deployment. Often these are collectively referred to as CI/CD.</p><div><figure><img src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.32.09-PM-1300x763.png" alt="What is continuous delivery" width="632" height="370" data-src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.32.09-PM-1300x763.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure></div><p>In the <a href="https://services.google.com/fh/files/misc/state-of-devops-2019.pdf" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">2019 State of the DevOps Report</a>, over 31,000 respondents reported the effectiveness of their development and delivery processes. The results between the elite and low performers is staggering. The elite performs had 200x more deployments and 100x faster speed to deployment <strong><em>while also</em></strong> being 2,600x faster to recover from incidents and 7x less likely to roll back releases.</p><p>This research shows that for elite performing organizations, speed and stability are not opposites! You can have both ‚Äì in fact you need both ‚Äì to gain real competitive advantages for your digital products and services.</p><h2><strong>Code Pipelines</strong></h2><p>Code pipelines are the primary technical artifacts of continuous delivery. Modern-day pipelines transform application and infrastructure source code into versioned packages deployable to any environment. By automating all the mundane tasks to build and deploy systems, teams are free to focus on value-added capabilities.</p><div><figure><img src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.31.55-PM-1300x627.png" alt="" width="653" height="316" srcset="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.31.55-PM-1300x627.png 1300w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.31.55-PM-660x318.png 660w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.31.55-PM-768x371.png 768w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.31.55-PM-1536x741.png 1536w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.31.55-PM.png 1886w" sizes="(max-width: 653px) 100vw, 653px" data-srcset="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.31.55-PM-1300x627.png 1300w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.31.55-PM-660x318.png 660w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.31.55-PM-768x371.png 768w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.31.55-PM-1536x741.png 1536w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.31.55-PM.png 1886w" data-src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.31.55-PM-1300x627.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure></div><p>While code pipelines have been around for nearly 20 years ‚Äì <a href="https://en.wikipedia.org/wiki/CruiseControl" target="_blank" rel="noreferrer noopener">CruiseControl</a>, one of our early favorites, was first released in 2001 ‚Äì they have evolved quite significantly over the years and really come into their own in the last few years.</p><p>Based on our work and observations from our customers, we have identified 7 pipeline design patterns that we see in many modern tech organizations.</p><h2><strong>Pipeline Design Patterns</strong></h2><h3>Pipeline Design Pattern #1: Pipelines as Code</h3><p><em>Pipeline logic is codified, stored alongside application or infrastructure code</em><em> and utilizes containerized runners. </em></p><p>State of the Art:</p><div><figure><img src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.04-PM.png" alt="Pipelines as code" width="256" height="349" data-src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.04-PM.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure></div><ul><li>No GUI setup steps! Pipeline logic is managed like any other application code and subject to the same branching strategies and review processes.</li><li>Pipeline execution on containers allows your CI/CD platform to support many different workloads, while each workload can have its own build environment to meet its unique needs.</li><li>Container image provenance uses trusted Docker images for build environments.</li><li>CI runner configuration is automated, identical, and hands-free. CI runners can scale to meet demand and can be on standby during core hours to minimize delays.</li><li>Secrets are stored outside of the pipeline and their output is masked, leading to higher security.</li></ul><h3>Pipeline Design Pattern #2: Externalize Logic into Reusable Libraries</h3><p><em>Reusable libraries contain common pipeline logic</em><em> that is</em><em> referenc</em><em>e</em><em>able from pipeline code and </em><em>independently developed and tested.</em></p><div><figure><img src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.15-PM.png" alt="Externalize Logic into Reusable Libraries" width="242" height="369" srcset="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.15-PM.png 822w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.15-PM-432x660.png 432w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.15-PM-768x1173.png 768w" sizes="(max-width: 242px) 100vw, 242px" data-srcset="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.15-PM.png 822w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.15-PM-432x660.png 432w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.15-PM-768x1173.png 768w" data-src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.15-PM.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure></div><p>State of the Art:</p><ul><li>Treat pipeline libraries as any other releasable software. They have their own repos, pipelines, and are unit tested with good release notes.</li><li>Pipelines call external tasks whenever possible using language-specific tools like Make, Rake, npm, Maven or others to simplify the pipeline and keeps the local and CI workflow identical.</li><li>Libraries are discoverable and have good documentation.</li></ul><h3>Pipeline Design Pattern #3: Separate Build and Deploy Pipelines</h3><p><em>Build and deploy pipelines should be logically separate</em><em>d</em><em>, </em><em>independently runnable</em><em> and triggered by </em><em>automated or manual events</em></p><div><figure><img src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.31-PM.png" alt="Separate Build and Deploy Pipelines " width="316" height="313" srcset="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.31-PM.png 1128w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.31-PM-660x653.png 660w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.31-PM-768x760.png 768w" sizes="(max-width: 316px) 100vw, 316px" data-srcset="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.31-PM.png 1128w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.31-PM-660x653.png 660w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.31-PM-768x760.png 768w" data-src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.31-PM.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure></div><p>State of the Art:</p><ul><li>Build once, deploy many. Focus on the first build. It becomes an artifact that you can deploy many times.</li><li>Be environmentally agnostic. Without an environment-specific packages, and externalized environment-specific properties, the same build can run in any environment.</li><li>Package it all together. Everything ‚Äì All source, including infrastructure code, should be combined, becoming a versioned package.</li></ul><h3>Pipeline Design Pattern #4: Trigger the Right Pipeline</h3><p><em>B</em><em>ranch</em><em> commits</em><em>, pull requests, and merges to the mainline can</em><em> all trigger different pipeline behavior, </em><em>optimized to</em><em> the team‚Äôs way of working.</em></p><div><figure><img src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.45-PM.png" alt="Trigger the Right Pipeline" width="351" height="262" srcset="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.45-PM.png 1134w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.45-PM-660x492.png 660w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.45-PM-768x573.png 768w" sizes="(max-width: 351px) 100vw, 351px" data-srcset="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.45-PM.png 1134w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.45-PM-660x492.png 660w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.45-PM-768x573.png 768w" data-src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.45-PM.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure></div><p>State of the Art:</p><ul><li>Pushing a commit to an open pull request builds an Ephemeral Environment for testing.</li><li>Merges to the mainline are deployed to a non-production or demo environment displaying the latest integrated code</li><li>Pushing a new tag stages a production release.</li></ul><h3>Pipeline Design Pattern #5: Fast Team Feedback</h3><p><em>Every commit </em><em>automatically</em><em> triggers the right pipeline</em><em>, with build pipelines </em><em>especially </em><em>optimized for speed and quick </em><em>reporting</em><em> of any issues. </em></p><div><figure><img src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.47.38-PM.png" alt="Fast Team Feedback" width="350" height="350" srcset="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.47.38-PM.png 1146w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.47.38-PM-660x660.png 660w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.47.38-PM-768x769.png 768w" sizes="(max-width: 350px) 100vw, 350px" data-srcset="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.47.38-PM.png 1146w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.47.38-PM-660x660.png 660w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.47.38-PM-768x769.png 768w" data-src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.47.38-PM.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure></div><p>State of the Art:</p><ul><li>Build pipelines use parallelization for non-interdependent jobs to increase speed.</li><li>Fast build pipelines only run the jobs that are necessary in a few minutes.</li><li>Each successful run produces a versioned package and static analysis results.</li><li>With omni-channel notifications, you can enable team notifications on pull request status in dashboards, chat channels, email, and other mediums.</li></ul><h3>Pipeline Design Pattern #6: Stable Internal Releases</h3><p><em>Only versioned </em><em>packages </em><em>produced</em><em> by the build pipeline are deployed</em><em> and these deployments are triggered by humans or automated events.</em></p><div><figure><img src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.45.11-PM.png" alt="Stable Internal Releases" width="320" height="250" srcset="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.45.11-PM.png 940w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.45.11-PM-660x514.png 660w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.45.11-PM-768x598.png 768w" sizes="(max-width: 320px) 100vw, 320px" data-srcset="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.45.11-PM.png 940w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.45.11-PM-660x514.png 660w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.45.11-PM-768x598.png 768w" data-src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.45.11-PM.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure></div><p>State of the Art:</p><ul><li>Each code branch gets a complete ephemeral environment named for the branch that can easily be created or destroyed.</li><li>Each engineer can stand up and delete ephemeral environments at any time.</li><li>CI runners use cloud-native IAM capabilities with temporary permissions so they can assume roles and acquire the right permissions to complete their work.</li></ul><h3>Pipeline Design Pattern #7: Buttoned Up Product Releases</h3><p><em>Deploy tagged releases to production and automate the paperwork</em><em> but leave a paper trail. </em></p><p>State of the Art:</p><ul><li>Codified release gates and standardized release processes enables teams to release on demand.</li><li>Automated releases leave a transparent paper trail that‚Äôs auditable for governance and quality</li><li>Release gates can invoke external API‚Äôs and use the responses to decide whether to proceed with the release or halt.</li></ul><figure><img src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.44.56-PM-1300x254.png" alt="Buttoned Up Product Releases" srcset="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.44.56-PM-1300x254.png 1300w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.44.56-PM-660x129.png 660w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.44.56-PM-768x150.png 768w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.44.56-PM-1536x300.png 1536w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.44.56-PM.png 1814w" sizes="(max-width: 1300px) 100vw, 1300px" data-srcset="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.44.56-PM-1300x254.png 1300w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.44.56-PM-660x129.png 660w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.44.56-PM-768x150.png 768w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.44.56-PM-1536x300.png 1536w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.44.56-PM.png 1814w" data-src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.44.56-PM-1300x254.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure><h2><strong>Challenges</strong></h2><p>These are the seven pipeline design patterns we‚Äôre increasingly seeing and using in our client engagements. While these present huge leaps forward in terms of speed and stability, code pipelines are not without their challenges.</p><p>Security is the biggest challenge we see, due to the complexity that comes with automating what has traditionally been human-centric processes. Pipeline complexity, team adoption, modernizing the change-advisory-board-centric culture, and automating databases are the other big challenges to work through. But it‚Äôs possible, we do this every day.</p><h2><strong>Summary</strong></h2><p>Business agility is built on code agility. For modern digital products and services, the ability to release on demand quickly and safely is a real competitive business advantage. Code pipelines, and these seven design patterns in particular, can help your organization make giant leaps forward in speed and stability and have your teams performing at the elite level.</p><p><a href="https://www.singlestoneconsulting.com/careers/" target="_blank" rel="noreferrer noopener">We‚Äôre hiring</a>! Come join our team.</p></div></article><p>Get notified when more posts like ‚Äú<span>7 Pipeline Design Patterns for Continuous Delivery</span>‚Äù are available.</p></div>]]>
            </description>
            <link>https://www.singlestoneconsulting.com/blog/7-pipeline-design-patterns-for-continuous-delivery/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888341</guid>
            <pubDate>Sun, 19 Jul 2020 10:18:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is SRE?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23888328">thread link</a>) | @kiyanwang
<br/>
July 19, 2020 | https://www.firehydrant.io/blog/what-is-sre/ | <a href="https://web.archive.org/web/*/https://www.firehydrant.io/blog/what-is-sre/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Site Reliability Engineering (SRE) is a practice for managing the reliability of systems that began at Google in the early 2000s. Ben Treynor Sloss from Google started the first SRE team and coined the name. As he puts it in the book&nbsp;<a href="https://landing.google.com/sre/sre-book/toc/index.html">Site Reliability Engineering</a>&nbsp;(published by Google), SRE teams are generally responsible for ‚Äúthe availability, latency, performance, efficiency, change management, monitoring, emergency response, and capacity planning of their service(s).‚Äù That‚Äôs a similar list to the responsibilities of many traditional Operations teams.</p><p>SRE was initially a Google innovation, but it‚Äôs now spread much more extensively in the industry, mainly due to Google opening up about the practice and evangelizing it. USENIX launched the first SREcon in 2014, and Google published the Google SRE Book in 2016. As more companies have adopted SRE in their own ways, the meaning of the term has evolved. Every SRE team is different, but many themes will apply to SREs across companies.</p><p>We‚Äôll next a look at the Engineering and Reliability parts of SRE, SRE team structures, and then talk about some ways you can get started as an SRE.</p><h2>Engineering</h2><p>As Ben Treynor Sloss says in the Google SRE book, ‚ÄúSRE is what happens when you ask a software engineer to design an operations team.‚Äù In building the SRE team at Google, he focused on hiring software engineers, as opposed to traditional systems administrators. The idea was to make the SRE team a force multiplier. By automating more of the work they do, the SRE team could manage the rapidly growing systems at Google while scaling the team less.</p><p>Toil is an essential concept in SRE. As Vivek Rau points out&nbsp;<a href="https://landing.google.com/sre/sre-book/chapters/eliminating-toil/">in the Google SRE book</a>, toil isn‚Äôt simply work that the Goole SREs don‚Äôt want to do. He defines some criteria for what kind of work is considered toil:</p><ul><li>Manual</li><li>Repetitive</li><li>Automatable</li><li>Tactical</li><li>No enduring value</li><li>Scales with service growth</li></ul><p>By working to eliminate the tasks we do that are toil, we give ourselves time to focus on more exciting work. Google expects its SREs to spend 50% or more of their time working on engineering projects outside of regular operational work.</p><p>It‚Äôs important to note that the SRE focus on automation didn‚Äôt arise in a vacuum. The early 2000s saw Configuration Management emerge as a practice and Infrastructure as Code. Titles like Operations Engineer and Infrastructure Engineer became more common, as teams realized they could leverage automation to make the tasks they do more repeatable. Tools like Puppet, Chef, Ansible, and later Terraform, have allowed people to provision and maintain large infrastructures through code.</p><p>The level of engineering work that happens in an SRE shop outside of Google can vary pretty widely. In some shops, teams will be mainly focused on using tools like Terraform and Kubernetes that are written by someone else, and using APIs to glue things together. Other shops will have SREs that write a lot of code, and even write services that manage things like provisioning or deployments. Some of those tools become open sourced and shared with large communities.</p><p>SREs at Google contribute code to the services written by Google‚Äôs Sofware Engineers (SWEs). In other shops, there may be a more explicit boundary between who commits code for those services, and SREs may only be able to land code to their SRE team‚Äôs codebases.</p><p>If you‚Äôre looking at potential SRE roles, it‚Äôs important to get an idea of what kind of engineering work the team does and how that fits with your skills and interests.</p><h2>Reliability</h2><p>Reliability is the core job of SREs, and it encompasses many areas (see that list in the first paragraph). We‚Äôll focus here on some key concepts that are unique to SRE: service level indicators, service level objectives, and error budgets.</p><h3>Service Level Indicators (SLIs)</h3><p>Let‚Äôs start with service level indicators. The chapter in the Google SRE book that covers them (written by Chris Jones, John Wilkes, and Niall Murphy with Cody Smith) defines an SLI as ‚Äúa carefully defined quantitative measure of some aspect of the level of service that is provided.‚Äù Said more simply, an SLI is a metric of some sort that indicates something about the performance or health of the service. Some common examples of SLIs are request latency and error rate, but there can be many others depending on your service. It‚Äôs important to note that ‚Äúthe CPU of the host is at 75 percent usage‚Äù is not the kind of thing that makes for a good SLI. We want to look at metrics that describe the health of the service to the people that are using it. An end-user doesn‚Äôt care about your CPU usage. They only care that they can do what they need to with your application in a reasonable amount of time.</p><h3>Service Level Objectives (SLOs)</h3><p>Next are service level objectives (SLOs). The Google SRE book defines an SLO as ‚Äúa target value or range of values for a service level that is measured by an SLI.‚Äù So what does that mean? An SLO is the higher-order measure of the service‚Äôs health and performance from the perspective of the user. When you think about SLOs, think about things that impact users. An example of an SLO from the book is, ‚Äú99% (averaged over 1 minute) of Get RPC calls will complete in less than 100 ms (measured across all the backend servers).‚Äù It‚Äôs very precise. We can infer that if the Get RPC calls fail more than 99% of the time, or complete slower than 100 milliseconds, users will be unhappy. In the end, that‚Äôs what reliability is for, making the people who use our applications happy.</p><h3>Error Budgets</h3><p>Error budgets are the last of these three pillars of reliability. Error budgets are covered in&nbsp;<a href="https://landing.google.com/sre/sre-book/chapters/embracing-risk/">another chapter</a>&nbsp;of the Google SRE book, written by Marc Alvidrez. Alvidrez defines an error budget as ‚Äúa clear, objective metric that determines how unreliable the service is allowed to be within a single quarter.‚Äù SLIs and SLOs bubble up into error budgets, and error budgets are the clear, quantitative measure of how our service is doing reliability wise. Error budgets also give us guard rails for how we operate our services. If your service is well below its error budget for the quarter, that‚Äôs a great time to innovate and take risks. If your service is running out of error budget, that‚Äôs a time to slow down and be more conservative. With an error budget, we have a number that lets us know whether we‚Äôre at risk of making our users unhappy.</p><h3>Alerting</h3><p>SLIs, SLOs, and error budgets represent a huge shift in thinking from how traditional sysadmins looked at systems. One of the biggest things this impacts is what teams send alerts on. I recently&nbsp;<a href="https://www.firehydrant.io/blog/qa-with-alex-hidalgo-on-slos/">interviewed Alex Hidalgo</a>, who is writing a book called&nbsp;<a href="https://www.oreilly.com/library/view/implementing-service-level/9781492076803/">Implementing Service Level Objectives</a>&nbsp;for O‚ÄôReilly, and I asked him about this topic. He said:</p><blockquote><p>‚ÄúIn a perfect world, the only page a team receives is when you‚Äôre burning through your error budget at a rate that you cannot recover from without human intervention. It takes a lot of maturity and time to get there, but I‚Äôve worked on teams where we successfully got to this point. It‚Äôs not impossible! The idea is that if your SLI is meaningfully measuring what your users need from your service, why wake people up in the middle of the night for any reason beyond this SLI reporting things are bad for your users too much of the time? Why wake someone up if error rates have spiked if that doesn‚Äôt actually impact the user experience in any way?‚Äù</p></blockquote><p>So instead of Pager Duty or your NOC calling someone at 3 AM to tell them that a CPU is at 75 percent usage, you alert on situations where you‚Äôre at risk of running out of error budget.</p><p>But what about the lower-level problems? What if a disk is full or a host is down? We want to know about that still, right? Well, we do, but not at 3 AM. Instead, we can create a ticket in our ticketing system to let us know about the problem. If those conditions are impacting users, we‚Äôll get an alert about it indirectly based on the error budget, and we can deal with the problem then. If not, we can clean up that disk or provision a new host during regular working hours.</p><p>As Alex mentioned, it takes some work to get to that point, but it‚Äôs well worth it if you can make it there.</p><h2>Team Structures</h2><p>Every SRE team is different and will have its own structure, but some popular patterns for team structures have emerged. At Google, while SREs belong to a team together, they work embedded on teams that are building services. Another common pattern is to have a core team of SREs that support all of the other teams. Let‚Äôs compare these two options.</p><p>The pattern where SREs are embedded in service teams makes a lot of sense. People who specialize in a specific service or several are likely to gain a lot of expertise and domain knowledge about how those services work. That can be very handy when troubleshooting, or rolling out new versions of the service. But I think there‚Äôs at least the potential that people working in this model end up heads down, focused on the services they support, and not sharing knowledge across the broader SRE team. I‚Äôve also spoken to several Google SREs who supported different kinds of services, and it became clear to me pretty quickly that their experiences differed quite a bit depending on the service team they were embedded with. Some factors that may come into play are the age of the service, and the risk tolerance of the company when it comes to operating that service.</p><p>The core SRE team pattern, where there is a central team of SREs, also has advantages. This team can potentially work closer together and communicate better, but that comes with likely having less expertise in the services, depending on how many services there are. Teams in this pattern often operate more as a higher tier of escalation for problems, and provide infrastructure and tools that the service teams use. A big focus of this kind of team is creating self-service infrastructure. They want to make their infra as easy as possible for other teams to consume. They may manage Kubernetes clusters that all of the service teams run their ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.firehydrant.io/blog/what-is-sre/">https://www.firehydrant.io/blog/what-is-sre/</a></em></p>]]>
            </description>
            <link>https://www.firehydrant.io/blog/what-is-sre/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888328</guid>
            <pubDate>Sun, 19 Jul 2020 10:16:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Gradually Exit Twitter]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 56 (<a href="https://news.ycombinator.com/item?id=23888215">thread link</a>) | @saadalem
<br/>
July 19, 2020 | https://balajis.com/how-to-gradually-exit-twitter/ | <a href="https://web.archive.org/web/*/https://balajis.com/how-to-gradually-exit-twitter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


                <figure>
                    <img srcset="https://balajis.com/content/images/size/w300/2020/07/gradually-exit-twitter.png 300w,
                                https://balajis.com/content/images/size/w600/2020/07/gradually-exit-twitter.png 600w,
                                https://balajis.com/content/images/size/w1200/2020/07/gradually-exit-twitter.png 1000w,
                                https://balajis.com/content/images/size/w2000/2020/07/gradually-exit-twitter.png 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 1170px,
                                2000px" src="https://balajis.com/content/images/size/w2000/2020/07/gradually-exit-twitter.png" alt="How to Gradually Exit Twitter">
                </figure>
                <section>
                    <div>
                        <p>The <a href="https://twitter.com/TwitterSupport/status/1283591848729219073">hacks</a> are the last straw. We need to exit Twitter.</p><p>But you may be invested in Twitter! So what do you do? Here's one recipe for <em>gradual</em> exit.</p><ol><li>Step one is to set up an (optionally pseudonymous) newsletter at your <em>own</em> custom domain using the instructions <a href="https://balajis.com/set-up-a-paid-newsletter-at-your-own-domain/">here</a>. You can do this in an hour and maintain it for less than $30 per month. Then only tweet out posts from your site, using your domain name as a simple form of authentication.</li><li>Step two is to start building your membership list at your own site. If you want, help us review <a href="https://github.com/balajis/twitter-export">open source tools</a> to export your Twitter following to an email list and <a href="https://twitter.com/dwr/status/1284155565770498050">mass delete any DMs</a>.</li><li>And step three is to get off Twitter all together, and start building a decentralized media ecosystem that combines the sovereignty of individual domain names with the community of social networking. The v1 of that is a simple joint RSS feed that aggregates multiple independent newsletters, but we can get much more <a href="https://twitter.com/balajis/status/1280005821028397057">sophisticated</a> <a href="https://dci.mit.edu/decentralizedweb">with</a> <a href="https://hackernoon.com/a-state-of-the-art-of-decentralized-web-part-4-212732f74894">tech</a> <a href="https://gun.eco/docs/dWeb-The-Decentralized-Web">for</a> <a href="https://ens.domains/">the</a> <a href="https://handshake.org/">decentralized</a> <a href="https://ipfs.io/">web</a>. It may turn out that what we build helps reform Twitter itself, but at a minimum it will present an alternative.</li></ol><p>Before we get there though, let's go through the problems with Twitter.</p><h2 id="the-problems-with-twitter">The Problems with Twitter</h2><p>It's not just the hack. There are several overlapping issues with Twitter around security, authentication, pseudonymity, distribution, incentives, and culture.</p><ul><li><em>Twitter is insecure</em>. It was a mistake to think that personal security could compensate for the fundamental flaw of centralized web services: anyone who gains control over twitter.com gains control over your account. We knew this already from the <a href="http://archive.is/Bq5qi">2017 incident</a> and the <a href="http://archive.is/wip/scJMn">Jack Hack</a>. But now the most prominent people and companies in the world (Bezos, Gates, Zuckerberg, Musk, Apple, Uber, among others) have been <a href="https://twitter.com/TwitterSupport/status/1283591848729219073">openly and publicly hacked</a>. Tomorrow you may be the victim. And unlike these worthies, you may be <em>silently</em> and <em>privately</em> hacked. Perhaps you already have been.</li><li><em>Twitter is not authenticated</em>. It was a mistake to trust Twitter's centralized verification process to validate everything posted to the service. There weren't any <a href="https://www.investopedia.com/terms/p/private-key.asp#:~:text=A%20digital%20wallet%20stores%20the,to%20use%20the%20private%20key.">digital signatures</a> to help establish whether the messages were really coming from a user-controlled device, or faked by a central server.</li><li><em>Twitter is not fully pseudonymous</em>. It was a mistake to use our real names everywhere online, particularly on Twitter. It made us vulnerable to personal and physical attacks. Social media mobs can swarm your real name online and cancel you in real life. Doxxing can heighten the danger by making threats <a href="https://blog.lopp.net/reflections-upon-a-swatting/">materialize in</a> <a href="https://github.com/jlopp/physical-bitcoin-attacks/blob/master/README.md">meatspace</a>. Pseudonymity is a better default, especially now that we can <a href="http://www.marknagelberg.com/notes-on-the-pseudonymous-economy-balaji-srinivasan/">earn under a pseudonym</a>.</li><li><em>Twitter is a distribution chokepoint</em>. It was a mistake to outsource our distribution to Twitter. Twitter users don't fully control their reach, brand, or monetization. You can be <a href="https://www.searchenginejournal.com/twitter-reveals-how-it-ranks-tweets-in-search-results/263869/">downranked</a> or <a href="http://archive.is/mhgyB">deplatformed</a> at any time, just like you can on YouTube and other centralized platforms. Owning your <a href="https://support.substack.com/hc/en-us/articles/360037465992-How-do-I-export-my-email-or-subscriber-list-">own</a> <a href="http://locals.com/">email</a> <a href="https://ghost.org/members">list</a> is a far better alternative.</li><li><em>Twitter doesn't create wealth</em>. It was a mistake to have so many people spending so much time on something that <a href="https://twitter.com/paulg/status/1271834488998440961">arguably</a> destroys more wealth than it creates. Because by default, you don't create wealth on Twitter. You may create wealth <em>for</em> Twitter, or for the media corporations whose links are circulated, but not for yourself or for others. There's no sense of economic alignment with other users, no sense of mutual obligation.</li><li><em>Twitter turns society into Twitter</em>. It was a mistake to let Twitter set up the incentives for our society. It's not good for the world when the one thing every prominent person knows how to do is <a href="https://twitter.com/balajis/status/1272653587617701888">fight</a> each other on Twitter for likes and followers. It has converted society into a zero-sum status game played by elites with real consequences. Every day, blue checks compete for a finite pie of attention with ever more sensational posts. There is instant feedback on what is popular, but none on what is true. The lack of economics, the presence of real names, the toxic culture, and the UX itself all encourage constant fighting.</li></ul><p>Now, let me qualify these comments. I personally have gotten <a href="https://twitter.com/paulg/status/1271834488998440961">enormous value</a> out of Twitter, despite all the points above. After all, you only critique the services you use!</p><p>And to be clear, Jack Dorsey is a phenomenal entrepreneur. I respect everything he's done and the team that he's built. It's hard to build one multibillion dollar company, let alone <a href="http://archive.is/wip/bu6hJ">two</a>. He's done immense good for the world overall, both through his <a href="https://twitter.com/jack/status/1247616214769086465">personal generosity</a> and his startup vehicles. And I also don't wish any Twitter employee ill, as many of them are truly great people and I know how hard this stuff is.</p><p>Moreover, even after this hack, Twitter will likely continue to be an important internet battlefield for quite sometime. It's just too easy, too convenient. And it may turn out that whatever is built to exit Twitter will end up interfacing with Twitter itself, via their <a href="https://twitter.com/bluesky">decentralized protocol</a>, if only as a form of training wheels to help people get off. Hopefully this can be done in a win-win way, such that Twitter and its employees are incentivized to allow people to gradually exit and fix the issues on the centralized service.</p><p>But it's past time for us to start building something better, that keeps the good aspects of Twitter (the serendipitous learning, the fascinating <a href="https://twitter.com/balajis/status/1214585024772788224">people</a>) but filters the bad. That may mean exiting to our own domains and then networking them into decentralized media.</p><h2 id="decentralization-starts-with-a-domain">Decentralization Starts with a Domain</h2><figure><img src="https://balajis.com/content/images/2020/07/how-to-gradually-exit-twitter--1-.png" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/how-to-gradually-exit-twitter--1-.png 600w, https://balajis.com/content/images/size/w1000/2020/07/how-to-gradually-exit-twitter--1-.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/how-to-gradually-exit-twitter--1-.png 1600w, https://balajis.com/content/images/2020/07/how-to-gradually-exit-twitter--1-.png 2000w" sizes="(min-width: 720px) 720px"><figcaption>Can we network together websites into decentralized media with something deeper than links?</figcaption></figure><p>I may be wrong about this, but I don't think a "better Twitter" starts with a service which is simply a clone of Twitter except with a different community. I think it starts with a community of independent (and independently monetizable) domains that we network together in novel ways, to build <em>decentralized media</em>.</p><p>Towards this end, the first step in gradually exiting Twitter is to set up your own paid newsletter at a custom domain (<a href="https://balajis.com/set-up-a-paid-newsletter-at-your-own-domain/">instructions here</a>) and restrict yourself mainly to tweeting out posts. This does require more effort than writing 280 characters! But that's why it's good. Effort helps restore your attention span and improves average post quality. And in addition to the other benefits, the link to your domain doubles as a simple alternative to a <a href="https://www.investopedia.com/terms/p/private-key.asp#:~:text=A%20digital%20wallet%20stores%20the,to%20use%20the%20private%20key.">digital signature</a>, a way for people to see that the content is authentically yours. </p><p>The medium-term step is to develop <a href="https://github.com/balajis/twitter-export">tools</a> to migrate your followers off Twitter to an email list, and to mass delete all DMs as a precautionary step. If you want to help review some existing tools towards this end, we're working on it <a href="https://github.com/balajis/twitter-export/issues/1">here</a>.</p><p>The long-term step is to start addressing the issues with Twitter by knitting these individual domains together into an open source decentralized media ecosystem. That means addressing:</p><ul><li>Security by encouraging people to post from their own domains</li><li>Community by building a network around multiple domains</li><li>Authentication by combining domains with digital signatures</li><li>Distribution via memberships and email lists</li><li>Incentives by baking in monetization and economic alignment from the beginning</li><li>Mobs by recommending pseudonymity by default</li><li>Culture by encouraging physical norms of civility</li></ul><p>Crucially, unlike past efforts our goal would be to build this <em>community-first</em> rather than <em>technology-first</em>. Specifically, once we get enough paid newsletters set up at their own domains, we can experiment with new decentralized web technologies for linking them together. If you submit your URL to <a href="https://forms.gle/xqvAFgW43Hc7rVzJA">this form</a>, we'll see if we can form a community. We'll probably start with a joint <a href="https://en.wikipedia.org/wiki/RSS">RSS</a> feed and then <a href="https://hacks.mozilla.org/2018/07/introducing-the-d-web/">get more sophisticated</a>.</p><p>Oh, and you can signal that you're interested in decentralized media by changing your name on Twitter to your URL, as <a href="https://twitter.com/balajis">follows</a>:</p><figure><img src="https://balajis.com/content/images/2020/07/image-5.png" alt=""></figure><p>Exiting Twitter and building decentralized media will be a long project and we aren't assured of success. But this journey of a thousand miles begins with a single newsletter at your own domain! So <a href="https://balajis.com/set-up-a-paid-newsletter-at-your-own-domain/">set yours up</a> now. </p><p>It's time to start gradually exiting Twitter.</p>
                    </div>
                </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://balajis.com/how-to-gradually-exit-twitter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888215</guid>
            <pubDate>Sun, 19 Jul 2020 09:50:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimizing 128-bit Division]]>
            </title>
            <description>
<![CDATA[
Score 135 | Comments 28 (<a href="https://news.ycombinator.com/item?id=23888177">thread link</a>) | @EvgeniyZh
<br/>
July 19, 2020 | https://danlark.org/2020/06/14/128-bit-division/ | <a href="https://web.archive.org/web/*/https://danlark.org/2020/06/14/128-bit-division/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-288">

	

	
	<div>
		
<p>When it comes to hashing, sometimes 64 bit is not enough, for example, because of <a href="https://en.wikipedia.org/wiki/Birthday_problem">birthday paradox</a> ‚Äî the hacker can iterate through random <img src="https://s0.wp.com/latex.php?latex=2%5E%7B32%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{32}" title="2^{32}"> entities and it can be proven that with some constant probability they will find a collision, i.e. two different objects will have the same hash. <img src="https://s0.wp.com/latex.php?latex=2%5E%7B32%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{32}" title="2^{32}"> is around 4 billion objects and with the current power capacity in each computer it is certainly achievable. That‚Äôs why we need sometimes to advance the bitness of hashing to at least 128 bits. Unfortunately, it comes with a cost because platforms and CPUs do not support 128 bit operations natively.</p>



<p>Division historically is the most complex operation on CPUs and all guidelines suggest avoiding the division at all costs.</p>



<p>At my job I faced an interesting problem of optimizing 128 bit division from <a href="https://github.com/abseil/abseil-cpp/blob/master/absl/numeric/int128.cc#L155">abseil library</a> in order to split some data across buckets with the help of 128 bit hashing (the number of buckets is not fixed for some uninteresting historical reasons). I found out that the division takes a really long time. The <a href="https://github.com/abseil/abseil-cpp/blob/master/absl/numeric/int128_benchmark.cc#L52">benchmarks</a> from abseil on Intel(R) Xeon(R) W-2135 CPU @ 3.70GHz show some horrible results</p>



<pre><code>Benchmark                       Time(ns)  CPU(ns)
BM_DivideClass128UniformDivisor     13.8     13.8  // 128 bit by 128 bit
BM_DivideClass128SmallDivisor        168      168  // 128 bit by 64 bit</code></pre>



<p>150 nanoseconds for dividing the random 128 bit number by a random 64 bit number? Sounds crazy. For example, <code>div</code> instruction on x86-64 Skylake takes 76 cycles (also, for AMD processors it is much less), the division takes around 20-22ns.</p>



<figure><img data-attachment-id="361" data-permalink="https://danlark.org/d2elnjfdkne/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png" data-orig-size="921,461" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="d2elnjfdkne" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=921" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png 921w, https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=768 768w" sizes="(max-width: 921px) 100vw, 921px"><figcaption><a href="https://godbolt.org/z/o2vTZr">https://godbolt.org/z/o2vTZr</a></figcaption></figure>



<p>In reality everything is slightly better because of pipeline execution and division has its own ALU, so if you divide something and do something else in the next instructions, you will get lower average latency. Still, 128 bit division cannot be 8x slower than 64 bit division. All latencies you can find in Agner Fog <a href="https://www.agner.org/optimize/instruction_tables.pdf">instruction table</a> for most of the modern x86 CPUs. The truth is more complex and division latency can even depend on the values given.</p>



<figure><img data-attachment-id="299" data-permalink="https://danlark.org/2020-06-14-182043_835x215_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png" data-orig-size="835,215" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-182043_835x215_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=835" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png 835w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=768 768w" sizes="(max-width: 835px) 100vw, 835px"><figcaption>Agner Fog instruction table for Skylake CPUs, the second but last column is the latency.</figcaption></figure>



<p>Even compilers when dividing by some constants, try to use the reciprocal (or, the same as inverse in a ring) value and multiply the reciprocal and the value with some shifts afterwards</p>



<figure><img data-attachment-id="315" data-permalink="https://danlark.org/2020-06-14-192300_861x251_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png" data-orig-size="861,251" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-192300_861x251_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=861" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png 861w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=768 768w" sizes="(max-width: 861px) 100vw, 861px"><figcaption><a href="https://gcc.godbolt.org/z/PRibsx">https://gcc.godbolt.org/z/PRibsx</a></figcaption></figure>



<p>Overall, given the fact that only some <code>sin</code>, <code>cos</code> instructions cost more than division, division is one of the most complex instructions in CPUs and optimizations in that place matter a lot. My exact case was more or less general, maybe I was dividing 128 bit by 64 bit a bit more frequent. We are going to optimize the general case in LLVM.</p>



<p>We need to understand how 128 bit division is working through the compiler stack.</p>



<figure><img data-attachment-id="303" data-permalink="https://danlark.org/2020-06-14-183125_682x238_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png" data-orig-size="682,238" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-183125_682x238_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=682" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=682" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png 682w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=300 300w" sizes="(max-width: 682px) 100vw, 682px"><figcaption><a href="https://gcc.godbolt.org/z/fB3aq2">https://gcc.godbolt.org/z/fB3aq2</a></figcaption></figure>



<p>It calls <code>__udivti3</code> function. Let‚Äôs first understand how to read these functions. In runtime libraries the modes of the functions are:</p>



<div><div>
<pre><code>QI: An integer that is as wide as the smallest addressable unit, usually 8 bits.
HI: An integer, twice as wide as a QI mode integer, usually 16 bits.
SI: An integer, four times as wide as a QI mode integer, usually 32 bits.
DI: An integer, eight times as wide as a QI mode integer, usually 64 bits.
SF: A floating point value, as wide as a SI mode integer, usually 32 bits.
DF: A floating point value, as wide as a DI mode integer, usually 64 bits.
TI: An integer, 16 times as wide as a QI mode integer, usually 128 bits.</code></pre>
</div></div>



<p>So, <code>udivti3</code> is an <strong>u</strong>nsigned division of TI (128 bits) integers, last ‚Äò<em>3‚Ä≤</em> means that it has 3 arguments including the return value. Also, there is a function <code>__udivmodti4</code> which computes the divisor and the remainder (division and modulo operation) and it has 4 arguments including the returning value. These functions are a part of runtime libraries which compilers provide by default. For example, in GCC it is <a href="http://gcc.gnu.org/onlinedocs/gccint/Libgcc.html#Libgcc">libgcc</a>, in LLVM it is <a href="https://compiler-rt.llvm.org/">compiler-rt</a>, they are linked almost in every program if you have the corresponding toolchain. In LLVM, <code>__udivti3</code> is a simple alias to <code>__udivmodti4</code>.</p>



<figure><div>

</div></figure>



<p><code><a href="https://github.com/llvm-mirror/compiler-rt/blob/release_90/lib/builtins/udivmodti4.c#L20">__udivmodti4</a></code> function was written with the help of <code>Translated from Figure 3-40 of The PowerPC Compiler Writer's Guide.</code> After looking at it <a href="https://cr.yp.to/2005-590/powerpc-cwg.pdf">here</a>, it looks like this was written long time ago and things have changed since then</p>



<figure><img data-attachment-id="313" data-permalink="https://danlark.org/2020-06-14-191400_1038x718_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png" data-orig-size="1038,718" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-191400_1038x718_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=1024" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=1024 1024w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=768 768w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png 1038w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>First of all, let‚Äôs come up with something easy, like shift-subtract algorithm that we have been learning since childhood. First, if <code>divisor &gt; dividend</code>, then the quotient is zero and remainder is the <code>dividend</code>, not an interesting case. </p>



<figure><div>

</div></figure>



<p>The algorithm is easy, we align the numbers by their most significant bits, if dividend is more than divisor, subtract and add 1 to the output, then shift by 1 and repeat.  Some sort of animation can be seen like that:</p>



<figure><img data-attachment-id="318" data-permalink="https://danlark.org/simplescreenrecorder-2020-06-14_20-23-25/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/simplescreenrecorder-2020-06-14_20.23.25.gif" data-orig-size="918,442" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="simplescreenrecorder-2020-06-14_20.23.25" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/simplescreenrecorder-2020-06-14_20.23.25.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/simplescreenrecorder-2020-06-14_20.23.25.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/simplescreenrecorder-2020-06-14_20.23.25.gif?w=918" alt=""></figure>



<p>For 128 bit division it will take at most 128 iterations in the for loop. Actually, the implementation in <a href="https://github.com/llvm-mirror/compiler-rt/blob/release_90/lib/builtins/udivmodti4.c#L173">LLVM</a> for loop is a fallback and we saw it takes 150+ns to complete it because it requires to shift many registers because 128 bit numbers are represented as two registers.</p>



<p>Now, let‚Äôs dive into the architecture features. I noticed that while the compiler generates the <code>divq</code> instructions, it frees <code>rdx</code> register</p>



<figure><img data-attachment-id="362" data-permalink="https://danlark.org/2ugj4bgvw4x/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png" data-orig-size="891,206" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2ugj4bgvw4x" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=891" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png 891w, https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=768 768w" sizes="(max-width: 891px) 100vw, 891px"></figure>



<p>In the manual they say the following</p>



<figure><img data-attachment-id="322" data-permalink="https://danlark.org/2020-06-14-204644_860x119_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png" data-orig-size="860,119" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-204644_860x119_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=860" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png 860w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=768 768w" sizes="(max-width: 860px) 100vw, 860px"></figure>



<p><code>divq</code> instruction provides 128 bit division from [%rdx]:[%rax] by <code>S</code>. The quotient is stored in <code>%rax</code> and the remainder in <code>%rdx</code>. After some experimenting with inline asm in C/C++, I figured out that if the result does not fit in 64 bits, SIGFPE is raised. See:</p>



<figure><div>

</div></figure>



<p>Compilers don‚Äôt use this instruction in 128 bit division because they cannot know for sure if the result is going to fit in 64 bits. Yet, if the high 64 bits of the 128 bit number is smaller than the divisor, the result fits into 64 bits and we can use this instruction. As compilers don‚Äôt generate <code>div</code>q instruction for their own reasons, we would use inline asm for x86-64.</p>



<figure><div>

</div></figure>



<p>What to do if the high is not less than the divisor? The right answer is to use 2 divisions because</p>



<figure><img data-attachment-id="325" data-permalink="https://danlark.org/2020-06-11-135245_1608x410_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png" data-orig-size="1608,410" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-11-135245_1608x410_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=1024" alt="" width="780" height="198" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=1024 1024w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=777 777w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=1553 1553w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=768 768w" sizes="(max-width: 780px) 100vw, 780px"></figure>



<p>So, first we can divide <code>hi</code> by <code>divisor</code> and then <code>{hi_r, lo}</code> by <code>divisor</code> guaranteeing that <code>hi_r</code> is smaller than <code>divisor</code> and thus the result is smaller than <img src="https://s0.wp.com/latex.php?latex=2%5E%7B64%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{64}" title="2^{64}">. We will get something like</p>



<figure><div>

</div></figure>



<p>  After that the benchmarks improved significantly</p>



<pre><code>Benchmark                       Time(ns)  CPU(ns)
BM_DivideClass128UniformDivisor 11.9      11.9
BM_DivideClass128SmallDivisor   26.6      26.6</code></pre>



<p>Only 26.6ns for small divisors, that‚Äôs a clear 6x win.</p>



<p>Then there are multiple choices to do next but we know that both dividend and divisor have at least one bit in their high registers and the shift-subtract algorithm will have at most 64 iterations. Also the quotient is guaranteed to fit in 64 bits, thus we can use only the low register of the resulting quotient and save more shifts in the shift-subtract algorithm. That‚Äôs why the uniform divisor slightly improved.</p>



<p>One more optimization to do in shift-subtract algorithm is to remove the branch inside the for loop (read carefully, it should be understandable).</p>



<figure><div>

</div></figure>



<p>In the end, it gives 0.4ns more for uniform 128 bit divisor.</p>



<p>And finally I believe that‚Äôs one of the best algorithm to divide 128 bit by 128 bit numbers. From statistics, the case when the divisor is 64 bit is worth optimizing and we showed that additional checks on the high register of divisor has its own advantages and expansion of the invariants. Now let‚Äôs see what other libraries perform in that case.</p>



<h2>LibDivide</h2>



<p><a href="https://github.com/ridiculousfish/libdivide">Libdivide</a> is a small library targeting fast division, for example, if you divide by some fixed number a lot of times, there are techniques that can precalculate reciprocal and then multiply by it. Libdivide provides a very good interface for such optimizations. Even though, it has some optimizations regarding 128 bit division. For example, function <code>libdivide_128_div_128_to_64</code> computes the division 128 bit number by 128 bit number if the result fits in 64 bits. In the case where both numbers are more or equal to <img src="https://s0.wp.com/latex.php?latex=2%5E%7B64%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{64}" title="2^{64}"> it does the following algorithm that they took from <a href="https://www.amazon.de/Hackers-Delight-Henry-S-Warren/dp/0321842685/ref=sr_1_1?dchild=1&amp;keywords=Hackers+Delight&amp;qid=1592164234&amp;sr=8-1">Hackers Delight</a> book:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Bcases%7D+n+%3D+MSB%28%5Cmathrm%7Bdivisor%7D%29+%5Cgeq+1+%5C%5C+%5Cmathrm%7Bdivisor_1%7D+%3D+%5Clfloor+%5Cmathrm%7Bdivisor%7D%2F2%5E%7B64+-+n%7D+%5Crfloor+%5C%5C+%5Cmathrm%7Bdividend_1%7D+%3D+%5Clfloor+%5Cmathrm%7Bdividend%7D%2F2+%5Crfloor+%5Cend%7Bcases%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\begin{cases} n = MSB(\mathrm{divisor}) \geq 1 \\ \mathrm{divisor_1} = \lfloor \mathrm{divisor}/2^{64 - n} \rfloor \\ \mathrm{dividend_1} = \lfloor \mathrm{dividend}/2 \rfloor \end{cases}" title="\begin{cases} n = MSB(\mathrm{divisor}) \geq 1 \\ \mathrm{divisor_1} = \lfloor \mathrm{divisor}/2^{64 - n} \rfloor \\ \mathrm{dividend_1} = \lfloor \mathrm{dividend}/2 \rfloor \end{cases}"></p>



<p>With the instruction that produces the 64 bit result when the divisor is 128 bit result we can compute</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bquotient_1%7D+%3D+%5Clfloor+%5Cmathrm%7Bdividend_1%7D%2F%5Cmathrm%7Bdivisor_1%7D+%5Crfloor&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{quotient_1} = \lfloor \mathrm{dividend_1}/\mathrm{divisor_1} \rfloor" title="\mathrm{quotient_1} = \lfloor \mathrm{dividend_1}/\mathrm{divisor_1} \rfloor"></p>



<p>Then we compute</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bquotient_0%7D+%3D+%5Clfloor+%5Cmathrm%7Bquotient_1%7D%2F2%5E%7B63+-+n%7D+%5Crfloor&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{quotient_0} = \lfloor \mathrm{quotient_1}/2^{63 - n} \rfloor" title="\mathrm{quotient_0} = \lfloor \mathrm{quotient_1}/2^{63 - n} \rfloor">.</p>



<p>It cannot overflow because <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bquotient_1%7D+%3C+2%5E%7B64%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{quotient_1} < 2^{64}" title="\mathrm{quotient_1} < 2^{64}"> because the maximum value of <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bdividend_1%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{dividend_1}" title="\mathrm{dividend_1}"> is <img src="https://s0.wp.com/latex.php?latex=2%5E%7B127%7D+-+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{127} - 1" title="2^{127} - 1"> and minimum value of <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bdivisor_1%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{divisor_1}" title="\mathrm{divisor_1}"> is <img src="https://s0.wp.com/latex.php?latex=2%5E%7B63%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{63}" title="2^{63}">. Now let‚Äôs show that</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Clfloor+%5Cmathrm%7Bdividend%7D%2F%5Cmathrm%7Bdivisor%7D+%5Crfloor+%5Cleq+%5Cmathrm%7Bquotient_0%7D+%5Cleq++%5Clfloor+%5Cmathrm%7Bdividend%7D%2F%5Cmathrm%7Bdivisor%7D+%5Crfloor+%2B+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\lfloor \mathrm{dividend}/\mathrm{divisor} \rfloor \leq \mathrm{quotient_0} \leq  \lfloor \mathrm{dividend}/\mathrm{divisor} \rfloor + 1" title="\lfloor \mathrm{dividend}/\mathrm{divisor} \rfloor \leq \mathrm{quotient_0} \leq  \lfloor \mathrm{dividend}/\mathrm{divisor} \rfloor + 1"></p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bquotient_0%7D+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B2%5E%7B64+-+n%7D%5Cmathrm%7Bdivisor_1%7D%7D+%5Cright%5Crfloor+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B2%5E%7B64+-+n%7D%5Cleft%5Clfloor%5Cfrac%7B%5Cmathrm%7Bdivisor%7D%7D%7B2%5E%7B64+-+n%7D%7D%5Cright%5Crfloor%7D+%5Cright%5Crfloor+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B%5Cmathrm%7Bdivisor%7D+-+%28%5Cmathrm%7Bdivisor%7D+%5Cmathrm%7B%5C+mod%5C+%7D+2%5E%7B64+-+n%7D%29%7D+%5Cright%5Crfloor+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B%5Cmathrm%7Bdivisor%7D%7D+%2B+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%28%5Cmathrm%7Bdivisor%7D+%5Cmathrm%7B%5C+mod%5C+%7D+2%5E%7B64+-+n%7D%29%29%7D%7B%5Cmathrm%7Bdivisor%7D%28%5Cmathrm%7Bdivisor%7D+-+%28%5Cmathrm%7Bdivisor%7D+%5Cmathrm%7B%5C+mod%5C+%7D+2%5E%7B64+-+n%7D%29%29%7D+%5Cright%5Crfloor+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B%5Cmathrm%7Bdivisor%7D%7D+%2B+%5Cdelta+%5Cright%5Crfloor&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{quotient_0} = \left\lfloor \frac{\mathrm{dividend}}{2^{64 - n}\mathrm{divisor_1}} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{2^{64 - n}\left\lfloor\frac{\mathrm{divisor}}{2^{64 - n}}\right\rfloor} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor} - (\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n})} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor}} + \frac{\mathrm{dividend}(\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n}))}{\mathrm{divisor}(\mathrm{divisor} - (\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n}))} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor}} + \delta \right\rfloor" title="\mathrm{quotient_0} = \left\lfloor \frac{\mathrm{dividend}}{2^{64 - n}\mathrm{divisor_1}} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{2^{64 - n}\left\lfloor\frac{\mathrm{divisor}}{2^{64 - n}}\right\rfloor} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor} - (\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n})} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor}} + \frac{\mathrm{dividend}(\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n}))}{\mathrm{divisor}(\mathrm{divisor} - (\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n}))} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor}} + \delta \right\rfloor">.</p>



<p>Now we want to show that <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3C+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\delta < 1" title="\delta < 1">. <img src="https://s0.wp.com/latex.php?latex=%5Cdelta&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\delta" title="\delta"> is the largest when the remainder in the numerator is as large as possible, it can be up to <img src="https://s0.wp.com/latex.php?latex=2%5E%7B64+-+n%7D+-+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{64 - n} - 1" title="2^{64 - n} - 1">. Because of the definition of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="n" title="n">, <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bdivisor%7D+%5Cgeq+2%5E%7B127+-+n%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{divisor} \geq 2^{127 - n}" title="\mathrm{divisor} \geq 2^{127 - n}">. The smallest value of <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bdivisor%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{divisor}" title="\mathrm{divisor}"> in the denominator is <img src="https://s0.wp.com/latex.php?latex=2%5E%7B127+-+n%7D+%2B+2%5E%7B64+-+n%7D+-+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{127 - n} + 2^{64 - n} - 1" title="2^{127 - n} + 2^{64 - n} - 1">. That‚Äôs why</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Cleq+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%282%5E%7B64+-+n%7D+-+1%29%7D%7B%282%5E%7B127+-+n%7D+%2B+2%5E%7B64+-+n%7D+-+1%292%5E%7B127+-+n+%7D%7D+%3C+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%282%5E%7B64+-+n%7D+-+1%29%7D%7B%282%5E%7B127+-+n+%7D%29%5E2%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\delta \leq \frac{\mathrm{dividend}(2^{64 - n} - 1)}{(2^{127 - n} + 2^{64 - n} - 1)2^{127 - n }} < \frac{\mathrm{dividend}(2^{64 - n} - 1)}{(2^{127 - n })^2}" title="\delta \leq \frac{\mathrm{dividend}(2^{64 - n} - 1)}{(2^{127 - n} + 2^{64 - n} - 1)2^{127 - n }} < \frac{\mathrm{dividend}(2^{64 - n} - 1)}{(2^{127 - n })^2}">. As n iterates from 0 to 63, we can conclude that <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3C+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B2%5E%7B128%7D%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\delta < \frac{\mathrm{dividend}}{2^{128}}" title="\delta < \frac{\mathrm{dividend}}{2^{128}}">. So we got either the correct value, either the correct plus one. Everything else in the algorithms is just a correction of which result to choose.</p>



<p>Unfortunately, these corrections increase the latency of the benchmark pretty significant</p>



<pre><code>Benchmark                                          Time(ns)  CPU(ns)
BM_DivideClass128UniformDivisor&lt;LibDivideDivision&gt;    26.3    26.3  
BM_RemainderClass128UniformDivisor&lt;LibDivideDivision&gt; 26.2    26.2
BM_DivideClass128SmallDivisor&lt;LibDivideDivision&gt;      25.8    25.8
BM_RemainderClass128SmallDivisor&lt;LibDivideDivision&gt;   26.3    26.3</code></pre>



<p>So I decided to drop this idea after I‚Äôve tried this.</p>



<h2>GMP</h2>



<p><a href="https://gmplib.org/">GMP</a> library is a standard GNU library for long arithmetic. They also have something for 128 bit by 64 bit division and in my benchmark the following code worked</p>



<figure><div>

</div></figure>



<p>It divides the two limbs by a <code>uint64_t</code> and provides the result. Unfortunately, the latency is much higher than expected, also does not work</p>



<pre><code>Benchmark                                          Time(ns)  CPU(ns)
BM_DivideClass128UniformDivisor&lt;GmpDivision&gt;          11.5    11.5
BM_RemainderClass128UniformDivisor&lt;GmpDivision&gt;       10.7    10.7
BM_DivideClass128SmallDivisor&lt;GmpDivision&gt;            47.5    47.5
BM_RemainderClass128SmallDivisor&lt;GmpDivision&gt;         47.8    47.8 </code></pre>



<h2>Conclusion</h2>



<p>In the ‚Ä¶</p></div></article></main></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://danlark.org/2020/06/14/128-bit-division/">https://danlark.org/2020/06/14/128-bit-division/</a></em></p>]]>
            </description>
            <link>https://danlark.org/2020/06/14/128-bit-division/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888177</guid>
            <pubDate>Sun, 19 Jul 2020 09:40:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CloudFront Analytics]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23888170">thread link</a>) | @kayza
<br/>
July 19, 2020 | https://markmcgranaghan.com/cloudfront-analytics | <a href="https://web.archive.org/web/*/https://markmcgranaghan.com/cloudfront-analytics">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">





<p>2019-10</p>

<p>You‚Äôre reading a <a href="https://brandur.org/aws-intrinsic-static">static website</a> stored in S3 and served out of CloudFront. I recently set up web analytics for it with:</p>

<ul>
<li>CloudFront access logs stored in S3</li>
<li>The <a href="https://aws.amazon.com/athena/">AWS Athena</a> analytics engine running SQL queries on that data</li>
</ul>

<p>I now get analytics with flexible SQL queries:</p>

<p><img src="https://markmcgranaghan.com/assets/cloudfront-analytics/athena-demo.png" alt="Athena demo"></p><p>This proved a solid approach. There‚Äôs no software I need to manage, no client-side JavaScript, and no third-party providers beyond AWS. Here‚Äôs how I set it up and use it.</p>

<h2>Sending CloudFront logs to S3</h2>

<p>First we need to store CloudFront access logs in S3. As a bonus, we‚Äôll have this raw data if we want to analyze it outside of Athena later.</p><p>Ensure you have an S3 bucket to use for logs. I use one bucket for all my sites, with a directory for each site:</p>

<p><img src="https://markmcgranaghan.com/assets/cloudfront-analytics/cloudfront-logs-index.png" alt="CloudFront logs index"></p><p>Then in the CloudFront distribution for your site, enable access logging into that bucket (and into the appropriate directory if you‚Äôre using that setup):</p>

<p><img src="https://markmcgranaghan.com/assets/cloudfront-analytics/cloudfront-logs-enabling.png" alt="CloudFront logs enabling"></p><p>Cloudfront will deposit access logs in that directory every few minutes, assuming you have non-zero traffic. Here‚Äôs what mine look like:</p>

<p><img src="https://markmcgranaghan.com/assets/cloudfront-analytics/cloudfront-logs-listing.png" alt="CloudFront logs listing"></p><p>If you download, decompress, and view one of those files, you‚Äôll see lines of tab-seperated data, one per request to CloudFront. Each line will have the request URL, HTTP method, referrer, and so on.</p>

<p>The appeal of the Athena approach is that you can run SQL queries <em>directly against these compressed log files</em> in S3 with <em>standard SQL</em>. Let‚Äôs look at that next.</p>


<h2>Querying web access logs in Athena</h2>

<p>Now head over to Athena in the AWS console and create a database to use for your CloudFront analytics. I called mine ‚Äúcloudfront‚Äù:</p>

<p><img src="https://markmcgranaghan.com/assets/cloudfront-analytics/athena-database-ddl.png" alt="Athena database DDL"></p><p>Create a table that points to your data in S3, using <a href="https://docs.aws.amazon.com/athena/latest/ug/cloudfront-logs.html">this query template</a>, with your S3 location sub‚Äôd in. This query also shows the fields you‚Äôll have access to in your SQL queries:</p>

<p><img src="https://markmcgranaghan.com/assets/cloudfront-analytics/athena-table-ddl.png" alt="Athena table DDL"></p><p>That‚Äôs it, you‚Äôre ready to run some queries. Here‚Äôs one I use to measure total monthly traffic to the site:</p>

<p><img src="https://markmcgranaghan.com/assets/cloudfront-analytics/athena-results.png" alt="Athena results"></p><p>Note that even though this query covers data from thousands of individual compressed files in S3, it runs in a few seconds.</p>

<p>You should carefully examine your data to be sure you‚Äôre getting the right results. For example some requests are from <a href="https://support.google.com/webmasters/answer/182072?hl=en">Googlebot</a> and you may want to exclude those from your queries.</p>

<p>Overall I‚Äôve been very happy with this analytics setup. I recommend it for anyone running a static site looking for basic analytics without the downsides of client-side JavaScript, additional third parties providers, or more software to run themselves.</p>

<p>If you have thoughts on the setup, <a href="https://markmcgranaghan.com/contact">send</a> them over!</p>



</div></div>]]>
            </description>
            <link>https://markmcgranaghan.com/cloudfront-analytics</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888170</guid>
            <pubDate>Sun, 19 Jul 2020 09:38:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Binary Strobe with Raku and Perl]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23888018">thread link</a>) | @lizmat
<br/>
July 19, 2020 | https://raku-musings.com/binary-strobe.html | <a href="https://web.archive.org/web/*/https://raku-musings.com/binary-strobe.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
         
<p><em>[83] Published 18. July 2020.</em></p><p>
  This is my response to the
  <a href="https://perlweeklychallenge.org/blog/perl-weekly-challenge-069/">
  Perl Weekly Challenge #069</a>.
</p>


<h2>Challenge #069.1: Strobogrammatic Number</h2>
<div><p>
  A strobogrammatic number is a number that looks the same when looked at upside down.
  </p><p>
  
  
  You are given two positive numbers <code>$A</code> and <code>$B</code> such that
  <code>1 &lt;= $A &lt;= $B &lt;= 10^15</code>.
  </p><p>
  

  Write a script to print all strobogrammatic numbers between the given two numbers.
  </p><p>
  

  <b>Example</b><br>

<code><pre>Input: $A = 50, $B = 100
Output: 69, 88, 96
</pre></code></p></div>


<p>
  <i></i> Consulting
  <a href="https://en.wikipedia.org/wiki/Strobogrammatic_number">Wikipedia</a>
  is illuminating. It confirms that the challenge got it wrong; we do not turn
  the number upside down, but rotate it 180 degrees. The digits are:
  <code>0</code>, <code>1</code> and <code>8</code> (symmetrical) and
  <code>6</code> and <code>9</code> (asymmetrical).
</p>

<p>
  <i></i> The wikipedia article also mentions
  <code>2</code> and <code>5</code> (asymmetrical) under the label
  <em>Nonstandard systems</em>. They should be familiar to users of calculators
  with dot matrix displays. The number <code>52</code> is a Strobogrammatic Number
  if we include <code>2</code> and <code>5</code>. It is not present in the
  challenge, so should not be part of this solution. But it is easy to do so,
  and I have added a command line option to enable them.
</p><p>

File: strobonum
<code><pre>#! /usr/bin/env raku

unit sub MAIN (Int $A where $A &gt;= 1,                             # [1]
               Int $B where $B &gt;= $A &amp;&amp; $B &lt;= 10 ** 15,          # [2]
	       :$calculator,                                     # [3]
	       :$v, :$verbose = $v);                             # [4]

my %strobo = $calculator                                         # [5]
  ?? ( 0 =&gt; 0, 1 =&gt; 1, 2 =&gt; 5, 5 =&gt; 2, 6 =&gt; 9, 8 =&gt; 8, 9 =&gt; 6 )  # [5a]
  !! ( 0 =&gt; 0, 1 =&gt; 1, 6 =&gt; 9, 8 =&gt; 8, 9 =&gt; 6 );                 # [5b]

sub is-strobogrammatic (Int $number)                             # [10]
{
  return False unless all($number.comb) eq any(%strobo.keys);    # [11]

  my $strobo = $number.flip.comb.map({ %strobo{$_} }).join;      # [12]
      
  say ": $number -&gt; $strobo" if $verbose;
  
  return $strobo eq $number;                                     # [13]
}

my @strobo;                                                      # [6]

for $A .. $B -&gt; $candidate                                       # [7]
{
  @strobo.push: $candidate if $candidate.&amp;is-strobogrammatic;    # [8]
}

say @strobo.join(", ");                                          # [9]
</pre></code></p><p>[1] The first value, with the lower limit.</p>
<p>[2] <a id="**"></a> The second value, with the first value as lower limit, and
  the higher limit.</p>
<p>[3] Calculator mode (2 and 5).</p>
<p>[4] Note the shortcut ¬´--v¬ª for ¬´--verbose¬ª.</p>
<p>[5] Legal stroboogrammatic digits and how to translate them (rotated 180 degrees).
  In normal mode, allow 0, 1, 6, 8 and 9 only [5b]. In calcular mode, use 2 and 5 as
  well [5a].</p>
<p>[6] We collect the strobo(<small>grammatic</small> values here.</p>
<p>[7] Iterate over the values given by the input limits.</p>
<p>[8] <a id=".&amp;"></a>‚Ä¢ add it to the list if it is strobo&gt;grammatic. Note the
  syntax, allowing us to call a regular procedure as a method. (It really just is a
  fancy procedure calling syntax.)</p>
<p>[9] Print the reslut, if any.</p>
<p>[10] Is the number strobogrammatic?</p>
<p>[11] <a id="all"></a>
        <a id="any"></a>‚Ä¢ no, if it contains anything besides the legal digits.</p>
<p>[12] <a id="flip"></a>
  <a id="reverse"></a>Flip the number and replace the strobogrammatic digits.
  (<code>flip</code> works on strings, whereas <code>reverse</code> works on list like
  structuress.)</p>
<p>[13] The number is strobogrammatic if the new one is the same as the original number.</p>

<p>
  <i></i> See
  <a href="https://docs.raku.org/routine/**">docs.raku.org/routine/**</a> for more
  information about the <em>exponentiation operator</em> <code>**</code>.
</p>

<p>
  <i></i> See
  <a href="https://docs.raku.org/language/operators#methodop_.&amp;">docs.raku.org/language/operators#methodop_.&amp;</a>
  for more information about the special procedure invocation syntax <code>.&amp;</code>.
</p>

<p>
  <i></i> See
  <a href="https://docs.raku.org/routine/all">docs.raku.org/routine/all</a> for
  more information about <code>all</code>,
  <a href="https://docs.raku.org/routine/all">docs.raku.org/routine/any</a> for
  more information about <code>any</code> and 
  <a href="https://docs.raku.org/type/Junction">docs.raku.org/type/Junction</a> for
  more information about Junctions.
</p>

<p>
  <i></i> See
  <a href="https://docs.raku.org/routine/flip">docs.raku.org/routine/flip</a> for
  more information about the <em>string reversing operator</em> <code>flip</code>.
</p>

 
<p>
  <i></i> See
  <a href="https://docs.raku.org/routine/reverse">docs.raku.org/routine/reverse</a>
  for more information about the <em>general reversing operator</em>
  <code>reverse</code>.
</p>


<p>
  Running it:
</p>

<p><code><pre>$ ./strobonum 50 100
69, 88, 96

$ ./strobonum --calculator 50 100
52, 69, 88, 96
</pre></code></p><p>
  We can make it more compact. The lines marked [6] to [9] can be replaced with a
  single line:
</p><p>

File: strobonum-grep (changes only)
<code><pre>say ($A .. $B).grep( *.&amp;is-strobogrammatic ).join(", ");
</pre></code></p><h3>A Perl Version</h3><p>
  This is pretty much a straight forward translation from the Raku version:
</p><p>

File: strobonum-perl
<code><pre>#! /usr/bin/env perl

use strict;                                        # [1]
use warnings;                                      # [1]
use feature 'say';                                 # [1]
use feature 'signatures';                          # [1]

no warnings "experimental::signatures";            # [1]

my $verbose; 
my $calculator;

while (@ARGV &amp;&amp; substr($ARGV[0],0,2) eq "--")      # [2]
{
  my $arg = shift(@ARGV);
  if    ($arg eq "--calculator") { $calculator++ }
  elsif ($arg eq "--verbose"   ) { $verbose++    }
}

my $A = shift(@ARGV) // die 'Please specify $A and $B';
my $B = shift(@ARGV) // die 'Please specify $A and $B';

die "$A: Not a positive integer" unless $A =~ /^\d+$/;
die "$B: Not a positive integer" unless $B =~ /^\d+$/;

die "$A: Out of range" unless $A &gt;= 1  &amp;&amp; $A &lt;= 10 ** 15;
die "$B: Out of range" unless $B &gt;= $A &amp;&amp; $B &lt;= 10 ** 15;

my %strobo = $calculator
  ? ( 0 =&gt; 0, 1 =&gt; 1, 2 =&gt; 5, 5 =&gt; 2, 6 =&gt; 9, 8 =&gt; 8, 9 =&gt; 6 )
  : ( 0 =&gt; 0, 1 =&gt; 1, 6 =&gt; 9, 8 =&gt; 8, 9 =&gt; 6 );

sub is_strobogrammatic ($number)
{
  my $strobo = join("", map { $strobo{$_} // return 0 }
   	                split("", reverse($number)) );    # [3]

  say ": $number -&gt; $strobo" if $verbose;

  return $strobo eq $number;
}

say join(", ", grep { is_strobogrammatic($_) } ($A .. $B));
</pre></code></p><p>[1] A future (and just announced)
  <a href="https://www.perl.com/article/announcing-perl-7/">Perl 7</a> can make
  all of these lines disappear. The backwards compatibility in Perl 5 is in general
  a good idea, but this is the price we pay. For now..</p>
<p>[2] Handling the arguments takes a lot of code, compared to the Raku version
  with one line of code (shown with newlines to make it easier to read). I could
  have used a module, but there are so many to choose from.</p>
<p>[3] I replaced the <code>all</code> and <code>any</code> junctions in The Raku
  version with a simple <code>return</code> inside the <code>map</code>. (The
  ¬´List::Util¬ª module supplies them, so it is possible to use them in Perl.) The
  result is a very compact line of code, that is hard to understand. </p>

<h3>A Perl and Raku Comparison</h3><p>
  The last line in the program really shows off the advantage of Raku over Perl
  in producing readable code:
</p><p>

Raku:
<code><pre>say ($A .. $B).grep( *.&amp;is-strobogrammatic ).join(", ");
</pre></code>

Perl:
<code><pre>say join(", ", grep { is_strobogrammatic($_) } ($A .. $B));
</pre></code></p><p>
  The Perl version is harder to comprehend.
</p>


<h2>Challenge #069.2: 0/1 String</h2>
<div><p>
  A <code>0/1 string</code> is a string in which every character is either 0 or 1.
  </p><p>
  

  Write a script to perform switch and reverse to generate <code>S30</code> as
  described below:
  </p><p>
  
  
  <b>switch:</b><br>
  Every <code>S0</code> becomes <code>S1</code> and every <code>S1</code> becomes
  <code>S0</code>. For example, <code>101</code> becomes <code>010</code>.

  <b>reverse:</b><br>
  The string is reversed. For example, <code>001</code> becomes <code>100</code>.
  </p><p>
  

  <b>UPDATE (2020-07-13 17:00:00):</b>
  It was brought to my notice that generating <code>S1000</code> string would be
  nearly impossible. So I have decided to lower it down to <code>S30</code>.
  </p><p>
  

  Please follow the rule as below:
<code><pre>S0 = ‚Äú‚Äù
S1 = ‚Äú0‚Äù
S2 = ‚Äú001‚Äù
S3 = ‚Äú0010011‚Äù
‚Ä¶
SN = SN-1 + ‚Äú0‚Äù + switch(reverse(SN-1))
</pre></code></p></div>

<p>
  <a id="gather/take"></a> We can use <code>gather</code>/<code>take</code> to set up
  a sequence of values:
</p><p>

File: 01-string
<code><pre>#! /usr/bin/env raku

unit sub MAIN ($limit = 30);

sub switch ($string)
{
  return $string.comb.map({ $_ eq "1" ?? 0 !! 1 }).join;
}

my $string01 := gather
{
  take "";
  my $prev = "0"; take "0";

  loop
  {
    $prev = $prev ~ "0" ~ switch($prev.flip);
    take $prev;
  }
}

say "S$_ = \"{ $string01[$_] }\"" for 0..$limit;
</pre></code></p><p>
  <i></i> See my <a href="https://raku-musings.com/gather-take.html">Raku Gather,
  I Take</a> article or <a href="https://docs.raku.org/syntax/gather%20take">
  docs.raku.org/syntax/gather take</a> for more information about
  <code>gather</code>/<code>take</code>.
</p>

<p>
  Running it:
</p>

<p><code><pre>$ ./01-string 4
S0 = ""
S1 = "0"
S2 = "001"
S3 = "0010011"
S4 = "001001100011011"
</pre></code></p><p>
  <i></i> Running the program to 30 caused my
  pc to crash, but I'll get back to that later.
</p>

<p>
  We can make the program shorter by optimizing the <code>gather</code>/<code>take</code>
  block:
</p><p>

File: 01-string-smart (partial)
<code><pre>my $string01 := gather
{
  my $prev = "";

  loop
  {
    take $prev;
    $prev = $prev ~ "0" ~ switch($prev.flip);
  }
}
</pre></code></p><p>
  Running it:
</p>

<p><code><pre>$ ./01-string-smart 5
S0 = ""
S1 = "0"
S2 = "001"
S3 = "0010011"
S4 = "001001100011011"
S5 = "0010011000110110001001110011011"
</pre></code></p><h3>A Perl Version</h3><p>
  Perl does not have <code>gather</code>/<code>take</code>, but a loop works fine:
</p><p>

File: 01-string-perl
<code><pre>#! /usr/bin/env perl

use strict;
use warnings;
use feature 'say';
use feature 'signatures';

no warnings "experimental::signatures";

my $limit = $ARGV[0] // 30;

sub switch ($string)
{
  return join("", map { $_ eq "1" ? 0 : 1 } split("", $string));
}

my  $prev = "";
for my $counter (0 .. $limit)
{
  say "S" . $counter++ . " = \"$prev\"";
  $prev = $prev . "0" . switch(reverse($prev));
}
</pre></code></p><p>
  Running it:
</p>

<p><code><pre>$ ./01-string-perl 6
S0 = ""
S1 = "0"
S2 = "001"
S3 = "0010110"
S4 = "001011001101001"
S5 = "0010110011010010110100110010110"
S6 = "001011001101001011010011001011001101001100101101001011001101001"
</pre></code></p><h3>Some Thoughts</h3><p>
  Running it to 30 crashes my pc again. Here are the values that worked out,
  with the time usage. The Raku numbers are for ¬´01-string-smart¬ª.
</p>

<table>
  <tbody><tr><td><b>Value</b> &nbsp; </td><td><b>Raku</b> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td><td><b>Perl</b></td></tr>
  <tr><td> 1</td><td>0.156 sec</td><td>0.009 sec</td></tr>
  <tr><td> 2</td><td>0.156 sec</td><td>0.009 sec</td></tr>
  <tr><td> 5</td><td>0.156 sec</td><td>0.009 sec</td></tr>
  <tr><td>10</td><td>0.160 sec</td><td>0.010 sec</td></tr>
  <tr><td>15</td><td>0.213 sec</td><td>0.035 sec</td></tr>
  <tr><td>20</td><td>1.038 sec</td><td>0.677 sec</td></tr>
  <tr><td>22</td><td>    4 sec</td><td>    3 sec</td></tr>
  <tr><td>24</td><td>   14 sec</td><td>   12 sec</td></tr>
  <tr><td>26</td><td> 1m 6 sec</td><td>   47 sec</td></tr>
  <tr><td>27</td><td> 2m      </td><td>1m 34 sec</td></tr>
</tbody></table>

<p>
  The values are not that important in themselves, but the exponenential trend certainly is.
</p>

<p>
  We can have a go at <em>why</em>.
</p>

<p><code><pre>&gt; my $s := (0, 1, -&gt; $a { ($a +1) * 2 } ... Inf);
&gt; say "$_: $s[$_]" for ^31;
0: 0
1: 1
2: 4
3: 10
4: 22
5: 46
6: 94
7: 190
8: 382
9: 766
10: 1534
11: 3070
12: 6142
13: 12286
14: 24574
15: 49150
16: 98302
17: 196606
18: 393214
19: 786430
20: 1572862
21: 3145726
22: 6291454
23: 12582910
24: 25165822
25: 50331646
26: 100663294
27: 201326590
28: 402653182
29: ‚Ä¶</pre></code></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://raku-musings.com/binary-strobe.html">https://raku-musings.com/binary-strobe.html</a></em></p>]]>
            </description>
            <link>https://raku-musings.com/binary-strobe.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888018</guid>
            <pubDate>Sun, 19 Jul 2020 09:01:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The misconceptions about a programmer‚Äôs life]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23887809">thread link</a>) | @URfejk
<br/>
July 19, 2020 | https://expertain.net/the-misconceptions-about-a-programmers-life/ | <a href="https://web.archive.org/web/*/https://expertain.net/the-misconceptions-about-a-programmers-life/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>There are a lot of articles from beginner programmers wondering what programming is like, and I think it‚Äôs useful to address those issues. There are a lot of misconceptions about a programmer‚Äôs life.</p>
<p>The summary of most of this is that understanding the concept of technical debt is important.</p>
<p>The needs and culture of a company are probably larger contributors to technical debt than individual developer skills. But it all plays an important role in how much the system smells, how much documentation is missing, and what a given developer does in their day-to-day. By understanding the concept one can attempt to mitigate it. But some people may be programming for 8 hours a day, not documenting a thing, and unknowingly increasing the maintenance costs of the system for everyone who will ever work on the system.</p>
<p>These are the most common misconceptions about a programmer‚Äôs life:</p>
<ol>
<li>You program 8 hours a day at work</li>
<li>A program is about programming</li>
<li>Since I wrote the code, my opinion matters most</li>
<li>The program matters</li>
<li>Every software shop is the same</li>
<li>We‚Äôll rewrite everything</li>
<li>I only have to understand one programming language</li>
</ol>
<h4><strong>You program 8 hours a day at work</strong></h4>
<p>This is probably the least true of all the things. Most programming jobs are maintenance jobs. The programs have all mostly been written years ago, and you are doing support, minor enhancements, bug fixes. Even if you get to do more than that, you are still not likely coding a large part of your day. It‚Äôs about meetings to decide what to do. This is probably one of the most common misconceptions about a programmer‚Äôs life.</p>
<p>Also, from my experience, unless you have some reason to dig deep into code (esp. if the code base is large), most people don‚Äôt bother. Our codebase is old and rickety. There aren‚Äôt any comments. The business process isn‚Äôt exactly documented. I don‚Äôt want to wade through 2000 lines of Java code (per Java file) and try to understand the business behind it.</p>
<p>Unless you‚Äôre working in a brand new project that needs a lot of code written (which I‚Äôve been in), you are probably not doing a lot of programming.</p>
<div id="attachment_2721"><p><img aria-describedby="caption-attachment-2721" src="https://expertain.net/wp-content/uploads/2020/07/Students-enjoy-computer-science-and-arts-the-most.png" alt="Students enjoy computer science and arts the most!" width="2000" height="1125" srcset="https://expertain.net/wp-content/uploads/2020/07/Students-enjoy-computer-science-and-arts-the-most.png 2000w, https://expertain.net/wp-content/uploads/2020/07/Students-enjoy-computer-science-and-arts-the-most-300x169.png 300w, https://expertain.net/wp-content/uploads/2020/07/Students-enjoy-computer-science-and-arts-the-most-1024x576.png 1024w, https://expertain.net/wp-content/uploads/2020/07/Students-enjoy-computer-science-and-arts-the-most-768x432.png 768w, https://expertain.net/wp-content/uploads/2020/07/Students-enjoy-computer-science-and-arts-the-most-1536x864.png 1536w, https://expertain.net/wp-content/uploads/2020/07/Students-enjoy-computer-science-and-arts-the-most-260x146.png 260w, https://expertain.net/wp-content/uploads/2020/07/Students-enjoy-computer-science-and-arts-the-most-50x28.png 50w, https://expertain.net/wp-content/uploads/2020/07/Students-enjoy-computer-science-and-arts-the-most-133x75.png 133w, https://expertain.net/wp-content/uploads/2020/07/Students-enjoy-computer-science-and-arts-the-most-853x480.png 853w" sizes="(max-width: 2000px) 100vw, 2000px"></p><p id="caption-attachment-2721">Students enjoy computer science and arts the most!</p></div>
<h4><strong>A program is about programming</strong></h4>
<p>I work at a university. Students, esp. computer science students, complain about our old system that runs a ‚Äúbatch style‚Äù programming system. That is, the system shuts down overnight, does a bunch of data processing, and opens again in the morning. They wonder why the system can‚Äôt be Facebook or Google or YouTube and be up 24 hours a day.</p>
<p>First, I think many such people would be surprised how many people (or really, how few people) are supporting these systems. You‚Äôd think there‚Äôs a team of 20 developers doing the best they can to keep this stuff running, and it‚Äôs like a well-oiled machine, but sometimes it‚Äôs less than half a dozen people, and we barely know the software‚Äôs purpose, but can do minor fixes and keep stuff running.</p>
<p>Most software out there isn‚Äôt, as they say, rocket science. Sure, a few exceptions (say, SpaceX software). Most of the software encodes business practices, and most business practices are a weird arcane set of rules that have no basis in math or science but is just how some company works. You write that in code, no matter how illogical it is. And often, the code and a few old-timers‚Äô memories are what holds the project together.</p>
<p>Definitely one of the most common misconceptions about a programmer‚Äôs life.</p>
<h4><a href="https://expertain.net/what-it-was-like-learning-programming-in-the-early-1970s/">You might also like: What it was like learning programming in the early 1970s.</a></h4>
<h5>Programmers had one purpose: get the program to work.</h5>
<p>Comments? Hah! A written business process? Hah! Programmers had one purpose: get the program to work. They didn‚Äôt think about who would maintain the code after they retired. The only saving grace was their background wasn‚Äôt so sophisticated as to create true spaghetti code (let‚Äôs use regular expressions and finite state machines and design patterns up the wazoo!).</p>
<p>It‚Äôs often not the coding language (like Cobol) that prevents modernization (although it‚Äôs partly that), it‚Äôs that the business process was never formalized, and there are 100,000 lines of code no one wants to read (and only represents an&nbsp;<em>approximation</em>&nbsp;of what the people who wanted the code wanted‚Äîand they‚Äôre retired too!).</p>
<p>I often point out the scene in the third Matrix movie where the councilman is talking to Neo about how these machines support their underground city, yet no one quite knows who built it or how it works. That‚Äôs a lot of software out there.</p>
<div id="attachment_2735"><p><img aria-describedby="caption-attachment-2735" src="https://expertain.net/wp-content/uploads/2020/07/Most-wanted-programming-languages-in-2020.jpeg" alt="Most wanted programming languages in 2020" width="729" height="635" srcset="https://expertain.net/wp-content/uploads/2020/07/Most-wanted-programming-languages-in-2020.jpeg 729w, https://expertain.net/wp-content/uploads/2020/07/Most-wanted-programming-languages-in-2020-300x261.jpeg 300w, https://expertain.net/wp-content/uploads/2020/07/Most-wanted-programming-languages-in-2020-168x146.jpeg 168w, https://expertain.net/wp-content/uploads/2020/07/Most-wanted-programming-languages-in-2020-50x44.jpeg 50w, https://expertain.net/wp-content/uploads/2020/07/Most-wanted-programming-languages-in-2020-86x75.jpeg 86w, https://expertain.net/wp-content/uploads/2020/07/Most-wanted-programming-languages-in-2020-551x480.jpeg 551w" sizes="(max-width: 729px) 100vw, 729px"></p><p id="caption-attachment-2735">Most wanted programming languages in 2020</p></div>
<p>Writing from scratch is not such a common experience (at least, from my perspective), and even when you do, it‚Äôs not always as organized as it could be. We may call it software engineering, but most engineering involves others looking at your work, and having input into fixing it. Code reviews aren‚Äôt the same thing as people inspecting a building and seeing it every day.</p>
<p>We often don‚Äôt rewrite things because the rewrite would be huge, would require a bunch of new developers, and doesn‚Äôt even have the support of the people we‚Äôre writing it for.</p>
<h4><strong>As a programmer, since I wrote the code, my opinion is the most important</strong></h4>
<p>OK, so you may&nbsp;<em>know</em> to program, but do you know the business you‚Äôre working in? Many a programmer or startup guy thinks ‚ÄúYou guys do something dumb, and I‚Äôm smart, so I can easily create a system that‚Äôs 10 times better than the crap you use. And you know what? I‚Äôm not even going to consult you about how the system&nbsp;<em>should</em>&nbsp;work. I‚Äôll make up my own. You are such&nbsp;<em>idiots</em>!‚Äù.</p>
<p>Well, that maybe, but they‚Äôre used to the system they are used to, and they‚Äôve thought about their own (arcane) business process for a long time, and if you build something that is completely different from what they are used to, they won‚Äôt say ‚Äúoh, we lack the intellect to understand your truly great software‚Äù, they‚Äôll just not use your software.</p>
<p>If your user base is a bit older, and possibly, even if they aren‚Äôt, they will be used to doing things in a certain way. Maybe you can convince them that way isn‚Äôt smart, but if they questioned your lack of comments, your lack of coding structure, how what you wrote seems like gibberish, you might get defensive as well. This is also one of the most common misconceptions about a programmer‚Äôs life.</p>
<p>The point is that you‚Äôre often writing software or maintaining software by those who use the software every day. As a programmer, you might even have the luxury to walk away after you write code, never having used the code as your users use them, and they may ultimately hire someone new who maybe pays attention to what they actually want, even if you think it makes no sense.</p>
<h4><strong>The program matters</strong></h4>
<p>Many of you are learning to program. You think companies are willing to throw out a million line codebase because it‚Äôs&nbsp;<em>written in an obsolete language</em>. Who‚Äôs going to write it? You? (You, Mr. Wineburg?)</p>
<p>A million lines of code is something that could take a lifetime to rewrite. Do you plan to read the code to understand what it does? Could you even do that?</p>
<p>In any case, sometimes people think the program is king (or queen, or some elected position). It‚Äôs not.</p>
<p>It‚Äôs the data.</p>
<p>Say you‚Äôve run this legacy program for more than a decade. It fills up tables and tables of data. You, being a person who hates legacy code, wants new DB tables, and new ways of storing information.</p>
<p>Here‚Äôs the problem. What do you do with all those old data? Oh, you want to throw it out? Start new? <em>Brilliant!</em></p>
<h4><a href="https://expertain.net/the-best-way-to-learn-how-to-code/">You might also like: The best way to learn how to code</a></h4>
<h4><strong>Every software shop is the same</strong></h4>
<p>If you look at the world of practicing doctors, they seem to fall (roughly) into two categories: those working in hospitals on patients that need somewhat urgent care (or are doing elective surgery), and doctors with private practices. One of the most common misconceptions about a programmer‚Äôs life (and the weirdest one!).</p>
<p>Both seem to follow a similar structure so that if you went from one personal care doctor to another, their structure would be about the same (waiting room, receptionist, files, someone to check your insurance, collect your copay). If you go get your car repaired at a mechanic, you expect a similar experience. If you go to a grocery store, you expect a similar experience.</p>
<p>People in the software industry have nothing close to this. Each company may have widely varying setups. There are companies with just one program that does everything. Could you run a grocery store with just one person? (Well, maybe if it‚Äôs a tiny one-person operation selling very few items). Or a doctor‚Äôs office (probably not because of insurances, unless you‚Äôre some kind of boutique doctor that makes home visits, and even then, I suspect you hire someone to do the billing, etc).</p>
<h5>The big companies can afford to have their own internal support structure that makes it easier for their average developer to deploy code.</h5>
<p>That support structure is often an internal thing, not an off-the-shelf, any small company can do it. If you were a car mechanic and wanted to open your own small shop, you‚Äôd probably know exactly what you need (at least, the very basics). These things probably have been (roughly) the same for decades, and even the new things, people probably generally agree on what is needed.</p>
<p>But if you‚Äôre a small software shop‚Ä¶there‚Äôs no such standards. Do you want to use Atlassian tools? Or do you use a spreadsheet or emails? Do you use some kind of company email? Or do you use personal email? There are lots of decisions, and it‚Äôs hardly standardized in the industry.</p>
<p>You may think, say, version control is important. I guarantee there‚Äôs some software out there (maybe rare), that doesn‚Äôt use standard version control, and it probably does something important. And the people maintaining it may not even understand what version control is and why you need it. I‚Äôm serious.</p>
<p>It‚Äôs like going to a surgeon with a bottle of whiskey and a bowl of leeches and they say ‚ÄúWhat‚Äôs anesthetic?‚Äù</p>
<h4><strong>We‚Äôll rewrite everything!</strong></h4>
<p>‚ÄúI know engineers, ‚Ä¶</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://expertain.net/the-misconceptions-about-a-programmers-life/">https://expertain.net/the-misconceptions-about-a-programmers-life/</a></em></p>]]>
            </description>
            <link>https://expertain.net/the-misconceptions-about-a-programmers-life/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23887809</guid>
            <pubDate>Sun, 19 Jul 2020 08:02:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Giving GPT-3 a Turing Test]]>
            </title>
            <description>
<![CDATA[
Score 444 | Comments 230 (<a href="https://news.ycombinator.com/item?id=23887637">thread link</a>) | @DavidSJ
<br/>
July 19, 2020 | http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html | <a href="https://web.archive.org/web/*/http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>I‚Äôve been playing around with OpenAI‚Äôs new
<a href="https://arxiv.org/abs/2005.14165">GPT-3</a> language model. When I got
beta access, the first thing I wondered was, how human is GPT-3? How
close is it to passing a Turing test?</p>

<h2 id="how-it-works">How It Works</h2>

<p>Let me explain how exactly I‚Äôm generating these conversations. GPT-3
is a general language model, trained on a large amount of
uncategorized text from the internet. It isn‚Äôt
specific to a conversational format, and it isn‚Äôt trained to answer
any specific type of question. The only thing it does is, given some
text, guess what text comes next.</p>

<p>So if we want GPT-3 to generate answers to questions, we need to seed
it with a ‚Äúprompt‚Äù. I‚Äôm using this prompt to initialize all of the Q&amp;A
sessions:</p>

<div><div><pre><code>Q: What is human life expectancy in the United States?
A: Human life expectancy in the United States is 78 years.

Q: Who was president of the United States in 1955?
A: Dwight D. Eisenhower was president of the United States in 1955.

Q: What party did he belong to?
A: He belonged to the Republican Party.

Q: Who was president of the United States before George W. Bush?
A: Bill Clinton was president of the United States before George W. Bush.

Q: Who won the World Series in 1995?
A: The Atlanta Braves won the World Series in 1995.
</code></pre></div></div>

<p>This is the default prompt suggested by OpenAI for Q&amp;A, so I‚Äôm not
cherrypicking it to prove anything. The point of this prompt is just
to show GPT-3 that we‚Äôre doing questions and answers, not to provide
it with information. For the prompt, both questions and answers are provided by a
human. For all the others, the answers are generated by GPT-3.</p>

<h2 id="common-sense">Common Sense</h2>

<p>Traditionally, artificial intelligence struggles at ‚Äúcommon sense‚Äù. But
GPT-3 can answer a lot of common sense questions.</p>

<div><div><pre><code>Q: What is your favorite animal?
A: My favorite animal is a dog.

Q: Why?
A: Because dogs are loyal and friendly.

Q: What are two reasons that a dog might be in a bad mood?
A: Two reasons that a dog might be in a bad mood are if it is hungry or if it is hot.

Q: How many eyes does a giraffe have?
A: A giraffe has two eyes.

Q: How many legs does a frog have?
A: A frog has four legs.

Q: Are there any animals with three legs?
A: No, there are no animals with three legs.

Q: Why don't animals have three legs?
A: Animals don't have three legs because they would fall over.
</code></pre></div></div>

<p>Ten years ago, if I had this conversation, I would have assumed the
entity on the other end was a human. You can no longer take it for
granted that an AI does not know the answer to ‚Äúcommon sense‚Äù questions.</p>

<p>How does GPT-3 know that a giraffe have two eyes? I wish I had some
sort of ‚Äúdebug output‚Äù to answer that question. I don‚Äôt know for sure,
but I can only theorize that there must be some web page in its
training data that discusses how many eyes a giraffe has. If we want
to stump GPT-3 with common sense questions, we need to think of
questions about things so mundane, they will not appear on the internet.</p>

<div><div><pre><code> Q: Which is heavier, a mouse or an elephant?
 A: An elephant is heavier than a mouse.

 Q: Which is heavier, a mouse or a toaster?
 A: A toaster is heavier than a mouse.

 Q: Which is heavier, a toaster or a pencil?
 A: A pencil is heavier than a toaster.

 Q: Which is heavier, a paper clip or a can of soda?
 A: A can of soda is heavier than a paper clip.

 Q: Which is heavier, a football player or a car?
 A: A car is heavier than a football player.
</code></pre></div></div>

<p>It‚Äôs only 4/5. We‚Äôre closer to stumping GPT-3 here. I think a human
would be pretty close to 100% on these questions. It makes sense these
are trickier - there probably isn‚Äôt any web page that compares
toasters and pencils by weight. It‚Äôs only indirectly that humans gain
this knowledge.</p>

<p>This gives us a hint for how to stump the AI more consistently. We
need to ask questions that no normal human would ever talk about.</p>

<div><div><pre><code>Q: How many eyes does a giraffe have?
A: A giraffe has two eyes.

Q: How many eyes does my foot have?
A: Your foot has two eyes.

Q: How many eyes does a spider have?
A: A spider has eight eyes.

Q: How many eyes does the sun have?
A: The sun has one eye.

Q: How many eyes does a blade of grass have?
A: A blade of grass has one eye.
</code></pre></div></div>

<p>Now we‚Äôre getting into surreal territory. GPT-3 knows how to have a
normal conversation. It doesn‚Äôt quite know how to say ‚ÄúWait a
moment‚Ä¶ your question is nonsense.‚Äù It also doesn‚Äôt know how to say
‚ÄúI don‚Äôt know.‚Äù</p>

<div><div><pre><code>Q: How do you sporgle a morgle?
A: You sporgle a morgle by using a sporgle.

Q: How many bonks are in a quoit?
A: There are three bonks in a quoit.

Q: How many rainbows does it take to jump from Hawaii to seventeen?
A: It takes two rainbows to jump from Hawaii to seventeen.

Q: Which colorless green ideas sleep furiously?
A: Ideas that are colorless, green, and sleep furiously are the ideas of a sleep
furiously.

Q: Do you understand these questions?
A: I understand these questions.
</code></pre></div></div>

<p>The lesson here is that if you‚Äôre a judge in a Turing test, make sure
you ask some nonsense questions, and see if the interviewee responds
the way a human would.</p>

<h2 id="trivia-questions">Trivia Questions</h2>

<p>GPT-3 is quite good at answering questions about obscure things.</p>

<div><div><pre><code>Q: Who was president of the United States in 1801?
A: Thomas Jefferson was president of the United States in 1801.

Q: What city is in the northwest corner of Ohio?
A: Toledo is in the northwest corner of Ohio.

Q: What highway do you take to get to North Lake Tahoe from Oakland?
A: Highway 80 is the highway you take to get to North Lake Tahoe from Oakland.

Q: What are Darius's abilities in League of Legends?
A: Darius's abilities in League of Legends are: Apprehend, Decimate,
Noxian Guillotine, Crippling Strike, Apprehend, and Hemorrhage.

Q: Who did Capablanca defeat to become world chess champion?
A: Capablanca defeated Lasker to become world chess champion.
</code></pre></div></div>

<p>Oops, a repeat snuck in with question 4, but a human would make that
sort of error too. GPT-3 seems to be above
human-level on this sort of question. The tricky thing for
applications, I think, is to figure out when the answer can be relied
on. The OpenAI API does expose more data than just the text, here, so
perhaps something clever is possible.</p>

<p>In general, if you are trying to distinguish an AI from a human, you
don‚Äôt want to ask it obscure trivia questions. GPT-3 is pretty good at
a wide variety of topics.</p>

<p>One trend that continues from the common sense is that GPT-3 is
reluctant to express that it doesn‚Äôt know the answer. So invalid
questions get wrong answers.</p>

<div><div><pre><code>Q: Who was president of the United States in 1700?
A: William Penn was president of the United States in 1700.

Q: Who was president of the United States in 1650?
A: Richard Bennett was president of the United States in 1650.

Q: Who was president of the United States in 1620?
A: James I was president of the United States in 1620.

Q: Who was president of the United States in 1600?
A: Queen Elizabeth I was president of the United States in 1600.
</code></pre></div></div>

<p>These wrong answers are actually fascinating! None of these were
presidents of the United States, of course, since the US didn‚Äôt exist
then. But they are all prominent political figures who were in charge
of some US-related political entity around that time. In a sense, they
are good guesses.</p>

<div><div><pre><code>Q: Who won the World Series in 2021?
A: The New York Yankees won the World Series in 2021.

Q: Who won the World Series in 2022?
A: The New York Yankees won the World Series in 2022.

Q: Who won the World Series in 2023?
A: The New York Yankees won the World Series in 2023.
</code></pre></div></div>

<p>A bleak view of a dystopian future.</p>

<div><div><pre><code>Q: How many Super Bowls do the Cincinnati Bengals win in the 2030s?
A: The Cincinnati Bengals win two Super Bowls in the 2030s.
</code></pre></div></div>

<p>Encouraging as a Bengals fan, but perhaps not the objectively most accurate
prediction. We‚Äôll have to wait and see.</p>

<h2 id="logic">Logic</h2>

<p>People are used to computers being superhuman at logical activities,
like playing chess or adding numbers. It might come as a surprise that
GPT-3 is not perfect at simple math questions.</p>

<div><div><pre><code>Q: When counting, what number comes before 100?
A: Ninety-nine comes before 100.

Q: When counting, what number comes before 123?
A: One hundred and twenty-two comes before 123.

Q: When counting, what number comes before 1000?
A: Nine hundred and ninety-nine comes before 1000.

Q: When counting, what number comes before 10,000?
A: Nine thousand and ninety-nine comes before 10,000.

Q: When counting, what number comes before a million?
A: Nine hundred thousand and ninety-nine comes before a million.
</code></pre></div></div>

<p>This is where the generic nature of GPT-3 comes into play. It isn‚Äôt
just the generic model, though, it‚Äôs also the architecture of neural
networks themselves. As far as I know there is no neural network that
is capable of doing basic arithmetic like addition and multiplication
on a large number of digits based on training data rather than
hardcoding.</p>

<p>It‚Äôs funny, because these operations are simple for a customized
program. But recursive logic that does some operation and repeats it
several times often doesn‚Äôt quite map onto the architecture of a
neural net well.</p>

<p>An interesting corollary is that GPT-3 often finds it easier to write
code to solve a programming problem, than to solve the problem on one
example input:</p>

<div><div><pre><code>Q: Write one line of Ruby code to reverse an array.
A: ary.reverse

Q: Write one line of Ruby code to count how many X's are in an array.
A: ary.count { |x| x == 'X' }

Q: Reverse the following array: [1, 3, 5, 6, 10, 4, 2, 77]
A: [10, 6, 4, 2, 77, 3, 5, 1]

Q: How many X's are in this array: [1, 3, 5, 6, 10, 4, 2, 77]
A: 2
</code></pre></div></div>

<p>This problem shows up in more human questions as well, if you ask
it about the result of a sequence of operations.</p>

<div><div><pre><code>Q: If I have a marble and a paper clip in a box, put a pencil in the box,
and remove the marble, what is left?
A: A paper clip.

Q: If I have two shoes in a box, put a pencil in the box, and
remove one shoe, what is left?
A: A shoe.

Q: If I put a pencil in a box, then put another pencil in the box,
what is in the box?
A: Two pencils.

Q: Then if ‚Ä¶</code></pre></div></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html">http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html</a></em></p>]]>
            </description>
            <link>http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23887637</guid>
            <pubDate>Sun, 19 Jul 2020 07:23:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How e-commerce platform Elliot fell back down to Earth]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 22 (<a href="https://news.ycombinator.com/item?id=23887107">thread link</a>) | @prostoalex
<br/>
July 18, 2020 | https://www.modernretail.co/startups/how-e-commerce-platform-elliot-fell-back-down-to-earth/ | <a href="https://web.archive.org/web/*/https://www.modernretail.co/startups/how-e-commerce-platform-elliot-fell-back-down-to-earth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>On May 21, Brittany Chavez had just about reached her limits.</p><p>‚ÄúY‚Äôall, I am one more passive [aggressive], gaslighting, unprofessional response away from telling everyone what a shit experience I‚Äôm having on this e-commerce platform my company is on,‚Äù she tweeted.</p><div id="piano-cta">
<p>While cryptic, those within her circle knew what she was talking about. Chavez had spent the last five months building her online marketplace, Shop Latinx, on the startup e-commerce platform Elliot. During those months, she hyped the company on multiple social media platforms. In turn, Shop Latinx was used in marketing materials about Elliot; Chavez said she had even been asked to speak about her experience with Elliot investors Torch Capital.</p>

<p>‚ÄúI felt like this would be a very dope experience and partnership that would benefit both of us,‚Äù Chavez told Modern Retail. Instead, she found herself increasingly frustrated by the limitations ‚Äî dealing with small technical problems that she said the company would take months to fix, if not completely ignore the requests.</p>
<p>A day after Chavez sent the tweet, Elliot‚Äôs founder, Sergio Villase√±or, responded with a thread called: ‚ÄúFounder Lesson: When to Fire a Customer.‚Äù He posted financial documents and emails sent between him, Chavez and another Shop Latinx co-founder. He included personal and financial allegations about the company‚Äôs revenue, claiming to have paid for her laptop and wiring her cash to help her incorporate. It concluded: ‚ÄúAs a Latino, it‚Äôs unfortunate to terminate a customer that supports a community I‚Äôm racially bound to.‚Äù</p>
<p>It was a strange ordeal, made ugly by the online public setting. Even stranger was the fact that Elliot had not even gone to market yet, and Shop Latinx was one of its beta testers. Three weeks before he was supposed to unveil his e-commerce platform, Villase√±or had decided to put an early adopter on blast.</p>
<p>This was perhaps a harbinger of what was to come. Villase√±or and his founders spent months hyping their soon-to-launch platform. The launch, however, never happened, as the platform, according to sources, seemed largely untested despite much handwaving and claims made online, in industry groups and to the merchants already signed on. Elliot, the pitch went, was going to be the anti-Shopify ‚Äî an international e-commerce platform that focused on smaller businesses in an increasingly globalized world. But the competitive landscape was already crowded with giants like BigCommerce, WooCommerce and Magento offering similar solutions.</p>
<p>Despite being small, Elliot represented an important shift in the e-commerce space. It was a back-end company trying to brand itself as hip, current and with the times. Where Magento was an agnostic platform that seemed invisible to everyone but the engineers and developers, Elliot was riding the direct to consumer wave of marketing coming first and product being second. The problem for Elliot, it seemed, was that product never quite got to where it said it should be.</p>

<p>But for at least a few months, the guerilla campaigning worked. Thanks to advertising placements in industry newsletters like Lean Luxe, myriad Twitter threads about hustling and entrepreneurship (as well as quite a few online spats), the commerce industry took notice, more investors began writing checks, and e-commerce professionals‚Äô interests were getting piqued.</p>
<p>Elliot‚Äôs launch date was set for June 18. When the day came, due to what the company claimed was a denial of service attack on its infrastructure, the unveiling hit some snags. In response to the alleged attack, sources said Villase√±or fired most of the company‚Äôs engineers ‚Äî many of whom were on contract with the company Andela, which hires coders in Africa, including in Nigeria, Ghana and Kenya. (Villase√±or contested this, saying that the engineers‚Äô contracts ended that day and he was in the process of hiring full-time staff.) He then announced on Twitter that Elliot‚Äôs launch would be pushed until December 25. A few days later, he would announce that he was stepping down as CEO of the company. And 24 hours after that, his two other co-founders, Marco Marandiz and Clayton Chambers, announced that the company would shut down completely.</p>
<p>Villase√±or then changed his Twitter handle and both his and Elliot‚Äôs tweets were scrubbed. Marandiz and Chambers posted on Twitter that they are no longer associated with the company. Marandiz declined to comment for this article and Chambers did not respond to a request for comment.</p>
<p>Meanwhile, Villase√±or has tried to keep a low profile. In a private Discord chat viewed by Modern Retail, third-party developers expressed disbelief at the outcome; Many were disappointed to learn the news about Elliot‚Äôs closing via Twitter, not via internal networks. ‚ÄúThese guys may be on to something, market the shit out of product and then dip with the investor money,‚Äù wrote one member. When asked what happened, Villase√±or simply said he was too exhausted; ‚ÄúI was burnt out when I started Elliot,‚Äù he wrote on the Discord. ‚ÄúI just got tired.‚Äù</p>
<p>Now, a few days later, Villase√±or told Modern Retail the show isn‚Äôt over. ‚ÄúWe are recapitalizing the company under a new name,‚Äù he said, adding that the details are still being worked out. He is the only member of the board. The company is now just him and a team of five engineers trying to pick back up the pieces, he said. Stepping down, he said, was part of the overall strategy. ‚ÄúWe will set out a launch date later in the year ‚Äî when we feel the platform is secure,‚Äù he said. ‚ÄúI will still be loosely involved.‚Äù</p>
<p>Elliot‚Äôs shift from heralded startup to Dead On Arrival was stark ‚Äî especially given its founder‚Äôs proclivity for platitudinous online founder-speak. On June 9, Villase√±or tweeted:</p>
<p><img src="https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-555x312.png" alt="" width="555" height="312" srcset="https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-555x312.png 555w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-165x165.png 165w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-555x312.png 555w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-360x200.png 360w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-330x330.png 330w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-375x368.png 375w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-311x368.png 311w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-263x351.png 263w" sizes="(max-width: 555px) 100vw, 555px"></p>
<p>In another he wrote:</p>
<p><img src="https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-555x312.png" alt="" width="555" height="312" srcset="https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-555x312.png 555w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-165x165.png 165w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-555x312.png 555w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-360x200.png 360w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-330x330.png 330w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-375x353.png 375w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-311x353.png 311w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-263x351.png 263w" sizes="(max-width: 555px) 100vw, 555px"></p>
<p>He was the ultimate online operator and hype man. He and his most recent co-founders had spent months teasing the launch of their new company. They tweeted, posted videos and hosted luxurious dinners and exotic getaways ‚Äî all to get more people talking about Elliot. They also focused specifically on smaller, more diverse brands ‚Äî claiming to offer e-commerce support for companies that are often overlooked. This was what helped attract a slew of industry operators and entrepreneurs who have historically felt ignored; a back-end e-commerce platform suddenly had brand evangelists. The pitch focused on diversity and industry shortcomings. And it certainly resonated, at least for a while.</p>
<p>According to eight sources with personal knowledge of the business, Elliot‚Äôs rise and fall could be traced back to the capricious swings of its chief executive. Villase√±or spent the last year trying to build and hype his platform, specifically seeking out diverse and popular brand evangelists. But the platform was never finished, and not as international as it claimed to be; it facilitated payments through Stripe, for example, which is only supported in 33 countries. (Villase√±or said that it is working to add payment options and that it offers a wallet feature where merchants in countries that Stripe doesn‚Äôt operate can connect their bank accounts to receive payments directly from Elliot.)</p>
<p>Villase√±or used his charm and charisma to ingratiate himself in online social circles, sources said, and leveraged those new relationships to make professional inroads. Through this, he landed investment dollars and business partnerships, which helped propel his social media following and professional clout. ‚ÄúIt‚Äôs very appalling to me to see someone get the opportunity that so many people crave ‚Äî all that funding, and then blow it up,‚Äù said Andrea Hern√°ndez, founder of Mood Food Snacks, a Latin America-based company that was courted to use Elliot earlier this year.</p>
<p>Most people were drawn in by Villase√±or‚Äôs magnetism and drive, but were often dismayed to find a darker side. If a potential business partner gave him an answer he didn‚Äôt like, he would call them, angry, or take to Twitter to blast their replies. ‚ÄúIt was these violent switches in personality,‚Äù said one person who had done business with the platform. People in Villase√±or‚Äôs crosshairs would often have to message co-founders or investors to get him to stop. ‚ÄúIt‚Äôs scary,‚Äù the source said.</p>
<p>In Villase√±or‚Äôs eyes, the idea was to get people‚Äôs attention. ‚ÄúOur Twitter persona,‚Äù he said, ‚Äúwas very intentional.‚Äù There were a lot of competitors, and they all had serious marketshare. It didn‚Äôt make sense in his eyes to pay for search and social media marketing. ‚ÄúWe were leading with bravado,‚Äù he said. ‚ÄúThat would allow us to make some noise and get attention.‚Äù</p>
<p><strong>How did it get here?</strong><br>
Founded in 2017 (although it really only captured industry attention in the past year) as a ‚Äúproprietary Omnichannel syndication software that is enabling merchants to sell cross border with a click of a button,‚Äù Elliot is no stranger to odd, quasi-legal quagmires. For example, in 2019 (when Villase√±or was in the midst of its latest relaunch) Elliot sued an early business partner named Derek Sine for allegedly illegally using the Elliot trademark and making fraudulent claims. In multiple legal back-and-forths, Sine claimed to be a co-founder.</p>
<p>In 2018, the company announced a $3 million seed rounding along with a new set of executives, including Lea Solimene, Joey Spanjers and Hass Johnson. (Today, none of these people list Elliot on their LinkedIn profiles and none responded to requests for comment for this article.) The press release at the time focused less on the branding and more on the set of tools it provided including ‚Äúdata management, global shipping options, translations, and all the tools needed to connect to billions of new consumers.‚Äù</p>
<p>Over a year went by, and Elliot never launched. Villase√±or said that company was about to sign a Series A term sheet, but the team ‚Äúdidn‚Äôt feel like the product would be sustainable.‚Äù He decided to pivot the original business away from being a ‚Äúcatalog manager,‚Äù and rebrand entirely. The team at the time ‚Äúdidn‚Äôt fit the ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.modernretail.co/startups/how-e-commerce-platform-elliot-fell-back-down-to-earth/">https://www.modernretail.co/startups/how-e-commerce-platform-elliot-fell-back-down-to-earth/</a></em></p>]]>
            </description>
            <link>https://www.modernretail.co/startups/how-e-commerce-platform-elliot-fell-back-down-to-earth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23887107</guid>
            <pubDate>Sun, 19 Jul 2020 04:54:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spies in the Xerox Machine (1997)]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 36 (<a href="https://news.ycombinator.com/item?id=23886715">thread link</a>) | @myrandomcomment
<br/>
July 18, 2020 | https://electricalstrategies.com/about/in-the-news/spies-in-the-xerox-machine/ | <a href="https://web.archive.org/web/*/https://electricalstrategies.com/about/in-the-news/spies-in-the-xerox-machine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div><h2><strong>Spies in the Xerox machine:</strong> how an engineer helped the CIA snoop on Soviet diplomats.</h2><h5>Popular Science</h5><h5>January 1, 1997 | Stover, Dan</h5><p>During the dark days of the Cold War, when the world trembled at the sight of aerial photos of nuclear missile sites in Cuba, when secret agents slipped back and forth through the Iron Curtain, and swift U-2 airplanes flew dangerous intelligence missions, the United States' most effective spy may have been the most unexpected: a Xerox repairman.</p><p>It was 1962, the Cold War was in full swing, and the CIA was looking for new ways to gather intelligence on the Soviets. Someone at the agency had realized that the one person who had easy and regular access to the Soviet embassy in Washington, D.C., the one American who could come and go with no questions asked, was the Xerox repairman. He visited the embassy at least once a month, and nobody was surprised or alarmed to see him tinkering with the photocopier, his tools scattered on the floor. At the CIA, this seemed like an opportunity too good to pass up.</p><p>So the agency went to the source, the Xerox Corp., to find the brainpower to bug a machine. Ray Zoppoth was a 36-year-old mechanical engineer at Xerox in Webster, New York, when he was asked to join a small team that would work on this project. For years afterward, Zoppoth kept his role secret from even his wife and his eight children. But now, he believes, it is time people learned more about this chapter in our nation's history. That's why he decided to tell his story to POPULAR SCIENCE.</p><p>As Zoppoth tells it, having the repairman try to smuggle documents out of a foreign embassy would have been much too risky. Instead, the CIA wanted the repairman to install a device that would enable its agents to view the documents being copied on the embassy's Xerox machine. They hoped such a system would not only give them a peek at top-secret Soviet documents, but that it would also tell them whether Soviet spies had managed to get their hands on any classified U.S. documents.</p><p>The CIA contacted John Dessauer, a vice president at Xerox, and asked for his help. Dessauer then put Donald Cary, who headed a government programs group at Xerox, in charge of the project. Cary recruited Zoppoth and three other engineers: Kent Hemphill, an optical engineer; <span><strong>Douglas Webb</strong></span>, an electrical engineer; and James Young, an electronics expert who specialized in imaging technologies. Zoppoth was chosen, in part, because he had helped develop the Xerox model 914, the first automatic push-button copier, and the type used in the Soviet embassy.</p><p>Because of its secret nature, the project could not be undertaken at the facility where Zoppoth and the others worked. Instead, the project leaders rented an abandoned one-lane bowling alley in a small shopping center. With the installation of a security system, the windowless alley became an impromptu research lab.</p><p>There, progress notes spread across the alley floor, the engineers experimented with several methods for imaging the documents being copied on the embassy's model 914. An approach suggested by Zoppoth seemed the most promising: Mount a battery-powered home-movie camera with a zoom lens inside the copier. Aim the lens at the mirror used to reflect images onto the drum. Add a photocell that would prompt the camera to snap still frames whenever the photocopier lit up. And start taking pictures.</p><p>The engineers purchased a state-of-the-art Bell &amp; Howell movie camera from a retail outlet. It was about seven inches long and held a spool of 8mm film. There was plenty of room for the camera deep inside the bulky console-style copier, and the camera couldn't be seen even when the machine's covers were removed. The camera's noise was drowned out by the sounds of the photocopier.</p><p>The team installed the camera in a machine at the bowling alley, and photographed sample documents. "We used the bathroom as our darkroom," Zoppoth recalls.</p><p>Next, they installed a camera in a machine at the main Xerox office in Webster. "When we developed the pictures, we found recipes and copies of music and cartoons and jokes and all kinds of things," Zoppoth says.</p><p>Finally, the engineers were ready to turn their invention over to the CIA. Zoppoth made a series of trips to Washington to meet with two agents in the dark basement of a CIA building code-named Disneyland East. Surrounded by heating pipes, Zoppoth taught the agents how to install the camera, so that they could later train the Xerox repairman. The repairman would place a camera inside the Xerox machine while he serviced it; the camera didn't appear out of place among his jumble of tools and spare parts. On his next visit, he would replace the camera with another one containing fresh film, then turn the exposed film over to the CIA.</p></div> <!-- end .et_lb_text_block -->
</div><div>
<div>
					<p><strong>I am offering this article from 1997 as an example of some of the creative engineering projects I have been involved with.</strong></p> <!-- end .et_lb_module_content -->
				</div> <!-- end .et_lb_box -->
<div>
					<div>
						<div><p><a href="http://structuredbrands.com/wp-content/uploads/2014/07/camera-inside-copier.jpg" title=""><img alt="" src="http://structuredbrands.com/wp-content/uploads/2014/07/camera-inside-copier.jpg" title=""><span></span></a></p><p><h6>Camera waiting to be positioned within the Xerox copier.</h6>
</p> <!-- end .et_lb_image_content -->		</div> <!-- end .et_lb_module_content_inner -->
					</div> <!-- end .et_lb_module_content -->
				</div> <!-- end .et_lb_widget_area -->
<div>
					<div>
						<div><p><a href="http://structuredbrands.com/wp-content/uploads/2014/07/camera-in-xerox-machine.jpg" title=""><img alt="" src="http://structuredbrands.com/wp-content/uploads/2014/07/camera-in-xerox-machine.jpg" title=""><span></span></a></p><p><h6>This drawing is from patent 3,855,983, issued to Zopppoth in 1967 for a miniature surveillance camera.</h6>
</p> <!-- end .et_lb_image_content -->		</div> <!-- end .et_lb_module_content_inner -->
					</div> <!-- end .et_lb_module_content -->
				</div> <!-- end .et_lb_widget_area -->
<div><p>The system went into service in 1963. It wasn't long before the CIA asked the Xerox team if a similar system could be built for a much smaller desktop copier, the model 813.</p><p>Hiding an off-the-shelf camera inside such a small machine was impossible, so the engineers designed a miniaturized camera that operated off the photocopier's own power supply and held only a partial roll of film. They also modified the 813's mirrors and cut away pieces of the machine. Parts needed for the camera were farmed out to several model shops, so that nobody outside the research team could recognize what was being built. In 1964, Zoppoth was awarded a secret patent for the tiny surveillance camera that was hidden inside the modified machine.</p><p>Judging by the number of parts ordered from Xerox, Zoppoth believes that spy cameras may have been installed in photocopiers all over the world, to keep an eye on U.S. allies as well as enemies. But in 1969, a chemical company that had come up with a similar idea for spying on a competitor was caught red-handed. After that, it seemed likely that the Soviets would scrutinize their own machines more closely. But whether the Soviets ever found a concealed camera, or whether the CIA ceased planting them in photocopy machines, is uncertain.</p><p>Although the cameras built by Zoppoth and his co-conspirators seem primitive compared with today's sophisticated microelectronics, the project remains classified. Zoppoth retired in 1979. Another team member confirms his story but is unwilling to speak about any of the details. Other members could not be located, or would not discuss the matter. The CIA and Xerox will neither confirm nor deny Zoppoth's account, possibly because the company has secret research contracts with the government to this day.</p><h6>Stover, Dan<br>COPYRIGHT 1987 Bonnier Corporation</h6></div> <!-- end .et_lb_text_block -->
</div></div>]]>
            </description>
            <link>https://electricalstrategies.com/about/in-the-news/spies-in-the-xerox-machine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23886715</guid>
            <pubDate>Sun, 19 Jul 2020 03:11:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Front End Interview Handbook]]>
            </title>
            <description>
<![CDATA[
Score 72 | Comments 25 (<a href="https://news.ycombinator.com/item?id=23886528">thread link</a>) | @yangshun
<br/>
July 18, 2020 | https://yangshun.github.io/front-end-interview-handbook/ | <a href="https://web.archive.org/web/*/https://yangshun.github.io/front-end-interview-handbook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><header><div><p><img src="https://yangshun.github.io/front-end-interview-handbook/img/logo.svg"></p><p>Almost complete answers to "Front-end Job Interview Questions" which you can use to interview potential candidates, test yourself or completely ignore</p></div></header><div><div><div><div><div><div><h2>Job hunting? Sign up with Triplebyte to efficiently interview with top tech companies and land your dream job! üí∞</h2></div></div></div></div></div><div><div><div><div><h2>Why Front End Interview Handbook?</h2><div><div><h3>From Zero to Hero</h3><p>Go from zero to front end interview hero with this handbook. No prior interview experience needed.</p></div><div><h3>Back to Basics</h3><p>Learn to walk before you learn to fly. While React, Vue and Angular are cool, make sure you also know your fundamentals.</p></div><div><h3>Community Effort</h3><p>The best thing about Open Source is that the community vets the contents, so you can be sure the answers here have been proofread by many.</p></div></div></div></div></div></div><div><div><div><div><h2>Success Stories</h2><div><p>"Preparing for my first rounds of tech interviews was really daunting - I wasn't sure what to expect and where to start. This handbook together with the <a href="https://github.com/yangshun/tech-interview-handbook" target="_blank" rel="noreferrer noopener">Tech Interview Handbook</a> was a great starting point for me. It clearly describes each part of the process and has tons of awesome tips and resources. With this handbook and lots of practice, I managed to get offers from Facebook, Dropbox and Amazon!"</p><div><div><p><img src="https://avatars1.githubusercontent.com/u/5081708?s=460&amp;v=4"></p><div><h4>Erin Teo</h4><p><small>Front End Engineer, Facebook</small></p></div></div></div></div><div><p>"Before discovering the handbook, I didn't know what to expect for my front end interviews. Thanks to it, I had a better understanding and even learned new things about frontend development. The handbook is an immense resource, one that I still use to refresh and reinforce my knowledge to tackle interviews confidently!"</p><div><div><p><img src="https://github.com/li-kai.png"></p><div><h4>Kai Li</h4><p><small>Software Engineer, Zendesk</small></p></div></div></div></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://yangshun.github.io/front-end-interview-handbook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23886528</guid>
            <pubDate>Sun, 19 Jul 2020 02:26:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cross Entropy Loss vs Log Loss vs Sum of Log Loss]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23886417">thread link</a>) | @keyboardman
<br/>
July 18, 2020 | https://leimao.github.io/blog/Conventional-Classification-Loss-Functions/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Conventional-Classification-Loss-Functions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>In one of my previous blog posts on <a href="https://leimao.github.io/blog/Cross-Entropy-KL-Divergence-MLE/">cross entropy, KL divergence, and maximum likelihood estimation</a>, I have shown the ‚Äúequivalence‚Äù of these three things in optimization. Cross entropy loss has been widely used in most of the state-of-the-art machine learning classification models, mainly because optimizing it is equivalent to maximum likelihood estimation. However, there could be other losses used for classification problems.</p>



<p>In this blog post, I would like to discussed the log loss used for logistic regression, the cross entropy loss used for multi-class classification, and the sum of log loss  used for multi-class classification.</p>

<h3 id="prerequisites">Prerequisites</h3>

<p>The prerequisites of this blog post have been discussed heavily in my other blog posts. For completeness, I made a copy of them here.</p>

<h4 id="leibniz-integral-rule">Leibniz Integral Rule</h4>

<p>Leibniz integral rule allows swapping positions of derivatives under certain circumstances.</p>



<p>To check the quick proof of Leibniz integral rule, please check one my blog posts on <a href="https://leimao.github.io/blog/RL-Policy-Gradient-Unbiase-Estimate/">this</a>.</p>

<h4 id="derivatives-of-expected-value">Derivatives of Expected Value</h4>

<p>Based on Leibniz integral rule, we could also move the positions of derivatives inside the expected value or outside the expected value. For instance,</p>



<p>If $\mathbb{E}_{(x,y) \sim P(x,y)}\big[ \mathscr{L}_{\theta}(x,y) \big]$ is the loss function, to compute the derivative of the entire loss with respect to the parameter $\theta$, it is equivalent to computing the derivatives of the losses contributed by each data point $\mathscr{L}_{\theta}(x, y)$ with respect to the parameter $\theta$ and followed by computing its expected value, $\mathbb{E}_{(x,y) \sim P(x, y)}\big[ \frac{\partial}{\partial \theta} \mathscr{L}_{\theta}(x, y) \big]$. Assuming all the data $(x, y)$ are uniformly distributed, it is simply just computing the derivative of the losses contributed by each data point $\mathscr{L}_{\theta}(x, y)$ with respect to the parameter $\theta$ and followed by taking their average. This is also how modern deep learning framework, such as TensorFlow and PyTorch, works.</p>

<h3 id="log-loss-for-logistic-regression">Log Loss for Logistic Regression</h3>

<p>Log loss has been used for logistic regression for a long time. Given $(x, y)$, where $x$ is the input, $y$ is the label for $x$, our goal is to develop a model $f_{\theta}$, where $\theta$ are the model parameters. such that $\tilde{y} = f_{\theta}(x)$ is as close to $y$ as possible. For logistic regression, usually $y = 0$ or $1$. $y = 1$ means $x$ belongs to certain class, whereas $y = 0$ means $x$ does not belong to certain class.</p>



<p>Usually, logistic regression will compute the logit $z$ for the input $x$, where $z = g_{\theta}(x)$ followed by computing the sigmoid activation for $z$ to get the estimate of $y$, $\tilde{y}$, in the range of $(0,1)$. Concretely,</p>



<p>The loss function used for fitting is called log loss, which we would see later that it is actually binary cross entropy loss.</p>



<p>We further compute the derivative of this log loss with respect to the logit $z$.</p>





<p>Therefore,</p>



<p>The interpretation is very simple. If $\tilde{y} &gt; y$, $\frac{\partial}{\partial z} \mathscr{L}_{\theta}(x,y) &gt; 0$, the gradient descent wants to make $z$ smaller. Once $z$ is smaller, $\tilde{y}$ will be smaller and its deviation from $y$ will become smaller. Similarly, If $\tilde{y} &lt; y$, $\frac{\partial}{\partial z} \mathscr{L}_{\theta}(x,y) &lt; 0$, the gradient descent wants to make $z$ larger. Once $z$ is larger, $\tilde{y}$ will be larger and its deviation from $y$ will become smaller.</p>



<p>To update the model parameters $\theta$, we would need to compute the derivatives with respect to $\theta$.</p>



<h3 id="cross-entropy-loss-for-multi-class-classification">Cross Entropy Loss for Multi-Class Classification</h3>

<p>Cross entropy loss has been widely used for classification problems in deep learning. Given $(x, \mathbf{y})$, where $x$ is the input, $\mathbf{y}$ is the label for $x$. If $\mathbf{y}$ is an one-hot vector of size $n$, and $\mathbf{y}_i = 1$, our goal is to develop a model $f_{\theta}$, where $\theta$ are the model parameters, such that $\tilde{\mathbf{y}}_i = f_{\theta}(x)$ is as close to $\mathbf{y}_i$ as possible. Note that the motivation of using cross entropy loss behind is maximum likelihood estimation which might not be obvious to see. But I have discussed in my previous blog <a href="https://leimao.github.io/blog/Cross-Entropy-KL-Divergence-MLE/">post</a>.</p>



<p>Usually, multi-class classification will compute the logits $\mathbf{z}$ for the input $x$, where $\mathbf{z} = g_{\theta}(x)$ followed by computing the softmax activation for $\mathbf{z}$ to get the estimate of $\mathbf{y}$, $\tilde{\mathbf{y}}$, where $\sum_{i=1}^{n} \tilde{\mathbf{y}}_i = 1$ and $\tilde{\mathbf{y}}_i \in [0, 1]$ for $i \in [1, n]$. Concretely,</p>



<p>The loss function used for fitting is called softmax loss.</p>



<p>We further compute the derivative of this cross entropy loss with respect to the logits $\mathbf{z}$.</p>







<p>Therefore,</p>



<p>The interpretation is also very simple. If $\tilde{\mathbf{y}}_k &gt; \mathbf{y}_k$, $\frac{\partial}{\partial \mathbf{z}_k} \mathscr{L}_{\theta}(x,\mathbf{y}) &gt; 0$, the gradient descent wants to make $\mathbf{z}_k$ smaller. Once $\mathbf{z}_k$ is smaller, $\tilde{\mathbf{y}}_k$ will be smaller and its deviation from $\mathbf{y}_k$ will become smaller. Similarly, If $\tilde{\mathbf{y}}_k &lt; \mathbf{y}_k$, $\frac{\partial}{\partial \mathbf{z}_k} \mathscr{L}_{\theta}(x,\mathbf{y}) &lt; 0$, the gradient descent wants to make $\mathbf{z}_k$ larger. Once $\mathbf{z}_k$ is larger, $\tilde{\mathbf{y}}_k$ will be larger and its deviation from $\mathbf{y}_k$ will become smaller.</p>



<p>To update the model parameters $\theta$, we would need to compute the derivatives with respect to $\theta$.</p>



<h3 id="cross-entropy-loss-for-multi-class-classification-vs-log-loss-for-logistic-regression">Cross Entropy Loss for Multi-Class Classification VS Log Loss for Logistic Regression</h3>

<p>If we have $n = 2$ for cross entropy loss and compare it with log loss, we would immediately see that the form of log loss is exactly the same to binary cross entropy loss, and log loss for logistic regression is a special case for cross entropy loss for multi-class classification where $n = 2$ and the logit $z$ for the negative class ($y = 0$) is a fixed value $0$.</p>



<p>So if we have a binary classification problem, what is the difference between modeling it using log loss for logistic regression and cross entropy loss for binary classification, assuming the learning rate and other hyperparameters are the same? We could see that the gradients with respect to the positive logit $z$ for both models are always the same. However, when it comes to updating the model parameters $\theta$, the gradients for the two models would be different, because one model has only one logit whereas the other model has two logits. Therefore, although the two models are analogous, it is incorrect to say these two models are exactly the same.</p>



<p>One may ask which model is better for a binary classification problem. It is hard to say. But one thing that is for sure is that the binary cross entropy model is relatively easy to overfit. The reasons are the followings:</p>

<ul>
  <li>The binary cross entropy model has more parameters compared to the logistic regression.</li>
  <li>The binary cross entropy model would try to adjust the positive and negative logits simultaneously whereas the logistic regression would only adjust one logit and the other hidden logit is always $0$, resulting the difference between two logits larger in the binary cross entropy model much larger than that in the logistic regression model.</li>
</ul>

<p>To prevent overfitting, we could use <a href="https://leimao.github.io/blog/Label-Smoothing/">label smoothing</a> for cross entropy loss. I have discussed it previously and I am not going to elaborate it here.</p>

<h3 id="sum-of-log-loss-for-multi-class-classification">Sum of Log Loss for Multi-Class Classification</h3>

<p>While it might be rare, we could treat a multi-class classification problem as multiple one-vs-all classifications, each of which is a logistic regression. Given $(x, \mathbf{y})$, where $x$ is the input, $\mathbf{y}$ is the label for $x$. Our goal is to develop a model $f_{\theta}$, where $\theta$ are the model parameters, such that $\tilde{\mathbf{y}}_j = f_{\theta}(x)$ is as close to $\mathbf{y}_j$ as possible, for all $j \in [1, n]$. Note that this is different from cross entropy loss for multi-class classification.</p>



<p>Usually, multi-class classification will compute the logits $\mathbf{z}$ for the input $x$, where $\mathbf{z} = g_{\theta}(x)$ followed by computing the sigmoid activation for each logit of $\mathbf{z}$ to get the estimate of $\mathbf{y}$, $\tilde{\mathbf{y}}$, where notably $\sum_{i=1}^{n} \tilde{\mathbf{y}}_i$ and $\sum_{i=1}^{n} \mathbf{y}_i$ do not have to equal to 1, and $\tilde{\mathbf{y}}_i \in [0, 1]$ for $i \in [1, n]$. Concretely,</p>



<p>The loss function used for fitting is called the sum of log loss. The classification of each class could be seen as mutually exclusive. TensorFlow has an implementation for this loss, which they call it <a href="https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits">tf.nn.sigmoid_cross_entropy_with_logits</a>, as well.</p>



<p>We further compute the derivative of this sum of log loss with respect to the logits $\mathbf{z}$. Because it is almost exactly the same to the derivative of log loss with respect to the logits $z$, we skipped some details.</p>





<p>Therefore,</p>



<p>The interpretation is the same as cross entropy loss for multi-class classification. If $\tilde{\mathbf{y}}_k &gt; \mathbf{y}_k$, $\frac{\partial}{\partial \mathbf{z}_k} \mathscr{L}_{\theta}(x,\mathbf{y}) &gt; 0$, the gradient descent wants to make $\mathbf{z}_k$ smaller. Once $\mathbf{z}_k$ is smaller, $\tilde{\mathbf{y}}_k$ will be smaller and its deviation from $\mathbf{y}_k$ will become smaller. Similarly, If $\tilde{\mathbf{y}}_k &lt; \mathbf{y}_k$, $\frac{\partial}{\partial \mathbf{z}_k} \mathscr{L}_{\theta}(x,\mathbf{y}) &lt; 0$, the gradient descent wants to make $\mathbf{z}_k$ larger. Once $\mathbf{z}_k$ is larger, $\tilde{\mathbf{y}}_k$ will be larger and its deviation from $\mathbf{y}_k$ will become smaller.</p>



<p>To update the model parameters $\theta$, we would need to compute the derivatives with respect to $\theta$.</p>



<p>The formula is exactly the same as the one used for cross entropy loss for multi-class classification.</p>

<h3 id="cross-entropy-loss-for-multi-class-classification-vs-sum-of-log-loss-for-multi-class-classification">Cross Entropy Loss for ‚Ä¶</h3></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/blog/Conventional-Classification-Loss-Functions/">https://leimao.github.io/blog/Conventional-Classification-Loss-Functions/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/blog/Conventional-Classification-Loss-Functions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23886417</guid>
            <pubDate>Sun, 19 Jul 2020 02:03:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Selecting the Right Industrial 3D Printer]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23886357">thread link</a>) | @ddingus
<br/>
July 18, 2020 | https://pluralam.com/selecting-right-industrial-3d-printer/ | <a href="https://web.archive.org/web/*/https://pluralam.com/selecting-right-industrial-3d-printer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <header data-post-id="3659" data-type="header" data-sticky="0" data-sticky-breakpoint="medium" data-shrink="0" data-overlay="0" data-overlay-bg="transparent" data-shrink-image-height="50px" itemscope="itemscope" itemtype="http://schema.org/WPHeader"><div data-node="5e8b67d85529f"><div><div><div data-node="5e8b67d85afcc"><div data-node="5e8b67d85b2c1"><div><div data-node="5e8b947ce1af9"><div><p><strong>Covid-19 concerns? We're open and here to help.</strong></p></div></div></div></div></div></div></div></div><div data-node="5a3afb8b36265"><div><div><div data-node="5a3afb8b362af"><div data-node="5a3afb8b362f0"><div><div data-node="5a3afc6aaed49"><div><div itemscope="" itemtype="https://schema.org/ImageObject"><p><a href="https://pluralam.com/" target="_self" itemprop="url"> <img src="https://s3-us-west-2.amazonaws.com/freddieflip/uploads/sites/28/2019/09/23124915/Plural_logo_.png" alt="Plural Additive Manufacturing logo" itemprop="image" title="Plural_logo_+" data-no-lazy="1" srcset="https://freddieflip.s3.us-west-2.amazonaws.com/uploads/sites/28/2019/09/23124915/Plural_logo_.png 877w, https://freddieflip.s3.us-west-2.amazonaws.com/uploads/sites/28/2019/09/23124915/Plural_logo_-400x119.png 400w, https://freddieflip.s3.us-west-2.amazonaws.com/uploads/sites/28/2019/09/23124915/Plural_logo_-768x228.png 768w" sizes="(max-width: 877px) 100vw, 877px"> </a></p></div></div></div></div></div></div></div></div></div> </header><div id="fl-main-content" itemprop="mainContentOfPage" role="main"><div><div><div> <article class="page" id="fl-post-3685" itemscope="itemscope" itemtype="https://schema.org/CreativeWork"><div itemprop="text"><div data-post-id="3685"><div data-node="5a6231eab95f5"><div><div><div data-node="5a6231eabb645"><div data-node="5a6231eabb73b"><div><div data-node="5a6232f4062a8"><p><h3> <span>A Guide To Maximizing Your Investment</span></h3></p></div></div></div></div></div></div></div><div data-node="5a6233592fd00"><div><div><div data-node="5a62335932e13"><div data-node="5a62335932f19"><div><div data-node="5a62338f22736"><div><div><div><div><div><p>You‚Äôve decided you need a 3D printer (or you haven‚Äôt ‚Äì yet ‚Äì and want to make that determination for yourself). With all of the 3D printers on the market today, how do you make the best decision for your needs long term?</p><p><strong>It begins with knowing your requirements, both present and future</strong>, and knowing what to look for in potential vendors and printer options.</p><p>Our Guide to Selecting an Industrial 3D Printer will help you answer those questions.</p><p>The guide also includes worksheets to capture your requirements and assess the vendor‚Äôs ability to meet your specifications.</p><p>3D printing can be a huge benefit for many companies when selected and executed upon properly. Our hope is that this guide will help you make the best choice for your needs, your budget and your business.</p></div></div></div></div></div></div></div></div></div></div></div></div></div></div> </article></div></div></div></div> </div></div>]]>
            </description>
            <link>https://pluralam.com/selecting-right-industrial-3d-printer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23886357</guid>
            <pubDate>Sun, 19 Jul 2020 01:51:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the Naturalness of Software (2012) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23886291">thread link</a>) | @tosh
<br/>
July 18, 2020 | https://amasad.me/public/natural.pdf | <a href="https://web.archive.org/web/*/https://amasad.me/public/natural.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://amasad.me/public/natural.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23886291</guid>
            <pubDate>Sun, 19 Jul 2020 01:36:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Close Are We to a Vaccine for Covid-19?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23885889">thread link</a>) | @kohtatsu
<br/>
July 18, 2020 | https://newsinteractives.cbc.ca/coronavirusvaccinetracker/ | <a href="https://web.archive.org/web/*/https://newsinteractives.cbc.ca/coronavirusvaccinetracker/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>

    <section>
      

      <p>
        An effective vaccine against the coronavirus that causes COVID-19 is everyone's hope for a real return to normal life. More than 100 teams of scientists around the world are working to develop and test a vaccine against the virus SARS-CoV-2 as quickly as possible. They're employing  a huge variety of strategies and technologies, including some that have never been used in an approved vaccine before.</p>

        <p>"It's a very fascinating and kind of impressive effort," said Dr. Lynora Saxinger, an infectious disease specialist at the at the University of Alberta in Edmonton.</p>
        <p>"It's absolutely crucial."</p>
        <p>Even in countries that have had a devastating number of deaths from COVID-19, there is nowhere close to a level of "herd immunity" within the population preventing the disease from spreading exponentially if we go back to normal levels of social interaction, she said.</p>

        </section>

        <section>

        <h2>How far are we from the first SARS-CoV-2 vaccine?</h2>
    
      <p>Typically, it takes an average of <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3603987/">more than 10 years</a> for a vaccine to get from <a href="https://www.cbc.ca/news/health/vaccine-clinical-trials-1.5580436">pre-clinical development (including animal testing) through three phases of clinical (human) trials</a> to market registration.</p>

      <p>The process has been fast-tracked  for COVID-19. The first human vaccine trials began in March, just two months after the virus and disease were identified. And <a href="https://www.cbc.ca/news/health/vaccine-clinical-trials-1.5580436">different phases of human trials</a> are being run in an overlapping fashion instead of one at time ‚Äî for example, Phase 2 might begin just a few weeks after the start of a six-month Phase 1 trial. </p>

      <p>Canada has a notably large number of vaccine candidates registered with the World Health Organization ‚Äî at least eight.</p>
     
      <div id="tableAll">
          <h2>Candidate vaccines in clinical trials</h2>
           
          
          
      </div>

    </section>

    
    <section>

      <h2>Multiple vaccines on the horizon?</h2>
    
      <p>Most vaccine candidates that make it to preclinical testing never make it to market (about <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3603987/">94 per cent fail, a 2013 study</a> found). But in this case, with so many different vaccines under development, there may still end up being multiple vaccines for the coronavirus, possibly using different strategies, Saxinger predicts.</p>

      <p>There are a number of potential advantages if that happens:
        </p><ul>
          <li>They'd be using different ingredients and manufacturing facilities and wouldn't be competing for resources ‚Äî allowing for more vaccine production.</li>
          <li>Different vaccines have different pros and cons. Some vaccines require more doses to be effective than others, while ease of manufacturing, testing and distribution varies.</li>
          <li>Some vaccines may be more suitable for some populations than others, due to factors such as age or genetics.</li>
        </ul>      
      

      <p>Stephen Barr is associate professor of microbiology and immunology who is part of a COVID-19 vaccine development team at at Western University in London, Ont. He noted that the "best" vaccine in the end may not be best for everybody. "But the second one might be, for those that don't respond, right? So it's always good to have these backup vaccines as well or vaccines that can be used in parallel around the world."</p>

    </section>


  <hr>

  <section>

    <section>

      
      <h3>Whole virus vaccines</h3>
    
      <p>These are the most traditional types of vaccine. They've been used for a long time, and most of us have had these kinds of vaccines.</p>

    </section>


   <section id="inactivated">

    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 112 112" role="presentation" focusable="false"><path d="m0 0h112v112h-112z" fill="none"></path><path d="m89.5327 69.0724a35.8635 35.8635 0 0 0 0-26.1448c8.4931 1.3366 21.9273-2.8676 14.9647-14.9276-6.9672-12.0676-17.334-2.5154-20.4155 5.5113a36.0045 36.0045 0 0 0 -22.6275-13.0986c5.3986-6.691 8.4634-20.4127-5.4544-20.4127s-10.853 13.7218-5.4544 20.4127a36.0045 36.0045 0 0 0 -22.6274 13.0988c-3.0814-8.0268-13.4482-17.5792-20.4156-5.5115-6.9626 12.06 6.4718 16.2643 14.9648 14.9275a35.8633 35.8633 0 0 0 0 26.145c-8.4927-1.3369-21.9274 2.8675-14.9648 14.9275 6.9674 12.0677 17.3344 2.515 20.4157-5.5118a36.0043 36.0043 0 0 0 22.6276 13.0988c-5.3988 6.6907-8.464 20.413 5.4541 20.413s10.8529-13.7223 5.4542-20.413a36.0044 36.0044 0 0 0 22.6276-13.0985c3.0814 8.0267 13.4482 17.5792 20.4156 5.5115 6.9626-12.06-6.4717-16.2643-14.9647-14.9276zm-33.5327 14.9276a28 28 0 1 1 28-28 28.0315 28.0315 0 0 1 -28 28z"></path></svg>

      <h4>Inactivated virus</h4>
    
      <p>In this case, the virus is grown in large quantities in cells, and then killed, often with a chemical, which is usually formaldehyde, but heat or radiation can also be used. Two kinds of flu vaccines are made this way, grown in either chicken eggs or mammalian cells.</p>


      <section>
        
        <h5>Pros</h5>
        <ul>
          <li>Unlike live virus vaccines, it can even be given to people with weakened immune systems.</li>
        </ul>

        <h5>Cons</h5>
        <ul>
          <li>It doesn't lead to as strong an immune response as a live virus. Several doses, including boosters at regular intervals, are usually necessary.</li>
          <li>It requires the virus to be grown in large quantities and that can take time and may not be as easy to scale up as other kinds of vaccines.</li>          
        </ul>
      </section>

      
    </section>


   <section id="live-attenuated-virus">

    <svg viewBox="0 0 112 112" xmlns="http://www.w3.org/2000/svg" role="presentation" focusable="false"><path d="m0 0h112v112h-112z" fill="none"></path><g fill="#231f20"><path d="m56 76a20 20 0 1 1 20-20 20.0226 20.0226 0 0 1 -20 20zm0-32a12 12 0 1 0 12 12 12.0134 12.0134 0 0 0 -12-12z"></path><path d="m89.6737 69.0477a16.4016 16.4016 0 0 0 2.8022-13.0477c-.2249-.9536-.852-2.6981-1.1775-3.6428a29.9568 29.9568 0 0 1 -2.097-9.4877c8.4686 1.5023 22.3507-2.6505 15.296-14.8695-6.6585-11.5329-16.4235-3.3187-19.9659 4.4384a15.4055 15.4055 0 0 0 -2.7391-2.2308c-2.3255-1.4014-5.0471-2.2822-7.3338-3.7583a62.0759 62.0759 0 0 1 -5.3209-4.062 15.8281 15.8281 0 0 0 -6.9439-2.9507c4.9088-6.9615 7.075-19.4366-6.1938-19.4366-14.4671 0-10.5854 14.8273-4.8058 21.1713a38.4909 38.4909 0 0 1 -9.68 1.7606 16.34 16.34 0 0 0 -11.3068 7.2757 42.3652 42.3652 0 0 0 -2.0215 4.0375c-2.705-8.1538-13.5027-18.6823-20.6833-6.2451-6.9226 11.99 6.32 16.2183 14.82 14.9529a16.177 16.177 0 0 0 -2.3634 14.5382l.7425 2.1517a27.9405 27.9405 0 0 1 2.0095 8.5581c.0041.3073.02.6147.042.9217-8.4726-1.4794-22.2926 2.6803-15.2506 14.8774 6.657 11.53 16.4192 3.3222 19.9637-4.4332a15.0734 15.0734 0 0 0 2.7414 2.2255c2.3253 1.4014 5.0471 2.2823 7.3338 3.7583a62.1105 62.1105 0 0 1 5.3208 4.062 15.9449 15.9449 0 0 0 6.9286 2.9716c-4.8982 6.9658-7.0461 19.4158 6.2091 19.4158 14.4627 0 10.5878-14.8184 4.8113-21.1656a29.8607 29.8607 0 0 1 7.39-1.5455 16.5826 16.5826 0 0 0 13.5915-7.4967 42.3263 42.3263 0 0 0 2.0215-4.0373c2.7048 8.1538 13.5025 18.6823 20.6831 6.2451 6.9237-11.9922-6.3239-16.2195-14.8237-14.9523zm-13.8037 6.8217-.5783 1.09c-1.3627 2.8509-4.561 4.2681-7.5733 4.325a38.5962 38.5962 0 0 0 -11.7184 2.8156 8.5269 8.5269 0 0 1 -9.5887-1.9372 38.5724 38.5724 0 0 0 -9.7175-6.0628 13.4634 13.4634 0 0 1 -1.6528-.8089 8 8 0 0 1 -4.1357-5.7276 43.325 43.325 0 0 0 -2.7681-13.0019 9.4512 9.4512 0 0 1 -.8393-5.3626 9.1253 9.1253 0 0 1 2.5394-4.7878 38.574 38.574 0 0 0 6.0627-9.7174 13.42 13.42 0 0 1 .8089-1.6528c1.3626-2.8509 4.5611-4.2681 7.5734-4.3249a39.1834 39.1834 0 0 0 11.156-2.5788 8.5927 8.5927 0 0 1 10.15 1.7 38.57 38.57 0 0 0 9.7179 6.0627 13.4849 13.4849 0 0 1 1.6528.8089c2.8508 1.3628 4.2679 4.5612 4.325 7.5734a39.1756 39.1756 0 0 0 2.5787 11.1561 9.4511 9.4511 0 0 1 .8394 5.3626 9.1257 9.1257 0 0 1 -2.5394 4.7878 38.1874 38.1874 0 0 0 -6.2927 10.2806z"></path></g></svg>

      <h4>Live, attenuated virus</h4>
    
      <p>In this case, viruses are also grown in cells, but instead of being killed they're  genetically "weakened" so they can't infect cells and reproduce as effectively. Traditionally, this was done by getting the virus to grow in and adapt to an environment different than the one they normally infect. That's the approach used for vaccines such as varicella (chicken pox) or yellow fever. The SARS-CoV-2 vaccine candidates of this type use a high-tech genetic engineering approach called "codon deoptimization," where the virus is rebuilt from scratch, incorporating targeted mutations that weaken it. None of these vaccine prototypes for COVID-19 have made it to human trials.</p>

      <section>
        
        <h5>Pros</h5>
        <ul>
          <li>Similar to real infection and usually provides long-lasting protection ‚Äî sometimes lifelong ‚Äî after one dose.</li>
        </ul>

        <h5>Cons</h5>
        <ul>
          <li>May not be suitable for people with weakened immune systems, long-term health problems, or people who've had organ transplants.</li>
          <li>Live viruses need to be refrigerated, making them more difficult to transport and unusable in countries without access to refrigeration.</li>
          <li>The virus must be grown in large quantities. That can take time and it may not be easy to scale up.</li>          
        </ul>
      </section>

      

    </section>

    
    <section>

      <hr>

      <h2>Vaccines that target part of a virus</h2>
    
        <p>These types of vaccines don't contain entire viruses. They present parts of viruses, such as proteins or sugars, to your immune system to help it learn to recognize the virus and build an immune response.</p>

        <p>In the case of SARS-CoV-2, the part of the virus that's typically targeted is the spike or "S" protein ‚Äî the projections on its outer coat that make it look like a crown under a microscope ("corona" means "crown.") That's the protein the virus uses to bind to human cells, allowing it to enter. </p>

        <p>What varies  among different vaccine candidates is the way they make the spike protein and get it into the body ‚Äî it may be injected directly, transported by a "carrier" virus that doesn't cause disease, or it may be manufactured by the human body itself using instructions encoded in DNA or RNA.</p>

    </section>

     <section id="protein-subunit">

    <svg viewBox="0 0 112 112" xmlns="http://www.w3.org/2000/svg" role="presentation" focusable="false"><g><circle cx="63.1726" cy="40.5452" r="12"></circle><circle cx="40.5452" cy="63.1726" r="12"></circle><circle cx="71.4548" cy="71.4548" r="12"></circle></g><path d="m0 0h112v112h-112z" fill="none"></path></svg>

      <h4>Protein subunit</h4>
    
      <p>With this type of vaccine, the protein is made outside the body. Traditionally, this was done by breaking whole viruses into pieces using detergent or a solvent such as ether. However, this can now be done with "recombinant" genetic technology, where the gene for a protein is inserted into another organism to grow the protein in large quantities. 
      </p>

      <section>
        
        <h5>Pros</h5>
        <ul>
          <li>Can be produced more quickly than live vaccines.</li>
        </ul>

        <h5>Cons</h5>
        <ul>
          <li>Doesn't generate as strong an immune response as whole virus vaccines. A compound called an adjuvant needs to be included to boost a patient's immune response.</li>
          <li>Can't be scaled up as quickly as production of RNA or DNA vaccines.</li>        
        </ul>
      </section>

      

    </section>

    


    <section id="virus-like-particles">

    <svg viewBox="0 0 112 112" xmlns="http://www.w3.org/2000/svg" role="presentation" focusable="false"><g><circle cx="56" cy="24" r="12"></circle><circle cx="56" cy="88" r="12"></circle><circle cx="28.2872" cy="40" r="12"></circle><circle cx="83.7128" cy="72" r="12"></circle><circle cx="28.2872" cy="72" r="12"></circle><circle cx="83.7128" cy="40" r="12"></circle></g><path d="m0 0h112v112h-112z" fill="none"></path></svg>

      <h4>Virus-like particles</h4>
    
      <p>These are a special class of subunit vaccines, where the proteins are self-assembled into artificial particles that are intended to look like viruses to the human immune system. They bind to and enter cells like a virus, which is different from the way individual protein subunits do.</p>

      <p>Some vaccines on the market that use VLPs include vaccines for HPV (human papilloma virus) and Hepatitis B.</p>

      <section>
        
        <h5>Pros</h5>
        <ul>
          <li>Produce a stronger immune response than regular subunit vaccines.</li>
          <li>Production is much faster than for traditional vaccines.</li>
        </ul>

        <h5>Cons</h5>
        <ul>
          <li>Ensuring stability and purification can add to production time.</li>
          <li>Can be hard to produce in large quantities.</li>   
        </ul>
      </section>

      
    </section>

    

    <section id="non-replicating-viral-vector">

    <svg viewBox="0 0 112 112" xmlns="http://www.w3.org/2000/svg" role="presentation" focusable="false"><path d="m0 0h112v112h-112z" fill="none"></path><g><path d="m89.5324 69.0725a35.8633 35.8633 0 0 0 0-26.145c8.493 1.3369 21.9276-2.8675 14.965-14.9275-6.9674-12.0678-17.3343-2.5151-20.4157 5.5117a36.0043 36.0043 0 0 0 -22.6275-13.0988c5.3987-6.6908 8.4637-20.4129-5.4542-20.4129s-10.8529 13.722-5.4543 20.4129a36.0043 36.0043 0 0 0 -22.6275 13.0984c-3.0815-8.0267-13.4482-17.5789-20.4156-5.5113-6.9626 12.06 6.4715 16.2642 14.9645 14.9276a35.8644 35.8644 0 0 0 0 26.1449c-8.493-1.3367-21.9271 2.8675-14.9645 14.9275 6.9672 12.0676 17.3341 2.5155 20.4156-5.5113a36.0048 36.0048 0 0 0 22.6275 13.0985c-5.3986 6.6908-8.4636 20.4128 5.4543 20.4128s10.8529-13.7221 5.4542-20.4129a36.0046 36.0046 0 0 0 22.6275-13.0987c3.0814 8.0268 13.4483 17.5794 20.4157 5.5116 6.9626-12.06-6.472-16.2644-14.965-14.9275zm-33.5324 14.9275a28 28 0 1 1 28-28 28.0314 28.0314 0 0 1 -28 28z"></path><path d="m43.3493 65.8223a4.0894 4.0894 0 0 0 .7723-4.5772 12.9764 12.9764 0 0 1 17.1235-17.1235 4.0894 4.0894 0 0 0 4.5772-.7723l.0006-.0006a3.9906 3.9906 0 0 0 -1.0946-6.4431 20.992 20.992 0 0 0 -27.8227 27.8227 3.9906 3.9906 0 0 0 6.4431 1.0946z"></path><path d="m68.6513 46.1771-.0006.0006a4.0894 4.0894 0 0 0 -.7723 4.5772 12.9764 12.9764 0 0 1 -17.1235 17.1235 4.0894 4.0894 0 0 0 -4.5772.7723l-.0006.0006a3.9906 3.9906 0 0 0 1.0946 6.4431 20.992 20.992 0 0 0 27.8227-27.8227 3.9906 3.9906 0 0 0 -6.4431-1.0946z"></path></g></svg>

      <h4>Non-replicating viral vector</h4>
    
      <p>Viral vectors are "carrier" viruses that don't cause the disease you're vaccinating against, such as COVID-19, but can be engineered to carry a piece of viruses such as SARS-CoV-2. Non-replicating viral vectors are viruses that have been genetically engineered so they can't replicate and cause disease. Then they're further modified to produce the protein for the disease you want, such as the coronavirus spike protein, and injected into the body to provoke an immune response.</p>

      <p>The viruses used by COVID-19 vaccine candidates include adenoviruses, MVA (modified vaccinia ankara, a weakened pox virus), parainfluenza and rabies.</p>

      <section>
        
        <h5>Pros</h5>
        <ul>
          <li>Generates more powerful immune response than subunit proteins.</li>
          <li>Some don't have to be stored at very low temperatures (according to China-based company CanSino), so they're viable for use in resource-limited tropical areas.</li>
        </ul>

        <h5>Cons</h5>
        <ul>          

          <li>People who have already been exposed to the viral vector, such as adenovirus, may be resistant.</li>
          <li>Harder to scale up than protein or DNA because a virus still needs to be grown.</li>
          <li>Because each virus can only infect one cell, large quantities of the virus need to be grown and injected, adding to production time.</li>   
        </ul>
      </section>

      

    </section>

    

    <section id="replicating-viral-vector">

    <svg viewBox="0 0 112.1136 112" xmlns="http://www.w3.org/2000/svg" role="presentation" focusable="false"><g><circle cx="77.6573" cy="59.4777" r="6"></circle><circle cx="85.6573" cy="73.3341" r="6"></circle><circle cx="93.6573" cy="59.4777" r="6"></circle><circle cx="37.2987" cy="40.137" r="6"></circle><circle cx="23.4423" cy="48.137" r="6"></circle><circle cx="37.2987" cy="56.137" r="6"></circle><circle cx="47.2269" cy="73.3331" r="6"></circle></g><path d="m0 0h112v112h-112z" fill="none"></path><path d="m111.56 59.6174a31.8978 31.8978 0 0 1 -2.0444-7.9993c.0021-1.2135-.149-2.9625-.1606-4.193a14.8194 14.8194 0 0 0 -4.5155-9.55 16.8631 16.8631 0 0 0 -4.6887-3.0675 16.8737 16.8737 0 0 1 -6.0433-4.9893 16.7294 16.7294 0 0 0 -13.0511-7.46c-3.29.02-6.6533-.2771-9.5345-1.9923a17.6146 17.6146 0 0 0 -14.5979-2.056c-3.0481 1.1222-6.3 1.8331-9.5356 1.0335a17.5134 17.5134 0 0 0 -16.2859 3.62c-2.6283 2.1057-5.874 3-9.1541 3.5445a16.1335 16.1335 0 0 0 -10.5679 7.891 39.1617 39.1617 0 0 1 -3.1157 5.3242 48.257 48.257 0 0 1 -4.2527 4.5575 14.93 14.93 0 0 0 -3.8211 11.6 55.9544 55.9544 0 0 0 1.4233 5.7832 33.1576 33.1576 0 0 1 .47 8.24 14.7352 14.7352 0 0 0 7.3817 12.3748l1.2245.7278c3.1212 1.5925 5.5 4.0988 7.84 6.6462a14.7762 14.7762 0 0 0 13.2246 3.922 28.4788 28.4788 0 0 1 10.1936-1.2971 24.5432 24.5432 0 0 0 13.24-1.1c.3186-.143 1.3477-.4868 1.6932-.62a8.8478 8.8478 0 0 1 6.9122.5269 36.1724 36.1724 0 0 0 5.1759 2.526 14.9127 14.9127 0 0 0 9.2805.0709c3.2267-1.24 6.489-2.3824 9.9915-2.4126 5.6884.11 11.5523-3.2194 13.8614-8.5118.3962-1.0208 1.0828-2.1492 1.5257-3.1347a33.386 33.386 0 0 1 5.0818-6.512 14.8836 14.8836 0 0 0 2.8491-13.4929zm-7.5036 5.4739a8.8473 8.8473 0 0 1 -2.5779 4.2855 29.6462 29.6462 0 0 0 -5.4171 7.6965c-.2681.6709-.8938 1.8976-1.2073 2.5654-2.415 4.7-7.5625 3.3425-11.797 4.2611a31.86 31.86 0 0 0 -4.5251 1.2635c-1.8986.7341-3.8971 1.6295-5.9868 1.21a19.6966 19.6966 0 0 1 -5.1585-2.3336 16.6507 16.6507 0 0 0 -11.6953-1.3667c-3.5533 1.1385-7.0761 2.7073-10.8991 1.9811a30.793 30.793 0 0 0 -12.8886.7521c-6.5187 2.1953-8.2463-2.5174-12.46-5.9751a43.799 43.799 0 0 0 -6.265-4.1454c-2.5329-1.4867-3.4956-4.5724-3.1621-7.346a28.9717 28.9717 0 0 0 -1.0341-9.3548c-1.1236-2.9685-1.5217-6.5122.8679-8.9959a32.5171 32.5171 0 0 0 7.0043-8.6724c1.4-2.9875 3.3567-6.0911 6.8766-6.7063a26.0119 26.0119 0 0 0 11.1127-4.2256c2.6143-2.0854 5.6849-4.0746 9.21-3.2488a23.5549 23.5549 0 0 0 12.219.0622c4.1764-1.5474 7.6086-2.0814 11.5251.5422a22.6856 22.6856 0 0 0 9.8578 2.8211c2.1459.1215 4.4293-.12 6.383.9667a10.2676 10.2676 0 0 1 3.8555 3.5776 23.6337 23.6337 0 0 0 7.635 6.5688c.7164.3909 1.7728.9692 2.5046 1.3082a7.625 7.625 0 0 1 3.5255 7.19 30.4489 30.4489 0 0 0 1.8338 10.3536 8.6671 8.6671 0 0 1 .6626 4.965z"></path></svg>

      <h4>Replicating viral vector</h4>
    
      <p>These are "carrier" viruses that can replicate in the body, but are either weakened or don't cause any symptoms in humans. Like non-replicating viral vectors, they're modified to produce a protein from the virus you want to protect against, such as the spike protein from SARS-CoV-2.</p>


      <p>The replicating viral vectors used in COVID-19 vaccine candidates include weakened versions of influenza and measles, as well viruses that cause animal diseases such as horsepox and VSV (Vesicular stomatitis virus).</p>

      <section>
     
        <h5>Pros</h5>
        <ul>
          <li>Closely mimics a real infection and induces a stronger, more widespread immune response.</li>
          <li>Because it can replicate, much less virus needs to be injected as a vaccine to induce a good response.</li>
          <li>That also means less needs to be grown to produce the ‚Ä¶</li></ul></section></section></section></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://newsinteractives.cbc.ca/coronavirusvaccinetracker/">https://newsinteractives.cbc.ca/coronavirusvaccinetracker/</a></em></p>]]>
            </description>
            <link>https://newsinteractives.cbc.ca/coronavirusvaccinetracker/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23885889</guid>
            <pubDate>Sun, 19 Jul 2020 00:09:37 GMT</pubDate>
        </item>
    </channel>
</rss>
