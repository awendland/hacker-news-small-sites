<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 22 Sep 2020 16:25:58 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 22 Sep 2020 16:25:58 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Aligning Span Annotations to Hugginface Tokenizers]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24541780">thread link</a>) | @talolard
<br/>
September 21, 2020 | https://www.lighttag.io/blog/sequence-labeling-with-transformers/example | <a href="https://web.archive.org/web/*/https://www.lighttag.io/blog/sequence-labeling-with-transformers/example">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote>
<p><em>This post <a href="https://github.com/LightTag/sequence-labeling-with-transformers">comes with a repo</a></em></p>
</blockquote>
<p>Our previous post on
<a href="https://www.lighttag.io/blog/sequence-labeling-with-transformers/">aligning span annotations to Hugginface's tokenizer outputs</a>
discussed the various tradeoffs one needs to consider, and concluded that a windowing strategy over the tokenized text
and labels is optimal for our use cases. </p>
<p>This post demonstrates an end to end implementation of token alignment and windowing. We'll start by implementing
utility classes that make programming a little easier, then implement the alignment functionality which aligns offset
annotations to the out of a tokenizer. Finnaly we'll implement a PyTorch Dataset that stores our aligned tokens and
labels as windows, a Collator to implement batching and a simple DataLoader to be used in training. </p>
<p>We'll show and end to end flow on the DDI Corpus, recognizing pharmacological entities with BERT.</p>
<h2>Utility Classes For Convenient APIs</h2>
<p>We'll start by defining some types and utility classes that will make our work more convenient</p>
<div data-language="python"><pre><code><span>from</span> typing_extensions <span>import</span> TypedDict
<span>from</span> typing <span>import</span> List<span>,</span>Any
IntList <span>=</span> List<span>[</span><span>int</span><span>]</span> 
IntListList <span>=</span> List<span>[</span>IntList<span>]</span> </code></pre></div>

<h2>The Alignment Algorithm</h2>
<h3>FastTokenizers Simplify Alignment</h3>
<p>Recent versions of Hugginface's tokenizers library include variants of Tokenizers that end with Fast and inherit
from <a href="https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.PreTrainedTokenizerFast">PreTrainedTokenizerFast</a><br>
such as <a href="https://huggingface.co/transformers/model_doc/bert.html#berttokenizerfast">BertTokenizerFast</a>
and <a href="https://huggingface.co/transformers/model_doc/gpt2.html#gpt2tokenizerfast">GPT2TokenizerFast</a>. </p>
<p>Per the tokenizer's documentation</p>
<blockquote>
<p>When the tokenizer is a “Fast” tokenizer (i.e., backed by HuggingFace tokenizers library), [the output] provides in addition several advanced alignment methods which can be used to map between the original string (character and words) and the token space (e.g., getting the index of the token comprising a given character or the span of characters corresponding to a given token).</p>
</blockquote>
<p>Notably, the output provides the methods
<a href="https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.BatchEncoding.token_to_chars">token<em>to</em>chars</a>
and <a href="https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.BatchEncoding.char_to_token">char<em>to</em>token</a>
which do exactly what their name implies, provide mappings between tokens and character offsets in the original text.
That's exactly what we need to align annotations in offset format with tokens.</p>
<h2>A warmup implementation</h2>
<p>Our final implementation will use the BIOUL scheme we mentioned before. But before we do that, let's try a simple
alignment to see what it feels like</p>
<div data-language="python"><pre><code>text <span>=</span> <span>"I am Tal Perry, founder of LightTag"</span>
annotations <span>=</span> <span>[</span>
    <span>dict</span><span>(</span>start<span>=</span><span>5</span><span>,</span>end<span>=</span><span>14</span><span>,</span>text<span>=</span><span>"Tal Perry"</span><span>,</span>label<span>=</span><span>"Person"</span><span>)</span><span>,</span>
    <span>dict</span><span>(</span>start<span>=</span><span>16</span><span>,</span>end<span>=</span><span>23</span><span>,</span>text<span>=</span><span>"founder"</span><span>,</span>label<span>=</span><span>"Title"</span><span>)</span><span>,</span>
    <span>dict</span><span>(</span>start<span>=</span><span>27</span><span>,</span>end<span>=</span><span>35</span><span>,</span>text<span>=</span><span>"LightTag"</span><span>,</span>label<span>=</span><span>"Org"</span><span>)</span><span>,</span>
    
              <span>]</span>
<span>for</span> anno <span>in</span> annotations<span>:</span>
    
    <span>print</span> <span>(</span>text<span>[</span>anno<span>[</span><span>'start'</span><span>]</span><span>:</span>anno<span>[</span><span>'end'</span><span>]</span><span>]</span><span>,</span>anno<span>[</span><span>'label'</span><span>]</span><span>)</span>
    </code></pre></div>
<div data-language="text"><pre><code>Tal Perry Person
founder Title
LightTag Org</code></pre></div>
<div data-language="python"><pre><code><span>from</span> transformers <span>import</span> BertTokenizerFast<span>,</span>  BatchEncoding
<span>from</span> tokenizers <span>import</span> Encoding
tokenizer <span>=</span> BertTokenizerFast<span>.</span>from_pretrained<span>(</span><span>'bert-base-cased'</span><span>)</span> 
tokenized_batch <span>:</span> BatchEncoding <span>=</span> tokenizer<span>(</span>text<span>)</span>
tokenized_text <span>:</span>Encoding  <span>=</span>tokenized_batch<span>[</span><span>0</span><span>]</span></code></pre></div>
<div data-language="python"><pre><code>tokens <span>=</span> tokenized_text<span>.</span>tokens
aligned_labels <span>=</span> <span>[</span><span>"O"</span><span>]</span><span>*</span><span>len</span><span>(</span>tokens<span>)</span> 
<span>for</span> anno <span>in</span> <span>(</span>annotations<span>)</span><span>:</span>
    <span>for</span> char_ix <span>in</span> <span>range</span><span>(</span>anno<span>[</span><span>'start'</span><span>]</span><span>,</span>anno<span>[</span><span>'end'</span><span>]</span><span>)</span><span>:</span>
        token_ix <span>=</span> tokenized_text<span>.</span>char_to_token<span>(</span>char_ix<span>)</span>
        <span>if</span> token_ix <span>is</span> <span>not</span> <span>None</span><span>:</span> 
            aligned_labels<span>[</span>token_ix<span>]</span> <span>=</span> anno<span>[</span><span>'label'</span><span>]</span>
<span>for</span> token<span>,</span>label <span>in</span> <span>zip</span><span>(</span>tokens<span>,</span>aligned_labels<span>)</span><span>:</span>
    <span>print</span> <span>(</span>token<span>,</span><span>"-"</span><span>,</span>label<span>)</span></code></pre></div>
<div data-language="text"><pre><code>[CLS] - O
I - O
am - O
Ta - Person
##l - Person
Perry - Person
, - O
founder - Title
of - O
Light - Org
##T - Org
##ag - Org
[SEP] - O</code></pre></div>
<h3>Accounting For Multi Token Annotations</h3>
<p>In the above example, some of our annotations spanned multiple tokens.
For instance "Tal Perry" spanned "Ta", "##l" and "Perry". Clearly by themselves none of those tokens are a Person, and
so our current alignment scheme isn't as useful as it could be.
To overcome that, we'll use the previously mentioned BIOLU scheme, which will indicate if a token is the beginning,
inside, last token in an annotation or if it is not part of an annotation or if it is perfectly aligned with an annotation.</p>
<div data-language="python"><pre><code><span>def</span> <span>align_tokens_and_annotations_bilou</span><span>(</span>tokenized<span>:</span> Encoding<span>,</span> annotations<span>)</span><span>:</span>
    tokens <span>=</span> tokenized<span>.</span>tokens
    aligned_labels <span>=</span> <span>[</span><span>"O"</span><span>]</span> <span>*</span> <span>len</span><span>(</span>
        tokens
    <span>)</span>  
    <span>for</span> anno <span>in</span> annotations<span>:</span>
        annotation_token_ix_set <span>=</span> <span>(</span>
            <span>set</span><span>(</span><span>)</span>
        <span>)</span>  
        <span>for</span> char_ix <span>in</span> <span>range</span><span>(</span>anno<span>[</span><span>"start"</span><span>]</span><span>,</span> anno<span>[</span><span>"end"</span><span>]</span><span>)</span><span>:</span>

            token_ix <span>=</span> tokenized<span>.</span>char_to_token<span>(</span>char_ix<span>)</span>
            <span>if</span> token_ix <span>is</span> <span>not</span> <span>None</span><span>:</span>
                annotation_token_ix_set<span>.</span>add<span>(</span>token_ix<span>)</span>
        <span>if</span> <span>len</span><span>(</span>annotation_token_ix_set<span>)</span> <span>==</span> <span>1</span><span>:</span>
            
            token_ix <span>=</span> annotation_token_ix_set<span>.</span>pop<span>(</span><span>)</span>
            prefix <span>=</span> <span>(</span>
                <span>"U"</span>  
            <span>)</span>
            aligned_labels<span>[</span>token_ix<span>]</span> <span>=</span> <span><span>f"</span><span><span>{</span>prefix<span>}</span></span><span>-</span><span><span>{</span>anno<span>[</span><span>'label'</span><span>]</span><span>}</span></span><span>"</span></span>

        <span>else</span><span>:</span>

            last_token_in_anno_ix <span>=</span> <span>len</span><span>(</span>annotation_token_ix_set<span>)</span> <span>-</span> <span>1</span>
            <span>for</span> num<span>,</span> token_ix <span>in</span> <span>enumerate</span><span>(</span><span>sorted</span><span>(</span>annotation_token_ix_set<span>)</span><span>)</span><span>:</span>
                <span>if</span> num <span>==</span> <span>0</span><span>:</span>
                    prefix <span>=</span> <span>"B"</span>
                <span>elif</span> num <span>==</span> last_token_in_anno_ix<span>:</span>
                    prefix <span>=</span> <span>"L"</span>  
                <span>else</span><span>:</span>
                    prefix <span>=</span> <span>"I"</span>  
                aligned_labels<span>[</span>token_ix<span>]</span> <span>=</span> <span><span>f"</span><span><span>{</span>prefix<span>}</span></span><span>-</span><span><span>{</span>anno<span>[</span><span>'label'</span><span>]</span><span>}</span></span><span>"</span></span>
    <span>return</span> aligned_labels


labels <span>=</span> align_tokens_and_annotations_bilou<span>(</span>tokenized_text<span>,</span> annotations<span>)</span>
<span>for</span> token<span>,</span> label <span>in</span> <span>zip</span><span>(</span>tokens<span>,</span> labels<span>)</span><span>:</span>
    <span>print</span><span>(</span>token<span>,</span> <span>"-"</span><span>,</span> label<span>)</span></code></pre></div>
<div data-language="text"><pre><code>[CLS] - O
I - O
am - O
Ta - B-Person
##l - I-Person
Perry - L-Person
, - O
founder - U-Title
of - O
Light - B-Org
##T - I-Org
##ag - L-Org
[SEP] - O</code></pre></div>
<p>Notice how <strong>founder</strong> above has a <strong>U</strong> prefix and the other annotations now follow a BIL scheme.</p>
<h3>Mapping Labels To Ids</h3>
<p>It's great that we have our annotations aligned, but we need the labels as integer ids for training.
During inference, we'll also need a way to map predicted ids back to labels.
I'm going to make a custom class that handles that, called a LabelSet. </p>
<div data-language="python"><pre><code><span>import</span> itertools


<span>class</span> <span>LabelSet</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span>self<span>,</span> labels<span>:</span> List<span>[</span><span>str</span><span>]</span><span>)</span><span>:</span>
        self<span>.</span>labels_to_id <span>=</span> <span>{</span><span>}</span>
        self<span>.</span>ids_to_label <span>=</span> <span>{</span><span>}</span>
        self<span>.</span>labels_to_id<span>[</span><span>"O"</span><span>]</span> <span>=</span> <span>0</span>
        self<span>.</span>ids_to_label<span>[</span><span>0</span><span>]</span> <span>=</span> <span>"O"</span>
        num <span>=</span> <span>0</span>  
        
        <span>for</span> _num<span>,</span> <span>(</span>label<span>,</span> s<span>)</span> <span>in</span> <span>enumerate</span><span>(</span>itertools<span>.</span>product<span>(</span>labels<span>,</span> <span>"BILU"</span><span>)</span><span>)</span><span>:</span>
            num <span>=</span> _num <span>+</span> <span>1</span>  
            l <span>=</span> <span><span>f"</span><span><span>{</span>s<span>}</span></span><span>-</span><span><span>{</span>label<span>}</span></span><span>"</span></span>
            self<span>.</span>labels_to_id<span>[</span>l<span>]</span> <span>=</span> num
            self<span>.</span>ids_to_label<span>[</span>num<span>]</span> <span>=</span> l
        

    <span>def</span> <span>get_aligned_label_ids_from_annotations</span><span>(</span>self<span>,</span> tokenized_text<span>,</span> annotations<span>)</span><span>:</span>
        raw_labels <span>=</span> align_tokens_and_annotations_bilou<span>(</span>tokenized_text<span>,</span> annotations<span>)</span>    
        <span>return</span> <span>list</span><span>(</span><span>map</span><span>(</span>self<span>.</span>labels_to_id<span>.</span>get<span>,</span> raw_labels<span>)</span><span>)</span>


example_label_set <span>=</span> LabelSet<span>(</span>labels<span>=</span><span>[</span><span>"Person"</span><span>,</span> <span>"Org"</span><span>,</span> <span>"Title"</span><span>]</span><span>)</span>
aligned_label_ids <span>=</span> example_label_set<span>.</span>get_aligned_label_ids_from_annotations<span>(</span>
    tokenized_text<span>,</span> annotations
<span>)</span>

<span>for</span> token<span>,</span> label <span>in</span> <span>zip</span><span>(</span>tokens<span>,</span> aligned_label_ids<span>)</span><span>:</span>
    <span>print</span><span>(</span>token<span>,</span> <span>"-"</span><span>,</span> label<span>)</span></code></pre></div>
<div data-language="text"><pre><code>[CLS] - 0
I - 0
am - 0
Ta - 1
##l - 2
Perry - 3
, - 0
founder - 12
of - 0
Light - 5
##T - 6
##ag - 7
[SEP] - 0</code></pre></div>

<p>Now that we have alignment logic in place, we need to figure out how to load, batch and pad the data. We also need
to handle the case where our text is longer than we can feed our model. Below we show an implementation of a
particular strategy, windowing over uniform length segments of the text. This isn't the only strategy, or even
necessarily the best, but it fits our use case well. You can read more about
why <a href="https://www.lighttag.io/blog/sequence-labeling-with-transformers/">we use windowing when training ner models with BERT here</a>.
Below we'll just show how to do that.</p>
<h2>The Raw Dataset</h2>
<p>We'll be using the <a href="https://www.sciencedirect.com/science/article/pii/S1532046413001123">DDI Corpus</a>. You can download
a JSON verion of it  <a href="https://github.com/LightTag/DDICorpus">here</a>.
Let's take a quick look at the data</p>
<div data-language="python"><pre><code><span>import</span> json
<span>from</span> pprint <span>import</span> pprint

raw <span>=</span> json<span>.</span>load<span>(</span><span>open</span><span>(</span><span>"./ddi_train.json"</span><span>)</span><span>)</span>
<span>for</span> example <span>in</span> raw<span>:</span>
    
    <span>for</span> anno <span>in</span> example<span>[</span><span>"annotations"</span><span>]</span><span>:</span>
        anno<span>[</span><span>"label"</span><span>]</span> <span>=</span> anno<span>[</span><span>"tag"</span><span>]</span>
pprint<span>(</span>raw<span>[</span><span>2</span><span>]</span><span>)</span></code></pre></div>
<div data-language="text"><pre><code>{'annotations': [{'end': 58, 'label': 'drug', 'start': 47, 'tag': 'drug'},
                 {'end': 75, 'label': 'drug', 'start': 62, 'tag': 'drug'},
                 {'end': 135, 'label': 'drug', 'start': 124, 'tag': 'drug'},
                 {'end': 164, 'label': 'drug', 'start': 152, 'tag': 'drug'}],
 'content': 'Pharmacokinetic studies have demonstrated that omeprazole and '
            'erythromycin significantly increased the systemic exposure of '
            'cilostazol and/or its major metabolites.',
 'metadata': {'original_id': 'DrugDDI.d452.s1'}}</code></pre></div>
<p>Lets take a look at that tokenized and aligned</p>
<div data-language="python"><pre><code>example <span>=</span> raw<span>[</span><span>2</span><span>]</span>
tokenized_batch <span>=</span> tokenizer<span>(</span>example<span>[</span><span>"content"</span><span>]</span><span>)</span>
tokenized_text <span>=</span> tokenized_batch<span>[</span><span>0</span><span>]</span>
labels <span>=</span> align_tokens_and_annotations_bilou<span>(</span>tokenized_text<span>,</span> example<span>[</span><span>"annotations"</span><span>]</span><span>)</span>
<span>for</span> token<span>,</span> label <span>in</span> <span>zip</span><span>(</span>tokenized_text<span>.</span>tokens<span>,</span> labels<span>)</span><span>:</span>
    <span>print</span><span>(</span>token<span>,</span> <span>"-"</span><span>,</span> label<span>)</span></code></pre></div>
<div data-language="text"><pre><code>[CLS] - O
Ph - O
##arma - O
##co - O
##kin - O
##etic - O
studies - O
have - O
demonstrated - O
that - O
o - B-drug
##me - I-drug
##pra - I-drug
##zo - I-drug
##le - L-drug
and - O
er - B-drug
##yt - I-drug
##hr - I-drug
##omy - I-drug
##cin - L-drug
significantly - O
increased - O
the - O
systemic - O
exposure - O
of - O
c - B-drug
##ilo - I-drug
##sta - I-drug
##zo - I-drug
##l - L-drug
and - O
/ - O
or - O
its - O
major - O
meta - B-drug
##bol - I-drug
##ites - I-drug
. - L-drug
[SEP] - O</code></pre></div>
<h2>Padding and Windowing in a Dataset</h2>
<p>Our dataset is conveniently split into sentences. We still need to batch it and pad the examples.
More commonly, data is not split into sentences, and so we will window over fixed sized parts of it.
The windowing, padding and alignment logic will be done in a pytorch Dataset and we'll get to batching in a moment.</p>
<div data-language="python"><pre><code><span>from</span> dataclasses <span>import</span> dataclass
<span>from</span> torch<span>.</span>utils<span>.</span>data <span>import</span> Dataset
<span>from</span> transformers <span>import</span> PreTrainedTokenizerFast</code></pre></div>
<div data-language="python"><pre><code><span>@dataclass</span>
<span>class</span> <span>TrainingExample</span><span>:</span>
    input_ids<span>:</span> IntList
    attention_masks<span>:</span> IntList
    labels<span>:</span> IntList


<span>class</span> <span>TraingDataset</span><span>(</span>Dataset<span>)</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span>
        self<span>,</span>
        data<span>:</span> Any<span>,</span>
        label_set<span>:</span> LabelSet<span>,</span>
        tokenizer<span>:</span> PreTrainedTokenizerFast<span>,</span>
        tokens_per_batch<span>=</span><span>32</span><span>,</span>
        window_stride<span>=</span><span>None</span><span>,</span>
    <span>)</span><span>:</span>
        self<span>.</span>label_set <span>=</span> label_set
        <span>if</span> window_stride <span>is</span> <span>None</span><span>:</span>
            self<span>.</span>window_stride <span>=</span> tokens_per_batch
        self<span>.</span>tokenizer <span>=</span> tokenizer
        <span>for</span> example <span>in</span> data<span>:</span>
            
            <span>for</span> a <span>in</span> example<span>[</span><span>"annotations"</span><span>]</span><span>:</span>
        …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lighttag.io/blog/sequence-labeling-with-transformers/example">https://www.lighttag.io/blog/sequence-labeling-with-transformers/example</a></em></p>]]>
            </description>
            <link>https://www.lighttag.io/blog/sequence-labeling-with-transformers/example</link>
            <guid isPermaLink="false">hacker-news-small-sites-24541780</guid>
            <pubDate>Mon, 21 Sep 2020 10:34:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to catch a spy that is using a numbers station – The KGB Experience]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24541163">thread link</a>) | @Shaddox
<br/>
September 21, 2020 | https://www.numbers-stations.com/how-to-catch-a-spy-who-uses-numbers-stations-the-kgb-experience/ | <a href="https://web.archive.org/web/*/https://www.numbers-stations.com/how-to-catch-a-spy-who-uses-numbers-stations-the-kgb-experience/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div id="attachment_166048"><p><a href="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?ssl=1"><img aria-describedby="caption-attachment-166048" src="https://i2.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547.jpg?resize=183%2C300&amp;ssl=1" alt="" width="183" height="300" srcset="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?resize=183%2C300&amp;ssl=1 183w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?resize=624%2C1024&amp;ssl=1 624w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?resize=768%2C1261&amp;ssl=1 768w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?resize=935%2C1536&amp;ssl=1 935w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?resize=1247%2C2048&amp;ssl=1 1247w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?w=1559&amp;ssl=1 1559w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?w=1500&amp;ssl=1 1500w" sizes="(max-width: 183px) 100vw, 183px" data-recalc-dims="1"></a></p><p id="caption-attachment-166048">Cover of the KGB manual. Mobile screen grab from Latvian national archive</p></div>


<p>From 2019 onwards the Latvian National Archive offers access to various KGB documents. The author had already previously shown the very detailed efforts of the Latvian KGB counterintelligence to monitor and study the CIA and BND numbers stations broadcasts, or what they called – “one directional communications”.<a href="#_ftn1" name="_ftnref1"><sup>[1]</sup></a> These are one of the most definitive archival sources which prove that foreign intelligence actively used shortwave in the USSR and that the KGB was aware of it. The documents showed that the KGB had monitored these broadcasts from at least 1978, but the files spoke very vaguely if the monitoring effort led to any apprehension and capture of a foreign agent. We, however, know that there were such cases like Alexander Ogorodnik<a href="#_ftn2" name="_ftnref2"><sup>[2]</sup></a>, and others where the use of shortwave signals was determined.</p>
<p>The Latvian National Archive digitized operational cases and also special KGB training manuals. These manuals were published for inner agency use and were never issued in public because they contained secret information. One such manual called “<em>Некоторые вопросы организаций работы по сигналам и делам оперативного учета лиц причастий в шпионажу”</em> published in 1985 by KGB of F. E Dzherzhinsky in Moscow.<a href="#_ftn3" name="_ftnref3"><sup>[3]</sup></a> (A few issues on organizing work on signals and cases recognizing persons taking part in espionage”). The manual was credited to major general A. A Fabrichinikov and colonel V.V Holopov The word “signal” in the title does not mean just a radio signal. In the KGB terminology “signal” meant a sign or report of a foreign intelligence or anti Soviet activity. If this “signal” indicated that the person is taking part in espionage he had to be investigated and evidence to be collected. The manual showed various historical cases as examples on how to apprehend and capture a foreign agent.</p>



<p>One such case was called” Case on Filatov”. Starting from page 41 the manual examples this case as one of the cases where radio communication was used between the agency and agent and how it was uncovered by counter intelligence. <strong>Anatoly N. Filatov</strong> was according to a 1981 Washington Post report sentenced in 1978 to be shot by a firing squad, though the sentence was commuted later to 15 years in prison.<a href="#_ftn4" name="_ftnref4"><sup>[4]</sup></a> A New York Times article in 1980 had rumored that A. Filatov was the same “Trigon” who is now commonly known as Alexandr Ogorodnik. The article states that A. Filatov was suspected of being discovered by the KGB counterintelligence and forced to send the CIA false information. The reasoning behind this hypothesis was that in 1977 “Trigon” went dark at the same time as A. Filatov sent a very questionable cable about Secretary of State Henry Kissinger, where he questioned the “bargaining position of president Carter” during the 1977 missile control talks.<a href="#_ftn5" name="_ftnref5"><sup>[5]</sup></a> Alexander Ogorodnik aka “Trigon” died on June 22 1977 after swallowing cyanide pills during a KGB break in.<a href="#_ftn6" name="_ftnref6"><sup>[6]</sup></a></p>
<p>David E. Hoffman, author of the book “The Million Dollar Spy” states that Filatov was arrested during a “car toss”, where a package is quickly swapped between two passing cars.<a href="#_ftn7" name="_ftnref7"><sup>[7]</sup></a> Russian author Aleksandr Kolpakidi in his book “The GRU Empire” writes that Filatov was born in 1940 in the Saratov district, joined the GRU in 1973. (GRU – the Main Intelligence Directorate – Soviet military intelligence agency) and served in Algiers where in 1974 he established contact with the CIA. Filatov had stated that his involvement with the adversary CIA happened as a result of being lured into a honey trap with a woman called Nadia, as similar happened to&nbsp; A. Ogorodnik. Either so or A. Filatov himself decided to become a double agent and started meeting CIA agent Edward Kane. In 1976 A. Filatov was called back to Moscow and the CIA had instructed him to receive shortwave coded broadcasts in German numbers from Frankfurt near Main, the broadcasts were to be carried out twice a week. Operative broadcast would be started with uneven numbers and training with even numbers. The broadcasts on precaution were carried out before A. Filatov returned to Moscow. The return message was to be carried out in a dead drop in an area near Dinamo sports stadium.</p>
<p>As the author states the coded messages contained such instructions: “Do not contain yourself with gathering information within your service only. Gain trust of friends and relatives. Visit them at their workplaces, their homes, invite them to restaurants, and with careful, clever talking gain information you could not get yourself”<a href="#_ftn8" name="_ftnref8"><sup>[8]</sup></a>. The instructions also stated that the agency is not just interested in documents with “Top Secret” on it but also common information about his department and situation in it. Filatov was arrested on the 2nd of September 1977. As A. Kolpakidi states he was first sentenced to death in 1978 but instead was sent to labor camp 389/35 near Perm. In 1989 Filatov was visited by French journalists to whom he stated that he took very high stakes risks in his life which he lost and now naturally pays for it.</p>
<p>After release he demanded compensation from the US embassy, but was denied as a non citizen. The Russian TV company TV Center in 2014 made the documentary series “Завербуй меня, если сможешь” (Contract me if you can) and featured the A. Filatov case showing various pictures of him and accounts from his colleagues, such as Anatoly Tereshchenko, colonel of the military counter intel. Tereshchenko stated that if A. Filatov had come to the GRU and reported that he was lured into cooperation with the CIA, they could outplay the CIA, and Filatov would be a hero.<a href="#_ftn9" name="_ftnref9"><sup>[9]</sup></a> What became of Filatov after his release, is not known, the TV documentary showed his picture after his release. Possibly A. Filatov is dead now.</p>
<div id="attachment_166050"><p><a href="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov.png?ssl=1"><img aria-describedby="caption-attachment-166050" src="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov.png?resize=300%2C177&amp;ssl=1" alt="" width="300" height="177" srcset="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov.png?resize=300%2C177&amp;ssl=1 300w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov.png?resize=768%2C453&amp;ssl=1 768w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov.png?w=873&amp;ssl=1 873w" sizes="(max-width: 300px) 100vw, 300px" data-recalc-dims="1"></a></p><p id="caption-attachment-166050">Anatoly Filatov</p></div>
<div id="attachment_166051"><p><a href="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov_2.png?ssl=1"><img aria-describedby="caption-attachment-166051" src="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov_2.png?resize=300%2C173&amp;ssl=1" alt="" width="300" height="173" srcset="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov_2.png?resize=300%2C173&amp;ssl=1 300w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov_2.png?resize=768%2C442&amp;ssl=1 768w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov_2.png?w=871&amp;ssl=1 871w" sizes="(max-width: 300px) 100vw, 300px" data-recalc-dims="1"></a></p><p id="caption-attachment-166051">Anatoly Filatov years after the arrest</p></div>
<p>What will follow is a translation from Russian to English from the mentioned KGB manual, where the case about Filatov is described as an example of apprehending and capturing foreign spies who use radio signals and codes. With photo scans of included photo evidence.</p>

<p><em>Start of the original translation</em></p>
<div id="attachment_166052"><p><a href="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135640-scaled.jpg?ssl=1"><img aria-describedby="caption-attachment-166052" src="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135640.jpg?resize=225%2C300&amp;ssl=1" alt="" width="225" height="300" srcset="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135640-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135640-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135640-scaled.jpg?resize=1152%2C1536&amp;ssl=1 1152w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135640-scaled.jpg?resize=1536%2C2048&amp;ssl=1 1536w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135640-scaled.jpg?w=1920&amp;ssl=1 1920w" sizes="(max-width: 225px) 100vw, 225px" data-recalc-dims="1"></a></p><p id="caption-attachment-166052">First page in the manual about A.FIlatov case</p></div>
<p>The case regarding American agent Filatov is particularly useful for agency and operative workers. Two agents who worked on this case had limited, but clear objectives: one controlled his work shifts, the other one lured him to a position within a GRU object (facility), where he was arrested. Secondary events were mostly carried out by the workers of the operational staff.</p>
<p>In the case materials the use of operational technical and criminal resources is very clearly displayed. The workers of the operational services had a clear objective: gain information about practical espionage activity.</p>
<p>A lot of support for apprehending the spy was provided by the GRU radio counterintelligence. During the first phase of the operation the counter radio intelligence played a helpful, but mostly backseat role, in terms of gaining radio information. However, after Filatov was discovered in possession of multiple ciphers the RCI<a href="#_ftn11" name="_ftnref11"><sup>[11]</sup></a> played the most active role in gaining information about the adversary’s plans for their agent. It must be asserted that the RCI data about the new communication line only gained importance after comprehensive analysis about known agents and data gained from agency postal communication lines.</p>
<p>It is useful to take note of the surveillance tactics used to monitor&nbsp; FIlatov, during all phases of the operation. Here the artistic use of surveillance, determination of the personality of the object, working out on his work conditions and living place (such an approach is essential for any future attempts for apprehending an adversary agent).</p>
<p>Finally it’s important to point out the very high level of secrecy is required to successfully&nbsp; carry out the operation, with minimal numbers&nbsp; of agents and operative staff workers as reglamented by the authority of KGB, and adjusted fully to the set parameters.</p>
<p>All this taken to an account assured that the case was carried out in highest quality the tasks were carried out decisively.</p>
<p>“””</p>
<p>The investigation into the incoming signals, and the timeline for the search for the CIA agent Filatov took place in the following order.</p>
<p>At the start of 1977 the second chief directorate of the KGB had received data that led to the belief that a new agent from American intelligence had become active within Soviet Union.</p>
<p>On January 21 and February 6 1977 the RCI had detected the transmission of operational (combat)<a href="#_ftn12" name="_ftnref12"><sup>[12]</sup></a> radiograms on the communication line sent from Frankfurt CIA radio center, that had appeared already in the first half of 1976.<a href="#_ftn13" name="_ftnref13"><sup>[13]</sup></a> With that the general reception of the radiograms was possible within the central part of European side of the USSR. <a href="#_ftn14" name="_ftnref14"><sup>[14]</sup></a></p>
<p>In this same timeframe espionage activity within CIA station inside the US embassy in Moscow, was observed to have increased, showing signs of preparing for creating operational dead drop communications, it was determined that these activities could not be part of the ongoing cases and operational games.</p>
<p>It was expected that the agent, after receiving operational radiograms, will likely make contact with the Frankfurt radio center using postal telegraph, telephone, dead drop, radio transmission or make a meeting with his handler, usually from US diplomatic service.</p>
<p>Taking this into account together with Operative-technical and Seventh authority of the KGB, extra measures were made to control the agency channels within Moscow and eavesdrop on CIA actions.</p>
<p>On February 9 1977 a postal parcel coming from Moscow to the US, a suspicious letter was identified which had signs which made its purpose likely being for espionage uses. This letter had a date indicating it was sent on February 7 and was written in the in English language “from English tourist”<a href="#_ftn15" name="_ftnref15"><sup>[15]</sup></a>. By using a physical-chemical method on the blank side of the letter, a cipher of 353 five number …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.numbers-stations.com/how-to-catch-a-spy-who-uses-numbers-stations-the-kgb-experience/">https://www.numbers-stations.com/how-to-catch-a-spy-who-uses-numbers-stations-the-kgb-experience/</a></em></p>]]>
            </description>
            <link>https://www.numbers-stations.com/how-to-catch-a-spy-who-uses-numbers-stations-the-kgb-experience/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24541163</guid>
            <pubDate>Mon, 21 Sep 2020 08:50:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facebook fears ruling may force it to pull social media platforms from EU]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 69 (<a href="https://news.ycombinator.com/item?id=24540991">thread link</a>) | @rusk
<br/>
September 21, 2020 | https://www.businesspost.ie/legal/facebook-fears-ruling-may-force-it-to-pull-social-media-platforms-from-eu-00644da4 | <a href="https://web.archive.org/web/*/https://www.businesspost.ie/legal/facebook-fears-ruling-may-force-it-to-pull-social-media-platforms-from-eu-00644da4">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="app">

        





<div>
    <div>
        <p>
            Tuesday September 22, 2020
        </p>
        
    </div>
</div>





        

        
    <div>
        
        
        <div>

            
            
                            <div>
                    
            
                            <p>Court filings show tech giant doesn’t believe it can convince Data Protection Commission to overturn preliminary ruling that bans transfer of data from EU to US</p>
                    
        
        

        
        
    </div>
            
                            
                <div id="img-article">
                    <figure>
                        
                        <figcaption>Under fire: Data Protection Commissioner Helen Dixon</figcaption>
                    </figure>
                </div>
                    </div>

        
        <div>
            <div>
                
                                    <div>
                                                    <div>
                                
                                <p>Facebook fears that a ruling by the Data Protection Commission (DPC) could force it to pull its social media platforms from Europe, High Court filings show.</p> <p>The social media giant said it does not believe it can convince the watchdog to overturn a preliminary ruling banning the transfer of personal data from EU citizens to servers in the US which relates to concerns about American intelligence agencies.</p> <p>In the filings which detail the gravity of...</p>
                            </div>
                        
                        
                                                    <div>
                                <div>
    <div>
        <h2>Subscribe from just €1 for the first month!</h2>
        <p>Exclusive offers:</p>
        <p>All Digital Access + eReader</p>
    </div>

            
        <div>
            <div>

                
                <div>
                    <h2>Trial</h2>
                                        <p>
                        €1
                                            </p>
                    <p>Unlimited Access for 1 Month</p>
                                            <p>Then €19.99 a month after the offer period.</p>
                                    </div>
                

                
            </div>
        </div>
            
        <div>
            <div>

                
                <div>
                    <h2>Annual</h2>
                                            <p>€200</p>
                                        <p>
                        €149
                                                    <span>For the 1st Year</span>
                                            </p>
                    <p>Unlimited Access for 1 Year</p>
                                    </div>
                

                
            </div>
        </div>
            
        <div>
            <div>

                
                <div>
                    <h2>Quarterly</h2>
                                            <p>€55</p>
                                        <p>
                        €42
                                            </p>
                    <p>90 Day Pass</p>
                                    </div>
                

                
            </div>
        </div>
            
        <div>
            <div>

                                    
                    <svg version="1.1" fill="#FFF" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 49.94 49.94" xml:space="preserve">
                        <path d="M48.856,22.73c0.983-0.958,1.33-2.364,0.906-3.671c-0.425-1.307-1.532-2.24-2.892-2.438l-12.092-1.757
                            c-0.515-0.075-0.96-0.398-1.19-0.865L28.182,3.043c-0.607-1.231-1.839-1.996-3.212-1.996c-1.372,0-2.604,0.765-3.211,1.996
                            L16.352,14c-0.23,0.467-0.676,0.79-1.191,0.865L3.069,16.622c-1.359,0.197-2.467,1.131-2.892,2.438
                            c-0.424,1.307-0.077,2.713,0.906,3.671l8.749,8.528c0.373,0.364,0.544,0.888,0.456,1.4L8.224,44.701
                            c-0.183,1.06,0.095,2.091,0.781,2.904c1.066,1.267,2.927,1.653,4.415,0.871l10.814-5.686c0.452-0.237,1.021-0.235,1.472,0
                            l10.815,5.686c0.526,0.277,1.087,0.417,1.666,0.417c1.057,0,2.059-0.47,2.748-1.288c0.687-0.813,0.964-1.846,0.781-2.904
                            l-2.065-12.042c-0.088-0.513,0.083-1.036,0.456-1.4L48.856,22.73z"></path>
                    </svg>
                
                <div>
                    <h2>2 Yearly</h2>
                                            <p>€315</p>
                                        <p>
                        €248
                                            </p>
                    <p>Unlimited Access for 2 Years</p>
                                    </div>
                

                <div>
                    <svg version="1.1" id="Capa_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="442.533px" height="442.533px" viewBox="0 0 442.533 442.533" style="enable-background:new 0 0 442.533 442.533;" xml:space="preserve">
                        <path d="M434.539,98.499l-38.828-38.828c-5.324-5.328-11.799-7.993-19.41-7.993c-7.618,0-14.093,2.665-19.417,7.993L169.59,247.248
                            l-83.939-84.225c-5.33-5.33-11.801-7.992-19.412-7.992c-7.616,0-14.087,2.662-19.417,7.992L7.994,201.852
                            C2.664,207.181,0,213.654,0,221.269c0,7.609,2.664,14.088,7.994,19.416l103.351,103.349l38.831,38.828
                            c5.327,5.332,11.8,7.994,19.414,7.994c7.611,0,14.084-2.669,19.414-7.994l38.83-38.828L434.539,137.33
                            c5.325-5.33,7.994-11.802,7.994-19.417C442.537,110.302,439.864,103.829,434.539,98.499z"></path>
                    </svg><p>
                    This product does not auto-renew
                </p></div>
            </div>
        </div>
    
    
    <div>
        <div>
            <h2>Team Pass</h2>
            <p>Get a Business Account for you and your team</p>
        </div>
        
    </div>
    
    
</div>

                            </div>
                                            </div>
                            </div>
        </div>

        

        
                    
            </div>

        

    </div></div>]]>
            </description>
            <link>https://www.businesspost.ie/legal/facebook-fears-ruling-may-force-it-to-pull-social-media-platforms-from-eu-00644da4</link>
            <guid isPermaLink="false">hacker-news-small-sites-24540991</guid>
            <pubDate>Mon, 21 Sep 2020 08:18:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We need young programmers; We need old programmers]]>
            </title>
            <description>
<![CDATA[
Score 78 | Comments 72 (<a href="https://news.ycombinator.com/item?id=24540919">thread link</a>) | @mrcsharp
<br/>
September 21, 2020 | https://blog.ploeh.dk/2020/09/14/we-need-young-programmers-we-need-old-programmers/ | <a href="https://web.archive.org/web/*/https://blog.ploeh.dk/2020/09/14/we-need-young-programmers-we-need-old-programmers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">
	<p>
		<em>The software industry loves young people, but old-timers serve an important purpose, too.</em>
	</p>
	<p>
		Our culture idolises youth. There's several reasons for this, I believe. Youth seems synonymous with vigour, strength, beauty, and many other desirable qualities. The cynical perspective is that young people, while rebellious, also tend to be easy to manipulate, if you know which buttons to push. A middle-aged man like me isn't susceptible to the argument that I should buy a particular pair of Nike shoes because they're named after Michael Jordan, but for a while, one pair wasn't enough for my teenage daughter.
	</p>
	<p>
		In intellectual pursuits (like software development), youth is often extolled as the source of innovation. You're often confronted with examples like that of <a href="https://en.wikipedia.org/wiki/%C3%89variste_Galois">Évariste Galois</a>, who made all his discoveries before turning 21. <a href="https://en.wikipedia.org/wiki/Ada_Lovelace">Ada Lovelace</a> was around 28 years when she produced what is considered the 'first computer program'. <a href="https://en.wikipedia.org/wiki/Alan_Turing">Alan Turing</a> was 24 when he wrote <a href="https://en.wikipedia.org/wiki/Turing%27s_proof">On Computable Numbers, with an Application to the Entscheidungsproblem</a>.
	</p>
	<p>
		Clearly, young age is no detriment to making ground-breaking contributions. It has even become folklore that everyone past the age of 35 is a has-been whose only chance at academic influence is to write a textbook.
	</p>
	<h3 id="800321a74c054ea0b75815c86f4ce18d">
		The story of the five monkeys <a href="#800321a74c054ea0b75815c86f4ce18d" title="permalink">#</a>
	</h3>
	<p>
		You may have seen a story called <em>the five monkeys experiment</em>. It's most likely a fabrication, but it goes like this:
	</p>
	<p>
		A group of scientists placed five monkeys in a cage, and in the middle, a ladder with bananas on the top. Every time a monkey went up the ladder, the scientists soaked the rest of the monkeys with cold water. After a while, every time a monkey went up the ladder, the others would beat it up.
	</p>
	<p>
		After some time, none of the monkeys dared go up the ladder regardless of the temptation. The scientists then substituted one of the monkeys with a new one, who'd immediately  go for the bananas, only to be beaten up by the others. After several beatings, the new member learned not to climb the ladder even though it never knew why.
	</p>
	<p>
		A second monkey was substituted and the same occurred. The first monkey participated in beating the second. A third monkey was exchanged and the story repeated. The fourth was substituted and the beating was repeated. Finally the fifth monkey was replaced.
	</p>
	<p>
		Left was a group of five monkeys who, even though they never received a cold shower, continued to beat up any monkey who attempted to climb the ladder. If it was possible to ask the monkeys why they would beat up all who attempted to go up the ladder, the answer would probably be:
	</p>
	<p>
		"That's how we do things here."
	</p>
	<p>
		While the story is probably just that: a story, it tells us something about the drag induced by age and experience. If you've been in the business for decades, you've seen numerous failed attempts at something you yourself tried when you were young. You know that it can't be done.
	</p>
	<p>
		Young people don't know that a thing can't be done. If they can avoid the monkey-beating, they'll attempt the impossible.
	</p>
	<h3 id="4add8a9af0424d7e889d3125837ed611">
		Changing circumstances <a href="#4add8a9af0424d7e889d3125837ed611" title="permalink">#</a>
	</h3>
	<p>
		Is attempting the impossible a good idea?
	</p>
	<p>
		In general, no, because it's... impossible. There's a reason older people tell young people that a thing can't be done. It's not just because they're stodgy conservatives who abhor change. It's because they see the effort as wasteful. Perhaps they're even trying to be kind, guiding young people off a path where only toil and disappointment is to be found.
	</p>
	<p>
		What old people don't realise is that sometimes, circumstances change.
	</p>
	<p>
		What was impossible twenty years ago may not be impossible today. We see this happening in many fields. Producing a commercially viable electric car was impossible for decades, until, with the advances made in battery technology, it became possible.
	</p>
	<p>
		Technology changes rapidly in software development. People trying something previously impossible may find that it's possible today. Once, if you had lots of data, you had to store it in fully normalised form, because storage was expensive. For a decade, relational databases were the only game in town. Then circumstances changed. Storage became cheaper, and a new movement of NoSQL storage emerged. What was before impossible became possible.
	</p>
	<p>
		Older people often don't see the new opportunities, because they 'know' that some things are impossible. Young people push the envelope driven by a combination of zest and ignorance. Most fail, but a few succeed.
	</p>
	<h3 id="4272a069588e47f796646bd282b9de02">
		Lottery of the impossible <a href="#4272a069588e47f796646bd282b9de02" title="permalink">#</a>
	</h3>
	<p>
		I think of this process as a lottery. Imagine that every impossible thing is a red ball in an urn. Every young person who tries the impossible draws a random ball from the urn.
	</p>
	<p>
		The urn contains millions of red balls, but every now and then, one of them turns green. You don't know which one, but if you draw it, it represents something that was previously impossible which has now become possible.
	</p>
	<p>
		This process produces growth, because once discovered, the new and better way of doing things can improve society in general. Occasionally, the young discoverer may even gain some fame and fortune.
	</p>
	<p>
		It seems wasteful, though. Most people who attempt the impossible will reach the predictable conclusion. What was deemed impossible was, indeed, impossible.
	</p>
	<p>
		When I'm in a cynical mood, I don't think that it's youth in itself that is the source of progress. It's just the <a href="https://en.wikipedia.org/wiki/Law_of_large_numbers">law of large numbers</a> applied. If there's a one in million chance that something will succeed, but ten million people attempt it, it's only a matter of time before one succeeds.
	</p>
	<p>
		Society at large can benefit from the success of the few, but ten million people still wasted their efforts.
	</p>
	<h3 id="016744f0ea77495c958a7914f08187db">
		We need the old, too <a href="#016744f0ea77495c958a7914f08187db" title="permalink">#</a>
	</h3>
	<p>
		If you accept the argument that young people are more likely to try the impossible, we need the young people. Do we need the old people?
	</p>
	<p>
		I'm turning fifty in 2020. You may consider that old, but I expect to work for many more years. I don't know if the software industry needs fifty-year-olds, but that's not the kind of old I have in mind. I'm thinking of people who have retired, or are close to retirement.
	</p>
	<p>
		In our youth-glorifying culture, we tend to dismiss the opinion and experiences of old people. <em>Oh, well, it's just a codgy old man</em> (or woman), we'll say.
	</p>
	<p>
		We ignore the experience of the old, because we believe that they haven't been keeping up with times. Their experiences don't apply to us, because we live under new circumstance. Well, see above.
	</p>
	<p>
		I'm not advocating that we turn into a gerontocracy that venerates our elders solely because of their age. Again, according to the law of large numbers, some people live to old age. There need not be any correlation between survivors and wisdom.
	</p>
	<p>
		We need the old to tell us the truth, because they have little to lose.
	</p>
	<h3 id="8b5c613ba6c44bb4b4e6dbba7ae7d19a">
		Nothing to lose <a href="#8b5c613ba6c44bb4b4e6dbba7ae7d19a" title="permalink">#</a>
	</h3>
	<p>
		In the last couple of years, I've noticed a trend. A book comes out, exposing the sad state of affairs in some organisation. This has happened regularly in Denmark, where I live. One book may expose the deplorable conditions of the Danish tax authorities, one may describe the situation in the ministry of defence, one criticises the groupthink associated with the climate crisis, and so on.
	</p>
	<p>
		Invariably, it turns out that the book is written by a professor emeritus or a retired department head.
	</p>
	<p>
		I don't think that these people, all of a sudden, had an epiphany after they retired. They knew all about the rot in the system they were part of, while they were part of it, but they've had too much to lose. You could argue that they should have said something before they retired, but that requires a moral backbone we can't expect most people to have.
	</p>
	<p>
		When people retire, the threat of getting fired disappears. Old people can speak freely to a degree most other people can't.
	</p>
	<p>
		Granted, many may simply use that freedom to spew bile or shout <em>Get off my lawn!</em>, but many are in the unique position to reveal truths no-one else dare speak. Many are, perhaps, just bitter, but some may possess knowledge that they are in a unique position to reveal.
	</p>
	<p>
		When that grumpy old guy on Twitter writes something that makes you uncomfortable, consider this: he may still be right.
	</p>
	<h3 id="2d64bd2c7ccb4b7ca2418802ed82689e">
		Being unreasonable <a href="#2d64bd2c7ccb4b7ca2418802ed82689e" title="permalink">#</a>
	</h3>
	<p>
		In a way, you could say that we need young and old people for the same fundamental reason. Not all of them, but enough of them, are in a position to be unreasonable.
		</p><blockquote>
			<p>
				"The reasonable man adapts himself to the world: the unreasonable one persists in trying to adapt the world to himself. Therefore all progress depends on the unreasonable man."
			</p>
			
		</blockquote><p>
		Young people and old people are unreasonable in each their own way, and we need both.
	</p>
	<h3 id="df88f595ec814e2bafcbd018ff5f5ad2">
		Conclusion <a href="#df88f595ec814e2bafcbd018ff5f5ad2" title="permalink">#</a>
	</h3>
	<p>
		We need young people in the software development industry. Because of their vigour and inexperience, they'll push the envelope. Most will fail to do the impossible, but a few succeed.
	</p>
	<p>
		This may seem like a cynical view, but we've all been young, and most of us have been through such a phase. It's like a rite of passage, and even if you fail to make your mark on the world, you're still likely to have learned a lot.
	</p>
	<p>
		We need old people because they're in a position to speak truth to the world. Notice that I didn't make my argument about the <em>experience</em> of old-timers. Actually, I find that valuable as well, but that's the ordinary argument: <em>Listen to old people, because they have experience and wisdom.</em>
	</p>
	<p>
		Some of them do, at least.
	</p>
	<p>
		I didn't make much out of that argument, because you already know it. There'd be no reason to write this essay if that was all I had to say. Old people have less on the line, so they can speak more freely. If someone you used to admire retires and all of a sudden starts saying or writing unpleasant and surprising things, there might be a good explanation, and it might be a good idea to pay attention.
	</p>
	<p>
		Or …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.ploeh.dk/2020/09/14/we-need-young-programmers-we-need-old-programmers/">https://blog.ploeh.dk/2020/09/14/we-need-young-programmers-we-need-old-programmers/</a></em></p>]]>
            </description>
            <link>https://blog.ploeh.dk/2020/09/14/we-need-young-programmers-we-need-old-programmers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24540919</guid>
            <pubDate>Mon, 21 Sep 2020 08:05:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft Teams as a Platform]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 65 (<a href="https://news.ycombinator.com/item?id=24540799">thread link</a>) | @homarp
<br/>
September 21, 2020 | https://jukkaniiranen.com/2020/09/microsoft-teams-as-a-platform/ | <a href="https://web.archive.org/web/*/https://jukkaniiranen.com/2020/09/microsoft-teams-as-a-platform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article aria-label="Microsoft Teams as a platform" itemref="hero-page-title"><div>
<p>2020 became the year of #WFH (work from home) and for many organizations also the turning point when Microsoft Teams became the primary place where being “at work” happens. This is accelerating the evolution of Teams from being merely a communication tool that connects human beings into a foundational service layer for many types of business applications.</p>



<p>How the concept of Teams as a platform contrasts with Microsoft’s Power Platform suite of technology is something I’ve been thinking about a lot lately. In this post I’ll first reflect on the relatively short history of where Teams came from. I’ll then examine how the recent feature announcements are brining apps front &amp; center in Teams. Finally, a few words on the possible future for Teams as part of Microsoft’s broader strategy.</p>



<h2>The road that lead to Teams</h2>



<p>Looking back ~10 years, the real-time communication &amp; instant messaging tools from MS seemed to be going through an endless renaming cycle: from OCS to Lync to Skype for Business. The core feature set presented to the end user didn’t seem to evolve nearly as much as product branding did. On a broader level, the communication activities of information workers within an organization still typically took place within Outlook’s inbox, and different servers like SharePoint and Dynamics CRM all packed their own features for posting short messages to other users.</p>



<figure></figure>



<p>4 years ago, when the first images of what was then called “Skype Teams” started to leak out, we were already waiting for MS to create something a bit more ambitious than just another online meeting tool. Office Groups had began to emerge in various different places inside the MS Cloud, but they were primarily a technical construct with no sensible UX for everyday people to approach them. Even Dynamics CRM had it’s own solution that attempted to bring together the dicussion, calendars, notes, documents and team memberships from under an Office 365 Group associated with a record like account or opportunity:</p>



<div><figure><a href="https://docs.microsoft.com/en-us/dynamics365/customerengagement/on-premises/basics/collaborate-with-colleagues-using-office-365-groups" target="_blank" rel="noopener noreferrer"><img src="https://docs.microsoft.com/en-us/dynamics365/customerengagement/on-premises/basics/media/office-groups-dashboard.png" alt=""></a></figure></div>



<p>I remember having many discussions with our CRM customers where I attempted to steer people away from deploying this Groups solution. Instead I wanted to encourage them to wait for something a bit more polished that I knew had to be on it’s way sooner or later.</p>



<p>At one point there was a clear &amp; present danger of another “Yammer moment” taking place, as Microsoft was reportedly quite serious about their plans to acquire Slack. In retrospect it was a blessing for both parties that MS decided to keep investing in building their own product, instead of trying to retrofit an established service like Slack into their existing software offering.</p>



<p>I would argue that this “build over buy” strategy which Microsoft has since then followed across their business software stack has been a key success factor for BizApps in particular.  It has enabled MS to move from merely chasing CRM competitors like Salesforce into redefining the business apps playing field with Power Platform. There’s a stark difference between acquiring companies and bundling them as “X Cloud” versus engineering your own software stack to act as a true platform.</p>



<h2>Teams: the collaboration chapter</h2>



<p>Initially the first version of the Microsoft Teams product that became generally available in Spring 2017 was pretty much focused on being three things: </p>



<ol><li>Replacement for Skype for Business</li><li>Alternative to Slack</li><li>UI layer for Office 365 Groups</li></ol>



<p>From a business applications perspective there wasn’t all that much you could do to hook Teams up with Dynamics 365, until Fall 2018 when the previews for the first integrated features were launched. In particular the integrated file sharing experience that Teams offered seemed almost like the Holy Grail for many CRM professionals, offering to fix the glaring hole in the SharePoint integration story that lacked any security model synchronization. The roadmap image below presents the plans from 2 years ago on how Teams and Dynamics 365 were going to be integrated:</p>



<figure></figure>







<p>The last item on the roadmap has still not been delivered, which is the visibility of Teams conversations inside the Dynamics 365 record form. Why this hasn’t been a higher priority for MS to implement seems to me like a sign of how Microsoft Teams is nowadays positioned as the primary UI for all information work. MS probably would prefer if everything always started from inside Teams. You pin record tabs into channels, you show previews of records inside teams discussions, you interact with records via bot interfaces and so on. As long as Teams is that big umbrella under which all work takes place.</p>



<p>The lack of a deep 2-way integration does not therefore mean that investments aren’t being made into the products involved. It can simply be a reflection of the new vision that is being built, by aligning many existing services to form a whole that aims to be greater than the sum of its parts.</p>



<p>As an example, if you look at Microsoft’s task management story, you’ll see that features and data from across various apps like To Do, Planner and Outlook tasks / flagged emails are currently being collapsed into a central location that is the <a href="https://docs.microsoft.com/en-us/microsoftteams/manage-tasks-app" target="_blank" rel="noreferrer noopener">Tasks app for Teams</a>. Tasks as a generic construct don’t necessarily need to be fully controlled by a single database, yet they very much need to be logically represented within “the hub for teamwork” that Teams is positioned as.</p>



<p>Going forward, when new apps appear into the MS cloud product portfolio and they need to offer task management features to users, the logical integration point to focus on would be Teams. For activity feed type of functionality the choice is even more clear for product development: choose to piggyback on Teams instead of inventing yet another stream of short messages.</p>



<h2>Teams: the platform chapter</h2>



<p>Moving beyond simply integrating Teams with products X, Y and Z, we’re now seeing the rise of a model where apps are built specifically to be used in Teams. This has of course been possible for a long time already, by developing custom web services and using the SDKs. Now there are many features coming up that will amplify the platform story around Teams on the no-code/low-code front specifically.</p>



<figure><img src="https://techcommunity.microsoft.com/t5/image/serverpage/image-id/215495iAC8095B3BF8D5E46/image-size/large?v=1.0&amp;px=999" alt="lists in teams1.png"></figure>



<p>Microsoft Lists app has been the  first to <a href="https://techcommunity.microsoft.com/t5/microsoft-teams-blog/microsoft-lists-in-microsoft-teams-is-now-generally-available/ba-p/1621979" target="_blank" rel="noreferrer noopener">reach GA</a> and offers an ultra low barrier for users to process data in a single table through a configurable, readymade UI. When accessed via Teams, the list data gains one more special dimension: discussions to be had regarding a list item. This is pretty much the same as the usage pattern offered for a Dynamics 365 record with the integration mentioned earlier.</p>



<p>Underneath the new covers of MS Lists is the technology familiar from SharePoint lists. If we were to only examine the UI layer, there is actually a remarkable similarity to a popular no-code service called Airtable. So much that the <a rel="noreferrer noopener" href="https://mspoweruser.com/airtable-accuses-microsoft-of-copying-its-service/" target="_blank">accusations</a> of MS simply copying the visuals and core features from this competitor don’t seem entirely unjustified. </p>



<figure><img loading="lazy" src="https://jukkaniiranen.com/wp-content/uploads/2020/09/Airtable_for_teams.png" alt="" width="583" height="729" srcset="https://jukkaniiranen.com/wp-content/uploads/2020/09/Airtable_for_teams.png 777w, https://jukkaniiranen.com/wp-content/uploads/2020/09/Airtable_for_teams-240x300.png 240w, https://jukkaniiranen.com/wp-content/uploads/2020/09/Airtable_for_teams-768x961.png 768w" sizes="(max-width: 583px) 100vw, 583px"></figure>



<p>Comparing these two offerings gives us some perspective on what exactly is the market position these tools are aiming to conquer. Simple lists themselves are not a particularly unique feature, rather it’s the team collaboration capabilities and ease of data sharing that turns these tables into what you’d call an actual app. Incidentally, just this week Airtable <a href="https://blog.airtable.com/airtable-platform-launch-automations-sync-apps/" target="_blank" rel="noreferrer noopener">announced</a> they were building a full platform with apps offering JavaScript based extensibility, a marketplace for sharing apps, automations for executing business logic, and finally a sync service to transfer data across environments (“bases”).</p>



<p>Collaboration scenarios around semi-structured data like lists and Excel style tables can be seen as a  gateway drug. They allow turning email or paper based manual processes into a quick first draft of what the digital process could be like. If there are indeed clear business benefits in automating the said process, the requirements for more complex app features will soon begin to emerge from the user base. Hence the collaboration platform should offer an obvious path to grow these pre-built app experiences into more advanced no-code/low-code apps.</p>



<h2>Project Oakdale a.k.a bringing CDS to Teams</h2>



<p>If Microsoft Lists is the equivalent of an Excel table within the Teams context, then <a href="https://jukkaniiranen.com/2020/07/dataflex-is-more-and-less-than-cds/">Project Oakdale</a> / “CDS Lite” could be though of as bringing SQL Server inside Teams. Now, obviously Microsoft has zero intent on actually replacing Excel nor SQL with features built into Teams. They only need to introduce those parts that make sense from a team collabocation perspective.</p>



<p>Microsoft Lists is a far cry from what a real Excel workbook can do, yet it can offer much more value in a collaboration scenarios that those lone .xlsx files ever could. Similarly, the version of CDS that will very soon be available for building Power Apps within Teams is nowhere near as powerful as the services powering enterprise CRM systems like Dynamics 365 (or the raw power offered by SQL). Still, the fact that it can be found from within every team and used by a much larger audience than what Power Apps citizen developer tools could hope to capture – those are the factors that can truly make CDS a mainstream service that most information workers in the Microsoft 365 cloud interact it.</p>



<figure><img loading="lazy" width="1024" height="576" src="https://jukkaniiranen.com/wp-content/uploads/2020/09/Oakdale_Teams_table_design-1024x576.jpg" alt="" srcset="https://jukkaniiranen.com/wp-content/uploads/2020/09/Oakdale_Teams_table_design-1024x576.jpg 1024w, https://jukkaniiranen.com/wp-content/uploads/2020/09/Oakdale_Teams_table_design-300x169.jpg 300w, https://jukkaniiranen.com/wp-content/uploads/2020/09/Oakdale_Teams_table_design-768x432.jpg 768w, https://jukkaniiranen.com/wp-content/uploads/2020/09/Oakdale_Teams_table_design.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The experience of defining the CDS data model in Project Oakdale will be very different from the path that Power Apps makers have gone through – let alone the XRM veterans. In fact, you could easily mistake the table design and row entry UX to be that of Microsoft Lists rather than CDS. This highlights a key aspect that not all Power Platform experts may yet have grasped: for MS this “CDS Lite” is not so much about deciding what premium features of the full Power Platform to give away for free to Teams subscibers – rather it’s about how to best simplify the enterprise CRM features of CDS into a new product that Teams users could adopt on their own.</p>



<p>This doesn’t mean that …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jukkaniiranen.com/2020/09/microsoft-teams-as-a-platform/">https://jukkaniiranen.com/2020/09/microsoft-teams-as-a-platform/</a></em></p>]]>
            </description>
            <link>https://jukkaniiranen.com/2020/09/microsoft-teams-as-a-platform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24540799</guid>
            <pubDate>Mon, 21 Sep 2020 07:36:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lab Snacks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24540166">thread link</a>) | @neilpanchal
<br/>
September 20, 2020 | https://neil.computer/notes/thorlabs-lab-snacks/ | <a href="https://web.archive.org/web/*/https://neil.computer/notes/thorlabs-lab-snacks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <article>
        
        <p>Throughout my engineering career (Semiconductor industry), I've come across dozens if not hundreds of equipment suppliers. But there are a few suppliers that leave a long lasting impression. Thorlabs is one of them. Why?</p><p>It is quite silly actually. Everytime I order a linear actuator, motorized stage or axis controller... something that's just normal industrial hardware, it ships unremarkably with billable weight in hundreds of dollars, docks and sits at the shipping &amp; receiving until I haul it into the lab. Cut open the box, and you see this:</p><figure><img src="https://neil.computer/content/images/2020/09/image.png" alt=""><figcaption>Source: https://jlfenimore.wixsite.com/jenniferfenimore/lab-snacks</figcaption></figure><p>Food and Drink are not allowed in our lab, except when it comes to the Thorlabs Snacks. This little red box brings so much joy it is hard to describe. Thorlabs shipping boxes contain one or more of these red boxes, it's got - cookies, candies, granola bars, chips, etc. to put a smile on the face. They didn't have to do it but they did. And they've been doing this for many years. Infact, they've trademarked "Lab Snacks" which is such a cool name on its own!</p><p>Thorlabs founder, Alex Cable, wrote an <a href="https://www.thorlabs.com/about_us.cfm">article</a> about his vision of what customer centricity is, there is so much to learn from it, Wikipedia quotes:</p><blockquote>An important part of Thorlabs' brand and culture is Lab Snacks. Lab Snacks were created to support the famished grad student researching all night, serving as an occasional meal for someone hard at work.</blockquote><p>I implore you to read the original <a href="https://www.thorlabs.com/about_us.cfm">source</a> because it exemplifies what a CEO and Founder should do to build an honest, customer centric business and how to genuinely connect with them. Everything at Thorlabs, from their phone support to documentation, is focusing on how best to make you, the customer, successful. Therein lies their success and they double-down on it.</p><p>Thorlabs has left such a long-lasting impact on me that I am writing this post after last enjoying Lab Snacks 2 years ago.</p>
        </article>
</div></div>]]>
            </description>
            <link>https://neil.computer/notes/thorlabs-lab-snacks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24540166</guid>
            <pubDate>Mon, 21 Sep 2020 05:38:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Choosing the right tech stack for your product]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24540001">thread link</a>) | @root993
<br/>
September 20, 2020 | https://www.sankalpjonna.com/posts/choosing-the-right-tech-stack-for-your-product | <a href="https://web.archive.org/web/*/https://www.sankalpjonna.com/posts/choosing-the-right-tech-stack-for-your-product">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>It is always difficult to choose a tech stack for your application. Especially one that is going to be worked on by many people in the future. The fact that technologies like Javascript change almost on a daily basis and new frameworks come up every time I browse the internet does not make this job any easier.<br></p><p>On one hand you want to be using the latest technologies available but on the other hand you can’t afford to have a high learning curve or use something that is not a 100% stable yet because you are most likely going to build a long term business that must stand the test of time.<br></p><p>In many ways it is similar to choosing a person to date. You wanna go with the best looking one but you also need the person to have some depth so that you can have a long term relationship!<br></p><p>So how do you choose the right tech stack? I can’t say for sure that the methods that am employing are the best ones and readers can always reach out to me on twitter and correct me but here are some of the things that I am keeping in mind right now<br></p><h3><strong>Prioritising speed over “doing the right thing”</strong><br></h3><p>It is important for a startup to move fast. If I spend time learning new technologies and understanding all the nuances of those technologies it might take a long time to actually build a product and get it out the door. <br></p><p>For instance, I am currently building a <a href="https://www.delight.chat/" target="_blank">customer support software for e-commerce businesses</a> and I have been advised by a few folks that my use case would involve dealing with a lot of unstructured data so MongoDB is the right database to use. <br></p><p>The issue here is that I do not have much experience with nosql and I have personally never used it in production. So even if this is the right thing, it might end up causing me a lot of grief down the line when I am not able to debug certain issues just because I don’t have a deeper understanding of the subject. <br></p><p>I decided to go with Postgres instead because while being a relational database which I am comfortable with, Postgres supports a datatype called JSONB where you can store unstructured data much like in Mongo. This seemed like the optimal thing to do.<br></p><h3><strong>Other people will be working on your codebase</strong><br></h3><p>I my previous venture, I wrote some services in Golang. I did this because I enjoy writing code in Go, not to mention that it is a compiled language with syntax that is easy to understand and yields performance that is close to C/C++.<br></p><p>This seemed like a good idea at the time because the services I wrote in Go were highly scalable and I did not have to touch them again for a long time. The issue came up when we exited the business and I had to transfer the codebase to folks who never worked in Golang. <br></p><p>The same thing could happen when you hire new folks who might have great aptitude for the role but do not necessarily know all the nuances of working with a brand new language. This is going to delay development time significantly.<br></p><h3><strong>Do not spend time on solved problems </strong><br></h3><p>The amount of work required to build your core product is already quite high, you don’t want to be making it worse by spending valuable development hours on building things that are not core to your product.<br></p><p>For our current product we needed a socket infrastructure so that the server can push real time updates to the browser when a certain event takes place. At first I thought of using something like <a href="http://socket.io/" target="_blank">socket.io</a> but after giving it some further thought, I realised that it would take up considerable bandwidth to maintain the socket service as the product scales in usage.<br></p><p>We decided to cough up some $$ and go with <a href="http://pusher.com/" target="_blank">pusher.com</a> instead. They are a SaaS that offer socket infrastructure as a service. If their entire business depends on one particular pain point, it is safe to assume that they would have done the best possible job of handling it and would have found out all the edge cases and bugs that might come up. <br></p><h3><strong>Break up the product into microservices</strong><br></h3><p>For a monolithic codebase there is pretty much no choice but to work on the same language and frameworks for the foreseeable future. This means that not only are you stuck with a tech stack that you choose a long time ago, but even the folks you hire in the future will be stuck working on the same thing as well.<br></p><p>To prevent this, it is important to segregate your product into micro services that can be developed, maintained and deployed independently so that you can easily swap some of these services with new ones written in a new language or framework without affecting the working of the rest of the product.<br></p><h3><strong>Closing notes</strong><br></h3><p>While speed is important, it is also important to make sure that your employees are comfortable with the tech stack and do not feel like their careers are being jeopardised due to not being able to work on the latest technologies and frameworks that are available in the market. It would not be fair for me to say that we will only use PHP and nothing else and whoever joins us must suck it up and work on it. <br></p><p>It could also negatively impact us if we miss out on the ease of problem solving that new technologies and frameworks provide. So there must always be balance &nbsp;between speed and upgrading yourself to something new and better. <br></p><p>So if you find yourself in a position where there is a new technology that can make things significantly better but it would require a learning curve and a considerable risk of not being able to find employees who can work on this technology very easily, it might still be worth to go for it.</p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.sankalpjonna.com/posts/choosing-the-right-tech-stack-for-your-product</link>
            <guid isPermaLink="false">hacker-news-small-sites-24540001</guid>
            <pubDate>Mon, 21 Sep 2020 05:06:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gitlab sped up Puma using sleep sort]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24539706">thread link</a>) | @eddietejeda
<br/>
September 20, 2020 | https://www.speedshop.co/2020/09/17/we-made-puma-faster-with-sleep-sort.html | <a href="https://web.archive.org/web/*/https://www.speedshop.co/2020/09/17/we-made-puma-faster-with-sleep-sort.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<article>



<p><b>Summary:</b> Puma 5 is a huge major release for the project. It brings several new experimental performance features, along with tons of bugfixes and features. Let's talk about some of the most important ones. <i>(1839 words / 7 minutes)</i>
</p>
<p>Puma 5 (codename Spoony Bard<sup>1</sup><span>(When Puma gets a new ‘supercontributor’ that submits lots of important work to the project, we let them name the next release. This release features a lot of code from Will Jordan, who named this release ‘Spoony Bard’. Will said: ‘Final Fantasy IV is especially nostalgic for me, the first big open-source project I ever worked on was a fan re-translation of the game back in the late 90s.’)</span><span><sup>1</sup> When Puma gets a new ‘supercontributor’ that submits lots of important work to the project, we let them name the next release. This release features a lot of code from Will Jordan, who named this release ‘Spoony Bard’. Will said: ‘Final Fantasy IV is especially nostalgic for me, the first big open-source project I ever worked on was a fan re-translation of the game back in the late 90s.’</span>) was released today (my birthday!). There’s a lot going on in this release, so I wanted to talk about the different features and changes to give Puma users confidence in upgrading.</p>
<h2 id="experimental-performance-features-for-cluster-mode-on-mri">Experimental Performance Features For Cluster Mode on MRI</h2>
<p>This is probably the headline of the release - two features for reducing memory usage, and one for reducing latency.</p>
<p>Puma 5 contains 3 new experimental performance features:</p>
<ul>
<li><code>wait_for_less_busy_worker</code> config. This may reduce latency on MRI through inserting a small delay (sleep sort!) before re-listening on the socket if worker is busy. Intended result: If enabled, should reduce latency in high-load (&gt;50% utilization) Puma clusters.</li>
<li><code>fork_worker</code> option and <code>refork</code> command for reduced memory usage by forking from a worker process instead of the master process. Intended result: If enabled, should reduce memory usage.</li>
<li>Added <code>nakayoshi_fork</code> config option. Reduce memory usage in preloaded cluster-mode apps by GCing before fork and compacting, where available. Intended result: If enabled, should reduce memory usage.</li>
</ul>
<p>All of these experiments are only for <strong>cluster mode</strong> Puma configs running on <strong>MRI</strong>.</p>
<p>We’re calling them <em>experimental</em> because we’re not sure if they’ll actually have any benefit. We’re pretty sure they’re stable and won’t break anything, but we’re not sure they’re actually going to have big benefits in the real world. People’s workloads are often not what we anticipate, and synthetic benchmarks are usually not of any help in figuring out if a change will be beneficial or not.</p>
<p>We do not believe any of the new features will have a negative effect or impact the stability of your application. This is either a “it works” or “it does nothing” experiment.</p>
<p>If any of the features turn out to be particularly beneficial, we may make them defaults in future versions of Puma.</p>
<p><strong>If you upgrade and try any of the 3 new features, please post before and after results or screenshots to <a href="https://github.com/puma/puma/issues/2258">this Github issue</a>.</strong> “It didn’t do anything” is still a useful report in this case. Posting ~24 hours of “before” and ~24 hours of “after” data would be most helpful.</p>
<h3 id="wait_for_less_busy_worker-sleep-sort-for-faster-apps">wait_for_less_busy_worker: sleep sort for faster apps?!</h3>
<p>This feature was contributed to Puma by Gitlab. Turn it on by adding <code>wait_for_less_busy_worker</code> to your Puma config.</p>
<p>When a request comes in to a Puma cluster, the operating system randomly selects a listening, free Puma worker process to pick up the request. “Listening” and “free” being the key words - a Puma process will only listen to the socket (and pick up more requests) if it has nothing else to do. However, when running Puma with multiple threads, Puma will also listen on the socket when all of its busy threads are waiting on I/O or have otherwise released <a href="https://www.speedshop.co/2020/09/17/2020/05/11/the-ruby-gvl-and-scaling.html">the Global VM Lock</a>.</p>
<p>When Gitlab investigated switching from Unicorn to Puma, they encountered an issue with this behavior. Under high load with moderate thread settings (a max pool size of 5 in their case), average request latency increased. Why?</p>
<p>Remember, I said that the operating system <em>randomly</em> assigns a request to a <em>listening</em> worker process. So, it will never send a request to a worker process that’s busy doing other things, but what about a worker process that’s got 4 threads that are processing other requests, but all 4 of those threads happen to be waiting on I/O right now?</p>
<p>Imagine a Puma cluster with 3 workers:</p>
<ul>
<li>Worker 1: 0/5 threads busy.</li>
<li>Worker 2: 1/5 threads busy.</li>
<li>Worker 3: 4/5 threads busy.</li>
</ul>
<p>If Worker 3’s 4 active threads happen to all have released the GVL, allowing that worker to listen to the socket, and a new request comes in - which worker process should we assign the request to, ideally? Worker 1, right? Unfortunately, most operating systems will assign the request to Worker 3 33% of the time.</p>
<p>So, what do we do? We want the operating system to prefer less-loaded workers. It would be really cool if we could sort the list of workers listening on the socket so that the operating system would give requests to the least-loaded worker. Well, we can’t really do that easily, but we can do something else.</p>
<p><code>wait_for_less_busy_worker</code> causes a worker to <em>wait</em> to re-listen on the socket if it’s thread pool isn’t completely empty. This means that in high-load scenarios, the operating system will assign requests to less-loaded workers.</p>
<p><strong>This is basically sleep-sorting our workers</strong>. We’re kind of doing doing this:</p>
<div><div><pre><code>[].tap { |a| workers.map { |e| Thread.new{ sleep worker_busyness.to_f/1000; a &lt;&lt; e} }.each{|t| t.join} }
</code></pre></div></div>
<p>… and hiding “more loaded” workers from the operating system by letting less-loaded workers listen first!</p>
<p>Originally the proposal was for a more complicated sort - processes slept longer if they had more busy threads - but that was removed when it was found that a simpler on/off sleep was just as effective.</p>
<p>The net effect is that in high-load scenarios, request latency decreases. This is because workers with more busy threads are slower than workers with no busy threads. We’re assuring that requests get assigned to the faster workers. Prior to this patch, Gitlab saw an increase in latency using Puma compared to Unicorn - after this patch, latency was the same (they also were able to reduce their fleet size by almost 30% thanks to Puma’s memory-saving multithreaded design).</p>
<p>There may be even more efficient ways for us to implement this behavior in the future. There’s some magic you can do with <code>libev</code>, I’m pretty sure, or we can just implement a different sleep/wait strategy.</p>
<h3 id="fork_worker">fork_worker</h3>
<p>Adding <code>fork_worker</code> to your puma.rb config file (or <code>--fork-worker</code> from the CLI) turns on this feature. This mode causes Puma to fork additional workers from worker 0, instead of directly from the master process:</p>
<div><div><pre><code>10000   \_ puma 5.0.0 (tcp://0.0.0.0:9292) [puma]
10001       \_ puma: cluster worker 0: 10000 [puma]
10002           \_ puma: cluster worker 1: 10000 [puma]
10003           \_ puma: cluster worker 2: 10000 [puma]
10004           \_ puma: cluster worker 3: 10000 [puma]
</code></pre></div></div>
<p>Similar to the <code>preload_app!</code> option, the <code>fork_worker</code> option allows your application to be initialized only once for copy-on-write memory savings, and it has two additional advantages:</p>
<ol>
<li><strong>Compatible with phased restart.</strong> Because the master process itself doesn’t preload the application, this mode works with phased restart (<code>SIGUSR1</code> or <code>pumactl phased-restart</code>), unlike <code>preload_app!</code>. When worker 0 reloads as part of a phased restart, it initializes a new copy of your application first, then the other workers reload by forking from this new worker already containing the new preloaded application.</li>
</ol>
<p>This allows a phased restart to complete as quickly as a hot restart (<code>SIGUSR2</code> or <code>pumactl restart</code>), while still minimizing downtime by staggering the restart across cluster workers.</p>
<ol>
<li><strong>‘Refork’ for additional copy-on-write improvements in running applications.</strong> Fork-worker mode introduces a new <code>refork</code> command that re-loads all nonzero workers by re-forking them from worker 0.</li>
</ol>
<p>This command can potentially improve memory utilization in large or complex applications that don’t fully pre-initialize on startup, because the re-forked workers can share copy-on-write memory with a worker that has been running for a while and serving requests.</p>
<p>You can trigger a refork by sending the cluster the <code>SIGURG</code> signal or running the <code>pumactl refork</code> command at any time. A refork will also automatically trigger once, after a certain number of requests have been processed by worker 0 (default 1000). To configure the number of requests before the auto-refork, pass a positive integer argument to <code>fork_worker</code> (e.g., <code>fork_worker 1000</code>), or <code>0</code> to disable.</p>
<h3 id="nakayoshi_fork">nakayoshi_fork</h3>
<p>Add <code>nakayoshi_fork</code> to your puma.rb config to try this option.</p>
<p>Nakayoshi means “friendly”, so this is a “friendly fork”. The concept was <a href="https://github.com/ko1/nakayoshi_fork">originally implemented by MRI supercontributor Koichi Sasada</a> in a gem, but we wanted to see if we could bring a simpler version into Puma.</p>
<p>Basically, we just do the following before forking a worker:</p>
<div><div><pre><code><span>4</span><span>.</span><span>times</span> <span>{</span> <span>GC</span><span>.</span><span>start</span> <span>}</span>
<span>GC</span><span>.</span><span>compact</span> <span># if available</span>
</code></pre></div></div>
<p>The concept here is that we’re trying to get as clean of a Ruby heap as possible before forking to maximize <a href="https://en.wikipedia.org/wiki/Copy-on-write">copy-on-write</a> benefits. That should, in turn, lead to reduced memory usage.</p>
<h2 id="other-new-features">Other New Features</h2>
<p>A few more things in the grab-bag:</p>
<ul>
<li>You can now compile Puma on machines where OpenSSL is not installed.</li>
<li>There is now a <code>thread-backtraces</code> command in pumactl to print all active threads backtraces. This has been available via SIGINFO on Darwin, but now it works on Linux via this new command.</li>
<li><code>Puma.stats</code> now has a <code>requests_count</code> counter.</li>
<li><code>lowlevel_error_handler</code> got some enhancements - we also pass the status code to it now.</li>
<li>Phased restarts and worker timeouts should be faster.</li>
<li><code>Puma.stats_hash</code> provides Puma statistics as a hash, rather than as JSON.</li>
</ul>
<h2 id="loads-of-bugfixes">Loads of Bugfixes</h2>
<p>The number of bugfixes in this release is pretty huge. Here’s the most important ones:</p>
<ul>
<li>Shutdowns should be more reliable.</li>
<li>Issues surrounding socket closing on shutdown have been resolved.</li>
<li>Fixed some concurrency …</li></ul></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.speedshop.co/2020/09/17/we-made-puma-faster-with-sleep-sort.html">https://www.speedshop.co/2020/09/17/we-made-puma-faster-with-sleep-sort.html</a></em></p>]]>
            </description>
            <link>https://www.speedshop.co/2020/09/17/we-made-puma-faster-with-sleep-sort.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24539706</guid>
            <pubDate>Mon, 21 Sep 2020 04:10:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is the Fediverse? Briefly]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24538962">thread link</a>) | @torresjrjr
<br/>
September 20, 2020 | https://torresjrjr.com/archive/2020-07-20-what-is-the-fediverse | <a href="https://web.archive.org/web/*/https://torresjrjr.com/archive/2020-07-20-what-is-the-fediverse">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>

<header id="Title">
  
  
  <time>2020-07-20</time>
</header>

<p><small> See also: <a href="https://torresjrjr.com/archive/2020-07-19-guide-to-the-fediverse"><em>full guide version</em></a> </small></p>
<p>Say you have a Twitter account 🐦, <code>@alice</code>. Your friends Bob and Charlie have Twitter accounts too, <code>@bob</code> and <code>@charlie</code>. You can talk seamlessly to each other, but <em>only</em> on <code>twitter.com</code> and nowhere else. Bad.</p>
<p>Now, you have an email account 📧, <code>alice@gmail.com</code>. Your friends Bob and Charlie also have email accounts, <code>bob@hotmail.com</code> and <code>charlie@yahoo.com</code>. You all can talk from different websites. Great, but email sucks as social media.</p>
<p>Now, imagine this. You have a Fediverse account 🌟, <code>@alice@tweet.com</code>. Your friends Bob and Charlie also have Fediverse accounts, <code>@bob@toot.net</code> and <code>@charlie@social.org</code>. <strong>You all can talk seamlessly like Twitter, from anywhere like email.</strong> That’s the Fediverse, and it’s amazing.</p>
<figure>
<img src="https://upload.wikimedia.org/wikipedia/commons/9/93/Fediverse_logo_proposal.svg" height="128" alt="Unofficial Fediverse logo">
</figure>
<h2 id="what-does-it-look-like">What does it look like?</h2>
<p>Like this. Microblogging, video sharing, photo sharing… And these Fediverse websites are <strong>all interconnected</strong>.</p>
<figure>
<img src="https://i.imgur.com/MDoyecc.png" alt="Mastodon, Pleroma, and PeerTube. All interconnected.">
</figure>
<p>Here’s an example of Fediverse accounts “tweeting” to each other across different websites. Talk to anyone, anywhere.</p>
<figure>
<img src="https://i.imgur.com/zdG7B0k.png" alt="A post and reply on Mastodon. Notice the handles in red.">
</figure>
<p>No more being tied down to a single place which abuses their power or your data. You decide were you reside.</p>
<h2 id="how-do-i-join">How do I join?</h2>
<p>Easiest way is to sign up to a <a href="https://joinmastodon.org/">Mastodon</a> instance (website/server) of your choice. If you’re feeling adventurous, browse <a href="https://fediverse.network/">Fediverse.network</a> for other Fediverse instances, including non-Mastodon ones. Remember, <strong>you can talk to anyone anywhere regardless of where they are on the Fediverse!</strong></p>
<figure>
<img src="https://i.imgur.com/EIlnJXc.png" alt="Pick a Mastodon instance and browse the Fediverse.">
</figure>
<h2 id="is-there-more-than-just-microblogging">Is there more than just microblogging?</h2>
<p>Yes, plenty! Check out <a href="https://fediverse.party/">Fediverse.party</a> for a cool interactive guide. The Fediverse is a whole family of miraculously <strong>interconnected</strong> (federated) services.</p>
<ul>
<li><a href="https://joinmastodon.org/">Mastodon</a> - Microblogging. The most popular service and Twitter alt.</li>
<li><a href="https://pleroma.com/">Pleroma</a> - Microblogging. A more lightweight, customisable alt.</li>
<li><a href="https://joinpeertube.org/">PeerTube</a> - Video streaming. YouTube alt.</li>
<li><a href="https://funkwhale.audio/">Funkwhale</a> - Audio streaming. Spotify alt.</li>
<li><a href="https://beta.joinpixelfed.org/">Pixelfed</a> - Photo sharing. Instagram alt.</li>
<li><a href="https://friendi.ca/">Friendica</a> - Microblogging+. Facebook alt.</li>
<li><a href="https://write.as/">Write.as</a> - Federated blogging.</li>
<li><a href="https://joinplu.me/">Plume</a> - Federated blogging.</li>
<li>And many more.</li>
</ul>
<h2 id="why-should-i-join">Why should I join?</h2>
<p>It’s no surprise nobody trust the big monster tech giants (Twitter, Facebook, YouTube, etc.) anymore. Why wait until the next case of them abusing your data, keeping permanent records, censoring arbitrarily, and manipulating your feed, when there is a better, thriving alternative? There’s no need to be kept shackled within their walled gardens.</p>
<figure>
<img src="https://i.imgur.com/qIttu4i.png" alt="Greedy big tech profiting from your ignorance.">
</figure>
<p>The Fediverse offers real internet <em>freedom</em>, and it’s come a long way since it’s beginnings. Sometimes you don’t value something until it’s truly gone. So don’t wait! Don’t miss out on this special internet subculture. <a href="https://joinmastodon.org/">Join</a> one of the thousands of thriving communities and get talking. It won’t hurt to sign up. We’re all waiting here for you!</p>
<p>Read <a href="https://write.as/eloquence/why-mastodon-and-the-fediverse-are-doomed-to-fail">eloquence’s article</a> for a sober take.</p>
<hr>
<p>Want to learn more? I wrote a simple <a href="https://torresjrjr.com/archive/2020-07-19-guide-to-the-fediverse"><em>Guide to the Fediverse</em></a>.</p>
<p>Or watch this great explanatory video.</p>

<p>Here’s a proper definition of the Fediverse.</p>
<blockquote>
<p>The <strong>Fediverse</strong> (federated + universe) is the decentralised social media network of federated (independent &amp; interconnected) servers, communicating via open protocols, especially ActivityPub.<br>
– <a href="https://en.wiktionary.org/wiki/Fediverse"><em>Wiktionary</em></a>, modified.</p>
</blockquote>
<p>OK now, go join the Fediverse, and enjoy internet freedom!</p>
<hr>
<p><small> Comments: <a href="https://qoto.org/@torresjrjr/104865046295137278">Fediverse</a></small></p><small>
<p><a href="https://torresjrjr.com/links#contact">Contribute</a>. Note, this article aims to explain the gist of the Fediverse to people unfamiliar with technology, not to be a comprehensive or technical overview.</p>
</small><p><small><em>Last updated: 2020 September 21th</em> </small></p>

  </article>
</div></div>]]>
            </description>
            <link>https://torresjrjr.com/archive/2020-07-20-what-is-the-fediverse</link>
            <guid isPermaLink="false">hacker-news-small-sites-24538962</guid>
            <pubDate>Mon, 21 Sep 2020 01:38:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Commons – Simple mini-forums for communities]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24538774">thread link</a>) | @kthez
<br/>
September 20, 2020 | https://www.startcommons.com/634fcf24-7448-4ac3-b393-35f52699dc23 | <a href="https://web.archive.org/web/*/https://www.startcommons.com/634fcf24-7448-4ac3-b393-35f52699dc23">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.startcommons.com/634fcf24-7448-4ac3-b393-35f52699dc23</link>
            <guid isPermaLink="false">hacker-news-small-sites-24538774</guid>
            <pubDate>Mon, 21 Sep 2020 00:58:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Does Rails Assign Variables to Rendered Views?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24537617">thread link</a>) | @devrob
<br/>
September 20, 2020 | https://blog.robsdomain.com/how-does-rails-assign-view-variables/ | <a href="https://web.archive.org/web/*/https://blog.robsdomain.com/how-does-rails-assign-view-variables/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section>
            <p><em>If you enjoy this article you may be interested in the book I am working on called <a href="https://buildingcryptotradingbots.com/">Building and Deploying Crypto Trading Bots</a>.</em></p><p>Throughout this post, we will investigate one source of that "Rails magic" that perplexes developers: how Rails assigns Controller instance variables to view templates.</p><p>Take the following for example:</p><figure><pre><code># If you inspect action_controller.rb you will find it inerhits from ActionController::Base
class MyController &lt; ApplicationController
 def index
  @my_index_var = [1,2,3,4]
 end
end</code></pre><figcaption>app/controller/my_controller.rb</figcaption></figure><figure><pre><code>&lt;% @my_index_var.each do |i| %&gt;
  &lt;p&gt; Number: &lt;%= I %&gt; &lt;/p&gt;
&lt;% end %&gt;</code></pre><figcaption>app/views/my_controller/index.html.erb</figcaption></figure><p>Have you ever wondered how on earth the view template <code>index.html.erb</code> gets access to the instance variable <code>@my_index_var</code> ? Well, let's find out.</p><h3 id="what-is-rails-anyway">What is Rails Anyway?</h3><p>Without jumping too far into Rails source code (yet), recall that the Ruby on Rails source code isn't a massive monolithic code base. Rather, it is a collection of isolated Ruby gems that are strung together to make up the tool we call Rails. Inside the &nbsp;codebase, the responsibilities of template rendering, rack request routing, object relational mapping and more are divided across &nbsp;several key gems that are usually prefixed with <code>Action*</code> or <code>Active*</code> . All these gems work together to deliver the end framework you and I use for web application development. With the primer out of the way, let's begin the journey to expose how controller instance variables are assigned to views.</p><h3 id="actionpack-d">ActionPack'd</h3><p>Our first stop is the gem called <code>ActionPack</code>. <code><a href="https://rubygems.org/gems/actionpack">ActionPack</a></code> defines several important modules including <code>ActionController</code>, <code>ActionDispatch</code> and <code>AbstractController</code>. Thematically the gem revolves around framework controller code, rendering and routing of rack requests.</p><p>For our investigation, the first class in <code>ActionPack</code> to take a look at is &nbsp;<code><a href="https://github.com/rails/rails/blob/661da266b94909574426fd1121ef13b800e01b9a/actionpack/lib/action_controller/base.rb#L166">ActionController::Base</a></code> . This is the base class that all your application controllers will inherit from. </p><pre><code>class ApplicationController &lt; ActionController::Base
end

class Posts &lt; ApplicationController
end</code></pre><p>In essence <code>ActionController::Base</code> is the core of a web request in Rails. It gives controllers the ability to define actions for requests, and have requests routed to those actions in order to render a template or redirecting somewhere else. <code>ActionController::Base</code> inherits from a parent class <a href="https://github.com/rails/rails/blob/661da266b94909574426fd1121ef13b800e01b9a/actionpack/lib/action_controller/metal.rb#L119"><code>ActionController::Metal</code></a> which in turn inherits from <code>AbstractController::Base</code>. <code>ActionController::Metal</code> isn't very interesting so we won't spend too much time on it. The in-line source comments describes it as:</p><p><em>... the simplest possible controller, providing a valid Rack interface without the additional niceties provided by ActionController::Base</em></p><p>Circling back to <code>ActionController::Base</code>, the class itself doesn't actually define many interesting methods. Instead <code>ActionController::Base</code> is a composite of <a href="https://github.com/rails/rails/blob/master/actionpack/lib/action_controller/base.rb#L210https://github.com/rails/rails/blob/661da266b94909574426fd1121ef13b800e01b9a/actionpack/lib/action_controller/base.rb#L210">various modules</a> such as <code>UrlFor</code>, <code>Redirecting</code>, <code>HttpAuthentication</code>, <code>Logging</code>, <code>Cookies</code> that are loaded into the class at require time. One module in deserving of our focus is &nbsp;<code>AbstractController::Rendering</code>. </p><p>The <code>AbstractController::<code>Rendering</code></code> module provides <code>ActionController</code> a variety of handy methods including the <code><a href="https://github.com/rails/rails/blob/661da266b94909574426fd1121ef13b800e01b9a/actionpack/lib/abstract_controller/rendering.rb#L23">render</a></code> method we know and love. </p><figure><pre><code>def render(*args, &amp;block)
  options = _normalize_render(*args, &amp;block)
  rendered_body = render_to_body(options)
  if options[:html]
    _set_html_content_type
  else
    _set_rendered_content_type rendered_format
  end
  _set_vary_header
  self.response_body = rendered_body
end</code></pre><figcaption><a href="https://github.com/rails/rails/blob/661da266b94909574426fd1121ef13b800e01b9a/actionpack/lib/abstract_controller/rendering.rb#L23">https://github.com/rails/rails/blob/661da266b94909574426fd1121ef13b800e01b9a/actionpack/lib/abstract_controller/rendering.rb#L23</a></figcaption></figure><pre><code>class Posts &lt; ApplicationController
  def new
    render 'new'
  end
end</code></pre><p>In addition to <code>render</code>, the module also contains a method called <code><a href="https://github.com/rails/rails/blob/661da266b94909574426fd1121ef13b800e01b9a/actionpack/lib/abstract_controller/rendering.rb#L63">view_assigns</a></code> . The <code>view_assigns</code> method is pretty quirky:</p><figure><pre><code># This method should return a hash with assigns.
# You can overwrite this configuration per controller.
def view_assigns
  variables = instance_variables - _protected_ivars

  variables.each_with_object({}) do |name, hash|
    hash[name.slice(1, name.length)] = instance_variable_get(name)
  end
end</code></pre><figcaption>https://github.com/rails/rails/blob/661da266b94909574426fd1121ef13b800e01b9a/actionpack/lib/abstract_controller/rendering.rb#L63</figcaption></figure><p>Basically, it calls the Ruby base <code>Object</code> method <code><a href="https://ruby-doc.org/core-2.7.1/Object.html#method-i-instance_variables">instance_variables</a></code> which returns an Array of all the currently defined instance variables for an object and creates a hash mapping their names to their values. &nbsp;Now, recall that <code>AbstractController::Rendering</code> is a <strong>module</strong> that is mixed in the <strong>class</strong> <code>ActionController::Base</code> which is what your concrete controller implementation inherits from. This means that if <code>view_assigns</code> is invoked from your controller all the currently defined instance variables will be assigned to this hash. Interesting.... We've discovered how the instance variables are captured but how does the controller connect to the view?</p><h3 id="actionview">ActionView</h3><p>Returning to our previous note about Rails being built from "Action" type gems, view and templating logic live in a fun little gem called <code><a href="https://rubygems.org/gems/actionview">ActionView</a></code>. <code>ActionView</code> is responsible for understanding <em>how to render</em> different template engines like embedded ruby, and HTML. To draw the lines of responsibility a bit more clearly, <code>ActionController</code> can tell us <em>what</em> to render, but, it does not know <em>how </em>to render it. That's <code>ActionView</code>'s job.</p><p>The base class for <code>ActionView</code> is somewhat anti-climatically named <code><a href="https://github.com/rails/rails/blob/d2cdf0be675b44771f950697fc0b19ef0ea453f9/actionview/lib/action_view/base.rb#L141">ActionView::Base</a></code>. The class itself does quite a bit of serious business. The job of hierarchal template rendering doesn't sound like a laughing matter (but then again maybe it is? <a href="https://twitter.com/dhh">DHH</a> seems to have a lot of fun on Twitter). Anyway, when an <code>ActionView</code> is <a href="https://github.com/rails/rails/blob/d2cdf0be675b44771f950697fc0b19ef0ea453f9/actionview/lib/action_view/base.rb#L243">instantia</a>ted it eventually calls an important method named <a href="https://github.com/rails/rails/blob/d2cdf0be675b44771f950697fc0b19ef0ea453f9/actionview/lib/action_view/base.rb#L267">assign</a> with a payload called <code>assigns</code>:</p><figure><pre><code>def assign(new_assigns) # :nodoc:
  @_assigns = new_assigns.each do |key, value|
    instance_variable_set("@#{key}", value)
  end
end</code></pre><figcaption><a href="https://github.com/rails/rails/blob/d2cdf0be675b44771f950697fc0b19ef0ea453f9/actionview/lib/action_view/base.rb#L206">https://github.com/rails/rails/blob/d2cdf0be675b44771f950697fc0b19ef0ea453f9/actionview/lib/action_view/base.rb#L206</a></figcaption></figure><p>The <code>ActionView::Base</code> <code>assign</code> method is responsible for taking the <code>new_assigns</code> argument iterating through it to define instance variables using the <code>instance_variable_set</code> method. These instance variables are named, assigned and set in the template object using the key and value pairs in the <code>new_assigns</code> hash. This means that the template object rendered will have access to these variables immediately after being instantiated. Does this look familiar?</p><figure><pre><code>&lt;% @my_index_var.each do |i| %&gt;
  &lt;p&gt; Number: &lt;%= I %&gt; &lt;/p&gt;
&lt;% end %&gt;</code></pre><figcaption>app/views/my_controller/index.html.erb</figcaption></figure><p>Ok so that all makes sense but how and where does the <code>new_assigns</code> payload come from?</p><h3 id="actionview-take-two">ActionView Take Two</h3><p>In the same <code>ActionView</code> gem lives a module called <code>ActionView::Rendering</code> where a view's "context" is built before it is rendered to the screen. In specific, the <code>ActionView::Rendering</code> module has a public hook method called <code><a href="https://github.com/rails/rails/blob/d2cdf0be675b44771f950697fc0b19ef0ea453f9/actionview/lib/action_view/rendering.rb#L101">render_to_body</a></code> which is invoked by <code>ActionController</code> when the <a href="https://github.com/rails/rails/blob/661da266b94909574426fd1121ef13b800e01b9a/actionpack/lib/abstract_controller/rendering.rb#L25"><code>render</code> method</a> is called. Under the hood <code>render_to_body</code> calls a <strong>private</strong> method <code><a href="https://github.com/rails/rails/blob/d2cdf0be675b44771f950697fc0b19ef0ea453f9/actionview/lib/action_view/rendering.rb#L108">_render_template</a></code>:</p><figure><pre><code> def _render_template(options)
    variant = options.delete(:variant)
    assigns = options.delete(:assigns)
    
    context = view_context

    context.assign assigns if assigns
    lookup_context.variants = variant if variant

    rendered_template = context.in_rendering_context(options) do |renderer|
      renderer.render_to_object(context, options)
    end

    rendered_format = rendered_template.format || lookup_context.formats.first
    @rendered_format = Template::Types[rendered_format]

    rendered_template.body
end</code></pre><figcaption><a href="https://github.com/rails/rails/blob/d2cdf0be675b44771f950697fc0b19ef0ea453f9/actionview/lib/action_view/rendering.rb#L108">https://github.com/rails/rails/blob/d2cdf0be675b44771f950697fc0b19ef0ea453f9/actionview/lib/action_view/rendering.rb#L108</a></figcaption></figure><p>Now, <code>_render_template</code> does quite a number of things but the important line for us to close in on is the invocation of the method <code><a href="https://github.com/rails/rails/blob/d2cdf0be675b44771f950697fc0b19ef0ea453f9/actionview/lib/action_view/rendering.rb#L111">view_context</a></code>.</p><p> The <code><a href="https://github.com/rails/rails/blob/d2cdf0be675b44771f950697fc0b19ef0ea453f9/actionview/lib/action_view/rendering.rb#L92">view_context</a></code> method is the glue that wraps everything together here:</p><figure><pre><code> def view_context
  view_context_class.new(lookup_context, view_assigns, self)
end</code></pre><figcaption><a href="https://github.com/rails/rails/blob/d2cdf0be675b44771f950697fc0b19ef0ea453f9/actionview/lib/action_view/rendering.rb#L92">https://github.com/rails/rails/blob/d2cdf0be675b44771f950697fc0b19ef0ea453f9/actionview/lib/action_view/rendering.rb#L92</a></figcaption></figure><p>It instantiates a new <code><a href="https://github.com/rails/rails/blob/d2cdf0be675b44771f950697fc0b19ef0ea453f9/actionview/lib/action_view/rendering.rb#L65">ActionView::Base</a></code> object (<code>view_context_class</code>) and passes it an <code>assigns</code> hash consisting of... a call to the <code>view_assigns</code> method from <code>AbstractController::Base</code> !!</p><p>This means that a hash of the currently defined instance variables for the controller that called render will be passed along as an argument to the <code>ActionView::Base</code> <code>initialize</code> method. Nice! We've found the source. Here is the the above words in image form:</p><figure><img src="https://blog.robsdomain.com/content/images/2020/06/Rails-Rendering-Variables.png"></figure><p>Phew... quite the journey but we've pulled &nbsp;the curtains back on one of the more opaque parts of the Ruby on Rails framework and have made it through in one piece.</p><p>Have fun!</p>
        </section>

        
    </article>
</div></div>]]>
            </description>
            <link>https://blog.robsdomain.com/how-does-rails-assign-view-variables/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24537617</guid>
            <pubDate>Sun, 20 Sep 2020 21:37:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BridgeCom Systems SkyBridge Hotspot Review]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24537600">thread link</a>) | @RFTinker
<br/>
September 20, 2020 | http://k0lwc.com/bridgecom-systems-skybridge-hotspot-review/ | <a href="https://web.archive.org/web/*/http://k0lwc.com/bridgecom-systems-skybridge-hotspot-review/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-248">
	<!-- .entry-header -->

	<div>
		
<p>Are you a ham radio operator interested in DMR? Getting started can be intimidating, but not with the <a href="https://www.bridgecomsystems.com/pages/plug-and-play-878-plus-skybridge">SkyBridge Hotspot DMR Plug N’ Play package</a> from BridgeCom Systems. </p>



<p>BridgeCom’s SkyBridge dual band hotspot is the latest hotspot on the market for amateur radio operators. What makes it such a compelling buy is the ease at which you can get on the air. BridgeCom will take care of programming the radio <em>and</em> the hotspot before it ships. Once it arrives, simply plug in the hotspot, turn on the radio and you’re on the air rag chewing. </p>



<h2>BridgeCom SkyBridge Hotspot features</h2>



<p>The SkyBridges uses a Pi-Zero board with a custom MMDVM hat putting out 10mW of output power. More than enough power to blanket your entire house and property (unless you live on acres of property) with seamless digital coverage. </p>



<ul><li>Wired and wireless Internet capability</li><li>High-performance 32-bit ARM processor</li><li>SkyBridge&nbsp;Board Fully Assembled And Tested</li><li><a href="https://www.pistar.uk/">Pi-Star Operating System</a></li><li>Compatible with DMR, D-Star, Yaesu System Fuzion (YSF),&nbsp; NXDN, P25 and POCSAG radios</li><li>Supports the following Cross-Mode Capabilities: DMR to NXDN, DMR to YSF, YSF to DMR and YSF to NXDN</li><li>Supports operation in both 2m (144Mhz) and 70cm (440Mhz) bands</li><li>Onboard LEDs to show status (Tx, Rx, PTT, Mode)</li><li>Up to 10mW RF power</li><li>SMA antenna connector, dual-band VHF/UHF antenna included</li><li>MMDVM open-source firmware is pre-loaded and is easily upgraded via software</li><li>Built-in 1.3″ OLED display</li><li>Connection for Nextion LCD display</li><li><strong>1 Year Warranty</strong></li><li><strong>FCC Part 15 Certified</strong></li></ul>



<p>The most important thing you get, in my opinion, is fantastic support form BridgeCom. You’re paying for the piece of mind you’ll have someone to call if you have troubles, or something malfunctions. You will also get access to BridgeCom University, and online portal that provides a long list of videos that will help you learn everything you need to know about DMR. </p>







<h2>How far does the BridgeCom SkyBridge reach?</h2>



<p>Many hams wonder just how far a little 10mW transmitter will work. The answer is— surprisingly far. I set my SkyBridge near the window in my basement and was able to walk about 600 feet in my suburban neighborhood before losing the signal from my hotspot. Don’t worry about having coverage around your home or property. This hotspot has you covered! I <a href="http://k0lwc.com/what-is-the-range-of-a-dmr-hotspot/">tested the coverage from my PiSpot</a> with a high gain antenna at 40 feet HAAT, it’s worth checking out. </p>



<h2>Is the SkyBridge hotspot reliable?</h2>



<p>I was able to use the SkyBridge for a week and I found it to be incredibly reliable. It handled my day-to-day just as well as my PiSpot hotspot running a Raspberry PiB3 board and a DVMega hat. In fact, it ran cooler in temperature than my custom built PiB3. </p>



<h2>Can I talk to friends who use D-Star or YSF?</h2>



<p>Yes! The hotspot supports cross-mode capability thanks to the Pi-Star firmware. You can use your DMR radio to talk to your ham radio friends who may be using D-Star, YSF, P25 or NXDN. This is huge. It sucks we have a fragmented digital protocol system. With this hotspot that becomes less of an issue.</p>



<h2>Is the SkyBridge hotspot worth the money?</h2>



<p>If you’re a ham looking to make the jump into DMR, I think it’s absolutely worth it. The real value of the SkyBridge Plug N’ Play package is the ease of getting on the air. BridgeCom makes it incredibly easy. Pair that with access to BridgeCom University you can watch hours and hours worth of tutorials on DMR — that’s a lot of value in a single package. </p>



<p>You can buy the BridgeCom SkyBridge hotspot <a href="https://www.bridgecomsystems.com/pages/skybridge">here</a>, or get their SkyBridge Plug N’ Play package <a href="https://www.bridgecomsystems.com/pages/plug-and-play-878-plus-skybridge">here</a>. </p>



<h2>Take a look at what you get in this YouTube video</h2>



<figure><p>
<iframe id="_ytid_87122" width="640" height="360" data-origwidth="640" data-origheight="360" src="https://www.youtube.com/embed/bghFnES-KI4?enablejsapi=1&amp;rel=0&amp;modestbranding=0&amp;autoplay=0&amp;cc_load_policy=0&amp;iv_load_policy=1&amp;loop=0&amp;fs=1&amp;playsinline=0&amp;autohide=2&amp;theme=dark&amp;color=red&amp;controls=1&amp;" title="YouTube player" allow="autoplay; encrypted-media" allowfullscreen="" data-no-lazy="1" data-skipgform_ajax_framebjll=""></iframe>
</p></figure>
<br>
			</div><!-- .entry-content -->
</article></div>]]>
            </description>
            <link>http://k0lwc.com/bridgecom-systems-skybridge-hotspot-review/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24537600</guid>
            <pubDate>Sun, 20 Sep 2020 21:35:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building underground tunnels for 30 second delivery times]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24537480">thread link</a>) | @Mat_Sherman
<br/>
September 20, 2020 | https://share.transistor.fm/s/feaa771d | <a href="https://web.archive.org/web/*/https://share.transistor.fm/s/feaa771d">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  

  <article>
    <section>
      <h4>Summary</h4>
      <p>Garrett McCurrach is the cofounder of Pipedream Labs. Pipedream is a network of underground tubes that offers near-instantaneous delivery of objects to and from homes and businesses.
</p>
    </section>
        <section>
          <h4>Show Notes</h4>
          <div><p>Garrett McCurrach is the cofounder of <a href="https://pipedreamlabs.co/">Pipedream</a>. Pipedream is a network of underground tubes that offers near-instantaneous delivery of objects to and from homes and businesses.</p><p><strong>Listen to this episode if you:</strong></p></div><ul><li>You love moonshots</li><li>You want to see underground transportation more ubiquitous&nbsp;</li><li>You want to hear the big vision for Pipedream.</li></ul><p><strong>Thanks to Primeflow for sponsoring this episode of FTF!<br></strong>Itâ€™s time to focus on your biggest advantage - your relationships. Partner up with your network and drive business. Their software takes care of everything else. With Primeflow, you can source partners, manage your leads, and collect your fees, all within one easy software product. Check it out <a href="https://bit.ly/3hMvKET">here</a>.<strong><br></strong><br></p><p><strong><a target="_donate" rel="payment" title="â˜… Support this podcast by donating â˜…" href="https://forwardthinking.substack.com/">â˜… Support this podcast by donating â˜…</a></strong></p>
        </section>
    <section>
      <h4>What is Forward Thinking Founders?</h4>
      <p>Forward Thinking Founders is a podcast where Mat interviews high potential founders with early stage companies. This allows us to see inside the brain of genius founders before the rest of the world knows they even exist. On this show, you'll learn all about how to start a startup, pros and cons of different verticals, and learn the backstory and vision of tomorrow's billion-dollar companies, straight from the founders. With guests coming from Y Combinator, The Thiel Fellowship, Pioneer, and the f20r.com network, you're sure to get a sneak peek at world-class founders at work, every day. This is Forward Thinking Founders.</p>
    </section>
  </article>
</div></div>]]>
            </description>
            <link>https://share.transistor.fm/s/feaa771d</link>
            <guid isPermaLink="false">hacker-news-small-sites-24537480</guid>
            <pubDate>Sun, 20 Sep 2020 21:16:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Little Things: Speeding up C++ compilation]]>
            </title>
            <description>
<![CDATA[
Score 118 | Comments 61 (<a href="https://news.ycombinator.com/item?id=24537231">thread link</a>) | @ingve
<br/>
September 20, 2020 | https://codingnest.com/the-little-things-speeding-up-c-compilation/ | <a href="https://web.archive.org/web/*/https://codingnest.com/the-little-things-speeding-up-c-compilation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

    <article>

        

        <section>
            <p><em>The Little Things</em> is a new series of posts based on Locksley's internal training sessions. Often the contents are either proprietary (e.g. the inner workings of specific master key platforms) or not generally interesting (e.g. our internal libraries and tooling), but sometimes the contents are suitable for a wider audience, in which case I want to share them.</p>
<hr>
<p>This post will be about some source-level techniques for speeding up C++ compilation, and their (dis)advantages. It will <strong>not</strong> talk about things external to C++, such as buying better hardware, using a better build system, or using smarter linker<sup><a href="#fn1" id="fnref1">[1]</a></sup>. It will also not talk about the tooling that can find compilation bottlenecks, as that will be a subject of a later post.</p>
<h2 id="overviewofccompilationmodel">Overview of C++ compilation model</h2>
<p>I will start with a quick overview of the C++ compilation model, to provide context for some of the tricks I will show later. Note that this overview will be very coarse, if you want a detailed look at the subtleties of the <em>9</em> phase compilation model defined in the C++ standard, look elsewhere.</p>
<p>We will consider the compilation of C++ binary to happen in 3 steps:</p>
<ol>
<li>Preprocessing</li>
<li>Compilation</li>
<li>Linking</li>
</ol>
<h3 id="preprocessing">Preprocessing</h3>
<p>The first step is preprocessing. During it, the preprocessor takes a .cpp file and parses it, looking for <em>preprocessor directives</em>, such as <code>#include</code>, <code>#define</code>, <code>#ifdef</code>, etc.</p>
<p>Let's take this super simple file as an example</p>
<pre><code>// tiny.cpp
#define KONSTANTA 123

int main() {
    return KONSTANTA;
}
</code></pre>
<p>It contains one preprocessor directive, <code>#define</code>. It says that any following occurence of <code>KONSTANTA</code> should be replaced with <code>123</code>. Running the file through a preprocessor leads to output like this one:</p>
<pre><code>$ clang++ -E tiny.cpp
# 1 "tiny.cpp"
# 1 "&lt;built-in&gt;" 1
# 1 "&lt;built-in&gt;" 3
# 383 "&lt;built-in&gt;" 3
# 1 "&lt;command line&gt;" 1
# 1 "&lt;built-in&gt;" 2
# 1 "tiny.cpp" 2


int main() {
    return 123;
}
</code></pre>
<p>We can see that in <code>return KONSTANTA</code> the <code>KONSTANTA</code> part was replaced with <code>123</code>, as it should be. We also see that the compiler left itself a bunch of other notes, that we do not care about that much<sup><a href="#fn2" id="fnref2">[2]</a></sup>.</p>
<p>The big problem with the preprocessor model is that the <code>#include</code> directive literally means "copy-paste all of this file's contents here". Of course, if that file's contents contain further <code>#include</code> directives, then more files will be opened, their contents copied out, and in turn, the compiler will have more code to deal with. In other words, preprocessing increases the size of the input, usually significantly so.</p>
<p>The following is a simple "Hello World" in C++, using streams.</p>
<pre><code>// hello-world.cpp
#include &lt;iostream&gt;

int main() {
    std::cout &lt;&lt; "Hello World\n";
}
</code></pre>
<p>After preprocessing, the file will have <strong>28115</strong><sup><a href="#fn3" id="fnref3">[3]</a></sup> lines for the next step, compilation, to deal with.</p>
<pre><code>$ clang++ -E hello-world.cpp | wc -l
28115
</code></pre>
<h3 id="compilation">Compilation</h3>
<p>After a file is preprocessed, it is compiled into an <em>object file</em>. Object files contain the actual code to run, but cannot be run without linking. One of the reasons for this is that object files can refer to symbols (usually functions) that they do not have the definition (code) for. This happens, e.g. if a .cpp file uses a function that has been declared, but not defined, like so:</p>
<pre><code>// unlinked.cpp
void bar(); // defined elsewhere (hopefully)

void foo() {
    bar();
}
</code></pre>
<p>You can look inside a compiled object file to see what symbols it provides and what symbols it needs, using <code>nm</code> (Linux) or <code>dumpbin</code> (Windows). If we look at the output for the <code>unlinked.cpp</code> file, we get this:</p>
<pre><code>$ clang++ -c unlinked.cpp &amp;&amp; nm -C unlinked.o
                 U bar()
0000000000000000 T foo()
</code></pre>
<p><code>U</code> means that the symbol is not defined in this object file. <code>T</code> means that the symbol is in the text/code section and that it is exported, which means that other object files can get <code>foo</code> from this <code>unlinked.o</code>. It is important to know that symbols might also be present in an object file, but not be available to other object files. Such symbols are marked with <code>t</code>.</p>
<h3 id="linking">Linking</h3>
<p>After all the files have been compiled into object files, they have to be <em>linked</em> into the final binary artefact. During linking, all the various object files are smashed together in a specific format, e.g. ELF, and the various references to undefined symbols in object files are resolved with the address of the symbol, as provided by a different object file (or library).</p>
<p>With this overview done, we can start tackling the different ways to speed up the compilation of your code. Let's start simple.</p>
<h2 id="includeless"><code>#include</code> less</h2>
<p>Including a file usually brings in a <em>lot</em> of extra code, which the compiler then needs to parse and check. Thus the simplest, and usually also the biggest, way to speed up the compilation of your code, is to just <code>#include</code> fewer files. Reducing the include set is especially beneficial in header files, as they are likely to be included from other files, thus amplifying the impact of your improvements.</p>
<p>The easiest way to do this is to remove any unused includes. Unused includes shouldn't happen often, but sometimes they are left behind during refactoring, and using a tool like <a href="https://include-what-you-use.org/">IWYU</a> <em>can</em><sup><a href="#fn4" id="fnref4">[4]</a></sup> make it simple to do. However, just cleaning up unused includes is unlikely to provide many benefits, and so you will have to reach for bigger guns, forward declarations and manual outlining.</p>
<p>But before explaining forward declarations and manual outlining, I want to go over the costs of header inclusion quickly, so we can build up intuition on what sort of speed-ups we can expect from pruning down include graphs.</p>

<p>The table below shows the time required by Clang<sup><a href="#fn5" id="fnref5">[5]</a></sup> to compile a file that <em>only</em> includes some stdlib headers.</p>

<table>
<thead>
<tr>
<th>header(s) included</th>
<th>time to compile (ms)</th>
<th>difference from baseline (ms)</th>
</tr>
</thead>
<tbody>
<tr>
<td>none</td>
<td>11.3  ± 0.2</td>
<td>-</td>
</tr>
<tr>
<td><code>&lt;vector&gt;</code></td>
<td>68.8  ± 0.3</td>
<td>57.5 ±  0.36</td>
</tr>
<tr>
<td><code>&lt;string&gt;</code></td>
<td>136.3  ± 0.8</td>
<td>125.0 ±  0.82</td>
</tr>
<tr>
<td><code>&lt;stdexcept&gt;</code></td>
<td>137.0  ± 0.8</td>
<td>125.7 ±  0.82</td>
</tr>
<tr>
<td><code>&lt;vector&gt;</code>, <code>&lt;string&gt;</code></td>
<td>155.3  ± 0.9</td>
<td>144.0 ±  0.92</td>
</tr>
<tr>
<td><code>&lt;string&gt;</code>, <code>&lt;stdexcept&gt;</code></td>
<td>136.7  ± 0.7</td>
<td>125.4 ±  0.73</td>
</tr>
<tr>
<td><code>&lt;vector&gt;</code>, <code>&lt;string&gt;</code>, <code>&lt;stdexcept&gt;</code></td>
<td>156.1  ± 0.8</td>
<td>144.8 ±  0.82</td>
</tr>
</tbody>
</table>
<p>The first row shows the time needed to compile a completely empty file, to provide a baseline time required by the compiler to start, read the file, and do nothing. The other lines are more interesting. As the second line says, just including <code>&lt;vector&gt;</code> adds 57 ms to compilation times, even though there will be no actual line emitted. As we can see, the cost to include <code>&lt;string&gt;</code> is more than double of <code>&lt;vector&gt;</code>, and the cost to include <code>&lt;stdexcept&gt;</code> is about the same as for <code>&lt;string&gt;</code>.</p>
<p>More interesting are the rows for combinations of headers, because no combination of headers is as expensive as compiling each of them on its own. The reason is quite simple: their internal include overlap. The most extreme case is <code>&lt;string&gt;</code> + <code>&lt;stdexcept&gt;</code>, because <code>&lt;stdexcept&gt;</code> is basically <code>&lt;string&gt;</code> + couple of types deriving from <code>std::exception</code>.</p>
<p>What you should take away from this are two things:</p>
<ul>
<li>Even if you do not use anything from a header, you still have to pay for it.</li>
<li>Include costs do not neatly sum, nor subtract.</li>
</ul>
<p>Now let's go through techniques we can use to include fewer files.</p>
<h3 id="forwarddeclarations">Forward declarations</h3>
<p>Quite often, when we mention a type, we only need to know that it exists but do not need to know its definition. The common case is creating a pointer or a reference to a type, in which case you need a knowledge that the type exists (a <em>forward declaration</em>), but not what it looks like (a <em>definition</em>).</p>
<p>As an example, this header is valid:</p>
<pre><code>class KeyShape; // forward declaration

size_t count_differences(KeyShape const&amp; lhs, KeyShape const&amp; rhs);
</code></pre>
<p>as long as the implementation file includes the appropriate headers:</p>
<pre><code>#include "key-shape.hpp" // provides the full definition of KeyShape

size_t count_differences(KeyShape const&amp; lhs, KeyShape const&amp; rhs) {
    assert(lhs.positions() == rhs.positions());
    ...
}
</code></pre>
<p>You can also use forward declaration together with some templated classes, whose size does not change depending on the template argument, e.g. <code>std::unique_ptr</code> and <code>std::vector</code><sup><a href="#fn6" id="fnref6">[6]</a></sup>. However, doing so can force you to outline your constructors, destructors and other special member functions (<em>SMFs</em>), as those usually need to see the full definition of the type. Your code then ends up looking like this:</p>
<pre><code>// foo.hpp
#include &lt;memory&gt;

class Bar;

class Foo {
    std::unique_ptr&lt;Bar&gt; m_ptr;
public:
    Foo(); // = default;
    ~Foo(); // = default;
};
</code></pre>
<pre><code>// foo.cpp
#include "bar.hpp"

Foo::Foo() = default;
Foo::~Foo() = default;
</code></pre>
<p>Notice that we still use the compiler-generated default constructor and destructor, but do so in the <code>.cpp</code> file, where we see the full definition of <code>Bar</code>. I also like to use the <code>// = default;</code> comment to signal to other programmers reading the code that the SMF is explicitly declared but will be defaulted, and thus there won't be any special logic in it.</p>
<p>When using this technique, please remember that the outlined functions cannot be inlined without LTO. In other words, you probably do not want to outline <em>every</em> function just because you can, because calling trivial functions can be much more expensive than inlining their code directly.</p>
<h3 id="explicitoutlining">Explicit outlining</h3>
<p>The idea underlying explicit outlining is quite simple: sometimes we get better results if a piece of code is explicitly split away from a function. One of the most common reasons is, perhaps ironically, improving inlining by making the common path of a function small. However, in our case, the reason for doing this is to improve the compilation times.</p>
<p>If a piece of code is expensive to compile, and inlining it is not crucial for performance, only one TU has to pay for compiling it. The canonical example of this is throwing an exception in general, and exceptions from <code>&lt;stdexcept&gt;</code> in particular. Throwing an exception generates quite a lot of code, and throwing more complex standard exception types, such as <code>std::runtime_error</code>, also requires an expensive<sup><a href="#fn7" id="fnref7">[7]</a></sup> header, <code>&lt;stdexcept&gt;</code> to be included.</p>
<p>By instead replacing all <code>throw foo;</code> statements with calls to a helper function along the lines of <code>[[noreturn]] void throw_foo(char const* msg)</code>, the call sites become …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://codingnest.com/the-little-things-speeding-up-c-compilation/">https://codingnest.com/the-little-things-speeding-up-c-compilation/</a></em></p>]]>
            </description>
            <link>https://codingnest.com/the-little-things-speeding-up-c-compilation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24537231</guid>
            <pubDate>Sun, 20 Sep 2020 20:41:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why aren’t you more serious?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24537147">thread link</a>) | @luu
<br/>
September 20, 2020 | https://rubenerd.com/why-arent-you-more-serious/ | <a href="https://web.archive.org/web/*/https://rubenerd.com/why-arent-you-more-serious/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div property="articleBody">
<p>I get more hits to my site and RSS feed in a typical month now than I used to get in a given year. For a fifteen year old blog that started life as a Perl CGI script in high school, it’s been wild to see. Whether you’re coming here from Hacker News, Reddit, Twitter, Discord, newsgroups, or the BSD Now podcast, hi! Sometimes I talk about tech here.</p>
<p>This marked increase in traffic corresponds with more feedback email, a not altogether insignificant number of which are negative. I’ll address some recurring themes here, because they’re Jason Bourne of the same misunderstanding of the kind of site people have come across.</p>
<p>Once you filter out the obvious trolls saying BSD is dead, Apple computers are for posers who value form over function, and that we’re all sheep for wearing a mask, most of the remainder concern the tone of my posts, and what they consider the ancillary topics I cover. They claim that my writing is too jovial, my site <a href="https://rubenerd.com/about/#mascot">mascot</a> drawn by Clara is inappropriate, and inclusion of posts about <a href="https://rubenerd.com/josh-on-how-to-peel-garlic/" title="Josh on how to peel garlic">cooking garlic</a> are a waste of time and somehow detract from my serious technical and political posts.</p>
<p><em>(One gentleman spent an inordinate amount of time criticising Rubi’s skirt in such lurid detail I felt but the tiniest twinge of what women must feel as creepy men ogle them walking past).</em></p>
<p>I appreciate—most of—the feedback, but respectfully disagree. There may not be many of us doing this anymore, but this is specifically a personal blog. This site has always been a labour of love for me since I started it in high school in 2004, and will necessarily be about stuff that’s on my mind and that I’m interested in. There are drier technical blogs by people I respect out there, but that’s not my style.</p>
<p>I’m also unsure how one can quantify detraction in this context. I remember having a similar debate with a WikiProject Albums contributor, who claimed compilation album articles similarly detracted from the quality of Wikipedia. In a finite space like a newspaper or book that might make sense, but in an electronic medium it seems to me the easiest solution is to ignore things in which you have no interest. Your also free to find an anime mascot drawn by my girlfriend offensive, just as I’m free to include her to make the world a slightly nicer place.</p>
<p>Which dovetails to the third comment which I take more seriously. I haven’t received permission to quote their email, but in summary they said my serious posts about COVID, social security, and attitudes in open source software communities are valuable, but sporadic. The implication is it’s incumbent upon me to only discuss important topics, and that by including what amounts to sidebars I’m trivialising them.</p>
<p>This one, selfishly, comes down to self-preservation. I need to write about the intricacies of BSD text editors and fun engineering or cooking videos to afford me sufficient mental fortitude to discuss serious topics. Sometimes we all need a break, and this is how I do it.</p>
<p>As I wrote on my <a href="https://rubenerd.com/the-first-post/">first post</a> fifteen years ago:</p>
<blockquote>
<p>… it’s a blog site with random stuff on it that I think is groovy, weird etc … maybe one percent of it, or maybe two, might be useful to someone, especially with respect to some of the tech problems I’ve had and solved over the years. So here it is.</p>
</blockquote>
<p>Thanks for reading.</p>
</div></div>]]>
            </description>
            <link>https://rubenerd.com/why-arent-you-more-serious/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24537147</guid>
            <pubDate>Sun, 20 Sep 2020 20:30:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Welcome to the Turbulent Twenties]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24536933">thread link</a>) | @dforrestwilson
<br/>
September 20, 2020 | https://www.noemamag.com/welcome-to-the-turbulent-twenties/ | <a href="https://web.archive.org/web/*/https://www.noemamag.com/welcome-to-the-turbulent-twenties/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

				


<p>Almost three decades ago, one of us, Jack Goldstone, published a <a href="https://www.amazon.com/Revolution-Rebellion-Early-Modern-World/dp/1138222127/ref=pd_lpo_14_img_0/140-4438334-0411838?_encoding=UTF8&amp;pd_rd_i=1138222127&amp;pd_rd_r=48abcf2c-170c-43f1-ac2b-6aceb88ec983&amp;pd_rd_w=ROnfs&amp;pd_rd_wg=qroCO&amp;pf_rd_p=7b36d496-f366-">simple model</a> to determine a country’s vulnerability to political crisis. The model was based on how population changes shifted state, elite and popular behavior. Goldstone argued that, according to this Demographic-Structural Theory, in the 21st century, America was likely to get a populist, America-first leader who would sow a whirlwind of conflict.</p>



<p>Then ten years ago, the other of us, Peter Turchin, <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0237458">applied</a> Goldstone’s model to U.S. history, using current data. What emerged was alarming: The U.S. was heading toward the highest level of vulnerability to political crisis seen in this country in over a hundred years. Even before Trump was elected, Turchin <a href="https://www.nature.com/articles/463608a">published</a> his prediction that the U.S. was headed for the “Turbulent Twenties,” forecasting a period of growing instability in the United States and western Europe.</p>



<p>Given the Black Lives Matter protests and cascading clashes between competing armed factions in cities across the United States, from Portland, Oregon to Kenosha, Wisconsin, we are already well on our way there. But worse likely lies ahead.</p>



<p>Our model is based on the fact that across history, what creates the risk of political instability is the behavior of elites, who all too often react to long-term increases in population by committing three cardinal sins. First, faced with a surge of labor that dampens growth in wages and productivity, elites<strong> </strong><em>seek to take a larger portion of economic gains for themselves</em>, driving up inequality. Second, facing greater competition for elite wealth and status, <em>they tighten up the path to mobility to favor themselves and their progeny</em>. For example, in an increasingly meritocratic society, elites could keep places at top universities limited and raise the entry requirements and costs in ways that favor the children of those who had already succeeded. </p>



<p>Third, anxious to hold on to their rising fortunes, they <em>do all they can to resist taxation of their wealth and profits</em>, even if that means starving the government of needed revenues, leading to decaying infrastructure, declining public services and fast-rising government debts.</p>



<p>Such selfish elites lead the way to revolutions. They create simmering conditions of greater inequality and declining effectiveness of, and respect for, government. But their actions alone are not sufficient. Urbanization and greater education are needed to create concentrations of aware and organized groups in the populace who can mobilize and act for change.</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “Such selfish elites lead the way to revolutions.”    </p>

    
    
  </div>
</div>




<p>Top leadership matters. Leaders who aim to be inclusive and solve national problems can manage conflicts and defer a crisis. However, leaders who seek to benefit from and fan political divisions bring the final crisis closer. Typically, tensions build between elites who back a leader seeking to preserve their privileges and reforming elites who seek to rally popular support for major changes to bring a more open and inclusive social order. Each side works to paint the other as a fatal threat to society, creating such deep polarization that little of value can be accomplished, and problems grow worse until a crisis comes along that explodes the fragile social order.</p>



<p>These were the conditions that prevailed in the lead-up to the great upheavals in political history, from the French Revolution in the eighteenth century, to the revolutions of 1848 and the U.S. Civil War in the nineteenth century, the Russian and Chinese revolutions of the twentieth century and the many “color revolutions” that opened the twenty-first century. So, it is eye-opening that the data show very similar conditions now building up in the United States.</p>



<p>In applying our model to the U.S., we tracked a number of indicators of popular well-being, inequality and political polarization, all the way from 1800 to the present. These included the ratio of median workers’ wages to GDP per capita, life expectancy, the number of new millionaires and their influence on politics, the degree of strict party-line voting in Congress, and the incidence of deadly riots, terrorism and political assassinations. We found that all of these indicators pointed to two broad cycles in U.S. history.</p>



<p>In the decades following independence, despite growing party competition, elites in office often compromised and voted together, and rising national prosperity was broadly shared. But that wave of positive conditions peaked around 1820; from there, political polarization and economic inequality rose sharply in the years leading up to the Civil War. The crisis indicators peaked in the 1860s but did not fall sharply after the war; instead, they remained high until 1920 (the years of Reconstruction, Jim Crow, Gilded Age and violent labor unrest, and the anarchists).</p>



<p>Then, the tide shifted, and a second wave of greater unity and prosperity began to gather strength. Contrary to expectations, World War I and the Great Depression did <em>not </em>produce a rise in political instability indicators. Instead, the country pulled together. The reforms introduced during the Progressive Era and clinched in the New Deal reduced inequality and strengthened the economic share of workers; during and after World War II, the country agreed on new tax policies and increased spending on roads and schools.</p>



<p>The 1950s were a golden age of worker progress and party cooperation; even in the 1960s and 1970s, despite serious racial conflicts, the country’s leaders were able to agree on remarkably far-reaching reforms to improve civil rights and environmental protection. However, the 1960s were a high point in our indicators of political resilience; in the 1970s and 1980s, things began to turn, and by the 1990s, a new wave of rising inequality and political divisions was well underway, exemplified by Newt Gingrich’s policies as speaker of the House. In the next two decades, the crisis indicators rose just as sharply as they had in the decades before the Civil War. It was not just that by the late 2010s, overall inequality was rising to the levels not seen since the Gilded Age; median wages in relation to GDP per capita also were falling to historically low levels.</p>



<p>Writing in the journal <a href="https://www.nature.com/articles/463608a">Nature in 2010</a>, we pointed out that such trends were a reliable indicator of looming political instability and that they “look set to peak in the years around 2020.” In <a href="https://www.amazon.com/Ages-Discord-Peter-Turchin/dp/0996139540/ref=pd_lpo_14_img_1/140-4438334-0411838?_encoding=UTF8&amp;pd_rd_i=0996139540&amp;pd_rd_r=e31aa110-1e97-41b5-b8b9-59732b68e1b1&amp;pd_rd_w=NKvjs&amp;pd_rd_wg=QoYuR&amp;pf_rd_p=7b36d496-f366-4631-94d3-61b87b52511b&amp;pf_rd_r=53CDBB3DFVBED71T3PKV&amp;psc=1&amp;refRID=53CDBB3DFVBED71T3PKV">Ages of Discord</a>, published early in 2016, we showed that America’s “political stress indicator” had turned up sharply in recent years and was on track to send us into the “Turbulent Twenties.”</p>


<!-- Content Image Block Template -->
<div>

  <div>

    <!-- Main Image -->
    <div>

            <div>
              <p><img width="1024" height="730" src="https://www.noemamag.com/wp-content/uploads/2020/09/Ages_of_Discord.png" alt="" srcset="https://www.noemamag.com/wp-content/uploads/2020/09/Ages_of_Discord.png 1024w, https://www.noemamag.com/wp-content/uploads/2020/09/Ages_of_Discord-300x214.png 300w, https://www.noemamag.com/wp-content/uploads/2020/09/Ages_of_Discord-768x548.png 768w, https://www.noemamag.com/wp-content/uploads/2020/09/Ages_of_Discord-540x385.png 540w, https://www.noemamag.com/wp-content/uploads/2020/09/Ages_of_Discord-701x500.png 701w, https://www.noemamag.com/wp-content/uploads/2020/09/Ages_of_Discord-898x640.png 898w, https://www.noemamag.com/wp-content/uploads/2020/09/Ages_of_Discord-600x428.png 600w" sizes="(max-width: 1024px) 100vw, 1024px"></p>
      </div>

              <div>
              
      <figcaption>
        <p>The Political Stress Index (PSI) combines the three crisis indicators in the Goldstone-Turchin theory: declining living standards, increasing intra-elite competition/conflict and a weakening state. Growing PSI indicates increased likelihood of political violence. The Well-Being Index indicates greater equality, greater elite consensus and a more legitimate state.</p>
      </figcaption>

            </div>
      
    </div>


      </div>

</div>



<hr>



<p>This year, the COVID-19 pandemic and the death of George Floyd at the hands of the Minneapolis police have delivered a double-barreled crisis to U.S. politics. America has reacted with a nationwide, months-long series of urban protests. But this explosion of protest is not just the result of this year’s events. The U.S. has weathered epidemics and racial protests before and produced legislation that made the country better as a result. What is different this decade is that these events are occurring at a time of extreme political polarization, after decades of falling worker’s share in national income, and with entrenched elite opposition to increased spending on public services. These trends have crippled the U.S. government’s ability to mount an effective response to the pandemic, hampered our ability to deliver an inclusive economic relief policy and exacerbated the tensions over racial injustice that boiled over in response to the video of Floyd’s death.</p>



<p>Is the U.S. likely headed for still greater protests and violence? In a word, yes. Inequality and polarization have not been this high since the nineteenth century. Democrats are certain that if Donald Trump is re-elected, American democracy will not survive. Republicans are equally certain that if Trump loses, radical socialists will seize the wealth of elites and distribute it to underserving poor and minorities, forever destroying the economy of the United States. Both sides are also convinced that the other side intends to change the democratic “rules of the game” in ways that will make it impossible for them to compete effectively in future elections. In such conditions, elections are not merely contests over policy preferences; they become existential battles for the future of the nation. Whichever party loses is likely to view the results as rigged and the outcome as intolerable.</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “Almost any election scenario this fall is likely to lead to popular protests on a scale we have not seen this century.”    </p>

    
    
  </div>
</div>




<p>The upcoming election therefore offers <a href="https://www.bostonglobe.com/2020/07/25/nation/bipartisan-group-secretly-gathered-game-out-contested-trump-biden-election-it-wasnt-pretty/">several outcomes</a> that could trigger mass violence. If Trump wins narrowly in the electoral college but loses the popular vote by a large margin, there will surely be massive demonstrations protesting the outcome, calling it illegitimate and demanding allegiance to the will of the majority of Americans. Trump may then be tempted to call in federal forces to put down these protests (as in Portland), which may in turn, as in Portland, provoke even larger uprisings.</p>



<p>If Trump loses, he is likely to contest the outcome as a “<a href="https://nymag.com/intelligencer/2020/05/trump-is-preparing-to-contest-any-election-loss.html">rigged</a>” election. But that action will again lead to massive popular protests, this time to insist that the election results be honored. If Trump again puts federal security forces in …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.noemamag.com/welcome-to-the-turbulent-twenties/">https://www.noemamag.com/welcome-to-the-turbulent-twenties/</a></em></p>]]>
            </description>
            <link>https://www.noemamag.com/welcome-to-the-turbulent-twenties/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24536933</guid>
            <pubDate>Sun, 20 Sep 2020 20:03:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Secrets I use to becoming a better remote developer]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24536775">thread link</a>) | @mateusfreira
<br/>
September 20, 2020 | https://mateusfreira.github.io/@mateusfreira-secrets-to-becoming-a-better-remote-developer/ | <a href="https://web.archive.org/web/*/https://mateusfreira.github.io/@mateusfreira-secrets-to-becoming-a-better-remote-developer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>I have been working as a remote developer fulltime, for the last five years. Part-time/freelancing for at least ten years, over this time, I have collected several tips and tricks on how to become better at it and how to succeed and deliver results under this environment. I am writing this post to share some of these tricks, while this is a brief list. I am always testing these things. I thought it would be useful to do this one and periodically create a new one to share some updates.</p>

<p>If you are a TLDR reader, I am sharing here the list of the subtitles:</p>

<ul id="markdown-toc">
  <li><a href="#secrets" id="markdown-toc-secrets">Secrets</a>    <ul>
      <li><a href="#be-positive-and-open-minded" id="markdown-toc-be-positive-and-open-minded">Be Positive and Open-minded</a></li>
      <li><a href="#create-a-clean-setup-and-neat-workspace" id="markdown-toc-create-a-clean-setup-and-neat-workspace">Create a clean setup and neat workspace</a></li>
      <li><a href="#create-a-before-commit-secret-message" id="markdown-toc-create-a-before-commit-secret-message">Create a “before commit” secret message</a></li>
      <li><a href="#create-a-pull-request-checklist" id="markdown-toc-create-a-pull-request-checklist">Create a Pull request checklist</a></li>
      <li><a href="#address-daily-meetings-like-a-diary" id="markdown-toc-address-daily-meetings-like-a-diary">Address daily meetings like a diary</a></li>
      <li><a href="#tools-you-should-use" id="markdown-toc-tools-you-should-use">Tools you should use</a>        <ul>
          <li><a href="#1-grammarly" id="markdown-toc-1-grammarly">1. Grammarly</a></li>
          <li><a href="#2-time-tracker" id="markdown-toc-2-time-tracker">2. Time tracker</a></li>
          <li><a href="#3-skitch" id="markdown-toc-3-skitch">3. Skitch</a></li>
          <li><a href="#4-obs-screen-recording" id="markdown-toc-4-obs-screen-recording">4. OBS (screen recording)</a></li>
        </ul>
      </li>
      <li><a href="#take-notes-notes-and-notes" id="markdown-toc-take-notes-notes-and-notes">Take Notes, notes, and notes</a></li>
      <li><a href="#work-in-the-morning" id="markdown-toc-work-in-the-morning">Work in the morning</a></li>
      <li><a href="#create-a-routine" id="markdown-toc-create-a-routine">Create a routine</a>        <ul>
          <li><a href="#1-wake-up-early" id="markdown-toc-1-wake-up-early">1. Wake up early</a></li>
          <li><a href="#2-prepare-coffee" id="markdown-toc-2-prepare-coffee">2. Prepare coffee</a></li>
          <li><a href="#3-workout-3-times-a-week" id="markdown-toc-3-workout-3-times-a-week">3. Workout 3 times a week</a></li>
          <li><a href="#4-read" id="markdown-toc-4-read">4. Read</a></li>
          <li><a href="#5-write" id="markdown-toc-5-write">5. Write</a></li>
          <li><a href="#6-sleep-regularly" id="markdown-toc-6-sleep-regularly">6. Sleep regularly</a></li>
        </ul>
      </li>
      <li><a href="#use-vim-and-tmux-or-at-least-master-your-env-and-editor" id="markdown-toc-use-vim-and-tmux-or-at-least-master-your-env-and-editor">Use Vim and Tmux (or at least master your Env and editor)</a></li>
      <li><a href="#create-a-dotproject" id="markdown-toc-create-a-dotproject">Create a Dotproject</a></li>
      <li><a href="#read-these-books" id="markdown-toc-read-these-books">Read these books</a>        <ul>
          <li><a href="#1-the-culture-map" id="markdown-toc-1-the-culture-map">1. The Culture map</a></li>
          <li><a href="#2-the-pragmatic-programmer" id="markdown-toc-2-the-pragmatic-programmer">2. The Pragmatic Programmer</a></li>
          <li><a href="#3-getting-thins-done" id="markdown-toc-3-getting-thins-done">3. Getting Thins done</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
  <li><a href="#reviewers" id="markdown-toc-reviewers">Reviewers</a></li>
</ul>

<p>Now, if you find something interesting, stay with me and let’s learn something.</p>

<h2 id="secrets">Secrets</h2>

<p>From the easiest to the hardest.</p>

<h3 id="be-positive-and-open-minded">Be Positive and Open-minded</h3>

<p>This may be cliche, and not everyone is a positive person (and does not need to be). Still, is cool to have a positive attitude upfront a challenge or request; I am not saying you should be a yes man, I am saying that when you get a request, try to think about it as if is a challenge rather than a boring request,  or someone wanting to steal some of your time.</p>

<p>Be energetic and show what happens when you overcome some hard challenges, push the time to be more positive (for example). Being positive and expressing the success will increase yours and your team morale, and high team morale increases the chance of success.</p>

<h3 id="create-a-clean-setup-and-neat-workspace">Create a clean setup and neat workspace</h3>

<p>My workspace has a significant impact on my state of mind and even my productivity; back when I started working remotely, my office was a mess. I had a lot of objects on my table, and lots of them I had never used or even touched. That all ended-up on a day that I got a massive allergy that lasted for over two weeks. I noticed that was because of the dust in my office. It was out of control, and it would have been easier to clean it up weren’t for all the objects I had on my table.</p>

<p><img src="https://user-images.githubusercontent.com/234049/92327865-0b314c80-f033-11ea-9727-baa8721d65a7.png" alt="Old office"></p>

<p>At that time, I also noticed I would work anywhere but in the office. After that day, I cleaned my office and removed everything from my table. In one week, I noticed a productivity-boosting and a much better sense of peace while working in my office. Then I started reading about all of that “clean-setup” movement, which immediately made sense. So I started the journey on how I could de more productive without working more hours, and I decided to go all-in. I stopped buying electronics that I rarely used and instead, I used the money to make my office simpler, cleaner, and more set to productivity.
I bought two ergonomic chairs, started using a single and bigger monitor instead of two. I got a mechanical arm that suspends it and therefore I do not occupy my table with supports. I switched my wired mouse and keyboard for wireless, added a plant, and even a fancy lamp to my office table.</p>

<p>Here is how it looks now.</p>

<p><img src="https://user-images.githubusercontent.com/234049/93273814-36ccd900-f78f-11ea-844e-bad54f0d8dab.png" alt="New office"></p>

<p>Since these changes, I’ve noticed an even more significant increase in my productivity and well-being while working. I am still working out of the office sometimes, like from the garden of my house, from coffee shops or libraries, but now I feel there is no more productive place than my office in the quiet hours of the day. And I have tested myself to see how to return to the old mess environment. I placed a single page of paper on my table next to my keyboard, and at the end of that day, I felt exhausted. That day didn’t feel productive at all. It amazes me how much impact can a little mess do to my well-being nowadays, and how could I possibly work on such a chaotic environment in a close past.</p>

<p><img src="https://user-images.githubusercontent.com/234049/92327958-bcd07d80-f033-11ea-86d5-4c8205b63a1f.jpg" alt="Garden"></p>

<h3 id="create-a-before-commit-secret-message">Create a “before commit” secret message</h3>

<p>Before doing any commit, my secret is that I will have my editor asking me, <code>Is it easy to change?</code>. This advice comes from several coding or software design books. The most important factory of a useful feature, project, software, method, and commit is that it needs to be changed easily. The idea for that message came from the book <a href="https://amzn.to/2AVGWiZ">Pragmatic programmer</a> (This is an outstanding book I recommend for any programmer at any level). As soon as I read it, I knew it would be a good idea to ask my self that question from time to time, once every commit seems to be the best I have for the moment.</p>

<p><img src="https://mateusfreira.github.io/images/commit-message.png" alt="Secret commit question"></p>

<h3 id="create-a-pull-request-checklist">Create a Pull request checklist</h3>

<p>In my daily notes, I have one checklist for each PR I will open for any project. This will help me making sure that PR will be good and will pass easily on review. I am also giving a grammar checking on Grammarly (I will talk about it in detail later in the Grammarly chapter). Check the variable names I have added in (You know how hard naming is), check the docs of the methods (So I make sure I’ve documented any critical information), check API docs (Changes in public APIs are usually rare, but when they happen you better remember to also update their docs). Smoke testing (of course, running the tests locally and seeing how they go). And finally, improve something I see that is bad (I try as much as I can not to rush on PR opening and to have this last step to improve something work for me like and “It won’t be possible to rush at this point”. The thing is, I usually find other small problem on the code in this step and consider it to be one of the most important)</p>

<div><div><pre><code><span># PR self review check list</span>
- <span>[</span> <span>]</span> Pass grammarly <span>in </span>the PR body
- <span>[</span> <span>]</span> Pass grammarly <span>in </span>the <span>test </span>spec
- <span>[</span> <span>]</span> Revisit variables and methods names
- <span>[</span> <span>]</span> Check every public method doc
- <span>[</span> <span>]</span> Check API docs
- <span>[</span> <span>]</span> Smoke <span>test </span>everyting
- <span>[</span> <span>]</span> Improvement
</code></pre></div></div>

<h3 id="address-daily-meetings-like-a-diary">Address daily meetings like a diary</h3>

<p>Some people think that daily meetings are boring, but I think they can and should be fun and productive. I write my daily meeting notes every day as if I were keeping a diary, telling a short story about yesterday and this morning, as well as what I plan to do today and whether the plan for the week needs to change. I usually start working 4 hours before the next member of my team wakes up (I work from Brazil with a team located in the USA), so I write the notes of the daily meetings between 2 and 3 hours after starting work, which helps me to clarify how my day was yesterday, what should I keep doing, what should I avoid and what is blocking.</p>

<p>Also, the notes will give you a direct message to say at daily meetings, and I avoid starting the meeting by saying, “Let me remember what I did yesterday !!!” you will look professional, having the updates you need to provide at your fingertips. It also gives you a sense of how things are going over the days; you can look back at your daily notes and see if you’re making progress or not.</p>

<p>The time tracker is your ally when taking notes; this will help you not to forget any details, even if you take notes 3 days later, on a Monday. After a while, it will be natural, and you will not need to remember to do them, to start this habit, I recommend adding a task in your agenda 1 hour before the daily meeting to make notes this way once in the daily meeting begins you will be ready.</p>

<h3 id="tools-you-should-use">Tools you should use</h3>

<h4 id="1-grammarly">1. <a href="https://www.grammarly.com/">Grammarly</a></h4>

<p>Grammarly, for me, is one of the most essential tools for my day-to-day, whether as my text editor or email corrector. Writing for me is a superpower for remote workers and we have to make sure our text is reasonable; you do not need to proofread every single document you produce but it helps you not having any typos or structural problems. I do overuse Grammarly, and it has paid dividends for the last three years. Since I started my master’s degree, I had it verifying every single article and master thesis. Since then, I use to say it is the best investment I do every year.</p>

<h4 id="2-time-tracker">2. Time tracker</h4>

<p>Time tracking is a superpower that will enable you to see where you are putting your time on, even if your employer does not require it, I would recommend you to have one for many reasons.</p>
<ul>
  <li>You will where you are spending most of your time in.</li>
  <li>You can avoid overworking by knowing how many hours you worked on that day and not trusting your sense of “have I worked too much or too few?”</li>
</ul>

<p>Today I use <a href="https://www.getharvest.com/">Harvest</a> but in the past, while working as independet contractor I have used <a href="http://toggl.com/">Toggl</a>, and I track my activities in real time, without caring about all about details (Like I will not stop the clock if I go out to grap coffee or to read email), but I would recommend using any if them that you like using.</p>

<h4 id="3-skitch">3. <a href="https://evernote.com/products/skitch">Skitch</a></h4>

<p>One picture worths a thousand words, but it needs to be good, because sometimes you need to explain complex subjects to people that will not have the same context you have about the topic you are talking about. In that matter, Skitch is a great tool to take prints and show critical points and do short explanations. Check out the next image, where I was explaining a chart just as an example.</p>

<p><img width="1849" alt="Grafana_-_Nun-Db_Monitoring" src="https://user-images.githubusercontent.com/234049/93271844-9d032d00-f78a-11ea-9e1c-922578623c36.png"></p>

<h4 id="4-obs-screen-recording">4. <a href="https://obsproject.com/">OBS</a> (screen recording)</h4>

<p>As well as writing, showing information as video can be a superpower. Some subjects are much easier to demonstrate as a video than as a text. For example, simulating a bug or showing a problem needs to touch several services and multiple monitoring charts and sources.
Recording a good video showing how you find the bug, how you made sure it was fixed, or even explaining the process you have implemented can save you several paragraphs of text, and save you from having a PR rejected. Any complex new feature or bug fix, I would advise you to come with an excellent text in the PR, great code comments, great self-review showing the critical areas, and a good video explaining …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mateusfreira.github.io/@mateusfreira-secrets-to-becoming-a-better-remote-developer/">https://mateusfreira.github.io/@mateusfreira-secrets-to-becoming-a-better-remote-developer/</a></em></p>]]>
            </description>
            <link>https://mateusfreira.github.io/@mateusfreira-secrets-to-becoming-a-better-remote-developer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24536775</guid>
            <pubDate>Sun, 20 Sep 2020 19:44:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Not Rust?]]>
            </title>
            <description>
<![CDATA[
Score 291 | Comments 271 (<a href="https://news.ycombinator.com/item?id=24536645">thread link</a>) | @dochtman
<br/>
September 20, 2020 | https://matklad.github.io/2020/09/20/why-not-rust.html | <a href="https://web.archive.org/web/*/https://matklad.github.io/2020/09/20/why-not-rust.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article>
  
  <p>Sep 20, 2020</p>
  <p>I’ve recently read an article criticizing Rust, and, while it made a bunch of good points, I didn’t enjoy it — it was an easy to argue with piece.
In general, I feel that I can’t recommend an article criticizing Rust.
This is a shame — confronting drawbacks is important, and debunking low effort/miss informed attempts at critique sadly inoculates against actually good arguments.</p>
<p>So, here’s my attempt to argue <em>against</em> Rust:</p>
<div>
<dl>
<dt>Not All Programming is Systems Programming</dt>
<dd>
<div>
<div>
<p>Rust is a systems programming language.
It offers precise control over data layout and runtime behavior of the code, granting  you maximal performance and flexibility.
Unlike other systems programming languages, it also provides memory safety — buggy programs terminate in a well-defined manner, instead of unleashing (potentially security-sensitive) undefined behavior.</p>
<p>However, in many (most) cases, one doesn’t need ultimate performance or control over hardware resources.
For these situations, modern managed languages like Kotlin or Go offer decent speed, enviable
<a href="https://qconlondon.com/london-2017/system/files/presentation-slides/highperformancemanagedlanguages.pdf">time to performance</a>, and are memory safe by virtue of using a garbage collector for dynamic memory management.</p>
</div>
</div>
</dd>
<dt>Complexity</dt>
<dd>
<div>
<div>
<p>Programmer’s time is valuable, and, if you pick Rust, expect to spend some of it on learning the ropes.
Rust community poured a lot of time into creating high-quality teaching materials, but the Rust language <em>is</em> big.
Even if a Rust implementation would provide value for you, you might not have resources to invest into growing the language expertise.</p>
<p>Rust’s price for improved control is the curse of choice:</p>
<div>
<div>
<pre><code data-lang="rust"><table><tbody><tr><td><pre>1
2
3
4
5
6
</pre></td><td><pre><span>struct</span> <span>Foo</span>     <span>{</span> <span>bar</span><span>:</span> <span>Bar</span>         <span>}</span>
<span>struct</span> <span>Foo</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>{</span> <span>bar</span><span>:</span> <span>&amp;</span><span>'a</span> <span>Bar</span>     <span>}</span>
<span>struct</span> <span>Foo</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>{</span> <span>bar</span><span>:</span> <span>&amp;</span><span>'a</span> <span>mut</span> <span>Bar</span> <span>}</span>
<span>struct</span> <span>Foo</span>     <span>{</span> <span>bar</span><span>:</span> <span>Box</span><span>&lt;</span><span>Bar</span><span>&gt;</span>    <span>}</span>
<span>struct</span> <span>Foo</span>     <span>{</span> <span>bar</span><span>:</span> <span>Rc</span><span>&lt;</span><span>Bar</span><span>&gt;</span>     <span>}</span>
<span>struct</span> <span>Foo</span>     <span>{</span> <span>bar</span><span>:</span> <span>Arc</span><span>&lt;</span><span>Bar</span><span>&gt;</span>    <span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>In Kotlin, you write <code>class Foo(val bar: Bar)</code>, and proceed with solving your business problem.
In Rust, there are choices to be made, some important enough to have dedicated syntax.</p>
<p>All this complexity is there for a reason — we don’t know how to create a simpler memory safe low-level language.
But not every task requires a low-level language to solve it.</p>

</div>
</div>
</dd>
<dt>Compile Times</dt>
<dd>
<div>
<div>
<p>Compile times are a multiplier for everything.
A program written in a slower to run but faster to compile programming language can be <em>faster</em> to run because the programmer will have more time to optimize!</p>
<p>Rust intentionally picked slow compilers in the <a href="https://research.swtch.com/generic">generics dilemma</a>.
This is not necessary the end of the world (the resulting runtime performance improvements are real), but it does mean that you’ll have to fight tooth and nail for reasonable build times in larger projects.</p>
<p><code>rustc</code> implements what is probably the most advanced <a href="https://rustc-dev-guide.rust-lang.org/queries/incremental-compilation.html">incremental compilation</a> algorithm in production compilers, but this feels a bit like fighting with language compilation model.</p>
<p>Unlike C++, Rust build is not embarrassingly parallel; the amount of parallelism is limited by length of the critical path in the dependency graph.
If you have 40+ cores to compile, this shows.</p>
<p>Rust also lacks an analog for the <a href="https://en.cppreference.com/w/cpp/language/pimpl">pimpl</a> idiom, which means that changing a crate requires recompiling (and not just relinking) all of its reverse dependencies.</p>
</div>
</div>
</dd>
<dt>Maturity</dt>
<dd>
<div>
<div>
<p>Five years old, Rust is definitely a young language.
Even though its future looks bright, I will bet more money on “C will be around in ten years” than on “Rust will be around in ten years”
(See <a href="https://en.wikipedia.org/wiki/Lindy_effect">Lindy Effect</a>).
If you are writing software to last decades, you should seriously consider risks associated with picking new technologies.
(But keep in mind that picking Java over Cobol for banking software in 90s retrospectively turned out to be the right choice).</p>
<p>There’s only one complete implementation of Rust — the <a href="https://github.com/rust-lang/rust/"><code>rustc</code></a> compiler.
The most advanced alternative implementation, <a href="https://github.com/thepowersgang/mrustc"><code>mrustc</code></a>, purposefully omits many static safety checks.
<code>rustc</code> at the moment supports only a single production-ready backend — LLVM.
Hence, its support for CPU architectures is narrower than that of C, which has GCC implementation as well as a number of vendor specific proprietary compilers.</p>
<p>Finally, Rust lacks an official specification.
<a href="https://doc.rust-lang.org/reference/">The reference</a> is a work in progress, and does not yet document all the fine implementation details.</p>
</div>
</div>
</dd>
<dt>Alternatives</dt>
<dd>
<div>
<div>
<p>There are other languages besides Rust in systems programming space, notably, C, C++, and Ada.</p>
<p>Modern C++ provides <a href="https://www.viva64.com/en/pvs-studio/">tools</a> and <a href="https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines">guidelines</a> for improving safety.
There’s even a proposal for a Rust-like <a href="https://github.com/isocpp/CppCoreGuidelines/blob/master/docs/Lifetime.pdf">lifetimes</a> mechanism!
Unlike Rust, using these tools does not <em>guarantee</em> the absence of memory safety issues.
However, if you already maintain a large body of C++ code, it makes sense to check if following best practices and using <a href="https://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html">sanitizers</a> helps with security issues.
This is hard, but clearly is easier than rewriting in another language!</p>
<p>If you use C, you can use formal methods to <a href="https://sel4.systems/Info/FAQ/proof.pml">prove</a> the absence of undefined behaviors, or just <a href="https://sqlite.org/testing.html">exhaustively test</a> everything.</p>
<p>Ada is memory safe if you don’t use dynamic memory (never call <code>free</code>).</p>
<p>Rust is an interesting point on the cost/safety curve, but is far from the only one!</p>
</div>
</div>
</dd>
<dt>Tooling</dt>
<dd>
<div>
<div>
<p>Rust tooling is a bit of a hit and miss.
The baseline tooling, the compiler and the build system
(<a href="https://doc.rust-lang.org/cargo/index.html">cargo</a>), are often cited as best in class.</p>
<p>But, for example, some runtime-related tools (most notably, heap profiling) are just absent — it’s hard to reflect on the runtime of the program if there’s no runtime!
Additionally, while IDE support is decent, it is nowhere near the Java-level of reliability.
Automated complex refactors of multi-million line programs are not possible in Rust today.</p>
</div>
</div>
</dd>
<dt>Integration</dt>
<dd>
<div>
<div>
<p>Whatever the Rust promise is, it’s a fact of life that today’s systems programming world speaks C, and is inhabited by C and C++.
Rust intentionally doesn’t try to mimic these languages — it doesn’t use C++-style classes or C ABI.</p>
<p>That means that integration between the worlds needs explicit bridges.
These are not seamless.
They are <code>unsafe</code>, not always completely zero-cost and need to be synchronized between the languages.
While the general promise of <a href="http://adventures.michaelfbryan.com/posts/how-to-riir/">piece-wise integration</a> holds up and the <a href="https://github.com/dtolnay/cxx">tooling</a> catches up, there is accidental complexity along the way.</p>
<p>One specific gotcha is that Cargo’s opinionated world view (which <em>is</em> a blessing for pure Rust projects) might make it harder to integrate with a bigger build system.</p>
</div>
</div>
</dd>
<dt>Performance</dt>
<dd>
<div>
<div>
<p>“Using LLVM” is not a universal solution to all performance problems.
While I am not aware of benchmarks comparing performance of C++ and Rust at scale, it’s not to hard to come up with a list of cases where Rust leaves some performance on the table relative to C++.</p>
<p>The biggest one is probably the fact that Rust’s move semantics is based on values (<code>memcpy</code> at the machine code level).
In contrast, C++ semantics uses special references you can steal data from (pointers at the machine code level).
In theory, compiler should be able to see through chain of copies; in practice it often doesn’t: <a href="https://github.com/rust-lang/rust/issues/57077">#57077</a>.
A related problem is the absence of placement new — Rust sometimes need to copy bytes to/from the stack, while C++ can construct the thing in place.</p>
<p>Somewhat amusingly, Rust’s default ABI (which is not stable, to make it as efficient as possible) is sometimes worse than that of C: <a href="https://github.com/rust-lang/rust/issues/26494#issuecomment-619506345">#26494</a>.</p>
<p>Finally, while in theory Rust code should be more efficient due to the significantly richer aliasing information, enabling aliasing-related optimizations triggers LLVM bugs and miscompilations: <a href="https://github.com/rust-lang/rust/issues/54878">#54878</a>.</p>
<p>But, to reiterate, these are cherry-picked examples, sometimes the field is tilted the other way.
For example, <code>std::unique_ptr</code> <a href="https://www.youtube.com/watch?v=rHIkrotSwcc&amp;feature=youtu.be&amp;t=1261">has a performance problem</a> which Rust’s <code>Box</code> lacks.</p>
<p>A potentially bigger issue is that Rust, with its definition time checked generics, is less expressive than C++.
So, some C++ <a href="http://eigen.tuxfamily.org/index.php?title=Expression_templates">template tricks</a> for high performance are not expressible in Rust using a nice syntax.</p>
</div>
</div>
</dd>
<dt>Meaning of Unsafe</dt>
<dd>
<div>
<div>
<p>An idea which is even more core to Rust than ownership &amp; borrowing is perhaps that of <code>unsafe</code> boundary.
That, by delineating all dangerous operations behind <code>unsafe</code> blocks and functions and insisting on providing a safe higher-level interface to them, it is possible to create a system which is both</p>
<div>
<ol>
<li>
<p>sound (non-<code>unsafe</code> code can’t cause undefined behavior),</p>
</li>
<li>
<p>and modular (different <code>unsafe</code> blocks can be checked separately).</p>
</li>
</ol>
</div>
<p>It’s pretty clear that the promise works out in practice: <a href="https://github.com/rust-fuzz/trophy-case">fuzzing Rust code</a> unearths panics, not buffer overruns.</p>
<p>But the theoretical outlook is not as rosy.</p>
<p><em>First</em>, there’s no definition of Rust memory model, so it is impossible to formally check if a given unsafe block is valid or not.
There’s informal definition of “things rustc does or might rely on” and in in-progress <a href="https://github.com/rust-lang/miri">runtime verifier</a>, but the actual model is in flux.
So there might be some <code>unsafe</code> code somewhere which works OK in practice today, might be declared invalid tomorrow, and broken by a new compiler optimization next year.</p>
<p><em>Second</em>, there’s also an observation that <code>unsafe</code> blocks are not, in fact, modular.
Sufficiently powerful <code>unsafe</code> blocks can, in effect, extend the language.
Two such extensions might be fine in isolation, but lead to undefined behavior if used simultaneously:
<a href="https://smallcultfollowing.com/babysteps/blog/2016/10/02/observational-equivalence-and-unsafe-code/">Observational equivalence and unsafe code</a>.</p>

</div>
</div>
</dd>
</dl>
</div>
<p>Here are some thing I’ve deliberately omitted from the list:</p>
<div>
<ul>
<li>
<p>Economics (“it’s harder to hire Rust programmers”) — I feel that the “maturity” section captures the essence of it which is not reducible to chicken and egg problem.</p>
</li>
<li>
<p>Dependencies (“stdlib is too small / everything has too many deps”) — given how good Cargo and the relevant parts of the language are, I personally don’t see this as a problem.</p>
</li>
<li>
<p>Dynamic linking (“Rust should have stable ABI”) — I don’t think this is a strong argument. Monomorphization is pretty fundamentally incompatible with dynamic linking and there’s C ABI if you really need to. I do think that the situation here can be improved, <a href="https://internals.rust-lang.org/t/a-stable-modular-abi-for-rust/12347/10?u=matklad">but I don’t think that improvement needs to be Rust-specific</a>.</p>
</li>
</ul>
</div>

</article>

  </div></div>]]>
            </description>
            <link>https://matklad.github.io/2020/09/20/why-not-rust.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24536645</guid>
            <pubDate>Sun, 20 Sep 2020 19:27:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tracing the NYC Trip in “The Warriors” (2006)]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24536427">thread link</a>) | @keiferski
<br/>
September 20, 2020 | http://www.stonegreasers.com/greaser/conclay.html | <a href="https://web.archive.org/web/*/http://www.stonegreasers.com/greaser/conclay.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="centernote"> 	
		<h3>Coney Island to The Bronx</h3>  
  		<p>"The Warriors" Movie: In 1979, the Street Gang the Coney Island Warriors made their Famous Trip - From Coney Island to Dyre Avenue/Eastchester in the Bronx - which would Change Their Lives Forever!. March 27, 2006, I Documented their Legendary Trip. "<em>It's still on, and we're going. Cyrus sent an emissary this afternoon to make sure. Cyrus don't want anybody packed or anybody flexing any muscle. So I gave him my word that the Warriors would uphold the truce. Everybody says that Cyrus is the one and only. I think we'd better go have a look for ourself</em>."</p>
		
<div><p><img src="http://www.stonegreasers.com/greaser/coney_station.jpg" alt="Its still and were going! Stillwells and Ocean Avenue Subway Station"> From Stillwells and Ocean Avenue, you take the Q Train to Union Square, that is where you catch the Number 5 Bronx train to Eastchester. 
		</p><p><span>"We ain't been to the Bronx before!"</span></p><p> <span>"No sweat! This Conclave is going to be a big item, every gang in the city is going to be there!"</span></p></div>

		<h2>The Big CI Coney Island</h2>
		<p><img src="http://www.stonegreasers.com/greaser/coney1.jpg" alt="Coney Island freak show building"><br>
      		<img src="http://www.stonegreasers.com/greaser/coney2.jpg" alt="Coney Island Neighborhood to the west from station">	
                <img src="http://www.stonegreasers.com/greaser/coney3.jpg" alt="Coney Island neighborhood to the North from the station">
      		<span>"We Fought All Night to Get Back to this?"</span></p>     	
  
    		<h2>Wonderwheel, The Cyclone, and the Observation Tower</h2>
		<div><p><img src="http://www.stonegreasers.com/greaser/q_train1.jpg" alt="From the Q Train, Coney Island and the Ocean">Q Train leaving Stillwells Station, you can see the world famous Cyclone Roller Coaster, the observation tower, the Wonderwheel, and the Ocean in the background. </p><p><span>"Were goin in there with nothing! Were goin in their like everybody else - nine guys, no weapons!"</span></p></div>
    
		<h4>At the Q line curve (East 16th Street) - Taggings on Buildings</h4>

         	<div><p><img src="http://www.stonegreasers.com/greaser/q_train2.jpg" alt="Around the curve, gang taggings on the buildings.">      The Q Train runs along Ocean Parkway, curves and heads up East 16th Street until it hits Prospect Park and runs along Flatbush Avenue.</p><p><span>"What do you know about Cyrus? He's the One and Only!" </span></p></div>
    
    		<h4>Union Square - 14th Street Station - Little Break in the Action</h4>
		<div><p><img src="http://www.stonegreasers.com/greaser/Union_sq.jpg" alt="Break in the action - the Gray Mime at Union Square">On my way down the ramp to pick up the Number 5 Bronx bound Lexington, I did not get delayed by the Punks or the Baseball Furies, but I did run into the Gray Lady Mime.</p><p><span>"You never what you're gonna run into. In our colours, we can't hide."<p>"Who wants to hide?"</p></span></p></div>

          	<h4>42nd Street - Grand Central Station</h4>
        	<div><p><img src="http://www.stonegreasers.com/greaser/lexington1.jpg" alt="The Lexington Number 5 Train"><span>"42nd Street - Next Stop!" </span></p><p>Made it to Grand Central. Now pick up the number 5 Bronx bound train.</p><p><span>"That's our train!" </span></p></div>
      
    		<h4>Lexington Number 5 Sights and Scenes</h4>    
      		<p><img src="http://www.stonegreasers.com/greaser/morris.jpg" alt="Bronx Morris Station">Morris Park Station - we are in the Bronx.  </p>
		<p><img src="http://www.stonegreasers.com/greaser/prospect.jpg" alt="Prospect Park Subway Station">Passing Prospect Avenue</p>
		<p><img src="http://www.stonegreasers.com/greaser/gunhill.jpg" alt="Gun Hill Subway station">Passing Gun Hill Road </p>
     
   		<h4>Dyre Avenue - Eastchester Final Stop</h4>
		<div><p><img src="http://www.stonegreasers.com/greaser/dyre.jpg" alt="Dyre Road Subway station">We made it! Dyre Avenue Station, the last stop on the Number 5. Now to make it to the Conclave to meet Cyrus.</p><p>Standing on the station platform, you can imagine the various gangs coming into the station and heading down the steps on their way to the Conclave.</p></div>
     
    		<h4>Scenes of the Dyre Avenue Hood</h4>
   		<p><img src="http://www.stonegreasers.com/greaser/dyre_station_3.jpg" alt="Dyre Road/Eastchester Subway Station">Eastchester Station </p>
          	<p><img src="http://www.stonegreasers.com/greaser/dyre_station_2.jpg" alt="Dyre Road Station - different angle photo">Not much in the way of a cemetery in the area, as I walked around looking for the Conclave. Today, the area seems to be desserted, or just a commuter stop. </p>
		<div><p><img src="http://www.stonegreasers.com/greaser/dyre_station_4.jpg" alt="Syre Road Subway station from a different angle">Picture taken from the Dyre Avenue Station platform.</p><p>Reminds me of the neighborhood the Orphans were from.</p></div>
     
    		<h4>Number 4 (Muggers' Express) Woodlawn Station</h4>
  		<p><img src="http://www.stonegreasers.com/greaser/woodlawn1.jpg" alt="Woodlawn Subway Station and Cementary">You have to wonder if the producer of the Warriors wanted us to imagine where the location of the Conclave was really at, because it seems like the Woodlawn line (aka. Muggers' Express), Route 4, would have been a better choice since across the street from the Woodlawn Station is the famous Civil War era Woodlawn Cemetery? </p>
  
		<h3>Retracing The Warriors By Subway Lines</h3> 
<ul>
<li>Looking at the MTA Subway Map, and considering that the map in the movie showed them taking the Number 5 Train to Eastchester, I would have to assume after the Warriors were chased by the Turnbull A.C's, they rode the Number 5 down as far as Morris Park before they were detoured by the subway line fire. That way they could walk to the Pelham Parkway Station and pick up the Number 2 line. If they were able to make it down as far as the 149th Street and Grand Concourse Station, they would be able to run between the B, D, 2, 4, 5, and 6 Lines. I assume that is what the Director wanted us to think. </li>

<li>After watching the Directors-cut DVD, you find that the producer wanted you to come to your own conclusion to the various questions that you have about the famous trip. He gave you the map on where the Warriors arrived, and I think the rest is up to
  	 your imagination on where the following events took place.</li>


<li>The subway map in "The Warriors" movie, showed that the "D", "M", "Q", and "B" trains made the Brighton Beach Coney Island loop. Today, the "B" train stops at Brighton Beach and the "M" train travels on the Fourth Avenue/New Utrecht line. The "Q" Train is the only train that still travels to Coney Island via the Brighton line. The trains that travel to and from Coney Island are the D, F, N, and Q lines. The N and D Trains connect to the number 4, 5, and 6 Bronx bound trains at the Broadway-Lafayette Street Station. The F Train connects to those lines at the Canal Street Station. The Q and the N Trains are the only two trains making the Union Square - 14th Street connection, but the Q train is the only one that swings out towards Brighton Beach from the Stillwell's station like the 1970 Subway map in the movie. The N train also runs through Bay Ridge instead of running either the Culver or Brighton Lines. Like the Fox said to Rembrant, "Nobody can read these maps anyways!"</li>
<li>I could not find Cyrus, the Turnbull A.C's, the Rogues, or the rest of the gangs at either location, but I wanted everyone to know - The Gaylords were there! <a href="http://www.stonegreasers.com/greaser/lords_of_kilbourn.html">"Lords of Kilbourn"</a></li>
<li><a href="http://www.scoutingny.com/the-new-york-city-filming-locations-of-the-warriors-ny-youve-changed/">New York City Filming Location for The Warriors</a> - Great website that takes you through the filming loacations in the movie.</li>
</ul>



        </div></div>]]>
            </description>
            <link>http://www.stonegreasers.com/greaser/conclay.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24536427</guid>
            <pubDate>Sun, 20 Sep 2020 19:03:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sixty second stories of exceptional founders every 10 days]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24536331">thread link</a>) | @evla
<br/>
September 20, 2020 | http://tareksway.com/visionaries | <a href="https://web.archive.org/web/*/http://tareksway.com/visionaries">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">	
<section>
<article id="page-5046">
<section>
<div data-token="zSb1c"><div><div><div><div>
<div>
<div>
<p><img src="https://tareksway.com/wp-content/uploads/2020/08/visionaries-logo-250-03-copy.png" alt="" width="250" height="40"></p><h5>60-SECOND STORIES OF EXCEPTIONAL FOUNDERS</h5>
<p>1 STORY EVERY 10 DAYS</p>

<h5>⬇︎ Read an example below ⬇︎</h5></div></div></div></div></div></div></div><div id="posts" data-token="5gLXL"><div><div><div><div><section>
<article id="post-5202">
<p><a href="https://tareksway.com/visionaries/sew-much-hope/"> <span><span><i></i></span></span> <img onload="Wpfcll.r(this,true);" src="https://tareksway.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" width="600" height="444" data-wpfc-original-src="https://tareksway.com/wp-content/uploads/2020/09/Singer-image.jpg" alt="blank" data-wpfc-original-srcset="https://tareksway.com/wp-content/uploads/2020/09/Singer-image.jpg 600w, https://tareksway.com/wp-content/uploads/2020/09/Singer-image-300x222.jpg 300w" sizes="(max-width: 600px) 100vw, 600px"> </a></p><div>
<h3>
<a href="https://tareksway.com/visionaries/sew-much-hope/" rel="bookmark" title="Permanent Link to Sew much hope">Sew much hope</a>
</h3>
<p><span>
<i></i><i></i>
<em>September 7, 2020</em>		</span></p><p><span>Reading time: 54 seconds</span></p>
<p>In 19th century America, less than 5% of US citizens had access to electricity and the average life expectancy was 45. Life was tough and opportunities were desperately needed.</p>
</div></article>
<article id="post-2525">
<p><a href="https://tareksway.com/visionaries/a-surprise-delivery-will-shu-deliveroo-story/"> <span><span><i></i></span></span> <img onload="Wpfcll.r(this,true);" src="https://tareksway.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" width="780" height="597" data-wpfc-original-src="https://tareksway.com/wp-content/uploads/2018/05/Will-Shu-Deliveroo-mini-780x597.jpg" alt="blank" data-wpfc-original-srcset="https://tareksway.com/wp-content/uploads/2018/05/Will-Shu-Deliveroo-mini-780x597.jpg 780w, https://tareksway.com/wp-content/uploads/2018/05/Will-Shu-Deliveroo-mini-300x230.jpg 300w, https://tareksway.com/wp-content/uploads/2018/05/Will-Shu-Deliveroo-mini-768x588.jpg 768w, https://tareksway.com/wp-content/uploads/2018/05/Will-Shu-Deliveroo-mini.jpg 900w" sizes="(max-width: 780px) 100vw, 780px"> </a></p><div>
<h3>
<a href="https://tareksway.com/visionaries/a-surprise-delivery-will-shu-deliveroo-story/" rel="bookmark" title="Permanent Link to A surprise delivery">A surprise delivery</a>
</h3>
<p><span>
<i></i><i></i>
<em>May 22, 2018</em>		</span></p><p><span>Reading time: 60 seconds</span></p>
<p>It was 2001 and American Will Shu was fresh out of college with a shiny new job at Morgan Stanley, New York. The money was awesome but the 100-hour workweek… not so much. </p>
</div></article>
<article id="post-2520">
<p><a href="https://tareksway.com/visionaries/from-grade-c-to-the-skies-fedex-story/"> <span><span><i></i></span></span> <img onload="Wpfcll.r(this,true);" src="https://tareksway.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" width="780" height="417" data-wpfc-original-src="https://tareksway.com/wp-content/uploads/2018/03/Frederick-Smith-FedEx-780x417.jpg" alt="blank" data-wpfc-original-srcset="https://tareksway.com/wp-content/uploads/2018/03/Frederick-Smith-FedEx-780x417.jpg 780w, https://tareksway.com/wp-content/uploads/2018/03/Frederick-Smith-FedEx-300x161.jpg 300w, https://tareksway.com/wp-content/uploads/2018/03/Frederick-Smith-FedEx-768x411.jpg 768w, https://tareksway.com/wp-content/uploads/2018/03/Frederick-Smith-FedEx.jpg 1000w" sizes="(max-width: 780px) 100vw, 780px"> </a></p><div>
<h3>
<a href="https://tareksway.com/visionaries/from-grade-c-to-the-skies-fedex-story/" rel="bookmark" title="Permanent Link to From grade “C” to the skies">From grade “C” to the skies</a>
</h3>
<p><span>
<i></i><i></i>
<em>March 15, 2018</em>		</span></p><p><span>Reading time: 60 seconds</span></p>
<p>Frederick Smith wasn’t exactly in love with academics. He attended Yale in 1962 and was a solid “C” student. When one of his courses assigned a paper, he wrote one at the last minute. He later admitted that it likely also got him a “C”.</p>
</div></article>
<article id="post-2516">
<p><a href="https://tareksway.com/visionaries/when-the-stars-are-misaligned-instagram-story/"> <span><span><i></i></span></span> <img onload="Wpfcll.r(this,true);" src="https://tareksway.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" width="780" height="569" data-wpfc-original-src="https://tareksway.com/wp-content/uploads/2018/02/22639499_1454023074646352_7020349780203143168_n900px-2-e1517504855497-780x569.jpg" alt="blank" data-wpfc-original-srcset="https://tareksway.com/wp-content/uploads/2018/02/22639499_1454023074646352_7020349780203143168_n900px-2-e1517504855497-780x569.jpg 780w, https://tareksway.com/wp-content/uploads/2018/02/22639499_1454023074646352_7020349780203143168_n900px-2-e1517504855497-300x219.jpg 300w, https://tareksway.com/wp-content/uploads/2018/02/22639499_1454023074646352_7020349780203143168_n900px-2-e1517504855497-768x560.jpg 768w, https://tareksway.com/wp-content/uploads/2018/02/22639499_1454023074646352_7020349780203143168_n900px-2-e1517504855497.jpg 897w" sizes="(max-width: 780px) 100vw, 780px"> </a></p><div>
<h3>
<a href="https://tareksway.com/visionaries/when-the-stars-are-misaligned-instagram-story/" rel="bookmark" title="Permanent Link to When the stars are misaligned">When the stars are misaligned</a>
</h3>
<p><span>
<i></i><i></i>
<em>February 4, 2018</em>		</span></p><p><span>Reading time: 59 seconds</span></p>
<p>In 2009, Kevin Systrom was working full time at a travel startup but was learning to code at night. Smartphones had only recently become “smart” after acquiring a camera and location capabilities.</p>
</div></article></section></div></div></div></div></div></section>
</article>
</section>
</div></div>]]>
            </description>
            <link>http://tareksway.com/visionaries</link>
            <guid isPermaLink="false">hacker-news-small-sites-24536331</guid>
            <pubDate>Sun, 20 Sep 2020 18:52:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In the computer]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24535977">thread link</a>) | @todsacerdoti
<br/>
September 20, 2020 | https://chris-martin.org/2020/in-the-computer | <a href="https://web.archive.org/web/*/https://chris-martin.org/2020/in-the-computer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>When people talk about "algebraic reasoning", explanations fall flat because we neglect to first figure out kind of reasoning we're contrasting it against. When we write computer code using an operational model, we do <i>think about</i> what we write — so what manner of reasoning are we using? Can we give it a name? And can we explain why it seems so incompatible with the sort of reasoning that Lambda Man is always going on about?</p><p>I propose that the culture of programming at present may be divided into two approaches, explained by the following competing conceptions of the act of programming:</p><ol><li>An operational programmer <i>goes into</i> the computer;</li><li>An algebraic programmer remains <i>outside</i> the computer.</li></ol><p>We all have some need to shift between the two perspectives, but many of us become more entrenched in one or the other.</p><h2>Who calls the calls</h2><p>To start piecing together the orientation of each kind of programmer with respect to the computer, I'd like to look at a curious question of agency regarding function calls.</p><ul><li>When I write the expression "f x", I may describe my act of programming by saying that "we <b>apply</b> the function <i>f</i> to an argument <i>x</i>".</li><li>When the machine executes the program, I expect that "it will <b>evaluate</b> the function <i>f</i> at the argument <i>x</i>".</li></ul><p>But this separation between my action as an author and the machine's action as an automaton is only so distinct in the parlance of an algebraic programmer. If I were a Python programmer:</p><ul><li>When I write the expression "f(x)", I am "calling the function <i>f</i>".</li><li>When the machine executes my program, I expect that the Python interpreter will "call the function <i>f</i>".</li></ul><p>So who calls the function: me or Python? The answer is both; I <i>am</i> Python, and its actions are my actions, regardless of whether I am present and typing into a REPL or whether I have scripted them out ahead of time in a program that may run in my absence.</p><h2>One with the machine</h2><p>In either variety of programming, we sometimes put ourselves in the shoes of the machine to reason about the anticipated outcome of what we write. But how this imagination works depends on a great deal on whether we are outside or in. When we trace an operational program flow, the text of the program forms a space we can move within, and each variable is a statue that comes alive and begins to talk. Algebraic expression evaluation is a much more sterile and dull affair, and we remain seated in our desk chair. <i>Evaluating</i> is rewriting an expression in another form; it does not take us into different headspace from the one in which we wrote the code in the first place.</p><h2>Removing the lime from the coconut</h2><p>When an experienced inside-the-computer author begins in a programming language that forces us to approach programs from the outside, we can expect the question: If "I have an <code>IO String</code>", then "how do I get to the <code>String</code>"?</p><p>While others have already addressed this question in detail, what I want to draw attention to here is that the misunderstanding originates from trying to apply the <i>inside</i> conceptual mapping to a programming model that is strongly <i>outside</i>. An <code>IO String</code> is a process that produces a <code>String</code> result. So if I <i>were</i> standing inside a Haskell program, holding such a thing in my hands, it stands to reason that I could run the process and get the string. But we do not <i>have</i> such values because we do not <i>go</i> inside to <i>get</i> anything. We remain at the text editor, writing definitions. One such definition might be for a process which consists of the machine 1. first running some <code>IO String</code> process; and then 2. doing some other action with the resulting string.</p><p>This is not an unfamiliar task for a JavaScript programmer, who knows that one cannot get the value from a Promise — all we can do is set up plans for what to do once the Promise is fulfilled. A JavaScript programmer, although inside of the computer, is outside of the event loop. When my callbacks are roused, I do my work, then I fall back sleep to await another gig.</p><h2>What you got in that room</h2><p>The term "global variable" reveals something interesting about our mental picture. Such a variable does not span the globe, nor even a local network. To what scope does a word so grand as "global" refer? Humbly, the scope of a process. Or perhaps an entire machine, if I am a kernel developer. When I code operationally, I reside in a tiny world — the landmasses on my little blue marble are the memory segments to which I have access.</p><p>When I switched from operational to algebraic programming, first I learned that there are no global variables, then that terminology began to fade from consciousness altogether. As a Haskell programmer, I'm not in a little globe on the desk; I live on the Earth and I type definitions. Among those definitions may be a datatype that represents the state of a process, true. But this datatype is not my world, and the vast majority definitions I write in service of the program will not be functions of it.</p><p>Private "member variables" in a Java class can only be accessed <i>from within</i> the class. Perhaps the preposition can be taken to refer somewhat literally to the lexical scope of the class definition — that is, the code that is written between the opening and closing braces. But do we employ a deeper container metaphor here? Maybe this one is just me, but I see the <i>instance</i> as a <i>room</i>, and the members as the stuff I have at my disposal when I'm working inside that room.</p><p>In Haskell we also have lexical scoping, as well as a notion of modules with definitions that are either exported or not exported, which for many purposes mirrors the public/private field distinction. But I do not have the experience of mentally going inside a module in the same sense as reasoning inside of a Java instance. I believe it is Java's coupling of modules with mutable state that encourages this spacial reasoning.</p><h2>Getting your steps in</h2><p>When you use a step debugger, you actually <i>step into</i> the program! This is true regardless of whether you are using the debugging facilities of Python or Haskell. Though the code may be algebraic, when we use a step debugger we are always looking at it from an operational perspective.</p><h2>Working on documents</h2><p>Lately I like to refer to my role as "author" more than "programmer" — regardless of whether the file extension is ".md" or ".hs". It's because I don't feel like I work inside a computer anymore. I work sitting <i>at</i> a computer, I write <i>about</i> programs, and — although much of what I write can be executed by a machine — I do not often become lost within, because I remain safely on the outside.</p></div></div></div>]]>
            </description>
            <link>https://chris-martin.org/2020/in-the-computer</link>
            <guid isPermaLink="false">hacker-news-small-sites-24535977</guid>
            <pubDate>Sun, 20 Sep 2020 18:18:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Waiting for the Next Python Implementation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24535503">thread link</a>) | @pcr910303
<br/>
September 20, 2020 | http://ballingt.com/next-python/ | <a href="https://web.archive.org/web/*/http://ballingt.com/next-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>The time may be ripe for a new Python implementation.</p>
<p>A <a href="https://www.youtube.com/watch?v=ITksU31c1WY">lot</a> <a href="https://www.youtube.com/watch?v=KDXhu4rxTNY">of</a> <a href="https://www.youtube.com/watch?v=ftP5BQh1-YM">keynotes</a> lately have called for one anyway. They are joined — informally, not speaking in an official capacity — by Python core developers in issuing a wakeup call: where is Python in the browser? Where is Python on mobile devices? How could Python be 2x faster?</p>
<p>Barry Warsaw at the <a href="https://youtu.be/8dDp-UHBJ_A?t=2288">PyCon 2019 Python Steering Council Panel Keynote</a>:</p>
<blockquote>
<p>The language is pretty awesome.
[…]
The interpreter, in a sense, is 28 years old.</p>
</blockquote>
<p>Such a new Python implementation might be faster, work on different platforms, or have a smaller end deliverable.</p>
<p>It might accomplish these goals with a just-in-time or ahead-of-time compiler.</p>
<p>WebAssembly might significantly influence its implementation.</p>
<p>And critically, it might implement a different specification of Python.</p>
<hr>
<p>Wait, what? Will this still be Python?</p>
<p>If the new implementation is useful enough and has a level of compatibility with CPython that the community can deal with, (Brett Cannon said <a href="https://talkpython.fm/episodes/transcript/213/webassembly-and-cpython">something like this on a podcast</a> a few months ago) then it might somehow be canonized.</p>
<p>This “Optimizable Python” or “Restricted Python” or “Fast Python” or “Static Python” or “Boring Python,” subset could, once agreed upon, have its semantics shadowed in CPython in an optional mode.</p>
<p>What might be up for debate? A few suggestions from <a href="https://youtu.be/KDXhu4rxTNY?t=1168">Łukasz’s talk</a>:</p>
<ul>
<li>eval / exec (compiled in an environment that doesn’t allow setting regions as executable, like iOS or (perhaps? I haven’t looked) the webassembly spec.</li>
<li>the complexities and dynamism of the import system.</li>
<li>metaclasses - I don’t know what this enables, but it seems like a concession parts of the community might be willing to make</li>
<li>descriptors</li>
<li>dynamic attribute access</li>
</ul>
<hr>
<p>So now that the Python 2 to 3 transition is wrapping up and the Python language’s governance issues have been dealt with, it’s time for some dramatic initiatives: let’s grab some stakeholders and come up with the parts of the Python spec to mark optional and get this into CPython so we can start porting code again! I propose <code>python -z</code> for zoom — there we go, ZoomPython! — because I don’t see <code>-z</code> in python or IPython command line tools. We’ll need some syntax like JavaScript’s <code>use strict</code> to mark code this way, I propose the magic string <code># this code zooms</code>. Can the committee just tell us what the new spec is already?</p>
<p>No! Or as Łukasz Langa says <a href="https://youtu.be/KDXhu4rxTNY?t=2470">in response to a a better question after his keynote</a>,</p>
<blockquote>
<p>“Yes, but the way you get there is to have an alternative platform that informs you what the constrained version of the language should be. If you try to predict the future of what are people are going to need, you’re likely to end up with a design that is artificial and not necessarily useful.”</p>
</blockquote>
<p>So we’re back to the hoping and waiting and wondering: where will the implementation proposal for FastPython come from?</p>
<hr>
<p>Despite some <a href="https://youtu.be/ftP5BQh1-YM?t=2898">calls for financially support of such an effort</a> it seems that leading the prototyping of a new language implementation is not at the top of the priority list for committee. Core developers and language steering committee members seem to believe that this kind of experimental project should come from the outside. (try searching for the word Community in the transcript of <a href="https://talkpython.fm/episodes/transcript/213/webassembly-and-cpython">the podcast Brett was on</a>) This makes sense to me.</p>
<p>PyPy is the second-most popular Python implementation. It’s “bug-compatible” with CPython, including the C extension interface, making it a viable drop-in, faster replacement for many CPython programs. It’s an incredible engineering effort, perhaps comparable in scope to the work optimizing JavaScript engines that made that language the fasted dynamically typed language in wide use. If dedicated graduate student and individual hackers, academic funding, and governments grants could make a Python so compliant and fast a Python implementation once, maybe that’s where the next implementation will come from too!</p>
<p>MicroPython is closer in design to an imagined implementation of the future: its behavior is <a href="https://docs.micropython.org/en/latest/genrst/index.html">different than CPython in a variety of cases</a> and includes <a href="https://docs.micropython.org/en/latest/reference/speed_python.html#the-native-code-emitter">the ability to compile individual functions</a> that do not use features like context managers and generators. MicroPython was initially a Kickstarter-backed effort, then later supported by the Python Software Foundation <a href="https://en.wikipedia.org/wiki/MicroPython">as part of its inclusion on the BBC Micro Bit</a>. The development of MicroPython provides an example of how an alternate implementation might be started by a single individual.</p>
<p>But I think the most likely place for a new implementation to come from is a large company that uses Python and has a specific need for a new interpreter. This belief comes from my time at Dropbox, where I’ve seen how projects to improve languages can happen at a company of that size: since we had so many programmers working on so much Python code, better Python tooling would be so useful a case could be made for doing it ourselves. At Dropbox this project has been the Mypy Python static type checker, but I could imagine similar projects to write language implementations. (I’m not imagining too hard; Dropbox is also supporting work on mypyc, a Python compiler I’ll discuss more in a future post.)</p>
<p>If you are employed at such a company, it’s hard for me to know how to help you make the business case, but know that it has been done before! Please consider it.</p>
<p>Where would that be? A lot of companies! Some of my favorite corporate contributions to the Python community have come from Dropbox and Instagram, but Python isn’t a niche thing anymore and there must be dozens? hundreds? of companies with idiosyncratic business interests such that a Python implementation that ran in the browser, or ran faster, or ran sandboxed, would save them millions of dollars.</p>
<hr>
<p>In <a href="https://youtu.be/KDXhu4rxTNY?t=962">his inspirational keynote</a>, Łukasz phrased this as a call to action:</p>
<blockquote>
<p>This is where you come in. Truly tremendous impact awaits!</p>
</blockquote>
<p>I don’t think I’ll be one the call-answerers here, but I wish these implementers the best!</p>
<p>I think I support the apparent decision for the search for the next implementation not to be centrally directed; I agree that this can come from the community, and the proof of its usefulness can too. But there is something I think we can do centrally.</p>
<p>Without pre-emptively deprecating Python language features or designating them as optional, Python can be made a more attractive implementation target by making it smaller in a another way: separating the language from standard library.</p>
<p>Glyph proposes moving CPython <a href="https://glyph.twistedmatrix.com/2019/06/kernel-python.html">toward a Kernel Python</a> for a variety of reasons. I find that case convincing.</p>

</div></div>]]>
            </description>
            <link>http://ballingt.com/next-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24535503</guid>
            <pubDate>Sun, 20 Sep 2020 17:29:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We need physical audio kill switches]]>
            </title>
            <description>
<![CDATA[
Score 418 | Comments 401 (<a href="https://news.ycombinator.com/item?id=24535408">thread link</a>) | @stargrave
<br/>
September 20, 2020 | https://rubenerd.com/we-need-physical-audio-kill-switches/ | <a href="https://web.archive.org/web/*/https://rubenerd.com/we-need-physical-audio-kill-switches/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div property="articleBody">
<p>(Update: I didn’t mention this concerned <strong>wired</strong> headphones).</p>
<p>I aggressively disagree with any computer design decisions that detract from ergonomics or health, and nowhere does this continue to remain bafflingly true than audio output. Strap in, I’m about to get a bit ranty!</p>
<p>If we encounter an unwanted audio signal emanating from our computers, especially an uncomfortably-loud one over headphones, we should <em>immediately</em> be able to terminate it. No exceptions. If there is any latency <em>whatsoever</em> between us hitting a mute button and the audio not cutting out, the hardware or software has failed. Crypton Future Media’s Hatsune Miku wouldn’t tolerate latency with her headphones, and neither should we.</p>
<p><img src="https://rubenerd.com/files/2020/miku-headphones@1x.jpg" srcset="https://rubenerd.com/files/2020/miku-headphones@1x.jpg 1x, https://rubenerd.com/files/2020/miku-headphones@2x.jpg 2x" alt=""></p>
<p>I was in a conference call last Friday where I’d adjusted the volume up to compensate for the client’s quiet microphone, only to be audibly shot in the ears by an auto-playing video on a website. There is a <em>lot</em> of problematic stuff to unpack there, much of which is not the fault of the audio hardware or OS. But shocked in the moment, I hit the mute button on my MacBook Pro Touchbar, and it took a solid two seconds for it to register. My ears were ringing throughout the whole call. <em>This is unacceptable.</em></p>
<p>Well-engineered mute buttons on keyboards shouldn’t need to go to software, they should immediately send a signal to the motherboard’s DAC—ideally on a separate wire or connection—to say <em>terminate this signal</em>. Then it’s less of a concern if it takes the OS a few seconds to react to the change, because our ears have been spared.</p>
<p id="just-ackchyually">The <em>just ackchyually</em> crowd would don their Captain Obvious capes and brightly-coloured underwear to proclaim that people could <em>just</em> unplug their headphones, or rip them off ones head when suddenly inundated with loud audio. Sure, and if you start getting electric shocks from your keyboard you could <em>just</em> use an external one, bro. Or if you get your hand caught in a mixer, <em>just</em> use your other hand, that’s why you have two of them. There are so many reasons why this dismissive attitude is specious, but even if it weren’t, it would still take more physical effort <em>than a button</em>. And if a mute button doesn’t fulfill the function for which it’s labelled and designed, what’s the point of it? But then, these people know all that, they’re just being obtuse.</p>
<p>We have valid privacy arguments advocating for physical Wi-Fi, camera, and microphone buttons; I’d say audio should be voiced in these discussions too. They should be heard. Sound ideas should be reverberated. Miku.</p>
</div></div>]]>
            </description>
            <link>https://rubenerd.com/we-need-physical-audio-kill-switches/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24535408</guid>
            <pubDate>Sun, 20 Sep 2020 17:19:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Basic Printing on OpenBSD]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24535357">thread link</a>) | @paedubucher
<br/>
September 20, 2020 | https://paedubucher.ch/articles/2020-09-20-basic-printing-on-openbsd.html | <a href="https://web.archive.org/web/*/https://paedubucher.ch/articles/2020-09-20-basic-printing-on-openbsd.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I have a roughly ten year old Brother HL-5370DW printer on the shelf next to me.
This printer is mostly used by my wife to print sewing patterns. When I was
studying computer science, I sometimes printed documents I've written for
proofreading. I often was able to find typos that I didn't see on the screen
even after proofreading the document two or three times. However, I didn't
bother to print out my bachelor thesis. Printing 120 pages just for proofreading
just seemed a waste to me. I did my proofreading on the screen extra carefully,
and nobody complained about typos. (Which doesn't mean that there were none.)</p>
<p>Having finished my studies, I hardly ever print out documents. However, I still
prefer to read long texts on paper rather than on the screen. Therefore I often
buy technical books as paperbacks or hardcovers rather than ebooks. And if I buy
an ebook with demanding content, I print out those sections for offline reading.</p>
<p>Having switched to OpenBSD for my private computing shifted my reading habits
more towards manpages. When I need to figure out how something works on
OpenBSD, <code>apropos(1)</code> beats Google as a starting point in many cases. Some
manpages are really long, for example <code>ksh(1)</code>. I have a book on the Korn Shell
in my basement, which covers <code>ksh93</code>.  However, there are some differences
between <code>ksh93</code> and OpenBSD's <code>pdksh</code>. So reading the manpage not only gives me
more accurate information, but also <em>less</em> to read.</p>
<p>So why not printing out the manpage <code>ksh(1)</code>? I can do so even nicely formatted
using PostScript:</p>
<pre><code>$ man -T ps -O paper=a4 ksh &gt;ksh.1.ps
</code></pre>
<p>Now <code>ksh.1.ps</code> can be read with <code>zathura(1)</code>, given that the package
<code>zathura-ps</code> is installed:</p>
<pre><code># pkg_add zathura zathura-ps
$ zathura ksh.1.ps
</code></pre>
<p>But why using PostScript and not PDF like anybody else for the last twenty five
years? Because PostScript is the least common denominator and, thus, supported
out of the box by OpenBSD. (For fancier printing options, check out <code>cups</code>, but
I'd like to keep it minimalistic for the moment.)</p>

<p>I figured out how to configure my printer by reading the section <em>The lpd
Printing Daemon</em> in the 16th chapter of <a href="https://nostarch.com/obenbsd2e">Absolute OpenBSD (2nd
Edition)</a> (p. 306-307) by <a href="https://mwl.io/">Michael W
Lucas</a>. This is how I applied the configuration to my local
setup.</p>
<p>First, I created the file <code>/etc/printcap</code> with the following content:</p>
<pre><code>lp|brother:\
    :sh=:\
    :rm=192.168.178.52:\
    :sd=/var/spool/output/brother:\
    :lf=/var/log/lpd-errs:\
    :rp=brother
</code></pre>
<p>There must be a newline at the end of the file. The line breaks are escaped
using backslashes, except for the last line. The options are defined as follows:</p>
<ul>
<li>The first line defines two names for my printer: <code>lp</code>, which should always be
  there, and <code>brother</code>, which is my arbitrary name for the printer.</li>
<li>The second line (<code>sh</code>) defines that no <em>burst page</em> (summarizing the last
  print job on a special page) should be printed.</li>
<li>The third line (<code>rm</code>) refers to the printer on the network. My FritzBox always
  gives the same IP to my printer. It's also possible to use the printer's
  hostname.</li>
<li>The fourth line (<code>sd</code>) defines the spooler directory for this printer. Print
  jobs are written into that directory.</li>
<li>The fifth line (<code>lf</code>) defines a log file for error messages, which you hopefully
  never need to check.</li>
<li>The sixth line (<code>rp</code>) defines the remote printer name.</li>
</ul>
<p>Next, the spooler directory needs to be created. It must be owned by the user
<code>root</code> and the group <code>daemon</code>. Regular users need write access to this directory
in order to print documents:</p>
<pre><code># mkdir /var/spool/output/brother
# chown -R root:daemon /var/spool/output/brother
# chmod 770 /var/spool/output/brother
</code></pre>
<p>Now the printer daemon <code>lpd</code> needs to be activated. To do so on system startup,
add the following line to <code>/etc/rc.conf/local</code>:</p>
<pre><code>lpd_flags=""
</code></pre>
<p>Then start the service:</p>
<pre><code># /etc/rc.d/lpd restart
</code></pre>
<p><strong>Update (2020-09-21)</strong>: As one reader on
<a href="https://news.ycombinator.com/item?id=24535357#24538879">Hacker News</a> pointed
out, the last two steps can be performed using <code>rcctl(8)</code>:</p>
<pre><code># rcctl enable lpd
# rcctl restart lpd
</code></pre>
<p>The manpage says that <code>rcctl(8)</code> was introduced in OpenBSD 5.7 back in 2015.
<em>Absolute OpenBSD (2nd Edition)</em> is from 2013 and, thus, older than that. (At
the time of this writing, I'm using Version 6.7.)</p>
<p>Another reader pointed out that setting the access rights to <code>777</code> is a bad
practice. That's true, and I actually got the reasoning behind this wrong: I
thought any user must be able to write to the spooler, because any user is
supposed to print. However, it's <code>lpd</code> that is writing to the spooler, which of
course runs under the <code>daemon</code> group. Therefore, the access rights for
<code>/var/spool/output/brother</code> should be set to <code>770</code>, not to <code>777</code> (as corrected
above).</p>

<p>Now the printer is ready to accept jobs. In order to print the PostScript file
generated before, just run <code>lpr</code> on the file:</p>
<pre><code>$ lpr ksh.1.ps
</code></pre>
<p>It's also possible to send the PostScript output directly to the printer (this
is Unix, after all), if no preview is needed:</p>
<pre><code>$ man -T ps -O paper=a4 ksh | lpr
</code></pre>
<p>Printing plain text files behaved strange on my setup, but could to using the
<code>pr</code> formatter with <code>lpr</code> as follows:</p>
<pre><code>$ lpr -p plain.txt
</code></pre>
<p>Instead, I also convert plain text files to PostScript, which looks quite nice
on paper. I use <code>enscript(1)</code> for this task:</p>
<pre><code># pkg_add enscript
$ enscript plain.txt -o plain.ps
$ lpr plain.ps
</code></pre>
<p>PDFs can also be converted to PostScript using <code>pdf2ps(1)</code>, which comes with
GhostScript, i.e. the <code>ghostscript</code> package:</p>
<pre><code>$ pdf2ps document.pdf document.ps
</code></pre>
<p>Unfortunately, this doesn't work with all PDFs. But for the time being, I have
enough manpages to read. Printing PostScript works extremely fast, by the way.
When I press return at the end of a <code>lpr</code> command, I can see the status LED on
my printer start blinking almost immediately.</p></div></div>]]>
            </description>
            <link>https://paedubucher.ch/articles/2020-09-20-basic-printing-on-openbsd.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24535357</guid>
            <pubDate>Sun, 20 Sep 2020 17:15:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bert NLP: Using DistilBert to Build a Question Answering System]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24535160">thread link</a>) | @boduma
<br/>
September 20, 2020 | https://programmerbackpack.com/bert-nlp-using-distilbert-to-build-a-question-answering-system/ | <a href="https://web.archive.org/web/*/https://programmerbackpack.com/bert-nlp-using-distilbert-to-build-a-question-answering-system/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p><strong>Question answering systems </strong>are being heavily researched at the moment thanks to huge advancements gained in the <a href="https://programmerbackpack.com/what-is-natural-language-processing-a-gentle-introduction-to-nlp/">Natural Language Processing</a> field. Key players in the industry have developed incredibly advanced models, some of which are already performing at human level. This is also the case for BERT (Bidirectional Encoder Representations from Transformers) which was developed by researchers at Google. </p><p>In this article we're going to use DistilBERT (a smaller, lightweight version of BERT) to build a small question answering system. This system will process text from Wikipedia pages and answer some questions for us. We are then going to put our model to test with some questions and analyze the results.</p><p><em>Interested in more? Follow me on Twitter at <a href="https://twitter.com/b_dmarius">@b_dmarius</a> and I'll post there every new article.</em></p><figure><img src="https://images.unsplash.com/photo-1527430253228-e93688616381?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="A little Robot"><figcaption>Photo by <a href="https://unsplash.com/@rocknrollmonkey?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Rock'n Roll Monkey</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><h3 id="article-overview">Article overview</h3><ul><li>Approach for building a question answering system</li><li>Project setup</li><li>Building a Wikipedia text extractor</li><li>Question processing</li><li>Searching for relevant context - BM25</li><li>Using DistilBERT for question answering</li><li>Building the question answering logic</li><li>Testing our system</li><li>Related articles</li><li>Conclusions</li></ul><p>Our question answering system will work in 4 stages:</p><ul><li><strong>Extract text from Wikipedia: </strong>We will download text from a few Wikipedia articles in order to build our dataset. I will cache the text in my local environment because there is no need to download the same text again and again everytime I make changes to the system.</li><li><strong>Process the question</strong>: Here I'm going to extract the most important bits of the input question, because using every word in the question would lower the accuracy of the results.</li><li><strong>Retrieve context from the text:</strong> Given an input question, we will try to find the most relevant sentences in the entire data corpus. This will help have a small search space for our answer retriever model and will lead to a higher accuracy</li><li><strong>Retrieve answer from the context: </strong>This is where our BERT model will come into action. We will feed the context from the earlier step to our model and will get our answer in return.</li></ul><p>What I'm trying to do here is what I think is found behind the instant answers that search engines sometimes offer for some search queries. If you Google "what is the capital city of Romania?" you will first get an answer box with "Bucharest" and results from other pages around the internet come below this box.</p><p>What my intuition tells me is that the search engine looks at your query and tries to find first the most relevant pages related to your question and it then looks at these pages and tries to extract a direct answer for you. This is what I also tried to do for this project.</p><p>As I was writing in the beginning of this article, a lot of research is going on in this field and the community can only benefit from this. A lot of tools have been built using the latest research results and awesome tools like this are exactly what makes this project not only possible, but also very easy and quick 😊.</p><p>First let's install <a href="https://spacy.io/">spaCy</a>, a library which I really like and which I've been using in many projects, such as <a href="https://programmerbackpack.com/python-nlp-tutorial-information-extraction-and-knowledge-graphs/">building a knowledge graph</a> or <a href="https://programmerbackpack.com/python-knowledge-graph-understanding-semantic-relationships/">analyzing semantic relationships</a>. I'm also going to download the small version of the spaCy language model for English. Larger models are available but the small version is just enough for this project.</p><pre><code>pip install spacy
python -m spacy download en_core_web_sm</code></pre><p>It's time now to install <a href="https://pypi.org/project/wikipedia/">wikipedia</a>, an awesome package for extracting text from Wikipedia pages.</p><pre><code>pip install wikipedia</code></pre><p>Next up is <a href="https://radimrehurek.com/gensim/">Gensim</a>, another package which I really enjoy using, especially for its really good <a href="https://programmerbackpack.com/explained-word2vec-word-embeddings-gensim-implementation-tutorial-and-vizualization/">Word2Vec implementation</a>.</p><pre><code>pip install gensim</code></pre><p>For the last 2 dependencies, I'll install <a href="https://pytorch.org/">pytorch</a> and t<a href="https://github.com/huggingface/transformers">ransformers from HuggingFace</a> 🤗. It's my first time using these 2 packages but I think they are really powerful and really easy and fun to work with.</p><pre><code>pip install torch
pip install transformers</code></pre><p>Now, with all our dependencies in place, it's time to start building our question answering system.</p><p>If you've been reading other articles on this blog you might already be familiar with my approach for extracting articles from Wikipedia pages. I know it's not the best or most efficient way of extracting the text, but it's quick and easy and let's you build a small, play dataset for a project. </p><p>First let's write a small class to extract the text from one Wikipedia page. Let's create a <strong>text_extractor.py </strong>file and put it in our project directory.</p><figure><pre><code>import wikipedia
import os


class TextExtractor:

    __pageTitle: str
    __pageId: str

    def __init__(self, pageTitle, pageId):
        self.__pageTitle = pageTitle
        self.__pageId = pageId

    def extract(self):
        fileName = "./text/" + self.__pageTitle + ".txt"
        if not os.path.isfile(fileName):
            page = wikipedia.page(title=self.__pageTitle, pageid=self.__pageId)
            f = open(fileName, "w")
            f.write(page.content)
            f.close()

    def getText(self):
        f = open("./text/" + self.__pageTitle + ".txt", "r")
        return f.read()</code></pre><figcaption>text_extractor.py</figcaption></figure><p>The approach is very simple here. The constructor takes 2 params, a page title and a page id. The reason for also requiring a page id is because I noticed that sometimes the wikipedia package gets confused for some titles and that's why I prefer to also use this param. To extract the page id for one Wikipedia article, go to <a href="https://www.wikidata.org/wiki/Wikidata:Main_Page">Wikidata</a> and search for your article there. The page id is the one in the brackets right after the title of your result.</p><p>As I said earlier, I'm storing the text in a local directory (/text) so that downloading the text is not necessary for every run of the project. </p><p>The second class needed for this step is a text extractor pipe. This allow us to collect multiple TextExtractor instances and combine the text from all of them into one big chunk. This is the content of the <strong>text_extractor_pipe.py </strong>file.</p><figure><pre><code>from text_extractor import TextExtractor


class TextExtractorPipe:

    __textExtractors: [TextExtractor]

    def __init__(self):
        self.__textExtractors = []

    def addTextExtractor(self, textExtractor: TextExtractor):
        self.__textExtractors.append(textExtractor)

    def extract(self) -&gt; str:
        result = ''
        for textExtractor in self.__textExtractors:
            result = result + textExtractor.getText()
        return result</code></pre><figcaption>text_extractor_pipe.py</figcaption></figure><p>It's time for the first real NLP step of this project. I'm going to do a little bit of question processing here. By that I mean I'm going to remove stop words from the original question text and keep only the essential parts. For example:</p><p><strong>Original question: </strong>"What is the capital city of Romania?"</p><p><strong>Processed question: </strong>"capital city Romania"</p><p>Why am I doing this? You might notice that the text contains words that are not necessarily essential for the question. This is especially for the purpose of this step, because we need to extract only the sentences that are the closest of all to our original question. Words like "what", "is", and especially "the" appear in too many places in our dataset and that can lower the accuracy of our search.</p><p>You might argue that the other words are important too, because once I find mentions of the capital city of Romania in the dataset, I need to know what to extract from there, what is the question that I need to answer too. And you're right, don't worry about it, we'll also keep the original question because we are going to reuse it later. But for searching purposes, the processed question should be enough.</p><p>I'm going to use spaCy to process the question. The logic here is very simple, I'm going to apply spaCy's NLP model to the question text in order to tokenize it and identify the parts of speech of all the words in the question. Then I'm going to keep only the parts of speech I'm interested in: nouns, proper nouns, and adjectives.</p><p>Here are the contents of <strong>question_processor.py.</strong></p><figure><pre><code>

class QuestionProcessor:


    def __init__(self, nlp):
        self.pos = ["NOUN", "PROPN", "ADJ"]
        self.nlp = nlp


    def process(self, text):
        tokens = self.nlp(text)
        return ' '.join(token.text for token in tokens if token.pos_ in self.pos)

</code></pre><figcaption>question_processor.py</figcaption></figure><p>Here starts the actual search for the context in which the answer to our question will probably be found. But first, we need to mention what <a href="https://en.wikipedia.org/wiki/Okapi_BM25">BM25 </a>is.</p><p><strong>BM25 </strong>is a function or an algorithm used to rank a list of documents based on a given query. That's why it is also called a ranking function. It is very similar to <a href="https://programmerbackpack.com/tf-idf-explained-and-python-implementation/">TF-IDF</a> and it is actually so good that I understand it is used in ElasticSearch for document ranking. I'm not going to go into the maths behind BM25 because it is a little too complicated for the purpose of this project, but the most relevant aspects here are:</p><ul><li>It is a bag-of-words model, and that means the algorithm disregards grammar structure but takes into account term frequencies - making it just ideal for our project.</li><li>It takes a query and helps us sort a collection of documents based on how relevant they are for that query.</li><li>The Gensim package has a very good BM25 implementation that is very easy to use.</li></ul><p>I see only good news in the list above, so let's get working 😃. Here's the approach I'm going to use:</p><ul><li>Get a list of all sentences in our dataset and the <strong>processed question</strong>.</li><li>Tokenize all our sentences and use lemmas of the words instead of the original words. The lemma of a given word is its base form (for example, we're transforming "running" to "run") and we are using it in order to improve the accuracy of our search. We're also doing it for the question text. If you want to know more about <a href="https://programmerbackpack.com/lemmatization-and-stemming-in-nlp-the-complete-practical-guide/">lemmatization and stemming you can read this article</a>.</li><li>Use the BM25 ranking function to rank all our documents against the given query.</li><li>Extract the top <em>N </em>results from the step above and build a paragraph out of all those <em>N</em> sentences.</li></ul><p>Here is the content of <strong>context_retriever.py</strong></p><figure><pre><code>from gensim.summarization.bm25 import BM25


class ContextRetriever:

    def …</code></pre></figure></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://programmerbackpack.com/bert-nlp-using-distilbert-to-build-a-question-answering-system/">https://programmerbackpack.com/bert-nlp-using-distilbert-to-build-a-question-answering-system/</a></em></p>]]>
            </description>
            <link>https://programmerbackpack.com/bert-nlp-using-distilbert-to-build-a-question-answering-system/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24535160</guid>
            <pubDate>Sun, 20 Sep 2020 16:55:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tarsnap – cleaning up old backups]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 23 (<a href="https://news.ycombinator.com/item?id=24535046">thread link</a>) | @tosh
<br/>
September 20, 2020 | https://dan.langille.org/2020/09/10/tarsnap-cleaning-up-old-backups/ | <a href="https://web.archive.org/web/*/https://dan.langille.org/2020/09/10/tarsnap-cleaning-up-old-backups/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<div>
<p>I use <a href="https://www.tarsnap.com/">Tarsnap</a> for my critical data. Case in point, I use it to backup my Bacula database dump. I use Bacula to backup my hosts. The database in question keeps track of what was backed up, from what host, the file size, checksum, where that backup is now, and many other items. Losing this data is annoying but not a disaster. It can be recreated from the backup volumes, but that is time consuming. As it is, the file is dumped daily, and rsynced to multiple locations.</p>
<p>I also backup that database daily via <span>tarsnap</span>. I’ve been doing this since at least 2015-10-09.</p>
<p>The uncompressed dump of this PostgreSQL database is now about 117G. </p>
<pre># ls -l bacula.dump 
-rw-r-----  1 10839  10839  125497737071 Sep  8 03:29 bacula.dump
</pre>
<p>Let’s look at recent usage by that host:</p>
<div id="attachment_6180"><p><a href="https://dan.langille.org/wp-content/uploads/2020/09/tarsnap-usage.png"><img aria-describedby="caption-attachment-6180" loading="lazy" src="https://dan.langille.org/wp-content/uploads/2020/09/tarsnap-usage-634x1024.png" alt="tarsnap recent usaage" width="634" height="1024" srcset="https://dan.langille.org/wp-content/uploads/2020/09/tarsnap-usage-634x1024.png 634w, https://dan.langille.org/wp-content/uploads/2020/09/tarsnap-usage-186x300.png 186w, https://dan.langille.org/wp-content/uploads/2020/09/tarsnap-usage.png 747w" sizes="(max-width: 634px) 100vw, 634px"></a></p><p id="caption-attachment-6180">tarsnap recent usaage</p></div>
<p>The latest <span>Daily storage</span> value is 96G.</p>
<p>Using this command, I obtained a list of the archives stored:</p>
<pre>tarsnap --list-archives -vv &gt; ~/tarsnap-knew-archive-list
</pre>
<p>See <a href="https://www.tarsnap.com/man-tarsnap.1.html">man 1 tarsnap</a></p>
<p>I found 1751 archives, the oldest one was created on 2015-10-08 19:01:17.</p>
<p>This is a great example of <a href="https://www.tarsnap.com/deduplication-examples.html">Tarsnap deduplication and compression</a>.  I have 5 years of backups taking up only 96G and the latest backup is 113G.</p>
<p>By comparison, my other <span>tarsnap</span> backups take up this amount of space:</p>
<hr>
<table>
<tbody><tr>
<th>backup</th>
<th>size</th>
</tr>
<tr>
<td>bacula dump</td>
<td>96G</td>
</tr>
<tr>
<td>bacula configuration</td>
<td>13.7G</td>
</tr>
<tr>
<td>subversion</td>
<td>8G</td>
</tr>
<tr>
<td>supernews</td>
<td>32.5G</td>
</tr>
<tr>
<td>zuul-postgresql</td>
<td>0.18G</td>
</tr>
<tr>
<td>zuul-mysql</td>
<td>0.57G</td>
</tr>
<tr>
<td>zuul-pg02</td>
<td>5.7G</td>
</tr>
</tbody></table>
<hr>
<p>I’m going to trim down the dump archives, for sure.</p>
<p>I’m curious about that bacula configuration archive.  The Bacula configuration is only about 600K:</p>
<pre>$ cd /usr/local/etc/bacula
$ sudo du -ch .
608K	.
608K	total
$ </pre>
<p>Checking the archive list for that machine, I find 6 database backups from early October 2015.</p>
<p>Let’s delete those backups first. The names of those archives are:</p>
<pre title="">bacula.int.BaculaDatabase.2015-10-02
bacula.int.BaculaDatabase.2015-10-03
bacula.int.BaculaDatabase.2015-10-05
bacula.int.BaculaDatabase.2015-10-06
bacula.int.BaculaDatabase.2015-10-07
bacula.int.BaculaDatabase.2015-10-08
</pre>
<p>Let’s delete one:</p>
<pre># tarsnap -d -f bacula.int.BaculaDatabase.2015-10-02
                                       Total size  Compressed size
All archives                         196056412740      57482749453
  (unique data)                       50147278933      14694175940
This archive                          48831544077      14324291125
Deleted data                              2073099          1672760
# 
</pre>
<p>Let’s delete the rest (based on <a href="https://www.tarsnap.com/improve-speed.html">Delete multiple archives faster</a>:</p>
<pre>[dan@bacula:~] $ sudo tarsnap -d \
&gt; -f bacula.int.BaculaDatabase.2015-10-03 \
&gt; -f bacula.int.BaculaDatabase.2015-10-05 \
&gt; -f bacula.int.BaculaDatabase.2015-10-06 \
&gt; -f bacula.int.BaculaDatabase.2015-10-07 \
&gt; -f bacula.int.BaculaDatabase.2015-10-08
                                       Total size  Compressed size
All archives                         147224869967      43158468600
  (unique data)                       50147260360      14694156775
bacula.int.BaculaDatabase.2015-10-03      48831542773      14324280853
Deleted data                                18573            19165
                                       Total size  Compressed size
All archives                          98393327194      28834187747
  (unique data)                       50147241787      14694137610
bacula.int.BaculaDatabase.2015-10-05      48831542773      14324280853
Deleted data                                18573            19165
                                       Total size  Compressed size
All archives                          49561784421      14509906894
  (unique data)                       49265856159      14448990041
bacula.int.BaculaDatabase.2015-10-06      48831542773      14324280853
Deleted data                            881385628        245147569
                                       Total size  Compressed size
All archives                            314745728         65670242
  (unique data)                          19214507          4841679
bacula.int.BaculaDatabase.2015-10-07      49247038693      14444236652
Deleted data                          49246641652      14444148362
                                       Total size  Compressed size
All archives                            314744195         65668842
  (unique data)                          19212974          4840279
bacula.int.BaculaDatabase.2015-10-08             1533             1400
Deleted data                                 1533             1400
[dan@bacula:~] $ [dan@bacula:~] $ sudo tarsnap -d \
</pre>
<p>I won’t see the change in the ‘Recent account usage by machine’ page because that ‘updates shortly after midnight UTC’.  I’ll come back tomorrow.</p>
<p>In the meantime, I think I can delete all my old Bacula database backups from before 2020.  For fun, I will keep each backup from 01-01, and the oldest backup.</p>
<p>Here is how I can get that list from the existing file:</p>
<pre>[dan@knew:~] $ head /root/tarsnap-knew-archive-list 
bacula.int.BaculaDatabase.2020-08-13	2020-08-13 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2020-08-13 bacula.dump
bacula.int.BaculaDatabase.2018-08-17	2018-08-17 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2018-08-17 bacula.dump
bacula.int.BaculaDatabase.2018-11-08	2018-11-08 13:25:01	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2018-11-08 bacula.dump
bacula.int.BaculaDatabase.2020-07-08	2020-07-08 13:25:00	/usr/local/bin/tarsnap -c -f ˜tarbacula.int.BaculaDatabase.2020-07-08 bacula.dump
bacula.int.BaculaDatabase.2016-05-25	2016-05-25 13:25:02	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2016-05-25 bacula.dump
bacula.int.BaculaDatabase.2018-08-09	2018-08-09 13:25:02	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2018-08-09 bacula.dump
bacula.int.BaculaDatabase.2016-10-12	2016-10-12 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2016-10-12 bacula.dump
bacula.int.BaculaDatabase.2016-01-20	2016-01-20 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2016-01-20 bacula.dump
bacula.int.BaculaDatabase.2019-02-06	2019-02-06 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2019-02-06 bacula.dump
bacula.int.BaculaDatabase.2016-03-18	2016-03-18 13:25:04	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2016-03-18 bacula.dump
[dan@knew:~] $ cut -f 1 -w /root/tarsnap-knew-archive-list  | head
bacula.int.BaculaDatabase.2020-08-13
bacula.int.BaculaDatabase.2018-08-17
bacula.int.BaculaDatabase.2018-11-08
bacula.int.BaculaDatabase.2020-07-08
bacula.int.BaculaDatabase.2016-05-25
bacula.int.BaculaDatabase.2018-08-09
bacula.int.BaculaDatabase.2016-10-12
bacula.int.BaculaDatabase.2016-01-20
bacula.int.BaculaDatabase.2019-02-06
bacula.int.BaculaDatabase.2016-03-18
[dan@knew:~] $ 
</pre>
<p>Oh wait, let’s sort that to get a proper range:</p>
<pre>[dan@knew:/root] $ sort tarsnap-knew-archive-list | tail -2
bacula.int.BaculaDatabase.2020-09-05	2020-09-05 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2020-09-05 bacula.dump
bacula.int.BaculaDatabase.2020-09-07	2020-09-07 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2020-09-07 bacula.dump
[dan@knew:/root] $ 
</pre>
<pre>[dan@knew:/root] $ sort tarsnap-knew-archive-list | head -2
bacula.int.BaculaDatabase.2015-10-08	2015-10-08 19:01:17	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2015-10-08 bacula.dump
bacula.int.BaculaDatabase.2015-10-09	2015-10-09 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2015-10-09 bacula.dump
</pre>
<p>Backups going back 5 years. Yeah, that might be a bit excessive, even for me. I usually keep them for three years at home.</p>
<p>Knowing that, let’s select the entries I want to keep:</p>
<pre>[dan@knew:~] $ cut -f 1 -w /root/tarsnap-knew-archive-list  | egrep -e '-01-01|2015-10-08' | sort
bacula.int.BaculaDatabase.2015-10-08
bacula.int.BaculaDatabase.2016-01-01
bacula.int.BaculaDatabase.2017-01-01
bacula.int.BaculaDatabase.2019-01-01
bacula.int.BaculaDatabase.2020-01-01
[dan@knew:~] $ 
</pre>
<p>I sorted the output just to make it easier.</p>
<p>Now, dump everything else, by using <span>-v</span>, into a file:</p>
<pre>[dan@knew:~] $ cut -f 1 -w /root/tarsnap-knew-archive-list  | egrep -ve '-01-01|2015-10-08' &gt; tarsnap-volumes-to-delete
[dan@knew:~] $ wc -l tarsnap-volumes-to-delete 
    1746 tarsnap-volumes-to-delete
</pre>
<p>Oh wait, I forgot to exclude 2020</p>
<pre>[dan@knew:~] $ cut -f 1 -w /root/tarsnap-knew-archive-list  | egrep -ve '-01-01|2015-10-08|bacula.int.BaculaDatabase.2020' &gt; tarsnap-volumes-to-delete
[dan@knew:~] $ wc -l tarsnap-volumes-to-delete 
    1503 tarsnap-volumes-to-delete
[dan@knew:~] $ 
</pre>
<p>I used an editor to quickly modify that file to look like this:</p>
<pre>[dan@knew:~] $ head tarsnap-volumes-to-delete 
#!/bin/sh
-f bacula.int.BaculaDatabase.2018-08-17 \
-f bacula.int.BaculaDatabase.2018-11-08 \
-f bacula.int.BaculaDatabase.2016-05-25 \
-f bacula.int.BaculaDatabase.2018-08-09 \
-f bacula.int.BaculaDatabase.2016-10-12 \
-f bacula.int.BaculaDatabase.2016-01-20 \
-f bacula.int.BaculaDatabase.2019-02-06 \
-f bacula.int.BaculaDatabase.2016-03-18 \
-f bacula.int.BaculaDatabase.2018-01-15 \
[dan@knew:~] $ 
</pre>
<p>This delete will take a while so I started a <span>tmux</span> session.  I did a <span>chmod +x</span> on the file.</p>
<p>I started the command and went on to do other lines.  It is deleting 1500 archives. It will be a few hours at least I think.</p>
<pre>[dan@knew:~] $ time sudo ./tarsnap-volumes-to-delete
</pre>
<p>I wish I sorted that list. I’d know easily where we were.</p>
<p>I know we are on <span>bacula.int.BaculaDatabase.2018-08-19</span> which is line 836 of 1505.</p>
<pre> $ ps auwwx | grep tmux
dan        78234   0.0  0.0   14344    5872  -  Is   13:15       0:00.36 tmux: server (/tmp//tmux-1001/default) (tmux)
</pre>
<p><span>tmux</span> was started at 13:15 and it is now 20:49 – so that’s 7.5 hours to get about half-way through. This should finish overnight.</p>
<p>Night passes….</p>
<p>The next morning I found:</p>
<pre>real    819m10.118s
user    372m34.315s
sys     3m23.045s
</pre>
<p>That is 13 hours and 40 minutes, or about 18 every 10 minutes.</p>
<p>I want to compare before and after disk usage, but I may have to wait until 0000 UTC when the statistics are updated.</p>
<p>The next day (2020-09-10), I found these …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dan.langille.org/2020/09/10/tarsnap-cleaning-up-old-backups/">https://dan.langille.org/2020/09/10/tarsnap-cleaning-up-old-backups/</a></em></p>]]>
            </description>
            <link>https://dan.langille.org/2020/09/10/tarsnap-cleaning-up-old-backups/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24535046</guid>
            <pubDate>Sun, 20 Sep 2020 16:43:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Laid Off, Now What?]]>
            </title>
            <description>
<![CDATA[
Score 374 | Comments 334 (<a href="https://news.ycombinator.com/item?id=24534685">thread link</a>) | @bbhat
<br/>
September 20, 2020 | https://bharathpbhat.github.io/2020/09/19/laid-off-now-what.html | <a href="https://web.archive.org/web/*/https://bharathpbhat.github.io/2020/09/19/laid-off-now-what.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>As an immigrant on an H1B, you have exactly 60 days to find a new job when you are laid-off. This is a very short window of time to explore and land any job, let alone a job that matches your skills and interests. I found myself in this situation along with many others when Uber announced <a href="https://www.theverge.com/2020/5/18/21262337/uber-layoff-3000-employees-covid-19-coronavirus">layoffs</a> earlier this year. The following is a recollection of some things that worked well for me during my eventually successful job hunt.</p>
<ul>
<li><a href="#always-be-prepping">Always be Prepping</a></li>
<li><a href="#reach-out-to-everyone">Reaching Out</a></li>
<li><a href="#interview-preparation">Interview Preparation</a></li>
<li><a href="#closing-thoughts">Closing Thoughts</a></li>
</ul>
<h3 id="always-be-prepping">Always be prepping</h3>
<p>Coding interviews are hard to crack if you haven't been prepping, so I was lucky that I had been spending roughly 3-4 hours every week on <a href="http://leetcode.com/">leetcode</a>, from about 2 months before the layoff rumours broke. I was lucky that</p>
<ul>
<li>I knew that I wanted to change jobs in any case and</li>
<li>Rumours of layoffs broke approximately a month before the actual layoffs happened, giving me more lead time to prepare and send out emails to recruiters and friends.</li>
</ul>
<p>Whenever there's an economic downturn, I think it's critical to be acutely aware of what's happening at the company and start preparing for job interviews right away.</p>
<h3 id="reach-out-to-everyone">Reach out to everyone</h3>
<p>One of the hardest things to do when you are laid off is to write to your friends and family seeking help. But if there's ever a time to swallow your pride, then this is it. I reached out to everyone I knew, and told them plainly about my situation, and asked to be recommended to specific roles at their companies, or to tell their friends who may be hiring. I am extremely grateful to the help I got from my network, and the kind messages that I received. So many friends wrote to make sure I was okay, and kept checking in throughout the interview process, and they all have my immense gratitude.</p>
<p>It is tempting to just apply on the careers page when you find relevant roles at a company instead of spending time on finding connections and reaching out to them, but in my experience, it was very much worth it. Response times from recruiters was roughly 1-2 days when I was referred by an employee, whereas applying on the careers page was a hit or miss. One BigCo. took 40 days to respond, while some smaller companies were much quicker (3-4 days).</p>
<h4 id="the-process">The Process</h4>
<p>In terms of companies, cast a wide net because you absolutely need <em>a</em> job before a deadline. The steps are the obvious ones:</p>
<ol>
<li>Make a list of companies</li>
<li>For each company, compile a list of open job profiles that are relevant.</li>
<li>Email/Text a connection at the company, or apply on the careers page if all else fails.</li>
</ol>
<p>I think I reached out to an initial list of 10 companies or so on the day news of the layoffs broke. This worked well because there's at least a week's time before you speak to a hiring manager or interviewer from when you reach out, so there's ample time to prepare.</p>
<p>What companies to reach out to? In my case, it was the usual suspects (FAANG), and then some domain specific ones such as autonomous vehicle companies. The two most common roles that I applied to were:</p>
<ul>
<li><strong>Machine Learning Engineer</strong> - This is a hybrid role with ML + Software Engineering skills needed, and job roles usually talk about some specific domain such as recommendation systems, or in the case of autonomous vehicles, things such as perception or object detection. I typically looked for some mention of Computer Vision, NLP and deep learning.</li>
<li><strong>Machine Learning Infra Engineer</strong> - This role tends to be more on the software systems side, and deals with the infra for training and serving ML models for production workloads.</li>
</ul>
<h3 id="interview-preparation">Interview Preparation</h3>
<ul>
<li><a href="#an-initial-screen-with-the-hiring-manager">Hiring Manager Screen</a></li>
<li><a href="#coding-interviews-phone--onsite">Coding Interviews</a></li>
<li><a href="#machine-learning-interviews">Machine Learning Interviews</a></li>
<li><a href="#behavioral-interviews">Behavioral Interviews</a></li>
</ul>
<p>Interviewing for ML specific roles typically involves a few different kinds of interviews, each of which needs specific preparation. I'm outlining the most common ones I saw below:</p>
<h3 id="an-initial-screen-with-the-hiring-manager">An initial screen with the hiring manager</h3>
<p>Companies that do general interviews (Google / Facebook) don't have this step, but most others do. I personally like this, because it means that you are interviewing for a specific position in a specific team, and there's a high level of engagement from the beginning. Most of these calls were about getting to know me, and making sure I have relevant work experience, while some of them also were rapid fire technical questions. The latter ones were rare, and I encountered them when the manager wasn't certain that I was the right person for the job. In my experience, the introduction is the most important part of this interview (<strong>Tell me about yourself</strong>), and it helps to have prepared intros for each type of role that you are applying to. The idea is to tailor your story to highlight aspects of your work experience that are relevant to the job role. The next most important question is "<strong>What would you like to do in your next role?</strong>". Again, it helps immensely to be prepared to answer this question, and ideally, in a way so that there's reasonable overlap between your answer and what the role offers. Being able to answer this question also provides clarity to the job search process. For example, a consistent theme for me was to be (a) in an impactful / critical role for the company and (b) continue to work with the latest in ML.</p>
<p>Writing and rehearsing your stories often seems unimportant when compared to more tangible preparation steps such as spending time on leetcode, but I believe that it was critical, because it sets the tone and gives you confidence that you have done this in the past, and done it well, and there's no reason for the interviewer to doubt your abilities.</p>
<h3 id="coding-interviews-phone--onsite">Coding Interviews (Phone / Onsite)</h3>
<p>These are the standard leetcode style coding interviews, done using coderpad, or some similar service. The template for these is consistent across all companies, and involves 1 or 2 coding questions (or 1 question with follow-ups) that you are expected to implement and test. Some tips that were helpful for me preparation:</p>
<ol>
<li><strong>Get a premium subscription with leetcode</strong> - It is nice to be able to filter by companies and have access to the entire question bank, and it is good karma. The service is valuable and the creators should be compensated.</li>
<li><strong>Simulate the interview setting as much as possible</strong> - For example, I would set aside a 3 hour block of time for leetcode, shut myself in a room, and do 4 questions, 45 minutes each. If you are unable to solve a question in 45 minutes, you still move on to the next one. No extensions or looking at the solution. Think of it like moving on to the next interviewer. After the 3 hour session is done, go back to the questions as needed, either to look at solutions or to understand them better. A question is <code>Done</code> when your solution passes all the tests on leetcode and is <code>Accepted</code>.</li>
<li><strong>Talk out loud</strong> - This is big. Again, assuming that you are in an actual interview, talk out loud about the process you are using during these practice sessions. Talking out loud helps massively because you are forced to put your current train of thought into words, and it is often evident when a solution isn't justifiable.</li>
<li><strong>How to pick questions?</strong> - I filtered for questions that were tagged <code>Hard</code>, and then picked at random. No filter for company, or problem type. I went from doing all Mediums to a mix of Mediums and Hard to all Hards over a span of 4-5 weeks.</li>
<li><strong>How many questions to do?</strong> - In the first 2-3 weeks of my prep, I was doing 4 questions on one of the weekend days, and once I had more time post the lay-off news, it was 4 questions every 3 days or so. Overall, my stats look so:</li>
</ol>
<p><img src="https://bharathpbhat.github.io/assets/images/leetcode_xp.png" alt="Leetcode stats"></p>
<h3 id="machine-learning-interviews">Machine Learning Interviews</h3>
<p>These typically come in two flavors:</p>
<h4 id="concepts--basics">Concepts / Basics</h4>
<p>These are kind of like rapid fire questions where the interviewer will quiz you about ML basics. Some questions that I recall right now, to give a flavor of things:</p>
<pre><code>- What are some unsupervised learning methods?
- What is underfitting / overfitting?
- What is batch normalization? What's the motivation behind it?
- What is dropout? 
- What optimizers have you used? And typically some follow-up like, why does momentum make sense?
- What are some object detection techniques / papers that you are familiar with? (Computer Vision specific)
- What are decision trees? 
- How does logistic regression work?
- How do you train a linear regression model?
- What are some loss functions that you are familiar with?
- Why does Cross Entropy loss make sense?
- What are residual networks?
</code></pre>
<p>These are usually follow up questions where the interviewer will try to dig deeper into these concepts, often picking on some portion of the initial answer.</p>
<p>I did a lot of reading, and then some writing with a pen and paper for this part of the interview. If I am already somewhat/fairly familiar with a topic, like say, object detection, then my process was:</p>
<ol>
<li><strong>Write</strong> from memory a summary of what I remember about the topic</li>
<li>Note down <strong>questions</strong> for the parts that I am not clear about</li>
<li><strong>Read</strong> about the topic, and fill in whatever I missed on first go.</li>
</ol>
<p>If I don't remember much about a topic at all, like say, multi-armed bandits, then I would do step (3) first, and then do steps (1) and (2) a few days later, and eventually repeating step (3) as needed.</p>
<p>It helps to start with a list of topics that you want do this for. This list will grow as you remember more topics or expand the list of companies you are interviewing at. For reference, the list of topics I looked at is <a href="https://bharathpbhat.github.io/assets/files/index_card.pdf">here</a>, and a sample of the handwritten notes I made is here, for <a href="https://bharathpbhat.github.io/assets/files/rec_sys.pdf">recommendation systems</a>.</p>
<h4 id="ml-system-design">ML System Design</h4>
<p>This is my favorite interview, and corresponds neatly to skills used day to day as a ML practitioner. These are typically open ended interviews where the candidate is expected to design a product with some ML at its core. For example, things like:</p>
<pre><code>- Let's build a model that ranks photos in your photo library based on quality.
- How would you build a model that identifies pedestrians from drone imagery?
- Let's build a model that can does face detection for a user's photo library.
- How do you build a model that automatically picks out …</code></pre></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bharathpbhat.github.io/2020/09/19/laid-off-now-what.html">https://bharathpbhat.github.io/2020/09/19/laid-off-now-what.html</a></em></p>]]>
            </description>
            <link>https://bharathpbhat.github.io/2020/09/19/laid-off-now-what.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534685</guid>
            <pubDate>Sun, 20 Sep 2020 15:54:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is unauthenticated encryption insecure?]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 34 (<a href="https://news.ycombinator.com/item?id=24534619">thread link</a>) | @todsacerdoti
<br/>
September 20, 2020 | https://cybergibbons.com/reverse-engineering-2/why-is-unauthenticated-encryption-insecure/ | <a href="https://web.archive.org/web/*/https://cybergibbons.com/reverse-engineering-2/why-is-unauthenticated-encryption-insecure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Cryptography is a complex subject. There are many subtle issues that can be introduced if you don’t know what you are doing.</p>



<p>There is a common mantra: “don’t roll your own crypto”. This is because both inexperienced and experienced developers frequently build cryptographic systems that are insecure.</p>



<p>However, there has to be a line – when does it start becoming “rolling your own”? Particularly in embedded systems, there are times when custom protocols need to be used, and developers stray into the dangerous area of cryptography.</p>



<p>One of the most common mistakes we have seen is the use of unauthenticated encryption.</p>



<h3>What is encryption?</h3>



<p>Encryption is encoding a plaintext into a ciphertext using a key, with the goal of keeping the plaintext confidential.</p>



<p>Only someone with the correct key should be able to decrypt the ciphertext and turn it back into plaintext.</p>



<p>Encryption provides confidentiality. It stops someone working out what the message is.</p>



<h3>So what’s the issue?</h3>



<p>An attacker can modify the ciphertext and cause the plaintext to change. There is no inherent means in encryption to detect this change.</p>



<p>Encryption does not provide authenticity. You cannot check that the message is genuine and has not been tampered with.</p>



<h3>What can an attacker do with this?</h3>



<p>I’m going to describe one attack against unauthenticated encryption.</p>



<p>Many encryption algorithms only operate on fixed-size blocks of data – they are called <a href="https://en.wikipedia.org/wiki/Block_cipher">block ciphers</a>. To encrypt longer lengths of data, a <a href="https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation">mode of operation</a> is used to apply the block cipher repeatedly.</p>



<p>One mode of operation is called <a href="https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Cipher_block_chaining_(CBC)">CBC</a> (Cipher Block Chaining). When encrypting the data, the previous ciphertext block is mixed into the current plaintext block using an operation called “<a href="https://en.wikipedia.org/wiki/Exclusive_or">exclusive OR</a>“. This is denoted with the + in a circle in diagrams.</p>



<figure><img src="https://upload.wikimedia.org/wikipedia/commons/8/80/CBC_encryption.svg" alt=""></figure>



<p>There is also an input called the initialisation vector, or IV. This is a random input to the algorithm, and is intended to ensure that the ciphertext is different, even if the same plaintext is encrypted. This prevents leaking information about the content.</p>



<p>The initialisation vector is transmitted alongside the ciphertext.</p>



<p>Decryption is similar. The previous ciphertext block is exclusive ORed with the output of the block cipher to obtain the plaintext.</p>



<figure><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/CBC_decryption.svg/1200px-CBC_decryption.svg.png" alt=""></figure>



<p>Exclusive OR is a deterministic operation. If we look at a single bit, then it operates as follows:</p>



<figure><table><tbody><tr><td>A</td><td>B</td><td>Output</td></tr><tr><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>1</td><td>1</td></tr><tr><td>1</td><td>0</td><td>1</td></tr><tr><td>1</td><td>1</td><td>0</td></tr></tbody></table></figure>



<p>I always think of this as “if one input is high, invert the other input, otherwise leave it alone”.</p>



<p>The operation is carried out for each bit in a byte.</p>



<pre><code>A: 0 1 0 1 1 0 0 1 (0x59)
B: 1 1 1 1 0 0 0 0 (0xF0)
O: 1 0 1 0 1 0 0 1 (0xA9)</code></pre>



<p>What this means is that modifying one of the inputs to exclusive OR results in a predictable change to the output. And the operation can be easily reversed.</p>



<pre><code>A: 0123456789ABCDEF
B: FFFF00FFF00F0FF0
O: FEDC459879A4C21F</code></pre>



<p>If we now exclusive OR the output with one of the inputs:</p>



<pre><code>A: FEDC459879A4C21F
B: FFFF00FFF00F0FF0
O: 0123456789ABCDEF</code></pre>



<p>Hopefully that explains exclusive OR.</p>



<p>Let’s look back to how CBC uses this in decryption. In the first block, the IV is exclusive ORed with the output of the block cipher. The IV is transmitted alongside the ciphertext and an attacker can modify both at at will.</p>



<figure><img loading="lazy" width="922" height="786" src="https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-14.55.37.png" alt="" srcset="https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-14.55.37.png 922w, https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-14.55.37-300x256.png 300w, https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-14.55.37-768x655.png 768w" sizes="(max-width: 922px) 100vw, 922px"></figure>



<p>We can encrypt the string “A dog’s breakfast” using a key and the initialisation vector of all 0x00 (<a href="https://gchq.github.io/CyberChef/#recipe=AES_Encrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'0000000000000000000000000000000'%7D,'CBC','Raw','Hex')&amp;input=QSBkb2cncyBicmVha2Zhc3Q">here</a> on CyberChef).</p>



<pre><code>Key: 0123456789ABCDEF0123456789ABCDEF
IV:  0000000000000000000000000000000
Plaintext: A dog's breakfast
Ciphertext: c7b1d96f0f520f33faaccfdc107f718aafe8892c3a29c76b0732a760a0f54f50</code></pre>



<p>Of course, this can be decrypted (<a href="https://gchq.github.io/CyberChef/#recipe=AES_Decrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'0000000000000000000000000000000'%7D,'CBC','Hex','Raw',%7B'option':'Hex','string':''%7D)&amp;input=YzdiMWQ5NmYwZjUyMGYzM2ZhYWNjZmRjMTA3ZjcxOGFhZmU4ODkyYzNhMjljNzZiMDczMmE3NjBhMGY1NGY1MA">here</a> on CyberChef).</p>



<p>If I change just one byte in the ciphertext, the entire message is corrupted (<a href="https://gchq.github.io/CyberChef/#recipe=AES_Decrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'0000000000000000000000000000000'%7D,'CBC','Hex','Raw',%7B'option':'Hex','string':''%7D)&amp;input=YzdiMmQ5NmYwZjUyMGYzM2ZhYWNjZmRjMTA3ZjcxOGFhZmU4ODkyYzNhMjljNzZiMDczMmE3NjBhMGY1NGY1MA">here</a> on Cyberchef). There’s no way for me to predictably modify this plaintext by changing the ciphertext.</p>



<pre><code>Key: 0123456789ABCDEF0123456789ABCDEF
IV:  0000000000000000000000000000000
Ciphertext: c7b2d96f0f520f33faaccfdc107f718aafe8892c3a29c76b0732a760a0f54f50
Plaintext: .L...Q½êU...ì7Ò.t</code></pre>



<p>But the attacker also has control over the IV. Let’s set the first byte of the IV to 0xFF (<a href="https://gchq.github.io/CyberChef/#recipe=AES_Decrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'FF00000000000000000000000000000'%7D,'CBC','Hex','Raw',%7B'option':'Hex','string':''%7D)&amp;input=YzdiMWQ5NmYwZjUyMGYzM2ZhYWNjZmRjMTA3ZjcxOGFhZmU4ODkyYzNhMjljNzZiMDczMmE3NjBhMGY1NGY1MA">here</a> on CyberChef). Only the first byte of the plaintext has changed!</p>



<pre><code>Key: 0123456789ABCDEF0123456789ABCDEF
IV:  FF00000000000000000000000000000
Ciphertext: c7b1d96f0f520f33faaccfdc107f718aafe8892c3a29c76b0732a760a0f54f50
Plaintext: ¾ dog's breakfast</code></pre>



<p>And it has changed predictably. The capital A (ASCII 0x41) has been exclusive ORed with 0xFF to become 0xBE (which decodes as ¾ although it’s above the normal ASCII range).</p>



<pre><code>A: 0 1 0 0 0 0 0 1 (0x41)
B: 1 1 1 1 1 1 1 1 (0xFF)
O: 1 0 1 1 1 1 1 0 (0xBE)</code></pre>



<p>This is a very high level of control! The attacker can now modify the plaintext without detection. Let’s try and significantly change the meaning of it.</p>



<p>The original message contained “A dog’s breakfast”. Can we change this canine feast into a feline one?</p>



<p>We exclusive OR the original plaintext with the desired one (<a href="https://gchq.github.io/CyberChef/#recipe=XOR(%7B'option':'UTF8','string':'The%20cat%5C's%20breakfast'%7D,'Standard',false)To_Hex('Space',0)&amp;input=VGhlIGRvZydzIGJyZWFrZmFzdA">here</a> on CyberChef). Notice how the output only has value for the characters we have changed.</p>



<pre><code>Original: A. .d.o.g.'.s. .b.r.e.a.k.f.a.s.t.
Original: 4120646f67277320627265616b66617374
Desired:  A. .c.a.t.'.s. .b.r.e.a.k.f.a.s.t.
Desired:  4120636174277320627265616b66617374
Output:   0000070e13000000000000000000000000</code></pre>



<p>Pop that output in as the IV to the decryption, and we’ve successfully changed the message (here on <a href="https://gchq.github.io/CyberChef/#recipe=AES_Decrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'0000070e13000000000000000000000000'%7D,'CBC','Hex','Raw',%7B'option':'Hex','string':''%7D)&amp;input=YzdiMWQ5NmYwZjUyMGYzM2ZhYWNjZmRjMTA3ZjcxOGFhZmU4ODkyYzNhMjljNzZiMDczMmE3NjBhMGY1NGY1MA">CyberChef</a>). All of this without even knowing the key.</p>



<pre><code>Key: 0123456789ABCDEF0123456789ABCDEF
IV:  0000070e130000000000000000000000
Ciphertext: c7b1d96f0f520f33faaccfdc107f718aafe8892c3a29c76b0732a760a0f54f50
Plaintext: A cat's breakfast</code></pre>



<p>Of course, the attacker needs to have knowledge of the plaintext to make use of this attack. However, it’s extremely common for some or all of the message to be known. For example, when we visit most websites, the first part of the response will be “HTTP/1.1 200 OK”. If this was only protected by CBC encryption, we could change that to “HTTP/1.1 404 No”, changing the behaviour of the browser (here on <a href="https://gchq.github.io/CyberChef/#recipe=AES_Decrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'00000000000000000006000000012400'%7D,'CBC','Hex','Raw',%7B'option':'Hex','string':''%7D)&amp;input=ZGJkY2FkYWZjYjQ5NTJiNDE0OTBhODM4NDFhYzgxZGE">CyberChef</a>).</p>



<p>This doesn’t just impact the first block of data either. After the first block, instead of the IV, the previous ciphertext block is used in the exclusive OR operation. The attacker can modify the ciphertext and end up controlling the plaintext.</p>



<figure><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/CBC_decryption.svg/2880px-CBC_decryption.svg.png" alt=""></figure>



<p>This comes at a cost though – the previous plaintext block will be totally corrupted as a result.</p>



<p>To illustrate this, we can encrypt a longer block of text (<a href="https://gchq.github.io/CyberChef/#recipe=AES_Encrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'0000000000000000000000000000000'%7D,'CBC','Raw','Hex')&amp;input=VGhpcyBpcyBvdXIgd29ybGQgbm93Li4uIHRoZSB3b3JsZCBvZiB0aGUgZWxlY3Ryb24gYW5kIHRoZSBzd2l0Y2gsIHRoZQpiZWF1dHkgb2YgdGhlIGJhdWQuICBXZSBtYWtlIHVzZSBvZiBhIHNlcnZpY2UgYWxyZWFkeSBleGlzdGluZyB3aXRob3V0IHBheWluZwpmb3Igd2hhdCBjb3VsZCBiZSBkaXJ0LWNoZWFwIGlmIGl0IHdhc24ndCBydW4gYnkgcHJvZml0ZWVyaW5nIGdsdXR0b25zLCBhbmQKeW91IGNhbGwgdXMgY3JpbWluYWxzLiAgV2UgZXhwbG9yZS4uLiBhbmQgeW91IGNhbGwgdXMgY3JpbWluYWxzLiAgV2Ugc2VlawphZnRlciBrbm93bGVkZ2UuLi4gYW5kIHlvdSBjYWxsIHVzIGNyaW1pbmFscy4gIFdlIGV4aXN0IHdpdGhvdXQgc2tpbiBjb2xvciwKd2l0aG91dCBuYXRpb25hbGl0eSwgd2l0aG91dCByZWxpZ2lvdXMgYmlhcy4uLiBhbmQgeW91IGNhbGwgdXMgY3JpbWluYWxzLgpZb3UgYnVpbGQgYXRvbWljIGJvbWJzLCB5b3Ugd2FnZSB3YXJzLCB5b3UgbXVyZGVyLCBjaGVhdCwgYW5kIGxpZSB0byB1cwphbmQgdHJ5IHRvIG1ha2UgdXMgYmVsaWV2ZSBpdCdzIGZvciBvdXIgb3duIGdvb2QsIHlldCB3ZSdyZSB0aGUgY3JpbWluYWxzLg">here</a> on CyberChef).</p>



<p>Let’s change “baud” to “cats”. We need to locate the correct place in the ciphertext. AES (the encryption algorithm we are using) works in 16 byte blocks. The word “baud” is 85 characters in, so in the 6th block. We therefore want to modify the 5th block of ciphertext.</p>



<p>The exclusive OR is a bit more complex than last time – we now need to exclusive OR the ciphertext, the original text, and the desired text (<a href="https://gchq.github.io/CyberChef/#recipe=AES_Decrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'0000000000000000000000000000000'%7D,'CBC','Hex','Raw',%7B'option':'Hex','string':''%7D)&amp;input=MTkxNWRkOGU4ODBhN2JlZjgzN2Y1NDRlMzBlZGI5YmQxMjA3ZjMwMmRjM2NlZGQwY2I2NGJkY2JiOTk3YjVkYmM4M2RhNjU3MmZkNmMyMDVmOGQ4ZDI2NjQ5MmQyMDY3M2U0NGZhNzUwNGU2YzY0ZTI4M2E2NzI2MmIyYzMwNjM4OGI4ZjQyZTBmYjMxNzdmNmFmMTNlMWE0OGUxNDBmYTFhNDhmMThmZGYyNTc3MzgwMTUwYzM5ZDIwZTYyY2QzMzQ1ZDVmNTFiYzU4NDU2NGUwMzc5MTFkYTM1MTc3YjVkY2ZmOTkxZTRmYzg3NDFlYmJjMmRmM2I2YTc3OGViOTU3MTI1MmQxYTY0Yjk5NmRhOWFkMzFmNGE5MTI3NjM0M2FhMmU1ODQ1NjEyOTM1MDg0Zjc3Y2FhMmRiNDRiYTM5OTA5NzFkOTcwZWVlMjFlZDc3MjRiOWU3MDMwODEyZWI4N2U1ZDVmYmI3Y2M1MGE1NzYxNDBiN2I0NzhiYmZiNzU1MGU1MWU3ZmM0ZTg5ODExY2Y4MTg1OTJjNGY4ZWU3NGIyNTQ0Y2VhMGE4ZDdkZjM0OTE2YjIzYmMwOWIxYWJhN2IwN2ZlNDM0YWRjNjY5MzhhNzczMDU4MjNhYzdkMWJjZmEwOGNlOTRhYzc0MjUzNjdiODQwMGE5NGFlMDc0ZTFhY2NmZDkwYThjNDllYmYzNDNkMmU4YWQ5MmI2NDZlZDM0OTM4Yzg3NTI2MDUyYjA4ZjQ1MzgxMWQ4YTYyZjE2MzczMzkxZmE4YTBlZGIwZDJlZDBhYWQyNDViY2RlZmI1YTk0ZmRmZTBkNzA4YTMwYTVjZDVlZmI5ZjExNTk3MDU2NWFiMjg1ZGUyY2FlYWNkMTI3YzBhNzhkZDRjNmE4Y2U2NjRjYTFiOWI0YjI1ODk0MTYxMmUzMjgwOWEwNGRhYzIxODlkNGVkN2Q2ZDU4ZDcwMGNlODM5NTIzYzlmNTZiOGU2YWY1NGIzYjMxYjAxM2E4ODM4MjljM2Y0YTJhZmI3Mzc3OTFjNjBiN2E1N2I4NGNhOTgxYjFiM2E3N2M2YmI5ZWNiMzIwNzk3YmVhNzAyMDk5NGUwNzRmYmQ1NzM0MWQwMmVjYTY3ZWM1NWU5YzA1MmFkODA3NjUzMmUxZTI4MDJjMzc2YmRhMzg1NWIxYzYzY2FhNzRhZmI0YTRjNTFkMDNlNGZiMjEzY2ZiMTM4YjcxMTc1NzFhNTIzOTQzZGU1MWJiNzZiYTgwMzY2MDNkNDI2NmFmMzI3MGMyYjBhOTNjZDdlYzkyZmVjMjA0MTAyYjJkYWZlNDliMzUwZDFhNDk2NjVhYjE0MTFiMjhkZWQ1MmE5ZWE5NTA3ZWU5ZDljM2M0NzI4ZDBlNTk0YjEzM2VkMmRiOGUwYWQxZjBjZWM0NWRhYjJlN2Y1ODE5YTQyNWQ4NTY2ZWQ5MGQwYzI4MTMzZjlkZTM4ODQ4OTE3NjJhYTcxMzc2MjZmNmM2MTEzMDY4M2NkNWEzYmFjN2EzNTFkZDY0MjZjYzI2NzdjOGRjYWI0ZDMwZjg0OGNiZjYwOTBmMjM4MDM2ZTFlMzczMGZmODc4MTk2YWYyMjg4YWY5MTU5ZThkZA">here</a> on CyberChef). But change those 4 bytes, and we change the word “baud” to “cats”.</p>



<figure><img loading="lazy" width="1024" height="272" src="https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-16.03.54-1024x272.png" alt="" srcset="https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-16.03.54-1024x272.png 1024w, https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-16.03.54-300x80.png 300w, https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-16.03.54-768x204.png 768w, https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-16.03.54-1536x407.png 1536w, https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-16.03.54.png 1682w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The only issue is, as expected, the previous block has been entirely corrupted. Whilst in this case, it’s made part of the message nonsensical, it frequently has no impact when carrying out attacks.</p>



<h3>But there are worse problems?</h3>



<p>The above issue allows an attacker to modify the plaintext without detection. This would be an issue in certain situations, such as lock/unlock messages to a door.</p>



<p>But not authenticating your encryption can lead to worse issues. A type of attack called <a href="https://en.wikipedia.org/wiki/Padding_oracle_attack">padding oracle attacks</a> can let an attacker obtain the plaintext by sending a large number of specially crafted packets.</p>



<p>Block ciphers only operated on fixed blocks. If the data is shorter than a block, it must be padded. There are a number of ways of doing this, such as appending the number of padding bytes (e.g. 0x02 0x02 or 0x05 0x05 0x05 0x05 0x05). The process of decryption may check this padding is correct or not, and respond differently in each case. </p>



<p>An attacker can exploit these differential responses to leak the plaintext. This can break the confidentiality of messages.</p>



<h3>What’s the solution to this?</h3>



<p>Encryption should always be authenticated. There are two common solutions to this:</p>



<ul><li>Add a <a href="https://en.wikipedia.org/wiki/Message_authentication_code">Message Authentication Code</a> (MAC). This is a keyed cryptographic checksum that provides authenticity and integrity.</li><li>Use an authenticated mode of operation such as <a href="https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Galois/Counter_(GCM)">GCM</a>.  </li></ul>



<p>Even with this advice, there are many pitfalls. Applying the authentication and encryption in the wrong order can lead to weaknesses; this is so common that it has been deemed the <a href="https://moxie.org/2011/12/13/the-cryptographic-doom-principle.html">Cryptographic Doom Principle</a>.</p>



<p>Generally, developers shouldn’t be working with cryptography at this level unless they are suitably skilled. That’s easy to say, harder to put into action. There is a big movement to make use of secure-by-default cryptographic libraries and APIs that provide developers with useful functions without giving them so much rope they can hang themselves.</p>



<p>There are scant few reasons for not authenticating encryption.</p>
			</div></div>]]>
            </description>
            <link>https://cybergibbons.com/reverse-engineering-2/why-is-unauthenticated-encryption-insecure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534619</guid>
            <pubDate>Sun, 20 Sep 2020 15:42:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is Backblaze tracking me?]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24534572">thread link</a>) | @gingerlime
<br/>
September 20, 2020 | https://blog.gingerlime.com/2020/why-is-backblaze-tracking-me/ | <a href="https://web.archive.org/web/*/https://blog.gingerlime.com/2020/why-is-backblaze-tracking-me/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div id="content">

<div>
	<div id="primary">
		<main id="main" role="main">

			
<article id="post-2612">
		<!-- .entry-header -->

	
	<div>
		
<p>This is a follow-up to my previous post: <a href="https://blog.gingerlime.com/2020/hey-com-is-onto-something-with-its-tracking-pixel-blocker/">hey.com is onto something with its tracking-pixel blocker</a>. I mentioned contacting Backblaze about their email tracking there. </p>



<div><figure><img loading="lazy" width="630" height="396" src="https://blog.gingerlime.com/assets/Screenshot-2020-06-21-at-08.17.12.png" alt="" srcset="https://blog.gingerlime.com/assets/Screenshot-2020-06-21-at-08.17.12.png 630w, https://blog.gingerlime.com/assets/Screenshot-2020-06-21-at-08.17.12-300x189.png 300w" sizes="(max-width: 630px) 100vw, 630px"></figure></div>



<p>I didn’t think too much of it at the time, and honestly (or naively?) was expecting some kind of a “Oh, yes, you’re right, there’s no need to track those emails”… But it didn’t unfold in quite the same way.</p>



<h2>TL;DR</h2>



<p>This is my own interpretation, obviously. Backblaze seems to think that tracking emails is totally fine, even under the GDPR. They’re not going to stop doing it until further notice.</p>



<h2>Blow by blow details</h2>



<p>Rather than describing the conversation, I think for the sake of transparency it’s easier to just quote the entire thread. So here goes, in chronological order… I removed names and identifying details to protect the privacy of the people involved, but the text was otherwise left exactly as-is. Some of the interaction is fairly mundane, but you can skip to the end to see how it was resolved (or rather, not resolved).</p>



<h2>Initial conversations with Backblaze support</h2>



<figure><div>Jun 20, 2020<p>Hi Backblaze,</p><p>I started forwarding my emails to hey.com and they spotted the use of tracking pixels on your emails. I (and I believe many other customers, especially in Europe) would appreciate not being tracked without explicit consent (and I didn’t give such consent).</p><p>Respectfully,<br>Yoav</p></div></figure>



<figure><div>Jun 21, 2020<p>Hello,&nbsp;</p><p>Thank you for writing in. We do use Sendgrid to send system emails, and only collect if an email was delivered, opened, and how many times it was opened. We do not gather other information beyond that.&nbsp;</p><p>Please note that the terms can be found when you click on the link below and by using the service agree to our terms:<br>–&nbsp;<a href="http://www.backblaze.com/terms.html" rel="noreferrer noopener" target="_blank">http://www.backblaze.com/terms.html</a></p><p>All the best,<br>A.<br>Support Technician</p></div></figure>



<figure><div>Jun 21, 2020<p>Hi A.,</p><p>Thanks for getting back to me. Your terms page doesn’t actually say anything about tracking my email opens etc. Or at least I couldn’t find anything.</p><p>Regardless, I don’t believe this is permissible without explicit consent under the GDPR. I also don’t quite understand why you would even want to track those alert emails?</p><p>Sincerely,<br>Yoav</p></div></figure>



<figure></figure>



<figure><div>Jun 22, 2020<p>Hi A.,</p><p>Perhaps the timestamps on their own aren’t considered personal data, but combined with my email address, IP, browser info etc, I’m pretty sure falls under personal data as defined by the GDPR. According to two articles I was able to find, this kind of tracking isn’t permissible by GDPR and the e-Privacy directive without explicit consent, which was not requested, nor given by me.</p><p><a href="https://www.lexology.com/library/detail.aspx?g=ac233fd4-cd49-45a7-9494-6085512c0312" rel="noreferrer noopener" target="_blank">https://www.lexology.com/library/detail.aspx?g=ac233fd4-cd49-45a7-9494-6085512c0312</a><br><a href="https://www.pipedrive.com/en/blog/gdpr-email-tracking" rel="noreferrer noopener" target="_blank">https://www.pipedrive.com/en/blog/gdpr-email-tracking</a></p><p>The links you provided so far do not appear to address this issue. Would appreciate if you could look into this more seriously.</p><p>Sincerely,<br>Yoav</p></div></figure>



<figure><div>Jun 23, 2020<p>Hello Yoav,</p><p>I asked my Compliance organization to review your concerns. They noted that much of the literature around this topic deals with Marketing Emails, which you can opt-out of at any time.&nbsp;&nbsp;</p><p>For Service Emails, which the message in question is, the rules are less clear and they will contact our GDPR attorney in the EU for clarification. That said, I believe you have four choices:<br>1) You may alter the settings on your email system to receive such emails as text, this will remove all tracking,<br>2) You can discontinue using the Backblaze service and delete your Backblaze account if you remain an active customer we will continue to send you Service emails per our Terms,<br>3) You can wait to see what our GDPR attorney says, or<br>4) You may file a complaint with the GDPR authorities in your jurisdiction.</p><p>All the best,<br>A.<br>Support Technician</p></div></figure>



<figure><div>Jun 23, 2020<p>Hi A.,</p><p>Happy to wait and hear from your GDPR attorneys.</p><p>I agree that most resources talk about marketing emails, because those are the most prevalent and most common use-case of B2C and B2B emails these days. Transactional emails are generally considered legitimate use, and in this case, I explicitly asked for those emails. So there’s no question there about *sending* these emails. As far as *tracking* how I interacted with the email, as well as further personal data like IP address, device/browser info etc (that this type of tracking typically involves), and storing this info on Sendgrid’s servers, I’m pretty confident that this isn’t considered legitimate without informed and explicit consent under the GDPR and the ePrivacy directives. hey.com seem also quite confident that this is illegal (although I don’t take legal advice from them).</p><p>But besides that, I’m just curious to understand why Backblaze even cares to track those emails? what insights do you gain from knowing that X% of those emails were opened? (especially given that those stats are hugely inaccurate and some email clients block them anyway?). Wouldn’t it be easier to do the right thing here, respect your customers privacy, and stop tracking those emails? (or if you do gain important insights, explicitly and clearly ask for consent?)</p><p>Sincerely,<br>Yoav</p><p>p.s. I also believe the same rules apply to tracking of marketing emails, even if someone explicitly gives consent to *receive* those, it does not automatically mean that they give consent to being tracked, and the privacy implications of such tracking.</p></div></figure>



<figure><div>Jun 24, 2020<p>Hello,&nbsp;</p><p>I have referred the matter to the legal department and will need to close this ticket. Any further communication will come from <a href="mailto:legal@backblaze.com" rel="noreferrer noopener" target="_blank">legal@backblaze.com</a>.</p><p>All the best,<br>A.<br>Support Technician</p></div></figure>



<h2>A month passes…</h2>



<p>I was losing my patience, so sent another message to Backblaze.</p>



<figure><div>Jul 25, 2020<p>This is a follow-up to your previous request #ZZZZZZZ “email tracking”</p><p>Hi A.,It’s been a month now, and I still haven’t heard back. Would appreciate if someone can get back to me on this.</p><p>Sincerely,<br>Yoav</p></div></figure>



<div><div>
<figure><div>Jul 25, 2020<p>Hi Yoav,</p><p>Thank you for reaching out regarding this issue. Apologies for any delay. I’m sorry to say but further communication will need to go through <a href="mailto:legal@backblaze.com" rel="noreferrer noopener" target="_blank">legal@backblaze.com</a>.</p><p>Please reach out to that email for additional information.<br>M.<br>Support Technician</p></div></figure>



<figure><div>Jul 26, 2020<p>Hi M.,</p><p>Yes, but it’s been a month, and I believe that under GDPR I can typically expect an answer within a month? see https://ico.org.uk/your-data-matters/time-limits-for-responding-to-data-protection-rights-requests/</p><p>Looking forward to hearing back from whichever team/person that can handle my enquiry.</p><p>Sincerely,<br>Yoav</p></div></figure>



<h2>Legal department steps in</h2>



<figure><div>Jul 31, 2020<p>Hi Yoav,</p><p>Thank you for following up on this matter. We take data privacy matters very seriously at Backblaze, Inc. We have reviewed your concerns and understand your sensitivity regarding the use of tracking technology on emails. In this particular case, we believe there is an exception allowed for doing so for a valid business purpose. There are two reasons we believe this is necessary.</p><p>The first reason is to accurately measure the reach and usefulness of our service email messages to our customers. Service emails communicate important information to the customer and if they are not being received or opened, valuable information is being missed. For example, the customer’s data we are storing could be at risk of being deleted, or their account could be in peril of being compromised. We use the tracking technology to provide an aggregated measure of this information versus using more invasive technologies such as user surveys or onscreen popups. Over the years we have sent many service emails and we have a full understanding as to the delivery and open rates of our service emails. As such, any anomalies are easily detected and can be acted upon to improve how well we communicate with our customers.</p><p>The second reason is for forensic purposes to respond to questions from customers and defend ourselves as needed. For example, we send multiple service emails to a customer whose subscription is expiring, as once it does expire, we will close their account and delete the data we are storing for them. From time-to-time an ex-customer will want their data and claim we did not notify them that their account was expiring. The tracking technology allows us to show what messages we have sent and what messages the customer received and opened. While not perfect, it has helped us defend ourselves in the past. There is no reasonable replacement for using the tracking technology in such cases. By the way, the same technology also allows us to prove the customer right in many cases, so it delivers value and protects both us and the customer at the same time.</p><p>Thank you for being a valued customer.</p><p>Best regards,<br>T.<br>Legal Department</p></div></figure>



<figure><div>Aug 1, 2020<p>Hi T.,</p><p>Thanks for getting back to me and explaining your reasoning in detail.</p><p>I have to admit, it sounds a bit like a husband spying on their wife “because they love her” to some extent. I don’t feel like these are valid reasons for blanket tracking of ALL emails across all customers, which seems to be the case at Backblaze. As far as I can tell, all Backblaze emails are tracking me and all other customers, from newsletters, across minor service notifications all the way to billing and other messages. Not all messages are the same, but they are all tracked in the same way as far as I can tell. Furthermore, not only there is no informed consent for this tracking, there’s actually no opt-out mechanism either. As a customer, I cannot tell you that I want your service emails, but I don’t want them tracking me. I don’t believe this meets the spirit nor the letter of the GDPR.</p><p>The first example does not at all sound like a legitimate reason to me, and I doubt the data protection authorities will accept it as legitimate either. Especially when it applies to all emails, including minor notifications, newsletters and other marketing materials. What you’re describing is that you’re compromising the privacy of your customers for your own internal reasons for marketing purposes. And as I mentioned before, with no informed consent, nor opt-out options. But besides that, given …</p></div></figure></div></div></div></article></main></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.gingerlime.com/2020/why-is-backblaze-tracking-me/">https://blog.gingerlime.com/2020/why-is-backblaze-tracking-me/</a></em></p>]]>
            </description>
            <link>https://blog.gingerlime.com/2020/why-is-backblaze-tracking-me/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534572</guid>
            <pubDate>Sun, 20 Sep 2020 15:32:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Labelai – speed up training your AI models with a free open-source app]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24534538">thread link</a>) | @aralroca
<br/>
September 20, 2020 | https://aralroca.com/blog/labelai | <a href="https://web.archive.org/web/*/https://aralroca.com/blog/labelai">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I'd like to tell you why I made <strong><a href="https://github.com/aralroca/labelai">Labelai</a></strong>, a tool that makes it easier to train image recognition AI models (ImageNet, YOLO and its variants) from any device ensuring security.</p>
<h2 id="a-little-bit-of-context">A little bit of context</h2>
<p>When we want to directly use existing image recognition models such as ImageNet, COCO-ssd or YOLO, we are limited to predict only everyday objects such as cars, people, etc. This is because these models have only learned to recognize these objects within an image. However, there are techniques such as transfer-learning that allow us to retrain these models to <strong>predict what we want</strong>. </p>
<p>In order to retrain these models, we have to <strong>manually label each object</strong> that we want to recognize by writing the coordinates of the object in a text file for each image to train. This way the model will be able to learn how to recognize them. This labeling process can be very boring and tedious.</p>
<p>Currently, there are not many alternative tools for this labeling process. The best known current tool is <a href="https://github.com/tzutalin/labelImg">labelImg</a>. The tool is good and does its job, although it has some root problems:</p>
<ul>
<li><strong>Not available in all devices</strong>. It can only be downloaded as a desktop application.</li>
<li><strong>Requires installation</strong>. It requires installation and it isn't very beginner-friendly. Depending on your OS and Python version the dependencies will be different. For example on Mac with Python 3+, you need to install first some dependencies like <code>qt</code> and <code>libxml2</code> with Homebrew, and <code>pyqt5</code> and <code>lxml</code> with pip.</li>
<li><strong>Security</strong>. The application manipulates the files on your system. In theory, it only manipulates files related to annotations. I say "in theory", because we hope there won't be a bug in the future touching what it shouldn't... </li>
<li><strong>Updates are not automatic</strong>. Related to the previous point, many updates are made for security reasons, especially if it has dependencies. The fact that updates are not done automatically makes it your responsibility to keep your application up to date.</li>
</ul>
<h2 id="launching-labelai">Launching Labelai</h2>
<p>Using labelImg during the last months, I realized that a <strong>web application</strong> inspired by it would solve several of these problems:</p>
<ul>
<li><strong>Available in all devices</strong>. Being a web application makes it accessible from any device, even tablets, and mobiles.</li>
<li><strong>No installation required</strong>. It speeds up the start, as it does not require installation and has no dependencies on your operating system. Only the browser.</li>
<li><strong>Automatic updates</strong>. You will always have the latest version available.</li>
<li><strong>Security</strong>. No file on your system is directly manipulated. Files are imported/saved using the security layer of your browser.</li>
<li><strong>Beginner-friendly</strong>. We want it to be an easy-to-use process without losing flexibility. To start, you only need to open a browser with any device.</li>
</ul>
<p>So during my August holiday, I took the opportunity to implement the first POC of my idea. And today, I announce that its <strong>first version is out</strong>.</p>
<a href="https://github.com/aralroca/labelai">
  <figure>
    <img loading="lazy" src="https://aralroca.com/images/blog-images/labelai.png" alt="Labelai logo">
    <figcaption><small>Labelai</small></figcaption>
  </figure>
</a>

<p>This version 1.0.0 is focused on being useful as a web tool to label your images and supports both <strong>ImageNet</strong> and <strong>YOLO</strong>, and its variants.</p>
<p>In addition, I tried to improve the user experience when labeling by making it less necessary to press so many buttons.</p>
<p>Currently, I have some future ideas to expand the features so that it does not remain only as an annotation tool, but to train models after labeling the images.</p>
<figure>
  <img loading="lazy" src="https://aralroca.com/images/blog-images/demo.gif" alt="Labelai demo">
  <figcaption><small>Labelai demo</small></figcaption>
</figure>


<h2 id="future-features">Future features</h2>
<p>As a free open-source tool we want to evolve according to the contributions of the community. However, in the first version, there are some things that have not yet been implemented and the idea is to implement them for the next version:</p>
<ul>
<li><strong>Improve tablet / mobile experience</strong>. Now the support is minimal, it works, but not as well as some users would like. For example, it is not very responsive. This should be improved in a next version.</li>
<li>Possibility to <strong>train directly</strong> your labeled images <strong>with the same app</strong> and also to save the generated model.</li>
<li><strong>Offline</strong> support. Now it only works online, but one of the improvements would be to support it offline as PWA.</li>
</ul>
<p>Any further improvements you would like to make? Please let me know in the comments.</p>
<h2 id="try-it">Try it</h2>
<p>I encourage you to try the app and contribute to GitHub to evolve this tool according to the community.</p>
<ul>
<li>App: <a href="https://labelai.vercel.app/">https://labelai.vercel.app/</a></li>
<li>GitHub: <a href="https://github.com/aralroca/labelai">https://github.com/aralroca/labelai</a></li>
</ul>
<p>To help me boost this project, please, let me know that you like it by <strong>starring on GitHub</strong>.</p>
</div></div>]]>
            </description>
            <link>https://aralroca.com/blog/labelai</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534538</guid>
            <pubDate>Sun, 20 Sep 2020 15:25:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apache Arrow and MinIO]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 32 (<a href="https://news.ycombinator.com/item?id=24534274">thread link</a>) | @jtsymonds
<br/>
September 20, 2020 | https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/ | <a href="https://web.archive.org/web/*/https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                    <p>More and more enterprises have begun or have already implemented a data lake strategy based on some of the work we did a couple of years ago. If you want to take a moment to review - you can find those posts below <a href="https://blog.min.io/modern-data-lake-with-minio-part-1/">here</a> and <a href="https://blog.min.io/modern-data-lake-with-minio-part-2/">here</a>. </p><h2 id="objective">Objective</h2><p>In this article, I am going to explain a mechanism to turbocharge the use of MinIO. Nothing changes as far as MinIO is concerned, the optimization will be on the underlying storage of our data. We are going to choose one of the latest formats to improve agility manifoldly. We are going to show the ways by which your data lake data can travel across systems without experiencing any "conversion" time. </p><h2 id="apache-arrow">Apache Arrow</h2><p>I believe understanding this article needs some basic concepts of<a href="https://arrow.apache.org/"> </a>how applications like Spark works. Let me explain it in simple terms.</p><p>Imagine you got a nice job at a location different from where you live currently and you want to relocate, as the new company demands it and pays for it. You have got the most modern televisions, refrigerators, super soft leather sofas, bed and so on. You engage a moving company, who comes, disassembles everything, packs it conveniently. They also make sure to pack as much possible in containers to fill the truck such that they can do it in a single trip. Once they reach the destination, they unpack, assembles and restore everything as it was.</p><p>The same applies to data. When I store some data in MinIO , and I need to feed it to, say, another application, say Spark, the consuming application needs to disassemble the data from MinIO data lake, pack it and transport it through the wire (or wireless), receive, unpack and re-assemble. </p><p>Let's use more technical terms for this disassembly and assembly - serialization and de-serialization of data. The unfortunate part is, both these processes are complex and time consuming. Here is a brief diagram illustrating what happens in Apache Spark when it reads data</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png 1944w" sizes="(min-width: 720px) 720px"><figcaption>Experimental setup. Courtesy: <a href="https://databricks.com/session/running-apache-spark-on-a-high-performance-cluster-using-rdma-and-nvme-flash">Spark Summit</a></figcaption></figure><p>You may not have noticed this problem before. Assume that MinIO is on a machine(s) on the network. We write a Spark Map-Reduce application. Eventhough the network limit is 100 GbE, we are almost getting less that 10 GbE speed. What's the use of this high speed network then? What is the potential problem which is not allowing us to utilize the full potential of the network, or at least 70-80% of it?</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png 1948w" sizes="(min-width: 720px) 720px"><figcaption>Additional layers, buffers and serializers</figcaption></figure><p>The issues are with the way in which Spark is retrieving the data. Look at the number of layers the data has to pass though. This creates a limit on the throughput that we can achieve. There are projects like <a href="https://crail.apache.org/">Apache Crail,</a> which are designed to address these issues.</p><h2 id="optimization-columnar-data-format">Optimization : Columnar Data Format </h2><div><p>If we think about the relocation example mentioned above, we see that the logistic company will never take the sofa as it is, they will break it down to make it easy to transport. Note that this is for transportation purposes only - if that objective is different, then disassembling the sofa might not be the right approach. </p><p>Given that the objective for a data lake is analytics - rather than transactional needs we must take that under consideration. For transactions, we often use OLTP systems like Oracle or PostGres - given that they are particularly well suited for the job. A quick review of OLAP's analytics requirements is probably in order. </p></div><figure><img src="https://blog.min.io/content/images/2020/09/Picture1.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Picture1.png 600w, https://blog.min.io/content/images/2020/09/Picture1.png 966w" sizes="(min-width: 720px) 720px"><figcaption>Introducing columnar format</figcaption></figure><p>Let's start with one of the most famous RDMBS table - the "emp" table of Oracle. The top part shows how the data is stored in RDBMS as a "relation" or "tuple". We call it a table. I am providing you two queries</p><!--kg-card-begin: markdown--><ol>
<li>select ename from emp where job = 'CLERK'</li>
<li>select sum(sal) from emp</li>
</ol>
<!--kg-card-end: markdown--><p>The first is a transactional query. It has to scan every row on the table and find out the name of the employee wherever the job is clerk. The second is an analytical query - rather than an atomic result, the goal is a general result. Unfortunately, the first and second query has to scan through all the rows, if we use RDBMS way of representation of data. If the size of data is 20 GB, all the 20 GB more or less will be scanned. This is the top part of above figure.</p><p>Let's make some changes - taking all of our columns and make them into rows. Like a transpose of a matrix - and see the bottom part of above figure, how your data will look like. Following this transposition, an entire block is just representing one column. How many blocks need to be scanned for the second analytical query? Just one block, probably around 2 GB of size. </p><p>The difference is significant? Columnar representation is what is being used in ORC (Optimized Row Columnar) and Parquet files - with the goal of making the analytics faster.</p><p>Columnar formats are easier to read, however, they pose another problem - they are usually stored in compressed format. As a result, the consuming application will need to uncompress it while reading and compress it back while writing. </p><p>Note this, as we will revisit the point later.</p><h2 id="the-science-of-reading-writing-data">The Science of Reading/Writing Data</h2><p>Let me explain briefly how reading/writing happens in a software system and what role is played by the hardware.</p><p>Microprocessors normally use two methods to connect external devices: <strong>memory mapped</strong> or <strong>port mapped</strong> I/O. </p><p>Memory mapped I/O is mapped into the same address space as program memory and/or user memory, and is accessed in the same way.</p><p>Port mapped I/O uses a separate, dedicated address space and is accessed via a dedicated set of microprocessor instructions.</p><p>In memory mapped approach, I/O devices are mapped into the system memory map along with RAM and ROM. To access a hardware device, simply read or write to those 'special' addresses using the normal memory access instructions.The advantage to this method is that every instruction which can access memory can be used to manipulate an I/O device.</p><p>Usually applications use Port mapped I/O. If we are using memory mapped I/O for a particular format, it will be faster, especially for analytical needs. When combined with our columnar data format, then it becomes even more advantageous.</p><p>Welcome to <a href="https://arrow.apache.org/">Apache Arrow</a>. </p><p>Arrow uses memory mapped I/O and avoids serialization/deserialization overheads when you convert between most of the formats while leveraging the columnar data format. </p><p>Thanks to <a href="https://wesmckinney.com/">Wes McKinney</a> for this brilliant innovation, its not a surprise that such an idea came from him and team, as he is well known as the creator of Pandas in Python. He calls Arrow as the future of data transfer.</p><h2 id="store-data-in-minio-in-arrow-format">Store Data in MinIO in Arrow Format</h2><p>This is how we are going to make MinIO even more powerful. </p><p>We are going to store that data in Arrow and then let the consuming applications read it - resulting in dramatically increased speeds. Step one has us putting the data into MinIO in Arrow format. I was using my own approach until I saw a much better implementation from <a href="https://github.com/BryanCutler">Bryan Cutler</a>, whose contributions include integrating Arrow formats to Spark as well.</p><p>We will start with a a .csv file, in this case movie ratings downloaded from the <a href="https://movielens.org/">movielens</a> site. For illustration purposes, I took about 100K rows. First, let's write a Spark program to read this CSV file and write it into Arrow format using Arrow RDD. You can get the full code from the link given towards the bottom of this article.</p><p>Step 1: build.sbt , please note the arrow dependencies</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png 1990w" sizes="(min-width: 720px) 720px"><figcaption>See lines 18 and 19, we have Arrow related dependencies with Spark</figcaption></figure><p>We will use Spark 3.0, with Apache Arrow 0.17.1</p><p>The ArrowRDD class has an iterator and RDD itself. For creating a custom RDD, essentially you must override mapPartitions method. You can browse the code for details. </p><p>Next, start MinIO and create a bucket named "arrowbucket". </p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png 1600w, https://blog.min.io/content/images/size/w2400/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Create a bucket named "arrowbucket" in MinIO</figcaption></figure><p>Let's use ArrowRDD and create an ArrowFile in local. Here is the code:</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png 2372w" sizes="(min-width: 720px) 720px"><figcaption>Writing Arrow file with ArrowRDD</figcaption></figure><p>Lines 22 to 34 do the main part. Compile and execute the code:</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png 1600w, https://blog.min.io/content/images/size/w2400/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Execute the code</figcaption></figure><p>As you see from code, the Arrow format file is is generated in data directory. Let's copy it to the MinIO bucket we created earlier (bucket name is arrowbucket)</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png 1600w, https://blog.min.io/content/images/size/w2400/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Copy the arrow file we generated to MinIO bucket</figcaption></figure><p>Let's have some fun now. </p><p>Use your favorite Python editor, and write some code. First, let us start with Spark reading the file and converting it to a dataframe, with and without Arrow enabled options.</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png 1698w" sizes="(min-width: 720px) 720px"><figcaption>Initializing Spark context and connection parameters to Minio</figcaption></figure><p>Start your Spark cluster. Complete the code with all settings and check whether we created the Spark context successfully. To ensure that our app (named Minio-Arrow-Spark at line 8) is connected, just check the Spark UI. You should see something like this:</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png 1600w, https://blog.min.io/content/images/size/w2400/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Spark UI (default localhost:8080) is showing our app is connected</figcaption></figure><p>Run the below code now:</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png 1708w" sizes="(min-width: 720px) 720px"><figcaption>Reading from MinIO with Arrow format "not enabled" (top) and "enabled"(bottom)</figcaption></figure><p>The output which displays the time, shows the power of this approach. The performance boost is tremendous, almost 50%.</p><p>Recall that we created an ArrowRDD earlier and used it to write to MinIO. Let us test the memory consumption in reading it. We will use different methods.</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png 1882w" sizes="(min-width: 720px) 720px"><figcaption>See the results - Arrow is zero copy memory format</figcaption></figure><p>We are reading different file formats and seeing the memory consumption for each. As it is evident, Arrow format based files are zero copy - almost no memory consumed at all.</p><p>By combining MinIO with the Arrow Format, you can enhance your analytics ecosystem and virtually eliminating the friction associated with converting between different formats. This is primarily due to the reduction of serialization overhead.</p><h2 id="code">Code </h2><p>You can see the<a href="https://github.com/passionbytes/ArrowRDD"> Jupyter notebook and ArrowRDD code here</a>.</p><p>Ravishankar Nair is a technology evangelist, a consultant and an inspiring speaker. He is the CTO of PassionBytes, based in Florida. With his vast expertise in data engineering, Ravi provides consultancy in machine learning, modern data lakes and distributed computing technology. You can refer to his other articles related to MinIO here:</p><p>1) <a href="https://blog.min.io/modern-data-lake-with-minio-part-1/">Modern Data Lakes with Minio - Part 1</a></p><p>2) <a href="https://blog.min.io/modern-data-lake-with-minio-part-2/">Modern Data Lakes with MinIO - Part 2</a></p><p>3) <a href="https://blog.min.io/building-an-on-premise-ml-ecosystem-with-minio-powered-by-presto-r-and-s3select-feature/">Building an …</a></p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/">https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/</a></em></p>]]>
            </description>
            <link>https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534274</guid>
            <pubDate>Sun, 20 Sep 2020 14:32:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Yelp: Local Economic Impact Report]]>
            </title>
            <description>
<![CDATA[
Score 137 | Comments 170 (<a href="https://news.ycombinator.com/item?id=24534186">thread link</a>) | @bookofjoe
<br/>
September 20, 2020 | https://www.yelpeconomicaverage.com/business-closures-update-sep-2020.html | <a href="https://web.archive.org/web/*/https://www.yelpeconomicaverage.com/business-closures-update-sep-2020.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
      
    
    <section>
      <!--<p class='prose flag'><i>If you'd like additional detail on how the economy is shifting, please contact us at <a href='mailto:press@yelp.com'>press@yelp.com</a> or <a class=underline href=http://eepurl.com/cMFvGL target=_blank>join our mailing list</a> to receive an email when new reports are released.</i></p>-->
    
      
        <p>Since the first fears of the pandemic emerged in the U.S. in early March, businesses across the nation have endured six months of uncertainty. Yet, businesses are adapting and proving their resilience through lockdowns, reopenings, a <a href="https://www.nytimes.com/interactive/2020/us/coronavirus-us-cases.html?name=styln-coronavirus-markets&amp;region=TOP_BANNER&amp;variant=1_Show&amp;block=storyline_menu_recirc&amp;action=click&amp;pgtype=Article&amp;impression_id=76e345d2-e946-11ea-8ee3-5b12c6c78bc9" target="_blank">summer surge in virus cases</a>, new ways of doing business such as <a href="https://www.nytimes.com/2020/08/23/nyregion/outdoor-dining-new-york.html" target="_blank">outdoor dining</a>, new mask wearing rules and backlash from <a href="https://www.washingtonpost.com/nation/2020/07/18/covid-pandemic-store-clerk-north-carolina/?arc404=true" target="_blank">anti-mask patrons</a>, as well as milestones such as the <a href="https://www.yelpeconomicaverage.com/back-to-school-2020.html" target="_blank">return to school</a>. Even in the wake of increased closures we’re seeing businesses effectively transition to new operating models while keeping their employees and consumers safe.</p>
        <p>Yelp closure data shows that businesses providing home, local and professional services have been able to withstand the effects of the pandemic particularly well. But despite bright spots in some sectors, restaurants and retail continue to struggle and total closures nationwide have started to increase.</p>
        <p>The <a href="https://www.yelpeconomicaverage.com/yea-q2-2020.html" target="_blank">last Yelp Economic Average</a> showed a decreasing number of overall closures, 132,580 in total. As of August 31, 163,735 total U.S. businesses on Yelp have closed since the beginning of the pandemic (observed as March 1), a 23% increase since July 10. In the wake of COVID-19 cases increasing and local restrictions continuing to change in many states we’re seeing both permanent and temporary closures rise across the nation, with 60% of those closed businesses not reopening (97,966 permanently closed).</p>
    </section>
    
    <section>
      <h3>Business Closures Continue to Increase Nationally</h3>
      <h4>Number of businesses marked closed on Yelp that were open March 1</h4>
      <p><i></i>Hover over a circle to see closures</p>
    	
    </section>
    
    <!--
    <section class='report-wrapper'>
    	<h3 class='centered-title'>Business Closures Continue to Increase Nationally</h3>
      <h4 class='centered-title'>Number of businesses marked closed on Yelp that were open March 1</h4>
    
    	<div class='static-image-container'>
    		<img class='static-image-desktop' src='./assets/img/closures092020/Closures_Rate_Desktop-2a05305cb0.png'/>
    		<img class='static-image-tablet' src='./assets/img/closures092020/Closures_Rate_Desktop-2a05305cb0.png'/>
    		<img class='static-image-mobile' src='./assets/img/closures092020/Closures_Rate_Mobile-f0f8a42c99.png'/>
    	</div>
    </section>
    -->    <section>
    	<h2>Resilient Businesses Operating in an Unpredictable Economy</h2>
        <p>Some business sectors have been able to weather the COVID-19 storm particularly well. In general, professional services and solo proprietors as a whole have been able to maintain a relatively low fraction of closures since March 1. This group includes lawyers, real estate agents, architects, and accountants – all with only two to three out of every thousand businesses closed, as of August 31. Health related businesses in particular have been able to maintain a low rate of closures – orthopedists, internal medicine, hospitals, physicians, family doctors and OB/GYNs all have less than three closures out of every thousand businesses.</p>
        <p>Yelp’s closure data also shows that demand for <a href="https://blog.yelp.com/2020/08/yelp-reinvents-the-hiring-experience-for-home-and-local-services" target="_blank">home, local</a> and automotive services has remained robust with a far lower rate of closures compared to restaurants and retail. Towing companies, plumbers and contractors in particular have maintained a low rate of closures, with only six to seven out of every thousand businesses closed. In fact, the share of consumer interest in home and local services is up 24% between March 1 and August 31, relative to all categories on Yelp, compared to the same time last year.</p>
    </section>
    
    <section>
    	<h3>Home, Local, Professional, and Auto Services Prove Their Strength Amid the Pandemic</h3>
    
    	<p><img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Sector_Desktop-b84f739960.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Sector_Desktop-b84f739960.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Sector_Mobile-069e01b319.png">
    	</p>
    </section>    <section>
      <h2>Restaurants Remain Hardest Hit, Permanent and Temporary Closures Increase</h2>
        <p>The restaurant industry continues to be among the most impacted with an increasing number of closures – totalling 32,109 closures as of August 31, with 19,590 of these business closures indicated to be permanent (61%). Breakfast and brunch restaurants, burger joints, sandwich shops, dessert places and Mexican restaurants are among the types of restaurants with the highest rate of business closures. Foods that work well for delivery and takeout have been able to keep their closure rates lower than others, including pizza places, delis, food trucks, bakeries and coffee shops.</p>
        <p>Meanwhile, bars and nightlife, an industry 6X smaller than restaurants, has endured an especially high closure rate, with an increasing percentage of closures being permanent. As of the end of August there were 6,451 total business closures, of which 3,499 were permanently closed (54%). The share of permanent closures within bars and nightlife have increased by 10% since our <a href="https://www.yelpeconomicaverage.com/yea-q2-2020.html" target="_blank">Economic Average Report</a> in July.</p>
        <p>Retail and shopping follows closely behind restaurants with 30,374 total business closures, 17,503 of which are permanent (58%). Similar to bars and nightlife, the share of permanent closures increased by 10% since July. Both men and women’s clothing, as well as home decor, have the highest rate of business closures.</p>
        <p>The beauty industry has seen a 22% increase in closures since July, totalling 16,585 closures. Of all closed businesses in the beauty industry 7,002 won’t reopen (42%), a significant 43% increase since July when we reported that 4,897 of all closures in the beauty industry were permanent. Similarly the fitness industry has endured a 23% increase in closures since July, with 6,024 total closures, 2,616 of which are permanently closed.</p>
    </section>
    
    <section>
    	<h3>Restaurants and Retail Continue to Struggle</h3>
      <h4>Number of businesses marked closed on Yelp that were open March 1</h4>
    
    	<p><img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Category_Desktop-91d671567c.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Category_Desktop-91d671567c.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Category_Mobile-529b856e87.png">
    	</p>
    </section>    <section>
      <h2>Larger States and Metros See a Greater COVID-19 Impact on Local Businesses</h2>
        <p>Even as the pandemic spreads nationally, geographically Yelp data shows business closure rates vary across the country. Bigger states and metros with higher rents and more stringent local operations for small businesses throughout the last six months have felt a greater toll. So have businesses more closely linked to physical locations that require crowds of consumers to attain profitability. Meanwhile, smaller cities and solo operations that can do their work one-on-one or virtually have proven better positioned to stay in business.</p>
        <p>For the states with widespread business closures, the economic struggle appears to be closely coupled with unemployment rates. Hawaii, California, and Nevada have the highest rate of total closures and permanent closures – they’re also the three states with the <a href="https://finance.yahoo.com/news/these-states-are-suffering-from-the-worst-unemployment-rates-144451899.html?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAABND8yZDak2Xg6GnNC9LukDHqDayj3GYnFbfZn_9NctEnowVC1JMpg9oZFKixnWrRLGLPortUEEaymyEAYmZ0jMN8vOuriLR1N7S0Roqv9OT99H-WdN5XH_sd_I_r0-EgEJSDExY9yTtI7Xduv3Q-Agxb55dUepi3-k8T1fGZ153" target="_blank">highest unemployment rates</a>, and among the <a href="https://www.worldatlas.com/articles/the-most-visited-states-in-the-us.html" target="_blank">biggest states for tourism</a>. Meanwhile, West Virginia and the Dakotas have the lowest closure rates.</p>
        <p>The states with the most closures are home to the hardest-hit metros: Las Vegas in Nevada, Honolulu in Hawaii, and several of the largest California urban areas all are among the metro areas with the highest total closure and permanent closure rates (San Diego, San Francisco, San Jose, Los Angeles and others), with roughly 20 businesses per thousand temporarily or permanently closing their doors since March 1. Larger metros with far fewer closures tend to be in the East, including Pittsburgh, Philadelphia, and Baltimore, all with closure rates below 10 per thousand.</p>
    </section>
    
    <section>
    	<h3>Where are the Most Businesses Closed?</h3>
      <h4>Geographic areas with the largest number of business closures since March 1</h4>
    	<div>
    		<p>Total Closures</p>
    		<p>Closures per 1,000</p>
    	</div>
    
    	<p><img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Geography_Total_Desktop-dce0442da9.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Geography_Total_Desktop-dce0442da9.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Geography_Total_Mobile-98f53c8115.png">
    	</p>
    
    	<p><img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Geography_Capita_Desktop-846de29ad1.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Geography_Capita_Desktop-846de29ad1.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Geography_Capita_Mobile-1878bbd645.png">
    	</p>
    </section>
    <section>
        <p>Keep an eye out for our next update in our Q3 <a href="https://www.yelpeconomicaverage.com/index.html" target="_blank">Yelp Economic Average</a>.</p>
        <p>—Carl Bialik and Daniel Gole contributed to this report</p>
    </section>
    
    <section>
        <p><em>If you'd like additional detail on how the economy is shifting, please contact us at <a href="https://www.yelpeconomicaverage.com/cdn-cgi/l/email-protection#2b5b594e58586b524e475b05484446"><span data-cfemail="d3a3a1b6a0a093aab6bfa3fdb0bcbe">[email&nbsp;protected]</span></a> or <a href="http://eepurl.com/cMFvGL" target="_blank">join our mailing list</a> to receive an email when new reports are released.</em></p>
        <p><em>Interested in learning how Yelp data can assist you in developing market insights for your business? Yelp Knowledge can help, learn more <a href="https://www.yelp.com/knowledge" target="_blank">here</a>.</em></p>
    </section>
    
    
    <!--
    <section class='report-wrapper'>
    </section>
    -->
    
    <section>
    	
    	<h2>Methodology</h2>
    
    		<p><em>Business Closures</em></p>
    		<p>On each date, starting with March 1, we count U.S. businesses that were open on March 1 and were closed on that day. Closure can be permanent or temporary, and is signaled by a business owner marking the business as closed, including by changing its hours or through a COVID-19 banner on its Yelp page. Closure counts are likely an estimate of the businesses most impacted, with many others not counted because they remain open with curtailed hours and staffing, or because they have not yet updated their Yelp business pages to reflect closures. Additionally, we only count closures that have been vetted by our User Ops team or have been updated directly by a business owner. Closures are counted by state, metro area, and category; some businesses are in more than one category. Businesses can also set automatic reopening dates on Yelp, which are counted as reopenings unless the business updates their information.</p>
    		<p><em>Downloadable static graphics can be found <a href="https://drive.google.com/drive/folders/1kSIOmVz_06NEP37NRfkODkzrpE0lAl3X?usp=sharing" target="_blank">here</a>.</em></p>
    		<p><em>See Yelp's previous Local Economic Impact Reports at our Data Science Medium, <a href="https://medium.com/tag/yelp-coronavirus-report/archive" target="_blank">Locally Optimal</a>.</em></p>
    </section>
    <section>
      <!-- <p class='prose'><strong>Interested in the numbers behind YEA? Check out the <a class='underline' href='./methodology.html'>methodology</a>.</strong></p> -->
      
    </section>    
  </div></div>]]>
            </description>
            <link>https://www.yelpeconomicaverage.com/business-closures-update-sep-2020.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534186</guid>
            <pubDate>Sun, 20 Sep 2020 14:17:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Syntax for Self-Tracking]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24534179">thread link</a>) | @mg
<br/>
September 20, 2020 | https://www.gibney.de/a_syntax_for_self-tracking | <a href="https://web.archive.org/web/*/https://www.gibney.de/a_syntax_for_self-tracking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div><meta property="og:image" content="https://www.gibney.de/images/direct/cat_size02/162.jpg?v2">
<meta name="twitter:card" content="summary">
<meta name="twitter:site" content="@marekgibney">
<meta name="twitter:title" content="A Syntax for Self-Tracking">
<meta name="twitter:description" content="How I keep a machine readable self-tracking log in a text file.">
<meta name="twitter:image" content="http://www.gibney.de/images/direct/cat_size02/162.jpg?v2">





<p>For a while now, I have been doing self-tracking in a text file. The reason is that I want to track not only one aspect of life, like fitness or health or nutrition, but anything that I suspect might be interesting to analyze later. Like how the time I wake up impacts my mood. Or which eye drops work best to prevent dry eyes. Or how the temperature of my bedroom impacts my energy the next day. Did I wake up with a headache because I ate pizza late at night? Or because I slept with the window wide open? Maybe I should avoid one of these in the future?</p>

<p>If a completely context-free self-tracking app exists, I am not aware of it. Every tracking app seems to apply only to a certain narrow topic - often sport or food. And then all the apps send the data to a central server, which makes me uncomfortable.</p>

<p>To get started experimenting with context-free self-tracking, I tried it in a simple text file. As it turns out, it is surprisingly doable, and it has led me to a bunch of interesting results already.</p>

<p>It has led to a data structure that I find useful to do context-free self-tracking. A bit like the Git data structure: you can manipulate it with simple tools, and if you are nerd enough you might stick with those. I, for example, use only raw Git to do version control. And I only use Vim to operate on the self-tracking data structure I describe in this article. The general population would probably prefer higher-level tools (i.e., an app), which I will probably write later on. But first I want to get the data structure right.</p>

<p>I started with a simple space-separated approach of "date time event":</p>

<p>
2020-05-28 18:41 Eat Pizza<br>
2020-05-29 09:00 Slept with the window open<br>
2020-05-29 09:00 Headaches<br>
</p>

<p>Everything is freeform. There is just one rule:</p>

<p>
 1: Every line starts with the date and time
</p>

<p>This gives me the complete freedom to log whatever data I want. But I knew there would be more than just free text logging in the future. Structured logging of quantities (how many kilometers I ran, how many hours I slept), fine-grain data on multiple levels (How strong is the headache? Is it on the right or left side?), proper A/B tests, etc. I wanted to keep the option to introduce all this into the syntax without losing the freedom of logging free text. So I made this second rule:</p>

<p>
2: Everything until [^a-z ] describes an observation
</p>

<p>(A non-technical way to put it: Everything that only consists of the characters A-Z plus the space sign describes an observation.)</p>

<p>To do away with any confusion about capitalization, I decided to make everything case-insensitive:</p>

<p>
3: Uppercase characters equal their lowercase counterparts
</p>

<p>This way, I can write anything into the log that comes to my mind without thinking about syntax at all. As long as I stick to the characters A-Z and the space, I can log anything in any way I like.</p>

<p>Another early design decision about my self-tracking was that it is OK to write events into the log at any time. So I wrote all three log entries above at 09:00 in the morning, even the one about 18:41 of the last day. It is impossible to proactively track everything that could be of interest later. This is different to scientific studies where you would usually define upfront which causes to measure against which outcomes. But I think it is still useful to retroactively log data in the hopes that you can later make sense of it. That is how the human mind works. It's normal to think about past events when you try to find causes for the current situation. And I think a proper lifelong log can help us with this, even if we do not set up A/B tests - but we will, further down in this article.</p>

<p>As you can see, I also took the liberty to log observations about the past. "Slept with the window open." An acceptable alternative is to retroactively put the beginning of the event into the log, like I did with the pizza:</p>

<p>
2020-05-28 18:41 Eat Pizza<br>
2020-05-28 23:20 Go to bed with the window open<br>
2020-05-29 09:00 Headaches<br>
</p>

<p>The idea is to log a lot of data quickly when I feel like logging it. The data can be dirty. No problem - clean it up later. Keep it in Git to have a track record how it changed.</p>

<p>A nice convenience in Vim is that you can make it suggest the next word by pressing CTRL+N. This makes logging very fast. Instead of typing "Headache" you can just type H and CTRL+N and it will give you a list of every word with H you already have in your log. It also prevents typos and makes the data cleaner.</p>

<p>For even greater convenience, I added another rule to my syntax:</p>

<p>
4: _ equals space.
</p>

<p>This means that instead of writing "Slept with the window open" I can write "Slept_with_the_window_open". From a data perspective, the two are equivalent. But for typing, now all I have to do is type S-CTRL+N and I get the whole event suggested by Vim "Slept_with_the_window_open". Which makes typing this event a matter of three keystrokes and keeps the data clean as I will always write it the same way.</p>

<p>At this point, writing the events was already super fast. The most cumbersome part of logging was typing the date and time manually. So I added a shortcut to Vim:</p>

<p>
nnoremap &lt;space&gt;t o&lt;C-r&gt;=strftime("%F %H:%M ")&lt;cr&gt;
</p>

<p>Now all I have to do to add a log line is to hit space+t and I will be on a line that already has the date and time. So I can directly start typing the event that I want to log. Making a log entry now usually only takes about three seconds as the date/time is automatically inserted and the event is usually suggested too after I type the first few characters.</p>

<p>After dabbling with freeform log events for a while, I wanted multiple levels of an observation. So instead of</p>

<p>
2020-06-01 18:41 Meeting with Hugo Mayer
</p>

<p>I started writing:</p>

<p>
2020-06-01 17:00 Meeting: Hugo Mayer
</p>

<p>So the colon has a special meaning:</p>

<p>
5: A colon begins another level of the observation
</p>

<p>I use this for measurements all the time:</p>

<p>
2020-06-02 11:00 Temperature: 22°C<br>
2020-06-02 11:00 Humidity: 43%
</p>

<p>And also for subjective measurements:</p>

<p>
2020-06-02 12:15 Mood: Very Good<br>
2020-06-04 13:20 Sore eyes: Medium<br>
</p>

<p>There can be multiple colons in one line. For example, the following would log that I had sore eyes and felt it mostly in my left eye:</p>

<p>
2020-06-04 13:20 Sore eyes: Medium: Mostly Left
</p>

<h2>A/B Tests</h2>

<p>What about A/B tests? Maybe it is not the pizza that causes headaches the next day, but that eating pizza and having a headache the next day have the same root cause, like not eating enough for breakfast?</p>

<p>Here comes the question mark:</p>

<p>
2020-06-05 22:30 Eat: Pizza? Yes
</p>

<p>A question mark marks a coin flip. So if I say to myself, "I am hungry, but should I really eat pizza at this time?" then I write down the thing I am about to do and add a question mark. This means I will now have to do a coin flip and decide between Yes and No. Yes means the event left to the coin flip took place. No means it did not.</p>

<p>To make this easier, I added this shortcut to my bashrc:</p>

<p>
alias coindecide='if (( RANDOM % 2 == 0 )); then echo Yes; else echo No; fi'
</p>

<p>So now I can just type "coindecide&lt;enter&gt;" to get a decision by coin flip. And since bash has autocompletion, I usually just type "coi&lt;tab&gt;&lt;enter&gt;" and have my decision. Super fast.</p>

<p>I could have put a coindecide macro into Vim, of course. But it is a nice tool in many situations, not only when writing. So I added it to the shell instead.</p>

<h2>Additional information</h2>

<p>To be able to put more info into the log even in lines structured according to the aforementioned six rules, I use parenthesis:</p>

<p>
2020-07-08 12:30 Take a walk? Yes (60min)
</p>



<p>
7: Parenthesis can be used to add additional information
</p>

<h2>Order</h2>

<p>Since I want a human-friendly format, the time is only tracked by the minute. This means that the order of events that are happening within the same minute is defined by their order in the log.
This is important when using tools on the log to convert, filter, or merge it with other logs. Or when importing it into a database. Order always has to be preserved.</p>

<p>
8: Order is important
</p>

<p>So these are the eight rules I have been developing over the last five months of self-tracking:</p>

<p>
1: Every line starts with the date and time<br>
2: Everything until [^a-z ] describes an observation<br>
3: Uppercase characters equal their lowercase counterparts<br>
4: _ equals space<br>
5: A colon begins another level of the observation<br>
6: A question mark indicates a coin flip<br>
7: Parenthesis can be used to add more information<br>
8: Order is important<br>
</p>

<p>
 Discussions about this text are taking place on <a href="https://twitter.com/marekgibney/status/1307690563198750723" target="_blank">Twitter</a> and <a href="https://lobste.rs/s/ri5utx/syntax_for_self_tracking" target="_blank">Lobste.rs</a>
</p></div>


</div></div>]]>
            </description>
            <link>https://www.gibney.de/a_syntax_for_self-tracking</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534179</guid>
            <pubDate>Sun, 20 Sep 2020 14:16:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python Web Assembly Playground]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24534088">thread link</a>) | @lanecwagner
<br/>
September 20, 2020 | https://app.qvault.io/playground/python | <a href="https://web.archive.org/web/*/https://app.qvault.io/playground/python">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://app.qvault.io/playground/python</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534088</guid>
            <pubDate>Sun, 20 Sep 2020 14:00:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why explore Venus, besides finding life]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24533926">thread link</a>) | @uncertainquark
<br/>
September 20, 2020 | https://jatan.space/why-explore-venus/ | <a href="https://web.archive.org/web/*/https://jatan.space/why-explore-venus/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div><figure><img loading="lazy" width="720" height="720" src="https://i2.wp.com/jatan.space/wp-content/uploads/2020/05/venus-visible-radar.jpg?resize=720%2C720&amp;ssl=1" alt="" srcset="https://i2.wp.com/jatan.space/wp-content/uploads/2020/05/venus-visible-radar.jpg?w=720&amp;ssl=1 720w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/05/venus-visible-radar.jpg?resize=200%2C200&amp;ssl=1 200w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/05/venus-visible-radar.jpg?resize=400%2C400&amp;ssl=1 400w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"><figcaption>Left – Venus as it would approximately look to the human eye, imaged by NASA’s Mariner 10 spacecraft (<a href="https://www.planetary.org/multimedia/space-images/venus/global-view-of-venus-from.html">full globe view</a>), Right – Radar image (false-color) of Venus’ surface taken by NASA’s Magellan orbiter (<a href="https://photojournal.jpl.nasa.gov/catalog/PIA00104">full globe view</a>).</figcaption></figure></div>



<h3>Why study Venus?</h3>



<p>The Sun rises in the east and sets in the west, except if you are on Venus. That’s because it rotates on its axis in the opposite direction from other planets, and nobody knows why. This is just one of the many mysteries of Venus, a cloud-shrouded hellscape with an atmosphere 50 times denser than Earth’s, and average surface temperatures of 470 degrees Celsius — hot enough to melt lead.</p>



<p>Venus is currently inhospitable, but it wasn’t always that way. Past missions there have observed <a href="https://www.semanticscholar.org/paper/Felsic-highland-crust-on-Venus-suggested-by-Galileo-Hashimoto-Roos-Serote/e251f805ea0cc28680788f0dc865acde415cda38">granite-like rocks</a> on the surface, which require abundant water to form. In the early solar system when the Sun was cooler, scientists think Venus may have had <a href="https://www.nasa.gov/feature/goddard/2016/nasa-climate-modeling-suggests-venus-may-have-been-habitable">liquid water on the surface for two billion years</a>—far longer than Mars, which may have had liquid water for <a href="https://www.planetary.org/blogs/guest-blogs/2019/mars-water-stable-paradox.html">300 million years</a>. Water is the key to life as we know it, so did Venus once have life?</p>



<div><figure><img loading="lazy" width="4096" height="4096" src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/ancient-venus-water-oceans.jpg?fit=1024%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/ancient-venus-water-oceans.jpg?w=4096&amp;ssl=1 4096w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/ancient-venus-water-oceans.jpg?resize=1024%2C1024&amp;ssl=1 1024w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/ancient-venus-water-oceans.jpg?resize=200%2C200&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/ancient-venus-water-oceans.jpg?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/ancient-venus-water-oceans.jpg?resize=1536%2C1536&amp;ssl=1 1536w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/ancient-venus-water-oceans.jpg?resize=2048%2C2048&amp;ssl=1 2048w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/ancient-venus-water-oceans.jpg?resize=1200%2C1200&amp;ssl=1 1200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/ancient-venus-water-oceans.jpg?resize=800%2C800&amp;ssl=1 800w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/ancient-venus-water-oceans.jpg?resize=400%2C400&amp;ssl=1 400w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/ancient-venus-water-oceans.jpg?w=2400&amp;ssl=1 2400w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/ancient-venus-water-oceans.jpg?w=3600&amp;ssl=1 3600w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption>This artist’s rendering shows what Venus might have looked like in the past, boasting a global ocean. <a href="https://www.nasa.gov/feature/goddard/2016/nasa-climate-modeling-suggests-venus-may-have-been-habitable">Credit: NASA</a></figcaption></figure></div>



<pre><strong>The hottest planet</strong>
Venus is the hottest planet in the solar system, even though Mercury is twice as close to the Sun and receives four times more solar energy. The reason? Mercury has no atmosphere, whereas Venus’ thick, carbon dioxide atmosphere creates a runaway greenhouse effect, trapping in heat. That’s also why unlike Mercury whose nightside can get as cold as -220 degrees Celsius, Venus continues to be equally hot even at night.</pre>



<p>How did Venus transform from a potentially habitable world to its current hellish state? Studying Venus helps scientists get answers to questions like that while simultaneously gaining insights into what makes Earth a haven for life. Scientists also use Venus as a reference to understand how Earth-sized planets around other stars evolve and what conditions might exist there. To that end, Venus also helps scientists model Earth’s climate, and serves as a cautionary tale on how dramatically a planet’s climate can change.</p>



<p>There is also a <a href="https://www.liebertpub.com/doi/10.1089/ast.2017.1783">slim chance microbial life currently exists</a> in Venus’s upper atmosphere, where mysterious dark patches absorb more than half the solar energy the planet receives. This region, approximately 50 kilometers above the surface, has Earth-like temperatures and pressures. In September 2020, scientists announced that Earth-based radio telescopes have <a href="https://ras.ac.uk/news-and-press/news/hints-life-venus">detected phosphine molecules</a> in this region, which could be a biosignature of microbial life. Venus is on average almost three times closer to Earth than Mars, often shining as a bright evening star in our skies. Have we been looking for life on the wrong planet?</p>



<h3>A brief history of Venus exploration</h3>



<p>Venus was the first planet to be visited by a spacecraft. In 1962, NASA’s Mariner 2 flew by the planet and discovered it was a hot world with no self-generated magnetic field. The Soviet Union became the world leader in early Venus exploration after that.</p>



<p>The Soviet Union sent the Venera 4, 5 and 6 spacecraft to explore Venus’ atmosphere in the same decade. As the probes descended, their instruments revealed the dense atmosphere to contain 96% carbon dioxide and atmospheric pressures to exceed Earth’s by 50 to 100 times, depending on the altitude.</p>



<p>The Soviet Union then went on to successfully land ten spacecraft on Venus from 1970 to 1985 – the Venera landers labelled 7 through 14 and Vega 1 &amp; 2. During their atmospheric descent, their instruments measured temperature and pressure profiles, elemental makeup of Venus’ clouds and their layering. After landing, these spacecraft lasted from a few tens of minutes to two hours at best under the harsh conditions. During that time, they took the first and the only images of Venus’ surface and also determined the chemical composition of nearby rocks. To this day, the Soviet Union remains the only nation to have landed spacecraft on the surface and transmitted both data and images back to Earth.</p>



<div><figure><img loading="lazy" width="960" height="481" src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/venus-surface-venera-13.jpg?resize=960%2C481&amp;ssl=1" alt="" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/venus-surface-venera-13.jpg?w=960&amp;ssl=1 960w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/venus-surface-venera-13.jpg?resize=200%2C100&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/venus-surface-venera-13.jpg?resize=768%2C385&amp;ssl=1 768w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"><figcaption>Composite views created from images of Venus’ surface taken by the Soviet Venera 13 Venus lander. Credit: Venera team/Don P. Mitchell.</figcaption></figure></div>



<p>Due to thick clouds, it is impossible to see Venus’ surface without radar. NASA’s Magellan orbiter, launched in 1990, used radar to map Venus’ surface at the highest resolution to date. Magellan revealed that all of the planet’s impact craters are formed <a href="https://www.semanticscholar.org/paper/VOLCANISM-AND-TECTONICS-ON-VENUS-Nimmo-Mckenzie/ca688453629b3971152c65443da14675fcbe3cf8">within the last 700 million years</a>. This implies that Venus’ surface was completely reshaped by a worldwide volcanic event in its recent geologic past—but <a href="https://www.planetary.org/blogs/guest-blogs/the-venus-controversy.html">exactly what happened is still up for debate</a>.</p>



<p>Magellan also found no sign of plate tectonics. On Earth, plate tectonics is a process in which sections of the planet’s outer crust glide over the mantle—the rocky inner layer above the core—allowing heat to escape through volcanism. Since we think Venus’s interior is similar to Earth’s, the lack of plate tectonics means that volcanoes on Venus must work differently than on Earth.</p>



<figure><img loading="lazy" width="1200" height="675" src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/venus-surface-volcano-crater-magellan-radar.jpg?resize=1200%2C675&amp;ssl=1" alt="" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/venus-surface-volcano-crater-magellan-radar.jpg?w=1249&amp;ssl=1 1249w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/venus-surface-volcano-crater-magellan-radar.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/venus-surface-volcano-crater-magellan-radar.jpg?resize=200%2C113&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/venus-surface-volcano-crater-magellan-radar.jpg?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/venus-surface-volcano-crater-magellan-radar.jpg?resize=1200%2C675&amp;ssl=1 1200w" sizes="(max-width: 1200px) 100vw, 1200px" data-recalc-dims="1"><figcaption>This 3D image of Venus’ surface was generated using radar data from NASA’s Magellan spacecraft. The 3-kilometer-tall volcano Gula Mons can be seen on the horizon, along with the 48-kilometer-wide Cunitz crater at near-center. <a href="https://photojournal.jpl.nasa.gov/catalog/PIA00233">Credit: NASA</a></figcaption></figure>



<p>The European Space Agency launched the Venus Express orbiter in 2006. By observing <a href="http://www.esa.int/Science_Exploration/Space_Science/Venus_Express/Hot_lava_flows_discovered_on_Venus">hotspots on the surface</a> and <a href="http://www.esa.int/Science_Exploration/Space_Science/Venus_Express/Have_Venusian_volcanoes_been_caught_in_the_act">changing sulfur dioxide levels</a> in the atmosphere over six years, the spacecraft collected the best evidence yet of active volcanism on Venus. Venus Express also discovered granite-like rocks across the planet that require abundant liquid water to form, solidifying the idea of the planet having past oceans.</p>



<p>Japan’s Akatsuki spacecraft is the only probe currently orbiting Venus. It <a href="https://www.bbc.com/news/science-environment-38638067">discovered a giant stationary wave</a> in Venus’ atmosphere that stretches across the planet, the largest of its kind in the solar system. Akatsuki continues to study Venus’s atmosphere in frequencies of light that human eyes cannot see, specifically ultraviolet, infrared, microwave and radio, so as to paint a complete picture of happenings on Venus.</p>



<h3>The road ahead</h3>



<p>Only three missions have visited Venus in the past 30 years, and many scientists feel <a href="https://www.planetary.org/blogs/guest-blogs/2020/the-next-10-years.html">new missions are long overdue</a>. The idea that Venus used to be at least as habitable as Mars and for a much longer period warrants further exploration and can have profound implications. Thanks to technological advancements in the last two decades, we can now unravel many of Venus’ mysteries.</p>



<p>Precise atmospheric measurements with a probe could test the hypothesis of microbial life in Venus’ upper atmosphere. Atmospheric probes would also analyze the extent that water may have existed on the surface, what the planet’s atmosphere was like, and how it changed into its present-day state. A spacecraft with a higher-resolution radar could help us solve the mystery of how Venus’s surface changed within the last billion years.</p>



<p>India aims to launch a Venus orbiter called Shukrayaan in 2023 equipped with a radar and infrared camera to map the surface. The spacecraft has a total of 12 instruments, and India’s space agency ISRO has <a href="https://www.isro.gov.in/sites/default/files/ao_venus.pdf">called for instrument proposals</a> in which scientists from international space agencies, including NASA, are expected to participate.</p>



<p>In February 2020 <a href="https://www.nasa.gov/press-release/nasa-selects-four-possible-missions-to-study-the-secrets-of-the-solar-system">NASA announced the selection of 4 mission concepts</a> that are under consideration to fly as part of the agency’s low-cost Discovery program. Two of these are Venus missions, DAVINCI+ and VERITAS.</p>



<p>DAVINCI+ consists of an orbiter and an atmospheric descent probe. The probe would make high precision measurements of trace gases in Venus’ atmosphere, helping firmly determine how much water Venus’ oceans had and how long they existed.</p>



<p>VERITAS will orbit Venus with a state-of-the-art radar and map the entire planet up to 100 times higher resolution than Magellan. This would give scientists a better handle on Venus’ geology and evolution and also reveal why the planet lacks large-scale plate tectonics.</p>



<p>Scientists hope that results from all these future orbiters will pave the way for renewed surface exploration of Venus, including roving platforms built specifically to endure the harsh environment.</p>



<hr>



<p><em>Originally published at <a href="https://www.planetary.org/explore/space-topics/venus/venus.html">The Planetary Society</a>.</em></p>

</div></div>]]>
            </description>
            <link>https://jatan.space/why-explore-venus/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533926</guid>
            <pubDate>Sun, 20 Sep 2020 13:31:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using QEMU to Create a Ubuntu 20.04 Desktop VM on macOS]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24533742">thread link</a>) | @arthurk
<br/>
September 20, 2020 | https://www.arthurkoziel.com/qemu-ubuntu-20-04/ | <a href="https://web.archive.org/web/*/https://www.arthurkoziel.com/qemu-ubuntu-20-04/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <time datetime="2020-09-20">September 20, 2020</time>
<p>In this blog post we’re going to create a Ubuntu 20.04 VM using <a href="https://www.qemu.org/">QEMU</a> on MacOS.</p>
<p><img src="https://www.arthurkoziel.com/qemu-ubuntu-20-04/ubuntu-20-04-with-qemu.png" alt="A picture of the Ubuntu 20.04 Desktop"></p>
<p>QEMU is a hardware emulator which can make use of different accelerators when running VMs. The most popular accelerator is <a href="https://www.linux-kvm.org/page/Main_Page">KVM</a> which is built into the Linux kernel and allows Linux hosts to run VMs with native performance.</p>
<p>Using QEMU on macOS used to be very slow as no accelerator was available. This changed 2 years ago when the project <a href="https://wiki.qemu.org/ChangeLog/2.12">added support</a> for the macOS native hypervisor with Hypervisor.framework (HVF) as an accelerator.</p>
<p>Before we begin with the setup I assume that the <a href="https://releases.ubuntu.com/20.04/">Ubuntu 20.04 Desktop ISO</a> has been downloaded in the current working directory.</p>
<h2 id="qemu-installation">QEMU Installation</h2>
<p>We can use Homebrew to install QEMU. The version we’re using in this tutorial is 5.1.0:</p>
<pre><code>$ brew install qemu

qemu-system-x86_64 --version
QEMU emulator version 5.1.0
Copyright (c) 2003-2020 Fabrice Bellard and the QEMU Project developers</code></pre>
<p>It will pull in a few dependencies (the package depends on 14 other packages) and the installation can take a few minutes.</p>
<h2 id="create-the-disk-image">Create the disk image</h2>
<p>Once the installation is done, we can create the disk image that we’re going to install Ubuntu on.</p>
<p>We’re using the QCOW2 format to create a 20GB image. This can be resized later on if needed. The Ubuntu installation took around 5GB of space when I installed it.</p>
<pre><code>qemu-img create -f qcow2 ubuntu-20.04.1-desktop-amd64.qcow2 20G</code></pre>
<h2 id="boot-machine-with-ubuntu-iso-mounted">Boot machine with Ubuntu ISO mounted</h2>
<p>We can now boot up the machine with the Ubuntu ISO attached as a</p>
<p>In this step we boot up the machine with the Ubuntu ISO mounted in the CD drive:</p>
<pre><code>qemu-system-x86_64 \
    -machine type=q35,accel=hvf \
    -cpu host \
    -smp 2 \
    -hda ubuntu-20.04.1-desktop-amd64.qcow2 \
    -cdrom ./ubuntu-20.04.1-desktop-amd64.iso \
    -m 4G \
    -vga virtio \
    -usb \
    -device usb-tablet \
    -display default,show-cursor=on</code></pre>
<p>The options are:</p>
<ul>
<li><code>-machine</code>: The emulated machine and the accelerator. q35 is the newest machine type and HVF is the macOS native hypervisor.</li>
<li><code>-cpu</code>: The CPU architecture. The value <code>host</code> will use the HVF processor with all supported host features</li>
<li><code>-smp</code>: Number of CPUs to use</li>
<li><code>-m</code>: Amount of memory to use</li>
<li><code>-hda</code>: Disk drive (the one we created earlier)</li>
<li><code>-cdrom</code>: The ISO image to put into the CD drive</li>
<li><code>-vga</code>: The graphic card to use. I found <code>virtio</code> (based on <a href="https://virgil3d.github.io/">Virgil</a> to have the best performance</li>
<li><code>-usb</code>: Enable USB host controller</li>
<li><code>-device</code> Adding a “usb-tablet” as an input device. I’m running this on a laptop and without this setting the mouse did not work.</li>
<li><code>-display</code>: To show the mouse cursor (disabled by default)</li>
</ul>
<p>During testing I had problems with the Linux kernel as it would panic during the boot process. The issue was the <code>-cpu host</code> parameter. I fixed it by specifying the CPU architecture manually (see <code>qemu-system-x86_64 -cpu help</code> for a list of all available architectures).</p>
<p>My machine has an IvyBridge processor (Core i7):</p>
<pre><code>$ sysctl -n machdep.cpu.brand_string

Intel(R) Core(TM) i7-3740QM CPU @ 2.70GHz</code></pre>
<p>And using <code>-cpu IvyBridge</code> would fail. However when using <code>-cpu Nehalem</code> (<a href="https://en.wikipedia.org/wiki/List_of_Intel_CPU_microarchitectures">also an i7 CPU</a>) everything worked well.</p>
<p>Now after the machine is booted up the Ubuntu installer will run. Follow the installation steps and don’t restart the VM at the end of the installation, instead shut it down by stopping the qemu process with CTRL-C on the host.</p>
<h2 id="boot-without-iso-mounted">Boot without ISO mounted</h2>
<p>When running the VM we don’t need the Ubuntu ISO mounted and can remove it by leaving out the <code>-cdrom</code> option:</p>
<pre><code>qemu-system-x86_64 \
    -machine type=q35,accel=hvf \
    -cpu host \
    -smp 2 \
    -hda ubuntu-20.04.1-desktop-amd64.qcow2 \
    -m 4G \
    -vga virtio \
    -usb \
    -device usb-tablet \
    -display default,show-cursor=on</code></pre>
<h2 id="conclusion">Conclusion</h2>
<p>In my experience QEMU is faster, more responsive and uses less CPU/RAM than VirtualBox. I didn’t have to configure any display scaling for HiDPI screens as it worked out of the box. The only thing I’m missing are shared clipboards and drag-and-drop of files (which are available when installing the VirtualBox Guest Additions).</p>
    </article></div>]]>
            </description>
            <link>https://www.arthurkoziel.com/qemu-ubuntu-20-04/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533742</guid>
            <pubDate>Sun, 20 Sep 2020 12:58:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SMAT – The Social Media Analysis Toolkit]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24533674">thread link</a>) | @stareatgoats
<br/>
September 20, 2020 | https://www.smat-app.com/timeline?searchTerm=Hacker%20News&startDate=2020-08-20&endDate=2020-09-20&websites=twitter,reddit,4chan,8kun&aggRedditBy=author&numberOf=10&interval=day&limit=1000&changepoint=false | <a href="https://web.archive.org/web/*/https://www.smat-app.com/timeline?searchTerm=Hacker%20News&startDate=2020-08-20&endDate=2020-09-20&websites=twitter,reddit,4chan,8kun&aggRedditBy=author&numberOf=10&interval=day&limit=1000&changepoint=false">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.smat-app.com/timeline?searchTerm=Hacker%20News&amp;startDate=2020-08-20&amp;endDate=2020-09-20&amp;websites=twitter,reddit,4chan,8kun&amp;aggRedditBy=author&amp;numberOf=10&amp;interval=day&amp;limit=1000&amp;changepoint=false</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533674</guid>
            <pubDate>Sun, 20 Sep 2020 12:41:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Interactive tutorial for learning Git's internals]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24533602">thread link</a>) | @chrisparnin
<br/>
September 20, 2020 | https://docable.cloud/chrisparnin/examples/tutorials/Git.md | <a href="https://web.archive.org/web/*/https://docable.cloud/chrisparnin/examples/tutorials/Git.md">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main" id="main">

        <!-- Display major errors here -->
        


        

        <!-- style="flex: 1;" -->
        <div>
            <!-- Rendered notebook content -->
            <!--
setup: 
  docker:
    image: git_workshop
-->
<p><img src="https://cloud.githubusercontent.com/assets/742934/15635543/d1044ff6-25ae-11e6-9680-077830cff8f5.png" alt="image"></p>
<p>Have you ever wondered how git worked <em>inside</em>? Here’s a chance to interactively play around with a few git commands that will help reveal the inner workings of git, itself!</p>
<p>Just click on the “Run” button in each cell, and see the result of the command, below. Some command results can be clicked on to reveal a few more details.</p>
<p><img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/docable-click.gif" alt="docable-click"></p>
<blockquote>
<p>See how this tutorial was built from simple markdown with <a href="https://github.com/ottomatica/docable-notebooks">docable notebooks</a>!</p>
</blockquote>
<h2 id="understanding-git-internals">Understanding Git Internals</h2>
<blockquote>
<p>By <a href="https://stolee.dev/">Derrick Stolee</a>, git core contributor, adapted into interactive notebook by <a href="http://chrisparnin.me/">Chris Parnin</a>.</p>
</blockquote>
<p>What better way to understand git, then check out git itself. </p>
<p><em>Note:</em> We have already run this step for you! Otherwise, this might take a while!</p>
<pre><code>git <span>clone</span> https://github.com/git/git</code></pre><p>We’ll be working inside the git/ directory set our working state to v2.23.0.</p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-failed_when="exitCode!=0" id="9a2cc51c-a60e-4ad3-a153-8628e768a422"><code><span>cd</span> git
git reset --hard v2.23.0</code></pre></div></div><h3 id="gits-object-model-content-addressable-data-store">Git’s Object Model: Content-Addressable Data Store.</h3>
<p><img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/git-object-model.png" alt="git object model"></p>
<ul>
<li>Every object has a SHA-1 hash: 40 hex characters.</li>
<li>Given 40 hex characters, we can find the unique object with that hash.</li>
</ul>
<p>Let’s examine a single commit.</p>
<h3 id="object-types-blobs-trees-commits">Object Types: Blobs, Trees, Commits</h3>
<p>We will use the <code>git cat-file</code> command to help us search for objects inside the store.
If we provide git with a partial hash, it will attempt to find a unique match, and if it is unable to, it will provide a list of those that did match.</p>
<h4 id="blobs">Blobs</h4>
<p>Let’s examine a <strong>blob</strong> object. A blob contains <em>file contents</em>. 
<img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/git-blob.png" alt="img"></p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="git" data-highlight="{&quot;word&quot;:&quot;Here are the topics that have been cooking&quot;,&quot;title&quot;:&quot;Note: the file name is not part of the object! It is just the text or binary contents.&quot;}" id="c9d943a4-89a4-440b-bb00-8932f83fc9a4"><code>git cat-file -p 5fa073a885</code></pre></div></div><h4 id="trees">Trees</h4>
<p>Let’s examine a <strong>tree</strong> object. A tree contains <em>folder contents</em>. 
<img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/git-tree.png" alt="img"></p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="git" data-block="{&quot;word&quot;:&quot;CodingGuidelines&quot;,&quot;rows&quot;:8,&quot;title&quot;:&quot;A tree can contain blobs and other trees. Notice that RelNotes is another tree with additional folder content.&quot;}" id="f0a05c07-9e6d-405f-a8be-339505bda61e"><code>git cat-file -p 5fa02bff4e</code></pre></div></div><p>Example representation of folder contents contained by a tree: </p>
<p><img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/git-tree-folder.png" alt="img"></p>
<h4 id="commits">Commits</h4>
<p>Perhaps one of the most important type of object inside the object model is a commit. A <strong>commit</strong> contains many things:</p>
<ul>
<li>A root <strong>tree</strong></li>
<li>A list of <strong>parent commits</strong></li>
<li>A commit message</li>
<li>An author name, email, time.</li>
<li>A committer name, email, time.</li>
</ul>
<p><img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/git-commit.png" alt="git commit"></p>
<p>Let’s examine an example commit.</p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="git" data-highlight="{&quot;word&quot;:&quot;committer&quot;,&quot;title&quot;:&quot;A committer can differ from an author, for example, a committer may be merging a pull request from another author.&quot;}" id="dfa324d6-4a4a-478c-be19-187c588497cb"><code>git cat-file -p 5fa00a4dcf</code></pre></div></div><p>We can examine the commit graph (but only the first part!).</p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="git" data-tty="true" id="ce96bf01-6d68-4680-b521-1be6ae58c542"><code>PAGER=<span>'head -n 80'</span> git <span>log</span> --graph --oneline</code></pre></div></div><h4 id="diffs">Diffs</h4>
<p>Diffs are not part of the object model!</p>
<blockquote>
<p><strong>Commits are NOT diffs</strong></p>
</blockquote>
<p>Instead, diffs are dynamically calculated from the commit graph inside the object store. For example, even object attributes, such as <em>file renames</em> are not represented inside the datastore and must be calculated dynamically.</p>
<p>Let’s examine a diff.</p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="git" id="09df604a-8868-46f6-9d51-e677f9e8ca37"><code>git diff --raw v2.22.0 v2.23.0</code></pre></div></div><h4 id="merkle-trees">Merkle Trees</h4>
<p>To enable efficient representation and fast computations of git operations, <em>merkle trees</em> provide forward references within the graph to blobs.</p>
<p><img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/git-merkle-tree.png" alt="merkle-tree"></p>
<h3 id="branches">Branches</h3>
<p><em>Branches</em> are simply pointers to commits. <em>Tags</em> are pointers to anything (commits, trees, blobs).</p>
<p><img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/git-branches.png" alt="git-branches"></p>
<h4 id="move-between-branches-with-git-switch">Move between branches with git switch</h4>
<p><code>git switch</code> is a new feature in v2.23.0 of git. It essentially replaces and does less work than <code>git checkout</code>. Primarily, <code>git switch</code> will:</p>
<ul>
<li>Change <code>HEAD</code> to point to a new branch.</li>
<li>Updates the working directory to match the commit’s tree.</li>
</ul>
<p>We can switch our branch to the maintenance branch.</p>
<p>Let’s confirm.</p>
<p>We can return to the main branch.</p>
<h2 id="practice-creating-a-repo">Practice: Creating a Repo</h2>
<p>Let’s try the basics. Let’s create a new local git repository.</p>
<p>Create a new directory (Basics) and file (README.md).</p>
<p>We are going to create a new git repository, but maybe not the way you’ve done it before. 
In the next set of commands, we will be working inside the <code>Basics/</code> directory.</p>
<p>This will create a new .git directory to store commits and other objects.</p>
<p>We can quickly inspect the contents of the git’s directory and object store.</p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="Basics" id="c51917a9-a216-45ce-8d5f-5d0ee0b16f75"><code>ls -l .git
<span>echo</span> <span>"objects:"</span>
ls -l .git/objects</code></pre></div></div><p>Before adding a file to the repository, it must first be staged.</p>
<p>We will commit our staged changes into the repository.</p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="Basics" id="aece6e24-add4-4542-837d-8164dcf27cfd"><code>git commit -m <span>"initial commit"</span></code></pre></div></div><p>Nice work!</p>
<h3 id="stage-unstage-and-discard-changes">Stage, unstage, and discard changes</h3>
<p>Changes flow from our working tree, to staging index, and into repository.</p>
<p><img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/git-staging.png" alt="git-staging"></p>
<p><strong>Exercise</strong>: Use the following sets of steps and execute them in any order you wish. Observe what happens to the <em>working tree</em> and <em>index</em>, by running the <code>git status</code> step.</p>
<p>Update the README.md and stage our change.</p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="Basics" data-shell="bash" id="9cf98f67-7f9d-4bfb-a186-73423559b862"><code><span>echo</span> <span>" Update: <span>$(date)</span>"</span> &gt;&gt; README.md
cat README.md
git add README.md</code></pre></div></div><p>View the current state of our <strong>working tree</strong> and <strong>index</strong>.</p>
<p>Unstage file (remove from index), but keep changes in working tree.</p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="Basics" id="da39cc19-87dc-4a44-859f-75ea2d7f5dfc"><code>git restore --staged README.md</code></pre></div></div><p>Discard changes in worktree (we will lose our work!). This will restore changes to both the index and the working tree based on the latest version in the repo.</p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="Basics" id="d7feff84-03f2-4fcd-aae1-9bded6c7d7d1"><code>git restore --<span>source</span>=HEAD --staged --worktree README.md</code></pre></div></div><h3 id="remotes">Remotes</h3>
<p>While having a local git repository is cool, we should connect it to another remote repository. In other words, we have no place to <code>git push</code> to…</p>
<p><img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/git-remote.png" alt="git-remote"></p>
<h4 id="remote-operations">Remote operations</h4>
<ul>
<li>Get new data: <code>git fetch &lt;remote&gt; [branch]</code></li>
<li>Upload your data: <code>git push &lt;remote&gt; &lt;branch&gt;</code></li>
<li>Get new data and merge into working tree: <code>git pull &lt;remote&gt; &lt;refspec&gt;</code></li>
</ul>
<p><em>Hot Take</em>: Avoid <code>git pull</code> on large repositories! You may want to handle merges yourself into your target branch instead of having git mess with your working tree.</p>
<p><strong>Exercise</strong>: Let’s open a terminal and perform the following steps.</p>
<p><em>Note</em>: You must be running local docable server to run these steps.</p>
<p>Windows:</p>
<p>Mac/Linux:</p>
<ol>
<li><p>Create a repo on GitHub (If you are a NCSU student, use GitHub Enterprise: <a href="https://github.ncsu.edu/">https://github.ncsu.edu</a>). </p>
</li>
<li><p>Follow the instructions on GitHub to add a remote url to an <em>existing git repository</em>. Basically, you need to run something like: <code>git remote add origin https://github.com/&lt;user&gt;/&lt;repo&gt;.git</code></p>
</li>
<li><p>Push your changes to GitHub. Verify you can see your updated README.md!</p>
</li>
<li><p>On GitHub, edit the README.md, to say “Hello GitHub!”. Commit the changes on GitHub. Now you have changes in your remote (origin), that are missing on your local copy.</p>
</li>
<li><p>Run <code>git pull</code> and verify you now have the updated changes.</p>
</li>
</ol>
<h2 id="git-branching-playground">Git Branching Playground</h2>
<p>Manipulating the commit graph can get quite complicated! This interactive visualization is very useful for getting a deeper understanding of how operations such as branches, merges, cherry-picking, and more work!</p>
<p>We will solve the “Introduction Sequence” levels in:<br><a href="http://pcottle.github.io/learnGitBranching/">http://pcottle.github.io/learnGitBranching/</a>   </p>
<p><img src="https://cloud.githubusercontent.com/assets/742934/9494425/c4dd4b66-4bd3-11e5-9aac-04bfc8fed771.png" alt="example"></p>
<h2 id="git-configuration-and-security">Git Configuration and Security</h2>
<p>If you want to make sure your commits are properly linked to your GitHub account, make sure you have configured your computer to have your name and email filled out.</p>
<pre><code>$ git config --global user.name "FirstName LastName"
$ git config --global user.email email@example.com</code></pre><p>You might also consider an authenication strategy. If you’re being asked to login everytime your pull/push to your remote repository, you might want to enable caching of your credentials. For example, you could use: </p>
<pre><code>git config --global credential.helper store</code></pre><p>However, this may store your credentials in plain text on your computer. There are other platform-specific credential.helpers that you can use to more securely store your credentials. It is also possible to generate <a href="https://help.github.com/articles/creating-a-personal-access-token-for-the-command-line/">personal access tokens</a> that you can use authenicate instead of a passcode.</p>
<p>An alternative approach is to use sshkeys. In this case, you have a public/private keypair, with the public key stored on GitHub. You then use a <a href="https://help.github.com/articles/which-remote-url-should-i-use/">different url pattern</a> for your commands such as <code>git clone</code>. Instead of the <code>https://</code> prefix, you instead use <code>git@github.com:user/repo.git</code>.</p>
<p>If you are interested in exploring this option: See these guides on GitHub:</p>
<ul>
<li><a href="https://help.github.com/articles/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent/">Generating SSH Key</a></li>
<li><a href="https://help.github.com/articles/adding-a-new-ssh-key-to-your-github-account/">Adding SSH Key to GitHub</a></li>
<li><a href="https://help.github.com/articles/testing-your-ssh-connection/">Testing SSH Connection</a></li>
</ul>

        </div>

        <!--- init and style customization not supported by css -->
        

    </div></div>]]>
            </description>
            <link>https://docable.cloud/chrisparnin/examples/tutorials/Git.md</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533602</guid>
            <pubDate>Sun, 20 Sep 2020 12:25:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Good Quality DOSBox Video Capture]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24533484">thread link</a>) | @susam
<br/>
September 20, 2020 | https://susam.in/blog/good-quality-dosbox-video-capture/ | <a href="https://web.archive.org/web/*/https://susam.in/blog/good-quality-dosbox-video-capture/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>By <b>Susam Pal</b> on 01 Sep 2020</p>
<h2 id="vintage-dos-programs"><a href="#vintage-dos-programs">Vintage DOS Programs</a></h2>

<p>
Once in a while, I fire up one of the vintage DOS games or language
interpreters in DOSBox for nostalgia's sake. I have archived these
vintage programs at <a href="https://github.com/susam/dosage">github.com/susam/dosage</a>.
DOSBox is an emulator program that emulates IBM PC compatible computers
running DOS. Trying my hands on these antiquated DOS programs now evokes
old memories from my childhood days days when I first came across
computers as part of our primary school curriculum.
</p>

<p>
Computers were much simpler in those days. The ones in our school were
IBM PC compatible computers with mostly monochrome displays. A couple of
them had support for a very limited number of colours provided by CGA or
EGA graphics cards. The ability to boot a computer using a
5¼-inch floppy disk containing MS-DOS, load a Logo or BASIC
interpreter, or a computer game from another floppy disk, and then write
some programs or play a few games without any distraction had its own
charm that I find missing from modern day computing.
</p>

<p>
Often while using old DOS programs with DOSBox in this day and age, I
want to take screenshot captures or video captures of the DOSBox
sessions and share them with my friends. In this article, I will explain
how I create good quality screenshot captures and video captures of
DOSBox sessions in formats that I can share with others.
</p>


<h2 id="contents"><a href="#contents">Contents</a></h2>
<ul>
  <li><a href="#vintage-dos-programs">Vintage DOS Programs</a></li>
  <li><a href="#software-versions">Software Versions</a></li>
  <li><a href="#ibm-pc-logo-in-dosbox">IBM PC Logo in DOSBox</a></li>
  <li><a href="#digger-in-dosbox">Digger in DOSBox</a></li>
  <li><a href="#dosbox-screenshot-capture">DOSBox Screenshot Capture</a></li>
  <li><a href="#dosbox-video-capture">DOSBox Video Capture</a></li>
  <li><a href="#dosbox-audio-video-capture">DOSBox Audio/Video Capture</a></li>
  <li><a href="#dosbox-gif-animation">DOSBox GIF Animation</a></li>
  <li><a href="#references">References</a></li>
</ul>


<h2 id="software-versions"><a href="#software-versions">Software Versions</a></h2>

<p>
Since this article involves several pieces of software, some of what is
written here may not hold good in future if the behaviour of any of
these software tools change in future. The list below contains the
versions of all software tools that were used to test the commands
provided in this article:
</p>

<ol>
  <li>macOS High Sierra 10.13.6</li>
  <li>DOSBox 0.74-3</li>
  <li>FFmpeg 4.3.1</li>
  <li>ImageMagick 7.0.10-28
  </li><li>IBM Personal Computer Logo Version 1.00</li>
  <li>Digger (Original PC booter version by Windmill Software)</li>
</ol>

<p>
Note that both Logo and Digger programs in the list above are DOS
programs that were released in 1983. They cannot be run directly on
modern computers but they can be run with DOSBox since it emulates old
IBM PC compatible computers.
</p>


<h2 id="ibm-pc-logo-in-dosbox"><a href="#ibm-pc-logo-in-dosbox">IBM PC Logo in DOSBox</a></h2>

<p>
IBM Personal Computer Logo developed by Logo Computer Systems Inc.
(LCSI) in 1983 was the first piece of software I got introduced to while
learning computers as a kid. I came across it at the age of 8 when I was
in Class 4 and our school had a 5¼-inch floppy disk with IBM PC
Logo on it. As a result, Logo was the first programming language I
learnt in my life. About 20 years later, I would realize that the first
programming language I learnt is a dialect of Lisp. How wonderful!
</p>

<figure id="logo-welcome-screenshot">
  <a href="https://susam.in/files/blog/dosbox-logo-0.png"><img src="https://susam.in/files/blog/dosbox-logo-0.png" alt="A screenshot of IBM Personal Computer Logo with copyright notices of IBM and LCSI, welcome message, and question mark prompt"></a>
  <figcaption>
    Welcome screen of IBM Personal Computer Logo
  </figcaption>
</figure>

<!--
Class Age Year
   KG   4   88
    1   5   89
    2   6   90
    3   7   91
    4   8   92
    5   9   93
    6  10   94
    7  11   95
    8  12   96
    9  13   97
   10  14   98
-->

<p>
If the Logo interpreter program <code>LOGO.COM</code> exists in the
current directory, it can be run with DOSBox using the following
command:
</p>

<pre><code>dosbox LOGO.COM</code></pre>

<p>
One of the things I enjoyed drawing with Logo was a grid of overlapping
circles like this:
</p>

<figure id="logo-program-screenshot">
  <a href="https://susam.in/files/blog/dosbox-logo-1.png"><img src="https://susam.in/files/blog/dosbox-logo-1.png" alt="A grid made with 20 circles along with Logo source code for it"></a>
  <figcaption>
    Grid of circles drawn with IBM Personal Computer Logo
  </figcaption>
</figure>

<p>
Here is the Logo source code for the above output:
</p>

<pre><code>REPEAT 20 [REPEAT 180 [FD 1 RT 2] RT 18]</code>
</pre>


<h2 id="digger-in-dosbox"><a href="#digger-in-dosbox">Digger in DOSBox</a></h2>

<p>
At around the same time I learnt Logo, I also came across Digger, a
computer game for IBM PC developed by Windmill Software in 1983.
</p>

<figure id="digger-welcome-screenshot">
  <a href="https://susam.in/files/blog/dosbox-digger-0.png"><img src="https://susam.in/files/blog/dosbox-digger-0.png" alt="A screenshot of Digger welcome screen with the names and pictures of various game characters with a copyright notice of Windmill Software"></a>
  <figcaption>
    Welcome screen of Digger
  </figcaption>
</figure>

<p>
If the Digger program <code>DIGGER.COM</code> exists in the directory,
it can be run using DOSBox with the following command:
</p>

<pre><code>dosbox DIGGER.COM -c "config -set cpu cycles=500" -machine cga</code>
</pre>

<p>
The <code>-machine cga</code> option emulates a machine with Color
Graphics Adapter (CGA) because Digger requires a machine of this type to
run correctly. The <code>cycles=500</code> configuration option slows
down the speed at which DOSBox emulates instructions in order to emulate
the slow machines of olden days. Without this option, Digger runs too
fast to be able to be conveniently playable.
</p>

<figure id="digger-game-screenshot">
  <a href="https://susam.in/files/blog/dosbox-digger-1.png"><img src="https://susam.in/files/blog/dosbox-digger-1.png" alt="A screenshot of underground maze in the game of Digger"></a>
  <figcaption>
    A game of Digger that has just begun
  </figcaption>
</figure>

<p>
Digger has an excellent gameplay where the player digs through
underground tunnels to pick up emeralds, drop gold bags to release the
gold or squash nobbins and hobbins, collect the released gold to earn
more points, and so on. It uses bright and attractive colours. The music
is great. When Digger was released in 1983, it was quite advanced for
its time.
</p>



<h2 id="dosbox-screenshot-capture"><a href="#dosbox-screenshot-capture">DOSBox Screenshot Capture</a></h2>

<p>
The screenshots above were obtained by running IBM PC Logo and the
original 1983 PC booter version of Digger on DOSBox and then resizing
the screenshots such that their aspect ratio matches the aspect ratio of
old CRT computer monitors.
</p>

<p>
To obtain the screenshots, we first press <kbd>Ctrl</kbd> +
<kbd>F5</kbd> while DOSBox is running. The paths of the screenshots
appear in the console output at the terminal where DOSBox was launched.
For example:
</p>

<pre><samp>Capturing Screenshot to /Users/susam/Library/Preferences/capture/logo_000.png
Capturing Screenshot to /Users/susam/Library/Preferences/capture/logo_001.png</samp>
</pre>

<pre><samp>Capturing Screenshot to /Users/susam/Library/Preferences/capture/digger_000.png
Capturing Screenshot to /Users/susam/Library/Preferences/capture/digger_001.png</samp>
</pre>

<p>
The screenshots obtained in this manner have an aspect ratio of 8:5
which makes the output look stretched horizontally. The old CRT computer
monitors for which these old DOS programs were written had an aspect
ratio of 4:3 instead. This stretched look can be fixed by resizing the
images to an aspect ratio of 4:3. Here are the commands used to fix the
aspect ratio and produce the images:
</p>

<pre><code>convert logo_000.png -sample '1920x1440!' dosbox-logo-0.png
convert logo_001.png -sample '1920x1440!' dosbox-logo-1.png</code>
</pre>
<pre><code>convert digger_000.png -sample '1920x1440!' dosbox-digger-0.png
convert digger_001.png -sample '1920x1440!' dosbox-digger-1.png</code>
</pre>

<!--
According to Screen Resolution Statistics for January 2020 by
w3schools.com, here are the statistics of browser resolutions:

Resolution   %age  Cumulative

Lower         9.0    9.0
1280 x  720   3.9   12.9
1024 x  768   1.4   14.3
1360 x  768   1.0   15.3
1366 x  768  27.6   42.9
1280 x  800   1.8   44.7
1536 x  864   9.8   54.5
1440 x  900   5.6   60.1
1600 x  900   4.1   64.2
1280 x 1024   2.4   66.6
1680 x 1050   2.6   69.2
1920 x 1080  20.3   89.5
1920 x 1200   1.5   91.0
2560 x 1440   1.7   92.7
Other High    7.3  100.0

1440 x 1080 is strictly larger than 55.3% displays.
1600 x 1200 is strictly larger than 66.6% displays.
1920 x 1440 is strictly larger than 91.0% displays.
x 1080 >= 89.5% displays
x 1200 >= 91.0% displays.
x 1440 >= 92.7% displays
-->

<p>
The <code>convert</code> program comes with ImageMagick. There are a few
things worth noting here:
</p>

<ul>
  <li>
    We use the <code>-sample</code> option here to resize the image as
    opposed to using <code>-resize</code> or <code>-scale</code>. The
    <code>-resize</code> or <code>-scale</code> option would smooth the
    jagged edges in the text and graphics by introducing additional
    colours. The <code>-resize</code> option is great for real world
    images where we do want the edges to be smooth while scaling up or
    down but in these screenshots we want to retain the crisp and jagged
    edges that is typical of DOSBox and the old CRT monitors. Therefore
    we use the <code>-sample</code> option that does not introduce any
    new colours. Instead it uses nearest-neighbour interpolation (point
    sampling) to decide the colours of the scaled image.
  </li>
  <li>
    The <code>!</code> flag is used to ignore the aspect ratio of the
    original image. Without this flag, the output files would be
    1920x1200 in size, that is, the largest size with an aspect ratio of
    8:5 that fits in a 1920x1440 box. With this flag, the original
    aspect ratio of 8:5 is ignored and the output is exactly 1920x1440
    in size.
  </li>
</ul>

<p>
By the way, I have donated these images above to Wikimedia Commons under
the Creative Commons Attribution 4.0 International (CC BY 4.0) license:
</p>

<ul>
  <li><a href="https://commons.wikimedia.org/wiki/File:IBM_LCSI_Logo_Welcome_Screen.png">File:IBM_LCSI_Logo_Welcome_Screen.png</a></li>
  <li><a href="https://commons.wikimedia.org/wiki/File:IBM_LCSI_Logo_Circles.png">File:IBM_LCSI_Logo_Circles.png</a></li>
  <li><a href="https://commons.wikimedia.org/wiki/File:Digger_Original_PC_Booter_Version_Welcome_Screen.png">File:Digger_Original_PC_Booter_Version_Welcome_Screen.png</a>
  </li><li><a href="https://commons.wikimedia.org/wiki/File:Digger_Original_PC_Booter_Version_Game.png">File:Digger_Original_PC_Booter_Version_Game.png</a></li>
</ul>

<p>
Having the images on Wikimedia Commons helps to include these
screenshots in the Wikipedia articles on <a href="https://en.wikipedia.org/wiki/Logo_(programming_language)#Implementations">Logo</a>
and <a href="https://en.wikipedia.org/wiki/Digger_(video_game)">Digger</a>.
</p>


<h2 id="dosbox-video-capture"><a href="#dosbox-video-capture">DOSBox Video Capture</a></h2>

<p>
To start capturing video of DOSBox, we press <kbd>Ctrl</kbd> +
<kbd>Alt</kbd> + <kbd>F5</kbd>. The same key combination stops capturing
video. The following output appears in the console output to show where
the video file is saved:
</p>

<pre><samp>Capturing Video to /Users/susam/Library/Preferences/capture/logo_000.avi
Stopped capturing video.</samp>
</pre>

<p>
Say, I want to share a video capture of DOSBox with Logo running on it
with my friends who might be on devices that do not support playing AVI
files. The following FFmpeg command converts the video to a format that
can be distributed widely and played on a wide range of devices and
players:
</p>

<pre><code>ffmpeg -i logo_000.avi -an -c:v libx264 -preset veryslow \
       -crf 17 -vf format=yuv420p,scale=1920:1440:flags=neighbor,fps=30 \
       dosbox-logo.mp4</code>
</pre>

<p>
Here is what the output looks like:
</p>

<figure id="logo-video">
  <video controls="">
    <source src="https://susam.in/files/blog/dosbox-logo.mp4" type="video/mp4">
  </video>
  <figcaption>
    Video capture of IBM Personal Computer Logo
    [<a href="https://susam.in/files/blog/dosbox-logo.mp4">MP4</a>]
  </figcaption>
</figure>

<p>
Let us briefly discuss the various FFmpeg options used here:
</p>

<ul>
  <li>
    <p>
      <code>-i logo_000.avi</code>
    </p>
    <p>
      This, of course, specifies the input file.
    </p>
  </li>
  <li>
    <p>
      <code>-an</code>
    </p>
    <p>
      The audio is silent in this video, so we reduce the file size a
      little by disabling the audio stream with this option. For
      example, without this option the output file size was 317 KB but
      with this option it turned out to be 282 KB.
    </p>
    <p>
      This option should not be specified if the audio stream needs to
      preserved, for example, with DOS games that have audio. We will
      see an example of this in the next section.
    </p>
  </li>
  <li>
    <p>
      <code>-c:v libx264</code>
    </p>
    <p>
      This option selects the x264 encoder to encode the video stream
      into H.264 format. H.264 is also known as MPEG-4 Part 10, Advanced
      Video Coding (MPEG-4 AVC). Currently, it is the most popular
      format for recording, compression, and distribution of video
      content.
    </p>
  </li>
  <li>
    <p>
      <code>-crf 17</code>
    </p>
    <p>
      This option provides visually lossless output, that is, high
      quality output without any loss in quality that can be perceived
      by human eyes. For completely lossless output, we need to use the
      <code>-crf 0</code> option. However, this option sets the video
      profile to <code>High 4:4:4 Predictive</code> which prevents the
      video from playing in some video players. This issue is discussed
      in more detail in the point about <code>yuv420p</code> pixel
      format that comes later in this list. Since <code>-crf 0</code>
      cannot be used due to this issue, the next best option is
      <code>-crf 1</code> which while not completely lossless is much
      better than …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://susam.in/blog/good-quality-dosbox-video-capture/">https://susam.in/blog/good-quality-dosbox-video-capture/</a></em></p>]]>
            </description>
            <link>https://susam.in/blog/good-quality-dosbox-video-capture/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533484</guid>
            <pubDate>Sun, 20 Sep 2020 12:02:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elixir in Production: Plausible Analytics]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24533464">thread link</a>) | @ksec
<br/>
September 20, 2020 | https://serokell.io/blog/elixir-in-production-plausible-analytics | <a href="https://web.archive.org/web/*/https://serokell.io/blog/elixir-in-production-plausible-analytics">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Searching for an open-source Google Analytics alternative?</em></p><p><em>Our guest has your back. Uku Täht is the founder of <a href="https://plausible.io/">Plausible Analytics</a>, an open-source web analytics project built with Elixir. For the last couple of months, his project has attracted a lot of attention through <a href="https://plausible.io/blog/remove-google-analytics">informative blog posts</a> and very positive user reviews.</em></p><p><em>In this interview, we talk about his use of Elixir in production: the benefits, the downsides, the specifics, and why Elixir is so good for projects like Plausible Analytics.</em></p><h2 id="interview-with-uku-t%C3%A4ht">Interview with Uku Täht</h2><p><strong>Could you tell us a little about your company and your role there?</strong></p><p>Plausible Analytics is an open-source project dedicated to making web analytics more privacy-friendly. Our mission is to reduce corporate surveillance by providing an alternative web analytics tool that doesn’t have any links to AdTech.</p><p>I started building Plausible almost two years ago as a side project. I’ve been working on it full-time since the beginning of this year and I’ve also partnered up with Marko who handles the marketing and communication side of things.</p><p><img src="https://serokell.io/files/uj/ujixp3oy.2_(22)_(1).jpg" alt="ujixp3oy.2_(22)_(1).jpg"></p><hr><center><i>Uku Täht, the founder of Plausible Analytics.</i></center><p><strong>What is the key feature or set of features that make using Plausible Analytics a feasible replacement over Google Analytics?</strong></p><p>Google Analytics is overkill for most website owners. Plausible cuts through the noise by presenting all the important website traffic insights and metrics on one single page. You don’t need training or experience in web analytics to get started.</p><p>Keeping the script lightweight is also a priority. Our script is more than 17 times smaller than the Google Analytics script and more than 45 times smaller than the recommended Google Analytics integration using the Google Tag Manager.</p><p>But the biggest reason to choose Plausible is the fact that we’re committed to building open source software. The code behind our service is freely available for anyone. By using Plausible you help build software that everyone can benefit from, not just the corporations.</p><p><strong>How did Elixir as the language of choice work for you when implementing these features?</strong></p><p>I think Elixir is perfect for our use-case. It’s a very productive language once you learn it and it can also handle tons of traffic. Last month we processed 60 million pageviews with absolutely no issues.</p><p>Elixir really shines when you have stateful requirements for the app server. For example, we keep all the active sessions in memory so we don’t have to look a session up from the database on every event. It was a joy to build this part of the app using the GenServer primitives.</p><p><strong>How much did the fact that your product is not only self-hosted but also a SaaS inform your decision to go with Elixir? Did you choose it to scale a SaaS?</strong></p><p>I do believe that using Elixir allows us to make self-hosting a bit easier. In other languages, it’s common to use tools like Redis and external message queues but in Elixir we can often avoid these extra tools and keep the infrastructure requirements simple.</p><p>Plausible is currently designed to run on just one node. Once we start building out support for multi-node deployments, things will get really interesting. I feel like Elixir and the BEAM are designed perfectly for our use-case where we need multiple nodes to share state about visitors sessions.</p><p>Hopefully, we can evolve the architecture without needing extra infrastructure bits and pieces. The goal is to keep the requirements as simple as possible so everyone can run the code on their own server. By relying on BEAM fundamentals, we can probably avoid in-memoy stores, external message queues, and cluster managers altogether, making Plausible easy to self-host.</p><p><strong>Could you tell us more about your deployment: where do you host, how do you deploy, do you use the hot code reload functionality?</strong></p><p>We <a href="https://plausible.io/blog/made-in-eu">recently moved</a> from Heroku to using Digital Ocean. I wanted to eat our own dog food when it comes to the Docker infrastructure we built for self-hosting. So now we have a Digital Ocean droplet pre-configured with Docker and we just pull new images from our <a href="https://hub.docker.com/r/plausible/analytics">DockerHub</a>.</p><p>Since we have a single node deployment, we do have around 30 seconds of downtime on each deploy and we don’t have auto-scaling support. We will deal with these issues as we scale, I just wanted to be upfront about the downsides of how we’re running it.</p><p>We don’t use hot code reloading since it doesn’t play well with the Docker flow.</p><p><strong>What was the biggest challenge while developing Plausible Analytics with Elixir?</strong></p><p>We use a database called Clickhouse for storing our stats. It’s a fairly new and cutting-edge database and it doesn’t have a robust integration with Elixir yet. We use a low-level connection library which gives us random errors sometimes.</p><p>I’m thinking about taking the time to write a proper Ecto adapter for Clickhouse so we can run migrations and have better error handling. It’s easy to complain about the lack of libraries in the Elixir ecosystem but I’d like to do my part in helping the ecosystem thrive.</p><p><strong>Are you satisfied with the result?</strong></p><p>Definitely. If I could go back and do it all over, I would choose the same stack again. Elixir+Phoenix is really fun to work with and it performs even better than I expected.</p><p><strong>Any key takeaways that you would like to share with our audience?</strong></p><p>Elixir is a wonderful language and its ecosystem is really coming along. I would encourage everyone to give it a try and contribute back to the ever-growing list of libraries and frameworks to make it even more powerful.</p><hr><p>I’d like to thank Uku for the interview! If you want to see more examples of Elixir used in production, check out <a href="https://serokell.io/blog/elixir-in-production-venu">our interview</a> with one of the Venu co-founders or read our post about <a href="https://serokell.io/blog/elixir-companies">companies that use Elixir</a>.</p><p>Additionally, if you have your own Elixir in production story to tell (both good and bad), we definitely want to hear it! You are welcome to write to us: <a href="mailto:hi@serokell.io">hi@serokell.io</a>.</p></div></div>]]>
            </description>
            <link>https://serokell.io/blog/elixir-in-production-plausible-analytics</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533464</guid>
            <pubDate>Sun, 20 Sep 2020 11:57:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Revisiting Apple Notes (6): The Protobuf]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24533249">thread link</a>) | @LaSombra
<br/>
September 20, 2020 | https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/ | <a href="https://web.archive.org/web/*/https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody"> <p><strong>TL;DR</strong>: This post explains portions of two protobufs used by Apple, one for the Note format itself and another for embedded objects. More importantly, it explains how you can figure out the structure of protobufs.</p> <!--more--> <h2 id="background">Background</h2> <p>Previous entries in this series covered how to deal with <a href="https://ciofecaforensics.com/2020/01/10/apple-notes-revisited/">Apple Notes</a> and the <a href="https://ciofecaforensics.com/2020/01/13/apple-notes-revisited-easy-embedded-objects/">embedded objects</a> in them, including <a href="https://ciofecaforensics.com/2020/01/14/apple-notes-revisited-embedded-tables/">embedded tables</a> and <a href="https://ciofecaforensics.com/2020/01/20/apple-notes-revisited-galleries/">galleries</a>. Throughout these posts, I have referred to the fact that Apple uses protocol buffers (protobufs) to store the information for both notes and the embedded objects within them. What I have not yet done is actually provide the .proto file that was used to generate the Ruby output, or explained how you can develop the same on your app of interest. If you only care about the first part of that, you can view the <a href="https://github.com/threeplanetssoftware/apple_cloud_notes_parser/blob/master/proto/notestore.proto">.proto file</a> or the <a href="https://github.com/threeplanetssoftware/apple_cloud_notes_parser/blob/master/proto/protobuf_config.py">config</a> I use for <a href="https://github.com/jmendeth/protobuf-inspector">protobuf-inspector</a>. Both of these files are just a start to pull out the important parts for processing and can certainly be improved.</p> <p>As with previous entries, I want to make sure I give credit where it is due. After pulling apart the Note protobuf and while I was trying to figure out the table protobuf, I came across <a href="https://github.com/dunhamsteve">dunhamsteve’s</a> work. As a result, I went back and modified some of my naming to better align to what he had <a href="https://github.com/dunhamsteve/notesutils/blob/master/notes.md">published</a> and added in some fields like version which I did not have the data to discover.</p> <h2 id="what-is-a-protocol-buffer">What is a Protocol Buffer?</h2> <p>To quote directly from <a href="https://developers.google.com/protocol-buffers">the source</a>,</p> <blockquote> <p>Protocol buffers are Google’s language-neutral, platform-neutral, extensible mechanism for serializing structured data – think XML, but smaller, faster, and simpler. You define how you want your data to be structured once, then you can use special generated source code to easily write and read your structured data to and from a variety of data streams and using a variety of languages.</p> </blockquote> <p>What does that mean? It means a protocol buffer is a way you can write a specification for your data and use it in many projects and languages with one command. The end result is source code for whatever language you are writing in. For example, <a href="https://github.com/sballin/alfred-search-notes-app/blob/master/search/proto/notestore.pb.go">Sean Ballinger’s Alfred Search Notes App</a> used my <code>notestore.proto</code> file to compile to Go instead of Ruby to interact with Notes on MacOS. When you use it in your program, the data which you save will be a raw data stream which won’t look like much, but will be intelligable to any code with that protobuf definition.</p> <p>The definition is generally a <code>.proto</code> file which would look something like:</p> <figure><pre><code data-lang="protobuf"><span>syntax</span> <span>=</span> <span>"proto2"</span><span>;</span>

<span>// Represents an attachment (embedded object)</span>
<span>message</span> <span>AttachmentInfo</span> <span>{</span>
   <span>optional</span> <span>string</span> <span>attachment_identifier</span> <span>=</span> <span>1</span><span>;</span>
   <span>optional</span> <span>string</span> <span>type_uti</span> <span>=</span> <span>2</span><span>;</span>
<span>}</span></code></pre></figure> <p>This definition would have just one message type (AttachmentInfo), with two fields (attachment_identifier and type_uti), both optional. This is using the <code>proto2</code> syntax.</p> <h2 id="why-care-about-protobufs">Why Care About Protobufs</h2> <p>Protobufs are everywhere, especially if you happen to be working with or looking at Google-based systems, such as Android. Apple also uses a lot of them in iOS, and for people that have to support both operating systems, using a protobuf makes the pain of maintaining two different code bases slightly less annoying because you can compile the same definition to different languages. If you are in forensics, you may come across something that looks like it isn’t plaintext and discover that you’re actually looking at a protobuf. When it comes specifically to Apple Notes, protobufs are used both for the Note itself and the attachments.</p> <h2 id="how-to-use-a-proto-file">How to Use a .proto file</h2> <p>Assuming you have a <code>.proto</code> file, either from building one yourself or from finding one from your favorite application, you can compile it to your target language using <a href="https://github.com/protocolbuffers/protobuf/releases">protoc</a>. The resulting file can then be included in your project using whatever that language’s include statement is to create the necessary classes for the data. For example, when writing Apple Cloud Notes Parser in Ruby, I used <code>protoc --ruby_out=. ./proto/notestore.proto</code> to compile it and then <code>require_relative 'notestore_pb.rb'</code> in my code to include it.</p> <p>If I wanted instead to add in support for python, I would only have to make this change: <code>protoc --ruby_out=. --python_out=. ./proto/notestore.proto</code></p> <h2 id="how-can-you-find-a-protobuf-definition-file">How Can You Find a Protobuf Definition File?</h2> <p>If you come up against a protobuf in an application you are looking at, you might be able to find the <code>.proto</code> protobuf definition file in the application itself or somewhere on the forensic image. I ended up going through an iOS 13 forensic image earlier this year and found that Apple still had some of theirs on disk:</p> <figure><pre><code data-lang="shell"><span>[</span>notta@cuppa iOS13_logical]<span>$ </span>find | <span>grep</span> <span>'\.proto$'</span>
./System/Library/Frameworks/MultipeerConnectivity.framework/MultipeerConnectivity.proto
./System/Library/PrivateFrameworks/ActivityAchievements.framework/ActivityAchievementsBackCompat.proto
./System/Library/PrivateFrameworks/ActivityAchievements.framework/ActivityAchievements.proto
./System/Library/PrivateFrameworks/CoreLocationProtobuf.framework/Support/Harvest/CLPCollectionRequest.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingDatabaseCodables.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingDomainCodables.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingInvitationCodables.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingCloudKitCodables.proto
./System/Library/PrivateFrameworks/CloudKitCode.framework/RecordTransport.proto
./System/Library/PrivateFrameworks/RemoteMediaServices.framework/RemoteMediaServices.proto
./System/Library/PrivateFrameworks/CoreDuet.framework/knowledge.proto
./System/Library/PrivateFrameworks/HealthDaemon.framework/Statistics.proto
./System/Library/PrivateFrameworks/AVConference.framework/VCCallInfoBlob.proto
./System/Library/PrivateFrameworks/AVConference.framework/captions.proto</code></pre></figure> <p>Some of these are <em>really</em> interesting when you look at them, particularly if you care about their location data and pairing. You don’t even have to have an iOS forensic image sitting around as all of the same files are included in your copy of MacOS 10.15.6, as well, if you run <code>sudo find /System/ -iname "*.proto"</code>. I am not including any interesting snippets of those because they are copyrighted by Apple and I would explicitly note that none are related to Apple Notes or the contents of this post.</p> <p>In general, you should not expect to find these definitions sitting around since the definition file isn’t needed once the code is generated. For more open source applications, you might be interested in some <a href="https://www.google.com/search?q=ext%3Aproto++AND+inurl%3Aproto+AND+message+AND+proto2">Google Dorks</a>, especially when looking at Android artifacts, as you might still find them.</p> <h2 id="how-can-you-rebuild-the-protobuf">How Can You Rebuild The Protobuf?</h2> <p>But what if you can’t find the definition file, how can you rebuild it yourself? This was the most interesting part of rewriting Apple Cloud Notes Parser as I had no knowledge of how Apple typically represents data, nor protobufs, so it was a fun learning adventure.</p> <p>If you have nothing else, the <code>protoc --decode-raw</code> command can give you an intial look at what is in the data, however this amounts to not much more than pretty printing a JSON object, it doesn’t do a great job of telling you you what might be in there. I made heavy use of mildsunrise’s <a href="https://github.com/mildsunrise/protobuf-inspector">protobuf-inspector</a> which at least makes an attempt to tell you what you might be looking at. Another benefit to using this is that it lets you incrementally build up your own definition by editing a file named <code>protobuf_config.py</code> in the protobuf-insepctor folder.</p> <p>For example, below is the output from protobuf-inspector when I ran it on the Gunzipped contents of one of the first notes in my test database.</p> <figure><pre><code data-lang="python"><span>[</span><span>notta</span><span>@</span><span>cuppa</span> <span>protobuf</span><span>-</span><span>inspector</span><span>]</span><span>$</span> <span>python3</span> <span>main</span><span>.</span><span>py</span> <span>&lt;</span> <span>~/</span><span>note_18</span><span>.</span><span>blob</span> 
<span>root</span><span>:</span>
    <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
    <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
        <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
        <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
        <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
            <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>"Pure blob title"</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>2</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>8</span><span>)</span>
                <span>4</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>3</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>10</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>4</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>14</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>10</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                    <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                    <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4294967295</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                    <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                    <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4294967295</span>
            <span>4</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                    <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>bytes</span> <span>(</span><span>16</span><span>)</span>
                        <span>0000</span>   <span>EE</span> <span>FE</span> <span>10</span> <span>DA</span> <span>5</span><span>A</span> <span>79</span> <span>43</span> <span>25</span> <span>88</span> <span>BA</span> <span>6</span><span>D</span> <span>CA</span> <span>E2</span> <span>E9</span> <span>B7</span> <span>EC</span>                          <span>....</span><span>ZyC</span><span>%</span><span>..</span><span>m</span><span>.....</span>
                    <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>24</span><span>)</span>
                    <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>9</span><span>)</span>
            <span>5</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>3</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>)</span>
            <span>5</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>3</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>)</span>
            <span>5</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
          …</code></pre></figure></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/">https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/</a></em></p>]]>
            </description>
            <link>https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533249</guid>
            <pubDate>Sun, 20 Sep 2020 11:02:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Demystifying AWS VPC: A short step-by-step guide to creating a secure AWS VPC]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24533200">thread link</a>) | @dinomad
<br/>
September 20, 2020 | https://scorpil.com/post/aws-vpc/ | <a href="https://web.archive.org/web/*/https://scorpil.com/post/aws-vpc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper"><div id="container"><div><article itemscope="" itemtype="http://schema.org/BlogPosting"><div itemprop="articleBody"><p>VPC is the topic that flies under the radar of many Software Developers, despite being present in every AWS account (well, maybe not for accounts created before 2009… But that’s unlikely). There are a few reasons for this I can think of:</p><ol><li>Big companies have Ops/DevOps/SysAdmin/SRE/Security departments that take care of VPC</li><li>Startups often don’t bother tuning it - everything works with default settings after all</li><li>Networking is complicated and is rarely regarded as fun</li></ol><p>Despite those somewhat justified arguments, most developers that deal with AWS would benefit from digging deeper into VPC setup and it’s configuration. Here are my counterpoints:</p><ol><li>Understanding VPC will help you communicate with; Ops/DevOps/SysAdmin/SRE/Security department much more efficiently</li><li>Everything works by default because everything is open (i.e. unsecure) by default</li><li>Oh but it <em>is</em> fun when you dig deep enough</li></ol><p>So let’s take a careful look into AWS networking from the software engineering perspective. This post requires from the reader a very basic level of familiarity with AWS terminology and networking: you need to understand things like regions and availability zones, and have an idea of what an IP address is.</p><p>To make this post a bit less abstract, we will configure a VPC for a common real-world scenario: distributed application running in two availability zones in a single region consisting of <em>public</em> EC-2 instances serving a web-application and <em>private</em> EC-2 instances hosting a database. You can improve on the architecture by using RDS, adding a loadbalancer, configuring VPC peering with other regions, etc., but we will leave those topics out of the scope of this post - the topic at hand is complicated enough.</p><h3 id="vpc---what-is-it-actually">VPC - what is it actually</h3><p>VPC stands for Virtual Private Cloud, which is a very apt name for a service, unlike some other AWS services I can think of…</p><ul><li>It’s <strong>Virtual</strong>, because like most user-facing things in modern clouds it’s powered by software and not copper. Hence its flexibility: neither you nor AWS will need to plug in a single RJ45 jack to configure it;</li><li>It’s <strong>Private</strong>, because it allows you to carve out your own dedicated space for your cloud infrastructure, walled out and carefully guarded against the dangers of the public internet;</li><li>It’s a <strong>Cloud</strong> because, well, it’s in <strong>AWS</strong>. Or, actually, the better way to think about it as being <em>around</em> AWS.</li></ul><p>In other words, the idea of VPC is to give the user a granular set of controls over what networks requests are allowed to reach its services from the outside, and how to route the requests inside the cloud infrastructure.</p><p>VPC operates on the regional level, meaning that if you want your application to span multiple regions you will need to perform VPC setup for each region separately and configure a VPC peering between them.</p><p>„Fresh“ AWS accounts come with the „default“ VPC preconfigured. You can’t really start, for example, an EC2 instance without any VPC at all, so „default“ VPC is where the new instances get launched into if nothing else is configured (hence the „default“ name). This way amazon manages to balance user-friendliness with flexibility, and that’s why launching an EC2 instance on a „fresh“ account works out of the box. The problem is, however, that the default VPC is not tailored in any way to the needs of your application, so it will allow all incoming traffic to all existing instances. Correctly configured Security Groups help somewhat protect your resources from completely exposing their ports to the public, and to be frank they are often completely sufficient to protect a simple app. However, as the infrastructure grows to accommodate more distinct components and services with complicated access patterns between them, you might want to invest in a more delicate access configuration.</p><p>When creating a custom VPC, there are two important decisions to make:</p><ul><li><p>the size of the VPC: e.g. roughly the number of instances and services you plan to <strong>ever</strong> host inside the VPC. You can’t change this value so make it big. Normally, you wouldn’t go lower than a few thousand addresses.</p></li><li><p>the private IP address range. Instances inside your VPC will receive IP addresses from this address range. Technically, nothing stops you from choosing any IP range you‘d like; however, if your private IP matches the IP of anything on the public internet you won’t be able to access it from within the VPC. For this reason, internal networks are configured to use the subset of one of the following <a href="https://en.wikipedia.org/wiki/Reserved_IP_addresses">reserved</a> IP ranges:</p><ul><li>10.0.0.0-10.255.255.255 - 16 million private IPs in total, the default choice for cloud hosting.</li><li>172.16.0.0 – 172.31.255.255 - almost 1 million IPs</li><li>192.168.0.0 – 192.168.255.255 - 65536 IP‘s, commonly seen on home routers</li></ul></li></ul><p>For our VPC we want to have around 4000 IPs available in 10.x.x.x range. We can’t enter those numbers directly into the VPC configuration, we need to translate them into a <a href="https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing">CIDR</a> notation first. CIDR is just a special format to describe an IP sub-range concisely. You can use IP subnet calculators like <a href="https://cidr.xyz/">cidr.xyz</a> (for IPv4) and <a href="https://cidrv6.xyz/">cidrv6.xyz</a> (for IPv6) to get an intuition into how CIDR works. CIDR value for our example is 10.0.0.0/20.</p><p>We will also enable IPv6 on our VPC. AWS VPC’s use IPv4 as a default addressing format, IPv6 configuration is completely optional. The approach AWS takes to IPv6 routing is quite different than what we used to for IPv4. IPv6 spec defines address range `fc00::/7` to be private but it’s used much less frequently than 10.x.x.x in IPv4. Ipv6 address space is just so large, that AWS simply allocates /56 public address range from his own address pool to your VPC and calls it a day. For this reason, there are no “private” IPv6 addresses in AWS. IPv6 range allocated to every VPC in AWS contains 2^72 addresses, which will be more than enough for *any* VPC ever. Just to put the number into perspective, it’s enough to assign an IPv6 address to each grain of sand on the planet. The ability to assign globally unique addresses to each of your resources makes network architecture in many ways simpler, but at the same time, it makes secure routing configuration even more important. We’ll discuss the reasons for it in more detail in a subnet section.</p><p>As a summary, here’s what our initial VPC configuration looks like:</p><table><thead><tr><th>Parameter</th><th>Value</th></tr></thead><tbody><tr><td>Name</td><td><code>my-secure-vpc</code> (can be anything really)</td></tr><tr><td>CIDR block</td><td><code>10.0.0.0/20</code></td></tr><tr><td>IPv6</td><td>Amazon-provided IPv6 CIDR block (in context of this post let’s assume it’s <code>2001:db8::aa00::/56</code>)</td></tr></tbody></table><h3 id="internet-gateway">Internet Gateway</h3><p>Internet Gateway is an abstract VPC component that represents internet access. The only purpose of the Internet Gateway is to serve as a source/target in the VPC routing configuration. You can’t really configure it in any meaningful way, apart from attaching it to VPC. Internet Gateway is present from the start in the default VPC, but <strong>it won’t be created</strong> for any custom VPC you create. Since we want to be able to access some resources in our VPC from the Internet, we need to create a new Internet Gateway and attach it to our VPC.</p><h3 id="subnets">Subnets</h3><p>The cornerstone of understanding VPC is understanding the concept of subnets. In short, <strong>subnet</strong> is a way of splitting your VPC into small manageable chunks, each of which contains instances and services with a similar type of network access. The „type of network access“ here is up to you to define, but in our case, we want a „private“ subnets for database instances and a „public“ subnet for our webserver. An important detail to remember is that subnets can’t span multiple availability zones. In our case we want our application to work in two different availability zones, this means we need “private” and “public” subnet in each of them, 4 subnets in total. Fortunately, it’s easy to configure functionally similar subnets by attaching them to the same routing table (more about them in the next section).</p><p>Subnets are defined in CIDR notation, which we already discussed in VPC section. AWS makes sure that you will not define two overlapping subnets, because that would break our routing logic. For each subnet, AWS reserves first four and last one IP’s for its internal tasks, so it’s common to configure the size of the subnet of at least /24. This size makes our IP addresses look “cleaner”: we can distinguish subnet based on the value of the second-to-last octet in the IP address. You can play around with a subnet calculator to understand why that’s the case. For IPv6, AWS set subnet size to /64 (not configurable).</p><p>You can configure the subnet to automatically map a public IPv4 address for all instances launched into it - we will need to do this for our public subnet.</p><p>Considering anything above, our 4 new subnets would look something like this:</p><table><thead><tr><th>Name</th><th>CIDR (v4)</th><th>CIDR (v6)</th><th>AZ</th><th>Public IPv4</th></tr></thead><tbody><tr><td>public-a</td><td>10.0.1.0/24</td><td>2001:db8::aa01/56</td><td>a</td><td>✓</td></tr><tr><td>public-b</td><td>10.0.2.0/24</td><td>2001:db8::aa02/56</td><td>b</td><td>✓</td></tr><tr><td>private-a</td><td>10.0.3.0/24</td><td>2001:db8::aa03/56</td><td>a</td><td></td></tr><tr><td>private-b</td><td>10.0.4.0/24</td><td>2001:db8::aa04/56</td><td>b</td><td></td></tr></tbody></table><h3 id="route-tables">Route tables</h3><p><em>Route tables</em> fill the role of the router for your VPC. They allow you to configure destinations for packets depending on their destination IP.</p><p>When you first create a VPC, a single “default” route table is created for you. It contains two rules needed to route private traffic internally within our VPC:</p><table><thead><tr><th>Destination</th><th>Target</th></tr></thead><tbody><tr><td><code>10.0.0.0/20</code></td><td>local</td></tr><tr><td><code>2001:db8::aa01/64</code></td><td>local</td></tr></tbody></table><p>All subnets that we created are by default associated with this route table. It’s a good security practice to make defaults as restricted as possible, so we will keep default route table private. For our public subnet we need to make a new table, and add routes to Internet Gateway there:</p><table><thead><tr><th>Destination</th><th>Target</th></tr></thead><tbody><tr><td><code>10.0.0.0/20</code></td><td>local</td></tr><tr><td><code>2001:db8::aa01/64</code></td><td>local</td></tr><tr><td><code>0.0.0.0/0</code></td><td>internet gateway</td></tr><tr><td><code>::/0</code></td><td>internet gateway</td></tr></tbody></table><p>Now we just associate our public subnet with the new route table to make them <em>really</em> public.</p><h3 id="network-access-control-lists-nacls">Network Access Control Lists (nACL’s)</h3><p><em>nACL’s</em> are an additional level of protection that sits in front of your subnets. You can configure them by adding firewall rules operating on <a href="https://en.wikipedia.org/wiki/OSI_model#Layer_4:_Transport_Layer">OSI layer 4</a>. Default NACL configuration allows all traffic through, and it suits our usecase. If you need to block a particular source IP or destination port …</p></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://scorpil.com/post/aws-vpc/">https://scorpil.com/post/aws-vpc/</a></em></p>]]>
            </description>
            <link>https://scorpil.com/post/aws-vpc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533200</guid>
            <pubDate>Sun, 20 Sep 2020 10:47:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a Ractor-based web server]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24533152">thread link</a>) | @todsacerdoti
<br/>
September 20, 2020 | http://kirshatrov.com/2020/09/08/ruby-ractor-web-server/ | <a href="https://web.archive.org/web/*/http://kirshatrov.com/2020/09/08/ruby-ractor-web-server/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p><span>08 Sep 2020</span></p><p>Ractor, the new concurrency primitive in Ruby, <a href="https://github.com/ruby/ruby/pull/3365" target="_blank">has been merged</a> to the upstream few days ago. I’ve been following that PR and watching the author’s <a href="https://www.youtube.com/watch?v=40t8EPpnujg&amp;list=PLbFmgWm555yZeLpdOLhYwORIF9UjBAFHw&amp;index=17" target="_blank">talk at RubyKaigi</a> (in Japanese, I wasn’t able to find the translated version but it should be available <em>somewhere</em>), which got me excited to try Ractor myself.</p>

<p>A web application server is the first thing that comes to mind when playing with concurrency. On top of that, not too long ago I’ve implemented TCP servers in Rust and Go, so I got curious to write a <strong>simple web server using Ractor</strong>.</p>

<p>Let’s dive in!</p>

<h2 id="whats-in-a-web-server">What’s in a web server?</h2>

<p>A web server is something that accepts a TCP socket, reads from it, parses HTTP headers and responds with HTTP body. It’s a text-based protocol that is easy to implement.</p>

<p>Here’s a sample request (what you’d read from the socket):</p>

<div><div><pre><code>GET / HTTP/1.1
Host: localhost:10000
User-Agent: curl/7.64.1
Accept: */*
</code></pre></div></div>

<p>And a sample response (what you’d write):</p>

<div><div><pre><code>HTTP/1.1 200
Content-Type: text/html

Hello world
</code></pre></div></div>

<p>We will start by grabbing a gist from the <a href="https://blog.appsignal.com/2016/11/23/ruby-magic-building-a-30-line-http-server-in-ruby.html" target="_blank">Building a 30 line HTTP server in Ruby</a> post by AppSignal.</p>

<div><div><pre><code><span>require</span> <span>'socket'</span>
<span>server</span> <span>=</span> <span>TCPServer</span><span>.</span><span>new</span><span>(</span><span>8080</span><span>)</span>

<span>while</span> <span>session</span> <span>=</span> <span>server</span><span>.</span><span>accept</span>
  <span>request</span> <span>=</span> <span>session</span><span>.</span><span>gets</span>
  <span>puts</span> <span>request</span>

  <span>session</span><span>.</span><span>print</span> <span>"HTTP/1.1 200</span><span>\r\n</span><span>"</span>
  <span>session</span><span>.</span><span>print</span> <span>"Content-Type: text/html</span><span>\r\n</span><span>"</span>
  <span>session</span><span>.</span><span>print</span> <span>"</span><span>\r\n</span><span>"</span>
  <span>session</span><span>.</span><span>print</span> <span>"Hello world! The time is </span><span>#{</span><span>Time</span><span>.</span><span>now</span><span>}</span><span>"</span>

  <span>session</span><span>.</span><span>close</span>
<span>end</span>
</code></pre></div></div>

<h2 id="starting-with-ractor">Starting with Ractor</h2>

<p>To get started with Ractor, I recommend to read the <a href="https://github.com/ko1/ruby/blob/dc7f421bbb129a7288fade62afe581279f4d06cd/doc/ractor.md" target="_blank">doc</a> in the ruby repo.</p>

<p>Now, let’s wrap the example from above into Ractors.</p>

<div><div><pre><code><span>require</span> <span>'socket'</span>
<span>server</span> <span>=</span> <span>TCPServer</span><span>.</span><span>new</span><span>(</span><span>8080</span><span>)</span>
<span>CPU_COUNT</span> <span>=</span> <span>4</span>
<span>workers</span> <span>=</span> <span>CPU_COUNT</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>do</span>
  <span>Ractor</span><span>.</span><span>new</span> <span>do</span>
    <span>loop</span> <span>do</span>
      <span># receive TCPSocket</span>
      <span>s</span> <span>=</span> <span>Ractor</span><span>.</span><span>recv</span>

      <span>request</span> <span>=</span> <span>s</span><span>.</span><span>gets</span>
      <span>puts</span> <span>request</span>

      <span>s</span><span>.</span><span>print</span> <span>"HTTP/1.1 200</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"Content-Type: text/html</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"Hello world! The time is </span><span>#{</span><span>Time</span><span>.</span><span>now</span><span>}</span><span>\n</span><span>"</span>
      <span>s</span><span>.</span><span>close</span>
    <span>end</span>
  <span>end</span>
<span>end</span>

<span>loop</span> <span>do</span>
  <span>conn</span><span>,</span> <span>_</span> <span>=</span> <span>server</span><span>.</span><span>accept</span>
  <span># pass TCPSocket to one of the workers</span>
  <span>workers</span><span>.</span><span>sample</span><span>.</span><span>send</span><span>(</span><span>conn</span><span>,</span> <span>move: </span><span>true</span><span>)</span>
<span>end</span>
</code></pre></div></div>

<p>We start the number of workers that equals the number of CPUs and have the main thread to listen to connections on the socket and send accepted connection to a random Ractor. We can validate that it works as expect by making a request with <code>curl</code>.</p>

<p>However, distributing requests among workers using <code>workers.sample</code> is not very efficient. That random worker might still be busy serving the previous request. We’d rather have workers pull from a shared queue where we’d send all requests.</p>

<p>I wanted to make that part better but I didn’t find any Ractor-friendly queue implementation. However, the <a href="https://github.com/ko1/ruby/blob/dc7f421bbb129a7288fade62afe581279f4d06cd/doc/ractor.md" target="_blank">doc</a> suggesting using a pipe like a queue. Let’s try that!</p>

<div><div><pre><code><span>require</span> <span>'socket'</span>

<span># pipe aka a queue</span>
<span>pipe</span> <span>=</span> <span>Ractor</span><span>.</span><span>new</span> <span>do</span>
  <span>loop</span> <span>do</span>
    <span>Ractor</span><span>.</span><span>yield</span><span>(</span><span>Ractor</span><span>.</span><span>recv</span><span>,</span> <span>move: </span><span>true</span><span>)</span>
  <span>end</span>
<span>end</span>

<span>CPU_COUNT</span> <span>=</span> <span>4</span>
<span>workers</span> <span>=</span> <span>CPU_COUNT</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>do</span>
  <span>Ractor</span><span>.</span><span>new</span><span>(</span><span>pipe</span><span>)</span> <span>do</span> <span>|</span><span>pipe</span><span>|</span>
    <span>loop</span> <span>do</span>
      <span>s</span> <span>=</span> <span>pipe</span><span>.</span><span>take</span>

      <span>data</span> <span>=</span> <span>s</span><span>.</span><span>recv</span><span>(</span><span>1024</span><span>)</span>
      <span>puts</span> <span>data</span><span>.</span><span>inspect</span>

      <span>s</span><span>.</span><span>print</span> <span>"HTTP/1.1 200</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"Content-Type: text/html</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"Hello world!</span><span>\n</span><span>"</span>
      <span>s</span><span>.</span><span>close</span>
    <span>end</span>
  <span>end</span>
<span>end</span>

<span>server</span> <span>=</span> <span>TCPServer</span><span>.</span><span>new</span><span>(</span><span>8080</span><span>)</span>
<span>loop</span> <span>do</span>
  <span>conn</span><span>,</span> <span>_</span> <span>=</span> <span>server</span><span>.</span><span>accept</span>
  <span>pipe</span><span>.</span><span>send</span><span>(</span><span>conn</span><span>,</span> <span>move: </span><span>true</span><span>)</span>
<span>end</span>
</code></pre></div></div>

<p>It worked! By using the pipe I was able to make all workers to pull for sockets which improved the load balancing part.</p>

<p>What’s still not great is that there’s nothing that monitors workers in case one of them unexpectedly dies. And similar to <a href="https://github.com/puma/puma/blob/master/docs/architecture.md" target="_blank">Puma’s architecture</a>, it would be more efficient to have a separate thread to wait for sockets to become ready to read before passing them to actual workers.</p>

<p>I was able to move listener into its own Ractor and to make the main thread to watch all Ractors:</p>

<div><div><pre><code><span>require</span> <span>'socket'</span>

<span>pipe</span> <span>=</span> <span>Ractor</span><span>.</span><span>new</span> <span>do</span>
  <span>loop</span> <span>do</span>
    <span>Ractor</span><span>.</span><span>yield</span><span>(</span><span>Ractor</span><span>.</span><span>recv</span><span>,</span> <span>move: </span><span>true</span><span>)</span>
  <span>end</span>
<span>end</span>

<span>CPU_COUNT</span> <span>=</span> <span>4</span>
<span>workers</span> <span>=</span> <span>CPU_COUNT</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>do</span>
  <span>Ractor</span><span>.</span><span>new</span><span>(</span><span>pipe</span><span>)</span> <span>do</span> <span>|</span><span>pipe</span><span>|</span>
    <span>loop</span> <span>do</span>
      <span>s</span> <span>=</span> <span>pipe</span><span>.</span><span>take</span>
      <span>puts</span> <span>"taken from pipe by </span><span>#{</span><span>Ractor</span><span>.</span><span>current</span><span>}</span><span>"</span>

      <span>data</span> <span>=</span> <span>s</span><span>.</span><span>recv</span><span>(</span><span>1024</span><span>)</span>
      <span>puts</span> <span>data</span><span>.</span><span>inspect</span>

      <span>s</span><span>.</span><span>print</span> <span>"HTTP/1.1 200</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"Content-Type: text/html</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"Hello world!</span><span>\n</span><span>"</span>
      <span>s</span><span>.</span><span>close</span>
    <span>end</span>
  <span>end</span>
<span>end</span>

<span>listener</span> <span>=</span> <span>Ractor</span><span>.</span><span>new</span><span>(</span><span>pipe</span><span>)</span> <span>do</span> <span>|</span><span>pipe</span><span>|</span>
  <span>server</span> <span>=</span> <span>TCPServer</span><span>.</span><span>new</span><span>(</span><span>8080</span><span>)</span>
  <span>loop</span> <span>do</span>
    <span>conn</span><span>,</span> <span>_</span> <span>=</span> <span>server</span><span>.</span><span>accept</span>
    <span>pipe</span><span>.</span><span>send</span><span>(</span><span>conn</span><span>,</span> <span>move: </span><span>true</span><span>)</span>
  <span>end</span>
<span>end</span>

<span>loop</span> <span>do</span>
  <span>Ractor</span><span>.</span><span>select</span><span>(</span><span>listener</span><span>,</span> <span>*</span><span>workers</span><span>)</span>
  <span># if the line above returned, one of the workers or the listener has crashed</span>
<span>end</span>
</code></pre></div></div>

<p>Again, it worked!</p>

<p>The next step of implementing a web server would be to bake a HTTP parser to read request headers. There’s a <a href="https://github.com/cotag/http-parser" target="_blank">http-parser</a> gem that is using a C extension, and I’ve heard that is not supported by Ractor yet.</p>

<p>I found an HTTP parser that comes as a part of WEBrick which is a built into Ruby’s standard library.</p>

<p>I tried the following snippet:</p>

<div><div><pre><code><span>require</span> <span>'webrick'</span>

<span>CPU_COUNT</span> <span>=</span> <span>4</span>
<span>workers</span> <span>=</span> <span>CPU_COUNT</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>do</span>
  <span>Ractor</span><span>.</span><span>new</span><span>(</span><span>pipe</span><span>)</span> <span>do</span> <span>|</span><span>pipe</span><span>|</span>
    <span>loop</span> <span>do</span>
      <span>s</span> <span>=</span> <span>pipe</span><span>.</span><span>take</span>

      <span># raises "can not access non-sharable objects in constant HTTP by non-main Ractors (NameError)"</span>
      <span>req</span> <span>=</span> <span>WEBrick</span><span>::</span><span>HTTPRequest</span><span>.</span><span>new</span><span>(</span><span>WEBrick</span><span>::</span><span>Config</span><span>::</span><span>HTTP</span><span>)</span>
      <span>req</span><span>.</span><span>parse</span><span>(</span><span>s</span><span>)</span>

      <span>s</span><span>.</span><span>print</span> <span>"HTTP/1.1 200</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"Content-Type: text/html</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"Hello world!</span><span>\n</span><span>"</span>
      <span>s</span><span>.</span><span>close</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p><code>WEBrick::Config::HTTP</code> turned to be a mutable hash with some configuration objects. Since that constant and a hash were initialized in the main thread, it wasn’t allowed to be safely used from ractors. I worked around by inlining the hash definition but then I hit another non-shareable constant referenced from the WEBrick code that wasn’t too easy to inline.</p>

<p>This is probably the part that will improve on the upstream very soon. After all, this is the earliest Ractor implementation.</p>

<h2 id="the-end">The end</h2>

<p>I’m really excited about new concurrency primitives like Ractor getting pushed into Ruby’s upstream.</p>

<p>The Ractor model seems powerful and ready for experimental use. Within the next 6 months (Ruby 3.0 release is scheduled for December), I foresee a Ractor-based web server to come out to leverage this feature and get the most out of server CPUs. This is a great opportunity to learn concurrent programming and to contribute to the Ruby community.</p>

<p>For those curious to try Ractor, I’d suggest to try implementing other things that benefit from parallel execution, for instance a background job processor.</p>

<p>To try Ractor, you’ll need to build Ruby from the upstream. Read my previous posts (<a href="https://kirshatrov.com/2020/01/11/contributing-to-mri/" target="_blank">Contributing to Ruby MRI</a>) to learn about how to do that.</p>

</div></div>]]>
            </description>
            <link>http://kirshatrov.com/2020/09/08/ruby-ractor-web-server/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533152</guid>
            <pubDate>Sun, 20 Sep 2020 10:35:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Orbán played Germany, Europe's great power]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24532961">thread link</a>) | @vr46
<br/>
September 20, 2020 | https://www.direkt36.hu/en/a-magyar-nemet-kapcsolatok-rejtett-tortenete/ | <a href="https://web.archive.org/web/*/https://www.direkt36.hu/en/a-magyar-nemet-kapcsolatok-rejtett-tortenete/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>In October 2017, important figures of German and international business and political life gathered at a reception in a glass-walled hall on one of the upper floors of Frankfurt’s tallest skyscraper. At the event, one of the top executives of a German automobile manufacturing group, warmed and loosened up by some glasses of wine, started entertaining those around him with anecdotes. After some time, the conversation was directed to Hungary.</p>
<p>The senior automotive manager bragged about the fact that the executives of his company could call Hungarian Foreign Minister Péter Szijjártó at any time if they had any requests regarding their factories in Hungary. He then added that if necessary, they could even speak directly to Viktor Orbán – in fact, he said, the Hungarian Prime Minister had already helped them with a specific case.</p>
<p>Two years earlier, in September 2015, Germany’s automotive industry was hit by its biggest scandal ever. It was found that Volkswagen Group’s (VW) diesel cars used software manipulation to cheat on emission tests for many years (later several other German and non-German companies were found to have manipulated their data in a similar way). As a result of the scandal, the price of VW shares began to plummet and it looked like several companies could be seriously endangered, forcing them to close factories and cut jobs.</p>
<p>At the reception in Frankfurt, the German automotive executive claimed that the diesel emissions scandal had become so embarrassing for the federal government after a while that they felt the German state was starting to back out from behind them. Executives of his group of companies then turned directly to Viktor Orbán, asking him to represent the interests of car manufacturers in the European Council that was currently discussing the matter. Viktor Orbán agreed to help and kept his promise, the German automotive executive said with satisfaction.</p>
<div itemscope="" itemtype="http://schema.org/VideoObject"><p><iframe src="//www.youtube.com/embed/xCtaFfcysH4?iv_load_policy=3&amp;modestbranding=1&amp;rel=0&amp;wmode=transparent&amp;autoplay=0" frameborder="0" scrolling="no" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe></p></div>
<p>Since the beginning of 2016, the European Council, which represents governments of European Union member states, has repeatedly addressed the reform of vehicle emission rules. However, Germany has been trying to soften stricter regulations in alliance with Italy and Eastern European member states with significant German automotive investments. In September 2017, a new regulation finally came into force but it was full of loopholes, applied only to new cars not yet on the roads, and made many other concessions to automakers.</p>
<p>A German business source present at the Frankfurt reception told Direkt36 about the lobbying and the role of Orbán, adding that there was nothing glaring about it. “Representatives of every important company say they have Szijjártó and others’ phone numbers,” the source said, adding that top executives of several German carmakers told similar stories, and that they all</p>
<blockquote><p>“absolutely feel that the Hungarian government is in their pockets.”</p></blockquote>
<p>The spokesperson of Viktor Orbán and the Ministry of Foreign Affairs and Trade headed by Szijjártó did not respond to our request.</p>
<p>However, a former senior official in the Orbán government confirmed that “Viktor Orbán defends the interests of German car manufacturers in the European Council”. Nevertheless, according to the source, there is nothing surprising in this, as Hungarian governments have always been accommodating to German carmakers. Following the outbreak of the diesel emissions scandal, Mihály Varga, Minister of Finance of the Orbán government, said that 2-2.5 million of the Volkswagen Group’s 11 million diesel cars with cheating engines were manufactured at the Audi plant in the city of Győr and that “the government’s most important goal is maintaining jobs in the automotive industry and preserving the stability that the automotive industry provides in Hungary”.</p>
<p>The above story is a good example of how a relationship based on mutual benefits and dependence has developed between German policy makers, influential companies in German industry and the Hungarian government over the years and decades. German carmakers are the number one engine of Hungarian economic growth and, through this, of the Orbán government’s political successes. According to data by the Hungarian Central Statistical Office, car manufacturing accounts for 4.5% of Hungary’s GDP and suppliers working for large car manufacturers account for another 5-8%. This means that every eighth to tenth forint produced in Hungary has to do something with the Germany-dominated car industry.</p>
<p>Now is a particularly sensitive period in Hungarian-German relations. In the coming months, political issues determining the long-term European bargaining power of the Orbán government and Hungary will be settled in the European Union. In these debates, Viktor Orbán’s German allies will have the final say, and although they have repeatedly criticized decisions of the Hungarian government, they have so far refrained from acting really hard.</p>
<p>Direkt36 uncovered details of this intricate system of relationships, the interests that drive it, and the key players in a months-long investigation. We found how decades of personal relationships control Orbán’s maneuvers in Germany; how German companies give up much-talked-about democratic values ​​if it is in their business interests; and, for example, that the Hungarian government was able to prevent Jewish leaders in Budapest from sharing their concerns with Angela Merkel.</p>
<p>In our research, we had in-depth background conversations with two dozen sources — current and former government officials, diplomats, political intermediaries, business executives, and analysts. Most of them shared information about behind-the-scenes events if we did not write down their names.</p>
<h2>I. Orbán’s German patrons</h2>
<figure id="attachment_6438"><img src="https://www.direkt36.hu/wp-content/uploads/2020/09/signal-2020-09-17-093904_001.jpeg" alt="" width="3868" height="2416" srcset="https://www.direkt36.hu/wp-content/uploads/2020/09/signal-2020-09-17-093904_001.jpeg 3868w, https://www.direkt36.hu/wp-content/uploads/2020/09/signal-2020-09-17-093904_001-150x94.jpeg 150w, https://www.direkt36.hu/wp-content/uploads/2020/09/signal-2020-09-17-093904_001-300x187.jpeg 300w, https://www.direkt36.hu/wp-content/uploads/2020/09/signal-2020-09-17-093904_001-768x480.jpeg 768w, https://www.direkt36.hu/wp-content/uploads/2020/09/signal-2020-09-17-093904_001-1200x750.jpeg 1200w, https://www.direkt36.hu/wp-content/uploads/2020/09/signal-2020-09-17-093904_001-1177x735.jpeg 1177w" sizes="(max-width: 3868px) 100vw, 3868px"><figcaption>Source: kormany.hu</figcaption></figure>
<p>“Call the Count and tell him we’d like to visit him!” <span lang="EN">This is the task Viktor Orbán gave Gergely Prőhle on the night of his first election victory, on May 24, 1998. Prőhle was the head of the Budapest office of the Friedrich Naumann Foundation (ie the party foundation of the German Free Democratic Party, the FDP). </span> Four days later, the new prime minister-elect was already in Bonn, where executives of German industrial giants like Audi, Bosch or Siemens were waiting to meet him. Orbán reassured them, according to the Hungarian state news agency’s report, that a predictable economic environment awaits them, moreover, his government wants to increase foreign investment, primarily in manufacturing.</p>
<p>The meeting, which was organized in only matter of few days, was thanks to to Otto Graf Lambsdorff, the influential liberal politician and honorary president of the FDP, who was most often referred to by his acquaintances only as “the Count”. Lambsdorff had known Orban for a long time, he led the Liberal International when Fidesz became a member in 1992. During Orbán’s visit, Lambsdorff proudly talked to the German press about the future prime minister and boasted that he “has been watching Orbán’s political career since the regime change in Hungary and is very happy to support him”. Gergely Prőhle, who later also served as ambassador to Berlin and deputy secretary of state for foreign affairs under the Orbán government, told Direkt36 that “Lambsdorff had already started traveling to Eastern Europe before 1989 and had become Orbán’s first German patron. He was an infinitely smart person from whom much could be learned. The count saw the economic-political ties in light of a full historical context, he was a formidable personality”.</p>
<p><span lang="EN">The relationship between Orbán and Lambsdorff was so close that it even survived when Fidesz broke ties with the European political family the Count represented. Prőhle also wrote an article on Lambsdorff for <a href="https://www.valaszonline.hu/2019/12/05/ezt-a-libprohle-gergely-otto-graf-lambsdorff/">Valasz Online</a>. According to him, the Count watched Orbán’s politics turn conservative in the mid-1990s with some disappointment, but accepted the political realities. He also observed, how over time, leader of the Christian Democratic Union (CDU) Helmut Kohl became the most important point of reference for Orbán. At one point, Orbán explained to Lambsdorff that </span></p>
<blockquote><p><span lang="EN">“in order for him to maximize votes in Hungary, the liberal slogan is not good, and the Count understood that”. </span></p></blockquote>
<p><span lang="EN">However, the two politicians remained close friends, and later in 2009 Orbán was the only foreign guest at Lambsdorff’s private funeral.</span></p>
<p><span lang="EN">During his visit to Germany in May 1998, Orbán not only spoke to company executives, but also spent an hour and a half meeting with German Chancellor Helmut Kohl, then head of government for 16 years, who was facing a really close election a few months later. At that time, officials from the Hungarian foreign ministry, which was still under socialist leadership, advised Orbán to also meet Kohl’s challenger, Gerhard Schröder, because he seemed more likely to win the election. However, because of his loyalty to Kohl, “Orbán rejected this idea, while for example, the Polish Prime Minister did meet with Schröder. Schröder and his people didn’t forget this later, neither for the Poles, nor for us,” a former Hungarian foreign ministry official told Direkt36.</span></p>
<p><span lang="EN">It was a tight race, but Schröder eventually defeated Kohl. According to Sándor Peisch, who served as Hungarian ambassador to Berlin under the Socialist MSZP governments between 2003 and 2010, this was also the end of an era when the German leadership still looked at Hungary with gratitude for its role in the country’s reunification. An important milestone in the process leading to the fall of the Berlin Wall, was the opening of the Hungarian-Austrian border. It started in the summer of 1989 and was officially announced in September, paving the way for East German refugees to travel via Austria to West Germany. But “the SPD was never enthusiastic about reunification. At one of our meetings, for example, Chancellor Schröder began to complain about how much money it had costed,” Peisch told Direkt36.</span></p>
<p><span lang="EN">Viktor Orbán and Helmut Kohl thus ruled simultaneously for only a few months. While Lambsdorff was a true …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.direkt36.hu/en/a-magyar-nemet-kapcsolatok-rejtett-tortenete/">https://www.direkt36.hu/en/a-magyar-nemet-kapcsolatok-rejtett-tortenete/</a></em></p>]]>
            </description>
            <link>https://www.direkt36.hu/en/a-magyar-nemet-kapcsolatok-rejtett-tortenete/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532961</guid>
            <pubDate>Sun, 20 Sep 2020 09:50:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Memex – A proof of concept built in Electron and Chrome Extension]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24532788">thread link</a>) | @steve1820
<br/>
September 20, 2020 | https://www.steveliu.co/memex | <a href="https://web.archive.org/web/*/https://www.steveliu.co/memex">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-block-type="2" id="block-33de0799eab39cfadbe1"><div><p>I’ve never been a huge online note taker. From high school to university, I’ve always relied on pen and paper as my weapon of choice. At the time and even to some extent now, I’ve felt like this was a good enough solution to my problems.</p><p>I’ve always felt the simpler the solution the better. Why complicate things?</p><p>This changed however after working as a software engineer in industry. As I worked on a software product that derived its core functionality from machine learning, it seemed that I was constantly drowning in a sea of information.&nbsp;</p><p>It was a constant repetition of learning something, forgetting about it 5 months later and then having to recycle through my notes and reread the article/paper/blog.</p><p>My brain was a leaky bucket. Every time I poured something in, something else would leak out.</p><p>It was during those dark times of desperation that I stumbled upon the “niche” industry of Knowledge Management Systems (KMS) and as an extension, the Memex.</p><p> I was fascinated with all the innovation coming from up and coming open source projects and companies in this space. Software like Athens (https://github.com/athensresearch/athens), Roam (https://roamresearch.com/), Obsidian (https://obsidian.md/) all seemed so promising. </p><p>I was particularly inspired by reading karlicoss’s blog (https://beepb00p.xyz/promnesia.html). He outlines so many good and intuitive reasons why the current solutions are broken (although in this particular post he focuses on browser history).</p></div></div></div></div>]]>
            </description>
            <link>https://www.steveliu.co/memex</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532788</guid>
            <pubDate>Sun, 20 Sep 2020 08:55:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making Skeletonised Leaves]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24532709">thread link</a>) | @arbol
<br/>
September 20, 2020 | https://blog.lidskialf.net/2020/09/17/making-skeletonised-leaves/ | <a href="https://web.archive.org/web/*/https://blog.lidskialf.net/2020/09/17/making-skeletonised-leaves/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-1332">

	

	
			<figure>
				<img width="992" height="1331" src="https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=992" alt="" loading="lazy" srcset="https://adq454703481.files.wordpress.com/2020/09/dried.jpg 992w, https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=112 112w, https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=224 224w, https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=768 768w" sizes="(max-width: 992px) 100vw, 992px" data-attachment-id="1333" data-permalink="https://blog.lidskialf.net/dried/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/dried.jpg" data-orig-size="992,1331" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600352312&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;211&quot;,&quot;shutter_speed&quot;:&quot;0.010013&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="dried" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=224" data-large-file="https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=763">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p>I decided I wanted to try making some skeletonised leaves. So I did some Googling and decided to try <a href="https://penguinbaybiology.org/make-clear-leaf-view-vein-structure/">this</a> approach.</p>



<p>We went out in the evening and gathered some leaves from the local  Shrubbery. Totally not suspicious 🙂</p>



<figure><img data-attachment-id="1343" data-permalink="https://blog.lidskialf.net/leaves/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/leaves.jpg" data-orig-size="992,1331" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600203574&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;909&quot;,&quot;shutter_speed&quot;:&quot;0.03&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="leaves" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=224" data-large-file="https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=763" src="https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=763" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=763 763w, https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=112 112w, https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=224 224w, https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/leaves.jpg 992w" sizes="(max-width: 763px) 100vw, 763px"></figure>



<p>I bought some Sodium Hydroxide and a cheap steel pot from ebay. Note: it must <strong>not</strong> be Aluminium as the Sodium Hydroxide will react with Aluminium!</p>



<figure><img data-attachment-id="1336" data-permalink="https://blog.lidskialf.net/ingredients/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg" data-orig-size="1331,998" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600381793&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;543&quot;,&quot;shutter_speed&quot;:&quot;0.03&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="ingredients" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=300" data-large-file="https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=900" src="https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=1024" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=1024 1024w, https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=150 150w, https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=300 300w, https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg 1331w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Although Sodium Hydroxide isn’t a deadly poison, you really don’t want it on your skin or in your eyes, so gloves/goggles are a necessity for safety. Hmm, I should really look into some sort of cheap lab coat as well to protect my clothes for this sorta stuff:</p>



<figure><img data-attachment-id="1339" data-permalink="https://blog.lidskialf.net/safety/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/safety.jpg" data-orig-size="1331,998" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600381856&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;634&quot;,&quot;shutter_speed&quot;:&quot;0.03&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="safety" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=300" data-large-file="https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=900" src="https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=1024" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=1024 1024w, https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=150 150w, https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=300 300w, https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/safety.jpg 1331w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>I scaled up the proportions to 1L of (Edinburgh) tap water and 30G of Sodium Hydroxide powder. I put them in the pot, brought it to the boil and added the leaves. </p>



<p>For fun I also tested the pH of the solution with my new pH paper (also from Ebay/China). Its about a 14, so pretty alkaline!</p>



<figure><img data-attachment-id="1340" data-permalink="https://blog.lidskialf.net/phpaper/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg" data-orig-size="992,1331" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600203853&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;108&quot;,&quot;shutter_speed&quot;:&quot;0.04001&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="phpaper" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=224" data-large-file="https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=763" src="https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=763" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=763 763w, https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=112 112w, https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=224 224w, https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg 992w" sizes="(max-width: 763px) 100vw, 763px"></figure>



<p>The instructions suggested boiling for about two hours, but it appears to depend on the leaves you choose. I checked on it every 20 minutes or so, and pulled leaves out as they became ready. </p>



<p>To process them, I had the following set up next to the pot:</p>



<ul><li>Tray 1: Plain tap water to wash off the Sodium Hydroxide.</li><li>Tray 2: Some “Ordinary Household Bleach” (aka Sodium Hypochlorite) to bleach any remaining colour out.</li><li>Tray 3: More plain tap water to wash off the bleach.</li><li>A sheet of alumunium foil to put the leaves on to dry out.</li></ul>



<p>After all of them were processed, I ended up with this:</p>



<figure><img data-attachment-id="1345" data-permalink="https://blog.lidskialf.net/drying/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/drying.jpg" data-orig-size="1331,998" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600212131&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;104&quot;,&quot;shutter_speed&quot;:&quot;0.010013&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="drying" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=300" data-large-file="https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=900" src="https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=1024" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=1024 1024w, https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=150 150w, https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=300 300w, https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/drying.jpg 1331w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The next morning I was able to unpeel the more robust leaves, yielding me these:</p>



<figure><img data-attachment-id="1346" data-permalink="https://blog.lidskialf.net/dried-1/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg" data-orig-size="992,1331" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600352312&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;211&quot;,&quot;shutter_speed&quot;:&quot;0.010013&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="dried-1" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=224" data-large-file="https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=763" src="https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=763" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=763 763w, https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=112 112w, https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=224 224w, https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg 992w" sizes="(max-width: 763px) 100vw, 763px"></figure>



<p>Observations</p>



<ul><li>You need to use <em>robust</em> leaves from trees. I tried some nettle leaves, but they quickly turned to mush. Some of the tree leaves appeared to process fine, but turned out to be way too delicate to remove from the foil after drying: definitely depends on the species. There may be a better way to dry them, will think on it.</li><li>Only process one species of leaf at a time, otherwise you constantly have to check each one in the pot, which means you’re disturbing them more to check.</li><li>Make sure to check on the water level! I <em>almost</em> boiled it dry.</li><li>Its fiddly! During processing, you have to <em>carefully</em> unroll the leaves by hand while wearing gloves to get them flat prior to drying.</li><li>I tried processing a dried up Oak leaf since theoretically it should be closer to being skeletonised: it didn’t seem to work very well (you can see the unsuccessful result on the aluminium foil photo).</li></ul>



<p>What Next?</p>



<p>They’re definitely more robust than I expected, but they’re still quite delicate. I fancy trying dying them and embedding them into some transparent resin next.</p>




	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://blog.lidskialf.net/2020/09/17/making-skeletonised-leaves/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532709</guid>
            <pubDate>Sun, 20 Sep 2020 08:35:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generative Bad Handwriting]]>
            </title>
            <description>
<![CDATA[
Score 164 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24532352">thread link</a>) | @atulvi
<br/>
September 19, 2020 | https://avinayak.github.io/programming/art/2020/09/18/p5-strokes.html | <a href="https://web.archive.org/web/*/https://avinayak.github.io/programming/art/2020/09/18/p5-strokes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>So.. I made a popular tweet last week in the <a href="https://twitter.com/hashtag/%E3%81%A4%E3%81%B6%E3%82%84%E3%81%8DProcessing?src=hashtag_click">#つぶやきProcessing</a> circles.</p>

<blockquote><p lang="cy" dir="ltr">j=24,m=0,draw=(a=&gt;{for(v=(i=&gt;w/3*(n=noise)(i)-k),createCanvas(w=1e3,w),noFill(),background('<a href="https://twitter.com/hashtag/fd7?src=hash&amp;ref_src=twsrc%5Etfw">#fd7</a>'),translate(0,m--),i=0,y=0;y&lt;w-m;y+=j)for(x=k=90;x&lt;w-k;x+=9)if(y+k&gt;-m?curve(v(i++)+x,v(i++)+y,x,j+y,x+9,j+y,v(i++)+x,v(i++)+y):i+=4,x+=v(i++)%9,n(x*y)&lt;.13)y+=j});//<a href="https://twitter.com/hashtag/%E3%81%A4%E3%81%B6%E3%82%84%E3%81%8DProcessing?src=hash&amp;ref_src=twsrc%5Etfw">#つぶやきProcessing</a> <a href="https://t.co/WNIwAAAXjQ">pic.twitter.com/WNIwAAAXjQ</a></p>— atulvinayak (@atulvinayak) <a href="https://twitter.com/atulvinayak/status/1305116417419653120?ref_src=twsrc%5Etfw">September 13, 2020</a></blockquote>


<p>I’ll try to explain how this script worked and how I was able to fit the whole thing into 280 characters.</p>



<p>All of this started when last week when I was experimenting with the p5js <code>curve()</code> function. Internally this is an implementation of the <a href="https://en.wikipedia.org/wiki/Centripetal_Catmull%E2%80%93Rom_spline" title="Centripetal Catmull–Rom spline">Centripetal Catmull–Rom spline</a>. I tried generating a bunch of 8 legged water spiders for fun :)</p>

<video controls="" muted="" src="https://video.twimg.com/ext_tw_video/1303620577589039104/pu/vid/720x720/8iYWjReFxe-9kWVl.mp4?tag=10">
</video>

<p>I admit this looks pretty stupid. The aim was to generate an animation a whole bunch of water spiders with the camera panning around. But then, for me to understand how exactly the Catmull-Rom spline worked, I decided to randomly plot a bunch of curves on a 2D canvas and it somehow resembled handwriting from my native language (<a href="https://en.wikipedia.org/wiki/Malayalam">Malayalam</a>).</p>

<p><img src="https://avinayak.github.io/uploads/download-12.png" alt=""></p>

<p>Actual Malayalam handwriting sample.<br>
<img src="https://avinayak.github.io/uploads/4f31bc2ce9a02537444fc6eeea276dc5.jpg" alt=""></p>

<p>Reducing character spacing.. Do you see the similarity now?<br>
<img src="https://avinayak.github.io/uploads/download-10.png" alt=""></p>

<p>Also, at this time I was playing the PC remaster of <a href="https://en.wikipedia.org/wiki/Journey_(2012_video_game)">Journey (2012)</a>. Journey has a very beautiful blocky scriptures all over the temples in the game.</p>

<p><img src="https://avinayak.github.io/uploads/eayhyxhueaagmqu.jpg" alt=""></p>

<p>I guessed this is pretty easy generate. I made a few attempts to reproduce the approximate style using p5.js</p>

<p><img src="https://avinayak.github.io/uploads/download-8.png" alt=""></p>

<p>and even an infinite scrolling version</p>

<video controls="" muted="" src="https://video.twimg.com/ext_tw_video/1304311867284664323/pu/vid/720x720/zNWZ-LQrIl0KrnCU.mp4?tag=10">
</video>

<p>This script had some serious performance issues(you can see it slowing down towards the end). Later I learned that this style of meaningless writing is a thing in the art community known as Generative <a href="https://en.wikipedia.org/wiki/Asemic_writing">Asemic Writing</a>. According to Wikipedia:</p>

<blockquote>
  <p><strong>Asemic writing</strong> is a wordless open semantic form of writing. The word asemic means “having no specific semantic content”. With the nonspecificity of asemic writing there comes a vacuum of meaning which is left for the reader to fill in and interpret.</p>
</blockquote>

<p>I decided to combine the two and make an infinite generator of malayalam-esque asemic writing. I’ve seen curve generated asemic <a href="https://www.reddit.com/r/asemic/comments/dw5ze3/generative_script/?ref=share&amp;ref_source=link">before</a>. So, What I did is not something new.. however, maybe the way I made it infinite scrolling was something new(?). I’ll try to explain how the code works.</p>



<p>I lost the original script in the minifying process, but I managed to unminify the tweet somehow.</p>

<div><div><pre><code>var yOffset = 24;
var scrollPosition = 0;
var canvasWidth = 800;
var margin = 90

function setup() {
    createCanvas(canvasWidth, canvasWidth)
    noFill();
}

function deterministicRandom(index) {
  return 1000 / 3 * noise(index) - 90
}

function draw() {
    background('#fd7');
    translate(0, scrollPosition--);

    for (i = 0, y = 0; y &lt; canvasWidth - scrollPosition; y += yOffset)
        for (x = 90; x &lt; canvasWidth - margin;) {
            if (y + margin &gt; -scrollPosition) {
                curve(
                  deterministicRandom(i++) + x, 
                  deterministicRandom(i++) + y, 
                  x, 
                  y + yOffset, 
                  x + 9, 
                  y + yOffset, 
                  deterministicRandom(i++) + x, 
                  deterministicRandom(i++) + y
                )
            } else {
                i += 4
            }
            x += (9 + deterministicRandom(i++) % 9)
            if (noise(x * y) &lt; .13)
            {
              y += 2*yOffset
              x = margin
            }
        }

}
</code></pre></div></div>

<p>The most important part of the code is the function <code>deterministicRandom()</code> which is used a lot of times in the sketch. It’s basically <code>noise()</code> but mapped to range <code>[243, -90]</code>. p5 js <code>curve()</code> takes in 2 control point and 2 physical point coordinate to determine the location and shape of the curve. Each character is is thus a set of 4 deterministically random numbers for control points + 4 constants for physical points. All of these points are offset by a base <code>&lt;x,y&gt;</code> coordinate to place the curve in a line. <em>Because it’s deterministically random, the shapes and location of the curves are preserved in every frame</em>.. making the infinite scroll effect work.</p>

<p>The 2 loops iterate over x and y, at a constant rate. x by 9 pixels and y by 24 pixels. But, inside the loop, based on deterministic random, x is randomly incremented by up to 9 pixels to simulate the randomness in spaces between characters. Also, if for a random condition with somewhat low probability (<code>noise(x * y) &lt; .13</code>), a line-break is added. Which means, y is incremented thrice in that loop and x is reset to a margin value (90).</p>





<p>The infinite scroll effect is basically done using <code>translate(0, scrollPosition--)</code>. The loop termination clause is adjusted such that only lines within the frame are rendered (between <code>y = scrollPosition to scrollPosition+canvasHeight</code>). The condition <code>y + margin &gt; -scrollPosition</code> directly inside the loop checks for this. This also offsets the random number index to the one needed by the lines being rendered in the else case. Here’s a version of the script that shows lines being rendered as the script runs:</p>



<p>And that’s basically it. The initial version I designed rendered every line from the first scroll position to the last in every frame, even if those lines were not visible. This is terrible for performance and the if condition inside the loop fixed this.</p>



<p>Step one of minifying was converting all the functions to <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Functions/Arrow_functions">arrow functions</a>. This took up way less space. Then I moved all the <code>setup()</code> stuff to <code>draw()</code>. p5 does not re-execute <code>createCanvas</code> even if you place it in <code>draw()</code>. Then I had to cut down number of variables as much as I can. 2 of them were reused: <code>canvasWidth(w)</code> and <code>margin(k)</code> were also used as a coefficient in <code>deterministicRandom()</code>. Finally spaces were removed and long names were truncated to single characters.</p>



<p>This script was written in about 2-3 hours. Looking back, I can see a lot of places where I’d try to reduce repeated code and make it smoother. I never thought this would go so popular, so I never really cared to optimize so much. But there you go.. a simple way to generate bad handwriting :)</p>

</div></div>]]>
            </description>
            <link>https://avinayak.github.io/programming/art/2020/09/18/p5-strokes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532352</guid>
            <pubDate>Sun, 20 Sep 2020 06:53:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You Are an Impostor]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24532307">thread link</a>) | @abyx
<br/>
September 19, 2020 | https://softwaresaltmines.com/2020/09/09/you-are-an-impostor/ | <a href="https://web.archive.org/web/*/https://softwaresaltmines.com/2020/09/09/you-are-an-impostor/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-2229">

	
<!-- .entry-header -->

	<div>

		<div>

			
<h5>By Jim Grey (<a rel="noreferrer noopener" href="https://softwaresaltmines.com/about/" target="_blank">about</a>)</h5>



<p>I hired a software developer right out of college. He had a lot to learn, but he learned it steadily. Yet he admitted to me privately that he wasn’t sure he belonged. He thought that the other developers spoke so confidently and delivered so competently. He compared himself to them and, in his mind, came up wanting.</p>



<div><figure><img loading="lazy" data-attachment-id="2237" data-permalink="https://dev.jimgrey.net/me-at-crown-hill/" data-orig-file="https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg" data-orig-size="1071,1339" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;Jim Grey&quot;,&quot;camera&quot;:&quot;F2AS&quot;,&quot;caption&quot;:&quot;Nikon F2\r50mm f\/2 AI Nikkor\rFujifilm Neopan 100 Acros\r\rMy son Damion shot these. I was going for a serious look but I think what I got was a bored look.&quot;,&quot;created_timestamp&quot;:&quot;1472162857&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;Me at Crown Hill&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Me at Crown Hill" data-image-description="" data-medium-file="https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg?w=240" data-large-file="https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg?w=580" src="https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg?w=819" alt="" width="413" height="516" srcset="https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg?w=819 819w, https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg?w=413 413w, https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg?w=826 826w, https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg?w=120 120w, https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg?w=240 240w, https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg?w=768 768w" sizes="(max-width: 413px) 100vw, 413px"><figcaption>Impostor.</figcaption></figure></div>



<p>What he didn’t know was that I was leading developers for the first time. I’d been in management roles in the industry for a very long time, but always of testing and communications teams. </p>



<p>Worse, I hadn’t written a meaningful line of code in about a decade. Even then, most of that code was test automation. That’s not the same as writing product code.</p>



<p>Yet here I was, leading developers. The CTO who hired me wanted my skill in managing people, leading projects, and refining process. But I had so much to learn about modern software development. It was embarrassing to need the developers to explain the basics to me.</p>



<p>I told this young developer this story and admitted that I felt like an impostor, too. But I’d experienced impostor syndrome before. I knew that with effort and time I’d learn what I needed to learn and the feeling would abate. More importantly, even with all I needed to learn, I knew I had something valuable to offer right now. He did too, I told him.</p>



<p>We all figure it out as we go. In time, we build experience that lets us get it right more often.</p>



<p>What I wish I’d told him, what I’ve learned since then, is that there are three kinds of impostors. There are the impostors who don’t know they’re impostors. They’re so self-possessed that they overestimate themselves. There are the impostors who know it but do everything they can to hide it. They live in fear and anxiety that they will be found out. And then there are the impostors who know it, admit it to themselves, and sometimes even admit it to others. They’re the ones who can grow the fastest.</p>



<p>This young developer was the best kind: he admitted it. It let me tell him my own story, which helped put his mind at ease. Then it let us talk frankly about the areas where he felt like he didn’t know what he was doing, so I could pair him with other engineers who could level him up faster.</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
		<!-- .comments-wrapper -->

		
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://softwaresaltmines.com/2020/09/09/you-are-an-impostor/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532307</guid>
            <pubDate>Sun, 20 Sep 2020 06:37:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Internet, Social Media and the Individual]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24532213">thread link</a>) | @nktsg
<br/>
September 19, 2020 | https://techimadions.com/internet-social-media-individual/ | <a href="https://web.archive.org/web/*/https://techimadions.com/internet-social-media-individual/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>As the COVID-19 pandemic has proliferated and as we have come to terms with it, the Internet became the heartbeat of our world. It has already become ubiquitous in our lives but the pandemic has forced people and businesses to realize how our socioeconomic lives have become dependent on it. This is only going to accelerate in the coming years considering the new ways of work and interaction people have adopted over the previous few months.</p>
<p>On the other hand, this has left people with increased psychological disquiet since we're already overwhelmed by the influence of the Internet and social media in our day to day lives. It's ever more important to reflect on our relationship with the Internet on the individual front and ask hard questions about our future with it.</p>
<p>The following are some of my reflections on the current state of the influence of the Internet in our individual lives and what can be done.</p>
<h3>Connected But Dejected</h3>
<p>We are living in the most connected times, yet we've never felt more isolated collectively. Our phones ring with so many notifications in a day that no single notification has more value. The asynchronicity of our communication patterns has no definite coherent start and end. Text is not suitable for hourly long conversations over food and drinks; so now we talk in bits and pieces. Instant messaging has made communication so cheap and effortless that talking on the phone for more than a few minutes feels like dread. Social media, online news, and videos on anything take so much of our time that later we end up deciding whether to work or check for what's up with a friend/family member.</p>
<p>I think it's not the time that we end up sacrificing, it's the fear of missing out of things. Information moves so fast on the Internet that we trade-off attention for aggregation. We've started to live in two realities. One is physical and the other is digital and unfortunately, the digital one is taking the lead. Even when we are in the physical one, we left some part of ourselves in the digital one. It's like we're sailing two boats at the same time. We're in constant flux. It's not so difficult to map both the realities with the characteristics of the modern world that humans cherish. The digital one is fast, productive, opportunistic, economic, scalable, reliable, and mostly non-discriminatory. But all this comes at the cost of our psychological health. While we marvel at the disruptive innovations of digital connection that the Internet has sown seeds for, it's no substitute for our fundamental biological and physical need for connection. We still long to sense fellow humans by engaging with them in a physical medium. And that's when our psychological instincts find refuge.</p>
<h3>The Desire For Feedback</h3>
<p>We are a creature that loves attention. This starts from the day we are born. Babies demand attention to care. Teens demand attention to self-esteem. Adults require attention to form new connections that help in job prospects. Attention is a natural and necessary part of our biological behavior. The problem occurs when instead of getting attention as a result of our personalities, we tend to <strong>seek</strong> attention. What popular culture does is divide people into two categories: the influencer and the follower. Class-based societies are everywhere in the world. But popular culture creates another category.</p>
<p>Before the internet, there were fixed avenues for a person to become popular. Internet followed by social media turned the table upside down. And after the smartphone revolution, anyone having a phone got the tools to broadcast to possibly every other person on the planet. Social media started with networks of friends and family and platforms like Instagram and YouTube eventually turned it into a worldwide virtual stage.</p>
<p>Now, everybody has got everybody's attention. The playing field has been leveled. Everyone wants a piece of it. This behavior is not permanent though. In the end, everybody can't win. Since social media is far less daunting than the physical space, we tend to delegate the feedback mechanism of society to it. The effort required to represent oneself is frugal and the consequences are far less intimidating. And since the said rules and codes of society are not applicable here, the expectation for feedback increases.</p>
<h3>The Perfect Life Diet</h3>
<p>Social media was started as a way to connect with friends and family. At least, it was projected like that. It's not that we didn't have mediums for that before. I think it provided a great escape from physical reality especially for teens and young adults. We know that these years are an intimidating phase of our lives. Connecting with other people to know a little more something about their life and creating your persona was way much easier.</p>
<p>Once all the young people onboarded, the network effects made the older generation to join it. Text was still a banal way of sharing your life. Soon after, the social media companies realized that photos are more stimulating to us than text and activate more parts of our brain. Then came platforms like Instagram and Snapchat. Photos became the dominant media crossing through our minds. <a href="https://marshallmcluhan.com/">Marshall McLuhan</a> in his book quotes that in the long run, content matters less than the medium itself in influencing how we think and act. Soon after, the advertisers got hold of this fact and since more people were shifting to these platforms leaving TV and newspapers behind, advertising gave way for people to make some extra cash. Eventually, the ship started sailing and marketing picked up speed.</p>
<p>Advertising has always worked on exaggerated product characteristics and contrived human behaviors. As a result, people started sharing their ideal lives. The perfect couple, the perfect job, the perfect clothing, the perfect diet, the perfect fitness regime, the perfect accessories, the perfect home, the perfect vacation became mainstream outlook.  Some people post multiple photos in a single day. Young people have even started to start their professional journey on social media. Dissatisfaction start to seep in when we start to compare our persona with other people's personas. Comparison is a natural trait of us. That's how we perceive the world around us and separate one thing from another.</p>
<p>But it doesn't work the same way in the physical and digital space. In the physical space, there can only be a handful of objects or people in our line of vision. Hence, our brains get an ample amount of time to process our emotions.  This changes completely in the digital space. We go through so much media in so little time that the brain is not able to register all of them at the moment. Instead, it registers hooks to all the information which resurface later in our daily lives</p>
<h3>Mimetic Paralysis</h3>
<p><a href="https://iep.utm.edu/girard/">René Girard's</a> Mimetic theory’s key insight is that human desire is not an autonomous process, but a collective one. We want things because other people want them. This is ever more visible today as we spend more of our time watching what's going on with other people and the world. The increased consumption of digital media might be rewiring our brain structures in ways that we don't understand yet. While we are mapping our social behaviors in the physical world onto the digital world, our digital persona is creating a space of its own. This novel persona is being shaped by the values and norms of the digital atmosphere.</p>
<p>We can already see the effect on how people have started curating their digital persona according to these rules and how the nature of every social profile has started to look the same. Someone creates a new style of content and soon after you can see mushrooms of other people creating the same content. It's not a special trait of social media. Just that it has aggravated this trend. We don't realize when our digital worlds start to influence our physical world. The places we go, the things we buy, the food we eat. Some people have started even doing things in their physical worlds just to enhance their digital curation. The mostly independent nature of social media also attracts many of the young people. Bringing up connected is also a huge reason for the current generation of teens trying to find a stable work opportunity out of it.</p>
<h3>The Information Rabbit Hole</h3>
<p>How many times have you opened a bunch of links in different browser tabs; all seeming interesting just to realize that you can't possibly read all of it? How many times have you started watching something on YouTube just to realize that it's been hours? Every new second, someone is publishing content somewhere in the world. And it's all available instantly. There are no distribution costs. There is simply too much information now. There are news sites, wiki sites, videos, blog posts, independent publishers, newsletters, twitter threads, documentaries, etc.</p>
<p>But information is not a substitute for knowledge. This is a great misunderstanding of the post-internet era. Cramming our minds with disparate information doesn't make us knowledgeable. The brain is a very efficient machine. It doesn't retain information which it doesn't find useful regularly. That's why however a great article you've read days ago, you don't remember much of it.  We've delegated memorization to search engines. Memorization is a key element in forming a solid understanding of the world.  Since there is so much content, every different person is reading, watching, and listening to different things.</p>
<p>That's why it's getting harder to talk or chat about a common topic of interest. Consequences are FOMO and despair. You're now subject to know every social, political, national, geopolitical news. Every second something bad is happening in some part of the world and it's all visible in plain sight. But we can't do much about any single incident. This ends up in a lot of mental despair. In the end, we've to pick our battles. There is limited fuel in our brains and it's in our control what we choose to put it at work.</p>
<h3>Where's the …</h3></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://techimadions.com/internet-social-media-individual/">https://techimadions.com/internet-social-media-individual/</a></em></p>]]>
            </description>
            <link>https://techimadions.com/internet-social-media-individual/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532213</guid>
            <pubDate>Sun, 20 Sep 2020 06:09:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is macOS under the biggest malware attack ever?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24532184">thread link</a>) | @todsacerdoti
<br/>
September 19, 2020 | https://reverse.put.as/2020/09/17/evilquest-revisited/ | <a href="https://web.archive.org/web/*/https://reverse.put.as/2020/09/17/evilquest-revisited/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <div>
    <div>
      <article role="main">
        <p>No. I just clickbaited you but don’t leave yet, keep reading for something fun!</p>
<p>A couple of days ago I found something curious on <a href="https://www.virustotal.com/gui/">VirusTotal</a>. There were more than 40 thousand binaries with the same size in a single day. That seemed very odd so I loaded two random binaries and compared their contents. The only difference was on strings section.</p>
<p>VirusTotal detections were very low (two to three) and identified the samples as EvilQuest/ThiefQuest malware.</p>
<p>To prove that all the binaries were the same except for strings, I wrote a quick <a href="https://github.com/gdbinit/evilquest_stats">Mach-O stats</a> utility in <a href="https://golang.org/">Go</a> (yes, 2020 is this crazy!) to hash the code and strings sections separately. The hypothesis is that the code section would have the same hash for all the samples, and the strings section would have a unique hash for each sample. The output confirmed that this was indeed the case - same code, different strings.</p>
<p>Running this program against 206091 binaries totalling 34GB of data:</p>
<div><pre><code data-lang="bash">Mach-O Stats
<span>(</span>c<span>)</span> <span>2020</span> Pedro Vilaca. All Rights Reserved
 100% |███████████████████████████████████████| <span>(</span>206091/206091, <span>1563</span> it/s<span>)</span> <span>[</span>2m11s:0s<span>]</span>
__text map
cd87dfd659fc2334ccc59093c1f41ba9abf4c88046d438ddd8bc2d82f55859d7 <span>206091</span>
</code></pre></div><p>Given that the strings are encrypted/obfuscated, my first idea was that this could be a new version with mutated versions being used in different sources. Doesn’t make that much sense given that the code was the same but given that EvilQuest has ransomware features, this could be for example different BitCoin wallets for each sample.</p>
<p>Now it was time to load one of the samples into a disassembler and give a look at its contents. Assuming that the VirusTotal detections were correct even if too low, I grabbed the <a href="https://objective-see.com/downloads/malware/EvilOSX.zip">known sample</a> of EvilQuest. This sample contains debugging symbols so it’s very easy to navigate since most function names are explicit about their intents. The new sample fixed that mistake and had that information removed.</p>
<p>Before bringing the heavy diffing guns such as <a href="https://www.zynamics.com/software.html">BinDiff</a> and <a href="http://diaphora.re/">Diaphora</a> I like to give a look around to feel what’s going on. In this case the code had differences but was very similar. I could see what were clearly obfuscated/encrypted strings like in the original sample. So, I tried to find those functions using the symbols from the first sample. That was fast and easy and confirmed that the code was related (either from the same author or someone reusing it - attribution is hard :P).</p>
<p>Scott Knight released a <a href="https://github.com/carbonblack/tau-tools/tree/master/malware_specific/ThiefQuest">script</a> to decrypt/encrypt the original samples strings, but it doesn’t work with the new samples. It makes sense given that there are keys and tables that could have changed, and also what appears to be a new type of obfuscated/encrypted string format.</p>
<div><pre><code data-lang="plaintext">000Bg{0000090nQ4XL1qPsnl1ZjpKX0lkFoa0000053
</code></pre></div><p>The new strings type appears to always starts with <strong>000Bg{</strong>.</p>
<p>Learning a new programming language is easier when you have things to do with it, so I decided to write a <a href="https://github.com/gdbinit/evilquest_deobfuscator">decrypter/deobfuscator</a> in Go. In hindsight it wasn’t a smart decision because it’s kind of ugly to deal with buffers in Go and much easier in C (or I don’t know yet the best way to do it in Go).</p>
<div><pre><code data-lang="bash">$ ./evilquest_deobfuscator -s <span>"000Bg{0000090nQ4XL1qPsnl1ZjpKX0lkFoa0000053"</span>
EvilQuest String Deobfuscator
<span>(</span>c<span>)</span> <span>2020</span> Pedro Vilaca. All Rights Reserved
000Bg<span>{</span>0000090nQ4XL1qPsnl1ZjpKX0lkFoa0000053 -&gt; rb+
</code></pre></div><p>Meanwhile, the next day there were again more than 40 thousand new samples with the same size. Confirmed again that the only difference was in strings. While reversing and writing the strings decrypter I noticed that the hash of the sample I was using was modified. That generated a brain click and I went to bed thinking that this wasn’t a big malware campaign (very sad!) because it didn’t make sense with so many samples but it could be a VirusTotal issue. VirusTotal sandbox just got trapped into an analysis loop. This idea was reinforced by the fact that the sample had been submitted from the <strong>ZZ</strong> country code, meaning unknown origin. Connecting these two ideas reinforced my belief that this was the right path.</p>
<p>After I finished the <a href="https://github.com/gdbinit/evilquest_deobfuscator">strings decrypter</a> I could verify that my unique samples campaign hypothesis wasn’t valid. The strings were all the same, just encrypted/obfuscated with different keys.</p>
<p>So, the next step was to verify the code to see what was happening there. This was very easy to find since it’s the first thing the sample does.</p>
<p>At the entrypoint we can observe the mutation function being called first with <code>argv[0]</code> as its argument.</p>
<div><pre><code data-lang="plaintext">000000010001A8D0         public start
000000010001A8D0 start   proc near
(...)
000000010001A8D0         push    rbp
000000010001A8D1         mov     rbp, rsp
000000010001A8D4         sub     rsp, 2F0h
000000010001A8DB         mov     rax, cs:___stack_chk_guard_ptr
000000010001A8E2         mov     rax, [rax]
000000010001A8E5         mov     [rbp+var_8], rax
000000010001A8E9         mov     [rbp+var_94], 0
000000010001A8F3         mov     [rbp+var_98], edi
000000010001A8F9         mov     [rbp+var_A0], rsi
000000010001A900         mov     rax, [rbp+var_A0]
000000010001A907         mov     rdi, [rax]      ; argv[0]
000000010001A90A         call    fg_open_and_reencrypt_cstrings ; binary self modifies here
(...)
</code></pre></div><p>Next follows opening the executable itself with <code>rb+</code> mode (reading and writing). Fun enough there is a memory leak because the decrypted string buffer is malloc’ed in the decryptor function. One of the differences from this sample versus the previous is the increased usage of dynamically allocated memory, increasing the potential for memory leaks. There are a lot more memory leaks all over the code. Xcode Instruments has a nice leak detector (<em>hint, hint</em>).</p>
<div><pre><code data-lang="plaintext">000000010001A840 fg_open_and_reencrypt_cstrings proc near
000000010001A840                                         ; CODE XREF: start+3A↓p
000000010001A840
000000010001A840 var_24          = dword ptr -24h
000000010001A840 __filename      = qword ptr -20h
000000010001A840 FILE_pointer    = qword ptr -18h
000000010001A840 var_10          = qword ptr -10h
000000010001A840 var_4           = dword ptr -4
000000010001A840
000000010001A840         push    rbp
000000010001A841         mov     rbp, rsp
000000010001A844         sub     rsp, 30h
000000010001A848         mov     [rbp+var_10], rdi
000000010001A84C         mov     rdi, [rbp+var_10]
000000010001A850         lea     rax, a000bg0000090nq_18 ; "000Bg{0000090nQ4XL1qPsnl1ZjpKX0lkFoa000"...
000000010001A857         mov     [rbp+__filename], rdi
000000010001A85B         mov     rdi, rax
000000010001A85E         call    fg_decrypt_0000Bg_string ; decrypt/decode string
000000010001A863         mov     rdi, [rbp+__filename]
000000010001A867         mov     rsi, rax  ; "rb+"
000000010001A867                           ; memleak here since the returned ptr was calloc'ed
000000010001A86A         call    _fopen
000000010001A86F         mov     [rbp+FILE_pointer], rax
000000010001A873         cmp     [rbp+FILE_pointer], 0
000000010001A878         jz      loc_10001A890
000000010001A87E         mov     rdi, [rbp+FILE_pointer] ; FILE *
000000010001A882         call    _ftrylockfile
000000010001A887         cmp     eax, 0
000000010001A88A         jz      loc_10001A89C
000000010001A890
000000010001A890 loc_10001A890:            ; CODE XREF: fg_open_and_reencrypt_cstrings+38↑j
000000010001A890         mov     [rbp+var_4], 0FFFFFFFFh
000000010001A897         jmp     loc_10001A8C1
000000010001A89C ; ---------------------------------------------------------------------------
000000010001A89C
000000010001A89C loc_10001A89C:            ; CODE XREF: fg_open_and_reencrypt_cstrings+4A↑j
000000010001A89C         mov     rdi, [rbp+FILE_pointer] ; FILE* handle
000000010001A8A0         call    fg_reencrypt_cstrings
000000010001A8A5         mov     rdi, [rbp+FILE_pointer] ; FILE *
000000010001A8A9         call    _funlockfile
000000010001A8AE         mov     rdi, [rbp+FILE_pointer] ; FILE *
000000010001A8B2         call    _fclose
000000010001A8B7         mov     [rbp+var_4], 0
000000010001A8BE         mov     [rbp+var_24], eax
000000010001A8C1
000000010001A8C1 loc_10001A8C1:            ; CODE XREF: fg_open_and_reencrypt_cstrings+57↑j
000000010001A8C1         mov     eax, [rbp+var_4]
000000010001A8C4         add     rsp, 30h
000000010001A8C8         pop     rbp
000000010001A8C9         retn
000000010001A8C9 fg_open_and_reencrypt_cstrings endp
</code></pre></div><p>The <code>fg_reencrypt_cstrings</code> function is previous listing is where the mutation occurs.
The function will find the <code>__cstring</code> section and iterate over its contents, decrypting and encrypting the strings, and write back to the binary. The original binary is already modified when it returns from <code>fg_open_and_reencrypt_cstrings</code> .</p>
<div><pre><code data-lang="c">(...)
<span>for</span> ( j <span>=</span> <span>0</span>; j <span>&lt;</span> sg<span>-&gt;</span>nsects; <span>++</span>j ) {
    v12 <span>=</span> (<span>__int64</span>)sub_100006580(a1, v17, <span>80LL</span>);
    <span>// obfuscated string is "__cstring"
</span><span></span>    v2 <span>=</span> fg_decrypt_0000Bg_string(<span>"000Bg{00000H0nQ4XL1qPsnl3oBkir1CDCUq3Z{iy|22B2MZ0000073"</span>);
    <span>if</span> ( <span>!</span>strcmp((<span>const</span> <span>char</span> <span>*</span>)v12, v2) ) {
        v11 <span>=</span> (<span>__int64</span>)sub_100006580(a1, <span>*</span>(<span>unsigned</span> <span>int</span> <span>*</span>)(v12 <span>+</span> <span>48</span>), <span>*</span>(_QWORD <span>*</span>)(v12 <span>+</span> <span>40</span>));
        v10 <span>=</span> <span>0LL</span>;
        v9 <span>=</span> <span>0LL</span>;
        v8 <span>=</span> <span>0</span>;
        fseek(a1, <span>*</span>(<span>unsigned</span> <span>int</span> <span>*</span>)(v12 <span>+</span> <span>48</span>), <span>0</span>);
        <span>while</span> ( (<span>unsigned</span> <span>__int64</span>)v8 <span>&lt;</span> <span>*</span>(_QWORD <span>*</span>)(v12 <span>+</span> <span>40</span>) ) {
            <span>if</span> ( <span>*</span>(_BYTE <span>*</span>)(v11 <span>+</span> v8) ) {
                <span>++</span>v9;
            }
            <span>else</span> <span>if</span> ( v9 ) {
                v7 <span>=</span> (<span>char</span> <span>*</span>)calloc(<span>1uLL</span>, v9 <span>+</span> <span>1</span>);
                __memcpy_chk(v7, v10 <span>+</span> v11, v9, <span>-</span><span>1LL</span>);
                v6 <span>=</span> fg_decrypt_0000Bg_string(v7);
                __s <span>=</span> (<span>char</span> <span>*</span>)fg_encrypt_0000Bg_string(v6);
                <span>if</span> ( v7 <span>!=</span> v6 ) {
                    v3 <span>=</span> strlen(__s);
                    <span>if</span> ( v3 <span>==</span> strlen(v7) ) {
                        fseek(a1, v10 <span>+</span> <span>*</span>(<span>unsigned</span> <span>int</span> <span>*</span>)(v12 <span>+</span> <span>48</span>), <span>0</span>);
                        fwrite(__s, <span>1uLL</span>, v9, a1);
                        free(v6);
                    }
                }
                free(v7);
                free(__s);
                v10 <span>+=</span> v9 <span>+</span> <span>1</span>;
                v9 <span>=</span> <span>0LL</span>;
            }
            <span>else</span> {
           …</code></pre></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://reverse.put.as/2020/09/17/evilquest-revisited/">https://reverse.put.as/2020/09/17/evilquest-revisited/</a></em></p>]]>
            </description>
            <link>https://reverse.put.as/2020/09/17/evilquest-revisited/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532184</guid>
            <pubDate>Sun, 20 Sep 2020 06:02:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Startups are a complex multivariable equation]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24531852">thread link</a>) | @grwthckrmstr
<br/>
September 19, 2020 | https://www.preetamnath.com/blog/startups-multivariable-equation | <a href="https://web.archive.org/web/*/https://www.preetamnath.com/blog/startups-multivariable-equation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Launching a startup and building it into a successful business requires a multidisciplinary skillset. Because startups are a complex <a href="https://en.wikipedia.org/wiki/Multivariable_calculus" target="_blank">multivariable equation</a>.</p><p>You have moving target, which is somewhat in sight but not really. You’re wearing glasses but objects at a great distance are blurry.&nbsp;</p><p>The multivariable equation looks something like this</p><ul role="list"><li>understanding the market and finding a gap</li><li>coming up with a product thesis to solve the customer’s needs</li><li>finding the right distribution channels that are profitable</li><li>discovering pockets of places to find the initial set of customers</li><li>positioning the solution with the right messaging</li><li>creating the right business model and pricing structure</li><li>building competitive differentiation to fight off competition</li><li>having a founding team that has the right skillset for all the problems listed above and the million others that aren’t</li></ul><figure id="w-node-2bc32fdcbb34-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f66be2bf4382616b86f3dba_startup%20complex%20multivariable%20equation%20photo.jpg" loading="lazy" alt=""></p><figcaption><em>Photo by </em><a href="https://unsplash.com/@barkiple?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank"><em>John Barkiple</em></a></figcaption></figure><p>There’s a million reasons a startup might fail. And you cannot control those million factors of chaos.</p><p>But you can piece together parts of this equation (via discovery) and solve them one by one. Solving a piece of the equation reduces your chances of crash and burn, i.e. increases your chances of success.</p><p>The factors I’ve listed above are some of the more well understood parts of this equation, and ones that you can actually control and influence.</p><p>However, it doesn’t matter if you get only solve a few parts of the equation, because one or two wrong answers such as distribution channels or business model might be enough to kill your business. That’s what runway (frugality, burn rate, funding, customer revenue) is for.</p><p>Even if you get all the above factors right, it takes a lot of time and effort for your business to take off, to build up momentum and achieve <a href="https://www.preetamnath.com/blog/momentum-escape-velocity" target="_blank">escape velocity</a>.</p><p>It boils down to - Can you solve your startup's multivariable equation before you run out of runway?</p><figure id="w-node-c061837fdebd-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f66c1f176b8944f5e9c79f3_startup%20runway.jpg" loading="lazy" alt=""></p><figcaption><em>Photo by </em><a href="https://unsplash.com/@jmoncasi?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank"><em>Jordi Moncasi</em></a><a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText"></a></figcaption></figure><p>This is why a lot of successful businesses don’t do something entirely new and from the ground up. They take something existing and working and improve parts of the equation. </p><p>Zoom took WebEx and made the product delightfully easy to use.</p><p>And similarly, a lot of businesses are copycats. They copy something existing and improve upon it slightly and meaningfully. One can argue that <a href="https://invertedpassion.com/copying-ideas-is-highly-underrated/" target="_blank">copying ideas</a> is highly underrated. </p><p>Instagram Stories is basically Snapchat’s innovation, but they won because the distribution piece of the equation was far ahead.</p><p>Zoom and Instagram simply picked a multivariable equation where some of the unknowns were already solved for.</p></div></div>]]>
            </description>
            <link>https://www.preetamnath.com/blog/startups-multivariable-equation</link>
            <guid isPermaLink="false">hacker-news-small-sites-24531852</guid>
            <pubDate>Sun, 20 Sep 2020 04:15:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Era of Regulatory Grift: TikTok-Oracle, NXP-Qualcomm, Arm-Nvidia]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24531657">thread link</a>) | @ceohockey60
<br/>
September 19, 2020 | https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/ | <a href="https://web.archive.org/web/*/https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="english-version">
                        <p>The dictionary definition of the word “grift” is as follows: “<a href="https://www.merriam-webster.com/dictionary/grift">to acquire money or property illicitly</a>”. It may be a strong word, but also more or less encapsulates the regulatory ethos that’s governing cross-border technology businesses these days.</p><p>The TikTok-Oracle deal flaunts this grifting ethos, but it’s just the latest example of a series of haphazard regulatory actions mired in geopolitical brinkmanship -- a trend that may implicate deals with much larger impact, like the pending Nvidia acquisition of Arm.</p><h2 id="tiktok-oracle">TikTok-Oracle</h2><p>There are still many missing details to the TikTok-Oracle deal, and Trump <a href="https://uk.reuters.com/article/us-usa-tiktok-oracle/trump-raises-questions-about-tiktok-oracle-deal-if-bytedance-ties-remain-idUKKBN2672KD">may not approve the deal</a>. But in the grand scheme of things, many of these details are no longer important, because the spirit of the entire TikTok “soap opera” is cemented: a <strong>regulatory grift </strong>by the Trump administration that enriches its political donor (Larry Ellison), strengthens its campaign message (anti-China, job creation), while doing next to nothing to protect Americans from either intrusive data collection or foreign influence.</p><p>Let’s look at each of these malfeasances.</p><p><strong><em>What Oracle gets.</em></strong> TikTok’s immediate business value accrues to Oracle Cloud to the tune of possibly <a href="https://www.theinformation.com/articles/with-tiktok-deal-oracle-could-gain-billion-dollar-cloud-customer?utm_content=article-4850&amp;utm_campaign=article_email&amp;utm_source=sg&amp;utm_medium=email">$1 billion in annual revenue</a> in the coming years, as it desperately tries to catch up to AWS and Azure. The Oracle brand may also get a boost from this young, cool consumer product, even though Oracle has no experience running such a product. Since I’ve written in detail about TikTok’s business value in “<a href="https://interconnected.blog/what-is-tiktok-worth-to-whom-and-why/"><strong>What is TikTok Worth to Whom and Why?</strong></a>”, I won’t repeat myself here. <strong>One element I did not discuss so explicitly is how valuable TikTok’s user data is to the Oracle data broker business.</strong></p><p>In a nutshell, a data broker sells data to third parties mostly for marketing or advertisement purposes. Oracle’s data broker businesses are euphemistically called <a href="https://www.oracle.com/cx/marketing/">Oracle CX Marketing</a> and <a href="https://www.oracle.com/data-cloud/">Oracle Data Cloud</a>. Having the treasure trove of data that TikTok has already collected is perhaps an even more immediate business boost to Oracle than getting the product’s workload onto its cloud. Ironically (or perhaps appropriately), the person who called out the privacy violations of data brokers like Oracle, Equifax, and others is <a href="https://www.linkedin.com/in/michael-beckerman-9b750a58/"><strong>Michael Berkerman</strong></a><strong>, who is currently TikTok US’s Head of Public Policy</strong>. He did so last year as the then President and CEO of the Internet Association in <a href="https://www.foxnews.com/opinion/michael-beckerman-why-do-we-need-a-federal-privacy-law-ask-the-data-brokers-selling-your-private-information">an OpEd published on Fox News</a> -- a “media” outlet that the President of the United States most certainly pays attention to. I wonder how long Berkerman will be sticking around, if at all, after the TikTok-Oracle deal closes.</p><p>Lastly, Oracle will likely get a <a href="https://www.ft.com/content/58eb7c26-2154-477f-af19-19157ae29261">minority stake in TikTok</a> with ByteDance still being the majority shareholder. This piece of equity in one of the most valuable private tech companies in the world -- trading at a $140 billion valuation in the secondary market earlier this year -- is something that Oracle would have no business getting in a normal investing situation. Not a bad deal <a href="https://www.businessinsider.com/oracle-billionaire-larry-ellison-is-fundraising-for-donald-trump-2020-2">for hosting a single fundraiser</a>.</p><p><strong><em>What the Trump campaign gets.</em> </strong>Being more “anti-China” than Biden and going after the Vice President’s son’s business dealings in China has been a messaging tentpole of the Trump re-election campaign. It can now claim credit for acting tough and forcing a marquee Chinese tech company to “surrender” its crown jewel product to America, while accomplishing none of those things, because TikTok’s core technology is staying with ByteDance in China.</p><p>The Oracle bid also apparently includes a “<strong>20,000 new jobs” </strong>commitment -- a typical public relations promise with no legally binding effect. Being “anti”-China while “creating” jobs is a strong one-two punch as we approach the final stretch of the 2020 election season, so much so that Secretary Mnuchin couldn't wait to sell the 20,000 jobs message on CNBC the day after Oracle’s winning bid was made public, <em>even though</em> the deal hasn’t been approved or finalized yet.</p><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/ZPRPswu2Cyc?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>TikTok US’s current payroll is about 1,400 people. <strong>That would be an almost 20x increase in headcount.</strong> Theoretically possible? Sure. Practical and sensible? Hardly.</p><p><em><strong>What the American people get.</strong> </em>Nothing, except that they still get to watch cool dance videos and <a href="https://www.tiktok.com/@rosssmith/video/6797540353730743557">grandmas do this</a> on their phones. We have no new information or answer to any of the three legitimate concerns surrounding TikTok:</p><ul><li>Does it send data to China?</li><li>Is its user data collection practices proper?</li><li>Is it being used as a tool for foreign influence?</li></ul><p>To be clear, there <em>are</em> regulatory tools based on technology at our disposal to answer these questions, <strong>with or without Oracle</strong>. I’ve laid them out in detail in “<a href="https://interconnected.blog/a-framework-to-dis-trust-and-verify-tiktok/"><strong>A Framework to (Dis)trust and Verify TikTok</strong></a>”. Unfortunately, it’s clear as day that the Trump administration is only interested in the political messaging benefits of TikTok-Oracle, not doing the actual work that is required to protect the interests of the American people.</p><p><strong>There is another winner that we should all take note of: <em>Chinese regulators.</em></strong></p><p>Chinese regulators typically use their power to force technology and IP transfers from foreign entities to domestic companies via joint-ventures or outright acquisitions -- <strong>another form of regulatory grift</strong>. This TikTok-Oracle deal is the first time to my knowledge, where Chinese regulators use their power to protect a home-grown technology from being <em>transferred out</em> to a foreign entity.</p><p>This win has just as much to do with exerting their regulatory power as the sucker on the other side of the negotiation table. This dynamic isn’t new, if we look at the failed NXP-Qualcomm acquisition in 2018.</p><h2 id="nxp-qualcomm">NXP-Qualcomm</h2><p>Qualcomm’s attempt to buy the Dutch semiconductor maker, NXP, for $44 billion was abandoned, because it could not get approval from Chinese regulators. This occurred during the previous height of tension when the U.S. and China were tossing retaliatory trade tariffs at each other like a couple of teenage boys in a backyard snowball fight.</p><p>The Chinese regulators did not disapprove of the deal and asked for changes to gain approval, which would’ve been a good faith move. <strong>They just ignored it and let the deadline pass.</strong> This is after Secretary Mnuchin and his Commerce Department counterpart, Wilbur Ross, lobbied the Chinese Vice Minister, Liu He, and Ambassador to the US, Cui Tiankai, to approve the deal. The backdrop of this lobbying was Trump easing the penalties on the Chinese telecom equipment maker, ZTE, for violating U.S. sanction rules with regard to Iran and North Korea -- hoping for some reciprocity and dealmaking.</p><p>This foolish hope did not pan out. Instead, Qualcomm, America’s national champion in the race to 5G, had to fork up a <a href="https://www.wsj.com/articles/qualcomm-plans-to-abandon-nxp-deal-1532549728">$2 billion cancellation fee to NXP and increase its stock buyback program from $10 to $30 billion</a> to appease its shareholders. What’s more, this turn of events showed Chinese regulators that given the <strong>interconnected nature of the global economy</strong>, particularly technology businesses, they have far-reaching authority and leverage to shape deals, events, and technology acquisition vis-a-vis <strong>a tough-talking, weak-acting </strong>Trump administration. It is a key reversal in fortune, when a large swath of China’s technology sector, particularly Huawei, has been hammered by U.S. sanctions.</p><p>Qualcomm-NXP was a defensive play -- not approving a deal. TikTok-Oracle is a proactive play -- not losing control of domestic technology. <strong>There’s now an opportunity for even more aggressive “regulatory grift”: Arm-Nvidia.</strong></p><h2 id="arm-nvidia">Arm-Nvidia</h2><p>It’s hard to comprehend the long-term impact that Nvidia’s $40 billion acquisition of Arm will have on the future of technology. One thing is certain though: it’s way more important than TikTok and Oracle, separately and combined.</p><p>We shouldn’t assume the Arm-Nvidia deal will be closed as expected given all the corporate governance issues with Arm’s China operation. Arm China’s CEO, Allen Wu, has been fired by the board for various acts of conflicts of interest and double dealing, <a href="https://www.zdnet.com/article/arms-fired-china-jv-head-refuses-to-leave-company-reps-banned-from-company-premises/">yet refuses to leave</a>. Arm’s CEO, Simon Segars, is trying to assure the public that the mess <a href="https://www.yicaiglobal.com/news/chip-designer-arm-to-solve-chinese-jv-management-issue-before-nvidia-buyout">will be cleaned up </a>in order to not endanger the sale, but he’s not in a position of leverage, now that the deal is public and the expectations are high. (Nvidia’s market cap increased by $17.5 billion the day after the deal was announced.)</p><p>Furthermore, the Arm China division is a joint-venture where 51% of the entity is owned by a consortium of these three funds:</p><ul><li><a href="https://en.wikipedia.org/wiki/China_Investment_Corporation">China Investment Corporation</a> (China’s sovereign wealth fund)</li><li><a href="https://en.wikipedia.org/wiki/Silk_Road_Fund">Silk Road Fund</a> (a state-owned fund focused on projects related to the Belt &amp; Road Initiative)</li><li><a href="https://en.wikipedia.org/wiki/Temasek_Holdings">Temasek Holding</a> (Singapore’s sovereign wealth fund)</li></ul><p>The other 49% is owned by Softbank via Arm. The joint venture structure is par for the course for any foreign technology company doing business in China. But such a tight ownership by state-owned funds means Chinese regulators (and Singaporean regulators for that matter) have strong jurisdictional power over the deal from the get-go. NXP-Qualcomm’s legal hook was a tenuous nexus. TikTok-Oracle’s hook was established by <a href="https://en.pingwest.com/a/7657">an eleventh hour change</a> to the government’s technology “entity list”. Arm-Nvidia doesn’t need any extra work for regulators to aggressively insert themselves into the picture.</p><p>What will the Chinese regulators do is hard to tell at this moment. However, given the fact that Arm’s chip design IP has a 95% global market share in mobile devices and is <a href="https://www.zdnet.com/article/aws-graviton2-what-it-means-for-arm-in-the-data-center-cloud-enterprise-aws/">making inroads into cloud data centers</a> as well, <strong>it’s likely that China will either veto the deal (like NXP-Qualcomm) or try to keep any semiconductor IP that Arm China has even a tangential connection to</strong>. Some Chinese tech media <a href="https://mp.weixin.qq.com/s/W8nhj6udDTdr54ui7_0RIQ">are already speculating about a veto</a>. Using this opportunity to acquire some key technology also makes sense, because by <em>not</em> doing so, China runs the monumental risk of having the entire Arm ecosystem be subject to U.S. sanctions after it becomes a property of Nvidia. An “<strong>Arm sanction</strong>” would cripple China’s entire mobile technology sector, where domestic chip design options barely exist and the open source option, RISC-V, still …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/">https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/</a></em></p>]]>
            </description>
            <link>https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24531657</guid>
            <pubDate>Sun, 20 Sep 2020 03:08:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Prodigal Techbro]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24531490">thread link</a>) | @cyunker
<br/>
September 19, 2020 | https://conversationalist.org/2020/03/05/the-prodigal-techbro/ | <a href="https://web.archive.org/web/*/https://conversationalist.org/2020/03/05/the-prodigal-techbro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

               <div>


                  <p><em>The tech executive turned data justice warrior is celebrated as a truth-telling hero, but there’s something a bit too smooth about this narrative arc.</em></p><div><p><img src="https://conversationalist.org/wp-content/uploads/2020/03/Tristan-Harris.jpg" alt="" srcset="https://conversationalist.org/wp-content/uploads/2020/03/Tristan-Harris.jpg 799w, https://conversationalist.org/wp-content/uploads/2020/03/Tristan-Harris-300x200.jpg 300w, https://conversationalist.org/wp-content/uploads/2020/03/Tristan-Harris-768x512.jpg 768w" sizes="(max-width: 640px) 100vw, 640px"></p><p><span>Credit: Stuart Isett/Fortune</span><span></span></p></div>
<p>A few months ago, I was contacted by a senior executive who was about to leave a marketing firm. He got in touch because I’ve worked on the non-profit side of tech for a long time, with lots of volunteering on digital and human rights. He wanted to ‘give back’. Could I put him in touch with digital rights activists? Sure. We met for coffee and I made some introductions. It was a perfectly lovely interaction with a perfectly lovely man. Perhaps he will do some good, sharing his expertise with the people working to save democracy and our private lives from the surveillance capitalism machine of his former employers. The way I rationalized helping him was: firstly, it’s nice to be nice; and secondly, movements are made of people who start off far apart but converge on a destination. And isn’t it an unqualified good when an insider decides to do the right thing, however late?</p>
<p>The Prodigal Son is a New Testament parable about two sons. One stays home to work the farm. The other cashes in his inheritance and gambles it away. When the gambler comes home, his father slaughters the fattened calf to celebrate, leaving the virtuous, hard-working brother to complain that all these years he wasn’t even given a small goat to share with his friends. His father replies that the prodigal son ‘was dead, now he’s alive; lost, now he’s found’. Cue party streamers. It’s a touching story of redemption, with a massive payload of moral hazard. It’s about coming home, saying sorry, being joyfully forgiven and starting again. Most of us would love to star in it, but few of us will be given the chance.</p>
<p>The Prodigal Tech Bro is a similar story, about tech executives who experience a sort of religious awakening. They suddenly see their former employers as toxic, and reinvent themselves as experts on taming the tech giants. They were lost and are now found. They are warmly welcomed home to the center of our discourse with invitations to write opeds for major newspapers, for think tank funding, book deals and TED talks. These guys – and yes, they are all guys – are generally thoughtful and well-meaning, and I wish them well. But I question why they seize so much attention and are awarded scarce resources, and why they’re given not just a second chance, but also the mantle of moral and expert authority.</p>
<p>I’m glad that Roger McNamee, the early Facebook investor, has <a href="https://www.theguardian.com/world/2020/feb/29/rebecca-solnit-younger-feminists-shift-understanding-give-new-tools">testified to the U.S. Congress</a> about Facebook’s wildly self-interested near-silence about its amplification of Russian disinformation during the 2016 presidential election. I’m thrilled that Google’s ex-‘design ethicist’, Tristan Harris, “<a href="https://www.theguardian.com/world/2020/feb/29/rebecca-solnit-younger-feminists-shift-understanding-give-new-tools">the </a><em>closest thing Silicon Valley has to a conscience,</em>“(startlingly faint praise) now runs a Center for Humane Technology, exposing the mind-hacking tricks of his former employer. I even <a href="https://www.youtube.com/watch?v=3hSrUaSNFSY&amp;t=2309s">spoke</a> —critically but, I hope, warmly—at the book launch of James Williams, another ex-Googler turned attention evangelist, who “<a href="https://en.wikipedia.org/wiki/Center_for_Humane_Technology">co-founded the movement</a>”of awareness of designed-in addiction. I wish all these guys well. I also wish that the many, exhausted activists who didn’t take money from Google or Facebook could have even a quarter of the attention, status and authority the Prodigal Techbro assumes is his birth-right.</p>
<p>Today, when the tide of public opinion on Big Tech is finally turning, the brothers (and sisters) who worked hard in the field all those years aren’t even invited to the party. No fattened calf for you, my all but unemployable tech activist. The moral hazard is clear; why would anyone do the right thing from the beginning when they can take the money, have their fun, and then, when the wind changes, convert their status and relative wealth into special pleading and a whole new career?</p>
<p>Just half an hour flipping through my contacts produced half a dozen friends and acquaintances who didn’t require a ‘road to Damascus’ conversion to see what was wrong with big tech or the ways governments abuse it. Nighat Dad runs the <a href="https://digitalrightsfoundation.pk/">Digital Rights Foundation in Pakistan</a>, defending online freedom of expression and privacy for women, minorities and dissidents. That’s real courage. <a href="https://privacyinternational.org/people/95/gus-hosein">Gus Hosein</a> has worked in tech and human rights for over 20 years, runs Privacy International, the UK-based non-profit, and is the most visionary thinker I know on how to shake up our assumptions about why things are as they are.&nbsp; <a href="https://biancawylie.com/">Bianca Wylie </a>founded the volunteer-run Open Data Institute Toronto, and works on open data, citizen privacy and civic engagement. The “<a href="https://www.citylab.com/life/2018/12/bianca-wylie-interview-toronto-quayside-protest-criticism/574477/">Jane Jacobs of the Smart Cities Age</a>,” she’s been a key figure in opening up and slowing down Alphabet’s Sidewalk Labs juggernaut in Toronto. Aral Balkan runs <a href="https://small-tech.org/">Small Technology Foundation </a>and works on both the tools and the policies to resist surveillance capitalism. Unafraid of being unpopular, even with other activists, Balkan freely hammers rights organizations or conferences for taking big tech’s sponsorship money while criticizing the companies’ practices. In the western Balkans, <a href="https://hvale.me/">hvale vale</a><a href="#_ftn10" name="_ftnref10"></a> works tirelessly and cheerfully on women’s rights, sexual rights and the political and practical path to a feminist internet. <a href="https://en.wikipedia.org/wiki/Robin_Gross">Robin Gross</a>, &nbsp;a Californian intellectual property lawyer, could have put her persistence and sheer pizazz to work defending big entertainment companies, but instead she’s worked for decades against the copyright maximalism that strangles artists’ creativity and does nothing to increase their incomes. I would love to hear their voices amplified, not (just) the voices of those who took a decade and more to work out the rottenness at the core of big tech.</p>
<p>Ex-Google lobbyist Ross Lajeunesse left the company in 2019 over its censored search engine for China and also because of homophobic, sexist and racist work practices. He’s now running for a Democratic senate nomination, and recently wrote a classic of the ‘scales have fallen from my eyes’ genre, called “I Was Google’s Head of International Relations. <a href="https://medium.com/@rossformaine/i-was-googles-head-of-international-relations-here-s-why-i-left-49313d23065">Here’s Why I Left</a>.” Its lede is <em>“The company’s motto used to be “Don’t be evil.” Things have changed.”</em></p>
<p>Really? Has Google really changed? Lajeunesse joined in 2008, years into Google’s multi-billion dollar <a href="https://www.bloomberg.com/news/articles/2010-10-21/google-2-4-rate-shows-how-60-billion-u-s-revenue-lost-to-tax-loopholes">tax avoidance</a>, <a href="https://www.cnet.com/news/google-hit-with-job-discrimination-lawsuit/">sexist labor practices</a> and <a href="http://news.bbc.co.uk/2/hi/technology/6740075.stm">privacy hostility</a> and continued to work there through the years of <a href="https://www.bbc.co.uk/news/technology-40406542">antitrust fines</a>, misuse of <a href="https://www.bbc.com/news/technology-40406542">personal health data</a>, <a href="https://www.cnet.com/news/judge-rejects-324-5m-wage-fixing-settlement-struck-by-apple-google-others/">wage fixing</a>, and financially <a href="https://www.nytimes.com/2017/08/30/us/politics/eric-schmidt-google-new-america.html">pressuring think tanks</a>. Google didn’t change. It just started treating some of its insiders like it already treated outsiders. That only looks like radical change if you’ve never thought too hard about what you are doing and to whom.</p>
<p>One hundred thousand people work for Google/Alphabet; some of them have much more power than others. The point isn’t whether Lajeunesse is or isn’t culpable for the many acts of the enormous company he represented—as its chief lobbyist in Asia for several years—it’s that of all the people who spent the decade of 2010-20 working thanklessly to expose and reduce the firm’s monopolistic abuse and assault on global privacy, it’s the ex-lobbyist who gets our attention now.</p>
<p>We all need second chances. Even if we don’t need those fresh starts ourselves, we want to live in a world where people have a reason to do better. But the prodigal tech bro’s redemption arc is so quick and smooth it’s barely a road bump. That’s because we keep skipping the most important part of the prodigal son story—where he hits rock bottom. In the original parable, the prodigal son wakes up in a pig sty, starving, and realizes his father’s servants now live better than he does. He resolves to go home to the people and place he did not value or respect before. He will beg to be one of his father’s servants. He accepts his complete loss of status. But instead of chastising and punishing his prodigal son, the rejoicing father greets him joyfully and heads off the apology with a huge party. It’s a great metaphor for how to run a religion, but a lousy way to run everything else.</p>
<p>Prodigal tech bro stories skip straight from the past, when they were part of something that—surprise!—turned out to be bad, to the present, where they are now a moral authority on how to do good, but without the transitional moments of revelation and remorse. &nbsp;But the bit where you say you got things wrong and people were hurt? That’s the most important part. It’s why these corporatized reinventions feel so slick and tinny, and why so many of the comments on Lajeunesse’s <a href="https://medium.com/@rossformaine/i-was-googles-head-of-international-relations-here-s-why-i-left-49313d23065">train wreck post</a> on Medium were critical. The journey feels fake. These ‘I was lost but now I’m found, please come to my TED talk’ accounts typically miss most of the actual journey, yet claim the moral authority of one who’s ‘been there’ but came back. It’s a teleportation machine, but for ethics.</p>
<p>(While we’re thinking about the neatly elided parts of the prodigal tech bro story, let’s dwell for one moment on the deletion of the entire stories of so many women and people of color barely given a first chance in Silicon Valley, let alone multiple reinventions.)</p>
<p>The only thing more fungible than cold, hard cash is privilege. The prodigal tech bro doesn’t so much take an off-ramp from the relatively high status and well-paid job he left when the scales fell from his eyes, as zoom up an on-ramp into a new sector that accepts the reputational currency he has accumulated. He’s not joining the resistance. He’s launching a new kind of start-up using his industry contacts for seed-funding in return for some reputation-laundering.</p>
<p>So what? Sure, it’s a little galling, but where’s the harm?</p>
<p>Allowing people who share responsibility for our tech dystopia to keep control of the narrative means we never get to the bottom of how and why we got here, and we artificially narrow the possibilities for where we go next. And centering people who were insiders before and claim to be leading the outsiders …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://conversationalist.org/2020/03/05/the-prodigal-techbro/">https://conversationalist.org/2020/03/05/the-prodigal-techbro/</a></em></p>]]>
            </description>
            <link>https://conversationalist.org/2020/03/05/the-prodigal-techbro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24531490</guid>
            <pubDate>Sun, 20 Sep 2020 02:06:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Apple Notes Protobuf]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24531472">thread link</a>) | @todsacerdoti
<br/>
September 19, 2020 | https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/ | <a href="https://web.archive.org/web/*/https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody"> <p><strong>TL;DR</strong>: This post explains portions of two protobufs used by Apple, one for the Note format itself and another for embedded objects. More importantly, it explains how you can figure out the structure of protobufs.</p> <!--more--> <h2 id="background">Background</h2> <p>Previous entries in this series covered how to deal with <a href="https://ciofecaforensics.com/2020/01/10/apple-notes-revisited/">Apple Notes</a> and the <a href="https://ciofecaforensics.com/2020/01/13/apple-notes-revisited-easy-embedded-objects/">embedded objects</a> in them, including <a href="https://ciofecaforensics.com/2020/01/14/apple-notes-revisited-embedded-tables/">embedded tables</a> and <a href="https://ciofecaforensics.com/2020/01/20/apple-notes-revisited-galleries/">galleries</a>. Throughout these posts, I have referred to the fact that Apple uses protocol buffers (protobufs) to store the information for both notes and the embedded objects within them. What I have not yet done is actually provide the .proto file that was used to generate the Ruby output, or explained how you can develop the same on your app of interest. If you only care about the first part of that, you can view the <a href="https://github.com/threeplanetssoftware/apple_cloud_notes_parser/blob/master/proto/notestore.proto">.proto file</a> or the <a href="https://github.com/threeplanetssoftware/apple_cloud_notes_parser/blob/master/proto/protobuf_config.py">config</a> I use for <a href="https://github.com/jmendeth/protobuf-inspector">protobuf-inspector</a>. Both of these files are just a start to pull out the important parts for processing and can certainly be improved.</p> <p>As with previous entries, I want to make sure I give credit where it is due. After pulling apart the Note protobuf and while I was trying to figure out the table protobuf, I came across <a href="https://github.com/dunhamsteve">dunhamsteve’s</a> work. As a result, I went back and modified some of my naming to better align to what he had <a href="https://github.com/dunhamsteve/notesutils/blob/master/notes.md">published</a> and added in some fields like version which I did not have the data to discover.</p> <h2 id="what-is-a-protocol-buffer">What is a Protocol Buffer?</h2> <p>To quote directly from <a href="https://developers.google.com/protocol-buffers">the source</a>,</p> <blockquote> <p>Protocol buffers are Google’s language-neutral, platform-neutral, extensible mechanism for serializing structured data – think XML, but smaller, faster, and simpler. You define how you want your data to be structured once, then you can use special generated source code to easily write and read your structured data to and from a variety of data streams and using a variety of languages.</p> </blockquote> <p>What does that mean? It means a protocol buffer is a way you can write a specification for your data and use it in many projects and languages with one command. The end result is source code for whatever language you are writing in. For example, <a href="https://github.com/sballin/alfred-search-notes-app/blob/master/search/proto/notestore.pb.go">Sean Ballinger’s Alfred Search Notes App</a> used my <code>notestore.proto</code> file to compile to Go instead of Ruby to interact with Notes on MacOS. When you use it in your program, the data which you save will be a raw data stream which won’t look like much, but will be intelligable to any code with that protobuf definition.</p> <p>The definition is generally a <code>.proto</code> file which would look something like:</p> <figure><pre><code data-lang="protobuf"><span>syntax</span> <span>=</span> <span>"proto2"</span><span>;</span>

<span>// Represents an attachment (embedded object)</span>
<span>message</span> <span>AttachmentInfo</span> <span>{</span>
   <span>optional</span> <span>string</span> <span>attachment_identifier</span> <span>=</span> <span>1</span><span>;</span>
   <span>optional</span> <span>string</span> <span>type_uti</span> <span>=</span> <span>2</span><span>;</span>
<span>}</span></code></pre></figure> <p>This definition would have just one message type (AttachmentInfo), with two fields (attachment_identifier and type_uti), both optional. This is using the <code>proto2</code> syntax.</p> <h2 id="why-care-about-protobufs">Why Care About Protobufs</h2> <p>Protobufs are everywhere, especially if you happen to be working with or looking at Google-based systems, such as Android. Apple also uses a lot of them in iOS, and for people that have to support both operating systems, using a protobuf makes the pain of maintaining two different code bases slightly less annoying because you can compile the same definition to different languages. If you are in forensics, you may come across something that looks like it isn’t plaintext and discover that you’re actually looking at a protobuf. When it comes specifically to Apple Notes, protobufs are used both for the Note itself and the attachments.</p> <h2 id="how-to-use-a-proto-file">How to Use a .proto file</h2> <p>Assuming you have a <code>.proto</code> file, either from building one yourself or from finding one from your favorite application, you can compile it to your target language using <a href="https://github.com/protocolbuffers/protobuf/releases">protoc</a>. The resulting file can then be included in your project using whatever that language’s include statement is to create the necessary classes for the data. For example, when writing Apple Cloud Notes Parser in Ruby, I used <code>protoc --ruby_out=. ./proto/notestore.proto</code> to compile it and then <code>require_relative 'notestore_pb.rb'</code> in my code to include it.</p> <p>If I wanted instead to add in support for python, I would only have to make this change: <code>protoc --ruby_out=. --python_out=. ./proto/notestore.proto</code></p> <h2 id="how-can-you-find-a-protobuf-definition-file">How Can You Find a Protobuf Definition File?</h2> <p>If you come up against a protobuf in an application you are looking at, you might be able to find the <code>.proto</code> protobuf definition file in the application itself or somewhere on the forensic image. I ended up going through an iOS 13 forensic image earlier this year and found that Apple still had some of theirs on disk:</p> <figure><pre><code data-lang="shell"><span>[</span>notta@cuppa iOS13_logical]<span>$ </span>find | <span>grep</span> <span>'\.proto$'</span>
./System/Library/Frameworks/MultipeerConnectivity.framework/MultipeerConnectivity.proto
./System/Library/PrivateFrameworks/ActivityAchievements.framework/ActivityAchievementsBackCompat.proto
./System/Library/PrivateFrameworks/ActivityAchievements.framework/ActivityAchievements.proto
./System/Library/PrivateFrameworks/CoreLocationProtobuf.framework/Support/Harvest/CLPCollectionRequest.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingDatabaseCodables.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingDomainCodables.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingInvitationCodables.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingCloudKitCodables.proto
./System/Library/PrivateFrameworks/CloudKitCode.framework/RecordTransport.proto
./System/Library/PrivateFrameworks/RemoteMediaServices.framework/RemoteMediaServices.proto
./System/Library/PrivateFrameworks/CoreDuet.framework/knowledge.proto
./System/Library/PrivateFrameworks/HealthDaemon.framework/Statistics.proto
./System/Library/PrivateFrameworks/AVConference.framework/VCCallInfoBlob.proto
./System/Library/PrivateFrameworks/AVConference.framework/captions.proto</code></pre></figure> <p>Some of these are <em>really</em> interesting when you look at them, particularly if you care about their location data and pairing. You don’t even have to have an iOS forensic image sitting around as all of the same files are included in your copy of MacOS 10.15.6, as well, if you run <code>sudo find /System/ -iname "*.proto"</code>. I am not including any interesting snippets of those because they are copyrighted by Apple and I would explicitly note that none are related to Apple Notes or the contents of this post.</p> <p>In general, you should not expect to find these definitions sitting around since the definition file isn’t needed once the code is generated. For more open source applications, you might be interested in some <a href="https://www.google.com/search?q=ext%3Aproto++AND+inurl%3Aproto+AND+message+AND+proto2">Google Dorks</a>, especially when looking at Android artifacts, as you might still find them.</p> <h2 id="how-can-you-rebuild-the-protobuf">How Can You Rebuild The Protobuf?</h2> <p>But what if you can’t find the definition file, how can you rebuild it yourself? This was the most interesting part of rewriting Apple Cloud Notes Parser as I had no knowledge of how Apple typically represents data, nor protobufs, so it was a fun learning adventure.</p> <p>If you have nothing else, the <code>protoc --decode-raw</code> command can give you an intial look at what is in the data, however this amounts to not much more than pretty printing a JSON object, it doesn’t do a great job of telling you you what might be in there. I made heavy use of mildsunrise’s <a href="https://github.com/mildsunrise/protobuf-inspector">protobuf-inspector</a> which at least makes an attempt to tell you what you might be looking at. Another benefit to using this is that it lets you incrementally build up your own definition by editing a file named <code>protobuf_config.py</code> in the protobuf-insepctor folder.</p> <p>For example, below is the output from protobuf-inspector when I ran it on the Gunzipped contents of one of the first notes in my test database.</p> <figure><pre><code data-lang="python"><span>[</span><span>notta</span><span>@</span><span>cuppa</span> <span>protobuf</span><span>-</span><span>inspector</span><span>]</span><span>$</span> <span>python3</span> <span>main</span><span>.</span><span>py</span> <span>&lt;</span> <span>~/</span><span>note_18</span><span>.</span><span>blob</span> 
<span>root</span><span>:</span>
    <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
    <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
        <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
        <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
        <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
            <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>"Pure blob title"</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>2</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>8</span><span>)</span>
                <span>4</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>3</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>10</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>4</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>14</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>10</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                    <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                    <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4294967295</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                    <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                    <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4294967295</span>
            <span>4</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                    <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>bytes</span> <span>(</span><span>16</span><span>)</span>
                        <span>0000</span>   <span>EE</span> <span>FE</span> <span>10</span> <span>DA</span> <span>5</span><span>A</span> <span>79</span> <span>43</span> <span>25</span> <span>88</span> <span>BA</span> <span>6</span><span>D</span> <span>CA</span> <span>E2</span> <span>E9</span> <span>B7</span> <span>EC</span>                          <span>....</span><span>ZyC</span><span>%</span><span>..</span><span>m</span><span>.....</span>
                    <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>24</span><span>)</span>
                    <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>9</span><span>)</span>
            <span>5</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>3</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>)</span>
            <span>5</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>3</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>)</span>
            <span>5</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
          …</code></pre></figure></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/">https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/</a></em></p>]]>
            </description>
            <link>https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24531472</guid>
            <pubDate>Sun, 20 Sep 2020 02:00:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Do Neobanks Make Money?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24531372">thread link</a>) | @michaelm244
<br/>
September 19, 2020 | https://blog.mattheakis.com/how_do_neobanks_make_money/ | <a href="https://web.archive.org/web/*/https://blog.mattheakis.com/how_do_neobanks_make_money/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <article>
  
  <time datetime="2020-09-15T06:52:31+00:00">15 Sep 2020</time>
  <p>Neobanks are on a tear and users are loving them. Neobanks are online-only banks, typically funded by venture capital, that piggy-back on top of an existing institution’s banking license and offer a way for customers to store/spend money. Examples include Revolut, Nubank, Chime, Simple, N26, and more. They have a real shot at becoming the mainstream banking choice for customers over the next decade. Nubank, the most popular neobank in Brazil, recently <a href="https://www.reuters.com/article/us-nubank-brazil-growth/brazilian-fintech-nubank-has-grown-to-15-million-users-ceo-idUSKBN1WQ26C" target="_blank">announced</a> that they have 15 million customers. For reference, Wells Fargo has <a href="https://google.com/" target="_blank">22 million active users</a> on its mobile app. Neobanks are a rising force and key in understanding where the financial services industry is headed.</p>

<p>But how do these neobanks make money? The imprecise answer of “they make money when you swipe their card” doesn’t tell you much. In this post, I’ll concretely show how the mechanics of a neobank’s business model works.</p>

<p>Let’s take a look at <a href="https://www.chime.com/" target="_blank">Chime</a>, the largest consumer neobank in the US. Chime’s core offering is a debit card alongside checking and savings accounts. They have nifty features like the ability to receive your paycheck two days early, no overdraft fees, and 100% mobile banking. With 60% of Americans not being able to cover a surprise $1,000 expense, a 2-day advance on a paycheck can be a huge relief for managing expenses. And the nixing of overdraft fees is a massive help for the <a href="https://www.pymnts.com/news/banking/2018/banking-overdraft-fees-cfbp-credit-unions/" target="_blank">US consumers paying a mind-boggling $34 billion/year</a> in overdraft fees. These differentiated features have led to Chime amassing <a href="https://techcrunch.com/2019/09/04/chime-now-has-5-million-customers-and-introduces-overdraft-alternative/" target="_blank">5 million customers</a> and <a href="https://www.businessinsider.com/chime-set-to-quadruple-revenue-in-2019-2019-11" target="_blank">$200 million in annualized revenue</a>.</p>

<p><strong>A neobank like Chime primarily makes money in two ways:</strong></p>

<ol>
  <li>Interchange revenue paid by payment processors (e.g., Stripe) when they process a payment for a Chime card</li>
  <li>Collecting interest from users’ deposits</li>
</ol>

<p>Although some neobanks have different revenue streams (e.g., Wealthfront charges users roboadvisor fees as a percentage of the total value of assets stored with them), interchange and deposits interest are the two largest and most common revenue streams for neobanks. These are also some of the largest revenue streams for big banks (lending though typically being the largest).</p>

<h3 id="interchange"><strong>Interchange</strong></h3>

<p>Interchange revenue is money that a card issuer (such as Chime) receives when someone swipes their card. Interchange is paid by the merchant through payment processing fees. The merchant is the party accepting a card payment in return for goods/services (e.g., your local supermarket). As an example, if a merchant uses <a href="https://stripe.com/" target="_blank">Stripe</a> for payment processing and is paying the standard <a href="https://stripe.com/pricing" target="_blank">2.9%</a> in transaction fees, Stripe will use a portion of that 2.9% to pay the card issuer.</p>

<h2><img src="https://www.helcim.com/pictures/credit-card-processing-flow-152858808066.jpg" alt="card_process"></h2>

<p>Image Credit: <a href="https://www.helcim.com/article/how-credit-card-processing-works/" target="_blank">Helcim</a></p>

<p>The specific amount paid to the card issuer depends on a number of factors and it varies for every transaction. The most important factors are:</p>

<ul>
  <li>Whether the card is debit or credit
    <ul>
      <li>Credit is significantly higher interchange</li>
    </ul>
  </li>
  <li>Whether the card has specific rewards/perks
    <ul>
      <li><a href="https://usa.visa.com/pay-with-visa/cards/visa-credit-cards/visa-infinite-credit-cards.html" target="_blank">Visa Infinite</a> (many rewards/perks) has a higher interchange rate than the standard Visa card</li>
    </ul>
  </li>
  <li>The type of the merchant for a given transaction
    <ul>
      <li>Hotels have some of the highest interchange rates</li>
    </ul>
  </li>
</ul>

<p>Ultimately the card network (e.g., Visa) decides what the interchange rates are. The key equation for an interchange revenue stream is:</p>

<p><i>avg. interchange rate * total transaction volume</i></p>

<p>In Chime’s case, their cards are on the Visa network so Visa decides how much interchange they receive. The Visa interchange rates, along with Chime’s specific rates, are <a href="https://usa.visa.com/dam/VCOM/download/merchants/visa-usa-interchange-reimbursement-fees.pdf" target="_blank">public</a> <sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>. Depending on the type of merchant and transaction, Chime earns between 0.8% - 1.9% of a transaction’s amount, Although it’s impossible to know the exact amount of interchange Chime receives without knowing the distribution of Chime users’ spending, a reasonable guess based on aggregate consumer spending would put Chime’s average interchange rate at 1.25%<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>. This means that Chime receives around 1.25% of _all spending on their cards_. Not bad! There are still a handful of costs that Chime has to pay per transaction:</p>

<ul>
  <li>Intermediary card processors
    <ul>
      <li>Example: Chime uses <a href="https://www.galileo-ft.com/" target="_blank">Galileo</a>, which likely charges them anywhere from 0.05% - 0.4% of transaction volume</li>
    </ul>
  </li>
  <li>Fraud: if a customer loses their card and a thief spends money on it, Chime may have to cover the cost
    <ul>
      <li>Note: keep in mind that since Chime is offering debit cards, not credit cards, there is no risk of the customer not paying back Chime for transactions</li>
    </ul>
  </li>
  <li>Server costs: the server that has to process a transaction</li>
</ul>

<p>Even with these costs, Chime is still making a handsome profit per transaction. Being the card issuer, as they are here, is a very high-margin business.</p>

<h3 id="deposits-interest"><strong>Deposits Interest</strong></h3>

<p>Interest revenue is earned by a depository institution investing customer funds in low-risk securities. The depository institution typically also pays the customer for keeping their deposits at the institution. The key equation for profitability of this revenue stream is:</p>

<p><i>(% interest earned - % interest paid to depositor) * deposits amount</i></p>

<p>The <em>% interest earned</em> for neobanks is typically equal to the <a href="https://fred.stlouisfed.org/series/FEDFUNDS" target="_blank">effective federal funds rate</a>. Because the federal funds rate is constantly shifting, the profitability of this revenue stream for neobanks is constantly shifting. This is why neobanks frequently change the interest rate offered to depositors (see <a href="https://blog.wealthfront.com/category/product-news/" target="_blank">Wealthfront’s blog</a> as an example). This is a stark contrast to big banks however. A key benefit of a banking charter is that banks can lend out a multiple of their deposits as loans (e.g., mortgages, business loans). This amount is referred to as net interest margin, and is typically much higher than the federal funds rate - <a href="https://www.investopedia.com/ask/answers/061715/what-net-interest-margin-typical-bank.asp" target="_blank">it was 3.3% on average for banks in 2018</a>. The _% interest paid to depositor* is how much the depositor earns by storing their funds with the institution, and is set by the depository institution. For the recent wave of high-yield accounts offered by neobanks, they’ve set <em>% interest paid to depositor</em> essentially equal to *% interest earned_, making this revenue stream’s profitability close to zero. The typical rationale is for the high-yield account to draw in consumers for other higher-margin products such as debit/credit cards or loans.</p>

<p>In Chime’s case, <em>% interest earned</em> (the federal funds rate) is 0.09% at the time of writing (Sept. 2020), and <a href="https://chime.zendesk.com/hc/en-us/articles/221487887-What-do-I-need-to-know-about-the-Chime-Savings-Account-" target="_blank"><em>% interest paid to depositor</em></a> is 1.00%. This means that Chime is actually losing money on their deposit account product, and likely using it as a <a href="https://en.wikipedia.org/wiki/Loss_leader" target="_blank">loss leader</a> for the debit card, which has far higher profit margins. Also note that Chime only gives depositors 1% in interest for funds in their savings account. For any funds in the checking account (which over all customers may be larger), no interest is given.</p>

<p>These are the two main revenue streams for the majority of neobanks, but there are also others such as <a href="https://en.wikipedia.org/wiki/Cross-selling" target="_blank">cross-selling</a>, <a href="https://www.svmcards.com/" target="_blank">reward redemption referrals</a>, and new ones being created by startups. Hopefully this has given you a grasp of the basics, let me know if you have any thoughts/questions below!</p>




  <br>
  
  
  
</article>

      </div></div>]]>
            </description>
            <link>https://blog.mattheakis.com/how_do_neobanks_make_money/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24531372</guid>
            <pubDate>Sun, 20 Sep 2020 01:29:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Bug Could Let Attackers Hijack Firefox for Android via Wi-Fi Network]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24530986">thread link</a>) | @assineproff
<br/>
September 19, 2020 | http://tech.thewebgangs.com/a-bug-could-let-attackers-hijack-firefox-for-android-via-wi-fi-network/ | <a href="https://web.archive.org/web/*/http://tech.thewebgangs.com/a-bug-could-let-attackers-hijack-firefox-for-android-via-wi-fi-network/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="tps_slideContainer_1237"><div>

<p>Dear Android users, if you use the Firefox web browser on your smartphones, make sure it has been updated to version 80 or the latest available version on the Google Play Store.</p>

<p>ESET security researcher Lukas Stefanko yesterday&nbsp;<a href="https://twitter.com/LukasStefanko/status/1307013106615418883" target="_blank" rel="noopener noreferrer">tweeted</a>&nbsp;an alert demonstrating the exploitation of a recently disclosed high-risk remote command execution vulnerability affecting the Firefox app for Android.</p>

<p>Discovered originally by Australian security researcher&nbsp;<a href="https://gitlab.com/gitlab-com/gl-security/security-operations/gl-redteam/red-team-tech-notes/-/tree/master/firefox-android-2020" target="_blank" rel="noopener noreferrer">Chris Moberly</a>, the vulnerability resides in the SSDP engine of the browser that can be exploited by an attacker to target Android smartphones connected to the same Wi-Fi network as the attacker, with Firefox app installed.</p>
<p>SSDP, stands for Simple Service Discovery Protocol, is a UDP based protocol that is a part of UPnP for finding other devices on a network. In Android, Firefox periodically sends out SSDP discovery messages to other devices connected to the same network, looking for second-screen devices to cast.</p>
<p>Any device on the local network can respond to these broadcasts and provide a location to obtain detailed information on a UPnP device, after which, Firefox attempts to access that location, expecting to find an XML file conforming to the UPnP specifications.</p>

<p>According to the vulnerability report Moberly submitted to the Firefox team, the SSDP engine of the victims’ Firefox browsers can be tricked into triggering an Android intent by simply replacing location of the XML file in the response packets with a specially crafted message pointing to an Android intent URI.</p>
<p>For this, an attacker connected to a targeted Wi-Fi network can run a malicious SSDP server on his/her device and trigger intent-based commands on nearby Android devices through Firefox—without requiring any interaction from the victims.</p>
<p>Activities allowed by the intent also includes automatically launching the browser and open any defined URL, which, according to the researchers, is sufficient to trick victims into providing their credentials, install malicious apps, and other malicious activities based on the surrounding scenarios.</p>
<p>“The target simply has to have the Firefox application running on their phone. They do not need to access any malicious websites or click any malicious links. No attacker-in-the-middle or malicious app installation is required. They can simply be sipping coffee while on a cafe’s Wi-Fi, and their device will start launching application URIs under the attacker’s control,” Moberly said.</p>

<p>“it could have been used in a way similar to phishing attacks where a malicious site is forced onto the target without their knowledge in the hopes they would enter some sensitive info or agree to install a malicious application.”</p>
<p>Moberly reported this vulnerability to the Firefox team a few weeks back, which the browser maker has now patched in the Firefox for Android versions 80 and later.</p>
<p>Moberly has also released a&nbsp;<a href="https://gitlab.com/gitlab-com/gl-security/security-operations/gl-redteam/red-team-tech-notes/-/blob/master/firefox-android-2020/ffssdp.py" target="_blank" rel="noopener noreferrer">proof-of-concept exploit</a>&nbsp;to the public that Stefanko used to demonstrate the issue in the above video against three devices connected to the same network.</p>

</div></div></div>]]>
            </description>
            <link>http://tech.thewebgangs.com/a-bug-could-let-attackers-hijack-firefox-for-android-via-wi-fi-network/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24530986</guid>
            <pubDate>Sat, 19 Sep 2020 23:34:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SCons Is Still Slow]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24530845">thread link</a>) | @luu
<br/>
September 19, 2020 | https://blog.melski.net/2013/12/11/update-scons-is-still-really-slow/ | <a href="https://web.archive.org/web/*/https://blog.melski.net/2013/12/11/update-scons-is-still-really-slow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div>
					
					<!-- .entry-header -->

											<div>
							<p>A while back I posted a series of articles exploring the scalability of SCons, a popular Python-based build tool.  In a nutshell, my experiments showed that <b>SCons exhibits roughly quadratic growth in build runtimes as the number of targets increases</b>:</p>
<ul>
<li><a href="https://blog.melski.net/2011/05/23/why-is-scons-so-slow/">Why is SCons so slow?</a></li>
<li><a href="http://www.electric-cloud.com/blog/2010/03/08/how-scalable-is-scons/">How scalable is SCons?</a></li>
<li><a href="http://www.electric-cloud.com/blog/2010/07/21/a-second-look-at-scons-performance/">A second look at SCons performance</a></li>
<li><a href="http://www.electric-cloud.com/blog/2010/08/11/the-last-word-on-scons-performance/">The last word on SCons performance</a></li>
</ul>
<p>
Recently Dirk Baechle attempted to rebut my findings in an entry on the SCons wiki:  <a href="http://scons.org/wiki/WhySconsIsNotSlow">Why SCons is not slow</a>.  I thought Dirk made some credible suggestions that could explain my results, and he did some smart things in his effort to invalidate my results.  Unfortunately, his methods were flawed and his conclusions are invalid.  My original results still stand: <b>SCons really is slow.</b>  In the sections that follow I’ll share my own updated benchmarks and show where Dirk’s analysis went wrong.</p>
<h3>Test setup</h3>
<p>
As before, I used <a href="https://github.com/emelski/scons_bench/blob/master/genscons.pl">genscons.pl</a> to generate sample builds ranging from 2,000 to 50,000 targets.  However, my test system was much beefier this time:</p>
<table>
<tbody><tr>
<th></th>
<th>2013</th>
<th>2010</th>
</tr>
<tr>
<th>OS</th>
<td>Linux Mint 14 (kernel version 3.5.0-17-generic)</td>
<td>RedHat Desktop 3 (kernel version 2.4.21-58.ELsmp)</td>
</tr>
<tr>
<th>CPU</th>
<td>Quad 1.7GHz Intel Core i7, hyperthreaded</td>
<td>Dual 2.4GHz Intel Xeon, hyperthreaded</td>
</tr>
<tr>
<th>RAM</th>
<td>16 GB</td>
<td>2 GB</td>
</tr>
<tr>
<th>HD</th>
<td>SSD</td>
<td>(unknown)</td>
</tr><tr>
<th>SCons</th>
<td>2.3.0</td>
<td>1.2.0.r3842</td>
</tr>
<tr>
<th>Python</th>
<td>2.7.3 (system default)</td>
<td>2.6.2</td>
</tr>
</tbody></table>
<p>
Before running the tests, I rebooted the system to ensure there were no rogue processes consuming memory or CPU.  I also forced the CPU cores into “performance” mode to ensure that they ran at their full 1.7GHz speed, rather than at the lower 933MHz they switch to when idle.</p>
<h3>Revisiting the original benchmark</h3>
<p>
I think Dirk had two credible theories to explain the results I obtained in my original tests.  First, Dirk wondered if those results may have been the result of <i>virtual memory swapping</i> — my original test system had relatively little RAM, and SCons itself uses a lot of memory.  It’s plausible that physical memory was exhausted, forcing the OS to swap memory to disk.  As Dirk said, “this would explain the increase of build times” — you bet it would!  I don’t remember seeing any indication of memory swapping when I ran these tests originally, but to be honest it was nearly 4 years ago and perhaps my memory is not reliable.  To eliminate this possibility, I ran the tests on a system with 16 GB RAM this time.  During the tests I ran <span><span face="Courier New">vmstat 5</span></span>, which collects memory and swap usage information at five second intervals, and captured the result in a log.</p>
<p>
Next, he suggested that I skewed the results by directing SCons to inherit the ambient environment, rather than using SCons’ default “sanitized” environment.  That is, he felt I should have used <span><span face="Courier New">env = Environment()</span></span> rather than <span><span face="Courier New">env = Environment(ENV = os.environ)</span></span>.  To ensure that this was not a factor, I modified the tests so that they did not inherit the environment.  At the same time, I substituted <span><span face="Courier New">echo</span></span> for the compiler and other commands, in order to make the tests faster.  Besides, I’m not interested in benchmarking the compiler — just SCons!  Here’s what my <span><span face="Courier New">Environment</span></span> declaration looks like now:</p>
<pre title="">env = Environment(CC = 'echo', AR = 'echo', RANLIB = 'echo')
</pre>
<p>With these changes in place I reran my benchmarks.  As expected, there was no change in the outcome.  There is no doubt:  <b>SCons does <i>not</i> scale linearly</b>.  Instead the growth is <i>polynomial</i>, following an n<sup>1.85</sup> curve.  And thanks to the the <a href="https://github.com/emelski/scons_bench/blob/master/logs/2.3.0/001/50000.vmstat">vmstat output</a> we can be certain that there was absolutely no swapping affecting the benchmarks.  Here’s a graph of the results, including an n<sup>1.85</sup> curve for comparison — notice that you can barely see that curve because it matches the observed data so well!</p>
<p>
<a href="https://emelski.files.wordpress.com/2013/12/scons_full.png"><img data-attachment-id="1040" data-permalink="https://blog.melski.net/2013/12/11/update-scons-is-still-really-slow/scons_full/#main" data-orig-file="https://emelski.files.wordpress.com/2013/12/scons_full.png" data-orig-size="500,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="SCons full build runtime" data-image-description="" data-medium-file="https://emelski.files.wordpress.com/2013/12/scons_full.png?w=300" data-large-file="https://emelski.files.wordpress.com/2013/12/scons_full.png?w=500" src="https://emelski.files.wordpress.com/2013/12/scons_full.png?w=640&amp;h=384" alt="SCons full build runtime - click for larger view" srcset="https://emelski.files.wordpress.com/2013/12/scons_full.png 500w, https://emelski.files.wordpress.com/2013/12/scons_full.png?w=150&amp;h=150 150w, https://emelski.files.wordpress.com/2013/12/scons_full.png?w=300&amp;h=300 300w" sizes="(max-width: 500px) 100vw, 500px"></a></p>
<p>
For comparison, I used the SCons build log to make a shell script that executes the same series of <span><span face="Courier New">echo</span></span> commands.  At 50,000 targets, the shell script ran in 1.097s.  You read that right:  <b>1.097s</b>.  Granted, the shell script doesn’t do stuff like up-to-date checks, etc., but still — of the 3,759s average SCons runtime, 3,758s — 99.97% — is SCons overhead.</p>
<p>
I also created a non-recursive Makefile that “builds” the same targets with the same <span><span face="Courier New">echo</span></span> commands.  This is a more realistic comparison to SCons — after all, nobody would dream of actually controlling a build with a straight-line shell script, but lots of people would use GNU make to do it.  With 50,000 targets, GNU make ran for <b>82.469s</b> — more than 45 times faster than SCons.</p>
<h3>What is linear scaling?</h3>
<p>
If the performance problems are so obvious, why did Dirk fail to see them?  Here’s a graph made from his test results:</p>
<p>
<a href="https://emelski.files.wordpress.com/2013/12/scons_baechle.png"><img data-attachment-id="1038" data-permalink="https://blog.melski.net/2013/12/11/update-scons-is-still-really-slow/scons_baechle/#main" data-orig-file="https://emelski.files.wordpress.com/2013/12/scons_baechle.png" data-orig-size="500,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="SCons full build runtime, via D. Baechle" data-image-description="" data-medium-file="https://emelski.files.wordpress.com/2013/12/scons_baechle.png?w=300" data-large-file="https://emelski.files.wordpress.com/2013/12/scons_baechle.png?w=500" src="https://emelski.files.wordpress.com/2013/12/scons_baechle.png?w=640&amp;h=640" alt="SCons full build runtime, via D. Baechle - click for full size" srcset="https://emelski.files.wordpress.com/2013/12/scons_baechle.png 500w, https://emelski.files.wordpress.com/2013/12/scons_baechle.png?w=150&amp;h=150 150w, https://emelski.files.wordpress.com/2013/12/scons_baechle.png?w=300&amp;h=300 300w" sizes="(max-width: 500px) 100vw, 500px"></a></p>
<p>
Dirk says that this <a href="http://scons.org/wiki/WhySconsIsNotSlow#Linear_scaling">demonstrates “SCons’ linear scaling”</a>.  I find this statement baffling, because his data clearly shows that <i>SCons does not scale linearly</i>.  It’s simple, really:  <i>linear scaling</i> just means that the build time increases by the same amount for each new target you add, regardless of how many targets you already have.  Put another way, it means that the difference in build time between 1,000 targets and 2,000 targets is <i>exactly the same</i> as the difference between 10,000 and 11,000 targets, or between 30,000 and 31,000 targets.  Or, put yet another way, it means that when you plot the build time versus the number of targets, you should get a straight line with <i>no change in slope at any point</i>.  Now you tell me:  does that describe Dirk’s graph?</p>
<p>
Here’s another version of that graph, this time augmented with a couple additional lines that show what the plot would look like if SCons were truly scaling linearly.  The first projection is based on the original graph from 2,500 to 4,500 targets — that is, if we assume that SCons scales linearly and that the increase in build time between 2,500 and 4,500 targets is representative of the cost to add 2,000 more targets, then this line shows us how we should expect the build time to increase.  Similarly, the second projection is based on the original graph between 4,500 and 8,500 targets.  You can easily see that the actual data does not match either projection.  Furthermore you can see that the slope of these projections is <i>increasing</i>:</p>
<p>
<a href="https://emelski.files.wordpress.com/2013/12/scons_baechle_augmented.png"><img data-attachment-id="1039" data-permalink="https://blog.melski.net/2013/12/11/update-scons-is-still-really-slow/scons_baechle_augmented/#main" data-orig-file="https://emelski.files.wordpress.com/2013/12/scons_baechle_augmented.png" data-orig-size="500,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="SCons full build runtime with linear projections, via D. Baechle" data-image-description="" data-medium-file="https://emelski.files.wordpress.com/2013/12/scons_baechle_augmented.png?w=300" data-large-file="https://emelski.files.wordpress.com/2013/12/scons_baechle_augmented.png?w=500" src="https://emelski.files.wordpress.com/2013/12/scons_baechle_augmented.png?w=640&amp;h=640" alt="SCons full build runtime with linear projections, via D. Baechle - click for full size" srcset="https://emelski.files.wordpress.com/2013/12/scons_baechle_augmented.png 500w, https://emelski.files.wordpress.com/2013/12/scons_baechle_augmented.png?w=150&amp;h=150 150w, https://emelski.files.wordpress.com/2013/12/scons_baechle_augmented.png?w=300&amp;h=300 300w" sizes="(max-width: 500px) 100vw, 500px"></a></p>
<p>
This shows the importance of testing at large scale when you’re trying to characterize the scalability of a system from empirical data.  It can be difficult to differentiate polynomial from logarithmic or linear at low scales, especially once you incorporate the constant factors — polynomial algorithms can sometimes even give <i>better</i> absolute performance for small inputs than linear algorithms!  It’s not until you plot enough data points at large enough values, as I’ve done, that it becomes easy to see and identify the curve.</p>
<h3>What does profiling tell us?</h3>
<p>
Next, Dirk reran some of his tests under a profiler, on the very reasonable assumption that if there was a performance problem to be found, it would manifest in the profiling data — surely at least one function would demonstrate a larger-than-expected growth in runtime.  Dirk only shared profiling data for two runs, both incremental builds, at 8,500 and 16,500 targets.  That’s unfortunate for a couple reasons.  First, the performance problem is less apparent on incremental builds than on full builds.  Second, with only two datapoints it is literally not possible to determine whether growth is linear or polynomial.  The results of Dirk’s profiling was negative:  he found no “significant difference or increase” in any function.</p>
<p>
Fortunately it’s easy to run this experiment myself.  Dirk used <a href="http://docs.python.org/2/library/profile.html">cProfile</a>, which is built-in to Python.  To profile a Python script you can inject cProfile from the command-line, like this: <span><span face="Courier New">python -m cProfile scons</span></span>.  Just before Python exits, cProfile dumps timing data for every function invoked during the run.  I ran several full builds with the profiler enabled, from 2,000 to 20,000 targets.  Then I sorted the profiling data by function internal time (time spent in the function exclusively, not in its descendents).  <i>In every run</i>, the same two functions appeared at the top of the list:  <span><span face="Courier New">posix.waitpid</span></span> and <span><span face="Courier New">posix.fork</span></span>.  To be honest this was a surprise to me — previously I believed the problem was in SCons’ Taskmaster implementation.  But I can’t really argue with the data.  It makes sense that SCons would spend most of its time running and waiting for child processes to execute, and even that the amount of time spent in these functions would increase as the number of child processes increases.  But look at the growth in runtimes in these two functions:</p>
<p>
<a href="https://emelski.files.wordpress.com/2013/12/scons_profiler.png"><img data-attachment-id="1041" data-permalink="https://blog.melski.net/2013/12/11/update-scons-is-still-really-slow/scons_profiler/#main" data-orig-file="https://emelski.files.wordpress.com/2013/12/scons_profiler.png" data-orig-size="500,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="SCons full build function time, top two functions" data-image-description="" data-medium-file="https://emelski.files.wordpress.com/2013/12/scons_profiler.png?w=300" data-large-file="https://emelski.files.wordpress.com/2013/12/scons_profiler.png?w=500" src="https://emelski.files.wordpress.com/2013/12/scons_profiler.png?w=640&amp;h=640" alt="SCons full build function time, top two functions - click for full size" srcset="https://emelski.files.wordpress.com/2013/12/scons_profiler.png 500w, https://emelski.files.wordpress.com/2013/12/scons_profiler.png?w=150&amp;h=150 150w, https://emelski.files.wordpress.com/2013/12/scons_profiler.png?w=300&amp;h=300 300w" sizes="(max-width: 500px) 100vw, 500px"></a></p>
<p>
Like the overall build time, these curves are obviously non-linear.  Armed with this knowledge, I went back to Dirk’s profiling data.  To my surprise, <i>posix.waitpid and posix.fork don’t even appear in Dirk’s data</i>.  On closer inspection, his data seems to include only a subset of all functions — about 600 functions, whereas <a href="https://github.com/emelski/scons_bench/blob/master/logs/2.3.0_profiling/001/20000.prof">my profiling data</a> contains more than 1,500.  I cannot explain this — perhaps Dirk filtered the results to exclude functions that are part of the Python library, assuming that the problem must be in SCons’ own code rather than in the library on which it is built.</p>
<p>
This demonstrates a second fundamental principle of performance analysis:  make sure that you consider <i>all</i> the data.  Programmers’ intuition about performance problems is notoriously bad — even mine! — which is why it’s important to measure before acting.  But measuring won’t help if you’re missing critical data or if you discard part of the data before doing any analysis.</p>
<h3>Conclusions</h3>
<p>
On the surface, performance analysis seems like it should be simple:  start a timer, run some code, stop the timer.  Done correctly, performance analysis can illuminate the dark corners of your application’s performance.  Done incorrectly — and there are <i>many</i> ways to do it incorrectly — it can lead you on a wild goose chase and cause you to squander resources fixing the wrong problems.</p>
<p>
Dirk Baechle had good intentions when he set out to analyze SCons performance, but he made some mistakes in his process that led him to an erroneous conclusion.  First, he didn’t run enough …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.melski.net/2013/12/11/update-scons-is-still-really-slow/">https://blog.melski.net/2013/12/11/update-scons-is-still-really-slow/</a></em></p>]]>
            </description>
            <link>https://blog.melski.net/2013/12/11/update-scons-is-still-really-slow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24530845</guid>
            <pubDate>Sat, 19 Sep 2020 22:56:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Calculus in SaaS]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24530760">thread link</a>) | @Lukas1994
<br/>
September 19, 2020 | https://www.causal.app/blog/calculus-in-saas | <a href="https://web.archive.org/web/*/https://www.causal.app/blog/calculus-in-saas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Note:&nbsp;this was originally published at </em><a href="https://alexoppenheimer.substack.com/" target="_blank"><em>https://alexoppenheimer.substack.com/</em></a>‍</p><p>I have been studying the SaaS model in depth for almost 7 years now. Since the day <a href="https://alexoppenheimer.substack.com/p/harry-2d5d1af6bf">Harry Weller</a> walked into my office with a stack of materials and told me to study it and then SaaS build models and bring them to portfolio companies, I don't think a day has gone by where I have not thought about the conceptual and operational nuances of the recurring revenue business model.</p><p>Somewhere around mid 2015 I had my "aha" moment in my research when I tied my academic training in mechanical engineering to the startup business models I was building: it's all calculus. The integral-derivative relationship applies incredibly well to the ARR and Recognized Revenue relationship. Making this connection between engineering math and financial math gave me a feeling that only a true nerd could appreciate: the joy of putting integral symbols and accounting terms on the same slide.</p><p>The simplest way to illustrate this mathematical parallel is with a car:</p><figure id="w-node-2abd43418357-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5f649b33c9e3271323643b3d_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252F42d5ef92-52d9-49fe-8be7-16028bee1ff4_884x306.png" alt=""></p></figure><p>If a car is moving at 60mph, then in one hour it will travel 60 miles (assuming its speed does not change). That is the definition of "miles per hour." ARR is very similar: if a company is "moving" at $10M ARR, then in one year it will recognize $10M of revenue (assuming everything stays consistent). Recognized revenue is the distance, ARR is the speed. It's critical to recognize that ARR is a rate at a specific point in time used to imply something (here, expected recognized revenue in the future period).</p><p>For the more accounting oriented, another analogy can be made to the balance sheet:</p><figure id="w-node-9fc87f218c80-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5f649b3392b0138c4e64006b_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252F6c06ddcc-de3e-4d96-960a-22b4b39e334e_842x455.png" alt=""></p></figure><p>While revenue is the top line metric on the income statement, ARR works more like a balance sheet metric: it is taken at a single point in time rather than over a period of time. This can make income statements confusing and misaligned - another example of the divergence of accounting in economics in subscription businesses.</p><p>Now back to calculus... if the ARR function was actually a mathematical equation, you could integrate it. If y = 10x where y = ARR and x = time in months, then after two months ARR = $20. After 12 months, ARR = $120 (assuming we start from $0 of ARR). So at the end of a year, the business has grown from $0 to $120 in ARR. But what is the recognized revenue? The complex answer is that it's the integral of 10x from 0 to 12 months. (Apologies in advance if this triggers a high school calculus flashback.)</p><figure><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5f649b337d3c7911d7362b81_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252Ff7fcb57f-644b-490c-bfa8-6d0c986d2fda_305x80.png" alt=""></p></figure><p>You could also chart this out and see that it is a right triangle with the area of 1/2*base*height. Where the base is 12 months and the height is $120: $1,440/2 = $720).</p><p>Pretty cool relationship and calculation conceptually, but in real businesses ARR growth doesn't fit a simple equation (or any equation at all), so it's not inherently practical to start breaking out the power rule and your old textbooks to predict ARR growth.</p><p>If we switch back to the car analogy, it takes on a little more of a nuanced meaning. Just like a business doesn't grow on a smooth curve, car speeds do not either. Just like the gas pedal makes the car go faster and the brake pedal &amp; friction make it go slower, so too in a SaaS company, <a href="https://alexoppenheimer.substack.com/p/thin-slicing-arr">the new sales are making the speed/ARR increase and the churned customers are making the speed/ARR decrease</a>. I will dive into more details in later posts, but the goal in a car is to go as far and fast as you can while burning the least amount of fuel. So too in a SaaS company, the goal is to have the highest ARR you can, recognize the most revenue and burn the least cash. You can think about SaaS Magic Number like the fuel efficiency of a SaaS business - looking forward to diving into why this is actually helpful in building a company.</p></div></div>]]>
            </description>
            <link>https://www.causal.app/blog/calculus-in-saas</link>
            <guid isPermaLink="false">hacker-news-small-sites-24530760</guid>
            <pubDate>Sat, 19 Sep 2020 22:33:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bevy 0.2]]>
            </title>
            <description>
<![CDATA[
Score 252 | Comments 42 (<a href="https://news.ycombinator.com/item?id=24530698">thread link</a>) | @_cart
<br/>
September 19, 2020 | https://bevyengine.org/news/bevy-0-2/ | <a href="https://web.archive.org/web/*/https://bevyengine.org/news/bevy-0-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><img src="https://bevyengine.org/news/bevy-0-2/matching_squares.png"></p>
      
    
  </div><div><p>A month after the initial Bevy release, and thanks to <strong>87</strong> contributors, <strong>174</strong> pull requests, and our <a href="https://github.com/sponsors/cart"><strong>generous sponsors</strong></a>, I'm happy to announce the <strong>Bevy 0.2</strong> release on <a href="https://crates.io/crates/bevy">crates.io</a>!</p>
<p>For those who don't know, Bevy is a refreshingly simple data-driven game engine built in Rust. You can check out <a href="https://bevyengine.org/learn/book/getting-started/">Quick Start Guide</a> to get started. Bevy is also free and open source forever! You can grab the full <a href="https://github.com/bevyengine/bevy">source code</a> on GitHub.</p>
<p>Here are some of the highlights from this release:</p>
<h2 id="async-task-system">Async Task System</h2>

<p>Bevy uses multi-threading throughout the engine: ECS scheduling, asset loading, rendering, etc. Before this release it used <a href="https://github.com/rayon-rs/rayon">Rayon</a> for almost all of these tasks. Rayon is nice because it is generally as simple as calling <code>some_list.par_iter().for_each(|x| do_something(x))</code>. Rayon then automatically breaks the <code>for_each</code> into tasks and runs them on as many cores as it can. Rayon is a great choice if you want to easily parallelize code, but it has the downside of being pretty cpu-hungry.</p>
<p>Bevy (and a number of other rust game engines and ecs frameworks using rayon) have received feedback that they were overly cpu hungry / usage was not proportional to "real" work done.</p>
<p>We decided to resolve this problem by building a custom async-friendly task system, which enables the creation of context-specific task pools. For example, you might have separate pools for compute, IO, networking, etc. This also gives us the flexibility to load balance work appropriately according to work type and/or priority. The cpu usage wins have been huge:</p>
<h3 id="total-combined-percent-cpu-usage-8-core-machine-smaller-is-better">Total Combined Percent CPU Usage - 8 Core Machine (smaller is better)</h3>
<p><img src="https://bevyengine.org/news/bevy-0-2/bevy_tasks_1.svg" alt="threading cpu usage 8 core"></p>
<h3 id="total-combined-percent-cpu-usage-32-core-machine-smaller-is-better">Total Combined Percent CPU Usage - 32 Core Machine (smaller is better)</h3>
<p><img src="https://bevyengine.org/news/bevy-0-2/bevy_tasks_2.svg" alt="threading cpu usage 32 core"></p>
<h2 id="initial-web-platform-support">Initial Web Platform Support</h2>
<p>authors: @smokku</p>
<p>(A subset of) Bevy now runs on the web using WebAssembly/WASM! Specifically, Bevy apps can run Bevy ECS schedules, react to input events, create an empty canvas (using winit), and a few other things. This is a huge first step, but it is important to call out that there are still a number of missing pieces, such as 2D/3D rendering, multi-threading, and sound. </p>
<p>Those limitations haven't stopped @mrk-its from building the first WASM Bevy game!</p>
<h3 id="bevy-robbo-playable-here"><a href="https://github.com/mrk-its/bevy-robbo">bevy-robbo</a> (<a href="https://s3.eu-central-1.amazonaws.com/mrk-public/bevy-robbo/index.html">playable here</a>)</h3>
<p><img src="https://bevyengine.org/news/bevy-0-2/bevy-robbo.png" alt="bevy-robbo"></p>
<p>They use Bevy for game logic and cleverly work around the render limitations by passing ASCII art game state from <a href="https://github.com/mrk-its/bevy-robbo/blob/master/src/systems/js_render.rs">this Bevy system</a> to <a href="https://github.com/mrk-its/bevy-robbo/blob/master/assets/render.js">this JavaScript function</a>. </p>
<p>You can play around with some Bevy WASM examples by <a href="https://github.com/bevyengine/bevy/tree/master/examples#wasm">following the instructions here</a>.</p>
<h2 id="parallel-queries">Parallel Queries</h2>
<p>authors: @GrantMoyer</p>
<p>Bevy ECS Queries are a flexible way to retrieve data from the Entity Component System. Systems that <em>use</em> queries already run in parallel, but before this change the queries themselves could not be <em>iterated</em> in parallel. <strong>Bevy 0.2</strong> adds the ability to easily iterate queries in parallel:</p>
<pre><code><span>fn </span><span>system</span><span>(</span><span>pool</span><span>: </span><span>Res</span><span>&lt;</span><span>ComputeTaskPool</span><span>&gt;</span><span>, </span><span>mut </span><span>query</span><span>: </span><span>Query</span><span>&lt;&amp;</span><span>mut</span><span> Transform</span><span>&gt;) {</span><span>
    query</span><span>.</span><span>iter</span><span>().</span><span>par_iter</span><span>(</span><span>32</span><span>).</span><span>for_each</span><span>(&amp;</span><span>pool</span><span>, |</span><span>mut </span><span>transform</span><span>| {</span><span>
      transform</span><span>.</span><span>translate</span><span>(</span><span>Vec3</span><span>::</span><span>new</span><span>(</span><span>1.0</span><span>, </span><span>0.0</span><span>, </span><span>0.0</span><span>));
    });
}
</span></code></pre>
<p>This provides a nice functional api (similar to Rayon) that runs on top of the new <code>bevy_tasks</code> system. It breaks the query up into 32 "batches" and runs each batch as a different task in the bevy task system. </p>
<h2 id="transform-system-rewrite">Transform System Rewrite</h2>
<p>authors: @MarekLg</p>
<pre><code><span>// old
</span><span>fn </span><span>system</span><span>(</span><span>translation</span><span>: &amp;</span><span>Translation, </span><span>rotation</span><span>: &amp;</span><span>Rotation, </span><span>scale</span><span>: &amp;</span><span>Scale</span><span>) {
  </span><span>println!</span><span>("</span><span>{} {} {}</span><span>",</span><span> translation</span><span>.</span><span>0</span><span>,</span><span> rotation</span><span>.</span><span>0</span><span>,</span><span> scale</span><span>.</span><span>0</span><span>);
}

</span><span>// new
</span><span>fn </span><span>system</span><span>(</span><span>transform</span><span>: &amp;</span><span>Transform</span><span>) {
  </span><span>println!</span><span>("</span><span>{} {} {}</span><span>",</span><span> transform</span><span>.</span><span>translation</span><span>(),</span><span> transform</span><span>.</span><span>rotation</span><span>(),</span><span> transform</span><span>.</span><span>scale</span><span>());
}
</span></code></pre>
<p>Bevy's old transform system used separate <code>Translation</code>, <code>Rotation</code>, and <code>Scale</code> components as the "source of truth". Users modified with these components in their systems, after which they were synced to a <code>LocalTransform</code> component, which was in turn synced to a global <code>Transform</code> component, taking hierarchy into account. This was nice for a couple of reasons:</p>
<ul>
<li>Slightly more cache efficient to retrieve individual components like <code>Translation</code> (because less data needs to be accessed)</li>
<li>Theoretically more parallel-friendly. Systems that only access <code>Translation</code> won't block systems accessing <code>Rotation</code>.</li>
</ul>
<p>However this approach also has some pretty serious downsides:</p>
<ul>
<li>The "individual components" are the source of truth, so <code>LocalTransform</code> is out of date when user systems are running. If an up to date "full transform" is needed, it must be manually constructed by accessing all three components.</li>
<li>Very hard to reason about. There are 5 components users need to think about and they all interact with each other differently.</li>
<li>Setting a Transform to a specific matrix value (ex: <code>Mat4::look_at()</code>) was extremely cumbersome, and the value would be immediately overwritten unless the user explicitly disabled component syncing.</li>
</ul>
<p>Given these issues, we decided to move to a single unified local-to-parent <code>Transform</code> component as the source of truth, and a computed <code>GlobalTransform</code> component for world-space transforms. We think this api will be much easier to use and to reason about. <a href="https://gist.github.com/joeante/79d25ec3a0e86436e53eb74f3ac82c0c">Unity is also considering a similar Transform rework for their ECS</a> and a lot of discussion on this topic happened in this <a href="https://community.amethyst.rs/t/legion-transform-design-discussion">Amethyst Forum Thread</a>.</p>
<h2 id="joystick-gamepad-input">Joystick/Gamepad Input</h2>
<p>authors: @simpuid</p>
<p>The Bevy Input plugin now has cross-platform support for most controllers thanks to the <a href="https://gitlab.com/gilrs-project/gilrs">gilrs</a> library!</p>
<pre><code><span>fn </span><span>button_system</span><span>(</span><span>gamepads</span><span>: </span><span>Res</span><span>&lt;</span><span>Vec</span><span>&lt;</span><span>Gamepad</span><span>&gt;&gt;</span><span>, </span><span>button_input</span><span>: </span><span>Res</span><span>&lt;</span><span>Input</span><span>&lt;</span><span>GamepadButton</span><span>&gt;&gt;) {
    </span><span>for</span><span> gamepad </span><span>in</span><span> gamepads</span><span>.</span><span>iter</span><span>() {
        </span><span>if</span><span> button_input</span><span>.</span><span>just_pressed</span><span>(</span><span>GamepadButton</span><span>(*</span><span>gamepad</span><span>, </span><span>GamepadButtonType</span><span>::</span><span>RightTrigger</span><span>)) {
            </span><span>println!</span><span>("</span><span>Pressed right trigger!</span><span>");
        }
    }
}
</span></code></pre><h2 id="bevy-ecs-performance-improvements">Bevy ECS Performance Improvements</h2>
<p>authors: @cart</p>
<h3 id="generational-entity-ids">Generational Entity IDs</h3>
<p>We changed Entity IDs from being random UUIDs to incrementing generational indices. Random UUIDs were nice because they could be created anywhere, were unique across game runs, and could be safely persisted to files or reused across networks. I was really hoping we could make them work, but they ended up being too slow relative to the alternatives. The randomness had a measurable cost and entity locations had to be looked up using a hash map.</p>
<p>By moving to generational indices (we use the hecs implementation), we can directly use entity ids as array indices, which makes entity location lookups lightning fast.</p>
<h3 id="read-only-queries">Read Only Queries</h3>
<p>I implemented "read only" traits for queries that don't mutate anything. This allows us to guarantee that a query won't mutate anything.</p>
<h3 id="removed-locking-from-world-apis">Removed locking from World apis</h3>
<p>This gives us a really nice speed boost. We can do this safely due to a combination of the new "read only queries" and changing World mutation apis to be a mutable World borrow.</p>
<p>This is not yet enabled for <code>Queries</code> in systems because a system could have multiple <code>Queries</code>, which could be simultaneously accessed in a way that doesn't make mutable access unique. I think thats a solve-able problem, but it will take a bit more work. Fortunately "for-each" systems don't have any collision risk, so we now use lock-less queries there.</p>
<h3 id="direct-component-lookup-in-nanoseconds-smaller-is-better">Direct component lookup (in nanoseconds, smaller is better)</h3>
<p>As a result of these optimizations, direct component lookup is <em>much</em> faster than it used to be:</p>
<p><img src="https://bevyengine.org/news/bevy-0-2/get_component.svg" alt="get_component graph"></p>
<p>Note that this benchmark used <code>world.get::&lt;T&gt;(entity)</code>. <code>query.get::&lt;T&gt;(entity)</code> should have results similar to the <code>hecs</code> results because it still uses a lock. Eventually I'm hoping that we can remove locks from system queries too.</p>
<h2 id="change-log">Change Log</h2>
<h3 id="added">Added</h3>
<ul>
<li><a href="https://github.com/bevyengine/bevy/pull/384">Task System for Bevy</a>
<ul>
<li>Replaces rayon with a custom designed task system that consists of several "TaskPools".</li>
<li>Exports <code>IOTaskPool</code>, <code>ComputePool</code>, and <code>AsyncComputePool</code> in <code>bevy_tasks</code> crate.</li>
</ul>
</li>
<li><a href="https://github.com/bevyengine/bevy/pull/292">Parallel queries for distributing work over with the <code>ParallelIterator</code> trait.</a>
<ul>
<li>e.g. <code>query.iter().par_iter(batch_size).for_each(/* ... */)</code></li>
</ul>
</li>
<li><a href="https://github.com/bevyengine/bevy/pull/280">Added gamepad support using Gilrs</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/503">Implement WASM support for bevy_winit</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/506">Create winit canvas under WebAssembly</a> </li>
<li><a href="https://github.com/bevyengine/bevy/pull/496">Implement single threaded task scheduler for WebAssembly</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/271">Support for binary glTF (.glb).</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/358">Support for <code>Or</code> in ECS queries.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/339">Added methods <code>unload()</code> and <code>unload_sync()</code> on <code>SceneSpawner</code> for unloading scenes.</a>.</li>
<li><a href="https://github.com/bevyengine/bevy/pull/145">Custom rodio source for audio.</a>
<ul>
<li><code>AudioOuput</code> is now able to play anything <code>Decodable</code>.</li>
</ul>
</li>
<li><a href="https://github.com/bevyengine/bevy/pull/362"><code>Color::hex</code></a> for creating <code>Color</code> from string hex values.
<ul>
<li>Accepts the forms RGB, RGBA, RRGGBB, and RRGGBBAA.</li>
</ul>
</li>
<li><a href="https://github.com/bevyengine/bevy/pull/381"><code>Color::rgb_u8</code> and <code>Color::rgba_u8</code>.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/396">Added <code>bevy_render::pass::ClearColor</code> to prelude.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/430"><code>SpriteResizeMode</code> may choose how <code>Sprite</code> resizing should be handled. <code>Automatic</code> by default.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/428">Added methods on <code>Input&lt;T&gt;</code></a> for iterator access to keys.
<ul>
<li><code>get_pressed()</code>, <code>get_just_pressed()</code>, <code>get_just_released()</code></li>
</ul>
</li>
<li><a href="https://github.com/bevyengine/bevy/pull/270">Derived <code>Copy</code> for <code>MouseScrollUnit</code>.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/390">Derived <code>Clone</code> for UI component bundles.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/332">Some examples of documentation</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/451">Update docs for Updated, Changed and Mutated</a></li>
<li>Tips for faster builds on macOS: <a href="https://github.com/bevyengine/bevy/pull/312">#312</a>, <a href="https://github.com/bevyengine/bevy/pull/314">#314</a>, <a href="https://github.com/bevyengine/bevy/pull/433">#433</a></li>
<li>Added and documented cargo features
<ul>
<li><a href="https://github.com/bevyengine/bevy/pull/249">Created document <code>docs/cargo_features.md</code>.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/249">Added features for x11 and wayland display servers.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/363">and added a feature to disable libloading.</a> (helpful for WASM support)</li>
</ul>
</li>
<li>Added more instructions for Linux dependencies
<ul>
<li><a href="https://github.com/bevyengine/bevy/pull/275">Arch / Manjaro</a>, <a href="https://github.com/bevyengine/bevy/pull/290">NixOS</a>, <a href="https://github.com/bevyengine/bevy/pull/463">Ubuntu</a> and <a href="https://github.com/bevyengine/bevy/pull/331">Solus</a></li>
</ul>
</li>
<li><a href="https://github.com/bevyengine/bevy/pull/491">Provide shell.nix for easier compiling with nix-shell</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/505">Add <code>AppBuilder::add_startup_stage_|before/after</code></a></li>
</ul>
<h3 id="changed">Changed</h3>
<ul>
<li><a href="https://github.com/bevyengine/bevy/pull/374">Transform rewrite</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/504">Use generational entity ids and other optimizations</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/417">Optimize transform systems to only run on changes.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/323">Send an AssetEvent when modifying using <code>get_id_mut</code></a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/332">Rename <code>Assets::get_id_mut</code> -&gt; <code>Assets::get_with_id_mut</code></a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/183">Support multiline text in <code>DrawableText</code></a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/324">iOS: use shaderc-rs for glsl to spirv compilation</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/304">Changed the default node size to Auto instead of Undefined to match the Stretch implementation.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/478">Load assets from root path when loading directly</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/485">Add <code>render</code> feature</a>, which makes the entire render pipeline optional.</li>
</ul>
<h3 id="fixed">Fixed</h3>
<ul>
<li><a href="https://github.com/bevyengine/bevy/pull/361">Properly track added and removed RenderResources in RenderResourcesNode.</a>
<ul>
<li>Fixes issues where entities vanished or changed color when new entities were spawned/despawned.</li>
</ul>
</li>
<li><a href="https://github.com/bevyengine/bevy/pull/385">Fixed sprite clipping at same depth</a>
<ul>
<li>Transparent sprites should no longer clip.</li>
</ul>
</li>
<li><a href="https://github.com/bevyengine/bevy/pull/345">Check asset path existence</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/376">Fixed deadlock in hot asset reloading</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/394">Fixed hot asset reloading on Windows</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/406">Allow glTFs to be loaded that don't have uvs and normals</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/383">Fixed archetypes_generation being …</a></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bevyengine.org/news/bevy-0-2/">https://bevyengine.org/news/bevy-0-2/</a></em></p>]]>
            </description>
            <link>https://bevyengine.org/news/bevy-0-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24530698</guid>
            <pubDate>Sat, 19 Sep 2020 22:21:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Provisioning an App Service on Azure Using Terraform with AzureDevOps]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24530366">thread link</a>) | @lokethien
<br/>
September 19, 2020 | https://www.andreasrein.net/posts/app-service-terraform-azure-azuredevops/ | <a href="https://web.archive.org/web/*/https://www.andreasrein.net/posts/app-service-terraform-azure-azuredevops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<article>
  
  <div><p>Part of a good DevOps routine is to have the infrastructure as code. This way you can utilize a high level of control with source control. You can also effortlessly spin up another identical environment.</p>

<h2 id="terraform">Terraform</h2>

<p>If you have a sizable project that has a lot of resources or a DevOps enthusiast, it may be smart to keep it in source control.</p>

<p>Terraform is Hashicorp’s solution for <em>IaC</em>. The configuration language of choice is HcL (Hashicorp configuration language). Please do not fear learning a new language. HcL is highly enjoyable and simple to learn. It’s also multi-cloud so you can learn Terraform once and use it to provision resources on AWS, Azure, and Google Cloud.</p>

<p>The Azure provider is relatively mature and it’s in constant development. It’s open-source so if you are having issues, you can always create an issue on their repository. If you absolutely cannot do what you want to do using Terraform, you could always use ARM templates in Terraform or even CLI commands. So let’s go through the tutorial of using it in Azure with CI/CD using Azure DevOps.</p>

<h2 id="recipe">Recipe</h2>

<h3 id="1-install-terraform-extension">1. Install Terraform extension</h3>

<p>In this tutorial, I will use an extension to AzureDevOps that will enable us to run Terraform in our build pipeline. Get it <a href="https://marketplace.visualstudio.com/items?itemName=ms-devlabs.custom-terraform-tasks">here</a> and install it in your organization.</p>

<h3 id="2-create-project-on-azuredevops">2. Create project on AzureDevOps</h3>

<p>Before you start creating a pipeline, you should have a project ready on AzureDevOps. Remember that the service <code>Pipelines</code> needs to be on (can be turned on in settings -&gt; overview) and <code>Repos</code> as well.</p>

<p>After that, you should create a repository and clone it to your desktop. Since the pipeline will include two stages; develop and master, it is smart to create a branch <code>develop</code> out from <code>master</code>.</p>

<h3 id="3-set-up-a-service-connection">3. Set-up a service connection</h3>

<p>A service connection enables you to hook-up the AzureDevOps project to the magical fairy-cloud of Azure. Create it by going to <code>Project settings</code> → <code>Service connections</code> and hit new service connection from the top right corner. There you select <code>Azure Resource Manager</code> and then you can use <code>Service principal (automatic)</code> as the authentication method.</p>

<p><img src="https://www.andreasrein.net/images/06-app-service-terraform/azure-devops-service-connection.png"></p>

<p>You then select the scope but remember that if you want Terraform to be able to create resource groups, you should leave the <code>Resource group</code> select as unselected. Pick a short and sweet name, create and you are good to go. I distinguish between the development environment and the production environment in this tutorial and, you should preferably do that too. If you do so, you can use two different subscriptions.</p>

<h3 id="4-install-terraform">4. Install Terraform</h3>

<p>Download Terraform <a href="https://www.terraform.io/downloads.html">here</a>, zip it out and put it somewhere on your disk. Remember to add it to your system’s <code>PATH</code>.</p>

<h3 id="5-write-infrastructure-code">5. Write infrastructure code</h3>

<p>The fun begins after you have successfully installed Terraform. You can finally start writing deliberate infrastructure code in HcL so warm your fingers up and let’s start by getting your editor ready. If you are using Visual Studio Code, I highly recommend the excellent plugin <a href="https://marketplace.visualstudio.com/items?itemName=mauve.terraform">Terraform</a>.</p>

<p>So create these files:</p>

<ul>
<li>variables.tf</li>
<li>variables/dev.tfvars</li>
<li>variables/prod.tfvars</li>
<li>main.tf</li>
</ul>

<p><em>Terraform can be highly modular but for the purpose of this guide, I have decided to keep it as simple as possible.</em></p>

<h4 id="variables-tf">variables.tf</h4>

<p><code>variables.tf</code> is the home of all the variables but not the values themselves. The values can be found in the environment specific .tfvars files.</p>

<pre><code># General
variable "resource_group_name" {
  description = "The name of the resource group"
}

variable "location" {
  description = "The Azure region in which all resources should be created"
}

# App Service
variable "app_service_plan_name" {
  description = "The name of the app service plan for the backend"
}

variable "app_service_name" {
  description = "The name of the app service for the backend"
}

# Application Insights
variable "application_insights_name" {
  description = "The name of the application insights resource"
}
</code></pre>

<h4 id="variables-dev-tfvars">variables/dev.tfvars</h4>

<p><code>variables/</code> is the folder with the environment specific variable values. The example uses an homegrown Azure resources naming convention. Go with what you like as long as you keep it consistent.</p>

<pre><code>resource_group_name                       = "rg-terraform-dev"
location                                  = "West Europe"
app_service_plan_name_backend             = "azappp-terraform-dev"
app_service_name_backend                  = "azapp-terraform-dev"
application_insights_name                 = "appi-terraform-dev"
</code></pre>

<h4 id="variables-prod-tfvars">variables/prod.tfvars</h4>

<pre><code>resource_group_name                       = "rg-terraform-prod"
location                                  = "West Europe"
app_service_plan_name_backend             = "azappp-terraform-prod"
app_service_name_backend                  = "azapp-terraform-prod"
application_insights_name                 = "appi-terraform-prod"
</code></pre>

<h4 id="main-tf">main.tf</h4>

<p><code>main.tf</code> is where the infrastructure code resides. The Azure Provider is well documented and it can be found <a href="https://www.terraform.io/docs/providers/azurerm/">here</a>.</p>

<pre><code>/*
* Provider block defines which provider they require
*/

provider "azurerm" {
  version = "=2.26.0"
  features {}
}

terraform {
  backend "azurerm" {}
}

/*
* Resource Group
*/
resource "azurerm_resource_group" "this" {
  name     = var.resource_group_name
  location = var.location
}

/*
* App Service Plan
*/
resource "azurerm_app_service_plan" "this" {
  name                = var.app_service_plan_name
  location            = azurerm_resource_group.this.location
  resource_group_name = azurerm_resource_group.this.name
  kind                = "Windows"

  sku {
    tier = "Standard"
    size = "S1"
  }
}

/*
* App Service
*/
resource "azurerm_app_service" "this" {
  name                = var.app_service_name
  location            = azurerm_resource_group.this.location
  resource_group_name = azurerm_resource_group.this.name
  app_service_plan_id = azurerm_app_service_plan.this.id

  site_config {
    websockets_enabled = true
  }

  app_settings = {
    "APPINSIGHTS_INSTRUMENTATIONKEY"      = "${azurerm_application_insights.this.instrumentation_key}"
    "APPINSIGHTS_PORTALINFO"              = "ASP.NET"
    "APPINSIGHTS_PROFILERFEATURE_VERSION" = "1.0.0"
    "WEBSITE_HTTPLOGGING_RETENTION_DAYS"  = "35"
  }
}

/*
* Application Insights
*/
resource "azurerm_application_insights" "this" {
  name                = var.application_insights_name
  location            = azurerm_resource_group.this.location
  resource_group_name = azurerm_resource_group.this.name
  application_type    = "web"
}
</code></pre>

<h3 id="6-create-storage-account-for-state-files">6. Create storage account for state files</h3>

<p>Terraform relies on a state file so it can know what has been done and so forth. The Terraform extension will use a storage account in Azure that we define. So go to your Azure portal and create these resources or use your existing ones.</p>

<ul>
<li>Resource Group: rg-terraform-demo</li>
<li>Storage Account: stterraformdemo</li>
<li>Storage Container: terraform</li>
</ul>

<p>The resource naming is completely optional since they are inside the azure-pipelines.yml file. Remember to double-check the state file resources in <code>azure-pipelines.yml</code>.</p>

<h3 id="7-write-build-pipeline">7. Write build pipeline</h3>

<p>The infrastructure is defined and ready to be deployed on Azure but before we can do that, we would have to define the AzureDevOps build pipeline.</p>

<p>In this example, I will use a deployment template so we can keep it clean in the main azure-pipelines file and reuse it later.</p>

<p>So create these files:</p>

<ul>
<li>azure-pipelines.yml</li>
<li>azure-pipelines-deployment-template.yml</li>
</ul>

<h4 id="azure-pipelines-yml">azure-pipelines.yml</h4>

<p>The two stages, <code>DeployDev</code> and <code>DeployProd</code> is identical apart from the variables passed in the template and that the <code>DeployProd</code> only triggers from the <code>master</code> branch.</p>

<pre><code># Set how the build pipeline triggers
trigger:
  branches:
    include:
      - develop
      - master

# Just say its gonna trigger on pull requests too
pr:
  branches:
    include:
      - develop
      - master

variables:
  # Name of the pipeline. Defaults to the AzureDevOps project name but it can be changed.
  - name: pipelineName
    value: TerraformDemo
  # Name of the resource group where the state file lies
  - name: tfStateRgName
    value: rg-terraform-demo
  # Name of the storage account for the state file
  - name: tfStateStName
    value: stterraformdemo
  # Name of the container for the state file
  - name: tfStateCtrName
    value: terraform

stages:
- stage: DeployDev
  displayName: Deploy Dev
  jobs:
  - template: azure-pipelines-deployment-template.yml
    parameters:
      environment: 'Dev'
      pipelineName: ${{variables.pipelineName}}
      backendServiceName: AzureDev
      tfStateRgName: ${{variables.tfStateRgName}}
      tfStateStName: ${{variables.tfStateStName}}
      tfStateCtrName: ${{variables.tfStateCtrName}}

- stage: DeployProd
  displayName: Deploy Prod
  condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/master'))
  jobs:
  - template: azure-pipelines-deployment-template.yml
    parameters:
      environment: 'Prod'
      pipelineName: '${{variables.pipelineName}}'
      backendServiceName: AzureProd
      tfStateRgName: '${{variables.tfStateRgName}}'
      tfStateStName: '${{variables.tfStateStName}}'
      tfStateCtrName: '${{variables.tfStateCtrName}}'
</code></pre>

<h4 id="azure-pipelines-deployment-template-yml">azure-pipelines-deployment-template.yml</h4>

<pre><code>parameters:
- name: 'environment'
  type: 'string'
  displayName: 'The name of the environment'

- name: 'pipelineName'
  type: 'string'
  displayName: 'The name of the pipeline'

- name: 'backendServiceName'
  type: 'string'
  displayName: 'The name of the backend service'

- name: 'tfStateRgName'
  type: 'string'
  displayName: 'The name of the az resource group where the tf state file should be'

- name: 'tfStateStName'
  type: 'string'
  displayName: 'The name of the az storage account where the tf state file should be'

- name: 'tfStateCtrName'
  type: 'string'
  displayName: 'The name of the az storage account container where the tf state should be'

jobs:
  - job: Deploy
    displayName: Deploy ${{parameters.environment}}
    continueOnError: false
    pool:
      name: 'Azure Pipelines'
      vmImage: 'windows-latest'
    steps:
    - task: …</code></pre></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.andreasrein.net/posts/app-service-terraform-azure-azuredevops/">https://www.andreasrein.net/posts/app-service-terraform-azure-azuredevops/</a></em></p>]]>
            </description>
            <link>https://www.andreasrein.net/posts/app-service-terraform-azure-azuredevops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24530366</guid>
            <pubDate>Sat, 19 Sep 2020 21:16:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: My Python Notebook Driven Book on Evolutionary Algorithms]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24530288">thread link</a>) | @DataCrayon
<br/>
September 19, 2020 | https://datacrayon.com/posts/search-and-optimisation/practical-evolutionary-algorithms/preface/ | <a href="https://web.archive.org/web/*/https://datacrayon.com/posts/search-and-optimisation/practical-evolutionary-algorithms/preface/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div>
<div>

<p>Evolutionary Algorithms (<em>EAs</em>) are a fascinating class of algorithms for meta-heuristic optimisation. There exist many books on the topic of EAs, ranging from their theory to practice. The first book I read on the topic was <em>Genetic algorithms in search, optimization, and machine learning</em> by David E. Goldberg (1989), and to this day I still recommend it to new students in the field.</p>

</div>
</div>
</div><div>

<div>
<p>However, there is a re-occurring difficulty when my students are starting out in the field, <em>"how do I move from theory to practice?"</em>. Most books will have some chapters dedicated to applications of EAs, but what's missing is an up-to-date book dedicated to using modern technology and concepts.</p>
</div>
</div><div>

<div>
<div>
<p>When writing this book, I had to answer some difficult questions:</p>
<ul>
<li>What programming language will my examples be written in?</li>
<li>What software libraries will I use?</li>
<li>How do I structure the chapters and sections, do I lead entirely by example or do I dedicate some parts to the theory?</li>
<li>Do I focus on single-objective EAs or multi-objective EAs?</li>
</ul>
<p>Nevertheless, the decisions had to be made. I selected Python as the programming language simply due to its rise in popularity (in 2019), and this was only a difficult choice because there is a wealth of resources written for MATLAB. Of the resources written in MATLAB, it is a shame to not be able to use PlatEMO, which is a well-maintained open-source platform for Evolutionary Multi-objective Optimisation. In its place, when a software library is needed, I will turn to Platypus, which provides optimisation algorithms and analysis tools for multi-objective optimisation.</p>
<p>For the structure of the chapters and sections, I have decided to lead entirely by example. There will be code to demonstrate every concept used, and I will show how we can implement algorithms from their mathematical representation. In these cases, I will focus on the readability of the implementations rather than their performance.</p>
<p>Finally, I will focus on multi-objective EAs as this represents the majority of real-world problems. However, single-objective EAs will make an appearance to highlight the differences between the two.</p>

</div>
</div>
</div><div>

<div>
<p>Perhaps the most difficult question to answer is <em>where do we start?</em> There is so much to cover, and many potential starting points. For this book, I will start with a definition of objective functions, and illustrate the relationship between what we call the problem space and the objective space. With this approach, I hope there will be a clear understanding of what the various operators within an EA are affecting.</p>
</div>
</div></div>]]>
            </description>
            <link>https://datacrayon.com/posts/search-and-optimisation/practical-evolutionary-algorithms/preface/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24530288</guid>
            <pubDate>Sat, 19 Sep 2020 21:01:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Can TikTok be banned from US based Android devices?]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 33 (<a href="https://news.ycombinator.com/item?id=24530155">thread link</a>) | @bluegopher
<br/>
September 19, 2020 | https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/ | <a href="https://web.archive.org/web/*/https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
      Legal questions aside, let's explore the technical possibilities.
    </p><div>

<p>Let’s be very clear here. I am not a fan of TikTok. I had the misfortune of coming across it when it was still called Musically and I had to explain to a little girl that she, unlike her friends, was not allowed to dance for strangers. That ruined an otherwise perfect evening.</p>

<p>I’m also not a fan of Donald Trump(et). It’s safe to assume that he threatens to shut down TikTok for all the wrong reasons, but if he manages to pull through, it will be a benefit for mankind. So, is it actually technically possible to get TikTok and WeChat banned in the US?</p>

<h2 id="removing-apps-from-google-play">Removing apps from Google Play</h2>

<p>Story time (you can skip ahead two paragraphs for an obvious revelation)!</p>

<p>I once wrote a pretty silly slot machine game for Android. It was as a coding exercise and failed in pretty much every aspect except being recognized for what it actually wasn’t: a real gambling app.
</p><figure>
  <a href="https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/pocketbandit.png">
    <img src="https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/pocketbandit.png">
  </a>
  
  <figcaption>Pocket Bandit: pretty (, colorful,) boring</figcaption>
  
</figure><p>
                             
                             
All you could do was to bet one to three coins, then pull the lever and watch the reels spin. You started with a fixed amount of credit and the laws of probability dictated that you’d eventually go bankrupt. Once that happened, you could simply restarted the “game” and had a full purse again. No <em>wait x hours or pay $$$ to continue playing</em> bullshit. No way of winning anything either. In other words: the most boring one-armed bandit ever. Not even suitable for detoxing a gambling addict. I had somehow managed to put in all the mechanics of a classical slot machine except the one (winning/loosing) that was responsible for producing the excitement.</p>

<p>Well, there’s no rule that states, you can’t publish rubbish on Google Play. Much to my surprise though, there is a rule that says, you can’t publish gambling apps in some Arab countries without governmental approval. So, one fateful morning, I received a mail from Google telling me that my app had been pulled from Play in those countries. I was pissed. Not because the world needed my app. Not because some Arabs were now deprived of the most dull entertainment, only I could provide. I was pissed because someone had obviously only spent the time of looking at the screenshots to determine that this was a gambling app, but hadn’t bothered to reason how you were suppose to spend (real) money in an app that doesn’t even request network permission. It felt unjustified. Like a downvote driven in with the banhammer. Someone with the attention span of a puppy had the power of Thor.</p>

<p>There was no point in appealing. After all, the game was crap, but the incident was a nice reminder on how fragile businesses, build on apps are. Somewhere, someone with too little time to be thorough can simply nuke them without prior warning. Needless to say, that in time, the same  kind of sloppiness resulted in more of my apps being pulled …</p>

<p>So, what’s the take away from my story?</p>

<p>Geo fencing has always been a core feature of Play and Google never really went out of its way to stand up for developers. Sure, my apps are small fries compared to behemoths like TikTok, but then again, they aren’t direct competitors to youtube either. Let’s keep that in mind in case anyone has high hopes for Google putting up a fight.</p>

<h2 id="what-about-sideloading">What about sideloading?</h2>

<p>Who needs Play anyway? Android is not IOS, we can simply download the APK off the web and install it ourselves, right? Eh well, no. It’s not that simple. Bytedance swallowed Google’s Cool Aid and switched to App Bundles/Dynamic Delivery in order to reduce the size of their app. So instead of a single, one size fits all APK, you get a bunch of individual files. In case of TikTok v17.6.3 and depending on your device, the list might look like this:</p>

<ul>
<li>com.zhiliaoapp.musically-2021706030.apk</li>
<li>com.zhiliaoapp.musically-2021706030_config.armeabi_v7a.apk</li>
<li>com.zhiliaoapp.musically-2021706030_config.en.apk</li>
<li>com.zhiliaoapp.musically-2021706030_config.xhdpi.apk</li>
<li>com.zhiliaoapp.musically-2021706030_df_creationtool_so.apk</li>
<li>com.zhiliaoapp.musically-2021706030_df_creationtool_so.config.armeabi_v7a.apk</li>
<li>com.zhiliaoapp.musically-2021706030_df_fusing.apk</li>
<li>com.zhiliaoapp.musically-2021706030_df_photomovie.apk</li>
</ul>

<p>Split APKs cannot be sideloaded (easily). On plain Android, there’s simply no user interface for telling the packagemanager that you want it to install an app from several connected files (<a href="https://raccoon.onyxbits.de/blog/merge-split-apk/">after all, making sideloading difficult was/is the whole idea behind App Bundles</a>). You need extra tools (e.g. ADB) for that. But let’s be brutally honest here, if you are in the target audience of TikTok, then you are probably missing a brain cell or two (out of a total of two) and won’t be able to use them.</p>

<div>
  
  <p><span>Fun fact</span>
  
  
App Bundles have a build in security flaw. Traditional APKs cannot be modified by the Playstore. App Bundles can. For rogue government agencies, this provides the option of pushing hacked app updates to </p><u>selected</u><p> individuals. For that reason, <b>no</b> app in the "communications" category should ever use App Bundles as a distribution format. Imagine that! Coincidentally, Trump was actually right when calling TikTok a security issue. Cheers ByteDance!

</p></div>
                             
                             

<p>So, why doesn’t ByteDance simply host a traditional APK on the TikTok website then?</p>

<p>Two reasons actually</p>

<ol>
<li>Self hosting your app means, people will download the self hosted version (duh!), even if they could get it from the Playstore. As a result, the Playstore version sees less downloads, less reviews and less ratings which may eventually lead to it spiraling down in the rankings (ever wondered why all youtubers end their videos with the magic mantra “like and subscribe, hit the bell and give me a thumbs up”? Same mechanic there). This, by the way was the leverage, Google used to monopolize the app store market on Android: you are free to host elsewhere, but if your competitors solely host with us, they will eventually outrank you.</li>
<li>ByteDance not only drank the Google Cool aid, but also coughed it up and swallowed it again. Part of their revenue is in-app purchases. Those don’t work with sideloaded APKs. They could, of course, implement their own <abbr title="In App Purchase">IAP</abbr>, but that’s something <a href="https://raccoon.onyxbits.de/blog/2020081401/">Epic tried with Fortnite</a> recently…</li>
</ol>

<h2 id="removing-existing-tiktok-installations-from-devices">Removing existing TikTok installations from devices</h2>

<p>Buckle up, this may come as a surprise or as a confirmation of your fears!</p>

<p>Did you ever notice the big green “install” button on the Google Play website? With it, you can conveniently browse the store on your PC and send apps to your phone for installation.</p>

<figure>
  <a href="https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/googleplay-tiktok.png">
    <img src="https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/googleplay-tiktok.png">
  </a>
  
  <figcaption>Screencap: The install button on the Play website is sort off a remnant from the old days when 320x480 screens where the norm and you'd rather browse the androidmarket (as it was called back then) on your PC.</figcaption>
  
</figure>
                             
                             

<p>This is done via “Push messages”. Which is just a modern way of saying that your phone wakes up every couple of minutes in order to waste battery and bandwidth on checking if there are any new ads you should see. It also checks if there are any app updates or pending installs (from the green button) while it is at it, just so you have a reason not to disable the <del>spy</del> playstore app when you don’t need it. The relevant <a href="https://developers.google.com/protocol-buffers/">message structure</a> looks like this:</p>

<div><pre><code data-lang="protobuf"><span>message</span> <span>Notification</span> {<span>
</span><span></span>  <span>optional</span> <span>int32</span> notificationType <span>=</span> <span>1</span>;<span>
</span><span></span>  <span>optional</span> <span>int64</span> timestamp <span>=</span> <span>3</span>;<span>
</span><span></span>  <span>optional</span> Docid docid <span>=</span> <span>4</span>;<span>
</span><span></span>  <span>optional</span> <span>string</span> docTitle <span>=</span> <span>5</span>;<span>
</span><span></span>  <span>optional</span> <span>string</span> userEmail <span>=</span> <span>6</span>;<span>
</span><span></span>  <span>optional</span> AndroidAppNotificationData appData <span>=</span> <span>7</span>;<span>
</span><span></span>  <span>optional</span> AndroidAppDeliveryData appDeliveryData <span>=</span> <span>8</span>;<span>
</span><span></span>  <span>optional</span> PurchaseRemovalData purchaseRemovalData <span>=</span> <span>9</span>;<span>
</span><span></span>  <span>optional</span> UserNotificationData userNotificationData <span>=</span> <span>10</span>;<span>
</span><span></span>  <span>//optional InAppNotificationData inAppNotificationData = 11;
</span><span></span>  <span>//optional PurchaseDeclinedData purchaseDeclinedData = 12;
</span><span></span>  <span>optional</span> <span>string</span> notificationId <span>=</span> <span>13</span>;<span>
</span><span></span>  <span>optional</span> LibraryUpdate libraryUpdate <span>=</span> <span>14</span>;<span>
</span><span></span>  <span>optional</span> LibraryDirtyData libraryDirtyData <span>=</span> <span>15</span>;<span>
</span><span></span>}<span>
</span><span>
</span><span></span><span>message</span> <span>AndroidAppDeliveryData</span> {<span>
</span><span></span>  <span>optional</span> <span>int64</span> downloadSize <span>=</span> <span>1</span>;<span>
</span><span></span>  <span>optional</span> <span>string</span> signature <span>=</span> <span>2</span>;<span>
</span><span></span>  <span>optional</span> <span>string</span> downloadUrl <span>=</span> <span>3</span>;<span>
</span><span></span>  <span>repeated</span> AppFileMetadata additionalFile <span>=</span> <span>4</span>;<span>
</span><span></span>  <span>repeated</span> HttpCookie downloadAuthCookie <span>=</span> <span>5</span>;<span>
</span><span></span>  <span>optional</span> <span>bool</span> forwardLocked <span>=</span> <span>6</span>;<span>
</span><span></span>  <span>optional</span> <span>int64</span> refundTimeout <span>=</span> <span>7</span>;<span>
</span><span></span>  <span>optional</span> <span>bool</span> serverInitiated <span>=</span> <span>8</span>;<span>
</span><span></span>  <span>optional</span> <span>int64</span> postInstallRefundWindowMillis <span>=</span> <span>9</span>;<span>
</span><span></span>  <span>optional</span> <span>bool</span> immediateStartNeeded <span>=</span> <span>10</span>;<span>
</span><span></span>  <span>optional</span> AndroidAppPatchData patchData <span>=</span> <span>11</span>;<span>
</span><span></span>  <span>optional</span> EncryptionParams encryptionParams <span>=</span> <span>12</span>;<span>
</span><span></span>  <span>optional</span> <span>string</span> gzippedDownloadUrl <span>=</span> <span>13</span>;<span>
</span><span></span>  <span>optional</span> <span>int64</span> gzippedDownloadSize <span>=</span> <span>14</span>;<span>
</span><span></span>  <span>repeated</span> SplitDeliveryData splitDeliveryData <span>=</span> <span>15</span>;<span>
</span><span></span>  <span>optional</span> <span>int32</span> installLocation <span>=</span> <span>16</span>;<span>
</span><span></span>}<span>
</span><span>
</span><span></span><span>message</span> <span>PurchaseRemovalData</span> {<span>
</span><span></span>  <span>optional</span> <span>bool</span> malicious <span>=</span> <span>1</span>;<span>
</span><span></span>}</code></pre></div>

<p>A request to delete an app from a device looks like this:</p>

<div><pre><code data-lang="protobuf">notificationType<span>:</span> <span>2</span><span>
</span><span></span>docid {<span>
</span><span></span>  backendDocId<span>:</span> <span>"com.zhiliaoapp.musically"</span><span>
</span><span></span>}<span>
</span><span></span>purchaseRemovalData {<span>
</span><span></span>  malicious<span>:</span> <span>true</span><span>
</span><span></span>}</code></pre></div>

<p>Note that the malicious flag is purely cosmetic. The only thing Play has to send is the package name of the app and the notificationType 2. The app gets deleted, even if it wasn’t installed via Play.</p>

<h2 id="blocking-tiktok-in-the-usa">Blocking TikTok in the USA</h2>

<p>Let’s say you are an existing TikTok user and a US citizen. Let’s say, after reading the above, you disable the Playstore client, so Google can’t delete apps from your phone. What are they going to do then? Tell your ISP to firewall the TikTok servers (I heard, China has the tech for that. Maybe they’ll share…)? Well, curiously, there’s a much simpler solution. Did I already mention that ByteDance drank the Google Coolaid to the last drip? Let’s use an <a href="https://raccoon.onyxbits.de/">apk downloader</a> to request the <a href="https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/com_zhiliaoapp_musically.json">Google Playstore entry for the TikTok app</a>. Here’s an excerpt:</p>

<div><pre><code data-lang="json"><span>"dependency"</span><span>:</span> [{
          <span>"packageName"</span>: <span>"com.google.android.gms"</span>,
          <span>"minVersionCode"</span>: <span>12451000</span>,
          <span>"skipPermissions"</span>: <span>true</span>,
          <span>"deferredInstallAllowed"</span>: <span>false</span>
        }]</code></pre></div>

<p>The <code>com.google.android.gms</code>package is …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/">https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/</a></em></p>]]>
            </description>
            <link>https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24530155</guid>
            <pubDate>Sat, 19 Sep 2020 20:35:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Effective ML (and F#)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24529774">thread link</a>) | @jasim
<br/>
September 19, 2020 | http://bugfree.dk/blog/2012/06/24/effective-ml-and-fsharp | <a href="https://web.archive.org/web/*/http://bugfree.dk/blog/2012/06/24/effective-ml-and-fsharp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">
  <p>
    This is a summary of <a href="http://twitter.com/#!/yminsky">Yaron Minsky</a>'s nine pieces of advice from the <a href="http://vimeo.com/14313378">Effective ML</a> video. Since ML is a predecessor of F#, most of the advice applies to F# as well.
  </p>
  <p>
    <strong>1. Favor readers over writers (10:20)</strong>. There're systematic differences in opinion between those who spent their time reading code and those who spent it writing code. Whenever there's a difference in opinion between these two groups, the readers are always right and the writers are always wrong. The readers will always push in the direction of clarity and simplicity and the ability to change behavior easily. At least if you're building software that's going to last.
  </p>
  <p>
    <strong>2. Create uniform interfaces (12:15)</strong>. Always create an interface to your code to make it easier on the reader. When you build interfaces, you should have standards that apply uniformly across your code base to build solid expectations. Those who use your code should know what to provide and what to expect when interfacing with your codebase.
  </p>
  <p>
    <strong>3. Make illegal states unrepresentable (18:03)</strong>. Use the type system as a tool to enforce invariants on the code you write. Choose your data types such that states that are illegal don't show up as legal states in the program. Take this code representing various connection information as an example. It keeps track of relevant information in a fairly readable manner:
  </p>
  <pre>type connection_state =
  | Connecting
  | Connected
  | Disconnected

type connection_info = {
    state:             connection_state
    server:            IPAddress
    last_ping_time:    DateTime option
    last_ping_id:      int option
    session_id:        string option
    when_initiated:    DateTime option
    when_disconnected: DateTime option
}</pre>
  <p>On the surface these types look reasonable, but there're some tricky invariants that need to hold about the data. For instance, if you have a last_ping_time, you should probably also have a last_ping_id and vice versa. And the session_id and when_initiated probably only makes sense when you're connected. Similarly, when_disconnected only makes sense if you've been disconnected.</p>
  <p>The key is that there's nothing about the types that help you enforce all these invariants. A better approach would be to refactor the connection_info into a series of types where the invariants would be inherent in the types themselves rather than being implicit in the logic surrounding the types:</p>
  <pre>type connecting = { when_initiated: DateTime }
type connected = { last_ping: (DateTime * int) option
                   session_id: string }
type disconnected = { when_connected: DateTime }

type connection_state =
  | Connecting of connecting
  | Connected of connected
  | Disconnected of disconnected

type connection_info = {
    state: connection_state
    server: IPAddress
}</pre>
  <p>server remains in connection_info because it applies to any of the states. The other information have been grouped together with the state it related to. The different connection_states are no longer merely a simple enumerated type but each of the different tags have content. Note also how the last_ping is now both the last_ping_time and last_ping_id. Either both are present, and grouped together, or not.</p>
  <p>
    <strong>4. Code for exhaustiveness (28:33)</strong>. This one is closely related to making illegal states unrepresentable in that you should write your code aiming at exhaustiveness guarantees. For instance, when you have a match statement, the compiler will warn you if the match isn't exhaustive. The key benefit is as a refactoring tool because it guides changes in the code base. Don't use the match all because it means that if you expand on the discriminated union the compiler will not warn you.
  </p>
  <p>
    <strong>5. Open few modules (34:08)</strong>. When you open a module, it makes your code a bit shorter, and that's great for the guy who wrote the code, but not the guy reading it. Now you can no longer just look at the code and tell where the value came from. In F#, with Visual Studio integration and IntelliSense, this is less of a problem. But the key advice is to respect the cognitive limitation of the people reading the code. If you want people to remember something, make them remember only for a short period of time.
  </p>
  <p>
    <strong>6. Make common errors obvious (38:10)</strong>. Use exceptions for exceptional conditions is what people often tell you. But whether something is a common case depends on context. For instance, in one context it's an error if an element isn't in a list, whereas in others it's perfectly acceptable. For your API it may depend on the caller if a case is exceptional or not. To better support the caller, you could create two versions depending on how you want to communicate an error:
  </p>
  <pre>val hd : 'T list -&gt; 'T option
val hd_exn : 'T list -&gt; 'T</pre>
  <p>Now you can tell from the name of the function weather it throws an exception or not. For people reading the code it makes it easier to understand the error behavior of the code.</p>
  <p>
    <strong>7. Avoid boilerplate (40:52)</strong>. Avoid repeating the same code, or almost the same code, in multiple places. Boilerplate appears, in general, because people have a cut and paste template they use to do almost the same thing in multiple spots and because their language isn't good enough to encode what they want to do in a clean way. You want to get rid of boilerplate because the structure you're repeating is there for a reason, and your code evolves. At that point you're not going to remember all the places where the repetition shows up. It also goes back to readability. It's hard to convince people to read code if it's dull. And nothing is duller than boilerplate, even though the code is critical.
  </p>
  <p>Interestingly, reducing boilerplate doesn't always make code less verbose. The goal isn't to make the code shorter but to separate out which parts of the code is the same and which parts vary.</p>
  <p>
    <strong>8. Avoid complex type hackery (45:30)</strong>. The enemy of good code, of correctness, isn't dynamic guarantees, properties about the code that cannot be proved at compile time, but complexity. Refrain from making your code more complex (using <a href="http://mlton.org/PhantomType">phantom types</a>, for instance), just so you can have the type system verify additional properties of the code.
  </p>
  <p>
    <strong>9. Don't be puritanical about purity (47:10)</strong>. Avoiding side-effect is generally worth striving for, because code without side-effects tends to be easier to reason about. But sometimes it's also just easier to code with side-effects. There may even be performance reasons for allowing side-effects so don't be embarrassed about it. In reality, programs don't just compute things, they do things like write files, send messages, and so on. All this doing involves side-effects. Again, remember that the enemy of correctness is complexity. Don't jump through hoops to make your code too complex just to make it pure.
  </p>
</div></div>]]>
            </description>
            <link>http://bugfree.dk/blog/2012/06/24/effective-ml-and-fsharp</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529774</guid>
            <pubDate>Sat, 19 Sep 2020 19:17:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How does Django validate passwords?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24529740">thread link</a>) | @rangerranvir
<br/>
September 19, 2020 | https://ranvir.xyz/blog/how-does-django-validate-passwords/ | <a href="https://web.archive.org/web/*/https://ranvir.xyz/blog/how-does-django-validate-passwords/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><img data-src="https://i.ibb.co/n3YzYyF/Main-Images-4-1.png" alt="How does Django validate passwords" title="How does Django validate passwords" src="https://i.ibb.co/n3YzYyF/Main-Images-4-1.png">
</p><p>
A few days ago, I was working on one of my old Django projects. It was running an old version of Django and I wanted to keep it updated with the latest changes of the framework.</p>
<p>
So to check the <a href="https://ranvir.xyz/blog/django-admin-tips-and-tricks/">admin site</a>, I tried to create the superuser after connection to the local database.</p>
<div><div><pre><code><span>python</span> <span>manage</span><span>.</span><span>py</span> <span>createsuperuser</span>
</code></pre></div></div>

<p>
When I passed a password similar to the username it failed saying, <code>The password is too similar to the username.</code></p>
<p><img data-src="https://i.ibb.co/94D2x9G/Screenshot-2020-09-19-at-1-32-17-AM.png" alt="The password is too similar to the username" title="The password is too similar to the username" src="https://i.ibb.co/94D2x9G/Screenshot-2020-09-19-at-1-32-17-AM.png">
</p><p>
This error triggered me to check the working behind this password validation feature.</p><p>
The first thing that I looked into was the <code>manage.py</code> file itself which in turn was importing and executing a method called, <code>execute_from_command_line</code>.</p><p>
I traced it back and found a package <code>commands</code> containing everything that I wanted to know. This directory had two files.</p>
<div><div><pre><code><span>1.</span> <span>createsuperuser</span><span>.</span><span>py</span>
<span>2.</span> <span>changepassword</span><span>.</span><span>py</span>
</code></pre></div></div>
<h2 id="the-changepassword-command">The changepassword command</h2><p>
Since I had never used/ heard about the <code>changepassword</code> command, I thought of trying it first and to my great pleasure, it worked. You have to pass the username as the first argument.</p>
<div><div><pre><code><span>python</span> <span>manage</span><span>.</span><span>py</span> <span>changepassword</span> <span>username</span>
</code></pre></div></div>
<p><img data-src="https://i.ibb.co/YRfMkYW/Screenshot-2020-09-19-at-3-10-09-AM.png" alt="python manage.py changepassword" title="python manage.py changepassword" src="https://i.ibb.co/YRfMkYW/Screenshot-2020-09-19-at-3-10-09-AM.png">
</p><p>
Sometimes you find gold when you read the code, right? ðŸ˜�</p><p>
Now letâ€™s get back to the business and look into the <code>createsuperuser</code> command class in more detail.</p>
<h2 id="fetching-the-correct-database">Fetching the correct database</h2><p>
If you have been using Django for some time, you would know that Django allows you to change a lot of things depending upon the settings you define.</p><p>
This also includes using some random model as your base User model. This is the first thing that the superuser creation <code>__init__</code> constructor method checks for.</p>
<h2 id="creating-the-superuser-without-interaction">Creating the superuser without interaction</h2><p>
You can use a version of the command that allows you to create the superuser without any interaction.</p>
<div><div><pre><code><span>python</span> <span>manage</span><span>.</span><span>py</span> <span>createsuperuser</span> <span>--</span><span>username</span> <span>ranvir</span> <span>--</span><span>email</span> <span>abc</span><span>@</span><span>abc</span><span>.</span><span>com</span> <span>--</span><span>no</span><span>-</span><span>input</span>
</code></pre></div></div>
<p><img data-src="https://i.ibb.co/LJtHHq5/Screenshot-2020-09-19-at-3-17-49-AM.png" alt="python manage.py createsuperuser no-input" title="python manage.py createsuperuser no-input" src="https://i.ibb.co/LJtHHq5/Screenshot-2020-09-19-at-3-17-49-AM.png">
</p><p>
Although the user created using this process will have no password. We can create the password either using the <code>changepassword</code> command or the admin panel.</p>
<h2 id="required-fields-and-interactive-mode">Required fields and interactive mode</h2><p>
For the default <code>User</code> model, <code>email</code> is the only required field but you can change that by changing your <code>REQUIRED_FIELD</code> setting as well.</p><p>
In the interactive mode( which is the default mode as well), the first thing that the prompt asks you to fill, is the username.</p><p>

Django tries to smartly suggest the current system username as the default username. (Just Wow)</p>
<p><img data-src="https://i.ibb.co/pr1Z1Qw/Screenshot-2020-09-19-at-2-14-46-AM.png" alt="django suggest the current system username" title="django suggest the current system username" src="https://i.ibb.co/pr1Z1Qw/Screenshot-2020-09-19-at-2-14-46-AM.png">
</p><p>
It wonâ€™t suggest the system username if it is already taken. (Thatâ€™s AI for me ðŸ˜‚)</p>
<p><img data-src="https://i.ibb.co/r3YxbKL/Screenshot-2020-09-19-at-2-15-41-AM.png" alt="django doens't suggest the current system username if already taken" title="django doens't suggest the current system username if already taken" src="https://i.ibb.co/r3YxbKL/Screenshot-2020-09-19-at-2-15-41-AM.png">
</p><p>
After the username, you have to fill in the required field which is the email field for the default User model.</p><p>
Finally, you have to fill in the password field.</p>
<h2 id="the-validate-password-method">The validate password method</h2><p>
Sorry for keeping you waiting this long before jumping onto the real reason behind the post.</p><p>
The <code>validatepassword</code> is the function that is used to validate the password provided by the user.</p><p>
Again, we can configure all these validators as well, if these different password validation doesnâ€™t work for you, go forward and remove the classes from your settings file.</p><p>
These are the default validators.</p>
<div><div><pre><code><span>AUTH_PASSWORD_VALIDATORS</span> <span>=</span> <span>[</span>
    <span>{</span>
        <span>'NAME'</span><span>:</span> <span>'django.contrib.auth.password_validation.UserAttributeSimilarityValidator'</span><span>,</span>
    <span>},</span>
    <span>{</span>
        <span>'NAME'</span><span>:</span> <span>'django.contrib.auth.password_validation.MinimumLengthValidator'</span><span>,</span>
    <span>},</span>
    <span>{</span>
        <span>'NAME'</span><span>:</span> <span>'django.contrib.auth.password_validation.CommonPasswordValidator'</span><span>,</span>
    <span>},</span>
    <span>{</span>
        <span>'NAME'</span><span>:</span> <span>'django.contrib.auth.password_validation.NumericPasswordValidator'</span><span>,</span>
    <span>},</span>
<span>]</span>
</code></pre></div></div><p>
If we use the default validators, then the password,</p>
<ol>
<li>Should not be similar to <code>username</code>, <code>first_name</code>, <code>last_name</code> and <code>email</code>. It also checks for the similarity using <a href="https://docs.python.org/2.4/lib/sequence-matcher.html">SequenceMatcher</a>. It should be less than 0.7 similar which you can customize. (Told you, itâ€™s AI)</li>
<li>Should be greater than 8 characters.</li>
<li>Should not be in the list of common passwords. The list of common passwords is in the file, <code>common-passwords.txt.gz</code>. It contains a list of around 20000 common passwords which you should not use.</li>
<li>Should not contain all numeric characters.</li>
</ol><p>
I would suggest keeping the basic configuration intact for the password handling. You can use your own validations on top of it as well.</p><p>
So, thatâ€™s it for this time. Till next time.</p>
</div></div>]]>
            </description>
            <link>https://ranvir.xyz/blog/how-does-django-validate-passwords/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529740</guid>
            <pubDate>Sat, 19 Sep 2020 19:11:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pachyderm vs. Airflow]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24529683">thread link</a>) | @ishcheklein
<br/>
September 19, 2020 | https://szeitlin.github.io/posts/engineering/pachyderm-vs-airflow/ | <a href="https://web.archive.org/web/*/https://szeitlin.github.io/posts/engineering/pachyderm-vs-airflow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

<p>If you do a lot of data pipelining, you’ve probably heard a lot about Airflow by now. I gave a talk
about it a while back at a meetup, and wrote a blog post about it. The gist of my pitch for Airflow
was essentially <em>“Look, it’s so much better than cron.”</em></p>

<p>Fast-forward a year or two, and my team is using Pachyderm now. This post is about why I wanted to try Pachyderm,
what I love about it, some things that can be improved about it, and some of the tricks you’ll need to know if you want to start using it.</p>

<p><em>Note: I am not in any way being paid by Pachyderm.</em></p>

<hr>



<ul>
<li><p>Designed for a machine learning model workflow, but can also handle regular data pipelining
(including cron-style scheduling). This is incredibly reassuring to me, because Airflow is kind of the other way around.</p></li>

<li><p>Scalability (parallelization support). I haven’t done much with this yet, but it’s also reassuring to know it’s there,
since we’re a rapidly growing company, and I’m sure our data needs are going to continue to expand.</p></li>

<li><p>Data and code provenance tracking are built-in.</p></li>
</ul>

<p><em>What that means:</em> It’s easy to figure out what version
 of your code was running at any given time, and on what data. This is critical if you’re iterating on
 code for ETL processes or models, or tracking a model that’s going to evolve over time based on what data it has seen.</p>

<ul>
<li>The egress feature and built-in feed-forward are amazingly elegant.<br></li>
</ul>

<p>Feed-forward (I don’t know what they call it, that’s just what I call it) means
you can have one pipeline read from the output of another, and trigger off of that directly.</p>

<p>In Airflow, for comparison, you had to configure this with messaging and it was kind of clunky
(and originally there was no push, only pull, so you were always polling for <em>is that thing done yet?</em>).</p>

<p>In Pachyderm, it’s an extremely simple configuration.</p>

<p>Egress means you don’t have to write a plugin to do something as basic as push your data to s3. Pachyderm already
knows how to do that for you (see below for an example of how this is specified in a pipeline).</p>

<p>There’s also an easy way to tell it to re-process as much data as you want (*except for cron inputs, but they’re
going to fix that).</p>

<ul>
<li>Not having to clean up the fallout from runaway backfills</li>
</ul>

<p>Runaway backfill in Airflow made our server fall down more than once whenever anybody
forgot to update the start date or name of their DAG. This was a built-in default setting that we couldn’t change,
where Airflow would try to backfill any missing data to the beginning of time
(1970, of course), and celery would get overloaded.</p>

<p>We tried numerous approaches to make it impossible to do this
by accident, including having tests for checking that the start_date for a revised DAG
was always after the date of the latest changes.</p>

<p>It was the bane of my Airflow existence. Clearing the celery cache
and getting it to restart, and then backfill what we <em>actually</em> wanted was always a time-consuming process, including
kicking the web server again and getting everything back online.</p>

<ul>
<li>Smart re-tries by default (and this is configurable).</li>
</ul>

<p>Having retries at all was a big advantage of Airflow over basic cron, especially since it’s modular, so you can
have different re-try settings for each step of an ETL pipeline.</p>

<p>Having said that, this was a also kind of a pain to deal with in Airflow, because
if somebody set a ridiculous number of retries, or a backfill job was failing,
it could easily become a blocker for unrelated pipelines just by
gunking up the celery queue with tons of re-tries for something that was
 already failing (see above re: runaway backfill).</p>

<p>With Airflow, we were always having to guess about how many
retries to do, and how much back-off to add in between tries.</p>

<p>Pachyderm’s defaults for this are completely reasonable
(3 retries, with increasing delay in between each try).</p>

<p>If you get the enterprise version (which is cheap for an enterprise product):</p>

<ul>
<li><p>It’s more secure than Airflow, with built-in encryption (There’s also no risk of exposing
passwords by printing all the logs to a webpage that anyone can see, the way Airflow did by default.)</p></li>

<li><p>Really responsive and smart team, and a growing community of users</p></li>

<li><p>Nice dashboard to go with the CLI tool</p></li>

<li><p>Finally, if you don’t like writing DAGs in Airflow, and are considering one of the myriad (!) new tools
to simplify that for you, this is even simpler than that. (And in my opinion, makes a lot more sense.)</p></li>
</ul>

<p>And here’s an example of a full ETL process with 3 pipeline steps:</p>

<p><strong>1. Get the data from an api</strong></p>

<pre><code>{
    "pipeline": {
       "name": "api_to_s3_pipeline"
    },

    "transform": {
       "cmd": ["python3", "get_requests.py"],
       "image": "pathto.ecr.region.aws.com/mydockerregistry:my_api_image_v1",
       "image_pull_secrets": ["regcred"]
    },
    "input":{
        "cron": {
            "name": "api_daily_job",
            "spec": "16 6 * * *",
            "repo": "api_to_s3"
         }
    },
    "egress": {"URL": "s3://mys3bucket/"},
    "enable_stats": true,
    "job_timeout": 10m
}
</code></pre>

<p><strong>2. Process the data with pyspark on kubernetes</strong></p>

<pre><code>{
    "pipeline": {
       "name": "pyspark_pipeline"
    },

    "transform": {
       "cmd": ["python3", "pyspark_processsing.py"],
       "image": "pathto.ecr.region.aws.com/mydockerregistry:my_pyspark_image_v1",
       "image_pull_secrets": ["regcred"]
    },
    "input":{
        "atom": {
            "name": "pyspark_daily_job",
            "repo": "pyspark_daily_job",
            "glob: "/*/*/*/"
         }
    },
    "egress": {"URL": "s3://my-pyspark-bucket/"},
    "enable_stats": true,
    "job_timeout": 120m
}
</code></pre>

<p><strong>3. Load the data to Redshift</strong></p>

<pre><code>{
    "pipeline": {
       "name": "load_to_redshift_pipeline"
    },

    "transform": {
       "cmd": ["python3", "load_to_redshift.py"],
       "image": "pathto.ecr.region.aws.com/mydockerregistry:my_psycopg2_image_v1",
       "image_pull_secrets": ["regcred"]
    },
    "input":{
        "atom": {
            "name": "daily_load_job",
            "repo": "daily_load_job",
            "glob: "daily_*.gz"
         }
    },
    "enable_stats": true,
    "job_timeout": 125m
}
</code></pre>

<p>Also, they just got Series A funding, so they’re going to be around for a while.</p>

<hr>



<p>This was my first time using kubernetes, never mind suddenly being in charge of it (!).</p>

<p>Fair warning: Minikube is deceptively easy to set up and use for very basic testing. If this is all you do with
kubernetes, you’ll think Kubernetes very simple.</p>

<p>Kubernetes itself
isn’t that hard to deploy if you know what needs to be configured, but I really didn’t
know any of that when I started. I ran into some weird issues where the kubernetes control script
<code>kubectl</code> didn’t set the permissions correctly on some of the config files. (Shoutout to Sean Jezewski for helping me
troubleshoot unintuitive stuff like that.)</p>

<p>In case you’re wondering, as did almost everyone I spoke to while I was doing this,
EKS on AWS is not really ready for prime-time yet.</p>

<p>I ended up relying on a script that the Pachyderm guys wrote to deploy Kubernetes
directly on EC2, and just adapted that for our needs.</p>

<p>Things that are great about deploying in the cloud:</p>

<ul>
<li><p>Encapsulation is your friend. It’s so much easier when you have complete control of the environment, and there’s no mystery
about what packages are available or what the paths are.</p></li>

<li><p>Scaling becomes relatively easy. Just split your data and run more jobs in parallel.</p></li>
</ul>

<p>Things to remember about deploying in the cloud:</p>

<ul>
<li><p>Logging is your friend. You won’t be able to debug with print statements on a remote, headless machine. Some of my
teammates didn’t quite understand this until they actually did it. Good logging makes it trivially easy to figure out what went wrong.</p></li>

<li><p>Versioning is your friend. Kubernetes won’t pull the container unless it knows it needs to, so you have to keep renaming your container
if you want to test changes. It’s kind of a pain, but it’s simple enough to
just make it part of the workflow (and our next step is to have Jenkins do this for us as part of our
CICD workflow).</p></li>

<li><p>Having to rebuild the container and version it and push it up each time does a couple of things:</p></li>
</ul>

<p>a) Testing is even more important. It’s a lot nicer if you can do enough testing that after a few bug fixes you’re on version 4, rather than
(as one of my early pipelines is) version 16.</p>

<p>b) It can be a little bit more annoying to push bug fixes/updates (especially without a CICD system
to build and deploy the containers for you)</p>

<hr>



<ul>
<li>People steered us away from EKS, so then setting up our own kubernetes cluster without a
devops person (!) was challenging, mostly because of</li>

<li><p>AWS permissions issues, including but not limited to:</p>

<p>a) giving the cluster the ability to run queries on the RDS database in the same account</p>

<p>b) creating a separate VPC for Redshift so I could create a peering connection for that (see separate post)</p>

<p>c) giving the cluster the ability to access s3 buckets</p>

<p>d) giving my team access to the docker registries on ECS</p>

<p>e) stupid things like legacy s3 bucket region restrictions that are (or should be?)
going away any minute now(?), but EC2 still cares about, which generate completely
uninformative AccessDenied errors</p></li>

<li><p>Figuring out the workflow for deploying and debugging. This was a little weird at first, but once I got the hang of it,
actually very easy (more on that below)</p></li>

<li><p>Setting up a docker registry and using that (and we don’t have Jenkins handling that for us yet)</p></li>

<li><p>Managing two clusters on two separate accounts, and switching between them (learning in hard mode is not
always twice as fun as just learning!)</p></li>

<li><p>There is a built-in outlet to connect Pachyderm up with Prometheus, but no built-in monitoring means we’re doing it downstream
(i.e with automated email alerts sent from Looker if something fails) or manually checking via the
CLI or dashboard view. I have been using the CLI thus far, but now that we have more than a few pipelines
going on one cluster, the dashboard is starting to make more sense.</p></li>

<li><p>Understanding how the …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://szeitlin.github.io/posts/engineering/pachyderm-vs-airflow/">https://szeitlin.github.io/posts/engineering/pachyderm-vs-airflow/</a></em></p>]]>
            </description>
            <link>https://szeitlin.github.io/posts/engineering/pachyderm-vs-airflow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529683</guid>
            <pubDate>Sat, 19 Sep 2020 19:02:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On fast navigation in the command line]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24529677">thread link</a>) | @kkoncevicius
<br/>
September 19, 2020 | http://karolis.koncevicius.lt/posts/fast_navigation_in_terminal_coming_full_cirlce/ | <a href="https://web.archive.org/web/*/http://karolis.koncevicius.lt/posts/fast_navigation_in_terminal_coming_full_cirlce/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">




<p>A small list of methods for fast file system navigation from the command line.
While I tried all of them and finally settled on a minimal approach described at the end, the article doesn’t advocate for one method over the others.
Different users have different needs and should choose the approach most suitable in their circumstances.</p>

<h2 id="spring">Spring</h2>

<p>At the beginning, just after learning to use the command line, my terminal navigation included a lot of <code>cd</code> and a lot of <code>ls</code>.
I jumped around folders, learned shortcuts like, <code>cd ~</code>, <code>cd -</code>, and started becoming familiar with the shell.
Having multi-argument commands for quick file manipulation felt powerful and fresh, or so I remember.</p>

<p>After going to command line you no longer have to open folders in a graphical window manager, scan their names, use <code>&lt;ctrl + mouse click&gt;</code> to select them, and then drag the mouse to move those selected folders to another place.
You do <code>'mv pattern* place/'</code> instead.
All is nice.</p>

<p>But there was one problem.</p>

<h2 id="summer">Summer</h2>

<p>Along the way I started organizing my folders using a structure like this:</p>

<pre><code>└── work
    ├── bitbucket
    │   └── user1
    │       ├── repo1
    │       └── repo2
    ├── github
    │   ├── user1
    │   │   ├── repo1
    │   │   └── repo2
    │   ├── user2
    │   │   ├── repo1
    │   │   └── repo2
    │   ├── user3
    │   │   ├── repo1
    │   │   ├── repo2
    │   │   ├── repo3
    │   │   └── repo4
    │   └── user4
    │       └── repo1
    ├── teaching
    │   ├── class1
    │   │   ├── lecture1
    │   │   └── lecture2
    │   └── class2
    │       ├── lecture1
    │       └── lecture2
    ├─── clients
    │   ├── client1
    │   │   ├── project1
    │   │   ├── project2
    │   │   └── project3
    │   ├── client2
    │   │   ├── project1
    │   │   ├── project2
    │   │   └── project3
    │   └── client3
    │      └── project1
    └─── ...
</code></pre>

<p>I often had to go in and out of various project folders and my <code>cd</code> + <code>ls</code> navigation became tedious.
Reaching a project involved navigating a big tree of directories.
On top of that a lot of directories had similar names which got in the way of tab completion.
This is where I found “z” - a command line utility that tracks your most visited folders based on frequency and recency<a href="#fn:1" id="fnref:1" title="see footnote"><sup>◦</sup></a>.</p>

<p>“z” keeps a database of your most frequently used folders and allows to quickly jump to these folders even if you don’t remember their full name.
Instead of doing a lot of <code>cd</code> + <code>&lt;tab&gt;</code> all you have to do is type <code>'z proj'</code> and <code>z</code> will take you to your most frequently/recently accessed folder that has <code>proj</code> somewhere in its name.
It takes a short amount of time for “z” to learn about your most visited places but after that it becomes quick and convenient.</p>

<p>But there was one problem.</p>

<h2 id="autumn">Autumn</h2>

<p>“z” didn’t always take me where I wanted to be.
It worked, I would say, around 95% of the time or more.
But those other times it took me to an unrelated directory and distracted from the work at hand forcing to navigate my way back using the old <code>cd</code>.
Moreover, sometimes I moved and renamed various folders which likely contributed to its disorientation.</p>

<p>After this experience I decided that the terminal should be dumb and deterministic without any fuzziness or smart guessing.
And here I found <code>marks</code> - a short and sweet command line script for keeping manual directory bookmarks.<a href="#fn:2" id="fnref:2" title="see footnote"><sup>◦</sup></a>
It consisted of 4 tiny functions: one for creating a mark, one for removing, one for listing all the marks, and one for jumping to the bookmarked folder:</p>

<pre><code>export MARKPATH=$HOME/.marks

function mark {
  mkdir -p "$MARKPATH"; ln -s "$(pwd)" "$MARKPATH/$1"
}

function unmark {
  rm -i "$MARKPATH/$1"
}

function marks {
  ls -l "$MARKPATH" | sed 's/  / /g' | cut -d' ' -f9- | sed 's/ -/\t-/g' &amp;&amp; echo
}

function jump {
  cd -P "$MARKPATH/$1" 2&gt;/dev/null || echo "No such mark: $1"
}
</code></pre>

<p>As well as a function generating completion suggestions after pressing <code>&lt;tab&gt;</code>:</p>

<pre><code>_completemarks() {
  local curw=${COMP_WORDS[COMP_CWORD]}
  local wordlist=$(find $MARKPATH -type l -printf "%f\n")
    COMPREPLY=($(compgen -W '${wordlist[@]}' -- "$curw"))
    return 0
}

complete -F _completemarks jump unmark
</code></pre>

<p>The workflow of marks is manual but convenient.
You have to go into the directory you want to bookmark and execute the <code>mark</code> command followed by the custom name, like <code>'mark myproject'</code>.
After that you can quickly jump back to this bookmarked folder using <code>'jump myproject'</code> and when the bookmark is no longer relevant you can get rid of it with <code>'unmark myproject'</code>.</p>

<p>With this approach the user is in control.
There is no secret smart behaviour which means no auto-magic and no surprises.
And after moving a project to another place the bookmark can be easily adjusted to point to its new location immediately, without waiting for a hidden automatic process to update its location, frequency, and recency.</p>

<p>But there was one problem.</p>

<h2 id="winter">Winter</h2>

<p>Neither of those <code>jump</code> nor <code>z</code> commands could take me everywhere I needed to go.
So the typical workflow would start with jumping to a project via the <code>jump</code> command but then switching to the old navigation via <code>cd</code> once inside it.
Which meant that for navigating the file system I always had to keep using both: <code>jump</code> and <code>cd</code>.
And having two distinct commands for doing the same thing felt a bit weird.
This is where I learned about the <code>$CDPATH</code><a href="#fn:3" id="fnref:3" title="see footnote"><sup>◦</sup></a> variable and rolled out my own solution.</p>

<p>All you have to do is add this to your .bashrc:</p>

<pre><code>export CDPATH=.:~/.marks/
</code></pre>

<p>Then, to add a bookmark called <code>@name</code> pointing to a <code>"dir"</code> directory:</p>

<pre><code>ln -sr dir ~/.marks/@name
</code></pre>

<p>To delete a bookmark:</p>

<pre><code>rm ~/.marks/@name
</code></pre>

<p>To jump to its location:</p>

<pre><code>cd @name
</code></pre>

<p>And to list all available bookmarks:</p>

<pre><code>cd @&lt;tab&gt;
</code></pre>

<p>The <code>$CDPATH</code> solution works best when all the bookmarks are started with a special symbol which in my case was <code>@</code>.
This solves a couple of problems.
One, the bookmarked directories, if prefixed with <code>@</code> symbol, will not interfere with directories in the current folder.
Second, all the available bookmarks will be displayed by typing <code>'cd @&lt;tab&gt;'</code>.
And third, all bookmarks are now part of <code>cd</code> and so they gain tab completion for free.
You can even use tab completion for jumping directly to folders nested within bookmarks by doing <code>'cd @bookmark/subfolder/'</code>.</p>

<p>Using this method you no longer have to maintain a short list of custom bookmark functions and their autocompletion in your .bashrc.
And command for “change directory” can always be done with the same old and familiar <code>cd</code> command, independant of context.</p>

<p>But there was one problem.</p>

<h2 id="springagain">Spring again</h2>

<p>After working with the <code>$CDPATH</code> approach for a while I began noticing something peculiar.
At no point in time did I have a list with a dozen or more bookmarks.
Instead I found myself constantly going to the same 2 or 3 projects, finishing them, removing them from <code>~/.marks/</code> folder, adding new ones, and repeating the cycle again.
Why would someone keep bookmarks for 3 directories?</p>

<p>This time, instead of changing the command, I tried to do something different and changed the folder structure.
My projects moved from the state of being relevant to being archived so why not create an archive directory and organize folders based not on their name or type but on state?
Thus the <code>"zzz"</code> folder was born.
And now my project structure looks something like this:</p>

<pre><code>└── work
    ├── active_project1
    ├── active_project2
    └── zzz
        ├── bitbucket
        │   └── user1
        │       ├── repo1
        │       └── repo2
        ├── github
        │   ├── user1
        │   │   ├── repo1
        │   │   └── repo2
        │   ├── user2
        │   │   ├── repo1
        │   │   └── repo2
        │   ├── user3
        │   │   ├── repo1
        │   │   ├── repo2
        │   │   ├── repo3
        │   │   └── repo4
        │   └── user4
        │       └── repo1
        ├── teaching
        │   ├── class1
        │   │   ├── lecture1
        │   │   └── lecture2
        │   └── class2
        │       ├── lecture1
        │       └── lecture2
        ├─── clients
        │   ├── client1
        │   │   ├── project1
        │   │   ├── project2
        │   │   └── project3
        │   ├── client2
        │   │   ├── project1
        │   │   ├── project2
        │   │   └── project3
        │   └── client3
        │      └── project1
        └─── ...
</code></pre>

<p>With this structure the bookmarking systems no longer provide big benefits as most frequent and recent folders are always under ~/work/some_project.
And since at any timepoint only a few of them are visible the tab completion will do its job: <code>'cd ~/w&lt;tab&gt;/s&lt;tab&gt;'</code>.</p>

<p>The name <code>"zzz"</code> might seem strange but is convenient: the letters “zzz” symbolically mark the projects within as being in a “sleeping” state while the 3 “z” letters in a row make sure that this folder is always placed at the very end of your active project list.
A nice folder structure is still maintained in the archive but for the ease of access all active folders are layed flat under the <code>~/work/</code> directory.
When the project is paused or completed it is moved to its place within the <code>"zzz"</code> hierarchy, maintaining the previous structure.
There is one extra benefit - contents of the <code>"work"</code> directory act as a reminder about all the projects that are in progress.
If necessary a to-do list with concrete details might be placed at the same level.</p>

<p>And just like that, like a newbie, I navigate the file system with <code>cd</code> and <code>ls</code> again.</p>






</div>]]>
            </description>
            <link>http://karolis.koncevicius.lt/posts/fast_navigation_in_terminal_coming_full_cirlce/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529677</guid>
            <pubDate>Sat, 19 Sep 2020 19:00:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: The Financial Status Template]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24529631">thread link</a>) | @jrdi
<br/>
September 19, 2020 | https://jordivillar.com/financial-status/ | <a href="https://web.archive.org/web/*/https://jordivillar.com/financial-status/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2><a href="https://bit.ly/2Fm374g">The Financial Status Template</a><svg width="30" height="30" viewBox="0 0 30 30" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M16.5 13V18.5H6.5V8.5H12" stroke="#4A5568"></path> <path d="M10 15L18.5 6.5" stroke="#4A5568"></path> <path d="M14 6.5H18.5V11" stroke="#4A5568"></path></svg></h2><h3>How to stay on top of your personal finances.</h3><p>Staying on top of your <stron>personal finances</stron> can be challenging, tedious, and even discouraging, but for most people this process is a necessary evil. Spending more than you earn is a sure way to bury yourself in debt, and not being careful about precisely where <strong>your money is going</strong> can leave you struggling to pay for the day-to-day necessites.</p><p>During the last year, I have been <strong>tracking my personal finances</strong> on a monthly basis. Nothing too complicated but useful with <strong>insightful visualizations</strong>, allowing you to evaluate your financial status at-a-glance.</p><figure><a href="https://bit.ly/2Fm374g"><img src="https://i.ibb.co/1sRmTpJ/Screenshot-2020-09-19-at-13-43-31.png" alt="The Financial Status Template"></a></figure><p>I share similar personal finances insights in Twitter, you can <a href="https://twitter.com/jrdi">follow me there</a> as I continue to document my journey.</p></div></div></div>]]>
            </description>
            <link>https://jordivillar.com/financial-status/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529631</guid>
            <pubDate>Sat, 19 Sep 2020 18:51:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Epsy Widgets for Epilepsy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24529613">thread link</a>) | @epsy-hn
<br/>
September 19, 2020 | https://www.epsyhealth.com/news/epsy-introduces-new-ios14-widgets | <a href="https://web.archive.org/web/*/https://www.epsyhealth.com/news/epsy-introduces-new-ios14-widgets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>New Epsy App widgets allow users to have their daily medication reminders all in one place. Users can log medications and seizures without having to open the app.</p><div><p>Sep 18 2020 - <a href="https://www.epsyhealth.com/">Epsy Health</a>, the leading digital health platform for the management of epilepsy, today unveiled a new iOS widgets feature for the Epsy App, designed to help users manage their epilepsy easier and improve their health and wellness.&nbsp;&nbsp;<br></p><p>Epsy widgets lets users see, at a glance, their weekly medication progress and upcoming or missed medications: this allows users to continually be on-top of their medication compliance. Users can choose from three different widget sizes, which can be&nbsp; arranged however they like, including on their iPhone home screen. Another key benefit is that Epsy widgets can replace the need to open the app directly, making the process of seizure logging easier and quicker.&nbsp;<br></p><p>The full list of features of the Epsy widgets include:</p><ul role="list"><li>Three widget sizes can be chosen, with the smallest widget size offering a focused view on the next action of the day, and the largest widget size displaying a 7-day medication compliance view;</li><li>The widget dashboard displaying both past and upcoming medications an works in both light and dark mode;;</li><li>Easy one-tap logging of seizures;</li><li>Easy one-tap logging of medications.<br></li></ul><p>Epsy’s mission to offer a comprehensive and easier approach to managing epilepsy is propelled by a relentless drive for innovation and user-centric design. “D<em>espite the success of digital health services and devices over the last decade, we have not seen a corresponding improvement in digital, mobile technologies for epilepsy, and Epsy is here to change that</em>” commented Marco Peluso, the Vice President, and co-creator of Epsy. “<em>By embracing Apple’s iOS 14 widgets as early adopters in the iOS ecosystem, Epsy Health is making another step in fulfilling its purpose to introduce exceptional designs and revolutionary features that empower consumers, patients and physicians.</em>”<br></p><h2><strong>Availability&nbsp;</strong></h2><p>Epsy widgets require iOS 14, or later, and are available on the Epsy App for iOS, in the USA only. The Epsy App is <a href="https://apps.apple.com/app/id1479108189?fbclid=IwAR0lvR6LdOigqEmL2i-s1z7YeZvOE6u8qsZb_eANmIzUKsPDBm6dzQF7-Kk">available for download now here</a><br></p><h2><strong>About Epsy Health</strong></h2><p>Epsy Health is a leading digital health platform for the management of epilepsy that empowers patients, caregivers and healthcare professionals. By combining innovative technologies, user-centric designs and state-of-the-art data analytics, Epsy provides patients and physicians with actionable insights that can help to accelerate the pathway towards better outcomes. You should not rely on Epsy Health apps as a substitute or a replacement for professional medical advice, diagnosis, or treatment. Epsy Health apps should be only used in conjunction with professional medical advice. Epsy Health, Epsy App, Epsy Hub and their respective logos are either registered trademarks or trademarks in the United States and/or other countries. All other trademarks are property of their respective owners. To learn more visit: <a href="https://www.epsyhealth.com/">https://www.epsyhealth.com</a> and follow @epsyhealth</p><p>‍<br></p><h4><strong>Media Contact for inquiries or demos:</strong></h4><p>- Contact name: Alex Meredith</p><p>- Email: <a href="mailto:press@epsyhealth.com">press@epsyhealth.com</a></p><p>- View our full <a href="https://www.epsyhealth.com/press-kit">press kit here</a><br></p></div></div>]]>
            </description>
            <link>https://www.epsyhealth.com/news/epsy-introduces-new-ios14-widgets</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529613</guid>
            <pubDate>Sat, 19 Sep 2020 18:48:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Quit a $500K Job at Amazon to Work for Myself (2019)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24529590">thread link</a>) | @jkchu
<br/>
September 19, 2020 | https://danielvassallo.com/only-intrinsic-motivation-lasts/ | <a href="https://web.archive.org/web/*/https://danielvassallo.com/only-intrinsic-motivation-lasts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-92">
			<!-- .entry-header -->
	<div>
		
<h2>Why I Quit a $500K Job at Amazon to Work for Myself</h2>



<p>Last week I left my cushy job at Amazon after 8 years. Despite getting rewarded repeatedly with promotions, compensation, recognition, and praise, I wasn’t motivated enough to do another year.</p>



<p>I spent my entire time in AWS building tools for developers. I liked that field so much that I would have been satisfied working in it for the rest of my life.</p>



<p>I joined Amazon as an entry level developer. Within 3.5 years I had been promoted twice to a senior engineer, and I was practically guaranteed another promotion to principal engineer this year if I had stayed. My potential at the company was high, I was told.</p>



<p>My esteem within the company grew along the years and I was regarded an expert and a leader in my field. People looked up to me and respected me.</p>



<p>I made $75K in my first year and that gradually grew to $511K by my last year. I could have made another $1M if I stayed another couple of years.</p>



<p>My work–life balance was good too, despite Amazon’s reputation. I didn’t need to prove myself anymore, and I could get everything done in 40 hours a week. My team worked from home one day a week, and I rarely opened my laptop at night or weekends.</p>



<p>Also, the people I worked with were exceptional. I had three managers in total, and all were generous people with lots of empathy. I’m very grateful to everyone I worked with.</p>



<p>Everything was going well and getting better. But despite all this, my motivation to go to work each morning was decreasing—almost in an inverse trend to my career and income growth.</p>



<figure><img loading="lazy" width="1024" height="576" src="https://i0.wp.com/danielvassallo.com/wp-content/uploads/2019/02/rewards_motivation-2340812862-1549830899929.png?resize=1024%2C576&amp;ssl=1" alt="Rewards up, motivation down." srcset="https://i0.wp.com/danielvassallo.com/wp-content/uploads/2019/02/rewards_motivation-2340812862-1549830899929.png?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/danielvassallo.com/wp-content/uploads/2019/02/rewards_motivation-2340812862-1549830899929.png?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/danielvassallo.com/wp-content/uploads/2019/02/rewards_motivation-2340812862-1549830899929.png?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/danielvassallo.com/wp-content/uploads/2019/02/rewards_motivation-2340812862-1549830899929.png?resize=1100%2C619&amp;ssl=1 1100w, https://i0.wp.com/danielvassallo.com/wp-content/uploads/2019/02/rewards_motivation-2340812862-1549830899929.png?w=1801&amp;ssl=1 1801w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"><figcaption>Rewards up, motivation down.</figcaption></figure>



<p>It would have been foolish of me to expect my motivation to start increasing if I got yet another promotion, or another compensation bump, or another big project. But there was something else that was trending down with my motivation. It was my freedom.</p>



<h3>The Motivation Decline</h3>



<p>For the first couple of years my motivation was off the charts. I was mostly working with another person on an internal tool, and there was very little scrutiny around it. It was a time where I had a lot of independence in choosing how to work and what to work on—at least relative to more recent years.  It was just me and the other person improving this thing, talking to users, releasing updates, testing it, and everything else. Whatever we felt was important, we generally got to do. We did the best work we could for its own sake and we were mostly self-directed.</p>



<p>The last couple of years, however, were quite different. I was leading the most important project in the history of my department, with many stakeholders and complex goals. What I could do was always bounded by my ability to convince all the people involved that it was the best way to navigate our goals. </p>



<p>I was always going to be working on somebody else’s terms at Amazon. The terms were simple in the beginning (keep fixing the thing), but kept getting more complicated as the years passed by (maximize all goals; satisfy all stakeholders). Then there were other restrictions inherent to working in a large organization about how to do the work, what work to do, what goals to set, and what business was worth pursuing. This situation was squeezing me into doing things that I’d rather not do, and vice versa.</p>



<h3 id="mce_19">Finding New Motivation</h3>



<p>What kind of work would I do if I had to do it forever? Not something that I did until I reached some milestone (an exit), but something that I would consider satisfactory if I continued to do it until I’m 80. What is out there that I could do that would make me excited waking up every day for the next 45 years that could also earn me enough money to cover my expenses? Is that too unambitious? I don’t think so. Because there are two types of drivers that get me out of bed in the morning.</p>



<p>One comes from the outside in the form of a carrot or a stick. For instance, I’m not automatically driven to do my tax returns every April, but I make sure I do because I don’t want to go to prison. Or I might not want to work on something I dislike, but I do so anyway because I may need to pay the bills, or want to buy a fancy car. These are the extrinsic motivators.</p>



<p>The other comes from within. This is what drives me to do things when there isn’t a carrot or a stick. Hobbies are one activity driven by this. But what I was looking for was something that I could do for a living that was also driven by this type of motivation: the intrinsic kind.</p>



<p>Back to the question of whether this is too unambitious. See, I realized that extrinsic motivation doesn’t last. Whenever I got promoted, it felt good for a week, and then it was as over. When I first hit $100K income, I would take a peek at my W2 for a few days admiring the six digits, but then it wore off. When I hit $200K, $300K, $400K, and $500K, it was the same thing. I would be delusional to think that earning $1M, or $10M would suddenly make it different. And I feel the same with every other extrinsic reward or material possession. Getting them feels good for a while, but this wears off quickly.</p>



<p>The things that don’t wear off are those that I’ve been doing since I was a kid, when nothing was forcing me to do them. Things such as writing code, selling my creations, charting my own path, calling it like I saw it. I know my strengths, and I know what motivates me, so why not do this all the time? I’m lucky to live in a time where I can do something independently in my area of expertise without requiring large amounts of capital or outside investors. So that’s what I’m doing.</p>



<h3>What’s Next?</h3>



<p>I’m going all in on independence, and I’m going to try to make a living with my own bare hands starting from nothing. I don’t expect to only do things that I like, but it will be on my terms. My target is to cover my family’s expenses before I run out of savings while doing something that intrinsically motivates me. What more would I ever want to be satisfied with my work?</p>



<p>If you liked this article, check out:</p>



<ul><li><a href="https://danielvassallo.com/from-employee-to-bootstrapper/">How I set myself up financially before I took the plunge</a>.</li><li><a rel="noreferrer noopener" aria-label="And obviously about what I’ll be doing for a living (opens in a new tab)" href="http://danielvassallo.com/#doing" target="_blank">And what I’m doing now for a living</a>.</li></ul>



<p>Now that I can use Twitter without being subject to Amazon’s social media policy, you can <a href="https://twitter.com/dvassallo">follow me there</a> as I continue to document my journey.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

</article></div>]]>
            </description>
            <link>https://danielvassallo.com/only-intrinsic-motivation-lasts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529590</guid>
            <pubDate>Sat, 19 Sep 2020 18:44:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Cruel Deception – RAF Pilot Remains Discovered in North Korea]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24529345">thread link</a>) | @Hansig_jw
<br/>
September 19, 2020 | https://www.mydiplomaticlife.com/a-cruel-deception-raf-pilots-remains-discovered-in-north-korea/ | <a href="https://web.archive.org/web/*/https://www.mydiplomaticlife.com/a-cruel-deception-raf-pilots-remains-discovered-in-north-korea/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p><strong>A cruel</strong> <strong>deception</strong> – <strong>RAF pilot</strong> <strong>remains</strong> discovered in <strong>North Korea</strong> is a story that once I had the full details of the aftermath several years later, quite frankly left me speechless and angry.</p><p>In early 2004, I was contacted at the embassy in Pyongyang by David Hinton, the brother of an RAF pilot who had been shot down in 1952 over North Korea during the Korean war. He said he had been working for several years trying to garner as much information from a variety of primary sources as to the fate of his brother.Â&nbsp; He said he now had in his possession most of the details of the shoot down supplied by eyewitness United States Air Force (USAF) pilots and map coordinates of the site of the crash (which he later sent to me).</p><p>He then expressed a wish to be able to visit North Korea and hopefully, finally discover the fate of his brother. Could we help?</p><p>The background was that the pilot, Flt Lt Desmond Hinton, who received the Distinguished Flying Cross in World War II for shooting down two Japanese fighters had bailed out of his burning F84e Thunderjet whilst carrying out a strafing mission north east of Pyongyang on 2 January 1952. At the time, Flt Lt Hinton was one of a number of RAF pilots who were attached to and flying with the USAF. Despite enquiries after the war and with no further information as to his fate forthcoming, Flt Lt Hinton was subsequently officially listed as missing in action.</p><div id="gallery-1"><figure><p><a href="https://www.mydiplomaticlife.com/british-diplomat-works-with-north-korean-military/thumbnail-1/#main"><img width="400" height="311" src="https://i0.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1-1.jpg?fit=400%2C311&amp;ssl=1&amp;is-pending-load=1" alt="Flt Lt Hinton North Korea" aria-describedby="gallery-1-980" data-lazy-srcset="https://i0.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1-1.jpg?w=400&amp;ssl=1 400w, https://i0.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1-1.jpg?resize=300%2C233&amp;ssl=1 300w" data-lazy-sizes="(max-width: 400px) 100vw, 400px" data-lazy-src="https://i0.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1-1.jpg?fit=400%2C311&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></a></p><figcaption id="gallery-1-980"> Flt Lt Hinton with USAF colleagues -Photo David Hinton</figcaption></figure></div><p>I knew that this was going to be a tall order to try and carry out. The Korean War itself was and still is a huge propaganda tool for the Kim dynasty. So requesting assistance in finding a hated enemy, albeit a fallen one, was perhaps a request too far.</p><p>But surprisingly, no.</p><p>Permission was granted for me to meet with the North Korean military and at the initial meeting, I provided them with all the research material sent to me by David Hinton and they said they would investigate.</p><p><em><strong>The</strong><strong> process of making this project happen, working with the North Korean military, I have covered in a previous post</strong></em> <a href="https://www.mydiplomaticlife.com/british-diplomat-works-with-north-korean-military/">British Diplomat Works With North Korean Military </a></p><p>Against all expectations, the military did get back to me shortly afterwards with some quite startling news. Based on the information I had given them, they had identified the crash site which was close to a village called Kuso-ri/Gueso-ri situated near to what is currently the main airport for Pyongyang.</p><p>They had spoken with villagers including two elders who had witnessed the shoot down. Flt Lt Hinton had indeed ejected but his parachute failed and he was killed on impact. The villagers had then interred him in an unmarked grave in a field adjacent to the village. An exact location had been identified and human bones and fragments of uniform and aircraft had been uncovered. <em><strong>This scenario is somewhat similar to my previous post</strong> </em><a href="https://www.mydiplomaticlife.com/tragic-raf-pilots-secret-grave-discovered-in-albania/">Tragic RAF Pilotâ€™s Secret Grave Discovered In Albania</a></p><p>With this discovery, events moved quickly. A visa for David to enter North Korea was fast tracked and he duly arrived hopeful for some form of final closure. During his visit, he was treated as an honoured guest by the North Koreans and enjoyed the rare distinction of being accompanied throughout his visit by a senior Korean People’s Army officer, Colonel Kwak Chol-hui, who was at that time Director of Negotiations for Remains at the armistice site at Panmunjom.</p><p>So, on the day appointed to visit the village to view the grave, we arrived early and were met by the Colonel and both witnesses who then led us to the gravesite which was a short distance away.</p><p>The grave consisted simply of a mound of earth surrounded by a white picket fence, without any inscription. It lay close to a narrow footpath on a hillside 200 meters from the road.</p><p>David was introduced at the grave to the two witnesses to Desmond’s crash, a Mr Ri and Mr Han, local villagers who were only 13-years old at the time of the incident but who still appeared to have perfect recollections of the event. Perhaps a little too perfect and too detailed I thought at the time. But, maybe it was just me being a tad too cynical.</p><p>David then gave a short speech at the grave, thanking Colonel Kwak and the British embassy for making his visit possible, while the head of the village promised to tend the grave and paint the fence regularly.</p><p>We spent about 2 hours in the village and at the gravesite before it was time to leave. We said farewell to the Colonel and the witnesses and set off back to Pyongyang and David left North Korea the next day.</p><p>Upon his return to the UK, he was kind enough to send me copies of the many photographs he had taken that day and which I still have.</p><p>I learnt later that in 2011, a casket containing the bones of Flt Lt Hinton had been passed with great ceremony to the then British ambassador to North Korea for repatriation and presumably for burial at the UN Korean War cemetery in Busan, South Korea.</p><p><strong>And here the story would have finally ended. But no!</strong></p><p>The British Daily Mail ran a story on 17th June 2018 that was a shocker to me. It was revealed that subsequent DNA testing carried out on the bones after the repatriation identified them not as those of Flt Lieutenant Hinton but those of an animal!</p><p>According to the paper, family members were informed but the media was kept in the dark for fear of damaging relations between North Korea and the UK. Don’t you just love political machinations!</p><p>The paper then went on to quote the source as the memoirs of Mr Thae Yong-Ho, a North Korean diplomat who was Deputy North Korean Ambassador to the UK at the time and who defected to South Korea in 2016.</p><p>It also came as North Korean dictator Kim Jong Un had agreed with US President Donald Trump at their Singapore summit that all remains of US servicemen who died in the Korean War would now be returned.</p><p>Interestingly, the New York Times ran a story on 1st August 2018 detailing how difficult it had been to identify remains of American MIA’s handed over by the North Koreans to the US as a result of the Agreement with the paper also quoting the Hinton DNA story.</p><p>Mr Thae maintained that the Hinton episode was a case of crass incompetence. He also stated that Britain did protest but North Korean officials countered by saying they lacked the proper equipment to distinguish human from animal bones.</p><p>To this day, I cannot believe how stupid the North Koreans behaved in this matter. They must have known that DNA would be carried out on the bones.Â&nbsp; If so, why did they release them?</p><p>A country that has a nuclear programme, the ability to launch missiles and a sophisticated scientific infrastructure coming out with such a lame excuse just didn’t hold water.</p><p>I might add that at the time of the Hinton project, Mr Thae was well known to the embassy in Pyongyang, both professionally and socially. He was an experienced diplomat at the Ministry of Foreign Affairs where as part of his portfolio, he was in charge of the UK desk, hence the contacts. So, he would have been well aware (and probably involved behind the scenes) in what developed.</p><p>So what should have been a positive North Korean story about the discovery and dignified burial of a fallen RAF pilot and the assistance given to a close relative to enable him to pay his last respects, in the end turned out to be nothing but a cruel and wicked deception.</p><p><em><strong>Sources:</strong></em></p><p>https://www.dailymail.co.uk/news/article-5852503/Remains-RAF-hero-shot-North-Korea-2011-turns-animal-bones.html</p><p>“Cryptography From the Third-<wbr>Floor Secretariatâ€� 2018 Thae Yong-Ho</p><div heateor-sss-data-href="https://www.mydiplomaticlife.com/a-cruel-deception-raf-pilots-remains-discovered-in-north-korea/"><p>Spread the love</p><ul><li><a data-pin-lang="en_US" href="https://www.pinterest.com/pin/create/button/?url=https://www.mydiplomaticlife.com/a-cruel-deception-raf-pilots-remains-discovered-in-north-korea/" data-pin-count="false" data-pin-do="buttonPin" data-pin-config="beside"><img src="https://i2.wp.com/assets.pinterest.com/images/pidgets/pinit_fg_en_rect_gray_20.png?w=845" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://i2.wp.com/assets.pinterest.com/images/pidgets/pinit_fg_en_rect_gray_20.png?w=845"></a></li></ul></div></div></div>]]>
            </description>
            <link>https://www.mydiplomaticlife.com/a-cruel-deception-raf-pilots-remains-discovered-in-north-korea/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529345</guid>
            <pubDate>Sat, 19 Sep 2020 18:09:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Discussion of Li-Meng Yan's Paper on SARS-CoV-2]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24529261">thread link</a>) | @akvadrako
<br/>
September 19, 2020 | https://www.randombio.com/ratg132.html | <a href="https://web.archive.org/web/*/https://www.randombio.com/ratg132.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<!-- change font to prevent FauI coming out as Faul -->
<section>

<p>
<span> <img src="https://www.randombio.com/O40gray-gray.png" alt="O" title="O"></span>
n September 14 2020, Li-Meng Yan, a dissident Chinese virologist, along with three
colleagues, posted an article at <a href="https://zenodo.org/record/4028830">zenodo.org</a>
<sup>[1]</sup> claiming to prove that SARS-CoV-2 was artificially created. Twitter 
canceled the author's account two days later and political activists vociferously 
attacked the paper on political grounds. It is clear that many people don't want to 
hear her evidence. But the issue is extremely important. If the virus was produced 
in an experiment and accidentally released, as this paper claims, it means the Wuhan 
Institute of Virology is in dire need of upgrades to their virus-handling procedures 
to prevent it from happening again.
</p><p>
My background is 30 years as a researcher in protein biochemistry using biophysical 
techniques and molecular biology, including design, cloning, and expression of 
recombinant proteins, to study protein function and structure. Here's a brief
summary of the argument put forward in the paper along with my comments.
</p><p>
<i>Update, Sep 20 2020</i>: I've expanded the comments to describe the evidence they
would need to make their case more convincing.
</p><hr><p>
<b>Claim 1:</b> 
   “[the sequences of] RaTG13, RmYN02, and several pangolin viruses recently
   published are highly suspicious and likely fraudulent.”
   “The RaTG13 virus is excluded from this analysis given the strong evidence 
   suggesting that its sequence may have been fabricated and the virus does not exist 
   in nature.”
</p><p>
<b>Comment:</b>
   RaTG13 was published by Shi Zhengli at the same time as the SARS-CoV-2 sequence. 
   In 2013 Shi also published a partial gene segment of RaBtCoV/4991, which is identical 
   to RaTG13, but it is incomplete. The authors say that the WIV took this partial
   sequence and fraudulently added the remainder to exculpate themselves, trying
   to make it appear that RaTG13 was a pre-existing virus. 
</p><p>
   Evidence in favor of this claim is that Shi <i>et al.</i> made no mention of 
   RaBtCoV/4991 in their 2020 paper. But unless someone wants to claim that 4991 
   was also fabricated, RaBtCoV/4991 had to come from somewhere, which is to say it is 
   a real virus. So Claim 1 doesn't make sense. 
</p><p>
<b>What is needed:</b>
   To prove this the authors would have to find another virus that is 100% identical 
   with the published partial RaBtCoV/4991 sequence but which differs from RaTG13. 
</p><hr><p>

<b>Claim 2:</b> 
   The WIV could have used transgenic hACE2 transgenic mice to improve the virus's
   ability to bind to its receptor. “This animal model 
   has been established during the study of SARS-CoV and has been available in the 
   Jackson Laboratory [a commercial supplier of transgenic mice] for many years.”
   However, hACE2 mice are “not a good model to reflect the virus' transmissibility
   and associated clinical symptoms in humans.” If they had used golden Syrian
   hamster instead, the authors say, “the highly contagious nature of SARS-CoV-2 
   would be extremely evident” and they could have released accurate information.
</p><p>
<b>Comment:</b> 
   This is a good point. If true, it would tend to exculpate the Chinese researchers.
   But we already know many techniques they could have used. No one was claiming 
   that making the virus was impossible. 
</p><p>
<b>What is needed:</b> 
   Sending live animals to another country requires tons of paperwork. They would need
   Jax's sales records or government export records (which might be available via a
   FOIA request). 
</p><hr><p>
<b>Claim 3:</b> 
   The paper provides a flow chart for how the virus could have been constructed.
   “Two restriction sites are present at either end of the RBM [receptor-binding
   motif] of SARS-CoV-2, providing convenience for replacing the RBM within the spike 
   gene.”
</p><p>
<b>Comment:</b> 
   The spike protein consists of two parts: S1, which binds to the receptor, and S2,
   which fuses the viral and cellular membranes. The point where the subunits are joined 
   is called the S1/S2 site. Proteolysis of this site is essential for infection.
   The RBM is the part of S1 that binds to the receptor. A common technique is 
   to take functional domains out of one protein and put them into another. The easiest 
   way to do this is by finding (or creating) restriction sites in the DNA that allow 
   you to cut the DNA in a specific place.
</p><p>
   The flow chart is quite reasonable, but again no one doubted that artificially 
   creating the virus is possible. So describing how someone could have done it
   doesn't tell us much; any competent molecular biologist could come up with
   a similar scheme.
</p><p>
   The article makes a big deal about the presence of restriction sites on the S1/S2 
   sequence, including an <code>EcoRI</code> site and a <code>BstEII</code> site. 
   But this does not indicate engineering. Many restriction sites occur naturally by 
   chance. Their presence is not unusual, but they are a major inconvenience for those 
   of us who try to clone DNA—many restriction sites we might wish to use are 
   ruled out by the presence of another one in an inconvenient location. The 
   probability of finding one of over a thousand known 
   <a href="http://rebase.neb.com/rebase/rebase.html">restriction sites</a> at an 
   arbitrary location in a 3800 base sequence by chance is very high.
</p><p>
<b>What is needed:</b> 
   To prove this convincingly, the authors would need to find an authentic copy 
   of the original virus sequence without the restriction sites to show what the virus 
   was like before the supposed change was made. 
</p><hr><p>
<b>Claim 4:</b> 
   The furin cleavage site contains rare codons, an unusual sequence not shared by other 
   lineage B betacoronaviruses, and a <code>FauI</code> restriction site. It 
   could not have been introduced by evolution, say the authors, and the probability 
   of successful homologous recombination ever occurring among the ancestors of these 
   viruses is low. “A  <code>FauI</code> restriction site is formulated by the codon choices 
   here, suggesting the possibility that the restriction fragment length polymorphism,
   a technique that a WIV lab is proficient at, could have been involved.”
   The authors suggest that the <code>FauI</code> site was added to monitor the presence
   of the furin-cleavage site.
</p><p>
<b>Comment:</b> 
   The furin cleavage site is known to increase the tropism of the virus, and it is 
   now known that the virus even infects the brain, but there is little evidence so
   far that it increases pathogenicity. There is as yet no good explanation for the 
   presence of the furin cleavage site. 
</p><p>
   It might make sense for a virus creator to put a restriction site in the middle of
   the furin cleavage site to make sure it didn't disappear. RFLP analysis is a simple 
   technique and any molecular biology lab could handle it easily. However, as mentioned,
   restriction sites pop up randomly all the time, so finding one proves little.
</p><p>
<b>What is needed:</b> 
   The <code>FauI</code> restriction site is a red herring. To prove that the furin cleavage
   site was added, the authors would have to find a trail of evidence showing step
   by step how the sequence was manipulated from whatever virus the WIV started from.
   It would also be helpful to have data showing that furin cleavage increases 
   pathogenicity. This is plausible but it needs to be shown experimentally.
</p><hr><p>
<b>Claim 5:</b> 
   WIV most likely used ZC45 and ZXC21, not RaTG13, to create SARS-CoV-2 because RaTG13 is 
   not real. The reasoning behind this claim is that the S1 sequence of SARS-CoV-2 
   is quite similar to these other viruses except for the receptor-binding motif and 
   furin-cleavage sites. Also, two other proteins on these viruses, the Orf8 protein 
   and E protein, are 94.2% and 100% identical to SARS-CoV-2.
</p><p>
<b>Comment:</b> 
   This is indeed strange but so far circumstantial.
</p><p>
<b>What is needed:</b> 
   The authors need to prove that RaTG13 is not real. They claim to have evidence,
   and I look forward to seeing it,  but to be convincing it would have to be more 
   than the discovery of mysterious unexplained features in the DNA sequence.
</p><hr><p>
The authors say they plan to prove that RaTG13 is fabricated in a follow-up report. 
If they can do this, it would be solid evidence of consciousness of guilt on the part 
of WIV researchers. However, the current paper doesn't say very much more than what 
other bloggers have already revealed.
</p><p>
It would be premature to draw any conclusion about the origins of the virus from this
paper. The authors have set for themselves a difficult and possibly impossible task: 
finding a signature of intel­ligent design in a virus is much like what the 
creationists have been doing without success for years. 
</p><p>
But what is not premature is that social media giants deciding for us what is 
true and what is false may turn out to be as big a threat as the virus. It is unfair 
and unscientific to dismiss ideas that one doesn't want to hear as “conspiracy 
theories” as many people are doing. 
</p><hr><p>
1. Yan LM, Kang S, Guan J, Hu S (2020). Unusual Features of the SARS-CoV-2 
Genome Suggesting Sophisticated Laboratory Modification Rather Than Natural 
Evolution and Delineation of Its Probable Synthetic Route.
https://zenodo.org/record/4028830
</p><hr><p>
<i>
sep 16 2020, 6:52 pm (Updated Sep 20 2020)
</i>
</p>
</section>
</div></div>]]>
            </description>
            <link>https://www.randombio.com/ratg132.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529261</guid>
            <pubDate>Sat, 19 Sep 2020 17:57:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Meeting everyone on a new team]]>
            </title>
            <description>
<![CDATA[
Score 256 | Comments 83 (<a href="https://news.ycombinator.com/item?id=24529176">thread link</a>) | @craigkerstiens
<br/>
September 19, 2020 | https://www.annashipman.co.uk/jfdi/meeting-everyone.html | <a href="https://web.archive.org/web/*/https://www.annashipman.co.uk/jfdi/meeting-everyone.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="meeting-everyone">
    
    <date>17 September 2020</date>
      <p>When I joined the Financial Times as Technical Director for FT.com, I inherited a team of around 50 engineers. One of the first things I did was meet each of them for a one-to-one. I was initially resistant, but it was extremely valuable, I’m glad I did it, and I would definitely do it again in a future role.</p>

<h2 id="my-mentors-advice-about-the-content-of-the-meeting">My mentor’s advice about the content of the meeting</h2>

<p>The idea was suggested to me by a mentor, who’d been advised to do it by <em>his</em> mentor, a Rear Admiral, who said this was something you should do whenever you have a team of fewer than 150 people. My mentor gave me some tips:</p>

<ul>
  <li>Be clear about whether you will take action or whether this is for information only.</li>
  <li>This should mostly be about listening – you should talk for maybe 5 minutes and they should talk for 25.</li>
  <li>It’s to find out what’s going well and what’s not going well.</li>
  <li>It’s informal, but make sure it’s in an enclosed meeting room so that people feel they can speak freely.</li>
  <li>Sometimes it will be quite boring, sometimes you may just learn a lot about someone’s family or hobbies, but that is useful from a getting to know people/relationship-building perspective and it means that you know some things about that person.</li>
  <li>Aim is to get a bit about their background, their priorities and their pressures.</li>
</ul>

<h2 id="making-time-was-hard">Making time was hard</h2>

<p>I was initially resistant because of the time commmitment. With a team of ~50, that’s a lot of hours, and I was also working four days a week so each meeting takes up a greater proportion of time. However, once I’d made the decision to do this and announced my intention, it was important to me to follow through, so I made sure to make time.</p>

<p>I scheduled four of these 1:1s a week, starting with the people reporting directly to me and then on down the management chain.</p>

<h2 id="i-ran-each-meeting-in-the-same-way">I ran each meeting in the same way</h2>

<p>Firstly I ran through everything I planned to cover, and then stepped through it.</p>


<ul>
  <li>I am asking the same questions to everyone</li>
  <li>This is information for me only to get an idea of themes and how things are going; I’m not explicitly planning to take action on anything we discuss, so if something comes up that I need to take action on, let’s make sure we discuss that after this meeting</li>
  <li>This is confidential. If you say something about someone else I’m not going to go and tell them. I may report on ‘what people are saying’, but I’ll say ‘the engineers feel’ or ‘an engineer said’; I won’t say “[Your name] said…”</li>
</ul>

<h3 id="what-were-going-to-discuss">What we’re going to discuss</h3>

<ul>
  <li>First I’ll introduce myself, and tell you a bit about my background</li>
  <li>Then, if you like, I’d love you to tell me a bit about yourself – as much or as little as you feel like sharing</li>
  <li>Then we’ll discuss the following questions:</li>
</ul>

<ol>
  <li>What do you think the most important things we should be doing over the next year?</li>
  <li>What will get in the way of us doing that?</li>
  <li>What’s going well, i.e. what should we make sure we don’t change?</li>
  <li>Is there anything you think I should know about?</li>
</ol>

<h2 id="is-there-anything-i-should-know-about">Is there anything I should know about?</h2>

<p>When I asked this question I talked a bit about why I was asking. I explained that I might not necessarily see or know things that may seem apparent to them, and while they should always feel able to bring things to me, now was a good opportunity to do so. It was an opportunity to make sure I’ve heard what’s important to you, what things should change and what things should stay the same.</p>

<p>This question always elicited very interesting responses, from organisational issues, to personal information people felt it was valuable for me to know about them.</p>

<h2 id="i-told-them-what-i-was-planning-to-ask-in-advance">I told them what I was planning to ask in advance</h2>

<p>I put all the information in the meeting invite.</p>

<div>
<p>I mentioned that I wanted to have a chat with everyone on FT.com to understand how things are going, does this time suit you for this?</p>

<p>The meeting agenda is the same for everyone; a quick intro and then the following questions (I'll go through this in the meeting too):</p>

<ul>
<li>What do you think the most important things we should be doing over the next year?</li>
<li>What will get in the way of us doing that?</li>
<li>What’s going well, i.e. what should we make sure we don’t change?</li>
<li>Is there anything you think I should know about?</li>
</ul>

<p>Thanks,</p>
<p>Anna</p>
</div>

<p>Some people did not read the meeting invite and came with no idea what the meeting was about. Some people had fully prepared and written notes that they then read out to me. Actually people having prepared sometimes was less useful, because sometimes it led the conversation to solutions rather than problems. However it was great that people had really given it some thought.</p>

<h2 id="making-notes-felt-too-much-like-a-promise">Making notes felt too much like a promise</h2>

<p>Each meeting was half an hour. In the very first one, I made notes in a notebook, but I realised that created an implicit commitment that I was going to take action on everything that was said, even though I had said it was information only.</p>

<p>However, I do not have a very good memory, so for all the subsequent ones I made a few notes after each meeting of key themes. This meant I couldn’t do more than two in a row or go straight into another meeting, so it made scheduling slightly harder. These days, people are much more aware of the shorter meeting approach so if doing this again, I’d go for the ‘therapy hour’ – 25 minutes for conversation then 5 minutes for me to make the notes.</p>

<h2 id="introducing-myself">Introducing myself</h2>

<p>In my intro, I gave a potted career history. Starting from my degree in philosophy, and my first career in <a href="https://www.barringtonstoke.co.uk/">children’s book publishing</a>, through teaching myself to code, my <a href="https://www.hw.ac.uk/study/uk/postgraduate/information-technology-software-systems.htm">masters in Software Systems</a> and then my 15+ year career in programming, infrastructure and operations, technical architecture, and my previous role as <a href="https://www.annashipman.co.uk/jfdi/a-year-in-the-life-os-lead.html">Open Source lead</a>. I also talked about what appealed to me about the job as Technical Director at the FT.</p>

<p>I said roughly the same thing to everyone. I don’t normally introduce myself and give my background, but in this case I thought that as a new Tech Director most of them would not be working closely with me, and I would not be contributing code, so it was worth giving my credentials.</p>

<p>My mentor had suggested I also say something personal. I think he intended something like “married with two children” (or whatever), but instead, I tried to give a different kind of personal detail, something about my interests. I tried to come up with a different one for each conversation, for example something about my <a href="https://twitter.com/annashipman/status/1043917006477643777">cross-stitch hobby</a>.</p>

<p>This part was the hardest part for me, because prior to this I had generally enjoyed keeping a clear boundary between work stuff and personal stuff, so that definitely didn’t cover talking about cross-stitch, or my home life, on a first meeting. However, I had been trying to bring more of my personal self to work, and this part of the intro did lead to some really interesting conversations and I think helped make a better connection.</p>

<p>Of course, these days, when we are all at home, my personal life is in meetings with me, so it’s good I’d already started on that journey!</p>

<p>Giving so much information in my introduction also allowed the other person to introduce themselves how they wanted. Some talked career history, some focused on their hobbies, others were really open about their lives and aspirations.</p>

<h2 id="i-am-so-glad-i-did-this">I am so glad I did this</h2>

<p>My mentor was wrong about one thing –&nbsp;none of the conversations were boring.</p>

<p>In my first few months in the new job, I often felt really stretched for time, but I never regretted a single one of these meetings; it was always extremely interesting, my team are brilliant and it was great to meet them one on one, and each conversation always contained some valuable information.</p>

<p>There were two very valuable things about this for me.</p>

<p>The first was getting an idea of what change was needed. These meetings gave me a brilliant insight that wasn’t available elsewhere. Patterns started emerging very quickly, and formed the basis of our <a href="https://medium.com/ft-product-technology/the-difficult-teenage-years-setting-tech-strategy-after-a-launch-7f42eb94a424">tech strategy</a>.</p>

<p>The second was building relationships. A lot of the people I had 1:1s with I would not have come into contact with during the course of the ordinary working week. It would have taken time to meet everyone at socials, and it wouldn’t have been the same quality of conversation. I still feel, two years on, that I know a bit about all the people I had those conversations with, which has felt to me like a good foundation for our subsequent conversations.</p>

<p>It was also good, as someone who is a bit shy, to have names to faces quite quickly and people to say hello to when walking round the office.</p>

<h2 id="was-it-useful-for-my-team">Was it useful for my team?</h2>

<p>About a year later, I asked some of the people with whom I’d had these conversations whether they’d been useful (in an anonymous form).</p>

<p>All of the people who responded said they found the conversation valuable, and some of their comments were:</p>

<ul>
  <li>“It broke down barriers and helped me feel less intimidated about approaching you, whether to talk about work or just to have a general chit chat. You are a very busy person who I wouldn’t ever work with directly so it was good to feel that you knew I existed.”</li>
  <li>“There is hardly any opportunity for me to talk to people in higher position like you except when the team has a big problem. The 1:1 was really casual and I felt really comfortable talking to you. It was a good time to know what kind of person you are. If we didn’t do the 1:1, the answer of the question below “Do you feel able to raise issues with me?” would be “No”.”</li>
  <li>“We sat down when you first started and it was nice to get some one-to-one time because it’s not often you get to do that with a Technical Director. It was nice to raise issues but for me, it was more of an opportunity to understand if I could trust you in the future with raising issues. Raising issues can be difficult and scary so it’s important to know if the person you are raising them to is receptive.”</li>
  <li>“It really showed that you cared about us as humans, and how we fit with the rest of the team. It was also a great opportunity to get to know you”</li>
  <li>“I think often of that conversation”</li>
</ul>

<h2 id="did-it-make-them-feel-more-able-to-raise-issues-with-me">Did it make them feel more able to raise issues with me?</h2>
</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.annashipman.co.uk/jfdi/meeting-everyone.html">https://www.annashipman.co.uk/jfdi/meeting-everyone.html</a></em></p>]]>
            </description>
            <link>https://www.annashipman.co.uk/jfdi/meeting-everyone.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529176</guid>
            <pubDate>Sat, 19 Sep 2020 17:45:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reasons Your Growth Startup Is Hiring Too Junior]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24529137">thread link</a>) | @svmanager
<br/>
September 19, 2020 | https://staysaasy.com/management/2020/09/11/Hiring-Too-Junior.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2020/09/11/Hiring-Too-Junior.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Growth startups often find themselves lacking senior team members as they scale. The problems that arise from this are plentiful, including things like:</p>
<ul>
  <li>Requiring heroics to fix things</li>
  <li>Penalizing junior team members for failure to meet responsibilities well above their pay grade.</li>
  <li>Building technology that doesn’t scale</li>
</ul>

<p>Here’s some reasons why companies get into this situation.</p>

<h2 id="reason-1-habit">Reason 1: Habit</h2>

<p>When you’re a tiny startup budgets are extremely lean and products don’t have a lot of users. In that environment companies often prioritize breadth of functionality (see what works) and getting that via several (more affordable) junior team members guided by a smaller group of senior team members.</p>

<p>Problems arise if that strategy exists past market fit. The add-a-junior-to-do-more strategy implodes as the team grows too large for the senior staff to manage closely and the technical challenges start to look more daunting.</p>

<h2 id="reason-2-hubris">Reason 2: Hubris</h2>

<p>Sometimes people recognize the problems are getting more difficult but still don’t hire more seniors. This can often be chalked up to hubris - surely I can just direct a bunch of juniors to execute on the genius solutions I come up with for all our problems. The problem here is that you’re not a genius and even if you were that strategy doesn’t scale.</p>

<h2 id="reason-3-fear">Reason 3: Fear</h2>

<p>The flip side of hubris is fear. New senior staff can look like a threat to the power of existing senior staff. You might have to choose between doing what’s right for the company and retaining certain kinds of power. The answer there is simple - it’s better to be part of something great than the owner of something that fails.</p>

<p>A different play on this theme is junior teammates fearing that new senior teammates will take away some of their opportunities. It’s possible, sure. But more often the opportunities they will take over are the ones juniors would have had trouble succeeding in.</p>

<p>In a growing company with reasonably difficult challenges, good seniors will do more to expand the set of opportunities than shrink them. And good senior talent will help juniors via mentorship and guidance.</p>

<h2 id="reason-4-money-issues">Reason 4: Money Issues</h2>

<p>Money issues play out in a couple ways.</p>

<p>First, the cost of senior talent can subconsciously make you concerned about the remaining budget for yourself. I haven’t seen this played out directly and blatantly, but it’s another version of the fear game - assuming compensation is a zero sum game leads to weird incentives.</p>

<p>Second, it’s easy to think 2 juniors are better than one senior. As you read about the myth of the 10x engineer you might find yourself thinking this way. Let’s talk more about how this is a misconception in reason 5…</p>

<h2 id="reason-5-miscalculation-of-necessary-skills-for-right-now">Reason 5: Miscalculation of Necessary Skills For Right Now</h2>

<p>As referenced earlier, problems get much harder when you add significant growth to a platform. It’s not uncommon to underestimate the challenges at hand. In reality, even simple products at massive scale need significant senior leadership to ensure they are being built and operated effectively. Trying to replace the leadership of senior talent with a volume of junior talent is a sure-fire way to screw this up.</p>

<h2 id="reason-6-miscalculation-of-necessary-skills-in-the-future">Reason 6: Miscalculation of Necessary Skills In the Future</h2>

<p>To make things more difficult, you don’t just have to hire for right now, you have to hire for 2 or more years in the future. The senior talent you hire now must seed the leadership ranks you need in the future. Especially in product and engineering, you can’t just hire everyone you need when you need them. For starters, the job market would laugh at that sort of just-in-time attempt at hiring. But also, these roles require much more detailed understanding of the systems at play, so you need to have people with intimate knowledge developed in advance.</p>

<p>Think of it this way - look at whatever company you’re trying to be like in 5 years. Look at their team. If you don’t start hiring towards something like that team sooner rather than later you’ll never be that company.</p>

<h2 id="reason-7-arguments-about-what-seniors-need">Reason 7: Arguments About What-Seniors-Need</h2>

<p>Another reason people hire too junior is thinking around senior talent needing explicit areas of responsibility that don’t overlap. This is the “one alpha” theory - that senior talent can’t collaborate productively and need their own pack. There might be some nuggets of truth here, but most of it is nonsense. That’s like NASA saying they couldn’t have smart people work together on getting to the moon because these great scientists need their own domains.</p>

<p>Ultimately you have to look at the problems you’re solving. If they are truly challenging they can support a number of seniors. If they aren’t you’ll probably have trouble hiring and retaining more than a few.</p>

<h2 id="conclusion">Conclusion</h2>

<p>There’s a lot of reasons why you might hire too junior as your company grows. Know them and hire intentionally.</p>


    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2020/09/11/Hiring-Too-Junior.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529137</guid>
            <pubDate>Sat, 19 Sep 2020 17:39:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Twister OS: Make Raspberry Pi Look Like Windows or macOS]]>
            </title>
            <description>
<![CDATA[
Score 147 | Comments 62 (<a href="https://news.ycombinator.com/item?id=24528732">thread link</a>) | @yboris
<br/>
September 19, 2020 | https://twisteros.com/index.html | <a href="https://web.archive.org/web/*/https://twisteros.com/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Twister OS 2020 | <a href="https://discord.gg/Fh8sjmu" target="_blank">Join our Discord!</a></p></div></div>]]>
            </description>
            <link>https://twisteros.com/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24528732</guid>
            <pubDate>Sat, 19 Sep 2020 16:50:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NATO Strap and James Bond]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24527065">thread link</a>) | @tosh
<br/>
September 19, 2020 | https://www.esprit-nato.com/en/content/10-nato-watch-strap-band-and-james-bond-007 | <a href="https://web.archive.org/web/*/https://www.esprit-nato.com/en/content/10-nato-watch-strap-band-and-james-bond-007">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-wrapper">
    
    

  <section id="main">

    
      
        
      
    

    
  <section id="content">

    
      
<p>———— ♦ ————</p>

<p>We widely detail attractive features of NATO strap on Esprit NATO, we are here concentrating on the myth "James Bond and NATO straps".</p>
<p>Let's start with the bad news : <strong>Sean Connery's strap in Golfinger (1964) was not a NATO strap</strong>. Many of us think the opposite, which have most likely contributed to the sucess of NATO straps, but we believe this watch strap first became famous mainly because of its characteristics and many benefits.</p>
<p>However, <strong>James Bond and NATO straps are indeniably connected</strong>. Why ? This is what we suggest to focus on this page...</p>

<p>———— ♦ ————</p>
<h3>James Bond was wearing a nylon strap in Goldfinger in 1964</h3>

<p><img src="https://www.esprit-nato.com/img/cms/James%20Bond/Sean-Connery-nylon-watch-strap-Goldfinger-1964.jpg" alt="" width="800" height="649"></p>

<p>The nylon strap was then put on the famous <strong>Rolex Submariner ref. 6538</strong>, iconic James Bond's watch.</p>

<p><img src="https://www.esprit-nato.com/img/cms/James%20Bond/Sean-Connery-nylon-watch-strap-Goldfinger-1964-focus-1.jpg" alt="" width="800" height="480"></p>

<p>It was 16 mm wide on a 20 mm lug width watch. It's a unique and surprising style as much aesthetically as functionaly. Not so British...</p>
<p>It is said that the strap <strong>belonged to a member of the production team</strong> who came to the assitance of this Submariner at the last minute. This would be an explanation of the wrong width... A mishap that would have left its mark in history ? We were unable to verify this information.</p>

<p>———— ♦ ————</p>
<h3>Why did this Submariner 6538 absolutely need a nylon strap ?</h3>
<p>Because at that time none other strap enabled to put James Bond's watch both on his wrist and on his diving suit, <strong>typical feature of nylon strap,</strong> which thereafter is part of&nbsp;<a href="https://www.esprit-nato.com/content/9-l-histoire-du-bracelet-nato" target="_blank" rel="noreferrer noopener">some requirements for the Royal Navy</a>...</p>

<p><img src="https://www.esprit-nato.com/img/cms/James%20Bond/Sean-Connery-nylon-watch-strap-Goldfinger-1964-focus-2.jpg" alt="" width="800" height="628"></p>

<p>———— ♦ ————</p>
<h3>Why is this Goldfinger strap not a NATO strap ?</h3>
<p>For two reasons :</p>
<p>- NATO straps and its strict requirements emerged <strong>nine years after</strong>, in 1973, further to British MOD request - <a href="https://www.esprit-nato.com/content/9-l-histoire-du-bracelet-nato" target="_blank" rel="noreferrer noopener">we explain this in detail on a dedicated page</a>.</p>
<p>- Sean Connery's Submariner strap in Goldfinger has <strong>a nylon loop</strong>, whereas NATO straps have two steel loops.</p>

<p><img src="https://www.esprit-nato.com/img/cms/James%20Bond/Sean-Connery-nylon-watch-strap-Goldfinger-1964-focus-3.jpg" alt="" width="800" height="827"></p>

<p>James Bond was then wearing a single pass nylon strap with a nylon loop from the same band (same width and pattern).</p>
<p><a href="https://www.esprit-nato.com/bracelets-montre-nylon/153-le-vrai-james-bond-sean-connery-dans-goldfinger-noir-kaki-rouge.html" target="_blank" rel="noreferrer noopener">We are proposing a version here on Esprit NATO</a>.</p>

<p>———— ♦ ————</p>
<h3>Another nylon strap in Goldfinger</h3>
<p>Pussy Galore, Goldfinger's private pilot, was wearing a Coke Rolex GMT Master ref. 6542 on a nylon strap too. Her character was one of the first woman to wear a Rolex sport watch for men in a movie.</p>

<p><img src="https://www.esprit-nato.com/img/cms/James%20Bond/Pussy-Galore-nylon-strap-Rolex-6542-Goldfinger-1964.jpg" alt="" width="800" height="1077"></p>

<p>Was nylon strap already essential ?</p>

<p>———— ♦ ————</p>
<h3>The real NATO strap in James Bond world</h3>

<p><img src="https://www.esprit-nato.com/img/cms/James%20Bond/publicite-bracelet-NATO-James-Bond.jpg" alt="" width="800" height="360"></p>

<p>We have seen several similarities between Sean Connery's nylon strap in Goldfinger and <a href="https://www.esprit-nato.com/content/9-l-histoire-du-bracelet-nato" target="_blank" rel="noreferrer noopener">the original NATO designed for British army</a>. It is probably <strong>the origin of the confusion</strong>...</p>

<p>———— ♦ ————</p>
<h3>Myth becomes reality</h3>
<p>In 2008, Daniel Craig is wearing a Rolex 6538 Submariner "Big Crown" offered by Barbara Broccoli, current producer of James Bond movies, and daughter of the original James Bond producer (Albert "Cubby" Broccoli), and he is wearing this inconic watch on ...</p>

<p><img src="https://www.esprit-nato.com/img/cms/James%20Bond/bracelet-NATO-Daniel-Craig-James-Bond-Rolex-Submariner-6538-1.jpg" alt="" width="799" height="1249"></p>

<p>No doubt, it is a real NATO strap as we clearly identify one of its typical stainless steel loops.</p>

<p>———— ♦ ————</p>
<h3>James Bond straps on Esprit NATO</h3>
<h4>The most mythical</h4>
<p>The most mythical pattern is Sean Connery's one in Goldfinger, Black 2 Green stripes and Burgundy borders. We propose it in multiple variations <strong>under the name "Bond Original"</strong>.</p>
<p><a href="https://www.esprit-nato.com/bracelets-montre-nylon/153-le-vrai-james-bond-sean-connery-dans-goldfinger-noir-kaki-rouge.html" target="_blank" rel="noreferrer noopener">But here is the authentic Bond Original Goldfinger strap</a> :</p>

<p><a href="https://www.esprit-nato.com/bracelets-montre-nylon/153-le-vrai-james-bond-sean-connery-dans-goldfinger-noir-kaki-rouge.html" target="_blank" rel="noreferrer noopener"><img src="https://www.esprit-nato.com/img/cms/James%20Bond/Bracelet-US-Military-Vrai-James-Bond-Sean-Connery-Noir-Kaki-Rouge.jpg" alt="" width="801" height="534"></a></p>

<h4>The most famous</h4>
<p>The most famous James Bond pattern is the Black 2 Grey stripes, for several reasons :</p>
<ul><li>It is Daniel Craig's one.</li>
<li>Goldfinger movie was initially in black and white, so the original pattern looked like black and grey. Confusion has existed for a long time...</li>
<li>It matches to any watch, any style and any other colours, and remains sober despite its strong character.</li>
</ul><p>We propose it <strong>under the name "Craig Bond"</strong>. It is so essential that you will find on Esprit NATO in <strong>every design and size</strong>.</p>

<p><a href="https://www.esprit-nato.com/nato-boucles-polies-bracelets-montre/276-bracelet-nylon-nato-bond-craig-noir-gris-boucle-polie.html" target="_blank" rel="noreferrer noopener"><img src="https://www.esprit-nato.com/img/cms/James%20Bond/Bracelet-NATO-Prestige-James-Bond-Craig-Noir-Gris.jpg" alt="" width="801" height="534"></a></p>

<h4>Others</h4>
<p>By extension, we name <a href="https://www.esprit-nato.com/6-nato-james-bond-bracelets-montre" target="_blank" rel="noreferrer noopener"><strong>"James Bond NATO straps"</strong></a> every 2 stripes strap (with or without borders).</p>

<p><a href="https://www.esprit-nato.com/6-nato-james-bond-bracelets-montre" target="_blank" rel="noreferrer noopener"><img src="https://www.esprit-nato.com/img/cms/James%20Bond/bracelets-nato-james-bond-straps.jpg" alt="" width="800" height="435"></a></p>

<hr><p><em>We hope you are now convinced that NATO strap and James Bond are connected forever.</em></p>
<p><em>However, if you want to watch Goldfinger again or to buy a Bond NATO, then we succeeded in our mission...</em></p>

    

    
      
    

    
      
    

  </section>


    
      
    

  </section>


    
  </div></div>]]>
            </description>
            <link>https://www.esprit-nato.com/en/content/10-nato-watch-strap-band-and-james-bond-007</link>
            <guid isPermaLink="false">hacker-news-small-sites-24527065</guid>
            <pubDate>Sat, 19 Sep 2020 12:48:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Describing and Inventing a New Regular Expression Quantifier]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24526895">thread link</a>) | @robertelder
<br/>
September 19, 2020 | https://blog.robertelder.org/regular-expression-quantifiers/ | <a href="https://web.archive.org/web/*/https://blog.robertelder.org/regular-expression-quantifiers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<div>


<h5>2020-08-18 - By Robert Elder</h5>






<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This article is part of a <a href="https://blog.robertelder.org/regular-expressions/">Series On Regular Expressions</a>.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In this article, we will discuss regular expression quantifiers with the ultimate goal of developing a very deep understanding of how they work. &nbsp;In fact, by the end of this article you'll understand quantifiers so well, that you'll be able to extend your knowledge to invent a completely new quantifier has never been seen before in any regular expression engine.</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;By the end of this article, you will understand everything in the following diagram:</p>

<table>
	<tbody>
		<tr><td>Quantifier Symbol</td><td>Min # Matches</td><td>Max # Matches</td><td>As Many/Few As Possible</td><td>Allow Backtracking?</td></tr>
		<tr><td>?</td><td>0</td><td>1</td><td>Many</td><td>Yes</td></tr>
		<tr><td>*</td><td>0</td><td>Infinity</td><td>Many</td><td>Yes</td></tr>
		<tr><td>+</td><td>1</td><td>Infinity</td><td>Many</td><td>Yes</td></tr>
		<tr><td>{N}</td><td>N</td><td>N</td><td>Many</td><td>Yes</td></tr>
		<tr><td>{,N}</td><td>0</td><td>N</td><td>Many</td><td>Yes</td></tr>
		<tr><td>{N,}</td><td>N</td><td>Infinity</td><td>Many</td><td>Yes</td></tr>
		<tr><td>{N,M}</td><td>N</td><td>M</td><td>Many</td><td>Yes</td></tr>

		<tr><td>??</td><td>0</td><td>1</td><td>Few</td><td>Yes</td></tr>
		<tr><td>*?</td><td>0</td><td>Infinity</td><td>Few</td><td>Yes</td></tr>
		<tr><td>+?</td><td>1</td><td>Infinity</td><td>Few</td><td>Yes</td></tr>
		<tr><td>{N}?</td><td>N</td><td>N</td><td>Few</td><td>Yes</td></tr>
		<tr><td>{,N}?</td><td>0</td><td>N</td><td>Few</td><td>Yes</td></tr>
		<tr><td>{N,}?</td><td>N</td><td>Infinity</td><td>Few</td><td>Yes</td></tr>
		<tr><td>{N,M}?</td><td>N</td><td>M</td><td>Few</td><td>Yes</td></tr>

		<tr><td>?+</td><td>0</td><td>1</td><td>Many</td><td>No</td></tr>
		<tr><td>*+</td><td>0</td><td>Infinity</td><td>Many</td><td>No</td></tr>
		<tr><td>++</td><td>1</td><td>Infinity</td><td>Many</td><td>No</td></tr>
		<tr><td>{N}+</td><td>N</td><td>N</td><td>Many</td><td>No</td></tr>
		<tr><td>{,N}+</td><td>0</td><td>N</td><td>Many</td><td>No</td></tr>
		<tr><td>{N,}+</td><td>N</td><td>Infinity</td><td>Many</td><td>No</td></tr>
		<tr><td>{N,M}+</td><td>N</td><td>M</td><td>Many</td><td>No</td></tr>

		<tr><td>?💩</td><td>0</td><td>1</td><td>Few</td><td>No</td></tr>
		<tr><td>*💩</td><td>0</td><td>Infinity</td><td>Few</td><td>No</td></tr>
		<tr><td>+💩</td><td>1</td><td>Infinity</td><td>Few</td><td>No</td></tr>
		<tr><td>{N}💩</td><td>N</td><td>N</td><td>Few</td><td>No</td></tr>
		<tr><td>{,N}💩</td><td>0</td><td>N</td><td>Few</td><td>No</td></tr>
		<tr><td>{N,}💩</td><td>N</td><td>Infinity</td><td>Few</td><td>No</td></tr>
		<tr><td>{N,M}💩</td><td>N</td><td>M</td><td>Few</td><td>No</td></tr>
	</tbody>
</table>

<iframe src="https://www.youtube.com/embed/YTMJ4E5qVkM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Quantifiers are used to quantify how many times a part of your regular expression should be repeated. &nbsp;Every time you want to repeat something in a regex (an individual character, a character class or a sub-expression) you can write a quantifier after it to specify how many times it should be repeated.</p>


<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The following list shows some examples of the most common quantifiers:</p>

<ul>
<li><strong>?</strong></li>
<li><strong>*</strong></li>
<li><strong>+</strong></li>
<li><strong>{N}</strong></li>
<li><strong>{,N}</strong></li>
<li><strong>{N,}</strong></li>
<li><strong>{N,M}</strong></li>
</ul>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This article will only discuss these quantifiers within the context of Perl-like regular expressions (<em>not</em> POSIX regular expressions). &nbsp;This is worth mentioning since the older POSIX style regular expression quantifiers lack certain features, and have significantly different behaviour in some cases.</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Most typical guides to regular expressions would probably start by immediately diving into a detailed description of what each of these symbols does. &nbsp;They would probably start by explaining the meaning of the '*', '+', and '?' symbols. &nbsp;However, <em><strong>this won't be your typical guide to regular expressions</strong></em>.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Instead, we'll start by focusing on understanding this quantifier:</p>

<p><code><pre>{N,M}
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The reason for this atypical approach is simple: &nbsp;Once you understand what <em>this</em> quantifier does, you're already 50% done learning everything there is to know about quantifiers. &nbsp;Let's do a few examples.</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Assume you need to write a regular expression that can match both spellings of the word 'enroll'. &nbsp;The word 'enroll' can sometimes be spelled with one 'l' or two 'l's depending on whether the author chooses to use British or American spelling conventions. &nbsp;Using this regex:</p>

<p><code><pre>enrol{1,2}
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;you'll be able to match both spellings of 'enroll':</p>

<ul>
	<li>enrol</li>
	<li>enroll</li>
</ul>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Here is a link to an <a href="https://blog.robertelder.org/regular-expression-visualizer/?the_regex=enrol%7B1%2C2%7D">interactive visualization of the regex enrol{1,2}</a></p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In this case the quantifier is the '{1,2}' part. &nbsp;The '{1,2}' quantifier can be interpreted in English to mean "Whatever came just before this quantifier, repeated anywhere from 1 to 2 times.". &nbsp;If you wanted to change the regex to also match any misspellings of 'enroll' that have 3 'l's, you could just change the upper bound of the range from 2 to 3:</p>

<p><code><pre>enrol{1,3}
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;And now, using the regex above, you can match all three spellings of the word 'enroll':</p>

<ul>
	<li>enrol</li>
	<li>enroll</li>
	<li>enrolll</li>
</ul>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;You could go even further and change the regex to include misspellings that don't have any 'l's at all, by decreasing the lower bound of the range 0:</p>

<p><code><pre>enrol{0,3}
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Using the regex above, you can match these four (miss)spellings of the word 'enroll':</p>

<ul>
	<li>enro</li>
	<li>enrol</li>
	<li>enroll</li>
	<li>enrolll</li>
</ul>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The pattern that this quantifier uses should now be a bit more obvious: &nbsp;Whenever we want specify that the previous character can be repeated a lower bound of N times up to an upper bound of M times, we can write this quantifier after the character:</p>

<p><code><pre>{N,M}
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Of course, the letters 'N' and 'M' here are placeholders that are used for the purposes of documentation. &nbsp;In reality, you would never literally write '{N,M}' as a quantifier in your regular expression. &nbsp;You would would write something like '{2,8}', '{0,20}' or any other pair of positive integers.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In order to make things crystal clear, there are a few cases where the endpoints of the range are not explicitly written, but are instead implied. &nbsp;Here is an example:</p>

<p><code><pre>a{,5}
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The interpretation of this quantifier is to repeat the character 'a' anywhere from (it doesn't matter times) to 5 times. &nbsp;Another way to describe the same thing would be to say "repeat the character 'a' anywhere from 0 times to 5 times" which you could do with the following equivalent regex:</p>

<p><code><pre>a{0,5}
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;You'll sometimes see the same thing with the upper bound of the range:</p>

<p><code><pre>a{3,}
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and in these cases the upper end of the range is assumed to be "Infinity", however there is no equivalent way to write this explicitly. &nbsp;You simply can't write something like this:</p>

<p><code><pre>a{3,Infinity} (This does not work)
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;since most regex engines will default to interpreting the range quantifier as literal text if it doesn't see the format it expects. &nbsp;Therefore, when the upper bound of your range is 'infinity', you must simply omit the second number like this: '{3,}'.</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;One final important case to consider is when a single number is used to describe that the previous character should be matched <em>exactly</em> the number of times specified. &nbsp;For example, this regex will match any sequence of <em>exactly</em> 4 'a' characters:</p>

<p><code><pre>a{4}
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If we wanted to re-write this using a range, we could write:</p>

<p><code><pre>a{4,4}
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;which means the same thing.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Of the quantifiers we've reviewed so far, it should be clear that they can all be re-written in the following standardized form:</p>

<p><code><pre>{N,M}
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;where</p>

<ul>
	<li>'N' is a positive integer.</li>
	<li>'M' is a positive integer OR left blank to represent 'infinity'.</li>
</ul>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;We still haven't discussed the meaning of the '?', '*' and '+' quantifiers, so let's do that now:</p>

<ul>
	<li>'<strong>?</strong>' is just <a href="https://en.wikipedia.org/wiki/Syntactic_sugar">syntax sugar</a> for '<strong>{0,1}</strong>'.</li>
	<li>'<strong>*</strong>' is just <a href="https://en.wikipedia.org/wiki/Syntactic_sugar">syntax sugar</a> for '<strong>{0,}</strong>'.</li>
	<li>'<strong>+</strong>' is just <a href="https://en.wikipedia.org/wiki/Syntactic_sugar">syntax sugar</a> for '<strong>{1,}</strong>'.</li>
</ul>


<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Here is an <a href="https://blog.robertelder.org/regular-expression-visualizer/?the_regex=a%3F&amp;the_subject=a">example interactive visualization showing the '?' quantifier</a> that makes the character 'a' optional. &nbsp;As you can see, the control flow graph splits into two possible paths: &nbsp;One that skips the character 'a', and one that requires it. &nbsp;If one path fails, the regular expression engine simply backtracks to try the other path.</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Here is an <a href="https://blog.robertelder.org/regular-expression-visualizer/?the_regex=a%2B&amp;the_subject=a">example interactive visualization showing the '+' quantifier</a> that matches the character 'a' one or more times. &nbsp;As you can see, the control flow graph starts by requiring an 'a' character. &nbsp;If there are no 'a' characters, it fails immediately. &nbsp;If there is at least one, control will split into two possible paths: &nbsp;One path goes back to try and get yet another 'a' character, and the other continues with the rest of the regex. &nbsp;By default, the regex engine will first try the path that consumes yet another 'a' character until there are no more in the search text.</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Here is an <a href="https://blog.robertelder.org/regular-expression-visualizer/?the_regex=a*&amp;the_subject=a">example interactive visualization showing the '*' quantifier</a> that matches the character 'a' zero or more times. &nbsp;As you can see, the control flow graph starts by splitting into two possible paths: &nbsp;One path immediately continues on with the rest of the regex, and the other attempts to consume an 'a' character. &nbsp;By default, this quantifier will first try the path that consumes an 'a' character. &nbsp;Once it fails to find another 'a' character, it will give up and continue on with the rest of the regex.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Here is a table to summarize what we've learned so far:</p>

<table>
	<tbody>
		<tr><td>Quantifier Symbol</td><td>Normalized As A Range</td><td>What It Really Means</td></tr>
		<tr><td>?</td><td>{0,1}</td><td>"Repeated from 0 to 1 times."</td></tr>
		<tr><td>*</td><td>{0,}</td><td>"Repeated from 0 to Infinity times."</td></tr>
		<tr><td>+</td><td>{1,}</td><td>"Repeated from 1 to Infinity times."</td></tr>
		<tr><td>{N}</td><td>{N,N}</td><td>"Repeated from N to N times."</td></tr>
		<tr><td>{,N}</td><td>{0,N}</td><td>"Repeated from 0 to N times."</td></tr>
		<tr><td>{N,}</td><td>{N,}</td><td>"Repeated from N to Infinity times."</td></tr>
		<tr><td>{N,M}</td><td>{N,M}</td><td>"Repeated from N to M times."</td></tr>
	</tbody>
</table>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;As discussed previously, quantifiers can be used to specify how many times a character in your regular expression can be repeated:</p>

<p><code><pre>a{0,5}
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;But, you can also apply quantifiers to character classes too:</p>

<p><code><pre>[0-9]{0,5}
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For example, you could use this regular expression to match chapter titles in a book, regardless of how many digits are in the chapter number:</p>

<p><code><pre>[Cc]hapter [0-9]+
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;And most importantly, you can also apply a quantifier to a sub-expression to repeat a sequence of characters. &nbsp;For example this regex:</p>

<p><code><pre>(Hello){2,5}
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;will match any of the following strings:</p>

<ul>
	<li>HelloHello</li>
	<li>HelloHelloHello</li>
	<li>HelloHelloHelloHello</li>
</ul>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;You can even apply quantifiers to a sub-expression that contains an alternation. &nbsp;This regex:</p>

<p><code><pre>(cat|dog|bird){1,2}
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;will match any of the following strings:</p>

<ul>
	<li>cat</li>
	<li>dog</li>
	<li>bird</li>
	<li>catcat</li>
	<li>catdog</li>
	<li>catbird</li>
	<li>dogcat</li>
	<li>dogdog</li>
	<li>dogbird</li>
	<li>birdcat</li>
	<li>birddog</li>
	<li>birdbird</li>
</ul>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Just as promised earlier, you're already 50% done learning everything there is to know about quantifiers. &nbsp;There are many more quantifiers than what we've seen so far, but fortunately, there are only 4 fundamental aspects to every regular expression quantifier, and you'll understand them all by the end of this article. &nbsp;Here are those 4 aspects:</p>

<ul>
	<li><strong>1)  The minimum number of times it can match.</strong></li>
	<li><strong>2)  The maximum number of times it can match.</strong></li>
	<li>3)  Whether it prefers to match as many times as possible, or as few times as possible.</li>
	<li>4)  Whether it will disable backtracking or not.</li>
</ul>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and as you can see, we've already covered the first two, so 2/4 = 50% done.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Now let's cover item #3 from the list above: "Whether it prefers to match as many times as possible, or as few times as possible.". &nbsp;Consider a case where we want to match this regular expression:</p>

<p><code><pre>a{2,4}(aabbcc|bb)
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;against this piece of text:</p>

<p><code><pre>aaaabbcc
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;You can follow through the matching process with an <a href="https://blog.robertelder.org/regular-expression-visualizer/?the_regex=a%7B2%2C4%7D(aabbcc%7Cbb)&amp;the_subject=aaaabbcc">interactive visualization of the matching process for this regex here</a>.</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Since the quantifier '{2,4}' can match the 'a' anywhere from 2 times to 4 times, and the text we're searching starts with 4 consecutive 'a's, it's ok for the regular …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.robertelder.org/regular-expression-quantifiers/">https://blog.robertelder.org/regular-expression-quantifiers/</a></em></p>]]>
            </description>
            <link>https://blog.robertelder.org/regular-expression-quantifiers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24526895</guid>
            <pubDate>Sat, 19 Sep 2020 12:12:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benchmark of popular graph/network packages]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24526881">thread link</a>) | @dvfjsdhgfv
<br/>
September 19, 2020 | https://www.timlrx.com/2019/05/05/benchmark-of-popular-graph-network-packages/ | <a href="https://web.archive.org/web/*/https://www.timlrx.com/2019/05/05/benchmark-of-popular-graph-network-packages/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <div>
    <div>
      <article role="main">
        



<p><strong>This post is superseded by an <a href="https://www.timlrx.com/2020/05/10/benchmark-of-popular-graph-network-packages-v2/">updated benchmark</a></strong></p>
<p>In this post I benchmark the performance of 5 popular graph/network packages. This was inspired by two questions I had:</p>
<ol>
<li><p>Recently, I have been working with large networks (millions of vertices and edges) and often wonder what is the best currently available package/tool that would scale well and handle large scale network analysis tasks. Having tried out a few (networkx in Python and igraph in R) but on different problems, I thought it would be nice to have a head to head comparison.</p></li>
<li><p>Running large scale computations is also much easier nowadays with the availability of virtual machines that could be easily spinned up thanks to the growth of cloud computing. I think the trend of powerful single machines will eliminate a lot of the need for enterprise clusters so it will be interesting to see how far we can push a single machine using optimised algorithms.<a href="#fn1" id="fnref1"><sup>1</sup></a></p></li>
</ol>
<p>To replicate the benchmark study and for the full codes, please refer to <a href="https://github.com/timlrx/graph-benchmarks">my github repository</a>. Instructions on how to setup and install the packages are also located in the repository.</p>
<div id="setup">
<h2>Setup</h2>
<p>The benchmark was carried out using a Google Compute n1-standard-16 instance (16vCPU Haswell 2.3GHz, 60 GB memory). I compare 5 different packages:</p>
<ul>
<li><a href="https://graph-tool.skewed.de/">graph-tool</a></li>
<li><a href="https://igraph.org/redirect.html">igraph</a></li>
<li><a href="https://networkit.github.io/">networkit</a></li>
<li><a href="https://networkx.github.io/">networkx</a></li>
<li><a href="https://snap.stanford.edu/snappy/">snap</a></li>
</ul>
<p>Networkx is written in Python while the other four packages are based on C / C++ but have Python APIs. Igraph has a R and Mathematica binding as well but to be consistent the following benchmark was based on the Python one. The other 3 libraries (snap, networkit and graph-tool) have an additional emphasis on performance with multi-processing capabilities built in.</p>
<p>Selecting what tasks to compare on is not really a trivial task with each package offering various tools and capabilities. In the end, I decided to focus on 5 specific problems:</p>
<ul>
<li>loading the data</li>
<li>single source shortest path</li>
<li>page rank</li>
<li>k-core decomposition</li>
<li>strongly connected components</li>
</ul>
<p>Loading is more of an I/O task while the other 4 are common graph algorithms. Disclaimer: I try as much as possible to specify the same parameters for each algorithm but differences in API across the packages could translate to actual differences in how the algorithm is run and the final output.</p>
<p><span>13/12/2019 Edit: Some of the observed differences in performance might be a result of different stopping criteria used - see algorithms for more information.</span></p>
<p>3 datasets from the <a href="https://snap.stanford.edu/data/index.html">Stanford Large Network Dataset Collection</a> were used in the exercise:</p>
<ul>
<li><a href="https://snap.stanford.edu/data/amazon0302.html">amazon</a>, 262k nodes, 1.2m edges</li>
<li><a href="https://snap.stanford.edu/data/web-Google.html">google</a>, 875k nodes, 5.1m edges</li>
<li><a href="https://snap.stanford.edu/data/soc-Pokec.html">pokec</a>, 1.6m nodes, 30.6m edges</li>
</ul>
<p>While it is the easiest to rank the packages based on the run-time of the algorithms, it is only one of the many considerations of what makes a good package. I try to offer a more subjective view based on my experience with these packages.</p>
</div>

<div id="results">
<h2>Results</h2>
<p>All timings reported are normalised to reflect the run time for a single run of the task.</p>
<p>Networkx is much slower than any of the other libraries. Across all computation tasks and for all datasets it is around 10 times slower than the <em>slowest</em> library.<a href="#fn2" id="fnref2"><sup>2</sup></a> For example, it took 67s to run the single source shortest path problem on the Pokec dataset compared to 6.8s for networkit (the next slowest). Page rank took more than 10 minutes to run compared to 1 minute for igraph. Hence, I left it out of the comparison plots.</p>
<p>Here are the run times of the remaining four packages:</p>
<p><img src="https://d33wubrfki0l68.cloudfront.net/b13c3d06c53af36cafd2b861d21948ee7613dd3a/3c0f3/post/2019-05-05-benchmark-of-popular-graph-network-packages_files/figure-html/plot_all-1.png" width="672"></p>
<p>Full results can be seen from the table below:</p>
<table>
<thead>
<tr>
<th>
dataset
</th>
<th>
Algorithm
</th>
<th>
graph-tool
</th>
<th>
igraph
</th>
<th>
networkit
</th>
<th>
networkx
</th>
<th>
snap
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Amazon
</td>
<td>
connected components
</td>
<td>
0.09
</td>
<td>
0.48
</td>
<td>
0.21
</td>
<td>
5.94
</td>
<td>
0.40
</td>
</tr>
<tr>
<td>
Amazon
</td>
<td>
k-core
</td>
<td>
0.11
</td>
<td>
0.33
</td>
<td>
0.01
</td>
<td>
8.62
</td>
<td>
0.42
</td>
</tr>
<tr>
<td>
Amazon
</td>
<td>
loading
</td>
<td>
5.00
</td>
<td>
0.79
</td>
<td>
3.27
</td>
<td>
9.96
</td>
<td>
1.90
</td>
</tr>
<tr>
<td>
Amazon
</td>
<td>
page rank
</td>
<td>
0.05
</td>
<td>
1.59
</td>
<td>
0.01
</td>
<td>
25.71
</td>
<td>
0.90
</td>
</tr>
<tr>
<td>
Amazon
</td>
<td>
shortest path
</td>
<td>
0.06
</td>
<td>
0.12
</td>
<td>
0.32
</td>
<td>
3.31
</td>
<td>
0.14
</td>
</tr>
<tr>
<td>
Google
</td>
<td>
connected components
</td>
<td>
0.32
</td>
<td>
2.23
</td>
<td>
0.65
</td>
<td>
21.71
</td>
<td>
2.02
</td>
</tr>
<tr>
<td>
Google
</td>
<td>
k-core
</td>
<td>
0.57
</td>
<td>
1.68
</td>
<td>
0.06
</td>
<td>
153.21
</td>
<td>
1.57
</td>
</tr>
<tr>
<td>
Google
</td>
<td>
loading
</td>
<td>
67.27
</td>
<td>
5.51
</td>
<td>
17.94
</td>
<td>
39.69
</td>
<td>
9.03
</td>
</tr>
<tr>
<td>
Google
</td>
<td>
page rank
</td>
<td>
0.76
</td>
<td>
5.24
</td>
<td>
0.12
</td>
<td>
106.49
</td>
<td>
4.16
</td>
</tr>
<tr>
<td>
Google
</td>
<td>
shortest path
</td>
<td>
0.20
</td>
<td>
0.69
</td>
<td>
0.98
</td>
<td>
12.33
</td>
<td>
0.30
</td>
</tr>
<tr>
<td>
Pokec
</td>
<td>
connected components
</td>
<td>
1.35
</td>
<td>
17.75
</td>
<td>
4.69
</td>
<td>
108.07
</td>
<td>
15.28
</td>
</tr>
<tr>
<td>
Pokec
</td>
<td>
k-core
</td>
<td>
5.73
</td>
<td>
10.87
</td>
<td>
0.34
</td>
<td>
649.81
</td>
<td>
8.87
</td>
</tr>
<tr>
<td>
Pokec
</td>
<td>
loading
</td>
<td>
119.57
</td>
<td>
34.53
</td>
<td>
157.61
</td>
<td>
237.72
</td>
<td>
59.75
</td>
</tr>
<tr>
<td>
Pokec
</td>
<td>
page rank
</td>
<td>
1.74
</td>
<td>
59.55
</td>
<td>
0.20
</td>
<td>
611.24
</td>
<td>
19.52
</td>
</tr>
<tr>
<td>
Pokec
</td>
<td>
shortest path
</td>
<td>
0.86
</td>
<td>
0.87
</td>
<td>
6.87
</td>
<td>
67.15
</td>
<td>
3.09
</td>
</tr>
</tbody>
</table>
<div id="io">
<h3>I/O</h3>
<p>Looking at the plots above, graph-tool and networkit loads data much more slowly than the other two libraries. I was reading the datasets as a tab delimited file and graph-tool basically uses a Python code to parse the input. The other 3 packages should be using C libraries to read the files which result in better performance.<a href="#fn3" id="fnref3"><sup>3</sup></a></p>
</div>
<div id="algorithms">
<h3>Algorithms</h3>
<p>Networkit and graph-tool takes the top spot in most of the tests with graph-tool having the shortest run time for the single source shortest path and connected components problems and networkit winning the race for k-core and page rank.</p>
<p>When networkit is fast, it is extremely fast. On the pokec dataset it takes just 0.2s to run the page rank algorithm (graph-tool: 1.7s, igraph: 59.6s, snap: 19.5s). For the k-core decomposition it is also 10 times faster than all other competitors or 2000 times networkx. That is consistent with the findings of their research paper where they claim that using some of the latest state of the art algorithms led to their processing speed being faster by an order of magnitude. However, for the shortest path problem (not analysed in their paper) it lags behind all other packages.<a href="#fn4" id="fnref4"><sup>4</sup></a></p>
<p><span>13/12/2019 Edit: Matthew Galati from SAS pointed out that for the pagerank algorithm, networkit (as of version 6.0) uses L2 norm as a stopping criteria while other packages use the L1 norm. This means that it is doing fewer iterations and the speed is somewhat artificial. Thanks Matthew!</span></p>
<p>graph-tool is the most steady performer and achieves very impressive performance across all four tasks. With openMP support it betters igraph and snap across all tasks. It is 3 to 10+ times faster than those two packages.</p>
<p>igraph and snap achieves mostly similar performance across all tasks with a slight edge towards snap. This is also consistent with snap’s research findings.</p>
</div>
<div id="other-considerations">
<h3>Other Considerations</h3>
<p>There are also other important considerations when making a switch from networkx or igraph to one graph-tool or networkit.</p>
<p><strong>Packages</strong><br>
First, the algorithms available differ quite significantly across the packages. Users interested in switching to one of these packages should read the documentation on the list of features available. For example, while they all contain the basic tools needed to manipulate networks, graph-tool does not have the more usual modular clustering tools but has additional functionalities on statistical inference on graphs using stochastic block models.</p>
<p>Visualising networks is also an important part of the analytical tool chain. Igraph implements quite a few layout algorithms and renders them using the cairo library. Snap supports graphviz while graph-tool supports both graphviz and cairo. Networkit takes a different approach and relies on networkx to draw while also providing support and integration with Gephi via its streaming plugin.</p>
<p><strong>API</strong><br>
Moving away from native Python or R means that the syntax for the packages can sometimes be quite convoluted. I compare the syntax for the shortest path problem below. Writing it in networkx would look something like this:</p>
<pre><code>nx.shortest_path_length(g, nodeid)</code></pre>
<p>igraph:</p>
<pre><code>g.shortest_paths([g.vs[node_index]])</code></pre>
<p>graph-tool:</p>
<pre><code>shortest_distance(g, g.vertex(node_index))</code></pre>
<p>networkit:</p>
<pre><code>distance.BFS(g, node_index).run()</code></pre>
<p>snap:</p>
<pre><code>NIdToDistH = snap.TIntH()
snap.GetShortPath(g, node_index, NIdToDistH, True)</code></pre>
<p>Of all, I find snap’s the most cumbersome since one has to define an additional variable (with the correct variable type) to store the results before running it. Running more advanced functions on graph-tool and networkit also requires a user to pre-define variables with the correct type to store results.<a href="#fn5" id="fnref5"><sup>5</sup></a></p>
<p><strong>Support and Documentation</strong><br>
User support and documentation is really important when one wants to use the project in an actual project setting. Networkx is by far the winner in this category with more than 4k github stars and lots of issues documented in github and stackoverflow. Igraph fairs decently as well with more than a thousand stars across its different modules.</p>
<p>graph-tool and networkit has much smaller followings though the creators seem relatively responsive to user issues and the packages are in active development.</p>
<p>snap was last updated on July 2018 but still supports only Python 2.7.x versions.</p>
</div>
<div id="conclusion">
<h3>Conclusion</h3>
<p>Overall, I am pleasantly surprised at the performance of the libraries especially graph-tool and networkit and plan to play around with them further. The fact that they breeze through the Pokec dataset is a good sign, but it will be interesting to find out what is the limit before computation becomes slow or memory issues start appearing.</p>
<p>As for recommendations on which package people should learn, I think picking up networkx is still important as it makes network science very accessible with a wide range of tools and capabilities. If analysis starts being too slow (and maybe that’s why you are here) then I will suggest taking a look at graph-tool or networkit to see if they contain the necessary algorithms for your needs.</p>
</div>
</div>



        
          
        

        

        
      </article>

      
        
      


      

    </div>
  </div>
</div></div>]]>
            </description>
            <link>https://www.timlrx.com/2019/05/05/benchmark-of-popular-graph-network-packages/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24526881</guid>
            <pubDate>Sat, 19 Sep 2020 12:09:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Rust is not a mature programming language]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 69 (<a href="https://news.ycombinator.com/item?id=24526861">thread link</a>) | @DarkCrusader2
<br/>
September 19, 2020 | https://codecs.multimedia.cx/2020/09/why-rust-is-not-a-mature-programming-language/ | <a href="https://web.archive.org/web/*/https://codecs.multimedia.cx/2020/09/why-rust-is-not-a-mature-programming-language/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>While I have nothing against Rust as such and keep writing my pet project in Rust, there are still some deficiencies I find preventing Rust from being a proper programming language. Here I’d like to present them and explain why I deem them as such even if not all of them have any impact on me.<br>
<span id="more-1971"></span></p>
<h3>Rust language problems</h3>
<p>First and foremost, <strong>Rust does not have a formal language specification</strong> and by that I mean that while some bits like grammar and objects are explained, there are no formal rules to describe what language features can and cannot be. If you’ve ever looked at ISO C standard you’ve seen that almost any entity there has three or four parts in the description: formal syntax, constraints (i.e. what is not allowed or what can’t be done with it), semantics (i.e. what it does, how it impacts the program, what implementation caveats are there), and there may be some examples to illustrate the points. The best close equivalent in Rust is <a href="https://doc.rust-lang.org/reference/" rel="noopener noreferrer" target="_blank">The Rust Reference</a> and e.g. structure there is described in the following way: syntax (no objections there), definition in a form of “A struct is a nominal struct type defined with the keyword <code>struct</code>.”, examples, a brief mention of empty (or unit-like) structures in the middle of examples, and “The precise memory layout of a struct is not specified.” at the end. I understand that adding new features is more important than documenting them but this is lame.</p>
<p>A proper mature language (with 1.0 in its version) should have a formal specification that should be useful both for people developing compilers and the programmers trying to understand certain intricacies of the language and why it does not work as expected (more on that later). For example, for that <code>struct</code> definition I find lacking at least these: mentioning that you can have <code>impl</code> for it (even a reference would do—even if you have to repeat it for every type), split off tuples into a separate entry because it’s very different syntactically and raises a question why you have anonymous tuples and not anonymous structs (which you also can’t find from the documentation), and of course create proper layout so that rather important information (about memory layout for example) is not lost among examples.</p>
<p>And now to the specific problems I encounter quite often and I don’t know whether I understand it wrong or the compiler understands it wrong. And since there’s no formal specification I can’t tell which one it is (even if the former is most probable).</p>
<p><strong>Function/method calling convention.</strong> Here’s a simple example:</p>
<blockquote><p>
struct Foo { a: i32 }<br>
impl Foo { fn bar(&amp;mut self, val: i32) { self.a = val + 42; } }<br>
fn main() {<br>
&nbsp; let mut foo = Foo { a: 0 };<br>
&nbsp; foo.bar(foo.a);<br>
}
</p></blockquote>
<p>For now this won’t compile because of the borrowing but shouldn’t the compiler be smart enough to create a copy of <code>foo.a</code> before call? I’m not sure but IIRC current implementation first mutably borrows object for the call and only then tries to borrow the arguments. Is it really so and if yes, why? <em>Update:</em> I’m told that newer versions of the compiler handle it just fine but the question still stands (was it just a compiler problem or the call definition has been changed?).</p>
<p>The other thing is the old C caveat of function arguments evaluation. Here’s a simple example:</p>
<blockquote><p>
let mut iter = “abc”.chars();<br>
foo(iter.next().unwrap(), iter.next().unwrap(), iter.next().unwrap());
</p></blockquote>
<p>So would it be <code>foo('a','b','c')</code> or <code>foo('c','b','a')</code> call. In C it’s undefined because it depends on how arguments are passed on the current platform (consider yourself lucky if you don’t remember <code>__pascal</code> or <code>__stdcall</code>). In Rust it’s undefined because there’s no formal specification to tell you even that much. And it would be even worse if you consider that you may use the same source for indexing the caller object like <code>handler[iter.next().unwrap() as usize].process(iter.next().unwrap());</code> in some theoretical bytecode handler (of course it’s a horrible way to write code and you should use named temporary variables but it should illustrate the problem).</p>
<p>And another source of annoyance for me is <strong>traits</strong>. I have almost no problems with owning/lifetime/borrowing concepts but traits get me almost every time. I’m vaguely aware that the answer to why the following problems exist is “because traits are implemented as a call table” but again, <em>should</em> they be implemented like that and what should be the constraints on them (after all the original object should be somehow linked to the trait pointer). So when you have a supertrait (i.e. <code>trait Foo: Bar</code>) you can’t easily cast it for subtrait (e.g. <code>&amp;Foo -&gt; &amp;Bar</code>) without writing a lot of boilerplate code. And even worse if you convert an object into <code>Box&lt;trait&gt;</code> there’s no way to get the original object back (still in boxed form of course; I remember seeing a special crate that implements a lot of boilerplate code in order to get a mutable reference though). To reiterate: the problem is not me being stupid but rather the lack of formal description on how it’s done and why what I want is so hard. Then I’d probably at least be able to realize how I should change my code to work around the limitations.</p>
<h3><code>rustc</code> problems</h3>
<p>No, I’m not going to talk about compilation speed. It’s certainly a nuisance but not a problem per se. Here I want to point rather theoretical problems that a mature language should not have. And having just one compiler is one of those problems (call that problem zero).</p>
<p>First of all, <strong>bootstrapping process</strong> is laughably bad. I realize that it’s never too easy but if you call yourself a systems programming language you should be able to bootstrap a compiler in a sane amount of steps. For instance, IIRC <code>Guix</code> has the following bootstrapping process for C compiler: simple C complier in Scheme (for which you can often write an implementation in assembly by hand) compiles TCC, TCC compiles GCC 2.95, GCC 2.95 compiles GCC 3.7, GCC 3.7 compiles GCC 4.9. For <code>rustc</code> you should either start with the original compiler written in OCaml and compile every following version with the previous one (i.e. 1.17 with 1.16) or cheat by using <code>mrustc</code> written in C++ which can compile Rust 1.19 or 1.29 (without borrow checks), then compile 1.30 with 1.29, 1.31 with 1.30 etc etc. The problem here is that you cannot skip versions and e.g. compile <code>rustc 1.46</code> with <code>rustc 1.36</code> (I’d be happy to learn that I’m wrong). IMO you should have maybe an ineffective compiler but written in a dialect that much older compiler should understand i.e. <code>rustc 1.0</code> should be able to compile a compiler for 1.10, which can be used to compile 1.20 and so forth. Of course it’s a huge waste of resources for rather theoretical problem but it may prove beneficial for compiler design itself.</p>
<p>Then there’s <strong>LLVM dependency.</strong> I understand that <code>LLVM</code> provides many advantages (like no need to worry about code generation for many platforms and optimising it) but it gives some disadvantages too. First, you don’t have a really self-hosting compiler (a theoretical problem but still a thing worth thinking about; also consider that you have to rely on a framework developed mostly by large corporations mostly in their own interests). Second, you’re limited by what it does e.g. I read complaints about debug builds being too slow mostly because of LLVM backend. And I suspect it still can’t do certain kinds of memory-related optimisations because it was designed with C++ compiler in mind which still has certain quirks regarding multiple memory access (plus IIRC there was one LLVM bug triggered by an infinite loop in Rust code that’s perfectly valid there but not according to C++ rules). I’m aware that <code>cranelift</code> exists (and Rust front-end for <code>GCC</code>) so hopefully this will be improved.</p>
<p>And finally there’s a thing related to the previous problem. Rust has poor <strong>support for assembly</strong>. Of course not so many people need standalone assembly and not inline one (which is still lacking but <code>asm!</code> is almost there) but languages oriented for systems programming support compiling assembly in addition to the higher-language code so it would be <em>proper</em> to support assembly files even with not so rich preprocessor syntax as GAS has. Fiddling with <code>build.rs</code> to invoke an external assembler is possible but not nice at all.</p>
<h3>Other Rust language problems</h3>
<p>There’s also one problem with Rust <code>std</code> library that I should mention too. It’s useless for interfacing OS. Now if I want to do something natural to any UNIX system I need to at least import <code>libc</code> crate <del datetime="2020-09-19T03:32:25+00:00">and link against an external libc</del> (it’s part of the runtime anyway). One solution would be that crate I heard of that wanted to translate <code>musl</code> into Rust so you can at least eliminate the linking step. But the proper solution would be to support at least OS-specific syscall() in <code>std</code> crate as many interesting libc functions are just a wrapper over it (like <code>open()</code>/<code>write()</code>/<code>ioctl()</code>; Windows is a different beast so I don’t mind if it’s <code>std::os::unix::syscall</code> and not something more common).</p>
<hr>
<p>I’m not a Rust language architect and I’m extremely unlikely to become one but I have an opinion on what Rust lacks in order to become a proper mature language really fit for systems development (three things essentially: being fully self-hosted, having a specification, and being able to interface low-level stuff without resorting to C compiler or assembler). Hopefully this will be rectified despite the lack of Mozilla.</p>

								
				<p>
					<small>
												This entry was posted on Friday, September 18th, 2020 at 2:03 pm and is filed under <a href="https://codecs.multimedia.cx/category/rust/" rel="category tag">Rust</a>, <a href="https://codecs.multimedia.cx/category/useless-rants/" rel="category tag">Useless Rants</a>.						You can follow any responses to this entry through the <a href="https://codecs.multimedia.cx/2020/09/why-rust-is-not-a-mature-programming-language/feed/">RSS 2.0</a> feed. 

													You can <a href="#respond">leave a response</a>, or <a href="https://codecs.multimedia.cx/2020/09/why-rust-is-not-a-mature-programming-language/trackback/" rel="trackback">trackback</a> from your own site.
						
					</small>
				</p>

			</div></div>]]>
            </description>
            <link>https://codecs.multimedia.cx/2020/09/why-rust-is-not-a-mature-programming-language/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24526861</guid>
            <pubDate>Sat, 19 Sep 2020 12:05:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Backing up data like the adult I supposedly am]]>
            </title>
            <description>
<![CDATA[
Score 182 | Comments 121 (<a href="https://news.ycombinator.com/item?id=24526706">thread link</a>) | @miked85
<br/>
September 19, 2020 | https://magnusson.io/post/backups/ | <a href="https://web.archive.org/web/*/https://magnusson.io/post/backups/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      <div>
        

<article>
  <header>
  
  
  <time datetime="2020-09-18T10:47:47+02:00">
    18 September, 2020
  </time>
  
</header>

  <p>Like so many things I’m supposed to do but don’t — getting exercise, eating right, sleeping well, standing up for women and minorities in public spaces — backing up my data has always been something I’ve half-assed at best.</p>
<p>I’ve lugged around an external hard drive with a few hundred gigabytes of data for the last 10 years, and made backups to it once every three or four years or so. Every time I’ve tried restoring anything from those backups I’ve regretted it, because of course I just bought the drive, plugged it in and copied stuff to it, so it is a FAT32 drive while I have mostly had EXT4 filesystems, which means all my file permissions get lost during the process.</p>
<p>I’ve written shameful little shell scripts to set file permissions to 0644 and directory permissions to 0755, recursively, many many times.</p>
<p>Part of my problem was that I both know just enough rsync to be dangerous and have a credit card so I can provision cloud VMs, so forever just around the corner was my perfect backup solution that I’d write myself and maintain and actually do instead of dealing with whatever I had going on in my life. I’ve come to accept that this will never happen, or perhaps more definitively, that I’d rather cut myself than write and maintain another piece of ad-hoc software for myself.</p>
<p>Luckily I recently found two things that have solved this whole problem for me: <a href="https://borgbackup.readthedocs.io/en/stable/">borg</a> and <a href="https://www.rsync.net/">rsync.net</a>.</p>
<p>Borg is backup software. It compresses and deduplicates data at the block level, and strongly encourages (but does not force) you to encrypt data before backing it up. It is everything I’d want from my half-assed rsync and shell script abomination.</p>
<p>I read its documentation a couple of times and was impressed. I then set about comparing different VM hosts to see which one would give me the cheapest block storage option, when the result of some <a href="https://github.com/scotte/borgsnap">random google search</a> led me to rsync.net. They are a company that stores backups, pretty cheaply, and <a href="http://www.rsync.net/products/attic.html">even more cheaply</a> if you use borg to take them. I guess they just really love borg and want us to love it too.</p>
<p>I signed up for their cheapest plan, which starts at 100GB stored for $18 per year. They have no network in- or egress costs, and the storage amount can be adjusted at any time. Once my account had been activated, I did a little password reset dance, and uploaded a public SSH key.</p>
<p>I wanted to back up my <code>$HOME</code> directory, so after installing borg I ran:</p>
<div>
<div>
<pre>export BORG_REMOTE_PATH="borg1"
borg init --encryption repokey-blake2 UID@ch-s011.rsync.net:home</pre>
</div>
</div>
<p>This created a remote borg repository called "home" on rsync.net’s servers. The environment variable is so we use a more recent version of borg on the remote server (version 1.1.11 at the time of writing), as the default version is rather old (version 0.29.0).</p>
<p>When choosing what encryption method to use, one can choose between a "repokey" or a "keyfile". They both create a private key locked with a passphrase; the difference is that with "repokey" the key is stored in the borg repo, while with "keyfile" it is stored outside of it. This boils down to whether we think a passphrase is enough security for our data, or whether we think having a secret keyfile is necessary. I figured my password manager could create a strong enough passphrase for my needs, and I didn’t want to think about losing the keyfile, so I chose "repokey-blake2".</p>
<p>To create my first backup, I ran</p>
<div>
<div>
<pre>borg create --exclude "$HOME/.cache" UID@ch-s011.rsync.net:home::backup-1 "$HOME"</pre>
</div>
</div>
<p>which created the archive "backup-1" in my "home" borg repository. I didn’t change the compression algorithm from the default one.</p>
<p>By default borg compresses data with lz4. It can use other compression methods (xz, zlib, zstd). I compared their compression ratios on some binary files I had and found no difference between them. I think this is because the large binary files I have are mostly audio and video files in lossy formats, which don’t seem to benefit very much from further compression. I have a lot of text files as well, but text takes up so little relative space on today’s hardware that it makes no sense to spend CPU cycles on compressing it better than lz4 does.</p>
<p>This backup command hummed along for a good while, and through a couple of reboot cycles. Doing a second backup right after it finished (or the day after) took a lot less time because of the deduplication:</p>
<div>
<div>
<pre>borg create --exclude "$HOME/.cache" UID@ch-s011.rsync.net:home::backup-2 "$HOME"</pre>
</div>
</div>
<p>Restoring from backup is also easy:</p>
<div>
<div>
<pre>borg extract UID@ch-s011.rsync.net:home::backup-2</pre>
</div>
</div>
<p>I set this up to run as a daily timed systemd service at noon (very easy on NixOS, which every Linux user should be using unless they hate themselves), and will never, ever think about this again. For a handful of bucks a year, that is a good deal.</p>

  







  



</article>


      </div>
    </div>
  </div></div>]]>
            </description>
            <link>https://magnusson.io/post/backups/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24526706</guid>
            <pubDate>Sat, 19 Sep 2020 11:32:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stanisław Leśniewski: rethinking the philosophy of mathematics [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24526676">thread link</a>) | @danielam
<br/>
September 19, 2020 | https://biblio.ugent.be/publication/4443772/file/4443780.pdf | <a href="https://web.archive.org/web/*/https://biblio.ugent.be/publication/4443772/file/4443780.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://biblio.ugent.be/publication/4443772/file/4443780.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24526676</guid>
            <pubDate>Sat, 19 Sep 2020 11:27:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Philosophers in an influence graph with PageRank scores]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24526402">thread link</a>) | @jonersRochen
<br/>
September 19, 2020 | https://s4n0i.github.io/schoolofathens/ | <a href="https://web.archive.org/web/*/https://s4n0i.github.io/schoolofathens/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Each node represents a philosopher. Nodes are linked if one philosopher was an influence to the other.
                The size of a node represents the overall influence of a philosopher on the network.</p><p>
                
                Click on a philosopher's node to get more info about them. You can also interact with the graph by dragging nodes, panning and zooming.
            </p></div></div>]]>
            </description>
            <link>https://s4n0i.github.io/schoolofathens/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24526402</guid>
            <pubDate>Sat, 19 Sep 2020 10:19:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I made a scraper that finds the Best Remote Jobs Every Week on the web]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24526323">thread link</a>) | @xoelop
<br/>
September 19, 2020 | https://blog.noicejobs.com/best-remote-jobs-in-the-world-between-sep-11-and-sep-18/ | <a href="https://web.archive.org/web/*/https://blog.noicejobs.com/best-remote-jobs-in-the-world-between-sep-11-and-sep-18/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<section>
<div>
<p>Hey everyone!</p><p>I'm <a href="https://twitter.com/xoelipedes" rel="noopener noreferrer">Xoel</a>, the creator of <a href="https://noicejobs.com/" rel="noopener noreferrer">NoiceJobs.com</a>. On this blog, we'll post the best remote jobs found every week, scraped, aggregated and curated from pretty much all job boards in the Internet.</p><p>For example...</p><ul> <li> 👉 🏝 <a target="blank" href="https://bit.ly/2RxVom5">Senior Software Developer</a> at <b>Jupiter</b>
<br>
<b>$70,000 - $120,000 USD + Equity depending on experience</b>
<br> 🏡 Hiring in EU, Canada, US, Mexico, Central &amp; South America, Rest of Europe  <p>• We're looking for someone to help <strong>build and support new features</strong> as we scale out the product and company. You will be primarily working with <strong>React, React Native, Node.js</strong>, and <strong>GraphQL</strong>.<br>• We're looking for someone who is particularly interested in creating systems within the constraints of a <strong>start-up</strong>.<br>• And finally: we're <strong>bootstrapped</strong>, so far, <strong>building a sustainable business we all want to work at</strong>.</p>
<br> 📨 Wanna get an intro with Rich, CTO at Jupiter? <a href="https://airtable.com/shrzoNF0Lcz50u9oh?prefill_open_for_offers=TRUE%20&amp;prefill_extra_info_reported=I%27m%20interested%20in%20the%20Senior%20Software%20Developer%20position%20at%20Jupiter.%0A%0AThis%20is%20why%20I%20think%20I%27m%20a%20great%20candidate%20for%20this%20position%3A" target="_blank" rel="noopener noreferrer">Join NoiceJobs</a> if you haven't yet or <a href="https://blog.noicejobs.com/cdn-cgi/l/email-protection#4a32252f260a242523292f202528396429252775393f28202f293e7703243e38256f787a2c25386f787a3e222f6f787a192f242325386f787a19252c3e3d2b382f6f787a0e2f3c2f26253a2f386f787a3a2539233e2325246f787a2b3e6f787a003f3a233e2f38" target="_blank" rel="noopener noreferrer">email us</a> if you're a member already.
<br> </li> </ul>
<p> Wanna promote your job on NoiceJobs? <a href="#hiring">Check this out</a> </p><p>This post will make it easier to navigate the blog and all the different categories. Jump to...</p><ul> <li> <a href="#Engineering">🖥 Best Remote Engineering jobs found this week</a> </li> <li> <a href="#Product">🖼 Best Remote Product jobs found this week</a> </li> <li> <a href="#Business">💵 Best Remote Business jobs found this week</a> </li> <li> <a href="#Other">💼 Best Other Remote jobs found this week</a> </li> </ul>
<p>BTW: now you can also get these jobs every week <a href="#newsletter">via email!</a></p><h2 id="-best-remote-engineering-jobs-found-this-week">🖥 Best Remote Engineering jobs found this week</h2><p><a href="https://blog.noicejobs.com/best-senior-cto-26-tech-lead-remote-jobs-between-sep-11-and-sep-18/">CTO &amp; Tech Lead jobs</a><br><a href="https://blog.noicejobs.com/best-senior-engineering-manager-remote-jobs-between-sep-11-and-sep-18/">Engineering Manager jobs</a><br><a href="https://blog.noicejobs.com/best-senior-fullstack-remote-jobs-between-sep-11-and-sep-18/">Fullstack jobs</a><br><a href="https://blog.noicejobs.com/best-senior-frontend-remote-jobs-between-sep-11-and-sep-18/">Frontend jobs</a><br><a href="https://blog.noicejobs.com/best-senior-backend-remote-jobs-between-sep-11-and-sep-18/">Backend jobs</a><br><a href="https://blog.noicejobs.com/best-senior-sre-26-devops-remote-jobs-between-sep-11-and-sep-18/">SRE &amp; Devops jobs</a><br><a href="https://blog.noicejobs.com/best-senior-infosec-remote-jobs-between-sep-11-and-sep-18/">Infosec jobs</a><br><a href="https://blog.noicejobs.com/best-senior-mobile-remote-jobs-between-sep-11-and-sep-18/">Mobile jobs</a><br><a href="https://blog.noicejobs.com/best-senior-ios-remote-jobs-between-sep-11-and-sep-18/">iOS jobs</a><br><a href="https://blog.noicejobs.com/best-senior-android-remote-jobs-between-sep-11-and-sep-18/">Android jobs</a><br><a href="https://blog.noicejobs.com/best-senior-python-remote-jobs-between-sep-11-and-sep-18/">Python jobs</a><br><a href="https://blog.noicejobs.com/best-senior-javascript-remote-jobs-between-sep-11-and-sep-18/">Javascript jobs</a><br><a href="https://blog.noicejobs.com/best-senior-java-remote-jobs-between-sep-11-and-sep-18/">Java jobs</a><br><a href="https://blog.noicejobs.com/best-senior-rails-ruby-remote-jobs-between-sep-11-and-sep-18-2/">Rails/Ruby jobs</a><br><a href="https://blog.noicejobs.com/best-senior-go-remote-jobs-between-sep-11-and-sep-18/">Go jobs</a><br><a href="https://blog.noicejobs.com/best-senior-rust-remote-jobs-between-sep-11-and-sep-18/">Rust jobs</a><br><a href="https://blog.noicejobs.com/best-senior-php-remote-jobs-between-sep-11-and-sep-18/">PHP jobs</a><br><a href="https://blog.noicejobs.com/best-senior-wordpress-remote-jobs-between-sep-11-and-sep-18/">Wordpress jobs</a><br><a href="https://blog.noicejobs.com/best-senior-qa-remote-jobs-between-sep-11-and-sep-18/">QA jobs</a><br><a href="https://blog.noicejobs.com/best-senior-solutions-architect-remote-jobs-between-sep-11-and-sep-18/">Solutions Architect jobs</a><br><a href="https://blog.noicejobs.com/best-senior-data-science-26-ml-remote-jobs-between-sep-11-and-sep-18-2/">Data Science &amp; ML jobs</a><br><a href="https://blog.noicejobs.com/best-senior-nlp-26-nlg-remote-jobs-between-sep-11-and-sep-18-2/">NLP &amp; NLG jobs</a><br><a href="https://blog.noicejobs.com/best-senior-data-engineering-26-big-data-remote-jobs-between-sep-11-and-sep-18-2/">Data Engineering &amp; Big Data jobs</a><br><a href="https://blog.noicejobs.com/best-senior-shopify-remote-jobs-between-sep-11-and-sep-18/">Shopify jobs</a><br><a href="https://blog.noicejobs.com/best-senior-gis-remote-jobs-between-sep-11-and-sep-18/">GIS jobs</a><br><a href="https://blog.noicejobs.com/best-senior-react-remote-jobs-between-sep-11-and-sep-18/">React jobs</a><br><a href="https://blog.noicejobs.com/best-senior-vue-remote-jobs-between-sep-11-and-sep-18/">Vue jobs</a><br><a href="https://blog.noicejobs.com/best-devrel-remote-jobs-found-between-sep-02-and-sep-09/">DevRel jobs</a><br><a href="https://blog.noicejobs.com/best-senior-game-dev-26-design-remote-jobs-between-sep-11-and-sep-18-2/">Game Dev &amp; Design jobs</a><br><a href="https://blog.noicejobs.com/best-senior-haskell-remote-jobs-between-sep-11-and-sep-18/">Haskell jobs</a><br><a href="https://blog.noicejobs.com/best-senior-scala-remote-jobs-between-sep-11-and-sep-18/">Scala jobs</a><br><a href="https://blog.noicejobs.com/best-generalist-remote-jobs-between-sep-11-and-sep-18/">Generalist jobs</a><br><a href="https://blog.noicejobs.com/best-senior-c-2b-2b-remote-jobs-between-sep-11-and-sep-18-2/">C++ jobs</a><br><a href="https://blog.noicejobs.com/best-senior-net-remote-jobs-between-sep-11-and-sep-18-2/">.NET jobs</a><br></p><h2 id="-best-remote-product-jobs-found-this-week">🖼 Best Remote Product jobs found this week</h2><p><a href="https://blog.noicejobs.com/best-senior-cpo-remote-jobs-between-sep-11-and-sep-18/">CPO jobs</a><br><a href="https://blog.noicejobs.com/best-senior-product-manager-remote-jobs-between-sep-11-and-sep-18/">Product Manager jobs</a><br><a href="https://blog.noicejobs.com/best-senior-ux-26-product-design-remote-jobs-between-sep-11-and-sep-18/">UX &amp; Product Design jobs</a><br><a href="https://blog.noicejobs.com/best-senior-ui-design-remote-jobs-between-sep-11-and-sep-18/">UI Design jobs</a><br><a href="https://blog.noicejobs.com/best-senior-art-26-visual-design-remote-jobs-between-sep-11-and-sep-18/">Art &amp; Visual Design jobs</a><br><a href="https://blog.noicejobs.com/best-senior-copywriting-remote-jobs-between-sep-11-and-sep-18/">Copywriting jobs</a><br><a href="https://blog.noicejobs.com/best-senior-video-editing-remote-jobs-between-sep-11-and-sep-18/">Video Editing jobs</a><br></p><h2 id="-best-remote-business-jobs-found-this-week">💵 Best Remote Business jobs found this week</h2><p><a href="https://blog.noicejobs.com/best-senior-sales-remote-jobs-between-sep-11-and-sep-18/">Sales jobs</a><br><a href="https://blog.noicejobs.com/best-senior-sdr-remote-jobs-between-sep-11-and-sep-18/">SDR jobs</a><br><a href="https://blog.noicejobs.com/best-senior-legal-remote-jobs-between-sep-11-and-sep-18/">Legal jobs</a><br><a href="https://blog.noicejobs.com/best-senior-operations-remote-jobs-between-sep-11-and-sep-18/">Operations jobs</a><br><a href="https://blog.noicejobs.com/best-senior-customer-support-remote-jobs-between-sep-11-and-sep-18/">Customer Support jobs</a><br><a href="https://blog.noicejobs.com/best-senior-seo-2c-sem-remote-jobs-between-sep-11-and-sep-18/">SEO, SEM jobs</a><br><a href="https://blog.noicejobs.com/best-senior-marketing-remote-jobs-between-sep-11-and-sep-18/">Marketing jobs</a><br><a href="https://blog.noicejobs.com/best-senior-growth-remote-jobs-between-sep-11-and-sep-18/">Growth jobs</a><br><a href="https://blog.noicejobs.com/best-senior-agile-scrum-remote-jobs-between-sep-11-and-sep-18-2/">Agile/Scrum jobs</a><br><a href="https://blog.noicejobs.com/best-senior-data-business-analyst-remote-jobs-between-sep-11-and-sep-18-2/">Data/Business Analyst jobs</a><br><a href="https://blog.noicejobs.com/best-senior-finance-26-investing-remote-jobs-between-sep-11-and-sep-18-2/">Finance &amp; Investing jobs</a><br><a href="https://blog.noicejobs.com/best-senior-accounting-26-bookkeping-remote-jobs-between-sep-11-and-sep-18-2/">Accounting &amp; Bookkeping jobs</a><br><a href="https://blog.noicejobs.com/best-senior-ecommerce-remote-jobs-between-sep-11-and-sep-18/">Ecommerce jobs</a><br><a href="https://blog.noicejobs.com/best-senior-social-media-remote-jobs-between-sep-11-and-sep-18/">Social Media jobs</a><br></p><h2 id="-best-other-remote-jobs-found-this-week">💼 Best Other Remote jobs found this week</h2><p><a href="https://blog.noicejobs.com/best-senior-software-contract-26-freelance-remote-jobs-between-sep-11-and-sep-18/">Software Contract &amp; Freelance jobs</a><br><a href="https://blog.noicejobs.com/best-senior-software-part-time-remote-jobs-between-sep-11-and-sep-18/">Software Part-time jobs</a><br><a href="https://blog.noicejobs.com/best-junior-remote-jobs-between-sep-11-and-sep-18/">Junior jobs</a><br></p>
<h2>📩 Get these jobs as weekly newsletters</h2>

<h2 id="hiring"> Are you hiring remotely?
</h2>
<p> 📣 If so, you can now <a href="https://airtable.com/shreWkzRKtq6oQFiK" target="_blank" rel="noopener noreferrer">post a job on NoiceJobs</a> to reach up to thousands of talented remote workers.
</p>
<p> Some numbers on NoiceJobs' audience:
</p>
<ul> <li> More than <b>3000 subscribers</b> on our <a href="https://t.me/noicejobs" target="_blank" rel="noopener noreferrer">Telegram channels</a> </li> <li> <b>Hundreds of people registered</b> on NoiceJobs and get these posts weekly </li> <li> This blog (launched on September 9) had <b><span id="pageviews"></span> page views</b> in the last month (verified by <a href="https://referral.simpleanalytics.com/xoel" target="_blank" rel="noopener noreferrer">Simple Analytics</a>). </li> <li> Our traffic analytics are 100% open. <a href="https://simpleanalytics.com/blog.noicejobs.com" target="_blank" rel="noopener noreferrer">Check them out here 👀</a> and see our pageviews in the graph below </li>
</ul>
<div> <p> A cool graph with our visits would go here, but ad blockers don't like the Simple Analytics embed. Disable yours if you'd like to view it :) </p>
</div>
<h3 id="that-s-it-">That's it!</h3><p>I also share jobs like these in these <a href="https://t.me/NoiceJobs">Telegram channels</a>. More than 3,000 people are subscribed to them.</p><p>Have a good weekend!</p><p>Xoel - <a href="https://twitter.com/xoelipedes" rel="noopener noreferrer">I'm on Twitter too. Say hi!</a></p>
</div>
</section>
</article>
</div>
</div></div>]]>
            </description>
            <link>https://blog.noicejobs.com/best-remote-jobs-in-the-world-between-sep-11-and-sep-18/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24526323</guid>
            <pubDate>Sat, 19 Sep 2020 09:51:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Better Way to Find Clients for Your IT Consulting Business]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24526274">thread link</a>) | @kureikain
<br/>
September 19, 2020 | https://corebrief.com/2020/09/09/a-better-way-to-find-clients-for-your-it-consulting-business/ | <a href="https://web.archive.org/web/*/https://corebrief.com/2020/09/09/a-better-way-to-find-clients-for-your-it-consulting-business/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-197">

    

	<div>

		
<p>As an experienced software engineer or IT professional, you have spent many years building up your expertise and your skill-set. You’ve built many solutions and you have solved many problems for clients of various sizes. You have finally decided to turn your expertise into a proper business and escape the rat race once and for all. </p>



<p>Perhaps you’ve even put a team together and have managed to secure a client or two with some decent projects. Everything is looking promising. </p>



<p>Except you run into a little problem. </p>



<p>You have NO idea how to get more clients. </p>



<p>The B2B sales process for technology products and services is complicated, it requires reaching out to the right people who are in a position to make a decision and navigating a complex sales cycle, and you don’t even know where to begin. In fact, you hate this part You really really do. You’re a technology person after all. You’re brilliant at what you do. Surely you shouldn’t have to engage in low-life scummy sales tactics to find clients. You really hate this part. </p>



<p>But you have a business now, so you try. You send out some cold e-mails. You pitch some people on LinkedIn. You spend some money on social media ads, and it just goes down a drain. And then…. nothing. Zero. You have NO new clients. You’re in a rut. You begin to panic.</p>



<hr>



<p>But there is good news. </p>



<p>Let’s take a step back. Whenever you find yourself in a rut, always take a step back. Take a few deep breaths, calm yourself down for a moment, and try to get more general. Try to look at the big picture. You have to put the problems aside for a moment so you can clear your mind and take a fresh look.</p>



<p>The good news is that there is a clear path to what you want.</p>



<p>In fact, you already have the components in place.</p>



<p>The first step is to realise that your professional career so far has given you a valuable competitive advantage.</p>



<p>You now know certain things and can do certain things that very few people on the planet know or can do. </p>



<p>The second step is to realise there is demand for these special skills and knowledge you possess.</p>



<p>There are business owners, managers, decision makers, leaders who are, right now, in need of what you know and what you can do for them. More importantly, many of them have both the willingness and the ability to compensate you generously if you can help them solve specific challenges they are currently facing, or specific goals they are currently committed to achieving.</p>



<p>The third step is to realise that you already have direct access to most of these people. It’s called LinkedIn (or, more broadly, social media).</p>



<p>As you can see, I was not being wishy-washy when I said the components are already in place. All 3 of the above are indeed already in place.</p>



<p>The path to what you want is through aligning yourself – your internal beliefs, your presentation and the messaging you put out – so you position yourself to be the natural choice for those seeking your expertise.</p>



<p>And yes, you do have to learn to sell. But this doesn’t have to be so intimidating and you certainly don’t have to feel like a low-life doing this. So take another deep breath, and allow yourself to get friendly with sales for a moment. Soon you will be best friends – better than you know. </p>



<p>I’ll give you a blueprint to follow, right here in this post. And in the future I’ll go into many more details, but this here should be more than enough to get you started. You shouldn’t need ANYTHING else, don’t get yourself overwhelmed. It’s actually very simple and even easy. </p>



<p>First I’ll tell you what NOT to do. </p>



<p>Then I’ll give you a few basic steps to follow.</p>



<hr>



<p>First and foremost – DO NOT go hire anyone to do this for you. Trust me on this one. No one can market or sell your product for you before you’ve mastered this process yourself first. You MUST learn to sell your own products and services, there is no way around it. What’s more – no one can do it better than you. You KNOW what you’re good at. You KNOW what you’ve been able to do for other clients before. You KNOW what problems you’ve been able to solve. You’ve SEEN people and businesses struggle and make wrong decisions and regret them and you KNOW how to do this right. You know how to do it better. No one else can communicate this better than you. No one can be more convincing. No one can connect with your future clients better than you. </p>



<p>Second, avoid paid advertising before you’ve learned how to generate high-ticket sales without it. Paid ads are an amplifier. If you’re making zero sales right now, the result of putting lots and lots of money in paid ads will be lots and lots of money multiplied by zero. Don’t waste your time and money doing this. I’ve been there. It ain’t pretty. </p>



<p>Repeat after me: Paid ads and sales people are for scaling only. Once you’ve got your offer and your messaging down to a proven working system, you can then pay for ads and hire sales people to go 10x or 100x bigger. But you are not ready for this. Delay this phase as long as possible. When the time comes, you will know it. </p>



<p>Finally, for the love kittens, please don’t go spamming people left and right with your offer. Don’t send e-mails. Don’t talk to strangers on messenger. Don’t call them on the phone. Don’t ask for appointments. Just don’t, ok? Don’t do it. No one likes that. It won’t get you anywhere. </p>



<p>There IS a better way.</p>



<hr>



<p>So here is what to do.</p>



<p>You can get started today, easily. And you can see results quickly, without spending a fortune on anyone or anything.</p>



<p>Your biggest problem right now is obscurity. No one knows you exist. Simple as that.</p>



<p>To start getting more sales, you have to get out there where relevant people can see you so that A) they know you exist and B) you get an opportunity to speak directly to their current pains and frustrations.</p>



<p>As tacky as it sounds, social media turns out to be useful for this.</p>



<p>I’ve found that LinkedIn can be pretty great for B2B sales – but I’ve also seen people get good results with high-ticket sales on Facebook as well. (Once again, though – DO NOT just go spamming people on LinkedIn! Keep calm and read on.)</p>



<p>There is a structure and sequence to the approach. You have to do things in the right order  and you have to get through some things first, but it’s easy, there’s no big expenses involved, and you can start getting results in weeks or even days if you do this right.</p>



<p>The first steps go like this:</p>



<ol><li>Get as much clarity as you can on who your ideal clients are and what your main offer is. I think you already have a good idea about this, but always worth thinking harder about it and putting it in writing for yourself and your team. Make sure to think about your ideal client as A PERSON, even if we’re talking billion-dollar corporations here. At the end of the day someone has to make a decision and write a check.</li><li>Prime your LinkedIn profile. Make it look professional. Use the tag-line to speak directly to your ideal buyer (this requires some creativity and it’s a bit of a process – don’t be afraid to keep changing it, but once you find something that works, stick with it.) Use the longer “About” section to do more of the same. You have to basically turn that into a mini sales letter. Don’t go into many technical details – always write as if it’s coming out of your ideal client’s head. Think of their situation, their current struggles and challenges, the urgency of the problem, and how you can relieve that. Talk about what they will gain from working with you and the amount of time, effort and money they will save.</li><li>Start adding very targeted connections – on a daily basis. If you wish, you can pay for LinkedIn’s Sales Navigator, but I’ve found that the basic search works good enough for me. Every day run a search for people who may be in a position to make decisions about your offer (or go through your LinkedIn network recommendations) and just send out connection requests to 5 – 10 people each day day (but don’t go crazy and start adding everyone indiscriminately.) You can add a little personalisation note, but I’m not sure it makes much of a difference with most people. Your profile (and especially the tag-line) should be able to speak for itself. There are people who use LinkedIn for networking and they will usually accept your connection request. Then there are people who don’t like connecting with strangers and they will ignore you. Don’t make a big deal out of it, don’t take it personally, just stick to the process and turn it into a habit.</li><li>While you are growing your network, start making more regular posts. You should aim for once a day, on average. You can do more (but not much more) or less (but not much less). In your posts, you can do a number of different things, but the whole point is to imagine you are speaking directly to your ideal clients. Don’t be too sales-y all the time, just speak from your expertise and experience. Talk about their problems and your solution to them. Talk about what you’ve done for other similar clients and the specific benefits they’ve experienced. Talk especially about saving time – that’s a big one. </li><li>Don’t be discouraged if you get little to no interactions with your posts at first! This DOESN’T mean people aren’t reading your content. Many people (especially busy people) will not react to your content, but if it’s relevant they WILL read it. When people do start interacting with your posts, feel free to start conversations with them. Keep the conversation exploratory and see how you can be of service. If you can get them on the phone, even better. Just keep this in mind: your first job is NOT to try to sell them anything. It’s to understand whether or not you’re a good fit for working together and to genuinely give them the advice that’s best for them. If this happens to mean working with you, great – don’t be shy about it either. </li><li>Once every few weeks, make a post with a very direct offer, …</li></ol></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://corebrief.com/2020/09/09/a-better-way-to-find-clients-for-your-it-consulting-business/">https://corebrief.com/2020/09/09/a-better-way-to-find-clients-for-your-it-consulting-business/</a></em></p>]]>
            </description>
            <link>https://corebrief.com/2020/09/09/a-better-way-to-find-clients-for-your-it-consulting-business/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24526274</guid>
            <pubDate>Sat, 19 Sep 2020 09:38:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A New Back End for Cranelift: Instruction Selection]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24526088">thread link</a>) | @pcr910303
<br/>
September 19, 2020 | https://cfallin.org/blog/2020/09/18/cranelift-isel-1/ | <a href="https://web.archive.org/web/*/https://cfallin.org/blog/2020/09/18/cranelift-isel-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>This post is the first in a three-part series about my recent work on
<a href="https://github.com/bytecodealliance/wasmtime/tree/main/cranelift">Cranelift</a>
as part of my day job at Mozilla. In this first post, I will set some context
and describe the instruction selection problem. In particular, I’ll talk about
a revamp to the instruction selector and backend framework in general that
we’ve been working on for the last nine months or so. This work has been
co-developed with my brilliant colleagues Julian Seward and <a href="https://benj.me/">Benjamin
Bouvier</a>, with significant early input from <a href="https://github.com/sunfishcode">Dan
Gohman</a> as well, and help from all of the
wonderful Cranelift hackers.</p>

<h2 id="background-cranelift">Background: Cranelift</h2>

<p>So what is Cranelift? The project is a compiler framework written in
<a href="https://www.rust-lang.org/">Rust</a> that is designed especially (but not
exclusively) for <a href="https://en.wikipedia.org/wiki/Just-in-time_compilation">just-in-time
compilation</a>. It’s a
general-purpose compiler: its most popular use-case is to compile
<a href="https://www.webassembly.org/">WebAssembly</a>, though several other frontends
exist, for example,
<a href="https://github.com/bjorn3/rustc_codegen_cranelift">cg_clif</a>, which adapts the
Rust compiler itself to use Cranelift. Folks at Mozilla and several other
places have been developing the compiler for a few years now.  It is the
default compiler backend for
<a href="https://github.com/bytecodealliance/wasmtime">wasmtime</a>, a runtime for
WebAssembly outside the browser, and is used in production in several other
places as well. We recently flipped the switch to turn on Cranelift-based
WebAssembly support in nightly Firefox on <a href="https://en.wikipedia.org/wiki/AArch64">ARM64
(AArch64)</a> machines, including most
smartphones, and if all goes well, it will eventually go out in a stable
Firefox release. Cranelift is developed under the umbrella of the <a href="https://bytecodealliance.org/">Bytecode
Alliance</a>.</p>

<p>In the past nine months, we have built a new framework in Cranelift for the
“machine backends”, or the parts of the compiler that support particular CPU
instruction sets. We also added a new backend for AArch64, mentioned above, and
filled out features as needed until Cranelift was ready for production use in
Firefox. This blog post sets some context and describes the design process that
went into the backend-framework revamp.</p>

<p>It can be a bit confusing to keep all of the moving parts straight. Here’s a
visual overview of Cranelift’s place among various other components, focusing
on two of the major Rust crates (the Wasm frontend and the codegen backend) and
several of the other programs that make use of Cranelift:</p>

<p><img src="https://cfallin.org/assets/2020-09-10-cranelift-components.svg" alt="Figure: Cranelift and other components"></p>

<h2 id="old-backend-design-instruction-legalizations">Old Backend Design: Instruction Legalizations</h2>

<p>To understand the work that we’ve done recently on Cranelift, we’ll need to
zoom into the <code>cranelift_codegen</code> crate above and talk about how it <em>used to</em>
work. What is this “CLIF” input, and how does the compiler translate it to
machine code that the CPU can execute?</p>

<p>Cranelift makes use of
<a href="https://github.com/bytecodealliance/wasmtime/blob/main/cranelift/docs/ir.md">CLIF</a>,
or the Cranelift IR (Intermediate Representation) Format, to represent the code
that it is compiling. Every compiler that performs program optimizations uses
some form of an <a href="https://en.wikipedia.org/wiki/Intermediate_representation">Intermediate Representation
(IR)</a>: you can think
of this like a virtual instruction set that can represent all the operations a
program is allowed to do. The IR is typically simpler than real instruction
sets, designed to use a small set of well-defined instructions so that the
compiler can easily reason about what a program means. The IR is also
independent of the CPU architecture that the compiler eventually targets; this
lets much of the compiler (such as the part that generates IR from the input
programming language, and the parts that optimize the IR) be reused whenever
the compiler is adapted to target a new CPU architecture.  CLIF is in <a href="https://en.wikipedia.org/wiki/Static_single_assignment_form">Static
Single Assignment
(SSA)</a> form, and
uses a conventional <a href="https://en.wikipedia.org/wiki/Control-flow_graph">control-flow
graph</a> with basic blocks
(though it previously allowed extended basic blocks, these have been phased
out). Unlike many SSA IRs, it represents φ-nodes with block parameters
rather than explicit φ-instructions.</p>

<p>Within <code>cranelift_codegen</code>, before we revamped the backend design, the program
remained in CLIF throughout compilation and up until the compiler emitted the
final machine code. This might seem to contradict what we just said: how can
the IR be machine-independent, but also be the final form from which we emit
machine code?</p>

<p>The answer is that the old backends were built around the concept of
“legalization” and “encodings”. At a high level, the idea is that every
<em>Cranelift</em> instruction either corresponds to one <em>machine</em> instruction, or can
be replaced by a sequence of other <em>Cranelift</em> instructions. Given such a
mapping, we can refine the CLIF in steps, starting from arbitrary
machine-independent instructions from earlier compiler stages, performing edits
until the CLIF corresponds 1-to-1 with machine code. Let’s visualize this
process:</p>

<p><img src="https://cfallin.org/assets/2020-09-10-cranelift-legalization.svg" alt="Figure: legalization by repeated instruction expansion"></p>

<p>A very simple example of a CLIF instruction that has a direct “encoding” to a
machine instruction is <code>iadd</code>, which just adds two integers. On essentially any
modern architecture, this should map to a simple ALU instruction that adds two
registers.</p>

<p>On the other hand, many CLIF instructions do not map cleanly. Some arithmetic
instructions fall into this category: for example, there is a CLIF instruction
to count the number of set bits in an integer’s binary representation
(<code>popcount</code>); not every CPU has a single instruction for this, so it might be
expanded into a longer series of bit manipulations. There are operations that
are defined at a higher semantic level, as well, that will necessarily be
lowered with expansions: for example, accesses to Wasm memories are lowered
into operations that fetch the linear memory base and its size, bounds-check
the Wasm address against the limit, compute the real address for the Wasm
address, and perform the access.</p>

<p>To compile a function, then, we iterate over the CLIF and find instructions
with no direct machine encodings; for each, we simply expand into the legalized
sequence, and then recursively consider the instructions in that sequence. We
loop until all instructions have machine encodings. At that point, we can emit
the bytes corresponding to each instruction’s encoding<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>.</p>

<h2 id="growing-pains-and-a-new-backend-framework">Growing Pains, and a New Backend Framework?</h2>

<p>There are a number of advantages to the legacy Cranelift backend design, which
performs expansion-based legalization with a single IR throughout. As one might
expect, though, there are also a number of drawbacks. Let’s discuss a few of
each.</p>

<h3 id="single-ir-and-legalization-pros">Single IR and Legalization: Pros</h3>

<ol>
  <li>
    <p>By operating on a single IR all the way to machine-code emission, the same
optimizations can be applied at multiple stages. For example, consider a
legalization expansion that turns a high-level “access Wasm memory”
instruction into a sequence of loads, adds and bounds-checks. If many such
sequences occur in one function, we might be able to factor out common
portions (e.g.: computing the base of the Wasm memory).  Thus the
legalization scheme exposes as much code as possible, at as many stages as
possible, to opportunities for optimization. The legacy Cranelift pipeline
in fact works in this way: it runs “pre-opt” and “post-opt” optimization
passes, before and after legalization respectively.</p>
  </li>
  <li>
    <p>If <em>most</em> of the Cranelift instructions become one machine instruction, and
few legalizations are necessary, then this scheme can be very fast: it
becomes simply a single traversal to fill in “encodings”, which were
represented by small indices into a table.</p>
  </li>
</ol>

<h3 id="single-ir-and-legalization-cons">Single IR and Legalization: Cons</h3>

<ol>
  <li>
    <p>Expansion-based legalization may not always result in
optimal code. So far we’ve seen that legalization can convert from CLIF to
machine instructions with one-to-one or one-to-many mappings. However, there
are sometimes also <em>single</em> machine instructions that implement the behavior of
<em>multiple</em> CLIF instructions, i.e. a many-to-one mapping. In order to generate
efficient code, we want to be able to make use of these instructions.</p>

    <p>For example, on x86, an instruction that references memory can compute an
address like <code>base + scale * index</code>, where <code>base</code> and <code>index</code> are registers
and <code>scale</code> is 1, 2, 4, or 8. There is no notion of such an address mode in
CLIF, so we would want to pattern-match the raw <code>iadd</code> (add) and <code>ishl</code>
(shift) or <code>imul</code> (multiply) operations when they occur in the address
computation. Then, we would want to somehow select the encoding on the
<code>load</code> instruction based on the fact that its input is some specific
combination of adds and shifts/multiplies.  This seems to break the
abstraction that the encoding represents only that instruction’s operation.</p>

    <p>In principle, we could implement more general pattern matching for legalization
rules to allow many-to-one mappings. However, this would be a significant
refactor; and as long as we were reconsidering the design in whole, there were
other reasons to avoid patching the problem in this way.</p>
  </li>
  <li>
    <p>There is a conceptual difficulty with the single-IR approach: there is
no static representation of which instructions are expanded into which others
and it is difficult to reason about the correctness and termination properties
of legalization as a whole.</p>

    <p>Specifically, the expansion-based legalization rules must obey a partial
order among instructions: if A expands into a sequence including B, then B
cannot later expand into A. In practice, mappings were mostly one-to-one,
and for those that weren’t, there was a clear domain separation between the
“input” high-level instructions and the “machine-level” instructions.
However, for more complex machines, or more complex matching schemes that
attempt to make better use of the target instruction set, this could become
a real difficulty for the machine-backend author to keep straight.</p>
  </li>
  <li>
    <p>There are efficiency concerns with expansion-based legalization. At
an algorithmic level, we prefer to avoid fixpoint loops (in this case,
“continue expanding until no more expansions exist”) whenever possible. The
runtime is bounded, but the bound is somewhat difficult to reason about,
because it depends on the maximum depth of chained expansions.</p>

    <p>The data structures that enable in-place editing are also much slower than
we would like. Typically, compilers store IR instructions in linked lists to
allow for in-place editing. …</p></li></ol></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cfallin.org/blog/2020/09/18/cranelift-isel-1/">https://cfallin.org/blog/2020/09/18/cranelift-isel-1/</a></em></p>]]>
            </description>
            <link>https://cfallin.org/blog/2020/09/18/cranelift-isel-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24526088</guid>
            <pubDate>Sat, 19 Sep 2020 08:40:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: How attractive is your website? Check using Visual Mind AI]]>
            </title>
            <description>
<![CDATA[
Score 107 | Comments 169 (<a href="https://news.ycombinator.com/item?id=24525995">thread link</a>) | @myraahio
<br/>
September 19, 2020 | https://myraah.io/visualmind | <a href="https://web.archive.org/web/*/https://myraah.io/visualmind">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            <div>
              
              <h4>Visual rank of your website is as important as your SEO rank.</h4>
              <p>Users make lasting judgments about a website’s appeal within a split second.  This first impression is influential enough to later affect their opinions of a site’s usability and trustworthiness.</p>
            </div>
          </div> <!-- col -->
        </div><div>
          <div>
            <div>
              
              <h4>What is Visual Mind ?</h4>
              <p>Visual Mind is an AI engine specifically designed for understanding and scoring visual appearance of a website. Visual Mind has analyzed over a million websites to achieve an accuracy rate of over 97%.</p>
            </div>
          </div> <!-- col -->
        </div><div>
          <div>
            <div>
              
              <h4>What is Visual Mind Score and why it matters ?</h4>
              <p>For too long, aesthetics of a website has been dismissed as a superficial concern. That is a mistake. As latest research demonstrates ( See recommended ref) , the visual appeal of a website is tied up with far weightier issues, such as functionality and trustworthiness.</p>
              <p>Have you “fast-tested” your website? Remember, you have only fifty milliseconds to impress your visitors. Flash your website to people for a very short period of time and then ask for their opinion. That is the opinion that matters.</p>
              <p>Visual Mind score – provides you with a qualitative score about that first impression. It can help you evaluate your website aesthetics and make improvements.</p>
              <p><a href="https://myraah.io/index.php/visualmind">Check Your VM SCORE</a></p>
            </div>
          </div> <!-- col -->
        </div><div>
          <div>
            <div>
				<h4>Want to explore more – we recommend</h4>
              <p>A.  Bauerly, M., and Liu, Y. Effects of Symmetry and Number of Compositional Elements on Interface and Design Aesthetics. Int. Journal of Human-Computer Interaction 3 (2008).</p>
              <p>B. Cyr, D. Modeling Website Design across Cultures: Relationships to Trust, Satisfaction and E-loyalty. Journal of Management Information Systems 24, 4 (2008)</p>
              <p>C. Everard, A., and Galletta, D. How presentation flaws affect perceived site quality, trust, and intention to purchase from an online store. Journal of Management Information Systems 22, 3 (2006)</p>
              <p>D. Geissler, G., Zinkhan, G., and Watson, R. The Influence of Home Page Complexity on Consumer Attention, Attitudes, and Purchase Intent. Journal of Advertising 35, 2 (2006)</p>
              <p>E. Hall, R. H., and Hanna, P. The Impact of Web Page Text-background Colour Combinations on Readability,Retention, Aesthetics and Behavioural Intention. Behaviour &amp; Information Technology 23, 3 (2004)</p>
              <p>G. Lindgaard, G., Fernandes, G., Dudek, C., and Brown, J. Attention Web Designers: You Have 50 Milliseconds to Make a Good First Impression! Behaviour &amp; Information Technology 25, 2 (2006)</p>
              <p>H. Michailidou, E., Harper, S., and Bechhofer, S. Visual Complexity and Aesthetic Perception of Web Pages. Proc. Design of Communication (2008)</p>
              <p>I. Tuch, A. N., Bargas-Avila, J. A., and Opwis, K. Symmetry and Aesthetics in Website Design: It’s a Man’s Business. Computers in Human Behavior 26, 6 (2010)</p>
              
			</div>
          </div> <!-- col -->
        </div></div>]]>
            </description>
            <link>https://myraah.io/visualmind</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525995</guid>
            <pubDate>Sat, 19 Sep 2020 08:13:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CrazyFast Crystal based 88x31 visitor counter img generator brought back to 2020]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24525873">thread link</a>) | @gcds
<br/>
September 19, 2020 | https://www.techprowd.com/evening-project-a-crystal-based-super-fast-visitor-counter/ | <a href="https://web.archive.org/web/*/https://www.techprowd.com/evening-project-a-crystal-based-super-fast-visitor-counter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1502570149819-b2260483d302?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 300w,
                            https://images.unsplash.com/photo-1502570149819-b2260483d302?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 600w,
                            https://images.unsplash.com/photo-1502570149819-b2260483d302?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1000w,
                            https://images.unsplash.com/photo-1502570149819-b2260483d302?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1502570149819-b2260483d302?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="Evening Project: A Crystal based super fast visitor counter">
            </figure>

            <section>
                <div>
                    <p>I have taken this week's holidays with the plan that the Overkill Workbench materials would be delivered today, but in the end, it will be delivered on Sunday, so I have a lot of free time on my hands.</p><p>Yesterday, while talking with some friends, I remembered old good &lt;2008 websites, portals, and how we created them; one of the most prominent features I loved about that period was 88x31, and 120x60 sized Ad's/Counters and other goodies. It was always a fight between website authors fighting for a higher number of page visits and similar metrics. Nowadays, everything is hidden and typical, only seen by webmasters on Google Analytics and similar tools.</p><p>So today's my evening project is <a href="https://crystal-lang.org/">Crystal</a> language-based 88x31 website visitor counter image rendered entirely in <a href="https://crystal-lang.org/">Crystal</a>.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-60.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-60.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-60.png 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/image-60.png 1600w, https://www.techprowd.com/content/images/2020/09/image-60.png 1754w" sizes="(min-width: 720px) 720px"></figure><h2 id="requirements-">Requirements:</h2><ul><li>A single endpoint would return 88x31 sized png with numbers</li><li>Provide two numbers, one unique visitor count, and other total visits.</li><li>Do not depend on external libraries for image generation.</li><li>Use the least amount of resources like memory and disk space. (Maybe one day my blog will be viral, who knows)</li><li>Most important, be as fast as possible!</li></ul><h2 id="architecture-">Architecture:</h2><p>The plan is to run the crystal internal HTTP server without any overhangs and host it on Heroku free plan.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-61.png" alt=""></figure><p>Store user identifiers in Redis for uniqueness measurement and fast lookup (Remember we need speed)</p><figure><img src="https://www.techprowd.com/content/images/2020/09/source.gif" alt=""></figure><p>I found a shard (Crystal libraries are called shards) for image rendering, which can generate a PNG image using raw X, Y pixel information no external libraries used.</p><figure><a href="https://github.com/stumpycr/stumpy_png"><div><p>stumpycr/stumpy_png</p><p>Read/Write PNG images in pure Crystal. Contribute to stumpycr/stumpy_png development by creating an account on GitHub.</p><p><img src="https://github.githubassets.com/favicons/favicon.svg"><span>GitHub</span></p></div><p><img src="https://avatars0.githubusercontent.com/u/27729351?s=400&amp;v=4"></p></a></figure><p>For Redis client, I am going to use this shard:</p><figure><a href="https://github.com/stefanwille/crystal-redis"><div><p>stefanwille/crystal-redis</p><p>Full featured Redis client for Crystal. Contribute to stefanwille/crystal-redis development by creating an account on GitHub.</p><p><img src="https://github.githubassets.com/favicons/favicon.svg"><span>stefanwille</span><span>GitHub</span></p></div><p><img src="https://avatars2.githubusercontent.com/u/331756?s=400&amp;v=4"></p></a></figure><h2 id="step-1-rendering-image">Step 1: Rendering image</h2><p>As I have chosen image size to be 88x31, I need to try to fit two numbers. Total visits - Every load counts and Unique Visitors - Number of unique visitors.</p><p>I have drawn some sample representation I imagine in Photoshop:</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-62.png" alt=""></figure><p>It looks tiny on my 4K monitor, but back in 2005, it looked huge on my 1024x768 monitor.</p><p>One of the problems now that I am not using external libraries is that I have no simple way to render text on the image. That's not a big deal, remembering practices I used for Graphical LCD/OLED on embedded electronic projects. I will create an array of Tuples of 3 uint8 integers of each pixel information in a 7x10 array for each number.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-64.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-64.png 600w, https://www.techprowd.com/content/images/2020/09/image-64.png 800w" sizes="(min-width: 720px) 720px"></figure><p>To make each number in array format, I need to generate 7x10 images of each number. Then using the <a href="https://javl.github.io/image2cpp/">https://javl.github.io/image2cpp/</a> tool, I generated arrays for each character.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=%2520%2520%2520%2520ONE%2520%253D%2520%255B%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x323233%252C%25200x4d4e4e%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x323233%252C%25200x9b9c9c%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x787879%252C%25200x939393%252C%25200xa4a4a4%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%250A%2520%2520%2520%2520%255D%2520%250A%2520%2520%2520%2520%250A%2520%2520%2520%2520ZERO%2520%253D%2520%255B%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x59595a%252C%25200x6e6f6f%252C%25200x646465%252C%25200x212222%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x787879%252C%25200xa4a4a4%252C%25200x6e6f6f%252C%25200x939393%252C%25200x9b9c9c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200xb3b3b3%252C%25200x323233%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200xa4a4a4%252C%25200x4d4e4e%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x4d4e4e%252C%25200x9b9c9c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x787879%252C%25200x6e6f6f%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x4d4e4e%252C%25200x939393%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x4d4e4e%252C%25200x939393%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x404141%252C%25200xa4a4a4%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x787879%252C%25200x6e6f6f%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200xababab%252C%25200x4d4e4e%252C%25200x0a0b0c%252C%25200x212222%252C%25200xababab%252C%25200x404141%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x646465%252C%25200xb3b3b3%252C%25200x939393%252C%25200xababab%252C%25200x828282%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x212222%252C%25200x4d4e4e%252C%25200x323233%252C%25200x0a0b0c%252C%25200x0a0b0c%250A%2520%2520%2520%2520%255D"><img src="https://www.techprowd.com/content/images/2020/09/carbon--19-.png" alt="carbon--19-"></a></p>
<!--kg-card-end: markdown--><p>Now that I have pixel data of each character, I can finally create a whole image.</p><p>Knowing the array's exact size, in our case, it's 7x10; we can loop through the array and fill in all pixels referenced from a given position.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=module%2520VisitorCounter%253A%253ACharacters%250A%2520%2520%2520%2520CHARACTER_WIDTH%2520%253D%25207%250A%2520%2520%2520%2520CHARACTER_HEIGHT%2520%253D%252010%250A%2520%2520%2520%2520%250A%2520%2520%2520%2520TWO%2520%253D%2520%255B%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x59595a%252C%25200x6e6f6f%252C%25200x646465%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x828282%252C%25200x9b9c9c%252C%25200x6e6f6f%252C%25200x939393%252C%25200x9b9c9c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x323233%252C%25200xababab%252C%25200x212222%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200xa4a4a4%252C%25200x4d4e4e%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x323233%252C%25200x646465%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x9b9c9c%252C%25200x404141%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x646465%252C%25200x939393%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x323233%252C%25200x8b8b8b%252C%25200x787879%252C%25200x212222%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x404141%252C%25200x939393%252C%25200x404141%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x9b9c9c%252C%25200x212222%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x4d4e4e%252C%25200xb3b3b3%252C%25200xb3b3b3%252C%25200xb3b3b3%252C%25200xb3b3b3%252C%25200xb3b3b3%252C%25200x4d4e4e%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%250A%2520%2520%2520%2520%255D%250A%2520%2520%2520%2520%250A%2520%2520%2520%2520ONE%2520%253D%2520%255B%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x323233%252C%25200x4d4e4e%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x323233%252C%25200x9b9c9c%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x787879%252C%25200x939393%252C%25200xa4a4a4%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%250A%2520%2520%2520%2520%255D%2520%250A%2520%2520%2520%2520%250A%2520%2520%2520%2520ZERO%2520%253D%2520%255B%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x59595a%252C%25200x6e6f6f%252C%25200x646465%252C%25200x212222%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x787879%252C%25200xa4a4a4%252C%25200x6e6f6f%252C%25200x939393%252C%25200x9b9c9c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200xb3b3b3%252C%25200x323233%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200xa4a4a4%252C%25200x4d4e4e%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x4d4e4e%252C%25200x9b9c9c%252C%25200x0a0b0c%252C%2520"><img src="https://www.techprowd.com/content/images/2020/09/carbon--20-.png" alt="carbon--20-"></a></p>
<!--kg-card-end: markdown--><p>After trying out <code>VisitorCounter::Characters.render_character</code> function I was able to see it working correctly.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-65.png" alt=""></figure><p>Now it's time to wrap it all and make the main function, which would generate and return generated image as <code>IO::Memory</code> buffer.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/carbon--21--1.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/carbon--21--1.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/carbon--21--1.png 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/carbon--21--1.png 1600w, https://www.techprowd.com/content/images/2020/09/carbon--21--1.png 2048w" sizes="(min-width: 720px) 720px"></figure><p>To make more usable, I added this image generator to a simple HTTP server and returned random numbers generated in response.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=require%2520%2522stumpy_png%2522%250Ainclude%2520StumpyPNG%250Arequire%2520%2522http%252Fserver%2522%250Arequire%2520%2522.%252Fvisitor_counter%252F*%2522%250A%250Aserver%2520%253D%2520HTTP%253A%253AServer.new%2520do%2520%257Ccontext%257C%250A%2520%2520context.response.content_type%2520%253D%2520%2522image%252Fpng%2522%250A%250A%2520%2520image%2520%253D%2520VisitorCounter%253A%253AImageGenerator.generate(%250A%2520%2520%2520%2520Random.new.rand(1..99999999)%252C%250A%2520%2520%2520%2520Random.new.rand(1..99999999)%252C%250A%2520%2520)%250A%250A%2520%2520context.response.content_length%2520%253D%2520image.size%250A%2520%2520IO.copy(image%252C%2520context.response)%250Aend%250A%250Aaddress%2520%253D%2520server.bind_tcp%25208080%250Aputs%2520%2522Listening%2520on%2520http%253A%252F%252F%2523%257Baddress%257D%2522%250Aserver.listen%250A"><img src="https://www.techprowd.com/content/images/2020/09/carbon--22-.png" alt="carbon--22-"></a></p>
<!--kg-card-end: markdown--><p>After running this code and going to <code>http://127.0.0.1:8080</code> I received generated image with random numbers.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-66.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-66.png 600w, https://www.techprowd.com/content/images/2020/09/image-66.png 612w"></figure><figure><img src="https://www.techprowd.com/content/images/2020/09/image-67.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-67.png 600w, https://www.techprowd.com/content/images/2020/09/image-67.png 612w"></figure><p>Now we can move on to a more exciting part, which is counting visitors.</p><h2 id="step-2-counting-visitors">Step 2: Counting Visitors</h2><p>To count visitors first, we need some kind of unique value. In this project, I am going to use the IP address of the client. As I plan to host this on Heroku, I know that IP will only be IPv4, so I can safely convert the IP address from 127.0.0.1 to its bytes equivalent by merging all 4 x Int8 parts of IP this way it will take less space in Redis memory 4 bytes instead of 15 bytes.</p><p>This is a function which extracts IP address from request. As I mentioned before, this will be hosted on Heroku, so the client IP address will be available in the HTTP header <code>X-Forwarded-For</code> as a load balancer will replace the client IP address with its own.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=private%2520def%2520extract_ip(request)%250A%2520%2520%2520%2520ip%2520%253D%2520request.headers%255B%2522X-Forwarded-For%2522%255D%253F%250A%2520%2520%2520%2520if%2520ip.nil%253F%250A%2520%2520%2520%2520%2520%2520%2520%2520case%2520remote_address%2520%253D%2520request.remote_address%250A%2520%2520%2520%2520%2520%2520%2520%2520when%2520Socket%253A%253AIPAddress%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520ip%2520%253D%2520remote_address.address%250A%2520%2520%2520%2520%2520%2520%2520%2520else%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520ip%2520%253D%2520nil%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520unless%2520ip.nil%253F%250A%2520%2520%2520%2520%2520%2520a%252C%2520b%252C%2520c%252C%2520d%2520%253D%2520ip.split(%27.%27)%250A%250A%2520%2520%2520%2520%2520%2520ip_address%2520%253D%2520Slice(UInt8).new(4)%250A%2520%2520%2520%2520%2520%2520ip_address%255B0%255D%2520%253D%2520a.to_u8%250A%2520%2520%2520%2520%2520%2520ip_address%255B1%255D%2520%253D%2520b.to_u8%250A%2520%2520%2520%2520%2520%2520ip_address%255B2%255D%2520%253D%2520c.to_u8%250A%2520%2520%2520%2520%2520%2520ip_address%255B3%255D%2520%253D%2520d.to_u8%250A%250A%2520%2520%2520%2520%2520%2520return%2520String.new(ip_address)%250A%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520nil%250Aend"><img src="https://www.techprowd.com/content/images/2020/09/carbon--25-.png" alt="carbon--25-"></a></p>
<!--kg-card-end: markdown--><p>If the IP address is not available for some reason, I will skip this visit from a unique visit count and just increase the total visit count.</p><p>Now wrapping everything into <code>WebHandler</code>, which will nicely integrate into HTTP Server, we should have a working counter.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=module%2520VisitorCounter%250A%2520%2520%2520%2520class%2520WebHandler%250A%2520%2520%2520%2520%2520%2520%2520%2520include%2520HTTP%253A%253AHandler%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520UNIQUE_VISITS_OFFSET_KEY%2520%253D%2520%2522UNIQUE_VISITS_OFFSET%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520TOTAL_VISITS_OFFSET_KEY%2520%253D%2520%2522TOTAL_VISITS_OFFSET%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520TOTAL_VISITS_KEY%2520%253D%2520%2522TOTAL_VISITS%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520UNIQUE_VISITS_KEY%2520%253D%2520%2522UNIQUE_VISITS%2522%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520def%2520initialize(redis%2520%253A%2520Redis%253A%253APooledClient)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2540redis%2520%253D%2520redis%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520def%2520call(context)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520context.response.headers%255B%2522Server%2522%255D%2520%253D%2520%2522Techprowd%2520Visitor%2520Counter%2520v1.0%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520unless%2520context.request.method%2520%253D%253D%2520%2522GET%2522%2520%257C%257C%2520context.request.method%2520%253D%253D%2520%2522HEAD%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520context.response.status_code%2520%253D%2520405%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520context.response.headers.add(%2522Allow%2522%252C%2520%2522GET%252C%2520HEAD%2522)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520return%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520if%2520context.request.path.not_nil!%2520!%253D%2520%2522%252F%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520call_next(context)%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520return%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520ip_address%2520%253D%2520extract_ip(context.request)%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520unless%2520ip_address.nil%253F%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520increase_total_visits(ip_address)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520increase_unique_visits(ip_address)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520image%2520%253D%2520ImageGenerator.generate(%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520get_total_visits()%252C%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520get_unique_visits()%252C%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520)%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520context.response.content_type%2520%253D%2520%2522image%252Fpng%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520context.response.content_length%2520%253D%2520image.size%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520IO.copy(image%252C%2520context.response)%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520private%2520def%2520increase_total_visits(ip)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2540redis.incr(TOTAL_VISITS_KEY).to_i%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520private%2520def%2520increase_unique_visits(ip)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520if%2520%2540redis.exists(ip)%2520%253D%253D%25200%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2540redis.set(ip%252C%25201)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2540redis.incr(UNIQUE_VISITS_KEY).to_i%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520end%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520private%2520def%2520get_unique_visits%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520(%2540redis.get(UNIQUE_VISITS_KEY)%2520%257C%257C%2520%25220%2522).to_i%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520private%2520def%2520get_total_visits%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520(%2540redis.get(TOTAL_VISITS_KEY)%2520%257C%257C%2520%25220%2522).to_i%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%2520%2520%2520%2520end%250Aend"><img src="https://www.techprowd.com/content/images/2020/09/carbon--35-.png" alt="carbon--35-"></a></p>
<!--kg-card-end: markdown--><p>The main file code should look like this right now:</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=require%2520%2522stumpy_png%2522%250Arequire%2520%2522http%252Fserver%2522%250Arequire%2520%2522http%252Fserver%252Fhandlers%252F*%2522%250Arequire%2520%2522redis%2522%250A%250Arequire%2520%2522.%252Fvisitor_counter%252F*%2522%250A%250Ainclude%2520StumpyPNG%250A%250Amodule%2520VisitorCounter%250A%2520%2520VERSION%2520%253D%2520%25220.1.0%2522%250A%250A%2520%2520ENV%255B%2522PORT%2522%255D%2520%257C%257C%253D%2520%25228080%2522%250A%2520%2520ENV%255B%2522REDIS_URL%2522%255D%2520%257C%257C%253D%2520%2522redis%253A%252F%252F127.0.0.1%252F%2522%250A%250A%2520%2520redis%2520%253D%2520Redis%253A%253APooledClient.new(url%253A%2520ENV%255B%2522REDIS_URL%2522%255D)%250A%250A%2520%2520server%2520%253D%2520HTTP%253A%253AServer.new(%255B%250A%2520%2520%2520%2520HTTP%253A%253AErrorHandler.new%252C%250A%2520%2520%2520%2520HTTP%253A%253ALogHandler.new%252C%250A%2520%2520%2520%2520HTTP%253A%253ACompressHandler.new%252C%250A%2520%2520%2520%2520VisitorCounter%253A%253AWebHandler.new(redis)%252C%250A%2520%2520%255D)%250A%250A%2520%2520address%2520%253D%2520server.bind_tcp%2520%25220.0.0.0%2522%252CENV%255B%2522PORT%2522%255D.to_i%250A%2520%2520puts%2520%2522Listening%2520on%2520http%253A%252F%252F%2523%257Baddress%257D%2522%250A%2520%2520server.listen%250Aend"><img src="https://www.techprowd.com/content/images/2020/09/carbon--31-.png" alt="carbon--31-"></a></p>
<!--kg-card-end: markdown--><p>Running the main code now we should see the counter working as expected:</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-80.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-80.png 600w, https://www.techprowd.com/content/images/2020/09/image-80.png 801w"></figure><figure><img src="https://www.techprowd.com/content/images/2020/09/image-79.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-79.png 600w, https://www.techprowd.com/content/images/2020/09/image-79.png 612w"></figure><p>Notice the response times of the web request! It's around 1ms per request! That's crazy fast... But wait, it's not built correctly.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-81.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-81.png 600w, https://www.techprowd.com/content/images/2020/09/image-81.png 829w"></figure><p>Now that's what I call FAST!</p><figure><img src="https://www.techprowd.com/content/images/2020/09/source-1.gif" alt=""></figure><p>Just one issue... While running Apache benchmarks, I noticed that the total visit counter is increasing at every request, which is right, but it can be easily abused. We need to rate-limit the total visit counter so that a single IP address can have only one visit per X amount of time.</p><p>Easy, he said! Remember, we are using Redis for our storage, and Redis has a Keys with Expiration feature. Which is precisely what we need.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=private%2520def%2520increase_total_visits(ip)%250A%2520%2520%2520%2520if%2520%2540redis.exists(%2522!%2523%257Bip%257D%2522)%2520%253D%253D%25200%250A%2520%2520%2520%2520%2520%2520%2520%2520%2540redis.incr(TOTAL_VISITS_KEY).to_i%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2540redis.set(%2522!%2523%257Bip%257D%2522%252C%25201%252C%2520RATE_LIMIT_SECONDS)%250A%2520%2520%2520%2520end%250Aend"><img src="https://www.techprowd.com/content/images/2020/09/carbon--37-.png" alt="carbon--37-"></a></p>
<!--kg-card-end: markdown--><p>This way now only increases total visits only when the rate limit timeout will be reached; in this code, it's 5 seconds, but I am going to set something like 1 minute in production.</p><p>Now that we have our application working as we expect. We should deploy our application. I am going to follow the official <a href="https://crystal-lang.org/2016/05/26/heroku-buildpack.html">Crystal guide for Heroku deployment</a>.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-82.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-82.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-82.png 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/image-82.png 1600w, https://www.techprowd.com/content/images/2020/09/image-82.png 1676w" sizes="(min-width: 1200px) 1200px"></figure><p>After easy set up and install now we have an working counter running on heroku.</p><p><a href="https://immense-beyond-23382.herokuapp.com/">https://immense-beyond-23382.herokuapp.com/</a></p><!--kg-card-begin: html--><p><img src="https://immense-beyond-23382.herokuapp.com/"></p><!--kg-card-end: html--><h2 id="conclusion">Conclusion</h2><p>The fully working source code is available on my <a href="https://www.patreon.com/posts/41771991">Patreon account</a> for all pledgers. I will try to add this small counter to this Ghost template as I really loved the idea of this small counter 15 years ago.</p><p>Don't forget to subscribe to the newsletters down bellow. Every new article will be delivered in a friendly email, readable format straight into your mailbox!</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to techprowd</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>
            

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.techprowd.com/evening-project-a-crystal-based-super-fast-visitor-counter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525873</guid>
            <pubDate>Sat, 19 Sep 2020 07:43:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My first 15000 curl commits]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24525665">thread link</a>) | @dosshell
<br/>
September 18, 2020 | https://daniel.haxx.se/blog/2020/09/18/my-first-15000-curl-commits/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/09/18/my-first-15000-curl-commits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>I’ve long maintained that <strong>persistence</strong> is one of the main qualities you need in order to succeed with your (software) project. In order to manage to ship a product that truly conquers the world. By continuously and never-ending keeping at it: polishing away flaws and adding good features. On and on and on.</p>



<p>Today marks the day when I landed my 15,000th commit in the <a href="https://github.com/curl/curl">master branch in curl’s git repository</a> – and we don’t do merge commits so this number doesn’t include such. Funnily enough, <a href="https://github.com/curl/curl/graphs/contributors">GitHub can’t count</a> and shows a marginally lower number.</p>



<figure><img loading="lazy" width="844" height="116" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits.png 844w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits-450x62.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits-200x27.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits-768x106.png 768w" sizes="(max-width: 844px) 100vw, 844px"></figure>



<p>This is of course a totally meaningless number and I’m only mentioning it here because it’s even and an opportunity for me to celebrate something. To cross off an imaginary milestone. This is not even a year since we passed <a href="https://daniel.haxx.se/blog/2019/11/29/curl-25000-commits/" data-type="post" data-id="12859">25,000 total number of commits</a>. Another meaningless number.</p>



<p>15,000 commits equals 57% of all commits done in curl so far and it makes me the only committer in the curl project with over 10% of the commits.</p>



<figure><a href="https://curl.haxx.se/dashboard1.html#daniel-vs-rest"><img loading="lazy" width="1200" height="675" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-1200x675.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-1200x675.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-450x253.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-200x113.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-768x432.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-1536x864.png 1536w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-2048x1152.png 2048w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure>



<p>The curl git history starts on December 29 1999, so the first 19 months of commits from the early curl history are lost. 15,000 commits over this period equals a little less than 2 commits per day on average. I reached 10,000 commits  in December 2011, so the latest 5,000 commits were done at a slower pace than the first 10,000.</p>



<p>I estimate that I’ve spent more than 15,000 hours working on curl over this period, so it would mean that I spend more than one hour of “curl time” per commit on average. According to <a href="https://curl.haxx.se/gitstats/authors.html">gitstats</a>, these 15,000 commits were done on 4,271 different days.</p>



<p>We also have other curl repositories that aren’t included in this commit number. For example, I have done over 4,400 commits in curl’s website repository.</p>



<p>With these my first 15,000 commits I’ve added 627,000 lines and removed 425,000, making an average commit adding 42 and removing 28 lines. (Feels pretty big but I figure the really large ones skew the average.)</p>



<p>The largest time gap ever between two of my commits in the curl tree is almost 35 days back in June 2000. If we limit the check to “modern times”, as in 2010 or later, there was a 19 day gap in July 2015. I <em>do</em> take vacations, but I usually keep up with the most important curl development even during those.</p>



<p>On average it is one commit done by me every 12.1 hours. Every 15.9 hours since 2010. </p>



<p>I’ve been working <a href="https://daniel.haxx.se/blog/2019/02/02/im-on-team-wolfssl/" data-type="post" data-id="11915">full time on curl since early 2019</a>, up until then it was a spare time project only for me. Development with pull-requests and CI and things that verify a lot of the work <em>before</em> merge is a recent thing so one explanation for a slightly higher commit frequency in the past is that we then needed more “oops” commits to rectify mistakes. These days, most of them are done in the PR branches that are squashed when subsequently merged into master. Fewer commits with higher quality.</p>



<h2>curl committers</h2>



<p>We have merged commits authored by over 833 authors into the curl master repository.  Out of these, 537 landed only a single commit (so far).</p>



<figure><a href="https://curl.haxx.se/dashboard1.html#authors"><img loading="lazy" width="1200" height="675" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-1200x675.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-1200x675.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-450x253.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-200x113.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-768x432.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-1536x864.png 1536w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-2048x1152.png 2048w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure>



<p>We are 48 authors who ever wrote 10 or more commits within the same year. 20 of us committed that amount of commits during more than one year.</p>



<figure><a href="https://curl.haxx.se/dashboard1.html#coreteam-per-year"><img loading="lazy" width="1200" height="675" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-1200x675.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-1200x675.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-450x253.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-200x113.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-768x432.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-1536x864.png 1536w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-2048x1152.png 2048w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure>



<p>We are 9 authors who wrote more than 1% of the commits each.</p>



<p>We are 5 authors who ever wrote 10 or more commits within the same year in 10 or more years.</p>



<p>Our second-most committer (by commit count) has not merged a commit for over seven years.</p>



<p>To reach curl’s top-100 committers list right now, you only need to land 6 commits.</p>



<h2>can I keep it up?</h2>



<p>I intend to stick around in the curl project going forward as well. If things just are this great and life remains fine, I hope that I will be maintaining roughly this commit speed for years to come. My prediction is therefore that it will take longer than another twenty years to reach 30,000 commits.</p>



<p>I’ve worked on curl and its precursors for almost <em>twenty-four years</em>. In another twenty-four years I will be well into my retirement years. At some point I will probably not be fit to shoulder this job anymore!</p>



<p>I have never planned long ahead before and I won’t start now. I will instead keep focused on keeping curl top quality, an exemplary open source project and a welcoming environment for newcomers and oldies alike. I will continue to make sure the project is able to function totally independently if I’m present or not.</p>



<h2>The 15,000th commit?</h2>



<p>So what exactly did I change in the project when I merged my 15,000th ever change into the branch?</p>



<p>It was a pretty boring and <a href="https://github.com/curl/curl/commit/559ed3ca2545c56a9acc4e805970434f657bd691">non-spectacular one</a>. I removed a document (<code>RESOURCES</code>) from the docs/ folder as that has been a bit forgotten and now is just completely outdated. There’s a much better page for this provided on the web site: <a href="https://curl.haxx.se/rfc/">https://curl.haxx.se/rfc/</a></p>



<h2>Celebrations!</h2>



<p>I of coursed asked my twitter friends a few days ago on how this occasion is best celebrated:</p>



<figure><a href="https://twitter.com/bagder/status/1302345161272418307"><img loading="lazy" width="825" height="493" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish.png 825w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish-450x269.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish-200x120.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish-768x459.png 768w" sizes="(max-width: 825px) 100vw, 825px"></a></figure>



<p>I showed these results to my wife. She approved.</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/09/18/my-first-15000-curl-commits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525665</guid>
            <pubDate>Sat, 19 Sep 2020 06:43:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Small Computing and the Security Mindset]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24525475">thread link</a>) | @zdw
<br/>
September 18, 2020 | http://www.lord-enki.net/medium-backup/2020-09-18_Small-Computing-and-the-Security-Mindset-821dfb512aa7.html | <a href="https://web.archive.org/web/*/http://www.lord-enki.net/medium-backup/2020-09-18_Small-Computing-and-the-Security-Mindset-821dfb512aa7.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<header>

</header>
<section data-field="subtitle">
The story of modern computing is the story of the big-computing mindset (scale, centralization, elitism, and paternalism) infecting…
</section>
<section data-field="body">
<section name="3648"><div><div><h3 name="8f02" id="8f02">Small Computing and the Security&nbsp;Mindset</h3><p name="3181" id="3181">The story of modern computing is the story of the big-computing mindset (scale, centralization, elitism, and paternalism) infecting everything it touches as programming becomes more of a profession than a craft. In the process, it creates edifices of practices — useful in big-computing situations — that get unthinkingly applied outside of their appropriate bounds, forcing small-computing projects into the strictures of big-computing design. One major domain where we must begin to think critically about the big- vs small-computing distinction is security.</p><p name="46d1" id="46d1">Small-computing systems ought to be secure. After all, they are our most personal environments! They are our diaries and our artworks and our dream journals! But computer security, as it has become professionalized, has become more and more focused on big-computing environments, and good security practices in those environments are inimical to the basic tenets of small computing.</p><p name="369b" id="369b">In a big-computing environment, valuable secrets (like credit card numbers) and desirable powers (like the ability to tweet on behalf of the president) are kept on a set of machines owned by a single entity (the corporation) on behalf of the ostensible owners of that information and power (particular end-users) and protected from illegitimate access (hacking/cracking) by an elite set of professionals (software engineers, ops teams, security consultants) who use their monopoly on legitimate access to certain power (superuser &amp; administrator privileges, commit access) to construct laws (security policies) that prohibit as many not-explicitly-allowed operations as possible. Because the adversaries are many, with infinite time and energy, and because the treasure is valuable, and because laws always have unseen loopholes, these elite professionals construct layers upon layers of rules to limit not only what users (legitimate or illegitimate) can do, but what kind of feedback they can receive.</p><p name="c145" id="c145">This mentality has even made its way into language design: Java (and C++) have a rudimentary form of access control where members can be marked private, and good style in these languages is to mark all member data as private and write accessor functions, ostensibly in order to perform validity checks on proposed modification. This boilerplate is added rather than doing the sensible thing and creating custom metatables such that assignments are implicitly passed through an integrity check (as may be done in Python and Lua). Of course, such checks are rarely implemented, and they cannot distinguish between ‘authorized’ and ‘unauthorized’ calling-classes anyhow — while C++ has ‘friend classes’ that can modify private data directly, and both support using inheritance hierarchies to control data access, there is no granularity smaller than kin/friend versus outsider, so these access controls are borderline useless for everything besides the ad-hoc plugging failures of the type system and increasing the line count of codebases.</p><p name="c4c2" id="c4c2">Systems that require big-computing style security exist. Problems that are best suited to those systems also exist — your bank ought to not only have big-computing style security, but ought to have substantially better security than it has. But, this model is not really sensible in many of the places it is used. For instance, Google Docs (which simulates a word processor with some limited support for simultaneous editing by multiple users) is locked into this model only because it is client-server, and a hypothetical local-first or peer-to-peer version should not be so professionalized and stratified; Microsoft Word, being a local application, has no legitimate excuse (though the real reason, as with most big-computing systems, is that unnecessary centralization is a very effective way to squeeze money out of users who don’t know any better).</p><p name="d95a" id="d95a">When I use Google Docs, I can modify the javascript running on my browser, modify the cookies being sent to the server, and modify URL parameters. If I do something wrong, I will get an entirely unhelpful error message from inside the black box of the remote server. This is because, by failing to fall precisely in line with the Alphabet Corporation’s desired behavior, I have become an adversary, and adversaries cannot be given information that might help them do whatever they might want to do (since some of the things they might want to do is get, for instance, the credit card numbers of everyone who has ever bought an advertisement). Of course, Google engineers writing and maintaining Google Docs face the same situation. Outside of an adversarial situation, investigating a poorly-understood piece of code by poking it and interpreting error messages is called debugging, and part of the small computing ethos is that users should not be prevented from debugging.</p><p name="05d7" id="05d7">The difference between big computing and small computing is, in essence, that in small computing, the user is never an adversary. This is because the running code is owned and controlled by the user. This goes beyond open source / free software (where the developer is no adversary, but the developer is an elite professional often working on behalf of a corporation inside a firewall, performing work that may well be detrimental to those who actually need to interact with its effects).</p><p name="bd41" id="bd41">What kinds of structures befit a small-computing system in an environment where networking exists, and what security models are appropriate for these structures?</p><p name="8df4" id="8df4">For one thing, a multi-user client-server model makes no sense. In a client-server model, whoever controls the single server functionally controls all clients. There is, therefore, incentive to hoard power by locking vital functionalities away on the shared server, making every client dependent — slowed by latency when online, shit out of luck when offline, and always under threat of sudden unilateral changes in policy or protocol.</p><p name="d853" id="d853">Instead, we should look to peer to peer systems: direct for real-time communication, and offline-first store-and-forward schemes for everything else. Asymmetric encryption for key exchange and for signing still make sense here, as does hash-based content addressing for storage. Secure Scuttlebutt and IPFS are good models for what small-computing-oriented network technologies of the future might look like: fully distributed, yet resistant to the kinds of threats that regularly take down federated systems like ActivityPub and IRC, because all nodes are equal and all nodes replicate for each other (under cryptographically-enforced anti-spoofing measures).</p><p name="32c0" id="32c0">What does a threat model for small-computing infrastructure look like?</p><p name="2535" id="2535">Well, unlike in big-computing systems, a small-computing system does not (typically) have large numbers of highly motivated dedicated attackers. Fuzzy Bear isn’t APTing your grandma’s laptop, because your grandma’s laptop has nothing on it but christmas MIDIs and questionable nudes. Our threat is really from folks doing large-scale automated sweeps for low-hanging fruit. So, small-computing threat modeling looks like everyday opsec: use encryption, don’t give strangers direct access to private spaces and limit the spaces they do have access to, distinguish between sensitive and non-sensitive data, and protect the integrity of the system from outsiders. Protect the network-facing portion of your machine, while maximizing your own access to it.</p><p name="aa5a" id="aa5a">In this context, technologies we absolutely do not need are: passwords, SSO, certificate authority hierarchies, name servers and host files, NAT firewalls, code signing, chroot jails, memory layout randomizers, executable symbol stripping, single-application containers, daemons running as ‘nobody’, web APIs for wrapping the web APIs around your web APIs, friend classes, and sudo.</p><p name="9477" id="9477">Technologies we might want to look into: distributed hash tables, chord routing, merkel trees, functional languages, JIT, fast copy-on-write, network-aware cache eviction policies, split-brain countermeasures, transitive blocking, store and forward, message passing, microversioning, journaling, and image-based environments.</p></div></div></section>
</section>
</article></div>]]>
            </description>
            <link>http://www.lord-enki.net/medium-backup/2020-09-18_Small-Computing-and-the-Security-Mindset-821dfb512aa7.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525475</guid>
            <pubDate>Sat, 19 Sep 2020 05:54:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From Vector Spaces to Periodic Functions]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24525383">thread link</a>) | @susam
<br/>
September 18, 2020 | https://susam.in/blog/from-vector-spaces-to-periodic-functions/ | <a href="https://web.archive.org/web/*/https://susam.in/blog/from-vector-spaces-to-periodic-functions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>By <b>Susam Pal</b> on 30 Jan 2019</p>
<h2 id="vector-spaces"><a href="#vector-spaces">Vector Spaces</a></h2>
<p>
A fascinating result that appears in linear algebra is the fact that the
set of real numbers \( \mathbb{R} \) is a vector space over the set of
rational numbers \( \mathbb{Q}. \) This may appear surprising at first
but it is easy to show that it is indeed so by checking that all eight
axioms of vector spaces hold good:
</p>

<ol>
  <li>
    <p>
      Commutativity of vector addition:<br>
      \( x + y = y + x \) for all \( x, y \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Associativity of vector addition:<br>
      \( x + (y + z) = (x + y) + z \) for all \( x, y, z \in \mathbb{R}.
      \)
    </p>
  </li>
  <li>
    <p>
      Existence of additive identity vector:<br>
      We have \( 0 \in \mathbb{R} \) such that \( x + 0 = x \) for all
      \( x \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Existence of additive inverse vectors:<br>
      There exists \( -x \in \mathbb{R} \) for all \( x \in \mathbb{R}.
      \)
    </p>
  </li>
  <li>
    <p>
      Associativity of scalar multiplication:<br>
      \( a(bx) = (ab)x \) for all \( a, b \in \mathbb{Q} \) and for all
      \( x \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Distributivity of scalar multiplication over vector addition:<br>
      \( a(x + y) = ax + by \) for all \( a \in \mathbb{Q} \) and for
      all \( x, y \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Distributivity of scalar multiplication over scalar addition:<br>
      \( (a + b)x = ax + bx \) for all \( a, b \in \mathbb{Q} \) and for
      all \( x \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Existence of scalar multiplicative identity:<br>
      We have \( 1 \in \mathbb{Q} \) such that \( 1 \cdot x = x \) for
      all \( x \in \mathbb{R}. \)
    </p>
  </li>
</ol>
<p>
  This shows that the set of real numbers \( \mathbb{R} \) forms a
  vector space over the field of rational numbers \( \mathbb{Q}. \)
  Another quick way to arrive at this fact is to observe that \(
  \mathbb{Q} \subseteq \mathbb{R}, \) that is, \( \mathbb{Q} \) is a
  subfield of \( \mathbb{R}. \) Any field is a vector space over any of
  its subfields, so \( \mathbb{R} \) must be a vector space over \(
  \mathbb{Q}. \)
</p>


<h2 id="problem"><a href="#problem">Problem</a></h2>

<p>
Here is an interesting problem related to vector spaces that I came
across recently:
</p>

<div>
<p>
Define two periodic functions \( f \) and \( g \) from \( \mathbb{R} \)
to \( \mathbb{R} \) such that their sum \( f + g \) is the identity
function. The axiom of choice is allowed.
</p>
<p>
A function \( f \) is periodic if there exists \( p \gt 0 \) such that
\( f(x + p) = f(x) \) for all \( x \) in the domain.
</p>
</div>

<p>
<em>
If you want to think about this problem, this is a good time to pause
and think about it. There are spoilers ahead.
</em>
</p>


<h2 id="solution"><a href="#solution">Solution</a></h2>

<p>
The axiom of choice is equivalent to the statement that every vector
space has a basis. Since the set of real numbers \( \mathbb{R} \) is a
vector space over the set of rational numbers \( \mathbb{Q}, \) there
must be a basis \( \mathcal{H} \subseteq \mathbb{R} \) such that every
real number \( x \) can be written uniquely as a finite linear
combination of elements of \( \mathcal{H} \) with rational coefficients,
that is,
\[
  x = \sum_{a \in \mathcal{H}} x_a a
\]
where each \( x_a \in \mathbb{Q} \) and \( \{ a \in \mathcal{H} \mid x_a
\ne 0 \} \) is finite. The set \( \mathcal{H} \) is also known as the
Hamel basis.
</p>

<p>
We know that \( b_a = 0 \) for distinct \( a, b \in \mathcal{H} \)
because \( a \) and \( b \) are basis vectors.
</p>

<p>
In the above expansion of \( x, \) each \( x_a \) is a rational number
that appears as the coefficient of the basis vector \( a. \) Therefore
\( (x + y)_{a} = x_a + y_a \) for all \( x, y \in \mathbb{R}. \) Thus \(
(x + b)_{a} = x_a + b_a = x_a + 0 = x_a. \) This shows that a function
\( f(x) = x_a \) is a periodic function with period \( b \) for any \( b
\in \mathcal{H} \setminus \{a\}. \)
</p>

<p>
Let us define two functions:
\begin{align*}
  f(x) &amp; = \sum_{a \in \mathcal{H} \setminus \{ b \}} x_a a,
  &amp;
  g(x) &amp; = x_b b.
\end{align*}
where \( b \in \mathcal{H} \) and \( x \in \mathbb{R}. \) Let us
choose \( c \in \mathcal{H} \) such that \( c \ne b. \) Then \( f(x) \)
is a periodic function with period \( b \) and \( g(x) \) is a periodic
function with period \( c. \) Further,
\[
  f(x) + g(x)
  = \left( \sum_{a \in \mathcal{H} \setminus \{ b \}} x_a a \right) + x_b b
  = \sum_{a \in \mathcal{H}} x_a a
  = x.
\]
Thus \( f(x) \) and \( g(x) \) are two periodic functions such that
their sum is the identity function.
</p>


<h2 id="references"><a href="#references">References</a></h2>
<ul>
  <li>
    <a href="https://mathworld.wolfram.com/VectorSpace.html">Vector
    Space</a> (by Eric W. Weisstein)
  </li>
  <li>
    <a href="https://web.archive.org/web/20141026224511/https://drexel28.wordpress.com/2010/10/22/the-dimension-of-r-over-q/">The
    Dimension of R over Q</a> (by Alex Youcis)
  </li>
  <li>
    <a href="https://mathblag.wordpress.com/2013/09/01/sums-of-periodic-functions/">Sums
  of Periodic Functions</a> (by David Radcliffe)
  </li>
</ul>



</div></div>]]>
            </description>
            <link>https://susam.in/blog/from-vector-spaces-to-periodic-functions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525383</guid>
            <pubDate>Sat, 19 Sep 2020 05:29:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hand-Optimizing VLIW Assembly Language as a Game]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 33 (<a href="https://news.ycombinator.com/item?id=24525372">thread link</a>) | @luu
<br/>
September 18, 2020 | http://silverspaceship.com/hovalaag/ | <a href="https://web.archive.org/web/*/http://silverspaceship.com/hovalaag/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://silverspaceship.com/hovalaag/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525372</guid>
            <pubDate>Sat, 19 Sep 2020 05:27:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Review of Pinephone PostmarketOS CE]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24525210">thread link</a>) | @vidak
<br/>
September 18, 2020 | https://proxy.vulpes.one/gemini/tanelorn.city/~vidak/pinephone/pinephone-review.gemini | <a href="https://web.archive.org/web/*/https://proxy.vulpes.one/gemini/tanelorn.city/~vidak/pinephone/pinephone-review.gemini">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div><p>The version of the Pinephone that I am reviewing is the postmarketOS</p><p>Community Edition (CE).</p><p>My first impression of the Pinephone after I unboxed the device was</p><p>very good. I enjoyed the feeling of the weight of the Pinephone in my</p><p>hand, and the overall build quality of the system still impresses</p><p>me. It is my opinion that the PINE64 hardware development and</p><p>manufacturing process is very solid. For what I paid, which was about</p><p>AUD$200 all up, I believe I have received hardware that is superior</p><p>than a phone that I could have bought from a retail store in my city</p><p>for the same price.</p><p>The screen is glossy, and the capacitive touch screen (this is a</p><p>question fellow smolnet citizen Shufei wanted answered in some detail)</p><p>responds well.</p><p>I was, however, disappointed with the stock postmarketOS software that</p><p>came flashed on the eMMC. The Software Centre was a particular</p><p>disappointment. It, by default, only showed the currently installed</p><p>software, and it was not possible to browse any other software which</p><p>was not already installed.</p><p>Also, the camera application that came installed by default, 'Cheese',</p><p>did not allow the camera to function.</p><p>I attempted to install Plasma Mobile using the command line, following</p><p>these instructions:</p><p>But it ended up completely wrecking the function of the</p><p>phone. Installing the package that the wiki article recommended did</p><p>not update LightDM, and I ended up soft-bricking the phone while</p><p>fiddling with the LightDM configuration in order to stop the phone</p><p>from (still) booting into phosh, and not Plasma Mobile.</p><p>It also disabled cell data functionality, and ended up messing with a</p><p>lot of the guts of the Linux installation. So I do not recommend</p><p>attempting to switch to Plasma Mobile on the Pinephone from inside an</p><p>already-existing postmarketOS installation. I recommend getting a</p><p>Plasma Mobile system image, and flashing that from the start if you</p><p>wish to experiment with different user interfaces.</p><div><p><span> ##</span></p><h2>Linux Software Distributions</h2></div><p>There is a great many Linux distributions available for the</p><p>Pinephone. The following link to the PINE64 wiki contains a</p><p>more-or-less exhaustive list of each of them:</p><p>The Linux distributions that I tested out are:</p><div><p><span>###</span></p><h3>postmarketOS (phosh UI)</h3></div><p>I enjoyed this system image because it came with a wizard for</p><p>NetworkManager which enabled me to make sure cell data worked most</p><p>consistently. However, the power consumption of this image was</p><p>prohibitively high, and it caused the phone to run very hot. When the</p><p>battery was at 10% charge, rebooting the phone would cause the last of</p><p>this precious charge to be used up, and the phone would run completely</p><p>out of power.</p><p>This image was basically a desktop UI, and did not have many, if any</p><p>mobile UI configurations present. It was rather fun to see the</p><p>Pinephone boot into a full GNOME desktop environment. I imagine if you</p><p>had a bigger screen connected to the Pinephone, you would be quite</p><p>impressed with what this phone could pull off.</p><div><p><span>###</span></p><h3>postmarketOS (Plasma Mobile)</h3></div><p>Slow and buggy, really.</p><p>This distribution has a major problem at the moment: the unlock/power</p><p>button is not properly debounced, and it makes it virtually impossible</p><p>sometimes to unlock the phone. Otherwise, this distribution is very,</p><p>very impressive, and I would actually like to switch to it, because</p><p>cell data works best for Optus on Ubuntu Touch.</p><p>This distribution could indeed be a daily driver for someone if they</p><p>could sort out the button debouncing problem.</p><p>This is a Linux-based operating system that uses a closed-source</p><p>UI. It was so glossy and locked-down in terms of configurability that</p><p>I was turned off using it. It has a great tutorial for teaching you</p><p>the gestures you need to learn in order to use the touch screen.</p><p>I did like the fact that it organised all your contacts and messages</p><p>into interesting metaphors, and it ran reasonably quickly, but there</p><p>is no way of configuring the UI beyond what how it arrives to you.</p><p>This image was fairly slow to run on the Pinephone, but in my opinion</p><p>it is the absolute best demonstration of KDE Plasma Mobile. It was</p><p>very visually impressive, and the menus were full-featured and</p><p>informative. It did not, however, support phone calls or SMS.</p><p>This is my current choice of Linux distribution for the phone. It has</p><p>a software centre full of different and interesting programs,</p><p>including Transmission (torrent client) and GIMP (!!! I have yet to</p><p>install this to see how or if it works well, but the fact that it is</p><p>possible to at least _run_ GIMP in some capacity on the Pinephone</p><p>would like like running Adobe Photoshop on a Samsung Galaxy).</p><p>This is merely anecdotal, and I have not performed any scientific</p><p>tests to work out if this is true, but the latest September 2020</p><p>stable release of this image seems to have the best power settings of</p><p>any of the other distributions for this phone.</p><p>I hesitate to give an estimate of exactly how long this phone will</p><p>last on a single charge, given normal use. But, I finished charging</p><p>this phone at 0700HRS this morning, and, with no other charge, it is now</p><p>on 50% charge, and the current time is 1230HRS. I think I have put the</p><p>phone through a little heavier use than I do normally, this morning,</p><p>however.</p><p>Virtually all of the functions of the phone are enabled without any</p><p>configuration in Mobian.</p><p>I highly recommend flashing the following system image to an SD card</p><p>so you can try out all the major Linux distributions for your phone:</p><p>It contains 13 different distributions, and it is trivial to switch</p><p>between each of them through the main boot menu.</p><p>I have rung a few people on the phone, and, assuming you have a</p><p>distribution flashed on the phone that supports phonecalls (like the</p><p>one I am currently using, Mobian), there should be absolutely no issue</p><p>using this fundamental feature of the Pinephone.</p><p>For the most part, the cell data modem in the Pinephone works well for</p><p>me. There is a fairly large problem with my use of the Pinephone with</p><p>its cell data, however.</p><p>I live in Australia, and the mobile phone carrier that I use is</p><p>Optus. The setup(s) that work for me with my Pinephone, running</p><p>Mobian, is:</p><p>&gt; Name: 1</p><p>&gt; APN: yesinternet</p><p>&gt; Name: Optus Yes Internet</p><p>&gt; APN: yesinternet</p><p>After about 3 or 4 hours after I boot up the phone, the cell data</p><p>stops working, and the Network Mode in the 'Mobile' submenu of</p><p>Settings changes from</p><p>&gt; 2G, 3G, 4G (Preferred)</p><p>to just</p><p>&gt; 2G, 3G, 4G</p><p>This issue is fixed for another 3 or 4 hours by rebooting the phone,</p><p>which does not actually take that long (about 10 to 15 seconds), but</p><p>it is a hassle to be cut off from mobile data if you forget about your</p><p>phone.</p><p>These two links help shed light on exactly what is happening with the</p><p>Pinephone when it tries to remain connected to the Optus network:</p><p>(A forum post. Someone using a similar, if not identical mobile data</p><p>modem as the Pinephone in Australia, with the Optus network)</p><p>(A Github post which familiarises the reader with the concepts and</p><p>command line tools involved in using Linux with 4G LTE modems on</p><p>Debian and Ubuntu)</p><p>The issue with the Pinephone is explained the forum thread (the first</p><p>link). The issue is that there are at least two modes for the Quectel</p><p>EG25 modem that the Pinephone uses, only one of which seems to be</p><p>supported by Optus. The two modes are QMI and MBIM. Optus, I assume,</p><p>only supoprts MBIM:</p><p>https://forum.gl-inet.com/t/using-rooter-on-the-gl-x750/8983/8 Forum post</p><p>The relevant sentence from the above forum post is:</p><p>&gt; Also, MBIM is buggy for Quectel modems even in OpenWRT 19.07</p><p>&gt; (snapshot), mostly sometimes modem “freezes” and I need to restart.</p><p>The issue that the original poster was having with this modem is</p><p>explained in the same post:</p><p>&gt; The reason is exactly this: user.notice Create Connection:</p><p>&gt; WDA-GET-DATA-FORMAT is “raw-ip” </p><p>&gt; When you use a modem over QMI and the data-format is “raw-ip” the</p><p>&gt; system needs to know that modem is on “raw-ip”, without that,</p><p>&gt; interface doesn’t get an IP address.</p><p>When I was using the postmarketOS version of phosh, the NetworkManager</p><p>program started a wizard which contained a lot more options about how</p><p>to configure the Pinephone's Quectel LTE modem. One activity I would</p><p>like to carry out is learning how to start this wizard from within</p><p>Mobian. I wish to keep Mobian as the primary operating system for the</p><p>Pinephone just because its Software Centre has such an amazing</p><p>quantity and quality of different programs, and the postmarketOS</p><p>Centre requires you to manually search for the programs you want, in</p><p>order for them to show up at all inside the Centre.</p><p>The GPS seems to function perfectly fine inside the default Mobian</p><p>maps program. It can show you, with reasonable accuracy (although not</p><p>to the same accuracy as, say, a proprietary maps application) exactly</p><p>where you are. I think the accuracy of the GPS on the Pinephone is</p><p>somewhere in the region of 10 square metres.</p><p>The main issue with the GPS, however, is that it does not currently</p><p>link in with the Perth public transport system. I cannot use this</p><p>program to plan public transport journeys. But I believe I should be</p><p>able to take care of this problem by either (a) adding data to</p><p>OpenStreetMap, or (b) using a web browser, where I should be able to</p><p>access the Transperth public transport trip planner webpage.</p><p>This is a feature that works without a hitch in Mobian. I was</p><p>surprised to see myself receiving SMS messages unexpectedly from</p><p>friends as I left the phone in my pocket and forgot about it.</p><p>The camera application in Mobian works. However it has a refresh rate</p><p>of around 1 FPS. The quality is passable. This is not an issue for me</p><p>because, philosophically, phone cameras should not replace the</p><p>function of proper dedicated photographic devices. Will this camera</p><p>take reasonable photos? Yes. What is the comparison of the quality of</p><p>the photos? I would venture a guess that it is about as good as a</p><p>cheap action camera, like a GoPro knock-off.</p><div><p><span> ##</span></p><h2>Flashing Different Operating Systems</h2></div><p>Compared to the arduous process that one has to go through in order to</p><p>change operating systems on an Android phone, the Pinephone is very</p><p>easy to flash. You can flash data onto both an SD card, or the phone's</p><p>internal eMMC.</p><p>For flashing an SD card, the process is as …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://proxy.vulpes.one/gemini/tanelorn.city/~vidak/pinephone/pinephone-review.gemini">https://proxy.vulpes.one/gemini/tanelorn.city/~vidak/pinephone/pinephone-review.gemini</a></em></p>]]>
            </description>
            <link>https://proxy.vulpes.one/gemini/tanelorn.city/~vidak/pinephone/pinephone-review.gemini</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525210</guid>
            <pubDate>Sat, 19 Sep 2020 04:56:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Deep Dive into K-pop]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24525108">thread link</a>) | @eswat
<br/>
September 18, 2020 | https://dormin.org/2020/09/06/a-deep-dive-into-k-pop/ | <a href="https://web.archive.org/web/*/https://dormin.org/2020/09/06/a-deep-dive-into-k-pop/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-719">

	
	<!-- .entry-header -->


			<div>

			<p><img src="https://images-wixmp-ed30a86b8c4ca887773594c2.wixmp.com/f/8dedad4c-ee57-46fd-91a2-32cbb9a652d1/d97l7vh-b56d2b05-419a-4aa2-90c9-1f7a87db1968.jpg/v1/fill/w_1024,h_725,q_75,strp/my_first_kpop_collage_by_rainbowcandleofjoy_d97l7vh-fullview.jpg?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJ1cm46YXBwOjdlMGQxODg5ODIyNjQzNzNhNWYwZDQxNWVhMGQyNmUwIiwiaXNzIjoidXJuOmFwcDo3ZTBkMTg4OTgyMjY0MzczYTVmMGQ0MTVlYTBkMjZlMCIsIm9iaiI6W1t7ImhlaWdodCI6Ijw9NzI1IiwicGF0aCI6IlwvZlwvOGRlZGFkNGMtZWU1Ny00NmZkLTkxYTItMzJjYmI5YTY1MmQxXC9kOTdsN3ZoLWI1NmQyYjA1LTQxOWEtNGFhMi05MGM5LTFmN2E4N2RiMTk2OC5qcGciLCJ3aWR0aCI6Ijw9MTAyNCJ9XV0sImF1ZCI6WyJ1cm46c2VydmljZTppbWFnZS5vcGVyYXRpb25zIl19.Py2kzajyzSvCd5CFWXNFSOW5m_rgR6UJMXllQj3dy18" alt="KPOP Collections: Kpop Groups Collage"></p>
<p>Prior to last month, I knew next to nothing about K-pop (Korean popular music) besides having heard a few songs in passing and the rumors of the industry’s infamous elements, most notably a string of high profile suicides over the last few years. As an American with no connection to music or South Korean culture, I wondered if I was getting an accurate picture of the industry or if I was being misled by the most lurid and morbid elements eagerly conveyed by the media.</p>
<p>So I decided to do a deep dive down the internet rabbit hole of K-pop to understand what it is, how it works, and what I think about it. For anything that’s not my personal opinion or that goes beyond basic historical knowledge, I’ll cite my sources, which are a mixture of news articles, academic articles, YouTube videos, and some content aggregators like Wikipedia and Statista. I welcome any corrections or criticisms on inaccurate sources or things I didn’t understand.</p>
<p>I’ll warn you upfront – this essay is over 30,000 words long. It is the largest post I have made on dormin.org besides my novel. Since I sympathize with anyone who doesn’t want to make such a large time investment into a subject of passing curiosity, I will present my key findings here divided between the five <strong>parts</strong> of the essay. If you’re not sure if you want to read everything, you can jump to any individual part and understand it without reading the other sections.</p>

<h3><a href="#Basics"><strong><u>Part 1</u> – <u>The Basics</u></strong></a></h3>
<ul>
<li>“K-pop” is both a genre of music and an entire industry which “manufacturers” performers and their performance output (music, dance routines, shows, merchandise, etc.) in a highly systematized top-down manner</li>
<li>The global popularity of K-pop is extraordinary considering the relatively small population of South Korea, and the relatively small size of K-pop production companies</li>
</ul>
<h3><a href="#Product"><strong><u>Part 2</u> – <u>The Product</u></strong></a></h3>
<ul>
<li>K-pop’s industrial/corporate structure represents a Korean (and East-Asian) cultural alternative to Western pop and broader music production</li>
<li>K-pop stars and bands are manufactured and controlled by production companies in the same manner Western athletes are trained and traded by sports teams.</li>
<li>K-pop stars are crafted into idealized portrays of individuals by East Asian cultural standards</li>
</ul>
<h3><a href="#Fans"><strong><u>Part 3</u> – <u>The Fans</u></strong></a></h3>
<ul>
<li>K-pop fandom is both more intense on average than Western fandom, and has a larger percentage of unhealthily obsessive fans</li>
<li>K-pop fandom is based on a parasocial relationship between fans and stars</li>
<li>K-pop stars are forced to abide by extremely restrictive behavioral norms to appease production companies and fans</li>
</ul>
<h3><a href="#Process"><strong><u>Part 4</u>– <u>The Process</u></strong></a></h3>
<ul>
<li>Trying to become a K-pop star is a terrible idea by any rational cost-benefit analysis</li>
<li>The process by which production companies train K-pop stars is abusive and depends on the ignorance of children/teenagers and clueless and/or malicious parents</li>
<li>Even after making it through the extraordinarily difficult audition and training process, the vast majority of K-pop stars will have short careers and earn little or possibly <em>no</em> money</li>
</ul>
<h3><a href="#Machine"><strong><u>Part 5</u> – <u>The Machine</u></strong></a></h3>
<ul>
<li>K-pop is an extremely centralized, hierarchical industry, where structural, business, and creative decisions are almost entirely made by corporate management, rather than the performers</li>
<li>Raw creativity in the music production process is largely outsourced to Westerners who write, produce, and choreograph the music</li>
<li>The K-pop industry is subsidized and supported by the South Korean government, if not implicitly or explicitly directed, as a conscious form of soft power projection and social control.</li>
</ul>
<p>As you can tell, I came away from my research with a negative view of K-pop. I don’t think it’s the worst thing in the world, but I find its fandom to be unhealthy and its production process to be exploitative. That being said, there are undoubtedly many tremendous talents in the K-pop world and the cultural power of K-pop is remarkable. I’ll give my summarized thoughts on K-pop as a whole at the conclusion of the essay.<br>
<a name="Basics"></a></p>
<hr>
<p><img src="https://www.rollingstone.com/wp-content/uploads/2018/08/BTS-kpop-takeover-the-world.jpg" alt="How K-Pop Conquered the West - Rolling Stone"></p>
<h2><strong><u>Part 1</u> – <u>The Basics</u></strong></h2>
<h3><strong>What is K-pop?</strong></h3>
<p>“K-pop” refers to a genre of music and the industry which creates it. Both are based out of South Korea and particularly Seoul.</p>
<h3><strong>What is K-pop music?</strong></h3>
<p>K-pop is an offshoot of 90s Western pop with heavy influences from synthetics and hip hop. Lyrics are mostly Korean, but with English words and sometimes other languages thrown in. K-pop is usually sung by mono-gendered bands with members aged from their mid-teens to late 20s. Such bands typically resemble the structure and appearance of American boy bands from the 90s and 2000s (ie. NSYNC). As a representative K-pop sample, check out “DNA” by BTS:</p>
<p><span><iframe width="760" height="428" src="https://www.youtube.com/embed/MBdVXkSdhwU?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>
<p>Properly understood, “K-pop music” is inseparable from “K-pop performance.” The music itself is one component of a larger presentation which includes dance choreography, music videos, fashion, and the personas of bands and individual band members. Though these elements are also present in Western music, they are far more important to K-pop music. K-pop fandom is considered the appreciation of all these aspects as an integrated whole.</p>
<h3><strong>What are the Origins of K-pop?</strong></h3>
<p>The Western influence on Korean music began in the 1940s with the American occupation of much of the Korean peninsula after its liberation from Imperial Japan. With the outbreak of the Korean War in the early 1950s, further American presence was added, with over 300,000 US troops at the peak.<a href="#_edn1" name="_ednref1">[1]</a> After the war, the American military stayed at dozens<a href="#_edn2" name="_ednref2">[2]</a> of bases throughout South Korea as a permanent fixture of the country. Over the decades, these soldiers imported American culture and media, including American music. Presently, there are still 20,000 US soldiers in South Korea.<a href="#_edn3" name="_ednref3">[3]</a></p>
<p>The early Western musical influence in South Korea was based on folk and hippie music in the 60s and 70s, and then evolved into sappy ballads in the 80s. These genres merged with traditional Korean music to form a small, localized music industry. Creative expansion was restrained by the South Korean government’s censorship and restrictions on movement in and out of the country. In the 1970s, the government banned American rock music and Korean offshoots for their connotations with drug use.<a href="#_edn4" name="_ednref4">[4]</a> Until 1983, South Korean citizens were banned from traveling abroad for tourism, and the last restrictions weren’t lifted until 1988 (year of the Seoul Summer Olympics).<a href="#_edn5" name="_ednref5">[5]</a></p>
<p>Korean music had a revolution in the early 1990s with the three-member band, Seo Taiji and the Boys. Founded in 1992, the Boys debuted on a South Korean television talent show and received the lowest ratings of the night.<a href="#_edn6" name="_ednref6">[6]</a> Unexpectedly, their premiere song was a huge hit and launched the band to fame. The Boys soon became the first successful Korean rap group and redefined the Korean music industry. Leader Seo Taiji was a rare experimenter in a country still emerging from isolation and relative cultural stagnancy. Prior to forming the Boys, he had been part of an indie heavy metal band.<a href="#_edn7" name="_ednref7">[7]</a></p>
<p>Through their music, style, and appearance, Seo Taiji and the Boys inadvertently became the first K-Pop band. While their music was more hip hop-based, the Boys pioneered the mixture of Western pop and hip hop presented with intense, highly-choreographed dance routines within a refined aesthetic theme.<a href="#_edn8" name="_ednref8">[8]</a> For a sample, see here:</p>
<p><span><iframe width="760" height="428" src="https://www.youtube.com/embed/IRFfPZQeJuo?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>
<p>Seo Taiji and the Boys disbanded in 1996. But by the end of its short career, mimicking boy bands had sprung up throughout South Korea. These bands were picked up by a new wave of music production companies which would become the basis of the K-pop industry. They looked to Japan and its well established “J-pop” industry as a template for the sustained production of popular musical talent. Thus, while the Boys were independent, experimental, and subversive, the bands created in their wake were more institutionalized, sanitized, and formed by top-down design.</p>
<h3><strong>How Big is K-pop?</strong></h3>
<p>In 2017, the entire K-pop industry produced $5 billion in revenue.<a href="#_edn9" name="_ednref9">[9]</a> For the closest American comparison I can find – in 2019, American <em>record labels</em> earned $8.7 billion in revenue.<a href="#_edn10" name="_ednref10">[10]</a> Unfortunately, I can’t find numbers for total music industry revenue in the US, so this isn’t quite a fair comparison. The two might be difficult to compare due to diverging industry structures;&nbsp; for instance, in South Korea, $1.2 billion of its 2017 revenues came from karaoke sales, only $250 million less than its digital music sales<a href="#_edn11" name="_ednref11">[11]</a></p>
<p>Nevertheless, considering that South Korea has less than 1/6<sup>th</sup> the US population and 1/14<sup>th</sup> the GDP, that’s pretty damn impressive.</p>
<p>Also of note, in 2019, South Korea was the 6<sup>th</sup> largest music market in the world, ahead of China and behind France.<a href="#_edn12" name="_ednref12">[12]</a> In 2017, South Korea exported $513 million worth of music and imported only $14 million worth, which is an extremely strong indicator of the country’s preference for K-pop over Western pop.<a href="#_edn13" name="_ednref13">[13]</a></p>
<p>BTS (AKA Bangtan Boys) is the most popular K-pop band in the world today and ever. According to the 2019 IFPI Global Music Report, BTS was the 7<sup>th</sup> most listened to artist in the world, and had the 3<sup>rd</sup> most popular album globally. Despite Spotify not streaming in South Korea, BTS was its second most popular artist in 2019.<a href="#_edn14" name="_ednref14">[14]</a></p>
<p>Perhaps more relevantly, a 2017 Hyundai Research Institute report claimed that BTS alone was worth $3.6 billion to the South Korean economy annually when accounting for adjacent economic activity and tourism. Supposedly 1/13th of all tourists to South Korea in 2017 came because of BTS.<a href="#_edn15" name="_ednref15">[15]</a> A 2019 report from Hollywood Reporter brought the figure up $4.65 billion.<a href="#_edn16" name="_ednref16">[16]</a></p>
<h3><strong>How Big is K-pop in America?</strong></h3>
<p>I can’t find firm figures, but the general consensus is that K-pop has been blowing up in the US since at least 2017, with articles about the genre’s American explosion popping up in the <em>New York Times</em>,<a href="#_edn17" name="_ednref17">[17]</a> <em>NPR</em>,<a href="#_edn18" name="_ednref18">[18]</a> the <em>Guardian</em>,<a href="#_edn19" name="_ednref19"><em><strong>[19]</strong></em></a> etc. From 2015 to 2019, demand for K-pop concert tickets increased 1,900% in the US.<a href="#_edn20" name="_ednref20">[20]</a> This growth seems to be largely thanks to BTS, which is about 5X more popular than Blackpink, the second most popular …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dormin.org/2020/09/06/a-deep-dive-into-k-pop/">https://dormin.org/2020/09/06/a-deep-dive-into-k-pop/</a></em></p>]]>
            </description>
            <link>https://dormin.org/2020/09/06/a-deep-dive-into-k-pop/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525108</guid>
            <pubDate>Sat, 19 Sep 2020 04:36:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[U.S. bans WeChat, TikTok, citing national security reasons]]>
            </title>
            <description>
<![CDATA[
Score 171 | Comments 183 (<a href="https://news.ycombinator.com/item?id=24524662">thread link</a>) | @empressplay
<br/>
September 18, 2020 | https://www.cbc.ca/news/world/u-s-bans-wechat-tiktok-1.5729249 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/world/u-s-bans-wechat-tiktok-1.5729249">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The U.S. Commerce Department has issued an order that will bar people in the United States from downloading Chinese-owned messaging app WeChat and video-sharing app TikTok, starting Sunday.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5729631.1600444028!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/1263681818.jpg"></p></div><figcaption>U.S. business transactions with the Chinese-owned social apps WeChat and TikTok are to be banned, starting Sunday.<!-- --> <!-- -->(Cindy Ord/Getty Images)</figcaption></figure><p><span><p>The U.S. Commerce Department has issued an order that will bar people in the United States from downloading Chinese-owned messaging app WeChat and video-sharing app TikTok, starting Sunday.</p>  <p>Commerce officials said the ban on new U.S. downloads of TikTok could be still rescinded by President Donald Trump before it takes effect late Sunday as TikTok owner ByteDance races to clinch an agreement over the fate of its U.S. operations.</p>  <p>ByteDance has been in talks with Oracle Corp and others to create a new company, TikTok Global, which&nbsp;aims to address U.S. concerns about the security of its users' data. ByteDance still needs Trump's approval to stave off a U.S. ban.</p>  <p>Commerce officials said they will not bar additional technical transactions for TikTok until Nov. 12, which gives the company additional time to see if ByteDance can reach a deal for its U.S. operations. "The basic TikTok will stay intact until Nov. 12," Commerce Secretary Wilbur Ross told Fox Business Network.</p>  <p>The department said the actions will "protect users in the U.S. by eliminating access to these applications and significantly reducing their functionality."</p>  <p>U.S. Commerce Department officials said they were taking the extraordinary step because of the risks the apps' data collection poses. China and the companies have denied U.S. user data is collected for spying.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/1205295609.jpg 300w,https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/1205295609.jpg 460w,https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/1205295609.jpg 620w,https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1205295609.jpg 780w,https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/1205295609.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1205295609.jpg"></p></div><figcaption>U.S. Secretary of Commerce Wilbur Ross said the ban on Tik Tok and WeChat will combat China's 'malicious collection of American citizens' personal data.'<!-- --> <!-- -->(Saul Loeb/AFP/Getty Images)</figcaption></figure></span></p>  <p>Ross said in a written statement "we have taken significant action to combat China's malicious collection of American citizens' personal data, while promoting our national values, democratic rules-based norms, and aggressive enforcement of U.S. laws and regulations."</p>  <p>"We disagree with the decision from the Commerce Department, and are disappointed that it stands to block new app downloads from Sunday and ban use of the TikTok app in the U.S. from Nov. 12," the company said in a statement. "We will continue to challenge the unjust executive order, which was enacted without due process and threatens to deprive the American people and small businesses across the U.S. of a significant platform for both a voice and livelihoods."</p>  <p>The Commerce Department order will "de-platform" the two apps in the U.S. and bar Apple Inc's app store, Alphabet Inc's Google Play and others from offering the apps on any platform "that can be reached from within the United States," a senior Commerce official told Reuters.</p>  <p>The order will not ban U.S. companies from doing business&nbsp;on WeChat outside the United States, which will be welcome news to U.S. firms like Walmart and Starbucks that use WeChat's embedded "mini-app"&nbsp;programs to facilitate transactions and engage consumers in China, officials said.</p>    <p>The order will not bar transactions with WeChat-owner Tencent Holdings' other businesses, including its online gaming operations, and will not prohibit Apple, Google or others from offering TikTok or WeChat apps anywhere outside the United States.</p>  <p>The bans are in response to a pair of executive orders issued by Trump on Aug.&nbsp;6 that gave the Commerce Department 45 days to determine what transactions to block from the apps he deemed pose a national security threat. That deadline expires on Sunday.</p>  <h2>'Untrusted'&nbsp;Chinese apps</h2>  <p>The Trump administration has ramped up efforts to purge "untrusted" Chinese apps from U.S. digital networks and has called TikTok and WeChat&nbsp;"significant threats."</p>  <p>TikTok has 100 million users in the United States and is especially popular among younger Americans.</p>  <p>WeChat has had an average of 19 million daily active users in the United States, analytics firm&nbsp;Apptopia said in early August. It is popular among Chinese students, ex-pats and some Americans who have personal or business relationships in China.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/1228542119.jpg 300w,https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/1228542119.jpg 460w,https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/1228542119.jpg 620w,https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1228542119.jpg 780w,https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/1228542119.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1228542119.jpg"></p></div><figcaption>People walk past the headquarters of ByteDance, the parent company of TikTok, in Beijing.<!-- --> <!-- -->(Greg Baker/AFP/Getty Images)</figcaption></figure></span></p>  <p>WeChat is an all-in-one mobile app that combines services similar to Facebook, WhatsApp, Instagram and Venmo. The app is an essential part of daily life for many in China and boasts more than 1 billion users.</p>  <p>The Commerce Department will not seek to compel people in the United States to remove the apps or stop using them but will not allow updates or new downloads. "We are aiming at a top corporate level. We're not going to go out after the individual users," one Commerce official said.</p>  <p>Over time, officials said, the lack of updates will degrade the apps' usability.</p>  <p>"The expectation is that people will find alternative ways to do these actions," a senior official said. "We expect the market to act and there will be more secure apps that will fill in these gaps that Americans can trust and that the United States government won't have to take similar actions against."</p>    <p>The Commerce Department is also barring additional technical transactions with WeChat starting Sunday that will significantly reduce the usability and functionality of the app in the United States.</p>  <p>The order bars data hosting within the United States for WeChat, content delivery services and networks that can increase functionality and internet transit or peering services.</p>  <p>"What immediately is going to happen is users are going to experience a lag or lack of functionality," a senior Commerce official said of WeChat users. "It may still be usable but it is not going to be as functional as it was." There may be sporadic outages as well, the official said.</p>  <p>Commerce will bar the same set of technical transactions for TikTok, but that will not take effect until Nov. 12 to give the company additional time to see if ByteDance can reach a deal for its U.S. operations. The official said TikTok U.S. users would not see "a major difference" in the app's performance until Nov. 12.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/1273236956.jpg 300w,https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/1273236956.jpg 460w,https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/1273236956.jpg 620w,https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1273236956.jpg 780w,https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/1273236956.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1273236956.jpg"></p></div><figcaption>U.S. President Donald Trump could still rescind the download ban before it comes into effect Sunday. <!-- --> <!-- -->(Scott Olson/Getty Images)</figcaption></figure></span></p>  <p>Commerce will not penalize people who use TikTok or WeChat in the United States.</p>  <p>The order does not bar data storage within the United States for WeChat or TikTok.</p>  <p>Some Americans may find workarounds. There is nothing that would bar an American from travelling to a foreign country and downloading either app, or potentially using a virtual private network and a desktop client, officials conceded.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/world/u-s-bans-wechat-tiktok-1.5729249</link>
            <guid isPermaLink="false">hacker-news-small-sites-24524662</guid>
            <pubDate>Sat, 19 Sep 2020 03:15:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Monitoring My Home Network]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24524433">thread link</a>) | @mr-karan
<br/>
September 18, 2020 | https://mrkaran.dev/posts/isp-monitoring/ | <a href="https://web.archive.org/web/*/https://mrkaran.dev/posts/isp-monitoring/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				

<p>I like monitoring <em>stuff</em>. That’s what I do at work and when my home ISP started giving me random problems and I decided it would be nice to monitor my home network as well. There are a couple of ways to go around this, a very popular and OSS solution is <a href="https://oss.oetiker.ch/smokeping/">SmokePing</a>. SmokePing is written in Perl and is used to visualise network latencies. It’s quite a great solution but for my current stack which involves Prometheus and Grafana, it meant I had to deploy a standalone tool separate from my monitoring stack - something which I wanted to avoid.</p>

<p><img src="https://oss.oetiker.ch/smokeping/doc/reading_detail.png" alt="SmokePing Graphs"></p>

<p>So, I looked for other solutions and luckily happened to stumble upon <a href="https://twitter.com/oddtazz">oddtazz</a> in one of the common Telegram groups where he shared his solution for the above: Telegraf ICMP <a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/ping">plugin</a> and Grafana. This is exactly what I’ve been looking for but for some reason, I had wrongly assumed Telegraf needs InfluxDB to store the data. Googling a bit more, I found Telegraf <a href="https://github.com/influxdata/telegraf/blob/release-1.15/plugins/outputs/prometheus_client/README.md">supports</a> Prometheus format (amongst a huge list of others!) but this wasn’t so clear in their docs.</p>

<p>I decided to run a Telegraf agent in my RPi connected to my home router over LAN and scrape metrics using Prometheus and visualise graphs in Grafana! For the non-patient readers, here’s what my dashboard looks like!:</p>

<p><img src="https://mrkaran.dev/images/ISP-Monitoring-Grafana2.png" alt="image"></p>

<p><img src="https://mrkaran.dev/images/ISP-Monitoring-Grafana1.png" alt="image"></p>

<h2 id="setup">Setup</h2>

<p>To get started, we need to download <a href="https://github.com/influxdata/telegraf">Telegraf</a> and configure the <a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/ping">Ping</a> plugin. Telegraf has the concept of <strong>Plugins</strong> for Input, Output, Aggregating and Processing. What this basically means is that you can configure multiple input plugins like DNS, ICMP, HTTP and export the data of these plugins in a format of your choice with Output plugins.
This makes Telegraf extermely extensible, you could write a plugin (in Go) of your choice if you fancy that as well!</p>

<p>Here’s what my <code>telegraf.conf</code> looks like:</p>
<div><pre><code data-lang="toml"><span># Input plugins</span>

<span># Ping plugin</span>
[[<span>inputs</span>.<span>ping</span>]]
<span>urls</span> = [<span>"mrkaran.dev"</span>, <span>"tailscale.mrkaran.dev"</span>, <span>"floyd.mrkaran.dev"</span>, <span>"1.1.1.1"</span>, <span>"kite.zerodha.com"</span>, <span>"google.com"</span>, <span>"reddit.com"</span>, <span>"twitter.com"</span>, <span>"amazon.in"</span>, <span>"zerodha.com"</span>]
<span>count</span> = <span>4</span>
<span>ping_interval</span> = <span>1.0</span>
<span>timeout</span> = <span>2.0</span>

<span># DNS plugin</span>
[[<span>inputs</span>.<span>dns_query</span>]]
  <span>servers</span> = [<span>"100.101.134.59"</span>]
  <span>domains</span> = [<span>"mrkaran.dev"</span>, <span>"tailscale.mrkaran.dev"</span>, <span>"floyd.mrkaran.dev"</span>, <span>"1.1.1.1"</span>, <span>"kite.zerodha.com"</span>, <span>"google.com"</span>, <span>"reddit.com"</span>, <span>"twitter.com"</span>, <span>"amazon.in"</span>, <span>"zerodha.com"</span>]

<span># Output format plugins</span>
[[<span>outputs</span>.<span>prometheus_client</span>]]
  <span>listen</span> = <span>":9283"</span>
  <span>metric_version</span> = <span>2</span></code></pre></div>
<p>Firstly, so nice to see an <em>Ops</em> tool <strong>not</strong> using <code>YAML</code>. Kudos to Telegraf for that. I’d love to see other tools follow suit.</p>

<p>Getting back to the configuration part, <code>input.plugin</code> is a list of plugins that can be configured and I have configured the Ping and DNS plugin in my config. The <code>output</code> is in Prometheus format so it can be scraped and ingested by Prometheus’ time-series DB.</p>

<h3 id="running-telegraf">Running Telegraf</h3>

<p>With the above config in place, let’s try running the agent and see what metrics we get. I am using <a href="https://hub.docker.com/_/telegraf/">official</a> Docker image to run the agent with the following config:</p>
<div><pre><code data-lang="sh">docker run --name telegraf-agent --restart always -d -p <span>9283</span>:9283 -v <span>$PWD</span>/telegraf.conf:/etc/telegraf/telegraf.conf:ro telegraf</code></pre></div>
<p>After running the above command, you should be able to see the metrics at <code>localhost:9283/metrics</code></p>
<div><pre><code data-lang="sh">$ curl localhost:9283/metrics | head
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  <span>0</span>     <span>0</span>    <span>0</span>     <span>0</span>    <span>0</span>     <span>0</span>      <span>0</span>      <span>0</span> --:--:-- --:--:-- --:--:--     <span>0</span><span># HELP dns_query_query_time_ms Telegraf collected metric</span>
<span># TYPE dns_query_query_time_ms untyped</span>
dns_query_query_time_ms{<span>dc</span>=<span>"floyd"</span>,domain=<span>"amazon.in"</span>,host=<span>"work"</span>,rack=<span>"work"</span>,rcode=<span>"NOERROR"</span>,record_type=<span>"NS"</span>,result=<span>"success"</span>,server=<span>"100.101.134.59"</span>} <span>124</span>.096472
dns_query_query_time_ms{<span>dc</span>=<span>"floyd"</span>,domain=<span>"google.com"</span>,host=<span>"work"</span>,rack=<span>"work"</span>,rcode=<span>"NOERROR"</span>,record_type=<span>"NS"</span>,result=<span>"success"</span>,server=<span>"100.101.134.59"</span>} <span>136</span>.793673
dns_query_query_time_ms{<span>dc</span>=<span>"floyd"</span>,domain=<span>"kite.zerodha.com"</span>,host=<span>"work"</span>,rack=<span>"work"</span>,rcode=<span>"NOERROR"</span>,record_type=<span>"NS"</span>,result=<span>"success"</span>,server=<span>"100.101.134.59"</span>} <span>122</span>.780946
dns_query_query_time_ms{<span>dc</span>=<span>"floyd"</span>,domain=<span>"mrkaran.dev"</span>,host=<span>"work"</span>,rack=<span>"work"</span>,rcode=<span>"NOERROR"</span>,record_type=<span>"NS"</span>,result=<span>"success"</span>,server=<span>"100.101.134.59"</span>} <span>137</span>.915851
dns_query_query_time_ms{<span>dc</span>=<span>"floyd"</span>,domain=<span>"twitter.com"</span>,host=<span>"work"</span>,rack=<span>"work"</span>,rcode=<span>"NOERROR"</span>,record_type=<span>"NS"</span>,result=<span>"success"</span>,server=<span>"100.101.134.59"</span>} <span>111</span>.097483</code></pre></div>
<p>Perfect! Now, we’re all set to configure Prometheus to scrape the metrics from this target. In order to do that you need to add a new <a href="https://prometheus.io/docs/concepts/jobs_instances/">Job</a>:</p>
<div><pre><code data-lang="yml">- job_name: <span>"ispmonitor"</span>
  scrape_interval: 60s
  static_configs:
    - targets: [<span>"100.94.241.54:9283"</span>] <span># RPi telegraf Agent</span></code></pre></div>
<p>In the above config, I am plugging my Tailscale IP assigned to my RPi on the port where Telegraf agent is bound to. This is one of the <strong>many</strong> reasons why Tailscale is so bloody awesome! I can connect different components in my network to each other without setting up any particular firewall rules, exposing ports on a case by case basis.</p>

<p><strong>Sidenote</strong>: If you haven’t read Tailscale’s <strong>amazing</strong> <a href="https://tailscale.com/blog/how-nat-traversal-works/">NAT Traversal blog post</a>, do yourself a favour and check it out after you finish reading this one ofcourse!</p>

<p>Anyway, coming back to our Prometheus setup, we can see the metrics being ingested:</p>

<p><img src="https://mrkaran.dev/images/Prometheus-Telegraf-Ingest.png" alt="image"></p>

<h2 id="show-me-the-graphs">Show me the graphs</h2>

<p>Now comes the exciting bit – making <strong>pretty</strong> graphs. First, let’s discuss what’s the most important data I can extract out of <code>Ping</code> and <code>DNS</code> plugins. These plugins export decent amount of data, but a good rule of thumb while making dashboards is to optimise signal v/s noise ratio. We’ll do that by filtering out only the metrics that we care for.</p>

<p>Let’s checkout all the metrics exported by <code>Ping</code> plugin:</p>
<div><pre><code data-lang="sh">$ curl localhost:9283/metrics | grep ping | grep TYPE
<span># TYPE ping_average_response_ms untyped</span>
<span># TYPE ping_maximum_response_ms untyped</span>
<span># TYPE ping_minimum_response_ms untyped</span>
<span># TYPE ping_packets_received untyped</span>
<span># TYPE ping_packets_transmitted untyped</span>
<span># TYPE ping_percent_packet_loss untyped</span>
<span># TYPE ping_result_code untyped</span>
<span># TYPE ping_standard_deviation_ms untyped</span>
<span># TYPE ping_ttl untyped</span></code></pre></div>
<p>Perfect! So, from the above list of metrics, the most important ones for us are:</p>

<ul>
<li><code>ping_average_response_ms</code>: Avg RTT for a packet</li>
<li><code>ping_maximum_response_ms</code>: Max RTT for a packet</li>
<li><code>ping_percent_packet_loss</code>: % of packets lost on the way</li>
</ul>

<p>With just the above 3 metrics, we can answer questions like:</p>

<ul>
<li><strong>Is my ISP suffering an outage?</strong></li>
</ul>

<p>If yes, <code>ping_percent_packet_loss</code> should be unusually higher than normal. This usually happens when the ISP has routing is borked and that causes the packet to be routed in a less optimized way and as a side effect packet loss becomes one of the key metrics to measure here.</p>

<ul>
<li><strong>Is the upstream down?</strong></li>
</ul>

<p>If yes, <code>ping_average_response_ms</code> over a recent window should be higher than a window compared to a previous time range when things were fine and dandy. This can either mean 2 things: Either your ISP isn’t routing correctly to the said upstream or the CDN/Region where your upstream is faced an outage. This is quite a handy metric for me to monitor!</p>

<p>How many times have your friends complained “<code>xyz.com</code> isn’t working for me” and when you try to load, it’s fine from your end? There are a lot of actors at play but <code>ping</code> is usually the most simple and quickest way to detect whether an issue persists or not. Of course, this doesn’t work for hosts which block ICMP packets altogether. They are not rare either, like <code>netflix.com</code> and <code>github.com</code> both block ICMP probes for example. For my use case, this wasn’t a major issue as I was able to still probe a decent amount of upstreams all over the world.</p>

<p>With that out of the way, let’s break the dashboard into different components and see what goes behind them.</p>

<h3 id="ping-response-panel">Ping Response Panel</h3>

<p><img src="https://mrkaran.dev/images/ping-row-panel3.png" alt=""></p>

<p>To plot this, simply choose a <code>Stat</code> visualisation with the query <code>ping_average_response_ms{url="$url"}</code>. Repeat this panel for the variable <code>$url</code> and you should be able to generate a nice row view like this.</p>

<p>Additonally you can choose Thresholds and the Unit to be displayed in the panel with these options.</p>

<p><img src="https://mrkaran.dev/images/ping-row-panel1.png" alt="">
<img src="https://mrkaran.dev/images/ping-row-panel2.png" alt=""></p>

<h3 id="ping-response-time-graph">Ping Response Time Graph</h3>

<p>The next graph is interesting, it lets me visualise the avg, min, max ping response time as well as the % packet loss plotted on the Y2 (right Y) axis.</p>

<p><img src="https://mrkaran.dev/images/floyd-ping.png" alt=""></p>

<h3 id="availability-panel">Availability Panel</h3>

<p>An interesting query to calculate uptime (just in the context whether the upstream is reachable) is:</p>
<div><pre>100 - avg_over_time(ping_percent_packet_loss[2m])</pre></div>
<p>Since I scrape metrics at an interval of <code>1m</code>(in order to not ping too frequently and disrupt my actual browsing experience), in this query I am averaging the data points for the metric <code>ping_percent_packet_loss</code> in a <code>[2m]</code> window.</p>

<p><img src="https://mrkaran.dev/images/ping-availability.png" alt=""></p>

<h3 id="dns-response-time-graph">DNS Response Time Graph</h3>

<p>We can similarly query the DNS response time by visualising the average response time for a DNS query. This might be useful only to people self-hosting their DNS servers.</p>

<p><img src="https://mrkaran.dev/images/telegraf-dns.png" alt=""></p>

<h2 id="conclusion">Conclusion</h2>

<p>So with a pretty simple and minimal OSS solution, I was able to setup monitoring for my home network! Over the last few days whenever my ISP had slightest of trouble, I can correlate it with my metrics! I mean I still can’t do anything about it cause the other person on ISP’s customer support is “Did you try rebooting your router”  – the quintessential solution to all tech problems. Wish we could reboot this entire damn 2020 as well, but one could hope!</p>

<p>Shoot me for any questions on my Twitter <a href="https://twitter.com/mrkaran_">@mrkaran_</a> :)</p>

<p>Fin!</p>

			</div></div>]]>
            </description>
            <link>https://mrkaran.dev/posts/isp-monitoring/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24524433</guid>
            <pubDate>Sat, 19 Sep 2020 02:39:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't hate the book because you don't use it]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24524046">thread link</a>) | @pietromenna
<br/>
September 18, 2020 | https://aseure.fr/articles/2020-09-18-dont-hate-the-book-because-you-dont-use-it/ | <a href="https://web.archive.org/web/*/https://aseure.fr/articles/2020-09-18-dont-hate-the-book-because-you-dont-use-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
<h3>
  18 September 2020
</h3>


  <p>In a few months, I’ll celebrate my fifth year as a professional - understand paid - software engineer. I find this role to be a right balance of technical skills, human relationships and it fulfils my curiosity. As time goes by, I’m also starting to be disappointed by some of its negative aspects. While it doesn’t prevent me from sleeping, I think an effort could be made to challenge some lousy and short-sighted comments we see daily on social platforms.</p>
<p>Today, I’d like to talk about <a href="https://www.amazon.com/Design-Patterns-Object-Oriented-Addison-Wesley-Professional-ebook/dp/B000SEIBB8">Design Patterns: Elements of Reusable Object-Oriented Software</a>, a book written by Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides, famously known as the <em>Gang of Four</em>. If you never read it: this is a fundamental programming book describing programming abstractions published in 1994. The date is essential here, but we’ll come to that later.</p>
<p>This book has recently been discussed by many, due to <a href="https://twitter.com/unclebobmartin/status/1306581616983183361">a recent tweet from Robert. C. Martin aka Uncle Bob</a>. Long story short, telling a massive audience that book X is great, and treating people who consider it outdated as “foolish” does not end well.</p>
<p>While I disagree with the tone here, I’d like to focus on the negative comments which followed, including but not limited to:</p>
<ul>
<li>the book is outdated</li>
<li>its concepts are outdated</li>
<li>its authors said it’s outdated</li>
<li>the book is only focused on mid-90s C++ developers</li>
<li>no one ever used the “flyweight” design pattern</li>
<li>the book is not even readable</li>
<li>its abstractions make code unreadable</li>
</ul>
<p>First of all, let’s get back to 1994. I was two at the time. All Internet websites could probably fit on a floppy disk, Jeff Bezos founded Amazon, Rasmus Lerdorf was only starting to work on its <em>Personal Home Page/Forms Interpreter</em> CGI C program, and Larry Page and Sergey Brin would only start their research project for a web search engine two years later. The biggest technology companies were IBM, Hewlett-Packard, Motorola and Xerox, which mostly sat behind the oil, car, and food industries. Programming existed, but it wasn’t the same field as we know it today. Tech companies were a few, and I assume a lot of programmers were working in other industries. Being a professional in this sector was arguably more difficult then, and knowledge was not as easily accessible as it is today. This book was published in a world where programming started to spread in many industries. It surely was a very good resource, to try to apply its concepts, and see what works and what doesn’t. The authors were literally inventing the field at the time: Erich Gamma, for instance, teamed up with Kent Beck to create the Java JUnit test framework just a few years later, which hugely helped to popularise testing.</p>
<p>My point is: let’s remind ourselves we stand on the shoulders of many people who tried and experimented a lot at the time. We too often take for granted the knowledge and productivity we have today. On top of that, let’s not be disrespectful towards the previous generation. My father and my grandfather both work(ed) as electricians: never did my father complain about his father’s tools or habits before him. He learned them and perfected them with modern knowledge.</p>
<p>Now about the book in itself. While I agree with people saying that some design patterns are too abstract, I strongly disagree with the ones saying the whole book is outdated. Should you develop in a OO language today, such as Java, C++, Python or Ruby, or even more notably, develop a framework or a tool <em>for</em> developers, I think this book is still highly relevant today.</p>
<p>Here are my top picks from the book and why I chose them.</p>
<p><strong>Builder:</strong> because in OOP, objects often hold too much data in them, you need to control how to instantiate them properly. Even with overloaded constructors, data validation at instantiation can become messy. Do you like your testing framework using a <em>fluent interface</em> with method chaining (<code>assert(...).not().equalTo(...)</code>)? Guess what, it’s directly inspired by the builder design pattern.</p>
<p><strong>Prototype:</strong> I often hear people complaining about how complicated JavaScript is. While I don’t think this language makes it easy for the developer to write non error-prone code, I better understood the language via the lens of its prototype-based nature, precisely described by the prototype design pattern.</p>
<p><strong>Most of the structural patterns:</strong> While everyone is focused on the bad parts of OOP, namely inheritance, all those design patterns are focused on composability. If you want to be cool nowadays, you could say you prefer “composition over inheritance”. Well, if you think composition is only about embedding objects in each other, you should read the part of structural design patterns. For instance, you probably know decorators from Python or annotations in Java/C#, they derive from the decorator design pattern.</p>
<p><strong>Chain of Responsibility:</strong> I think we can all agree on how great it is to use and implement a middleware in our modern web framework. Just use or write functions which take a <em>next</em> handler, a request object. Pass it to your web framework instance via a <code>.use(...)</code> method and you’re done. This is what the Chain of Responsibility pattern is all about. All Rails, Django, and Laravel developers knew that was NIH.</p>
<p><strong>Iterator:</strong> This one seems obvious now, perhaps not so much at a time where iterating on arrays with pointer arithmetic was common. Today, iterators are even buried behind standard libraries to implement even higher abstract functionalities, but they are still there. I don’t see a more universal way to implement, with the same public API, a traversal of an array, a tree, or a graph (they are better ways of iterating those last data structures though).</p>
<p><strong>Observer:</strong> For this last one, here is the verbatim definition from the book: “Define a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically”. Now, if we take a look at some modern technologies, doesn’t this resonate with PubSub models or React hooks for instance?</p>
<p>To conclude, I’m not saying the book is not old, quite the opposite: you can feel it when it takes as examples from 90s user interfaces. I’m merely advocating that our industry and its workers have changed a lot in the last 30 years, dare I say even more than in any other industry. But this should not be an excuse to sweep away years of meticulous R&amp;D and documentation, on which our modern tools still rely on nowadays, and the people behind it.</p>
<p>Because a lot of people complained that they were never able to finish the book, here is an extract from the end, section “What to Expect from Design Patterns”, page 351:</p>
<blockquote>
<p>It’s possible to argue that this book hasn’t accomplished much. After all, it doesn’t present any algorithms or programming techniques that haven’t been used before. […] it just documents existing designs. You could conclude that it makes a reasonable tutorial, perhaps, but it certainly can’t offer much to an experienced object-oriented designer.</p>
<p>We hope you think differently. Cataloging design patterns is important. It gives us standard names and definitions for the techniques we use. If we don’t study design patterns in software, we won’t be able to improve them, and it’ll be harder to come up with new ones.</p>
<p>This book is only a start.</p>
</blockquote>

</div></div>]]>
            </description>
            <link>https://aseure.fr/articles/2020-09-18-dont-hate-the-book-because-you-dont-use-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24524046</guid>
            <pubDate>Sat, 19 Sep 2020 01:38:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Test Machine Learning Code and Systems]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24523930">thread link</a>) | @7d7n
<br/>
September 18, 2020 | https://eugeneyan.com/writing/testing-ml/ | <a href="https://web.archive.org/web/*/https://eugeneyan.com/writing/testing-ml/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Two weeks ago, <a href="https://twitter.com/jeremyjordan" target="_blank">Jeremy</a> wrote a great post on <a href="https://www.jeremyjordan.me/testing-ml/" target="_blank">Effective Testing for Machine Learning Systems</a>. He distinguished between traditional software tests and machine learning (ML) tests; software tests check the <strong>written logic</strong> while ML tests check the <strong>learned logic</strong>.</p>

<p>ML tests can be further split into <strong>testing</strong> and <strong>evaluation</strong>. We’re familiar with ML <strong>evaluation</strong> where we train a model and evaluate its performance on an unseen validation set; this is done via metrics (e.g., accuracy, <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve" target="_blank">Area under Curve of Receiver Operating Characteristic (AUC ROC)</a>) and visuals (e.g., <a href="https://eugeneyan.com/writing/recommender-systems-baseline-pytorch/#implementation-2-matrix-factorization-with-bias" target="_blank">precision-recall curve</a>).</p>

<p>On the other hand, ML <strong>testing</strong> involves checks on model behaviour. <strong>Pre-train tests</strong>—which can be run without trained parameters—check if our <em>written logic</em> is correct. For example, is classification probability between 0 to 1? <strong>Post-train tests</strong> check if the <em>learned logic</em> is expected. For example, on the <a href="https://www.kaggle.com/c/titanic/data" target="_blank">Titanic dataset</a>, we should expect females to have a higher survival probability (relative to males).</p>

<p><img src="https://eugeneyan.com/assets/testing-ml-flow.jpg" title="Workflow for testing machine learning" alt="Workflow for testing machine learning"></p>
<p>Workflow for testing machine learning (<a href="https://www.jeremyjordan.me/testing-ml/" target="_blank">source</a>)</p>

<p>Taken together, here’s how the workflow might look like. To complement this, we’ll implement a machine learning model and run the following tests on it:</p>
<ul>
  <li><a href="#pre-train-tests-to-ensure-correct-implementation">Pre-train tests to ensure correct implementation</a></li>
  <li><a href="#post-train-tests-to-ensure-expected-learned-behaviour">Post-train tests to ensure expected learned behaviour</a></li>
  <li><a href="#model-evaluation-to-ensure-satisfactory-performance">Evaluation to ensure satisfactory model performance</a></li>
</ul>

<blockquote>
  <p>Follow along with the code in this Github repository: <a href="https://github.com/eugeneyan/testing-ml" target="_blank"><code>testing-ml</code></a></p>
</blockquote>

<h2 id="setting-up-the-context-algorithm-and-data">Setting up the context (algorithm and data)</h2>

<p>Before we can do ML testing, we’ll need an <strong>algorithm and some data</strong>. Our algorithm will be a <a href="https://numpy.org/" target="_blank"><code>numpy</code></a> implementation of <a href="https://github.com/eugeneyan/testing-ml/blob/master/src/tree/decision_tree.py" target="_blank"><code>DecisionTree</code></a> which predicts a probability for binary classification. (<a href="#try-it-for-yourself-and-break-something">Extensions to make it support regression welcome!</a>).</p>

<p>To run our tests, we’ll use the <a href="https://www.kaggle.com/c/titanic/data" target="_blank">Titanic dataset</a>. This tiny data set (~900 rows, 10 features) makes for fast testing (when model training is involved) and allows us to iterate quickly. (As part of performance evaluation, we run <code>fit()</code> and <code>predict()</code> hundreds of times to get the 99th percentile timing.) The simplicity and familiarity of the data also makes it easier to discuss the post-train (i.e., learned logic) tests.</p>

<div><div><pre><code>+ ------------+----------+--------+-----------------------------------------+--------+-----+-------+-------+-----------+---------+-------+----------+
| PassengerId | Survived | Pclass | Name                                    | Sex    | Age | SibSp | Parch | Ticket    |    Fare | Cabin | Embarked |
+ ------------+----------+--------+-----------------------------------------+--------+-----+-------+-------+-----------+---------+-------+----------|
|           1 |        0 |      3 | Braund, Mr. Owen Harris                 | male   |  22 |     1 |     0 | A/5 21171 |    7.25 | nan   | S        |
|           2 |        1 |      1 | Cumings, Mrs. John Bradley (Florence... | female |  38 |     1 |     0 | PC 17599  | 71.2833 | C85   | C        |
|           3 |        1 |      3 | Heikkinen, Miss. Laina                  | female |  26 |     0 |     0 | STON/O2.  |   7.925 | nan   | S        |
|           4 |        1 |      1 | Futrelle, Mrs. Jacques Heath (Lily M... | female |  35 |     1 |     0 | 113803    |    53.1 | C123  | S        |
|           5 |        0 |      3 | Allen, Mr. William Henry                | male   |  35 |     0 |     0 | 373450    |    8.05 | nan   | S        |
|           6 |        0 |      3 | Moran, Mr. James                        | male   | nan |     0 |     0 | 330877    |  8.4583 | nan   | Q        |
|           7 |        0 |      1 | McCarthy, Mr. Timothy J                 | male   |  54 |     0 |     0 | 17463     | 51.8625 | E46   | S        |
|           8 |        0 |      3 | Palsson, Master. Gosta Leonard          | male   |   2 |     3 |     1 | 349909    |  21.075 | nan   | S        |
|           9 |        1 |      3 | Johnson, Mrs. Oscar W (Elisabeth Vil... | female |  27 |     0 |     2 | 347742    | 11.1333 | nan   | S        |
|          10 |        1 |      2 | Nasser, Mrs. Nicholas (Adele Achem)     | female |  14 |     1 |     0 | 237736    | 30.0708 | nan   | C        |
+ ------------+----------+--------+-----------------------------------------+--------+-----+-------+-------+-----------+---------+-------+----------+
</code></pre></div></div>
<p>If you're unfamiliar with the Titanic dataset, here's how it looks like (scroll to the right).</p>

<h2 id="adopting-testing-habits-from-software-engineering">Adopting testing habits from software engineering</h2>

<p>We’ll adopt some good habits from software engineering. We won’t go through them in detail here though it was previously covered in another <a href="https://eugeneyan.com/writing/setting-up-python-project-for-automation-and-collaboration/" target="_blank">post</a>:</p>
<ul>
  <li><a href="https://eugeneyan.com/writing/setting-up-python-project-for-automation-and-collaboration/#write-some-unit-tests-theyre-our-safety-harness" target="_blank">Unit test</a> fixture reuse, exceptions testing, etc with <a href="https://docs.pytest.org/en/latest/" target="_blank"><code>pytest</code></a></li>
  <li><a href="https://eugeneyan.com/writing/setting-up-python-project-for-automation-and-collaboration/#check-for-coverage-how-extensive-are-our-tests" target="_blank">Code coverage</a> with <a href="https://coverage.readthedocs.io/en/coverage-5.2.1/" target="_blank"><code>Coverage.py</code></a> and <a href="https://pytest-cov.readthedocs.io/en/latest/" target="_blank"><code>pytest-cov</code></a></li>
  <li><a href="https://eugeneyan.com/writing/setting-up-python-project-for-automation-and-collaboration/#lint-to-ensure-consistency-across-projects" target="_blank">Linting</a> to ensure code consistency with <a href="https://www.pylint.org/" target="_blank"><code>pylint</code></a></li>
  <li><a href="https://eugeneyan.com/writing/setting-up-python-project-for-automation-and-collaboration/#check-for-type-errors-to-prevent-them" target="_blank">Type checking</a> to verify type correctness with <a href="http://mypy-lang.org/" target="_blank"><code>mypy</code></a></li>
</ul>

<p>(Note: The tests below won’t include type hints though the <a href="https://github.com/eugeneyan/testing-ml/blob/master/src/tree/decision_tree.py#L16" target="_blank">implementation code</a> does.)</p>

<h2 id="pre-train-tests-to-ensure-correct-implementation">Pre-train tests to ensure correct implementation</h2>

<p>In pre-train tests, we want to <strong>catch errors in our implementation</strong> (i.e., written logic) before training an erroneous model. We can run these tests without a fully trained model.</p>

<p>First, we’ll test our functions of <a href="https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity" target="_blank">Gini impurity</a> and <a href="https://en.wikipedia.org/wiki/Decision_tree_learning#Information_gain" target="_blank">Gini gain</a>. These will be used to <a href="https://en.wikipedia.org/wiki/Decision_tree_learning#General" target="_blank">split the data</a> and grow our decision tree.</p>

<div><div><pre><code><span>def</span> <span>test_gini_impurity</span><span>():</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_impurity</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>]),</span> <span>3</span><span>)</span> <span>==</span> <span>0</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_impurity</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.219</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_impurity</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.375</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_impurity</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.469</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_impurity</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.500</span>


<span>def</span> <span>test_gini_gain</span><span>():</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_gain</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[[</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>],</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.5</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_gain</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[[</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>],</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>1</span><span>]]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.125</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_gain</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[[</span><span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>]]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.125</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_gain</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[[</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>]]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.0</span>
</code></pre></div></div>

<p>Next, we’ll check if the model prediction shape is expected. We should have the same number of rows as the input features.</p>

<div><div><pre><code><span>def</span> <span>test_dt_output_shape</span><span>(</span><span>dummy_titanic</span><span>):</span>
    <span>X_train</span><span>,</span> <span>y_train</span><span>,</span> <span>X_test</span><span>,</span> <span>y_test</span> <span>=</span> <span>dummy_titanic</span>
    <span>dt</span> <span>=</span> <span>DecisionTree</span><span>()</span>
    <span>dt</span><span>.</span><span>fit</span><span>(</span><span>X_train</span><span>,</span> <span>y_train</span><span>)</span>
    <span>pred_train</span> <span>=</span> <span>dt</span><span>.</span><span>predict</span><span>(</span><span>X_train</span><span>)</span>
    <span>pred_test</span> <span>=</span> <span>dt</span><span>.</span><span>predict</span><span>(</span><span>X_test</span><span>)</span>

    <span>assert</span> <span>pred_train</span><span>.</span><span>shape</span> <span>==</span> <span>(</span><span>X_train</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>],),</span> <span>'DecisionTree output should be same as training labels.'</span>
    <span>assert</span> <span>pred_test</span><span>.</span><span>shape</span> <span>==</span> <span>(</span><span>X_test</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>],),</span> <span>'DecisionTree output should be same as testing labels.'</span>
</code></pre></div></div>

<p>We’ll also want to check the output ranges. Given that we’re predicting probabilities, we should expect the output to range from 0 to 1 inclusive.</p>

<div><div><pre><code><span>def</span> <span>test_dt_output_range</span><span>(</span><span>dummy_titanic</span><span>):</span>
    <span>X_train</span><span>,</span> <span>y_train</span><span>,</span> <span>X_test</span><span>,</span> <span>y_test</span> <span>=</span> <span>dummy_titanic</span>
    <span>dt</span> <span>=</span> <span>DecisionTree</span><span>()</span>
    <span>dt</span><span>.</span><span>fit</span><span>(</span><span>X_train</span><span>,</span> <span>y_train</span><span>)</span>
    <span>pred_train</span> <span>=</span> <span>dt</span><span>.</span><span>predict</span><span>(</span><span>X_train</span><span>)</span>
    <span>pred_test</span> <span>=</span> <span>dt</span><span>.</span><span>predict</span><span>(</span><span>X_test</span><span>)</span>

    <span>assert</span> <span>(</span><span>pred_train</span> <span>&lt;=</span> <span>1</span><span>).</span><span>all</span><span>()</span> <span>&amp;</span> <span>(</span><span>pred_train</span> <span>&gt;=</span> <span>0</span><span>).</span><span>all</span><span>(),</span> <span>'Decision tree output should range from 0 to 1 inclusive'</span>
    <span>assert</span> <span>(</span><span>pred_test</span> <span>&lt;=</span> <span>1</span><span>).</span><span>all</span><span>()</span> <span>&amp;</span> <span>(</span><span>pred_test</span> <span>&gt;=</span> <span>0</span><span>).</span><span>all</span><span>(),</span> <span>'Decision tree output should range from 0 to 1 inclusive'</span>
</code></pre></div></div>

<p>Here, we’ll check for test set leakage (i.e., duplicate rows in train/test splits) by concatenating train and test data, dropping duplicates, and checking the number of rows. (Note: Other leakages include <a href="https://www.fast.ai/2017/11/13/validation-sets/#time-series" target="_blank">temporal leaks</a> and <a href="https://en.wikipedia.org/wiki/Leakage_(machine_learning)#Feature_leakage" target="_blank">feature leaks</a>; we won’t cover them here.)</p>

<div><div><pre><code><span>def</span> <span>test_data_leak_in_test_data</span><span>(</span><span>dummy_titanic_df</span><span>):</span>
    <span>train</span><span>,</span> <span>test</span> <span>=</span> <span>dummy_titanic_df</span>

    <span>concat_df</span> <span>=</span> <span>pd</span><span>.</span><span>concat</span><span>([</span><span>train</span><span>,</span> <span>test</span><span>])</span>
    <span>concat_df</span><span>.</span><span>drop_duplicates</span><span>(</span><span>inplace</span><span>=</span><span>True</span><span>)</span>

    <span>assert</span> <span>concat_df</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span> <span>==</span> <span>train</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span> <span>+</span> <span>test</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span>
</code></pre></div></div>

<p>Given perfectly separable data and unlimited depth, our decision tree should be able to “memorise” the training data and <em><a href="https://en.wikipedia.org/wiki/Overfitting" target="_blank">overfit</a> completely</em>. In other words, if we train <em>and</em> evaluate on the training data, we should get 100% accuracy. (Note: the Titanic data isn’t perfectly separable so we’ll create a small data sample for this.)</p>

<div><div><pre><code><span>@</span><span>pytest</span><span>.</span><span>fixture</span>
<span>def</span> <span>dummy_feats_and_labels</span><span>():</span>
    <span>feats</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>([[</span><span>0.7057</span><span>,</span> <span>-</span><span>5.4981</span><span>,</span> <span>8.3368</span><span>,</span> <span>-</span><span>2.8715</span><span>],</span>
                      <span>[</span><span>2.4391</span><span>,</span> <span>6.4417</span><span>,</span> <span>-</span><span>0.80743</span><span>,</span> <span>-</span><span>0.69139</span><span>],</span>
                      <span>[</span><span>-</span><span>0.2062</span><span>,</span> <span>9.2207</span><span>,</span> <span>-</span><span>3.7044</span><span>,</span> <span>-</span><span>6.8103</span><span>],</span>
                      <span>[</span><span>4.2586</span><span>,</span> <span>11.2962</span><span>,</span> <span>-</span><span>4.0943</span><span>,</span> <span>-</span><span>4.3457</span><span>],</span>
                      <span>[</span><span>-</span><span>2.343</span><span>,</span> <span>12.9516</span><span>,</span> <span>3.3285</span><span>,</span> <span>-</span><span>5.9426</span><span>],</span>
                      <span>[</span><span>-</span><span>2.0545</span><span>,</span> <span>-</span><span>10.8679</span><span>,</span> <span>9.4926</span><span>,</span> <span>-</span><span>1.4116</span><span>],</span>
                      <span>[</span><span>2.2279</span><span>,</span> <span>4.0951</span><span>,</span> <span>-</span><span>4.8037</span><span>,</span> <span>-</span><span>2.1112</span><span>],</span>
                      <span>[</span><span>-</span><span>6.1632</span><span>,</span> <span>8.7096</span><span>,</span> <span>-</span><span>0.21621</span><span>,</span> <span>-</span><span>3.6345</span><span>],</span>
                      <span>[</span><span>0.52374</span><span>,</span> <span>3.644</span><span>,</span> <span>-</span><span>4.0746</span><span>,</span> <span>-</span><span>1.9909</span><span>],</span>
                      <span>[</span><span>1.5077</span><span>,</span> <span>1.9596</span><span>,</span> <span>-</span><span>3.0584</span><span>,</span> <span>-</span><span>0.12243</span><span>]</span>
                      <span>])</span>
    <span>labels</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>])</span>
    <span>return</span> <span>feats</span><span>,</span> <span>labels</span>

<span>def</span> <span>test_dt_overfit</span><span>(</span><span>dummy_feats_and_labels</span><span>):</span>
    <span>feats</span><span>,</span> <span>labels</span> <span>=</span> <span>dummy_feats_and_labels</span>
    <span>dt</span> <span>=</span> <span>DecisionTree</span><span>()</span>
    <span>dt</span><span>.</span><span>fit</span><span>(</span><span>feats</span><span>,</span> <span>labels</span><span>)</span>
    <span>pred</span> <span>=</span> <span>np</span><span>.</span><span>round</span><span>(</span><span>dt</span><span>.</span><span>predict</span><span>(</span><span>feats</span><span>))</span>

    <span>assert</span> <span>np</span><span>.</span><span>array_equal</span><span>(</span><span>labels</span><span>,</span> <span>pred</span><span>),</span> <span>'DecisionTree should fit data perfectly and prediction should == labels.'</span>
</code></pre></div></div>

<p>Lastly, we check if increasing tree depth leads to increased accuracy and AUC ROC on <em>training</em> data (though it’ll overfit and perform poorly on <em>validation</em> data). In the test below, we fit trees of depth one to 10 and ensure training accuracy and AUC increases consistently.</p>

<div><div><pre><code><span>def</span> <span>test_dt_increase_acc</span><span>(</span><span>dummy_titanic</span><span>):</span>
    <span>X_train</span><span>,</span> <span>y_train</span><span>,</span> <span>_</span><span>,</span> <span>_</span> <span>=</span> <span>dummy_titanic</span>

    <span>acc_list</span> <span>=</span> <span>[]</span>
    <span>auc_list</span> <span>=</span> <span>[]</span>
    <span>for</span> <span>depth</span> <span>in</span> <span>range</span><span>(</span><span>1</span><span>,</span> <span>10</span><span>):</span>
        <span>dt</span> <span>=</span> <span>DecisionTree</span><span>(</span><span>depth_limit</span><span>=</span><span>depth</span><span>)</span>
        <span>dt</span><span>.</span><span>fit</span><span>(</span><span>X_train</span><span>,</span> <span>y_train</span><span>)</span>
        <span>pred</span> <span>=</span> <span>dt</span><span>.</span><span>predict</span><span>(</span><span>X_train</span><span>)</span>
        <span>pred_binary</span> <span>=</span> <span>np</span><span>.</span><span>round</span><span>(</span><span>pred</span><span>)</span>
        <span>acc_list</span><span>.</span><span>append</span><span>(</span><span>accuracy_score</span><span>(</span><span>y_train</span><span>,</span> <span>pred_binary</span><span>))</span>
        <span>auc_list</span><span>.</span><span>append</span><span>(</span><span>roc_auc_score</span><span>(</span><span>y_train</span><span>,</span> <span>pred</span><span>))</span>

    <span>assert</span> <span>sorted</span><span>(</span><span>acc_list</span><span>)</span> <span>==</span> <span>acc_list</span><span>,</span> <span>'Accuracy should increase as tree depth increases.'</span>
    <span>assert</span> <span>sorted</span><span>(</span><span>auc_list</span><span>)</span> <span>==</span> <span>auc_list</span><span>,</span> <span>'AUC ROC should increase as tree depth increases.'</span>
</code></pre></div></div>

<h2 id="post-train-tests-to-ensure-expected-learned-behaviour">Post-train tests to ensure expected learned behaviour</h2>

<p>In post-train tests, we want to <strong>check if the model is behaving …</strong></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://eugeneyan.com/writing/testing-ml/">https://eugeneyan.com/writing/testing-ml/</a></em></p>]]>
            </description>
            <link>https://eugeneyan.com/writing/testing-ml/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24523930</guid>
            <pubDate>Sat, 19 Sep 2020 01:23:15 GMT</pubDate>
        </item>
    </channel>
</rss>
