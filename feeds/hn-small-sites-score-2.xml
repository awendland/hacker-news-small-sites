<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 21 Feb 2021 12:38:42 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 21 Feb 2021 12:38:42 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Where Everything Went Wrong: Error Handling and Error Messages in Rust]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 10 (<a href="https://news.ycombinator.com/item?id=26191006">thread link</a>) | @lukastyrychtr
<br/>
February 19, 2021 | https://msirringhaus.github.io/Where-everything-went-wrong/ | <a href="https://web.archive.org/web/*/https://msirringhaus.github.io/Where-everything-went-wrong/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><strong>Today you are frustrated.</strong></p>

<p>This is so annoying. YouÃ¢â‚¬â„¢ve written a Rust crate and now that you want to test it for the very first time, <em>it doesnÃ¢â‚¬â„¢t work!</em></p>

<p>Come on, Rust! How dare you? You promised that once one gets past the compiler, it.<br>
<em>Just.<br>
<strong>Works!</strong></em><br>
And now this!</p>

<p>Ok, ok. You calm yourself down. Lets start from the beginning. You want to create so called <a href="https://docs.sentry.io/platforms/native/guides/minidumps/">minidumps</a>. This is a file that contains information about a crashed program (like stacks of all threads, CPU registers, system info, etc.).
The minidump consists of various sections, such as the minidump header (including time of day, versions and basically a table of contents), a thread section (including all threads of the process and their stacks), memory mappings and libraries, etc. [Just to give some context, as all of this is actually not really important.]</p>

<p>For this, you created a <a href="https://github.com/msirringhaus/minidump_writer_linux">crate</a>. One section gets written after the other, while information about the targeted process is retrieved from the system. You even created a nice, simple API. You hand in a process ID and an open file, where the minidump should be written to. like this:</p>

<div><div><pre><code>    <span>MinidumpWriter</span><span>::</span><span>new</span><span>(</span><span>pid</span><span>,</span> <span>blamed_thread</span><span>)</span>
        <span>.dump</span><span>(</span><span>&amp;</span><span>mut</span> <span>dump_file</span><span>)</span>
        <span>.expect</span><span>(</span><span>"Dumping failed!"</span><span>)</span>
</code></pre></div></div>

<p>You can also hand in user specified memory regions that should be included in the dump, like so:</p>

<div><div><pre><code>    <span>let</span> <span>app_memory</span> <span>=</span> <span>AppMemory</span> <span>{</span>
        <span>ptr</span><span>:</span> <span>some_address</span><span>,</span>
        <span>length</span><span>:</span> <span>memory_size</span><span>,</span>
    <span>};</span>

    <span>MinidumpWriter</span><span>::</span><span>new</span><span>(</span><span>pid</span><span>,</span> <span>pid</span><span>)</span>
        <span>.set_app_memory</span><span>(</span><span>vec!</span><span>[</span><span>app_memory</span><span>])</span>
        <span>.dump</span><span>(</span><span>&amp;</span><span>mut</span> <span>tmpfile</span><span>)</span>
        <span>.expect</span><span>(</span><span>"Dumping failed"</span><span>);</span>
</code></pre></div></div>



<p>But when you run your nice library code in an application, you get <code>'Dumping failed: "Failed in ptrace::read: Sys(EIO)"'</code>.</p>

<p><em>How useless is that?!</em></p>

<p>Okay, maybe you could enhance your library error handling, a little. And by enhance, you mean Ã¢â‚¬Å“implement one in the first placeÃ¢â‚¬ï¿½.</p>

<h2 id="state-of-the-dart">State of the dart</h2>

<p>Your current approach is to define</p>

<div><div><pre><code><span>type</span> <span>Error</span> <span>=</span> <span>Box</span><span>&lt;</span><span>dyn</span> <span>error</span><span>::</span><span>Error</span> <span>+</span> <span>std</span><span>::</span><span>marker</span><span>::</span><span>Send</span> <span>+</span> <span>std</span><span>::</span><span>marker</span><span>::</span><span>Sync</span><span>&gt;</span><span>;</span>
<span>pub</span> <span>type</span> <span>Result</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>=</span> <span>result</span><span>::</span><span>Result</span><span>&lt;</span><span>T</span><span>,</span> <span>Error</span><span>&gt;</span><span>;</span>
</code></pre></div></div>

<p>and using <code>Result&lt;T&gt;</code> in all of your functions as the return value and handing all of them to the parent function using <code>?</code>. Thus the original error pierces through your callstack like a dart throughÃ¢â‚¬Â¦.jelly (Yes, you are good with words and you know it.).</p>

<div><div><pre><code>    <span>pub</span> <span>fn</span> <span>init</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>()</span><span>&gt;</span> <span>{</span>
        <span>self</span><span>.read_auxv</span><span>()</span><span>?</span><span>;</span>
        <span>self</span><span>.enumerate_threads</span><span>()</span><span>?</span><span>;</span>
        <span>self</span><span>.enumerate_mappings</span><span>()</span><span>?</span><span>;</span>
        <span>Ok</span><span>(())</span>
    <span>}</span>
</code></pre></div></div>

<p>In Rust parlance, this is also called bubbling up errors.</p>

<p>Usually, you just bubble up errors from libraries you use, but for the rare errors you have to define yourself, you currently just do</p>
<div><div><pre><code><span>Err</span><span>(</span><span>"Found no auxv entry"</span><span>.into</span><span>())</span>
</code></pre></div></div>

<p>Well, now you know there is an error, at least. And that it has <em>something</em> to do with your usage of <code>ptrace</code>. But you have no idea where that happens. You use that functionality in various places. Is it during the init-phase? During one of the sections? And if so, which one? What are you trying to read? And from where? Or in short: <strong>What is going on?!</strong></p>

<h2 id="shoes-off-get-some-tea-research-time">Shoes off, get some tea: Research time!</h2>

<p>Well, Rust has been around for quite some time now and they always boast about how error handling is a first class citizen and all that. So error handling should be a done deal, right? With a canonical way of dealing with errors, officially documented and all that should be right there, correct?</p>

<p>Oh boy, were you wrong.</p>

<p>Turns out, this is a very active field ofÃ¢â‚¬Â¦mhÃ¢â‚¬Â¦experimentation, lets say. There has been <a href="https://blog.yoshuawuyts.com/error-handling-survey/">a survey</a> recently, listing and quickly describing most the different libraries and ways for error handling that emerged, fallen out of favor, got forked, died anyways, got superseded, fallen out of favor again, etc.
And the opinions seem to change frequently, if you should use <code>error-chain</code> or <code>failure</code> or <code>fehler</code> or <code>snafu</code> or <code>thiserror</code> or <code>anyhow</code> or <code>eyre</code> orÃ¢â‚¬Â¦</p>

<p>You opened a can of hornets there, or whatever that saying is.</p>

<p>Then you find <a href="https://blog.rust-lang.org/inside-rust/2020/11/23/What-the-error-handling-project-group-is-working-on.html">this gem</a> and donÃ¢â‚¬â„¢t know if you should laugh or cry. Almost six years after Rust hit 1.0 an error handling project group is formed. Six. Years. <em>(heavy breathing)</em></p>

<p>Well, okay. At least they are sorting it out now. Problem is, you needÃ¢â‚¬Â¦.<em>SIX YEARS? Are you serious?</em>Ã¢â‚¬Â¦ahem, sorryÃ¢â‚¬Â¦Problem is, you need helpful error messages now.</p>

<p>After reading a few decent blogs on the topic (like <a href="http://www.sheshbabu.com/posts/rust-error-handling/">this</a> or <a href="https://nick.groenen.me/posts/rust-error-handling/">that</a>), there seems to emerge a consensus, at least for libraries: Return something that derives from <code>std::error::Error</code>. Either implement them by hand, or use a crate that does it for you, using macro magic. like <code>thiserror</code>. Which method you use depends on your level of laziness plus your patience regarding compile times.</p>

<h2 id="examples-vs-reality">Examples vs. Reality</h2>

<p>Another post highlighted <a href="https://doc.rust-lang.org/rust-by-example/error/multiple_error_types/wrap_error.html">error wrapping</a>, a particularly intriguing idea to you.</p>

<p>Unfortunately, all the articles have the understandable, but rather annoying tendency to use very simple example code for illustration purposes. Unrealistically simple, you might even say. They have callstacks of depth 1, return only three kinds of error in total in their API, and their errors are obvious and easily describable (e.g. Ã¢â‚¬Å“Input file XY not found in your Ã¢â‚¬Ëœcounting wordsÃ¢â‚¬â„¢ programÃ¢â‚¬ï¿½).</p>

<p>You have a more complicated callstack, with tons of different errors and code reuse in different places. For example, the function you think is to blame for the above error is <code>copy_from_process()</code>, which calls <code>ptrace::read()</code>, which probably returns something like <code>Failed in ptrace::read: Sys(EIO)</code>.
This function is used in multiple places in your code, e.g.:</p>

<div><div><pre><code>Ã¢â€Å“Ã¢â€â‚¬ init()
Ã¢â€â€š   Ã¢â€Å“Ã¢â€â‚¬ read_auxv()
Ã¢â€â€š   Ã¢â€â€š  Ã¢â€Å“Ã¢â€â‚¬ open(format!("/proc/{}/auxv", self.pid))
Ã¢â€â€š   Ã¢â€â€š  Ã¢â€â€Ã¢â€â‚¬ some_parsing()
Ã¢â€â€š   Ã¢â€Å“Ã¢â€â‚¬ ...
Ã¢â€â€š   Ã¢â€Å“Ã¢â€â‚¬ enumerate_mappings()
Ã¢â€â€š   Ã¢â€â€š  Ã¢â€Å“Ã¢â€â‚¬ open(format!("/proc/{}/maps", self.pid))
Ã¢â€â€š   Ã¢â€â€š  Ã¢â€â€Ã¢â€â‚¬ some_parsing()
Ã¢â€â€š   Ã¢â€â€š
Ã¢â€â€š   Ã¢â€â€Ã¢â€â‚¬ some_more_checks()
Ã¢â€â€š      Ã¢â€â€Ã¢â€â‚¬ copy_from_process()
Ã¢â€â€š
Ã¢â€â€Ã¢â€â‚¬ dump()
   Ã¢â€â€š
   Ã¢â€Å“Ã¢â€â‚¬ sections::header::write()
   Ã¢â€â€š
   Ã¢â€Å“Ã¢â€â‚¬ sections::thread_list_stream::write()
   Ã¢â€â€š  Ã¢â€â€Ã¢â€â‚¬ copy_from_process()
   Ã¢â€â€š
   Ã¢â€Å“Ã¢â€â‚¬ sections::mappings::write()
   Ã¢â€â€š  Ã¢â€â€Ã¢â€â‚¬ elf_identifier_for_mapping()
   Ã¢â€â€š     Ã¢â€â€Ã¢â€â‚¬ copy_from_process()
   Ã¢â€â€š
   Ã¢â€Å“Ã¢â€â‚¬ sections::app_memory::write()
   Ã¢â€â€š  Ã¢â€â€Ã¢â€â‚¬ copy_from_process()
   Ã¢â€â€š
   Ã¢â€â€Ã¢â€â‚¬ ...
</code></pre></div></div>

<p>Same goes for opening files, which happens in multiple places (two examples of which are shown in <code>init()</code>), so getting <code>FileNotFound</code> without context is going to be equally fun, and so on.</p>



<p>Wrapping errors still sounds like a nice idea, but one layer alone is not going to <del>wrap it</del> cut it.
Going with <code>copy_from_process()</code> as an example, you see a few possibilities:</p>
<ol>
  <li>Wrapping the <code>ptrace</code> error into an <code>CopyFromProcessError</code>, but that gives you nothing (except maybe some context, if you add some)</li>
  <li>With <code>InitError</code>s and <code>DumpingError</code>s that wrap the <code>ptrace</code> errors, you will still not know which section failed and why, but know if it was during <code>init()</code> or not.</li>
</ol>

<p>You might add context to option 2 as well (see below on how), but each section has a variety of reasons why it could fail. Some unique to the section, some shared among a few, some among all of them.</p>

<p>Complex problems sometimes require complex solutions, maybe?</p>

<h2 id="inc-err-ption">Inc <em>Err()</em> ption</h2>

<p>Using <code>thiserror</code> and the fabulous <code>#[from]</code> macro, you quickly define a plethora of errors and wrappers, starting from the deepest, darkest places in your callstack, wrapping your way up:</p>

<div><div><pre><code><span>#[derive(Debug,</span> <span>Error)]</span>
<span>pub</span> <span>enum</span> <span>PtraceDumperError</span> <span>{</span>
    <span>#[error(</span><span>"nix::ptrace() error"</span><span>)]</span>
    <span>PtraceError</span><span>(</span><span>#[from]</span> <span>nix</span><span>::</span><span>Error</span><span>),</span>
    <span>...</span>
<span>}</span>

<span>#[derive(Debug,</span> <span>Error)]</span>
<span>pub</span> <span>enum</span> <span>SectionAppMemoryError</span> <span>{</span>
    <span>#[error(</span><span>"Failed to copy memory from process"</span><span>)]</span>
    <span>CopyFromProcessError</span><span>(</span><span>#[from]</span> <span>PtraceDumperError</span><span>),</span>
    <span>...</span>
<span>}</span>

<span>#[derive(Debug,</span> <span>Error)]</span>
<span>pub</span> <span>enum</span> <span>DumpError</span> <span>{</span>
    <span>#[error(</span><span>"Error during init phase"</span><span>)]</span>
    <span>InitError</span><span>(</span><span>#[from]</span> <span>InitError</span><span>),</span>
    <span>#[error(transparent)]</span>
    <span>PtraceDumperError</span><span>(</span><span>#[from]</span> <span>PtraceDumperError</span><span>),</span>
    <span>#[error(</span><span>"Failed when writing section AppMemory"</span><span>)]</span>
    <span>SectionAppMemoryError</span><span>(</span><span>#[from]</span> <span>SectionAppMemoryError</span><span>),</span>
    <span>...</span>
</code></pre></div></div>

<p>The fun part is: You have to touch very little of your existing code, thanks to the automatic conversion from one error to the other, conveniently provided by <code>#[from]</code>:</p>
<div><div><pre><code><span>- pub fn init(&amp;mut self) -&gt; Result&lt;()&gt; {
</span><span>+ pub fn init(&amp;mut self) -&gt; Result&lt;(), InitError&gt; {
</span>     self.read_auxv()?;
     self.enumerate_threads()?;
     self.enumerate_mappings()?;
     Ok(())
 }
</code></pre></div></div>

<p>or</p>

<div><div><pre><code><span>- pub fn get_stack_info(&amp;self, int_stack_pointer: usize) -&gt; Result&lt;(usize, usize)&gt; {
</span><span>+ pub fn get_stack_info(&amp;self, int_stack_pointer: usize) -&gt; Result&lt;(usize, usize), DumperError&gt; {
</span> // snip

    let mapping = self
        .find_mapping(stack_pointer)
<span>-        .ok_or("No mapping for stack pointer found")?;
</span><span>+        .ok_or(DumperError::NoStackPointerMapping)?;
</span>    let offset = stack_pointer - mapping.start_address;
    let distance_to_end = mapping.size - offset;
  // snip
</code></pre></div></div>

<p>If you run your test binary again, you now get</p>
<div><div><pre><code>Failed when writing section AppMemory
</code></pre></div></div>
<p>which isÃ¢â‚¬Â¦.<em>(Throws a stack of papers from the desk)</em>Ã¢â‚¬Â¦short. Too short, and not that much more helpful, actually. Well, you know which section is failing. Thats good. But where are all the nice error messages you specified in your errors?</p>

<p>Hm, you do only use <code>println!("{}", error);</code>. Maybe <code>{:?}</code> is better?</p>
<div><div><pre><code>SectionAppMemoryError(CopyFromProcessError(PtraceError(Sys(EIO))))
</code></pre></div></div>

<p>Aha! Now you are getting somewhere! Tiny, tiny, painfully <strong>tiny</strong> steps, but you are getting somewhere! No error texts, but at least a chain!</p>

<p>Normal printing doesnÃ¢â‚¬â„¢t seem to recursively go through all the wrapped errors, but stop at the top most. For this, you need to either go through all the errors yourself by hand, or use a crate that does this for you. There are a number of them that provide this, but <code>anyhow</code> will do (its by the same author as <code>thiserror</code>, so interoperability shouldnÃ¢â‚¬â„¢t be an issue).</p>

<div><div><pre><code>    <span>println!</span><span>(</span><span>"{:#}"</span><span>,</span> <span>anyhow</span><span>::</span><span>Error</span><span>::</span><span>new</span><span>(</span><span>error</span><span>));</span>
</code></pre></div></div>

<p>aaaaand:</p>

<div><div><pre><code>Failed when writing section AppMemory: Failed to copy memory from process: nix::ptrace() error: EIO: I/O error
</code></pre></div></div>

<p><em>Collects papers from the â€¦</em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://msirringhaus.github.io/Where-everything-went-wrong/">https://msirringhaus.github.io/Where-everything-went-wrong/</a></em></p>]]>
            </description>
            <link>https://msirringhaus.github.io/Where-everything-went-wrong/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26191006</guid>
            <pubDate>Fri, 19 Feb 2021 08:57:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software Engineers struggle to write â€œchunksâ€ function]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26190554">thread link</a>) | @javaguy1
<br/>
February 18, 2021 | https://shekhargulati.com/2021/02/18/why-do-software-engineers-struggle-to-write-chunks-function/ | <a href="https://web.archive.org/web/*/https://shekhargulati.com/2021/02/18/why-do-software-engineers-struggle-to-write-chunks-function/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-6533">
	<!-- .entry-header -->

	
	
	<div>
		
<p>In the last couple of years, I took close to two hundred interviews. These interviews range from Java engineers with two years of experience to architects holding more than fifteen years of experience. The first round of our interview process, irrespective of the candidate experience, involves solving a small problem in a Google document.&nbsp;</p>



<p>I prefer Google docs because it removes the unnecessary fluff and most candidates are familiar with it. I understand that you may feel awkward and conscious when someone watches you while you are writing code. At the same time, it does give some understanding on how candidates keep calm under pressure, recover from their mistakes, and explain things.</p>



<p>I donâ€™t expect people to write completely syntactically correct formatted code in Google docs. I give them 20 minutes of peaceful time to write the program. I once read that in other tech organizations, it is expected that you explain your approach and your thinking as you write code on a whiteboard (virtual or physical), but I prefer to give people an uninterrupted time so that they donâ€™t have to do two things at a time. I try to make sure that they have understood the problem by giving them a couple of inputs and their expected output.&nbsp;</p>



<p>One question that I have used in most of our L1 interview rounds is shown below. Since 2021 I have stopped using this question so I thought it can be useful to share my analysis on how people performed in attempting this problem.</p>



<p><strong><em>You have to write a function that chunks an array into smaller arrays of specified size. For example, chunks([1,2,3,4,5] , 2) should return [[1,2],[3,4], [5]].</em></strong></p>



<p>Coming up with your own â€œFizz Buzz Testâ€[1] is not easy. I came up with the following requirements on which I evaluate such coding questions [2].</p>



<ol><li>It should be a real problem. The kind of problem you solve in a real-world scenario.</li><li>It should feel simple and give confidence to the developer that they can solve it.</li><li>The solution should not require more than 20 lines of code.</li><li>The problem should not be domain specific that it gives advantage to some candidates.</li><li>It should not require any special data structure, which you donâ€™t use in your day to day work.</li><li>Problem should not have a long text. Anyone should be able to read the problem text in less than a minute.</li><li>It should not require knowledge of a special library function.</li><li>A reasonable developer should be able to write the first version in 15-20 minutes. Candidates do tend to miss a few aspects of the problem, so it can involve more than one iteration.</li></ol>



<p><strong><em>I have used this question for evaluating Java candidates only. It is possible that it is not a good question for your specific programming language. So, please keep </em></strong><strong><em>this point </em></strong><strong><em>in </em></strong><strong><em>your</em></strong><strong><em> mind.</em></strong></p>



<p>There are three skills that I am trying to evaluate about the candidate.</p>



<ol><li>Can they code?</li><li>Can they explain the code they have written?</li><li>Can they explain how they will test the code they have written?</li></ol>



<p>Coming back to the chunks problem, one possible Java solution is shown below.</p>


<pre title="">public static int[][] chunks(int[] numbers, int chunkSize) {
   int length = numbers.length;
   int resultArraySize = (length % chunkSize == 0) ? length / chunkSize : length / chunkSize + 1;
   int[][] result = new int[resultArraySize][];
 
   int numberArrIndex = 0;
   for (int i = 0; i &lt; resultArraySize; i++) {
       int chunkArraySize = i == resultArraySize - 1 &amp;&amp; (length % chunkSize != 0)
               ? length % chunkSize
               : chunkSize;
 
       int[] chunk = new int[chunkArraySize];
 
       for (int j = 0; j &lt; chunkArraySize; j++) {
           chunk[j] = numbers[numberArrIndex++];
       }
       result[i] = chunk;
   }
   return result;
}
</pre>


<p>Java 8 solution using the Stream API is shown below. I donâ€™t expect candidates to write this version.</p>


<pre title="">public static int[][] chunk(int[] numbers, int size) {
   return IntStream.iterate(0, i -&gt; i + size)
           .limit((long) Math.ceil((double) numbers.length / size))
           .mapToObj(cur -&gt; Arrays.copyOfRange(numbers, cur, cur + size &gt; numbers.length ? numbers.length : cur + size))
           .toArray(int[][]::new);
}
</pre>


<p>My analysis is that only 10% of the total candidates solved the problem correctly in the first attempt. 30-40% missed a few scenarios and while explaining the solution they figured out the gaps and suggested improvements to fix their first version. And, remaining 50% failed to write even the partially correct first version.&nbsp;</p>



<p>Following are my observations on the attempts made by people:</p>



<ul><li>Candidates for some reason choose a function name different from chunks. I fail to understand why they donâ€™t use function name as chunks. Some of the names used by candidates <em>getSmallArray</em>, <em>getChunksArray</em>, <em>getMeArray</em>, <em>getRefactorArray</em>, <em>getChunks</em>, <em>splitArrayInChunks</em>, <em>convertArray</em>, <em>splitArray</em>, <em>chunkInputArray</em>, etc.</li><li>Candidates who did well in the attempt first wrote chunks algorithm in plain English and then attempted to write code.</li><li>Candidates struggled to come up with the correct function declaration in the first go. They directly wrote the first version of the problem and then came up with the correct declaration.</li><li>Many candidates struggled with multi-dimensional array syntax.&nbsp;</li><li>The first solution written by most candidates didnâ€™t handle the last chunk correctly. They created all chunks with equal size. So, the answer returned by their solution is [[1,2], [3,4], [5,0]]. Some candidates while explaining the solution with the example input figured out the problem and explained how they will handle this scenario.</li><li>Candidates struggled with the size of the result array. They need to consider whether the array is fully divisible by chunkSize or leaves a remainder.</li><li>Some candidates at times used String. They failed to make much progress.</li><li>Candidates make chunks an instance method of some class. They donâ€™t think whether they should make the method static. For some reason, they think static is bad.</li><li>Some candidates prefer to convert an array to a List and then only they can write code.&nbsp;</li><li>Java developers still struggle with Generics. Only a handful of them were able to convert the program to a version that uses generics.</li><li>Only a handful of developers can eloquently explain the code they have written.&nbsp;</li></ul>



<p>By no means I am underestimating the pressure of giving an interview. Both taking a good interview and giving an interview are difficult. I know it is hard for most of us to write code when someone is watching us in an interview. But, given that this is the kind of code we write everyday and we do have to pair with others. I think it is still a better and scalable way to filter good candidates from average candidates.&nbsp;</p>



<h2>References</h2>



<ol><li>Fizz Buzz Test â€“ <a href="https://wiki.c2.com/?FizzBuzzTest">Link</a></li><li>Picking problems for programming interviews â€“ <a href="https://lethain.com/appropriate-programming-problems/">Link</a></li></ol>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://shekhargulati.com/2021/02/18/why-do-software-engineers-struggle-to-write-chunks-function/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26190554</guid>
            <pubDate>Fri, 19 Feb 2021 07:18:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Write and Read Google Spreadsheet from Telegram Bot with Google Cloud Functions]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26190430">thread link</a>) | @fazlerocks
<br/>
February 18, 2021 | https://xakpc.info/write-and-read-google-spreadsheet-from-telegram-bot-with-google-cloud-functions | <a href="https://web.archive.org/web/*/https://xakpc.info/write-and-read-google-spreadsheet-from-telegram-bot-with-google-cloud-functions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://xakpc.info/write-and-read-google-spreadsheet-from-telegram-bot-with-google-cloud-functions</link>
            <guid isPermaLink="false">hacker-news-small-sites-26190430</guid>
            <pubDate>Fri, 19 Feb 2021 06:48:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Anjuna Support for Amazon Nitro Enclaves]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26189898">thread link</a>) | @boxstream
<br/>
February 18, 2021 | https://www.anjuna.io/amazon-nitro-enclaves | <a href="https://web.archive.org/web/*/https://www.anjuna.io/amazon-nitro-enclaves">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.anjuna.io/amazon-nitro-enclaves</link>
            <guid isPermaLink="false">hacker-news-small-sites-26189898</guid>
            <pubDate>Fri, 19 Feb 2021 04:52:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[12 requests per second: A realistic look at Python web frameworks]]>
            </title>
            <description>
<![CDATA[
Score 267 | Comments 105 (<a href="https://news.ycombinator.com/item?id=26188765">thread link</a>) | @gilad
<br/>
February 18, 2021 | https://suade.org/dev/12-requests-per-second-with-python/ | <a href="https://web.archive.org/web/*/https://suade.org/dev/12-requests-per-second-with-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<article>

<figure>
<img src="https://suade.org/content/images/2021/01/The_Tortoise_and_the_Hare_-_Project_Gutenberg_etext_19993-1.jpeg" alt="12 requests per second">
</figure>
<section>
<div>
<blockquote>
<p>A realistic look at Python web frameworks</p>
</blockquote>
<p>If you take a look around the blogosphere at various benchmarks for Python web frameworks, you might start to feel pretty bad about your own setup. Or, alternatively, super-hyped about the possibilities.</p><p>Consider, for instance, the incredible work of the guys at <a href="https://magic.io/blog/uvloop-blazing-fast-python-networking/">magic stack</a>, getting <strong>100,000 requests per second</strong> from <a href="https://github.com/MagicStack/uvloop">uvloop</a> in a single thread. This is on par with compiled language like Go's performance.</p><p>But that benchmark doesn't really cover a fully fleshed out web framework, right? We need a lot more functionality and structure from our frameworks than reading and writing bytes. What about fully fleshed-out web-frameworks in python?</p><p>One such framework is <a href="https://github.com/sanic-org/sanic">Sanic</a>, which again has been shown to have similar performance: <strong>100,000</strong> requests per-second. Or there's <a href="https://vibora.io/">Vibora</a>. Not only does this claim to be a drop-in replacement for <a href="https://github.com/pallets/flask">Flask</a>, but it also has its own templating engine. And it handles <strong>350,000 requests per second</strong>!</p><p>Even more mind-blowing is <a href="https://github.com/squeaky-pl/japronto">Japronto</a> which claims an insane <strong>1.2 million requests per-second</strong> in a single thread ğŸ¤¯ trouncing the performance of other languages and frameworks:</p><p><img src="https://raw.githubusercontent.com/squeaky-pl/japronto/master/benchmarks/results.png" alt="https://github.com/squeaky-pl/japronto"></p><p>Recently we've been doing a lot of work improving the performance of our Python APIs. Currently we're running <a href="https://github.com/pallets/flask">Flask</a>, and we initially had a single question: <em>how can we serve more requests from a single worker thread? </em>But looking at these benchmarks had us asking more:</p><ol><li>Can we meaningfully compare them to our setup?</li><li>How realistic are they for a full production application?</li><li>Would we be better using one of these frameworks over Flask?</li></ol><p>In other words, how much should we trust these benchmarks? And to what extent should they influence our choice of technology?</p><p>In order to answer these questions, in this post, I benchmark a realistic Flask application along with it's <a href="https://github.com/sanic-org/sanic">Sanic</a> equivalent. I'm going to guess that most readers come from a background with one of the more "traditional" Python frameworks (<a href="https://github.com/pallets/flask">Flask</a> or <a href="https://www.djangoproject.com/">Django</a>), and it's certainly more relevant to devs here at Suade Labs. For this reason, I run the Flask app in a number of different ways, to see what the best bang for our buck is: how performant can we make our application with (almost) zero changes to the code? Along the way we'll pick up some tips for the original question: <em>how can we serve more requests from a single worker thread?</em></p><p><strong>Sidenote: </strong>if you're new to Python's web frameworks, or its asynchronous libraries, take a look at [1] from the addenda at the bottom of this post for a quick explainer. This post mostly assumes you know these things.</p><h2 id="the-baseline">The baseline</h2><p>First let's run some simple "Hello, World!" benchmarks on our system to get a meaningful baseline for comparison. For reference, the Flask benchmarks on <a href="https://www.techempower.com/benchmarks/#section=data-r18&amp;hw=ph&amp;test=fortune&amp;l=zijzen-f">techempower</a> give 25,000 requests per second.</p><p>Here's our Flask app:</p><pre><code>app = Flask(__name__)

@app.route("/", methods=["GET", "POST"])
def hello():
    if request.method == "GET":
        return "Hello, World!"

    data = request.get_json(force=True)
    try:
        return "Hello, {id}".format(**data)
    except KeyError:
        return "Missing required parameter 'id'", 400</code></pre><p>I ran it under a variety of conditions. First "raw" via <code>python app.py</code>, and then under <a href="https://gunicorn.org/">Gunicorn</a> with a single <code>sync</code> worker via <code>gunicorn -k sync app:app</code> and finally Gunicorn with a single <a href="https://github.com/gevent/gevent">gevent</a> worker via <code>gunicorn -k gevent app:app</code>. In theory Gunicorn should handle concurrency and dropped connections much better than the raw python, and using the gevent worker should allow us to do asynchronous IO without changing our code [2a]. We also ran these benchmarks under <a href="https://www.pypy.org/">PyPy</a>, which in theory should speed up any CPU-bound code without making any changes (if you haven't heard of PyPy see [2b] in the addenda below for a quick explanation and some terminology).</p><p>And what about Sanic? Well, here's the "rewrite" of our app:</p><pre><code>app = Sanic(__name__)

@app.route("/", methods=["GET", "POST"])
async def hello(request):
    if request.method == "GET":
        return text("Hello, World!")

    data = request.json
    try:
        return text("Hello, {id}".format(**data))
    except KeyError:
        raise InvalidUsage("Missing required parameter 'id'")</code></pre><p>And here are the results:</p><figure><img src="https://suade.org/content/images/2021/01/hello_world-3.png" alt="" srcset="https://suade.org/content/images/size/w600/2021/01/hello_world-3.png 600w, https://suade.org/content/images/size/w1000/2021/01/hello_world-3.png 1000w, https://suade.org/content/images/2021/01/hello_world-3.png 1161w" sizes="(min-width: 720px) 720px"></figure><div><p>Some technical details: I used Python 3.7 with the regular CPython interpreter and Python 3.6 with PyPy 7.3.3. At the time of writing, running 3.6 is the latest PyPy interpreter, and their Python 2.7 interpreter is faster in some edge cases, but as Python 2 is <a href="https://www.python.org/doc/sunset-python-2/">officially dead</a>, I don't believe it productive to benchmark. My system details are available in the addenda [3]. I used <a href="https://github.com/wg/wrk">wrk</a> to actually execute the benchmarks.</p><p>I'll break the results down in two parts. First: Sanic dominates, with 23,000 requests a second, although running our Flask app under Guncorn + gevent and PyPy does a pretty good job at keeping up. Second: what's going on with the performance range for our Flask app?</p></div><p>Under CPython, we see that using Gunicorn quadruples the number of Flask requests per second from 1,000 to 4,000 and using a gevent worker adds a mild (sub 10%) speed boost to this. The PyPy results are more impressive. In the raw test, it is churning through 3,000 requests a second; it received the same 4x speed boost from Gunicorn, getting us to 12,000 requests a second; finally with the addition of gevent, it cranks up to 17,000 requests a second, 17x more than the raw CPython version without changing a single line of code.</p><p>I was quite struck by the fact that gevent had such little effect on the CPython process - probably this is because the CPU is maxed out at this point. On the other hand, it seems that PyPy's better speed means it is still spending time waiting on system calls / IO, even under Gunicorn. Adding gevent to the mix means that it switches between concurrent connections, processing them as fast as the CPU will let it.</p><p>To get a real sense of this, I ran the benchmark whilst monitoring CPU usage. Here's a short test against the raw app under PyPy:</p><figure><img src="https://suade.org/content/images/2021/01/sync_cpu_usage.png" alt="" srcset="https://suade.org/content/images/size/w600/2021/01/sync_cpu_usage.png 600w, https://suade.org/content/images/2021/01/sync_cpu_usage.png 919w" sizes="(min-width: 720px) 720px"></figure><p>You can see that the program hops between CPU cores and rarely utilises 100% of a given core. On the other hand, here's part of a much longer test against the Gunicorn gevent worker under PyPy:</p><figure><img src="https://suade.org/content/images/2021/01/gevent_cpu_usage.png" alt="" srcset="https://suade.org/content/images/size/w600/2021/01/gevent_cpu_usage.png 600w, https://suade.org/content/images/2021/01/gevent_cpu_usage.png 900w" sizes="(min-width: 720px) 720px"></figure><p>Now it's evident that there is no switching between CPU cores (the process has become "sticky") and the individual core is being utilised to a far higher degree.</p><p><strong>Key takeaways</strong>: Sanic wins. PyPy is fast. Run your "traditional" app under Gunicorn.</p><h2 id="realistic-benchmarks">Realistic benchmarks</h2><div><p>The benchmark above, while fun, is pretty meaningless for real-world applications. Let's add some more functionality to our app!</p><p>First, we'll allow users to actually store data in a database, which we'll retrieve via an ORM (in our case <a href="https://www.sqlalchemy.org/">SQLAlchemy</a>, the de-facto stand-alone ORM in python). Second, we'll add input-validation to make sure our users get meaningful error messages, and that we're not accepting junk that crashes our app. Finally we'll add a response marshaller to automate the process of converting our database object to JSON.</p></div><p>We'll write a simple book store app, for a publishing house. We have a number of authors each writing zero or more books in several genres. For simplicity, each book has only a single author, but can have multiple genres - for example we could have a book which is in both the "Existential Fiction" and "Beatnik Poetry" categories. We're going to add 1 million authors to our database and roughly 10 million books. [4]</p><p>Our SQLAlchemy models look a little like this:</p>
<pre><code>class Author(db.Model):
    id = db.Column(UUIDType, primary_key=True)
    name = db.Column(db.String, nullable=False)
    ... # snip!

class Book(db.Model):
    author_id = db.Column(
        UUIDType, db.ForeignKey("author.id"), nullable=False, index=True
    )
    author = db.relationship("Author", backref="books")
    ... # snip!
</code></pre>
<p>To marshal these, we use <a href="https://marshmallow.readthedocs.io/en/stable/">Marshmallow</a>, which is a popular Python marshalling library. Here's an example of the Marshmallow model for the Author overview:</p>
<pre><code>class Author(Schema):
    id = fields.Str(dump_only=True)
    name = fields.Str(required=True)
    country_code = EnumField(CountryCodes, required=True)
    email = fields.Str(required=True)
    phone = fields.Str(required=True)
    contact_address = fields.Str(required=True)
    contract_started = fields.DateTime(format="iso")
    contract_finished = fields.DateTime(format="iso")
    contract_value = fields.Integer()
</code></pre>
<p>In our endpoints these are used for validating input and returning results like so:</p>
<pre><code>@bp.route("/author", methods=["GET", "POST"])
def author():
    """View all authors, or create a new one."""

    if request.method == "GET":
        args = validate_get(marshallers.LimitOffsetSchema())
        limit = args["limit"]
        offset = args["offset"]

        authors = Author.query.limit(limit).offset(offset).all()
        return jsonify(marshallers.authors.dump(authors))

    if request.method == "POST":
        author = Author(**validate_post(marshallers.author))

        db.session.add(author)
        db.session.commit()

        return jsonify({"id": author.id})
</code></pre>
<p>The full source code can be viewed in the <a href="https://github.com/olliemath/async_python">GitHub repo</a>. Here, the thing to note is that <code>marshallers.foo</code> is an instance of a <a href="https://marshmallow.readthedocs.io/en/stable/">Marshmallow</a> schema, which can be used both to validate a Foo input, for instance in a POST request, as well as to marshal Foo instances ready for returning as JSON.</p>
<p>In order to actually perform asynchronous database requests, some fancy footwork is required with patching libraries, which depends on which postgres connector you use. SQLAlchemy does not support this out of the box, and in fact its primary developer has a great post arguing that <a href="https://techspot.zzzeek.org/2015/02/15/asynchronous-python-and-databases/">an async ORM is not always a great idea</a>. Juicy technical details in addenda [5], but beware that just using a Gunicorn gevent worker will not necessarily get you what you want.</p><p>PyPy tends to suffer a performance hit when using C-extensions and libraries instead of pure python, conversely CPython should get a performance boost from the C-based libs. To take account of this I tested two different underlying database connectors: both <a href="https://github.com/psycopg/psycopg2">psycopg2</a> and a â€¦</p></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://suade.org/dev/12-requests-per-second-with-python/">https://suade.org/dev/12-requests-per-second-with-python/</a></em></p>]]>
            </description>
            <link>https://suade.org/dev/12-requests-per-second-with-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26188765</guid>
            <pubDate>Fri, 19 Feb 2021 02:21:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dismantling Racism in Mathematics Instruction [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26188717">thread link</a>) | @kofejnik
<br/>
February 18, 2021 | https://equitablemath.org/wp-content/uploads/sites/2/2020/11/1_STRIDE1.pdf | <a href="https://web.archive.org/web/*/https://equitablemath.org/wp-content/uploads/sites/2/2020/11/1_STRIDE1.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>Ã¥,Â®kÂ´yX=â„¢:Â§â€™Ã‹Â§fâ€¦-@rÃ¯P
Â¢â€
Â´Å¾Ã’Ã›â€ ~hÃ”AÃ™â€œo
UÃsÂ»Ã‘Â²@mÃˆ3Â±lAÃ™Ë†2@XÃ¥Ã¸Â©1MÃ²H&amp;ï¿½Ã‚	TÃ–Ã—Â¹Ã¤Å“ Â¡Ã¨Â¹
ÃšÃ¶Â²Â±Ã™Â©Ã–CÃ…]Ã¶Ã‡Ã©â€šÃ– Â§&nbsp;VECÃÂ£CTÃºÂ£Ã³Å¾\Ã‹â‚¬!ToÃ„SL#Ã¢	y(7^Ã…2
:ÂºdÂ¥Ã—a$}AÃ¥â€¹Â¸Ã£gBERÂº Â£â€¦Â²Ã·Å’Â¥=Â¤â€â‚¬â€|Ã—â€œÂ¦l&nbsp;aÃŒâ€Å“â€¦T1
Å¡Â­hâ€ºâ€¢Ã‘ÃƒÃ·Â­Ã•U=Â¦â€“vâ€ºÂ§Ã¨
Ã²P.	Â¹7Ã˜Å½!ÃÃ”JEÃºÂ¾|*Â½Æ’Ã¹â€šÃ³â€šJï¿½Âµâ€œÃ“ÃÃ±Ã’+Ã¤HÃ¾{M~Ã’&gt;Ã»Ã­Â¾#5â€¢&nbsp;â€°Â¥Å¡Ãšâ€°.^â€˜ÃºÃ”Ã§	9#G~â€™Ã¹TÃ´KÃ˜Ã¿Â¨	Æ’	ï¿½â€¹ËœÅ¡BNâ€ SÂ§Â´BÂ©Â¥cs6HCÃ•2Ã‘VÂ·Ãµ'_QÃ¿XÂ»Ã²LÃ’u_	â€”Æ’)Â²lÃ»â‚¬fÂ½Ã¯Å½Â£Ã„c Ã¤â€ºYÃ›Ã’ÃªÃ™,uÃœbjÂªLÃµcÅ’Ã Ã¯Ã»<rf8jâ€œ3Â¹'yÃ—Â³ÃŠz2ï¿½):8gl{bucï¿½Ã…:Ã¨Å Å¾Å“â‚¬â€™*eÃ†2ÃÃºv9ÃµÂ¦;@Ã¬qÂ¥ï¿½bËœÃÃŠÂªÂ©zÂºÂ©Ã‘ Ã¤8vÃ¤tÂ°wsqÃc!fÂ¯â€zsÃ•Ã¤ï¿½{Â¸}Â°Ã¹Ãƒâ€œ="Ã­ÃšÃ»Ã²FÃªÃŠâ€”:cÂ¤&nbsp;O&quot;Â¶UÃ€H8Â»/Â´Ã®AÃ·ÂºÅ’Ã¢&amp;ÃÃ†kPÂ°\â€™Â¹Ã‰(â€¢Ã•$Ã¡#Ã»TÃ£4Ã“Å’;']â€¦&quot;_Ã‡Ã«$â€¹â€˜ï¿½Â²Ã­FKÂ½;0iÃ¢Â¸Ã YÃ´Ã¶m){Ã²h0" â€“qÂ»'$Â·zÃ¦bÃ¶â€°Â´ÃœÃ°.Â¹!Â¢k]Ã²sÃ!Ã‹!!oÂ¤Â¥Ã´Ã‘Ã°ÃÃ©&Ã¨1%mÃ´Â¤â€˜fzÂ©="" yÅ¾="Câ€œï¿½7Ã£Å¡ËœpSÃ”Â¥" Ã´fÂ½`b5ÃÂ¼Ã“udÂ²pÃ›Ã…Å¸#Ã¤ï¿½9Âª^Â¦Ã–vmÃ‘xâ€Â¹Å“Â Ã‘Ã¯Æ’â€“'â€¦="}Ã¸QPÃ·Ã¤<`9â€“Ã…Ã­,ÃqÂ®|ÃÂ²Ã‚AÂ©â€¦Â«Ã´{â€”Ã‹â€ÃœÅ¸ÃƒKÂº<Ã–,ÃJ2%&nbsp;ï¿½.dumÂ±ÃŠÂ¢â€°<â€¡â€ºâ€¢Â·Li+â€™+ÃŠ1Ãªï¿½Ã“Â²â€šÃ¶ÂµÃ–?ÃŒâ€˜sYuÃµÃµyk|ÂµÃ“Â¤\Ã‡Â±Lâ€¹Ã‘Eâ€¡ÃµÃ¶" Ã¤lÃŒÃ…Ã¹8Ã“Å¾â€œzuÃ»3ÃŸÃ™vÃ²Ã…#Â°}Ã„Ã¤â€ kÃ¥sgÂ¯Â¬Ã^Ã¤ÃÂ¨Â²Å¸d5Â©_Ã¼rÂ»â€a="" uÃ’dnÃmÆ’tË†Ã­Ã\Â­Â¹(pr.Â¼"ÂµÃŒiÃ•<Ã–qÃ»"Å Ã¦kÅ½Â¨Ã–ÃsÃâ€œÃŠâ€˜Ã¶Â±Ã²hÃ–Ã’Ã›Â¥<xcÃ¸(`="" Ã«Â¥â€™*iÃ‚yÃ¶Ã—:ÃŒâ€”[49rÃ­Â±%="" uwÃ±Ã¦oÂµsâ€¢â€™0â‚¬8â€ â€ºËœÃ•Ã‘Ã¤yÃ´â€šÂ¦[!â€“gÃ‰Ã—Â¼Ã–ÃˆiÂ«Â¿Ã»qâ€šÃ»Ã½?Ã§â€ idÃµâ€œï¿½Â«vÂ«jqabâ€¹"Â¨Ã–0Â©Âµ\Â²j?(Ã‘.ÃŒÃ‘#Ã¤Ã¡\Â«]$Ãâ€°{="">:Âªâ€“R[m{Ã¯c
#Ã¤ÃŒHÂ´A`jm_&gt;MÃ‚ï¿½{ÂµÂ¤}ÃƒTBÂ¹Ã±ÂªÂ²ÂºÃ¥ï¿½Ã‰ÃÃ¸Ã±_//?Ã¼Ã¦Ã¿Â³OÃ¿Ã€Â£`Ã§Ã’Ã·J3â€¹Ã¶SÂ·Ã¼ï¿½Ã“â€¦Â¢ÃÂ¸Ãâ€“DÃœOcÃ¾ÃÃŸÃ¼Ã»oÅ½ÃÃŸâ€¦ÃŸÃ½)Ã¼â€Å¸ï¿½Ã¿ÃºÃ¡Ã‡Â½Ã’Ã³â€¢ÃªÃ‚pÂ¡_Â¨â€º|ï¿½Ã‡Å¡GÂ½VRsÃ¤Âµâ€”Ã„-AÃ¤Ã¼Ã¾Â»%&gt;~ÃºÃ¸Ã«Ã·Ãâ€¡ï¿½Ã¯Ã¿|Ã»Ã¯Â¾Ã—c8â€“ÃµNÅ¸Ã°Ã«q}bwâ€¹Â¾Ã¶Ã©Å½Ã‡Â¢Å¸Ã¿â€œÂ¿?Â¼hxÃ¹Ã›OÂ¾Ã¯BÃ¸Â®DÃ½5Ã‡Ã¾Ã£iÂ¯yÂ²Å’qï¿½`.{ÃŸÂ­â€œï¿½â€K#Â±JÂ¹Ã‚Y*Â¦@LÃÃ¦Â¥Ã—Ã€Ã¯~Ã¹Ã°Ã²Â¾Å’?Ã¼ÃºÃŸÃ¸Ã®ÃƒgÃ½Ã©Å¸Ã¿Ã´â€”Ã°Ã½Ã‹Ã±â€¡Ã°Ã¾Ã³Â§OÃ¡â€”mÃ¸Ã³3^Ã¼Ã R/!Â¡iÂ¾ÃŒQRE?Ã”Å¾â€¹Âµ7_Å’Ã«Ã‹Ã¸Ã¿Â³_Â¶Â°q3AÂ¶VÂ£( Ã€
	
2+
â€¹Å½W:Vx 8Â¸Ã¸T\Ã¼Ã¡Ãª``Ã Â±â€™â‚¬TÅ tUÃ•Ã¼Ã˜Ã»ï¿½Ã­Â³Â½Â»Ã]Â¯vÃ§â€™ÃÂ£Ã¶ÃÃ?Ã»&amp;Ã¯Â»3Kâ€“Ã±ÃŠÂ¿&gt;â€¹Â¾Â¿Ã¦â€”Ã§Â¿8Å¸EEÂ³ÃªË†ÃœYâ€˜5Ã®â€”sË†Å¾N#XÃ¥Â·gÂ·Ã¼Ã¹ÃÃ›{Â¡Â¥ÃµÃŠâ€™YÃ‚Ã„Ã¾Âªï¿½5g-$Ã¶=`Ã¶pzÃ„Ã¹Å¸â€ºÃÃ¸Ã¶Ã¼p{zEOkï¿½%vâ€¦OeÂ³eÃ†Å¸Å Ã›tÃ‰_gÃ˜Â¿ÃbÃSÃ	&nbsp;n+`ÃªTh2Â¯:ÃªÃ‘Â»Ã¯DC`Ã³xqâ€”Ã‰Å Ã¿Ã¹ÃµÃ¼Ã«Â­Ã‘eÂ¶Ã¸uâ€™Ã¾nÃ¹*Â¹9Ã†Ã¾%Â£ï¿½ï¿½Âªâ„¢n:ÃŠÃ½9@+Ã·Â¦BcÂºÂµÃˆxÂ¼h5oÂ·Ã§wâ€°ÃšÂ°Ã„Ã¾!~(â€™aâ‚¬%Ã‚ï¿½Ã­ÂªÂªâ€”Ã„Ã©ÃÃ²GÃ›&nbsp;Â¶â€œ?Ã‹.Ã±;Ã³Å Ã½[Fï¿½(Ã·,ÃŸÃ€Uâ€˜3Ã¡Â³Â¼Â¬Â´Â»Ã»Â«'ï¿½â€“DÃ•Å’Ã„Ã§6Â³5ÃfbjÂ®Â²Ã®lÃÆ’Ã»Ã·Ã˜â€°Ã]vu5YÃµÂ¬Ã’oÂ­ÃµÂºÂªO
PNÃ–Å“Fv7Â­Ã´ Ãµ[ 7xâ€šMhâ€¡â€šÃ¯Â«Â»eÅ’Ã½Â«Ã¼Ã²)AÃ’$kï¿½Â®Å½Uâ€˜$H=oIÃ¤%Ã€Â¼Ëœiâ€œDÃ‰Â¾Ã†Ã˜Â¿Ã‹LÂ¥CU~Â¶Ã³mÃ“Ã‡Ã¢Ãªâ€š5evPÃ·~Ãµ@Ã‘^Ã”.â€¡ÃÂ¿uÃŠ Â¦&amp;Ã·Ãƒâ€“yâ€rÃ¬65M!$Â¥Å Â¢ÂªÃ¾â„¢2*Ã’ËœAÃˆ5\`-Å¾ÃˆÃ8]pÂ¾L|X"ÃÃ°wg	MQ#Â¦h5WÃ‚Ã™ÃµÂ­xÃ€ï¿½Â¦*â€”Ã–#1!&gt;ÃŒÃÃ°â€šÃ½Ã³ÃŒÅ’Ã™fÃ‹Â¹Ã¹Aâ‚¬)mÃ‚H9DÅ¡Ã¯Ã‹Ã„Â¢8ÃÃ°bÃ¢â€°Æ’Râ€7NRÂ¿â€“Ã wÃ˜?Ã‘â€°Â¦Ã’pÃ’Ã¬â€ï¿½Å¸ [Â¥â€¢Â¥Ã¥ i=hÃ»/qÃ•9Ã¹Ã/Å¾Ã`Ã¿@'ZÃ•ï¿½Â®Â»Ã¸â€Ã´BoÃ©i
TiÃ”RhgÅ¾Ã–	C}Å¡yÃ¼Ã¬Ã›/â€¡UÃµÅ’Ã¼[{Â¡{YÃ–Ã¶ÃnSÂ´-xÂ§ï¿½$ÃŠÃÂ­ËœÃ„Ã•0ÃÂ£â€ºÂ¶7Ã„7ÃƒÃ±Ã®Ã»(J~Ã»6Ã„â€“Ãrï¿½Ãº{Ã»Â¢
_-â‚¬â€~E&nbsp;Ã€&nbsp;Ã²Æ’yÃ©RÃÂ»ÃÂº'VFÂ¶Â¤O^Ã°Ã‡Ã©ÃÃ¶Â°ZÃÅ¸Ã·Â¾ï¿½5Â«sÃ¬_Ã­DSÂ¹&nbsp;Ã®Ã³Ã…Â¡"â€“Ã»ÃµÂ»;hÃ³f]8i&lt;Ã•QÃ—c8_Ã±pVhÃ˜Ã¾Â¥9ÃÃ–IÃ·Ã†Ã…&nbsp;Ã¹Ã’ÃcuÃ«XXZÃ…tÂ¤hÃ¾Sâ€™Ã°ÃƒÃ¹UÂ¢RÃ’Ã±Â°ÃÅ Ã¯[Ã¬Â¤KhÂµ6Ã¹Ã€]Â½Ã›â€˜â€°t'ÃµQfÃ°Ã»â„¢n6Hâ€“Â¨Ëœ`GaÃšBGtâ€¦xÂ¼Â¨Ã«Â¯ÃšÃBÅ“7Å½&gt;Ã’Â¾AÃ”Ã‹â€¡DÃƒÃ‘%Â²Â¶Â¬oÃ¶Â¯tjÃ“Ã¨â€¹Ã•zÃfï¿½Ã¤Â±Ã…oËœÃÃ‚PÃ¥ehÃ›$x/,Â°DÃ‰zï¿½Dy[iâ€°Âµ(Ã½!Ã’â€¢TÃ‚Ã™@Ãˆ:(vpsÃ¹Â¦?Ã¾`[aKÃ¶+}Ã™Ã°5v,Ãœ`Å¡+Â±Â¥jÂ­T^Â¶Â±RÃ°Â±nÃ…jdÃµ%Ã•OFHÃ¨~x~Ã…Â¶Æ’v4Â¨uÂºÂ¶râ€°â€¹;Â¥Â²*Ã¯â€œÂ¼\*Â®]Ã’K~Ã¨ï¿½e?Â¸-GÃ´bÅ¾bÂ»@bÂ¿ï¿½Ã‚fuÆ’4Vuï¿½\Â©Â«ÃŸÂ±Ã”Ã…ÃªSÂµD9cNâ€œÃ›Ã™ÃŸÃ¼Â­bÃ¤Â¨tRnÃ&nbsp;â€”!Â«Ã¤)PÃ²\ÃÂ¼Â²Â¤:bÂ±SÂªÂ»Ã‘;â€š|Ã’â€ºÃ³Â¶	T.Â°CbÃâ€“!@Â¾lj$ï¿½Â»â„¢vÅ Â®)Â¿Å½ï¿½Ã¯Ã¢ï¿½eEâ€¡.Â¢Ã¡Ã¸Ã³-Â¶Tâ€“Ã˜AÃ‘#Vt6uÃ…Ã‚5Ã‹Ã¥ÃÃ²â€¦Ã²Â«m7TKï¿½fÃ¯ÃŸÂ¶Ã…Ã€ÃšKu&gt;Ëœ?
'Â³oÃ»U7Ã¥$Ã±Ã¶Ã…Â°#cGÂ¯?ÃÃ¾_Â©Âª{â„¢#Ãµâ€”â€”ISâ€¡
â€ÃŒÃ¢ÃŠÃ‘MÃ­]Å½(Â¸Ã§Â§IÃ·Ã»#QkÂ¶&lt;8ÃªM&gt;[Ã˜eÅ¡H&nbsp;râ€¡X(9Ã–JD?Ã¦â€”Ã‰lÂ½9Â¢ ]Ã¤Â©biÃ‹Ã&nbsp;â€˜Ã¦Â®i[?uW&lt;&nbsp;9Å¡~Ã™Æ’ Ã£tÃ²Ã©"Â½N~Â¼bkÃŸÃˆrÃÃ²â€]R,Ã¯râ‚¬q4ÃˆÂ½Ã‚8hÂ¬Â¡sâ€¡`
h.Â¼*Â¡Ã¥0^&gt;Ã¾Â¾Ã§Â±â€¦o!]`GÃ‰Å &nbsp;Â»Ã³â€šzWï¿½gÂµâ€¹Â¤Z(O:]kÂ¥NÃºÅ¸â€ CÂ¾Ã,Ã˜Â¢Ã¯Ã¤Ã¾NxÃŒ23Â«_Å¾ÃƒL=â€¡Ã½â€™Â¾OÃ Ãª'Ã§Ã™Ã½&gt;Â§Ë†â€™tâ€°*YÃœm:â€ÂªÃ©nÂ­Ã²7HyÃ„Ã´9Â«Ã˜_â€šÃ¨fï¿½akÃâ€¢Ã¬Ã¾M)Ã¬Â¶aâ€“Â»Å“xÃ¸Ã›â€œ0Ã‡Ã–y?Ã¦Ã³;b*ÃÂ»rkD,Â¶0yÂ«Â§â€ Â®â€¡RÅ¡Ã…Ã‘â€ºI;Â²Ãµjâ€¦Â®Ã²aÃªQ@ÃŒÅ¡Â¹`Ã­%&lt;Ã°Ã–QpÅ¸Å“aÃ‡Mâ€¹ ÃšÂ¸jï¿½ÃÃÅ’Â±Ã¤ï¿½Ã–â€™Â¶|ALÃŒÂ¶Â¼â€™bNA=hwÃ·ÃºÅ 5Ã‰AÃ‘Â¼Â¨Ã²Ã5Ã€Ã®Â²?tâ€“Sâ€#	Â¶Â¶â€¡Ã²Ã§Ã¯ÃŸÃ¯Â¡Ã¥Ã¨Ãš.ÂªoÃ¤uÂ½;â€™fÂ¸ÃºVÅ¸CÃ€â€“Ã¶`Â¶%ÃŸÃµ]Â°09iMw0MlÂ·kqÂ«EÃŠTOy[Ã™cxÃ¾yË†&gt; Ã¯Ã»b&gt;0gâ€vÃ…W6HÃ£Ã¬Â«Ã½xÂ³uSÃ‰Å¡Ã…Å½&nbsp;R)ï¿½â€°8H_Ã¿Ã«VdrÂ±5^Ã @&amp;qeÆ’-ÃªÃ‘câ€¡ÃBÂ¡Ã«\Ã¡zâ€Ã–â€¦Ã’Ã™Â­hRÃ¼$Å“`Ã‹y&gt;ÃŸ=bGÃ’â€š&nbsp;UfÃ¬1Å½Qâ€ ZÂ½Ã“ÃEtÂ²Ã†VÃ³T&lt;=-CÃ‡ÃÂ®<vÃ¼â€¡Ãºâ€ Ã©'â€°ï¿½k]â€“'ÂªÃ¨|9Ã‚ÃˆÂ·[ÃŠr"bâ€ #Ãƒâ€œ[mÃµÂ¦_ql]yÂ¨Â¾Ã‰Â½9ÃƒvÃ±Â¤<\Â­ï¿½#(â€°Å½ÂµzÂ¤qÃ¹â€˜b>Ã¨Â°$Ã›Ã¿Ã›Ã»Ã„ÃµMË†Ã<cÃ‹xj>!Â´Âªoeâ€™ÃÃ†"eÃˆÃ&nbsp;TÂ¨Å“dÂ´(Câ€°&gt;\Â¾;KÃ°02Â´%Wâ€œZÂ¯Ã¨Â´Å¡f%â€ Ã©Ã‰Â°Ã¬ï¿½â€” â€˜kmÃ©_BÃ»Å½Â³ï¿½â„¢DÃ²Ã¤Å¡~Â°Ã‡;lÃ»=Â¬Ã’â€¢)mÂ©~Â°Ã£Ã-â€â€ Â£â€”[Â¾Ã“Ã³p|ÃˆÂ¢8hÂ»ÃµÂ©ÃŠÂ¿uï¿½PÃ®ÃªÂ«Â¤Ã—Æ’Ã‰(Ã£8â€¹Â¢Ã˜Ãºï¿½Å¾O|v:â€™&nbsp;Â£E&nbsp;LÂ½S=Ã“ÃŒï¿½ï¿½â€”%CÅ’Ã¤Ã¦1Å¡?bxzÅ¾Ã¹Ã¦<dÃ›:â€ÃªsmlÃºryÂªÃ¯ï¿½b Ã‘Ã‰Ã_lÃ½zaâ€ z-a;â€”="ï¿½]#Ë†Ã±|XFÃ‘Eâ€ Â­^Ã¼]ï¿½Â¤iÃ“â€”Ã¤Z1Wi#â€°Å¾CvÃ°ÃŒbï¿½bkÃ—Yzwâ€°Ãš0zEâ€6â€œÂ¯@vÅ½Ãâ€°yYbÂ³Ã¥[Â¾">ÃˆÂ®ï¿½Â±CÃ«â‚¬Ã–-PÃŠÂªÂ»VÂ·q&amp;1Ã¼Ã¥]fâ€°Å“oWÃ˜Ã5&nbsp;Ãˆ9ÃŸÃ¦EH6&nbsp;M?$ï¿½â€“Ã˜Ã‚ÃµÃˆ+vâ€{Â°â€œÂ¾ÃƒÃ¦ÃTâ€”ï¿½kÂ¦Ã¢cÂ´LÃâ€™Ã·l	Ã¾Ã¥1Â¾Ã²Ã†oâ€â€“â€°mÂ¬4â€¦ËœÅ¾ÃWkÃ¾ryï¿½Â­ZÂ¯dâ€ºÃ™Â§)cÃ¦ÂªFâ€”qÃ­1Ã–Ã¡Å¸KÂ¾=DÂ¼Ã›sDÃ…Ã¢;Ã-XY
=â„¢Ã…Å¸Â±Ã•â€?WÃb	Fï¿½ÃªÃÂ¦Ã³â€šEÃ¬GÂ°Â¼Ã¡ÃŒÃ¥olÂ¹â€ !ÃƒÂ´hÂ®vw&nbsp;f[Ã‚Â¾.YÂ¤?â€¹[Â¬Ã¾Ã™â€”8Â¿Ã°BiÃ¯vÃ•&nbsp;ÂºÃ¡'ÃµlR12lÂ½Ã Ã¶rÂµÃ¼Ã '|VÃ½j:k'x)qÃˆMSâ‚¬-Ã—dÃ.â€“ÃŸÂ£x.Â®=Ã”Ã©&lt;Â´{ ybÂ°Ã¥Å’Ã´.Ã,Â°Â£mâ€/V	;Ã†yâ€”lÂ¥dÃµâ€°sÂ¤(Æ’rÂ§ÃÃÂ¡uÃ€Â°TWâ€“|@Â©bÃ˜:
ÃˆbÃ»?[ÃºÃ¥)6SWÃ„ÃºÃ Ãâ€¢$ÃƒOË†Ã„Ã˜B
GZ|^ÃªÂ¨}ZMÂ¦Ã•AÂ¾5\Ã½AÃ–ip&gt;c\ÃªOÂ¡ï¿½$ï¿½ÃŠ/lï¿½&amp;Ã†Â¸â€¢fÃ«wpÂ´.Ë†)xÃ€Ã–h`Â¯Â°CÃ®Â´Â´ÃYUÃ£Ã¹Ã—Â²Ã„Ã“,L\Â­Ã¢Ã•oÃ«ÃŒÃÃo1b0GÃ˜
Lvt<y ;dÃ©ÂªÃ™zsÅ¾cvËœÅ¾Ã£glï¿½â€ fï¿½Ã²ÃˆÂ¦dï¿½'Ã»8Ã±Ã¼[Â¡ÃÂ¹Å¡:â€ Â Â½$Ã(Ã™?â€”$8Ã‡Å½ymÃ‹@ÃŒzï¿½!â€šï¿½aÃ«ï¿½$hdu="" Ã´wlÃ¸$ï¿½iÂ°Ã¥â€°Ã‚â€tâ€¢Â¯6Ã¬fï¿½Ã˜"ÃœÂ¬Â¶:Â§q7â‚¬Ã“â€¢Ã“Ã²$â€¦â€¡ï¿½[â€ºhÃ¸lÃ¿"Â¨<â€ºtÃ¼dÂ¤~â„¢ckâ€¡â€¡â€œÃ·$â€wÃ´sÃÂ¹ÃºgÃ‹&Ãbâ€¡Â¾Â£ÃŒÃ»gÃ‚ï¿½yÂ¶Ãâ€“&qÃ´1\Â uÃº6iâ€ºÂ¶|lÃ˜ÂºÃ„Ã£="">Nn}â€¡Ã— Ã®~Ã 6\cï¿½lsÃ¬%Â¤ÂªÂ¼Fâ€”9Â¤Ã—&nbsp;,Â±â€¦â€°Å OL
Y"(	Â¶*QÃ¹4Ã–Â£Ã“â€[â€“Â¨`GÂ¿?â€2Â¼sâ€¦Â­JTÃ¾cÆ’Å’GÂ«â€ºÃ¬Ã¡lUbrÂ®â€“Â±Ã‰wÃ[ï¿½Â¼ï¿½-KLfÃ¡Ã‚Ãœ[Ã&nbsp;|ÃËœcÃ«â€˜Ã•Ã¸Ã°9Ã®Ã°zaÃ·iÃ¶b3l]"â€™.â€œâ€˜Ã‘Æ’ÃºCjâ„¢â€™8?Â°uâ€°ÃŠÃ£ ^Ã’Ã»&gt;Æ’-J\Ã¾ÃƒHÃˆË†n`â€¹â€¢ï¿½0Ã·Å“9Â¶(QÃ‰HÅ¸â€ÃŠ3Â¶*qÂ¹ÃƒÅ½Â¿
Ã²+
Ã˜Å¡Ã„&amp;X&nbsp;'Ã•7â„¢Ã…Â±%â€°ÃŒwÃ¬?Â±o&lt;`kÅ“Â°Â³A]DÂ°â€°ÃÂ³â€¡ËœÃ®ÂªÅ¡1ÃšÃ¥â€ºÃ†[â€™ÃˆÂ¤Â£Â¢Ã§ XÃ’Ã´[câ€ Â­I\~OP*{Ã&lt;Ã˜Â¢D;Ã¼f(Â½`â€˜bâ€¹â€”Ã‹`ï¿½6JÃœÂª}2FxÃ¾`â€¹â€¢Ã—3Ã¯(jÃ²Ã—Ã˜ÂªÃ„eï¿½bÃ¯8Ã„Ã¥Ã¿Ã¬Ã—/lIÃ†qÂ«ZUÂ«ï¿½Câ€¡ÃŒBÃƒNfÃÃ…Â¯dvÃ´Ã°AÆ’Ã¢Ã¢`Â«Ã¸ppexÂ°Ã,Â¤Ã€â€¢*9Âªnâ€œÃŒÃ¬Ã¿Ã·&amp;^{7Ãâ„¢Ã¯ÃŒÃºÃ¹HÃ­Âµï¿½Â½Ã«{~ÃxfQÃ‡7Ã¸mÃ¾Â®Â¹KÃ‰1Ã¨VÂ¢Ã’.Â¾Å½GÂºÂ¦[Ã‰Å¡Å¾Ã‹FkÃ&nbsp;Ãï¿½Â¤&nbsp;Â¾Ã¨Ã›â€ Â®$Ã­ÃŠ]Â´Z,QÅ¡Ã’â€¢Â¤Â¹zËœÃzË†ÃH=â‚¬Âª*,1Â­Ã‚FXÂºâ€™Â¸=	]Ãˆ|ÃªÃÃ’SÂ¨HÃ›â‚¬tCÃÂ«kÂ²vMÃ·1â€”Ã´$$t`?Ãï¿½Ht"
ÃÃ‡Ã¼CÃ@â€šÃ²â€¦.dÃ¨HPÃ¨&gt;â‚¬Å¾ï¿½Â¥GÃ·1.rÃ•Ã£AÂ´~Ã‘}=	
]GÅ¾Ã­v:gï¿½Ã¥Â©Ã!zt!pÅ¸vzÃ´$Âºï¿½Â¼Ã‘ÃÃ©)H@.Ã©BÃ²&gt;Å¾Ã½qIï¿½AÃ‚1Â¢	Å½oÃ­ï¿½â€šâ€â€Â®$-Â»Ã‹s=HÃˆ=KÃ´3zÂºâ€˜Â¸â€Å¾â‚¬â€Ã¥wÂºâ€˜Â¬Ã¯6Â§' Â¡Â¡KIÃ»â€œÃ€ÃºÂ´RJWvF@B3Â¥;	ÃºuIÂ§/Â¢kIÃºAâ€¡/!Â¢kIÂ¢Â³â€”ï¿½Ã²Â£Ã„ï¿½_Bâ€ÃÂ½5bcWÃ)Ã¯_Ã¨Ã°%DCÂºâ€”&nbsp;{:|	Ã‘)/â€°?Ã©Ã°%D#Âºâ€” :{	Ã’/Âºâ€”ËœÃ«3:{	]LLÂ³1&amp;Ã^N@t3)tÃ®,ÂºÅ¡â€”â€˜jÃ‡Ë†ÃMÃ†g:v	]NÃ„
ï¿½ÂºÅ’n'Ã¢;â€œÂµNTQ&nbsp;Ã›â€°8Â§Sâ€”â‚¬Ã‘Ã­DÂ¸R[@[ÃÃ­DÃÂ¡KÃ€Âºï¿½:u	Ëœâ€“D!6|=!Â¥t;tÃªÂ°ÃNï¿½ÂºLKBÂ¤&nbsp;GÂ·â€œ`Ã©Ã”%`}ÂºÅ¾â€otÃªÂ°â€œ&lt;8Ã½Ã›`â‚¬IÆ’Ã—â€™LÃ¨zÃÃ©Ã”%`]OÂºâ€LKBÂ¤`HÃ—`Ã¨Ã%dÂºÅ¸â‚¬Âºâ€Ã¬â€”ï¿½Â¹MKBÂ¤`LÃ·@g.AÃ‘Ã½Ã´oJg.AÃ’ÃµoDg.A;ÃÆ’Ã“ËœÃ\â€švâ€šÂ§â€Ã\â€švâ€šKâ€šÅ½\Ã‚Â¦%!RpzÃÃŸÃ¨Ãˆ%l}ÂºÂ¡Ã}Â¤#â€”Â°uÃ©â€ zG'.ï¿½KÃ©â€ Ãº6Â¦â€”Ã€%tE}KÃ©Ã„%ttE}Â£Ã³â€“Ã Ã‘ÃµlHÃ§-ÃÂ£;ÃªYJÃ§-ÃÂ£;Ãªâ€”Â¡Ã£â€“Ã°Ã‘%ÃµÂ«OÃ‡-Ã¡Â£KÃªï¿½Â¶Dâ‚¬.Â©W7tÃšÂ¾â€nÂ©W	Â·Dâ‚¬nÂ©O?Ã¨Â°%}ÂºÂ¦&gt;iâ€œï¿½ÃƒtM}Â¢Ãƒâ€“Å’Ã¨Å¡z4Â¤Ãƒâ€“Å“Ã’.Ag-QÃˆÃ¨Å¾Ãºâ€œÃ‘YKÃ¨Å¾zÃ”Â£Â³â€“(Ã=ÃµË†Å½ZÃ¢@Ã·Ã”Å¸Ã¯tÃ”â€¦â€.Âª?tÃ”â€¡]TÃ¨Â¨%Â§Â³$Ã¾Â¦Â£â€“8ÃEÃµâ€¡NZ"AÃ•â€º':iâ€°CJ7Ã•â€ºÂ³â€ÃZÂ¢0Â¢â€ºÃª
ï¿½Â´Dâ€š.Âª7Ã¯ÂµIH%tSÂ½Â¡Æ’â€“HÃ´Ã©Â¦ÃºÃ’Ã‘&amp;!â€¢ÃMÃµâ€ ZbA7Ã•:gâ€°EBWÃ•â€œ)ï¿½Â´DÃ‚Ã’]Ãµâ€ÃYÂ¢AWÃ•â€œNB-Â±&nbsp;Â»Ãªï¿½Â²Ã„#Â£Ã‹Ãªï¿½Â²Dâ€.Â«?Ã¡Å’%&amp;	]WÃº)ï¿½Â²DÃ„Ã’}uÂ¯Ã“Â¥Câ€“ËœÃ}uÂ¯â€œÃ’KLRÂºÂ°Â®ÃÃ‘	KdÃš~n:Â§â€“Ã˜Ãâ€¢uÂ¬â€ºÃ’KdztgÃÃ’câ€Ã”EwÃ–Â­ÃŸÃ¨x%&gt;tiï¿½Â²tÂºÅ¸&gt;ÃZÂ§Ã¨t%Btiï¿½Ãª%tÂ¼ÂºÂµNÃ‘Ã¡Jâ€Ftk]JÂµIHmtkï¿½Â¢Ãƒâ€¢Ã‘Â­uÅ W"4Â¦[Ã«Ã’HÃ§&amp;Â©ï¿½nÂ­SZRÃZÂ§Ã¨p%B=ÂºÂµNÃ‘Ã©Jâ€Ã¨Ã’ÂºEÂ§+Â¢KÃ«ï¿½Â®Ã„Â§Kâ€”Ã–-:^â€°OFâ€”Ã–-:^â€°ÃYÃ‡Ã¨x%:-?7iIH]-?7iIH]te]Â£Ã³â€¢Ã˜Â´Ã½ÃœÂ¤%!5ÂµÃ½ÃœÂ¤%!5Ã‘ï¿½uÅ½XbC7Ã–Â¹â€NXÃ¢2Â¦Ã«Å“â€“â€Ã”BÃ–=:aâ€°]XÃ·Ã¨â€%.SÂºÂ°Ã®Ã©Ã $uÃ}Ãµ&nbsp;Kg,1Ã©Ã‘}Ãµ@KBj&nbsp;Ã«ÃªCÅ¸YbBÃ—Ã•â€¡Â¡Â¿8ÃµÃ˜Â½)]W&amp;tÃŠÂºÂ­^:eâ€°Gï¿½nÂ«tÃŒÂºÂ«Å¾Ã1K&lt;Ã¨Â®zÃ¢:Ã†Ã„Ãµ
Ã„â€”Å’Ã®Âª'tÃ
ÂºÂªÂ¾Ã9K,Ã¨Â¦zC-Â±&nbsp;â€ºÃª
Â´Dâ€š.Âª?	ÂµÃ„ï¿½.Âª?tÃ’ÂºÂ§Ã‘QKtO=Â¢Â³â€“Æ’~Ã«
Ãº_Ã¯_Ã¿Â¹|ï¿½}ÂºÂ¦ï¿½Â±ï¿½Â¥â€™Ã¾hbmfÃ²ÃœÃšÃ§q=}Â½Ã¹ÃÃ Ã…â€œÃ®hZÃ©â€¦tM}JXÃ—ï¿½ËœÃ§Ã¥`Å 3Â»Â½&lt;Ã¾Ã‚Â£Ã¢%{&gt;â€ Â¿BÃ²Å½WÅ“y7Å“&gt;Ã¤vÂ±?}Ã»Ã­Ë†Ã‹Ã¶wWaÃ~Ã¡Â¸â€A9"XqÂ­7y^
Ã³Ã¥Ã°zMÃ¤Ã¦Ã¯ÃšÃ—KzÃ“u0Â»ÃŸÃ¨&nbsp;xÃ94qh4ï¿½=@&lt;Ã®XKÃ¿UÂ¾Ã”Â¤F'ÃºÂ¯ÃÃ;Â¾hÃ‘xÃ½/ÃËœËœÃƒÃ¬VÂ¸ÃÃ¨Ã°e^zÂ±YÃ”Â¿@Â´<s5+Ã±yÂ³ÃÅ¾!Å’)ÃŸ#Ã¦Ã¾Ãšâ€˜:Â»ÃƒÆ’ÃµÃ€Ã~ï¿½Ã˜Å’ÃtÅ½â€˜eâ€¹)xÃ¹Ã§Ã²kÃÃ.38Ãº2Ã·Ã“nÃšl&Â£aÅ¡zÂ­Â¼Ã‰07Ã³Ã¥` ÂµlÅ¸Ã°qÂ¨Ã¨uv'Ãdâ€¡ËœÃ€%ynÃÃ³ÃÃ‰ÃÃ­Â·sÅ¸Ã°rÂ¨Ã¸Ã¹Å¾Â«Â¼Ã™xÂ±lÅ¾â„¢ÃƒsÃ½Ã´ÃªÃ­Å½â€¹Ã”Ã¾'+oÃ³Â¼"Ã¦kÃ¢ÃÂ±ty|Â·Ã‹Âµ="" 3^Â©Â­kÃ³Â§Ã¹Ã„lveÂ®Â¿Ã®?lÂ½Ã™iâ€¦ÃšÂ±Ã”cjÃ­6Â³Â·Ã«Â·ÂºÃ¬oï¿½câ€“v6Â¯Ã°="" â€˜ÃÅ¸8="">/ÃÃ©Â²=mdÃ™AKECÂ»Âµ?TÃš)Ã¬bÂ¶ÃÅ¡Ã“Z?Ã‘AK5WÃ“Ã™Â¬Ã¬r1TÃ›&amp;Ã¤ï¿½Â¦Ã´Â´Ã¥&nbsp;ï¿½?L6â€ºUÃ…Ã‡9ÃÃˆÃ¥,â€”?Ã¯Ã¯Ã²,â€ºmÃšÃ¼Ã“â€”Ã½Ã®LnÂ²WÂ«Aâ€ ;FÃŸÃ¤!Ã»cÃ–}kÃ§Â¿Â£51Ã“oâ€ºu9Ã»&lt;6kÃ­Â²Â¤â€¡.Ã¥ÃOÃ§#2Ã…Ã¥@TÃ±~Å¡aÃ·Ã¶Å½Â»â€Âº_LhÃ±uÅ’â€“qâ€™ï¿½Ã§Å¸aÂ±QÂ´Ã½Â¡â€ Å¾Â»â€Ã¸k1Â»Â»â‚¬^WÃˆÃ´n{-Ëœâ€“/â€°	=yÃ™Ã©bÃ•yÃ¾ÃˆÂ¾Ã¸â€“ÃŸÂ«<iÃ¨Ã™Ã‹.Ã£Ã¥xÂ¬ÃkÂ¸Â½&Â³ÃÃ±ÃÃ¥jok"@Å¸vÃ£yÃ€vÃ„ÃºÂ¾Â³ÃÃlÃ¾1[Ã¼Ã‡Â´vixzÃ¸Â²Ãƒh=â€œÃ­â€ºÅ¾cÃ«Ã›Ã¥ 3Ã¿ÃµÃ¼Ã»sÂ¾y#-d_^Â»^o'+[Â®Â¿Â¡Ã­Ã£tvzâ€ºmÃmÃ»Ã·Ã–ny="">&nbsp;Ã‡//]&lt;Â®Â§c2Ã´Ã‹Ã˜."Ã†f~\2Ã‹SSNm\^&lt;Ã‘Ã³â€”â€”Â¾Â¬â€¡cÂ­ÃŸaâ€¹Â´vÂ¹6Â³Â§Ã‚ÃMfÃ³Ã¯)])ÂºxXÃ&amp;3ÃÃÂµPÃ³K1+â€¢VÂ²Â¦Â½Ã«!HÃ¨HÃ‘Â·ÃµlÂ¬Ã‰Ã˜Ã¢=Â­Ã¾Â°^Ã‹j<o^Å¾Å’Ã‡6Å¸Â¤tÂ¤Ã¨ÃÃ·Ã•|Ã¬Ã¼Ã Ã®â€¹]Ã¿Ã—Â¼<Ã™Ã¢ÃÃ§ÃÃ–<Ã¤Ã­c_vÂ¸xÂ·Ã‘d.Ã&Â¶Ã¤kÃÃ®Ã¸Ã‰ÃÃ•!jÃ½g go_^Ã»Â±Å½Ã2â€¡â€¡Â¦Ã¬iÃ³%_Ã½.oâ€¡_Ã¢Ãƒgâ€”Â¾Â£Ã§="" ÃÂ¯fcÅ’}Ã¦jÃ²Ã–Â¿ÃµÃ£Ã²Â¡Ã£nmÃï¿½Â¢Ã³_Â«Ã‰Ã˜Ã§sâ€œâ€Å“Ã­fq9ÂºÂ£Â¥+="" Ã—Ã«Ã‰de'Ã½fÃ¦Å¾â€”Â¶-wÂ³Â¬ÃÃ\Ã»Å¾Ã®â‚¬lÂ»yÃ†fÃÃ›dcÃ‡â„¢â€”Â±Â»Ã¿9h;â€“Ã®"Â­?Å“ÃœÃ®â€ Â­â‚¬Ã¼\ÃÂ¥Â±Ã¥Ã;â€“Ã„Ã¯â€¹Â¼Â®\ÃœÂ®Ã‡v@Â¶ï¿½7-Ãâ€™Ã˜Ã¬bÂ»xÃ‹Ã„.ÃœÂ­â‚¬Ãœoâ€¢Ãd|ÃoÃŠ{~Ã¶kâ„¢Ã™â€”Ã†Ã¯:e;="" [ÃÃ—sÂ±Ã±Å“Ã³9oâ€¹Ã˜="">}Â¡NÃ‡Ã¿*a8Ã›Å¡â€¹Ã–CQVÃ²Ã¯Ã³Ã &gt;yÃ±^Ã’Ã©lÃ½ÃµÃ®ï¿½Â¬\iâ€*ï¿½Ã¦|Ãâ€˜ÃÃ³Ã¸Ã—â€¹Â®â€¡Â¶@6Âºâ€ºÃ©!Â¢â€ nÃ§SÂ§Ã°%_[Â²Å“Ã€Ã”Ã˜&lt;â€šï¿½â€šï¿½â€º/Ã‚LÃ›Ã…3ï¿½CLLY*fÅ¾ÃŸwâ‚¬'/Â»Ã½oÂ³3Â«%Â±bf;Â¦9Ã°%q6OÃ°ÃÂ¡Ãâ€œâ€”ÃÂ®Â·Z&nbsp;Â±fÃ†Ã“*a,C|Ã£MÃÃKâ€°â€º7NÂ³ÃµÂ¦Ã“J_Ã‹ÃŸtâ€¹ï¿½Ã¨Ã¤eÂ·Ã±â€ºfÃ™~?Â¬1Â¹ï¿½-Å Ã«Ã¢bâ€¢Ã¤nB^JÃœÂ®Ã‡Â£#SÃÃ³Å Ãˆ6Ã™Ã·ÃŠuâ€“WÂµo^J|Â«ÃŸâ€¢Ã“Â±YÃ–Ã¬yÃ™VÅ“Ã½z78Ã‡Ã¦.enÃŸTâ€¢Â´oIÂ¿Ã«Ã·Â¾rÃŸ%ï¿½GEÃ¦^Â¤ZyÂ«Â¸Bâ€ .{|uÃ™â€œâ€“Ã™Ã·4a_%â€ºVÂº&amp;0rÃ™Ã«K3e9{Ã…Â®tG/ËœÃ¸Â¸Ã°OÆ’u9Ã·Ã¥?ÃšÃ°ï¿½Ã”ÃÃ¯Â¸Ã¥&nbsp;Â¿â€º-ÃŒI+â€°8Ã™Ã·Å¾GÂ¯Ã“â€“ÃƒÂ®}Ã•Â¥EÃŠï¿½Ne)ÃŠÂ¯Ã¥sÃ˜Rï¿½NMï¿½*ÂºÃ¤
_Ã½ï¿½Z*Ã¹sÃÂ³Â¢â€2e?xÂ¿'Ã«]Â¯O}
Z*:sÃ—Å¡Ã¶Â°Yï¿½Ã¯ï¿½Ã»Ã…JÃŠOcâ€“Ãª&amp;ï¿½vÂ§Â¥Â²Â¬Ã†Vz0Ã²in&amp;Æ’Ã‘x&lt;zËœÂ¯Ã”ÃµÃ“]ï¿½ÃšÃƒÃ®&lt;&amp;â€¢ï¿½Ã¨â€˜ÃŠQÃÂ»lR[Xâ€ºÃ—yÃÂ¢g*GÂ¹wÃ–Â£Â©Â³Å¾}&nbsp;â€¡*GÂ¸tÃ“Â¡Â¶ÂªÂ¶6nÃ©Â©ÃŠWÂ¨%Â³Ã¿Â³_Â¿Â¡uÃuÃ‡Ã¡pÂ¸\ÃŠ%\.%eâ€Ãâ€”	Â¡â€šÂ¬â€â€¹PFÆ’JEBh)Æ’
#Ã‚P&amp;-Ãˆ
tPÅ¸â€ÃºÃ€ÃŠZVÂ¬8Â¬s&nbsp;Â¨ÃƒÂ©â€œÂªLÂ«Râ€°6Å“Â³6Ã’ÂµMâ€”MÃš{Â®Â¡UÃ©Â¿$Ã·Å“ÃœÃ³{Â¿ÃŸÃ§Ã(Ã¬Ã‘Ã·Ã³&gt;;Ã§vÃ®Ã¹ÃÂ°Ã®sâ€˜Ã‘Â«JqgÃ‹)ZÃ¨YÂ¥8:Â¿,ÃµÃ¸â€ºbâ€Å¾U
;YnBÃY^ZÃ¹jÃŠVÂ¾Â¡:kÃ¾gÃ´Â¬RÅ“Â£â€™Ã‚Â²Ã²8dkÂ¿.Ã¨YÂ¥0Ã½â€™Ã˜ËœÃ•zW)ÃŒi?AÃ‰Ã®&gt;Â«&lt;Ã´Â®RTÃ›eDï¿½YÃ³Ã‹â€°VÅ ZÃ»7Â¢F+ï¿½Ã“Ã¥â€jâ€˜^V
ZÂ¤Ã“	Ã•&lt;&lt;Â¬ÂµÃ¦Ã§Â°wÅ“^VÅ Â©ÃÃ¥Â«BO+Ã…Â¥Ã‹	VJO+Ã…ÃœÂ¤Ã‹	Â½Â¬Dâ€¡.zY)F?%JCO+Ã…LÃ‘Ã¡â€â€¹Å¾VÅ Â¹@â€¡Â¬Å’Å¾VÅ Â¹Mâ€”Â¬)zZ)â€ '\Ã´Â²RNÂ¸Ã¨eÂ¥ :Å“pÃ‘Ã‹J1St8Ã¡Â¢Â§â€¢bfÃ©pÃ‚EO+Ã…ÃŒÃ“Ã¡â€â€¹Å¾VÅ Â¡Â»	XBo+â€¦ÃÃâ€Å’ÃV
Â¡Â³	Ã™Mz\)`Å“Ã&amp;h5z^Ã‰oâ€Â®&amp;lÃ´Â¼â€™Å¸â€°RÃ½Æ’ÃWrÃ“#Q.z_Ã‰Â­I7:z`Ã‰kÅ N&amp;t
zaÃ‰Ã©$ï¿½LÃ°Ã¨â€¦%Â§Ã³t1Ãâ€ºÂ¢'â€“|Â¾H&gt;zbÃ‰gÅ“&amp;|OÃK.Â¯Ã“ÃDâ‚¬ÃXrÃ¹ÃKvÃ‘#Kâ€¹t/1&nbsp;Gâ€“&lt;Ã¨ZÂ¢@ï¿½,yÃÂµD!Â£Wâ€“Ã¨ZÃ¢@Â¯,9ÃÂ±Ã„Ã¡=Â³Ã´Å½Å½%Ã´ÃŒÃ’;Âºâ€¢H$Ã´ÃÃ’3Âºâ€¢HdÃ´ÃÃ’3Âºâ€¢XÃ;KÃÃ¨Tb1N-Â½Å¡Â¥[â€°=Â´Ã´ÂªAÂ§Â®Ã»Ã¿oC-=Æ’zâ€°Ã€Ã’}kÃ’CKÂ¯&nbsp;^bÂ°pÃ¯_:Ã´ÃÃ’â€œÃªâ€“Ã±y*ËœÃ˜Ã[Ã‹Âºâ€™ÃªÃ–Ã–Ã”WÃŸÃ¸+ï¿½JÃ€Ã®{MÃ{Ã‹ÃšVÅ¾â€¡'&gt;{Ãª7Ã—â€“3*â€”Ã¨ÃŒÃ’â€ºÃ‹jâ€™Â´1Ã´Ã¸Â¾#/Ã¿Ã¶Ãš-Âºâ€™Â¸ÃÃƒÃ‹Â£Â¤ï¿½Ã¡Å¸?Ã»Ã³woÃ¨ypï¿½_â€Ã–Â¶Ã®|jÃºÃ”Ã¸&nbsp;Ã›Ã•Ã§â‚¬@Ã®â€œ4?ÃºÃœKÃ§Â¯Ã’YÃ„L?&amp;ÃŒHÂª[Ã†&gt;vÃ¤ÃŒÃ…ktÂ±Â£Cï¿½;â€™ÃªÃÃÃ½Ã‡Â¾OÃ— ]=Â¬Â¼&gt;|Ã°Ã¸[t
rï¿½CÃ´*ÃµÂ­Â»Ã¶Ã¥/tÃ’Ã­fwÃ¿Ã•Â¤â€œË†ZÂºylÃ¯Ã¡Ã“Â¿Â¸Å½â€“ Ã¿sÃ·â„¢8OWÂ³FÃ«ÃˆÂ¹?ÃÃˆCÃ¨,Ã¢U;Ã¼Ã¦=Â¿ÃœÂ«sÃ§Å¸tÂ±JÅ¡Ã»Â¿= ï¿½DÂ§Â§ÃŠcÃ»Â¾vï¿½Å¾^rÃ§5AÃ‡Â£dÃ‹Å¾Ã¨Ã±Ã¥â€˜VÃ¾Ã”Ã¨&gt;Â¢â€œ4Ã¿&lt;Â½Â¼Â¬"[Ã¹sâ€.$6â€ºFÅ¸Ã½=Â¼Â¬jÂ©Ã›Ã½ï¿½H\â€™ÃÂ§ÃdÃ´Ã¬Â²6:â€™Â¨TFÃšÃ©Ãe=t%1Iwâ€ºÂ£Ã·â€“uÃ‘â„¢D$9vâ€¦Å¾[Ã–â€œÃ©â€˜pgxÅ¡Å¾[zpâ€ºÃ®$Ã©Â±Â¥Ã­â€.%Ã©NzkÃ©IFâ€”ï¿½AzjÃ©]J,*Ã´ÃÃ’Â«Âºâ€¢HÃ;KÃ¯Ã¨VÃ¢@Â¯,9Ã”Ã©ZbÂ°@Â¯,yÃÂ¹D`Ë†ÃXrÂ¡{	_JO,Ã¹tÃ¨bâ€šG/,yÃ‘Ã…â€-Â©Ã‘Ã»JnzMâ€Â©AÃ+ÃÃ•â€Â¬Ã’Â¦Ã—â€¢Å¡t7Â¡Ã‡â€¢BÃ¨nÃ‚â€¢ÃÃ“J1t8Ã¡zÅ’Å¾VÅ Ã©ÃÃ¥â€J/	oÃ‘Ã©â€ÂªA+EÂ¥t;aJÃ©aÂ¥Â¨Å’Å½'LCÃ´Â®ROï¿½jÃ´ÂªÂ²-:Å¸Uâ€“Ã©Ue#Ã¨~Ã‚â€œu3zUÃ™:&nbsp;Ã°Ã”&lt;Â±Â¿LÃ’â€¦&amp;Ã½TÂ·sÃŸâ€¦;Â«\^Â¬Â¢
ÃÃ Ã·Ã•;Ã‚;tBï¿½Â©,Ã’Æ’ÃŠF-Ãâ€¦eÂ°{â€¹^T6Å Å½((	Â½Â¦Ã´AJgâ€™â€ ~;â€â‚¬Ã( )Â½Â¥Ã´ÃQ@nÃª%â€:Â¤`Â¤Ã=Â¦Ã´]R(zHÃ©:Â¥@$[Ã¨!Â¥oÃ¨ËœÃ‚PÂ¿AÃ¯(}CÃ‡â€Ãšâ€œÃ´Å’Ã’?tM!Â¨OdÃ´Å’Ã’?Ãâ€œÃ¿?Ã¾CzEÃ©':(Ã¯5&gt;Ã±zCÃ©Â«I:)ÃUwÂ¿Â¶Do(Ã½E7Ã¥Â·Â¤yÃ¢zAÃ©3:*Â¿Ã•Å¸~;Â£â€&gt;â€ºÂ¥Â«Ã²YÂºÃ£â€ºÃ‹Ã´â‚¬Ã’wtV&gt;Â«O]Â¢Ã§â€œÃ¾Â£Â³Ã²XÂ²Ã½Ã•[Ã´|Ã’stXÃ¾ÃšÃ´ÃŒez=)â€“Â¿FÂ¿Â¡_AÂ¢ÃƒÃ²VÃ­Ã€Â»Ã´vR:-O%c__Â¢Â§â€œrÃmyÂª&gt;ÃµÂ½Å“â€dÅ½Å½Ã‹KÃ©Ã¸Â«Ã´pRÂº./
|zÅ½ÃMJCÃ—Ã¥Â£tÃ¬=â€ºâ€Â§MÃ·Ã¥Â¡ï¿½CÂ§gâ€œÃ‘}Ã¹'ÃÃ¾-z4)Ëœ6Â¾Bï¿½&amp;ejÃ’â€¦Ã¹&amp;mÃ½â€ÃLÃŠE'Ã¦â€ºÃ/ÃÂ¤'â€œrÃ‘â€°yÂ¦2Ã±Kz1)YJGÃ¦â€”Â¡Â£Ã´bRÂ²Å’Å½ÃŒ+â€¢=oÃ‘Æ’IÃ©Ã¨ÃŠÂ¼2Ã´=â€”â€ï¿½Â®ÃŒ'Ã•Â½Â¿Â£Ã§â€™Ã²-Ã‘ï¿½Ã¹#iÂ¾HÂ¯%.ÃÂ¡Ã¹Â£~hÅ¾K\&nbsp;CÃ³FÂºÃ³{Ã´VÃ¢Ã„ï¿½Å¡/â€ Å¾Â§Â§GÃ¨Ã”<qÃ»Ã¤ez)qâ€nÃÃ‰Ã˜Ã‹Ã´pÃ¢jï¿½Â®Ãsz(qÂ¥cÃ—Ã¦Æ’dÃ¼5z'qâ€¡ÃÃ[Â¦Â¯Ã’3â€°;tnÂ¨Ã­Ã½â€¢Â¾â€º"Ã’Â¤Æ’3 ÃÃ¾Ã’Â¿Ã©â€¢Ã„Â¡9Âº8Ã³6?7gï¿½$nÃ‘Ã…yâ€”Ã®Ã¾â„¢="">â€ºÃ¢B'gÃÃ°	}6Eâ€ NÃÂ¸M.Ã“â€°c3ttÂ¦%Â£Â¯gÃ´BÃ¢]ï¿½iÃµÃ©%zqÅ½Â®ÃÂ²Ã¤#Ã¯Ã‘Ã³Ë†{tvâ€“
ÃŒÃ¨Â³)BmÂº;ÃƒvÃ&nbsp;Ã—Ã€Ãï¿½]â€º^Â¡Ã‡Å¾]{nÃ’Ã›â€šÃÂ¬ÃšiÃ½â€™Ë†]Å¾Y;Â¯ÃÃ“câ€ NÃÂ¨ÃŠâ€”;Ã´4Â¡Ã›3jÃ«Ã©aâ€BÂ·gSÃ²Â¬^Ã‘Â¢Ã£Â³iâ€º~IÃ„Â«EÃ—gQÃµhFÃ¯"Ëœ:?â€¹Zâ€”Ã©YDÃ§gP}F/â€°ËœÃ‘Ã½Ã™â€œÃ¬Â»Nï¿½"$:@{â€ Â¾Ko"Â¨&amp;]&nbsp;5Ã‰Ã“Ã¿Â¢7TF'hMÃ³Ã—Ã´$Â£4Â¦rÂ¤C/"0ÂºAcÅ¡Ã¯ÃÆ’mâ€“Å½Ãâ€Ã´3Ã´Ã‚Â£+4eÃ°MzÃ¡Ã‘Å¡2râ€°Å¾Cxtâ€¦Â¦Å’Ã“kË†tâ€¦Â¦l[Â¦Ã§^ï¿½ÃÃâ€™3Ã´b@â€ºÃÃâ€™msÃ´Ã‚â€ºÂ¤34d?=â€ X0GwhÃˆÃ¦Ã›Ã´bÃÂ¡Ã‰Ã±[Ã´bÂ¢WÃ¨)Ã„:D3j?ÃÃ¨-Ã„ÂºD+â€™Ã©%Ã„Ë†â€nÃ‘Ë†ÃºÅ¸Ãµâ€™ï¿½;Ztâ€¹F<i!vdtâ€¹64nÃ©%!Ã¿eÃ‡hÃƒÂ®ez1Æ’Å½Ã‘â€Ãª%zÂ±Æ’Â®Ã‘â€ }6Ã‰Ã¿Ã‘5zp}Å¸^a="" Ã‰Ã¨="" Ã˜Ã±Â½â€šxbÃ·ÃˆÂ«~ï¿½Ã@liÃ©"qzÂ¤7s&Ã©"iÃ©="" zÂ±eâ€ nâ€™6ÃœÂ¡'cÃ¨$aÃ‰Ã¡Å’^@Å’Â¡â€ºâ€5ÃµdÃˆÃ¨&yÃ©3Ã´Ã½Ã…Å“:]%jÃ°Å¸Ã´Ã½Ã…Å“yÂºjÃ”="">}7Ã‰CÃ¨*IÃ•Ã“Ã´ÃµÃ… :KÃ’Ã¨UÃºÃºbï¿½%(ï¿½Â¼E__JÃ©09Ã•sÃ´Ã±Ã…Â¢&amp;gÃ¤}ÃºÃ¸bÃ‘$&amp;&amp;â„¢&nbsp;o/6Ã‘eb*â€¡Ã¨Ã“â€¹Mtâ„¢ËœÃŠ%ÃºÃ´b]&amp;&amp;]Â¤O/6Ã‘ebÃšÃ´Ã¥Ã…(ÂºLLâ€¡Â¾Â¼Eâ€”â€°Ã‘#!ï¿½Ã–Â¤Ã“â€Å“Â¤/VÂµÃ©6!Ã­ÃºÃ²bTFÂ·	â„¢Â¥/fÃ‘m2ZÃ´Ã™Ã….:NÃ†}vÂ±â€¹Å½â€œA_]Â£Ã£DLÃ’WÃƒÃ¨:Ã´Ã‘Ã…Â²â€Ãï¿½ÃGÃ‹fÃ¨&gt;Ã³Ã´Ã‘Ã…Â²9ÂºO@7Â£Â¯.â€ etÅ¸Ã®Â¥o.Â¶Ã‘ï¿½ÂºG_\Å’Â£uï¿½Â¾Â¸GÃªÅ“~HÃˆÃšÃ¨Bï¿½Â£.Ã–5Ã©D;I\Â¬â€ºÂ¥ulÅ¡&gt;Â¸ËœG7Ãª}nÂ±ï¿½nÃ”Â­Ã‘Ã§Ã»Ã¨HÃZ&nbsp;Ã-Ã¶Ã‘â€˜:Â¥'BÃ–GWÃªTwâ„¢&gt;Â·Ã˜Ã—Â¦3uÂ¨N[Â¼@wÃªPÂ·C[|@wÃªï¿½	Ã©Eâ€¡Ã•â„¢}jÃ±]Âª3Ã´Â¡Ã…tÂªÂ®ÃwÃÂ­Âº1Ã™Â½NZ|AÃ‡Ãª}eÃ±	]Â«Ã´â€˜Ã…'tÂ­.Ã”Ã©#â€¹OÃ¨\]&nbsp;o,^Â¡su`}cÃ±
ÃÂ«ÃƒÃ´ï¿½Ã…+tÂ¯Ã'Â¿ÃÂ½â€“/Â¡O,~iÃ“Ã…â€“Â®JÅ¸X<c[ÂºÃÃ´â€¦Ã…3tÂ±Â¥Â¢ ,Â¾Â¡â€œ-Ã›}`Ã±="" ï¿½lÃ™Ã†Ã©â€¹oÃ¨dÃ‹Â¶ï¿½="">Â°Ã¸Â¦E7[Â®Ã´ÃºÃ€Ã¢:ÃšrÃ•Ã©Ã³Å Ã¨hÃ‹Âµï¿½&gt;Â¯Ã¸Â§CW[Âª	ÃºÂ¼Ã¢!ÂºÃš2U&gt;G_W<dg[Â¦ï¿½Â³Ã´uÃ…gtÂ·%Ã¾=}\Ã±Ãmâ€°Â¶_Â£ï¿½+^Â¢Ãƒ-ÃÃ®%ÃºÂ¶Ã¢%:ÃœÃ’$Ã¨Ã“Å Å¸Ã¾ÃƒnÂ£Ã„@qn&â€“ÃšÂ¤â€¹ï¿½ Ë†="" "ÂºÃ›Ã¬$hi9â€¦a-,Ã¬,dÂ°1Ã•"zÂ¦ËœdÂ°0rÃ¿ï¿½jÂ¸Ã®ÃÃ¹â€“pÂ¸Ãâ€Å¾nÃŠÃ†:Â­jÃ‘Ã“mÃ™<Â§Ã‹Âª="Ãâ€ï¿½Â·tYâ€¢zÂ¢Â·Â²Â³Â¤Ã‹ÂªÂ½Ãï¿½Ã©VÂ­Ã¨Ã­â€ ÃŒ~Ã‘aÃ•Å ÃnÃˆÃ®Å Â«Vâ€”Ã´x3Ã¦k:Â¬Zï¿½Ã‘Ã£ÃËœÃ“]UkÂ¤'qHwUÂ­â€˜Å¾Ã„ÃUÂµ<" iÃ€â€œï¿½fzsÂºÂ«j}Â£Ã‡â€ºÂ±owuÂ­zÂ¼{twÃ•Ã²$Â¤ï¿½â€˜Å¾Ã„Å’Ã®Âªz#="â€°)ÃUÂµÃ´x3Â¦tWÃ•ÂºÂ¢Ã‡â€ºqOwUÂ­Ã´x3Ã–tWÃ•ÂºÂ¡Ã‡â€ºAgUÂ¯;zÂ¼tVÃµz&nbsp;Ã‡â€ºAgUÂ¯gzÂ¼tVÃµÃºMï¿½7Æ’ÃÂªbÅ¸Ã¨ÃµFÃUUÃ¬Ëœ^o]UÃ…Â¾Ã’Ã«ï¿½&nbsp;Â«ÂªÃ˜wzÂ½tUÃ»IÂ¯7â€šÂ®ÂªbKzÂ½" 3ÂºÂªÅ yÃ’Ã€(obbwuÂ±qÅ¾Ã„â€šÂ®ÂªbÅ¾â€4Ã°hÃ7ÃÃ‡iÃ¯Â·Â¢Ã§awuÂ±wzÂ½tu5Ã»@Ã7ï¿½Å½Âªf[Ã´|Ã¨Â¦jÃ¶gbÃ¯7â‚¬Å½ÂªfkzÂ¾="" tt5[ÃÃ³mÂ Â£ÂªÃ™gzÂ¾="" tt{Ã›Â¦Ã§â€º@wuÂ±szÂ½tuÃµÃº{dÂ¯7Ã¡â€šÃÂª^Ã—Ã´zÃ¿Ã£Å¸ï¿½ï¿½â€°Ã¡Â§="" endstream="" endobj="" 5917="" 0="" obj="" <<="" bitspercomponent="" 8="" colorspace="" devicegray="" filter="" jpxdecode="" height="" 765="" intent="" relativecolorimetric="" length="" 30351="" name="" x="" smask="" 5916="" r="" subtype="" image="" type="" xobject="" width="" 787="">&gt;stream
jP  
â€¡
ftypjp2 jp2 jpxbjpx rreqÃ¸Ã¸â‚¬@ .-jp2hihdrÃ½colrvjp2cÃ¿OÃ¿Q)Ã½Ã¿RÃ¿\#B@HHPHHPHHPHHPHHPÃ¿ï¿½
?Ã¿â€œÃ&nbsp;Ãˆ\Â®Fâ€˜Ã¬â€“ÂªQv~}Ã &nbsp;M!â€ Ã¿Ã‰Ã±cÃŒCÅ½Ã¨GÃ¨Ã‹â‚¬Ã£W	S Ã¸Ã‹â‚¬â‚¬Ã¿ï¿½
5Ã¿â€œÃŸpÃ¨Y.:)Â¯Ã³|Ã½Â½â„¢Â¹AÃ¢GÃšï¿½ÃƒÃ¾/Â³&amp;Ã¾ÃšÃƒÃ â‚¬tâ‚¬â‚¬â‚¬â‚¬Ã¿ï¿½
SÃ¿â€œÃŸY`gÃ¥Ã´Ã¥	e~;Ã•jÃÃ¶LpCÂ¶q'Ã£Â¿ÃŠ9@vÃŒÃ„u)â€”Ãš2ï¿½Â«FÃ¡FÅ¡qâ€ºÃ™Ã¤Â­Æ’qÃµ+Ãaâ‚¬Ã°Ã â„¢ï¿½Ã—ÃŒO!Aâ‚¬â‚¬Ã¿ï¿½
Ã¿â€œÃÂ´Pâ‚¬â‚¬â‚¬â‚¬â‚¬Ã¿ï¿½
1Ã¿â€œÃŸXÂ°[Ã†Å¡7â€â‚¬.Å¡Ã»Ã¸44ÃµÂ´cÂ¼bÃ½^ÂªÃ¸@TÂ·Ã¯Ãœâ‚¬â‚¬â‚¬â‚¬Ã¿ï¿½
[Ã¿â€œÃŸYÂ¨$6Â¼Ã¯!aÂ¹9TÂ¡^&gt;Ã•Å“Â¤Ã«_"-Ã™$Å½KÃ¦ÃœaÅ¸dqÅ“hâ‚¬Ã¾â€”'eYQ/Â¦Wy1Â¿â€ºÃˆÃºÅ¸Ã«ssÃ±Â¯4Ã§XÃ±Ëœ+Ã£Å½Ã¯Ã–Â·oIâ‚¬â‚¬â‚¬Ã¿ï¿½
\Ã¿â€œÃŸYÂ¨31ue	Å“ÃÃ°\Ã®Â©ZU6MÃŠÃ†Â¡ÃºÂ²CÅ¸Â¯Ã¶Ã³mQÃ¿TÂ·oâ€¹Â»Ã‰lÃ¶!NÂ®c6Â¡Â£ÃŠSÂ¾EÃ±Â¤aÃœ^â€™ÃŠâ‚¬Ã£â‚¬Ã§,xZ.â‚¬â‚¬Ã¿ï¿½
Ã¿â€œÃÂ´Pâ‚¬â‚¬â‚¬â‚¬â‚¬Ã¿ï¿½
TÃ¿â€œÃŸYx#Å¡â€¡ÃŒ+ÃŠbjÃ®Æ’Ã¥!Ã¦Â®?ï¿½Â§V}Ã*Ã‡Ã”&gt;Ãƒâ€ LÃ½Å¾â„¢LGÃ‰
x6=cÃ‚Ã¹gÃ±â€¹wÃÃ¾,Ã—1â‚¬Ã¢â‚¬Ã§Sâ€˜"â‚¬â‚¬Ã¿ï¿½
	[Ã¿â€œÃŸBÂ°Â¯ )&nbsp;Å¸â€º
Â¬Ãƒw%Â¬
Â·Ã¬|Ã¨Ëœ(ÂµÂ¶AÃ‘Ã¢&amp;Â©Ã•â€Ãœâ€”ÃÃ¼Â³Å¸
Ã¹PÅ’Ã™Â·Ã‰Ãâ€˜`GÃŠÃ§Ã»â‚¬Ã£â‚¬`1â€”lâ€ â‚¬â‚¬Ã¿ï¿½

LÃ¿â€œÃŸY@Ã‡â€â€¡&gt;56Â¬`OÅ¸â‚¬Ã˜ÂºÂ¢1jÃ“ÃµÃµUÃÃ›â€šÂ¶Â±mÃ‡YsÂ¬CÃ·Ã³Ã¦Ã®7ÃºÃ°Ã ;gwvoï¿½Ã³Ã¢â‚¬UÃšdÃ˜â‚¬â‚¬â‚¬Ã¿ï¿½
Ã¿â€œÃÂ´Pâ‚¬â‚¬â‚¬â‚¬â‚¬Ã¿ï¿½
IÃ¿â€œâ‚¬Ã€Ã¡Ã tâ‚¬ ?Â°Â³Ã|,â€¹BPV1pÅ½Ã±(	â‚¬Å“Ã¨VÃ«0NÆ’H+^{Â¶Ãƒâ€¹Å â€¹Ã»Ã¥â€¹ÃƒÃ†yNÃ—â‚¬Â¢Â¦&amp;Ã¿ï¿½
HÃ¿â€œÃâ€ZÃ€]Â¾KÂ¤#Ã­â€ºwÃ´Gâ€š_Â®Â¸Ã„Ã¸8&gt; Ã¸@C(Ã¡_Ã™^2â€!Ã´Å“ =Ã¨â€”Ã°lGbÂ¥Ã‰Â¡Âµâ‚¬Ã¿ï¿½
Â£Ã¿â€œÃ‡Ã†F&gt;#Ã²@[Ã–&gt;Ã¬Â¨ÃÃŸRxtÂ®tlFÃ§1Ã¸Â¼ï¿½eÃ·Ã©Ã’Â­C&lt;Ã¨â€°I
GÃ«Â«)AÃŸqÂ¢1Ã‰Â«|Å½Â¢KÃ‰Ã³ÃœRÃ´Â¯Ã°Ã¡Ã´RÂ±ï¿½ÃMxâ€¹Ã„8Â±#ZÃªu#pâ€Ã’Å â€˜Å¡Â¾Å’oÂ½â‚¬Ã±'Ã¼Â¦â€¡lÃ­ÃŒlÃ–Å½lÂ¡
â€™â€”ÃÃ³jâ€ºwÂ°Ã£Å¸Ã¡xÂ­1Ã°Ã€]Â¾_09ÃŒÃ¿ï¿½
Ã¿â€œâ‚¬â‚¬â‚¬â‚¬â‚¬â‚¬Ã¿ï¿½
EÃ¿â€œÃï¿½D&lt;,&gt;Ã€`â€”â„¢Ã¶Ã†U]Oâ„¢Ã–E\Ã§Â¢Âº#Ã©Ã¼Ã´//Ã–sÃÅ“Â³PQÂ°â‚¬ÃŠ+Â°@Ã•Ã°H@
Ã­â‚¬Ã¿ï¿½
Â°Ã¿â€œÃ‡Ã„^&gt;#QÃ±1[EkÂ­Ã™Â¹BÃŒâ€Âª.â€¹`Ãªâ‚¬â€“ï¿½geMÃ½m3.VÅ Å Â»tÃšÃ¹Å¡Ã¥MÂ¿kÅ¸4-Ã³vGF3kÃ¬\oH,,Ã¥ÃÅ½1Å’nÃ¸ÃÃ¢Ã€HÂµ,Å¾Ã‘ÃÃ­S\Ã'Âº 7.]Ã¯Ã­Â«â„¢EÂ¤Ã» 
Â½C_Ã†Ã²Ã˜&lt;Ã¢Ã°Ã¼@D5â€ºT.Ã‰"TÅ¸p\MÂ¥;JÅ Ã†â€“Â¦Ã„ÃµNÃ¢E*Ã›&nbsp;OwÃ¿ï¿½
Â­Ã¿â€œÃ‡Ã„b&gt;"Ã±Ã±â€¢1`â€”Âµâ€œC4Â¼Ã¥ÂºÃ™ÂºÃ…XÅ¡Ã„Â«:Â¶â€šÃ â€¦ÃšÅ“?ÃÃ–Ã„2;Ã‘dÃ„Ã¢Ã¸Ã™Ã¬Ã·Ã·?Â¨(Ã‡ÃŠTÃ‡Â¶Ã¸XGÃ¶â€˜!Â¡8?ÃŠÃ¼Ã¸Â®â€™Ã—â€ºoÃ»Ã±
-9qÂ«â€ 7Mâ€”UÂ³ÃšÂ±EÃ¢(Ã³ï¿½Å¡Â»UÃ¬DÃ·Â¹Â°Â¤ËœÃ â€ºÃ‚Ãâ€˜â€¦Â¤Â²Ã£caâ‚¬{Ã¸ÃÃšOÃœÃ’VÆ’"4\
ÃˆÂ¢Å’BÃƒPÃ€0Â±â€Ã²Â­&amp;Ã¿ï¿½</dg[Â¦ï¿½Â³Ã´uÃ¥gtÂ·%Ã¾=}\Ã±Ã½mâ€°Â¶_Â£ï¿½+^Â¢Ã£-Ã¯Ã®%ÃºÂ¶Ã¢%:Ã¼Ã²$Ã¨Ã³Å¡Ã¿Ã¾Ã£nÂ£Ã¤@qn&â€“ÃºÂ¤â€¹ï¿½></c[ÂºÃ­Ã´â€¦Ã¥3tÂ±Â¥Â¢></i!vdtâ€¹64nÃ©%!Ã¿eÃ§hÃ£Â®ez1Æ’Å¾Ã±â€Ãª%zÂ±Æ’Â®Ã±â€></qÃ»Ã¤ez)qâ€nÃ­Ã©Ã¸Ã«Ã´pÃ¢jï¿½Â®Ã­sz(qÂ¥cÃ—Ã¦Æ’dÃ¼5z'qâ€¡Ã®Ã­[Â¦Â¯Ã²3â€°;tnÂ¨Ã­Ã½â€¢Â¾â€º"Ã²Â¤Æ’3></o^Å¾Å“Ã§6Ã¿Â¤tÂ¤Ã¨Ã½Ã·Ãµ|Ã¬Ã¼Ã Ã®â€¹]Ã¿Ã—Â¼<Ã¹Ã¢Ã¯Ã§Ã¯Ã¶<Ã¤Ã­c_vÂ¸xÂ·Ã±d.Ã¯&Â¶Ã¤kÃ¾Ã®Ã¸Ã©Ã¯Ãµ!jÃ½g></iÃ¨Ã¹Ã«.Ã£Ã¥xÂ¬Ã¡kÂ¸Â½&Â³Ã­Ã±Ã¯Ã¥jok"@Ã¿vÃ£yÃ vÃ¤ÃºÂ¾Â³Ã½Ã¡lÃ¾1[Ã¼Ã§Â´vixzÃ¸Â²Ã£h=â€œÃ­â€ºÅ¾cÃ«Ã»Ã¥></s5+Ã±yÂ³Ã¯Å¾!Å“)ÃŸ#Ã¦Ã¾Ãºâ€˜:Â»Ã£Æ’ÃµÃ Ã¾~ï¿½Ã¸Å“Ã¯tÅ¾â€˜eâ€¹)xÃ¹Ã§Ã²kÃ¾Ã¯.38Ãº2Ã·Ã³nÃºl&Â£aÅ¡zÂ­Â¼Ã©07Ã³Ã¥`></y></dÃ»:â€ÃªsmlÃºryÂªÃ¯ï¿½b></cÃ«xj></vÃ¼â€¡Ãºâ€ Ã©'â€°ï¿½k]â€“'ÂªÃ¨|9Ã¢Ã¨Â·[Ãªr"bâ€ #Ã£â€œ[mÃµÂ¦_ql]yÂ¨Â¾Ã©Â½9Ã£vÃ±Â¤<\Â­ï¿½#(â€°Å¾ÂµzÂ¤qÃ¹â€˜b></rf8jâ€œ3Â¹'yÃ—Â³Ãªz2ï¿½):8gl{bucï¿½Ã¥:Ã¨Å¡Å¾Å“â‚¬â€™*eÃ¦2Ã½Ãºv9ÃµÂ¦;@Ã¬qÂ¥ï¿½bËœÃ¾ÃªÂªÂ©zÂºÂ©Ã±></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://equitablemath.org/wp-content/uploads/sites/2/2020/11/1_STRIDE1.pdf">https://equitablemath.org/wp-content/uploads/sites/2/2020/11/1_STRIDE1.pdf</a></em></p>]]>
            </description>
            <link>https://equitablemath.org/wp-content/uploads/sites/2/2020/11/1_STRIDE1.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26188717</guid>
            <pubDate>Fri, 19 Feb 2021 02:15:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[5-MeO-DMT: The Story Behind the 'â€œGod Moleculeâ€ (2020)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26188612">thread link</a>) | @mardiyah
<br/>
February 18, 2021 | https://doubleblindmag.com/5-meo-dmt-the-story-behind-the-god-molecule/ | <a href="https://web.archive.org/web/*/https://doubleblindmag.com/5-meo-dmt-the-story-behind-the-god-molecule/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>The Colorado River toadâ€”a.k.a. the Sonoran Desert toadâ€”is flat and squat. No distinctive markings adorn its swampy olive skin, and while a passerby may remark upon its large size, the toad does little to draw attention to itself. And yet, for an animal so easy to miss or ignore, the amphibian provides a surprising asset for psychonauts: The Colorado River toad is the only animal source of â€œthe God moleculeâ€â€”5-MeO-DMT.&nbsp;</p>
<h2 id="h-5-meo-dmt-sonoran-desert-toad-venom-synthetic-psychedelic-plant-medicine-or-all-three"><span id="5-MeO_DMT_Sonoran_Desert_Toad_Venom_Synthetic_Psychedelic_Plant_Medicine_or_All_Three">5-MeO DMT: Sonoran Desert Toad Venom, Synthetic Psychedelic, Plant Medicine, or All Three?</span></h2>
<p>5-MeO-DMT is a potent psychedelic found within the excretion of the Colorado River toad (<em>Bufo alvarius </em>or<em> Incilius alvarius</em>). Although, itâ€™s also present in some plants and can be <a href="https://doubleblindmag.com/toad-venom-vs-synthetic-5-meo-dmt/">made synthetically</a>â€”the latter being the most sustainable way to consume the entheogen. It belongs to a class of chemical compounds called <a href="https://psychedelicstoday.com/2018/01/05/psychedelic-tryptamine-chemistry/">tryptamines</a>, which include psilocybin and DMT (N,N-dimethyltryptamine).</p>
<p>In the United States, the Colorado River toad is one of the most common and controversial sources of 5-MeO-DMT. Its native habitat runs along the southwestern United States and northern Mexico. But, the oldest known uses of 5-MeO-DMT come from South America. The chemical is a natural constituent in <em>Anadenanthera peregrina </em>seeds, which are used to make entheogenic Yopo snuff.&nbsp;</p>
<h3 id="h-5-meo-dmt-trip-how-long-does-it-last"><span id="5-MeO-DMT_Trip_How_Long_Does_It_Last">5-MeO-DMT Trip: How Long Does It Last?&nbsp;</span></h3>

<p>5-MeO-DMT produces an intense but short psychedelic experience. A full dose 5-MeO-DMT trip lasts between 30 and 90 minutes at most, and the majority are even significantly shorter than that. However, while the time on the clock may tick away quickly for those on the outside world, it certainly doesnâ€™t for those in the middle of the psychedelic experience.</p>
<p>During a 5-MeO-DMT trip, itâ€™s not uncommon for consumers to feel like theyâ€™ve transcended time. A 5-MeO-DMT trip is strong enough to take participants out of normal consciousness, into a state of temporary unconsciousness, with <a title="" target="_blank" href="https://doubleblindmag.com/ego-death/">ego death</a> making room for therapeutic exploration of the subconscious or an encounter with the divine. For this reason, a <a href="https://doubleblindmag.com/trip-sit-lsd-psilocybin/">trip sitter</a> plays an important role in monitoring the participant while theyâ€™re on their journey.</p>
<h3 id="h-5-meo-dmt-average-dosage"><span id="5-MeO-DMT_Average_Dosage">5-MeO-DMT Average Dosage</span></h3>
<p>The average dosage of 5-MeO-DMT is small compared to many other psychedelics. Researchers report that <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6292276/#:~:text=5%2DMeO%2DDMT%20appears%20to,with%20consumption)%2C%20which%20requires%20further">five to seven milligrams</a> are enough to occasion a moderate to strong experience. Those using toad secretion rather than synthetic 5-MeO-DMT often <a href="https://www.forbes.com/sites/davidcarpenter/2020/02/02/5-meo-dmt-the-20-minute-psychoactive-toad-experience-thats-transforming-lives/#398c2d2338a1">take doses of up to 50 milligrams</a>. Itâ€™s risky, however, for new consumers to start with such a dose, which may be overwhelming and more likely to cause negative reactions.</p>
<h3 id="h-how-do-you-take-5-meo-dmt"><span id="How_Do_You_Take_5-MeO-DMT">How Do You Take 5-MeO-DMT?</span></h3>
<p>5-MeO-DMT is most often inhaled through a vaporization device. Both synthesized 5-MeO-DMT and powdered toad venom comes in a crystallized or viscous form, and theyâ€™re often smoked using a high-heat pipe or rig. The active effects kick in within a mere couple seconds after inhalation, causing consumers to lose their sense of motor control and retreat inward into the depths of their consciousness.&nbsp;</p>
<h2 id="h-5-meo-dmt-vs-dmt"><span id="5-MeO-DMT_vs_DMT">5-MeO-DMT <em>vs</em>. DMT</span></h2>
<p>Dimethyltryptamine (DMT) is the active chemical component in <a title="" target="_blank" href="https://doubleblindmag.com/what-is-ayahuasca-iowaska/">ayahuasca</a>, famously dubbed â€œthe spirit molecule.â€ Itâ€™s what thousands of tourists seek out during psychedelic pilgrimages to Latin America every year. DMT can also be smoked on its own, occasioning a more rapid, intense trip than the hours-long ayahuasca experience.&nbsp;&nbsp;</p>
<h3 id="h-5-meo-dmt-is-different"><span id="5-MeO-DMT_is_Different">5-MeO-DMT is Different</span></h3>

<p>Itâ€™s a derivative of DMT, meaning that they are related compounds. But, the two can produce different experiential and physiological effects. 5-MeO is often considered to be stronger than DMT, and consumers <a href="https://www.reddit.com/r/5MeODMT/comments/esb3jm/first_time_dmt_vs_5_meo_dmt/ff8wr6a/">often report</a> that it inspires a potent transcendent experienceâ€”devoid of visualsâ€”rather than a highly visual experience, such as what DMT is known for.&nbsp;&nbsp;</p>

<figure><img width="819" height="1024" src="https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-meo-dmt-bufo-alvarius-1-1-819x1024.jpg" alt="" srcset="https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-meo-dmt-bufo-alvarius-1-1-819x1024.jpg 819w, https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-meo-dmt-bufo-alvarius-1-1-240x300.jpg 240w, https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-meo-dmt-bufo-alvarius-1-1-768x960.jpg 768w, https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-meo-dmt-bufo-alvarius-1-1.jpg 835w" sizes="(max-width: 819px) 100vw, 819px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20819%201024'%3E%3C/svg%3E" data-lazy-srcset="https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-meo-dmt-bufo-alvarius-1-1-819x1024.jpg 819w, https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-meo-dmt-bufo-alvarius-1-1-240x300.jpg 240w, https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-meo-dmt-bufo-alvarius-1-1-768x960.jpg 768w, https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-meo-dmt-bufo-alvarius-1-1.jpg 835w" data-lazy-src="https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-meo-dmt-bufo-alvarius-1-1-819x1024.jpg"><figcaption>Colorado River Toad<em> </em>(Bufo alvarius) via <a href="https://commons.wikimedia.org/wiki/File:2009-03-13Bufo_alvarius067.jpg" target="_blank" rel="noreferrer noopener">Wikimedia Commons</a>.</figcaption></figure>

<h2 id="h-the-god-molecule-and-mystical-experiences"><span id="The_God_Molecule_and_Mystical_Experiences">The â€œGod Moleculeâ€ and Mystical Experiences</span></h2>
<p>5-MeO-DMT is called â€œthe God Moleculeâ€ for a simple and yet astounding reason: It can make one feel as if they are speaking to, connected with, or becoming one with the divine. Like many other psychedelics, 5-MeO-DMT is an <a href="https://doubleblindmag.com/what-does-entheogen-actually-mean/">entheogen</a>. An <em>entheogen</em> is a chemical compound that can trigger <a href="https://doubleblindmag.com/rick-strassman-dmt-mystical-state/">mystical experiences</a>â€”feelings of intense spirituality.&nbsp;</p>
<p>But you need not be religious or spiritual to have an entheogenic experience with 5-MeO-DMT (or any psychedelic for that matter). Every personâ€™s individual experience is unique, and â€œGodâ€ is merely one word to describe the <a href="https://doubleblindmag.com/why-feeling-connected-is-good-for-your-health/">connection</a> that the drug seems to make possible. Instead of â€œGod,â€ others may prefer terms like Brahman, Nirvana, Gaia, Nature, Universal Consciousness, Higher Power, or none at all. Whatever term they use, each personâ€™s experience is ultimately different, and the meaning and interpretation of that experience is up to the individual.&nbsp;</p>
<p>The idea that spirituality can be chemically triggered is one that many may find uncomfortable. But, as scientists probe into the mysterious world of psychedelics, many studies are finding exactly that: Psychedelics can inspire intense mystical experiences, similar to spontaneous religious epiphanies and spiritual revelations. Like religious or spiritual epiphanies, these chemically-induced experiences can be life-changingâ€”and often correlate with the magnitude of healing the subject may experience for whatever indication they are aiming to treat with the psychedelic.&nbsp;</p>

<p><strong><em>Read: <a href="https://doubleblindmag.com/toad-venom-vs-synthetic-5-meo-dmt/">Is it Worth Kidnapping Toads to Extract their Psychedelic Venomâ€”When You Could Make it In a Lab?</a></em></strong></p>

<p>Indeed, some of the core tenants of a mystical experience include a deep-rooted feeling of unity and interconnectedness with the world around you, as well as profound feelings of joy, transcendence of time and space, and feelings of importance beyond the scope of the self. Psychedelic mystical experiences can be particularly profound because they can inspire a sense that this interconnectedness <em>is</em> reality, that this experience <em>is</em> the natural state of the worldâ€”the experience can have an inherent truth that extends beyond what words can describe.&nbsp;</p>
<p>In 2011, researchers used psilocybin to<a href="https://europepmc.org/backend/ptpmcrender.fcgi?accid=PMC3537171&amp;blobtype=pdf"> test the long-term impact of psychedelic therapy on personality changes in adults</a>; psilocybin is the active constituent in magic mushrooms (sometimes simply called <a href="https://doubleblindmag.com/how-to-take-shrooms-shroom-dosage-shroom-effects/">shrooms</a>). In general, personality is considered relatively set after adults reach the age of 30. But, in this particular study, researchers found that psilocybin could inspire â€œlasting personality changesâ€ for over a year after treatment.&nbsp;</p>
<p>And these changes were positive. After high-dose psilocybin therapy, participants who achieved a â€œmystical experienceâ€â€”defined by specific criteria put forth by psychedelic scientistsâ€”left the study with higher marks of openness than they had upon arrival. â€œOpennessâ€ consists of a collection of personality traits, that includes a willingness to try new experiences, tolerance of othersâ€™ viewpoints, the appreciation of aesthetic qualities, and more.&nbsp;</p>

<p><strong><em>Read: <a href="https://doubleblindmag.com/rick-strassman-dmt-mystical-state/">Rick Strassman on DMT and the Mystical State</a></em></strong></p>

<p>Other studies found that psychedelic experiences have reduced depression and anxiety, aided in trauma therapy for post-traumatic stress, and even had positive impacts in reducing alcoholic addictions and obsessive-compulsive tendencies. But, the majority of these studies were performed on more common psychedelics, like psilocybin, lysergic acid diethylamide (LSD), and ketamine.</p>
<p>Now, researchers are testing the ability of 5-MeO-DMT to occasion similar resultsâ€”and theyâ€™ve had small successes thus far. Recently, scientists proved that the toad molecule indeed can<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6292276/"> inspire mystical experiences</a>, and may even hold potential as a more manageable therapy tool than psilocybin and LSD.&nbsp;</p>
<p>Of course, not every person will have such an awe-inspiring interaction with the drug. Itâ€™s even possible to have a challenging experienceâ€”one thatâ€™s uncomfortable, traumatizing, and even unsafe. Unlike your average medicine, there is no regulation nor substantive clinical research that provide guidance about how to use 5-MeO-DMT, while scientists also have not extensively looked into whether or not certain people may face considerable physical and mental health risks when trying the compound.</p>

<figure><img width="1013" height="768" src="https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-MeO-DMT.png" alt="" srcset="https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-MeO-DMT.png 1013w, https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-MeO-DMT-300x227.png 300w, https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-MeO-DMT-768x582.png 768w" sizes="(max-width: 1013px) 100vw, 1013px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201013%20768'%3E%3C/svg%3E" data-lazy-srcset="https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-MeO-DMT.png 1013w, https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-MeO-DMT-300x227.png 300w, https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-MeO-DMT-768x582.png 768w" data-lazy-src="https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-MeO-DMT.png"><figcaption>Chemical structure of 5-MeO-DMT via <a href="https://commons.wikimedia.org/wiki/File:5-MeO-DMT.png" target="_blank" rel="noreferrer noopener">Wikimedia Commons</a>.</figcaption></figure>

<h2 id="h-therapeutic-research-on-5-meo-dmt"><span id="Therapeutic_Research_on_5-MeO-DMT">Therapeutic Research on 5-MeO-DMT</span></h2>
<p>In recent years, 5-MeO-DMT has garnered some attention among the scientific community. The chemical compound is particularly intriguing to those interested in psychedelic therapy. The 5-MeO-DMT experience can inspire profound experiences, but in a very short time-spanâ€”less than half an hour! By comparison, a psilocybin or LSD experience can last upward of six hours. But research on the psychoactive is only just beginning. Nevertheless, the following is a brief summary of what researchers have discovered thus far:</p>
<h3 id="h-5-meo-dmt-and-alcoholism"><span id="5-MeO-DMT_and_Alcoholism">5-MeO-DMT and Alcoholism&nbsp;</span></h3>
<p>In 2018, researchers with the Crossroads Treatment Center in Tijuana, Mexico <a href="https://www.sciencedirect.com/science/article/pii/S0079612318300931">presented a case study for the combined use of ibogaine and 5-MeO-DMT</a> in the treatment of alcoholism. In their case study, a 42-year-old man was able to remain sober for one month after treatment, returning to mild alcohol use two months after treatment. The patient did report reduced cravings and desire to drink alcohol following the treatment.&nbsp;</p>
<h3 id="h-5-meo-dmt-and-depression-and-anxiety"><span id="5-MeO-DMT_and_Depression_and_Anxiety">5-MeO-DMT and Depression and Anxiety&nbsp;</span></h3>
<p>In March of 2019, researchers from John Hopkins University<a href="https://www.hopkinsmedicine.org/news/newsroom/news-releases/fast-acting-psychedelic-associated-with-improvements-in-depressionanxiety"> surveyed 362 adults who used 5-MeO-DMT</a>. They found that 80 percent of participants reported improvements in depression and anxiety after use.&nbsp;</p>
<h3 id="h-5-meo-dmt-and-mindfulness"><span id="5-MeO-DMT_and_Mindfulness">5-MeO-DMT and Mindfulness</span></h3>
<p>In a 2019 study published in the journal <em>Psychopharmacology</em>, researchers reported that a single dose of 5-MeO-DMT <a href="https://link.springer.com/article/10.1007%2Fs00213-019-05236-w">increased feelings of mindfulness</a>, satisfaction with life, and decreased feelings of anxiety and depression. These positive effects were still noticeable four weeks after treatment. The 5-MeO-DMT was administered to 42 participants in a naturalistic and community-oriented setting.</p>
<h3 id="h-5-meo-dmt-and-neurogenesis"><span id="5-MeO-DMT_and_Neurogenesis">5-MeO-DMT and Neurogenesis&nbsp;</span></h3>
<p>In 2018, Brazilian and Sweedish researchers <a href="https://www.frontiersin.org/articles/10.3389/fnmol.2018.00312/full">teamed up to test the effects of 5-MeO-DMT</a> on neurogenesis in adult mice. <em>Neurogenesiâ€¦</em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://doubleblindmag.com/5-meo-dmt-the-story-behind-the-god-molecule/">https://doubleblindmag.com/5-meo-dmt-the-story-behind-the-god-molecule/</a></em></p>]]>
            </description>
            <link>https://doubleblindmag.com/5-meo-dmt-the-story-behind-the-god-molecule/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26188612</guid>
            <pubDate>Fri, 19 Feb 2021 02:03:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Squad: Forth on Chip-8]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26188165">thread link</a>) | @RodgerTheGreat
<br/>
February 18, 2021 | https://internet-janitor.itch.io/squad | <a href="https://web.archive.org/web/*/https://internet-janitor.itch.io/squad">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://internet-janitor.itch.io/squad</link>
            <guid isPermaLink="false">hacker-news-small-sites-26188165</guid>
            <pubDate>Fri, 19 Feb 2021 01:06:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facebook Calls Australia's Bluff]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26187669">thread link</a>) | @1cvmask
<br/>
February 18, 2021 | https://www.platformer.news/p/facebook-calls-australias-bluff | <a href="https://web.archive.org/web/*/https://www.platformer.news/p/facebook-calls-australias-bluff">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.platformer.news/p/facebook-calls-australias-bluff</link>
            <guid isPermaLink="false">hacker-news-small-sites-26187669</guid>
            <pubDate>Fri, 19 Feb 2021 00:07:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Florida outperformed lockdown states on excess deaths, education, and economy]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 4 (<a href="https://news.ycombinator.com/item?id=26187395">thread link</a>) | @Pausanias
<br/>
February 18, 2021 | https://rationalground.com/floridas-covid-19-response-has-outperformed-lockdown-states-on-excess-deaths-education-and-the-economy/ | <a href="https://web.archive.org/web/*/https://rationalground.com/floridas-covid-19-response-has-outperformed-lockdown-states-on-excess-deaths-education-and-the-economy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://rationalground.com/floridas-covid-19-response-has-outperformed-lockdown-states-on-excess-deaths-education-and-the-economy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26187395</guid>
            <pubDate>Thu, 18 Feb 2021 23:38:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to know if you're interviewing at a product-led company]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26187334">thread link</a>) | @skotzko
<br/>
February 18, 2021 | https://andrewskotzko.com/how-to-know-if-youre-interviewing-at-a-product-led-company/ | <a href="https://web.archive.org/web/*/https://andrewskotzko.com/how-to-know-if-youre-interviewing-at-a-product-led-company/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><main id="genesis-content"><article aria-label="How to know if youâ€™re interviewing at a product-led company"><div><div><figure><img loading="lazy" width="732" height="307" src="https://andrewskotzko.com/wp-content/uploads/2021/02/TN9ww6_OmxtkBn4j3aKpJw7c2cQZJsdZSEt6FlMAgqTBTD_i2Z4gzRmNvW42Jx1CFbIreJIpDTB4i2QR_bH5JGIoxZH5EIkH3kTji7t8uMhgBO61qtJ84EHpab-QgVWt53Y2hF2_.png" alt="" srcset="https://andrewskotzko.com/wp-content/uploads/2021/02/TN9ww6_OmxtkBn4j3aKpJw7c2cQZJsdZSEt6FlMAgqTBTD_i2Z4gzRmNvW42Jx1CFbIreJIpDTB4i2QR_bH5JGIoxZH5EIkH3kTji7t8uMhgBO61qtJ84EHpab-QgVWt53Y2hF2_.png 732w, https://andrewskotzko.com/wp-content/uploads/2021/02/TN9ww6_OmxtkBn4j3aKpJw7c2cQZJsdZSEt6FlMAgqTBTD_i2Z4gzRmNvW42Jx1CFbIreJIpDTB4i2QR_bH5JGIoxZH5EIkH3kTji7t8uMhgBO61qtJ84EHpab-QgVWt53Y2hF2_-300x126.png 300w" sizes="(max-width: 732px) 100vw, 732px"></figure></div><p>Iâ€™m seeing this sentiment pop up with alarming frequency. Many product people are dealing with career uncertainty â€” and not just the â€œwill my company make it through the pandemic?â€ variety. Without the usual distractions of life available, things that were easily overlooked are now front and center.</p><p>And what are many of these product people realizing without the distractions of normal life?</p><p><strong>Theyâ€™re set up to fail.</strong></p><p>Their work environment and culture is not set up to create strong products. It is distinctly <em>not</em> set up to empower the collaboration of product, design, and engineering to build things that matter.</p><p>This has led many to realize itâ€™s time for a job change.</p><p>As product people, we want to work in a product-led company. A place that truly values the craft and contribution of product, and that empowers individuals and teams to work to their highest potential. A place that is built around creating amazing products that truly make life better for the people theyâ€™re trying to serve.</p><p>We all know itâ€™s possible. Itâ€™s what the best product companies are doing. Yet despite many attempts tried, there are many frustrated PMs that canâ€™t seem to get their work environment to change.</p><p>This is because, frankly, they joined the wrong company in the first place.</p><p>They took a role where good product work occurs in spite of the dominant practices and culture, not because of them.</p><p>Jobs like this waste precious years of your career. Iâ€™ve made this mistake too, and it hurts. I hope this article helps you avoid it in the future.</p><p>Itâ€™s actually really hard to know how strong of a product culture and environment that a team has prior to living in it. Even within the FAANG companies, every team and manager is different and you need to find out the truth.</p><p>After reading this, you should have a go-to set of questions to ask the next companies you interview. These will help you suss out the reality of how the company operates before you commit to an offer. Iâ€™m writing this for product managers, but itâ€™s equally relevant to design and engineering.</p><p>So, what <em>can</em> you do to make sure that your next company is <em>actually</em> a good place to be a product person?</p><p>The key to solving this is to <em>interview companies the same way we interview users and customers</em>.</p><p>Think of this as â€œThe Mom Test,â€ applied to product job interviews.</p><h2 id="interviewing-companies-like-users-customers">Interviewing companies like users/customers<a href="#interviewing-companies-like-users-customers"></a></h2><h3 id="why-you-need-to-do-this">Why you need to do this<a href="#why-you-need-to-do-this"></a></h3><p>One of the most common complaints in the job search process is â€œthis place isnâ€™t what I thought it would be.â€</p><p>People join a company full of vigor and excitement, and within a few months they are bored, going through the motions, and fantasizing yet again about being somewhere that â€œgets product.â€</p><p>It doesnâ€™t have to be this way.</p><div><figure><img loading="lazy" src="https://andrewskotzko.com/wp-content/uploads/2021/02/t3pawlU7qxNyGBkCZMWQLQxfOUct30uDWgZqusxwAHau6pIJ6hAh530ETyv3vLRSapIHNHHSBevu-zemY4za4V5cY7ONyvP97DtHfMILgezcPqd8eOngk1mPY7nD9smhqwVqNA64.jpg" alt="" width="480" height="308" srcset="https://andrewskotzko.com/wp-content/uploads/2021/02/t3pawlU7qxNyGBkCZMWQLQxfOUct30uDWgZqusxwAHau6pIJ6hAh530ETyv3vLRSapIHNHHSBevu-zemY4za4V5cY7ONyvP97DtHfMILgezcPqd8eOngk1mPY7nD9smhqwVqNA64.jpg 640w, https://andrewskotzko.com/wp-content/uploads/2021/02/t3pawlU7qxNyGBkCZMWQLQxfOUct30uDWgZqusxwAHau6pIJ6hAh530ETyv3vLRSapIHNHHSBevu-zemY4za4V5cY7ONyvP97DtHfMILgezcPqd8eOngk1mPY7nD9smhqwVqNA64-300x192.jpg 300w" sizes="(max-width: 480px) 100vw, 480px"></figure></div><p>As PMs, we invest so much getting ready for those damn product interviews that we often forget: <strong>we need to interview the company just as hard as theyâ€™re interviewing us.</strong></p><p>This is called â€œreverse interviewing.â€ As product people, we already know how to do this.</p><p>We know how to interview customers and users. We know to ask questions to account for bias and speculation, surface actual behavior, and understand how decisions are really made.</p><p>When applying for a job, we need to apply those same skills to interview our interviewers.</p><p>As Marty Cagan said to me in <a href="https://pod.fo/e/af7e6">our podcast conversation</a>:</p><blockquote><p><em>From your point of view, your job is to learn as much as possible about how that company really works, and especially how that manager would be like to work for.</em></p></blockquote><p>Letâ€™s see how to do just that.</p><h3 id="principles-for-interviewing">Principles for interviewing<a href="#principles-for-interviewing"></a></h3><p>Two excellent resources on interviewing usersâ€”which you really should read if you havenâ€™tâ€”are <a href="https://www.producttalk.org/2016/03/customer-interview-questions/">this post by Teresa Torres</a> and <a href="https://amzn.to/2MXuN2D">The Mom Test</a>.</p><p>I distill their points into these two overarching principles for interviewing:</p><ol><li>Separate your research questions and interview questions</li><li>Ask questions that uncover actual past behavior, rather than speculative or aspirational future behavior</li></ol><h3 id="separate-research-questions-from-interview-questions">Separate research questions from interview questions<a href="#separate-research-questions-from-interview-questions"></a></h3><p>The user research community has learned that we often canâ€™t directly ask our questions and get reliable answers.</p><p>The way around this is to map our research questions to interview questions.</p><p>Research questions are what we really want to know. Interview questions are what we actually ask to get the interviewee telling stories that show their behavior. (This is a concept I learned from Teresa Torres in her <a href="https://learn.producttalk.org/p/continuous-interviewing">excellent interviewing course</a>.)</p><p>For example, imagine you work at Spotify and your team is assigned to work on reducing the churn rate.</p><p>Letâ€™s say youâ€™ve learned that users who play a given playlist consistently at the start of their workday are retained ~20% longer than those who donâ€™t. Your research questions might be:</p><ul><li>Why are people using the same playlist every day?</li><li>What are people looking for in such a playlist? How do they choose playlists?</li><li>When, where, and how do people find these playlists?</li><li>What is unique about playlists that have high retention rates?</li><li>Are users more likely to exhibit the desired behavior with a playlist they follow, or one they create?</li></ul><p>Some interview questions to get stories containing this information could be:</p><ul><li>Tell me about your morning playlist? How did you first find it?</li><li>Walk me through your day. Start with the moment you woke up.</li><li>Tell me about how you start your workday</li><li>Tell me about the last playlist you discovered that you really liked</li><li>Tell me about the last playlist you made yourself</li></ul><p>Each of these prompts a story about actual behavior, and we can then ask more questions to go deeper. A well-extracted story can often answer multiple research questions at once.</p><p>Now letâ€™s talk about how to apply this to finding a great product environment to work in.</p><h3 id="the-droids-were-looking-for">The droids weâ€™re looking for <a href="#the-droids-were-looking-for"></a></h3><p>What weâ€™re seeking in our job search: empowered product teams.</p><p>Empowered product teamsâ€”as opposed to delivery or feature teamsâ€”only exist in environments with strong product leadership.</p><p>Empowered product teams:</p><ol id="block-31aad864-d497-461b-8f72-65138efd7926"><li>are small, cross-functional, and durable</li><li>address product risks early with collaborative product discovery, and regularly â€œkill their darlingsâ€ en route to ideas that work</li><li>are accountable to delivering results rather than output</li></ol><p>These teams exist in product orgs with an environment that has:</p><ol id="block-31aad864-d497-461b-8f72-65138efd7926"><li>a focused and insight-rich product strategy</li><li>regular, ongoing cadence of lightweight research directly with their user/customer, rather than handing this off to a research group</li><li>people connected to the product vision in a visceral, energetic way</li><li>managers that are proactively and regularly coaching and developing team members</li><li>an equal partnership with the rest of the business</li></ol><p>Teams like this are great places to be a product person. These are where magical career experiences and products come from. And they are made up of ordinary, hard-working, sincere people just like you.</p><p>(To go deep on the idea of empowered teams, read Marty Caganâ€™s latest book, <a href="https://amzn.to/3cFAo8G">EMPOWERED</a>, and listen to the <a href="https://pod.fo/e/af7e6">deep dive conversation I had with him about the ideas in the book</a>.)</p><p>Our research question is: â€œis this a place that empowers product people/teams?â€</p><p>Now that we know what weâ€™re looking for, how do we assess a given job opportunity?</p><p>This is where our interview questions come in.</p><h2 id="reverse-interview-questions">Reverse interview questions<a href="#reverse-interview-questions"></a></h2><p>Since every company we talk to will <em>say</em> theyâ€™re a good product company, we need to dig deeper. Just as with users, we canâ€™t take them at their word. We need evidence from real behavior.</p><p>Based on my own career, research, listener questions and podcast interviews with product people, here are my top reverse interview questions (click to jump to the section for the given question):</p><ol><li><a href="#1-what-were-the-last-few-things-your-team-has-built-and-shipped-and-how-did-you-decide-to-do-those">What were the last few things your team has built and shipped, and how did you decide to do those?</a></li><li><a href="#2-whens-the-last-time-you-talked-with-your-customers-users-how-often-have-you-done-that-in-the-last-month">Whenâ€™s the last time you talked with your customers? How often have you done that in the last month?</a></li><li><a href="#3-what-was-the-last-feature-or-product-your-team-killed">What was the last feature or product your team killed?</a></li><li><a href="#4-can-you-describe-your-product-vision">Can you describe your product vision?</a></li><li><a href="#5-tell-me-about-the-last-coaching-session-you-had-with-your-manager-how-often-did-that-happen-last-month">Tell me about the last coaching session you had with your manager. How often did that happen last month?</a></li></ol><p>Letâ€™s discuss the rationale for each of these, and what you want to hear/avoid.</p><h3 id="1-what-were-the-last-few-things-your-team-has-built-and-shipped-and-how-did-you-decide-to-do-those">1) What were the last few things your team has built and shipped, and how did you decide to do those?<a href="#1-what-were-the-last-few-things-your-team-has-built-and-shipped-and-how-did-you-decide-to-do-those"></a></h3><h4 id="why-youre-asking">Why youâ€™re asking<a href="#why-youre-asking"></a></h4><p>We need to understand the core of how work happens here. How is work assigned? Who decides what gets built, and how?</p><p>This is the biggest indicator of whether this team is empowered. This is the motherlode. Plan to dig deep into this one. Pull every thread and see where it takes you.</p><h4 id="what-youre-looking-for">What youâ€™re looking for<a href="#what-youre-looking-for"></a></h4><p>We want to see that leadership has assigned the team clear objectives â€” customer or business problems to solve â€” and empowered the team to come up with solutions to those problems. Weâ€™re looking to see that leadership has pointed the team in the right direction, and empowered them to figure it out.</p><p>We want to hear things like â€œwell, our goal this quarter is to increase the average 4-week retention for a new user cohort from 33% to at least 40%. We interview users every week and dug into this pattern from last quarterâ€™s data. The PM/designer/tech lead ran a fast series of prototypes/experiments to figure out what worked with users, and to make sure our stakeholders could support it. After we had enough confidence that it was the right thing to build, we put it on the backlog and built it out for production.â€</p><p>Whatâ€™s wrapped up in that statement? Tons of goodness:</p><ul><li>A clear goal, with metrics, that the whole team is focused on</li><li>A regular cadence of user/customer contact</li><li>Insights that inform the product strategy and shape the objectives the teams pursue</li><li>Rapid, iterative, and collaborative prototyping and continuous discovery practices</li><li>Addressing the <a href="https://svpg.com/four-big-risks/">four big risks</a> early on in discovery, before building for production</li><li>A collaborative, rather than subservient, relationship with stakeholdersâ€”we hear that the product team exists to delight the customer, in a way that works for the business</li></ul><p>Weâ€™d also love to dig into the tradeoffs and tough calls that were made in that process. This is a place weâ€™d love to hear the product vision and principles shaping the daily product decisions that the â€¦</p></div></article></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://andrewskotzko.com/how-to-know-if-youre-interviewing-at-a-product-led-company/">https://andrewskotzko.com/how-to-know-if-youre-interviewing-at-a-product-led-company/</a></em></p>]]>
            </description>
            <link>https://andrewskotzko.com/how-to-know-if-youre-interviewing-at-a-product-led-company/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26187334</guid>
            <pubDate>Thu, 18 Feb 2021 23:31:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Some Background (On CheapETH)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26187156">thread link</a>) | @lumpa
<br/>
February 18, 2021 | https://www.deveth.org/background.html | <a href="https://web.archive.org/web/*/https://www.deveth.org/background.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

  <nav>
    <div>
      <p><a href="https://www.deveth.org/"><img src="https://www.deveth.org/logo.png" alt="deveth.org" width="110"></a>
      </p>
    </div>
  </nav>

  <main>
    

    <p>In February 2021, George Hotz (geohot) et al. <a href="https://github.com/cheapETH/go-ethereum/tree/cheapeth">forked the Ethereum chain</a> to form <a rel="nofollow" href="https://cheapeth.org/">cheapETH</a>. A project intended to provide a stable, affordable
      testnet for the
      Ethereum ecosystem, with cross-chain communication functionality. The founders of the devETH project participated
      in this community, spending time and resources building infrastructure surrounding the project.</p>
    <p>Unfortunately, days after the project was started, a member of the cheapETH community discovered and pointed out
      <a href="https://github.com/cheapETH/go-ethereum/commit/412c38434d8d88840452c090e738a672139a73d4#diff-67b4f96b9bd587cc5f508f38eb63f372fa31f339bf66fedcb188f78774318201R88">patch</a>
      in the cheapETH fork of go-ethereum, that grants 25,000,000 cheapETH tokens to the developers associated with the
      project. According to the <a href="https://github.com/cheapETH/cheapeth-website/blob/442027739ee61444c711346c7e3b2a06aecd94aa/index.html#L93">cheapETH
        website</a>, that would theoretically amount to 25,000 Ethereum as per the pegged 1/1000 ratio described by the
      cheapETH developers. This single transaction has <b>theoretical</b> market value of $46 million USD at the time of
      writing. (Feb 18th)
    </p>
    <p>Following this revelation on the cheapETH Discord server, a number of community members expressed their concern
      regarding this seemingly gratuitous developer fund, and the details surrounding its implementation. Instead of
      addressing these issues, the cheapETH staff appointed in the Discord community resorted to deleting messages and
      banning members of the community who were posing unwanted questions about the financial motivations of the
      cheapETH project.</p>
    <p>The devETH project authors do not intend to make any assumptions/accusations as to the financial
      dealings/motivations of the cheapETH developers - They are free to do whatever they wish with their project.
      However, prompted by the drastic response in the Discord community, and a suggestion by <a href="https://github.com/cheapETH/go-ethereum/pull/2#issuecomment-779544030">George Hotz</a>, a group of
      cheapETH community members decided to launch the devETH project as a direct fork of the cheapETH project.</p>
    <p>We intend to continue innovating on the vision of the cheapETH project, and wish all the best to the cheapETH
      team on their endeavour.</p>
    <p>The devETH team invites anyone interested in our take on the cheapETH vision to participate in our <a href="https://discord.gg/xFmCcaEjPK">Discord server</a>.</p>
    <p>- The devETH team</p>

  </main>

  
  


</div>]]>
            </description>
            <link>https://www.deveth.org/background.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26187156</guid>
            <pubDate>Thu, 18 Feb 2021 23:12:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Kanban board that helps Engineers learn Marketing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26186864">thread link</a>) | @krm01
<br/>
February 18, 2021 | https://phireworks.co/pro/?pro | <a href="https://web.archive.org/web/*/https://phireworks.co/pro/?pro">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<table>
  <tbody><tr>
    <td>

      <h3>Examples from real companies. </h3>
      <h4>New marketing ideas are constantly added to your dashboard so you can learn how other founders acquired their first set of customers.</h4>
    </td>

    <td>

      <h3>Drag &amp; drop to organize</h3>
      <h4>Organize and prioritize weekly marketing experiments that you can implement yourself. Design your process for consistent growth.</h4>
    </td>

    <td>

      <h3>Practical and actionable guides</h3>
      <h4>Discover practical marketing ideas without the fluff, so you can save time and start implementing right away.  </h4>
    </td>
  </tr>
</tbody></table>





</div></div>]]>
            </description>
            <link>https://phireworks.co/pro/?pro</link>
            <guid isPermaLink="false">hacker-news-small-sites-26186864</guid>
            <pubDate>Thu, 18 Feb 2021 22:44:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Texas power outage is a nation-wide problem]]>
            </title>
            <description>
<![CDATA[
Score 241 | Comments 395 (<a href="https://news.ycombinator.com/item?id=26186645">thread link</a>) | @gwoplock
<br/>
February 18, 2021 | https://garrettbattaglia.com/post/texas-power/ | <a href="https://web.archive.org/web/*/https://garrettbattaglia.com/post/texas-power/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
        <p>Let me preface this with an explanation. Over the last few days I read online people saying that Texas' power outages had been caused by Texas being on its own gridâ€¦ deregulationâ€¦ Not following national standardsâ€¦  had Texas been connected to the Eastern Interconnection or the Western Interconnection none of this would have happened. But not one post shows any evidence or requirements that backed up these claims. So, I went looking for proof and instead of finding requirements, I found a nationwide problem with winterization. As an aside I am not an expert in the grid or electricity, I am a software developer, and this is my best interpretation of the requirements I could find.</p>
<p>Letâ€™s start off with how the electrical grid works in the US. The grid is made up of 3 interconnections: the Eastern Interconnection, the Western Interconnection, and the Texas Interconnect. Each of these interconnections operate in (near) isolation with their own frequency, voltage, and phase. There are several high voltage DC interconnects (HVDC or DC-DC) between them. In each of these interconnections there is at least one grid operators, for example ERCOT in Texas. These grid operators manage the generation and load of their interconnection, acting as almost as an electric clearing house. They are also responsible for keeping voltage and frequency within range and directing distributors (like ONCOR in north Texas) to shed load during Electrical Emergency Alerts (EEA). An important thing to note for later, from the best I can tell the different grid operators in the Eastern Interconnect share power in a â€œnon-firm, as-available basisâ€.</p>
<p>What happened in Texas, starting 12:30 AM February 15. The long and short of it is an estimated 34GW of generation went offline in about 2 hours[1]. Looking at ERCOTâ€™s tweets [2,3,4], generation was starting to have an issue at 00:17:45 and some load needed to be shed so ERCOT issued the first EEA (EEA1). In the February EEA tools document[5] EEA1 can open up around 1.6GW of â€œpeekerâ€ generation and importation from the Eastern and Western Interconnections. But by 1:12:06 that wasnâ€™t enough and additional load had to be shed.  A second EEA was issued (EEA2) shedding another 1.6GW. But just a few minutes later the house came crashing down and at 1:25:40 the third EEA (EEA3) was issued. In addition to starting rolling blackouts to shed most of the load it also allowed for other actions to free .1-.2GW of load.</p>
<p>The 34GW of generation lost was from every fuel source used. Most of it was frozen-off natural gas (gas) wells, some of it was frozen wind turbines, solar panels that had snow on them and even a nuclear plant had to go offline due to issues with feedwater pressure sensing issues related to the cold.
What do the North American Electric Reliability Corporation (NERC) standards say about protecting any of these sources? Not much.</p>
<p>Letâ€™s start by looking at the least complex, wind turbines. On September 12, 2012 NERC published a Lesson Learned document in regards to Texasâ€™s issues with some of the wind farms freezing in extreme winter weather[6]. According to the document the event that was predicted over a week beforehand brought 4 days of low temperature, high winds and wind chills, ice and snow that limited the generation facility to just 25% of capacity. The facility did have a SOP for icing conditions that was implemented. However, the facility never defined itâ€™s minimum operating temperature. When lightning knocked out some of the sensing equipment, the turbines had to be stop for safety. The repair crews couldnâ€™t immediately get to the turbines and they had to sit, this gave the oil a chance to cool and partly freeze. When the turbines were returned to service, they tripped back off due to high oil pressure. Eventually after working with the manufacturer they were able to safely heat the oil and restart the turbines. One of the big lessons from this was to install cold weather packs for wind turbines and watch the oil temperature. Youâ€™d think that would solve future outage, but no, in 2019 in the midwestwind turbines failed due to exceptionally low temperatures, around -21. Again the cold weather package hadnâ€™t been installed and was one of the root causes of the failure[7].</p>
<p>The nuclear plantâ€™s sensing problems had happened before too. Although it wasnâ€™t a nuclear plant, there are several documented cases on NERCâ€™s website citing cold weather and sensor issues [8,9]. This repeated in Texas (2011) and in the south east (2018)[10].</p>
<p>Letâ€™s discuss natural gas next. It appears that most of the issues in the problematic natural gas fired facilities was due to low gas supplies. In 2012 NERC warned of the interconnectivity of natural gas and electric[11]. Natural gas coming out of the ground has a naturally high water content. This water can freeze the extraction equipment during sub-freezing weather in improperly winterized wells creating what is know as a freeze-off. businesses, residential customers, and powerplants all run off the same supply, once wells start freezing off the supply dwindles for all. Natural gas companies prioritize residential customers as needed and will cut businesses and powerplants. This obviously creates issues in electrical generation.</p>
<p>In this latest case, much of the gas generation loss was due to under pressure conditions at the generation site. When generation sites detect this kind of fault, they are taken offline for safety. Not only is this what happened this year, but it has happened many, many times before</p>
<p>The most resent case I could find was 2018 in the south east[10]. Starting on January 18, 2018 a large area in the south east US experienced unusually cold weather. This caused 183 generation facilities to go offline or operate with greatly reduced output. At the peak there was nearly 30GW of production lost. This caused several grid operators to issue EEAs and begin rolling blackouts. In the â€œevent areaâ€ 14% of the failures could be directly attributed to the cold weather. And another 30% could be indirectly linked to weather, including mechanical failures know to happen in cold weather and gas supply issues. NERC found that more than 33% of the failed powerplants didnâ€™t have a winterization plan.</p>
<p>Why didnâ€™t these plants have a winterization plan? Because it wasnâ€™t required[10,12].</p>
<p>This wouldnâ€™t be so bad if this wqs the first time it happened, it wasnâ€™t even the second time it happened. In 2014 a polar vortex hit the US. bringing temperatures well below normal. During this event 55% of the outages were at gas power plants and in all 90GW of generation was lost[13].</p>
<p>The earliest report I could find was from the 2011 winter event in Texas[14]. A very strong cold front hit Texas (and other parts of the south central US) bringing temperatures below freezing for over 4 days and winds over 30 MPH. Leading up to the event, ERCOT and other grid operators in surrounding areas felt that there wouldnâ€™t be a need for rolling blackouts. At the beginning of the event ERCOT had 3.1GW of reserve, nearly 1GW over the minimum required. However, over the next 2 days ERCOT lost nearly 30GW of production in 193 generation facilities. ERCOT was able to stabilize the grid with rolling blackouts and the other EEA methods[5]. Other grids suffered problems as well, EPE (El Paso) and SRP (Arizona) lost nearly 1.4GW due to cold weather. Another issue in ERCOTâ€™s region was nearly 50% of the â€œblack startâ€ facilities were either down for scheduled maintenance or failed on startup. One of the main causes again was the loss of gas during this blackout period. 14.8 Bcf of natural gas production was lost due to freeze-offs, electrical outages (ironically) and customer curtailments. following the previous equivalent storm in 1989, the PUCT (Public Utility Commission of Texas) issued several recommendations and guidelines for winterization of power plants and gas wells. However, due to the infrequency of these storms the implementation lacked. With many of the same facilities that failed in 1989 also failed in 2011.  My guess is these same sites failed again in 2021. Interestingly the NERC found that it is quite possible that gas production in these unusually cold conditions may be impossible.</p>
<p>What has been done since 2011? Not a whole lot. A request for a new standard was issued to NERC in late 2012, however a few months later it was denied.[15] Also in 2012 NERC put out a set of guidelines for developing a plan for winter weather[16]. In 2017 NERC put out a special reliability report on the relationship between gas and electricity[17]. Finally, after the 2018 event NERC received another standard request that was approved[23], however it wonâ€™t be finalized until late 2021[18,19,20].</p>
<p>From what I can see, ERCOT has more restrictive rules in their Generator Winter Weatherization Workshop than NERC[21]. All generation stations must have plans for emergencies, address abnormal weather, critical failure points, weather design limits, alternative fuels and testing[21,22]. ERCOT reports that there were 80 spot checks done in the 2019/2020 season with 71 being gas plants and 6 being black start gas plants. 23 had to improve and would be reinspected in early 2021 the rest passed.</p>
<p>The issue of extreme cold weather and electrical outages is a national issue that needs to be addressed. However, after repeated failings it hasnâ€™t really been addressed. Hopefully with the new NERC requirements and the Texas legislature in session progress can be made.</p>
<hr>
<p>[1] <a href="http://www.ercot.com/news/releases/show/225244">http://www.ercot.com/news/releases/show/225244</a><br>
[2] <a href="https://twitter.com/ERCOT_ISO/status/1361197991659503618">https://twitter.com/ERCOT_ISO/status/1361197991659503618</a><br>
[3] <a href="https://twitter.com/ERCOT_ISO/status/1361211669788176384">https://twitter.com/ERCOT_ISO/status/1361211669788176384</a><br>
[4] <a href="https://twitter.com/ERCOT_ISO/status/1361215084010352644">https://twitter.com/ERCOT_ISO/status/1361215084010352644</a><br>
[5] <a href="http://www.ercot.com/content/wcm/lists/219692/EEA_Tools_One_Pager_Winter_2021_2-13-2021.pdf">http://www.ercot.com/content/wcm/lists/219692/EEA_Tools_One_Pager_Winter_2021_2-13-2021.pdf</a><br>
[6] <a href="https://www.nerc.com/pa/rrm/ea/Lessons%20Learned%20Document%20Library/LL20120901_Wind_Farm_Winter_Storm_Issues.pdf">https://www.nerc.com/pa/rrm/ea/Lessons%20Learned%20Document%20Library/LL20120901_Wind_Farm_Winter_Storm_Issues.pdf</a><br>
[7] <a href="https://www.nerc.com/pa/rrm/ea/Lessons%20Learned%20Document%20Library/LL20200601_Unanticipated_Wind_Generation_Cutoffs_during_a_Cold_Weather_Event.pdf">https://wâ€¦</a></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://garrettbattaglia.com/post/texas-power/">https://garrettbattaglia.com/post/texas-power/</a></em></p>]]>
            </description>
            <link>https://garrettbattaglia.com/post/texas-power/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26186645</guid>
            <pubDate>Thu, 18 Feb 2021 22:26:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top Latex Fonts]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26186538">thread link</a>) | @alderz
<br/>
February 18, 2021 | https://r2src.github.io/top10fonts/ | <a href="https://web.archive.org/web/*/https://r2src.github.io/top10fonts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2>assembled by Jaap Joris Vens</h2>

<p>

This page contains ten paragraphs typeset by the
<a href="http://www.latex-project.org/"><span>L<sup>a</sup>T<sub>e</sub>X</span>
typesetting system</a>, converted to images by
the <a href="http://savannah.nongnu.org/projects/dvipng/">dvipng</a>
utility.  Each paragraph<sup>1</sup> showcases a different font family
and provides some background and usage instructions.

The source of this page is <a href="https://github.com/r2src/top10fonts/">available on GitHub</a>.

All the fonts are free and open source and are included by default in
most <span>L<sup>a</sup>T<sub>e</sub>X</span>
distributions.  All fonts are also available
on <a href="http://www.ctan.org/tex-archive/fonts/">CTAN</a>, as well as in the
<a href="http://www.tug.dk/FontCatalogue/"><span>T<sub>e</sub>X</span>
Font Catalogue</a>.<br>
<span>
&nbsp;&nbsp;&nbsp;<sup>1</sup> except for this one, which is the only
paragraph rendered by your browser.
</span>
</p>

<p>
<img src="https://r2src.github.io/top10fonts/lmodern.png" alt="1 Computer Modern">
</p>

<p>
<img src="https://r2src.github.io/top10fonts/kpfonts.png" alt="2 Kepler Fonts">
</p>
<p>
<img src="https://r2src.github.io/top10fonts/fontcomp.png" alt="Comparison table">
</p>
<p>
<img src="https://r2src.github.io/top10fonts/kpsans.png" alt="Kepler Sans">
</p>

<p>
<img src="https://r2src.github.io/top10fonts/didot.png" alt="6 GFS Didot">
</p>

<p>
<img src="https://r2src.github.io/top10fonts/utopia.png" alt="4 Utopia">
</p>

<p>
<img src="https://r2src.github.io/top10fonts/venturis.png" alt="5 Venturis ADF">
</p>
<p>
<img src="https://r2src.github.io/top10fonts/venturisrm1.png" alt="">
</p>
<p>
<img src="https://r2src.github.io/top10fonts/venturisrm2.png" alt="">
</p>
<p>
<img src="https://r2src.github.io/top10fonts/venturisrm3.png" alt="">
</p>

<p>
<img src="https://r2src.github.io/top10fonts/libertine.png" alt="6 Libertine">
</p>

<p>
<img src="https://r2src.github.io/top10fonts/gyre.png" alt="7 TeX Gyre Collection">
</p>
<p>
<img src="https://r2src.github.io/top10fonts/gyrebonum.png" alt="Bonum">
</p>
<p>
<img src="https://r2src.github.io/top10fonts/gyrepagella.png" alt="Pagella">
</p>
<p>
<img src="https://r2src.github.io/top10fonts/gyreschola.png" alt="Schola">
</p>
<p>
<img src="https://r2src.github.io/top10fonts/gyretermes.png" alt="Termes">
</p>

<p>
<img src="https://r2src.github.io/top10fonts/antiqua.png" alt="7 URW Antiqua">
</p>

<p>
<img src="https://r2src.github.io/top10fonts/bera.png" alt="10 Bitstream Vera">
</p>

<p>
<img src="https://r2src.github.io/top10fonts/boisik.png" alt="8 Boisik">
</p>



</div>]]>
            </description>
            <link>https://r2src.github.io/top10fonts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26186538</guid>
            <pubDate>Thu, 18 Feb 2021 22:19:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Which startups let their employees sell stock?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26186119">thread link</a>) | @gk1
<br/>
February 18, 2021 | https://sacra.com/startup-employee-liquidity/ | <a href="https://web.archive.org/web/*/https://sacra.com/startup-employee-liquidity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article class="page">
      <section>
        <div>
          

          <div>
            <p>Selling stock is a taboo subject at a lot of startups.</p>

            <p>To normalize talking about liquidity and help employees make informed career decisions, we built this list of companies that do and donâ€™t allow employees to sell their stock.</p>

            <p><strong>Want to help?</strong> <a href="https://airtable.com/shrbQ6hB22DzXsHOR">Fill out out our survey</a>.</p>
          </div>
        </div>
      </section>
      <section>
        <div>
          

          <div>
            <div>
              <h3>Do you work at a VC-backed company?</h3>

              <p>Help us add to this database anonymously. Your responses will be kept confidential.</p>

              <p><a href="https://airtable.com/shrbQ6hB22DzXsHOR">Add a report</a>
            </p></div>
            <div>
              <h3>Are you an employer?</h3>

              <p>Tell us about your companyâ€™s policies around secondary sales and employee liquidity. Weâ€™d love to hear from you.</p>

              <p><a href="https://airtable.com/shr8aZVC34siGSxAx">Respond to this report</a>
            </p></div>
          </div>
        </div>
      </section>

      <section>
        <div>
          <h2>Liquidity programs by stage</h2>
          
          <div>
            <p>Later-stage companies are more likely to allow employee stock sales, either through company-led transactions or by allowing employee-led transactions. Doing so allows them to provide long-time members of the team with an opportunity to de-risk by getting some liquidity. 

            </p><p>However, today, some companies like Pipe have begun making liquidity available for their employees as early as seed/Series A.</p>

            <p>Some companies donâ€™t allow for employee sales of their stock. In some instances, these companies implement transfer restrictions that prevent private sales from occurring.</p>

          </div>
        </div>
      </section>
      <section>
        <div>
          <h2>Resources for employees</h2>



          <h3>Stock option exercise lending</h3> 
          
          <p>One barrier to employee liquidity is exercising your stock options, which can be expensive and confusing. Some companies help by allowing employees to borrow cash to meet their option exercise and tax obligations. </p>

          <h3>Secondary brokerages</h3>
          
          <p>If your company allows for you to sell your stock, but doesnâ€™t offer regular company-led liquidity, you may be able to sell it on a secondary marketplace or via a broker.</p>
          <h3>Secondary funds</h3>
          
          <p>Certain venture funds specialize in â€œspecial situationsâ€ like employee and/or founder liquidity at private companies, and actually prefer to buy stock in secondary markets.</p>
          <h3>Company liquidity platforms</h3>
          
          <p>If your company offers regular liquidity by way of tender offers, share buybacks, or auctions, you will likely know about it well in advance. If youâ€™re not sure, you can ask your HR or finance team and they will let you know if your company allows for these types of transactions.</p>

          <h4>Learn more</h4>

          
        </div>
      </section>
    </article>
  </div></div>]]>
            </description>
            <link>https://sacra.com/startup-employee-liquidity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26186119</guid>
            <pubDate>Thu, 18 Feb 2021 21:46:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Bug on Aurora PostgreSQL 12 causes Autovacuum to hang forever]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26185711">thread link</a>) | @fdr
<br/>
February 18, 2021 | https://www.migops.com/blog/2021/02/15/a-bug-on-aurora-postgresql-12-causes-autovacuum-to-hang-forever/ | <a href="https://web.archive.org/web/*/https://www.migops.com/blog/2021/02/15/a-bug-on-aurora-postgresql-12-causes-autovacuum-to-hang-forever/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.migops.com/blog/2021/02/15/a-bug-on-aurora-postgresql-12-causes-autovacuum-to-hang-forever/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26185711</guid>
            <pubDate>Thu, 18 Feb 2021 21:18:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gleam 0.14 â€“ type-safe language for the Erlang VM]]>
            </title>
            <description>
<![CDATA[
Score 244 | Comments 38 (<a href="https://news.ycombinator.com/item?id=26185690">thread link</a>) | @lpil
<br/>
February 18, 2021 | https://gleam.run/news/gleam-v0.14-released/ | <a href="https://web.archive.org/web/*/https://gleam.run/news/gleam-v0.14-released/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <div>
<p>Hot on the heels of Gleam v0.13 comes another release, <a href="https://github.com/gleam-lang/gleam/releases/tag/v0.14.0">Gleam v0.14</a>!
As always, letâ€™s take a look at some of the highlights.</p>

<h2 id="dialyzer--erlang-typespecs">Dialyzer &amp; Erlang typespecs</h2>

<p>Many dynamically typed BEAM languages support Erlangâ€™s typespecs, type
annotations that can be analysed with the <a href="https://erlang.org/doc/man/dialyzer.html">Dialyzer</a> tool. While
not as powerful or reliable as Gleamâ€™s type system it can be a useful tool
for finding problems with your Erlang or Elixir code. Dialyzer doesnâ€™t
require typespecs but it can work better if they are added to the code.</p>

<p>Starting with this release Gleam will generate typespecs for all functions
and Erlang type definitions for all declared types within a Gleam program,
giving you one extra tool to help you write robust and reliable code when
using Gleam alongside Elixir or Erlang.</p>

<p>For a quick example, hereâ€™s some code in Gleam:</p>

<div><div><pre><code><span>pub</span> <span>type</span> <span>LinkedList</span><span>(</span><span>element</span><span>)</span> <span>{</span>
  <span>Empty</span>
  <span>Node</span><span>(</span><span>element</span><span>,</span> <span>LinkedList</span><span>(</span><span>element</span><span>))</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>is_empty</span><span>(</span><span>list</span><span>)</span> <span>{</span>
  <span>list</span> <span>==</span> <span>Empty</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>map</span><span>(</span><span>list</span><span>,</span> <span>fun</span><span>)</span> <span>{</span>
  <span>case</span> <span>list</span> <span>{</span>
    <span>Empty</span> <span>-&gt;</span> <span>Empty</span>
    <span>Node</span><span>(</span><span>i</span><span>,</span> <span>list</span><span>)</span> <span>-&gt;</span> <span>Node</span><span>(</span><span>fun</span><span>(</span><span>i</span><span>),</span> <span>map</span><span>(</span><span>list</span><span>,</span> <span>fun</span><span>))</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>And hereâ€™s the Erlang code and typespecs it compiles to:</p>

<div><div><pre><code><span>-</span><span>module</span><span>(</span><span>linked_list</span><span>).</span>
<span>-</span><span>compile</span><span>(</span><span>no_auto_import</span><span>).</span>

<span>-</span><span>export</span><span>([</span><span>is_empty</span><span>/</span><span>1</span><span>,</span> <span>map</span><span>/</span><span>2</span><span>]).</span>
<span>-</span><span>export_type</span><span>([</span><span>linked_list</span><span>/</span><span>1</span><span>]).</span>

<span>-</span><span>type</span> <span>linked_list</span><span>(</span><span>H</span><span>)</span> <span>::</span> <span>empty</span> <span>|</span> <span>{</span><span>node</span><span>,</span> <span>H</span><span>,</span> <span>linked_list</span><span>(</span><span>H</span><span>)}.</span>

<span>-</span><span>spec</span> <span>is_empty</span><span>(</span><span>linked_list</span><span>(</span><span>any</span><span>()))</span> <span>-&gt;</span> <span>boolean</span><span>().</span>
<span>is_empty</span><span>(</span><span>List</span><span>)</span> <span>-&gt;</span>
    <span>List</span> <span>=:=</span> <span>empty</span><span>.</span>

<span>-</span><span>spec</span> <span>map</span><span>(</span><span>linked_list</span><span>(</span><span>R</span><span>),</span> <span>fun</span><span>((</span><span>R</span><span>)</span> <span>-&gt;</span> <span>U</span><span>))</span> <span>-&gt;</span> <span>linked_list</span><span>(</span><span>U</span><span>).</span>
<span>map</span><span>(</span><span>List</span><span>,</span> <span>Fun</span><span>)</span> <span>-&gt;</span>
    <span>case</span> <span>List</span> <span>of</span>
        <span>empty</span> <span>-&gt;</span>
            <span>empty</span><span>;</span>

        <span>{</span><span>node</span><span>,</span> <span>I</span><span>,</span> <span>List</span><span>@</span><span>1</span><span>}</span> <span>-&gt;</span>
            <span>{</span><span>node</span><span>,</span> <span>Fun</span><span>(</span><span>I</span><span>),</span> <span>map</span><span>(</span><span>List</span><span>@</span><span>1</span><span>,</span> <span>Fun</span><span>)}</span>
    <span>end</span><span>.</span>
</code></pre></div></div>

<p>No annotations are required at all in your Gleam code to get full typespec
coverage, Gleamâ€™s compiler reuses the type information from its powerful type
inference algorithm to determine the correct typespecs.</p>

<p>Thank you <a href="https://gitlab.com/greggreg">Greg</a> for this brilliant new feature!</p>

<h2 id="erlang-escripts">Erlang escripts</h2>

<p>Erlang projects are unusual in that typically instead of having a <code>main</code>
function as the entrypoint of your application you define a tree of actors to
come online and process items of work while your program is running.</p>

<p>This can be a powerful way to write long-lived services that make use of the
runtimeâ€™s fault tolerance features, but it does not lend itself well to
short-lived programs such as command line scripts. It can be confusing to
newcomers from other languages too.</p>

<p>For these short lived programs Erlang <a href="https://erlang.org/doc/man/escript.html">escripts</a> are typically used.
These are lightweight Erlang programs that have a <code>main</code> function as an entrypoint.</p>

<p>To make it easier to use these from Gleam the <code>gleam new</code> command now has an
escript template that can be used to create an escript project without any
further configuration required.</p>

<div><div><pre><code>gleam new my_script <span>--template</span> escript
</code></pre></div></div>

<p>A world class developer experience is a key goal of the Gleam project.
Further tooling improvements are right around the corner!</p>

<h2 id="night-mode">Night mode</h2>

<p>Gleam has the ability to render <a href="https://hexdocs.pm/gleam_stdlib/">HTML documentation</a> 
for your code, ready to upload to Hexdocs.</p>

<p>Thanks to <a href="https://github.com/tynanbe">Tynan Beatty</a> the documentation is
looking better than ever! Thereâ€™s too many improvements to list but the big
one is they now have a night mode! If youâ€™re a night owl like me Iâ€™m sure you
will enjoy the lower contrast dark tones when doing some late evening coding.</p>

<p><img src="https://gleam.run/images/news/gleam-v0.14-released/night-mode.png" alt="A screenshot of Gleam's rendered docs showing a beautiful dark theme"></p>

<h2 id="better-errors-again">Better errors, again</h2>

<p>At the risk of sounding like a broken record Gleamâ€™s error messages have been
improved yet again. Hereâ€™s an example of one of the improvements:</p>

<p>Before:</p>

<div><div><pre><code>error: Syntax error
    â”Œâ”€ /src/thing.gleam:115:18
    â”‚
115 â”‚ pub fn overlappedBy(compare, a, b) -&gt; Bool {
    â”‚                  ^^ I was not expecting this.

Expected one of: "("
</code></pre></div></div>

<p>Now:</p>

<div><div><pre><code>error: Syntax error
    â”Œâ”€ /src/thing.gleam:115:18
    â”‚
115 â”‚ pub fn overlappedBy(compare, a, b) -&gt; Bool {
    â”‚                  ^^ This is not a valid name.

Hint: Names start with a lowercase letter and contain a-z, 0-9, or _.
Try: overlapped_by
</code></pre></div></div>

<p>Thank you to <a href="https://github.com/samontea">Samuel Mercier</a> and <a href="https://github.com/pd-andy">Andy
Thompson</a> for these.</p>

<h2 id="static-bit-string-validation">Static bit string validation</h2>

<p>Bit string syntax is a feature that Gleam inherits from Erlang. It provides a
way to declartively and concisely construct and manipulate raw bits of data
through literals and pattern matching.</p>

<p>With this Gleam release we apply further static analysis to bit string
literals and patterns used in Gleam programs to catch invalid or incorrect
code.</p>

<p>Hereâ€™s an example of one of the errors that may be reported:</p>

<div><div><pre><code>error: Syntax error
  â”Œâ”€ /Users/a/parser_test/src/a.gleam:2:20
  â”‚
2 â”‚   &lt;&lt;1:size(1)-unit(0)&gt;&gt;
  â”‚                    ^ This is not a valid BitString unit value.

Hint: unit must be an integer literal &gt;= 1 and &lt;= 256
See: https://gleam.run/book/tour/bit-strings
</code></pre></div></div>

<p>Thank you <a href="https://gitlab.com/greggreg">Greg</a> for this bit string safety net.</p>

<h2 id="docker-images">Docker images</h2>

<p>Up until now <a href="https://github.com/CrowdHailer">Peter Saxton</a> has been very kindly
building Gleam docker images for use in <a href="https://sendmemo.app/">Memo</a> and the
wider community.</p>

<p>With this release he has ported his build automation over to the Gleam repo
so we have automation creation of OCI/Docker images built and published
automatically with each release.</p>

<p>We are building these variants:</p>

<ul>
  <li><code>gleam-erlang</code>: Gleam and the Erlang tooling on Ubuntu Linux</li>
  <li><code>gleam-erlang-slim</code>: Gleam and the Erlang tooling on slim Debian Linux</li>
  <li><code>gleam-erlang-alpine</code>: Gleam and the Erlang tooling on Alpine Linux</li>
  <li><code>gleam-elixir</code>: Gleam and the Elixir tooling on Ubuntu Linux</li>
  <li><code>gleam-elixir-slim</code>: Gleam and the Elixir tooling on slim Debian Linux</li>
  <li><code>gleam-elixir-alpine</code>: Gleam and the Elixir tooling on Alpine Linux</li>
</ul>

<p>For all the images see the <a href="https://github.com/orgs/gleam-lang/packages/container/package/gleam">Gleam image registry</a>. Thanks Peter!</p>

<h2 id="other-stuff">Other stuff</h2>

<p>These are just some of the highlights, but thereâ€™s plenty more improvements
made to the compiler and the standard library since the last release. For all
the details check out the changelog files:</p>

<ul>
  <li><a href="https://github.com/gleam-lang/gleam/blob/main/CHANGELOG.md">Gleamâ€™s changelog</a></li>
  <li><a href="https://github.com/gleam-lang/stdlib/blob/main/CHANGELOG.md">Gleam stdlibâ€™s changelog</a></li>
</ul>

<h2 id="discord-chat">Discord chat</h2>

<p>Itâ€™s time to plug the Gleam Discord server again! The community continues to
grow and it would be great to have you there too, so please click on the
button below.</p>

<center>
  <a href="https://discord.gg/Fm8Pwmy"><img src="https://img.shields.io/discord/768594524158427167?color=blue" alt="Discord chat"></a>
</center>

<h2 id="try-it-out">Try it out</h2>

<p>If you want to try out the new version of Gleam head over to the <a href="https://gleam.run/getting-started/">getting started
page</a>. Iâ€™d love to hear how you find it and get your feedback so
Gleam can continue to improve.</p>

<p>Want to view some existing Gleam projects? Head on over to the
<a href="https://github.com/gleam-lang/awesome-gleam">awesome-gleam</a> list. Looking for something to build in
Gleam? Check out <a href="https://github.com/gleam-lang/suggestions/issues">the suggestions tracker</a>.</p>

<h2 id="supporting-gleam">Supporting Gleam</h2>

<p>If you would like to help make strongly typed programming on the Erlang
virtual machine a production-ready reality please consider <strong><a href="https://github.com/sponsors/lpil">sponsoring
Gleam</a></strong> via the GitHub Sponsors program.</p>

<p>â­ Or alternatively give us a star on <a href="https://github.com/gleam-lang/gleam">GitHub</a>! â­</p>

<p>This release would not have been possible without the support of all the
people who have <a href="https://github.com/sponsors/lpil">sponsored</a> and contributed
to it, so a huge thank you to them.</p>

<ul>
  <li><a href="https://github.com/adamnbowen">Adam Bowen</a></li>
  <li><a href="https://github.com/amokan">Adam Mokan</a></li>
  <li><a href="https://github.com/aditya7iyengar">Adi Iyengar</a></li>
  <li><a href="https://github.com/scripttease">Al Dee</a></li>
  <li><a href="https://github.com/mudriyjo">Alexander Babin</a></li>
  <li><a href="https://github.com/farhadi">Ali Farhadi</a></li>
  <li><a href="https://github.com/pd-andy">Andy Thompson</a></li>
  <li><a href="https://github.com/bees">Arian Daneshvar</a></li>
  <li><a href="https://github.com/arnodirlam">Arno Dirlam</a></li>
  <li><a href="https://github.com/benmyles">Ben Myles</a></li>
  <li><a href="https://github.com/nono">Bruno Michel</a></li>
  <li><a href="https://github.com/brightly-salty">Caden Haustein</a></li>
  <li><a href="https://github.com/choonkeat">Chew Choon Keat</a></li>
  <li><a href="https://github.com/chrislloyd">Chris Lloyd</a></li>
  <li><a href="https://github.com/worldofchris">Chris Young</a></li>
  <li><a href="https://github.com/tlvenn">Christian Meunier</a></li>
  <li><a href="https://github.com/clangley">clangley</a></li>
  <li><a href="https://github.com/cleverbunny">Clever Bunny LTD</a></li>
  <li><a href="https://github.com/codec-abc">codec-abc</a></li>
  <li><a href="https://github.com/colelawrence">Cole Lawrence</a></li>
  <li><a href="https://github.com/connorlay">Connor Lay (Clay)</a></li>
  <li><a href="https://github.com/cschembor3">Connor Schembor</a></li>
  <li><a href="https://github.com/unthought">Dan Mueller</a></li>
  <li><a href="https://github.com/davydog187">Dave Lucia</a></li>
  <li><a href="https://github.com/rawkode">David McKay</a></li>
  <li><a href="https://github.com/davidpdrsn">David Pedersen</a></li>
  <li><a href="https://github.com/dangdennis">Dennis Dang</a></li>
  <li><a href="https://github.com/lostbean">Edgar Gomes</a></li>
  <li><a href="https://github.com/ericmj">Eric Meadows-JÃ¶nsson</a></li>
  <li><a href="https://github.com/eterps">Erik Terpstra</a></li>
  <li><a href="https://github.com/floriank">Florian Kraft</a></li>
  <li><a href="https://github.com/itsgreggreg">greggreg</a></li>
  <li><a href="https://github.com/ggpasqualino">Guilherme Pasqualino</a></li>
  <li><a href="https://github.com/hendi">Hendrik Richter</a></li>
  <li><a href="https://github.com/hhandoko">Herdy Handoko</a></li>
  <li><a href="https://github.com/human154">human154</a></li>
  <li><a href="https://github.com/Ian-GL">Ian GonzÃ¡lez</a></li>
  <li><a href="https://github.com/igagen">Ingmar Gagen</a></li>
  <li><a href="https://github.com/ivarvong">Ivar Vong</a></li>
  <li><a href="https://github.com/gampleman">Jakub Hampl</a></li>
  <li><a href="https://github.com/jamesmacaulay">James MacAulay</a></li>
  <li><a href="https://github.com/janpieper">Jan Pieper</a></li>
  <li><a href="https://github.com/jechol">Jechol Lee</a></li>
  <li><a href="https://github.com/jeffkreeftmeijer">Jeff Kreeftmeijer</a></li>
  <li><a href="https://github.com/jiangplus">jiangplus</a></li>
  <li><a href="https://github.com/joecorkerton">Joe Corkerton</a></li>
  <li><a href="https://github.com/Jwsonic">John Palgut</a></li>
  <li><a href="https://github.com/josevalim">JosÃ© Valim</a></li>
  <li><a href="https://github.com/jveiga">JoÃ£o Veiga</a></li>
  <li><a href="https://github.com/jmn">Jussi Norlund</a></li>
  <li><a href="https://github.com/kapp-technology">Kapp Technology</a></li>
  <li><a href="https://github.com/kodeFant">Lars Lillo Ulvestad</a></li>
  <li><a href="https://github.com/lawik">Lars Wikman</a></li>
  <li><a href="https://github.com/leandrocp">Leandro Cesquini Pereira</a></li>
  <li><a href="https://github.com/malcolmseyd">Malcolm Seyd</a></li>
  <li><a href="https://github.com/mario-mazo">mario</a></li>
  <li><a href="https://github.com/mvellandi">Mario Vellandi</a></li>
  <li><a href="https://github.com/markmark206">Mark Markaryan</a></li>
  <li><a href="https://github.com/markusfeyh">Markus</a></li>
  <li><a href="https://github.com/derhechi">Markus Hechenberger</a></li>
  <li><a href="https://github.com/MattCheely">Matthew Cheely</a></li>
  <li><a href="https://github.com/bausano">Michael Bausano</a></li>
  <li><a href="https://github.com/michaeljones">Michael Jones</a></li>
  <li><a href="https://github.com/michallepicki">MichaÅ‚ ÅÄ™picki</a></li>
  <li><a href="https://github.com/mroach">Mike Roach</a></li>
  <li><a href="https://github.com/slashmili">Milad</a></li>
  <li><a href="https://github.com/ndreynolds">Nick Reynolds</a></li>
  <li><a href="http://www.ninefx.com/">NineFX</a></li>
  <li><a href="https://github.com/jraregris">Oddmund StrÃ¸mme</a></li>
  <li><a href="https://github.com/sorentwo">Parker Selbert</a></li>
  <li><a href="https://github.com/phiat">Patrick Ryan</a></li>
  <li><a href="https://github.com/PeteJodo">Pete Jodo</a></li>
  <li><a href="https://github.com/CrowdHailer">Peter Saxton</a></li>
  <li><a href="https://github.com/praveenperera">Praveen Perera</a></li>
  <li><a href="https://github.com/qingliangcn">qingliangcn</a></li>
  <li><a href="https://github.com/happysalada">Raphael Megzari</a></li>
  <li><a href="https://github.com/chouzar">RaÃºl  Humberto Chouza Delgado</a></li>
  <li><a href="https://github.com/redmar">Redmar Kerkhoff</a></li>
  <li><a href="https://github.com/reneklacan">RenÃ© KlaÄan</a></li>
  <li><a href="https://github.com/romatthe">Robin Mattheussen</a></li>
  <li><a href="https://github.com/rvcas">rvcas</a></li>
  <li><a href="https://github.com/samaaron">Sam Aaron</a></li>
  <li><a href="https://github.com/samontea">samontea</a></li>
  <li><a href="https://github.com/mrgleam">Santi</a></li>
  <li><a href="https://github.com/sascha-wolf">Sascha Wolf</a></li>
  <li><a href="https://github.com/sasa1977">SaÅ¡a JuriÄ‡Ã§</a></li>
  <li><a href="https://github.com/scottwey">Scott Wey</a></li>
  <li><a href="https://github.com/seanjensengrey">Sean Jensen-Grey</a></li>
  <li><a href="https://github.com/sporto">Sebastian</a></li>
  <li><a href="https://github.com/shanesveller">Shane Sveller</a></li>
  <li><a href="https://github.com/shritesh">Shritesh Bhattarai</a></li>
  <li><a href="https://github.com/simonewebdesign">Simone Vittori</a></li>
  <li><a href="https://github.com/syukronrm">Syukron Rifail M</a></li>
  <li><a href="https://github.com/terkiterje">Terje Bakken</a></li>
  <li><a href="https://github.com/timbuchwaldt">Tim Buchwaldt</a></li>
  <li><a href="https://github.com/tomekowal">Tomasz Kowal</a></li>
  <li><a href="https://github.com/thara">Tomochika Hara</a></li>
  <li><a href="https://github.com/topherhunt">Topher Hunt</a></li>
  <li><a href="https://github.com/tsloughter">Tristan Sloughter</a></li>
  <li><a href="https://github.com/twilco">Tyler Wilcock</a></li>
  <li><a href="https://github.com/tynanbe">tynanbe</a></li>
  <li><a href="https://github.com/wojtekmach">Wojtek Mach</a></li>
</ul>

<p>Thanks for reading! Have fun! ğŸ’œ</p>

</div>

</article></div>]]>
            </description>
            <link>https://gleam.run/news/gleam-v0.14-released/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26185690</guid>
            <pubDate>Thu, 18 Feb 2021 21:16:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Over 140K virus species identified in human gut, 50% never seen before]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26185338">thread link</a>) | @finphil
<br/>
February 18, 2021 | https://nuadox.com/post/643491384977948672/140k-virus-species-in-human-gut | <a href="https://web.archive.org/web/*/https://nuadox.com/post/643491384977948672/140k-virus-species-in-human-gut">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="643491384977948672">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/643491384977948672/140k-virus-species-in-human-gut"><h2>Over 140K virus species identified in human gut, 50% never seen before</h2></a>
                                <figure data-orig-width="1280" data-orig-height="904"><img src="https://64.media.tumblr.com/1a0215a61c5578609506d640223a0ec8/5275df9a1bb2e1fe-38/s1280x1920/64f1e6d38b7d741e57ff618b396d3322a825dc76.jpg" alt="image" data-orig-width="1280" data-orig-height="904" width="1280" height="904"></figure><p><b>- By <a href="https://href.li/?https://www.sanger.ac.uk/">Wellcome Sanger Institute</a> -</b></p><p>

Viruses are the most numerous biological entities on the planet. Now researchers at the Wellcome Sanger Institute and EMBLâ€™s European Bioinformatics Institute (EMBL-EBI) have identified over 140,000 viral species living in the human gut, more than half of which have never been seen before.

<br></p><p>The paper, published today in <i><a href="https://href.li/?https://doi.org/10.1016/j.cell.2021.01.029">Cell</a></i>, contains an analysis of over 28,000 gut microbiome samples collected in different parts of the world. The number and diversity of the viruses the researchers found was surprisingly high, and the data opens up new research avenues for understanding how viruses living in the gut affect human health.</p><p>The human gut is an incredibly biodiverse environment. In addition to bacteria, hundreds of thousands of viruses called bacteriophages, which can infect bacteria, also live in the human gut.</p><p>It is known that imbalances in our gut microbiome can contribute to diseases and complex conditions such as Inflammatory Bowel Disease, allergies and obesity. But relatively little is known about the role our gut bacteria, and the bacteriophages that infect them, play in human health and disease.</p><p>Using a DNA-sequencing method called metagenomics*, researchers at the Wellcome Sanger Institute and EMBLâ€™s European Bioinformatics Institute (EMBL-EBI) explored and catalogued the biodiversity of the viral species found in 28,060 public human gut metagenomes and 2,898 bacterial isolate genomes cultured from the human gut.</p><p>The analysis identified over 140,000 viral species living in the human gut, more than half of which have never been seen before.</p><h2>â€œItâ€™s important to remember that not all viruses are harmful, but represent an integral component of the gut ecosystem. For one thing, most of the viruses we found have DNA as their genetic material, which is different from the pathogens most people know, such as SARS-CoV-2 or Zika, which are RNA viruses. Secondly, these samples came mainly from healthy individuals who didnâ€™t share any specific diseases. Itâ€™s fascinating to see how many unknown species live in our gut, and to try and unravel the link between them and human health.â€<b><br></b></h2><p><b>Dr Alexandre Almeida, Postdoctoral Fellow at EMBL-EBI and the Wellcome Sanger Institute</b><br></p><p>Among the tens of thousands of viruses discovered, a new highly prevalent clade â€“ or group of viruses believed to have a common ancestor â€“ was identified, which the authors refer to as the Gubaphage. This was found to be the second most prevalent virus clade in the human gut, after the crAssphage, which was discovered in 2014.</p><p>Both of these viruses seem to infect similar types of human gut bacteria, but without further research itâ€™s very difficult to know the exact functions of the newly discovered Gubaphage.</p><h2>â€œAn important aspect of our work was to ensure that the reconstructed viral genomes were of the highest quality. A stringent quality control pipeline coupled with a machine learning approach enabled us to mitigate contamination and obtain highly complete viral genomes. High-quality viral genomes pave the way to better understand what role viruses play in our gut microbiome, including the discovery of new treatments such as antimicrobials from bacteriophage origin.â€<br></h2><p><b><a href="https://href.li/?https://www.sanger.ac.uk/person/camarillo-guerrero-luis-fernando/">Dr Luis F. Camarillo-Guerrero,</a>&nbsp;first author of the study from the Wellcome Sanger Institute</b></p><p>

The results of the study form the basis of the Gut Phage Database (GPD), a highly curated database containing 142,809 non-redundant phage genomes that will be an invaluable resource for those studying bacteriophages and the role they play on regulating the health of both our gut bacteria and ourselves.

<br></p><h2>â€œBacteriophage research is currently experiencing a renaissance. This high-quality, large-scale catalogue of human gut viruses comes at the right time to serve as a blueprint to guide ecological and evolutionary analysis in future virome studies.â€</h2><p><b><a href="https://href.li/?https://www.sanger.ac.uk/person/lawley-trevor/">Dr Trevor Lawley,</a>&nbsp;senior author of the study from the Wellcome Sanger Institute</b></p><p>â€“</p><p><i>

* Metagenomics is the study of a collection of genetic material (genomes) from a mixed community of organisms. Metagenomics usually refers to the study of microbial communities. The NIH National Human Genome Research Institute has more information here: <a href="https://href.li/?https://www.genome.gov/genetics-glossary/Metagenomics" title="* this link opens in a new window/tab">https://www.genome.gov/genetics-glossary/Metagenomics</a></i><br></p><p><b>Source:&nbsp;<a href="https://href.li/?https://www.sanger.ac.uk/news_item/scientists-identify-over-140000-virus-species-in-the-human-gut-half-of-which-are-new-to-science/">Wellcome Sanger Institute</a></b></p><p><b>Full study:</b>&nbsp;â€œMassive expansion of human gut bacteriophage diversityâ€,&nbsp;<i>Cell</i>.</p><p><a href="https://href.li/?https://doi.org/10.1016/j.cell.2021.01.029">https://doi.org/10.1016/j.cell.2021.01.029</a><br></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/611601599114231808/fruit-fly-gut-microbiome">We could perhaps learn a lot by looking into a fruit flyâ€™s gut</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/virus">virus</a>
                                    
                                        <a href="https://nuadox.com/tagged/gut">gut</a>
                                    
                                        <a href="https://nuadox.com/tagged/biology">biology</a>
                                    
                                        <a href="https://nuadox.com/tagged/microbiology">microbiology</a>
                                    
                                        <a href="https://nuadox.com/tagged/bacteriophage">bacteriophage</a>
                                    
                                        <a href="https://nuadox.com/tagged/molecular-biology">molecular biology</a>
                                    
                                        <a href="https://nuadox.com/tagged/dna">dna</a>
                                    
                                        <a href="https://nuadox.com/tagged/genomics">genomics</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/643491384977948672/140k-virus-species-in-human-gut</link>
            <guid isPermaLink="false">hacker-news-small-sites-26185338</guid>
            <pubDate>Thu, 18 Feb 2021 20:52:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bad Software and Expensive Mistakes]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26185082">thread link</a>) | @mattmarcus
<br/>
February 18, 2021 | https://www.moderntreasury.com/journal/bad-software-and-expensive-mistakes | <a href="https://web.archive.org/web/*/https://www.moderntreasury.com/journal/bad-software-and-expensive-mistakes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Recently, thereâ€™s been discussion about an accidental $900 million wire that Citibank sent out while Revlon was restructuring some of its debt. You can read the details <a href="https://www.bloomberg.com/opinion/articles/2021-02-17/citi-can-t-have-its-900-million-back" target="_blank">here</a>, but in short, the payment escaped controls and was completed, and when the team realized their mistake they asked for their money back. But they <a href="https://arstechnica.com/tech-policy/2021/02/citibank-just-got-a-500-million-lesson-in-the-importance-of-ui-design/" target="_blank">couldnâ€™t</a> get it all back.<br></p><p>Although $900 million is an astonishing number, Citibank is not alone. In 2018 Deutsche Bank accidentally wired an exchange <a href="https://money.cnn.com/2018/04/19/investing/deutsche-bank-35-billion-mistake/index.html" target="_blank">$35 billion</a> â€” $5 billion more than the bank was worth at the time. The worst â€œfat-fingerâ€ mistake I know of happened in Tokyo in 2005, when a trader filed a share order worth <a href="https://spectrum.ieee.org/riskfactor/computing/it/japan-traders-617-billion-fat-finger-nearmiss-rattles-tokyo-market" target="_blank">$617 billion</a> and sent it to the exchange.<br></p><p>These types of errors happen all the time, and theyâ€™re entirely the fault of software, not people.&nbsp;<br></p><p>The Citibank case goes to the heart of why we started Modern Treasury.&nbsp;<br></p><p>In 2015, Sam and I started building a marketplace for individuals to invest in the renovation loans that LendingHome was making. Building a â€œfractionalâ€ marketplace <a href="#1">[1]</a> increases the number of transactions in a system. When it really started working, it exploded the number of payments we made â€” from hundreds to tens of thousands per month â€” and thatâ€™s when we started uncovering the many issues that we now call â€œpayment operations.â€<br></p><p>In spite of being the lifeblood of every business, there has been a dearth of modern software built for payment operations in the past half century. So I wanted to share a few of our near misses and provide a perspective on why we believe so passionately that payment operations deserves great software.&nbsp;</p><h4>Could Citiâ€™s Mistake Have been Prevented?&nbsp;<br></h4><p>There are several levels.<br></p><p>Hereâ€™s a screenshot of the <a href="https://www.oracle.com/industries/financial-services/banking/flexcube-universal-banking/" target="_blank">Flexcube</a> product that the team at Citibank used for this transaction. The team wanted to pay out interest but not loan principal, but in order to do so the software required an internal â€œwashâ€ account, and a process that involved checking three boxes (and no less: checking only one doesnâ€™t trigger any alerts.) I think we can agree that this product is less than intuitive to use.<br></p><figure><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/602ec598b91eff48eb08f141_flexcube.png" loading="lazy" alt=""></p></figure><p>In addition to being simple to use, a payment ops product needs to be flexible. For this team, there is no API, so the workflow had been hard-coded years before. It was so out of date that the team had to have a <a href="https://www.bloomberg.com/opinion/articles/2021-02-17/citi-can-t-have-its-900-million-back" target="_blank">manual</a> to instruct how to work around it. The reason the high amount was being typed in at all was that this â€œsoftware will only let you pay principal to some lenders if you pretend to pay it to every lenderâ€ (<a href="https://www.bloomberg.com/opinion/articles/2021-02-17/citi-can-t-have-its-900-million-back" target="_blank">source</a>). The workflow is so rigid itâ€™s all or nothing.</p><p>Finally, controls. The Citibank team went through three levels of approvals over email. A good payment operations system should dynamically route payments to the right person or persons for release, but only if those users get the information they need to make an informed decision. Over email, that doesnâ€™t happen.&nbsp;</p><p>Good people operating bad software will eventually make a mistake.&nbsp;<br>â€<br></p><h3>How Software Like This Gets Built</h3><h4>Act One: The Tech Team Wants to Talk to the Bank</h4><p>The first realization we had when we set out to solve this problem at LendingHome was that in order to make payments, you must do so through your bank. But banks do not have clean APIs. To compensate, we had to build a custom bank integration.&nbsp;</p><p>The US has a single system for wire transfers, the Fedwire system, and that is the common denominator across all banks. But each bank then operates its own â€œbank coreâ€ software on top of the Fedwire system, and that software maintains accounts and ledgers, records transactions, and so on. The bank therefore actually has a separate interface. So we now have two interfaces:&nbsp;</p><p>Customer -- Bank -- Fedwire</p><p>Building on these interfaces takes investment of time and resources, because bank cores are challenging to integrate with and understand. Some banks use <a href="https://www.moderntreasury.com/journal/what-is-direct-transmission" target="_blank">Direct Transmission</a> over SFTP while others provide SOAP APIs. Timings <a href="https://docs.moderntreasury.com/reference#ach-timings" target="_blank">vary</a>. There are different, competing, data exchange formats for things like reporting on errors, and the configurations can vary from banks on identical cores.&nbsp;<br></p><p>When pressed for resources, teams cut corners. Itâ€™s hard to justify investing in wonderful design and robust systems for internal processes, so much of whatâ€™s out there is half-built, inflexible, and non-intuitive, and rarely gets any attention from the design team.&nbsp;<br></p><p>The result of poor software is workarounds. We had finance colleagues who had Excel wizard skills and a tolerance for manual process pain at which we marveled, but at some point even they would come down to the engineering floor and, in a desperate cry for help, ask us to â€œJUST COMPUTER IT!â€<br></p><p>(We registered that domain a couple of years later. Check out <a href="http://www.justcomputerit.com/" target="_blank">www.justcomputerit.com</a> the next time youâ€™re frustrated with a payment ops problem.)</p><h4>Act Two: Itâ€™s Not One Bank, Itâ€™s Many</h4><p>Itâ€™s not just a single bank integration problem. Itâ€™s many.<br></p><p>Most companies, once they become somewhat large, operate on more than one bank. So not only does the engineering team have to understand and integrate with one bank, they have to repeat that process for each subsequent bank from scratch, and as we have seen, thatâ€™s a scary proposition.<br></p><p>Now we have many integrations:<br></p><p>Customer&nbsp;<br>-- Bank 1 -- Fedwire<br>-- Bank 2 -- Fedwire<br>-- Bank 3 -- Fedwire<br>-- Bank 4 -- Fedwire<br></p><div><p>Every bank is a unique filter on the Fedwire system, making it even harder to make it flexible, intuitive software. The challenges of a single bank integration are now proliferating, and the engineering team tasked with this has to grow.</p></div><h4>Act Three: The Controller Wants Control</h4><p>Thereâ€™s good reasons why bank relationships are sensitive. After all, the executive team has a fiduciary responsibility to make sure company funds are safe and secure at all times. The CFO and their team are concerned about the prospect of the engineering team building an integration to talk to the bank and move money around whenever they want. Not to mention that with each money movement, the accounting team has to track, tag, and reconcile every dollar that moves in and out of every bank account.<br></p><p>â€œMove fast and break thingsâ€ is quite literally the worst way to sell software to CFOs.&nbsp;<br></p><p>So now we discover the next layer of issues: a good bank integration is necessary but not sufficient. There must be a smart, easy-to-use, and intuitive app for the controller that allows them to manage the process. Some of the features this app must have include the ability to create rules to manage the API, to monitor what is happening, and to provide context and trigger approvals for actions that are unexpected.&nbsp;<br></p><p>One such surprise happened to us when we were subleasing office space from Salesforce. The accounting team saw a giant payment to Salesforce and came over to us, angry and flustered that someone irresponsible had sent Salesforce several salariesâ€™ worth of cash for what should have been a few CRM seats. We were amused as we had to explain that indeed, the payment was made to Salesforce, yes, that Salesforce, but no, it wasnâ€™t for software. It was rent.&nbsp;<br></p><h4>Bonus Act: Idempotency and Reversibility</h4><p>There are some very specific engineering concerns that anyone building a payment ops system has to keep in mind.&nbsp;<br></p><p>The first one is idempotency, or doing things only once. We put together a post on <a href="https://www.moderntreasury.com/journal/why-idempotency-matters-in-payments" target="_blank">â€œWhy Idempotency Matters in Payments</a>,â€ which I highly encourage anyone working in payments to read, because the only thing worse than sending the wrong amount is sending it twice.&nbsp;<br></p><p>We lived this. One day we accidentally double-funded every mortgage: many millions of dollars, paid out twice. That was not a good day. Mercifully, because mortgages are disbursed to <a href="https://www.moderntreasury.com/journal/how-to-build-an-escrow-product" target="_blank">escrow</a>, we got all the funds back, but we never forgot idempotency matters in payments after that day.&nbsp;<br></p><div><p>Wires are not reversible, which makes mistakes particularly scary. There are other payment types, such as ACH, that are. If you sent an ACH and you didnâ€™t mean to, or if someone debits your account without your permission, you can reverse it.<a href="#2">[2]</a> Approvals are important, but theyâ€™re particularly important for irreversible transactions, such as the wire Citi sent and couldnâ€™t recall after sending.&nbsp;</p></div><h4>Thinking About Payment Ops as a Single Continuous Process</h4><p>Steve Jobs said, â€œDesign is not just what it looks like and feels like. Design is how it works.â€&nbsp;<br></p><p>This sums up how we believe payment operations should run. Rather than have many silos for information â€” from a database to a CSV to a bank portal to an accounting system â€” we believe in a single piece of payment operations software. This software crosses systems and, perhaps most importantly, it crosses teams. The tech team wants to live in the <a href="https://www.moderntreasury.com/developer-solutions" target="_blank">API</a>, the finance team wants to live in the <a href="https://www.moderntreasury.com/finance-solutions" target="_blank">app</a>, accountants need <a href="https://www.moderntreasury.com/journal/introducing-continuous-accounting" target="_blank">continuous accounting</a>, and customer service teams need to <a href="https://www.moderntreasury.com/journal/how-customer-support-teams-use-modern-treasury" target="_blank">answer customer requests</a>.&nbsp;<br></p><p>Weâ€™ve written at length in the <a href="https://www.moderntreasury.com/journal" target="_blank">Modern Treasury Journal</a> about these issues. ACH, wire, and paper check account for the <a href="https://www.moderntreasury.com/journal/b2b-payments-vs-c2b-payments-what-makes-them-so-different" target="_blank">vast majority</a> of payments in the US, and yet have seen very little innovation in the last fifty years.&nbsp;<br></p><p>We believe that will change this decade. <a href="https://angel.co/company/moderntreasury/jobs" target="_blank">Join us</a>, <a href="https://app.moderntreasury.com/sign_up" target="_blank">build with us</a>, and <a href="https://www.moderntreasury.com/journal" target="_blank">learn with us</a>.&nbsp;<br></p></div></div><div><h4>References</h4><div><div id="1"><p>A fractional loan marketplace is one where each loan is sold not to one institutional investor but to many individuals. This means that every repayment of that loan has to be split between all the investors that &nbsp;invested in each loan, and therefore number of individual transactions in the system balloons.</p></div><div id="2"><div><p>There are lots of ACH return codes, and you can check out our post on <a href="https://www.moderntreasury.com/journal/what-happens-when-you-ach-a-dead-person" target="_blank">What Happens When You ACH a Dead Person </a>to learn more about those.</p></div></div></div></div></div>]]>
            </description>
            <link>https://www.moderntreasury.com/journal/bad-software-and-expensive-mistakes</link>
            <guid isPermaLink="false">hacker-news-small-sites-26185082</guid>
            <pubDate>Thu, 18 Feb 2021 20:32:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Series A to Revolutionize Computing]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26184594">thread link</a>) | @tosh
<br/>
February 18, 2021 | https://blog.repl.it/seriesa | <a href="https://web.archive.org/web/*/https://blog.repl.it/seriesa">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Our mission is to give everyone in the world <strong>computer superpowers</strong>. We build powerful yet approachable tools &amp; platforms for developers, students, and educators.</p>
<p>We see a new generation of hackers and entrepreneurs rising to seize the power of computers and the internet to create software that empowers them and their communities. They refuse to be programmed by the software priesthood that wants them to endlessly consume ads. Instead, they build a more free society where computers work for and under human users, not the other way around. The world we're describing is coming, and we exist to accelerate the shift.</p>
<p><img src="https://repl.art/replit.png" alt="art"></p>
<p>Replit is a multiplayer computing environment that makes it <a href="https://blog.replit.com/internet-of-fun">fun</a> to learn how to code, build, and <a href="https://repl.it/talk/share">share apps</a> with other people. You can create a cloud-powered computer in milliseconds -- we call them "repls" -- and you can create as many of them as you'd like, all for free. Repls come with storage for your code and files, a <a href="https://blog.repl.it/database">database</a> for your data, and a <a href="https://repl.it/site/multiplayer">multiplayer editor</a> &amp; console to code with your friends. For <a href="https://repl.it/pricing">$7/month</a>, you'll get more powerful machines and, with one-click, make them <a href="https://blog.repl.it/alwayson">run forever</a>.</p>
<p><img src="https://blog.repl.it/images/database/database1.gif" alt="db"></p>
<p>When you invite a friend to your repl, you can see them in your editor and talk to them <a href="https://blog.repl.it/annotations-for-education">right in your code</a>. You can make <a href="https://docs.repl.it/repls/http-servers">web</a>, <a href="https://blog.repl.it/native-graphics-love">desktop</a>, and even command-line apps. Replit takes care of the entire process of <a href="https://docs.repl.it/repls/web-hosting">publishing and hosting apps</a> so you can focus on your ideas.</p>
<p><img src="https://venturebeat.com/wp-content/uploads/2021/02/Live-Code-Editing.gif?resize=800%2C450&amp;strip=all" alt="multiplayer"></p>
<p>When you've built something you want to share, you can share the <a href="https://blog.replit.com/spotlight">repl URL</a>, and your users can play with your app, react to it, comment on it, and even fork and remix it. Replit gives you a profile to keep and showcase all your apps and repls. You can make <a href="https://repl.it/site/teams">shared team profiles</a> for your class, friends, or company to collaborate on repls.</p>
<p><img src="https://blog.repl.it/images/spotlight/ios-demo.gif" alt="share"></p>
<p>Because you can make a repl in milliseconds, Replit makes it fun and safe to experiment with ideas. Learning comes naturally as a side effect of playing in the Replit ecosystem.</p>
<p>Millions of people have learned how to code with Replit and built great apps with thousands of happy users. Some have even built businesses and become rich &amp; famous.</p>
<p>Replit's design principles:</p>
<ul>
<li><p><strong>Learnable yet scalable interfaces</strong>: Interfaces today present the same UI to vastly different users, from children to adults, from novices to experts. Our mission demands that we make computing environments more accessible to novices while making it possible to transition to more powerful interfaces. Replit starts with a simple editor and console, which gets learners very far. The UI, however, is adaptable and presents different faces to different users and use-cases.</p>
</li>
<li><p><strong>Infrastructure as legos</strong>: A core part of commanding computer power is to be able to build for the modern internet-connected world. Despite progress in cloud computing, infrastructure remains inaccessible to novices, hobbyists, and educators. We change this by designing simple and scalable components, like cloud-hosted servers accessible right from the repl, storage, databases, etc., that require little configuration and maintenance by the programmer. Coders can then mix and match components to create endless possibilities.</p>
</li>
<li><p><strong>People-centric technology</strong>: It's more exciting and fun to create and learn with other people. The future demands that computers and the internet have human interconnectedness as a core primitive. From our multiplayer computing protocol to our community spaces for sharing software, we build support for human beings, and we put collaboration right at the heart of our technology.</p>
</li>
</ul>
<h2 id="series-a">Series A</h2>
<p>As a team, we've always thought about the long-term, and we've grown Replit responsibly. We have so much conviction in our mission and our plan that we're willing to take our time. </p>
<p>Last year, with rapid growth in all aspects of our business, we felt it was a good time to raise a sizeable round to make faster progress our mission. We raised <a href="https://venturebeat.com/2021/02/18/replit-raises-20-million-for-collaborative-browser-based-coding/">$20M in Series A</a> financing led by <a href="https://acapital.com/">A.Capital</a> with strong participation from our seed investors: Andreessen Horowitz, Bloomberg Beta, Y Combinator, and Reach Capital. </p>
<p>Since then, thanks to the new capital and to <a href="https://amasad.me/moad">Engelbartian Bootstrapping</a>, we've accelerated feature development, and there's so much more on the horizon: extra resources for more complex projects, support for any language or package, further dev ops simplifications for novices and pros, business collaboration features, improvements to <a href="https://repl.it/teams-for-education">teacher workflows</a>, high quality content, a game development library, and more breakthroughs in collaborative coding. We're excited to see all the amazing things you build with the tools we provide!</p>
<p>Finally, we're hiring for multiple roles and want to bring on people who share our vision and passion. If you're interested in making computing more accessible while working with a creative and hardworking team building fantastic technology, <a href="https://repl.it/careers">join us</a>!</p>

	</div></div>]]>
            </description>
            <link>https://blog.repl.it/seriesa</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184594</guid>
            <pubDate>Thu, 18 Feb 2021 19:53:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coronavirus in Slovakia: What Is Going On]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26184366">thread link</a>) | @scandox
<br/>
February 18, 2021 | https://spectator.sme.sk/c/22598901/coronavirus-in-slovakia-what-is-going-on.html | <a href="https://web.archive.org/web/*/https://spectator.sme.sk/c/22598901/coronavirus-in-slovakia-what-is-going-on.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The answer is just three words.</p><div><p><a href="https://m.smedata.sk/api-media/media/image/spectator/9/68/6821849/6821849_1200x.jpeg?rev=3"><img alt="Mathematician Richard KollÃ¡r during the press conference in the Presidential Palace on February 16, 2021. " src="https://m.smedata.sk/api-media/media/image/spectator/9/68/6821849/6821849_600x400.jpeg?rev=3"><span><span><svg width="30px" height="30px"><use xlink:href="#svg-icon-magnifier"></use></svg><span></span></span></span></a><span><small>Mathematician Richard KollÃ¡r during the press conference in the Presidential Palace on February 16, 2021.  (Source: TASR)</small></span></p></div><article data-article-stats-id="22598901" id="js-article" data-user-login-url="https://prihlasenie.sme.sk"><p><span data-deep-event-tags="position-top"><span><span title="pÃ´vodnÃ¡ veÄ¾kosÅ¥ pÃ­sma">Font size:</span><span title="zmenÅ¡iÅ¥ pÃ­smo"><span data-ga-event-id="gaev-art-toolbox" data-ga-event-category="article_toolbox_top" data-ga-event-action="fontminus">A</span><sup>-</sup></span>|<span title="zvÃ¤ÄÅ¡iÅ¥ pÃ­smo"><span data-ga-event-id="gaev-art-toolbox" data-ga-event-category="article_toolbox_top" data-ga-event-action="fontplus">A</span><sup>+</sup></span></span></span></p>
<p><em>Richard KollÃ¡r is a mathematician. He delivered this speech during the press conference after a meeting of scientists with President Zuzana ÄŒaputovÃ¡ on February 16, 2021. </em></p><p>I am a mathematician and I will speak exclusively about numbers and data. I will answer one question, often posed by journalists and the wider public - how we are doing and what is going on regarding the pandemic in Slovakia.</p><p>The answer is very simple. Just three words.</p><p>We don't know. We don't know, in fact.</p><p>I will try to sum up all the things we do not know.</p><p>We are missing absolutely key data to be able to assess the effects of our measures, and the epidemiological situation we are in.</p><p>We have no clue how many people are arriving to hospitals as new patients, we have no clue how many are leaving the hospitals. We therefore cannot say what is causing the increase in the number of hospitalisations we are seeing.</p><p>We don't know that about ventilators either, because the numbers we have do not match. When you put the arrivals and the departures in an equation, you do not get the number we have got now.</p><p>We don't know the age of the hospital patients, so we don't know what's going on.</p><p>We don't know how many infections are hospital-acquired.</p><p>We don't know how many patients are transferred from Covid to non-Covid wards in hospitals.</p><p>We don't know what is the structure of the tests we are performing.</p><p>We don't now how many tests have been done per health indication in hospitals, how many were indicated by epidemiologists or self-indicated.</p><p>We don't know how many tests were part of screening.</p><p>We don't know how many tests are performed in hospitals and what are their results.</p><p>We have no information about tracing.</p><p>We don't now exactly how many people have been traced and how many have been indicated as positive. We don't know how many of the people who were found through tracing ended up in hospitals.</p><p>We don't know what the effectiveness of our tracing is.</p><p>We don't know where the problem lies.</p><p>We don't know about the new variants. We probably have the best tests in Europe to find that out. We are the only country with tests for the British strain. Yet we still don't know how its prevalence developed in the Slovak samples in January. We have looked at one day's sample, but we have no clue how it developed in time. Even though there have been promises and interest in doing that, we still do not have that data.</p><p>We haven't learned from the regional public health offices where Slovak citizens become infected.</p><p>We don't know if it is safe to go to the store. We don't know if it is safe to travel by public transport.</p><p>We don't know how many people got infected where and we do not report such numbers.</p><p>We don't know how the opening of schools last week went, and how many have been closed.</p><p>We don't know how many people have passed through the border crossings and we don't know which countries they came from; how many then end up positive and hospitalised.</p><p>As for the tests proposed by the Education Ministry, we don't know how they have been validated and what are their parametres. We know they are being purchased, but we don't have a clue what they will look like.</p><p>When we apply  theCovid automat, we don't know how its parametres are assessed. We cannot assess the incidence because the numbers of PCR and antigen tests are counted together. PCR tests are reported based on the person's permanent residence, antigen tests are reported based on the testing site location.</p><p>We don't know how things stand with hospitalisations.</p><p>We have no idea how to calculate the reproduction number, which is why we don't dare to announce it during press conferences.</p><p>We have no clue how these three parametres are combined and evaluated on the level of districts.</p><p>We don't know why some districts have the colour they have.</p><p>We don't know why the Health Ministry laid off 10 percent of its staff as part of the corona-crisis measures just like other ministries, and why they have not reinforced the analytical units.</p><p>We are in a data hell. And we don't know if we are facing another wave; if it will be stronger than the one we are going through, or milder.</p><p>We don't know if we are facing the same fate as the Czech city of Cheb, where a quarter of a percent of its inhabitants have died in the past five weeks. Perhaps Slovakia is facing the same.</p><p>We don't know, we have no way of knowing what is going on.</p><p>
            17. Feb 2021 at 13:15
        &nbsp;|&nbsp;Richard KollÃ¡r
    
    </p></article></div>]]>
            </description>
            <link>https://spectator.sme.sk/c/22598901/coronavirus-in-slovakia-what-is-going-on.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184366</guid>
            <pubDate>Thu, 18 Feb 2021 19:31:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BioNTech/Pfizer sought 54.08 Euro per vaccine dose from EU (de)]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 41 (<a href="https://news.ycombinator.com/item?id=26184301">thread link</a>) | @_Microft
<br/>
February 18, 2021 | https://www.tagesschau.de/investigativ/ndr-wdr/corona-impfstoff-biontech-105.html | <a href="https://web.archive.org/web/*/https://www.tagesschau.de/investigativ/ndr-wdr/corona-impfstoff-biontech-105.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                <div>
    
    
    <div>
        <div>
            <p><span>
                    Exklusiv
                </span>
            </p>
            
            <p>
                Stand: 18.02.2021 17:00 Uhr
            </p>
        </div>
    </div>
</div>
                
                    

    
    
        
    
    <p>
        <strong>Die Pharmaunternehmen Pfizer und BioNTech wollten nach Informationen von </strong><strong><em>NDR, WDR</em></strong><strong> und "SZ" im Juni von der EU fÃ¼r eine Dosis Impfstoff 54,08 Euro. Der Arzneimittelchef der Ã„rztekammer spricht von "unseriÃ¶sem Profitstreben".</strong>
    </p>

    

    




    

                
                    

    
    
        <div>

    

    
        <div>
            <p>
                    <span><em>Von Markus Grill und Georg Mascolo,  </em></span><em>
                    <span>NDR/WDR</span></em>
                </p>
        </div>
    
</div>
    

    




    

                
                    

    
    
        
    
    <p>
        Im Juni des vergangenen Jahres ging bei der EU-Kommission ein streng vertrauliches Angebot der Pharmahersteller Pfizer und BioNTech ein. Darin boten sie nach Informationen von <em>NDR, WDR</em> und "SÃ¼ddeutscher Zeitung" ihren Impfstoff zum Preis von 54,08 Euro pro Dosis an, bei einer Abnahme von 500 Millionen Dosen. Insgesamt wollten BioNTech/Pfizer also 27 Milliarden Euro fÃ¼r so viel Impfstoff, dass man damit gut die HÃ¤lfte der EU-BevÃ¶lkerung impfen kÃ¶nnte. Der Preis, so versicherten Pfizer/BioNTech, beinhalte bereits "den hÃ¶chsten prozentualen Rabatt", der einem Industrieland weltweit angeboten worden sei.
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        Mit 54,08 Euro wÃ¤re der BioNTech-Impfstoff allerdings mehr als 20-mal so teuer gewesen wie eine Dosis jenes Impfstoffs, den AstraZeneca gemeinsam mit der UniversitÃ¤t Oxford entwickelt hat. "Ich halte den Preis fÃ¼r unseriÃ¶s", kritisiert der Vorsitzende der Arzneimittelkommission der Deutschen Ã„rzteschaft, Wolf Dieter Ludwig, das Angebot von Pfizer/BioNTech. "Ich sehe darin ein Profitstreben, das in der jetzigen Situation der Pandemie in keiner Weise gerechtfertigt ist."
    </p>

    

    




    

                
                    

    
    
        
    

    




    
        
        
            
            
            
            
            
            
                
    
    

        
    

            
            
            
            
            
        
    

                
                    

    
    
        
    

    




    
        
        
            
            
            
            
            
                
            
            
            
            
            
            
        
    

                
                    

    
    
        

    

    <h2>VerstÃ¤ndnis fÃ¼r ZÃ¶gern der EU</h2>


    

    




    

                
                    

    
    
        
    
    <p>
        WomÃ¶glich werfen diese vergleichsweise hohen Preisvorstellungen auch ein neues Licht auf die ZurÃ¼ckhaltung mancher EU-LÃ¤nder im Sommer gegenÃ¼ber dem BioNTech-Impfstoff. Ludwig jedenfalls sagt, dass er die EU verstehe: "Ich denke, sie hat mit Recht gezÃ¶gert bei einem derartig hohen Preis."
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        In einem Interview mit dem "Spiegel" Anfang des Jahres kritisierte BioNTech-Chef Ugur Sahin die Verhandlungen mit der EU: "Der Prozess in Europa lief sicherlich nicht so schnell und geradlinig ab wie mit anderen LÃ¤ndern", sagte der Firmenchef. "Offenbar herrschte der Eindruck: Wir kriegen genug, es wird alles nicht so schlimm, und wir haben das unter Kontrolle. Mich hat das gewundert."
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        Eine Anfrage zu einem GesprÃ¤ch Ã¼ber das hohe Preisangebot lieÃŸ Sahin diese Woche unbeantwortet. Eine Firmensprecherin beantwortete konkrete Fragen zum Angebot nicht, wies aber darauf hin, dass der Preis fÃ¼r den Impfstoff "von verschiedenen Faktoren abhÃ¤ngig" sei. Er liege "in einer gewissen Spanne fÃ¼r alle LÃ¤nder mit hÃ¶herem Einkommen". Bisher habe das Unternehmen jedoch keine Gewinne gemacht. Wenn man aber Gewinne aus dem Vertrieb des Covid-19-Impfstoffs mache, wolle man diese "in die Weiterentwicklung dieser Technologie reinvestieren". Ein Sprecher der EU-Kommission teilte per E-Mail mit, dass die EU-Kommission aus vertragsrechtlichen GrÃ¼nden keine Angaben Ã¼ber die Preise machen dÃ¼rfe.
    </p>

    

    




    

                
                    

    
    
        
    

    




    
        
        
            
            
            
            
            
                
            
            
            
            
            
            
        
    

                
                    

    
    
        

    

    <h2>Offenbar deutlich niedrigeren Preis durchgesetzt</h2>


    

    




    

                
                    

    
    
        
    
    <p>
        Erst im November kam die EU zu einem Vertragsabschluss mit Pfizer/BioNTech. Der endgÃ¼ltige Preis wird bis heute zwar geheim gehalten, doch nach Informationen von <em>NDR, WDR</em> und "SZ" soll er bei 15,50 Euro pro Dosis liegen. Als erste hatte auch die Nachrichtenagentur Reuters diesen Preis erfahren. Die EU hÃ¤tte damit also eine deutliche Preissenkung gegenÃ¼ber dem Angebot im Juni erreicht.
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        Auch die USA zahlen in etwa gleich viel. Sie hatten im Juli bereits einen Vertrag mit Pfizer geschlossen, der ihnen 100 Millionen Dosen fÃ¼r 1,95 Milliarden Dollar sicherte. Umgerechnet ergibt das rund 16 Euro pro Dosis.
    </p>

    

    




    

                
                    

    
    
        
    

    




    
        
        
            
            
            
            
            
                
            
            
            
            
            
            
        
    

                
                    

    
    
        

    

    <h2>Staatliche Subventionierung in MillionenhÃ¶he</h2>


    

    




    

                
                    

    
    
        
    
    <p>
        Ãœberraschend ist aber nicht nur der hohe Preis, den Pfizer/BioNTech von der EU kassieren wollten, sondern auch die Behauptung in dem Angebot an die EU, man hÃ¤tte die Entwicklung des Impfstoffes "komplett selbst finanziert".
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        Das mag vielleicht fÃ¼r Pfizer gelten. Nicht aber fÃ¼r die deutsche Firma BioNTech, die den Impfstoff entwickelt hatte - auch wenn manche derzeit glauben, dass BioNTech allein mit dem Geld der Hexal-GrÃ¼nder Andreas und Thomas StrÃ¼ngmann aufgebaut wurde. 
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        TatsÃ¤chlich war ihr Engagement entscheidend - aber BioNTech wurde auch mit mehreren Millionen Euro staatlich subventioniert. So teilt das Bundesministerium fÃ¼r Bildung und Forschung (BMBF) auf Anfrage von <em>NDR, WDR</em> und "SZ" mit, dass das Ministerium "die GrÃ¼ndungsphase von Biontech maÃŸgeblich unterstÃ¼tzt und die entscheidenden ersten Jahre der AusgrÃ¼ndung finanziell und auch strukturell gefÃ¶rdert hat".
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        Einen weiteren Schub hatte BioNTech demnach von 2012 bis 2017 als Gewinner des Spitzencluster-Wettbewerbs erhalten, das vom Forschungsministerium mit 12,9 Millionen Euro gefÃ¶rdert worden sei, wie BMBF-Sprecher Stephan KÃ¼gele mitteilte. Auf Nachfrage teilt auch die BioNTech-Sprecherin mit, das Unternehmen habe "wÃ¤hrend der ersten Jahre nach GrÃ¼ndung ca. 50 Millionen Euro FÃ¶rdergelder durch die Clusterinitiative und EU-Programme erhalten." Im Sommer 2020 bekam die Firma weitere 375 Millionen Euro vom Bundesforschungsministerium fÃ¼r die mRNA-basierte Impfstoffentwicklung zugesagt.
    </p>

    

    




    

                
                    

    
    
        
    

    




    
        
        
            
            
            
            
            
                
            
            
            
            
            
            
        
    

                
                    

    
    
        

    

    <h2>Impfschutz wichtiger als AktionÃ¤rsinteressen</h2>


    

    




    

                
                    

    
    
        
    
    <p>
        "Die pharmazeutische Industrie sagt ja immer, die hohen Kosten entstehen aufgrund der Forschungs- und Entwicklungskosten, aber auch, weil der Nutzen so groÃŸ ist", sagt Wolf Dieter Ludwig. TatsÃ¤chlich kÃ¶nne man den Nutzen derzeit aber nicht endgÃ¼ltig beurteilen und die Forschung und Entwicklung sei zum Teil mit staatlichen Geldern subventioniert worden. Allein die US-Regierung zahlte mehrere Milliarden US-Dollar an verschiedene Hersteller. 
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        "Von daher sind diese hohen Preisforderungen aus meiner Sicht nicht berechtigt", sagt Ludwig. Er verstehe zwar, dass die AktionÃ¤re dieser Firmen auch ihren Anteil wollen. "Aber wir sind derzeit in einer Krisensituation, wo es das Ziel sein muss, nicht nur in den IndustrielÃ¤ndern, sondern weltweit zu impfen. Vor diesem Hintergrund, denke ich, haben die Interessen der AktionÃ¤re weniger Bedeutung als die Interessen der BevÃ¶lkerungen, die von dieser Pandemie befreit werden wollen."
    </p>

    

    




    

                
                    

    
    
        
    

    




    
        
        
            
            
            
            
            
            
            
                

    

        

        
    

            
            
            
            
        
    

                
                    

    
    
        
    

    




    
        
        
            
            
            
            
            
                
            
            
     â€¦</article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tagesschau.de/investigativ/ndr-wdr/corona-impfstoff-biontech-105.html">https://www.tagesschau.de/investigativ/ndr-wdr/corona-impfstoff-biontech-105.html</a></em></p>]]>
            </description>
            <link>https://www.tagesschau.de/investigativ/ndr-wdr/corona-impfstoff-biontech-105.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184301</guid>
            <pubDate>Thu, 18 Feb 2021 19:26:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Year of Rails]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26184215">thread link</a>) | @jashkenas
<br/>
February 18, 2021 | https://macwright.com/2021/02/18/a-year-of-rails.html | <a href="https://web.archive.org/web/*/https://macwright.com/2021/02/18/a-year-of-rails.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><picture><source srcset="https://macwright.com/images/2021-02-18-a-year-of-rails-railroad.webp" type="image/webp"><img alt="Railroad" src="https://macwright.com/images/2021-02-18-a-year-of-rails-railroad.jpg"></picture></p><p>I spent most of 2020 working with <a href="https://rubyonrails.org/">Ruby on Rails</a>. I moved a project from <a href="https://nextjs.org/">Next.js</a> + <a href="https://www.rust-lang.org/">Rust</a> toâ€¦&nbsp;Rails, baby! Back to the future. My earlier post on <a href="https://macwright.com/2020/05/10/spa-fatigue.html"><em>Second-guessing the modern web</em></a> was inspired by this experience, that for the product we were building, a â€˜modernâ€™ stack was not working as well as a traditional one.</p><p>We didnâ€™t do competitive analysis against Laravel, Django, or Phoenix. Theyâ€™re similar, not radically better or worse. There are multiple acceptable solutions to a problem, and this was more a matter of choosing the right <em>kind</em> of solution than pursuing some kind of perfect choice and burning hours and motivation doing the window-shopping.</p><p>What helped Rails win was that the team had a little more experience in Ruby (with the exception of myself), and we found plenty of resources for developing and deploying the stack. Rails fit perfectly into the ideology of <a href="http://boringtechnology.club/"><em>Choosing boring technology</em></a>. Another part of the product would be the hard, innovative part, so it made no sense to grapple with bleeding-edge web frameworks.</p><p>This was a really fun experience. Thereâ€™s a lot to love about Rails. Other communities could learn a bit from the Ruby &amp; Rails culture and wisdom. I wonâ€™t implement <em>everything</em> in Rails, but itâ€™ll be part of the toolbox.</p><p>Before this, I hadnâ€™t touched the stuff. And I bet a lot of people are like that - they came of age in the world of React and Go, and havenâ€™t tried anything even remotely similar to Rails. For their benefit, and to debrief from 2020, here are some notes on the experience. Plus, <a href="https://macwright.com/2020/10/28/if-not-spas.html">Rails-like projects in JavaScript</a> are ramping up quickly, and itâ€™s fun to know the origins.</p><h2 id="the-good">The good</h2><h3 id="debugging-rails-apps-is-amazing">Debugging Rails apps is amazing</h3><p>A while ago, I <a href="https://twitter.com/tmcw/status/1321133460501585922">wrote on Twitter</a></p><blockquote><p>the real reason why javascript developers donâ€™t use breakpoints and use console.log is that breakpoints donâ€™t work</p></blockquote><p>After years of working in JavaScript, Iâ€™m used to bad debugging experiences. The Chrome debuggerâ€™s <a href="https://developers.google.com/web/updates/2015/05/automatically-pause-on-any-exception">automatic pause on caught exceptions</a> is amazing, sometimes. But throwing a <code>debugger</code> statement in some React code is dodgy as hell. Sometimes it works, mostly it doesnâ€™t. You have to deal with code that might not have the right <a href="https://www.html5rocks.com/en/tutorials/developertools/sourcemaps/">sourcemap</a> to translate from bundled &amp; minified code to original source. Subtle abstractions like React hooks and advanced transpiler stuff like <a href="https://github.com/facebook/regenerator">Regenerator</a> mean that your codeâ€™s stacktrace probably looks nothing like what you expect, with lots of internal garbage. Sure, you can learn better techniques for diagnosing and debugging errors, but itâ€™s not just you - the debugging story in JavaScript is pretty bad. This applies even to Node.js, where one of the debugging stories is to connect Chromeâ€™s debugger to a Node.js instance:&nbsp;a finicky solution that doesnâ€™t consistently work.</p><p>In Rails, there is <a href="https://github.com/deivid-rodriguez/byebug">byebug</a>. You write <strong><code>byebug</code></strong> in your source code, and you get an interactive REPL right there. It works in views, controllers, database migrations, everywhere. It almost always works. Variables are named what you expect. The whole system is paused at that moment, and you can actually interact with it, using all of the Rails utilities and your installed gems.</p><p>If a page crashes unexpectedly, you get a similar REPL experience, in your browser, automatically. With an automatically cleaned-up stacktrace that excludes Railsâ€™s own frames. Like the byebug interface, this REPL actually works and is consistently helpful in finding root causes. Rarely will you need to use <code>puts</code> to print something to the console because this debugging system is so good.</p><h3 id="the-magic-mostly-works">The magic mostly works</h3><p>Our Rails app didnâ€™t have any <code>require</code> statements. You mention a moduleâ€™s name, and itâ€™s automatically included, using <a href="https://github.com/fxn/zeitwerk">Zeitwork</a>, a tool that comes standard with Rails.</p><p>This kind of system was terrifying to me before. What if you accidentally import something just by mentioning it? What if two things have the same name and you import the wrong one? How do you really know whatâ€™s happening? Sure, youâ€™re happy now, with all of that annoying importing and exporting taken care of, but the sky might fall.</p><p>Or maybe it justâ€¦ doesnâ€™t. Maybe impure, vaguely risky techniques are just a net positive over time, and making everything fully explicit isnâ€™t really necessary? Now when Iâ€™m using other systems, I wonder - what if I could just mention one of my React components and it would justâ€¦ be there? Sure, the system would have to complain if there were two components with the same name, and it would have to make assumptions about directory structure, but overall, wouldnâ€™t this be nice?</p><p>This applies to a lot of other parts of the system too. Rails is famous for doing pluralization - you name a model <code>Post</code> and you automatically get an interface called <code>posts</code>. But what, you ask, of words with uneven pluralization rules? Rails actually&nbsp;<a href="https://weblog.rubyonrails.org/2005/8/25/10-reasons-rails-does-pluralization/">does the right thing</a>, almost always. And when it fails, you can override it. It actually just saves time, reliably.</p><h3 id="testing-works">Testing works</h3><p>Iâ€™ve tried to test front-end applications. Iâ€™ve set up <a href="https://nightwatchjs.org/">nightwatch</a>, <a href="https://jestjs.io/">jest</a>, <a href="https://enzymejs.github.io/enzyme/">enzyme</a>, <a href="https://www.cypress.io/">cypress</a>, and probably 5-10 other frameworks. <em>Front-end testing is universally terrible.</em> Projects like Cypress are throwing untold hours into making it less terrible, taking on massive amounts of complexity to abstract away from fickle browser behavior and complex interactions.</p><p>But it still sucks. Frontend testing has no good attributes: itâ€™s unreliable, hard to automate, hard to debug when it fails, and often doesnâ€™t even assert for important behaviors, so it doesnâ€™t actually identify regressions. Running frontend tests in CI is resource-heavy, requiring you to set up headless X windows environments on servers or use specialized CI services that produce screencasts of test runs.</p><p>Testing fully-server-rendered applications, on the other hand, is <em>amazing</em>. A vanilla testing setup with Rails &amp; <a href="https://rspec.info/">RSpec</a> can give you fast, stable, concise, and actually-useful test coverage. You can actually assert for behavior and navigate through an application like a user would. These tests are solving a simpler problem - making requests and parsing responses, without the need for a full browser or headless browser, without multiple kinds of state to track.</p><p>Not only do the tests work better, the testing culture is a completely different universe. There are entire books written about how to write RSpec tests that catch bugs, allow software evolution, and arenâ€™t filled with boilerplate.</p><h3 id="gems-are-so-powerful">Gems are so powerful</h3><p>Powerful and dangerous.</p><p>Iâ€™m used to modules as they work in other systems - Python, Node, Elm, and so on. They provide objects, functions, and variables that you can import and combine into your code explicitly. Usually they sit on some specific level of abstraction - itâ€™s a utility for connecting to servers or a React component you can use.</p><p>Gems can do so much more. You install something like <a href="https://github.com/heartcombo/devise">Devise</a> into your system and it adds views, routes, methods, utilities, you name it. Itâ€™s not like â€œloading some functionsâ€, itâ€™s more like composing a whole different app <em>into</em> your app, implicitly.</p><p>This is obviously terrifying. It means that you canâ€™t look at your directories of views and your file of <code>routes.rb</code> and know what exists at a glance. There are other layers, lurking in the ephemeral space of third-party code. They interact in serious but uncertain ways.</p><p>But itâ€™s also pretty incredible - the idea that something like <a href="http://www.passportjs.org/">passport</a>, Nodeâ€™s middleware, could instead be a full-fledged authentication system. It means that you have to write a lot less code, and it also means that the people who <em>use</em> that code have a lot more code in common. That gems can work on a higher level of abstraction, making it possible to cobble together software faster, to write less â€˜glue code.â€™</p><h3 id="theres-so-much-good-writing-about-rails">Thereâ€™s so much good writing about Rails</h3><p>Even if you donâ€™t write Ruby, you should pay attention to <a href="https://sandimetz.com/">Sandi Metz</a>. Sheâ€™s incredibly wise and has so many incredible ideas to share.</p><p>And then thereâ€™s <a href="https://blog.arkency.com/">arkency</a>, <a href="https://thoughtbot.com/blog/">ThoughtBot</a>, and so many other thoughtful writers with years of experience in Rails. Sometimes itâ€™s a little shocking to google for some obscure problem and see a decade of discussion about it.</p><p>The best practices are also formalized into tools like <a href="https://codeclimate.com/">Code Climate</a> and <a href="https://github.com/troessner/reek">reek</a>. Iâ€™ve never seen so many actually-useful suggestions come out of automated systems as I did in the world of Ruby and Rails.</p><h3 id="ruby">Ruby</h3><p>Ruby is a pretty pleasant language to work in. Sure, it has a lot of syntax and a sprawling standard library, but you donâ€™t have to use all of that if you donâ€™t want to. It took me a while to adjust to the object-oriented way of doing things - in particular, the idea that you canâ€™t just have a free-range function floating out there, unassociated with a class or module, like you can in JavaScript. And you canâ€™t just create an arbitrary one-off object - you either need to define a class to create an object, or use a Hash to store data.</p><p>But Rubyâ€™s standard library isnâ€™t that huge. Iâ€™ve seen JavaScriptâ€™s â€˜standard libraryâ€™ grow a lot too, and frankly itâ€™s nice to have methods like <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/padStart"><code>String.prototype.padStart</code></a> instead of having every little thing in userspace. The only part that felt actively weird was <a href="https://rubygems.org/gems/activesupport/versions/6.1.1">activesupport</a> - a gem that extends Rubyâ€™s core objects, but is part of Rails. It felt weird to have <em>string</em> methods that would only work if your environment was Rails.</p><p>The <a href="https://kapeli.com/dash">Dash</a> app for documentation rocketed from my pile of unused tools to an absolute must-have. In the world of Ruby and Rails, with <em>most</em> gems having pretty good, semi-standard documentation, you can search for, and get answers, super fast. The Ruby language documentation and the Rails documentation is absolutely great. The JavaScript equivalent - <a href="https://developer.mozilla.org/en-US/">MDN</a> - pales in comparison.</p><h2 id="the-bad">The bad</h2><h3 id="the-asset-pipeline">The asset pipeline</h3><p>Remember SASS and the YUI Compressor? These are, unfortunately, defaults in the <a href="https://guides.rubyonrails.org/asset_pipeline.html">asset pipeline</a>. Thereâ€™s <a href="https://edgeguides.rubyonrails.org/webpacker.html">Webpacker</a> too, which has a parallel approach to CSS and images as the asset pipeline. It has <a href="https://github.com/rails/webpacker#integrations">opinionated integrations</a> with stuff like React. Ah, and I should mention that Railsâ€™s <a href="https://github.com/rails/rails/tree/main/actionview/app/assets/javascripts">JavaScript utilities are written inâ€¦ CoffeeScript</a>.</p><p>I get it - itâ€™s hard to keep up with the latest trends in frontend. But this is one â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://macwright.com/2021/02/18/a-year-of-rails.html">https://macwright.com/2021/02/18/a-year-of-rails.html</a></em></p>]]>
            </description>
            <link>https://macwright.com/2021/02/18/a-year-of-rails.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184215</guid>
            <pubDate>Thu, 18 Feb 2021 19:17:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing a RISC-V CPU, Part 1]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26184136">thread link</a>) | @newswasboring
<br/>
February 18, 2021 | https://mcla.ug/blog/risc-v-cpu-part-1.html#fnref:3 | <a href="https://web.archive.org/web/*/https://mcla.ug/blog/risc-v-cpu-part-1.html#fnref:3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
	
	<p><span>Tue 16 February 2021</span></p><p>I have no experience in digital logic design. That is, I didn't until I
recently decided that I would like to try designing my own CPU and running it
on an FPGA! If you too are a software engineer with a vague interest in
hardware design, I hope this series of posts about what I've learnt will be
helpful and interesting. In this first installment, I hope to answer these
questions:</p>
<ul>
<li>
<p>What is digital logic design?</p>
</li>
<li>
<p>How do I get started, and what tools might I use?</p>
</li>
</ul>
<p>In future installments, I will go into more detail about my CPU design and the
RISC-V architecture, as well as hopefully answering these questions:</p>
<ul>
<li>
<p>What about digital logic design is fundamentally different from software
  design?</p>
</li>
<li>
<p>What about digital logic design is similar to software design?</p>
</li>
</ul>
<p>You can see the code for my CPU at the time of writing
<a href="https://github.com/lochsh/riscy-boi/tree/47e94dc6e9665f73c871add002c34d1516fd5106">here</a>
or an up to date version <a href="https://github.com/lochsh/riscy-boi">here</a>.</p>
<h2>What is digital logic design?</h2>
<p>Digital logic design is designing logic circuits that operate on binary values.
The elementary components are logic gates: an AND gate, for example, has two
inputs and one output. The output is 1 iff<sup id="fnref:1"><a href="#fn:1">1</a></sup> both inputs are 1.</p>
<p>Typically, we design synchronous circuits which use flip-flops to store state,
and thereby synchronise the operation of the circuit to a common clock.
Flip-flops are composed of logic gates.</p>
<p>Analogue circuit design is concerned with the electronic components that make
up logic gates, like transistors and diodes. This level of abstraction is often
needed for applications dealing directly with signals derived from analogue
sensors, like radio receivers. When designing a CPU, this level of abstraction
would not be feasible: modern CPUs can have billions of transistors!</p>
<p>Instead, we use tools that can translate our digital logic design into
different useful formats: the configuration of an FPGA (see below); a
simulation; silicon layout.</p>
<h2>What is an FPGA and why are they used?</h2>
<p>We noted above that the same digital logic design tools can be used whether we
are creating a custom ASIC to be made into silicon, or configuring an FPGA. A
Field-Programmable Gate Array is an integrated circuit containing an array of
programmable logic blocks. You could imagine it is as a big array of logic
gates that can be connected together in various ways.</p>
<p>Making a custom chip generally costs millions, and of course once your chip is
manufactured it cannot be changed. Thus, generally FPGAs are used when:</p>
<ul>
<li>
<p>You cannot afford to create a custom ASIC due to lack of capital (e.g. if
  you're just some hacker like me and not ARM or Intel)</p>
</li>
<li>
<p>You cannot afford to create a custom ASIC because your volume is too low to
  make it worth the high one-off costs (e.g. if you are making a small quantity
  of MRI machines with custom data acquisition hardware)</p>
</li>
<li>
<p>You need the flexibility</p>
</li>
</ul>
<p>The downsides? FPGAs have a much higher per-chip cost, and they are generally
much slower as a consequence of being able to connect logic blocks together in
very flexible ways. In contrast, a custom design can be reduced to the minimum
number of transistors, with no concern for flexibility.</p>
<p>I think it's helpful context to compare the custom ASIC design process against
that of an FPGA design:</p>
<ul>
<li>
<p><span>Logic design</span>: just like we'd do for an FPGA, the logic design of an ASIC is
  done in a hardware description language.</p>
</li>
<li>
<p><span>Verification</span>: FPGA designs may well be verified, but you might expect the
  process for an ASIC design to be more rigorous â€“ after all, the design
  can't be changed once manufactured! Often verification will involve formally
  verifying<sup id="fnref:2"><a href="#fn:2">2</a></sup> parts of the design.</p>
</li>
<li>
<p><span>Synthesis</span>: This creates a <em>netlist</em>: a list of logic blocks and their
  connections. The connections are called <em>nets</em>, and the blocks are called
  <em>cells</em>. For both FPGAs and ASICs, the cells are vendor-specific.</p>
</li>
<li>
<p><span>Placement and routing</span> (P&amp;R): for an FPGA, this involves mapping the logic
  blocks described in the netlist to actual blocks in the FPGA. The resulting
  binary is often called a <em>bitstream</em>.  For an ASIC, this involves deciding
  where to place the cells on the silicon, and how to connect them up. Both
  applications generally use automated optimisation tools for this.</p>
</li>
</ul>
<h2>What tools do I need?</h2>
<h3>A hardware description language: I am using <a href="https://github.com/nmigen/nmigen">nMigen</a><sup id="fnref:3"><a href="#fn:3">3</a></sup></h3>
<p>You may have heard of Verilog or VHDL: both popular hardware description
languages (HDLs). I use "popular" here to mean widely used, not widely loved.</p>
<p>I won't pretend to know much about these tools: I only know that smarter people
than me with vast logic design experience have a lot of hate for them.
Due to the problems with Verilog and other similar tools, there have been
various attempts at making more useful and friendlier alternatives.  nMigen is
one such project, which creates a domain-specific language in Python. In their
own words:</p>
<blockquote>
<p>Despite being faster than schematics entry, hardware design with Verilog and
VHDL remains tedious and inefficient for several reasons. The event-driven
model introduces issues and manual coding that are unnecessary for
synchronous circuits, which represent the lion's share of today's logic
designs. Counterintuitive arithmetic rules result in steeper learning curves
and provide a fertile ground for subtle bugs in designs. Finally, support for
procedural generation of logic (metaprogramming) through "generate"
statements is very limited and restricts the ways code can be made generic,
reused and organized.</p>
<p>To address those issues, we have developed the nMigen FHDL, a library that
replaces the event-driven paradigm with the notions of combinatorial and
synchronous statements, has arithmetic rules that make integers always behave
like mathematical integers, and most importantly allows the design's logic to
be constructed by a Python program. This last point enables hardware
designers to take advantage of the richness of the Python languageâ€”object
oriented programming, function parameters, generators, operator overloading,
libraries, etc.â€”to build well organized, reusable and elegant designs.</p>
</blockquote>
<p>If, like me, you've never used Verilog, then not all of this will have more
than abstract meaning to you. But it certainly sounds promising,
and I can attest that it has been very straightforward to get started with
logic design without the reportedly large barrier of grappling with Verilog. I
would recommend it, particularly if you are already familiar with Python!</p>
<p>The only downside I can think of is that nMigen is still in development, and
in particular the documentation is not complete. There is a helpful community
at #nmigen on <a href="https://mcla.ug/blog/chat.freenode.net">chat.freenode.net</a>.</p>
<h3>A wave viewer for inspecting simulations: I am using <a href="http://gtkwave.sourceforge.net/">GTKWave</a></h3>
<p>nMigen provides simulation tooling: I use it in my tests, written using
<code>pytest</code>. I record the signals during these tests and view them in a wave
viewer to help debug.</p>
<p><img alt="gtkwave" src="https://mcla.ug/blog/images/gtkwave.png" title="A screenshot of GTKWave"></p>
<h3>Optional: An FPGA dev board. I am using a myStorm BlackIce II</h3>
<p>You don't need an FPGA dev board to create your own CPU. You could do
everything in simulation! The fun of having a board to work with, for me, is
being able to flash LEDs and see my design in action.</p>
<p>Of course, if you were creating something more useful than my very basic CPU,
then you would probably want some hardware to run it on, and this would be less
"optional"!</p>
<h2>Getting started with nMigen</h2>
<p>Rather than immediately trying to design a CPU, I started by making an
Arithmetic Logic Unit (ALU) in nMigen. The ALU is a key piece of any CPU design
that I have seen: it performs arithmetic operations.</p>
<p>Why start with this? I knew I would need an ALU for my CPU; I knew I could make
a simple one; I knew that the feeling of making something is an important
motivator when starting a new project!</p>
<p>My design looked something like this:</p>

<div>
<pre id="vimCodeElement"><span id="L1"> 1 </span><span>"""</span><span>Arithmetic Logic Unit</span><span>"""</span>
<span id="L2"> 2 </span><span>import</span> enum
<span id="L3"> 3 </span>
<span id="L4"> 4 </span><span>import</span> nmigen <span>as</span> nm
<span id="L5"> 5 </span>
<span id="L6"> 6 </span>
<span id="L7"> 7 </span><span>class</span> <span>ALUOp</span><span>(</span>enum<span>.</span>IntEnum<span>)</span><span>:</span>
<span id="L8"> 8 </span>    <span>"""</span><span>Operations for the ALU</span><span>"""</span>
<span id="L9"> 9 </span>    ADD <span>=</span> <span>0</span>
<span id="L10">10 </span>    SUB <span>=</span> <span>1</span>
<span id="L11">11 </span>
<span id="L12">12 </span>
<span id="L13">13 </span><span>class</span> <span>ALU</span><span>(</span>nm<span>.</span>Elaboratable<span>)</span><span>:</span>
<span id="L14">14 </span>    <span>"""</span>
<span id="L15">15 </span><span>    Arithmetic Logic Unit</span>
<span id="L16">16 </span>
<span id="L17">17 </span><span>    * op (in): the opcode</span>
<span id="L18">18 </span><span>    * a (in): the first operand</span>
<span id="L19">19 </span><span>    * b (in): the second operand</span>
<span id="L20">20 </span>
<span id="L21">21 </span><span>    * o (out): the output</span>
<span id="L22">22 </span><span>    </span><span>"""</span>
<span id="L23">23 </span>
<span id="L24">24 </span>    <span>def</span> <span>__init__</span><span>(</span>self<span>,</span> width<span>)</span><span>:</span>
<span id="L25">25 </span>        <span>"""</span>
<span id="L26">26 </span><span>        Initialiser</span>
<span id="L27">27 </span>
<span id="L28">28 </span><span>        Args:</span>
<span id="L29">29 </span><span>            width (int): data width</span>
<span id="L30">30 </span><span>        </span><span>"""</span>
<span id="L31">31 </span>        self<span>.</span>op <span>=</span> nm<span>.</span>Signal<span>()</span>
<span id="L32">32 </span>        self<span>.</span>a <span>=</span> nm<span>.</span>Signal<span>(</span>width<span>)</span>
<span id="L33">33 </span>        self<span>.</span>b <span>=</span> nm<span>.</span>Signal<span>(</span>width<span>)</span>
<span id="L34">34 </span>        self<span>.</span>o <span>=</span> nm<span>.</span>Signal<span>(</span>width<span>)</span>
<span id="L35">35 </span>
<span id="L36">36 </span>    <span>def</span> <span>elaborate</span><span>(</span>self<span>,</span> _<span>)</span><span>:</span>
<span id="L37">37 </span>        m <span>=</span> nm<span>.</span>Module<span>()</span>
<span id="L38">38 </span>
<span id="L39">39 </span>        <span>with</span> m<span>.</span>Switch<span>(</span>self<span>.</span>op<span>)</span><span>:</span>
<span id="L40">40 </span>            <span>with</span> m<span>.</span>Case<span>(</span>ALUOp<span>.</span>ADD<span>)</span><span>:</span>
<span id="L41">41 </span>                m<span>.</span>d<span>.</span>comb <span>+=</span> self<span>.</span>o<span>.</span>eq<span>(</span>self<span>.</span>a <span>+</span> self<span>.</span>b<span>)</span>
<span id="L42">42 </span>            <span>with</span> m<span>.</span>Case<span>(</span>ALUOp<span>.</span>SUB<span>)</span><span>:</span>
<span id="L43">43 </span>                m<span>.</span>d<span>.</span>comb <span>+=</span> self<span>.</span>o<span>.</span>eq<span>(</span>self<span>.</span>a <span>-</span> self<span>.</span>b<span>)</span>
<span id="L44">44 </span>        <span>return</span> m
</pre>
</div>

<p>As you can see, we've created a lot of nMigen <code>Signal</code> instances to represent
well...the signals that define the interface to our ALU! But what is this
<code>elaborate</code> method? My understanding is that "elaboration" is the name for the
first step in synthesising the netlist (see above). The idea in the nMigen code
above is that we've created some <em>elaboratable</em> structure (by inheriting from
<code>nm.Elaboratable</code>), i.e. something that describes digital logic we want to
synthesise. The <code>elaborate</code> method describes that digital logic. It has to
return an nMigen <code>Module</code>.</p>
<p>Let's have a closer look at the contents of the <code>elaborate</code> method. The
<code>Switch</code> will create some kind of decision logic in the synthesised design.
But what is <code>m.d.comb</code>? nMigen has the concept of synchronous (<code>m.d.sync</code>)
and combinatorial<sup id="fnref:4"><a href="#fn:4">4</a></sup> (<code>m.d.comb</code>) control domains. From the nMigen
<a href="https://nmigen.info/nmigen/latest/lang.html#lang-domains">docs</a>:</p>
<blockquote>
<p>A control domain is a named group of signals that change their value in
identical conditions.</p>
<p>All designs have a single predefined <em>combinatorial domain</em>, containing all
signals that change immediately when any value used to compute them changes.
The name comb is reserved for the combinatorial domain.</p>
<p>A design can also have any amount of user-defined <em>synchronous domains</em>, also
called clock domains, containing signals that change when a specific edge
occurs on the domainâ€™s â€¦</p></blockquote></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mcla.ug/blog/risc-v-cpu-part-1.html#fnref:3">https://mcla.ug/blog/risc-v-cpu-part-1.html#fnref:3</a></em></p>]]>
            </description>
            <link>https://mcla.ug/blog/risc-v-cpu-part-1.html#fnref:3</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184136</guid>
            <pubDate>Thu, 18 Feb 2021 19:11:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scala 3.0.0-RC1 â€“ first release candidate is here]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 4 (<a href="https://news.ycombinator.com/item?id=26184110">thread link</a>) | @tmfi
<br/>
February 18, 2021 | https://dotty.epfl.ch/blog/2021/02/17/scala3-rc1.html | <a href="https://web.archive.org/web/*/https://dotty.epfl.ch/blog/2021/02/17/scala3-rc1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-wrapper"> 
   <main> 
    <header> 
      
      
    </header> 
    <p>Greetings from the Scala 3 team! We are delighted to announce the first release candidate of the stable version of Scala 3 â€“ Scala 3.0.0-RC1.</p> 
    <p>This release brings some last-minute polishings, clean-ups and changes before the big release. There were a few language changes to improve the user experience, as well as the polishings of the metaprogramming framework. We have also worked on the issues that had to be fixed before the stable release.</p> 
    <p>Overall, more than <a href="https://github.com/lampepfl/dotty/pulls?q=is%3Apr+is%3Aclosed+closed%3A%3E2020-12-02+sort%3Acomments-desc">400 PRs</a> were merged after the M3 release and until today! Read more below!</p> <!--more--> 
     
    <p>Type parameters on extensions can now be combined with type parameters on the methods themselves. E.g.:</p> 
    <pre><code>List(1, 2, 3).second[Int]
extension [A](xs: List[A])
   def sumBy[B](f: A =&gt; B)(using Numeric[B]): B = ...
</code></pre> 
    <p>Type arguments matching method type parameters are passed as usual:</p> 
    <pre><code>List("a", "bb", "ccc").sumBy[Int](_.length)
</code></pre> 
    <p>By contrast, type arguments matching type parameters following <code>extension</code> can be passed only if the method is referenced as a non-extension method:</p> 
    <pre><code>sumBy[String](List("a", "bb", "ccc"))(_.length)
</code></pre> 
    <p>Or, when passing both type arguments:</p> 
    <pre><code>sumBy[String](List("a", "bb", "ccc"))[Int](_.length)
</code></pre> 
    <p>For discussion, see <a href="https://github.com/lampepfl/dotty/pull/10940">PR #10940</a>. For more information about the extension methods, see <a href="https://dotty.epfl.ch/docs/reference/contextual/extension-methods.html">documentation</a>.</p> 
     
    <p>The following are the changes to the <code>import</code> syntax made in this release.</p> 
    <p>Wildcard import <code>_</code> is replaced by <code>*</code>. The motivation is that the majority of other languages use <code>*</code>. For example:</p> 
    <pre><code>import scala.annotation.*  // imports everything in the annotation package
</code></pre> 
    <p>Renaming operator <code>=&gt;</code> is replaced by a soft keyword <code>as</code>. <code>as</code> is also allowed outside braces. For example:</p> 
    <pre><code>import scala.collection.mutable as mut
import NumPy as np
</code></pre> 
    <p>For the details and discussion, see <a href="https://github.com/lampepfl/dotty/pull/11244">PR #11244</a>. Read more about this change in the <a href="https://dotty.epfl.ch/docs/reference/changed-features/imports.html">documentation</a>.</p> 
     
    <p><a href="https://github.com/lampepfl/dotty/pull/11240">PR #11240</a> changed the syntax of vararg splices in patterns and function arguments. The new syntax uses a postfix <code>*</code>, instead of <code>: _*</code>, analogously to how a vararg parameter is declared.</p> 
     
    <p>An obscure use of <code>_</code> occurs in var definitions:</p> 
    <pre><code>var x: T = _
</code></pre> 
    <p>It defines a concrete variable x without an initial value, or rather the default initial value that the JVM assigns to object fields. It can only be used in a class or object, not to initialize a local variable.</p> 
    <p>We came up with an arguably better way to express this idiom: the special <code>uninitialized</code> value in the <code>scala.compiletime</code> object. To get an uninitialized field, you now write:</p> 
    <pre><code>import scala.compiletime.uninitialized

var x: A = uninitialized
</code></pre> 
    <p>This way expresses the intent of the idiom in a more verbose and easy to read way than simply writing an underscore.</p> 
    <p>For discussion, see <a href="https://github.com/lampepfl/dotty/pull/11231">PR #11231</a>, and the <a href="https://dotty.epfl.ch/docs/reference/dropped-features/wildcard-init.html">documentation</a> is available on our website.</p> 
     
    <p>Starting from RC1, we no longer generate a function parent for companions of case classes. Which means, for example, that given <code>case class Foo(x: Int)</code>, you won't be able to use <code>Foo</code> in a position where a function is expected:</p> 
    <pre><code>case class Foo(x: Int)
def f(g: Int =&gt; Foo) = g(10)

f(Foo)
</code></pre> 
    <p>Results in:</p> 
    <pre><code>1 |f(Foo)
  |  ^^^
  |The method `apply` is inserted. The auto insertion will be deprecated, please write `Foo.apply` explicitly.
</code></pre> 
    <p>As the warning suggests, now you should write <code>Foo.apply</code> instead of <code>Foo</code>. See <a href="https://github.com/lampepfl/dotty/issues/6190">Issue #6190</a> and <a href="https://github.com/lampepfl/dotty/pull/7207">PR #7207</a> for discussion.</p> 
     
    <p>We have settled on using the well-known <code>scaladoc</code> as a name for the documentation tool for Scala 3 (known previously as <code>scala3doc</code>).. The obsolete <code>dotty-doc</code> (or <code>scala3-doc</code>) is removed in RC1. We have also removed all the Kotlin dependencies (Dokka, etc.) from scaladoc. For details, see <a href="https://github.com/lampepfl/dotty/pull/11349">PR #11349</a>. To read more about <code>scaladoc</code>, see <a href="https://dotty.epfl.ch/docs/usage/scaladoc/index.html">documentation</a></p> 
     
    <p><a href="https://github.com/lampepfl/dotty/pull/11355">PR #11355</a> changes the <code>-source</code> specifier for the Scala version(s) after 3.0 from <code>3.1</code> to <code>future</code>. I.e. it is now <code>-source future</code> and <code>-source future-migration</code> instead of <code>-source 3.1</code> and <code>-source 3.1-migration</code>. Language imports are changed analogously. The reason for the change is that we want to keep the possibility open to ship a <code>3.1</code> version that does not yet contain all the changes enabled under <code>-source future</code>.</p> 
     
    <ul> 
     <li>Warn when matching against an opaque type <a href="https://github.com/lampepfl/dotty/pull/10664">#10664</a></li> 
     <li>Fix <a href="https://github.com/lampepfl/dotty/issues/8634">#8634</a>: Support -release option <a href="https://github.com/lampepfl/dotty/pull/10746">#10746</a> â€“ the same way Scala 2 does. This setting allows you to specify a version of the Java platform (8, 9 etc) and compile the code with classes specific to the that Java platform, and emit the bytecode for that version.</li> 
    </ul> 
     
    <p>A lot of work has been done on the metaprogramming side of things. Mostly we are cleaning up and polishing the API to prepare it for the stable release. The following are the important metaprogramming changes that took place:</p> 
    <ul> 
     <li>Add <code>scala.quoted.Expr.unapply</code> as dual of <code>Expr.apply</code> <a href="https://github.com/lampepfl/dotty/pull/10580">#10580</a></li> 
     <li>Remove <code>Expr.StringContext.unapply</code> <a href="https://github.com/lampepfl/dotty/pull/10675">#10675</a></li> 
     <li>Add reflect <code>MatchCase</code> <code>TypeRepr</code> <a href="https://github.com/lampepfl/dotty/pull/10735">#10735</a></li> 
     <li>Rename <code>scala.quoted.staging.{Toolbox =&gt; Compiler}</code> <a href="https://github.com/lampepfl/dotty/pull/11129">#11129</a></li> 
     <li>Fix <a href="https://github.com/lampepfl/dotty/issues/10863">#10863</a>: Make show <code>AnyKind</code>ed <a href="https://github.com/lampepfl/dotty/pull/10988">#10988</a></li> 
     <li>Add ParamClause to allow multiple type param clauses <a href="https://github.com/lampepfl/dotty/pull/11074">#11074</a></li> 
     <li>Rework reflect Symbol fields API <a href="https://github.com/lampepfl/dotty/pull/10705">#10705</a></li> 
     <li>Rename <code>Liftable</code> to <code>ToExpr</code> and <code>Unliftable</code> to <code>FromExpr</code> <a href="https://github.com/lampepfl/dotty/pull/10618">#10618</a></li> 
     <li>Expand non-transparent macros after Typer <a href="https://github.com/lampepfl/dotty/pull/9984">#9984</a></li> 
     <li>Rework TastyInspector API to allow inspection of all files <a href="https://github.com/lampepfl/dotty/pull/10792">#10792</a></li> 
     <li>Allow leading context parameters in extension methods <a href="https://github.com/lampepfl/dotty/pull/10940">#10940</a></li> 
     <li>Rename <code>Not</code> to <code>NotGiven</code> to make its purpose clearer <a href="https://github.com/lampepfl/dotty/pull/10720">#10720</a></li> 
     <li>Fix <a href="https://github.com/lampepfl/dotty/issues/10709">#10709</a>: Add missing level check before inlining <a href="https://github.com/lampepfl/dotty/pull/10781">#10781</a></li> 
    </ul> 
     
    <p>If you have questions or any sort of feedback, feel free to send us a message on our <a href="https://gitter.im/lampepfl/dotty">Gitter channel</a>. If you encounter a bug, please <a href="https://github.com/lampepfl/dotty/issues/new">open an issue on GitHub</a>.</p> 
    <h2><a href="#contributors" id="contributors"></a>Contributors</h2> 
    <p>Thank you to all the contributors who made this release possible ğŸ‰</p> 
    <p>According to <code>git shortlog -sn --no-merges 3.0.0-M3..3.0.0-RC1</code> these are:</p> 
    <pre><code>   183  Martin Odersky
   138  Nicolas Stucki
    36  Krzysztof Romanowski
    25  Filip ZybaÅ‚a
    25  Liu Fengyun
    24  Lan, Jian
    22  Jamie Thompson
    19  Tom Grigg
    17  Andrzej Ratajczak
    16  StÃ©phane Micheloud
    15  Guillaume Martres
    11  PaweÅ‚ Marks
     9  Phil
     6  Aleksander Boruch-Gruszecki
     6  Jonathan BrachthÃ¤user
     6  Natsu Kagami
     6  odersky
     4  Jasper Moeys
     4  Adrien Piquerez
     3  SÃ©bastien Doeraene
     3  MichaÅ‚ PaÅ‚ka
     3  Albert Chen
     2  Alexandre Archambault
     2  Som Snytt
     2  kenji yoshida
     2  Luc Henninger
     2  Ayush
     2  Raphael Jolly
     2  Anatolii Kmetiuk
     2  Olivier Blanvillain
     2  changvvb
     1  ysthakur
     1  Ang Hao Yang
     1  Ang9876
     1  AngAng
     1  August Nagro
     1  Ciara O'Brien
     1  Dale Wijnand
     1  Florian Cassayre
     1  Florian Schmaus
     1  Iltotore
     1  Jason Zaugg
     1  Julien Richard-Foy
     1  Katrix
     1  Master-Killer
     1  Michael Pilquist
     1  Mikael Blomstrand
     1  Mike Samuel
     1  Philippus
     1  Philippus Baalman
     1  Rick M
     1  Stephane MICHELOUD
     1  Timur Abishev
     1  Tomas
     1  ansvonwa
     1  ayush
     1  costa100
     1  iroha168
     1  noti0na1
     1  riiswa
     1  tanishiking
</code></pre> 
    <p>If you want to get your hands dirty and contribute to Scala 3, now is a good time to get involved! Head to our <a href="https://dotty.epfl.ch/docs/contributing/getting-started.html">Getting Started page for new contributors</a>, and have a look at some of the <a href="https://github.com/lampepfl/dotty/issues?q=is%3Aissue+is%3Aopen+label%3Aexp%3Anovice">good first issues</a>. They make perfect entry points into hacking on the compiler.</p> 
    <p>We are looking forward to having you join the team of contributors.</p> 
    <hr> 
    <p><img id="author-img" src="https://dotty.epfl.ch/images/anatolii.png"> <span id="author-signature"> Anatolii Kmetiuk </span> 
    </p> 
   </main> 
  </div></div>]]>
            </description>
            <link>https://dotty.epfl.ch/blog/2021/02/17/scala3-rc1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184110</guid>
            <pubDate>Thu, 18 Feb 2021 19:09:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rockset is up to 9.4 times faster than Druid on Star Schema Benchmark queries]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26184105">thread link</a>) | @box2A1
<br/>
February 18, 2021 | https://rockset.com/blog/rockset-up-to-9x-faster-than-apache-druid-star-schema-benchmark/ | <a href="https://web.archive.org/web/*/https://rockset.com/blog/rockset-up-to-9x-faster-than-apache-druid-star-schema-benchmark/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Real-time analytics is all about deriving insights and taking actions as soon as data is produced. When broken down into its core requirements, real-time analytics means two things: access to fresh data and fast responses to queries. These are essentially two measures of latency, which we term data latency and query latency, respectively.</p>
<p>Data latency is the time from when data is produced to when it can be queried, and is a function of how efficiently a database can sustain writes. As it usually gets less focus in benchmarks, we released <a href="https://rockset.com/blog/rockset-1-billion-events-in-a-day-with-1-second-data-latency/">RockBench</a>, a data latency benchmark, last September. Using RockBench, we ascertained Rocksetâ€™s suitability for many real-time analytics applications due to its ability to keep data latency to under 1 second, while ingesting 1 billion events per day, on a standard 4XLarge Virtual Instance.</p>
<h3>Query Latency and the Star Schema Benchmark</h3>
<p>Query latency is the second key measure of real-time analytics performance and is the focus of the rest of this post.
To evaluate query latency, we turned to the Star Schema Benchmark (SSB), an industry-standard benchmark to measure database performance on analytical applications. The SSB was designed for a batch analytics scenario, rather than real-time analytics, but will still yield useful insight into Rocksetâ€™s performance on analytical queries.</p>
<p>The SSB has also been used for performance measurements of other modern data technologies. In June 2020, Imply released a <a href="https://go.imply.io/rs/910-OTN-223/images/Apache-Druid-and-Google-BigQuery-performance-evaluation.pdf">study</a> of Apache Druid and Google BigQuery performance on the SSB. For the Rockset benchmark, we used the same hardware resources that were used in the Druid benchmark to provide greater context for our SSB evaluation.</p>
<h3>Up to 9.4x Faster than Druid</h3>
<p>From the benchmarking results, we observed one SSB query execute 9.4x faster on Rockset than on Druid, with many queries running 2x to 4x faster. The entire SSB suite ran 1.5x faster on <a href="https://rockset.com/comparisons/rockset-vs-apache-druid">Rockset compared to Druid</a>. This demonstrates better performance with resource parity, since pricing was not available for a true price-performance comparison.</p>
<p>In making these comparisons, we recognize we are not experts in configuring Druid, so we relied on a benchmark report from those who have the most knowledge about their system and can tune it best. In addition, benchmarks represent a snapshot in time, and systems will get faster with each new release. We are using the most recent benchmark published by Imply for comparison, but we expect Druid performance will continue to improve, as will Rocksetâ€™s.</p>
<h3>Running the Star Schema Benchmark on Rockset</h3>
<p><strong>Benchmark Overview</strong></p>
<p>The SSB comprises a suite of 13 analytical SQL queries that provide a good combination of functional and selectivity coverage.</p>
<p>We conducted the benchmark using SSB data at scale factor 100, which corresponds to 100GB and 600M rows of data. We denormalized the generated data prior to loading to provide a more direct comparison to the Druid benchmark, which avoided query-time joins, since Druid only recently added some limited join support.</p>
<p><span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/6wQnA481EPGFKQEBq9jqlD/c385adf28f987ec64149ee5ce6b6af4c/rockset-ssb-diagram.png?w=560&amp;fm=webp 560w,
https://images.ctfassets.net/1d31s1aajogl/6wQnA481EPGFKQEBq9jqlD/c385adf28f987ec64149ee5ce6b6af4c/rockset-ssb-diagram.png?w=1120&amp;fm=webp 1120w,
https://images.ctfassets.net/1d31s1aajogl/6wQnA481EPGFKQEBq9jqlD/c385adf28f987ec64149ee5ce6b6af4c/rockset-ssb-diagram.png?w=2240&amp;fm=webp 2240w" sizes="(max-width: 590px) 100vw, 590px" type="image/webp">
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/6wQnA481EPGFKQEBq9jqlD/c385adf28f987ec64149ee5ce6b6af4c/rockset-ssb-diagram.png?w=560 560w,
https://images.ctfassets.net/1d31s1aajogl/6wQnA481EPGFKQEBq9jqlD/c385adf28f987ec64149ee5ce6b6af4c/rockset-ssb-diagram.png?w=1120 1120w,
https://images.ctfassets.net/1d31s1aajogl/6wQnA481EPGFKQEBq9jqlD/c385adf28f987ec64149ee5ce6b6af4c/rockset-ssb-diagram.png?w=2240 2240w" sizes="(max-width: 590px) 100vw, 590px">
          <img alt="rockset-ssb-diagram" title="" src="https://images.ctfassets.net/1d31s1aajogl/6wQnA481EPGFKQEBq9jqlD/c385adf28f987ec64149ee5ce6b6af4c/rockset-ssb-diagram.png" loading="lazy">
        </picture>
        </span>
      </span>
<em>Figure 1: Performance harness used to generate and load SSB data, run queries and measure query runtimes</em></p>
<p>Loading into Rockset was straightforward and required zero configuration, apart from specifying some keys for column-based clustering. Once the SSB data was loaded into Rockset, we ran a load-generator query script, based on the Rockset Python client, that issued queries and measured runtimes.</p>
<p><strong>Benchmark Results</strong></p>
<p>We recorded the following runtimes across the 13 SSB queries.</p>
<p><span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/gtyqIwjx5kKG2PxpXGrJk/2842c3354e855724fee008c2a252a1da/rockset-ssb-results.png?w=281&amp;fm=webp 281w,
https://images.ctfassets.net/1d31s1aajogl/gtyqIwjx5kKG2PxpXGrJk/2842c3354e855724fee008c2a252a1da/rockset-ssb-results.png?w=562&amp;fm=webp 562w,
https://images.ctfassets.net/1d31s1aajogl/gtyqIwjx5kKG2PxpXGrJk/2842c3354e855724fee008c2a252a1da/rockset-ssb-results.png?w=1124&amp;fm=webp 1124w" sizes="(max-width: 590px) 100vw, 590px" type="image/webp">
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/gtyqIwjx5kKG2PxpXGrJk/2842c3354e855724fee008c2a252a1da/rockset-ssb-results.png?w=281 281w,
https://images.ctfassets.net/1d31s1aajogl/gtyqIwjx5kKG2PxpXGrJk/2842c3354e855724fee008c2a252a1da/rockset-ssb-results.png?w=562 562w,
https://images.ctfassets.net/1d31s1aajogl/gtyqIwjx5kKG2PxpXGrJk/2842c3354e855724fee008c2a252a1da/rockset-ssb-results.png?w=1124 1124w" sizes="(max-width: 590px) 100vw, 590px">
          <img alt="rockset-ssb-results" title="" src="https://images.ctfassets.net/1d31s1aajogl/gtyqIwjx5kKG2PxpXGrJk/2842c3354e855724fee008c2a252a1da/rockset-ssb-results.png" loading="lazy">
        </picture>
        </span>
      </span>
<em>Figure 2: Benchmark results when running SSB on Rockset (600M rows, 100GB data set)</em></p>
<p>All queries in the SSB suite executed in under 1 second on Rockset, with a median runtime of 254 ms. This result demonstrates Rocksetâ€™s ability to run complex analytics with sub-second performance, a common requirement for real-time analytics applications.</p>
<p>When comparing to these results with Druidâ€™s, we observe that 9 out of the 13 queries ran faster on Rockset. Rockset was 9.4x faster on the query with the largest speedup, with many queries in the 2x to 4x range, whereas Druidâ€™s largest advantage was a 3.2x speedup. The suite of 13 queries completed in 4,146 ms on Rockset compared to 6,043 ms on Druid, corresponding to a 1.5x speedup overall. The following figures show Rocksetâ€™s query runtimes compared to those reported in Implyâ€™s Druid and BigQuery paper.</p>
<p><span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/3iI6RKmdNIU1LMPZADHr4L/c85c70cd8a53d8a2e25f1359e210f5ab/rockset-druid-ssb.png?w=408&amp;fm=webp 408w,
https://images.ctfassets.net/1d31s1aajogl/3iI6RKmdNIU1LMPZADHr4L/c85c70cd8a53d8a2e25f1359e210f5ab/rockset-druid-ssb.png?w=815&amp;fm=webp 815w,
https://images.ctfassets.net/1d31s1aajogl/3iI6RKmdNIU1LMPZADHr4L/c85c70cd8a53d8a2e25f1359e210f5ab/rockset-druid-ssb.png?w=1630&amp;fm=webp 1630w" sizes="(max-width: 590px) 100vw, 590px" type="image/webp">
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/3iI6RKmdNIU1LMPZADHr4L/c85c70cd8a53d8a2e25f1359e210f5ab/rockset-druid-ssb.png?w=408 408w,
https://images.ctfassets.net/1d31s1aajogl/3iI6RKmdNIU1LMPZADHr4L/c85c70cd8a53d8a2e25f1359e210f5ab/rockset-druid-ssb.png?w=815 815w,
https://images.ctfassets.net/1d31s1aajogl/3iI6RKmdNIU1LMPZADHr4L/c85c70cd8a53d8a2e25f1359e210f5ab/rockset-druid-ssb.png?w=1630 1630w" sizes="(max-width: 590px) 100vw, 590px">
          <img alt="rockset-druid-ssb" title="" src="https://images.ctfassets.net/1d31s1aajogl/3iI6RKmdNIU1LMPZADHr4L/c85c70cd8a53d8a2e25f1359e210f5ab/rockset-druid-ssb.png" loading="lazy">
        </picture>
        </span>
      </span>
<em>Figure 3: Comparing Rockset and Druid SSB results</em></p>
<p><span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/2nTaKbhcNK407P8T9r15ye/477be128e68d9a5535629d2cbccbbb7f/rockset-ssb-graph.png?w=429&amp;fm=webp 429w,
https://images.ctfassets.net/1d31s1aajogl/2nTaKbhcNK407P8T9r15ye/477be128e68d9a5535629d2cbccbbb7f/rockset-ssb-graph.png?w=857&amp;fm=webp 857w,
https://images.ctfassets.net/1d31s1aajogl/2nTaKbhcNK407P8T9r15ye/477be128e68d9a5535629d2cbccbbb7f/rockset-ssb-graph.png?w=1714&amp;fm=webp 1714w" sizes="(max-width: 590px) 100vw, 590px" type="image/webp">
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/2nTaKbhcNK407P8T9r15ye/477be128e68d9a5535629d2cbccbbb7f/rockset-ssb-graph.png?w=429 429w,
https://images.ctfassets.net/1d31s1aajogl/2nTaKbhcNK407P8T9r15ye/477be128e68d9a5535629d2cbccbbb7f/rockset-ssb-graph.png?w=857 857w,
https://images.ctfassets.net/1d31s1aajogl/2nTaKbhcNK407P8T9r15ye/477be128e68d9a5535629d2cbccbbb7f/rockset-ssb-graph.png?w=1714 1714w" sizes="(max-width: 590px) 100vw, 590px">
          <img alt="rockset-ssb-graph" title="" src="https://images.ctfassets.net/1d31s1aajogl/2nTaKbhcNK407P8T9r15ye/477be128e68d9a5535629d2cbccbbb7f/rockset-ssb-graph.png" loading="lazy">
        </picture>
        </span>
      </span>
<em>Figure 4: Graph showing Rockset, Druid and BigQuery runtimes on SSB queries</em></p>
<h3>How Rockset Accelerates Real-Time Analytics</h3>
<p>Several Rockset features work in concert to accelerate these SSB queries and real-time analytics in general.</p>
<ul>
<li>Converged Indexâ„¢</li>
<li>Column-based clustering</li>
<li>Vectorization</li>
</ul>
<p><strong>Converged Index</strong></p>
<p>Rockset stores all ingested data in a <a href="https://rockset.com/blog/how-rocksets-converged-index-powers-real-time-analytics/">Converged Index</a>, which is a combination of: </p>
<ul>
<li>Inverted index</li>
<li>Column-based index</li>
<li>Row-based index</li>
</ul>
<p>Each query can take advantage of the index that is best suited for it and leads to the fastest execution. For instance, highly selective queries typically benefit from using the inverted index, while queries that require aggregations over large numbers of records will benefit from using the column-based index. By indexing data in three different ways, multiple types of queries can be executed efficiently without any manual intervention.</p>
<p><strong>Column-based clustering</strong></p>
<p>Users can configure column-based clustering so as to colocate data according to a clustering key they specify. This maximizes the opportunity for sequential access and reduces the amount of data that needs to be scanned for each query.</p>
<p><strong>Vectorization</strong></p>
<p>Rockset uses columnar data chunks to exchange data between query execution operators. This allows vectorized processing, where operations are performed on many values, instead of one value, at a time, resulting in more efficient query execution.</p>
<h3>What This Means for Developers of Real-Time Analytics</h3>
<p>With this SSB performance evaluation, we determined that Rockset is capable of delivering the sub-second query latency needed for real-time analytics, with better performance than alternatives like Druid. Coupled with the earlier RockBench evaluation that established Rocksetâ€™s ability to analyze data being written in real time, we see that Rockset can be a good fit for real-time analytics applications that require fast queries on the latest data. These include many use cases like logistics tracking, security analytics, e-commerce personalization, gaming leaderboards and customer-facing SaaS analytics.</p>
<p>While this evaluation was performed on a denormalized data set, Rockset's design also allows it to execute joins efficiently, so applications are not limited to operating on denormalized data. Future work would include running Rockset performance evaluations involving joins on normalized data.</p>
<p>Additionally, SSB data is well structured and therefore less representative of the real-life semi-structured data sets we commonly come across. It should be noted that Rockset can support the same analytical SQL queries on complex, nested data as well.</p>
<p>Given Rocksetâ€™s ability to provide both the write and read performance required for real-time analytics, we invite you to include Rockset in your consideration if you are developing real-time analytics features or products. Read the <a href="http://rockset.com/star-schema-benchmark">Rockset Performance Evaluation on the Star Schema Benchmark</a> white paper to get the details on how we ran the SSB evaluation. Or, <a href="https://console.rockset.com/create">sign up for a free Rockset account</a> to try running your own queries on Rockset!</p></div></div>]]>
            </description>
            <link>https://rockset.com/blog/rockset-up-to-9x-faster-than-apache-druid-star-schema-benchmark/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184105</guid>
            <pubDate>Thu, 18 Feb 2021 19:09:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The 1802 Membership Card Computer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26183553">thread link</a>) | @bilegeek
<br/>
February 18, 2021 | http://www.sunrise-ev.com/1802.htm | <a href="https://web.archive.org/web/*/http://www.sunrise-ev.com/1802.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Once upon a time, microcomputers were simple and easy to understand. So simple in fact that a kid like me, with no computer experience whatsoever, could actually understand them, build them, program them, and put them to work in his very own projects!</p><p>The COSMAC 1802 was created in the 1970's at the dawn of the microcomputer revolution, by <a href="https://en.wikipedia.org/wiki/Joseph_Weisbecker">Joseph Weisbecker</a> of RCA Corporation. It used their new CMOS fabrication process, which had very low power consumption, very high noise immunity, and was very simple to use. It was intended for military and aerospace; applications too tough for other microcomputers to survive.</p><p>But Joe was a hacker at heart. He wrote a series of articles starting in the August 1976 issue of Popular Electronics magazine called "Build the COSMAC ELF". It described a simple low-cost computer, using the 1802 microprocessor. At the time, microcomputer systems cost hundreds to thousands of dollars. (Hmm... they still do today!) But Weisbecker's ELF cost about $80! Yet, it was an honest-to-goodness real live computer, able to do anything its much bigger cousins could do -- albeit a bit slower and cruder.</p><p>It was the ideal computer trainer. Hobbyists built thousands of ELFs, learning about computer design, construction, and programming in the process. A dozen companies produced versions of the ELF, also selling for low prices. It was the "Legos" of computers; a simple building-block computer that could be assembled many ways to become almost anything, limited only by your imagination.</p><p>I learned about computing on my ELF. It put me on a career in engineering, as it did for thousands of others. 1802's got designed into all sorts of amazing things; video games, music synthesizers, auto engine controllers, military weapon systems, and even NASA missions such as the Galileo spacecraft. Eat stardust, PCs and Macs!</p><p>Today's computers are far more powerful than the 1802. But they have also become so complicated that virtually no one can build them or truly understand how they work. We depend on someone else to make them for us, and to provide us with the megabytes of pre-written software needed to do anything with them. You can't learn the basics if there is nothing "basic" to learn on! I decided to do something about it.</p><p>The <strong>Membership Card</strong> is a reproduction of the original Popular Electronics Elf computer, repackaged to fit in a pocket-sized Altoids(R) tin. It is entirely built with 1980's parts and technology. It uses only common low-cost through-hole parts (no custom ICs or surface-mount assembly). To use it, you don't need a modern PC, or megabytes of proprietary software. Now you can learn about computers right from the ground up, and <u>really</u> understand how they work!</p><div>

<img src="http://www.sunrise-ev.com/MembershipCard/dev4k-cpu-asm.jpg" width="464" height="279" title="Membership Card Assembled" alt="Membership Card Assembled">
<img src="http://www.sunrise-ev.com/photos/pixelshim.gif" width="12" height="279">

<h3>What's inside?</h3>

<p>There are two circuit boards, each the size of a credit card. One is the <strong>Membership Card</strong> itself. It has the 1802 microprocessor, up to 64k bytes of memory, 22 bits of I/O, clock, reset, and power supply circuits, plus a supercapacitor to maintain memory contents without power. It can be used by itself as a microcontroller for projects like the Parallax BASIC Stamps or Arduino microcontrollers. All power, input, and output signals are available on the 30-pin header along the bottom.</p>
<br clear="left">

<img src="http://www.sunrise-ev.com/MembershipCard/dev4j-fpanel-asm.jpg" width="464" height="286" title="Membership Card Front Panel Assembled" alt="Membership Card Front Panel Assembled">
<img src="http://www.sunrise-ev.com/photos/pixelshim.gif" width="12" height="286">

<p>The second board is the <strong>Front Panel</strong>. It provides the switches and LEDs for a "blinkin-lights" control panel, just like the classic computers of old. The Front Panel lets you read and write to memory and I/O ports manually, without any help from software or external devices. A USB-serial adapter (<a href="https://www.sparkfun.com/products/9718">Sparkfun #9718</a> or equivalent) plugs directly into the 6-pin header to provide power and serial I/O. The Front Panel also brings the power and I/O signals out to a robust DB25 to connect external devices. It can be plugged into a PC parallel or RS-232 serial port, so a PC can load, save, and run programs.</p>

<p>The Membership Card can be purchased as a bare board with manual, or as a complete kit with all parts including the RCA 1802 microcomputer, 32k bytes of RAM, and even an empty Altoids tin to put it all in. An optional Cover Card provides a finished cover with holes and labels for all the lights, switches, and connectors.</p>

<img src="http://www.sunrise-ev.com/MembershipCard/mshipcardkit.jpg" width="400" height="285" title="Membership Card Kit" alt="Membership Card Kit">
<img src="http://www.sunrise-ev.com/photos/pixelshim.gif" width="20" height="285">

<h3>Specifications</h3>
<ul>
<li>CPU: RCA CDP1802ACE microprocessor.
</li><li>Clock: Stable 4 MHz ceramic resonator.
</li><li>Memory:	32k bytes RAM; plus socket for another 32k RAM or EPROM. Supercapacitor holds RAM contents without power.
</li><li>I/O: one 8-bit output port, with LEDs.
<br>one 8-bit input port, with switches.
<br>one 1-bit output, with red LED.
<br>four 1-bit flag inputs, one with pushbutton switch, one with green LED
<br>one interrupt input.
</li><li>Connectors: 6-pin power/TTL serial connector (/ON, TX, RX, +V, GND).
<br>25-pin DB25 connector with all I/O (power, PC parallel, RS-232 serial).
</li><li>Size: 3-1/2" x 2-1/8" x 3/4" (89 x 54 x 19 mm).
</li><li>Power: 3v to 5v DC at 0.1 to 5ma (depends on clock speed, memory size, and number of LEDs on).
</li><li>Aroma: A hint of curiously strong peppermint.
</li></ul>

<a name="1802mc-special">
<p>The <b>Membership Card</b> is your ticket to the fascinating world of microcomputing. Return with us now to those thrilling days of yesteryear, when the heroic pioneers of the microcomputer revolution built their own computers from scratch, and learned to program them to do incredible things, all for a tiny amount of money!</p>

<hr>
</a><ul><a name="1802mcbare">
	</a><li><a name="1802mcbare"></a><a href="http://www.sunrise-ev.com/MembershipCard/memberk3.pdf">Membership Card Manual, rev.K3</a> in PDF format. This is the current version.
	</li><li><a href="http://www.sunrise-ev.com/MembershipCard/dev4k3-sch.png">Membership Card Schematic</a> in PNG format. How often do you get a real schematic for anything today? The schematic, parts list, and part sources are all in the manual as well.
	</li><li><a href="http://www.sunrise-ev.com/MembershipCard/1802cpuK3.pdf">"Special" 1802 CPU Card Quickstart Manual</a> in PDF format. This is an abbreviated manual for operating the 1802MC CPU card by itself.
	</li><li><a href="http://www.sunrise-ev.com/MembershipCard/memberjk3.pdf">Membership Card Manual, rev.JK3</a> in PDF format. Rev.JK3 was the previous version I was shipping last year. Email me if you need a manual for an older version.
	</li><li><a href="http://www.sunrise-ev.com/MembershipCard/1802cheatsheet.pdf">1802 Elf "Cheat Sheet"</a> in PDF format. A pocket card with the 1802 pinouts, instruction set, and operating summary for the Membership Card and other 1802-based computers.
	</li></ul>
Software
	<ul>
	<li>BASIC for the 1802
		<ul>
		<li><b>Tiny BASIC</b> is Tom Pittman's classic 1976 integer BASIC in just 2K bytes. Lee Hart, Herb Johnson, and Loren Christiansen have tweaked it for the 1802MC's memory map. The vintage TMSI IDIOT monitor is included for serial I/O.
			<ul>
			<li><a href="http://www.sunrise-ev.com/photos/1802/tb0_christiansen.zip">Tiny BASIC</a> is a ZIP file with everything needed. Burn the HEX file into a 4K-32K EPROM. Address the EPROM at 0000h, and RAM at 8000h. It's currently assembled to run with a rev.J or later Front Panel.
			</li><li><a href="http://www.ittybittycomputers.com/IttyBitty/TinyBasic/TBuserMan.txt">Tiny BASIC User Manual</a> by Tom Pittman (c) 1976. It documents the language, and provides many examples and internal details. His <a href="http://www.ittybittycomputers.com/IttyBitty/TinyBasic/">website</a> has more info, sample programs, and the interesting history of Tiny BASIC.
			</li><li><a href="http://www.ittybittycomputers.com/IttyBitty/TinyBasic/TBEK.txt">Tiny BASIC Experimenters Kit</a> This booklet provides many internal details, including an assembler for the intermediate language that Tiny BASIC was written in.
			</li><li><a href="http://www.sunrise-ev.com/photos/1802/TFBOTBAS.HTM">The First Book of Tiny BASIC Programs</a> by Tom Pittman (c) 1981. This is a gold mine of impressive Tiny BASIC programs; games, spreadsheets, disassemblers, etc.
			</li></ul>
		</li><li><b>BASIC3</b> is RCA's floating-point BASIC (equivalent to Microsoft BASIC), written by Ron Cenker in 1981. It's been resurrected by Chuck Yakym, Ed Keefe, Herb Johnson, and Lee Hart to run on the 1802MC or any ELF using the EF3 and Q pins for serial input/output.
			<ul>
			<li><a href="http://www.sunrise-ev.com/MembershipCard/BASIC3v11user.pdf">BASIC3 User Manual</a> for RCA BASIC3, in PDF format.
			</li><li>BASIC3 program ROMs: Download, and burn into a 16K 27C128 or 32K 27C256 EPROM. Address it to start at 0000h (U2-LO), and RAM to start at 8000h (U8-HI). BASIC3 starts immediately on power-up or reset, so no Front Panel or "jump" instruction is needed to start it. BASIC3 includes an auto-start feature; if a BASIC program is stored in ROM, it will run automatically on power-up or reset. <a href="http://www.sunrise-ev.com/MembershipCard/CALL3800.pdf">CALL3800.pdf</a> describes how to use this feature.
				<ul>
				<li><a href="http://www.sunrise-ev.com/MembershipCard/MCBASIC3.bin">MCBASIC3.bin</a> for any version Membership Card by itself (no Front Panel); or with rev.I and earlier MC Front Panels.
				</li><li><a href="http://www.sunrise-ev.com/MembershipCard/MCBASIC3J.bin">MCBASIC3J.bin</a> with rev.J and later Membership Card Front Panels.
				</li></ul>
			</li></ul>
		</li></ul>

</li><li>Monitor programs
	<ul>
	<li>Chuck Yakym's <b>MCSMP Super Monitor Program</b> plus <b>BASIC3</b>, in a single 32K EPROM. Download, and burn it into a 27C256 EPROM. Here are his <a href="http://www.sunrise-ev.com/MembershipCard/Readme.txt">Quickstart notes</a> and <a href="http://www.sunrise-ev.com/MembershipCard/MCSMP20.pdf">Instructions</a> for installing and running MCSMP in PDF format.
<ul>
<li>Versions for an EPROM at 8000h (jumper U2-HI), and RAM at 0000h (jumper U8-LO). In classic ELF fashion, you need a front panel to load an LBR 8000h instruction (C0 80 00) into the first 3 bytes of RAM, and execute it.
<ul>
<li><a href="http://www.sunrise-ev.com/MembershipCard/MCSMP20.bin">MCSMP20.bin</a> for any Membership Card with rev.I or earlier Front Panels.
</li><li><a href="http://www.sunrise-ev.com/MembershipCard/MCSMP20J.bin">MCSMP20J.bin</a> with rev.J and later MC Front Panels.
</li><li><a href="http://www.sunrise-ev.com/MembershipCard/mcsmp20r_vt52_1.1.bin">MCSMP20J plus VT52 Adventureland</a> <span color="red">NEW!</span> MCSMP20J with "Adventureland", written in 1980 by famous game author Scott Adams. It's brought to you by the tireless efforts of Richard Goedeken. Instructions and the source code (licensed under BSD are available <a href="https://github.com/richard42/1802-adventureland-plus">HERE</a> on Github. This version uses VT52 ESC commands, so set your Terminal program for VT52 emulation.
</li><li><a href="http://www.sunrise-ev.com/MembershipCard/mcsmp20r_ansi_1.1.bin">MCSMP20J plus ANSI Adventureland</a> Same, but this version uses ANSI ESC commands to add color. Set your Terminal program for ANSI mode.
</li></ul>
</li><li>Versions for an EPROM at 0000h (jumper U2-LO), and RAM at 8000h (jumper U8-HI). The monitor starts immediately on power-up or reset, so no Front Panel or LBR instruction is needed to start them.
<ul>
<li><a href="http://www.sunrise-ev.com/MembershipCard/MCSMP20A.bin">MCSMP20A.bin</a> for any version Membership Cards, either stand-alone, or with rev.I or earlier Front Panels.
</li><li><a href="http://www.sunrise-ev.com/MembershipCard/MCSMP20B.bin">MCSMP20B.bin</a> for any Membership Card with rev.J or later Front Panels.
</li></ul>
</li></ul>
</li><li><b>ELF-LINK</b> by Josh Bensadon controls the Membership Card from a PC parallel port. No software at all is needed in the Membership Card itself to examine and change memory, and load, save, and execute programs. Here is <a href="http://www.sunrise-ev.com/MembershipCard/ELF-LINK.BAS">ELF-LINK.BAS for QuickBASIC</a> in plain ASCII format, so you can see how to do it with your favorite programming language. And here is <a href="http://www.sunrise-ev.com/MembershipCard/ELF-LINK.exe">ELF-LINK.exe in executable format</a> if you don't have QuickBASIC. Who will be the first to translate it into C? :-)
	</li></ul>
	</li></ul>
More 1802 Information
	<ul>
	<li><a href="http://www.exemark.com/Microcontrollers/PopularElecwebc.pdf">Build the COSMAC "ELF" -- A Low-Cost Experimenter's Microcomputer</a>. The original Aug 1976 Popular Electronics article by Joseph Weisbecker that started it all.
	</li><li><a href="http://www.sunrise-ev.com/vcf-elf.htm">The VCF-ELF</a> is â€¦</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.sunrise-ev.com/1802.htm">http://www.sunrise-ev.com/1802.htm</a></em></p>]]>
            </description>
            <link>http://www.sunrise-ev.com/1802.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-26183553</guid>
            <pubDate>Thu, 18 Feb 2021 18:27:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Frax: Worldâ€™s first fractional-algorithmically stabilized stablecoin]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 4 (<a href="https://news.ycombinator.com/item?id=26183483">thread link</a>) | @Bluestein
<br/>
February 18, 2021 | https://docs.frax.finance/overview | <a href="https://web.archive.org/web/*/https://docs.frax.finance/overview">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div data-editioncontainer="true"><div data-slate-editor="true" data-key="c661deaabfde4250bbd107c32d586f40" autocorrect="on" spellcheck="true" data-gramm="false"><p data-key="5c2f6050e8fe4fbea3690680c1d996b1"><span><span data-key="6ccd4104bbe54ed8bfc0983c8bef054d"><span data-offset-key="6ccd4104bbe54ed8bfc0983c8bef054d:0">Many stablecoin protocols have entirely embraced one spectrum of design (entirely collateralized) or the other extreme (entirely algorithmic with no backing). Collatralized stablecoins either have custodial risk or require on-chain overcollateralization. These designs provide a stablecoin with a fairly tight peg with higher confidence than purely algorithmic designs. Purely algorithmic designs such as Basis, Empty Set Dollar, and Seigniorage Shares provide a highly trustless and scalable model that captures the early Bitcoin vision of decentralized money but with useful stability. The issue with algorithmic designs is that they are difficult to bootstrap, slow to grow (as of Q4 2020 none have significant traction), and exhibit extreme periods of volatility which erodes confidence in their usefulness as actual stablecoins. They are mainly seen as a game/experiment than a serious alternative to collateralized stablecoins.

Frax attempts to be the first stablecoin protocol to implement design principles of both to create a highly scalable, trustless, extremely stable, and ideologically pure on-chain money. The Frax protocol is a two token system encompassing a stablecoin, Frax (FRAX), and a governance token, Frax Shares (FXS). The protocol also has pool contracts which hold collateral (at genesis USDT and USDC). Pools can be added or removed with governance.

Although there's no predetermined timeframes for how quickly the amount of collateralization changes, we believe that as FRAX adoption increases, users will be more comfortable with a higher percentage of FRAX supply being stabilized algorithmically rather than with collateral. The collateral ratio refresh function in the protocol can be called by any user once per hour. The function can change the collateral ratio in steps of .25% if the price of FRAX is above or below $1. When FRAX is above $1, the function lowers the collateral ratio by one step and when the price of FRAX is below $1, the function increases the collateral ratio by one step. Both refresh rate and step parameters can be adjusted through governance. In a future update of the protocol, they can even be adjusted dynamically using a PID controller design. The price of FRAX, FXS, and collateral are all calculated with a time-weighted average of the Uniswap pair price and the ETH:USD Chainlink oracle. The Chainlink oracle allows the protocol to get the true price of USD instead of an average of stablecoin pools on Uniswap. This allows FRAX to stay stable against the dollar itself which would provide greater resiliency instead of using a weighted average of existing stablecoins only.</span></span></span></p><p data-key="6a0fb64f8ddf49a292075e3f23b3f9a4"><span><span data-key="c7f1350efb8f4be4bbfcd688e0dcabba"><span data-offset-key="c7f1350efb8f4be4bbfcd688e0dcabba:0">FRAX stablecoins can be minted by placing the appropriate amount of its constituent parts into the system. At genesis, FRAX is 100% collateralized, meaning that minting FRAX only requires placing collateral into the minting contract. During the fractional phase, minting FRAX requires placing the appropriate ratio of collateral and burning the ratio of Frax Shares (FXS). While the protocol is designed to accept any type of cryptocurrency as collateral, this implementation of the Frax Protocol will mainly accept on-chain stablecoins as collateral to smoothen out volatility in the collateral so that FRAX can transition to more algorithmic ratios smoothly. As the velocity of the system increases, it becomes easier and safer to include volatile cryptocurrency such as ETH and wrapped BTC into future pools with governance. </span></span></span></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://docs.frax.finance/overview</link>
            <guid isPermaLink="false">hacker-news-small-sites-26183483</guid>
            <pubDate>Thu, 18 Feb 2021 18:22:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cutting Build Time in Half with Dockerâ€™s Buildx Kubernetes Driver]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26183334">thread link</a>) | @jeremy_k
<br/>
February 18, 2021 | https://releaseapp.io/blog/cutting-build-time-in-half-docker-buildx-kubernetes | <a href="https://web.archive.org/web/*/https://releaseapp.io/blog/cutting-build-time-in-half-docker-buildx-kubernetes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>At Release, environments are our main focus, but we canâ€™t create environments without builds. Recently we undertook a project to revisit our build infrastructure and determine if it needed to be upgraded. Build times had become a big factor in our service delivery and we needed a way to improve our customersâ€™ experiences. One of the main areas that we wanted to improve upon was the parallelism of building multiple docker images for a single application.</p><p>The title of the article already spoiled the solution, and the alternative â€˜Release Did This One Thing To Cut Their Build Time In Half!â€™ didnâ€™t quite fly with the rest of the company, but Dockerâ€™s new <a href="https://github.com/docker/buildx" target="_blank" rel="noreferrer">buildx</a> project fit the bill. First, weâ€™ll cover what our original infrastructure looked like and how long builds on an example project were taking. Then, weâ€™ll describe the changes we made to use buildx and the speed increases we observed.</p><p>Letâ€™s start off with a diagram of what our original infrastructure looked like.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/75WoaAxoZMIL73zK0JKPId/f98ff948f97c0cc7b979c4b4352a032c/release-builder-architecture.png" alt="release-builder-architecture"></p><p>As you can see, the requests for builds would flow into our main Rails application and then divvied out to the different builder instances through Sidekiq. The <code>builder</code> container is Ruby code that would authenticate to Github, clone the repository, check out the correct SHA, and then execute the <code>docker build</code>. Due to the way we built the authentication to pull the code from Github, a single <code>builder</code> container could only clone one repository at a time. Which meant that the container could only do a single build request at a time. We added threading in the Ruby code to be able to execute multiple <code>docker build</code> commands at a time, but the number of builder containers we had spun up limited our concurrent builds. While itâ€™s not hard to horizontally scale with Kubernetes, we saw this authentication setup as a major bottleneck. </p><p>Another issue we encountered was that we had no mechanism for attempting to place builds on servers where they had been previously built, instead opting for grabbing the first free server. This meant there was very little chance to land on the same server and get the full benefit of Docker caching. While this isnâ€™t a deal breaker for us, we still believed we could do better when creating the version of our build infrastructure. Enough of the theoretical, letâ€™s actually build something!</p><p>Release Applications can contain many docker images and one of our favorite example repositories to showcase this is our fork of <a href="https://github.com/awesome-release/release-example-voting-app" target="_blank" rel="noreferrer">example-voting-app</a>. Looking at the <a href="https://github.com/awesome-release/release-example-voting-app/blob/master/docker-compose.yml" target="_blank" rel="noreferrer">docker-compose</a> we see that there are 3 different Docker images that we have to build, <code>result</code>, <code>vote</code>, and <code>worker</code>. Now that we have an understanding of Releaseâ€™s original infrastructure and the application we want to build, letâ€™s start up a fresh build and see the results.</p><p><em>NOTE</em> I forked the <code>awesome-release</code> repo to my own Github, <code>jer-k</code> for the following results.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/21reYa1lgqocT6MTojva4J/0d6826574fb8718d76bfcf6c855dd490/uncached-release.png" alt="uncached-release"></p><p>We can see that this brand new build with no cache hits took two minutes and 15 seconds to complete. Next, we want to make a few changes to ensure that each Docker image needs to be rebuilt. The changes are listed below.</p><div><pre><p><span>1</span><span>git status</span></p><p><span>2</span><span>On branch release_builders</span></p><p><span>3</span><span>Changes to be committed:</span></p><p><span>4</span><span>  (use "git restore --staged &lt;file&gt;..." to unstage)</span></p><p><span>5</span><span>    modified:   result/views/index.html</span></p><p><span>6</span><span>    modified:   vote/app.py</span></p><p><span>7</span><span>    modified:   worker/src/main/java/worker/Worker.java</span></p></pre></div><p>For the purpose of this blog post, I ensured the following build ran on the same builder as the first and that we will have cache hits. As noted before, this wasnâ€™t always the case in our production environment.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/69tKlV3mBuV6S6c7BhSaay/c51464f443c1888cd4f74fe3394b32f4/cached-release.png" alt="cached-release"></p><p>The caching helps and cuts 45 seconds off the build! The uncached build took almost twice as long as the second build with caching, but our assumption was that we could do a lot better (cached and uncached) with some new technology.</p><h2 id="enter-dockers-buildx-kubernetes-driver">Enter Dockerâ€™s Buildx Kubernetes Driver</h2><p>One of the first things we wanted to solve was the concurrency issue and we set out to ensure that Docker itself was able to handle a larger workload. We came across the issue <a href="https://github.com/moby/moby/issues/9656" target="_blank" rel="noreferrer">Concurrent â€œdocker buildâ€ takes longer than sequential builds</a> where people were describing what we feared; Docker slowed down when many builds were being run at the same time. Lucky for us, that issue was opened in 2014 and plenty of work had been done to resolve this issue. The final comment, by a member of the Docker team, was <a href="https://github.com/moby/moby/issues/9656#issuecomment-610476810" target="_blank" rel="noreferrer">â€œClosing this. BuildKit is highly optimized for parallel workloads. If you see anything like this in buildkit or buildkit compared to legacy builder please report a new issue with a repro case.â€</a> Thus we set out to learn more about <a href="https://docs.docker.com/develop/develop-images/build_enhancements/" target="_blank" rel="noreferrer">BuildKit</a> (the Github repository is located <a href="https://github.com/moby/buildkit" target="_blank" rel="noreferrer">here</a>). While researching, we came across <a href="https://github.com/docker/buildx" target="_blank" rel="noreferrer">buildx</a>, which ended up having three key features we believed would resolve many of our issues. These three features were the <a href="https://github.com/docker/buildx#buildx-bake-options-target" target="_blank" rel="noreferrer">bake</a> command, the <a href="https://github.com/docker/buildx#--driver-driver" target="_blank" rel="noreferrer">buildx kubernetes driver</a>, and the ability for the Kubernetes driver to consistently send builds to the same server. Letâ€™s cover each of these, first up the <code>bake</code> command.</p><div><pre><p><span>1</span><span>buildx bake [OPTIONS] [TARGET...]</span></p><p><span>2</span><span>Bake is a high-level build command.</span></p><p><span>3</span><span></span></p><p><span>4</span><span>Each specified target will run in parallel as part of the build.</span></p></pre></div><p><code>bake</code> intrigued us because it seemed to be a built-in command for us to avoid using Ruby threading for our parallelism. <code>bake</code> takes an input of a file, which can either be in the form of a <code>docker-compose</code>, <code>.json</code>, or <code>.hcl</code>. We initially tested <code>bake</code> with the docker-compose from example-voting-app and we were blown away at how smoothly it built directly out of the box and how quickly it was able to build the three images! However, we opted to create our own <code>.json</code> file generator in Ruby, parsing our <a href="">Application Template</a> into an output. Here is our generated file for example-voting-app.</p><div><pre><p><span>1</span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>"group"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>3</span><span>    </span><span>"default"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>4</span><span>      </span><span>"targets"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>5</span><span>        </span><span>"vote"</span><span>,</span><span></span></p><p><span>6</span><span>        </span><span>"result"</span><span>,</span><span></span></p><p><span>7</span><span>        </span><span>"worker"</span><span></span></p><p><span>8</span><span>      </span><span>]</span><span></span></p><p><span>9</span><span>    </span><span>}</span><span></span></p><p><span>10</span><span>  </span><span>}</span><span>,</span><span></span></p><p><span>11</span><span>  </span><span>"target"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>12</span><span>    </span><span>"vote"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>13</span><span>      </span><span>"context"</span><span>:</span><span> </span><span>"./vote"</span><span>,</span><span></span></p><p><span>14</span><span>      </span><span>"tags"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>15</span><span>        </span><span>"&lt;REDACTED&gt;.dkr.ecr.us-west-2.amazonaws.com/jer-k/release-example-voting-app/vote:latest"</span><span>,</span><span></span></p><p><span>16</span><span>        </span><span>"&lt;REDACTED&gt;.dkr.ecr.us-west-2.amazonaws.com/jer-k/release-example-voting-app/vote:buildx-builders"</span><span></span></p><p><span>17</span><span>      </span><span>]</span><span></span></p><p><span>18</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>19</span><span>    </span><span>"result"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>20</span><span>      </span><span>"context"</span><span>:</span><span> </span><span>"./result"</span><span>,</span><span></span></p><p><span>21</span><span>      </span><span>"tags"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>22</span><span>        </span><span>"&lt;REDACTED&gt;.dkr.ecr.us-west-2.amazonaws.com/jer-k/release-example-voting-app/result:latest"</span><span>,</span><span></span></p><p><span>23</span><span>        </span><span>"&lt;REDACTED&gt;.dkr.ecr.us-west-2.amazonaws.com/jer-k/release-example-voting-app/result:buildx-builders"</span><span></span></p><p><span>24</span><span>      </span><span>]</span><span></span></p><p><span>25</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>26</span><span>    </span><span>"worker"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>27</span><span>      </span><span>"context"</span><span>:</span><span> </span><span>"./worker"</span><span>,</span><span></span></p><p><span>28</span><span>      </span><span>"tags"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>29</span><span>        </span><span>"&lt;REDACTED&gt;.dkr.ecr.us-west-2.amazonaws.com/jer-k/release-example-voting-app/worker:latest"</span><span>,</span><span></span></p><p><span>30</span><span>        </span><span>"&lt;REDACTED&gt;.dkr.ecr.us-west-2.amazonaws.com/jer-k/release-example-voting-app/worker:buildx-builders"</span><span></span></p><p><span>31</span><span>      </span><span>]</span><span></span></p><p><span>32</span><span>    </span><span>}</span><span></span></p><p><span>33</span><span>  </span><span>}</span><span></span></p><p><span>34</span><span></span><span>}</span></p></pre></div><p>There are other inputs which can make their way into this file, such as build args, but since example-voting-app does not have any, they are omitted.</p><p>Next, we wanted to find more information on the Kubernetes driver and we found this blog post <a href="https://medium.com/nttlabs/buildx-kubernetes-ad0fe59b0c64" target="_blank" rel="noreferrer">Kubernetes driver for Docker BuildX</a> from the author of the <a href="https://github.com/docker/buildx/pull/167" target="_blank" rel="noreferrer">Pull Request</a>. We encourage you to read the latter as it covers getting up and running with the Kubernetes driver as well how the caching works, which is exactly what we needed. With that information in hand, we were able to start work on adding the buildx servers to our cluster. We created a generic way to deploy the servers into different clusters and adjust the number of replicas with the final command being</p><div><pre><p><span>1</span><span>docker buildx create --name #{name} --driver kubernetes --driver-opt replicas=#{num_replicas},namespace=#{builder_namespace} --use</span></p></pre></div><p>For us, we created a <code>release-builder</code> namespace with five replicas, in our development cluster. We can see the output by querying for the pods</p><div><pre><p><span>1</span><span>kubectl get pods --namespace=release-builder</span></p><p><span>2</span><span>NAME                            READY   STATUS    RESTARTS   AGE</span></p><p><span>3</span><span>development0-86d99fcf46-26j9f   1/1     Running   0          6d10h</span></p><p><span>4</span><span>development0-86d99fcf46-5scpq   1/1     Running   0          6d13h</span></p><p><span>5</span><span>development0-86d99fcf46-jkk2b   1/1     Running   0          15d</span></p><p><span>6</span><span>development0-86d99fcf46-llkgq   1/1     Running   0          18d</span></p><p><span>7</span><span>development0-86d99fcf46-mr9jt   1/1     Running   0          20d</span></p></pre></div><p>Since we have five replicas, we wanted to ensure that when we build applications, they end up on the same server so that we get the greatest amount of caching possible (distributed caching is a topic for another day). Luckily for us, <code>buildx</code>, with the Kubernetes driver, has an option for where to send the builds called <code>loadbalance</code>.</p><div><pre><p><span>1</span><span>loadbalance=(sticky|random) - Load-balancing strategy. </span></p><p><span>2</span><span>If set to "sticky", the pod is chosen using the hash of the context path. Defaults to "sticky"</span></p></pre></div><p>The default <code>sticky</code> means that the builds should always end up on the same server due to the hashing (more detailed information on this is described in the aforementioned blog post). With all of that in place, we are ready to test out our new setup!</p><p>Using the same example-voting-app repository as before, I created a new branch <code>buildx_builders</code> and pointed the code to the buildx servers. </p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/3gqbExE2XQMNqyUQ60m27m/9e215fc99510b5a18bb6792eba5679ec/uncached-buildx.png" alt="uncached-buildx"></p><p>What we see is that this uncached build was more than twice as fast as the other uncached build and even faster than the cached build on the old infrastructure! But uncached builds should be a thing of the past with the sticky load balancing, so letâ€™s make the same changes as the previous branch and see the results.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/2MxDyCqaSrOnffVSNC3SFu/abc0896e3eef27b927394b12fc9e1e29/cached-buildx.png" alt="cached-buildx"></p><p>This build finished three times faster than the previous cached build! These types of speed increases are the reason we set out to redo our build infrastructure. The faster the builds complete, the faster we can create environments and help our customers deliver their products.</p><p>Weâ€™re still experimenting with <code>buildx</code> and learning as we go, but the initial results were more than enough for us to migrate our own production builds to the new infrastructure. Weâ€™re going to continue to blog about this topic as we learn more and scale so check back in with the Release blog in the future!</p></div></article></div>]]>
            </description>
            <link>https://releaseapp.io/blog/cutting-build-time-in-half-docker-buildx-kubernetes</link>
            <guid isPermaLink="false">hacker-news-small-sites-26183334</guid>
            <pubDate>Thu, 18 Feb 2021 18:11:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dockerize Your Dev Env]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26183231">thread link</a>) | @benzaita
<br/>
February 18, 2021 | https://benzaita.github.io/dockerized-cli/index.html | <a href="https://web.archive.org/web/*/https://benzaita.github.io/dockerized-cli/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            <div>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/code.svg"></figure>
                    
                    <p>
                        Declare which build and/or development tools are needed in code, rather than in a README file.
                    </p>
                </section>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/door.svg"></figure>
                    
                    <p>
                        Bootstrapping a development environment is as easy as running <code>dockerized shell</code>.
                    </p>
                </section>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/checkmark.svg"></figure>
                    
                    <p>
                        No more "Works on my machine" because everyone in the team is using
                        exactly the same toolset.
                    </p>
                </section>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/flip-horizontal.svg"></figure>
                    
                    <p>
                        Your CI can use exactly the same toolset as your developers.
                    </p>
                </section>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/dock-row.svg"></figure>
                    
                    <p>
                        No need for <code>nvm</code>, <code>virtualenv</code>, <code>SDKMAN</code>, and such. Each
                        development environment is isolated.
                    </p>
                </section>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/drink-margarita.svg"></figure>
                    
                    <p>
                        You no longer need to maintain messy <code>docker run</code> commands yourself.
                    </p>
                </section>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/magic-wand.svg"></figure>
                    
                    <p>
                        Just prepend any command with <code>dockerized exec</code>.
                    </p>
                </section>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/vscode.svg"></figure>
                    
                    <p>
                        "dockerized" complements VS Code and can use the <a href="https://code.visualstudio.com/docs/remote/containers">Remote Container</a>
                        you already configured.
                    </p>
                </section>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/emoji.svg"></figure>
                    
                    <p>
                        You can use the "dockerized" development environment, or set up one
                        directly on your machine. Unlike other tools
                        "dockerized" is a non-intrusive guest on your machine.
                    </p>
                </section>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/fast.svg"></figure>
                    
                    <p>
                        "dockerized" can <a href="https://github.com/benzaita/dockerized-cli/wiki/Caching-the-'dockerized'-image">cache</a> the build environment to speed up builds on CI pipelines.
                    </p>
                </section>
            </div>
        </article></div>]]>
            </description>
            <link>https://benzaita.github.io/dockerized-cli/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26183231</guid>
            <pubDate>Thu, 18 Feb 2021 18:02:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GPT-3, Esq? Evaluating AI Legal Summaries [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 37 (<a href="https://news.ycombinator.com/item?id=26183114">thread link</a>) | @gavelin
<br/>
February 18, 2021 | http://www.davidvictorrodriguez.com/uploads/2/6/4/2/26420847/gpt-3_esq_-_evaluating_ai_legal_summaries.pdf | <a href="https://web.archive.org/web/*/http://www.davidvictorrodriguez.com/uploads/2/6/4/2/26420847/gpt-3_esq_-_evaluating_ai_legal_summaries.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.davidvictorrodriguez.com/uploads/2/6/4/2/26420847/gpt-3_esq_-_evaluating_ai_legal_summaries.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26183114</guid>
            <pubDate>Thu, 18 Feb 2021 17:53:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Turn an Idea into a Business]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26183057">thread link</a>) | @davidkolodny
<br/>
February 18, 2021 | https://www.wilburlabs.com/blueprints/how-to-turn-an-idea-into-a-business | <a href="https://web.archive.org/web/*/https://www.wilburlabs.com/blueprints/how-to-turn-an-idea-into-a-business">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Turning an idea into a business can be one of the most fulfilling and rewarding challenges of a lifetime. ItÃ¢â‚¬â„¢s not easy, but the skills and experiences required to start a business are learnable. </p><p>Great entrepreneurs are made, not born. Hard work, drive, and absolute determination can make up for gaps in skills and experience. The rest is learned by doing, making mistakes, and adapting along the way.</p><p>Wilbur Labs is a startup studio turning bold ideas into market-leading companies. Since 2016 we have launched and invested in 15 technology companies, including <a href="https://www.vacationrenter.com/">VacationRenter</a>, <a href="https://www.vitabox.com/">Vitabox</a>, <a href="https://www.joblist.com/">Joblist</a>, and <a href="https://www.barkbus.com/">Barkbus</a>. Today, our portfolio companies have hundreds of millions of users from around the world, and have generated billions of dollars in sales. We plan to launch several companies every year.</p><p>One question that weÃ¢â‚¬â„¢re constantly asked is: <br></p></div><h2>How do you turn an idea into a business?</h2><div><p>Launching a business is typically a one-time event. At Wilbur Labs, itÃ¢â‚¬â„¢s a repeatable and systematized process. Turning a bold idea into a business Ã¢â‚¬â€œ over and over Ã¢â‚¬â€œ is what we do. Over time, we have defined several critical steps that are key to effectively turn any idea into a business. WeÃ¢â‚¬â„¢re sharing that playbook with you to help you on your journey.</p><p><em>Note: This guide assumes that you already have an idea for a business. Coming up with an idea for a company is a separate topic covered in our <a href="https://www.wilburlabs.com/blueprints/how-to-get-startup-ideas">How to Get Startup Ideas</a> Blueprint.</em></p></div><h2>Step 1: Research</h2><div><p>The research stage is where you pair your initial idea with independent and external information. This should include first-hand research, speaking with industry experts, and talking with target customers to answer key questions:</p><ul><li>What problem are you trying to solve? </li><li>How big is this problem?</li><li>How would this make people's lives better?</li><li>Why are the current solutions not optimal?</li><li>Who are the competitors?</li><li>What is the business model?</li><li>How big of a business could you build?</li><li>Are you the right person to solve this problem?</li><li>What advantages do you have in solving this problem?</li><li>Do you care about this enough to work on it for 5+ years?</li><li>What are the outstanding challenges or questions?</li></ul><p>During this stage, you should talk with as many people as possible. You will be surprised how many target customers and industry experts are receptive to cold outreach to discuss a business idea. We recommend using LinkedIn or Twitter to source experts who know the problem you are trying to solve, and ask if theyÃ¢â‚¬â„¢re open to having a quick chat to discuss your idea. Many people passionate about an industry or a problem love talking with others who are equally as interested.</p><p>In addition to cold outreach, you should also use your personal network to reach out to any existing industry contacts who may be helpful Ã¢â‚¬â€œ or know people who might be helpful Ã¢â‚¬â€œ in researching this idea.</p><p>Be cautious about asking business advice from people close to you, because itÃ¢â‚¬â„¢s unlikely that you will get truly honest and critical feedback. Expect pushback because itÃ¢â‚¬â„¢s unlikely that everyone will love your idea, and thatÃ¢â‚¬â„¢s okay. Some of our boldest ideas received mixed feedback in the beginning. The point here is that you hear multiple viewpoints and use feedback to guide your research and planning. </p><p>Make sure to go very deep on your research during this stage. Some of our ideas remain in this stage for 6 to 12 months. Ideas are easy and everyone has them. This stage helps filter out the so-so ideas to prevent you from wasting time in a later stage. Frontloading research and due diligence here can also reduce risk and expedite future stages.</p><p>The best business ideas will bring a sense of urgency and motivation, pushing you to keep moving forward. If you are able to gain significant momentum through research, it makes sense to move into the planning stage.</p></div><h2>Step 2: Plan</h2><div><p>In the planning stage you should focus on taking your learnings and creating an executable plan. This will require diving deeper into the areas you looked into during the research phase, as well as answering new questions.</p><p>At Wilbur Labs, we create a Ã¢â‚¬Å“Concept EvaluationÃ¢â‚¬ï¿½ which is our own version of a business plan. Whatever format you choose, itÃ¢â‚¬â„¢s important to have a written plan that organizes all your research into an actionable plan that looks at every angle of your idea.</p><p>We like to work backwards during this stage, thinking about how we want the business to look 3 to 5 years ahead and then build a roadmap to get there. In our Concept Evaluation, we answer a number of questions, including but not limited to:</p><ul><li>What does the product look like at launch, year 1, year 2, etc?</li><li>How will you get customers (marketing/distribution)? How much will it cost?</li><li>What are the sources of revenue?</li><li>WhatÃ¢â‚¬â„¢s the expected lifetime value of a customer?</li><li>How will you retain customers long term to boost lifetime value?</li><li>Where is the break-even point (cost) of this business?</li><li>Where is the break-even point (time) of this business?</li><li>How do you solve the challenges you identified in the research phase?</li><li>What initial investment is required to get this off the ground?</li><li>How much time will it take to get this off the ground?</li><li>What investment is required over the next 3-5 years?</li><li>WhatÃ¢â‚¬â„¢s the optimal funding source?</li><li>What partnership(s) will you need?</li><li>What type of infrastructure will this company need?</li><li>What team is needed to build and grow this business?</li><li>What advisors could you reach out to for help?</li></ul><p>In addition to answering the questions above, our Concept Evaluations also include a product roadmap/gantt chart, financial model, and start-up checklist.<strong><br></strong></p><h3><strong>Product Roadmap</strong></h3><p>The product roadmap and corresponding gantt chart provide a simple, but tangible way to look at the different work streams that will be a part of each phase of the business. The key here is to plan out dependencies, so you can parallel process and avoid bottlenecks.</p><p>You wonÃ¢â‚¬â„¢t be able to do everything on day one. The important question to ask yourself during this planning stage is: what is the Minimum Viable Product (MVP) that you can launch with and how do you build on that MVP post launch? We are believers in launching as soon as possible to collect real customer feedback and use that to evolve the product along the way. <strong><br></strong></p><h3><strong>Financial Model</strong></h3><p>Our financial model is built using assumptions we find on our own, or inputs from industry experts. While this model is likely to change in the real world, we want to keep a close eye on the economics and the break even point. This is used to forecast the growth plan, timing, and investment level required. </p><p>Funding is a separate topic on its own and there is no universal best practice to finance a business. As an entrepreneur, you will need to look at a number of factors, including your personal situation, business cash requirements, and long term plan. ItÃ¢â‚¬â„¢s worth spending time with advisors or mentors to discuss the best funding option for your situation. <strong><br></strong></p><h3><strong>Startup Checklist</strong></h3><p>We love checklists and have a checklist for everything. Checklists ensure consistency and completeness in carrying out a task. Checklists also allow you to frontload all the planning so you can focus on executing at the next stage. For our startup checklist, we include everything required to get from day zero to launch day. This includes corporate structuring and entity formation; legal and accounting prep; compliance, hiring, product building; distribution and marketing; operations, partnerships, and business development. We are extremely thorough and write out every critical task, corresponding notes, status, and owner.</p><p>Before moving on to the next stage you should ask yourself, <em>Ã¢â‚¬Å“Do I want to spend the next 5+ years of my life building this business?Ã¢â‚¬ï¿½ </em></p><p>More often than not, entrepreneurship is not a way to get rich quickly. You will likely need to work harder and longer, with higher stress and more at stake than working a regular day job. The journey is absolutely worth it for the right person, but itÃ¢â‚¬â„¢s important that you go into it knowing what to expect. Many companies die early due to missed expectations on what it takes to start a company. If possible, you can start out part-time and build traction before diving in full-time. </p><p>If you want to dedicate years of your life solving this problem, and building a business along the way, then move on to the execute phase.</p></div><h2>Step 3: Execute</h2><div><p>Every single person has ideas, but very few take the jump and start a company. The execution stage is where you leave the planning stage and take that jump. You have spent time researching, putting together a plan, and you are now ready to dedicate time to building a business.</p><p>Depending on the type of business, this stage will look very different. In all cases, this stage involves working through your plan, roadmap, and startup checklist to begin getting your idea off the ground. </p><p>The primary focus of this stage is prioritization. Prioritizing often will allow you to manage bottlenecks and work in parallel across different areas of your business. The goal is to align your input (time &amp; money) with the activities that will yield the highest output (progress on your plan). This is easier said than done, but it is absolutely critical to execute your plan in an efficient way.</p><p>If you need to raise money or get funding, this is the stage where that could happen. This is also the stage where you may need to start building your team by hiring contractors or employees. </p></div><h2>Step 4: Adapt</h2><div><p>Roughly 90% of businesses fail, and this is the stage where that usually happens. One thingÃ¢â‚¬â„¢s for certain in starting a business: you will never be able to create and follow a bulletproof plan. As your business takes off, youÃ¢â‚¬â„¢ll need to constantly adapt and change your plan. The best entrepreneurs are comfortable being uncomfortable, adapting as they go.</p><p>The optimal Ã¢â‚¬Å“go liveÃ¢â‚¬ï¿½ point will vary by business. At Wilbur Labs, we strongly believe that getting customers to vote for products and services with their wallet or with their time is by far the best measure of product-market fit. If customers wonÃ¢â‚¬â„¢t spend time or money on your â€¦</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.wilburlabs.com/blueprints/how-to-turn-an-idea-into-a-business">https://www.wilburlabs.com/blueprints/how-to-turn-an-idea-into-a-business</a></em></p>]]>
            </description>
            <link>https://www.wilburlabs.com/blueprints/how-to-turn-an-idea-into-a-business</link>
            <guid isPermaLink="false">hacker-news-small-sites-26183057</guid>
            <pubDate>Thu, 18 Feb 2021 17:50:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Terms Archive: Terms and Conditions of popular services tracked on GitHub]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26182878">thread link</a>) | @sirffuzzylogik
<br/>
February 18, 2021 | https://disinfo.quaidorsay.fr/en/open-terms-archive | <a href="https://web.archive.org/web/*/https://disinfo.quaidorsay.fr/en/open-terms-archive">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<div class="page">
				<div>
					

<nav>
	<ol itemscope="" itemtype="https://schema.org/BreadcrumbList">
		<li itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">	
			<a href="https://disinfo.quaidorsay.fr/en" itemprop="item">Home</a>
			
		</li>

		
			<li itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">	
				<a href="https://disinfo.quaidorsay.fr/en/our-tools" itemprop="item">Our tools</a>
				
			</li>
		
		
		<li itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
			Open Terms Archive
		</li>
	</ol>
</nav>

<p><img src="https://disinfo.quaidorsay.fr/assets/img/open-terms-archive/thumb.jpg" alt=""></p>

<p>Services have terms that can change over time. Open Terms Archive enables users rights advocates, regulatory bodies and any interested citizen to <strong>follow the changes to these terms</strong>.</p>

<h3 id="follow-the-changes-to-the-terms-of-service">Follow the changes to the Terms of Service</h3>

<p>Services are declared within Open Terms Archive with a declaration file listing all the documents that, together, constitute <strong>the terms under which this service can be used</strong>. These documents all have a type, such as â€œterms and conditionsâ€, â€œprivacy policyâ€, â€œdeveloper agreementâ€.</p>

<p>The practices described regarding information manipulation can lead to a <strong>better understanding of the vulnerabilities</strong> of these actors and the transcription of legislative constraints, recommendations from public authorities or voluntary measures implemented enables us to <strong>appreciate their loyalty</strong>.</p>

<h3 id="case-studies">Case studies</h3>

<ul>
  <li>Google has changed its Review Guidelines to prohibit apps that hat mislead users by impersonating someone else or another app or falsely imply a relationship to another company / developer. These measures thus close certain vulnerabilities exploited for information manipulation. <a href="https://github.com/ambanum/CGUs-versions/commit/98f6c">See the change</a>.</li>
</ul>

<p><img src="https://disinfo.quaidorsay.fr/assets/img/open-terms-archive/google-case-studie.png" alt=""></p>

<ul>
  <li>TikTok refers to Comminuty Guidelines to offer its users the opportunity to report content that would be considered inappropriate. <a href="https://github.com/ambanum/CGUs-versions/commit/0d2f0386">See the change</a>.</li>
</ul>

<p><img src="https://disinfo.quaidorsay.fr/assets/img/open-terms-archive/tiktok-case-studie.png" alt=""></p>

<ul>
  <li>Google AdSense has changed its Acceptable Use Policy to add a reference to Coordinated Deceptive Practices to prohibit (i) practices that seek to coordinate with other sites or accounts and concealing or misrepresenting identity or other material details, when content relates to politics, social issues or matters of public concern and (ii) directe content about politics, social issues, or matters of public concern to users in a country other than oneâ€™s own, if you misrepresent or conceal oneâ€™s country of origin or other material details. <a href="https://github.com/ambanum/CGUs-versions/commit/c62b7">See the change</a>.</li>
</ul>

<p><img src="https://disinfo.quaidorsay.fr/assets/img/open-terms-archive/google-case-studie.png" alt=""></p>

<p><a href="https://github.com/ambanum/CGUs/wiki/%C3%89tudes-de-cas">Discover more case studies</a></p>

<h2 id="how-it-works">How it works</h2>

<p><em>Words in bold are <a href="https://en.wikipedia.org/wiki/Domain-driven_design">business domain names</a>.</em></p>

<p><strong>Services</strong> are <strong>declared</strong> within <em>Open Terms Archive</em> with a <strong>declaration file</strong> listing all the <strong>documents</strong> that, together, constitute the <strong>terms</strong> under which this <strong>service</strong> can be used. These <strong>documents</strong> all have a <strong>type</strong>, such as â€œterms and conditionsâ€, â€œprivacy policyâ€, â€œdeveloper agreementâ€â€¦</p>

<p>In order to track their <strong>changes</strong>, <strong>documents</strong> are periodically obtained by fetching a web location and selecting content within the web page to remove the noise (ads, navigation menu, login fieldsâ€¦).</p>

<p>Anyone can run their own private instance and track changes on their own. However, we also publish each version on a <a href="https://github.com/ambanum/CGUs-versions"><strong>public</strong> instance</a> that makes it easy to explore the entire history and enables notifying over email whenever a new version is recorded.
Users can <a href="#be-notified"><strong>subscribe</strong> to <strong>notifications</strong></a>.</p>

<p><em>For now, when multiple versions coexist, <strong>terms</strong> are only <strong>tracked</strong> in their English version and for the European jurisdiction.</em></p>

<h3 id="exploring-the-versions-history">Exploring the versions history</h3>

<p>From the <strong>repository homepage</strong> <a href="https://github.com/ambanum/CGUs-versions">CGUs-versions</a>, open the folder of the service of your choice. You will see the set of documents tracked for that service, now click on the document of your choice. The latest version (updated hourly) will be displayed.</p>

<p><em>For more details, see our <a href="https://github.com/ambanum/CGUs#exploring-the-versions-history">wiki</a></em>.</p>

<h3 id="be-notified">Be notified</h3>

<p>You can <a href="https://59692a77.sibforms.com/serve/MUIEAKuTv3y67e27PkjAiw7UkHCn0qVrcD188cQb-ofHVBGpvdUWQ6EraZ5AIb6vJqz3L8LDvYhEzPb2SE6eGWP35zXrpwEFVJCpGuER9DKPBUrifKScpF_ENMqwE_OiOZ3FdCV2ra-TXQNxB2sTEL13Zj8HU7U0vbbeF7TnbFiW8gGbcOa5liqmMvw_rghnEB2htMQRCk6A3eyj">subscribe</a> to receive an email whenever a document is updated in the database.</p>

<p><strong>Beware, this service is in beta and you are likely to receive a large amount of notifications!</strong> You can unsubscribe by replying to any email you will receive.</p>

<p><em>For more details, see our <a href="https://github.com/ambanum/CGUs#be-notified">wiki</a></em>.</p>

<h2 id="scripta-manent">Scripta Manent</h2>

<p>Scripta Manent lists 637 Terms of Services (in French, Conditions GÃ©nÃ©rales dâ€™Utilisation or CGU) and legal documents coming from 174 digital service providers and gives simple tools to compare changes between two dates of your choice.</p>

<p><a href="https://disinfo.quaidorsay.fr/en/open-terms-archive/scripta-manent">Compare</a></p>

<h2 id="experiments">Experiments</h2>

<p>Experiments are ongoing so as to produce use cases using Open Terms Archive data.</p>

<p><a href="https://disinfo.quaidorsay.fr/en/open-terms-archive/experiments">See ours experiments</a></p>

<h2 id="api">API</h2>

<p>An API endpoint to find specific terms in the Open Terms Archive dataset is available.</p>

<p><a href="https://disinfo.quaidorsay.fr/api/open-terms-archive/">Access the API</a></p>

<h2 id="contributing">Contributing</h2>

<p>The tool is built as an <strong>open source and collaborative software</strong>, which means that everyone can contribute to its improvement and to the addition of documents and service providers to be tracked.</p>

<ul>
  <li>
    <p>Terms of Service Didnâ€™t Read (ToSDR)
The association Terms of Service Didnâ€™t Read (ToSDR) had developed a similar tool, <a href="https://tosback.org/">TOSBack</a> and thus transferred its resources and documents followed for several years to our tool.</p>
  </li>
  <li>
    <p>Direction GÃ©nÃ©rale des Entreprises<br>
The Direction GÃ©nÃ©rale des Entreprises (DGE), through the Digital Regulation Expertise Center (PEReN), contributes to the tool by developing new functionalities, such as tracking images and documents in PDF format.</p>
  </li>
</ul>

<div>
	<h3>Help us to improve Open Terms Archive</h3>
	<p>You can add service providers or documents that you would like to follow or suggest ways to add value to the case studies.</p>
	<p><a href="https://github.com/ambanum/CGUs">Contribute</a>
</p></div>

				</div>
			</div>
		</div></div>]]>
            </description>
            <link>https://disinfo.quaidorsay.fr/en/open-terms-archive</link>
            <guid isPermaLink="false">hacker-news-small-sites-26182878</guid>
            <pubDate>Thu, 18 Feb 2021 17:37:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ruby Garbage Collection Deep Dive: Tri-Color Mark and Sweep]]>
            </title>
            <description>
<![CDATA[
Score 132 | Comments 15 (<a href="https://news.ycombinator.com/item?id=26182796">thread link</a>) | @mooreds
<br/>
February 18, 2021 | https://jemma.dev/blog/gc-mark-and-sweep | <a href="https://web.archive.org/web/*/https://jemma.dev/blog/gc-mark-and-sweep">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>In the <a href="https://jemma.dev/blog/gc-internal">first post</a> in the Ruby Garbage Collection Deep Dive series, we went through a few definitions to give us a picture of how Ruby stores values in memory. If you havenâ€™t read it yet, <a href="https://jemma.dev/blog/gc-internal">read it first</a>! Weâ€™ll build on those definitions in this post. Particularly, weâ€™ll talk more about the Ruby Heap, Pages, Slots and RVALUES.</p>

<p>Okay, now that we have those baseline definitions out of the way, this post is going to explain the algorithm Rubyâ€™s garbage collector uses to determine which objects it can collect: the Tri-Color Mark and Sweep algorithm. There are two phases to this algorithm. You guessed it: marking and sweeping. In the marking phase, the garbage collector marks all slots which contain accessible RVALUES. In the sweeping phase, the garbage collector clears the RVALUES out of all slots which are not marked. Letâ€™s dig in!</p>

<h2 id="tri-color-mark-and-sweep">Tri-Color Mark and Sweep</h2>

<h3 id="marking">Marking</h3>

<p>Weâ€™ll start off by discussing the marking phase. This is most straightforward to understand if we imagine the <a href="https://ruby-doc.org/core-3.0.0/ObjectSpace.html">Ruby ObjectSpace</a> to be a directed graph with root nodes. All of the nodes in the graphs are RVALUES. All of the edges in the graph are references from one RVALUE to another.</p>

<p>Rubyâ€™s garbage collector starts at the root nodes and traces every edge it can access from these root nodes, marking every RVALUE it sees through this process. At the end, any RVALUE which was not traced, and therefore not accessible from a root RVALUE will be garbage collected.</p>

<h4 id="tri-color">Tri-Color</h4>

<p>Okay, but the algorithm Ruby uses for garbage collection is called a Tri-Color Mark and Sweep algorithm, so whatâ€™s the Tri-Color part all about? The Tri-Color algorithm is a model we can use to understand what Rubyâ€™s garbage collector is doing, and how tracks its progress. The three colors in the Tri-Color algorithm (three shades, really) are white, black and grey.</p>

<p>At the beginning of garbage collection, every slot in the Ruby Heap is white. Then, as part of the initial setup, all slots which contain root RVALUEs are marked as grey.</p>

<p>Root RVALUES are all of the RVALUES that a Ruby program knows it will need to run. Examples of these are RVALUES that exist on the stack of instructions that the program is following, or protected global variables.</p>

<p>With all root slots grey, and all other slots white, we then get to the crux of the algorithm:</p>

<div><div><pre><code><span>while</span> <span>(</span><span>!</span><span>grey_slots</span><span>.</span><span>empty?</span><span>)</span>
  <span>current_slot</span> <span>=</span> <span>grey_slots</span><span>.</span><span>pop</span>
  <span>grey_slots</span> <span>+=</span> <span>current_slot</span><span>.</span><span>referenced_slots</span>
  <span>black_slots</span> <span>&lt;&lt;</span> <span>current_slot</span>
<span>end</span>
</code></pre></div></div>

<p>We iterate over all grey slots, coloring the slots that their RVALUES reference grey, and coloring themselves black. The algorithm continues until there are no grey slots left. At this point, any black slots contain RVALUES which were reachable by the RVALUEs in the root slots, and any white slots do not contain RVALUES which were reachable so can be swept away!</p>

<p>For the visual learners, hereâ€™s a gif of what the algorithm is doing:</p>

<p><img src="https://jemma.dev/assets/mark.gif" alt="mark-gif"></p>

<h4 id="references">References</h4>

<p>There is one detail which needs further explanation here: how does an RVALUE know which other RVALUES it references?</p>

<p>It depends on the type of object. For Ruby builtins, tracing the references are just baked into the garbage collector code itself. For example, to find all references from an array RVALUE, the collector iterates each element in the array and finds its references. For a hash, it will do this for both the keys and the values. This all happens in the garbage collectorâ€™s <a href="https://github.com/ruby/ruby/blob/296a2cab07ce530809ee74dee61180fbb3ca6f91/gc.c#L6269"><code>mark_children</code></a> method.</p>

<p>But, when objects are defined by C extensions, the C extensions must mark all child objects on their own. Weâ€™ll dive more into this in a future C extensions post (which Iâ€™ll backlink here).</p>

<p>Okay, so now that we understand how we find all accessbile objects, we need to learn how to dispose of all unaccessible objects.</p>

<h3 id="sweeping">Sweeping</h3>

<p>At this point, we have two sets: black slots and white slots. Internally, these are represented as a <code>marked</code> bitmap. Every Page on the Ruby Heap has its own <code>marked</code> bitmap with one bit per slot. A <code>1</code> bit means the slot is accessible, or Black in our Tri-Color scheme. A <code>0</code> bit means that the slot is no longer accessible, or White in our Tri-Color scheme.</p>

<p>In addition to holding this <code>marked</code> bitmap, each page also has a <code>freelist</code> which represents slots on that page which do not have live objects. The garbage collector iterates over all pages, finding all slots which are not marked. Where applicable, the garbage collector then adds the unmarked slots to each pageâ€™s freelist. If the RVALUES which were occupying these slots are also taking up space in the operating system heap, it also frees this memory.</p>

<p>Once pages have been swept, there might be pages which are now completely unallocated; they have no slots which contain RVALUES. These pages are referred to as â€œTomb Pages.â€ Tomb pages have their memory completely returned to the operating systemâ€™s heap. This is really helpful for memory management. It means that sweeping can result in freeing memory, or diminishing the overall size of the Ruby Heap.</p>

<p>Any pages with at least one occupied slot are called â€œEden Pagesâ€. The sweeping phase might reduce the number of occupied slots in an Eden Page. The garbage collector will use the freelists from Eden Pages for future object allocations. That is to say, if you instantiate an object, the garbage collector will look for one of these free slots in an Eden Page and place the RVALUE representing your object in there.</p>

<p><img src="https://jemma.dev/assets/eden-and-tomb.png" alt="eden-and-tomb"></p>

<p>There is one more nuance here. As of Ruby 3.0, if auto-compaction is enabled, compaction will actually happen as part of the sweeping phase. A more in depth explanation of how and why this happens will follow in a later post about compaction in this Garbage Collection Deep Dive Series.</p>

<h3 id="tldr">TL;DR</h3>

<p>The Tri-Color mark and sweep algorithm is what Rubyâ€™s garbage collector uses to determine which slots hold objects which no longer have accessible references. It marks all of the slots it has references to by following the Tri-Color algorithm in which it follows all references from root RVALUES. Once the garbage collector knows which objects are accessible from the roots, it can begin the sweep phase, where it will add the unoccupied slots to each pageâ€™s freelist, and release any operating system memory those RVALUES held. This enables the slots to be reused for new object allocation.</p>

<p>Here are a few new definitions we learned:</p>

<ul>
  <li><strong>Eden page</strong>: A page which contains slots with RVALUES, might also have empty slots</li>
  <li><strong>Tomb page</strong>: A page which contains only empty slots</li>
  <li><strong>Free list</strong>: A linked list per Heap Page of empty slots</li>
</ul>

<p>And thatâ€™s it for this post! Iâ€™m going to continue writing blog posts in this series, and am also writing a book about managed garbage collection, with a focus on Ruby. If this interests you, join the newsletter below or follow me <a href="https://twitter.com/jemmaissroff">on twitter</a> for updates!</p>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://jemma.dev/blog/gc-mark-and-sweep</link>
            <guid isPermaLink="false">hacker-news-small-sites-26182796</guid>
            <pubDate>Thu, 18 Feb 2021 17:32:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Love F# for Mathematical Planning]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26182563">thread link</a>) | @dunefox
<br/>
February 18, 2021 | https://matthewcrews.com/blog/2020-12-09-why-i-love-fsharp-for-mathematical-planning/ | <a href="https://web.archive.org/web/*/https://matthewcrews.com/blog/2020-12-09-why-i-love-fsharp-for-mathematical-planning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<article>
   

  <div>
<blockquote>
<p>A designer knows he has achieved perfection not when there is nothing left to add, but when there is nothing left to take away</p>
<ul>
<li>Antoine de Saint-Exupery</li>
</ul>
</blockquote>
<p>On my journey of growing as a developer, I am consistently inspired by language features which seem incredibly simple but yield remarkable benefit. As I try to master F#, I am frequently surprised by how powerful the language is for expressing ideas while having so few features. Discussions frequently pop up about the need for ever more powerful abstractions, yet I find myself amazed by how far you can take the language with what is already there.</p>
<p>I am no programming language expert, but I admire languages that maintain a lean feature set. Every new feature added to a language makes it just a little bit more difficult to fully understand and a little more intimidating for new developers. It is an impressive design feat when a language can remain approachable for beginners but enable the flexibility that library authors need.</p>
<p>I am an Industrial Engineering turned Machine Learning Engineer, and I focus on the problem of maximizing the profitability and efficiency of companies. Often the solution involves a Mathematical Planning Model (aka Mathematical Programming). What I hope to do in the next few paragraphs is illustrate to you how some of the most basic features of F#, Discriminated Unions and Units of Measure, eliminate the most pernicious bugs when developing these models.</p>
<h2 id="the-domain-of-mathematical-planning">The Domain of Mathematical Planning</h2>
<p>The domain of Mathematical Planning is made up of Decisions, Constraints, and Objectives. A Decision is a choice that a business needs to make. It can be how many of Item X do we buy, do we build in Location A or Location B, or how many people do we assign to each job. Constraints are the rules we need to abide by. They are the limitations on what is possible. A Constraint could be that we only have 10 people available, or we can only build in Seattle or Portland, or we only have $1,000,000 to invest. The Objective is how we measure success. It is the function we want to maximize or minimize. We could minimize waste, maximize profit, or minimize cost.</p>
<p>Many of my colleagues are building their models with Python. Python is a great language and I have been productive with it in the past. Here is a snippet of what a mathematical planning model may look like in Python:</p>
<div><pre><code data-lang="python"><span># Define a list of items to optimize for</span>
items <span>=</span> [<span>"A"</span>, <span>"B"</span>, <span>"C"</span>]

<span># Define a list of locations to assign items to</span>
locations <span>=</span> [<span>"Portland"</span>, <span>"Seattle"</span>, <span>"Detroit"</span>]

<span># Define a dictionary of revenue associated with each item and location tuple</span>
revenue <span>=</span> {(<span>"A"</span>,<span>"Portland"</span>):<span>1.5</span>;, (<span>"A"</span>,<span>"Seattle"</span>):<span>1.7</span> <span>...</span> }

<span># Define a dictionary with the availability of each item</span>
availability <span>=</span> {<span>"A"</span>:<span>10.0</span>, <span>"B"</span>:<span>20.0</span>, <span>"C"</span>:<span>14.0</span>}

<span># Create a Decision for each Item, Location combination. This will be how much</span>
<span># of a given item we decide to send to that location</span>
allocation <span>=</span> LpVariable<span>.</span>dicts(<span>"AmountSent"</span>,(items,locations), <span>0</span>)

<span># Create an instance of a `Problem` object and state that we want to maximize</span>
<span># the objective we give it</span>
problem <span>=</span> LpProblem(<span>"ItemAllocation"</span>, LpMaximize)

<span># We create an expression which evaluates the total revenue</span>
revenue_expr <span>=</span>
    lpSum([revenue[i][l] <span>*</span> allocation[i][l] <span>for</span> i <span>in</span> items <span>for</span> l <span>in</span> locations])

<span># We set the Objective of the Problem by adding it</span>
problem <span>+=</span> revenue_expr, <span>"MaximizeRevenue"</span>

<span># For each item in items, create a constraint which states that the total number</span>
<span># of items that is allocated cannot exceed the availability of the item</span>
<span>for</span> i <span>in</span> items:
    problem <span>+=</span> lpSum([allocation[l][i] <span>for</span> l <span>in</span> location] <span>&lt;=</span> availability[i])

</code></pre></div><p>This is the beginning of a straightforward assignment problem. We have a list of items, <code>items</code>. For each <code>item</code> in <code>items</code>, we must decide how many we send to each <code>location</code> in <code>locations</code>. There is a limit on how much of each <code>item</code> is available for us to send. There is a revenue associated with sending a particular <code>item</code> to a given <code>location</code>. In this problem we want to maximize our revenue which is calculated by multiplying the <code>decision</code> for a given <code>item</code> and <code>location</code> by the <code>revenue</code> associated with it. Finally, we create a constraint for each <code>item</code> in <code>items</code> which states that the total number of a given <code>item</code> that is allocated cannot exceed the total that is available.</p>
<p>This is only part of the problem. Normally there would be more constraints that would make it more interesting. This is enough of a problem to illustrate my case though. There are two errors in this model already. If you were paying close attention you may have found one. I promise you cannot detect the second.</p>
<h2 id="the-power-of-domain-modeling-using-discriminated-unions">The Power of Domain Modeling Using Discriminated Unions</h2>
<p>F# provides two simple but powerful features which help ensure against the errors in the Python code. The first is Discriminated Unions. If we were to reformulate this problem using F#, the first thing we would do was define some simple types to model our domain.</p>
<div><pre><code data-lang="fsharp"><span>type</span> <span>Item</span> <span>=</span> Item <span>of</span> <span>string</span>
<span>type</span> <span>Location</span> <span>=</span> Location <span>of</span> <span>string</span>
</code></pre></div><p>Instead of just using strings to describe our Items and Locations, we create simple, single case Discriminated Unions (DU). These DUs provide context around what the strings are meant to represent. Letâ€™s go ahead and create our <code>item</code> and <code>locations</code> lists again. This time, wrapping them in DUs.</p>
<div><pre><code data-lang="fsharp"><span>let</span> items <span>=</span> 
  <span>[</span><span>"A"</span><span>;</span> <span>"B"</span><span>;</span> <span>"C"</span><span>]</span> 
  <span>|&gt;</span> List.map Item

<span>let</span> locations <span>=</span> 
  <span>[</span><span>"Portland"</span><span>;</span> <span>"Seattle"</span><span>;</span> <span>"Detroit"</span><span>]</span>
  <span>|&gt;</span> List.map Location
</code></pre></div><p>We will also update our <code>availability</code> information to use these new types.</p>
<div><pre><code data-lang="fsharp"><span>let</span> availability <span>=</span>
    <span>[</span>
        Item <span>"A"</span><span>,</span> 10<span>.</span>0
        Item <span>"B"</span><span>,</span> 20<span>.</span>0
        Item <span>"C"</span><span>,</span> 14<span>.</span>0
    <span>]</span> <span>|&gt;</span> Map
</code></pre></div><p>We will create the Decisions for each <code>item</code> and <code>location</code>. We store these <code>Decision</code> types in a <code>Map</code> which is indexed by an <code>(Item * Location)</code> tuple.</p>
<div><pre><code data-lang="fsharp"><span>let</span> allocation <span>=</span>
    DecisionBuilder<span>&lt;</span>Servings<span>&gt;</span> <span>"AmountSent"</span> <span>{</span>
        <span>for</span> i <span>in</span> items <span>do</span>
            <span>for</span> l <span>in</span> locations <span>-&gt;</span>
                Continuous <span>(</span>0<span>.</span>0<span>,</span> infinity<span>)</span>
    <span>}</span> <span>|&gt;</span> Map
</code></pre></div><p>We now attempt to create the same constraints we did in Python with a direct translation.</p>
<div><pre><code data-lang="fsharp"><span>let</span> allocationContraints <span>=</span>
    ConstraintBuilder <span>"ItemLimit"</span> <span>{</span>
        <span>for</span> i <span>in</span> items <span>-&gt;</span>
            List.sum <span>[</span><span>for</span> l <span>in</span> locations <span>-&gt;</span> 1<span>.</span>0 <span>*</span> allocation<span>.[</span>l<span>,</span> i<span>]]</span> <span>&lt;==</span> availability<span>.[</span>i<span>]</span>
    <span>}</span>   
</code></pre></div><p>Except, the compiler is gives us an error on the indexing of <code>allocation</code>.</p>
<p><img src="https://matthewcrews.com/img/2020-12-08-indexing-error.png" alt="Compiler error for indexing Map"></p>
<p>What some of you may have noticed in the Python code is that the <code>allocation</code> collection is indexed by an <code>Item</code> then <code>Location</code>. The original code was trying to access it by <code>location</code> then by <code>item</code>. This would have thrown an error at runtime due to a missing value. In F# this becomes a compiler error. The type system itself it is helping you. This may seem small, but this is one of the most painful types of errors when debugging a Mathematical Planning model.</p>
<p>Someone may say that this can be accomplished in other languages and I would agree. I believe where F# is unique is in the simplicity and ease of using single case Discriminated Unions for wrapping primitives. It is virtually no additional effort.</p>
<h2 id="units-of-measure-the-achilles-heel-of-numbers">Units of Measure: The Achilles Heel of Numbers</h2>
<p>There is an underappreciated problem in software development, numbers are rarely just numbers. They represent something: <code>cm</code>, <code>feet</code>, <code>kg</code>, or <code>meters</code>. Normally we do not care about a raw number. Our primary concern is with what the number represents. In most languages there are no easy mechanisms for tracking the Units of Measure associated with a number. F# on the other hand has baked the concept of a Unit of Measure into the type system.</p>
<p>The Units of Measure feature will reveal the second problem with the Python code that otherwise may remain undetected. Letâ€™s update our domain with some new types to track the units on our numbers.</p>
<div><pre><code data-lang="fsharp"><span>[&lt;</span>Measure<span>&gt;]</span> <span>type</span> <span>Servings</span>
<span>[&lt;</span>Measure<span>&gt;]</span> <span>type</span> <span>Kg</span>
</code></pre></div><p>We now have units to represent <code>Servings</code> and <code>Kg</code>. Letâ€™s update our <code>availability</code> collection to store numbers with these units attached.</p>
<div><pre><code data-lang="fsharp"><span>let</span> availability <span>=</span>
    <span>[</span>
        Item <span>"A"</span><span>,</span> 10<span>.</span>0<span>&lt;</span>Kg<span>&gt;</span>
        Item <span>"B"</span><span>,</span> 20<span>.</span>0<span>&lt;</span>Kg<span>&gt;</span>
        Item <span>"C"</span><span>,</span> 14<span>.</span>0<span>&lt;</span>Kg<span>&gt;</span>
    <span>]</span> <span>|&gt;</span> Map
</code></pre></div><p>We have now provided more context around our availability numbers. We now know they are stored in units of <code>Kg</code>. The F# compiler will enforce correct algebra as we work with them. We now update our Decisions to be in units of <code>Servings</code>.</p>
<div><pre><code data-lang="fsharp"><span>let</span> allocation <span>=</span>
    DecisionBuilder<span>&lt;</span>Servings<span>&gt;</span> <span>"AmountSent"</span> <span>{</span>
        <span>for</span> i <span>in</span> items <span>do</span>
            <span>for</span> l <span>in</span> locations <span>-&gt;</span>
                Continuous <span>(</span>0<span>.</span>0<span>&lt;</span>Servings<span>&gt;,</span> 1_000_000<span>.</span>0<span>&lt;</span>Servings<span>&gt;)</span>
    <span>}</span> <span>|&gt;</span> Map
</code></pre></div><p>With our Decisions updated, we go back to our constraint definition and we now see a new bug.</p>
<p><img src="https://matthewcrews.com/img/2020-12-08-units-of-measure-mismatch.png" alt="Units of Measure Mismatch"></p>
<p>The important part of this message is at the bottom. The compiler is complaining that the left-hand is in units of <code>Servings</code> and the right-hand side is in units of <code>Kg</code>. It does not make sense to compare values that are in different units, so the compiler is throwing an error. In other languages this error would go undetected. Worse, it may not even be caught in unit testing because the math will still work, it just wonâ€™t give correct results.</p>
<p>Letâ€™s go ahead and add some conversion data so that we can fix this.</p>
<div><pre><code data-lang="fsharp"><span>let</span> itemMass <span>=</span>
    <span>[</span>
        Item <span>"A"</span><span>,</span> 1<span>.</span>1<span>&lt;</span>Kg<span>/</span>Servings<span>&gt;</span>
        Item <span>"B"</span><span>,</span> 2<span>.</span>0<span>&lt;</span>Kg<span>/</span>Servings<span>&gt;</span>
        Item <span>"C"</span><span>,</span> 0<span>.</span>7<span>&lt;</span>Kg<span>/</span>Servings<span>&gt;</span>
    <span>]</span> <span>|&gt;</span> Map
</code></pre></div><p>We now have data which will allow us to convert from <code>Serving</code> to <code>Kg</code>. Letâ€™s incorporate it into our constraint creation expression.</p>
<div><pre><code data-lang="fsharp"><span>let</span> allocationContraints <span>=</span>
  ConstraintBuilder <span>"ItemLimit"</span> <span>{</span>
    <span>for</span> i <span>in</span> items <span>-&gt;</span>
      List.sum <span>[</span><span>for</span> l <span>in</span> locations <span>-&gt;</span> itemMass<span>.[</span>i<span>]</span> <span>*</span> itemAllocation<span>.[</span>i<span>,</span> l<span>]]</span> <span>&lt;==</span> availability<span>.[</span>i<span>]</span>
  <span>}</span> 
</code></pre></div><p>Now the compiler is happy because the units are in <code>Kg</code> on both sides. This simple feature of ensuring correct Units of Measure eliminates what is possibly the most nefarious bug in Mathematical Planning. It would be hard to calculate the number of hours wasted on badly formulated models due to mismatched Units of Measure.</p>
<h2 id="simple-building-blocks">Simple Building Blocks</h2>
<p>F# is an incredibly expressive language while staying lean on the number of features. Other languages have taken the approach of throwing every possible feature in. F# is relatively slow to â€¦</p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://matthewcrews.com/blog/2020-12-09-why-i-love-fsharp-for-mathematical-planning/">https://matthewcrews.com/blog/2020-12-09-why-i-love-fsharp-for-mathematical-planning/</a></em></p>]]>
            </description>
            <link>https://matthewcrews.com/blog/2020-12-09-why-i-love-fsharp-for-mathematical-planning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26182563</guid>
            <pubDate>Thu, 18 Feb 2021 17:16:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Census Raises $16M Series A from Sequoia]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26181985">thread link</a>) | @nate
<br/>
February 18, 2021 | https://blog.getcensus.com/announcing-our-series-a-from-sequoia/ | <a href="https://web.archive.org/web/*/https://blog.getcensus.com/announcing-our-series-a-from-sequoia/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <section>
                <div>
                    <p>Iâ€™m thrilled to announce that Census has raised a $16 million Series A, led by Sequoia Capital. Andreessen Horowitz (who led our seed) is also participating, along with operators like Dylan Field (Figma CEO), Jason Warner (GitHub CTO), Akshay Kothari (Notion COO), Parker Conrad (Rippling CEO), Josh Ferguson (Mode Chief Architect), Bryant Chou (Webflow CTO), Joe Thomas (Loom CEO), Patrick McKenzie (Stripe) and Guillaume Cabane. This round brings our total amount raised to just over $20 million.</p><p>We're also launching the <a href="https://blog.getcensus.com/introducing-the-census-startup-program">Census Startup Program</a> to empower startups to easily build the last mile of the modern data stack. Companies with fewer than 40 employees and less than $10MM in funding will be able to use Census for a flat rate of $100 per month.</p><figure><img src="https://lh3.googleusercontent.com/PqQs9ECN6mKTopIPG2ZhvZL_-FmCS_h7uB_VAAizC02R6hS7wXGBj2G2ph7tafLbpJ_66C5dfvp6ljRvWCqejYEW-GHIiVWw5KEqwi42b2sijRGJsCFh-ZhMkWJffuIxVNbl0m2j" alt=""></figure><p>In 2018, we started with a simple product that helped business teams sync data from their cloud warehouses into their favorite tools. Since then, the data landscape has changed a lot â€“ now we're starting to see analytics &amp; data move to the core of all company operations. We <a href="https://blog.getcensus.com/meet-census/">launched publicly</a> last year with the world's first reverse ETL that natively publishes from any data warehouse (we dubbed this the "missing piece" in the modern data stack). The reaction has been nothing short of phenomenal â€“ Census is now syncing analytics for over half a billion users every day.</p><p>We're lucky to support some pretty amazing teams using Census, like Canva, Figma, Drizly, Heap Analytics, Netlify, Mode Analytics, Notion, and Chorus.ai just to name a few. These organizations are unified by a shared focus on delivering personalized experiences for every customer, even when they've scaled to hundreds of millions of users.</p><p>To do this, they treat data as a central pillar of their organization, instead of just paying lip service to being "data-driven." Putting data teams on the critical path of every business operation has emerged as the category of <a href="https://blog.getcensus.com/what-is-operational-analytics/">Operational Analytics</a> â€“ and has been the driving force for our company.</p><h3 id="operational-analytics-aka-the-data-warehouse-as-hub">Operational Analytics, aka. the Data Warehouse as Hub</h3><p>Three years ago, we asked, â€œWhy are we relying on a clumsy tangle of wires connecting every app when everything we need is already in the warehouse? What if you could leverage your data team to drive operations?â€</p><p>When the data warehouse is connected to the rest of the business, the possibilities are limitless. When we launched, our focus was enabling product-led companies like Figma, Canva, and Notion to drive better marketing, sales, and customer success. Along the way, our customers have pulled Census into more and more scenarios, like auto-prioritizing support tickets in <a href="https://blog.getcensus.com/census-zendesk-for-better-customer-support/">Zendesk</a>, automating invoices in <a href="https://headwayapp.co/census-changelog/netsuite-destination-186207">Netsuite</a>, or even integrating with HR systems. With our growing library of <a href="https://www.getcensus.com/integrations">native integrations</a>, Census makes it possible for data models in your cloud data warehouse to power any business workflow.</p><figure><img src="https://blog.getcensus.com/content/images/2021/02/Eventail-Diagram-4.png" alt="" srcset="https://blog.getcensus.com/content/images/size/w600/2021/02/Eventail-Diagram-4.png 600w, https://blog.getcensus.com/content/images/size/w1000/2021/02/Eventail-Diagram-4.png 1000w, https://blog.getcensus.com/content/images/size/w1600/2021/02/Eventail-Diagram-4.png 1600w, https://blog.getcensus.com/content/images/size/w2400/2021/02/Eventail-Diagram-4.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>The performance improvements we've seen in the modern data stack (fast incremental ingestion from our partners at <a href="https://fivetran.com/blog/fivetran-partners-with-census-to-complete-the-loop-on-operational-analytics">Fivetran</a>, separated workloads on Redshift, improving latency from Snowflake, the arrival of <a href="https://blog.getcensus.com/census-databricks/">Delta Lake</a>, etc.) finally make it possible for the data warehouse to act as a <a href="https://blog.getcensus.com/the-best-cdp-solution-is-already-sitting-in-your-data-warehouse/">new kind of CDP</a> (Customer Data Platform). One that enables hyper-scale businesses to deliver the attention and personalization that customers historically only get from, say, a small neighborhood boutique. This is the promise of Operational Analytics.</p><h3 id="the-rise-of-the-data-ops-ecosystem">The Rise of the Data Ops Ecosystem</h3><p>Census is part of a larger movement in the data ecosystem, one in which the precepts of Engineering and DevOps are washing over the world of analytics. Marc Andreessen famously said "software is eating the world." Our team has always believed in the corollary: "software practices will eat the business." We've made it our mission from day one to help data teams build solutions like engineers. And weâ€™ve worked with amazing partners in bringing this vision to reality.</p><figure><img src="https://lh6.googleusercontent.com/eLy_nydDOnPyVwsQEHTu8k3cGiicY2EAKJn6E8pC4gankSOLcc66qnhf1O0KiY4cD2Y6-LABH4KGMtQ9pw9D61APtXf5UPcGLp-f3bs-bFCnTsM42AInrUL6_PXvTUH6GW10t7aW" alt=""><figcaption>Fivetran + dbt + Census = Feedback Loop</figcaption></figure><p>Census takes models and insights from a data warehouse then <a href="https://whatsnew.getcensus.com/built-in-data-validation-186053">validates</a> and <a href="https://blog.getcensus.com/making-your-dbt-models-more-useful-with-census/">deploys</a> the results so they can be put to work in other teams (ie. the real world). With our native understanding of dbt model versions, you can safely orchestrate your entire data operations from input to output. Census closes the feedback loop to make the whole much greater than the sum of the parts.</p><p>But what most drives this movementâ€”and what we love most about itâ€”is the amazing community of developers, analysts, and operations experts that all help each other to build better systems. Our partners at Fishtown have fostered one of the most inclusive and helpful communities, which supported and embraced Census early on â€“ led by the intrepid <a href="https://twitter.com/clairebcarroll">Claire Caroll</a> (fun fact: she helped popularize our â€œreverse ETLâ€ concept in 2019). We participate in our small way with tool talks and office hours. Thereâ€™s a real excitement around the modern data stack, which is why we created our new startup program so folks could adopt this stack regardless of company size or budget.</p><h3 id="the-future-data-as-a-product">The Future: Data as a Product</h3><p>The next decade is going to be an exciting one for data teams, and our early customers are pointing the way. Instead of constantly building (and fixing) one-off reports, data teams are poised to become a central nervous system for the business.</p><p>Traditionally, BI teams have been focused on asynchronous, batch processing instead of real-time, personalized processing. Analysts build reports to answer questions about what happened in the business, which is like looking at the rear view mirror. This data architecture could crunch raw data into KPIs and charts but wasnâ€™t optimized for understanding individual users or entities. Even worse, it was disconnected from day-to-day operations, which forced data teams to do painful periodic reconciliations with the business.</p><figure><img src="https://blog.getcensus.com/content/images/2021/02/new-data-teams-4.png" alt="" srcset="https://blog.getcensus.com/content/images/size/w600/2021/02/new-data-teams-4.png 600w, https://blog.getcensus.com/content/images/size/w1000/2021/02/new-data-teams-4.png 1000w, https://blog.getcensus.com/content/images/size/w1600/2021/02/new-data-teams-4.png 1600w, https://blog.getcensus.com/content/images/size/w2400/2021/02/new-data-teams-4.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Operational Analytics changes the role of data teams</figcaption></figure><p>Modern data teams are built differently. Instead of a data sink, they are a platform for applications, analysis, visualization â€“ and most importantly, action. Instead of focusing on data aggregation for BI visualization, a new modeling layer must emerge that captures clean, unified yet individualized entities that can be used in any application. In order to support all these scenarios, a few things are crucial.</p><ol><li>The data infrastructure must be scalable, efficient, and real-time.</li><li>The data modeling layer must be versioned, tested, deployed, and ultimately standardized for broad consumption.</li><li>The data pipelines must reach any application, and be seamlessly monitored to create tight feedback loops with every part of the organization</li></ol><h3 id="the-road-map-ahead">The Road(map) Ahead</h3><p>Thereâ€™s a ton of capabilities in Census and even more to come. Hereâ€™s some of the areas weâ€™ve been working on and plan to expand upon this year.</p><ul><li><strong>Code-Based Orchestration.</strong> Today, we sync models seamlessly from a warehouse but we want to push the bar forward here and make every Census workflow versionable and pluggable into larger orchestration systems.</li><li><strong>Deeper Data Validation.</strong> When your data models are connected to business systems, failures become much worse (which is a good thing, after all if your mistakes have no impact, whatâ€™s the point?). Census is your last line of defense before the data is live so validating your data is key.</li><li><strong>Visual Query Experience.</strong> When data becomes a product, it means you have more consumers. Many of these consumers need a way to interact with models with a simple UX, which furthers our goal of data reaching every part of the organization.</li></ul><p>If this sounds like a lot, it's because it is. We're embarking on a long journey to transform data organizations into product teams. Teams that can scale to support many users and many use cases. By shifting into this central role, data teams stop being backwards-looking and become the biggest drivers of change in an organization â€“ the ultimate feedback loop.</p><h3 id="join-us">Join us</h3><p>The companies &amp; leaders who understand this will certainly succeed and I look forward to seeing an amazing cohort of Chief Data Officers in the decade to come. There is a huge amount of work ahead of us and I am unbelievably excited to tackle these problems every day. Empowering people with tools has been my passion ever since I started my career in technology. If you want to help make an impact and move the needle on the entire data ecosystem, <a href="https://jobs.ashbyhq.com/Census">come join our team</a>. Weâ€™re small but mighty and hiring for every position. You can reach me on <a href="https://twitter.com/borisjabes">Twitter</a> or via <a href="mailto:boris@getcensus.com">email</a>.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.getcensus.com/announcing-our-series-a-from-sequoia/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26181985</guid>
            <pubDate>Thu, 18 Feb 2021 16:38:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SSH Certificates Security]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26181568">thread link</a>) | @alexk
<br/>
February 18, 2021 | https://goteleport.com/blog/ssh-certificates | <a href="https://web.archive.org/web/*/https://goteleport.com/blog/ssh-certificates">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
      <a href="https://goteleport.com/blog/index.xml"><i></i></a>
      
      

        

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-security.png" width="100%" alt="SSH Certificates Security"></p>

<h2 id="ssh-access-hardening">SSH Access Hardening</h2>

<p>SSH certificates, when deployed properly, improve security.
A half-baked access system using certs is more vulnerable than a public-key-based one if a user or host gets hacked.</p>

<p>SSH is hard. Our team learned this at Rackspace, a large managed hosting and cloud provider.
We started with deploying public keys to every server. We added a jump server with a second factor login to prevent
hacks using stolen keys. Soon, infosec team asked us to log into a web portal to match SSH logins with emails.
Evolution does not produce the most efficient result, and our system did not turn out great either.
We were missing keys on some servers and found stale keys on others.
No one liked login screens popping up multiple times a day.
We received only one one-time password token, and some folks pointed their home webcam to it.</p>

<p>In 2015 we left Rackspace to build <a href="https://github.com/gravitational/teleport" data-size="large" aria-label="Star gravitational/teleport on GitHub">Teleport</a> â€” a unified access plane
for infrastructure, and we started with SSH. We chose SSH certificates as the main cryptography engineering primitive. Since then our customers and open source users have deployed Teleport at most impressive systems, and Teleport went through
several security audits.</p>

<p>I would like to share some of the lessons we learned with you.
We will start with the SSH authentication basics, dig into SSH certificates
and learn what it takes to build a secure SSH certificate-based authentication.</p>

<h3 id="ssh-public-key-authentication">SSH Public Key Authentication</h3>

<p>An SSH public key is distributed openly, and anyone holding it can verify messages
signed using its private key counterpart.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-public-key-auth.png" width="100%" alt="SSH Public Key Authentication"></p>

<p>An SSH server generates a random string â€” a challenge â€” and asks a client to sign it.
The server verifies clientsâ€™ signature to prove that the client has the private key associated with
the trusted public key. Here is how it looks on the wire:</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-public-key-protocol.png" width="100%" alt="SSH Public Key Challenge"></p>

<p>Public keys constitute a solid way to authenticate and are used to secure both Web and SSH.</p>

<p>The problems with public key authentication are caused by key management: trust on first use (a.k.a. TOFU)
and rotating and revoking trusted public keys.</p>

<h3 id="trust-on-first-use">Trust On First Use</h3>

<p>When an SSH connection is first established, an SSH server sends its public key to identify
itself to a user.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-host-auth.png" width="100%" alt="SSH Host Authentication"></p>

<p>The user can accept the public key offered by the SSH server and assume that the host is trusted
if the user connects to it first time. This authentication scheme is called â€œtrust on first useâ€ or TOFU.</p>

<p>If the hostâ€™s IP, name or public key change, the user can no longer trust this combination
of the hostname, the IP and the public key.</p>

<p>The user sees a scary warning.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-tofu.png" width="100%" alt="SSH TOFU"></p>

<p>The user can alert security folks or ignore the warning by removing the old key.
For cloud environments, however, an IP address and a hostname can be
reused many times. Users learn to ignore those warnings, because there is no way to learn whether itâ€™s an attack or an IP or a hostname change. Letâ€™s call it TOFU fatigue.</p>

<h3 id="problems-with-public-keys">Problems With Public Keys</h3>

<p>A second problem of public keys for security is caused by complexities of public key distribution.
Imagine a deployment with 100 servers and 10 users, where every user has 2 public keys.
You have to build a system that distributes 20 userâ€™s public keys on each server and
100 public keys to every userâ€™s computer, and keep those up to date.</p>

<p>Directory services like LDAP are used to store userâ€™s and hostâ€™s public keys.
Every host runs an agent that connects to an LDAP server and updates public keys.
Sysadmin folks have been deploying this Keycloak and FreeIPA pair for years.</p>

<p>This system breaks down at a small and a large scale. Sysadmins of small systems
rarely deploy key management software. Itâ€™s not worth setting up FreeIPA and Keycloak for 3 nodes.
They use tools like Ansible and end up with keys going out of sync when someone loses their key, computer, or leaves the company. Sometimes, letâ€™s face it, there is no Ansible and everyone uses the same shared key.</p>

<p>Admins of large clusters learn that the system of moving the key around stops working beyond the 1K nodes or 100 users mark â€”
there are just too many keys to keep track of.</p>

<h2 id="ssh-certificates">SSH Certificates</h2>

<p>SSH certificates are built using public keys and donâ€™t offer anything extra from a cryptography engineering standpoint.</p>

<p>A certificate authority (CA) is a trusted party that holds its own public and private key pair.
SSH CA keys are used to sign user and host SSH certificates.
An SSH certificate consists of fields signed by the certificate authority.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-certificate.png" width="100%" alt="SSH Certificate"></p>

<p>Clients cannot modify these fields without breaking the signature.</p>

<p>SSH certificate authentication extends public-key-based auth and uses the same protocol messages.
In addition to verifying the public key signature, SSH server will check whether
the certificate is signed by the trusted certificate authority.</p>

<h3 id="solving-the-tofu-problem">Solving the TOFU Problem</h3>

<p>Clients use metadata in SSH certificates to verify host identities too.
When an SSH connection is established, a host sends a signed SSH certificate to a client to verify
the hostâ€™s identity. The hostâ€™s certificate is signed by a trusted CA.
It includes information about the hostname, and has an expiration date.
Here Alice checks if she can trust the hostâ€™s cert:</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-host-certs.png" width="100%" alt="SSH Host Certificates"></p>

<p>As an extra precaution, SSH clients check if the hostname or the IP matches the certificate.
It makes it harder for a malicious host to impersonate another host.
If the signature check has failed or the CA is not trusted, either a serious misconfiguration
has happened or someone is attempting a man-in-the-middle attack.</p>

<p>Even if the public key of the host has been changed because the hostname has been reused in a cloud environment
during instance re-provisioning, the certificate will still match; there will be no conflict between different
public keys.</p>

<p>Sysadmins can replace the complex system of moving hundreds of public keys around
with two files â€” a host and a user SSH certificatesâ€™ authority public keys.
But in practice if we had stopped at this point, we would have made SSH security much, much worse.</p>

<h3 id="compromised-users-and-hosts">Compromised Users and Hosts</h3>

<p>If a user or a host gets compromised, we have to revoke their certs.
We are back to building a system of keeping track and distributing revocation lists to users and hosts.
Even worse, if a private key of a SSH user or a host certificate authority gets compromised,
all users and hosts certificates have to be invalidated and reissued.</p>

<p>This realization hits at the worst possible moment â€” when someone is hacked, there is no time to waste.
Time works against us because with every issued cert, the potential for compromise
increases. At least with public keys, we test the rotation on a regular basis. Revocation is so rare,
that it could be broken for all this time and no one would notice. This problem reminds me of backup restore â€”
you either test backup and restore regularly, or all bets are off.</p>

<h2 id="making-time-work-for-you">Making Time Work for You</h2>

<p>There is one trick that makes time work in favor of security.
SSH certificates include an optional expiry date that can be verified
by a server in addition to a signature.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-short-lived.png" width="100%" alt="SSH Short Lived Certs"></p>

<p>Organizations ca issue certificates that are good for a few hours before they auto-expire
without any action. The shorter the duration for these certificates, the better.
Ideally, certs should be issued only for the duration of a session.
In practice, several hours or the duration of the workday are OK too.</p>

<p>Instead of distributing revocation lists, we can rely on time to do the job for us.</p>

<h3 id="user-certificates-and-sso">User Certificates and SSO</h3>

<p>How would users get a short-lived certificate? The best way is to use SSO
with GitHub, Okta or any other identity provider and get a cert.
Teleport opens login screen, issues a cert and delivers it back to a userâ€™s computer:</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-sso.png" width="100%" alt="SSH certs SSO"></p>

<p>Here is an example of Teleportâ€™s CLI tool <code>tsh</code> issuing a certificate
based on my GitHub credentials.</p>

<video autoplay="" loop="" muted="" playsinline="">
  <source src="https://goteleport.com/blog/images/2021/ssh-certs-github.mp4" type="video/mp4">
  <source src="https://goteleport.com/blog/images/2021/ssh-certs-github.webm" type="video/webm">
Your browser does not support the video tag.
</video>

<p>The cert is valid for 12 hours and has my GitHub identity encoded in it.</p>

<h2 id="rotate-ca-keys">Rotate CA Keys</h2>

<p>An attacker getting access to a private key of a certificate authority can impersonate
any user or host. Thatâ€™s why admins store CA private keys in the most secure place possible.
What happens if a user, a host, or a CA gets compromised? Youâ€™d need to replace certificate authority
and reissue all certs for hosts and users. Any system dealing with certs should support this out of the box.</p>

<p>Take a look at how I rotate a user CA in less than a minute with Teleport:</p>

<video autoplay="" loop="" muted="" playsinline="">
  <source src="https://goteleport.com/blog/images/2021/ssh-certs-rotation.mp4" type="video/mp4">
  <source src="https://goteleport.com/blog/images/2021/ssh-certs-rotation.webm" type="video/webm">
Your browser does not support the video tag.
</video>

<p>With user certificate authority updated, all certificates issued by the old CA become invalid.
Itâ€™s not a problem if you use SSO; users have to re-login to get new certs.
The same command rotates hosts CA as well. Instead of waiting for the compromise
to happen, we should be rotating certificate authorities every day turning
them from a precious secret to a replaceable commodity. Here again, time
will work in our favor, not against us.</p>

<h2 id="wrapping-up">Wrapping Up</h2>

<p>Use certs with caution, and beware of long-lived certificates. Rotate your CA regularly
and use SSO to get user certs. And maybe, give <a href="https://github.com/gravitational/teleport" data-size="large" aria-label="Star gravitational/teleport on GitHub">Teleport</a> a try.</p>


        
        
        <p><strong>Related Posts</strong></p>
          <ul>
            
            <li><a href="https://goteleport.com/blog/how-to-ssh-properly/">How to SSH Properly | SSH Security Best Practices</a></li>
            
            <li><a href="https://goteleport.com/blog/ssh-handshake-explained/">SSH Handshake Explained | What is SSH Handshake?</a></li>
            
            <li><a href="https://goteleport.com/blog/ssh-restricted-shells/">Restricted Shell | Restricted commands for SSH</a></li>
            
          </ul>
        

        
        
        <a href="https://goteleport.com/tags/ssh/">ssh</a>
        
        <a href="https://goteleport.com/tags/teleport/">teleport</a>
        
        <a href="https://goteleport.com/tags/security/">security</a>
        

      
      
      &nbsp;
      </article></div>]]>
            </description>
            <link>https://goteleport.com/blog/ssh-certificates</link>
            <guid isPermaLink="false">hacker-news-small-sites-26181568</guid>
            <pubDate>Thu, 18 Feb 2021 16:09:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zoom is the solution nobody asked for, to a problem that doesnâ€™t exist]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26181268">thread link</a>) | @tompccs
<br/>
February 18, 2021 | https://www.vanityfarce.com/office/work/zoom/2021/02/17/zoom.html | <a href="https://web.archive.org/web/*/https://www.vanityfarce.com/office/work/zoom/2021/02/17/zoom.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>Disclaimer â€“ This post was poorly researched and most of the historical â€˜factsâ€™ are pieced together from my own recollection, books Iâ€™ve been reading and Wikipedia searches. Despite the lack of rigorous scholarship (or perhaps because of it) I expect the conclusion to be 100% correct.</em></p>

<p>When the pandemic is â€œoverâ€ â€“ or, more precisely, when the right people decide to declare it â€œoverâ€ and we are living in a world split between Covid-negative and Covid-positive countries with a several year life expectancy gap between them â€“ the consensus is that some things will go back to the way they were pre-2020, and others wonâ€™t. Whether or not you think white collar workers will still be working from home â€“ living in commuter belts, in or around small towns or in remoter parts of the country side with decent broadband â€“ or will have migrated back into the offices, city pubs and crammed trains, depends largely on whether or not you have a financial interest in the value of commercial real estate. One thing everyone seems to agree on, though, is that video conferencing technology, such as Zoom, has been, and will continue to be, central to this revolution in working patterns.</p>

<p>Whatever the future of white collar work holds, I feel I can confidently predict that video conferencing will be not-so-fondly remembered as a weird crutch that everyone was obsessed with for about 12-18 months, before people realised it actually serves no purpose at all.</p>

<p>To argue this point, I will ask the question â€“ why do we actually have offices in the first place? Who are they for? What problems do they solve? And which of those problems does video conferencing actually come close to addressing?</p>

<p>The history of bureaucratic white-collar work goes something like this: there are two main threads of office work which emerged around the Industrial Revolution â€“ state-administration, and the bourgeoise professions (accountants, lawyers, traders, etc). Of the two threads, state administration is the older: bureaucracies of this sort can be traced back to ancient Egypt. Hierarchies beyond a certain size need paperwork, because the people in charge need a way to have their wishes transmitted authentically without corruption (accidental of nefarious) to hundreds or thousands of  lowly peons. Hence the priestly, and later bureaucratic, class, tasked with the top-down administration of unwieldy empires and later nation-states according to the insights or whims of their rulers.</p>

<p>Obviously, this type of administration pre-dates the â€œofficeâ€ as we currently recognise it. There arenâ€™t many western institutions which have been in continuous operation from medieval through to post-industrial times which we can analyse in this way, but one of them might be the British Parliament. Originally an ad-hoc assembly of the Kingâ€™s noblemen, gathered as and when the King needed to raise some cash through taxation, this travelling parliament eventually evolved into the more stationary one we know today, where MPs have permanent offices and travel between their constituencies and the debating chambers according to how often they feel the need to escape from those people who elected them there in the first place. In 2021, those MPs are now spending a lot more time in their constituencies. Voting can now happen remotely, although MPs still have the option of attending debates in person. Itâ€™s hard to imagine British government functioning in quite the same way without the cut-and-thrust of rigorous parliamentary debate, but then again, itâ€™s hard to see how any type of video conferencing solution could recreate it either (just look at what happened in this <a href="https://www.youtube.com/watch?v=jB3P_0GAi0I">disastrous parish council meeting</a>)</p>

<p>What of the rest of the state apparatus? The ambassadors, bureaucrats, etc? Well, to once again take an example from British history, a small cadre of Oxbridge-educated civil servants based in Whitehall, London, used to administer the largest empire in history with no more advanced technology than the telegraph. I canâ€™t quite imagine a Zoom meeting between Prime Minister Disraeli and the governor-general of India, not to mention with the 120-or-so Indian noblemen scattered about the subcontinent, making this unwieldy task any easier.</p>

<p>So much for administering an empire. What about lower-level state administration â€“ things like welfare, sanitation, treasury, etc? You might not be surprised to learn that the primary reason for co-locating lots of bureaucrats is becauseâ€¦<em>thatâ€™s where the filing cabinets were!</em> If you needed to process a tax return, or look up some obscure by-law, you generally had to be co-located with reams and reams of paper containing this information. The fact that this constituted an â€œofficeâ€ is purely down to the fact that other people needed to be co-located with these files as well as you. The office was originally built for collaboration insofar as a library is built for meeting girls.</p>

<p>Weâ€™ve still not explored the other thread of this â€“ the thread that runs from Venetian merchants to Googleâ€™s bean-bags and free lunches. This one is harder to explain. As the artisan evolved into the factory worker, so too did the other professionals â€“ lawyers, accountants, merchants â€“ evolve into the office worker. What was the rationale for this? Why should a lawyer or accountant, each of whom has a few assigned clients, need to work in an office with lots of other lawyers and accountants? Rather than being co-located with their filing cabinets, I suppose the reason is to allow them to share a pool of ancillary staff, like paralegals, typists, etc. However, as the digital revolution has swept through (and, since WWII, rising wages), much of the ancillary staff have been done away with altogether, or else morphed into something called â€˜middle managementâ€™. The function of middle management, of course, is the same as the ancillary staff: to help the professionals do their jobs better, although by tweaking their job description they were able to negotiate better pay.</p>

<p>If you need ancillary staff (read: middle management), then it stands to reason that you need an office, too. And if you donâ€™t have an office, then you probably need something that will â€˜simulateâ€™ an office. Hereâ€™s the problem: whereas the ancillary staff of old knew that their job was to type things up, keep appointment diaries and fetch post, middle management believes their job is to hold meetings. Therefore, synonymous with â€˜home workingâ€™ is â€˜Zoom meetingsâ€™.</p>

<p>Iâ€™ve actually omitted a third thread of office history, which is the monastery (or university in 21st century parlance). Why the need to have a bunch of monks living together? In fact, the original Christian monk was a hermit, living in total solitude. But perhaps in not having a family such a degree of loneliness was too much to bear. Hence the monastery, where, as well as (or perhaps in the course of) worshipping God, monks partook in such pastimes as beer brewing, geometry, and science. The fact that big groups of celibate, literate men living in the same place led to all sorts of interesting by-products is perhaps the root of the modern idea of a university, and that legacy also dovetails into our modern corporate culture which has its roots in the 1980s, whose hallmarks are the borrowing of university lingo such as â€˜campusâ€™, and a growing obsession with a nicely marketable form of self-improvement which can be delivered through highly lucrative training contracts.</p>

<p>There is a fleeting sense in which a modern university, with students living in halls, unemployed and frugal, could look a bit like, if you squint, a short stint at a medieval monastery, and whatever value universities still hold is probably related to how long you can hold onto that mirage. But the modern office, with its 9-to-5 clock and day punctuated by meetings and the ambitious preoccupied by the arduous climb up the corporate hierarchy, is even further away. Perhaps the closest thing to the medieval monastery is the startup, with its ungodly hours and religious-fanatical devotion to the cause, and itâ€™s probably no coincidence that working in a startup is generally seen as incompatible with having a social or family life. But no, other than the monastic startup-office-cum-bedsit, the office serves no creative purpose. The modern office is little more than a cargo-cult monastery.</p>

<p>Having read and of course also agreed with all of this, one can only wonder what function software such as Zoom can possibly serve. And I think the answer to this is similar to something we often see from new digital technology: the skeuomorphism of existing â€˜analogueâ€™ concepts (ie, the modern â€˜desktopâ€™ containing â€˜filesâ€™ and â€˜documentsâ€™). Skeuomorphisms are almost always a temporary crutch, a cognitive bridge between the old inefficient way of doing something and the new but conceptually abstract way which will eventually replace it. Consider, for instance, the transition from written letters, to email, to instant messaging. Or how indeed the very idea of an email has become distinct in itself â€“ look at how email etiquette has gradually evolved from when you might write one as you would write a letter in the early 2000s to the modern â€œsee attached. cheers, Tomâ€. Or look at social media, how Facebook was built on top of your real-world idea of â€˜friendsâ€™ by inventing the highly skeuomorphic (and somewhat autistic) concept of â€˜friend requestsâ€™, before Instagram and Twitter developed the more digitally-native concept of â€˜followingâ€™.</p>

<p>Zoom is the â€˜friend requestâ€™ of the office world. As our work places reverse the 150-year migration from our homes into purpose built offices, recall that that reversal is due to the sudden erosion of the logic which made us move into offices in the first place: record keeping and reference, ancillary staff, and creative collaboration. Zoom and video conferencing is a sticking plaster, and perhaps a desperate plea by the old guard to remind us of how much better â€¦</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.vanityfarce.com/office/work/zoom/2021/02/17/zoom.html">https://www.vanityfarce.com/office/work/zoom/2021/02/17/zoom.html</a></em></p>]]>
            </description>
            <link>https://www.vanityfarce.com/office/work/zoom/2021/02/17/zoom.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26181268</guid>
            <pubDate>Thu, 18 Feb 2021 15:52:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coq 8.13]]>
            </title>
            <description>
<![CDATA[
Score 113 | Comments 38 (<a href="https://news.ycombinator.com/item?id=26180078">thread link</a>) | @infruset
<br/>
February 18, 2021 | https://coq.inria.fr/news/coq-8-13-0-is-out.html | <a href="https://web.archive.org/web/*/https://coq.inria.fr/news/coq-8-13-0-is-out.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>





<p>
The Coq development team is proud to announce the immediate availability of
<a href="https://github.com/coq/coq/releases/tag/V8.13.0">Coq 8.13.0</a>
</p>

<p>
Highlights:
</p><ul>
<li>Introduction of primitive persistent arrays in the core language, implemented using imperative persistent arrays. </li>
<li>Introduction of definitional proof irrelevance for the equality type defined in the SProp sort. </li>
<li>Many improvements to the handling of notations, including number notations, recursive notations and notations with bindings. A new algorithm chooses the most precise notation available to print an expression, which might introduce changes in printing behavior.</li>
</ul>



<p>Please see <a href="https://coq.github.io/doc/v8.13/refman/changes.html#version-8-13" rel="nofollow">the changelog</a> to learn more about this release.</p>




</div></div>]]>
            </description>
            <link>https://coq.inria.fr/news/coq-8-13-0-is-out.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26180078</guid>
            <pubDate>Thu, 18 Feb 2021 14:23:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Browsers eating RAM]]>
            </title>
            <description>
<![CDATA[
Score 131 | Comments 134 (<a href="https://news.ycombinator.com/item?id=26179817">thread link</a>) | @todsacerdoti
<br/>
February 18, 2021 | https://www.flotato.com/post/memory-chrome-safari-flotato | <a href="https://web.archive.org/web/*/https://www.flotato.com/post/memory-chrome-safari-flotato">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>I reached a point where I could barely hear the podcast I was trying to listen to. That's how loud the fan was. Then I&nbsp;closed down all open Chrome windows, and a few minutes after, the fan went silent. So I decided to see if it was just me.</p><div href=""><h3>How I&nbsp;measured</h3><p>I&nbsp;ran the 2-tab test in a completely fresh macOS install on a virtual machine. Then I ran the 54-tabs test on my own Big Sur installation, but with all extensions disabled. To record a usage snapshot ~250 times per second, I&nbsp;used <a href="https://github.com/astrofrog/psrecord">psrecord.</a></p></div><div><h2>2&nbsp;tabs:&nbsp;Twitter, then Gmail</h2><p>To simulate a realistic environment, I&nbsp;did the same steps on Safari, then Chrome:&nbsp;Go to twitter.com, scroll around, then open a new tab with Gmail and open an email. A dot means I interacted with the system. You can hover a dot to see what I&nbsp;did. </p></div><div><h3>Putting Flotato to the test</h3><p>To be light-weight, Flotato doesn't just run a stripped down, Safari-backed web view, it also defaults to the mobile version if one is available. Here's Flotato compared to a regular session in Safari. Note the slightly lower CPU usage. It's kind of hard to put a finger on what exactly the mobile version isn't calculating that the desktop version is; the two versions are almost identical when you use them.</p></div><div><h2>54 tabs:&nbsp;the stress test</h2><p>I&nbsp;bet you have more than 2 tabs open right now, I&nbsp;sure have more. So here's a stress test where I&nbsp;open 54 tabs while measuring the impact on my Mac's RAM and CPU. A dot means I&nbsp;opened a new tab. Hover the dot to see which site I&nbsp;opened.</p></div><div><h2>Is it bad?</h2><p>When I saw the results I got suspicious. Chrome was using way more memory than I thought it would. Maybe it was the virtual machine blocking Chrome's direct access to my Macbook's* GPU?&nbsp;I&nbsp;decided to run the next test, the one with 54 tabs directly on my own Big Sur installation. The results were, well, slightly worse.</p><h3>The graphs don't tell the full story</h3><p>But it's probably not as bad as it looks. It's not a terrible thing that an app actually <em>uses</em> your computer. And you've got to hand it to Chrome:&nbsp;it is fast! </p><p>I'm sure Chrome is going out of its way to manage its memory usage across tabs, keeping the current tab fast and responsive. That's great if you're not running any other macOS apps than Chrome, effectively using Chrome as your operating system, and macOS&nbsp;as a kind of bootloader. </p><p>But when you're using Sketch, Final Cut, Photoshop next to Chrome, that seems to be a problem. MacOS&nbsp;likely tries to tell Chrome to take it easy, and Chrome likely <em>does</em> take it easy. These graphs don't tell that story. </p><p>So no, it's most likely not as bad as it looks, but that doesn't change the fact since switching to Safari, I almost forgot what my fan sounds like.</p><p>And then there's <em>this</em> chart. As we can see, the two browsers heat up the computer almost to the exact same level - Safari even getting slightly warmer. This probably points to psutil not being able to see all Safari's child processes, but only the main ones â€” despite the fact that Activity Monitor is able to group them. That's a little confusing. </p><figure><p><img src="https://uploads-ssl.webflow.com/5e78c687e58e25134b3fb751/602feb36d1388bb94f881998_EumcL7jXYAEBG_4.png" alt="Image"></p></figure><p>â€</p><p>â€</p><p><em>*&nbsp;Macbook 16" from 2019 with2.4 GHz, 8-Core Intel Core i9 with 32&nbsp;GB&nbsp;2667 MHz DDR4 RAM and an AMD&nbsp;Radeon Pro 5500M 8GB GPU</em></p></div></div>]]>
            </description>
            <link>https://www.flotato.com/post/memory-chrome-safari-flotato</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179817</guid>
            <pubDate>Thu, 18 Feb 2021 13:56:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Advanced Types in TypeScript]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26179620">thread link</a>) | @mooreds
<br/>
February 18, 2021 | https://www.geekabyte.io/2021/01/introduction-to-advance-types-in.html | <a href="https://web.archive.org/web/*/https://www.geekabyte.io/2021/01/introduction-to-advance-types-in.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-5372611965284124411" itemprop="description articleBody">
<p>This is the start of a series of posts where I take a look at aspects of TypeScript's type system that can be referred to as "Advanced".&nbsp; See this as an exploration of TypeScriptâ€™s type system past <span>Classes</span> and <span>Interfaces</span>.</p><p>A good mental model to have when exploring the advanced part of TypeScript type system is to see it as a more sophisticated mechanism for creating types.&nbsp;</p><p>The normal, non-advanced ways of creating types in TypeScript involve using features of the language like <span>type alias</span>,&nbsp; <span>class</span> and <span>interface</span>.&nbsp;</p>

<p>For example these:&nbsp;</p>

<pre><code>interface IPerson {
  name: string
  age: number
}

type TPerson = {
  name: string
  age: number
}

class CPerson {
  constructor(private name:string, private age: number) {}
  
  getName() {
    return this.name;
  }

  getAge() {
    return this.name;
  }
}
</code></pre>



<p>With the advanced type features, types can be constructed directly or indirectly based on other existing types. How exactly this is done, will be the subject of this series of posts.</p><p>The posts in the series include:</p><ul><li><a href="https://www.geekabyte.io/2021/01/introduction-to-generics-in-typescript.html">Introduction to Generics in TypeScript</a></li><li><a href="https://www.geekabyte.io/2021/01/generic-constraints-methods-and.html">Generic Constraints and More</a></li><li><a href="https://www.geekabyte.io/2021/01/union-and-intersection-types-in.html">Union and Intersection Types</a></li><li><a href="https://www.geekabyte.io/2021/02/literal-and-template-literal-types.html">Literal and Template Literal Types</a></li><li><a href="https://www.geekabyte.io/2021/02/using-literal-and-template-literal.html">Using Literal and Template Literal Types in TypeScript</a></li><li><a href="https://www.geekabyte.io/2021/02/overview-of-indexable-types-in.html">Overview of Indexable Types in TypeScript</a></li><li>Indexed Access Types and KeyOf - <i>Published soon</i></li><li>Type Queries: Typeof operator - <i>Published soon</i></li><li>Conditional Types - <i>Published soon</i></li><li>Mapped Types - <i>Published soon</i></li></ul>

</div></div>]]>
            </description>
            <link>https://www.geekabyte.io/2021/01/introduction-to-advance-types-in.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179620</guid>
            <pubDate>Thu, 18 Feb 2021 13:36:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Curl is C (2017)]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 65 (<a href="https://news.ycombinator.com/item?id=26179601">thread link</a>) | @taf2
<br/>
February 18, 2021 | https://daniel.haxx.se/blog/2017/03/27/curl-is-c/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2017/03/27/curl-is-c/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>For some reason, this post got picked up again and is <a href="https://news.ycombinator.com/item?id=26179601">debated today</a> in 2021, almost 4 years since I wrote it. Some things have changed in the mean time and I mightâ€™ve phrased a few things differently if I had written this today. But still, whatâ€™s here below is what I wrote back then. Enjoy!</p>



<div><figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_.png"><img loading="lazy" width="348" height="450" src="https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_-348x450.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_-348x450.png 348w, https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_-155x200.png 155w, https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_-768x992.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_.png 792w" sizes="(max-width: 348px) 100vw, 348px"></a></figure></div>



<p>Every once in a while someone suggests to me that curl and libcurl would do better if rewritten in a â€œsafe languageâ€. Rust is one such alternative language commonly suggested. This happens especially often when we publish new security vulnerabilities. (Update: I think Rust is a fine language! This post and my stance here has nothing to do with what I think about Rust or other languages, safe or not.)</p>



<h2>curl is written in C</h2>



<p>The curl code guidelines mandate that we stick to using C89 for any code to be accepted into the repository. C89 (sometimes also called C90) â€“ the oldest possible ANSI C standard. Ancient and conservative.</p>



<h2>C is everywhere</h2>



<p>This fact has made it possible for projects, companies and people to adopt curl into things using basically any known operating system and whatever CPU architecture you can think of (at least if it was 32bit or larger). No other programming language is as widespread and easily available for <em>everything</em>. This has made curl one of the most portable projects out there and is part of the explanation for curlâ€™s success.</p>



<p>The curl project was also started in the 90s, even long before most of these alternative languages youâ€™d suggest, existed. Heck, for a truly stable project it wouldnâ€™t be responsible to go with a language that isnâ€™t even old enough to start school yet.</p>



<h2>Everyone knows C</h2>



<p>Perhaps not necessarily true anymore, but at least the knowledge of C is very widespread, where as the current existing alternative languages for sure have more narrow audiences or amount of people that master them.</p>



<h2>C is not a safe language</h2>



<p>Does writing safe code in C require more carefulness and more â€œtricksâ€ than writing the same code in a more modern language better designed to be â€œsafeâ€ ? Yes it does. But weâ€™ve done most of that job already and maintaining that level isnâ€™t as hard or troublesome.</p>



<p>We keep scanning the curl code regularly with static code analyzers (we maintain a <em>zero <a href="https://scan.coverity.com/projects/curl">Coverity</a> problems</em> policy) and we run the test suite with <a href="http://valgrind.org/">valgrind</a> and <a href="https://en.wikipedia.org/wiki/AddressSanitizer">address sanitizers</a>.</p>



<h2>C is not the primary reason for our past vulnerabilities</h2>



<p>There. The simple fact is that most of our past vulnerabilities happened because of logical mistakes in the code. Logical mistakes that arenâ€™t really language bound and they would not be fixed simply by changing language.</p>



<p>Of course that leaves a share of problems that couldâ€™ve been avoided if we used another language. Buffer overflows, double frees and out of boundary reads etc, but the bulk of our security problems has not happened due to curl being written in C.</p>



<h2>C is not a new dependency</h2>



<p>It is easy for projects to add a dependency on a library that is written in C since thatâ€™s what operating systems and system libraries are written in, still today in 2017. Thatâ€™s the default. Everyone can build and install such libraries and theyâ€™re used and people know how they work.</p>



<p>A library in another language will add that language (and compiler, and debugger and whatever dependencies a libcurl written in that language would need) as a new dependency to a large amount of projects that are themselves written in C or C++ today. Those projects would in many cases downright ignore and reject projects written in â€œan alternative languageâ€.</p>



<h2>curl sits in the boat</h2>



<p>In the curl project weâ€™re deliberately conservative and we stick to old standards, to remain a viable and reliable library for everyone. Right now and for the foreseeable future. Things that worked in curl 15 years ago still work like that today. The same way. Users can rely on curl. We stick around. We donâ€™t knee-jerk react to modern trends. We sit still in the boat. We donâ€™t rock it.</p>



<h2>Rewriting means adding heaps of bugs</h2>



<p>The plain fact, that also isnâ€™t really about languages but is about plain old software engineering: translating or rewriting curl into a new language will introduce a lot of bugs. Bugs that we donâ€™t have today.</p>



<p>Not to mention how rewriting would take a huge effort and a lot of time. That energy can instead today be spent on improving curl further.</p>



<h2>What if</h2>



<p><em>If I would start the project today, would Iâ€™ve picked another language?</em> Maybe. Maybe not. If memory safety and related issues was the primary concern I had, then sure. But as Iâ€™ve mentioned above there are several others concerns too so it would really depend on my priorities.</p>



<h2>Finally</h2>



<p>At the end of the day the question that remains is: would we gain more than we would pay, and over which time frame? Who would gain and who would lose?</p>



<p>Iâ€™m sure that there will be or it may even already exist, curl and libcurl competitors and potent alternatives written in most of these new alternative languages. Some of them are absolutely really good and will get used and reach fame and glory. Some of them will be crap. Just like software always work. Let a thousand curl competitors bloom!</p>



<p>Will curl be rewritten at some point in the future? I wonâ€™t rule it out, but I find it unlikely. I find it even more unlikely that it will happen in the short term or within the next few years.</p>



<p>Discuss this post on <a href="https://news.ycombinator.com/item?id=13966241">Hacker news</a> or <a href="https://www.reddit.com/r/programming/comments/61rh9j/curl_is_c/">Reddit</a>!</p>



<p><strong>Followup-post: </strong><a href="https://daniel.haxx.se/blog/2017/03/30/yes-c-is-unsafe-but/">Yes, C is unsafe, butâ€¦</a></p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2017/03/27/curl-is-c/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179601</guid>
            <pubDate>Thu, 18 Feb 2021 13:34:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Proof of work: the reason behind Bitcoinâ€™s horrendous energy consumption]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26179585">thread link</a>) | @throw0101a
<br/>
February 18, 2021 | https://amycastor.com/2021/02/17/proof-of-work-the-reason-behind-bitcoins-horrendous-energy-consumption/ | <a href="https://web.archive.org/web/*/https://amycastor.com/2021/02/17/proof-of-work-the-reason-behind-bitcoins-horrendous-energy-consumption/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-6038">
		<div>
		
<p>Any company that supports bitcoin is making one thing clear: they donâ€™t care about the environment. At a time when global warming is a real threat to the planet, bitcoin is one of the worst offenders.&nbsp;</p>



<p>The global network of computers that â€œmineâ€ bitcoin consumes an entire countryâ€™s worth of energy in their race to win the next block on the blockchainâ€”and get the 6.25 bitcoin block reward, currently worth $300,000.&nbsp;</p>



<p>Since PayPal, Square, MicroStrategy, and <a href="https://amycastor.com/2021/02/08/tesla-spent-1-5b-in-clean-car-credits-on-bitcoin-the-filthiest-asset-imaginable/" target="_blank" rel="noreferrer noopener">Tesla</a> got onto the gameâ€”and started shilling bitcoin on social mediaâ€”the price of bitcoin has soared to new heights. And the higher the bitcoin price, the greater the lure for people to invest in warehouses full of power-hungry rigs to mine bitcoin for profit. </p>



<p>Digiconomistâ€™s <a href="https://digiconomist.net/bitcoin-energy-consumption" target="_blank" rel="noreferrer noopener">Bitcoin Energy Consumption Index,</a> run by Alex de Vries, a blockchain specialist at Big Four accounting firm PwC, estimates bitcoinâ€™s energy consumption to be 79 terawatt-hours of electricity per year, on par with the entire country of Chile. Per his index, bitcoin also emits 37 megatons of carbon dioxide per year, comparable to that of New Zealand.&nbsp;&nbsp;</p>



<p>Researchers at the University of Cambridge Judge Business School figure bitcoinâ€™s power consumption to be even higher. According to their <a href="https://cbeci.org/" target="_blank" rel="noreferrer noopener">Cambridge Bitcoin Electricity Consumption Index,</a> bitcoin consumes 124 terawatt-hours of electricity a year, bringing it inline with countries like Argentina and Norway.</p>



<p>In October, just before PayPal announced it would allow users to buy and sell bitcoin via their digital wallets, bitcoinâ€™s power consumption was 75 terawatt-hours per year, according to the CBECI. Since then, bitcoinâ€™s price climbed from $10,000 to upwards of $50,000, increasing its energy consumption by 40 percent the process.</p>



<p>In 2018, all of the worldâ€™s data centers consumed <a href="https://science.sciencemag.org/content/367/6481/984" target="_blank" rel="noreferrer noopener">205 terawatt-hours of electricity,</a> or 1% of all of the worldâ€™s electricity. Bitcoin accounts for half of that. </p>



<p>Can the worldâ€™s power grids tolerate this added demand for electricity in the midst of global warming? In the U.S., we are already seeing the impact of extreme weather on our power gridsâ€”millions in Texas <a href="https://www.nbcnews.com/news/weather/millions-texans-left-shivering-arctic-cold-without-power-n1257959" target="_blank" rel="noreferrer noopener">shivering in cold, dark homes</a> this week. And <a href="https://www.politico.com/states/california/story/2020/08/18/california-has-first-rolling-blackouts-in-19-years-and-everyone-faces-blame-1309757" target="_blank" rel="noreferrer noopener">rolling black outs in California</a> last year. In Iran last month, authorities blamed <a href="https://www.washingtonpost.com/world/2021/01/16/massive-blackouts-have-hit-iran-government-is-blaming-bitcoin/" target="_blank" rel="noreferrer noopener">massive blackouts on bitcoin mining.</a>  </p>



<h2><strong>Coal powered&nbsp;&nbsp;</strong></h2>



<p>And bitcoinâ€™s energy consumption isnâ€™t green eitherâ€”though bitcoiners like to say that it is. Bitcoin miners are tuned to profits. That means the fastest rigs and the cheapest energy available, mostly in the form of fossil fuels.&nbsp;</p>



<p>â€œCoal is fueling bitcoin,â€ Christian Stoll, an energy researcher at the Technical University of Munich, told <a href="https://www.wired.com/story/bitcoins-climate-impact-global-cures-local/?mbid=social_twitter&amp;mbid=social_twitter&amp;utm_brand=wired&amp;utm_brand=wired&amp;utm_campaign=wired&amp;utm_campaign=wired&amp;utm_medium=social&amp;utm_medium=social&amp;utm_social-type=owned&amp;utm_social-type=owned&amp;utm_source=twitter&amp;utm_source=twitter" target="_blank" rel="noreferrer noopener">Wired magazine</a> a few years ago.&nbsp;&nbsp;</p>



<p>In <a href="https://www.cell.com/joule/fulltext/S2542-4351(19)30255-7" target="_blank" rel="noreferrer noopener">a paper published in <em>Joule</em></a> in June 2019, Stoll and his researchers examined bitcoin mining based on where miners are located and the types of rigs they use. Two-thirds of all bitcoin mining is centered in China, 17% is in Europe, and 15% in North America, the researchers found.&nbsp;</p>



<p>In China, bitcoinâ€™s mining is spread throughout the countryâ€™s sprawling western provinces, Sichuan and Yunnan, and also in the north, in Xinjiang and Mongolia. In the Sichuan province, where about 58% of the worldâ€™s bitcoin mining takes place, miners take advantage of cheap hydroelectric powerâ€”but only during the rainy season, which lasts about six months.&nbsp;</p>



<p>Bitcoin is a 24/7 business, however, and when green energy isnâ€™t availableâ€”and the price of bitcoin is high enough to reap a profit in the dry seasonâ€”the miners in Sichuan turn to coal, the countryâ€™s most abundant energy source. <a href="https://www.iea.org/data-and-statistics?country=CHINA&amp;fuel=Energy%20supply&amp;indicator=ElecGenByFuel" target="_blank" rel="noreferrer noopener">Sixty-five percent of Chinaâ€™s electricity comes from coal.</a>&nbsp;Bitcoin miners in the Xinjiang province and inner Mongolia also rely heavily on coal-fired electricity.&nbsp;</p>



<p>Even when bitcoin uses clean energy, that pushes the use of dirty energy elsewhere. A few years ago, HyperBlock, a bitcoin mine in Missoula County, Montana, struck a deal with a nearby dam for cheap renewable power. They thought they were doing it right, until county officials noted that if energy from the dam went to bitcoin mining, the county as a whole would end up using more coal. </p>



<p>That was the end of that. <a href="https://www.wired.com/story/montana-county-crimp-bitcoin-save-the-earth/" target="_blank" rel="noreferrer noopener">In April 2019,</a> Missoula required all future mines to purchase or build their own renewable power. And soon after the price of bitcoin crashed in March 2020â€”slipping down to below $5,000â€”HyperBlock <a href="https://missoulian.com/news/local/bonner-bitcoin-company-ceases-operations/article_789d8594-f17c-5809-a8fe-918ad226266e.html" target="_blank" rel="noreferrer noopener">declared bankruptcy</a> because it could not pay its power bills.</p>



<h2><strong>Bitcoin mining and proof of work</strong></h2>



<p>Why is bitcoin so inefficient? It turns out that the system uses copious amounts energy not by accident but by design. </p>



<p>Satoshi Nakomoto, bitcoinâ€™s pseudonymous creator, had to figure out a way to solve the <a href="https://en.wikipedia.org/wiki/Double-spending" target="_blank" rel="noreferrer noopener">double-spend problem.</a> We donâ€™t have this problem with paper money. But with digital money, someone could copy the file and use it to spend the funds over and over, rendering the currency useless.&nbsp;</p>



<p>In a centralized system, a trusted third-party, like a bank, checks the digital money you spend against a central ledger to make sure thereâ€™s no funny business going on. But bitcoinâ€™s ledger (the blockchain) is decentralized, which makes the double-spend problem harder to solve.&nbsp;&nbsp;</p>



<p>The solution Satoshi came up with was a clever hack that involves bitcoin mining and proof-of-work. In bitcoin, mining is the process of adding new transactions to the blockchain, and proof-of-work secures the network so transactions canâ€™t be reversed. You would need more than half of all the computing power on the bitcoin network to double-spend a bitcoin.&nbsp;</p>



<p>It wasnâ€™t a perfect solution, but Satoshi solved what computer scientists had long thought was unsolvable: how to build a decentralized payment system. The irony is, unless you are collecting payments for <a href="https://news.bitcoin.com/ransomware-ryuk-rakes-in-150-million-in-bitcoin/" target="_blank" rel="noreferrer noopener">ransomware,</a> bitcoin has proven <a href="https://www.wsj.com/articles/why-bitcoin-hasnt-gained-traction-as-a-form-of-payment-11612886974" target="_blank" rel="noreferrer noopener">unusable as a payment system.</a> No merchant wants to risk their profit margin on bitcoinâ€™s volatility. </p>



<p>Today, bitcoin functions mainly as a <a href="https://www.coindesk.com/store-of-value-remains-cryptos-best-use-case" target="_blank" rel="noreferrer noopener">speculative investment,</a> getting scooped up by retailers and venture capitalistsâ€”and now big companies and <a href="https://cointelegraph.com/news/pension-funds-are-getting-in-on-bitcoin-according-to-grayscalehttps://www.hedgeweek.com/2021/01/19/294600/bitcoins-inefficiencies-are-creating-arbitrage-trades-crypto-hedge-funds" target="_blank" rel="noreferrer noopener">hedge funds</a>â€”in the hopes the price will go ever skyward.  &nbsp;</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">$250k by end of 2022. Just 5X from here. Looking a lot more likely than when I made the initial prediction three years ago, eh? <a href="https://twitter.com/hashtag/Bitcoin?src=hash&amp;ref_src=twsrc%5Etfw">#Bitcoin</a></p>â€” Tim Draper (@TimDraper) <a href="https://twitter.com/TimDraper/status/1362131856544702469?ref_src=twsrc%5Etfw">February 17, 2021</a></blockquote></div>
</div></figure>



<h2>Winning the lottery</h2>



<p>Bitcoin miners have their eyes feasted on the bitcoin block reward. </p>



<p>Every 10 minutes, the bitcoin network adds a new block to the blockchain, minting 900 new bitcoins a day in the process. That block reward is reduced by half every four years. Prior to May 2020, the bitcoin block reward was 12.5 bitcoinsâ€”double what it is nowâ€”and the network produced 1,800 new bitcoins per day. And around February 2024,* the block reward will be 3.125 bitcoins. </p>



<p>When you request a transaction on the bitcoin blockchain, your transaction goes into the <a rel="noreferrer noopener" href="https://www.blockchain.com/charts/mempool-size" target="_blank">bitcoin mempool,</a> a waiting area for unconfirmed bitcoin transactions. Miners select transactions from the poolâ€”usually the ones with the highest transaction feesâ€”and package those into a block ready to process as the next block in the blockchain. </p>



<p>Any server can produce a â€œcandidate block,â€ but if it were too easy to do, the network would be spammed. So there had to be a financial cost to creating a block, hence the work.&nbsp;</p>



<p>In the case of bitcoin, that work involves solving a hash puzzle; the cost is computing time and electricity. The hash puzzle is very difficult to solve, but easy for peers in the bitcoin network to verify, so they can prove you did the work and the block is valid.</p>



<p>Some people refer to this puzzle as a complex math problem, but itâ€™s really not. Working out a hash is easy, but in bitcoin, working out a hash that meets certain conditions is tricky. Finding the solution is a bit like winning a lottery.</p>



<h2>Solving the hash puzzle</h2>



<p>A <a href="https://en.wikipedia.org/wiki/Cryptographic_hash_function" target="_blank" rel="noreferrer noopener">hash</a> is a fixed-length output calculated from a piece of data. Whether you hash Herman Woukâ€™s â€œWar and Remembranceâ€ or a grocery store list, the resultant hash will always be the same length. And you will always get the same hash for the same string. But if even one letter changes in â€œWar and Remembrance,â€ the resultant hash will be different.</p>



<p>Bitcoin uses the <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Hashcash" target="_blank">hashcash proof-of-work,</a> originally developed by cryptographer Adam Back in 1997 as a way to prevent email spam and denial-of-service attacks, and the <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/SHA-2" target="_blank">SHA-256</a> hashing function, which has been around since 2001.</p>



<p>When you hash a bitcoin block, you also track the hash of the previous blockâ€”which â€œchainsâ€ a block to the one before it, and so on down the line to the first bitcoin block ever createdâ€”and a random number called a <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Cryptographic_nonce" target="_blank">nonce.</a> The idea is to produce a hash that is lower than the numeric value of the <a href="https://en.bitcoin.it/wiki/Target" target="_blank" rel="noreferrer noopener">network target.</a> (This target changes periodically to adjust the mining difficulty, thereby assuring only one block gets created every 10 minutes.) </p>



<p>When you mine bitcoin, you repeatedly hash the block while incrementing the nonce. Each time you change the nonce, you also change the value of the resultant hash. The number of hashes that a miner makes per second is called the hash rate; the higher your hash rate, the better your chance of solving the puzzle. A single bitcoin mining rig can make up to 14 trillion guesses per second.</p>



<p>If you discover a hash value that is small enough before anyone else does, you win! Your block is then transmitted to the rest of the network, and the other nodes begin work on the next block using the hash of the accepted block.&nbsp;</p>



<h2>Powerful computers</h2>



<p>As bitcoin went up in value over the years, miners found faster and faster ways to win the bitcoin lottery. When bitcoin was first introduced in 2009, you could mine bitcoin with the CPU on your own personal computer.</p>



<p>Those days are a distant memory. As bitcoin mining became more profitable, miners switched to graphic processing units (GPUs). And in 2011, they migrated to field-programmable gate arrays (FPGAs). But starting in 2013, the field was taken over by application-specific integrated circuit equipment (ASIC) rigsâ€”which is â€¦</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://amycastor.com/2021/02/17/proof-of-work-the-reason-behind-bitcoins-horrendous-energy-consumption/">https://amycastor.com/2021/02/17/proof-of-work-the-reason-behind-bitcoins-horrendous-energy-consumption/</a></em></p>]]>
            </description>
            <link>https://amycastor.com/2021/02/17/proof-of-work-the-reason-behind-bitcoins-horrendous-energy-consumption/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179585</guid>
            <pubDate>Thu, 18 Feb 2021 13:32:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenZFS â€“ dRAID, Finally]]>
            </title>
            <description>
<![CDATA[
Score 161 | Comments 46 (<a href="https://news.ycombinator.com/item?id=26179566">thread link</a>) | @throw0101a
<br/>
February 18, 2021 | https://klarasystems.com/articles/openzfs-draid-finally/ | <a href="https://web.archive.org/web/*/https://klarasystems.com/articles/openzfs-draid-finally/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>




<div>
<h3><em>This is part of our article series published as â€œOpenZFS in Depthâ€. <a href="https://klarasystems.com/articles/"><strong><span>Subscribe to our article series</span></strong> </a>to find out more about the secrets of OpenZFS</em></h3>



<hr>



<p><strong><em>Isaac Huangâ€™s <a href="https://www.youtube.com/watch?v=xPU3rIHyCTs">talk at the OpenZFS 2017 developers summit</a> witnessed the expansion of the ZFS storage endurance envelope for large installations.&nbsp; dRAID or distributed RAID is a new vdev type that complements existing ZFS data protection capabilities for very large storage arrays.&nbsp; Starting with the RAID-Z-like underpinnings, dRAID permutes, or mixes, disk blocks together in a way where accesses are evenly spread across all the drives. Fast spindle replacement is accomplished by using all members of the pool, using pre-allocated virtual spares, spread evenly over all the spindles. Contributors include Intel, Lawrence Livermore Labs, and HP Enterprise, which have material interest in storage at datacenter scale and high reliability. The OpenZFS user community are the benefactors of this enhancement if we apply it well.</em></strong></p>



<h3><strong>Avoiding the Death Spiral</strong></h3>



<p>Admins will often use wide RAID stripes to maximize usable storage given a number of spindles. RAID-Z deployments with large stripe widths, ten or larger, are subject to poor resilver performance for a number of reasons. Resilvering a full vdev means reading from every healthy disk and continuously writing to the new spare. This will saturate the replacement disk with writes while scattering seeks over the rest of the vdev. For 14 wide RAID-Z2 vdevs using 12TB spindles, rebuilds can take weeks. Resilver I/O activity is deprioritized when the system has not been idle for a minimum period. Full zpools get fragmented and require additional I/Oâ€™s to recalculate data during reslivering. A pool can degenerate into a never ending cycle of rebuilds or loss of the pool Aka: the Death Spiral.</p>



<p>As spindles age together, disks may fail in groups as defect counts and mechanical failure are not independent random processes with respect to age. SSDâ€™s further complicate this math as the wear leveling endurance will be very closely matched and clusters of devices under identical load may fail together.&nbsp; Manufacturer provided mean time to failure is a forward-looking statement and is not suitable for replenishment planning. One manufacturer claims 1.2 Million hour MTBF: a dubious 137 year commitment to quality. Itâ€™s poor planning to assume any drive isnâ€™t going to pick today to dramatically fail.&nbsp;</p>



<p>dRAID is an option providing rapid parity rebuild that can mitigate the death spiral behaviour of wide RAIDZ stripes, but as reflected in its default width setting of eight, it does not encourage wide stripes. Dedicating sufficient parity increases the durability of the ZFS pool and the investment in parity should be informed by the risk of losing the pool.</p>



<h3><strong>Distributed Spares?</strong></h3>



<p>Spare disks are a way of keeping a disk warm and ready to replace a failed member. Usually, a spareâ€™s life is leisurely idle until they are scrammed into action during a rebuild. That idleness is a wasted opportunity to do useful work. There are no specific spare disks in a dRAID. Rather, enough blocks are allocated throughout out the vdev to act as spares. The distributed spare is a clever redistribution of work so that all disks are always in use. A disk failure precipitates a rebuild into that dedicated space. After replacement disks are available, the vdev can be re-balanced to return the spare block and put the replacement disk in to use.</p>



<h3><strong><strong><strong>Fixed Stripe Width</strong></strong></strong></h3>



<p>Unlike RAID-Z, an entire stripe in dRAID is allocated at once, no matter how many disk blocks are needed to store the object. The stripe width is determined by the disk sector size multiplied by the number of data drives in the RAID group.</p>



<div data-columns="3" data-layout="50-25-25"><div>




<div><div>
<p>Did you know?</p>



<h2>You can maximize the <strong>power of your FreeBSD</strong> infrastructure with our <strong>Support Subscription!</strong></h2>




</div></div>




</div></div>



<p>RAID-Z has a method of optimizing block layout to minimize block allocations for small files. dRAID however priorities the speed of rebuilding parity and does not make the same space preserving attempt. If your files are a small fraction of the stripe size, dRAID will not be able to use all the disk blocks fully. For example, a default dRAID vdev has a stripe with of 32k (4k per disk, 8 disks); any allocation will require at least 32k. Internal padding is allocated to fill out the stripe width after the request object is stored. Using a smaller stripe width or providing a special mirror vdev will suit smaller allocations and improve drive utilization.</p>



<h3><strong>A Tale of Two Resilvers</strong></h3>



<p>After a failure, the real or distributed spare is written to in sequence, following only the parity layout in the space map to rebuild the drive according to parity data. Sequential reconstruction can be accomplished rapidly by issuing large I/O blocks, reducing seeks, and avoiding tree indirection overhead. The rebuilt diskâ€™s contents are not necessarily consistent with the Merkle tree that proves the zpools data is intact.&nbsp; Itâ€™s important to reconstruct this bitwise copy of the disk first, allowing the system to return to mostly intact state and return to service. That is to say, the sequential reconstruction process restores the redundancy level of the pool, but without being able to verify the checksums of the data. The advantage to this is that it can be completed much more quickly, reducing the window during which additional disk failures might put the pool at risk.</p>



<p>A healing resilver is triggered automatically after a sequential resilver, it is a final operation that verifies that all the contents of the drives match their initial checksums via block pointer traversal. The healing resilver has a number of optimizations to quickly find and reconstruct writes to the failed disk. When a replacement drive can be added to the pool, the rebalance operation is another sequential resilver followed by a healing resilver.</p>



<p>A scrub is the gold standard for a pool health; however, a scrub might be a prohibitive amount of work, visiting every block allocated in the pool. The healing resilver allows a practical return to operation in an environment where failures must be repaired routinely.</p>



<h3><strong><em>â€œAre We There Yet? When Can I Play With it?â€</em></strong></h3>



<p>According to a report from the January OpenZFS leadership meeting, OpenZFS 2.1 will support dRAID in early 2021. If you must have it now; the head branch of the OpenZFS build against recently supported operating systems: FreeBSD 12.1+, Linux 5.10+, Illumos, NetBSD et al. The OpenZFS regression test suite ztest is a good indication that dRAID satisfies the ZFS commitment to data protection. Corporate customers at IBM and Panasas have been flogging other distributed RAID systems for more than ten years. Itâ€™s a mature concept that complements the ZFS tool set.</p>



<h4><strong>Quick Start</strong></h4>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; There is no better way to learn software than to run headlong into mistakes.&nbsp;</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Weâ€™ll install ZFS head from source and gin up some â€˜mdâ€™ file backed disks.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; â€˜zpool create r2dRAID dRAID2:3d:1s:14c /dev/md1 /dev/md2 â€¦.&nbsp; /dev/md13 /dev/md14â€™</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; There it is, a zpool with a dRAID vdev, ready to go to work.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The OpenZFS wiki has a good description of <a href="https://openzfs.github.io/openzfs-docs/Basic%20Concepts/dRAID%20Howto.html">dRAID care, resilvering and rebalancing</a></p>



<p>Following the life cycle of failure and replacement in the documentation is recommended before those skills are tested in production.</p>



<h4><strong>dRAID Nomenclature</strong></h4>



<p>Letâ€™s decode the nomenclature that describes the geometry of a dRAID vdev. A string such as â€œdRAID2:3d:14c:1sâ€ encodes the following about a dRAID vdev.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -dRAID[&lt;parity&gt;][:&lt;data&gt;d][:&lt;children&gt;c][:&lt;spares&gt;s]</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -parity: Required, the number of spindles to use to store parity information. Eg: A dRAID3 can survive until a fourth disk failure without losing data. Parity may be 1,2 or 3.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -[d] data: (spindles per RAID group): Determines the width of the data stripe, 8 is the default. Larger values will increase the stripe width and reduce total parity.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -[c] children: This parameter should match the number of device entries that you feed to the vdev. A helpful check will warn you if you donâ€™t get the right number of disks named correctly: â€œinvalid number of dRAID children; 14 required but 13 providedâ€</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -[s] spares: The number of disk areas to mix in as distributed spares. No spares are created by default, a maximum of four are welcome. Each spare will remove a fraction of space from every disk.</p>



<h2><strong>Parting Short</strong></h2>



<p>The dRAID offers a solution for large arrays, vdevs with fewer than 20 spindles will have limited benefits from the new option. The performance and resilver result will be similar to RAIDZ for small numbers of spindles. Installations with many spindles will see the best results with regards to performance, fast spare activation and replacement. The benefits come with the associated cost of whole stripe at a time allocation for small objects in the pool. This overhead should be calculated in the design of the pool before itâ€™s an operational surprise.</p>



<p>There is no free lunch with dRAID for in saving parity or spare drives, they are your defense against data loss. As drives increase in size, their time to resilver increases and the amount of data they can destroy increases.</p>



<h2><strong>Like this article? Share it!</strong></h2>


</div>




</div></div>]]>
            </description>
            <link>https://klarasystems.com/articles/openzfs-draid-finally/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179566</guid>
            <pubDate>Thu, 18 Feb 2021 13:31:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nx (Numerical Elixir) is now publicly available]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26179373">thread link</a>) | @che_shr_cat
<br/>
February 18, 2021 | https://dashbit.co/blog/nx-numerical-elixir-is-now-publicly-available | <a href="https://web.archive.org/web/*/https://dashbit.co/blog/nx-numerical-elixir-is-now-publicly-available">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    
<ul>
  <li>
    <i></i> JosÃ© Valim
  </li>
  <li>
    <i></i> February 18th, 2021
  </li>
  <li>
    <i></i><a href="https://dashbit.co/blog/tags/nx">nx</a>, <a href="https://dashbit.co/blog/tags/defn">defn</a>
  </li>
</ul>
<p><img src="https://dashbit.co/images/posts/2021/nx.png" alt="Nx" width="400"></p>
<p>
Sean Moriarity and I are glad to announce that the project we have been working on for the last 3 months, Nx, is finally <a href="https://github.com/elixir-nx/nx">publicly available on GitHub</a>. Our goal with Nx is to provide the foundation for Numerical Elixir.</p>
<p>
In this blog post, I am going to outline the work we have done so far, some of the design decisions, and what we are planning to explore next. If you are looking for other resources to learn about Nx, you can <a href="https://thinkingelixir.com/podcast-episodes/034-jose-valim-reveals-project-nx/">hear me unveiling Nx on the ThinkingElixir podcast</a>.</p>
<h2>
  Nx</h2>
<p>
Nx is a multi-dimensional tensors library for Elixir with multi-staged compilation to the CPU/GPU. Letâ€™s see an example:</p>
<pre><code><span>iex&gt; </span><span>t</span><span> </span><span>=</span><span> </span><span>Nx</span><span>.</span><span>tensor</span><span data-group-id="4885761117-1">(</span><span data-group-id="4885761117-2">[</span><span data-group-id="4885761117-3">[</span><span>1</span><span>,</span><span> </span><span>2</span><span data-group-id="4885761117-3">]</span><span>,</span><span> </span><span data-group-id="4885761117-4">[</span><span>3</span><span>,</span><span> </span><span>4</span><span data-group-id="4885761117-4">]</span><span data-group-id="4885761117-2">]</span><span data-group-id="4885761117-1">)</span><span>
</span><span data-group-id="4885761117-5">#</span><span data-group-id="4885761117-5">Nx.Tensor</span><span data-group-id="4885761117-5">&lt;</span><span>
  </span><span>s64</span><span data-group-id="4885761117-6">[</span><span>2</span><span data-group-id="4885761117-6">]</span><span data-group-id="4885761117-7">[</span><span>2</span><span data-group-id="4885761117-7">]</span><span>
  </span><span data-group-id="4885761117-8">[</span><span>
    </span><span data-group-id="4885761117-9">[</span><span>1</span><span>,</span><span> </span><span>2</span><span data-group-id="4885761117-9">]</span><span>,</span><span>
    </span><span data-group-id="4885761117-10">[</span><span>3</span><span>,</span><span> </span><span>4</span><span data-group-id="4885761117-10">]</span><span>
  </span><span data-group-id="4885761117-8">]</span><span>
</span><span data-group-id="4885761117-5">&gt;</span></code></pre>
<p>
As you see, tensors have a type (s64) and a shape (2x2). Tensor operations are also done with the <code>Nx</code> module. To implement <a href="https://en.wikipedia.org/wiki/Softmax_function">the Softmax function</a>:</p>
<pre><code><span>iex&gt; </span><span>t</span><span> </span><span>=</span><span> </span><span>Nx</span><span>.</span><span>tensor</span><span data-group-id="2015320651-1">(</span><span data-group-id="2015320651-2">[</span><span data-group-id="2015320651-3">[</span><span>1</span><span>,</span><span> </span><span>2</span><span data-group-id="2015320651-3">]</span><span>,</span><span> </span><span data-group-id="2015320651-4">[</span><span>3</span><span>,</span><span> </span><span>4</span><span data-group-id="2015320651-4">]</span><span data-group-id="2015320651-2">]</span><span data-group-id="2015320651-1">)</span><span>
</span><span>iex&gt; </span><span>Nx</span><span>.</span><span>divide</span><span data-group-id="2015320651-5">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="2015320651-6">(</span><span>t</span><span data-group-id="2015320651-6">)</span><span>,</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="2015320651-7">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="2015320651-8">(</span><span>t</span><span data-group-id="2015320651-8">)</span><span data-group-id="2015320651-7">)</span><span data-group-id="2015320651-5">)</span><span>
</span><span data-group-id="2015320651-9">#</span><span data-group-id="2015320651-9">Nx.Tensor</span><span data-group-id="2015320651-9">&lt;</span><span>
  </span><span>f64</span><span data-group-id="2015320651-10">[</span><span>2</span><span data-group-id="2015320651-10">]</span><span data-group-id="2015320651-11">[</span><span>2</span><span data-group-id="2015320651-11">]</span><span>
  </span><span data-group-id="2015320651-12">[</span><span>
    </span><span data-group-id="2015320651-13">[</span><span>0.03205860328008499</span><span>,</span><span> </span><span>0.08714431874203257</span><span data-group-id="2015320651-13">]</span><span>,</span><span>
    </span><span data-group-id="2015320651-14">[</span><span>0.23688281808991013</span><span>,</span><span> </span><span>0.6439142598879722</span><span data-group-id="2015320651-14">]</span><span>
  </span><span data-group-id="2015320651-12">]</span><span>
</span><span data-group-id="2015320651-9">&gt;</span></code></pre>
<p>
The high-level features in Nx are:</p>
<ul>
  <li>
    <p>
Typed multi-dimensional tensors, where the tensors can be unsigned integers (<code>u8</code>, <code>u16</code>, <code>u32</code>, <code>u64</code>), signed integers (<code>s8</code>, <code>s16</code>, <code>s32</code>, <code>s64</code>), floats (<code>f32</code>, <code>f64</code>) and brain floats (<code>bf16</code>);    </p>
  </li>
  <li>
    <p>
<a href="http://nlp.seas.harvard.edu/NamedTensor">Named tensors</a>, allowing developers to give names to each dimension, leading to more readable and less error prone codebases;    </p>
  </li>
  <li>
    <p>
Automatic differentiation, also known as autograd. The <code>grad</code> function provides reverse-mode differentiation, useful for simulations, training probabilistic models, etc;    </p>
  </li>
  <li>
    <p>
Tensors backends, which enables the main <code>Nx</code> API to be used to manipulate binary tensors, GPU-backed tensors, sparse matrices, and more;    </p>
  </li>
  <li>
    <p>
Numerical definitions, known as <code>defn</code>, provide multi-stage compilation of tensor operations to multiple targets, such as highly specialized CPU code or the GPU. The compilation can happen either ahead-of-time (AOT) or just-in-time (JIT) with a compiler of your choice;    </p>
  </li>
</ul>
<p>
For Python developers, <code>Nx</code> currently takes its main inspirations from <a href="https://numpy.org/"><code>Numpy</code></a> and <a href="https://github.com/google/jax"><code>JAX</code></a> but packaged into a single unified library.</p>
<p>
Our initial efforts have focused on the underlying abstractions. For example, while Nx implements dense tensors out-of-the-box, we also want the same high-level API to be valid for sparse tensors. You should also be able to use all functions in the <code>Nx</code> module with tensors that are backed by Elixir binaries and with tensors that are stored directly in the GPU.</p>
<p>
By ensuring the underlying tensor backend is ultimately replaceable, we can build an ecosystem of libraries on top of Nx, and allow end-users to experiment with different backends, hardware, and approaches to run their software on.</p>
<p>
<em>Nxâ€™s mascot is the Numbat, a marsupial native to southern Australia. Unfortunately the Numbat are endangered and it is estimated to be fewer than 1000 left. If you are excited about Nx, consider donating to Numbat conservation efforts, such as <a href="https://www.numbat.org.au/">Project Numbat</a> and <a href="https://www.australianwildlife.org/">Australian Wildlife Conservancy</a>.</em></p>
<h2>
Numerical definitions</h2>
<p>
One of the most important features in <code>Nx</code> is the numerical definition, called <code>defn</code>. Numerical definitions are a subset of Elixir tailored for numerical computing. Here is the <code>softmax</code> formula above, now written with <code>defn</code>:</p>
<pre><code><span>defmodule</span><span> </span><span>Formula</span><span> </span><span data-group-id="4810618200-1">do</span><span>
  </span><span>import</span><span> </span><span>Nx.Defn</span><span>

  </span><span>defn</span><span> </span><span>softmax</span><span data-group-id="4810618200-2">(</span><span>t</span><span data-group-id="4810618200-2">)</span><span> </span><span data-group-id="4810618200-3">do</span><span>
    </span><span>inspect_expr</span><span data-group-id="4810618200-4">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="4810618200-5">(</span><span>t</span><span data-group-id="4810618200-5">)</span><span> </span><span>/</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="4810618200-6">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="4810618200-7">(</span><span>t</span><span data-group-id="4810618200-7">)</span><span data-group-id="4810618200-6">)</span><span data-group-id="4810618200-4">)</span><span>
  </span><span data-group-id="4810618200-3">end</span><span>
</span><span data-group-id="4810618200-1">end</span></code></pre>
<p>
The first difference we see with <code>defn</code> is that Elixirâ€™s built-in operators have been augmented to also work with tensors. Effectively, <code>defn</code> replaces Elixirâ€™s <code>Kernel</code> with <code>Nx.Defn.Kernel</code>.</p>
<p>
However, <code>defn</code> goes even further. When using <code>defn</code>, <code>Nx</code> builds a computation with all of your tensor operations. Letâ€™s inspect it:</p>
<pre><code><span>defn</span><span> </span><span>softmax</span><span data-group-id="0860724160-1">(</span><span>t</span><span data-group-id="0860724160-1">)</span><span> </span><span data-group-id="0860724160-2">do</span><span>
  </span><span>inspect_expr</span><span data-group-id="0860724160-3">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="0860724160-4">(</span><span>t</span><span data-group-id="0860724160-4">)</span><span> </span><span>/</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="0860724160-5">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="0860724160-6">(</span><span>t</span><span data-group-id="0860724160-6">)</span><span data-group-id="0860724160-5">)</span><span data-group-id="0860724160-3">)</span><span>
</span><span data-group-id="0860724160-2">end</span></code></pre>
<p>
Now when invoked, you will see this printed:</p>
<pre><code><span>iex(3)&gt; </span><span>Formula</span><span>.</span><span>softmax</span><span data-group-id="4848142189-1">(</span><span>Nx</span><span>.</span><span>tensor</span><span data-group-id="4848142189-2">(</span><span data-group-id="4848142189-3">[</span><span data-group-id="4848142189-4">[</span><span>1</span><span>,</span><span> </span><span>2</span><span data-group-id="4848142189-4">]</span><span>,</span><span> </span><span data-group-id="4848142189-5">[</span><span>3</span><span>,</span><span> </span><span>4</span><span data-group-id="4848142189-5">]</span><span data-group-id="4848142189-3">]</span><span data-group-id="4848142189-2">)</span><span data-group-id="4848142189-1">)</span><span>
</span><span data-group-id="4848142189-6">#</span><span data-group-id="4848142189-6">Nx.Tensor</span><span data-group-id="4848142189-6">&lt;</span><span>
  </span><span>f64</span><span data-group-id="4848142189-7">[</span><span>2</span><span data-group-id="4848142189-7">]</span><span data-group-id="4848142189-8">[</span><span>2</span><span data-group-id="4848142189-8">]</span><span>
  
  </span><span>Nx.Defn.Expr</span><span>
  </span><span>parameter</span><span> </span><span>a</span><span>                                 </span><span>s64</span><span data-group-id="4848142189-9">[</span><span>2</span><span data-group-id="4848142189-9">]</span><span data-group-id="4848142189-10">[</span><span>2</span><span data-group-id="4848142189-10">]</span><span>
  </span><span>b</span><span> </span><span>=</span><span> </span><span>exp</span><span> </span><span data-group-id="4848142189-11">[</span><span> </span><span>a</span><span> </span><span data-group-id="4848142189-11">]</span><span>                               </span><span>f64</span><span data-group-id="4848142189-12">[</span><span>2</span><span data-group-id="4848142189-12">]</span><span data-group-id="4848142189-13">[</span><span>2</span><span data-group-id="4848142189-13">]</span><span>
  </span><span>c</span><span> </span><span>=</span><span> </span><span>exp</span><span> </span><span data-group-id="4848142189-14">[</span><span> </span><span>a</span><span> </span><span data-group-id="4848142189-14">]</span><span>                               </span><span>f64</span><span data-group-id="4848142189-15">[</span><span>2</span><span data-group-id="4848142189-15">]</span><span data-group-id="4848142189-16">[</span><span>2</span><span data-group-id="4848142189-16">]</span><span>
  </span><span>d</span><span> </span><span>=</span><span> </span><span>sum</span><span> </span><span data-group-id="4848142189-17">[</span><span> </span><span>c</span><span>,</span><span> </span><span>axes</span><span>:</span><span> </span><span>nil</span><span>,</span><span> </span><span>keep_axes</span><span>:</span><span> </span><span>false</span><span> </span><span data-group-id="4848142189-17">]</span><span>  </span><span>f64</span><span>
  </span><span>e</span><span> </span><span>=</span><span> </span><span>divide</span><span> </span><span data-group-id="4848142189-18">[</span><span> </span><span>b</span><span>,</span><span> </span><span>d</span><span> </span><span data-group-id="4848142189-18">]</span><span>                         </span><span>f64</span><span data-group-id="4848142189-19">[</span><span>2</span><span data-group-id="4848142189-19">]</span><span data-group-id="4848142189-20">[</span><span>2</span><span data-group-id="4848142189-20">]</span><span>
</span><span data-group-id="4848142189-6">&gt;</span><span>
</span><span data-group-id="4848142189-21">#</span><span data-group-id="4848142189-21">Nx.Tensor</span><span data-group-id="4848142189-21">&lt;</span><span>
  </span><span>f64</span><span data-group-id="4848142189-22">[</span><span>2</span><span data-group-id="4848142189-22">]</span><span data-group-id="4848142189-23">[</span><span>2</span><span data-group-id="4848142189-23">]</span><span>
  </span><span data-group-id="4848142189-24">[</span><span>
    </span><span data-group-id="4848142189-25">[</span><span>0.03205860328008499</span><span>,</span><span> </span><span>0.08714431874203257</span><span data-group-id="4848142189-25">]</span><span>,</span><span>
    </span><span data-group-id="4848142189-26">[</span><span>0.23688281808991013</span><span>,</span><span> </span><span>0.6439142598879722</span><span data-group-id="4848142189-26">]</span><span>
  </span><span data-group-id="4848142189-24">]</span><span>
</span><span data-group-id="4848142189-21">&gt;</span></code></pre>
<p>
This computation graph can also be transformed programatically. The transformation is precisely how we implement automatic differentiation, also known as <code>autograd</code>, by traversing each node and computing their derivative:</p>
<pre><code><span>defn</span><span> </span><span>grad_softmax</span><span data-group-id="5969204985-1">(</span><span>t</span><span data-group-id="5969204985-1">)</span><span> </span><span data-group-id="5969204985-2">do</span><span>
  </span><span>grad</span><span data-group-id="5969204985-3">(</span><span>t</span><span>,</span><span> </span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5969204985-4">(</span><span>t</span><span data-group-id="5969204985-4">)</span><span> </span><span>/</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="5969204985-5">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5969204985-6">(</span><span>t</span><span data-group-id="5969204985-6">)</span><span data-group-id="5969204985-5">)</span><span data-group-id="5969204985-3">)</span><span>
</span><span data-group-id="5969204985-2">end</span></code></pre>
<p>
Finally, this computation graph can also be handed out to different compilers. As an example, we have implemented bindings for <a href="https://www.tensorflow.org/xla/">Googleâ€™s XLA</a> compiler, called EXLA. We can ask the <code>softmax</code> function to use this new compiler with a module attribute:</p>
<pre><code><span>@defn_compiler</span><span> </span><span data-group-id="5313365207-1">{</span><span>EXLA</span><span>,</span><span> </span><span>client</span><span>:</span><span> </span><span>:host</span><span data-group-id="5313365207-1">}</span><span>
</span><span>defn</span><span> </span><span>softmax</span><span data-group-id="5313365207-2">(</span><span>t</span><span data-group-id="5313365207-2">)</span><span> </span><span data-group-id="5313365207-3">do</span><span>
  </span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5313365207-4">(</span><span>t</span><span data-group-id="5313365207-4">)</span><span> </span><span>/</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="5313365207-5">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5313365207-6">(</span><span>t</span><span data-group-id="5313365207-6">)</span><span data-group-id="5313365207-5">)</span><span>
</span><span data-group-id="5313365207-3">end</span></code></pre>
<p>
Once <code>softmax</code> is called, <code>Nx.Defn</code> will invoke <code>EXLA</code> to emit a just-in-time and highly-specialized compiled version of the code, tailored to the tensor type and shape. By passing <code>client: :cuda</code> or <code>client: :rocm</code>, the code can be compiled for the GPU. For reference, here are some benchmarks of the function above when called with a tensor of one million random float values on different clients:</p>
<pre><code>Name                       ips        average  deviation         median         99th %
xla gpu f32 keep      15308.14      0.0653 ms    Â±29.01%      0.0638 ms      0.0758 ms
xla gpu f64 keep       4550.59        0.22 ms     Â±7.54%        0.22 ms        0.33 ms
xla cpu f32             434.21        2.30 ms     Â±7.04%        2.26 ms        2.69 ms
xla gpu f32             398.45        2.51 ms     Â±2.28%        2.50 ms        2.69 ms
xla gpu f64             190.27        5.26 ms     Â±2.16%        5.23 ms        5.56 ms
xla cpu f64             168.25        5.94 ms     Â±5.64%        5.88 ms        7.35 ms
elixir f32                3.22      311.01 ms     Â±1.88%      309.69 ms      340.27 ms
elixir f64                3.11      321.70 ms     Â±1.44%      322.10 ms      328.98 ms

Comparison:
xla gpu f32 keep      15308.14
xla gpu f64 keep       4550.59 - 3.36x slower +0.154 ms
xla cpu f32             434.21 - 35.26x slower +2.24 ms
xla gpu f32             398.45 - 38.42x slower +2.44 ms
xla gpu f64             190.27 - 80.46x slower +5.19 ms
xla cpu f64             168.25 - 90.98x slower +5.88 ms
elixir f32                3.22 - 4760.93x slower +310.94 ms
elixir f64                3.11 - 4924.56x slower +321.63 ms</code></pre>
<p>
Where <code>keep</code> indicates the tensor was kept on the device instead of being transferred back to Elixir. You can see the benchmark in the <a href="https://github.com/elixir-nx/nx/tree/main/exla/bench"><code>bench</code></a> directory and find some examples in the <a href="https://github.com/elixir-nx/nx/tree/main/exla/examples"><code>examples</code></a> directory of the EXLA project.</p>
<h3>
Compiling numerical definitions</h3>
<p>
Before moving forward, it is important for us to take a look at how numerical definitions are compiled. For example, take the <code>softmax</code> function:</p>
<pre><code><span>defn</span><span> </span><span>softmax</span><span data-group-id="5791259392-1">(</span><span>t</span><span data-group-id="5791259392-1">)</span><span> </span><span data-group-id="5791259392-2">do</span><span>
  </span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5791259392-3">(</span><span>t</span><span data-group-id="5791259392-3">)</span><span> </span><span>/</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="5791259392-4">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5791259392-5">(</span><span>t</span><span data-group-id="5791259392-5">)</span><span data-group-id="5791259392-4">)</span><span>
</span><span data-group-id="5791259392-2">end</span></code></pre>
<p>
One might think that Elixir takes the AST of the softmax function above and compiles it directly to the GPU. However, thatâ€™s not the case! Numerical definitions are first compiled to Elixir code that will emit the computation graph and this computation graph is then compiled to the GPU. The multiple stages go like this:</p>
<pre><code>Elixir AST
-&gt; compiles to .beam (Erlang VM bytecode)
   -&gt; executes into defn AST
      -&gt; compiles to GPU</code></pre>
<p>
This multi-stage programming is made possible thanks to Elixir macros. For example, when you see a conditional inside <code>defn</code>, that conditional looks exactly like Elixir conditionals, but it will be compiled to an accelerator:</p>
<pre><code><span>defn</span><span> </span><span>softmax</span><span data-group-id="8102420814-1">(</span><span>t</span><span data-group-id="8102420814-1">)</span><span> </span><span data-group-id="8102420814-2">do</span><span>
  </span><span>if</span><span> </span><span>Nx</span><span>.</span><span>any?</span><span data-group-id="8102420814-3">(</span><span>t</span><span data-group-id="8102420814-3">)</span><span> </span><span data-group-id="8102420814-4">do</span><span>
    </span><span>-</span><span>1</span><span>
  </span><span data-group-id="8102420814-4">else</span><span>
    </span><span>1</span><span>
  </span><span data-group-id="8102420814-4">end</span><span>
</span><span data-group-id="8102420814-2">end</span></code></pre>
<p>
In a nutshell, <code>defn</code> provides us with a subset of Elixir for numerical computations that can be compiled to specific hardware, such as CPU, GPU, and other accelerators. All of this was possible without making changes or forking the language.</p>
<p>
And while <code>defn</code> is a subset of the language, it is a considerable one. You will find support for:</p>
<ul>
  <li>
Mathematical operators  </li>
  <li>
Pipes (<code>|&gt;</code>), module attributes, the access syntax (i.e. <code>tensor[1][1..-1]</code>), etc  </li>
  <li>
Elixir macros constructs (imports, aliases, etc)  </li>
  <li>
Control-flow with conditionals (both <code>if</code> and <code>cond</code>), loops (coming soon), etc  </li>
  <li>
Transformations, an explicit mechanism to invoke Elixir code from a <code>defn</code> (which enables constructs such as <code>grad</code>)  </li>
</ul>
<p>
And more coming down the road.</p>
<h2>
Why functional programming?</h2>
<p>
At this point, you may be wondering: is functional programming a good fit for numerical computing? One of the main concerns is that immutability can be expensive when working with large blobs of memory. And thatâ€™s a valid concern! In fact, when using the default tensor backend, tensors will be backed by Elixir binaries which are copied on every operation. Thatâ€™s why it was critical for us to design <code>Nx</code> with pluggable backends from day one.</p>
<p>
However, as we move to higher-level abstractions, such as numerical definitions, we will start to reap the benefits of functional programming.</p>
<p>
For example, in order to build computation graphs, immutability becomes an indispensable tool both in terms of implementation and in terms of reasoning. The JAX library for Python, which has been one of the guiding lights for Nx design, also promotes functional and immutable principles:</p>
<blockquote>
  <p>
<em>JAX is intended to be used with a functional style of programming</em>  </p>
  <p>
â€” <a href="https://jax.readthedocs.io/en/latest/jax.ops.html?highlight=functional#indexed-update-operators">JAX Docs</a>  </p>
</blockquote>
<blockquote>
  <p>
<em>Unlike NumPy arrays, JAX arrays are always immutable</em>  </p>
  <p>
â€” <a href="https://jax.readthedocs.io/en/latest/notebooks/thinking_in_jax.html?highlight=immutable#JAX-vs.-NumPy">JAX Docs</a>  </p>
</blockquote>
<p>
Similarly, frameworks like <a href="https://thinc.ai/">Thinc.ai</a> argue that functional programming can provide better abstractions and more composable building blocks for deep learning libraries.</p>
<p>
We hope that, by exploring these ideas in a language that is functional by design, Elixir can bring new ideas and insights at the higher-level.</p>
<h2>
What is next?</h2>
<p>
There is a lot of work ahead of us â€¦</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashbit.co/blog/nx-numerical-elixir-is-now-publicly-available">https://dashbit.co/blog/nx-numerical-elixir-is-now-publicly-available</a></em></p>]]>
            </description>
            <link>https://dashbit.co/blog/nx-numerical-elixir-is-now-publicly-available</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179373</guid>
            <pubDate>Thu, 18 Feb 2021 13:08:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Moiva.io v3: a universal tool to Evaluate, Discover and Compare software]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26179252">thread link</a>) | @alexey2020
<br/>
February 18, 2021 | https://moiva.io/blog/universal-tool-to-evaluate-discover-compare-software | <a href="https://web.archive.org/web/*/https://moiva.io/blog/universal-tool-to-evaluate-discover-compare-software">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <div>
    <p><span>Feb 17 2021</span>
    <span>Â· written by</span>
    <a href="https://twitter.com/_aantipov" target="_blank">Alexey Antipov</a>
  </p></div>

  <p>Hi, Alexey is here. I have some exciting news for you!</p>
<p>I rewrote <a href="https://moiva.io/">Moiva.io</a> from scratch and made it a Universal and Flexible tool to suit a taste of every software developer be they a JavaScript, Python or [put your favorite language here] developer.</p>
<p>This article marks a third major release of Moiva.</p>
<p><img src="https://moiva.io/blog/images/universal-tool/full.png" alt="A screenshot of Moiva.io showing comparison of Vue and Svelte npm packages"></p>
<h2 id="whats-new-in-short">Whatâ€™s new (in short)</h2>
<ul>
<li>ability to search for and get data for any GitHub repository in addition to search and comparison of NPM packages.</li>
<li>possibility to bring (relatively easy) Search, Suggestion, and Comparison capabilities to other programming languages' package management systems like <a href="https://mvnrepository.com/">Maven</a> (Java), <a href="https://pypi.org/">PIP</a> (Python), or <a href="https://packagist.org/">Packagist</a> (PHP).</li>
<li>last but not least, Moiva got <a href="https://github.com/aantipov/moiva">open-sourced</a>.</li>
</ul>
<h2 id="why-i-did-it">Why I did it</h2>
<p>At first, I wanted to focus on JavaScript ecosystem, making npm packages first-class citizens in Moiva.io.</p>
<p>The goal was to provide developers with a good tool to evaluate and compare npm packages in different dimensions - Popularity, Maintenance, Security, etc.</p>
<p>But very soon I realized that there are many JavaScript-related projects which donâ€™t have any published npm packages.</p>
<p>Think of, for example, frameworks like <code>Meteor</code>.</p>
<p>Moiva.io could potentially be useful for the evaluation of those projects as well thanks to GitHub charts (Contributors, Issues, Commits Frequency, etc.), but search functionality was limited to npm packages only and everything was built around the concept of npm packages.</p>
<p>On the other hand, if Moiva gets opened up to the search, evaluation and comparison of <strong>any</strong> GitHub project, it will essentially convert Moiva into a universal tool and make it useful to many more developers.</p>
<p>So I got convinced that Moiva should become more Universal and Agile, I just need to come up with a good harmonious concept of how it should look, work and how to implement it.</p>
<h2 id="aha-moment">AHA moment</h2>
<p>In the beginning, the idea of supporting GitHub looked vague and blurred. I didnâ€™t have any good idea how to put together existing functionality for npm packages and the new one for GitHub repositories.</p>
<p>I could implement separate pages for npm and GitHub, but that was not ideal. Both have a lot in common when comparing JavaScript projects.</p>
<p>Then the <code>AHA</code> moment came - everything became clear, I realized how to put together different things and since then I was unstoppable.</p>
<p>Here is the essence of the solution.</p>
<h3 id="one-search-for-all">One Search for All</h3>
<p>The same single search field can be used to search for both npm packages and GitHub repositories. It can be easily achieved via search modifiers (prefixes).</p>
<p>The default search is for GitHub.</p>
<p>The search prefixed with <code>n:</code> is for npm packages.</p>
<p><img src="https://moiva.io/blog/images/universal-tool/search.gif" alt="A gif showing how Search field at Moiva.io works: search for NPM packages and GitHub repositories"></p>
<p>What I like about that solution is that it can be easily extended in the future to search for other things as well.</p>
<h3 id="show-only-relevant-charts">Show only relevant charts</h3>
<p>If a user selects only GitHub repositories without related npm packages, then we can just hide npm-related charts. No reason to show them.</p>
<p>Itâ€™s similar to how ThoughtWorks TechRadar and Developer Usage charts work - they are shown only when there is data for the selected npm packages.</p>
<p>At the same time, if the user selects a mix of npm and Github projects, we will show npm-related charts for the selected npm packages.</p>
<h3 id="how-about-urls">How about URLs</h3>
<p>Every comparison a user makes in Moiva should be easily reproducible via URL.</p>
<p>It means that Moiva should be able to derive from the URL what information to load, what to put into comparison.</p>
<p>When npm packages were the only citizens in the Moiva world, the task was solved easily - the selected npm packages' names were listed in a query parameter: <code>https://moiva.io/?compare=react+svelte+vue</code>.</p>
<p>Having 2 types of citizens, npm and Github, where one depends on the other, complicates things a bit. Moreover, we want to build a future-proof solution that can incorporate other types of citizens like PIP and Maven.</p>
<p>GitHub has a broader scope than npm and my first idea was to replace URL npm identifiers with GitHub identifiers. But there are 2 problems with it:</p>
<ul>
<li>itâ€™s not clear how to derive the npm package from the GitHub repository. At least I couldnâ€™t find the solution for that.</li>
<li>one GitHub repo can be a source of multiple npm packages. There is no 1:1 connection.</li>
</ul>
<p>It lead me to the conclusion that GitHub and npm should be referenced separately in the URL.</p>
<p>So I just decided to have separate query parameters: <code>https://moiva.io/?npm=svelte+vue&amp;github=meteor/meteor</code>.</p>
<h3 id="github-and-npm-reconciliation">GitHub and NPM reconciliation</h3>
<p>Imagine two situations:</p>
<ol>
<li>a user selects Vue as an npm package.</li>
<li>a user selects Vue as a GitHub repo.</li>
</ol>
<p>In the first situation Moiva shows npm-related data and charts like npm Downloads. In the second situation, it doesnâ€™t.</p>
<p>But is it fair? Most probably a user would expect to see the same set of information in both cases, right?</p>
<p>Could we still somehow derive information about the npm package from the GitHub repository? If yes, then we could show npm data for the selected GitHub repository.</p>
<p>Turns out we can make use of <a href="https://github.com/aantipov/moiva-catalog">Moiva Catalog</a> which was built to implement the Suggestions mechanism.
For every listed GitHub repository we can add a name of the npm package if there is one. It means we can solve the problem of the reconciliation for items listed in the catalog. And I think itâ€™s a good enough solution with which we can cover the most popular libraries.</p>
<p>We just need to take care of some details and edge cases.</p>
<ol>
<li>If a repository does have an npm package, but that package is just one of the repoâ€™s â€œby-productsâ€, then probably it doesnâ€™t make sense to show that npm package data when selecting the repository. To solve that problem, an additional flag <code>isNpmCoreArtifact</code> in the catalog can be used to indicate the â€œroleâ€ of the npm package.</li>
<li>If we successfully derive npm data from the GitHub repository, it means we essentially display the same information for both npm and GitHub and have different URL identifiers for the same page. Itâ€™s not good, especially in terms of SEO. So I decided to use npm packageâ€™s name as a URL identifier in such cases. Try load <code>https://moiva.io/?github=vuejs/vue</code> url and see what happens ;=)</li>
</ol>
<h3 id="data-model">Data model</h3>
<p>I mentioned just a few of the problems I had to solve. There were, of course, many others, like duplication handling, aliases, SEO, etc.</p>
<p>Most of the problems got a straightforward solution once I implemented a proper Data Model - I came up with a new abstraction called â€œLibraryâ€ and provided it with certain properties and behavior.</p>
<p>If you are interested, you can check the <a href="https://github.com/aantipov/moiva/">repositoryâ€™s readme</a> for more details about the Library concept.</p>
<h2 id="whats-next">Whatâ€™s next</h2>
<p>I clearly see a huge potential for <a href="https://moiva.io/">Moiva.io</a> to become a really useful tool to many developers.</p>
<p>It can grow and become better in different directions.
I will mention a few of them which look most important to me:</p>
<ul>
<li>enable search/suggestion/comparison for more languages' package systems (Maven, PIP, etc.).</li>
<li>add more useful charts and data, both generic and language/package-system specific.</li>
<li>improve significantly the alternatives suggestion system. Currently, itâ€™s based on <a href="https://github.com/aantipov/moiva-catalog">Moiva Catalog</a> and needs a lot of data to be put there. I see a way how the community could help and contribute there.</li>
</ul>
<hr>
<p>I hope I didnâ€™t waste your time and you found the reading and the project itself interesting.</p>
<p>Stay tuned and Subscribe to the newsletter. I want to publish more interesting content about Moiva development.</p>

</div></div>]]>
            </description>
            <link>https://moiva.io/blog/universal-tool-to-evaluate-discover-compare-software</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179252</guid>
            <pubDate>Thu, 18 Feb 2021 12:55:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taking a Stand in the War on General-Purpose Computing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26179176">thread link</a>) | @TLM275
<br/>
February 18, 2021 | http://cheapskatesguide.org/articles/war-on-gp-computing.html | <a href="https://web.archive.org/web/*/http://cheapskatesguide.org/articles/war-on-gp-computing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://cheapskatesguide.org/articles/war-on-gp-computing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179176</guid>
            <pubDate>Thu, 18 Feb 2021 12:47:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I am a heroin user. I do not have a drug problem]]>
            </title>
            <description>
<![CDATA[
Score 261 | Comments 625 (<a href="https://news.ycombinator.com/item?id=26179003">thread link</a>) | @CapitalistCartr
<br/>
February 18, 2021 | http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem | <a href="https://web.archive.org/web/*/http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			<p><span>C</span>arl Hart is a neuroscientist and Ziff Professor of Psychology at Columbia Universityâ€”he was the first tenured African-American professor of sciences at Columbia. His research focuses on the â€œbehavioral and neuropharmacological effects of psychoactive drugs in humans.â€ Hartâ€™s new book, <i>Drug Use For Grown-Ups</i>, is a bold and engaging effort to counter what he sees as generations of misinformation and moral grandstanding about drug use. Todayâ€™s â€œsensationalistic media coverage of the opioid crisis continues a long, awful tradition of exploiting ignorance and fear to vilify certain members of our society,â€ Hart writes. The media is not the only problem. Scientists, he states, â€œhave frequently overinterpreted and distortedâ€ drugsâ€™ effects on the brain.</p><p>Hart reports that more than 70 percent of drug usersâ€”whether they use alcohol, cocaine, prescription medications, or heroinâ€”do not meet the health criteria for drug addiction. In <i>Drug Use for Grown-Ups</i>, Hart strives to â€œpresent a more realistic image of the typical drug user: a responsible professional who happens to use drugs in his pursuit of happiness.â€ With genial candor, Hart presents himself as a model drug user. â€œI am now entering my fifth year as a regular heroin user,â€ he writes. â€œI do not have a drug-use problem. Never have. Each day, I meet my parental, personal, and professional responsibilities. I pay my taxes, serve as a volunteer in my community on a regular basis, and contribute to the global community as an informed and engaged citizen. I am better for my drug use.â€</p><p><i>Nautilus</i> caught up with Hart to discuss his drug use and his sharp points about science and society. He was as casually bold in conversation as he is in <i>Drug Use for Grown-Ups</i>.</p><figure data-alt="MacNamara_BREAKER"><img src="http://static.nautil.us/18174_0f004440ba0c8f1ccc5c355f3d77207f.png" width="733" alt=""><figcaption><span><strong>HABIT OF A HIGHLY EFFECTIVE PERSON:</strong> â€œMy heroin use is as rational as my alcohol use,â€ Carl Hart writes. â€œLike vacation, sex, and the arts, heroin is one of the tools that I use to maintain my work-life balance.â€</span><span>Courtesy of Carl Hart</span></figcaption></figure><p><b>You say â€œmost drug-use scenarios cause little or no harm and that some responsible drug-use scenarios are actually beneficial for human health and functioning.â€ How so?</b></p><p>Letâ€™s just talk about alcohol first. When youâ€™re at a wedding reception, alcohol serves as a social lubricant. People are more gregarious. They talk, they interact. The same is true with cocaine at parties, heroin among friends, or opium among friends, NDMA among lovers. It enhances empathy, openness, and forgiveness, all of these pro-social attributes.</p><p><b>Drug research, you write, is full of bad science. If you had to name one example, what would it be?</b></p><p>The notion that drug addiction is a brain disease. That encapsulates all thatâ€™s wrong with todayâ€™s science in this area. There is absolutely no data in humans to show that drug addiction is a brain disease. Yet the narrative, the dogma, the dominant perspective is that it does. Even though nobody will dispute that, thereâ€™s absolutely no data in humans to support that statement.</p><p><b>Yet opioids do change the brain biologically, do they not?</b></p><p>Yes, opioids bind to a class of receptors called endogenous opioids, which you find in endorphins, for example. Opioids bind to these receptorsâ€”just like natural chemicals doâ€”which results in a response. In some cases, because of decreased sensitivities and certain types of pain, they may enhance a sense of euphoria. So itâ€™s really just facilitating whatâ€™s already in the body naturally, a system that helps in our survival. Think of fructose or glucose. We add sugar to our tea, our coffee, whatever we have, we add more and more because we like it, it tastes good, and it enhances pleasure. It can give you energy. It can make life more interesting. Humans do not live on logic alone. And so sometimes we do these things, and thatâ€™s OK.</p><blockquote><p>People become addicted because they once had a middle-class-paying job that made them someone in their community.</p> </blockquote><p><b>How have scientists â€œoverinterpreted and distortedâ€ the effects of drugs on the brain?</b><br></p><p>Take brain imaging. People often show one image of someoneâ€™s brain. Letâ€™s say this person is addicted to methamphetamine, according to DSM criteria, versus the brain of someone whoâ€™s not addicted. If you see some difference, some researchers have a propensity to make more out of the differences than are there. Thereâ€™s a wide range of brain structural sizes, such that when we think about one personâ€™s size of their nucleus accumbens, it may be smaller or larger than somebody elseâ€™s nucleus accumbens. But both of the nucleus accumbens, despite their sizes, are within the normal range of human variability. Itâ€™s like height. One guy might be 5â€™10â€, another guy might be 6â€™2â€. But we donâ€™t say the guy whoâ€™s 5â€™10â€ is height deficient. We just say that heâ€™s in a normal range, and heâ€™s not as tall as the other guy. We wouldnâ€™t say one is deficient versus the other. In neuroscience, one of the things that has happened, particularly when it comes to drugs, people have over-interpreted the differences to mean pathology, when, in fact, both of the brain structures are within the normal range of human variability. The overinterpretation is to interpret it as being pathological.</p><p><b>You say the opioid crisis has been sensationalized, and write, â€œPeople are not dying because of opioids; they are dying because of ignorance.â€ What do you mean?</b></p><p>Some people donâ€™t know not to mix specific sedatives with opioids. For example, they donâ€™t know not to mix large amounts of alcohol or large amounts of antihistamines. Specific combinations can lead to respiratory depression, which can lead to death. Another point of ignorance involves people who buy street drugs and donâ€™t necessarily know if the drugs contain contaminants. Thatâ€™s the kind of ignorance Iâ€™m talking about.</p><div>
<article>
<p><a href="http://m.nautil.us/issue/91/The%20Amazing%20Brain/our-mind_boggling-sense-of-smell" data-trval="our-mind_boggling-sense-of-smell" data-trlbl="foc_rec" data-tract="internal_art">
<img src="http://static.nautil.us/17790_d881b3c19eeb9941a2ae1b1afe343442.png" alt="Sapolsky_TH-F1" width="314" height="177">
</a>
</p>
<div>
<p><span>
<span>

<span><a href="http://m.nautil.us/term/f/Neuroscience">Also in Neuroscience</a></span>&nbsp;&nbsp;</span>
</span></p><h4><a href="http://m.nautil.us/issue/91/The%20Amazing%20Brain/our-mind_boggling-sense-of-smell" data-trval="our-mind_boggling-sense-of-smell" data-trlbl="foc_rec" data-tract="internal_art">Our Mind-Boggling Sense of Smell</a></h4>
<p>By Ann-Sophie Barwich</p>
<p>
You might say the brain is our most photogenic organ. We are, thanks to modern neuroimaging, living amid an explosion of brain data. Just consider: We can zoom into the brainâ€™s connectivity to the most minute, molecular level. We can...<strong><a href="http://m.nautil.us/issue/91/The%20Amazing%20Brain/our-mind_boggling-sense-of-smell" data-trval="our-mind_boggling-sense-of-smell" data-trlbl="foc_rec" data-tract="internal_art">READ MORE</a></strong>
</p>

</div>

</article>
</div><p><b>So itâ€™s the mix of drugs that is the problem, not opioids like heroin themselves?&nbsp;</b></p><p>Yes, the majority of opioid deaths occur as a result of combining opioids with multiple sedatives. But there are certain opioids that do concern us if taken alone and the person isnâ€™t aware that they have this particular opioid. Those are fentanyl and the fentanyl analogs. These drugs are a lot more potent than something like heroin, meaning they require less of it to produce the effect. Most of the public arenâ€™t seeking fentanyl or its analogs, but people are tainting things like heroin and oxycodone pills with fentanyl or an analog.</p><p>One way to deal with this tainting, this contamination, is to have free drug-checking facilities, where people can submit samples of their drug and get a chemical readout of what is contained in the substance. That way theyâ€™ll know whether to take the substance or how much of it to take. The public also needs to know that most people who use these drugs are not addicts. If you understand that, then you know that for the people who do become addicted, we have to look beyond the drug and look at the personâ€™s environment, their life. Do they have co-occurring psychiatric illnesses? Do they have pain that is not treated? All of these kinds of issues become important.</p><p><b>At what point does biological change in the brain lead to physical addiction?</b></p><p>Physical addiction occurs as a result of opioidsâ€”or any other drug, alcohol tooâ€”being in the body for consecutive weeks or periods, in particularly high doses. And then the body tries to compensate. For example, with opioids, one of the things that happens is that your gut, your gastrointestinal system, slows down the receptors. Your body is trying to compensate by speeding up the gastrointestinal tract. So when the drug abruptly leaves after several weeks of constant administration of the opioid, now the body is unprepared for the drug not being there and it overcompensates. It really ramps up the motility of the gastrointestinal tract, which causes diarrhea, among other things.</p><blockquote><p>It can give you energy. It can make life more interesting. Humans do not live on logic alone.</p> </blockquote><p><b>Why do some people get addicted and not others?</b><br></p><p>The amount of drugs they take, the period at which they take it. Some people can take opioids for extended periods of time. As long as they keep the doses fairly low and they donâ€™t take multiple doses a day, they probably wonâ€™t experience physical dependence. Itâ€™s just like with alcohol. Most people drink alcohol on a regular basis, but they donâ€™t become physically dependent. Whereas others drink every day in large amounts, and they will become physically dependent.</p><p><b>Why canâ€™t people overcome addiction?</b></p><p>One of the major reasons people canâ€™t overcome it is because weâ€™re not very good at treating addiction in this country. Just think about why people become addicted. A large number become addicted because of co-occurring psychiatric illnesses, because of pain issues, because they once had a middle-class-paying job that made them someone in their home, someone in their community. Those jobs are gone. Then thereâ€™s no healthcare or thereâ€™s poor education. If your treatment is not addressing these issues, people are not going to overcome it. But if we have treatments that are holistic, and theyâ€™re looking at the individual, and not so much the drug, then weâ€™re good. But if weâ€™re just talking about the drug, then weâ€™re already behind the eight ball, then we will lose that battle.</p><p><b>Your definition of addiction follows the DSM-5, which refers to a â€œsubstance use disorderâ€ and values functioning over regular ingestion of a substance. How do you define â€œfunctioningâ€?</b></p><p>Functioning is determined by whether a user is happy in meeting their obligations, whatever they may be, whether theyâ€™re work-related, whether theyâ€™re family-related, or other social sorts of things. The person is not stressed out about their substance â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem">http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem</a></em></p>]]>
            </description>
            <link>http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179003</guid>
            <pubDate>Thu, 18 Feb 2021 12:23:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Why of Technology]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26178726">thread link</a>) | @mpereira
<br/>
February 18, 2021 | https://www.murilopereira.com/the-why-of-technology/ | <a href="https://web.archive.org/web/*/https://www.murilopereira.com/the-why-of-technology/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure><img src="https://www.murilopereira.com/man_on_a_bicycle.jpg"></figure><blockquote><p>I think one of the things that really separates us from the high primates
is that weâ€™re tool builders. I read a study that measured the efficiency of
locomotion for various species on the planet. The condor used the least
energy to move a kilometer. Humans came in with a rather unimpressive
showing about a third of the way down the list. It was not too proud a
showing for the crown of creation. So, that didnâ€™t look so good.</p><p>But then, somebody at Scientific American had the insight to test the
efficiency of locomotion for a man on a bicycle. And, a man on a bicycle, a
human on a bicycle, blew the condor away, completely off the top of the
charts.</p><p>And thatâ€™s what a computer is to me. What a computer is to me is itâ€™s the
most remarkable tool that weâ€™ve ever come up with.</p><p>Itâ€™s the equivalent of a bicycle for our minds.</p><p>â€” <a href="https://www.youtube.com/watch?v=0lvMgMrNDlg&amp;feature=youtu.be&amp;t=322">Steve Jobs (1980)</a></p></blockquote><p>* * *</p><p><a href="https://www.it-hiroshima.ac.jp/institution/library/pdf/research52%5F007-013.pdf">No one knows</a> when or how we, the human species, started talking to each
other. It is likely a natural progression from gesturing, but we can only
speculate about it.</p><p>Language allowed us to break out of our brains and reveal the inner
workings of our consciousness to others.</p><figure><img src="https://www.murilopereira.com/language_speech.jpg" alt="Figure 2: Scott H. Young"><figcaption><p>Figure 2: <a href="https://www.scotthyoung.com/blog/2018/12/04/25-thinking-tools/">Scott H. Young</a></p></figcaption></figure><p>Language is the vessel that carried us from the stone age through the
agricultural revolution, the development of written language, the
scientific and industrial revolutions, and now, the digital age.</p><p>Writing allowed us to <em>offload</em> memories to the physical worldâ€”outside of
our brains. Through our collective and external memories, each generation
has a head start on the previous one. Little by little, standing on the
shoulders of taller and taller giants, we accumulate knowledge about
ourselves and everything around us.</p><p>Weâ€™ve been for long using tools to help us think: notebooks help us
calculate formulas, reason geometrically and preserve our ideas. With
computers, our <em>thinking</em> is now occurring outside of our brains.</p><p>Computers are extensions of our minds in that they allow us to store,
process, and retrieve information from them. With the advent of the
internet we now have immediate access to not only almost all of the
information ever produced by humankind but also to reproducible <em>thinking</em>
encoded into these machines: algorithms.</p><p>Our brain is still a much more impressive device than any of today's
computers. Computers learn
<a href="https://www.davidsilver.uk/wp-content/uploads/2020/03/nfsp-1.pdf">mostly</a>
by finding patterns in massive
quantities of examples given by us. Teaching a young kid about carsâ€”how
to recognize one, what they are, what their purpose is, and how they're
related to other thingsâ€”requires little supervision. Noam Chomsky talks
about it in
<a href="https://www.youtube.com/watch?v=hdUbIlwHRkY&amp;t=1462">this interview</a>.</p><p>Each of these processesâ€”storing, processing and retrieving
informationâ€”have concrete effects on the physical world: if Iâ€™m in
Munich, saying â€œshow route to Hamburgâ€ to my phone will immediately show me
the distance, ETAs and paths for different types of transport to reach my
destination. Not only do I now suddenly know how to navigate across the
country to reach another city, Iâ€™m also able to follow through the exact
path via GPSâ€”a sixth sense giving me perfect geolocation!</p><p>These <em>things</em> that we createdâ€”computers, and the internetâ€”are literally
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6502424/">rewiring our brains</a>, right now, shaping how we think, and engage in social
relationships, changing not only our individual selves but the societies we
live in.</p><p>They started as mechanical machines that filled entire laboratories, turned
into beige boxes in our homes and places of work, and are now sleek slabs
of plastic, metal and glass in everyoneâ€™s pockets. Step by step they get
closer to our bodies, their interfaces more intuitive and natural.</p><p>The way we communicate with them is changing: before, we could only
interact with them by speaking their language. We have now taught them
ours. The torch of progress blazes on: itâ€™s a matter of <em>time</em> until theyâ€™re
connected directly with our brainsâ€”which is equally terrifying and
awe-inspiring.</p><figure><img src="https://www.murilopereira.com/neuralink.jpg" alt="Figure 3: Neuralink"><figcaption><p>Figure 3: <a href="https://neuralink.com/">Neuralink</a></p></figcaption></figure><p>Brain-computer interfaces present a monumental scientific and engineering
challenge, and brain-to-brain, a whole other category of difficulty.</p><p>First, we have no idea how information is encoded in the brain. That needs
to be understood. Second, even assuming weâ€™re able to take a perfect
snapshot of a piece of information in someoneâ€™s brainâ€”for example, how a
particular movie scene makes them feelâ€”we still need to be able to encode
it in a way that includes the full context of their subjective experiences.
Maybe the scene evokes unique memories of their childhood or is somehow
entangled with the smell of a particular cinemaâ€™s leather seats. Third, we
need to figure out how to safely write this perfect snapshot into someone
elseâ€™s brain in a way that can be perceived identically.</p><p>Which is to say, itâ€™s a difficult problem. But a worthwhile one: imagine
having the capability to suddenly become aware of answers for questions you
just thought about. To expertly control <a href="https://youtu.be/PLk8Pm%5FXBJE?t=13">truly integrated</a> prosthetics giving
you superhuman abilities. To give movement to the paralized, sound to the
deaf, and sight to the blind.</p><p>What would be the impacts on society if we were able to communicate an
order of magnitude more effectively? What if <em>everyone</em> was equipped with
the same undisputed basic knowledge of history and science?</p><p>There are internal thoughts that we can attempt to describe with a thousand
words, but ultimately fail to capture in a way thatâ€™s precise, much less
comprehensible by someone else. Words and sentences are an incomplete
representation of our internal thoughts. In the same way that 3D objects
cast 2D shadows (<a href="https://www.youtube.com/watch?v=N0WjV6MmCyM">and 4D, 3D</a>) communicating through language doesnâ€™t carry
all of our cultural and developmental contextâ€”transmitting all of that
along with every phrase would be impractical. Language is in this sense,
lossily compressed thought.</p><figure><img src="https://www.murilopereira.com/tesseract_shadow.jpg"></figure><p>Inert strings of words of ink and paper take a life of their own inside our
heads. Itâ€™s why the exact same information can be interpreted completely
differently by different people.</p><p>Before language, fire and cooking technology allowed us to reallocate
energy usage from the digestive system to the brain by outsourcing
digestion to outside of our bodies, making macronutrients more efficiently
absorbable. Almost all of a cooked meal is metabolized by the body, whereas
raw foods yield less than half of their nutrients.</p><p>Cooking is an extension of our digestive system, and enabled us to develop
large, calorie-hungry brains. It also gave us time to think: our primate
cousins spend half of their days chewing raw food to consume enough
calories to stay alive.</p><p>Brains can be seen as <em>survival machines</em>, locked inside dark skulls,
constantly building a model of the outside world by predicting and learning
through senses and memory. The biological human brain evolved to have the
necessary sophistication to not only expertly navigate and understand the
brute physical reality but also to construct <em>social</em> reality. Democracy,
religion, money: all made up by us, for us.</p><p>We remember the past so that we can predict the future, and by doing so, we
thrive.</p><p>We create technology, which functions as a non-biological extra layer to
our brains and bodies, augmenting, complementing, and sometimes replacing
our natural capabilities.</p><blockquote><p>The wheelâ€¦ is an extension of the foot.</p><p>The bookâ€¦ is an extension of the eyeâ€¦</p><p>Clothing, an extension of the skinâ€¦</p><p>Electric circuitry, an extension of the central nervous system.</p><p>â€”
<a href="https://en.wikipedia.org/wiki/Understanding_Media">Understanding Media: The Extensions of Man (1964)</a></p></blockquote><p>Relatively speaking, we are done evolving <em>biologically</em>. Further adaptations
and enhancements to our bodies and minds will come through technology.</p><figure><img src="https://www.murilopereira.com/brain_layers.jpg" alt="Figure 5: Check out &amp;ldquo;Neuralink and the Brain&amp;rsquo;s Magical Future&amp;rdquo; for a very entertaining primer on the brain."><figcaption><p>Figure 5: Check out â€œ<a href="https://waitbutwhy.com/2017/04/neuralink.html">Neuralink and the Brainâ€™s Magical Future</a>â€ for a very entertaining primer on the brain.</p></figcaption></figure><p>To be human is to have the ability to change the world around us. The shift
from hunting and gathering to farming allowed us to spend less energy to
acquire food while giving us a predictable calorie supply.</p><p>The resulting food surplus made it possible for populations to settle down
and grow quickly while supporting people not being directly involved in the
production of foodâ€”before agriculture that was everyoneâ€™s job. For one,
it allowed some to specialize and focus on developing better farming tools
and more resistant crops, starting a vicious cycle of improvement and
consumption that continues until today.</p><p>The transition from active foraging to a more sedentary lifestyle resulted
in worse health for the general population. The average farmer worked
harder than the average forager and got a worse diet in return. Our teeth,
bones and joints became more fragile, and we became afflicted by novel
diseases coming from newly domesticated animals, carriers of pathogens that
incubated in our new densely populated cities.</p><p>Owning land suddenly became really important. Agriculture and the concept
of private property reinforced each other and grew together, allowing us to
create value and secure the fruits of our labor. It also created the
circumstances for slavery to arise, and wars to be waged.</p><p>The groups of people growing the first crops could not have anticipated all
of the collateral effects of their breakthrough. They just wanted more
food.</p><p>If the past has taught us anything is that we have to be mindful of the
consequences of our progress. In an increasingly connected world, change is
often <a href="https://hbr.org/2017/05/linear-thinking-in-a-nonlinear-world">nonlinear</a> and unpredictable. Cars didnâ€™t just replace horsesâ€”they
forever changed the entire outlook of every city. Did Tim Berners-Lee
anticipate his invention adding to forces pulling whole countries apart?</p><p>Our progress will continue to bring us previously unimaginable challenges.
Against an unknowable future, it doesnâ€™t hurt to keep improving our
capabilities to adapt and, more difficultly, to cooperateâ€”especially at
scale.</p><figure><img src="https://www.murilopereira.com/humanity.jpg" alt="Figure 6: &amp;ldquo;Humanity&amp;rdquo; by Pawel Kuczynski"><figcaption><p>Figure 6: â€œ<a href="https://www.pictorem.com/24592/humanity.html">Humanity</a>â€ by Pawel Kuczynski</p></figcaption></figure><p>Computers are getting pretty good at driving carsâ€”even in the most
difficult situationsâ€”and can already instantly diagnose some diseases
better than human doctors. Technology has a way to <a href="https://www.thenewatlantis.com/publications/understanding-heidegger-on-technology">reveal</a> the potential of
our environment, and ourselves. We have to be careful not to look at â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.murilopereira.com/the-why-of-technology/">https://www.murilopereira.com/the-why-of-technology/</a></em></p>]]>
            </description>
            <link>https://www.murilopereira.com/the-why-of-technology/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26178726</guid>
            <pubDate>Thu, 18 Feb 2021 11:45:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The frame rate of the universe (2009)]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 55 (<a href="https://news.ycombinator.com/item?id=26178259">thread link</a>) | @codesections
<br/>
February 18, 2021 | https://www.librador.com/2009/01/16/The-frame-rate-of-the-universe/ | <a href="https://web.archive.org/web/*/https://www.librador.com/2009/01/16/The-frame-rate-of-the-universe/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
      
<div id="page-2009-2009-01-16-The-frame-rate-of-the-universe-">
  
  <p><abbr title="2009-01-16T01:04:00+01:00">16 Jan 2009</abbr></p><div>
    <p>

    I stumbled upon <a href="http://www.newscientist.com/article/mg20126911.300-our-world-may-be-a-giant-hologram.html?full=true">this
article</a> which presents the hypothesis that the universe is a 3D projection of a 2D
surface, like a giant hologram. I like to read about modern physics. It is so weird and I can't say
I really understand very much of it. But the descriptions provoke strange and fascinating images
and thoughts in my head. Like this one:</p><p>The article mentions the <a href="http://en.wikipedia.org/wiki/Planck_length">Planck length</a>, which as I understand it is
the smallest distance there is. It's extremely small: 1.6 Ã— 10<sup>-35</sup> meters, which makes
it billions and billions of times smaller than an atom (or even a proton). I'm used to thinking
about computer graphics, so I imagine the Planck length as the size of one "pixel" of the universe.
Nothing can be smaller than a pixel. (The pixels of the universe are small, I calculate the
resolution to correspond to 2.19 Ã— 10<sup>33</sup> DPI.) The radius of the observable universe is
4.4 Ã— 10<sup>26</sup> meters. If we want to fit the universe into a box, its sides would have to
be twice that size. That is 5.4 Ã— 10<sup>61</sup> Planck lengths. So that's the width, height and
depth of the universe in pixels. Quite a good resolution. (Actually since they are 3D cubes instead
of 2D squares, I should call them voxels instead of pixels. All 1.61 Ã— 10<sup>185</sup> of
them.)</p><p>There is also the <a href="http://en.wikipedia.org/wiki/Planck_time">Planck time</a>
which is the time it takes for light to travel one Planck length. As light is fast and the Planck
length is tiny (tiniest there is!), you can image that it's a very short period of time. Certainly.
The Planck time is 5.39 Ã— 10<sup>-44</sup> seconds. No measurable time can be shorter than that
according to quantum physics. Thinking about graphics again, this is like a limit on the frame rate
of the universe. Inverting the Planck time, I get 1.855 Ã— 10<sup>43</sup>. So by my surely
incorrect logic, we get the value of the universe's frame rate:</p><p>One thousand eight hundred
and fifty-five billion billion billion billion frames per second.</p><p>I'll say that
again:</p><p>18.55 septillion FPS!</p><p>Video cameras won't be perfect until they can record at
that speed.</p><p>I hope I got the calculations right, but I'm pretty sure my interpretation of the
quantum physics behind this are way off. It's still fascinating to think of the universe as a
computer simulation. Modern physics make it seem more like a video game than ever.<br>


</p>
  </div>
  
  
  <p><a href="http://disqus.com/">blog comments powered by </a>
</p></div>

    </div></div>]]>
            </description>
            <link>https://www.librador.com/2009/01/16/The-frame-rate-of-the-universe/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26178259</guid>
            <pubDate>Thu, 18 Feb 2021 10:37:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lithuania plans to hold drills in case of accident at the Belarus nuclear plant]]>
            </title>
            <description>
<![CDATA[
Score 156 | Comments 132 (<a href="https://news.ycombinator.com/item?id=26178235">thread link</a>) | @maury91
<br/>
February 18, 2021 | https://www.lrt.lt/en/news-in-english/19/1346034/lithuania-plans-to-hold-evacuation-drills-after-belarus-launches-nuclear-plant | <a href="https://web.archive.org/web/*/https://www.lrt.lt/en/news-in-english/19/1346034/lithuania-plans-to-hold-evacuation-drills-after-belarus-launches-nuclear-plant">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article id="article1346034">    

    
    
    <div>

        <div id="article_text1346034">
            <p>Lithuaniaâ€™s Interior Ministry plans to hold drills and assess the need to evacuate Vilniusâ€™ residents in case of an accident at the Astravyets nuclear plant in Belarus, located some 50 kilometres from the Lithuanian capital.</p>
            
            <p>"That will be one of the key questions during the drafting of the exercises schedule and probably going back to the scenarios: do we or do we not need to evacuate Vilnius residents,â€ Vitalij Dmitrijev, vice minister of the interior, told LRT RADIO.</p>
            <p>The so-called Astravyets drill was held in October 2019 in Vilnius and SvenÄionys districts, which are located close to the Belarusian border. During the exercises, authorities prepared to evacuate people from radiation-affected territories, distribute iodine pills, as well as simulated a resident cleanup and monitoring operation.</p>
            <p>The exercise involved around 300 officers, troops and civil servants from six municipalities and 24 institutions. Due to a dispute over the exercise scenario with the Vilnius authorities, officers from the capital did not take part in the drills.</p>
                

            <p><em>Read more: <a href="https://www.lrt.lt/en/news-in-english/19/1103053/lithuanians-stage-mock-evacuations-to-train-for-nuclear-accident-photos">Lithuanians stage mock evacuations to train for nuclear accident â€“ photos</a></em></p>
            <!--googleoff: all--><!--googleon: all-->            <p>Previously, the Vilnius authorities cancelled another exercise, planned in early September, to simulate an accident at the nuclear power plant in Belarus.</p>
            <p>Based on the information available to BNS, Vilnius Municipality faced resistance from the government at the time.</p>
            <p>Lithuanian officials say that the nuclear power plant built by the Russian state atomic corporation Rosatom and funded by a loan from the Kremlin was built in breach of international safety standards. Minsk denies all accusations.</p>
            <p>Estonia, Latvia, and Lithuania are also due to unplug from the Moscow-controlled energy grid that links them with Belarus. Vilnius says that the Kremlin may use the plant to derail the move.</p>
<!--googleoff: all--><div>
            
<div id="mlb2-1612938">
    <div>
        <div>
            <div>
                <div>
                    <p><img src="https://bucket.mlcdn.com/a/1239/1239192/templates/39/39540/5dcc95ea35753170c2955994a6fea7c948ffb283.png"></p><p>LRT English Newsletter<span><span><br></span><span><span>Every Friday morning.</span></span></span></p>
                    
                </div>
            </div>
            
        </div>
    </div>
</div>

<p><img src="https://track.mailerlite.com/webforms/o/1612938/i0s8k2?v4a60e9ef938a7fa0240ac9ba567062cb" width="1" height="1">
</p></div><!--googleon: all-->        </div>
    </div>
    <!--googleoff: all-->
        <!--googleon: all-->
        

<div data-id="gallery1346034"><div>
            <div>
                <div>
                    <div>
<p><img data-src="/img/2019/10/02/522637-581058-1287x836.jpg" alt="â€˜Astravyets drillâ€™ in Lithuania" title="â€˜Astravyets drillâ€™ in Lithuania" src="https://www.lrt.lt/img/2019/10/02/522637-581058-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>â€˜Astravyets drillâ€™ in Lithuania</p>            <p><span>1 / 5</span><span>D. Umbrasas / LRT</span></p>
        </div></div>
</div>
                    </div>
                    <div>
<p><img data-src="/img/2019/12/23/573047-835055-1287x836.jpg" alt="Lithuania has staged 'Astravyets drills' to prepare for nuclear emergencies" title="Lithuania has staged 'Astravyets drills' to prepare for nuclear emergencies" src="https://www.lrt.lt/img/2019/12/23/573047-835055-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>Lithuania has staged 'Astravyets drills' to prepare for nuclear emergencies</p>            <p><span>2 / 5</span><span>D. Umbrasas/LRT</span></p>
        </div></div>
</div>
                    </div>
                    <div>
<p><img data-src="/img/2019/10/02/522627-981621-1287x836.jpg" alt="â€˜Astravyets drillâ€™ in Lithuania" title="â€˜Astravyets drillâ€™ in Lithuania" src="https://www.lrt.lt/img/2019/10/02/522627-981621-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>â€˜Astravyets drillâ€™ in Lithuania</p>            <p><span>3 / 5</span><span>D. Umbrasas / LRT</span></p>
        </div></div>
</div>
                    </div>
                    <div>
<p><img data-src="/img/2019/10/02/522623-306261-1287x836.jpg" alt="â€˜Astravyets drillâ€™ in Lithuania" title="â€˜Astravyets drillâ€™ in Lithuania" src="https://www.lrt.lt/img/2019/10/02/522623-306261-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>â€˜Astravyets drillâ€™ in Lithuania</p>            <p><span>4 / 5</span><span>D. Umbrasas / LRT</span></p>
        </div></div>
</div>
                    </div>
                    <div>
<p><img data-src="/img/2019/10/02/522612-821132-1287x836.jpg" alt="â€˜Astravyets drillâ€™ in Lithuania" title="â€˜Astravyets drillâ€™ in Lithuania" src="https://www.lrt.lt/img/2019/10/02/522612-821132-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>â€˜Astravyets drillâ€™ in Lithuania</p>            <p><span>5 / 5</span><span>D. Umbrasas / LRT</span></p>
        </div></div>
</div>
                    </div>
                </div>
                
            </div>
        </div>
        
    </div>
 

    
    
</article>

        
    </div></div>]]>
            </description>
            <link>https://www.lrt.lt/en/news-in-english/19/1346034/lithuania-plans-to-hold-evacuation-drills-after-belarus-launches-nuclear-plant</link>
            <guid isPermaLink="false">hacker-news-small-sites-26178235</guid>
            <pubDate>Thu, 18 Feb 2021 10:34:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Urbit: The Good, the Bad, and the Insane]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26177720">thread link</a>) | @wcerfgba
<br/>
February 18, 2021 | https://wejn.org/2021/02/urbit-good-bad-insane/ | <a href="https://web.archive.org/web/*/https://wejn.org/2021/02/urbit-good-bad-insane/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  <p><span>Written</span>
    

    
      <span>on&nbsp;</span><time datetime="2021-02-17 19:02:00 +0100">2021-02-17</time>
    
    
  </p>

  

  

  

  <p>In this post Iâ€™m gonna be making all kinds of fun of <a href="https://urbit.org/">Urbit</a>.
And all that after spending just a few hours poking around it.</p>
<p>Originally, I wanted to write in the layout of the good, the bad, and the ugly,
but Iâ€™m not entirely sure how that would pan out.<sup><a href="#fn1" id="fnref1">1</a></sup></p>
<p>Before I begin, Iâ€™ll somewhat oversimplify and explain Urbit to those of you not
in the know.</p>
<p><em>And before I do that, hereâ€™s a PSA: thereâ€™s a <a href="#tldr">tl;dr at the end</a>. So you
donâ€™t need to read all this drivel. Youâ€™re welcome.</em></p>
<h2 id="urwhat">Urâ€¦what?</h2>
<p>According to its own webpage, Urbit is an â€œoverlay OSâ€ and network for the 21st
century.</p>
<p>What that means at the time of writing<sup><a href="#fn2" id="fnref2">2</a></sup> is that itâ€™s a single-threaded
interpreter running as a unix process that speaks udp protocol to a meshed
network (and http to your browser).</p>
<p>And all of that in the name of delivering you flaky, unreliable, and feature-poor
implementation of an internet forum. (in a nutshell)<sup><a href="#fn3" id="fnref3">3</a></sup></p>
<p>An additional component of Urbit is its â€œdistributedâ€ identity component, where
your identity is uniquely tied to a 32-bit integer. And to go with the zeitgeist,
itâ€™s backed by Ethereum blockchain. Naturally.</p>
<p>All we need is quantum computing and ML, and we have all the latest buzzwords.
<a href="https://groups.google.com/a/urbit.org/g/dev/c/a6hdQdzIgqo">Oh, wait.</a></p>
<p>But to better explain whatâ€™s going on, letâ€™s look atâ€¦</p>
<h2 id="a-bit-of-history">A bit of history</h2>
<p>Iâ€™m going to take Urbitâ€™s history page on authority here.</p>
<p>This project started in 2002 as a PhD thesis to reinvent computing. Over the
next 6 years the progress was a language specification (Nock) for
a turing-complete language with ~11 instructions.</p>
<p>Then, over 10+ years other people ran with it, took it further, and implemented:</p>
<ul>
<li>(more than one) VM interpreting that language</li>
<li>a higher level language â€“ Hoon (to make Nock â€œpracticalâ€)</li>
<li>an encrypted mesh protocol</li>
<li>a versioned control system</li>
<li>an application layer</li>
<li>a web frontend (several apps, actually)</li>
<li>an identity layer</li>
<li>â€¦</li>
</ul>
<p>If this smells like a bad case of <a href="https://en.wikipedia.org/wiki/Not_invented_here">NIH</a>,
itâ€™s probably because thatâ€™s exactly the case.</p>
<h2 id="urbit-as-an-ideal-good-and-insane-at-the-same-time">Urbit as an ideal: good and insane at the same time</h2>
<p>But letâ€™s talk about Urbit as an ideal for a moment.</p>
<p>Letâ€™s assume that when <a href="https://youtu.be/M04AKTCDavc">the marketing materials</a>
speak of</p>
<blockquote>
<p>defining an operating system on a single piece of paper</p>
</blockquote>
<p>and</p>
<blockquote>
<p>throwing away every line of code from the 1970s</p>
</blockquote>
<p>they mean well. Given some sort of hardware implementation of Nock (the low level
language) you theoretically <em>could</em> throw away everything and start from scratch.</p>
<p>And it would be all kinds of awesome, if you could have decent control over your
personal computing without all the cruft accumulated since â€™70s.</p>
<p>Onlyâ€¦ with Urbit this ideal would be so slow as to be useless. See, Nock has
one arithmetic operation, increment (<code>x+1</code>). So if you want to decrement <code>x</code>,
you have to loop from <code>0</code> to <code>x-1</code>. Or you can break your promise of throwing
away all the code from â€™70sâ€¦ and implement decrement in C.</p>
<p>And the same story (of replacing godawfully ineffective implementation of native
code with C implementation) goes pretty much for any reasonable functionality you
might expect. Crypto? Sorting? Basic math and string ops? All of it.</p>
<p>The entire frickinâ€™ peer to peer protocol is written in C, too. So are vast
swaths of the OS: db, ames, http, terminal, database, event processing, â€¦</p>
<p>Is it possible to truly throw away every line of code from the 1970s up until
nowâ€¦ and start from clean slate? Hell yeah. Only, probably not with Nock.</p>
<p>So we have the pivot to â€œoverlay OSâ€ (mentioned on urbit.org), in other words:
<strong>letâ€™s not throw away any lines of code, but instead build on top of them</strong>.
And then access the UI using a conventional browser over http, that will
interpret the React-based javascript (among other things).</p>
<p>So far so good.</p>
<p>Ubitâ€™s core promise:reality â€“ 0:1.</p>
<h2 id="hoon-as-a-language-amazing">Hoon as a language: amazing</h2>
<p>Letâ€™s move on to the Hoon language<sup><a href="#fn4" id="fnref4">4</a></sup>, the workhose of the platform.</p>
<p>Once you start diggin in, you will be constantly met with such <a href="https://github.com/urbit/urbit/blob/master/pkg/arvo/gen/cat.hoon">vomit inducing
beauty</a>:</p>
<pre><code>::  ConCATenate file listings
::
::::  /hoon/cat/gen
  ::
/?    310
/+    pretty-file, show-dir
::
::::
  ::
:-  %say
|=  [^ [arg=(list path)] vane=?(%g %c)]
=-  tang+(flop `tang`(zing -))
%+  turn  arg
|=  pax=path
^-  tang
=+  ark=.^(arch (cat 3 vane %y) pax)
?^  fil.ark
  ?:  =(%sched -:(flop pax))
    [&gt;.^((map @da cord) (cat 3 vane %x) pax)&lt;]~
  [leaf+(spud pax) (pretty-file .^(noun (cat 3 vane %x) pax))]
?-     dir.ark                                          ::  handle ambiguity
    ~
  [rose+[" " `~]^~[leaf+"~" (smyt pax)]]~
::
    [[@t ~] ~ ~]
  $(pax (welp pax /[p.n.dir.ark]))
::
    *
  =-  [palm+[": " ``~]^-]~
  :~  rose+[" " `~]^~[leaf+"*" (smyt pax)]
      `tank`(show-dir vane pax dir.ark)
  ==
==
</code></pre>
<p>that makes Perl the world champion of readable languages by comparison.</p>
<p>Iâ€™m not being entirely fair here, because Iâ€™m sure you can memorize the digraphs
in a few weeks<sup><a href="#fn5" id="fnref5">5</a></sup>, and eventually you get the hang of writing this.
But in the grand scheme of thingsâ€¦ why the heck would you want to?!</p>
<p>It is hard enough to write bug free code in a language that you can find
tens of thousands of top notch coders for (that would give you an honest
code review). Itâ€™s quite another thing doing basic reading of Hoon.</p>
<p>But letâ€™s say Iâ€™m biased, this is the future, and 5 years down the road it
will be the gold standard for personal computing dev<sup><a href="#fn6" id="fnref6">6</a></sup>.</p>
<p>What can you expect in terms of features, then?</p>
<p>Well, since youâ€™re essentially supposed to run on top of Nock, and itâ€™s
all supposed to be strictly deterministic on top of an event stream, my
imagination is failing me as to how itâ€™s going to support some sort of
parallel processing, because you probably donâ€™t want to be stuck humping
one core of your CPU.</p>
<p>Letâ€™s say you try to make it work in parallel using message passing.
Hmm, there goes determinism.</p>
<p>Or shared memory? There goes using â€œNockâ€ (as youâ€™re poking yet another
hole in the substrate).</p>
<p>Iâ€™m sure thereâ€™s a solution, but Iâ€™d bet you a doughnut itâ€™s not going
to be as pure as the marketing.</p>
<p>Hoon:reality â€“ draw (it works, but sigh)</p>
<h2 id="urbit-as-an-os--capable">Urbit as an OS â€“ capable?</h2>
<p>Do you remember how we were supposed to throw away all that code from â€™70s?</p>
<p>So thatâ€™s not happening (as described above).</p>
<p>But at least the OS is a shiny awesome thing capable of real tasks, yes?</p>
<p>Okay.</p>
<p>Given my short exposure to Urbit Iâ€™m sure Iâ€™m missing some dark corners
where clumps of awesome lurk, but if you expect more than a Weather app,
half-assed web forum, simple shared notebooks, and a weird ass terminal,
you will be sorely disappointed.</p>
<p>Again, this will be rectified in the future (of that Iâ€™m actually and
honestly sure).</p>
<p>There are already some third party Hoon implementations of bit torrent,
chat bots, etc.</p>
<p>And thereâ€™s some plans for bitcoin integration, 3rd party apps, etc.</p>
<p>So if the ecosystem takes off, it could be rich and wondrous.</p>
<p>Exceptâ€¦ most of it wonâ€™t be written in Hoon or Nock. Since Urbitians
are hard at work providing language bindings for well known languages.</p>
<p>So what are you gaining by using Urbit that you couldnâ€™t get elsewhere?
No, seriouslyâ€¦ I have yet to figure this one out.</p>
<p>Letâ€™s move onâ€¦</p>
<h2 id="hosted-urbit--only-if-you-want-to-wash-your-dirty-laundry-in-public">Hosted Urbit â€“ only if you want to wash your dirty laundry in public</h2>
<p>Now, letâ€™s think about hosting Urbit for just a moment.</p>
<p>You can run it on your Raspberry (and it will work). You even own your
data that way. <em>(duh? donâ€™t you always, in that case?)</em></p>
<p>But letâ€™s suppose you want to host it elsewhere. I mean, thereâ€™s this
awesome peer-to-peer encrypted protocol in Urbit, so itâ€™s secure, right?</p>
<p>Well, thereâ€™s encryption during transit, and then thereâ€™s encryption at
rest.</p>
<p>And the failboat comes in the latter case.</p>
<p><strong>Nothing in Urbit is encrypted at rest</strong>.</p>
<p>No, seriously, all the chat logs, events, everythingâ€¦ is dumped into
a journal on disk<sup><a href="#fn7" id="fnref7">7</a></sup> in cleartext form.</p>
<p>So, hey, also the whole â€œa vault for secretsâ€ from the marketing video?
Hmmâ€¦ are you going to risk it?</p>
<p>And are you going to risk storing your bitcoin wallet on Urbit,
unencrypted?</p>
<p>In other words, <strong>when hosting urbit at any 3rd party, you better be the
only one with access to the underlying OS</strong> (and have it fully encrypted),
lest you want your entire history worth of data readable by the company
running the instance for you. Or anyone with access to the system.</p>
<p>So, running this on GCP? Digital Ocean? Tlonâ€™s hosting? Only if youâ€™re
comfortable [potentially] washing your dirty laundry in public.</p>
<p>Urbit:real world â€“ 0:1</p>
<h2 id="lets-fail-together-over-the-air">Letâ€™s fail together over the air</h2>
<p>So say you run your Urbit securely on your Pi, you love the platform,
the UI, the whole shebang.</p>
<p>Great.</p>
<p>Nothing to fear then?</p>
<p>Yeah, maybe except the teeny tiny detail that if you want to stay up
to date, you need to configure OTA<sup><a href="#fn8" id="fnref8">8</a></sup>.</p>
<p>So you will be receiving updates to your Urbit instance from one of your
neighbors (one that you configure).</p>
<p>And you talk to your neighbors over an end to end encrypted channel.</p>
<p>Sounds great, since this is 2021, and surely the updates are signed.</p>
<p>Well, no. They are not. The transmission is, though. Big help!</p>
<p>So â€“ I guess it wouldnâ€™t be that hard for one rotten apple somewhere
on higher ranks of the network<sup><a href="#fn9" id="fnref9">9</a></sup> <em>(rogue operator, hacked machine, hacked
core devâ€™s machine)</em> to push a code update that exfiltrates all your data,
possibly including all your secrets (hey, remember the BTC integration)?</p>
<p>And imagine the fun of auditing Hoon for potential security holes in
an update, if you were paranoid. Just the thought is hilarious.</p>
<p>Urbit:security â€“ 0:1</p>
<h2 id="urbit-id--scarcity-creates-value-and-you-pay-a-premium-for-that">Urbit ID â€“ scarcity creates value, and you pay a premium for that</h2>
<p>So I watch in great amazement the booming ecosystem of cryptocurrencies
of different shapes and colors, and of all things blockchain.</p>
<p>Urbit ID is even better than all of them, though.</p>
<p>You see, the entire identity address space is artificially constrained
to 32bit integers<sup><a href="#fn10" id="fnref10">10</a></sup>.</p>
<p>And according to the Urbit promoters and backers, <em>scarcity creates value</em>.</p>
<p>Just like that.</p>
<p>No need for demand or anything. Itâ€™s scarce, hence it has value. Done<sup><a href="#fn11" id="fnref11">11</a></sup>.</p>
<p>The fact that a desperate enough person could do an equivalent of a hard
fork, and run it independently with a different Identity root isâ€¦
impossible?</p>
<p>Whatever.</p>
<p>But anyway, letâ€™s say you â€¦</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wejn.org/2021/02/urbit-good-bad-insane/">https://wejn.org/2021/02/urbit-good-bad-insane/</a></em></p>]]>
            </description>
            <link>https://wejn.org/2021/02/urbit-good-bad-insane/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26177720</guid>
            <pubDate>Thu, 18 Feb 2021 09:22:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reflections on Using Haskell for My Startup]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 16 (<a href="https://news.ycombinator.com/item?id=26176940">thread link</a>) | @_query
<br/>
February 17, 2021 | https://alistairb.dev/reflections-on-haskell-for-startup/ | <a href="https://web.archive.org/web/*/https://alistairb.dev/reflections-on-haskell-for-startup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Almost exactly one year ago I quit my job to create a Haskell startup as a solo developer. I had about 20 ideas, but eventually settled on the idea of dependency project health tracking with <a href="https://deadpendency.com/" target="_blank" rel="noopener">Deadpendency</a>.</p>

<p>This post describes the experience and evaluates Haskell and its ecosystem.</p>

<p><small>Disclaimer: This blog post contains a bunch of memes. They are trying to be humorous, not accurate or fair ğŸ˜‰.</small></p>

<h2 id="why-haskell">Why Haskell?</h2>

<p>Since about 2016 I have had a strong <del>obsession</del> love of Haskell. Prior to learning Haskell, I was an experienced OO style developer but I didnâ€™t really know how to keep improving my raw programming ability. Haskell introduced me to the world of functional programming (FP) which has an almost infinite depth of concepts to learn, which do actually help improve code quality and application architecture.</p>

<p><img width="400" src="https://i.imgflip.com/4x9eeq.jpg" alt="I should learn functional programming meme"></p>

<p>Haskell is challenging to learn, but extremely fun to write. For my own learning and pleasure, if my startup succeeds, I want to be doing Haskell.</p>

<p>Additionally, I think Haskell is the best general purpose programming language (that you can use in production). In particular, Haskell excels at writing â€˜boringâ€™ business applications which is typically what I work on. <a href="https://www.foxhound.systems/blog/why-haskell-for-production/" target="_blank" rel="noopener">â€˜Why Haskell For Productionâ€™</a> goes into more detail on the benefits Haskell offers.</p>

<p><img width="400" src="https://i.imgflip.com/4x9fwz.jpg" alt="Haskell is the best change my mind meme"></p>

<h2 id="the-setup-phase">The Setup Phase</h2>

<p>Probably the most challenging part was building out a skeleton architecture to hang my business logic on. I decided to go with, even within Haskell, fairly advanced libraries of <a href="https://docs.servant.dev/en/stable/" target="_blank" rel="noopener"><code>servant</code></a> and <a href="https://hackage.haskell.org/package/fused-effects" target="_blank" rel="noopener"><code>fused-effects</code></a>.</p>

<p>I spent a fair amount of time banging my head against a wall trying to get these libraries to work nicely together. This was primarily from a lack of Haskell ability on my part. I had prepared as best I could, but Haskell is deep and I needed to learn more to work day to day with it. I was lucky enough to eventually find <a href="https://github.com/mitchellwrosen/hspolls" target="_blank" rel="noopener">an example</a> that marries these two libraries together, which was a life saver. Iâ€™m sure I would have gotten there eventually, but I was in a bit over my head at that point.</p>

<p><img width="400" src="https://i.imgflip.com/4x9j14.jpg" alt="Haskell with servant fused-effects is hard meme"></p>

<p>Haskell is awesome, but like most languages there is cruft and legacy to be avoided. Haskell has a standard library known as <a href="https://hackage.haskell.org/package/base" target="_blank" rel="noopener"><code>base</code></a> which unfortunately has a fair amount of unsafe or unperformant functions included. As such I went with an alternative standard library <a href="https://hackage.haskell.org/package/relude" target="_blank" rel="noopener"><code>relude</code></a> that builds on and improves <code>base</code>. On top of this, there are many core libraries that are not part of the standard library I wanted to use and have nice patterns around.</p>

<p>Additionally, I was <a href="https://alistairb.dev/haskell-on-google-cloud-is-great">deploying to google cloud</a> and so needed to figure out good patterns for that integration from Haskell.</p>

<p>This setup effort was quite challenging. I spent most of it squinting at compiler errors. Yet it only took about 2 weeks to have a good foundation of code to start building my business logic upon.</p>

<h2 id="building-it-out">Building it Out</h2>

<p>This is when it started to get really fun. I had my core patterns set out and I could focus on building a pipeline. The day in day out of writing out my logic as small pure functions that I composed together was very nice.</p>

<p>Haskell has such impressive auto-magic code generation techniques that you spend much more time focused on the interesting logic of your application rather than boilerplate.</p>

<div><div><pre><code><span>data</span> <span>HappinessLevel</span> <span>=</span>
    <span>Miserable</span>
  <span>|</span> <span>Sad</span>
  <span>|</span> <span>Average</span>
  <span>|</span> <span>Happy</span>
  <span>|</span> <span>HaskellDeveloper</span>
  <span>deriving</span> <span>(</span><span>Show</span><span>,</span> <span>Eq</span><span>,</span> <span>Ord</span><span>,</span> <span>Bounded</span><span>,</span> <span>Enum</span><span>,</span> <span>ToJSON</span><span>,</span> <span>FromJSON</span><span>)</span> <span>-- magic code generation</span>

<span>-- ok not really magic, think 'convention over configuration'</span>
<span>-- where you can have generated sane defaults, or customise if you like</span>
</code></pre></div></div>

<p>And personally I think Haskell is quite beautiful to read and write. #notbiased</p>

<h3 id="parsing-libraries">Parsing Libraries</h3>

<p>A lot of the logic of Deadpendency is parsing. Either parsing dependency files or parsing various API responses. Haskell has many excellent parsing libraries, most notably <a href="https://hackage.haskell.org/package/aeson" target="_blank" rel="noopener"><code>aeson</code></a> for JSON.</p>

<p>Why is this nice in Haskell? The â€˜monadâ€™ abstraction is excellent for dealing with code with a lot of failure conditions (ie. parsing) and avoids â€˜pyramid of doomâ€™ type code. Haskell worked out really well in this key area.</p>

<p><img width="400" src="https://alistairb.dev/images/hadouken.jpeg" alt="Pyramid of doom meme"></p>

<h3 id="testing">Testing</h3>

<p>Another strong positive for writing Deadpendency was testing. Haskell has a lesser-known style of testing libraries that do â€˜property based testingâ€™ (PBT).</p>

<p>PBT allows you to write value generators for your data types, which you use to generate 100s or 1000s of test cases. Then, you run these generated values against some function and check that certain properties hold.</p>

<p>For example, part of the Deadpendency logic is generating an HTML report at the end. I had some <code>toHtml :: Report -&gt; HTML</code> function that I wanted to test. So I wrote a <code>fromHtml :: HTML -&gt; Report</code> function where it goes the other way (ok writing that was pretty painful). Then my PBT test will generate 100s of <code>Report</code> values and check that <code>report == fromHtml (toHtml report)</code> (this is known as â€˜roundtrip testingâ€™). With this single test I was able to find many edge case bugs with my HTML report generation logic.</p>

<p><img width="400" src="https://i.imgflip.com/4x9tqj.jpg" alt="Haskell with servant fused-effects is hard meme"></p>

<p>PBT exists in some other languages, but it originated (I believe?) in Haskell so the libraries are excellent.</p>

<h3 id="not-actively-maintained-libraries">Not Actively Maintained Libraries</h3>

<p>A big challenge of working with Haskell was the lack of well-maintained libraries. Ironically, of the 75 (!) packages I depend upon 19 are flagged by Deadpendency as unhealthy (deprecated or inactive). This means I often donâ€™t have the luxury of asking library maintainers to fix bugs. Even if I PR a fix, sometimes that PR will be ignored for months.</p>

<p>This I think is the reality of using a niche language like Haskell. To be clear, I do not think library developers owe me anything, but it is nonetheless a downside when compared to more popular languages.</p>

<p><img width="400" src="https://i.imgflip.com/4x9xjq.jpg" alt="Haskell not actively maintained meme"></p>

<p>Thankfully Haskell build tools have good support for loading a package from git. This means you can PR some bug fix or feature and immediately use your fork to work around the problem.</p>

<h3 id="compile-times-were-fine">Compile Times.. Were Fine</h3>

<p>I thought Iâ€™d call this out as it is a common complaint I see around Haskell. I followed some <a href="https://www.parsonsmatt.org/2019/11/27/keeping_compilation_fast.html" target="_blank" rel="noopener">good advice</a> which kept compilation fast (aside from <a href="https://twitter.com/AlistairBuzz/status/1253507016242294784" target="_blank" rel="noopener">one interesting edge case I resolved</a>).</p>

<ul>
  <li>Number of modules (Haskell source files) - 509</li>
  <li>Number of lines of Haskell - 20090</li>
  <li>Number of dependencies - 75</li>
  <li>Dell 9570 XPS Laptop - (Hex core - 8th-gen Intel Core i7-8750H CPU), 32GB memory</li>
</ul>

<p>So what are the numbers?</p>

<h4 id="compile-dependencies-from-scratch">Compile dependencies from scratch</h4>

<p>Time: 17m44s</p>

<p>This is compiling all application dependencies, which needs to be done before you can compile your application code. Rebuilding all from scratch rarely happens as both my dev machines and CI will cache and only rebuild what has changed.</p>

<p>You do sometimes update a very core package which triggers a lot of dependent packages to recompile which can take a while. Although, I usually do dependency updates at the start of the day while Iâ€™m sipping my coffee, so usually donâ€™t notice.</p>

<h4 id="compile-app-including-tests-in-development">Compile app (including tests) in development</h4>

<p>Time: 1m1s</p>

<p>Likewise, due to caching a full recompilation rarely happens. As such, most code edits do not trigger many modules to be recompiled and it is fast.</p>

<p>Additionally, Haskell has nice â€˜continuous compilationâ€™ tools that fire on save. Usually by the time I actually look at my terminal compilation is already done.</p>

<h4 id="compile-app-for-deployment">Compile app for deployment</h4>

<p>with <a href="https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/using-optimisation.html" target="_blank" rel="noopener">full optimisations</a> (-02).</p>

<p>Time: 2m53s</p>

<p>This typically runs in CI. It runs in parallel with a host of other checks such as running my tests, which also take a few minutes. Due to this, the time doesnâ€™t really impact the build + deploy time too much.</p>

<p><img width="400" src="https://i.imgflip.com/4xp4zu.jpg" alt="Compile times meme"></p>

<h3 id="refactoring-pain">Refactoring Pain</h3>

<p>Deadpendency is relatively simple in what it does, but there is a lot of hidden complexity to the problem. Which is to say, it is like 99% of applications ğŸ˜‰. When developing it I was constantly realising I had modelled things a bit too simplistically and would need to refactor.</p>

<p>Haskell is very safe to refactor thanks to the type safety the compiler brings, which is probably the most important thing. However, Haskell does not have great tools to help with refactoring, at least in terms of the restructuring changes I kept making. The <a href="https://hackage.haskell.org/package/apply-refact" target="_blank" rel="noopener">existing</a> <a href="https://hackage.haskell.org/package/retrie" target="_blank" rel="noopener">tools</a> seem more geared towards complex rewriting of common code, not restructuring modules or renaming identifiers.</p>

<p>As such I did it all manually with text search replace, or just change something and fix all the new compiler errors. This was a bit of a grind and it caused me to delay needed refactoring sometimes.</p>

<p>Itâ€™s a pity Haskell doesnâ€™t have the refactoring tools to help in this situation. The dream would be these tools integrated into an IDE.</p>

<p><img width="400" src="https://i.redd.it/dbdshzzflgd31.jpg" alt="Haskell had an IDE meme"></p>

<p>(Stolen from <a href="https://www.reddit.com/r/ProgrammerHumor/comments/cjtbfj/society_if_haskell_has_ide/" target="_blank" rel="noopener">reddit</a>)</p>

<p>Having said that, it should be noted that Haskell does have an excellent IDE now in the form of <a href="https://github.com/haskell/haskell-language-server" target="_blank" rel="noopener">Haskell Language Server</a> (HLS). The momentum around the project is insane and I applaud the developers. One fixed pain point from HLS is it does auto imports now, which used to greatly contribute to the friction of working with Haskell. Iâ€™m sure Haskell will get there eventually.</p>

<h3 id="waiting-for-new-ghc-versions-to-be-usable">Waiting for New GHC Versions to be Usable</h3>

<p>This is mostly me complaining for the sake of it, but as someone pretty obsessed with both new shiny versions of things and Haskell, waiting for new GHC (GHC is the Haskell compiler) versions to be usable has been painful. There is a long tail of libraries and platforms that need to be updated before I can use a new GHC version. Sometimes these updates can drag a lot.</p>

<p>For example GHC 9 was just released, but I still havenâ€™t been able to upgrade to GHC 8.10 yet which was first released in March 2020.</p>

<p><img width="500" src="https://i.imgflip.com/4xebid.jpg" alt="GHC releases meme"></p>

<h2 id="launching">Launching</h2>

<p>So after about 8 months of work I was ready to start getting users. I slowly soft launched, promoting it in a few small channels. How did my Haskell fair in prod?</p>

<h3 id="very-few-logic-bugs">Very Few Logic Bugs</h3>

<p>My core Haskell had very few logic bugs. This is because Haskell is very safe by default and I had opted into strict types that help catch edge cases.</p>

<p>For example, I was using a lot of <a href="https://hackage.haskell.org/package/base-4.14.1.0/docs/Data-List-NonEmpty.html" target="_blank" rel="noopener"><code>NonEmpty</code></a> lists which the compiler will guarantee is not empty. To use them you must specify how to handle the empty case. ie. what do I do if Deadpendency canâ€™t find any dependencies to check?</p>

<p>And of course, I had â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://alistairb.dev/reflections-on-haskell-for-startup/">https://alistairb.dev/reflections-on-haskell-for-startup/</a></em></p>]]>
            </description>
            <link>https://alistairb.dev/reflections-on-haskell-for-startup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26176940</guid>
            <pubDate>Thu, 18 Feb 2021 07:17:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Americentrism]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26176606">thread link</a>) | @jlelse
<br/>
February 17, 2021 | https://jlelse.blog/thoughts/2021/02/americentrism | <a href="https://web.archive.org/web/*/https://jlelse.blog/thoughts/2021/02/americentrism">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Wikipedia has an article on a phenomenon I often observe on the Internet, such as on Hacker News: <a href="https://en.wikipedia.org/wiki/List_of_countries_in_the_Americas_by_population" target="_blank" rel="noopener">Americentrism</a>.</p><blockquote><p><strong>Americentrism</strong>, also known as <em>American-centrism</em> or <em>US-centrism</em>, is a tendency to assume the culture of the United States is more important than those of other countries or to judge foreign cultures based on American cultural standards. It refers to the practice of viewing the world from an overly US-focused perspective, with an implied belief, either consciously or subconsciously, in the preeminence of American culture.</p></blockquote><p>But even that word in itself, I think (as an European), contains U.S. bias: America is equated with the USA, but there are <a href="https://en.wikipedia.org/wiki/List_of_countries_in_the_Americas_by_population" target="_blank" rel="noopener">so many more countries in America</a>.</p><p>Is it just me who thinks like that?</p></div></div>]]>
            </description>
            <link>https://jlelse.blog/thoughts/2021/02/americentrism</link>
            <guid isPermaLink="false">hacker-news-small-sites-26176606</guid>
            <pubDate>Thu, 18 Feb 2021 06:22:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TLS certificates specifying hosts via the CommonName field is more or less gone]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 21 (<a href="https://news.ycombinator.com/item?id=26176448">thread link</a>) | @zdw
<br/>
February 17, 2021 | https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificateCNMostlyGone | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificateCNMostlyGone">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>TLS certificates specifying hosts via their CommonName field is more or less gone</h2>

	<p><small>February 17, 2021</small></p>
</div><div><p><a href="https://en.wikipedia.org/wiki/Transport_Layer_Security">TLS</a>
certificates for hosts and domains must somehow identify what
hostname (or names) they're for. Historically <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificatesNamingHosts">there have been two
ways to do this</a>. The first way was a
specific sub-field, the <em>CN</em> or CommonName, of the certificate's
overall <em>Subject Name</em>. This had the problem that it could only
have one name. When people started wanting to have TLS certificates
that covered more than one name, they invented another mechanism,
the <em>Subject Alternative Name</em> (SAN) extension.</p>

<p>As a practical matter, all vaguely modern software that wants to
properly validate TLS certificates has supported (and often preferred)
Subject Alternative Names for some time. A great many TLS certificates
in the wild are for multiple hosts and it's generally unlikely that the
host you're connecting to is the one name that the system chose to put
in the CN field; software that only supports CN cannot validate those
TLS certificates. As a matter of timing, SANs have been theoretically
mandatory since 2002 and checking only SANs has been theoretically
required since 2011 (which means that since 2011 or earlier, the CN was
supposed to always be one of the SANs).</p>

<p>These days, any remaining support for looking at TLS certificate
CommonName to validate TLS certificates is getting more and more
extinct (and more so than I expected when I started writing this
entry). In the browser realm, <a href="https://www.chromestatus.com/feature/4981025180483584">Chrome apparently turned it off in
58, released in 2017</a>, and then
threw out the option to check it again in Chrome 65 (from the comment
on <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificatesNamingHosts">my old entry</a>, which was ironically
written shortly before Chrome did this). Firefox is said to have
removed support in version 48, from August of 2016. <a href="https://support.apple.com/en-ca/HT210176">Safari
apparently stopped looking at CommonName in iOS 13 and macOS 10.15</a>, which I believe date
from late 2019. <a href="https://go-review.googlesource.com/c/go/+/231379">This Go change</a> also talks about
how browsers removed it in 2019 ('last year' for a mid 2020 change).</p>

<p>In non-browser TLS code, Go started ignoring CN by default in
Go 1.15 (released in August of 2020) and this will be the only
option starting in Go 1.17 (to be released in August of 2021),
per <a href="https://golang.org/doc/go1.16#crypto/x509">here</a>. Since
Firefox doesn't support CN any more, I assume that <a href="https://en.wikipedia.org/wiki/Network_Security_Services">NSS</a> doesn't
either, since NSS is basically Firefox's underlying TLS implementation.
I have no idea what other TLS libraries are doing, but I would expect
that many of them will support CommonName for some time to come; TLS
libraries are historically behind browser practices.  Hopefully they
are all following the 2011 requirement to check only SANs when SANs are
present (which they should always be in public certificates).</p>

<p>Probably TLS certificates will continue to contain CommonName fields
for a long time to come. Having a <em>Subject Name</em> in general is
common (although apparently not actually required) and the CN is a
standard (although not required) part of the Subject Name, so you
might as well throw it in. Even Mozilla and Let's Encrypt (still)
have TLS certificates with CNs. However, since I checked this now,
the current <a href="https://cabforum.org/">CA/Browser Forum</a> <a href="https://cabforum.org/baseline-requirements-documents/">baseline
requirements</a>
(version 1.7.3) allow but don't require CommonName (section 7.1.4.2.2,
which says that it's 'discouraged, but not prohibited'). Given how
conservative most Certificate Authorities are, I expect them to be
issuing TLS certificates with CommonName fields until they're
required to stop.</p>

<p>(An interested party could scan Certificate Transparency logs to see if
there were very many issued certificates without CNs. Probably there are
some; someone must have tried it out at some point through an official
CA.)</p>

<p>PS: <a href="https://no-common-name.badssl.com/">no-common-name.badssl.com</a>
has a TLS certificate without a CN, or at least it's supposed to
(<a href="https://community.letsencrypt.org/t/how-to-obtain-a-cert-without-a-common-name/72807/6">via</a>),
but the TLS certificate is expired right now as I write this entry
so it's hard to test how client software behaves. <a href="https://community.letsencrypt.org/t/compatibility-testing-of-no-common-name/72863">See also</a>,
which pointed me to <a href="https://no-subject.labs.vu.nl/">no-subject.labs.vu.nl</a>,
which has a currently valid TLS certificate with no <em>Subject Name</em> at all.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificateCNMostlyGone</link>
            <guid isPermaLink="false">hacker-news-small-sites-26176448</guid>
            <pubDate>Thu, 18 Feb 2021 05:54:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The questionable use of AI for job applications]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26175871">thread link</a>) | @shirappu
<br/>
February 17, 2021 | https://web.br.de/interaktiv/ki-bewerbung/en/ | <a href="https://web.archive.org/web/*/https://web.br.de/interaktiv/ki-bewerbung/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://web.br.de/interaktiv/ki-bewerbung/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26175871</guid>
            <pubDate>Thu, 18 Feb 2021 04:38:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Extract Tables by Docsumo]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26175273">thread link</a>) | @amitness
<br/>
February 17, 2021 | https://docsumo.com/free-tools/extract-tables-from-pdf-images | <a href="https://web.archive.org/web/*/https://docsumo.com/free-tools/extract-tables-from-pdf-images">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-tool"><div><div><p>Automated table extraction from pdf &amp; images</p><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>It doesn't support in mobile view. <br>You can copy the link and view it in your desktop.</p></div><div id="rating-section"><div id="rating-block"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div></div></div></div></div><div><p>How it works?</p><div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5faa7831743ca77a6aa3ee11_Choose%20File.png" loading="lazy" width="93" alt=""></p><div><p>1. Choose File</p><p>Select or drop the files you want to convert.<br></p></div></div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5faa628aeb96926ffa789a4f_edit%20%20and%20review.png" loading="lazy" width="101" alt=""></p><div><p>2. Edit &amp; Review</p><p>Review the extracted information in the review panel and make changes if needed.</p></div></div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5faa629ae8714b4bf57f0719_Convert%20%26%20Download.png" loading="lazy" width="101" alt=""></p><div><p>3. Convert &amp; Download</p><p>Download the converted file. Right after that, the input file is removed from our server.</p></div></div></div></div><div><p>Extract tables from PDF/Images</p><p>Save your crucial time and prevent any error from occurring with Docsumo's free table extraction from a PDF/Image tool. With this tool, extract tables from PDF documents and images in real-time with 100% accuracy.</p></div><div><p>Questions we often hear</p><p>Let's look at the answers</p><div><div role="list"><div role="listitem"><div><div><div><h4>Why do I need to extract tables from a PDF document?</h4></div><p>Tables are cleaner data format, and often you need only the data from tables embedded in a pdf document. That's why, businesses find it useful to extract tables from pdf documents and process the data.</p></div></div></div><div role="listitem"><div><div><div><h4>Do I need to train this free table extractor from pdf tool?</h4></div><p>The efficiency of Artificial Intelligence and Machine Learning technology improves with number of sample documents processed. So, it is highly recommended to have at least couple of sample documents ready for training.</p></div></div></div><div role="listitem"><div><div><div><h4>What fields does it capture?</h4></div><p>The tool lets you capture any text based field. The tool allows you to review the extracted data before downloading the output.</p></div></div></div><div role="listitem"><div><div><div><h4>Can I convert my document without installing the software?</h4></div><p>Documo's free online OCR tool is capable of processing any document online with complete accuracy. So, there is no need to install the tool on your system.</p></div></div></div><div role="listitem"><div><div><div><h4>Is my data secure with Docsumo?</h4></div><p>Docsumo doesn't sell or share your data to any third-party person or organization. Your data is completely secure and confidential.</p></div></div></div><div role="listitem"><div><div><div><h4>Is there any limit on using the tool?</h4></div><p>There's no usage limit on our free tool. No payment required and no credit card details needed. Sign up with us to get access to more of our resources.</p></div></div></div></div></div></div><div><h2>What Our Customers Are Saying</h2><div><div data-animation="slide" data-nav-spacing="4" data-duration="500" data-infinite="1"><div><div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5f61bd1ba58812799fe2bd13_paysense.svg" loading="lazy" height="" alt=""></p><p>â€œWe are using Docsumoâ€™s APIs for automating data capture from bank statements and identity cards while on-boarding customers. It has reduced the time our operations team spends on data entry by manifolds while providing a much better customer experience.â€</p><p>Prashanth Ranganathan</p><p>CEO, Paysense.com</p></div></div><div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5f61bd1b531b085edc6c1cbf_Onez.jpeg" loading="lazy" height="" width="25" alt=""></p><p>Since the very beginning everything was fine, they always say â€œAsk anything even if you need support from our developers. The support for initial user was exceptional, even for small users like me.</p><div><p>Dario G</p><p>Operations Manager, Onerz</p></div></div></div><div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5f61bd1bf817cf304f90e758_dhanwise.svg" loading="lazy" height="" alt=""></p><p>"With Docsumo we were able to automate invoice processing completely. It has reduced invoice processing time from hours to minutes. Since there is no data entry required, our data extraction accuracy has improved. We highly recommend Docsumo to everyone. "</p><p>Subodh Malgonde</p><p>CEO, DhanWise.com</p></div></div></div></div></div><a href="https://docsumo.com/case-studies"><p>View more Customers Stories</p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5f62f7ab382b1fa34db4108a_arrow.svg" loading="lazy" height="" alt=""></a></div><div id="free-trial-form"><div><div><div><h2>Start your free trial</h2><p>Weâ€™d love to show you how you can increase your productivity, process your documents faster and save operations cost!</p></div></div><div><div><div id="formId"><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://docsumo.com/free-tools/extract-tables-from-pdf-images</link>
            <guid isPermaLink="false">hacker-news-small-sites-26175273</guid>
            <pubDate>Thu, 18 Feb 2021 03:29:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[40 Year History of Opposition to Nuclear Power in California]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 39 (<a href="https://news.ycombinator.com/item?id=26175253">thread link</a>) | @Lammy
<br/>
February 17, 2021 | https://www.energy-net.org/01NUKE/CALIF.HTM | <a href="https://web.archive.org/web/*/https://www.energy-net.org/01NUKE/CALIF.HTM">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="49%"> 
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2" color="#CC6600"><b><span size="3" color="#000000">40 
		Year History of Opposition to Nuclear Power in California </span></b></span> 
		<br>
	  </p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">California 
		citizens have made a unique stand concerning the attempts by Nuclear proponents 
		to make the state a premiere model for commercial nuclear energy. California's major 
		utilities, in particular Pacific Gas and Electric (PG&amp;E) has spent an
		enormous amount of money and political muscle in attempts to build reactors 
		across California but have mostly failed. PG&amp;E was supposedly involved in 
		the Atoms for Peace proposal made in 1953 and was 
		part of a coalition of american utilities that investigated the technical 
		potentials for building nuclear reactors as a source of electricity.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The following 
		is a brief summary of the battles against nuclear power that started here 
		in California in 1958.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Northern 
		California is the home of the first successful opposition to the promotion 
		and development of commercial nuclear reactors in the U.S. In the 1950's 
		northern and central California's privately Owned utility company, PG&amp;E 
		was planning to be one of the giants in the new field of nuclear energy. 
		It had helped design and build the Dresden I reactor in Illinois with 
		a consortium of 5 major companies, including General Electric(GE).</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">In conjunction 
		with GE, it built the vallecitos nuclear complex south of San Francisco 
		and then went it alone with their Humboldt reactor near Arcata. But their 
		luck took a turn for the worse when they tried to build the world's largest 
		nuclear facility 1000 feet from the fault that caused the 1906 earthquake.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Yes, PG&amp;E 
		even said they could build a reactor in downtown San Francisco! In 
		fact they were planning the construction of 63 reactors in California 
		during the early 1960's, one every 25 miles along the coast They even 
		 planned to build a floating reactor!!</span></p>
	  <h2><span face="Verdana, Arial, Helvetica, sans-serif" size="2"><b>The 
		Bodega Bay Duck Pond</b><br>
		</span></h2>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">When PG&amp;E 
		started pushing plans to build the reactors at Bodega Pay in 1958 a literal 
		groundswell of opposition erupted during the next 6 years to stop them 
		dead cold. The site they had chosen near the San Andreas Fault Zone was 
		just a few miles from the epicenter of the Great San Francisco Quake where 
		ground shifts of over 20 feet had occurred in 1906.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">PG&amp;E's 
		unethical plans to build the reactor is not new for this company, as they 
		have a history of unfair tactics that goes back to the company's birth. 
		Upon deciding that the Bodega Headlands would be an excellent site for the largest nuclear 
		facility in the world, PG&amp;E simply beat the state out in its plans 
		to make the area a state park. </span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The battle 
		started in 1958 when the Santa Rosa Press Democrat published the first 
		story on PG&amp;E's plans. The company's ignored their own geologist, who had warned 
		that the area was likely to be effected by strong shaking during a quake. 
		Concerned citizens started getting involved as PG&amp;E refused to acknowledge 
		publicly that they were actually going to build nuclear reactors at the 
		proposed site.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The 1957 
		windscale accident in England, where a small reactor had burned out of 
		control for more than a day, helped focus concerns about safety on this 
		new idea of nuclear power.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">In 1961, 
		after nearly 3 years of pushing their plan behind the scenes, PG&amp;E 
		announced plans to build the Atomic Park at the Bodega site. The ensuing battle 
		and PG&amp;E's nasty style started to backfire though as public concerns 
		grew.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Major opposition 
		came from within the ranks of the Sierra Club, but the board refused to 
		allow its active members the right to oppose the reactors on the issue 
		of earthquakes. When it came out that PG&amp;E had doctored fault maps 
		of the site, all hell broke loose.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">One of PG&amp;E's 
		major claims at the time was that they could build reactors that would 
		survive a great Earthguake. At one point they said that the reactors could 
		survive a quake 50 per cent bigger than the O6' quake by floating the 
		reactors on 3 feet of compressable material but when the public and the 
		Atomic Energy Commission (AEC) got a close-up view of the devastation 
		from the air of the quake in Alaska during the spring of 1964, support 
		for the reactor complex dried up.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Opponents 
		had "infiltrated" the federal government and were pushing 
		for closure. With the disclosure of the AEC's WASH 740 report, which documented 
		potential dangers to the bay area residents in case of an accident, opposition 
		finally reached all government levels.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">California 
		governor Pat Brown asked that PG&amp;E abandon the reactors. Two days 
		later PG&amp;E caved in and called the project off. The battle ended in 
		1964 with a $7 million duck pond as a living monunent to the future. (It 
		is still there today)</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">This experience 
		gave PG&amp;E a deadly lesson on how to overcome public concerns at their 
		next reactor site--Diablo Canyon.</span></p>
	  <h2><span face="Verdana, Arial, Helvetica, sans-serif" size="2"><b>The 
		Diablo Canyon Nightmare:</b><br>
		</span></h2>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The 25 year 
		battle over Diablo Canyon is a classic case of courage in the face of 
		the political power this utility unleashed in its drive to build a major 
		nuclear facility in California.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">PG&amp;E's 
		plans to build a mega facility shifted south to the less populated coastal 
		area near San Luis Obispo. The company purchased the Nipomo Dunes and 
		told environmental leaders that unless an acceptable site was chosen that 
		they would go ahead and build a facility at the popular beach area. The 
		wife of the Sierra Club president was selected to come up with an acceptable 
		site in secrecy with the company. </span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The site 
		chosen, Diablo Canyon, was California's second to last coastal wilderness 
		area, an area that had been proposed as a National Park due to its beauty. 
		Besides being a sacred Chumash burial ground, it was the home of one of 
		a kind 1,000 year old Oak trees (the largest in the world). It was also 
		the home of one of the state's largest populations of abalone and sea 
		otters.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">In the process 
		of getting permission to go ahead with Diablo, PG&amp;E suceeded in selling 
		the site to key members of the Sierra Club's board of directors. The Utility 
		had sympathetic board members flown over the Diablo site in Frank Sinatra's 
		Lear jet, with entertainment by Danny Kaye (Danny later came out against 
		the reactors).</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The first 
		slam-dunk by PG&amp;E came against the local farmer who had the right 
		of way access rights over the Diablo property. The company went to court 
		and had his rights removed. The beligerant act made the man a life-long 
		opponent of PG&amp;E's plan.</span></p>
	  <h2><span face="Verdana, Arial, Helvetica, sans-serif" size="2"><b>PG&amp;E 
		gets Cozy with Sierra Club Board Members</b><br>
		</span></h2>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The biggest 
		tactical plan was to focus on the Sierra Club. The company and the electric 
		industry already had the board's ear with their claims that nuclear power 
		could reduce air pollution that was caused by coal power plants. The utility, 
		with inside help then sought official support for Diablo Canyon when club's 
		only board member who knew about the site's natural value was in Europe. 
		The board went along with PG&amp;E, and in fact voted to block any Club 
		members or chapters opposition to the facility. This move enraged David 
		Brower, eventually resulting in the split up of the club and the creation 
		of Friends of the Earth by embittered Sierra Club members who were angered 
		by the actions of key Sierra Club Board members.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">PG&amp;E's 
		success within the Sierra Club was the culmination of 2 years of behind 
		the scenes work by Doris Leonard. She was the wife of the president of 
		the club. Her role in exchanging the Nipomo Dunes site for Diablo Canyon 
		was rewarded later when she was elected to PG&amp;E's board of directors. 
		</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The Sierra 
		Club refused to allow its local chapter near Diablo to use the club nane 
		in opposing the five proposed reactors at the site. The group was forced 
		to take on another name in 1966, the Shoreline Preservation Conference.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The group 
		was concerned about earthquake faults along the coast as locals were fully 
		aware of the 1927 quake that completely destroyed a nearby city. They 
		called for a full investigation into potential fault areas. Their efforts 
		were ignored by the government and the media.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">News of the 
		reactor siting was poorly covered by the Bay area's conservative media, 
		a tactic that made the issue invisible to bay area residents who had stopped 
		PG&amp;E's Bodega reactor plans.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Oil companies 
		chart the Hosgri Fault The Hosgri fault had been mapped by Shell oil geologists 
		during the 1960's, but not published until 1970. PG&amp;E claims to have 
		not found out about the fault until late 1972. The information was finally 
		publicized in November 1973 by an investigative reporter in Los Angeles. 
		In a suspicious turn of events, the lawyer who had been fighting the case 
		since 1965 was found dead in his car just after the announcement. Authorities 
		claimed it was suicide, with no other investigation to follow up.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">P&amp;GE's 
		bad memories of Bodega Bay helped fuel their push to ignore earthquake 
		concerns at Diabl Canyon. The same Seismic experts who had been involved 
		with the Bodega Bay facility were brought in to review the site for seismicity. 
		They pointed out major flaws in PG&amp;E's own $2,000 seismic study. A 
		state of the art study at the time would have cost $100,000)</span></p>
	  <h2><span face="Verdana, Arial, Helvetica, sans-serif" size="2"><b>The 
		Hosgri Fault Forces PG&amp;E to Rebuild Diablo Again</b><br>
		</span></h2>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">A storm of 
		controversy erupted around the facility as one of the units was reaching 
		completion. Even with the help of the Nuclear Regulatory Commission's 
		(NRC) predecessor, the AEC, PG&amp;E was finally forced after 3 years 
		of federal in-fighting to rebuild seismic bracing in 1976.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">In attempts 
		to stop a seismic retrofit, PG&amp;E even coined the Tao Effect which 
		said that the bigger the structure, the less damage a quake would have.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Seismic experts 
		for the concerned activists remained uninpressed, â€¦</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.energy-net.org/01NUKE/CALIF.HTM">https://www.energy-net.org/01NUKE/CALIF.HTM</a></em></p>]]>
            </description>
            <link>https://www.energy-net.org/01NUKE/CALIF.HTM</link>
            <guid isPermaLink="false">hacker-news-small-sites-26175253</guid>
            <pubDate>Thu, 18 Feb 2021 03:28:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building products â€“ Things I wish I knew when I started building products]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26173963">thread link</a>) | @gmays
<br/>
February 17, 2021 | https://amiltonpaglia.com/writing/building-products | <a href="https://web.archive.org/web/*/https://amiltonpaglia.com/writing/building-products">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><main><header></header><div><p>Nov 7, 2020, 21:00<!-- --> <svg width="16" height="16" style="position:relative;top:2px"><line x1="4" y1="16" x2="12" y2="2" style="stroke:#ccc"></line></svg> <time datetime="1604782800000">3 months ago</time></p></div><p>It's not a step by step guide but rather an attempt to synthesize my thinking about what it really matters to build great products.</p><p>I've been building products for the last 12 years. On this journey, I have been fortunate to have the opportunity to wear a lot of different hats in the making of a digital product.&nbsp;</p><p>I've worked as Interface designer, Front-end developer, UX Designer, Product Designer and lastly, as a Product Manager. All along the way, I've always had a close relationship with engineers, learning everything I could about development and understanding all the effort and creativity necessary to bring products to life.</p><p>To keep this valuable for a wider audience and range of professionals, I've tried to extract the essence of I believe to be essential to keep in mind when building products.</p><p>Loading...</p><h2>Purpose</h2><p><strong>Everything starts with a clear purpose.</strong></p><p>When building products, you have to be an<!-- --> <strong>eternal optimist about your missionâ€Š</strong> â€“ â€Što help you get through the rough times, and<!-- --> <strong>very pessimist about executionâ€Š</strong> â€“ â€Šit always takes way more time and effort to nail it.</p><p><strong>Build great products takes time; it's a long-term commitment.</strong> <!-- -->It's almost impossible (in my experience) to immerse yourself in a work whose purpose isn't aligned with your beliefs.</p><p>Without a clear purpose for you (and your team), it's tough to find an intrinsic motivation to keep iterating your product on a problem space.</p><p>Loading...</p><h2>Constraints</h2><blockquote>"...Here is one of the few effective keys to the Design problem: the ability of the Designer to recognize as many of the constraints as possible; his willingness and enthusiasm for working within these constraints. Constraints of price, of size, of strength, of balance, of surface, of time, and so forth. Each problem has its own peculiar list."<p>Charles &amp; Ray Eames</p></blockquote><p>I love this excerpt from an<!-- --> <a href="https://www.hermanmiller.com/stories/why-magazine/design-q-and-a-charles-and-ray-eames/">interview with Charles and Ray Eames</a> <!-- -->in 1972 about Design. This quote stayed on my mind since the first time I've read it.</p><p><strong>Embracing constraints is essential to creativity.</strong> The primary fuel to your problem-solving is to identify what restrictions you're dealing with.</p><p>Your purpose is what drives your "willingness and enthusiasm for working within these constraints." Once you have a clear purpose and goal in mind, you have to "identify as many constraints as possible" to have a clear problem space to tackle, and sometimes you need to enforce additional constraints.</p><p>I like to think about constraints in two spectrums:</p><ul><li>From <strong>hard constraints</strong> to<!-- --> <strong>self-imposed constraints</strong>;</li><li>From <strong>under constraint</strong> to<!-- --> <strong>over constraint</strong>;</li></ul><h3>Hard &amp; Self-imposed constraints</h3><p><strong>Hard constraints</strong> are the ones that you have little to no influence under it. It's time, resources, team, skills, funding, knowledge, market conditions, laws, available technology, and so on. It's the constraints that you'll have to work within, no matter what.</p><p><strong>Self-imposed constraints</strong> are the ones you set to have a clear problem space and increase your focus. It could come in different shapes. It could be your values, product principles, strategy, and everything else you and your team agree on that helps you stay on the right path. It's your conscious trade-offs.</p><h3>Under &amp; Over Constraints</h3><p><strong>An under constrained problem space will be too broad and challenging to narrow down what really matters.</strong> <!-- -->You'll see yourself drowned in the endless possibilities to solve problems. When you find yourself in this scenario, it's better to enforce new constraints and make trade-offs to eliminate noise.</p><p>On the other hand,<!-- --> <strong>when you over constrain it, you won't leave room for improvisation, innovation, and adaption when it's needed.</strong> <!-- -->You have to find a sweet spot on this spectrum to have the freedom to experiment.</p><p><strong>Identifying the right constraints and balancing them is an ongoing challenge.</strong> <!-- -->Your team will grow, new technologies will enable new solutions, markets, and users will continuously evolve.</p><p>You have to keep your eyes open to see what stays true and what helps you stay focused on what matters.<!-- --> </p><p>Loading...</p><h3>Shaping friction</h3><p><strong>Your goal when designing a product is to shape friction.</strong> <!-- -->You'll have to shape as many frictions as possible from your user's journey to achieve the desired outcome. Here are some examples:</p><ul><li><strong>Optimize your user acquisitionâ€Š</strong> â€“ remove friction from each step of the funnel;</li><li><strong>Improve engagementâ€Š</strong> â€“ remove friction to make core actions more intuitive and accessible;</li><li><strong>Reduce churnâ€Š</strong> â€“ â€Šremove friction that is keeping users away from their goals;</li><li><strong>Avoid unintended behaviorsâ€Š</strong> â€“â€Š Instagram adding features to avoid users (adding friction) to pos offensive content;</li><li>You got the pointâ€¦</li></ul><p><mark><strong>To identify which friction worth solving/shaping, you have to have a deep understating of your product and the people using it.</strong></mark> <!-- -->You'll have to know product goals and the user's job-to-be-done (context, objectives, functional and emotional needs).</p><p>In essence, your job is to continuously iterate, shape, and balance the right amount of friction on each part of the product.</p><h3>Prioritization &amp;&nbsp;Judgment</h3><p>Loading...</p><p><strong><mark>Prioritization is one of the most essential subjects in building products.</mark></strong></p><p>There are endless techniques, frameworks, mental models, and tools to help you make the right decisions when prioritizing your next move.</p><p>The truth is that it's tough to make the "best" decisions, even when you have lots of qualitative and quantitative insights (not the case for early-stage products) to inform your prioritization.</p><p><strong>Confident decision making takes time</strong>. When working on a high-growth startup, you'll have to be comfortable with the uncertainty, lack of time, data, and resources to make the right call.</p><p>Another critical factor to keep in mind is your (and your team's) biases. Even when you have plenty of data at your disposal, you and your team are always influenced by some bias (<a href="https://en.wikipedia.org/wiki/List_of_cognitive_biases" title="Cognitive biases" target="_blank">confirmation bias and others</a>).</p><p>There will be times when you won't have enough data, other times you won't have enough time, and most of the time, you won't be aware of your biases.</p><p>That leads me to my last point, <strong>judgment</strong>. Good judgment is extremely underrated these days, but I find it one of the most valuable traits.</p><blockquote>"Good Judgment depends mostly on experience, and experience usually comes from poor judgment."<p>Old saying</p></blockquote><p>Good judgment is also impossible to measure upfront, but<!-- --> <strong>it will be your judgment</strong> to assess the risk and time needed to make each decision<strong>that will lead you towards the best possible outcomes</strong> <!-- -->in times of uncertainty.</p></main></div></div></div>]]>
            </description>
            <link>https://amiltonpaglia.com/writing/building-products</link>
            <guid isPermaLink="false">hacker-news-small-sites-26173963</guid>
            <pubDate>Thu, 18 Feb 2021 00:44:06 GMT</pubDate>
        </item>
    </channel>
</rss>
