<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 11 Nov 2020 08:21:27 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 11 Nov 2020 08:21:27 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[A Think Piece on Privacy and Big Data]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25033030">thread link</a>) | @Rohitha_Perera
<br/>
November 9, 2020 | https://talk.hyvor.com/blog/privacy-and-big-data/ | <a href="https://web.archive.org/web/*/https://talk.hyvor.com/blog/privacy-and-big-data/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><span></span>
<span>114</span>
</p>
<p>The majority of us in the present and in the immediate future <a href="https://www.beyondtrust.com/blog/entry/exactis-data-breach-paving-road-data-dystopia-us-gdpr">will face the issue of Privacy</a>. Consider this basic thought, which may sound like science fiction, but is actually quite present today: Thanks to the devices we wear now, <a href="https://www.beyondtrust.com/blog/entry/exactis-data-breach-paving-road-data-dystopia-us-gdpr">the harvesting of our biometric data</a> is a possibility. It is this thought process that led to this think piece on privacy and big data.</p>
<p>Corporations can get to know us far better than we know ourselves. They can then not just predict our feelings but also manipulate our feelings. Monitoring of our biometrics can make episodes like that of Cambridge Analytica’s data hacks prehistoric in comparison. </p>
<p>Remember that <a href="https://www.cheatsheet.com/money-career/heres-much-google-facebook-really-think-youre-worth.html/">you are worth quite a bit of money to the social channels </a>you use. The podcast detailing the <a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9IY09mTE41Mg&amp;ep=14&amp;episode=MjM0YjM1OTgtZTQ1Mi00NGZhLTkzYjUtMTQxMGJjZTY1NGE4">Congressional Antitrust Investigation on Tech Monopolies: Google, Facebook, Amazon, and Apple</a> gives a serious look at how powerful these big data companies are. The scale is astronomical. Amazon captures 70% of all retails in the United States. They literally have seven times the revenue of their next largest competitor. </p>
<p>Now imagine their cloud computing capabilities. Take stock of the number of iPhones that are there. We know that what you share on social media, and the information that you surrender is a Big Data Issue; and, consider the number of search results Google controls. There’s information about you being harvested. You should know how your information is being used. </p>
<h2>Some Background</h2>
<p>We hear of how <a href="https://www.theguardian.com/us-news/2018/mar/22/steve-bannon-on-cambridge-analytica-facebook-data-is-for-sale-all-over-the-world">Steve Bannon used Facebook</a> to change politics and change culture. Facebook data, algorithms and narratives were his key weapons. These tools were used by the <a href="https://www.reuters.com/article/us-facebook-cambridge-analytica-kogan-idUSKBN1GX2F6">Cambridge Analytica team to identify the dark triad</a> — Narcissism, Machiavellianism and Psychopathy — in people. We now know about the Russian interference in American politics. We know how data had been manipulated to channel the latent proclivities of racism and anti-Semitism within America to divide it. </p>
<p>The same podcast makes mention of a great knowledge-infused book, which is Shoshana Zuboff’s <a href="https://youtu.be/QL4bz3QXWEo">The Age of Surveillance Capitalism</a>. In this book, Zuboff details the rise of a new form of power which will forever change our lives. By collecting behavioral data from their users, corporations have amassed an incomprehensibly large and detailed picture of our personal lives. They use this data to expand their corporate power and profitability. This, of course, has tremendous consequences for our privacy, but also for our political system.</p>
<figure><img src="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/big-5-personality.jpg" alt="" data-src="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/big-5-personality.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>Surveillance Capitalism talks of <a href="https://www.simplypsychology.org/big-five-personality.html">The Five Factor Personality Test</a>, which helps companies like Facebook infer our political proclivities and sexuality. This is based on the predictive signals based on the punctuation we use on a Facebook status. </figcaption></figure>
<p>Surveillance Capitalism is where it universally claims our private human experience as their free source of raw material. They take the rich predictive signals in our behavior and convert it into data. We hear of <a href="https://arstechnica.com/information-technology/2017/05/facebook-helped-advertisers-target-teens-who-feel-worthless/#:~:text=Leaked%202017%20document%20reveals%20FB,exploit%20teens'%20words%2C%20images.&amp;text=Facebook's%20secretive%20advertising%20practices%20became,of%20the%20company's%20Australian%20office.">Facebook executives who promote&nbsp;advertising campaigns that exploit Facebook users’ emotional states</a>. Facebook’s algorithms can determine, and&nbsp;allow&nbsp;advertisers to pinpoint, “moments when young people need a confidence boost.”&nbsp;97% of Facebook’s revenue comes from its online targeted advertising markets. These are wholly-owned and operated in this surveillance capitalist economic logic. </p>
<p>Readers of Cathy O’Neil’s Weapons of Math Destruction will be compelled to believe the potential dangers of big data. O’Neil, a mathematician, analyses how the use of big data and algorithms in a variety of fields. These include insurance, advertising, education, and policing. They can lead to decisions that harm the poor, reinforce racism, and amplify inequality. Mathematicians and statisticians were for a very long time studying our desires, movements, and spending power. This is the Big Data economy we are living in. </p>
<h2>Trust is Important </h2>
<p>Consumers are more conscious of their data privacy than ever. A recent <a href="https://tealium.com/resource/whitepaper/how-brands-can-prioritize-privacy-in-the-age-of-data/">Tealium study</a> on consumer data privacy found that 97% of consumers surveyed said they are somewhat or very concerned about protecting their data. <a href="https://www.accenture.com/t20171220T024439Z__w__/us-en/_acnmedia/PDF-68/Accenture-Global-Anthem-POV.pdf#zoom=50">Research by Accenture</a>&nbsp;shows that&nbsp;88% of<strong> </strong>consumers say companies that provide personalized experiences without compromising their trust are more appealing and can relate to their needs better than others.</p>
<p>We are focusing on Facebook on this particular blog post to quite a degree since it is the one singular social medium that is growing exponentially. One of the ways in which Facebook garners your data is with you revealing your data and your intentions via the act of publishing status updates and even commenting. You see, the act of commenting fulfills just one touchpoint in the process of these tech giants harvesting of data. Facebook built&nbsp;<a rel="noreferrer noopener" href="https://developers.facebook.com/docs/plugins/comments/" target="_blank">comments plugin</a>&nbsp;to allow users to leave comments on websites, blogs and forums through their Facebook accounts. It was expected to provide high-quality conversations over the internet but instead ended up spamming popular sites.</p>
<p>If you do use the Facebook Comments plugin, remember that your comments are a valuable content asset that shouldn’t be subject to <a href="https://ducttapemarketing.com/how-and-why-i-use-the-facebook-comments-plugin/">Facebook’s Terms of Service</a>, which basically says they can do whatever they want with them. An increasing amount of spam raises questions about how well the policy of malicious content online is going on. There are many misleading and offensive comments, usually attracting and persuading users towards a specific link to click it. These comments are often repetitive and can easily be identified as spam.</p>
<p>According to an estimation by&nbsp;<a href="https://www.similartech.com/technologies/facebook-comments">Similartech</a>&nbsp;more than 360,000 unique domains have installed Facebook Comments plugin. It is still not clear why and how the spam filters of Facebook failed to filter spam comments. <a href="https://www.similartech.com/technologies/facebook-comments">In 2015</a>, one of the security firms, Symantec reported scammers had been trying to affect the comments sections of Facebook to spread malware. </p>
<p>For more than two years now, Facebook has been working on its content-moderation efforts and the spamming in Facebook Comment boxes shows that problematic content still finds its way to escape the loopholes. Moreover, <a href="https://www-dailymail-co-uk.cdn.ampproject.org/v/s/www.dailymail.co.uk/sciencetech/article-2525227/amp/Facebook-tracks-type-DONT-post-update-comment.html?amp_js_v=a6&amp;amp_gsa=1&amp;usqp=mq331AQFKAGwASA%3D#aoh=16034519192504&amp;referrer=https%3A%2F%2Fwww.google.com&amp;amp_tf=From%20%251%24s&amp;ampshare=https%3A%2F%2Fwww.dailymail.co.uk%2Fsciencetech%2Farticle-2525227%2FFacebook-tracks-type-DONT-post-update-comment.html">Facebook can track what </a><a href="https://www-dailymail-co-uk.cdn.ampproject.org/v/s/www.dailymail.co.uk/sciencetech/article-2525227/amp/Facebook-tracks-type-DONT-post-update-comment.html?usqp=mq331AQFKAGwASA%3D&amp;amp_js_v=0.1#aoh=16034519192504&amp;referrer=https%3A%2F%2Fwww.google.com&amp;amp_tf=From%20%251%24s&amp;ampshare=https%3A%2F%2Fwww.dailymail.co.uk%2Fsciencetech%2Farticle-2525227%2FFacebook-tracks-type-DONT-post-update-comment.html">you</a><a href="https://www-dailymail-co-uk.cdn.ampproject.org/v/s/www.dailymail.co.uk/sciencetech/article-2525227/amp/Facebook-tracks-type-DONT-post-update-comment.html?amp_js_v=a6&amp;amp_gsa=1&amp;usqp=mq331AQFKAGwASA%3D#aoh=16034519192504&amp;referrer=https%3A%2F%2Fwww.google.com&amp;amp_tf=From%20%251%24s&amp;ampshare=https%3A%2F%2Fwww.dailymail.co.uk%2Fsciencetech%2Farticle-2525227%2FFacebook-tracks-type-DONT-post-update-comment.html"> type</a>, even if you never post it.&nbsp;Data scientists can determine that a status or comment has been typed by tracking code in the HTML form element of each page.</p>
<h2>Read The Terms and Conditions</h2>
<p>We live in a world where the concept of privacy already seems outdated. But that is largely because we’ve decided not to inquire about what happens when we trade it for convenience. The more connected you, and billions of others, are to Facebook, the more money Facebook makes by selling your personal information, and the more powerful it becomes.</p>
<p>The terms of service state,&nbsp;<em>We use the data we have — for example, about the connections you make, the choices and settings you select, and what you share and do on and off our Products — to personalize your experience.</em></p>
<figure><img loading="lazy" width="746" height="634" src="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/DcrJMbSW0AAxJXC.jpg" alt="" srcset="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/DcrJMbSW0AAxJXC.jpg 746w, https://talk.hyvor.com/blog/wp-content/uploads/2020/10/DcrJMbSW0AAxJXC-300x255.jpg 300w" sizes="(max-width: 746px) 100vw, 746px" data-srcset="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/DcrJMbSW0AAxJXC.jpg 746w, https://talk.hyvor.com/blog/wp-content/uploads/2020/10/DcrJMbSW0AAxJXC-300x255.jpg 300w" data-src="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/DcrJMbSW0AAxJXC.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption><a href="https://qz.com/1266835/facebooks-terms-of-service-translated-so-you-understand-your-data-and-privacy-settings/">Be wary of nebulous terms and promises</a></figcaption></figure>
<p>Basically, this means that Facebook uses every bit of personal information it can, collected&nbsp;<a href="https://www.consumerreports.org/privacy/how-facebook-tracks-you-even-when-youre-not-on-facebook/">both on and off Facebook</a>, to entice advertisers. The better the company knows you through the personal information you share with your friends and family, the more likely they are to be able to sell you stuff you want.</p>
<h2>Choose The Right to Privacy</h2>
<p>Big data is big business and value is created from customer insight. But, where is the moral line? What happens when companies cross that line? What if consumers could flip the equation to offer their data directly to the companies they trust? The future could be customer-monetized data.</p>
<p>We are the authors of our own destruction here since we don’t choose to be aware. If you participate in Facebook, should you not have some semblance of an expectation of privacy. The former Federal Trade Commission Chairperson Jon Leibowitz publicly stated, “We all agree that consumers don’t read privacy policies.”</p>
<p><a href="https://talk.hyvor.com/docs/gdpr">Ensure you choose privacy</a> and are aware of how technology plans on using your data. The only solution is being non-participatory. The solution is choosing not to be part of a pernicious agenda that can be defined as Surveillance Capitalism. </p>
<div><div><div><h4>
Need a privacy-focused commenting platform for your website?
</h4>

</div></div></div> </div></div>]]>
            </description>
            <link>https://talk.hyvor.com/blog/privacy-and-big-data/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033030</guid>
            <pubDate>Mon, 09 Nov 2020 09:37:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This is how I Git]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25032951">thread link</a>) | @stargrave
<br/>
November 9, 2020 | https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Every now and then I get questions on how to work with git in a smooth way when developing, bug-fixing or extending curl – or how I do it. After all, I <a href="https://daniel.haxx.se/blog/2020/10/26/working-open-source/" data-type="post" data-id="14901">work on open source full time</a> which means I have very frequent interactions with git (and GitHub). Simply put, I work with git all day long. Ordinary days, I issue git commands several hundred times.</p>



<p>I have a very simple approach and way of working with git in curl. This is how it works.</p>



<h2>command line</h2>



<p>I use git almost exclusively from the command line in a terminal. To help me see which branch I’m working in, I have this little bash helper script.</p>



<pre>brname () {
  a=$(<code>git rev-parse --abbrev-ref HEAD 2&gt;/dev/null</code>)
  if [ -n "$a" ]; then
    echo " [$a]"
  else
    echo ""
  fi
}
PS1="\u@\h:\w\$(brname)$ "</pre>



<p>That gives me a prompt that shows username, host name, the current working directory and the current checked out git branch.</p>



<p>In addition: I use Debian’s <a href="https://salsa.debian.org/debian/bash-completion/-/blob/master/README.md">bash command line completion</a> for git which is also really handy. It allows me to use tab to complete things like git commands and branch names. </p>



<h2>git config</h2>



<p>I of course also have my customized <code>~/.gitconfig</code> file to provide me with some convenient aliases and settings. My most commonly used git aliases are:</p>


<pre title="">st = status --short -uno
ci = commit
ca = commit --amend
caa = commit -a --amend
br = branch
co = checkout
df = diff
lg = log -p --pretty=fuller --abbrev-commit
lgg = log --pretty=fuller --abbrev-commit --stat
up = pull --rebase
latest = log @^{/RELEASE-NOTES:.synced}..
</pre>


<p>The ‘latest’ one is for listing all changes done to curl since the most recent RELEASE-NOTES “sync”. The others should hopefully be rather self-explanatory.</p>



<p>The config also sets <code>gpgsign = true</code>, enables mailmap and a few other things.</p>



<h2>master is clean and working</h2>



<p>The main curl development is done in the single <a href="https://github.com/curl/curl">curl/curl</a> git repository (primarily hosted on GitHub). We keep the master branch the bleeding edge development tree and we work hard to always keep that working and functional. We do our releases off the master branch when that day comes (every eight weeks) and we provide “<a href="https://curl.haxx.se/snapshots/">daily snapshots</a>” from that branch, put together – yeah – daily.</p>



<p>When merging fixes and features into master, we avoid merge commits and use rebases and fast-forward as much as possible. This makes the branch very easy to browse, understand and work with – as it is 100% linear.</p>



<h2>Work on a fix or feature</h2>



<p>When I start something new, like work on a bug or trying out someone’s patch or similar, I first create a local branch off master and work in that. That is, I don’t work directly in the master branch. Branches are easy and quick to do and there’s no reason to shy away from having loads of them!</p>



<p>I typically name the branch prefixed with my GitHub user name, so that when I push them to the server it is noticeable who is the creator (and I can use the same branch name locally as I do remotely).</p>



<pre>$ git checkout -b bagder/my-new-stuff-or-bugfix</pre>



<p>Once I’ve reached somewhere, I commit to the branch. It can then end up one or more commits before I consider myself “done for now” with what I was set out to do.</p>



<p>I try not to leave the tree with any uncommitted changes – like if I take off for the day or even just leave for food or an extended break. This puts the repository in a state that allows me to easily switch over to another branch  when I get back – should I feel the need to. Plus, it’s better to commit and explain the change <em>before</em> the break rather than having to recall the details again when coming back.</p>



<h2>Never stash</h2>



<p>“git stash” is therefore not a command I ever use. I rather create a new branch and commit the (temporary?) work in there as a potential new line of work.</p>



<h2>Show it off and get reviews</h2>



<p>Yes I am the lead developer of the project but I still maintain the same work flow as everyone else. All changes, except the most minuscule ones, are done as pull requests on GitHub.</p>



<p>When I’m happy with the functionality in my local branch. When the bug seems to be fixed or the feature seems to be doing what it’s supposed to do and the test suite runs fine locally.</p>



<p>I then clean up the commit series with “<code>git rebase -i</code>” (or if it is a single commit I can instead use just “<code>git commit --amend</code>“).</p>



<p>The commit series should be a set of logical changes that are related to this change and not any more than necessary, but kept separate if they are separate. Each commit also gets its own proper commit message. Unrelated changes should be split out into its own separate branch and subsequent separate pull request.</p>



<pre>git push origin bagder/my-new-stuff-or-bugfix</pre>



<h2>Make the push a pull request</h2>



<p>On GitHub, I then make the newly pushed branch into a <a href="https://github.com/curl/curl/pulls">pull request</a> (aka “a PR”). It will then become visible in the list of pull requests on the site for the curl source repository, it will be announced in the #curl IRC channel and everyone who follows the repository on GitHub will be notified accordingly.</p>



<p>Perhaps most importantly, a pull request kicks of a flood of CI jobs that will build and test the code in numerous different combinations and on several platforms, and the results of those tests will trickle in over the coming hours. When I write this, we have around 90 different CI jobs – per pull request – and something like 8 different code analyzers will scrutinize the change to see if there’s any obvious flaws in there.</p>



<figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-05-curl-Project-status-dashboard.png"><img loading="lazy" width="2686" height="1510" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-05-curl-Project-status-dashboard.png" alt=""></a><figcaption>CI jobs per platform over time. Graph snapped on November 5, 2020</figcaption></figure>



<h2>A branch in the actual curl/curl repo</h2>



<p>Most contributors who would work on curl would not do like me and make the branch in the curl repository itself, but would rather do them in their own forked version instead. The difference isn’t that big and I <em>could</em> of course also do it that way.</p>



<h2>After push, switch branch</h2>



<p>As it will take some time to get the full CI results from the PR to come in (generally a few hours), I switch over to the next branch with work on my agenda. On a normal work-day I can easily move over ten different branches, polish them and submit updates in their respective pull-requests.</p>



<p>I can go back to the&nbsp;master branch again with ‘<code>git checkout master</code>‘ and there I can “<code>git pull</code>” to get everything from upstream – like when my fellow developers have pushed stuff in the mean time.</p>



<h2>PR comments or CI alerts</h2>



<p>If a reviewer or a CI job find a mistake in one of my PRs, that becomes visible on GitHub and I get to work to handle it. To either fix the bug or discuss with the reviewer what the better approach might be.</p>



<p>Unfortunately, flaky CI jobs is a part of life so very often there ends up one or two red markers in the list of CI jobs that can be ignored as the test failures in them are there due to problems in the setup and not because of actual mistakes in the PR…</p>



<p>To get back to my branch for that PR again, I “<code>git checkout bagder/my-new-stuff-or-bugfix</code>“, and fix the issues.</p>



<p>I normally start out by doing follow-up commits that repair the immediate mistake and push them on the branch:</p>



<pre>git push origin <code>bagder/my-new-stuff-or-bugfix</code></pre>



<p>If the number of fixup commits gets large, or if the follow-up fixes aren’t small, I usually end up doing a squash to reduce the number of commits into a smaller, simpler set, and then force-push them to the branch.</p>



<p>The reason for that is to make the patch series easy to review, read and understand. When a commit series has too many commits that changes the previous commits, it becomes hard to review.</p>



<h2>Ripe to merge?</h2>



<p>When the pull request is ripe for merging (independently of who authored it), I switch over to the master branch again and I merge the pull request’s commits into it. In special cases I cherry-pick specific commits from the branch instead. When all the stuff has been yanked into master properly that should be there, I push the changes to the remote.</p>



<p>Usually, and especially if the pull request wasn’t done by me, I also go over the commit messages and polish them somewhat before I push everything. Commit messages should follow our style and mention not only which PR that it closes but also which issue it fixes and properly give credit to the bug reporter and all the helpers – using the right syntax so that our automatic tools can pick them up correctly!</p>



<p>As already mentioned above, I merge fast-forward or rebased into master. No merge commits.</p>



<h2>Never merge with GitHub!</h2>



<p>There’s a button GitHub that says “rebase and merge” that could theoretically be used for merging pull requests. I <em>never</em> use that (and if I could, I’d disable/hide it). The reasons are simply:</p>



<ol><li>I don’t feel that I have the proper control of the commit message(s)</li><li>I can’t select to squash a subset of the commits, only all or nothing</li><li>I often want to cleanup the author parts too before push, which the UI doesn’t allow</li></ol>



<p>The downside with not using the merge button is that the message in the  PR says “closed by [hash]” instead of “merged in…” which causes confusion to a fair amount of users who don’t realize it means that it actually means the same thing! I consider this is a (long-standing) GitHub UX flaw.</p>



<h2>Post merge</h2>



<p>If the branch has nothing to be kept around more, I delete the local branch again with “<code>git branch -d [name]</code>” and I remove it remotely too since it was completely merged there’s no reason to keep the work version left.</p>



<p>At any given point in time, I have some 20-30 different local branches alive using this approach so things I work on over time all live in their own branches and also submissions from various people that haven’t been merged into master yet exist in branches of various maturity levels. Out of those local branches, the number of concurrent pull requests I have in progress can be somewhere between just a few up to ten, twelve something.</p>



<h2>RELEASE-NOTES</h2>



<p>Not strictly related, but in order to keep interested people informed about what’s happening in the tree, we sync the <a href="https://github.com/curl/curl/blob/master/RELEASE-NOTES">RELEASE-NOTES</a> file every once in a while. Maybe every 5-7 days or so. It …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/">https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/</a></em></p>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25032951</guid>
            <pubDate>Mon, 09 Nov 2020 09:23:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Productivity vs. Privacy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25032481">thread link</a>) | @jessems
<br/>
November 9, 2020 | https://jessems.com/productivity-vs-privacy | <a href="https://web.archive.org/web/*/https://jessems.com/productivity-vs-privacy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>In recent years there's been a steady growth in privacy focused companies. Some examples that have reached large-scale adoption are <a href="https://protonmail.com/">ProtonMail</a>, <a href="https://signal.com/">Signal</a>, and <a href="https://duckduckgo.com/">DuckDuckGo</a>. These are companies that have put privacy front and center to their value proposition and can be considered <em>privacy-preserving products</em>.</p><p>What these services have in common is that they promise their users a higher degree of privacy relative to their competitors. Instead of the usual encryption in transit (protection from eavesdroppers) and encryption at rest (protection against unauthorized users), services like Signal and ProtonMail enable their users to hide data from anyone except the intended recipient, which — crucially — includes the service providers themselves.</p><p>This category of encryption is known as end-to-end encryption (e2e) and has been vital for anyone whose safety depends on the privacy of their communication (e.g. human rights activists and journalists).</p><p>The canonical implementation of e2e for email is known as Pretty Good Privacy (PGP) and its reference implementation is GPG. GPG never reached mass adoption and there seems to be a myriad of reasons for that. The most overarching reason, however, seems to be that it continues to be difficult to use. As the founder of Signal, Moxie Marlinspike <a href="https://moxie.org/2015/02/24/gpg-and-me.html">explains</a>, the spirit behind GPG had been the following:</p><blockquote><p>Instead of developing opinionated software with a simple interface, GPG was written to be as powerful and flexible as possible.</p></blockquote><p>Powerful, flexible software written by nerds, unfortunately also tends to be prohibitively complex for normal users. Combined with the fact that <a href="https://signal.org/blog/the-ecosystem-is-moving/">decentralized technology seems unable to quickly adapt to change</a>, the result has been a clunky solution that has, quite frankly, stayed clunky. With no feasible privacy-preserving alternative <!-- -->[1]<!-- -->, non-privacy preserving email providers became the norm.</p><p>One such email provider, Gmail by Google, started off by scanning your emails to serve you personalized ads. Although they've stopped personalizing ads based on your emails, they're using email content to serve you a better experience across their services. Similarly, Facebook tracks what you do so as to shape your experience and keep you glued to their platform.</p><p>What unites these platforms, is described by Professor Shoshana Zuboff as “<a href="https://en.wikipedia.org/wiki/Surveillance_capitalism">surveillance capitalism</a>”. The business model of surveillance capitalist companies is to harvest personal data about you to build a model that predicts your behavior. These prediction models are packaged and sold as advertisement opportunities to companies eager to buy your attention. The incentive of surveillance capitalists is to harvest your data so they can keep you on the platform and get you to interact with ads. You might be the user, but you're not the customer.</p><p>It should come as no surprise then, that none of these platforms has shipped with end-to-end encryption by default. Doing so would go against the incentives that undergird their very business model. Their ability to predict your behavior, and sell ads based on those predictions, hinges on their ability to harvest your data.</p><p>Selling your data as a predictive model is not the only incentive that exists for collecting your data. Usage data also helps inform product improvements. These improvements typically make the experience even more compelling <!-- -->[2]<!-- -->.</p><p>A company like Google has other business models of course. Google Workspace, aimed at businesses, is a collection of collaboration and productivity tools. This ranges from Google Docs, to chat, to video conferencing, and more. By making this a paid service, Google introduces a different incentive for itself. The customer and the user are now one and the same.</p><p>Even in the case of the user being the customer, user data is still being harvested. This data might not feed into personalized ads (because that’s no longer the primary business model) but it might feed into making the experience better. But what does “better” mean in the business environment?</p><p>Better is often equated with being more productive and in economics productivity is thought of as the ratio between outputs (e.g. GDP for a country, or unit outputs for a business) and its inputs (hours worked). It's a blunt, but useful tool for thinking about how much is produced per hour of work invested.</p><p>We can think about the productivity of a business by considering a company’s profits and its salaries as outputs and the hours worked by its employees as the inputs. Using these quantities we can arrive at a measure that captures a business’ productivity. We would expect both national productivity and business productivity to increase with advances in technology.</p><p>How does technology lead to increases in productivity? One obvious way is by making us more efficient. If some new technology saves us time doing a certain task, all other things being equal, we’ll end up seeing those gains in our outputs (corporate profits and salaries).</p><p>What exactly are the things that increase efficiency for the tasks that we do? In many ways, in the realm of knowledge work, we don't always know before the gains are made. We are still discovering ways in which we can be more productive and especially so in the ways in which collaboration can be improved. A illustrative example of how productivity gains are discovered comes from Kevin A. Kwok's description of Figma's road to success.</p><p>In "Why Figma Wins", <a href="https://kwokchain.com/2020/06/19/why-figma-wins/">Kwok details</a> how the product team discovered a way to enable more efficient collaboration in the design process. That this was possible wasn't obvious to even those within the scene. While Sketch had broken new ground with their vector based design tool geared towards product designers, Figma took it to another level by taking many of the same (dare I say revolutionary) UX patterns and offering them in a web-native, multiplayer web application.</p><blockquote><p>The core insight of Figma is that design is larger than just designers. Design is all of the conversations between designers and PMs about what to build. It is the mocks and prototypes and the feedback on them. It is the handoff of specs and assets to engineers and how easy it is for them to implement them.</p></blockquote><p>As Kevin explains, Figma brought together the disparate disciplines that are involved in a design process into a synced browser window for everybody. This helped democratize design and remove a lot of friction that had existed before.</p><p>Not only did Figma push the frontier of productivity into new territory, it wasn’t obvious beforehand what that territory would look like. The lesson is that productivity improvements are won through a process of <em>discovery</em>. Kevin explains:</p><blockquote><p>As disciplines evolve, they figure out the social norms needed to operate better, build tools that can be shared across the industry, and invent abstractions that allow offloading more and more of the workload. They learn how to collaborate better, not just with each other but with all the other functions as well.</p></blockquote><p>What <em>is</em> obvious are the relentless improvements that continue to be made in the direction of increased productivity and that the big tech platforms aren’t shying away from investing heavily in innovation (discovery) in that direction.</p><p>One strategy that software companies — especially ones with a lot of resources - are bringing to bear on the challenge of unlocking greater productivity is the harvesting of user data. They  turn the data into insights which informs and enables new features as well as improves existing features.</p><p>The seeking of productivity gains through the harvesting of user data is a path not available to privacy-preserving products. The user data isn't readable to them — and that's the whole point.</p><p>This creates a trade-off from the user's perspective. Whatever your particular motivation might be, as soon as you opt for a privacy-preserving service you're opting for a service that is not able to read your data, and by extension, not able to harvest it. Because the harvesting of data is what is driving many of the improvements in productivity, in choosing to preserve user privacy, these services are forgoing their ability to provide additional gains in productivity.</p><p>Historically, as we saw with the origins of GPG, there has always been additional friction involved in replicating a workflow in a privacy-preserving manner. Although using e2e services such as Signal and ProtonMail has become nearly frictionless, they lack many features their non-privacy preserving counterparts offer.</p><p>If you compare the productivity gains between privacy-preserving and non-preserving products from the perspective of the user, it's hard not to arrive at the conclusion that there’s a gap between the two — and it appears to be growing.</p><p>There is perhaps no better example of a feature which hinges on the ability to read user data than search. Although ProtonMail is reminiscent of Gmail in many ways, one area where it falls short is the absence of any ability to  search the contents of your emails. Search only works if the provider of such functionality can scan and index your content. It works even better if the provider is able to harvest search queries and use those to build predictive models (e.g. autocomplete and smart suggestions). These are features which make Gmail users more productive but aren't available to ProtonMail users <!-- -->[3]<!-- -->.</p><p>The absence of search might not be a dealbreaker for a journalist wanting only to communicate securely with a source. But it is just one example of an ever growing list of productivity improvements that are happening on the side of non-privacy preserving products which cannot be mirrored on the side of the privacy preserving ones.</p><p>Some UX patterns which enable higher degrees of productivity, once discovered by non-privacy preserving products, can be copied relatively easily by their privacy-preserving counterparts. ProtonMail's UX is reminiscent of Gmail, Signal's UX is reminiscent of WhatsApp, DuckDuckGo's UX is reminiscent of Google.</p><p>But there are other features and patterns that, …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jessems.com/productivity-vs-privacy">https://jessems.com/productivity-vs-privacy</a></em></p>]]>
            </description>
            <link>https://jessems.com/productivity-vs-privacy</link>
            <guid isPermaLink="false">hacker-news-small-sites-25032481</guid>
            <pubDate>Mon, 09 Nov 2020 08:13:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Structured Concurrency]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25032133">thread link</a>) | @ingve
<br/>
November 8, 2020 | https://ericniebler.com/2020/11/08/structured-concurrency/ | <a href="https://web.archive.org/web/*/https://ericniebler.com/2020/11/08/structured-concurrency/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>TL;DR: <strong>“Structured concurrency” refers to a way to structure async computations so that child operations are guaranteed to complete before their parents, just the way a function is guaranteed to complete before its caller.</strong> This sounds simple and boring, but in C++ it’s anything but. Structured concurrency — most notably, C++20 coroutines — has profound implications for the correctness and the simplicity of async architecture. It brings the <a href="https://docs.microsoft.com/en-us/cpp/cpp/welcome-back-to-cpp-modern-cpp?view=msvc-160">Modern C++ style</a> to our async programs by making async lifetimes correspond to ordinary C++ lexical scopes, eliminating the need for reference counting to manage object lifetime.</p>
<h2>Structured Programming and C++</h2>
<p>Back in the 1950’s, the nascent computing industry discovered structured programming: that high-level programming languages with lexical scopes, control structures, and subroutines resulted in programs that were far easier to read, write, and maintain than programming at the assembly level with test-and-jump instructions and <code>goto</code>. The advance was such a quantum leap that nobody talks about structured programming anymore; it’s just “programming”.</p>
<p>C++, more so than any other language, leverages structured programming to the hilt. The semantics of object lifetime mirror — and are tied to — the strict nesting of scopes; i.e., the <em>structure</em> of your code. Function activations nest, scopes nest, and object lifetimes nest. Objects’ lifetimes end with a scope’s closing curly brace, and objects are destroyed in the reverse order of their construction to preserve the strict nesting.</p>
<p>The Modern C++ programming style is built on this structured foundation. Objects have <em>value semantics</em> — they behave like the ints — and resources are cleaned up in destructors deterministically, which guarantees structurally that resources aren’t used after their lifetimes have ended. This is <em>very</em> important.</p>
<p>When we abandon this strict nesting of scopes and lifetimes — say, when we reference count an object on the heap, or when we use the singleton pattern — we are fighting against the strengths of the language rather than working with them.</p>
<h2>The Trouble With Threads</h2>
<p>Writing correct programs in the presence of concurrency is far more difficult than in single-threaded code. There are lots of reasons for this. One reason is that threads, like singletons and dynamically allocated objects, scoff at your puny nested scopes. Although you can use the Modern C++ style <em>within</em> a thread, when logic and lifetimes are scattered across threads, the hierarchical structure of your program is lost. The tools we use to manage complexity in single-threaded code — in particular, nested lifetimes tied to nested scopes — simply don’t translate to async code.</p>
<p>To see what I mean, let’s look at what happens when we take a simple synchronous function and make it asynchronous.</p>
<pre>void computeResult(State &amp; s);

int doThing() {
  State s;
  computeResult(s);
  return s.result;
}
</pre>
<p><code>doThing()</code> is simple enough. It declares some local state, calls a helper, then returns some result. Now imagine that we want to make both functions async, maybe because they take too long. No problem, let’s use Boost futures, which support continuation chaining:</p>
<pre>boost::future&lt;void&gt; computeResult(State &amp; s);

boost::future&lt;int&gt; doThing() {
  State s;
  auto fut = computeResult(s);
  return fut.then(
    [&amp;](auto&amp;&amp;) { return s.result; }); // OOPS
}
</pre>
<p>If you’ve programmed with futures before, you’re probably screaming, <em>“Nooooo!”</em> The <code>.then()</code> on the last line queues up some work to run after <code>computeResult()</code> completes. <code>doThing()</code> then returns the resulting future. The trouble is, when <code>doThing()</code> returns, the lifetime of the <code>State</code> object ends, <em>and the continuation is still referencing it</em>. That is now a dangling reference, and will likely cause a crash.</p>
<p>What has gone wrong? Futures let us compute with results that aren’t available yet, and the Boost flavor lets us chain continuations. But the continuation is a separate function with a separate scope. We often need to share data across those separate scopes. No more tidy nested scopes, no more nested lifetimes. We have to manage the lifetime of the state manually, something like this:</p>
<pre>boost::future&lt;void&gt;
computeResult(shared_ptr&lt;State&gt; s); // addref
                                    // the state

boost::future&lt;int&gt; doThing() {
  auto s = std::make_shared&lt;State&gt;();
  auto fut = computeResult(s);
  return fut.then(
    [s](auto&amp;&amp;) { return s.result; }); // addref
                                       // the state
}
</pre>
<p>Since both async operations refer to the state, they both need to share responsibility to keep it alive.</p>
<p>Another way to think about this is: <em>what is the lifetime of this asynchronous computation?</em> It starts when <code>doThing()</code> is called, but it doesn’t end until the continuation — the lambda passed to <code>future.then()</code> — returns. <em>There is no lexical scope that corresponds to that lifetime.</em> And that is the source of our woes.</p>
<h2>Unstructured Concurrency</h2>
<p>The story gets more complicated yet when we consider executors. Executors are handles to executions contexts that let you schedule work onto, say, a thread or thread pool. Many codebases have some notion of an executor, and some let you schedule things with a delay or with some other policy. This lets us do cool things, like move a computation from an IO thread pool to a CPU thread pool, or retry an async operation with a delay. Handy, but like <code>goto</code> it is a very low-level control structure that tends to obfuscate rather than clarify.</p>
<p>For instance, I recently came across an algorithm that uses executors and callbacks (called Listeners here) that retries the async allocation of some resource. Below is a greatly abridged version. It is described after the break.</p>
<pre>// This is a continuation that gets invoked when
// the async operation completes:
struct Manager::Listener : ListenerInterface {
  shared_ptr&lt;Manager&gt; manager_;
  executor executor_;
  size_t retriesCount_;

  void onSucceeded() override {
    /* ...yay, allocation succeeded... */
  }
  void onFailed() override {
    // When the allocation fails, post a retry
    // to the executor with a delay
    auto alloc = [manager = manager_]() {
      manager-&gt;allocate();
    };
    // Run "alloc" at some point in the future:
    executor_.execute_after(
      alloc, 10ms * (1 &lt;&lt; retriesCount_));
  }
};

// Try asynchronously allocating some resource
// with the above class as a continuation
void Manager::allocate() {
  // Have we already tried too many times?
  if (retriesCount_ &gt; kMaxRetries) {
    /* ...notify any observers that we failed */
    return;
  }

  // Try once more:
  ++retriesCount_;
  allocator_.doAllocate(
    make_shared&lt;Listener&gt;(
      shared_from_this(),
      executor_,
      retriesCount_));
}
</pre>
<p>The <code>allocate()</code> member function first checks to see if the operation has already been retried too many times. If not it calls a helper <code>doAllocate()</code> function, passing in a callback to be notified on either success or failure. On failure, the handler posts deferred work to the executor, which will call <code>allocate()</code> back, thus retrying the allocation with a delay.</p>
<p>This is a heavily stateful and rather circuitous async algorithm. The logic spans many functions and several objects, and the control and data flow is not obvious. Note the intricate ref-counting dance necessary to keep the objects alive. Posting the work to an executor makes it even harder. Executors in this code have no notion of continuations, so errors that happen during task execution have nowhere to go. The <code>allocate()</code> function can’t signal an error by throwing an exception if it wants any part of the program to be able to recover from the error. Error handling must be done manually and out-of-band. Ditto if we wanted to support cancellation.</p>
<p>This is <strong>unstructured concurrency</strong>: we queue up async operations in an <em>ad hoc</em> fashion; we chain dependent work, use continuations or “strand” executors to enforce sequential consistency; and we use strong and weak reference counts to keep data alive until we are certain it’s no longer needed. There is no formal notion of task A being a child of task B, no way to enforce that child tasks complete before their parents, and no one place in the code that we can point to and say, “Here is the algorithm.”</p>
<blockquote>
<p><strong>If you don’t mind the analogy, the hops through the executor are a bit like <code>goto</code> statements that are non-local in both time and space: “Jump to this point in the program, <em>X</em> milliseconds from now, on this particular thread.”</strong></p>
</blockquote>
<p>That non-local discontinuity makes it hard to reason about correctness and efficiency. Scale unstructured concurrency up to whole programs handling lots of concurrent real-time events, and the incidental complexity of manually handling out-of-band asynchronous control and data flow, controlling concurrent access to shared state, and managing object lifetime becomes overwhelming.</p>
<h2>Structured Concurrency</h2>
<p>Recall that in the early days of computing, unstructured programming styles rapidly gave way to structured styles. With the addition of coroutines to C++, we are seeing a similar phase shift happening today to our asynchronous code. If we were to rewrite the above retry algorithm in terms of coroutines (using Lewis Baker’s popular <a href="https://github.com/lewissbaker/cppcoro">cppcoro</a> library), it might look something like this:</p>
<pre>// Try asynchronously allocating some resource
// with retry:
cppcoro::task&lt;&gt; Manager::allocate() {
  // Retry the allocation up to kMaxRetries
  // times:
  for (int retriesCount = 1;
       retriesCount &lt;= kMaxRetries;
       ++retriesCount) {
    try {
      co_await allocator_.doAllocate();
      co_return; // success!
    } catch (...) {}

    // Oops, it failed. Yield the thread for a
    // bit and then retry:
    co_await scheduler_.schedule_after(
      10ms * (1 &lt;&lt; retriesCount));
  }

  // Error, too many retries
  throw std::runtime_error(
    "Resource allocation retry count exceeded.");
}
</pre>
<blockquote>
<p>Aside: This replaces the <code>executor_</code> with a <code>scheduler_</code> that implements cppcoro’s <a href="https://github.com/lewissbaker/cppcoro#delayedscheduler-concept">DelayedScheduler</a> concept.</p>
</blockquote>
<p>Let’s …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ericniebler.com/2020/11/08/structured-concurrency/">https://ericniebler.com/2020/11/08/structured-concurrency/</a></em></p>]]>
            </description>
            <link>https://ericniebler.com/2020/11/08/structured-concurrency/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25032133</guid>
            <pubDate>Mon, 09 Nov 2020 07:15:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I'm going to experiment by being Blind and Alone for 24 Hours]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 42 (<a href="https://news.ycombinator.com/item?id=25031774">thread link</a>) | @Osiris30
<br/>
November 8, 2020 | https://dormin.org/2020/11/08/the-blind-alone-and-confused-for-24-hours-challenge/ | <a href="https://web.archive.org/web/*/https://dormin.org/2020/11/08/the-blind-alone-and-confused-for-24-hours-challenge/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-896">

	
	<!-- .entry-header -->


			<div>

			
<figure><img data-attachment-id="901" data-permalink="https://dormin.org/bird-box/" data-orig-file="https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg" data-orig-size="2000,1050" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="bird-box" data-image-description="" data-medium-file="https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=300" data-large-file="https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=760" src="https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=1024" alt="" srcset="https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=1024 1024w, https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=150 150w, https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=300 300w, https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=768 768w, https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>For 24 hours I will be blind and alone in my apartment. I eventually want to try being blind for a week, but I’ll need seven days with no other obligations, and I won’t have that for a while. For now, I’ll suffice with a smaller-scale experiments with a few extra provisions for added difficulty.</p>







<ol type="1"><li>I must leave my blindfold on for 24 hours.<ul><li>If I remove the blindfold, I have failed the experiment</li><li>If the blindfold falls off or I can get partial sight, I have failed the experiment.</li><li>I am only allowed to readjust my blindfold if I can see light.</li></ul></li><li>I must not be in contact with any other people for 24 hours.<ul><li>I cannot answer my phone or any other messaging system.</li><li>I cannot receive in-person visitors.</li><li>If someone knocks at the door, I cannot answer verbally or physically.</li></ul></li><li>I will set an alarm for 24 hours. I cannot set any other alarms or use any other means to ascertain the time.<ul><li>It is up to me to keep my phone charged so the alarm goes off.</li></ul></li><li>I cannot leave my apartment.</li></ol>











<p>I have no good reason. I just want to see if I am capable of doing it and what will happen. Some things I’m curious about:</p>



<ul><li>Do I have the willpower to get through the experiment?</li><li>Will I become disoriented from losing all sense of time?</li><li>Will I be able to stave off boredom with podcasts, audiobooks, and music on my phone?</li><li>Will I enter some sort of meditative state due to a lack of sensory input?</li><li><a href="https://www.discovermagazine.com/the-sciences/scientists-made-people-wear-blindfolds-for-4-days-the-resulting-hallucinations-were-incredible">Will I hallucinate</a>?</li><li>Will my non-sight senses heighten?</li><li>Will I hurt myself by falling or banging into something?</li><li>Will I sleep?</li><li>Will I eat? Is consuming caffeine a good idea (for entertainment) or a bad idea (energy with no direction)?</li><li>Will this experience make me more interested in being blind for a week? Or less?</li></ul>



<figure><img src="https://digitalimpact.io/wp-content/uploads/2014/08/Blind.png" alt="Modern CEOs Are Blindfolded - Digital Impact"></figure>







<p>Attempt One started at 10:30 AM and failed at 1:13 PM. I purposefully took off my blindfold because I was worried that my multiple failures to input my Iphone’s password had resulted in a permanent lock or data wipe. But the password screen was just locked for a minute and all was well.</p>



<p>Given that I failed in the early afternoon, I considered restarting the experiment on another day in the morning. But I had already carved out a 24 hour period when I wouldn’t do any work or be disturbed, and it might have been a week or two longer before I got that opportunity again.</p>



<p>So I checked my messages, briefly went on Reddit, and then restarted.</p>



<div><figure><img data-attachment-id="903" data-permalink="https://dormin.org/t86752/" data-orig-file="https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg" data-orig-size="521,610" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;CSA Images \/ CSA Images&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Blindfolded Woman&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;\u00a9 CSA Images \/ CSA Images&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;T86752&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="T86752" data-image-description="" data-medium-file="https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg?w=256" data-large-file="https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg?w=521" src="https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg?w=521" alt="" srcset="https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg 521w, https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg?w=128 128w, https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg?w=256 256w" sizes="(max-width: 521px) 100vw, 521px"></figure></div>







<p>Attempt Two was successful. I put on my blindfold at 1:23 PM on Thursday, November 5, 2020. I removed it at 1:28 PM on Friday, November 6.</p>



<p>It was an… interesting experience. I don’t recommend it, but I’m glad I did it. I’m not sure where to begin in describing it, especially since I couldn’t take notes, and part of the challenge was being confused. But I’ll do my best to break down the experience.</p>



<div><figure><img src="https://cdn.shopify.com/s/files/1/0818/3417/products/Les_Sublimes_Cashmere_Scarf_Dark_Blue_packshot_2048x.jpg?v=1539973736" alt="Large Cashmere Scarf in Dark Blue | Les Sublimes" width="427" height="427"></figure></div>



<h2><strong><span>Blindfold</span></strong></h2>



<p>To simulate blindness, I used a dark blue scarf as a blindfold. One layer wasn’t quite dark enough, so I folded it in half for extra light defense.</p>



<p>With the blindfold securely on, my vision was the same whether my eyes were open or closed. I kept my eyes closed 99.9% of the time since it was usually more comfortable and helped limit light. I occasionally opened my eyes to check the brightness level and to… I guess you could call it <em>stretch my eyelids.</em> They don’t feel good if you leave them closed for too long.</p>



<p>I couldn’t get a perfect scarf seal around my eyes, so sometimes when I tilted my head back while sitting I noticed a little light come into the bottom of my vision. To limit this, I often pinched the scarf around my nose in that position. But many/most blind people can see some light anyway, so I don’t think this was a significant violation of the experiment.</p>



<p>My eyes got quite dry under the scarf, so I applied moisturizer to this lids and sockets four or five times. I wanted to use eyedrops too, but there was no way to do so without failing the experiment.</p>



<figure><img loading="lazy" data-attachment-id="906" data-permalink="https://dormin.org/image/" data-orig-file="https://dorminorg.files.wordpress.com/2020/11/image.jpeg" data-orig-size="225,225" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-medium-file="https://dorminorg.files.wordpress.com/2020/11/image.jpeg?w=225" data-large-file="https://dorminorg.files.wordpress.com/2020/11/image.jpeg?w=225" src="https://dorminorg.files.wordpress.com/2020/11/image.jpeg?w=225" alt="BLACK N BLACK - #blackouttuesday ✊🏻✊🏼✊🏽✊🏾✊🏿 | Facebook" width="786" height="786" srcset="https://dorminorg.files.wordpress.com/2020/11/image.jpeg 225w, https://dorminorg.files.wordpress.com/2020/11/image.jpeg?w=150 150w" sizes="(max-width: 786px) 100vw, 786px"></figure>



<h2><strong><span>Blindness</span></strong></h2>



<p>Initially, everything was black, but as the day went on and the sun went down, I could tell it was nighttime even through two layers of scarf and my eyelids. I’m not sure if I could tell because my eyes had adjusted to become extremely sensitive to light, or if there were other subtle signals (ie. noises, air temperature, circadian rhythms, etc.) which my body picked up on. As evidence of the latter, I could not see any difference between the tv being on or off, nor the refrigerator being opened or closed, even when I was sitting right in front of either.</p>



<p>What I saw depended on how I applied my focus. If I did focus on my vision, I’d see the typical blackness you get from closing your eyes, but it was never perfectly black nor uniform; there was always some odd movement and occasional coloring (whiteness, pale blue, or sometimes red). The most common distortions were a swirling or flowing whiteness, sort of like cream in coffee. I hoped that being blindfolded for so long would make the distortions more extreme, but for the most part it looked no different than what you’d see if you closed your eyes right now for ten minutes.</p>



<p>There was one exception. It must have been about 20+ hours into the experiment, and my eyes were itching, so I rubbed both of them at the same time over the scarf. If you rub your closed eyes and focus on your sight any time you can see some weird stuff, but this was far more extreme than usual. I remember my entire vision filling up with white bubbles which then broke and briefly returned to black. Then white lightning bolt shapes stretched across my sight, expanded to make my vision purely white, and then slowly faded back to black. The strangest thing about it was the <em>brightness</em>. I literally felt like I was staring into lights despite being blindfolded in a dark room. Unfortunately, it only lasted about 30 seconds, but my heart was racing.</p>



<p>More notable than what I saw was what I didn’t see. By default, I was lost in thought and I focused on nothing. In such a state, I didn’t even register my vision or notice the darkness. I <em>think</em> this made my imagination and mental visualization more acute. On occasion, I’d be deep in thought and I’d get the <em>brightness</em> sensation again because I’d be mentally picturing something so vividly that the inevitable return to darkness felt like shutting off the lights in my brain. I’ll explain more about this in the <strong>Three Phases</strong> section.</p>



<p>Sadly, I did not hallucinate, or at least not as far as I could tell.</p>



<figure><img src="https://i1.wp.com/www.intelligentliving.co/wp-content/uploads/2014/07/sloth-sleeping.jpg?fit=1024%2C698&amp;ssl=1" alt="Fighting Bacteria With Sloth Fur"></figure>



<h2><strong><span>Energy</span></strong></h2>



<p>This was the most surprising aspect of the experiment.</p>



<p>I read that <a href="https://abcnews.go.com/Health/story?id=117902&amp;page=1#:~:text=Without%20light%20cues%20that%20the,as%20a%20result%2C%20researchers%20say.">blind people have trouble getting to sleep</a> because they don’t access any/enough light for their circadian rhythms. I seem to have the exact opposite problem. Without light, my body always thinks it’s time to sleep and has trouble doing anything else. Throughout most of the experiment, I felt extremely lethargic, lazy, and had to fight to stay awake.</p>



<p>I started my first failed experiment attempt at 10:30 AM. I had gotten 7.5 solid hours of sleep, I hadn’t done anything tiring the previous day, and I generally felt fine. Then I put on my blindfold, and within thirty minutes I was nodding off. I semi-slept for two hours before deciding to get an energy drink to get myself out of the funk. That worked, but as soon as it wore off, I was back in semi-sleep mode.</p>



<p>Even when I was firmly awake, I generally felt weak and lethargic. Movement around the apartment was annoying of course, but made so much more difficult by my energy levels. I ended up lying perfectly still in my comfy computer chair with my feet on a table 95% of the time. That is, when I wasn’t lying in bed.</p>



<p>On the other hand, when I removed my blindfold after 24 hours, I experienced a <em>burst</em> of energy. Seriously, it was like I had downed a double shot of espresso. It was like a switch had been flicked. The haziness and cobwebs were gone in an instant, and I felt the energy coursing through my body. I guess light has a big impact on me.</p>



<div><figure><img data-attachment-id="908" data-permalink="https://dormin.org/blind-man-2/" data-orig-file="https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg" data-orig-size="615,479" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1604789422&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="blind-man-2" data-image-description="" data-medium-file="https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg?w=300" data-large-file="https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg?w=615" src="https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg?w=615" alt="" srcset="https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg 615w, https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg?w=150 150w, https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg?w=300 300w" sizes="(max-width: 615px) 100vw, 615px"></figure></div>



<h2><strong><span>Movement</span></strong></h2>



<p>I moved exactly how you’d expect… clumsily.</p>



<p>For the most part, I slowly walked around my apartment with a hand out to feel for walls and edges. Sometimes I’d get lazy and crawl just so it was easier. I know my apartment well enough that it wasn’t hard to get around, but every once in awhile I’d lose track of where I was and would be left slowly swinging my arm around searching for anything. It’s not a pleasant sensation.</p>



<p>Before the experiment, I had planned to pace around for fun, or maybe even do some exercise with the free time. But the confusion and especially the lethargy stopped all that. I just sat in my chair and didn’t move unless I needed to get a drink, go to the bathroom, or sleep.</p>



<p>I kind of wish I had done the experiment in an unfamiliar environment to add to the movement challenge, but oh well.</p>



<div><figure><img src="https://secure.img1-fg.wfcdn.com/im/99629273/compr-r85/1167/116715839/dual-flush-elongated-one-piece-toilet-seat-included.jpg" alt="DeerValley Dual-Flush Elongated One-Piece Toilet (Seat Included) &amp; Reviews  | Wayfair" width="729" height="729"></figure></div>



<h2><strong><span>Necessities</span></strong></h2>



<p>For food, I ate a big lunch at 10 AM before the experiment and then munched on dark chocolate throughout the night. I felt the heavy lethargy well before the lack of calories was an issue. I probably should have put some prepackaged meals in my fridge to eat, but I was worried about making a mess and not being able to clean up. Do I want ants? Because that’s how I get ants.</p>



<p>For drinks, I could manage to get to the kitchen and fill a cup with water when I needed to. I never took a full cup back to my chair just in case I knocked it over (clean up would be a nightmare). I also had some diet coke to serve as entertainment and put a little caffeine in me.</p>



<p>For the bathroom, I (a man) peed sitting down. I’m not ashamed to admit it.</p>



<div><figure><img src="https://imgaz2.staticbg.com/thumb/large/oaupload/banggood/images/F2/09/b934b522-e3e3-491d-b758-d0b92c259f0c.jpg" alt="Novel surreal melting distorted wall clock surrealist salvador dali style  wall clock amazing home decoration gift Sale - Banggood.com" width="802" height="801"></figure></div>



<h2><strong><span>Time</span></strong></h2>



<p>As part of the experiment, I never knew what time it was. This was intended to confuse me throughout the 24 hours, and it did, but it may have helped too. With no sense of time, it was easy to sit back and not think about it. Time drifted by and I existed. That was that.</p>



<p>I actually did ask Siri for the time once… it was late in the experiment, and it felt like I had put on the blindfold forever ago. As you’d expect, …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dormin.org/2020/11/08/the-blind-alone-and-confused-for-24-hours-challenge/">https://dormin.org/2020/11/08/the-blind-alone-and-confused-for-24-hours-challenge/</a></em></p>]]>
            </description>
            <link>https://dormin.org/2020/11/08/the-blind-alone-and-confused-for-24-hours-challenge/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031774</guid>
            <pubDate>Mon, 09 Nov 2020 05:39:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Postgres Constraints]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25031762">thread link</a>) | @mkfeuhrer
<br/>
November 8, 2020 | https://www.mohitkhare.com/blog/postgres-constraints | <a href="https://web.archive.org/web/*/https://www.mohitkhare.com/blog/postgres-constraints">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-373a3b57=""><div data-v-373a3b57=""><div data-v-373a3b57=""><div data-v-373a3b57=""><div data-v-373a3b57=""><p data-v-373a3b57="">Postgres Constraints</p> <div data-v-373a3b57=""><div data-v-373a3b57=""><div data-v-373a3b57=""><div data-v-373a3b57=""><a href="https://www.mohitkhare.com/categories/postgres" data-v-373a3b57=""><p>Postgres</p></a></div><div data-v-373a3b57=""><a href="https://www.mohitkhare.com/categories/programming" data-v-373a3b57=""><p>Programming</p></a></div></div> <p><span data-v-373a3b57="">7 Nov 2020</span></p></div></div></div> <p><img data-src="/_nuxt/img/postgres-constraints.8f3344a.webp" alt="Postgres Constraints" data-v-25298ab3="" src="https://www.mohitkhare.com/_nuxt/img/postgres-constraints.8f3344a.webp"></p></div></div> <div data-v-1bfa12aa="" data-v-373a3b57=""><p data-v-1bfa12aa="">Get latest articles directly in your inbox</p> <div data-v-1bfa12aa=""><form action="https://usetaski.us18.list-manage.com/subscribe/post?u=2974614c11e6abca644007be7&amp;id=3b5ecce493" method="post" name="mc-embedded-subscribe-form" target="_blank" novalidate="" data-v-1bfa12aa=""><div data-v-1bfa12aa=""> </div></form></div></div>  <div data-v-5c76b055="" data-v-373a3b57=""><p data-v-5c76b055="">Liked the content? Do support :)</p> <div data-v-5c76b055=""><p><a href="https://www.paypal.me/mkfeuhrer" aria-label="Paypal - Mohit Khare" data-v-5c76b055=""><img src="https://www.mohitkhare.com/_nuxt/9922499ba185bcccc368872c4cf7b0ea-320.png" alt="Paypal - Mohit Khare" width="125px" data-v-5c76b055=""></a></p> <p><a target="_blank" href="https://www.buymeacoffee.com/chHAzigTb" aria-label="Buy me a coffee - Mohit Khare" data-v-5c76b055=""><img src="https://www.mohitkhare.com/_nuxt/img/bmc.87873ba.svg" width="175px" alt="Buy me a coffee" data-v-5c76b055=""></a></p></div></div>  <div data-v-373a3b57=""></div></div> <div data-v-373a3b57=""><div data-v-e9f7aa1a="" data-v-373a3b57=""><p data-v-e9f7aa1a="">Explore more</p> <div data-v-e9f7aa1a=""><div data-v-e9f7aa1a=""><div data-v-36f5b510="" data-v-e9f7aa1a=""><div data-v-36f5b510=""><div data-v-36f5b510=""><a href="https://www.mohitkhare.com/blog/personal-okrs" data-v-36f5b510=""><p><img data-src="/_nuxt/0b543a8b05ad63f5c8bf88ee97692842-613.png" data-loading="data:image/png;base64,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" alt="Personal OKRs for Success" data-v-25298ab3="" src="https://www.mohitkhare.com/_nuxt/0b543a8b05ad63f5c8bf88ee97692842-613.png"></p></a></div> <div data-v-36f5b510=""><a href="https://www.mohitkhare.com/blog/personal-okrs" data-v-36f5b510=""><p data-v-36f5b510="">Personal OKRs for Success</p></a></div></div></div><div data-v-36f5b510="" data-v-e9f7aa1a=""><div data-v-36f5b510=""><div data-v-36f5b510=""><a href="https://www.mohitkhare.com/blog/making-decisions-the-right-way" data-v-36f5b510=""><p><img data-src="/_nuxt/c04ef31c75ad70464207ddcf44872feb-1000.png" data-loading="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAIAAAADnC86AAAACXBIWXMAAAsSAAALEgHS3X78AAAFHUlEQVRYw+2W+09TdxTA+09MGTDkMR52wtg0BgqlLZTe3va+2t7e8hDDFKPy2ARRhhRaufSW12Jw04y5OQXceMz34qyoqDhhY0sQGMrMEoNITOYmTggOKN1p76yLulEQ2C+cfHPy7b3f7/mcc773e04FerzsfxmCJfASeAm8BF58ME1Y9bhFj7OLCgYqoyjQq0160jo39qzBDM5qMGsquj0vMmrd61FatVlPcHNgzxYMAEsqkn9MhLQLVbYVcUYhpsFZZiHBTtNJOItj3D4FMxhD9Abi/SHkWR9xeuxmmqpgsFLXGnaewQxZbsDLKKoyWba1A8X6I/CT4fgFIdblK2dDURVZxhAcQ1gYj9PuEZjGLVp5PomXZoo21gpjbiHY2VimfXCwqba+dZm4wUdUGInRmJlCjTploYdHPiOYpQkuVVlQFRzDvYm2BSHNwrhfVJoLb1MnWk7X51vavCRHfMS21ySfrdGYwxONq1QUyTEvHzGDsSRZkS/L6A5Bmv0kF5fhjcK4W5i2JwQ77yNt95N3BarrvKNPL1e0+isvhctPBSJauGbEzHdsBrABZwmyoliWfiMUPfyqqOUVSX2o+Cam6V5J9K3UXA+jOgLQQ95RX3pJWrzFVyMQmz9CJ+TqyfKXBcM90ZLlGfJsW2B0/ipShxiz1mq7EfSncOpaENoVinWuQKr9xLQ8L02SWbcqvjYonlSbGGdFm4ePy0JjpWmidJ3KnEqYDoTJrsgUA6u1dcGxtuDEi36KWq/VOVEbcN2eFFlOijST9qyWeXyPSasWL9+C5FwTyo9Gym7GaurCYk8GyL7ylZ7yFnHhOtJ1l2iPK6inYAO2W4tbN6C530WgXwdIv49WHgmLa/KN/cI7psNfXhJpICmrAWqIs4zMbwGBw8at6ej27gikOQCpWaNqDI7at3ztByGJ/f5y41tJBFUOV2D+S6azNxDWDOX2pjckqfE7kvD8XKl0vRgjUGONECuJ0BGaygUBu1ohl4LuSpNlUUTlOmzbFjpZr2B00J2Uu9ZLc+hZ9sfZdSeonToo2oQFTzQdq2vdmbmfUJgY0qqbfVeewx8B1kBa1AnFPddvV3EtMIGfi9CPoQuV6dRsqq784cjY8eZvUVlREsXxz2HCD2hTswMbSKcJWs265y6LFl7zI1nDYfJiU2G9w+G40T+oVZXCQwPF0RgL0ePyEtAkYv5vNngp+OcP2IPJS8CEc3+8kSdRSjO4AmepkhnV8cV4YgmWUNxxtd/hkt1FDQmiAlW8ESwc/MTW1Tnwzemu7E37YL2B4p4tBqSFIZ02IWdPwaTCXGVp6eu5PXz3txt9g3urTwCDQsxb3tkL2duW+fG5Mz+2X+4r2nGIMzcC0m6fBn1n8Ne2892HP23lXbHb7aD/eDiWtekj8MadNkBCPOANkWgCnayxCvinEOjnB87BnulppzmHS5063nm5rffx44mhO/dHHozyIY6P/zn6aNzxIpmassOYnJiCeW/P7a0b9sJBAAPaM+QSJu/nHSzMO5iXXfvzwJAAAteqdmdu/JA3NzkJu537+YDcAg7xdqed4ph+8hKWTf293u5eDBZA3xv+HWAKcSFkrqb6xN2h+xOTUxMTU2Njj+GtANII7/ZUHnUnyi3ghNMPl2m3H4B9xqcXCmwEbTvzAxxfU8OlJ1467fAxCMCdne8duDf84GmeF0Cetyx4d/P+kZHRBaJCfHyIz78SXLnUy38XjsUVwSPXN7VgOf5X+QuyMiOTQYnkogAAAABJRU5ErkJggg==" alt="Making Decisions: The right way" data-v-25298ab3="" src="https://www.mohitkhare.com/_nuxt/c04ef31c75ad70464207ddcf44872feb-1000.png"></p></a></div> <div data-v-36f5b510=""><a href="https://www.mohitkhare.com/blog/making-decisions-the-right-way" data-v-36f5b510=""><p data-v-36f5b510="">Making Decisions: The right way</p></a></div></div></div><div data-v-36f5b510="" data-v-e9f7aa1a=""><div data-v-36f5b510=""><div data-v-36f5b510=""><a href="https://www.mohitkhare.com/blog/productivity-chrome-extensions" data-v-36f5b510=""><p><img data-src="/_nuxt/6162e8bc88982ff3c2db9ce53102c07a-800.png" data-loading="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAIAAAADnC86AAAACXBIWXMAAAsSAAALEgHS3X78AAAEEUlEQVRYw+1WW0hbSRgOFNanug+CVXxYlWi9BrO1+BBpC6XQy1OfFJaCpcIKuwuLUGhrK4oYtcULWu9RXBcvVbNGI6s16x2lrZfE1tbGKxVtjTG9JEZNTs45/TzT1ZgYm9K+FM73MJlz8s985/vnn29GcNwNhISECIXCqKiotbU1lmUZhmG/GgKemCfmiXni7484ODhY+DkEBQUFBASIRKJvSRwZGRkdHX3iUCBALBbHxMTodLpdYpPJ9MFtINiRWCqV0jSt1+vfugb+tVqtNTU18/PzZNjW1lZERISHh4enp+fRQ4EAhIWHh2OIfbYEBQUF+KEo6pC02Gw2tE1NTXNzc+TN9va2RCLx9fX19/f/yQ4BTggMDPTz84uNjcWQfcT5+fl7xNxbBhnY2qStFub/Nw7EZDBaBDIcyCMAWZsHgcjdl+o9Ym78pnr0nfT2+h8Jhuu/GR/8bds0H6gYme/q6hoZGRkeHh4cHBwYGOjv7+/u7iaRbhXXJ2KLBa3h0cDrsxKdRPz+4inDhZMrkgh9+i2aYWknYijIyMiQyWS1tbXV1dUlJSWFhYV9fX1fUNWEmKZs26ztZtu18Wjh/K+/P6jvHZHnmTv8TP/8QOnbaS7UQXFbm0Iul3d2dv7LAepHR0ehG/QKhWJ8fBz9hxw0Go1LYpZhV94vn+68eC/tTHFl3+n7T+IrplZexLHPBdSbVJsTMbZHXV1dRUVFcXFxeXl5aWkpOtDd0NCA5OODWltb6+vrlUrl1NQUvmBHG00fTKwzrZ2rvXBZcelGsyLqT+WlrIf6Z+dZjYB6LXUmRqqxtCqVCuLa29uheGlpqbe3t6enp6OjA4uNztDQEOSiFBYWFpxtZ19VX1feEBWJr7Yl/FKXK1MlsE+PmB8fpTbUNONIjPiioqL09HTCmpmZqdVqoRJpSE1NzcvLq6qqyuWQmJiIT3Sp2EpZ0b4yLMX/dSUs9+czMtFzlYfpvx+NCyVcVVPOxJhOrVajhT5S2KQzMTEBrRCKxZ6ennZlEnuKGXZH1zuzQfa4UT50x/Iixax/xMUwztsJa5yTk1NWVoaXEJeVlZWcnIw6T0tLq6ysRIXjMSUlpaWlZXc3OhIjG8SJ8PcOPXEDZIYzDxsHC7fZGhsb7Q0EqaM47DoJwlDtmIrYhZWDy+2EpXLTMpubm4lXE5MyGAxw/42NDXTW19ctHEBpNBqJ+ZOzYYUDzMuROC4uDpnJzs6+6xrIKlYkKSlpeXl51yw1avXY2NhLrXZ2dha7FuuNzurqKjb04uIi+jMzM4ifnJzEquOkcShsAZzd29v72KHw8fHx8vLCjQA69o23m8jZwO1t/IBUh4aGhn0OONRwCcGRbH8eO0z6pbcD/rLHE/PEPDFP7DY+Aj8diF6OEZ/ZAAAAAElFTkSuQmCC" alt="Boost Productivity with Chrome Extensions" data-v-25298ab3="" src="https://www.mohitkhare.com/_nuxt/6162e8bc88982ff3c2db9ce53102c07a-800.png"></p></a></div> <div data-v-36f5b510=""><a href="https://www.mohitkhare.com/blog/productivity-chrome-extensions" data-v-36f5b510=""><p data-v-36f5b510="">Boost Productivity with Chrome Extensions</p></a></div></div></div><div data-v-36f5b510="" data-v-e9f7aa1a=""><div data-v-36f5b510=""><div data-v-36f5b510=""><a href="https://www.mohitkhare.com/blog/reading-101" data-v-36f5b510=""><p><img data-src="/_nuxt/9eb30de577280fbbf9bf2f184e8fba97-800.png" data-loading="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAIAAAADnC86AAAACXBIWXMAAAsSAAALEgHS3X78AAAEnklEQVRYw2NQJwJoaGioqKgYGBi8evXq//////79+08xYBi1eNTiUYtHLR61mBSL1UBAHYRgNqmpo7BpYrGGhromEGioa6iraaipaoDt0gSywfaBgDpISklJSU9Pn5oW5yaFH10z+ci62Tsa3TdPzlnVm7mmLuT0jOqTS8tWNiXNyLE4syh/SYH1smKLgiC9h0+pZ3FHXfH36zt/Pjz9ZGHYw93997Z1PVxT9v/m7v+3Z96dl763wfz/pe6bU4KfLwmfnmN15+ELuMVfv379TDT4+uXLf1TnMtTlxz/cPuH5rik3eiwvrap5cmz13b1z359Z/f9s591pQQfr9b9syzzUYLO/xaY1wfD+45cQbT9+/DA0NOTl5RURERHGC4AKgMqA6eP79+/IocXgZSydZ8na4CV6fGLUoaU9hxe2XVjZfmp+2erm6EBdbk9NzjAj3iwrjjADTjdj+Wcv38AtNjMzAxoqIyMjJSUlKSkJJyEAwpaWlgYqEBUVNTc3R7c4z9/4Up/nwQUNq2f2zmvK3D2t6OzcnFkFbuUR1jEu+iFutllh7ulWvBuq7Upjne4/fo6s+e/fv7/B4C8YAMUhIj9//vwHBt++ffsKBkAGehz3tDf8un902YS60sTA1qzA3oKgzmyfJQ2xVzb171vY3lWWOrkutzlQ/vai2O6CgLsPnkK0/fr1a+eOnQcPHLh06dKVK1d27dp16tSpLVu2nDhx4vLly3fv3j1y+PDBgweAAYMzcXXWFtzfPWtpX8W66U3HVk04smrSrgWdG6ZUnlw77eGFo6e3LS2NdKryEDnW6dSc5nrv0TOINqAPaqpr2traent7p06dWlVVNW/evKysrEkTJ65bt+7AgQP9/f09PT1fgGkKRy5gKMlOfHz99I1jW/ZtWLRgWs/8KV2bl82+fHjzrWMbH53c8P/9vYV1sdE6DO7qnHYGSi9evUYLaiD48+cPMHgh4j9//QJygWxgaEMYOH3s7Wyxc/PKFZv3lNS0FFXUFpZVlpZXNtTXzZkxae+m5TfP7r+yoX+SN2uoIY+dvhrcYiB48+bNx48fgX56BwZAm4ABC0xBnz59ArJfv34NjFqg+LOnT58/f44Z5gwtFbmfr2y7c/Xc60e3vz+5+uPp1Z9Pr/x8cvHr/TNf7526tGf5zAj1+V4Msea8trqqL2EWAz164fz5M6dP37xx4/atW+fOnj1//vzt27dfvHhx/Pjx+/fvQ2IayLhw4QKQDXQiWpgzNNeU/X937+nlI/du3Xj/8NLHm4ffXj/66vbxN7f2v7+99+r2abOi1FttGNItWd2NlJ6/fI2qH2EQRBDkpj9/IGxIOscZ1K21pf/f3vl45/SHO2dfXT/x+e6pz/fOfLp3+uv9ky+v7F/Snr26yrPJnfdsiUF5tOWDJy+Q7UB2BKnlKIOPp1tNaX5pflZZfmZxTjqIUQBiA1FJboa3o5Wvg0mkg0ahn5m3k+mz5y+pVlYrKipJSklLScsAkbSMLIQB48ooKqsoKqsqqGhIyClp6+hTt1rU0MQNINUikFJXUwWWty9fjjZ9Ri0etXjU4lGL6W8xAIU/JG106R/JAAAAAElFTkSuQmCC" alt="Improving Reading 101" data-v-25298ab3="" src="https://www.mohitkhare.com/_nuxt/9eb30de577280fbbf9bf2f184e8fba97-800.png"></p></a></div> <div data-v-36f5b510=""><a href="https://www.mohitkhare.com/blog/reading-101" data-v-36f5b510=""><p data-v-36f5b510="">Improving Reading 101</p></a></div></div></div><div data-v-36f5b510="" data-v-e9f7aa1a=""><div data-v-36f5b510=""><div data-v-36f5b510=""><a href="https://www.mohitkhare.com/blog/transactions-postgres-golang" data-v-36f5b510=""><p><img data-src="/_nuxt/6431c37e5906bbb06dc74faf07dfbcfd-800.png" data-loading="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAIAAAADnC86AAAACXBIWXMAAAsSAAALEgHS3X78AAAE8klEQVRYw+1W6U/bZRxv4F8giEAMJBhgkAnJwjLfmMzEbS9MFuWFJm4sgEOQTWRcy4CBAoVSekEvrq4ctqWFFhgttJylXHITbgQ55CwDFghYQPBDf66rBZnHErOknzTf3/P7Pk/7+d5PSe5/Ax4eHm5ubj4+Pmtra8fHx0dHR8f/GSQrsZXYSmwlfvOI8aMXXgUvLy8c8/X1XV1dfW3Erq6ubxvh4OAA+ZYRhMbJycnZ2RkLR0dHKD09PfV6vYkY8rd/AkvigIAAkUgkFBaJxeLS0pIyiUQslpQUF+PD5/F5XE5p6Q/FJSeIiIiYm5t7bR6zWCw8nunXdLrWZm1rW1t7b3dXQ1OzVqttam4pq1Q2NzWu609SW1xcPDk5icXh4SFkZ2dnUFBQWFhY6LnAgeDg4JSUFAunSTQafd+wl5RO/ySOc/lLSjRTnMCWXAmh3ojMThaobqWWXotgJaRlra2uiMTiiYkJfGd/fx8yPz+fRCLZ2tqSzoWNjQ0kSsRgMJhHi8ThcAd6u28/5nsGsfxCc77hPPUOZngH0n3uMr0DaZHsqg8eFNyMYTc2aBQKxdjYGL5D2L6+vt5pRFtbW0dHBxaQWLe3t2PR1dVlUgKDg4OWHnO5XJ1O5/+Q6x3E+Cg6L0feFpervBFbcDGYdjWSz6rQRfGVHz9g6bTNcrncnHhjY2NkZGRpaWlvb29lZWVxcRHNtru7iwKEcnx8HK9Qwj5UhnlV/kHM5nCG+nsDk/Pc79Cux+QnPVFHcqsfFdS+81laNO9pSpHmHrvmi1jq0vxMmVRGhNrkcXZ2NplMzsjISE1NjYuLY7PZFAoFKZAZwePxaDRaenp6+L1woVBoScxksXaeb4Qm0i/ezb4WnfcVvdwnmB7Dr3n3FuXz70vDmfKo3NqEdDqOikRiorgI4s3NzYaGBrVa3d3drao9QX19vVKlQkbqNRqEuq6urrKqSqNWz8zMIDyWVc1gMPDIYPKu3Od9GMn7lltzPU4A+gt3qJdCmJSy1gKZUiB4gjNFRUXmVY2wM5lMKpUqlUorKysLCwtz+XxoYA3W+Nn4+HiqEfPzC6ebkEShZOJRIZN++pDnG8ZP5pVJlC0hDMV7QTT32xkx+Wp5jYZKow8MDJSXlyNzJo9nZ2fhYktLi0qlgtPT09OQRHFNTU3By76+PlRPY2Mjts4gzsw8If555qfYFFoYWUDOzMrIkzBlWr9QllcgLYGvSM0RJqZSJicnkDaCmPAYNFFRUfAMsUWaq6urcQBTAU6j45FppP9xUhIkjDOZ+5IYoSDMGRwckMukFYpKgbDoUSb/cjjX72tOxHeM4f4f9cYBguFFhNpkOywgxiGhMbzAnhEHBwfYwuvpefmSGIdMqt3t52RuyaUwzvsReYmZ7M1nekJvQbyzs4PC3tra2t7eXl5exit6CTToHEhUE7Yg0VpotjNmNRFqHAU3JJzYN/wqFEmv3mfejGaVycoPjXqiuJA883bq6ekZGhpCmw4PD2OBKQFlf3//6OgocozUQkKPVyI7Z8xqk8eEN78szNeqNRg78OMkpMbd06E+H0dG/OUl4e/vjzbHBCC/QFpaWlZWFlJAp9MxENKMwCuuhIWFBfNr0QLmpr/SOJKLiwvuWoc/g7iV7e3tiS1cyXZ2dhj0pyffv78Wcb3/P/9ArP8yrcRWYivxG0f8O49FUp+RTJP8AAAAAElFTkSuQmCC" alt="Transactions on Postgres with Golang" data-v-25298ab3="" src="https://www.mohitkhare.com/_nuxt/6431c37e5906bbb06dc74faf07dfbcfd-800.png"></p></a></div> <div data-v-36f5b510=""><a href="https://www.mohitkhare.com/blog/transactions-postgres-golang" data-v-36f5b510=""><p data-v-36f5b510="">Transactions on Postgres with Golang</p></a></div></div></div><div data-v-36f5b510="" data-v-e9f7aa1a=""><div data-v-36f5b510=""><div data-v-36f5b510=""><a href="https://www.mohitkhare.com/blog/productivity-in-vscode" data-v-36f5b510=""><p><img data-src="/_nuxt/c00f15909b09287ab6dcd91cb9702fc0-800.png" data-loading="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAIAAAADnC86AAAACXBIWXMAAAsSAAALEgHS3X78AAAEiUlEQVRYw+1WSUwbZxSeQntp1KoHxBJUBCpKIeQAUqscorRVlaKqt1YcKvWAWhSpBzZFIKoACkLBZjNpIRKrTezYgCEoFAqBIlybTQaMHfadmMVgA8YYXC94mX7MUMcMiNI2l6r+NHrzzz8z//e+997/Zoj3L4CIiIjw8PDo6OitrS2SJF0uF/mvQXiJvcReYi/xf48Yi179K0RFReGxmJgYnU7nJoZ1XBhOp5NJHBYWFhQUdPksYD6QuhUcHOzv7x8ZGbm9vf3KFMfHxzc0NHC53NqT4PJ4IgFfLOQ/qq2t4fJEdXWpqakrKyt4BwpgFQpFcnJyenp62rnAAykpKRwOhyGaKCsrw8lut3vO0orW9x1jBqebSSgUzs/PY3B4eAhbXV1NEISvry9xLnx8fGBRKDabzTNaRFFREU5Wq81uP87HIeWEQr17q/DXm5UzqTJL56IJMwKBYH5hAQPad61W29PTI5VKe3t7ZTKZlIJEIsEYFuPfKEgoDA0NMRUXFxe7FcMbh/PII+nc1o0CybXsXz7lzsX+bIltMhhIUlwnnKMU015bLJbNzU3U+eLiIlKgo2A0GtVqNSzmURCwGK+uruJhZo5p4nK5tmJ420Gt2PJcE53b9V5mxwe5HXHi1din5s+fGHROsrH+mJiO/OjoaE5OTmJiIlYoLCxksVjl5eWIP9I5Ozvb2dnJ4/GQR8xnZGSoVCp3qI6JSzgcnD6qnL50T5n2TFMhWwy/2xqY3nqzSDLyYueB0vah0Hir8QQx/f7S0lJbW1tXV9fIyEh/f39fX9/k5CQI6GjPzMzAs46OjpaWFqVSabVamYqLKMUv9OYvRcv+7IkQliLkh/bvBUOavaPgsIYtMULjJ2KD1kk2nVQMPkgsKCioqqrKy8srLS1FuUDlwMCAWCyuqakRiUTNzc1yuRx+MOS+DDXpdNxpVL2T2ReYP3mZ/fzhoI6+nSu3XBMYb9QbNj2I6SWQS0hB+bS3t8NOTEwgwt3d3dC9vLyMW1AMJ2DHxsZO736CQ4X6m+pB4rv66/c7vxIuvJmjejtX9W2z2mp35its4bXG6yLDhoOpeHh4OCkpqaSkBMGEbiQV9Gw2u6mpCdXO5/MrKipQBFlZWRifoZjO8Rc/ST97IFvV/+5wkbefqt/IHvXNVn5cOf11q/7Ko/2Yx7uexO6WaTab7X8C61ooWCkcHByYTCYzBUaTOBHqA7PNbHPQOwpH2rP11zKVr9+Vv/vj0tXHppBK/doh+eQk8Wn8rVb6ch+7aCAm1Ov3pVoiffCt/IUrfFNyzz5m6kTHnevV9Gq6c6Gfub8k9qPjKB8PBzS32zZUW7i20Z1rwaNzoTOggej1+r29vbW1tX0KCOz6+jqCvLOzo6egpnDGdsI2ON2rGWD0app4d3cXpYtiRmOanp4eHx9H9YIJg6mpKY1Gg3a2sbGBMeocDjGJ4+LiUJnYiOxTYLHcBwsZSUhIgLKLh/r8x4jQ0NCAgIDAc4EPs5+fH/4FGN9j1ym4Jz3pz/SAwOf9n/2BeH/2vMReYi/x/474D5XblxQw5EkNAAAAAElFTkSuQmCC" alt="Improve your productivity with VS Code" data-v-25298ab3="" src="https://www.mohitkhare.com/_nuxt/c00f15909b09287ab6dcd91cb9702fc0-800.png"></p></a></div> <div data-v-36f5b510=""><a href="https://www.mohitkhare.com/blog/productivity-in-vscode" data-v-36f5b510=""><p data-v-36f5b510="">Improve your productivity with VS Code</p></a></div></div></div></div></div></div> <div data-v-373a3b57=""><div data-v-76d4e02f="" data-v-373a3b57=""><p data-v-76d4e02f="">
    Liked the content? <br data-v-76d4e02f="">
    Do support :)
  </p> <div data-v-76d4e02f=""><p><a href="https://www.paypal.me/mkfeuhrer" aria-label="Paypal - Mohit Khare" data-v-76d4e02f=""><img src="https://www.mohitkhare.com/_nuxt/9922499ba185bcccc368872c4cf7b0ea-320.png" alt="Paypal - Mohit Khare" width="125px" data-v-76d4e02f=""></a></p> <p><a target="_blank" href="https://www.buymeacoffee.com/chHAzigTb" aria-label="Buy me a coffee - Mohit Khare" data-v-76d4e02f=""><img src="https://www.mohitkhare.com/_nuxt/img/bmc.87873ba.svg" width="175px" alt="Buy me a coffee" data-v-76d4e02f=""></a></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.mohitkhare.com/blog/postgres-constraints</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031762</guid>
            <pubDate>Mon, 09 Nov 2020 05:35:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[4 Billion USD ICO From 2017: Clues Emerging, Finally]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25031582">thread link</a>) | @npguy
<br/>
November 8, 2020 | https://doublespend.io/2020/10/28/breaking-object-floating-in-atlantic-could-be-carrying-funds-raised-in-eos-ico/ | <a href="https://web.archive.org/web/*/https://doublespend.io/2020/10/28/breaking-object-floating-in-atlantic-could-be-carrying-funds-raised-in-eos-ico/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Travelers aboard a luxury TransAtlantic cruise have shared pictures that many in the crypto community believe could provide clues on the missing 4 billion dollars raised during the EOS ICO. </p>



<p>DoubleSpend’s own analysis based on the size of the box show that it could very well contain the amount in USDs that was raised in the year-long ICO.</p>
<div><p><a href="https://twitter.com/share?url=https://doublespend.io/2020/10/28/breaking-object-floating-in-atlantic-could-be-carrying-funds-raised-in-eos-ico/&amp;text=Object%20Floating%20In%20Atlantic%20Ocean%20Could%20Contain%20EOS%E2%80%99%20ICO%20Funds%3A%20Sources" title="Share on Twitter" target="_blank" rel="nofollow noopener noreferrer" data-postid="409" data-social-network="Twitter" data-social-action="Tweet" data-social-target="https://doublespend.io/2020/10/28/breaking-object-floating-in-atlantic-could-be-carrying-funds-raised-in-eos-ico/"><span><span><svg version="1.1" xmlns="http://www.w3.org/2000/svg" width="29.71875" height="32" viewBox="0 0 951 1024"><path d="M925.714 233.143q-38.286 56-92.571 95.429 0.571 8 0.571 24 0 74.286-21.714 148.286t-66 142-105.429 120.286-147.429 83.429-184.571 31.143q-154.857 0-283.429-82.857 20 2.286 44.571 2.286 128.571 0 229.143-78.857-60-1.143-107.429-36.857t-65.143-91.143q18.857 2.857 34.857 2.857 24.571 0 48.571-6.286-64-13.143-106-63.714t-42-117.429v-2.286q38.857 21.714 83.429 23.429-37.714-25.143-60-65.714t-22.286-88q0-50.286 25.143-93.143 69.143 85.143 168.286 136.286t212.286 56.857q-4.571-21.714-4.571-42.286 0-76.571 54-130.571t130.571-54q80 0 134.857 58.286 62.286-12 117.143-44.571-21.143 65.714-81.143 101.714 53.143-5.714 106.286-28.571z"></path></svg></span><span>Tweet</span></span><span>0</span></a></p></div>		</div></div>]]>
            </description>
            <link>https://doublespend.io/2020/10/28/breaking-object-floating-in-atlantic-could-be-carrying-funds-raised-in-eos-ico/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031582</guid>
            <pubDate>Mon, 09 Nov 2020 04:55:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Strategies to working remotely and smashing goals]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25031490">thread link</a>) | @veebuv
<br/>
November 8, 2020 | https://www.remoteworkly.co/blog/22-tips-to-working-remotely-and-smash-your-goals | <a href="https://web.archive.org/web/*/https://www.remoteworkly.co/blog/22-tips-to-working-remotely-and-smash-your-goals">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-w-id="45d72c63-4641-3f9f-f271-8df897413c12"><p>Alright the future of work is here to stay and we all need to prepare for the best remote work practices. Regardless of what happens, work has changed forever, people will go back to the office surely, but the dynamic will now be a hybrid mode.<br>‍</p><p>So learning how to work remotely will be a skill in your arsenal that might just propel you to your next career promotion. If you've asked yourself the question "how to work from home" - you've reached the right place.<br>‍</p><h4>1) Create a routine</h4><p>If you want to succeed working from home or working remotely this is a must, which is why it's the top position. You need to build a system that builds a body clock. I used to get into the zone when I got onto the train and grabbed by morning coffee at my office, when I couldn't do this anymore I spiraled. This was until I started building an atomic habit again, micro habits that signal the mind for whats about to happen next. Nowadays my trigger is early morning juice, similarly so, build a routine. Get out of bed, go to the gym, have a process.<br>‍</p><h4>2) Have your creative work space</h4><p>Separate your living, from your office space. Even if it means working from a coffee shop. You need to keep your area of comfort for leisure and work for work. This is an important work tip as separation of concerns as well as "environments" make a significant difference to motivation. Pretty much the same reason people go to libraries when they can read at home</p><p>‍</p><h4>3) Set time boundaries</h4><p>Its very easy to be sucked into 24 hour work when working from home. One of the keys to working remotely is creating time boundaries. Employers may feel like you're available to message after work hours. In addition you might get FOMO from all the slack notifications. Fight the urge, set your boundaries. 80% of 130 people I spoke to said they were constantly fatigued from working from home. This is a very important tip amongst other work from home tips and tricks. Stay disciplined to time<br>‍</p><h4>4) Leave home</h4><p>How to be productive working from home ? Leave your home. Ironic - I know but cabin fever can creep into you. As humans we need social interaction and movement. Step away from your home, go for a walk, meet a friend or better yet exercise. This will stimulate both your body muscles as well as your brain. Feeling fresh air graze your face makes a big difference, especially when you're glued to your screen<br>‍</p><h4>5) Plan meetings with work colleagues</h4><p>We've been remote for nearly 1.5 years now and I always advice social meetings for working remotely. Catch up with any team-mate in the same city as you and make it a monthly if not weekly thing. Building bonds with people in real life not only helps you create long lasting relationships, but also helps you connect deeper with another person. 70% of communication is non - verbal, which you miss out over zoom calls.<br>‍</p><h4>6) Reduce distractions</h4><p>"Minimise the number of distractions you have in your office" - simple yet sage advice for working remotely. We've got a concentration span of 12 seconds, with slack messages going off every moment combined with our innate nature of not wanting to miss out on important conversations leads us to doing absolutely no work at all. I encourage you to embrace an async first work culture, tools like <a href="http://remoteworkly.co/">remoteworkly.co</a> help with async video meetings or even loom for screen recording.<br>‍</p><h4>7) Have no meeting Wednesdays</h4><p>Meets really hurt productivity. 72% of managers say meetings are a complete waste and 60% of employees think they will work better without meetings. This is the same reason Zoom fatigue is becoming a big issue, because you need to have your camera on and focus the entire time. Try encourage a culture where you have certain days with no meetings. Any conversation that needs to happen can occur in an asynchronous way, weather thats via tools like <a href="http://remoteworkly.co/">remoteworkly.co</a> or vidyard. If you're reporting bugs, use feedback tools like bugheard or <a href="http://remoteworkly.co/show">remoteworkly.co/show</a></p><h4><br>8)Avoid unwanted meetings with conversation bloat</h4><p>Focus on getting work done, try set a decorum where you can leave meetings you're not needed in anymore. Teams that embrace the concept of async communication will win. This will reduce anxiety within teams, improve culture and make sure the meetings that do happen are purely focused on value and outcome. This can be done using tools like <a href="http://remoteworkly.co/">remoteworkly.co</a> for async meetings and startups or even voice notes like recordify</p><h4><br>9)Start with the toughest task</h4><p>There's a science behind this but it works. We often think starting with easy tasks gives us the feeling of accomplishment and builds up momentum. There is some truth to this, however by the time you reach the tough/long task to complete you're left drained of energy and delay it to tomorrow, which never comes. Start with the toughest tasks, its the best way to be productive working from home<br>‍</p><h4>10)Over communicate</h4><p>There will be obvious disconnect between you and your team mates when you're remote. That is the nature of VoIP communication. So make sure you overcommunicate. This does not mean to spam people with 100 messages, but rather use video and tools that capture as much data as possible for you to make it easier for the other person to understand what you're doing without having to reach back to you."</p><h4><br>11)Leverage asynchronous communication</h4><p>My favorite tip in my list of remote work best practices. I strongly believe async communication is the way of the future. Leverage using async communication whenever and wherever possible without organizing impromptu/time blocking calls. There's several tools out there that let you take full advantage of async communication, <a href="http://remoteworkly.co/">remoteworkly</a>, <a href="http://loom.com/">loom</a>, <a href="http://vidyard.com/">vidyard</a>, <a href="http://marker.io/">marker</a> (for website feedback), <a href="http://remoteworkly.co/show">remoteworkly</a> (for QA feedback), <a href="http://trello.com/">trello</a>, <a href="http://asana.com/">asana<br>‍</a></p><h4>12)Use productivity hacks like pomodoro</h4><p>The pomodoro technique is one of the best productivity tips I came across. Its an old technique that lets you cut down your work into an investment reward balance. This builds another atomic habit loop where you learn to enjoy difficult tasks in anticipation of the reward. Your day is broken down into 25 minute work chunks of pure focus with 5 minute breaks, do this 4 times and then take a 20 minute break, rinse and repeat. Checkout timechi.com</p><h4><br>13)Share your project progress</h4><p>The easiest way to start working when you're feeling down or demotivated is by sharing your progress. Social accountability plays a big role in human motivation, something about putting our reputation at risk that kicks us in the behind. In addition, sharing your progress becomes a incredible feedback cycle, where you encourage others with your progress or cause them to reach out to you and motivate you to push faster. Lastly, having progress updates is a great way to look back and see how far you come, consequentially motivating you to work better</p><h4><br>14)Avoid jumping on impromptu phonecalls</h4><p>This rolls back to my earlier point about async conversations, Paul Graham mentioned that one of the downfalls of remote work is impromptu meetings where a large number of incredible ideas are usually generated is being robbed from todays workforce. Yes this is true, but on the flip side, most of the inefficiencies in working from an office came from these "tap on the shoulder" interruptions. I no longer pick up calls unless the message following up says "this is urgent", your concentration is sacred in 2020. Protect it at all costs.</p><h4><br>15)Set clear expectations for each day</h4><p>Employing a daily manifest of long term goals, short term goals, micro tasks as well as schedule has been a game changer in working remote. You almost get to "grade" each day in terms of the success you wanted to achieve and what you did achieve. This lets you work out what is the most effective work from home schedule for you. Each week, analyze the good days and bad days, pick up patterns that lead to bad days and those that lead to good days and optimize to focus on the good patterns.</p><h4><br>16Share with video whenever you can</h4><p>To prevent the feeling of isolation, use video software whenever you can. <a href="http://loom.com/">Loom</a> is a great place to begin, or even zoom for work meetings. I know it can be daunting at times, but it provides a great path to building deeper and more meaningful relationships with teams. PS - when you're chatting, look into the camera and not your screen. Makes double the impact</p><h4><br>17) Ask for one on one checkins</h4><p>Do NOT cancel your one on ones with your team mates, they're more important than every given there is no face to face relationship with your direct supervisor or subordinate. Use a template with a clear structure to find out how your team is doing, how things can be done better. This builds trust and encourages them to keep motivated even when people feel disconnected.<br>‍</p><h4>18) Bond with your team beyond work, get to learn about their family</h4><p>Use tools like <a href="http://donut.com/">donut</a> to encourage your team members to learn about each other. This is vital for new employees who don't have a chance to meet new people given you're restricted to a computer, donut runs introduction meetings between people. Encouraging that communication between new colleagues is a great way to improve team bond, morale and company culture</p><h4><br>19) Exercise</h4><p>Yes, do it. As human's we're not made to be seat potatoes. Despite how tasty potatoes are, you can't aspire to be one. Get out, hit the gym and exercise. The endorphins release as well as adrenaline rush you get post exercise is fundamental for peak performance. You won't find one successful person who doesn't preach for a daily exercise schedule</p><h4><br>20) Use noise filtering software</h4><p>Working at home with kids or even a dog can be very disturbing and sometimes embarrassing. Even though everyone is working remote, the noise of a grinder in the background whilst you're delivering your Q4 results can be quite distractive. Use tools like <a href="http://krisp.ai/">krisp</a> that magically cut out background noise and give you the confidence that regardless of who's speaking at the back, your colleagues won't be able to hear it.<br>‍</p><h4>21) Check in with 5 of your friends</h4><p>I assure you many of your friends will be …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.remoteworkly.co/blog/22-tips-to-working-remotely-and-smash-your-goals">https://www.remoteworkly.co/blog/22-tips-to-working-remotely-and-smash-your-goals</a></em></p>]]>
            </description>
            <link>https://www.remoteworkly.co/blog/22-tips-to-working-remotely-and-smash-your-goals</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031490</guid>
            <pubDate>Mon, 09 Nov 2020 04:34:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Start with pen and paper]]>
            </title>
            <description>
<![CDATA[
Score 72 | Comments 32 (<a href="https://news.ycombinator.com/item?id=25031483">thread link</a>) | @sethetter
<br/>
November 8, 2020 | https://sethetter.com/posts/start-with-pen-and-paper/ | <a href="https://web.archive.org/web/*/https://sethetter.com/posts/start-with-pen-and-paper/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            


<article>
    
    <section>
        <p>tl;dr — If you feel unfocused, grab a pen and paper and start writing your thoughts down.</p>
<p>Is there a question you are stuck on? A ambiguous goal you're trying to accomplish? Maybe a task you know you need to do but from which you keep getting distracted?</p>
<p><strong>Nothing will provide focus like pen and paper.</strong></p>
<p>It's all too easy these days to have a clear intention only to be sidetracked by the whirlpool of apps and services clawing for our attention on our devices.</p>
<p>It helps to take the time to groom our notification settings for importance and timeliness, but a digital device that we can use to complete nearly any task will never stand up to pen and paper in terms of it's ability to provide focus.</p>
<p>My thoughts are a constant whirlwind, I'm certainly more distractible than most, and interacting with nearly any online service only fuels that fire. So how can I get anything done if I'm unable to control my focus?</p>
<p><strong>Pen and paper.</strong> Whenever I catch myself stuck in the whirlpool, feeling not-great because I <em>know</em> I'm not doing what I want to be doing, or what I should be doing, I step away, grab pen and paper, and start writing.</p>
<p>The simple act of writing can focus my thoughts and attention in a way that nothing else can. Free from distractions, just a canvas to pour my thoughts into, and turn them into something with a sense of direction and purpose.</p>
<p>Writing is like a superpower to me. If there's any task I want to accomplish, the first step is always to write it down. Anytime I need to recenter myself on that task, I simply return to paper.</p>
<p>Throughout my life I've found that the simplest solutions are often the most powerful. So far I've found no simpler solution to start tackling any problem than to simply write it down, and then keep on writing.</p>

    </section>
</article>


        </div></div>]]>
            </description>
            <link>https://sethetter.com/posts/start-with-pen-and-paper/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031483</guid>
            <pubDate>Mon, 09 Nov 2020 04:33:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cool Machine Learning Books]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25031455">thread link</a>) | @ridddle
<br/>
November 8, 2020 | http://matpalm.com/blog/cool_machine_learning_books/ | <a href="https://web.archive.org/web/*/http://matpalm.com/blog/cool_machine_learning_books/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
  <p>awhile ago i posted
   <a href="http://matpalm.com/blog/2010/08/06/my-list-of-cool-machine-learning-books/">my list of cool machine learning books</a>,
   but it's been awhile so it's probably time to update it...
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/mml.jpg"></p>
<p><b><a href="https://mml-book.github.io/">Mathematics for Machine Learning</a>
   by Marc Peter Deisenroth, A. Aldo Faisal &amp; Cheng Soon Ong.</b>
</p>
<p>this is my personal favorite book on the general math required for machine learning,
   the way things are described really resonate with me.
   available as a free pdf but i got a paper copy to support the authors after reading the
   first half.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/laalfd.jpg"></p>
<p><b><a href="http://math.mit.edu/~gs/learningfromdata/">Linear Algebra and Learning from Data</a>
   by Gilbert Strang.</b>
</p>
<p>this is gilbert's most recent work. it's really great, he's such a good teacher, and
   <a href="https://ocw.mit.edu/courses/mathematics/18-065-matrix-methods-in-data-analysis-signal-processing-and-machine-learning-spring-2018/">his freely available lectures</a>
   are even better. it's a shorter text than his other classic intro below with
   more of a focus on how things are connected to modern machine learning techniques.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/itla.jpg"></p>
<p><b><a href="https://math.mit.edu/~gs/linearalgebra/">Introduction to Linear Algebra</a>
   by Gilbert Strang.</b>
</p>
<p>this was my favorite linear algebra book for a long time before his 'learning from
   data' came out. this is a larger book with a more comprehensive view of linear algebra.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/ts.jpg"></p>
<p><b><a href="https://greenteapress.com/wp/think-stats-2e/">Think Stats: Probability and Statistics for Programmers</a> by Allen Downey.</b>
</p>
<p>this book focuses on practical computation methods for probability and statistics.
   i got a lot out of working through this one.
   it's all in python and available for free.
   ( exciting update! as part of writing this post i've discovered there's a new edition
   to read!)
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/dbda.jpg"></p>
<p><b><a href="https://sites.google.com/site/doingbayesiandataanalysis/">Doing Bayesian Data Analysis</a>
   by John Kruscgke</b>
</p>
<p>on the bayesian side of things this is the book i've most enjoyed working through.
   i've only got the first edition which was R and
   <a href="https://en.wikipedia.org/wiki/OpenBUGS">BUGS</a> but i see
   the second edition is R,
   <a href="http://mcmc-jags.sourceforge.net/">JAGS</a> and
   <a href="https://mc-stan.org/">Stan</a>.
   it'd be fun i'm sure to work through it doing
   everything in <a href="https://github.com/pyro-ppl/numpyro">numpyro</a>. i might do that in all
   my free time. haha. "free time" hahaha. sob.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/eosl.jpg"></p>
<p><b><a href="https://web.stanford.edu/~hastie/ElemStatLearn/">The Elements of Statistical Learning</a>
   by Hastie, Tibshirani and Friedman</b>
</p>
<p>this is still one of the most amazing fundamental machine learning books i've ever had.
   in fact i've purchased this book <em>twice</em> and given it away both times :/ i might buy another
   copy some time soon, even though it's been freely available to download for ages. an
   amazing piece of work.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/pgm.jpg"></p>
<p><b>
   <a href="https://mitpress.mit.edu/books/probabilistic-graphical-models">Probabilistic Graphical Models</a>
   by Daphne Koller &amp; Nir Friedman</b>
</p>
<p>this is an epic textbook that i'd love to understand better. i've read a couple of sections in
   detail but not the entire tome yet.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/praml.jpg"></p>
<p><b>
   <a href="https://www.microsoft.com/en-us/research/people/cmbishop/prml-book/">Pattern Recognition and Machine Learning</a>
   by Christopher Bishop</b>
</p>
<p>this is probably the best overall machine learning text book i've ever read. such a beautiful book
   and <a href="https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf">the pdf is FREE FOR DOWNLOAD!!!</a>
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/mlapp.jpg"></p>
<p><b><a href="https://mitpress.mit.edu/books/machine-learning-1">Machine Learning: A Probabilistic Perspective</a> by Kevin Murphy</b>
</p>
<p>this is my second favorite general theory text on machine learning.
   i got kevin to sign my copy when he was passing my desk once but
   someone borrowed it and never gave it back :(
   so if you see a copy with my name on the spine let me know!
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/homl.jpg"></p>
<p><b><a href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/">Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow</a> by Aurélien Géron</b>
</p>
<p>this is the book i point most people to when they are interested in getting up
   to speed with modern applied machine learning without too much concern for the
   theory. it's very up to date (as much as a book can be) with the latest libraries
   and, most importantly, provides a good overview of not just neural stuff but fundamental
   <a href="https://scikit-learn.org/stable/">scikit-learn</a> as well.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/mle.jpg"></p>
<p><b><a href="http://www.mlebook.com/wiki/doku.php">Machine Learning Engineering</a> by Andriy Burkov</b>
</p>
<p>a great book focussing on the operations side of running a machine learning system. i'm a bit
   under half way through the free online version and very likely to buy a physical copy to finish
   it and support the author. great stuff and, in many ways, a more impactful book than any of
   the theory books here.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/itdm.jpg"></p>
<p><b><a href="https://www-users.cs.umn.edu/~kumar001/dmbook/index.php">Introduction to Data Mining</a>
   by Pang-Ning Tan, Michael Steinbach &amp; Vipin Kumar</b>
</p>
<p>this is another one that was also on my list from ten years ago and though it's section
   on neural networks is a bit of chuckle these days there is still a bunch of really
   great fundamental stuff in this book. very practical and easy to digest. i also see there's
   a second edition now. i reckon this would compliment the "hands on" book above very well.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/salp.jpg"></p>
<p><b><a href="https://web.stanford.edu/~jurafsky/slp3/">Speech and Language Processing</a>
   by Dan Jurafsky &amp; James Martin</b>
</p>
<p>still the best overview of NLP there is (IMHO). can't wait to read the 3rd edition which
   apparently will cover more modern stuff (e.g. transformers) but until then, for the
   love of god though, please don't be one of those "this entire book is
   irrelevant now! just fine tune BERT" people :/
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/no.jpg"></p>
<p><b><a href="https://link.springer.com/book/10.1007/978-0-387-40065-5">Numerical Optimization</a>
   by Jorge NocedalStephen J. Wright</b>
</p>
<p>this book is super hard core and maybe more an operations
   research book than machine learning. though i've not read it cover to cover the
   couple of bits i've worked through really taught me a lot. i'd love to understand
   the stuff in this text better; it's so so fundamental to machine learning (and more)
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/dl.jpg"></p>
<p><b><a href="https://www.deeplearningbook.org/">Deep Learning</a>
   by Ian Goodfellow</b>
</p>
<p>writing a book specifically on deep learning is very dangerous since things move so fast but
   if anyone can do it, ian can... i think ian's approach to explaining neural networks
   from the ground up is one of my favorites. i got the first edition hardback but it's free to
   download from the website.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/pr.jpg"></p>
<p><b><a href="https://mitpress.mit.edu/books/probabilistic-robotics">Probabilistic Robotics</a>
   by Sebastian Thrun, Wolfram Burgard and Dieter Fox</b>
</p>
<p>when i first joined a robotics group i bought a stack of ML/robotics books and this
   was by far the best. it's good intro stuff, and maybe already dated in places given
   it's age (the 2006 edition i have) but i still got a bunch from it.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/tml.jpg"></p>
<p><b><a href="https://www.oreilly.com/library/view/tinyml/9781492052036/">TinyML</a>
   by Pete Warden &amp; Daniel Situnayake</b>
</p>
<p>this was a super super fun book to tech review! neural networks on microcontrollers?!?
   yes please!
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/ec.jpg"></p>
<p><b><a href="https://www.wiley.com/en-us/Evolutionary+Computation%3A+Toward+a+New+Philosophy+of+Machine+Intelligence%2C+3rd+Edition-p-9780471669517">Evolutionary Computation</a> by David Fogel</b>
</p>
<p>this is still by favorite book on evolutionary algorithms; i've had this for a loooong
   time now. i still feel like evolutionary approaches are due for a big big comeback
   any time soon....
</p>
<hr>


<h2>in the mail...</h2>
<p>the good thing about writing a list is you get people telling you cool ones you've missed :)
</p>
<p>the top three i've chosen (that are in the mail) are...
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/ciis.jpg"></p>
<p><b><a href="http://bayes.cs.ucla.edu/PRIMER/">Causal Inference in Statistics</a> by
   Judea Pearl, Madelyn Glymour &amp; Nicholas P. Jewell</b>
</p>
<p>recommended by <a href="https://twitter.com/animesh_garg">animesh</a> who quite rightly points out
   the lack of causality in machine learning books in the books above.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/itiala.jpg"></p>
<p><b><a href="https://www.cambridge.org/au/academic/subjects/computer-science/pattern-recognition-and-machine-learning/information-theory-inference-and-learning-algorithms?format=HB&amp;isbn=9780521642989">Information Theory, Inference and Learning Algorithms</a> by David MacKay</b>
</p>
<p>i've seen this book mentioned a number of times and was most recently recommended by
   my colleague <a href="https://twitter.com/danesherbs">dane</a> so it's time to get it.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/bmlpa.jpg"></p>
<p><b><a href="https://www.oreilly.com/library/view/building-machine-learning/9781492045106/">Building Machine Learning Powered Applications</a> by Emmanuel Ameisen</b>
</p>
<p>a number of people i worked with have enjoyed this. first recommended by another
   colleague <a href="https://twitter.com/davidcolls">dave</a>.
   looks to be on the practical side rather than the theory but that's ok some times :)
</p>

  </div></div>]]>
            </description>
            <link>http://matpalm.com/blog/cool_machine_learning_books/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031455</guid>
            <pubDate>Mon, 09 Nov 2020 04:26:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How does the event loop work in JavaScript? [video]]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25031384">thread link</a>) | @krayonatan
<br/>
November 8, 2020 | https://yonatankra.com/how-does-the-event-loop-work/ | <a href="https://web.archive.org/web/*/https://yonatankra.com/how-does-the-event-loop-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="primary"><main id="main" role="main"><article id="post-599"><div><!-- .entry-meta --><div> <p><span><span>Estimated Reading Time: </span> <span>&lt; 1</span> <span>minute</span></span></p><figure><p><span><iframe width="640" height="360" data-src="https://www.youtube.com/embed/Nqx3rtv_dko?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en-US&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span></p><figcaption>The event loop and your code talk from WarsawJS</figcaption></figure><p>On august 2020 I spoke at <a rel="noreferrer noopener" href="https://warsawjs.com/" data-type="URL" data-id="https://warsawjs.com/" target="_blank">WarsawJS</a>, explaining about the event loop and how it works.  I hope you will enjoy this talk.</p><p>If you prefer to read – <a href="https://yonatankra.com/the-event-loop-and-your-code/" data-type="post" data-id="299">here’s the blog post this talk is based on</a>.</p><p id="jp-relatedposts"><h3><em>Related</em></h3></p></div><!-- .entry-content --><!-- .entry-footer --></div></article><!-- #post-## --><p><h3>Enjoyed the article?</h3><h4>Sign up to my newsletter to enjoy more content:</h4></p>  <nav role="navigation" aria-label="Posts"><h2>Post navigation</h2></nav><!-- #comments --></main><!-- #main --></div></div>]]>
            </description>
            <link>https://yonatankra.com/how-does-the-event-loop-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031384</guid>
            <pubDate>Mon, 09 Nov 2020 04:12:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid-19 The Biden-Harris plan to beat Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25031354">thread link</a>) | @hkhn
<br/>
November 8, 2020 | https://buildbackbetter.com/priorities/covid-19/ | <a href="https://web.archive.org/web/*/https://buildbackbetter.com/priorities/covid-19/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	

		<section id="content">

	  
<div data-module="">
  <div>
	<div>
	  <p><span>The American people deserve an urgent, robust, and professional response to the growing public health and economic crisis caused by the coronavirus (COVID-19) outbreak. President-elect Biden believes that the federal government must act swiftly and aggressively to help protect and support our families, small businesses, first responders, and caregivers essential to help us face this challenge, those who are most vulnerable to health and economic impacts, and our broader communities – not to blame others or bail out corporations. </span></p>
	</div>
  </div>
</div>

<div data-module="" id="covid-19-2" data-new-section="false" data-id="covid-19-2">
  <div>
	<div>
	  <div>
	   <p>The Biden-Harris administration will always:</p>
<ul>
<li><strong>Listen to science</strong></li>
<li><strong>Ensure public health decisions are informed by public health professionals</strong></li>
<li><strong>Promote trust, transparency, common purpose, and accountability in our government</strong></li>
</ul>
<p>President-elect Biden and Vice President-elect Harris have a seven-point plan to beat COVID-19.</p>
<p><strong>Ensure all Americans have access to regular, reliable, and free testing.</strong></p>
<ul>
<li>Double the number of drive-through testing sites.</li>
<li>Invest in next-generation testing, including at home tests and instant tests, so we can scale up our testing capacity by orders of magnitude.</li>
<li>Stand up a Pandemic Testing Board like Roosevelt’s War Production Board. It’s how we produced tanks, planes, uniforms, and supplies in record time, and it’s how we will produce and distribute tens of millions of tests.</li>
<li>Establish a U.S. Public Health Jobs Corps to mobilize at least 100,000 Americans across the country with support from trusted local organizations in communities most at risk to perform culturally competent approaches to contact tracing and protecting at-risk populations.</li>
</ul>
<p><strong>Fix personal protective equipment (PPE) problems for good.</strong></p>
<p>President-elect Joe Biden is taking responsibility and giving states, cities, tribes, and territories the critical supplies they need.</p>
<ul>
<li>Fully use the Defense Production Act to ramp up production of masks, face shields, and other PPE so that the national supply of personal protective equipment exceeds demand and our stores and stockpiles — especially in hard-hit areas that serve disproportionately vulnerable populations — are fully replenished.</li>
<li>Build immediately toward a future, flexible American-sourced and manufactured capability to ensure we are not dependent on other countries in a crisis.</li>
</ul>
<p><strong>Provide clear, consistent, evidence-based guidance for how communities should navigate the pandemic – and the resources for schools, small businesses, and families to make it through.</strong></p>
<ul>
<li>Social distancing is not a light switch. It is a dial. President-elect Biden will direct the CDC to provide specific evidence-based guidance for how to turn the dial up or down relative to the level of risk and degree of viral spread in a community, including when to open or close certain businesses, bars, restaurants, and other spaces; when to open or close schools, and what steps they need to take to make classrooms and facilities safe; appropriate restrictions on size of gatherings; when to issue stay-at-home restrictions.</li>
<li>Establish a renewable fund for state and local governments to help prevent budget shortfalls, which may cause states to face steep cuts to teachers and first responders.</li>
<li>Call on Congress to pass an emergency package to ensure schools have the additional resources they need to adapt effectively to COVID-19.</li>
<li>Provide a “restart package” that helps small businesses cover the costs of operating safely, including things like plexiglass and PPE.</li>
</ul>
	  </div>
	</div>
  </div>
</div>

<!-- .module.block-quote -->

<div data-module="" id="covid-19-4" data-new-section="false" data-id="covid-19-4">
  <div>
	<div>
	  <div>
	   <p><strong>Plan for the effective, equitable distribution of treatments and vaccines — because development isn’t enough if they aren’t effectively distributed.</strong></p>
<ul>
<li>Invest $25 billion in a vaccine manufacturing and distribution plan that will guarantee it gets to every American, cost-free.</li>
<li>Ensure that politics plays no role in determining the safety and efficacy of any vaccine. The following 3 principles will guide the Biden-Harris administration: Put scientists in charge of all decisions on safety and efficacy; publicly release clinical data for any vaccine the FDA approves; and authorize career staff to write a written report for public review and permit them to appear before Congress and speak publicly uncensored.</li>
<li>Ensure everyone — not just the wealthy and well-connected — in America receives the protection and care they deserve, and consumers are not price gouged as new drugs and therapies come to market.</li>
</ul>
<p><strong>Protect older Americans and others at high risk.</strong></p>
<p>President-elect Biden understands that older Americans and others at high-risk are most vulnerable to COVID-19.</p>
<ul>
<li>Establish a COVID-19 Racial and Ethnic Disparities Task Force, as proposed by Vice President-elect Harris, to provide recommendations and oversight on disparities in the public health and economic response. At the end of this health crisis, it will transition to a permanent Infectious Disease Racial Disparities Task Force.</li>
<li>Create the Nationwide Pandemic Dashboard that Americans can check in real-time to help them gauge whether local transmission is actively occurring in their zip codes. This information is critical to helping all individuals, but especially older Americans and others at high risk, understand what level of precaution to take.</li>
</ul>
<p><strong>Rebuild and expand defenses to predict, prevent, and mitigate pandemic threats, including those coming from China.</strong></p>
<ul>
<li>Immediately restore the White House National Security Council Directorate for Global Health Security and Biodefense, originally established by the Obama-Biden administration.</li>
<li>Immediately restore our relationship with the World Health Organization, which — while not perfect — is essential to coordinating a global response during a pandemic.</li>
<li>Re-launch and strengthen U.S. Agency for International Development’s pathogen-tracking program called PREDICT.</li>
<li>Expand the number of CDC’s deployed disease detectives so we have eyes and ears on the ground, including rebuilding the office in Beijing.</li>
</ul>
<p><strong>Implement mask mandates nationwide by working with governors and mayors and by asking the American people to do what they do best: step up in a time of crisis.</strong></p>
<p>Experts agree that tens of thousands of lives can be saved if Americans wear masks. President-elect Biden will continue to call on:</p>
<ul>
<li>Every American to wear a mask when they are around people outside their household.</li>
<li>Every Governor to make that mandatory in their state.</li>
<li>Local authorities to also make it mandatory to buttress their state orders.</li>
</ul>
<p>Once we succeed in getting beyond this pandemic, we must ensure that the millions of Americans who suffer long-term side effects from COVID don’t face higher premiums or denial of health insurance because of this new pre-existing condition. The Biden-Harris Administration will work to ensure that the protections for those with pre-existing conditions that were won with Obamacare are protected. And, they will work to lower health care costs and expand access to quality, affordable health care through a Medicare-like public option.</p>
	  </div>
	</div>
  </div>
</div>



	</section>

  </article></div>]]>
            </description>
            <link>https://buildbackbetter.com/priorities/covid-19/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031354</guid>
            <pubDate>Mon, 09 Nov 2020 04:04:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A fun website that simulates fluid]]>
            </title>
            <description>
<![CDATA[
Score 112 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25031304">thread link</a>) | @svikashk
<br/>
November 8, 2020 | https://paveldogreat.github.io/WebGL-Fluid-Simulation/ | <a href="https://web.archive.org/web/*/https://paveldogreat.github.io/WebGL-Fluid-Simulation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        <p>Try Fluid Simulation app!</p>
                        <p><a id="apple_link" target="_blank">
                                <img alt="Download on the App Store" src="https://paveldogreat.github.io/WebGL-Fluid-Simulation/app_badge.png">
                            </a>
                            <a id="google_link" target="_blank">
                                <img alt="Get it on Google Play" src="https://paveldogreat.github.io/WebGL-Fluid-Simulation/gp_badge.png">
                            </a>
                        </p>
                    </div></div>]]>
            </description>
            <link>https://paveldogreat.github.io/WebGL-Fluid-Simulation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031304</guid>
            <pubDate>Mon, 09 Nov 2020 03:54:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Program Development in Limbo for Inferno OS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25030961">thread link</a>) | @marttt
<br/>
November 8, 2020 | https://seh.dev/limbo-intro/ | <a href="https://web.archive.org/web/*/https://seh.dev/limbo-intro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
    <div>
<h2 id="motivation">Motivation</h2>
<p>Resources covering software development under Inferno are fairly scarce.</p>
<p>As such, this post aims to provide a start-to-finish demonstration of program development in Limbo inside Inferno.</p>
<h2 id="introduction">Introduction</h2>
<p>This post assumes you’re using Inferno, specifically <a href="https://code.9front.org/hg/purgatorio/">purgatorio</a>, hosted under <code>linux/amd64</code> or similar.</p>
<p>It’s also possible to use Inferno under Docker as per the <code>INSTALL</code> file.</p>
<p>Other platforms are supported, but steps may differ here or there.</p>
<p>The rune <code>$</code> indicates a unix shell command under <code>bash</code>, probably.</p>
<p>The rune <code>;</code> or <code>%</code> indicates a command to be run from inside Inferno.</p>
<p>The final source from this post: <a href="https://github.com/henesy/socketh-limbo">https://github.com/henesy/socketh-limbo</a></p>
<p>This post will be an implementation of <a href="https://github.com/henesy/SocketH">SocketH</a> which was originally written in Go and has a few other implementations:</p>
<ul>
<li><a href="https://github.com/henesy/socketh-myr">https://github.com/henesy/socketh-myr</a></li>
<li><a href="https://github.com/henesy/SocketS">https://github.com/henesy/SocketS</a></li>
</ul>
<p>The original code isn’t great, but it gives a target for what we want to create.</p>
<h2 id="getting-started">Getting started</h2>
<p>Many, if not all, of these development steps prior to <em>running</em> the final Dis bytecode can be done from outside of Inferno.</p>
<p>The limbo compiler can be called as <code>limbo</code> and with the right workflow development may be more pleasant.</p>
<p>This post assumes:</p>
<ul>
<li>Development occurs inside of Inferno for the purpose of consistency</li>
<li>Some knowledge about imperative, C-like, language programming</li>
<li>Some knowledge about how unix-like systems work</li>
<li>Some knowledge about how C-like compiler and linker flows work</li>
<li>Knowledge about how to interact with a unix-like shell</li>
<li>Vague knowledge about Inferno, such as the fact Inferno exists ☺</li>
</ul>
<h3 id="build-inferno">Build Inferno</h3>
<p>Steps provided are targeted for <code>linux/amd64</code> as a host for Inferno.</p>
<p>The official <a href="https://bitbucket.org/inferno-os/inferno-os/">Inferno</a> tree is hosted over <a href="https://git-scm.com/">Git</a>.</p>
<p>The <a href="https://code.9front.org/hg/purgatorio/">purgatorio</a> fork is hosted by the 9front project over <a href="https://www.mercurial-scm.org/">Mercurial</a>.</p>
<p>Cloning:</p>
<div><pre><code data-lang="text">$ hg clone https://code.9front.org/hg/purgatorio
destination directory: purgatorio
requesting all changes
adding changesets
adding manifests
adding file changes
added 86 changesets with 10904 changes to 10545 files
new changesets 78950db8e089:749c484c1b9c
updating to branch default
9584 files updated, 0 files merged, 0 files removed, 0 files unresolved
$ cd purgatorio/
$ ls
acme                     FreeBSD  libdynld     libprefab      mkfile       scripts
AIX                      icons    libfreetype  libsec         mkfiles      services
appl                     include  libinterp    libtk          module       Solaris
bitbucket-pipelines.yml  Inferno  libkern      limbo          NetBSD       tools
CHANGES                  INSTALL  libkeyring   Linux          NOTICE       usr
dis                      Irix     liblogfs     locale         Nt           utils
doc                      keydb    libmath      MacOSX         OpenBSD
Dockerfile               lib      libmemdraw   makemk-AIX.sh  os
DragonFly                lib9     libmemlayer  makemk.sh      Plan9
emu                      libbio   libmp        man            POSTINSTALL
fonts                    libdraw  libnandfs    mkconfig       README.md
$
</code></pre></div><p><strong>Read the</strong> <code>INSTALL</code> <strong>file!</strong></p>
<p>Update our <code>$HOME/.profile</code> to reflect the Inferno install, adapt this to your directories:</p>
<div><pre><code data-lang="text">export EMU='-g1280x960 -c1'
export INFERNO=$HOME/repos/purgatorio
export PATH=$PATH:$INFERNO/Linux/386/bin
</code></pre></div><p>Reload our shell currently in the purgatorio root tree:</p>
<div><pre><code data-lang="text">$ source $HOME/.profile
$
</code></pre></div><p>Update the <code>mkconfig</code> file to reflect our environment, adapt this as needed:</p>
<div><pre><code data-lang="text">ROOT=$HOME/repos/purgatorio

TKSTYLE=std

CONF=emu

SYSHOST=Linux		# build system OS type (Hp, Inferno, Irix, Linux, MacOSX, Nt, Plan9, Solaris)
SYSTARG=$SYSHOST	# target system OS type (Hp, Inferno, Irix, Linux, Nt, Plan9, Solaris)

OBJTYPE=386

OBJDIR=$SYSTARG/$OBJTYPE

&lt;$ROOT/mkfiles/mkhost-$SYSHOST			# variables appropriate for host system
&lt;$ROOT/mkfiles/mkfile-$SYSTARG-$OBJTYPE	# variables used to build target object type
</code></pre></div><p>Enable multi-arch support on debian-based distributions if on amd64 (64-bit) as Inferno is 32-bit only:</p>
<div><pre><code data-lang="text">$ dpkg --add-architecture i386
$ apt-get update
</code></pre></div><p>Install dependencies required to compile Inferno, this example shows dependencies for debian-based (Ubuntu) distributions:</p>
<div><pre><code data-lang="text">$ apt install libc6-dev-i386 libxext6:i386 libx11-dev:i386 libxext-dev:i386 libfontconfig1-dev:i386
…
$
</code></pre></div><p>Build <code>mk</code> which will be used to bootstrap the rest of the process:</p>
<p>Build and install Inferno!</p>
<div><pre><code data-lang="text">$ mk mkdirs
…
$ mk clean
…
$ mk install
…
$
</code></pre></div><h3 id="start-inferno">Start Inferno</h3>
<p>A graphical environment should appear.</p>
<p>You can make the gui window for Inferno larger by passing in a different size to <code>emu</code> as per <a href="http://man.postnix.pw/purgatorio/1/emu">the manual</a>:</p>
<div><pre><code data-lang="text">-gXsizexYsize
	Define screen width and height in pixels.  The default
	values are 640x480 and the minimum values are 64x48.
	Values smaller than the minimum or greater than the
	available display size are ignored.
</code></pre></div><p>thus:</p>
<p>and so forth.</p>
<p>Some programs can be found under the start menu in the bottom left corner decorated with the <a href="https://seh.dev/limbo-intro/vitanuova.com/">Vita Nuova</a> logo:</p>
<p><img src="http://www.vitanuova.com/images/vitanuova.jpg" alt="Vita Nuova’s logo"></p>
<p>The <code>Shell</code> entry in the start menu will provide a shell-interpreter window from which further commands can be run inside Inferno.</p>
<h3 id="preparation">Preparation</h3>
<div><pre><code data-lang="text">% cd $home/appl
% os git clone https://github.com/henesy/socketh-limbo
% cd socketh-limbo
% lc
.git/     LICENSE   README.md
% touch .gitignore socketh.b
% acme socketh.b
</code></pre></div><p><code>.gitignore</code>:</p>
<p>Limbo ‘libraries’, known as ‘modules’, and ‘programs’ are one and the same in terms of semantics, bar ‘libraries’ having module <code>.m</code> files which are similar to header <code>.h</code> files in C.</p>
<p>As such, the boilerplate for most Limbo programs is very similar. We can initialize our main file as follows.</p>
<p><code>socketh.b</code>:</p>
<div><pre><code data-lang="c">implement SocketH;

include <span>"sys.m"</span>;
	<span>sys</span>: Sys;

include <span>"draw.m"</span>;
include <span>"arg.m"</span>;

<span>SocketH</span>: module {
	<span>init</span>: fn(<span>nil</span>: ref Draw<span>-&gt;</span>Context, <span>argv</span>: list of string);
};


<span># An implementation of the SocketH chat protocol
</span><span></span>init(<span>nil</span>: ref Draw<span>-&gt;</span>Context, <span>argv</span>: list of string) {
	sys <span>=</span> load Sys Sys<span>-&gt;</span>PATH;
	<span>arg</span> :<span>=</span> load Arg Arg<span>-&gt;</span>PATH;
	<span>if</span>(arg <span>==</span> nil)
		raise <span>"could not load arg"</span>;



	exit;
}
</code></pre></div><p>We can break this down a bit.</p>
<p><code>implement</code> declares a module by name.</p>
<p>A module definition must be provided indicating exported functions from the module:</p>
<div><pre><code data-lang="text">SocketH: module {
	init: fn(nil: ref Draw-&gt;Context, argv: list of string);
};
</code></pre></div><p>Note how a variable name of <code>nil</code> is used to drop assignment of a value.</p>
<p>The <code>init</code> function is special in shell-loaded Limbo programs and its signature <em>must</em> match what the shell expects the init function interface to be.</p>
<p>Functionally, <code>init</code> is equivalent to <code>main</code> in most other languages.</p>
<p><code>include</code> imports an external module’s definitions into our scope.</p>
<p><code>load</code> performs the dynamic loading of a module at runtime.</p>
<p><code>exit</code> performs the dynamic un-loading of a module at runtime.</p>
<p><code>raise</code> will throw an exception with a given string as its content.</p>
<p>We refer to names inside a module using the <code>-&gt;</code> operator.</p>
<p>We can jointly assign and declare in one step using the <code>:=</code> operator.</p>
<p>Curly braces are optional.</p>
<p>Semicolons are not.</p>
<p>Note the absence of a reserved <code>main</code> module. This is due to each <code>.dis</code> file, potentially an independent module, being theoretically loadable in its own right. A reserved name would cause significant issues with namespaces ☺.</p>
<h3 id="setting-up-a-workflow">Setting up a workflow</h3>
<p>Compiling our program should be as straightforward as running the Limbo compiler against our source file:</p>
<div><pre><code data-lang="text">% limbo socketh.b
% lc
.git/		LICENSE		socketh.b
.gitignore	README.md	socketh.dis
% socketh.dis
%
</code></pre></div><p>This program does nothing right now, but that’s fine.</p>
<p>Note how we can omit the <code>./</code> when running <code>.dis</code> programs.</p>
<p>Calling the limbo compiler each time is a bit of a pain, and if we start using commandline flags this will become tedious to type.</p>
<p>In acme, we could type the text we want to run in a tag or window and middle-click said text to run the compilation (or more!) on-demand. In Inferno, acme comes with a <code>Limbo</code> command in the default window tag, but that only works for one file.</p>
<p>We can simplify this process by writing a <s>makefile</s> <a href="http://doc.cat-v.org/bell_labs/mk/">mkfile</a>!</p>
<p><code>mkfile</code>:</p>
<div><pre><code data-lang="text">&lt;/mkconfig

DISBIN = /dis

TARG = socketh.dis

&lt;/mkfiles/mkdis
</code></pre></div><p>Mk semantics are similar to make with some changes.</p>
<p>How mk will behave inside Inferno using the <code>mkdis</code> mkfile as the trailing import:</p>
<ul>
<li>Mk can import outside mkfiles using the <code>&lt;</code> operator</li>
<li><code>mk</code> will call <code>mk all</code> which resolves to the <code>all</code> (default) target</li>
<li><code>mk install</code> calls the <code>all</code> target and copies the <code>TARG</code> file(s) to the <code>DISBIN</code> destination directory</li>
<li><code>mk clean</code> removes files such as <code>.dis</code> and <code>.sbl</code> from the working directory</li>
<li><code>mk nuke</code> calls the <code>clean</code> target as well as delete the ‘target’ files such as the <code>/dis/socketh</code> binary if the <code>install</code> target has been called</li>
</ul>
<p>A demonstration:</p>
<div><pre><code data-lang="text">% lc
.git/		LICENSE		mkfile
.gitignore	README.md	socketh.b
% mk
limbo -I/module -gw socketh.b
socketh.b:15: warning: argument argv not referenced
% lc
.git/		LICENSE		mkfile		socketh.dis
.gitignore	README.md	socketh.b	socketh.sbl
% mk install
rm -f /dis/socketh.dis &amp;&amp; cp socketh.dis /dis/socketh.dis
% mk clean
rm -f *.dis *.sbl
% whatis socketh
/dis/socketh.dis
% mk nuke
rm -f *.dis *.sbl
cd /dis; rm -f socketh.dis
% whatis socketh.dis
socketh.dis: not found
% lc
.git/		LICENSE		mkfile
.gitignore	README.md	socketh.b
%
</code></pre></div><p>Note the Limbo compiler flags being passed by default now for the <code>all</code> target.</p>
<p>At this point, I usually add <code>mk clean &amp;&amp; mk</code> to my acme tag and run that for multi-file or more complex Limbo programs. This flow is very similar to how I do development under Plan 9.</p>
<h3 id="common-patterns">Common patterns</h3>
<h4 id="commandline-flags">Commandline flags</h4>
<p>We can use <a href="https://seh.dev/limbo-intro/man.postnix.pw/purgatorio/2/arg">arg(2)</a> to process commandline flags:</p>
<div><pre><code data-lang="c"><span>…</span>

<span>chatty</span>: <span>int</span>	<span>=</span> <span>0</span>;	<span>#</span> Verbose debug output


<span># An implementation of the SocketH chat protocol
</span><span></span>init(<span>nil</span>: ref Draw<span>-&gt;</span>Context, <span>argv</span>: list of string) {
	sys <span>=</span> load Sys Sys<span>-&gt;</span>PATH;
	<span>arg</span> :<span>=</span> load Arg Arg<span>-&gt;</span>PATH;
	<span>if</span>(arg <span>==</span> nil)
		raise <span>"could not load arg"</span>;

	<span>addr</span>: string <span>=</span> <span>"tcp!*!9090"</span>;

	arg<span>-&gt;</span>init(argv);
	arg<span>-&gt;</span>setusage(<span>"socketh [-D] [-a addr]"</span>);

	<span>while</span>((<span>c</span> :<span>=</span> arg<span>-&gt;</span>opt()) <span>!=</span> <span>0</span>)
		<span>case</span> c {
		<span>'D'</span> <span>=&gt;</span>
			chatty<span>++</span>;

		<span>'a'</span> <span>=&gt;</span>
			addr <span>=</span> arg<span>-&gt;</span>earg();

		<span>*</span> <span>=&gt;</span>
			arg<span>-&gt;</span>usage();
		}

	argv <span>=</span> arg<span>-&gt;</span>argv();



	exit;
}
</code></pre></div><p>We can see how these flags are parsed and how these functions act:</p>
<div><pre><code data-lang="text">% mk
mk: 'all' is up to date
% socketh -h
usage: socketh [-D] [-a addr]
% socketh -D
% socketh -a
usage: socketh [-D] [-a addr]
% socketh -a -D
% socketh -D -a
usage: socketh [-D] [-a …</code></pre></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://seh.dev/limbo-intro/">https://seh.dev/limbo-intro/</a></em></p>]]>
            </description>
            <link>https://seh.dev/limbo-intro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25030961</guid>
            <pubDate>Mon, 09 Nov 2020 02:43:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Attention Is My Most Valuable Asset for Productivity as a Software Developer]]>
            </title>
            <description>
<![CDATA[
Score 226 | Comments 89 (<a href="https://news.ycombinator.com/item?id=25030938">thread link</a>) | @zwbetz
<br/>
November 8, 2020 | https://zwbetz.com/attention-is-my-most-valuable-asset-for-productivity-as-a-software-developer/ | <a href="https://web.archive.org/web/*/https://zwbetz.com/attention-is-my-most-valuable-asset-for-productivity-as-a-software-developer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content">
      <div>
        <div>
          <div>
            
  
  
  <p>
    
    
    
    <strong>Published: </strong>2020-11-08

    
    
      
      
        • <strong>Lastmod: </strong>2020-11-09

      
    
    
    
    
      <br>
      <span>
        <strong>Tags: </strong>
        
          
          
          
        
          
          
          
        
          
          
          
        
        <a href="https://zwbetz.com/tags/life/">life</a> • <a href="https://zwbetz.com/tags/attention/">attention</a> • <a href="https://zwbetz.com/tags/productivity/">productivity</a>
      
    </span>
  </p>
  
  
  
  

<p>Like a tightly written function, I prefer to exit early if no work should be done. So, if you disagree with these definitions and assumptions, now’s a good time to stop reading.</p>
<ul>
<li><strong>Sustainable productivity:</strong> The maximum rate of quality work output, without loss to the wellbeing of the developer</li>
<li><strong>Quality work:</strong> Software that meets requirements, is valuable to users, is maintainable, and is as bug free as possible</li>
<li><strong>Attention:</strong> The limited mental capacity to focus on a task</li>
<li>Sustainable productivity is desired</li>
<li>Attention is essential to sustainable productivity</li>
</ul>
<p>My high-level workflow looks something like this: identify the problem to solve; think on the problem and let ideas percolate; research, discuss, and experiment with these ideas; implement and test the solution; deliver and maintain the solution.</p>
<p>This cycle could repeat many times in a day. Or I could spend days stuck on a single cycle step. Every step in this cycle requires attention. The more attention I can devote, the more cycles I can complete, and the more productive I am.</p>
<p>How long you can focus on a task varies by person. Some people are very good at it out of the box, some people, not so much. Regardless of the hand you were dealt, I believe that focus (the act of devoting your attention) is a skill, and like any skill, can be improved with practice.</p>
<p>So, how can you increase your attention reserves? The most bang for your buck is to organize your outside world in such a way that it’s distraction free as possible. Once you do that, you’ll have more time to practice, and therefore more time to get better.</p>
<p><strong>Build physical strength.</strong> The damage done by sitting 8+ hours a day is underrated. You need a way to offset this damage, especially if you plan to work in this field for decades. Opinions abound on this topic, but I personally prefer deadlifts. There are few movements more primal than picking a heavy object off the ground and standing up with it. You can <a href="https://www.youtube.com/watch?v=wYREQkVtvEc">learn correct technique in little time</a>. I most like deadlifts because you can do them safely, at high weights, into old age. I also like the hand, back, and hip strength they give, to make it that much harder for sitting damage to have its way with you.</p>
<p><strong>Make your place of work boring and tidy.</strong> My office is a spare bedroom. The walls are blank. There’s no tv. There’s a desk, chair, laptop, laptop stand, keyboard, mouse, and mouse pad. There’s a window, which lets enough light in so that I don’t feel like I’m missing a beautiful day, but not too much light to cause screen glare. If I need to work with paper, it’s immediately filed somewhere when done. Like I said, boring and tidy.</p>
<p><strong>Make your smart phone dumb.</strong> My phone has all notifications disabled, except for calls and text messages. Well, and National Hurricane Center alerts, since I live in Louisiana. Unless you’re my wife, you know that I don’t respond to text messages immediately, that’s just how it is. I disabled my social media accounts some time ago. But if you have them, turning off notifications should help curve the urge to compulsively check them.</p>
<p><strong>Be an OS minimalist.</strong> Apps I use less commonly are a keypress combo away. Given this, my dock has only the apps I use on a daily basis:</p>
<ul>
<li>File system explorer</li>
<li>Internet browser</li>
<li>Terminal</li>
<li>Text editor for front-end code and notes</li>
<li>IDE for back-end code</li>
<li>IDE for database</li>
<li>Visual file differ for version control</li>
<li>Email client</li>
<li>Instant message client</li>
</ul>
<p>My desktop alternates between clean and dirty states. Files I’m currently working with live on the desktop. Then they’re filed away into sensible folders when done.</p>
<p><strong>Organize your browser bookmarks.</strong> When I read something useful that I may need to reference later, I file it under a general archive folder. Then more specific items get their own folders. Frequently accessed links are visible on my bookmarks bar under their own folder.</p>
<p><strong>Minimize meetings.</strong> Look, I know some things make sense to discuss face to face, or voice to voice. But if they don’t, then you don’t need a meeting. An email or instant message will suffice.</p>
<p><strong>Finally, use the <a href="https://en.wikipedia.org/wiki/Time_management#The_Eisenhower_Method">The Eisenhower Method</a> to categorize your tasks.</strong> Imagine a grid of 4 quadrants:</p>
<ul>
<li>Important and Urgent</li>
<li>Important and Not Urgent</li>
<li>Not Important and Urgent</li>
<li>Not Important and Not Urgent</li>
</ul>
<p>Important and Urgent tasks have to be dealt with. For me, these are usually major production issues.</p>
<p>Important and Not Urgent tasks should absorb the bulk of your time. For me, this is the plain old development work of implementing features, fixing bugs, and making existing code more maintainable and performant. Also included are building relationships with others and planning ahead.</p>
<p>Not Important and Urgent tasks are nasty attention thieves. They shout out to you in immediacy, but offer little value in return. You know what these are for you. For me, these are most often lazily asked questions, where the asker did not do their due diligence, and expects a top-notch answer immediately. Also included are last-minute meetings, and over-talkative coworkers.</p>
<p>Not Important and Not Urgent tasks are usually not known to your users. Take internal documentation updates as an example. Thing is, they’re an investment in yourself, which means a more productive future “you”. So don’t forget to show them some love in your spare moments.</p>
<p><strong>Further reading.</strong> If you don’t know who Cal Newport is, you’re missing out. He has a whole blog dedicated to this type of thing, and has written books such as <em>Deep Work</em> and <em>Digital Minimalism</em>. Here are some of my favorite articles by him:</p>
<ul>
<li><a href="https://www.calnewport.com/blog/2009/02/04/have-we-lost-our-tolerance-for-a-little-boredom/">Have We Lost Our Tolerance For a Little Boredom?</a></li>
<li><a href="https://www.calnewport.com/blog/2010/06/10/is-allowing-your-child-to-study-while-on-facebook-morally-equivalent-to-drinking-while-pregnant/">Is Allowing Your Child to Study While on Facebook Morally Irresponsible?</a></li>
<li><a href="https://www.calnewport.com/blog/2008/04/07/monday-master-class-how-to-reduce-stress-and-get-more-done-by-building-an-autopilot-schedule/">Monday Master Class: How to Reduce Stress and Get More Done By Building an Autopilot Schedule</a></li>
<li><a href="https://www.calnewport.com/blog/2009/11/24/are-passions-serendipitously-discovered-or-painstakingly-constructed/">Are Passions Serendipitously Discovered or Painstakingly Constructed?</a></li>
<li><a href="https://www.calnewport.com/blog/2018/06/08/jerry-seinfelds-closed-door/">Jerry Seinfeld’s Closed Door</a></li>
</ul>



  
  
  

  
  




          </div>
        </div>
      </div>
    </div></div>]]>
            </description>
            <link>https://zwbetz.com/attention-is-my-most-valuable-asset-for-productivity-as-a-software-developer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25030938</guid>
            <pubDate>Mon, 09 Nov 2020 02:39:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Windows 10 Installer Dystopia]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25030752">thread link</a>) | @brenns10
<br/>
November 8, 2020 | https://brennan.io/2020/11/08/windows-10-nightmare-edition/ | <a href="https://web.archive.org/web/*/https://brennan.io/2020/11/08/windows-10-nightmare-edition/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

  
<p><em>Stephen Brennan • 08 November 2020</em></p><p>A few days ago I had the displeasure of helping a friend reinstall Windows on
their laptop, which had previously contained Ubuntu. The reason for their switch
isn’t that important – although I helpfully suggested keeping Linux, it was
their machine and their decision. I didn’t expect the process to be particularly
difficult. After all, I work on operating systems for a living now, so I didn’t
expect any trouble. But to my surprise, I encountered a nearly dystopian
situation before I even got to the desktop.</p>

<p>I started the process by creating a bootable USB from the ISO downloaded from
Microsoft’s <a href="https://www.microsoft.com/en-us/software-download/windows10ISO">download page</a>. It feels weird writing that, but yes, the ISO
seems to be freely, easily downloaded. No product key was required to download,
or even install. The USB creation process was not easy (Microsoft suggests using
Windows to create the bootable USB, a chicken-and-egg problem if ever there was
one). It seems that the standard <code>dd</code> process used by every Linux vendor does
not work here – instead you need to get the correct magic incantations of
partition types and filesystems, and then copy files from the ISO file into the
USB. I ended up falling back to a tool called <a href="https://github.com/slacka/WoeUSB">WoeUSB</a> to do this process,
after three failed manual attempts.</p>

<p>The real fun started after I (finally) successfully booted from the USB and
started through the installation wizard. Cortana loudly greeted me, telling me
she’d walk me through the installation process using my voice. I must say that,
while I don’t really care to have a voice assistant guide me through OS
installation, I can see it helping a lot of folks out there, if it works
properly (I did not test it). I’m glad that Microsoft is at least trying this
out!</p>

<p>I went through the (impressively quick) installation process, and the laptop
automatically rebooted. It prompted me to connect to the Internet, which I
foolishly did. Directly after connecting to WiFi, the wizard asked me to login
with a Microsoft account!</p>

<p>I chuckled internally. “Classic Microsoft, asking for a silly cloud login just
to use Windows,” I thought. I don’t know my friend’s MS account login, and even
if I did I wouldn’t link their OS account to some cloud account!</p>

<p>I searched for the cancel button, but couldn’t find one. I tried to submit the
form with empty username and password, but that didn’t work. Realizing that I
might be trapped, I got my phone and fired up Google.  Surely, Microsoft
wouldn’t make it <em>impossible</em> to setup a new PC without linking it to their
cloud, right?</p>

<p>I found an <a href="https://helpdeskgeek.com/windows-10/how-to-setup-windows-10-without-a-microsoft-account/">article</a> which said that, by disabling the Internet connection I
had just configured, I could skip the login process. So, I hit the back button
on the installer. The wizard animated for a moment as if it was working, and
then showed me the same login screen. No matter how many times I hit the back
button, the wizard did not let me go back to the Internet configuration page!</p>

<p>“They haven’t got me yet,” I thought. I held down the power button and rebooted
the computer. Certainly on reboot I would restart the process, and could skip
the Internet configuration, right?</p>

<p>The laptop rebooted to a Microsoft Account login page.</p>

<p>So, I did what any self-respecting, conscientious friend would do for a friend:
<strong>I reinstalled Windows all over again.</strong>  This time, during the setup wizard
after the reboot, I skipped configuring an Internet connection. I was greeted
with this page:</p>

<p><img src="https://brennan.io/images/win10-nointernet.png" alt="win10-nointernet"></p>

<p>This, to me, felt kind of chilling. After all, it’s not like I asked not to use
a MS account. All I did was decide not to configure Internet on my first boot,
which has nothing to do with linking a MS account. After all, maybe I just don’t
have Internet access at the moment, or maybe I forgot the WiFi password.  Why
should the installer lecture me about the benefits of a MS account when simply I
did not configure WiFi? It felt obvious that this was a bald-faced statement:
“we know you’re avoiding our login process, and in a few years we’ll get rid of
this loophole too. Welcome to the future!”</p>

<p>I clicked the text (which wasn’t highlighted as a link or as a button) which
said “Continue with limited setup”. This was an odd phrasing, given that none of
the operating system features I’m familiar with (scheduling processes, providing
a unified interface to hardware devices, etc) requires a cloud account.</p>

<p>At this point, I was allowed to create a “local account” for my friend, and
finish the setup. I was presented with a list of preferences, all helpfully
enabled by default:</p>

<p><img src="https://brennan.io/images/win10-privacy.png" alt="win10-privacy"></p>

<p>The irony here is beautiful. Ads “may be less relevant to you”. The only entity
this harms is Microsoft, being able to avertise at you less (within your very
<em>operating system</em>, no less). Why should they bill this as a negative?</p>

<p>After disabling all of the toggles, the desktop loaded for the first time, I
noticed the following at the bottom right:</p>

<p><img src="https://brennan.io/images/win10-edge.png" alt="win10-edge"></p>

<p>I used MS Edge to install Firefox, and closed it out. On reboot, the login
screen contained two advertisements (!!!) for MS Edge. I returned the laptop to
my friend, grateful I didn’t have to use this horror show of an operating
system.</p>

<h2 id="why-does-this-even-matter">Why does this even matter?</h2>

<p>I spend my workday working on operating systems. Don’t get me wrong, I’m new to
the field, and I have a lot to learn. But as far as I know, <strong>there is no
feature in a modern operating system which requires a cloud account login.</strong> (I
would love to be educated if this claim is false, please get in touch!)</p>

<p>I used to spend my career working on machine learning and data analysis. One
thing I remember from my “past life” is that <strong>there’s nothing better than
linking different types of identifiers together.</strong> If Microsoft can track you by
your “Windows installation ID” and also by your “Microsoft Account”, then <em>of
course</em> they want to link those two identifiers together.</p>

<p>More links means more data about you. What applications you run, what sites you
visit, etc. An operating system as at the root of what you trust when you use a
computer. Do you use online banking? Your operating system can read the password
to your bank account, the balances, and more, directly out of memory! I’m not
suggesting that Windows does that – I just want to illustrate the sort of trust
you implicitly use every time you login to your bank account on Windows (or Mac
OS for that matter). But maybe Microsoft just looks at how frequently you login
to your computer, or what sites you’re interested in. What DNS queries does your
OS resolve? What IP addresses have you used in the last 90 days?</p>

<p>All of the data which is obvious to your operating system, can be linked to your
personal identity when you connect it to a cloud account. Don’t get me wrong,
even if you don’t connect it to a cloud account, you still are getting
incredible amounts of telemetry and tracking recording your every move. But why
would you voluntarily give more links and data to Microsoft?</p>

<p>I don’t think most people understand the sort of data they’re giving over to
Microsoft when they login and use Windows. These dark patterns that Microsoft
employs are sickeningly obvious, and really difficult to avoid. Why would I
trust a company that tries to manipulate its customers into such total data
collection, to be responsible with the data it receives?</p>

<p>I can’t imagine how frustrating it must be to be an operating system developer
at Microsoft. I have a lot of respect for the operating system kernel they make.
It seems to be one of the few major non-Unix like kernels out there. It seems
fascinating and I’d love to learn more about it. But it must be frustrating to
see the product of your hard work go out packaged with software capable of
collecting and tracking your users’ every move, and thrown together with an
installer intent on forcing them to submit to this data collection.</p>



<hr>



  
  

  </div></div>]]>
            </description>
            <link>https://brennan.io/2020/11/08/windows-10-nightmare-edition/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25030752</guid>
            <pubDate>Mon, 09 Nov 2020 02:02:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Observations from listening and producing 350 startup podcasts]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25030613">thread link</a>) | @JollyMerchant
<br/>
November 8, 2020 | https://viralwegrow.com/blog/observations-from-over-350-startup-podcasts/ | <a href="https://web.archive.org/web/*/https://viralwegrow.com/blog/observations-from-over-350-startup-podcasts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        




<main id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://viralwegrow.com/blog/content/images/size/w300/2020/11/istockphoto-165518488-170667a-1.jpg 300w,
                            https://viralwegrow.com/blog/content/images/size/w600/2020/11/istockphoto-165518488-170667a-1.jpg 600w,
                            https://viralwegrow.com/blog/content/images/size/w1000/2020/11/istockphoto-165518488-170667a-1.jpg 1000w,
                            https://viralwegrow.com/blog/content/images/size/w2000/2020/11/istockphoto-165518488-170667a-1.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://viralwegrow.com/blog/content/images/size/w2000/2020/11/istockphoto-165518488-170667a-1.jpg" alt="Observations from listening and producing 350+ startup podcasts">
            </figure>

            <section>
                <div>
                    <div><p>After listening to over 100 Nathan Latka Podcasts, observing 200 Indiehacker podcasts and watching 50 Microconf talks AND recording 80 episodes myself.</p><p>Here's what I've observed:</p><p><strong>SEO</strong><br>Over 70% of founders credited SEO for being their best source of growth. Invest into ASAP and build up that MOAT.</p><p><strong>FB / Social Media</strong><br>Its a hit or miss. Don't waste time curating the perfect Ad or post. Tim Doyle of Eucalyptus shared that his most profitable Ad was not some high quality video but rather a Doge meme.</p><p><strong>Velocity is everything</strong><br>When building companies you NEED to move fast, there is no alternative to it.</p><p><strong>Product</strong><br>Product led growth is the BEST type, its natural and doesn't feel forced.</p><p><strong>Distribution</strong><br>This is probably just as much if not more important than the content or product itself. Build with distribution in mind, articles / SEO or products.</p><p><strong>SLC</strong><br>NO ONE wants to use an MVP - stop using that mindset. Literally no one other than your Mum/Dad will use a "minimum" "viable" thing you build. Its 2020, the whole patchy product cycle doesn't exist. Aim for Simple, Loveable and Complete (or what I call Minimal Product for Impact) Introduce simple features that meet your north star and make sure they're complete.</p><p><strong>Cold Email</strong><br>Learn to master this, its a great skillset to have in building a company and distributing content.</p><p><strong>Feature Validation</strong><br>Before you build a feature, literally build a simple landing page, run some GAds to it for lifetime deals (this doesn't work always, but for some apps).</p><p><strong>Communicate</strong><br>Build every channel possible to communicate with your user as often as possible for as long as possible.</p><p><strong>No CC No Bueno</strong><br>UNTIL someone gives you their CC, you don't have validation. Do not take anything else as validation other than their CC.</p><p><strong>Timeframe</strong><br>Before you start, set a goal to hit, if you don't hit that goal, be quick to reflect. Build more or move on Last but the MOST important.</p><p><strong>Audience</strong><br>Almost 90% of all the "Super successful" founders attributed having a previous built audience as their reason for success. They built this audience through, podcasts, blogs, Youtube, Tiktok or even Newsletters. BUILD. AN. AUDIENCE. You have a higher chance of succeeding with a shit product and a large audience than vice versa For those that are keen.</p><p>All the best peeps!</p></div><p>-Vaibhav<br></p><blockquote><em><strong>Vaibhav</strong></em> has built several startups into Million Dollar businesses serving Millions of customers across the globe via five2one. He's commonly found on stage talking about AI/ML or Product engineering whilst building his 2nd startup cenario.</blockquote>
                </div>
            </section>

                <section>
    <h3>Subscribe to ViralWeGrow</h3>
    <p>Gain a personal advantage with our weekly insights and analysis into the startup hacks world.</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</main>






        

    </div><p><span></span>
        Could not sign up! Invalid sign up link.
    </p></div>]]>
            </description>
            <link>https://viralwegrow.com/blog/observations-from-over-350-startup-podcasts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25030613</guid>
            <pubDate>Mon, 09 Nov 2020 01:33:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Big-O]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25030390">thread link</a>) | @dleskosky
<br/>
November 8, 2020 | https://www.danielleskosky.com/big-o/ | <a href="https://web.archive.org/web/*/https://www.danielleskosky.com/big-o/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article aria-label="Big-O"><div>
<div><figure><img loading="lazy" width="2240" height="1260" src="https://www.danielleskosky.com/wp-content/uploads/media-uploads/bigO/bigo-banner.png" alt="Big O Banner"></figure></div>


<p>Big-O is pretty important.&nbsp; It is the metric that is used to describe the efficiency of algorithms.&nbsp; Having a thorough understanding of Big-O is crucial for ensuring that algorithms are as efficient as possible.&nbsp; Let’s learn more about this fundamental computer science topic.</p>


<h2>What is Big-O?</h2>


<p>Imagine that there is a ship builder.&nbsp; Her name is Andrea.&nbsp; She makes big ships and small ships for a port city.&nbsp; She can make the small ships pretty quickly, but the bigger ships take longer.&nbsp; The amount of&nbsp;<strong>time</strong> that it takes her to build a ship is proportional to the&nbsp;<strong>size</strong> of the ship.&nbsp;&nbsp;</p>
<p>Andrea is also a pirate.&nbsp; She is known to steal other peoples’ ships.&nbsp; She usually does her pirating in a port town that is 10 days worth of travel by land and 5 days of travel back with the stolen ship, so 15 days round trip.&nbsp; The port town that she pirates from always has the ship size that she is looking for.&nbsp;</p>
<p>If a customer asks Andrea to build a ship, she has two options.&nbsp; She can either build the ship or she could put on her pirate hat and go steal a ship.&nbsp;&nbsp;</p>
<p>So if someone wants Andrea to build a ship for them, which option should Andrea choose?&nbsp; That’s right!&nbsp; It depends.</p>
<ul>
<li><strong>Build the Ship: O(s):</strong>&nbsp; where s is the size of the ship.&nbsp; This is <strong>linear</strong> time.&nbsp; The time that it takes to build the ship increases linearly depending on the size of the ship.&nbsp;</li>
<li><strong>Steal the Ship: O(1):&nbsp;&nbsp;</strong>this is <strong>constant</strong> time.&nbsp; It doesn’t matter how big or small the ship is.&nbsp; It will always take Andrea 15 days to get the ship back to the customer.&nbsp;&nbsp;</li>
</ul>
<p>So Andrea should build the ship if she can get it done in less than 15 days.&nbsp; If the ship is big enough that it would take longer than 15 days to build, then Andrea should go steal the ship.&nbsp;</p>
<p>On a side note, this blog does not condone stealing and Andrea should really rethink her life of crime.</p>
<p>Here is a graph that represents the relationship between linear O(s) and constant O(1) time:</p>


<div><figure><img loading="lazy" width="532" height="484" src="https://www.danielleskosky.com/wp-content/uploads/media-uploads/bigO/constant-linear.png" alt="Constant v linear"></figure></div>


<p>There are many more possible runtimes that can occur besides linear and constant.&nbsp; Here is a graph that shows some of the more commonly-used runtimes:</p>


<figure><img loading="lazy" width="1618" height="1130" src="https://www.danielleskosky.com/wp-content/uploads/media-uploads/bigO/complexity-chart.png" alt="Complexity Chart"></figure>


<p>The above complexity chart comes from the <a href="https://www.bigocheatsheet.com/" target="_blank" rel="noopener noreferrer">Big-O Cheatsheet</a> website.&nbsp; Definitely a useful resource!</p>


<h2>The Three Cases</h2>


<p>Let’s use quick sort as an example.&nbsp; Quick sort picks a random element as a pivot and then swaps the values so that the elements less than the pivot appear before the elements that are greater than the pivot.&nbsp; Then it uses recursion to further sort the left and right sides.&nbsp; Learn more about quick sort <a href="https://www.geeksforgeeks.org/quick-sort/" target="_blank" rel="noopener noreferrer">here</a>.</p>
<ul>
<li><strong>Best Case:</strong>&nbsp; The best case means that the algorithm is given the most ideal data.&nbsp; If all elements are equal in the array then quick sort will just have to traverse the array once.&nbsp; Traversing an array of <strong>N</strong> elements will give a runtime of&nbsp;<strong>O(N)</strong>.</li>
<li><strong>Worst Case:</strong>&nbsp; The worst case means that the algorithm is given the least ideal data.&nbsp; With quick sort, it could happen that the pivot is repeatedly the biggest element in the array.&nbsp; If this were to happen then instead of the subarray being recursively divided in half each time, the subbarray would only be reduced by one element.&nbsp; This would give a runtime of&nbsp;<strong>O(<b><i>N</i><sup>&nbsp;2</sup></b>)</strong>.</li>
<li><strong>Expected Case:</strong>&nbsp; Typically instead of having a worst case or a best case you are more likely to have an expected case.&nbsp; Sometimes the pivot will be high and sometimes the pivot will be low, but over time they will average each other out.&nbsp; This will give a runtime more close to&nbsp;<strong>O(N log N)</strong>.</li>
</ul>
<p>The best case runtime usually isn’t of too much interest when analyzing an algorithm.&nbsp; The&nbsp;<strong>worst</strong> and&nbsp;<strong>expected&nbsp;</strong>cases are the ones that need to be considered.</p>


<h2>Space Complexity</h2>


<p>Space complexity is used to describe the total amount of memory that an algorithm uses in respect to the input size of the algorithm.&nbsp;&nbsp;</p>
<p>If an algorithm requires an array of size <em>n</em>, this will require O(n) space.&nbsp; If there is a two dimensional array of size&nbsp;<em>n </em>by <em>n, </em>then O(n<sup>2</sup>) space is required.</p>


<h2>Some Useful Big-O Tips</h2>


<p>There are a couple of tips that you should keep in the back of your mind when you are working on finding the Big-O.&nbsp; Here they are:</p>
<ul>
<li><strong>No constants</strong></li>
<li><strong>No non-dominant terms</strong></li>
<li><strong>Consider multiple runtimes</strong></li>
</ul>


<h2>No Constants</h2>


<p>With Big-O time the constants are not taken into consideration.&nbsp;</p>
<blockquote>
<p>Big-O notation doesn’t care about constants because Big-O notation only describes the long-term growth rate of functions, rather than their absolute magnitudes.”&nbsp;&nbsp;</p>
</blockquote>
<p>An algorithm that might seem to be <em>O(2N)</em> is actually only <em>O(N).&nbsp; </em>Here is a <a href="https://stackoverflow.com/questions/22188851/why-is-the-constant-always-dropped-from-big-o-analysis#:~:text=Big%2DO%20notation%20doesn't,rather%20than%20their%20absolute%20magnitudes.&amp;text=A%20function%20whose%20runtime%20is%20n2%20%2F%202%20will%20be,runtime%20is%20just%20n2." target="_blank" rel="noopener noreferrer">Stack Overflow post</a> that does a pretty good job of describing it.&nbsp;</p>
<p>Take a look at some code:</p>

<pre title="">int min = Integer.MAX_VALUE;
int max = Integer.MIN_VALUE;
for (int x : array) {
    if (x &lt; min) {
        min = x;
    }
    if (x &gt; max) {
        max = x;
    }
}
</pre>

<p>The runtime is O(array.length) or O(N).&nbsp;</p>
<p>Let’s take look at some more code:</p>

<pre title="">int min = Integer.MAX_VALUE;
int max = Integer.MIN_VALUE;
for (int x : array) {
    if (x &lt; min) {
        min = x;
    }
}
for (int x : array) {
    if (x &gt; max) {
        max = x;
    }
}
</pre>

<p>Your first intuition might to be assume that because there are two for loops that iterate the length of the array that the runtime must be O(2N).&nbsp; Don’t fall into this trap!&nbsp; The runtime is O(N).&nbsp; Remember to drop the constant!</p>


<h2>No Non-Dominant Terms</h2>


<p>What if you get a runtime like O(<i>N</i><sup>&nbsp;2</sup> + N)?&nbsp; What should we do then?&nbsp; Well, if you were able to deduce that we should drop the non-dominant term, then congratulations!&nbsp;&nbsp;</p>
<p>Consider the runtime O(<i>N</i><sup>&nbsp;2</sup> + <i>N</i><sup>&nbsp;2</sup>).&nbsp; This is the same as O(2<i>N</i><sup>&nbsp;2</sup>).&nbsp; We know that we should not include constants in our runtimes.&nbsp; So if one of the <i>N</i><sup>&nbsp;2</sup> terms is ignored then we can ignore the N in O(<i>N</i><sup>&nbsp;2</sup> + N) as well.&nbsp;&nbsp;</p>
<ul>
<li>O(<i>N</i><sup>&nbsp;2</sup> + N) becomes O(<i>N</i><sup> 2</sup>).</li>
<li>O(N + logN) becomes O(N).</li>
<li>O(5*2<sup>N</sup> + 1000N<sup>100</sup>) becomes O(2<sup>N</sup>).</li>
</ul>


<h2>Consider Multiple Runtimes</h2>


<p>If we had to iterate through two arrays of the same length N then we could say that the runtime was O(N) (remember to drop constants!).&nbsp; However what happens if the arrays are of different lengths?&nbsp;&nbsp;</p>
<p>Take a look at some code:</p>

<pre title="">for (int a : arrA) {
    print(a);
}

for (int b : arrB) {
    print(b);
}
</pre>

<p>We are iterating through two arrays of different lengths.&nbsp; The runtime is O(A + B).&nbsp; Both runtime lengths must be considered!</p>
<p>Let’s take a look at some more code:</p>

<pre title="">for (int a : arrA) {
    for (int b : arrB) {
        print(a + "," + b);
    }
}
</pre>

<p>If the arrays were of equal length we could say that the runtime was O(<i>N</i><sup>&nbsp;2</sup>).&nbsp; However, the arrays are different lengths.&nbsp; This means that for every element of A, arrB will be iterated through.&nbsp; This results in a runtime of <br>O(A * B).</p>


<h2>Thanks!</h2>


<p>Thanks for reading my post.&nbsp; I hope that you found it useful.&nbsp; Once you understand the material presented here, be sure to continue your learning about Big-O.</p>
<p>Here are some topics that you should explore next:</p>
<ul>
<li><a href="https://hackernoon.com/what-does-the-time-complexity-o-log-n-actually-mean-45f94bb5bfbf" target="_blank" rel="noopener noreferrer">Log N Runtimes</a></li>
<li><a href="https://yourbasic.org/algorithms/time-complexity-recursive-functions/" target="_blank" rel="noopener noreferrer">Recursive Runtimes</a></li>
<li><a href="https://yourbasic.org/algorithms/amortized-time-complexity-analysis/" target="_blank" rel="noopener noreferrer">Amortized Time</a></li>
</ul>
<p>Thanks again!</p><!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://www.danielleskosky.com/big-o/"
    dc:identifier="https://www.danielleskosky.com/big-o/"
    dc:title="Big-O"
    trackback:ping="https://www.danielleskosky.com/big-o/trackback/" />
</rdf:RDF>-->
</div></article></div>]]>
            </description>
            <link>https://www.danielleskosky.com/big-o/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25030390</guid>
            <pubDate>Mon, 09 Nov 2020 00:35:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mapping the Underground: Supervised Discovery of Cybercrime Supply Chains [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25030329">thread link</a>) | @stjo
<br/>
November 8, 2020 | https://damonmccoy.com/papers/ecrime2019.pdf | <a href="https://web.archive.org/web/*/https://damonmccoy.com/papers/ecrime2019.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://damonmccoy.com/papers/ecrime2019.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25030329</guid>
            <pubDate>Mon, 09 Nov 2020 00:23:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Onboarding is not a one way street]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25030054">thread link</a>) | @bored_hacker
<br/>
November 8, 2020 | https://boredhacking.com/onboarding-is-not-a-one-way-street/ | <a href="https://web.archive.org/web/*/https://boredhacking.com/onboarding-is-not-a-one-way-street/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><header><h3><a href="https://boredhacking.com/">Bored Hacking</a></h3></header><main><p>November 08, 2020<!-- --> | <b>4<!-- --> min read</b></p><div><p>Onboarding can be a very hectic and stressful time when you are starting a new job. New coworkers to meet, new codebases to learn, new languages to learn, new technologies, new processes, and the list can go on and on. Good onboarding materials and processes can go a long way when you’re first starting out. However, it shouldn’t just be a one way street. Onboarding should be a collaborative and incremental process that every new hire(and employee) actively contributes to. Things change from onboarding class to onboarding class, especially in a fast moving startup. It is therefore not only up to the existing members but also the new hires to contribute to the onboarding experience and documentation to keep it up to date and make it better overtime. Here are some recommendations for making onboarding not only productive for you but also better for future new hires.</p>
<h2>Take Your Time to Onboard</h2>
<p>Onboarding isn’t a race to the finish line. It can feel like you need to onboard as quickly as possible and be productive right away. However, you have to remember that Rome wasn’t built in a day and this time is important to build a good foundation for the rest of your time at the company. You don’t want to jump in before you’re ready and struggle to keep up. Take your time to properly onboard, and learn as much as you can during this time. Your team will be understanding that you are onboarding and shouldn’t feel like you need to be productive from day 1. Although there is generally a set time period for new hires to still be onboarding, the first month or two generally depending on your company. Take full advantage of your expected onboarding period. When you run into something you don’t know or haven’t seen before, take the time to really dig into it and learn it. Do your own research or ask teammates about it and make sure you fully understand it. Once again, this will pay off in the future and help you compound your knowledge as you continue to learn and work at the company.</p>
<h2>Write and Update Documentation</h2>
<p>As you are onboarding hopefully there is already some documentation on how to at the very least setup local development. Depending on your company, you may also have documentation on team specific information, common tasks, etc. Find out what your company uses to store documentation(Google Drive, Github, Notion, Confluence, Dropbox Paper, etc.) and look through it for even more documents. As you go through this documentation, if there’s anything that doesn’t make sense or is outdated make sure to update the documentation. And if you realize there isn’t any documentation for something you encountered then you should write it! Anything you do while onboarding that didn’t have clear directions or documentation, feel free to write it up yourself. Even once you are done onboarding, you should continue this. Every little improvement will benefit someone else down the road and make them productive quicker, multiplying your effect and increasing overall productivity.</p>
<h2>Take Notes During Onboarding</h2>
<p>Take notes of things that went well during your onboarding and things that could have gone better. These will be important for improving the situation for the next hire(s). Take these notes to your manager and talk through the good and bad. This will help the organization understand what they are doing well and what they can do to make it better for the next hire on your team. Your manager will want to make sure they are doing everything they can to help you onboard better and improve the situation for the future.</p>
<h2>Ask Questions</h2>
<p>Asking questions and getting good answers is incredibly important during onboarding. You may get blocked often while onboarding because there are a lot of unknowns and that’s okay. But don’t wait too long to unblock yourself. One big thing to remember is, you should never hesitate to reach out to someone because they seem too busy. They may be busy but they will normally make the time to help onboard new people. Although not all onboarding buddies may be okay with constant interruptions, it is reasonable that you should try and limit their context shifting. Therefore, setup time to talk with your onboarding buddy or teammate. Setting up time can help limit this but also ensure you get your questions answered. At first this should probably be a set time daily for the first week, but as you continue to onboard it can be less often.</p>
<h2>Good Onboarding and Helping Out New Hires is a 10X Situation</h2>
<p>The 10x engineer is often talked about in tech and seen as a unicorn of sorts. For those not familiar, it was commonly thought that a 10x engineer performed 10 times as efficiently as other engineers, performing the work of 10 engineers. However, I don’t think that a 10x engineer should only be more efficient but I think 10x engineers are engineers who help 10X the learning of other engineers as well. A 10x engineer helps their whole team be more efficient by teaching and mentoring them. This applies directly to onboarding and new hires. The faster new hires onboard the faster they can be productive. Spreading information to more people makes everyone better and creates a cycle of spreading information, which can lead not only to a 10x situation but a 100x situation where multiple people within your org are increasing their knowledge and productivity by 10x. The real “unicorn” engineers are the ones who lift up the whole organization or team, and onboarding is a key component of that. Everyone should realize the importance of a good onboarding period for new hires and how it can help the organization as a whole.</p></div><hr><ul><li><a rel="prev" href="https://boredhacking.com/starting-a-new-elixir-project/">Starting a new Elixir Project</a></li><li></li></ul></main></div></div>]]>
            </description>
            <link>https://boredhacking.com/onboarding-is-not-a-one-way-street/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25030054</guid>
            <pubDate>Sun, 08 Nov 2020 23:26:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CS 2150: Program and Data Representation]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25029751">thread link</a>) | @swatson741
<br/>
November 8, 2020 | https://aaronbloomfield.github.io/pdr/readme.html | <a href="https://web.archive.org/web/*/https://aaronbloomfield.github.io/pdr/readme.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<p><a href="#introduction">Introduction</a> | <a href="#contents">Repository contents</a> | <a href="#contributing">Contributing to this repository</a> | <a href="#description">Course description</a> | <a href="#markdown">Markdown</a> | <a href="#sourcecode">Source code</a> | <a href="#license">License</a></p>
<h2 id="introduction"><a name="introduction"></a>Introduction</h2>
<p>This repository contains the materials for the course entitled “CS 2150: Program and Data Representation” in the <a href="http://www.cs.virginia.edu/">Computer Science Department</a> at the <a href="http://www.virginia.edu/">University of Virginia</a>. It contains all of the slides, labs, exams, etc., used throughout the course. The course description is <a href="#description">below</a>. The github repository for this course is at <a href="https://github.com/uva-cs/pdr">https://github.com/uva-cs/pdr</a>. It can be viewed online at <a href="http://uva-cs.github.io/pdr/">http://uva-cs.github.io/pdr/</a>.</p>
<p>Students <em>currently</em> in the course should view the <a href="https://aaronbloomfield.github.io/pdr/uva/index.html">uva/index.html</a> (<a href="https://aaronbloomfield.github.io/pdr/uva/index.md">md</a>) file in the <strong>cloned</strong> repository (i.e., don’t try to view it on github.com); current students may also want to view the <a href="https://aaronbloomfield.github.io/pdr/uva/daily-announcements.html#/">daily announcements</a>. Note that many of the course materials are modified right before they are needed – for example, this repository will be updated right before the semester starts.</p>
<p>Students who were previously in the course may want to view the current version, or you can view the version from your semester. All semester versions are tagged with an end-of-semester tag of the form “year-semester”. For example, the spring 2014 semester was tagged as <code>2014-spring</code>. To obtain a specific tag, you can enter <code>git checkout tags/2014-spring</code> in an already cloned repository.</p>
<p>The primary authors of this repository are <a href="http://www.cs.virginia.edu/~mrf8t">Mark Floryan</a> (<a href="mailto:mrf8t@cs.virginia.edu">mrf8t@cs.virginia.edu</a>), <a href="http://www.cs.virginia.edu/~nn4pj">Rich Nguyen</a> (<a href="mailto:nn4pj@virginia.edu">nn4pj@virginia.edu</a>), and <a href="http://www.cs.virginia.edu/~asb">Aaron Bloomfield</a> (<a href="mailto:aaron@virginia.edu">aaron@virginia.edu</a>). Many students and faculty have worked on this course material over the years.</p>
<h2 id="repository-contents"><a name="contents"></a>Repository Contents</h2>
<p><strong>Note that the links below will not work correctly if you are viewing this online at github.com – you will need to clone (download) the repository first</strong></p>
<ul>
<li><a href="https://aaronbloomfield.github.io/pdr/book/index.html">book</a> (<a href="https://aaronbloomfield.github.io/pdr/book/index.md">md</a>): the beginnings of a textbook to be used for this course. It is written using LaTeX.</li>
<li><a href="https://aaronbloomfield.github.io/pdr/docs/index.html">docs</a> (<a href="https://aaronbloomfield.github.io/pdr/docs/index.md">md</a>): a series of useful documents that are not labs or tutorials.</li>
<li><a href="https://aaronbloomfield.github.io/pdr/uva/index.html">uva</a> (<a href="https://aaronbloomfield.github.io/pdr/uva/index.md">md</a>): the materials that are specific to CS 2150 as taught at the University of Virginia, such as daily announcements, due dates, etc.</li>
<li><a href="https://aaronbloomfield.github.io/pdr/exams/index.html">exams</a> (<a href="https://aaronbloomfield.github.io/pdr/exams/index.md">md</a>): past exams for the course; there are two midterms and a final for each semester.</li>
<li><a href="https://aaronbloomfield.github.io/pdr/ibcm/ibcm.html">ibcm</a> (<a href="https://aaronbloomfield.github.io/pdr/ibcm/ibcm.md">md</a>): the files necessary for the IBCM module on machine language, which is taught about two thirds of the way into the course.</li>
<li><a href="https://aaronbloomfield.github.io/pdr/labs/index.html">labs</a> (<a href="https://aaronbloomfield.github.io/pdr/labs/index.md">md</a>): the labs are the main assignments in the course, and each lab is split into pre-lab, in-lab, and post-lab parts. There are 11 full labs, with a partial 12th lab that is an optional component of the course. The labs are written using <a href="http://daringfireball.net/projects/markdown/">markdown</a>, and the rendered HTML version of each lab is also committed to this repository.</li>
<li><a href="https://aaronbloomfield.github.io/pdr/slides/index.html">slides</a> (<a href="https://aaronbloomfield.github.io/pdr/slides/index.md">md</a>): Contains the slides used in the course. The slides use <a href="https://github.com/hakimel/reveal.js/">reveal.js</a>, an HTML presentation framework.</li>
<li><a href="https://aaronbloomfield.github.io/pdr/tutorials/index.html">tutorials</a> (<a href="https://aaronbloomfield.github.io/pdr/tutorials/index.md">md</a>): the tutorials that are used as part of the lab assignments, these are primarily Linux tutorials.</li>
<li><a href="https://aaronbloomfield.github.io/pdr/utils/index.html">utils</a> (<a href="https://aaronbloomfield.github.io/pdr/utils/index.md">md</a>): various utilities for this repository</li>
</ul>
<h2 id="contributing-to-this-repository"><a name="contributing"></a>Contributing to this Repository</h2>
<p>Updates to the repository are restricted to approved individuals only, to prevent anybody from messing with the slides right before a lecture. However, others can still contribute to this repository – to do so, take the following steps:</p>
<ol type="1">
<li>Create a github account, if you do not have one</li>
<li>Fork this repository: you can click on the “Fork” link in the upper right, or just click <a href="https://github.com/uva-cs/pdr/fork">here</a></li>
<li>Clone your forked repository on to your local machine</li>
<li>Make any changes you want to your forked version</li>
<li>Run <code>make</code> - note that you will need <a href="http://johnmacfarlane.net/pandoc/">pandoc</a>, <a href="http://astyle.sourceforge.net/">astyle</a>, and <a href="http://www.gnu.org/software/src-highlite/source-highlight.html">source-highlight</a> installed</li>
<li>Commit and push your changes back to your forked repository</li>
<li>Create a pull request, following the instructions <a href="https://help.github.com/articles/creating-a-pull-request">here</a></li>
</ol>
<p>At that point, I will receive a notice that a change has been submitted, and I’ll look at it and hopefully accept it into the main repository.</p>
<p>When you want to bring in the updates from the main pdr github repository into your forked repository, you will need to follow the instructions <a href="https://help.github.com/articles/syncing-a-fork">here</a>.</p>
<h2 id="course-description"><a name="description"></a>Course Description</h2>
<p>This course is a second-year course for computer science majors. It is the primary data structures course in the <a href="http://www.virginia.edu/">University of Virginia</a>’s <a href="http://www.cs.virginia.edu/">computer science</a> curriculum. Unlike many other data structure courses at other institutions, it is intended as the <em>third</em> course in sequence, meaning that students are expected to have taken two semesters of Java (or equivalent, although some of the examples are specifically from Java). The course focuses on how programs and data are represented from the high level down to the low level. For programs, we examine (from high to low): abstract data types, Java code, C++ code, C code, assembly (x86) code, and a customized machine language. For data, we examine (also from high to low): abstract data types, objects, primitive types, and how numbers are encoded (both floats (IEEE 754) and integers (two’s complement)). About two-thirds of this course is programming using C++. The remainder of this course uses other languages, including (in decreasing order): x86 assembly, IBCM (a machine language), C, Objective C, and shell scripting.</p>
<p>The <a href="http://www.abet.org/">ABET</a> course objects are as follows:</p>
<ul>
<li>Understand program representation from the high-level programming language perspective down to the underlying machine level representation, including: number representation, operations, conditionals, and control structures</li>
<li>Be able to implement basic and advanced abstract data types in C++ including: linked lists, stacks, queues, hash tables, trees, and graphs</li>
<li>Be able to evaluate asymptotic time and space complexity analysis of programs and data structure implementations using Big-O, Big-Omega, and Big-Theta notation and assess the suitability of a data structure for a particular problem</li>
<li>Understand the basic program execution model and the underlying computer hardware and software (fetch-execute cycle, memory hierarchy, operating system, compiler)</li>
<li>Be able to implement basic program control and data structures in an assembly language (loops, conditionals, subroutines and parameter passing modes, arrays)</li>
</ul>
<h2 id="markdown"><a name="markdown"></a>Markdown</h2>
<p>The majority of the content in this repository was created using <a href="http://daringfireball.net/projects/markdown/">Markdown</a>. Unfortunately, the only standardized Markdown is very old (2004), and has limited support for many HTML features, such as tables. A simple conversion script in a Makefile is in the <a href="https://aaronbloomfield.github.io/pdr/utils/index.html">utils</a> (<a href="https://aaronbloomfield.github.io/pdr/tutorials/index.md">md</a>) directory, which uses <a href="http://johnmacfarlane.net/pandoc/">pandoc</a>. Assuming pandoc is installed, run <code>make markdown</code> in the root repo directory to re-create all the .html files from their associated .md files.</p>
<p>For all the Markdown files in this repository, both the original (.md) file and the HTML version (.html) are added to the repository, so that people who do not have Markdown installed can still view the contents of this repository.</p>
<p>Note that Github supports an enhanced version of Markdown, called <a href="https://help.github.com/articles/github-flavored-markdown">Github Flavored Markdown</a>, or GFM. This mostly pertains to this README file. In an effort to ensure compatibility with other Markdown programs (such as the one described here and what reveal.js uses), GFM specific features are generally avoided. One example is the use of anchors in this document – the HTML tags are included instead of using GFM’s version.</p>
<h2 id="source-code"><a name="sourcecode"></a>Source code</h2>
<p>All source code is formatted via <a href="http://astyle.sourceforge.net/">astyle</a> and then highlighted via <a href="http://www.gnu.org/software/src-highlite/source-highlight.html">source-highlight</a>. Both the original file (foo.cpp) and the highlighted version (foo.cpp.html) are included in the repository. All links to source code will like to the .html, with a “(<a href="https://aaronbloomfield.github.io/pdr/README.md">src</a>)” after it to link to the original source code. Utility scripts are provided to convert all the files in the <a href="https://aaronbloomfield.github.io/pdr/utils/index.html">utils</a> (<a href="https://aaronbloomfield.github.io/pdr/tutorials/index.md">md</a>) directory. <code>make format</code> and <code>make highlight</code> can also be run to invoke the scripts.</p>
<h2 id="license"><a name="license"></a>License</h2>
<p>The material in this repository is released under a <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a> (CC BY-SA).</p>
<p>Copyright (c) 2017-2018 by Mark Floryan Copyright (c) 2013-2017 by Aaron Bloomfield.</p>
<p>Some parts of this repository are taken, with permission, from other sources. The full details are in the <a href="https://aaronbloomfield.github.io/pdr/license.html">License</a> (<a href="https://aaronbloomfield.github.io/pdr/license.md">md</a>) file. In particular, some parts of this repository that were obtained elsewhere can not be used for commercial purposes.</p>


</div>]]>
            </description>
            <link>https://aaronbloomfield.github.io/pdr/readme.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25029751</guid>
            <pubDate>Sun, 08 Nov 2020 22:36:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Restoring a 37 Year-Old IBM F Mechanical Keyboard]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 55 (<a href="https://news.ycombinator.com/item?id=25029571">thread link</a>) | @opsdisk
<br/>
November 8, 2020 | https://blog.opsdisk.com/restoring-a-37-year-old-ibm-model-f-mechanical-keyboard.html | <a href="https://web.archive.org/web/*/https://blog.opsdisk.com/restoring-a-37-year-old-ibm-model-f-mechanical-keyboard.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <p>I wanted to share my journey from start to finish to restore a 1983 IBM Model F XT mechanical keyboard to it's former glory.  It includes the steps, mistakes, and additional hardware required to make it functional with a modern computer.  This blog post is dedicated to my dad for teaching me about computers.</p>
<p><img alt="original.jpg" src="https://blog.opsdisk.com/images/keyboard/original.jpg"></p>

<p>A few months ago, my dad asked if I was interested in taking ownership of his <a href="https://en.wikipedia.org/wiki/IBM_Personal_Computer">IBM model 5150 PC</a>.  Without hesitation, I said "yes!".  The first project I wanted to tackle was to restore the
<a href="https://en.wikipedia.org/wiki/Model_F_keyboard">1983 Model F XT mechanical keyboard</a> keyboard.  In a sentimental and
journeyman/apprentice-sense, it felt like my dad was passing on the tools of his craft to continue the family line of
computer work and I couldn't pass that up.</p>
<p><img alt="datestamp.jpg" src="https://blog.opsdisk.com/images/keyboard/datestamp.jpg"></p>

<p>For those of you unfamiliar with the IBM Model F, <a href="https://www.modelfkeyboards.com/">modelfkeyboards.com</a> summarizes it
nicely:</p>
<blockquote>
<p>The IBM Model F keyboards not only used the best switches, the materials used in their production (well over 5lbs of
steel and other metals) means they will be working as good as new when it’s time to pass it on to your grandchildren.
The problem...they just aren't made that way any more.  The IBM Model F was discontinued in the 1980's.  If you do
find a Model F, it will be some combination of dirty, broken and/or expensive, requiring hours of work to get it
working again!</p>
</blockquote>
<p>This tank of a keyboard weighs in at over 6 pounds, sounds like <a href="https://youtu.be/XTVeSCqYSmE?t=7">this</a>, and at the
time of production, retailed for $300-400 in 1982 ($800-1000 dollars adjusted in today's dollars!) according to this
<a href="https://www.youtube.com/watch?v=y9Jds326gks">review</a>.</p>
<p>The restoration did take a few hours and fortunately none of it involved a soldering iron or replacing any of the
electrical or physical components because it was already in great functioning shape...a true testament to the design.
Even cooler, this blog post was typed up using the restored Model F keyboard!</p>

<p>Before beginning the project, I discovered <a href="https://www.clickykeyboards.com/">ClickyKeyboards</a>, a site "Specializing in
the restoration and collection of model M keyboards", the successor to the Model F.  On ClickyKeyboards, there is a
section dedicated to the adapters and converters that may be required to make older 5-pin DIN plug keyboards compatible
with modern USB ports.  One of the companies mentioned on ClickyKeyboards is
<a href="https://www.hagstromelectronics.com/">Hagstrom Electronics</a>, which sells keyboard encoders and protocol converters.
Without looking too closely at the other products, I quickly purchased the
<a href="https://www.hagstromelectronics.com/keyboard-encoder-ke18-xtat-ps2-shp.html">KE18-XTAT-PS/2</a> which "converts an XT
keyboard into a PS/2 protocol keyboard" for $55.  I was ecstatic that there was at least something to get me into PS/2
land, because at that point I knew I could easily find a PS/2 to USB converter.</p>
<p>After the KE18-XTAT-PS/2 arrived, I quickly fired up an ancient box (yes, that is Windows 2000!) with a PS/2 input on
the motherboard.  I tested all the keys to ensure they still worked and they did!  With confirmation that the keyboard
still worked, it was time to start the restoration.</p>
<p><img alt="win2000.jpg" src="https://blog.opsdisk.com/images/keyboard/win2000.jpg"></p>

<p><img alt="original2.jpg" src="https://blog.opsdisk.com/images/keyboard/original2.jpg"></p>
<p>The first step was to remove the metal casing and see what the state of the board was underneath the keys.  There was
years worth of debris, coffee stains, and gunk that had to be removed.  In addition, there were a few spots with
corrosion on the board that needed to be addressed.</p>
<p><img alt="preclean.jpg" src="https://blog.opsdisk.com/images/keyboard/preclean.jpg"></p>
<p>Once the casing was off, I utilized compressed air to clean out the key bunkers and get rid of any loose nastiness.
Next, I tried using rubbing alcohol and Q-tips to try and remove some of the stickier stuff, but that didn't
really work.</p>

<p>I borrowed a rotary tool to buff out the corrosion.  I used one of the provided bits that had soft plastic tentacles to
try and buff out the corroded spots as gently as possible.  There are likely better and more appropriate bits, but it
did the job.  The rotary tool's power and RPMs were a bit overkill even on the lowest setting.  Ideally, I would have
used one with fewer minimum RPMs and a more precise bit to get all the spots.</p>
<p><img alt="buffing_tool_and_bit.jpg" src="https://blog.opsdisk.com/images/keyboard/buffing_tool_and_bit.jpg"></p>
<p><img alt="bit.jpg" src="https://blog.opsdisk.com/images/keyboard/bit.jpg"></p>
<p>I was using the rotary tool under a bright overhead desk lamp, and with the way the light was reflecting, I didn't
notice it was taking off the black finish and revealing the silver metal base.  At that point, I just decided to buff
off the finish where I could to make it look more uniform.  The silver metal is visible when the keys and cover are back
on it, but it looks fine.  Unfortunately, with the rotary head and bit size, I wasn't able to buff every last square
inch of the board, but I knew it'd be covered so I wasn't too concerned with it looking perfect.</p>
<p><img alt="allbuffed.jpg" src="https://blog.opsdisk.com/images/keyboard/allbuffed.jpg"></p>

<p><img alt="postbuffing.jpg" src="https://blog.opsdisk.com/images/keyboard/postbuffing.jpg"></p>
<p>There was still some residue stuck to the board that I wanted to remove.  I started out using a small eye glass
screwdriver to scrape it off, but it took some of the black finish off as well and didn't look that nice.  At that point,
a chemical pivot was required and I reached for the <a href="https://googone.com/">Goo Gone</a>, which I should have done from the
beginning.  The Goo Gone and a bit of elbow grease with Q-Tips did the trick in removing the stubborn gunk on the board.</p>
<p><img alt="postgoogone.jpg" src="https://blog.opsdisk.com/images/keyboard/postgoogone.jpg"></p>

<p>With the board in good shape, it was time to tackle the actual keys.  I first gave them a good wipe-down using desk
cleaning wipes, which removed most of the discoloration and stains.  However, they still didn't look as good as they
could, and I read that just soaking them in a bowl of dish soap and water for a few hours can do wonders...and it did.
They keys look brand new.</p>
<p><img alt="keybath.jpg" src="https://blog.opsdisk.com/images/keyboard/keybath.jpg"></p>
<p>One mistake I made after washing them was to not let them completely dry on the inside.  I placed the keys back on the
board too soon, and some water leaked onto a few of the springs causing a small amount of rusting (slightly visible in
the post-Goo Gone image).  I gave them another soap soak and used the compressed air to really get out the water.  I
also let them air dry for 1-2 days before putting them back on the board.</p>

<p>After successfully testing the actual keyboard and the restoration almost complete, it was time to search for a PS/2 to
USB cable.  On a whim, I was back on the Hagstrom Electronic site and noticed they already had a small box, the
<a href="https://www.hagstromelectronics.com/ke-xtusb-keyboard-encoder-shp.html">KE-XTUSB</a>, that converted the XT signal to USB,
and it was the same price.  They graciously allowed me to return the KE18-XTAT-PS/2 in exchange for the KE-XTUSB which
was the same price.  A few days later the KE-XTUSB arrived in the mail and I eagerly connected it to my current computer.</p>
<p><img alt="xtusb.jpg" src="https://blog.opsdisk.com/images/keyboard/xtusb.jpg"></p>

<p>Everything worked beautifully except for two keys.  The "s" key's spring mechanism would either not detect a key press
or would be stuck in the depressed state blasting "sssssssssssssssssssssssssssssssssssss" across the screen.  With a
bit of finagling, I got the key cap placed correctly so now it works like a champ.  The other key that has issues is the
accountant's "+" near the 10 key pad.  The spring had come off somehow and I super glued it back, but something still
isn't right and it fails to register key strokes.  Not a huge loss since "+" can be achieved with another key
combination.</p>
<p>Overall, I'm really impressed with how it looks and, when comparing it to <a href="https://www.youtube.com/watch?v=E2bAhxK76hc">this</a>
unboxing video of a never before opened Model F, it looks about the same!</p>
<p>If you have any questions or comments, hit me up on Twitter <a href="https://twitter.com/opsdisk">@opsdisk</a>.</p>
<p><img alt="final.jpg" src="https://blog.opsdisk.com/images/keyboard/final.jpg"></p>
            </section></div>]]>
            </description>
            <link>https://blog.opsdisk.com/restoring-a-37-year-old-ibm-model-f-mechanical-keyboard.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25029571</guid>
            <pubDate>Sun, 08 Nov 2020 22:09:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The traffic of some Apple processes isn’t shown in Little Snitch 5]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25029535">thread link</a>) | @bangonkeyboard
<br/>
November 8, 2020 | https://www.obdev.at/support/littlesnitch/245914647368270 | <a href="https://web.archive.org/web/*/https://www.obdev.at/support/littlesnitch/245914647368270">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div>
<p><label for="ctr_expandable_34">
<h3>The traffic of some Apple processes isn’t shown in Little&nbsp;Snitch&nbsp;5.</h3>
</label></p><div>
<p>This is due to a limitation in Apple’s Network Extension API, which surprisingly whitelists a number of system services like Maps, FaceTime, App Store or Software Update and therefore doesn’t report the network activity of these services to third-party application firewalls.</p>
<p>The use of this new API is now mandatory for third-party developers on macOS Big Sur, because Apple no longer supports the previous kernel extension based approach, which didn’t suffer from this limitation.</p>
<p>We are currently investigating a solution in Little Snitch to make these whitelisted connections visible by means of alternative techniques.</p>
<p>There’s an ongoing discussion about this problem in various online media, and we assume that Apple will address these concerns in a future macOS update.</p>
<p>At the time of this writing, the whitelist seems to inlcude the following macOS processes:</p>
<p>

/System/Applications/App Store.app/Contents/MacOS/App Store<br>

/System/Library/CoreServices/cloudpaird<br>

/System/Library/CoreServices/mapspushd<br>

/System/Library/CoreServices/Software Update.app/Contents/Resources/softwareupdated<br>

/System/Library/Frameworks/Accounts.framework/Versions/A/Support/accountsd<br>

/System/Library/Frameworks/CoreTelephony.framework/Support/CommCenter<br>

/System/Library/PrivateFrameworks/ApplePushService.framework/apsd<br>

/System/Library/PrivateFrameworks/AppStoreDaemon.framework/Support/appstoreagent<br>

/System/Library/PrivateFrameworks/AppStoreDaemon.framework/Support/appstored<br>

/System/Library/PrivateFrameworks/AssetCacheServices.framework/Versions/A/XPCServices/AssetCacheLocatorService.xpc/Contents/MacOS/AssetCacheLocatorService<br>

/System/Library/PrivateFrameworks/AssistantServices.framework/Versions/A/Support/assistantd<br>

/System/Library/PrivateFrameworks/AuthKit.framework/Versions/A/Support/akd<br>

/System/Library/PrivateFrameworks/CloudKitDaemon.framework/Support/cloudd<br>

/System/Library/PrivateFrameworks/CommerceKit.framework/Resources/commerced<br>

/System/Library/PrivateFrameworks/CommerceKit.framework/Versions/A/Resources/commerce<br>

/System/Library/PrivateFrameworks/CoreLSKD.framework/Versions/A/lskdd<br>

/System/Library/PrivateFrameworks/CoreParsec.framework/parsecd<br>

/System/Library/PrivateFrameworks/CoreSpeech.framework/corespeechd<br>

/System/Library/PrivateFrameworks/DistributedEvaluation.framework/Versions/A/XPCServices/com.apple.siri-distributed-evaluation.xpc/Contents/MacOS/com.apple.siri-distributed-evaluation<br>

/System/Library/PrivateFrameworks/FamilyCircle.framework/Versions/A/Resources/familycircled<br>

/System/Library/PrivateFrameworks/FamilyNotification.framework/FamilyNotification<br>

/System/Library/PrivateFrameworks/GeoServices.framework/Versions/A/XPCServices/com.apple.geod.xpc/Contents/MacOS/com.apple.geod<br>

/System/Library/PrivateFrameworks/HomeKitDaemon.framework/Support/homed<br>

/System/Library/PrivateFrameworks/IDS.framework/identityservicesd.app/Contents/MacOS/identityservicesd<br>

/System/Library/PrivateFrameworks/IDSFoundation.framework/IDSRemoteURLConnectionAgent.app/Contents/MacOS/IDSRemoteURLConnectionAgent<br>

/System/Library/PrivateFrameworks/IMCore.framework/imagent.app/Contents/MacOS/imagent<br>

/System/Library/PrivateFrameworks/IMFoundation.framework/XPCServices/IMRemoteURLConnectionAgent.xpc/Contents/MacOS/IMRemoteURLConnectionAgent<br>

/System/Library/PrivateFrameworks/IMTransferServices.framework/IMTransferAgent.app/Contents/MacOS/IMTransferAgent<br>

/System/Library/PrivateFrameworks/MapsSuggestions.framework/MapsSuggestions<br>

/System/Library/PrivateFrameworks/MapsSupport.framework/MapsSupport<br>

/System/Library/PrivateFrameworks/MediaStream.framework/MediaStream<br>

/System/Library/PrivateFrameworks/MusicLibrary.framework/MusicLibrary<br>

/System/Library/PrivateFrameworks/PassKitCore.framework/passd<br>

/System/Library/PrivateFrameworks/ProtectedCloudStorage.framework/Helpers/ProtectedCloudKeySyncing<br>

/System/Library/PrivateFrameworks/SyncedDefaults.framework/Support/syncdefaultsd<br>

/System/Library/TextInput/kbd<br>

/usr/libexec/coreduetd<br>

/usr/libexec/diagnosticd<br>

/usr/libexec/findmydeviced<br>

/usr/libexec/fmfd<br>

/usr/libexec/locationd<br>

/usr/libexec/mdmclient<br>

/usr/libexec/mobileactivationd<br>

/usr/libexec/mobileassetd<br>

/usr/libexec/networkserviceproxy<br>

/usr/libexec/rtcreportingd<br>

/usr/libexec/secd<br>

/usr/libexec/siriknowledged<br>

/usr/libexec/swcd<br>

/usr/libexec/tailspind<br>

/usr/libexec/teslad<br>

/usr/libexec/timed<br>

/usr/libexec/trustd<br>

/usr/sbin/securityd<br>

com.apple.facetime<br></p>

</div>
</div></div></div></div>]]>
            </description>
            <link>https://www.obdev.at/support/littlesnitch/245914647368270</link>
            <guid isPermaLink="false">hacker-news-small-sites-25029535</guid>
            <pubDate>Sun, 08 Nov 2020 22:06:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Took a Break from Ham Radio and Why I Came Back]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25029459">thread link</a>) | @parsecs
<br/>
November 8, 2020 | https://www.kj7nzl.net/blog/3-reasons-why-i-took-a-break-from-ham-radio-why-i-came-back/ | <a href="https://web.archive.org/web/*/https://www.kj7nzl.net/blog/3-reasons-why-i-took-a-break-from-ham-radio-why-i-came-back/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content-pane">
  <div>
    
    <p>About three months ago I unconsciously or perhaps consciously lost interest in ham radio. This isn’t the first time this has happened to me, in fact this was what lead me to allow my license to lapse the first time in 2016. If it weren’t for a new coworker of mine showing interest in ham radio again after a twenty-five year absent; I presumably wouldn’t be writing this post now. His excitement about all of the recent advances that have been made since he was first license reminded me of the things I missed about ham radio. This forced me to reflect on the reasons that I stepped away from the hobby for nearly three months. After some time I narrowed it down to three primary reasons. Without further ado I present to you my three reasons I took a break from ham radio.</p>
<h2 id="1-2020-amsat-board-of-directors-election">1. 2020 AMSAT Board of Directors Election</h2>
<p>I love satellite operations! It was my primary reason for returning to the hobby earlier this year. Shortly after becoming licensed I joined AMSAT to support amateur radio in space. Little did I know there was an ongoing dispute among two newly elected board members and the rest of the board of directors. Apparently the dispute was over the access of to AMSAT’s finical records with the lengthy ordeal playing out like some pollical scandal with lawyers and secret audio recordings. The board of directors went as far as <a href="https://www.amsat.org/amsat-leadership-explains-2018-2020-legal-expenses/">releasing a statement</a> that was full of contempt for the two new directors. In turn Patrick Stoddard WD9EWK, one of the individuals at that center of this controversy <a href="http://amsat.wd9ewk.net/">released his own statement</a> on the events that transpired. All of this drama culminated with those who sided with Mr. Stoddard attempting replace three of the existing board members with there of their own candidates. Ultimately they were unsuccessful in their coup attempt, and I’ve exhausted all interest in being a part of AMSAT.</p>
<figure>
    <img src="https://www.kj7nzl.net/img/satellites/amsat-fm-0001.webp" alt="KJ7NZL working AO-92."> <figcaption>
            <p>KJ7NZL working AO-92</p>
        </figcaption>
</figure>

<h2 id="2-limited-radio-budget--limited-operating-options">2. Limited Radio Budget = Limited Operating Options</h2>
<p>Whether you want to admit it or not, ham radio is an expensive hobby. Sure you can purchase a Baofeng handheld for thirty-five dollars, but to really take advantage of all your license privileges you need to shell out some cold hard cash for either an HF rig or an all mode VHF/UHF radio. Initially, I wanted to get on the air as quickly and cheaply as possible to try my hand at working a few of the FM satellites, as a result I purchased an Arrow Antenna II and the Wouxun KG-UV8D Plus. To make a long story short, the Wouxun radio was garbage. Don’t believe me <a href="https://www.kj7nzl.net/blog/wouxun-kg-uv8d-plus-fm-satellites/">check out my review of the Wouxun KG-UV8D Plus</a>. After some time of fooling around with that dumb thing, I decided to purchase a Yaesu FT3D and I’m glad I did. On a side note, I should absolutely do a review of that thing since I’ve had it for about three months now and I’ve explored most everything the radio has to offer. With the KG-UV8D I was limited in how I could operate. With just supporting FM I really only could use the thing for satellites outside of using it to connect to any of the local repeaters in the area. On the other hand the Yaesu FT3D allowed me the ability to expore APRS and C4FM AKA System Fussion. This however came at the cost of three times the price of the KG-UV8D. All told, even after selling my KG-UV8D, I am about $600 into the hobby with an Arrow Antenna II, Yaesu FT3D, and Comet Dual Band HT antenna. Even with this setup I’m only able play around with FM satellites, APRS, and simplex/repeaters. I would have loved exploring some of the other areas of the hobby when I jumped back in the spring of this year, but discretionary funds were spread out among different things at the time.</p>
<figure>
    <img src="https://www.kj7nzl.net/img/aprs/aprs-001.webp" alt="KJ7NZL's Trip to Antelope Island State Park"> <figcaption>
            <p>KJ7NZL’s Trip to Antelope Island State Park</p>
        </figcaption>
</figure>

<h2 id="3-life-just-got-in-the-way">3. Life Just Got in the Way</h2>
<p>This year 2020 has been an unusual year for me. Between a global pandemic and finishing some of my basement, I’ve been very busy. As a result I’ve had little free time. What free time I’ve possessed has been divided between multiple hobbies with amateur radio taking a back seat most of the time. It’s my own fault really since I set out earlier this year with the goal of exclusively working FM satellites. I initial assumed it would be effortless to make time through out my day for a quick ten to fifteen minute pass. It made sense at the time; take a brief break, make a couple of contacts, and back to what I was doing before hand. But it turns out that FM satellite QSOs are hard work This in turn lead me to get frustrated very quickly and wish I could operate at my own pace whenever I felt like it. Just so you know, rarely do two FM satellite passes line up back to back when you want them two giving you a thirty to forty minute window of time in which to have fun. Looking back on my journey into ham radio, both the first time and second time, I should have just gone the HF route from the get go. Since I didn’t, I feel like I set myself up for disappointment. With very little motivation and other competing priorities it’s no wonder why I stepped away from ham radio as long I did.</p>
<figure>
    <img src="https://www.kj7nzl.net/img/radios/yaesu-ftdx-3000.webp" alt="Yaesu FTDX 3000"> <figcaption>
            <p>Yaesu FTDX 3000</p>
        </figcaption>
</figure>

<h3 id="moving-forward">Moving Forward</h3>
<p>So what does the future hold for me now that I’m interested in ham radio again? Well, Santa is coming to town, and he’s going to have a new Yaesu FTDX 3000 wrapped up under three for me. I’ll finally be able to dive head first into the world of HF. I have some ambitious plans too. I’d like to explore some of the lesser used digital modes like Hellschreiber, Olivia, and Contestia. I’ll still jump on the FT8 bandwagon, but ultimately I want to explore all the digital modes. I also want to <a href="https://www.kj7nzl.net/blog/learning-morse-code-series/">learn morse code</a>, which I’ve unsuccessfully started and begin working som CW. The Yaesu FTDX 3000 contains some exceptionally attractive features for CW operations that I really want to take advantage of. Another area that I’m going to focus on coming up soon will be building a MMDVM hotspot. Sure I could merely purchase a prebuilt one, but what the fun in that? All in all I think the rest of this year and next year is shaping up to be a excellent time for me to get back into ham radio.</p>

  </div>
</section></div>]]>
            </description>
            <link>https://www.kj7nzl.net/blog/3-reasons-why-i-took-a-break-from-ham-radio-why-i-came-back/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25029459</guid>
            <pubDate>Sun, 08 Nov 2020 21:56:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Started with VMware ESXi on ARM with a Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25029404">thread link</a>) | @todsacerdoti
<br/>
November 8, 2020 | https://www.servethehome.com/getting-started-with-vmware-esxi-on-arm-with-a-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://www.servethehome.com/getting-started-with-vmware-esxi-on-arm-with-a-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://www.servethehome.com/wp-content/uploads/2020/11/IMG_20201107_151735.jpg" data-caption="Raspberry Pi"><img width="696" height="522" src="https://www.servethehome.com/wp-content/uploads/2020/11/IMG_20201107_151735-696x522.jpg" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/IMG_20201107_151735-696x522.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/11/IMG_20201107_151735-400x300.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/11/IMG_20201107_151735-800x600.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/11/IMG_20201107_151735-1068x801.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/IMG_20201107_151735-560x420.jpg 560w, https://www.servethehome.com/wp-content/uploads/2020/11/IMG_20201107_151735-80x60.jpg 80w, https://www.servethehome.com/wp-content/uploads/2020/11/IMG_20201107_151735-265x198.jpg 265w, https://www.servethehome.com/wp-content/uploads/2020/11/IMG_20201107_151735.jpg 1163w" sizes="(max-width: 696px) 100vw, 696px" alt="Raspberry Pi" title="Raspberry Pi"></a><figcaption>Raspberry Pi</figcaption></figure></div>
            <!-- content --><p>Last month VMWare released what they have called <a href="https://blogs.vmware.com/vsphere/2020/10/announcing-the-esxi-arm-fling.html">ESXi Arm-fling.</a> This new release allows you to install the same ESXi you know and love on an ARM processor. VMWare has certified a few systems for datacenter use. They also have certified it for the Raspberry Pi 4, but only for what they call “Far Edge”.</p>
<p>Today we are going to perform the installation on a Raspberry Pi 8GB and do some testing. While we generally feel <a href="https://www.servethehome.com/introducing-project-tinyminimicro-home-lab-revolution/">ProjectTinyMiniMicro</a> may be a better option for some, there are many enthusiasts who sing the praises of the Raspberry Pi. The Pi has exceptional power efficiency, scalability, and a small footprint.<span id="more-48249"></span></p>
<figure id="attachment_48251" aria-describedby="caption-attachment-48251"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/IMG_20201107_151215-1-800x670.jpg" alt="Raspberry Pi 4" width="696" height="583" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/IMG_20201107_151215-1-800x670.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/11/IMG_20201107_151215-1-358x300.jpg 358w, https://www.servethehome.com/wp-content/uploads/2020/11/IMG_20201107_151215-1-696x583.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/11/IMG_20201107_151215-1-502x420.jpg 502w, https://www.servethehome.com/wp-content/uploads/2020/11/IMG_20201107_151215-1.jpg 1014w" sizes="(max-width: 696px) 100vw, 696px"><figcaption id="caption-attachment-48251">Raspberry Pi 4 CanaKit and a LovePI PoE HAT</figcaption></figure>
<p>Before we continue, it is worth noting that this installation is a little bit different than other Raspberry Pi installations. We will need a total of <strong>three</strong> different pieces of storage to complete this installation. You need a microSD card for the firmware, but in this guide that is ALL the microSD card will be used for. Then you will need a USB thumb drive to act as your VMWare installer. Finally, you will need a place to install VMWare to. While it is possible to install it to your microSD card, that is not officially supported. Instead, you want to look at a USB based solution or a network solution such as PXE or iSCSI.</p>
<h2>Preparing our Pi for ESXi</h2>
<p>You will need to grab the<a href="https://www.raspberrypi.org/downloads/noobs/"> NOOBS </a>image and&nbsp;burn it to your microSD card if you did not buy a kit with it preinstalled as we had. To do so you can utilize the <a href="https://www.raspberrypi.org/downloads/">Raspberry Pi Imager</a>.</p>
<p>When the NOOBs installer boots up, select the Raspberry Pi OS Lite (32-bit) option. You do not need the full desktop version. We are only using the OS to update the EEPROM and get some other updates out of the way.</p>
<figure id="attachment_48252" aria-describedby="caption-attachment-48252"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/NOOBS-800x501.png" alt="N" width="696" height="436" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/NOOBS-800x501.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/NOOBS-400x251.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/NOOBS-696x436.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/NOOBS-670x420.png 670w, https://www.servethehome.com/wp-content/uploads/2020/11/NOOBS.png 921w" sizes="(max-width: 696px) 100vw, 696px"><figcaption id="caption-attachment-48252">NOOBS Selecting Raspberry Pi OS 32-bit</figcaption></figure>
<p>When the installation is completed, run the following commands:</p>
<pre><code>sudo rpi-eeprom-update -a
sudo reboot</code></pre>
<p>After you have completed the EEPROM update, we need to now update the firmware and switch to the community UEFI firmware. First, start by going to the Raspberry Pi <a href="https://github.com/raspberrypi/firmware">Github page</a> and download the latest firmware. Next, go to pftf’s UEFI <a href="https://github.com/pftf/RPi4">Github page</a>, and download it as well.</p>
<p>Safely shutdown your Pi and take the microSD card out. Next, plug your microSD card into a computer and prepare to update the files on it. To get started, we need to format the RECOVERY partition and rename it UEFI:</p>
<figure id="attachment_48259" aria-describedby="caption-attachment-48259"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/format.png" alt="Format" width="251" height="460" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/format.png 251w, https://www.servethehome.com/wp-content/uploads/2020/11/format-164x300.png 164w, https://www.servethehome.com/wp-content/uploads/2020/11/format-229x420.png 229w" sizes="(max-width: 251px) 100vw, 251px"><figcaption id="caption-attachment-48259">SD CARD Format for UEFI</figcaption></figure>
<p>Next, drag and drop the new files from the <strong>boot folder in the firmware-master</strong> onto the <strong>SD card</strong>. Start by going to the firmware-master folder and selecting everything. Once completed, you must remove the four files starting with the name “kernel”:</p>
<figure id="attachment_48260" aria-describedby="caption-attachment-48260"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/kernel.png" alt="Kernel" width="605" height="87" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/kernel.png 605w, https://www.servethehome.com/wp-content/uploads/2020/11/kernel-400x58.png 400w" sizes="(max-width: 605px) 100vw, 605px"><figcaption id="caption-attachment-48260">VMware ESXi Raspberry Pi Kernel in firmware-master</figcaption></figure>
<p>Next, do the same thing for the files from the <strong>UEFI firmware</strong>. Make sure you <strong>replace/overwrite</strong>&nbsp;the files with the updated ones.</p>
<figure id="attachment_48255" aria-describedby="caption-attachment-48255"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/UEFI-800x347.png" alt="UEFI" width="696" height="302" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/UEFI-800x347.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/UEFI-400x173.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/UEFI-1536x666.png 1536w, https://www.servethehome.com/wp-content/uploads/2020/11/UEFI-696x302.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/UEFI-1068x463.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/UEFI-969x420.png 969w, https://www.servethehome.com/wp-content/uploads/2020/11/UEFI.png 1829w" sizes="(max-width: 696px) 100vw, 696px"><figcaption id="caption-attachment-48255">VMware ESXi Raspberry Pi UEFI Setup</figcaption></figure>
<p>Now, open the config.txt file in the UEFI drive. We need to modify it by adding a line</p>
<pre><code>gpu_mem=32</code></pre>
<p>You can now put the SD card back into your RPI.</p>
<h2>Setting up ESXi for ARM</h2>
<p>To get started you will need to navigate to <a href="https://flings.vmware.com/esxi-arm-edition#summary">VMware’s page</a> for ESXi for ARM. Once there you will need to create an account and download the ISO. You will need to burn this ISO to a separate USB thumb drive. To burn it to the drive, you can utilize <a href="https://rufus.ie/">Rufus</a>.</p>
<figure id="attachment_48258" aria-describedby="caption-attachment-48258"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/esxi.png" alt="Esxi" width="352" height="485" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/esxi.png 419w, https://www.servethehome.com/wp-content/uploads/2020/11/esxi-218x300.png 218w, https://www.servethehome.com/wp-content/uploads/2020/11/esxi-305x420.png 305w" sizes="(max-width: 352px) 100vw, 352px"><figcaption id="caption-attachment-48258">Rufus Esxi for Raspberry Pi</figcaption></figure>
<p>After you have burned the ISO to your thumb drive, you need to plug it into your Pi and turn it on. You will see a new UEFI boot menu, press escape, and get into the UEFI to make any changes.</p>
<p>Click on&nbsp;<strong>Device Manager&nbsp;</strong>and then click <strong>Limit Ram to 3GB</strong> and change it to <strong>Disabled</strong>.</p>
<figure id="attachment_48262" aria-describedby="caption-attachment-48262"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Unlimited-RAM-800x557.png" alt="Unlimited RAM" width="696" height="485" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Unlimited-RAM-800x557.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Unlimited-RAM-400x279.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Unlimited-RAM-696x485.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Unlimited-RAM-603x420.png 603w, https://www.servethehome.com/wp-content/uploads/2020/11/Unlimited-RAM-100x70.png 100w, https://www.servethehome.com/wp-content/uploads/2020/11/Unlimited-RAM.png 1034w" sizes="(max-width: 696px) 100vw, 696px"><figcaption id="caption-attachment-48262">Unlimited RAM</figcaption></figure>
<p>Press <strong>F10</strong> and save the change you made. Exit the UEFI and press <strong>Enter</strong> to boot to the USB drive. The system will then boot into the ESXi installer. One option for installing ESXi to an SSD, using something like a <a href="https://www.amazon.com/StarTech-com-SATA-USB-Cable-USB3S2SAT3CB/dp/B00HJZJI84/ref=sr_1_1_sspa?dchild=1&amp;keywords=usb+to+sata+startech&amp;qid=1604788276&amp;sr=8-1-spons&amp;psc=1&amp;spLa=ZW5jcnlwdGVkUXVhbGlmaWVyPUEySDJEUE9JUUgxQzlQJmVuY3J5cHRlZElkPUEwNTM2MTQ1RDA0VFA3V0lJUUZYJmVuY3J5cHRlZEFkSWQ9QTA3MzMzOTgzUzAwNTNCQkxWSk9XJndpZGdldE5hbWU9c3BfYXRmJmFjdGlvbj1jbGlja1JlZGlyZWN0JmRvTm90TG9nQ2xpY2s9dHJ1ZQ==">Startech USB3.0 to SATA adapter</a>. Another option is to install it to another USB thumb drive and use iSCSI storage for your VMs.</p>
<figure id="attachment_48263" aria-describedby="caption-attachment-48263"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/SSD-800x600.jpg" alt="SSD" width="696" height="522" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/SSD-800x600.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/11/SSD-400x300.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/11/SSD-696x522.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/11/SSD-560x420.jpg 560w, https://www.servethehome.com/wp-content/uploads/2020/11/SSD-80x60.jpg 80w, https://www.servethehome.com/wp-content/uploads/2020/11/SSD-265x198.jpg 265w, https://www.servethehome.com/wp-content/uploads/2020/11/SSD.jpg 1000w" sizes="(max-width: 696px) 100vw, 696px"><figcaption id="caption-attachment-48263">Intel DC S3500 SATA SSD with StarTech USB adapter</figcaption></figure>
<p>Select your disk, it has to be one other than the USB installer drive or the microSD card. Once you have selected your disk, the installer will format it and destructively remove all data. You need only to assign a password and installation will begin. When you are done, simply remove the installation media and reboot.</p>
<h2>Getting Started in VMware ESXi on the Pi</h2>
<p>To get started, open a web browser on another computer and point it to the IP of your Pi. Once there, you should see the familiar ESXi home page. For more information on setting up ESXi, please see our <a href="https://www.servethehome.com/building-a-lab-part-3-configuring-vmware-esxi-and-truenas-core/">Building a Lab series</a>.</p>
<figure id="attachment_48264" aria-describedby="caption-attachment-48264"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/esxi-home-800x450.png" alt="Esxi Home" width="696" height="392" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/esxi-home-800x450.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/esxi-home-400x225.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/esxi-home-696x392.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/esxi-home-1068x601.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/esxi-home-746x420.png 746w, https://www.servethehome.com/wp-content/uploads/2020/11/esxi-home.png 1276w" sizes="(max-width: 696px) 100vw, 696px"><figcaption id="caption-attachment-48264">VMware Esxi Home with VMware ESXi on Arm Fling Label</figcaption></figure>
<p>The first step we should do is to add our NTP servers. Go to&nbsp;<strong>Manage&nbsp;</strong>then to <strong>System</strong><strong>&nbsp;</strong>and finally to <strong>Time and Date. </strong>Add some NTP servers, then click on&nbsp;<strong>Services&nbsp;</strong>and start the <strong>ntpd</strong> service.</p>
<figure id="attachment_48265" aria-describedby="caption-attachment-48265"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/time-and-date-800x399.png" alt="Time And Date" width="696" height="347" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/time-and-date-800x399.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/time-and-date-400x200.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/time-and-date-696x347.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/time-and-date-842x420.png 842w, https://www.servethehome.com/wp-content/uploads/2020/11/time-and-date.png 1034w" sizes="(max-width: 696px) 100vw, 696px"><figcaption id="caption-attachment-48265">VMware ESXi on Arm Fling Time And Date</figcaption></figure>
<p>If you wanted to add iSCSI storage you can. For my testing, I added a 1TiB iSCSI LUN from my production TrueNAS Core box.</p>
<figure id="attachment_48267" aria-describedby="caption-attachment-48267"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/iscsi-800x256.png" alt="Iscsi" width="696" height="223" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/iscsi-800x256.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/iscsi-400x128.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/iscsi-696x223.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/iscsi-1068x342.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/iscsi.png 1281w" sizes="(max-width: 696px) 100vw, 696px"><figcaption id="caption-attachment-48267">VMware ESXi on Arm Fling iSCSI</figcaption></figure>
<p>Additionally, you can add it to a vCenter just like a normal ESXi host. You simply right-click on a datacenter, press <strong>A</strong><strong>dd Host,&nbsp;</strong>type your IP address, credentials and select a license.</p>
<figure id="attachment_48266" aria-describedby="caption-attachment-48266"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/vsphere-800x402.png" alt="Vsphere" width="696" height="350" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/vsphere-800x402.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/vsphere-400x201.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/vsphere-696x349.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/vsphere-1068x536.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/vsphere-837x420.png 837w, https://www.servethehome.com/wp-content/uploads/2020/11/vsphere.png 1281w" sizes="(max-width: 696px) 100vw, 696px"><figcaption id="caption-attachment-48266">VMware ESXi on Arm Fling vSphere</figcaption></figure>
<p>At this point, you are basically ready to get going with the VMware ESXi on Arm Fling using your Raspberry Pi.</p>
<h2>A Word on Some Limitations</h2>
<p>There are some limitations to this setup, however. As one example, ESXi on Arm cannot run X86 compatible operating systems. As a result, you will not be able to install Windows in the traditional sense. At this time Windows 10 for ARM is not supported. You will be able to install operating systems compiled for Arm, however. As a result, we see Ubuntu Server being a more popular guest OS than Windows Server.</p>
<p>Using ESXi on a Raspberry Pi in conjunction with something like Kubernetes makes for an interesting solution, however. This gives us tinkerers the ability to build an entire three node cluster on a single Raspberry Pi. While I certainly would not suggest doing this in production, it is a fantastic opportunity for learning and development.</p>
<h2>Final Words</h2>
<p>As Patrick stated in his piece <a href="https://www.servethehome.com/of-bbq-and-virtualization-large-nodes/">of BBQ and Virtualization</a>, large nodes make sense. With the advent of ESXi on Arm, we get to look at the other side of that picture. If you need a highly available solution for a lightweight application, you can use a cluster of Raspberry Pis to build a vSAN capable of obtaining that goal. Alternatively, if you are new to this world and just trying to learn, having ESXi available gives you access to what is used in the enterprise.</p>
<p>One of the coolest possibilities for this platform is for the Raspberry Pi to become a witness node for a cluster in vCenter. If you have two production x86 servers and are planning to build a vSAN, a RaspberryPi can be added as a witness node. This will effectively save you a ton of money by not having to buy a full-blown third server. Using a small node like this in the future can lower both up-front as well as operating costs over time due to the low power consumption. A note of warning, however. That is not an officially supported topology by VMWare, but it is certainly interesting! For those using other virtualization setups such as standard KVM on Linux clusters, this is a great use case as well.</p>
<figure id="attachment_47443" aria-describedby="caption-attachment-47443"><a href="https://www.servethehome.com/nvidia-bluefield-2-and-bluefield-2x-dpu-offerings-launched/nvidia-dpu-roadmap/" rel="attachment wp-att-47443"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/10/NVIDIA-DPU-Roadmap.jpg" alt="NVIDIA DPU Roadmap" width="1721" height="911" srcset="https://www.servethehome.com/wp-content/uploads/2020/10/NVIDIA-DPU-Roadmap.jpg 1721w, https://www.servethehome.com/wp-content/uploads/2020/10/NVIDIA-DPU-Roadmap-400x212.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/10/NVIDIA-DPU-Roadmap-800x423.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/10/NVIDIA-DPU-Roadmap-1536x813.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/10/NVIDIA-DPU-Roadmap-696x368.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/10/NVIDIA-DPU-Roadmap-1068x565.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/10/NVIDIA-DPU-Roadmap-793x420.jpg 793w" sizes="(max-width: 1721px) 100vw, 1721px"></a><figcaption id="caption-attachment-47443"><a href="https://www.servethehome.com/nvidia-shows-dpu-roadmap-combining-arm-cores-gpu-and-networking/">NVIDIA DPU</a> Roadmap</figcaption></figure>
<p>With Apple switching to Arm, NVIDIA looking to <a href="https://www.servethehome.com/nvidia-to-acquire-arm-in-major-shift/">acquire</a> Arm, and <a href="https://www.servethehome.com/an-arm-opportunity-with-cloud-service-providers/2/">Cloud Providers</a> looking more at Arm, VMWare has made a strong move here. To be clear, it needed to do this as it was falling behind in the edge. Likewise, VMware is many years behind Amazon AWS in the <a href="https://www.servethehome.com/what-is-a-dpu-a-data-processing-unit-quick-primer/">DPU</a> architecture but is catching up with <a href="https://www.servethehome.com/vmware-project-monterey-esxi-on-arm-on-dpu/">VMware Project Monterey ESXi on Arm on DPU</a>. It may be harder to buy a DPU today to work with ESXi on Arm, but it is relatively low-cost to simply get a Raspberry Pi. I am personally excited to see what happens next.</p>
        </div></div>]]>
            </description>
            <link>https://www.servethehome.com/getting-started-with-vmware-esxi-on-arm-with-a-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25029404</guid>
            <pubDate>Sun, 08 Nov 2020 21:49:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Demystifying malloc]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25028746">thread link</a>) | @riverg
<br/>
November 8, 2020 | https://river.codes/demystifying-malloc/ | <a href="https://web.archive.org/web/*/https://river.codes/demystifying-malloc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content"> <article itemscope="" itemtype="https://schema.org/BlogPosting">  <div itemprop="articleBody"> <p>It feels wrong to use a tool without knowing fully how it works. As programmers it is hard to accept that there is only so much that can fit into our noggins at once, but looking at code benchmarks or stack traces to see that some large amount of time is spent in some low-level C code always makes me wonder what is really going on in there. Maybe you’re like me and occasionally start to use the ‘Go to definition’ IDE feature on standard libraries, and after a second or two of searching your window fills with scary underscores and <code>#DEFINE</code>s of things you didn’t know existed, you think maybe this thing was auto-generated and no human would bother writing this header-file-hell. Unsatisfied you go back to whatever you were working on, no closer to understanding what’s <em>really</em> going on down there.</p> <p>For me I was always perplexed by <code>malloc</code>. It’s a simple function, you ask for memory and it gives it to you. But <em>how</em> could a C function do that? What on Earth does it mean to <em>allocate</em> memory? Isn’t it all there, sitting on the bus, just <strong>waiting</strong> for us to issue some good ‘ol <code>MOV</code> instructions? Even worse, it is used <em>everywhere</em>. Even if you aren’t using C there’s a good chance you’re using <code>malloc</code>, every time you create a new object in a language implemented in C, like <code>cpython</code> for instance. It isn’t the only way to acquire memory, but it sure is a popular one.</p> <p>So let’s take a look at <code>malloc</code>, it can’t be that complicated right? Here’s a simple <code>malloc</code>:</p> <div><div><pre><code><span>void</span><span>*</span> <span>malloc</span><span>(</span><span>size_t</span> <span>size</span><span>)</span> <span>{</span>
  <span>return</span> <span>sbrk</span><span>(</span><span>size</span><span>);</span>
<span>}</span>
</code></pre></div></div> <p>From this you may be able to figure out what <code>sbrk</code> does. It gives us a chunk of memory. Specifically it allocates program heap memory of a given size and returns a pointer to it. What exactly is “it” that is being pointed to? Let’s start printing stuff and find out.</p> <div><div><pre><code><span>void</span><span>*</span> <span>a</span> <span>=</span> <span>sbrk</span><span>(</span><span>0</span><span>);</span>
<span>void</span><span>*</span> <span>b</span> <span>=</span> <span>sbrk</span><span>(</span><span>100</span><span>);</span>
<span>void</span><span>*</span> <span>c</span> <span>=</span> <span>sbrk</span><span>(</span><span>0</span><span>);</span>
<span>printf</span><span>(</span><span>"[a: %p]</span><span>\n</span><span>[b: %p]</span><span>\n</span><span>[c: %p]</span><span>\n</span><span>"</span><span>,</span> <span>a</span><span>,</span> <span>b</span><span>,</span> <span>c</span><span>);</span>
</code></pre></div></div> <div><div><pre><code>&gt; [a: 0x1065b4064]
  [b: 0x1065b4064]
  [c: 0x1065b40c8]
</code></pre></div></div> <p>Looks like <code>b</code> is the same as <code>a</code> and <code>c</code> is <code>b + 100</code> bytes. So <code>sbrk</code> returns a pointer to whatever the last ‘tip’ of the program heap is, and if we give it a size in bytes it’ll move that ‘tip’ up. Meaning if we <code>sbrk</code> ourselves that 100 byte chunk we can do whatever we want with it knowing that the next time we <code>sbrk</code> ourselves some more memory, it’ll be 100 bytes farther along.</p> <p>This may not be too satisfying, we’ve replaced one magical function with another. However, in this case <code>sbrk</code> is a system call. It’s going to jump the CPU over to some assembly to execute (the instruction set implemented by your CPU is very likely to have a set of functions for interfacing with memory), at least now we’re talking to the kernel instead of wondering what’s going in the the C standard library.</p> <p>So that’s <code>malloc</code>, simple right? Well judging from the length of this article you can probably deduce otherwise. There’s more here, and for two reasons:</p> <ol> <li><code>sbrk</code> is absolutely ancient and super-deprecated. In fact if you run these snippets on macOS you’re going to get tons of warnings (but hey, it still works!). It doesn’t work with virtual memory and it isn’t thread-safe. However, its API is very simple to use and <code>malloc</code> at one point in time very likely was implemented using <code>sbrk</code>.</li> <li>This implementation of <code>malloc</code> is incorrect. The first reason why, which you may be able to guess, is that <code>sbrk</code> can fail. Memory is a finite resource.</li> </ol> <p>According to <code>man sbrk</code>, the call can return -1 if it fails, but <code>malloc</code> is supposed to return <code>NULL</code>. This is fixed easily enough.</p> <div><div><pre><code><span>void</span><span>*</span> <span>malloc</span><span>(</span><span>size_t</span> <span>size</span><span>)</span> <span>{</span>
  <span>void</span><span>*</span> <span>chunk_start</span> <span>=</span> <span>sbrk</span><span>(</span><span>size</span><span>);</span>
  <span>return</span> <span>chunk_start</span> <span>==</span> <span>(</span><span>void</span><span>*</span><span>)</span><span>-</span><span>1</span> <span>?</span> <span>NULL</span> <span>:</span> <span>chunk_start</span><span>;</span>
<span>}</span>
</code></pre></div></div> <p>One more thing. <code>malloc(0)</code> has special behavior, it needs to return <code>NULL</code> as well, otherwise you’d be able to get a pointer back from <code>malloc</code> that you didn’t actually allocate, and that would be weird.</p> <div><div><pre><code><span>void</span><span>*</span> <span>malloc</span><span>(</span><span>size_t</span> <span>size</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>size</span> <span>==</span> <span>0</span><span>)</span> <span>return</span> <span>NULL</span><span>;</span>
  <span>void</span><span>*</span> <span>chunk_start</span> <span>=</span> <span>sbrk</span><span>(</span><span>size</span><span>);</span>
  <span>return</span> <span>chunk_start</span> <span>==</span> <span>(</span><span>void</span><span>*</span><span>)</span><span>-</span><span>1</span> <span>?</span> <span>NULL</span> <span>:</span> <span>chunk_start</span><span>;</span>
<span>}</span>
</code></pre></div></div> <p>Great, now the user can actually know whether their memory request was fulfilled. We’re still missing something though, the result of our <code>malloc</code> doesn’t work with <code>free</code>. What <em>is</em> <code>free</code> exactly?</p> <p>According to <code>man free</code>, <code>free</code> will remove the allocation (“free”ing the space) from an input pointer that was previously returned from malloc. Now <code>sbrk</code> has a feature where when a negative input is passed to it, it will move the tip of the heap <em>down</em> instead of up. So effectively it allows us to push and pop from the program heap, because the heap is a stack and computer terminology is silly.</p> <p>Unfortunately this isn’t enough for us. Imagine a user does the following:</p> <div><div><pre><code><span>void</span><span>*</span> <span>a</span> <span>=</span> <span>malloc</span><span>(</span><span>500</span><span>);</span>
<span>// We can now call sbrk(-500) to free a.</span>
<span>void</span><span>*</span> <span>b</span> <span>=</span> <span>malloc</span><span>(</span><span>1000</span><span>);</span>
<span>// But how do we free a from here?</span>
</code></pre></div></div> <p>This is the age-old problem of trying to delete something from the middle of the stack. We could pop everything off of the stack until we reach the memory we’re trying to delete (storing it somewhere else, we could even use the disk), then pop the item to delete, then push everything else back onto the stack. This would be miserably slow. We could also abandon the stack mentality and just use <code>memcpy</code> to copy over the old bytes. This would also be very slow, usually we expect <code>free</code> to take an insignificant amount of time to complete. In either of these cases, we’ve created a new problem: when shifting all of the old memory to utilize the newly free’d space, all of the pointers in the program refering to that old memory would be invalidated.</p> <p>It looks like we’re going to have take matters into our own hands. Maybe in the future we’ll have more memory than we know what to do with and never free anything. Until then we’ll need to do something clever. We have one thing going for us though, <code>malloc</code> always returns a pointer to <em>contiguous</em> memory. If we have a single “hole” of <code>free</code>d memory in the heap large enough to use somewhere, we can use it. It’s simply a matter, then, of us keeping track of the allocated chunks (and the “holes” created by <code>free</code>ing those chunks) ourselves.</p> <p>So maybe it was wrong to say earlier that <code>sbrk</code> “allocates” memory for us, because now it seems like it just moves some pointer and tells us where it used to be. The actual “allocation” part of <code>malloc</code> is something we’ll have to implement. Let’s set up a general outline of what we want to accomplish.</p> <div><div><pre><code><span>typedef</span> <span>struct</span> <span>chunk</span> <span>{</span>
  <span>size_t</span> <span>size</span><span>;</span>  <span>// size of user-accessible memory.</span>
  <span>struct</span> <span>chunk</span><span>*</span> <span>next</span><span>;</span>
  <span>bool</span> <span>allocated</span><span>;</span>
<span>}</span> <span>Chunk</span><span>;</span>

<span>Chunk</span><span>*</span> <span>heap</span><span>;</span>

<span>void</span><span>*</span> <span>chunk_data</span><span>(</span><span>Chunk</span><span>*</span> <span>chunk</span><span>)</span> <span>{</span>
  <span>// Adding 1 to a Chunk* will get us to the part of memory</span>
  <span>// directly after the fields.</span>
  <span>return</span> <span>chunk</span> <span>?</span> <span>chunk</span><span>+</span><span>1</span> <span>:</span> <span>NULL</span><span>;</span>
<span>}</span>

<span>// Returns the Chunk corresponding to the chunk's data.</span>
<span>Chunk</span><span>*</span> <span>chunk_metadata</span><span>(</span><span>void</span><span>*</span> <span>ptr</span><span>)</span> <span>{</span>
  <span>return</span> <span>ptr</span> <span>?</span> <span>(</span><span>Chunk</span><span>*</span><span>)</span><span>ptr</span><span>-</span><span>1</span> <span>:</span> <span>NULL</span><span>;</span>
<span>}</span>

 <span>// TODO: Do the hard part.</span>
<span>Chunk</span><span>*</span> <span>find_or_reserve_chunk</span><span>(</span><span>size_t</span> <span>size</span><span>);</span>

<span>void</span><span>*</span> <span>malloc</span><span>(</span><span>size_t</span> <span>size</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>size</span> <span>==</span> <span>0</span><span>)</span> <span>return</span> <span>NULL</span><span>;</span>
  <span>return</span> <span>chunk_data</span><span>(</span><span>find_or_reserve_chunk</span><span>(</span><span>size</span><span>));</span>
<span>}</span>

<span>void</span> <span>free</span><span>(</span><span>void</span><span>*</span> <span>ptr</span><span>)</span> <span>{</span>
  <span>Chunk</span><span>*</span> <span>chunk</span> <span>=</span> <span>chunk_metadata</span><span>(</span><span>ptr</span><span>);</span>
  <span>if</span> <span>(</span><span>!</span><span>chunk</span><span>)</span> <span>return</span><span>;</span>
  <span>chunk</span><span>-&gt;</span><span>allocated</span> <span>=</span> <span>false</span><span>;</span>
<span>}</span>
</code></pre></div></div> <p>We want some way to model the heap, so a linked list sounds simple enough. We could extend it to create an actual stack, but it isn’t really needed here. Normally we’d implement a linked list using <code>malloc</code>, but we’re implementing <code>malloc</code> so we can’t really use that, can we? So let’s just sneak our data structure in with the user data. The general idea is that for every chunk of memory allocated by <code>malloc</code>, the we store a few bytes (specifically <code>sizeof(Chunk)</code>) of metadata about that chunk right beforehand. We could store a pointer in Chunk to the actual user memory, but since the memory is contiguous we can easily compute where the metadata ends and the user data begins. <code>free</code>ing then becomes super easy, we can just get the metadata and mark that it’s no longer allocated. The hard part is using that information.</p> <div><div><pre><code><span>// Allocates a new chunk right after 'prev'.</span>
<span>Chunk</span><span>*</span> <span>allocate_chunk</span><span>(</span><span>Chunk</span><span>*</span> <span>prev</span><span>,</span> <span>size_t</span> <span>size</span><span>);</span>

<span>Chunk</span><span>*</span> <span>find_or_reserve_chunk</span><span>(</span><span>size_t</span> <span>size</span><span>)</span> <span>{</span>
  <span>Chunk</span><span>*</span> <span>prev_chunk</span> <span>=</span> <span>NULL</span><span>;</span>

  <span>// Initialize the heap if necessary.</span>
  <span>if</span> <span>(</span><span>!</span><span>heap</span><span>)</span> <span>{</span>
    <span>heap</span> <span>=</span> <span>allocate_chunk</span><span>(</span><span>prev_chunk</span><span>,</span> <span>size</span><span>);</span>
    <span>return</span> <span>chunk_data</span><span>(</span><span>heap</span><span>);</span>
  <span>}</span>

  <span>// Scan the heap for holes large enough for the chunk we want.</span>
  <span>Chunk</span><span>*</span> <span>chunk</span> <span>=</span> <span>heap</span><span>;</span>
  <span>while</span> <span>(</span><span>chunk</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>!</span><span>chunk</span><span>-&gt;</span><span>allocated</span> <span>&amp;&amp;</span> <span>chunk</span><span>-&gt;</span><span>size</span> <span>&gt;=</span> <span>size</span><span>)</span> <span>break</span><span>;</span>
    <span>prev_chunk</span> <span>=</span> <span>chunk</span><span>;</span>
    <span>chunk</span> <span>=</span> <span>chunk</span><span>-&gt;</span><span>next</span><span>;</span>
  <span>}</span>

  <span>if</span> <span>(</span><span>chunk</span><span>)</span> <span>{</span>
    <span>chunk</span><span>-&gt;</span><span>allocated</span> <span>=</span> <span>true</span><span>;</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>chunk</span> <span>=</span> <span>allocate_chunk</span><span>(</span><span>prev_chunk</span><span>,</span> <span>size</span><span>);</span>
  <span>}</span>

  <span>return</span> <span>chunk</span><span>;</span>
<span>}</span>
</code></pre></div></div> <p>From here you can devise faster ways of doing this. The memory-speed tradeoff here is real, you can avoid scanning the heap every time by reserving a portion of the start of the heap for a hash map storing holes by size requirement, but then of course you’ve got less of the heap for the user. You also need to consider the size of this portion. You won’t be able to grow it, since then you’d be invalidating user pointers.</p> <p>If speed is less of a concern, you’d want to scan the entire heap rather than stopping at the first available hole. With the above implementation the user would often get back chunks of memory where the allocation is actually greater than they requested. If you scan the entire heap, you can look for the smallest hole that fits the requirements. Another way of doing this is to terminate the chunk to always fit the requested size, creating a new chunk for the leftover data. You’d have to make sure whatever leftover has enough room for the metadata fields.</p> <p>This is why the data stored in the pointer returned from <code>malloc</code> is uninitiliazed, it may have been a chunk from some previously requested memory.</p> <p>The last bit is where we actually build up the heap model:</p> <div><div><pre><code><span>Chunk</span><span>*</span> <span>allocate_chunk</span><span>(</span><span>Chunk</span><span>*</span> <span>prev</span><span>,</span> <span>size_t</span> <span>size</span><span>)</span> <span>{</span>
  <span>Chunk</span><span>*</span> <span>chunk</span> <span>=</span> <span>(</span><span>Chunk</span><span>*</span><span>)</span><span>sbrk</span><span>(</span><span>size</span> <span>+</span> <span>sizeof</span><span>(</span><span>Chunk</span><span>));</span>
  <span>if</span> <span>(</span><span>chunk</span> <span>==</span> <span>(</span><span>Chunk</span><span>*</span><span>)</span><span>-</span><span>1</span><span>)</span> <span>{</span>
    <span>return</span> <span>NULL</span><span>;</span>
  <span>}</span>

  <span>if</span> <span>(</span><span>prev</span><span>)</span> <span>{</span>
    <span>prev</span><span>-&gt;</span><span>next</span> <span>=</span> <span>chunk</span><span>;</span>
  <span>}</span>

  <span>chunk</span><span>-&gt;</span><span>size</span> <span>=</span> <span>size</span><span>;</span>
  <span>chunk</span><span>-&gt;</span><span>allocated</span> <span>=</span> <span>true</span><span>;</span>
  <span>chunk</span><span>-&gt;</span><span>next</span> <span>=</span> <span>NULL</span><span>;</span>
  <span>return</span> <span>chunk</span><span>;</span>
<span>}</span>
</code></pre></div></div> <p>We take in …</p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://river.codes/demystifying-malloc/">https://river.codes/demystifying-malloc/</a></em></p>]]>
            </description>
            <link>https://river.codes/demystifying-malloc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25028746</guid>
            <pubDate>Sun, 08 Nov 2020 20:34:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Adding OpenStreetMaps to Matplotlib]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25028727">thread link</a>) | @jhrabb
<br/>
November 8, 2020 | https://bryanbrattlof.com/adding-openstreetmaps-to-matplotlib/ | <a href="https://web.archive.org/web/*/https://bryanbrattlof.com/adding-openstreetmaps-to-matplotlib/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><header><p>Adding context to thousands of dots</p><p> published:&nbsp; <time datetime="2020-10-21T00:00:00+00:00"> 21 October 2020 </time></p></header><p>Adding a map to your visuals is a great way to quickly understand the geographic information you're trying to investigate. Thankfully there are quite a few packages and libraries (like <a href="https://geopandas.org/">geopandas</a>, <a href="https://scitools.org.uk/cartopy/docs/latest/">cartopy</a>, <a href="https://github.com/rossant/smopy">smopy</a>, <a href="https://github.com/python-visualization/folium">folium</a>, <a href="https://github.com/MatthewDaws/TileMapBase">tilemapbase</a>, or <a href="https://ipyleaflet.readthedocs.io/en/latest/">ipyleaflet</a>) that can make creating these visuals fairly straightforward and easy in your jupyter notebooks or whatever stack you're using.</p><p>For this essay though, I'll walk through the process of adding a base-map from OpenStreetMap to you're matplotlib visuals without using any of these libraries. In the end, we'll have a visual much like this (very messy) scatter-plot of buses as they service route 16 in New Orleans.</p><img alt="A plot of the ~466,000 position reports for buses servicing route 16 as they work their way up and down South Claiborne Avenue, between South Carrollton Avenue and Harrah's near the French Quarter." src="https://bryanbrattlof.com/adding-openstreetmaps-to-matplotlib/route-16-plot.png"><div id="how-it-works"><h2>How it Works</h2><p>The ability to add our base-map to our <a href="https://matplotlib.org/">matplotlib</a> visuals relies on matplotlib's <a href="https://matplotlib.org/3.2.1/api/_as_gen/matplotlib.pyplot.imshow.html">imshow() function</a>, which internally uses the <a href="https://python-pillow.org/">Pillow library</a> to display images, or any other two dimensional scalar data we want (like <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html">numpy arrays</a>).</p><p>For example, if we download <a href="https://bryanbrattlof.com/pages/hi/profile.png">my self-portrait</a>, we can add the image to a plot using code like this:</p><div><pre><span></span><span>from</span> <span>matplotlib</span> <span>import</span> <span>pyplot</span> <span>as</span> <span>plt</span>

<span>img</span> <span>=</span> <span>plt</span><span>.</span><span>imread</span><span>(</span><span>'path/to/my/self-portrait.png'</span><span>)</span>
<span>plt</span><span>.</span><span>imshow</span><span>(</span><span>img</span><span>)</span>

<span>plt</span><span>.</span><span>show</span><span>()</span>
</pre></div><p>Resulting in a matplotlib visual that looks like this:</p><p><img alt="A matplotlib plot of a self portrait (stick figure drawing) of Bryan Brattlof" src="https://bryanbrattlof.com/adding-openstreetmaps-to-matplotlib/self-portrait-plot.png"></p></div><div id="creating-the-map"><h2>Creating the Map</h2><p>The easiest way to generate the base-map for <code>plt.imshow()</code> is to use a mapping service. These mapping services use enormous amounts of raw computing power to take the <a href="https://wiki.openstreetmap.org/wiki/Planet.osm">terabytes of map data</a> and render a map for us. Today there are quite a few services available online. The one I enjoy working with (and the one we will be using in this essay) is a free, community maintained service called <a href="https://www.openstreetmap.org/about">OpenStreetMap</a>.</p></div><div id="tile-servers"><h2>Tile Servers</h2><p>To make updating and sharing their work easier, OpenStreetMap (and virtually all other mapping services) have split their maps into billions of tiny (256 pixel) sections, called tiles, that we can download individually from their tile servers.</p><p>OpenStreetMap has <a href="https://wiki.openstreetmap.org/wiki/Tile_servers">quite a few tile servers</a> that style or prioritize different map features with some having a slightly different <a href="https://en.wikipedia.org/wiki/API">API</a> to request tiles. For example the <a href="http://maps.stamen.com/toner/#12/29.9722/-90.1167">Stamen Toner Map</a> that I used in the first visual and prefer for it's simple color pallet.</p><p>For this essay though, we'll use the default tile server's API to request tiles:</p><div><pre><span></span>URL = "https://tile.openstreetmap.org/{z}/{x}/{y}.png".format
</pre></div><p>This string formatting function will replace the <code>{z}</code>, <code>{x}</code>, and <code>{y}</code> with the tile coordinates and zoom level of the tile we want to download, where:</p><ul><li><code>{z}</code> is the "zoom" level ranging from 0 to 18. Zoom 0 being the most "zoomed out" and needs only one tile to depict <a href="https://tile.openstreetmap.org/0/0/0.png">the entire world</a> at that level.</li><li><code>{x}</code> is the number of tiles from the left most tile of the map.</li><li>and <code>{y}</code> is the number of tiles from the top most tile of the map.</li></ul><p>Both <code>{x}</code> and <code>{y}</code> depend on the zoom level <code>{z}</code> we've chosen, with larger zoom levels requiring more tiles to render the map. To understand how to calculate which tiles we need for our data-set, we'll need to understand how mapping projections work.</p></div><div id="map-projections"><h2>Map Projections</h2><p>Without going too deep into mapping projections, OpenStreetMap (along with many other mapping services) needed a way to convert <span>(<i>lat</i>, <i>lon</i>)</span> coordinates into planer <span>(<i>x</i>, <i>y</i>)</span> coordinates which work with their maps. Sadly there is no perfect way to do this.</p><p>Google (and everyone else eventually) settled on a variant of the <a href="https://en.wikipedia.org/wiki/Mercator_projection">Mercator Projection</a> called the <a href="https://en.wikipedia.org/wiki/Web_Mercator_projection">Web Mercator Projection</a> which simplifies the conversion by assuming the earth is a perfect sphere (it's not). This can (and does) lead to confusion in the final visuals and why many official bodies refuse to accept this standard.</p><p>The advantage of assuming the earth is a perfect sphere is that the equation to convert our GPS coordinates into Web Mercator coordinates is fairly straightforward. The <a href="https://wiki.openstreetmap.org/wiki/Main_Page">OpenStreetMap Wiki</a> has the algorithm available in <a href="https://wiki.openstreetmap.org/wiki/Mercator">multiple programming languages</a>. Here is the one for Python:</p><div><pre><span></span><span>import</span> <span>math</span>
<span>TILE_SIZE</span> <span>=</span> <span>256</span>

<span>def</span> <span>point_to_pixels</span><span>(</span><span>lon</span><span>,</span> <span>lat</span><span>,</span> <span>zoom</span><span>):</span>
    <span>"""convert gps coordinates to web mercator"""</span>
    <span>r</span> <span>=</span> <span>math</span><span>.</span><span>pow</span><span>(</span><span>2</span><span>,</span> <span>zoom</span><span>)</span> <span>*</span> <span>TILE_SIZE</span>
    <span>lat</span> <span>=</span> <span>math</span><span>.</span><span>radians</span><span>(</span><span>lat</span><span>)</span>

    <span>x</span> <span>=</span> <span>int</span><span>((</span><span>lon</span> <span>+</span> <span>180.0</span><span>)</span> <span>/</span> <span>360.0</span> <span>*</span> <span>r</span><span>)</span>
    <span>y</span> <span>=</span> <span>int</span><span>((</span><span>1.0</span> <span>-</span> <span>math</span><span>.</span><span>log</span><span>(</span><span>math</span><span>.</span><span>tan</span><span>(</span><span>lat</span><span>)</span> <span>+</span> <span>(</span><span>1.0</span> <span>/</span> <span>math</span><span>.</span><span>cos</span><span>(</span><span>lat</span><span>)))</span> <span>/</span> <span>math</span><span>.</span><span>pi</span><span>)</span> <span>/</span> <span>2.0</span> <span>*</span> <span>r</span><span>)</span>

    <span>return</span> <span>x</span><span>,</span> <span>y</span>
</pre></div></div><div id="downloading-a-tile"><h2>Downloading A Tile</h2><p>Now we can use the <code>point_to_pixels()</code> function to calculate the number of pixels from the top-left corner of the OSM map from the GPS coordinates in our data-set at any <code>zoom</code> level, for example the French Quarter of New Orleans:</p><div><pre><span></span><span>zoom</span> <span>=</span> <span>16</span>
<span>x</span><span>,</span> <span>y</span> <span>=</span> <span>point_to_pixels</span><span>(</span><span>-</span><span>90.064279</span><span>,</span> <span>29.95863</span><span>,</span> <span>zoom</span><span>)</span>
</pre></div><p>Dividing the number of pixels by <code>TILE_SIZE</code> will then give us the <code>{x}</code> and <code>{y}</code> that we need for the <code>URL()</code> function we created <a href="#tile-servers">a few sections ago</a> for the OpenStreetMap API.</p><div><pre><span></span><span>x_tiles</span><span>,</span> <span>y_tiles</span> <span>=</span> <span>int</span><span>(</span><span>x</span> <span>/</span> <span>TILE_SIZE</span><span>),</span> <span>int</span><span>(</span><span>y</span> <span>/</span> <span>TILE_SIZE</span><span>)</span>
</pre></div><p>That we can then use, along with the <a href="https://requests.readthedocs.io/en/master/">requests</a> and <a href="https://python-pillow.org/">Pillow</a> libraries, to download a tile from the OpenStreetMap tile servers:</p><div><pre><span></span><span>from</span> <span>io</span> <span>import</span> <span>BytesIO</span>
<span>from</span> <span>PIL</span> <span>import</span> <span>Image</span>
<span>import</span> <span>requests</span>

<span># format the url</span>
<span>url</span> <span>=</span> <span>URL</span><span>(</span><span>x</span><span>=</span><span>x_tiles</span><span>,</span> <span>y</span><span>=</span><span>y_tiles</span><span>,</span> <span>z</span><span>=</span><span>zoom</span><span>)</span>

<span># make the request</span>
<span>with</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>url</span><span>)</span> <span>as</span> <span>resp</span><span>:</span>
    <span>img</span> <span>=</span> <span>Image</span><span>.</span><span>open</span><span>(</span><span>BytesIO</span><span>(</span><span>resp</span><span>.</span><span>content</span><span>))</span>

<span># plot the tile</span>
<span>plt</span><span>.</span><span>imshow</span><span>(</span><span>img</span><span>)</span>
<span>plt</span><span>.</span><span>show</span><span>()</span>
</pre></div><p>Producing a tile of Jackson Square in the French Quarter of New Orleans:</p><p><img alt="the tile" src="https://bryanbrattlof.com/adding-openstreetmaps-to-matplotlib/french-quarter-plot.png"></p></div><div id="stitching-tiles-together"><h2>Stitching Tiles Together</h2><p>To download all the tiles needed for our visual, we'll need to calculate the limits of the data we'll be using in our visual. There are many ways we can do this, all of them are valid. For simplicity though, I'll calculate the <span><i>min</i></span> and <span><i>max</i></span> of both the <code>lat</code> and <code>lon</code> columns in my <a href="https://pandas.pydata.org/">pandas</a> DataFrame:</p><div><pre><span></span><span>top</span><span>,</span> <span>bot</span> <span>=</span> <span>df</span><span>.</span><span>lat</span><span>.</span><span>max</span><span>(),</span> <span>df</span><span>.</span><span>lat</span><span>.</span><span>min</span><span>()</span>
<span>lef</span><span>,</span> <span>rgt</span> <span>=</span> <span>df</span><span>.</span><span>lon</span><span>.</span><span>min</span><span>(),</span> <span>df</span><span>.</span><span>lon</span><span>.</span><span>max</span><span>()</span>
</pre></div><p>This gives us a bounding box (in GPS coordinates) that encompasses our entire data-set.</p><p>Next, just like we did in <a href="#downloading-a-tile">the last section</a>, we'll use the <code>point_to_pixels()</code> function to convert our GPS coordinates into Web Mercator coordinates.</p><div><pre><span></span><span>zoom</span> <span>=</span> <span>13</span>
<span>x0</span><span>,</span> <span>y0</span> <span>=</span> <span>point_to_pixels</span><span>(</span><span>lef</span><span>,</span> <span>top</span><span>,</span> <span>zoom</span><span>)</span>
<span>x1</span><span>,</span> <span>y1</span> <span>=</span> <span>point_to_pixels</span><span>(</span><span>rgt</span><span>,</span> <span>bot</span><span>,</span> <span>zoom</span><span>)</span>
</pre></div><p>That we can then divide by <code>TILE_SIZE</code> to calculate the minimum and maximum number of tiles we'll need to download for both the <code>{x}</code> and <code>{y}</code> arguments for the API:</p><div><pre><span></span><span>x0_tile</span><span>,</span> <span>y0_tile</span> <span>=</span> <span>int</span><span>(</span><span>x0</span> <span>/</span> <span>TILE_SIZE</span><span>),</span> <span>int</span><span>(</span><span>y0</span> <span>/</span> <span>TILE_SIZE</span><span>)</span>
<span>x1_tile</span><span>,</span> <span>y1_tile</span> <span>=</span> <span>math</span><span>.</span><span>ceil</span><span>(</span><span>x1</span> <span>/</span> <span>TILE_SIZE</span><span>),</span> <span>math</span><span>.</span><span>ceil</span><span>(</span><span>y1</span> <span>/</span> <span>TILE_SIZE</span><span>)</span>
</pre></div><p>As a precaution, we'll add an <code>assert</code> statement to limit the number of tiles we can download and save us from the embarrassment of accidentally burdening OpenStreetMap tile servers.</p><div><pre><span></span><span>assert</span> <span>(</span><span>x1_tile</span> <span>-</span> <span>x0_tile</span><span>)</span> <span>*</span> <span>(</span><span>y1_tile</span> <span>-</span> <span>y0_tile</span><span>)</span> <span>&lt;</span> <span>50</span><span>,</span> <span>"That's too many tiles!"</span>
</pre></div><p>Now that we've calculated which tiles we need to download from OpenStreetMap, we can use the built-in <a href="https://docs.python.org/3/library/itertools.html">itertools</a><code>product()</code> function to loop through every tile, downloading and saving the tiles to a single large pillow image using <a href="https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.paste">Pillow's paste() function</a>:</p><div><pre><span></span><span>from</span> <span>itertools</span> <span>import</span> <span>product</span>

<span># full size image we'll add tiles to</span>
<span>img</span> <span>=</span> <span>Image</span><span>.</span><span>new</span><span>(</span><span>'RGB'</span><span>,</span> <span>(</span>
    <span>(</span><span>x1_tile</span> <span>-</span> <span>x0_tile</span><span>)</span> <span>*</span> <span>TILE_SIZE</span><span>,</span>
    <span>(</span><span>y1_tile</span> <span>-</span> <span>y0_tile</span><span>)</span> <span>*</span> <span>TILE_SIZE</span><span>))</span>

<span># loop through every tile inside our bounded box</span>
<span>for</span> <span>x_tile</span><span>,</span> <span>y_tile</span> <span>in</span> <span>product</span><span>(</span><span>range</span><span>(</span><span>x0_tile</span><span>,</span> <span>x1_tile</span><span>),</span> <span>range</span><span>(</span><span>y0_tile</span><span>,</span> <span>y1_tile</span><span>)):</span>
    <span>with</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>URL</span><span>(</span><span>x</span><span>=</span><span>x_tile</span><span>,</span> <span>y</span><span>=</span><span>y_tile</span><span>,</span> <span>z</span><span>=</span><span>zoom</span><span>))</span> <span>as</span> <span>resp</span><span>:</span>
        <span>tile_img</span> <span>=</span> <span>Image</span><span>.</span><span>open</span><span>(</span><span>BytesIO</span><span>(</span><span>resp</span><span>.</span><span>content</span><span>))</span>

    <span># add each tile to the full size image</span>
    <span>img</span><span>.</span><span>paste</span><span>(</span>
        <span>im</span><span>=</span><span>tile_img</span><span>,</span>
        <span>box</span><span>=</span><span>((</span><span>x_tile</span> <span>-</span> <span>x0_tile</span><span>)</span> <span>*</span> <span>TILE_SIZE</span><span>,</span> <span>(</span><span>y_tile</span> <span>-</span> <span>y0_tile</span><span>)</span> <span>*</span> <span>TILE_SIZE</span><span>))</span>

<span>plt</span><span>.</span><span>imshow</span><span>(</span><span>img</span><span>)</span>
<span>plt</span><span>.</span><span>show</span><span>()</span>
</pre></div><p>Resulting in a plot like this:</p><p><img alt="A plot of New Orleans using the script we just developed to stitch multiple tiles together into one continuous map that we can place under our scatter plot in the next section." src="https://bryanbrattlof.com/adding-openstreetmaps-to-matplotlib/the-basemap.png"></p><p>The eagle-eyed among us will notice the image is too large for the visual we want to create. This is because of the <code>math.ceil()</code> and <code>int()</code> functions we used to round the pixel coordinates into <code>{x}</code> and <code>{y}</code> tiles we used above. To get our image back to size we'll need to crop out the fractions of tiles not inside our bounding box.</p></div><div id="cropping-the-basemap"><h2>Cropping the Basemap</h2><p>To help my human-eyed brethren, I added some lines to our previous graphic to help understand what's going on. Essentially some fraction of each tile we've downloaded (outlined in black) will be used in our final visual (outlined in red) that we calculated in <a href="#stitching-tiles-together">the last section</a>. Our goal for this section is to trim the fraction of tiles outside of our red square.</p><p><img alt="A plot of New Orleans with black lines outlining each tile we downloaded from the tile servers overlaid with a red line representing the section of the map we wish to keep after we crop the image." src="https://bryanbrattlof.com/adding-openstreetmaps-to-matplotlib/basemap-cropping-lines.png"></p><p>To curtail our oversize image, we'll use pillow's <a href="https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.crop">Image.crop()</a> function, which takes a tuple <code>(left, top, right, bottom)</code> measured in pixels from the top left corner to crop our image.</p><p><a href="https://bryanbrattlof.com/adding-openstreetmaps-to-matplotlib/StitchingTilesTogether">From our work above</a>, we know the pixel coordinates of the red square is defined as <code>x0, y0</code> and <code>x1, y1</code>. We can then multiply the tile coordinates <code>x0_tile, y0_tile</code> by <code>TILE_SIZE</code> to find the pixel coordinates for the top-left corner of the current (oversize) basemap:</p><div><pre><span></span><span>x</span><span>,</span> <span>y</span> <span>=</span> <span>x0_tile</span> <span>*</span> <span>TILE_SIZE</span><span>,</span> <span>y0_tile</span> <span>*</span> <span>TILE_SIZE</span>
</pre></div><p>It is a simple process of subtracting the edges of our red square from the pixel coordinates we just calculated for our oversize image to crop it to our desired size:</p><div><pre><span></span><span>img</span> <span>=</span> <span>img</span><span>.</span><span>crop</span><span>((</span>
    <span>int</span><span>(</span><span>x</span> <span>-</span> <span>x0</span><span>),</span>  <span># left</span>
    <span>int</span><span>(</span><span>y</span> <span>-</span> <span>y0</span><span>),</span>  <span># top</span>
    <span>int</span><span>(</span><span>x</span> <span>-</span> <span>x1</span><span>),</span>  <span># right</span>
    <span>int</span><span>(</span><span>y</span> <span>-</span> <span>y1</span><span>)))</span> <span># bottom</span>

<span>plt</span><span>.</span><span>imshow</span><span>(</span><span>img</span><span>)</span>
<span>plt</span><span>.</span><span>show</span><span>()</span>
</pre></div><p>Resulting in our final (properly sized) basemap for our visual:</p><p><img alt="A, now properly sized, plot of New Orleans using the cropping script we just developed to resize our basemap to the proper size for our visual." src="https://bryanbrattlof.com/adding-openstreetmaps-to-matplotlib/basemap-cropped.png"></p></div><div id="plotting-the-data"><h2>Plotting The Data</h2><p>Finally, with our basemap created, we can plot our data just like any other visual with some key exceptions. We can start by setting a <a href="https://matplotlib.org/3.3.1/api/_as_gen/matplotlib.pyplot.subplot.html">matplotlib subplots()</a> and a <a href="https://matplotlib.org/3.3.1/api/_as_gen/matplotlib.axes.Axes.scatter.html">scatter()</a> plot for the <code>lat</code> and <code>lon</code> columns in our pandas DataFrames:</p><div><pre><span></span><span>fig</span><span>,</span> <span>ax</span> <span>=</span> <span>plt</span><span>.</span><span>subplots</span><span>()</span>
<span>ax</span><span>.</span><span>scatter</span><span>(</span><span>df</span><span>.</span><span>lon</span><span>,</span> <span>df</span><span>.</span><span>lat</span><span>,</span> <span>alpha</span><span>=</span><span>0.1</span><span>,</span> <span>c</span><span>=</span><span>'red'</span><span>,</span> <span>s</span><span>=</span><span>1</span><span>)</span>
</pre></div><p>Then we'll add an extra argument to the <code>imshow()</code> function to properly locate our image in the final visual. The <code>extent</code> argument is used to move a image to a <a href="https://matplotlib.org/3.3.1/tutorials/intermediate/imshow_extent.html">particular region in dataspace</a>.</p><div><pre><span></span><span>ax</span><span>.</span><span>imshow</span><span>(</span><span>img</span><span>,</span> <span>extent</span><span>=</span><span>(</span><span>lef</span><span>,</span> <span>rgt</span><span>,</span> <span>bot</span><span>,</span> <span>top</span><span>))</span>
</pre></div><p>Next, we'll lock down the <span><i>x</i></span> and <span><i>y</i></span> axes to the limits we defined <a href="#stitching-tiles-together">a few sections ago</a> by using the <code>set_ylim()</code> and <code>set_xlim()</code> functions.</p><div><pre><span></span><span>ax</span><span>.</span><span>set_ylim</span><span>(</span><span>bot</span><span>,</span> <span>top</span><span>)</span>
<span>ax</span><span>.</span><span>set_xlim</span><span>(</span><span>lef</span><span>,</span> <span>rgt</span><span>)</span>
</pre></div><p>All of this work will produce a simple graphic with a (gorgeous) basemap of buses servicing New Orleans' Route 16.</p><p><img alt="The final visual we've been working to depicting the roughly 400,000 position reports of buses as they service route 16 of New Orleans." src="https://bryanbrattlof.com/adding-openstreetmaps-to-matplotlib/final-visual.png"></p></div></div></div>]]>
            </description>
            <link>https://bryanbrattlof.com/adding-openstreetmaps-to-matplotlib/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25028727</guid>
            <pubDate>Sun, 08 Nov 2020 20:32:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Trustpilot and Difficult Incentive Problems]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25028645">thread link</a>) | @lharries
<br/>
November 8, 2020 | https://harries.co/trustpilot/ | <a href="https://web.archive.org/web/*/https://harries.co/trustpilot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><blockquote>
<p>💡 TL;DR Trustpilot and Glassdoor are PR agencies for companies. Not impartial review platforms for customers. This creates a challenging incentive problem.</p>
</blockquote>
<p>Trustpilot enables customers to review companies and Glassdoor enables employees to review companies. They have similar and fascinating business models. Let’s dive into Trustpilot.</p>
<p><strong>How does Trustpilot work?</strong></p>
<p>Let’s imagine you are setting up an online physiotherapy clinic called StiffNecks.com. To build your reputation as a clinic you create a Trustpilot page. The first client comes along, has a great experience, and you send them an email to the Trustpilot page asking them to leave a review. The client had a great experience and writes a lovely review of StiffNecks.com rating it 5/5 stars. BOOM your Trustpilot page now has a 3.5/5 “TrustScore”. Wait, what?!</p>
<p>With that 3.5/5 rating, TrustPilot now has you hostage. They use a <a href="https://support.trustpilot.com/hc/en-us/articles/201748946-TrustScore-explained-How-is-the-TrustScore-calculated-">Bayesian average</a> to calculate the TrustScore which takes into account how old the reviews are, the frequency you collect reviews, and they start you with a lovely 7 reviews of 3.5 for good measure. In other words, they control what your reputation is. And they charge businesses for this service with incentives misaligned from the business and definitely the customer.</p>
<p>Let’s jump back to StiffNecks.com. You now have anxiety from the yellow 3.5/5 score staring at you and so with each new customer, you do your best to push them towards Trustpilot. Eventually, (with about 10x5 star reviews) you get past the dreaded 4/5 threshold beyond which no customer dares to buy. But with each new review, it signals to customers that this is a valid reflection of your business’s reputation. And did I forget that you get penalised if the frequency of collecting reviews decreases. No stopping now. A few days later you get a call from Trustpilot agent offering the paid service.</p>
<p><strong>Where do the incentives go wrong?</strong></p>
<p>The immediate incentive is for Trustpilot to charge businesses more. Pretty easy to do when they directly control a business’s reputation. How can Trustpilot charge more? By either threatening to reduce their reputation or helping them to improve their score.</p>
<p>How do you help a company improve their score? At the moment Trustpilot uses widgets to show reviews and tools to collect reviews. But… there’s also strong incentives for Trustpilot to curate/remove negative reviews. Something that is already happening at Glassdoor (<a href="https://news.ycombinator.com/item?id=24789865">anecdotal evidence here</a>).</p>
<p>What does this mean for the customer? Believing in Trustpilot as a measure of reputation is a crucial part of their flywheel. But there’s much stronger incentives to be on the side of helping paying businesses have an artificially high score.</p>
<p><strong>How can Trustpilot remedy this?</strong></p>
<p>I think Trustpilot is an awesome service for consumers but the incentive problem is tough… For Trustpilot to truly fix the incentive problem they would need to be directly aligned with the reviewer. But the obvious business models such as a paywalling reviews would strongly interfere with their flywheel.</p>
<p>It’s possible to continue charging businesses. But Trustpilot would need to play the long game - not fudging the reviews at any cost. Instead, continuing to be a forcing function for businesses to treat their customers better, and thus improve their score. But, moderating reviews is hard because customer experience is subjective and Trustpilot does not have proper validation for who has and has not been a customer. Solutions to the verification problem seem feasible, such as the Facebook retargeting mechanism of sharing a hashed list of their customer emails.</p>
<p><strong>Appendix: The Trustpilot flywheel</strong></p>
<p>More companies email customers to leave reviews on Trustpilot → More customers leave reviews → More customers trust and use Trustpilot → More companies sign up to Trustpilot → More companies email customers to leave reviews on Trustpilot → …</p></section></div>]]>
            </description>
            <link>https://harries.co/trustpilot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25028645</guid>
            <pubDate>Sun, 08 Nov 2020 20:23:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Live stream – Zig 0.7.0 Release Party]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25028620">thread link</a>) | @todsacerdoti
<br/>
November 8, 2020 | https://www.twitch.tv/kristoff_it | <a href="https://web.archive.org/web/*/https://www.twitch.tv/kristoff_it">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.twitch.tv/kristoff_it</link>
            <guid isPermaLink="false">hacker-news-small-sites-25028620</guid>
            <pubDate>Sun, 08 Nov 2020 20:19:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Tiny CI System]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25028450">thread link</a>) | @todsacerdoti
<br/>
November 8, 2020 | https://www.0chris.com/tiny-ci-system.html | <a href="https://web.archive.org/web/*/https://www.0chris.com/tiny-ci-system.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

<p>2020-11-08</p>
<p>This is a little demonstration of how little you need to host your own git
repositories and have a modest <a href="https://en.wikipedia.org/wiki/Continuous_integration">Continuous Integration</a>
system for them. All you need is a unixy
server you can ssh into, but arguably you can try this out locally as well.
We will use Redis at one point to queue tasks, but
strictly speaking this can be achieved without additional software. To keep things
simple this will only work with one repository, since this is only describing a
pattern.</p>
<p>The source code to all of that follows below can be found <a href="https://git.sr.ht/%7Estchris/tiny-ci">here</a>.</p>
<h2>Hosting bare git repositories</h2>
<p>Assuming you can ssh into a server and create a directory, this is all you need
to create a shareable git repository:</p>
<pre><code>$ git init --bare
</code></pre>
<p>Ideally you are using a distinct user for it (named <code>git</code>) and have it set to
use <code>git-shell</code> as its default shell. By convention bare repositories are stored
in directories which end in <code>.git</code>. You can now clone this repository from your
machine with:</p>
<pre><code>$ git clone ssh://git@host.example.com/~git/repo.git
</code></pre>
<h2>post-receive hooks</h2>
<p>A <a href="https://git-scm.com/docs/githooks#post-receive">post-receive hook</a> is an executable which can do some work as soon as something new was pushed to the repository. We will use an executable shell script which needs to go inside the <code>hooks</code> directory of the (bare) repository on the server side.</p>
<p>Now the most trivial thing to do would be to do the actual work in here, but this would block the <code>git push</code> on the client side, so we just want to enqueue a new job, return a handle and exit. If what you do takes only a short amount of time, you can stop here. Alternatively you can use this repository for deployments only, by defining it as a separate remote. But the goal here is to have tests run on every push, so we will split the job creation from the actual run.</p>
<p>This is where Redis comes into play for the job queueing. We will assume redis is installed and running and we will use redis-cli to access it from the script. We will use two data structures: a list of jobs waiting to be executed, referenced by a UUID we will generate and a hash where we can store the git revision and the state associated to a given job, as well as its output.</p>
<p>Note that git is passing three arguments to the script via stdin: the old revision before the push, the new revision and the current ref.</p>
<pre><code>#!/bin/bash
while read -r _ newrev ref
do
	id=$(uuid)
	echo "Starting CI job $id"
	redis-cli hset "$id" rev "$newrev" &gt;/dev/null
	redis-cli hset "$id" ref "$ref" &gt;/dev/null
	redis-cli lpush jobs "$id" &gt;/dev/null
done
</code></pre>
<h2>Defining build jobs</h2>
<p>By convention our system will run whatever is in an executable script named <code>ci.sh</code>. The drawback is that this only works with trusted systems and access to the repository needs to be guarded to prevent random code execution. The big advantage is that we don't need to come up with a job definition DSL or cumbersome file format.</p>
<p>Our convention will also be that the script will be passed one argument: the name of the git ref, so we can decide what to do based on the branch we are on.</p>
<p>Let's just put this into a file named <code>ci.sh</code>:</p>
<pre><code>#!/usr/bin/env bash

# the git ref gets passed in as the only argument
ref="$1"

# pretend we're running tests
echo "running tests"

# only deploy if we're on the main branch
[[ "$ref" == "refs/heads/main" ]] &amp;&amp; echo "Deploying"
</code></pre>
<h2>The build runner</h2>
<p>Now that jobs are queued the last piece missing is a job runner. We will make use of Redis' <a href="https://redis.io/commands/blpop">BLPOP command</a> to block until the jobs list has a new job for us. That job id will give us the revision we need to check out and will allow us to write back the output and status of the job.</p>
<p>Note that, as discussed, this assumes a repository called <code>test</code> is already checked out right next to the script.</p>
<p>tiny-ci.sh</p>
<pre><code>#!/usr/bin/env bash

# ./runner.sh is supposed to run on the server where your git repository lives

# the logic in here will run in an infinite loop:
# * (block and) wait for a job
# * run it
while :
do

# Announce that we're waiting
echo "Job runner waiting"

# We are using https://redis.io/commands/blpop to block until we have a new
# message on the "jobs" list. We use `tail` to get the last line because the
# output of BLPOP is of the form "list-that-got-an-element\nelement"
jobid=$(redis-cli blpop jobs 0 | tail -n 1)

# The message we received will have the job uuid
echo "Running job $jobid"

# Get the git revision we're supposed to check out
rev=$(redis-cli hget "${jobid}" "rev")
echo Checking out revision "$rev"

# Get the git ref
ref=$(redis-cli hget "${jobid}" "ref")

# Prepare the repository (hardcoded path) by getting that commit
cd test || exit; git fetch &amp;&amp; git reset --hard "$rev";

# Actually runs the job and saves the output
if ! output=$(./ci.sh "$ref" 2&gt;&amp;1);
then
    status="failed";
else
    status="success";
fi;

# Update the result status
redis-cli hset "${jobid}" "status" $status;

# Update the job output
redis-cli hset "${jobid}" "output" "$output";

echo "Job ${jobid} done"

done
</code></pre>
<h2>Running it</h2>
<p>Summing up:</p>
<ul>
<li>there's a bare git repository somewhere, called <code>test.git</code></li>
<li>we can clone the empty repo (or create a new one and add the respective remote)</li>
<li>on the server hosting the git repository we clone <code>test.git</code> into <code>test</code> and place <code>tiny-ci.sh</code> next to it</li>
<li>we run builds by starting <code>tiny-ci.sh</code> on the server hosting the repository</li>
</ul>
<p>Now if we <code>git push</code> a new commit to the <code>main</code> branch with the <code>ci.sh</code> file from above, the output will return the job id</p>
<pre><code>Enumerating objects: 5, done.
...
remote: Starting CI job dab82634-21cc-11eb-b3b3-9b8767dff47c
</code></pre>
<h2>Checking build status</h2>
<p>Knowing a job uuid, the easiest way to get the status
of a build is by using the <code>--csv</code> style output of the <a href="https://redis.io/commands/hgetall">HGETALL</a> command of redis.</p>
<pre><code>$ ssh example.com redis-cli --csv hgetall $JOB_UUID
"rev","f0706ea18a22031f84619b1161c8fbdb0dcd6850","ref","refs/heads/master","status","success","output","running tests\nDeploying"
</code></pre>
<h2>Possible further improvements</h2>
<ul>
<li>
<p><strong>multi-repo support</strong></p>
<p>This would mean changes to the <code>post-receive</code> hook to put jobs in a list named <code>job-${REPONAME}</code> and then have the worker also react based on that. Notice how <code>redis-cli blpop</code> takes several lists to watch and will also return the name of the list.</p>
</li>
<li>
<p><strong>job cleanup</strong></p>
<p>Creating a key for every job pollutes the redis database unnecesarily. Enqueuing the job could be done via <a href="https://redis.io/commands/setex">SETEX</a> so that the keys go away after one hour / one day / one week. The purpose of Redis here is short term storage and not long-term archival of job results</p>
</li>
<li>
<p><strong>more workers</strong></p>
<p>Scaling to multiple workers on the same machine would need different working folders (and some process isolation depending on the tasks run in there). Scaling to multiple machines would need access to a central redis instance for job distribution.</p>
</li>
<li>
<p><strong>worker isolation / sandboxing</strong></p>
<p>For more complex tasks some kind of process and file-system isolation is necessary. The worker could spin up VMs or Docker containers. The build system used on <a href="https://builds.sr.ht/">builds.sr.ht</a> for instance uses a <a href="https://man.sr.ht/builds.sr.ht/installation.md#security-model">Docker container run as an unprivileged user in a KVM qemu machine</a>.</p>
</li>
<li>
<p><strong>timestamps</strong></p>
<p>For convenience you would definitely want timestamps for every operation. This also allows to list queries like "the last five jobs" or to do maintenance on job results based on their time.</p>
</li>
<li>
<p><strong>notifications</strong></p>
<p>Any CI system will have some form of notifications and the simplest form would be to do something in the script, right at the end. But this covers only the success case, so a better approach would be to create a notification queue and have a notification worker react on that.</p>
</li>
</ul>
<p><a href="https://lobste.rs/s/fbc6wl/tiny_ci_system">Discuss on lobste.rs</a></p>


<ul>
  
</ul>

    </div></div>]]>
            </description>
            <link>https://www.0chris.com/tiny-ci-system.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25028450</guid>
            <pubDate>Sun, 08 Nov 2020 19:59:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[About iSH’s pending removal from the App Store]]>
            </title>
            <description>
<![CDATA[
Score 640 | Comments 369 (<a href="https://news.ycombinator.com/item?id=25028252">thread link</a>) | @tbodt
<br/>
November 8, 2020 | https://ish.app/app-store-removal | <a href="https://web.archive.org/web/*/https://ish.app/app-store-removal">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
        

<p><strong><span>Update</span></strong>: We got a call this evening from someone who runs App Review. They apologized for the experience we had, then told us they've accepted our appeal and won't be removing iSH from the store tomorrow. We'll stay in contact with them to work out details. Thanks everyone for your support!
</p>


<p>On Monday, October 26th, just four days after we launched iSH on the App Store, we received a call from Apple informing us that they had found our app noncompliant with section 2.5.2 of the App Store Review Guidelines and that they would remove the app from sale if we did not submit a satisfactory update within two weeks. Despite our best efforts, we do not believe we will be able to bring iSH into compliance by tomorrow, the conclusion of this 14 day period, and we expect iSH to no longer be available to download from the App Store after that time. We are working our hardest to get iSH back on the App Store as soon as possible and hope for your understanding and support as we navigate our next steps in this process.</p>

<p>Thanks for using iSH!<br>
Theodore Dubois, Saagar Jha &amp; Martin Persson</p>

<h2 id="why-is-ish-being-removed">Why is iSH being removed?</h2>
<p>Apple believes iSH is not compliant with section 2.5.2 of the App Store Review Guidelines, which governs applications which download and run executable code. Specifically, they believe that iSH “is not self-contained and has remote package updating functionality”, and suggest that we should “remove the remote network activity functionality which could allow for remote code importing into the app, such as wget or curl, or other remote network commands”. Additional communication with Apple has indicated that they believe that iSH is a security concern if we allow any sort of code importing by the user.</p>

<p><strong>We believe iSH is fully compliant with the App Store Review Guidelines.</strong> <a href="https://saagarjha.com/blog/2020/11/08/fixing-section-2-5-2/">Saagar has written</a> a more detailed analysis of why we believe this rejection is incorrect, how we believe Apple has misinterpreted and misapplied this rule to our app, and describe how 2.5.2’s poor wording coupled with the review team being unable to review functionality of scripting applications leads to mistaken classifications like these. At a high level, Apple has selectively targeted iSH using section 2.5.2 without fullying understanding our application, their own guidelines, or the consequences of what they are asking and how they affect the App Store ecosystem as a whole. <strong>Consistent enforcement of Apple’s incorrect interpretation would require the removal of all scripting apps, including many of the most popular applications in the App Store and some of Apple’s own applications.</strong></p>

<h2 id="what-have-we-done-to-get-ish-back-on-the-app-store">What have we done to get iSH back on the App Store?</h2>
<p>We’ve been working for the last two weeks to try to keep iSH available without interruptions. We have drafted numerous appeals, requests for clarifications, rule modifications, and explanatory emails. We’ve been on the phone with Apple for hours. Unfortunately, even with this we have been unable to resolve the issue, and the process has been significantly more stressful than we would have liked it to be. Theodore, the primary iSH liaison to Apple, <a href="https://tbodt.com/2020/11/08/app-review-experiences.html">has written about</a> how this process should be improved.</p>

<p>Our first interaction with the App Store review team actually dates back to May, not October: we wanted to know what Apple thought of iSH, since we weren’t sure how the rules would be enforced for it. Of course, iSH complies with the letter of the guidelines, but review found it to violate 2.5.2 because it could download Linux executable code. The problem appeared that apk lets you install packages, so we decided to remove it and work on other features to make the app more useful in its absence. We submitted this updated build in October and this was what is currently on the App Store.</p>

<p>After our build was flagged for noncompliance, we went through the usual review process: we first asked for clarification, and then after we realized that the rule was being misapplied we submitted a rule change request and of course appealed the decision as well. As the deadline approached we sent off an email to Phil Schiller as well detailing our situation. Unfortunately none of this led anywhere, which brings up to our current situation today.</p>

<h2 id="does-this-mean-i-cant-use-ish-anymore">Does this mean I can’t use iSH anymore?</h2>
<p>No, not at all. However, it will mean that you will no longer be able to get iSH from the App Store, which is something which we would still like to be able to provide. The App Store remains the easiest and most popular method of software distribution on iOS, and we’re working hard to save iSH’s listing because we think the app should have a permanent spot there for users who prefer this method of distribution.</p>

<p>Removal of iSH’s listing on the App Store should not affect your use of iSH if you download the app before it is removed. We have not received any compliance messages from Apple regarding <a href="https://testflight.apple.com/join/97i7KM8O">our TestFlight beta</a>, so we plan to continue offering prerelease versions of iSH there for up to 10,000 beta testers.</p>

<p>Precompiled builds of iSH (distributed as IPA files) will <a href="https://github.com/ish-app/ish/releases">remain available on GitHub</a> for <a href="https://ish.app/altstore">installation through AltStore</a> and for jailbroken users. Advanced users are welcome to <a href="https://github.com/ish-app/ish#build-for-ios">build iSH</a> themselves—it’s free and open source and always will be!</p>

<p><strong><span>Update</span>: <a href="https://twitter.com/a_Shell_iOS/status/1325526061099196416">a-Shell has mentioned</a> that they have received a similar rejection notice. Apple may be running extra review for scripting apps.</strong></p>

        <hr>
        <p><a href="https://ish.app/">Return home</a> | 2020-11-08</p>
    

</div>]]>
            </description>
            <link>https://ish.app/app-store-removal</link>
            <guid isPermaLink="false">hacker-news-small-sites-25028252</guid>
            <pubDate>Sun, 08 Nov 2020 19:33:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CVE-2020-5387: Prevent a Dell XPS 9370 from booting]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25028250">thread link</a>) | @Sayrus
<br/>
November 8, 2020 | https://sayr.us/exploit/dell-exploit/ | <a href="https://web.archive.org/web/*/https://sayr.us/exploit/dell-exploit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>In August 2019, I’ve discovered a bug in how the XPS Bios handles a bootable
device. This bug allows an attacker with write permission to a bootable device
or physical access to the computer to prevent it from booting.</p>

<h2 id="the-bug">The bug</h2>

<blockquote>
  <p>The vulnerability is available <a href="https://www.dell.com/support/article/en-us/sln322626/dsa-2020-209-dell-xps-13-9370-improper-exception-handling-vulnerability">on Dell’s website</a>
or by its <a href="https://nvd.nist.gov/vuln/detail/CVE-2020-5387">CVE Identifier</a>.</p>
</blockquote>

<p>The Dell XPS reads and drops file on the primary disk during the booting and
BIOS upgrade process. Namely, it drops:</p>
<ol>
  <li><code>/boot/EFI/Dell/Bios/Recovery/BIOS_PRE.rcv</code></li>
  <li><code>/boot/EFI/Dell/Bios/Recovery/BIOS_CUR.RCV</code></li>
</ol>

<p>These files are used by a process called BIOS Recovery Tool. On the XPS 9370,
<a href="https://www.dell.com/support/article/en-us/sln300716/how-to-recover-the-bios-on-a-dell-computer-or-tablet">BIOS Recovery 3</a>
is used.</p>

<blockquote>
  <p><code>BIOS_PRE.rcv</code> is used for F2/F12 recovery.
<code>BIOS_CUR.rcv</code> is used only during the process of flash update failures. After the successful FW update <code>BIOS_CUR.rcv</code> is always copied to <code>BIOS_PRE.rcv</code>.</p>
</blockquote>

<p>When <code>BIOS_PRE.rcv</code> is corrupted, the BIOS crashes. Triggering this bug prevents
the laptop from accessing the boot menu and accessing the BIOS. The only way to
recover from the exploit is to unplug the exploited boot device. If the exploit is
done on the internal disk, this means that you need to disassemble the laptop.</p>

<p>When “Bios Recovery from Hard Drive” is disabled, recovery (and the exploit) only works from USB stick / USB hard drive.</p>

<h2 id="a-tale-of-failure">A tale of failure</h2>

<p>This writeup is not your usual exploit writeup. I am not an experienced
attacker, especially not against a blackbox such as my laptop’s BIOS. So how did
I end up finding it?</p>

<p>It all started while I was benchmarking my laptop’s internal drive using <code>fio</code>. I
simply wrote <code>randrw</code> instead of <code>randread</code> and thus overwrote a part of my
own hard drive. This part mostly included my boot partition and the two aforementioned BIOS
files.</p>

<p>Luckily, I already had a live Arch Linux USB key to repair everything. My plan was
simple: reboot, fix, reboot. That doesn’t sound so hard!</p>

<p><img src="https://sayr.us/assets/images/20minutesadventure.jpg" alt="Reboot and fix. Twenty minutes adventure."></p>

<p>After rebooting, I could not access a single BIOS Menu. Everything either froze
on a black screen, or on “Preparing one-time boot menu”. If I was unable to boot
anything or access the BIOS setup, I was not going to be able to fix my problem.</p>

<p>At that time, I didn’t know I found a bug in the BIOS, only that I somehow
fucked up so hard that my laptop was bricked. So I contacted the Dell support,
because I should not be able to brick my laptop like this! They agreed that it
was not supposed to happen and offered me a replacement.</p>

<h3 id="backups-and-a-surprise">Backups and a surprise</h3>

<p>Before sending back my laptop, I wished to recover what I was working on as it
had yet to be pushed. So I took the NVMe out of the laptop and put it in another
machine to dump a disk image. Right after removing the NVMe, I could access the
Bios and even boot on my USB stick.</p>

<p>Was my NVMe broken? From another computer, I could access any file on it. The
boot partition was indeed corrupted but the content of the LUKS partition was
sane.</p>

<p>Well then, if it’s not hardware, is it something on the drive? I dumped a full
disk image on an external HDD, tried to boot it on my laptop and <strong>boom</strong>. I
just reproduced the bug I had earlier on another drive.</p>

<p>I couldn’t miss the chance to play with what I had found so I kept a full disk
image as a backup of my data and another as a way to trigger the bug.</p>

<h3 id="finding-the-culprit">Finding the culprit</h3>

<p>Now that I had a disk image that triggered the bug, it was time to investigate.
At that point, the only information I had were:</p>
<ul>
  <li>I wrote random bytes on my disk, including in the partitions table, the boot
partition, and part of my encrypted disk</li>
  <li>Something on the disk is definitely messing up with the BIOS</li>
  <li>Duplicating the disk image and plugging it in as a USB Disk triggers the bug</li>
</ul>

<p>I assumed that bytes inside my encrypted partition were not the cause as the
BIOS had no reason to read them and they were valid when read from another
computer. Hopefully, it is not broken hardware either.</p>

<h4 id="partitions-table">Partitions table</h4>

<p>My first guess was that my partitions table was invalid and something broke
while enumerating tables. For instance, I might have been listing a partition
offset outside of the disk size, or an invalid size.</p>

<p>To verify that, I created a new partition table from scratch and copied the boot
partition content (files) and tried to boot.</p>

<p>Spoiler alert: <strong>Still broken.</strong></p>

<p>Even better, I did not copy my encrypted partition so the bug was definitely
triggered by something inside the boot partition!</p>

<h4 id="boot-partition">Boot partition</h4>

<p>Obviously, there was something in my boot partition that triggered the bug. But
why would the BIOS read the content of the boot partition? Silly me, I did not
know that BIOS recovery from hard drive was a thing. As far as I knew, it might
have been coming from anything: an invalid folder name, a corrupted file or even
a hard-link to an invalid INode…</p>

<p><em>Obviously not an invalid hard-link as I just did copy the files and there were
no hard-links on this new drive…</em></p>

<p>I was lacking the experience in this kind of bug so the easiest way for me was
to proceed by elimination:</p>
<ul>
  <li><strong>Step 1:</strong> Delete a folder</li>
  <li><strong>Step 2:</strong> Try to boot</li>
  <li>If it boots, restore only this folder, and apply Step 1 to the content of this
folder</li>
  <li>If it does not boot, simply go back to Step 1</li>
  <li><strong>Repeat</strong> until there is only a single file or folder remaining that triggers
the bug</li>
</ul>

<p>I deleted files using this method until I found out that deleting the
<code>/boot/EFI/Dell/Bios/Recovery</code> folder fixed the issue.</p>

<p><strong>Fixed !</strong></p>

<p>At this point, I notified Dell about the bug and sent them the two files that
were triggering the bug. The BIOS being closed source, it would be time
consuming to find:</p>
<ul>
  <li>What the format of <code>BIOS_PRE.rcv</code> and <code>BIOS_CUR.rcv</code> was (looking at
Dell’s documentation, <em>it might just be a Windows executable</em>)</li>
  <li>What field in that file triggers the bug</li>
</ul>

<p>I might have been able to <code>hexdiff</code> a working file with the broken one, to
highlight the differences. However, that would not have given me a better
understanding of the issue. From there, Dell took over and we now have access to
the result of the investigation: <strong>Improper Exception Handling</strong>.</p>

<h2 id="timeline">Timeline</h2>

<ul>
  <li>12 August 2019: Message sent to secure@dell.com without the PoC</li>
  <li>13 August 2019: Answer from Dell asking for more details</li>
  <li>11 September 2019: Message sent to secure@dell.com with steps to reproduce,
including a small disk image and the broken files.</li>
  <li>12 September 2019: Answer from Dell with the ticket number</li>
  <li>26 September 2019: Dell confirmed the problem exists</li>
  <li>January 2020: Dell plans to try to release a patch in April</li>
  <li>April 2020: Dell plans to publish the patch end of May</li>
  <li>May 2020: Dell plans to publish the patch beginning of July</li>
  <li>19 August 2020: Bios 1.13.1 released with the patch</li>
  <li>29 September 2020: Dell notifies me a Security Advisory was published</li>
  <li>16 October 2020: Dell updates the CVE score as the CVE does not require physical access, only high privileges</li>
</ul>

<h2 id="final-words">Final words</h2>

<p>The story might have begun as a scary <em>do your backups</em> story, but it ends without
any data-loss and with a reported vulnerability. Overall, it was a lot of fun and
a fine addition to my collection.</p>

<p>Perhaps next time we’ll talk about how to destroy the displayed image on my
monitor using only a JPEG file or making a video input detected as HDR by
squeezing the DisplayPort cable.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://sayr.us/exploit/dell-exploit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25028250</guid>
            <pubDate>Sun, 08 Nov 2020 19:33:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We Pay for Software]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25027907">thread link</a>) | @aberoham
<br/>
November 8, 2020 | https://adamwiggins.com/making-computers-better/pay | <a href="https://web.archive.org/web/*/https://adamwiggins.com/making-computers-better/pay">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <h3>how we pay for software</h3>

    <p>Quality software costs money to make.</p>

    <p>The tech industry has backed itself into a corner in the last couple decades by implying to users that software doesn’t cost much. Google led the charge here, by providing a series of useful and well-made applications like Gmail, Google Maps, and its core search product for free. They aren’t free, of course: users ”pay“ with their attention and personal data for advertisements.</p>

    <p>Paying with attention and personal data is probably a good trade for search and maps, maybe less so for email. But it’s not a model that fits professional and creative tools.</p>

    <p>Here are three proven models for paying for software:</p>

    <ul>
      <li><p><strong>Ad-supported software.</strong> Only really appropriate for pure-consumer products that are attention-oriented to begin with (e.g. social media). Requires huge scale since <a href="https://www.quora.com/What-is-Twitters-ARPU-average-revenue-per-user">each user is only worth a few bucks</a>. Because the user is the product rather than the customer, the user’s needs are not the priority of the business.</p></li>
      <li><p><strong>Software bundled with hardware or content.</strong> End users seem to be fine with paying directly for hardware (smartphone, laptop) or content (Netflix, Spotify). In these examples the software is a huge part of what you’re paying for—a Mac without macOS is just an overpriced PC, and Netflix without its excellent browsing and playback software is just cloud storage media stocked with MP4 files. Yet few people think of themselves as paying for macOS or Netflix’s app.</p></li>
    </ul>

    <figure>
      <img src="https://adamwiggins.com/making-computers-better/spotify-pricing.png" alt="pricing page for Spotify">

      <figcaption>
        <svg width="50" height="10" viewBox="0 0 50 10" fill="none" xmlns="http://www.w3.org/2000/svg">
          <rect width="50" height="10" rx="2.5" fill="#298070"></rect>
        </svg>

        <p><a href="https://www.spotify.com/us/premium/">Spotify’s pricing</a> demonstrates the common price range for individually-purchased subscriptions: $5/month on the low end, $15/month on the high end.</p>
      </figcaption>
    </figure>

    <ul>
      <li><p><strong>B2B SaaS.</strong> ”Business-to-business software-as-a-service“ is a mouthful, but represents a a beautiful, pure, and simple payment model for software. A business has a problem; a software creator offers a web-based product that solves the problem; the business purchases directly from the creator, and continues to pay as long as they have the problem and the product is good. Interests are aligned, and the no-middleman nature of the web means software creators have a direct relationship with their customers. Everybody wins. That’s why there’s so many success stories here: Slack, GitHub, Mailchimp, Atlassian, Zoom, Notion, and Carta just to name a few.</p></li>
    </ul>

    <p>I seek a world with a great diversity of lovingly-crafted software for niche audiences. But niche is not possible with ad-supported which requires huge scale to work, and hardware and content licensing have massive up-front capital costs that imply financing models not compatible with small-scale.</p>

    <p>Happily, B2B SaaS is having its <a href="https://microconf.com/">revolution for small independents</a> right now. So what’s the equivalent of that for pro creator tools like <a href="http://www.telestream.net/screenflow/overview.htm">video editing</a> or <a href="https://www.literatureandlatte.com/scrivener/overview">writing</a> or <a href="https://www.devontechnologies.com/apps/devonthink">knowledge management</a>? Can we have something as beautiful and pure as B2B SaaS but for individuals as well as businesses, and for desktop, mobile, and other native apps?</p>

    <p>And indeed there does seem to be movement toward subscription-priced prosumer products in the $5 –&nbsp;$15/month range. See
      established players like
      <a href="https://www.dropbox.com/individual/plans-comparison">Dropbox</a>,
      <a href="https://evernote.com/compare-plans">Evernote</a>,
      <a href="https://ulysses.app/get/">Ulysses</a> and
      <a href="https://www.omnigroup.com/omnifocus/buy/">OmniFocus</a>;
      plus up-and-comers like
      <a href="https://hey.com/pricing/">HEY</a>,
      <a href="https://roamresearch.com/">Roam</a>,
      <a href="https://www.descript.com/pricing">Descript</a>, and my own venture <a href="https://museapp.com/">Muse</a>.
    </p>

    <figure>
      <img src="https://adamwiggins.com/making-computers-better/calendly-pricing.png" alt="pricing for Calendly">

      <figcaption>
        <svg width="50" height="10" viewBox="0 0 50 10" fill="none" xmlns="http://www.w3.org/2000/svg">
          <rect width="50" height="10" rx="2.5" fill="#298070"></rect>
        </svg>

        <p><a href="https://calendly.com/pages/pricing">Calendly’s pricing</a> is similar to other prosumer products.</p>
      </figcaption>
    </figure>

    <p>As a <strike>user</strike> customer, I like the idea of finding a few great tools that empower my work and paying for them directly. That gives me confidence the product will serve my needs long-term, because I’m the customer.</p>

    <p>And this doesn’t mean a bigger budget for my tech product purchases overall: I can subtract these subscriptions from the money I previously spent on a new phone and laptop every two years, then buy new hardware a little less often. Right now I think great software is more important than hardware advances, much as I love shiny new devices.</p>

    <p>As a software creator, I love the idea of serving a niche of customers who are deeply connected with the product I’m making and get lots of value from it. It has that pure, direct, and personal relationship we see in B2B SaaS, but maybe even more initimate because these are personal tools.</p>

    <p>Ok sounds good—but now the next problem with a direct-payment model. If we’re going to make software subscriptions work, we as creators have to address the sharp edges and <a href="https://www.matthewball.vc/all/misnomers">subscription fatigue</a> people may experience maintaining a stack of software subscriptions.</p>

    <p>Individuals are cautious about recurring billing due to poorly-designed—even <a href="https://help.nytimes.com/hc/en-us/articles/360003499613-Cancel-your-subscription">borderline scammy</a>—subscription buying, renewal, and canceling experiences. The reference worst-case scenario are gym memberships or mobile phone contracts: being trapped in a recurring payment that no longer fits your needs, and being forced to navigate a customer service maze to try to downgrade or cancel.</p>

    <p>So how can we give customers a great experience with subscriptions? A few proposals:</p>

    <ul>
      <li><p>Treat the <strong>buying experience as part of your product</strong>. Make it easy for prospective customers to see what they will get; making buying easy and fun; show them love afterward, not just a ”you’re all set“ dialog and nothing else.</p></li>
    </ul>

    <figure>
      <img src="https://adamwiggins.com/making-computers-better/gumroad-pay.png" alt="paying for a product on Gumroad">

      <figcaption>
        <svg width="50" height="10" viewBox="0 0 50 10" fill="none" xmlns="http://www.w3.org/2000/svg">
          <rect width="50" height="10" rx="2.5" fill="#298070"></rect>
        </svg>

        <p><a href="https://gumroad.com/">Gumroad</a> offers <a href="https://gumroad.com/l/NlhpD">a great buying experience</a> with a minimum of fuss.</p>
      </figcaption>
    </figure>

    <ul>
      <li><p>Make it <strong>easy to cancel</strong> at any moment. Canceling should be as smooth as purchasing initially. For bonus points, give a refund for any unused portion of purchased time.</p></li>
      <li><p>For longer-cycle payments (e.g. annual), give <strong>heads-up notifications before payment</strong> so that users are not surprised. Direct them on how they can cancel with just a couple of clicks. You shouldn’t want any money from someone who is no longer getting value from your product.</p></li>
    </ul>

    <figure>
      <img src="https://adamwiggins.com/making-computers-better/hey-cancel.png" alt="canceling your subscription on HEY">

      <figcaption>
        <svg width="50" height="10" viewBox="0 0 50 10" fill="none" xmlns="http://www.w3.org/2000/svg">
          <rect width="50" height="10" rx="2.5" fill="#298070"></rect>
        </svg>

        <p>HEY makes canceling easy: just two clicks. The confirmation dialog is clear on exactly what happens next.</p>
      </figcaption>
    </figure>

    <ul>
     <li><p>Don’t lock users out of their data, even if their trial runs out or their subscription ends. Make it easy to <strong>get at their data and export</strong> for use in other places.</p></li>
      <li><p>Don’t treat lapsed or canceled subscriptions as strangers or defectors. Instead, <strong>consider them alumni and offer them your respect</strong> and maybe even some extra perks. They’ve been customers in the past, so be thankful for that. Remember they might return as a customer in the future or refer other potential customers.</p></li>
    </ul>

    <figure>
      <img src="https://adamwiggins.com/making-computers-better/slack-credit.png" alt="a credit for inactive users on Slack">

      <figcaption>
        <svg width="50" height="10" viewBox="0 0 50 10" fill="none" xmlns="http://www.w3.org/2000/svg">
          <rect width="50" height="10" rx="2.5" fill="#298070"></rect>
        </svg>

        <p>Slack delights and surprises with their <a href="https://slack.com/intl/en-de/help/articles/218915077-Fair-Billing-Policy">fair billing policy</a>.</p>
      </figcaption>
    </figure>

    <p>Beyond prosumer subscriptions, I’m happy to see products experimenting with models appropriate to their domain, like the ski app <a href="https://twitter.com/parrots/status/1314192830500347906">Slopes offering</a> packs of day passes; time-based notes app <a href="https://medium.com/@drewmccormack/cash-cow-revisited-4c2185e2b3d8">Agenda</a> with feature unlock based on subscription time windows; and <a href="https://www.komoot.com/product">Komoot</a> with hiking region budles for sale.</p>

    <p>One last one I find especially promising is the half-crowdfunding, half-early-purchase model that’s seen success with <a href="https://store.steampowered.com/earlyaccessfaq/?snr=1_200_200_Early+Access">video games</a>, <a href="https://www.studiobinder.com/blog/kickstarter-film-projects/">films</a>, and <a href="https://www.futurefonts.xyz/about">typefaces</a>. This blurs the distinctions between customer, investor, and donor. When you buy a Steam Early Access game you’re saying not just ”I want to purchase this product“ but also ”I believe in this product and the team behind it; I want it to exist; and I’m willing to risk a bit of my money to make that happen.“ And maybe: ”I like getting to give early feedback and influence the outcome of the finished product.“ <a href="https://wikimediafoundation.org/support/">Wikipedia with its pure patronage model</a> and <a href="https://www.are.na/roadmap">Are.na with its earnings transparency</a> are variations on this theme.</p>

    <p><strong>The world we have:</strong> Almost all software is paid for by (1) ads and selling personal data (2) bundling software with hardware or content or (3) business-purchased subscriptions. As a result, the type of software we have is limited to what will fit in those boxes.</p>

    <p><strong>The world I want:</strong> A wide diversity of funding and payment models for pure software products. Prosumer subscriptions are commonplace; users feel great about buying tools that matter to them; and they get a great experience when buying and canceling. Crowdfunding, patronage, and many other models flourish and individual products can choose the model that best fits them and their customers.</p>
  </article></div>]]>
            </description>
            <link>https://adamwiggins.com/making-computers-better/pay</link>
            <guid isPermaLink="false">hacker-news-small-sites-25027907</guid>
            <pubDate>Sun, 08 Nov 2020 18:51:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It’s OK to Not Care About Politics]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 48 (<a href="https://news.ycombinator.com/item?id=25027906">thread link</a>) | @freediver
<br/>
November 8, 2020 | https://www.meta-nomad.net/its-ok-to-not-care-about-politics/ | <a href="https://web.archive.org/web/*/https://www.meta-nomad.net/its-ok-to-not-care-about-politics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1182">

	<!-- .entry-header -->

	
	<div>

		<p><span>During recent research into the life of Machiavelli something began to become quite clear to me. We weren’t always, universally, socially, communally or even personally, political. That is to say, it’s only recently that it’s become commonplace to declare oneself as left, right, Republican, Democrat, Labour, Conservative, Centrist, Reactionary, Socialist, Red, Blue, x-pilled, y-pilled etc. In terms of human history this way of </span><span><em><span>being</span></em></span><span> – as a political-being, or even as homo-politicus – is </span><span><em><span>extremely</span></em></span><span> new. The very idea of a left/right split/spectrum comes from where people sat during the French Revolution, when members of the National Assembly divided themselves into those in support of the king (right) and supporters of the Revolution (left). Arguably this is one and only time that the idea of a left/right spectrum has ever made sense. Since then </span><span><em><span>both</span></em></span><span> ‘directions’ signal virtue to various camps and striate one into relatively specific ways of thinking. The year we’re roughly talking about here is 1789, that’s round that all up and say – for clarity’s sake – we’ve been political ‘beings’ for just over 200 years. Once again, humans in their current evolutionary iteration have been around for 200,000 years. So we’ve had this political chip on our shoulders for roughly 0.1% of our entire lifetime. Of course, you could argue that for a large amount of that time we haven’t exactly had the infrastructure to allow for what we now commonly understand as politics or political economy, but we </span><span><em><span>have</span></em></span><span> had that for a few thousand years at least, so even going by that metric, the notion of a political-being or of a political-human is still quite new. </span></p>
<p><span>It seems to me the reason for the original (non) position, wherein man wasn’t apolitical, nor anti-political, but simply detached from the political, wasn’t due to some oppression (though some would argue otherwise)[1], nor was it really to do with any ignorance; it was largely because in relation to man’s daily life, the specific political on-goings didn’t matter to him. I would argue that this is still true, we’re just all caught up in status and popularity games. </span></p>
<p><span>The very idea that within contemporary (Western) society one could be ‘detached’ from politics seems absurd, that’s how tight of a grasp it has on our lives. A grasp which is ever-tightened by the popular rhetoric surrounding politics. Society in general seems to unconsciously believe that they now have some kind of duty to </span><span><em><span>be</span></em></span><span> political, they must be in a certain camp, they must have certain opinions on various matters, and most of all, they must </span><span><em><span>care</span></em></span><span> in a specifically political way. I’m here to say that this way of thinking and being is complete bullshit, and it slowly leads one to misery and submission. There are a lot of factors as to why someone might feel compelled to constantly </span><span><em><span>be</span></em></span><span> political, largely emanating from one’s perpetual attachment to media. The two most heinous forms of media are – of course – social and mainstream. Primarily because, once you actually begin to think about what these terms actually mean, like most things in modernity, they no longer make any sense whatsoever. Let’s begin with ‘social media’.</span></p>
<p><span>We all apparently ‘know’ what social media is, which is another way of saying we understand it. I’ll admit, I don’t really understand social media, and I never have. The basic reasons as to why it’s so popular are of course clear, on average humans quite like attention, they quite like having a say and they quite like boasting about their lives. However, I would ask this? If it wasn’t </span><span><em><span>for</span></em></span><span> social media, and its invasive societally pressuring structures, would you actually </span><span><em><span>want</span></em></span><span> to express certain opinions? Would you even have them? Would you have even thought about them? Maybe you would, maybe you wouldn’t, be honest with yourself. If no one was looking, and you had no proof anyone </span><span><em><span>had</span></em></span><span> looked, would you expend energy on the various political and social tasks you do? Ok, so this then begs the question, why the hell </span><span><em><span>do</span></em></span><span> we want to express these opinions? Well, for that you need a mainstream current which tells you the correct, conventional and confirmative way to </span><span><em><span>be.</span></em></span><span> Enter the mainstream media. Such an idea of a ‘mainstream’ is already idiotic. There can’t be such a thing because we all live in different areas of the world, within different cultures, within different families, with different values, within different contexts, and so, the job the mainstream media then is to subsume all of these alternative ways of being and differing value systems into one relatively homogenous lump, which is then there’s to mold as they wish. I’d insert here Ted Kaczynski’s ‘critique’ of ‘multiculturalism’, though it’s less a critique and more of a deconstruction. Kaczynski’s point is that there isn’t really any such thing as ‘multiculturalism’ as it’s sold to us. The overt idea is that multiple diverse cultures live amongst one another, learn from each other and share their cultures for the betterment of all. Kaczynski makes it clear that this is </span><span><em><span>not</span></em></span><span> what happens within contemporary multiculturalism, all that really happens is that every culture is subsumed into the exact same culture of middle-class consumerist aspiration, and perhaps allowed to retain any cultural aesthetic which might be deemed profitable by their new culture of consumerist aspiration. The exact same thing happens with mainstream media. One begins with a variety of views, opinions, values, outlooks, perspectives and contexts which have been grown organically, from their local surroundings and upbringing, these are then pushed through the conformity thresher of mainstream media, cherry-picked for their applicability for submission, and what’s left are deemed dangerous, archaic, bad, fascist, radical, silly, absurd, weird, not-normal, odd or perhaps just too common-sensical for them to remain.</span></p>
<p><span>Now, the </span><span><em><span>exact</span></em></span><span> same process happens with the idea of a ‘political-human’ with a few minor alterations. Much like homo-criminalis, or homo-economicus, once the suffix is assumed </span><span><em><span>a priori</span></em></span><span> as a </span><span><em><span>way</span></em></span><span> of being – man </span><span><em><span>can</span></em></span><span> be a criminal, or man </span><span><em><span>can</span></em></span><span> be economical. There’s no longer such a thing as a man detached entirely from criminality or the economy, there is only a man who is </span><span><em><span>not</span></em></span><span> a criminal, or a man who acts within the economy in a </span><span><em><span>different</span></em></span><span> way than what is preferred. The exact same thing happens with political man. Once a political-outlook, a political-perspective or a political-reality is assumed as the given reality, everything is then filtered through politics in some manner. Then there is no longer such a thing as a entirely unpolitical man, only a man who is deemed ignorant of politics, someone who is seen as turning a blind eye or as simply too lazy to investigate that which they </span><span><em><span>should</span></em></span><span> be. The language here is the problem. Foucault makes this point clear with homo-criminalis and homo-economicus, once the ontology is taken as a given, no one is </span><span><em><span>not</span></em></span><span> of it, but simply seen as not part of a certain section of it. Men are not men, they are either criminals or </span><span><em><span>not-</span></em></span><span>criminals, we are not ourselves we are either economizing or </span><span><em><span>not-</span></em></span><span>economizing, either way, we’re still tethered to a way of being we had no say in.</span></p>
<p><span>Well I’m here to say that this is complete and utter crap. If you want to go get involved in politics, then be my guest, but do NOT assume that just because I don’t care about a certain topic, opinion or perspective that I am immediately the antagonist of that position. There is a difference between a hostile apathy, in which one truly doesn’t care about the plight of others and a detachment within one simply is not involved. Of course, any </span><span><em><span>involved</span></em></span><span> are going to disagree. ‘It’s your duty!’ they will cry. ‘Do you not care about the world!’ they will shriek. ‘How can you just do nothing?’ they will plead. Actually, I am doing something, I’m not expending my energy on a status game which largely exists to inflate various egos and create jobs. Lest we forget that politicians are </span><span><em><span>workers</span></em></span><span>, to be a politician is a </span><span><em><span>job</span></em></span><span>, and by the looks of it, quite a cushy one at that. </span></p>
<p><span>Being </span><span><em><span>detached</span></em></span><span> from politics isn’t </span><span><em><span>not caring</span></em></span><span> about those things you left behind, in fact, it’s arguably the opposite. As soon as a charitable organization, a communal effort or a group event becomes politicized, I am instantly skeptical of its agenda, why? Well, because since when did helping others, loving thy neighbor or creating something helpful </span><span><em><span>have</span></em></span><span> to be seen through a political lens. Call me a soppy-sod, but buying a homeless person some food, donating to a local charity or helping out in a local event isn’t – and doesn’t have to be – a specifically political move or motivation, and if it is, you’re doing so to cater to your own narcissism. What </span><span><em><span>are</span></em></span><span> these acts then? Well, they are what they are. You help someone because they need help, you do something because it needs doing, you create because something needs creating; once sincere acts are filtered through the malicious gauze of politics they are usually lost entirely, abused into a self-congratulatory mutation. </span></p>
<p><span>Ok, maybe you’re with me, but you’re starting to think…’Ok, so what do I…</span><span><em><span>do?</span></em></span><span>‘ Isn’t that the point? Up until now, for many people, each and every act they undertook was done primarily from a political position as opposed to the multitude of other (healthier) perspectives that exist. What do you do? Do what you’d like and what you understand to be right. </span></p>
<p><span>“Ah yes Meta, but if we ‘do nothing’ as you propose, wont we be simply bolstering support for whichever party is in the running to win?” You’re still thinking politically, why does it </span><span><em><span>actually</span></em></span><span> matter to you? If I support X I’ve entered into a system which is so unfathomably corrupt, confused and rife with personality that I will never </span><span><em><span>truly</span></em></span><span> know what it is my vote is doing. It is NOT an apathy, an ignorance or a superiority. It is a detachment. It is one unclipping themselves from a perspective they never asked for in the first place. The years upon years spent drooling …</span></p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.meta-nomad.net/its-ok-to-not-care-about-politics/">https://www.meta-nomad.net/its-ok-to-not-care-about-politics/</a></em></p>]]>
            </description>
            <link>https://www.meta-nomad.net/its-ok-to-not-care-about-politics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25027906</guid>
            <pubDate>Sun, 08 Nov 2020 18:51:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remote Work: Tips on how to successfully work remotely in 2020]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25027569">thread link</a>) | @martin_crd
<br/>
November 8, 2020 | https://remoteworkers.net/blog/7-tips-how-successfully-work-remotely-2020 | <a href="https://web.archive.org/web/*/https://remoteworkers.net/blog/7-tips-how-successfully-work-remotely-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>It’s no secret that this year has been a testing year on all fronts of our waking lives, leading us to ‘get out of our comfort zones’ and learn to adapt in vastly changing times. Subsequently, most employees have had to work remotely to some capacity (if not fully remotely), and we’ve all had to learn how to improve our work-life balance while finding new ways to still be as efficient as before in our professional lives.</p><p>Needless to say, today you do not need to be tech-savvy to adjust to the digital world. The key to surviving and succeeding in this world is to make sure you’re prepared with the necessary online tools, mindset, and time management skills.</p><p>Below is a list of tips to help you thrive in a digital workforce:</p><h2>1. Make sure you have a strong internet connection</h2><p>This may seem like a no-brainer, but possibly the first thing you need to make sure you have when working remotely is a strong internet connection. This will help ensure you’re always accessible to your colleagues, therefore able to carry out your daily tasks and duties without interruption. Depending on your household and the number of devices you have connected to your WIFI, you may need to upgrade your internet package so you have a fast and reliable connection.</p><p>Just as in the traditional work environment, it’s important to collaborate with your co-workers and management, and poor internet connection may hinder that. Luckily, most service providers provide affordable internet bundle packages that will cater to your needs without breaking your bank balance.</p><h2>2. Invest in good office furniture and computer equipment</h2><p>Following some basic, yet essential ergonomics tips can improve your efficiency, reduce fatigue and strain to your back and neck, and facilitate proper posture. That’s why it’s important to invest in comfortable and adjustable furniture just as much as it is to have reliable computer equipment and updated software to complete your home office setup.</p><p>When working an eight-hour day or more, maintaining proper posture while sitting is crucial, not only for immediate benefits but for long-term damage you may cause to your back if you do not adopt the correct seating posture with adequate lower back support. Adjustable chairs and tables are a must-have to help ease pressure and body discomfort while working.</p><p>What often goes overlooked is the importance of taking care of your eyes. Protect your eyes from digital eye strain with an anti-blue light screen protector for your laptop or display monitor and you’ll disrupt the chances of sleep deprivation, fatigue, and risk of macular degeneration.</p><h2>3. Have a dedicated workspace</h2><p>Apart from helping you curb unnecessary distractions from the TV, social media, or dare I say: your kids, having a dedicated workspace is necessary to help improve productivity and creativity. Usually, when you go to the office it’s easier to get into ‘work-mode’ since you’re in an environment that induces productivity, but when working from home, you have to put in a little more effort to stay focused and motivated. Avoid working from your bed, the couch, or anywhere else that may lead to inattentiveness and interruptions to the work at hand.</p><p>Working remotely is a benefit that requires both accountability and responsibility as an employee, so creating an environment that promotes efficiency<strong></strong>goes a long way. Even if you don’t have the luxury of having an actual office at home you can still dedicate a certain ‘work-zone’ (preferably close to a window so you can enjoy the benefits of fresh air and natural light) in a quiet part of your home.</p><h2>4. Take breaks</h2><p>Don’t be hesitant to take breaks during the day. Taking regular short breaks will help keep your productivity at a high as well as help you feel constantly recharged and engaged. These could include short breaks to meditate for 5-10 minutes, having coffee, stretching, or simply just walking around to increase your blood circulation. Incorporate the 20-20-20 rule into your schedule: Take a 20-second break every 20 minutes by looking at things at least 20 feet away.</p><p>You can set reminders on your phone to help you remember to get up and walk. You can even get creative and strategic in your approach and place certain equipment (like the printer for instance) in another room to necessitate getting up and walking.</p><h2>5. Keep learning and improving your skills.</h2><p>Continuously upgrading your knowledge and skills will not only help keep you relevant in your respective field but will also help you map out your career progression. In an ever-changing job market and surplus in demand for remote work, you need to be marketable to progress. The more skilled and experienced you are, the wider your opportunities and growth prospects.</p><p>There are amazing free online learning materials you can take advantage of, or find reasonably affordable online courses. Even reading books on self-improvement, motivation, and success will help to keep you driven and inspired.</p><h2>6. Engage with colleagues and maintain positive professional relationships</h2><p>One of the downsides of working remotely is that you lose the benefits of building rapport with colleagues and your managers, which can result in life-long and beneficial professional connections.</p><p>You spend 8 hours of the day working, so it’s important to have healthy relations with the people you work with so that you feel level-headed and motivated to work. Something as simple as a good morning message to using professional and friendly jargon to communicate will help facilitate solid and positive relationships.</p><p>Be proactive and participate actively in meetings, after-work activities (provided you’re protecting yourself and others by social distancing and wearing a mask), and any other engagement activities offered. Be mindful to respect each other's diversities but also know when to not distract your co-workers as you must always maintain a professional demeanor. This will help to build trust, mutual respect, and open communication amongst each other, and bring about teamwork.</p><h2>7. Disconnect and know when to ‘call it a day’</h2><p>Time is valuable, and so are you! In order to be the best employee you can be, you need to learn to take care of yourself and your health, including your mental health. In a cut-throat work environment where we’re constantly being graded on our performance, it’s easy to feel overwhelmed and work to an excess.</p><p>Follow a strict work schedule but know when it’s time to ‘switch off’ and relax. If you find yourself unable to disconnect, practice managing your time better throughout the day so you’re able to finish your work on time. This will help reduce stress and improve the quality of your sleep.</p><p>Working overtime is necessary in certain cases, but downfall into the trap where you don’t give yourself (and your family and loved ones) the time to live and enjoy your life. Remember, the most productive employees are the ones who are well-rested and feel motivated to work.</p></div></div>]]>
            </description>
            <link>https://remoteworkers.net/blog/7-tips-how-successfully-work-remotely-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-25027569</guid>
            <pubDate>Sun, 08 Nov 2020 18:13:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spring boot vs. quarkus vs. micranaut vs. helidon vs. vertx]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25027554">thread link</a>) | @ozkanpakdil
<br/>
November 8, 2020 | https://ozkanpakdil.github.io/microservicetests/2020-10-31-microservice-framework-test-11.html | <a href="https://web.archive.org/web/*/https://ozkanpakdil.github.io/microservicetests/2020-10-31-microservice-framework-test-11.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      <p>Here is total package generation times for separate modules,</p>

<figure><pre><code data-lang="bash"><span>[</span>INFO] eclipse-microprofile-kumuluz-test 1.0-SNAPSHOT ..... SUCCESS <span>[</span> 33.217 s]
<span>[</span>INFO] helidon-quickstart-se 1.0-SNAPSHOT ................. SUCCESS <span>[</span> 30.383 s]
<span>[</span>INFO] micronaut-demo 0.1 ................................. SUCCESS <span>[</span> 31.055 s]
<span>[</span>INFO] quarkus-demo 1.0.0-SNAPSHOT ........................ SUCCESS <span>[</span> 38.910 s]
<span>[</span>INFO] springboot-demo 0.0.1-SNAPSHOT ..................... SUCCESS <span>[</span> 11.680 s]
<span>[</span>INFO] vertx-demo 1.0.0-SNAPSHOT .......................... SUCCESS <span>[</span>  4.269 s]</code></pre></figure>

<p>Size of created packages:</p>

<table>
  <thead>
    <tr>
      <th>Size in MB</th>
      <th>Name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>21M</td>
      <td>eclipse-microprofile-kumuluz-test/target/eclipse-microprofile-kumuluz-test.jar</td>
    </tr>
    <tr>
      <td>7.0M</td>
      <td>helidon-se-netty/target/helidon-quickstart-se.jar</td>
    </tr>
    <tr>
      <td>14M</td>
      <td>micronaut/target/micronaut-demo-0.1.jar</td>
    </tr>
    <tr>
      <td>14M</td>
      <td>quarkus/target/quarkus-demo-1.0.0-SNAPSHOT-runner.jar</td>
    </tr>
    <tr>
      <td>18M</td>
      <td>spring-boot/target/springboot-demo-0.0.1-SNAPSHOT.jar</td>
    </tr>
    <tr>
      <td>6.8M</td>
      <td>vertx/target/vertx-demo-1.0.0-SNAPSHOT-fat.jar</td>
    </tr>
  </tbody>
</table>

<p>:: Spring Boot :: (v2.3.5.RELEASE) Started DemoApplication in 2.503 seconds (JVM running for 3.16)</p>

<figure><pre><code data-lang="bash"><span>----</span> Global Information <span>--------------------------------------------------------</span>
<span>&gt;</span> request count                                       2000 <span>(</span><span>OK</span><span>=</span>2000   <span>KO</span><span>=</span>0     <span>)</span>
<span>&gt;</span> min response <span>time                                      </span>0 <span>(</span><span>OK</span><span>=</span>0      <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> max response <span>time                                    </span>339 <span>(</span><span>OK</span><span>=</span>339    <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> mean response <span>time                                    </span>39 <span>(</span><span>OK</span><span>=</span>39     <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> std deviation                                         62 <span>(</span><span>OK</span><span>=</span>62     <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> response <span>time </span>50th percentile                          2 <span>(</span><span>OK</span><span>=</span>2      <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> response <span>time </span>75th percentile                         61 <span>(</span><span>OK</span><span>=</span>61     <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> response <span>time </span>95th percentile                        178 <span>(</span><span>OK</span><span>=</span>178    <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> response <span>time </span>99th percentile                        249 <span>(</span><span>OK</span><span>=</span>249    <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> mean requests/sec                                    400 <span>(</span><span>OK</span><span>=</span>400    <span>KO</span><span>=</span>-     <span>)</span></code></pre></figure>

<p>powered by Quarkus 1.9.1.Final) started in 1.098s. Listening on: http://0.0.0.0:8080</p>

<figure><pre><code data-lang="bash"><span>----</span> Global Information <span>--------------------------------------------------------</span>
<span>&gt;</span> request count                                       2000 <span>(</span><span>OK</span><span>=</span>2000   <span>KO</span><span>=</span>0     <span>)</span>
<span>&gt;</span> min response <span>time                                      </span>0 <span>(</span><span>OK</span><span>=</span>0      <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> max response <span>time                                    </span>430 <span>(</span><span>OK</span><span>=</span>430    <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> mean response <span>time                                    </span>33 <span>(</span><span>OK</span><span>=</span>33     <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> std deviation                                         61 <span>(</span><span>OK</span><span>=</span>61     <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> response <span>time </span>50th percentile                          2 <span>(</span><span>OK</span><span>=</span>2      <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> response <span>time </span>75th percentile                         40 <span>(</span><span>OK</span><span>=</span>40     <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> response <span>time </span>95th percentile                        169 <span>(</span><span>OK</span><span>=</span>169    <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> response <span>time </span>99th percentile                        260 <span>(</span><span>OK</span><span>=</span>260    <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> mean requests/sec                                    400 <span>(</span><span>OK</span><span>=</span>400    <span>KO</span><span>=</span>-     <span>)</span></code></pre></figure>

<p>micronaut version:2.0.1 Startup completed in 1163ms. Server Running: http://localhost:8080</p>

<figure><pre><code data-lang="bash"><span>----</span> Global Information <span>--------------------------------------------------------</span>
<span>&gt;</span> request count                                       2000 <span>(</span><span>OK</span><span>=</span>2000   <span>KO</span><span>=</span>0     <span>)</span>
<span>&gt;</span> min response <span>time                                      </span>0 <span>(</span><span>OK</span><span>=</span>0      <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> max response <span>time                                    </span>266 <span>(</span><span>OK</span><span>=</span>266    <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> mean response <span>time                                    </span>34 <span>(</span><span>OK</span><span>=</span>34     <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> std deviation                                         58 <span>(</span><span>OK</span><span>=</span>58     <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> response <span>time </span>50th percentile                          2 <span>(</span><span>OK</span><span>=</span>2      <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> response <span>time </span>75th percentile                         45 <span>(</span><span>OK</span><span>=</span>45     <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> response <span>time </span>95th percentile                        179 <span>(</span><span>OK</span><span>=</span>179    <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> response <span>time </span>99th percentile                        228 <span>(</span><span>OK</span><span>=</span>228    <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> mean requests/sec                                    400 <span>(</span><span>OK</span><span>=</span>400    <span>KO</span><span>=</span>-     <span>)</span></code></pre></figure>

<p>vertx version:3.9.4</p>

<figure><pre><code data-lang="bash"><span>----</span> Global Information <span>--------------------------------------------------------</span>
<span>&gt;</span> request count                                       2000 <span>(</span><span>OK</span><span>=</span>2000   <span>KO</span><span>=</span>0     <span>)</span>
<span>&gt;</span> min response <span>time                                      </span>0 <span>(</span><span>OK</span><span>=</span>0      <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> max response <span>time                                    </span>190 <span>(</span><span>OK</span><span>=</span>190    <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> mean response <span>time                                    </span>19 <span>(</span><span>OK</span><span>=</span>19     <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> std deviation                                         41 <span>(</span><span>OK</span><span>=</span>41     <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> response <span>time </span>50th percentile                          1 <span>(</span><span>OK</span><span>=</span>1      <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> response <span>time </span>75th percentile                          5 <span>(</span><span>OK</span><span>=</span>5      <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> response <span>time </span>95th percentile                        125 <span>(</span><span>OK</span><span>=</span>125    <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> response <span>time </span>99th percentile                        172 <span>(</span><span>OK</span><span>=</span>172    <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> mean requests/sec                                    400 <span>(</span><span>OK</span><span>=</span>400    <span>KO</span><span>=</span>-     <span>)</span></code></pre></figure>

<p>kumuluz version:3.11.0 Server – Started @5032ms</p>

<figure><pre><code data-lang="bash"><span>----</span> Global Information <span>--------------------------------------------------------</span>
<span>&gt;</span> request count                                       2000 <span>(</span><span>OK</span><span>=</span>2000   <span>KO</span><span>=</span>0     <span>)</span>
<span>&gt;</span> min response <span>time                                      </span>0 <span>(</span><span>OK</span><span>=</span>0      <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> max response <span>time                                    </span>343 <span>(</span><span>OK</span><span>=</span>343    <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> mean response <span>time                                    </span>48 <span>(</span><span>OK</span><span>=</span>48     <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> std deviation                                         77 <span>(</span><span>OK</span><span>=</span>77     <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> response <span>time </span>50th percentile                          3 <span>(</span><span>OK</span><span>=</span>3      <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> response <span>time </span>75th percentile                         75 <span>(</span><span>OK</span><span>=</span>75     <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> response <span>time </span>95th percentile                        223 <span>(</span><span>OK</span><span>=</span>223    <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> response <span>time </span>99th percentile                        292 <span>(</span><span>OK</span><span>=</span>292    <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> mean requests/sec                                    400 <span>(</span><span>OK</span><span>=</span>400    <span>KO</span><span>=</span>-     <span>)</span></code></pre></figure>

<p>Helidon SE 2.1.0 features: [Config, Health, Metrics, WebServer]</p>

<figure><pre><code data-lang="bash"><span>----</span> Global Information <span>--------------------------------------------------------</span>
<span>&gt;</span> request count                                       2000 <span>(</span><span>OK</span><span>=</span>2000   <span>KO</span><span>=</span>0     <span>)</span>
<span>&gt;</span> min response <span>time                                      </span>0 <span>(</span><span>OK</span><span>=</span>0      <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> max response <span>time                                    </span>472 <span>(</span><span>OK</span><span>=</span>472    <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> mean response <span>time                                    </span>76 <span>(</span><span>OK</span><span>=</span>76     <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> std deviation                                        108 <span>(</span><span>OK</span><span>=</span>108    <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> response <span>time </span>50th percentile                          7 <span>(</span><span>OK</span><span>=</span>7      <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> response <span>time </span>75th percentile                        123 <span>(</span><span>OK</span><span>=</span>123    <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> response <span>time </span>95th percentile                        331 <span>(</span><span>OK</span><span>=</span>331    <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> response <span>time </span>99th percentile                        419 <span>(</span><span>OK</span><span>=</span>419    <span>KO</span><span>=</span>-     <span>)</span>
<span>&gt;</span> mean requests/sec                                    400 <span>(</span><span>OK</span><span>=</span>400    <span>KO</span><span>=</span>-     <span>)</span></code></pre></figure>


      


    </article></div>]]>
            </description>
            <link>https://ozkanpakdil.github.io/microservicetests/2020-10-31-microservice-framework-test-11.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25027554</guid>
            <pubDate>Sun, 08 Nov 2020 18:12:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When “Progress” Is Backwards]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25027462">thread link</a>) | @pmarin
<br/>
November 8, 2020 | https://sabotage-linux.github.io/blog/8 | <a href="https://web.archive.org/web/*/https://sabotage-linux.github.io/blog/8">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>When "progress" is backwards</h2>

<p>20 Oct 2020 15:58 UTC</p>
<p>Lately I see many developments in the linux FOSS world that sell themselves as progress, but are actually hugely annoying and counter-productive.</p>

<p>Counter-productive to a point where they actually cause major regressions, costs, and as in the case of GTK+3 ruin user experience and the possibility that we'll ever enjoy "The year of the Linux desktop".</p>

<h2>Showcase 1: GTK+3</h2>

<p>GTK+2 used to be <em>the</em> GUI toolkit for Linux desktop applications.
It is highly customizable, reasonably lightweight and programmable from C, which means almost any scripting language can interface to it too.</p>

<p>Rather than improving the existing toolkit code in a backwards-compatible manner, <a href="https://www.freedesktop.org/">its developers</a> decided to introduce many breaking API changes which require a major porting effort to make an existing codebase compatible with the successor GTK+3, and keeping support for GTK+2 while supporting GTK+3 at the same time typically involves a lot of #ifdef clutter in the source base which not many developers are willing to maintain.</p>

<p>Additionally GTK+3 made away with a lot of user-customizable themeing options, effectively rendering useless most of the existing themes that took considerable developer effort for their creation.
Here's a <a href="https://ubuntu-mate.community/t/gtk3-regressions-from-a-gtk2-perspective/19511">list of issues</a> users are complaining about.</p>

<p>Due to the effort required to port a GTK+2 application to use GTK+3, many finished GUI application projects will never be ported due to lack of manpower, lost interest of the main developer or his untimely demise.
An example of such a program is the excellent audio editor <a href="http://www.metadecks.org/software/sweep/">sweep</a> which has seen its last release in 2008.
With Linux distros removing support for GTK+2, these apps are basically lost in the void of time.</p>

<p>The other option for distros is to keep both the (unmaintained) GTK+2 and GTK+3 in their repositories so GTK+2-only apps can still be used, however that causes the user of these apps to require basically the double amount of disk and RAM space as both toolkits need to live next to each other. Also this will only work as long as there are no breaking changes in the Glib library which both toolkits are built upon.</p>

<p>Even worse, due to the irritation the GTK+3 move caused to developers, many switched to QT4 or QT5, which requires use of C++, so a typical linux distro now has a mix of GTK+2, GTK+3, GTK+4, QT4 and QT5 applications, where each toolkit consumes considerable resources.</p>

<p>Microsoft (TM) knows better and sees backwards compatibility as the holy grail and underlying root cause of its success and market position. Any 25 year old Win32 GUI application from the Win95 era still works without issues on the latest Windows (TM) release. They even still support 16bit MS-DOS apps using some built-in emulator.</p>

<p>From MS' perspective, the freedesktop.org decision makers played into their hands when they decided to make GTK+3 a completely different beast.
Of course, we are <a href="https://en.wikipedia.org/wiki/Hanlon%27s_razor">taught to never believe in malice but in stupidity</a>, so it is unthinkable that there was actually a real conspiracy and monetary compensations behind this move.
Otherwise we would be conspiracy theorist nuts, right ?</p>

<h2>Showcase 2: python3</h2>

<p>Python is a hugely successful programming/scripting language used by probably millions of programmers.</p>

<p>Whereas python2 development has been very stable for many years, python3 changes at the blink of an eye. It's not uncommon to find that after an update of python3 to the next release, existing code no longer works as expected.</p>

<p>Many developers such as myself prefer to use a stable development environment over one that is as volatile as python3.</p>

<p>With the decision to <a href="https://mail.python.org/archives/list/python-announce-list@python.org/thread/OFCIETIXLX34X7FVK5B5WPZH22HXV342/">EOL python2</a> thousands of py2-based applications will experience the same fate as GTK+2 applications without maintainer: they will be rendered obsolete and disappear from the distro repositories. This may happen quicker than one would expect, as python by default provides bindings to the system's OpenSSL library, which has a history of making backwards-incompatible changes. At the very least, once the web agrees on a new TLS standard, python2 will be rendered completely useless.</p>

<p>Porting python2 to python3 isn't usually as involving as GTK+2 to GTK+3, but due to the dynamic nature of python the syntax checker can't catch all code issues automatically so many issues will be experienced at runtime in cornercases, causing the ported application to throw a backtrace and stopping execution, which can have grave consequences.</p>

<p>Many companies have <a href="https://www.techrepublic.com/article/jpmorgans-athena-has-35-million-lines-of-python-code-and-wont-be-updated-to-python-3-in-time/">millions of line of code still in python2</a> and will have to produce quite some sweat and expenses to make it compatible to python3.</p>

<h2>Showcase 3: ip vs ifconfig</h2>

<p>Once one had learned his handful of ifconfig and route commands to configure a Linux' box network connections, one could comfortably manage this aspect across all distros. Not any longer, someone had the glorious idea to declare ifconfig and friends obsolete and provide a new, more "powerful" tool to do its job: <code>ip</code>.</p>

<p>The command for bringing up a network device is now <code>ip link set dev eth1 up</code> vs the older <code>ifconfig eth1 up</code>. Does this really look like progress?
Worst, the documentation of the tool is non-intuitive so one basically has to google for examples that show the translation from one command to the other.</p>

<p>The same critics apply to <code>iw</code> vs <code>iwconfig</code>.</p>

<h2>Showcase 4: ethernet adapter renaming by systemd/udev</h2>

<p>Latest systemd-based distros come up with network interface names such as <code>enx78e7d1ea46da</code> or <code>vethb817d6a</code>, instead of the traditional <code>eth0</code>.
The interface names assigned by default on Ubuntu 20 are so long a regular human can't even remember them, any configuration attempt requires one to copy/paste the name from <code>ip a</code> output.
Yet almost every distro goes along with this <a href="https://www.freedesktop.org/wiki/Software/systemd/PredictableNetworkInterfaceNames/">Poettering/freedesktop.org-dictated</a> nonsense.</p>

<h2>Showcase 5: CMake, meson, and $BUILDSYSTEMOFTHEDAY</h2>

<p>While the traditional buildsystem used on UNIX, <code>autoconf</code>, has its warts, it was designed in such a way that only the application developer required the full set of tools, whereas the consumer requires only a POSIX compatible shell environment and a <code>make</code> program.</p>

<p>More "modern" build systems like <code>cmake</code> and <code>meson</code> don't give a damn about the dependencies a user has to install, in fact according to <a href="https://kevstras.com/programming/2017/12/18/meson.html">this</a>, <code>meson</code> authors claimed it to be one of their goals to force users to have a bleeding edge version of python3 installed so it can be universally assumed as a given.</p>

<p><code>CMake</code> is written in C++, consists of 70+ MB of extracted sources and requires an impressive amount of time to build from source. Built with debug information, it takes up 434 MB of my harddisk space as of version 3.9.3.
It's primary raison-d'etre is its support for the Microsoft (TM) Visual Studio (R) (TM) solution files, so Windows (TM) people can compile stuff from source with a few clicks.</p>

<p>The two of them have in common that they threw over board the well-known user interface to configure and make and invented their own NIH solution, which requires the user to learn yet another way to build his applications.</p>

<p>Both of these build systems seem to have either acquired a cult following just like systemd, or someone is paying trolls to show up on github with pull requests to replace GNU autoconf with either of those, for example <a href="https://github.com/containers/crun/issues/495">1</a> <a href="https://github.com/karelzak/util-linux/pull/968">2</a> .
Interestingly also, GNOME, which is tightly connected to freedesktop.org, has made it one of its goals to <a href="https://wiki.gnome.org/Initiatives/GnomeGoals/MesonPorting">switch all components to meson</a>.
Their porting effort involves almost every key component in the Linux desktop stack, including cairo, pango, fontconfig, freetype, and dozens of others. What might be the agenda behind this effort?</p>

<h2>Conclusion</h2>

<p>We live in an era where in the FOSS world one constantly has to relearn things, switch to new, supposedly "better", but more bloated solutions, and is generally left with the impression that someone is pulling the rug from below one's feet.
Many of the key changes in this area have been rammed through by a small set of decision makers, often closely related to Red Hat/Gnome/freedesktop.org.
We're buying this "progress" at a high cost, and one can't avoid asking oneself whether there's more to the story than meets the eye.
Never forget, Red Hat and Microsoft (TM) are <a href="https://www.redhat.com/en/partners/microsoft">partners</a> and might even have the same shareholders.</p>
</div></div>]]>
            </description>
            <link>https://sabotage-linux.github.io/blog/8</link>
            <guid isPermaLink="false">hacker-news-small-sites-25027462</guid>
            <pubDate>Sun, 08 Nov 2020 18:02:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: React Frontload V2 – Simple full-stack data loading for React]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25027368">thread link</a>) | @davnicwil
<br/>
November 8, 2020 | https://davnicwil.com/react-frontload | <a href="https://web.archive.org/web/*/https://davnicwil.com/react-frontload">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-reactroot="" data-reactid="1" data-react-checksum="1067123220"><div data-reactid="6"><div data-reactid="7"><p><img src="https://davnicwil.com/image/react-frontload-logo.png" width="100" height="100" data-reactid="8"></p></div><p data-reactid="10"><h2 data-reactid="11">Simple full-stack data loading for React</h2></p><p><a href="https://www.npmjs.com/package/react-frontload" data-reactid="13"><img src="https://img.shields.io/npm/v/react-frontload?style=social&amp;logo=npm" data-reactid="14"></a><a href="https://github.com/davnicwil/react-frontload" data-reactid="15"><img src="https://img.shields.io/github/stars/davnicwil/react-frontload?style=social" data-reactid="16"></a><a href="https://www.npmjs.com/package/react-frontload" data-reactid="17"><img src="https://img.shields.io/npm/dm/react-frontload?style=social" data-reactid="18"></a><a href="https://twitter.com/davnicwil" data-reactid="19"><img src="https://img.shields.io/twitter/url?label=made%20by%20%40davnicwil&amp;style=social&amp;url=https%3A%2F%2Fdavnicwil.com" data-reactid="20"></a></p></div><p data-reactid="21">React Frontload is a library to load and manage data inline in React components that works on both client and server.</p><div data-reactid="22"><ul data-reactid="23"><li data-reactid="24"><span data-reactid="25">Load data with a hook which works on client and server</span></li><li data-reactid="26"><span data-reactid="27">Data is managed in component state - no need for Redux / MobX</span></li><li data-reactid="28"><span data-reactid="29">Written in TypeScript, typing is easy as everything's inline</span></li><li data-reactid="30"><span data-reactid="31">Less than 3.5KB Gzipped, zero dependencies</span></li></ul></div><div data-reactid="32"><div data-reactid="33"><!-- react-text: 34 --><p>v2 has just shipped! </p><!-- /react-text --><p><a href="https://davnicwil.com/v2" data-reactid="35">See here</a></p><!-- react-text: 36 --><p> for the motivation for v2 and comparison with v1</p><!-- /react-text --></div></div><div data-reactid="37"><p>Install</p><p>npm install react-frontload</p></div><div id="problem" data-reactid="53"><h3 data-reactid="54">What problem does this solve?</h3><p><a href="#problem" data-reactid="55">#</a></p></div><p data-reactid="56">React provides no built-in way to do data loading - it's left for you to implement. Doing this is tricky in a React app that uses server side rendering (SSR) because client and server rendering work quite differently: Client render is async so data can be loaded inside components when they render, but server render is completely synchronous - the data must be loaded before render happens.</p><p data-reactid="57">Data loading is, of course, async. The client component-centric data loading pattern is nice, but it's incompatible with synchronous server render. React simply has no mechanism to wait for data to load when components render on SSR. There's a further problem too: React also provides no built-in way to hydrate data loaded during SSR into client state on first render. This is also up to you to implement.</p><p data-reactid="58">So, full stack data loading in React is a tricky problem. A couple of solutions have emerged:</p><ol data-reactid="59"><li data-reactid="60"><p data-reactid="61">Load data at the route level, instead of the component level, then pass data to all components under the route. Works on SSR since the route is known in the request, so data can be loaded before render begins. Can be implemented by piecing together router and state manager libraries.</p></li><li data-reactid="62"><p data-reactid="63">Use a framework that wraps React and abstracts the problem away, perhaps by providing a framework-specific async data loading function for components that works on SSR, and also takes care of hydrating state on the client.</p></li></ol><p data-reactid="64">React Frontload aims to provide a third way - the component-centric data loading pattern available full stack, but without having to buy into a whole framework just to get this feature. It's just a small library that solves this one problem, and can be used in any React stack.</p><p data-reactid="68">Here's an example of loading data into a component with React Frontload</p><p><span>const</span> <span>Component</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>{</span> data<span>,</span> frontloadMeta <span>}</span> <span>=</span> <span>useFrontload</span><span>(</span><span>'my-component'</span><span>,</span> <span>async</span> <span>(</span><span><span>{</span> api <span>}</span></span><span>)</span> <span>=&gt;</span> <span>(</span><span>{</span>
    stuff<span>:</span> <span>await</span> api<span>.</span><span>getStuff</span><span>(</span><span>)</span>
  <span>}</span><span>)</span><span>)</span>

  <span>if</span> <span>(</span>frontloadMeta<span>.</span>pending<span>)</span> <span>return</span> <span>&lt;</span>div<span>&gt;</span>loading<span>&lt;</span><span>/</span>div<span>&gt;</span>
  <span>if</span> <span>(</span>frontloadMeta<span>.</span>error<span>)</span>   <span>return</span> <span>&lt;</span>div<span>&gt;</span>error<span>&lt;</span><span>/</span>div<span>&gt;</span>

  <span>return</span> <span>&lt;</span>div<span>&gt;</span><span>{</span>data<span>.</span>stuff<span>}</span><span>&lt;</span><span>/</span>div<span>&gt;</span>
<span>}</span>
</p><p data-reactid="70"><!-- react-text: 71 -->Here we have a <!-- /react-text --><span data-reactid="72">Component</span><!-- react-text: 73 --> that needs to load <!-- /react-text --><span data-reactid="74">stuff</span><!-- react-text: 75 --> from an API, with the usual loading state whilst it loads and some sort of error state if loading fails for some reason.<!-- /react-text --></p><p data-reactid="76"><!-- react-text: 77 -->With React Frontload, we do this by passing an async data loading function to the <!-- /react-text --><span data-reactid="78">useFrontload</span><!-- react-text: 79 --> hook. The hook loads the return value of the function into<!-- /react-text --><!-- react-text: 80 --> <!-- /react-text --><span data-reactid="81">data</span><!-- react-text: 82 -->, and gives us<!-- /react-text --><!-- react-text: 83 --> <!-- /react-text --><span data-reactid="84">frontloadMetadata</span><!-- react-text: 85 --> out the box so we can see when it's still <!-- /react-text --><span data-reactid="86">pending</span><!-- react-text: 87 --> or if an <!-- /react-text --><span data-reactid="88">error</span><!-- react-text: 89 --> is thrown when running the function.<!-- /react-text --></p><p data-reactid="90"><!-- react-text: 91 -->That's it - we're done in those few lines of code. That's the power of doing data loading inline in a component. And the best part here is that this just works on the server. If we render<!-- /react-text --><!-- react-text: 92 --> <!-- /react-text --><span data-reactid="93">Component</span><!-- react-text: 94 --> in a route, any route,<!-- /react-text --><!-- react-text: 95 --> <!-- /react-text --><span data-reactid="96">stuff</span><!-- react-text: 97 --> will load.<!-- /react-text --></p><p data-reactid="98"><!-- react-text: 99 -->To emphasise the ease and lack of plumbing involved in making changes, let's have <!-- /react-text --><span data-reactid="100">Component</span><!-- react-text: 101 --> load some more stuff:<!-- /react-text --></p><p><span>const</span> <span>Component</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>{</span> data<span>,</span> frontloadMeta <span>}</span> <span>=</span> <span>useFrontload</span><span>(</span><span>'my-component'</span><span>,</span> <span>async</span> <span>(</span><span><span>{</span> api <span>}</span></span><span>)</span> <span>=&gt;</span> <span>(</span><span>{</span>
    stuff<span>:</span> <span>await</span> api<span>.</span><span>getStuff</span><span>(</span><span>)</span><span>,</span>
    moreStuff<span>:</span> <span>await</span> api<span>.</span><span>getMoreStuff</span><span>(</span><span>)</span> 
  <span>}</span><span>)</span><span>)</span>

  <span>if</span> <span>(</span>frontloadMeta<span>.</span>pending<span>)</span> <span>return</span> <span>&lt;</span>div<span>&gt;</span>loading<span>&lt;</span><span>/</span>div<span>&gt;</span>
  <span>if</span> <span>(</span>frontloadMeta<span>.</span>error<span>)</span>   <span>return</span> <span>&lt;</span>div<span>&gt;</span>error<span>&lt;</span><span>/</span>div<span>&gt;</span>

  <span>return</span> <span>&lt;</span>div<span>&gt;</span><span>{</span>data<span>.</span>stuff<span>}</span> and <span>{</span>data<span>.</span>moreStuff<span>}</span><span>&lt;</span><span>/</span>div<span>&gt;</span> 
<span>}</span>
</p><p data-reactid="103"><!-- react-text: 104 -->It's literally that simple - just add whatever you need to<!-- /react-text --><!-- react-text: 105 --> <!-- /react-text --><span data-reactid="106">useFrontload</span><!-- react-text: 107 --> and use it. Remember that this is all automatically typed. If the value returned by the<!-- /react-text --><!-- react-text: 108 --> <!-- /react-text --><span data-reactid="109">getMoreStuff</span><!-- react-text: 110 --> api call is a<!-- /react-text --><span data-reactid="111">string</span><!-- react-text: 112 -->,<!-- /react-text --><!-- react-text: 113 --> <!-- /react-text --><span data-reactid="114">data.moreStuff</span><!-- react-text: 115 --> has the string type, and you'll get errors if you try to use it as a number.<!-- /react-text --></p><p data-reactid="116"><!-- react-text: 117 -->You may have noticed that the above code loads data less efficiently than it could. <!-- /react-text --><span data-reactid="118">api.getStuff()</span><!-- react-text: 119 --> and<!-- /react-text --><!-- react-text: 120 --> <!-- /react-text --><span data-reactid="121">api.getMoreStuff()</span><!-- react-text: 122 --> are called in serial, when they could probably be called in parallel. Since it's just Javascript, though, we can change this:<!-- /react-text --></p><p><span>const</span> <span>{</span> data<span>,</span> frontloadMeta <span>}</span> <span>=</span> <span>useFrontload</span><span>(</span><span>'my-component'</span><span>,</span> <span>async</span> <span>(</span><span><span>{</span> api <span>}</span></span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>[</span>stuff<span>,</span> moreStuff<span>]</span> <span>=</span> Promise<span>.</span><span>all</span><span>(</span><span>[</span>
    api<span>.</span><span>getStuff</span><span>(</span><span>)</span><span>,</span>
    api<span>.</span><span>getMoreStuff</span><span>(</span><span>)</span>
  <span>]</span><span>)</span>

  <span>return</span> <span>{</span> stuff<span>,</span> moreStuff <span>}</span>
<span>}</span><span>)</span>
</p><p data-reactid="124">In fact as data loaders get more complex, you can use any combination of serial and parallel that you need. It's just Javascript - you have the full power of the language without any abstractions or misdirection on top.</p><p data-reactid="125"><!-- react-text: 126 -->There is one more piece to this - what about updating data? Since React Frontload uses React component state to hold<!-- /react-text --><!-- react-text: 127 --> <!-- /react-text --><span data-reactid="128">data</span><!-- react-text: 129 -->, updating it is just a case of updating that state. React Frontload provides another function, called<!-- /react-text --><!-- react-text: 130 --> <!-- /react-text --><span data-reactid="131">setData</span><!-- react-text: 132 -->, for this:<!-- /react-text --></p><p><span>const</span> <span>Component</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>{</span> data<span>,</span> setData<span>,</span> frontloadMeta <span>}</span> <span>=</span> <span>useFrontload</span><span>(</span><span>'my-component'</span><span>,</span> <span>async</span> <span>(</span><span><span>{</span> api <span>}</span></span><span>)</span> <span>=&gt;</span> <span>(</span><span>{</span>
    stuff<span>:</span> <span>await</span> api<span>.</span><span>getStuff</span><span>(</span><span>)</span>
  <span>}</span><span>)</span><span>)</span>

  <span>if</span> <span>(</span>frontloadMeta<span>.</span>pending<span>)</span> <span>return</span> <span>&lt;</span>div<span>&gt;</span>loading<span>&lt;</span><span>/</span>div<span>&gt;</span>
  <span>if</span> <span>(</span>frontloadMeta<span>.</span>error<span>)</span>   <span>return</span> <span>&lt;</span>div<span>&gt;</span>error<span>&lt;</span><span>/</span>div<span>&gt;</span>

  <span>const</span> <span>updateStuff</span> <span>=</span> <span>async</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>try</span> <span>{</span>
      <span>const</span> updatedStuff <span>=</span> <span>await</span> <span>updateStuff</span><span>(</span><span>'new value'</span><span>)</span> 
      <span>setData</span><span>(</span><span>data</span> <span>=&gt;</span> <span>(</span><span>{</span> <span>...</span>data<span>,</span> stuff<span>:</span> updatedStuff <span>}</span><span>)</span><span>)</span> 
    <span>}</span> <span>catch</span> <span>{</span>
      
    <span>}</span>
  <span>}</span>

  <span>return</span> <span>(</span>
    <span>&lt;</span><span>&gt;</span>
      <span>&lt;</span>div<span>&gt;</span><span>{</span>data<span>.</span>stuff<span>}</span><span>&lt;</span><span>/</span>div<span>&gt;</span>
      <span>&lt;</span>button onClick<span>=</span><span>{</span>updateStuff<span>}</span><span>&gt;</span>update<span>&lt;</span><span>/</span>button<span>&gt;</span>
    <span>&lt;</span><span>&gt;</span>
  <span>)</span>
</p><p data-reactid="134"><!-- react-text: 135 -->Again, this is all just inline in the component with zero plumbing. If you're coming from Redux, you can think of<!-- /react-text --><!-- react-text: 136 --> <!-- /react-text --><span data-reactid="137">setData</span><!-- react-text: 138 --> a little bit like a mini reducer. It takes the existing value of<!-- /react-text --><!-- react-text: 139 --> <!-- /react-text --><span data-reactid="140">data</span><!-- react-text: 141 --> as an argument, and you merge updates into it to return an updated value of<!-- /react-text --><!-- react-text: 142 --> <!-- /react-text --><span data-reactid="143">data</span><!-- react-text: 144 -->.<!-- /react-text --></p><p data-reactid="145">And that's it - full stack data loading and management inline in your React components.</p><p data-reactid="149"><!-- react-text: 150 -->The <!-- /react-text --><span data-reactid="151">useEffect</span><!-- react-text: 152 --> hook seen in the example above is the core of React Frontload - the code you'll actually work with in your components - but there is also a small amount of one-time setup code to write to get it to work.<!-- /react-text --></p><p data-reactid="153"><!-- react-text: 154 -->Essentially this is setting up wrappers around your server render logic, and your React application on both server and client, to make the<!-- /react-text --><span data-reactid="155">useFrontload</span><!-- react-text: 156 --> hook work, and also enable hydration of state loaded on server render to the client.<!-- /react-text --></p><p data-reactid="157">App Provider</p><p data-reactid="158">Wrap your app in the React Frontload provider</p><p><span>import</span> <span>{</span> FrontloadProvider <span>}</span> <span>from</span> <span>'react-frontload'</span>

<span>const</span> <span>App</span> <span>=</span> <span>(</span><span><span>{</span> frontloadState <span>}</span></span><span>)</span> <span>=&gt;</span> <span>(</span>
  <span>&lt;</span>FrontloadProvider initialState<span>=</span><span>{</span>frontloadState<span>}</span><span>&gt;</span>
    <span>&lt;</span>Content<span>&gt;</span><span>...</span><span>&lt;</span><span>/</span>Content<span>&gt;</span>
  <span>&lt;</span><span>/</span>FrontloadProvider<span>&gt;</span>
<span>)</span>
</p><p data-reactid="160">Server render</p><p data-reactid="161"><!-- react-text: 162 -->On server render, you need to wrap your existing synchronous server render code with<!-- /react-text --><!-- react-text: 163 --> <!-- /react-text --><span data-reactid="164">reactFrontloadServerRender</span><!-- react-text: 165 -->.<!-- /react-text --></p><p data-reactid="166"><!-- react-text: 167 -->You can think of this as the polyfill that allows React Frontload to load data asynchronously on server render. It just uses regular React server rendering under the hood, and its output is exactly the same. Read more about this <!-- /react-text --><a href="#how-it-works" data-reactid="168">here</a><!-- react-text: 169 -->.<!-- /react-text --></p><p><span>import</span> <span>{</span> renderToString <span>}</span> <span>from</span> <span>'react-dom/server'</span>
<span>import</span> <span>{</span> createFrontloadState<span>,</span> frontloadServerRender <span>}</span> <span>from</span> <span>'react-frontload'</span>
<span>import</span> serverApi <span>from</span> <span>'./serverApi'</span>

app<span>.</span><span>get</span><span>(</span><span>'*'</span><span>,</span> <span>async</span> <span>(</span><span>req<span>,</span> res</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>...</span>

  
  
  <span>const</span> frontloadState <span>=</span> createFrontloadState<span>.</span><span>server</span><span>(</span><span>{</span>
    
    
    
    context<span>:</span> <span>{</span> api<span>:</span> serverApi <span>}</span>
  <span>}</span><span>)</span>

  <span>try</span> <span>{</span>
    
    <span>const</span> <span>{</span> rendered<span>,</span> data <span>}</span> <span>=</span> <span>await</span> <span>frontloadServerRender</span><span>(</span><span>{</span>
      frontloadState<span>,</span>
      <span>render</span><span>:</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>renderToString</span><span>(</span><span>&lt;</span>App frontloadState<span>=</span><span>{</span>frontloadState<span>}</span> <span>/</span><span>&gt;</span><span>)</span>
    <span>}</span><span>)</span>

    res<span>.</span><span>send</span><span>(</span><span><span>`</span><span>
      &lt;html&gt;
        ...
        &lt;!-- server rendered markup --&gt;
        </span><span><span>${</span>rendered<span>}</span></span><span>

        &lt;!-- loaded data (to be hydrated on client) --&gt;
        &lt;script&gt;window._frontloadData=</span><span><span>${</span><span>toSanitizedJSON</span><span>(</span>data<span>)</span><span>}</span></span><span>&lt;/script&gt;
        ...
      &lt;/html&gt;
    </span><span>`</span></span><span>)</span>
  <span>}</span> <span>catch</span> <span>(</span>err<span>)</span> <span>{</span>
    
  <span>}</span>
<span>}</span><span>)</span>
</p><p data-reactid="171"><!-- react-text: 172 -->The output of<!-- /react-text --><!-- react-text: 173 --> <!-- /react-text --><span data-reactid="174">reactFrontloadServerRender</span><!-- react-text: 175 --> contains a <!-- /react-text --><span data-reactid="176">rendered</span><!-- react-text: 177 --> string, which is just the server render output to inject into your HTML template as usual.<!-- /react-text --></p><p data-reactid="178"><!-- react-text: 179 -->It also contains a <!-- /react-text --><span data-reactid="180">data</span><!-- react-text: 181 --> object, which you should serialize into your HTML as sanitised JSON.<!-- /react-text --><!-- react-text: 182 --> <!-- /react-text --><span data-reactid="183">data</span><!-- react-text: 184 --> contains all the data loaded for the current view across all components, and the purpose of this is to hydrate this data into React Frontload on the client (using<!-- /react-text --><!-- react-text: 185 --> <!-- /react-text --><span data-reactid="186">initialState</span><!-- react-text: 187 -->) so that it does not have to be reloaded on first render. This pattern is essentially the same as the one you see with other state managers such as Redux.<!-- /react-text --></p><p data-reactid="188">Client render</p><p data-reactid="189">The last remaining step is client integration, which is rather simpler. Just initialise a React Frontload state object on the client using your serialized data from server render, and pass it to the provider.</p><p><span>import</span> clientApi <span>from</span> <span>'./clientApi'</span>

<span>const</span> frontloadState <span>=</span> createFrontloadState<span>.</span><span>client</span><span>(</span><span>{</span>
  
  
  context<span>:</span> <span>{</span> api<span>:</span> clientApi <span>}</span><span>,</span>

  
  serverRenderedData<span>:</span> window<span>.</span>_frontloadData
<span>}</span><span>)</span>
<span>...</span>
ReactDOM<span>.</span><span>render</span><span>(</span><span>&lt;</span>App frontloadState<span>=</span><span>{</span>frontloadState<span>}</span> <span>/</span><span>&gt;</span><span>,</span> <span>...</span><span>)</span>
</p><p data-reactid="194">For most usecases, you don't need to care about this.</p><p data-reactid="195">That said, all abstractions are leaky at some point, and it's always useful to understand how things work under the hood so that when they behave unexpectedly, you can figure out why.</p><p data-reactid="196">The mechanism used to polyfill async on server render is deliberately very simple. As shown in the code above, React Frontload wraps ordinary synchronous server render code with an async function.</p><p data-reactid="197"><!-- react-text: 198 -->It works by running that synchronous function, and collecting the promises encountered on each render of a<!-- /react-text --><!-- react-text: 199 --> <!-- /react-text --><span data-reactid="200">useFrontload</span><!-- react-text: 201 --> hook. After the render, the collected promises are then awaited, which loads the data in those functions the same as it would be on the client. Now, React Frontload runs the server render again - this time injecting the data loaded from the previous run into each component ahead of the render. In this new render round, if no new<!-- /react-text --><!-- react-text: 202 --> <!-- /react-text --><span data-reactid="203">useFrontload</span><!-- react-text: 204 --> hooks are encountered (i.e. if there are no nested components with a<!-- /react-text --><!-- react-text: 205 --> <!-- /react-text --><span data-reactid="206">useFrontload</span><!-- react-text: 207 --> hook), then the output of this render is returned as the final output. If nested<!-- /react-text --><!-- react-text: 208 --> <!-- /react-text --><span data-reactid="209">useFrontload</span><!-- react-text: 210 --> hooks<!-- /react-text --><!-- react-text: 211 --> <!-- /react-text --><span data-reactid="212">are</span><!-- react-text: 213 --> found, the process repeats.<!-- /react-text --></p><ul id="api-useFrontload" data-reactid="225"><li data-reactid="226"><span data-reactid="227">useFrontload</span><a href="#api-useFrontload" data-reactid="228">#</a></li></ul><p data-reactid="229"><span data-reactid="230">useFrontload</span><!-- react-text: 231 --> is the React Frontload hook.<!-- /react-text --></p><p><span>import</span> <span>{</span> useFrontload <span>}</span> <span>from</span> <span>'react-frontload'</span>

<span>useFrontload</span><span>(</span>
  …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://davnicwil.com/react-frontload">https://davnicwil.com/react-frontload</a></em></p>]]>
            </description>
            <link>https://davnicwil.com/react-frontload</link>
            <guid isPermaLink="false">hacker-news-small-sites-25027368</guid>
            <pubDate>Sun, 08 Nov 2020 17:46:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Winning Without Competing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25027249">thread link</a>) | @jdcampolargo
<br/>
November 8, 2020 | https://www.juandavidcampolargo.com/blog/winning-competion | <a href="https://web.archive.org/web/*/https://www.juandavidcampolargo.com/blog/winning-competion">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-405d26435b59c98dcb8b"><div><p>It was Monday at 9:58 PM, and I finished a CAD assignment with the help of my TA. Nick is a great dude, not only because of how helpful and knowledgeable he is but because of his willingness to explain the fundamentals of CAD and engineering until one deeply understands it.&nbsp;</p><p>It’s become a routine when I finish the assignments, we talk about life, economics, psychology, and anything that comes our way. In our conversation, the topic of competition came up.&nbsp;</p><p>He tells me when he applied to colleges, he avoided the “famous” and “prestigious” places from the East Coast because of the overfocus on competition, and the lack of focus on what you’re genuinely curious about.&nbsp;</p><p>He says, “Students don’t do what they like or what they want to learn more about, rather they tend to do what they’re good at because the school, parents, friends, etc tell them to.”</p><p>As soon as he said that, sparks started happening in my head, and I was ready to share my response about the dangers of competition.&nbsp;</p><p>Competition is great [1], yet I avoid it as much as possible. Competing with others can lead you to an unhealthy path where you end up doing what you thought would make you a winner, and not what would make you enjoy what you do.&nbsp;</p><p>Nick tells me that often being the best and competing with others can often lead to putting other people down. In zero-sum games, if I win, that means you have to lose. There are plenty of cases where it's positive-sum, where no one wins at someone else’s expense.&nbsp;</p><p>I avoid competition [2] because if you want what other people want 1) it becomes harder to get what you want, and 2) even if you win or get what you wanted, you may realize that was not what you wanted.&nbsp;</p><p>It doesn’t have to be this way, as there are many alternatives to thrive without putting other people down and doing things you want to do by following your curiosity and interests.&nbsp;</p><p>How?</p><p><strong>You uniquely define what you do in a way that no one else is doing it.&nbsp;</strong></p><p>If you are passionate about entrepreneurship, you can’t call yourself an “entrepreneur.” You need to go deeper. For instance, if you are an entrepreneur, define the areas, the people who you work with, where you work, how you work, and why you work.&nbsp;</p><p>You might be an entrepreneur focused on the well-being of the environment and human life in the southern parts of the country who is trying to implement Algae-based biofuel on tractors. That’s specific and you can go even deeper like the states, the brand of the tractors, and the type of algae.&nbsp;</p><p>Or if you like writing, you can’t call yourself a “writer.” See within and start unburying. You could write about how the sophisticated Roman city of Pompeii affected how we think about building and designing cities in the 20th and 21st centuries.&nbsp;</p><p>I know you may feel uncomfortable being that specific because you may think: 1) You’re passionate about more topics, 2) You may lose opportunities, 3) You may not like being that specific.&nbsp;</p><p>Frankly, that’s how I feel too. However, I can define what I do in such a unique way so I can see where to go or what to do. I don’t have to follow it and can always change it. In my case, I didn’t even worry about it, and I followed what interested me and what seemed curious.&nbsp;</p><p>I’ve realized that following your genuine curiosity is the best way to avoid competition and win (whatever that means for you).&nbsp;</p><p>I followed my curiosity and I can look back at the essays. Although they may seem like different topics, they all have one purpose: making my readers more optimistic, ambitious, and curious.&nbsp;</p><p>Define what you do uniquely so you have no competition. That way, you’ll win without winning and without other people down.&nbsp;</p><p>And that was only ten minutes of one of my chats with Nick. Our conversations get more interesting every week. If you’d like to hear more about them, join hundreds of people in the <a href="http://juandavidcampolargo.com/newsletter" target="_blank"><strong><em>Weekly Memos</em></strong></a><strong><em>.</em></strong></p><p><strong>Notes</strong></p><p>[1] I’m not talking about “Market Competition.” I’m referring to competition at a personal and an individual level.</p><p>[2] I don’t just avoid competition for the sake of avoiding it. But if I find myself competing for no reason, it could be a sign that I’m not thinking for myself. </p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604669904171_5110"><p>If you’re into interesting ideas (like the one you just read), sign up for my <a href="https://juandavidcampolargo.com/newsletter" target="_blank">Weekly Memos</a>, and I’ll send you new essays right when they come out. Better than having to check the site!</p></div></div>]]>
            </description>
            <link>https://www.juandavidcampolargo.com/blog/winning-competion</link>
            <guid isPermaLink="false">hacker-news-small-sites-25027249</guid>
            <pubDate>Sun, 08 Nov 2020 17:30:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Illustrated GPT-2 (Visualizing Transformer Language Models)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25027205">thread link</a>) | @bjourne
<br/>
November 8, 2020 | http://jalammar.github.io/illustrated-gpt2/ | <a href="https://web.archive.org/web/*/http://jalammar.github.io/illustrated-gpt2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><span>Discussions:
<a href="https://news.ycombinator.com/item?id=20677411">Hacker News (64 points, 3 comments)</a>, <a href="https://www.reddit.com/r/MachineLearning/comments/cp8prq/p_the_illustrated_gpt2_visualizing_transformer/">Reddit r/MachineLearning (219 points, 18 comments)</a>
</span></p>

<p><span>Translations: <a href="https://habr.com/ru/post/490842/">Russian</a></span></p>

<p><img src="http://jalammar.github.io/images/gpt2/openAI-GPT-2-3.png">
  <br>
</p>

<p>This year, we saw a dazzling application of machine learning. <a href="https://openai.com/blog/better-language-models/">The OpenAI GPT-2</a> exhibited impressive ability of writing coherent and passionate essays that exceed what we anticipated current language models are able to produce. The GPT-2 wasn’t a particularly novel architecture – it’s architecture is very similar to the decoder-only transformer. The GPT2 was, however, a very large, transformer-based language model trained on a massive dataset. In this post, we’ll look at the architecture that enabled the model to produce its results. We will go into the depths of its self-attention layer. And then we’ll look at applications for the decoder-only transformer beyond language modeling.</p>

<p>My goal here is to also supplement my earlier post, <a href="http://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a>, with more visuals explaining the inner-workings of transformers, and how they’ve evolved since the original paper. My hope is that this visual language will hopefully make it easier to explain later Transformer-based models as their inner-workings continue to evolve.</p>

<!--more-->

<div>

  <p><strong>Contents</strong></p>

  <ul>
    <li><strong><a href="#part-1-got-and-language-modeling">Part 1: GPT2 And Language Modeling</a></strong>
      <ul>
        <li>What is a Language Model</li>
        <li>Transformers for Language Modeling</li>
        <li>One Difference From BERT</li>
        <li>The Evolution of The Transformer Block</li>
        <li>Crash Course in Brain Surgery: Looking Inside GPT-2</li>
        <li>A Deeper Look Inside</li>
        <li>End of part #1: The GPT-2, Ladies and Gentlemen</li>
      </ul>
    </li>
    <li><strong><a href="#part-2-illustrated-self-attention">Part 2: The Illustrated Self-Attention</a></strong>
      <ul>
        <li>Self-Attention (without masking)</li>
        <li>1- Create Query, Key, and Value Vectors</li>
        <li>2- Score</li>
        <li>3- Sum</li>
        <li>The Illustrated Masked Self-Attention</li>
        <li>GPT-2 Masked Self-Attention</li>
        <li>Beyond Language modeling</li>
        <li>You’ve Made it!</li>
      </ul>
    </li>
    <li><strong><a href="#part-3-beyond-language-modeling">Part 3: Beyond Language Modeling</a></strong>
      <ul>
        <li>Machine Translation</li>
        <li>Summarization</li>
        <li>Transfer Learning</li>
        <li>Music Generation</li>
      </ul>
    </li>
  </ul>

</div>

<h2 id="part-1-gpt2-and-language-modeling-">Part #1: GPT2 And Language Modeling <a href="#part-1-got-and-language-modeling" name="part-1-got-and-language-modeling">#</a></h2>

<p>So what exactly is a language model?</p>

<h3 id="what-is-a-language-model">What is a Language Model</h3>
<p>In <a href="http://jalammar.github.io/illustrated-word2vec/">The Illustrated Word2vec</a>, we’ve looked at what a language model is – basically a machine learning model that is able to look at part of a sentence and predict the next word. The most famous language models are smartphone keyboards that suggest the next word based on what you’ve currently typed.</p>

<p><img src="http://jalammar.github.io/images/word2vec/swiftkey-keyboard.png">
  <br>
</p>

<p>In this sense, we can say that the GPT-2 is basically the next word prediction feature of a keyboard app, but one that is much larger and more sophisticated than what your phone has. The GPT-2 was trained on a massive 40GB dataset called WebText that the OpenAI researchers crawled from the internet as part of the research effort. To compare in terms of storage size, the keyboard app I use, SwiftKey, takes up 78MBs of space. The smallest variant of the trained GPT-2, takes up 500MBs of storage to store all of its parameters. The largest GPT-2 variant is 13 times the size so it could take up more than 6.5 GBs of storage space.</p>

<p><img src="http://jalammar.github.io/images/gpt2/gpt2-sizes.png">
  <br>
</p>

<p>One great way to experiment with GPT-2 is using the <a href="https://gpt2.apps.allenai.org/?text=Joel%20is">AllenAI GPT-2 Explorer</a>. It uses GPT-2 to display ten possible predictions for the next word (alongside their probability score). You can select a word then see the next list of predictions to continue writing the passage.</p>

<h3 id="transformers-for-language-modeling">Transformers for Language Modeling</h3>

<p>As we’ve seen in The <a href="http://jalammar.github.io/illustrated-transformer/">Illustrated Transformer</a>, the original transformer model is made up of an encoder and decoder – each is a stack of what we can call transformer blocks. That architecture was appropriate because the model tackled machine translation  – a problem where encoder-decoder architectures have been successful in the past.</p>

<p><img src="http://jalammar.github.io/images/xlnet/transformer-encoder-decoder.png">
  <br>
</p>

<p>A lot of the subsequent research work saw the architecture shed either the encoder or decoder, and use just one stack of transformer blocks – stacking them up as high as practically possible, feeding them massive amounts of training text, and throwing vast amounts of compute at them (hundreds of thousands of dollars to train some of these language models, likely millions in the case of <a href="https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/">AlphaStar</a>).</p>

<p><img src="http://jalammar.github.io/images/gpt2/gpt-2-transformer-xl-bert-3.png">
  <br>
</p>

<p>How high can we stack up these blocks? It turns out that’s one of the main distinguishing factors between the different GPT2 model sizes:</p>

<p><img src="http://jalammar.github.io/images/gpt2/gpt2-sizes-hyperparameters-3.png">
  <br>
</p>

<h3 id="one-difference-from-bert">One Difference From BERT</h3>
<blockquote>
<strong>First Law of Robotics</strong><br>
A robot may not injure a human being or, through inaction, allow a human being to come to harm.
</blockquote>

<p>The GPT-2 is built using transformer decoder blocks. BERT, on the other hand, uses transformer encoder blocks. We will examine the difference in a following section. But one key difference between the two is that GPT2, like traditional language models, outputs one token at a time. Let’s for example prompt a well-trained GPT-2 to recite the first law of robotics:</p>

<p><img src="http://jalammar.github.io/images/xlnet/gpt-2-output.gif">
  <br>
</p>

<p>The way these models actually work is that after each token is produced, that token is added to the sequence of inputs. And that new sequence becomes the input to the model in its next step. This is an idea called “auto-regression”. This is one of the ideas that <a href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/">made RNNs unreasonably effective</a>.</p>

<p><img src="http://jalammar.github.io/images/xlnet/gpt-2-autoregression-2.gif">
  <br>
</p>

<p>The GPT2, and some later models like TransformerXL and XLNet are auto-regressive in nature. BERT is not. That is a trade off. In losing auto-regression, BERT gained the ability to incorporate the context on both sides of a word to gain better results. XLNet brings back autoregression while finding an alternative way to incorporate the context on both sides.</p>

<h3 id="the-evolution-of-the-transformer-block">The Evolution of the Transformer Block</h3>

<p>The <a href="https://arxiv.org/abs/1706.03762">initial transformer paper</a> introduced two types of transformer blocks:</p>

<h4 id="the-encoder-block">The Encoder Block</h4>

<p>First is the encoder block:</p>

<p><img src="http://jalammar.github.io/images/xlnet/transformer-encoder-block-2.png">
  <br>
  An encoder block from the original transformer paper can take inputs up until a certain max sequence length (e.g. 512 tokens). It's okay if an input sequence is shorter than this limit, we can just pad the rest of the sequence.
</p>

<h4 id="the-decoder-block">The Decoder Block</h4>
<p>Second, there’s the decoder block which has a small architectural variation from the encoder block – a layer to allow it to pay attention to specific segments from the encoder:</p>

<p><img src="http://jalammar.github.io/images/xlnet/transformer-decoder-block-2.png">
  <br>
</p>

<p>One key difference in the self-attention layer here, is that it masks future tokens – not by changing the word to [mask] like BERT, but by interfering in the self-attention calculation blocking information from tokens that are to the right of the position being calculated.</p>

<p>If, for example, we’re to highlight the path of position #4, we can see that it is only allowed to attend to the present and previous tokens:</p>

<p><img src="http://jalammar.github.io/images/xlnet/transformer-decoder-block-self-attention-2.png">
  <br>
</p>

<p>It’s important that the distinction between self-attention (what BERT uses) and masked self-attention (what GPT-2 uses) is clear. A normal self-attention block allows a position to peak at tokens to its right. Masked self-attention prevents that from happening:</p>

<p><img src="http://jalammar.github.io/images/gpt2/self-attention-and-masked-self-attention.png">
  <br>
</p>

<h4 id="the-decoder-only-block">The Decoder-Only Block</h4>
<p>Subsequent to the original paper, <a href="https://arxiv.org/pdf/1801.10198.pdf">Generating Wikipedia by Summarizing Long Sequences</a> proposed another arrangement of the transformer block that is capable of doing language modeling. This model threw away the Transformer encoder. For that reason, let’s call the model the “Transformer-Decoder”. This early transformer-based language model was made up of a stack of six transformer decoder blocks:</p>

<p><img src="http://jalammar.github.io/images/xlnet/transformer-decoder-intro.png">
  <br>
  The decoder blocks are identical. I have expanded the first one so you can see its self-attention layer is the masked variant. Notice that the model now can address up to 4,000 tokens in a certain segment -- a massive upgrade from the 512 in the original transformer.
</p>

<p>These blocks were very similar to the original decoder blocks, except they did away with that second self-attention layer. A similar architecture was examined in <a href="https://arxiv.org/pdf/1808.04444.pdf">Character-Level Language Modeling with Deeper Self-Attention</a> to create a language model that predicts one letter/character at a time.</p>

<p>The OpenAI GPT-2 model uses these decoder-only blocks.</p>

<h3 id="crash-course-in-brain-surgery-looking-inside-gpt-2">Crash Course in Brain Surgery: Looking Inside GPT-2</h3>

<blockquote>
  <p>Look inside and you will see,
The words are cutting deep inside my brain.
Thunder burning, quickly burning,
Knife of words is driving me insane, insane yeah.
~<strong><a href="https://en.wikipedia.org/wiki/Budgie_(band)">Budgie</a></strong></p>

</blockquote>

<p>Let’s lay a trained GPT-2 on our surgery table and look at how it works.</p>

<p><img src="http://jalammar.github.io/images/gpt2/gpt-2-layers-2.png">
  <br>
  The GPT-2 can process 1024 tokens. Each token flows through all the decoder blocks along its own path.
</p>

<p>The simplest way to run a trained GPT-2 is to allow it to ramble on its own (which is technically called <em>generating unconditional samples</em>) – alternatively, we can give it a prompt to have it speak about a certain topic (a.k.a generating <em>interactive conditional samples</em>). In the rambling case, we can simply hand it the start token and have it start generating words (the trained model uses <code>&lt;|endoftext|&gt;</code> as its start token. Let’s call it <code>&lt;s&gt;</code> instead).</p>

<div>
  <p><img src="http://jalammar.github.io/images/gpt2/gpt2-simple-output-2.gif"></p>
</div>

<p>The model only has one input token, so that path would be the only active one. The token is processed successively through all the layers, then a vector is produced along that path. That vector can be scored against the model’s vocabulary (all the words the model knows, 50,000 words in the case of GPT-2). In this case we selected the token with the highest probability, ‘the’. But we can certainly mix things up – you know how if you keep clicking the suggested word in your keyboard app, it sometimes can stuck in repetitive loops where the only way out is if you click the second or third suggested word. The same can happen here. GPT-2 has a parameter called top-k that we can use to have the model consider sampling words other than the top word (which is the case when top-k = 1).</p>

<p>In the next step, we add the output from the first step to our input sequence, and have the model make its next prediction:</p>

<p><img src="http://jalammar.github.io/images/gpt2/gpt-2-simple-output-3.gif">
  <br>
</p>

<p>Notice that the second path is the only that’s active in this calculation. Each layer of GPT-2 has retained its own interpretation of the first token and will use it in processing the second token (we’ll get into more detail about this in the following section about self-attention). GPT-2 does not re-interpret the first token in light of the second token.</p>

<h3 id="a-deeper-look-inside">A Deeper Look Inside</h3>

<h4 id="input-encoding">Input Encoding</h4>
<p>Let’s look at more details to get to know the model more intimately. Let’s start from the input. As in other NLP models we’ve discussed before, the model looks up the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://jalammar.github.io/illustrated-gpt2/">http://jalammar.github.io/illustrated-gpt2/</a></em></p>]]>
            </description>
            <link>http://jalammar.github.io/illustrated-gpt2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25027205</guid>
            <pubDate>Sun, 08 Nov 2020 17:23:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Ownership Is Important for Great Product Managers]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25026963">thread link</a>) | @justanotherpm
<br/>
November 8, 2020 | https://blog.justanotherpm.com/why-is-ownership-such-an-important-quality-for-great-product-managers-5-reasons/ | <a href="https://web.archive.org/web/*/https://blog.justanotherpm.com/why-is-ownership-such-an-important-quality-for-great-product-managers-5-reasons/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
    <main>
            <article>
    
    <div>
            <p>Close your eyes and think about these situations:</p><p>Situation one: Imagine you are on your way to work on a Monday morning. You take the regular metro (or subway or bus), which is extremely crowded. Five minutes after you get in, you notice that an older woman loses her balance and falls. She gets hurt and is crying in pain. By the looks, it might be a severe injury.</p><p>What would you do?</p><p>Before you read on, please take a second to visualize what you would do for the older woman.</p><p>Situation two- It is the same as above. The only difference is that the injured person is not an older stranger, but one of your parents.</p><p>What would you do now? Would it be any different from the first situation?</p><p>I believe that a lot of people would help the older woman from the first situation to a certain extent. Maybe they take her to the closest hospital, or they call the emergency services, or they call someone from her phone. And the situation would end there.</p><p>In the second case, most would probably take their parent to the hospital, take the day off from work, and stay with their parent until they get the necessary treatment and recover fully.</p><p>As expected, the level of <em>ownership</em> is much higher in the second case compared to the first.</p><p>In the first instance, the person worked towards a short term goal or an instant output - get the injured person immediate help. In the second case, the person fought for a longer-term goal and an <em>outcome - </em>help the parent get <em>whatever</em> they need to recover.</p><p>The above set of actions sound apparent, because in one situation, the wounded is a stranger, and in the second, they are a parent. But that is not the point. The point is that the same person can operate at different levels of ownership depending on how much they care about the outcome.</p><p>Great product managers genuinely care about the problems they solve and the solutions they deliver. Great product managers also have an exceptionally high level of ownership.</p><p>Let us understand the advantages of being a high ownership PM:</p><ol><li><strong>Confidence and trust. </strong>Direct manager, peers, and seniors will have very high confidence in those who consistently own and deliver results. They will be the most coveted team member or leader for critical and complex tasks.</li><li><strong>Better decision making. </strong>High ownership individuals have the "do whatever it takes" attitude. Getting things done requires excellent decision making. PMs who are ownership driven create systems and processes to enable and improve their decisions.</li><li><strong>Bigger and stronger network.</strong> Most business-critical decisions require alignment across multiple leaders and teams. High ownership PMs build and leverage relationships to expedite the process of making difficult decisions.</li><li><strong>Create a positive and happy culture in the organization. </strong>Great PMs are self-motivated and deliver positive results, which builds a success-driven culture - something that every employer desires.</li><li><strong>Create a meaningful and visible impact. </strong>As long as PMs are working on the right tasks - which great PMs always do - their work will create a positive impact on their team and the organization.</li></ol><p>At this stage, you might be asking yourself - "How do I become (more) ownership driven?" And, we have the answer to that question, which I will share in the next post.</p><p>For now, I leave you with one of Gary W. Keller's quote, that summarizes the importance of <em>ownership</em>.</p><blockquote>Taking complete ownership of your outcomes by holding no one but yourself responsible for them is the most powerful thing you can do to drive your success.</blockquote>
    </div>
        
</article>                    
                </main>
</div>
        </div></div>]]>
            </description>
            <link>https://blog.justanotherpm.com/why-is-ownership-such-an-important-quality-for-great-product-managers-5-reasons/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25026963</guid>
            <pubDate>Sun, 08 Nov 2020 16:51:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How active noise cancellation for automotive works]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 65 (<a href="https://news.ycombinator.com/item?id=25026841">thread link</a>) | @giuliomagnifico
<br/>
November 8, 2020 | https://www.silentium.com/advanced-broad-band-active-noise-cancellation-now-available-in-cars/ | <a href="https://web.archive.org/web/*/https://www.silentium.com/advanced-broad-band-active-noise-cancellation-now-available-in-cars/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div id="mk-page-id-6588">
					<div itemprop="mainEntityOfPage">
							
	<article id="6588" itemscope="itemscope" itemprop="blogPost" itemtype="http://schema.org/BlogPosting">

	<div><p><a title="Advanced, broad-band active noise cancellation now available in cars" href="https://www.silentium.com/wp-content/uploads/2020/11/silentium-anc-system.jpg">&nbsp;</a><img alt="Advanced, broad-band active noise cancellation now available in cars" title="Advanced, broad-band active noise cancellation now available in cars" src="https://www.silentium.com/wp-content/uploads/bfi_thumb/dummy-transparent-oj3yxgsoeorp9werpevcwqrlmj5p4y57n6vjhiqmq0.png" data-mk-image-src-set="{&quot;default&quot;:&quot;https://www.silentium.com/wp-content/uploads/2020/11/silentium-anc-system.jpg&quot;,&quot;2x&quot;:&quot;&quot;,&quot;mobile&quot;:&quot;&quot;,&quot;responsive&quot;:&quot;true&quot;}" width="800" height="500" itemprop="image"></p></div>				
	





<div itemprop="mainEntityOfPage">
	<p>Silentium has introduced advanced, broad-band active road noise cancellation to the auto industry for the first time.</p>
<p>After several years in development, Jaguar and Land Rover are the first carmakers to integrate Silentium’s ‘Active Acoustics’ software in three of their new vehicles, meaning the technology is now available for car buyers to experience. Active road noise cancellation removes 90% of unwanted noise across a broad band of frequencies – from 20Hz up to 1kHz – providing a quieter and more refined experience for occupants, and therefore preventing driver fatigue.</p>
<p>In addition to wellbeing benefits, Silentium’s Active Acoustics technology offers vehicle manufacturers a way to reduce their reliance on costly passive noise damping and insulation materials, and reduce vehicle weight – an increasingly important R&amp;D factor as the industry enters a new era of electro-mobility.</p>
<p>Anthony Manias, Head of Automotive at Silentium, commented: “<em>Active Acoustics will change the way car manufacturers reduce, cancel and enhance sound inside their vehicles, and how customers perceive and interact with these sounds. Silentium has proven that it can make broadband in-car noise cancellation work – now the duty is on carmakers to adopt the technology and ensure their customers can enjoy the benefits.”</em></p>
<p><img src="https://www.silentium.com/wp-content/uploads/2020/11/graphic-silentium1.jpg" alt="" width="1000" height="756" srcset="https://www.silentium.com/wp-content/uploads/2020/11/graphic-silentium1.jpg 1000w, https://www.silentium.com/wp-content/uploads/2020/11/graphic-silentium1-300x227.jpg 300w, https://www.silentium.com/wp-content/uploads/2020/11/graphic-silentium1-768x581.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></p>
<p><strong>How active noise cancellation works</strong></p>
<p>Silentium’s industry-first technology is similar to that found in a pair of high-end noise-cancelling headphones, but more advanced as it manipulates a larger amount of air. Up to six strategically positioned accelerometers on a vehicle’s chassis monitor unwanted road noise and send a signal to an on-board control unit with Silentium’s software, which plays an equivalent anti-noise signal through the vehicle’s speaker system. The pressure waves from both the unwanted exterior noise and manufactured anti-noise reach occupants’ eardrums at exactly the same time and cancel each other out.</p>
<p>Silentium’s Active Acoustics software can reduce, cancel and enhance sound inside any vehicle, improving occupant comfort, safety and wellbeing, and creating a more enjoyable environment for all.</p>
<p><iframe title="Silentium Active Acoustics on road noise" width="1140" height="641" src="https://www.youtube.com/embed/5x9NEpfRZuc?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p><iframe title="Silentium Active Acoustics with road noise and music" width="1140" height="641" src="https://www.youtube.com/embed/uDzSkaWBD7E?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
</div>



</article>

							
											</div>
										
				</div>
			</div></div>]]>
            </description>
            <link>https://www.silentium.com/advanced-broad-band-active-noise-cancellation-now-available-in-cars/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25026841</guid>
            <pubDate>Sun, 08 Nov 2020 16:35:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Alfred to open your GitHub repositories in the browser]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 29 (<a href="https://news.ycombinator.com/item?id=25026757">thread link</a>) | @mmazzarolo
<br/>
November 8, 2020 | https://mmazzarolo.com/blog/2020-09-28-alfred-github-repos/ | <a href="https://web.archive.org/web/*/https://mmazzarolo.com/blog/2020-09-28-alfred-github-repos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>One thing I do multiple times a day is browsing my company’s GitHub organization repositories.<br>
My process for opening these repositories in the browser is:</p>
<ul>
<li>Open Chrome</li>
<li>Press <kbd>Command</kbd> + <kbd>L</kbd> to focus the address bar</li>
<li>Start typing the GitHub repository name</li>
<li>Look for the page suggestion and click on it</li>
</ul>
<p>This flow works well for repositories that I have starred as bookmarks or that I browsed recently…<br>
…But because I’m a total sucker for Alfred, today I wasted almost an hour moving this process into an Alfred workflow.</p>
<p><span>
      <span></span>
  <img alt="alfred" title="alfred" src="https://mmazzarolo.com/static/f6b79b275f646159f864ae32c3d83508/fcda8/alfred.png" srcset="https://mmazzarolo.com/static/f6b79b275f646159f864ae32c3d83508/12f09/alfred.png 148w,
https://mmazzarolo.com/static/f6b79b275f646159f864ae32c3d83508/e4a3f/alfred.png 295w,
https://mmazzarolo.com/static/f6b79b275f646159f864ae32c3d83508/fcda8/alfred.png 590w,
https://mmazzarolo.com/static/f6b79b275f646159f864ae32c3d83508/efc66/alfred.png 885w,
https://mmazzarolo.com/static/f6b79b275f646159f864ae32c3d83508/c83ae/alfred.png 1180w,
https://mmazzarolo.com/static/f6b79b275f646159f864ae32c3d83508/7ef4c/alfred.png 1748w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></p>
<h2>The Action Plan</h2>
<p>Knowing that:</p>
<ul>
<li>The entire repository list is huge and doesn’t change often</li>
<li>I wanted the Alfred repository search result to be instant</li>
</ul>
<p>Making an API request to filter the repositories each time I invoke the Alfred workflow wasn’t an option.</p>
<p>So I decided to 1) download the entire repository list into a JSON file, 2) transform it into an Alred-compatible format, and 3) use the <a href="https://github.com/deanishe/alfred-fuzzy" target="_blank" rel="nofollow noopener noreferrer">Alfred’s fuzzy search helper</a> to filter the results.</p>
<h2>Creating the GitHub repository list</h2>
<p>First of all, I <a href="https://github.com/settings/tokens/new" target="_blank" rel="nofollow noopener noreferrer">created a GitHub API token with a scope to access the repositories list</a>.</p>
<p><span>
      <span></span>
  <img alt="github repo access" title="github repo access" src="https://mmazzarolo.com/static/5debf06855fa8eef2379c163d8d95943/fcda8/github-repo-access.png" srcset="https://mmazzarolo.com/static/5debf06855fa8eef2379c163d8d95943/12f09/github-repo-access.png 148w,
https://mmazzarolo.com/static/5debf06855fa8eef2379c163d8d95943/e4a3f/github-repo-access.png 295w,
https://mmazzarolo.com/static/5debf06855fa8eef2379c163d8d95943/fcda8/github-repo-access.png 590w,
https://mmazzarolo.com/static/5debf06855fa8eef2379c163d8d95943/efc66/github-repo-access.png 885w,
https://mmazzarolo.com/static/5debf06855fa8eef2379c163d8d95943/69476/github-repo-access.png 926w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></p>
<blockquote>
<p>TIL: Selecting all the “repo” sub-scopes is not the same as selecting the entire scope — which is needed to use the API token to get the list of all the private repositories.</p>
</blockquote>
<p>The GitHub API pagination has a limit of 200 items per page. I needed to fetch way more than 200 repositories, so I modified <a href="https://gist.github.com/mbohun/b161521b2440b9f08b59" target="_blank" rel="nofollow noopener noreferrer">this cool (but outdated) bash script</a> to fetch all of them in a single command and print them out to the console:</p>
<div data-language="bash"><pre><code><span>#!/bin/bash</span>

<span>if</span> <span>[</span> <span>${<span>#</span>@}</span> -lt <span>2</span> <span>]</span><span>;</span> <span>then</span>
    <span>echo</span> <span>"usage: <span>$0</span> [your github credentials as 'user:token'] [REST expression]"</span>
    <span>exit</span> <span>1</span><span>;</span>
<span>fi</span>

<span>GITHUB_CREDENTIALS</span><span>=</span><span>$1</span>
<span>GITHUB_API_REST</span><span>=</span><span>$2</span>

<span>GITHUB_API_HEADER_ACCEPT</span><span>=</span><span>"Accept: application/vnd.github.v3+json"</span>

<span>temp</span><span>=</span><span><span>`</span><span>basename</span> $0<span>`</span></span>
<span>TMPFILE</span><span>=</span><span><span>`</span>mktemp /tmp/$<span>{</span>temp<span>}</span>.XXXXXX<span>`</span></span> <span>||</span> <span>exit</span> <span>1</span>

<span>function</span> <span>rest_call</span> <span>{</span>
    <span>curl</span> -s -u <span>$GITHUB_CREDENTIALS</span> <span>$1</span> -H <span>"<span>${GITHUB_API_HEADER_ACCEPT}</span>"</span> <span>&gt;&gt;</span> <span>$TMPFILE</span>
<span>}</span>


<span>last_page</span><span>=</span><span><span>`</span><span>curl</span> -s -I -u $GITHUB_CREDENTIALS <span>"https://api.github.com<span>${GITHUB_API_REST}</span>?per_page=200"</span> -H <span>"<span>${GITHUB_API_HEADER_ACCEPT}</span>"</span> <span>|</span> <span>grep</span> <span>'^Link:'</span> <span>|</span> <span>sed</span> -e <span>'s/^Link:.*page=//g'</span> -e <span>'s/&gt;.*$//g'</span><span>`</span></span>


<span>if</span> <span>[</span> -z <span>"<span>$last_page</span>"</span> <span>]</span><span>;</span> <span>then</span>
    
    rest_call <span>"https://api.github.com<span>${GITHUB_API_REST}</span>?per_page=200"</span>
<span>else</span>
    
    <span>for</span> <span>p</span> <span>in</span> <span><span>`</span><span>seq</span> <span>1</span> $last_page<span>`</span></span><span>;</span> <span>do</span>
        rest_call <span>"https://api.github.com<span>${GITHUB_API_REST}</span>?per_page=200&amp;page=<span>$p</span>"</span>
    <span>done</span>
<span>fi</span>

<span>cat</span> <span>$TMPFILE</span></code></pre></div>
<p>I named the script <code>githubapi-get.sh</code> and used it this way:</p>
<div data-language="bash"><pre><code>
githubapi-get.sh <span>"{USERNAME}:{TOKEN}"</span> <span>"/orgs/{ORGANIZATION}/repos"</span> <span>&gt;</span> ~/my-company-repos.txt</code></pre></div>
<p>FYI, you can also run it this way to get all the repositories you have access to (both on your personal account and on other organization accounts):</p>
<div data-language="bash"><pre><code>
githubapi-get.sh <span>"{USERNAME}:{TOKEN}"</span> <span>"/user/repos"</span> <span>&gt;</span> ~/my-github-repos.txt</code></pre></div>
<h2>Making the repository list compatible with Alfred</h2>
<p>To populate the Alfred list filter, for each repo I extracted the following information:</p>
<ul>
<li><code>uid</code>: Unique identifier for the item which allows Alfred to learn about this item for subsequent sorting and ordering of the user’s actioned results. I used the repository ID (<code>id</code>).</li>
<li><code>arg</code>: The argument which is passed through the workflow to open it in the browser. I used the repository URL (<code>html_url</code>).</li>
<li><code>title</code>: The title displayed in the result row. I used the repository name (<code>name</code>).</li>
<li><code>subtitle</code>: The subtitle displayed in the result row. I used the repository description (<code>description</code>).</li>
</ul>
<p>Using the following <code>jq</code> script:</p>
<div data-language="bash"><pre><code><span>cat</span> ~/my-company-repos.txt <span>|</span> jq -s <span>'.[] | map({ arg: .html_url, uid: .id, title: .name, subtitle: .description }) | { items: . }'</span> <span>&gt;</span> ~/my-company-repos.json</code></pre></div>
<p>The <code>jq</code> script generates a <code>~/my-company-repos.json</code> file compatible with the <a href="https://www.alfredapp.com/help/workflows/inputs/script-filter/json/" target="_blank" rel="nofollow noopener noreferrer">Alfred Script Filter JSON format</a>.</p>
<h2>Creating the Alfred workflow</h2>
<p>The Alfred standard script filtering doesn’t have a good fuzzy search option — which I really wanted given the huge amount of repositories.</p>
<p>As a workaround, I used <a href="https://github.com/deanishe/alfred-fuzzy" target="_blank" rel="nofollow noopener noreferrer">alfred-fuzzy</a>, a Python helper script for Alfred that replaces the “Alfred filters results” option with fuzzy search.</p>
<p>Here’s what I did, step by step:</p>
<ol>
<li>Create a new empty Alfred workflow</li>
<li>Right-click on the created workflow ⭢ “Open in Finder”</li>
<li>In the workflow directory, copy and paste both <a href="https://raw.githubusercontent.com/deanishe/alfred-fuzzy/master/fuzzy.py" target="_blank" rel="nofollow noopener noreferrer">fuzzy.py</a> and <code>my-company-repos.json</code>.</li>
<li>In the workflow, create the following “Script Filter”:
<span>
      <span></span>
  <img alt="workflow 0" title="workflow 0" src="https://mmazzarolo.com/static/79ea20fa5f1577ca4cb07a0fd9329861/fcda8/workflow-0.png" srcset="https://mmazzarolo.com/static/79ea20fa5f1577ca4cb07a0fd9329861/12f09/workflow-0.png 148w,
https://mmazzarolo.com/static/79ea20fa5f1577ca4cb07a0fd9329861/e4a3f/workflow-0.png 295w,
https://mmazzarolo.com/static/79ea20fa5f1577ca4cb07a0fd9329861/fcda8/workflow-0.png 590w,
https://mmazzarolo.com/static/79ea20fa5f1577ca4cb07a0fd9329861/efc66/workflow-0.png 885w,
https://mmazzarolo.com/static/79ea20fa5f1577ca4cb07a0fd9329861/c83ae/workflow-0.png 1180w,
https://mmazzarolo.com/static/79ea20fa5f1577ca4cb07a0fd9329861/2b608/workflow-0.png 1540w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></li>
<li>In the workflow, create the following “Open URL” action:
<span>
      <span></span>
  <img alt="workflow 1" title="workflow 1" src="https://mmazzarolo.com/static/5f157cd5f9d5e2e8f928074cc6d37708/fcda8/workflow-1.png" srcset="https://mmazzarolo.com/static/5f157cd5f9d5e2e8f928074cc6d37708/12f09/workflow-1.png 148w,
https://mmazzarolo.com/static/5f157cd5f9d5e2e8f928074cc6d37708/e4a3f/workflow-1.png 295w,
https://mmazzarolo.com/static/5f157cd5f9d5e2e8f928074cc6d37708/fcda8/workflow-1.png 590w,
https://mmazzarolo.com/static/5f157cd5f9d5e2e8f928074cc6d37708/efc66/workflow-1.png 885w,
https://mmazzarolo.com/static/5f157cd5f9d5e2e8f928074cc6d37708/c83ae/workflow-1.png 1180w,
https://mmazzarolo.com/static/5f157cd5f9d5e2e8f928074cc6d37708/7960f/workflow-1.png 1274w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></li>
<li>In the workflow, connect the “Script Filter” to the “Open URL” action:
<span>
      <span></span>
  <img alt="workflow 2" title="workflow 2" src="https://mmazzarolo.com/static/ca9a91ea4b4aed993050fc92f0780f4d/fcda8/workflow-2.png" srcset="https://mmazzarolo.com/static/ca9a91ea4b4aed993050fc92f0780f4d/12f09/workflow-2.png 148w,
https://mmazzarolo.com/static/ca9a91ea4b4aed993050fc92f0780f4d/e4a3f/workflow-2.png 295w,
https://mmazzarolo.com/static/ca9a91ea4b4aed993050fc92f0780f4d/fcda8/workflow-2.png 590w,
https://mmazzarolo.com/static/ca9a91ea4b4aed993050fc92f0780f4d/8ae3e/workflow-2.png 756w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></li>
</ol>
<p>That’s it.
I can now invoke the workflow using the keyword set in the “Script Filter” action and fuzzy search the repo I’m interested in.</p>
<p>Alfred is also smart enough to keep track of my workflow usage, surfacing the most clicked results to the top of the list 💥</p>
<blockquote>
<p>Yes, the workflow can be improved in several ways (e.g.: auto-update the repository list after n days)… but I’m happy enough with the current result for now.</p>
</blockquote></section></div>]]>
            </description>
            <link>https://mmazzarolo.com/blog/2020-09-28-alfred-github-repos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25026757</guid>
            <pubDate>Sun, 08 Nov 2020 16:24:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I made a website to guess tomorrow’s Covid-19 case count]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25026666">thread link</a>) | @nathell
<br/>
November 8, 2020 | http://blog.danieljanus.pl/2020/11/08/coronalotto/ | <a href="https://web.archive.org/web/*/http://blog.danieljanus.pl/2020/11/08/coronalotto/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Before</h2><p>It seems so obvious in hindsight. Here in Poland, people have been guessing it ever since the pandemic breakout: in private conversations, in random threads on social media, in comments under governmental information outlets. It seemed a&nbsp;matter of time before someone came up with something like this. In fact, on one Sunday evening in October, I&nbsp;found myself flabbergasted that apparently no one yet has.</p><p>I&nbsp;doled out $4 for a&nbsp;domain, <a href="http://koronalotek.pl/">koronalotek.pl</a> (can be translated as “coronalotto” or “coronalottery” – occurrences of the name on Twitter date back at least as far as April), and fired up a&nbsp;REPL. A&nbsp;few hours and 250 Clojure LOCs later, the site was up.</p><p>I&nbsp;wanted it to&nbsp;be as simple as possible. A&nbsp;form with two fields: “your name” and “how many cases tomorrow?” A&nbsp;top-ten list of today’s winners, sorted by the absolute difference between the guess and the actual number of cases, as <a href="https://twitter.com/mz_gov_pl">reported daily on Twitter</a> by the Polish Ministry of Health. The official number, prominently displayed. And that’s all.</p><p><img src="http://blog.danieljanus.pl/img/blog/koronalotek.png"></p><p>On 17 October, I&nbsp;posted the link on my Facebook and Twitter feeds, and waited. The stream of guesses started to&nbsp;trickle in.</p><h2>After</h2><p>It never grew to&nbsp;be more than a&nbsp;stream, but it hasn’t gone completely unnoticed either.</p><p><img src="http://blog.danieljanus.pl/img/blog/koronalotek-g1.png"></p><p>The above plot shows daily number of accepted guesses (i.e., those that were used to&nbsp;generate the next day’s winners) over time – a&nbsp;metric of popularity. Each day’s number means guesses cast in the 24 hours up until 10:30 (Warsaw time) on that day, which is when the official numbers are published by the Ministry of Health.</p><p>I’ve been filtering out automated submissions, as well as excess manual submissions by the same IP that seemed to&nbsp;skew the results too much – I’ve arbitrarily set the “excess” threshold at 10. The missing datapoint for 19 October is not a&nbsp;zero, but a&nbsp;N/A: I’ve lost that datapoint due to&nbsp;a&nbsp;glitch. More on this below.</p><p>The interest peaked on October 23, with more than a&nbsp;thousand guesses for that day (I&nbsp;think it was reposted by someone with a&nbsp;significant outreach back then), and has been slowly declining since.</p><p>I&nbsp;have privately received some feedback. One person has pointed out that they found the site distasteful and that making fun of pandemic tragedies made them uncomfortable. (I&nbsp;empathise; for me it’s not so much making fun as it is a&nbsp;coping mechanism—a&nbsp;way to&nbsp;put distance between my thoughts and the difficult times we’re in and to&nbsp;keep fears at bay.) Some people, however, have thanked me for making them smile when they guessed more or less correctly.</p><p>Back to&nbsp;data. Being a&nbsp;data junkie, I&nbsp;looked at what I&nbsp;had been collecting. First things first: how accurate is the collective predictive power of the guessers?</p><p><img src="http://blog.danieljanus.pl/img/blog/koronalotek-g2.png"></p><p>Quite accurate, in fact! Data for this plot has only been slightly preprocessed, by filtering out “unreasonable” guesses that don’t fall within the range <code>[100; 50000]</code>.</p><p>People have over- and underguesstimated the number of new cases, but not by much. There were only a&nbsp;few occasions where the actual case count didn’t fall within one standard deviation of the mean of guesses (represented by the whiskers around blue bars on the plot). Granted, the daily standard deviation tends to&nbsp;be large (on the order of a&nbsp;few thousand), but still, I’m impressed. A&nbsp;paper on estimating the growth of pandemic based on coronalottery results coming soon to&nbsp;a&nbsp;journal near you! ;-)</p><p>Just for the heck of it, I’ve also been looking at individual votes. Specifically, names. Here’s a&nbsp;snapshot of unique guessers’ names sorted by decreasing length, on 23 October. (NSFW warning: expletives ahead!)</p><p><img src="http://blog.danieljanus.pl/img/blog/koronalotek-names.jpg"></p><p>Let me translate a&nbsp;few of these for those of you who don’t speak Polish:</p><p>1 is “Sasin has fucked over 70 million zlotys for elections that didn’t take place and was never held responsible.” This alludes to&nbsp;the <a href="https://notesfrompoland.com/2020/05/27/70-million-zloty-bill-for-polands-abandoned-presidential-election/">ghost election in Poland</a> from May. This news had gone memetic, going so far as Minister Sasin’s name being ironically used as a&nbsp;dimensionless unit of 70 million (think Avogadro’s number). You’ll discover the same theme in #2, #3, #5, and others.</p><p>6 is “CT {Constitutional Tribunal}, you focking botch, stop repressing my abortion”. Just a&nbsp;day before, the Polish constitutional court (whose current legality is <a href="https://en.wikipedia.org/wiki/Constitutional_Tribunal_(Poland)#2015%E2%80%93present:_Polish_Constitutional_Court_crisis">disputed at best</a>) has <a href="https://notesfrompoland.com/2020/10/22/constitutional-court-ruling-ends-almost-all-legal-abortion-in-poland/">decreed a&nbsp;ban on almost all legal abortion</a> in Poland, giving rise to&nbsp;<a href="https://edition.cnn.com/2020/10/31/europe/poland-abortion-protests-scli-intl/index.html">the biggest street protests in decades</a>.</p><p>Not all is political: 4 is “Why study for the exam if we’re not gonna survive until November anyway?”. I&nbsp;hope whoever wrote this is alive and well.</p><p>Corollary? Give people a&nbsp;text field, and they’ll use it to&nbsp;express themselves: politically or otherwise.</p><p>In fact, I&nbsp;have taken the liberty of chiming in. Shortly after, I&nbsp;altered the thank-you page (which used to&nbsp;just say “thanks for guessing”) to&nbsp;proudly display one of the emblems of the Women’s Strike, along with a&nbsp;link to&nbsp;a&nbsp;<a href="https://zrzutka.pl/kasa-na-aborcyjny-dream-team-55g5gx">crowdfounding campaign</a> for an NGO that supports women needing abortion.</p><p><img src="http://blog.danieljanus.pl/img/blog/koronalotek-thanks.jpg"></p><h2>Inside out</h2><p>I’m not much of a&nbsp;DevOps person, so I&nbsp;deployed it the quick and dirty way, not caring about scalability or performance. The maxim “make it as simple as possible” permeates the setup.</p><p>I&nbsp;just started a&nbsp;REPL within a&nbsp;<code>screen</code> session on the tiny Scaleway C1 server that also hosts this blog and some of my other personal stuff. I&nbsp;launched a&nbsp;Jetty server within it, and set up a&nbsp;nginx proxy. And that’s pretty much it. I&nbsp;liberally tinker with the app’s state in “production,” evaluating all kinds of expressions when I&nbsp;feel like it.</p><p>Code changes are deployed by <code>git pull</code>ing new developments and doing <code>(require 'koronalotek.core :reload)</code> in the REPL.</p><p>Someone tried a&nbsp;SQL injection attack. This is doomed to&nbsp;fail because there’s no SQL involved. In fact, there’s no database at all. The entire state is kept in an in-memory atom and periodically synced out to&nbsp;an EDN file. In addition, state is reset and archived daily at the time of announcing winners. (I’ve added the archiving after forgetting it on one occasion – hence the lack of data for 19 October.)</p><p>I&nbsp;also don’t yet have a&nbsp;mechanism of automatically pulling in the Ministry of Health’s data. Every morning, I&nbsp;spend two minutes checking if there’s excess automatic votes, removing them if any, and then filling in the blanks:</p><pre><code>(new-data! #inst "2020-11-08T10:30+01:00" 24785)
</code></pre><p>For all the violations of good practices in this setup, it has worked out surprisingly well so far. I’ve resorted to&nbsp;removing automated votes a&nbsp;handful of times, and blacklisting IPs of voting bots in the nginx setup twice, but otherwise it’s been a&nbsp;low-maintenance toy. People seem to&nbsp;be willing to&nbsp;have fun, and I’m just not interfering.</p><h2>Takeaways</h2><ol><li>You should call on your country’s authorities to&nbsp;exert pressure on the Polish government to&nbsp;respect women’s choices and stop actively repressing them.</li><li>Give people a&nbsp;text field, and they’ll use it to&nbsp;express themselves.</li><li>Release early, release often.</li></ol></div></div>]]>
            </description>
            <link>http://blog.danieljanus.pl/2020/11/08/coronalotto/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25026666</guid>
            <pubDate>Sun, 08 Nov 2020 16:13:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Makefiles]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25026656">thread link</a>) | @ingve
<br/>
November 8, 2020 | https://xs-labs.com/en/blog/2020/11/07/introduction-to-makefiles/ | <a href="https://web.archive.org/web/*/https://xs-labs.com/en/blog/2020/11/07/introduction-to-makefiles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<h2>Introduction to Makefiles</h2><p>
    I often use Makefiles in some of my projects.<br>
    I really like the flexibility it gives, and I often find myself writing a Makefile instead of a simple shell script to automatize tasks.
</p>
<p>
    So here's a little crash course.<br>
    I'll obviously only cover the basics, but I hope this will give you a good idea on how you could improve your workflows using Makefiles.
</p>
<h3>About Make</h3>
<p>
    Make was developed in 1976 mainly as a build automation tool, to produce executable files or libraries from source code.
</p>
<p>
    While it excels as a build system, it can also be used for a lot of different things.<br>
    If you do write shell scripts to automatize certain tasks, you'll be able to use Makefiles instead.<br>
    As we're going to see, a Makefile can have several advantages over a regular shell script.
</p>
<p>
    This tutorial will only be focused on the GNU version of Make, as it's the most widely used and the most powerful.
</p>
<h3>Basics</h3>
<p>
    First of all, when you invoke the <code>make</code> command, it will look for a file named <code>Makefile</code> in the current working directory.<br>
    This is the default, but note that a specific Makefile can be used with the <code>-f</code> flag, followed by the file name or path.
</p>
<p>
    If such a file is found, it will by default execute the <code>all</code> target.
</p>
<p>
    <strong>Make is target-based system.</strong><br>
    Your Makefile can specify multiple targets, and targets may be executed individually when invoking <code>make</code>. But more on this later.
</p>
<p>
    <strong>For now, we'll just start by creating a basic <em>hello world</em> example.</strong>
</p>
<h4>hello, world</h4>
<p>
    In some directory, create a file called <code>Makefile</code> with the following content:
</p>
<pre>all:
    
    echo "hello, world"
</pre>
<p>
    <code>all</code> is the target name. Target definitions are followed by a colon sign.<br>
    As mentioned earlier, <code>make</code> will by default look for a target called <code>all</code>. So this is our main entry point.
</p>
<p>
    Inside the target, you'll simply execute shell commands.  
    Here, we print the <em>hello, world</em> string, using the shell's builtin <code>echo</code> command.
</p>
<p>
    <strong>Note that target commands need to be indented with at least a single tab.</strong><br>
    <strong>While spaces can be used elsewhere for indentation, tabulation is mandatory inside a target.</strong>
</p>
<p>
    Now from a command prompt, <code>cd</code> to that directory and type <code>make</code>.
</p>
<p>
    <code>make</code> will read the <code>Makefile</code>, and execute the <code>all</code> target, giving the following output:
</p>
<pre>echo "hello, world"
hello, world
</pre>
<p>    
    As you can see, <code>make</code> will first print the full command, before printing any output.<br>
    This can be disabled by using an <code>@</code> sign before the command:
</p>
<pre>all:
    
    @echo "hello, world"
</pre>
<p>
    Now the output is simply:
</p>
<pre>hello, world
</pre>
<h4>Additional targets</h4>
<p>
    You can define as many targets as you want.<br>
    For instance:
</p>
<pre>all:
    
    @echo "hello, world"

foo:
    
    @echo "hello, foo"

bar:
    
    @echo "hello, bar"
</pre>
<p>
    While invoking <code>make</code> will still only execute the <code>all</code> target, the <code>foo</code> or <code>bar</code> targets can be executed individually by specifying their names:
</p>
<pre>$ make
hello, world

$ make foo
hello, foo

$ make bar
hello, bar
</pre>
<h4>Target dependencies</h4>
<p>
    A target may depend on another target, or on multiple other targets.<br>
    This is called a <strong>prerequisite</strong>.
</p>
<p>
    Prerequisites follows the target name:
</p>
<pre>foo: bar
    
    @echo "hello, foo"
</pre>
<p>
    Here, the <code>foo</code> target depends on <code>bar</code>. This means that when <code>foo</code> is about to be executed, <code>bar</code> will be executed first.
</p>
<p>
    Multiple prerequisites are simply separated by a space:
</p>
<pre>foo: bar all
    
    @echo "hello, foo"
</pre>
<p>
    Here, upon executing <code>foo</code>, <code>make</code> will start by executing <code>bar</code>, then <code>all</code>, and finally <code>foo</code>.
</p>
<p>
    And obviously, chaining works too:
</p>
<pre>all: foo
    
    @echo "hello, world"

foo: bar
    
    @echo "hello, foo"

bar:
    
    @echo "hello, bar"
</pre>
<p>
    <code>all</code> depends on <code>foo</code>, which depends on <code>bar</code>. So when invoking <code>make</code>, you'll get the following output:
</p>
<pre>hello, bar
hello, foo
hello, world
</pre>
<p>    
    And you can also manually execute <code>foo</code> by typing <code>make foo</code>, which will give:
</p>
<pre>hello, bar
hello, foo
</pre>
<h4>Error handling</h4>
<p>
    <strong>A very nice thing about <code>make</code> is that it does error handling for you.</strong><br>
    If a command returns a <strong>non-zero</strong> exit status, <code>make</code> will report the error and <strong>abort execution</strong>.
</p>
<p>
    This means that if a command fails inside some target (which may be a prerequisite of another target), the whole execution will stop.<br>
    So you don't have to do any manual error checking, as you would/should do with a shell script.
</p>
<p>
    For instance:
</p>
<pre>all: foo
    
    @echo "hello, world"

foo: bar
    
    @echo "hello, foo"

bar:
    
    @echo "Executing false"
    @false
    @echo "hello, bar"
</pre>
<p>
    Note that in the <code>bar</code> target, we execute the shell's <code>false</code> command, which always returns a non-zero exit status.<br>
    Now if we invoke <code>main</code>, we'll get the following output:
</p>
<pre>Executing false
make: *** [bar] Error 1
</pre>
<p>
    <code>make</code> will execute <code>all</code>, which needs to execute <code>foo</code>, which needs to execute <code>bar</code>.  
    <code>bar</code> will print the first message, and then execute the <code>false</code> command.
</p>
<p>
    As it returns a non-zero exit status, this is detected as an error, and execution is stopped.<br>
    The remaining message in <code>bar</code> will not be printed, and the <code>foo</code> and <code>all</code> targets won't be executed.
</p>
<h4>Debugging</h4>
<p>
    Also note that you can obtain detailed informations about how <code>make</code> reads your Makefile using the <code>--debug</code> flag.<br>
    With the previous example:
</p>
<pre>$ make --debug
Reading makefiles...
Updating goal targets....
    File `all' does not exist.
        File `foo' does not exist.
            File `bar' does not exist.
        Must remake target `bar'.
Executing false
make: *** [bar] Error 1
</pre>
<h4>Variables</h4>
<p>
    You can also define variables inside your Makefile.<br>
    Variables are defined outside targets, and can be referred to with a <code>$</code> sign and parenthesis:
</p>
<pre>HELLO := hello, world

all:

    @echo "$(HELLO)"
</pre>
<p>
    Variables may also be overridden when invoking <code>make</code>, giving extra flexibility.<br>
    For instance, with the example above:
</p>
<pre>$ make HELLO="This is a test"
This is a test
</pre>
<p>
    We'll cover more about variables later.
</p>
<h3>Real life example - Build system</h3>
<p>
    <strong>Now that we have covered the basics, let's take a more useful example.</strong>
</p>
<p>
    We'll create a simple build system for the C programming language.<br>
    The goal is to compile C source files, and to produce an executable.
</p>
<p>
    We'll start by a very simple build system, and work on it step by step to achieve a more generic one.
</p>
<h4>Project structure</h4>
<p>
    Here's the basic project structure:
</p>
<ul>
    <li><code>build</code> (directory)</li>
    <li><code>Makefile</code></li>
    <li>
        <code>source</code> (directory)
        <ul>
            <li><code>main.c</code></li>
        </ul>
    </li>
</ul>

<p>
    We have a <code>build</code> directory for the final executable and temporary files, the Makefile, and a <code>source</code> directory with a single <code>main.c</code> file.
</p>
<p>
The <code>main.c</code> file is a basic <em>hello world</em> program:
</p>
<pre>#include &lt;stdio.h&gt;

int main( void )
{
    printf( "hello, world\n" );
    
    return 0;
}
</pre>
<h4>Producing a simple executable</h4>
<p>
    We'll start with a very simple <code>Makefile</code> that invokes the <code>clang</code> C compiler.<br>
    You can obviously replace it with <code>gcc</code> if you want:
</p>
<pre>all:
    
    @clang -Wall -Werror source/main.c -o build/main
</pre>
<p>
    When invoking <code>make</code>, it will compile the <code>source/main.c</code> and produce an executable in <code>build/main</code>.<br>
    Dead simple.
</p>
<h4>Compiling multiple files</h4>
<p>
    Now let's say we want to compile multiple C files to produce the executable.
</p>
<p>
    We'll first create a function named <code>hello</code> in the <code>source/hello.c</code> file:
</p>
<pre>#include &lt;stdio.h&gt;
#include "hello.h"

void hello( void )
{
    printf( "hello, world\n" );
}
</pre>
<p>
    And we'll also add the corresponding header in <code>source/hello.h</code> with the function prototype:
</p>
<pre>#ifndef HELLO_H
#define HELLO_H

void hello( void );

#endif
</pre>
<p>
    Our <code>main.c</code> file will then call the <code>hello</code> function:
</p>
<pre>#include "hello.h"

int main( void )
{
    hello();
    
    return 0;
}
</pre>
<p>
    Now the <code>Makefile</code> could simply be:
</p>
<pre>all:

    @clang -Wall -Werror source/hello.c source/main.c -o build/main
</pre>
<p>
    However, this is not really flexible, and this is usually not how individual files are compiled.<br>
    Instead, we'll produce an <strong>object file</strong> for each C source file, and <strong>link them together</strong> to produce the final executable:
</p>
<pre>all:

    @clang -Wall -Werror -c source/hello.c -o build/hello.o
    @clang -Wall -Werror -c source/main.c -o build/main.o
    @clang -Wall -Werror build/hello.o build/main.o -o build/main
</pre>
<p>
    Note the additional <code>-c</code> flag, needed to tell the compiler to produce an unlinked object file, instead of an executable.
</p>
<p>
    But we obviously want the compilation to happen in separate targets, so we'll create a specific target for each C source file.<br>
    The <code>all</code> target will depend on these, and be responsible for linking the executable:
</p>
<pre>all: main hello
    
    @clang -Wall -Werror build/hello.o build/main.o -o build/main
    
main:
    
    @clang -Wall -Werror -c source/main.c -o build/main.o
    
hello:
    
    @clang -Wall -Werror -c source/hello.c -o build/hello.o
</pre>
<p>
    Also notice that the compiler flags (<code>-Wall -Werror</code>) are now repeated in each target.<br>
    Time to create a variable:
</p>
<pre>CFLAGS := -Wall -Werror

all: main hello
    
    @clang $(CFLAGS) build/hello.o build/main.o -o build/main
    
main:
    
    @clang $(CFLAGS) -c source/main.c -o build/main.o
    
hello:
    
    @clang $(CFLAGS) -c source/hello.c -o build/hello.o
</pre>
<p>
    This is obviously better, and it also mean we can now override the compiler flags when invoking <code>make</code>:
</p>
<pre>$ make CFLAGS=-Weverything
</pre>
<p>
    It might also be a good idea to create a variable for the compiler itself:
</p>
<pre>CC     := clang
CFLAGS := -Wall -Werror

all: main hello
    
    @$(CC) $(CFLAGS) build/hello.o build/main.o -o build/main
    
main:
    
    @$(CC) $(CFLAGS) -c source/main.c -o build/main.o
    
hello:
    
    @$(CC) $(CFLAGS) -c source/hello.c -o build/hello.o
</pre>
<p>
    So if you want to use <code>gcc</code> instead of <code>clang</code>, you can simply use:
</p>
<pre>$ make CC=gcc
</pre>
<p>
    And we should also add some output:
</p>
<pre>    
CC     := clang
CFLAGS := -Wall -Werror

all: main hello
    
    @echo "Linking executable"
    @$(CC) $(CFLAGS) build/hello.o build/main.o -o build/main
    
main:
    
    @echo "Compiling main.c"
    @$(CC) $(CFLAGS) -c source/main.c …</pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://xs-labs.com/en/blog/2020/11/07/introduction-to-makefiles/">https://xs-labs.com/en/blog/2020/11/07/introduction-to-makefiles/</a></em></p>]]>
            </description>
            <link>https://xs-labs.com/en/blog/2020/11/07/introduction-to-makefiles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25026656</guid>
            <pubDate>Sun, 08 Nov 2020 16:12:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Problem Solving Techniques]]>
            </title>
            <description>
<![CDATA[
Score 162 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25026561">thread link</a>) | @denvaar
<br/>
November 8, 2020 | https://denvaar.github.io/articles/problem_solving_example.html | <a href="https://web.archive.org/web/*/https://denvaar.github.io/articles/problem_solving_example.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>âœ�ï¸� Going meta - Working through a programming problem to understand problem solving techniques.</p><div>
        <p>The technical skills of computer programming fall under two broad categories, in my opinion.</p>
<p>The first category includes things like learning language syntax, constructs, and patterns. I would summarize it as the ability to connect and utilize the myriad, "tools of the trade" -- languages, frameworks, APIs, libraries -- to create software. There's usually tutorials for these things.</p>
<p>The second category includes things that are a little bit harder to put your finger on, but can probably be best described as problem solving. It's the ability to analyze, troubleshoot, debug, or solve a problem. It's the ability to reason with abstract ideas and turn them into code.</p>
<p>There is for sure some overlap between these two categories, but this is how I like to think about it.</p>
<p>It's hard to be specific about what it takes to be good at problem solving. I believe that's because we all have a slightly different perception of the world around us. Everyone learns differently. There must, however, be at least some techniques that I might learn from you, and vice versa.</p>
<p>Problems like the one I am about to share can be great tools for learning about problem solving. This one's from Project Euler. My intention is not to simply spoil the answer. I want to share my process of figuring it out, with the hope of being able to pinpoint some specific strategies that can be used to solve all kinds of problems.</p>
<h2 id="thechallenge">The challenge</h2>
<p>You can find the original problem statement <a href="https://projecteuler.net/problem=79">here</a>. It's short, so take a moment to read through.</p>
<p><img src="https://denvaar.github.io/assets/secret_number_0.png" alt=""></p>
<p>The challenge is to determine what the shortest possible secret number is. Here's an excerpt from the keylogger file.</p>
<pre><code>...
160
689
716
731
736
...
</code></pre>
<h2 id="firststeps">First steps</h2>
<p>I began by sitting down with pencil and paper to write some numbers from the list. Writing helps me begin to think about the problem.</p>
<p>I thought about what these numbers in the list could tell me about the secret number. Maybe I could find a way to at least figure out its length. There are about fifty numbers in the list, so maybe that number is somehow correlated to the secret number.</p>
<p>These were a few of the questions going through my head. If the answers seem super obvious to you, then congratulations, you might be smarter than me. What's most important during the first steps is that you ask questions.</p>
<p>I realized pretty quickly that no, the length of the list I was given didn't tell me much, but you've got to start somewhere. Next, my thoughts turned to the fact that each number was three digits long.</p>
<p><em>What if I was given a list of two-digit numbers, or even a list of just one-digit numbers? What could that tell me about the length of the secret number? Is there something special about three-digit numbers in particular?</em> These were valuable questions to ask, because it helped me to simplify the problem.</p>
<p>I made a list of one-digit numbers and tried to think about how I might be able to solve the same problem with that instead.</p>
<pre><code>6
2
1
0
</code></pre>
<p>Given a list like this as clues, I could say for certain that the secret number has at least a 6,2,1, and 0, but I also loose essential information about the problem: The order that the numbers appear in. A list of one-digit numbers is too ambiguous. The secret number could be <code>6210</code>, <code>2601</code>, or any other combination, and I would have no way of knowing which one is correct.</p>
<p>A list of two-digit numbers might be nice. It's less to think about, yet is still able to convey the needed information. From this point forward, I decided to think about the list as two-digit numbers, rather than three-digit numbers.</p>
<h2 id="possibleoptionmaintainasortedarray">Possible option: Maintain a sorted array</h2>
<p>At this point, I still wasn't sure how to solve the problem on paper, so I decided to try and work backwards. I wrote down a random number and then picked a few pairs of digits from it to try and reconstruct my own version of the problem. I decided to go through each number in the list and write down the digits as if they were being inserted into some kind of array.</p>
<p><img src="https://denvaar.github.io/assets/secret_number_1.png" alt=""></p>
<p>I realized an approach like this would not be very practical because it still leaves room for ambiguity.</p>
<p>In the example above, its clear that 5 is before 2, but if I continue to add the digits from the next number, I can't tell if the 1 should come before or after the 5. It's the same problem for the 8: I know it should come before the 2, but the data says nothing about if it should be before or after the 1, or the 5.</p>
<p>Even if I had another data point to disambiguate the clues -- <code>51</code>, for example -- sure, it would tell me that the 1 is in the correct spot between 5 and 2, but I already get the feeling that trying to write code to account for switching numbers around in an array is not going to be practical, and that there is probably an easier way.</p>
<p>Writing it out this way helped me realize that the help of some sort of data structure would be useful for solving this problem.</p>
<p>So now the question is, <em>what kind of data structure could help model this problem?</em> To help with this decision, I thought about what data is actually provided in the problem. Using the example above, the list of numbers reads as:</p>
<ul>
<li>5 "comes before" 2</li>
<li>1 "comes before" 2</li>
<li>8 "comes before" 2</li>
</ul>
<p>Each number in the list provides helpful clues, but the problem is that it's difficult to keep track of how each clue ultimately fits together. I tried to think of some kind of data structure that would be able to represent each clue individually, but also as a whole.</p>
<p>A directed graph seems to be a pretty natural fit to represent this information. Each node could be a digit, and the edges between nodes could represent the relationship between them.</p>
<p><img src="https://denvaar.github.io/assets/secret_number_2.png" alt=""></p>
<p>I felt good about using a graph to solve the problem, but there were still some questions that I had to figure out.</p>
<ul>
<li>How would I know when the graph has enough information to to be able to get the secret number? In other words, how can I know when my answer is conclusive?</li>
<li>How could the graph be read or interpreted programmatically to produce the secret number?</li>
<li>What if a secret number had more than one of the same digit? Would that ruin my approach?</li>
</ul>
<h2 id="howtoknowwhentheanswerisconclusive">How to know when the answer is conclusive</h2>
<p>To help answer this question I used the same technique of creating a simplified version of the problem and working backwards. Pretend now that 157 is the secret number. How many edges between the nodes would it take to definitively say that 1 comes before both 5 and 7, and 5 comes before 7? The answer is three edges for this particular graph.</p>
<p><img src="https://denvaar.github.io/assets/secret_number_3.png" alt=""></p>
<p>In this example, the order is known when number of edges are equal to the number of nodes. <em>Is it that simple? Can we know what the secret number is if the number of edges are equal to the number of nodes?</em></p>
<p>In this example, yes, but it doesn't hold true for the general case. By creating more examples, I start to find a relationship between the number of nodes, and the number of edges. Have a look at what four and five-digit secret numbers look like as a graph:</p>
<p><img src="https://denvaar.github.io/assets/secret_number_4.png" alt=""></p>
<p><img src="https://denvaar.github.io/assets/secret_number_5.png" alt=""></p>
<p>After drawing a few of these, I could begin to see a pattern emerge. As the number of nodes increase, the number of edges increase like, <code>1, 3, 6, 10, 15, 21, 28, ..</code>.</p>
<p>It can be helpful to look for patterns, because it means that there's an equation which can be used to represent some aspect of the problem. Here the pattern showed me what condition to use in order to know when my answer could be considered conclusive. This is the equation that represents that pattern, where n is the number of nodes in the graph.</p>
<p><img src="https://denvaar.github.io/assets/secret_number_6.png"></p>
<h2 id="readingthegraphtofindtheanswer">Reading the graph to find the answer</h2>
<p>A hand-drawn graph helps to visualize the approach of solving this problem, but I knew that I would also need to keep in mind how the graph could be represented with code. Specifically, how to programmatically traverse the graph to produce a result.</p>
<p>After staring at the examples for a bit longer, I realized an obvious and helpful property about the graph.</p>
<p>The nodes with the most outward edges come before those with less outward edges. Additionally, the number of edges for each node differ by exactly one. This means that the first digit of the secret number should have the most outward edges, while the last digit would not have any outward edges.</p>
<p>This property made logical sense to me, and was something that could be easily translated into code.</p>
<h2 id="duplicatedigits">Duplicate digits</h2>
<p>A secret number with more than one of the same digit could cause problems with my approach. This was something that worried me as I was working, because it was not clear how to know which two nodes to put the edge between. For example, take a look at 1030 as the secret number, and imagine the digits given in the following order:</p>
<p><img src="https://denvaar.github.io/assets/secret_number_7.png" alt=""></p>
<p>There are multiple ways to draw the graph because there are two 0's. There should still be only one "correct" way. Creating a correct graph might depend on the order in which the digits are given. I might need to think of some way to backtrack and re-connect nodes in order to end up with the correct graph.</p>
<p>The correct and incorrect graphs can be compared to understand how exactly they differ. The incorrect graph has a circular dependency: 3 comes before both the orange and blue 0's, but then the blue 0 comes before 3, which is contradictory.</p>
<p>Another difference is that the correct version is the only one that satisfies the property mentioned above, where the number of each node's edges differ by exactly one. This property should always be true for any secret number modeled with the graph.</p>
<p><img src="https://denvaar.github.io/assets/secret_number_8.png" alt=""></p>
<p>At this point, I decided to put the question of duplicate digits on hold. It looked like this would break the approach that I had planned to use. I think its possible to figure out, but it was unclear if this use case needed to be supported at all.</p>
<p>My plan was now to turn my ideas into code to see if it would produce the correct answer.</p>
<h2 id="translateideastocode">Translate ideas to code</h2>
<p>This part went by pretty quickly because I had formed a good understanding of the problem, as well as an approach for how to solve it. I picked Python for no particular reason, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://denvaar.github.io/articles/problem_solving_example.html">https://denvaar.github.io/articles/problem_solving_example.html</a></em></p>]]>
            </description>
            <link>https://denvaar.github.io/articles/problem_solving_example.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25026561</guid>
            <pubDate>Sun, 08 Nov 2020 15:57:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why the Average Customer Lifetime Value is not enough]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25026559">thread link</a>) | @dthread3
<br/>
November 8, 2020 | https://www.revenueforesight.com/blog | <a href="https://web.archive.org/web/*/https://www.revenueforesight.com/blog">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          <div><div>
	<table id="blogTable">
	<tbody><tr>
	    <td>
	        	<div id="272954475637336152-blog"> 
		<div id="wsite-content">	<div id="blog-post-378967267713861712">
	
	
		
	
		
	
		<div>
				<p><span size="7" color="#5040ae">W</span>hen you think of the demand curve for your business, you imagine a general downward sloping curve.&nbsp; Generally, economic theory would dictate that as you decrease the price, the quantity sold might increase.&nbsp; However, decreasing the price might not be the revenue maximizing action, because things would depend on what economists call the elasticity of the demand.&nbsp; The elasticity of demand is the percentage change in goods demanded for a percentage change in price.&nbsp; If the demand is highly elastic, then lowering prices will raise revenue, but if the demand is highly inelastic, then lowering prices will lower revenue.<br></p>  <p>We see a similar dynamic play out in the Customer's Lifetime Value.&nbsp; Suppose that you were to give a discount to a particular group of customers.&nbsp; Would that raise customer lifetime values so that total revenue is higher, or would it lower customer lifetime values so that total revenue is lower?&nbsp; This is a question that is played out over and over again in the relationship between the customers and the seller.<br></p>  <p>Consider the case with your "best" customer, in terms of generating the highest amount of revenue over their lifetime for your business.&nbsp; If you gave your "best" customer a discount, would that generate more revenue for you over their lifetime for your business, or less?&nbsp; Paradoxically, the answer is that it would most likely generate less revenue.&nbsp; The reason is because at the current prices, their demand is satiated.&nbsp; If you gave them a discount, it would not increase consumption enough to cover the discount.<br></p>  <p>Consider the case of your "worst" customer, in terms of generating the lowest amount of revenue over their lifetime for your business.&nbsp; These are the people who will most likely churn.&nbsp; If you gave these people a discount would they generate more revenue over their lifetime to cover the discount and have a gain, or would they generate less?&nbsp; Unsurprisingly, they would most likely still churn and use your discount, so your business would lose revenue.<br></p>  <p>However, there is a particular class of customers that you currently have, which would most likely grow their consumption given the right incentives.&nbsp; They are the ones that need to be introduced into to new products, or features, or even to help their own businesses grow so that they could consume more.&nbsp; They have the potential to grow into your "best" customers.&nbsp; They are however a very select group that is hard to identify.<br></p>  <p>With our AI software that forecasts future lifetime values we can identify this group easily and help you avoid incentivizing the wrong groups.&nbsp; We are able to see what levels of incentives are necessary to induce changes in behavior and the resulting gains or losses.<br></p>  <div><div> <p><a> <img src="https://www.revenueforesight.com/uploads/1/3/4/4/134486339/clv-presentation3-pic_orig.jpg" alt="Picture"> </a></p> </div></div>  <p>Because we are able to forecast down to individual future purchase values for each customer, you can target only those customers that bring you a net gain.&nbsp; We can even automate this feature for you. &nbsp; Contact us for a demo.<br></p>

		</div>
	
	
			

	
		
	
		
	</div>	<div id="blog-post-895881066272963342">
	
	
		
	
		
	
		<div>
				<p><strong><span size="6" color="#5040ae"><em>W</em></span></strong>e previously covered average lifetime value by looking at actual past purchase lifetimes.&nbsp; There is however an alternative formulation that is widely used that doesn't look necessarily at averaging each individual lifetime value, but instead just uses the averages in customer behavior.&nbsp; Let us elaborate with each formula.<br></p>  <h2><span size="4">The Average Order Size</span><br></h2>  <p>The Average Order size is given by&nbsp; AO = Total Revenue / Number of Orders. This treats all orders from everyone the same, as if they came from each individual equally.<br></p>  <h2><span size="4">The Average Frequency Of Orders</span></h2>  <p>The Average Frequency of Orders is given by AF = Number of Customers / Number of Purchases.&nbsp; This doesn't measure true frequency because you don't know the actual time between purchases.<br></p>  <h2><span size="4">The Average Lifetime</span></h2>  <p>The Average Lifetime is given by AL = sum of Customer Lifetimes / Number of Customers.&nbsp; However, because you can't necessarily wait 20 years to see the total customer lifetimes, it is sometimes suggested to use 1 / churn rate percentage to estimate this value.<br></p>  <h2><span size="4">The Average Customer Lifetime Value</span></h2>  <p>The Average Customer Lifetime Value is then given by AvgCLV = AO*AF*AL.&nbsp; It is just the previous formulas multiplied with each other to get the "average" in lifetime value.<br></p>  <h2><span size="4">Correlated Values and Problems with using the "<em>Average</em>"</span><br></h2>  <p>The above formula, while simple, has a few glaring flaws that are not fixable.&nbsp; Customers don't behave like the average, and the "average" lifetime value will be terribly misleading.&nbsp; When you multiple the averages together, you assume that each factor AO, AF,&nbsp; and AL are statistically independent.&nbsp;&nbsp; They are not.&nbsp; When the customer is a high lifetime value customer, the Average Order sizes are larger, the Average Frequency is greater, and the Average Lifetime is greater, for example.&nbsp; When the customer is a low lifetime value customer, the Average Order sizes are smaller, the Average Frequency is less, and the Average Lifetime is shorter, for example.<br></p>  <p>Let's work through an example where we can see the effect of correlation on the "average" lifetime value.&nbsp; For simplicity, assume the correlation is perfect, which won't be too far from the actual case.&nbsp; These numbers come from a Starbucks case study.&nbsp; For Starbucks, the average frequency is AF = 4.2 visits per week.&nbsp; The average order size is AO = $4.05 per visit.&nbsp; The estimated lifetime is 20 years, so AL = 52 weeks * 20 years.&nbsp; This gives the Average Customer Lifetime Value as<br></p>  <p>AvgCLV = $4.05*4.2*52*20 = $17,690.40<br></p>  <p>We can look at the correlation effect as equivalent to adding an extra term inside the formula for Average Customer Lifetime Value</p>  <p>AvgCLV = (AO+x)(AF+x)(AL+x)</p>  <p>When a customer is high lifetime value customer, x is added to all the base values.&nbsp; When a customer is a low lifetime value customer, you can think of subtracting x from all the base values.&nbsp; Now let us look at what happens to the Starbucks customer when they are a high value lifetime customer by assuming it raises all the values by 20%.<br></p>  <p>HighAvgCLV = ($4.05*1.2)*(4.2*1.2)*(52*20*1.2) = $ 30,569.01<br></p>  <p>This value is almost twice the baseline. And let's look similarly at what happens when the Starbucks customer is a low value lifetime customer by lowering all the values by 20%.<br></p>  <p>LowAvgCLV = ($4.05*0.8)*(4.2*0.8)*(52*20*0.8) = $9,057.48<br></p>  <p>This value is almost half the baseline value.&nbsp; High and Low value customers might not be a problem with there were an equal number of both types, but if you recall the L-Shaped distribution from the previous post on "Why The Average Customer Lifetime Value is Not Enough", the majority of customers come from the low value of the distribution with a long tail, since roughly 80% of revenue is generated by only 20% of the customers.<br></p>  <div><div> <p><a> <img src="https://www.revenueforesight.com/uploads/1/3/4/4/134486339/clv-presentation-4-001_orig.png" alt="Picture"> </a></p> </div></div>  <p>The real-world effect of correlation on the terms in the "average" lifetime value AvgCLV = AO*AF*AL, is to make the calculation highly biased and misleading by making the L-shaped distribution have greater extremes in the tails and making it more L-shaped.&nbsp;&nbsp; When the true lifetime value of customers affects the profitability of your business, you cannot depend on the "average" formulas. Given that there is a cost to acquiring customers (through ads and incentives), then knowing the true lifetime values is a key piece of information that you need for your business.<br></p>  <p>We can help you with discovering what the true lifetime value is of each and every customer in your business, because we have AI software that forecasts what each individual customer's lifetime value will be, and what their stream of future purchase values will be, with high accuracy, early in their life.&nbsp; Contact us for a demo.<br></p>

		</div>
	
	
			

	
		
	
		
	</div>	<div id="blog-post-898714202450837069">
	
	
		
	
		
	
		<div>
				<div><p><span size="7" color="#5040ae"><em><strong>A</strong></em></span> lot of e-commerce advice sites will suggest you look at customer lifetime value by their average.&nbsp; The average value however will be very misleading and may cause you to make terrible decisions on acquiring customers.</p><p>Let's examine why the average lifetime value is highly misleading.&nbsp; Below is a graph of customer lifetime purchase values ordered by customer.&nbsp; It is a familiar L-shaped distribution with long tails.</p></div>  <div><div> <p><a> <img src="https://www.revenueforesight.com/uploads/1/3/4/4/134486339/clv-presentation2-pic_orig.jpg" alt="Picture"> </a></p> </div></div>  <p>This distribution becomes more L-shaped as more customers are added.&nbsp; It never becomes the shape of a normal Gaussian distribution that everyone is familiar with, which is a symmetric bell-shaped distribution with 2 sides.<br></p>  <h2><span size="5">The 80/20 rule</span><br></h2>  <p>There is a rule of thumb for business that roughly 80% of the revenues are driven by 20% of the customers. (In actually it is closer to 73-76%).&nbsp; Let's see what kind of implications such an extreme distribution has on the average customer lifetime value.</p>  <p>Let's begin with some round numbers.&nbsp; Say $80 million of lifetime revenue is generated by 20 customers.&nbsp; The rest of the 80 customers only generate $20 million of lifetime revenue.&nbsp;&nbsp; This makes the average lifetime revenue generated to be $4m*20% + $0.25m*80% = $1 million lifetime revenue on average per customer (out of 100 customers and $100m revenue).&nbsp; From the high revenue generating group the average is $4 million per customer.&nbsp; From the low revenue generating group the average is $0.25 million per customer. &nbsp;<br></p>  <p>Now for the sake of simplicity, assume that the Cost of Acquisition of&nbsp; each Customer (<strong>CAC</strong>) is $1 million, or close to it because you are basing decisions on the average lifetime revenue generated by each customer.&nbsp;&nbsp; Then for 20 customers, you are profitable by $3 million, but for 80 customers you are losing $0.75million, each.<br></p>  <p>As you scale your business, it is more likely that you will add customers who are unprofitable.&nbsp;&nbsp; The tail of the L-shaped distribution becomes more extreme, and what you thought was the average lifetime revenue of $1 million 6 months ago, is now only $0.5 million on average.&nbsp; You will not know this is changing because it takes a while to realize that new customer lifetime values are lower than before.&nbsp; This could be disastrous if you kept the $1 million per Customer Acquisition Cost.&nbsp; …</p></div></div></div></div></td></tr></tbody></table></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.revenueforesight.com/blog">https://www.revenueforesight.com/blog</a></em></p>]]>
            </description>
            <link>https://www.revenueforesight.com/blog</link>
            <guid isPermaLink="false">hacker-news-small-sites-25026559</guid>
            <pubDate>Sun, 08 Nov 2020 15:57:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making a programming language using Rust]]>
            </title>
            <description>
<![CDATA[
Score 182 | Comments 23 (<a href="https://news.ycombinator.com/item?id=25026419">thread link</a>) | @azhenley
<br/>
November 8, 2020 | https://arzg.github.io/lang/ | <a href="https://web.archive.org/web/*/https://arzg.github.io/lang/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A series about making a programming language called <a href="https://github.com/arzg/eldiro">Eldiro</a> using the <a href="https://rust-lang.org/">Rust</a> programming language.</p><p><a href="https://arzg.github.io/lang/9/">Part Nine: Function Calls</a></p><p><a href="https://arzg.github.io/lang/8/">Part Eight: Function Definitions</a></p><p><a href="https://arzg.github.io/lang/7/">Part Seven: A REPL</a></p><p><a href="https://arzg.github.io/lang/6/">Part Six: Blocks</a></p><p><a href="https://arzg.github.io/lang/5/">Part Five: Binding Usages</a></p><p><a href="https://arzg.github.io/lang/4/">Part Four: Backtracking</a></p><p><a href="https://arzg.github.io/lang/3/">Part Three: Defining Variables</a></p><p><a href="https://arzg.github.io/lang/2/">Part Two: Whitespace Support</a></p><p><a href="https://arzg.github.io/lang/1/">Part One: A Basic Parser</a></p><p><a href="https://arzg.github.io/lang/0/">Part Zero: Getting set up</a></p></div></div>]]>
            </description>
            <link>https://arzg.github.io/lang/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25026419</guid>
            <pubDate>Sun, 08 Nov 2020 15:41:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Cloud IAM for Security Teams]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25026227">thread link</a>) | @gbrindisi
<br/>
November 8, 2020 | https://cloudberry.engineering/article/google-cloud-iam-security-guide/ | <a href="https://web.archive.org/web/*/https://cloudberry.engineering/article/google-cloud-iam-security-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        <div>
            <p>Identity and Access Management (IAM) is an important piece of the cloud puzzle and it’s usually a source of headaches from a security point of view. Let’s try to give some pointers from a blue team perspective.</p>

<p>If you are a security team that just inherited a bunch of Google Cloud Platform (GCP) accounts, this guide is for you.</p>

<h2 id="identities-and-roles">Identities and Roles</h2>

<p>IAM revolves around the concept of <strong>identity</strong>: an (authenticated) entity to which authorization grants are applied.</p>

<h3 id="members">Members</h3>

<p>In Google Cloud, identities are called <strong>members</strong> and are the following:</p>

<ul>
<li>A <strong>User</strong>: defined by a Google Account</li>
<li>A <strong>Group</strong>: defined by a Google Group</li>
<li>A <strong>domain</strong>: a super group representing all accounts under a gsuite/workspace domain</li>
<li>A <strong>Service Account</strong>: an account for an application rather than an end user</li>
</ul>

<p>To make things spicier, there are also two special members that you are going to hate and you want to make sure they will <em>never be used</em> (unless valid business reasons):</p>

<ul>
<li><strong>allAuthenticatedUsers</strong>: a special group comprised of everyone on earth with a google account (yes)</li>
<li><strong>allUser</strong>: anyone on the internet, authenticated or not</li>
</ul>


<div><p>
Pro Tip:</p>

<ul>
<li>scan your IAM policies and make sure that <code>allAuthenticatedUsers</code> and <code>allUsers</code> are never used</li>
<li>or even better, set up an organizational policy to only allow members from your gsuite/workspace domain</li>
</ul>
</div>


<h3 id="roles">Roles</h3>

<p>You assign (bind) a Role to a Member to grant that identity access to a resource. An example role is  <code>resourcemanager.projectCreator</code>:</p>

<pre><code>$ gcloud iam roles list
…
---
description: Access to create new GCP projects.
etag: AA==
name: roles/resourcemanager.projectCreator
stage: GA
title: Project Creator
---
…
</code></pre>

<p>Roles are a set of <em>permissions</em> grouped together, each one representing a fine grained operation. You can’t assign permissions directly to members.</p>

<p>An example permission would be <code>resource manager.projects.create</code>:</p>

<pre><code>$ gcloud iam roles describe roles/resourcemanager.projectCreator
description: Access to create new GCP projects.
etag: AA==
includedPermissions:
- resourcemanager.organizations.get
- resourcemanager.projects.create
name: roles/resourcemanager.projectCreator
stage: GA
title: Project Creator
</code></pre>

<p>Usually, every cloud service will come with a dedicated set of Roles (<a href="https://cloudberry.engineering/article/stricter-access-control-to-gcr/">not for Google Container Registry</a>).</p>

<h3 id="custom-roles">Custom Roles</h3>

<p>As a rule of thumb <strong>stick to standard roles</strong>, but if you have to bind a role to a member in a high level policy you might want to <a href="https://cloud.google.com/iam/docs/creating-custom-roles">use a custom role</a>. Custom Roles allows you to group together the specific set of permissions you need.</p>

<p>They are helpful to maintain least privilege because a role bind on a high level policy (like the Organization one) will affect way more resources.</p>


<div><p>
Pro Tip:</p>

<ul>
<li>Use standard roles when the number of affected resources is limited</li>
<li>Use custom roles when the authorization grant affect too many resources</li>
</ul>
</div>


<h3 id="primitive-roles">Primitive Roles</h3>

<p>There are a bunch of roles you should be wary of: <em>primitive roles</em>. These are <code>Owner</code>, <code>Editor</code> and <code>Viewer</code>. When they are bind on the Project IAM policy they translate to admin, write and read access to everything inside that project.</p>

<p>You want to be wary for two reasons:</p>

<ol>
<li>The set of permissions change over time: when Google release new cloud services, permissions for such services are included in the primitive roles. This means <strong>you have an authorization grant that change over time and you have no control over</strong>. No bueno.</li>
<li><strong>They are a bridge to <a href="https://cloud.google.com/storage/docs/access-control/lists">Access Control List</a></strong> (ACL). ACL are the legacy authorization system for some storage services such as Buckets and Bigquery. In such resources you can assign ACL grants to whoever is bind to a primitive role in the Project. This relationship <strong>adds complexity when trying to understand the <a href="https://cloudberry.engineering/article/lateral-movement-cloud/">blast radius</a></strong> of a member.</li>
</ol>

<p>If you can’t escape using a primitive role, bind them to members that you will use only in “break the glass” scenarios. In practice, you don’t want a team doing their day to day operations as <code>Owners</code>.</p>


<div><p>
Pro Tip:</p>

<ul>
<li>Avoid primitive roles</li>
<li>Do not use Access Control Lists (ACL)</li>
</ul>
</div>


<h2 id="iam-policies-and-where-to-find-them">IAM Policies (and where to find them)</h2>

<p>Roles are bind to members in an IAM Policy. Policies are organized in hierarchical layers (from top to bottom):</p>

<ul>
<li><strong>Organization</strong></li>
<li><strong>Folder</strong></li>
<li><strong>Project</strong></li>
<li>Specific Resources.</li>
</ul>

<p>Bindings will be inherited from top to bottom.</p>

<p>So if you assign <code>Storage Admin</code> to a service account in the Organization IAM Policy, the same grant will be applied to everything down (don’t do that).</p>

<p>You obviously want to be extra careful when binding roles high in the hierarchy as the authorization grant will be quite large. That’s why it’s a good idea to use custom roles to shrink it to just the permissions you need.</p>

<p>Some specific cloud resources, such as Buckets, have their own IAM policy. These are easy to overlook because they don’t have a consistent place in the google cloud admin interface.</p>

<p>The best way to <strong>get visibility over all IAM policies</strong> is to <a href="https://cloud.google.com/asset-inventory/">create a Cloud Asset Inventory (CAI) dump</a>. CAI is, in my opinion, <strong>the most useful thing in GCP</strong>. It’s an API that will generate a json (or bigquery) dump of all the resources and IAM Policies you are currently running.</p>

<p>The best thing you can do on day one is to set up periodical CAI dumps, and then build your detections on top of them.</p>

<h3 id="maintain-the-principle-of-least-privilege">Maintain the principle of least privilege</h3>

<p>The second best thing is to <a href="https://cloud.google.com/iam/docs/recommender-overview">use the IAM Recommender</a>: a service that monitors how role bindings are actually used to make sure you are not over granting them.</p>

<p>Another helpful trick to know is that you can <a href="https://cloud.google.com/iam/docs/conditions-overview">attach conditions to role bindings</a>. For example you can set an expiration time, or you can scope down the binding to affect only certain resources matching a pattern.</p>


<div><p>
Pro Tip:</p>

<ul>
<li>The higher in the IAM hierarchy, the wider the scope of the authorization grant: use sporadically, be a gatekeeper.</li>
<li>Set up Cloud Asset Inventory to not miss anything</li>
<li>Use the IAM Recommender</li>
<li>Use IAM Conditions</li>
</ul>
</div>


<h2 id="notes-on-service-accounts">Notes on Service Accounts</h2>

<p>Service accounts can be of two types: google managed and user managed.</p>

<p>A user managed service account is one you manually create. To use it, you need to create a private key and embed it into your application. A service account can have multiple keys.</p>

<p><strong>Service Account keys lifecycle is your responsibility</strong>: they never really expires, are hard to audit (you don’t see which key has been used from the audit logs). From day one you should start thinking how to keep track of them.</p>

<p>Personally I am a fan of wrapping keys creation into an internal service for your developers to use, but I understand it’s not always possible.</p>

<p>The best alternative is to <strong>use google managed service accounts</strong>. For example each project will come with a default service account that is used by Google Compute Engine (GCE) services (if the GCE API is enabled).</p>

<p>This means that virtual machines will transparently be identified by that service account, and they are authorized to request short-lived authorization tokens from the internal metadata service. You can configure them to use a service account of your choice and <strong>no keys are involved</strong>.</p>


<div><p>
Pro tip:</p>

<ul>
<li>Become a gatekeeper for provisioning Service Accounts keys</li>
<li>Use the identity of the virtual machines whenever possible</li>
<li>Are you running Google Kubernetes Engine (GKE)? Take a look at <a href="https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity">Workload Identity</a></li>
<li>Follow <a href="https://cloudberry.engineering/article/google-cloud-service-accounts-security-best-practices/">service accounts best practices</a></li>
</ul>
</div>


<h2 id="conclusion">Conclusion</h2>

<p>To recap:</p>

<ul>
<li>scan your IAM policies and make sure that <code>allAuthenticatedUsers</code> and <code>allUsers</code> are never used</li>
<li>or even better, set up an organizational policy to only allow members from your gsuite/workspace domain</li>
<li>Use standard roles when the number of affected resources is limited</li>
<li>Use custom roles when the authorization grant affect too many resources</li>
<li>Avoid primitive roles</li>
<li>Do not use Access Control Lists (ACL)</li>
<li>The higher in the IAM hierarchy, the wider the scope of the authorization grant: use sporadically, be a gatekeeper.</li>
<li>Set up Cloud Asset Inventory to not miss anything</li>
<li>Adhere to the least privilege principle with the IAM Recommender and IAM Conditions</li>
<li>Become a gatekeeper for provisioning Service Accounts keys</li>
<li>Use the identity of the virtual machines whenever possible</li>
<li>Are you running Google Kubernetes Engine (GKE)? Take a look at <a href="https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity">Workload Identity</a></li>
<li>Follow <a href="https://cloudberry.engineering/article/google-cloud-service-accounts-security-best-practices/">service accounts best practices</a></li>
</ul>

<p>There is a lot more to say about IAM governance and security best practices. This article’s purpose is to give a high level overview of the main security considerations.</p>

<p>If you are looking for specific advices, <a href="mailto:hello@cloudberry.engineering">let me know</a>. I might have some.</p>

<p>Finally, I highly recommend this <a href="https://www.youtube.com/watch?v=YGT_AmCA-eA&amp;feature=youtu.be">fantastic talk by Kat Traxler</a> about primitive roles and IAM quirks in GCP.</p>
        </div>
        
    </div>
</section></div>]]>
            </description>
            <link>https://cloudberry.engineering/article/google-cloud-iam-security-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25026227</guid>
            <pubDate>Sun, 08 Nov 2020 15:13:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[South Ayrshire Golf club owner loses 2020 presidential election]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25026202">thread link</a>) | @gnufx
<br/>
November 8, 2020 | https://www.ayrshiredailynews.co.uk/post/south-ayrshire-golf-club-owner-loses-2020-presidential-election | <a href="https://web.archive.org/web/*/https://www.ayrshiredailynews.co.uk/post/south-ayrshire-golf-club-owner-loses-2020-presidential-election">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.3.0"><div dir="ltr"><div><p id="viewer-8j2hn"><span>Donald Trump, a South Ayrshire golf club owner has lost the 2020 presidential election to Joe Biden, after running again to be re-elected for a second presidential term.</span></p><div id="viewer-2nsni"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label=""><p><img data-pin-url="https://www.ayrshiredailynews.co.uk/post/south-ayrshire-golf-club-owner-loses-2020-presidential-election" data-pin-media="https://static.wixstatic.com/media/bc51f5_8bc1fa53ac3f4237b0037c9490c6fb37~mv2.jpg/v1/fit/w_1000%2Ch_637%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/bc51f5_8bc1fa53ac3f4237b0037c9490c6fb37~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg" alt=""></p></div><p><span dir="auto">Pic - Northwest Public Broadcasting </span></p></div></div></div><p id="viewer-1nsvc"><span>Donald Trump, currently the 45th president who also owns the Trump Turnberry golf course in South Ayrshire, Scotland has lost the 2020 presidential race to Joe Biden It’s been confirmed.</span></p><p id="viewer-42nml"><span><span>Biden is projected to win Pennsylvania, Arizona &amp; Georgia taking him well over the 270 needed to win the US election and the win for Joe was projected by CNN earlier this afternoon (UK Time).</span></span></p><p id="viewer-b9m6j"><span>Donald who is currently the 45th US president has now lost to Joe Biden who is projected at 290 vs Trumps projected 214 with Joe Biden now set to become the 46th US president.</span></p><p id="viewer-85of6"><span>Donald Trump has however vowed to contest the election in the Supreme Court after saying the election was a fraud, and rigged by the Democrats after loosing his big majorities in states like Pennsylvania &amp; Georgia to postal votes which have been counted over the past several days. </span></p><p id="viewer-3fp2h"><span>Trump has also repeated his unfounded claims that poll watchers were not allowed into ballot counting rooms to observe.&nbsp;</span></p><p id="viewer-1r2l8"><span>Election officials have however said that both Republican and Democrat poll watchers were able to watch the process, and have rubbished claims of unfairness.&nbsp;</span></p><blockquote id="viewer-csnc2"><span><strong><em>Donald Trump tweeted the following earlier after hearing Biden was projected to win the election:</em></strong></span></blockquote><p id="viewer-52uur"><span><span>"THE OBSERVERS WERE NOT ALLOWED INTO THE COUNTING ROOMS. I WON THE ELECTION, GOT 71,000,000 LEGAL VOTES. BAD THINGS HAPPENED WHICH OUR OBSERVERS WERE NOT ALLOWED TO SEE. NEVER HAPPENED BEFORE. MILLIONS OF MAIL-IN BALLOTS WERE SENT TO PEOPLE WHO NEVER ASKED FOR THEM!"</span></span></p><p id="viewer-6b0kl"><span><span>"71,000,000 Legal Votes. The most EVER for a sitting President!"</span></span></p><blockquote id="viewer-dk8em"><span><span><strong>Donald Trump also issued the following statement this afternoon:</strong></span></span></blockquote><p id="viewer-ef707"><span>"Beginning Monday, our campaign will start prosecuting our case in court to ensure election laws are fully upheld and the rightful winner is seated," he added.</span></p><p id="viewer-7m3av"><span>"I will not rest until the American people have the honest vote count they deserve and that democracy demands."</span></p><blockquote id="viewer-162q3"><span><span><strong>Joe Biden also issued statement this afternoon after finding out he had won the US Election:</strong></span></span></blockquote><p id="viewer-ao2b6"><span>"America, I’m honored that you have chosen me to lead our great country.</span></p><p id="viewer-85u1p"><span>The work ahead of us will be hard, but I promise you this: I will be a President for all Americans — whether you voted for me or not."</span></p><p id="viewer-5akrg"><span>"I will keep the faith that you have placed in me."</span></p><p id="viewer-ceo50"><span><span>Joe Biden is also expected to give a speech in the early hours of tomorrow morning at around 1AM UK Time.</span></span></p><p id="viewer-cfvr0"><span><span><em><strong>PM Boris Johnson also congratulated Joe Biden on his win</strong></em></span></span></p><div id="viewer-bq7va"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.ayrshiredailynews.co.uk/post/south-ayrshire-golf-club-owner-loses-2020-presidential-election" data-pin-media="https://static.wixstatic.com/media/bc51f5_3155158b89b94139b5a3131dfeb4df65~mv2.jpg/v1/fit/w_680%2Ch_383%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/bc51f5_3155158b89b94139b5a3131dfeb4df65~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.ayrshiredailynews.co.uk/post/south-ayrshire-golf-club-owner-loses-2020-presidential-election</link>
            <guid isPermaLink="false">hacker-news-small-sites-25026202</guid>
            <pubDate>Sun, 08 Nov 2020 15:09:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BGP Lego Bricks]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25026189">thread link</a>) | @bitcynth
<br/>
November 8, 2020 | https://blog.cynthia.re/post/bgp-lego | <a href="https://web.archive.org/web/*/https://blog.cynthia.re/post/bgp-lego">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<h3>Nov 8 2020</h3>


<p>Since I was 7 years old, I have wanted a LEGO Mindstorms robot. I will admit that in the later years it was mainly that I wanted to prove to myself that I got somewhere as it seemed so infinitely expensive back when I was younger…</p>

<p><a href="https://twitter.com/bitcynth/status/1319956429252513792" title="Tweet about it"><img src="https://blog.cynthia.re/asset/g1ZkG7sMAD" alt="LEGO Robot Inventor"></a></p>

<p>Well I finally got one!</p>

<p>I knew this thing had some capability to run <a href="https://micropython.org/">MicroPython</a> since that was mentioned in the product description quite predominantly, which sounded like a pretty hackable platform.</p>

<p>However, shortly after opening the box, I realized that this wasn’t at all just an update to the <a href="https://www.lego.com/en-us/product/lego-mindstorms-ev3-31313">Mindstorms EV3</a>. Apparently the Robot Inventor was a slightly more expensive thing with less features and using a LiPo battery instead of AA cells.</p>

<p>Luckily I ordered it via the store’s website which means that by law I can return it within 14 days for any reason, and it allows me to open the box for inspection.</p>

<p>So after convincing some stubborn store employee that this is not a consumable product (which would remove my right to open the box), I got it returned and ordered the EV3.</p>

<p>Then two days later I finally had the thing which I have wanted for so long.</p>

<p>While I was waiting for the EV3, I was looking around at how it did MicroPython as it had this paragraph on the downloads page.</p>

<pre><code>You can now use your EV3 Brick to unleash the power of Python programming using MicroPython. Simply install the EV3 MicroPython image onto any micro SD card and boot up your EV3 Brick from it to start programming straight away. 
</code></pre>

<p>After just a few minutes of searching I found <a href="https://www.ev3dev.org/">ev3dev</a> which is an open source community project that allows you to run Debian on it!</p>

<p>It appears to be really well made and apparently good enough for LEGO to provide <a href="https://education.lego.com/en-us/support/mindstorms-ev3/python-for-ev3">official builds</a> of it, which is what they use for MicroPython support.</p>

<p>So I just went ahead and downloaded and flashed the disk image to a microSD card with <code>dd</code>.
I then plugged in the microSD card into the EV3 controller and turned it on…</p>

<p><img src="https://blog.cynthia.re/asset/rC3JqPiBNA" alt="EV3 kernel dmesg"></p>

<p>To my surprise, after applying power I was pleased to see kernel dmesg output scrolling out on the LCD of the EV3 on the first try!</p>

<pre><code>robot@ev3dev:~$ uname -a
Linux ev3dev 4.14.117-ev3dev-2.3.5-ev3 #1 PREEMPT Sat Mar 7 12:54:39 CST 2020 armv5tejl GNU/Linux

robot@ev3dev:~$ cat /etc/os-release 
PRETTY_NAME="ev3dev-stretch"
NAME="ev3dev-stretch"
ID=ev3dev
ID_LIKE=debian
HOME_URL="http://www.ev3dev.org"
SUPPORT_URL="http://www.ev3dev.org/support"
BUG_REPORT_URL="https://github.com/ev3dev/ev3dev/issues"
</code></pre>

<p>After playing around with it for about two minutes, I realized something… this thing runs Debian with a pretty damn complete package repository (it has ~64000 packages and normal amd64 Debian has ~66000 packages), can this thing run BIRD?</p>

<p>I assumed that if the ARM926EJ-S CPU can run Debian and stuff it can probably run a very minimal BIRD config, however I wasn’t so sure about the 56MB of RAM.</p>

<p>But well you won’t know if you don’t try :p</p>

<p>So I just went ahead and typed <code>sudo apt install bird</code> and pressed enter…</p>

<pre><code>robot@ev3dev:~$ sudo apt install bird
Reading package lists... Done
Building dependency tree       
Reading state information... Done
Suggested packages:
  bird-doc
</code></pre>

<p>(this was actually painfully slow as this thing doesn’t have a powerful CPU in the slightest)</p>

<p>As soon as I saw <code>bird-doc</code> I realized that yes it did at least have BIRD in the repo so that was a good first step.</p>

<p>I am only installing BIRD 1.6.3 here as it will probably use less resources than BIRD 2 if I only run the IPv6 daemon and disable the IPv4 daemon.</p>

<p>I then wrote a <a href="https://blog.cynthia.re/asset/gv3GvwzBGH">quick little bird config</a> to let the EV3 (AS202314) announce 2a0d:1a45:666::/48 to my home router (AS210089), and the home router will then deal with the rest.</p>

<p>I applied that and wrote the other end of the config on my home router and applied that too.</p>

<p>Then I went to the <a href="http://lg.ring.nlnog.net/">NLNOG RING Looking Glass</a> and I saw the /48 show up as announced by AS202314!</p>

<p><img src="https://blog.cynthia.re/asset/KVCU9bynjB" alt="NLNOG RING Looking Glass"></p>

<p>I then sent it to a friend who pointed out only about half of his sources could see the route, and well turns out I forgot to give AS202314 an <a href="https://en.wikipedia.org/wiki/Resource_Public_Key_Infrastructure">RPKI ROA</a> for the prefix, so I added that.</p>

<p>Then just for demo purposes I installed nginx which worked surprisingly well, so then I had a website I could access at http://[2a0d:1a45:666::]/ <sup><a href="#fn1">[1]</a></sup>.</p>

<p>This was surprisingly easy to get working. Hats off to the <a href="https://www.ev3dev.org/">ev3dev</a> people for making this Debian derivative for the EV3.</p>

<p>While having the EV3 sitting there announcing a /48 of IPv6 is not useful in itself, this shows off how flexible the platform is. The fact that I can do this silly thing means that I can do much cooler things that don’t involve BGP on this, like running web servers and other things.</p>

<hr>

<p>If this was to your liking then maybe you will find my other posts interesting, and you can also find my smaller projects and ramblings on twitter: <a href="https://twitter.com/bitcynth">@bitcynth</a>.</p>

<p>Thank you to <a href="https://twitter.com/Benjojo12">Ben Cox</a> and <a href="https://www.mollymiller.net/">Molly Miller</a> for the help in editing this blog post.</p>

<p><sup><a name="fn1">[1]</a></sup>: no longer online</p>

</div></div>]]>
            </description>
            <link>https://blog.cynthia.re/post/bgp-lego</link>
            <guid isPermaLink="false">hacker-news-small-sites-25026189</guid>
            <pubDate>Sun, 08 Nov 2020 15:06:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[macOS file diff app, Kaleidoscope, acquired by Letter Opener GmbH]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25026070">thread link</a>) | @dplgk
<br/>
November 8, 2020 | https://kaleidoscope.app/release-notes | <a href="https://web.archive.org/web/*/https://kaleidoscope.app/release-notes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="macos"><h3>Kaleidoscope 2.3.4<p>November 6 2020</p></h3><p>build 1444 (Direct)</p><ul><li>Fixed some potential bugs hiding behind warnings.</li><li>Fixed missing update functionality of version 2.3.2.</li><li><strong>Note:</strong> If you installed version 2.3.2 please download manually the latest version.</li></ul><h3>Kaleidoscope 2.3.3<p>October 24 2020</p></h3><p>build 1443.1 (Mac App Store)</p><ul><li>Update contact information to support@kaleidoscope.app, don't be shy and say hi!</li><li>Fixed newsletter sign-up in the Help &gt; Getting Started window.</li></ul><h3>Change of ownership<p>October 9 2020</p></h3><ul><li>Letter Opener GmbH acquired Kaleidoscope from Hypergiant LLC.</li></ul><h3>Kaleidoscope 2.3.2<p>April 17 2020</p></h3><p>build 1442 (Direct) / 1442.1 (Mac App Store)</p><ul><li><strong>Note:</strong> build 1442 (Direct) was pulled because it is missing update functionality. If you installed version 2.3.2 please download manually the latest version.</li><li>Fixed bug in integration window</li></ul><h3>Kaleidoscope 2.3.1<p>April 7 2020</p></h3><p>build 1441 (Direct) / 1441.2 (Mac App Store)</p><ul><li>Fixed a crash caused by opening a zero-length text file</li><li>Improved scrolling performance when using Find to search for text</li><li>Minor bug fixes</li></ul><h3>Kaleidoscope 2.3<p>February 21 2020</p></h3><p>build 1438 (Direct)</p><ul><li>Improved macOS Catalina compatibility</li><li>Notarized builds for improved security</li><li>Fixed blurred scrollbar endcap issue on Retina displays</li><li>Updated crash analytics package</li><li>Minor bug fixes</li></ul><h3>Kaleidoscope 2.2.2<p>November 7 2017</p></h3><p>build 1376 (Direct) / 1376.01 (Mac App Store)</p><ul><li>Bug Fixes.</li></ul><h3>Kaleidoscope 2.2.1<p>August 9 2017</p></h3><p>build 1158 (Direct) / 1158.01 (Mac App Store)</p><ul><li><strong>Note:</strong> Kaleidoscope now requires macOS 10.12 or above.</li><ul><li>Fixed crashes related to future macOS releases.</li><li>Fixed an issue where the user is unnecessarily prompted to update ksdiff.</li><li>Updated documentation.</li><li>Added analytics to help our developers improve future releases.</li></ul></ul><h3>Kaleidoscope 2.2<p>May 3 2017</p></h3><p>build 439 (Direct) / 439.01 (Mac App Store)</p><ul><li><strong>New:</strong> Added support for recent macOS updates.</li><ul><li>Overhauled the interface to better reflect the contemporary Mac environment.</li><li>Added stability with multiple under-the-hood improvements.</li><li>Modernized the codebase to make future work more manageable.</li><li>Fixed various issues related to macOS Sierra.</li></ul></ul><h3>Kaleidoscope 2.1.1<p>June 9 2015</p></h3><p>build 219 (Direct)</p><ul><li><strong>Note:</strong> We are working to get version 2.1.1 into the Mac App Store. For now, please <a href="http://www.kaleidoscopeapp.com/download">download</a> the direct sale version. Your purchase will carry over.</li><li>Fixed a couple issues with our Bazaar integration instructions.</li><li>⌘-D now triggers the Don't Resolve button when dismissing a merge warning.</li><li>Improved automatic graphics switching support (Early 2011 or newer MacBooks Pro): Kaleidoscope will now only use the discrete GPU when necessary.</li><li>Updated our mechanism for purchasing a Kaleidoscope registration.</li></ul><h3>Kaleidoscope 2.1<p>April 30 2014</p></h3><p>build 134 (Direct) / 133.01 (Mac App Store)</p><ul><li><strong>New Feature:</strong> Added support for ignoring whitespace (leading, trailing and line ending) in text comparisons.</li><li><strong>New Feature:</strong> Added an indicator to display remaining unresolved conflicts in a merge document.</li><li><strong>Text Scope</strong><ul><li>Added dropdown menus on either side of Choose Left/Choose Right buttons to make “Choose Both” options more discoverable.</li><li>Added better tooltips for the “Copy to” buttons when in Unified view.</li><li>Fixed various issues with Dark Theme which made text difficult to read.</li><li>Fixed issue where selecting different text scope views on one window could affect copy right/left buttons on other windows.</li><li>Fixed issue where holding option to modify the behavior of copy right/left buttons on one window could affect other windows.</li><li>Fixed issue that could prevent Kaleidoscope from picking up changes made to a document open in more than one window.</li><li>Fixed issue that could prevent Kaleidoscope from picking up changes made to documents externally, especially on the MAS build.</li></ul></li><li><strong>Folder Scope</strong><ul><li>Fixed issue where sometimes Folder Scope copies would not show up correctly after the copy had taken place.</li><li>Fixed issue where Folder Scope would not pick up external additions of empty files or directories.</li><li>Fixed issue that caused the app to reject dragging of folders to the dock icon.</li></ul></li><li><strong>Integration</strong><ul><li>Fixed issue that caused git integration to fail on 10.9 Mavericks.</li><li>Fixed issue where ksdiff was sometimes not able to connect to Kaleidoscope after reboots with window restoration enabled.</li><li>Fixed issue that where Kaleidoscope would not allow quitting when choosing “Review Conflicts” on a modified document.</li></ul></li><li><strong>General Improvements</strong><ul><li>Updated Automator actions to categorize correctly in Automator.</li><li>Added support for copy/paste shortcuts in the crash reporter window.</li><li>Kaleidoscope now avoids saving files without changes.</li><li>Kaleidoscope will now disallow edits to files that can be read but not written to (e.g. docx files).</li><li>Kaleidoscope now better remembers size and position of your windows.</li><li>Fixed issue that stopped the comparison windows from minimizing when double clicking their title bar.</li><li>Fixed issue where the path bar area could fail to update correctly when switching tabs.</li><li>Fixed issue where clicking the dock icon would not restore minimized documents.</li><li>Fixed issue where dragging a group of files that were already open in Kaleidoscope could cause issues resulting in not all new files being added.</li><li>Fixed issue that made it possible for the comparison window to grow vertically offscreen on 10.9 leaving you with a window you could not reposition afterwards.</li><li>Fixed issue that made it impossible to bring up the open dialog by clicking on an empty tab when fullscreen in 10.9.</li><li>Fixed issue where sometimes full-screen windows would not be full-screen.</li><li>Fixed small visual issues with the Ignored Files dialog window.</li><li>Fixed documentation issues with ksdiff help.</li><li>Improved Help Documentation.</li><li>Various performance and stability fixes.</li></ul></li></ul><h3>Kaleidoscope 2.0.2<p>October 23 2013</p></h3><p>build 116</p><ul><li>Improved compatibility with OS X 10.9 Mavericks</li><li>Improved stability</li></ul><h3>Kaleidoscope 2.0.1<p>February 19 2013</p></h3><p>build 114</p><ul><li><strong>Text Scope</strong><ul><li>Tweaked the visual appearance of the change count stepper in Text Scope.</li><li>Fixed the "Reset Selection" menu item in Text Scope to enable and disable properly.</li><li>The Save menu is now properly disabled when comparing text snippets.</li><li>Fixed a bug where the summary text in document titles and tabs might not properly update.</li><li>The Resolved document in Three Way Blocks now has better alignment with similar content in A and B.</li><li>Kaleidoscope can now properly diff .textClipping documents.</li></ul></li><li><strong>Folder Scope</strong><ul><li>User-defined system date formats will now be properly used.</li><li>Fixed a bug that prevented Folder Scope from having the correct keyboard focus by default.</li></ul></li><li><strong>Image Scope</strong><ul><li>Kaleidoscope now handles different color spaces more reliably in Image Scope.</li><li>Kaleidoscope now properly accounts for camera orientation when displaying images in Image Scope.</li></ul></li><li><strong>Changesets</strong><ul><li>Improved keyboard navigation in changesets.</li><li>Unsaved files will now be properly marked as dirty in changesets.</li><li>Changesets now properly select the list of files on the left when opening, allowing you to quickly review changes.</li></ul></li><li><strong>General Improvements</strong><ul><li>Direct Sale fulfillment emails will now properly activate Kaleidoscope for users with diacritics in their names.</li><li>Kaleidoscope will no longer move itself to ~/Applications if that folder exists. It will now move to /Applications in all cases.</li><li>Fixed a bug that caused temporary licenses to expire one day earlier than they should have.</li><li>Fixed a bug that caused the corner radii of windows in Full Screen to not match.</li><li>Fixed an issue that sometimes led to poor vertical alignment in the File Shelf.</li><li>Dragging files to Kaleidoscope will properly open to a comparison document and will no longer leave the launch window open in the background.</li><li>Fixed a bug that caused accessing files from the Recents list to sometimes stop working.</li><li>Improved the messaging if Kaleidoscope is unable to open a document that was previously available via AFP.</li></ul></li></ul><h3>Kaleidoscope 2.0<p>January 17, 2013</p></h3><p>build 107</p><ul><li>Resets trial period for users whose trial period expired during beta</li></ul><h3>Kaleidoscope 2.0<p>January 17, 2013</p></h3><p>build 104</p><ul><li><strong>New Feature:</strong> Added support for merging text documents using a Two-Way interface in Text Scope.</li><li><strong>New Feature:</strong> Added version control integration for merging and resolving conflicts using a Three-Way interface in Text Scope.</li><li><strong>New Feature:</strong> Folder Scope — now you can spot the differences between folders and copy files and folders between them. Double click any row to open a new comparison and look at any pair of files or folders more closely.</li><li><strong>New Feature:</strong> Kaleidoscope Snippets and Services</li><ul><li>You can now drag text and images directly into the Kaleidoscope window, or the Kaleidoscope dock icon, to create Snippets. This lets you quickly compare content without having to save and name files. Try dragging images or text directly from Safari or an email message!</li><li>Kaleidoscope now includes OS X System Services to make you more productive. They are enabled by default, but you can manually turn them On or Off in the Keyboard section of System Preferences. You can also set global keyboard shortcuts for them in the Keyboard pane of System Preferences if you want to get to these even faster.</li><li>Open in Kaleidoscope: Right click on any files or folders in Finder, and compare them in a single Kaleidoscope tab. This is the easiest way to compare folders!</li><li>Text and Image Compare: Right click on text or images and send them directly to Kaleidoscope as Snippets. Try this by selecting and right clicking on any text in TextEdit, then select “Compare Text in Kaleidoscope” from the Services menu.</li></ul><li><strong>New Feature:</strong> Clipboard Support</li><ul><li>You can use the new "Edit -&gt; Paste as File" and "File -&gt; New from Clipboard" menu items to compare directly from the Clipboard. This works similarly to the drag and drop Snippets functionality. Use this to quickly create a new comparison document or to add existing text or images to an open document.</li></ul><li><strong>New Feature:</strong> Kaleidoscope now supports resolving merge conflicts for images.</li><li><strong>New Feature:</strong> Added support for Full Screen on Lion and Mountain Lion.</li><li>Full support for Macs with Retina displays.</li><li>Substantially updated and modernized user interface.</li><li>Added support for sending arbitrary changesets and partial changsets with ksdiff.</li><li>Added support for arbitrary merges and diffs using ksdiff.</li><li>Integration with third-party tools now requires installation of the ksdiff command-line tool from the Integration …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kaleidoscope.app/release-notes">https://kaleidoscope.app/release-notes</a></em></p>]]>
            </description>
            <link>https://kaleidoscope.app/release-notes</link>
            <guid isPermaLink="false">hacker-news-small-sites-25026070</guid>
            <pubDate>Sun, 08 Nov 2020 14:44:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Collect Log for SIEM?]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25026039">thread link</a>) | @gunal2
<br/>
November 8, 2020 | https://letsdefend.io/blog/how-to-collect-log-for-siem/?q=hackernews | <a href="https://web.archive.org/web/*/https://letsdefend.io/blog/how-to-collect-log-for-siem/?q=hackernews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<h2>Log Collection</h2>



<p>It contains a basic log, time, source system and a message. For example, when we look at the content of the “/var/log/auth.log” file on an Ubuntu server, we can see the source, time and message information.</p>



<figure><img src="https://letsdefend.io/blog/wp-content/uploads/2020/11/log.png" alt="" srcset="https://letsdefend.io/blog/wp-content/uploads/2020/11/log.png 685w, https://letsdefend.io/blog/wp-content/uploads/2020/11/log-300x22.png 300w, https://letsdefend.io/blog/wp-content/uploads/2020/11/log-330x24.png 330w" sizes="(max-width: 685px) 100vw, 685px"></figure>



<p>Logs are generally collected in the following 2 ways:</p>



<ul><li>Log Agents</li><li>Agentless</li></ul>



<p>We created online lab for investigation SIEM alerts. If you are interested, you can try for free on <a href="https://letsdefend.io/" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">letsdefend.io</a></p>



<h3>Log Agents</h3>



<p>In order to implement this method, a log agent software is required. Agents often have parsing, log rotation, buffering, log integrity, encryption, conversion features. In other words, this agent software can take action on the logs it collects before forwarding them to the target.</p>



<p>For example, with the agent software, we can divide a log with “username: LetsDefend; account: Administrator” into 2 parts and forward it as:</p>



<ul><li>message1 = “username: LetsDefend”&nbsp;</li><li>message2 = “account: Administrator”</li></ul>



<p><strong>Syslog</strong></p>



<p>It is a very popular network protocol for log transfers. It can work with both UDP and TCP, and can optionally be encrypted with TLS. Some devices that support syslog: Switch, Router, IDS, Firewall, Linux, Mac, Windows devices can become syslog supported with additional software.</p>



<p>If you want to forward your log with Syslog, you will need to parsing in syslog format.</p>



<p>Syslog Format:</p>



<p>Timestamp – Source Device – Facility – Severity – Message Number – Message Text</p>



<figure><img src="https://letsdefend.io/blog/wp-content/uploads/2020/11/09fig02.gif" alt=""><figcaption><em>https://flylib.com/books/1/297/1/html/2/images/1587051583/graphics/09fig02.gif</em></figcaption></figure>



<p>Also, the maximum packet size that can be sent with Syslog UDP is 1024 bytes. For TCP it is 4096 bytes.</p>



<p><strong>3. Party Agents</strong></p>



<p>Most SIEM products have their own agent software. 3rd party agents have more capabilities than syslog because of the features they support. Some agents:</p>



<p><strong>Splunk: </strong>universal forwarder</p>



<p><strong>ArcSight</strong>: ArcSight Connectors</p>



<p>These agents are easy to integrate into SIEM and have parsing features.</p>



<p><strong>Open Source Agents</strong></p>



<p>They are generally agents that provide basic needs comfortably. However, it may not be as effective as the agent of the SIEM product itself. (Ease of installation, integration, additional features etc.)</p>



<p>Popular open source agents:</p>



<ul><li><a aria-label="undefined (opens in a new tab)" href="https://www.elastic.co/beats/" target="_blank" rel="noreferrer noopener">Beats </a></li><li><a aria-label="undefined (opens in a new tab)" href="https://nxlog.co/" target="_blank" rel="noreferrer noopener">NXLog </a></li></ul>



<h3>Agentless</h3>



<p>Agentless log sending process is sometimes preferred as there is no installation and update cost. Usually, logs are sent by connecting to the target with SSH or WMI.</p>



<p>For this method, the username and password of the log server are required, therefore there is a risk of the password being stolen.</p>



<p>Easier to prepare and manage than the agent method. However, it has limited capabilities and credentials are wrapped in the network.</p>



<h3>Manual Collection</h3>



<p>Sometimes there are logs that you cannot collect with existing agent software. For example, if you cannot read the logs of a cloud-based application with the agent, you may need to write your own script</p>



<h3>Summary</h3>



<p>As you can see, there are various ways to collect logs. These are agents and agentless. In cases where the agents on the market are not sufficient, you should write your own scripts.</p>





		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://letsdefend.io/blog/how-to-collect-log-for-siem/?q=hackernews</link>
            <guid isPermaLink="false">hacker-news-small-sites-25026039</guid>
            <pubDate>Sun, 08 Nov 2020 14:36:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Can we talk about failure?]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25025819">thread link</a>) | @mqsley
<br/>
November 8, 2020 | https://www.mquinn.online/blog/can-we-talk-about-failure | <a href="https://web.archive.org/web/*/https://www.mquinn.online/blog/can-we-talk-about-failure">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>For the longest time felt like I didn’t fail at things. I was brought up with the mindset that if something is doable, it cannot be hard. A mindset which compels you to find harder and harder challenges.</p><p>That all changed when Flex, the Techstars company I co-founded didn’t work out. It broke me.&nbsp;</p></div><div><p>What surprised me was that the network, “give first” and all of the opportunity that comes with it is great when you’re on the up but awkward, uncomfortable and at times “crickets” on the down.</p><p>Part of this I now realise is because when you’re in failure mode, you’re insufferable to everyone around you.</p><p>You carry this huge weight on your shoulders that you put on others every time you meet like a wounded animal, limping around looking to be put down.</p><p>I’m not sure if everyone has gone through this, but for me I suffered through thoughts like:<br>Will I be ever successful?<br>Will I ever be happy?<br>Will I ever have another good idea?<br>Was my idea good?<br>Can I have good Ideas?<br>Can I be good at anything?</p><p>I came to learn these can be called cognitive distortions, and the best way to stop them is to write them down and use reason and logic to disprove them.</p><p>Everyone just tells you its okay, put in their perspective, you’ll work it out - This whole experience was incredibly frustrating, how could a non founder possibly relate to the level of aspiration I had taken away from me. What is a well meaning attempt at helping often comes across as people shrugging you off.</p><p>There was a limit to what my coach could do because I convinced myself he hadn’t experienced it. How could he possibly understand what was left behind after this huge emotional debt bubble deflated.</p><p>I sought out others who’s companies had died, or who had been ousted from their own boards but it was hard to match with other failures because it was either a sufferfest of two people feeling sorry for themselves or one of you values success more than the other and you judge the others’ failure.</p><p>I didn't grieve, I tried to re-inflate the bubble inside me.</p><p>I didn’t get angry, I just wanted to get better, I just wanted to feel better without putting in the work.</p><p>I turned to reading, thinking that with over a century of modern business practices surely titans have recovered from this. Reading a gazillion business biographies, literature I now know to pop science schlop, did not help. In fact it made it worse.&nbsp;</p><p>I remember reading Lean In and it slid me into depression. How did Sheryl Sandberg career magically line up at the end? Was I on the right track? How do I get on track? Where is the track? What is the track?</p><p>I would openly talk about imposter syndrome to explain why I approached work and decisions the way I did, and came to learn that:</p><ul><li>Outside of tech many people have never heard of the concept<br></li><li>People who had, did not understand it<br></li><li>Many people thought imposter syndrome was in fact the Dunning Kruger effect and thus I was admitting to them I was a fraud.&nbsp;</li></ul><p>For me, the voices in my head eventually did die off. Normalcy came about a year later when I realised I was talking about and writing about my experiences from a perspective of wisdom rather than re-hashing scar tissue.</p><p>Serendipitously after this point, I was gifted the book - <a href="https://www.amazon.com/When-Smart-People-Fail-Rebuilding/dp/0140178112" target="_blank">When Smart People Fail </a>by another Techstars founder whose grandmother had gifted her the book after she had experienced a set back. A set back which ultimately led to the founding of her Techstars company.</p><p>Where was this book when I failed? While a subjectively unnecessary read, I read it anyway. In my personal opinion, it was probably the best thing I’ve ever read on dealing with personal failure.</p><p>I think it would have saved me months of anguish had I read it earlier, and while I truly love helping entrepreneurs and makers - my goto advice now, when someone has experienced failure and is looking for guidance is - read this book.</p><p>I think Techstars should gift this to every founder that fails, whether they leave their company, are forced out or go insolvent.</p><p>Between stories of failure, to understanding the core stages of grief that one must go through - there is something in the book for everyone.&nbsp;</p></div><div><p>Key things the book taught me:</p><ul><li>Failure is subjective to the victim</li><li>Failure has stages of grief that you must go through - if you skip any, you will experience prolonged pain. I can first hand attest to this.</li><li>If we treat success as a binary outcome, everything we sacrifice in the pursuit of success is meaningless when we fail.</li></ul><p>The third point is something I embraced over the year that followed. Clearly others think I have experience/advice/wisdom/ideas to share so there is value there and it made it all much less painful. If success is binary, those of us who don’t make it, lose many years of our lives for nothing.</p><p>This is a stance I fully reject and I thank Jen and the book for really teaching me this.</p><p>In full realisation of this final point - <a href="https://www.mquinn.online/failures.html">I’m committing to my failures in public.</a> We’ll see how long I can keep it up for, but for every project that didn’t hit the goal, the ideas that crash landed and the products that went unloved I’m keeping a record because these failures are not a waste of life, they are the stepping stones that when looking back in 20 years will all make sense.</p><p>Show me someone without failure and I’ll show you someone without learning.&nbsp;</p></div><div><p>Thanks to everyone that listened to me moan for a year about my failures.</p><p>A special thanks to fellow Techstars founder Sarah Tuneberg who gave me perspective through the journey, <span>Techstars founder&nbsp;</span>Jen Saxton who gifted me “When smart people fail” and my wife for supporting me while I put myself back together.&nbsp;</p></div></div>]]>
            </description>
            <link>https://www.mquinn.online/blog/can-we-talk-about-failure</link>
            <guid isPermaLink="false">hacker-news-small-sites-25025819</guid>
            <pubDate>Sun, 08 Nov 2020 13:54:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jaccard Similarity Coefficient and MinHash]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25025683">thread link</a>) | @arpitbbhayani
<br/>
November 8, 2020 | https://arpitbhayani.me/blogs/jaccard-minhash | <a href="https://web.archive.org/web/*/https://arpitbhayani.me/blogs/jaccard-minhash">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Set similarity measure finds its application spanning the Computer Science spectrum; some applications being - user segmentation, finding near-duplicate webpages/documents, clustering, recommendation generation, sequence alignment, and many more. In this essay, we take a detailed look into a set-similarity measure called - Jaccard's Similarity Coefficient and how its computation can be optimized using a neat technique called MinHash.</p>

<p>Jaccard Similarity Coefficient quantifies how similar two <em>finite</em> sets really are and is defined as the size of their intersection divided by the size of their union. This similarity measure is very intuitive and we can clearly see that it is a real-valued measure bounded in the interval <code>[0, 1]</code>.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/98461673-302d7180-21d4-11eb-9722-41f473c1fe84.png" alt="https://user-images.githubusercontent.com/4745789/98461673-302d7180-21d4-11eb-9722-41f473c1fe84.png"></p>
<p>The coefficient is <code>0</code> when the two sets are mutually exclusive (disjoint) and it is <code>1</code> when the sets are equal. Below we see the one-line python function that computes this similarity measure.</p>
<pre><code><span><span>def</span> <span>similarity_jaccard</span><span>(a: set, b: set)</span> -&gt; float:</span>
    <span>return</span> len(a.intersection(b)) / len(a.union(b))
</code></pre>
<h2>Jaccard Similarity Coefficient as Probability</h2>
<p>Jaccard Coefficient can also be interpreted as the probability that an element picked at random from the universal set <code>U</code> is present in both sets <code>A</code> and <code>B</code>.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/98462221-8dc3bd00-21d8-11eb-95bf-5a9267e88b97.png" alt="https://user-images.githubusercontent.com/4745789/98462221-8dc3bd00-21d8-11eb-95bf-5a9267e88b97.png"></p>
<p>Another analogy for this probability is the chances of throwing a dart and it hitting the intersection. Thus we see how we can transform the Jaccard Similarity Coefficient into a simple probability statement. This will come in very handy when we try to optimize the computation at scale.</p>
<h2>Problem at Scale</h2>
<p>Computing Jaccard Similarity Coefficient is very simple, all we require is a union operation and an intersection operation on the participating sets. But these computations go haywire when things run at scale.</p>
<p>Computing set similarity is usually a subproblem fitting in a bigger picture, for example, near-duplicate detection which finds near-duplicate articles across millions of documents. When we tokenize the documents and apply raw Jaccard Similarity Coefficient for every two combinations of documents we find that the computation will take <a href="https://mccormickml.com/2015/06/12/minhash-tutorial-with-python-code/">years</a>.</p>
<p>Instead of finding the true value for this coefficient, we can rely on an approximation if we can get a considerable speedup and this is where a technique called MinHash fits well.</p>

<p>MinHash algorithm gives us a fast approximation to the Jaccard Similarity Coefficient between any two finite sets. Instead of computing the unions and the intersections every single time, this method once creates <em>MinHash Signature</em> for each set and use it to approximate the coefficient.</p>
<h2>Computing single MinHash</h2>
<p>MinHash <code>h</code> of the set <code>S</code> is the index of the first element, from a permuted Universal Set, that is present in the set <code>S</code>. But since permutation is a computation heavy operation especially for large sets we use a hashing/mapping function that typically reorders the elements using simple math operation. One such hashing function is</p>
<p><img src="https://user-images.githubusercontent.com/4745789/98463097-f7df6080-21de-11eb-8b61-a84ff7ad85de.png" alt="https://user-images.githubusercontent.com/4745789/98463097-f7df6080-21de-11eb-8b61-a84ff7ad85de.png"></p>
<p>If <code>u</code> is the total number of elements in the Universal Set <code>U</code> then <code>a</code> and <code>b</code> are the random integers less than <code>u</code> and <code>c</code> is the prime number slightly higher than <code>u</code>.  A sample permute function could be</p>
<pre><code><span><span>def</span> <span>permute_fn</span><span>(x: int)</span> -&gt; int:</span>
    <span>return</span> (<span>23</span> * x + <span>67</span>) % <span>199</span>
</code></pre>
<p>Now that we have defined permutation as a simple mathematical operation that spits out the new row index, we can find MinHash of a set as the element that has the minimum new row number. Hence we can define the MinHash function as</p>
<pre><code><span><span>def</span> <span>minhash</span><span>(s: set)</span> -&gt; int:</span>
    <span>return</span> min([permute_fn(e) <span>for</span> e <span>in</span> s])
</code></pre>
<h2>A surprising property of MinHash</h2>
<p>MinHash has a surprising property, according to which, the probability that the MinHash of random permutation produces the same value for the two sets equals the Jaccard Similarity Coefficient of those sets.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/98463732-8229c380-21e3-11eb-9b26-04ec08bc8753.png" alt="https://user-images.githubusercontent.com/4745789/98463732-8229c380-21e3-11eb-9b26-04ec08bc8753.png"></p>
<p>The above equality holds true because the probability of MinHash of two sets to be the same is the number of elements present in both the sets divided by the total number of elements in both the sets combined; which in fact is the definition of Jaccard Similarity Coefficient.</p>
<p>Hence to approximate Similarity Coefficient using MinHash all we have to do is find the Probability of MinHash of two sets to be the same, and this is where the MinHash Signature comes in to play.</p>
<h2>MinHash Signature</h2>
<p>MinHash Signature of a set <code>S</code> is a collection of <code>k</code> MinHash values corresponding to <code>k</code> different MinHash functions. The size <code>k</code> depends on the error tolerance, keeping it higher leads to more accurate approximations.</p>
<pre><code><span><span>def</span> <span>minhash_signature</span><span>(s: set)</span>:</span>
    <span>return</span> [minhash(s) <span>for</span> minhash <span>in</span> minhash_fns]
</code></pre>
<blockquote>
<p>MinHash functions usually differ in the permutation parameters i.e. coefficients <code>a</code>, <code>b</code> and <code>c</code>.</p>
</blockquote>
<p>Now in order to compute <code>Pr[h(A) = h(B)]</code> we have to compare the MinHash Signature of the participating sets <code>A</code> and <code>B</code> and find how many values in their signatures match; dividing this number by the number of hash functions <code>k</code> will give the required probability and in turn an approximation of Jaccard Similarity Coefficient.</p>
<pre><code><span><span>def</span> <span>similarity_minhash</span><span>(a: set, b: set)</span> -&gt; float:</span>
    sign_a = minhash_signature(a)
    sign_b = minhash_signature(b)
    <span>return</span> sum([<span>1</span> <span>for</span> a, b <span>in</span> zip(sign_a, sign_b) <span>if</span> a == b]) / len(sign_a)
</code></pre>
<blockquote>
<p>MinHash Signature could well be computed just once per set.</p>
</blockquote>
<p>Thus to compute set similarity, we need not perform heavy computation like Union and Intersection and that too across millions of sets at scale, rather we can simply compare <code>k</code> items of in their signatures and get a fairly good estimate of it.</p>

<p>In order to find how close the estimate is we compute the Jaccard Similarity Coefficient and its approximate using MinHash on two disjoint sets having equal cardinality. One of the sets will undergo a transition where one element of it will be replaced with one element of the other set. So with time, the sets will go from disjoint to being equal.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/98465023-860e1380-21ec-11eb-8813-7cb6920bc1fd.png" alt="https://user-images.githubusercontent.com/4745789/98465023-860e1380-21ec-11eb-8813-7cb6920bc1fd.png"></p>
<p>The illustration above shows the two plots and we can clearly see that the MinHash technique provides a fairly good estimate of Jaccard Similarity Coefficient with much fewer computations.</p>

<ul>
<li><a href="https://en.wikipedia.org/wiki/Jaccard_index">Jaccard Index</a></li>
<li><a href="https://en.wikipedia.org/wiki/MinHash">MinHash Wikipedia</a></li>
<li><a href="https://www.researchgate.net/profile/Ekkachai_Naenudorn/publication/317248581_Using_of_Jaccard_Coefficient_for_Keywords_Similarity/links/592e560ba6fdcc89e759c6d0/Using-of-Jaccard-Coefficient-for-Keywords-Similarity.pdf">Using of Jaccard Coefficient for Keywords Similarity</a></li>
<li><a href="https://mccormickml.com/2015/06/12/minhash-tutorial-with-python-code/">MinHash Tutorial with Python Code</a></li>
</ul>
</div></div><section><div><div><p><img src="https://arpitbhayani.me/static/img/arpit.jpg"></p>  <h2>
              500+ Signups
            </h2> <p>
              If you like what you read subscribe you can always subscribe to
              my newsletter and get the post delivered straight to your inbox.
              I write
              <a href="https://arpitbhayani.me/blogs">essays</a> on various
              engineering topics and share it through my weekly
              <a href="https://arpitbhayani.me/newsletter">newsletter</a> 👇
            </p> <br> </div></div></section></div>]]>
            </description>
            <link>https://arpitbhayani.me/blogs/jaccard-minhash</link>
            <guid isPermaLink="false">hacker-news-small-sites-25025683</guid>
            <pubDate>Sun, 08 Nov 2020 13:32:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Artificial and Machine Learning in Finance]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25025512">thread link</a>) | @tosky
<br/>
November 8, 2020 | https://blog.swizel.co/artificial-and-machine-learning-in-finance-ckgns119e03dfncs11pereysu | <a href="https://web.archive.org/web/*/https://blog.swizel.co/artificial-and-machine-learning-in-finance-ckgns119e03dfncs11pereysu">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1603549835455/fClS2ugSU.jpeg?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><p>The year is 1992. In the United States, the cold war has been declared officially over and a young Bill Clinton is set to become the 42nd president of America. The space shuttle Atlantis takes off from Cape Canaveral with meteorological instruments to study global warming as the resources tied up in the costly cold war are freed for nobler pursuits. In South Africa, white citizens vote for political reforms to end apartheid, the struggle of the past two years is coming to an end. On the British Isles, the most famous speculative attack in history has been carried out on the British Pound by a group of investors masterminded by Hungarian-American financier George Soros. On ‘Black Wednesday’ 16 September 1992, investors sell massive amounts of British Pounds, expecting a devaluation- a drop in the price of the pound against other currencies. The Bank of England buys £4 billion in order to keep the demand for the pound high, but by the next day the value of the pound has fallen by more than 10%. The Bank reports a loss of £3.3 billion, a third of which George Soros gets to keep.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1603548855412/aABMN3Nsu.jpeg?auto=format&amp;q=60" alt="https___specials-images.forbesimg.com_imageserve_5f4e72bdd82a882a3012a595_0x0.jpg_background=000000&amp;cropX1=886&amp;cropX2=3035&amp;cropY1=515&amp;cropY2=2664.jpg"></p>
<p>Fast forward to 2001. The September 11 attacks have just taken place prompting the formation of four new security agencies and a war on terror that would last for over a decade.
What do these two events have in common? Two things. Firstly, they are both ‘black swan’ events. ‘Black swan’ is a termed coined by Lebanese-American statistician Nicholas Nassim Taleb to describe events that have low probabilities of happening and cannot be predicted. They usually have major effects and are often wrongly explained away by historians and analysts who have the benefit of hindsight. In other words, events that seem obvious when viewed from a perspective further in time, but are unpredictable by observers in the present. Examples include; World war 1, the dissolution of the Soviet Union, the housing crisis of 2008, and Donald Trump’s election.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1603548997001/tSn4UkG9K.jpeg?auto=format&amp;q=60" alt="donald-trump-portrait-with-silhouette-style_23-2147952267.jpg"></p>
<p>More interestingly, both of these events may not have happened today. This due to the advances being made in the prediction of rare events in the field of Machine learning. Machine learning is a branch of the Artificial intelligence discipline that automates analytical model building. A model is a simple structure that captures all the features of more complicated real-world situations.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1603549165479/1VwKMKpzR.jpeg?auto=format&amp;q=60" alt="file-20190409-2931-2n3fgx.jpg"></p>
<p>Machine learning is currently being considered in predicting future cyber-terrorist attacks, and is already being used to anticipate sudden changes in stock prices here, and here.</p>
<p>While Machine learning already has so many applications today in almost every sphere of human life; </p>
<ol>
<li>Technology (virtual assistants and self-driving cars) </li>
<li>Banking (fraud detection)</li>
<li>Marketing (adaptive online ads)</li>
</ol>
<p>A number of criticisms have yet to be addressed by proponents of machine learning in black swan event prediction such as;</p>
<ol>
<li><strong>Delusional turkeys:</strong> Algorithms predict events based on past data, which is well… from the past. This has been likened to Inductive reasoning, a generalization of which is the anecdotal turkey predicting that the farmer will not kill it, based on past data which holds up until thanksgiving.</li>
<li><strong>Fighting fire with fire:</strong> Other critics have pointed out that the stock market is very complex and responds to the actions which members take. This means that algorithms that predict what humans do right now, will eventually have to predict what other algorithms will do as more traders resort to Machine learning. Eventually those algorithms will also have to predict what other algorithms predict that other algorithms will do. The same reasoning applies to terrorist attacks. What happens when the terrorists resort to machine learning?</li>
<li><strong>The enemy within:</strong> Other critics have yet opined that machines are incapable of predicting black swan events and instead are most likely to cause one like in the 2010 flash crash. This carries greater implications in predicting terrorist attacks. Implications such as strained diplomatic relations or even war.</li>
</ol>
<p>In conclusion, while the pros and cons of machine learning have not yet been fully measured, we can only say two things with the exact minimum degree of certainty with which you might be comfortable, that machine learning will predict black swan events or that it will itself be absolved as a factor in the black hole that is the quest for the prediction of black swan events. But whatever the case, like with google maps, there is no wrong turn and there certainly is no going back now.</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.swizel.co/artificial-and-machine-learning-in-finance-ckgns119e03dfncs11pereysu</link>
            <guid isPermaLink="false">hacker-news-small-sites-25025512</guid>
            <pubDate>Sun, 08 Nov 2020 12:59:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is Software Architecture]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25025368">thread link</a>) | @DevTalker
<br/>
November 8, 2020 | https://ddimitrov.dev/2020/11/08/what-is-software-architecture/ | <a href="https://web.archive.org/web/*/https://ddimitrov.dev/2020/11/08/what-is-software-architecture/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


			
<p>In this series of posts, I will introduce you to the most popular software architecture types. But before we delve into the most common variants, let us talk about software architecture itself.</p>



<h2><strong>What is software architecture?</strong></h2>



<p>It is tough to write simply for such a complex topic as software architecture but let me try my best.</p>



<p>A software system is made up of individual elements. Elements could be databases, application servers, message brokers, load balancers, etc.</p>



<p>Each element has its properties and characteristics. Between these elements, there are relationships.</p>



<p>The way we structure these elements and their relationships, we call software architecture.</p>



<p>By defining such a structure, we aim to gain some benefits. Quality attributes define and describe these benefits, and it is essential to remember that they are not business logic related.</p>



<p>Software architecture is the skeleton of your application. Once you start implementation, it is tough to change it, so the right decision for architecture is crucial in the early phase of the project.</p>



<h2><strong>Quality attributes</strong></h2>



<p>Though quality attributes are not functionality requirements, they mainly arise from the functional requirements.&nbsp;</p>



<p>By defining requirements for a software product, the business aims to enhance some competitive advantages.</p>



<p>In the best-case scenario, quality attributes gathering should come from those competitive advantages.</p>



<p>A simple example. Back in the days, I worked in a company that wanted to develop a new retail system. The business analysis showed that most of our main competitor’s customers do not like their system because it was always online. The user couldn’t even check product stocks in case of an internet outage.</p>



<p>For our new product to be competitive in the market, we had to aim for a competitive advantage. Our system had to work offline during internet outages and sync all recorded operations when the internet is back.</p>



<p>We, developers, translated that requirement into the <strong>availability</strong> quality attribute.</p>



<p>Sometimes quality attributes don’t come from requirements. Some quality attributes are enforced by constraints. Constraints could be different, from the dev team’s experience level to government regulations.</p>



<p>And last but not least, quality attributes should be measurable and testable.</p>



<h3><strong>Some of the most popular quality attributes:</strong></h3>



<h4>Availability</h4>



<p>It defines to what level the system is available to perform its tasks. Availability expands on the notion of reliability. Systems with high availability tend to be resilient to faults and errors (well, to most of them). High availability systems implement methods for fault detection and recovery.</p>



<h4>Modifiability</h4>



<p>Modifiability defines how well a system can adapt to changes. Technologies change, business requirements change. High modifiability software should be able to embrace new changes by reducing change costs and risks.</p>



<h4>Interoperability</h4>



<p>No system can live in total isolation. Interoperability quality attribute measures to what degree a software system can “communicate” with other software systems. Systems with high interoperability tend to have very well defined interfaces and implement widely accepted standards and communication protocols.</p>



<h4>Security</h4>



<p>The security of a system could be viewed from three different angles. &nbsp;</p>



<p>Confidentiality â€“ is the data well secured from users who don’t have the right to access it.</p>



<p>Availability â€“ is the data available when needed.</p>



<p>Integrity â€“ is the data well secured, so tampering and deletion are not possible.</p>



<h4>Performance</h4>



<p>Well, performance is all about time. This quality attribute aims to put an upper execution time limit to the system’s tasks (no matter if the user or internal mechanisms initiate them).</p>



<h4>Testability</h4>



<p>Testability defines to what degree a system can be <a href="https://ddimitrov.dev/2020/10/24/how-to-write-a-good-unit-tests/">tested</a>. How well business and technical requirements can be simulated, observed, and analyzed. High testability systems provide a high level of isolation and abstraction of its modules.</p>



<h4>Usability</h4>



<p>Usability is about how easy it is for the user to perform tasks in the system.</p>



<p>Sound simple but believe me, usability is a real pain. Usability is even bigger pain when we talk about systems with very complex business logic and processes.</p>



<p>Every user comes with his own previous experience and opinions. That’s why usability is often based on compromises for the greater good ðŸ˜Š.</p>



<p>For more comprehensive list you can check <a href="https://en.wikipedia.org/wiki/List_of_system_quality_attributes" target="_blank" rel="noreferrer noopener nofollow">this</a>.</p>



<h2><strong>What is the difference between software architecture and software design?</strong></h2>



<p>While software architecture aims to define the structure and relationships of the different system elements (considering all the present constraints), the software design focuses on their specific implementation.</p>



<p>If a software architecture specifies that we will have microservices with async internal communication, the software design will define how this will be implemented.</p>



<p>Do we use RabitMQ or Mass Transit, or something other? What is the format of our messages? How will the data models reflect the bounded context we have defined? The software design answers all these questions.</p>



<h2><strong>Architecting for performance (example)</strong></h2>



<p>Let us see how a quality attribute requirement affects system architecture.</p>



<p>We have a potential client who wants a very fast (performance quality attribute) reporting system.</p>



<p>The client should make decisions fast so that the reporting system’s speed is a competitive advantage for his business.</p>



<p>Currently, the client has two different systems. He queries them when he needs some data (using their operational databases, which degrade performance additionally) and combines the extracted data in an ugly excel report.</p>



<p>Back in the days, that approach worked perfectly for him, but now, this is becoming a bottleneck when his business is much bigger.</p>



<p>Our company “Drink beer and code Ltd.” receives invite to solve the problem.</p>



<p>After a complete analysis of the case, the developers come with the solution. According to the research, they think that a report’s average execution time could be lowered to 1500 ms (yeahâ€¦).</p>



<p>At this stage, dev team will not change current systems. Either way, they work well to meet the customer’s needs, and he doesn’t want to change them.</p>



<p>The Dev team plans to deploy a new SQL Server. The server will have a new analytics database and two replicated copies of the other systems’ operational databases.</p>



<p>Operational database replication is event-based.</p>



<p>A worker service extracts the data from the replicated databases, transforms it appropriately for the analytics database, and loads it into the analytics database.</p>



<p>The analytics database design is structured and optimized for the format of the needed reports. <a href="https://ddimitrov.dev/2020/10/04/optimizing-sql-queries-sometimes-two-queries-are-better-than-one/">Querying</a> the database will be very fast.</p>



<p>Finally, we have a reporting application reading the data over the analytics database and visualizing it in beautiful tables and charts.</p>



<h2>Summary</h2>



<p>Even with that oversimplistic example, we can see that we have introduced new elements and relationships between them to meet the desired quality attribute metric.</p>



<p>We also faced the constraint that the old systems enforced over our technical decision.</p>



<p>But in the end, we achieved the desired performance and that enhanced our client’s competitive advantage.</p>
				
		</div></div>]]>
            </description>
            <link>https://ddimitrov.dev/2020/11/08/what-is-software-architecture/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25025368</guid>
            <pubDate>Sun, 08 Nov 2020 12:32:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clues to identify a destructive leader]]>
            </title>
            <description>
<![CDATA[
Score 247 | Comments 106 (<a href="https://news.ycombinator.com/item?id=25025363">thread link</a>) | @BossingAround
<br/>
November 8, 2020 | https://articles.tilt365.com/identify-destructive-leadership-patterns/ | <a href="https://web.archive.org/web/*/https://articles.tilt365.com/identify-destructive-leadership-patterns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://articles.tilt365.com/content/images/size/w300/2020/11/sharks-in-the-water-1.png 300w,
                            https://articles.tilt365.com/content/images/size/w600/2020/11/sharks-in-the-water-1.png 600w,
                            https://articles.tilt365.com/content/images/size/w1000/2020/11/sharks-in-the-water-1.png 1000w,
                            https://articles.tilt365.com/content/images/size/w2000/2020/11/sharks-in-the-water-1.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://articles.tilt365.com/content/images/size/w2000/2020/11/sharks-in-the-water-1.png" alt="4 Clues to Identify a Destructive Leader">
            </figure>

            <section>
                <div>
                    <p>In many aspects of our lives, we rely on those in positions of power to lead us. The role of leaders becomes especially salient in times of uncertainty. Throughout your life, you’ve probably seen several ways leaders can respond to challenging and ambiguous situations. A transformational leader can see the opportunities in turmoil and inspire people to follow them to a better future. On the other hand, an incompetent leader will leave you to deal with everything alone. In the worst-case scenario, a destructive leader will see the potential for self-enhancement and exploit others to maximize their gain. </p><figure><img src="https://articles.tilt365.com/content/images/2020/11/four-patterns-of-destructive-leadership.png" alt="" srcset="https://articles.tilt365.com/content/images/size/w600/2020/11/four-patterns-of-destructive-leadership.png 600w, https://articles.tilt365.com/content/images/size/w1000/2020/11/four-patterns-of-destructive-leadership.png 1000w, https://articles.tilt365.com/content/images/2020/11/four-patterns-of-destructive-leadership.png 1069w" sizes="(min-width: 720px) 720px"><figcaption>4 Clues to Identify a Destructive Leader</figcaption></figure><h3 id="people-leave-managers-not-companies-">People leave managers, not companies.</h3><p>Incompetent and destructive leaders both create negative consequences, but the distinction between the two is essential. An incompetent leader may lack the compelling charisma to engage others to follow, but we wouldn’t call someone lacking charisma actively destructive. A <a href="https://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780199755615.001.0001/oxfordhb-9780199755615-e-014">destructive leader</a> intentionally and systematically behaves in a way that violates the organization’s members and stakeholders’ best interests. The extent of damage that a destructive leader can cause often goes unnoticed until it is too late (e.g., Enron), but there are clues you can look for to help you identify destructive leaders earlier. These clues reflect behaviors and attitudes that can reveal the destructive nature of an otherwise seemingly competent leader.</p><h3 id="what-causes-destructive-leadership-patterns">What causes destructive leadership patterns?</h3><p>Everyone has some characteristics that are annoying to someone who prefers a different way of behaving and working. These characteristics are inherited in our DNA and influenced by the environment in which we grew up. The genetic influence was passed down from generation to generation and is a product of evolution that helped your ancestors survive the environments they encountered. And they can help you too, as long as they don’t become distorted from early experiences of chronic fear. </p><p>In destructive leadership, typical behavior patterns become distorted into extremes powered by the brain’s more primitive parts under such circumstances. When this happens, we are in fear-mode, and a blend of fear reactions becomes our norm. These distorted patterns become habitual, and our responses to others become unhealthy. For example, suppose we experienced excessive criticism in our early development. In that case, our ego will record a perception of being diminished by important caregivers and sense that our very survival depends on not being criticized. In this case, we may learn to strive excessively for superiority to alleviate the fear of feeling inferior in our assessment of ourselves.</p><p>While a reactive pattern like this helped us survive the precise environment we were born into, in a global world, that same pattern may not. The brain’s brilliant design constructs a set of behaviors that will ensure our survival in whatever we experience in the development years to maturity. But if we move to an entirely new environment as an adult, the patterns that served us before may not translate into helpful practices somewhere else. </p><h3 id="the-reason-anxiety-and-stress-are-at-an-all-time-high-">The reason anxiety and stress are at an all-time high.</h3><p>In the last century, this phenomenon has become even more complicated. With the advancement of technology comes exposure to human systems all over the world. Transportation enables moving to any part of the globe in a day or two. As we move about rapidly from one culture to another, we find ourselves unable to understand why we are perceived positively in one environment and the opposite in another. No wonder anxiety and stress are at an all-time high, especially for those who interact in global companies. Adaptation to other cultures becomes a necessity, making self-awareness and emotional intelligence some of the most critical skill sets of our time. </p><h3 id="first-look-for-the-underlying-intention-">First, look for the underlying intention.</h3><p>Because all human systems are imperfect, and most parents do the best they can do, many of us have traces of fear behaviors that can drive others nuts. There are a few prototypical examples of these types of behaviors, including, but not limited to </p><ul><li>The constant worrier who is always second-guessing themselves,</li><li>The storyteller who seems to live in an ideal world no one else can relate to,</li><li>The dominant driver who wants everything to go their way,</li><li>The prideful judge who doesn’t realize they can’t possibly know everything there is to know about everything. </li></ul><p>When we’re talking about destructive leadership, we’re not merely referring to annoying habits unless they have become very extreme or painfully frequent. Destructive leaders have little interest in how they are perceived, so they are rarely interested in how they could improve. </p><h3 id="destructive-leaders-are-single-mindedly-self-interested-">Destructive leaders are single-mindedly self-interested.</h3><p>Generally, healthy leaders may have annoying habits, but when you look beneath the surface, two things are different: </p><ol><li>They adopt a mindset that conveys they care about their impact on others and are willing to listen, learn, and exert the choice and character to change.</li><li>They hold a positive intention toward others and work for the good of the mission and the enterprise they serve. </li></ol><p>On the other hand, destructive leaders are either:</p><ol><li>Un-coachable because they adopt a rigid mindset that conveys they don’t care about their impact on others and will use their authority to manipulate others to bend to their will. They imply, “I am who I am, so deal with it.”</li><li>They have a hidden ulterior motive for wanting and using power to serve themselves at the expense of others, the mission, or the enterprise. </li></ol><p>So, as we lay out the four clues of destructive leaders, keep two things in mind. Do you have a hunch that they are well-intended, and are they willing to work on themselves? If the answer to both is affirmative, they are probably not destructive, but just like you and me, they are trying to serve their company and grow as best they can. In these circumstances, we can mind our own business and work on our self-improvement plan rather than thinking about how annoying they are. After all, it’s temporary unless they are genuinely destructive. And then you must do everything in your power to remove them from your company, or they could take the whole thing down. </p><h3 id="clue-1-behaviors-or-words-that-imply-i-m-kind-of-a-big-deal-">Clue 1: Behaviors or words that imply “I’m kind of a big deal!”</h3><p><strong>Excessive fabrication and exaggeration that is nowhere near the truth. </strong></p><p>This destructive pattern arises from an inner identity that seeks to resolve a childhood dilemma about not getting enough attention from caregivers, so they do not feel special. This dilemma results in insatiable attention-seeking and an inflated need to be special, unique, or novel. The inner fear is feeling trapped in the loneliness or sadness of not being “special” enough to those who matter. Because they perceive being attention-deprived or unworthy, they feel shame, and it becomes so painful, they rebel from authority figures whom they believe could not be trusted. Instead of following appropriately, they become rebellious and provocative, conning others to go along with their fantastic plans. </p><h3 id="clues-you-will-notice-">Clues you will notice: </h3><ul><li>Exaggeration of the truth to the point of fantasy</li><li>Unapologetic self-promoting and self-aggrandizing</li><li>Excessive talking to dominate others</li><li>Pontification and fabrication of elaborate stories</li><li>Disrespect for authority figures</li><li>Disregard for rules that are contrary to their aims</li><li>Automatically dismiss ideas from others</li><li>An insatiable need to be the center of attention</li><li>Terminally individualistic, unique, or novel</li><li>External image is unusually extreme in some way</li></ul><h3 id="results-in-a-chaotic-climate">Results in a Chaotic Climate</h3><p>These destructive leaders are challenging to work with because they demand attention but don’t want the restrictions that come with being front and center. When they are in the limelight, it can be exceedingly uncomfortable because they also unconsciously fail to believe they are impressive enough. So they attract attention, initiate excessive activity, and then thwart the attention this draws. This pattern makes them unpredictable, so the shadow of the climate they create around them is chaotic and confusing for others. </p><h3 id="clue-2-behaviors-or-words-that-imply-none-of-this-is-my-fault-">Clue 2: Behaviors or words that imply “None of this is my fault!”</h3><p><strong>Excessive conflict-avoidance by deflecting personal responsibility. </strong></p><p>This destructive pattern arises from an inner identity that seeks to resolve a childhood dilemma about not getting enough approval and acceptance. This dilemma results in insatiable approval-seeking and an excessive need to be liked by everyone, even strangers. The inner fear is to be rejected or ridiculed by others as unlovable by those who matter. Because they perceive being unacceptable to others, they feel powerless and unworthy of care. This experience can become painful and they are unable to communicate or ask others for what they need because they don’t feel they deserve it. They defer to those in authority roles and suffer quietly in dependence, hopelessness, and seen as “needy” for any shred of approval. </p><h3 id="clues-you-will-notice--1">Clues you will notice:</h3><ul><li>Complaining, blaming, gossiping about others</li><li>Disgruntled resentment of those in authority</li><li>Giving up their power and being dependent on others</li><li>Come across as “needy” and draining</li><li>Asking others to decide and then resenting it</li><li>Avoiding leadership to avoid culpability later</li><li>Unconsciously inviting others to dominate them</li><li>Blaming others for being the “bully”</li><li>Desire to be the “nice” or “good” one</li><li>An insatiable need to be liked, accepted, included</li></ul><h3 id="results-in-a-conflict-averse-climate">Results in a Conflict Averse Climate </h3><p>These destructive leaders are challenging to work with because they put extreme energy into taking care of or helping others with an unstated expectation that there will be a reward in return. For example, they take care of someone with the expectation that the other person will take the responsibility of making decisions for them. However, they may not tell the other person this expectation. There is an unconscious …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://articles.tilt365.com/identify-destructive-leadership-patterns/">https://articles.tilt365.com/identify-destructive-leadership-patterns/</a></em></p>]]>
            </description>
            <link>https://articles.tilt365.com/identify-destructive-leadership-patterns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25025363</guid>
            <pubDate>Sun, 08 Nov 2020 12:30:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clojure: Going Faster Than TensorFlow on the GPU (GTX 1080Ti)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25025262">thread link</a>) | @tosh
<br/>
November 8, 2020 | https://dragan.rocks/articles/20/Going-faster-than-Tensorflow-on-GPU-with-Clojure | <a href="https://web.archive.org/web/*/https://dragan.rocks/articles/20/Going-faster-than-Tensorflow-on-GPU-with-Clojure">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
You can <a href="https://www.patreon.com/posts/22476035">adopt a pet function!</a>
Support my work <a href="https://patreon.com/draganrocks">on my Patreon page</a>, and access my <a href="https://www.patreon.com/posts/im-ditching-and-22476348">dedicated discussion server</a>. Can't afford to <a href="https://patreon.com/draganrocks">donate</a>? Ask for a free invite.
<p>November 2, 2020</p>
<p>
    Please share: .
</p>

<p>
    <a href="https://aiprobook.com/">New books are available for subscription.</a>
    </p><p><a href="https://aiprobook.com/deep-learning-for-programmers">
            <img src="http://aiprobook.com/img/dlfp-cover.png">
        </a>
        <a href="https://aiprobook.com/numerical-linear-algebra-for-programmers">
            <img src="http://aiprobook.com/img/lafp-cover.png">
        </a>
    </p>


<p>
A few weeks ago I've shown you how simple Clojure's
<a href="https://github.com/uncomplicate/deep-diamond">Deep Diamond</a>() is, even compared to Keras. I've also mentioned
that it's superfast. Here's how fast it is on the GPU!
</p>

<div id="outline-container-orgc0a2ae3">
<h2 id="orgc0a2ae3">TL;DR Much faster than Keras+TensorFlow on the GPU, too!</h2>
<div id="text-orgc0a2ae3">
<p>
In the <a href="https://dragan.rocks/articles/20/Going-faster-than-TensorFlow-with-Clojure">previous article</a>, we have only compared the libraries on the CPU.
Deep Diamond was considerably faster: 368 seconds vs 509 seconds. Most readers were intrigued,
but, being skeptical as they should be, they complained that CPU performance doesn't matter
anyway, since everybody uses GPU for training convolution networks;
let's do the GPU comparison then.
</p>

<p>
Both Deep Diamond, and Keras with TensorFlow, use <a href="https://developer.nvidia.com/cudnn">Nvidia's cuDNN</a> low level performance
library under the hood, and any difference is due to the higher-level implementation.
</p>

<p>
Deep Diamond completes this training in <b>21</b> seconds while Keras + TensorFlow takes <b>35</b> seconds.
The gap even increased in favor of Deep Diamond! Now the ratio is <b>1.67</b>, in place of 1.38 on the CPU.
</p>
</div>
</div>

<div id="outline-container-org0601d75">
<h2 id="org0601d75">Keras CNN in Python</h2>
<div id="text-org0601d75">
<p>
I repeat the relevant model code for reference. We're
interested in the running time of <code>model.fit</code>, with minimal verbosity,
for 12 epochs. I'm using Nvidia's GTX 1080Ti GPU. Keras code is taken from official Keras examples.
</p>

<div>
<pre>model = Sequential<span>()</span>
model.add<span>(</span>Conv2D<span>(</span>32, kernel_size=<span>(</span>3, 3<span>)</span>,
                 activation='relu',
                 input_shape=<span>(</span>28, 28, 1<span>)</span><span>)</span><span>)</span>
model.add<span>(</span>Conv2D<span>(</span>64, <span>(</span>3, 3<span>)</span>, activation='relu'<span>)</span><span>)</span>
model.add<span>(</span>MaxPooling2D<span>(</span>pool_size=<span>(</span>2, 2<span>)</span><span>)</span><span>)</span>
model.add<span>(</span>Dropout<span>(</span>0.25<span>)</span><span>)</span>
model.add<span>(</span>Flatten<span>()</span><span>)</span>
model.add<span>(</span>Dense<span>(</span>128, activation='relu'<span>)</span><span>)</span>
model.add<span>(</span>Dropout<span>(</span>0.5<span>)</span><span>)</span>
model.add<span>(</span>Dense<span>(</span>num_classes, activation='softmax'<span>)</span><span>)</span>

model.compile<span>(</span>loss=keras.losses.categorical_crossentropy,
              optimizer=Adam<span>(</span>learning_rate=0.01<span>)</span>,
              metrics=<span>[</span>'accuracy'<span>]</span><span>)</span>

s = time.time_ns<span>()</span>
model.fit<span>(</span>x_train, y_train,
          batch_size=128,
          verbose=2,
          epochs=12<span>)</span>
e = time.time_ns<span>()</span>
print<span>(</span><span>(</span>e-s<span>)</span>/<span>(</span>10**9<span>)</span>, <span>" seconds"</span><span>)</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-org7c1e24e">
<h2 id="org7c1e24e">Deep Diamond CNN in Clojure</h2>
<div id="text-org7c1e24e">
<p>
In Clojure, we're measuring the runtime of the <code>train</code> function.
</p>

<div>
<pre><span>(</span><span>defonce</span> <span>net-bp</span>
  <span>(</span>network <span>(</span>desc <span>[</span>128 1 28 28<span>]</span> <span>:float</span> <span>:nchw</span><span>)</span>
           <span>[</span><span>(</span>convo <span>[</span>32<span>]</span> <span>[</span>3 3<span>]</span> <span>:relu</span><span>)</span>
            <span>(</span>convo <span>[</span>64<span>]</span> <span>[</span>3 3<span>]</span> <span>:relu</span><span>)</span>
            <span>(</span>pooling <span>[</span>2 2<span>]</span> <span>:max</span><span>)</span>
            <span>(</span>dropout<span>)</span>
            <span>(</span>dense <span>[</span>128<span>]</span> <span>:relu</span><span>)</span>
            <span>(</span>dropout<span>)</span>
            <span>(</span>dense <span>[</span>10<span>]</span> <span>:softmax</span><span>)</span><span>]</span><span>)</span><span>)</span>

<span>(</span><span>defonce</span> <span>net</span> <span>(</span>init! <span>(</span>net-bp <span>:adam</span><span>)</span><span>)</span><span>)</span>

<span>(</span>time <span>(</span>train net train-images y-train <span>:crossentropy</span> 12 <span>[]</span><span>)</span><span>)</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-orgf9c6799">
<h2 id="orgf9c6799">The books</h2>
<div id="text-orgf9c6799">
<p>
The book <a href="https://aiprobook.com/deep-learning-for-programmers/">Deep Learning for Programmers: An Interactive Tutorial with
CUDA, OpenCL, DNNL, Java, and Clojure</a> teaches the nuts and bolts of neural networks and deep learning
by showing you how Deep Diamond is built, <b>from scratch</b>, in interactive sessions. Each line of code
can be executed and the results inspected in the plain Clojure REPL. The best way to master something is to build
it yourself!
</p>

<p>
It' simple. But fast and powerful!
</p>

<p>
Please subscribe, read the drafts, get the full book soon, and support my work on this free open source library.
</p>
</div>
</div>


    </article></div>]]>
            </description>
            <link>https://dragan.rocks/articles/20/Going-faster-than-Tensorflow-on-GPU-with-Clojure</link>
            <guid isPermaLink="false">hacker-news-small-sites-25025262</guid>
            <pubDate>Sun, 08 Nov 2020 12:14:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing Terraform, but with TypeScript]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25025186">thread link</a>) | @juliankrispel
<br/>
November 8, 2020 | https://jkrsp.com/writing-terraform-with-typescript/ | <a href="https://web.archive.org/web/*/https://jkrsp.com/writing-terraform-with-typescript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>You may or may not have heard about the release of the <a href="https://github.com/hashicorp/terraform-cdk">terraform cdk</a> (short for cloud development kit). It’s HashiCorps answer to the aws cdk. In the words of the projects readme:</p>
<blockquote>
<p>CDK (Cloud Development Kit) for Terraform allows developers to use familiar programming languages to define cloud infrastructure and provision it through HashiCorp Terraform.</p>
</blockquote>
<p>Let’s try this out shall we?</p>
<p>To get the full developer experience, make sure you have <a href="https://github.com/Microsoft/TypeScript/wiki/TypeScript-Editor-Support">typescript support installed for your IDE</a></p>
<p><span>
      <a href="https://jkrsp.com/static/006a51697ab63c90c57788793394fd25/00172/cover.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="autocomplete-terraform" title="autocomplete-terraform" src="https://jkrsp.com/static/006a51697ab63c90c57788793394fd25/fcda8/cover.png" srcset="https://jkrsp.com/static/006a51697ab63c90c57788793394fd25/12f09/cover.png 148w,
https://jkrsp.com/static/006a51697ab63c90c57788793394fd25/e4a3f/cover.png 295w,
https://jkrsp.com/static/006a51697ab63c90c57788793394fd25/fcda8/cover.png 590w,
https://jkrsp.com/static/006a51697ab63c90c57788793394fd25/efc66/cover.png 885w,
https://jkrsp.com/static/006a51697ab63c90c57788793394fd25/00172/cover.png 1044w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h3>Generating the boilerplate</h3>
<p>Let’s open our terminal and install install cdktf-cli:</p>

<p>Next we’ll initialize the project</p>
<div data-language="bash"><pre><code><span>mkdir</span> hello-cdktf
<span>cd</span> hello-cdktf
cdktf init --template<span>=</span><span>"typescript"</span> --local</code></pre></div>
<p>Answer the two configuration questions and the project boilerplate will be generated.</p>
<p>Now we should see a <code>main.ts</code> file with the following contents in our folder:</p>
<div data-language="ts"><pre><code><span>import</span> <span>{</span> Construct <span>}</span> <span>from</span> <span>'constructs'</span><span>;</span>
<span>import</span> <span>{</span> App<span>,</span> TerraformStack <span>}</span> <span>from</span> <span>'cdktf'</span><span>;</span>

<span>class</span> <span>MyStack</span> <span>extends</span> <span>TerraformStack</span> <span>{</span>
  <span>constructor</span><span>(</span>scope<span>:</span> Construct<span>,</span> name<span>:</span> <span>string</span><span>)</span> <span>{</span>
    <span>super</span><span>(</span>scope<span>,</span> name<span>)</span><span>;</span>

    

  <span>}</span>
<span>}</span>

<span>const</span> app <span>=</span> <span>new</span> <span>App</span><span>(</span><span>)</span><span>;</span>
<span>new</span> <span>MyStack</span><span>(</span>app<span>,</span> <span>'hello-cdktf2'</span><span>)</span><span>;</span>
app<span>.</span><span>synth</span><span>(</span><span>)</span><span>;</span></code></pre></div>
<h3>Adding a provider package and importing modules from it</h3>
<p>After generation finishes you’ll see a message in the console listing instructions of what to do next. To add the prebuilt aws provider (which also gives us all the modules and types that we might want).</p>
<div data-language="bash"><pre><code><span>npm</span> <span>install</span> -a @cdktf/provider-aws</code></pre></div>
<p>Now you can import modules from <code>@cdktf/provider-aws</code> such as <code>AwsProvider</code> and others. We’ll go for the <code>AwsProvider</code>, <code>LambdaFunction</code> and <code>IamRole</code>. Add this at the top of your file:</p>
<div data-language="ts"><pre><code><span>import</span> <span>{</span> AwsProvider<span>,</span> LambdaFunction<span>,</span> IamRole <span>}</span> <span>from</span> <span>'@cdktf/provider-aws'</span><span>;</span></code></pre></div>
<p>and then create an AwsProvider in your stack:</p>
<div data-language="ts"><pre><code><span>new</span> <span>AwsProvider</span><span>(</span><span>this</span><span>,</span> <span>'aws'</span><span>,</span> <span>{</span>
  region<span>:</span> <span>'eu-west-2'</span>
<span>}</span><span>)</span></code></pre></div>
<h3>Adding a lambda function to our stack</h3>
<p>To create a lambda we need to define an IAM role at first. Boring, but made easier by autocomplete of cours. Anyway here’s the default policy:</p>
<div data-language="ts"><pre><code><span>const</span> roleForLambda <span>=</span> <span>new</span> <span>IamRole</span><span>(</span><span>this</span><span>,</span> <span>'iam-role-for-lambda'</span><span>,</span> <span>{</span>
  name<span>:</span> <span>'iam-role-for-lambda'</span><span>,</span>
  assumeRolePolicy<span>:</span> <span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span>
    <span>"Version"</span><span>:</span> <span>"2012-10-17"</span><span>,</span>
    <span>"Statement"</span><span>:</span> <span>[</span>
      <span>{</span>
        <span>"Action"</span><span>:</span> <span>"sts:AssumeRole"</span><span>,</span>
        <span>"Principal"</span><span>:</span> <span>{</span>
          <span>"Service"</span><span>:</span> <span>"lambda.amazonaws.com"</span>
        <span>}</span><span>,</span>
        <span>"Effect"</span><span>:</span> <span>"Allow"</span>
      <span>}</span>
    <span>]</span>
  <span>}</span><span>)</span>
<span>}</span><span>)</span></code></pre></div>
<p>Now we can add a lambda function to the stack like this:</p>
<div data-language="typescript"><pre><code><span>new</span> <span>LambdaFunction</span><span>(</span><span>this</span><span>,</span> <span>'hello-world'</span><span>,</span> <span>{</span>
  filename<span>:</span> process<span>.</span><span>cwd</span><span>(</span><span>)</span> <span>+</span> <span>'hello-world.zip'</span>
  functionName<span>:</span> <span>'hello-world'</span><span>,</span>
  handler<span>:</span> <span>'index.handler'</span><span>,</span>
  runtime<span>:</span> <span>'nodejs12.x'</span><span>,</span>
  role<span>:</span> roleForLambda<span>.</span>arn<span>,</span>
<span>}</span><span>)</span></code></pre></div>
<p>You will need to zip your lambda function - which is usually a separate step before running terraform. For example sake, let’s say you have a file in your project named <code>hello-world.js</code>:</p>
<div data-language="js"><pre><code><span>export</span> <span>const</span> <span>handler</span> <span>=</span> <span>async</span> <span>function</span> <span>(</span><span>)</span> <span>{</span>
  <span>return</span> <span>{</span> hello<span>:</span> world <span>}</span>
<span>}</span></code></pre></div>
<p>Then zip your lambda <code>zip -r lambda.zip hello-world.js</code></p>
<h3>Deploying your stack</h3>
<p>Before you deploy don’t forget need to <a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html">have your aws credentials in your path</a>.</p>
<p>Now that you have everything ready you can deploy your stack with <code>cdktf deploy</code>. This command will display an execution plan and ask you if you want to deploy. Press the <code>Y</code> and <code>Enter</code> key to deploy.</p>
<p>Any errors at this stage should be farely self-explanatory. If they don’t make sense, google the error message - other people have likely run into the same problem.</p>
<hr>
<p>If you’re a terraform user and you’ve used the <code>lambda_function</code> module before, you’ll notice that the configuration is exactly the same.</p>
<p>Ultimately, when you run <code>cdktf synth</code> cdktf compiles your javascript/typescript modules into terraforms alternative <a href="https://www.terraform.io/docs/configuration/syntax-json.html"><code>JSON</code> configuration syntax</a>.</p>
<p>This is an extremely powerful feature of terraform’s design since it can be a compile target not just for javascript and typescript, but any kind of language. The open source community could add it’s own language compilers.</p>
<p>Why not write one in rust? 😅</p></section></div>]]>
            </description>
            <link>https://jkrsp.com/writing-terraform-with-typescript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25025186</guid>
            <pubDate>Sun, 08 Nov 2020 12:00:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“Only a Woman If You Have Breasts? That's Nonsense”]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25024715">thread link</a>) | @Tomte
<br/>
November 8, 2020 | https://www.spiegel.de/international/zeitgeist/a-personal-experience-with-breast-cancer-only-a-woman-if-you-have-breasts-that-s-nonsense-a-88da903d-2aa5-428b-99d6-a4fc4ce28a68 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/zeitgeist/a-personal-experience-with-breast-cancer-only-a-woman-if-you-have-breasts-that-s-nonsense-a-88da903d-2aa5-428b-99d6-a4fc4ce28a68">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="true">


</section>
<section>
<div>
<section>
<p><em>NOTE TO OUR READERS: Journalist Hajo Schumacher, who conducted this interview, and former politician Silvana Koch-Mehrin have known each other for many years. It is on the basis of this mutual trust that Koch-Mehrin responded to the questions that many of our readers found to be impertinent and unsettling. We apologize for not having been clear about their rapport from the very beginning.</em></p>
</section>


<section>
<p><strong>DER SPIEGEL:</strong> Ms. Koch-Mehrin, you were diagnosed with breast cancer last fall. How are you doing today?</p><p><strong>Koch-Mehrin:</strong> I'm doing well, thank you. I feel healthy. And the prognoses look good; it will likely stay that way.</p><p><strong>DER SPIEGEL:</strong> What physical and psychological effects did your experience leave you with.</p><p><strong>Koch-Mehrin:</strong> So much has changed that "leave" is the wrong word. Cancer diagnosis, mastectomy, chemo and radiation therapy: It is an existential experience. Very little is like it was before, both physically and psychologically. But it's not worse, just different.</p><p><strong>DER SPIEGEL:</strong> Can you give us an example?</p>
</section>


<section>
<p><strong>Koch-Mehrin:</strong> The side effects I experienced from chemo included a runny and bloody nose, my eyes would tear up and I had to constantly clear my throat. Picking up and holding small things became difficult and I experienced a loss of feeling in my fingertips. My hair, eyebrows and eyelashes fell out. "Before," I took those things, and the ability to do things, for granted. Now, I see it as a gift.</p><p><strong>DER SPIEGEL:</strong> Describe the moment when you received your diagnosis.</p><p><strong>Koch-Mehrin:</strong> I can precisely recall every detail - the vase on the table, the pictures and books on the shelf. I was in the United States for work and was sitting in a friend's office when my doctor called me: cancer. It was a shock because I felt so healthy. I thought it was just my normal annual checkup. Simply uttering the sentence "I have cancer" sounded to me like "I am dying." Still, even after the telephone call, I went to all of the meetings on my schedule. I was like a robot, which is probably a protective mechanism. The doctor's optimism helped me a great deal in getting over the shock. I can only urge all women, even if you're under 50, to please get screened regularly. The stage at which cancer is discovered makes a huge difference.</p>
</section>

<section>
<p><strong>DER SPIEGEL:</strong> Is breast cancer more taboo than other varieties of cancer?</p><p><strong>Koch-Mehrin:</strong> When people learn from somebody that he or she has cancer, they often fall silent. They don't know what to say. And how should they? "You'll be fine" sounds rather desperate and doesn't help the person who is sick. We live in a society that suppresses things: We still ignore illness and death far too often. Because of that, many women remain silent about their breast cancer diagnosis. On the one hand, they do so because they themselves are shaken up, but also because they want to spare others from having to talk about something they simply can't talk about.</p>
</section>

<section>
<p><strong>DER SPIEGEL:</strong> You were long seen as a kind of superwoman during your political career with the liberal Free Democrats (FDP), combining career and family, with never a hair out of place. You were also fond of playing that role. How has breast cancer changed your feeling of femininity?</p><p><strong>Koch-Mehrin:</strong> Do I hear the male perspective seeping through? Long hair on the head and no hair on the legs? Only a woman if you have breasts? That's nonsense. Take a look at the self-confident women at #goingflat or #onebreastpride. That is a kind of femininity that has nothing to do with conventions. I admire it.</p><p><strong>DER SPIEGEL:</strong> You haven't given an interview for nine years. Are you considering a return to politics?</p><p><strong>Koch-Mehrin:</strong> If I wanted to return to politics, I certainly wouldn't do so with an interview. My focus is elsewhere entirely. I decided to do this interview to address the silence surrounding cancer and to encourage openness in dealing with serious illnesses.</p><p><strong>DER SPIEGEL:</strong> What did you find particularly helpful during the most difficult times?</p><p><strong>Koch-Mehrin:</strong> I was overwhelmed by the readiness to help, the warmth and the empathy I experienced from family and friends, but also from people whom I hardly knew. My husband and brother shaved their hair off in solidarity. Particularly in moments of despondence, I found it encouraging to hear about how open other women were about their illness.</p><p><strong>DER SPIEGEL:</strong> How great is the danger of remission?</p><p><strong>Koch-Mehrin:</strong> There isn't a single day when I don't think of cancer. The statistical improbability of remission is certainly reassuring, but every checkup sets me off on an emotional rollercoaster.</p><p><strong>DER SPIEGEL:</strong> How did you tell your daughters about your diagnosis?</p><p><strong>Koch-Mehrin:</strong> I was open and honest with them because I wanted them to continue trusting me.</p><p><strong>DER SPIEGEL:</strong> What were the most difficult moments?</p>
</section>
<blockquote>

<div>
<p>"I wanted to be strong for my children."</p>
</div>

</blockquote>
<section>
<p><strong>Koch-Mehrin:</strong> The first and last chemotherapy sessions were extremely challenging. At the first one, I was so afraid of the side effects that I almost went crazy. By the last session, my mental strength was almost completely used up. I didn't want to do it anymore. I was only able to make it through because I wanted to be strong for my children.</p><p><strong>DER SPIEGEL:</strong> What aspects of the experience did you underestimate?</p><p><strong>Koch-Mehrin:</strong> That it is a marathon. The treatment goes on for so long, it was almost nine months for me, and it is difficult. And afterwards, it still isn't over. A small example: fingernails take months to grow back normally. And I will be facing regular follow-up appointments for the next 10 years. Plus, some side effects are permanent.</p><p><strong>DER SPIEGEL:</strong> What were the most important lessons you learned?</p><p><strong>Koch-Mehrin:</strong> For the first time in my life, I really became acquainted with fear. And I had to learn how to deal with it. It's easy for me to say, but it's not easy to do.</p><p><strong>DER SPIEGEL:</strong> Whether you wanted to or not, you fulfilled the classic stereotypes of the blond during your political career. What was it like to be bald and have to wear a wig?</p><p><strong>Koch-Mehrin:</strong> I missed these kinds of questions so much …</p><p><strong>DER SPIEGEL:</strong> … it is my pleasure.</p><p><strong>Koch-Mehrin:</strong> Promoting clichés is apparently still part of the standard repertoire of journalism. The virologist Sandra Ciesek is a token woman at the side of Christian Drosten, of course. In the Reykjavik Index, which measures the influence stereotypes have on opinions, Germany doesn't do particularly well. Such questions, which subconsciously strengthen prejudices, contribute to that.</p><p><strong>DER SPIEGEL:</strong> Fine, but you were pretty good at the blond game. You knew very well that in a male-dominated party such as the FDP, you got a lot of attention and that you wouldn't have risen through the ranks so quickly if you had been a man. That is exactly why those who were envious of you abandoned you in 2011 and were happy to see you fall. Did your illness change any of your political positions?</p><p><strong>Koch-Mehrin:</strong> Everyone should have access to first-class health care, irrespective of how much money they have. COVID-19 has made us all realize how vulnerable we are.</p><p><strong>DER SPIEGEL:</strong> You sound like the Social Democratic health expert Karl Lauterbach.</p><p><strong>Koch-Mehrin:</strong> Take a look at what (Free Democrat) Daniel Bahr proposed back when he was health minister: a legally mandated health-care system rooted in liberalism. It was an intelligent and affordable program that put the focus on the patient.</p><p><strong>DER SPIEGEL:</strong> Do you miss the FDP?</p><p><strong>Koch-Mehrin:</strong> Some fellow party members became real friends of mine, and I've stayed in touch with a lot of them, even if most are no longer active in politics. I am still convinced that Germany needs a strong liberal party. But I am no longer engaged in party politics. Today, I work with and for women politicians around the world in a strictly non-partisan manner. I am head of Women Political Leaders, a foundation which aims at increasing both the number and the influence of women in politics.</p><p><strong>DER SPIEGEL:</strong> Will you vote for the FDP in the general election next year?</p><p><strong>Koch-Mehrin:</strong> I will always vote for a liberal party.</p><p><strong>DER SPIEGEL:</strong> Many cancer patients look for reasons why they fell ill, whether it be stress or an unhealthy lifestyle. What explanation did you come up with?</p>
</section>
<blockquote>

<div>
<p>"The most important thing is that the women in question feel good about the decision they make, and not whether others like it or not."</p>
</div>

</blockquote>
<section>
<p><strong>Koch-Mehrin:</strong> It is pretty much impossible to not search for potential causes. There have been huge advances in treatments and cures for breast cancer, but the "why" question has never been adequately answered. The pill is a blessing, because it provides women with self-determination. But I'm not the only one furious at the fact that even 50 years after the pill's introduction, hormones are the focus of contraception, even though the correlation with breast cancer is clear and proven. The focus must be more squarely on women's health.</p><p><strong>DER SPIEGEL:</strong> The Reykjavik Global Forum, which is organized by your foundation every year, recognizes initiatives that are important for women. This year, the prize has been awarded to the pink ribbon, the symbol for the fight against breast cancer. Why?</p><p><strong>Koch-Mehrin:</strong> The pink ribbon, which was introduced exactly 30 years ago, is now a global symbol of the fight against breast cancer. Because women - and now also men – have joined together around the world for the fight, it has been a huge success story. Many women are now able to survive breast cancer because it has been possible to destigmatize the illness, collect donations, finance research and improve treatments. That is what we are recognizing. Prize recipients are the American Nancy Brinker, the first to use the pink ribbon back in the 1990s, and Vigdís Finnbogadóttir of Iceland, a breast cancer survivor and activist in addition to being the first female head of state in the world.</p><p><strong>DER SPIEGEL:</strong> The Berlin-based music journalist Anja Caspary is extremely open about her double mastectomy, not shying away from wearing tight tops in public, which confuses some. What do you think about her confrontational strategy?</p><p><strong>Koch-Me…</strong></p></section></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/zeitgeist/a-personal-experience-with-breast-cancer-only-a-woman-if-you-have-breasts-that-s-nonsense-a-88da903d-2aa5-428b-99d6-a4fc4ce28a68">https://www.spiegel.de/international/zeitgeist/a-personal-experience-with-breast-cancer-only-a-woman-if-you-have-breasts-that-s-nonsense-a-88da903d-2aa5-428b-99d6-a4fc4ce28a68</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/zeitgeist/a-personal-experience-with-breast-cancer-only-a-woman-if-you-have-breasts-that-s-nonsense-a-88da903d-2aa5-428b-99d6-a4fc4ce28a68</link>
            <guid isPermaLink="false">hacker-news-small-sites-25024715</guid>
            <pubDate>Sun, 08 Nov 2020 10:31:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One Week of NixOS]]>
            </title>
            <description>
<![CDATA[
Score 238 | Comments 153 (<a href="https://news.ycombinator.com/item?id=25024639">thread link</a>) | @jaemoe
<br/>
November 8, 2020 | https://jae.moe/blog/2020/11/one-week-of-nixos/ | <a href="https://web.archive.org/web/*/https://jae.moe/blog/2020/11/one-week-of-nixos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <h4>One week of NixOS</h4><p>
            Reading time: 4 minutes.
            </p><p>As you may have seen I on Mastodon, I am testing NixOS for over a week now and here is a few comments about how the distro works and what doesn’t work for me.</p>










<p>First, everything is NixOS is declared in a configuration file located at <code>/etc/nixos/configuration.nix</code> where you declare packages you want to install, services to start, udev rules, ECT, you get it.</p>
<p>This is the first very weird thing as you don’t really install packages with the CLI directly (even if you can), instead you modify the config file and rebuild the system with <code>nixos-rebuild switch</code>.</p>
<p>NixOS is made in such a way that everything aims to be reproducible. An example: if you want to get the exact same setup as I have, you can just take <a href="https://forge.tedomum.net/jae/nixos-configs">my configs repo</a>, clone it on your NixOS installation, run <code>nixos-rebuild switch</code> and voilà, you will have the exact same programs as me installed in the same way with the same version (roughly).</p>
<p>In this distro, adding a user is really easy and goes like this:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span></code></pre></td>
<td>
<pre><code data-lang="nixos"><span>{</span> <span>config</span><span>,</span> <span>pkgs</span><span>,</span> <span>...</span> <span>}:</span>

<span>{</span>

    <span>users</span><span>.</span><span>groups</span><span>.</span><span>plugdev</span> <span>=</span> <span>{};</span>

    <span>users</span><span>.</span><span>users</span><span>.</span><span>jae</span> <span>=</span> <span>{</span>
        <span>isNormalUser</span> <span>=</span> <span>true</span><span>;</span>
        <span>extraGroups</span> <span>=</span> <span>[</span> <span>"wheel"</span> <span>"docker"</span> <span>"adbusers"</span> <span>"plugdev"</span> <span>];</span>
        <span>shell</span> <span>=</span> <span>pkgs</span><span>.</span><span>zsh</span><span>;</span>
        <span>packages</span> <span>=</span> <span>with</span> <span>pkgs</span><span>;</span> <span>[</span>
            <span># Games</span>
            <span>minetest</span> <span>stepmania</span> <span>lutris-free</span> <span>pcsx2</span>
            <span># Misc audio / video / image</span>
            <span>pulseeffects</span> <span>ffmpeg-full</span> <span>obs-studio</span> <span>inkscape</span> <span>krita</span>
            <span># Useful software</span>
            <span>mumble</span> <span>qbittorrent</span> <span>libreoffice</span> <span>ledger-live-desktop</span>
            <span># Dev</span>
            <span>jetbrains</span><span>.</span><span>idea-community</span> <span>lazygit</span> <span>gnome3</span><span>.</span><span>zenity</span> <span>insomnia</span> <span>jetbrains</span><span>.</span><span>rider</span> <span>mono</span> <span>msbuild</span> <span>dotnet-sdk_3</span> <span>ganttproject-bin</span> <span>kubectx</span>
            <span># SDR</span>
            <span>rtl-sdr</span> <span>gqrx</span> <span>gpredict</span> <span>noaa-apt</span> <span>welle-io</span>
        <span>];</span>
    <span>};</span>
    <span>users</span><span>.</span><span>extraGroups</span><span>.</span><span>vboxusers</span><span>.</span><span>members</span> <span>=</span> <span>[</span> <span>"jae"</span> <span>];</span>
<span>}</span></code></pre></td></tr></tbody></table>
</div>
</div>
<p>Let’s see what everything does!</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span></code></pre></td>
<td>
<pre><code data-lang="nixos"> <span>users</span><span>.</span><span>groups</span><span>.</span><span>plugdev</span> <span>=</span> <span>{};</span></code></pre></td></tr></tbody></table>
</div>
</div><p>
Creates a group named <code>plugdev</code>, don’t pay attention to it, it is just a test for the Ledger Live application.</p>
<p>
Tells the os that the current user is a normal one. It will create a home folder and set the default shell.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span></code></pre></td>
<td>
<pre><code data-lang="nixos"> <span>extraGroups</span> <span>=</span> <span>[</span> <span>"wheel"</span> <span>"docker"</span> <span>"adbusers"</span> <span>"plugdev"</span> <span>];</span></code></pre></td></tr></tbody></table>
</div>
</div><p>
Here, we are setting the groups the user is in to grant special permissions.</p>
<p>
As you may have guessed it, we are setting the default user shell to ZSH.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span></code></pre></td>
<td>
<pre><code data-lang="nixos"> <span>packages</span> <span>=</span> <span>with</span> <span>pkgs</span><span>;</span> <span>[</span>
            <span># Games</span>
            <span>minetest</span> <span>stepmania</span> <span>lutris-free</span> <span>pcsx2</span>
            <span># Misc audio / video / image</span>
            <span>pulseeffects</span> <span>ffmpeg-full</span> <span>obs-studio</span> <span>inkscape</span> <span>krita</span>
            <span># Useful software</span>
            <span>mumble</span> <span>qbittorrent</span> <span>libreoffice</span> <span>ledger-live-desktop</span>
            <span># Dev</span>
            <span>jetbrains</span><span>.</span><span>idea-community</span> <span>lazygit</span> <span>gnome3</span><span>.</span><span>zenity</span> <span>insomnia</span> <span>jetbrains</span><span>.</span><span>rider</span> <span>mono</span> <span>msbuild</span> <span>dotnet-sdk_3</span> <span>ganttproject-bin</span> <span>kubectx</span>
            <span># SDR</span>
            <span>rtl-sdr</span> <span>gqrx</span> <span>gpredict</span> <span>noaa-apt</span> <span>welle-io</span>
        <span>];</span></code></pre></td></tr></tbody></table>
</div>
</div><p>
There, we are installing per-user packages because yes, NixOS supports that, any user can have its own packages that others users can’t access.</p>
<blockquote>
<p>Correction from <em>hvdijk</em> on Hacker News, “<em>Other users can access those packages if they want to. Those packages won’t show up in other users' $PATH, so other users will not be affected by them, but they could see what’s in /nix/store if they wanted to. This matters when you’re thinking of putting private data (such as an encryption key) in a package: it’s vital that you don’t do that on a multi-user system.</em>”</p>
</blockquote>
<p>Configuring NixOS for a daily use is at the end very easy (although I am getting some trouble to get Ledger Live working; which is the biggest problem I’ve had so far).</p>
<p>Now, let’s talk about where I got some trouble.
As you may know it, I am a dev and every day I need to compile, test, run and so on.
NixOS gave me some trouble to only run some programs from source such as <a href="https://element.io/">Element Desktop</a> or <a href="https://img.tedomum.net/">TeDomum IMG</a> as the way the system is built, lots of directories are read-only and programs can’t be installed globally through NPM or PIP.
I ended up using Docker to build the apps (even if it took a bit more time).</p>
<p>Needless to say, almost every other project worked.
If you want NodeJS to start a project for instance, you can just do <code>nix-shell -p nodejs</code> and here you go, a shell with nodejs installed, ready to do what you want.</p>
<p>At the end, NixOS brings very interesting concepts such as a really great reproducibility but new users can feel lost as its way to work is really different from conventional Linux distributions.
I’ll give NixOS more time and write a follow-up in some time to see how everything went.</p>
<p>If you want to give it a shot, the <a href="https://nixos.org/">official NixOS website awaits you</a>!</p>
<p>That’s all for today,
I’ll see you next time!
If you like my content, <a href="https://jae.moe/blog/index.xml">don’t forget to subscribe through RSS</a>!</p>

            
                <p><a href="https://news.ycombinator.com/item?id=25024639">Talk about it on Hacker News!</a>
            
        </p></div></div>]]>
            </description>
            <link>https://jae.moe/blog/2020/11/one-week-of-nixos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25024639</guid>
            <pubDate>Sun, 08 Nov 2020 10:17:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pro Rata and User Centric Distribution Models: A Comparative Study (2017)]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 85 (<a href="https://news.ycombinator.com/item?id=25024552">thread link</a>) | @iamacyborg
<br/>
November 8, 2020 | http://www.digitalmedia.fi/wp-content/uploads/2018/02/UC_report_final_171213.pdf | <a href="https://web.archive.org/web/*/http://www.digitalmedia.fi/wp-content/uploads/2018/02/UC_report_final_171213.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.digitalmedia.fi/wp-content/uploads/2018/02/UC_report_final_171213.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25024552</guid>
            <pubDate>Sun, 08 Nov 2020 10:01:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Protecting TimeMachine Backups from Itself]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25024547">thread link</a>) | @gingerlime
<br/>
November 8, 2020 | https://blog.gingerlime.com/2020/going-down-the-time-machine-rabbit-hole/ | <a href="https://web.archive.org/web/*/https://blog.gingerlime.com/2020/going-down-the-time-machine-rabbit-hole/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2650">
		<!-- .entry-header -->

	
	<div>
		
<h2>Going down the time machine rabbit hole…</h2>



<p>I love the fact that MacOS comes with TimeMachine built-in, and I also really appreciate its simplicity. It makes backups easy and accessible even for non-technical people. It gets messy though if you also want to have real offsite backups however.</p>



<p>TimeMachine works great with a USB external HD, but things get tricky over the network.</p>



<p>I own a small Synology NAS, and I managed to mount a TimeMachine volume and get it to backup to that volume. The problem started when the volume size started to grow. I could set a quota on the volume, but for some strange reason, when the quota is reached, TimeMachine just started failing without a clear reason. There’s no way to tell TimeMachine to only keep X versions, or keep disk storage below a certain threshold. It’s <em>supposed</em> to prune backups automatically, but seems to fail with my network volume.</p>



<h2>tmutil to the rescue</h2>



<p>After a bit of digging, I discovered a useful command-line utility that helps managing TimeMachine. <code>tmutil</code> lets you list your backups and also delete specific backups. I could manually easily prune the oldest backup of TimeMachine using <code>tmutil listbackups | head -1 | xargs -I {} sudo tmutil delete "{}"</code>.</p>



<p>How difficult could it be to automate this script so it runs regularly and keeps X copies?</p>



<h2>The script</h2>



<p>The script itself was pretty simple. Please don’t bash my bash skills, but I hope the code is clear and seems to do the job</p>


<pre title="">#!/bin/bash

# keeps backups for up to 7 days
KEEP=7

function timestamp() {
    date -jf '%F-%H%M%S' "$1" '+%s'
}

LAST_BACKUP=$(/usr/bin/tmutil listbackups | /usr/bin/tail -n1)
LAST_BACKUP_DATE=$(basename "$LAST_BACKUP")
LAST_TIMESTAMP=$(timestamp $LAST_BACKUP_DATE)

OLDEST_BACKUP=$(/usr/bin/tmutil listbackups | /usr/bin/head -n1)
OLDEST_BACKUP_DATE=$(basename "$OLDEST_BACKUP")
OLDEST_TIMESTAMP=$(timestamp $OLDEST_BACKUP_DATE)

DIFF=$(( ($LAST_TIMESTAMP - $OLDEST_TIMESTAMP) / (24*3600) ))

while [[ $DIFF &gt; $KEEP ]]; do
    echo "cleaning"
    sudo tmutil delete "$OLDEST_BACKUP"
    OLDEST_BACKUP=$(/usr/bin/tmutil listbackups | /usr/bin/head -n1)    
    OLDEST_BACKUP_DATE=$(basename "$OLDEST_BACKUP")
    OLDEST_TIMESTAMP=$(timestamp $OLDEST_BACKUP_DATE)
    DIFF=$(( ($LAST_TIMESTAMP - $OLDEST_TIMESTAMP) / (24*3600) ))
done
</pre>


<p>Easy-peasy, right? There were two problems left to solve:</p>



<ol><li>run this script on schedule, let’s say once a day or once a week</li><li>make sure we can run this as root, so we don’t need to use <code>sudo</code> (or avoid the password prompt if we do run sudo)</li></ol>



<h2>How difficult can it be?</h2>



<p>Running scheduled jobs on MacOS is quite a bit different from Linux. You could still somehow use a cron job, but it’s not recommended, might be deprecated, and generally not the “right way” to do things. You are supposed to create a <code>launchd</code> script… Ok, so without digging too deep, here’s a simple launchd file for running a command every 24 hours. You need to place this file under <code>~/Library/LaunchAgents/</code> and give it a name like <code>org.whatever.script-name.plist</code></p>


<pre title="">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd"&gt;
&lt;plist version="1.0"&gt;
&lt;dict&gt;
    &lt;key&gt;Label&lt;/key&gt;
    &lt;!-- The label should be the same as the filename without the extension --&gt;
    &lt;string&gt;org.whatever.script-name&lt;/string&gt;
    &lt;!-- Specify how to run your program here --&gt;
    &lt;key&gt;ProgramArguments&lt;/key&gt;
    &lt;array&gt;
        &lt;string&gt;/path/to/code/timemachine-cleanup.sh&lt;/string&gt;
    &lt;/array&gt;
    &lt;!-- Run every 24 hours --&gt;
    &lt;key&gt;StartInterval&lt;/key&gt;
    &lt;integer&gt;86400&lt;/integer&gt;&lt;!-- seconds --&gt;
&lt;/dict&gt;
&lt;/plist&gt;
</pre>


<p>Then you would need to run this command, so the launchd script gets scheduled</p>



<p><code>launchctl load org.whatever.script-name.plist</code></p>



<p>note: if you need to stop your script from running, you can use the same command, but with <code>unload</code> instead to unload it.</p>



<h2>First problem: Run as root</h2>



<p>The first problem is that this job now runs as your own user id. This is fixable if you move the file to the global /Library/LaunchAgents, make the owner of the file root and use sudo to load it.  It runs as root, but tmutil now fails. Why? because some tools/operations like tmutil require something called Full Disk Access (FDA). </p>



<h2>Second problem: Full Disk Access</h2>



<p>Here’s an interesting post explaining <a href="https://eclecticlight.co/2020/02/15/why-privileged-commands-may-never-be-allowed/" target="_blank" rel="noreferrer noopener">why some privileged commands are not allowed on MacOS</a>, and a few <a href="https://apple.stackexchange.com/questions/338213/how-to-run-a-launchagent-that-runs-a-script-which-causes-failures-because-of-sys" target="_blank" rel="noreferrer noopener">problems/workarounds being suggested </a>on StackOverflow’s Ask Different.</p>



<p>You can get those commands to run from your terminal, if you add your terminal to the list of allowed apps with Full Disk Access</p>



<figure><img loading="lazy" width="853" height="758" src="https://blog.gingerlime.com/assets/CleanShot-2020-11-08-at-10.15.10.png" alt="" srcset="https://blog.gingerlime.com/assets/CleanShot-2020-11-08-at-10.15.10.png 853w, https://blog.gingerlime.com/assets/CleanShot-2020-11-08-at-10.15.10-300x267.png 300w, https://blog.gingerlime.com/assets/CleanShot-2020-11-08-at-10.15.10-768x682.png 768w" sizes="(max-width: 706px) 89vw, (max-width: 767px) 82vw, 740px"></figure>



<p>The problem however, is that for some strange reason, you cannot simply add your script to the list. Or you could add it, but it will still be blocked. I have no clue why.</p>



<h2>Workaround: wrap your script as an app</h2>



<p>You could use Automator.app or Script Editor to do that. You can then add this wrapper app to give it Full Disk Access permissions. That works, but then there’s no way to make it run as root. So we’re back to the first problem again… :-/</p>



<h2>Workaround #2: sudoers with NOPASSWD</h2>



<p>So we won’t run it as root, but use sudo. Then we’re prompted for a password, which we tried to avoid for a scheduled job.</p>



<p>We can however add any specific command to be allowed to run with sudo without a password. We’ll run <code>sudo visudo</code> and then edit the file to add this line:</p>



<p><code>myuser ALL=(ALL) NOPASSWD: /usr/bin/tmutil</code></p>



<p>If you want to be even more secure, you can include the sha256 hash of tmutil. First get the hash by running <code>sha256sum /usr/bin/tmutil</code> and then adding this sha to your sudoers file. Mine looks like this</p>



<p><code>myuser ALL=(ALL) NOPASSWD: sha256:57a753bd2bef425205684630a676765913e1adca7ec0a9d73c205e4da32488c6 /usr/bin/tmutil</code></p>



<h2>Alternatives to app wrapper</h2>



<p>One thing I noticed with the wrapper app is that when it launches, it’s visible on my desktop. It could even grab my input for a moment, which is slightly annoying. It also felt weird to have a whole app just to wrap a script to give it Full Disk Access.</p>



<p>One alternative mentioned on the <a href="https://apple.stackexchange.com/questions/338213/how-to-run-a-launchagent-that-runs-a-script-which-causes-failures-because-of-sys" target="_blank" rel="noreferrer noopener">linked StackOverflow page</a> above is to compile a binary app to wrap your shell script. I didn’t try it, since I am not using any compiled languages regularly.</p>



<p>Another thing I did try and will probably end up using is launching the script via the terminal. How? I already have passwordless (public key) SSH remote login access set up on my Mac. So I simply modified the launchd script slightly so it launches my script via ssh</p>


<pre title="">&lt;key&gt;ProgramArguments&lt;/key&gt;
&lt;array&gt;
    &lt;string&gt;ssh&lt;/string&gt;
    &lt;string&gt;myuser@myhost.local&lt;/string&gt;
    &lt;string&gt;/path/to/code/timemachine-cleanup.sh&lt;/string&gt;
&lt;/array&gt;
</pre>


<p>Since terminal is already set with FDA, this seems to work :)</p>



<p>It’s a bit of an awkward workaround to ssh to your own host with your own user in order to run a script, but it’s not that much different from compiling a binary to wrap your script, or wrapping it in an “app”.</p>



<h2>Why TimeMachine?</h2>



<p>I guess some people might rightfully question why I’m using TimeMachine and not a more flexible backup tool for Mac. I did consider it and tested a couple of options like CarbonCopyCloner and others. As far as I could tell, none of the commercial backup tools can create a full machine image on a remote network storage like TimeMachine does. If you know of something that does this, please let me know!</p>



<p>… and for those backup freaks out there: No. the Synology volume isn’t my only backup copy. I then also run restic to clone the TimeMachine volume to Backblaze B2 for offsite safekeeping.</p>
	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://blog.gingerlime.com/2020/going-down-the-time-machine-rabbit-hole/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25024547</guid>
            <pubDate>Sun, 08 Nov 2020 10:01:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pongmechanik]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25024499">thread link</a>) | @remix2000
<br/>
November 8, 2020 | http://cyberniklas.de/pongmechanik/indexen.html | <a href="https://web.archive.org/web/*/http://cyberniklas.de/pongmechanik/indexen.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://cyberniklas.de/pongmechanik/indexen.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25024499</guid>
            <pubDate>Sun, 08 Nov 2020 09:52:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PostgreSQL Configuration for Humans]]>
            </title>
            <description>
<![CDATA[
Score 245 | Comments 38 (<a href="https://news.ycombinator.com/item?id=25024224">thread link</a>) | @sharjeelsayed
<br/>
November 8, 2020 | https://postgresqlco.nf/en/doc/param/ | <a href="https://web.archive.org/web/*/https://postgresqlco.nf/en/doc/param/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <div id="welcome">
      
      <div lang="en">
        <h4><p>Your postgresql.conf documentation and recommendations.</p><p>Our mission is to help you tune and optimize your PostgreSQL configuration.</p><p>With around 270 configuration parameters in <span>postgresql.conf</span>, plus all the knobs in pg_hba.conf, it is definitely a difficult task!</p><p>How many parameters do you tune? 1? 8? 32? Ever tuned more than 64? We aim to make PostgreSQL configuration possible for HUMANS.</p></h4>
      </div>
    </div>
  </div>
</div></div>]]>
            </description>
            <link>https://postgresqlco.nf/en/doc/param/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25024224</guid>
            <pubDate>Sun, 08 Nov 2020 08:52:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to build a Gatsby website with Google Sheets]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25024204">thread link</a>) | @iliashad
<br/>
November 8, 2020 | https://iliashaddad.com/blog/how-to-build-a-gatsby-website-with-google-sheets | <a href="https://web.archive.org/web/*/https://iliashaddad.com/blog/how-to-build-a-gatsby-website-with-google-sheets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main><div><article><div><p><span>
      <span></span>
  <img alt="Photo by Arian Darvishi on Unsplash" title="Photo by Arian Darvishi on Unsplash" src="https://iliashaddad.com/static/7b43ce90104c55d06ec59e66f30bb906/0a251/how-to-build-a-gatsby-website-with-google-sheets-0.jpg" srcset="https://iliashaddad.com/static/7b43ce90104c55d06ec59e66f30bb906/bce2d/how-to-build-a-gatsby-website-with-google-sheets-0.jpg 250w,https://iliashaddad.com/static/7b43ce90104c55d06ec59e66f30bb906/953fe/how-to-build-a-gatsby-website-with-google-sheets-0.jpg 500w,https://iliashaddad.com/static/7b43ce90104c55d06ec59e66f30bb906/0a251/how-to-build-a-gatsby-website-with-google-sheets-0.jpg 1000w,https://iliashaddad.com/static/7b43ce90104c55d06ec59e66f30bb906/e3932/how-to-build-a-gatsby-website-with-google-sheets-0.jpg 1500w,https://iliashaddad.com/static/7b43ce90104c55d06ec59e66f30bb906/451a4/how-to-build-a-gatsby-website-with-google-sheets-0.jpg 2000w,https://iliashaddad.com/static/7b43ce90104c55d06ec59e66f30bb906/af240/how-to-build-a-gatsby-website-with-google-sheets-0.jpg 2600w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
    </span>
Photo by  <a href="https://unsplash.com/@arianismmm?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Arian Darvishi</a> on&nbsp;<a href="https://unsplash.com/s/photos/learning?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></p><p>Recently I created a Gatsby website that uses Google sheets as Database and. It took me some time to get it right but the process was not that tough and once I completed it I thought I would share how to build similar one with basic functionality</p><h3>What we will be doing&nbsp;today?</h3><ul><li>Setup new Gatsby Project</li><li>Install and Config Gatsby Google Sheets Source Plugin</li><li>Fetch remote images and make them ready to use in Gatbsy Image</li><li>Query and Display the data from Google Sheets</li></ul><h3><strong>Setup New Gatsby&nbsp;Project</strong></h3><ul><li>Ensure you have the latest <strong>LTS</strong> version of Node installed (&gt;= 10.16.0). <code>node --version</code></li><li><a href="https://yarnpkg.com/en/docs/install">Install</a> the Yarn package manager.</li><li>Ensure you have the latest version of Yarn installed (&gt;= 1.0.2). <code>yarn --version</code></li></ul><p>First, install gatsby-cli globally</p><pre data-language="javascript" data-index="0"><code><span><span></span></span>
<span><span><span> </span><span>yarn</span><span> </span><span>global</span><span> </span><span>add</span><span> </span><span>gatsby</span><span>-</span><span>cli</span></span></span>
<span><span><span> </span></span></span></code></pre><p>Second, Create a new Gatsby website</p><pre data-language="javascript" data-index="1"><code><span><span></span></span>
<span><span><span>gatsby</span><span> </span><span>new</span><span> </span><span>gatsby</span><span>-</span><span>google</span><span>-</span><span>sheets</span><span>-</span><span>starter</span><span> </span></span></span>
<span><span></span></span></code></pre><p>Finally, run the Gatsby website</p><pre data-language="javascript" data-index="2"><code><span><span></span></span>
<span><span><span>gatsby</span><span>-</span><span>google</span><span>-</span><span>sheets</span><span>-</span><span>starte</span><span> </span><span>&amp;&amp;</span><span> </span><span>yarn</span><span> </span><span>develop</span></span></span>
<span><span></span></span></code></pre><h3><strong>Install and Config Gatsby Google Sheets Source&nbsp;Plugin</strong></h3><p>First, you need to get Google Sheets API credentials to be able to read data from sheets</p><ol><li>Go to the <a href="https://console.developers.google.com/">Google APIs Console</a>.</li><li>Create a new project.</li><li>Click <code>Enable API</code>. Search for and enable the Google Drive API.</li><li><code>Create credentials</code> for a <code>Web Server</code> to access <code>Application Data</code>.</li><li>Name the service account and grant it a <code>Project</code> Role of <code>Editor</code>.</li><li>Download the JSON file.</li><li>Copy the JSON file to your code directory and rename it to <code>secret.json</code></li></ol><p>Second, you need to install the gatsby source google sheets</p><pre data-language="javascript" data-index="3"><code><span><span></span></span>
<span><span><span> </span><span>yarn</span><span> </span><span>add</span><span> </span><span>gatsby</span><span>-</span><span>source</span><span>-</span><span>google</span><span>-</span><span>sheets</span></span></span>
<span><span></span></span></code></pre><p>Third, add the plugin in gatsby-config.js</p><pre data-language="javascript" data-index="4"><code><span><span></span></span>
<span><span><span>spreadsheetId</span><span>=</span><span> </span><span>// the id is after the [https://docs.google.com/spreadsheets/d/](https://docs.google.com/spreadsheets/d/)YOUR ID/edit#gid=0</span></span></span>
<span><span></span></span></code></pre><h3>Fetch remote images and make them ready to use in Gatbsy&nbsp;Image</h3><p>Note: I’ll use this G<a href="https://docs.google.com/spreadsheets/d/1L0aW6utYrcfd7xwYp1cIUkv8As4cFx1ECb0phF9-CEE/edit#gid=0">oogle Sheet</a> as a demo</p><p>First, install gatsby-source-filesystem</p><pre data-language="javascript" data-index="5"><code><span><span></span></span>
<span><span><span> </span><span>yarn</span><span> </span><span>add</span><span> </span><span>gatsby</span><span>-</span><span>source</span><span>-</span><span>filesystem</span><span> </span></span></span>
<span><span><span> </span></span></span></code></pre><p>Second, add this code to gatsby-node.js</p><p>Finally, replace node.featuredimage with the field where you have remote image URL</p><h3>Query and Display the data from Google&nbsp;Sheets</h3><p>First, change pages/index.js file</p><p>Second, run the gatsby website</p><pre data-language="javascript" data-index="6"><code><span><span></span></span>
<span><span><span>gatsby</span><span> </span><span>develop</span></span></span>
<span><span></span></span></code></pre><p>Voila, You have a Gatsby website powered by Google Sheets</p><p><span>
      <a href="https://iliashaddad.com/static/68f08f86dafba2bff6ae3f6a63fedfd0/78d47/1__TG1lwHGnlbim9PAbTBL42w.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Gatsby Website Powered By Google&nbsp;Sheets" title="Gatsby Website Powered By Google&nbsp;Sheets" src="https://iliashaddad.com/static/68f08f86dafba2bff6ae3f6a63fedfd0/78d47/1__TG1lwHGnlbim9PAbTBL42w.png" srcset="https://iliashaddad.com/static/68f08f86dafba2bff6ae3f6a63fedfd0/86700/1__TG1lwHGnlbim9PAbTBL42w.png 250w,https://iliashaddad.com/static/68f08f86dafba2bff6ae3f6a63fedfd0/0eb09/1__TG1lwHGnlbim9PAbTBL42w.png 500w,https://iliashaddad.com/static/68f08f86dafba2bff6ae3f6a63fedfd0/78d47/1__TG1lwHGnlbim9PAbTBL42w.png 800w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
  </a>
    </span>
Gatsby Website Powered By Google&nbsp;Sheets</p></div></article></div></main></div></div>]]>
            </description>
            <link>https://iliashaddad.com/blog/how-to-build-a-gatsby-website-with-google-sheets</link>
            <guid isPermaLink="false">hacker-news-small-sites-25024204</guid>
            <pubDate>Sun, 08 Nov 2020 08:47:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Migrating My Blog to Zola]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25024170">thread link</a>) | @todsacerdoti
<br/>
November 8, 2020 | https://mrkaran.dev/posts/migrating-to-zola/ | <a href="https://web.archive.org/web/*/https://mrkaran.dev/posts/migrating-to-zola/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<section>
    
    <article>
        <p>I've been writing on this blog for about 2 years now. This has been the longest I've stuck on to the same <em>technology stack</em> for my blog. I've previously jumped from a Jekyll based static site to a Medium blog before finally settling for <a href="https://gohugo.io/">Hugo</a>.</p>
<p>I've been using Hugo since 2018 but I don't recall as to <em>why</em> I went ahead with it. Maybe it was increasingly popular at that time and everyone touted Hugo as <em>the</em> solution to Static Site Generator (referred to as SSG from here on). There are 1000s of SSGs and at least a dozen of websites which lists all the SSGs out there. This is crazy by any standards. Hugo started as a generic blog generator but over the years it has become a <em>website generator</em>. It's no longer aimed at people who just want to have a small little static website/blog but supports all the use cases for people building full-fledged static websites. IMHO these two goals are overarching however this has resulted in a simple project to become incredibly complex over time.</p>
<h3 id="tipping-point">Tipping Point</h3>
<p>Anyway, so I wanted to change the look of the homepage on my website so I decided to look at Hugo's documentation. Hugo's documentation is great for someone who knows what exactly are they looking for. The documentation is so huge that you simply cannot grok it in one evening. I had zero ideas on how to customise the damn homepage of my blog and after spending hours buried in the documentation I was able to kind of figure the solution but it was unintuitive, to say the least. Apparently, to override any template from the theme, you have to mirror the directory structure of the theme in your root directory. Which meant, I needed to look at the source code of the theme, figure out the project structure, copy-paste all the folder names and put my override of <code>index.html</code> there. Which, BTW <strong>magically</strong> overrides it. This whole magic thing is BS and I am being strongly opinionated here.</p>
<p>There is more than one way to do something in Hugo. Different theme authors use different styles, which makes the whole thing even more complex. It also means for my customisations to work across themes, well you guessed it right: <strong>it's impossible</strong>.</p>
<p>Recently I discovered that I was unable to preview my Hugo website locally without internet because I had a Twitter <a href="https://gohugo.io/content-management/shortcodes/#tweet">shortcode</a> in one of my blog post (which makes an API call to Twitter to render a nice card preview). The site completely failed to render instead of just logging a warning. Bollocks.</p>
<p>The tipping point for me, however, was when the theme I was using stopped working with the latest version of Hugo at that point. So, picture this -- You make dozens of custom changes and then one update just <em>breaks</em> your website. Now not only you have to fix your shit but the theme you were using, you've to make upstream changes to the theme or maintain your own fork. And no, this is not a one-off experience. Hugo upgrades are a joke, they are known to break very very often.</p>
<p>I was done at this point. I didn't want to deal with this BS of continuously fighting the generator for my blog.</p>
<h3 id="a-fresh-change">A fresh change</h3>
<p>Being a practitioner of <a href="https://projects.csail.mit.edu/gsb/old-archive/gsb-archive/gsb2000-02-11.html">Yak Shaving</a>, I discussed the idea of a "tinyhugo" with <a href="https://nadh.in/">Kailash</a> and <a href="https://www.saratchandra.in/">Sarat</a>. We'd arrived at a spec and I started writing some code to pander to my NIH syndrome.</p>
<p>However, I was still not convinced that a simpler solution doesn't exist. I spent countless hours exploring other alternatives. I'd used <a href="https://www.getlektor.com/">Lektor</a>, <a href="https://blog.getpelican.com/">Pelican</a>, <a href="https://www.11ty.dev/">Eleventy</a> before finally stumbling upon <a href="https://www.getzola.org/">Zola</a> from HN/Lobster discussions. I've got to say, the landing page gave a <em>fresh</em> feeling - one that I've not seen with any other alternatives. In fact quite opposite to the Eleventy landing page which looks like an over-engineered piece of software to generate websites (Not hating on it, there might be use cases for it, but the JS tooling and dependency system is something that I would not want to touch with a 10ft pole).</p>
<p>Zola's primary appeal to me was that like Hugo it's extremely fast and comes as a single binary no dependency package. I looked at the docs the first impression was they are concise enough to get a basic idea. Zola is strongly opinionated, even to the extent of dictating a project structure and sometimes filenames too. I actually preferred this over the <em>magic</em> Hugo does. In less than 2 hours I was able to port the home page of my blog (and tweak it to my liking) in Zola. I decided to abandon my own <code>tinyhugo</code> attempt because for the very fact Zola fits my needs very well.</p>
<p>The thing that I really loved about Zola is how it enforces a separation between <a href="https://www.getzola.org/documentation/content/section/">Section</a> and <a href="https://www.getzola.org/documentation/content/page/">Pages</a>. The section represents a "collection" of posts. So a <em>blog</em> can be a section, and I can have another section called "Book Reviews". I could easily tell Zola where to look for the templates by specifying the same in <code>content/book_reviews/_index.md</code>. I don't have to read Hugo docs or do <em>Google-fu</em> to figure this out, it's right there in the docs and very apparent.</p>
<p>For the record, I still don't know how to customise different templates for different sections in Hugo, but I couldn't care less.</p>
<h3 id="migration">Migration</h3>
<p>The migration was pretty straightforward -- I had to copy the <code>content folder</code>s of my blog (which are just a bunch of <code>.md</code> fikes) and replace <code>YAML</code> frontmatter to <code>TOML</code>. There were a few variable changes that I needed to do manually but since they were a manageable 20-25 posts, I did it by hand. I could potentially automate but then rabbit deep in the rabbit hole of Yak Shaving. The good part was that I was able to retain the same URL structure for my new blog because the URL scheme was based on the file paths.</p>
<p>I spent some time porting <a href="https://github.com/knadh/hugo-ink">hugo-ink</a> to Zola and did minor CSS tweaks to it. Zola uses the Terra language for templating and it's much more pleasing to eyes than the Go Template syntax. Zola comes with pretty neat features like Search, RSS/Atom Feeds, Syntax Highlighting and SASS-&gt;CSS Processors.</p>
<p>What took me time however was to figure out how to get <code>opengraph</code> tags in each page. Hugo provides nifty <a href="https://github.com/gohugoio/hugo/blob/master/tpl/tplimpl/embedded/templates/opengraph.html">template</a> for this use case but Zola is pretty barebones like that. People who care a lot about SEO need to spend some extra efforts here.</p>
<h3 id="future">Future</h3>
<p>Zola is still a pretty new kid on the block but the author shares the same frustration about Hugo:</p>
<blockquote>
<p>it personally drives me insane, to the point of writing my own template engine and static site generator. Yes, this is a bit biased. -- <a href="https://github.com/getzola/zola#-explanations">Source</a></p>
</blockquote>
<p>This also reflects in the issues/PRs I've seen for Zola and the author is opinionated about not adding features which would make Zola complicated. Overall I am very happy with the switch and it was long due. I feel more confident in tweaking certain sections of my website. I plan to open-source the current theme in the next few days.</p>
<p>You can read the <a href="https://git.mrkaran.dev/karan/website">Source Code</a> of this website if you'd like to explore how this website is built.</p>
<p>Fin!</p>

    </article>
</section>
</article></div>]]>
            </description>
            <link>https://mrkaran.dev/posts/migrating-to-zola/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25024170</guid>
            <pubDate>Sun, 08 Nov 2020 08:39:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crypto Paper: Man Continues Reading After First Math Equation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25023856">thread link</a>) | @npguy
<br/>
November 7, 2020 | https://doublespend.io/2020/10/28/man-continues-reading-crypto-white-paper-after-first-mathematical-equation/ | <a href="https://web.archive.org/web/*/https://doublespend.io/2020/10/28/man-continues-reading-crypto-white-paper-after-first-mathematical-equation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>DoubleSpend has obtained exclusive video footage of a man continuing to read a white paper after the occurrence of the first mathematical equation in the paper. The video footage has been analyzed with WebGazeAnalyzer, a system for capturing and analyzing web reading behavior using eye gaze to confirm that this was not a case of the viewer moving off the page or just leaving the desk. </p>



<p>More details on this to follow soon.</p>
<div><p><a href="https://twitter.com/share?url=https://doublespend.io/2020/10/28/man-continues-reading-crypto-white-paper-after-first-mathematical-equation/&amp;text=Man%20Continues%20Reading%20Crypto%20White%20Paper%20After%20First%20Math%20Equation" title="Share on Twitter" target="_blank" rel="nofollow noopener noreferrer" data-postid="453" data-social-network="Twitter" data-social-action="Tweet" data-social-target="https://doublespend.io/2020/10/28/man-continues-reading-crypto-white-paper-after-first-mathematical-equation/"><span><span><svg version="1.1" xmlns="http://www.w3.org/2000/svg" width="29.71875" height="32" viewBox="0 0 951 1024"><path d="M925.714 233.143q-38.286 56-92.571 95.429 0.571 8 0.571 24 0 74.286-21.714 148.286t-66 142-105.429 120.286-147.429 83.429-184.571 31.143q-154.857 0-283.429-82.857 20 2.286 44.571 2.286 128.571 0 229.143-78.857-60-1.143-107.429-36.857t-65.143-91.143q18.857 2.857 34.857 2.857 24.571 0 48.571-6.286-64-13.143-106-63.714t-42-117.429v-2.286q38.857 21.714 83.429 23.429-37.714-25.143-60-65.714t-22.286-88q0-50.286 25.143-93.143 69.143 85.143 168.286 136.286t212.286 56.857q-4.571-21.714-4.571-42.286 0-76.571 54-130.571t130.571-54q80 0 134.857 58.286 62.286-12 117.143-44.571-21.143 65.714-81.143 101.714 53.143-5.714 106.286-28.571z"></path></svg></span><span>Tweet</span></span><span>0</span></a></p></div>		</div></div>]]>
            </description>
            <link>https://doublespend.io/2020/10/28/man-continues-reading-crypto-white-paper-after-first-mathematical-equation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25023856</guid>
            <pubDate>Sun, 08 Nov 2020 07:29:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Embed Gravity programming language into your code]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25023836">thread link</a>) | @creolabs
<br/>
November 7, 2020 | https://marcobambini.github.io/gravity/#/embedding | <a href="https://web.archive.org/web/*/https://marcobambini.github.io/gravity/#/embedding">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://marcobambini.github.io/gravity/#/embedding</link>
            <guid isPermaLink="false">hacker-news-small-sites-25023836</guid>
            <pubDate>Sun, 08 Nov 2020 07:25:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parsing the Infamous Japanese Postal CSV]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25023673">thread link</a>) | @polm23
<br/>
November 7, 2020 | https://www.dampfkraft.com/posuto.html | <a href="https://web.archive.org/web/*/https://www.dampfkraft.com/posuto.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Late last year I released <a href="https://github.com/polm/posuto">posuto</a>, a package presenting Japanese postal code
data in an easy-to-use format. It's based on <a href="https://www.post.japanpost.jp/zipcode/dl/kogaki-zip.html">data released by Japan
Post</a>, which is infamous for being widely used but hard to parse.</p>
<figure><a href="https://www.dampfkraft.com/by-id/806ae69c/postcharacter.png"><img src="https://www.dampfkraft.com/by-id/806ae69c/img/postcharacter.png.l.png"></a><figcaption>This adorable character by <a href="https://www.irasutoya.com/2019/08/blog-post_590.html">Irasutoya</a> is cute, but the raw postal CSV data is not.
</figcaption></figure>
<p>I first became aware of the postal data when I entered my postal code in an
online form and it auto-completed my address as "XXX-borough (except the
following buildings)". I had no idea what that parenthetical was referring to,
so I looked for a common source of postal data, found the CSV, and found the
issue.  It turns out the CSV file contains parenthetical notes for anyone
reading the CSV file and makes reference to the order of the rows.</p>
<p>This causes problems. The data is mainly useful one row at a time, where the
parenthetical is meaningless. Since CSV is a field-delimited format, there's
also no need for parentheticals - you could just add a note field.</p>
<p>This is only one of many issues with <code>ken_all.csv</code>. You can find people
complaining about it regularly <a href="https://twitter.com/search?q=ken_all.csv&amp;src=typed_query&amp;f=live">on Twitter</a>, and there was
even briefly <a href="http://ken-all.hatenadiary.com/">a blog</a> just collecting posts from all over the web
about it. A <a href="https://twitter.com/bulkneets/status/1259457777862184966">particularly amusing tweet</a> describes people who expect
computers to bend to the will of humans being punished in Hell by having to
parse <code>ken_all.csv</code> forever.</p>
<p>The <a href="https://www.post.japanpost.jp/zipcode/dl/readme.html">README</a> for the file explains that lines with overly long fields will be
broken up into multiple lines. Specifically, if the neighborhood name is over
38 characters, or if the half-width katakana (<em>half-width katakana</em>)
pronunciation field is over 76 characters, the line will be split into two
lines. The overly-long neighborhood field will be continued and all other
fields will be duplicated. This is an abbreviated sample of what that looks
like:</p>
<pre><code>12345,Tokyo,Minato,This place name is really
12345,Tokyo,Minato,very long it didn't fit in
12345,Tokyo,Minato,a single line so we had to 
12345,Tokyo,Minato,split it
</code></pre>
<p>The motivation for this is not explained. Maybe there was a fixed-width buffer
for storing a line somewhere thirty years ago. I used to process CSV and other
files from hundreds of different providers at an old job and I saw many
horrors, but I've never seen this particular formatting choice anywhere else.
It should also be noted that while the length limits are as stated, the
location where line breaks are inserted in long lines appears random, occurring
neither at the character limit nor at normal word boundaries.</p>
<p>It's worth noting not all the issues with the CSV are inherently technical;
postal codes are always complicated. The postal code with the most rows in the
CSV - a stunning 66 - is 〒452-0961, which refers to the <a href="https://ja.wikipedia.org/wiki/%E6%98%A5%E6%97%A5%E7%94%BA_(%E6%84%9B%E7%9F%A5%E7%9C%8C)">Haruhi region</a> of
Kiyosu City in Aichi Prefecture. This has that many lines because every
neighborhood gets a separate line. (This particular case may be related to Haruhi
having been the smallest town by area in Japan from 2006 until 2009, when it
was incorporated into Kiyosu City.)</p>
<p>In contrast, the longest <em>continued</em> line, using the line break rules above, is
the entry for 〒602-8368 or 〒602-8374, both with eight lines. These are both in
one of a few areas in Kyoto that uses <a href="https://en.wikipedia.org/wiki/Japanese_addressing_system#Kyoto">a unique, bizarre system of
intersection-based addressing</a>. The entry looks a bit like this:</p>
<pre><code>12345,Kyoto,Kyoto,"North Town (Up Lower Godsroad from"
12345,Kyoto,Kyoto,"the West, Down Turtle Street from the"
12345,Kyoto,Kyoto,"East, Up Old Temple Road from the"
12345,Kyoto,Kyoto,"West)"
</code></pre>
<p>I have used quoted fields here, but the actual CSV doesn't quote fields and
instead uses a different kind of comma.</p>
<p>There are other issues. There are catch-all postal codes for many areas, where
the neighborhood is given as "except the following", and the only thing to do
is look for that exact string and exclude it. There's a variety of similar
strings, and it's hard to be sure I've caught them all.</p>
<p>An example of another comment is 一円. Normally this would mean "one yen", but
it also means "the area surrounding", and is a note in the CSV that should be
removed from neighborhood names, <em>except</em> for exactly one neighborhood in Shiga where
that's actually the name (〒522-0317).</p>
<p>There's also a <a href="https://www.post.japanpost.jp/zipcode/dl/roman.html">separate romaji file</a> offered by JP Post. It's updated
less frequently than the main files, is often out of sync, and the provided
romaji are extremely low quality. For the moment I'm still providing the data
in posuto in the name of consistency, but honestly you should just use
<a href="https://www.dampfkraft.com/nlp/cutlet-python-romaji-converter.html">cutlet</a>. To give an example of bad romaji:</p>
<pre><code>大手町 JAビル
OTEMACHI JIEIEIBIRU
</code></pre>
<p>What's happening here is that "JA" is being converted to the phonetic reading
in Japanese, "ジェイエイ". Then ジェ, which is written "large ji small e" but
pronounced "je", is being converted to "jie" by treating the small character as
though it were large, and the other characters are translated as-is, turning
something already in the latin alphabet into alphabet soup. For contrast,
cutlet has no problem converting "JAビル" into "JA building" (case handling
admittedly needs some work still). Similar issues turn "Roppongi Hills" into
"Roppongihiruzu", and "Sweden Hills" into "Suedenhiruzu".</p>
<p>Anyway, dealing with the file was a humbling lesson in the amount of complexity
it's possible to pack into one place. I've glossed over many details, but you
can find them covered in posuto's README.</p>
<p>You can use <a href="https://github.com/polm/posuto">posuto</a> as a library, or if you're not using Python, just
download the pre-processed JSON and make use of that. If you find a good use
for it I'd be delighted to hear about it.</p>
<p>Oh, and if you need a Win3.1 or DOS program to copy the data onto an IBM H
floppy disk, just check the bottom of <a href="https://www.post.japanpost.jp/zipcode/dl/kogaki-zip.html">JP Post's page</a> - they've
got you covered. Ψ</p>
</div></div>]]>
            </description>
            <link>https://www.dampfkraft.com/posuto.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25023673</guid>
            <pubDate>Sun, 08 Nov 2020 06:52:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I wrote JavaScript to avoid JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25023594">thread link</a>) | @asaaki
<br/>
November 7, 2020 | https://markentier.tech/posts/2020/10/wrote-javascript-to-avoid-javascript/ | <a href="https://web.archive.org/web/*/https://markentier.tech/posts/2020/10/wrote-javascript-to-avoid-javascript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Web technologies have come so far, that you realize: not everything needs to be done in JavaScript nowadays anymore.</p><blockquote><p><em>»Life is really simple, but we insist on making it complicated.« — Confucius</em></p></blockquote><p>My initial headline would have been:</p><p><em>How I wrote more JavaScript in the backend to eliminate JavaScript in the frontend.</em></p><p>But that's already a mouthful and also would have revealed too much and you might not have clicked my slightly clickbait-y title, right?</p><p>So here is my Public Service Announcement:</p><p> 📣 <strong>This site does not use any frontend JavaScript.<sup>*</sup></strong></p><p><em><small>*) There are only tiny exceptions on 2 pages, but for a good reason. More on that later.</small></em></p><p>First of all I am not against JavaScript (<span>JS</span>) at all. If you're building a web <strong>application</strong>, then this is not only totally fine but most likely a core requirement.</p><p>But I do have my pet peeve with <span>JS</span> for plain websites and blogs. Currently there is still such a strong draught in the static site generator world, telling us all our sites should be some kind of React or other frontend framework based project (looking at you, Gatsby, Next, Nuxt, VuePress, …). That you need to have that plentyful of code running in the browser of your visitors to have a smooth and <em>feels like a native app</em> user experience. That a site should be a <em>Single Page Application (SPA).</em> I can tell you, a plain HTML+CSS website does it really well, too. Surprise!</p><p>While on one hand the browser vendors add more and more <a href="https://developer.mozilla.org/en-US/docs/Web/API">Web APIs</a>, we also got a lot of improvement in the HTML and CSS area. Usually there is no big hype train around them, unless you are very enthusiastic and live in that niche.</p><p>Take a look at <a href="https://caniuse.com/">caniuse.com</a> to get an idea what is possible today and what might come tomorrow. <em>Did you know that HTML5 is still iterated on and we're moving towards <a href="https://www.w3.org/TR/html53/">version 5.3</a>?</em> On the other hand »HTML 5« is also used as an umbrella term for a <a href="https://spec.whatwg.org/" title="WHATWG Standards">wide variety of standards</a>. Also for CSS the story got very interesting: while CSS until 2.1 was a single specification, since CSS 3 there is a whole potpourri of recommendations and drafts. The <a href="https://wiki.csswg.org/spec">wiki of the CSS Working Group</a> might be a good starting point for further discovery.</p><p>But I want to give you some more practical examples and an experience report:</p><h2 id="sticky-navigation-bar">Sticky navigation bar</h2><p>This is something you can observe here on this blog:</p><video autoplay="" loop="" muted="" playsinline=""><source src="https://markentier.tech/posts/2020/10/wrote-javascript-to-avoid-javascript/pos-sticky.hvec.mp4" type="video/mp4; codecs=hvc1"><source src="https://markentier.tech/posts/2020/10/wrote-javascript-to-avoid-javascript/pos-sticky.hvec.mp4" type="video/mp4; codecs=hevc"><source src="https://markentier.tech/posts/2020/10/wrote-javascript-to-avoid-javascript/pos-sticky.h264.mp4" type="video/mp4; codecs=avc1"><source src="https://markentier.tech/posts/2020/10/wrote-javascript-to-avoid-javascript/pos-sticky.webm" type="video/webm; codecs=vp9"></video><p>The key ingredient is the CSS <code>position: sticky</code> <a href="https://caniuse.com/css-sticky">🛈</a>. Even though most of them are labeled as <em>partial support,</em> this property value can be used in most scenarios except in some table related cases. If you want a sticky menu after scrolling and use only elements like <code>div</code> everything is just fine. I could throw away all the code for that after I realized that none of the common and modern browsers had any blocking issues. So I did. The only real latecomers were the web view components, no big deal for me here.</p><h3 id="before">Before</h3><h4 id="javascript">JavaScript</h4><pre><code><span>const </span><span>navbar </span><span>= </span><span>document</span><span>.querySelector(</span><span>'.navbar'</span><span>);
</span><span>let </span><span>sticky </span><span>= </span><span>navbar.offsetTop;
</span><span>const </span><span>navbarScroll </span><span>= </span><span>() </span><span>=&gt; </span><span>{
  </span><span>if </span><span>(</span><span>window</span><span>.pageYOffset </span><span>&gt;= </span><span>sticky) {
    navbar.classList.add(</span><span>'sticky'</span><span>)
  } </span><span>else </span><span>{
    navbar.classList.remove(</span><span>'sticky'</span><span>);
  }
};

</span><span>window</span><span>.onscroll </span><span>= </span><span>navbarScroll;
</span></code></pre><h4 id="stylesheet">Stylesheet</h4><pre><code><span>.navbar </span><span>{
  </span><span>position</span><span>: </span><span>relative</span><span>;
}
</span><span>.sticky </span><span>{
  </span><span>position</span><span>: </span><span>fixed</span><span>;
  </span><span>top</span><span>: </span><span>0</span><span>;
  </span><span>left</span><span>: </span><span>0</span><span>;
}
</span></code></pre><h3 id="after">After</h3><h4 id="javascript-1">JavaScript</h4><pre><code><span>// nope
</span></code></pre><h4 id="stylesheet-1">Stylesheet</h4><pre><code><span>.navbar </span><span>{
  </span><span>position</span><span>: </span><span>sticky</span><span>;
  </span><span>top</span><span>: </span><span>0</span><span>; </span><span>/* it does not reposition right away,
             but determines at which point it sticks */
</span><span>}
</span></code></pre><h3 id="resolution">Resolution</h3><p>The workaround with <span>JS</span> is no more. Yay!</p><p>Also notice how little code is actually needed now? Two CSS properties and the job is done.</p><hr><h2 id="service-workers">Service Workers</h2><p>Also in 2018 I played with <a href="https://markentier.tech/posts/2018/04/progressive-web-app/">Progressive Web Apps (PWA)</a>. The whole blog was one. A few days ago I teared down all of it. At the core of PWAs sit <a href="https://serviceworke.rs/">Service Workers (SW)</a>, though you can use SW also without building an app. And that's what I was aiming for, but in the end my home-grown dynamic cache solution was more annoying to me than helpful for anyone else. Every time I updated anything here, I had to wait and/or force refresh to see the result. I'm sure some people probably see visual inconsistencies due to a still running service worker in their browser. If you do, try to force clear all data for this website.</p><p>Long story short: if you do not build a web <strong>app</strong>, you most likely do not need service workers. So yet another thing down from the <span>JS</span> list.</p><p>No <em>before/after</em> comparison here, but several precious kilobytes of JavaScript shaved off by removing them.</p><hr><h2 id="sqip-svg-lqip">SQIP (SVG LQIP)</h2><p><em>Woa, what are all these random acronyms here?</em> Don't worry, the simple answer is:</p><p>If you have images and they are not very small in file size, you maybe want to provide a temporary placeholder with very low resolution and quality. This is pretty useful for slow internet connections; living here in Germany I know how difficult this situation can be. That thing called internet is still very Neuland to us. 🤦</p><p>Anyway, <code>SQIP</code> can be translated with »<code>SVG</code>-based <code>LQIP</code>.«</p><p><code>SVG</code> are Scalable Vector Graphics, an image format I really love a lot, my logo is done with it (<a href="https://markentier.tech/posts/2018/05/minimalism-focus-clean-redesign/">I wrote about it a while ago</a>).</p><p>LQIP finally stands for <em>»Low Quality Image Placeholders«</em> and is based on an algorithm to find primitive shapes to describe the source image. Basically try to find only a few triangles, rectangles, circles, ellipsis, and other low poly shapes. It is also an art form in its own, you can enjoy some <a href="https://github.com/fogleman/primitive#static-animation">nice examples there</a>. The advantage of SVG is that it is made to encode such figures in very few characters of human readable text, so a less complex image for a placeholder can be written in one kilobyte or less.</p><p>Compared to the original high resolution image which can easily weigh half a megabyte and more this is great. You can reserve the space in your page and very early in the loading process display some visual hint that there will be a proper picture soon. Especially for types which do not support progessive loading (as JPEG can) using SQIP/LQIP placeholders makes a lot of sense.</p><p>In this scenario at first it was not really about saving frontend <span>JS</span>, more about saving it on the backend site and replacing it with something else. Unfortunately in between some code creeped into the frontend anyway.</p><p>But what happened that this beautiful technique fell out of favor with me?</p><h3 id="picture"><code>&lt;picture&gt;</code></h3><p>Enter another interesting HTML tag combo: <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/picture"><code>&lt;picture&gt;</code></a> with <code>&lt;source&gt;</code>.</p><p>So one reason to use small low quality placeholders is because before such tags became a thing we solely relied on a single <code>&lt;img&gt;</code> and some trickery with CSS (and sometimes aided by sprinkles of JavaScript). I tried to avoid <span>JS</span> completely, but of course I had to use some styling hacks eventually.</p><p>The essence of it was some style attached to the image in question:</p><pre><code><span>&lt;</span><span>img </span><span>src</span><span>=</span><span>"highres-and-heavy.png"
     </span><span>style</span><span>=</span><span>"</span><span>background-size</span><span>: </span><span>cover</span><span>;
            </span><span>background-image</span><span>: </span><span>url</span><span>(</span><span>'data:image/svg+xml;base64,PHN2…'</span><span>);</span><span>"</span><span>&gt;
</span><span>&lt;!-- Usually in some post processing all style attributes were collected
     into a &lt;style&gt; tag or CSS file. --&gt;
</span></code></pre><p>The JavaScript entered this scenery at one point: after I used images with transparency. Sadly with this background image workaround you would've seen the low quality placeholder through the transparent parts, and this was extremly ugly to be honest. I could not stand it and deployed some snippet to trigger a background removal once the actual image was loaded:</p><pre><code><span>// remove the background image styling, so transparent images won't have
// strange SQIP artefacts shining through
</span><span>document</span><span>.querySelectorAll(
  </span><span>"img[loading=lazy][class]:not(.thumbnail):not(.loaded)"
</span><span>).forEach((</span><span>img</span><span>) </span><span>=&gt; </span><span>{
  </span><span>img</span><span>.</span><span>onload </span><span>= </span><span>(</span><span>_event</span><span>) </span><span>=&gt; </span><span>img.className </span><span>= </span><span>"loaded"</span><span>;
});
</span><span>document</span><span>.querySelectorAll(
  </span><span>"img[loading=lazy].thumbnail:not(.loaded)"
</span><span>).forEach((</span><span>img</span><span>) </span><span>=&gt; </span><span>{
  </span><span>img</span><span>.</span><span>onload </span><span>= </span><span>(</span><span>_event</span><span>) </span><span>=&gt; </span><span>img.className </span><span>= </span><span>"thumbnail loaded"</span><span>;
});
</span></code></pre><p>Theoretically it would have been tolerable, but I noticed some strange behaviour once I started wrapping my images into <code>picture</code> tags.</p><p>Let's <a href="https://en.wiktionary.org/wiki/yak_shaving">shave the yak</a> a bit further to understand why.</p><h4 id="webp-and-avif">WEBP and AVIF</h4><p><em>Come on, more acronyms?</em> I'm sorry, the web is a place with a lot of them.</p><p>All you need to know for now is that both of them are pretty modern image formats with quite good (lossy) compression rates while keeping a respectable quality. <a href="https://caniuse.com/webp"><code>WEBP</code></a> has been around for some time and most of the browsers do support it. <a href="https://caniuse.com/avif"><code>AVIF</code></a> is extremly new and right now only Chrome since version 85 and Opera 71 can display them. Firefox has a configuration flag, maybe they will enable it by default pretty soon.</p><p>So the current situation is that I have my original image (PNG or JPEG in most cases), a WEBP version, an AVIF version, and the SQIP placeholder. How do I deal with it? Back to our <code>&lt;picture&gt;</code> tag:</p><pre><code><span>&lt;</span><span>picture</span><span>&gt;
  &lt;</span><span>source </span><span>srcset</span><span>=</span><span>"./cover.avif" </span><span>type</span><span>=</span><span>"image/avif"</span><span>&gt;
  &lt;</span><span>source </span><span>srcset</span><span>=</span><span>"./cover.webp" </span><span>type</span><span>=</span><span>"image/webp"</span><span>&gt;
  &lt;</span><span>img </span><span>src</span><span>=</span><span>"./cover.png"
       </span><span>style</span><span>=</span><span>"</span><span>/* SQIP data: see example above */</span><span>"</span><span>&gt;
&lt;/</span><span>picture</span><span>&gt;
</span></code></pre><p>You can also use source sets for different view sizes based on media queries, but in my case I'm mainly concerned about supporting different image formats. My idea is to prioritize the formats with the smallest file size first, and given the compression ratios the order is usually: AVIF, WEBP, PNG/JPG. Not in every case will this be true; WEBP does not always have better savings then a decently compressed JPEG for example. AVIF has not disappointed so far, but sadly a part of my visitors will not see the effect yet.</p><p>What did not really happen anymore was a display of the placeholder before the final image was loaded. I experimented for quite some time until I realized that I do not want to spent more energy any further.</p><p><picture><source srcset="https://markentier.tech/posts/2020/10/wrote-javascript-to-avoid-javascript/sizes-png-webp-avif.w.avif" type="image/avif"><source srcset="https://markentier.tech/posts/2020/10/wrote-javascript-to-avoid-javascript/sizes-png-webp-avif.w.webp" type="image/webp"><img src="https://markentier.tech/posts/2020/10/wrote-javascript-to-avoid-javascript/sizes-png-webp-avif.w.png" alt="Size comparison of an example image; PNG original (22 KB), WEBP (14 KB, 37% saved), AVIF (7.3 KB, 67% saved)" width="1024" height="120" loading="lazy"></picture></p><p>I made a <em>risk-return tradeoff</em> compromise and got rid of SQIP altogether. For the growing number of AVIF support the images are sometimes significantly smaller which makes it acceptable to allow for some display delay anyway.</p><p>In the following screenshot the JPEG was the source photo. The PNG was created for some transparency stuff; of course, for photos this format does not really make a lot of sense in general. Sadly also WEBP fails to compete in this scenario. That's why I have to make this picture group generation a bit smarter soon to reorder based on the actual file …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://markentier.tech/posts/2020/10/wrote-javascript-to-avoid-javascript/">https://markentier.tech/posts/2020/10/wrote-javascript-to-avoid-javascript/</a></em></p>]]>
            </description>
            <link>https://markentier.tech/posts/2020/10/wrote-javascript-to-avoid-javascript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25023594</guid>
            <pubDate>Sun, 08 Nov 2020 06:30:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I’m Building a Personal Platform Why You Should Too]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25023515">thread link</a>) | @dannyeei
<br/>
November 7, 2020 | http://dasit.xyz/index.php/2020/10/15/building-a-personal-platform/ | <a href="https://web.archive.org/web/*/http://dasit.xyz/index.php/2020/10/15/building-a-personal-platform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-47">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>Recently I’ve got into the idea of building a personal platform for myself. By that I mean a system which makes it easy to distribute new things I’m working on and a way to grow the group of people who could be interested in what I’m working on.</p>



<h2>How I’m going about building a platform</h2>



<ol><li>Leveraging what I already have<ol><li>I have a <a href="https://www.youtube.com/channel/UCjRhOxof_h24gemf8If3Klw?view_as=subscriber">YouTube channel</a> with a following</li><li>I have a network from my personal and professional life</li></ol></li><li>More content<ol><li>This blog</li><li>“Computer Security: Attacking and defending web apps” course on Udemy (because my most successful content on YouTube is about Cyber Security and I’ve had a lot of demand for making a video on how to write shell code)</li><li><a href="https://scenario95.com/">Scenario95</a></li></ol></li><li>Creating a pipeline which I use for all new content<ol><li>Send an email to followers of my platform</li><li>Sharing on several platforms including: Facebook, HackerNews, Reddit, Twitter, and LinkedIn</li></ol></li></ol>



<h2>Why I’m doing this?</h2>



<p>When coming up with new ideas I’ve noticed that I often base them around what I already have access to and natural advantages I’ve got. For example when on a course topic for Udemy, I referred to the YouTube video which I released 4 years ago… and I’ve realised that since finishing university I haven’t done a good job of continuing to create things like this.</p>







<p>This is something I’m new to and and still learning the ropes so if you’ve got any advice please leave it in the comments below. </p>



<p>If you want to follow my adventure then subscribe to my platform! </p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
		<!-- .comments-wrapper -->

		
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>http://dasit.xyz/index.php/2020/10/15/building-a-personal-platform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25023515</guid>
            <pubDate>Sun, 08 Nov 2020 06:14:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Cheapest Online Documentation Repository for Startups]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25023085">thread link</a>) | @timothy-quinn
<br/>
November 7, 2020 | https://blog.congruentlabs.co/the-cheapest-online-documentation-repository-for-startups/ | <a href="https://web.archive.org/web/*/https://blog.congruentlabs.co/the-cheapest-online-documentation-repository-for-startups/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.congruentlabs.co/content/images/size/w300/2020/11/Screenshot-2020-11-08-151315.png 300w,
                            https://blog.congruentlabs.co/content/images/size/w600/2020/11/Screenshot-2020-11-08-151315.png 600w,
                            https://blog.congruentlabs.co/content/images/size/w1000/2020/11/Screenshot-2020-11-08-151315.png 1000w,
                            https://blog.congruentlabs.co/content/images/size/w2000/2020/11/Screenshot-2020-11-08-151315.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.congruentlabs.co/content/images/size/w2000/2020/11/Screenshot-2020-11-08-151315.png" alt="The Cheapest Online Documentation Repository for Startups">
            </figure>

            <section>
                <div>
                    <p>I had a problem. I wanted public documentation with open collaboration, but I couldn't afford most of the products out there. As a startup we need to keep lean, and adding a paid documentation/knowledge base service is an expense I don't want to have to try to recover.</p><p>So we're moving all of our product documentation into public Github repositories, as it's the cheapest option with it being free 😉</p><p>The first repository is here, for our Signata MFA product: <a href="https://github.com/cl-tim/signata-mfa-docs">https://github.com/cl-tim/signata-mfa-docs</a></p><h3 id="why-github">Why Github?</h3><p>As much as I find it frustrating to write documentation in markdown (writing is easy, dealing with screenshots is clunky), the benefits of having a publicly accessible repository for documentation far outweighs my frustration.</p><p>I want to make sure documentation isn't sitting behind paywalls or needing a sign up. In fact, forcing people to sign up to read it has created a ton of accounts in our system that don't actually get used, which is an inconvenience for both parties.</p><p>The best part of putting it into Github is now there's the ability to collaborate - if you find a problem, or ambiguous statement, or you want something added, you can now directly interact with the content to submit pull requests or open issues.</p><p>We've also put a link to the documentation onto the Signata MFA website in a few places, which you'll also notice has undergone some rebranding:</p><figure><img src="https://blog.congruentlabs.co/content/images/2020/11/image.png" alt="" srcset="https://blog.congruentlabs.co/content/images/size/w600/2020/11/image.png 600w, https://blog.congruentlabs.co/content/images/size/w1000/2020/11/image.png 1000w, https://blog.congruentlabs.co/content/images/2020/11/image.png 1458w" sizes="(min-width: 720px) 720px"></figure><p>It's actually quite expensive to run an online knowledgebase in most instances. <a href="https://readthedocs.org/">Read the Docs</a> would've been the ideal choice, but it's only free for open source projects, and at this stage we don't yet have plans to open source our products. I could've spun up a self-hosted service like Dokuwiki, but that would be an additional $10/month of operating costs, as well as the administrative overhead for keeping it up to date.</p><p>An alternative we thought about was to use publicly accessible Google Docs, but they lose the ability to be indexed by search engines for people to actually find these guides. There's not much use to public documentation if it's not actually discoverable by the public.</p><h3 id="signata-mfa-presentation">Signata MFA Presentation</h3><p>I've also thrown a presentation that we put together about Signata MFA into the repository as well. <a href="https://github.com/cl-tim/signata-mfa-docs/blob/main/signata-mfa-overview-presentation.pdf">You can find it here</a> - it'll give you a quick overview of the product, it's capabilities, it's pricing, and how to get in contact with us.</p><p>Have you looked at Signata MFA? <a href="https://mfa.signata.net/">You can check it out by clicking here</a>. You can try it for free for a month, no credit card required.</p>
                </div>
            </section>

            
            
        </article>
    </div>
</div></div>]]>
            </description>
            <link>https://blog.congruentlabs.co/the-cheapest-online-documentation-repository-for-startups/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25023085</guid>
            <pubDate>Sun, 08 Nov 2020 04:45:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Undemocratic Republic: The Tyranny of the Senate]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25022747">thread link</a>) | @krasney
<br/>
November 7, 2020 | https://ni.chol.as/posts/senate-reform/ | <a href="https://web.archive.org/web/*/https://ni.chol.as/posts/senate-reform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>“It may happen that this majority of States is a small minority of the people of America; and two thirds of the people of America could not long be persuaded, upon the credit of artificial distinctions and syllogistic subtleties, to submit their interests to the management and disposal of one third.” Alexander Hamilton, <a href="https://www.newyorker.com/news/hendrik-hertzberg/alexander-hamilton-speaks-out-iii-two-senators-per-state-regardless-of-population" target="_blank" rel="nofollow noopener noreferrer">Federalist 22</a>, December 14, 1787</p>
<p>“Legislators represent people, not trees or acres. Legislators are elected by voters, not farms or cities or economic interests. … And, if a State should provide that the votes of citizens in one part of the State should be given two times, or five times, or 10 times the weight of votes of citizens in another part of the State, it could hardly be contended that the right to vote of those residing in the disfavored areas had not been effectively diluted.” Reynold v Sims</p>
<p>The US Senate has incredible legislative and “advise and consent” powers. It passes bills, but also approves treaties, confirms Cabinet secretaries, Supreme Court justices, judges, and other officials.</p>
<p>It’s 2020, and:</p>
<ul>
<li>~33% of the population lives in just 4 states—California, Texas, Florida, and New York—and is represented by just 8 Senators.</li>
<li>~50% of the population is represented by just 18 Senators</li>
<li>~70% of the population is represented by just ~1/3 of the Senators</li>
<li>
<p>10% of the population is distributed across the 19 least populated states, and control 38 Senators.</p>
<p><span>
      <a href="https://ni.chol.as/static/a4dfaef4c9cc10d6c536bf146ac1e9d1/8affb/Senate-Population.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://ni.chol.as/static/a4dfaef4c9cc10d6c536bf146ac1e9d1/8ac56/Senate-Population.webp 240w,
https://ni.chol.as/static/a4dfaef4c9cc10d6c536bf146ac1e9d1/d3be9/Senate-Population.webp 480w,
https://ni.chol.as/static/a4dfaef4c9cc10d6c536bf146ac1e9d1/e46b2/Senate-Population.webp 960w,
https://ni.chol.as/static/a4dfaef4c9cc10d6c536bf146ac1e9d1/a1214/Senate-Population.webp 1254w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://ni.chol.as/static/a4dfaef4c9cc10d6c536bf146ac1e9d1/8ff5a/Senate-Population.png 240w,
https://ni.chol.as/static/a4dfaef4c9cc10d6c536bf146ac1e9d1/e85cb/Senate-Population.png 480w,
https://ni.chol.as/static/a4dfaef4c9cc10d6c536bf146ac1e9d1/d9199/Senate-Population.png 960w,
https://ni.chol.as/static/a4dfaef4c9cc10d6c536bf146ac1e9d1/8affb/Senate-Population.png 1254w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://ni.chol.as/static/a4dfaef4c9cc10d6c536bf146ac1e9d1/d9199/Senate-Population.png" alt="/media/Senate-Population.png" title="/media/Senate-Population.png" loading="lazy">
      </picture>
  </a>
    </span></p>
</li>
</ul>
<p>In 1790, the gap between the smallest and largest states was about 10x. Today, the most populous state, California, is about 70x more populous than the least populous state, Wyoming. A resident of California, New York, Florida, or Texas has no effective impact on the Senate impact, and a resident of a smaller state Wyoming, Vermont, Alaska, the Dakotas, Delaware, Rhode Island, or Maine has a disproportionate impact on the Senate.</p>
<p>While the Electoral College favors smaller states as well, it is still mostly driven by membership in the House of Representatives, which is proportionate to population. That’s unfair—the popular vote loser became president in 2000 and 2016— but it’s far less unfair than the even-more-undemocratic Senate.</p>
<p><strong>The Senate has become the defining slow-motion crisis of American democracy.</strong></p>
<ul>
<li><strong>The US Senate could be the <a href="https://nymag.com/intelligencer/2020/08/senate-washington-dc-puerto-rico-statehood-filibuster-obama-biden-racist.html" target="_blank" rel="nofollow noopener noreferrer">most structurally racist institution</a>.</strong> In the 1960s, Black people from the South <a href="https://onlinelibrary.wiley.com/doi/abs/10.3162/036298006X201869" target="_blank" rel="nofollow noopener noreferrer">migrated to populous Northern states</a>, eroding their political representation in the Senate. Similarly, recent decades have seen <a href="https://onlinelibrary.wiley.com/doi/abs/10.3162/036298006X201869" target="_blank" rel="nofollow noopener noreferrer">growing Latinx populations in urban areas</a>, primarily located in populous states. As a result, <a href="https://www.nytimes.com/2018/10/14/opinion/dc-puerto-rico-statehood-senate.html" target="_blank" rel="nofollow noopener noreferrer">David Leonhardt found</a> that whites have 0.35 Senators per million people, Blacks have 0.26, Asian-Americans 0.25, and Latinos just 0.19.</li>
<li><strong>Partisanship and rule changes have caused the problem to boil over.</strong> According to <a href="https://govtrackinsider.com/the-senate-has-never-been-as-un-democratic-as-it-was-in-2017-2018-and-minority-rule-could-801e1046af28" target="_blank" rel="nofollow noopener noreferrer">a 2018 analysis</a>, the Senate has never been as undemocratic as it was in 2017-2018. According to this analysis, “in 2017, for the first time, the Senate’s decisions were often made by a coalition of states representing less than half of the country’s population. The median share of senators supporting passed bills, confirmed judges and agency leaders, and other matters dropped to 58% (the lowest since 1930), with those senators representing just 49.5% of the U.S. population (the lowest ever)!”</li>
</ul>
<p>It’s time for us to revisit the Connecticut Compromise, the Devil’s Bargain that allowed for the adoption of the Constitution at the expense of a democratic Senate.</p>
<h2 id="whats-the-role-of-the-senate"><a href="#whats-the-role-of-the-senate" aria-label="whats the role of the senate permalink"></a>What’s the Role of the Senate?</h2>
<p>The Senate is a smaller, more deliberative body than the House of Representatives. You have to be 30 years old to run for the Senate, and in 1790, you would have had an average life expectancy of about <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2885717/" target="_blank" rel="nofollow noopener noreferrer">45 years</a>. Indeed, “Senator” comes from the Latin word “senex,” which means “senior” or “old man.”</p>
<p>Senators run on staggered 6-year terms, not the 2-year term of the House. That means that their terms exceed presidential terms and—unlike representatives—they don’t have to run in every election. While there are 435 representatives in the House, there are only 100 senators. Unlike members of the House, Senate representatives were meant to be appointed by the state legislatures, a process that changed after the 17th amendment in 1913. This meant that the Senate was meant to be a kind of U.N.-but-with-teeth for 13 (and now 50) coequal sovereigns.</p>
<p>These features—insulation from short-term political pressure and a more selective and deliberative group of representatives—are unrelated to the two-per-state design of the US Senate, and don’t benefit from it.</p>
<h2 id="the-connecticut-compromise-was-pragmatic-but-not-wise"><a href="#the-connecticut-compromise-was-pragmatic-but-not-wise" aria-label="the connecticut compromise was pragmatic but not wise permalink"></a>The Connecticut Compromise was Pragmatic, but Not Wise</h2>
<p>Some people defend the Connecticut Compromise as an enduring legacy of founder wisdom. But the Connecticut Compromise wasn’t meant to be wise, it was meant to be pragmatic. </p>
<p>Seven weeks into the Constitutional Convention of 1787, the founders were at an impasse.</p>
<p>Many large states felt that representation should be proportional to population in Congress. As larger states would be contributing more to the treasury and defense, they felt that should have more say.</p>
<p>Smaller states like Delaware and Rhode Island—and representatives from certain larger but slower-growing states like New York (except for Alexander Hamilton, of course)—weren’t having it, and had leverage. These states enjoyed authority and autonomy under the Articles of Confederation. Proportionate representation—plus anticipation of a rapidly growing South and West—would erode their political power.</p>
<p>Connecticut delegates Roger Sherman and Oliver Ellsworth, with the support of Benjamin Franklin, struck a compromise: a bicameral (two-chambered) legislature, with one chamber, the House of Representatives, allocating seats in proportion to population, and the other chamber, the Senate, allocated evenly by state. Benjamin Franklin proposed that the House originate all revenue matters.</p>
<p>Alexander Hamilton hated it. Writing in Federalist 22:</p>
<blockquote>
<p>Its operation contradicts the fundamental maxim of republican government, which requires that the sense of the majority should prevail. Sophistry may reply, that sovereigns are equal, and that a majority of the votes of the States will be a majority of confederated America. But this kind of logical legerdemain will never counteract the plain suggestions of justice and common-sense.</p>
</blockquote>
<p>Madison, in Federalist 62, didn’t want to defend it:</p>
<blockquote>
<p>The equality of representation in the Senate is another point, which, being evidently the result of compromise between the opposite pretensions of the large and the small States, does not call for much discussion.</p>
</blockquote>
<p>The decision to allocate Senate seats was a compromise needed to ratify the Constitution and satisfice an existing power structure—nothing more.</p>
<h2 id="this-is-the-hardest-thing-to-change-about-the-constitution"><a href="#this-is-the-hardest-thing-to-change-about-the-constitution" aria-label="this is the hardest thing to change about the constitution permalink"></a>This is the Hardest Thing to Change about the Constitution</h2>
<p>One possible mechanism of reform is amending the Constitution. Suppose you wanted to change the Senate to allocate seats in proportion to population. Not so fast—Article V of the Constitution writes that:</p>
<blockquote>
<p><strong>The Congress, whenever two thirds of both Houses shall deem it necessary, shall propose Amendments to this Constitution,</strong> or, on the Application of the Legislatures of two thirds of the several States, shall call a Convention for proposing Amendments, which, in either Case, shall be valid to all Intents and Purposes, as Part of this Constitution, when ratified by the Legislatures of three fourths of the several States, or by Conventions in three fourths thereof, as the one or the other Mode of Ratification may be proposed by the Congress; Provided that no Amendment which may be made prior to the Year One thousand eight hundred and eight shall in any Manner affect the first and fourth Clauses in the Ninth Section of the first Article; <strong>and that no State, without its Consent, shall be deprived of its equal Suffrage in the Senate.</strong></p>
</blockquote>
<p>Article V articulates a state right—equal suffrage in the Senate—that cannot be deprived through the Constitutional change process. Put differently: you can change anything in the Constitution (after 1808) through amendments or a convention, but you cannot change this aspect of the Connecticut Compromise.</p>
<p>In practice, even Justice Scalia <a href="https://www.newyorker.com/news/hendrik-hertzberg/the-weirdest-sentence-in-the-u-s-constitution" target="_blank" rel="nofollow noopener noreferrer">once remarked</a> that he didn’t see how the Supreme Court could declare a properly proposed and ratified Constitutional amendment unconstitutional. It is unclear how a future Supreme Court might view a dispute around this kind of Constitutional amendment, although any well-written amendment would begin by changing Article V.</p>
<p>Notwithstanding this speed bump, passing constitutional amendments requires the consent of 3/4 of the states, meaning that the 12 least populous states could block any Senate reform amendment.</p>
<h2 id="finding-a-way-out"><a href="#finding-a-way-out" aria-label="finding a way out permalink"></a>Finding a Way Out</h2>
<h2 id="what-does-a-good-solution-look-like"><a href="#what-does-a-good-solution-look-like" aria-label="what does a good solution look like permalink"></a>What does a good solution look like?</h2>
<p>An improvement to the representation problem has the following qualities:</p>
<ul>
<li>It is legal. In this sense, legal means that it would survive a challenge in the Supreme Court in which the justices were approved by a partisan Senate.</li>
<li>It preserves the “deliberative” aspects of the Senate.</li>
<li>It reduces population inequality in the Senate.</li>
<li>It is politically tractable.</li>
</ul>
<p>A better solution to this problem has these additional properties:</p>
<ul>
<li>New statehood, or reorganized statehood, is incentive-compatible. That means that citizens of prospective new states (Puerto Rico, for instance) should have the opportunity to form a state and be admitted to the Senate without disproportionately diluting power.</li>
<li>Senate proportionality is robust to population shifts. If Wyoming became a booming population center, then Wyoming should have more Senate representation.</li>
<li>It decreases wasted votes and reduces the <a href="https://www.brennancenter.org/sites/default/files/legal-work/How_the_Efficiency_Gap_Standard_Works.pdf" target="_blank" rel="nofollow noopener noreferrer">efficiency gap</a>. Conservatives in California and liberals in Texas have important interests, and they deserve a say.</li>
</ul>
<h3 id="state-swaps"><a href="#state-swaps" aria-label="state swaps permalink"></a>State Swaps</h3>
<p>The Constitution didn’t anticipate political parties, and Washington’s farewell address decried them as “likely in the course of time and things, to become potent engines, by which cunning, ambitious, and unprincipled men will …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ni.chol.as/posts/senate-reform/">https://ni.chol.as/posts/senate-reform/</a></em></p>]]>
            </description>
            <link>https://ni.chol.as/posts/senate-reform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25022747</guid>
            <pubDate>Sun, 08 Nov 2020 03:50:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[QR Codes Aren't Magic]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25022738">thread link</a>) | @allending
<br/>
November 7, 2020 | https://blog.snappymob.com/qr-codes-arent-actually-magic | <a href="https://web.archive.org/web/*/https://blog.snappymob.com/qr-codes-arent-actually-magic">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>Especially after COVID-19 began plaguing the planet, QR codes have been a big part of our daily lives. In this day and age, it’s quite impossible for one to have never seen a QR code, or used one. Even before the pandemic, QR codes had been around us for a while, but many of us — having grown up in the Digital Age — simply accept new technology into our lives without wondering too much about how they work. For most of us, QR codes just look like... square pixelated versions of the alien heptapod symbols in Arrival (2016), that somehow, magically (and really quickly) bring us to a different screen when we scan them.</p>
<!--more-->
<p>So what are these cryptic codes? Are they magic? Clearly they’re not, but how do they work? Before we take you in for the ride, let’s get the basics down.&nbsp;</p>
<p>QR stands for <em>Quick Response</em>, and a QR code is pretty much a barcode (which has been around since the 1950s) except two-dimensional. Because it’s 2D, it can contain more data than a barcode. It can encode over 7000 characters, which is a vast improvement from the standard barcode with a limited capacity of about 20 alphanumeric characters.</p>
<h2>How did they come about?&nbsp;</h2>
<p>In Japan circa 1990s, Denso Wave Incorporated was contacted by manufacturing sites and asked if it was possible to come up with a faster barcode scanning system. This presented a problem as barcodes had a limited capacity, which made the scanning process time consuming for workers no matter how efficient the scanner was. To tackle this, Denso Wave began developing a compact code that can contain more data, including Kanji and Kana characters. The launch of the QR code was later announced in 1994.</p>
<h2>What are they used for?</h2>
<p>The QR code was first used by the auto industry to track parts and products shipped around the globe. Then, gradually, other industries all over the world began joining in. Today, QR codes are used by nearly every physical and digital establishment for quick check-ins, displaying geolocation or contact info, redirecting customers to their websites, etc.</p>
<h2>How do they work?</h2>
<p>Grasping how a QR code works would require understanding the functions of its different parts. With the help of the labelled diagram, we hope to make this palatable for the layman. Let’s break it down.</p>
<p><img src="https://blog.snappymob.com/hs-fs/hubfs/QR%20Structure.png?width=715&amp;name=QR%20Structure.png" alt="QR Structure, modules, separators, alignment, timing, format info, version, labels, black and white" width="715" srcset="https://blog.snappymob.com/hs-fs/hubfs/QR%20Structure.png?width=358&amp;name=QR%20Structure.png 358w, https://blog.snappymob.com/hs-fs/hubfs/QR%20Structure.png?width=715&amp;name=QR%20Structure.png 715w, https://blog.snappymob.com/hs-fs/hubfs/QR%20Structure.png?width=1073&amp;name=QR%20Structure.png 1073w, https://blog.snappymob.com/hs-fs/hubfs/QR%20Structure.png?width=1430&amp;name=QR%20Structure.png 1430w, https://blog.snappymob.com/hs-fs/hubfs/QR%20Structure.png?width=1788&amp;name=QR%20Structure.png 1788w, https://blog.snappymob.com/hs-fs/hubfs/QR%20Structure.png?width=2145&amp;name=QR%20Structure.png 2145w" sizes="(max-width: 715px) 100vw, 715px"></p>
<p>(Image Source: techspot.com)</p>
<p>The tiny squares in a QR code are called <em><strong>modules</strong></em> - black squares would be considered foreground modules, and white ones would be background modules. They don’t always have to be black and white, though, they could be in color too. Most QR codes are in black and white only so decoder softwares easily distinguish the contrast between the background and foreground. If you want your QR code to be colorful, you just have to make sure that the contrast is retained when it is in grayscale / black and white.</p>
<p>The bigger the code, the more rows and columns of modules it will contain. Yup, just like humankind, QR codes come in different shapes, sizes and colors (although there are standards to follow).</p>
<p>There are 40 preset sizes (or, <em><strong>versions</strong></em>) to choose from. Version 1 being the smallest type with 21 rows and 21 columns, and Version 40 being the largest with 177 rows and 177 columns. When a generator produces a code for you, it will determine the suitable QR code version number for you depending on the amount of data you are encoding.</p>
<p>The 3 big squares on 3 corners of the QR code are <em><strong>finder patterns</strong></em>, which help your device camera determine the boundaries of the code and its correct orientation. This is so if the code is rotated, or upside-down, decoders would still be able to read it. These finder patterns are surrounded by a single-module spacing called <em><strong>separators</strong></em> which help decoders separate the finder patterns from the code data.</p>
<p>Connecting each finder pattern are <em><strong>timing patterns</strong></em> that alternate between black and white. These lines tell your decoder software how big the data cells are within the code.</p>
<p>The smaller square (that is distinctively not a finder pattern) on the fourth corner is an <em><strong>alignment pattern</strong></em> that helps the decoder prevent image distortions. Level 1 QR codes (the smallest size of QR codes) do not contain alignment patterns. The bigger the code, however, the more alignment patterns are added.&nbsp;</p>
<p>The 15 bits beside the separators are <em><strong>format and version strings</strong></em> which contain information on the code’s error correction level and the chosen mask pattern for the particular code. Hold on… information on the what and what?</p>
<p><em><strong>Error correction</strong></em> code makes sure that the code is still readable if up to 30% of the code is corrupt. Designers or generators of a code can decide how many levels of error correction they want to include in the code. The higher the level of error correction, the higher percentage of corruption a decoder can read past. However, the higher the level of error correction, the more space it takes up on the QR code, leaving less space for data. In other words, the more space the error correction code takes up, the lower the max numerical characters a QR code can fit. How much error correction a QR code needs probably will depend on where it will be displayed. E.g. A QR code on a paper flyer would need higher error correction than one on a laminated poster placed indoors, and a digital QR code could do with none because it is unlikely to be damaged.</p>
<p>The code is also overlaid by a <em><strong>mask pattern</strong></em>, inverting and retaining certain data areas to “mix it up” / conceal it. Decoder softwares detect the mask type from the format information and demask the QR code before reading the rest of the data. Of course this happens in a matter of milliseconds.</p>
<p><em><strong>Encoded characters </strong></em>- The black and white modules read in a fixed zigzaggy direction (as shown in the image), starting from the bottom right corner, gives the decoder a sequence of data bits that goes something like 001010111…&nbsp;&nbsp;&nbsp;</p>
<p><img src="https://blog.snappymob.com/hs-fs/hubfs/Google%20Drive%20Integration/Copy%20of%20(Writeup)%20QR%20codes%20arent%20actually%20magic-2.png?width=447&amp;name=Copy%20of%20(Writeup)%20QR%20codes%20arent%20actually%20magic-2.png" alt="QR code, zigzag sequence, binary sequence, pattern" width="447" srcset="https://blog.snappymob.com/hs-fs/hubfs/Google%20Drive%20Integration/Copy%20of%20(Writeup)%20QR%20codes%20arent%20actually%20magic-2.png?width=224&amp;name=Copy%20of%20(Writeup)%20QR%20codes%20arent%20actually%20magic-2.png 224w, https://blog.snappymob.com/hs-fs/hubfs/Google%20Drive%20Integration/Copy%20of%20(Writeup)%20QR%20codes%20arent%20actually%20magic-2.png?width=447&amp;name=Copy%20of%20(Writeup)%20QR%20codes%20arent%20actually%20magic-2.png 447w, https://blog.snappymob.com/hs-fs/hubfs/Google%20Drive%20Integration/Copy%20of%20(Writeup)%20QR%20codes%20arent%20actually%20magic-2.png?width=671&amp;name=Copy%20of%20(Writeup)%20QR%20codes%20arent%20actually%20magic-2.png 671w, https://blog.snappymob.com/hs-fs/hubfs/Google%20Drive%20Integration/Copy%20of%20(Writeup)%20QR%20codes%20arent%20actually%20magic-2.png?width=894&amp;name=Copy%20of%20(Writeup)%20QR%20codes%20arent%20actually%20magic-2.png 894w, https://blog.snappymob.com/hs-fs/hubfs/Google%20Drive%20Integration/Copy%20of%20(Writeup)%20QR%20codes%20arent%20actually%20magic-2.png?width=1118&amp;name=Copy%20of%20(Writeup)%20QR%20codes%20arent%20actually%20magic-2.png 1118w, https://blog.snappymob.com/hs-fs/hubfs/Google%20Drive%20Integration/Copy%20of%20(Writeup)%20QR%20codes%20arent%20actually%20magic-2.png?width=1341&amp;name=Copy%20of%20(Writeup)%20QR%20codes%20arent%20actually%20magic-2.png 1341w" sizes="(max-width: 447px) 100vw, 447px"><br>(Image Source: nayuki.io)</p>
<p>Different binary sequences represent different codewords, which include symbols, lowercase letters, uppercase letters, etc. For example, the binary sequence 01110111 represents the letter ‘w’, 00100001 represents the exclamation point ‘!’, and 00100000 represents a space.</p>
<h2><strong>How can you make a QR code?</strong></h2>
<p><span><img src="https://lh3.googleusercontent.com/Mi8ate-UiC0ZpKEoRFn8EUpe5bZDS5O6ggTSK96wPR1OTHx_zoKu_dbS5NvJDpPRsDAt9qdHXkQdfo1sm8Jun4Id0dpS3JjSnmOO51mXv6NT1ql7rb5P0DJc01k-kuw9RYw5vMF2" alt="QR code, generated QR code, snappymob website" width="297"></span></p>
<p>Here’s a QR code generated with <a href="http://www.qr-code-generator.com/"><span>www.qr-code-generator.com</span></a>. Do the patterns make a lot more sense to you now? If you can’t answer in confidence, that’s okay. You’re not going to have to make one by hand, ever. (Unless you want to.)&nbsp;</p>
<p>There are plenty of offline and online QR code generators free for use. All you have to do is key in what you want to encode in the QR code, be it a link to a coupon redemption page, a YouTube video, your social media sites, your contact details, or simply a website homepage.&nbsp;</p>
<p>Most free QR code generators, though, require you to sign up or subscribe to a plan to gain access to more design options and features, such as error correction levels and insights tracking.&nbsp;</p>
<h2><strong>How can QR codes help you?</strong></h2>
<p>Whether you own a business or simply have a web page to share, a QR code could help people reach you easily and quickly. In case you were looking for ideas, here are some of the ways in which using a QR code could greatly benefit you:</p>
<h4><strong>Webpages and Location</strong></h4>
<p>Your customers can get to your website, social media platforms, or map location in a matter of seconds. They don’t have to manually type your website URL, usernames, or addresses into their browsers or maps. They simply need to whip out their phones and scan the QR code to be redirected to you.</p>
<h4><strong>Payment</strong></h4>
<p>Payment is also made easy with QR codes. Most stores enable QR codes for quick payment via e-wallets so customers don’t have to fumble through their wallets for cash and keep others waiting. Some good examples would be GrabPay or ShopeePay, which are enabled at many on and offline merchants in Malaysia.</p>
<p><img src="https://blog.snappymob.com/hs-fs/hubfs/grabpayshopeepay.jpg?width=648&amp;name=grabpayshopeepay.jpg" alt="grabpay, shopeepay, qr code, merchant, scan to pay, app" width="648" srcset="https://blog.snappymob.com/hs-fs/hubfs/grabpayshopeepay.jpg?width=324&amp;name=grabpayshopeepay.jpg 324w, https://blog.snappymob.com/hs-fs/hubfs/grabpayshopeepay.jpg?width=648&amp;name=grabpayshopeepay.jpg 648w, https://blog.snappymob.com/hs-fs/hubfs/grabpayshopeepay.jpg?width=972&amp;name=grabpayshopeepay.jpg 972w, https://blog.snappymob.com/hs-fs/hubfs/grabpayshopeepay.jpg?width=1296&amp;name=grabpayshopeepay.jpg 1296w, https://blog.snappymob.com/hs-fs/hubfs/grabpayshopeepay.jpg?width=1620&amp;name=grabpayshopeepay.jpg 1620w, https://blog.snappymob.com/hs-fs/hubfs/grabpayshopeepay.jpg?width=1944&amp;name=grabpayshopeepay.jpg 1944w" sizes="(max-width: 648px) 100vw, 648px"><br>(Image Source: help.shopee.com.my, grab.com)</p>
<h4><strong>Email and Direct Messaging</strong></h4>
<p>You can embed URL links that lead straight to a ‘compose email’ or ‘compose direct message’ page (for instance, <a href="mailto:hello@snappymob.com">mailto:hello@snappymob.com</a>) into your QR code. For email, this saves your customers up to 10 seconds because it helps them skip the process of opening their email app, tapping on compose email, and typing your email address manually into the recipient bar. For social media, this saves them the effort of opening the app, typing your username into the search bar, and tapping on the message button. This might literally be “a matter of seconds” which seems small, but it keeps people who are interested in your services or products, well, interested. Making things quicker and easier for your patrons is always a good move.</p></span></p><p><label>app insights</label></p>
        
      </div></div>]]>
            </description>
            <link>https://blog.snappymob.com/qr-codes-arent-actually-magic</link>
            <guid isPermaLink="false">hacker-news-small-sites-25022738</guid>
            <pubDate>Sun, 08 Nov 2020 03:48:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why you should stop using Google Alerts]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25022723">thread link</a>) | @fstopmick
<br/>
November 7, 2020 | https://www.karma.fm/p/0SZfbtW/why-you-should-stop-using-google-alerts | <a href="https://web.archive.org/web/*/https://www.karma.fm/p/0SZfbtW/why-you-should-stop-using-google-alerts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="report-contribution-modal" tabindex="-1" role="dialog">
    <div role="document">
        <div>
            

            <div>
                <div>
                    <p>
                        Report a violation of our TBD:
                    </p>

                    <dl>
                        <dt><label for="exclude-links">Dead Link:</label></dt>
                        <dd></dd>
                        <dt><label for="exclude-links">Jerk Vibes:</label></dt>
                        <dd></dd>
                        <dt><label for="exclude-links">Copyright Infringement:</label></dt>
                        <dd></dd>
                        <dt><label for="exclude-links">PII:</label></dt>
                        <dd></dd>
                        <dt><label for="exclude-links">Other:</label></dt>
                        <dd></dd>
                    </dl>

                    </div>
            </div>
        </div>
    </div>
</div></div>]]>
            </description>
            <link>https://www.karma.fm/p/0SZfbtW/why-you-should-stop-using-google-alerts</link>
            <guid isPermaLink="false">hacker-news-small-sites-25022723</guid>
            <pubDate>Sun, 08 Nov 2020 03:45:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stack Videos Horizontally, Vertically, in a Grid With FFmpeg]]>
            </title>
            <description>
<![CDATA[
Score 215 | Comments 43 (<a href="https://news.ycombinator.com/item?id=25022665">thread link</a>) | @rrao84
<br/>
November 7, 2020 | https://ottverse.com/stack-videos-horizontally-vertically-grid-with-ffmpeg/ | <a href="https://web.archive.org/web/*/https://ottverse.com/stack-videos-horizontally-vertically-grid-with-ffmpeg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure>
<img src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/11/stacking-videos.png?resize=678%2C381&amp;ssl=1" alt="stack videos using ffmpeg" title="stacking-videos" data-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/11/stacking-videos.png?resize=678%2C381&amp;ssl=1" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
</figure>


<p>Often times, when you want to compare two videos side-by-side or you want to create an effect during post-processing, you might want to stack videos together. It can get expensive if you end up buying a tool to do this, but, guess what? </p>



<p><strong>FFmpeg offers a variety of tools to help stack videos together – horizontally, vertically, or in a grid fashion. In this tutorial, let’s learn about FFmpeg’s <code>hstack</code> and <code>vstack</code> filters for stacking videos. </strong></p>



<hr>




<h2><span id="How_to_Stack_Videos_Horizontally_using_FFmpeg"></span><strong>How to Stack Videos Horizontally using FFmpeg?</strong><span></span></h2>



<p>“Horizontally stacking videos” refers to placing videos side-by-side (one on the left and the other on the right). </p>



<p>Before you do this, there are a couple of points that you need to consider. </p>



<ol><li>The videos that you want to stack need to have the same height. </li><li> The videos need to have the same pixel format. </li></ol>



<p>The command line is shown below where we try and stack two <code>mp4</code> videos. </p>



<pre><code>ffmpeg -i input0.mp4 -i input1.mp4&nbsp;-filter_complex hstack=inputs=2 horizontal-stacked-output.mp4</code></pre>



<p>The <code>hstack</code> filter has a simple format. You need to specify the number of inputs and it parses that from the beginning portion of the commandline. The order of stacking follows the order of inputs. </p>



<p>Here is a screenshot of what it looks like. </p>



<figure><img src="https://lh6.googleusercontent.com/4FwbqByqDpDpOGTNvpSWSOh6RVE9yzesrQyAyGvaOF1ZjVsycKOlQUjrTmdJRFJWblHjC9gF6zMds0s5w2Yy2w6CVXXme-H-zF8nYoJ496khN0aHXHaWbnwEe41BYmu6c2mdoQb8" alt="stack videos using ffmpeg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>And, here is a video! </p>



<p><iframe frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" data-src="https://player.vimeo.com/video/475731721" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>







<p>Here is another use case. Companies or teams working on video compression often like to compare videos side-by-side in the lab or showcase their work in conferences. FFmpeg’s horizontal stacking is an easy way to do this and achieve a very good result. </p>



<p>Below are two videos encoded at different video quality settings and stacked horizontally. Comparison made simple, right? <em>(note: Vimeo’s choise of bitrate might mess with the comparison, but, when done offline (downloaded), the <code>hstack</code> filter makes comparisons easy!)</em></p>



<p><iframe frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" data-src="https://player.vimeo.com/video/476095363" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>



<hr>



<h2><span id="Stacking_Videos_Vertically_using_FFmpeg"></span><strong>Stacking Videos Vertically using FFmpeg</strong><span></span></h2>



<p>“Vertically stacked videos” results in placing videos one below the other. Unlike in horizontal stacking, inputs need to be having the same width. The command is as shown.&nbsp;</p>



<p>For vertical stacking, we need to use the <code>vstack</code> filter whose syntax is similar to the <code>hstack</code> filter we used in the previous horizontal stacking example.</p>



<pre><code>ffmpeg -i input0.mp4 -i input1.mp4&nbsp;-filter_complex vstack=inputs=2 vertical-stack-output.mp4</code></pre>



<figure><img src="https://lh5.googleusercontent.com/qtyxioWFR54pqwZhX7jgX6HkSG7gCw840GdK78HGHHP7X3sv3fr3Pou9hOMFu2O-e6O7nmCith3U6CM1SpDanhwmIFIBzZUQyaG4T0BJaF9QCdMIPrmMmH0qc9WTK5f-5Nf4-92y" alt="stack videos using ffmpeg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Both functions pretty much use the same commands with a simple distinction, the <a href="https://ffmpeg.org/ffmpeg-filters.html#hstack" target="_blank" rel="noopener"><code>hstack</code></a> and the <a href="https://ffmpeg.org/ffmpeg-filters.html#vstack" target="_blank" rel="noopener"><code>vstack</code></a> under the <code>-filter_complex</code> argument.&nbsp;</p>



<p>Here’s a video of stacking two videos vertically using FFmpeg. </p>



<p><iframe frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" data-src="https://player.vimeo.com/video/475731607" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>



<hr>



<h2><span id="Stacking_Videos_of_Different_Lengths"></span><strong>Stacking Videos of Different Lengths</strong><span></span></h2>



<p>Well, there’s a really nifty ability for both of these to prioritize the length of the shortest video. And as luck would have it the parameter is named <code>shortest</code>, and it’s applicable to both the horizontal and vertical stacking filters. Using <code>shortest=1</code> ensures the shortest length is used. </p>



<p>For example – </p>



<pre><code>ffmpeg -i input0.mp4 -i input1.mp4 -filter_complex hstack=inputs=2:shortest=1 shortest-output.mp4</code></pre>



<p>As a <b>side note</b>, if you run into an error that claims frames are being duplicated, the easiest workaround is to slip the <code>vsync 2</code> parameter into your command, and it worked like a charm.</p>



<h3><span id="Stacking_Videos_of_Different_Lengths_Without_the_shortest_parameter"></span>Stacking Videos of Different Lengths Without the <code>shortest</code> parameter<span></span></h3>



<p>To test what happens in this situation, let’s stack two videos vertically – a 10 second clip and an 18 second clip. You’ll see that the shorter clip just stops after it completes, but the output video continues till the longest of the input clips complete.  </p>



<p><iframe frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" data-src="https://player.vimeo.com/video/475731684" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>











<p>If you want to truncate the clips to the length of the shortest clip, then you need to use the <code>shortest=1</code> parameter. Let’s look at that in the next section.</p>



<h3><span id="Stacking_Videos_of_Different_Lengths_With_the_shortest=1_parameter"></span>Stacking Videos of Different Lengths With the <code>shortest=1</code> parameter<span></span></h3>



<p>In this example, we use the <code>shortest=1</code> command-line parameter and as you can see, the length of the final video is truncated to the length of the shortest of the inputs. </p>



<p><iframe frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" data-src="https://player.vimeo.com/video/475731643" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>



<hr>



<h2><span id="2%C3%972_Grid_of_Videos_using_FFmpeg"></span><strong><strong>2×2 Grid of Videos using FFmpeg</strong></strong><span></span></h2>



<p>We can achieve a 2×2 grid of videos using a combination of the <code>hstack</code> and <code>vstack</code> filters. Let’s start by looking at the command-line and then break it down. It’s actually pretty simple! </p>



<pre><code>ffmpeg \
-i input0.mp4 -i input1.mp4 -i input2.mp4 -i input3.mp4 \
-filter_complex \
"[0:v][1:v]hstack=inputs=2[top]; \
[2:v][3:v]hstack=inputs=2[bottom]; \
[top][bottom]vstack=inputs=2[v]" \
-map "[v]" \
finalOutput.mp4</code></pre>



<p>What’s happening here?</p>



<ul><li>firstly, you need to provide 4 input videos with the same height and width</li><li>next, you stack the first two videos horizontally and call it “top” i.e. <code>[0:v][1:v]hstack=inputs=2[top]</code></li><li>then, you you stack the next two videos horizontally and call it “bottom” i.e. <code>[2:v][3:v]hstack=inputs=2[bottom]</code></li><li>then, you stack <code>top</code> and <code>bottom</code> vertically to create a 2×2 grid. — <code>[top][bottom]vstack=inputs=2[v]</code></li><li>then using the <code>map</code> command, we can extract and push the video track to the output container. </li></ul>



<p>Here is what the video looks like. </p>



<p><iframe frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" data-src="https://player.vimeo.com/video/475771172" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>



<hr>



<h2><span id="3%C3%972_Grid_of_Videos_using_FFmpeg"></span><strong>3×2 Grid of Videos using FFmpeg</strong><span></span></h2>



<p>Along the same lines, here is a 3×2 grid of videos using <code>hstack</code> and <code>vstack</code> filters. </p>



<pre><code>ffmpeg \
-i input0.mp4 -i input1.mp4 \
-i input2.mp4 -i input3.mp4 \
-i input4.mp4 -i input5.mp4 \
-filter_complex \
"[0:v][1:v][2:v]hstack=inputs=3[top];\
[3:v][4:v][5:v]hstack=inputs=3[bottom];\
[top][bottom]vstack=inputs=2[v]" \
-map "[v]" \
finalOutput.mp4</code></pre>



<p><iframe frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" data-src="https://player.vimeo.com/video/475780643" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>



<hr>



<h2><span id="Conclusion"></span>Conclusion<span></span></h2>



<p>That’s it folks. Now you know how to stack videos together horizontally, vertically, and in a grid. This is very useful in comparing videos and also creating fun effects along the way! </p>



<p>If you enjoyed this post, do check out the rest of<a href="https://ottverse.com/category/ffmpeg/"> <strong>OTTVerse’s FFmpeg tutorials</strong></a> to learn more about this amazing media editing and compression software!  </p>

	</div></div>]]>
            </description>
            <link>https://ottverse.com/stack-videos-horizontally-vertically-grid-with-ffmpeg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25022665</guid>
            <pubDate>Sun, 08 Nov 2020 03:36:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everything you wanted to know about drone light shows]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25022274">thread link</a>) | @zuhayeer
<br/>
November 7, 2020 | https://verge.aero/everything-about-drone-light-shows/ | <a href="https://web.archive.org/web/*/https://verge.aero/everything-about-drone-light-shows/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
	
<figure><img loading="lazy" width="2000" height="1126" src="https://verge.aero/wp-content/uploads/2020/05/1_jWBjNhkYW18BwHjpukUUzQ.jpeg" alt="Philadelphia Drone Light Show" srcset="https://verge.aero/wp-content/uploads/2020/05/1_jWBjNhkYW18BwHjpukUUzQ.jpeg 2000w, https://verge.aero/wp-content/uploads/2020/05/1_jWBjNhkYW18BwHjpukUUzQ-300x169.jpeg 300w, https://verge.aero/wp-content/uploads/2020/05/1_jWBjNhkYW18BwHjpukUUzQ-768x432.jpeg 768w, https://verge.aero/wp-content/uploads/2020/05/1_jWBjNhkYW18BwHjpukUUzQ-1536x865.jpeg 1536w" sizes="(max-width: 2000px) 100vw, 2000px"><figcaption>Verge Aero flying over Franklin field for Philadelphia Drone Light Show</figcaption></figure>



<p>“Amazing”, “Beautiful”, “Incredible”, “Unreal”, “Brought tears to my eyes”.</p>



<p>These are all comments that repeatedly appeared in response to a viral Facebook video of a drone light show that <a href="https://verge.aero/">Verge Aero</a> flew to show gratitude for healthcare and essential workers in Philadelphia. The response was overwhelming, and these words demonstrate that when properly executed, drone light shows are a mesmerizing and powerful experience. Since then, we’ve received many questions about our technology, and we’d like to share our responses with a wider audience.</p>



<iframe src="https://player.vimeo.com/video/415494003" width="640" height="360" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe>



<h2><strong>What is a drone light show, exactly?</strong></h2>



<p>Drone light shows are performed by illuminated, synchronized, and choreographed groups of drones that arrange themselves into various aerial formations. Almost any image can be recreated in the sky by a computer program that turns graphics into flight commands and communicates them to the drones.</p>



<p>In recent years, drone shows have migrated from the university laboratory to being deployed at scale on prominent events around the world. We were originally inspired by this 2012 <a href="https://www.ted.com/talks/vijay_kumar_robots_that_fly_and_cooperate">TED video</a> featuring the University of Pennsylvania’s Dean of Engineering, Vijay Kumar, demonstrating drone fleets doing all kinds of stunning maneuvers. Later, pioneering work was done in Europe by the <a href="https://www.spaxels.at/">Spaxels Research Initiative</a>, <a href="https://collmot.com/">Collmot</a>, and <a href="http://www.veritystudios.com/">Verity</a>.<a href="https://www.intel.com/"> Intel</a> has done the most to popularize the concept, flying drone shows on big events such as the Super Bowl halftime show and the Winter Olympics.</p>



<figure><img loading="lazy" width="1000" height="562" src="https://verge.aero/wp-content/uploads/2020/05/1_xIWK_MTjYpP_xFAK9zP8gg.jpeg" alt="Philadelphia Drone Light Show LOVE" srcset="https://verge.aero/wp-content/uploads/2020/05/1_xIWK_MTjYpP_xFAK9zP8gg.jpeg 1000w, https://verge.aero/wp-content/uploads/2020/05/1_xIWK_MTjYpP_xFAK9zP8gg-300x169.jpeg 300w, https://verge.aero/wp-content/uploads/2020/05/1_xIWK_MTjYpP_xFAK9zP8gg-768x432.jpeg 768w" sizes="(max-width: 1000px) 100vw, 1000px"><figcaption>First Responders filming LOVE during Philadelphia Drone Light Show</figcaption></figure>



<h2><strong>How do drone shows work?</strong></h2>



<p>Let’s clear up one thing first: drone light shows are <strong>not </strong>powered by <a href="https://en.wikipedia.org/wiki/Skynet_%28Terminator%29">Skynet</a>, the artificial intelligence network depicted in <em>The Terminator</em>! Drones used in shows are not self-aware, can’t think for themselves, and make no real-time decisions. Instead, like obedient servants, they follow specific commands sent to them and can’t deviate!</p>



<p>The process for creating a show is quite straightforward. First, the design team creates a storyboard timeline showing the desired images and effects. These looks are then animated in a specialized piece of software that translates them into synchronized flight paths for each drone, and usually a soundtrack is created to accompany the show. Complete shows are sent to the drones via radio signal from a ground control station operated by a pilot. When the pilot is satisfied that everything is safe and ready to go, the show starts, and the drones take off to draw the storyboard in the sky.</p>



<figure><img loading="lazy" width="960" height="638" src="https://verge.aero/wp-content/uploads/2020/03/Mazatlan-2.jpg" alt="verge aero flying a drone light show in Mazatlan for Carnaval de Mazatlan" srcset="https://verge.aero/wp-content/uploads/2020/03/Mazatlan-2.jpg 960w, https://verge.aero/wp-content/uploads/2020/03/Mazatlan-2-300x199.jpg 300w, https://verge.aero/wp-content/uploads/2020/03/Mazatlan-2-768x510.jpg 768w" sizes="(max-width: 960px) 100vw, 960px"><figcaption>Verge Aero flies a show in Mazatlan for Carnaval 2020</figcaption></figure>



<p>Creating a system that can be flown safely and repeatedly requires a lot of clever engineering work. Verge Aero’s drones and software were designed by our engineers specifically for performing shows. Our custom drones are missing some things normally found on drones, like cameras, and include unique features, such as a blindingly bright LED light source.</p>



<p>Verge Aero’s design software lets users select graphics and special effects and place them in a timeline, similar to those found in video editing software. This software calculates the flight paths of each drone to guarantee they don’t collide in the air, and generates a full 3D rendering of the show to ensure it looks exactly as intended. Every drone is sent a unique program and the ground control station monitors each drone over a local, encrypted network for maximum safety.</p>



<p>The flight crew uses a detailed dashboard display on the ground station to prepare drones for flight and continuously monitor status. The drones themselves carry multiple radios operating simultaneously, away from busy WiFi frequencies, to ensure communications are maintained even in busy and noisy radio environments.</p>



<p>Shows are flown by certified pilots, experts in relevant aviation subject matter, including regulations and weather. Prior to every show, checklists are used to make sure everything is in order: drones are fully operational, batteries are charged, and the flight area is clear. Once these checks are complete, the pilot presses <strong>GO</strong> and the drones take off on their mission!</p>



<figure><img loading="lazy" width="2700" height="1800" src="https://verge.aero/wp-content/uploads/2020/03/FIG2019-2700x1800.jpg" alt="guitar drone light show at Festival Internacional del Globo" srcset="https://verge.aero/wp-content/uploads/2020/03/FIG2019-2700x1800.jpg 2700w, https://verge.aero/wp-content/uploads/2020/03/FIG2019-300x200.jpg 300w, https://verge.aero/wp-content/uploads/2020/03/FIG2019-768x512.jpg 768w, https://verge.aero/wp-content/uploads/2020/03/FIG2019-1536x1024.jpg 1536w, https://verge.aero/wp-content/uploads/2020/03/FIG2019-2048x1365.jpg 2048w" sizes="(max-width: 2700px) 100vw, 2700px"><figcaption>Guitar in drone light show at Festival Internacional del Globo</figcaption></figure>



<h2><strong>Will drones replace fireworks?</strong></h2>



<p>Fireworks shows are increasingly criticized for their negative environmental impact—they are noisy, polluting, and wasteful. Concerns are regularly raised around their impact on sensitive wildlife populations, as well as military veterans experiencing PTSD. What’s more, in many locations, fireworks displays have been banned altogether, due to the increased risk of wildfires.</p>



<p>These and other factors have led many people to consider replacing fireworks displays with alternatives—and drone light shows are perfectly positioned to fill the gap.</p>



<div><figure><img loading="lazy" src="https://verge.aero/wp-content/uploads/2020/05/1_tWamVl5u_EH8BWg5Nmm3ZQ.jpeg" alt="Philadelphia Drone Light Show Stethoscope" width="286" height="391" srcset="https://verge.aero/wp-content/uploads/2020/05/1_tWamVl5u_EH8BWg5Nmm3ZQ.jpeg 1000w, https://verge.aero/wp-content/uploads/2020/05/1_tWamVl5u_EH8BWg5Nmm3ZQ-220x300.jpeg 220w, https://verge.aero/wp-content/uploads/2020/05/1_tWamVl5u_EH8BWg5Nmm3ZQ-768x1049.jpeg 768w" sizes="(max-width: 286px) 100vw, 286px"><figcaption>Verge Aero flies a stethoscope for frontline workers at the Hospital of the University of Pennsylvania</figcaption></figure></div>



<p>In many cases, drone shows have been used successfully as a great complement to fireworks displays. However, as a new and exciting form of entertainment, drones have much more to offer. They are capable of a far greater range of effects than fireworks, and their capacity for sophisticated choreography gives them vastly more potential for storytelling in the sky. Drones can also be deployed in more constrained environments where fireworks would never be allowed.</p>



<p>When you think about it, fireworks actually have quite a limited repertoire. Usually, a handful of effects are repeated over and over again, just in varying combinations, sizes, colors and intensities. Why settle for this when you can have dynamic, repositionable 3D pixels capable of generating virtually unlimited imagery? Drones offer far more creative options than fireworks. In fact, it’s easy to envision that as drone shows become more commonplace, people will one day look back on fireworks displays as being quite mundane in comparison.</p>



<p>Regardless, the transition from fireworks to drones will happen gradually. Fireworks shows will be with us for some time to come, if for no other reason than that they are fairly inexpensive to stage. But as drone shows become more affordable, we can expect to see events using them more frequently.</p>



<h2><strong>Why haven’t I seen more shows?</strong></h2>



<p>Even Wal-Mart now sells drones, so why aren’t we seeing more light shows? The problem is that successful show execution requires different technologies that are only now maturing. Innovations usually take time to disseminate, and drone shows are no different. A number of factors have limited the uptake of drone shows before now:</p>



<ul><li>High cost</li><li>Need for regulatory approval</li><li>Expensive and limited insurance options</li><li>Labor intensive operations</li><li>Lack of efficient show design tools</li><li>Safety requirements</li></ul>



<p>The use of specialized drones with high-precision avionics drives high cost. Labor intensive operations also contribute, whether it’s wrangling rudimentary control software or preparing finicky drones for flight.</p>



<p>High operating expenses are possibly acceptable for the Super Bowl or the Olympics, but are not viable for most events. Nonetheless, things are changing, and Verge Aero’s innovations are helping to make drone light shows more accessible to a far wider range of budgets.&nbsp;</p>



<figure><img loading="lazy" width="1400" height="399" src="https://verge.aero/wp-content/uploads/2020/05/1_GwmlzLjRyU-BpqmpEpLzhA.jpeg" alt="Verge Aero X1 drones ready for flight" srcset="https://verge.aero/wp-content/uploads/2020/05/1_GwmlzLjRyU-BpqmpEpLzhA.jpeg 1400w, https://verge.aero/wp-content/uploads/2020/05/1_GwmlzLjRyU-BpqmpEpLzhA-300x86.jpeg 300w, https://verge.aero/wp-content/uploads/2020/05/1_GwmlzLjRyU-BpqmpEpLzhA-768x219.jpeg 768w" sizes="(max-width: 1400px) 100vw, 1400px"><figcaption>Verge Aero X1 drones ready for flight</figcaption></figure>



<h2><strong>How much do drone light shows cost?</strong></h2>



<p>Like many new technologies, drone light shows were extremely expensive at first, and they’re still more expensive than desired. But as with computers and flat panel TVs, prices are decreasing over time. Drone light shows will go mainstream as the technology matures. The tools developed by Verge Aero already make it possible to do more for less!</p>



<p>The main driver of cost is the number of drones being flown. It clearly costs a lot more to put on a 500-drone show than a 50-drone show. In addition to the drones themselves, labor, freight, and logistics all add expense.</p>



<p>A small show that’s easy to deploy costs as little as $20,000. But larger and more complicated shows can easily cost many times this number. Here’s a list of factors that impact price:</p>



<ul><li>Drone quantity</li><li>Show design complexity</li><li>Show coordination and rehearsal time</li><li>Airspace authorization and regulatory compliance</li><li>Shipping and logistics</li><li>Crew travel and accommodation</li></ul>



<h2><strong>What is Verge Aero doing differently?</strong></h2>



<p>To make drone shows more affordable, we introduced a few innovations to streamline the process and reduce the amount of work required.</p>



<figure><img loading="lazy" width="1200" height="550" src="https://verge.aero/wp-content/uploads/2020/03/swarm_550.jpg" alt="drone swarm for PNAU All of Us" srcset="https://verge.aero/wp-content/uploads/2020/03/swarm_550.jpg 1200w, https://verge.aero/wp-content/uploads/2020/03/swarm_550-300x138.jpg 300w, https://verge.aero/wp-content/uploads/2020/03/swarm_550-768x352.jpg 768w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption>Drones swarming for PNAU’s music video All of Us</figcaption></figure>



<h3>Simplified Show Design</h3>



<p>Historically, drone light shows were manually created using a series of applications including animation software like<a href="https://www.blender.org/"> Blender</a>—which was an extremely tedious and limiting process. Even worse, the programmer had to check that vertices in Blender <strong>never </strong>overlapped during animation, because that would mean drones colliding in the air. The output then needed to be transferred to at least one more program to prepare for flight. All this is an extremely unsafe process because it’s prone to human error.&nbsp;</p>



<p>A far better way is to use a unified software application with an easy-to-use interface, like the Verge Aero Design Studio, which automatically handles the anti-collision calculations. Cues are created in the built-in animation software and easily manipulated. Once the design process is complete, the software removes the possibility of human error by deconflicting flight paths, identifying potential issues or mistakes in the show design, and simulating the performance via a rendering pipeline—all without any human intervention.</p>



<p>This software allows designers to generate content with a few key presses, instead of through the laborious processes of using animation tools or writing code. Effects such as complex flocking, as seen in this<a href="https://youtu.be/7DQ4covPEyE"> All of Us music video by PNAU</a>, are automatically created by an effects generator in the Verge Aero Design Studio. Effects created by one designer can easily be …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://verge.aero/everything-about-drone-light-shows/">https://verge.aero/everything-about-drone-light-shows/</a></em></p>]]>
            </description>
            <link>https://verge.aero/everything-about-drone-light-shows/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25022274</guid>
            <pubDate>Sun, 08 Nov 2020 02:34:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remote Work: How the alternative has become the new norm]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25021471">thread link</a>) | @martin_crd
<br/>
November 7, 2020 | https://remoteworkers.net/blog/remote-work-how-alternative-has-become-new-norm | <a href="https://web.archive.org/web/*/https://remoteworkers.net/blog/remote-work-how-alternative-has-become-new-norm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The debate on the impact telework has on employee productivity &amp; morale is one that has slowly aged with the improvement of technology, but never so important to discuss than in the current global pandemic state the world is faced with.</p><p>For decades the working class has enjoyed, and even thrived in the conventional 9-to-5 office workday with very little contention. In fact, most of the well-known productivity techniques are centered around the premise that employees can only maximize team cohesion &amp; communication when working in a controlled work environment like the office.</p><p>But with the rise of the digital age and need to travel, the world has started to realize the value and need for remote work and set in place internal measures to promote alternative work methods that benefit the workforce.<br>
&nbsp;</p><h2>Reimagining the 9-to-5 workday could improve productivity</h2><p>The contemporary 9-to-5, eight-hour workday was imagined by American labor unions in the 1800s and normalized by Henry Ford in the 1920s. Most employees today simply accept this narrative because it’s what they have gotten so acquainted with. But despite the growing popularity in the demand for remote and flexible work, the need for a change in work culture has been met with much skepticism from managers. A recent study conducted by Remote Workplace Study explores the prime obstacles to implementing a flexible workplace policy:&nbsp;</p><ul><li>Company’s long-standing resistance to change &nbsp;</li><li>Privacy</li><li>Lack of understanding about the benefits of remote work</li><li>Fear of how it will impact the overall company culture</li><li>Technology requirements</li><li>Data security</li></ul><p>Understandably, managers have reservations about changing traditional work culture. Most concerns center around losing control of assessing team cohesiveness and potential reduction in employee productivity &amp; focus. But despite this, change is inevitable. In fact, most studies confirm an increase in productivity, working “smarter” and willingness to work over-time when employees are given the flexibility to choose when and how to work.&nbsp;</p><h2>Millennials are driving the demand for flexible and remote work&nbsp;</h2><p>As of today, millennials (those born between 1981 and 1996) account for almost 50% of the global workforce and are expected to grow to 75% by 2025. This means that the need for companies to adopt flexible and remote work policies is more compelling today than ever before in order to attract and retain a younger, skilled workforce.&nbsp;</p><h2>There are equal benefits to jumping on the remote-work bandwagon for both companies and employees:</h2><p>There are equal benefits to jumping on the remote-work bandwagon for both companies and employees:</p><h3>For Companies</h3><ul><li>Cost savings (office &amp; overhead costs)</li><li>Increase in productivity</li><li>Employee retention &amp; reduced turnover</li><li>Profitability (companies save avg. $11, 000 &nbsp;per part-time telecommuter)</li><li>Environmental benefits (less commuting to work reduces carbon footprint)</li><li>Improved inclusivity and diversity (easier reach and accessibility to skilled talent from different demographics, races, and people with disabilities from all over the world)</li></ul><h3>For Employees</h3><ul><li>Improved work-life balance</li><li>Flexible schedule</li><li>No commute (time and cost savings)</li><li>Location independence (work from home/travel while working)</li><li>More time to spend with family</li><li>Expense savings (transportation, gas, &amp; freedom &nbsp;to live in low-cost cities) &nbsp;</li></ul><h2>The world’s largest firms have endorsed remote working policies in the wake of Covid19</h2><p>It’s no secret that the novel Coronavirus pandemic has played an integral role in the sudden surge of remote work policies implemented across companies worldwide. Big corporations such as Twitter, Facebook, Google, Amazon, &amp; Microsoft have adopted such changes with Twitter and Square CEO Jack Dorsey announcing that his employees can work remotely indefinitely.&nbsp;</p><blockquote><p>“... the work-from-home revolution is shaping the future of the workplace.”</p></blockquote><p>Improved inclusivity and diversity (easier reach and accessibility to skilled talent from different demographics, races, and people with disabilities from all over the world)</p><p>In closing, albeit reservations from conservative and outdated work practices, the future of the work environment is remote and flexible work. In the age of the internet, connecting with skilled professionals has become easier and accessible. Thanks to online professional platforms like remoteworkers.net, companies have access to a wider pool of highly experienced talent and job-seekers can find their ideal remote jobs. Companies would be wise to evolve with the growth in remote work trends in order to become more competitive &amp; improve productivity.</p><h2>Looking for a remote job?</h2><p>Thanks to the internet, connecting skilled professionals with remote-friendly companies has never been easier. Whether you’re an experienced professional looking for your dream remote job or a remote-friendly company looking to hire the best talent, join <a href="https://remoteworkers.net/signup">Remote Workers</a>&nbsp;today!&nbsp;</p></div></div>]]>
            </description>
            <link>https://remoteworkers.net/blog/remote-work-how-alternative-has-become-new-norm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25021471</guid>
            <pubDate>Sun, 08 Nov 2020 00:36:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why do things go right? – Safety Differently]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25021366">thread link</a>) | @absolute100
<br/>
November 7, 2020 | https://safetydifferently.com/why-do-things-go-right/ | <a href="https://web.archive.org/web/*/https://safetydifferently.com/why-do-things-go-right/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<div id="attachment_3805"><p><img aria-describedby="caption-attachment-3805" src="http://www.safetydifferently.com/wp-content/uploads/2018/09/josue-isai-ramos-figueroa-741921-unsplash-1-300x218.jpg" alt="" width="300" height="218"></p><p id="caption-attachment-3805">Photo by Josue Isai Ramos Figueroa on Unsplash</p></div>
<p>In his 2014 <em>Safety I and Safety II: The past and future of safety management</em>, Erik Hollnagel makes the argument that we should not (just) try to stop things from going wrong. Instead, we need to understand why most things go right, and then ensure that as much as possible indeed goes right. It seems so obvious. Yet it is light years away from how most organizations ‘do’ safety today, with their focus on low numbers of lagging indicators, incidents and injuries.</p>
<p>That said, many organizations have now begun to recognize the severe organizational deficiencies, cultural problems and ethical headaches that lag indicators create for them. Most will be familiar with the following sorts of things:</p>
<ul>
<li>Numbers games and the hiding or renaming of injuries and incidents;</li>
<li>Counterproductive and credibility-straining sloganeering (‘Zero Harm!’);</li>
<li>Short-termism (driven by quarterly figures);</li>
<li>Creative case management and a lack of compassion for those who do get hurt in the course of work (think of the cynical use of ‘suitable duties’ to keep someone off the injury stats or lost time books);</li>
<li>The misdirection of accountability through sanctioning, dismissal or exclusion of those who have been hurt in the past (just cancel the contractor’s access card, for instance);</li>
<li>The statistical insignificance of any change in typical lagging indicators (‘We went from 3 lost time injuries last year to 1 this year! And we worked a total of 5 million person-hours!’ …<em>Uhmm, right</em>);</li>
<li>Organizational learning disabilities and cultures of risk secrecy;</li>
<li>Worker cynicism, mistrust and disenchantment;</li>
<li>Cases of outright management fraud that have got managers dismissed or even in jail.</li>
</ul>
<p>Erik’s insight is the hinge on which the transition to Safety Differently turns. Let’s not stare ourselves silly at the lowest possible injury and incident numbers, with the ridiculous and counterproductive Siren Song of ‘Zero Harm’ (See Sheratt &amp; Dainty, 2017, for how ‘Zero’ is linked to more fatalities and serious injuries)as the ultimate paradise we want to reach. Deming said it long before anybody in the Resilience community said it: get rid of targets, slogans and exhortations. They get in the way of allowing your people to produce quality work (Deming, 1982). So instead, let’s learn why things go right and find out what we can do to make it even more so. Safety is not about the <em>absence&nbsp;</em>of negatives; it is about the <em>presence&nbsp;</em>of capacities. The field of Resilience Engineering, formally founded at a meeting in Söderköping in Sweden over a decade ago (Dekker, 2006)was of course driven by this logic. I witnessed Erik and others forcefully making this very point, from many different angles, for a week in a room full of peers and stakeholders.</p>
<p>One way to illustrate this point, as Erik indeed does (and others now do as well) is by way of a Gaussian, or normal curve. The curve shows that the number of the things that go wrong (the left side of the curve) is tiny. On the right side of the curve are the heroic, unexpected surprises (a Hudson River landing, for instance) that fall far outside what people would normally experience or have to deal with. In between, the huge bulbous middle of the figure, sits the quotidian or daily creation of success. This is where good outcomes are made, despite the organizational, operational and financial obstacles, despite the rules, the bureaucracy, the common frustrations and obstacles. This is where work can be hard, but is still successful. The way to make even further progress on safety, suggests this figure, is not by trying to make the red part of things that go wrong even smaller, but by understanding what accounts for the big middle part where things go right. And then enhancing the capacities that make it so. That way, we don’t make the red part smaller by making the red part smaller. We make the red part smaller by making the white part bigger. Research by René Amalberti tells us that it is indeed likely that this is <em>the&nbsp;</em>way to make progress on safety in already safe systems (Amalberti, 2001, 2006, 2013). In those systems, we have milked the recipes for how to prevent things from going wrong to the maximum already. We have many layers of protection in place. We have rules to the point of overregulation. We monitor, record, investigate and standardize the designs people work with. Ever more things targeted at the red part are not going to make it any smaller. The complexity of the system won’t let us. And in fact, the more we do to make that part smaller with what we already know (more rules, more limits on people, more technology and barriers) may in fact contribute to novel pathways to breakdown, accidents and failures (Dekker, 2011).</p>
<div id="attachment_3799"><p><img aria-describedby="caption-attachment-3799" src="http://www.safetydifferently.com/wp-content/uploads/2018/09/Picture1.png" alt="" width="939" height="633" srcset="https://safetydifferently.com/wp-content/uploads/2018/09/Picture1.png 939w, https://safetydifferently.com/wp-content/uploads/2018/09/Picture1-768x518.png 768w" sizes="(max-width: 939px) 100vw, 939px"></p><p id="caption-attachment-3799">The way to make the red part (unwanted outcomes) on the left smaller is not by making it impossible for things to go wrong (as we’ve done almost everything in that regard already). We make the red part smaller by making the white part bigger: focusing on why things go right and enhancing the capacities that make it so. Figure by Kelvin Genn.</p></div>
<p><em>Shifting the paradigm</em></p>
<p>The question that most organizations yearn to have answered, though, is this: what is going to take the place of their long-held and easily communicated total recordable injury frequency rate? As Thomas Kuhn (1970)pointed out, people are unwilling to relinquish a paradigm—despite all its faults—if there is no plausible, viable alternative to take its place.</p>
<p>A few years back, I was working, together with some students, with a large health authority which employed some 25,000 people. The patient safety statistics were dire, if typical: one in thirteen of the patients who walked (or were carried) through the doors to receive care were hurt in the process of receiving that care. 1 in 13, or 7%. These numbers weren’t unique, of course. They were also problematic. Because what exactly is ‘nosocomial harm,’ harm that originates in a hospital? What is ‘medical error’ and when is it putatively responsible for the adverse event that happened to the patient? Indeed, when exactly does the patient become that ‘one’ out of thirteen? These are important (and huge) epistemological and ontological questions. I have vociferously commented on them before (and I didn’t exactly make friends in the field, for example by claiming how safe gun owners are in comparison to doctors) (Dekker, 2007).</p>
<p>But it’s not the point here. When we asked the health authority what they typically found in the one case that went wrong—the one that turned into an ‘adverse event,’ the one that inflicted harm on the patient—here is what they came up with. After all, they had plenty of data to go on: one out of thirteen in a large healthcare system can add up to a sizable number of patients per day. So in the patterns that all this data yielded, they consistently found:</p>
<ul>
<li>Workarounds</li>
<li>Shortcuts</li>
<li>Violations</li>
<li>Guidelines not followed</li>
<li>Errors and miscalculations</li>
<li>Unfindable people or medical instruments</li>
<li>Unreliable measurements</li>
<li>User-unfriendly technologies</li>
<li>Organizational frustrations</li>
<li>Supervisory shortcomings</li>
</ul>
<p>It seemed a pretty intuitive and straightforward list. It was also a list that firmly belonged to a particular era in our evolving understanding of safety: that of the person as the weakest link, of the ‘human factor’ as a set of mental and moral deficiencies that only great systems and stringent supervision can meaningfully guard against. In that sort of logic, we’ve got great systems and solid procedures—it’s just those people who are unreliable or non-compliant:</p>
<ul>
<li>People are the problem to control</li>
<li>We need to find out what people did wrong</li>
<li>We write or enforce more rules</li>
<li>We tell everyone to try harder</li>
<li>We get rid of bad apples</li>
</ul>
<p>Many organizational strategies, to the extent that you can call them that, were indeed organized around these very premises. Poster campaigns that reminded people of particular risks they needed to be aware of, for instance. Or strict surveillance and compliance monitoring with respect to certain ‘zero-tolerance’ or ‘red-rule’ activities (e.g. hand hygiene, drug administration protocols). Or a ‘just culture’ process that got those lower on the medical competence hierarchy more frequently ‘just-cultured’ (code for suspended, demoted, dismissed, fired) than those with more power in the system. Or some miserably measly attention to supervisor leadership training.</p>
<p>We were of course interested to know the extent to which these investments in reducing the ‘one in thirteen’ had paid off. They hadn’t. The health authority was still stuck at one in thirteen.</p>
<p><em>What would Erik do?</em></p>
<p>This is when we asked the Erik Hollnagel question. We asked: “What about the other twelve? Do you even know why they go right? Have you ever asked yourself that question?” The answer we got was “no.” All the resources that the health authority had were directed toward investigating and understanding the ones that went wrong. There was organizational, reputational and political pressure to do so, for sure. And the resources to investigate the instances of harm were too meager to begin with. So this is all they could do. We then offered to do it for them. And so, in an acutely unscientific but highly opportunistic way, we spent time in the hospitals of the authority to find out what happened when things went well, when there was no evidence of adverse events or patient harm.</p>
<p>When we got back together after a period of weeks, we compared notes. At first we couldn’t believe it, thinking that what we had found was just a fluke, an irregular and rare irritant in data that should otherwise have been telling us something quite different. But it turned out that everybody had found that in the twelve cases that go right, that don’t result in an adverse event or patient harm, there were:</p>
<ul>
<li>Workarounds</li>
<li>Shortcuts</li>
<li>Violations</li>
<li>Guidelines not followed</li>
<li>Errors and miscalculations</li>
<li>Unfindable people or medical instruments</li>
<li>Unreliable measurements</li>
<li>User-unfriendly technologies</li>
<li>Organizational frustrations</li>
<li>Supervisory …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://safetydifferently.com/why-do-things-go-right/">https://safetydifferently.com/why-do-things-go-right/</a></em></p>]]>
            </description>
            <link>https://safetydifferently.com/why-do-things-go-right/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25021366</guid>
            <pubDate>Sun, 08 Nov 2020 00:25:41 GMT</pubDate>
        </item>
    </channel>
</rss>
