<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 21 Feb 2021 20:29:07 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 21 Feb 2021 20:29:07 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Art of Finishing Things (or how to stop the never-ending perfectionism loop)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26202468">thread link</a>) | @mjoksimovic
<br/>
February 20, 2021 | https://unstructed.tech/2021/02/20/art-of-finishing-things/ | <a href="https://web.archive.org/web/*/https://unstructed.tech/2021/02/20/art-of-finishing-things/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				












<h2>Background</h2>



<p>You would think that starting or sustaining at anything is hard enough, right? But once you do start and once you do keep doing it, assuming that thereâ€™s an actual end to it, youâ€™d expect it to be easy, no? Since you overcame the static friction and (hopefully) managed to do it for long enough to bring it to closure, finalizing the thing (whatever the thing is) should be a no brainer, right?</p>



<p>WRONG! </p>



<p>I can tell you, firsthand, that you are so damn wrong. Doubly so if you are somewhere high on the perfectionist spectrum.</p>



<p>Finishing a task, finalizing a project or wrapping up your bachelor thesis â€“ they all come with specific set of issues. And this article is all about tackling them.</p>



<h2>Real-life story</h2>



<p>I finished all my exams and was discussing with my mentor which subject to tackle for my thesis work. Everything run by so fast and I just felt like I never gave my 100%. I did pretty good overall but I just felt like I never demonstrated my best. This was a time to make up for that.</p>



<p>â€œHow much time do I actually have to submit this thesis?â€. It was around late February.</p>



<p>â€œWell, the latest you have is by October, but Iâ€™d strongly suggest you to aim for June. No need to drag it any further than thatâ€.</p>



<p>Almost eight months in worst case. Hell, even if I wrote half a page a day, I could tackle this in three months. EASILY.</p>



<p>Now, you have to understand that, by being a perfectionist and if youâ€™re reading this â€“ you probably are one, <span>you tend to categorize tasks in two categories â€” ULTRA IMPORTANT or NOT IMPORTANT AT ALL</span>. The latter ones are fine â€“ you probably donâ€™t need this article to have those tackled. But the ones that you categorize as ULTRA IMPORTANT, well hellâ€™s bells, <span>unless you apply some tools of the trade, those tasks are doomed to last FOREVER</span>.</p>



<p>Needless to say in which category did my thesis end up, right? It was my personal work of art, expressed by letters being grouped into words. Every chapter would be a mind blowing one. Every comma had a pure holistic reasoning behind it. It was my terrestrial legacy to all of the readers and all future generations to come.</p>



<p>Two months and, I kid you not, all I had was a title. Well, a rather good one I should say â€“ â€œUsing audio-fingerprinting technique for the purpose of identification and categorization of an audio sampleâ€. But still, itâ€™s ALL I had in TWO months. And it wasnâ€™t even written in a required format, but rather hanging in my notes app. At least it ticked all of my shitboxes â€“ it sounded holistic and Iâ€™m sure the academia would fall over itâ€™s butt once I released it to wilderness â€¦</p>



<p>â€œOkayâ€, I thought, â€œat least I have a month to wrap it up. I can do two pages a day or so and Iâ€™ll be good to goâ€. What a dumb-ass thinking it was â€¦</p>



<p>Iâ€™d like to say that it took me a month to finish, but thatâ€™d be a lie. It took me seven months and twenty eight days of randomly writing thoughts here and there, widening and narrowing down all the topics that Iâ€™d love to cover â€¦ And the clock was actively working against me. The paranoia started kicking in. Frankly, I probably would never even have finished it if it wasnâ€™t for my professor who contacted me in late September to tell me that I have two days to deliver a finished and printed version. He loved the progress and he approved everything that I covered so far, but he needed it finished. F*ck!</p>



<p>Not only did I finish the whole thesis in 48 hours (I was literally writing the day and night; the only time when I wasnâ€™t writing was during the 8 hours when I had work to attend to), but it turned out pretty good! Probably not how I envisioned it, but regardless. And I liked it.</p>



<p>Now, I would love to say that I learned my lesson here and that my master thesis took a different course. Not exactly. However, Iâ€™ve learned a trick â€“ <span>I wrote the intro and conclusion before I wrote the middle part</span>. Combined with a fixed deadline, it actually did wonders. And Iâ€™ll elaborate on that now â€¦</p>



<h2>The â€œLifeâ€™s Workâ€ problem</h2>



<p>You know, Iâ€™m not exactly sure if this is just my problem or a rather generic one. I would bet on the latter.</p>



<p><span>Be it a thesis, a short-term task or a whole project that you are working on, we tend to believe that it just has to be perfect. Good enough is not good enough</span>. But, why so?</p>



<p>I canâ€™t speak for everyone, but when it comes to me, I actually think that Iâ€™m afraid of being judged. Especially for something that I do care about. Iâ€™m afraid that someone is going to look at what I did and just be like â€œmeh, itâ€™s okayâ€, or â€œmeh, it could have been betterâ€. The sheer thought of that scares the living shit out of me.</p>



<p>Obviously, the only way of preventing someone from judging you (yes, YOU!) is to make it your lifeâ€™s work. Pour all time and energy into it, trying to make it perfect.</p>



<p>And you know whatâ€™s the problem with â€œlifeâ€™s workâ€? You either drop dead before youâ€™re finished, or you give up on it. But one thing is guaranteed â€“ they take shitload of time and you probably miss bunch of other opportunities in the process. Worst of all? <span>Once you do do finish (assuming that you do so), and once the initial excitement wears of, you realize that it wasnâ€™t even that important in the first place</span>. It becomes yet another â€œmeh, itâ€™s okayâ€ on your shelf. And you move on, determined not to repeat the same mistake again.</p>



<h2>Deadline as a medium of creative drive</h2>



<p>You know, Iâ€™m a programmer. And Iâ€™ve been so my whole life. And <span>if there is ONE thing that is guaranteed to trigger my vomit reflex it has to be the mention of a â€œdeadlineâ€</span>. Seriously.</p>



<p>Yet, <span>I would lie if I told you that thereâ€™s been anything remotely more efficient than having a fixed deadline</span>. The date when you have to have your project finished, or the date when you have to turn your homework or thesis in.</p>



<p>You would assume that NOT having a deadline is a proper way to fire up your creative juices, right? Because, putting a TIMELINE on a creative work beats the purpose of creativity, right? </p>



<p>Wrong. Partially, at least.</p>



<p>If you havenâ€™t done so already, Iâ€™d strongly suggest you go and read <a href="https://www.goodreads.com/book/show/18077903-creativity-inc?ac=1&amp;from_search=true&amp;qid=UIM1mGMSpj&amp;rank=1" target="_blank" rel="noreferrer noopener">Creativity, Inc</a>. Itâ€™s written by Ed Catmull, a guy who happens to be a brain behind 3D graphics and many of the Pixarâ€™s cartoons. He also happens to be a President of Disneyâ€™s animation studio. </p>



<p>He argues that the deadlines are THE BEST way to bring your creativity to anything that is useful. Like, you know, a Toy Story for example. And how so? Well, by treating it as a medium, and not as a whip. You set a deadline for a check-up, but you donâ€™t threaten people with being beaten if they miss it. You have people commit to deliver SOMETHING by the fixed date and then you decide how to proceed. Rinse &amp; repeat until itâ€™s perfect!</p>



<p><span>But, what do you do if you DONâ€™T have a fixed deadline (e.g. youâ€™re working on your personal pet project, like, a blog post for example)? Well, you MAKE one</span>! And just to ensure that you do have actual stakeholders waiting for the â€œoutcomeâ€, you make a public commitment!</p>



<h2>Public Commitment as a viable alternative</h2>



<p>If youâ€™ve been following my â€œworkâ€ on Instagram or LinkedIn, you probably have noticed that I usually publish a screenshot of the new article that Iâ€™m starting to work on. And you might have been wondering, and rightfully so, WHY am I doing that? Whatâ€™s the purpose of publishing a screenshot of an unpublished article?</p>



<p>That is my public commitment! That is how I make an artificial deadline and how I make you a stakeholder. By publishing the screenshot, Iâ€™m passively announcing that Iâ€™m working on something new and that you should expect the final version soon. And there it is. My artificial 5-days deadline is set and my creative juices are on fire now!</p>



<p><span>So, in case that you want to work on ANYTHING that doesnâ€™t have a strong deadline, go and make one</span>! If youâ€™re about to embark on a diet â€“ announce that you are planning to â€œlose X kilograms by â€¦..â€. If youâ€™re working on a task, tell your boss that you will be finished by next week. Or, if youâ€™re about to start blogging â€¦ well, announce it! Make your public commitment and then, the only thing that youâ€™ll be left with is â€“ having to do it ğŸ™‚ Because, you wouldnâ€™t want to be a liar, wouldnâ€™t you? ğŸ™‚</p>



<h2>Your turn!</h2>



<p>Whatever it is that you are working on (or planning to do), go and announce WHEN will it be finished! Make a PUBLIC COMMITMENT. Make artificial stakeholders.</p>



<p><strong>You donâ€™t have to make it PUBLIC PUBLIC</strong> though. Sharing it with your inner circle, your family or, you know, your boss, is absolutely OK as well. <span>Whatâ€™s important is that<strong> you commit to at least one person </strong>and that person has to keep you accountable</span>!</p>



<p>I guarantee that once you scratch the power that lies under the surface of public commitment, youâ€™ll have hard time NOT finishing anything ever again!</p>



<h2>Conclusion</h2>



<p>Be it a task, a project, a thesis or a general goal that you want to achieve, putting end to what you started is as complex as starting and sustaining at it is. Combined with a â€œlifeâ€™s workâ€ problem where we tend to categorize things as ultimate expression of our creativity and skilfulness, we have a perfect recipe for a never-ending crusade.</p>



<p>One of the best ways to tackle this is a battle tested method of a deadline and commitment. Commit yourself either to your best friend or by announcing it publicly, and do make sure to create stakeholders and set expectations. This, in turn, will be one of the best driving forces both to keep you on track of what matters and to ensure that you are actually going to close.</p>



<p>Good luck and let me know how you did!</p>



<h2>Useful resources</h2>



<p>Unfortunately, I donâ€™t have that many resources directly related to the subject of â€œfinishingâ€ things. Hence, I will recommend some of the things that, among other things, tackle some of the topics that I wrote about:</p>



<ul><li>Creativity, Inc. by Ed Catmull â€“ itâ€™s not a self-help book but it deals with the topic of creativity and how Pixar achieved it. Youâ€™ll get to â€¦</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://unstructed.tech/2021/02/20/art-of-finishing-things/">https://unstructed.tech/2021/02/20/art-of-finishing-things/</a></em></p>]]>
            </description>
            <link>https://unstructed.tech/2021/02/20/art-of-finishing-things/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26202468</guid>
            <pubDate>Sat, 20 Feb 2021 08:03:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mastodon Is Bound to Fail]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26202281">thread link</a>) | @todsacerdoti
<br/>
February 19, 2021 | https://raccoon.onyxbits.de/blog/mastodon-social-network-review/ | <a href="https://web.archive.org/web/*/https://raccoon.onyxbits.de/blog/mastodon-social-network-review/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>I have a problem with this blog. It used to be powered by Wordpress, but the <bbr title="Content Management System">CMS pissed me off without end over the years, so I migrated to Hugo. That fixed a lot of the problems, except the main one: it is still (mostly) a Wordpress style blog, in which posts are fat content pieces of content, consisting of a  title and at least one paragraph of text. This is utterly unsuitable for things like posting status updates or sharing thoughts. Twitter does way better here, but itâ€™s a proprietary platform, Iâ€™m not willing to bind myself to.</bbr></p>

<p>So, how about Mastodon then? Looks like Twitter, works like Twitter, but is federated and sadly, also a lost cause.</p>

<h2 id="the-thing-mastodon-gets-wrong">The thing, Mastodon gets wrong</h2>

<p>To me, it seems like Mastodon is trying to be a social network, while, ironically, completely failing to understand the network effect. Itâ€™s the right tool for the wrong people (or the wrong tool for the right people? I donâ€™t know).</p>

<p>Letâ€™s face it, what we want is a platform where you can have an intelligent conversation, where our privacy is respected and where we stay in control. But thatâ€™s not at all the audience, social media is build for. The ecosystem is entirely structured around all those gone gaga self promoters and would be celebrities that have nothing to contribute except â€œthemselvesâ€ and are willing to sacrifice any last piece of dignity, if only it increases their following, so they have a number to show to their sponsors. The deal influencers enter is simple: bring in two new followers to the platform, get (an old) one for free. Keep any of the money, you may make from sponsors. Now go and post pictures of your lunch before (and after) you eat it.</p>

<p>
  
  <span>An ugly truth about building a better mousetrap</span>
  
  
It's the shitty parts, that made the original design so successful.

</p>
                             
                             

<p>And that in a nutshell is why Mastodon is going to fail: it simply is not build for the people who bring in other people, as it lacks any reward mechanism for multipliers. Social media is (and has to be) inherently anti-privacy in order to allow for monetizing â€œmy personal lifeâ€. A commodity, available to everyone without any skill requirement to exploit, so thereâ€™s no shortage of dipshits, willing to take the deal. Most fail, but even in doing so, still promote the networks.</p>

<h2 id="quo-vadis">Quo vadis</h2>

<p>So, Mastodon has a choice. Either continue on the path of mimicking Twitter (without getting the crucial part right) and stay a niche product. Or (actively) attract marketeers, influencers and other attention whores, by promising them an audience while becoming a federated ad platform.</p>

<p>Either way, itâ€™s not for me.</p>
</div></div>]]>
            </description>
            <link>https://raccoon.onyxbits.de/blog/mastodon-social-network-review/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26202281</guid>
            <pubDate>Sat, 20 Feb 2021 07:16:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Skeptics Introduction to Crypto Art and NFTs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26202152">thread link</a>) | @zuhayeer
<br/>
February 19, 2021 | https://justincone.com/posts/nft-skeptics-guide/ | <a href="https://web.archive.org/web/*/https://justincone.com/posts/nft-skeptics-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://justincone.com/images/warning.png" alt="Warning"></p><p>Since writing this guide, Iâ€™ve become increasingly concerned about <a href="https://memoakten.medium.com/the-unreasonable-ecological-cost-of-cryptoart-2221d3eb2053" target="_blank">the enormous environmental impact of cryptoart</a>, which currently relies on the Ethereum blockchain.</p><p><strong>The energy usage of Ethereum is ludicrous.</strong> Yes, there are solutions <a href="https://spectrum.ieee.org/computing/networks/ethereum-plans-to-cut-its-absurd-energy-consumption-by-99-percent" target="_blank">in the works</a>, but theyâ€™re going to take a lot of time to implement.</p><p>Iâ€™m going to leave the contents below online for reference, but I might decide to take them down (or radically alter them) soon.</p><p>Please be responsible. Donâ€™t jump into this scene until a clear, viable, environmentally-responsible pathway has opened up.</p><p>â€”<strong>2021.01.20</strong></p><h2 id="who-is-this-guide-for">Who is this guide for?</h2><p>This guide is for digital artists and designers curious about cryptoart and NFTs.</p><p>If youâ€™re reading this, youâ€™ve probablyâ€¦</p><ul><li><p>heard about <a href="https://decrypt.co/51270/beeple-nft-sale" target="_blank">Beeple selling $582,000 USD of cryptoart in 5 minutes</a>.</p></li><li><p>been confused by what NFTs are.</p></li><li><p>wondered if you could get in on this whole thing before it disappears.</p></li></ul><p>This guide has been intentionally written as a high-level introduction for general audiences.</p><h2 id="what-this-guide-isnt">What this guide isnâ€™t</h2><p>This is not a technical guide.</p><p>Iâ€™m not going to explain the details of the technology involved. You can visit the <a href="#further-reading">further reading</a> section below if you want to go deep.</p><p>If youâ€™re the type of person who likes to start sentences with, â€œWell, <em>actuallyâ€¦</em>â€ then <strong>this guide is not for you.</strong> Please go away.</p><p><img src="https://justincone.com/images/cryptopunks.png" alt="Cryptopunks"><em><a href="https://larvalabs.com/cryptopunks" target="_blank">Cryptopunks</a>, a beloved cryptoart experiment and early NFT</em></p><h3 id="this-is-unotu-an-endorsement-of-cryptoart">This is <u>not</u> an endorsement of cryptoart</h3><p>While the cryptoart scene is interesting and sometimes exciting, it currently has <a href="https://digiconomist.net/ethereum-energy-consumption/" target="_blank">a massive energy consumption problem</a>.</p><p>Weâ€™ll get into this <a href="#isnt-crypto-really-bad-for-the-environment">later</a>, but please understand that the environmental impacts of the cryptoart market are sizable.</p><h2 id="who-am-i">Who am I?</h2><p>Iâ€™ve been a designer, technologist, and communicator for over 20 years.</p><p>Many guides to cryptoart and NFTs are written by a) groups that stand to benefit from them or b) zealous individuals who drank an entire gallon of crypto kool-aid in one sitting.</p><p>I am neither.</p><p>Iâ€™ll shoot straight, and Iâ€™ll skip the jargon and acronyms when I can.</p><p>(And trust me: I havenâ€™t been drinking the kool-aid. I find this topic fascinating, but Iâ€™m a skepticâ€”as youâ€™ll see below.)</p><h3 id="disclaimer">Disclaimer</h3><p>Iâ€™m not a cryptoart expert. Iâ€™m a nerd who saw a need for this guide, and I filled it.</p><p>Iâ€™ll regularly correct and update this guide, keeping track of major changes and giving credit for contributions in the <a href="#changelog">Changelog</a> below.</p><p>âœ‰ï¸ <em><a href="mailto:me@justincone.com">Contact me</a> with questions or ideas. Donâ€™t be shy! Iâ€™m nice.</em></p><h3 id="why-did-i-create-this-guide">Why did I create this guide?</h3><p>I donâ€™t know. It was fun? Iâ€™m weird.</p><h2 id="what-is-cryptoart">What is cryptoart?</h2><p>Thereâ€™s no universally accepted definition of cryptoart. For now, letâ€™s use this:</p><blockquote><p>Cryptoart is art that uses blockchain technology in its creation and/or distribution.</p></blockquote><h2 id="okay-so-what-is-blockchain-technology">Okay, so what is blockchain technology?</h2><p>Think of blockchains as giant spreadsheets<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> that can be viewed by anyone. I know: <em>Boooring!</em></p><p>But wait! These spreadsheets have âœ¨special rulesâœ¨.</p><ul><li><p>Youâ€™re not allowed to delete or change rows in the spreadsheet.</p></li><li><p>You can only add a new row after the last row. (Weird, right?)</p></li><li><p>When you add a row to the spreadsheet, a network of computers do a bunch of super complex math to confirm that what you added is okay. (Even weirder.)</p></li><li><p>If you try to sneak a change into the spreadsheetâ€”like, I donâ€™t know, give yourself a million bucksâ€”that change will be rejected by the network.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p></li></ul><p>Just like normal spreadsheets, blockchains are great for keeping track of transactions.</p><h3 id="um-transactions">Umâ€¦ transactions?</h3><p>Yeah, you know: I give you something, you give me something in return. Transactions.</p><p>Blockchains store transactions in a way that is viewable by anyone but editable only under certain conditions.</p><p>(See the <a href="#okay-so-what-is-blockchain-technology">special spreadsheet rules above</a>, in case you already forgot them.)</p><h2 id="what-are-nfts">What are NFTs?</h2><p>Now weâ€™re getting to the juicy stuff. ğŸ‹</p><p>NFT stands for Non-Fungible Token. But what does that mean?</p><p><em>Donâ€™t worry about it.</em> Seriously. Other guides try to explain fungibility, but Iâ€™m not going to. Itâ€™s boring and too technical for our purposes.<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></p><p>The keyword to remember is <strong>token.</strong> Weâ€™ll come back to it in a minute.</p><p>For now, letâ€™s <strong>think of NFTs as digital collectibles.</strong> In the real world, pretty much anything can be collectible, given the right conditions: stamps, books, PokÃ©mon cards, spoons.</p><p>(No really, <a href="https://www.ebay.com/b/Souvenir-Spoons/bn_7006309973" target="_blank">people collect spoons</a>.)</p><p>The same is true in the digital world. <strong>NFTs are a <a href="#okay-so-what-is-blockchain-technology">blockchain technology</a></strong> that allow people to collect and trade just about anything, includingâ€¦ wait for itâ€¦ <em>art.</em></p><p><img src="https://justincone.com/images/mona.jpg" alt="Modern Mona Lisa"><em>This terrible thing, which I created in five minutes, could totally be an NFT.</em></p><p>Theoretically, NFTs can be used for lots of other stuff, too: issuing movie tickets, selling video game items, or even proving ownership of real estate.</p><p>But letâ€™s stay focused: weâ€™re talking about digital art here.</p><h2 id="what-is-digital-art">What is â€œdigital artâ€?</h2><p>Oh no, weâ€™re not going down <em>that</em> rabbit hole.</p><p>Youâ€™ll have to define digital art for yourself. Whatever definition you have in your head is probably good enough for our purposes.</p><p>Letâ€™s keep moving.</p><p>There are two basic steps to creating an NFT:</p><ol><li>Make a thing.</li><li>Tokenize the thing.</li></ol><h2 id="1-make-a-thing">1. Make a thing</h2><p>NFTs start as digital art (i.e. stuff you already know how to make):</p><ul><li>still images</li><li>GIFs</li><li>video loops (with or without audio)</li><li>music</li></ul><h3 id="what-about-physical-art-cant-i-turn-a-sculpture-or-a-painting-into-an-nft">â€œWhat about physical art? Canâ€™t I turn a sculpture or a painting into an NFT?â€</h3><p>Kind of. Itâ€™s trickier than you think. Weâ€™ll get to it in a second.</p><p>(If you really canâ€™t wait, <a href="#creating-physical-objects">jump ahead</a>. But donâ€™t get mad at me if youâ€™re confused.)</p><h2 id="2-tokenize-the-thing">2. Tokenize the thing</h2><p>Remember <a href="#what-are-nfts">earlier</a> that we said NFTs are tokens? Follow along:</p><ul><li><p>For our purposes, think of a token as a digital link to something youâ€™ve made.</p></li><li><p>Tokens live on blockchains, which weâ€™ve <a href="#okay-so-what-is-blockchain-technology">already established</a> are great for keeping track of transactions.</p></li><li><p>When you â€œtokenizeâ€ a digital artwork, youâ€™re linking something youâ€™ve made to a blockchain, which can be useful for proving ownership of that thing (among other things).</p></li></ul><h3 id="wait-there-are-_multiple_-blockchains">â€œWait, there are <em>multiple</em> blockchains?â€</h3><p>Oh yeah, there are loads of blockchains. You can even <a href="https://dzone.com/articles/how-to-create-your-own-cryptocurrency-blockchain-i" target="_blank">create your own</a>.</p><p>For NFTs, Ethereum is currently the most popular blockchain.<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup></p><p>This is important: <strong>the token by itself is not cryptoart.</strong></p><p>The NFT (remember: T is for token) merely <em>points</em> to something else and says, â€œHey, this thing and I are joined at the hip. Weâ€™re inseparable. Think of us as <strong>one</strong>.â€</p><p><img src="https://justincone.com/images/nft-diagram.jpg" alt="Diagram showing the relationship between an NFT and a hosted digital image."><em>Token + media = cryptoart</em></p><h3 id="how-do-you-link-a-token-to-a-digital-thing">How do you link a token to a digital thing?</h3><p>Typically, you link a token to a digital thing youâ€™ve made by attaching some extra information (metadata) to the NFT. That extra info includes a link to an image, video, GIF, song, etc. thatâ€™s hosted somewhere else.<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup></p><p>This arrangement begs a few questions:</p><ul><li>Where will the â€œofficialâ€ digital asset be hosted?</li><li>How can collectors ensure that the asset wonâ€™t be changed by the artist?</li><li>What happens if the asset host goes down? Or disappears?</li></ul><p>There are solutions to these problems in the works,<sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup> and some of them get technical pretty fast<sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup>. This topic goes beyond the introductory level, so letâ€™s keep moving for now.</p><h2 id="understanding-ownership">Understanding â€œownershipâ€</h2><h4 id="if-the-nft-isnt-the-actual-image-animation-music-etc-that-i-created-cant-people-just-copy-my-artwork">â€œIf the NFT isnâ€™t the actual image, animation, music, etc. that I created, canâ€™t people just copy my artwork?â€</h4><p>Remember: <strong>The complete cryptoart is the token <em>and</em> the media you created.</strong> So they can copy your image or your GIF or whateverâ€¦ but it doesnâ€™t really matter.</p><p>Depending on how you see things, this is either great news or a big problem.</p><p><em>(By the way, the inherently copiable nature of digital art is the #1 thing I see NFT newbies struggling withâ€”and for good reason. Itâ€™s confusing.)</em></p><h3 id="okay-lets-work-through-this-together">Okay, letâ€™s work through this together.</h3><p>An NFT says that one specific copy of your digital mediaâ€”the one listed in the NFTâ€™s metadataâ€”is the one that matters.</p><p><em>We discussed this above. If you missed it, <a href="#token--media--cryptoart">go back</a> and make sure you understand it before moving on.</em></p><p>So you could have literally millions of copies of your sweet CG teapot floating around the web, but the owner of your cryptoart only cares about the â€œofficialâ€ copy linked to the NFT.</p><h4 id="im-sorry-but-thats-insane">â€œIâ€™m sorry, but thatâ€™s insane.â€</h4><p>At first blush, <em>I agree.</em> But letâ€™s step back for a second.</p><p>For a few bucks, you can find and print a high-resolution copy of Cindy Shermanâ€™s â€œUntitled #96.â€ Hereâ€™s a copy of it <em>right here:</em></p><p><img src="https://justincone.com/images/sherman.jpeg" alt="Cindy Sherman's 'Untitled #96'"><em>â€œUntitled #96â€ by Cindy Sherman (1981)</em></p><p>In 2011, a print of that photograph <a href="https://en.wikipedia.org/wiki/Untitled_96" target="_blank">sold for $3.89 million USD during a Christie's auction</a>â€”setting a record for the most expensive photo ever sold (at that time).&nbsp;</p><p>Then, as now, people could easily reproduce the photo. Somehow, though, this didnâ€™t stop the photo from selling for a boatload of cash.</p><h4 id="thats-different-people-were-buying-one-specific-print-of-the-photograph-one-created-by-the-artist-and-it-was-a-print-of-the-highest-quality">â€œThatâ€™s different. People were buying one specific print of the photograph, one created by the artist. And it was a print of the highest quality.â€</h4><p>What if we broke into Cindy Shermanâ€™s private studio, stole the original negative of the photograph, and then produced a print that was identical in quality to the one sold during the 2011 auction?</p><p>Would we be able to sell it for the same amount? Or more?</p><h4 id="no">â€œNo.â€</h4><p>Why not?</p><h4 id="it-wouldnt-be-official-it-wouldnt-be-from-the-artist">â€œIt wouldnâ€™t be official. It wouldnâ€™t be from the artist.â€</h4><p>Ah! Interesting. So we need to be able to trace the print back to the artist somehow?</p><h4 id="okay-i-see-where-youre-going-an-nft-traces-the-official-artwork-back-to-the-artist-and-the-blockchain-can-show-all-the-subsequent-owners-including-the-current-one">â€œOkay, I see where youâ€™re going. An NFT traces the official artwork back to the artist, and the blockchain can show all the subsequent owners, including the current one.â€</h4><p>Exactly.</p><h4 id="but-what-if-we-hung-our-copy-right-next-to-the-official-print-in-an-identical-frame">â€œBut what if we hung our copy right next to the official print in an identical frame?â€</h4><p>It wouldnâ€™t matter.</p><h4 id="what-yes-it-would-you-wouldnt-be-able-to-tell-them-apart">â€œWhat?! Yes, it would! You wouldnâ€™t be able to tell them apart.â€</h4><p>The owner would know that the official version is the one in that <em>exact</em> spot on the wall, in that specific building.</p><p>Itâ€™s the same with NFTs: They point to a specific copy of a digital artwork â€œhangingâ€ in a specific place on the internet.</p><h4 id="i-still-think-its-crazy-that-people-can-copy-my-images-that-devalues-the-art">â€œI still think itâ€™s crazy that people can copy my images. That devalues the art!â€</h4><p>Maybe. But it doesnâ€™t <em>always</em> work that way.</p><p>I bet your mother or your uncle has a magnet on their refrigerator of one of Monetâ€™s famous Water Lilies paintings.</p><p>Amazon currently returns nearly 800 items when you search for â€œMonet Water Lilies,â€ including neckties, mouse pads, and face masks.</p><p><img src="https://justincone.com/images/mask.jpeg" alt="Monet face mask"><em>A horrendous idea for a face mask. And yet, there it is.</em></p><p>Despite these countless copies, Monetâ€™s Water Lilies paintings <a href="https://en.wikipedia.org/wiki/Water_Lilies_%28Monet_series%29#The_paintings_at_auction" target="_blank">routinely fetch tens of millions of dollars</a> at auctions.&nbsp;</p><p>Perhaps the prevalence of reproductions in our culture has â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://justincone.com/posts/nft-skeptics-guide/">https://justincone.com/posts/nft-skeptics-guide/</a></em></p>]]>
            </description>
            <link>https://justincone.com/posts/nft-skeptics-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26202152</guid>
            <pubDate>Sat, 20 Feb 2021 06:38:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What on Earth is this Encryption Scheme?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26201723">thread link</a>) | @soopurman
<br/>
February 19, 2021 | https://capnfabs.net/posts/wtf-encryption-scheme-synology-diskstation-nas/ | <a href="https://web.archive.org/web/*/https://capnfabs.net/posts/wtf-encryption-scheme-synology-diskstation-nas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody" id="content"><p>I have taken a couple terabytes of photos over the years, and have a mild phobia of deleting data, so I keep my photos on a <a href="https://www.synology.com/en-global">Synology DiskStation NAS</a>. Iâ€™ve got all the files on the thing:</p><ul><li>backed up to the cloud</li><li>encrypted,</li></ul><p>because back in 2016, my <a href="https://www.instagram.com/p/BMpgY9zAGbD/">apartment was broken into and thieves took all the electronics</a>. Iâ€™ve been slightly paranoid ever since.</p><p>The Synology NAS generally works pretty well, but the interface for decrypting a drive after booting is <em>extremely</em> painful. Itâ€™s about 10 clicks, a username, two different passwords, and a UI that is kinda wonky (itâ€™s a desktop in a web browser)? Hereâ€™s a screengrab:</p><figure><video alt="Unlocking an encrypted drive in the Synology DiskStation UI" src="https://capnfabs.net/posts/wtf-encryption-scheme-synology-diskstation-nas/decrypt.mp4" width="588" muted="" autoplay="" loop="" playsinline=""></video><figcaption><p>22 seconds is my personal speed record.</p></figcaption></figure><p>There are alternative solutions to this â€“ you can set it up so that it <a href="https://www.synology.com/en-au/knowledgebase/DSM/tutorial/File_Sharing/How_to_encrypt_and_decrypt_shared_folders_on_my_Synology_NAS#t4_1">reads the encryption key from a USB disk on startup, for example</a> â€“ but, if Iâ€™m worried about the whole thing being stolen, itâ€™s not a good idea to leave the encryption keys plugged into the thing, and itâ€™s also not a nice UX to find and plug in a USB before turning the thing on.</p><p>Thisâ€¦ seems kinda silly to me, and something that should be solvable with âœ¨ <em>technology</em> âœ¨. Iâ€™m only ever accessing this from one computer, for example, and every modern operating system has a good credential storage system (think <a href="https://support.apple.com/guide/keychain-access/what-is-keychain-access-kyca1083/mac"><em>Keychain Access</em></a> on OSX or <a href="https://support.microsoft.com/en-us/windows/accessing-credential-manager-1b5c916a-6a16-889f-8581-fc16e8165ac0"><em>Credential Manager</em></a> on Windows 10). So, maybe my computer could take care of supplying encryption keys to the DiskStation!</p><p>I went looking for options, and discovered that the DiskStation Software has a <a href="https://global.download.synology.com/download/Document/Software/DeveloperGuide/Package/FileStation/All/enu/Synology_File_Station_API_Guide.pdf">publicly-documented web API (pdf)</a>. At least, a <em>mostly</em> publicly documented web API â€“ thereâ€™s no documentation for the methods to mount and unmount encrypted shares.</p><p>That web API is <em>also</em> used by the desktop software though! So it should theoretically be possible to use <a href="https://developer.mozilla.org/en-US/docs/Learn/Common_questions/What_are_browser_developer_tools">browser devtools</a> to see exactly <em>what</em> is being sent to the DiskStation. ğŸ¤”</p><p>So, I clicked on all the right things in the Web UI, got to the bit where you type in the password, opened the devtools to the â€œNetwork Requestsâ€ tab, typed in <code>abc123</code> as my password, hit â€œsendâ€ and then watched for the requests:</p><figure><img src="https://capnfabs.net/posts/wtf-encryption-scheme-synology-diskstation-nas/encryption-dot-cgi.png" alt="Firefox devtools screenshot, showing a request to an ominously-named 'encryption.cgi'"><figcaption><p>hmmmmmmmmmmm</p></figcaption></figure><p>Hmmm, that <code>encryption.cgi</code> looks a little ominous. I wonder whatâ€™s in it?</p><figure><img src="https://capnfabs.net/posts/wtf-encryption-scheme-synology-diskstation-nas/public-key.png" alt="Firefox devtools screenshot, showing huge blob of base16-encoded public-key"><figcaption><p>Yep, looks like encryption, alright</p></figcaption></figure><p>Ok, a public key. And then the web interface loads a spinner, and makes a request to <code>entry.cgi</code>. Letâ€™s take a look at the contents of that request:</p><figure><img src="https://capnfabs.net/posts/wtf-encryption-scheme-synology-diskstation-nas/ciphertext.png" alt="A devtools screenshot, showing a jumbled blob of base64-encoded data with the phrases 'rsa' and 'aes' sprinkled throughout."><figcaption><p>HMMMMMMMMMMMMMMMM</p></figcaption></figure><p>Ok, so if we want to send a magic request to mount the encrypted share, itâ€™s not going to be enough to supply the encryption password; weâ€™re also going to need to figure out how to <em>correctly</em> supply it â€“ how to <em>encrypt</em> the encryption password, so to speak.</p><h2 id="so-what-is-this-crypto-system">So, what is this crypto system?</h2><p>Right. Hereâ€™s a high-level overview:</p><ul><li>First, we fetch the <code>public_key</code> from the server. Thatâ€™s the call to the <code>encryption.cgi</code> endpoint we saw earlier. This isnâ€™t actually the entire public key, itâ€™s only <em>part</em> of it. In fact, this is a 4096-bit integer, encoded in base-16. The <em>other</em> part of the public key is the number <code>0x10001 == 65537</code>, which is hardcoded into the JavaScript.</li><li>Then, we generate 501 bytes worth of random text from the charset <code>0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ~!@#$%^&amp;*()_+-/</code> (thatâ€™s 77 different possible characters; I have no idea why this set was chosen though!).</li><li>We encrypt that random text using our public key. The encryption method is <a href="https://tools.ietf.org/html/rfc3447#section-7.2">RSA with PKCS1.5 padding</a>.</li><li>We MD5-hash that random text a bunch of times with an 8-byte salt. The end result of this is 48 bytes which certainly <em>look</em> pretty random to the naked eye.</li><li>We split those 48 bytes into two components â€“ a 32-byte (== 256-bit) key, and a 16-byte initialisation vector.</li><li>Remember the password we typed in? Yeah, Iâ€™d forgotten about it too! But now, we <em>finally</em> take that password, and encrypt it with AES in Cipher Block Chaining (CBC) mode with PKCSv7 padding, using the 256-bit key and 16-byte IV we derived in the previous step.</li><li>We bundle the RSA ciphertext, the 8-byte salt, and the AES ciphertext together and ship them across to the DiskStation.</li></ul><p>Still with me? Itâ€™s ok if that didnâ€™t all make loads of sense yet; weâ€™ll now go over the interesting bits more closely.</p><h3 id="symmetric--asymmetric-ciphers">Symmetric / Asymmetric Ciphers</h3><p>Fundamentally, weâ€™re using two cryptographic algorithms in concert:</p><ul><li><strong>RSA</strong>: RSA is an <em>asymmetric</em> cryptographic algorithm. Asymmetric cryptographic systems have two <em>keys</em> â€“ a public key, which allows only for encryption of the data, and a private key, which allows for both encryption <em>and</em> decryption.</li><li><strong>AES</strong>: AES is a <em>symmetric</em> cryptographic algorithm. In symmetric cryptography, all parties have the same key, and that key allows you to both encrypt and decrypt.</li></ul><p>It seems weird that weâ€™re using both of these at the same time, right? But both systems have weaknesses, and mixing them together is an attempt at minimising the disadvantages of both schemes.</p><p>The problem with <em>symmetric</em> crypto systems by themselves is that you need a way to get that one key to every party that needs it. But you canâ€™t just <em>send</em> it to them, because you donâ€™t have a secure channel yet! Your options are:</p><ul><li>Share the key over a different trusted channel beforehand, or</li><li>have both parties derive the same shared key (from e.g. some partial data that they negotiate over the wire beforehand).</li></ul><p>Asymmetric crypto doesnâ€™t have this problem â€“ if youâ€™re able to share a key that can only be used for encrypting and not for decrypting, then the decryption keys never have to leave the recipient machine. You can then encrypt some text, and nobody except for the recipient can decrypt it â€“ not even you! Put it on the internet, write it on a banner attached to the back of a propeller plane â€“ the message will only be readable by the intended recipient.</p><figure><img src="https://capnfabs.net/posts/wtf-encryption-scheme-synology-diskstation-nas/your-ciphertext-here.jpg" alt="A propeller plane with a banner reading 'your ciphertext here'"></figure><p>Asymmetric cryptography is <em>slow</em>, though, so doing it for lots of data is going to really hurt performance.</p><p>A common solution is to simply <em>make up</em> a symmetric key, perform some symmetric encryption using that key, then encrypt <em>that</em> key using asymmetric cryptography, and deliver both to the remote party. Then, the remote party can:</p><ul><li>First, perform asymmetric decryption to obtain the symmetric key</li><li>Then, use that symmetric key to decrypt the rest.</li></ul><p>Thatâ€™s what <em>this</em> particular system is doing. âœ¨</p><h3 id="a-quick-note-about-rsa">A quick note about RSA</h3><p>I donâ€™t know much about how RSA works, but as part of researching this article I discovered that itâ€™s pretty easy to implement badly, and <a href="https://blog.trailofbits.com/2019/07/08/fuck-rsa/">extremely difficult to implement well</a>.</p><figure><img src="https://capnfabs.net/posts/wtf-encryption-scheme-synology-diskstation-nas/rsa-correct.gif" alt="Two developers correctly implement RSA, 2010, colorised"><figcaption><p><a href="https://www.youtube.com/watch?v=vPwzHm6buB8">Two developers correctly implement RSA</a>, 2010, colorised</p></figcaption></figure><p>As software developers, we spend a lot of time shipping things once they get to a point of â€œit looks like it worksâ€. <strong>You canâ€™t take that approach with cryptography</strong>, and because everything is so opaque, itâ€™s a lot easier to declare that your implementation works without realising that itâ€™s missing fundamentals. Like correctness, for example.</p><h3 id="lets-talk-about-random-keyslets-talk-about-you-and-me">Letâ€™s talk about random keys<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></h3><p>Recall that this algorithm is generating 501 random bytes from a 77-character set, and encrypting that with RSA. 501 seemed like an oddly specific number to me; hereâ€™s the specific set of circumstances that characterise <em>why</em> weâ€™re generating a string of this length.</p><p>RSA is a <a href="https://en.wikipedia.org/wiki/Block_cipher"><em>block cipher</em></a>, which means it operates on distinct fixed-size blocks of input and produces fixed-size blocks of output. How big can each block be? Well, RSA public keys are made up of two numbers: a (very large) modulus <code>n</code>, and a much smaller exponent <code>e</code>. RSA is capable of encrypting any message thatâ€™s smaller than <code>n</code> if you convert it to a number. In our case, we said that our modulus was a seemingly-random 4096-bit integer â€“ that means (approximately) that we can encrypt 512-byte blocks.</p><p>Thereâ€™s an important implication here: if you donâ€™t have enough input for a block, you need to fill it up somehow. Normally this is called a <em>padding scheme</em><sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> in block-based cryptography.</p><p>Now, the system on this NAS in particular uses <a href="https://tools.ietf.org/html/rfc3447#section-7.2.1">PKCS1-v1.5 padding</a>, which prepends the message (before encryption) with 3 bytes of headers <em>plus</em> a minimum of 8 bytes<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> of random garbage. That makes 11 bytes out of a 512 byte block, which means weâ€™ve gotâ€¦ 501 bytes left for our message. âœ¨</p><h3 id="lo-fi-key-derivation">Lo-fi key derivation</h3><p>Soâ€¦ weâ€™ve got this 501-byte string, with each character being one of 77 possibilities, and we think we know <em>why</em> it was chosen to be 501 bytes long. But thatâ€™s not going to work for AES-encrypting the password:</p><ul><li>AES requires a key size of 128, 192, or 256 bits. Thatâ€™s 16, 24, or 32 bytes respectively, but weâ€™ve got <em>lots</em> more than that.</li><li>We canâ€™t, however, just take a subset of bytes from the text and go from there â€“ because theyâ€™re selected from a narrow subset of possible bytes (77 out of 255!), youâ€™d be losing an <em>enormous</em> amount of entropy in the key, making the encrypted text about 44,000,000,000,000,000 times<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> easier to break.</li></ul><p>These constraints need to be managed. We can smooth over both by applying a <a href="https://en.wikipedia.org/wiki/Key_derivation_function">key derivation function</a>, based on repeated rounds of MD5 hashing and concatenating. Hash algorithms, in general, are good for this because they map input data toâ€¦ not random, but random-<em>looking</em> output data.</p><p>I like to think of hashing as â€œentropy launderingâ€ â€“ if youâ€™ve got 256 bits of entropy in a 16kB file, taking the first 256 bits will give you only 64 bits of entropy. If you hash the whole 16kB file, then the entropy goes back up to the maximum of the entropy in the file and the entropy provided by the hash algorithm. This works because hash algorithms are designed to exhibit an <a href="https://en.wikipedia.org/wiki/Avalanche_effect">avalanche effect</a>.</p><p>I do <em>not</em> have the tools or experience to evaluate whether this specific scheme is secure or not (this one seems esoteric, and the <a href="https://security.stackexchange.com/questions/19906/is-md5-considered-insecure">use of MD5 is scary</a>!)â€¦ so letâ€™s move briskly on.</p><h3 id="aes-encryption">AES-encryption</h3><p>Finally, after a bunch of outdated and somewhat esoteric primitives, weâ€™re back to something that is <em>good</em> and <em>works</em> and <em>only slightly</em> a <a href="https://en.wiktionary.org/wiki/footgun">loaded footgun</a> and is <em>still recommended for widespread use!</em> Itâ€™s AES with a 256-bit key.</p><p>AES is our symmetric cipher. Like RSA, it operates on blocks of fixed length. <a href="https://crypto.stackexchange.com/questions/66314/whats-the-best-block-cipher-mode-of-operation-for-rsa/66321#66321">Unlike RSA</a>, these blocks can be chained together. The strategies to do this are called <a href="https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation">â€œBlock cipher modes of operationâ€</a>, and AES implementations ship with a number of them. The problem is, this means you have access â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://capnfabs.net/posts/wtf-encryption-scheme-synology-diskstation-nas/">https://capnfabs.net/posts/wtf-encryption-scheme-synology-diskstation-nas/</a></em></p>]]>
            </description>
            <link>https://capnfabs.net/posts/wtf-encryption-scheme-synology-diskstation-nas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26201723</guid>
            <pubDate>Sat, 20 Feb 2021 05:00:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fixing EKS DNS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26201292">thread link</a>) | @mooreds
<br/>
February 19, 2021 | https://www.vladionescu.me/posts/eks-dns/ | <a href="https://web.archive.org/web/*/https://www.vladionescu.me/posts/eks-dns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>Got to blog on the AWS Containers Blog: <a href="https://aws.amazon.com/blogs/containers/eks-dns-at-scale-and-spikeiness/">EKS DNS at scale and spikeiness</a>! ğŸ‰</p>
<p>I usually just get to mentor people, and they get to post stuff publicly, so this is a nice change!</p>
<hr>
<blockquote>
<p>The AWS Containers Blog now <a href="https://github.com/aws/containers-roadmap/issues/303">seems to be missing my blog post</a>, so hereâ€™s a copy:</p>
</blockquote>
<h2 id="eks-dns-at-scale-and-spikeiness">EKS DNS at scale and spikeiness</h2>
<p><em>This is a guest post by&nbsp;Vlad Ionescu for Ownzones.</em></p>
<p>In his post we will discuss the issue of DNS errors at scale, that is, several hundreds to thousands of nodes, showing how the problems can be mitigated. This was an obstacle that affected Ownzones for several months and a problem that we expect everybody at scale will encounter. Two solutions will be proposed and their implementation will be discussed. Troubleshooting steps are shared for easy identification of the problem.</p>
<p>Ownzones is a pioneering technological force thatâ€™s transforming the OTT industry with ground-breaking innovations. Our product Ownzones Connect is a cloud-native platform, which leverages our proprietary technology as well as the best tools in the industry to provide studios an agile, low-cost solution for global distribution and localization. Some of the key features include the worldâ€™s first fully cloud-based, parallel processing IMF transcoder.</p>
<h3 id="problem">Problem</h3>
<p>At Ownzones, we run our applications in containers for increased developer velocity. Due to rather intense scaling requirements â€” a multi-TB movie comes in and needs to be processed as soon as possible â€” the decision was made to use Kubernetes for container orchestration. Since we are running in AWS, we make use of the amazing <a href="https://aws.amazon.com/eks/">Amazon Elastic Kubernetes Service</a> or EKS for short. We leverage other AWS services such as <a href="https://aws.amazon.com/rds/">Amazon Relational Database Service</a>, <a href="https://aws.amazon.com/elasticache/">Amazon ElastiCache</a>, and more. We manage all the services and infrastructure configuration in code with <a href="https://www.terraform.io/">Terraform</a> and we practice gitops with <a href="https://www.runatlantis.io/">Atlantis</a>.</p>
<p>The EKS clusters are running version 1.12 and we are in the process of upgrading all our clusters to 1.13. Each cluster has a different configuration depending on the customer needs for scale, but all of them scale a lot. As soon as jobs come in â€” be they transcoding jobs, media analysis jobs, deliveries, or anything else â€” the EKS clusters are scaled up by cluster-autoscaler. At peak, clusters may scale to hundreds or thousands of nodes to process the work as soon as possible.</p>
<p>The problems started to appear when customers or internal testing teams were scaling the system to higher limits, such as when transcoding or using FrameDNA to analyze large films or libraries of content. When the Kubernetes cluster was doing intense work and scaling above several hundreds of nodes, the processing time was stagnating or increasing. Having built a cloud native solution, the expectation was that adding additional processing power would lower the processing time.</p>
<p>We quickly established a cross-functional task force to investigate this issue.</p>
<p>A multitude of tools are used for observability at Ownzones: <a href="https://honeycomb.io/">Honeycomb</a> for events and traces, Sysdig for monitoring, Papertrail for logs, <a href="https://sentry.io/">Sentry</a> for error tracking, and more. Investigation into traces from Honeycomb showcased DNS resolution times taking seconds or more:</p>
<figure>
    <img src="https://www.vladionescu.me/posts/eks-dns/1-DNS-lookup-to-s3-taking-1-second.png" alt="A screenshot of a Honeycomb trace showing the DNS lookup for an S3 connection taking almost one second."> <figcaption>
            <p>A DNS lookup for S3 taking almost 1 second</p>
        </figcaption>
</figure>

<p>In some cases DNS lookups were taking multiple seconds:</p>
<figure>
    <img src="https://www.vladionescu.me/posts/eks-dns/2-DNS-lookup-to-s3-taking-2-seconds.png" alt="A screenshot of a Honeycomb trace showing the DNS lookup for an S3 connection taking more than 2 seconds"> <figcaption>
            <p>Sometimes DNS resulution spiked to multiple seconds</p>
        </figcaption>
</figure>

<p>Looking further into network metrics showed DNS errors spiking while work was being processed and recovering when the work was finished:</p>
<figure>
    <img src="https://www.vladionescu.me/posts/eks-dns/3-graph-showing-2-spikes-in-DNS-errors.png" alt="A screenshot of a Sysdig DNS errors graph showing spies in DNS errors"> <figcaption>
            <p>DNS errors spiking when work was happening</p>
        </figcaption>
</figure>

<p>The culprit was identified: when reaching a certain scale, a significant number of DNS errors (<code>EAI_AGAIN</code> and <code>ENOTFOUND</code>) that were leading to a lot of retries. Operations that were supposed to take a couple minutes were taking orders or magnitude longer. For example, transcoding a single 4K feature film in Ownzones Connect takes around 16 minutes. During this time, the EKS cluster is scaled to hundreds of nodes, which are peaking at 1.64 TB/s network traffic to S3 and 8.55k requests per second to S3.&nbsp;&nbsp;And that is for a single video track! Processing files in massively parallel ways is where cloud native approaches shine and Ownzones Connect is fully taking advantage of that. The result is a massive spike of work and DNS traffic. Having multi-second lookup times when doing 8.550 requests per second to S3 adds up to quite a lot.</p>
<p>Since the cause was narrowed down to DNS, the next step was to contact AWS Support.&nbsp;The DNS issues were appearing at scale and spiky workloads were especially affected. After investigation by AWS it was confirmed that the VPC networking was not experiencing elevated error rates, nor was S3.&nbsp;It was pointed out that due to the <a href="https://docs.aws.amazon.com/vpc/latest/userguide/vpc-dns.html#vpc-dns-limits">Amazon VPC DNS Limits</a> of 1024 packets per second per network interface the EKS-default 2 CoreDNS pods can be quickly overloaded. Each CoreDNS pod has to serve DNS traffic from the host through its own elastic network interface, which is limited to 1024 packets per second.</p>
<h3 id="attempt-one-increasing-coredns-pods">Attempt one: increasing CoreDNS pods</h3>
<p>The first and easiest improvement for DNS failures was to increase the number of CoreDNS pods. By default EKS has two replicas and that can be increased:</p>
<pre><code data-lang="console">kubectl scale deployment/coredns \
    --namespace kube-system \
    --current-replicas=2 \
    --replicas=10
</code></pre><p>At Ownzones, we run both on On-Demand Instances as well as on Spot Instances. This is not ideal as CoreDNS pods could be scheduled on a Spot Instance, which may be terminated at any time and potentially add disruption.</p>
<p>To work around this we edited the CoreDNS deployment to only run on On-Demand EC2 instances which we have tagged with the <code>stable</code> label:</p>
<pre><code data-lang="console">kubectl --namespace kube-system edit deployment/coredns

    ...
    spec:
        affinity:
        nodeAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
                - key: beta.kubernetes.io/os
                operator: In
                values:
                - linux
                - key: beta.kubernetes.io/arch
                operator: In
                values:
                - amd64
                - key: nodegroup
                operator: In
                values:
                - stable
        containers:
            ...

</code></pre><p>Scaling the CoreDNS pods was an improvement, but we still saw significant error rates. We had thousands of nodes sending network traffic to 10 CoreDNS pods, which were spread on significantly fewer On-Demand nodes.</p>
<h3 id="attempt-two-node-local-dns">Attempt two: Node-local DNS</h3>
<p>Kubernetes developers have an addon that addresses the DNS problem: <a href="https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/dns/nodelocaldns">NodeLocal DNS Cache</a>. Using this addon, a new CoreDNS DaemonSet can be configured so it runs on each node. Those new CoreDNS pods will act as a DNS cache: all pods on a specific node would have their requests sent to the local CoreDNS pod which would either serve a result from cache or forward the request upstream to the main CoreDNS pods.</p>
<p>This massively lowers the volume of DNS queries and makes spike handling a breeze and follows <a href="https://aws.amazon.com/premiumsupport/knowledge-center/dns-resolution-failures-ec2-linux/?nc1=h_ls">the AWS recommendation to cache DNS</a>.&nbsp;The first step is to decide which IP will be used for NodeLocal DNS. Typically <code>169.254.20.10</code> is chosen.</p>
<p>With the IP address decided, the YAML files from <a href="https://github.com/kubernetes/kubernetes/tree/release-1.15/cluster/addons/dns/nodelocaldns">k/k/cluster/addons/dns/nodelocaldns</a> need to be acquired. They cannot be applied directly as some values need to be replaced:</p>
<ul>
<li><code>__PILLAR__DNS__DOMAIN__</code> with <code>cluster.local</code> as per <a href="https://github.com/awslabs/amazon-eks-ami/blob/28845f97c05dacaf699a102faa690a4238b79f02/files/kubelet-config.json#L24">amazon-eks-amiâ€™s kubelet-config.json.</a></li>
<li><code>__PILLAR__LOCAL__DNS__</code> with <code>169.254.20.10</code>, which is like the default address chosen above that the Node-local DNS will bind to on each node.</li>
<li><code>__PILLAR__DNS__SERVER__</code> with <code>10.100.0.10</code> or <code>172.20.0.10</code> depending on the VPC CIDR. <a href="https://github.com/awslabs/amazon-eks-ami/blob/ca61cc2bb6ef6fe982cc71ede7552a4a2c6b93e9/files/bootstrap.sh#L167-L170">On EKS</a>, the DNS Service is running at one of the two IPs and the relevant one needs to be chosen. The value can be seen by running <code>kubectl -n kube-system get service kube-dns</code> and checking the cluster IP.</li>
</ul>
<p>After the values are replaced the files have to be applied:</p>
<pre><code data-lang="console">kubectl apply -f nodelocaldns.yaml
</code></pre><p>This is not enough: Node-local DNS was installed, but it is not used by the pods! To actually have the pods use Node-local DNS the kubelet running on each node needs to be configured. The DNS resolver for the pods needs to point to the newly created Node-local DNS server running at <code>169.254.20.10</code> on each node.</p>
<p>Users of the amazing <a href="https://eksctl.io/">eksctl</a> project can easily configure this since <a href="https://github.com/weaveworks/eksctl/pull/550">support was added in February</a> by editing the node group definition:</p>
<div><pre><code data-lang="yaml">
...
<span>nodeGroups</span>:
- <span>name</span>: <span>mygroup</span>
    <span>clusterDNS</span>: <span>169.254.20.10</span>
...

</code></pre></div><p>Users of <a href="https://github.com/terraform-aws-modules/terraform-aws-eks">the Terraform community EKS module</a> have to send an extra parameter to the <code>kubelet</code> binary in the worker group definition:</p>
<div><pre><code data-lang="hcl">
...
worker_groups_launch_template <span>=</span> [
    {
        ...
        name <span>=</span> <span>"mygroup"</span>
        kubelet_extra_args <span>=</span> "--node-labels<span>=</span>kubernetes.io/lifecycle<span>=</span>spot,nodegroup<span>=</span>mygroup --cluster-dns<span>=</span><span>169</span>.<span>254</span>.<span>20</span>.<span>10</span><span>"</span>
        ...
    },
    {
        ...
    },
]
...

</code></pre></div><p>Thatâ€™s all!</p>
<p>At Ownzones, we have been running the above setup in production for more than 2 months on Amazon EKS and Kubernetes 1.12 with very good results. DNS errors have fallen drastically with 99% of DNS queries resolved in less than 2ms during stress-testing:</p>
<figure>
    <img src="https://www.vladionescu.me/posts/eks-dns/4-DNS-p99-during-stress-testing.png" alt="A screenshot of a Honeycomb query showing consistent low DNS resolution"> <figcaption>
            <p>Dramatic improvement in DNS resolution</p>
        </figcaption>
</figure>

<h3 id="troubleshooting-tips">Troubleshooting tips</h3>
<p>Identifying the need for a more in-depth DNS configuration is not straightforward. Debugging Node-local DNS is a task in itself that requires networking experience and familiarity with networking in Kubernetes.</p>
<p>To lower the time investment, we can share two pointers that would have helped us a lot when starting the investigation.</p>
<h4 id="visibility">Visibility</h4>
<p>Knowing how many CoreDNS replicas to use and knowing if NodeLocal DNS is needed are both two very hard questions. Prometheus and Grafana can showcase the relevant metrics on the <a href="https://grafana.com/grafana/dashboards/7279">CoreDNS dashboard</a>.</p>
<p>While at Ownzones we debugged resolution issues with <a href="https://www.honeycomb.io/">Honeycomb</a>, a tracing solution combined with a rich monitoring setup will likely reach the same depth. An important point is for the investigation to happen â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.vladionescu.me/posts/eks-dns/">https://www.vladionescu.me/posts/eks-dns/</a></em></p>]]>
            </description>
            <link>https://www.vladionescu.me/posts/eks-dns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26201292</guid>
            <pubDate>Sat, 20 Feb 2021 03:38:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Embracing Functional Programming in Ruby (2017)]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26201237">thread link</a>) | @mooreds
<br/>
February 19, 2021 | https://kellysutton.com/2017/09/13/embracing-functional-programming-in-ruby.html | <a href="https://web.archive.org/web/*/https://kellysutton.com/2017/09/13/embracing-functional-programming-in-ruby.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>At <a href="https://gusto.com/">Gusto</a>, weâ€™ve been knee-deep in a substantial refactor of our system for running payrolls.</p>

<p>Running a payroll requires taking several different inputs such as how much an employee should get paid, where did they work, how much did they work, how much taxes should they pay, how much taxes have they paid this year, and so on and so on.</p>

<p>As a company that offers a payroll service, keeping this piece of the system in tip-top shape is important for the business. Customers love Gusto for its simplicity and speed when it comes to running payroll.</p>

<p>Over the years, this system grew beyond its original mandate. Rather than just serve payroll for one state, it now serves them for all 50 states and the District of Columbia. Although customers love our payroll, internally new engineers had a difficult time understanding the code and making changes safely. This system needed a tune up, so we embarked on a sizable refactor.</p>

<p>Because the process of calculating what you need for a payroll is one big formula, we set the goal of making this system â€œmore functionalâ€ as in functional programming. We wanted to take the process of calculating a payroll and make it one big stateless operation.</p>

<p>The server-side code at Gusto is written in Ruby, a language usually known for its object-oriented and metaprogrammatic roots. Nonetheless, we wanted to integrate some more functional concepts into our code in the hopes of increasing the systemâ€™s safety and clarity. The result has been maintainable code that is easier to reason about and safer to change.</p>

<h2 id="embracing-the-pfaao">Embracing the PFaaO</h2>

<p>Ruby is an expressive language, but it does not lend itself to some common functional practices. Although Ruby allows for closures and first-class functions via <code>Proc</code>s, one does not see many <code>Proc</code>s passed around as objects in idiomatic Ruby.</p>

<p>Throughout our work, we discovered that you can create expressive interfaces with clean internals by embracing both OO and functional aspects of Ruby.</p>

<p>To do this, we used a pattern called <a href="https://www.tomdalling.com/blog/ruby/pure-function-as-an-object-PFAAO-pattern/">Pure Function as an Object (PFaaO)</a>. Essentially, you design objects as you would a <a href="https://en.wikipedia.org/wiki/Pure_function">pure function</a> but dress them up as Ruby classes.</p>

<p>A pure function is a function without observable side effects that always returns the same value for a given set of inputs. That means no talking to the database, no modifying the state of other objects, no accessing the system clock, etc. When we write a PFaaO in Ruby, we want to build an object that has no side effects.</p>

<p>A simple PFaaO might look like the following:</p>

<div><div><pre><code><span>class</span> <span>PayrollCalculator</span>
  <span>def</span> <span>self</span><span>.</span><span>calculate</span><span>(</span><span>payroll</span><span>)</span>
    <span>new</span><span>(</span><span>payroll</span><span>).</span><span>calculate</span>
  <span>end</span>

  <span>def</span> <span>initialize</span><span>(</span><span>payroll</span><span>)</span>
    <span>@payroll</span> <span>=</span> <span>payroll</span>
  <span>end</span>
  <span>private_class_method</span> <span>:new</span>

  <span>def</span> <span>calculate</span>
    <span>PayrollResult</span><span>.</span><span>new</span><span>(</span>
      <span>payroll: </span><span>payroll</span><span>,</span>
      <span>paystubs: </span><span>paystubs</span><span>,</span>
      <span>taxes: </span><span>taxes</span><span>,</span>
      <span>debits: </span><span>debits</span>
    <span>)</span>
  <span>end</span>

  <span>def</span> <span>paystubs</span>
    <span># ...</span>
  <span>end</span>

  <span>def</span> <span>taxes</span>
    <span># ...</span>
  <span>end</span>

  <span>def</span> <span>debits</span>
    <span># ...</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Thereâ€™s quite a bit going on here, so letâ€™s break it down bit by bit.</p>

<p>First, our class has only one effective public interface: <code>PayrollCalculator.calculate</code>. Because weâ€™ve declared the constructor private using <code>private_class_method :new</code>, the instance method <code>#calculate</code> is effectively private.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup></p>

<p>This means that all of the other instance methods we declare are implicitly private, even though there is no explicit <code>private</code> block within this class. Because thereâ€™s no way to <code>.new</code> up an instance, there is not a vector to call any instance methods.</p>

<p>Our method only has one public interface and its designed operation is effectively stateless, therefore we only need to exercise one interface in our tests. Put some data in, assert that the data coming out is what we expected.</p>

<h2 id="referential-transparency-for-free">Referential Transparency for Free</h2>

<p>In our above example, letâ€™s say that the process of calculating taxes is expensive from a time perspective.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup> Thus, we want to make a time/space tradeoff to consume more memory to minimize the number of times we need to compute taxes. In our example, calculating both <code>#paystubs</code> and <code>#debits</code> will require the result of <code>#taxes</code>.</p>

<p>Now because each of these private methods is a pure function, we have referential transparency. This means we can replace a method and its parameters with its return value. Think of it like algebra: Given the function <code>f(x) = x + 5</code>, you can safely replace any occurrence of <code>f(2)</code> with the value <code>7</code>.</p>

<p>What does this mean for a Rubyist? Free and safe memoization:</p>

<div><div><pre><code><span>def</span> <span>paystubs</span>
  <span>calculate_paystubs</span><span>(</span><span>taxes</span><span>,</span> <span>...</span><span>)</span>
<span>end</span>

<span>def</span> <span>debits</span>
  <span>calculate_debits</span><span>(</span><span>taxes</span><span>,</span> <span>...</span><span>)</span>
<span>end</span>

<span>def</span> <span>taxes</span>
  <span>@taxes</span> <span>||=</span> <span>calculate_taxes</span><span>(</span><span>@payroll</span><span>)</span>
<span>end</span>
</code></pre></div></div>

<p>Memoization is a form of caching, and can be fraught with issues if the memoized value does not actually come from a pure function. But because we make everything within the PFaaO pure, we can safely memoize this method call.</p>

<p>This is interesting because it looks like this class is no longer stateless: it now assigns local values. However the only interface is the single <code>.calculate</code> class method, each instance of our PFaaO is single-use. Any intermediate state can never be accessed by externally. Because this cached state is not observable externally, our function is still technically pure.</p>

<p>Much in the way a developer can abstract synchronous and asynchronous behavior, you can do the same with functional purity. Any local state changes are irrelevant in the lifecycle of the PFaaO. These local state changes are not observable from the outside world.</p>

<h2 id="expanding-pfaaos">Expanding PFaaOs</h2>

<p>As Iâ€™ve grown in my career, I have become less interested in how software is written but how it is maintained. Software maintenance is the blessing and the curse of any successful project: <em>Congratulations!</em> You have a business with lasting value. <em>Our condolences!</em> You must now pay for all of your mistakes. Nonetheless, it is always preferred to have a business that exists with technical debt, than to have a bankrupt company with a pristine code base.</p>

<p>PFaaOs in Ruby are great because they are easy to maintain. Not only are they easy to test, but they are predisposed to healthy growth.</p>

<p>What do I mean by that?</p>

<p>Letâ€™s again take the example of our <code>#taxes</code> method. Early in Gustoâ€™s history (back when it was still known as ZenPayroll), we only offered payroll services in California. Thus, we only needed to worry about payroll taxes for California.</p>

<p>In the grand scheme of things, California is a simple state when it comes to payroll taxes. Our taxes method might have looked like nothing more than the following:</p>

<div><div><pre><code><span>def</span> <span>taxes</span>
  <span>federal_taxes</span><span>(</span><span>@payroll</span><span>)</span> <span>+</span>
    <span>california_taxes</span><span>(</span><span>@payroll</span><span>)</span> <span>+</span>
    <span>local_taxes</span><span>(</span><span>@payroll</span><span>)</span>
<span>end</span>
</code></pre></div></div>

<p>Now letâ€™s say we expanded into a new state, New York. Now our method grows a little bit:</p>

<div><div><pre><code><span>def</span> <span>taxes</span>
  <span>federal_taxes</span><span>(</span><span>@payroll</span><span>)</span> <span>+</span>
    <span>california_taxes</span><span>(</span><span>@payroll</span><span>)</span> <span>+</span>
    <span>new_york_taxes</span><span>(</span><span>@payroll</span><span>)</span> <span>+</span>
    <span>local_california_taxes</span><span>(</span><span>@payroll</span><span>)</span> <span>+</span>
    <span>local_new_york_taxes</span><span>(</span><span>@payroll</span><span>)</span>
<span>end</span>
</code></pre></div></div>

<p>As we expand into every state,<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup> this method will grow to be quite large! Furthermore, each of these methods adds to the length of our <code>PayrollCalculator</code> class. Without constant gardening, the class could become difficult to understand.</p>

<p>But because each of our methods within a PFaaO is itself a pure function, we are able to extract classes as we see fit and make each one a new PFaaO. We can safely replace our growing methods with new PFaaOs:</p>

<div><div><pre><code><span>def</span> <span>taxes</span>
  <span>PayrollCalculator</span><span>::</span><span>Taxes</span><span>.</span><span>calculate</span><span>(</span><span>@payroll</span><span>)</span>
<span>end</span>
</code></pre></div></div>

<p>As we tease apart these different PFaaOs, we also get a much better idea of the input requirements for these service classes. Our <code>@payroll</code> is a large parameter object, and each extracted PFaaO probably only needs a subset of its data.</p>

<p>So we can get away with something like:</p>

<div><div><pre><code><span>def</span> <span>taxes</span>
  <span>PayrollCalculator</span><span>::</span><span>Taxes</span><span>.</span><span>calculate</span><span>(</span>
    <span>@payroll</span><span>.</span><span>only_pay_and_location_data</span>
  <span>)</span>
<span>end</span>
</code></pre></div></div>

<p>Here we assume that the <code>Payroll#only_pay_and_location_data</code> returns a slice of the total data within the instance as a new <a href="https://martinfowler.com/bliki/ValueObject.html">Value Object</a>. This Value Object represents only the data required to calculate the taxes part of running a payroll.</p>

<h2 id="data-is-immutable-by-default">Data is Immutable by Default</h2>

<p>Another important ingredient for scalable PFaaOs is the requirement that all data be immutable by default. <em>This is a drastic change from how most folks traditionally write Ruby.</em></p>

<p>Every time you reach for your <code>=</code>, youâ€™ll need to replace it with a <code>#set</code> or <code>#put</code>. Rather than modifying objects in place, you will get used to returning new copies with new values. (<a href="https://github.com/hamstergem/hamster/">Hamster</a>, which provides great immutable data structures, can help you from having to hand-roll FP functionality.)</p>

<p>What does this mean for Rails? It will often mean creating functions or classes that take <code>ActiveRecord</code> objects and convert them into immutable value objects. For us, we carve out these value objects into the namespace of what weâ€™re doing. For example, here are the two representations of a payroll in our system:</p>

<div><div><pre><code><span># app/models/payroll.rb</span>
<span>class</span> <span>Payroll</span> <span>&lt;</span> <span>ActiveRecord</span><span>::</span><span>Base</span>
<span>end</span>

<span># app/services/payroll_calculator/payroll.rb</span>
<span>class</span> <span>PayrollCalculator::Payroll</span> <span>&lt;</span> <span>ValueObject</span>
<span>end</span>
</code></pre></div></div>

<p>The <code>ActiveRecord</code> version of a payroll represents the data that lives in the database. It is a superset of the data required for actually running a payroll. Although they have the same name, they do not have the same attributes. For example, the <code>ActiveRecord</code> version of <code>Payroll</code> will have a <code>processed_at</code> attribute, whereas the <code>Payroll</code> that lives in the calculation domain does not.</p>

<p>In the words of <a href="https://kellysutton.com/2017/06/07/domain-driven-design.html"><em>Domain-Driven Design</em></a>, each namespace here is a different Bounded Context. We implement adapters to take <code>ActiveRecord</code> payrolls and turn them into <code>PayrollCalculator</code> payrolls, and vice versa.</p>

<p>The upside of this is the same that you might see in any other large system with well-defined abstractions; changes in models donâ€™t cross domains. In our example, we can change the structure of the <code>Payroll</code> in our database without needing to change the calculation code. We would only need to change our adapter. Furthermore, this context is entirely separate from the machinations of Rails. We could easily and safely pull this into its own â€¦</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kellysutton.com/2017/09/13/embracing-functional-programming-in-ruby.html">https://kellysutton.com/2017/09/13/embracing-functional-programming-in-ruby.html</a></em></p>]]>
            </description>
            <link>https://kellysutton.com/2017/09/13/embracing-functional-programming-in-ruby.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26201237</guid>
            <pubDate>Sat, 20 Feb 2021 03:30:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Draw an iceberg and see how it would float in water]]>
            </title>
            <description>
<![CDATA[
Score 695 | Comments 88 (<a href="https://news.ycombinator.com/item?id=26201160">thread link</a>) | @raldi
<br/>
February 19, 2021 | https://joshdata.me/iceberger.html | <a href="https://web.archive.org/web/*/https://joshdata.me/iceberger.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://joshdata.me/iceberger.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26201160</guid>
            <pubDate>Sat, 20 Feb 2021 03:16:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Life in E-Ink]]>
            </title>
            <description>
<![CDATA[
Score 143 | Comments 77 (<a href="https://news.ycombinator.com/item?id=26200630">thread link</a>) | @HaoZeke
<br/>
February 19, 2021 | https://rgoswami.me/posts/my-life-in-eink/ | <a href="https://web.archive.org/web/*/https://rgoswami.me/posts/my-life-in-eink/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>Collection of odds and ends relating to e-readers including personal reminisces</p></blockquote><h2 id="background">Background</h2><p>Reading has been a huge part of my life. The written word has had arguably more of an impact on my life than anything I have experienced in person. As a kid back in early 2000â€™s; this meant a lot of library trips and saving for paperbacks. I also caught the first wave of the e-ink revolution. Nothing beats a real book, in terms of textures and scents; but e-ink devices and the fantastic tools outlined here should make reading digital books much more palpable&nbsp;<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.</p><p>I have been reading on my <a href="https://en.wikipedia.org/wiki/Kobo%5FAura%5FHD">Kobo Aura HD</a> for almost a decade now, ever since its release. This means my setup is about as stable as its going to get in the near future. As good a time as any to collect my thoughts&nbsp;<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. The focus is on e-ink devices and auxiliary tools; not on all digital content; so there are no mentions of syncing or reading on the go (with a phone) or of monitors which are good for reading on.</p><h3 id="the-content">The Content</h3><p>In general; my e-ink reading habits can be broadly broken into the following categories:</p><dl><dt>Light Reading</dt><dd>Practically this includes <a href="https://www.goodreads.com/user/show/33462912-rohit-goswami">anything I review on Goodreads</a>; these are not often re-read; nor read very deeply; since they are read for pleasure. They are however, rarely deleted</dd><dt>Required Reading</dt><dd>Anything which typically requires me to take notes or practice / write out proofs; these are most often considered to be either coursework (for someone somewhere) or research monographs. These are typically large (in size) and unwieldy (in that they often lack TOCs) and are read multiple times; with a focus on highlights and notes</dd><dt>Active Research</dt><dd>These are the most ephemeral of my reading habits; and also the most numerous; I do not typically store these on my e-reader; and rarely need to make notes on the reader&nbsp;<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>. These are often tiny; but require special work due to the metadata involved</dd></dl><table><thead><tr><th>Content Type</th><th>Software Stack</th><th>Deletion Rate</th></tr></thead><tbody><tr><td>Light Reading</td><td>Calibre</td><td>Rare</td></tr><tr><td>Required Reading</td><td>Calibre</td><td>Never</td></tr><tr><td>Active Research</td><td>Calibre + Zotero</td><td>Frequent</td></tr></tbody></table><p>Though I am a huge proponent of RSS feeds (with <a href="https://gitlab.com/news-flash/news%5Fflash%5Fgtk">Newsflash</a>) and read online content voraciously with both a <a href="https://app.getpocket.com/">Pocket</a> and <a href="https://www.diigo.com/user/rgoswami">Diigo</a> subscription<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>; I sincerely do not believe blog stuff or anything tailored for the web should have a presence on an e-ink device; so there shall be no mention of those parts of my reading habits<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup>.</p><h2 id="hardware">Hardware</h2><p>My primary e-reader is still my <a href="https://www.kobo.com/koboaurahd?%5F%5F%5Fstore=au&amp;style=onestore">Kobo Aura HD</a> (complete with a snazzy <a href="https://www.amazon.com/Cover-Up-eReader-Natural-Cover-Function/dp/B00DZJ5VM0">hemp sleep-cover</a>), and has been my go to for almost a decade now since its release. Recently I have augmented my workflow with the <a href="https://remarkable.com/store/remarkable-2">reMarkable 2</a>; though I have yet to break it in very well; mostly because I tend to gravitate towards typing out my thoughts&nbsp;<sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup> instead of writing.</p><p>The Kobo Aura HD is still the pinnacle of reading technology to me; mostly because the firmware is easy to bypass; and there is a vibrant community of developers on the <a href="https://www.mobileread.com/forums/showthread.php?t=210800">MobileRead Forums</a>. Display and spec aside; the biggest reason for never replacing it has been been the simple fact that most modern e-readers no longer support SD cards; and much of my workflow depends on storing insane amounts of material offline&nbsp;<sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup>.</p><figure><img src="https://d33wubrfki0l68.cloudfront.net/d393a91160884052b7717a31a565283336a03ccf/eb437/ox-hugo/2021-02-20_01-39-20_screenshot.png" alt="Figure 1: Primary reading device with Koreader"><figcaption><p>Figure 1: Primary reading device with Koreader</p></figcaption></figure><p>Personally, I never use Nickel (the default Kobo interface), and it would probably choke trying to scan my 200 GB of content; so I havenâ€™t updated the firmware in forever. My interactions are almost always in <a href="https://koreader.rocks/">Koreader</a>; and my launching poison of choice is the now no longer developed <a href="https://www.mobileread.com/forums/showthread.php?t=293804">Kobo start menu</a>&nbsp;<sup id="fnref:8"><a href="#fn:8" role="doc-noteref">8</a></sup>.</p><h2 id="software">Software</h2><p>Broadly speaking; the main parts of the software pipeline from digital book to brain are simply the syncing mechanism and the UI/UX/OS of the device in question; though it is often best to consider pre-processing books for devices too. These are covered in the order used.</p><h3 id="k2pdfopt">k2pdfopt</h3><p>The thought of reflowing text for an optimal reading experience, especially given the slightly limited processing power of my primary reading device is an enticing prospect. <a href="https://www.willus.com/k2pdfopt/">K2pdfopt or the Kindle 2 PDF Optimizer</a> is as criminally underrated as it is fantastic. An approach which works well for my device involves setting up <a href="https://github.com/HaoZeke/Dotfiles/blob/master/dotfiles/common/.local/bin/fileHelpers/docK2pdf">a simple shell script</a> (part <a href="https://github.com/HaoZeke/Dotfiles">of my Dotfiles</a>) for optimizing files on the fly before sending them through <code>calibre</code>.</p><div><pre><code data-lang="bash"><span>#!/usr/bin/env bash
</span><span></span><span># Get a filename</span>
<span>case</span> <span>"</span><span>$#</span><span>"</span> in
0<span>)</span>
      <span>echo</span> <span>"No arguments, so enter the filename, WITH the extension"</span>
      <span>read</span> -p <span>'Document: '</span> docfile
      <span>;;</span>
1<span>)</span>
      <span>echo</span> <span>"OK, using the filename"</span>
      <span>docfile</span><span>=</span><span>"</span><span>$1</span><span>"</span>
      <span>;;</span>
*<span>)</span>
      <span>echo</span> <span>"Illegal number of parameters"</span>
      <span>exit</span>
      <span>;;</span>
<span>esac</span>
<span># Get basename</span>
<span>basename</span><span>=</span><span>"</span><span>${</span><span>docfile</span><span>%.*</span><span>}</span><span>"</span>
<span>ext</span><span>=</span><span>"</span><span>${</span><span>docfile</span><span>##*</span><span>\.</span><span>}</span><span>"</span>
<span>echo</span> <span>"Basename </span><span>${</span><span>basename</span><span>}</span><span> with </span><span>$ext</span><span> from </span><span>$docfile</span><span>"</span>
<span>echo</span> <span>"Making a local store for the outputs"</span>
mkdir -p <span>"</span><span>$HOME</span><span>/auraHDopt"</span>

<span>case</span> <span>"</span><span>$ext</span><span>"</span> in
<span>"djvu"</span><span>)</span>
      <span>echo</span> <span>"Converting djvu to pdf via ps and running k2pdfopt"</span>
      djvups <span>"</span><span>${</span><span>basename</span><span>}</span><span>.djvu"</span> <span>"</span><span>${</span><span>basename</span><span>}</span><span>.ps"</span>
      ps2pdf <span>"</span><span>${</span><span>basename</span><span>}</span><span>.ps"</span> <span>"</span><span>${</span><span>basename</span><span>}</span><span>.pdf"</span>
      <span># The newline is for simulating the Enter key</span>
      <span>echo</span> <span>|</span> k2pdfopt <span>"</span><span>${</span><span>basename</span><span>}</span><span>.pdf"</span> -wrap -hy -ws -0.2 -dev kbhd -x
      <span>echo</span> <span>"Cleaning up"</span>
      mv <span>"</span><span>${</span><span>basename</span><span>}</span><span>_k2opt.pdf"</span> <span>"</span><span>$HOME</span><span>/auraHDopt"</span>
      rm -rf <span>"</span><span>${</span><span>basename</span><span>}</span><span>.{ps,pdf}"</span>
      <span>;;</span>
<span>"pdf"</span><span>)</span>
      <span>echo</span> <span>"Converting pdf with gs and running k2pdfopt"</span>
      gs -sDEVICE<span>=</span>pdfwrite -dCompatibilityLevel<span>=</span>1.4 -dPDFSETTINGS<span>=</span>/screen <span>\
</span><span></span>              -dNOPAUSE -dQUIET -dBATCH -sOutputFile<span>=</span><span>"</span><span>${</span><span>basename</span><span>}</span><span>gs.pdf"</span> <span>"</span><span>${</span><span>basename</span><span>}</span><span>.pdf"</span>
      <span>echo</span> <span>|</span> k2pdfopt <span>"</span><span>${</span><span>basename</span><span>}</span><span>gs.pdf"</span> -wrap -hy -ws -0.2 -dev kbhd -x
      <span>echo</span> <span>"Cleaning up"</span>
      rm <span>"</span><span>${</span><span>basename</span><span>}</span><span>gs.pdf"</span> -rf
      mv <span>"</span><span>${</span><span>basename</span><span>}</span><span>gs_k2opt.pdf"</span> <span>"</span><span>$HOME</span><span>/auraHDopt"</span>
      <span>;;</span>
*<span>)</span>
      <span>echo</span> <span>"Illegal file type"</span>
      <span>exit</span>
      <span>;;</span>
<span>esac</span>
</code></pre></div><p>The outputs can also be further processed with an <a href="https://github.com/HaoZeke/Dotfiles/blob/master/dotfiles/common/.local/bin/fileHelpers/isOcr">OCR (Optical Character Recognition) script</a> if required, and then edited in <a href="https://code-industry.net/masterpdfeditor/">Master PDF Editor</a> or something similar to add the table of contents interactively as well.</p><div><pre><code data-lang="bash"><span>#!/bin/bash
</span><span></span><span># Use as  find . -type f -name "*.pdf" -exec isOcr '{}' \;</span>

<span># Shamelessly kanged from here:</span>
<span># https://stackoverflow.com/questions/7997399/bash-script-to-check-pdfs-are-ocrd</span>
<span># Only searches for text on the first 5 pages</span>
<span># Modified to have red text. Also to possibly ocr the thing.</span>

<span># -*- mode: shell-script-mode -*-</span>

<span>MYFONTS</span><span>=</span><span>$(</span>pdffonts -l <span>15</span> <span>"</span><span>$1</span><span>"</span> <span>|</span> tail -n +3 <span>|</span> cut -d<span>' '</span> -f1 <span>|</span> sort <span>|</span> uniq<span>)</span>
<span>if</span> <span>[</span> <span>"</span><span>$MYFONTS</span><span>"</span> <span>=</span> <span>''</span> <span>]</span> <span>||</span> <span>[</span> <span>"</span><span>$MYFONTS</span><span>"</span> <span>=</span> <span>'[none]'</span> <span>]</span><span>;</span> <span>then</span>
    <span>echo</span> <span>"</span><span>$(</span>tput setaf 1<span>)</span><span>NOT OCR'ed: </span><span>$1</span><span>"</span>
    <span>if</span> <span>[[</span> -x <span>"</span><span>$(</span>which ocrmypdf<span>)</span><span>"</span> <span>]]</span><span>;</span> <span>then</span>
        <span>echo</span> <span>"</span><span>$(</span>tput setaf 4<span>)</span><span>"</span>
        <span>echo</span> <span>"Converting to </span><span>${</span><span>1</span><span>%.*</span><span>}</span><span>_ocr.pdf with ocrmypdf"</span>
        <span>echo</span> <span>"</span><span>$(</span>tput setaf 7<span>)</span><span>"</span>
        ocrmypdf --deskew --clean --rotate-pages <span>\
</span><span></span>            --jobs <span>4</span> -v --output-type pdfa <span>"</span><span>$1</span><span>"</span> <span>"</span><span>${</span><span>1</span><span>%.*</span><span>}</span><span>_ocr.pdf"</span>
    <span>elif</span> <span>[[</span> -x <span>"</span><span>$(</span>which pypdfocr<span>)</span><span>"</span> <span>]]</span><span>;</span> <span>then</span>
        <span>echo</span> <span>"</span><span>$(</span>tput setaf 2<span>)</span><span> Looking for config files at </span><span>$XDG_CONFIG_HOME</span><span>/pypdfocr/config.yml"</span>
        <span>echo</span> <span>"</span><span>$(</span>tput setaf 3<span>)</span><span>"</span>
        <span>if</span> <span>[[</span> -e <span>$XDG_CONFIG_HOME</span>/pypdfocr/config.yml <span>]]</span><span>;</span> <span>then</span>
            <span>echo</span> <span>"Using configuration settings"</span>
            <span>echo</span> <span>"</span><span>$(</span>tput setaf 4<span>)</span><span>"</span>
            pypdfocr -c <span>$XDG_CONFIG_HOME</span>/pypdfocr/config.yml <span>"</span><span>$1</span><span>"</span>
        <span>else</span>
            <span>echo</span> <span>"Using default settings"</span>
            <span>echo</span> <span>"</span><span>$(</span>tput setaf 4<span>)</span><span>"</span>
            pypdfocr <span>"</span><span>$1</span><span>"</span>
        <span>fi</span>
        <span>echo</span> <span>"</span><span>$(</span>tput setaf 2<span>)</span><span> You might want to get pypdfocr"</span>
    <span>fi</span>
<span>else</span>
    <span>echo</span> <span>"</span><span>$1</span><span> is OCR'ed."</span>
<span>fi</span>
</code></pre></div><p>The end result is:</p><ul><li>A directory with perfectly <code>pdf</code> files re-flowed text<ul><li>Possibly OCRâ€™ed for string searches</li></ul></li></ul><p>TOC editing is still rather janky; but this is also because the OCR process is still rather spotty.</p><h3 id="calibre">Calibre</h3><p><a href="https://calibre-ebook.com/">Calibre</a> is an excellent library software, and there are very few alternatives which offer all the salient features:</p><dl><dt>Syncing</dt><dd>Apart from working well with a plethora of official devices, Koreader is also pretty well supported, and mounting folders allows for easy management of a secret library (e.g. <code>.Library</code>) on an SD card to prevent Nickel from reading and choking on large libraries</dd><dt>Multiple Libraries</dt><dd>I personally keep one for fiction, one for non-fiction, and one (transiently populated) one for papers</dd><dt>Good metadata collection</dt><dd>Nothing beats rich metadata, and with third party plugins, all the best content providers can be leveraged for blurbs; plus most purchased books come with metadata which <code>calibre</code> can read</dd></dl><p>It isnâ€™t perfect, there are far better <a href="https://opds.io/">OPDS (Open Publication Distribution System)</a> servers like the fantastic <a href="https://github.com/seblucas/cops">COPS (Calibre OPDS)</a> project, and there have been <a href="https://anarc.at/software/desktop/calibre/">some security concerns in the past</a>, but it is really usable and is <a href="https://github.com/kovidgoyal/calibre">under active development</a>; plus it has a <a href="https://kovidgoyal.net/">fun developer</a>. I also personally find the file conversion lacking, compared to <code>k2pdfopt</code>, but as a library management system it is really good.</p><h3 id="zotero-sync">Zotero Sync</h3><p>Calibre provides a handy <a href="https://www.mobileread.com/forums/showthread.php?p=3339191#poststop">ZMI (Zotero Metadata Importer) plugin</a> which allows for exported papers to be imported into <code>calibre</code> and from then into the e-reader as expected. Combined with the folder mounts facilitated by <code>calibre</code> this allows for a painless way to ensure a quick export; optimize; sync; read and delete workflow.</p><h3 id="koreader">Koreader</h3><p>Koreader is probably the best thing to happen to e-ink devices since sliced bread. It replaces the need to use any cables with an e-reader; since newer versions have a nice SSH server, and can also update itself. Since this is mostly used as is; and all the information required is on the <a href="https://github.com/koreader/koreader/wiki">Github Wiki</a>, thereâ€™s not much else to say here.</p><p>It is probably worth noting that the in-built re-flow options do tend to cause major artifacts on older hardware, and is best avoided. Almost equivalently, and at a far lower cost in terms of performance, page contents can be fit to width and zoomed in automatically, which is almost as good as working with <code>k2pdfopt</code> in some special cases.</p><h2 id="conclusions">Conclusions</h2><p>Given my unfortunate separation from my library back home; it is likely that my e-ink devices will continue to be my primary source of reading material. Plus the long retarded color e-ink market finally seems to be moving out of its stupor&nbsp;<sup id="fnref:9"><a href="#fn:9" role="doc-noteref">9</a></sup>. The only possible addendum to this methodology would probably involve integrating <code>orgmode</code> and the reMarkable 2 sometime. E-ink is here to stay. This setup would probably need revisions involving <code>rclone</code> or <code>syncthing</code> if I ever gave â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rgoswami.me/posts/my-life-in-eink/">https://rgoswami.me/posts/my-life-in-eink/</a></em></p>]]>
            </description>
            <link>https://rgoswami.me/posts/my-life-in-eink/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26200630</guid>
            <pubDate>Sat, 20 Feb 2021 01:46:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A request for Pinboard old-timers]]>
            </title>
            <description>
<![CDATA[
Score 225 | Comments 104 (<a href="https://news.ycombinator.com/item?id=26199676">thread link</a>) | @Alex3917
<br/>
February 19, 2021 | https://www.prettyfwd.com/t/XiK8ArVIT6uVItPGeH3lzA/ | <a href="https://web.archive.org/web/*/https://www.prettyfwd.com/t/XiK8ArVIT6uVItPGeH3lzA/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.prettyfwd.com/t/XiK8ArVIT6uVItPGeH3lzA/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26199676</guid>
            <pubDate>Fri, 19 Feb 2021 23:56:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The making of d20 version 3]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26199638">thread link</a>) | @blakewatson
<br/>
February 19, 2021 | https://blakewatson.com/journal/the-making-of-d20-version-3 | <a href="https://web.archive.org/web/*/https://blakewatson.com/journal/the-making-of-d20-version-3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://blakewatson.com/journal/the-making-of-d20-version-3</link>
            <guid isPermaLink="false">hacker-news-small-sites-26199638</guid>
            <pubDate>Fri, 19 Feb 2021 23:52:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Collections: The Universal Warrior, Part III: The Cult of the Badass]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26199396">thread link</a>) | @jrott
<br/>
February 19, 2021 | https://acoup.blog/2021/02/19/collections-the-universal-warrior-part-iii-the-cult-of-the-badass/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2021/02/19/collections-the-universal-warrior-part-iii-the-cult-of-the-badass/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://acoup.blog/2021/02/19/collections-the-universal-warrior-part-iii-the-cult-of-the-badass/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26199396</guid>
            <pubDate>Fri, 19 Feb 2021 23:20:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fâ€™: Flight Software and Embedded Systems Framework]]>
            </title>
            <description>
<![CDATA[
Score 135 | Comments 26 (<a href="https://news.ycombinator.com/item?id=26199346">thread link</a>) | @zeristor
<br/>
February 19, 2021 | https://nasa.github.io/fprime/ | <a href="https://web.archive.org/web/*/https://nasa.github.io/fprime/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
        <p>FÂ´ is a software framework for rapid development and deployment of embedded systems and spaceflight applications.
Originally developed at NASAâ€™s Jet Propulsion Laboratory, FÂ´ is open source software that has been successfully deployed
for several space applications. It has been used for, but is not limited to, CubeSats, SmallSats, instruments, and
deployables.</p>

<p>FÂ´ has the following features:</p>
<ul>
  <li>Component architecture with well-defined interfaces</li>
  <li>C++ framework providing core capabilities like queues, threads, and operating-system abstraction</li>
  <li>Tools for designing systems and automatically generating code from systems design</li>
  <li>A standard library of flight-worthy components</li>
  <li>Testing tools for unit and system-level testing</li>
</ul>

<table>
  <thead>
    <tr>
      <th>FÂ´ Resources</th>
      <th>&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Features</td>
      <td><a href="https://nasa.github.io/fprime/features.html">Features</a></td>
    </tr>
    <tr>
      <td>Projects</td>
      <td><a href="https://nasa.github.io/fprime/projects.html">Projects</a></td>
    </tr>
    <tr>
      <td>Installation</td>
      <td><a href="https://nasa.github.io/fprime/INSTALL.html">INSTALL.md</a></td>
    </tr>
    <tr>
      <td>Tutorials</td>
      <td><a href="https://nasa.github.io/fprime/Tutorials/README.html">Tutorials</a></td>
    </tr>
    <tr>
      <td>User Guide</td>
      <td><a href="https://nasa.github.io/fprime/UsersGuide/guide.html">User Guide</a></td>
    </tr>
    <tr>
      <td>Repository</td>
      <td><a href="https://github.com/nasa/fprime">https://github.com/nasa/fprime</a></td>
    </tr>
    <tr>
      <td>Community Forum and Mailing List</td>
      <td><a href="https://groups.google.com/d/forum/fprime-community">https://groups.google.com/d/forum/fprime-community</a></td>
    </tr>
    <tr>
      <td>Community GitHub Organization</td>
      <td><a href="https://github.com/fprime-community">https://github.com/fprime-community</a></td>
    </tr>
    <tr>
      <td>Standard Reference Application</td>
      <td><a href="https://github.com/nasa/fprime/blob/master/Ref/README.md">Ref</a></td>
    </tr>
    <tr>
      <td>Raspberry PI Reference Application</td>
      <td><a href="https://github.com/nasa/fprime/blob/master/RPI/README.md">RPI</a></td>
    </tr>
    <tr>
      <td>Architecture Overview</td>
      <td><a href="https://nasa.github.io/fprime/Architecture/FPrimeArchitectureShort.pdf">Architecture</a></td>
    </tr>
  </tbody>
</table>

<h2 id="f-system-requirements">FÂ´ System Requirements</h2>

<p>In order to develop applications with FÂ´, the following requirements of the userâ€™s system must be met.</p>

<ol>
  <li>Linux or Mac OS X operating system (or Windows Subsystem for Linux on Windows)</li>
  <li>CMake <a href="https://cmake.org/download/">https://cmake.org/download/</a> available on the system path</li>
  <li>Bash or Bash compatible shell</li>
  <li>CLang or GCC compiler</li>
  <li>Python 3 and PIP <a href="https://www.python.org/downloads/">https://www.python.org/downloads/</a></li>
</ol>

<h2 id="quick-installation-guide">Quick Installation Guide</h2>

<p>FÂ´ can be quickly installed and ready to use by cloning the GitHub repository, installing Python code (typically in a
virtual environment), and building on of our reference applications. For full install instructions please see:
<a href="https://nasa.github.io/fprime/INSTALL.html">INSTALL.md</a>.</p>

<p><strong>Clone and Install</strong></p>
<div><div><pre><code>git clone https://github.com/nasa/fprime.git
cd fprime
pip install --upgrade wheel setuptools pip
pip install Fw/Python Gds/
</code></pre></div></div>
<p><strong>Build the Ref Application</strong></p>
<div><div><pre><code>cd Ref
fprime-util generate
fprime-util install
</code></pre></div></div>
<p><strong>Run the Ref Application</strong></p>


<h2 id="further-references">Further References</h2>

<p>Full information on the code and FÂ´ are available at our Github page:
<a href="http://github.com/nasa/fprime">http://github.com/nasa/fprime</a>.</p>

<p>To start with, follow the <a href="https://nasa.github.io/fprime/INSTALL.html">installation guide</a>. Then inspect
either the <a href="https://github.com/nasa/fprime/blob/master/Ref/README.md">reference application</a>, 
<a href="https://github.com/nasa/fprime/blob/master/RPI/README.md">rapberry pi reference</a>, or the
<a href="https://nasa.github.io/fprime/Tutorials/README.html">tutorials</a>.</p>

      </section>
    </div></div>]]>
            </description>
            <link>https://nasa.github.io/fprime/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26199346</guid>
            <pubDate>Fri, 19 Feb 2021 23:16:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Free and Safe Bookmarking Tool]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26199099">thread link</a>) | @totaldude87
<br/>
February 19, 2021 | https://booky.io/about | <a href="https://web.archive.org/web/*/https://booky.io/about">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://booky.io/about</link>
            <guid isPermaLink="false">hacker-news-small-sites-26199099</guid>
            <pubDate>Fri, 19 Feb 2021 22:52:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IDOM â€“ It's React, but in Python]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26199008">thread link</a>) | @xdze2
<br/>
February 19, 2021 | https://rmorshea.github.io/articles/2021/idom-react-but-its-python/article/ | <a href="https://web.archive.org/web/*/https://rmorshea.github.io/articles/2021/idom-react-but-its-python/article/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-md-component="container">
      
      
        
      
      <main data-md-component="main">
        <div>
          
            
              
            
            
              
            
          
          <div>
            <article><a download="" href="https://rmorshea.github.io/articles/2021/idom-react-but-its-python/article/article.pdf" title="PDF Export"><svg style="height: 1.2rem; width: 1.2rem;" viewBox="0 0 384 512" xmlns="http://www.w3.org/2000/svg"><path d="M224 136V0H24C10.7 0 0 10.7 0 24v464c0 13.3 10.7 24 24 24h336c13.3 0 24-10.7 24-24V160H248c-13.2 0-24-10.8-24-24zm76.45 211.36l-96.42 95.7c-6.65 6.61-17.39 6.61-24.04 0l-96.42-95.7C73.42 337.29 80.54 320 94.82 320H160v-80c0-8.84 7.16-16 16-16h32c8.84 0 16 7.16 16 16v80h65.18c14.28 0 21.4 17.29 11.27 27.36zM377 105L279.1 7c-4.5-4.5-10.6-7-17-7H256v128h128v-6.1c0-6.3-2.5-12.4-7-16.9z"></path></svg></a>
              
                
                
                
<p><a href="https://github.com/idom-team/idom" target="_blank">IDOM</a> is a new declarative Python
package for building highly interactive user interfaces.</p>
<ul>
<li><a href="https://github.com/idom-team/idom"><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></span> https://github.com/idom-team/idom</a></li>
<li><a href="https://idom-docs.herokuapp.com/"><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M448 360V24c0-13.3-10.7-24-24-24H96C43 0 0 43 0 96v320c0 53 43 96 96 96h328c13.3 0 24-10.7 24-24v-16c0-7.5-3.5-14.3-8.9-18.7-4.2-15.4-4.2-59.3 0-74.7 5.4-4.3 8.9-11.1 8.9-18.6zM128 134c0-3.3 2.7-6 6-6h212c3.3 0 6 2.7 6 6v20c0 3.3-2.7 6-6 6H134c-3.3 0-6-2.7-6-6v-20zm0 64c0-3.3 2.7-6 6-6h212c3.3 0 6 2.7 6 6v20c0 3.3-2.7 6-6 6H134c-3.3 0-6-2.7-6-6v-20zm253.4 250H96c-17.7 0-32-14.3-32-32 0-17.6 14.4-32 32-32h285.4c-1.9 17.1-1.9 46.9 0 64z"></path></svg></span> https://idom-docs.herokuapp.com</a></li>
<li><a href="https://github.com/idom-team/idom/discussions"><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M504 256c0 136.997-111.043 248-248 248S8 392.997 8 256C8 119.083 119.043 8 256 8s248 111.083 248 248zM262.655 90c-54.497 0-89.255 22.957-116.549 63.758-3.536 5.286-2.353 12.415 2.715 16.258l34.699 26.31c5.205 3.947 12.621 3.008 16.665-2.122 17.864-22.658 30.113-35.797 57.303-35.797 20.429 0 45.698 13.148 45.698 32.958 0 14.976-12.363 22.667-32.534 33.976C247.128 238.528 216 254.941 216 296v4c0 6.627 5.373 12 12 12h56c6.627 0 12-5.373 12-12v-1.333c0-28.462 83.186-29.647 83.186-106.667 0-58.002-60.165-102-116.531-102zM256 338c-25.365 0-46 20.635-46 46 0 25.364 20.635 46 46 46s46-20.636 46-46c0-25.365-20.635-46-46-46z"></path></svg></span> https://github.com/idom-team/idom/discussions</a></li>
</ul>
<p><a href="https://github.com/idom-team/idom"><img alt="idom logo" src="https://github.com/idom-team/idom/raw/929d07ff4a643320a6148336613621242284f8d2/docs/source/branding/idom-logo.png"></a></p>
<p>IDOM takes inspiration from <a href="https://reactjs.org/" target="_blank">React</a>, and wherever
possible, attempts to achieve parity with the features it copies more directly. Nowhere
is this more evident than the version of React's often lauded
<a href="https://reactjs.org/docs/hooks-intro.html" target="_blank">"Hooks"</a> that IDOM
implements in Python.</p>
<p>At a glance, the similarities between IDOM and React are rather striking. Below is a
React component which defines a simple <code>Counter</code> displaying the number of times a button
has been clicked:</p>
<div><pre><span></span><code><span>import</span> <span>React</span><span>,</span> <span>{</span> <span>useState</span> <span>}</span> <span>from</span> <span>"react"</span><span>;</span>
<span>import</span> <span>ReactDOM</span> <span>from</span> <span>"react-dom"</span><span>;</span>

<span>function</span> <span>Counter</span><span>()</span> <span>{</span>
  <span>const</span> <span>[</span><span>count</span><span>,</span> <span>setCount</span><span>]</span> <span>=</span> <span>useState</span><span>(</span><span>0</span><span>);</span>
  <span>return</span> <span>(</span>
    <span>&lt;</span><span>div</span><span>&gt;</span>
      <span>&lt;</span><span>button</span> <span>onClick</span><span>=</span><span>{()</span> <span>=&gt;</span> <span>setCount</span><span>(</span><span>count</span> <span>+</span> <span>1</span><span>)}&gt;</span><span>Click</span> <span>me</span><span>!</span><span>&lt;/</span><span>button</span><span>&gt;</span>
      <span>&lt;</span><span>p</span><span>&gt;{</span><span>`Click count: </span><span>${</span><span>count</span><span>}</span><span>`</span><span>}&lt;/</span><span>p</span><span>&gt;</span>
    <span>&lt;/</span><span>div</span><span>&gt;</span>
  <span>);</span>
<span>}</span>

<span>ReactDOM</span><span>.</span><span>render</span><span>(&lt;</span><span>Counter</span> <span>/&gt;,</span> <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>"root"</span><span>));</span>
</code></pre></div>

<p>And this is the same component implemented in Python using IDOM:</p>
<div><pre><span></span><code><span>import</span> <span>idom</span>

<span>@idom</span><span>.</span><span>component</span>
<span>def</span> <span>Counter</span><span>():</span>
    <span>count</span><span>,</span> <span>set_count</span> <span>=</span> <span>idom</span><span>.</span><span>hooks</span><span>.</span><span>use_state</span><span>(</span><span>0</span><span>)</span>
    <span>return</span> <span>idom</span><span>.</span><span>html</span><span>.</span><span>div</span><span>(</span>
        <span>idom</span><span>.</span><span>html</span><span>.</span><span>button</span><span>(</span>
            <span>{</span><span>"onClick"</span><span>:</span> <span>lambda</span> <span>event</span><span>:</span> <span>set_count</span><span>(</span><span>count</span> <span>+</span> <span>1</span><span>)},</span>
            <span>"Click me!"</span>
        <span>),</span>
        <span>idom</span><span>.</span><span>html</span><span>.</span><span>p</span><span>(</span><span>f</span><span>"Click count: </span><span>{</span><span>count</span><span>}</span><span>"</span><span>)</span>
    <span>)</span>

<span>idom</span><span>.</span><span>run</span><span>(</span><span>Counter</span><span>)</span>
</code></pre></div>

<p>Which, when displayed in your browser, should look something like this:</p>
<p><img alt="click-counter-example" src="https://rmorshea.github.io/articles/2021/idom-react-but-its-python/click-counter.gif"></p>
<h2 id="why-do-we-need-idom">Why Do We Need IDOM?</h2>
<p>Over the <a href="https://www.npmtrends.com/react-vs-angular-vs-vue" target="_blank">past 5
years</a> front-end
developers seem to have concluded that programs written with a
<a href="https://www.youtube.com/watch?v=yGh0bjzj4IQ" target="_blank">declarative</a> style or
framework tend to be easier to understand and maintain than those done imperatively. Put
more simply, mutable state in programs can quickly lead to unsustainable complexity.
This trend is largely evidenced by the
<a href="https://gist.github.com/tkrotoff/b1caa4c3a185629299ec234d2314e190" target="_blank">rise</a>
of Javascript frameworks like <a href="https://vuejs.org/" target="_blank">Vue</a> and
<a href="https://reactjs.org/" target="_blank">React</a> which describe the logic of computations
without explicitly stating their control flow.</p>
<p><img alt="npm download trends" src="https://rmorshea.github.io/articles/2021/idom-react-but-its-python/npm-download-trends.png"></p>
<p>So what does this have to do with Python and IDOM? Well, because browsers are the de
facto "operating system of the internet", even back-end languages like Python have had
to figure out clever ways to integrate with them. While standard
<a href="https://en.wikipedia.org/wiki/Representational_state_transfer">REST</a> APIs are well
suited to applications built using HTML templates, modern browser users expect a higher
degree of interactivity than this alone can achieve.</p>
<p>A variety of Python packages have since been created to help solve this problem:</p>
<ul>
<li><a href="https://github.com/jupyter-widgets/ipywidgets" target="_blank">IPyWidgets</a> - Adds
  interactive widgets to <a href="https://jupyter.org/" target="_blank">Jupyter Notebooks</a></li>
<li><a href="https://plotly.com/dash/" target="_blank">Dash</a> - Allows data scientists to produces
  enterprise-ready analytic apps</li>
<li><a href="https://www.streamlit.io/" target="_blank">Streamlit</a> - Turns simple Python scripts
  into interactive dashboards</li>
<li><a href="https://docs.bokeh.org/" target="_blank">Bokeh</a> - An interactive visualization
  library for modern web browsers</li>
</ul>
<p>However they each have drawbacks that can make them difficult to use.</p>
<ol>
<li>
<p><strong>Restrictive ecosystems</strong> - UI components developed for one framework cannot be
   easily ported to any of the others because their APIs are either too complex,
   undocumented, or are structurally inaccesible.</p>
</li>
<li>
<p><strong>Imperative paradigm</strong> - IPyWidgets and Bokeh have not embraced the same declarative
   design principles pioneered by front-end developers. Streamlit and Dash on the
   otherhand, are declarative, but fall short of the features provided by React or Vue.</p>
</li>
<li>
<p><strong>Limited layouts</strong> - At their initial inception, the developers of these libraries
   were driven by the visualization needs of data scientists so the ability to create
   complex UI layouts may not have been a primary engineering goal.</p>
</li>
</ol>
<p>A future article will address specific comparisons to each of the projects mentioned
above, but for now, we'll just focus on IDOM and its solutions to these problems.</p>
<h2 id="ecosystem-independence">Ecosystem Independence</h2>
<p>IDOM has a flexible set of core abstractions that allow it to interface with its peers.
At the time of writing, both Jupyter and Dash are supported, while Streamlit and Bokeh
are in the works:</p>
<ul>
<li><a href="https://github.com/idom-team/idom-jupyter" target="_blank">idom-jupyter</a> (try it now
  with
  <a href="https://mybinder.org/v2/gh/idom-team/idom-jupyter/main?filepath=notebooks%2Fintroduction.ipynb" target="_blank">Binder</a>)</li>
<li><a href="https://github.com/idom-team/idom-dash" target="_blank">idom-dash</a></li>
</ul>
<p>By providing well defined interfaces and straighforward protocols, IDOM makes it easy to
swap out any part of the stack with an alternate implementation if you want to. For
example, if you need a different web server for your application, IDOM already has 3
options to choose from or, use as blueprints to create your own:</p>
<ul>
<li><a href="https://github.com/sanic-org/sanic" target="_blank">Sanic</a></li>
<li><a href="https://github.com/pallets/flask" target="_blank">Flask</a></li>
<li><a href="https://github.com/tornadoweb/tornado" target="_blank">Tornado</a></li>
</ul>
<p>You can even target your usage of IDOM in your production-grade applications with IDOM's
Javascript <a href="https://github.com/idom-team/idom-client-react" target="_blank">React client library</a>. Just install
it in your front-end app and connect to a back-end websocket that's serving up IDOM
models. IDOM's own
<a href="https://idom-docs.herokuapp.com/docs/index.html" target="_blank">documentation</a> acts as
a prime example for this targeted usage - most of the page is static HTML, but embedded
in it are interactive examples that feature live views being served from a web socket:</p>
<p><img alt="live-examples-in-docs" src="https://rmorshea.github.io/articles/2021/idom-react-but-its-python/live-examples-in-docs.gif"></p>
<h2 id="declarative-components">Declarative Components</h2>
<p>IDOM, by adopting the hook design pattern from React, inherits many of its aesthetic and
functional characteristics. For those unfamiliar with hooks, user interfaces are
composed of basic <a href="https://en.wikipedia.org/wiki/HTML_element" target="_blank">HTML elements</a> that are
constructed and returned by special functions called "components". Then, through the
magic of hooks, those component functions can be made to have state. Consider the
component below which displays a basic representation of an
<a href="https://en.wikipedia.org/wiki/AND_gate" target="_blank">AND-gate</a>:</p>
<div><pre><span></span><code><span>import</span> <span>idom</span>

<span>@idom</span><span>.</span><span>component</span>
<span>def</span> <span>AndGate</span><span>():</span>
    <span>input_1</span><span>,</span> <span>toggle_1</span> <span>=</span> <span>use_toggle</span><span>()</span>
    <span>input_2</span><span>,</span> <span>toggle_2</span> <span>=</span> <span>use_toggle</span><span>()</span>
    <span>return</span> <span>idom</span><span>.</span><span>html</span><span>.</span><span>div</span><span>(</span>
        <span>idom</span><span>.</span><span>html</span><span>.</span><span>input</span><span>(</span>
            <span>{</span><span>"type"</span><span>:</span> <span>"checkbox"</span><span>,</span> <span>"onClick"</span><span>:</span> <span>lambda</span> <span>event</span><span>:</span> <span>toggle_1</span><span>()}</span>
        <span>),</span>
        <span>idom</span><span>.</span><span>html</span><span>.</span><span>input</span><span>(</span>
            <span>{</span><span>"type"</span><span>:</span> <span>"checkbox"</span><span>,</span> <span>"onClick"</span><span>:</span> <span>lambda</span> <span>event</span><span>:</span> <span>toggle_2</span><span>()}</span>
        <span>),</span>
        <span>idom</span><span>.</span><span>html</span><span>.</span><span>pre</span><span>(</span><span>f</span><span>"</span><span>{</span><span>input_1</span><span>}</span><span> AND </span><span>{</span><span>input_2</span><span>}</span><span> = </span><span>{</span><span>input_1</span> <span>and</span> <span>input_2</span><span>}</span><span>"</span><span>),</span>
    <span>)</span>

<span>def</span> <span>use_toggle</span><span>():</span>
    <span>state</span><span>,</span> <span>set_state</span> <span>=</span> <span>idom</span><span>.</span><span>hooks</span><span>.</span><span>use_state</span><span>(</span><span>False</span><span>)</span>

    <span>def</span> <span>toggle_state</span><span>():</span>
        <span>set_state</span><span>(</span><span>lambda</span> <span>old_state</span><span>:</span> <span>not</span> <span>old_state</span><span>)</span>

    <span>return</span> <span>state</span><span>,</span> <span>toggle_state</span>

<span>idom</span><span>.</span><span>run</span><span>(</span><span>AndGate</span><span>)</span>
</code></pre></div>

<p><img alt="and-gate-demo" src="https://rmorshea.github.io/articles/2021/idom-react-but-its-python/and-gate.gif"></p>
<p>Here's a very high level summary of how it works... the first time a view of the
component above is rendered, the <code>AndGate</code> function is called where its initial <code>state</code>
for <code>input_1</code> and <code>input_2</code> is <code>False</code>. The function then returns a series of HTML
elements with callbacks that respond to client-side events. Machinery behind the scenes
subsequently realizes that declaration and displays two checkbox buttons with the text
<code>False AND False = False</code>. Later, when a user clicks the now visible checkbox buttons,
client-side events are triggered, the associated callbacks respond by inverting the old
<code>state</code> from <code>False</code> to <code>True</code>, and a re-render of the component is scheduled. When
re-rendering, the function is again called, this time though, where <code>input_1</code> and
<code>input_2</code> have been updated to reflect the new <code>state</code>, thus causing the displayed text
to change.</p>
<p>In the code above, consider the fact that it never explicitely describes how to evolve
the frontend view when events occur. Instead, it declares that, given a particular
state, this is how the view should look. It's then IDOM's responsibility to figure out
how to bring that declaration into being. This behavior of defining outcomes without
stating the means by which to achieve them is what makes components in IDOM and React
"declarative". For comparison, a hypothetical, and a more imperative approach to
defining the same interface might look similar to the following:</p>
<div><pre><span></span><code><span>layout</span> <span>=</span> <span>Layout</span><span>()</span>

<span>def</span> <span>make_and_gate</span><span>():</span>
    <span>state</span> <span>=</span> <span>{</span><span>"input_1"</span><span>:</span> <span>False</span><span>,</span> <span>"input_2"</span><span>:</span> <span>False</span><span>}</span>
    <span>output_text</span> <span>=</span> <span>html</span><span>.</span><span>pre</span><span>()</span>
    <span>update_output_text</span><span>(</span><span>output_text</span><span>,</span> <span>state</span><span>)</span>

    <span>def</span> <span>toggle_input</span><span>(</span><span>index</span><span>):</span>
      <span>state</span><span>[</span><span>f</span><span>"input_</span><span>{</span><span>index</span><span>}</span><span>"</span><span>]</span> <span>=</span> <span>not</span> <span>state</span><span>[</span><span>f</span><span>"input_</span><span>{</span><span>index</span><span>}</span><span>"</span><span>]</span>
      <span>update_output_text</span><span>(</span><span>output_text</span><span>,</span> <span>state</span><span>)</span>

    <span>return</span> <span>html</span><span>.</span><span>div</span><span>(</span>
        <span>html</span><span>.</span><span>input</span><span>(</span>
            <span>{</span><span>"type"</span><span>:</span> <span>"checkbox"</span><span>,</span> <span>"onClick"</span><span>:</span> <span>lambda</span> <span>event</span><span>:</span> <span>toggle_input</span><span>(</span><span>1</span><span>)}</span>
        <span>),</span>
        <span>html</span><span>.</span><span>input</span><span>(</span>
            <span>{</span><span>"type"</span><span>:</span> <span>"checkbox"</span><span>,</span> <span>"onClick"</span><span>:</span> <span>lambda</span> <span>event</span><span>:</span> <span>toggle_input</span><span>(</span><span>2</span><span>)}</span>
        <span>),</span>
        <span>output_text</span>
    <span>)</span>

<span>def</span> <span>update_output_text</span><span>(</span><span>text</span><span>,</span> <span>state</span><span>):</span>
    <span>text</span><span>.</span><span>update</span><span>(</span>
        <span>children</span><span>=</span><span>"</span><span>{input_1}</span><span> AND </span><span>{input_2}</span><span> = </span><span>{output}</span><span>"</span><span>.</span><span>format</span><span>(</span>
            <span>input_1</span><span>=</span><span>state</span><span>[</span><span>"input_1"</span><span>],</span>
            <span>input_2</span><span>=</span><span>state</span><span>[</span><span>"input_2"</span><span>],</span>
            <span>output</span><span>=</span><span>state</span><span>[</span><span>"input_1"</span><span>]</span> <span>and</span> <span>state</span><span>[</span><span>"input_2"</span><span>],</span>
        <span>)</span>
    <span>)</span>

<span>layout</span><span>.</span><span>add_element</span><span>(</span><span>make_and_gate</span><span>())</span>
<span>layout</span><span>.</span><span>run</span><span>()</span>
</code></pre></div>

<p>In this imperative incarnation there are several disadvantages:</p>
<ol>
<li>
<p><strong>Refactoring is difficult</strong> - Functions are much more specialized to their
   particular usages in <code>make_and_gate</code> and thus cannot be easily generalized. By
   comparison, <code>use_toggle</code> from the declarative implementation could be applicable to
   any scenario where boolean indicators are toggled on and off.</p>
</li>
<li>
<p><strong>No clear static relations</strong> - There is no one section of code through which to
   discern the basic structure and behaviors of the view. This issue is exemplified by
   the fact that we must call <code>update_output_text</code> from two different locations. Once in
   the body of <code>make_and_gate</code> and again in the body of the callback <code>toggle_input</code>.
   This means that, to understand what the <code>output_text</code> might contain, we must also
   understand all the business logic that surrounds it.</p>
</li>
<li>
<p><strong>Referential links cause complexity</strong> - To evolve the view, various callbacks must
   hold references to all the elements that they will update. At the outset this makes
   writing programs difficult since elements must be passed up and down the call stack
   wherever they are needed. Considered further though, it also means that a function
   layers down in the call stack can accidentally or intentionally impact the behavior
   of ostensibly unrelated parts of the program.</p>
</li>
</ol>
<h2 id="virtual-document-object-model">Virtual Document Object Model</h2>
<p>To communicate between their back-end Python servers and Javascript clients, IDOM's
peers take an approach that aligns fairly closely with the
<a href="https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller" target="_blank">Model-View-Controller</a>
design pattern - the controller lives server-side (though not always), the model is
what's synchronized between the server and client, and the view is run client-side in</p></article></div></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rmorshea.github.io/articles/2021/idom-react-but-its-python/article/">https://rmorshea.github.io/articles/2021/idom-react-but-its-python/article/</a></em></p>]]>
            </description>
            <link>https://rmorshea.github.io/articles/2021/idom-react-but-its-python/article/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26199008</guid>
            <pubDate>Fri, 19 Feb 2021 22:43:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Meth Kingpin Was Director of Operations at US Air Force Combat Controller School]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26198555">thread link</a>) | @AndrewBissell
<br/>
February 19, 2021 | https://narco.news/meth-kingpin-was-director-of-operations-for-combat-controller-school | <a href="https://web.archive.org/web/*/https://narco.news/meth-kingpin-was-director-of-operations-for-combat-controller-school">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-6d96295c=""><div data-v-6d96295c=""><p>On the skydiving forum <em><a href="https://www.dropzone.com/forums/topic/222999-weekend-raeford-pics/?tab=comments#comment-439487">Dropzone</a></em>, a post from 2002 shows a picture of an individual identifiable as Tim Thacker along with his siblings. </p><figure><div><div><p><img src="https://publish.narco.news/content/images/2021/02/Screen-Shot-2021-02-11-at-12.35.02-PM-3.png" width="1214" height="1130"></p><p><img src="https://publish.narco.news/content/images/2021/02/Screen-Shot-2021-02-16-at-4.59.19-PM-2.png" width="488" height="606"></p></div><div><p><img src="https://publish.narco.news/content/images/2021/02/Screen-Shot-2021-02-19-at-1.21.51-PM.png" width="1572" height="1252"></p><p><img src="https://publish.narco.news/content/images/2021/02/Screen-Shot-2021-02-19-at-1.31.10-PM-2.png" width="1274" height="990"></p></div></div><figcaption><em><a href="https://www.linkedin.com/in/tim-thacker-8b173b71/">LinkedIn</a></em>;<em> <a href="https://www.facebook.com/PoliceWarsaw/posts/yesterday-may-11-2016-officers-with-the-warsaw-police-department-responded-to-a-/960425930732138/">Facebook</a></em>;<em> <a href="https://www.dropzone.com/forums/topic/222999-weekend-raeford-pics/?tab=comments#comment-439487">Dropzone</a> (<a href="https://web.archive.org/web/20210219184359/https://www.dropzone.com/forums/topic/222999-weekend-raeford-pics/">archived link</a>)</em></figcaption></figure><p>The user SkymonkeyONE identifies Tim Thacker as the subject and lists his username on the <em>Dropzone</em> forum: "USSkydiver". Curiously, the user USSkydiver identifies himself as "Tim Tennant" in several of his <a href="https://www.dropzone.com/profile/1794-usskydiver/content/page/3/?all_activity=1">posts</a>, including one from <a href="https://www.dropzone.com/forums/topic/184982-it's-my-last-day-at-work---and-i-am-not-sad!/">February 4, 2005</a>, in which he states that he will officially retire from the United States Air Force on April 1, 2005 after 25 years of active duty service.</p><figure><div><div><p><img src="https://publish.narco.news/content/images/2021/02/Screen-Shot-2021-02-19-at-1.30.33-PM.png" width="2176" height="732"></p></div></div><figcaption><a href="https://www.dropzone.com/forums/topic/184982-it's-my-last-day-at-work---and-i-am-not-sad!/?tab=comments#comment-86729">Link</a></figcaption></figure><p>In an <a href="https://www.socom.mil/TipOfTheSpear/June%202004%20Tip%20of%20the%20Spear.pdf">article</a> from the June 2004 issue of U.S. SOCOM's <em>Tip of the Spear</em>, a publication about the U.S. special operations forces (SOF), Master Sgt. Tim Tennant, United States Air Force, is listed as the Director of Operations for the USAF's Combat Controller School at Pope AFB, which is part of the Fort Bragg military complex near Fayetteville, NC. The USAF Combat Controllers (CCT) are an elite SOF unit that specialize in airborne warfare. According to a <a href="https://web.archive.org/web/20130628090639/http://www.af.mil/information/factsheets/factsheet.asp?id=174">fact sheet</a> published by the USAF about CCT:</p><blockquote>Air Force Special Operations Command's combat controllers, or CCT, are Battlefield Airmen assigned to special tactics squadrons. The CCT mission is to deploy undetected into combat and hostile environments to establish assault zones or airfields, while simultaneously conducting air traffic control, fire support, command and control, direct action, counter-terrorism, foreign internal defense, humanitarian assistance and special reconnaissance.</blockquote><figure><div><div><p><img src="https://publish.narco.news/content/images/2021/02/Screen-Shot-2021-02-19-at-1.07.40-PM-2.png" width="1008" height="1302"></p></div></div><figcaption><em><a href="https://www.socom.mil/TipOfTheSpear/June%202004%20Tip%20of%20the%20Spear.pdf">U.S. SOCOM</a></em></figcaption></figure><p>In August of 2019, Tim Thacker of Raeford, NC was sentenced to 40 years for his role in a large-scale, multi-state <a href="https://www.justice.gov/usao-ednc/pr/hoke-county-man-sentenced-forty-years-drug-distribution">methamphetamine distribution</a> conspiracy going back over a decade, which he ran out of the municipal airport, P K Airpark-5w4, owned by the Thacker family, the same airport implicated in a massive cocaine trafficking conspiracy in 1984. His father, Gene Paul Thacker, a former Green Beret and Vietnam War veteran, was acquitted essentially on the basis of his character despite "overwhelming" evidence implicating him, <a href="https://www.sun-sentinel.com/news/fl-xpm-1985-05-31-8501210917-story.html">according</a> to the prosecutor.</p><figure><div><div><p><img src="https://publish.narco.news/content/images/2021/02/Screen-Shot-2021-02-19-at-3.13.26-PM.png" width="1234" height="700"></p><p><img src="https://publish.narco.news/content/images/2021/02/Screen-Shot-2021-02-19-at-3.12.41-PM.png" width="1234" height="700"></p></div></div><figcaption>Google Maps</figcaption></figure><figure><img src="https://publish.narco.news/content/images/2021/02/Screen-Shot-2021-02-19-at-1.30.33-PM-3.png"></figure><p>On the <a href="https://www.dropzone.com/forums/topic/184982-it's-my-last-day-at-work---and-i-am-not-sad!/">Dropzone forum</a>, when asked about his plans after retirement from the Air Force, Tim mentioned that he would continue fighting the global war on terror with his old unit as a contractor.</p><figure><div><div><p><img src="https://publish.narco.news/content/images/2021/02/Screen-Shot-2021-02-19-at-3.25.33-PM.png" width="1082" height="554"></p></div></div><figcaption><em><a href="https://www.dropzone.com/forums/topic/184982-it's-my-last-day-at-work---and-i-am-not-sad!/">Dropzone</a></em></figcaption></figure><figure><div><div><p><img src="https://publish.narco.news/content/images/2021/02/Screen-Shot-2021-02-20-at-2.27.46-PM-1.png" width="1056" height="1100"></p><p><img src="https://publish.narco.news/content/images/2021/02/Screen-Shot-2021-02-16-at-4.59.19-PM-5.png" width="488" height="606"></p></div><div><p><img src="https://publish.narco.news/content/images/2021/02/Screen-Shot-2021-02-20-at-2.44.08-PM.png" width="632" height="662"></p></div><div><p><img src="https://publish.narco.news/content/images/2021/02/Screen-Shot-2021-02-20-at-2.41.42-PM.png" width="822" height="746"></p></div></div><figcaption><em><a href="https://www.facebook.com/PoliceWarsaw/posts/yesterday-may-11-2016-officers-with-the-warsaw-police-department-responded-to-a-/960425930732138/">Facebook</a> ;</em><a href="http://www.omniskore.com/comp/2003/nats/teams_pics/702.htm"><em>Omniskore</em></a><em>; </em><a href="https://www.dropzone.com/forums/topic/222999-weekend-raeford-pics/?tab=comments#comment-439487"><em>Dropzone</em></a></figcaption></figure></div></div></div>]]>
            </description>
            <link>https://narco.news/meth-kingpin-was-director-of-operations-for-combat-controller-school</link>
            <guid isPermaLink="false">hacker-news-small-sites-26198555</guid>
            <pubDate>Fri, 19 Feb 2021 21:57:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rethinking Our Sister Planet: A Handbook for the Development of Venus (2017) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26198358">thread link</a>) | @asterialite
<br/>
February 19, 2021 | http://venuslabs.org/Rethinking%20Our%20Sister%20Planet%20(ebook).pdf | <a href="https://web.archive.org/web/*/http://venuslabs.org/Rethinking%20Our%20Sister%20Planet%20(ebook).pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>|w&lt;%/â€“JsÃ—Ã.8&lt;Ã¼EMÃ’/WÃ¤Ã†Fâ„¢Ã¨ÃÃ‡Â²@Æ’	oÃ²uÂ«zÂ½Â§ï¿½esÂ¦&amp;\Ã«Ã¤Â¦ÃÂ½Ãš/Ã¥Æ’Ã“ï¿½qÂ«Ã¢Ã“&lt;Å¾Ã¸bÃ•Ã¹Ã¬ÂºÂ±
oÃ˜ÂºÃšÃ¶Â¿Å’Ã£Ã°Â¤nÃ”jwâ€“Ã£Ã´ÂºÂº2Â­ÃŠÃ‹Â¾â€˜Ã§oÂ¶NÂ¶ÃŠÂ¢Â²Ã–ÃºÅ“sRËœÃ¿Ã¥!Ã¨}ÃºÃ¥!Ã¥YVÂ«ÃšYÃ¶Ã’Ã¿Ã©?Ë†Â¢Å¸Å’Âº	{Ã‘Ã™Ã´Âº4Ã½ÂºÃ­:Ë†Ã ÃœÃ‹Ã¾[gJTlrÃ«â€¹uÂ°Â¸}ï¿½â€¦ÃˆÅ¸â€¡Ã²Â«Â¥e*â€ºÃ±Ã¢â€¡PÃ¶~Æ’Â·ÃUÂ¡Â¬jÃ½Ã¶Ã­g!Â¸Â¾Ã˜ÃºÂ±X7DFÃ¼Ã’mÃ§ÃºÃ¢Ã“Ã¸
|â€¦Ã¡Ã‹Â¼krw&gt;Ã &lt;Ã¥/Ã£Â«|Ã›Ã‰jâ€¢mÃ›YÃ­ÃŒÂ¤Æ’0Nâ€™;WÃ¨ÃŠÃ’Â³Å“nÂ¹\uÃ¯,Â¹(Ã¿Ã«RÂªR]Ã¡

^kÂ³5uMMÃŸ$Â®Â©Ãiâ€ºÂ¢QÂªâ€¡Ã±Ã‡ÃµÃ­ÃºoÃ“Â¼Å’KÂ´â€”%lÂ§(Ã¬Â´Ë†eÃ¼Ã°Â¶3Ã“Å¡Â·BÃ¯Â§Â©iÂ¦ÃµÃ¯Å¸Â¿â‚¬Ãº/c3ÃÃ¢!Ã”Ã†-2lâ‚¬Ã†Â¹EMÂ¸ÃŒ\Â·ÃµÂ´Ãˆ]Ã“LÃ’Â¶ndjÃš^Ã°jhÅ¾Â¾ÂºjÃƒÂ¾2I#Ã·Â¡Ã‚MhÃ‡â€šâ€œwÃ¥Ã–Ã‡Ã¯&gt;â€¡:Ã½4Ã©ÃŠÃ¡Ã¨ÃªÅ“N|Ã™Â¶Ã‰ÃƒJJÃ›â€¡NÃ¡ÃÂ¨Ã¶Â¶Ã“Ã½'Ë†EL/Å¾â€™/
#Ã‡:â€¡Bï¿½3~Ã†Å¾P9tÂ«LTI}â„¢~Â«sstÃšÃ–Â¹Ã¯&gt;Ë†ÃµÂ¿Ã¸Ã°Ã¸Ãƒ#Â¾Ã’Â¨Ã„Ã”pÃ§Â­Ã—beâ€¢Â­Ã¬:Ã­Ã…Uwu7MÂ©~ÃÃ¢fÃ™Ã¶^uÃ–Å¡+0Ã¾,FÃ‡ËœÃŠgw4Â«Ãš)aÃ¿â€¹AÃ‡|kÃœlZÃ…VÂªÂ¨Ãš:Ã®Ã™23(7â€°Ã¡Ã‹u]Ã­&amp;Ã‡tÃˆPÃµâ€™?ï¿½Eâ€ Ã®:Ã•ï¿½Å½@â€¢&gt;*Ã·Â»&nbsp;Ã¹Ã+Ã—UÃ—Ã…Â½O,T_Â¼'Â´Ã¹Å¾ÃŸÃ­{ÃªÃ Â»XÃÅ½z:Ã¬,(Ã±Â¯bÃ­;ÃÃmÃ’Ã¶lÂ´â€¡Â¡Ã¼Ã›8Â¬Ã¯{Ã­Tâ€¡Ã¤Ã˜Ã©Ã©Ã‹Ã¸T0'h+Pâ€¢e{â€™Ã”Ã¦Â·Â¡Ã¾(?â‚¬:Ã¸.Â­?_Ã•Ã¿}Â¨5~Ã¬â€˜ï¿½ÂºÂµâ€¦1
Eg&nbsp;HÃŒÂ¬Â¬qÃ½:ËœÃ™Ã–:&lt;03^f~hÃ©â€Ã¿O[Ã»Â£NWâ€¦,CÃ¹5lÃ+Dâ€“}q@â€“Ã•ÃŸ
XÂ¢|_)Â°Â¬Ã«Â¢uhÃÂºÃ¡ÂºJÂªvÃ¿_Ã›Ã‹KÃ—BÃŸ$.iÃ§?Â½ï¿½O`RTe/BÂ¬Ã»Â¤F;Â¨9Å¾C5Â¢
Ã¬â€°Ã¢Â°ytÃ²v5I]a}*Ã´Ã€Ã±5Â¼â€°pÃ§Å¾Â¿&amp;GÃ¼ï¿½cÂ¨Ãµa ÂªpÅ¸9qÃ«@+'Â¤ÃP`[â€šJ{hiÂ»Â¢Ã©Ã¢â€˜Ã«Â©0Ã‘Ã˜ï¿½Ã Ëœ&nbsp;â€¹p
Ãˆ	gÃ«Å¸Ãâ€¡ÃªB4â€ Ãµ_Ã±@4Ã,MÂ®Ã–â€°ÃiÂ·Ã‰ÃÃ®Ã«Ã â€!â€“Ã„Ã¶QÃÂ½â€ Ãâ€™â€ Å’vVÃºÅ“Å¾Ã”Â³Å¡â€ÃÃ´{Ã‰ï¿½CÃ
Â¨kgÂ©Å¡Ã¦2Ãšeâ€â€^Ã‹tÂ¥BÂ·Ã•Ã£Â¶Â¸ÃˆÂ¥Å {Â¬T&amp;Ã†Ã£Ã™5Â«Ã»_ÃšIâ€¡Â¹Mhâ€ºY,:Ã)&gt;nq8Æ’ÃÃ¹SÂ´
Ã§Ã°Ã”Ã“ÃÃœNÂ¬â€¡Å¡â€œ8Ã\Ã†7Ã&nbsp;!Â¨EÂ½hÂ¾ÃÃ±Ã¦â€”Ã°Ã¼&amp;wÂ±/Ã“h`X?â‚¬Ã§ï¿½I}~ï¿½dÂºÂ°JÃ¨Â¶+Â¥:Ã¸Ã¼!â€Ã¯~5ÃŒÃ¶Â¬*%Ãºâ€¢
R	Ã³Ã z~â€Ã·&nbsp;Â¼
ï¿½Ã³}RÃuhÃ³nÃ²Ã¥â€”Ã—Âª4Å¡Â´(ï¿½Â¸Ã¶Â¿,ÃÃº[ZÃ–Ã—ï¿½.
Â®Ã¿ÃŸ^Â¾Â­ÃŸÃ„ÂºÃ°Ã´Ã«Ã¸Ã´ï¿½Â¼%enaSÂ·iÃµwÃ½â€¡h~Ã¦;Ã¿Ã½@Ã™Ã¹Ã˜ÃNÃ¬VÃœÅ¾Ã¡cLcÃ¥*7@ZÃ–â€˜â€GPÃ¾ÃŒ+mÅ¸ËœÃ‘_kHr&gt;â€Â©Ãœ^UxÂ·Â­[ÃŠÃ‹XYâ€œâ€œÃªâ€ºtvÃ›aÃ¹Ãƒâ€ºII*â€L
B)ÃœÂ¢~Â¾Ã„Ã”~=ï¿½FÂªÂ½)â€”Ãº\Å½Ã–Ã‹xÃ›Ã£Ã¤HÂ¤7N6F&amp;â€Âºâ€ºÂ¡uxâ€ 6mâ€ Ã»Å¾rÃ¶Å“bÂ¼OÃ€A^Â¿Â´&amp;Ã—Ã®ÃŠÂªÃŠ6Âª$Â³â€ºÃ¡,Ã¢&amp;!ÃªfËœ(DÃšÃ‘O!Ã¨JÂµÂ¬D#â€°uÃ­}Ã³wÅ¾ÃŸ$ÃºbWYÃ£Â¬â€”]Ã­Zgl*Ã¸=Å¡Ã‰ï¿½Å’JÂ©â€Ë†â€/ÃŸÃŠÃ«`Ã¹1Â´Ãƒâ€º
â€ â€š9Å¡CÃÃªÃ‘â€¢TÃ‘ eÃ»Ã–Â¿ï¿½}Ã‚`iÃÃª ÃšÂ£Ã¬
Ã #Ã²mcÂ®Ã”TeQÃ±Å¸`7*ÃÃ†xâ„¢Å¡Ã¼Â°Â¦Ã©ÃœÃ®[Ã¹Ã„Mï¿½HÅ¡ÂºÃï¿½	b`DÃ¼Â±Ã†gÂ¸Å’lï¿½Ã¿ï¿½rï¿½Ã|6Â¦â€ Ã¾lÃ·CÃ˜Ã®?lÂ¢zÃœZIxcâ€”Ã€Ã§ÃœU	vÃ•hï¿½TÃ˜:Ã¹Æ’Â£&gt;â€œÃƒ(â€ºÂ¢Â¡#Haâ€¢ÃºÃ Â¦Â¯7Ã 2Q\Å¸@Ã¹1luâ€Ëœ+Ã¤2Ã«Â²?â€˜Ã¢Ã–Â³vï¿½kbÃªÂ¶Â¸Ã›Ã Å¡Ã´)â„¢Ã™â€šÃ¤ÂºKÃ­/B&amp;8Ã¡Ã•Ã†Wâ€šÂ²G\#â€Ãâ€¦8+[Ã¼ZÂ¤Â¤Â£â€°Â°)`+QlXÂ­&gt;~Ã lï¿½â€“NÃ«eÂ¨UX5l&amp;gï¿½ï¿½	Ã™Ã˜Ãâ€¡g0jP;Â¸L
Å“ÃnÂ¾\Æ’Xâ€¹Ã²Ã€Â¾Qâ€IAÃK2vÃ‚$~"ÂµÂ¬ÂµÃ«Ã˜Ã™ï¿½TÃ¨Ã¦Ã½$Ã“â€¢Ã±â‚¬Ã‘Ã Â»h1yAÅ¡+JÃ¸â€¡:{Ã¥ÃŸÂ£ÂªBaÃ¥Â£Ë†Â´~ w&nbsp;Ã³â€¡	ÃŸâ€Hk'Â¨Zz-=zÃ»Ãe Â§Â®uQÃ¹ÃŸÂ¸!Ã§Ã¨â€”YÃ¹Ã”Â¹Â¼Ã‡R?iâ€¡Ã£Ã¿ÃhÃ§pXBÃ€Ã…â€ Ã™â‚¬Â¹MÃ†Ã¸qÃŠ?@Â£Ã¯Â¡â€Ã„Å¡Hâ„¢râ€â€ºÂ¤Â¬â€“Ã¯mÃ¦Ã—YÂ·mÂ­sÃ¢BÂµâ€¡â€¢ZÃ¹FgÃƒÃŸÂ¦.â€ÃŸ~Ã«0tOÂ®â€š:Ã°Ã¡p3-\â€šÂº]PZ=Â¨:Ã€[RNÂ²ï¿½Ã¨Â¢`Â°
ÃÂ¯w9Â½â€”Ã‹\Â¦d_Ã·;^&amp;xÃ„|Ã¦Â±Ã Â¢tÃ®Ã‘/Ã¨Å¡ThÃ‘Â¬&nbsp;bâ€šâ€¹3Å Ã¼Â¿ï¿½Ev~'Ë†Å½Ã¤Â®,Hâ€œÃ±9â‚¬Ã¨Ã’â€*â€Â°dÃœ+Ã‹Xâ€ Â²ÃšÂ©â€-ÃªÃšÅ’Ã—ÃUFÃ»Ã¿]Ã¤"Â©' Lâ€°â€”Ã›Ã°ï¿½Tâ€˜&gt;1Ã:â€œÃ¾{â€šNÂ¥9&amp;â‚¬â€ Ã¶ï¿½&amp;Å¸Ã‚f]biÅ¾N3Â¼Ã7Ã½fÂªÃÂ·Aâ€°LÂº4Ã´Ã›hÅ½â€™YR2j5ÃŒoCÃ–,Ã¬0â€¡ZMÃœa#Ã°Ã•Ã²TÃœâ‚¬AÃï¿½&lt;ï¿½Ã²c@Ë†Â®â€“4Ã—mÃ›:xÃ¦4oÃ­Ã¬FÂ³jÃœ*ÂºÂ¿]Ã†YtMmÃŸ$*Ã³cÃ’Ë†Ã1ÃŸâ€dQ$<dÃ—Â¤a{!Å¸@ï¿½Ã²p% Ã«Ã“ï¿½}Ã'$Â¬jÃ›zfÃµjbÃ¶':e="">ÃŒÃ†Â¶0Ne4Ã€ÃˆÃ…P&amp;Â£Â¯Å¾Ã¸UQ}cÂ´â€™Ã—Ã‘Ã¨@Æ’`Ã€ÃÅ“Ã³â€¢_Ã„ÃŠXÃ¸ChÅ½&amp;?Ã“Ã±Â¡Uâ€Â¾ï¿½ÃºÃ’Â¡|Ã›Â¡PÃ¬9pXË†6aÂ¼Â¸CÂ¥ËœÆ’Ã `oHâ€¹@ eOxâ€œ&amp;ÃÅ’aÅ’ï¿½gÃÂ¶Å’gAQÃ©cÃ²Ã”)Ã­sbÃº:Ã´SÃ§,Å½Ã¬â€“â€°zÅ¡Ã‡ÂªzÃ“$MÃ¤:/â€ l0ÃŠâ€6?Ã‹&nbsp;0Ã¾EÂ¨â€¹qËœÅ¸Â«Â¶sÅ¾oÂ®"$-Ã¿Ë†Ã¦Ã²Ã‘Ã¼Â½Ã¹Ã¸ ÃkÆ’Â¤&amp;Ã»FI#Ë†y=&gt;Â¯Ã«Â©Å¡Ã´ÃŠâ„¢â€¹Ã©Ã‡Ã¡Zgâ€“ÃšÃŒmÃ¿hÃ®QIÃ¥*Ãºâ€¦&nbsp;â€“1uï¿½Â¦aÃ{Â³Â¼W"yÃ™gÂ±Ã¶1i$â€¡Ã²d&gt;Â©jÃ™ÃFI;-Â«iÂ¾#$Ã¼?EË†Â¯Å’Â¸@Ë†=IA_ÃœRH5MOï¿½0mâ‚¬â‚¬Ã¨Ãº?ï¿½Ã²cÃ¨Ã«Ãl;Â£Â¼rÃ“Ã­38Ã¿-%Â°Jâ„¢ÂµÂ¨~P2â€¦\Ã’#AÃ§IÃŠâ€OjÂ¸5Å½Ë†(ÃƒÂ¥Ã¹]$â€ Â´Å“Ã«Â»t]Ã»Ã™Â»'Â¬Ã®Æ’GPÃ§Ã‘{Ã¨ï¿½Ãâ€ &nbsp;Â¹)Ã¨VtPÃ¾ÃqÃÃ½Ã³Ã€?t2ï¿½E:UÃ£Ã“6Æ’Å¸XBMË†Â¸;â€¦Â³yÃ¯Â¡qtâ„¢ÃÃ´Ã³qÃ³qÂ³Â¿/ÃtÃ±(!vwâ€¢Ãµ?Â¶ï¿½k[ERÅ¾Ã“sÃ3O`Â·Kâ€°ÃŒ)Å¡aÃ–U,PnÃ¤Ã‰X~Bâ„¢Uâ€¦Ã–ï¿½ÃÃ©â€¦LÃ‰!cÅ â€-ÃªÃµGP2Â¥wÂ¥SÃ›â€”&amp;Ã½ÂµXÃ®ÃŸÂ¥Â¿FÃ‡ÃRÅ½Â¥)Âª6gÃ¯FÃ†Ã±vdo_â€qÃ¼Ë†Ã¾Â»Dâ€™â€”{Ãâ€œâ€¦+Ã›U=Å¾â€¹Â¼TÃÃ›*Â¯ÃˆÂºÂ«z'Æ’Ã»Ã³Ã¾Ã³Ã¾Ã³Ã¾Ã¤1Ã¯DÃ¦Ã–a9â€”,ï¿½p2Ã›Ã™nÂ¯Ã“Ã¾&gt;Ã‡Ãˆ?Ã‡Ãˆ?Ã‡ÃˆÃ¿f1rTÂ¥ÃœÃ½AÂº~â€“â€ Ã‡â€”w.Å /â€˜Ã+N`3ï¿½Â¦Ã§~Å½Â¹aNYÃŒ â€¹eÅ½â€“ÂªF(0lÃœ|{Â³Ã‘Ã¬Â¹oÂ¡Â®â€ Â°Câ€”HI!Ã‰t8;Â¬~Ã§oÂ°Â«Â®TÂ²Ã¶gÃ¦m6&nbsp;XÃ’3Â¡Â³Â±Ãœï¿½ KR`ÃÂ¬{]Ëœ:Ã¾Ãšâ€ â€vÂ¿NÃ¨â€”â€°ÃÃ²O(&gt;Wt3UÂ¹%X9=Ã­Â³Â¤Wumï¿½Ã”Ã•Ã«!jÃÃœÂº6Ã½ohÂ®Å’sï¿½Â´Ã’Â¦Ã–&gt;ÃƒX9Â°â€œ.Â¹Â¸Ã¼Ã‰	gÃ§â€¹RÃ«lHÃ’Ã´ï¿½Ã”Â¦Ã7Y'Ã”â€ Fd`â€šm$xÃÃ‡Ë†ÃŠÃ¡â€˜0zrÃƒÃ¾t_Ã&amp;&nbsp;@â€zOÂ°Ã¼HÃ¨Ã³Ã‘&amp;Ã¦CÅ½Ã‚Â¼]CÃªÅ’Â¿Â«Â®iÅ’Ã¦ÃÅ“&nbsp;Ã¡â€Ã´rGÂ¢}â€¡Ã©Â¨Â¯n:â€ Lâ€ÃÃŸ
8`Â¼ï¿½RÃ©wÂ®Ã¿Ã§J&lt;{Bendstream
endobj
1195 0 obj
7817
endobj
1200 0 obj
&lt;&gt;
stream
xÅ“Ã­]QoÃœ6Ãª7'@ÃªÃ†IÅ¡Â¦=Ã¬CÃšÃ³Ã¶bUER:Ã ^Å½Ã—vÅ’8Ã«8Â±['OÂ½kï¿½z@Ã›Â¿p?Ã¼(R?â€™CIÂ»ÃÃ­]ï¿½â€¡Â²ÃœÃ‘ï¿½ÃÃŒ73Â¤Ã¤Å¸gyÃ†fyÃ³Â¯Ã½Ã¯Ã·?msÂ®f?Ã¾ÂºÃ½Ã³v&gt;SYÃY!fÂ¢Ã¹Â¬*â€¹"Â«Ã•Ã¬â€”Ã.Â¿Å¾Ã½{â€ºÃÅ¡Â¿Ã¼Â¸Ã<g(xÂ¡Â¤Ã”Â¿oÃ¿@Ã¶- ovfâ€š3ÃÃ±d"+iÅ¾="" ï¿½ÃŠ=":ÃÃ±n~Â«yeSÂ²â€“zÅ¾nÃœÂ¼a&nbsp;Xï¿½Ã±ZÃŒX%Âª,Ã—\K^eÂªÃ–K*Ã«â€šÃ•â€“ÃºÃ§mfhÃ¿Ã³Ã½OÂ³Â¿_h0Ã½\Å¾Ã•ÃºÃ‘Ã™Ã…Ã›V2â€ EV5,dÅ¾" yÃ.~ÃšÂ¾ÃÂ»Ãµ|Â®iyÃÃ¤ÃÂ­Ã“9sâ€”j7o\="" lÃeÃ†xqv{Â·\Ã¯â€ºÃ¹~)2yÃ—-ï¿½Â¬Ã²rÃ¯Ã–="GÂ°Ã£Ã›uÂ½/Ã§Ã»â€šgJÅ Â½[Ãlo.Âº!Â¸ÃÃŒ^Â¹ÃsÃ—Ã¬FSÂµÃŸâ€ Ã‰Â»3Ã“Ã‹â€¹Â½[GÂ®sgÂ¾ÃrÂ¦Ã…ÃŠÂ½Ã±Å¾Ã¨Ã®Ã¦Ëœn/ÃµÂ¥YSÃâ€7ÃŒ&amp;g+Å¡ÃÂ·oan[Å½_GÂ³oÃ¦Â¹pGï¿½X,â€¡gï¿½Ã®Ã„uÃ‚$â€”Â´Ã˜`Ãâ€”Ã¤ÃŒâ‚¬Ã Å¾{=wqÂ²Â­Ã‡Ã‹" Â¥Â´j]Ã¼Â£qÂ vÂ¥*Ãy7Å’m_:.Â­Â¶ÂªÃ›)Â¸Ã—<uÃwÃ€Ã¢Ãˆ="s:wÂ½WÂ®" Ãƒï¿½Â´Ã’Â¶Ã¹ÃÃœwÃ0â€°nÂ«uÃ‘<Ã˜Ë†Ã€xËœÃ”6\â€“Â²Â±Â°}vÃ–ÃšÂ´ÃŠyÂ©Â­sâ€“u+â„¢Ã»zÂ¡Å Å’uÃ†ÃºÃ¦}Ã‡Å’tÅ¸5bÂ»ï¿½}mÃ¸eÃ…eÃ‹Ã¬Ã¬ÃŒmÃ¬Â¥Â³Â³Ã“Â Ã—ÃšÃ™â€¢{lÃ¡Å¡ghâ€œÂ­="" Â¨Ã”Â¢Â¸v5Â²jÃ—â€Ã—ÃÅ¡dÃ¥Ã•Â´ÃÂ«r\Â»Â½ÃŠ_u3Ã Ã…Â¿Â¶ÃµÂ´Ã«jÃ‹jo7â€0?}Ã´Å¸Ã¦'ÃÂ¦Ã¶<xc*Å ^Ã¥Â¤Â±Ã”Â¼vÂ¥Â·Â¦3Â·~Ã¨]ÃÃ·ÂµÃŸÃ§Â¼Ã©="">urÂ»â€šÃ®â€”Ã³"+x)Â¤Ã§ÃlÂ¯ï¿½ÃŠÂ³Ã„Ã‹Ã¹Â¾â€“Å¡TÂ¹sâ€šÃ–Ã‘Ã´uâ€”TÃ„CGÃ»â€ &gt;CtÃÂ¯uÃ›ËœÂ¶h'mÃ¹-â€™J#Ã·Ã¦Ã´Ã†5Ã©Ãâ€˜Ãµ5ÂºÅ 1Ã[Ã¤Â¶jÂ®Ã|AÅ¡â€œ.rÃ‘Ã»Â¬#â€^Â¯Ã„â€˜Â£Â²ÃŒZÃ‡Â¢â€”Ã+wÃ®Ã»Â½Ã’q";ÃšC@Ã¯Ã³Ë†EÃ yÃâ‚¬Å Â¼Å¾Ã¥Ã’Â®Ã®Ã­Ãª,qQWï¿½sï¿½Ã…aÂº_Â¹'[@hÂ¦w0$sgÃšlÃ³~Â·Â¯hâ€™isÂ£ÃÃ“_5Â¯Â®Vâ€¦"Ã¼Â­TZÂ®ÃšÃŸT3Ã¿Â¹Â»ÃÂ¦!Ãº8ï¿½ÃµÃ…ï¿½&gt;]Ã¯Â¹â€¢â€°d=AÃ¬Ã˜kÃšÂ¸:/I%[&nbsp;ÃPÅ Ec+Ã¨Ã±â€™dCÃ ÃŒâ‚¬Ã…Â®Â£Â¸GNâ€š(hZ=Â®BÃ¢Æ’Â±	ÃÃˆaaâ€¡â€ºOXÃ·â‚¬Â¨:Ã¯Ã©Å¾;Ã¯Â¹yâ€œ4Â±â€°`â„¢ÂªÃªÃ1ï¿½Â¶/isÂ¥Ã­&lt;â€¹Ã™Ã†Å Â¥ÃÃ¢6Ã¬ËœÃ¼zÃ³Ã‚Ã˜$Ã²Â»Å½Ã Ã±xlÂ²cï¿½Â¸JÃ‹&nbsp;Ã¬Å’ËœÃ¤Ã†qÃ‹Å 2/hÅ’Ã—6Ã£cÃ¼CÃ£Â¹ÃˆjmHÃ†x5W,Ã£,Ã§1Ã„[Â´Â¿Ã°Â²ÃˆÃ‰Â­Ã›Â»ÃšÂ³`Ãâ„¢(ÃšÃ2Â½â‚¬Ã™Â¿+Â¬Ã¯Ãˆ=XÂ¯â€˜Â¤oÃ¿â€“Ã³Ã›pÃ²ÃÂ¥~EYdJÃ§Ã¸Sbâ€˜*L&amp;tF)ÃŠâ€º~-gÃ¬â€ Ã¤â€lÃ‘Å¾gj4Â°X#Ã©Â±Ã®Â¡â€¢Wâ‚¬Ã±ï¿½ï¿½Ã£~Ã¡PÃ’3Ã‚Å¾&nbsp;OskÅ¸]_â€˜Ã©Ã 3wÃ¤&nbsp;Ãº.Ã©â€¢&amp;Ã~â€šâ€”Â© Å“â€ºjÃ²â„¢Å CÃŠ5Ã‚ï¿½h:DÃ¤Ã—nEÃ¨Å¡P#â€˜0Â¹E&amp;Â¦Ã¹Â¿Y(F%QiÅ¡thZPÂµÃ¿â€šÃ‰â‚¬-B$Å“Vâ€°0Ã†FÂ©hÂ«0Ã‘HÃ³cÃ{Ã—Ã´[GÅ Â¶,1ZÃ°0Ã†Ãâ€¢Ã¥Â¹ï¿½Âªrï¿½]Å’Âª]~Ã±Å’,Ã¤ÃšÃÃ°*Q	Å¸Ã’Aâ€¦â€zdÂ®6T|Æ’LÂ³R(Â²,Â¨Â¼|Â¢Â§Ë†Ã“P#Â¦Ã±Å Ã«"ÃºÃªâ€¦Ë†Â¡Ã dÃ“Âµâ‚¬RÃªPÃ±Ã¿Â¡Ã¸Å¡â€”qHÃ±?R&nbsp;f
Â´Ã aÃ¨m	Â¡Uâ€¡Ã€ÃƒÃÃƒylÃµÂ¹Ã«m=Â©Â¨â€¢â€¡wt3Â¬`QÂ´IÃ˜â€¡Ã‹,GyÃªÃ”Ãºâ€°ÃŠâ€ Ã›ÃŠÃµKpE'Âºâ€œ0Ã™rLÂ¾ÃŸ3Â­Ãœâ€¡Ã—,tjaSeEÃ­Å“Ã¶Ãªuâ€˜Â£C
.Ã¼Ã„{â€¡ï¿½N&lt;Â¤nÃ–Ã¼Fâ€œÃ»G$â€¡0M?ÃC`Ã†xÃ†â€H Â°Rï¿½â€¢ï¿½NÃ«kâ„¢â€¢Â¬CÃ 2
Ã€lÃ¾@ Ã£Âºj!Â£Â¸%â€ "Ã€Ã¹hÂ±}Â£ï¿½ZÃ·  Ëœyâ€¢iÃ§Ã¦f4Ã¦`Fv5â€ËœËœÂ¯ÃšÃ®iË†9Ã¤Ã©9ÃŒÃÃ—Ã'Â¦Ã£ËœÃ¬Å½pâ€°Ã„TÃ•)IÃ„Â°qÃªÂ¢Â¥mÅ½Â£%:ZePÃ!Ã‘Ã¸JwW
?\i+.tÂ°^Ã¥uâ€ºÃJIËœÃ±â€Â¶n0â€¦ï¿½k6_(Ãµ&gt;Â²rÃÂ·â€¡ÂªÃ«Ã†Ã¾Ã˜\ÂªcAâ‚¬Ã±Ã’#Â¼ï¿½Å“Ã¶Â¡Â£Â¨Â´Ã¥Â´Â´Ã™Â¼,ï¿½tÃ ZÂ©Ãh|Ã¯"NdC&lt;Ã«sÃ¡Â¼,{Â¯Ã§"Â´wÂ´)Â¯râ€ Ã¿Ã€LÂªâ€œï¿½Ã¡Â§Â¨Â³Z#gÃ¢Ã¨;Ã„ÃÃÃ¸Â©mÂ§â€“â€º&gt;Ãº~ÃªÃŒ	Â¶4Â®ba&lt;,{oWÃÃ¾$puÂ³`JsKÂ»Ã—NfEÅ¾Ã‰â€š'â€œÃ™ÃŸ6o6â€ºÃµkÃ‰#Ã‰lï¿½!â„¢5â€˜Ã²`2kË†Ã£dvsÃ°Ã¬Ã•=lVÃšÃ®+FÂ¬Ã—)Ã¤Â¸Â¸QÂ²Ã²,iS)Â®BÂ­^zÃ¶R!S%â„¢XzÃ¾Ã£â€šÃ¯Â¸â€˜Â­â‚¬Ã’2^bÂ¥ÃLÃYÃ“â‚¬}Ã£"tTÃ°]%Ã¥]Â³Ã´llzbÃŠâ€º*=wÂ²BÃ‰â€¡Ã(Â¹Ã¦FJÃÂ£wÃ–Â¿ÃÃ’Ã³â€”6Ã´Ã§Â¬Ã´rÃ’7Ã¨Vzâ‚¬Ã†Ã£ÃªKÃ°Ã‘ Â¾Ã¢yÃ® Å ï¿½Ã-Ã›Ã¬5Â¹Â¡ÃªÃ´Ã”y&amp;Â°]Ã¥Y%Ã¤HÂ¡ÃºÃ³Â©|sGÃ†4Å“oÃ·8Ã€Ã¹/Ã¡â€ºÆ’Â±Â¯Ã€"aÃ¿Ã‰Â¸Â¶^Ta2Ã¾`ÂµkmA2n&lt;Ã€Â´kmQÅ’1Å“xÂ¿Ã—Ã“Ã¤0â€¡Å“Ã©Ã¦Â©Ã—pÃfÃ³ywÃª6Ã¸&amp;Ã³Ã®  ÂºÃ™7Â­â€˜GÃ‰EÂ¦jâ„¢&gt;JNâ€Â°ï¿½â€¢Â®{Ã~Ã´~ÃšÂ§Å½Ã Ã
ywÃ²ÃŠÂ¹Ã’â‚¬Â«:1Ã¯Ã¾Å“â€ Ã¯RÃJÃ²:Å¡Â»Â©Ã¦Ã… Ãâ€¹&lt;6;kÂ¢PÂ¬Â¢/Â®Ã)ÃÃ’Ã‡Tï¿½'Ã EÅ¡7&amp;
Ã§Â±â„¢Ã—)â€”Ã°*TSoBÃ“.Â©@Ã¤EÂ¿Å ÃšyxÃ–â€¦Â¶@g1cÃ¥cÃ¤@Ã—â€ pÃ®Ã®â€ Ãâ€™Â¤Â¥-Â¦Â½Ã¸rÃ+|ÃÂ¾Â£2wÃiÂ¯{Ã³k9`ï¿½â€¡Ã˜â€ Ã«ghlW.WÃ³Â§-Å¡Â¾HBg)â€ºÃÂ»Ã©Å Ãˆ9Ã—Ã¶EÃ¾&nbsp;Ãƒ]nÃÂ°ÃšlÃ­Dz?Â·Ã¶ Eâ€˜Â²4@KÂ¸Ã–1`Â¶Ã–ÃÃ€*ï¿½â€¡Â¨bqÂ£ÃŸÃ„Â¡Ã¯Å“ÃƒÃ 0&nbsp;Â°â€”]ËœÃ¿Zï¿½j&nbsp;}Ã£Ã§-&nbsp;Ã—Â¤Ãµ!8Â»Ã©DNo!Ã˜Ã®ÃŒ,w&nbsp;
Â¦M:9!Ãˆ;qâ€ â„¢Ã—[Ãˆâ€¹ÃÂ½Ã¦ï¿½n_|Ãâ€Ã†Ã£Ãƒ9ÃƒÂ±Ã›Ã˜Ã€vyÃ•;RËœÃ¯ ï¿½&lt;
v(Ã’Ã„Ã™Ã„ï¿½`#Ãâ„¢SÃ©+Ã’*7VR1FÃ¸
YÃ´Â²#Ã­dÂ½Ëœâ„¢zÃ¯Ã©$Ã’Å¸DÂ¢Ã£Ux{Å cCâ‚¬(ÃÂ·Â£â€Ã€Ã¸UÂ¿&amp;Zpâ€”Â¤Å¾â€œlÃ¥*:Ã²&lt;Ã€7zÃ¹7Âº0Â½Ã—t	8{Â¸Ã—ï¿½`j3`YÅ¸v
Ã®ï¿½u[d5Â´]Ã¼yÃ¼&nbsp;_ÃµÃÃ³Ã«â€ºÃ°"dÃ…EÂ´4$?0Â¦Â­tâ€¹t!Ã XÃ€)Ã„7Â£CÂ¥â€°Å¡'Ã}Ë†&gt;â€˜Â®ï¿½â€ ]82Ã¥AÃ²Ã³Â¼7ÃšÃ¶afÂ£lGÃ»Ã‘ÃÃ–Ã’Ã´0"Hv"Ã„iÃÂ®Â¬Ëœ7_\Â½ÃÃ±Ã7â€˜Ãï¿½Â½Â¥ï¿½pÂªKRâ€škVp&nbsp;Ã·x^Ã°Å’Ã•RyÂ®1QBï¿½
â€°*ÃQyâ„¢Ã¶Â´Ã“,Ã³Âºt^Ã€n_Ãš	\Ã±Ã§yÃ©&nbsp;[Â¥_â€ Â¦qL5Å½â€Â«Kâ€â€,&lt;Ã02]Å½`L%Ã‘Ã¢Â§Ã±ï¿½&gt;tÂ§Ãƒâ€šr[Â»:X!S@v@Â«Â¸â€¹Ã•'|Ã­â‚¬Â¼â„¢LÃ¤lâ€“â€¢gÂªbÂ½&nbsp;Â¥Bâ€œï¿½Ã¶Å“`ÂµÃâ€CwÃªYQ Ã–Â®Å¡iBËœ<j2ÃºÃ¾lÅ’Ã®â€œÂ¾dÃ°Å’â€ Ã¦Ã°bntÃ¥l5lÃ©,Ã­i0Âµ(Ã½Â£Ã§Ã³1}Ãyâ€¹Ãµ Ã­â€“ÃµyÃ¦Â©^aeÃ="">/=Ã«CSï¿½Ã¢Ã¤Ãi[â€ 
Â§â€œÂ¾dÂº	â€œ&nbsp;Ã€Fâ€¢Å¸hjKIÃ¬â€Å’ï¿½tÃŸÃ®ÃÂ§Kâ€˜/]qÃ‘&lt;Â¤aâ€°ÂªKÃ¸Mâ€H#1&gt;Ë†4Â°â„¢Â¨Vï¿½Ã‘ÃƒÂ¦ÃƒuÃºÂ¼iâ€¢;Â´sÃ4&amp;f6Ã‘ÃœÂ¢Â´+Â¼Ã°Â¾$Â¬Ã—tgï¿½#0Ã…axs0cÃº%IÂºJ#Ã‡Ã¯t{â€“Â¾MÃ˜â„¢[Â´Â«"â€¢â‚¬Â¡Ã“`&amp;D[Ã¡Ã¨â€¹tâ€1D5^(#Â¿â€¹Ã—,Ã½ï¿½ÃÂ¥Æ’Ã±uÂ¿Ã¨â€”Ã­â€™y/Ã´zOhÃ¿Â´jâ€°7Å¡F"â€¦Ã¦Ãœ|Â§ÃŠâ€ 	Ã¤â€˜Å“ï¿½YQâ€°Ã”Ã½Ã˜ioxÃ¶ï¿½â€¦Ã‹6Ã‹KTï¿½ÃµÂ´â€KÂ£Ã—Å zÃ‚ï¿½Ã‹Ã®ALâ€¹ÃŸDTÃ¿\9Â¦Ãƒï¿½3Ã’Ã”Ã£â€œ0ÃŠÃ¸WÂ»{7d=R"Lï¿½X Ã§EÃ¨
â€ Ã¢Â¹
uÂ§qÃ´Â¹Ã‹hÃ‚&gt;zÃº
Â®Â¼Â¸tÃºÃ»JÃ“jÂ¶Ã­Â½WÃ¼&nbsp;kÃˆ4Ã²ÃÂ²J:Ã™Å½Â­7Â©Â°2fÃ´Ã¿;0ÃˆÃ‘Ã“Å’oiN|Â¤ï¿½N
hï¿½&amp;vÃ¤â€¢Â¬Ã¯rï¿½ï¿½pÃ‘W/â‚¬tÂ¢L]
Å’ÃªÃ£Â¥@OÃ€ÃŸÃƒÃÂ°â€¹yÃ 3&lt;Ã€Ã´:~RÃ‹Dâ€¢UrÃ¨â€ Ã´Â®wjKÅ¸Ã”Ã¦\Ã‹â€”â€¦Å¸&lt;{ÃªÃ¢ÃºÃÅ’Ã®â‚¬ÃÃ‹Ã¡Â±A|6h#Ã“w5Ã€ÂªÃÃ‰â€˜ï¿½Ã Â¹â€¹Ã¨(ï¿½Ã¨EdPï¿½;Â¸â€˜ÃÂ®Ã“	tâ€¡EÃ¡Ã‚Ã€Ã©Ã“ â€ FÂ·~
Â­â€¹â€šÂ»KÃ›Ã€
Ã–â€°Ã•Ã‚Ã±Ã¨Ã½ÃµÂ¼TcÃ•&nbsp;GÅ¡
ÃµKrBÂ£ÃŸ+L\Ewï¿½(Ã—Ã“7&lt;Ã©Ãr9 :ï¿½
,Ãâ€¡e!ÃœÃ§ÃÃ¶Â»ÃIÃ½.Ãâ€¡Ã Ã|Â®Ã©â€™Ã¿Ã°Ã´Ã˜OËœjvÃ¿!-8&gt;Ã’Ã´Ã¸CÃ‡Ã‡P,5N&lt;Ã«â‚¬n"IÃ´Ã§ï¿½xeÅ Ã†Ã¾ÃBÃ—ÃÂ·Â£ÃˆÂ¸LÅ“Â°Ã†Ã½â€ &nbsp;Ã—+fÃ§J+UoÃ hÃŠ4ÃÃƒhâ€°Ã—â€¹Ãœâ€¦"Å½ÃµÃ…Ãºâ€°â€ºÃ¼
Â²Â¤Ã«Âª
.Ã«Fâ„¢VAcÂ¶Æ’ÃŸÃ»K+Ã˜Ã¦ÃŠÃ³Ã¨ï¿½Æ’#UÂ¤Â³Ã¯Å¾â€“A2Ã°tÂµÃ‘;sÂ¶[Ã°ÂºQÅ¾
c
%Â³WÅ½bÂ´Ã’Fc6Ã´^Ã‡|Â¥Â¸Ã„5â€œI}ÃºÆ’H&nbsp;Ãï¿½Ã“Â¡~Ã®1	{Å¸j\ÂªÃ€GÅ¸â€œ[â€œvIÃ³_IÃ«Â·Ã¨Ã(GuaÃ¢ÃªÂ¥-Ã¯Ã‹L)9Ã²2Ë†Å’xâ€°&gt;~Ãƒp&lt;ÃÃ¦â€šÃ”fÃ¼nÃ‚Ã„â€™|â€Ãâ€Ã¤Â£/Â­VgÂ£Â²Ã¯
vâ€â€¡GÃŸÃ¤ÃWÃ’Å¾Ã­KÃ™â€ºfÃÂ¢ÃŒTÂ­ÃÃ‰Â°(xâ€œÂ«â€”Â³}Ã‰ÂµÃÂ¤Ã¨yTJkvsÃ«Ã¦^Ã“dU`ÃÃ·ï¿½â€ºW&amp;ÂªÂ¢nxhÃ(KÂ¡Ãƒâ€ Â®ZÃ“Â¥wÂºÂ£dJrÃ³1â„¢Ã©Â´Ã~"Â°iWeÃ£kÂ­3*eibÂ®Ã—QÃ¤Ã¶â€ºdÂ²hhxÃÂ¦*Â»'Â¹(LÂ²Ãw[
Â©ÃŒÂ¥9GqÃ–Ã°Ã£Å Ã•ï¿½]&nbsp;Ã¸Â¼ï¿½â€°Ã½Ëœâ€™Ã«Â¿Ã­-ZlÃ½Å¡EVÃ—e]Å Ã­ÃÂºbÃ»Ë†Ã§
DÂ¸^=
hÃ©-Â¢â€”Ã&nbsp;MÃ³Â¤rÃ¦Ã¶xÃ„2Â´Ã­Ã‡Ã°Ã¤Æ’
Ã‹Ã°Ã¡ÃXâ€ Å¸~ï¿½Ã¡ï¿½eÃ¸Ã¨Æ’o,ÃƒÃ&gt;ÃˆÃ°Ã†2|Ã¼Aâ€ 7â€“Ã¡Ã§dÂ¸Å¾wï¿½Ã¯Â­+ÃƒÂ¯Ã§ÃÃ›Â»â€¦Ã Ã¶Ã®~YÃ¨Â¶,ÃºnPÅ¾wIÃ½u.Yâ€œÃƒJSÃ¯zÃ³Â¹Ã¹tvÂµÃ¯â€ï¿½Â©ÃÂ¶Æ’Ã§Mâ€°bJtË†Â¼Ã“N\yÃ©Ã¤ÃŠÂ¥DÂ¡Â¨&amp;L/Ã°Â³Ã™ÃÃ¸â€=Ã™w&lt;Â¯Ã›Ã Wx!Ã±Â¡Ã«EbrÂ±Ã»Ã¦ÃÃ¤ÃÂ£ÃœÃâ€ºÃ­gâ€°Ã´Ã‡Â¤dZâ€˜Ã‹ÃŠÂ¾ÃlÂ¶Ã…Ã–f\Â»%ÃÃ™ÃÃ›=â€œÂ±Â¨Ã®Â«â€º0Ã’Ã¯Ã-h[Â©VBÃ–Â½:Ã¤Ã’Ã™Â¹~Â¤GÅ¾o&gt;â€&gt;Â²\Â§â€Å Ãƒ	Ã¡,Ã¬
Â¤[Ã€Â«Ã„â€NÂ­Ã„Ã›Â¯ÂºÃ´Ã£Å¾Ã¹1pÂ·[Ãˆjâ€”Ã¸â€™3Ã‡g7!ï¿½Â§ÃÃ¾Ã˜|â€˜&nbsp;Ã¿ÂªuPEÂ°sâ€°EÃtPÂ°oÃœÂ¦Â¸Â§Ã¶SÃ™4\â€°Ã’Å¸Ã9ÃŒÃ Â¥3MÅ“Ã˜O_IÃ…*â„¢Ã•ÃÃ·Â¶Â¦Â¸Â¨Ãu]TÃ§[Â¸Â®Ã¨Â¸Â¨]h?Å¡;Ã U"Ã—Ã°Ã¬b{Â¹ï¿½7Â¾ÂªÂªK1Ã“*Ã‡yÅ¾WÂºQÃ¥ysÃ©Ã®â€”ÂµÃŠ*â€“Ã‰YÃ…Â«Â¬Ã¹Â¬U6Ã½oÅ Â¡Ã®wS,Ã—Ã‘EÃ†+Â©Ãš?)fÂ«Å’â€šqÃ¦;DÂ©ï¿½ï¿½â€œÂ«Ã§R4G&lt;Ã©â€¦Â¥Ã‡N`Ã—Æ’ï¿½Å¾+,â€Ã¨ÃÂ·Ã«y,`p_]z&amp;Â·ÃÂ¬Â¥Ã£wEÃÃ¼RÂ¼v&lt;`Ã°Ãƒx@Â£Ã²Ã­Â´9Ã«ÃÃ’Ã±AT~Ã´)1Â½ÃµRÃœyÂ©Ã§Ã°Ã¨ylÂ¹fÃ¨Ã‰bSÂ´Ã­nÂ¥Bx3Å¾Â²Ã”FÂ¡Â­=Ã°Ã‰0rÃ‘w`Â´â€Ã®/Ã©Â­Â¦ÃÃÃ‹Å Â¹:Ã¥ï¿½:EoT
Â½iÃ‘â€¦!Â½Å¡(ÃŸKÃ°Ãœ)Âº]nÃšHiÃ€Ã…"KÃœâ€Ã£*=qÃ»Â½Ã§Ã®Ã¡Ã½eEÃ±Â¾Â¢Ã¶ï¿½9Â´Ã‚	@Ã•Ã‚WeÃ‡Ãœâ€™&lt;â€¡Ã¾shÂ·Ã¸]Ãˆâ€™Â´T3Â±Ã›&nbsp;Â¬Â½Ã°â€¡mÃï¿½Ã§Pï¿½RÃˆÃ¹vÃQÃ=	&nbsp;Â¬â€°8Ã‡ÃŒÂ½?GaclÂ¶_kÂ¤`PÂ´ÃÅ½Ã±*ï¿½Å½Ã§ÃœsÂ²Å¾Fï¿½ZÃ¡Ã®Ã¹VÃœvÃÂ¬UÃ€.Ãš*Kâ€¡Â¶Â¼Ã¶â€œÂ«Ãâ€“Ã¾ÃÃ,?Kâ€Â¼Ã·Â¢Ã‚Â¶Â£Ã˜Ã›â€Å O]/Ã®2Â¶Â¯â‚¬9f;QqÃ–â€™xÃzÃ¯*Å¡Ã¿â€{Ã¿fendstream
endobj
1201 0 obj
4716
endobj
1211 0 obj
&lt;&gt;
stream
xÅ“Â½][ï¿½ÃœÃ†Â±Â²/'â€ºÃ’ÃŠÂºÃ†ÃÃ&lt;Ã¸Ã„ÃšXKÂ³Ã™Ã¬Ã³HÃšYIÃ‘z/Ã’Å½,Ã©)'	Ã€Å“Ã¼ Ãlâ€™Ã½uW59Â³+Ã¬UÂ¬Â¾Ã•Ã¥Â«G?Â­ÃªJÂ¬jÃ¿gÃ¸Ã¿Å¸ÃœÃ¿Ã®ÃœÂ¬Ã¾Ã¶Â¯Ã½Å¸Ã¶Ã«â€¢Â©DÃIÂ»Rï¿½ÂªWÂ¶mÅ¡ÃŠvÂ«Ã¾euÃµÃ»Ã•?Ã¶Ã…ÃŠÃ¿Ã¹Ã§ÃŸÃ¶Ã½{=â€¦lÅ’Ã–Ã®Ã¯Ã·Ã¿ÃŠ&gt;;Ã«yÅ Â¶Ã’uÃ—Å½&lt;â€¦Âª$Ã‹Ã“Ã‘)SK&nbsp;kÃ¥ÃˆÃ›Ã¿ÃÂ´.Â£;]Ã•2Ã[{FtÅ½Â±Z	Â­eÃ•Â¸7Â¤Â­LÃ§vÃ”vï¿½Ã¨Ã±OÃ»"ÃÃ¿Ã»Ã³ï¿½Â«Ã¿Â»tÃ»Ã®ÂµÂºÃªÂ¬Â²Â«Ã‹Â¿Ã®â€¡Æ’+#ÂªÃs4Âºv+Â«Ã‹Ã·?&lt;Â¹Âµ&gt;tÂ¤Â²Ã¢Ã‰Â­â€¡GÂ­ÂªtÃ—=Â¹uÃ¡Å¸6ZÂ©'Â·Ã#ÃÂ»HÂ°Å¾Ãª'Â·ÃÃ™ÂªÃ–Âª3â€˜â€º{|pÂ¨*Â¡mÃ&gt;Â¹ÂµÃ§â€¡Â²iÃ­â€œ[Ã·#&lt;Ã½Ã¾Ã°HÃ‰ÃŠh7ÃÃ‹Hp7râ€šÃtÃ€Ã¢$Å¸â€¡Ã…kâ€˜Â®m/RÅ“Ã„Ã·^
SImÃœ|Ã¯Ã£Ã¶Ã–Ã¬2ï¿½ÃƒÃ“ÃšÂ­Ã¢Y~Ã¼8Â¼gÂºxD~Ãâ€ÂªKf!ÂºÅ½Ã‹x<lÃ€==â€¹Ã“Ã {Ã€Ã–Â´Å½ÃƒaÃŸÂ¦Â¶Ã‰c â€ Ã…="Ã‹Å¾â€ !â€¹0Å¸lÃ¼*">]Â¾ÃœwÂ§QÃ•mÃ£Ã„ÃªÃ²Ã¿Â½Â½Ã¡Ã·tÃ‚Ãï¿½;Â½Å Ã§Ã¼ÃªyvÃ‹Ã„â€˜b3Ã§i&lt;7ï¿½(`6Å“wcÂ¦Ã»!N1ÃœÂ¶Â©kâ€˜Ã¢:â€™Ã‡!&lt;'4MÃ‚Ã»vdÂ«â€šÂ³Â°zÃ¿0ÃšÃ»Ã¸Ã”ÃŸÃÃ‘x=GÃÃtÃ–Â¨Ã¡â€“-Æ’â€“IÂ¹Â¤eDqÃyÂ°Ã‡RÅ“Ã…!Â¯ZÂ¯Ã¢SxÂ­`e`AÃXnHÃŒÂ¨^%Â¶+"Â°FÃŠvÃ˜pÃ®s2.Ã´dÃ¢Ã§&lt;Ã\â€¡^Ã…Ã‡Ã§Ã¼Â¢yÃ¯r=Ã¤Ã´&gt;hÂ»cÃ¤&lt;ÃÂ¨Ã­Dï¿½Ãƒâ€¹pÃÃ¹â€Â½Ã²â€°Z8ÃrÃ”ÃSiÃ§
Ã›V{OÃ•Ã¨ÂªiÅ’YÂµÃÃ‰Ã©Ã–Ã“ÃwÃ¯5â€¢Â°n#Ã·Ã¢Ã°~Ã¤Â¾Ã®Â¨1MU7Ã‚â€°~WÂµVjÃÃƒOwÃ¹Ã·}Â©ÂªÃ]xÂ®Ã¦Ã°ÃˆÃƒÃ“Ã‰D
Ã—Ã‘â€°â‚¬Â¸Ã±Â²y%DÅ’Ã©Â²Ã¸Â¯YUyÃ2CÃ¡ÃU,,Ã´xÃ^=ÃœÃšÅ’Ã½Ã©o
H]Ã†	1â€¡Å¾Ã wÃ€Ã–{ï¿½Â°Ã 5ifÂ¢StmEÂ²&nbsp;cV5&gt;ï¿½Ã¼Â®9Wâ€ºÃ™+Æ’2â€¢Â±rRâ€ Â»qiÃ”|Ã¦NÃ©tÃ²Â£Ã§Ã¬ÃŠÃ$AÃ¼xâ€ Ã™Â«Ã‰Å“Ã„Ã‹Ã¨E'Â¨$u3aÃ¸fâ€“HJÃ°3ï¿½Ã›Â®â€™Â¹Fï¿½69â€¢Ã„QÂ¤Ã RÂ¹Ã.Ã›Â¹^wÃ‰ÂªÃ®Å¡q1Â½Ã®â‚¬zâ€š"Å¾gzÅ¾/)"ÃÂ¯Â¡"â€šzÂ¾Ã´^&gt;]â€šZSÃ±Ã›Â¾â€°ÃƒÃ¼TsKÃÃˆÂ¿!Ã’K"/Ã·Ã¯r8JÃ±Â´lÃ®ÃƒÃ°Ã¥â€™VG,i5)o"Ã  Ã–,_*HÃ ï¿½;~Â¿Ë†Â¤Ã¡Â¬aÂ½Â°cËœÃÃ›Å¡Â¼â€”ÃƒÃ‡eÂ­Ã¦mÃ&amp;â‚¬Ã¾â€ aÃ“q2Ã°-hÃµÂµ_BÃ…%Â¿ï¿½Â±Ã°TÃ“Ã­Ãpâ€¢â„¢=xÃ¦Â¨Ã£"ÃºDâ€˜Ã„&nbsp;kJ&nbsp;Â·ÃÃ¶ÃœqEÃ½|Â±Ã¤Â¢Ã¹Ã€â€Ã‡â€˜Â¼Ã«â€¡EÃ¦rI Ã…Ã¬.2Â­DPÃ‡Ã«ÃŸâ€ â€¢}Â¸d&gt;^|Q0Â¼Ã¢Â¢KX(oÂ¢Ã»KbfxÃ¯j0	uÂ¥Ã¾Mb`Â«Ã¼&nbsp;
Ã‹aÂ±apOor|0gÃ„xÃ³Â¹Ã¡Ã«Ã¹dÂ¢yÃKpÃ4TÃŒÃ³Ã¨Ãˆ_Ã†â€”Â±Âµï¿½Â¦Â²Â¶-`kc"Â¸Ã¶Ã£&lt;Âºâ€“Ã†VÂ­lv@Ã—_;Â¦Ã½Â±â€¢Ã‚HPÃ—Ã‘â€™Å 4eÃº
ZÃŒ'kâ‚¬`F3â€°I(Â¤Â°(Ã°Â¯SÃ³
Ã·Â½/ï¿½â€šÃ£	ï¿½Â¸8FÃ©Ã¥R(0.Ãˆâ€2Dâ€¹.Â·ï¿½Â¾Ã¢â€¢Å ï¿½GnÃ²}Â¢kÃ€~{Ã˜Å¡ÂªÂ¶M;Â¦sÃ€Ã»Ã±"8'ï¿½Ã›%9Â§Ã›,C$Ã¦Ã½.Ë†ÃÅ’YOÃ¼bÃ‘Ã¥#Â¼ËœÂ§{Â¨â€”bÂ´WÃ¹^`Ã²Ã„&gt;OÃ¦Gâ€°Ã â€¢Ã¦`}wÃ¨ÃŒrÂ­Ã Â½â€”Ã¥&gt;Â½,SÃŒ'k@;y8Â¼Ã¨Ã‘Ã¹ËœÅ¡ï¿½Â¿ÃºÃÃ»|p
Ã¼â€šï¿½1&lt;ÃÂ°|yÃ·xâ€”Ujâ€™â€¹Ã·Å¸Ã°ï¿½Ã·Ã¸â€¹~kÃâ€¡ÃÃ³Â¾6ÃÃœÂ½K]â€°Å½â€¦Ãµ_FÃšÂ¯Ã¢Ã°Â¿â€ºÂªâ€˜JÂ§np9ï¿½Ãµâ€šÃ·Ã–yÂ¶#Lï¿½yâ€“Qlâ€”Ã…ÃºÃ¯ÃÃ“zâ€¢Ã¬)W(Ã¢Ã?&gt;<a+Å ÃÃ1Â¢â„¢Ã®sÃ«Å“%â„¢kÃ™Ã©Ã§,5ï¿½Â°$Ã‰Ãº9(Ã‘Ã©jkÂ½Å“Â¥Ã³@Ã¢ahhgÂ±ÃµËœÂ¦kiÃ¢Ã *Ã† Æ’Ã‘Ã‰Ãƒwâ€˜Å’qaÃ¥aÂ¹Ã="">,Ã§â„¢_Â°Æ’â€¡&amp;|Â²â€ºÃ§ï¿½XÂ¼B:ï¿½7<tÂºl{!ï¿½Â¼aï¿½ ÃµÃ‡;Â x[Å¾~Å“Ã‹iÃ€`Ã³Ã€Â¿Ãï¿½â„¢â€œh="">SÂ©hcâ‚¬CÂ¬Ã¹Ã¬â€ÃË†iÃ
Â­Ã‘dâ€ Â¯+Ã¡â€“ï¿½Ã¥Yï¿½~ÃÅ’Ë†@ï¿½xÃ²Bl0â€¡HFï¿½Ã±Å“Ã¡!â€“Å½/XRÅ¸â‚¬Ã…ËœÂ¸-Ã—Â¿Rv&nbsp;â€kÃ°â€°nÃ¿^Â´_Ã„Â¡w+pË†Â¾â€ Ã–U=Ã‹tÃ²Â³hmÂ¨â€Ã[ZÃšÃ’1tZÂ³kÃ£Ã½Ã¡Ã±$H4u*||ÃˆÆ’ÃÃ…\Ã›ÂµÃƒ"Ã±1;Ã¤UqÃ†=ÃÃ¥Ã«Ã’Â£aFW5BÂ§Ã¸â€(Ã¶Â²â„¢XÃ„\hQ'Ã¬â‚¬Ã¬Å¡Â¦KË†.Å¾Â°Â·ÂºSï¿½Ã±:fÃ†â€ ÃZÂ¼Å f'ÃÃ€Å¡ï¿½Ã¾1Ã˜&nbsp;&nbsp;Ã¦Â²Ã®JÂ¨Ã£HhUÂ©VÃœQwÃ®P6?~Ã„Ãšh#Tâ€™ÃÃ¸Ã€Å¡â€)Ã¯bÃ»Ã›Â¸Ë†ï¿½yÃ 

Ã¸Å¸O=Ã°Uï¿½kBÂ¹Ã•ÃÅ½â€¹axÂ¶Å¾â€¹Ã¸â€O&lt;â€xÂ¶c!wvÃ‹â€°rÂ¢Â¥&gt;Â¾Ã™â€°Ã±Ã§Ã•Ã—BË†ï¿½6zÂ¢]Â¼Ã‚Ã¦(ydÃ…+hÅ¾,"â‚¬câ€Ã‘Ã!P2Â¨Ã£&nbsp;Ã˜Â§<rÃ˜Â¥ ,ï¿½nÂ¼ÃÂ¤yhv@â€¢â€“s_-m="Ã¢â€ peY^Æ’dÃ³Ã»ï¿½â€™PÂ©&nbsp;â€“:Â«TÃ¤Ã$Ã‹Â½2A]/xÅ Ã³LÂ·i{_Ã˜ï¿½Ã¢â„¢|GËœÅ¡tÃ…Ã™ÃªYÃÃ‰Ã¼ï¿½Q:Ã€Ã›ï¿½.$Ã‡ï¿½ÃŸkbÂ¾cÂ½|!Âµ7~Ã§â€¹Ã…Â¡â€™ï¿½Â±GÃ§w<ï¿½Ã â€˜Câ€”Â¹xaÃÃ°Ã†Â¢ï¿½â€˜.BÃ“RhÃŠ5=Yrâ€ Ã¤Ã³Â´.(Â¨4Ã¯Ã¸OY,," kqtÃ¸eÃ£â€“ï¿½Âº8Â¯="" 3Â´\Â§tÂ¢yÃƒÂ´jï¿½Â©â€¹wyÃ´p#Ã§~â€œ="" ÃƒÂ¶vcâ€”xeï¿½ÂµrlÃ‘Â¡rÃ®Â´o!="" Ã«Ã³Ã¶Ã¡Ã¾â€°rÃâ€šÂ¶bd+Ã â€¢â€“'xÃ‡eÃ¸"+Â¼urÃ˜hâ€¹ÃªÂ­j="`$#,Ã¢Â¶Ã˜IÃ…Â¨Â´Â§XÂ¶â€¹;Â¥FxÃµÂ¾bÆ’Ã¿Ã¿ï¿½Ã¢&quot;Â¾Â·Ã¦ÂµlÃ‚&nbsp;">cÃ§Ã¦1D&lt;Â¼%Ã³Ã‡Â¢:eÃ›â€¦ÃœÃƒËœÃ†0If2ÃgÃ¶Ã™â€¡Â½Ë†1Ã¢ÃƒÃ…Ã†C^]iÂ²iÅ’Â¿TÃ¹$Ã˜
,mÂ¬qhJ?Ã¶@Â´ÃÃºÅ½Ã{|uÃ¡â€Ã…Ã¯Â¼Ã‚Ã¥*@lÂ¯#;wZ]Ãâ€â€¦ÃˆAWï¿½Ã¨&amp;ÃƒÃÃ«Â¯osiÃ”&amp;kÃ¸â€Ã…NÃ¾"?bÃ™$%Ã±9I@a!â€¡ÃAÂ½gÃ½Ã§Â¼Ã¥Ã˜03Â¼
[Â¨Â¡ÃŒÃ‰Ã³Ã·ÃÅ¡Ã¸â€˜Â¶Q8â€Ã›
,Å“LZ]Ã€
â€”qÂ¸aâ€¢â€™Â¯â‚¬NmÃ¾Ã‘Ã©Â¡ÃŸÃ©Â£Â¥Ã€5;Â·_ÃÃ†
|nÂ¯e.Â³WN|Â®|Ã¼Â¶Ã‰LÂ¥$.:Ã´5â„¢ÂªÃ©Ã¢g3lÂ´ÃÃ¯Ã¨9Â¿Ã¶Ã‚Ã·
QÂ¾=+Ã¯f	Ãƒm"bÃ€Æ’Ã§Â±Ãºï¿½1ÃŸÂ»ï¿½FACb8Ã£LUÃ¹h-ÃŸÅ½ÃˆÃ´Ã¨Ã¦Ã˜â„¢ÃºÂ¡!ÃÃ›%ÃŠ,@yÃ‹Â°Å“G&nbsp;ï¿½SeO[â€šn^ HÂ£l6;Ã” ÃÅ¸xHÃºâ€“Â¯Ã¶Ã¥Â¨â‚¬&nbsp;	Â¾3Ã¨i|ZRK&gt;Bâ€°}H-W Ã Â¿Â¯Ë†â€¦86K,Â¶oqÅ¾iÃ»\@
Ãkâ„¢Ã¨ÃŸCPHâ‚¬â€šÂ³Ã¤Â±9zÃ³Ãƒï¿½:lÂ¦Â¡?Ã›â€¡Â¨Â·YEYÃ¾|m1Â¶KÃ¿1ÃŸÃ„Â¸Ëœ*ÃˆÃwIÃŸÂ·Ã\M["Ã©Âª,Â¾Ã¼yÂ³U[~Ã³ZJVgÃšTÂ¦â€¹Â¼Bï¿½Â»Ã‹Ã¢y Â¾Ã¼â€¦-%Ã°3Ã³Oâ€¢
Ã†Ã•Ã|UÂº\xâ€”Å’ï¿½Ã¼Ã€ï¿½&amp;ÃÃ“Ã¿Â¥RPÃ²AjÂ¸Â«,jÃ¦Â»Ã«Ã)Ã³M%&nbsp;Ã²Ã°â€Ws&nbsp;Â½`5,â€¡Â¹â€â‚¬Ã—QÂ¾Ã½xUÃƒÃ‡AÃ‹UHÃ…Ã²hâ€œÃ¯EÅ¾Ã±Ã Â½â€ mÃ«Ã€â€œ\ï¿½Å v9CÃ\Â½Ã¸ÃÃ¹bÃ*ÂµÃ)Â·ÃwDÂ¥ÃŸÂ²0oÅ¡k$Â¾8_|Ã¾)Ã±eâ€ SÃˆÂ¯$â€¡kÃ•ÃŠ)H+Ã‚Â·Â¬Ãƒfï¿½Â¤Â©ZmÃ‡NÂ»oâ€¦u"_Ã·2vÃ¤+Ã¤ÂºÃ­Ã…Ã‰ï¿½MSÃ·vÃ¼HVRÃ”ÂºiÅ’Ã}Â³J[YÂ¡uÅ¸ÃÃ³ÂµÃ²VÃ¸l6Æ’-sKÂ´Â¶ï¿½Â­â€”Ã†Ãª&gt;')Ãâ‚¬Ã¡1&lt;Ã²x|Ã£ÃºÂ¥[Â¥Ã¢Ã’Ã­Â´,Ã“Ã†9U
SÃ‚ÃŸhhÃ½Ã³;Âª;;q4MÃºÃ¦3`Ã¸2RÃ &lt;ÃˆÃ·&amp;2ï¿½Ã©Â¤xwY"Ã‰Ã›f0}Ã‘Â¸Ã¹d=Ã¿1Ã¹%zÃ¢f,~O&gt;Ã¾{Â¥,rÃÃœÃ‡Â¸VÃOAJ}y^jâ€¦</rÃ¸Â¥></tÂºl{!ï¿½Â¼aï¿½></a+Å¡Ã¡Ã¡1Â¢â„¢Ã®sÃ«Å“%â„¢kÃ¹Ã©Ã§,5ï¿½Â°$Ã©Ãº9(Ã±Ã©jkÂ½Å“Â¥Ã³@Ã¢ahhgÂ±ÃµËœÂ¦kiÃ¢Ã *Ã¦></lÃ ==â€¹Ã³Ã {Ã Ã¶Â´Å¾Ã£aÃŸÂ¦Â¶Ã©c></j2ÃºÃ¾lÅ“Ã®â€œÂ¾dÃ°Å“â€ Ã¦Ã°bntÃ¥l5lÃ©,Ã­i0Âµ(Ã½Â£Ã§Ã³1}Ã¯yâ€¹Ãµ></g(xÂ¡Â¤Ã´Â¿oÃ¿@Ã¶-></dÃ—Â¤a{!Ã¿@ï¿½Ã²p%></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://venuslabs.org/Rethinking%20Our%20Sister%20Planet%20(ebook).pdf">http://venuslabs.org/Rethinking%20Our%20Sister%20Planet%20(ebook).pdf</a></em></p>]]>
            </description>
            <link>http://venuslabs.org/Rethinking%20Our%20Sister%20Planet%20(ebook).pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26198358</guid>
            <pubDate>Fri, 19 Feb 2021 21:39:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Skeleton and Principles for a Maintainable Test Suite]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26198173">thread link</a>) | @lukastyrychtr
<br/>
February 19, 2021 | https://www.lpalmieri.com/posts/skeleton-and-principles-for-a-maintainable-test-suite/ | <a href="https://web.archive.org/web/*/https://www.lpalmieri.com/posts/skeleton-and-principles-for-a-maintainable-test-suite/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  <article>
    
      
      
<ul id="frontmatter">
    <li>
        <time datetime="2021-02-14T14:00:10.47Z">February 14, 2021</time>
    </li>
    <span></span>
    <li> 4133 words </li>
    <span></span>
    <li> 21 min </li>
</ul>

      <blockquote>
<p>This article is a sample from <a href="https://zero2prod.com/"><strong>Zero To Production In Rust</strong></a>, a book on backend development in Rust.<br>
You can get a copy of the book on <a href="https://zero2prod.com/">zero2prod.com</a>.<br>
<a href="https://www.lpalmieri.com/subscribe">Subscribe to the newsletter</a> to be notified when a new episode is published.</p>
</blockquote>

<p>We have used a test-driven approach to write all new pieces of functionality throughout the book.<br>
While this strategy has served us well, we have not invested a lot of time into <em>refactoring</em> our test code. As a result, our <code>tests</code> folder is a bit of mess at this point.<br>
Before moving forward, we will restructure our integration test suite to support us as our application grows in complexity and the number of tests increases.</p>

<ol>
<li><a href="https://www.lpalmieri.com/posts/skeleton-and-principles-for-a-maintainable-test-suite/#why-do-we-write-tests">Why Do We Write Tests?</a></li>
<li><a href="https://www.lpalmieri.com/posts/skeleton-and-principles-for-a-maintainable-test-suite/#why-dont-we-write-tests">Why Don't We Write Tests?</a></li>
<li><a href="https://www.lpalmieri.com/posts/skeleton-and-principles-for-a-maintainable-test-suite/#test-code-is-still-code">Test Code Is Still Code</a></li>
<li><a href="https://www.lpalmieri.com/posts/skeleton-and-principles-for-a-maintainable-test-suite/#our-test-suite">Our Test Suite</a></li>
<li><a href="https://www.lpalmieri.com/posts/skeleton-and-principles-for-a-maintainable-test-suite/#test-discovery">Test Discovery</a></li>
<li><a href="https://www.lpalmieri.com/posts/skeleton-and-principles-for-a-maintainable-test-suite/#one-test-file-one-crate">One Test File, One Crate</a></li>
<li><a href="https://www.lpalmieri.com/posts/skeleton-and-principles-for-a-maintainable-test-suite/#sharing-test-helpers">Sharing Test Helpers</a></li>
<li><a href="https://www.lpalmieri.com/posts/skeleton-and-principles-for-a-maintainable-test-suite/#sharing-startup-logic">Sharing Startup Logic</a>
<ul>
<li><a href="https://www.lpalmieri.com/posts/skeleton-and-principles-for-a-maintainable-test-suite/#extracting-our-startup-code">Extracting Our Startup Code</a></li>
<li><a href="https://www.lpalmieri.com/posts/skeleton-and-principles-for-a-maintainable-test-suite/#testing-hooks-in-our-startup-logic">Testing Hooks In Our Startup Logic</a></li>
</ul>
</li>
<li><a href="https://www.lpalmieri.com/posts/skeleton-and-principles-for-a-maintainable-test-suite/#build-an-api-client">Build An API Client</a></li>
<li><a href="https://www.lpalmieri.com/posts/skeleton-and-principles-for-a-maintainable-test-suite/#summary">Summary</a></li>
</ol>

<p>Is writing tests a good use of developers' time?</p>
<p>A good test suite is, first and foremost, a risk-mitigation measure.<br>
Automated tests reduce the risk associated with changes to an existing codebase - most regressions and bugs are caught in the continuous integration pipeline and never reach users. The team is therefore empowered to iterate faster and release more often.</p>
<p>Tests act as documentation as well.<br>
The test suite is often the best starting point when deep-diving in an unknown code base - it shows you how the code is supposed to behave and what scenarios are considered relevant enough to have dedicated tests for.</p>
<p>"Write a test suite!" should definitely be on your to-do list if you want to make your project more welcoming to new contributors.</p>
<p>There are other positive side-effects often associated with good tests - modularity, decoupling. These are harder to quantify, as we have yet to agree as an industry on what "good code" looks like.</p>

<p>Although there are compelling reasons to invest time and effort in writing a good test suite, reality is somewhat messier.</p>
<p>First, the development community did not always believe in the value of testing.<br>
We can find examples of test-driven development throughout the history of the discipline, but it is only with the "Extreme Programming" (XP) book that the practice entered the mainstream debate - in 1999!</p>
<p>Paradigm shifts do not happen overnight - it took years for the test-driven approach to gain traction as a "best practice" within the industry.</p>
<p>If test-driven development has won the minds and hearts of developers, the battle with management is often still undergoing.<br>
Good tests build technical leverage, but writing tests takes time. When a deadline is pressing, testing is often the first to be sacrificed.</p>
<p>As a consequence, most of the material you find around is either an introduction to testing or a guide on how to pitch its value to stakeholders.<br>
There is very little about testing <em>at scale</em> - what happens if you stick to the book and keep writing tests as the codebase grows to tens of thousands of lines, with hundreds of test cases?</p>

<p>All test suites start in the same way: an empty file, a world of possibilities.<br>
You go in, you add the first test. Easy, done.<br>
Then the second. Boom.<br>
The third. You just had to copy a few lines from the first, all good.<br>
The fourth...</p>
<p>After a while, test coverage starts to go down: new code is less thoroughly tested than the code you wrote at the very beginning of the project. Have you started to doubt the value of tests?<br>
Absolutely not, tests are great!<br>
Yet, you are writing fewer tests as the project moves forward.<br>
It's because of friction - it got progressively more cumbersome to write new tests as the codebase evolved.</p>
<blockquote>
<p>Test code is still code.</p>
</blockquote>
<p>It has to be modular, well-structured, sufficiently documented. It requires maintenance.<br>
If we do not actively invest in the health of our test suite, it will rot over time.<br>
Coverage goes down and soon enough we will find critical paths in our application code that are never exercised by automated tests.</p>
<p>You need to regularly step back to take a look at your test suite <em>as a whole</em>.<br>
Time to look at ours, isn't it?</p>

<p>All our integration tests live within a single file, <code>tests/health_check.rs</code>:</p>
<pre><code><span>//! tests/health_check.rs
// [...]

// Ensure that the `tracing` stack is only initialised once using `lazy_static`
</span><span>lazy_static::lazy_static! {
    </span><span>static ref </span><span>TRACING</span><span>: () = {
        </span><span>let</span><span> filter = </span><span>if </span><span>std::env::var("</span><span>TEST_LOG</span><span>").</span><span>is_ok</span><span>() { "</span><span>debug</span><span>" } </span><span>else </span><span>{ "" };
        </span><span>let</span><span> subscriber = </span><span>get_subscriber</span><span>("</span><span>test</span><span>".</span><span>into</span><span>(), filter.</span><span>into</span><span>());
        </span><span>init_subscriber</span><span>(subscriber);
    };
}

</span><span>pub struct </span><span>TestApp {
    </span><span>pub </span><span>address</span><span>: String,
    </span><span>pub </span><span>db_pool</span><span>: PgPool,
}

async </span><span>fn </span><span>spawn_app</span><span>() -&gt; TestApp {
    </span><span>// [...]
</span><span>}

</span><span>pub</span><span> async </span><span>fn </span><span>configure_database</span><span>(</span><span>config</span><span>: &amp;DatabaseSettings) -&gt; PgPool {
    </span><span>// [...]
</span><span>}

#[</span><span>actix_rt</span><span>::</span><span>test</span><span>]
async </span><span>fn </span><span>health_check_works</span><span>() {
    </span><span>// [...]
</span><span>}

#[</span><span>actix_rt</span><span>::</span><span>test</span><span>]
async </span><span>fn </span><span>subscribe_returns_a_200_for_valid_form_data</span><span>() {
    </span><span>// [...]
</span><span>}

#[</span><span>actix_rt</span><span>::</span><span>test</span><span>]
async </span><span>fn </span><span>subscribe_returns_a_400_when_data_is_missing</span><span>() {
    </span><span>// [...]
</span><span>}

#[</span><span>actix_rt</span><span>::</span><span>test</span><span>]
async </span><span>fn </span><span>subscribe_returns_a_400_when_fields_are_present_but_invalid</span><span>() {
    </span><span>// [...]
</span><span>}
</span></code></pre>
<p>There is only one test dealing with our health check endpoint - <code>health_check_works</code>.<br>
The other three tests are probing our <code>POST /subscriptions</code> endpoint while the rest of the code deals with shared setup steps (<code>spawn_app</code>, <code>TestApp</code>, <code>configure_database</code>, <code>TRACING</code>).</p>
<p>Why have we shoved everything in <code>tests/health_check.rs</code>?<br>
Because it was convenient!<br>
The setup functions were already there - it was easier to add another test case within the same file than figuring out how to share that code properly across multiple test modules.</p>
<p>Our main goal in this refactoring is <em>discoverability</em>: </p>
<ul>
<li>given an application endpoint, it should be easy to find the corresponding integration tests within the <code>tests</code> folder;</li>
<li>when writing a test, it should be easy to find the relevant test helper functions.</li>
</ul>
<p>We will focus on folder structure, but that  is definitely not the only tool available when it comes to test discovery.<br>
Test coverage tools can often tell you which tests triggered the execution of a certain line of application code.<br>
You can rely on techniques such as <a href="https://ferrous-systems.com/blog/coverage-marks/">coverage marks</a> to create an obvious link between test and application code.</p>
<p>As always, a multi-pronged approach is likely to give you the best results as the complexity of your test suite increases.</p>

<p>Before we start moving things around, let's nail down a few facts about integration testing in Rust.<br>
The <code>tests</code> folder is somewhat special - <code>cargo</code> knows to look into it searching for integration tests.</p>
<p>Each file within the <code>tests</code> folder gets compiled as its own crate.<br>
We can check this out by running <code>cargo build --tests</code> and then looking under <code>target/debug/deps</code>:</p>
<pre><code><span># Build test code, without running tests 
</span><span>cargo</span><span> build</span><span> --tests
</span><span># Find all files with a name starting with `health_check` 
</span><span>ls</span><span> target/debug/deps | </span><span>grep</span><span> health_check
</span></code></pre><pre><code><span>health_check-fc23645bf877da35
health_check-fc23645bf877da35.d
</span></code></pre>
<p>The trailing hashes will likely be different on your machine, but there should be two entries starting with <code>health_check-*</code>.<br>
What happens if you try to run it? </p>
<pre><code><span>./target/debug/deps/health_check-fc23645bf877da35
</span></code></pre><pre><code><span>running</span><span> 4 tests
</span><span>test</span><span> health_check_works ... ok
</span><span>test</span><span> subscribe_returns_a_400_when_fields_are_present_but_invalid ... ok
</span><span>test</span><span> subscribe_returns_a_400_when_data_is_missing ... ok
</span><span>test</span><span> subscribe_returns_a_200_for_valid_form_data ... ok

</span><span>test</span><span> result: ok. 4 passed; </span><span>finished</span><span> in 0.44s
</span></code></pre>
<p>That's right, it runs our integration tests!<br>
If we had five <code>*.rs</code> files under <code>tests</code>, we'd find five executables in <code>target/debug/deps</code>.</p>

<p>If each integration test file is its own executable, how do we share test helpers functions?</p>
<p>The first option is to define a stand-alone module - e.g. <code>tests/helpers/mod.rs</code><sup><a href="#test-common-folder">1</a></sup>.<br>
You can add common functions in <code>mod.rs</code> (or define other sub-modules in there) and then refer to <code>helpers</code> in your test file (e.g. <code>tests/health_check.rs</code>) with:</p>
<pre><code><span>//! tests/health_check.rs
// [...]
</span><span>mod </span><span>helpers;

</span><span>// [...]
</span></code></pre>
<p><code>helpers</code> is bundled in the <code>health_check</code> test executable as a sub-module and we get access to the functions it exposes in our test cases.<br>
This approach works fairly well to start out, but it leads to annoying <code>function is never used</code> warnings down the line.<br>
The issue is that <code>helpers</code> is bundled as a sub-module, it is not invoked as a third-party crate: <code>cargo</code> compiles each test executable in isolation and warns us if, for a specific test file, one or more public functions in <code>helpers</code> have never been invoked. This is bound to happen as your test suite grows - not all test files will use <em>all</em> your helper methods.</p>
<p>The second option takes full advantage of that each file under <code>tests</code> is its own executable - we can create sub-modules <em>scoped to a single test executable</em>!<br>
Let's create an <code>api</code> folder under <code>tests</code>, with a single <code>main.rs</code> file inside:</p>
<pre><code><span>tests/
  api/
    main.rs
  health_check.rs
</span></code></pre>
<p>First, we gain clarity: we are structuring <code>api</code> in the very same way we would structure a binary crate. Less magic - it builds on the same knowledge of the module system you built while working on application code.<br>
If you run <code>cargo build --tests</code> you should be able to spot</p>
<pre><code><span>Running</span><span> target/debug/deps/api-0a1bfb817843fdcf

</span><span>running</span><span> 0 tests

</span><span>test</span><span> result: ok. 0 passed; </span><span>finished</span><span> in 0.00s
</span></code></pre>
<p>in the output - <code>cargo</code> compiled <code>api</code> as a test executable, looking for tests cases.<br>
There is no need to define a <code>main</code> function in <code>main.rs</code> - the Rust test framework adds one for us behind the scenes<sup><a href="#custom-test-framework">2</a></sup>.</p>
<p>We can now add sub-modules in <code>main.rs</code>:</p>
<pre><code><span>//! tests/api/main.rs

</span><span>mod </span><span>helpers;
</span><span>mod </span><span>health_check;
</span><span>mod </span><span>subscriptions;
</span></code></pre>
<p>Add three empty files - <code>tests/api/helpers.rs</code>, <code>tests/api/health_check.rs</code> and <code>tests/api/subscriptions.rs</code>.<br>
Time to delete <code>tests/health_check.rs</code> and re-distribute its content:</p>
<pre><code><span>//! tests/api/helpers.rs
</span><span>use </span><span>sqlx::{Connection, Executor, PgConnection, PgPool};
</span><span>use </span><span>std::net::TcpListener;
</span><span>use </span><span>uuid::Uuid;
</span><span>use </span><span>zero2prod::configuration::{get_configuration, DatabaseSettings};
</span><span>use </span><span>zero2prod::eâ€¦</span></code></pre></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lpalmieri.com/posts/skeleton-and-principles-for-a-maintainable-test-suite/">https://www.lpalmieri.com/posts/skeleton-and-principles-for-a-maintainable-test-suite/</a></em></p>]]>
            </description>
            <link>https://www.lpalmieri.com/posts/skeleton-and-principles-for-a-maintainable-test-suite/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26198173</guid>
            <pubDate>Fri, 19 Feb 2021 21:20:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stompenberg FX: Testing guitar effects pedal remotely]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26197848">thread link</a>) | @xavieralexandre
<br/>
February 19, 2021 | https://www.thomann.de/blog/en/stompenberg-effects/ | <a href="https://web.archive.org/web/*/https://www.thomann.de/blog/en/stompenberg-effects/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3>The idea</h3><p><strong>Stompenberg.</strong> Sounds like a brand of Swedish outdoor clothing, but also like a villain in the next James Bond film â€“ but in this case itâ€™s actually a mash-up of two things. Stompenberg is the hybrid of <strong>â€œstomp boxesâ€</strong> and <strong>â€œHeisenbergâ€,</strong> which made the impossible possible after a long time of <strong>screwing</strong> and <strong>soldering.</strong>&nbsp;Itâ€™s a Thomann <strong>online app</strong> that allows musicians to<strong> test out real effect pedals</strong> with their own equipment, either <strong>from home</strong> or <strong>on the go</strong>. Below you will get a brief idea of the concept, development and implementation and of what <strong>Stompenberg</strong>&nbsp;is capable ofâ€¦ ğŸ’¥ğŸ¶</p><hr><h3>Growing pains</h3><h4><strong>Planning&nbsp;</strong></h4><p>The <a href="https://www.thomann.de/gb/stompenberg_devices.html" target="_blank" rel="noopener noreferrer"><strong>selected pedals</strong></a> travel to the<strong> Thomann partner laboratory</strong> in <strong>Erlangen, Germany</strong> where they undergo some <strong>operations</strong> and <b>transformations&nbsp;</b>by our men in white with the <strong>license to solder.</strong></p><p>The following happens: A pedal is first deprived of its <strong>shell</strong>, <strong>pots</strong> and <strong>switches.</strong> The pots are measured to see what they do (whether they are <strong>linear, logarithmic,</strong> etc.) and replaced with <strong>digital pots</strong> and <strong>switches.</strong></p><p>Then, for reasons of shielding, the original <strong>housing</strong> is put back on. Everything is recognisable as a pedal again, but now, instead of pots and switches, <strong>ribbon cables</strong> hang from the orphaned holes.</p><h4><strong>The construction</strong></h4><p>This ever-growing Frankenstein is mounted on a <strong>rack drawer,</strong> which houses not only the <strong>power supply</strong> but also a <strong>mini-computer</strong> specially developed for this purpose, per pedal.</p><p><strong>Ribbon cable</strong> runs to the computer, audio cable into the pedal, everything is beautifully adjusted and balanced and then off to the rack!</p><p><img src="https://www.thomann.de/blog/wp-content/uploads/2018/12/1-1-300x200.jpg"></p><p><img src="https://www.thomann.de/blog/wp-content/uploads/2018/12/2-1-300x200.jpg"></p><p><img src="https://www.thomann.de/blog/wp-content/uploads/2018/12/4-300x200.jpg"></p><p><img src="https://www.thomann.de/blog/wp-content/uploads/2018/12/3-1-300x200.jpg"></p><hr><h3>Connection to the shop</h3><h4><strong>The longest guitar cable in the worldâ€¦</strong></h4><p>â€¦ is available from <strong>Thomann</strong> in the <strong>shop,</strong> but not from <strong><a href="https://www.thomann.de/gb/stompenberg_devices.html">Stompenberg</a>.</strong> From now on the <strong>soldering iron</strong> gets put away and is replaced by a <strong>PC</strong> and <strong>keyboard</strong> in Thomannâ€™s Treppendorf. This is where our <strong>developers</strong> and <strong>designers</strong> sit, brooding over the visualization of the pedals and the interface that allows the pedals to be operated from anywhere in the world. From the logo to the controls to each button, everything comes from Thomannâ€™s teamwork.</p><p>When you turn the <strong>virtual knob</strong> at home, the <strong>digital knob</strong> on the pedal in the Thomann lab is adjusted via this interface, while your sound runs through exactly this pedal and comes back to you with effect. There are<strong> 3</strong> <strong>modes</strong> and a lot of <strong>UI tricks</strong> to discover.</p><p><img src="https://www.thomann.de/blog/wp-content/uploads/2018/12/lava-150x150.jpg" width="275">&nbsp; <img src="https://www.thomann.de/blog/wp-content/uploads/2018/12/6-1024x682.jpg" width="412"></p><hr><h2><strong>The Interface</strong></h2><h4><strong>The effect device</strong></h4><p>Design and development flow together here with loving attention to detail: Every <strong>knob</strong> can be rotated, every <strong>footswitch</strong> can be stepped on and every <strong>lever</strong> is slidable. This replica <strong>behaves exactly like the real pedal</strong> in the lab, right down to the smallest <strong>LED,</strong> and can therefore be operated in exactly the same way.</p><h4><strong>The three modes: PLAY, REC &amp; LIVE</strong></h4><p><strong>PLAY:</strong> You feed <strong>pre-recorded samples</strong> or specially <strong>uploaded sounds</strong> through the pedals and operate the controls with <strong>both hands</strong> (if using a <strong>touchscreen)</strong> while the sound loops through the effect pedal.</p><p><strong>REC:</strong> If you want to go a step beyond, you can <strong>record your own riffs</strong> and loop them through the pedal of your choice!</p><p><strong>LIVE:</strong> The ultimate experience â€“ here you <strong>play live</strong> and get the result back directly from the Thomann lab. So you can try out the pedal, live, from the comfort of your bedroom, with just a small <strong>latency,</strong> but thatâ€™s not bad considering the signal travels virtually at the speed of light&nbsp;through the<strong> whole of Germany or even the whole of Europe.&nbsp;</strong></p><p>The bright side: Even if your pedal is busy and you end up in the waiting queue, you donâ€™t have to listen to the dude in front of you butchering a cover of Stairway To Heaven ğŸ˜‰</p><h4><strong>And the rest of my equipment?</strong></h4><p>If you want to know exactly how the distortion in front of your own amp is done, you might need a <strong>reamping box.</strong> But under certain circumstances the line output of the interface does the trick too, just turned down low. The result reads like a poem:</p><p>You play your own guitar</p><p>through a real pedal (which is somewhere else)</p><p>through your amp</p><p>through your cabinet or speakers</p><p>at the volume you want</p><p>and you can turn, shift and control all the knobs as you like.</p><p>â€¦ and get a pretty accurate picture if this pedal will be your new one or if you prefer another one (which you tested with Stompenberg). No need to drive to Treppendorf, to send cardboard boxes back to Thomann halfway around the world, or to listen to annoying comments from the people waiting in line.</p><p><img loading="lazy" src="https://www.thomann.de/blog/wp-content/uploads/2018/12/8-1.jpg" alt="" width="1400" height="626" srcset="https://www.thomann.de/blog/wp-content/uploads/2018/12/8-1.jpg 1400w, https://www.thomann.de/blog/wp-content/uploads/2018/12/8-1-565x253.jpg 565w, https://www.thomann.de/blog/wp-content/uploads/2018/12/8-1-300x134.jpg 300w, https://www.thomann.de/blog/wp-content/uploads/2018/12/8-1-768x343.jpg 768w, https://www.thomann.de/blog/wp-content/uploads/2018/12/8-1-1024x458.jpg 1024w, https://www.thomann.de/blog/wp-content/uploads/2018/12/8-1-215x96.jpg 215w" sizes="(max-width: 1400px) 100vw, 1400px"></p><hr><h3><strong>The Future</strong></h3><p>The conversion is in full swing and while <strong>Stompenberg</strong> is running, our partners in <strong>Erlangen</strong> are taking more pedals apart every day to make them digitally accessible. There is plenty of room for <strong>growth</strong> â€“ ultimately, your <strong>demand</strong> determines the <strong>supply</strong> of pedals. So letâ€™s go, the smiles of satisfied guitarists are what keep us motivated!</p><p>Your Thomann R&amp;D Team</p><hr><h2><a href="https://www.thomann.de/gb/stompenberg_devices.html" target="_blank" rel="noopener noreferrer">Get stompinâ€™ at Stompenberg now</a>!</h2><p>Our<strong> YouTube</strong> host <strong>Felix Fleer</strong> took a closer look at Stompberg. Enjoy the <strong>video</strong> and try out the tool yourself!</p><p><span><iframe width="640" height="360" src="https://www.youtube-nocookie.com/embed/1lBYRQUTzYk?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en-GB&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span></p><div><p><img alt="Authorâ€™s gravatar" src="https://secure.gravatar.com/avatar/c9e90005014b2194675c8a066705c293?s=90&amp;d=blank&amp;r=g" srcset="https://secure.gravatar.com/avatar/c9e90005014b2194675c8a066705c293?s=180&amp;d=blank&amp;r=g 2x" height="90" width="90" loading="lazy"></p><p> Joe has been singing since he can remember and started playing guitar when he was 10. He's been using it as a songwriting tool ever since. He is passionate about melody and harmony and admires musicians who create these in unique ways. Check out his alternative / indie projects Best of Feelings and Zef RaÄek.</p></div></div></div>]]>
            </description>
            <link>https://www.thomann.de/blog/en/stompenberg-effects/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26197848</guid>
            <pubDate>Fri, 19 Feb 2021 20:46:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It's Not an Attention Economy. It's Attention Stewardship]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26197135">thread link</a>) | @chrbutler
<br/>
February 19, 2021 | https://www.chrbutler.com/attention-stewardship | <a href="https://web.archive.org/web/*/https://www.chrbutler.com/attention-stewardship">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<br>

<h6>â† <a href="https://www.chrbutler.com/essays">See All Articles</a></h6>
        
<p>
Some people saw the thrashing idscape in which we tribulate coming from a long way off. And they called it â€œthe attention economy.â€
</p>
<p>
A recent <a href="https://www.nytimes.com/2021/02/04/opinion/michael-goldhaber-internet.html" target="_blank">New York Times opinion column by Charlie Warzel</a> reminded me that as easy as it has been to trace some of the more dangerous effects of the attention economy to events of the last decade, some people could tell where things were headed long, long before that. One of them was Michael Goldhaber, a theoretical physicist and, as Warzel grandly introduces him, â€œthe internet prophet youâ€™ve never heard of.â€ Well, he had me at <i>internet</i>. And <i>prophet</i>. And <i>never heard of</i>.
</p>
<p>
Goldhaber has been writing about the attention economy for decades. In fact, back in 1997, he wrote an <a href="https://www.wired.com/1997/12/es-attention/" target="_blank">essay for <span>WIRED</span></a> about how the transactions of our dollars-and-cents economy would not only begin to include exchanges of attention, but would eventually be replaced entirely by them. For a population just getting to know the internet, the idea that attention would matter more than money was preposterous. For us who now know it well, itâ€™s remarkably on-point.
</p>
<p>
Looking back, itâ€™s fascinating â€” and more than a little bit concerning â€” to note that Goldhaberâ€™s own pessimism was far more accurate than his optimism. He earnestly predicted that attention would replace money because â€œattention canâ€™t be bought.â€ Well, it turns out that it very much can. And as utopic as a moneyless future sounds, a future in which attention replaces money as our currency seems obviously worse when you consider what Goldhaber got <i>right</i>. He warned that the pressure individuals would feel to both attract and give attention would metastasize into a wide-spreading erosion of culture. Goldhaber believed that simple human psychology predicted this. He wrote, â€œOur abilities to pay attention are limited. Not so our abilities to receive it. The value of true modesty or humility is hard to sustain in an attention economy.â€ In a recent conversation in preparation for Charlie Warzelâ€™s op-ed, Goldhaber echoed the same point: â€œWhen you have attention, you have power, and some people will try and succeed in getting huge amounts of attention, and they would not use it in equal or positive ways.â€
</p>
<p>
Weâ€™ve all lived and suffered that truth, especially acutely over the last few years, havenâ€™t we? Warzel sums it up this way, â€œAttention is a bit like the air we breathe. And it feels as if our attention has become polluted.â€
</p>
<p>
Warzel connects Goldhaberâ€™s early warnings to their latest effects, including the attempted insurrection on January 6th. The mob may have been after many different things, but the one thing every participant seems to have had in common was a desire for attention. The event itself, he writes, was â€œthe result of thousands of influencers and news outlets that, in an attempt to gain fortune and fame and attention, trotted out increasingly dangerous conspiracy theories on platforms optimized to amplify outrage.â€ Implied here is something Iâ€™d been observing as an increasingly rapid contagion of anti-truth since the day Donald Trump descended his escalator to declare his intention to destroy the country: that conspiracies and accusations of conspiracy are <i>products</i>, not byproducts of the attention economy. Theyâ€™re not something to believe in, but merely material to exchange for attention. In an inversion of assumptions about meaning, itâ€™s no longer relevant whether a person <i>believes</i> what they are saying as long as it is understood <i>why</i> they are saying it. Lies can be quite expedient.
</p>
<p>
That the attention economy is oversupplied with bile and bullshit is a compound problem. Itâ€™s obvious that the effects of peddling and buying lies can be profound. People can lose their grips on reality. Systems upon which many rely can fall apart. The equity of hundreds of years of history can dry up in a moment. These are the agonies of our public reckoning with how technology, truth, and treason have mixed and mingled in recent years. But we may get past this very shared and public struggle with truth and technology and still suffer the erosion of culture that Goldhaber warned about. Culture, after all, is bigger than political partisanship, bigger than sovereign nations, bigger than infrastructure, bigger than multinational corporations. Culture is a tapestry of ideas, beliefs, and agreements. And as powerful as any idea or belief or agreement may be, each relies upon attention.
</p>
<p>
Goldhaber also wrote, â€œWhen you pay attention to one thing, you ignore something else.â€ That is such a simple statement, but itâ€™s no less profound. It explains why thousands of articles go unread as you read this one â€” simple, indeed â€” but also why the aggregate of billions of equally simple exchanges of attention lead to the grand murmurations of culture.
</p>
<p>
If attention is an economy, then, in theory, it should follow a simple law of supply and demand just like any other economic system. In other words, the value and supply of attention should settle at a point where the thereâ€™s enough attention to meet demand. The problem is that while such a balance can be expected of bars of gold or even shares of a videogame retailerâ€™s stock, attention works by its own rules that upend the law of supply and demand. There will never be enough attention to meet demand.
</p>
<p>
Goldhaber puts it this way:
</p>
<blockquote>
â€œThe attention economy is a zero-sum game. What one person gets, someone else is denied. The size of the attention pie can grow as more and more people join the world audience, but the size of the average slice canâ€™t. Real attention to you, meaning minds focusing on you, is always limited by the number of minds there are. The more minds, the more attention - but also the more who might want attention. The total available attention per capita (per mind) is simply not going to change.â€
</blockquote>
<p>
These very words that I have written and that you are now reading provide a good example of what Goldhaber is talking about. Youâ€™re reading this. Thatâ€™s good for me. But that also means there are billions of things youâ€™re <i>not</i> reading. Thatâ€™s not good for the people who wrote them and whatever attention they hoped to get from you. Meanwhile, every moment that you spend paying attention to me is not only a moment youâ€™re not paying attention to someone else, itâ€™s a moment youâ€™re not spending doing something that could get you attention. Thatâ€™s where the law of supply and demand breaks down. Attention canâ€™t be stored up or mass produced; itâ€™s an inherently temporal matter. The more attention we pay, the less we can get.
</p>
<p>
But what if you donâ€™t care about getting attention? This is a question that should be asked. Itâ€™s easy enough to say that the internet, and specifically things like social media, have trained us to desire and seek attention more and more rapidly than we did before. Iâ€™m willing to accept that as true. But I donâ€™t think we can say that every one of us has been affected in the same way, or that the desire for attention has increased equally across all of humanity, or that the form attention takes and the means by which we seek it is a singular thing. Of course it is not. Though there are people willing to do all kinds of things simply for attention, not all of us go to such lengths. But even so, we do seek attention and we do pay it out. Our transactions may be much more mundane than a streamed coup, but they exist nonetheless and they are a finite resource.
</p>
<p>
That makes me wonder whether, through the frame of the attention economy, we are seeing its mechanics all wrong.
</p>
<p>
In the zero-sum attention game, the reader, you, gives the writer, me, your attention. You only get what I have written, for as long as youâ€™re reading it. But by these terms, I stand to get â€œmore.â€ There could be thousands of you reading this at the same time. Though I canâ€™t store your attention on the shelf, I can still get more than I pay out. If Iâ€™m a good writer, I â€œwinâ€ the game. Is that really the best way to think of this? After all, surely you stand to gain something, too. In the zero sum attention game, I am the beneficiary of your attention. But what if we chose to reverse that? What if we chose to see the beneficiary of the attention economy not as the recipient, but as the one paying attention?
</p>
<p>
Perhaps, then, we might think differently about information. We might begin to care more about its <i>value</i> than its volume.
</p>
<p>
<a href="https://en.wikipedia.org/wiki/Ren%C3%A9_Girard" target="_blank">RenÃ© Girard</a> was a widely influential thinker who certainly would have agreed. Girard is probably most famous for his thinking about the nature of human desire. He proposed that itâ€™s not a singular phenomenon, but an aggregate effect. His <i>mimetic theory</i> suggests that what you and I want is not original, but derives from what others want â€” that desire is an imitation. <i>Mimesis</i> is mimicry.
</p>
<p>
Naturally, this is a fiercely debated point. Even right now, you may be thinking of half a dozen things that youâ€™ve chosen for your own reasons, perhaps even at the resistance of others. That something as obviously personal as desire is really just the imitation of someone elseâ€™s desire seems, on its face, to be absurd. Is your favorite breakfast cereal really the end of an infinite regress of desires, and if so, originating with whom? That I canâ€™t answer. Perhaps thereâ€™s a Girard scholar out there who can.
</p>
<p>
But the more interesting thing about Girardâ€™s theories is the broader idea that, as this <a href="https://www.reddit.com/r/ThePortal/comments/cfmtq2/peter_thiel_during_the_portal_about_the_book/euiv3op/?utm_source=share&amp;utm_medium=web2x" target="_blank">incredibly robust Reddit explanation</a> puts it, â€œsecrets may exist in far more abundance than we realize <span>AND</span> YETâ€¦There are reasons we donâ€™t see them. And those reasons involve the details, mechanics and implications of Girardâ€™s theories. How we focus our desire and our attention is less under our control than we realize.â€
</p>
<p>
Regardless of the question of origin in Girardâ€™s theory of desire, the mechanics of how desire and attention work together to influence people are obvious. This is why fortunes can be created within hours of a photograph of a celebrity wearing something interesting being published online. â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.chrbutler.com/attention-stewardship">https://www.chrbutler.com/attention-stewardship</a></em></p>]]>
            </description>
            <link>https://www.chrbutler.com/attention-stewardship</link>
            <guid isPermaLink="false">hacker-news-small-sites-26197135</guid>
            <pubDate>Fri, 19 Feb 2021 19:41:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NFT/crypto art is exploding â€“ so here come the tech moguls to screw it up]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26196589">thread link</a>) | @smalera
<br/>
February 19, 2021 | https://www.businessofbusiness.com/articles/crypto-art-nft-beeple-christies-auction-token-ethereum-dada-blockchain/ | <a href="https://web.archive.org/web/*/https://www.businessofbusiness.com/articles/crypto-art-nft-beeple-christies-auction-token-ethereum-dada-blockchain/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-section">
    <!-- .sidebar -->

    <section>
      
      

      <p>Next week the venerable British auction house Christieâ€™s will set a precedent: Itâ€™s conducting the first ever auction of a digital artwork. And just to spice things up, thereâ€™s a crypto component to it all.&nbsp;</p>
<p><span>The groundbreaking Christieâ€™s auction will feature the work of an artist calling himself </span><a href="https://www.beeple-crap.com/"><span>Beeple</span></a><span>. The artwork being sold is a massive digital collage of five thousand pieces of work Beeple has released on the internet daily over 5,000 days.&nbsp;</span></p>
<p><span>That art is delivered in the form of a plain old JPG, of the sort that you might encounter on any website. The crypto twist is that a unique digital token on the Ethereum blockchain (</span><a href="https://etherscan.io/address/0x2a46f2ffd99e19a89476e2f62270e0a35bbf0756#code"><span>you can see the code here</span></a><span>) was â€œmintedâ€&nbsp;by the artist, connecting it to the JPG file. To be precise, a </span><a href="https://simple.wikipedia.org/wiki/Cryptographic_hash_function"><span>cryptographic hash</span></a><span> of the image is embedded in a smart contract on the Ethereum blockchain. Itâ€™s sort of like painters of yore signing a canvas, except this takes place cryptographically, and on a blockchain. These are called non-fungible tokens, or NFTs.&nbsp;</span></p>
<p><span>The Christieâ€™s auction is eagerly awaited. The auction house had earlier dabbled in crypto art with the October 2020 sale of a physical installation linked to an NFT called â€œBlock 21â€. That piece </span><a href="https://www.nbcnews.com/tech/tech-news/how-blockchain-technology-reached-christie-s-changed-art-world-along-n1244951"><span>fetched $130,000</span></a><span> or almost 11 times its low estimate. &nbsp;</span></p>
<p><span>But the upcoming Beeple auction could bring in much more. Beeple </span><a href="https://unchainedpodcast.com/beeple-on-how-and-why-he-raked-in-3-5-million/"><span>earlier sold $3.5 million worth</span></a><span> of digital tokens in a single weekend in December, a landmark amount in the burgeoning field of crypto art. These sales happened on crypto focused marketplaces, so the Christieâ€™s event is expected to expose the artist to a whole new crowd, as </span><a href="https://www.artnews.com/art-news/market/christies-beeple-blockchain-art-sale-1234583847/"><span>Art News has reported</span></a><span>.&nbsp;</span></p>
<p>Indeed, Christieâ€™s alludes to this in its prospectus accompanying the auction. The earlier sales make putting a price estimate on the upcoming event â€œimpossible to predict,â€ the auction-house says. â€œYour guess is as good as ours,â€ said Noah Davis, the Christieâ€™s specialist overseeing the sale, in the prospectus. &nbsp;</p>
<h2>Here Come the Tech Moguls</h2>
<p><span>Christieâ€™s isnâ€™t alone in recognizing the potential â€”&nbsp;and chasing the returns â€”&nbsp;on crypto collectibles. Tech moguls appear to be enthusiastic about the trend. Mark Cuban kicked it all off at the end of January when he wrote a blog post praising â€œthe store of value generation,â€&nbsp;</span><span>a new cohort of people who understood that digital objects on a blockchain could hold their value just as well as a fine art painting, vintage car or rare baseball collection.&nbsp;</span></p>
<p><span>â€œThis generation knows that a smart contract and the digital good it reflects â€¦ are a better investment than old school see, touch or feel uses,â€ the </span><a href="https://blogmaverick.com/2021/01/31/the-store-of-value-generation-is-kicking-your-ass-and-you-dont-even-know-it/'"><span>Shark Tank star wrote</span></a><span>.</span></p>
<p><span>Cubanâ€™s fellow tech elites have followed his lead. The billionaire Chamath Palihapitiya </span><span>told Bloomberg</span><span> a few days ago that he has been building a â€œfairly sizeableâ€ collection of digital art and other NFTs. â€œThese may sound crazy to some, but I do think that thatâ€™s the next frontier of digital currency and digital assets,â€ he said. Palihapitiya is a long-time Bitcoin bull, and rumored sightings of the crypto whale had trickled through the Ether for weeks. â€œ</span><span>Is that you, @Chamath?</span><span>â€ became a punch-line in NFT circles.&nbsp;</span></p>
<p><span>Yesterday, the wine entrepreneur turned tech investor Gary Vaynerchuk </span><a href="https://twitter.com/CNBCFastMoney/status/1362192935937323011?s=20"><span>took to CNBC</span></a><span> to extol the virtues of NFTs and other alternative investments, including trading cards. He had been steadily increasing mentions of crypto tokens on his Twitter feed, where he talks to 2.2 million followers, over the last week (he also started following me, for some reason!). Here he is </span><a href="https://twitter.com/garyvee/status/1361886864538562568?s=20"><span>on Wednesday</span></a><span>: â€œMy current situation - Iâ€™m trying to trade cases of Chateau D'Yquem for #NFT. 2021 life, lolâ€</span></p>
<p><span>The tech millionaires and Christieâ€™s are on to something. According to the </span><a href="https://cryptoart.io/data"><span>data site CryptoArt.io</span></a><span>, the value of all crypto art that changed hands in January was nearly $12 million. Twelve months ago, that figure stood at $160,000, representing growth of over 100 times over 12 months. Februaryâ€™s volumes have already topped Januaryâ€™s, and weâ€™re only 18 days in.&nbsp;</span></p>
<p><span>A report from data site NonFungible.com and Lâ€™Atelier, a unit of the French bank BNP Paribas </span><a href="https://nonfungible.com/blog/nft-yearly-report-2020"><span>released this week</span></a><span> says that crypto art now represents 24% of the entire NFT marketplace by value, accounting for the biggest ticket sales. The art segment lags only NFTs associated with â€œmetaversesâ€ or virtual worlds where users can buy pieces of land, outfits and other items that are secured by a blockchain.&nbsp;</span></p>
<h2><span>The dark side of crypto art</span></h2>
<p><span>As investors pile in to crypto art, and artists make millions from their sale, surely the utopian vision of a blockchain cutting out intermediaries and rewarding creators has been realized? Maybe not, as it turns out.&nbsp;</span></p>
<p><span>Beatriz Helena Ramos is the founder of a pioneering crypto art platform called </span><a href="https://dada.art/"><span>Dada</span></a><span>. An artist herself, she has worked on everything from editorial illustrations for the New York Times to animations for Disney and MTV. To hear Ramos tell it, the surging crypto art market has become successfulâ€”at the wrong thing.&nbsp;</span></p>
<p>â€œWhatâ€™s happening in the space is that the technology is very innovative, yet all of the social layer and the economic layer is just a repetition of everything from the legacy, default, world,â€ she says. â€œWhat we see with NFTs is that itâ€™s producing the exact same outcomes that we were trying to disrupt.â€</p>
<p>What are those outcomes, exactly? Ramos says the market remains tilted in favor of investors, and the vast majority of artists arenâ€™t going to sell their work for millions the way Beeple has. Instead, they will toil in the long tail of art, replicating the star system of the current art market.&nbsp;</p>
<p><span>A </span><a href="https://powerdada.medium.com/the-inconvenient-truth-about-secondary-markets-886d5c929efa"><span>study by Massimo Franceschet</span></a><span>, a computer scientist at the University of Udine, on the largest crypto art platform Superrare shows that the crypto art market has more wealth disparity among artists than any country in the history of the world. Some 80% of sales go to the top 25% of artists. While artists on Superrare at present earn the lionâ€™s share of sales volume, but as artworks get resold on secondary markets, Franceschet expects collectors to start earning more than artists by next June.&nbsp;</span></p>
<p><span>Ramos says she sees the human side of these statistics often. â€œWe see the casualties coming to us all the time. Tons of people who leave the space because they never sold anything, because they have to shill, because collectors actually harass artists on these chats and Discord channels. Weâ€™ve heard some horror stories, and thereâ€™s no accountability for anything,â€ she says.&nbsp;</span></p>
<p>While blockchains hold out the possibility of tokenizing anything, they also quickly run into the limits of this reductive logic. As Ramos says, turning everything into a market leads to â€œperverseâ€ incentives, like an artistsâ€™s work rising after her death, ensuring the supply of work is limited. â€œMarkets canâ€™t account for anything that isnâ€™t quantitative,â€ she tells me. &nbsp;</p>
<p>Still, the lure of a blockchainâ€™s ability to shift paradigms holds Ramos in its sway. She and a community of artists and technologists at Dada are working on a system that they believe will create fairer outcomes for artists and participants. They are focused on the social implications, and how the system might be governed.&nbsp;</p>
<p>â€œYou can have huge networks with network effects, coordinating people with each other and creating things. You donâ€™t need structures like companies and things like that,â€ she says. <span>â€œ</span>Imagine the quality and broad value that can be created. All you have to do is coordinate them. And so blockchain comes again.â€</p>
      

      

      



    </section><!-- .article-body -->

    
  </div></div>]]>
            </description>
            <link>https://www.businessofbusiness.com/articles/crypto-art-nft-beeple-christies-auction-token-ethereum-dada-blockchain/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26196589</guid>
            <pubDate>Fri, 19 Feb 2021 18:58:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Koo, Indiaâ€™s free-speech Twitter alternative]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 168 (<a href="https://news.ycombinator.com/item?id=26196588">thread link</a>) | @donohoe
<br/>
February 19, 2021 | https://restofworld.org/2021/how-koo-became-a-right-wing-darling-in-india/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2021/how-koo-became-a-right-wing-darling-in-india/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			<!-- Article Start -->
			
<p>It hasnâ€™t been a quiet few weeks on Twitter in India. The countryâ€™s capital city has seen over four months of protest after Prime Minister Narendra Modiâ€™s government enacted agricultural laws that would adversely affect farmers across India. <a href="https://www.bbc.com/news/world-asia-india-55899754">The farmer protests</a>, as the movement has come to be known, has taken to social media platforms like Twitter and Facebook to make the cause heard globally â€” and itâ€™s worked. Earlier this month, celebrities like <a href="https://www.dw.com/en/greta-thunberg-under-fire-for-tweeting-about-indian-farmers-toolkit/a-56458306">Greta Thunberg</a> and <a href="https://www.bbc.com/news/world-asia-india-55931894">Rihanna</a> weighed in with their tweets of support. Backlash <a href="https://www.bbc.com/news/world-asia-india-55931894">soon followed</a>.&nbsp;</p>



<p>But the governmentâ€™s ire against global critics of Modiâ€™s Hindu nationalist party has turned to Twitter itself. Citing threats to public order, on February 1, Indian authorities <a href="https://www.buzzfeednews.com/article/pranavdixit/indian-government-block-critics">appeared to have requested Twitter to suspend or remove</a> dozens of accounts on its platform. Twitter briefly complied but, after public outcry, reinstated the accounts and then <a href="https://www.cjr.org/the_media_today/twitter-stands-up-to-india-and-refuses-to-block-journalists.php">refused to remove</a> hundreds more.</p>



<p>Itâ€™s in the middle of this battle that Aprameya Radhakrishnaâ€™s 10-month-old social media platform was thrust into the spotlight. Soft-spoken and studious, Radhakrishna is a serial entrepreneur: in 2015, <a href="https://economictimes.indiatimes.com/magazines/panache/taxiforsure-founder-aprameya-radhakrishnas-life-after-sell-off/articleshow/48078627.cms">he sold his first company</a>, a ride-sharing app called TaxiForSure, to local giant Ola for $200 million. His latest venture is an app called Koo, <a href="https://www.kooapp.com/">a microblogging platform similar to Twitter</a> but for local-language speakers in India, a country with more than 20 languages and over 700 dialects.&nbsp;</p>



<p>After weeks of battling with Twitter, some of Indiaâ€™s most prominent Hindu nationalist politicians took to their social accounts and instructed their followers to leave Western social networks for Koo, a local, free-speech platform. â€œI am now on Koo,â€ <a href="https://twitter.com/PiyushGoyal/status/1359058583934013442">tweeted</a> Indiaâ€™s minister of commerce and industry, Piyush Goyal. â€œConnect with me on this Indian micro-blogging platform for real-time, exciting and exclusive updates.â€ Many of his <a href="https://twitter.com/PiyushGoyal">9.6 million followers</a> obliged. More right-wing politicians <a href="https://twitter.com/rsprasad/status/1360067772571545606?s=20">followed suit</a>, as did some of <a href="https://twitter.com/KanganaTeam/status/1361421114220576768">Bollywood</a>â€™s biggest stars.&nbsp;</p>



<p>Overnight, the platform went from a relatively obscure app to <a href="https://timesofindia.indiatimes.com/business/india-business/koo-lines-up-indian-investors-as-popularity-surges/articleshow/80867206.cms">headline news</a> and bagged <a href="https://economictimes.indiatimes.com/tech/funding/microblogging-platform-koo-bags-4-1-million-in-funding/articleshow/80685024.cms">$4.1 million in series A funding</a>.&nbsp;</p>



<p>Radhakrishna and his platform are in a curious position. The founder insists heâ€™s apolitical â€” heâ€™s appeared in both <a href="https://www.ndtv.com/video/news/news/koo-app-everything-you-need-to-know-about-koo-the-indian-alternative-to-twitter-575160">left-leaning</a> and <a href="https://www.opindia.com/2021/02/rahul-roushan-aprameya-radhakrishna-koo-co-founder-twitter-alternative-made-in-india-interview/">right-wing</a> outlets in the days since Koo has found the limelight â€” but is happily embracing the sudden rush to his app: Koo crossed <a href="https://www.livemint.com/technology/apps/koo-sees-10-fold-increase-in-downloads-this-week-crosses-3-million-users-11613038170243.html">3 million users </a>this month, fueled in large part by Modiâ€™s party.&nbsp;</p>



<p>And while itâ€™s unclear whether Koo will follow in the path of other social platforms <a href="https://www.usatoday.com/story/tech/2020/11/11/parler-mewe-gab-social-media-trump-election-facebook-twitter/6232351002/">that espouse â€œfree speechâ€ ideology</a>, itâ€™s likely more Indian apps like Radhakrishnaâ€™s will follow. Prominent among Modiâ€™s mantras for his vision of India is <em>Atmanirbhar Bharat: </em>a self-sufficient India. That vision <a href="https://restofworld.org/2021/indias-hashtag-war/">extends to the internet and social media</a>.&nbsp;</p>



<p>Six months before prominent right-wing politicians began heralding his app as Indiaâ€™s Twitter, Radhakrishna and his team submitted Koo to a government <em>atmanirbhar </em>social media challenge, <a href="https://navbharattimes.indiatimes.com/business/business-news/koo-app-wins-pm-modi-aatm-nirbhar-app-innovation-challenge/articleshow/77432196.cms">and won</a>.</p>



<p>Radhakrishna spoke to <em>Rest Of World </em>over Google Meet from Bangalore. This conversation has been edited for length and clarity.</p>



<hr>



<h4><strong>Tell me a bit about how you came up with the idea for Koo.&nbsp;</strong></h4>



<p>We started building it in November 2019 and launched it in March 2020. The idea behind it was that Twitter is existing in English in India, but the language speakers of India are not on Twitter. Letâ€™s build a deeper experience for the language speakers. And because we built a deeper experience for the language speakers, we were able to make a very localized community.&nbsp;</p>



<p>We started with Kannada, then we did Hindi, then Telugu, Marathi, then Tamil: we launched all of these languages. Then, we started noticing Twitter was getting into trouble in the U.S. We said, Maybe we should just have English as well as the local languages, if ever Twitter gets into trouble or users want a separate option.&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/IMG-20210218-WA0009-1-40x71.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/IMG-20210218-WA0009-1-600x1066.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/IMG-20210218-WA0009-1-400x711.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/IMG-20210218-WA0009-1-600x1067.jpg 600w, " sizes="(max-width: 640px) 100vw, 300px" alt="Aprameya Radhakrishna, a serial entrepreneur sold his first company, a ride-sharing app called TaxiForSure, for $200 million.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Aprameya Radhakrishna</span>
			</figcaption>
		</figure>


<h4><strong>When you started Koo, how soon were you approached by government officials who saw the </strong><a href="http://www.makeinindia.com/about"><strong>â€œMake in Indiaâ€</strong></a><strong> potential for the app?&nbsp;</strong></h4>



<p>We were a two-month-old app when we applied to the <a href="https://innovate.mygov.in/app-challenge/">[<em>Atmanibhar Bharat</em>]</a> challenge. We got into that challenge at the last minute, almost. Nobody approached us or anything. We applied just like any other startup â€” there were something like 7,000 social media startups that applied. We won that challenge, so that put us into the limelight: Oh, thereâ€™s an alternative microblogging platform that promotes local language<em>.&nbsp;</em></p>



<h4><strong>Walk me through how the last two or three weeks have been for you. Did you know that Piyush Goyal and the Ministry of Electronics and Technology would be encouraging their followers on Twitter to move to Koo en masse?&nbsp;</strong></h4>



<p>No. Itâ€™s been totally surreal for us. Itâ€™s totally welcome at Koo. We as a company are benefiting from the love that users who are shifting [from Twitter] are showing us. We werenâ€™t expecting it, but itâ€™s a pleasant surprise. Weâ€™re happy this move is happening.&nbsp;</p>



<h4><strong>Were you prepared for the sudden influx of users on the back end?&nbsp;</strong></h4>



<p>Not at all. Scaling 10x suddenly, in a week, is a challenge for any company, especially a 10-month-old startup. But weâ€™ve come through it; we are able to scale faster.&nbsp;</p>



<h4><strong>What were the user numbers like? Can you tell me how quickly they grew after the events of this month?&nbsp;</strong></h4>



<p>We were very small, we were sub-100,000 DAU [daily active users]. Now weâ€™re close to a million DAU. Close, not a million yet but close.&nbsp;</p>



<h4><strong>By virtue of chance, or deliberate action, thereâ€™s an ideological framework under which Koo has been positioned. You donâ€™t seem bothered by the fact that Koo is heralded </strong><a href="https://www.bbc.com/news/world-asia-india-56037901"><strong>as the right-wingâ€™s answer to Twitter</strong></a><strong>. Politics has played a role in the sudden attention that Koo has received. Have you considered the risks of embracing the way your app has been politicized?&nbsp;</strong></h4>



<p>It depends on the actions on the app. That first community [we built] in Kannada was built in a slower manner, and it has people from all parties in Karnataka.&nbsp;</p>



<p>What we are seeing is that India wants to be more self-reliant. India includes everybody. Our app doesnâ€™t understand â€œleftâ€ or â€œright.â€ <em>I </em>donâ€™t understand â€œleftâ€ or â€œright.â€ Iâ€™m an entrepreneur; Iâ€™m extremely apolitical. And Iâ€™m all for the development of the country. If Koo as a statement can make us self-reliant on our own social networks and technology, then we should be cheering for it. We shouldnâ€™t unnecessarily politicize it.</p>



<h4><strong>Social media is shaped by its users and early adopters. Most of Kooâ€™s early video content partnerships with, say, Republic TV [a channel </strong><a href="https://www.theguardian.com/media/2020/dec/23/indian-news-channel-fined-in-uk-for-hate-speech-about-pakistan"><strong>notorious for its allegiance</strong></a><strong> with the ruling Hindu nationalist party] or Mitron [a short-form video app that Modi supporters </strong><a href="https://www.techradar.com/news/mitron-app-gives-tiktok-a-challenge-will-it-sustain-though"><strong>have embraced after the ban on TikTok</strong></a><strong>] have come to associate the app with a particular ideology. Are you worried Koo might get too polarized too quickly?&nbsp;</strong></h4>



<p>Not at all. In Karnataka, we have everybody [on Koo], as I said. As a business, we keep looking for partners to grow our business. Now, the partners who come aggressively and see the vision that weâ€™re seeing as a free-expression platform and embrace the platform, weâ€™re happy to welcome them. Why would I say no to somebody who wants to use our platform? Republic [TV] came first, that doesnâ€™t mean I donâ€™t want everybody else.&nbsp;</p>


    <figure>
      <div>
				<ul>
					<li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone1-40x67.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone1-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone1-400x667.png 400w, https://restofworld.org/wp-content/uploads/2021/02/KooPhone1-600x1000.png 600w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone3-40x67.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone3-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone3-400x667.png 400w, https://restofworld.org/wp-content/uploads/2021/02/KooPhone3-600x1000.png 600w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone4-40x67.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone4-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone4-400x667.png 400w, https://restofworld.org/wp-content/uploads/2021/02/KooPhone4-600x1000.png 600w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone2-40x67.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone2-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone2-400x667.png 400w, https://restofworld.org/wp-content/uploads/2021/02/KooPhone2-600x1000.png 600w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li>
				</ul>
			</div>
      <figcaption>On Kooâ€™s Hindi language setting, itâ€™s easy to find the accounts of several of Indiaâ€™s biggest Hindu nationalist politicians next to celebrities and right-leaning media channels. The majority of the appâ€™s top trending hashtags in Hindi are pro-Modi.</figcaption>
    </figure>


<h4><strong>In a recent BBC report about your app, thereâ€™s a rhetorical question, </strong><a href="https://www.bbc.com/news/world-asia-india-56037901"><strong>â€œIs Koo Indiaâ€™s Parler?â€</strong></a><strong> What do you make of that comparison?&nbsp;</strong></h4>



<p>Each platform comes into being for different reasons. Iâ€™ve already explained my story. We were doing this irrespective of whether Twitter existed, got banned, got into trouble, or flourished in India.&nbsp;</p>



<p>We started in November 2019 because we said the voice of the Indian user who doesnâ€™t speak English is not there. We are building an inclusive social media network for India. So what was your question?&nbsp;</p>



<h4><strong>My question was what do you make of Parler andâ€”</strong></h4>



<p>Parler came into existence because there was an anti-Trump thing, and they wanted to do a pro-Trump thing. We donâ€™t exist because of some anti or pro thing. We are existing today irrespective of whether Twitter gets into trouble or not, irrespective of one ideology being there or not. We exist because we want to give a voice to every Indian. The purpose of our existence is very different from what a Parler is.&nbsp;</p>



<h4><strong>What do you make of the â€œMake in Indiaâ€ push, considering Facebook and Twitter have </strong><a href="https://www.nytimes.com/2021/01/14/technology/trump-facebook-twitter.html"><strong>an undeniable influence</strong></a><strong> in our current political discourse?</strong></h4>



<p>Every social media [platform] has to be responsible, to a certain extent, of what they bring into a country because it defines a lot of things in the country, like youth culture or how citizens of a country react to a situation.&nbsp;</p>



<p>When a company is registered elsewhere and doesnâ€™t take into consideration the nuances of the local culture, I think it can be dangerous. Indian entrepreneurs building for Indian cultural nuances is better than somebody who doesnâ€™t understand the cultural nuances trying to build for India.</p>



<figure><blockquote><p>â€œIndian entrepreneurs building for Indian cultural nuances is better than somebody who doesnâ€™t understand the cultural nuances trying to build for India.â€</p></blockquote></figure>



<h4><strong>The way Indian internet is shaping, </strong><a href="https://restofworld.org/2021/indias-hashtag-war/"><strong>an extreme version of â€œIndian apps for Indiaâ€</strong></a><strong> is an entire separate internet for India, the way China has Weibo and its own social network. Do you think that kind of internet would be a good thing for India as a whole?&nbsp;</strong></h4>



<p>Absolutely, we should have our own <em>atmanirbhar</em> platforms. We â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2021/how-koo-became-a-right-wing-darling-in-india/">https://restofworld.org/2021/how-koo-became-a-right-wing-darling-in-india/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2021/how-koo-became-a-right-wing-darling-in-india/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26196588</guid>
            <pubDate>Fri, 19 Feb 2021 18:58:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cleaner parallel curves with Euler spirals]]>
            </title>
            <description>
<![CDATA[
Score 124 | Comments 12 (<a href="https://news.ycombinator.com/item?id=26196470">thread link</a>) | @raphlinus
<br/>
February 19, 2021 | https://raphlinus.github.io/curves/2021/02/19/parallel-curves.html | <a href="https://web.archive.org/web/*/https://raphlinus.github.io/curves/2021/02/19/parallel-curves.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <!-- I should figure out a cleaner way to do this include, rather than cutting and pasting. Ah well.-->




<p><img src="https://raphlinus.github.io/assets/euler-parallel-flower.svg" alt="Many parallel curve of an Euler spiral, resembling a flower"></p>

<p>Determining <a href="https://en.wikipedia.org/wiki/Parallel_curve">parallel curves</a> is one of the basic 2D geometry operations. It has obvious applications in graphics, being the basis of creating a stroke outline from a path, but also in computer aided manufacturing (determining the path of a milling tool with finite radius) and path planning for robotics. There are plenty of solutions in the literature by now, but in this post I propose a cleaner solution.</p>

<p>A good survey paper is <a href="https://www.semanticscholar.org/paper/Comparing-Offset-Curve-Approximation-Methods-Elber-Lee/9ac1978746ec54bdd555b906e2ea1eb922cd6ffd">Comparing Offset Curve Approximation Methods</a>. The main difference between these approaches is the choice of curve representation. An example of a curve representation highly specialized for deriving parallel curves is the <a href="https://www.semanticscholar.org/paper/Pythagorean-hodographs-Farouki-Sakkalis/e20aeb60de908061797b6eaf3af79fdc7e5acdd7">Pythagorean Hodograph</a>. This parallel curve of a Pythagorean Hodograph is an exact parametric polynomial curve, but approximation techniques are still needed in practice, both to convert the source curve into the representation, and because the resulting curves are higher order rational polynomials, which require further approximation to convert into, say, cubic BÃ©ziers.</p>

<p>Specifically, this blog proposes piecewise Euler spirals as a curve representation particularly well suited to the parallel curve problem.</p>

<p>Thereâ€™s an implementation of many of these ideas (currently still in PR stage) in <a href="https://github.com/linebender/kurbo/pull/169">kurbo</a>. I also used a colab notebook to explore a bunch of the math, and Iâ€™ve made a <a href="https://github.com/raphlinus/raphlinus.github.io/blob/master/assets/Euler_spiral_scratchpad.ipynb">copy of that available</a> as well.</p>

<h2 id="the-cusp">The cusp</h2>

<p>One of the things that makes parallel curves special is that cusps often appear. In particular, a cusp appears whenever the radius of curvature of the source curve matches the offset. This is classified as an <a href="https://en.wikipedia.org/wiki/Cusp_(singularity)">ordinary cusp</a> and is a feature of many curve families â€“ weâ€™ll quantify that a bit more below.</p>

<p><img src="https://raphlinus.github.io/assets/euler-parallel-cusp.svg" alt="Parallel curve of an Euler spiral, showing the cusp"></p>

<p>A common feature of algorithms for computing parallel curves is identifying the location of the cusp, and subdividing there. That basically means solving for the specific value of curvature (the reciprocal of the offset distance). If the source curve is a cubic BÃ©zier, there can be up to four such cusps, and finding them requires some nontrivial numerical solving.</p>

<h2 id="curvature-as-a-function-of-arclength">Curvature as a function of arclength</h2>

<p>A theme of my approach to parallel curves (and much of my curve work in general, including my <a href="https://www.levien.com/phd/phd.html">thesis</a>), is to consider the relationship of curvature to arclength. A concrete intuition is that it is the position of the steering wheel as a car drives along the curve at constant speed. For some curves, curvature can be represented as a closed-form analytical formula as a function of arclength (the <a href="https://en.wikipedia.org/wiki/Ces%C3%A0ro_equation">CesÃ ro equation</a>), but in general determining the relation requires numerical techniques. For example, in the <a href="https://levien.com/euler_explorer/">Euler explorer</a>, thereâ€™s a plot of curvature as a function of arclength below the interactive cubic BÃ©zier. Experimenting with that is an excellent way to develop intuition.</p>

<p>One curve that <em>does</em> have an especially simple CesÃ ro equation is the Euler spiral. An Euler spiral segment has this formula:</p><p>

\[\kappa(s) = \kappa_0 + \kappa_1 s\]

</p><p>(A note for those trying to follow along with the detailed math and code: most of the math and numerical code uses $-0.5 \leq s \leq 0.5$ because it helps exploit even/odd symmetries, but the convention for parametrized curves, including the <a href="https://docs.rs/kurbo/0.8.0/kurbo/trait.ParamCurve.html">ParamCurve</a> trait in kurbo, is $0 \leq s \leq 1$. Thus, youâ€™ll frequently see offsets of 0.5. Similarly, youâ€™ll see various scaling to the actual arc length, while the parametrized curve convention assumes an arc length of 1. In this blog, weâ€™ll skim over such details, as the goal is to provide intuition without too much clutter from details.)</p>

<h2 id="the-parallel-curve-of-an-euler-spiral">The parallel curve of an Euler spiral</h2>

<p>In general, most curves do not have a simple formula for their parallel curve. The obvious exception is a circular arc, for which the parallel curve is another circular arc. Another curve family with tractable representation for its parallel curve is Pythagorean Hodographs.</p>

<p>Thanks to its exceptionally simple formulation as a CesÃ ro equation, the Euler spiral is one of the rare curves with a simple closed-form equation for its parallel curve. That equation was first published in a 1906 paper by Heinrich Wieleitner, <a href="https://books.google.com/books?id=UvpZAAAAYAAJ&amp;pg=PA373&amp;lpg=PA373&amp;dq=%22Die+Parallelkurve+der+Klothoide%22&amp;source=bl&amp;ots=fuY39VdPpd&amp;sig=K0AbL03rXAm_g4J9KsheQbbxyaA&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwiUrcD1poTfAhVvFjQIHVthBPoQ6AEwAnoECAMQAQ#v=onepage&amp;q=%22Die%20Parallelkurve%20der%20Klothoide%22&amp;f=false">Die Parallelkurve der Klothoide</a>. For those who donâ€™t read German, <a href="https://github.com/Rahix">Rahix</a> has kindly provided a translation into English: <a href="https://raphlinus.github.io/assets/clothoids.pdf">PDF</a>, <a href="https://raphlinus.github.io/assets/clothoids.text">TeX source</a>.</p>

<p>Going over this math, I see Wieleitner missed an opportunity for further simplification. The style at the time was to write the CesÃ ro equation in terms of the <em>radius</em> of curvature (the reciprocal of curvature), but especially for the Euler spiral and its parallel curve, using curvature directly yields a much simpler equation. With the cusp located at $s_0$, the equation is gratifyingly simple:</p><p>

\[\kappa(s) = \frac{c}{\sqrt{s - s_0}} + \frac{1}{l}\]

</p><p>The equation is graphed below, and clicking on it links to a <a href="https://www.desmos.com/calculator/qznzk9xnac">Desmos calculator graph</a> with sliders for the parameters.</p>

<p><a href="https://www.desmos.com/calculator/qznzk9xnac"><img src="https://raphlinus.github.io/assets/euler-spiral-parallel-cesaro.png" width="400" height="400"></a></p>

<p>Here $c$ is a coefficient dependent on the parameters of the spiral. To connect it to the notation in the Wieleitner paper, $c = a / \sqrt{2 l^3}$, and $s_0 = -a^2/{2l}$. Iâ€™ve also made a <a href="https://www.desmos.com/calculator/imvqywsb8o">Desmos calculator graph</a> that interactively demonstrates the equivalence of this equation and the more involved one from the Wieleitner paper.</p>

<p>There are a number of other curves that have a cusp similar to the above, with characteristic inverse-square root curvature. The clearest connection is the <a href="https://en.wikipedia.org/wiki/Involute">circle involute</a>, which is the same but without the $1/l$ term, or in other words the Euler spiral parallel curve approaches the circle involute as the offset goes to infinity. This provides intuition for the fact that a circle involute is its own parallel curve. The circle involute is perhaps most famous as the optimized profile for meshing <a href="https://ciechanow.ski/gears/">gear</a> teeth, transferring force smoothly with no slop or friction.</p>

<p>Other curves with a similar cusp include the <a href="https://en.wikipedia.org/wiki/Cycloid">cycloid</a> (as well as its many variants including epicycloid, hypocycloid, astroid, deltoid, cardioid, and nephroid), as well as the <a href="https://en.wikipedia.org/wiki/Semicubical_parabola">semicubical parabola</a>. The latter is of particular interest because it can be exactly represented as a case of a cubic BÃ©zier (it is when the control arms form a symmetrical X).</p>

<p><img src="https://raphlinus.github.io/assets/semicubical_parabola.svg" alt="semicubical parabola"></p>

<p>The parallel curve of the Euler spiral is perfectly cromulent, and, following the tradition of Pythagorean Hodograph curves and their higher-order rational polynomials, we could simply require everything downstream to simply deal with them. But to make that downstream processing easier, we will convert back to piecewise Euler spirals, a more tractable representation.</p>

<h2 id="geometric-hermite-interpolation">Geometric Hermite interpolation</h2>

<p><a href="https://en.wikipedia.org/wiki/Hermite_interpolation">Hermite interpolation</a> is a well known technique. In its simplest form, it is used to generate a piecewise polynomial approximation to some function, where the parameters for each polynomial segment are determined from the values and derivatives of the endpoints. For example, in cubic Hermite interpolation, a cubic polynomial is determined from the values and first derivatives at the endpoints â€“ four values, corresponding to four coefficients for the polynomial. The result is C1 continuous as the derivatives exactly match (and are equal to the source curve).</p>

<p>In 2D, there is a distinction between C1 and G1 (geometric) continuity. In C1 continuity, the full derivatives must match, both direction and magnitude. For applications such as animating motion curves, the magnitude is important (it represents speed of motion), but for curves, it is not. G1 continuity requires that the tangents match, but does not specify the magnitude of the derivatives.</p>

<p>In these applications, geometric Hermite interpolation is more efficient, as all parameters of the curve are available to make the shape fit. The Euler spiral is especially well suited to geometric Hermite interpolation, and there is literature on this topic. For reasonable assumptions of smoothness (excluding fractal curves but including simple cusps), the accuracy scales as $O(n^4)$ â€“ a doubling of the number of subdivisions reduces the error by a factor of 16. This scaling is the same as cubic Hermite interpolation of a 1D function, not surprising as an Euler spiral segment approximates a cubic polynomial when $y$ values are small.</p>

<p>Section 8.2 of my <a href="https://www.levien.com/phd/phd.html">thesis</a> provides a secant method for determining the Euler spiral parameters from the G1 Hermite constraints, and thatâ€™s implemented in the <code>fit_euler</code> method in the <a href="https://github.com/linebender/kurbo/pull/169">kurbo PR</a>. Thatâ€™s a good technique and its convergence is excellent (quadratic, as typical for Newton-style solvers for near-linear problems), but Iâ€™ve also been experimenting with ways to do it better. The linked notebook explores a polynomial approximation (based on 2D Taylorâ€™s series) that is much faster â€“ 7ns vs 240ns in my measurements, and should be very accurate over a wide range of parameters. Iâ€™m not quite done making the error bounds rigorous, but this approach should help make the overall algorithm lightning-fast.</p>

<p>Geometric Hermite interpolation works well to approximate the parallel curve of an Euler spiral segment with another Euler spiral segment:</p>

<p><img src="https://raphlinus.github.io/assets/euler-parallel-approx.svg" alt="Approximation of the parallel curve of an Euler spiral segment"></p>

<p>The true parallel curve is in blue, and the approximation in red. It has the same rough shape, but bulges out in the middle. We need to be able to estimate that error in order to make a more accurate approximation.</p>

<h3 id="a-simple-accurate-error-metric">A simple, accurate error metric</h3>

<p>The most common approach to approximation given a target error bound is adaptive subdivision: approximate the error, and if it exceeds the target, subdivide. Evaluating the error is not always easy; most generally, itâ€™s based on numerical techniques such as evaluating the curve at several points along its length and testing how near those points lie to the source curve.</p>

<p>Fortunately, for approximating an Euler spiral parallel curve using an Euler spiral, there is an extremely simple formula for the error. In fact, itâ€™s possible to avoid the adaptive subdivision altogether, and precisely predict how many subdivisions are needed to meet an error bound, as well as analytically place the subdivisions so each segment has the same error.</p>

<p>Normalized to a chord length of 1, where the arc â€¦</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://raphlinus.github.io/curves/2021/02/19/parallel-curves.html">https://raphlinus.github.io/curves/2021/02/19/parallel-curves.html</a></em></p>]]>
            </description>
            <link>https://raphlinus.github.io/curves/2021/02/19/parallel-curves.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26196470</guid>
            <pubDate>Fri, 19 Feb 2021 18:49:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Researchers looking for mRNA were ridiculed by colleagues]]>
            </title>
            <description>
<![CDATA[
Score 292 | Comments 99 (<a href="https://news.ycombinator.com/item?id=26196372">thread link</a>) | @fortran77
<br/>
February 19, 2021 | https://www.macleans.ca/society/science/scientists-mrna-covid-vaccines/ | <a href="https://web.archive.org/web/*/https://www.macleans.ca/society/science/scientists-mrna-covid-vaccines/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Sixty years ago, the scientists who were pioneering the technology that would make today's COVID-19 vaccines possible were mocked and dismissed</p><div>
																		<p>A few days before Christmas, Matthew Meselson, a 90-year-old professor at Harvard, called his universityâ€™s health service to inquire about being vaccinated against COVID-19. He was eager for his shot. Meselson felt imprisoned in his Cambridge apartment, just blocks from the campus where heâ€™d worked for six decades. Heâ€™d officially retired from teaching at the beginning of 2020, but continued his research as much as possible throughout the pandemic, wearing a K95 mask to work in his lab.</p>
<p>He longed to re-engage in the world around him. He missed his weekly date with close friends over lunch at Bostonâ€™s best French restaurant; theyâ€™d switched to Zoom, but staring into a computer screen is no replacement for lingering at linen-covered tables. He longed for his wife of 32 years, Jeanne Guillemin, who died from cancer late in 2019. Meselson was still figuring out how his world worked without her, and isolation made this hard task harder.</p>
<p>The person on the other end of the phone apologized to the professor. â€œWe donâ€™t have a vaccine schedule yet,â€ she told him.</p>
<p>The first two COVID-19 vaccines to be approved for use in North America were developed, tested and delivered into freezers before many jurisdictions figured out how to administer them. The vaccines from Pfizer-BioNTech and Moderna are the first approved vaccines ever to employ modified mRNA, which is delivered sealed in a lipid shell. The mRNA slips into our cells, carrying instructions to make antibodies that target SARS-CoV-2. The vaccines function almost like a wanted poster: if you see these guys, get â€™em. Then, the mRNA degrades, leaving no trace.</p>
<blockquote><p><strong>READ:&nbsp;<a href="https://www.macleans.ca/news/covid-19-vaccines-curbing-pandemic-vaxx-populi/">How quickly will the COVID-19 vaccines start curbing the pandemic in Canada?</a></strong></p></blockquote>
<p>The fact that mRNA is the basis of these vaccines contributed to their rapid development. In November, the <em>New York Times</em> reported that within two days of China releasing the genetic sequence of SARS-CoV-2, scientists at Moderna Inc., a 10-year-old company headquartered not far from Meselsonâ€™s home in Cambridge, â€œplugged that data into its computers and came up with a design for an mRNA vaccine.â€ Meanwhile, BioNTech, a small biotech company in Germany that had been working on mRNA flu vaccines with the pharmaceutical powerhouse Pfizer, soon similarly turned its resources to generating an mRNA COVID vaccine.</p>
<p>But these fastest vaccines in history have been decades in the making. Theyâ€™re the product of generations of scientists who built on one idea after another, and kept at it despite failed experiments, rejections, threats of deportation, a lack of funding and skepticism from contemporaries. They were inspired by the discovery of DNA: in 1951, a young English physical chemist named Rosalind Franklin took X-ray photographs that captured DNAâ€™s helical shape; two years later, James Watson and Francis Crick of Cambridge University published the first report describing DNAâ€™s double helix, for which they received the Nobel Prize. (Franklin died of ovarian cancer in 1958; her contributions were largely overlooked in her lifetime.) And they were driven not by a race to halt a raging pathogen or by the chance to patent a multi-billion-dollar drug, but by one big, irresistible question: What makes life?</p>
<p>â€œThese werenâ€™t people who wanted to solve little problems,â€ says Meselson. â€œThese were people who wanted to solve a great big problem.â€</p>
<p>He was one of them.</p>
<p>***</p>
<p>Born in Colorado in 1930, Meselson zipped through the sciences at a young age. By 16, he enrolled at the University of Chicago. In 1957, while doing post-doctoral work at the California Institute of Technology (Caltech), Meselson and Frank Stahl demonstrated how DNA replicates itself, a model that had been suggested but never shown. Science historian Frederic Lawrence Holmes later characterized their work as â€œthe most beautiful experiment in biology,â€ having revealed how life worked.</p>
<p>But many unanswered questions remained about what happens inside our cells. Meselson and colleagues knew that DNA resides in the nucleus, a compartment barricaded off from the rest of the cell by a membrane. On the other side of the membrane is the cytoplasm, a gelatinous liquid that fills the remainder of the cell. This is the home of tiny granules called ribosomes, which house RNA.</p>
<p>Around the same time that Meselson and Stahl published their groundbreaking work on DNA, French scientists discovered that cells made proteins through the ribosomes. DNA, despite holding the critical codes for life, is a relatively passive molecule. Ribosomes do the busy labour, building proteins to carry out the biological processes of survival. The question was how?</p>
<p>One of the French scientists, Dr. FranÃ§ois Jacob, theorized that there must be an â€œunstable intermediaryâ€ that went between the DNA and the RNAâ€”sending messages from the DNA to the RNA, and then disappearing.</p>
<p>Jacob, a physician whoâ€™d been forced from medical school when Germany invaded France in 1940 and spent the war years fighting with Charles de Gaulleâ€™s Free French Forces, called this theoretical intermediary â€œX.â€ Other researchers â€œrolled their eyes in horrorâ€ when he presented his theory, Jacob recalled in his memoir, <em>The Statue Within</em>. â€œWith a little encouragement, my audience would have jeered and left,â€ he wrote.</p>
<div id="attachment_1216833"><p><img data-sizes="auto" src="https://www.macleans.ca/wp-content/uploads/2021/02/MATTHEW-MESELSON-DNA-FRANGOU-FEB02-766x431.jpg" alt="Meselson at Caltech in 1958 (Courtesy of the Caltech Archives)" width="766" height="431"></p><p>Meselson at Caltech in 1958 (Courtesy of the Caltech Archives)</p></div>
<p>In spring 1960, Jacob wrote to Meselson with a proposal: he and Sydney Brenner, a South African biologist at the University of Cambridge, would meet at Meselsonâ€™s lab at Caltech to find X. Meselson, who was in his first year on faculty, had developed a technique to track smaller molecules inside a cell. Jacob believed this technique would help identify X. That summer, with Jacob and Brenner in his lab, Meselson set up initial cultures and tests. Brenner took over the operations, while Jacob sat in a chair taking notesâ€”pain from bomb fragments in his legs was worsened by the California humidity, says Meselson. For three weeks, they met with one failure after another. The ribosomes kept falling apart. Other scientists poked their heads in periodically and asked sarcastically for news of X. Jacob wrote that they â€œcame to visit as one would visit the zoo.â€ On the trioâ€™s very last scheduled day in the lab, Meselson, having given up on X, left. He flew to Boston to propose to his first wife.</p>
<p>Dejected, Jacob and Brenner went to Malibu Beach. The duo lay on the beach, watching huge waves of the Pacific crashing onto the sand and contemplating where their idea had gone wrong. Jacob wrote in his memoir: â€œSuddenly, Sydney gives a hoot. He leaps up, yelling, â€˜The magnesium! Itâ€™s the magnesium!â€™ â€ They raced back to the lab to run the experiment one last time, with additional magnesium. The result was spectacular. X existed.</p>
<blockquote><p><strong>READ:&nbsp;<a href="https://www.macleans.ca/news/theres-a-new-strain-of-covid-19-will-the-vaccines-work-against-it/">Thereâ€™s a new strain of COVID-19. Will the vaccines work against it?</a></strong></p></blockquote>
<p>The pair gave a seminar the same day at Caltech to demonstrate X. Even then, no one believed them. They contacted Meselson in Boston that night to tell him. He was delighted. â€œIt didnâ€™t occur to me that they would figure out what was going wrong on the very last day,â€ he says. When the trio published their findings in 1961, they renamed X as messenger RNA.</p>
<p>They did not imagine that their finding would be used for therapeutics or a vaccine. Their questions were more philosophical. Meselson says, â€œWe wondered what is it that allows you to put together the atoms of the ordinary periodic chart and end up with something thatâ€™s alive?â€</p>
<p>Their work became the central tenet of molecular biology: DNA makes RNA makes protein makes life. It took another generation of scientists to find a way to harness RNA to treat and prevent illness.</p>
<p>***</p>
<p>As a kid in KisÃºjszÃ¡llÃ¡s, Hungary, Katalin KarikÃ³ watched her father, a butcher, dismember the carcasses of pigs. It was her first introduction to science. In the 1970s, while studying biochemistry at the University of Szeged, KarikÃ³ heard about a new report from London: interferon, a type of protein made by the body to trigger a defence against a virus, was mediated by an RNA called 2-5A. KarikÃ³ remembers a mentor talking to her about the discovery and being thrilled by the possibilities. He suggested to her that if they could make a synthetic version of a 2-5A molecule, they might be able to treat cancer or viral disease. â€œI immediately thought that what I was doing was tremendously important,â€ she says. It was the start of a 40-year quest to make synthetic RNA that could cure illness.</p>
<p>But she couldnâ€™t secure funding in Hungary. Married with a two-year-old daughter, KarikÃ³ saw no way to continue her work in her home country. She wrote to professors throughout Europe about joining their labs, but no one could hire her. In 1985, she received an offer from Temple University in Philadelphia. If she could get to the United States, a job was waiting for her.</p>
<p>At the time, Hungarian money could not legally be converted to another currency and taken out of the country. Worried about how their family would survive until her first paycheque, KarikÃ³ and her husband, Bela Francia, sold their Russian-made car and converted the proceeds on the black market for a total of 900 British pounds. They sewed the money into their daughterâ€™s teddy bear to smuggle it out of the country. The teddy bearâ€™s owner, their daughter, Susan Francia, grew up to become a two-time Olympic gold medallist for the United States in rowing.</p>
<div id="attachment_1216834"><p><img data-sizes="auto" src="https://www.macleans.ca/wp-content/uploads/2021/02/KATALIN-KARIKO-MRNA-COVID-19-FRANGOU-FEB02.jpg" alt="KarikÃ³ at home in Pennsylvania (Rachel Wisniewski)" width="820" height="547"></p><p>KarikÃ³ at home in Pennsylvania (Rachel Wisniewski)</p></div>
<p>In their new home, things did not go as planned. KarikÃ³â€™s bosses changed, she couldnâ€™t get funding and she lost her job. Her supervisor cited her for deportation. Desperate to stay in the United States as her daughter entered first grade, KarikÃ³ accepted a researcher post in Bethesda, Maryland. She commuted from Philadelphia every Monday morning at 3 a.m. and â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.macleans.ca/society/science/scientists-mrna-covid-vaccines/">https://www.macleans.ca/society/science/scientists-mrna-covid-vaccines/</a></em></p>]]>
            </description>
            <link>https://www.macleans.ca/society/science/scientists-mrna-covid-vaccines/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26196372</guid>
            <pubDate>Fri, 19 Feb 2021 18:41:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gaussian Processes: from one to many outputs]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26196255">thread link</a>) | @wesselb
<br/>
February 19, 2021 | https://invenia.github.io/blog/2021/02/19/OILMM-pt1/ | <a href="https://web.archive.org/web/*/https://invenia.github.io/blog/2021/02/19/OILMM-pt1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p><span>19 Feb 2021</span></p>
  <p>This is the first post in a three-part series we are preparing on multi-output Gaussian Processes. Gaussian Processes (GPs) are a popular tool in machine learning, and a technique that we routinely use in our work.
Essentially, GPs are a powerful Bayesian tool for regression problems (which can be extended to classification problems through some modifications).
As a Bayesian approach, GPs provide a natural and automatic mechanism to construct and calibrate uncertainties.
Naturally, getting <em>well</em>-calibrated uncertainties is not easy and depends on a combination of how well the model matches the data and on how much data is available.
Predictions made using GPs are not just point predictions: they are whole probability distributions, which is convenient for downstream tasks. There are several good references for those interested in learning more about the benefits of Bayesian methods, from <a href="https://towardsdatascience.com/an-introduction-to-bayesian-inference-e6186cfc87bc">introductory</a> <a href="https://towardsdatascience.com/what-is-bayesian-statistics-used-for">blog posts</a> to <a href="https://probml.github.io/pml-book/book0.html">classical</a> <a href="http://www.stat.columbia.edu/~gelman/book/">books</a>.</p>

<p>In this post (and in the forthcoming ones in this series), we are going to assume that the reader has some level of familiarity with GPs in the single-output setting.
We will try to keep the maths to a minimum, but will rely on mathematical notation whenever that helps making the message clear.
For those who are interested in an introduction to GPsâ€”or just a refresherâ€”we point towards <a href="https://distill.pub/2019/visual-exploration-gaussian-processes/">other</a> <a href="https://medium.com/analytics-vidhya/intuitive-intro-to-gaussian-processes-328740cdc37f">resources</a>.
For a rigorous and in-depth introduction, the <a href="http://www.gaussianprocess.org/gpml/">book by Rasmussen and Williams</a> stands as one of the best references (and it is made freely available in electronic form by the authors).</p>

<p>We will start by discussing the extension of GPs from one to multiple dimensions, and review popular (and powerful) approaches from the literature.
In the following posts, we will look further into some powerful tricks that bring improved scalability and will also share some of our code.</p>

<h2 id="multi-output-gps">Multi-output GPs</h2>

<p>While most people with a background in machine learning or statistics are familiar with GPs, it is not uncommon to have only encountered their single-output formulation.
However, many interesting problems require the modelling of multiple outputs instead of just one.
Fortunately, it is simple to extend single-output GPs to multiple outputs, and there are a few different ways of doing so. We will call these constructions multi-output GPs (MOGPs).</p>

<p>An example application of a MOGP might be to predict both temperature and humidity as a function of time. Sometimes we might want to include binary or categorical outputs as well, but in this article we will limit the discussion to real-valued outputs.
(MOGPs are also sometimes called multi-task GPs, in which case an output is instead referred to as a task. But the idea is the same.)
Moreover we will refer to inputs as time, as in the time series setting, but all the discussion in here is valid for any kind of input.</p>

<p>The simplest way to extend GPs to multi-output problems is to model each of the outputs independently, with single-output GPs.
We call this model IGPs (for independent GPs). While conceptually simple, computationally cheap, and easy to implement, this approach fails to account for correlations between outputs.
If the outputs are correlated, knowing one can provide useful information about others (as we illustrate below), so assuming independence can hurt performance and, in many cases, limit it to being used as a baseline.</p>

<p>To define a general MOGP, all we have to do is to also specify how the outputs covary.
Perhaps the simplest way of doing this is by prescribing an additional covariance function (kernel) over outputs, \(k_{\mathrm{o}}(i, j)\), which specifies the covariance between outputs \(i\) and \(j\).
Combining this kernel over outputs with a kernel over inputs, e.g. \(k_{\mathrm{t}}(t, t')\), the full kernel of the MOGP is then given by</p><p>

\[\begin{equation}

k((i, t), (j, t')) = \operatorname{cov}(f_i(t), f_j(t')) = k_{\mathrm{o}}(i, j) k_{\mathrm{t}}(t, t'),

\end{equation}\]

</p><p>which says that the covariance between output \(i\) at input \(t\) and output \(j\) at input \(t'\) is equal to the product \(k_{\mathrm{o}}(i, j) k_{\mathrm{t}}(t, t')\).
When the kernel \(k((i, t), (j, t'))\) is a product between a kernel over outputs \(k_{\mathrm{o}}(i, j)\) and a kernel over inputs \(k_{\mathrm{t}}(t,tâ€™)\), the kernel \(k((i, t), (j, t'))\) is called <em>separable</em>.
In the general case, the kernel \(k((i, t), (j, t'))\) does not have to be separable, i.e. it can be any arbitrary <a href="https://en.wikipedia.org/wiki/Positive-definite_function">positive-definite function</a>.</p>

<p>Contrary to IGPs, general MOGPs do model correlations between outputs, which means that they are able to use observations from one output to better predict another output.
We illustrate this below by contrasting the predictions for two of the outputs in the <a href="https://sccn.ucsd.edu/~arno/fam2data/publicly_available_EEG_data.html">EEG dataset</a>, one observed and one not observed, using IGPs and another flavour of MOGPs, the ILMM, which we will discuss in detail in the next section. Contrary to the independent GP (IGP), the ILMM is able to successfully predict F2 by exploiting the observations for F3 (and other outputs not shown).</p>

<p><img src="https://invenia.github.io/blog/public/images/eeg.png" alt="IGP_vs_MOGP">
Figure 1: Predictions for two of the outputs in the EEG dataset using two distinct MOGP approaches, the ILMM and the IGP.
All outputs are modelled jointly, but we only plot two of them for clarity.</p>

<h3 id="equivalence-to-single-output-gps">Equivalence to single-output GPs</h3>

<p>An interesting thing to notice is that a general MOGP kernel is just another kernel, like those used in single-output GPs, but one that now operates on an <em>extended</em> input space (because it also takes in \(i\) and \(j\) as input).
Mathematically, say one wants to model \(p\) outputs over some input space \(\mathcal{T}\).
By also letting the index of the output be part of the input, we can construct this extended input space: \(\mathcal{T}_{\mathrm{ext}} = \{1,...,p\} \times \mathcal{T}\). Then, a multi-output Gaussian process (MOGP) can be defined via a mean function, \(m\colon \mathcal{T}_{\mathrm{ext}} \to \mathbb{R}\), and a kernel, \(k\colon \mathcal{T}_{\mathrm{ext}}^2 \to \mathbb{R}\).
Under this construction it is clear that any property of single-output GPs immediately transfers to MOGPs, because MOGPs can simply be seen as single-output GPs on an extended input space.</p>

<p>An equivalent formulation of MOGPs can be obtained by stacking the multiple outputs into a vector, creating a <em>vector-valued GP</em>.
It is sometimes helpful to view MOGPs from this perspective, in which the multiple outputs are viewed as one multidimensional output.
We can use this equivalent formulation to define MOGP via a <em>vector-valued</em> mean function, \(m\colon \mathcal{T} \to \mathbb{R}^p\), and a <em>matrix-valued</em> kernel, \(k\colon\mathcal{T}^2 \to \mathbb{R}^{p \times p}\). This mean function and kernel are <em>not</em> defined on the extended input space; rather, in this equivalent formulation, they produce <em>multi-valued outputs</em>.
The vector-valued mean function corresponds to the mean of the vector-valued GP, \(m(t) = \mathbb{E}[f(t)]\), and the matrix-valued kernel to the covariance matrix of vector-valued GP, \(k(t, tâ€™) = \mathbb{E}[(f(t) - m(t))(f(tâ€™) - m(tâ€™))^\top]\).
When the matrix-valued kernel is evaluated at \(t = tâ€™\), the resulting matrix \(k(t, t) =  \mathbb{E}[(f(t) - m(t))(f(t) - m(t))^\top]\) is sometimes called the <em>instantaneous spatial covariance</em>: it describes a covariance between different outputs at a given point in time \(t\).</p>

<p>Because MOGPs can be viewed as single-output GPs on an extended input space, inference works exactly the same way.
However, by extending the input space we exacerbate the scaling issues inherent with GPs, because the total number of observations is counted by adding the numbers of observations for each output, and GPs scale badly in the number of observations.
While inference in the single-output setting requires the inversion of an \(n \times n\) matrix (where \(n\) is the number of data points), in the case of \(p\) outputs, assuming that at all times all outputs are observed,<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> this turns into the inversion of an \(np \times np\) matrix (assuming the same number of input points for each output as in the single output case), which can quickly become computationally intractable (i.e. not feasible to compute with limited computing power and time).
That is because the inversion of a \(q \times q\) matrix takes \(\mathcal{O}(q^3)\) time and \(\mathcal{O}(q^2)\) memory, meaning that time and memory performance will scale, respectively, cubically and quadratically on the number of points in time, \(n\), and outputs, \(p\).
In practice this scaling characteristic limits the application of this general MOGP formulation to data sets with very few outputs and data points.</p>

<h3 id="low-rank-approximations">Low-rank approximations</h3>

<p>A popular and powerful approach to making MOGPs computationally tractable is to impose a <a href="https://en.wikipedia.org/wiki/Rank_(linear_algebra)">low-rank</a> structure over the covariance between outputs.
That is equivalent to assuming that the data can be described by a set of latent (unobserved) Gaussian processes in which the number of these <em>latent processes</em> is fewer than the number of outputs.
This builds a simpler lower-dimensional representation of the data. The structure imposed over the covariance matrices through this lower-dimensional representation of the data can be exploited to perform the inversion operation more efficiently (we are going to discuss in detail one of these cases in the next post of this series).
There are a variety of different ways in which this kind of structure can be imposed, leading to an interesting class of models which we discuss in the next section.</p>

<p>This kind of assumption is typically used to make the method computationally cheaper.
However, these assumptions do bring extra <a href="https://en.wikipedia.org/wiki/Inductive_bias">inductive bias</a> to the model. Introducing inductive bias <a href="https://towardsdatascience.com/supercharge-your-model-performance-with-inductive-bias-48559dba5133">can be a powerful tool</a> in making the model more data-efficient and better-performing in practice, provided that such assumptions are adequate to the particular problem at hand.
For instance, <a href="https://epubs.siam.org/doi/pdf/10.1137/18M1183480">low-rank data</a> <a href="https://ieeexplore.ieee.org/document/1177153">occurs naturally</a> in <a href="https://www.sciencedirect.com/science/article/abs/pii/S0005109807003950">different settings</a>.
This also happens to be true in electricity grids, due to the <a href="https://lib.dr.iastate.edu/cgi/viewcontent.cgi?article=1031&amp;context=econ_las_conf">mathematical structure</a> of the â€¦</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://invenia.github.io/blog/2021/02/19/OILMM-pt1/">https://invenia.github.io/blog/2021/02/19/OILMM-pt1/</a></em></p>]]>
            </description>
            <link>https://invenia.github.io/blog/2021/02/19/OILMM-pt1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26196255</guid>
            <pubDate>Fri, 19 Feb 2021 18:30:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python Resources for Everybody]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26196218">thread link</a>) | @EntICOnc
<br/>
February 19, 2021 | https://learnbyexample.github.io/py_resources/ | <a href="https://web.archive.org/web/*/https://learnbyexample.github.io/py_resources/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><nav id="sidebar" aria-label="Table of contents"></nav><div id="page-wrapper"><div class="page"><div id="content"><main><h2><a href="#about" id="about">About</a></h2><p>This is a collection of Python <strong>learning</strong> resources. Many of the resources, especially the beginner ones, are free.</p><p><img src="https://learnbyexample.github.io/py_resources/images/info.svg" alt="info"> For a curated list of frameworks, libraries, software, etc, see <a href="https://github.com/vinta/awesome-python">awesome-python</a></p><h2><a href="#img-srcimageswarningsvg-altwarning--disclaimer-and-disclosure" id="img-srcimageswarningsvg-altwarning--disclaimer-and-disclosure"><img src="https://learnbyexample.github.io/py_resources/images/warning.svg" alt="warning"> Disclaimer and Disclosure</a></h2><p>I don't have personal experience with majority of the resources mentioned here. I have collected them from various recommendation threads on Reddit, Hacker News, Stackexchange sites, Twitter, GitHub, etc.</p><p><a href="https://learnbyexample.github.io/py_regular_expressions/">Python re(gex)?</a> and <a href="https://learnbyexample.github.io/100_page_python_intro/">100 Page Python Intro</a> are my own books.</p><h2><a href="#table-of-contents" id="table-of-contents">Table of Contents</a></h2><ul><li><a href="https://learnbyexample.github.io/py_resources/beginners.html">Beginner resources</a> <ul><li><a href="https://learnbyexample.github.io/py_resources/beginners.html#new-to-programming">New to programming</a></li><li><a href="https://learnbyexample.github.io/py_resources/beginners.html#new-to-python">New to Python</a></li><li><a href="https://learnbyexample.github.io/py_resources/beginners.html#courses-with-certificates">Courses with certificates</a></li><li><a href="https://learnbyexample.github.io/py_resources/beginners.html#exercises">Exercises</a></li><li><a href="https://learnbyexample.github.io/py_resources/beginners.html#projects">Projects</a></li><li><a href="https://learnbyexample.github.io/py_resources/beginners.html#debugging">Debugging</a></li><li><a href="https://learnbyexample.github.io/py_resources/beginners.html#tools-ide-and-text-editors">Tools, IDE and Text Editors</a></li><li><a href="https://learnbyexample.github.io/py_resources/beginners.html#cheatsheets">Cheatsheets</a></li><li><a href="https://learnbyexample.github.io/py_resources/beginners.html#documentation-and-getting-help">Documentation and getting help</a></li></ul></li><li><a href="https://learnbyexample.github.io/py_resources/specific.html">Specific features</a> <ul><li><a href="https://learnbyexample.github.io/py_resources/specific.html#async-and-concurrency">Async and concurrency</a></li><li><a href="https://learnbyexample.github.io/py_resources/specific.html#command-line-applications">Command line applications</a></li><li><a href="https://learnbyexample.github.io/py_resources/specific.html#context-managers">Context managers</a></li><li><a href="https://learnbyexample.github.io/py_resources/specific.html#decorators-and-closures">Decorators and closures</a></li><li><a href="https://learnbyexample.github.io/py_resources/specific.html#iterables-generators-yield-itertools">Iterables, Generators, Yield, Itertools</a></li><li><a href="https://learnbyexample.github.io/py_resources/specific.html#lambda">Lambda</a></li><li><a href="https://learnbyexample.github.io/py_resources/specific.html#lists-and-comprehensions">Lists and comprehensions</a></li><li><a href="https://learnbyexample.github.io/py_resources/specific.html#memoization">Memoization</a></li><li><a href="https://learnbyexample.github.io/py_resources/specific.html#os-interaction">OS interaction</a></li><li><a href="https://learnbyexample.github.io/py_resources/specific.html#profiling-code-and-speeding-up-python">Profiling code and speeding up Python</a></li><li><a href="https://learnbyexample.github.io/py_resources/specific.html#regular-expressions">Regular Expressions</a></li><li><a href="https://learnbyexample.github.io/py_resources/specific.html#virtual-environments-and-packaging">Virtual Environments and Packaging</a></li></ul></li><li><a href="https://learnbyexample.github.io/py_resources/intermediate.html">Intermediate to Advanced resources</a> <ul><li><a href="https://learnbyexample.github.io/py_resources/intermediate.html#intermediate">Intermediate</a></li><li><a href="https://learnbyexample.github.io/py_resources/intermediate.html#testing">Testing</a></li><li><a href="https://learnbyexample.github.io/py_resources/intermediate.html#algorithms-and-data-structures">Algorithms and data structures</a></li><li><a href="https://learnbyexample.github.io/py_resources/intermediate.html#design-patterns">Design patterns</a></li><li><a href="https://learnbyexample.github.io/py_resources/intermediate.html#advanced">Advanced</a></li></ul></li><li><a href="https://learnbyexample.github.io/py_resources/domain.html">Domain specific resources</a> <ul><li><a href="https://learnbyexample.github.io/py_resources/domain.html#bioinformatics">Bioinformatics</a></li><li><a href="https://learnbyexample.github.io/py_resources/domain.html#data-science">Data Science</a></li><li><a href="https://learnbyexample.github.io/py_resources/domain.html#gui-and-games">GUI and Games</a></li><li><a href="https://learnbyexample.github.io/py_resources/domain.html#machine-learning">Machine Learning</a></li><li><a href="https://learnbyexample.github.io/py_resources/domain.html#robotics-and-computer-vision">Robotics and Computer Vision</a></li><li><a href="https://learnbyexample.github.io/py_resources/domain.html#scientific-computing">Scientific computing</a></li><li><a href="https://learnbyexample.github.io/py_resources/domain.html#web-development">Web development</a></li></ul></li></ul><h2><a href="#acknowledgements" id="acknowledgements">Acknowledgements</a></h2><ul><li><a href="https://github.com/rust-lang/mdBook">mdBook</a></li><li><a href="https://github.com/JorelAli/mdBook-pagetoc">mdBook-pagetoc</a></li><li><a href="https://github.com/wilsonzlin/minify-html">minify-html</a></li><li><a href="https://commons.wikimedia.org/wiki/File:Warning_icon.svg">Warning</a> and <a href="https://commons.wikimedia.org/wiki/File:Info_icon_002.svg">Info</a> icons by <a href="https://commons.wikimedia.org/wiki/User:Amada44">Amada44</a> under public domain</li><li><a href="https://inkscape.org/">Inkscape</a></li><li><a href="https://github.com/RazrFalcon/svgcleaner">svgcleaner</a></li></ul><h2><a href="#license" id="license">License</a></h2><p>This work is licensed under a <a href="https://github.com/learnbyexample/py_resources/blob/master/LICENSE">Creative Commons Zero v1.0 Universal License</a></p></main><nav aria-label="Page navigation"><a rel="next" href="https://learnbyexample.github.io/py_resources/beginners.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right"> <i></i> </a></nav></div></div><nav aria-label="Page navigation"><a rel="next" href="https://learnbyexample.github.io/py_resources/beginners.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right"> <i></i> </a></nav></div></div>]]>
            </description>
            <link>https://learnbyexample.github.io/py_resources/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26196218</guid>
            <pubDate>Fri, 19 Feb 2021 18:27:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nyan Cat on the Blockchain]]>
            </title>
            <description>
<![CDATA[
Score 89 | Comments 88 (<a href="https://news.ycombinator.com/item?id=26196027">thread link</a>) | @awaxman11
<br/>
February 19, 2021 | https://foundation.app/NyanCat/nyan-cat-219 | <a href="https://web.archive.org/web/*/https://foundation.app/NyanCat/nyan-cat-219">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Nyan Cat is the name of an animation uploaded on April 2 2011, and became a viral internet sensation. The design of Nyan Cat was inspired by my cat Marty, who crossed the Rainbow Bridge but lives on in spirit.</p><p>I am the original artist behind the iconic GIF and have remastered the image for its 10 year anniversary.  Owning this piece grants the following stats:</p><p>Charisma +10<br>Luck +10<br>Happiness +15</p><hr><p>1400x1400 - 12 Frames</p></div></div>]]>
            </description>
            <link>https://foundation.app/NyanCat/nyan-cat-219</link>
            <guid isPermaLink="false">hacker-news-small-sites-26196027</guid>
            <pubDate>Fri, 19 Feb 2021 18:12:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Hotwire Could be the Future of Front-end Dev]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26195969">thread link</a>) | @timdl
<br/>
February 19, 2021 | https://wizville.fr/en/blog/a-product-guys-take-on-hotwire-vs-vue-react/ | <a href="https://web.archive.org/web/*/https://wizville.fr/en/blog/a-product-guys-take-on-hotwire-vs-vue-react/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						
							<p><span>Iâ€™ve had the chance of talking directly to <a href="https://twitter.com/dhh" target="_blank" rel="noopener">@DHH</a>&nbsp;himself, creator of Ruby on Rails, on the 28th of January, mostly about Hotwire (video at the end of the post). Just writing this, as a product guy who never shipped a line of Ruby in production, still feels completely crazy.&nbsp;</span></p>
<h2><b>How it happened</b></h2>
<p><span>It all started as a joke. At <a href="https://wizville.fr/en/" target="_blank" rel="noopener">WizVille</a>, like most startups, we struggle to hire Fullstack Rails developers that match our (rather high) expectations. Which is a problem when your whole strategy is based on changing the way your customers go about their business through technology and innovation. Especially when you feel like youâ€™ve&nbsp;<a href="https://techcrunch.com/2020/10/15/wizville-local-monitor-helps-small-shops-track-google-maps-ratings-of-competitors/" target="_blank" rel="noopener">cracked it</a> and start having stronger traction than ever, both nationally and internationally, and have had <strong>3 senior Software Engineers positions open for 4 months (see our&nbsp;<a href="https://www.welcometothejungle.com/fr/companies/wizville/jobs/ruby-on-rails-developer-experimente-e-h-f-x_paris">remaining open position</a>)</strong>â€¦&nbsp;</span></p>
<p><span>So one night, I call ClÃ©ment, our CTO, and tell him : Â« Letâ€™s ask DHH to come talk at our first ever WizVille-hosted tech event!Â». The idea would be to make a powerful statement to the Rails community in France: Â« WizVille means business, and takes inspiration from the best, you should join us! Â».</span></p>
<p><span>ClÃ©ment laughed and answered, Â« well, thatâ€™s a crazy idea, but he just launched Hotwire and a new version of Turbo today Â». I open Hacker News, Â« <a href="https://hotwire.dev/" target="_blank" rel="noopener">Hotwire: HMTL over the wire</a> Â» is the #1 post. I find out about the tech and realize that not only Hotwire is a potential game changer, but also that this is the perfect opportunity.&nbsp;</span></p>
<p><span>It just took one email, I offered to gather as much of the French Rails community as possible for an event during which he could spread the word about Hotwire, and he accepted within 24 hours. I think he did because the email transpired the fact that I was maybe the most determined guy out there to be willing to gather as much of the Rails community for a dedicated event about HW.&nbsp;</span></p>
<h2><b>Not just another front-end framework</b></h2>
<p><span>At first, I thought Hotwire wasnâ€™t meant to take over the front-end development game in Davidâ€™s mind. But <strong>I was shocked by his answers and the displayed pureness of his ambition</strong> on why he created it and shipped HW for the world to use.&nbsp;</span></p>
<p><span>We all know David for his game changing vision with Rails, and his radical approach to working described in Rework and how it influenced the way the tech world sees work. But Rails was launched at a different time, when youâ€™d think the competing technologies were â€œrather clearlyâ€ retrograde.&nbsp;</span></p>
<p><span>We also know how powerful frameworks like Vue and React are today. </span> <span>So, assuming the potential limitations of Hotwire, since itâ€™s HTML-based, and the incredible contenders there are in the front-end development world (lead by the likes of Facebook, Googleâ€¦), I never thought David was going to pitch us an upcoming shift in the way apps are createdâ€¦ even though it kinda feels obvious now that heâ€™s described it to me.&nbsp;</span></p>
<h2><b>Why Hotwire could be the future&nbsp;</b></h2>
<ol>
<li aria-level="1"><span>You can learn Hotwire over a week-end according to David. On average it takes about a month or two with React. With V ue, about 2 to 4 weeks.&nbsp;</span></li>
<li aria-level="1"><b>Having to code everything in Javascript on the front-end has never been a free choice</b><span>: itâ€™s always been a choice made out of the absence of alternatives. With HW, app builders wonâ€™t have to deal with the complexities of having developers specialized in a completely different technology. And will use the needed technology for the appropriate goal. That will dramatically increase the developerâ€™s satisfaction since he will be able to use his preferred language and also manage most of the spectrum of web app building himself.&nbsp;</span></li>
<li aria-level="1"><span>Hotwire is an independent project from Rails, which means it works with any back end development framework.&nbsp;</span></li>
<li aria-level="1"><span>Hotwire also works on mobile. Out of Heyâ€™s mobile appâ€™s +100 screens, only one of them is built in native languages. Thereâ€™s also a misconception about Strada (not released at the moment Iâ€™m writing this): it will just give developers a more conventionalized approach for interacting with their native apps, but thatâ€™s it.&nbsp;</span></li>
<li aria-level="1"><span>Hotwire works for every kind of app, save for apps that really require javascriptâ€™s abilities as a technology, and need to work independently in the client (calendars or apps like Figma). That kind of app is a very small fraction, and Hotwire can be combined with a JS framework like React or Vue if needed.&nbsp;</span></li>
</ol>
<p><b>So there you have all the ingredients to replace any front-end framework:</b></p>
<ul>
<li aria-level="1"><span>Speed: get your developers up to speed on your front-end framework faster, and therefore potentially ship your product faster</span></li>
<li aria-level="1"><span>Simplicity: easier for back-end developers to do otherwise complex front-end work</span></li>
<li aria-level="1"><span>Coherent technology choice : use complex front-end frameworks only when needed for some features</span></li>
<li aria-level="1"><span>Compatibility : works with all back-end frameworks and all types of web apps</span></li>
</ul>
<h2><b>Main concerns to date&nbsp;</b></h2>
<p><span>The main concerns are mostly related to <strong>how little time itâ€™s been since Hotwire has been released</strong>. This means smaller community and stack overflow threads, and also fewer plugins. The most advanced design framework you could use is <a href="https://tailwindcss.com/" target="_blank" rel="noopener">Tailwind</a>, a CSS framework. Which may have us coding our own animations or having to combine with other librariesâ€¦? </span><span>Also, having to combine front-end frameworks in some cases, doesnâ€™t feel ideal.</span></p>
<p><span>David told us that Hotwire was up to a much stronger start than Rails, so we could expect to have most of those concerns solved along the road.&nbsp;</span></p>
<p><b>But the mere fact that David Heinemier Hansson deeply believes that his personal mission is to liberate developers from the grip of Single-Page-Apps with Hotwire should definitely have everyoneâ€™s attention in Tech. And it definitely has ours at WizVille.&nbsp;</b></p>
<h2><b>About the event&nbsp;</b></h2>
<p><span>The event was called Â« Hotwire &amp; Startups: Dreaming bigger With Rails in 2021 Â» and you can enjoy Davidâ€™s 1 hour fireside chat mainly about Hotwire below:&nbsp;</span></p>
<p><iframe width="669" height="376" src="https://www.youtube.com/embed/GtWc-xo9ZBo?start=4347&amp;feature=oembed&amp;enablejsapi=1&amp;origin=https://wizville.fr" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>We also asked their opinions about Hotwire to <a href="https://twitter.com/sylvainutard?lang=fr">Sylvain Utard</a> (AI General Manager @&nbsp;<a href="http://algolia.com/">Algolia</a>), and Nicolas Denayer (VP Engineering @&nbsp;<a href="http://doctolib.com/">Doctolib</a>) along with our own CTO, <a href="https://www.linkedin.com/in/clement-bruchon-37319545/?originalSubdomain=fr">ClÃ©ment Bruchon</a>, see the video of the panel here (in French):</p>
<p><iframe width="669" height="376" src="https://www.youtube.com/embed/GtWc-xo9ZBo?start=296&amp;feature=oembed&amp;enablejsapi=1&amp;origin=https://wizville.fr" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p><span>We plan on hosting a 2022 edition of a similar event and are sure to have even more to say on the matter of Hotwire vs React &amp; Vue.&nbsp;</span></p>
<h2><strong>About the author&nbsp;</strong></h2>
<p><a href="http://twitter.com/timdl">TimothÃ©e de Laitre</a>&nbsp;is CEO &amp; Head of Product @ <a href="http://wizville.fr/en">WizVille</a>, a 30 people SaaS startup developing a Customer Feedback Platform dedicated to Retail Chains. See our currently open positions <a href="https://www.welcometothejungle.co/companies/wizville/jobs" target="_blank" rel="noopener">here.</a></p>

							</div></div>]]>
            </description>
            <link>https://wizville.fr/en/blog/a-product-guys-take-on-hotwire-vs-vue-react/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26195969</guid>
            <pubDate>Fri, 19 Feb 2021 18:07:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parsec: Platform Abstraction for Security (secure obj storage, crypto services)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26195270">thread link</a>) | @Terretta
<br/>
February 19, 2021 | https://parallaxsecond.github.io/parsec-book/overview.html | <a href="https://web.archive.org/web/*/https://parallaxsecond.github.io/parsec-book/overview.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
        <!-- Provide site root to javascript -->
        

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        

        <!-- Set the theme before any content is loaded, prevents flash -->
        

        <!-- Hide / unhide sidebar before it is displayed -->
        

        <nav id="sidebar" aria-label="Table of contents">
            
            
        </nav>

        <div id="page-wrapper">

            <div class="page">
                
                
                

                
                
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                

                <div id="content">
                    <main>
                        
<p><strong>Parsec</strong> is the <strong>P</strong>latform <strong>A</strong>bst<strong>R</strong>action for <strong>SEC</strong>urity, a new open-source initiative to
provide a common <a href="https://parallaxsecond.github.io/parsec-book/parsec_client/api_overview.html">API</a> to secure services in a platform-agnostic way.</p>
<p>Parsec aims to define a universal software standard for interacting with secure object storage and
cryptography services, creating a common way to interface with functions that would traditionally
have been accessed by more specialised APIs. Parsec establishes an ecosystem of developer-friendly
libraries in a variety of popular programming languages. Each library is designed to be highly
ergonomic and simple to consume. This growing ecosystem will put secure facilities at the fingertips
of developers across a broad range of use cases in infrastructure computing, edge computing and the
secure Internet of Things.</p>

<p>Today's computing platforms have evolved to offer a range of facilities for secure storage and
secure operations. There are hardware-backed facilities such as the Hardware Security Module (HSM)
or Trusted Platform Module (TPM). There are firmware services running in Trusted Execution
Environments (TEE). There are also cloud-based security services. At a bare minimum, security
facilities may be provided purely in software, where they are protected by mechanisms provided in
the operating system.</p>
<p>Over the years, software standards have emerged to allow developers to use these facilities from
their applications. But these standards bring with them the following challenges:</p>
<ul>
<li>They are defined with the expectation that the caller is the "owner" of the platform, meaning that
it has sole access to the underlying hardware. In reality, this is often not the case, because
the caller might reside in a container or virtual machine, where it is sharing the host hardware
with other applications. Existing software standards do not cater well for this situation.</li>
<li>They are defined exhaustively, with lengthy specifications detailing all permissible operations
and parameters. They are written from the perspective of the security device and its
capabilities, rather than from the perspective of the application and its use case. This can
offer a daunting and bewildering experience for developers, who spend a lot of time and effort
figuring out how to map their use case onto the API. There is nothing to tailor the API so that
it can be consumed easily for common, simple cases.</li>
<li>They are specific to a programming language such as C. To consume them in other languages, it is
necessary to use interoperability layers such as Foreign Function Interface (FFI), which can make
the developer experience even more cumbersome and unnatural. Interoperability layers can also be
a source of vulnerabilities.</li>
<li>Standards tend to be adopted based on some knowledge of the target platform. So while it might be
possible for code to be portable across multiple HSM vendors, for example, it is much harder to
make code portable between an HSM-based platform and a TPM-based platform.</li>
</ul>
<p>Parsec inverts this traditional approach to standardizing security interfaces, and it does so by
putting applications front and center. It offers an API that is no less comprehensive, but it does
so in a way that puts the needs of applications and their common use cases first.</p>
<p>Applications simply want the best-available security, and they want to be able to consume it in a
way that is simple, natural, and hard to get wrong.</p>
<p>The following observations can be made about such applications:</p>
<ul>
<li>They can be written in a variety of programming languages.</li>
<li>They may be written with no explicit knowledge of the hardware capabilities of the target
platform, such as whether an HSM or TPM is available.</li>
<li>They are often sharing the target platform hardware with other applications due to the use of
virtualization or containerization technology.</li>
<li>The secure assets owned by one application must be isolated from those owned by another. For
example, private keys provisioned on a hardware device must be isolated such that only the
provisioning application would be able to perform subsequent operations with those keys.</li>
<li>They have differing requirements in terms of permissible cryptographic algorithms and key
strengths.</li>
</ul>
<p>These observations motivate the need for a new platform abstraction that offers a common palette of
security primitives via a software interface that is both agnostic with respect to the underlying
hardware capabilities, and also capable of supporting multiple client applications on the same host,
whether those be within containers or within traditional virtual machines.</p>
<p>Parsec is a new software architecture and ecosystem that addresses this need.</p>

<p>Parsec is founded on the <a href="https://developer.arm.com/architectures/security-architectures/platform-security-architecture"><strong>Platform Security Architecture
(PSA)</strong></a>.
The PSA is a holistic set of threat models, security analyses, hardware and firmware architecture
specifications, and an open source firmware reference implementation. The PSA provides a recipe,
based on industry best practice, that allows security to be consistently designed in, at both a
hardware and firmware level.</p>
<p>One of the provisions of the PSA is the <a href="https://github.com/ARMmbed/mbed-crypto/blob/psa-crypto-api/docs/PSA_Cryptography_API_Specification.pdf"><strong>PSA Crypto
API</strong></a>.
The PSA Crypto API is a comprehensive library of modern security primitives covering the following
functional areas:</p>
<ul>
<li>Key provisioning and management</li>
<li>Hashing</li>
<li>Signing</li>
<li>Message Authentication Codes (MAC)</li>
<li>Asymmetric encryption</li>
<li>Symmetric encryption</li>
<li>Authenticated Encryption with Associated Data (AEAD)</li>
<li>Key derivation</li>
<li>Entropy (random number generation)</li>
</ul>
<p>A crucial characteristic of the PSA Crypto API is that applications always reference the keys
opaquely, making it ideally suited to implementations where keys are provisioned within hardware and
are never exposed.</p>
<p>The PSA Crypto API is defined in the C language. Parsec adopts the operations and contracts of the C
API, and uses them as the basis for a language-independent <a href="https://parallaxsecond.github.io/parsec-book/parsec_client/wire_protocol.html"><strong>wire
protocol</strong></a>. Each <a href="https://parallaxsecond.github.io/parsec-book/parsec_client/operations">operation</a> is defined,
along with all of its inputs and outputs, as a serializable contract, making it suitable to be
invoked over an Inter-Process Communication (IPC) transport. Parsec maintains functional equivalence
with the PSA Crypto API, but allows for out-of-process callers in any programming language.</p>

<p>The core component of Parsec is the <strong>security service</strong> (or <strong>security daemon</strong>). This is a
background process that runs on the host platform and provides connectivity with the secure
facilities of that host and surfaces the wire protocol based on PSA Crypto.</p>
<p>The security service listens on a suitable transport medium. The transport technology is one of
Parsec's many pluggable components, and no single transport is mandated. Choice of transport is
dependent on the operating system and the deployment. On Linux-based systems where the client
applications are running in containers (isolation with a shared kernel), the transport can be based
on Unix sockets.</p>
<p>Client applications make connections with the service by posting API requests to the transport
endpoint. This is usually done via a client library that hides the details of both the wire protocol
and the transport. This is one of the ways in which the client library simplifies the experience of
Parsec for application developers.</p>
<p>A single instance of the Parsec service executes on each physical host. In virtualized environments,
the Parsec service may reside on a specially-assigned guest, or potentially within the hypervisor.</p>
<p>The security service does not support remote client applications. Each physical host or node must
have its own instance of the service. However, it is possible for the service to initiate outbound
remote calls of other services, such as cloud-hosted HSM services.</p>

<p>In addition to surfacing the common API, the Parsec service is also responsible for brokering access
to the underlying security facilities amongst the multiple client applications. The exact way that
this is done will vary from one deployment to another. (See the section below on pluggable back-end
modules). Some of the brokering functionality may already reside in kernel drivers and other parts
of the software stack. The Parsec service is responsible for creating isolated views of key storage
and cryptographic services for each client application. The secure assets of one client must be kept
protected from those of another.</p>
<p>Central to this multi-tenant operation is the notion of <strong>application identity</strong> and the need for a
separate <strong>identity provider</strong> service. A Parsec-enabled host must contain an identity provider
service in addition to the Parsec service itself.</p>
<p>For more information about application identities and the identity provider, please refer to the
<a href="https://parallaxsecond.github.io/parsec-book/parsec_service/system_architecture.html"><strong>system architecture</strong></a> document.</p>

<p>The Parsec service employs a layered architecture, structured into a front-end and a back-end.</p>
<p>The front-end module provides the transport endpoint and listens for connections from clients. The
front-end understands the wire protocol and the common API. It is responsible for serialization and
de-serialization of the operation contracts.</p>
<p>The back-end modules are known as <strong>providers</strong>. An instance of the Parsec security service can load
one or more providers. Providers implement the API operations using platform-specific or
vendor-specific code. They provide the "last mile" of connectivity down to the underlying hardware,
software or firmware.</p>
<p>For a deeper dive into the modular structure of the Parsec service, please take a look at the
<a href="https://parallaxsecond.github.io/parsec-book/parsec_service/interfaces_and_dataflow.html"><strong>interfaces and dataflow</strong></a> design document.</p>
<p>Then delve into the <a href="https://parallaxsecond.github.io/parsec-book/parsec_service/source_code_structure.html"><strong>source code</strong></a> to discover the
back-end provider modules that exist. If you cannot find one that is compatible with the platform
you intend to use, then please consider contributing a new provider.</p>

<p>A key aim of Parsec is to evolve an ecosystem of developer-friendly client libraries in multiple
programming languages.</p>
<p>Parsec â€¦</p></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://parallaxsecond.github.io/parsec-book/overview.html">https://parallaxsecond.github.io/parsec-book/overview.html</a></em></p>]]>
            </description>
            <link>https://parallaxsecond.github.io/parsec-book/overview.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26195270</guid>
            <pubDate>Fri, 19 Feb 2021 17:13:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Backup is essential This is Butterfly Backup]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26195250">thread link</a>) | @jajjarax
<br/>
February 19, 2021 | https://matteoguadrini.github.io/Butterfly-Backup/ | <a href="https://web.archive.org/web/*/https://matteoguadrini.github.io/Butterfly-Backup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <header>
        
        
        

        <p>Butterfly Backup is a simple command line wrapper of rsync for complex task, written in python.</p>

        
        <p><a href="https://github.com/MatteoGuadrini/Butterfly-Backup">View the Project on GitHub <small>MatteoGuadrini/Butterfly-Backup</small></a></p>
        

        

        
        <ul>
          <li><a href="https://github.com/MatteoGuadrini/Butterfly-Backup/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/MatteoGuadrini/Butterfly-Backup/tarball/master">Download <strong>TAR Ball</strong></a></li>
          <li><a href="https://github.com/MatteoGuadrini/Butterfly-Backup">View On <strong>GitHub</strong></a></li>
        </ul>
        
      </header>
      <section>

      <p><img src="https://matteoguadrini.github.io/Butterfly-Backup/img/butterfly_backup.png" alt="Butterfly Backup"></p>

<p><img src="https://matteoguadrini.github.io/Butterfly-Backup/img/bb.png" alt="Greta oto"></p>

<p><a href="https://app.codacy.com/app/MatteoGuadrini/Butterfly-Backup?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=MatteoGuadrini/Butterfly-Backup&amp;utm_campaign=Badge_Grade_Dashboard"><img src="https://api.codacy.com/project/badge/Grade/7fc47024f17f4dffa3be08a7a5ab31bd" alt="Codacy Badge"></a>
<a href="https://circleci.com/gh/MatteoGuadrini/Butterfly-Backup"><img src="https://circleci.com/gh/MatteoGuadrini/Butterfly-Backup.svg?style=svg" alt="CircleCI"></a></p>


<p><strong>The plan is great when the backup plan is excellent!</strong></p>

<h2 id="what-is-that">What is that?</h2>
<p>Butterfly Backup is a <em>simple</em> command line wrapper of rsync for <em>complex</em> task, written in python.</p>

<h2 id="why-butterfly">Why butterfly?</h2>
<p>Butterfly Backup exploits the potential of rsync with maximum simplicity, maximum flexibility and more. Moreover,
its greatest strength is the organization of backups in a catalog, easy to consult.</p>

<h2 id="what-can-i-do">What can I do?</h2>
<p>With Butterfly Backup I can perform single or group backups (Full, Incremental, Differential and Mirror), restore, export, list and archive old backups.</p>

<h2 id="how-can-you-do-it">How can you do it?</h2>
<p>Naturally through the synergy of rsync and OpenSSH technology and the power of Python..</p>

<h2 id="which-platforms-support">Which platforms support?</h2>
<p>Butterfly Backup can backup Linux, BSD, MacOSX and Windows(with cygwin, see <a href="https://butterfly-backup.readthedocs.io/en/latest/">config docs</a>)</p>

<h2 id="real-uses">Real uses</h2>
<p>This list consists of only a few examples; applications can be endless:</p>
<ul>
  <li>Backing up periodically (ex. once a month) a folder where I store my photos over the years;</li>
  <li>Logâ€™s backup of one or more servers;</li>
  <li>Backup of users of one or more machines;</li>
  <li>Backup system config of much servers;</li>
  <li>Create a backup snapshot of the my laptop;</li>
  <li>Create a central server than backupping client and server;</li>
  <li>Backup a entire file server, incrementally;</li>
</ul>

<h2 id="real-possibilities">Real possibilities</h2>
<ul>
  <li>Configuration for silently or bulk backup</li>
  <li>All backup are organized into a catalog</li>
  <li>List single or all backup by the catalog</li>
  <li>List detail of a single backup</li>
  <li>Backup single PC, with Full,Incremental,Differential and Mirror mode;</li>
  <li>Backup more PCs, with Full,Incremental,Differential and Mirror mode (with parallelism algorithm);</li>
  <li>Backup custom folder or predefined data (User,Config,Application,System,Log): see <a href="https://butterfly-backup.readthedocs.io/en/latest/#backup">backup docs</a></li>
  <li>Restore backup on the same PC</li>
  <li>Restore backup in other PC</li>
  <li>Restore backup in other operating system</li>
  <li>Apply retention policy to delete old backup</li>
  <li>Archive old backup in other file system or same (zip backup folder)</li>
  <li>Export one backup to another file system</li>
</ul>


<p><strong>Transform rsync in a powerfully backup/restore/archive tool</strong></p>

<h2 id="operation">Operation</h2>
<p>All operation of Butterfly Backup are <em>server to client</em>, agent-less. The server must be Unix machine with latest rsync installed.
This means that all commands must be executed by the backup server. Of course, nothing prevents the backup server from being itself (localhost).</p>

<p>To see all the operations and more examples, see the <a href="https://butterfly-backup.readthedocs.io/en/latest/">docs</a>.</p>

<h2 id="test">Test</h2>
<p>If you want to try or test Butterfly Backup before installing it, run the test:</p>
<div><div><pre><code><span>$</span><span> </span>git clone https://github.com/MatteoGuadrini/Butterfly-Backup.git
<span>$</span><span> </span><span>cd </span>Butterfly-Backup
<span>$</span><span> </span>bash test_bb.py
<span>...
</span><span>[92512a6e-506e-11eb-b747-2ba55b805ea5]
type = Full
path = /tmp/bb_repo/localhost/2021_01_06__23_28
name = localhost
os = Unix
timestamp = 2021-01-06 23:28:59
start = 2021-01-06 23:28:59
end = 2021-01-06 23:29:04
status = 0
</span></code></pre></div></div>

<h2 id="installation">Installation</h2>
<p>Install Butterfly Backup is very simple; run this:</p>
<div><div><pre><code>git clone https://github.com/MatteoGuadrini/Butterfly-Backup.git
<span>cd </span>Butterfly-Backup
<span>sudo </span>python3 setup.py
bb <span>--help</span>
man bb
</code></pre></div></div>

<h3 id="backup-machine">Backup machine</h3>
<p>Backup a single PC or server is a everyday task.
But most of the data may not change in the various backups made;
then, in these cases, an incremental backup is needed.
Butterfly Backup natively supports incremental and differential backups, starting from a full.
In this case, the first backup to be performed on the machine will be as follows:</p>
<div><div><pre><code>bb backup <span>--computer</span> pc1 <span>--destination</span> /nas/mybackup <span>--data</span> User Config <span>--type</span> MacOS <span>--mode</span> Full
</code></pre></div></div>
<p>or with short option:</p>
<div><div><pre><code>bb backup <span>-c</span> pc1 <span>-d</span> /nas/mybackup <span>-D</span> User Config <span>-t</span> MacOS <span>-m</span> Full
</code></pre></div></div>
<p>So we created a first <em>Full</em> backup, on a <em>MacOS</em> machine, considering the folders <em>User</em> -&gt; /Users and <em>Config</em> -&gt; /private/etc in the destination <em>/nas/mybackup</em></p>
<blockquote>
  <p><strong>Note</strong>: if you do not specify the user, Butterfly Backup will assume that the source and the destination know the same user; for example, I start the backup with the above command and my user is calling <em>arthur</em>, he will use the latter to log in to pc1.</p>
</blockquote>

<p>Now that we have our first Full backup, we can run <em>incremental</em> for the next few times.</p>
<div><div><pre><code>bb backup <span>--computer</span> pc1 <span>--destination</span> /nas/mybackup <span>--data</span> User Config <span>--type</span> MacOS
</code></pre></div></div>
<p>or with short option:</p>
<div><div><pre><code>bb backup <span>-c</span> pc1 <span>-d</span> /nas/mybackup <span>-D</span> User Config <span>-t</span> MacOS
</code></pre></div></div>
<blockquote>
  <p><strong>Note</strong>: Incremental mode performs a Full backup when they have not been done before.</p>
</blockquote>

<h3 id="restore-machine">Restore machine</h3>
<p>Before starting any restore, you need to understand what kind of data and in what time period you have to start.
So, letâ€™s start checking our backups, with this command:</p>
<div><div><pre><code>bb list <span>--catalog</span> /nas/mybackup
</code></pre></div></div>
<p>The result will be the following:</p>
<div><div><pre><code>BUTTERFLY BACKUP CATALOG

Backup <span>id</span>: f65e5afe-9734-11e8-b0bb-005056a664e0
Hostname or ip: pc1
Timestamp: 2018-08-03 17:50:36

Backup <span>id</span>: 4f2b5f6e-9939-11e8-9ab6-005056a664e0
Hostname or ip: pc1
Timestamp: 2018-08-06 07:26:46

Backup <span>id</span>: cc6e2744-9944-11e8-b82a-005056a664e0
Hostname or ip: pc1
Timestamp: 2018-08-06 08:49:00
</code></pre></div></div>
<p>Select (copy) <em>Backup id</em> when you want restore a backup.
For exit, press <code>q</code>
Now, run this command for more detail (for example, try the first):</p>
<div><div><pre><code>bb list <span>--catalog</span> /nas/mybackup <span>--backup-id</span> f65e5afe-9734-11e8-b0bb-005056a664e0
</code></pre></div></div>
<p>The result will be the following:</p>
<div><div><pre><code>Backup <span>id</span>: f65e5afe-9734-11e8-b0bb-005056a664e0
Hostname or ip: pc1
Type: Full
Timestamp: 2018-08-03 17:50:36
Start: 2018-08-03 17:50:36
Finish: 2018-08-03 18:02:32
OS: MacOS
ExitCode: 0
Path: /nas/mybackup/pc1/2018_08_03__17_50
List: etc
Users
</code></pre></div></div>
<p>Now that we are sure that the selected backup is what we want (both in data and on date), run this command:</p>
<div><div><pre><code>bb restore <span>--computer</span> pc1 <span>--catalog</span> /nas/mybackup <span>--backup-id</span> f65e5afe-9734-11e8-b0bb-005056a664e0
</code></pre></div></div>
<p>So we have restored the data saved on the date indicated in our <em>pc1</em>.</p>

<h3 id="other-operation">Other operation</h3>
<p>With Butterfly Backup, you can perform Full, Incremental and Mirror backups, applying retention or archive rules;
you can activate the log function, so as to track any operation over time and/or increase verbosity.
Bulk backup operations can be performed using a simple text file, formatted in a list.
Is possible create, by means of openssh operations, a configuration and copy them into the machines impacted by the backup without causing the machine to request the password (key exchange).
For all this, <a href="https://butterfly-backup.readthedocs.io/en/latest/">Read the Docs</a> or run help:</p>




<h2 id="one-more-thing">One more thing</h2>
<p>The name butterfly, is born precisely because agent-less; like a butterfly takes the pollen from a flower and brings it elsewhere.
A backup or restore is performed without any iteration responsibility on the part of the final machine.
The performances are not altered.
While all the operations of Butterfly Backup are carried out, the impacted machine can continuously work with <em>peace of mind</em>.</p>

<h2 id="follow-the-project">Follow the project</h2>
<p>See the new features in development through this <a href="https://tree.taiga.io/project/matteoguadrini-butterfly-backup/kanban">link</a>.</p>

<h2 id="open-source">Open source</h2>
<p>Butterfly Backup is a open source project. Any contribute, Itâ€™s welcome.</p>

<p><strong>A great thanks</strong>.</p>

<p>For donations, press this</p>

<p>For me</p>

<p><a href="https://www.paypal.me/guos"><img src="https://www.paypalobjects.com/en_US/i/btn/btn_donateCC_LG.gif" alt="paypal"></a></p>

<p>For <a href="http://www.telethon.it/">Telethon</a></p>

<p>The Telethon Foundation is a non-profit organization recognized by the Ministry of University and Scientific and Technological Research.
They were born in 1990 to respond to the appeal of patients suffering from rare diseases.
Come today, we are organized to dare to listen to them and answers, every day of the year.</p>

<p><a href="https://www.telethon.it/sostienici/dona-ora"> <img src="https://www.telethon.it/dev/_nuxt/img/c6d474e.svg" alt="Telethon" title="Telethon" width="200" height="104"> </a></p>

<p><a href="https://www.ioadottoilfuturo.it/">Adopt the future</a></p>


      </section>
      
    </div></div>]]>
            </description>
            <link>https://matteoguadrini.github.io/Butterfly-Backup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26195250</guid>
            <pubDate>Fri, 19 Feb 2021 17:11:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Higher Kinded Types in Rust]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26195079">thread link</a>) | @ibraheemdev
<br/>
February 19, 2021 | https://rustyyato.github.io/type/system,type/families/2021/02/15/Type-Families-1.html | <a href="https://web.archive.org/web/*/https://rustyyato.github.io/type/system,type/families/2021/02/15/Type-Families-1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Do you want to use Higher Kinded Types (<code>HKT</code>) in Rust? Are you tired of waiting for <code>GAT</code>? Well, this is the place to be.</p>

<p>Itâ€™s easiest to understand <code>HKT</code> by analogy. In programming we have many different tiers of abstractions. Starting at the bottom we have <code>term</code>s (aka values) like <code>0</code>, <code>true</code>, <code>"hello world!"</code>. If we want to work with a lot of <code>term</code>s that share a property, we use <code>type</code>s. For example, if we want to work with â€¦</p>

<ul>
  <li>32-bit integer, we use <code>i32</code></li>
  <li>utf-8 strings, we use <code>&amp;str</code> or <code>String</code></li>
</ul>

<p>We generally use snake case to refer to <code>term</code>s generically like <code>x</code>, <code>im_an_integer</code>, and <code>database_connection</code>. We use functions to operate on these generic values.</p>

<div><div><pre><code><span>fn</span> <span>add_one</span><span>(</span>
    <span>// a generic 32-bit integer</span>
    <span>x</span><span>:</span> <span>i32</span>
<span>)</span> <span>-&gt;</span> <span>i32</span> <span>{</span> <span>x</span> <span>+</span> <span>1</span> <span>}</span>
</code></pre></div></div>

<p>Moving up the abstraction tiers, we come to <code>type</code>s. For example: <code>String</code>, <code>i32</code>, or <code>bool</code>. If we want to work with a lot of <code>type</code>s that share a property, we use <code>trait</code>s and generics. For example, if we want to work with â€¦</p>

<ul>
  <li>types that can be debug printed, we use <code>std::fmt::Debug</code></li>
  <li>types that can be iterated, we use <code>Iterator</code></li>
</ul>

<p>We generally use pascal case to refer to <code>types</code>s generically like <code>T</code>, <code>Self</code>, and <code>This</code>. We use generic functions to work with these generic types.</p>

<div><div><pre><code><span>fn</span> <span>print</span><span>&lt;</span><span>T</span><span>:</span> <span>Debug</span><span>&gt;</span><span>(</span><span>x</span><span>:</span> <span>T</span><span>)</span> <span>{</span>
    <span>println!</span><span>(</span><span>"{:?}"</span><span>,</span> <span>x</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>Moving up the abstraction tiers again, we come to <code>kind</code>s. For example: <code>Option</code>, <code>Result</code>, or <code>Vec</code>. Wait what. Letâ€™s take a step back. Before I mentioned that <code>String</code>, <code>i32</code>, and <code>bool</code> are types. We also have more types that we can use, generic types like <code>Option&lt;i32&gt;</code> or <code>Result&lt;String, String&gt;</code>. What if you want to generalize over these types? Something of the form <code>T&lt;U&gt;</code>. Thatâ€™s where we get to kinds. For example:</p>

<ul>
  <li><code>i32</code> has the kind <code>Type</code></li>
  <li><code>Option&lt;i32&gt;</code> has the kind <code>Type</code></li>
  <li><code>'a</code> has the kind <code>Lifetime</code></li>
  <li><code>Option</code> has the kind <code>Type -&gt; Type</code>
    <ul>
      <li>W H A T, letâ€™s stop and explain whatâ€™s going on here</li>
    </ul>
  </li>
</ul>

<p>Generic types can be represented as a function from kinds to kinds. For example, <code>Option</code> is a function that takes a <code>Type</code> and produces a <code>Type</code> (hence <code>Type -&gt; Type</code>). Letâ€™s see some more examples:</p>

<ul>
  <li><code>Result</code> has the kind <code>Type -&gt; Type -&gt; Type</code>
    <ul>
      <li>Iâ€™ll use this notation because thatâ€™s how itâ€™s done in the literature</li>
      <li>Note: this is equivalent to <code>(Type, Type) -&gt; Type</code> (you can always transform a function that take a tuple of arguments into one that takes multiple arguments, and vice versa)</li>
    </ul>
  </li>
  <li>references have a kind <code>Lifetime -&gt; Type -&gt; Type</code>
    <ul>
      <li><code>&amp;'a T</code>, one lifetime and one type parameter :)</li>
    </ul>
  </li>
  <li>arrays have the kind <code>Type -&gt; usize -&gt; Type</code>
    <ul>
      <li><code>[T; len]</code>, one type and one <code>usize</code> <code>term</code> (getting close to dependent types, something we wonâ€™t touch in this post)</li>
    </ul>
  </li>
</ul>

<p>With this notion of <code>kind</code>s we are now well equipped to generalize over generics. Just one cinch, <code>Rust</code> doesnâ€™t know about <code>kind</code>s! So how do we generalize over generics if we canâ€™t even express the fundamental building blocks.</p>



<p>The key insight is that we can represent <code>kind</code>s as a system of types and traits. For example, hereâ€™s how to handle <code>Type -&gt; Type</code> kinds.</p>

<p>Note: Iâ€™ll show how <code>Option</code> fits in, and introduce <code>Result&lt;_, E&gt;</code>, but Iâ€™ll leave the implementation of <code>Vec</code> to you. Itâ€™s an interesting puzzle if you are inclined</p>

<div><div><pre><code><span>// `Option` has the kind `Type -&gt; Type`,</span>
<span>// we'll represent it with `OptionFamily`</span>
<span>struct</span> <span>OptionFamily</span><span>;</span>
<span>// `Result` has the kind `Type -&gt; Type -&gt; Type`,</span>
<span>// so we fill in one of the types with a concrete one</span>
<span>struct</span> <span>ResultFamily</span><span>&lt;</span><span>E</span><span>&gt;</span><span>(</span><span>PhantomData</span><span>&lt;</span><span>E</span><span>&gt;</span><span>);</span>

<span>// I'll leave the implementation of `VecFamily` to you</span>

<span>// This trait represents the `kind` `Type -&gt; Type`</span>
<span>pub</span> <span>trait</span> <span>OneTypeParam</span><span>&lt;</span><span>A</span><span>&gt;</span> <span>{</span>
    <span>// This represents the output of the function `Type -&gt; Type`</span>
    <span>// for a specific argument `A`.</span>
    <span>type</span> <span>This</span><span>;</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>A</span><span>&gt;</span> <span>OneTypeParam</span><span>&lt;</span><span>A</span><span>&gt;</span> <span>for</span> <span>OptionFamily</span> <span>{</span>
    <span>// `OptionFamily` represents `Type -&gt; Type`,</span>
    <span>// so filling in the first argument means</span>
    <span>// `Option&lt;A&gt;`</span>
    <span>type</span> <span>This</span> <span>=</span> <span>Option</span><span>&lt;</span><span>A</span><span>&gt;</span><span>;</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>A</span><span>,</span> <span>E</span><span>&gt;</span> <span>OneTypeParam</span><span>&lt;</span><span>A</span><span>&gt;</span> <span>for</span> <span>ResultFamily</span><span>&lt;</span><span>E</span><span>&gt;</span> <span>{</span>
    <span>// note how all results in this family have `E` as the error type</span>
    <span>// This is similar to how currying works in functional languages</span>
    <span>type</span> <span>This</span> <span>=</span> <span>Result</span><span>&lt;</span><span>A</span><span>,</span> <span>E</span><span>&gt;</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Note how a <code>trait</code> can act as a function over types, so you can encode the idea <code>Type -&gt; Type</code> using a trait!</p>

<p>Letâ€™s also introduce a type alias for ease of use.</p>

<div><div><pre><code><span>// Option&lt;A&gt; == This&lt;OptionFamily, A&gt;</span>
<span>pub</span> <span>type</span> <span>This</span><span>&lt;</span><span>T</span><span>,</span> <span>A</span><span>&gt;</span> <span>=</span> <span>&lt;</span><span>T</span> <span>as</span> <span>OneTypeParam</span><span>&lt;</span><span>A</span><span>&gt;&gt;</span><span>::</span><span>This</span><span>;</span>
</code></pre></div></div>

<p>Now we can replace all usage of <code>Option</code>, <code>Result&lt;_, E&gt;</code> with <code>OptionFamily</code> or <code>ResultFamily&lt;E&gt;</code>! From this we can build up abstractions that â€œrequireâ€ HKT. Letâ€™s start with the simplest abstraction <code>Functor</code>. This is just any <code>Type -&gt; Type</code> that has a notion of mapping a value. Generally <code>Functor</code> represents a collection, but it can do much more than that (But I wonâ€™t dive into <code>Functor</code> in particular in this post).</p>

<div><div><pre><code><span>trait</span> <span>Functor</span><span>&lt;</span><span>A</span><span>,</span> <span>B</span><span>&gt;</span><span>:</span> <span>OneTypeParam</span><span>&lt;</span><span>A</span><span>&gt;</span> <span>+</span> <span>OneTypeParam</span><span>&lt;</span><span>B</span><span>&gt;</span> <span>{</span>
    <span>fn</span> <span>map</span><span>&lt;</span><span>F</span><span>&gt;</span><span>(</span><span>self</span><span>,</span> <span>this</span><span>:</span> <span>This</span><span>&lt;</span><span>Self</span><span>,</span> <span>A</span><span>&gt;</span><span>,</span> <span>f</span><span>:</span> <span>F</span><span>)</span> <span>-&gt;</span> <span>This</span><span>&lt;</span><span>Self</span><span>,</span> <span>B</span><span>&gt;</span>
    <span>where</span>
        <span>F</span><span>:</span> <span>Fn</span><span>(</span><span>A</span><span>)</span> <span>-&gt;</span> <span>B</span> <span>+</span> <span>Copy</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>This is quite a lot, so letâ€™s soak it in.</p>

<div><div><pre><code><span>OneTypeParam</span><span>&lt;</span><span>A</span><span>&gt;</span> <span>+</span> <span>OneTypeParam</span><span>&lt;</span><span>B</span><span>&gt;</span>
</code></pre></div></div>

<p>First, we require that our families can be used with either type. This allows you to restrict the families in some ways, for example for <code>HashSet</code>, only allow <code>T: Hash + Eq</code>. <code>A</code> will be the input type, and <code>B</code> will be the output type.</p>

<div><div><pre><code><span>fn</span> <span>map</span><span>&lt;</span><span>F</span><span>&gt;</span><span>(</span><span>self</span><span>,</span> <span>this</span><span>:</span> <span>This</span><span>&lt;</span><span>Self</span><span>,</span> <span>A</span><span>&gt;</span><span>,</span> <span>f</span><span>:</span> <span>F</span><span>)</span> <span>-&gt;</span> <span>This</span><span>&lt;</span><span>Self</span><span>,</span> <span>B</span><span>&gt;</span>
<span>where</span>
    <span>F</span><span>:</span> <span>Fn</span><span>(</span><span>A</span><span>)</span> <span>-&gt;</span> <span>B</span> <span>+</span> <span>Copy</span><span>;</span>
</code></pre></div></div>

<p>Next we have this monstrous function! This will be easier to explain if we have a concrete family.</p>

<div><div><pre><code><span>/// for `OptionFamily`</span>
<span>fn</span> <span>map</span><span>&lt;</span><span>F</span><span>&gt;</span><span>(</span><span>self</span><span>,</span> <span>this</span><span>:</span> <span>Option</span><span>&lt;</span><span>A</span><span>&gt;</span><span>,</span> <span>f</span><span>:</span> <span>F</span><span>)</span> <span>-&gt;</span> <span>Option</span><span>&lt;</span><span>B</span><span>&gt;</span>
<span>where</span>
    <span>F</span><span>:</span> <span>Fn</span><span>(</span><span>A</span><span>)</span> <span>-&gt;</span> <span>B</span> <span>+</span> <span>Copy</span><span>;</span>
</code></pre></div></div>

<p>So this is just the same as the ordinary map in <code>Option</code>, except it requires <code>Fn</code>, instead of <code>FnOnce</code>. We could generalize over <code>Fn</code> and <code>FnOnce</code> if Rust had associated traits, but alas we donâ€™t, so weâ€™ll have to make do with <code>Fn</code> (Iâ€™ll leave it to you to figure out a nice way to abstract over <code>Fn</code>, <code>FnMut</code> and <code>FnOnce</code>). All weâ€™ve done is generalize it to <em>any</em> family, not just <code>Option</code>.</p>

<p>The <code>Copy</code> bound is nice for things like <code>Vec</code> where you need to apply the function multiple times. You can convert any <code>Fn</code> to a <code>Fn + Copy</code> because <code>&amp;_</code> implement <code>Fn</code> and are <code>Copy</code>.</p>

<p>So all together again:</p>

<div><div><pre><code><span>trait</span> <span>Functor</span><span>&lt;</span><span>A</span><span>,</span> <span>B</span><span>&gt;</span><span>:</span> <span>OneTypeParam</span><span>&lt;</span><span>A</span><span>&gt;</span> <span>+</span> <span>OneTypeParam</span><span>&lt;</span><span>B</span><span>&gt;</span> <span>{</span>
    <span>fn</span> <span>map</span><span>&lt;</span><span>F</span><span>&gt;</span><span>(</span><span>self</span><span>,</span> <span>this</span><span>:</span> <span>This</span><span>&lt;</span><span>Self</span><span>,</span> <span>A</span><span>&gt;</span><span>,</span> <span>f</span><span>:</span> <span>F</span><span>)</span> <span>-&gt;</span> <span>This</span><span>&lt;</span><span>Self</span><span>,</span> <span>B</span><span>&gt;</span>
    <span>where</span>
        <span>F</span><span>:</span> <span>Fn</span><span>(</span><span>A</span><span>)</span> <span>-&gt;</span> <span>B</span> <span>+</span> <span>Copy</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p><code>Functor</code> just specifies a mapping operation. We can implement this rather easily.</p>

<div><div><pre><code><span>impl</span><span>&lt;</span><span>A</span><span>,</span> <span>B</span><span>&gt;</span> <span>Functor</span><span>&lt;</span><span>A</span><span>,</span> <span>B</span><span>&gt;</span> <span>for</span> <span>OptionFamily</span> <span>{</span>
    <span>fn</span> <span>map</span><span>&lt;</span><span>F</span><span>&gt;</span><span>(</span><span>self</span><span>,</span> <span>this</span><span>:</span> <span>This</span><span>&lt;</span><span>Self</span><span>,</span> <span>A</span><span>&gt;</span><span>,</span> <span>f</span><span>:</span> <span>F</span><span>)</span> <span>-&gt;</span> <span>This</span><span>&lt;</span><span>Self</span><span>,</span> <span>B</span><span>&gt;</span>
    <span>where</span>
        <span>F</span><span>:</span> <span>Fn</span><span>(</span><span>A</span><span>)</span> <span>-&gt;</span> <span>B</span> <span>+</span> <span>Copy</span> <span>{</span>
        <span>// I'm not cheating!</span>
        <span>this</span><span>.map</span><span>(</span><span>f</span><span>)</span>
    <span>}</span>
<span>}</span>

<span>// try out `VecFamily`, it doesn't need to be optimal, it just needs to work!</span>
</code></pre></div></div>

<p>Ok, but thatâ€™s boring, I hear you say. What about <code>Monad</code>? Typically itâ€™s defined by itâ€™s <code>bind</code> operation (Weâ€™ll skip <code>Applicative</code> here, try it out yourself!). Iâ€™m not going to explain how <code>Monad</code> works, or why you would want it, just how to implement it.</p>

<div><div><pre><code><span>trait</span> <span>Monad</span><span>&lt;</span><span>A</span><span>,</span> <span>B</span><span>&gt;</span><span>:</span> <span>Functor</span><span>&lt;</span><span>A</span><span>,</span> <span>B</span><span>&gt;</span> <span>{</span>
    <span>fn</span> <span>bind</span><span>&lt;</span><span>F</span><span>&gt;</span><span>(</span><span>self</span><span>,</span> <span>a</span><span>:</span> <span>This</span><span>&lt;</span><span>Self</span><span>,</span> <span>A</span><span>&gt;</span><span>,</span> <span>f</span><span>:</span> <span>F</span><span>)</span> <span>-&gt;</span> <span>This</span><span>&lt;</span><span>Self</span><span>,</span> <span>B</span><span>&gt;</span>
    <span>where</span>
        <span>F</span><span>:</span> <span>Fn</span><span>(</span><span>A</span><span>)</span> <span>-&gt;</span> <span>This</span><span>&lt;</span><span>Self</span><span>,</span> <span>B</span><span>&gt;</span> <span>+</span> <span>Copy</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Looks the same as <code>Functor</code> to me! â€¦ Wait, the bound on <code>F</code> looks funky. Letâ€™s dig in to the <code>OptionFamily</code> implementation again, maybe that will clear things up.</p>

<div><div><pre><code><span>/// for `OptionFamily`</span>
<span>fn</span> <span>bind</span><span>&lt;</span><span>F</span><span>&gt;</span><span>(</span><span>self</span><span>,</span> <span>a</span><span>:</span> <span>Option</span><span>&lt;</span><span>A</span><span>&gt;</span><span>,</span> <span>f</span><span>:</span> <span>F</span><span>)</span> <span>-&gt;</span> <span>Option</span><span>&lt;</span><span>B</span><span>&gt;</span>
<span>where</span>
    <span>F</span><span>:</span> <span>Fn</span><span>(</span><span>A</span><span>)</span> <span>-&gt;</span> <span>Option</span><span>&lt;</span><span>B</span><span>&gt;</span> <span>+</span> <span>Copy</span><span>;</span>
</code></pre></div></div>

<p>This looks very familiar, â€¦ where have I seen this before? <code>Option::and_then</code> is that you?</p>

<div><div><pre><code><span>impl</span><span>&lt;</span><span>A</span><span>,</span> <span>B</span><span>&gt;</span> <span>Monad</span><span>&lt;</span><span>A</span><span>,</span> <span>B</span><span>&gt;</span> <span>for</span> <span>OptionFamily</span> <span>{</span>
    <span>fn</span> <span>bind</span><span>&lt;</span><span>F</span><span>&gt;</span><span>(</span><span>self</span><span>,</span> <span>this</span><span>:</span> <span>This</span><span>&lt;</span><span>Self</span><span>,</span> <span>A</span><span>&gt;</span><span>,</span> <span>f</span><span>:</span> <span>F</span><span>)</span> <span>-&gt;</span> <span>This</span><span>&lt;</span><span>Self</span><span>,</span> <span>B</span><span>&gt;</span>
    <span>where</span>
        <span>F</span><span>:</span> <span>Fn</span><span>(</span><span>A</span><span>)</span> <span>-&gt;</span> <span>This</span><span>&lt;</span><span>Self</span><span>,</span> <span>B</span><span>&gt;</span> <span>+</span> <span>Copy</span> <span>{</span>
        <span>// It fits ğŸ˜‰</span>
        <span>this</span><span>.and_then</span><span>(</span><span>f</span><span>)</span>
    <span>}</span>
<span>}</span>

<span>// try out `VecFamily`, it doesn't need to be optimal, it just needs to work!</span>
</code></pre></div></div>

<p>In this way you can implement most, if not all <code>HKT</code> abstractions in stable Rust. However the ergonomics of these abstractions are downright abysmal. Bounds, bounds, bounds <em>everywhere</em>. We saw this a little in <code>Functor&lt;A, B&gt;</code>, we needed <code>OneTypeParam&lt;A&gt; + OneTypeParam&lt;B&gt;</code> (why does family need to be repeated!). Hopefully we can solve this on nightly, find out next time â€¦</p>

<p>If you canâ€™t wait and must know more, check out <a href="https://github.com/rustyyato/type-families"><code>type-families</code></a>, an experimental crate that implements the ideas outlined in this blog post.</p>

<p>You can discuss this on reddit <a href="https://www.reddit.com/r/rust/comments/ll9un4/generalizing_over_generics_in_rust_part_1_aka/">here</a> or the users.rust-lang.org <a href="https://users.rust-lang.org/t/generalizing-over-generics-in-rust-part-1-aka-higher-kinded-types-in-rust/55716/2">here</a></p>

<p>Credits:</p>

<p>Thanks /u/CalligrapherMinute77 for requesting this post
Thanks /u/IshKebab for helping me reword the introduction to make things more clear</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://rustyyato.github.io/type/system,type/families/2021/02/15/Type-Families-1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26195079</guid>
            <pubDate>Fri, 19 Feb 2021 16:56:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Serverless browser automation with AWS Lambda and Puppeteer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26195005">thread link</a>) | @EntICOnc
<br/>
February 19, 2021 | https://acloudguru.com/blog/engineering/serverless-browser-automation-with-aws-lambda-and-puppeteer | <a href="https://web.archive.org/web/*/https://acloudguru.com/blog/engineering/serverless-browser-automation-with-aws-lambda-and-puppeteer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="8a920a5" data-element_type="widget" data-widget_type="theme-post-content.default"><div><p>Manipulating a web browser environment with an API provides a wide range of automation capabilities for developers. It allows you to generate PDF files, screenshot webpages, or run health checks on a website, all from code. It can also enable you to automate form submissions, build UI tests, or diagnose performance issues. <a href="https://chromium.googlesource.com/chromium/src/+/lkgr/headless/README.md">Headless Chromium</a> is a popular package for operating a browser programmatically. Whether you are load testing a website or periodically fetching content, this can be configured with minimal code.&nbsp;</p><p>You can run a headless browser on your local development machine or a remote server. However, many typical browser automation tasks are a good fit for <a href="https://aws.amazon.com/lambda/">AWS Lambda</a>. You can configure a Lambda function to start on a schedule, or in response to an event. You can also configure Lambda to scale up for load testing operations, making it a cost effective alternative to managing a fleet of instances.</p><p>In this blog post, I show how you can deploy a browser automation task to Lambda. This example uses the <a href="https://aws.amazon.com/serverless/sam/">AWS Serverless Application Model</a> (AWS SAM) to simplify the deployment of cloud resources. You can download the code for this blog post from the companion <a href="https://github.com/aws-samples/scheduled-website-screenshot-app">GitHub repository</a>. To deploy to your AWS account, follow the instructions in the <a href="https://github.com/aws-samples/scheduled-website-screenshot-app/blob/main/README.md">README file</a>.</p><h2 id="h-overview">Overview</h2><p>In the example application, a Lambda function is invoked every 15 minutes to take a screenshot of a webpage and save the image to an S3 bucket. The architecture looks like this:</p><figure><img loading="lazy" width="622" height="272" src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/02/image001.png" alt="" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/02/image001.png 622w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/02/image001.png 300w" sizes="(max-width: 622px) 100vw, 622px"></figure><ol><li>An <a href="https://aws.amazon.com/eventbridge/">Amazon EventBridge</a> rule invokes the Lambda function using a <a href="https://docs.aws.amazon.com/eventbridge/latest/userguide/scheduled-events.html">schedule expression</a>.</li><li>The Lambda function uses Chromium to load the target webpage. Once the page is loaded and rendered, it takes a screenshot.</li><li>The screenshot is saved to an <a href="https://aws.amazon.com/s3/">Amazon S3</a> bucket.</li></ol><h2 id="h-how-the-code-works">How the code works</h2><p>This Node.js example uses an npm package called <a href="https://github.com/puppeteer/puppeteer">Puppeteer</a>, which exposes a high-level API to control the Chromium browser. A snippet of the <a href="https://github.com/aws-samples/scheduled-website-screenshot-app/blob/main/src/app.js">Lambda function</a> shows how this works:</p><div><div><div><div><pre>browser = await chromium.puppeteer.launch({
 &nbsp; &nbsp; args: chromium.args,
     defaultViewport: chromium.defaultViewport,
 &nbsp;   executablePath: await chromium.executablePath,
     headless: chromium.headless,
     ignoreHTTPSErrors: true,
});

let page = await browser.newPage()
await page.goto(pageURL)
const buffer = await page.screenshot()</pre></div></div></div></div><p>This uses JavaScript <a href="https://developer.mozilla.org/en-US/docs/Learn/JavaScript/Asynchronous/Async_await">async/await</a> syntax to avoid callbacks and use sequential code flow. Once the browser object is defined, the code instructs Chromium (via Puppeteer) to fetch the webpage. After the page is loaded and the <a href="https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model/Introduction">DOM</a> is rendered in the headless Chromium instance, it stores a screenshot of the page in a buffer variable. Finally, the image is written to the S3 bucket:</p><pre>const&nbsp;s3result&nbsp;=&nbsp;await&nbsp;s3
 &nbsp;&nbsp;.upload({
 &nbsp;&nbsp;   Bucket:&nbsp;process.env.S3_BUCKET,
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Key:&nbsp;`${Date.now()}.png`,
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Body:&nbsp;buffer,
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ContentType:&nbsp;'image/png',
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ACL:&nbsp;'public-read'
 &nbsp;&nbsp;&nbsp;})
 &nbsp;&nbsp;&nbsp;.promise()

console.log('S3 image URL:', s3result.Location) </pre><p>This uses the <a href="https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/S3.html#upload-property">S3 upload method</a> in the <a href="https://aws.amazon.com/sdk-for-javascript/">AWS SDK for JavaScript</a>. It defines the bucket and key, sets the content type to PNG, and then configures the access control list (ACL) so the object is publicly viewable. Finally, it logs the public URL of the stored object.</p><h2 id="h-packaging-puppeteer-for-the-lambda-function">Packaging Puppeteer for the Lambda function</h2><p>Lambda allows you to package dependencies together with your code as a zip file. The deployment package can be up to <a href="https://docs.aws.amazon.com/lambda/latest/dg/gettingstarted-limits.html">250 MB (unzipped)</a> or 50 MB (zipped, for direct upload). For larger packages, itâ€™s recommended that you use the new <a href="https://acloudguru.com/blog/engineering/packaging-aws-lambda-functions-as-container-images">container packaging format</a> for Lambda functions, which allows packages of up to 10 GB.&nbsp;</p><p>If you use a tool like AWS SAM or <a href="https://www.serverless.com/">Serverless framework</a>, the packages are created on your development machine, then zipped and uploaded to the Lambda service. At runtime, these files are unzipped in the Lambda execution environment when the function is run. These tools can simplify this packaging process and help streamline your deployments.</p><p>However, when you use a dependency that contains a binary, you must ensure that you package a version of the binary that is compatible with the operating system used by Lambda. The Puppeteer package contains an entire Chromium browser bundled into the deployment. Since the browser relies on binaries, npm installs the binary that matches the operating system of your local development machine. However, Lambda requires the binary that matches its underlying operating system, which is Amazon Linux 2.</p><p>To help with this, many popular packages have been converted into <a href="https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html">Lambda layers</a> by the community. You can define up to five layers per Lambda function and these are copied into your deployment package when you create or update a function. For Chromium, this makes it easier to run one binary version in development and use another binary version at runtime. Learn more about <a href="https://aws.amazon.com/blogs/compute/using-lambda-layers-to-simplify-your-development-process/">creating and using Lambda layers</a> to simplify your development process.</p><h2 id="h-using-a-community-maintained-lambda-layer">Using a community-maintained Lambda layer</h2><p>One developer has packaged a <a href="https://github.com/alixaxel/chrome-aws-lambda">Chromium binary for AWS Lambda</a> and published this to GitHub. You can install this with Puppeteer in your Lambda function by including the libraries in package.json. You can also bundle both with an existing public Lambda layer. <a href="https://github.com/shelfio/chrome-aws-lambda-layer">This GitHub repo</a> frequently publishes new versions of the <em>chrome-aws-lambda</em> package, which you can include directly in your Lambda function.</p><p>Layers are only available in the AWS Region where they are published. The maintainers of this public repo have published this layer to 16 Regions and provided layer ARNs in the <a href="https://github.com/shelfio/chrome-aws-lambda-layer/blob/master/readme.md">README file</a>. These ARNs are public and you can include in any Lambda function in those Regions in any AWS account.&nbsp;</p><p>These are many popular libraries that have been bundled into Lambda layers by the community. <a href="https://github.com/mthenw/awesome-layers">This GitHub repo</a> aggregates layers for commonly used utilities like GeoIP, MySQL, OpenSSL, Pandas, scikit-learn, and many others. To use these in your Lambda functions from a compatible runtime, you only need to include the layer ARN in a supported Region.</p><h2 id="h-understanding-the-aws-sam-template">Understanding the AWS SAM template</h2><p>The Lambda function in this example could have been defined directly in the AWS Management Console. However, by using AWS SAM, you can define the same infrastructure as code. This helps create repeatable deployments quickly and reduces human error from clicking around the console.</p><p>The <a href="https://github.com/aws-samples/scheduled-website-screenshot-app/blob/main/template.yaml">AWS SAM template</a> defines all the AW resources used by the application. First, it declares an S3 bucket:</p><pre>&nbsp; S3Bucket:
    Type: AWS::S3::Bucket &nbsp;</pre><p>Next, the template defines the Lambda function and where the code can be found. Since it runs an entire browser within the function, the memory is set to 4096 MB. The timeout is configured to 15 seconds to ensure that the function ends if the target webpage is unresponsive.&nbsp;</p><pre>SnapshotFunction:
 &nbsp; &nbsp; Type: AWS::Serverless::Function
 &nbsp; &nbsp; Description: Invoked by EventBridge scheduled rule
 &nbsp; &nbsp; Properties:
 &nbsp; &nbsp; &nbsp; CodeUri: src/
 &nbsp; &nbsp; &nbsp; Handler: app.handler
 &nbsp; &nbsp; &nbsp; Runtime: nodejs12.x
 &nbsp; &nbsp; &nbsp; Timeout: 15
 &nbsp; &nbsp; &nbsp; MemorySize: 4096 </pre><p>The template includes a reference to the publicly available Chromium layer and substitutes the Region code at deployment time. Providing that the example is deployed in one of those 16 Regions where the layer is available, the layer ARN is valid:</p><pre>Layers:
  - !Sub 'arn:aws:lambda:${AWS::Region}:764866452798:layer:chrome-aws-lambda:22'</pre><p>Environment variables are used to set the target website URL and define the bucket name to store the image. Finally, since the function only writes data to S3, it uses an AWS SAM <a href="https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-policy-templates.html">policy template</a> to provide write permissions to the single bucket. This follows the <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html#grant-least-privilege">principle of least privilege</a>:</p><pre>Environment:
 &nbsp;Variables:
 &nbsp; TARGET_URL: 'https://serverlessland.com'
 &nbsp; S3_BUCKET: !Ref S3Bucket
 Policies:
 &nbsp; - S3WritePolicy:
 &nbsp; &nbsp; &nbsp; BucketName: !Ref S3Bucket </pre><p>Lambda functions are invoked in response to events. In this case, the function runs at a timed interval, which is managed by EventBridge. Using a schedule expression, the template configures the function to run every 15 minutes:</p><pre>Events:
 &nbsp;CheckWebsiteScheduledEvent:
 &nbsp; &nbsp;Type: Schedule
 &nbsp; &nbsp;Properties:
 &nbsp; &nbsp; &nbsp;Schedule: rate(15 minutes) </pre><p>Anytime you make changes to the Lambda function or the resource in this template, run <em>sam deploy</em> again to deploy the new version to the AWS Cloud. The AWS SAM CLI detects the differences between versions and deploys the new code and resources automatically.&nbsp;</p><h2 id="h-testing-the-function">Testing the function</h2><p>After deployment the example application, navigate to the <a href="https://console.aws.amazon.com/lambda/home">Lambda console</a>. Open <em>SnapshotFunction</em> deployed by AWS SAM. The function is invoked automatically every 15 minutes but you can trigger the function by choosing <em>Test</em>:</p><figure><img loading="lazy" width="1008" height="1001" src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/02/image002.png" alt="" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/02/image002.png 1008w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/02/image002.png 300w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/02/image002.png 150w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/02/image002.png 768w" sizes="(max-width: 1008px) 100vw, 1008px"></figure><p>The <em>Log output</em> contains details of the function duration and the public URL of the image that is generated and stored in the S3 bucket. Navigate to this URL in a browser to view the screenshot:</p><figure><img loading="lazy" width="874" height="542" src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/02/image004.png" alt="" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/02/image004.png 874w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/02/image004.png 300w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/02/image004.png 768w" sizes="(max-width: 874px) 100vw, 874px"></figure><p>After the function has been deployed for a few hours, it has been invoked multiple times by the scheduled event. You can monitor its performance using <a href="https://aws.amazon.com/cloudwatch/">Amazon CloudWatch</a> metric. From the Lambda function, choose <em>Monitoring</em> to see the number of invocations, average duration, and any errors:</p><figure><img loading="lazy" width="1122" height="790" src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/02/image006.png" alt="" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/02/image006.png 1122w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/02/image006.png 300w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/02/image006.png 1024w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/02/image006.png 768w" sizes="(max-width: 1122px) 100vw, 1122px"></figure><p>From the <a href="https://s3.console.aws.amazon.com/s3/buckets/">S3 console</a>, open the S3 bucket created by the AWS SAM deployment to see the date-stamped objects created by each Lambda invocation:</p><figure><img loading="lazy" width="985" height="686" src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/02/image008.png" alt="" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/02/image008.png 985w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/02/image008.png 300w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/02/image008.png 768w" sizes="(max-width: 985px) 100vw, 985px"></figure><h2 id="h-conclusion">Conclusion</h2><p>Programmatically controlling a web browser enables you to automate many useful tasks with code. For many of these, you can use Lambda to minimize infrastructure overhead and simplify scaling. This blog post shows how to deploy an example application that uses a headless browser to take periodic screenshots of a webpage.</p><p>For commonly used libraries or packages with operating-system specific binaries, Lambda layers can help simplify deployment. Many libraries have publicly maintained layers you can include in your Lambda functions. With infrastructure as code tools like AWS SAM, you can define your code and layers together in YAML, to help create repeatable deployments and accelerate development.</p><p>For more serverless learning resources, visit <a href="https://serverlessland.com/">Serverless Land</a>.</p></div></div></div>]]>
            </description>
            <link>https://acloudguru.com/blog/engineering/serverless-browser-automation-with-aws-lambda-and-puppeteer</link>
            <guid isPermaLink="false">hacker-news-small-sites-26195005</guid>
            <pubDate>Fri, 19 Feb 2021 16:50:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What on Earth is this Encryption Scheme?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26194999">thread link</a>) | @LinuxBender
<br/>
February 19, 2021 | https://capnfabs.net/posts/wtf-encryption-scheme-synology-diskstation-nas/ | <a href="https://web.archive.org/web/*/https://capnfabs.net/posts/wtf-encryption-scheme-synology-diskstation-nas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody" id="content"><p>I have taken a couple terabytes of photos over the years, and have a mild phobia of deleting data, so I keep my photos on a <a href="https://www.synology.com/en-global">Synology DiskStation NAS</a>. Iâ€™ve got all the files on the thing:</p><ul><li>backed up to the cloud</li><li>encrypted,</li></ul><p>because back in 2016, my <a href="https://www.instagram.com/p/BMpgY9zAGbD/">apartment was broken into and thieves took all the electronics</a>. Iâ€™ve been slightly paranoid ever since.</p><p>The Synology NAS generally works pretty well, but the interface for decrypting a drive after booting is <em>extremely</em> painful. Itâ€™s about 10 clicks, a username, two different passwords, and a UI that is kinda wonky (itâ€™s a desktop in a web browser)? Hereâ€™s a screengrab:</p><figure><video alt="Unlocking an encrypted drive in the Synology DiskStation UI" src="https://capnfabs.net/posts/wtf-encryption-scheme-synology-diskstation-nas/decrypt.mp4" width="588" muted="" autoplay="" loop="" playsinline=""></video><figcaption><p>22 seconds is my personal speed record.</p></figcaption></figure><p>There are alternative solutions to this â€“ you can set it up so that it <a href="https://www.synology.com/en-au/knowledgebase/DSM/tutorial/File_Sharing/How_to_encrypt_and_decrypt_shared_folders_on_my_Synology_NAS#t4_1">reads the encryption key from a USB disk on startup, for example</a> â€“ but, if Iâ€™m worried about the whole thing being stolen, itâ€™s not a good idea to leave the encryption keys plugged into the thing, and itâ€™s also not a nice UX to find and plug in a USB before turning the thing on.</p><p>Thisâ€¦ seems kinda silly to me, and something that should be solvable with âœ¨ <em>technology</em> âœ¨. Iâ€™m only ever accessing this from one computer, for example, and every modern operating system has a good credential storage system (think <a href="https://support.apple.com/guide/keychain-access/what-is-keychain-access-kyca1083/mac"><em>Keychain Access</em></a> on OSX or <a href="https://support.microsoft.com/en-us/windows/accessing-credential-manager-1b5c916a-6a16-889f-8581-fc16e8165ac0"><em>Credential Manager</em></a> on Windows 10). So, maybe my computer could take care of supplying encryption keys to the DiskStation!</p><p>I went looking for options, and discovered that the DiskStation Software has a <a href="https://global.download.synology.com/download/Document/Software/DeveloperGuide/Package/FileStation/All/enu/Synology_File_Station_API_Guide.pdf">publicly-documented web API (pdf)</a>. At least, a <em>mostly</em> publicly documented web API â€“ thereâ€™s no documentation for the methods to mount and unmount encrypted shares.</p><p>That web API is <em>also</em> used by the desktop software though! So it should theoretically be possible to use <a href="https://developer.mozilla.org/en-US/docs/Learn/Common_questions/What_are_browser_developer_tools">browser devtools</a> to see exactly <em>what</em> is being sent to the DiskStation. ğŸ¤”</p><p>So, I clicked on all the right things in the Web UI, got to the bit where you type in the password, opened the devtools to the â€œNetwork Requestsâ€ tab, typed in <code>abc123</code> as my password, hit â€œsendâ€ and then watched for the requests:</p><figure><img src="https://capnfabs.net/posts/wtf-encryption-scheme-synology-diskstation-nas/encryption-dot-cgi.png" alt="Firefox devtools screenshot, showing a request to an ominously-named 'encryption.cgi'"><figcaption><p>hmmmmmmmmmmm</p></figcaption></figure><p>Hmmm, that <code>encryption.cgi</code> looks a little ominous. I wonder whatâ€™s in it?</p><figure><img src="https://capnfabs.net/posts/wtf-encryption-scheme-synology-diskstation-nas/public-key.png" alt="Firefox devtools screenshot, showing huge blob of base16-encoded public-key"><figcaption><p>Yep, looks like encryption, alright</p></figcaption></figure><p>Ok, a public key. And then the web interface loads a spinner, and makes a request to <code>entry.cgi</code>. Letâ€™s take a look at the contents of that request:</p><figure><img src="https://capnfabs.net/posts/wtf-encryption-scheme-synology-diskstation-nas/ciphertext.png" alt="A devtools screenshot, showing a jumbled blob of base64-encoded data with the phrases 'rsa' and 'aes' sprinkled throughout."><figcaption><p>HMMMMMMMMMMMMMMMM</p></figcaption></figure><p>Ok, so if we want to send a magic request to mount the encrypted share, itâ€™s not going to be enough to supply the encryption password; weâ€™re also going to need to figure out how to <em>correctly</em> supply it â€“ how to <em>encrypt</em> the encryption password, so to speak.</p><h2 id="so-what-is-this-crypto-system">So, what is this crypto system?</h2><p>Right. Hereâ€™s a high-level overview:</p><ul><li>First, we fetch the <code>public_key</code> from the server. Thatâ€™s the call to the <code>encryption.cgi</code> endpoint we saw earlier. This isnâ€™t actually the entire public key, itâ€™s only <em>part</em> of it. In fact, this is a 4096-bit integer, encoded in base-16. The <em>other</em> part of the public key is the number <code>0x10001 == 65537</code>, which is hardcoded into the JavaScript.</li><li>Then, we generate 501 bytes worth of random text from the charset <code>0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ~!@#$%^&amp;*()_+-/</code> (thatâ€™s 77 different possible characters; I have no idea why this set was chosen though!).</li><li>We encrypt that random text using our public key. The encryption method is <a href="https://tools.ietf.org/html/rfc3447#section-7.2">RSA with PKCS1.5 padding</a>.</li><li>We MD5-hash that random text a bunch of times with an 8-byte salt. The end result of this is 48 bytes which certainly <em>look</em> pretty random to the naked eye.</li><li>We split those 48 bytes into two components â€“ a 32-byte (== 256-bit) key, and a 16-byte initialisation vector.</li><li>Remember the password we typed in? Yeah, Iâ€™d forgotten about it too! But now, we <em>finally</em> take that password, and encrypt it with AES in Cipher Block Chaining (CBC) mode with PKCSv7 padding, using the 256-bit key and 16-byte IV we derived in the previous step.</li><li>We bundle the RSA ciphertext, the 8-byte salt, and the AES ciphertext together and ship them across to the DiskStation.</li></ul><p>Still with me? Itâ€™s ok if that didnâ€™t all make loads of sense yet; weâ€™ll now go over the interesting bits more closely.</p><h3 id="symmetric--asymmetric-ciphers">Symmetric / Asymmetric Ciphers</h3><p>Fundamentally, weâ€™re using two cryptographic algorithms in concert:</p><ul><li><strong>RSA</strong>: RSA is an <em>asymmetric</em> cryptographic algorithm. Asymmetric cryptographic systems have two <em>keys</em> â€“ a public key, which allows only for encryption of the data, and a private key, which allows for both encryption <em>and</em> decryption.</li><li><strong>AES</strong>: AES is a <em>symmetric</em> cryptographic algorithm. In symmetric cryptography, all parties have the same key, and that key allows you to both encrypt and decrypt.</li></ul><p>It seems weird that weâ€™re using both of these at the same time, right? But both systems have weaknesses, and mixing them together is an attempt at minimising the disadvantages of both schemes.</p><p>The problem with <em>symmetric</em> crypto systems by themselves is that you need a way to get that one key to every party that needs it. But you canâ€™t just <em>send</em> it to them, because you donâ€™t have a secure channel yet! Your options are:</p><ul><li>Share the key over a different trusted channel beforehand, or</li><li>have both parties derive the same shared key (from e.g. some partial data that they negotiate over the wire beforehand).</li></ul><p>Asymmetric crypto doesnâ€™t have this problem â€“ if youâ€™re able to share a key that can only be used for encrypting and not for decrypting, then the decryption keys never have to leave the recipient machine. You can then encrypt some text, and nobody except for the recipient can decrypt it â€“ not even you! Put it on the internet, write it on a banner attached to the back of a propeller plane â€“ the message will only be readable by the intended recipient.</p><figure><img src="https://capnfabs.net/posts/wtf-encryption-scheme-synology-diskstation-nas/your-ciphertext-here.jpg" alt="A propeller plane with a banner reading 'your ciphertext here'"></figure><p>Asymmetric cryptography is <em>slow</em>, though, so doing it for lots of data is going to really hurt performance.</p><p>A common solution is to simply <em>make up</em> a symmetric key, perform some symmetric encryption using that key, then encrypt <em>that</em> key using asymmetric cryptography, and deliver both to the remote party. Then, the remote party can:</p><ul><li>First, perform asymmetric decryption to obtain the symmetric key</li><li>Then, use that symmetric key to decrypt the rest.</li></ul><p>Thatâ€™s what <em>this</em> particular system is doing. âœ¨</p><h3 id="a-quick-note-about-rsa">A quick note about RSA</h3><p>I donâ€™t know much about how RSA works, but as part of researching this article I discovered that itâ€™s pretty easy to implement badly, and <a href="https://blog.trailofbits.com/2019/07/08/fuck-rsa/">extremely difficult to implement well</a>.</p><figure><img src="https://capnfabs.net/posts/wtf-encryption-scheme-synology-diskstation-nas/rsa-correct.gif" alt="Two developers correctly implement RSA, 2010, colorised"><figcaption><p><a href="https://www.youtube.com/watch?v=vPwzHm6buB8">Two developers correctly implement RSA</a>, 2010, colorised</p></figcaption></figure><p>As software developers, we spend a lot of time shipping things once they get to a point of â€œit looks like it worksâ€. <strong>You canâ€™t take that approach with cryptography</strong>, and because everything is so opaque, itâ€™s a lot easier to declare that your implementation works without realising that itâ€™s missing fundamentals. Like correctness, for example.</p><h3 id="lets-talk-about-random-keyslets-talk-about-you-and-me">Letâ€™s talk about random keys<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></h3><p>Recall that this algorithm is generating 501 random bytes from a 77-character set, and encrypting that with RSA. 501 seemed like an oddly specific number to me; hereâ€™s the specific set of circumstances that characterise <em>why</em> weâ€™re generating a string of this length.</p><p>RSA is a <a href="https://en.wikipedia.org/wiki/Block_cipher"><em>block cipher</em></a>, which means it operates on distinct fixed-size blocks of input and produces fixed-size blocks of output. How big can each block be? Well, RSA public keys are made up of two numbers: a (very large) modulus <code>n</code>, and a much smaller exponent <code>e</code>. RSA is capable of encrypting any message thatâ€™s smaller than <code>n</code> if you convert it to a number. In our case, we said that our modulus was a seemingly-random 4096-bit integer â€“ that means (approximately) that we can encrypt 512-byte blocks.</p><p>Thereâ€™s an important implication here: if you donâ€™t have enough input for a block, you need to fill it up somehow. Normally this is called a <em>padding scheme</em><sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> in block-based cryptography.</p><p>Now, the system on this NAS in particular uses <a href="https://tools.ietf.org/html/rfc3447#section-7.2.1">PKCS1-v1.5 padding</a>, which prepends the message (before encryption) with 3 bytes of headers <em>plus</em> a minimum of 8 bytes<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> of random garbage. That makes 11 bytes out of a 512 byte block, which means weâ€™ve gotâ€¦ 501 bytes left for our message. âœ¨</p><h3 id="lo-fi-key-derivation">Lo-fi key derivation</h3><p>Soâ€¦ weâ€™ve got this 501-byte string, with each character being one of 77 possibilities, and we think we know <em>why</em> it was chosen to be 501 bytes long. But thatâ€™s not going to work for AES-encrypting the password:</p><ul><li>AES requires a key size of 128, 192, or 256 bits. Thatâ€™s 16, 24, or 32 bytes respectively, but weâ€™ve got <em>lots</em> more than that.</li><li>We canâ€™t, however, just take a subset of bytes from the text and go from there â€“ because theyâ€™re selected from a narrow subset of possible bytes (77 out of 255!), youâ€™d be losing an <em>enormous</em> amount of entropy in the key, making the encrypted text about 44,000,000,000,000,000 times<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> easier to break.</li></ul><p>These constraints need to be managed. We can smooth over both by applying a <a href="https://en.wikipedia.org/wiki/Key_derivation_function">key derivation function</a>, based on repeated rounds of MD5 hashing and concatenating. Hash algorithms, in general, are good for this because they map input data toâ€¦ not random, but random-<em>looking</em> output data.</p><p>I like to think of hashing as â€œentropy launderingâ€ â€“ if youâ€™ve got 256 bits of entropy in a 16kB file, taking the first 256 bits will give you only 64 bits of entropy. If you hash the whole 16kB file, then the entropy goes back up to the maximum of the entropy in the file and the entropy provided by the hash algorithm. This works because hash algorithms are designed to exhibit an <a href="https://en.wikipedia.org/wiki/Avalanche_effect">avalanche effect</a>.</p><p>I do <em>not</em> have the tools or experience to evaluate whether this specific scheme is secure or not (this one seems esoteric, and the <a href="https://security.stackexchange.com/questions/19906/is-md5-considered-insecure">use of MD5 is scary</a>!)â€¦ so letâ€™s move briskly on.</p><h3 id="aes-encryption">AES-encryption</h3><p>Finally, after a bunch of outdated and somewhat esoteric primitives, weâ€™re back to something that is <em>good</em> and <em>works</em> and <em>only slightly</em> a <a href="https://en.wiktionary.org/wiki/footgun">loaded footgun</a> and is <em>still recommended for widespread use!</em> Itâ€™s AES with a 256-bit key.</p><p>AES is our symmetric cipher. Like RSA, it operates on blocks of fixed length. <a href="https://crypto.stackexchange.com/questions/66314/whats-the-best-block-cipher-mode-of-operation-for-rsa/66321#66321">Unlike RSA</a>, these blocks can be chained together. The strategies to do this are called <a href="https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation">â€œBlock cipher modes of operationâ€</a>, and AES implementations ship with a number of them. The problem is, this means you have access â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://capnfabs.net/posts/wtf-encryption-scheme-synology-diskstation-nas/">https://capnfabs.net/posts/wtf-encryption-scheme-synology-diskstation-nas/</a></em></p>]]>
            </description>
            <link>https://capnfabs.net/posts/wtf-encryption-scheme-synology-diskstation-nas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26194999</guid>
            <pubDate>Fri, 19 Feb 2021 16:50:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Brave Browser leaks your Tor / Onion service requests through DNS]]>
            </title>
            <description>
<![CDATA[
Score 341 | Comments 84 (<a href="https://news.ycombinator.com/item?id=26194764">thread link</a>) | @todsacerdoti
<br/>
February 19, 2021 | https://ramble.pw/f/privacy/2387/brave-browser-leaks-your-tor-onion-service-requests-through | <a href="https://web.archive.org/web/*/https://ramble.pw/f/privacy/2387/brave-browser-leaks-your-tor-onion-service-requests-through">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              <div lang="en" dir="ltr"><p>Edit: (Since this is gaining traction elsewhere.) I'm not trying to shit on Brave. I'm just wanting to help protect end-users who may use Brave for it's Tor feature to do stuff over Tor that should only be done with the actual Tor browser. If you're using Brave you probably use it because you expect a certain level of privacy/anonymity. Piping .onion requests through DNS where your ISP or DNS provider can see that <em>you</em> made a request for an .onion site defeats that purpose.</p>
<p>I'm also no NetSec expert but you don't have to be to replicate this. I'm just a dude with some websites and projects and I'm not certain I would have taken notice of this if it wasn't reported to me by a partner on another project who witnessed this behavior when monitoring his local requests leaving his network. He'll be doing his own write-up and is more equipped to discuss this in length than me.</p>
<hr><p>Testing out something that was noted a week or so ago, and wanting to replicate it for the purpose of this post.</p>
<p>Some of you know I'm working on an ad, tracker, and other BS blocking VPN service for an unrelated project to this site. Go to <a href="https://ramble.pw/f/incoghost">/f/incoghost</a> (<a href="https://incog.host/" rel="nofollow">website</a>) for more because I try to keep these things separated.</p>
<p>Anyhow, it was reported by a partner that Brave was leaking DNS requests for onion sites and I was able to confirm it at the time. Decided to spin up a VM with Brave and test with this site's Onion service (though it will do this for any .onion)</p>
<p>Example:</p>
<pre><code> Feb 18 12:02:25: query[A] rambleeeqrhty6s5jgefdfdtc6tfgg4jj6svr4jpgk4wjtg3qshwbaad.onion from 104.244.xx.xxx
</code></pre>
<p>What this entry shows (simply) is that the request made for the domain rambleeeqrhty6s5jgefdfdtc6tfgg4jj6svr4jpgk4wjtg3qshwbaad.onion made it to the DNS server and is tagged with the IP of the requester, which in this case is just the test / dev VPN. This shouldn't happen. There isn't any reason for Brave to attempt to resolve a .onion domain through traditional means as it would with a regular clearnet site.</p>
<p>This is especially worrisome for those of you who use Brave browser from your normal residential IP and (for whatever reason) use the Tor feature built into the browser to access Tor sites. Your ISP or DNS provider <em>will</em> know that a request made to a specific Tor site was made by <em>your</em> IP. With Brave, your ISP would know that you accessed <em>somesketchyonionsite.onion</em> .</p>
<p>TL;DR: If you're going to use Tor, use the Tor Browser and not Brave. The Tor browser itself doesn't leak these requests like Brave does.</p>
<hr><p>Edit: To clarify, the VPN service we're working on is no-logging but during this dev and testing period we're logging DNS requests while we work out the kinks in the blocklists. This has also allowed us to witness .onions being passed through which is a fault of Brave.</p>
<hr><p>Edit 2: Screenshot: <a href="https://images2.imgbox.com/98/46/1i084PbC_o.png" rel="nofollow">https://images2.imgbox.com/98/46/1i084PbC_o.png</a></p>
<p>That was me loading duckduckgo in a different container, with brave, while live fetching DNS requests made to the DNS server. I blurred out the non-onion requests. (Different VPN test location than in the above example so 209.x.x.x IP instead of the 104.x.x.x one in the original example.</p>
<hr><h3>EDIT 2: The mods of /r/privacy won't let this be posted. They say:</h3>
<blockquote>
<p>While we (vastly) prefer the Tor Browser over the Brave one, you'll need a better source than the one you found. Can you find something from a more widely recognized NetSec expert? Something along the lines of Bruce Schneier's blog or something at that level of credibility?</p>
</blockquote>
<p>and</p>
<blockquote>
<p>The problem with screenshots is that they can be faked, trivially. There are also a host of approaches that credible writers/reporters do in the NetSec space do before a line of text appears in print. It's this kind of journalism that we have to trust, since we humble Mods don't have the time or resources to vet. So, we'll need something better sourced. Sorry!</p>
</blockquote>
<p>and</p>
<blockquote>
<p>There are new posts everyday "warning" people of things that aren't legitimate, hence the caution. This is not a "security" subreddit. A moderator's job is to ensure that the subreddit doesn't devolve into conspiracy theories and misinformation. Security announcements should be vetted and confirmed, not independent claims that the mods have no time to independently verify.</p>
<blockquote>
<p>I can post the steps on how to easily replicate this by using pi-hole on their local networks. Anyone is capable of verifying this.</p>
</blockquote>
<p>Great. Please do so on r/brave, r/netsec, r/infosec, and other places where this is both directly relevant and appropriate to seek others confirmation. Once vetted by the community (and republished by professionals), you're welcome to post those official responses.</p>
</blockquote>
<p>/r/brave is private, invite only. I posted on netsec and infosec so we'll see. I guess /r/privacy must love Brave and not allow anything against it since it's so god damned easy to verify this...</p>
<p>All you have to do to VERIFY that this is happening is A.) Use Brave B.) Go to an Onion site C.) Observe DNS traffic. Install Pi-Hole on a Raspberry Pi or in a Virtual Machine on your desktop and run your DNS requests through it for ease of use and you can verify it. Not sure why they're so hesitant to inform their subscribers of this.</p>
<hr><p>Edit 3: Tested on both a Debian 10 and Ubuntu desktop. I'm not esteemed NetSec researcher and I'm not setting up a 100 different scenarios.</p>
</div>
            </div></div>]]>
            </description>
            <link>https://ramble.pw/f/privacy/2387/brave-browser-leaks-your-tor-onion-service-requests-through</link>
            <guid isPermaLink="false">hacker-news-small-sites-26194764</guid>
            <pubDate>Fri, 19 Feb 2021 16:27:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We are starting to operate our CNC machines remotely]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 93 (<a href="https://news.ycombinator.com/item?id=26193769">thread link</a>) | @Sharapolas
<br/>
February 19, 2021 | https://1d.works/how-we-started-operating-our-cnc-machines-remotely/ | <a href="https://web.archive.org/web/*/https://1d.works/how-we-started-operating-our-cnc-machines-remotely/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <h2 id="introduction"><strong>Introduction</strong></h2><p>Not only COVID-19 has brought many challenges to our daily lives, but it also has inspired a lot of change in how we work and do things. Some professions transitioned to remote work more easily than others. Factory workers and machine operators have been less lucky in this regard and that also applies to us in our CNC-based micro-factory.</p><p>Allowing more people to work remotely opens up many opportunities for businesses. Not only you can bring talent from anywhere in the world, but also you have more choices where to house the hardware allowing to optimise on cost. Furthermore, reaction times can be reduced if travel to the worksite can be eliminated. Quite a few IT professionals have been doing a good job from spectacular locations and we should strive to let more people experience that.</p><p>Another important aspect of structuring work such that it can be done remotely is that it is the first step to automating it. Local to remote, and remote to autonomous allows for a smoother transition than local to autonomous straight away. In the future, we plan on coupling our remote system to AI so if youâ€™re interested, make sure to follow us on LinkedIn or Facebook!</p><p><strong>WARNING! </strong>Running machinery unsupervised is dangerous and must be avoided. This article is elaborating on how to operate machines more efficiently with more staff working remote, but does not suggest running machines without supervision or people on-site.</p><h2 id="how-corona-showed-us-an-opportunity"><strong>How Corona showed us an opportunity</strong></h2><p>Before the COVID-19 hit our workflow for a CNC job has been as follows:</p><ol><li>Make CAD/ CAM in the office;</li><li>Finalise CAM in the shop;</li><li>Run CNC jobs in the shop.</li></ol><p>However, during the quarantine at times it has become difficult to proceed this way because of the travel restrictions ( our CNC lab and office are based in different districts and district travel is cumbersome during quarantine ). We took up this challenge and used it as an opportunity to do the first step towards our micro-factory automation by doing more of the shop work remotely.</p><h2 id="the-cnc-lab-problem"><strong>The CNC lab problem</strong></h2><p>Running a CNC job required:</p><ol><li>Prepare the CAD/CAM files;</li><li>Setup the CNC machine for the job;</li><li>Loop: place the material, run the program, take out the cut parts, clean the table</li></ol><p>In our team, a single person has been doing all of these things. However, is it wise to use a skilled designer/ operator to be in charge of moving material and parts? Not really, because those skills could be invested in something with a much better return on investment (ROI).</p><p>Why donâ€™t we have an unskilled person doing that work? Because CNC jobs are prone to small and costly mistakes, so to ensure high quality and safe operation, that person has to have some skills. Those skills need to either be brought in or be taught and as soon as a person has those skills we are back at having a skilled person doing a large amount of unskilled work.</p><h3 id="iteration-1">Iteration 1</h3><p>Our first step towards a solution was finding an unskilled person to be at the shop while we remote into the PC which controls the CNC machine. This has greatly improved our ROI and created a truly win-win situation because not only we are more efficiently using our time resources, but also created a new job position.</p><p>Still, there were issues to be solved. Coordination was done by phone and in order to operate the machine safely, we had to do multiple repeated questions making sure that it is safe to run the machine. Setup was particularly tricky because misunderstandings led to tool breakage and material waste. Lastly, making sure that the operation is proceeding smoothly was tricky as well since it required experienced evaluation and experience we did not have on-site.</p><h3 id="iteration-2">Iteration 2</h3><p>Having drawn conclusions from iteration 1, weâ€™ve decided to upgrade the CNC lab with a camera for more efficient and higher quality feedback. And it is surprising how much easier work became then!</p><figure><img src="https://cdn-images-1.medium.com/max/1600/1*ukzIoHs74MRrQd9Xu3ZBJQ.png" alt=""><figcaption>Figure 1. CNC shop&nbsp;camera</figcaption></figure><p>Much less coordination was required and we were much more confident operating the CNC machine knowing that the site was safe for operation. Setups became easier because we could verify that the right measurements were made.</p><p>Soon enough weâ€™ve found many things that could be improved:</p><ul><li>Running cameras in one window and remoting in on another tended to be inconvenient on a single screen workstation;</li><li>Although monitoring was much better, the single-camera setup did not allow to evaluate the quality of the finish or how smoothly the work was progressing;</li><li>When we were executing tool adjustments (eg. changing a bit in the tool chuck ) it was still hard to be sure that the right tool was where it needed to be;</li><li>It has become very apparent that some of the tasks could be semi-automated using feedback from the on-site worker. For example, at the beginning of each session, the machine needs to be initialised by moving it to reference and calibrating all the tools which involved checking if the site was clear for action and then going through a sequence of clicks;</li><li>Measurements still took a while to explain and then took a while to do properly.</li></ul><h3 id="iteration-3">Iteration 3</h3><p>Taking into account the inefficiencies weâ€™ve identified, weâ€™ve decided to work on a cohesive platform with an intuitive dashboard which would merge all the systems we have and provide the base for automation to be built upon.</p><p>First, was the network setup. We needed to merge multi-site networks into a mesh topology network where all the nodes could be interconnected which was solved using a hub and spoke topology VPN. Although, it does have its own drawbacks it had a good cost-benefit ratio when it comes to setup and deployment and is working for us for now.</p><p>Next, was building the dashboard which not only required the making of the UI but required figuring out how weâ€™re going to expose and manage resources in our shop network. We decided to build the backend in the spirit of Kubernetes, so it is easy to manage at scale with the addition of new sensors, machines and full-blown sites themselves.</p><figure><img src="https://cdn-images-1.medium.com/max/1600/1*JYyqKIXsBTgfg8A-ENR-xw.png" alt=""><figcaption>Figure 2. CNC shop dashboard prototype</figcaption></figure><p>For the GUI we choose to go with Pythonâ€™s Tkinter package in order to be able to rapidly iterate and once it reaches a stable state weâ€™re planning to move it into a web app for easy access from any device. The dashboard is set up such that one could interface with the embedded CNC software by just doing the relevant actions on the dashboard.</p><h3 id="conclusions">Conclusions</h3><p>Based on our experience using the shop dashboard, it has helped us improve our process in the CNC shop by a mile. We are significantly more confident running remote jobs, have more oversight and control and the process is much more efficient with time.</p><p>It has also opened the possibility to (semi)-automate processes involved in running a CNC shop, which we are continuing to work with and will be posting later. We have a few ideas on how to couple the camera and control system with AI and that is an exciting prospect!</p><p>One key feature that the system requires is being able to remotely access the CNC control software. We are lucky to have it running on a PC which we can easily remote-in, but in case of embedded software, some middleware might be needed to control it remotely.</p><p>Allowing the machine operator to work remote adds value to our business as we could easier relocate the shop to cheaper areas, further from the cities or have talented engineers from nearly anywhere in the world away from work with us. That is why we will continue on this journey and will share it with you as we go!</p><hr><h3 id="check-out-more-">Check out more:</h3><ol><li><a href="https://1d.works/welcome-to-1d-works-cnc-lab/" rel="noopener">Welcome to 1D.works CNC Lab</a></li><li><a href="https://1d.works/object-oriented-computer-assisted-machining/" rel="noopener">Simplifying CAM workflow with Fusion 360</a></li><li><a href="https://1d.works/unique-products-at-scale-with-ai-infused-cad/" rel="noopener">Unique products at scale with AI-infused CAD</a></li></ol><p>and more in our <a href="https://1d.works/blog/" rel="noopener">blog</a></p><hr><h3 id="connect-">Connect!</h3><p>At <a href="https://1d.works/" rel="noopener nofollow noopener noopener">1D.works</a> weâ€™re excited about the potential of AI to improve businesses and peopleâ€™s lives. CAD and CAM are two of the largely unexplored territories weâ€™re invested in. If you think you can benefit from a decade-long experience of applying machine learning to business processes, <a href="https://1d.works/" rel="noopener nofollow noopener noopener">get in touch</a>!</p><hr><figure><img src="https://cdn-images-1.medium.com/max/1600/1*ZttLaS6wTmFLgKZ6_9LeeA.png" alt=""></figure>
                </div>
            </section></div>]]>
            </description>
            <link>https://1d.works/how-we-started-operating-our-cnc-machines-remotely/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26193769</guid>
            <pubDate>Fri, 19 Feb 2021 14:53:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Universal Warrior, Part III: The Cult of the Badass]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26193719">thread link</a>) | @myWindoonn
<br/>
February 19, 2021 | https://acoup.blog/2021/02/19/collections-the-universal-warrior-part-iii-the-cult-of-the-badass/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2021/02/19/collections-the-universal-warrior-part-iii-the-cult-of-the-badass/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://acoup.blog/2021/02/19/collections-the-universal-warrior-part-iii-the-cult-of-the-badass/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26193719</guid>
            <pubDate>Fri, 19 Feb 2021 14:50:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing Our Own Cheat Engine]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26193563">thread link</a>) | @asicsp
<br/>
February 19, 2021 | https://lonami.dev/blog/woce-1/ | <a href="https://web.archive.org/web/*/https://lonami.dev/blog/woce-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>2021-02-07</p><p>last updated 2021-02-19</p></div><p>This is part 1 on the <em>Writing our own Cheat Engine</em> series:</p><ul><li>Part 1: Introduction</li><li><a href="https://lonami.dev/blog/woce-2">Part 2: Exact Value scanning</a></li><li><a href="https://lonami.dev/blog/woce-3">Part 3: Unknown initial value</a></li></ul><p><a href="https://cheatengine.org/">Cheat Engine</a> is a tool designed to modify single player games and contains other useful tools within itself that enable its users to debug games or other applications. It comes with a memory scanner, (dis)assembler, inspection tools and a handful other things. In this series, we will be writing our own tiny Cheat Engine capable of solving all steps of the tutorial, and diving into how it all works underneath.</p><p>Needless to say, we're doing this for private and educational purposes only. One has to make sure to not violate the EULA or ToS of the specific application we're attaching to. This series, much like cheatengine.org, does not condone the illegal use of the code shared.</p><p>Cheat Engine is a tool for Windows, so we will be developing for Windows as well. However, you can also <a href="https://stackoverflow.com/q/12977179/4759433">read memory from Linux-like systems</a>. <a href="https://github.com/scanmem/scanmem">GameConqueror</a> is a popular alternative to Cheat Engine on Linux systems, so if you feel adventurous, you could definitely follow along too! The techniques shown in this series apply regardless of how we read memory from a process. You will learn a fair bit about doing FFI in Rust too.</p><p>We will be developing the application in Rust, because it enables us to interface with the Windows API easily, is memory safe (as long as we're careful with <code>unsafe</code>!), and is speedy (we will need this for later steps in the Cheat Engine tutorial). You could use any language of your choice though. For example, <a href="https://lonami.dev/blog/ctypes-and-windows/">Python also makes it relatively easy to use the Windows API</a>. You don't need to be a Rust expert to follow along, but this series assumes some familiarity with C-family languages. Slightly advanced concepts like the use of <code>unsafe</code> or the <code>MaybeUninit</code> type will be briefly explained. What a <code>fn</code> is or what <code>let</code> does will not be explained.</p><p><a href="https://github.com/cheat-engine/cheat-engine/">Cheat Engine's source code</a> is mostly written in Pascal and C. And it's <em>a lot</em> of code, with a very flat project structure, and files ranging in the thousand lines of code each. It's daunting<sup><a href="#1">1</a></sup>. It's a mature project, with a lot of knowledge encoded in the code base, and a lot of features like distributed scanning or an entire disassembler. Unfortunately, there's not a lot of comments. For these reasons, I'll do some guesswork when possible as to how it's working underneath, rather than actually digging into what Cheat Engine is actually doing.</p><p>With that out of the way, let's get started!</p><h2 id="welcome-to-the-cheat-engine-tutorial">Welcome to the Cheat Engine Tutorial</h2><details open=""><summary>Cheat Engine Tutorial: Step 1</summary> <blockquote><p>This tutorial will teach you the basics of cheating in video games. It will also show you foundational aspects of using Cheat Engine (or CE for short). Follow the steps below to get started.</p><ol><li>Open Cheat Engine if it currently isn't running.</li><li>Click on the "Open Process" icon (it's the top-left icon with the computer on it, below "File".).</li><li>With the Process List window now open, look for this tutorial's process in the list. It will look something like &gt; "00001F98-Tutorial-x86_64.exe" or "0000047C-Tutorial-i386.exe". (The first 8 numbers/letters will probably be different.)</li><li>Once you've found the process, click on it to select it, then click the "Open" button. (Don't worry about all the &gt; other buttons right now. You can learn about them later if you're interested.)</li></ol><p>Congratulations! If you did everything correctly, the process window should be gone with Cheat Engine now attached to the &gt; tutorial (you will see the process name towards the top-center of CE).</p><p>Click the "Next" button below to continue, or fill in the password and click the "OK" button to proceed to that step.)</p><p>If you're having problems, simply head over to forum.cheatengine.org, then click on "Tutorials" to view beginner-friendly &gt; guides!</p></blockquote></details><h2 id="enumerating-processes">Enumerating processes</h2><p>Our first step is attaching to the process we want to work with. But we need a way to find that process in the first place! Having to open the task manager, look for the process we care about, noting down the process ID (PID), and slapping it in the source code is not satisfying at all. Instead, let's enumerate all the processes from within the program, and let the user select one by typing its name.</p><p>From a quick <a href="https://ddg.gg/winapi%20enumerate%20all%20processes">DuckDuckGo search</a>, we find an official tutorial for <a href="https://docs.microsoft.com/en-us/windows/win32/psapi/enumerating-all-processes">Enumerating All Processes</a>, which leads to the <a href="https://docs.microsoft.com/en-us/windows/win32/api/psapi/nf-psapi-enumprocesses"><code>EnumProcesses</code></a> call. Cool! Let's slap in the <a href="https://crates.io/crates/winapi"><code>winapi</code></a> crate on <code>Cargo.toml</code>, because I don't want to write all the definitions by myself:</p><pre><code data-lang="toml">[dependencies]
winapi = { version = "0.3.9", features = ["psapi"] }
</code></pre><p>Because <a href="https://docs.microsoft.com/en-us/windows/win32/api/psapi/nf-psapi-enumprocesses"><code>EnumProcesses</code></a> is in <code>Psapi.h</code> (you can see this in the online page of its documentation), we know we'll need the <code>psapi</code> crate feature. Another option is to search for it in the <a href="https://docs.rs/winapi/"><code>winapi</code> documentation</a> and noting down the parent module where its stored.</p><p>The documentation for the method has the following remark:</p><blockquote><p>It is a good idea to use a large array, because it is hard to predict how many processes there will be at the time you call <strong>EnumProcesses</strong>.</p></blockquote><p><em>Sidenote: reading the documentation for the methods we'll use from the Windows API is extremely important. There's a lot of gotchas involved, so we need to make sure we're extra careful.</em></p><p>1024 is a pretty big number, so let's go with that:</p><pre><code data-lang="rust">use std::io;
use std::mem;
use winapi::shared::minwindef::{DWORD, FALSE};

pub fn enum_proc() -&gt; io::Result&lt;Vec&lt;u32&gt;&gt; {
    let mut pids = Vec::&lt;DWORD&gt;::with_capacity(1024);
    let mut size = 0;
    // SAFETY: the pointer is valid and the size matches the capacity.
    if unsafe {
        winapi::um::psapi::EnumProcesses(
            pids.as_mut_ptr(),
            (pids.capacity() * mem::size_of::&lt;DWORD&gt;()) as u32,
            &amp;mut size,
        )
    } == FALSE
    {
        return Err(io::Error::last_os_error());
    }

    todo!()
}
</code></pre><p>We allocate enough space<sup><a href="#2">2</a></sup> for 1024 <code>pids</code> in a vector<sup><a href="#3">3</a></sup>, and pass a mutable pointer to the contents to <code>EnumProcesses</code>. Note that the size of the array is in <em>bytes</em>, not items, so we need to multiply the capacity by the size of <code>DWORD</code>. The API likes to use <code>u32</code> for sizes, unlike Rust which uses <code>usize</code>, so we need a cast.</p><p>Last, we need another mutable variable where the amount of bytes written is stored, <code>size</code>.</p><blockquote><p>If the function fails, the return value is zero. To get extended error information, call <a href="https://docs.microsoft.com/en-us/windows/win32/api/errhandlingapi/nf-errhandlingapi-getlasterror"><code>GetLastError</code></a>.</p></blockquote><p>That's precisely what we do. If it returns false (zero), we return the last OS error. Rust provides us with <a href="https://doc.rust-lang.org/stable/std/io/struct.Error.html#method.last_os_error"><code>std::io::Error::last_os_error</code></a>, which essentially makes that same call but returns a proper <code>io::Error</code> instance. Cool!</p><blockquote><p>To determine how many processes were enumerated, divide the <em>lpcbNeeded</em> value by <code>sizeof(DWORD)</code>.</p></blockquote><p>Easy enough:</p><pre><code data-lang="rust">let count = size as usize / mem::size_of::&lt;DWORD&gt;();
// SAFETY: the call succeeded and count equals the right amount of items.
unsafe { pids.set_len(count) };
Ok(pids)
</code></pre><p>Rust doesn't know that the memory for <code>count</code> items were initialized by the call, but we do, so we make use of the <a href="https://doc.rust-lang.org/stable/std/vec/struct.Vec.html#method.set_len"><code>Vec::set_len</code></a> call to indicate this. The Rust documentation even includes a FFI similar to our code!</p><p>Let's give it a ride:</p><pre><code data-lang="rust">fn main() {
    dbg!(enum_proc().unwrap().len());
}
</code></pre><pre><code>&gt;cargo run
   Compiling memo v0.1.0
    Finished dev [unoptimized + debuginfo] target(s) in 0.20s
     Running `target\debug\memo.exe`
[src\main.rs:27] enum_proc().unwrap().len() = 178
</code></pre><p>It works! But currently we only have a bunch of process identifiers, with no way of knowing which process they refer to.</p><blockquote><p>To obtain process handles for the processes whose identifiers you have just obtained, call the <a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-openprocess"><code>OpenProcess</code></a> function.</p></blockquote><p>Oh!</p><h2 id="opening-a-process">Opening a process</h2><p>The documentation for <code>OpenProcess</code> also contains the following:</p><blockquote><p>When you are finished with the handle, be sure to close it using the <a href="https://lonami.dev/blog/woce-1/closehandle"><code>CloseHandle</code></a> function.</p></blockquote><p>This sounds to me like the perfect time to introduce a custom <code>struct Process</code> with an <code>impl Drop</code>! We're using <code>Drop</code> to cleanup resources, not behaviour, so it's fine. <a href="https://internals.rust-lang.org/t/pre-rfc-leave-auto-trait-for-reliable-destruction/13825">Using <code>Drop</code> to cleanup behaviour is a bad idea</a>. But anyway, let's get back to the code:</p><pre><code data-lang="rust">use std::ptr::NonNull;
use winapi::ctypes::c_void;

pub struct Process {
    pid: u32,
    handle: NonNull&lt;c_void&gt;,
}

impl Process {
    pub fn open(pid: u32) -&gt; io::Result&lt;Self&gt; {
        todo!()
    }
}

impl Drop for Process {
    fn drop(&amp;mut self) {
        todo!()
    }
}
</code></pre><p>For <code>open</code>, we'll want to use <code>OpenProcess</code> (and we also need to add the <code>processthreadsapi</code> feature to the <code>winapi</code> dependency in <code>Cargo.toml</code>). It returns a <code>HANDLE</code>, which is a nullable mutable pointer to <code>c_void</code>. If it's null, the call failed, and if it's non-null, it succeeded and we have a valid handle. This is why we use Rust's <a href="https://doc.rust-lang.org/stable/std/ptr/struct.NonNull.html"><code>NonNull</code></a>:</p><pre><code data-lang="rust">// SAFETY: the call doesn't have dangerous side-effects.
NonNull::new(unsafe { winapi::um::processthreadsapi::OpenProcess(0, FALSE, pid) })
    .map(|handle| Self { pid, handle })
    .ok_or_else(io::Error::last_os_error)
</code></pre><p><code>NonNull</code> will return <code>Some</code> if the pointer is non-null. We map the non-null pointer to a <code>Process</code> instance with <code>Self { .. }</code>. <code>ok_or_else</code> converts the <code>Option</code> to a <code>Result</code> with the error builder function we provide if it was <code>None</code>.</p><p>The first parameter is a bitflag of permissions we want to have. For now, we can leave it as zero (all bits unset, no specific permissions granted). The second one is whether we want to inherit the handle, which we don't, and the third one is the process identifier. Let's close the resource handle on <code>Drop</code> (after adding <code>handleapi</code> to the crate features):</p><pre><code data-lang="rust">// SAFETY: the handle is valid and non-null.
unsafe { winapi::um::handleapi::CloseHandle(self.handle.as_mut()) };
</code></pre><p><code>CloseHandle</code> can actually fail (for example, on double-close), but given our invariants, it won't. You could add an <code>assert!</code> to panic if this is not the case.</p><p>We can now open processes, and they will be automatically closed on <code>Drop</code>. Does any of this work though?</p><pre><code data-lang="rust">fn main() {
    let mut success = 0;
    let mut failed = 0;
    enum_proc().unwrap().into_iter().for_each(|pid| match Process::open(pid) {
        Ok(_) =&gt; success += 1,
        Err(_) =&gt; failed += 1,
    });

    eprintln!("Successfully opened {}/{} processes", success, success + failed);
}
</code></pre><pre><code>&gt;cargo run
   Compiling memo v0.1.0
    â€¦</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lonami.dev/blog/woce-1/">https://lonami.dev/blog/woce-1/</a></em></p>]]>
            </description>
            <link>https://lonami.dev/blog/woce-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26193563</guid>
            <pubDate>Fri, 19 Feb 2021 14:36:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CC Academy (Free Fellowship) opens its doors to the 3rd cohort of ML/FE/UX folks]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26193517">thread link</a>) | @billnyetheai
<br/>
February 19, 2021 | https://www.notion.so/Chronic-Coder-Academy-Season-3-dbd4a42c517a4902b345a7fb7287cedf | <a href="https://web.archive.org/web/*/https://www.notion.so/Chronic-Coder-Academy-Season-3-dbd4a42c517a4902b345a7fb7287cedf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/Chronic-Coder-Academy-Season-3-dbd4a42c517a4902b345a7fb7287cedf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26193517</guid>
            <pubDate>Fri, 19 Feb 2021 14:31:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Brave Browser leaks your Tor / Onion service requests through DNS]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 14 (<a href="https://news.ycombinator.com/item?id=26192574">thread link</a>) | @input_sh
<br/>
February 19, 2021 | https://ramble.pw/f/privacy/2387 | <a href="https://web.archive.org/web/*/https://ramble.pw/f/privacy/2387">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              <div lang="en" dir="ltr"><p>Edit: (Since this is gaining traction elsewhere.) I'm not trying to shit on Brave. I'm just wanting to help protect end-users who may use Brave for it's Tor feature to do stuff over Tor that should only be done with the actual Tor browser. If you're using Brave you probably use it because you expect a certain level of privacy/anonymity. Piping .onion requests through DNS where your ISP or DNS provider can see that <em>you</em> made a request for an .onion site defeats that purpose.</p>
<p>I'm also no NetSec expert but you don't have to be to replicate this. I'm just a dude with some websites and projects and I'm not certain I would have taken notice of this if it wasn't reported to me by a partner on another project who witnessed this behavior when monitoring his local requests leaving his network. He'll be doing his own write-up and is more equipped to discuss this in length than me.</p>
<hr><p>Testing out something that was noted a week or so ago, and wanting to replicate it for the purpose of this post.</p>
<p>Some of you know I'm working on an ad, tracker, and other BS blocking VPN service for an unrelated project to this site. Go to <a href="https://ramble.pw/f/incoghost">/f/incoghost</a> (<a href="https://incog.host/" rel="nofollow">website</a>) for more because I try to keep these things separated.</p>
<p>Anyhow, it was reported by a partner that Brave was leaking DNS requests for onion sites and I was able to confirm it at the time. Decided to spin up a VM with Brave and test with this site's Onion service (though it will do this for any .onion)</p>
<p>Example:</p>
<pre><code> Feb 18 12:02:25: query[A] rambleeeqrhty6s5jgefdfdtc6tfgg4jj6svr4jpgk4wjtg3qshwbaad.onion from 104.244.xx.xxx
</code></pre>
<p>What this entry shows (simply) is that the request made for the domain rambleeeqrhty6s5jgefdfdtc6tfgg4jj6svr4jpgk4wjtg3qshwbaad.onion made it to the DNS server and is tagged with the IP of the requester, which in this case is just the test / dev VPN. This shouldn't happen. There isn't any reason for Brave to attempt to resolve a .onion domain through traditional means as it would with a regular clearnet site.</p>
<p>This is especially worrisome for those of you who use Brave browser from your normal residential IP and (for whatever reason) use the Tor feature built into the browser to access Tor sites. Your ISP or DNS provider <em>will</em> know that a request made to a specific Tor site was made by <em>your</em> IP. With Brave, your ISP would know that you accessed <em>somesketchyonionsite.onion</em> .</p>
<p>TL;DR: If you're going to use Tor, use the Tor Browser and not Brave. The Tor browser itself doesn't leak these requests like Brave does.</p>
<hr><p>Edit: To clarify, the VPN service we're working on is no-logging but during this dev and testing period we're logging DNS requests while we work out the kinks in the blocklists. This has also allowed us to witness .onions being passed through which is a fault of Brave.</p>
<hr><p>Edit 2: Screenshot: <a href="https://images2.imgbox.com/98/46/1i084PbC_o.png" rel="nofollow">https://images2.imgbox.com/98/46/1i084PbC_o.png</a></p>
<p>That was me loading duckduckgo in a different container, with brave, while live fetching DNS requests made to the DNS server. I blurred out the non-onion requests. (Different VPN test location than in the above example so 209.x.x.x IP instead of the 104.x.x.x one in the original example.</p>
<hr><h3>EDIT 2: The mods of /r/privacy won't let this be posted. They say:</h3>
<blockquote>
<p>While we (vastly) prefer the Tor Browser over the Brave one, you'll need a better source than the one you found. Can you find something from a more widely recognized NetSec expert? Something along the lines of Bruce Schneier's blog or something at that level of credibility?</p>
</blockquote>
<p>and</p>
<blockquote>
<p>The problem with screenshots is that they can be faked, trivially. There are also a host of approaches that credible writers/reporters do in the NetSec space do before a line of text appears in print. It's this kind of journalism that we have to trust, since we humble Mods don't have the time or resources to vet. So, we'll need something better sourced. Sorry!</p>
</blockquote>
<p>and</p>
<blockquote>
<p>There are new posts everyday "warning" people of things that aren't legitimate, hence the caution. This is not a "security" subreddit. A moderator's job is to ensure that the subreddit doesn't devolve into conspiracy theories and misinformation. Security announcements should be vetted and confirmed, not independent claims that the mods have no time to independently verify.</p>
<blockquote>
<p>I can post the steps on how to easily replicate this by using pi-hole on their local networks. Anyone is capable of verifying this.</p>
</blockquote>
<p>Great. Please do so on r/brave, r/netsec, r/infosec, and other places where this is both directly relevant and appropriate to seek others confirmation. Once vetted by the community (and republished by professionals), you're welcome to post those official responses.</p>
</blockquote>
<p>/r/brave is private, invite only. I posted on netsec and infosec so we'll see. I guess /r/privacy must love Brave and not allow anything against it since it's so god damned easy to verify this...</p>
<p>All you have to do to VERIFY that this is happening is A.) Use Brave B.) Go to an Onion site C.) Observe DNS traffic. Install Pi-Hole on a Raspberry Pi or in a Virtual Machine on your desktop and run your DNS requests through it for ease of use and you can verify it. Not sure why they're so hesitant to inform their subscribers of this.</p>
<hr><p>Edit 3: Tested on both a Debian 10 and Ubuntu desktop. I'm not esteemed NetSec researcher and I'm not setting up a 100 different scenarios.</p>
</div>
            </div></div>]]>
            </description>
            <link>https://ramble.pw/f/privacy/2387</link>
            <guid isPermaLink="false">hacker-news-small-sites-26192574</guid>
            <pubDate>Fri, 19 Feb 2021 12:51:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[â€œI will slaughter youâ€]]>
            </title>
            <description>
<![CDATA[
Score 516 | Comments 225 (<a href="https://news.ycombinator.com/item?id=26192025">thread link</a>) | @ingve
<br/>
February 19, 2021 | https://daniel.haxx.se/blog/2021/02/19/i-will-slaughter-you/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2021/02/19/i-will-slaughter-you/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>You might know that Iâ€™ve posted funny emails Iâ€™ve received on my blog several times in the past. The kind of emails people send me when they experience problems with some device they own (like a <a href="https://daniel.haxx.se/blog/2018/02/16/why-is-your-email-in-my-car/" data-type="post" data-id="10856">car</a>) and they contact me because my email address happens to be visible somewhere.</p>



<p>People sometimes say I should get a different email address or use another one in the curl license file, but Iâ€™ve truly never had a problem with these emails, as they mostly remind me about the tough challenges the modern technical life bring to people and it gives me insights about what things that run curl.</p>



<p>But not all of these emails are â€œfunnyâ€.</p>



<h2>Category: not funny</h2>



<p>Today I received the following email</p>



<pre>From: Al Nocai &lt;[redacted]@icloud.com&gt;
Date: Fri, 19 Feb 2021 03:02:24 -0600
Subject: I will slaughter you</pre>



<p>That subject.</p>



<p>As an open source maintainer since over twenty years, I know flame wars and personal attacks and I have a fairly thick skin and I donâ€™t let words get to me easily. It took me a minute to absorb and realize it was actually meant as a direct physical threat. It found its ways through and got to me. This level of aggressiveness is not what Iâ€™m prepared for.</p>



<p>Attached in this email, there were seven images and no text at all. The images all look like screenshots from a phone and the first one is clearly showing <a href="https://github.com/curl/curl/blob/master/include/curl/multi.h">source code I wrote</a> and my copyright line:</p>



<div><figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2021/02/image0.png"><img loading="lazy" width="295" height="640" src="https://daniel.haxx.se/blog/wp-content/uploads/2021/02/image0.png" alt=""></a></figure></div>



<p>The <a href="https://daniel.haxx.se/al/">other images</a> showed other source code and related build/software info of other components, but I couldnâ€™t spot how they were associated with me in any way.</p>



<p>No explanation, just that subject and the seven images and I was left to draw my own conclusions.</p>



<p>I presume the name in the email is made up and the email account is probably a throw-away one. The time zone used in the <code>Date:</code> string might imply US <a href="https://www.timeanddate.com/time/zones/cst">central standard time</a> but could of course easily be phony as well. </p>



<h2>How I responded</h2>



<p>Normally I donâ€™t respond to these confused emails because the distance between me and the person writing them is usually almost interplanetary. This time though, it was so far beyond whatâ€™s acceptable to me and in any decent society I couldnâ€™t just let it slide. After I took a little pause and walked around my house for a few minutes to cool off, I wrote a really angry reply and sent it off.</p>



<blockquote><p>This was a totally and completely utterly unacceptable email and it hurt me deep in my soul. You should be ashamed and seriously reconsider your manners.</p><p>I have no idea what your screenshots are supposed to show, but clearly something somewhere is using code I wrote. Code I have written runs in virtually every Internet connected device on the planet and in most cases the users download and use it without even telling me, for free.</p><p>Clearly you donâ€™t deserve my code.</p></blockquote>



<p>I donâ€™t expect that it will be read or make any difference.</p>



<p>Update below, added after my initial post.</p>



<h2>Al Nocaiâ€™s response</h2>



<p>Contrary to my expectations above, he responded. Itâ€™s not even worth commenting but for transparency Iâ€™ll include it here.</p>



<p><em>I do not care. Your bullshit software was an attack vector that cost me a multimillion dollar defense project.</em></p>



<p><em>Your bullshit software has been used to root me and multiple others. I lost over $15k in prototyping alone from bullshit rooting to the charge arbitrators.</em></p>



<p><em>I have now since October been sandboxed because of your bullshit software so dipshit google kids could grift me trying to get out of the sandbox because they are too piss poor to know shat they are doing.</em></p>



<p><em>You know what I did to deserve that? I tried to develop a trade route in tech and establish project based learning methodologies to make sure kids arenâ€™t left behind. You know who is all over those god damn files? You are. Its sickening. I got breached in Oct 2020 through federal server hijacking, and I owe a great amount of that to you.</em></p>



<p><em>Ive had to sit and watch as i reported:</em></p>



<ol><li><em>fireeye Oct/2020</em></li><li><em>Solarwinds Oct/2020</em></li><li><em>Zyxel Modem Breach Oct/2020</em></li><li><em>Multiple Sigover attack vectors utilizing favicon XML injection</em></li><li><em>JS Stochastic templating utilizing comparison expressions to write to data registers</em></li><li><em>Get strong armed by $50billion companies because i exposed bullshit malware</em></li></ol>



<p><em>And i was rooted and had my important correspondence all rerouted as some sick fuck dismantled my life with the code you have your name plastered all over. I cant even leave the country because of the situation; qas you have so effectively built a code base to shit all over people, I dont give a shit how you feel about this.</em></p>



<p><em>You built a formula 1 race car and tossed the keys to kids with ego problems. Now i have to deal with Win10 0-days because this garbage.</em></p>



<p><em>I lost my family, my country my friends, my home and 6 years of work trying to build a better place for posterity. And it has beginnings in that code. That code is used to root and exploit people. That code is used to blackmail people.</em></p>



<p><em>So no, I donâ€™t feel bad one bit. You knew exactly the utility of what you were building. And you thought it was all a big joke. Im not laughing. I am so far past that point now.</em></p>



<p><em>/- Al</em></p>



<h2>Al continues</h2>



<p>Nine hours after I first published this blog post , Al replied again with two additional emails. His third and forth emails to me.</p>



<h3>Email 3:</h3>



<p><em><a href="https://davidkrider.com/i-will-slaughter-you-daniel-haxx-se/">https://davidkrider.com/i-will-slaughter-you-daniel-haxx-se/</a><br>Step up. You arent scaring me. What led me here? The 5th violent attempt on my life. Apple terms of service? gtfo, thanks for the platform.</em></p>



<p>Amusingly he has found a blog post about my blog post.</p>



<h3>Email 4:</h3>



<p><em>There is the project: MOUT Ops Risk Analysis through Wide Band Em Spectrum analysis through different fourier transforms.<br>You and whoever the fuck david dick rider is, you are a part of this.<br>Federal server breaches-<br>Accomplice to attempted murder-<br>Fraud-<br>just a few.</em></p>



<p><em>I have talked to now: FBI FBI Regional, VA, VA OIG, FCC, SEC, NSA, DOH, GSA, DOI, CIA, CFPB, HUD, MS, Convercent, as of today 22 separate local law enforcement agencies calling my ass up and wasting my time.</em></p>



<p><em>You and dick ridinâ€™ dave are respinsible. I dont give a shit, call the cops. I cuss them out wheb they call and they all go silent.</em></p>



<p>Iâ€™ve kept his peculiar formatting and typos. In email 4 there was also a PDF file attached named <code>BustyBabes 4.pdf</code>. It is apparently a 13 page document about the â€œNERVEBUS NERVOUS SYSTEMâ€ described in the first paragraph as â€œNerveBus Nervous System aims to be a general utility platform that provides comprehensive and complex analysis to provide the end user with cohesive, coherent and â€œreal-timeâ€ information about the environment it monitors.â€. Thereâ€™s no mention of curl or my name in the document.</p>



<p>Since I donâ€™t know the status of this document I will not share it publicly, but hereâ€™s a screenshot of the front page:</p>



<div><figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2021/02/Screenshot_2021-02-20-BustyBabes-4-pdf.png"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2021/02/Screenshot_2021-02-20-BustyBabes-4-pdf.png" alt="" width="358" height="462"></a></figure></div>



<h2>Related</h2>



<p>This topic on <a href="https://news.ycombinator.com/item?id=26192025">hacker news</a> and <a href="https://www.reddit.com/r/programming/comments/lnhcrc/i_will_slaughter_you_daniel_stenberg_got_a_quite/">reddit</a>.</p>



<p>I have reported the threat to the Swedish police (where I live).</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2021/02/19/i-will-slaughter-you/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26192025</guid>
            <pubDate>Fri, 19 Feb 2021 11:36:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compressive transformer PyTorch implementation with notes]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26192005">thread link</a>) | @vpj
<br/>
February 19, 2021 | https://nn.labml.ai/transformers/compressive/index.html | <a href="https://web.archive.org/web/*/https://nn.labml.ai/transformers/compressive/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">
    
    
    <div id="section-0">
        <div>
                
                
<p>This is an implementation of
<a href="https://arxiv.org/abs/1911.05507">Compressive Transformers for Long-Range Sequence Modelling</a>
in <a href="https://pytorch.org/">PyTorch</a>.</p>
<p>This is an extension of <a href="https://nn.labml.ai/transformers/xl/index.html">Transformer XL</a> where past memories
are compressed to give a longer attention range.
That is, the furthest $n_{cm} c$ memories are compressed into
$n_{cm}$ memories, where $c$ is the compression rate.</p>
<h2>Compression operation</h2>
<p>The compression operation is defined as
$f_c: \mathbb{R}^{nc \times d} \rightarrow \mathbb{R}^{n \times d}$.
The paper introduces multiple choices for $f_c$ and we have only implemented
1D convolution which seems to give the best results.
Each layer has a separate compression operation $f_c^{(i)}$ where
$i$ is the layer number.</p>
<h2>Training compression operation</h2>
<p>Since training compression with BPTT requires maintaining
a very large computational graph (many time steps), the paper proposes
an <em>auto-encoding loss</em> and an <em>attention reconstruction loss</em>.
The auto-encoding loss decodes the original memories from the compressed memories
and calculates the loss.
Attention reconstruction loss computes the multi-headed attention results
on the compressed memory and on uncompressed memory and gets a mean squared error
between them.
We have implemented the latter here since it gives better results.</p>
<p>This implementation uses pre-layer normalization
while the paper uses post-layer normalization.
Pre-layer norm does the layer norm before FFN[../feedforward.html) and
self-attention, and the pass-through in the residual connection is not normalized.
This is supposed to be more stable in standard transformer setups.</p>
<p>Here are <a href="https://nn.labml.ai/transformers/compressive/experiment.html">the training code</a> and a notebook for training a compressive transformer
model on the Tiny Shakespeare dataset.</p>
<p><a href="https://colab.research.google.com/github/lab-ml/nn/blob/master/labml_nn/transformers/compressive/experiment.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"></a>
<a href="https://web.lab-ml.com/run?uuid=0d9b5338726c11ebb7c80242ac1c0002"><img alt="View Run" src="https://img.shields.io/badge/labml-experiment-brightgreen"></a></p>
            </div>
            <div>
                <div><pre><span>54</span><span></span><span>from</span> <span>typing</span> <span>import</span> <span>Optional</span><span>,</span> <span>List</span>
<span>55</span>
<span>56</span><span>import</span> <span>torch</span>
<span>57</span><span>import</span> <span>torch.nn.functional</span> <span>as</span> <span>F</span>
<span>58</span><span>from</span> <span>torch</span> <span>import</span> <span>nn</span>
<span>59</span>
<span>60</span><span>from</span> <span>labml_helpers.module</span> <span>import</span> <span>Module</span><span>,</span> <span>TypedModuleList</span>
<span>61</span><span>from</span> <span>labml_nn.transformers.feed_forward</span> <span>import</span> <span>FeedForward</span>
<span>62</span><span>from</span> <span>labml_nn.transformers.mha</span> <span>import</span> <span>PrepareForMultiHeadAttention</span>
<span>63</span><span>from</span> <span>labml_nn.transformers.xl.relative_mha</span> <span>import</span> <span>RelativeMultiHeadAttention</span>
<span>64</span><span>from</span> <span>labml_nn.utils</span> <span>import</span> <span>clone_module_list</span></pre></div>
            </div>
        </div>
    <div id="section-1">
        <div>
                
                <h2>1D Convolution Compression $f_c$</h2>
<p>This is a simple wrapper around
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html"><code>nn.Conv1d</code></a>
with some tensor dimension permutations.</p>
            </div>
            <div>
                <div><pre><span>67</span><span>class</span> <span>Conv1dCompression</span><span>(</span><span>Module</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-2">
        <div>
                
                <ul>
<li><code>compression_rate</code> $c$</li>
<li><code>d_model</code> is the embedding size</li>
</ul>
            </div>
            <div>
                <div><pre><span>75</span>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>compression_rate</span><span>:</span> <span>int</span><span>,</span> <span>d_model</span><span>:</span> <span>int</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-3">
            
            <div>
                <div><pre><span>80</span>        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
<span>81</span>        <span>self</span><span>.</span><span>conv</span> <span>=</span> <span>nn</span><span>.</span><span>Conv1d</span><span>(</span><span>d_model</span><span>,</span> <span>d_model</span><span>,</span> <span>kernel_size</span><span>=</span><span>compression_rate</span><span>,</span> <span>stride</span><span>=</span><span>compression_rate</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-4">
        <div>
                
                <p><code>mem</code> has shape <code>[seq_len, batch, d_model]</code></p>
            </div>
            <div>
                <div><pre><span>83</span>    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>mem</span><span>:</span> <span>torch</span><span>.</span><span>Tensor</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-5">
            <div>
                
                <p>Permute the dimensions of <code>mem</code> so that we can run it through the convolution layer.
The convolution layer accepts in the form <code>[batch, features, sequence]</code></p>
            </div>
            <div>
                <div><pre><span>90</span>        <span>mem</span> <span>=</span> <span>mem</span><span>.</span><span>permute</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>0</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-6">
            <div>
                
                <p>Get compressed memory by running it through the convolution layer</p>
            </div>
            <div>
                <div><pre><span>92</span>        <span>c_mem</span> <span>=</span> <span>self</span><span>.</span><span>conv</span><span>(</span><span>mem</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-7">
            <div>
                
                <p>Permute back to form <code>[seq_len, batch, d_model]</code></p>
            </div>
            <div>
                <div><pre><span>94</span>        <span>return</span> <span>c_mem</span><span>.</span><span>permute</span><span>(</span><span>2</span><span>,</span> <span>0</span><span>,</span> <span>1</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-8">
        <div>
                
                <h2>Compressive Transformer Layer</h2>
<p>This is the implementation of a single compressive transformer layer</p>
            </div>
            <div>
                <div><pre><span>97</span><span>class</span> <span>CompressiveTransformerLayer</span><span>(</span><span>Module</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-9">
        <div>
                
                <ul>
<li><code>d_model</code> is the token embedding size</li>
<li><code>self_attn</code> is the <a href="https://nn.labml.ai/transformers/xl/relative_mha.html">self attention module</a></li>
<li><code>feed_forward</code> is the <a href="https://nn.labml.ai/transformers/feed_forward.html">feed forward module</a></li>
<li><code>dropout_prob</code> is the probability of dropping out after self attention and FFN</li>
<li><code>compress</code> is the compression function $f_c$</li>
</ul>
            </div>
            <div>
                <div><pre><span>103</span>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>*</span><span>,</span>
<span>104</span>                 <span>d_model</span><span>:</span> <span>int</span><span>,</span>
<span>105</span>                 <span>self_attn</span><span>:</span> <span>RelativeMultiHeadAttention</span><span>,</span>
<span>106</span>                 <span>feed_forward</span><span>:</span> <span>FeedForward</span><span>,</span>
<span>107</span>                 <span>dropout_prob</span><span>:</span> <span>float</span><span>,</span>
<span>108</span>                 <span>compress</span><span>:</span> <span>Conv1dCompression</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-10">
            
            <div>
                <div><pre><span>116</span>        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
<span>117</span>        <span>self</span><span>.</span><span>compress</span> <span>=</span> <span>compress</span>
<span>118</span>        <span>self</span><span>.</span><span>size</span> <span>=</span> <span>d_model</span>
<span>119</span>        <span>self</span><span>.</span><span>self_attn</span> <span>=</span> <span>self_attn</span>
<span>120</span>        <span>self</span><span>.</span><span>feed_forward</span> <span>=</span> <span>feed_forward</span>
<span>121</span>        <span>self</span><span>.</span><span>dropout</span> <span>=</span> <span>nn</span><span>.</span><span>Dropout</span><span>(</span><span>dropout_prob</span><span>)</span>
<span>122</span>        <span>self</span><span>.</span><span>norm_self_attn</span> <span>=</span> <span>nn</span><span>.</span><span>LayerNorm</span><span>([</span><span>d_model</span><span>])</span>
<span>123</span>        <span>self</span><span>.</span><span>norm_ff</span> <span>=</span> <span>nn</span><span>.</span><span>LayerNorm</span><span>([</span><span>d_model</span><span>])</span></pre></div>
            </div>
        </div>
    <div id="section-11">
        <div>
                
                <p>Concatenate the normalized token embeddings with memory and compressed memory.</p>
<ul>
<li><code>z</code> is layer normalized token embeddings.</li>
<li><code>mem</code> and <code>c_mem</code> are memory and compressed memory (not normalized).</li>
</ul>
            </div>
            <div>
                <div><pre><span>125</span>    <span>def</span> <span>concat_memory</span><span>(</span><span>self</span><span>,</span> <span>z</span><span>:</span> <span>torch</span><span>.</span><span>Tensor</span><span>,</span> <span>mem</span><span>:</span> <span>Optional</span><span>[</span><span>torch</span><span>.</span><span>Tensor</span><span>],</span> <span>c_mem</span><span>:</span> <span>Optional</span><span>[</span><span>torch</span><span>.</span><span>Tensor</span><span>]):</span></pre></div>
            </div>
        </div>
    <div id="section-12">
            <div>
                
                <p>If there is no memory just return the token embeddings</p>
            </div>
            <div>
                <div><pre><span>134</span>        <span>if</span> <span>mem</span> <span>is</span> <span>None</span><span>:</span>
<span>135</span>            <span>return</span> <span>z</span></pre></div>
            </div>
        </div>
    <div id="section-13">
            <div>
                
                <p>If there are compressed memory concatenate that with memory</p>
            </div>
            <div>
                <div><pre><span>138</span>        <span>if</span> <span>c_mem</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
<span>139</span>            <span>mem</span> <span>=</span> <span>torch</span><span>.</span><span>cat</span><span>((</span><span>c_mem</span><span>,</span> <span>mem</span><span>),</span> <span>dim</span><span>=</span><span>0</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-14">
            <div>
                
                <p>Run the memory through the normalization layer</p>
            </div>
            <div>
                <div><pre><span>142</span>        <span>mem</span> <span>=</span> <span>self</span><span>.</span><span>norm_self_attn</span><span>(</span><span>mem</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-15">
            <div>
                
                <p>Concatenate normalized memory and normalized token embeddings</p>
            </div>
            <div>
                <div><pre><span>144</span>        <span>return</span> <span>torch</span><span>.</span><span>cat</span><span>((</span><span>mem</span><span>,</span> <span>z</span><span>),</span> <span>dim</span><span>=</span><span>0</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-16">
        <div>
                
                <ul>
<li><code>x</code> is a tensor of token level feature vectors of shape <code>[seq_len, batch_size, d_model]</code></li>
<li><code>mem</code> is a tensor of the past token level feature vectors (memory) of shape <code>[mem_len, batch_size, d_model]</code></li>
<li><code>c_mem</code> is a tensor of the compressed memory <code>[c_mem_len, batch_size, d_model]</code></li>
<li><code>mask</code> is a matrix of shape <code>[seq_len, c_mem_len + mem_len + seq_len, batch_size]</code> or <code>[seq_len, c_mem_len + mem_len + seq_len, 1]</code>.
<code>mask[i, j]</code> is  true if token at <code>i</code> can see token at <code>j</code>.</li>
</ul>
            </div>
            <div>
                <div><pre><span>146</span>    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>*</span><span>,</span>
<span>147</span>                <span>x</span><span>:</span> <span>torch</span><span>.</span><span>Tensor</span><span>,</span>
<span>148</span>                <span>mem</span><span>:</span> <span>Optional</span><span>[</span><span>torch</span><span>.</span><span>Tensor</span><span>],</span>
<span>149</span>                <span>c_mem</span><span>:</span> <span>Optional</span><span>[</span><span>torch</span><span>.</span><span>Tensor</span><span>],</span>
<span>150</span>                <span>mask</span><span>:</span> <span>torch</span><span>.</span><span>Tensor</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-17">
            <div>
                
                <p>Normalize the vectors before doing self attention</p>
            </div>
            <div>
                <div><pre><span>160</span>        <span>z</span> <span>=</span> <span>self</span><span>.</span><span>norm_self_attn</span><span>(</span><span>x</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-18">
            <div>
                
                <p>Normalize and concatenate memory and compressed memory</p>
            </div>
            <div>
                <div><pre><span>162</span>        <span>m_z</span> <span>=</span> <span>self</span><span>.</span><span>concat_memory</span><span>(</span><span>z</span><span>,</span> <span>mem</span><span>,</span> <span>c_mem</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-19">
            
            <div>
                <div><pre><span>164</span>        <span>self_attn</span> <span>=</span> <span>self</span><span>.</span><span>self_attn</span><span>(</span><span>query</span><span>=</span><span>z</span><span>,</span> <span>key</span><span>=</span><span>m_z</span><span>,</span> <span>value</span><span>=</span><span>m_z</span><span>,</span> <span>mask</span><span>=</span><span>mask</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-20">
            <div>
                
                <p>Add the attention results</p>
            </div>
            <div>
                <div><pre><span>166</span>        <span>x</span> <span>=</span> <span>x</span> <span>+</span> <span>self</span><span>.</span><span>dropout</span><span>(</span><span>self_attn</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-21">
            <div>
                
                <p>Normalize for feed-forward</p>
            </div>
            
        </div>
    <div id="section-22">
            <div>
                
                <p>Pass through the feed-forward network</p>
            </div>
            <div>
                <div><pre><span>171</span>        <span>ff</span> <span>=</span> <span>self</span><span>.</span><span>feed_forward</span><span>(</span><span>z</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-23">
            <div>
                
                <p>Add the feed-forward results back</p>
            </div>
            <div>
                <div><pre><span>173</span>        <span>x</span> <span>=</span> <span>x</span> <span>+</span> <span>self</span><span>.</span><span>dropout</span><span>(</span><span>ff</span><span>)</span></pre></div>
            </div>
        </div>
    
    <div id="section-25">
        <div>
                
                <h2>Compressive Transformer Model</h2>
<p>This consists of multiple compressive transformer layers</p>
            </div>
            <div>
                <div><pre><span>179</span><span>class</span> <span>CompressiveTransformer</span><span>(</span><span>Module</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-26">
            
            <div>
                <div><pre><span>186</span>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>layer</span><span>:</span> <span>CompressiveTransformerLayer</span><span>,</span> <span>n_layers</span><span>:</span> <span>int</span><span>):</span>
<span>187</span>        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span></pre></div>
            </div>
        </div>
    <div id="section-27">
            <div>
                
                <p>Make copies of the transformer layer</p>
            </div>
            <div>
                <div><pre><span>189</span>        <span>self</span><span>.</span><span>layers</span> <span>=</span> <span>clone_module_list</span><span>(</span><span>layer</span><span>,</span> <span>n_layers</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-28">
            <div>
                
                <p>Final normalization layer</p>
            </div>
            <div>
                <div><pre><span>191</span>        <span>self</span><span>.</span><span>norm</span> <span>=</span> <span>nn</span><span>.</span><span>LayerNorm</span><span>([</span><span>layer</span><span>.</span><span>size</span><span>])</span></pre></div>
            </div>
        </div>
    <div id="section-29">
        <div>
                
                <ul>
<li><code>x</code> is a tensor of the token embeddings vectors of shape <code>[seq_len, batch_size, d_model]</code></li>
<li><code>mem</code> is a list of tensors of the past token level feature vectors of shape
 <code>[mem_len, batch_size, d_model]</code> for each layer</li>
<li><code>c_mem</code> is a list of tensors of the compressed memory
 <code>[c_mem_len, batch_size, d_model]</code> for each layer</li>
<li><code>mask</code> is the masking matrix</li>
</ul>
            </div>
            <div>
                <div><pre><span>193</span>    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>x</span><span>:</span> <span>torch</span><span>.</span><span>Tensor</span><span>,</span> <span>mem</span><span>:</span> <span>List</span><span>[</span><span>torch</span><span>.</span><span>Tensor</span><span>],</span> <span>c_mem</span><span>:</span> <span>List</span><span>[</span><span>torch</span><span>.</span><span>Tensor</span><span>],</span> <span>mask</span><span>:</span> <span>torch</span><span>.</span><span>Tensor</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-30">
            <div>
                
                <p>List to store token level feature vectors,
which will become the memories for the next sequential batch.</p>
            </div>
            
        </div>
    <div id="section-31">
        â€¦</div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nn.labml.ai/transformers/compressive/index.html">https://nn.labml.ai/transformers/compressive/index.html</a></em></p>]]>
            </description>
            <link>https://nn.labml.ai/transformers/compressive/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26192005</guid>
            <pubDate>Fri, 19 Feb 2021 11:34:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Towards a sustainable solution to open source sustainability]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26191853">thread link</a>) | @polm23
<br/>
February 19, 2021 | https://speaking.unlockopen.com/5JrQdv/towards-a-sustainable-solution-to-open-source-sustainability | <a href="https://web.archive.org/web/*/https://speaking.unlockopen.com/5JrQdv/towards-a-sustainable-solution-to-open-source-sustainability">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div id="desc">
        <p>A few years ago, Heartbleed epitomized a massive open source sustainability problem for critical parts of the internet infrastructure. The bug, which affected the popular OpenSSL cryptographic software library, notably compromised the confidentiality of 4.5 million US patient records and cost the industry an estimated $500M.</p>
<p>It was soon revealed that the root-cause of the issue was that OpenSSL was precariously understaffed. Open source sustainability became a major theme overnight. Stories of maintainer burn-out made the headlines. And tentative solutions started to emerge, most of them donation-based.</p>
<p>In this talk weâ€™ll explore a number of existing strategies to fund open source and make it more sustainable, from patronage to dedicated ad networks. And weâ€™ll defend the idea that the best path to open source sustainability is to help companies understand the tangible business value they can get from contributing to open source.</p>

    </div>
</div></div>]]>
            </description>
            <link>https://speaking.unlockopen.com/5JrQdv/towards-a-sustainable-solution-to-open-source-sustainability</link>
            <guid isPermaLink="false">hacker-news-small-sites-26191853</guid>
            <pubDate>Fri, 19 Feb 2021 11:14:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenNebula EE Maintenance Release 5.12.8 is available]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26191673">thread link</a>) | @amarti
<br/>
February 19, 2021 | https://opennebula.io/opennebula-enterprise-edition-maintenance-release-v-5-12-8-is-available/ | <a href="https://web.archive.org/web/*/https://opennebula.io/opennebula-enterprise-edition-maintenance-release-v-5-12-8-is-available/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			    <!-- .entry-header -->

				
					
<article id="post-30088">

    <!-- .entry-header -->

    <div>

		<p>The <strong>Enterprise Edition</strong> of OpenNebula is a tested, hardened, and production-ready version that incorporates additional bug fixes and software patches with minor enhancements developed by OpenNebula Systems.</p>
<p>While we make all our products open source under Apache License Version 2.0, the packages of the<strong> Enterprise Edition</strong> and the <strong>Enterprise Tools</strong> weâ€™ve created for Corporate Users are distributed under commercial license terms only to those customers with an active <a href="https://opennebula.io/subscriptions" target="_blank" rel="noopener noreferrer">OpenNebula Subscription</a>.</p>
<p>The following <strong>new features</strong> has been backported to 5.12.8:</p>
<ul>
<li>Add option to disable raw section validation.</li>
</ul>
<p>The following <strong>issues</strong> has been solved in 5.12.8:</p>
<ul>
<li>Fix RAFT Race condition when node fail to become leader.</li>
<li>Fix update service cardinality when terminating a VM.</li>
<li>Fix set VCPU range on Sunstone.</li>
<li>Fix OneGate context attributes when update VM template on Sunstone.</li>
<li>Fix update of the host zombie VM list.</li>
<li>Fix alias IPs in service role VM on Sunstone.</li>
<li>Fix option to edit VCENTER_PASSWORD from Sunstone.</li>
<li>Fix VM disk monitor for shared storage datastores.</li>
<li>Fix IPs dropdown on VMs datatable.</li>
<li>Fix monitoring IPs on Sunstone.</li>
</ul>
<p>If you are a customer with an active<strong> OpenNebula Subscription</strong>, you have immediate access to the packages for this EE Maintenance Release. Please <strong>check your private repository</strong> at the <a href="https://support.opennebula.pro/" target="_blank" rel="noopener noreferrer">OpenNebula Customer Portal</a>.</p>




		
		


        <div>
            <p><img alt="" src="https://secure.gravatar.com/avatar/a1737e9efc6920480d8a1abc8d21fd64?s=96&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/a1737e9efc6920480d8a1abc8d21fd64?s=192&amp;d=mm&amp;r=g 2x" height="96" width="96" loading="lazy">            </p>
            <div>
                <p><span id="autorblog">Michael Abdou</span></p><p>Customer Success Manager at OpenNebula</p>
            </div>
        </div>
	</div><!-- .entry-content -->

</article><!-- #post-## -->

					
<!-- #comments -->

				
			</div></div>]]>
            </description>
            <link>https://opennebula.io/opennebula-enterprise-edition-maintenance-release-v-5-12-8-is-available/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26191673</guid>
            <pubDate>Fri, 19 Feb 2021 10:49:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to be more productive without forcing yourself]]>
            </title>
            <description>
<![CDATA[
Score 248 | Comments 120 (<a href="https://news.ycombinator.com/item?id=26191516">thread link</a>) | @vitabenes
<br/>
February 19, 2021 | https://www.deprocrastination.co/blog/how-to-be-productive-without-forcing-yourself | <a href="https://web.archive.org/web/*/https://www.deprocrastination.co/blog/how-to-be-productive-without-forcing-yourself">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p><img src="https://www.deprocrastination.co/assets/illustrations/work_bad_rect.png" referrerpolicy="no-referrer" alt="How to be more productive without forcing yourself"></p><p>Imagine you could work more and be wildly productive. And the best thing about it? You wouldnâ€™t need to force yourself to work.</p><p>There are people exactly like that who sit down and work without pushing themselves to do it. They even look forward to working. The good news is that you can learn to do it too.</p><p>Letâ€™s get to it.</p><p>Most people have a negative mindset about work. People see work as an annoyance that keeps them from doing whatever they really want to do. They also think that resting and having nothing to do is an ideal state theyâ€™d like to be in forever. This leads to thinking that you need to push yourself to work. You need to use willpower to get yourself to do it.</p><p>Itâ€™s simple to understand where this attitude comes from:</p><ol><li>People usually want things they donâ€™t have and think that grass is greener on the other side.</li><li>Everyone talks about how work is hard.</li><li>In comparison to dead-end or corporate jobs without impact or freedom, neverending leisure looks like paradise.</li></ol><p>In reality, most people who try to be in this nothing-to-do state for a long time become unhappy, depressed, and bored. Rich people who â€œmade itâ€ report how soon they become restless again.&nbsp;<a href="https://www.reddit.com/r/StopGaming/">People who game all the time</a>&nbsp;realize how empty it feels. Too much leisure isnâ€™t satisfying for long.</p><p>On the other hand, there is a certain group of people who work a lot and enjoy it. Letâ€™s call this group&nbsp;<em>producers</em>. By this, we donâ€™t mean workaholics who escape from their whole life by working all the time. Producers have a healthy work-life balance. So what do they do that people who hate work donâ€™t?</p><p>First, they tend to think about work differently.</p><p>For them, work is&nbsp;<a href="https://www.deprocrastination.co/blog/what-is-a-positive-feedback-loop-and-why-it-matters">a virtuous cycle of positive feedback loops</a>. Producers see&nbsp;<strong>work as a source of meaning and satisfaction</strong>. They see work as something that allows them to savor deserved leisure. They see rest as something that increases their life happiness and fuels their motivation towards work.</p><p>Second, their work is usually:</p><ul><li>Interesting</li><li>Meaningful</li><li>Well-defined</li></ul><p>If you check at least 1 or 2 boxes somehow, something magical happens:</p><p><strong>You donâ€™t have to push yourself towards work anymore.</strong></p><p>Well-defined, meaningful, and especially interesting work is easy to look forward to.</p><p>Non-producers often think that these producers are lucky because they stumbled upon work like this. In reality, producers often go a long way to make their work fun.</p><h2>How to make work more interesting</h2><p>This is the crucial factor in whether work gets done.</p><p>You donâ€™t have to see any meaning in your work for it to be interesting.</p><p>Even if the task is totally undefined, complex, and difficult, curiosity can carry you to its completion.</p><p>So how can you develop this curiosity towards work?</p><p>You have to give the work a chance to become interesting. How? By combining these 3 steps:</p><h3>1. Have less exposure towards super fun things</h3><p>Video games, surfing the internet, porn, alcohol, and drugs etc. make work significantly more difficult. Why?</p><p>They establish a certain standard of mental stimulation. Anything thatâ€™s not super fun will seem boring.</p><p><img src="https://www.deprocrastination.co/assets/illustrations/stimulation_standard.png" referrerpolicy="no-referrer" alt="We develop a Stimulation Standard"></p><p>Unfortunately, work often falls in the â€œfeels badâ€ category. In comparison to games or social media, work can feel uninteresting or annoying.</p><p><img src="https://www.deprocrastination.co/assets/illustrations/stimulation_work_distractions.png" referrerpolicy="no-referrer" alt="Switching from distractions to work is hard"></p><p>You might argue that there are people who work just fine even while drinking alcohol, playing video games etc.</p><p>However, consider that there are two types of people: ones who can moderate their consumption and others who canâ€™t. The latter society often describes as addicts.</p><p>Basically, if youâ€™re addicted to any of the high-dopamine, low-effort activity, please quit it. At least temporarily so you can reestablish a healthy relationship to work. The more experienced weâ€™re about the topic, the more obvious this is. There is no other way than to temporarily quit the addiction. If your vice is gaming, weâ€™ve covered&nbsp;<a href="https://www.deprocrastination.co/blog/should-i-quit-video-games">video gaming addiction here</a>.</p><p>Some can have a healthy relationship with, for example, gaming.</p><p>However, for some people gaming is kryptonite. Here are some signs that super-fun activities have a detrimental effect on your work:</p><ol><li>You rush and half-ass everything else in order to get to your super-fun activity.         When I (Mat) was addicted to gaming, everything during the day was half-assed so I could finally start playing.</li><li>You keep postponing or forgetting everything that isnâ€™t urgent in order to get to your super fun activity. You have this book that you want to read but you never get to actually reading it.</li><li>Your orderliness suffers once you start with the super fun activity.        Most people who come back to gaming report how their sense of orderliness starts to depreciate rather quickly. Their room gets messy, they start skipping workouts, stop meal-prepping, start eating more junk food, stop organizing their days.</li></ol><p>If the points above describe you, it might be time to quit your super fun activity. At least for a while.</p><p>Once your brain is not constantly hyper-stimulated, itâ€™s easier to find mundane activities like work or tidying more interesting.</p><h3>2. Get bored more often</h3><p>When you get bored, everything else becomes more interesting.</p><p>Donâ€™t believe us? Try this little experiment. Turn everything off. Set a timer for 15 minutes. Sit on a chair and stare at a wall. Donâ€™t move. Donâ€™t consume any information. Donâ€™t talk. Donâ€™t write anything down. Just stare at the wall.</p><p>Except for zen masters, most of us will become restless after a few minutes. Often, our brain starts dreaming and imagining things. For the first few minutes, you might feel alright, thinking about your day. However, after 5 or 10 minutes, youâ€™ll be itching to do something, anything really. Suddenly, creating a website, writing an article, or drawing a picture sounds like more interesting, more fun.</p><p><img src="https://www.deprocrastination.co/assets/illustrations/stimulation_work_boredom.png" referrerpolicy="no-referrer" alt="Switching from boredom to work is easier"></p><p>If you feel like you never stop scrolling and consume content all the time, schedule a 15 minute boredom window for tomorrow right before you want to start working.&nbsp;<a href="https://www.deprocrastination.co/blog/how-to-use-boredom-to-procrastinate-less">Use boredom strategically.</a></p><h3>3. Dive deep into a topic</h3><p>Itâ€™s fun when we can connect the dots. When we can draw new connections between ideas, we get a rush.&nbsp;<em>Oh, I can see how this historical event contributed to an uprisingâ€¦</em></p><p>The more connections we can draw within a topic, the more interested we become. This is what curiosity is all about.</p><p>If you take the time to watch a documentary related to what youâ€™re working on, read a book about it, or find a couple relevant articles. Youâ€™ll collect more dots to connect. Youâ€™ll see how everything fits together.</p><p>When you do feel like watching something or have a free evening, instead of watching random videos or reruns of old TV shows, steer your attention to something related to what you need to do.</p><p>Give yourself time to develop an interest.</p><h2>How to make work more meaningful</h2><p>It's hard to feel motivated when you don't have a personal reason to do something.</p><p>However, â€œmeaningful workâ€ has become something of a buzzword.</p><p>Everyone is trying to find meaning in their work. This can be wasted energy, especially if you work in a corporate or a dead-end job. We say this so you donâ€™t dwell on it and donâ€™t feel frustrated because you canâ€™t figure out how to save the world by doing what you do.</p><p>In any case, whatever your work is, you can make it meaningful enough to start.</p><p>Letâ€™s say you have to study for an exam. You donâ€™t find this particular class enjoyable. If you remind yourself why you chose to take the class and why studying is important for you, you will have an easier time persuading yourself to push through.</p><p>The fact is that some things simply need to be done. It's better if you find a compelling and personal reason to do them and get them over with as soon as possible, instead of putting them off forever.</p><p>When something is boring, ask yourself: Why do I need to do this? Find and reinforce the why behind the work.</p><h2>How to make work well-defined</h2><p>If you have a recipe that tells you step-by-step how to cook a meal, it is usually quite easy to follow. You know exactly where to start and how.</p><p>In todayâ€™s creative work, this often isnâ€™t the case. There are no recipes for the work we need to do, or they donâ€™t make the work any easier because the recipe would be too complex to understand.</p><p>Additionally, we often hamper our enthusiasm towards work by ourselves. How often do you find yourself with vague and unhelpful to-dos like â€œwrite the essayâ€ or â€œmake a video.â€</p><p>There are so many steps in â€œmake a videoâ€ that this vague task definition only causes anxiety and procrastination.</p><p>We always say that itâ€™s more difficult to start working than to keep working. Therefore we should make starting easier by defining well&nbsp;<em>how</em>&nbsp;to begin and&nbsp;<em>what</em>&nbsp;to begin with.</p><p>The better you can define how to start working, the easier itâ€™ll be to actually do it.</p><p>Basically, you do this in 3 steps:</p><h3>1. Always define exactly where youâ€™ll start</h3><p>This means you write down the next physical action to take.</p><p>Do you need to write an essay?</p><p>The next physical action is: Open the scientific study and start reading</p><p>Or: Create a document â†’ Create a rough draft in the next 15 minutes</p><p>Do you want to start learning coding?</p><p>The next physical action should be: Open freecodecamp.org â†’ Start solving the first challenge</p><p>It might sound silly to define the next physical action, but it isnâ€™t. Finding it is easy, and you can do it immediately.</p><p>Whatâ€™s the next physical action you need to take?</p><h3>2. Start with only having to work for 5/15 minutes</h3><p>You probably don't feel like creating a 20 slide presentation right now from scratch, and then presenting it in 2 hours.</p><p>You don't feel like writing a whole final thesis on a topic you barely know.</p><p>You don't feel like running a marathon.</p><p>But you might feel like looking up a couple pictures or articles for the presentation.</p><p>Or feel like writing a paragraph or two before lunch break.</p><p>Or feel like taking a 1km walk.</p><p>Those are the small steps along the longer journey.</p><p>We often underestimate the power of small steps, but they are essential because they help us get into the right routine.</p><p>If you start running a couple miles every other day, you'll get familiar with the routine and then you'll naturally want to start increasing the â€¦</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.deprocrastination.co/blog/how-to-be-productive-without-forcing-yourself">https://www.deprocrastination.co/blog/how-to-be-productive-without-forcing-yourself</a></em></p>]]>
            </description>
            <link>https://www.deprocrastination.co/blog/how-to-be-productive-without-forcing-yourself</link>
            <guid isPermaLink="false">hacker-news-small-sites-26191516</guid>
            <pubDate>Fri, 19 Feb 2021 10:27:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[German Physicist professor says evidence points to Covid escaped from lab]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 4 (<a href="https://news.ycombinator.com/item?id=26191355">thread link</a>) | @dominik-2020
<br/>
February 19, 2021 | https://www.uni-hamburg.de/newsroom/presse/2021/pm8.html | <a href="https://web.archive.org/web/*/https://www.uni-hamburg.de/newsroom/presse/2021/pm8.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><img alt="Prof. Dr. Roland Wiesendanger" src="https://assets.rrz.uni-hamburg.de/instance_assets/uni/15056328/wisendanger-733x414-screen-6a3135136ea4c8abccd4c1a6e9d4b3b49f85e7e1.jpg"></p><p>Foto: Sebastian Engels</p><p>Prof. Dr. Roland Wiesendanger</p></div><p>Seit mehr als einem Jahr sorgt das Coronavirus fÃ¼r eine weltweite Krise. In einer Studie hat nun der Nanowissenschaftler Prof. Dr. Roland Wiesendanger den Ursprung des Virus beleuchtet. Er kommt zu dem Ergebnis, dass sowohl die Zahl als auch die QualitÃ¤t der Indizien fÃ¼r einen Laborunfall am virologischen Institut der Stadt Wuhan als Ursache der gegenwÃ¤rtigen Pandemie sprechen.</p><p>Die Studie wurde im Zeitraum von Januar 2020 bis Dezember 2020 durchgefÃ¼hrt. Sie basiert auf einem interdisziplinÃ¤ren wissenschaftlichen Ansatz sowie auf einer umfangreichen Recherche unter Nutzung verschiedenster Informationsquellen. Hierzu gehÃ¶ren unter anderem wissenschaftliche Literatur, Artikel in Print- und Online-Medien sowie persÃ¶nliche Kommunikation mit internationalen Kolleginnen und Kollegen. Sie liefert keine hochwissenschaftlichen Beweise, wohl aber zahlreiche und schwerwiegende Indizien:</p>
<ul>
<li>Im Gegensatz zu frÃ¼heren Coronaviren-bedingten Epidemien wie SARS und MERS konnte bis heute, d. h. weit Ã¼ber ein Jahr nach Ausbruch der gegenwÃ¤rtigen Pandemie, kein Zwischenwirtstier identifiziert werden, welches die Ãœbertragung von SARS-CoV-2-Erregern von FledermÃ¤usen auf den Menschen ermÃ¶glicht haben kÃ¶nnte. Die Zoonose-Theorie als mÃ¶gliche ErklÃ¤rung fÃ¼r die Pandemie besitzt daher keine fundierte wissenschaftliche Grundlage.</li>
<li>Die SARS-CoV-2-Viren kÃ¶nnen erstaunlich gut an menschliche Zellrezeptoren ankoppeln und in menschliche Zellen eindringen. ErmÃ¶glicht wird dies durch spezielle Zellrezeptor-BindungsdomÃ¤nen verbunden mit einer speziellen (Furin-)Spaltstelle des Coronavirus-Zacken-Proteins. Beide Eigenschaften zusammen waren bislang bei Coronaviren nicht bekannt und weisen auf einen nicht-natÃ¼rlichen Ursprung des SARS-CoV-2-Erregers hin.</li>
<li>FledermÃ¤use wurden nicht auf dem in Verdacht geratenen Fischmarkt im Zentrum der Stadt Wuhan angeboten. Im virologischen Institut der Stadt Wuhan gibt es jedoch eine der weltweit grÃ¶ÃŸten Sammlungen von Fledermauserregern, welche von weit entfernten HÃ¶hlen in sÃ¼dchinesischen Provinzen stammen. Es ist extrem unwahrscheinlich, dass sich FledermÃ¤use aus dieser Entfernung von nahezu 2.000 km auf natÃ¼rliche Weise auf den Weg nach Wuhan begeben haben, um dann in unmittelbarer NÃ¤he dieses virologischen Instituts eine weltweite Pandemie auszulÃ¶sen.</li>
<li>Eine Forschungsgruppe am virologischen Institut der Stadt Wuhan hat Ã¼ber viele Jahre hinweg gentechnische Manipulationen an Coronaviren vorgenommen mit dem Ziel, diese fÃ¼r Menschen ansteckender, gefÃ¤hrlicher und tÃ¶dlicher zu machen. Dies ist in der wissenschaftlichen Fachliteratur durch zahlreiche Publikationen belegt.</li>
<li>Es existierten erhebliche SicherheitsmÃ¤ngel im virologischen Institut der Stadt Wuhan bereits vor Ausbruch der Coronavirus-Pandemie, welche dokumentiert sind.</li>
<li>Es gibt zahlreiche direkte Hinweise auf einen Laborursprung des SARS-CoV-2 Erregers. So soll sich eine junge Wissenschaftlerin des virologischen Instituts in Wuhan als erste infiziert haben. Es gibt ferner zahlreiche Hinweise darauf, dass sich bereits im Oktober 2019 der SARS-CoV-2 Erreger ausgehend von dem virologischen Institut in der Stadt Wuhan und darÃ¼ber hinaus verbreitet hat. Ferner gibt es Hinweise auf eine entsprechende Untersuchung des virologischen Instituts durch die chinesischen BehÃ¶rden in der ersten OktoberhÃ¤lfte 2019.&nbsp; &nbsp;</li>
</ul>
<p>&nbsp;â€Die gegenwÃ¤rtige Coronavirus-Pandemie beherrscht nicht nur die derzeitigen Schlagzeilen, sondern wird uns noch Ã¼ber viele Jahre hinweg beschÃ¤ftigen â€“ nicht zuletzt aufgrund der sozialen und wirtschaftlichen Auswirkungen. Seit Monaten steht verstÃ¤ndlicherweise der Umgang mit und die BewÃ¤ltigung von der Corona-Krise im Vordergrund der Themen in der Politik und in den Medien. Von groÃŸer Bedeutung ist jedoch schon heute die kritische wissenschaftsbasierte Auseinandersetzung mit der Frage nach dem Ursprung der derzeitigen Pandemie, denn nur auf Basis dieses Wissens kÃ¶nnen adÃ¤quate Vorkehrungen getroffen werden, die Wahrscheinlichkeit fÃ¼r das Auftreten Ã¤hnlicher Pandemien in Zukunft so klein wie mÃ¶glich zu haltenâ€œ, sagt Prof. Dr. Roland Wiesendanger.</p>
<p>Die Studie wurde im Januar 2021 fertiggestellt und zunÃ¤chst in Wissenschaftskreisen verteilt und diskutiert. Mit der VerÃ¶ffentlichung soll nun eine breit angelegte Diskussion angeregt werden, insbesondere im Hinblick auf die ethischen Aspekte der sogenannten â€gain-of-functionâ€œ-Forschung, welche Krankheitserreger fÃ¼r Menschen ansteckender, gefÃ¤hrlicher und tÃ¶dlicher macht. â€Dies kann nicht lÃ¤nger nur Angelegenheit einer kleinen Gruppe von Wissenschaftlerinnen und Wissenschaftlern bleiben, sondern muss dringend Gegenstand einer Ã¶ffentlichen Debatte werdenâ€œ, so der Autor der Studie.&nbsp;</p>
<p>Die Studie ist verÃ¶ffentlicht unter: <a href="http://doi.org/10.13140/RG.2.2.31754.80323" target="_blank">http://doi.org/10.13140/RG.2.2.31754.80323</a></p><p><a target="_blank" href="https://www.uni-hamburg.de/newsroom/presse/2021/pm8/pm-8-21.pdf">Pressemitteilung als PDF</a></p></div></div></div>]]>
            </description>
            <link>https://www.uni-hamburg.de/newsroom/presse/2021/pm8.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26191355</guid>
            <pubDate>Fri, 19 Feb 2021 10:00:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I made a PRORES-lookalike for Windows]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26191274">thread link</a>) | @CinematicStudio
<br/>
February 19, 2021 | https://cinematicstudio.app/blog/prores.html | <a href="https://web.archive.org/web/*/https://cinematicstudio.app/blog/prores.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
            <div>
                <div>
					
					<div>
					<h2>
					I made a PRORES-lookalike for Windows
					</h2>



					
					
					<h2>Preface â€“ What is PRORES?
					</h2>
					<p>
PRORES is a line of intermediate codecs, which means they are intended for use during video editing, and not for practical end-user viewing. Itâ€™s been developed by Apple, back in 2007 (<a href="https://en.wikipedia.org/wiki/Apple_ProRes" target="_blank">Wikipedia</a>).
</p>


					<h2>Why did I do it?
					</h2>
					<div><p>
There have been several reasons, but it all boils down to: I got very frustrated with the implementation of the Windows decoders when dealing with .mp4 (h264 and h265 codecs) â€“ which are pretty much 98% of all videos out there.<br>

Since Iâ€™m actually developing a <a href="https://cinematicstudio.app/" target="_blank">video editor</a>, when it comes to loading video frames in memory, you can:<br>
1. use <a href="https://docs.microsoft.com/en-us/uwp/api/windows.media.playback.mediaplayer?view=winrt-19041" target="_blank">MediaPlayer</a> class, from Microsoft<br>
2. use <a href="https://ffmpeg.org/" target="_blank">ffmpeg</a></p><p>


MediaPlayer is unreliable and slow <a href="#n1">[1]</a>. And, wait for it, it has Video RAM memory leaks <a href="#n2">[2]</a>.<br>

Using ffmpeg: Most advice on the internet â€“ whether you can use ffmpeg in a commercial app or not â€“ ends with â€œbut Iâ€™m not a lawyerâ€. I chose to avoid it, at least at the beginning <a href="#n3">[3]</a>. </p><p>

I initially went with using MediaPlayer. This frustrated me (and a lot of my users) a lot, making my app close to impossible to use in certain scenarios. Like, what if I want to play a video backwards, at 3x speed? What Iâ€™d do is cache that specific video segment ahead of time â€“ which not only did take a lot of RAM, but it also made my app show the â€œLoadingâ€ icon when you would press Play â€“ until I would pre-load all such segments.</p><p>

At some point I painfully realized: if I donâ€™t do something similar to PRORES, Iâ€™m screwed. Clearly, the first idea was â€“ what if I could use the codecs from Apple? Spoiler alert: you canâ€™t. <br>

So, what else could I do? Develop my own!

</p></div>





					<h2>Lets see the numbers!
					</h2>
					<div><p>
Well, I canâ€™t say it was easy to develop this. I had to get creative quite a few times. But once I realized thereâ€™s really no way around it, I stuck with it. And Iâ€™ve created some limitations, just to make sure frames will load up insanely fast.</p><p>

When you hit Play, the video project will strive to play at 60 frames / second â€“ even if your video project is 30 fps or something else. </p><p>

What this basically means, I have 16.66 milliseconds to load everything thatâ€™s needed (which if you have several video layers, means loading several video frames) and apply video effects on top of that. And, play the sound, of course.</p><p>

We can relax this requirement a bit, because even if the video project would play at 30 frames / second, it would still look smooth to you. So, I have 33.33 milliseconds tops to load all needed video frames and apply video effects on top of that.</p><p>

Applying video effects, such as blur, directional blur, masking, lighting takes an insane amount of time. By doing a lot of trial and error, I chose to do it like this â€“ I will show the video at 640 x 360 (no, itâ€™s not as low res as you may think <a href="#n4">[4]</a>). This will make frame loading very fast, and the video effects will be fast as well. I will improve upon this <a href="#n5">[5]</a>.</p><p>

Complicated video effects can take up to 5ms on a decent GPU. They take slightly longer on older GPUs, but itâ€™s still decent. It can take up to 9ms on an Nvidia Quadro M600M with 2GB of RAM (a 5-year old video card). Compounding video effects (several effects on top of each other) will be a bit harder <a href="#n6">[6]</a>.</p><p>

This still leaves us with 24.33 milliseconds to load video frames. In my tests, I load one video frame in 2ms on an Nvidia Geforce RTX 2070, and 3.45ms on Nvidia Quadro M600M. So, worst case scenario, I could still load 6-7 video frames in time for drawing them on-screen.</p><p>

One thing to note is that you will need a decent SSD for this to happen. Or, do a â€œsacrifice playâ€ â€“ basically hit Play, and this will be a bit slower the first time, so that Windows will be able to cache the video files in memory.
					
</p></div>


					<h2>Creating the PRORES-lookalike files
					</h2>
					<div><p>
When you import a video file, I will automatically create the PRORES-lookalike file. Thereâ€™s no point in using MediaPlayer until the PRORES-lookalike is complete â€“ it would drain further resources (Memory + CPU + GPU) with very little gains.</p><p>

One thing I do, while creating the PRORES-lookalike, I will keep in memory the first 3.5 minutes of the video, thus, you can still have a decent preview in real-time while Iâ€™m doing this.</p><p>

To give you the numbers, itâ€™s not something set in stone, it depends on the video Iâ€™m converting. It will range between 15-18 times faster than duration of the video on my Geforce RTX 2070 card. So for instance, it takes roughly 3:20 minutes to process a 1 hour video.</p></div>


					<h2>Behind the scenes
					</h2>
					<p>
What Iâ€™m doing is something remarkably simple, and after running a lot of tests, I realized itâ€™s enough, at least for now. Itâ€™s similar to <a href="https://en.wikipedia.org/wiki/Motion_JPEG" target="_blank">Motion JPEG</a>, with the difference that Iâ€™m in control 100%. In other words, I always get to decide when each video frame is loaded and how long it stays in memory.					
</p>


					<h2>Is this battle tested?
					</h2>
					<p>
Yes! Iâ€™ve had this in production since late September 2020. Iâ€™ve done a few tweaks along the way, but the core code is the same.</p>


					<h2>How does it compare with ffmpeg?
					</h2>
					<p>
My take is that itâ€™s 6-10 times faster. Iâ€™ve looked into it in the last few days, but I canâ€™t do a proper test just yet. Iâ€™ve used <a href="https://github.com/unosquare/ffmediaelement" target="_blank">FFMediaElement library</a> to do some testing, but I canâ€™t get it to use GPU (I did ask in the forum, will publish the results once I have them). At this time, for a 4K video, my results indicate processing a video frame takes 77ms on the CPU on my machine with the Geforce video card. I assume the GPU should be 5-7 times faster, thus it would likely take somewhere between 11-15ms, compared to 2ms for me.
</p>

					<h2>How does it compare with Apple PRORES?
					</h2>
					<div><p>
Honestly, I donâ€™t know. I would say it should be roughly on-par, since Iâ€™m pretty sure the underlying concepts should be similar. It may be that Apple might generate the PRORES files faster, Iâ€™m not sure. But accessing them, I would say we should see similar times.</p><p>

If anyone wants to test this â€“ youâ€™d need a machine with both MacOS and Windows 10 â€“ , drop me an email at <a href="mailto:cinematic@cinematicstudio.com">cinematic@cinematicstudio.com</a> I can easily allow turning on statistics that would show you the average video frame loading time.</p><p>

John @ Cinematic Studio</p></div>






					<h2>Notes
					</h2>
					<div>
<p>[1] For one thing, when you seek to a frame, youâ€™re not entirely sure youâ€™ve actually gotten there, in <b>VideoFrameAvailable</b> event â€“ because of how they internally do caching. So even if Microsoft tells you youâ€™re there, well youâ€™re not. To give you an example, say youâ€™re at position 10.5 seconds, and you want to go to position 20.1 seconds. When you receive the first 2-3 <b>VideoFrameAvailable</b> events, what you may get is frames at position 10.5 seconds, and at some point, youâ€™ll start receiving frames at position 20.1 seconds. </p><p>

In practice, Iâ€™ve found out that 5 frames seems to be a safe bet â€“ in other words, I would go to position 20.1 seconds â€“ 5 frames, then simply ignore the first 5 frames. Even though in practice I never met a case when you would still get an invalid frame after the first 5 frames, it doesnâ€™t really mean it canâ€™t happen. This gets even worse if you need to do several seeks at very small intervals.</p><p>

Thereâ€™s no way to go several frames ahead. You can only <b>StepForwardOneFrame()</b> and <b>StepBackwardOneFrame()</b>. In practice, going backward is roughly 5 times slower.</p><p>

Having several <b>MediaPlayer</b> instances doesnâ€™t help things either â€“ in practice, I noticed that the more instances I would have, the slower everything got.</p><p>

Sometimes, I would get an infinite amount of <b>VideoFrameAvailable</b> events, because, thatâ€™s how Microsoft rolls.

<a name="n2"></a></p><p>[2] Finally, <b>VideoFrameAvailable</b> has memory leaks. I found this out the hard way â€“ from one user being very, lets say, frustrated. At Export, within 60-70 seconds, it sometimes could end eating up 8GB of video RAM when dealing with 4K footage.

<a name="n3"></a></p><p>[3] Iâ€™ve pondered about using ffmpeg more times than I can count. </p><p>

Thereâ€™s a lot of mambo jambo about whether/how you can use this in commercial code, because MPEG LA holds the patent for it â€“ so even if you use your own implementation, youâ€™d still need to pay MPEG LA. It didn't really sit right with me. It's also unclear to me how they would figure out the number of "downloaded copies".</p><p>

Iâ€™ve done another round of searching lately, and Iâ€™m in talks with <a href="https://x264.org/en/" target="_blank">x264</a> It seems I need to  obtain a license from them, in order to compile ffmpeg to use LGPL (thus, be able to use it commercially) â€“ this would be on top of what I'd pay MPEG LA.</p><p>

I wonâ€™t get my hopes up until I receive a quote from them â€“ the fact that you need to request a quote makes me think theyâ€™ll do their best to milk you as much as possible.

<a name="n4"></a></p><p>[4] I can hear you screaming â€“ thatâ€™s sooo low res! Turns out itâ€™s not. If you come to think about it, most of the time the video takes less than Â¼ of the screen, the rest being occupied by the timeline, and other panes. And in the future, I will allow you to select a higher resolution, such as 1280 x 720, or simply 1920 x 1080 if youâ€™ve got some hard core video card.

<a name="n5"></a></p><p>[5] The next steps will be: once you settle on one video frame (you pause the project, and do some editing), to show the video frame at Full HD (1920 x 1080). Itâ€™s not as easy as youâ€™d think, but I can do it :) 

<a name="n6"></a></p><p>[6] The more video effects you compound (one video effect on top of another, on top of another, and so on), the more GPU is needed. One of the reasons I chose to go with 640 x 360 resolution is that this gives a quite reasonable number of compound effects that can be played in real time. On a decent video card, you wonâ€™t really need any pre-rendering ahead of time (which pretty much breaks your flow).
					
</p></div>
					
	
					</div>
                </div>
            </div>
        </section></div>]]>
            </description>
            <link>https://cinematicstudio.app/blog/prores.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26191274</guid>
            <pubDate>Fri, 19 Feb 2021 09:44:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Where Everything Went Wrong: Error Handling and Error Messages in Rust (2020)]]>
            </title>
            <description>
<![CDATA[
Score 148 | Comments 181 (<a href="https://news.ycombinator.com/item?id=26191006">thread link</a>) | @lukastyrychtr
<br/>
February 19, 2021 | https://msirringhaus.github.io/Where-everything-went-wrong/ | <a href="https://web.archive.org/web/*/https://msirringhaus.github.io/Where-everything-went-wrong/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><strong>Today you are frustrated.</strong></p>

<p>This is so annoying. YouÃ¢â‚¬â„¢ve written a Rust crate and now that you want to test it for the very first time, <em>it doesnÃ¢â‚¬â„¢t work!</em></p>

<p>Come on, Rust! How dare you? You promised that once one gets past the compiler, it.<br>
<em>Just.<br>
<strong>Works!</strong></em><br>
And now this!</p>

<p>Ok, ok. You calm yourself down. Lets start from the beginning. You want to create so called <a href="https://docs.sentry.io/platforms/native/guides/minidumps/">minidumps</a>. This is a file that contains information about a crashed program (like stacks of all threads, CPU registers, system info, etc.).
The minidump consists of various sections, such as the minidump header (including time of day, versions and basically a table of contents), a thread section (including all threads of the process and their stacks), memory mappings and libraries, etc. [Just to give some context, as all of this is actually not really important.]</p>

<p>For this, you created a <a href="https://github.com/msirringhaus/minidump_writer_linux">crate</a>. One section gets written after the other, while information about the targeted process is retrieved from the system. You even created a nice, simple API. You hand in a process ID and an open file, where the minidump should be written to. like this:</p>

<div><div><pre><code>    <span>MinidumpWriter</span><span>::</span><span>new</span><span>(</span><span>pid</span><span>,</span> <span>blamed_thread</span><span>)</span>
        <span>.dump</span><span>(</span><span>&amp;</span><span>mut</span> <span>dump_file</span><span>)</span>
        <span>.expect</span><span>(</span><span>"Dumping failed!"</span><span>)</span>
</code></pre></div></div>

<p>You can also hand in user specified memory regions that should be included in the dump, like so:</p>

<div><div><pre><code>    <span>let</span> <span>app_memory</span> <span>=</span> <span>AppMemory</span> <span>{</span>
        <span>ptr</span><span>:</span> <span>some_address</span><span>,</span>
        <span>length</span><span>:</span> <span>memory_size</span><span>,</span>
    <span>};</span>

    <span>MinidumpWriter</span><span>::</span><span>new</span><span>(</span><span>pid</span><span>,</span> <span>pid</span><span>)</span>
        <span>.set_app_memory</span><span>(</span><span>vec!</span><span>[</span><span>app_memory</span><span>])</span>
        <span>.dump</span><span>(</span><span>&amp;</span><span>mut</span> <span>tmpfile</span><span>)</span>
        <span>.expect</span><span>(</span><span>"Dumping failed"</span><span>);</span>
</code></pre></div></div>



<p>But when you run your nice library code in an application, you get <code>'Dumping failed: "Failed in ptrace::read: Sys(EIO)"'</code>.</p>

<p><em>How useless is that?!</em></p>

<p>Okay, maybe you could enhance your library error handling, a little. And by enhance, you mean Ã¢â‚¬Å“implement one in the first placeÃ¢â‚¬ï¿½.</p>

<h2 id="state-of-the-dart">State of the dart</h2>

<p>Your current approach is to define</p>

<div><div><pre><code><span>type</span> <span>Error</span> <span>=</span> <span>Box</span><span>&lt;</span><span>dyn</span> <span>error</span><span>::</span><span>Error</span> <span>+</span> <span>std</span><span>::</span><span>marker</span><span>::</span><span>Send</span> <span>+</span> <span>std</span><span>::</span><span>marker</span><span>::</span><span>Sync</span><span>&gt;</span><span>;</span>
<span>pub</span> <span>type</span> <span>Result</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>=</span> <span>result</span><span>::</span><span>Result</span><span>&lt;</span><span>T</span><span>,</span> <span>Error</span><span>&gt;</span><span>;</span>
</code></pre></div></div>

<p>and using <code>Result&lt;T&gt;</code> in all of your functions as the return value and handing all of them to the parent function using <code>?</code>. Thus the original error pierces through your callstack like a dart throughÃ¢â‚¬Â¦.jelly (Yes, you are good with words and you know it.).</p>

<div><div><pre><code>    <span>pub</span> <span>fn</span> <span>init</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>()</span><span>&gt;</span> <span>{</span>
        <span>self</span><span>.read_auxv</span><span>()</span><span>?</span><span>;</span>
        <span>self</span><span>.enumerate_threads</span><span>()</span><span>?</span><span>;</span>
        <span>self</span><span>.enumerate_mappings</span><span>()</span><span>?</span><span>;</span>
        <span>Ok</span><span>(())</span>
    <span>}</span>
</code></pre></div></div>

<p>In Rust parlance, this is also called bubbling up errors.</p>

<p>Usually, you just bubble up errors from libraries you use, but for the rare errors you have to define yourself, you currently just do</p>
<div><div><pre><code><span>Err</span><span>(</span><span>"Found no auxv entry"</span><span>.into</span><span>())</span>
</code></pre></div></div>

<p>Well, now you know there is an error, at least. And that it has <em>something</em> to do with your usage of <code>ptrace</code>. But you have no idea where that happens. You use that functionality in various places. Is it during the init-phase? During one of the sections? And if so, which one? What are you trying to read? And from where? Or in short: <strong>What is going on?!</strong></p>

<h2 id="shoes-off-get-some-tea-research-time">Shoes off, get some tea: Research time!</h2>

<p>Well, Rust has been around for quite some time now and they always boast about how error handling is a first class citizen and all that. So error handling should be a done deal, right? With a canonical way of dealing with errors, officially documented and all that should be right there, correct?</p>

<p>Oh boy, were you wrong.</p>

<p>Turns out, this is a very active field ofÃ¢â‚¬Â¦mhÃ¢â‚¬Â¦experimentation, lets say. There has been <a href="https://blog.yoshuawuyts.com/error-handling-survey/">a survey</a> recently, listing and quickly describing most the different libraries and ways for error handling that emerged, fallen out of favor, got forked, died anyways, got superseded, fallen out of favor again, etc.
And the opinions seem to change frequently, if you should use <code>error-chain</code> or <code>failure</code> or <code>fehler</code> or <code>snafu</code> or <code>thiserror</code> or <code>anyhow</code> or <code>eyre</code> orÃ¢â‚¬Â¦</p>

<p>You opened a can of hornets there, or whatever that saying is.</p>

<p>Then you find <a href="https://blog.rust-lang.org/inside-rust/2020/11/23/What-the-error-handling-project-group-is-working-on.html">this gem</a> and donÃ¢â‚¬â„¢t know if you should laugh or cry. Almost six years after Rust hit 1.0 an error handling project group is formed. Six. Years. <em>(heavy breathing)</em></p>

<p>Well, okay. At least they are sorting it out now. Problem is, you needÃ¢â‚¬Â¦.<em>SIX YEARS? Are you serious?</em>Ã¢â‚¬Â¦ahem, sorryÃ¢â‚¬Â¦Problem is, you need helpful error messages now.</p>

<p>After reading a few decent blogs on the topic (like <a href="http://www.sheshbabu.com/posts/rust-error-handling/">this</a> or <a href="https://nick.groenen.me/posts/rust-error-handling/">that</a>), there seems to emerge a consensus, at least for libraries: Return something that derives from <code>std::error::Error</code>. Either implement them by hand, or use a crate that does it for you, using macro magic. like <code>thiserror</code>. Which method you use depends on your level of laziness plus your patience regarding compile times.</p>

<h2 id="examples-vs-reality">Examples vs. Reality</h2>

<p>Another post highlighted <a href="https://doc.rust-lang.org/rust-by-example/error/multiple_error_types/wrap_error.html">error wrapping</a>, a particularly intriguing idea to you.</p>

<p>Unfortunately, all the articles have the understandable, but rather annoying tendency to use very simple example code for illustration purposes. Unrealistically simple, you might even say. They have callstacks of depth 1, return only three kinds of error in total in their API, and their errors are obvious and easily describable (e.g. Ã¢â‚¬Å“Input file XY not found in your Ã¢â‚¬Ëœcounting wordsÃ¢â‚¬â„¢ programÃ¢â‚¬ï¿½).</p>

<p>You have a more complicated callstack, with tons of different errors and code reuse in different places. For example, the function you think is to blame for the above error is <code>copy_from_process()</code>, which calls <code>ptrace::read()</code>, which probably returns something like <code>Failed in ptrace::read: Sys(EIO)</code>.
This function is used in multiple places in your code, e.g.:</p>

<div><div><pre><code>Ã¢â€Å“Ã¢â€â‚¬ init()
Ã¢â€â€š   Ã¢â€Å“Ã¢â€â‚¬ read_auxv()
Ã¢â€â€š   Ã¢â€â€š  Ã¢â€Å“Ã¢â€â‚¬ open(format!("/proc/{}/auxv", self.pid))
Ã¢â€â€š   Ã¢â€â€š  Ã¢â€â€Ã¢â€â‚¬ some_parsing()
Ã¢â€â€š   Ã¢â€Å“Ã¢â€â‚¬ ...
Ã¢â€â€š   Ã¢â€Å“Ã¢â€â‚¬ enumerate_mappings()
Ã¢â€â€š   Ã¢â€â€š  Ã¢â€Å“Ã¢â€â‚¬ open(format!("/proc/{}/maps", self.pid))
Ã¢â€â€š   Ã¢â€â€š  Ã¢â€â€Ã¢â€â‚¬ some_parsing()
Ã¢â€â€š   Ã¢â€â€š
Ã¢â€â€š   Ã¢â€â€Ã¢â€â‚¬ some_more_checks()
Ã¢â€â€š      Ã¢â€â€Ã¢â€â‚¬ copy_from_process()
Ã¢â€â€š
Ã¢â€â€Ã¢â€â‚¬ dump()
   Ã¢â€â€š
   Ã¢â€Å“Ã¢â€â‚¬ sections::header::write()
   Ã¢â€â€š
   Ã¢â€Å“Ã¢â€â‚¬ sections::thread_list_stream::write()
   Ã¢â€â€š  Ã¢â€â€Ã¢â€â‚¬ copy_from_process()
   Ã¢â€â€š
   Ã¢â€Å“Ã¢â€â‚¬ sections::mappings::write()
   Ã¢â€â€š  Ã¢â€â€Ã¢â€â‚¬ elf_identifier_for_mapping()
   Ã¢â€â€š     Ã¢â€â€Ã¢â€â‚¬ copy_from_process()
   Ã¢â€â€š
   Ã¢â€Å“Ã¢â€â‚¬ sections::app_memory::write()
   Ã¢â€â€š  Ã¢â€â€Ã¢â€â‚¬ copy_from_process()
   Ã¢â€â€š
   Ã¢â€â€Ã¢â€â‚¬ ...
</code></pre></div></div>

<p>Same goes for opening files, which happens in multiple places (two examples of which are shown in <code>init()</code>), so getting <code>FileNotFound</code> without context is going to be equally fun, and so on.</p>



<p>Wrapping errors still sounds like a nice idea, but one layer alone is not going to <del>wrap it</del> cut it.
Going with <code>copy_from_process()</code> as an example, you see a few possibilities:</p>
<ol>
  <li>Wrapping the <code>ptrace</code> error into an <code>CopyFromProcessError</code>, but that gives you nothing (except maybe some context, if you add some)</li>
  <li>With <code>InitError</code>s and <code>DumpingError</code>s that wrap the <code>ptrace</code> errors, you will still not know which section failed and why, but know if it was during <code>init()</code> or not.</li>
</ol>

<p>You might add context to option 2 as well (see below on how), but each section has a variety of reasons why it could fail. Some unique to the section, some shared among a few, some among all of them.</p>

<p>Complex problems sometimes require complex solutions, maybe?</p>

<h2 id="inc-err-ption">Inc <em>Err()</em> ption</h2>

<p>Using <code>thiserror</code> and the fabulous <code>#[from]</code> macro, you quickly define a plethora of errors and wrappers, starting from the deepest, darkest places in your callstack, wrapping your way up:</p>

<div><div><pre><code><span>#[derive(Debug,</span> <span>Error)]</span>
<span>pub</span> <span>enum</span> <span>PtraceDumperError</span> <span>{</span>
    <span>#[error(</span><span>"nix::ptrace() error"</span><span>)]</span>
    <span>PtraceError</span><span>(</span><span>#[from]</span> <span>nix</span><span>::</span><span>Error</span><span>),</span>
    <span>...</span>
<span>}</span>

<span>#[derive(Debug,</span> <span>Error)]</span>
<span>pub</span> <span>enum</span> <span>SectionAppMemoryError</span> <span>{</span>
    <span>#[error(</span><span>"Failed to copy memory from process"</span><span>)]</span>
    <span>CopyFromProcessError</span><span>(</span><span>#[from]</span> <span>PtraceDumperError</span><span>),</span>
    <span>...</span>
<span>}</span>

<span>#[derive(Debug,</span> <span>Error)]</span>
<span>pub</span> <span>enum</span> <span>DumpError</span> <span>{</span>
    <span>#[error(</span><span>"Error during init phase"</span><span>)]</span>
    <span>InitError</span><span>(</span><span>#[from]</span> <span>InitError</span><span>),</span>
    <span>#[error(transparent)]</span>
    <span>PtraceDumperError</span><span>(</span><span>#[from]</span> <span>PtraceDumperError</span><span>),</span>
    <span>#[error(</span><span>"Failed when writing section AppMemory"</span><span>)]</span>
    <span>SectionAppMemoryError</span><span>(</span><span>#[from]</span> <span>SectionAppMemoryError</span><span>),</span>
    <span>...</span>
</code></pre></div></div>

<p>The fun part is: You have to touch very little of your existing code, thanks to the automatic conversion from one error to the other, conveniently provided by <code>#[from]</code>:</p>
<div><div><pre><code><span>- pub fn init(&amp;mut self) -&gt; Result&lt;()&gt; {
</span><span>+ pub fn init(&amp;mut self) -&gt; Result&lt;(), InitError&gt; {
</span>     self.read_auxv()?;
     self.enumerate_threads()?;
     self.enumerate_mappings()?;
     Ok(())
 }
</code></pre></div></div>

<p>or</p>

<div><div><pre><code><span>- pub fn get_stack_info(&amp;self, int_stack_pointer: usize) -&gt; Result&lt;(usize, usize)&gt; {
</span><span>+ pub fn get_stack_info(&amp;self, int_stack_pointer: usize) -&gt; Result&lt;(usize, usize), DumperError&gt; {
</span> // snip

    let mapping = self
        .find_mapping(stack_pointer)
<span>-        .ok_or("No mapping for stack pointer found")?;
</span><span>+        .ok_or(DumperError::NoStackPointerMapping)?;
</span>    let offset = stack_pointer - mapping.start_address;
    let distance_to_end = mapping.size - offset;
  // snip
</code></pre></div></div>

<p>If you run your test binary again, you now get</p>
<div><div><pre><code>Failed when writing section AppMemory
</code></pre></div></div>
<p>which isÃ¢â‚¬Â¦.<em>(Throws a stack of papers from the desk)</em>Ã¢â‚¬Â¦short. Too short, and not that much more helpful, actually. Well, you know which section is failing. Thats good. But where are all the nice error messages you specified in your errors?</p>

<p>Hm, you do only use <code>println!("{}", error);</code>. Maybe <code>{:?}</code> is better?</p>
<div><div><pre><code>SectionAppMemoryError(CopyFromProcessError(PtraceError(Sys(EIO))))
</code></pre></div></div>

<p>Aha! Now you are getting somewhere! Tiny, tiny, painfully <strong>tiny</strong> steps, but you are getting somewhere! No error texts, but at least a chain!</p>

<p>Normal printing doesnÃ¢â‚¬â„¢t seem to recursively go through all the wrapped errors, but stop at the top most. For this, you need to either go through all the errors yourself by hand, or use a crate that does this for you. There are a number of them that provide this, but <code>anyhow</code> will do (its by the same author as <code>thiserror</code>, so interoperability shouldnÃ¢â‚¬â„¢t be an issue).</p>

<div><div><pre><code>    <span>println!</span><span>(</span><span>"{:#}"</span><span>,</span> <span>anyhow</span><span>::</span><span>Error</span><span>::</span><span>new</span><span>(</span><span>error</span><span>));</span>
</code></pre></div></div>

<p>aaaaand:</p>

<div><div><pre><code>Failed when writing section AppMemory: Failed to copy memory from process: nix::ptrace() error: EIO: I/O error
</code></pre></div></div>

<p><em>Collects papers from the â€¦</em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://msirringhaus.github.io/Where-everything-went-wrong/">https://msirringhaus.github.io/Where-everything-went-wrong/</a></em></p>]]>
            </description>
            <link>https://msirringhaus.github.io/Where-everything-went-wrong/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26191006</guid>
            <pubDate>Fri, 19 Feb 2021 08:57:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software Engineers struggle to write â€œchunksâ€ function]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26190554">thread link</a>) | @javaguy1
<br/>
February 18, 2021 | https://shekhargulati.com/2021/02/18/why-do-software-engineers-struggle-to-write-chunks-function/ | <a href="https://web.archive.org/web/*/https://shekhargulati.com/2021/02/18/why-do-software-engineers-struggle-to-write-chunks-function/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-6533">
	<!-- .entry-header -->

	
	
	<div>
		
<p>In the last couple of years, I took close to two hundred interviews. These interviews range from Java engineers with two years of experience to architects holding more than fifteen years of experience. The first round of our interview process, irrespective of the candidate experience, involves solving a small problem in a Google document.&nbsp;</p>



<p>I prefer Google docs because it removes the unnecessary fluff and most candidates are familiar with it. I understand that you may feel awkward and conscious when someone watches you while you are writing code. At the same time, it does give some understanding on how candidates keep calm under pressure, recover from their mistakes, and explain things.</p>



<p>I donâ€™t expect people to write completely syntactically correct formatted code in Google docs. I give them 20 minutes of peaceful time to write the program. I once read that in other tech organizations, it is expected that you explain your approach and your thinking as you write code on a whiteboard (virtual or physical), but I prefer to give people an uninterrupted time so that they donâ€™t have to do two things at a time. I try to make sure that they have understood the problem by giving them a couple of inputs and their expected output.&nbsp;</p>



<p>One question that I have used in most of our L1 interview rounds is shown below. Since 2021 I have stopped using this question so I thought it can be useful to share my analysis on how people performed in attempting this problem.</p>



<p><strong><em>You have to write a function that chunks an array into smaller arrays of specified size. For example, chunks([1,2,3,4,5] , 2) should return [[1,2],[3,4], [5]].</em></strong></p>



<p>Coming up with your own â€œFizz Buzz Testâ€[1] is not easy. I came up with the following requirements on which I evaluate such coding questions [2].</p>



<ol><li>It should be a real problem. The kind of problem you solve in a real-world scenario.</li><li>It should feel simple and give confidence to the developer that they can solve it.</li><li>The solution should not require more than 20 lines of code.</li><li>The problem should not be domain specific that it gives advantage to some candidates.</li><li>It should not require any special data structure, which you donâ€™t use in your day to day work.</li><li>Problem should not have a long text. Anyone should be able to read the problem text in less than a minute.</li><li>It should not require knowledge of a special library function.</li><li>A reasonable developer should be able to write the first version in 15-20 minutes. Candidates do tend to miss a few aspects of the problem, so it can involve more than one iteration.</li></ol>



<p><strong><em>I have used this question for evaluating Java candidates only. It is possible that it is not a good question for your specific programming language. So, please keep </em></strong><strong><em>this point </em></strong><strong><em>in </em></strong><strong><em>your</em></strong><strong><em> mind.</em></strong></p>



<p>There are three skills that I am trying to evaluate about the candidate.</p>



<ol><li>Can they code?</li><li>Can they explain the code they have written?</li><li>Can they explain how they will test the code they have written?</li></ol>



<p>Coming back to the chunks problem, one possible Java solution is shown below.</p>


<pre title="">public static int[][] chunks(int[] numbers, int chunkSize) {
   int length = numbers.length;
   int resultArraySize = (length % chunkSize == 0) ? length / chunkSize : length / chunkSize + 1;
   int[][] result = new int[resultArraySize][];
 
   int numberArrIndex = 0;
   for (int i = 0; i &lt; resultArraySize; i++) {
       int chunkArraySize = i == resultArraySize - 1 &amp;&amp; (length % chunkSize != 0)
               ? length % chunkSize
               : chunkSize;
 
       int[] chunk = new int[chunkArraySize];
 
       for (int j = 0; j &lt; chunkArraySize; j++) {
           chunk[j] = numbers[numberArrIndex++];
       }
       result[i] = chunk;
   }
   return result;
}
</pre>


<p>Java 8 solution using the Stream API is shown below. I donâ€™t expect candidates to write this version.</p>


<pre title="">public static int[][] chunk(int[] numbers, int size) {
   return IntStream.iterate(0, i -&gt; i + size)
           .limit((long) Math.ceil((double) numbers.length / size))
           .mapToObj(cur -&gt; Arrays.copyOfRange(numbers, cur, cur + size &gt; numbers.length ? numbers.length : cur + size))
           .toArray(int[][]::new);
}
</pre>


<p>My analysis is that only 10% of the total candidates solved the problem correctly in the first attempt. 30-40% missed a few scenarios and while explaining the solution they figured out the gaps and suggested improvements to fix their first version. And, remaining 50% failed to write even the partially correct first version.&nbsp;</p>



<p>Following are my observations on the attempts made by people:</p>



<ul><li>Candidates for some reason choose a function name different from chunks. I fail to understand why they donâ€™t use function name as chunks. Some of the names used by candidates <em>getSmallArray</em>, <em>getChunksArray</em>, <em>getMeArray</em>, <em>getRefactorArray</em>, <em>getChunks</em>, <em>splitArrayInChunks</em>, <em>convertArray</em>, <em>splitArray</em>, <em>chunkInputArray</em>, etc.</li><li>Candidates who did well in the attempt first wrote chunks algorithm in plain English and then attempted to write code.</li><li>Candidates struggled to come up with the correct function declaration in the first go. They directly wrote the first version of the problem and then came up with the correct declaration.</li><li>Many candidates struggled with multi-dimensional array syntax.&nbsp;</li><li>The first solution written by most candidates didnâ€™t handle the last chunk correctly. They created all chunks with equal size. So, the answer returned by their solution is [[1,2], [3,4], [5,0]]. Some candidates while explaining the solution with the example input figured out the problem and explained how they will handle this scenario.</li><li>Candidates struggled with the size of the result array. They need to consider whether the array is fully divisible by chunkSize or leaves a remainder.</li><li>Some candidates at times used String. They failed to make much progress.</li><li>Candidates make chunks an instance method of some class. They donâ€™t think whether they should make the method static. For some reason, they think static is bad.</li><li>Some candidates prefer to convert an array to a List and then only they can write code.&nbsp;</li><li>Java developers still struggle with Generics. Only a handful of them were able to convert the program to a version that uses generics.</li><li>Only a handful of developers can eloquently explain the code they have written.&nbsp;</li></ul>



<p>By no means I am underestimating the pressure of giving an interview. Both taking a good interview and giving an interview are difficult. I know it is hard for most of us to write code when someone is watching us in an interview. But, given that this is the kind of code we write everyday and we do have to pair with others. I think it is still a better and scalable way to filter good candidates from average candidates.&nbsp;</p>



<h2>References</h2>



<ol><li>Fizz Buzz Test â€“ <a href="https://wiki.c2.com/?FizzBuzzTest">Link</a></li><li>Picking problems for programming interviews â€“ <a href="https://lethain.com/appropriate-programming-problems/">Link</a></li></ol>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://shekhargulati.com/2021/02/18/why-do-software-engineers-struggle-to-write-chunks-function/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26190554</guid>
            <pubDate>Fri, 19 Feb 2021 07:18:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Write and Read Google Spreadsheet from Telegram Bot with Google Cloud Functions]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26190430">thread link</a>) | @fazlerocks
<br/>
February 18, 2021 | https://xakpc.info/write-and-read-google-spreadsheet-from-telegram-bot-with-google-cloud-functions | <a href="https://web.archive.org/web/*/https://xakpc.info/write-and-read-google-spreadsheet-from-telegram-bot-with-google-cloud-functions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1613670455547/FEONztOOP.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=compress"><div><div itemprop="text"><p>Recently I faced a request</p>
<blockquote>
<p>I'm tracking the number of days off each person in my company in google sheets, where I manually add/subtract their remaining days off. Can a telegram bot show them how many days off they have left once they search for their names?</p>
</blockquote>
<p>The answer is yes, and here is how to do that with Google Cloud Functions and API.chat chatbot platform in <strong>under 100 lines of code</strong>.</p>
<h2 id="setup-google-functions">Setup Google Functions</h2>
<p>First, you need to set up cloud functions and give them access to our document. </p>
<p>Overall you will need two functions: <code>gsheet-get</code> to provide answers and <code>gsheet-add</code> to register users. Let's create them.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1613663747484/Fas9Hx7_q.png?auto=compress" alt="image.png"></p>
<p>We do not care about the function code yet. When you set up the first function GCloud will probably ask you to enable Billing and, most importantly, will create a Service account - App Engine default service account. Usage of this account will allow you to perform <a target="_blank" href="https://github.com/googleapis/google-api-nodejs-client#service-account-credentials">server to server, app-level authentication</a>  later.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1613663799653/PyiIOpK2x.png?auto=compress" alt="image.png"></p>
<p>But you do need to give access rights to our document to this account.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1613662238923/jaVl7Falj.png?auto=compress" alt="image.png"></p>
<p>The document itself is quite simple 
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1613663879198/fqWuUfk7H.png?auto=compress" alt="image.png"></p>
<h2 id="function-google-sheet-add">Function <code>google-sheet-add</code></h2>
<p>This function will store the user channel (telegram in the case), chat id, and a name to your table. Google Functions support different languages, including <code>.net core 3.1</code>, but I found out that node.js gives more compact code, so let's stick to it, and sorry for <em>dotnetish</em> code-style</p>
<pre><code><span>const</span> { google } = <span>require</span>(<span>'googleapis'</span>);

<span>exports</span>.main = <span>async</span> (req, res) =&gt; {
  <span>let</span> auth = <span>await</span> google.auth.getClient({ <span>scopes</span>: [<span>'https://www.googleapis.com/auth/spreadsheets'</span>] });  
  <span>let</span> sheets = google.sheets({ <span>version</span>: <span>'v4'</span>, auth });
  <span>try</span>
  {
    <span>await</span> sheets.spreadsheets.values.append({
      <span>spreadsheetId</span>: <span>"INSERT-SHEET-ID-HERE"</span>,
      <span>range</span>: <span>"Days!A:C"</span>,
      <span>valueInputOption</span>: <span>"RAW"</span>,
      <span>insertDataOption</span>: <span>"INSERT_ROWS"</span>,
      <span>resource</span>: {
        <span>values</span>: [
          [req.query.channel, req.query.id, req.query.name]
        ],
      },
      <span>auth</span>: auth
    });    
    res.status(<span>200</span>).send();
  }
  <span>catch</span> (err)
  {
    res.status(<span>500</span>).send({ err })
  }
};
</code></pre>
<p>The code here will append provided values as a new row to the Days sheet. API.chat will provide user data such as channel, chat id, and the name of the user.</p>
<p>Don't forget to add <code>googleapis</code> dependency into <code>package.json</code></p>
<pre><code>{
  <span>"dependencies"</span>: {
    <span>"googleapis"</span>: <span>"^42"</span>
  }
}
</code></pre><p>The main need for this function is to match actual people with their telegram account. There could be more sophisticated ways to do this, but for now this simple way: ask user name - is enough.</p>
<p>That will give you all the required information about the user and you could start calculating his day-offs.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1613665878737/i_tzh-dEv.png?auto=compress" alt="image.png"></p>
<h2 id="function-google-sheet-get">Function <code>google-sheet-get</code></h2>
<p>The second function is for getting data from Google Spreadsheet. </p>
<pre><code><span>const</span> { google } = <span>require</span>(<span>'googleapis'</span>);

<span>exports</span>.main = <span>async</span> (req, res) =&gt; {
  <span>const</span> chatId = req.query.id;
  <span>const</span> auth = <span>await</span> google.auth.getClient({ <span>scopes</span>: [<span>'https://www.googleapis.com/auth/spreadsheets'</span>] });  
  <span>const</span> sheets = google.sheets({ <span>version</span>: <span>'v4'</span>, auth });
  <span>try</span> 
  {
    <span>let</span> sheet = <span>await</span> sheets.spreadsheets.values.get({
      <span>spreadsheetId</span>: <span>'INSERT-SHEET-ID-HERE'</span>,
      <span>range</span>: <span>'Days!A:D'</span>
    });

    <span>const</span> rows = sheet.data.values;
    <span>if</span> (rows.length) {
      <span>let</span> finded = rows.find(<span><span>el</span> =&gt;</span> el[<span>1</span>] === chatId)      
      <span>if</span> (finded === <span>undefined</span>) {     
        res.status(<span>200</span>).send({ <span>CorrelationId</span>: req.query.request, <span>Messages</span>: [ <span>"Information not availible"</span> ] });
      } <span>else</span> {      
        res.status(<span>200</span>).send({ <span>CorrelationId</span>: req.query.request, <span>Messages</span>: [ <span>`You have <span>${finded[<span>3</span>]}</span> days off`</span> ] });
      }
    } <span>else</span> {
      <span>console</span>.warn(<span>'No data found.'</span>);
      res.status(<span>200</span>).send({ <span>CorrelationId</span>: req.query.request, <span>Messages</span>: [ <span>"No data found"</span> ] });
    }
    res.status(<span>200</span>).send();
  }
  <span>catch</span>  (err)
  {
    <span>console</span>.error(<span>'The API returned an error: '</span> + err)
    res.status(<span>500</span>).send({ err })
  }
};
</code></pre><p>The main thing I found out here is that google.sheets API filter does not allow you to filter on actual data - only on metadata. That's why you need to get the entire sheet and filter it in code. Like I said before, API.chat will provide your endpoint with chat-id for filtering. From there you can return a formatted string with the answer like that</p>
<pre><code>{
  <span>"Messages"</span>: [
    <span>"You have 7 days off"</span>
  ]
}
</code></pre><h2 id="chatbot-scenario">Chatbot Scenario</h2>
<p>Now when you have all endpoints in place and working you can create an actual chatbot. I will use my very own <a target="_blank" href="https://api.chat/">chatbot builder API.chat</a>. Scenario might be very simple, like that </p>
<pre><code><span>&lt;<span>bot</span>&gt;</span>
  <span>&lt;<span>states</span>&gt;</span>
    <span>&lt;<span>state</span> <span>name</span>=<span>"Start"</span>&gt;</span>
      <span>&lt;<span>transition</span> <span>input</span>=<span>"register"</span> <span>next</span>=<span>"Registration"</span>&gt;</span>Please enter your name<span>&lt;/<span>transition</span>&gt;</span>
      <span>&lt;<span>transition</span> <span>input</span>=<span>"*"</span> <span>next</span>=<span>"Start"</span> <span>pending_keyboard</span>=<span>"Register Me"</span>&gt;</span>Hello. Please Register first<span>&lt;/<span>transition</span>&gt;</span>      
    <span>&lt;/<span>state</span>&gt;</span>
    <span>&lt;<span>state</span> <span>name</span>=<span>"Registration"</span>&gt;</span>      
      <span>&lt;<span>transition</span> <span>input</span>=<span>"*"</span> <span>next</span>=<span>"Registered"</span> <span>morphology</span>=<span>"msg"</span> <span>action</span>=<span>"https://us-central1-REDACTED.cloudfunctions.net/gsheet-add?name={msg}"</span> <span>no_stop</span>=<span>"true"</span>&gt;</span>Welcome!<span>&lt;/<span>transition</span>&gt;</span>
    <span>&lt;/<span>state</span>&gt;</span>
    <span>&lt;<span>state</span> <span>name</span>=<span>"Registered"</span>&gt;</span>
      <span>&lt;<span>transition</span> <span>input</span>=<span>"days"</span> <span>next</span>=<span>"Registered"</span> <span>action</span>=<span>"https://us-central1-REDACTED.net/gsheet-get"</span> <span>pending_keyboard</span>=<span>"Days Off"</span>/&gt;</span>
      <span>&lt;<span>transition</span> <span>input</span>=<span>"*"</span> <span>next</span>=<span>"Registered"</span> <span>pending_keyboard</span>=<span>"Days Off"</span>&gt;</span>Press the button to get your Days off<span>&lt;/<span>transition</span>&gt;</span>
    <span>&lt;/<span>state</span>&gt;</span>
  <span>&lt;/<span>states</span>&gt;</span>
<span>&lt;/<span>bot</span>&gt;</span>
</code></pre><p>What we do here is register the user, asking his or her name, and pass it into <code>gsheet-add</code> action in query. After registration user stays in the <code>Registered</code> state forever with the ability to request their days-off through <code>gsheet-get</code> action at any time.</p>
<p>All that's left is to PUT this scenario to the chatbot scenario endpoint and our bot is ready to deliver.</p>
<pre><code>curl -v -X PUT "https://bot.api.chat/v1/bots/botName/scenario"
-H "Content-Type: application/xml"
-H "Cache-Control: no-cache"
-H "Ocp-Apim-Subscription-Key: REDACTED"
--data-raw '<span>&lt;<span>bot</span>&gt;</span>
  <span>&lt;<span>states</span>&gt;</span>
    <span>&lt;<span>state</span> <span>name</span>=<span>"Start"</span>&gt;</span>
      <span>&lt;<span>transition</span> <span>input</span>=<span>"register"</span> <span>next</span>=<span>"Registration"</span>&gt;</span>Please enter your name<span>&lt;/<span>transition</span>&gt;</span>
      <span>&lt;<span>transition</span> <span>input</span>=<span>"*"</span> <span>next</span>=<span>"Start"</span> <span>pending_keyboard</span>=<span>"Register Me"</span>&gt;</span>Hello. Please Register first<span>&lt;/<span>transition</span>&gt;</span>      
    <span>&lt;/<span>state</span>&gt;</span>
    <span>&lt;<span>state</span> <span>name</span>=<span>"Registration"</span>&gt;</span>      
      <span>&lt;<span>transition</span> <span>input</span>=<span>"*"</span> <span>next</span>=<span>"Registered"</span> <span>morphology</span>=<span>"msg"</span> <span>action</span>=<span>"https://us-central1-REDACTED.cloudfunctions.net/gsheet-add?name={msg}"</span> <span>no_stop</span>=<span>"true"</span>&gt;</span>Welcome!<span>&lt;/<span>transition</span>&gt;</span>
    <span>&lt;/<span>state</span>&gt;</span>
    <span>&lt;<span>state</span> <span>name</span>=<span>"Registered"</span>&gt;</span>
      <span>&lt;<span>transition</span> <span>input</span>=<span>"days"</span> <span>next</span>=<span>"Registered"</span> <span>action</span>=<span>"https://us-central1-REDACTED.cloudfunctions.net/gsheet-get"</span> <span>pending_keyboard</span>=<span>"Days Off"</span>/&gt;</span>
      <span>&lt;<span>transition</span> <span>input</span>=<span>"*"</span> <span>next</span>=<span>"Registered"</span> <span>pending_keyboard</span>=<span>"Days Off"</span>&gt;</span>Press the button to get your Days off<span>&lt;/<span>transition</span>&gt;</span>
    <span>&lt;/<span>state</span>&gt;</span>
  <span>&lt;/<span>states</span>&gt;</span>
<span>&lt;/<span>bot</span>&gt;</span>'
</code></pre><p>Let's count code lines</p>
<ul>
<li><code>google-sheet-add</code>: 25</li>
<li><code>google-sheet-get</code>: 30</li>
<li><code>scenario</code>: 15</li>
<li><strong>overall</strong>: 70 lines of code</li>
</ul>
<p>Not bad</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://xakpc.info/write-and-read-google-spreadsheet-from-telegram-bot-with-google-cloud-functions</link>
            <guid isPermaLink="false">hacker-news-small-sites-26190430</guid>
            <pubDate>Fri, 19 Feb 2021 06:48:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Universal Warrior, Part III: The Cult of the Badass]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26190353">thread link</a>) | @parsecs
<br/>
February 18, 2021 | https://acoup.blog/2021/02/19/collections-the-universal-warrior-part-iii-the-cult-of-the-badass/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2021/02/19/collections-the-universal-warrior-part-iii-the-cult-of-the-badass/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://acoup.blog/2021/02/19/collections-the-universal-warrior-part-iii-the-cult-of-the-badass/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26190353</guid>
            <pubDate>Fri, 19 Feb 2021 06:29:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Anjuna Support for Amazon Nitro Enclaves]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26189898">thread link</a>) | @boxstream
<br/>
February 18, 2021 | https://www.anjuna.io/amazon-nitro-enclaves | <a href="https://web.archive.org/web/*/https://www.anjuna.io/amazon-nitro-enclaves">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.anjuna.io/amazon-nitro-enclaves</link>
            <guid isPermaLink="false">hacker-news-small-sites-26189898</guid>
            <pubDate>Fri, 19 Feb 2021 04:52:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LED Characterization]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26189817">thread link</a>) | @parsecs
<br/>
February 18, 2021 | https://blog.jaseg.de/posts/led-characterization/ | <a href="https://web.archive.org/web/*/https://blog.jaseg.de/posts/led-characterization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://blog.jaseg.de/posts/led-characterization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26189817</guid>
            <pubDate>Fri, 19 Feb 2021 04:38:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[12 requests per second: A realistic look at Python web frameworks]]>
            </title>
            <description>
<![CDATA[
Score 473 | Comments 227 (<a href="https://news.ycombinator.com/item?id=26188765">thread link</a>) | @gilad
<br/>
February 18, 2021 | https://suade.org/dev/12-requests-per-second-with-python/ | <a href="https://web.archive.org/web/*/https://suade.org/dev/12-requests-per-second-with-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://suade.org/dev/12-requests-per-second-with-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26188765</guid>
            <pubDate>Fri, 19 Feb 2021 02:21:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dismantling Racism in Mathematics Instruction [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26188717">thread link</a>) | @kofejnik
<br/>
February 18, 2021 | https://equitablemath.org/wp-content/uploads/sites/2/2020/11/1_STRIDE1.pdf | <a href="https://web.archive.org/web/*/https://equitablemath.org/wp-content/uploads/sites/2/2020/11/1_STRIDE1.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://equitablemath.org/wp-content/uploads/sites/2/2020/11/1_STRIDE1.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26188717</guid>
            <pubDate>Fri, 19 Feb 2021 02:15:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[5-MeO-DMT: The Story Behind the 'â€œGod Moleculeâ€ (2020)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26188612">thread link</a>) | @mardiyah
<br/>
February 18, 2021 | https://doubleblindmag.com/5-meo-dmt-the-story-behind-the-god-molecule/ | <a href="https://web.archive.org/web/*/https://doubleblindmag.com/5-meo-dmt-the-story-behind-the-god-molecule/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://doubleblindmag.com/5-meo-dmt-the-story-behind-the-god-molecule/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26188612</guid>
            <pubDate>Fri, 19 Feb 2021 02:03:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Squad: Forth on Chip-8]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 8 (<a href="https://news.ycombinator.com/item?id=26188165">thread link</a>) | @RodgerTheGreat
<br/>
February 18, 2021 | https://internet-janitor.itch.io/squad | <a href="https://web.archive.org/web/*/https://internet-janitor.itch.io/squad">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Squad</h2>
<p>Squad is a <a href="https://en.wikipedia.org/wiki/Forth_(programming_language)" rel="nofollow noopener">Forth</a> interpreter that runs on the <a href="https://en.wikipedia.org/wiki/CHIP-8" rel="nofollow noopener">SCHIP</a> virtual machine. It extends the 8-bit operations of this host machine to 16 bit "cells", per tradition, which also allows pointers to be easily transported and manipulated on the stacks. The parameter and return stacks have room for 32 cells apiece, and at startup there is a bit over 1kb of free space available for user definitions.</p>
<p>While many niceties are missing from the built-in lexicon, due to space constraints, Squad is a fairly complete Forth environment, with a conventional outer and inner interpreter, immediate words, and a mutable return stack.&nbsp;Squad's functionality compares favorably to&nbsp;<a href="https://github.com/JohnEarnest/chip8Archive/blob/master/src/applejak" rel="nofollow noopener"></a><a href="https://internet-janitor.itch.io/applejak">Applejak</a>&nbsp;and&nbsp;<a href="https://internet-janitor.itch.io/bulb">Bulb</a>.</p>
<p>Dictionary entries consist of a pointer to the previous entry (or 0 for the root entry), a "type" cell (see "&gt;type") which distinguishes immediate words with its high byte and word classes with its low byte, the name of the word as a string (see "&gt;name"), and the body of the word itself (see "&gt;body"). Strings are represented with a custom encoding in which each character is a byte, and strings are null-terminated by the byte 0xFF. Properly-formed characters should be multiples of 5, and represent indices into the following alphabet:</p>
<pre>0123456789abcdefghijklmnopqrstuvwxyz+-&lt;&gt;=!@.,:;[]
</pre>
<p>Source code and other materials are also available on <a href="https://github.com/JohnEarnest/chip8Archive/tree/master/src/squad" rel="nofollow noopener">the CHIP-8 Archive</a>.</p>
<h2>Controls</h2>
<p>The ASWD keys and E are always interchangeable with the arrow keys and space.</p>
<p>The outer interpreter will prompt the user for a token at a time, and then either append it to the current definition or execute it, based on "mode". Whenever text is drawn with an inverted background, it is a pending input. Pressing right-arrow or space will confirm a selection, while the up and down arrows cycle between available options.</p>
<p>First, the outer interpreter will ask the user to choose between several coarse categories- a number ("num"), or one of six categories of word, described in detail below. Numbers are always shown in 16-bit hexadecimal. The up and down arrows will increment or decrement the number, while 2 and X will increment or decrement the the number by 256 at a time, to ease entering pointers and large values. If the user is ever prompted to enter a previously unused word name (see "name"), the entry can be terminated by choosing a space character (which will confirm the name up to but not including the space), or by pressing space (which will confirm the name up to and including the present pending character). Pressing Q while entering a new name will back up one character.</p>
<p>At the top level of the outer interpreter, the user may also press `Z`, which is a shorthand for entering ".s"; it will print the current contents of the parameter stack on a new line without modifying it.</p>
<h2>Simple Examples</h2>
<p>Bump allocator:</p>
<pre>: allot here @ + here ! ;</pre>
<p>Calculate and print some terms of the Fibonacci sequence imperatively:</p>
<pre>: fib  0 1 loop dup . swap over + dup 100 &gt; until ;</pre>
<h2>Vocabulary</h2>
<p>The following word lists include stack effects in parentheses. The names to the left of the "--" sign are the input arguments, bottom to top,&nbsp;and the names to the right are the results, if any, bottom to top.</p>
<h3>IO</h3>
<p>Input and output words. Type code 1.</p>
<ul><li>emit ( char -- ) print a single character to the terminal. The high byte of "char" is ignored.</li><li>space ( -- ) print a space to the terminal.</li><li>cr ( -- ) advance terminal output to a new line.</li><li>erase ( -- ) un-print a single character from the current line of terminal output.</li><li>type ( str -- ) given a string (as described above), print it to the terminal.</li><li>untype ( str -- ) erase a string, by issuing "erase" for each character.</li><li>num ( -- n ) prompt the user to enter a 16-bit number.</li><li>name ( -- ) prompt the user to enter a string for a new word name, appending this string to "here".</li><li>word ( type -- xt ) prompt the user to select the name of an existing word. If "type" is 0, any word. Otherwise, it should be the type code of one of these categories.</li><li>token ( -- x flag ) prompt the user for a token, as in the outer interpreter. If "flag" is 0, "x" is a number. Otherwise it's a dictionary entry ("xt").</li></ul>
<h3>Core</h3>
<p>Fundamental forth primitives. Type code 2.</p>
<ul><li>dup ( x -- x x ) copy the top of the parameter stack.</li><li>drop ( x -- ) discard the top of the parameter stack.</li><li>over ( x y -- x y x ) copy the second item on the parameter stack.</li><li>swap ( x y -- y x ) exchange the top two items on the parameter stack.</li><li>r&gt; ( | x -- x | ) move an item from the parameter stack to the return stack.</li><li>&gt;r ( x | -- | x ) move an item from the return stack to the parameter stack.</li><li>! ( x addr -- ) write a 16-bit value x to "addr".</li><li>c! ( x addr -- ) write an 8-bit value (the low byte of x) to "addr".</li><li>@ ( addr -- x ) read a 16-bit value from addr.</li><li>c@ ( addr -- x ) read an 8-bit value from addr.</li><li>not ( x -- flag ) logically invert the flag x.</li><li>&gt; ( x y -- flag ) is x greater than y?</li><li>&lt; ( x y -- flag ) is x less than y?</li><li>= ( x y -- flag ) is x equal to y?</li><li>xor ( x y -- z ) bitwise XOR of x and y.</li><li>and ( x y -- z ) bitwise AND of x and y.</li><li>or ( x y -- z ) bitwise OR of x and y.</li><li>- ( x y -- z ) difference of x and y.</li><li>+ ( x y -- z ) sum of x and y.</li></ul>
<h3>Mem</h3>
<p>Words concerning working with memory and dictionary entries. Type code 3.</p>
<ul><li>here ( -- addr ) a variable containing the address of the first available cell of memory.</li><li>head ( -- addr ) a variable containing the xt of the most recent dictionary entry.</li><li>mode ( -- addr ) a variable containing 0 during interpretation or 1 during compilation.</li><li>, ( x -- ) write a cell to here, incrementing here by 2.</li><li>,c ( x -- ) write a byte to here, incrementing here by 1.</li><li>,ret ( -- ) append an exit to the current definition. This word performs tail-call elimination if the exit follows a threaded code subroutine call.</li><li>,lit ( x -- ) append a literal (push a number) to the current definition.</li><li>,jump ( addr -- ) append an unconditional branch to threaded code at addr to the current definition.</li><li>,jump0 ( addr -- ) append a conditional branch (branch if top of parameter stack is 0) to threaded code at addr to the current definition.</li><li>,call ( xt -- ) append a subroutine call to the current definition. This word will do the right thing whether the provided xt is a "native" (built-in) or threaded code subroutine.</li><li>&gt;type ( xt -- n ) given a dictionary entry, get its category. High byte is the immediate flag, low byte is the category type code.</li><li>&gt;name ( xt -- str ) given a dictionary entry, get the address of its name (suitable for "type").</li><li>&gt;body ( xt -- addr ) given a dictionary entry, get the address where its body begins.</li><li>create ( -- ) prompt for a name, and create a new dictionary entry with that name.</li><li>exec ( xt -- ) given a dictionary entry, execute the word. interpretation counterpart to ",call".</li></ul>
<h3>Flow</h3>
<p>Immediate words, mostly for dealing with control flow and compilation state. Type code 4.</p>
<ul><li>if ... (else) ... then: basic conditional control structure. if consumes a boolean flag.</li><li>loop ... (again | until | while): basic infinite and conditional loops. until and while consume a boolean flag.</li><li>:imm ( -- )&nbsp;prompt for a new name, and then begin defining an immediate word. Counterpart to ":".</li><li>: &nbsp;( -- )&nbsp;prompt for a new name, and then begin defining an ordinary word.</li><li>; &nbsp;( -- )&nbsp;terminate a word and stop compiling.</li><li>exit ( -- )&nbsp;early return from a word; do not stop compiling.</li><li>[ &nbsp;&nbsp;( -- )&nbsp;switch to interpreting. Use with "]" and ",lit" to pre-evaluate constant expressions, for example.</li><li>] ( --&nbsp;)&nbsp;switch to compiling.</li></ul>
<h3>Env</h3>
<p>Helper words for maintaining and inspecting the Forth environment. Type code 5.</p>
<ul><li>free ( -- x ) how many bytes of memory are available?</li><li>forget ( -- ) prompt for a word name, and destroy that dictionary entry as well as all later definitions. This can really donk up your interpreter if you apply it to internal bits of Squad.</li><li>.s ( -- ) display the contents of the parameter stack without altering it.</li><li>words ( -- ) list all available words.</li></ul>
<h3>User</h3>
<p>"User-defined" (non-primitive) words. Type code 6.</p>
<pre>:    1+     1 +    ; ( x -- y )
:imm quote  0 word ; ( -- xt )</pre>
</div></div>]]>
            </description>
            <link>https://internet-janitor.itch.io/squad</link>
            <guid isPermaLink="false">hacker-news-small-sites-26188165</guid>
            <pubDate>Fri, 19 Feb 2021 01:06:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facebook Calls Australia's Bluff]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26187669">thread link</a>) | @1cvmask
<br/>
February 18, 2021 | https://www.platformer.news/p/facebook-calls-australias-bluff | <a href="https://web.archive.org/web/*/https://www.platformer.news/p/facebook-calls-australias-bluff">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb6d2995-a033-40d3-b2ea-14dd040d770b_7952x5304.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb6d2995-a033-40d3-b2ea-14dd040d770b_7952x5304.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/bb6d2995-a033-40d3-b2ea-14dd040d770b_7952x5304.jpeg&quot;,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:9776013,&quot;alt&quot;:&quot;A map of Australia. Photo by Joey Csunyo / Unsplash&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt="A map of Australia. Photo by Joey Csunyo / Unsplash"></a><figcaption>Joey Csunyo / Unsplash</figcaption></figure></div><p>Yesterday, I wrote that <a href="https://www.platformer.news/p/australias-bad-bargain-with-platforms">Australiaâ€™s News Media Bargaining Code threatened to splinter the internet</a>. On Wednesday morning, the splintering arrived: Google cut a deal with News Corp. that will ensure its services continue to be provided in Australia, and Facebook walked away from the bargaining table and began preventing people from sharing news links from Australian publishers around the world. </p><p>I think Facebook basically did the right thing, and Google basically did the wrong thing, even though Google had a much tougher call to make. Today, letâ€™s talk about why the tech giants made the decisions that they did, why Australiaâ€™s shakedown is rotten, and whatâ€™s likely to happen next. (If you didnâ€™t <a href="https://www.platformer.news/p/australias-bad-bargain-with-platforms">read my piece on the subject yesterday</a>, it offers a lot of useful context for what follows. Iâ€™ve made it free for all subscribers to read.)</p><p>In development for three years, the bargaining code is intended to give Australiaâ€™s heavily concentrated media industry more leverage as publishers seek direct payment from Google and Facebook for the right to display links to their work. It does this by forcing the platforms into binding arbitration with publishers who bring cases, and puts the decision for how much the platform has to pay the publishers into the hands of the arbiter. Each side throws out a number, and the arbiter picks the one they think is most fair. </p><p>(The arbiter does <em>not</em> pick a number in between, by the way; I got that wrong yesterday and have corrected the post.)</p><p>By design, the arbitration process favors the publisher. Also by design, it encourages platforms to avoid the process altogether by signing one-off deals with individual publishers in hopes that they can get better terms that way. </p><p><strong>I. Google</strong></p><p>Over the past few days, Google has been signing deals with the biggest publishers in Australia for exactly this reason. <a href="https://www.businessinsider.com/google-australia-news-technology-seven-west-media-2021-2#:~:text=Google%20signed%20up%20a%20major,force%20payments%20to%20media%20outlets.">Seven West Media got a deal</a>, <a href="https://www.theguardian.com/media/2021/feb/17/nine-agrees-to-join-google-news-showcase-in-australia-for-reported-30m-a-year#:~:text=Australia's%20biggest%20locally%2Downed%20media,laws%20being%20debated%20in%20parliament.">Nine Entertainment got a deal</a>, and on Wednesday, one of the countryâ€™s biggest conglomerates â€” Rupert Murdochâ€™s News Corp. â€”&nbsp;got its deal. In exchange for an undisclosed sum, Google will feature News Corp. articles in its News Showcase product in Australia and beyond.</p><p>â€œAmong the News Corp publications joining Google News Showcase will be the<em> Wall Street Journal</em>, <em>Barronâ€™s</em>, <em>MarketWatch</em>, and the <em>New York Post</em>; in the UK: the<em> Times</em> and the <em>Sunday Times</em>; and the <em>Sun</em>; and in Australia a range of news platforms, including the <em>Australian</em>, news.com.au, Sky News, and multiple metropolitan and local titles,â€ the company told me in a statement.</p><p>As announced, the deals pertain to <a href="https://blog.google/outreach-initiatives/google-news-initiative/google-news-showcase/">Google News Showcase</a>, a tab within Google News that contains licensed content from official partners. But the people Iâ€™ve spoken with are operating under the assumption that if thereâ€™s a deal between Google and a big publisher in Australia, that publisher either canâ€™t or wonâ€™t be dragged to arbitration for showing links and snippets of text in search results.</p><p>Search, of course, is what Google cares about the most, and explains why the company caved. Removing links to news&nbsp;stories from Google would break the search engine in Australia, <a href="https://blogs.microsoft.com/on-the-issues/2021/02/11/endorsement-australias-proposal-technology-news/">opening it up to rivals</a>. And so the company signed a bunch of deals under duress. </p><p>(Itâ€™s worth mentioning that any Australian publisher aggrieved by an unfair exchange of value with Google here could opt out of search results&nbsp;at any time by adding one line of HTML to their website. But almost none of them do, because traffic from Google drives significant advertising and subscription revenue to them.)</p><p>With its moves today, Google has now invited every other country to pursue a similar protection racket. Parliament members in Canada and the European Union have already endorsed measures similar to Australiaâ€™s. And a basic tenet of the open web â€” that hyperlinks can be freely displayed on any website â€”&nbsp;just took a body blow.</p><p>Iâ€™d feel better about this if publishers said a single word about how much of their new Google revenue that they planned to spend on journalistsâ€™ salaries, or news gathering. </p><p>They didnâ€™t, though, and why would they? Australiaâ€™s bargaining code doesnâ€™t say one word about requiring that any of this money be spent on journalism, either.  </p><p><strong>II.</strong> <strong>Facebook</strong></p><p>Unlike Google, Facebookâ€™s core service doesnâ€™t rely heavily on news articles. The company estimates that only about 4 percent of posts on the network are works of journalism. It is not all that hard to imagine opening up Facebook and scrolling for a few minutes, never to see a link to a news article at all â€”&nbsp;and in fact, millions of people do this every day.</p><p>And so it is perhaps less surprising that when Google blinked at Australiaâ€™s demand, Facebook walked away. Hereâ€™s William Easton, <a href="https://about.fb.com/news/2021/02/changes-to-sharing-and-viewing-news-on-facebook-in-australia/">Facebookâ€™s managing director for Australia and New Zealand</a>:</p><blockquote><p>While the government has made some changes, the proposed law fundamentally&nbsp;<a href="https://australia.fb.com/post/our-response-to-australias-proposed-news-media-laws/">fails to understand</a>&nbsp;how our services work.</p><p>Unfortunately, this means people and news organisations in Australia are now restricted from posting news links and sharing or viewing Australian and international news content on Facebook. Globally, posting and sharing news links from Australian publishers is also restricted. To do this, we are using a combination of technologies to restrict news content and we will have processes to review any content that was inadvertently removed.</p></blockquote><p>And just like that, news articles originating in Australia disappeared from Facebook.</p><p>Easton says that in the past year, Facebook sent more than 5 billion clicks to Australian publishers, whose value he estimated at AU$ 407 million. If the current situation holds, Facebook will send those same publishers zero clicks â€”&nbsp;a move that, I imagine, may force publishers to recalibrate in their minds the relative value that Facebook and publishers provide one another.</p><p>Of course, many critics were apoplectic that Facebook had taken this move, calling it <a href="https://twitter.com/matthewstoller/status/1362135211606220800?s=20">a vile act of censorship</a>, <a href="https://twitter.com/JuddLegum/status/1362172282102304769">unchecked greed</a>, and <a href="https://twitter.com/evelyndouek/status/1362171044136710144">destruction of the public sphere</a>. </p><p>Certainly the execution of the ban left something to be desired. </p><p>Rather than building a blacklist of news sites to restrict, Facebook tried using its machine learning systems to identify news publishers, and the systems went <a href="https://www.abc.net.au/news/2021-02-18/bom-health-authorities-betoota-caught-in-facebook-news-ban/13166394?section=technology">predictably haywire</a>. There were reports that government and emergency pages, nonprofit groups, and the Bureau of Meteorology <a href="https://twitter.com/maxchalm/status/1362160410984476672?s=21">could no longer share</a>. Given how long the possibility of restricting links has loomed, youâ€™d think Facebook would have better prepared for it to arrive.</p><p>And while I donâ€™t want to make light of these mistakes, to the extent that they teach Facebookâ€™s user base to seek their news elsewhere, they can serve a noble purpose. I donâ€™t know a single journalist who feels comfortable with social networks being anyoneâ€™s primary source of news, particularly after years of daily reporting on the misinformation and conspiracy theories that so often thrive on them. And so it is more than a little strange to see so many people insisting that Facebook is obligated to share publishersâ€™ content, on whatever terms those publishers set.</p><p>Some, <a href="https://twitter.com/WillOremus/status/1362132040544628736?s=20">like OneZeroâ€™s Will Oremus</a>, have noted that removing high-quality news sources from Facebook will likely mean a boost for lower-quality blog posts, memes, and other junk. That seems fair, and I do think it bears watching. But what if, in the meantime, Australians simply â€¦ visit websites? Subscribe to newsletters? Read â€¦ books? I realize I sound hopelessly naive here. But if this is the beginning of more people coming to understand the value in visiting trusted news sources directly, I think weâ€™d all be better off. Publishers included!</p><p>In reality, though, I suspect the great Australian news outage of 2021 will be short lived. Australiaâ€™s treasurer, a leading figure in the negotiations, <a href="https://twitter.com/joshfrydenberg/status/1362144150712315905?s=21">said he spoke with Mark Zuckerberg today</a>, and that negotiations continue. (<a href="https://www.nytimes.com/2021/02/17/business/media/australia-google-pay-for-news.html">Fun fact from the </a><em><a href="https://www.nytimes.com/2021/02/17/business/media/australia-google-pay-for-news.html">New York Times</a></em>: Australiaâ€™s treasurer was also â€œ<a href="https://www.smh.com.au/entertainment/celebrity/ryan-stokes-society-wedding-a-sizzler-20161202-gt30re.html" title="">the best man at the wedding of Ryan Stokes</a>, who is a son of Kerry Stokes, the billionaire owner of Seven West Media, one of the companies that have reached a deal with Google.â€)</p><p>â€œWe will continue to engage with the government on amendments to the law, with the aim of achieving a stable, fair path for both Facebook and publishers,â€ Facebook told me today when I asked for an update.</p><p>In the meantime, though, Iâ€™m glad Facebook called publishersâ€™ bluff. </p><p><strong>III. Whatâ€™s next</strong></p><p>I wish Australia would take Facebookâ€™s rejection as a sign it should rethink its approach to media regulation entirely. It could just tax companies based on their revenues, for example. It could earmark those revenues to support journalism â€” nonprofit public media, even, <a href="http://www.orangemedianetwork.com/blog/screengaze/the-importance-of-public-broadcasting/article_dda75496-e27e-11e6-a558-2f6b46140340.html">which has consistently been shown to have powerful civic benefits</a>. Or it could pursue a bargaining code that requires big media conglomerates to create and support <em>jobs</em> in journalism, rather than simply accept tens of millions of dollars and spend them however they like â€” or just return it to shareholders.</p><p>In reality, though, none of that seems likely to happen. Googleâ€™s capitulation means that Australian crony capitalism is now likely to be exported worldwide. Legacy media outlets will become richer â€”&nbsp;and also more dependent on the tech giants that they excoriate daily for having too much power over them. All the while, the media industry will continue to consolidate, and it will be harder to get or keep a job in journalism.</p><p>A bargaining code that truly sought to level the playing field between the platforms and the public would take these realities into account. There is still time to amend it before Parliament takes a vote, and hereâ€™s hoping that lawmakers do â€” both&nbsp;in Australia and beyond it.</p><h3>Message received</h3><p>Yâ€™all really, really prefer the standard linking format. So weâ€™re back to normal today â€” though I still feel like I could make these feel more valuable somehow; maybe just arranging them differently. Iâ€™ll keep you posted, but thanks to everyone who wrote in yesterday with feedback!</p><h3>The Ratio</h3><p><em>Today in news that could affect public perception of the big tech companies. See if you can spot todayâ€™s â€¦</em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.platformer.news/p/facebook-calls-australias-bluff">https://www.platformer.news/p/facebook-calls-australias-bluff</a></em></p>]]>
            </description>
            <link>https://www.platformer.news/p/facebook-calls-australias-bluff</link>
            <guid isPermaLink="false">hacker-news-small-sites-26187669</guid>
            <pubDate>Fri, 19 Feb 2021 00:07:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Florida outperformed lockdown states on excess deaths, education, and economy]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 4 (<a href="https://news.ycombinator.com/item?id=26187395">thread link</a>) | @Pausanias
<br/>
February 18, 2021 | https://rationalground.com/floridas-covid-19-response-has-outperformed-lockdown-states-on-excess-deaths-education-and-the-economy/ | <a href="https://web.archive.org/web/*/https://rationalground.com/floridas-covid-19-response-has-outperformed-lockdown-states-on-excess-deaths-education-and-the-economy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    	<div>

			

			<!--<h5>jenniferhcabrera</h5>!-->

			<!--<h5>Posted on February 16th, 2021</h5>!-->

			
<figure><img loading="lazy" width="853" height="510" src="https://rationalground.com/wp-content/uploads/2021/02/unnamed-44.png" alt="" srcset="https://rationalground.com/wp-content/uploads/2021/02/unnamed-44.png 853w, https://rationalground.com/wp-content/uploads/2021/02/unnamed-44-300x179.png 300w, https://rationalground.com/wp-content/uploads/2021/02/unnamed-44-768x459.png 768w" sizes="(max-width: 853px) 100vw, 853px"></figure>



<p>BY JENNIFER CABRERA</p>



<p>According to data released today by Florida Governor Ron DeSantisÃ¢â‚¬â„¢ office, Florida is outperforming lockdown states like California and New York on all metrics. Florida has lower per-capita mortality, higher availability of in-person education, and a lower unemployment rate.</p>



<p><strong>Excess deaths</strong></p>



<ul><li>Compared to Florida, 34 states had a higher rate of all-cause mortality from 2019 to 2020, per capita. Higher-than-average increases indicate that states probably had extra deaths resulting from lockdown policies, not just from COVID-19.</li></ul>



<figure><img loading="lazy" width="851" height="479" src="https://rationalground.com/wp-content/uploads/2021/02/unnamed-2021-02-16T185337.679.jpg" alt="" srcset="https://rationalground.com/wp-content/uploads/2021/02/unnamed-2021-02-16T185337.679.jpg 851w, https://rationalground.com/wp-content/uploads/2021/02/unnamed-2021-02-16T185337.679-300x169.jpg 300w, https://rationalground.com/wp-content/uploads/2021/02/unnamed-2021-02-16T185337.679-768x432.jpg 768w" sizes="(max-width: 851px) 100vw, 851px"></figure>



<ul><li>Compared to Florida, 38 other states rank higher for per-capita COVID-19 mortality among seniors 65 and older.</li></ul>



<figure><img loading="lazy" width="851" height="479" src="https://rationalground.com/wp-content/uploads/2021/02/unnamed-2021-02-16T185401.219.jpg" alt="" srcset="https://rationalground.com/wp-content/uploads/2021/02/unnamed-2021-02-16T185401.219.jpg 851w, https://rationalground.com/wp-content/uploads/2021/02/unnamed-2021-02-16T185401.219-300x169.jpg 300w, https://rationalground.com/wp-content/uploads/2021/02/unnamed-2021-02-16T185401.219-768x432.jpg 768w" sizes="(max-width: 851px) 100vw, 851px"></figure>



<p><strong>Florida has fewer pediatric COVID-19 cases while having the highest rate of in-person instruction offered.</strong></p>



<ul><li>Schools have been open in Florida, and Florida still has fewer COVID-19 cases among kids when compared to other large states on a per capita basis. (New York is not included because they donÃ¢â‚¬â„¢t make pediatric cases publicly available).</li></ul>



<figure><img loading="lazy" width="851" height="479" src="https://rationalground.com/wp-content/uploads/2021/02/unnamed-2021-02-16T185436.454.jpg" alt="" srcset="https://rationalground.com/wp-content/uploads/2021/02/unnamed-2021-02-16T185436.454.jpg 851w, https://rationalground.com/wp-content/uploads/2021/02/unnamed-2021-02-16T185436.454-300x169.jpg 300w, https://rationalground.com/wp-content/uploads/2021/02/unnamed-2021-02-16T185436.454-768x432.jpg 768w" sizes="(max-width: 851px) 100vw, 851px"></figure>



<p><strong>From the beginning, Governor DeSantis has emphasized nursing homes and protecting the most vulnerable.</strong></p>



<ul><li>California and New York had significantly higher rates for new COVID-19 cases per 1 million compared to Florida.</li></ul>



<figure><img loading="lazy" width="856" height="512" src="https://rationalground.com/wp-content/uploads/2021/02/unnamed-45.png" alt="" srcset="https://rationalground.com/wp-content/uploads/2021/02/unnamed-45.png 856w, https://rationalground.com/wp-content/uploads/2021/02/unnamed-45-300x179.png 300w, https://rationalground.com/wp-content/uploads/2021/02/unnamed-45-768x459.png 768w" sizes="(max-width: 856px) 100vw, 856px"></figure>



<ul><li>California and New York had significantly higher hospitalizations per 1 million compared to Florida.</li></ul>



<figure><img loading="lazy" width="853" height="510" src="http://rationalground.com/wp-content/uploads/2021/02/unnamed-44.png" alt="" srcset="https://rationalground.com/wp-content/uploads/2021/02/unnamed-44.png 853w, https://rationalground.com/wp-content/uploads/2021/02/unnamed-44-300x179.png 300w, https://rationalground.com/wp-content/uploads/2021/02/unnamed-44-768x459.png 768w" sizes="(max-width: 853px) 100vw, 853px"></figure>



<ul><li>Governor DeSantis acted early in the pandemic to protect the stateÃ¢â‚¬â„¢s most vulnerable, and his actions saved lives:<ul><li>Governor DeSantis established 23 COVID-19 dedicated nursing facilities across the state to prevent spread within long-term care facilities, help with hospital decompression, and protect long-term care patients. The Governor also required hospitals to test all individuals discharged to long-term care facilities and required these facilities to transfer COVID-19 positive residents if the facility was not equipped for appropriate care.</li><li>Governor DeSantis issued an executive order putting Seniors First and prioritizing seniors 65 and older to receive the vaccine. To date, 40% of FloridaÃ¢â‚¬â„¢s nearly 4.5 million senior population have received a vaccine.</li><li>Governor DeSantis deployed Florida National Guard and Florida Department of Health Strike Teams to nursing homes and assisted living facilities for testing throughout the pandemic, and now for vaccine distribution.</li><li>Governor DeSantis launched a pilot program for homebound seniors, including Holocaust survivors, WWII and Korean War veterans, and anti-communist Bay of Pigs veterans, to prioritize and protect our Greatest Generation.</li></ul></li></ul>



<p><strong>FloridaÃ¢â‚¬â„¢s economic recovery is leading the nation.</strong></p>



<ul><li>Florida leads the nationÃ¢â‚¬â„¢s most populous states in unemployment rate for December 2020, and Florida was well below the national average.</li></ul>



<figure><img loading="lazy" width="856" height="481" src="https://rationalground.com/wp-content/uploads/2021/02/unnamed-46.png" alt="" srcset="https://rationalground.com/wp-content/uploads/2021/02/unnamed-46.png 856w, https://rationalground.com/wp-content/uploads/2021/02/unnamed-46-300x169.png 300w, https://rationalground.com/wp-content/uploads/2021/02/unnamed-46-768x432.png 768w" sizes="(max-width: 856px) 100vw, 856px"></figure>



<ul><li>Home sales in Florida continued to increase during the height of the pandemic as Americans fled lockdown states.</li></ul>



<figure><img loading="lazy" width="854" height="480" src="https://rationalground.com/wp-content/uploads/2021/02/unnamed-47.png" alt="" srcset="https://rationalground.com/wp-content/uploads/2021/02/unnamed-47.png 854w, https://rationalground.com/wp-content/uploads/2021/02/unnamed-47-300x169.png 300w, https://rationalground.com/wp-content/uploads/2021/02/unnamed-47-768x432.png 768w" sizes="(max-width: 854px) 100vw, 854px"></figure>



<ul><li>U-Haul migration data shows that Florida ranks 3<sup>rd</sup>&nbsp;in the nation for one-way rental moving vans. California ranks 50<sup>th</sup>&nbsp;(at the bottom), and New York ranks 42<sup>nd</sup>.</li></ul>



<figure><img loading="lazy" width="853" height="480" src="https://rationalground.com/wp-content/uploads/2021/02/unnamed-48.png" alt="" srcset="https://rationalground.com/wp-content/uploads/2021/02/unnamed-48.png 853w, https://rationalground.com/wp-content/uploads/2021/02/unnamed-48-300x169.png 300w, https://rationalground.com/wp-content/uploads/2021/02/unnamed-48-768x432.png 768w" sizes="(max-width: 853px) 100vw, 853px"></figure>

		</div>

	</div></div>]]>
            </description>
            <link>https://rationalground.com/floridas-covid-19-response-has-outperformed-lockdown-states-on-excess-deaths-education-and-the-economy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26187395</guid>
            <pubDate>Thu, 18 Feb 2021 23:38:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to know if you're interviewing at a product-led company]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26187334">thread link</a>) | @skotzko
<br/>
February 18, 2021 | https://andrewskotzko.com/how-to-know-if-youre-interviewing-at-a-product-led-company/ | <a href="https://web.archive.org/web/*/https://andrewskotzko.com/how-to-know-if-youre-interviewing-at-a-product-led-company/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><main id="genesis-content"><article aria-label="How to know if youâ€™re interviewing at a product-led company"><div><div><figure><img loading="lazy" width="732" height="307" src="https://andrewskotzko.com/wp-content/uploads/2021/02/TN9ww6_OmxtkBn4j3aKpJw7c2cQZJsdZSEt6FlMAgqTBTD_i2Z4gzRmNvW42Jx1CFbIreJIpDTB4i2QR_bH5JGIoxZH5EIkH3kTji7t8uMhgBO61qtJ84EHpab-QgVWt53Y2hF2_.png" alt="" srcset="https://andrewskotzko.com/wp-content/uploads/2021/02/TN9ww6_OmxtkBn4j3aKpJw7c2cQZJsdZSEt6FlMAgqTBTD_i2Z4gzRmNvW42Jx1CFbIreJIpDTB4i2QR_bH5JGIoxZH5EIkH3kTji7t8uMhgBO61qtJ84EHpab-QgVWt53Y2hF2_.png 732w, https://andrewskotzko.com/wp-content/uploads/2021/02/TN9ww6_OmxtkBn4j3aKpJw7c2cQZJsdZSEt6FlMAgqTBTD_i2Z4gzRmNvW42Jx1CFbIreJIpDTB4i2QR_bH5JGIoxZH5EIkH3kTji7t8uMhgBO61qtJ84EHpab-QgVWt53Y2hF2_-300x126.png 300w" sizes="(max-width: 732px) 100vw, 732px"></figure></div><p>Iâ€™m seeing this sentiment pop up with alarming frequency. Many product people are dealing with career uncertainty â€” and not just the â€œwill my company make it through the pandemic?â€ variety. Without the usual distractions of life available, things that were easily overlooked are now front and center.</p><p>And what are many of these product people realizing without the distractions of normal life?</p><p><strong>Theyâ€™re set up to fail.</strong></p><p>Their work environment and culture is not set up to create strong products. It is distinctly <em>not</em> set up to empower the collaboration of product, design, and engineering to build things that matter.</p><p>This has led many to realize itâ€™s time for a job change.</p><p>As product people, we want to work in a product-led company. A place that truly values the craft and contribution of product, and that empowers individuals and teams to work to their highest potential. A place that is built around creating amazing products that truly make life better for the people theyâ€™re trying to serve.</p><p>We all know itâ€™s possible. Itâ€™s what the best product companies are doing. Yet despite many attempts tried, there are many frustrated PMs that canâ€™t seem to get their work environment to change.</p><p>This is because, frankly, they joined the wrong company in the first place.</p><p>They took a role where good product work occurs in spite of the dominant practices and culture, not because of them.</p><p>Jobs like this waste precious years of your career. Iâ€™ve made this mistake too, and it hurts. I hope this article helps you avoid it in the future.</p><p>Itâ€™s actually really hard to know how strong of a product culture and environment that a team has prior to living in it. Even within the FAANG companies, every team and manager is different and you need to find out the truth.</p><p>After reading this, you should have a go-to set of questions to ask the next companies you interview. These will help you suss out the reality of how the company operates before you commit to an offer. Iâ€™m writing this for product managers, but itâ€™s equally relevant to design and engineering.</p><p>So, what <em>can</em> you do to make sure that your next company is <em>actually</em> a good place to be a product person?</p><p>The key to solving this is to <em>interview companies the same way we interview users and customers</em>.</p><p>Think of this as â€œThe Mom Test,â€ applied to product job interviews.</p><h2 id="interviewing-companies-like-users-customers">Interviewing companies like users/customers<a href="#interviewing-companies-like-users-customers"></a></h2><h3 id="why-you-need-to-do-this">Why you need to do this<a href="#why-you-need-to-do-this"></a></h3><p>One of the most common complaints in the job search process is â€œthis place isnâ€™t what I thought it would be.â€</p><p>People join a company full of vigor and excitement, and within a few months they are bored, going through the motions, and fantasizing yet again about being somewhere that â€œgets product.â€</p><p>It doesnâ€™t have to be this way.</p><div><figure><img loading="lazy" src="https://andrewskotzko.com/wp-content/uploads/2021/02/t3pawlU7qxNyGBkCZMWQLQxfOUct30uDWgZqusxwAHau6pIJ6hAh530ETyv3vLRSapIHNHHSBevu-zemY4za4V5cY7ONyvP97DtHfMILgezcPqd8eOngk1mPY7nD9smhqwVqNA64.jpg" alt="" width="480" height="308" srcset="https://andrewskotzko.com/wp-content/uploads/2021/02/t3pawlU7qxNyGBkCZMWQLQxfOUct30uDWgZqusxwAHau6pIJ6hAh530ETyv3vLRSapIHNHHSBevu-zemY4za4V5cY7ONyvP97DtHfMILgezcPqd8eOngk1mPY7nD9smhqwVqNA64.jpg 640w, https://andrewskotzko.com/wp-content/uploads/2021/02/t3pawlU7qxNyGBkCZMWQLQxfOUct30uDWgZqusxwAHau6pIJ6hAh530ETyv3vLRSapIHNHHSBevu-zemY4za4V5cY7ONyvP97DtHfMILgezcPqd8eOngk1mPY7nD9smhqwVqNA64-300x192.jpg 300w" sizes="(max-width: 480px) 100vw, 480px"></figure></div><p>As PMs, we invest so much getting ready for those damn product interviews that we often forget: <strong>we need to interview the company just as hard as theyâ€™re interviewing us.</strong></p><p>This is called â€œreverse interviewing.â€ As product people, we already know how to do this.</p><p>We know how to interview customers and users. We know to ask questions to account for bias and speculation, surface actual behavior, and understand how decisions are really made.</p><p>When applying for a job, we need to apply those same skills to interview our interviewers.</p><p>As Marty Cagan said to me in <a href="https://pod.fo/e/af7e6">our podcast conversation</a>:</p><blockquote><p><em>From your point of view, your job is to learn as much as possible about how that company really works, and especially how that manager would be like to work for.</em></p></blockquote><p>Letâ€™s see how to do just that.</p><h3 id="principles-for-interviewing">Principles for interviewing<a href="#principles-for-interviewing"></a></h3><p>Two excellent resources on interviewing usersâ€”which you really should read if you havenâ€™tâ€”are <a href="https://www.producttalk.org/2016/03/customer-interview-questions/">this post by Teresa Torres</a> and <a href="https://amzn.to/2MXuN2D">The Mom Test</a>.</p><p>I distill their points into these two overarching principles for interviewing:</p><ol><li>Separate your research questions and interview questions</li><li>Ask questions that uncover actual past behavior, rather than speculative or aspirational future behavior</li></ol><h3 id="separate-research-questions-from-interview-questions">Separate research questions from interview questions<a href="#separate-research-questions-from-interview-questions"></a></h3><p>The user research community has learned that we often canâ€™t directly ask our questions and get reliable answers.</p><p>The way around this is to map our research questions to interview questions.</p><p>Research questions are what we really want to know. Interview questions are what we actually ask to get the interviewee telling stories that show their behavior. (This is a concept I learned from Teresa Torres in her <a href="https://learn.producttalk.org/p/continuous-interviewing">excellent interviewing course</a>.)</p><p>For example, imagine you work at Spotify and your team is assigned to work on reducing the churn rate.</p><p>Letâ€™s say youâ€™ve learned that users who play a given playlist consistently at the start of their workday are retained ~20% longer than those who donâ€™t. Your research questions might be:</p><ul><li>Why are people using the same playlist every day?</li><li>What are people looking for in such a playlist? How do they choose playlists?</li><li>When, where, and how do people find these playlists?</li><li>What is unique about playlists that have high retention rates?</li><li>Are users more likely to exhibit the desired behavior with a playlist they follow, or one they create?</li></ul><p>Some interview questions to get stories containing this information could be:</p><ul><li>Tell me about your morning playlist? How did you first find it?</li><li>Walk me through your day. Start with the moment you woke up.</li><li>Tell me about how you start your workday</li><li>Tell me about the last playlist you discovered that you really liked</li><li>Tell me about the last playlist you made yourself</li></ul><p>Each of these prompts a story about actual behavior, and we can then ask more questions to go deeper. A well-extracted story can often answer multiple research questions at once.</p><p>Now letâ€™s talk about how to apply this to finding a great product environment to work in.</p><h3 id="the-droids-were-looking-for">The droids weâ€™re looking for <a href="#the-droids-were-looking-for"></a></h3><p>What weâ€™re seeking in our job search: empowered product teams.</p><p>Empowered product teamsâ€”as opposed to delivery or feature teamsâ€”only exist in environments with strong product leadership.</p><p>Empowered product teams:</p><ol id="block-31aad864-d497-461b-8f72-65138efd7926"><li>are small, cross-functional, and durable</li><li>address product risks early with collaborative product discovery, and regularly â€œkill their darlingsâ€ en route to ideas that work</li><li>are accountable to delivering results rather than output</li></ol><p>These teams exist in product orgs with an environment that has:</p><ol id="block-31aad864-d497-461b-8f72-65138efd7926"><li>a focused and insight-rich product strategy</li><li>regular, ongoing cadence of lightweight research directly with their user/customer, rather than handing this off to a research group</li><li>people connected to the product vision in a visceral, energetic way</li><li>managers that are proactively and regularly coaching and developing team members</li><li>an equal partnership with the rest of the business</li></ol><p>Teams like this are great places to be a product person. These are where magical career experiences and products come from. And they are made up of ordinary, hard-working, sincere people just like you.</p><p>(To go deep on the idea of empowered teams, read Marty Caganâ€™s latest book, <a href="https://amzn.to/3cFAo8G">EMPOWERED</a>, and listen to the <a href="https://pod.fo/e/af7e6">deep dive conversation I had with him about the ideas in the book</a>.)</p><p>Our research question is: â€œis this a place that empowers product people/teams?â€</p><p>Now that we know what weâ€™re looking for, how do we assess a given job opportunity?</p><p>This is where our interview questions come in.</p><h2 id="reverse-interview-questions">Reverse interview questions<a href="#reverse-interview-questions"></a></h2><p>Since every company we talk to will <em>say</em> theyâ€™re a good product company, we need to dig deeper. Just as with users, we canâ€™t take them at their word. We need evidence from real behavior.</p><p>Based on my own career, research, listener questions and podcast interviews with product people, here are my top reverse interview questions (click to jump to the section for the given question):</p><ol><li><a href="#1-what-were-the-last-few-things-your-team-has-built-and-shipped-and-how-did-you-decide-to-do-those">What were the last few things your team has built and shipped, and how did you decide to do those?</a></li><li><a href="#2-whens-the-last-time-you-talked-with-your-customers-users-how-often-have-you-done-that-in-the-last-month">Whenâ€™s the last time you talked with your customers? How often have you done that in the last month?</a></li><li><a href="#3-what-was-the-last-feature-or-product-your-team-killed">What was the last feature or product your team killed?</a></li><li><a href="#4-can-you-describe-your-product-vision">Can you describe your product vision?</a></li><li><a href="#5-tell-me-about-the-last-coaching-session-you-had-with-your-manager-how-often-did-that-happen-last-month">Tell me about the last coaching session you had with your manager. How often did that happen last month?</a></li></ol><p>Letâ€™s discuss the rationale for each of these, and what you want to hear/avoid.</p><h3 id="1-what-were-the-last-few-things-your-team-has-built-and-shipped-and-how-did-you-decide-to-do-those">1) What were the last few things your team has built and shipped, and how did you decide to do those?<a href="#1-what-were-the-last-few-things-your-team-has-built-and-shipped-and-how-did-you-decide-to-do-those"></a></h3><h4 id="why-youre-asking">Why youâ€™re asking<a href="#why-youre-asking"></a></h4><p>We need to understand the core of how work happens here. How is work assigned? Who decides what gets built, and how?</p><p>This is the biggest indicator of whether this team is empowered. This is the motherlode. Plan to dig deep into this one. Pull every thread and see where it takes you.</p><h4 id="what-youre-looking-for">What youâ€™re looking for<a href="#what-youre-looking-for"></a></h4><p>We want to see that leadership has assigned the team clear objectives â€” customer or business problems to solve â€” and empowered the team to come up with solutions to those problems. Weâ€™re looking to see that leadership has pointed the team in the right direction, and empowered them to figure it out.</p><p>We want to hear things like â€œwell, our goal this quarter is to increase the average 4-week retention for a new user cohort from 33% to at least 40%. We interview users every week and dug into this pattern from last quarterâ€™s data. The PM/designer/tech lead ran a fast series of prototypes/experiments to figure out what worked with users, and to make sure our stakeholders could support it. After we had enough confidence that it was the right thing to build, we put it on the backlog and built it out for production.â€</p><p>Whatâ€™s wrapped up in that statement? Tons of goodness:</p><ul><li>A clear goal, with metrics, that the whole team is focused on</li><li>A regular cadence of user/customer contact</li><li>Insights that inform the product strategy and shape the objectives the teams pursue</li><li>Rapid, iterative, and collaborative prototyping and continuous discovery practices</li><li>Addressing the <a href="https://svpg.com/four-big-risks/">four big risks</a> early on in discovery, before building for production</li><li>A collaborative, rather than subservient, relationship with stakeholdersâ€”we hear that the product team exists to delight the customer, in a way that works for the business</li></ul><p>Weâ€™d also love to dig into the tradeoffs and tough calls that were made in that process. This is a place weâ€™d love to hear the product vision and principles shaping the daily product decisions that the â€¦</p></div></article></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://andrewskotzko.com/how-to-know-if-youre-interviewing-at-a-product-led-company/">https://andrewskotzko.com/how-to-know-if-youre-interviewing-at-a-product-led-company/</a></em></p>]]>
            </description>
            <link>https://andrewskotzko.com/how-to-know-if-youre-interviewing-at-a-product-led-company/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26187334</guid>
            <pubDate>Thu, 18 Feb 2021 23:31:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Some Background (On CheapETH)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26187156">thread link</a>) | @lumpa
<br/>
February 18, 2021 | https://www.deveth.org/background.html | <a href="https://web.archive.org/web/*/https://www.deveth.org/background.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

  <nav>
    <div>
      <p><a href="https://www.deveth.org/"><img src="https://www.deveth.org/logo.png" alt="deveth.org" width="110"></a>
      </p>
    </div>
  </nav>

  <main>
    

    <p>In February 2021, George Hotz (geohot) et al. <a href="https://github.com/cheapETH/go-ethereum/tree/cheapeth">forked the Ethereum chain</a> to form <a rel="nofollow" href="https://cheapeth.org/">cheapETH</a>. A project intended to provide a stable, affordable
      testnet for the
      Ethereum ecosystem, with cross-chain communication functionality. The founders of the devETH project participated
      in this community, spending time and resources building infrastructure surrounding the project.</p>
    <p>Unfortunately, days after the project was started, a member of the cheapETH community discovered and pointed out
      <a href="https://github.com/cheapETH/go-ethereum/commit/412c38434d8d88840452c090e738a672139a73d4#diff-67b4f96b9bd587cc5f508f38eb63f372fa31f339bf66fedcb188f78774318201R88">patch</a>
      in the cheapETH fork of go-ethereum, that grants 25,000,000 cheapETH tokens to the developers associated with the
      project. According to the <a href="https://github.com/cheapETH/cheapeth-website/blob/442027739ee61444c711346c7e3b2a06aecd94aa/index.html#L93">cheapETH
        website</a>, that would theoretically amount to 25,000 Ethereum as per the pegged 1/1000 ratio described by the
      cheapETH developers. This single transaction has <b>theoretical</b> market value of $46 million USD at the time of
      writing. (Feb 18th)
    </p>
    <p>Following this revelation on the cheapETH Discord server, a number of community members expressed their concern
      regarding this seemingly gratuitous developer fund, and the details surrounding its implementation. Instead of
      addressing these issues, the cheapETH staff appointed in the Discord community resorted to deleting messages and
      banning members of the community who were posing unwanted questions about the financial motivations of the
      cheapETH project.</p>
    <p>The devETH project authors do not intend to make any assumptions/accusations as to the financial
      dealings/motivations of the cheapETH developers - They are free to do whatever they wish with their project.
      However, prompted by the drastic response in the Discord community, and a suggestion by <a href="https://github.com/cheapETH/go-ethereum/pull/2#issuecomment-779544030">George Hotz</a>, a group of
      cheapETH community members decided to launch the devETH project as a direct fork of the cheapETH project.</p>
    <p>We intend to continue innovating on the vision of the cheapETH project, and wish all the best to the cheapETH
      team on their endeavour.</p>
    <p>The devETH team invites anyone interested in our take on the cheapETH vision to participate in our <a href="https://discord.gg/xFmCcaEjPK">Discord server</a>.</p>
    <p>- The devETH team</p>

  </main>

  
  


</div>]]>
            </description>
            <link>https://www.deveth.org/background.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26187156</guid>
            <pubDate>Thu, 18 Feb 2021 23:12:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Kanban board that helps Engineers learn Marketing]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26186864">thread link</a>) | @krm01
<br/>
February 18, 2021 | https://phireworks.co/pro/?pro | <a href="https://web.archive.org/web/*/https://phireworks.co/pro/?pro">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<table>
  <tbody><tr>
    <td>

      <h3>Examples from real companies. </h3>
      <h4>New marketing ideas are constantly added to your dashboard so you can learn how other founders acquired their first set of customers.</h4>
    </td>

    <td>

      <h3>Drag &amp; drop to organize</h3>
      <h4>Organize and prioritize weekly marketing experiments that you can implement yourself. Design your process for consistent growth.</h4>
    </td>

    <td>

      <h3>Practical and actionable guides</h3>
      <h4>Discover practical marketing ideas without the fluff, so you can save time and start implementing right away.  </h4>
    </td>
  </tr>
</tbody></table>





</div></div>]]>
            </description>
            <link>https://phireworks.co/pro/?pro</link>
            <guid isPermaLink="false">hacker-news-small-sites-26186864</guid>
            <pubDate>Thu, 18 Feb 2021 22:44:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Texas power outage is a nation-wide problem]]>
            </title>
            <description>
<![CDATA[
Score 290 | Comments 486 (<a href="https://news.ycombinator.com/item?id=26186645">thread link</a>) | @gwoplock
<br/>
February 18, 2021 | https://garrettbattaglia.com/post/texas-power/ | <a href="https://web.archive.org/web/*/https://garrettbattaglia.com/post/texas-power/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
        <p>Let me preface this with an explanation. Over the last few days I read online people saying that Texas' power outages had been caused by Texas being on its own gridâ€¦ deregulationâ€¦ Not following national standardsâ€¦  had Texas been connected to the Eastern Interconnection or the Western Interconnection none of this would have happened. But not one post shows any evidence or requirements that backed up these claims. So, I went looking for proof and instead of finding requirements, I found a nationwide problem with winterization. As an aside I am not an expert in the grid or electricity, I am a software developer, and this is my best interpretation of the requirements I could find.</p>
<p>Letâ€™s start off with how the electrical grid works in the US. The grid is made up of 3 interconnections: the Eastern Interconnection, the Western Interconnection, and the Texas Interconnect. Each of these interconnections operate in (near) isolation with their own frequency, voltage, and phase. There are several high voltage DC interconnects (HVDC or DC-DC) between them. In each of these interconnections there is at least one grid operators, for example ERCOT in Texas. These grid operators manage the generation and load of their interconnection, acting as almost as an electric clearing house. They are also responsible for keeping voltage and frequency within range and directing distributors (like ONCOR in north Texas) to shed load during Electrical Emergency Alerts (EEA). An important thing to note for later, from the best I can tell the different grid operators in the Eastern Interconnect share power in a â€œnon-firm, as-available basisâ€.</p>
<p>What happened in Texas, starting 12:30 AM February 15. The long and short of it is an estimated 34GW of generation went offline in about 2 hours[1]. Looking at ERCOTâ€™s tweets [2,3,4], generation was starting to have an issue at 00:17:45 and some load needed to be shed so ERCOT issued the first EEA (EEA1). In the February EEA tools document[5] EEA1 can open up around 1.6GW of â€œpeekerâ€ generation and importation from the Eastern and Western Interconnections. But by 1:12:06 that wasnâ€™t enough and additional load had to be shed.  A second EEA was issued (EEA2) shedding another 1.6GW. But just a few minutes later the house came crashing down and at 1:25:40 the third EEA (EEA3) was issued. In addition to starting rolling blackouts to shed most of the load it also allowed for other actions to free .1-.2GW of load.</p>
<p>The 34GW of generation lost was from every fuel source used. Most of it was frozen-off natural gas (gas) wells, some of it was frozen wind turbines, solar panels that had snow on them and even a nuclear plant had to go offline due to issues with feedwater pressure sensing issues related to the cold.
What do the North American Electric Reliability Corporation (NERC) standards say about protecting any of these sources? Not much.</p>
<p>Letâ€™s start by looking at the least complex, wind turbines. On September 12, 2012 NERC published a Lesson Learned document in regards to Texasâ€™s issues with some of the wind farms freezing in extreme winter weather[6]. According to the document the event that was predicted over a week beforehand brought 4 days of low temperature, high winds and wind chills, ice and snow that limited the generation facility to just 25% of capacity. The facility did have a SOP for icing conditions that was implemented. However, the facility never defined itâ€™s minimum operating temperature. When lightning knocked out some of the sensing equipment, the turbines had to be stop for safety. The repair crews couldnâ€™t immediately get to the turbines and they had to sit, this gave the oil a chance to cool and partly freeze. When the turbines were returned to service, they tripped back off due to high oil pressure. Eventually after working with the manufacturer they were able to safely heat the oil and restart the turbines. One of the big lessons from this was to install cold weather packs for wind turbines and watch the oil temperature. Youâ€™d think that would solve future outage, but no, in 2019 in the midwestwind turbines failed due to exceptionally low temperatures, around -21. Again the cold weather package hadnâ€™t been installed and was one of the root causes of the failure[7].</p>
<p>The nuclear plantâ€™s sensing problems had happened before too. Although it wasnâ€™t a nuclear plant, there are several documented cases on NERCâ€™s website citing cold weather and sensor issues [8,9]. This repeated in Texas (2011) and in the south east (2018)[10].</p>
<p>Letâ€™s discuss natural gas next. It appears that most of the issues in the problematic natural gas fired facilities was due to low gas supplies. In 2012 NERC warned of the interconnectivity of natural gas and electric[11]. Natural gas coming out of the ground has a naturally high water content. This water can freeze the extraction equipment during sub-freezing weather in improperly winterized wells creating what is know as a freeze-off. businesses, residential customers, and powerplants all run off the same supply, once wells start freezing off the supply dwindles for all. Natural gas companies prioritize residential customers as needed and will cut businesses and powerplants. This obviously creates issues in electrical generation.</p>
<p>In this latest case, much of the gas generation loss was due to under pressure conditions at the generation site. When generation sites detect this kind of fault, they are taken offline for safety. Not only is this what happened this year, but it has happened many, many times before</p>
<p>The most resent case I could find was 2018 in the south east[10]. Starting on January 18, 2018 a large area in the south east US experienced unusually cold weather. This caused 183 generation facilities to go offline or operate with greatly reduced output. At the peak there was nearly 30GW of production lost. This caused several grid operators to issue EEAs and begin rolling blackouts. In the â€œevent areaâ€ 14% of the failures could be directly attributed to the cold weather. And another 30% could be indirectly linked to weather, including mechanical failures know to happen in cold weather and gas supply issues. NERC found that more than 33% of the failed powerplants didnâ€™t have a winterization plan.</p>
<p>Why didnâ€™t these plants have a winterization plan? Because it wasnâ€™t required[10,12].</p>
<p>This wouldnâ€™t be so bad if this wqs the first time it happened, it wasnâ€™t even the second time it happened. In 2014 a polar vortex hit the US. bringing temperatures well below normal. During this event 55% of the outages were at gas power plants and in all 90GW of generation was lost[13].</p>
<p>The earliest report I could find was from the 2011 winter event in Texas[14]. A very strong cold front hit Texas (and other parts of the south central US) bringing temperatures below freezing for over 4 days and winds over 30 MPH. Leading up to the event, ERCOT and other grid operators in surrounding areas felt that there wouldnâ€™t be a need for rolling blackouts. At the beginning of the event ERCOT had 3.1GW of reserve, nearly 1GW over the minimum required. However, over the next 2 days ERCOT lost nearly 30GW of production in 193 generation facilities. ERCOT was able to stabilize the grid with rolling blackouts and the other EEA methods[5]. Other grids suffered problems as well, EPE (El Paso) and SRP (Arizona) lost nearly 1.4GW due to cold weather. Another issue in ERCOTâ€™s region was nearly 50% of the â€œblack startâ€ facilities were either down for scheduled maintenance or failed on startup. One of the main causes again was the loss of gas during this blackout period. 14.8 Bcf of natural gas production was lost due to freeze-offs, electrical outages (ironically) and customer curtailments. following the previous equivalent storm in 1989, the PUCT (Public Utility Commission of Texas) issued several recommendations and guidelines for winterization of power plants and gas wells. However, due to the infrequency of these storms the implementation lacked. With many of the same facilities that failed in 1989 also failed in 2011.  My guess is these same sites failed again in 2021. Interestingly the NERC found that it is quite possible that gas production in these unusually cold conditions may be impossible.</p>
<p>What has been done since 2011? Not a whole lot. A request for a new standard was issued to NERC in late 2012, however a few months later it was denied.[15] Also in 2012 NERC put out a set of guidelines for developing a plan for winter weather[16]. In 2017 NERC put out a special reliability report on the relationship between gas and electricity[17]. Finally, after the 2018 event NERC received another standard request that was approved[23], however it wonâ€™t be finalized until late 2021[18,19,20].</p>
<p>From what I can see, ERCOT has more restrictive rules in their Generator Winter Weatherization Workshop than NERC[21]. All generation stations must have plans for emergencies, address abnormal weather, critical failure points, weather design limits, alternative fuels and testing[21,22]. ERCOT reports that there were 80 spot checks done in the 2019/2020 season with 71 being gas plants and 6 being black start gas plants. 23 had to improve and would be reinspected in early 2021 the rest passed.</p>
<p>The issue of extreme cold weather and electrical outages is a national issue that needs to be addressed. However, after repeated failings it hasnâ€™t really been addressed. Hopefully with the new NERC requirements and the Texas legislature in session progress can be made.</p>
<hr>
<p>[1] <a href="http://www.ercot.com/news/releases/show/225244">http://www.ercot.com/news/releases/show/225244</a><br>
[2] <a href="https://twitter.com/ERCOT_ISO/status/1361197991659503618">https://twitter.com/ERCOT_ISO/status/1361197991659503618</a><br>
[3] <a href="https://twitter.com/ERCOT_ISO/status/1361211669788176384">https://twitter.com/ERCOT_ISO/status/1361211669788176384</a><br>
[4] <a href="https://twitter.com/ERCOT_ISO/status/1361215084010352644">https://twitter.com/ERCOT_ISO/status/1361215084010352644</a><br>
[5] <a href="http://www.ercot.com/content/wcm/lists/219692/EEA_Tools_One_Pager_Winter_2021_2-13-2021.pdf">http://www.ercot.com/content/wcm/lists/219692/EEA_Tools_One_Pager_Winter_2021_2-13-2021.pdf</a><br>
[6] <a href="https://www.nerc.com/pa/rrm/ea/Lessons%20Learned%20Document%20Library/LL20120901_Wind_Farm_Winter_Storm_Issues.pdf">https://www.nerc.com/pa/rrm/ea/Lessons%20Learned%20Document%20Library/LL20120901_Wind_Farm_Winter_Storm_Issues.pdf</a><br>
[7] <a href="https://www.nerc.com/pa/rrm/ea/Lessons%20Learned%20Document%20Library/LL20200601_Unanticipated_Wind_Generation_Cutoffs_during_a_Cold_Weather_Event.pdf">https://wâ€¦</a></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://garrettbattaglia.com/post/texas-power/">https://garrettbattaglia.com/post/texas-power/</a></em></p>]]>
            </description>
            <link>https://garrettbattaglia.com/post/texas-power/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26186645</guid>
            <pubDate>Thu, 18 Feb 2021 22:26:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top Latex Fonts]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26186538">thread link</a>) | @alderz
<br/>
February 18, 2021 | https://r2src.github.io/top10fonts/ | <a href="https://web.archive.org/web/*/https://r2src.github.io/top10fonts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2>assembled by Jaap Joris Vens</h2>

<p>

This page contains ten paragraphs typeset by the
<a href="http://www.latex-project.org/"><span>L<sup>a</sup>T<sub>e</sub>X</span>
typesetting system</a>, converted to images by
the <a href="http://savannah.nongnu.org/projects/dvipng/">dvipng</a>
utility.  Each paragraph<sup>1</sup> showcases a different font family
and provides some background and usage instructions.

The source of this page is <a href="https://github.com/r2src/top10fonts/">available on GitHub</a>.

All the fonts are free and open source and are included by default in
most <span>L<sup>a</sup>T<sub>e</sub>X</span>
distributions.  All fonts are also available
on <a href="http://www.ctan.org/tex-archive/fonts/">CTAN</a>, as well as in the
<a href="http://www.tug.dk/FontCatalogue/"><span>T<sub>e</sub>X</span>
Font Catalogue</a>.<br>
<span>
&nbsp;&nbsp;&nbsp;<sup>1</sup> except for this one, which is the only
paragraph rendered by your browser.
</span>
</p>

<p>
<img src="https://r2src.github.io/top10fonts/lmodern.png" alt="1 Computer Modern">
</p>

<p>
<img src="https://r2src.github.io/top10fonts/kpfonts.png" alt="2 Kepler Fonts">
</p>
<p>
<img src="https://r2src.github.io/top10fonts/fontcomp.png" alt="Comparison table">
</p>
<p>
<img src="https://r2src.github.io/top10fonts/kpsans.png" alt="Kepler Sans">
</p>

<p>
<img src="https://r2src.github.io/top10fonts/didot.png" alt="6 GFS Didot">
</p>

<p>
<img src="https://r2src.github.io/top10fonts/utopia.png" alt="4 Utopia">
</p>

<p>
<img src="https://r2src.github.io/top10fonts/venturis.png" alt="5 Venturis ADF">
</p>
<p>
<img src="https://r2src.github.io/top10fonts/venturisrm1.png" alt="">
</p>
<p>
<img src="https://r2src.github.io/top10fonts/venturisrm2.png" alt="">
</p>
<p>
<img src="https://r2src.github.io/top10fonts/venturisrm3.png" alt="">
</p>

<p>
<img src="https://r2src.github.io/top10fonts/libertine.png" alt="6 Libertine">
</p>

<p>
<img src="https://r2src.github.io/top10fonts/gyre.png" alt="7 TeX Gyre Collection">
</p>
<p>
<img src="https://r2src.github.io/top10fonts/gyrebonum.png" alt="Bonum">
</p>
<p>
<img src="https://r2src.github.io/top10fonts/gyrepagella.png" alt="Pagella">
</p>
<p>
<img src="https://r2src.github.io/top10fonts/gyreschola.png" alt="Schola">
</p>
<p>
<img src="https://r2src.github.io/top10fonts/gyretermes.png" alt="Termes">
</p>

<p>
<img src="https://r2src.github.io/top10fonts/antiqua.png" alt="7 URW Antiqua">
</p>

<p>
<img src="https://r2src.github.io/top10fonts/bera.png" alt="10 Bitstream Vera">
</p>

<p>
<img src="https://r2src.github.io/top10fonts/boisik.png" alt="8 Boisik">
</p>



</div>]]>
            </description>
            <link>https://r2src.github.io/top10fonts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26186538</guid>
            <pubDate>Thu, 18 Feb 2021 22:19:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Which startups let their employees sell stock?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26186119">thread link</a>) | @gk1
<br/>
February 18, 2021 | https://sacra.com/startup-employee-liquidity/ | <a href="https://web.archive.org/web/*/https://sacra.com/startup-employee-liquidity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article class="page">
      <section>
        <div>
          

          <div>
            <p>Selling stock is a taboo subject at a lot of startups.</p>

            <p>To normalize talking about liquidity and help employees make informed career decisions, we built this list of companies that do and donâ€™t allow employees to sell their stock.</p>

            <p><strong>Want to help?</strong> <a href="https://airtable.com/shrbQ6hB22DzXsHOR">Fill out out our survey</a>.</p>
          </div>
        </div>
      </section>
      <section>
        <div>
          

          <div>
            <div>
              <h3>Do you work at a VC-backed company?</h3>

              <p>Help us add to this database anonymously. Your responses will be kept confidential.</p>

              <p><a href="https://airtable.com/shrbQ6hB22DzXsHOR">Add a report</a>
            </p></div>
            <div>
              <h3>Are you an employer?</h3>

              <p>Tell us about your companyâ€™s policies around secondary sales and employee liquidity. Weâ€™d love to hear from you.</p>

              <p><a href="https://airtable.com/shr8aZVC34siGSxAx">Respond to this report</a>
            </p></div>
          </div>
        </div>
      </section>

      <section>
        <div>
          <h2>Liquidity programs by stage</h2>
          
          <div>
            <p>Later-stage companies are more likely to allow employee stock sales, either through company-led transactions or by allowing employee-led transactions. Doing so allows them to provide long-time members of the team with an opportunity to de-risk by getting some liquidity. 

            </p><p>However, today, some companies like Pipe have begun making liquidity available for their employees as early as seed/Series A.</p>

            <p>Some companies donâ€™t allow for employee sales of their stock. In some instances, these companies implement transfer restrictions that prevent private sales from occurring.</p>

          </div>
        </div>
      </section>
      <section>
        <div>
          <h2>Resources for employees</h2>



          <h3>Stock option exercise lending</h3> 
          
          <p>One barrier to employee liquidity is exercising your stock options, which can be expensive and confusing. Some companies help by allowing employees to borrow cash to meet their option exercise and tax obligations. </p>

          <h3>Secondary brokerages</h3>
          
          <p>If your company allows for you to sell your stock, but doesnâ€™t offer regular company-led liquidity, you may be able to sell it on a secondary marketplace or via a broker.</p>
          <h3>Secondary funds</h3>
          
          <p>Certain venture funds specialize in â€œspecial situationsâ€ like employee and/or founder liquidity at private companies, and actually prefer to buy stock in secondary markets.</p>
          <h3>Company liquidity platforms</h3>
          
          <p>If your company offers regular liquidity by way of tender offers, share buybacks, or auctions, you will likely know about it well in advance. If youâ€™re not sure, you can ask your HR or finance team and they will let you know if your company allows for these types of transactions.</p>

          <h4>Learn more</h4>

          
        </div>
      </section>
    </article>
  </div></div>]]>
            </description>
            <link>https://sacra.com/startup-employee-liquidity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26186119</guid>
            <pubDate>Thu, 18 Feb 2021 21:46:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Bug on Aurora PostgreSQL 12 causes Autovacuum to hang forever]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26185711">thread link</a>) | @fdr
<br/>
February 18, 2021 | https://www.migops.com/blog/2021/02/15/a-bug-on-aurora-postgresql-12-causes-autovacuum-to-hang-forever/ | <a href="https://web.archive.org/web/*/https://www.migops.com/blog/2021/02/15/a-bug-on-aurora-postgresql-12-causes-autovacuum-to-hang-forever/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.migops.com/blog/2021/02/15/a-bug-on-aurora-postgresql-12-causes-autovacuum-to-hang-forever/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26185711</guid>
            <pubDate>Thu, 18 Feb 2021 21:18:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gleam 0.14 â€“ Type-safe language for the Erlang VM]]>
            </title>
            <description>
<![CDATA[
Score 275 | Comments 48 (<a href="https://news.ycombinator.com/item?id=26185690">thread link</a>) | @lpil
<br/>
February 18, 2021 | https://gleam.run/news/gleam-v0.14-released/ | <a href="https://web.archive.org/web/*/https://gleam.run/news/gleam-v0.14-released/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <div>
<p>Hot on the heels of Gleam v0.13 comes another release, <a href="https://github.com/gleam-lang/gleam/releases/tag/v0.14.0">Gleam v0.14</a>!
As always, letâ€™s take a look at some of the highlights.</p>

<h2 id="dialyzer--erlang-typespecs">Dialyzer &amp; Erlang typespecs</h2>

<p>Many dynamically typed BEAM languages support Erlangâ€™s typespecs, type
annotations that can be analysed with the <a href="https://erlang.org/doc/man/dialyzer.html">Dialyzer</a> tool. While
not as powerful or reliable as Gleamâ€™s type system it can be a useful tool
for finding problems with your Erlang or Elixir code. Dialyzer doesnâ€™t
require typespecs but it can work better if they are added to the code.</p>

<p>Starting with this release Gleam will generate typespecs for all functions
and Erlang type definitions for all declared types within a Gleam program,
giving you one extra tool to help you write robust and reliable code when
using Gleam alongside Elixir or Erlang.</p>

<p>For a quick example, hereâ€™s some code in Gleam:</p>

<div><div><pre><code><span>pub</span> <span>type</span> <span>LinkedList</span><span>(</span><span>element</span><span>)</span> <span>{</span>
  <span>Empty</span>
  <span>Node</span><span>(</span><span>element</span><span>,</span> <span>LinkedList</span><span>(</span><span>element</span><span>))</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>is_empty</span><span>(</span><span>list</span><span>)</span> <span>{</span>
  <span>list</span> <span>==</span> <span>Empty</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>map</span><span>(</span><span>list</span><span>,</span> <span>fun</span><span>)</span> <span>{</span>
  <span>case</span> <span>list</span> <span>{</span>
    <span>Empty</span> <span>-&gt;</span> <span>Empty</span>
    <span>Node</span><span>(</span><span>i</span><span>,</span> <span>list</span><span>)</span> <span>-&gt;</span> <span>Node</span><span>(</span><span>fun</span><span>(</span><span>i</span><span>),</span> <span>map</span><span>(</span><span>list</span><span>,</span> <span>fun</span><span>))</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>And hereâ€™s the Erlang code and typespecs it compiles to:</p>

<div><div><pre><code><span>-</span><span>module</span><span>(</span><span>linked_list</span><span>).</span>
<span>-</span><span>compile</span><span>(</span><span>no_auto_import</span><span>).</span>

<span>-</span><span>export</span><span>([</span><span>is_empty</span><span>/</span><span>1</span><span>,</span> <span>map</span><span>/</span><span>2</span><span>]).</span>
<span>-</span><span>export_type</span><span>([</span><span>linked_list</span><span>/</span><span>1</span><span>]).</span>

<span>-</span><span>type</span> <span>linked_list</span><span>(</span><span>H</span><span>)</span> <span>::</span> <span>empty</span> <span>|</span> <span>{</span><span>node</span><span>,</span> <span>H</span><span>,</span> <span>linked_list</span><span>(</span><span>H</span><span>)}.</span>

<span>-</span><span>spec</span> <span>is_empty</span><span>(</span><span>linked_list</span><span>(</span><span>any</span><span>()))</span> <span>-&gt;</span> <span>boolean</span><span>().</span>
<span>is_empty</span><span>(</span><span>List</span><span>)</span> <span>-&gt;</span>
    <span>List</span> <span>=:=</span> <span>empty</span><span>.</span>

<span>-</span><span>spec</span> <span>map</span><span>(</span><span>linked_list</span><span>(</span><span>R</span><span>),</span> <span>fun</span><span>((</span><span>R</span><span>)</span> <span>-&gt;</span> <span>U</span><span>))</span> <span>-&gt;</span> <span>linked_list</span><span>(</span><span>U</span><span>).</span>
<span>map</span><span>(</span><span>List</span><span>,</span> <span>Fun</span><span>)</span> <span>-&gt;</span>
    <span>case</span> <span>List</span> <span>of</span>
        <span>empty</span> <span>-&gt;</span>
            <span>empty</span><span>;</span>

        <span>{</span><span>node</span><span>,</span> <span>I</span><span>,</span> <span>List</span><span>@</span><span>1</span><span>}</span> <span>-&gt;</span>
            <span>{</span><span>node</span><span>,</span> <span>Fun</span><span>(</span><span>I</span><span>),</span> <span>map</span><span>(</span><span>List</span><span>@</span><span>1</span><span>,</span> <span>Fun</span><span>)}</span>
    <span>end</span><span>.</span>
</code></pre></div></div>

<p>No annotations are required at all in your Gleam code to get full typespec
coverage, Gleamâ€™s compiler reuses the type information from its powerful type
inference algorithm to determine the correct typespecs.</p>

<p>Thank you <a href="https://gitlab.com/greggreg">Greg</a> for this brilliant new feature!</p>

<h2 id="erlang-escripts">Erlang escripts</h2>

<p>Erlang projects are unusual in that typically instead of having a <code>main</code>
function as the entrypoint of your application you define a tree of actors to
come online and process items of work while your program is running.</p>

<p>This can be a powerful way to write long-lived services that make use of the
runtimeâ€™s fault tolerance features, but it does not lend itself well to
short-lived programs such as command line scripts. It can be confusing to
newcomers from other languages too.</p>

<p>For these short lived programs Erlang <a href="https://erlang.org/doc/man/escript.html">escripts</a> are typically used.
These are lightweight Erlang programs that have a <code>main</code> function as an entrypoint.</p>

<p>To make it easier to use these from Gleam the <code>gleam new</code> command now has an
escript template that can be used to create an escript project without any
further configuration required.</p>

<div><div><pre><code>gleam new my_script <span>--template</span> escript
</code></pre></div></div>

<p>A world class developer experience is a key goal of the Gleam project.
Further tooling improvements are right around the corner!</p>

<h2 id="night-mode">Night mode</h2>

<p>Gleam has the ability to render <a href="https://hexdocs.pm/gleam_stdlib/">HTML documentation</a> 
for your code, ready to upload to Hexdocs.</p>

<p>Thanks to <a href="https://github.com/tynanbe">Tynan Beatty</a> the documentation is
looking better than ever! Thereâ€™s too many improvements to list but the big
one is they now have a night mode! If youâ€™re a night owl like me Iâ€™m sure you
will enjoy the lower contrast dark tones when doing some late evening coding.</p>

<p><img src="https://gleam.run/images/news/gleam-v0.14-released/night-mode.png" alt="A screenshot of Gleam's rendered docs showing a beautiful dark theme"></p>

<h2 id="better-errors-again">Better errors, again</h2>

<p>At the risk of sounding like a broken record Gleamâ€™s error messages have been
improved yet again. Hereâ€™s an example of one of the improvements:</p>

<p>Before:</p>

<div><div><pre><code>error: Syntax error
    â”Œâ”€ /src/thing.gleam:115:18
    â”‚
115 â”‚ pub fn overlappedBy(compare, a, b) -&gt; Bool {
    â”‚                  ^^ I was not expecting this.

Expected one of: "("
</code></pre></div></div>

<p>Now:</p>

<div><div><pre><code>error: Syntax error
    â”Œâ”€ /src/thing.gleam:115:18
    â”‚
115 â”‚ pub fn overlappedBy(compare, a, b) -&gt; Bool {
    â”‚                  ^^ This is not a valid name.

Hint: Names start with a lowercase letter and contain a-z, 0-9, or _.
Try: overlapped_by
</code></pre></div></div>

<p>Thank you to <a href="https://github.com/samontea">Samuel Mercier</a> and <a href="https://github.com/pd-andy">Andy
Thompson</a> for these.</p>

<h2 id="static-bit-string-validation">Static bit string validation</h2>

<p>Bit string syntax is a feature that Gleam inherits from Erlang. It provides a
way to declartively and concisely construct and manipulate raw bits of data
through literals and pattern matching.</p>

<p>With this Gleam release we apply further static analysis to bit string
literals and patterns used in Gleam programs to catch invalid or incorrect
code.</p>

<p>Hereâ€™s an example of one of the errors that may be reported:</p>

<div><div><pre><code>error: Syntax error
  â”Œâ”€ /Users/a/parser_test/src/a.gleam:2:20
  â”‚
2 â”‚   &lt;&lt;1:size(1)-unit(0)&gt;&gt;
  â”‚                    ^ This is not a valid BitString unit value.

Hint: unit must be an integer literal &gt;= 1 and &lt;= 256
See: https://gleam.run/book/tour/bit-strings
</code></pre></div></div>

<p>Thank you <a href="https://gitlab.com/greggreg">Greg</a> for this bit string safety net.</p>

<h2 id="docker-images">Docker images</h2>

<p>Up until now <a href="https://github.com/CrowdHailer">Peter Saxton</a> has been very kindly
building Gleam docker images for use in <a href="https://sendmemo.app/">Memo</a> and the
wider community.</p>

<p>With this release he has ported his build automation over to the Gleam repo
so we have automation creation of OCI/Docker images built and published
automatically with each release.</p>

<p>We are building these variants:</p>

<ul>
  <li><code>gleam-erlang</code>: Gleam and the Erlang tooling on Ubuntu Linux</li>
  <li><code>gleam-erlang-slim</code>: Gleam and the Erlang tooling on slim Debian Linux</li>
  <li><code>gleam-erlang-alpine</code>: Gleam and the Erlang tooling on Alpine Linux</li>
  <li><code>gleam-elixir</code>: Gleam and the Elixir tooling on Ubuntu Linux</li>
  <li><code>gleam-elixir-slim</code>: Gleam and the Elixir tooling on slim Debian Linux</li>
  <li><code>gleam-elixir-alpine</code>: Gleam and the Elixir tooling on Alpine Linux</li>
</ul>

<p>For all the images see the <a href="https://github.com/orgs/gleam-lang/packages/container/package/gleam">Gleam image registry</a>. Thanks Peter!</p>

<h2 id="other-stuff">Other stuff</h2>

<p>These are just some of the highlights, but thereâ€™s plenty more improvements
made to the compiler and the standard library since the last release. For all
the details check out the changelog files:</p>

<ul>
  <li><a href="https://github.com/gleam-lang/gleam/blob/main/CHANGELOG.md">Gleamâ€™s changelog</a></li>
  <li><a href="https://github.com/gleam-lang/stdlib/blob/main/CHANGELOG.md">Gleam stdlibâ€™s changelog</a></li>
</ul>

<h2 id="discord-chat">Discord chat</h2>

<p>Itâ€™s time to plug the Gleam Discord server again! The community continues to
grow and it would be great to have you there too, so please click on the
button below.</p>

<center>
  <a href="https://discord.gg/Fm8Pwmy"><img src="https://img.shields.io/discord/768594524158427167?color=blue" alt="Discord chat"></a>
</center>

<h2 id="try-it-out">Try it out</h2>

<p>If you want to try out the new version of Gleam head over to the <a href="https://gleam.run/getting-started/">getting started
page</a>. Iâ€™d love to hear how you find it and get your feedback so
Gleam can continue to improve.</p>

<p>Want to view some existing Gleam projects? Head on over to the
<a href="https://github.com/gleam-lang/awesome-gleam">awesome-gleam</a> list. Looking for something to build in
Gleam? Check out <a href="https://github.com/gleam-lang/suggestions/issues">the suggestions tracker</a>.</p>

<h2 id="supporting-gleam">Supporting Gleam</h2>

<p>If you would like to help make strongly typed programming on the Erlang
virtual machine a production-ready reality please consider <strong><a href="https://github.com/sponsors/lpil">sponsoring
Gleam</a></strong> via the GitHub Sponsors program.</p>

<p>â­ Or alternatively give us a star on <a href="https://github.com/gleam-lang/gleam">GitHub</a>! â­</p>

<p>This release would not have been possible without the support of all the
people who have <a href="https://github.com/sponsors/lpil">sponsored</a> and contributed
to it, so a huge thank you to them.</p>

<ul>
  <li><a href="https://github.com/adamnbowen">Adam Bowen</a></li>
  <li><a href="https://github.com/amokan">Adam Mokan</a></li>
  <li><a href="https://github.com/aditya7iyengar">Adi Iyengar</a></li>
  <li><a href="https://github.com/scripttease">Al Dee</a></li>
  <li><a href="https://github.com/mudriyjo">Alexander Babin</a></li>
  <li><a href="https://github.com/farhadi">Ali Farhadi</a></li>
  <li><a href="https://github.com/pd-andy">Andy Thompson</a></li>
  <li><a href="https://github.com/bees">Arian Daneshvar</a></li>
  <li><a href="https://github.com/arnodirlam">Arno Dirlam</a></li>
  <li><a href="https://github.com/benmyles">Ben Myles</a></li>
  <li><a href="https://github.com/nono">Bruno Michel</a></li>
  <li><a href="https://github.com/brightly-salty">Caden Haustein</a></li>
  <li><a href="https://github.com/choonkeat">Chew Choon Keat</a></li>
  <li><a href="https://github.com/chrislloyd">Chris Lloyd</a></li>
  <li><a href="https://github.com/worldofchris">Chris Young</a></li>
  <li><a href="https://github.com/tlvenn">Christian Meunier</a></li>
  <li><a href="https://github.com/clangley">clangley</a></li>
  <li><a href="https://github.com/cleverbunny">Clever Bunny LTD</a></li>
  <li><a href="https://github.com/codec-abc">codec-abc</a></li>
  <li><a href="https://github.com/colelawrence">Cole Lawrence</a></li>
  <li><a href="https://github.com/connorlay">Connor Lay (Clay)</a></li>
  <li><a href="https://github.com/cschembor3">Connor Schembor</a></li>
  <li><a href="https://github.com/unthought">Dan Mueller</a></li>
  <li><a href="https://github.com/davydog187">Dave Lucia</a></li>
  <li><a href="https://github.com/rawkode">David McKay</a></li>
  <li><a href="https://github.com/davidpdrsn">David Pedersen</a></li>
  <li><a href="https://github.com/dangdennis">Dennis Dang</a></li>
  <li><a href="https://github.com/lostbean">Edgar Gomes</a></li>
  <li><a href="https://github.com/ericmj">Eric Meadows-JÃ¶nsson</a></li>
  <li><a href="https://github.com/eterps">Erik Terpstra</a></li>
  <li><a href="https://github.com/floriank">Florian Kraft</a></li>
  <li><a href="https://github.com/itsgreggreg">greggreg</a></li>
  <li><a href="https://github.com/ggpasqualino">Guilherme Pasqualino</a></li>
  <li><a href="https://github.com/hendi">Hendrik Richter</a></li>
  <li><a href="https://github.com/hhandoko">Herdy Handoko</a></li>
  <li><a href="https://github.com/human154">human154</a></li>
  <li><a href="https://github.com/Ian-GL">Ian GonzÃ¡lez</a></li>
  <li><a href="https://github.com/igagen">Ingmar Gagen</a></li>
  <li><a href="https://github.com/ivarvong">Ivar Vong</a></li>
  <li><a href="https://github.com/gampleman">Jakub Hampl</a></li>
  <li><a href="https://github.com/jamesmacaulay">James MacAulay</a></li>
  <li><a href="https://github.com/janpieper">Jan Pieper</a></li>
  <li><a href="https://github.com/jechol">Jechol Lee</a></li>
  <li><a href="https://github.com/jeffkreeftmeijer">Jeff Kreeftmeijer</a></li>
  <li><a href="https://github.com/jiangplus">jiangplus</a></li>
  <li><a href="https://github.com/joecorkerton">Joe Corkerton</a></li>
  <li><a href="https://github.com/Jwsonic">John Palgut</a></li>
  <li><a href="https://github.com/josevalim">JosÃ© Valim</a></li>
  <li><a href="https://github.com/jveiga">JoÃ£o Veiga</a></li>
  <li><a href="https://github.com/jmn">Jussi Norlund</a></li>
  <li><a href="https://github.com/kapp-technology">Kapp Technology</a></li>
  <li><a href="https://github.com/kodeFant">Lars Lillo Ulvestad</a></li>
  <li><a href="https://github.com/lawik">Lars Wikman</a></li>
  <li><a href="https://github.com/leandrocp">Leandro Cesquini Pereira</a></li>
  <li><a href="https://github.com/malcolmseyd">Malcolm Seyd</a></li>
  <li><a href="https://github.com/mario-mazo">mario</a></li>
  <li><a href="https://github.com/mvellandi">Mario Vellandi</a></li>
  <li><a href="https://github.com/markmark206">Mark Markaryan</a></li>
  <li><a href="https://github.com/markusfeyh">Markus</a></li>
  <li><a href="https://github.com/derhechi">Markus Hechenberger</a></li>
  <li><a href="https://github.com/MattCheely">Matthew Cheely</a></li>
  <li><a href="https://github.com/bausano">Michael Bausano</a></li>
  <li><a href="https://github.com/michaeljones">Michael Jones</a></li>
  <li><a href="https://github.com/michallepicki">MichaÅ‚ ÅÄ™picki</a></li>
  <li><a href="https://github.com/mroach">Mike Roach</a></li>
  <li><a href="https://github.com/slashmili">Milad</a></li>
  <li><a href="https://github.com/ndreynolds">Nick Reynolds</a></li>
  <li><a href="http://www.ninefx.com/">NineFX</a></li>
  <li><a href="https://github.com/jraregris">Oddmund StrÃ¸mme</a></li>
  <li><a href="https://github.com/sorentwo">Parker Selbert</a></li>
  <li><a href="https://github.com/phiat">Patrick Ryan</a></li>
  <li><a href="https://github.com/PeteJodo">Pete Jodo</a></li>
  <li><a href="https://github.com/CrowdHailer">Peter Saxton</a></li>
  <li><a href="https://github.com/praveenperera">Praveen Perera</a></li>
  <li><a href="https://github.com/qingliangcn">qingliangcn</a></li>
  <li><a href="https://github.com/happysalada">Raphael Megzari</a></li>
  <li><a href="https://github.com/chouzar">RaÃºl  Humberto Chouza Delgado</a></li>
  <li><a href="https://github.com/redmar">Redmar Kerkhoff</a></li>
  <li><a href="https://github.com/reneklacan">RenÃ© KlaÄan</a></li>
  <li><a href="https://github.com/romatthe">Robin Mattheussen</a></li>
  <li><a href="https://github.com/rvcas">rvcas</a></li>
  <li><a href="https://github.com/samaaron">Sam Aaron</a></li>
  <li><a href="https://github.com/samontea">samontea</a></li>
  <li><a href="https://github.com/mrgleam">Santi</a></li>
  <li><a href="https://github.com/sascha-wolf">Sascha Wolf</a></li>
  <li><a href="https://github.com/sasa1977">SaÅ¡a JuriÄ‡Ã§</a></li>
  <li><a href="https://github.com/scottwey">Scott Wey</a></li>
  <li><a href="https://github.com/seanjensengrey">Sean Jensen-Grey</a></li>
  <li><a href="https://github.com/sporto">Sebastian</a></li>
  <li><a href="https://github.com/shanesveller">Shane Sveller</a></li>
  <li><a href="https://github.com/shritesh">Shritesh Bhattarai</a></li>
  <li><a href="https://github.com/simonewebdesign">Simone Vittori</a></li>
  <li><a href="https://github.com/syukronrm">Syukron Rifail M</a></li>
  <li><a href="https://github.com/terkiterje">Terje Bakken</a></li>
  <li><a href="https://github.com/timbuchwaldt">Tim Buchwaldt</a></li>
  <li><a href="https://github.com/tomekowal">Tomasz Kowal</a></li>
  <li><a href="https://github.com/thara">Tomochika Hara</a></li>
  <li><a href="https://github.com/topherhunt">Topher Hunt</a></li>
  <li><a href="https://github.com/tsloughter">Tristan Sloughter</a></li>
  <li><a href="https://github.com/twilco">Tyler Wilcock</a></li>
  <li><a href="https://github.com/tynanbe">tynanbe</a></li>
  <li><a href="https://github.com/wojtekmach">Wojtek Mach</a></li>
</ul>

<p>Thanks for reading! Have fun! ğŸ’œ</p>

</div>

</article></div>]]>
            </description>
            <link>https://gleam.run/news/gleam-v0.14-released/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26185690</guid>
            <pubDate>Thu, 18 Feb 2021 21:16:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Over 140K virus species identified in human gut, 50% never seen before]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26185338">thread link</a>) | @finphil
<br/>
February 18, 2021 | https://nuadox.com/post/643491384977948672/140k-virus-species-in-human-gut | <a href="https://web.archive.org/web/*/https://nuadox.com/post/643491384977948672/140k-virus-species-in-human-gut">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="643491384977948672">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/643491384977948672/140k-virus-species-in-human-gut"><h2>Over 140K virus species identified in human gut, 50% never seen before</h2></a>
                                <figure data-orig-width="1280" data-orig-height="904"><img src="https://64.media.tumblr.com/1a0215a61c5578609506d640223a0ec8/5275df9a1bb2e1fe-38/s1280x1920/64f1e6d38b7d741e57ff618b396d3322a825dc76.jpg" alt="image" data-orig-width="1280" data-orig-height="904" width="1280" height="904"></figure><p><b>- By <a href="https://href.li/?https://www.sanger.ac.uk/">Wellcome Sanger Institute</a> -</b></p><p>

Viruses are the most numerous biological entities on the planet. Now researchers at the Wellcome Sanger Institute and EMBLâ€™s European Bioinformatics Institute (EMBL-EBI) have identified over 140,000 viral species living in the human gut, more than half of which have never been seen before.

<br></p><p>The paper, published today in <i><a href="https://href.li/?https://doi.org/10.1016/j.cell.2021.01.029">Cell</a></i>, contains an analysis of over 28,000 gut microbiome samples collected in different parts of the world. The number and diversity of the viruses the researchers found was surprisingly high, and the data opens up new research avenues for understanding how viruses living in the gut affect human health.</p><p>The human gut is an incredibly biodiverse environment. In addition to bacteria, hundreds of thousands of viruses called bacteriophages, which can infect bacteria, also live in the human gut.</p><p>It is known that imbalances in our gut microbiome can contribute to diseases and complex conditions such as Inflammatory Bowel Disease, allergies and obesity. But relatively little is known about the role our gut bacteria, and the bacteriophages that infect them, play in human health and disease.</p><p>Using a DNA-sequencing method called metagenomics*, researchers at the Wellcome Sanger Institute and EMBLâ€™s European Bioinformatics Institute (EMBL-EBI) explored and catalogued the biodiversity of the viral species found in 28,060 public human gut metagenomes and 2,898 bacterial isolate genomes cultured from the human gut.</p><p>The analysis identified over 140,000 viral species living in the human gut, more than half of which have never been seen before.</p><h2>â€œItâ€™s important to remember that not all viruses are harmful, but represent an integral component of the gut ecosystem. For one thing, most of the viruses we found have DNA as their genetic material, which is different from the pathogens most people know, such as SARS-CoV-2 or Zika, which are RNA viruses. Secondly, these samples came mainly from healthy individuals who didnâ€™t share any specific diseases. Itâ€™s fascinating to see how many unknown species live in our gut, and to try and unravel the link between them and human health.â€<b><br></b></h2><p><b>Dr Alexandre Almeida, Postdoctoral Fellow at EMBL-EBI and the Wellcome Sanger Institute</b><br></p><p>Among the tens of thousands of viruses discovered, a new highly prevalent clade â€“ or group of viruses believed to have a common ancestor â€“ was identified, which the authors refer to as the Gubaphage. This was found to be the second most prevalent virus clade in the human gut, after the crAssphage, which was discovered in 2014.</p><p>Both of these viruses seem to infect similar types of human gut bacteria, but without further research itâ€™s very difficult to know the exact functions of the newly discovered Gubaphage.</p><h2>â€œAn important aspect of our work was to ensure that the reconstructed viral genomes were of the highest quality. A stringent quality control pipeline coupled with a machine learning approach enabled us to mitigate contamination and obtain highly complete viral genomes. High-quality viral genomes pave the way to better understand what role viruses play in our gut microbiome, including the discovery of new treatments such as antimicrobials from bacteriophage origin.â€<br></h2><p><b><a href="https://href.li/?https://www.sanger.ac.uk/person/camarillo-guerrero-luis-fernando/">Dr Luis F. Camarillo-Guerrero,</a>&nbsp;first author of the study from the Wellcome Sanger Institute</b></p><p>

The results of the study form the basis of the Gut Phage Database (GPD), a highly curated database containing 142,809 non-redundant phage genomes that will be an invaluable resource for those studying bacteriophages and the role they play on regulating the health of both our gut bacteria and ourselves.

<br></p><h2>â€œBacteriophage research is currently experiencing a renaissance. This high-quality, large-scale catalogue of human gut viruses comes at the right time to serve as a blueprint to guide ecological and evolutionary analysis in future virome studies.â€</h2><p><b><a href="https://href.li/?https://www.sanger.ac.uk/person/lawley-trevor/">Dr Trevor Lawley,</a>&nbsp;senior author of the study from the Wellcome Sanger Institute</b></p><p>â€“</p><p><i>

* Metagenomics is the study of a collection of genetic material (genomes) from a mixed community of organisms. Metagenomics usually refers to the study of microbial communities. The NIH National Human Genome Research Institute has more information here: <a href="https://href.li/?https://www.genome.gov/genetics-glossary/Metagenomics" title="* this link opens in a new window/tab">https://www.genome.gov/genetics-glossary/Metagenomics</a></i><br></p><p><b>Source:&nbsp;<a href="https://href.li/?https://www.sanger.ac.uk/news_item/scientists-identify-over-140000-virus-species-in-the-human-gut-half-of-which-are-new-to-science/">Wellcome Sanger Institute</a></b></p><p><b>Full study:</b>&nbsp;â€œMassive expansion of human gut bacteriophage diversityâ€,&nbsp;<i>Cell</i>.</p><p><a href="https://href.li/?https://doi.org/10.1016/j.cell.2021.01.029">https://doi.org/10.1016/j.cell.2021.01.029</a><br></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/611601599114231808/fruit-fly-gut-microbiome">We could perhaps learn a lot by looking into a fruit flyâ€™s gut</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/virus">virus</a>
                                    
                                        <a href="https://nuadox.com/tagged/gut">gut</a>
                                    
                                        <a href="https://nuadox.com/tagged/biology">biology</a>
                                    
                                        <a href="https://nuadox.com/tagged/microbiology">microbiology</a>
                                    
                                        <a href="https://nuadox.com/tagged/bacteriophage">bacteriophage</a>
                                    
                                        <a href="https://nuadox.com/tagged/molecular-biology">molecular biology</a>
                                    
                                        <a href="https://nuadox.com/tagged/dna">dna</a>
                                    
                                        <a href="https://nuadox.com/tagged/genomics">genomics</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/643491384977948672/140k-virus-species-in-human-gut</link>
            <guid isPermaLink="false">hacker-news-small-sites-26185338</guid>
            <pubDate>Thu, 18 Feb 2021 20:52:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bad Software and Expensive Mistakes]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26185082">thread link</a>) | @mattmarcus
<br/>
February 18, 2021 | https://www.moderntreasury.com/journal/bad-software-and-expensive-mistakes | <a href="https://web.archive.org/web/*/https://www.moderntreasury.com/journal/bad-software-and-expensive-mistakes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Recently, thereâ€™s been discussion about an accidental $900 million wire that Citibank sent out while Revlon was restructuring some of its debt. You can read the details <a href="https://www.bloomberg.com/opinion/articles/2021-02-17/citi-can-t-have-its-900-million-back" target="_blank">here</a>, but in short, the payment escaped controls and was completed, and when the team realized their mistake they asked for their money back. But they <a href="https://arstechnica.com/tech-policy/2021/02/citibank-just-got-a-500-million-lesson-in-the-importance-of-ui-design/" target="_blank">couldnâ€™t</a> get it all back.<br></p><p>Although $900 million is an astonishing number, Citibank is not alone. In 2018 Deutsche Bank accidentally wired an exchange <a href="https://money.cnn.com/2018/04/19/investing/deutsche-bank-35-billion-mistake/index.html" target="_blank">$35 billion</a> â€” $5 billion more than the bank was worth at the time. The worst â€œfat-fingerâ€ mistake I know of happened in Tokyo in 2005, when a trader filed a share order worth <a href="https://spectrum.ieee.org/riskfactor/computing/it/japan-traders-617-billion-fat-finger-nearmiss-rattles-tokyo-market" target="_blank">$617 billion</a> and sent it to the exchange.<br></p><p>These types of errors happen all the time, and theyâ€™re entirely the fault of software, not people.&nbsp;<br></p><p>The Citibank case goes to the heart of why we started Modern Treasury.&nbsp;<br></p><p>In 2015, Sam and I started building a marketplace for individuals to invest in the renovation loans that LendingHome was making. Building a â€œfractionalâ€ marketplace <a href="#1">[1]</a> increases the number of transactions in a system. When it really started working, it exploded the number of payments we made â€” from hundreds to tens of thousands per month â€” and thatâ€™s when we started uncovering the many issues that we now call â€œpayment operations.â€<br></p><p>In spite of being the lifeblood of every business, there has been a dearth of modern software built for payment operations in the past half century. So I wanted to share a few of our near misses and provide a perspective on why we believe so passionately that payment operations deserves great software.&nbsp;</p><h4>Could Citiâ€™s Mistake Have been Prevented?&nbsp;<br></h4><p>There are several levels.<br></p><p>Hereâ€™s a screenshot of the <a href="https://www.oracle.com/industries/financial-services/banking/flexcube-universal-banking/" target="_blank">Flexcube</a> product that the team at Citibank used for this transaction. The team wanted to pay out interest but not loan principal, but in order to do so the software required an internal â€œwashâ€ account, and a process that involved checking three boxes (and no less: checking only one doesnâ€™t trigger any alerts.) I think we can agree that this product is less than intuitive to use.<br></p><figure><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/602ec598b91eff48eb08f141_flexcube.png" loading="lazy" alt=""></p></figure><p>In addition to being simple to use, a payment ops product needs to be flexible. For this team, there is no API, so the workflow had been hard-coded years before. It was so out of date that the team had to have a <a href="https://www.bloomberg.com/opinion/articles/2021-02-17/citi-can-t-have-its-900-million-back" target="_blank">manual</a> to instruct how to work around it. The reason the high amount was being typed in at all was that this â€œsoftware will only let you pay principal to some lenders if you pretend to pay it to every lenderâ€ (<a href="https://www.bloomberg.com/opinion/articles/2021-02-17/citi-can-t-have-its-900-million-back" target="_blank">source</a>). The workflow is so rigid itâ€™s all or nothing.</p><p>Finally, controls. The Citibank team went through three levels of approvals over email. A good payment operations system should dynamically route payments to the right person or persons for release, but only if those users get the information they need to make an informed decision. Over email, that doesnâ€™t happen.&nbsp;</p><p>Good people operating bad software will eventually make a mistake.&nbsp;<br>â€<br></p><h3>How Software Like This Gets Built</h3><h4>Act One: The Tech Team Wants to Talk to the Bank</h4><p>The first realization we had when we set out to solve this problem at LendingHome was that in order to make payments, you must do so through your bank. But banks do not have clean APIs. To compensate, we had to build a custom bank integration.&nbsp;</p><p>The US has a single system for wire transfers, the Fedwire system, and that is the common denominator across all banks. But each bank then operates its own â€œbank coreâ€ software on top of the Fedwire system, and that software maintains accounts and ledgers, records transactions, and so on. The bank therefore actually has a separate interface. So we now have two interfaces:&nbsp;</p><p>Customer -- Bank -- Fedwire</p><p>Building on these interfaces takes investment of time and resources, because bank cores are challenging to integrate with and understand. Some banks use <a href="https://www.moderntreasury.com/journal/what-is-direct-transmission" target="_blank">Direct Transmission</a> over SFTP while others provide SOAP APIs. Timings <a href="https://docs.moderntreasury.com/reference#ach-timings" target="_blank">vary</a>. There are different, competing, data exchange formats for things like reporting on errors, and the configurations can vary from banks on identical cores.&nbsp;<br></p><p>When pressed for resources, teams cut corners. Itâ€™s hard to justify investing in wonderful design and robust systems for internal processes, so much of whatâ€™s out there is half-built, inflexible, and non-intuitive, and rarely gets any attention from the design team.&nbsp;<br></p><p>The result of poor software is workarounds. We had finance colleagues who had Excel wizard skills and a tolerance for manual process pain at which we marveled, but at some point even they would come down to the engineering floor and, in a desperate cry for help, ask us to â€œJUST COMPUTER IT!â€<br></p><p>(We registered that domain a couple of years later. Check out <a href="http://www.justcomputerit.com/" target="_blank">www.justcomputerit.com</a> the next time youâ€™re frustrated with a payment ops problem.)</p><h4>Act Two: Itâ€™s Not One Bank, Itâ€™s Many</h4><p>Itâ€™s not just a single bank integration problem. Itâ€™s many.<br></p><p>Most companies, once they become somewhat large, operate on more than one bank. So not only does the engineering team have to understand and integrate with one bank, they have to repeat that process for each subsequent bank from scratch, and as we have seen, thatâ€™s a scary proposition.<br></p><p>Now we have many integrations:<br></p><p>Customer&nbsp;<br>-- Bank 1 -- Fedwire<br>-- Bank 2 -- Fedwire<br>-- Bank 3 -- Fedwire<br>-- Bank 4 -- Fedwire<br></p><div><p>Every bank is a unique filter on the Fedwire system, making it even harder to make it flexible, intuitive software. The challenges of a single bank integration are now proliferating, and the engineering team tasked with this has to grow.</p></div><h4>Act Three: The Controller Wants Control</h4><p>Thereâ€™s good reasons why bank relationships are sensitive. After all, the executive team has a fiduciary responsibility to make sure company funds are safe and secure at all times. The CFO and their team are concerned about the prospect of the engineering team building an integration to talk to the bank and move money around whenever they want. Not to mention that with each money movement, the accounting team has to track, tag, and reconcile every dollar that moves in and out of every bank account.<br></p><p>â€œMove fast and break thingsâ€ is quite literally the worst way to sell software to CFOs.&nbsp;<br></p><p>So now we discover the next layer of issues: a good bank integration is necessary but not sufficient. There must be a smart, easy-to-use, and intuitive app for the controller that allows them to manage the process. Some of the features this app must have include the ability to create rules to manage the API, to monitor what is happening, and to provide context and trigger approvals for actions that are unexpected.&nbsp;<br></p><p>One such surprise happened to us when we were subleasing office space from Salesforce. The accounting team saw a giant payment to Salesforce and came over to us, angry and flustered that someone irresponsible had sent Salesforce several salariesâ€™ worth of cash for what should have been a few CRM seats. We were amused as we had to explain that indeed, the payment was made to Salesforce, yes, that Salesforce, but no, it wasnâ€™t for software. It was rent.&nbsp;<br></p><h4>Bonus Act: Idempotency and Reversibility</h4><p>There are some very specific engineering concerns that anyone building a payment ops system has to keep in mind.&nbsp;<br></p><p>The first one is idempotency, or doing things only once. We put together a post on <a href="https://www.moderntreasury.com/journal/why-idempotency-matters-in-payments" target="_blank">â€œWhy Idempotency Matters in Payments</a>,â€ which I highly encourage anyone working in payments to read, because the only thing worse than sending the wrong amount is sending it twice.&nbsp;<br></p><p>We lived this. One day we accidentally double-funded every mortgage: many millions of dollars, paid out twice. That was not a good day. Mercifully, because mortgages are disbursed to <a href="https://www.moderntreasury.com/journal/how-to-build-an-escrow-product" target="_blank">escrow</a>, we got all the funds back, but we never forgot idempotency matters in payments after that day.&nbsp;<br></p><div><p>Wires are not reversible, which makes mistakes particularly scary. There are other payment types, such as ACH, that are. If you sent an ACH and you didnâ€™t mean to, or if someone debits your account without your permission, you can reverse it.<a href="#2">[2]</a> Approvals are important, but theyâ€™re particularly important for irreversible transactions, such as the wire Citi sent and couldnâ€™t recall after sending.&nbsp;</p></div><h4>Thinking About Payment Ops as a Single Continuous Process</h4><p>Steve Jobs said, â€œDesign is not just what it looks like and feels like. Design is how it works.â€&nbsp;<br></p><p>This sums up how we believe payment operations should run. Rather than have many silos for information â€” from a database to a CSV to a bank portal to an accounting system â€” we believe in a single piece of payment operations software. This software crosses systems and, perhaps most importantly, it crosses teams. The tech team wants to live in the <a href="https://www.moderntreasury.com/developer-solutions" target="_blank">API</a>, the finance team wants to live in the <a href="https://www.moderntreasury.com/finance-solutions" target="_blank">app</a>, accountants need <a href="https://www.moderntreasury.com/journal/introducing-continuous-accounting" target="_blank">continuous accounting</a>, and customer service teams need to <a href="https://www.moderntreasury.com/journal/how-customer-support-teams-use-modern-treasury" target="_blank">answer customer requests</a>.&nbsp;<br></p><p>Weâ€™ve written at length in the <a href="https://www.moderntreasury.com/journal" target="_blank">Modern Treasury Journal</a> about these issues. ACH, wire, and paper check account for the <a href="https://www.moderntreasury.com/journal/b2b-payments-vs-c2b-payments-what-makes-them-so-different" target="_blank">vast majority</a> of payments in the US, and yet have seen very little innovation in the last fifty years.&nbsp;<br></p><p>We believe that will change this decade. <a href="https://angel.co/company/moderntreasury/jobs" target="_blank">Join us</a>, <a href="https://app.moderntreasury.com/sign_up" target="_blank">build with us</a>, and <a href="https://www.moderntreasury.com/journal" target="_blank">learn with us</a>.&nbsp;<br></p></div></div><div><h4>References</h4><div><div id="1"><p>A fractional loan marketplace is one where each loan is sold not to one institutional investor but to many individuals. This means that every repayment of that loan has to be split between all the investors that &nbsp;invested in each loan, and therefore number of individual transactions in the system balloons.</p></div><div id="2"><div><p>There are lots of ACH return codes, and you can check out our post on <a href="https://www.moderntreasury.com/journal/what-happens-when-you-ach-a-dead-person" target="_blank">What Happens When You ACH a Dead Person </a>to learn more about those.</p></div></div></div></div></div>]]>
            </description>
            <link>https://www.moderntreasury.com/journal/bad-software-and-expensive-mistakes</link>
            <guid isPermaLink="false">hacker-news-small-sites-26185082</guid>
            <pubDate>Thu, 18 Feb 2021 20:32:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Series A to Revolutionize Computing]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26184594">thread link</a>) | @tosh
<br/>
February 18, 2021 | https://blog.repl.it/seriesa | <a href="https://web.archive.org/web/*/https://blog.repl.it/seriesa">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Our mission is to give everyone in the world <strong>computer superpowers</strong>. We build powerful yet approachable tools &amp; platforms for developers, students, and educators.</p>
<p>We see a new generation of hackers and entrepreneurs rising to seize the power of computers and the internet to create software that empowers them and their communities. They refuse to be programmed by the software priesthood that wants them to endlessly consume ads. Instead, they build a more free society where computers work for and under human users, not the other way around. The world we're describing is coming, and we exist to accelerate the shift.</p>
<p><img src="https://repl.art/replit.png" alt="art"></p>
<p>Replit is a multiplayer computing environment that makes it <a href="https://blog.replit.com/internet-of-fun">fun</a> to learn how to code, build, and <a href="https://repl.it/talk/share">share apps</a> with other people. You can create a cloud-powered computer in milliseconds -- we call them "repls" -- and you can create as many of them as you'd like, all for free. Repls come with storage for your code and files, a <a href="https://blog.repl.it/database">database</a> for your data, and a <a href="https://repl.it/site/multiplayer">multiplayer editor</a> &amp; console to code with your friends. For <a href="https://repl.it/pricing">$7/month</a>, you'll get more powerful machines and, with one-click, make them <a href="https://blog.repl.it/alwayson">run forever</a>.</p>
<p><img src="https://blog.repl.it/images/database/database1.gif" alt="db"></p>
<p>When you invite a friend to your repl, you can see them in your editor and talk to them <a href="https://blog.repl.it/annotations-for-education">right in your code</a>. You can make <a href="https://docs.repl.it/repls/http-servers">web</a>, <a href="https://blog.repl.it/native-graphics-love">desktop</a>, and even command-line apps. Replit takes care of the entire process of <a href="https://docs.repl.it/repls/web-hosting">publishing and hosting apps</a> so you can focus on your ideas.</p>
<p><img src="https://venturebeat.com/wp-content/uploads/2021/02/Live-Code-Editing.gif?resize=800%2C450&amp;strip=all" alt="multiplayer"></p>
<p>When you've built something you want to share, you can share the <a href="https://blog.replit.com/spotlight">repl URL</a>, and your users can play with your app, react to it, comment on it, and even fork and remix it. Replit gives you a profile to keep and showcase all your apps and repls. You can make <a href="https://repl.it/site/teams">shared team profiles</a> for your class, friends, or company to collaborate on repls.</p>
<p><img src="https://blog.repl.it/images/spotlight/ios-demo.gif" alt="share"></p>
<p>Because you can make a repl in milliseconds, Replit makes it fun and safe to experiment with ideas. Learning comes naturally as a side effect of playing in the Replit ecosystem.</p>
<p>Millions of people have learned how to code with Replit and built great apps with thousands of happy users. Some have even built businesses and become rich &amp; famous.</p>
<p>Replit's design principles:</p>
<ul>
<li><p><strong>Learnable yet scalable interfaces</strong>: Interfaces today present the same UI to vastly different users, from children to adults, from novices to experts. Our mission demands that we make computing environments more accessible to novices while making it possible to transition to more powerful interfaces. Replit starts with a simple editor and console, which gets learners very far. The UI, however, is adaptable and presents different faces to different users and use-cases.</p>
</li>
<li><p><strong>Infrastructure as legos</strong>: A core part of commanding computer power is to be able to build for the modern internet-connected world. Despite progress in cloud computing, infrastructure remains inaccessible to novices, hobbyists, and educators. We change this by designing simple and scalable components, like cloud-hosted servers accessible right from the repl, storage, databases, etc., that require little configuration and maintenance by the programmer. Coders can then mix and match components to create endless possibilities.</p>
</li>
<li><p><strong>People-centric technology</strong>: It's more exciting and fun to create and learn with other people. The future demands that computers and the internet have human interconnectedness as a core primitive. From our multiplayer computing protocol to our community spaces for sharing software, we build support for human beings, and we put collaboration right at the heart of our technology.</p>
</li>
</ul>
<h2 id="series-a">Series A</h2>
<p>As a team, we've always thought about the long-term, and we've grown Replit responsibly. We have so much conviction in our mission and our plan that we're willing to take our time. </p>
<p>Last year, with rapid growth in all aspects of our business, we felt it was a good time to raise a sizeable round to make faster progress our mission. We raised <a href="https://venturebeat.com/2021/02/18/replit-raises-20-million-for-collaborative-browser-based-coding/">$20M in Series A</a> financing led by <a href="https://acapital.com/">A.Capital</a> with strong participation from our seed investors: Andreessen Horowitz, Bloomberg Beta, Y Combinator, and Reach Capital. </p>
<p>Since then, thanks to the new capital and to <a href="https://amasad.me/moad">Engelbartian Bootstrapping</a>, we've accelerated feature development, and there's so much more on the horizon: extra resources for more complex projects, support for any language or package, further dev ops simplifications for novices and pros, business collaboration features, improvements to <a href="https://repl.it/teams-for-education">teacher workflows</a>, high quality content, a game development library, and more breakthroughs in collaborative coding. We're excited to see all the amazing things you build with the tools we provide!</p>
<p>Finally, we're hiring for multiple roles and want to bring on people who share our vision and passion. If you're interested in making computing more accessible while working with a creative and hardworking team building fantastic technology, <a href="https://repl.it/careers">join us</a>!</p>

	</div></div>]]>
            </description>
            <link>https://blog.repl.it/seriesa</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184594</guid>
            <pubDate>Thu, 18 Feb 2021 19:53:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coronavirus in Slovakia: What Is Going On]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26184366">thread link</a>) | @scandox
<br/>
February 18, 2021 | https://spectator.sme.sk/c/22598901/coronavirus-in-slovakia-what-is-going-on.html | <a href="https://web.archive.org/web/*/https://spectator.sme.sk/c/22598901/coronavirus-in-slovakia-what-is-going-on.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The answer is just three words.</p><div><p><a href="https://m.smedata.sk/api-media/media/image/spectator/9/68/6821849/6821849_1200x.jpeg?rev=3"><img alt="Mathematician Richard KollÃ¡r during the press conference in the Presidential Palace on February 16, 2021. " src="https://m.smedata.sk/api-media/media/image/spectator/9/68/6821849/6821849_600x400.jpeg?rev=3"><span><span><svg width="30px" height="30px"><use xlink:href="#svg-icon-magnifier"></use></svg><span></span></span></span></a><span><small>Mathematician Richard KollÃ¡r during the press conference in the Presidential Palace on February 16, 2021.  (Source: TASR)</small></span></p></div><article data-article-stats-id="22598901" id="js-article" data-user-login-url="https://prihlasenie.sme.sk"><p><span data-deep-event-tags="position-top"><span><span title="pÃ´vodnÃ¡ veÄ¾kosÅ¥ pÃ­sma">Font size:</span><span title="zmenÅ¡iÅ¥ pÃ­smo"><span data-ga-event-id="gaev-art-toolbox" data-ga-event-category="article_toolbox_top" data-ga-event-action="fontminus">A</span><sup>-</sup></span>|<span title="zvÃ¤ÄÅ¡iÅ¥ pÃ­smo"><span data-ga-event-id="gaev-art-toolbox" data-ga-event-category="article_toolbox_top" data-ga-event-action="fontplus">A</span><sup>+</sup></span></span></span></p>
<p><em>Richard KollÃ¡r is a mathematician. He delivered this speech during the press conference after a meeting of scientists with President Zuzana ÄŒaputovÃ¡ on February 16, 2021. </em></p><p>I am a mathematician and I will speak exclusively about numbers and data. I will answer one question, often posed by journalists and the wider public - how we are doing and what is going on regarding the pandemic in Slovakia.</p><p>The answer is very simple. Just three words.</p><p>We don't know. We don't know, in fact.</p><p>I will try to sum up all the things we do not know.</p><p>We are missing absolutely key data to be able to assess the effects of our measures, and the epidemiological situation we are in.</p><p>We have no clue how many people are arriving to hospitals as new patients, we have no clue how many are leaving the hospitals. We therefore cannot say what is causing the increase in the number of hospitalisations we are seeing.</p><p>We don't know that about ventilators either, because the numbers we have do not match. When you put the arrivals and the departures in an equation, you do not get the number we have got now.</p><p>We don't know the age of the hospital patients, so we don't know what's going on.</p><p>We don't know how many infections are hospital-acquired.</p><p>We don't know how many patients are transferred from Covid to non-Covid wards in hospitals.</p><p>We don't know what is the structure of the tests we are performing.</p><p>We don't now how many tests have been done per health indication in hospitals, how many were indicated by epidemiologists or self-indicated.</p><p>We don't know how many tests were part of screening.</p><p>We don't know how many tests are performed in hospitals and what are their results.</p><p>We have no information about tracing.</p><p>We don't now exactly how many people have been traced and how many have been indicated as positive. We don't know how many of the people who were found through tracing ended up in hospitals.</p><p>We don't know what the effectiveness of our tracing is.</p><p>We don't know where the problem lies.</p><p>We don't know about the new variants. We probably have the best tests in Europe to find that out. We are the only country with tests for the British strain. Yet we still don't know how its prevalence developed in the Slovak samples in January. We have looked at one day's sample, but we have no clue how it developed in time. Even though there have been promises and interest in doing that, we still do not have that data.</p><p>We haven't learned from the regional public health offices where Slovak citizens become infected.</p><p>We don't know if it is safe to go to the store. We don't know if it is safe to travel by public transport.</p><p>We don't know how many people got infected where and we do not report such numbers.</p><p>We don't know how the opening of schools last week went, and how many have been closed.</p><p>We don't know how many people have passed through the border crossings and we don't know which countries they came from; how many then end up positive and hospitalised.</p><p>As for the tests proposed by the Education Ministry, we don't know how they have been validated and what are their parametres. We know they are being purchased, but we don't have a clue what they will look like.</p><p>When we apply  theCovid automat, we don't know how its parametres are assessed. We cannot assess the incidence because the numbers of PCR and antigen tests are counted together. PCR tests are reported based on the person's permanent residence, antigen tests are reported based on the testing site location.</p><p>We don't know how things stand with hospitalisations.</p><p>We have no idea how to calculate the reproduction number, which is why we don't dare to announce it during press conferences.</p><p>We have no clue how these three parametres are combined and evaluated on the level of districts.</p><p>We don't know why some districts have the colour they have.</p><p>We don't know why the Health Ministry laid off 10 percent of its staff as part of the corona-crisis measures just like other ministries, and why they have not reinforced the analytical units.</p><p>We are in a data hell. And we don't know if we are facing another wave; if it will be stronger than the one we are going through, or milder.</p><p>We don't know if we are facing the same fate as the Czech city of Cheb, where a quarter of a percent of its inhabitants have died in the past five weeks. Perhaps Slovakia is facing the same.</p><p>We don't know, we have no way of knowing what is going on.</p><p>
            17. Feb 2021 at 13:15
        &nbsp;|&nbsp;Richard KollÃ¡r
    
    </p></article></div>]]>
            </description>
            <link>https://spectator.sme.sk/c/22598901/coronavirus-in-slovakia-what-is-going-on.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184366</guid>
            <pubDate>Thu, 18 Feb 2021 19:31:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BioNTech/Pfizer sought 54.08 Euro per vaccine dose from EU (de)]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 41 (<a href="https://news.ycombinator.com/item?id=26184301">thread link</a>) | @_Microft
<br/>
February 18, 2021 | https://www.tagesschau.de/investigativ/ndr-wdr/corona-impfstoff-biontech-105.html | <a href="https://web.archive.org/web/*/https://www.tagesschau.de/investigativ/ndr-wdr/corona-impfstoff-biontech-105.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                <div>
    
    
    <div>
        <div>
            <p><span>
                    Exklusiv
                </span>
            </p>
            
            <p>
                Stand: 18.02.2021 17:00 Uhr
            </p>
        </div>
    </div>
</div>
                
                    

    
    
        
    
    <p>
        <strong>Die Pharmaunternehmen Pfizer und BioNTech wollten nach Informationen von </strong><strong><em>NDR, WDR</em></strong><strong> und "SZ" im Juni von der EU fÃ¼r eine Dosis Impfstoff 54,08 Euro. Der Arzneimittelchef der Ã„rztekammer spricht von "unseriÃ¶sem Profitstreben".</strong>
    </p>

    

    




    

                
                    

    
    
        <div>

    

    
        <div>
            <p>
                    <span><em>Von Markus Grill und Georg Mascolo,  </em></span><em>
                    <span>NDR/WDR</span></em>
                </p>
        </div>
    
</div>
    

    




    

                
                    

    
    
        
    
    <p>
        Im Juni des vergangenen Jahres ging bei der EU-Kommission ein streng vertrauliches Angebot der Pharmahersteller Pfizer und BioNTech ein. Darin boten sie nach Informationen von <em>NDR, WDR</em> und "SÃ¼ddeutscher Zeitung" ihren Impfstoff zum Preis von 54,08 Euro pro Dosis an, bei einer Abnahme von 500 Millionen Dosen. Insgesamt wollten BioNTech/Pfizer also 27 Milliarden Euro fÃ¼r so viel Impfstoff, dass man damit gut die HÃ¤lfte der EU-BevÃ¶lkerung impfen kÃ¶nnte. Der Preis, so versicherten Pfizer/BioNTech, beinhalte bereits "den hÃ¶chsten prozentualen Rabatt", der einem Industrieland weltweit angeboten worden sei.
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        Mit 54,08 Euro wÃ¤re der BioNTech-Impfstoff allerdings mehr als 20-mal so teuer gewesen wie eine Dosis jenes Impfstoffs, den AstraZeneca gemeinsam mit der UniversitÃ¤t Oxford entwickelt hat. "Ich halte den Preis fÃ¼r unseriÃ¶s", kritisiert der Vorsitzende der Arzneimittelkommission der Deutschen Ã„rzteschaft, Wolf Dieter Ludwig, das Angebot von Pfizer/BioNTech. "Ich sehe darin ein Profitstreben, das in der jetzigen Situation der Pandemie in keiner Weise gerechtfertigt ist."
    </p>

    

    




    

                
                    

    
    
        
    

    




    
        
        
            
            
            
            
            
            
                
    
    

        
    

            
            
            
            
            
        
    

                
                    

    
    
        
    

    




    
        
        
            
            
            
            
            
                
            
            
            
            
            
            
        
    

                
                    

    
    
        

    

    <h2>VerstÃ¤ndnis fÃ¼r ZÃ¶gern der EU</h2>


    

    




    

                
                    

    
    
        
    
    <p>
        WomÃ¶glich werfen diese vergleichsweise hohen Preisvorstellungen auch ein neues Licht auf die ZurÃ¼ckhaltung mancher EU-LÃ¤nder im Sommer gegenÃ¼ber dem BioNTech-Impfstoff. Ludwig jedenfalls sagt, dass er die EU verstehe: "Ich denke, sie hat mit Recht gezÃ¶gert bei einem derartig hohen Preis."
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        In einem Interview mit dem "Spiegel" Anfang des Jahres kritisierte BioNTech-Chef Ugur Sahin die Verhandlungen mit der EU: "Der Prozess in Europa lief sicherlich nicht so schnell und geradlinig ab wie mit anderen LÃ¤ndern", sagte der Firmenchef. "Offenbar herrschte der Eindruck: Wir kriegen genug, es wird alles nicht so schlimm, und wir haben das unter Kontrolle. Mich hat das gewundert."
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        Eine Anfrage zu einem GesprÃ¤ch Ã¼ber das hohe Preisangebot lieÃŸ Sahin diese Woche unbeantwortet. Eine Firmensprecherin beantwortete konkrete Fragen zum Angebot nicht, wies aber darauf hin, dass der Preis fÃ¼r den Impfstoff "von verschiedenen Faktoren abhÃ¤ngig" sei. Er liege "in einer gewissen Spanne fÃ¼r alle LÃ¤nder mit hÃ¶herem Einkommen". Bisher habe das Unternehmen jedoch keine Gewinne gemacht. Wenn man aber Gewinne aus dem Vertrieb des Covid-19-Impfstoffs mache, wolle man diese "in die Weiterentwicklung dieser Technologie reinvestieren". Ein Sprecher der EU-Kommission teilte per E-Mail mit, dass die EU-Kommission aus vertragsrechtlichen GrÃ¼nden keine Angaben Ã¼ber die Preise machen dÃ¼rfe.
    </p>

    

    




    

                
                    

    
    
        
    

    




    
        
        
            
            
            
            
            
                
            
            
            
            
            
            
        
    

                
                    

    
    
        

    

    <h2>Offenbar deutlich niedrigeren Preis durchgesetzt</h2>


    

    




    

                
                    

    
    
        
    
    <p>
        Erst im November kam die EU zu einem Vertragsabschluss mit Pfizer/BioNTech. Der endgÃ¼ltige Preis wird bis heute zwar geheim gehalten, doch nach Informationen von <em>NDR, WDR</em> und "SZ" soll er bei 15,50 Euro pro Dosis liegen. Als erste hatte auch die Nachrichtenagentur Reuters diesen Preis erfahren. Die EU hÃ¤tte damit also eine deutliche Preissenkung gegenÃ¼ber dem Angebot im Juni erreicht.
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        Auch die USA zahlen in etwa gleich viel. Sie hatten im Juli bereits einen Vertrag mit Pfizer geschlossen, der ihnen 100 Millionen Dosen fÃ¼r 1,95 Milliarden Dollar sicherte. Umgerechnet ergibt das rund 16 Euro pro Dosis.
    </p>

    

    




    

                
                    

    
    
        
    

    




    
        
        
            
            
            
            
            
                
            
            
            
            
            
            
        
    

                
                    

    
    
        

    

    <h2>Staatliche Subventionierung in MillionenhÃ¶he</h2>


    

    




    

                
                    

    
    
        
    
    <p>
        Ãœberraschend ist aber nicht nur der hohe Preis, den Pfizer/BioNTech von der EU kassieren wollten, sondern auch die Behauptung in dem Angebot an die EU, man hÃ¤tte die Entwicklung des Impfstoffes "komplett selbst finanziert".
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        Das mag vielleicht fÃ¼r Pfizer gelten. Nicht aber fÃ¼r die deutsche Firma BioNTech, die den Impfstoff entwickelt hatte - auch wenn manche derzeit glauben, dass BioNTech allein mit dem Geld der Hexal-GrÃ¼nder Andreas und Thomas StrÃ¼ngmann aufgebaut wurde. 
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        TatsÃ¤chlich war ihr Engagement entscheidend - aber BioNTech wurde auch mit mehreren Millionen Euro staatlich subventioniert. So teilt das Bundesministerium fÃ¼r Bildung und Forschung (BMBF) auf Anfrage von <em>NDR, WDR</em> und "SZ" mit, dass das Ministerium "die GrÃ¼ndungsphase von Biontech maÃŸgeblich unterstÃ¼tzt und die entscheidenden ersten Jahre der AusgrÃ¼ndung finanziell und auch strukturell gefÃ¶rdert hat".
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        Einen weiteren Schub hatte BioNTech demnach von 2012 bis 2017 als Gewinner des Spitzencluster-Wettbewerbs erhalten, das vom Forschungsministerium mit 12,9 Millionen Euro gefÃ¶rdert worden sei, wie BMBF-Sprecher Stephan KÃ¼gele mitteilte. Auf Nachfrage teilt auch die BioNTech-Sprecherin mit, das Unternehmen habe "wÃ¤hrend der ersten Jahre nach GrÃ¼ndung ca. 50 Millionen Euro FÃ¶rdergelder durch die Clusterinitiative und EU-Programme erhalten." Im Sommer 2020 bekam die Firma weitere 375 Millionen Euro vom Bundesforschungsministerium fÃ¼r die mRNA-basierte Impfstoffentwicklung zugesagt.
    </p>

    

    




    

                
                    

    
    
        
    

    




    
        
        
            
            
            
            
            
                
            
            
            
            
            
            
        
    

                
                    

    
    
        

    

    <h2>Impfschutz wichtiger als AktionÃ¤rsinteressen</h2>


    

    




    

                
                    

    
    
        
    
    <p>
        "Die pharmazeutische Industrie sagt ja immer, die hohen Kosten entstehen aufgrund der Forschungs- und Entwicklungskosten, aber auch, weil der Nutzen so groÃŸ ist", sagt Wolf Dieter Ludwig. TatsÃ¤chlich kÃ¶nne man den Nutzen derzeit aber nicht endgÃ¼ltig beurteilen und die Forschung und Entwicklung sei zum Teil mit staatlichen Geldern subventioniert worden. Allein die US-Regierung zahlte mehrere Milliarden US-Dollar an verschiedene Hersteller. 
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        "Von daher sind diese hohen Preisforderungen aus meiner Sicht nicht berechtigt", sagt Ludwig. Er verstehe zwar, dass die AktionÃ¤re dieser Firmen auch ihren Anteil wollen. "Aber wir sind derzeit in einer Krisensituation, wo es das Ziel sein muss, nicht nur in den IndustrielÃ¤ndern, sondern weltweit zu impfen. Vor diesem Hintergrund, denke ich, haben die Interessen der AktionÃ¤re weniger Bedeutung als die Interessen der BevÃ¶lkerungen, die von dieser Pandemie befreit werden wollen."
    </p>

    

    




    

                
                    

    
    
        
    

    




    
        
        
            
            
            
            
            
            
            
                

    

        

        
    

            
            
            
            
        
    

                
                    

    
    
        
    

    




    
        
        
            
            
            
            
            
                
            
            
     â€¦</article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tagesschau.de/investigativ/ndr-wdr/corona-impfstoff-biontech-105.html">https://www.tagesschau.de/investigativ/ndr-wdr/corona-impfstoff-biontech-105.html</a></em></p>]]>
            </description>
            <link>https://www.tagesschau.de/investigativ/ndr-wdr/corona-impfstoff-biontech-105.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184301</guid>
            <pubDate>Thu, 18 Feb 2021 19:26:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Year of Rails]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26184215">thread link</a>) | @jashkenas
<br/>
February 18, 2021 | https://macwright.com/2021/02/18/a-year-of-rails.html | <a href="https://web.archive.org/web/*/https://macwright.com/2021/02/18/a-year-of-rails.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><picture><source srcset="https://macwright.com/images/2021-02-18-a-year-of-rails-railroad.webp" type="image/webp"><img alt="Railroad" src="https://macwright.com/images/2021-02-18-a-year-of-rails-railroad.jpg"></picture></p><p>I spent most of 2020 working with <a href="https://rubyonrails.org/">Ruby on Rails</a>. I moved a project from <a href="https://nextjs.org/">Next.js</a> + <a href="https://www.rust-lang.org/">Rust</a> toâ€¦&nbsp;Rails, baby! Back to the future. My earlier post on <a href="https://macwright.com/2020/05/10/spa-fatigue.html"><em>Second-guessing the modern web</em></a> was inspired by this experience, that for the product we were building, a â€˜modernâ€™ stack was not working as well as a traditional one.</p><p>We didnâ€™t do competitive analysis against Laravel, Django, or Phoenix. Theyâ€™re similar, not radically better or worse. There are multiple acceptable solutions to a problem, and this was more a matter of choosing the right <em>kind</em> of solution than pursuing some kind of perfect choice and burning hours and motivation doing the window-shopping.</p><p>What helped Rails win was that the team had a little more experience in Ruby (with the exception of myself), and we found plenty of resources for developing and deploying the stack. Rails fit perfectly into the ideology of <a href="http://boringtechnology.club/"><em>Choosing boring technology</em></a>. Another part of the product would be the hard, innovative part, so it made no sense to grapple with bleeding-edge web frameworks.</p><p>This was a really fun experience. Thereâ€™s a lot to love about Rails. Other communities could learn a bit from the Ruby &amp; Rails culture and wisdom. I wonâ€™t implement <em>everything</em> in Rails, but itâ€™ll be part of the toolbox.</p><p>Before this, I hadnâ€™t touched the stuff. And I bet a lot of people are like that - they came of age in the world of React and Go, and havenâ€™t tried anything even remotely similar to Rails. For their benefit, and to debrief from 2020, here are some notes on the experience. Plus, <a href="https://macwright.com/2020/10/28/if-not-spas.html">Rails-like projects in JavaScript</a> are ramping up quickly, and itâ€™s fun to know the origins.</p><h2 id="the-good">The good</h2><h3 id="debugging-rails-apps-is-amazing">Debugging Rails apps is amazing</h3><p>A while ago, I <a href="https://twitter.com/tmcw/status/1321133460501585922">wrote on Twitter</a></p><blockquote><p>the real reason why javascript developers donâ€™t use breakpoints and use console.log is that breakpoints donâ€™t work</p></blockquote><p>After years of working in JavaScript, Iâ€™m used to bad debugging experiences. The Chrome debuggerâ€™s <a href="https://developers.google.com/web/updates/2015/05/automatically-pause-on-any-exception">automatic pause on caught exceptions</a> is amazing, sometimes. But throwing a <code>debugger</code> statement in some React code is dodgy as hell. Sometimes it works, mostly it doesnâ€™t. You have to deal with code that might not have the right <a href="https://www.html5rocks.com/en/tutorials/developertools/sourcemaps/">sourcemap</a> to translate from bundled &amp; minified code to original source. Subtle abstractions like React hooks and advanced transpiler stuff like <a href="https://github.com/facebook/regenerator">Regenerator</a> mean that your codeâ€™s stacktrace probably looks nothing like what you expect, with lots of internal garbage. Sure, you can learn better techniques for diagnosing and debugging errors, but itâ€™s not just you - the debugging story in JavaScript is pretty bad. This applies even to Node.js, where one of the debugging stories is to connect Chromeâ€™s debugger to a Node.js instance:&nbsp;a finicky solution that doesnâ€™t consistently work.</p><p>In Rails, there is <a href="https://github.com/deivid-rodriguez/byebug">byebug</a>. You write <strong><code>byebug</code></strong> in your source code, and you get an interactive REPL right there. It works in views, controllers, database migrations, everywhere. It almost always works. Variables are named what you expect. The whole system is paused at that moment, and you can actually interact with it, using all of the Rails utilities and your installed gems.</p><p>If a page crashes unexpectedly, you get a similar REPL experience, in your browser, automatically. With an automatically cleaned-up stacktrace that excludes Railsâ€™s own frames. Like the byebug interface, this REPL actually works and is consistently helpful in finding root causes. Rarely will you need to use <code>puts</code> to print something to the console because this debugging system is so good.</p><h3 id="the-magic-mostly-works">The magic mostly works</h3><p>Our Rails app didnâ€™t have any <code>require</code> statements. You mention a moduleâ€™s name, and itâ€™s automatically included, using <a href="https://github.com/fxn/zeitwerk">Zeitwork</a>, a tool that comes standard with Rails.</p><p>This kind of system was terrifying to me before. What if you accidentally import something just by mentioning it? What if two things have the same name and you import the wrong one? How do you really know whatâ€™s happening? Sure, youâ€™re happy now, with all of that annoying importing and exporting taken care of, but the sky might fall.</p><p>Or maybe it justâ€¦ doesnâ€™t. Maybe impure, vaguely risky techniques are just a net positive over time, and making everything fully explicit isnâ€™t really necessary? Now when Iâ€™m using other systems, I wonder - what if I could just mention one of my React components and it would justâ€¦ be there? Sure, the system would have to complain if there were two components with the same name, and it would have to make assumptions about directory structure, but overall, wouldnâ€™t this be nice?</p><p>This applies to a lot of other parts of the system too. Rails is famous for doing pluralization - you name a model <code>Post</code> and you automatically get an interface called <code>posts</code>. But what, you ask, of words with uneven pluralization rules? Rails actually&nbsp;<a href="https://weblog.rubyonrails.org/2005/8/25/10-reasons-rails-does-pluralization/">does the right thing</a>, almost always. And when it fails, you can override it. It actually just saves time, reliably.</p><h3 id="testing-works">Testing works</h3><p>Iâ€™ve tried to test front-end applications. Iâ€™ve set up <a href="https://nightwatchjs.org/">nightwatch</a>, <a href="https://jestjs.io/">jest</a>, <a href="https://enzymejs.github.io/enzyme/">enzyme</a>, <a href="https://www.cypress.io/">cypress</a>, and probably 5-10 other frameworks. <em>Front-end testing is universally terrible.</em> Projects like Cypress are throwing untold hours into making it less terrible, taking on massive amounts of complexity to abstract away from fickle browser behavior and complex interactions.</p><p>But it still sucks. Frontend testing has no good attributes: itâ€™s unreliable, hard to automate, hard to debug when it fails, and often doesnâ€™t even assert for important behaviors, so it doesnâ€™t actually identify regressions. Running frontend tests in CI is resource-heavy, requiring you to set up headless X windows environments on servers or use specialized CI services that produce screencasts of test runs.</p><p>Testing fully-server-rendered applications, on the other hand, is <em>amazing</em>. A vanilla testing setup with Rails &amp; <a href="https://rspec.info/">RSpec</a> can give you fast, stable, concise, and actually-useful test coverage. You can actually assert for behavior and navigate through an application like a user would. These tests are solving a simpler problem - making requests and parsing responses, without the need for a full browser or headless browser, without multiple kinds of state to track.</p><p>Not only do the tests work better, the testing culture is a completely different universe. There are entire books written about how to write RSpec tests that catch bugs, allow software evolution, and arenâ€™t filled with boilerplate.</p><h3 id="gems-are-so-powerful">Gems are so powerful</h3><p>Powerful and dangerous.</p><p>Iâ€™m used to modules as they work in other systems - Python, Node, Elm, and so on. They provide objects, functions, and variables that you can import and combine into your code explicitly. Usually they sit on some specific level of abstraction - itâ€™s a utility for connecting to servers or a React component you can use.</p><p>Gems can do so much more. You install something like <a href="https://github.com/heartcombo/devise">Devise</a> into your system and it adds views, routes, methods, utilities, you name it. Itâ€™s not like â€œloading some functionsâ€, itâ€™s more like composing a whole different app <em>into</em> your app, implicitly.</p><p>This is obviously terrifying. It means that you canâ€™t look at your directories of views and your file of <code>routes.rb</code> and know what exists at a glance. There are other layers, lurking in the ephemeral space of third-party code. They interact in serious but uncertain ways.</p><p>But itâ€™s also pretty incredible - the idea that something like <a href="http://www.passportjs.org/">passport</a>, Nodeâ€™s middleware, could instead be a full-fledged authentication system. It means that you have to write a lot less code, and it also means that the people who <em>use</em> that code have a lot more code in common. That gems can work on a higher level of abstraction, making it possible to cobble together software faster, to write less â€˜glue code.â€™</p><h3 id="theres-so-much-good-writing-about-rails">Thereâ€™s so much good writing about Rails</h3><p>Even if you donâ€™t write Ruby, you should pay attention to <a href="https://sandimetz.com/">Sandi Metz</a>. Sheâ€™s incredibly wise and has so many incredible ideas to share.</p><p>And then thereâ€™s <a href="https://blog.arkency.com/">arkency</a>, <a href="https://thoughtbot.com/blog/">ThoughtBot</a>, and so many other thoughtful writers with years of experience in Rails. Sometimes itâ€™s a little shocking to google for some obscure problem and see a decade of discussion about it.</p><p>The best practices are also formalized into tools like <a href="https://codeclimate.com/">Code Climate</a> and <a href="https://github.com/troessner/reek">reek</a>. Iâ€™ve never seen so many actually-useful suggestions come out of automated systems as I did in the world of Ruby and Rails.</p><h3 id="ruby">Ruby</h3><p>Ruby is a pretty pleasant language to work in. Sure, it has a lot of syntax and a sprawling standard library, but you donâ€™t have to use all of that if you donâ€™t want to. It took me a while to adjust to the object-oriented way of doing things - in particular, the idea that you canâ€™t just have a free-range function floating out there, unassociated with a class or module, like you can in JavaScript. And you canâ€™t just create an arbitrary one-off object - you either need to define a class to create an object, or use a Hash to store data.</p><p>But Rubyâ€™s standard library isnâ€™t that huge. Iâ€™ve seen JavaScriptâ€™s â€˜standard libraryâ€™ grow a lot too, and frankly itâ€™s nice to have methods like <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/padStart"><code>String.prototype.padStart</code></a> instead of having every little thing in userspace. The only part that felt actively weird was <a href="https://rubygems.org/gems/activesupport/versions/6.1.1">activesupport</a> - a gem that extends Rubyâ€™s core objects, but is part of Rails. It felt weird to have <em>string</em> methods that would only work if your environment was Rails.</p><p>The <a href="https://kapeli.com/dash">Dash</a> app for documentation rocketed from my pile of unused tools to an absolute must-have. In the world of Ruby and Rails, with <em>most</em> gems having pretty good, semi-standard documentation, you can search for, and get answers, super fast. The Ruby language documentation and the Rails documentation is absolutely great. The JavaScript equivalent - <a href="https://developer.mozilla.org/en-US/">MDN</a> - pales in comparison.</p><h2 id="the-bad">The bad</h2><h3 id="the-asset-pipeline">The asset pipeline</h3><p>Remember SASS and the YUI Compressor? These are, unfortunately, defaults in the <a href="https://guides.rubyonrails.org/asset_pipeline.html">asset pipeline</a>. Thereâ€™s <a href="https://edgeguides.rubyonrails.org/webpacker.html">Webpacker</a> too, which has a parallel approach to CSS and images as the asset pipeline. It has <a href="https://github.com/rails/webpacker#integrations">opinionated integrations</a> with stuff like React. Ah, and I should mention that Railsâ€™s <a href="https://github.com/rails/rails/tree/main/actionview/app/assets/javascripts">JavaScript utilities are written inâ€¦ CoffeeScript</a>.</p><p>I get it - itâ€™s hard to keep up with the latest trends in frontend. But this is one â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://macwright.com/2021/02/18/a-year-of-rails.html">https://macwright.com/2021/02/18/a-year-of-rails.html</a></em></p>]]>
            </description>
            <link>https://macwright.com/2021/02/18/a-year-of-rails.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184215</guid>
            <pubDate>Thu, 18 Feb 2021 19:17:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing a RISC-V CPU, Part 1]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26184136">thread link</a>) | @newswasboring
<br/>
February 18, 2021 | https://mcla.ug/blog/risc-v-cpu-part-1.html#fnref:3 | <a href="https://web.archive.org/web/*/https://mcla.ug/blog/risc-v-cpu-part-1.html#fnref:3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
	
	<p><span>Tue 16 February 2021</span></p><p>I have no experience in digital logic design. That is, I didn't until I
recently decided that I would like to try designing my own CPU and running it
on an FPGA! If you too are a software engineer with a vague interest in
hardware design, I hope this series of posts about what I've learnt will be
helpful and interesting. In this first installment, I hope to answer these
questions:</p>
<ul>
<li>
<p>What is digital logic design?</p>
</li>
<li>
<p>How do I get started, and what tools might I use?</p>
</li>
</ul>
<p>In future installments, I will go into more detail about my CPU design and the
RISC-V architecture, as well as hopefully answering these questions:</p>
<ul>
<li>
<p>What about digital logic design is fundamentally different from software
  design?</p>
</li>
<li>
<p>What about digital logic design is similar to software design?</p>
</li>
</ul>
<p>You can see the code for my CPU at the time of writing
<a href="https://github.com/lochsh/riscy-boi/tree/47e94dc6e9665f73c871add002c34d1516fd5106">here</a>
or an up to date version <a href="https://github.com/lochsh/riscy-boi">here</a>.</p>
<h2>What is digital logic design?</h2>
<p>Digital logic design is designing logic circuits that operate on binary values.
The elementary components are logic gates: an AND gate, for example, has two
inputs and one output. The output is 1 iff<sup id="fnref:1"><a href="#fn:1">1</a></sup> both inputs are 1.</p>
<p>Typically, we design synchronous circuits which use flip-flops to store state,
and thereby synchronise the operation of the circuit to a common clock.
Flip-flops are composed of logic gates.</p>
<p>Analogue circuit design is concerned with the electronic components that make
up logic gates, like transistors and diodes. This level of abstraction is often
needed for applications dealing directly with signals derived from analogue
sensors, like radio receivers. When designing a CPU, this level of abstraction
would not be feasible: modern CPUs can have billions of transistors!</p>
<p>Instead, we use tools that can translate our digital logic design into
different useful formats: the configuration of an FPGA (see below); a
simulation; silicon layout.</p>
<h2>What is an FPGA and why are they used?</h2>
<p>We noted above that the same digital logic design tools can be used whether we
are creating a custom ASIC to be made into silicon, or configuring an FPGA. A
Field-Programmable Gate Array is an integrated circuit containing an array of
programmable logic blocks. You could imagine it is as a big array of logic
gates that can be connected together in various ways.</p>
<p>Making a custom chip generally costs millions, and of course once your chip is
manufactured it cannot be changed. Thus, generally FPGAs are used when:</p>
<ul>
<li>
<p>You cannot afford to create a custom ASIC due to lack of capital (e.g. if
  you're just some hacker like me and not ARM or Intel)</p>
</li>
<li>
<p>You cannot afford to create a custom ASIC because your volume is too low to
  make it worth the high one-off costs (e.g. if you are making a small quantity
  of MRI machines with custom data acquisition hardware)</p>
</li>
<li>
<p>You need the flexibility</p>
</li>
</ul>
<p>The downsides? FPGAs have a much higher per-chip cost, and they are generally
much slower as a consequence of being able to connect logic blocks together in
very flexible ways. In contrast, a custom design can be reduced to the minimum
number of transistors, with no concern for flexibility.</p>
<p>I think it's helpful context to compare the custom ASIC design process against
that of an FPGA design:</p>
<ul>
<li>
<p><span>Logic design</span>: just like we'd do for an FPGA, the logic design of an ASIC is
  done in a hardware description language.</p>
</li>
<li>
<p><span>Verification</span>: FPGA designs may well be verified, but you might expect the
  process for an ASIC design to be more rigorous â€“ after all, the design
  can't be changed once manufactured! Often verification will involve formally
  verifying<sup id="fnref:2"><a href="#fn:2">2</a></sup> parts of the design.</p>
</li>
<li>
<p><span>Synthesis</span>: This creates a <em>netlist</em>: a list of logic blocks and their
  connections. The connections are called <em>nets</em>, and the blocks are called
  <em>cells</em>. For both FPGAs and ASICs, the cells are vendor-specific.</p>
</li>
<li>
<p><span>Placement and routing</span> (P&amp;R): for an FPGA, this involves mapping the logic
  blocks described in the netlist to actual blocks in the FPGA. The resulting
  binary is often called a <em>bitstream</em>.  For an ASIC, this involves deciding
  where to place the cells on the silicon, and how to connect them up. Both
  applications generally use automated optimisation tools for this.</p>
</li>
</ul>
<h2>What tools do I need?</h2>
<h3>A hardware description language: I am using <a href="https://github.com/nmigen/nmigen">nMigen</a><sup id="fnref:3"><a href="#fn:3">3</a></sup></h3>
<p>You may have heard of Verilog or VHDL: both popular hardware description
languages (HDLs). I use "popular" here to mean widely used, not widely loved.</p>
<p>I won't pretend to know much about these tools: I only know that smarter people
than me with vast logic design experience have a lot of hate for them.
Due to the problems with Verilog and other similar tools, there have been
various attempts at making more useful and friendlier alternatives.  nMigen is
one such project, which creates a domain-specific language in Python. In their
own words:</p>
<blockquote>
<p>Despite being faster than schematics entry, hardware design with Verilog and
VHDL remains tedious and inefficient for several reasons. The event-driven
model introduces issues and manual coding that are unnecessary for
synchronous circuits, which represent the lion's share of today's logic
designs. Counterintuitive arithmetic rules result in steeper learning curves
and provide a fertile ground for subtle bugs in designs. Finally, support for
procedural generation of logic (metaprogramming) through "generate"
statements is very limited and restricts the ways code can be made generic,
reused and organized.</p>
<p>To address those issues, we have developed the nMigen FHDL, a library that
replaces the event-driven paradigm with the notions of combinatorial and
synchronous statements, has arithmetic rules that make integers always behave
like mathematical integers, and most importantly allows the design's logic to
be constructed by a Python program. This last point enables hardware
designers to take advantage of the richness of the Python languageâ€”object
oriented programming, function parameters, generators, operator overloading,
libraries, etc.â€”to build well organized, reusable and elegant designs.</p>
</blockquote>
<p>If, like me, you've never used Verilog, then not all of this will have more
than abstract meaning to you. But it certainly sounds promising,
and I can attest that it has been very straightforward to get started with
logic design without the reportedly large barrier of grappling with Verilog. I
would recommend it, particularly if you are already familiar with Python!</p>
<p>The only downside I can think of is that nMigen is still in development, and
in particular the documentation is not complete. There is a helpful community
at #nmigen on <a href="https://mcla.ug/blog/chat.freenode.net">chat.freenode.net</a>.</p>
<h3>A wave viewer for inspecting simulations: I am using <a href="http://gtkwave.sourceforge.net/">GTKWave</a></h3>
<p>nMigen provides simulation tooling: I use it in my tests, written using
<code>pytest</code>. I record the signals during these tests and view them in a wave
viewer to help debug.</p>
<p><img alt="gtkwave" src="https://mcla.ug/blog/images/gtkwave.png" title="A screenshot of GTKWave"></p>
<h3>Optional: An FPGA dev board. I am using a myStorm BlackIce II</h3>
<p>You don't need an FPGA dev board to create your own CPU. You could do
everything in simulation! The fun of having a board to work with, for me, is
being able to flash LEDs and see my design in action.</p>
<p>Of course, if you were creating something more useful than my very basic CPU,
then you would probably want some hardware to run it on, and this would be less
"optional"!</p>
<h2>Getting started with nMigen</h2>
<p>Rather than immediately trying to design a CPU, I started by making an
Arithmetic Logic Unit (ALU) in nMigen. The ALU is a key piece of any CPU design
that I have seen: it performs arithmetic operations.</p>
<p>Why start with this? I knew I would need an ALU for my CPU; I knew I could make
a simple one; I knew that the feeling of making something is an important
motivator when starting a new project!</p>
<p>My design looked something like this:</p>

<div>
<pre id="vimCodeElement"><span id="L1"> 1 </span><span>"""</span><span>Arithmetic Logic Unit</span><span>"""</span>
<span id="L2"> 2 </span><span>import</span> enum
<span id="L3"> 3 </span>
<span id="L4"> 4 </span><span>import</span> nmigen <span>as</span> nm
<span id="L5"> 5 </span>
<span id="L6"> 6 </span>
<span id="L7"> 7 </span><span>class</span> <span>ALUOp</span><span>(</span>enum<span>.</span>IntEnum<span>)</span><span>:</span>
<span id="L8"> 8 </span>    <span>"""</span><span>Operations for the ALU</span><span>"""</span>
<span id="L9"> 9 </span>    ADD <span>=</span> <span>0</span>
<span id="L10">10 </span>    SUB <span>=</span> <span>1</span>
<span id="L11">11 </span>
<span id="L12">12 </span>
<span id="L13">13 </span><span>class</span> <span>ALU</span><span>(</span>nm<span>.</span>Elaboratable<span>)</span><span>:</span>
<span id="L14">14 </span>    <span>"""</span>
<span id="L15">15 </span><span>    Arithmetic Logic Unit</span>
<span id="L16">16 </span>
<span id="L17">17 </span><span>    * op (in): the opcode</span>
<span id="L18">18 </span><span>    * a (in): the first operand</span>
<span id="L19">19 </span><span>    * b (in): the second operand</span>
<span id="L20">20 </span>
<span id="L21">21 </span><span>    * o (out): the output</span>
<span id="L22">22 </span><span>    </span><span>"""</span>
<span id="L23">23 </span>
<span id="L24">24 </span>    <span>def</span> <span>__init__</span><span>(</span>self<span>,</span> width<span>)</span><span>:</span>
<span id="L25">25 </span>        <span>"""</span>
<span id="L26">26 </span><span>        Initialiser</span>
<span id="L27">27 </span>
<span id="L28">28 </span><span>        Args:</span>
<span id="L29">29 </span><span>            width (int): data width</span>
<span id="L30">30 </span><span>        </span><span>"""</span>
<span id="L31">31 </span>        self<span>.</span>op <span>=</span> nm<span>.</span>Signal<span>()</span>
<span id="L32">32 </span>        self<span>.</span>a <span>=</span> nm<span>.</span>Signal<span>(</span>width<span>)</span>
<span id="L33">33 </span>        self<span>.</span>b <span>=</span> nm<span>.</span>Signal<span>(</span>width<span>)</span>
<span id="L34">34 </span>        self<span>.</span>o <span>=</span> nm<span>.</span>Signal<span>(</span>width<span>)</span>
<span id="L35">35 </span>
<span id="L36">36 </span>    <span>def</span> <span>elaborate</span><span>(</span>self<span>,</span> _<span>)</span><span>:</span>
<span id="L37">37 </span>        m <span>=</span> nm<span>.</span>Module<span>()</span>
<span id="L38">38 </span>
<span id="L39">39 </span>        <span>with</span> m<span>.</span>Switch<span>(</span>self<span>.</span>op<span>)</span><span>:</span>
<span id="L40">40 </span>            <span>with</span> m<span>.</span>Case<span>(</span>ALUOp<span>.</span>ADD<span>)</span><span>:</span>
<span id="L41">41 </span>                m<span>.</span>d<span>.</span>comb <span>+=</span> self<span>.</span>o<span>.</span>eq<span>(</span>self<span>.</span>a <span>+</span> self<span>.</span>b<span>)</span>
<span id="L42">42 </span>            <span>with</span> m<span>.</span>Case<span>(</span>ALUOp<span>.</span>SUB<span>)</span><span>:</span>
<span id="L43">43 </span>                m<span>.</span>d<span>.</span>comb <span>+=</span> self<span>.</span>o<span>.</span>eq<span>(</span>self<span>.</span>a <span>-</span> self<span>.</span>b<span>)</span>
<span id="L44">44 </span>        <span>return</span> m
</pre>
</div>

<p>As you can see, we've created a lot of nMigen <code>Signal</code> instances to represent
well...the signals that define the interface to our ALU! But what is this
<code>elaborate</code> method? My understanding is that "elaboration" is the name for the
first step in synthesising the netlist (see above). The idea in the nMigen code
above is that we've created some <em>elaboratable</em> structure (by inheriting from
<code>nm.Elaboratable</code>), i.e. something that describes digital logic we want to
synthesise. The <code>elaborate</code> method describes that digital logic. It has to
return an nMigen <code>Module</code>.</p>
<p>Let's have a closer look at the contents of the <code>elaborate</code> method. The
<code>Switch</code> will create some kind of decision logic in the synthesised design.
But what is <code>m.d.comb</code>? nMigen has the concept of synchronous (<code>m.d.sync</code>)
and combinatorial<sup id="fnref:4"><a href="#fn:4">4</a></sup> (<code>m.d.comb</code>) control domains. From the nMigen
<a href="https://nmigen.info/nmigen/latest/lang.html#lang-domains">docs</a>:</p>
<blockquote>
<p>A control domain is a named group of signals that change their value in
identical conditions.</p>
<p>All designs have a single predefined <em>combinatorial domain</em>, containing all
signals that change immediately when any value used to compute them changes.
The name comb is reserved for the combinatorial domain.</p>
<p>A design can also have any amount of user-defined <em>synchronous domains</em>, also
called clock domains, containing signals that change when a specific edge
occurs on the domainâ€™s â€¦</p></blockquote></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mcla.ug/blog/risc-v-cpu-part-1.html#fnref:3">https://mcla.ug/blog/risc-v-cpu-part-1.html#fnref:3</a></em></p>]]>
            </description>
            <link>https://mcla.ug/blog/risc-v-cpu-part-1.html#fnref:3</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184136</guid>
            <pubDate>Thu, 18 Feb 2021 19:11:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scala 3.0.0-RC1 â€“ first release candidate is here]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 7 (<a href="https://news.ycombinator.com/item?id=26184110">thread link</a>) | @tmfi
<br/>
February 18, 2021 | https://dotty.epfl.ch/blog/2021/02/17/scala3-rc1.html | <a href="https://web.archive.org/web/*/https://dotty.epfl.ch/blog/2021/02/17/scala3-rc1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-wrapper"> 
   <main> 
    <header> 
      
      
    </header> 
    <p>Greetings from the Scala 3 team! We are delighted to announce the first release candidate of the stable version of Scala 3 â€“ Scala 3.0.0-RC1.</p> 
    <p>This release brings some last-minute polishings, clean-ups and changes before the big release. There were a few language changes to improve the user experience, as well as the polishings of the metaprogramming framework. We have also worked on the issues that had to be fixed before the stable release.</p> 
    <p>Overall, more than <a href="https://github.com/lampepfl/dotty/pulls?q=is%3Apr+is%3Aclosed+closed%3A%3E2020-12-02+sort%3Acomments-desc">400 PRs</a> were merged after the M3 release and until today! Read more below!</p> <!--more--> 
     
    <p>Type parameters on extensions can now be combined with type parameters on the methods themselves. E.g.:</p> 
    <pre><code>List(1, 2, 3).second[Int]
extension [A](xs: List[A])
   def sumBy[B](f: A =&gt; B)(using Numeric[B]): B = ...
</code></pre> 
    <p>Type arguments matching method type parameters are passed as usual:</p> 
    <pre><code>List("a", "bb", "ccc").sumBy[Int](_.length)
</code></pre> 
    <p>By contrast, type arguments matching type parameters following <code>extension</code> can be passed only if the method is referenced as a non-extension method:</p> 
    <pre><code>sumBy[String](List("a", "bb", "ccc"))(_.length)
</code></pre> 
    <p>Or, when passing both type arguments:</p> 
    <pre><code>sumBy[String](List("a", "bb", "ccc"))[Int](_.length)
</code></pre> 
    <p>For discussion, see <a href="https://github.com/lampepfl/dotty/pull/10940">PR #10940</a>. For more information about the extension methods, see <a href="https://dotty.epfl.ch/docs/reference/contextual/extension-methods.html">documentation</a>.</p> 
     
    <p>The following are the changes to the <code>import</code> syntax made in this release.</p> 
    <p>Wildcard import <code>_</code> is replaced by <code>*</code>. The motivation is that the majority of other languages use <code>*</code>. For example:</p> 
    <pre><code>import scala.annotation.*  // imports everything in the annotation package
</code></pre> 
    <p>Renaming operator <code>=&gt;</code> is replaced by a soft keyword <code>as</code>. <code>as</code> is also allowed outside braces. For example:</p> 
    <pre><code>import scala.collection.mutable as mut
import NumPy as np
</code></pre> 
    <p>For the details and discussion, see <a href="https://github.com/lampepfl/dotty/pull/11244">PR #11244</a>. Read more about this change in the <a href="https://dotty.epfl.ch/docs/reference/changed-features/imports.html">documentation</a>.</p> 
     
    <p><a href="https://github.com/lampepfl/dotty/pull/11240">PR #11240</a> changed the syntax of vararg splices in patterns and function arguments. The new syntax uses a postfix <code>*</code>, instead of <code>: _*</code>, analogously to how a vararg parameter is declared.</p> 
     
    <p>An obscure use of <code>_</code> occurs in var definitions:</p> 
    <pre><code>var x: T = _
</code></pre> 
    <p>It defines a concrete variable x without an initial value, or rather the default initial value that the JVM assigns to object fields. It can only be used in a class or object, not to initialize a local variable.</p> 
    <p>We came up with an arguably better way to express this idiom: the special <code>uninitialized</code> value in the <code>scala.compiletime</code> object. To get an uninitialized field, you now write:</p> 
    <pre><code>import scala.compiletime.uninitialized

var x: A = uninitialized
</code></pre> 
    <p>This way expresses the intent of the idiom in a more verbose and easy to read way than simply writing an underscore.</p> 
    <p>For discussion, see <a href="https://github.com/lampepfl/dotty/pull/11231">PR #11231</a>, and the <a href="https://dotty.epfl.ch/docs/reference/dropped-features/wildcard-init.html">documentation</a> is available on our website.</p> 
     
    <p>Starting from RC1, we no longer generate a function parent for companions of case classes. Which means, for example, that given <code>case class Foo(x: Int)</code>, you won't be able to use <code>Foo</code> in a position where a function is expected:</p> 
    <pre><code>case class Foo(x: Int)
def f(g: Int =&gt; Foo) = g(10)

f(Foo)
</code></pre> 
    <p>Results in:</p> 
    <pre><code>1 |f(Foo)
  |  ^^^
  |The method `apply` is inserted. The auto insertion will be deprecated, please write `Foo.apply` explicitly.
</code></pre> 
    <p>As the warning suggests, now you should write <code>Foo.apply</code> instead of <code>Foo</code>. See <a href="https://github.com/lampepfl/dotty/issues/6190">Issue #6190</a> and <a href="https://github.com/lampepfl/dotty/pull/7207">PR #7207</a> for discussion.</p> 
     
    <p>We have settled on using the well-known <code>scaladoc</code> as a name for the documentation tool for Scala 3 (known previously as <code>scala3doc</code>).. The obsolete <code>dotty-doc</code> (or <code>scala3-doc</code>) is removed in RC1. We have also removed all the Kotlin dependencies (Dokka, etc.) from scaladoc. For details, see <a href="https://github.com/lampepfl/dotty/pull/11349">PR #11349</a>. To read more about <code>scaladoc</code>, see <a href="https://dotty.epfl.ch/docs/usage/scaladoc/index.html">documentation</a></p> 
     
    <p><a href="https://github.com/lampepfl/dotty/pull/11355">PR #11355</a> changes the <code>-source</code> specifier for the Scala version(s) after 3.0 from <code>3.1</code> to <code>future</code>. I.e. it is now <code>-source future</code> and <code>-source future-migration</code> instead of <code>-source 3.1</code> and <code>-source 3.1-migration</code>. Language imports are changed analogously. The reason for the change is that we want to keep the possibility open to ship a <code>3.1</code> version that does not yet contain all the changes enabled under <code>-source future</code>.</p> 
     
    <ul> 
     <li>Warn when matching against an opaque type <a href="https://github.com/lampepfl/dotty/pull/10664">#10664</a></li> 
     <li>Fix <a href="https://github.com/lampepfl/dotty/issues/8634">#8634</a>: Support -release option <a href="https://github.com/lampepfl/dotty/pull/10746">#10746</a> â€“ the same way Scala 2 does. This setting allows you to specify a version of the Java platform (8, 9 etc) and compile the code with classes specific to the that Java platform, and emit the bytecode for that version.</li> 
    </ul> 
     
    <p>A lot of work has been done on the metaprogramming side of things. Mostly we are cleaning up and polishing the API to prepare it for the stable release. The following are the important metaprogramming changes that took place:</p> 
    <ul> 
     <li>Add <code>scala.quoted.Expr.unapply</code> as dual of <code>Expr.apply</code> <a href="https://github.com/lampepfl/dotty/pull/10580">#10580</a></li> 
     <li>Remove <code>Expr.StringContext.unapply</code> <a href="https://github.com/lampepfl/dotty/pull/10675">#10675</a></li> 
     <li>Add reflect <code>MatchCase</code> <code>TypeRepr</code> <a href="https://github.com/lampepfl/dotty/pull/10735">#10735</a></li> 
     <li>Rename <code>scala.quoted.staging.{Toolbox =&gt; Compiler}</code> <a href="https://github.com/lampepfl/dotty/pull/11129">#11129</a></li> 
     <li>Fix <a href="https://github.com/lampepfl/dotty/issues/10863">#10863</a>: Make show <code>AnyKind</code>ed <a href="https://github.com/lampepfl/dotty/pull/10988">#10988</a></li> 
     <li>Add ParamClause to allow multiple type param clauses <a href="https://github.com/lampepfl/dotty/pull/11074">#11074</a></li> 
     <li>Rework reflect Symbol fields API <a href="https://github.com/lampepfl/dotty/pull/10705">#10705</a></li> 
     <li>Rename <code>Liftable</code> to <code>ToExpr</code> and <code>Unliftable</code> to <code>FromExpr</code> <a href="https://github.com/lampepfl/dotty/pull/10618">#10618</a></li> 
     <li>Expand non-transparent macros after Typer <a href="https://github.com/lampepfl/dotty/pull/9984">#9984</a></li> 
     <li>Rework TastyInspector API to allow inspection of all files <a href="https://github.com/lampepfl/dotty/pull/10792">#10792</a></li> 
     <li>Allow leading context parameters in extension methods <a href="https://github.com/lampepfl/dotty/pull/10940">#10940</a></li> 
     <li>Rename <code>Not</code> to <code>NotGiven</code> to make its purpose clearer <a href="https://github.com/lampepfl/dotty/pull/10720">#10720</a></li> 
     <li>Fix <a href="https://github.com/lampepfl/dotty/issues/10709">#10709</a>: Add missing level check before inlining <a href="https://github.com/lampepfl/dotty/pull/10781">#10781</a></li> 
    </ul> 
     
    <p>If you have questions or any sort of feedback, feel free to send us a message on our <a href="https://gitter.im/lampepfl/dotty">Gitter channel</a>. If you encounter a bug, please <a href="https://github.com/lampepfl/dotty/issues/new">open an issue on GitHub</a>.</p> 
    <h2><a href="#contributors" id="contributors"></a>Contributors</h2> 
    <p>Thank you to all the contributors who made this release possible ğŸ‰</p> 
    <p>According to <code>git shortlog -sn --no-merges 3.0.0-M3..3.0.0-RC1</code> these are:</p> 
    <pre><code>   183  Martin Odersky
   138  Nicolas Stucki
    36  Krzysztof Romanowski
    25  Filip ZybaÅ‚a
    25  Liu Fengyun
    24  Lan, Jian
    22  Jamie Thompson
    19  Tom Grigg
    17  Andrzej Ratajczak
    16  StÃ©phane Micheloud
    15  Guillaume Martres
    11  PaweÅ‚ Marks
     9  Phil
     6  Aleksander Boruch-Gruszecki
     6  Jonathan BrachthÃ¤user
     6  Natsu Kagami
     6  odersky
     4  Jasper Moeys
     4  Adrien Piquerez
     3  SÃ©bastien Doeraene
     3  MichaÅ‚ PaÅ‚ka
     3  Albert Chen
     2  Alexandre Archambault
     2  Som Snytt
     2  kenji yoshida
     2  Luc Henninger
     2  Ayush
     2  Raphael Jolly
     2  Anatolii Kmetiuk
     2  Olivier Blanvillain
     2  changvvb
     1  ysthakur
     1  Ang Hao Yang
     1  Ang9876
     1  AngAng
     1  August Nagro
     1  Ciara O'Brien
     1  Dale Wijnand
     1  Florian Cassayre
     1  Florian Schmaus
     1  Iltotore
     1  Jason Zaugg
     1  Julien Richard-Foy
     1  Katrix
     1  Master-Killer
     1  Michael Pilquist
     1  Mikael Blomstrand
     1  Mike Samuel
     1  Philippus
     1  Philippus Baalman
     1  Rick M
     1  Stephane MICHELOUD
     1  Timur Abishev
     1  Tomas
     1  ansvonwa
     1  ayush
     1  costa100
     1  iroha168
     1  noti0na1
     1  riiswa
     1  tanishiking
</code></pre> 
    <p>If you want to get your hands dirty and contribute to Scala 3, now is a good time to get involved! Head to our <a href="https://dotty.epfl.ch/docs/contributing/getting-started.html">Getting Started page for new contributors</a>, and have a look at some of the <a href="https://github.com/lampepfl/dotty/issues?q=is%3Aissue+is%3Aopen+label%3Aexp%3Anovice">good first issues</a>. They make perfect entry points into hacking on the compiler.</p> 
    <p>We are looking forward to having you join the team of contributors.</p> 
    <hr> 
    <p><img id="author-img" src="https://dotty.epfl.ch/images/anatolii.png"> <span id="author-signature"> Anatolii Kmetiuk </span> 
    </p> 
   </main> 
  </div></div>]]>
            </description>
            <link>https://dotty.epfl.ch/blog/2021/02/17/scala3-rc1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184110</guid>
            <pubDate>Thu, 18 Feb 2021 19:09:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rockset is up to 9.4 times faster than Druid on Star Schema Benchmark queries]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26184105">thread link</a>) | @box2A1
<br/>
February 18, 2021 | https://rockset.com/blog/rockset-up-to-9x-faster-than-apache-druid-star-schema-benchmark/ | <a href="https://web.archive.org/web/*/https://rockset.com/blog/rockset-up-to-9x-faster-than-apache-druid-star-schema-benchmark/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Real-time analytics is all about deriving insights and taking actions as soon as data is produced. When broken down into its core requirements, real-time analytics means two things: access to fresh data and fast responses to queries. These are essentially two measures of latency, which we term data latency and query latency, respectively.</p>
<p>Data latency is the time from when data is produced to when it can be queried, and is a function of how efficiently a database can sustain writes. As it usually gets less focus in benchmarks, we released <a href="https://rockset.com/blog/rockset-1-billion-events-in-a-day-with-1-second-data-latency/">RockBench</a>, a data latency benchmark, last September. Using RockBench, we ascertained Rocksetâ€™s suitability for many real-time analytics applications due to its ability to keep data latency to under 1 second, while ingesting 1 billion events per day, on a standard 4XLarge Virtual Instance.</p>
<h3>Query Latency and the Star Schema Benchmark</h3>
<p>Query latency is the second key measure of real-time analytics performance and is the focus of the rest of this post.
To evaluate query latency, we turned to the Star Schema Benchmark (SSB), an industry-standard benchmark to measure database performance on analytical applications. The SSB was designed for a batch analytics scenario, rather than real-time analytics, but will still yield useful insight into Rocksetâ€™s performance on analytical queries.</p>
<p>The SSB has also been used for performance measurements of other modern data technologies. In June 2020, Imply released a <a href="https://go.imply.io/rs/910-OTN-223/images/Apache-Druid-and-Google-BigQuery-performance-evaluation.pdf">study</a> of Apache Druid and Google BigQuery performance on the SSB. For the Rockset benchmark, we used the same hardware resources that were used in the Druid benchmark to provide greater context for our SSB evaluation.</p>
<h3>Up to 9.4x Faster than Druid</h3>
<p>From the benchmarking results, we observed one SSB query execute 9.4x faster on Rockset than on Druid, with many queries running 2x to 4x faster. The entire SSB suite ran 1.5x faster on <a href="https://rockset.com/comparisons/rockset-vs-apache-druid">Rockset compared to Druid</a>. This demonstrates better performance with resource parity, since pricing was not available for a true price-performance comparison.</p>
<p>In making these comparisons, we recognize we are not experts in configuring Druid, so we relied on a benchmark report from those who have the most knowledge about their system and can tune it best. In addition, benchmarks represent a snapshot in time, and systems will get faster with each new release. We are using the most recent benchmark published by Imply for comparison, but we expect Druid performance will continue to improve, as will Rocksetâ€™s.</p>
<h3>Running the Star Schema Benchmark on Rockset</h3>
<p><strong>Benchmark Overview</strong></p>
<p>The SSB comprises a suite of 13 analytical SQL queries that provide a good combination of functional and selectivity coverage.</p>
<p>We conducted the benchmark using SSB data at scale factor 100, which corresponds to 100GB and 600M rows of data. We denormalized the generated data prior to loading to provide a more direct comparison to the Druid benchmark, which avoided query-time joins, since Druid only recently added some limited join support.</p>
<p><span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/6wQnA481EPGFKQEBq9jqlD/c385adf28f987ec64149ee5ce6b6af4c/rockset-ssb-diagram.png?w=560&amp;fm=webp 560w,
https://images.ctfassets.net/1d31s1aajogl/6wQnA481EPGFKQEBq9jqlD/c385adf28f987ec64149ee5ce6b6af4c/rockset-ssb-diagram.png?w=1120&amp;fm=webp 1120w,
https://images.ctfassets.net/1d31s1aajogl/6wQnA481EPGFKQEBq9jqlD/c385adf28f987ec64149ee5ce6b6af4c/rockset-ssb-diagram.png?w=2240&amp;fm=webp 2240w" sizes="(max-width: 590px) 100vw, 590px" type="image/webp">
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/6wQnA481EPGFKQEBq9jqlD/c385adf28f987ec64149ee5ce6b6af4c/rockset-ssb-diagram.png?w=560 560w,
https://images.ctfassets.net/1d31s1aajogl/6wQnA481EPGFKQEBq9jqlD/c385adf28f987ec64149ee5ce6b6af4c/rockset-ssb-diagram.png?w=1120 1120w,
https://images.ctfassets.net/1d31s1aajogl/6wQnA481EPGFKQEBq9jqlD/c385adf28f987ec64149ee5ce6b6af4c/rockset-ssb-diagram.png?w=2240 2240w" sizes="(max-width: 590px) 100vw, 590px">
          <img alt="rockset-ssb-diagram" title="" src="https://images.ctfassets.net/1d31s1aajogl/6wQnA481EPGFKQEBq9jqlD/c385adf28f987ec64149ee5ce6b6af4c/rockset-ssb-diagram.png" loading="lazy">
        </picture>
        </span>
      </span>
<em>Figure 1: Performance harness used to generate and load SSB data, run queries and measure query runtimes</em></p>
<p>Loading into Rockset was straightforward and required zero configuration, apart from specifying some keys for column-based clustering. Once the SSB data was loaded into Rockset, we ran a load-generator query script, based on the Rockset Python client, that issued queries and measured runtimes.</p>
<p><strong>Benchmark Results</strong></p>
<p>We recorded the following runtimes across the 13 SSB queries.</p>
<p><span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/gtyqIwjx5kKG2PxpXGrJk/2842c3354e855724fee008c2a252a1da/rockset-ssb-results.png?w=281&amp;fm=webp 281w,
https://images.ctfassets.net/1d31s1aajogl/gtyqIwjx5kKG2PxpXGrJk/2842c3354e855724fee008c2a252a1da/rockset-ssb-results.png?w=562&amp;fm=webp 562w,
https://images.ctfassets.net/1d31s1aajogl/gtyqIwjx5kKG2PxpXGrJk/2842c3354e855724fee008c2a252a1da/rockset-ssb-results.png?w=1124&amp;fm=webp 1124w" sizes="(max-width: 590px) 100vw, 590px" type="image/webp">
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/gtyqIwjx5kKG2PxpXGrJk/2842c3354e855724fee008c2a252a1da/rockset-ssb-results.png?w=281 281w,
https://images.ctfassets.net/1d31s1aajogl/gtyqIwjx5kKG2PxpXGrJk/2842c3354e855724fee008c2a252a1da/rockset-ssb-results.png?w=562 562w,
https://images.ctfassets.net/1d31s1aajogl/gtyqIwjx5kKG2PxpXGrJk/2842c3354e855724fee008c2a252a1da/rockset-ssb-results.png?w=1124 1124w" sizes="(max-width: 590px) 100vw, 590px">
          <img alt="rockset-ssb-results" title="" src="https://images.ctfassets.net/1d31s1aajogl/gtyqIwjx5kKG2PxpXGrJk/2842c3354e855724fee008c2a252a1da/rockset-ssb-results.png" loading="lazy">
        </picture>
        </span>
      </span>
<em>Figure 2: Benchmark results when running SSB on Rockset (600M rows, 100GB data set)</em></p>
<p>All queries in the SSB suite executed in under 1 second on Rockset, with a median runtime of 254 ms. This result demonstrates Rocksetâ€™s ability to run complex analytics with sub-second performance, a common requirement for real-time analytics applications.</p>
<p>When comparing to these results with Druidâ€™s, we observe that 9 out of the 13 queries ran faster on Rockset. Rockset was 9.4x faster on the query with the largest speedup, with many queries in the 2x to 4x range, whereas Druidâ€™s largest advantage was a 3.2x speedup. The suite of 13 queries completed in 4,146 ms on Rockset compared to 6,043 ms on Druid, corresponding to a 1.5x speedup overall. The following figures show Rocksetâ€™s query runtimes compared to those reported in Implyâ€™s Druid and BigQuery paper.</p>
<p><span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/3iI6RKmdNIU1LMPZADHr4L/c85c70cd8a53d8a2e25f1359e210f5ab/rockset-druid-ssb.png?w=408&amp;fm=webp 408w,
https://images.ctfassets.net/1d31s1aajogl/3iI6RKmdNIU1LMPZADHr4L/c85c70cd8a53d8a2e25f1359e210f5ab/rockset-druid-ssb.png?w=815&amp;fm=webp 815w,
https://images.ctfassets.net/1d31s1aajogl/3iI6RKmdNIU1LMPZADHr4L/c85c70cd8a53d8a2e25f1359e210f5ab/rockset-druid-ssb.png?w=1630&amp;fm=webp 1630w" sizes="(max-width: 590px) 100vw, 590px" type="image/webp">
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/3iI6RKmdNIU1LMPZADHr4L/c85c70cd8a53d8a2e25f1359e210f5ab/rockset-druid-ssb.png?w=408 408w,
https://images.ctfassets.net/1d31s1aajogl/3iI6RKmdNIU1LMPZADHr4L/c85c70cd8a53d8a2e25f1359e210f5ab/rockset-druid-ssb.png?w=815 815w,
https://images.ctfassets.net/1d31s1aajogl/3iI6RKmdNIU1LMPZADHr4L/c85c70cd8a53d8a2e25f1359e210f5ab/rockset-druid-ssb.png?w=1630 1630w" sizes="(max-width: 590px) 100vw, 590px">
          <img alt="rockset-druid-ssb" title="" src="https://images.ctfassets.net/1d31s1aajogl/3iI6RKmdNIU1LMPZADHr4L/c85c70cd8a53d8a2e25f1359e210f5ab/rockset-druid-ssb.png" loading="lazy">
        </picture>
        </span>
      </span>
<em>Figure 3: Comparing Rockset and Druid SSB results</em></p>
<p><span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/2nTaKbhcNK407P8T9r15ye/477be128e68d9a5535629d2cbccbbb7f/rockset-ssb-graph.png?w=429&amp;fm=webp 429w,
https://images.ctfassets.net/1d31s1aajogl/2nTaKbhcNK407P8T9r15ye/477be128e68d9a5535629d2cbccbbb7f/rockset-ssb-graph.png?w=857&amp;fm=webp 857w,
https://images.ctfassets.net/1d31s1aajogl/2nTaKbhcNK407P8T9r15ye/477be128e68d9a5535629d2cbccbbb7f/rockset-ssb-graph.png?w=1714&amp;fm=webp 1714w" sizes="(max-width: 590px) 100vw, 590px" type="image/webp">
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/2nTaKbhcNK407P8T9r15ye/477be128e68d9a5535629d2cbccbbb7f/rockset-ssb-graph.png?w=429 429w,
https://images.ctfassets.net/1d31s1aajogl/2nTaKbhcNK407P8T9r15ye/477be128e68d9a5535629d2cbccbbb7f/rockset-ssb-graph.png?w=857 857w,
https://images.ctfassets.net/1d31s1aajogl/2nTaKbhcNK407P8T9r15ye/477be128e68d9a5535629d2cbccbbb7f/rockset-ssb-graph.png?w=1714 1714w" sizes="(max-width: 590px) 100vw, 590px">
          <img alt="rockset-ssb-graph" title="" src="https://images.ctfassets.net/1d31s1aajogl/2nTaKbhcNK407P8T9r15ye/477be128e68d9a5535629d2cbccbbb7f/rockset-ssb-graph.png" loading="lazy">
        </picture>
        </span>
      </span>
<em>Figure 4: Graph showing Rockset, Druid and BigQuery runtimes on SSB queries</em></p>
<h3>How Rockset Accelerates Real-Time Analytics</h3>
<p>Several Rockset features work in concert to accelerate these SSB queries and real-time analytics in general.</p>
<ul>
<li>Converged Indexâ„¢</li>
<li>Column-based clustering</li>
<li>Vectorization</li>
</ul>
<p><strong>Converged Index</strong></p>
<p>Rockset stores all ingested data in a <a href="https://rockset.com/blog/how-rocksets-converged-index-powers-real-time-analytics/">Converged Index</a>, which is a combination of: </p>
<ul>
<li>Inverted index</li>
<li>Column-based index</li>
<li>Row-based index</li>
</ul>
<p>Each query can take advantage of the index that is best suited for it and leads to the fastest execution. For instance, highly selective queries typically benefit from using the inverted index, while queries that require aggregations over large numbers of records will benefit from using the column-based index. By indexing data in three different ways, multiple types of queries can be executed efficiently without any manual intervention.</p>
<p><strong>Column-based clustering</strong></p>
<p>Users can configure column-based clustering so as to colocate data according to a clustering key they specify. This maximizes the opportunity for sequential access and reduces the amount of data that needs to be scanned for each query.</p>
<p><strong>Vectorization</strong></p>
<p>Rockset uses columnar data chunks to exchange data between query execution operators. This allows vectorized processing, where operations are performed on many values, instead of one value, at a time, resulting in more efficient query execution.</p>
<h3>What This Means for Developers of Real-Time Analytics</h3>
<p>With this SSB performance evaluation, we determined that Rockset is capable of delivering the sub-second query latency needed for real-time analytics, with better performance than alternatives like Druid. Coupled with the earlier RockBench evaluation that established Rocksetâ€™s ability to analyze data being written in real time, we see that Rockset can be a good fit for real-time analytics applications that require fast queries on the latest data. These include many use cases like logistics tracking, security analytics, e-commerce personalization, gaming leaderboards and customer-facing SaaS analytics.</p>
<p>While this evaluation was performed on a denormalized data set, Rockset's design also allows it to execute joins efficiently, so applications are not limited to operating on denormalized data. Future work would include running Rockset performance evaluations involving joins on normalized data.</p>
<p>Additionally, SSB data is well structured and therefore less representative of the real-life semi-structured data sets we commonly come across. It should be noted that Rockset can support the same analytical SQL queries on complex, nested data as well.</p>
<p>Given Rocksetâ€™s ability to provide both the write and read performance required for real-time analytics, we invite you to include Rockset in your consideration if you are developing real-time analytics features or products. Read the <a href="http://rockset.com/star-schema-benchmark">Rockset Performance Evaluation on the Star Schema Benchmark</a> white paper to get the details on how we ran the SSB evaluation. Or, <a href="https://console.rockset.com/create">sign up for a free Rockset account</a> to try running your own queries on Rockset!</p></div></div>]]>
            </description>
            <link>https://rockset.com/blog/rockset-up-to-9x-faster-than-apache-druid-star-schema-benchmark/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184105</guid>
            <pubDate>Thu, 18 Feb 2021 19:09:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The 1802 Membership Card Computer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26183553">thread link</a>) | @bilegeek
<br/>
February 18, 2021 | http://www.sunrise-ev.com/1802.htm | <a href="https://web.archive.org/web/*/http://www.sunrise-ev.com/1802.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Once upon a time, microcomputers were simple and easy to understand. So simple in fact that a kid like me, with no computer experience whatsoever, could actually understand them, build them, program them, and put them to work in his very own projects!</p><p>The COSMAC 1802 was created in the 1970's at the dawn of the microcomputer revolution, by <a href="https://en.wikipedia.org/wiki/Joseph_Weisbecker">Joseph Weisbecker</a> of RCA Corporation. It used their new CMOS fabrication process, which had very low power consumption, very high noise immunity, and was very simple to use. It was intended for military and aerospace; applications too tough for other microcomputers to survive.</p><p>But Joe was a hacker at heart. He wrote a series of articles starting in the August 1976 issue of Popular Electronics magazine called "Build the COSMAC ELF". It described a simple low-cost computer, using the 1802 microprocessor. At the time, microcomputer systems cost hundreds to thousands of dollars. (Hmm... they still do today!) But Weisbecker's ELF cost about $80! Yet, it was an honest-to-goodness real live computer, able to do anything its much bigger cousins could do -- albeit a bit slower and cruder.</p><p>It was the ideal computer trainer. Hobbyists built thousands of ELFs, learning about computer design, construction, and programming in the process. A dozen companies produced versions of the ELF, also selling for low prices. It was the "Legos" of computers; a simple building-block computer that could be assembled many ways to become almost anything, limited only by your imagination.</p><p>I learned about computing on my ELF. It put me on a career in engineering, as it did for thousands of others. 1802's got designed into all sorts of amazing things; video games, music synthesizers, auto engine controllers, military weapon systems, and even NASA missions such as the Galileo spacecraft. Eat stardust, PCs and Macs!</p><p>Today's computers are far more powerful than the 1802. But they have also become so complicated that virtually no one can build them or truly understand how they work. We depend on someone else to make them for us, and to provide us with the megabytes of pre-written software needed to do anything with them. You can't learn the basics if there is nothing "basic" to learn on! I decided to do something about it.</p><p>The <strong>Membership Card</strong> is a reproduction of the original Popular Electronics Elf computer, repackaged to fit in a pocket-sized Altoids(R) tin. It is entirely built with 1980's parts and technology. It uses only common low-cost through-hole parts (no custom ICs or surface-mount assembly). To use it, you don't need a modern PC, or megabytes of proprietary software. Now you can learn about computers right from the ground up, and <u>really</u> understand how they work!</p><div>

<img src="http://www.sunrise-ev.com/MembershipCard/dev4k-cpu-asm.jpg" width="464" height="279" title="Membership Card Assembled" alt="Membership Card Assembled">
<img src="http://www.sunrise-ev.com/photos/pixelshim.gif" width="12" height="279">

<h3>What's inside?</h3>

<p>There are two circuit boards, each the size of a credit card. One is the <strong>Membership Card</strong> itself. It has the 1802 microprocessor, up to 64k bytes of memory, 22 bits of I/O, clock, reset, and power supply circuits, plus a supercapacitor to maintain memory contents without power. It can be used by itself as a microcontroller for projects like the Parallax BASIC Stamps or Arduino microcontrollers. All power, input, and output signals are available on the 30-pin header along the bottom.</p>
<br clear="left">

<img src="http://www.sunrise-ev.com/MembershipCard/dev4j-fpanel-asm.jpg" width="464" height="286" title="Membership Card Front Panel Assembled" alt="Membership Card Front Panel Assembled">
<img src="http://www.sunrise-ev.com/photos/pixelshim.gif" width="12" height="286">

<p>The second board is the <strong>Front Panel</strong>. It provides the switches and LEDs for a "blinkin-lights" control panel, just like the classic computers of old. The Front Panel lets you read and write to memory and I/O ports manually, without any help from software or external devices. A USB-serial adapter (<a href="https://www.sparkfun.com/products/9718">Sparkfun #9718</a> or equivalent) plugs directly into the 6-pin header to provide power and serial I/O. The Front Panel also brings the power and I/O signals out to a robust DB25 to connect external devices. It can be plugged into a PC parallel or RS-232 serial port, so a PC can load, save, and run programs.</p>

<p>The Membership Card can be purchased as a bare board with manual, or as a complete kit with all parts including the RCA 1802 microcomputer, 32k bytes of RAM, and even an empty Altoids tin to put it all in. An optional Cover Card provides a finished cover with holes and labels for all the lights, switches, and connectors.</p>

<img src="http://www.sunrise-ev.com/MembershipCard/mshipcardkit.jpg" width="400" height="285" title="Membership Card Kit" alt="Membership Card Kit">
<img src="http://www.sunrise-ev.com/photos/pixelshim.gif" width="20" height="285">

<h3>Specifications</h3>
<ul>
<li>CPU: RCA CDP1802ACE microprocessor.
</li><li>Clock: Stable 4 MHz ceramic resonator.
</li><li>Memory:	32k bytes RAM; plus socket for another 32k RAM or EPROM. Supercapacitor holds RAM contents without power.
</li><li>I/O: one 8-bit output port, with LEDs.
<br>one 8-bit input port, with switches.
<br>one 1-bit output, with red LED.
<br>four 1-bit flag inputs, one with pushbutton switch, one with green LED
<br>one interrupt input.
</li><li>Connectors: 6-pin power/TTL serial connector (/ON, TX, RX, +V, GND).
<br>25-pin DB25 connector with all I/O (power, PC parallel, RS-232 serial).
</li><li>Size: 3-1/2" x 2-1/8" x 3/4" (89 x 54 x 19 mm).
</li><li>Power: 3v to 5v DC at 0.1 to 5ma (depends on clock speed, memory size, and number of LEDs on).
</li><li>Aroma: A hint of curiously strong peppermint.
</li></ul>

<a name="1802mc-special">
<p>The <b>Membership Card</b> is your ticket to the fascinating world of microcomputing. Return with us now to those thrilling days of yesteryear, when the heroic pioneers of the microcomputer revolution built their own computers from scratch, and learned to program them to do incredible things, all for a tiny amount of money!</p>

<hr>
</a><ul><a name="1802mcbare">
	</a><li><a name="1802mcbare"></a><a href="http://www.sunrise-ev.com/MembershipCard/memberk3.pdf">Membership Card Manual, rev.K3</a> in PDF format. This is the current version.
	</li><li><a href="http://www.sunrise-ev.com/MembershipCard/dev4k3-sch.png">Membership Card Schematic</a> in PNG format. How often do you get a real schematic for anything today? The schematic, parts list, and part sources are all in the manual as well.
	</li><li><a href="http://www.sunrise-ev.com/MembershipCard/1802cpuK3.pdf">"Special" 1802 CPU Card Quickstart Manual</a> in PDF format. This is an abbreviated manual for operating the 1802MC CPU card by itself.
	</li><li><a href="http://www.sunrise-ev.com/MembershipCard/memberjk3.pdf">Membership Card Manual, rev.JK3</a> in PDF format. Rev.JK3 was the previous version I was shipping last year. Email me if you need a manual for an older version.
	</li><li><a href="http://www.sunrise-ev.com/MembershipCard/1802cheatsheet.pdf">1802 Elf "Cheat Sheet"</a> in PDF format. A pocket card with the 1802 pinouts, instruction set, and operating summary for the Membership Card and other 1802-based computers.
	</li></ul>
Software
	<ul>
	<li>BASIC for the 1802
		<ul>
		<li><b>Tiny BASIC</b> is Tom Pittman's classic 1976 integer BASIC in just 2K bytes. Lee Hart, Herb Johnson, and Loren Christiansen have tweaked it for the 1802MC's memory map. The vintage TMSI IDIOT monitor is included for serial I/O.
			<ul>
			<li><a href="http://www.sunrise-ev.com/photos/1802/tb0_christiansen.zip">Tiny BASIC</a> is a ZIP file with everything needed. Burn the HEX file into a 4K-32K EPROM. Address the EPROM at 0000h, and RAM at 8000h. It's currently assembled to run with a rev.J or later Front Panel.
			</li><li><a href="http://www.ittybittycomputers.com/IttyBitty/TinyBasic/TBuserMan.txt">Tiny BASIC User Manual</a> by Tom Pittman (c) 1976. It documents the language, and provides many examples and internal details. His <a href="http://www.ittybittycomputers.com/IttyBitty/TinyBasic/">website</a> has more info, sample programs, and the interesting history of Tiny BASIC.
			</li><li><a href="http://www.ittybittycomputers.com/IttyBitty/TinyBasic/TBEK.txt">Tiny BASIC Experimenters Kit</a> This booklet provides many internal details, including an assembler for the intermediate language that Tiny BASIC was written in.
			</li><li><a href="http://www.sunrise-ev.com/photos/1802/TFBOTBAS.HTM">The First Book of Tiny BASIC Programs</a> by Tom Pittman (c) 1981. This is a gold mine of impressive Tiny BASIC programs; games, spreadsheets, disassemblers, etc.
			</li></ul>
		</li><li><b>BASIC3</b> is RCA's floating-point BASIC (equivalent to Microsoft BASIC), written by Ron Cenker in 1981. It's been resurrected by Chuck Yakym, Ed Keefe, Herb Johnson, and Lee Hart to run on the 1802MC or any ELF using the EF3 and Q pins for serial input/output.
			<ul>
			<li><a href="http://www.sunrise-ev.com/MembershipCard/BASIC3v11user.pdf">BASIC3 User Manual</a> for RCA BASIC3, in PDF format.
			</li><li>BASIC3 program ROMs: Download, and burn into a 16K 27C128 or 32K 27C256 EPROM. Address it to start at 0000h (U2-LO), and RAM to start at 8000h (U8-HI). BASIC3 starts immediately on power-up or reset, so no Front Panel or "jump" instruction is needed to start it. BASIC3 includes an auto-start feature; if a BASIC program is stored in ROM, it will run automatically on power-up or reset. <a href="http://www.sunrise-ev.com/MembershipCard/CALL3800.pdf">CALL3800.pdf</a> describes how to use this feature.
				<ul>
				<li><a href="http://www.sunrise-ev.com/MembershipCard/MCBASIC3.bin">MCBASIC3.bin</a> for any version Membership Card by itself (no Front Panel); or with rev.I and earlier MC Front Panels.
				</li><li><a href="http://www.sunrise-ev.com/MembershipCard/MCBASIC3J.bin">MCBASIC3J.bin</a> with rev.J and later Membership Card Front Panels.
				</li></ul>
			</li></ul>
		</li></ul>

</li><li>Monitor programs
	<ul>
	<li>Chuck Yakym's <b>MCSMP Super Monitor Program</b> plus <b>BASIC3</b>, in a single 32K EPROM. Download, and burn it into a 27C256 EPROM. Here are his <a href="http://www.sunrise-ev.com/MembershipCard/Readme.txt">Quickstart notes</a> and <a href="http://www.sunrise-ev.com/MembershipCard/MCSMP20.pdf">Instructions</a> for installing and running MCSMP in PDF format.
<ul>
<li>Versions for an EPROM at 8000h (jumper U2-HI), and RAM at 0000h (jumper U8-LO). In classic ELF fashion, you need a front panel to load an LBR 8000h instruction (C0 80 00) into the first 3 bytes of RAM, and execute it.
<ul>
<li><a href="http://www.sunrise-ev.com/MembershipCard/MCSMP20.bin">MCSMP20.bin</a> for any Membership Card with rev.I or earlier Front Panels.
</li><li><a href="http://www.sunrise-ev.com/MembershipCard/MCSMP20J.bin">MCSMP20J.bin</a> with rev.J and later MC Front Panels.
</li><li><a href="http://www.sunrise-ev.com/MembershipCard/mcsmp20r_vt52_1.1.bin">MCSMP20J plus VT52 Adventureland</a> <span color="red">NEW!</span> MCSMP20J with "Adventureland", written in 1980 by famous game author Scott Adams. It's brought to you by the tireless efforts of Richard Goedeken. Instructions and the source code (licensed under BSD are available <a href="https://github.com/richard42/1802-adventureland-plus">HERE</a> on Github. This version uses VT52 ESC commands, so set your Terminal program for VT52 emulation.
</li><li><a href="http://www.sunrise-ev.com/MembershipCard/mcsmp20r_ansi_1.1.bin">MCSMP20J plus ANSI Adventureland</a> Same, but this version uses ANSI ESC commands to add color. Set your Terminal program for ANSI mode.
</li></ul>
</li><li>Versions for an EPROM at 0000h (jumper U2-LO), and RAM at 8000h (jumper U8-HI). The monitor starts immediately on power-up or reset, so no Front Panel or LBR instruction is needed to start them.
<ul>
<li><a href="http://www.sunrise-ev.com/MembershipCard/MCSMP20A.bin">MCSMP20A.bin</a> for any version Membership Cards, either stand-alone, or with rev.I or earlier Front Panels.
</li><li><a href="http://www.sunrise-ev.com/MembershipCard/MCSMP20B.bin">MCSMP20B.bin</a> for any Membership Card with rev.J or later Front Panels.
</li></ul>
</li></ul>
</li><li><b>ELF-LINK</b> by Josh Bensadon controls the Membership Card from a PC parallel port. No software at all is needed in the Membership Card itself to examine and change memory, and load, save, and execute programs. Here is <a href="http://www.sunrise-ev.com/MembershipCard/ELF-LINK.BAS">ELF-LINK.BAS for QuickBASIC</a> in plain ASCII format, so you can see how to do it with your favorite programming language. And here is <a href="http://www.sunrise-ev.com/MembershipCard/ELF-LINK.exe">ELF-LINK.exe in executable format</a> if you don't have QuickBASIC. Who will be the first to translate it into C? :-)
	</li></ul>
	</li></ul>
More 1802 Information
	<ul>
	<li><a href="http://www.exemark.com/Microcontrollers/PopularElecwebc.pdf">Build the COSMAC "ELF" -- A Low-Cost Experimenter's Microcomputer</a>. The original Aug 1976 Popular Electronics article by Joseph Weisbecker that started it all.
	</li><li><a href="http://www.sunrise-ev.com/vcf-elf.htm">The VCF-ELF</a> is â€¦</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.sunrise-ev.com/1802.htm">http://www.sunrise-ev.com/1802.htm</a></em></p>]]>
            </description>
            <link>http://www.sunrise-ev.com/1802.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-26183553</guid>
            <pubDate>Thu, 18 Feb 2021 18:27:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Frax: Worldâ€™s first fractional-algorithmically stabilized stablecoin]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 4 (<a href="https://news.ycombinator.com/item?id=26183483">thread link</a>) | @Bluestein
<br/>
February 18, 2021 | https://docs.frax.finance/overview | <a href="https://web.archive.org/web/*/https://docs.frax.finance/overview">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div data-editioncontainer="true"><div data-slate-editor="true" data-key="c661deaabfde4250bbd107c32d586f40" autocorrect="on" spellcheck="true" data-gramm="false"><p data-key="5c2f6050e8fe4fbea3690680c1d996b1"><span><span data-key="6ccd4104bbe54ed8bfc0983c8bef054d"><span data-offset-key="6ccd4104bbe54ed8bfc0983c8bef054d:0">Many stablecoin protocols have entirely embraced one spectrum of design (entirely collateralized) or the other extreme (entirely algorithmic with no backing). Collatralized stablecoins either have custodial risk or require on-chain overcollateralization. These designs provide a stablecoin with a fairly tight peg with higher confidence than purely algorithmic designs. Purely algorithmic designs such as Basis, Empty Set Dollar, and Seigniorage Shares provide a highly trustless and scalable model that captures the early Bitcoin vision of decentralized money but with useful stability. The issue with algorithmic designs is that they are difficult to bootstrap, slow to grow (as of Q4 2020 none have significant traction), and exhibit extreme periods of volatility which erodes confidence in their usefulness as actual stablecoins. They are mainly seen as a game/experiment than a serious alternative to collateralized stablecoins.

Frax attempts to be the first stablecoin protocol to implement design principles of both to create a highly scalable, trustless, extremely stable, and ideologically pure on-chain money. The Frax protocol is a two token system encompassing a stablecoin, Frax (FRAX), and a governance token, Frax Shares (FXS). The protocol also has pool contracts which hold collateral (at genesis USDT and USDC). Pools can be added or removed with governance.

Although there's no predetermined timeframes for how quickly the amount of collateralization changes, we believe that as FRAX adoption increases, users will be more comfortable with a higher percentage of FRAX supply being stabilized algorithmically rather than with collateral. The collateral ratio refresh function in the protocol can be called by any user once per hour. The function can change the collateral ratio in steps of .25% if the price of FRAX is above or below $1. When FRAX is above $1, the function lowers the collateral ratio by one step and when the price of FRAX is below $1, the function increases the collateral ratio by one step. Both refresh rate and step parameters can be adjusted through governance. In a future update of the protocol, they can even be adjusted dynamically using a PID controller design. The price of FRAX, FXS, and collateral are all calculated with a time-weighted average of the Uniswap pair price and the ETH:USD Chainlink oracle. The Chainlink oracle allows the protocol to get the true price of USD instead of an average of stablecoin pools on Uniswap. This allows FRAX to stay stable against the dollar itself which would provide greater resiliency instead of using a weighted average of existing stablecoins only.</span></span></span></p><p data-key="6a0fb64f8ddf49a292075e3f23b3f9a4"><span><span data-key="c7f1350efb8f4be4bbfcd688e0dcabba"><span data-offset-key="c7f1350efb8f4be4bbfcd688e0dcabba:0">FRAX stablecoins can be minted by placing the appropriate amount of its constituent parts into the system. At genesis, FRAX is 100% collateralized, meaning that minting FRAX only requires placing collateral into the minting contract. During the fractional phase, minting FRAX requires placing the appropriate ratio of collateral and burning the ratio of Frax Shares (FXS). While the protocol is designed to accept any type of cryptocurrency as collateral, this implementation of the Frax Protocol will mainly accept on-chain stablecoins as collateral to smoothen out volatility in the collateral so that FRAX can transition to more algorithmic ratios smoothly. As the velocity of the system increases, it becomes easier and safer to include volatile cryptocurrency such as ETH and wrapped BTC into future pools with governance. </span></span></span></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://docs.frax.finance/overview</link>
            <guid isPermaLink="false">hacker-news-small-sites-26183483</guid>
            <pubDate>Thu, 18 Feb 2021 18:22:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cutting Build Time in Half with Dockerâ€™s Buildx Kubernetes Driver]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26183334">thread link</a>) | @jeremy_k
<br/>
February 18, 2021 | https://releaseapp.io/blog/cutting-build-time-in-half-docker-buildx-kubernetes | <a href="https://web.archive.org/web/*/https://releaseapp.io/blog/cutting-build-time-in-half-docker-buildx-kubernetes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>At Release, environments are our main focus, but we canâ€™t create environments without builds. Recently we undertook a project to revisit our build infrastructure and determine if it needed to be upgraded. Build times had become a big factor in our service delivery and we needed a way to improve our customersâ€™ experiences. One of the main areas that we wanted to improve upon was the parallelism of building multiple docker images for a single application.</p><p>The title of the article already spoiled the solution, and the alternative â€˜Release Did This One Thing To Cut Their Build Time In Half!â€™ didnâ€™t quite fly with the rest of the company, but Dockerâ€™s new <a href="https://github.com/docker/buildx" target="_blank" rel="noreferrer">buildx</a> project fit the bill. First, weâ€™ll cover what our original infrastructure looked like and how long builds on an example project were taking. Then, weâ€™ll describe the changes we made to use buildx and the speed increases we observed.</p><p>Letâ€™s start off with a diagram of what our original infrastructure looked like.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/75WoaAxoZMIL73zK0JKPId/f98ff948f97c0cc7b979c4b4352a032c/release-builder-architecture.png" alt="release-builder-architecture"></p><p>As you can see, the requests for builds would flow into our main Rails application and then divvied out to the different builder instances through Sidekiq. The <code>builder</code> container is Ruby code that would authenticate to Github, clone the repository, check out the correct SHA, and then execute the <code>docker build</code>. Due to the way we built the authentication to pull the code from Github, a single <code>builder</code> container could only clone one repository at a time. Which meant that the container could only do a single build request at a time. We added threading in the Ruby code to be able to execute multiple <code>docker build</code> commands at a time, but the number of builder containers we had spun up limited our concurrent builds. While itâ€™s not hard to horizontally scale with Kubernetes, we saw this authentication setup as a major bottleneck. </p><p>Another issue we encountered was that we had no mechanism for attempting to place builds on servers where they had been previously built, instead opting for grabbing the first free server. This meant there was very little chance to land on the same server and get the full benefit of Docker caching. While this isnâ€™t a deal breaker for us, we still believed we could do better when creating the version of our build infrastructure. Enough of the theoretical, letâ€™s actually build something!</p><p>Release Applications can contain many docker images and one of our favorite example repositories to showcase this is our fork of <a href="https://github.com/awesome-release/release-example-voting-app" target="_blank" rel="noreferrer">example-voting-app</a>. Looking at the <a href="https://github.com/awesome-release/release-example-voting-app/blob/master/docker-compose.yml" target="_blank" rel="noreferrer">docker-compose</a> we see that there are 3 different Docker images that we have to build, <code>result</code>, <code>vote</code>, and <code>worker</code>. Now that we have an understanding of Releaseâ€™s original infrastructure and the application we want to build, letâ€™s start up a fresh build and see the results.</p><p><em>NOTE</em> I forked the <code>awesome-release</code> repo to my own Github, <code>jer-k</code> for the following results.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/21reYa1lgqocT6MTojva4J/0d6826574fb8718d76bfcf6c855dd490/uncached-release.png" alt="uncached-release"></p><p>We can see that this brand new build with no cache hits took two minutes and 15 seconds to complete. Next, we want to make a few changes to ensure that each Docker image needs to be rebuilt. The changes are listed below.</p><div><pre><p><span>1</span><span>git status</span></p><p><span>2</span><span>On branch release_builders</span></p><p><span>3</span><span>Changes to be committed:</span></p><p><span>4</span><span>  (use "git restore --staged &lt;file&gt;..." to unstage)</span></p><p><span>5</span><span>    modified:   result/views/index.html</span></p><p><span>6</span><span>    modified:   vote/app.py</span></p><p><span>7</span><span>    modified:   worker/src/main/java/worker/Worker.java</span></p></pre></div><p>For the purpose of this blog post, I ensured the following build ran on the same builder as the first and that we will have cache hits. As noted before, this wasnâ€™t always the case in our production environment.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/69tKlV3mBuV6S6c7BhSaay/c51464f443c1888cd4f74fe3394b32f4/cached-release.png" alt="cached-release"></p><p>The caching helps and cuts 45 seconds off the build! The uncached build took almost twice as long as the second build with caching, but our assumption was that we could do a lot better (cached and uncached) with some new technology.</p><h2 id="enter-dockers-buildx-kubernetes-driver">Enter Dockerâ€™s Buildx Kubernetes Driver</h2><p>One of the first things we wanted to solve was the concurrency issue and we set out to ensure that Docker itself was able to handle a larger workload. We came across the issue <a href="https://github.com/moby/moby/issues/9656" target="_blank" rel="noreferrer">Concurrent â€œdocker buildâ€ takes longer than sequential builds</a> where people were describing what we feared; Docker slowed down when many builds were being run at the same time. Lucky for us, that issue was opened in 2014 and plenty of work had been done to resolve this issue. The final comment, by a member of the Docker team, was <a href="https://github.com/moby/moby/issues/9656#issuecomment-610476810" target="_blank" rel="noreferrer">â€œClosing this. BuildKit is highly optimized for parallel workloads. If you see anything like this in buildkit or buildkit compared to legacy builder please report a new issue with a repro case.â€</a> Thus we set out to learn more about <a href="https://docs.docker.com/develop/develop-images/build_enhancements/" target="_blank" rel="noreferrer">BuildKit</a> (the Github repository is located <a href="https://github.com/moby/buildkit" target="_blank" rel="noreferrer">here</a>). While researching, we came across <a href="https://github.com/docker/buildx" target="_blank" rel="noreferrer">buildx</a>, which ended up having three key features we believed would resolve many of our issues. These three features were the <a href="https://github.com/docker/buildx#buildx-bake-options-target" target="_blank" rel="noreferrer">bake</a> command, the <a href="https://github.com/docker/buildx#--driver-driver" target="_blank" rel="noreferrer">buildx kubernetes driver</a>, and the ability for the Kubernetes driver to consistently send builds to the same server. Letâ€™s cover each of these, first up the <code>bake</code> command.</p><div><pre><p><span>1</span><span>buildx bake [OPTIONS] [TARGET...]</span></p><p><span>2</span><span>Bake is a high-level build command.</span></p><p><span>3</span><span></span></p><p><span>4</span><span>Each specified target will run in parallel as part of the build.</span></p></pre></div><p><code>bake</code> intrigued us because it seemed to be a built-in command for us to avoid using Ruby threading for our parallelism. <code>bake</code> takes an input of a file, which can either be in the form of a <code>docker-compose</code>, <code>.json</code>, or <code>.hcl</code>. We initially tested <code>bake</code> with the docker-compose from example-voting-app and we were blown away at how smoothly it built directly out of the box and how quickly it was able to build the three images! However, we opted to create our own <code>.json</code> file generator in Ruby, parsing our <a href="">Application Template</a> into an output. Here is our generated file for example-voting-app.</p><div><pre><p><span>1</span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>"group"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>3</span><span>    </span><span>"default"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>4</span><span>      </span><span>"targets"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>5</span><span>        </span><span>"vote"</span><span>,</span><span></span></p><p><span>6</span><span>        </span><span>"result"</span><span>,</span><span></span></p><p><span>7</span><span>        </span><span>"worker"</span><span></span></p><p><span>8</span><span>      </span><span>]</span><span></span></p><p><span>9</span><span>    </span><span>}</span><span></span></p><p><span>10</span><span>  </span><span>}</span><span>,</span><span></span></p><p><span>11</span><span>  </span><span>"target"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>12</span><span>    </span><span>"vote"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>13</span><span>      </span><span>"context"</span><span>:</span><span> </span><span>"./vote"</span><span>,</span><span></span></p><p><span>14</span><span>      </span><span>"tags"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>15</span><span>        </span><span>"&lt;REDACTED&gt;.dkr.ecr.us-west-2.amazonaws.com/jer-k/release-example-voting-app/vote:latest"</span><span>,</span><span></span></p><p><span>16</span><span>        </span><span>"&lt;REDACTED&gt;.dkr.ecr.us-west-2.amazonaws.com/jer-k/release-example-voting-app/vote:buildx-builders"</span><span></span></p><p><span>17</span><span>      </span><span>]</span><span></span></p><p><span>18</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>19</span><span>    </span><span>"result"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>20</span><span>      </span><span>"context"</span><span>:</span><span> </span><span>"./result"</span><span>,</span><span></span></p><p><span>21</span><span>      </span><span>"tags"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>22</span><span>        </span><span>"&lt;REDACTED&gt;.dkr.ecr.us-west-2.amazonaws.com/jer-k/release-example-voting-app/result:latest"</span><span>,</span><span></span></p><p><span>23</span><span>        </span><span>"&lt;REDACTED&gt;.dkr.ecr.us-west-2.amazonaws.com/jer-k/release-example-voting-app/result:buildx-builders"</span><span></span></p><p><span>24</span><span>      </span><span>]</span><span></span></p><p><span>25</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>26</span><span>    </span><span>"worker"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>27</span><span>      </span><span>"context"</span><span>:</span><span> </span><span>"./worker"</span><span>,</span><span></span></p><p><span>28</span><span>      </span><span>"tags"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>29</span><span>        </span><span>"&lt;REDACTED&gt;.dkr.ecr.us-west-2.amazonaws.com/jer-k/release-example-voting-app/worker:latest"</span><span>,</span><span></span></p><p><span>30</span><span>        </span><span>"&lt;REDACTED&gt;.dkr.ecr.us-west-2.amazonaws.com/jer-k/release-example-voting-app/worker:buildx-builders"</span><span></span></p><p><span>31</span><span>      </span><span>]</span><span></span></p><p><span>32</span><span>    </span><span>}</span><span></span></p><p><span>33</span><span>  </span><span>}</span><span></span></p><p><span>34</span><span></span><span>}</span></p></pre></div><p>There are other inputs which can make their way into this file, such as build args, but since example-voting-app does not have any, they are omitted.</p><p>Next, we wanted to find more information on the Kubernetes driver and we found this blog post <a href="https://medium.com/nttlabs/buildx-kubernetes-ad0fe59b0c64" target="_blank" rel="noreferrer">Kubernetes driver for Docker BuildX</a> from the author of the <a href="https://github.com/docker/buildx/pull/167" target="_blank" rel="noreferrer">Pull Request</a>. We encourage you to read the latter as it covers getting up and running with the Kubernetes driver as well how the caching works, which is exactly what we needed. With that information in hand, we were able to start work on adding the buildx servers to our cluster. We created a generic way to deploy the servers into different clusters and adjust the number of replicas with the final command being</p><div><pre><p><span>1</span><span>docker buildx create --name #{name} --driver kubernetes --driver-opt replicas=#{num_replicas},namespace=#{builder_namespace} --use</span></p></pre></div><p>For us, we created a <code>release-builder</code> namespace with five replicas, in our development cluster. We can see the output by querying for the pods</p><div><pre><p><span>1</span><span>kubectl get pods --namespace=release-builder</span></p><p><span>2</span><span>NAME                            READY   STATUS    RESTARTS   AGE</span></p><p><span>3</span><span>development0-86d99fcf46-26j9f   1/1     Running   0          6d10h</span></p><p><span>4</span><span>development0-86d99fcf46-5scpq   1/1     Running   0          6d13h</span></p><p><span>5</span><span>development0-86d99fcf46-jkk2b   1/1     Running   0          15d</span></p><p><span>6</span><span>development0-86d99fcf46-llkgq   1/1     Running   0          18d</span></p><p><span>7</span><span>development0-86d99fcf46-mr9jt   1/1     Running   0          20d</span></p></pre></div><p>Since we have five replicas, we wanted to ensure that when we build applications, they end up on the same server so that we get the greatest amount of caching possible (distributed caching is a topic for another day). Luckily for us, <code>buildx</code>, with the Kubernetes driver, has an option for where to send the builds called <code>loadbalance</code>.</p><div><pre><p><span>1</span><span>loadbalance=(sticky|random) - Load-balancing strategy. </span></p><p><span>2</span><span>If set to "sticky", the pod is chosen using the hash of the context path. Defaults to "sticky"</span></p></pre></div><p>The default <code>sticky</code> means that the builds should always end up on the same server due to the hashing (more detailed information on this is described in the aforementioned blog post). With all of that in place, we are ready to test out our new setup!</p><p>Using the same example-voting-app repository as before, I created a new branch <code>buildx_builders</code> and pointed the code to the buildx servers. </p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/3gqbExE2XQMNqyUQ60m27m/9e215fc99510b5a18bb6792eba5679ec/uncached-buildx.png" alt="uncached-buildx"></p><p>What we see is that this uncached build was more than twice as fast as the other uncached build and even faster than the cached build on the old infrastructure! But uncached builds should be a thing of the past with the sticky load balancing, so letâ€™s make the same changes as the previous branch and see the results.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/2MxDyCqaSrOnffVSNC3SFu/abc0896e3eef27b927394b12fc9e1e29/cached-buildx.png" alt="cached-buildx"></p><p>This build finished three times faster than the previous cached build! These types of speed increases are the reason we set out to redo our build infrastructure. The faster the builds complete, the faster we can create environments and help our customers deliver their products.</p><p>Weâ€™re still experimenting with <code>buildx</code> and learning as we go, but the initial results were more than enough for us to migrate our own production builds to the new infrastructure. Weâ€™re going to continue to blog about this topic as we learn more and scale so check back in with the Release blog in the future!</p></div></article></div>]]>
            </description>
            <link>https://releaseapp.io/blog/cutting-build-time-in-half-docker-buildx-kubernetes</link>
            <guid isPermaLink="false">hacker-news-small-sites-26183334</guid>
            <pubDate>Thu, 18 Feb 2021 18:11:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dockerize Your Dev Env]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26183231">thread link</a>) | @benzaita
<br/>
February 18, 2021 | https://benzaita.github.io/dockerized-cli/index.html | <a href="https://web.archive.org/web/*/https://benzaita.github.io/dockerized-cli/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            <div>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/code.svg"></figure>
                    
                    <p>
                        Declare which build and/or development tools are needed in code, rather than in a README file.
                    </p>
                </section>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/door.svg"></figure>
                    
                    <p>
                        Bootstrapping a development environment is as easy as running <code>dockerized shell</code>.
                    </p>
                </section>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/checkmark.svg"></figure>
                    
                    <p>
                        No more "Works on my machine" because everyone in the team is using
                        exactly the same toolset.
                    </p>
                </section>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/flip-horizontal.svg"></figure>
                    
                    <p>
                        Your CI can use exactly the same toolset as your developers.
                    </p>
                </section>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/dock-row.svg"></figure>
                    
                    <p>
                        No need for <code>nvm</code>, <code>virtualenv</code>, <code>SDKMAN</code>, and such. Each
                        development environment is isolated.
                    </p>
                </section>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/drink-margarita.svg"></figure>
                    
                    <p>
                        You no longer need to maintain messy <code>docker run</code> commands yourself.
                    </p>
                </section>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/magic-wand.svg"></figure>
                    
                    <p>
                        Just prepend any command with <code>dockerized exec</code>.
                    </p>
                </section>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/vscode.svg"></figure>
                    
                    <p>
                        "dockerized" complements VS Code and can use the <a href="https://code.visualstudio.com/docs/remote/containers">Remote Container</a>
                        you already configured.
                    </p>
                </section>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/emoji.svg"></figure>
                    
                    <p>
                        You can use the "dockerized" development environment, or set up one
                        directly on your machine. Unlike other tools
                        "dockerized" is a non-intrusive guest on your machine.
                    </p>
                </section>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/fast.svg"></figure>
                    
                    <p>
                        "dockerized" can <a href="https://github.com/benzaita/dockerized-cli/wiki/Caching-the-'dockerized'-image">cache</a> the build environment to speed up builds on CI pipelines.
                    </p>
                </section>
            </div>
        </article></div>]]>
            </description>
            <link>https://benzaita.github.io/dockerized-cli/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26183231</guid>
            <pubDate>Thu, 18 Feb 2021 18:02:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GPT-3, Esq? Evaluating AI Legal Summaries [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 39 (<a href="https://news.ycombinator.com/item?id=26183114">thread link</a>) | @gavelin
<br/>
February 18, 2021 | http://www.davidvictorrodriguez.com/uploads/2/6/4/2/26420847/gpt-3_esq_-_evaluating_ai_legal_summaries.pdf | <a href="https://web.archive.org/web/*/http://www.davidvictorrodriguez.com/uploads/2/6/4/2/26420847/gpt-3_esq_-_evaluating_ai_legal_summaries.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.davidvictorrodriguez.com/uploads/2/6/4/2/26420847/gpt-3_esq_-_evaluating_ai_legal_summaries.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26183114</guid>
            <pubDate>Thu, 18 Feb 2021 17:53:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Turn an Idea into a Business]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26183057">thread link</a>) | @davidkolodny
<br/>
February 18, 2021 | https://www.wilburlabs.com/blueprints/how-to-turn-an-idea-into-a-business | <a href="https://web.archive.org/web/*/https://www.wilburlabs.com/blueprints/how-to-turn-an-idea-into-a-business">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Turning an idea into a business can be one of the most fulfilling and rewarding challenges of a lifetime. ItÃ¢â‚¬â„¢s not easy, but the skills and experiences required to start a business are learnable. </p><p>Great entrepreneurs are made, not born. Hard work, drive, and absolute determination can make up for gaps in skills and experience. The rest is learned by doing, making mistakes, and adapting along the way.</p><p>Wilbur Labs is a startup studio turning bold ideas into market-leading companies. Since 2016 we have launched and invested in 15 technology companies, including <a href="https://www.vacationrenter.com/">VacationRenter</a>, <a href="https://www.vitabox.com/">Vitabox</a>, <a href="https://www.joblist.com/">Joblist</a>, and <a href="https://www.barkbus.com/">Barkbus</a>. Today, our portfolio companies have hundreds of millions of users from around the world, and have generated billions of dollars in sales. We plan to launch several companies every year.</p><p>One question that weÃ¢â‚¬â„¢re constantly asked is: <br></p></div><h2>How do you turn an idea into a business?</h2><div><p>Launching a business is typically a one-time event. At Wilbur Labs, itÃ¢â‚¬â„¢s a repeatable and systematized process. Turning a bold idea into a business Ã¢â‚¬â€œ over and over Ã¢â‚¬â€œ is what we do. Over time, we have defined several critical steps that are key to effectively turn any idea into a business. WeÃ¢â‚¬â„¢re sharing that playbook with you to help you on your journey.</p><p><em>Note: This guide assumes that you already have an idea for a business. Coming up with an idea for a company is a separate topic covered in our <a href="https://www.wilburlabs.com/blueprints/how-to-get-startup-ideas">How to Get Startup Ideas</a> Blueprint.</em></p></div><h2>Step 1: Research</h2><div><p>The research stage is where you pair your initial idea with independent and external information. This should include first-hand research, speaking with industry experts, and talking with target customers to answer key questions:</p><ul><li>What problem are you trying to solve? </li><li>How big is this problem?</li><li>How would this make people's lives better?</li><li>Why are the current solutions not optimal?</li><li>Who are the competitors?</li><li>What is the business model?</li><li>How big of a business could you build?</li><li>Are you the right person to solve this problem?</li><li>What advantages do you have in solving this problem?</li><li>Do you care about this enough to work on it for 5+ years?</li><li>What are the outstanding challenges or questions?</li></ul><p>During this stage, you should talk with as many people as possible. You will be surprised how many target customers and industry experts are receptive to cold outreach to discuss a business idea. We recommend using LinkedIn or Twitter to source experts who know the problem you are trying to solve, and ask if theyÃ¢â‚¬â„¢re open to having a quick chat to discuss your idea. Many people passionate about an industry or a problem love talking with others who are equally as interested.</p><p>In addition to cold outreach, you should also use your personal network to reach out to any existing industry contacts who may be helpful Ã¢â‚¬â€œ or know people who might be helpful Ã¢â‚¬â€œ in researching this idea.</p><p>Be cautious about asking business advice from people close to you, because itÃ¢â‚¬â„¢s unlikely that you will get truly honest and critical feedback. Expect pushback because itÃ¢â‚¬â„¢s unlikely that everyone will love your idea, and thatÃ¢â‚¬â„¢s okay. Some of our boldest ideas received mixed feedback in the beginning. The point here is that you hear multiple viewpoints and use feedback to guide your research and planning. </p><p>Make sure to go very deep on your research during this stage. Some of our ideas remain in this stage for 6 to 12 months. Ideas are easy and everyone has them. This stage helps filter out the so-so ideas to prevent you from wasting time in a later stage. Frontloading research and due diligence here can also reduce risk and expedite future stages.</p><p>The best business ideas will bring a sense of urgency and motivation, pushing you to keep moving forward. If you are able to gain significant momentum through research, it makes sense to move into the planning stage.</p></div><h2>Step 2: Plan</h2><div><p>In the planning stage you should focus on taking your learnings and creating an executable plan. This will require diving deeper into the areas you looked into during the research phase, as well as answering new questions.</p><p>At Wilbur Labs, we create a Ã¢â‚¬Å“Concept EvaluationÃ¢â‚¬ï¿½ which is our own version of a business plan. Whatever format you choose, itÃ¢â‚¬â„¢s important to have a written plan that organizes all your research into an actionable plan that looks at every angle of your idea.</p><p>We like to work backwards during this stage, thinking about how we want the business to look 3 to 5 years ahead and then build a roadmap to get there. In our Concept Evaluation, we answer a number of questions, including but not limited to:</p><ul><li>What does the product look like at launch, year 1, year 2, etc?</li><li>How will you get customers (marketing/distribution)? How much will it cost?</li><li>What are the sources of revenue?</li><li>WhatÃ¢â‚¬â„¢s the expected lifetime value of a customer?</li><li>How will you retain customers long term to boost lifetime value?</li><li>Where is the break-even point (cost) of this business?</li><li>Where is the break-even point (time) of this business?</li><li>How do you solve the challenges you identified in the research phase?</li><li>What initial investment is required to get this off the ground?</li><li>How much time will it take to get this off the ground?</li><li>What investment is required over the next 3-5 years?</li><li>WhatÃ¢â‚¬â„¢s the optimal funding source?</li><li>What partnership(s) will you need?</li><li>What type of infrastructure will this company need?</li><li>What team is needed to build and grow this business?</li><li>What advisors could you reach out to for help?</li></ul><p>In addition to answering the questions above, our Concept Evaluations also include a product roadmap/gantt chart, financial model, and start-up checklist.<strong><br></strong></p><h3><strong>Product Roadmap</strong></h3><p>The product roadmap and corresponding gantt chart provide a simple, but tangible way to look at the different work streams that will be a part of each phase of the business. The key here is to plan out dependencies, so you can parallel process and avoid bottlenecks.</p><p>You wonÃ¢â‚¬â„¢t be able to do everything on day one. The important question to ask yourself during this planning stage is: what is the Minimum Viable Product (MVP) that you can launch with and how do you build on that MVP post launch? We are believers in launching as soon as possible to collect real customer feedback and use that to evolve the product along the way. <strong><br></strong></p><h3><strong>Financial Model</strong></h3><p>Our financial model is built using assumptions we find on our own, or inputs from industry experts. While this model is likely to change in the real world, we want to keep a close eye on the economics and the break even point. This is used to forecast the growth plan, timing, and investment level required. </p><p>Funding is a separate topic on its own and there is no universal best practice to finance a business. As an entrepreneur, you will need to look at a number of factors, including your personal situation, business cash requirements, and long term plan. ItÃ¢â‚¬â„¢s worth spending time with advisors or mentors to discuss the best funding option for your situation. <strong><br></strong></p><h3><strong>Startup Checklist</strong></h3><p>We love checklists and have a checklist for everything. Checklists ensure consistency and completeness in carrying out a task. Checklists also allow you to frontload all the planning so you can focus on executing at the next stage. For our startup checklist, we include everything required to get from day zero to launch day. This includes corporate structuring and entity formation; legal and accounting prep; compliance, hiring, product building; distribution and marketing; operations, partnerships, and business development. We are extremely thorough and write out every critical task, corresponding notes, status, and owner.</p><p>Before moving on to the next stage you should ask yourself, <em>Ã¢â‚¬Å“Do I want to spend the next 5+ years of my life building this business?Ã¢â‚¬ï¿½ </em></p><p>More often than not, entrepreneurship is not a way to get rich quickly. You will likely need to work harder and longer, with higher stress and more at stake than working a regular day job. The journey is absolutely worth it for the right person, but itÃ¢â‚¬â„¢s important that you go into it knowing what to expect. Many companies die early due to missed expectations on what it takes to start a company. If possible, you can start out part-time and build traction before diving in full-time. </p><p>If you want to dedicate years of your life solving this problem, and building a business along the way, then move on to the execute phase.</p></div><h2>Step 3: Execute</h2><div><p>Every single person has ideas, but very few take the jump and start a company. The execution stage is where you leave the planning stage and take that jump. You have spent time researching, putting together a plan, and you are now ready to dedicate time to building a business.</p><p>Depending on the type of business, this stage will look very different. In all cases, this stage involves working through your plan, roadmap, and startup checklist to begin getting your idea off the ground. </p><p>The primary focus of this stage is prioritization. Prioritizing often will allow you to manage bottlenecks and work in parallel across different areas of your business. The goal is to align your input (time &amp; money) with the activities that will yield the highest output (progress on your plan). This is easier said than done, but it is absolutely critical to execute your plan in an efficient way.</p><p>If you need to raise money or get funding, this is the stage where that could happen. This is also the stage where you may need to start building your team by hiring contractors or employees. </p></div><h2>Step 4: Adapt</h2><div><p>Roughly 90% of businesses fail, and this is the stage where that usually happens. One thingÃ¢â‚¬â„¢s for certain in starting a business: you will never be able to create and follow a bulletproof plan. As your business takes off, youÃ¢â‚¬â„¢ll need to constantly adapt and change your plan. The best entrepreneurs are comfortable being uncomfortable, adapting as they go.</p><p>The optimal Ã¢â‚¬Å“go liveÃ¢â‚¬ï¿½ point will vary by business. At Wilbur Labs, we strongly believe that getting customers to vote for products and services with their wallet or with their time is by far the best measure of product-market fit. If customers wonÃ¢â‚¬â„¢t spend time or money on your â€¦</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.wilburlabs.com/blueprints/how-to-turn-an-idea-into-a-business">https://www.wilburlabs.com/blueprints/how-to-turn-an-idea-into-a-business</a></em></p>]]>
            </description>
            <link>https://www.wilburlabs.com/blueprints/how-to-turn-an-idea-into-a-business</link>
            <guid isPermaLink="false">hacker-news-small-sites-26183057</guid>
            <pubDate>Thu, 18 Feb 2021 17:50:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Terms Archive: Terms and Conditions of popular services tracked on GitHub]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26182878">thread link</a>) | @sirffuzzylogik
<br/>
February 18, 2021 | https://disinfo.quaidorsay.fr/en/open-terms-archive | <a href="https://web.archive.org/web/*/https://disinfo.quaidorsay.fr/en/open-terms-archive">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<div class="page">
				<div>
					

<nav>
	<ol itemscope="" itemtype="https://schema.org/BreadcrumbList">
		<li itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">	
			<a href="https://disinfo.quaidorsay.fr/en" itemprop="item">Home</a>
			
		</li>

		
			<li itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">	
				<a href="https://disinfo.quaidorsay.fr/en/our-tools" itemprop="item">Our tools</a>
				
			</li>
		
		
		<li itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
			Open Terms Archive
		</li>
	</ol>
</nav>

<p><img src="https://disinfo.quaidorsay.fr/assets/img/open-terms-archive/thumb.jpg" alt=""></p>

<p>Services have terms that can change over time. Open Terms Archive enables users rights advocates, regulatory bodies and any interested citizen to <strong>follow the changes to these terms</strong>.</p>

<h3 id="follow-the-changes-to-the-terms-of-service">Follow the changes to the Terms of Service</h3>

<p>Services are declared within Open Terms Archive with a declaration file listing all the documents that, together, constitute <strong>the terms under which this service can be used</strong>. These documents all have a type, such as â€œterms and conditionsâ€, â€œprivacy policyâ€, â€œdeveloper agreementâ€.</p>

<p>The practices described regarding information manipulation can lead to a <strong>better understanding of the vulnerabilities</strong> of these actors and the transcription of legislative constraints, recommendations from public authorities or voluntary measures implemented enables us to <strong>appreciate their loyalty</strong>.</p>

<h3 id="case-studies">Case studies</h3>

<ul>
  <li>Google has changed its Review Guidelines to prohibit apps that hat mislead users by impersonating someone else or another app or falsely imply a relationship to another company / developer. These measures thus close certain vulnerabilities exploited for information manipulation. <a href="https://github.com/ambanum/CGUs-versions/commit/98f6c">See the change</a>.</li>
</ul>

<p><img src="https://disinfo.quaidorsay.fr/assets/img/open-terms-archive/google-case-studie.png" alt=""></p>

<ul>
  <li>TikTok refers to Comminuty Guidelines to offer its users the opportunity to report content that would be considered inappropriate. <a href="https://github.com/ambanum/CGUs-versions/commit/0d2f0386">See the change</a>.</li>
</ul>

<p><img src="https://disinfo.quaidorsay.fr/assets/img/open-terms-archive/tiktok-case-studie.png" alt=""></p>

<ul>
  <li>Google AdSense has changed its Acceptable Use Policy to add a reference to Coordinated Deceptive Practices to prohibit (i) practices that seek to coordinate with other sites or accounts and concealing or misrepresenting identity or other material details, when content relates to politics, social issues or matters of public concern and (ii) directe content about politics, social issues, or matters of public concern to users in a country other than oneâ€™s own, if you misrepresent or conceal oneâ€™s country of origin or other material details. <a href="https://github.com/ambanum/CGUs-versions/commit/c62b7">See the change</a>.</li>
</ul>

<p><img src="https://disinfo.quaidorsay.fr/assets/img/open-terms-archive/google-case-studie.png" alt=""></p>

<p><a href="https://github.com/ambanum/CGUs/wiki/%C3%89tudes-de-cas">Discover more case studies</a></p>

<h2 id="how-it-works">How it works</h2>

<p><em>Words in bold are <a href="https://en.wikipedia.org/wiki/Domain-driven_design">business domain names</a>.</em></p>

<p><strong>Services</strong> are <strong>declared</strong> within <em>Open Terms Archive</em> with a <strong>declaration file</strong> listing all the <strong>documents</strong> that, together, constitute the <strong>terms</strong> under which this <strong>service</strong> can be used. These <strong>documents</strong> all have a <strong>type</strong>, such as â€œterms and conditionsâ€, â€œprivacy policyâ€, â€œdeveloper agreementâ€â€¦</p>

<p>In order to track their <strong>changes</strong>, <strong>documents</strong> are periodically obtained by fetching a web location and selecting content within the web page to remove the noise (ads, navigation menu, login fieldsâ€¦).</p>

<p>Anyone can run their own private instance and track changes on their own. However, we also publish each version on a <a href="https://github.com/ambanum/CGUs-versions"><strong>public</strong> instance</a> that makes it easy to explore the entire history and enables notifying over email whenever a new version is recorded.
Users can <a href="#be-notified"><strong>subscribe</strong> to <strong>notifications</strong></a>.</p>

<p><em>For now, when multiple versions coexist, <strong>terms</strong> are only <strong>tracked</strong> in their English version and for the European jurisdiction.</em></p>

<h3 id="exploring-the-versions-history">Exploring the versions history</h3>

<p>From the <strong>repository homepage</strong> <a href="https://github.com/ambanum/CGUs-versions">CGUs-versions</a>, open the folder of the service of your choice. You will see the set of documents tracked for that service, now click on the document of your choice. The latest version (updated hourly) will be displayed.</p>

<p><em>For more details, see our <a href="https://github.com/ambanum/CGUs#exploring-the-versions-history">wiki</a></em>.</p>

<h3 id="be-notified">Be notified</h3>

<p>You can <a href="https://59692a77.sibforms.com/serve/MUIEAKuTv3y67e27PkjAiw7UkHCn0qVrcD188cQb-ofHVBGpvdUWQ6EraZ5AIb6vJqz3L8LDvYhEzPb2SE6eGWP35zXrpwEFVJCpGuER9DKPBUrifKScpF_ENMqwE_OiOZ3FdCV2ra-TXQNxB2sTEL13Zj8HU7U0vbbeF7TnbFiW8gGbcOa5liqmMvw_rghnEB2htMQRCk6A3eyj">subscribe</a> to receive an email whenever a document is updated in the database.</p>

<p><strong>Beware, this service is in beta and you are likely to receive a large amount of notifications!</strong> You can unsubscribe by replying to any email you will receive.</p>

<p><em>For more details, see our <a href="https://github.com/ambanum/CGUs#be-notified">wiki</a></em>.</p>

<h2 id="scripta-manent">Scripta Manent</h2>

<p>Scripta Manent lists 637 Terms of Services (in French, Conditions GÃ©nÃ©rales dâ€™Utilisation or CGU) and legal documents coming from 174 digital service providers and gives simple tools to compare changes between two dates of your choice.</p>

<p><a href="https://disinfo.quaidorsay.fr/en/open-terms-archive/scripta-manent">Compare</a></p>

<h2 id="experiments">Experiments</h2>

<p>Experiments are ongoing so as to produce use cases using Open Terms Archive data.</p>

<p><a href="https://disinfo.quaidorsay.fr/en/open-terms-archive/experiments">See ours experiments</a></p>

<h2 id="api">API</h2>

<p>An API endpoint to find specific terms in the Open Terms Archive dataset is available.</p>

<p><a href="https://disinfo.quaidorsay.fr/api/open-terms-archive/">Access the API</a></p>

<h2 id="contributing">Contributing</h2>

<p>The tool is built as an <strong>open source and collaborative software</strong>, which means that everyone can contribute to its improvement and to the addition of documents and service providers to be tracked.</p>

<ul>
  <li>
    <p>Terms of Service Didnâ€™t Read (ToSDR)
The association Terms of Service Didnâ€™t Read (ToSDR) had developed a similar tool, <a href="https://tosback.org/">TOSBack</a> and thus transferred its resources and documents followed for several years to our tool.</p>
  </li>
  <li>
    <p>Direction GÃ©nÃ©rale des Entreprises<br>
The Direction GÃ©nÃ©rale des Entreprises (DGE), through the Digital Regulation Expertise Center (PEReN), contributes to the tool by developing new functionalities, such as tracking images and documents in PDF format.</p>
  </li>
</ul>

<div>
	<h3>Help us to improve Open Terms Archive</h3>
	<p>You can add service providers or documents that you would like to follow or suggest ways to add value to the case studies.</p>
	<p><a href="https://github.com/ambanum/CGUs">Contribute</a>
</p></div>

				</div>
			</div>
		</div></div>]]>
            </description>
            <link>https://disinfo.quaidorsay.fr/en/open-terms-archive</link>
            <guid isPermaLink="false">hacker-news-small-sites-26182878</guid>
            <pubDate>Thu, 18 Feb 2021 17:37:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ruby Garbage Collection Deep Dive: Tri-Color Mark and Sweep]]>
            </title>
            <description>
<![CDATA[
Score 137 | Comments 15 (<a href="https://news.ycombinator.com/item?id=26182796">thread link</a>) | @mooreds
<br/>
February 18, 2021 | https://jemma.dev/blog/gc-mark-and-sweep | <a href="https://web.archive.org/web/*/https://jemma.dev/blog/gc-mark-and-sweep">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>In the <a href="https://jemma.dev/blog/gc-internal">first post</a> in the Ruby Garbage Collection Deep Dive series, we went through a few definitions to give us a picture of how Ruby stores values in memory. If you havenâ€™t read it yet, <a href="https://jemma.dev/blog/gc-internal">read it first</a>! Weâ€™ll build on those definitions in this post. Particularly, weâ€™ll talk more about the Ruby Heap, Pages, Slots and RVALUES.</p>

<p>Okay, now that we have those baseline definitions out of the way, this post is going to explain the algorithm Rubyâ€™s garbage collector uses to determine which objects it can collect: the Tri-Color Mark and Sweep algorithm. There are two phases to this algorithm. You guessed it: marking and sweeping. In the marking phase, the garbage collector marks all slots which contain accessible RVALUES. In the sweeping phase, the garbage collector clears the RVALUES out of all slots which are not marked. Letâ€™s dig in!</p>

<h2 id="tri-color-mark-and-sweep">Tri-Color Mark and Sweep</h2>

<h3 id="marking">Marking</h3>

<p>Weâ€™ll start off by discussing the marking phase. This is most straightforward to understand if we imagine the <a href="https://ruby-doc.org/core-3.0.0/ObjectSpace.html">Ruby ObjectSpace</a> to be a directed graph with root nodes. All of the nodes in the graphs are RVALUES. All of the edges in the graph are references from one RVALUE to another.</p>

<p>Rubyâ€™s garbage collector starts at the root nodes and traces every edge it can access from these root nodes, marking every RVALUE it sees through this process. At the end, any RVALUE which was not traced, and therefore not accessible from a root RVALUE will be garbage collected.</p>

<h4 id="tri-color">Tri-Color</h4>

<p>Okay, but the algorithm Ruby uses for garbage collection is called a Tri-Color Mark and Sweep algorithm, so whatâ€™s the Tri-Color part all about? The Tri-Color algorithm is a model we can use to understand what Rubyâ€™s garbage collector is doing, and how tracks its progress. The three colors in the Tri-Color algorithm (three shades, really) are white, black and grey.</p>

<p>At the beginning of garbage collection, every slot in the Ruby Heap is white. Then, as part of the initial setup, all slots which contain root RVALUEs are marked as grey.</p>

<p>Root RVALUES are all of the RVALUES that a Ruby program knows it will need to run. Examples of these are RVALUES that exist on the stack of instructions that the program is following, or protected global variables.</p>

<p>With all root slots grey, and all other slots white, we then get to the crux of the algorithm:</p>

<div><div><pre><code><span>while</span> <span>(</span><span>!</span><span>grey_slots</span><span>.</span><span>empty?</span><span>)</span>
  <span>current_slot</span> <span>=</span> <span>grey_slots</span><span>.</span><span>pop</span>
  <span>grey_slots</span> <span>+=</span> <span>current_slot</span><span>.</span><span>referenced_slots</span>
  <span>black_slots</span> <span>&lt;&lt;</span> <span>current_slot</span>
<span>end</span>
</code></pre></div></div>

<p>We iterate over all grey slots, coloring the slots that their RVALUES reference grey, and coloring themselves black. The algorithm continues until there are no grey slots left. At this point, any black slots contain RVALUES which were reachable by the RVALUEs in the root slots, and any white slots do not contain RVALUES which were reachable so can be swept away!</p>

<p>For the visual learners, hereâ€™s a gif of what the algorithm is doing:</p>

<p><img src="https://jemma.dev/assets/mark.gif" alt="mark-gif"></p>

<h4 id="references">References</h4>

<p>There is one detail which needs further explanation here: how does an RVALUE know which other RVALUES it references?</p>

<p>It depends on the type of object. For Ruby builtins, tracing the references are just baked into the garbage collector code itself. For example, to find all references from an array RVALUE, the collector iterates each element in the array and finds its references. For a hash, it will do this for both the keys and the values. This all happens in the garbage collectorâ€™s <a href="https://github.com/ruby/ruby/blob/296a2cab07ce530809ee74dee61180fbb3ca6f91/gc.c#L6269"><code>mark_children</code></a> method.</p>

<p>But, when objects are defined by C extensions, the C extensions must mark all child objects on their own. Weâ€™ll dive more into this in a future C extensions post (which Iâ€™ll backlink here).</p>

<p>Okay, so now that we understand how we find all accessbile objects, we need to learn how to dispose of all unaccessible objects.</p>

<h3 id="sweeping">Sweeping</h3>

<p>At this point, we have two sets: black slots and white slots. Internally, these are represented as a <code>marked</code> bitmap. Every Page on the Ruby Heap has its own <code>marked</code> bitmap with one bit per slot. A <code>1</code> bit means the slot is accessible, or Black in our Tri-Color scheme. A <code>0</code> bit means that the slot is no longer accessible, or White in our Tri-Color scheme.</p>

<p>In addition to holding this <code>marked</code> bitmap, each page also has a <code>freelist</code> which represents slots on that page which do not have live objects. The garbage collector iterates over all pages, finding all slots which are not marked. Where applicable, the garbage collector then adds the unmarked slots to each pageâ€™s freelist. If the RVALUES which were occupying these slots are also taking up space in the operating system heap, it also frees this memory.</p>

<p>Once pages have been swept, there might be pages which are now completely unallocated; they have no slots which contain RVALUES. These pages are referred to as â€œTomb Pages.â€ Tomb pages have their memory completely returned to the operating systemâ€™s heap. This is really helpful for memory management. It means that sweeping can result in freeing memory, or diminishing the overall size of the Ruby Heap.</p>

<p>Any pages with at least one occupied slot are called â€œEden Pagesâ€. The sweeping phase might reduce the number of occupied slots in an Eden Page. The garbage collector will use the freelists from Eden Pages for future object allocations. That is to say, if you instantiate an object, the garbage collector will look for one of these free slots in an Eden Page and place the RVALUE representing your object in there.</p>

<p><img src="https://jemma.dev/assets/eden-and-tomb.png" alt="eden-and-tomb"></p>

<p>There is one more nuance here. As of Ruby 3.0, if auto-compaction is enabled, compaction will actually happen as part of the sweeping phase. A more in depth explanation of how and why this happens will follow in a later post about compaction in this Garbage Collection Deep Dive Series.</p>

<h3 id="tldr">TL;DR</h3>

<p>The Tri-Color mark and sweep algorithm is what Rubyâ€™s garbage collector uses to determine which slots hold objects which no longer have accessible references. It marks all of the slots it has references to by following the Tri-Color algorithm in which it follows all references from root RVALUES. Once the garbage collector knows which objects are accessible from the roots, it can begin the sweep phase, where it will add the unoccupied slots to each pageâ€™s freelist, and release any operating system memory those RVALUES held. This enables the slots to be reused for new object allocation.</p>

<p>Here are a few new definitions we learned:</p>

<ul>
  <li><strong>Eden page</strong>: A page which contains slots with RVALUES, might also have empty slots</li>
  <li><strong>Tomb page</strong>: A page which contains only empty slots</li>
  <li><strong>Free list</strong>: A linked list per Heap Page of empty slots</li>
</ul>

<p>And thatâ€™s it for this post! Iâ€™m going to continue writing blog posts in this series, and am also writing a book about managed garbage collection, with a focus on Ruby. If this interests you, join the newsletter below or follow me <a href="https://twitter.com/jemmaissroff">on twitter</a> for updates!</p>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://jemma.dev/blog/gc-mark-and-sweep</link>
            <guid isPermaLink="false">hacker-news-small-sites-26182796</guid>
            <pubDate>Thu, 18 Feb 2021 17:32:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Love F# for Mathematical Planning]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26182563">thread link</a>) | @dunefox
<br/>
February 18, 2021 | https://matthewcrews.com/blog/2020-12-09-why-i-love-fsharp-for-mathematical-planning/ | <a href="https://web.archive.org/web/*/https://matthewcrews.com/blog/2020-12-09-why-i-love-fsharp-for-mathematical-planning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<article>
   

  <div>
<blockquote>
<p>A designer knows he has achieved perfection not when there is nothing left to add, but when there is nothing left to take away</p>
<ul>
<li>Antoine de Saint-Exupery</li>
</ul>
</blockquote>
<p>On my journey of growing as a developer, I am consistently inspired by language features which seem incredibly simple but yield remarkable benefit. As I try to master F#, I am frequently surprised by how powerful the language is for expressing ideas while having so few features. Discussions frequently pop up about the need for ever more powerful abstractions, yet I find myself amazed by how far you can take the language with what is already there.</p>
<p>I am no programming language expert, but I admire languages that maintain a lean feature set. Every new feature added to a language makes it just a little bit more difficult to fully understand and a little more intimidating for new developers. It is an impressive design feat when a language can remain approachable for beginners but enable the flexibility that library authors need.</p>
<p>I am an Industrial Engineering turned Machine Learning Engineer, and I focus on the problem of maximizing the profitability and efficiency of companies. Often the solution involves a Mathematical Planning Model (aka Mathematical Programming). What I hope to do in the next few paragraphs is illustrate to you how some of the most basic features of F#, Discriminated Unions and Units of Measure, eliminate the most pernicious bugs when developing these models.</p>
<h2 id="the-domain-of-mathematical-planning">The Domain of Mathematical Planning</h2>
<p>The domain of Mathematical Planning is made up of Decisions, Constraints, and Objectives. A Decision is a choice that a business needs to make. It can be how many of Item X do we buy, do we build in Location A or Location B, or how many people do we assign to each job. Constraints are the rules we need to abide by. They are the limitations on what is possible. A Constraint could be that we only have 10 people available, or we can only build in Seattle or Portland, or we only have $1,000,000 to invest. The Objective is how we measure success. It is the function we want to maximize or minimize. We could minimize waste, maximize profit, or minimize cost.</p>
<p>Many of my colleagues are building their models with Python. Python is a great language and I have been productive with it in the past. Here is a snippet of what a mathematical planning model may look like in Python:</p>
<div><pre><code data-lang="python"><span># Define a list of items to optimize for</span>
items <span>=</span> [<span>"A"</span>, <span>"B"</span>, <span>"C"</span>]

<span># Define a list of locations to assign items to</span>
locations <span>=</span> [<span>"Portland"</span>, <span>"Seattle"</span>, <span>"Detroit"</span>]

<span># Define a dictionary of revenue associated with each item and location tuple</span>
revenue <span>=</span> {(<span>"A"</span>,<span>"Portland"</span>):<span>1.5</span>;, (<span>"A"</span>,<span>"Seattle"</span>):<span>1.7</span> <span>...</span> }

<span># Define a dictionary with the availability of each item</span>
availability <span>=</span> {<span>"A"</span>:<span>10.0</span>, <span>"B"</span>:<span>20.0</span>, <span>"C"</span>:<span>14.0</span>}

<span># Create a Decision for each Item, Location combination. This will be how much</span>
<span># of a given item we decide to send to that location</span>
allocation <span>=</span> LpVariable<span>.</span>dicts(<span>"AmountSent"</span>,(items,locations), <span>0</span>)

<span># Create an instance of a `Problem` object and state that we want to maximize</span>
<span># the objective we give it</span>
problem <span>=</span> LpProblem(<span>"ItemAllocation"</span>, LpMaximize)

<span># We create an expression which evaluates the total revenue</span>
revenue_expr <span>=</span>
    lpSum([revenue[i][l] <span>*</span> allocation[i][l] <span>for</span> i <span>in</span> items <span>for</span> l <span>in</span> locations])

<span># We set the Objective of the Problem by adding it</span>
problem <span>+=</span> revenue_expr, <span>"MaximizeRevenue"</span>

<span># For each item in items, create a constraint which states that the total number</span>
<span># of items that is allocated cannot exceed the availability of the item</span>
<span>for</span> i <span>in</span> items:
    problem <span>+=</span> lpSum([allocation[l][i] <span>for</span> l <span>in</span> location] <span>&lt;=</span> availability[i])

</code></pre></div><p>This is the beginning of a straightforward assignment problem. We have a list of items, <code>items</code>. For each <code>item</code> in <code>items</code>, we must decide how many we send to each <code>location</code> in <code>locations</code>. There is a limit on how much of each <code>item</code> is available for us to send. There is a revenue associated with sending a particular <code>item</code> to a given <code>location</code>. In this problem we want to maximize our revenue which is calculated by multiplying the <code>decision</code> for a given <code>item</code> and <code>location</code> by the <code>revenue</code> associated with it. Finally, we create a constraint for each <code>item</code> in <code>items</code> which states that the total number of a given <code>item</code> that is allocated cannot exceed the total that is available.</p>
<p>This is only part of the problem. Normally there would be more constraints that would make it more interesting. This is enough of a problem to illustrate my case though. There are two errors in this model already. If you were paying close attention you may have found one. I promise you cannot detect the second.</p>
<h2 id="the-power-of-domain-modeling-using-discriminated-unions">The Power of Domain Modeling Using Discriminated Unions</h2>
<p>F# provides two simple but powerful features which help ensure against the errors in the Python code. The first is Discriminated Unions. If we were to reformulate this problem using F#, the first thing we would do was define some simple types to model our domain.</p>
<div><pre><code data-lang="fsharp"><span>type</span> <span>Item</span> <span>=</span> Item <span>of</span> <span>string</span>
<span>type</span> <span>Location</span> <span>=</span> Location <span>of</span> <span>string</span>
</code></pre></div><p>Instead of just using strings to describe our Items and Locations, we create simple, single case Discriminated Unions (DU). These DUs provide context around what the strings are meant to represent. Letâ€™s go ahead and create our <code>item</code> and <code>locations</code> lists again. This time, wrapping them in DUs.</p>
<div><pre><code data-lang="fsharp"><span>let</span> items <span>=</span> 
  <span>[</span><span>"A"</span><span>;</span> <span>"B"</span><span>;</span> <span>"C"</span><span>]</span> 
  <span>|&gt;</span> List.map Item

<span>let</span> locations <span>=</span> 
  <span>[</span><span>"Portland"</span><span>;</span> <span>"Seattle"</span><span>;</span> <span>"Detroit"</span><span>]</span>
  <span>|&gt;</span> List.map Location
</code></pre></div><p>We will also update our <code>availability</code> information to use these new types.</p>
<div><pre><code data-lang="fsharp"><span>let</span> availability <span>=</span>
    <span>[</span>
        Item <span>"A"</span><span>,</span> 10<span>.</span>0
        Item <span>"B"</span><span>,</span> 20<span>.</span>0
        Item <span>"C"</span><span>,</span> 14<span>.</span>0
    <span>]</span> <span>|&gt;</span> Map
</code></pre></div><p>We will create the Decisions for each <code>item</code> and <code>location</code>. We store these <code>Decision</code> types in a <code>Map</code> which is indexed by an <code>(Item * Location)</code> tuple.</p>
<div><pre><code data-lang="fsharp"><span>let</span> allocation <span>=</span>
    DecisionBuilder<span>&lt;</span>Servings<span>&gt;</span> <span>"AmountSent"</span> <span>{</span>
        <span>for</span> i <span>in</span> items <span>do</span>
            <span>for</span> l <span>in</span> locations <span>-&gt;</span>
                Continuous <span>(</span>0<span>.</span>0<span>,</span> infinity<span>)</span>
    <span>}</span> <span>|&gt;</span> Map
</code></pre></div><p>We now attempt to create the same constraints we did in Python with a direct translation.</p>
<div><pre><code data-lang="fsharp"><span>let</span> allocationContraints <span>=</span>
    ConstraintBuilder <span>"ItemLimit"</span> <span>{</span>
        <span>for</span> i <span>in</span> items <span>-&gt;</span>
            List.sum <span>[</span><span>for</span> l <span>in</span> locations <span>-&gt;</span> 1<span>.</span>0 <span>*</span> allocation<span>.[</span>l<span>,</span> i<span>]]</span> <span>&lt;==</span> availability<span>.[</span>i<span>]</span>
    <span>}</span>   
</code></pre></div><p>Except, the compiler is gives us an error on the indexing of <code>allocation</code>.</p>
<p><img src="https://matthewcrews.com/img/2020-12-08-indexing-error.png" alt="Compiler error for indexing Map"></p>
<p>What some of you may have noticed in the Python code is that the <code>allocation</code> collection is indexed by an <code>Item</code> then <code>Location</code>. The original code was trying to access it by <code>location</code> then by <code>item</code>. This would have thrown an error at runtime due to a missing value. In F# this becomes a compiler error. The type system itself it is helping you. This may seem small, but this is one of the most painful types of errors when debugging a Mathematical Planning model.</p>
<p>Someone may say that this can be accomplished in other languages and I would agree. I believe where F# is unique is in the simplicity and ease of using single case Discriminated Unions for wrapping primitives. It is virtually no additional effort.</p>
<h2 id="units-of-measure-the-achilles-heel-of-numbers">Units of Measure: The Achilles Heel of Numbers</h2>
<p>There is an underappreciated problem in software development, numbers are rarely just numbers. They represent something: <code>cm</code>, <code>feet</code>, <code>kg</code>, or <code>meters</code>. Normally we do not care about a raw number. Our primary concern is with what the number represents. In most languages there are no easy mechanisms for tracking the Units of Measure associated with a number. F# on the other hand has baked the concept of a Unit of Measure into the type system.</p>
<p>The Units of Measure feature will reveal the second problem with the Python code that otherwise may remain undetected. Letâ€™s update our domain with some new types to track the units on our numbers.</p>
<div><pre><code data-lang="fsharp"><span>[&lt;</span>Measure<span>&gt;]</span> <span>type</span> <span>Servings</span>
<span>[&lt;</span>Measure<span>&gt;]</span> <span>type</span> <span>Kg</span>
</code></pre></div><p>We now have units to represent <code>Servings</code> and <code>Kg</code>. Letâ€™s update our <code>availability</code> collection to store numbers with these units attached.</p>
<div><pre><code data-lang="fsharp"><span>let</span> availability <span>=</span>
    <span>[</span>
        Item <span>"A"</span><span>,</span> 10<span>.</span>0<span>&lt;</span>Kg<span>&gt;</span>
        Item <span>"B"</span><span>,</span> 20<span>.</span>0<span>&lt;</span>Kg<span>&gt;</span>
        Item <span>"C"</span><span>,</span> 14<span>.</span>0<span>&lt;</span>Kg<span>&gt;</span>
    <span>]</span> <span>|&gt;</span> Map
</code></pre></div><p>We have now provided more context around our availability numbers. We now know they are stored in units of <code>Kg</code>. The F# compiler will enforce correct algebra as we work with them. We now update our Decisions to be in units of <code>Servings</code>.</p>
<div><pre><code data-lang="fsharp"><span>let</span> allocation <span>=</span>
    DecisionBuilder<span>&lt;</span>Servings<span>&gt;</span> <span>"AmountSent"</span> <span>{</span>
        <span>for</span> i <span>in</span> items <span>do</span>
            <span>for</span> l <span>in</span> locations <span>-&gt;</span>
                Continuous <span>(</span>0<span>.</span>0<span>&lt;</span>Servings<span>&gt;,</span> 1_000_000<span>.</span>0<span>&lt;</span>Servings<span>&gt;)</span>
    <span>}</span> <span>|&gt;</span> Map
</code></pre></div><p>With our Decisions updated, we go back to our constraint definition and we now see a new bug.</p>
<p><img src="https://matthewcrews.com/img/2020-12-08-units-of-measure-mismatch.png" alt="Units of Measure Mismatch"></p>
<p>The important part of this message is at the bottom. The compiler is complaining that the left-hand is in units of <code>Servings</code> and the right-hand side is in units of <code>Kg</code>. It does not make sense to compare values that are in different units, so the compiler is throwing an error. In other languages this error would go undetected. Worse, it may not even be caught in unit testing because the math will still work, it just wonâ€™t give correct results.</p>
<p>Letâ€™s go ahead and add some conversion data so that we can fix this.</p>
<div><pre><code data-lang="fsharp"><span>let</span> itemMass <span>=</span>
    <span>[</span>
        Item <span>"A"</span><span>,</span> 1<span>.</span>1<span>&lt;</span>Kg<span>/</span>Servings<span>&gt;</span>
        Item <span>"B"</span><span>,</span> 2<span>.</span>0<span>&lt;</span>Kg<span>/</span>Servings<span>&gt;</span>
        Item <span>"C"</span><span>,</span> 0<span>.</span>7<span>&lt;</span>Kg<span>/</span>Servings<span>&gt;</span>
    <span>]</span> <span>|&gt;</span> Map
</code></pre></div><p>We now have data which will allow us to convert from <code>Serving</code> to <code>Kg</code>. Letâ€™s incorporate it into our constraint creation expression.</p>
<div><pre><code data-lang="fsharp"><span>let</span> allocationContraints <span>=</span>
  ConstraintBuilder <span>"ItemLimit"</span> <span>{</span>
    <span>for</span> i <span>in</span> items <span>-&gt;</span>
      List.sum <span>[</span><span>for</span> l <span>in</span> locations <span>-&gt;</span> itemMass<span>.[</span>i<span>]</span> <span>*</span> itemAllocation<span>.[</span>i<span>,</span> l<span>]]</span> <span>&lt;==</span> availability<span>.[</span>i<span>]</span>
  <span>}</span> 
</code></pre></div><p>Now the compiler is happy because the units are in <code>Kg</code> on both sides. This simple feature of ensuring correct Units of Measure eliminates what is possibly the most nefarious bug in Mathematical Planning. It would be hard to calculate the number of hours wasted on badly formulated models due to mismatched Units of Measure.</p>
<h2 id="simple-building-blocks">Simple Building Blocks</h2>
<p>F# is an incredibly expressive language while staying lean on the number of features. Other languages have taken the approach of throwing every possible feature in. F# is relatively slow to â€¦</p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://matthewcrews.com/blog/2020-12-09-why-i-love-fsharp-for-mathematical-planning/">https://matthewcrews.com/blog/2020-12-09-why-i-love-fsharp-for-mathematical-planning/</a></em></p>]]>
            </description>
            <link>https://matthewcrews.com/blog/2020-12-09-why-i-love-fsharp-for-mathematical-planning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26182563</guid>
            <pubDate>Thu, 18 Feb 2021 17:16:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Census Raises $16M Series A from Sequoia]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26181985">thread link</a>) | @nate
<br/>
February 18, 2021 | https://blog.getcensus.com/announcing-our-series-a-from-sequoia/ | <a href="https://web.archive.org/web/*/https://blog.getcensus.com/announcing-our-series-a-from-sequoia/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <section>
                <div>
                    <p>Iâ€™m thrilled to announce that Census has raised a $16 million Series A, led by Sequoia Capital. Andreessen Horowitz (who led our seed) is also participating, along with operators like Dylan Field (Figma CEO), Jason Warner (GitHub CTO), Akshay Kothari (Notion COO), Parker Conrad (Rippling CEO), Josh Ferguson (Mode Chief Architect), Bryant Chou (Webflow CTO), Joe Thomas (Loom CEO), Patrick McKenzie (Stripe) and Guillaume Cabane. This round brings our total amount raised to just over $20 million.</p><p>We're also launching the <a href="https://blog.getcensus.com/introducing-the-census-startup-program">Census Startup Program</a> to empower startups to easily build the last mile of the modern data stack. Companies with fewer than 40 employees and less than $10MM in funding will be able to use Census for a flat rate of $100 per month.</p><figure><img src="https://lh3.googleusercontent.com/PqQs9ECN6mKTopIPG2ZhvZL_-FmCS_h7uB_VAAizC02R6hS7wXGBj2G2ph7tafLbpJ_66C5dfvp6ljRvWCqejYEW-GHIiVWw5KEqwi42b2sijRGJsCFh-ZhMkWJffuIxVNbl0m2j" alt=""></figure><p>In 2018, we started with a simple product that helped business teams sync data from their cloud warehouses into their favorite tools. Since then, the data landscape has changed a lot â€“ now we're starting to see analytics &amp; data move to the core of all company operations. We <a href="https://blog.getcensus.com/meet-census/">launched publicly</a> last year with the world's first reverse ETL that natively publishes from any data warehouse (we dubbed this the "missing piece" in the modern data stack). The reaction has been nothing short of phenomenal â€“ Census is now syncing analytics for over half a billion users every day.</p><p>We're lucky to support some pretty amazing teams using Census, like Canva, Figma, Drizly, Heap Analytics, Netlify, Mode Analytics, Notion, and Chorus.ai just to name a few. These organizations are unified by a shared focus on delivering personalized experiences for every customer, even when they've scaled to hundreds of millions of users.</p><p>To do this, they treat data as a central pillar of their organization, instead of just paying lip service to being "data-driven." Putting data teams on the critical path of every business operation has emerged as the category of <a href="https://blog.getcensus.com/what-is-operational-analytics/">Operational Analytics</a> â€“ and has been the driving force for our company.</p><h3 id="operational-analytics-aka-the-data-warehouse-as-hub">Operational Analytics, aka. the Data Warehouse as Hub</h3><p>Three years ago, we asked, â€œWhy are we relying on a clumsy tangle of wires connecting every app when everything we need is already in the warehouse? What if you could leverage your data team to drive operations?â€</p><p>When the data warehouse is connected to the rest of the business, the possibilities are limitless. When we launched, our focus was enabling product-led companies like Figma, Canva, and Notion to drive better marketing, sales, and customer success. Along the way, our customers have pulled Census into more and more scenarios, like auto-prioritizing support tickets in <a href="https://blog.getcensus.com/census-zendesk-for-better-customer-support/">Zendesk</a>, automating invoices in <a href="https://headwayapp.co/census-changelog/netsuite-destination-186207">Netsuite</a>, or even integrating with HR systems. With our growing library of <a href="https://www.getcensus.com/integrations">native integrations</a>, Census makes it possible for data models in your cloud data warehouse to power any business workflow.</p><figure><img src="https://blog.getcensus.com/content/images/2021/02/Eventail-Diagram-4.png" alt="" srcset="https://blog.getcensus.com/content/images/size/w600/2021/02/Eventail-Diagram-4.png 600w, https://blog.getcensus.com/content/images/size/w1000/2021/02/Eventail-Diagram-4.png 1000w, https://blog.getcensus.com/content/images/size/w1600/2021/02/Eventail-Diagram-4.png 1600w, https://blog.getcensus.com/content/images/size/w2400/2021/02/Eventail-Diagram-4.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>The performance improvements we've seen in the modern data stack (fast incremental ingestion from our partners at <a href="https://fivetran.com/blog/fivetran-partners-with-census-to-complete-the-loop-on-operational-analytics">Fivetran</a>, separated workloads on Redshift, improving latency from Snowflake, the arrival of <a href="https://blog.getcensus.com/census-databricks/">Delta Lake</a>, etc.) finally make it possible for the data warehouse to act as a <a href="https://blog.getcensus.com/the-best-cdp-solution-is-already-sitting-in-your-data-warehouse/">new kind of CDP</a> (Customer Data Platform). One that enables hyper-scale businesses to deliver the attention and personalization that customers historically only get from, say, a small neighborhood boutique. This is the promise of Operational Analytics.</p><h3 id="the-rise-of-the-data-ops-ecosystem">The Rise of the Data Ops Ecosystem</h3><p>Census is part of a larger movement in the data ecosystem, one in which the precepts of Engineering and DevOps are washing over the world of analytics. Marc Andreessen famously said "software is eating the world." Our team has always believed in the corollary: "software practices will eat the business." We've made it our mission from day one to help data teams build solutions like engineers. And weâ€™ve worked with amazing partners in bringing this vision to reality.</p><figure><img src="https://lh6.googleusercontent.com/eLy_nydDOnPyVwsQEHTu8k3cGiicY2EAKJn6E8pC4gankSOLcc66qnhf1O0KiY4cD2Y6-LABH4KGMtQ9pw9D61APtXf5UPcGLp-f3bs-bFCnTsM42AInrUL6_PXvTUH6GW10t7aW" alt=""><figcaption>Fivetran + dbt + Census = Feedback Loop</figcaption></figure><p>Census takes models and insights from a data warehouse then <a href="https://whatsnew.getcensus.com/built-in-data-validation-186053">validates</a> and <a href="https://blog.getcensus.com/making-your-dbt-models-more-useful-with-census/">deploys</a> the results so they can be put to work in other teams (ie. the real world). With our native understanding of dbt model versions, you can safely orchestrate your entire data operations from input to output. Census closes the feedback loop to make the whole much greater than the sum of the parts.</p><p>But what most drives this movementâ€”and what we love most about itâ€”is the amazing community of developers, analysts, and operations experts that all help each other to build better systems. Our partners at Fishtown have fostered one of the most inclusive and helpful communities, which supported and embraced Census early on â€“ led by the intrepid <a href="https://twitter.com/clairebcarroll">Claire Caroll</a> (fun fact: she helped popularize our â€œreverse ETLâ€ concept in 2019). We participate in our small way with tool talks and office hours. Thereâ€™s a real excitement around the modern data stack, which is why we created our new startup program so folks could adopt this stack regardless of company size or budget.</p><h3 id="the-future-data-as-a-product">The Future: Data as a Product</h3><p>The next decade is going to be an exciting one for data teams, and our early customers are pointing the way. Instead of constantly building (and fixing) one-off reports, data teams are poised to become a central nervous system for the business.</p><p>Traditionally, BI teams have been focused on asynchronous, batch processing instead of real-time, personalized processing. Analysts build reports to answer questions about what happened in the business, which is like looking at the rear view mirror. This data architecture could crunch raw data into KPIs and charts but wasnâ€™t optimized for understanding individual users or entities. Even worse, it was disconnected from day-to-day operations, which forced data teams to do painful periodic reconciliations with the business.</p><figure><img src="https://blog.getcensus.com/content/images/2021/02/new-data-teams-4.png" alt="" srcset="https://blog.getcensus.com/content/images/size/w600/2021/02/new-data-teams-4.png 600w, https://blog.getcensus.com/content/images/size/w1000/2021/02/new-data-teams-4.png 1000w, https://blog.getcensus.com/content/images/size/w1600/2021/02/new-data-teams-4.png 1600w, https://blog.getcensus.com/content/images/size/w2400/2021/02/new-data-teams-4.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Operational Analytics changes the role of data teams</figcaption></figure><p>Modern data teams are built differently. Instead of a data sink, they are a platform for applications, analysis, visualization â€“ and most importantly, action. Instead of focusing on data aggregation for BI visualization, a new modeling layer must emerge that captures clean, unified yet individualized entities that can be used in any application. In order to support all these scenarios, a few things are crucial.</p><ol><li>The data infrastructure must be scalable, efficient, and real-time.</li><li>The data modeling layer must be versioned, tested, deployed, and ultimately standardized for broad consumption.</li><li>The data pipelines must reach any application, and be seamlessly monitored to create tight feedback loops with every part of the organization</li></ol><h3 id="the-road-map-ahead">The Road(map) Ahead</h3><p>Thereâ€™s a ton of capabilities in Census and even more to come. Hereâ€™s some of the areas weâ€™ve been working on and plan to expand upon this year.</p><ul><li><strong>Code-Based Orchestration.</strong> Today, we sync models seamlessly from a warehouse but we want to push the bar forward here and make every Census workflow versionable and pluggable into larger orchestration systems.</li><li><strong>Deeper Data Validation.</strong> When your data models are connected to business systems, failures become much worse (which is a good thing, after all if your mistakes have no impact, whatâ€™s the point?). Census is your last line of defense before the data is live so validating your data is key.</li><li><strong>Visual Query Experience.</strong> When data becomes a product, it means you have more consumers. Many of these consumers need a way to interact with models with a simple UX, which furthers our goal of data reaching every part of the organization.</li></ul><p>If this sounds like a lot, it's because it is. We're embarking on a long journey to transform data organizations into product teams. Teams that can scale to support many users and many use cases. By shifting into this central role, data teams stop being backwards-looking and become the biggest drivers of change in an organization â€“ the ultimate feedback loop.</p><h3 id="join-us">Join us</h3><p>The companies &amp; leaders who understand this will certainly succeed and I look forward to seeing an amazing cohort of Chief Data Officers in the decade to come. There is a huge amount of work ahead of us and I am unbelievably excited to tackle these problems every day. Empowering people with tools has been my passion ever since I started my career in technology. If you want to help make an impact and move the needle on the entire data ecosystem, <a href="https://jobs.ashbyhq.com/Census">come join our team</a>. Weâ€™re small but mighty and hiring for every position. You can reach me on <a href="https://twitter.com/borisjabes">Twitter</a> or via <a href="mailto:boris@getcensus.com">email</a>.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.getcensus.com/announcing-our-series-a-from-sequoia/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26181985</guid>
            <pubDate>Thu, 18 Feb 2021 16:38:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SSH Certificates Security]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26181568">thread link</a>) | @alexk
<br/>
February 18, 2021 | https://goteleport.com/blog/ssh-certificates | <a href="https://web.archive.org/web/*/https://goteleport.com/blog/ssh-certificates">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
      <a href="https://goteleport.com/blog/index.xml"><i></i></a>
      
      

        

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-security.png" width="100%" alt="SSH Certificates Security"></p>

<h2 id="ssh-access-hardening">SSH Access Hardening</h2>

<p>SSH certificates, when deployed properly, improve security.
A half-baked access system using certs is more vulnerable than a public-key-based one if a user or host gets hacked.</p>

<p>SSH is hard. Our team learned this at Rackspace, a large managed hosting and cloud provider.
We started with deploying public keys to every server. We added a jump server with a second factor login to prevent
hacks using stolen keys. Soon, infosec team asked us to log into a web portal to match SSH logins with emails.
Evolution does not produce the most efficient result, and our system did not turn out great either.
We were missing keys on some servers and found stale keys on others.
No one liked login screens popping up multiple times a day.
We received only one one-time password token, and some folks pointed their home webcam to it.</p>

<p>In 2015 we left Rackspace to build <a href="https://github.com/gravitational/teleport" data-size="large" aria-label="Star gravitational/teleport on GitHub">Teleport</a> â€” a unified access plane
for infrastructure, and we started with SSH. We chose SSH certificates as the main cryptography engineering primitive. Since then our customers and open source users have deployed Teleport at most impressive systems, and Teleport went through
several security audits.</p>

<p>I would like to share some of the lessons we learned with you.
We will start with the SSH authentication basics, dig into SSH certificates
and learn what it takes to build a secure SSH certificate-based authentication.</p>

<h3 id="ssh-public-key-authentication">SSH Public Key Authentication</h3>

<p>An SSH public key is distributed openly, and anyone holding it can verify messages
signed using its private key counterpart.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-public-key-auth.png" width="100%" alt="SSH Public Key Authentication"></p>

<p>An SSH server generates a random string â€” a challenge â€” and asks a client to sign it.
The server verifies clientsâ€™ signature to prove that the client has the private key associated with
the trusted public key. Here is how it looks on the wire:</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-public-key-protocol.png" width="100%" alt="SSH Public Key Challenge"></p>

<p>Public keys constitute a solid way to authenticate and are used to secure both Web and SSH.</p>

<p>The problems with public key authentication are caused by key management: trust on first use (a.k.a. TOFU)
and rotating and revoking trusted public keys.</p>

<h3 id="trust-on-first-use">Trust On First Use</h3>

<p>When an SSH connection is first established, an SSH server sends its public key to identify
itself to a user.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-host-auth.png" width="100%" alt="SSH Host Authentication"></p>

<p>The user can accept the public key offered by the SSH server and assume that the host is trusted
if the user connects to it first time. This authentication scheme is called â€œtrust on first useâ€ or TOFU.</p>

<p>If the hostâ€™s IP, name or public key change, the user can no longer trust this combination
of the hostname, the IP and the public key.</p>

<p>The user sees a scary warning.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-tofu.png" width="100%" alt="SSH TOFU"></p>

<p>The user can alert security folks or ignore the warning by removing the old key.
For cloud environments, however, an IP address and a hostname can be
reused many times. Users learn to ignore those warnings, because there is no way to learn whether itâ€™s an attack or an IP or a hostname change. Letâ€™s call it TOFU fatigue.</p>

<h3 id="problems-with-public-keys">Problems With Public Keys</h3>

<p>A second problem of public keys for security is caused by complexities of public key distribution.
Imagine a deployment with 100 servers and 10 users, where every user has 2 public keys.
You have to build a system that distributes 20 userâ€™s public keys on each server and
100 public keys to every userâ€™s computer, and keep those up to date.</p>

<p>Directory services like LDAP are used to store userâ€™s and hostâ€™s public keys.
Every host runs an agent that connects to an LDAP server and updates public keys.
Sysadmin folks have been deploying this Keycloak and FreeIPA pair for years.</p>

<p>This system breaks down at a small and a large scale. Sysadmins of small systems
rarely deploy key management software. Itâ€™s not worth setting up FreeIPA and Keycloak for 3 nodes.
They use tools like Ansible and end up with keys going out of sync when someone loses their key, computer, or leaves the company. Sometimes, letâ€™s face it, there is no Ansible and everyone uses the same shared key.</p>

<p>Admins of large clusters learn that the system of moving the key around stops working beyond the 1K nodes or 100 users mark â€”
there are just too many keys to keep track of.</p>

<h2 id="ssh-certificates">SSH Certificates</h2>

<p>SSH certificates are built using public keys and donâ€™t offer anything extra from a cryptography engineering standpoint.</p>

<p>A certificate authority (CA) is a trusted party that holds its own public and private key pair.
SSH CA keys are used to sign user and host SSH certificates.
An SSH certificate consists of fields signed by the certificate authority.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-certificate.png" width="100%" alt="SSH Certificate"></p>

<p>Clients cannot modify these fields without breaking the signature.</p>

<p>SSH certificate authentication extends public-key-based auth and uses the same protocol messages.
In addition to verifying the public key signature, SSH server will check whether
the certificate is signed by the trusted certificate authority.</p>

<h3 id="solving-the-tofu-problem">Solving the TOFU Problem</h3>

<p>Clients use metadata in SSH certificates to verify host identities too.
When an SSH connection is established, a host sends a signed SSH certificate to a client to verify
the hostâ€™s identity. The hostâ€™s certificate is signed by a trusted CA.
It includes information about the hostname, and has an expiration date.
Here Alice checks if she can trust the hostâ€™s cert:</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-host-certs.png" width="100%" alt="SSH Host Certificates"></p>

<p>As an extra precaution, SSH clients check if the hostname or the IP matches the certificate.
It makes it harder for a malicious host to impersonate another host.
If the signature check has failed or the CA is not trusted, either a serious misconfiguration
has happened or someone is attempting a man-in-the-middle attack.</p>

<p>Even if the public key of the host has been changed because the hostname has been reused in a cloud environment
during instance re-provisioning, the certificate will still match; there will be no conflict between different
public keys.</p>

<p>Sysadmins can replace the complex system of moving hundreds of public keys around
with two files â€” a host and a user SSH certificatesâ€™ authority public keys.
But in practice if we had stopped at this point, we would have made SSH security much, much worse.</p>

<h3 id="compromised-users-and-hosts">Compromised Users and Hosts</h3>

<p>If a user or a host gets compromised, we have to revoke their certs.
We are back to building a system of keeping track and distributing revocation lists to users and hosts.
Even worse, if a private key of a SSH user or a host certificate authority gets compromised,
all users and hosts certificates have to be invalidated and reissued.</p>

<p>This realization hits at the worst possible moment â€” when someone is hacked, there is no time to waste.
Time works against us because with every issued cert, the potential for compromise
increases. At least with public keys, we test the rotation on a regular basis. Revocation is so rare,
that it could be broken for all this time and no one would notice. This problem reminds me of backup restore â€”
you either test backup and restore regularly, or all bets are off.</p>

<h2 id="making-time-work-for-you">Making Time Work for You</h2>

<p>There is one trick that makes time work in favor of security.
SSH certificates include an optional expiry date that can be verified
by a server in addition to a signature.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-short-lived.png" width="100%" alt="SSH Short Lived Certs"></p>

<p>Organizations ca issue certificates that are good for a few hours before they auto-expire
without any action. The shorter the duration for these certificates, the better.
Ideally, certs should be issued only for the duration of a session.
In practice, several hours or the duration of the workday are OK too.</p>

<p>Instead of distributing revocation lists, we can rely on time to do the job for us.</p>

<h3 id="user-certificates-and-sso">User Certificates and SSO</h3>

<p>How would users get a short-lived certificate? The best way is to use SSO
with GitHub, Okta or any other identity provider and get a cert.
Teleport opens login screen, issues a cert and delivers it back to a userâ€™s computer:</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-sso.png" width="100%" alt="SSH certs SSO"></p>

<p>Here is an example of Teleportâ€™s CLI tool <code>tsh</code> issuing a certificate
based on my GitHub credentials.</p>

<video autoplay="" loop="" muted="" playsinline="">
  <source src="https://goteleport.com/blog/images/2021/ssh-certs-github.mp4" type="video/mp4">
  <source src="https://goteleport.com/blog/images/2021/ssh-certs-github.webm" type="video/webm">
Your browser does not support the video tag.
</video>

<p>The cert is valid for 12 hours and has my GitHub identity encoded in it.</p>

<h2 id="rotate-ca-keys">Rotate CA Keys</h2>

<p>An attacker getting access to a private key of a certificate authority can impersonate
any user or host. Thatâ€™s why admins store CA private keys in the most secure place possible.
What happens if a user, a host, or a CA gets compromised? Youâ€™d need to replace certificate authority
and reissue all certs for hosts and users. Any system dealing with certs should support this out of the box.</p>

<p>Take a look at how I rotate a user CA in less than a minute with Teleport:</p>

<video autoplay="" loop="" muted="" playsinline="">
  <source src="https://goteleport.com/blog/images/2021/ssh-certs-rotation.mp4" type="video/mp4">
  <source src="https://goteleport.com/blog/images/2021/ssh-certs-rotation.webm" type="video/webm">
Your browser does not support the video tag.
</video>

<p>With user certificate authority updated, all certificates issued by the old CA become invalid.
Itâ€™s not a problem if you use SSO; users have to re-login to get new certs.
The same command rotates hosts CA as well. Instead of waiting for the compromise
to happen, we should be rotating certificate authorities every day turning
them from a precious secret to a replaceable commodity. Here again, time
will work in our favor, not against us.</p>

<h2 id="wrapping-up">Wrapping Up</h2>

<p>Use certs with caution, and beware of long-lived certificates. Rotate your CA regularly
and use SSO to get user certs. And maybe, give <a href="https://github.com/gravitational/teleport" data-size="large" aria-label="Star gravitational/teleport on GitHub">Teleport</a> a try.</p>


        
        
        <p><strong>Related Posts</strong></p>
          <ul>
            
            <li><a href="https://goteleport.com/blog/how-to-ssh-properly/">How to SSH Properly | SSH Security Best Practices</a></li>
            
            <li><a href="https://goteleport.com/blog/ssh-handshake-explained/">SSH Handshake Explained | What is SSH Handshake?</a></li>
            
            <li><a href="https://goteleport.com/blog/ssh-restricted-shells/">Restricted Shell | Restricted commands for SSH</a></li>
            
          </ul>
        

        
        
        <a href="https://goteleport.com/tags/ssh/">ssh</a>
        
        <a href="https://goteleport.com/tags/teleport/">teleport</a>
        
        <a href="https://goteleport.com/tags/security/">security</a>
        

      
      
      &nbsp;
      </article></div>]]>
            </description>
            <link>https://goteleport.com/blog/ssh-certificates</link>
            <guid isPermaLink="false">hacker-news-small-sites-26181568</guid>
            <pubDate>Thu, 18 Feb 2021 16:09:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zoom is the solution nobody asked for, to a problem that doesnâ€™t exist]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26181268">thread link</a>) | @tompccs
<br/>
February 18, 2021 | https://www.vanityfarce.com/office/work/zoom/2021/02/17/zoom.html | <a href="https://web.archive.org/web/*/https://www.vanityfarce.com/office/work/zoom/2021/02/17/zoom.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>Disclaimer â€“ This post was poorly researched and most of the historical â€˜factsâ€™ are pieced together from my own recollection, books Iâ€™ve been reading and Wikipedia searches. Despite the lack of rigorous scholarship (or perhaps because of it) I expect the conclusion to be 100% correct.</em></p>

<p>When the pandemic is â€œoverâ€ â€“ or, more precisely, when the right people decide to declare it â€œoverâ€ and we are living in a world split between Covid-negative and Covid-positive countries with a several year life expectancy gap between them â€“ the consensus is that some things will go back to the way they were pre-2020, and others wonâ€™t. Whether or not you think white collar workers will still be working from home â€“ living in commuter belts, in or around small towns or in remoter parts of the country side with decent broadband â€“ or will have migrated back into the offices, city pubs and crammed trains, depends largely on whether or not you have a financial interest in the value of commercial real estate. One thing everyone seems to agree on, though, is that video conferencing technology, such as Zoom, has been, and will continue to be, central to this revolution in working patterns.</p>

<p>Whatever the future of white collar work holds, I feel I can confidently predict that video conferencing will be not-so-fondly remembered as a weird crutch that everyone was obsessed with for about 12-18 months, before people realised it actually serves no purpose at all.</p>

<p>To argue this point, I will ask the question â€“ why do we actually have offices in the first place? Who are they for? What problems do they solve? And which of those problems does video conferencing actually come close to addressing?</p>

<p>The history of bureaucratic white-collar work goes something like this: there are two main threads of office work which emerged around the Industrial Revolution â€“ state-administration, and the bourgeoise professions (accountants, lawyers, traders, etc). Of the two threads, state administration is the older: bureaucracies of this sort can be traced back to ancient Egypt. Hierarchies beyond a certain size need paperwork, because the people in charge need a way to have their wishes transmitted authentically without corruption (accidental of nefarious) to hundreds or thousands of  lowly peons. Hence the priestly, and later bureaucratic, class, tasked with the top-down administration of unwieldy empires and later nation-states according to the insights or whims of their rulers.</p>

<p>Obviously, this type of administration pre-dates the â€œofficeâ€ as we currently recognise it. There arenâ€™t many western institutions which have been in continuous operation from medieval through to post-industrial times which we can analyse in this way, but one of them might be the British Parliament. Originally an ad-hoc assembly of the Kingâ€™s noblemen, gathered as and when the King needed to raise some cash through taxation, this travelling parliament eventually evolved into the more stationary one we know today, where MPs have permanent offices and travel between their constituencies and the debating chambers according to how often they feel the need to escape from those people who elected them there in the first place. In 2021, those MPs are now spending a lot more time in their constituencies. Voting can now happen remotely, although MPs still have the option of attending debates in person. Itâ€™s hard to imagine British government functioning in quite the same way without the cut-and-thrust of rigorous parliamentary debate, but then again, itâ€™s hard to see how any type of video conferencing solution could recreate it either (just look at what happened in this <a href="https://www.youtube.com/watch?v=jB3P_0GAi0I">disastrous parish council meeting</a>)</p>

<p>What of the rest of the state apparatus? The ambassadors, bureaucrats, etc? Well, to once again take an example from British history, a small cadre of Oxbridge-educated civil servants based in Whitehall, London, used to administer the largest empire in history with no more advanced technology than the telegraph. I canâ€™t quite imagine a Zoom meeting between Prime Minister Disraeli and the governor-general of India, not to mention with the 120-or-so Indian noblemen scattered about the subcontinent, making this unwieldy task any easier.</p>

<p>So much for administering an empire. What about lower-level state administration â€“ things like welfare, sanitation, treasury, etc? You might not be surprised to learn that the primary reason for co-locating lots of bureaucrats is becauseâ€¦<em>thatâ€™s where the filing cabinets were!</em> If you needed to process a tax return, or look up some obscure by-law, you generally had to be co-located with reams and reams of paper containing this information. The fact that this constituted an â€œofficeâ€ is purely down to the fact that other people needed to be co-located with these files as well as you. The office was originally built for collaboration insofar as a library is built for meeting girls.</p>

<p>Weâ€™ve still not explored the other thread of this â€“ the thread that runs from Venetian merchants to Googleâ€™s bean-bags and free lunches. This one is harder to explain. As the artisan evolved into the factory worker, so too did the other professionals â€“ lawyers, accountants, merchants â€“ evolve into the office worker. What was the rationale for this? Why should a lawyer or accountant, each of whom has a few assigned clients, need to work in an office with lots of other lawyers and accountants? Rather than being co-located with their filing cabinets, I suppose the reason is to allow them to share a pool of ancillary staff, like paralegals, typists, etc. However, as the digital revolution has swept through (and, since WWII, rising wages), much of the ancillary staff have been done away with altogether, or else morphed into something called â€˜middle managementâ€™. The function of middle management, of course, is the same as the ancillary staff: to help the professionals do their jobs better, although by tweaking their job description they were able to negotiate better pay.</p>

<p>If you need ancillary staff (read: middle management), then it stands to reason that you need an office, too. And if you donâ€™t have an office, then you probably need something that will â€˜simulateâ€™ an office. Hereâ€™s the problem: whereas the ancillary staff of old knew that their job was to type things up, keep appointment diaries and fetch post, middle management believes their job is to hold meetings. Therefore, synonymous with â€˜home workingâ€™ is â€˜Zoom meetingsâ€™.</p>

<p>Iâ€™ve actually omitted a third thread of office history, which is the monastery (or university in 21st century parlance). Why the need to have a bunch of monks living together? In fact, the original Christian monk was a hermit, living in total solitude. But perhaps in not having a family such a degree of loneliness was too much to bear. Hence the monastery, where, as well as (or perhaps in the course of) worshipping God, monks partook in such pastimes as beer brewing, geometry, and science. The fact that big groups of celibate, literate men living in the same place led to all sorts of interesting by-products is perhaps the root of the modern idea of a university, and that legacy also dovetails into our modern corporate culture which has its roots in the 1980s, whose hallmarks are the borrowing of university lingo such as â€˜campusâ€™, and a growing obsession with a nicely marketable form of self-improvement which can be delivered through highly lucrative training contracts.</p>

<p>There is a fleeting sense in which a modern university, with students living in halls, unemployed and frugal, could look a bit like, if you squint, a short stint at a medieval monastery, and whatever value universities still hold is probably related to how long you can hold onto that mirage. But the modern office, with its 9-to-5 clock and day punctuated by meetings and the ambitious preoccupied by the arduous climb up the corporate hierarchy, is even further away. Perhaps the closest thing to the medieval monastery is the startup, with its ungodly hours and religious-fanatical devotion to the cause, and itâ€™s probably no coincidence that working in a startup is generally seen as incompatible with having a social or family life. But no, other than the monastic startup-office-cum-bedsit, the office serves no creative purpose. The modern office is little more than a cargo-cult monastery.</p>

<p>Having read and of course also agreed with all of this, one can only wonder what function software such as Zoom can possibly serve. And I think the answer to this is similar to something we often see from new digital technology: the skeuomorphism of existing â€˜analogueâ€™ concepts (ie, the modern â€˜desktopâ€™ containing â€˜filesâ€™ and â€˜documentsâ€™). Skeuomorphisms are almost always a temporary crutch, a cognitive bridge between the old inefficient way of doing something and the new but conceptually abstract way which will eventually replace it. Consider, for instance, the transition from written letters, to email, to instant messaging. Or how indeed the very idea of an email has become distinct in itself â€“ look at how email etiquette has gradually evolved from when you might write one as you would write a letter in the early 2000s to the modern â€œsee attached. cheers, Tomâ€. Or look at social media, how Facebook was built on top of your real-world idea of â€˜friendsâ€™ by inventing the highly skeuomorphic (and somewhat autistic) concept of â€˜friend requestsâ€™, before Instagram and Twitter developed the more digitally-native concept of â€˜followingâ€™.</p>

<p>Zoom is the â€˜friend requestâ€™ of the office world. As our work places reverse the 150-year migration from our homes into purpose built offices, recall that that reversal is due to the sudden erosion of the logic which made us move into offices in the first place: record keeping and reference, ancillary staff, and creative collaboration. Zoom and video conferencing is a sticking plaster, and perhaps a desperate plea by the old guard to remind us of how much better â€¦</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.vanityfarce.com/office/work/zoom/2021/02/17/zoom.html">https://www.vanityfarce.com/office/work/zoom/2021/02/17/zoom.html</a></em></p>]]>
            </description>
            <link>https://www.vanityfarce.com/office/work/zoom/2021/02/17/zoom.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26181268</guid>
            <pubDate>Thu, 18 Feb 2021 15:52:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coq 8.13]]>
            </title>
            <description>
<![CDATA[
Score 115 | Comments 40 (<a href="https://news.ycombinator.com/item?id=26180078">thread link</a>) | @infruset
<br/>
February 18, 2021 | https://coq.inria.fr/news/coq-8-13-0-is-out.html | <a href="https://web.archive.org/web/*/https://coq.inria.fr/news/coq-8-13-0-is-out.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>





<p>
The Coq development team is proud to announce the immediate availability of
<a href="https://github.com/coq/coq/releases/tag/V8.13.0">Coq 8.13.0</a>
</p>

<p>
Highlights:
</p><ul>
<li>Introduction of primitive persistent arrays in the core language, implemented using imperative persistent arrays. </li>
<li>Introduction of definitional proof irrelevance for the equality type defined in the SProp sort. </li>
<li>Many improvements to the handling of notations, including number notations, recursive notations and notations with bindings. A new algorithm chooses the most precise notation available to print an expression, which might introduce changes in printing behavior.</li>
</ul>



<p>Please see <a href="https://coq.github.io/doc/v8.13/refman/changes.html#version-8-13" rel="nofollow">the changelog</a> to learn more about this release.</p>




</div></div>]]>
            </description>
            <link>https://coq.inria.fr/news/coq-8-13-0-is-out.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26180078</guid>
            <pubDate>Thu, 18 Feb 2021 14:23:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Browsers eating RAM]]>
            </title>
            <description>
<![CDATA[
Score 138 | Comments 148 (<a href="https://news.ycombinator.com/item?id=26179817">thread link</a>) | @todsacerdoti
<br/>
February 18, 2021 | https://www.flotato.com/post/memory-chrome-safari-flotato | <a href="https://web.archive.org/web/*/https://www.flotato.com/post/memory-chrome-safari-flotato">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>I reached a point where I could barely hear the podcast I was trying to listen to. That's how loud the fan was. Then I&nbsp;closed down all open Chrome windows, and a few minutes after, the fan went silent. So I decided to see if it was just me.</p><div href=""><h3>How I&nbsp;measured</h3><p>I&nbsp;ran the 2-tab test in a completely fresh macOS install on a virtual machine. Then I ran the 54-tabs test on my own Big Sur installation, but with all extensions disabled. To record a usage snapshot ~250 times per second, I&nbsp;used <a href="https://github.com/astrofrog/psrecord">psrecord.</a></p></div><div><h2>2&nbsp;tabs:&nbsp;Twitter, then Gmail</h2><p>To simulate a realistic environment, I&nbsp;did the same steps on Safari, then Chrome:&nbsp;Go to twitter.com, scroll around, then open a new tab with Gmail and open an email. A dot means I interacted with the system. You can hover a dot to see what I&nbsp;did. </p></div><div><h3>Putting Flotato to the test</h3><p>To be light-weight, Flotato doesn't just run a stripped down, Safari-backed web view, it also defaults to the mobile version if one is available. Here's Flotato compared to a regular session in Safari. Note the slightly lower CPU usage. It's kind of hard to put a finger on what exactly the mobile version isn't calculating that the desktop version is; the two versions are almost identical when you use them.</p></div><div><h2>54 tabs:&nbsp;the stress test</h2><p>I&nbsp;bet you have more than 2 tabs open right now, I&nbsp;sure have more. So here's a stress test where I&nbsp;open 54 tabs while measuring the impact on my Mac's RAM and CPU. A dot means I&nbsp;opened a new tab. Hover the dot to see which site I&nbsp;opened.</p></div><div><h2>Is it bad?</h2><p>When I saw the results I got suspicious. Chrome was using way more memory than I thought it would. Maybe it was the virtual machine blocking Chrome's direct access to my Macbook's* GPU?&nbsp;I&nbsp;decided to run the next test, the one with 54 tabs directly on my own Big Sur installation. The results were, well, slightly worse.</p><h3>The graphs don't tell the full story</h3><p>But it's probably not as bad as it looks. It's not a terrible thing that an app actually <em>uses</em> your computer. And you've got to hand it to Chrome:&nbsp;it is fast! </p><p>I'm sure Chrome is going out of its way to manage its memory usage across tabs, keeping the current tab fast and responsive. That's great if you're not running any other macOS apps than Chrome, effectively using Chrome as your operating system, and macOS&nbsp;as a kind of bootloader. </p><p>But when you're using Sketch, Final Cut, Photoshop next to Chrome, that seems to be a problem. MacOS&nbsp;likely tries to tell Chrome to take it easy, and Chrome likely <em>does</em> take it easy. These graphs don't tell that story. </p><p>So no, it's most likely not as bad as it looks, but that doesn't change the fact since switching to Safari, I almost forgot what my fan sounds like.</p><p>And then there's <em>this</em> chart. As we can see, the two browsers heat up the computer almost to the exact same level - Safari even getting slightly warmer. This probably points to psutil not being able to see all Safari's child processes, but only the main ones â€” despite the fact that Activity Monitor is able to group them. That's a little confusing. </p><figure><p><img src="https://uploads-ssl.webflow.com/5e78c687e58e25134b3fb751/602feb36d1388bb94f881998_EumcL7jXYAEBG_4.png" alt="Image"></p></figure><p>â€</p><p>â€</p><p><em>*&nbsp;Macbook 16" from 2019 with2.4 GHz, 8-Core Intel Core i9 with 32&nbsp;GB&nbsp;2667 MHz DDR4 RAM and an AMD&nbsp;Radeon Pro 5500M 8GB GPU</em></p></div></div>]]>
            </description>
            <link>https://www.flotato.com/post/memory-chrome-safari-flotato</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179817</guid>
            <pubDate>Thu, 18 Feb 2021 13:56:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Advanced Types in TypeScript]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26179620">thread link</a>) | @mooreds
<br/>
February 18, 2021 | https://www.geekabyte.io/2021/01/introduction-to-advance-types-in.html | <a href="https://web.archive.org/web/*/https://www.geekabyte.io/2021/01/introduction-to-advance-types-in.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-5372611965284124411" itemprop="description articleBody">
<p>This is the start of a series of posts where I take a look at aspects of TypeScript's type system that can be referred to as "Advanced".&nbsp; See this as an exploration of TypeScriptâ€™s type system past <span>Classes</span> and <span>Interfaces</span>.</p><p>A good mental model to have when exploring the advanced part of TypeScript type system is to see it as a more sophisticated mechanism for creating types.&nbsp;</p><p>The normal, non-advanced ways of creating types in TypeScript involve using features of the language like <span>type alias</span>,&nbsp; <span>class</span> and <span>interface</span>.&nbsp;</p>

<p>For example these:&nbsp;</p>

<pre><code>interface IPerson {
  name: string
  age: number
}

type TPerson = {
  name: string
  age: number
}

class CPerson {
  constructor(private name:string, private age: number) {}
  
  getName() {
    return this.name;
  }

  getAge() {
    return this.name;
  }
}
</code></pre>



<p>With the advanced type features, types can be constructed directly or indirectly based on other existing types. How exactly this is done, will be the subject of this series of posts.</p><p>The posts in the series include:</p><ul><li><a href="https://www.geekabyte.io/2021/01/introduction-to-generics-in-typescript.html">Introduction to Generics in TypeScript</a></li><li><a href="https://www.geekabyte.io/2021/01/generic-constraints-methods-and.html">Generic Constraints and More</a></li><li><a href="https://www.geekabyte.io/2021/01/union-and-intersection-types-in.html">Union and Intersection Types</a></li><li><a href="https://www.geekabyte.io/2021/02/literal-and-template-literal-types.html">Literal and Template Literal Types</a></li><li><a href="https://www.geekabyte.io/2021/02/using-literal-and-template-literal.html">Using Literal and Template Literal Types in TypeScript</a></li><li><a href="https://www.geekabyte.io/2021/02/overview-of-indexable-types-in.html">Overview of Indexable Types in TypeScript</a></li><li>Indexed Access Types and KeyOf - <i>Published soon</i></li><li>Type Queries: Typeof operator - <i>Published soon</i></li><li>Conditional Types - <i>Published soon</i></li><li>Mapped Types - <i>Published soon</i></li></ul>

</div></div>]]>
            </description>
            <link>https://www.geekabyte.io/2021/01/introduction-to-advance-types-in.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179620</guid>
            <pubDate>Thu, 18 Feb 2021 13:36:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Curl is C (2017)]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 79 (<a href="https://news.ycombinator.com/item?id=26179601">thread link</a>) | @taf2
<br/>
February 18, 2021 | https://daniel.haxx.se/blog/2017/03/27/curl-is-c/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2017/03/27/curl-is-c/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>For some reason, this post got picked up again and is <a href="https://news.ycombinator.com/item?id=26179601">debated today</a> in 2021, almost 4 years since I wrote it. Some things have changed in the mean time and I mightâ€™ve phrased a few things differently if I had written this today. But still, whatâ€™s here below is what I wrote back then. Enjoy!</p>



<div><figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_.png"><img loading="lazy" width="348" height="450" src="https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_-348x450.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_-348x450.png 348w, https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_-155x200.png 155w, https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_-768x992.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_.png 792w" sizes="(max-width: 348px) 100vw, 348px"></a></figure></div>



<p>Every once in a while someone suggests to me that curl and libcurl would do better if rewritten in a â€œsafe languageâ€. Rust is one such alternative language commonly suggested. This happens especially often when we publish new security vulnerabilities. (Update: I think Rust is a fine language! This post and my stance here has nothing to do with what I think about Rust or other languages, safe or not.)</p>



<h2>curl is written in C</h2>



<p>The curl code guidelines mandate that we stick to using C89 for any code to be accepted into the repository. C89 (sometimes also called C90) â€“ the oldest possible ANSI C standard. Ancient and conservative.</p>



<h2>C is everywhere</h2>



<p>This fact has made it possible for projects, companies and people to adopt curl into things using basically any known operating system and whatever CPU architecture you can think of (at least if it was 32bit or larger). No other programming language is as widespread and easily available for <em>everything</em>. This has made curl one of the most portable projects out there and is part of the explanation for curlâ€™s success.</p>



<p>The curl project was also started in the 90s, even long before most of these alternative languages youâ€™d suggest, existed. Heck, for a truly stable project it wouldnâ€™t be responsible to go with a language that isnâ€™t even old enough to start school yet.</p>



<h2>Everyone knows C</h2>



<p>Perhaps not necessarily true anymore, but at least the knowledge of C is very widespread, where as the current existing alternative languages for sure have more narrow audiences or amount of people that master them.</p>



<h2>C is not a safe language</h2>



<p>Does writing safe code in C require more carefulness and more â€œtricksâ€ than writing the same code in a more modern language better designed to be â€œsafeâ€ ? Yes it does. But weâ€™ve done most of that job already and maintaining that level isnâ€™t as hard or troublesome.</p>



<p>We keep scanning the curl code regularly with static code analyzers (we maintain a <em>zero <a href="https://scan.coverity.com/projects/curl">Coverity</a> problems</em> policy) and we run the test suite with <a href="http://valgrind.org/">valgrind</a> and <a href="https://en.wikipedia.org/wiki/AddressSanitizer">address sanitizers</a>.</p>



<h2>C is not the primary reason for our past vulnerabilities</h2>



<p>There. The simple fact is that most of our past vulnerabilities happened because of logical mistakes in the code. Logical mistakes that arenâ€™t really language bound and they would not be fixed simply by changing language.</p>



<p>Of course that leaves a share of problems that couldâ€™ve been avoided if we used another language. Buffer overflows, double frees and out of boundary reads etc, but the bulk of our security problems has not happened due to curl being written in C.</p>



<h2>C is not a new dependency</h2>



<p>It is easy for projects to add a dependency on a library that is written in C since thatâ€™s what operating systems and system libraries are written in, still today in 2017. Thatâ€™s the default. Everyone can build and install such libraries and theyâ€™re used and people know how they work.</p>



<p>A library in another language will add that language (and compiler, and debugger and whatever dependencies a libcurl written in that language would need) as a new dependency to a large amount of projects that are themselves written in C or C++ today. Those projects would in many cases downright ignore and reject projects written in â€œan alternative languageâ€.</p>



<h2>curl sits in the boat</h2>



<p>In the curl project weâ€™re deliberately conservative and we stick to old standards, to remain a viable and reliable library for everyone. Right now and for the foreseeable future. Things that worked in curl 15 years ago still work like that today. The same way. Users can rely on curl. We stick around. We donâ€™t knee-jerk react to modern trends. We sit still in the boat. We donâ€™t rock it.</p>



<h2>Rewriting means adding heaps of bugs</h2>



<p>The plain fact, that also isnâ€™t really about languages but is about plain old software engineering: translating or rewriting curl into a new language will introduce a lot of bugs. Bugs that we donâ€™t have today.</p>



<p>Not to mention how rewriting would take a huge effort and a lot of time. That energy can instead today be spent on improving curl further.</p>



<h2>What if</h2>



<p><em>If I would start the project today, would Iâ€™ve picked another language?</em> Maybe. Maybe not. If memory safety and related issues was the primary concern I had, then sure. But as Iâ€™ve mentioned above there are several others concerns too so it would really depend on my priorities.</p>



<h2>Finally</h2>



<p>At the end of the day the question that remains is: would we gain more than we would pay, and over which time frame? Who would gain and who would lose?</p>



<p>Iâ€™m sure that there will be or it may even already exist, curl and libcurl competitors and potent alternatives written in most of these new alternative languages. Some of them are absolutely really good and will get used and reach fame and glory. Some of them will be crap. Just like software always work. Let a thousand curl competitors bloom!</p>



<p>Will curl be rewritten at some point in the future? I wonâ€™t rule it out, but I find it unlikely. I find it even more unlikely that it will happen in the short term or within the next few years.</p>



<p>Discuss this post on <a href="https://news.ycombinator.com/item?id=13966241">Hacker news</a> or <a href="https://www.reddit.com/r/programming/comments/61rh9j/curl_is_c/">Reddit</a>!</p>



<p><strong>Followup-post: </strong><a href="https://daniel.haxx.se/blog/2017/03/30/yes-c-is-unsafe-but/">Yes, C is unsafe, butâ€¦</a></p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2017/03/27/curl-is-c/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179601</guid>
            <pubDate>Thu, 18 Feb 2021 13:34:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Proof of work: the reason behind Bitcoinâ€™s horrendous energy consumption]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26179585">thread link</a>) | @throw0101a
<br/>
February 18, 2021 | https://amycastor.com/2021/02/17/proof-of-work-the-reason-behind-bitcoins-horrendous-energy-consumption/ | <a href="https://web.archive.org/web/*/https://amycastor.com/2021/02/17/proof-of-work-the-reason-behind-bitcoins-horrendous-energy-consumption/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-6038">
		<div>
		
<p>Any company that supports bitcoin is making one thing clear: they donâ€™t care about the environment. At a time when global warming is a real threat to the planet, bitcoin is one of the worst offenders.&nbsp;</p>



<p>The global network of computers that â€œmineâ€ bitcoin consumes an entire countryâ€™s worth of energy in their race to win the next block on the blockchainâ€”and get the 6.25 bitcoin block reward, currently worth $300,000.&nbsp;</p>



<p>Since PayPal, Square, MicroStrategy, and <a href="https://amycastor.com/2021/02/08/tesla-spent-1-5b-in-clean-car-credits-on-bitcoin-the-filthiest-asset-imaginable/" target="_blank" rel="noreferrer noopener">Tesla</a> got onto the gameâ€”and started shilling bitcoin on social mediaâ€”the price of bitcoin has soared to new heights. And the higher the bitcoin price, the greater the lure for people to invest in warehouses full of power-hungry rigs to mine bitcoin for profit. </p>



<p>Digiconomistâ€™s <a href="https://digiconomist.net/bitcoin-energy-consumption" target="_blank" rel="noreferrer noopener">Bitcoin Energy Consumption Index,</a> run by Alex de Vries, a blockchain specialist at Big Four accounting firm PwC, estimates bitcoinâ€™s energy consumption to be 79 terawatt-hours of electricity per year, on par with the entire country of Chile. Per his index, bitcoin also emits 37 megatons of carbon dioxide per year, comparable to that of New Zealand.&nbsp;&nbsp;</p>



<p>Researchers at the University of Cambridge Judge Business School figure bitcoinâ€™s power consumption to be even higher. According to their <a href="https://cbeci.org/" target="_blank" rel="noreferrer noopener">Cambridge Bitcoin Electricity Consumption Index,</a> bitcoin consumes 124 terawatt-hours of electricity a year, bringing it inline with countries like Argentina and Norway.</p>



<p>In October, just before PayPal announced it would allow users to buy and sell bitcoin via their digital wallets, bitcoinâ€™s power consumption was 75 terawatt-hours per year, according to the CBECI. Since then, bitcoinâ€™s price climbed from $10,000 to upwards of $50,000, increasing its energy consumption by 40 percent the process.</p>



<p>In 2018, all of the worldâ€™s data centers consumed <a href="https://science.sciencemag.org/content/367/6481/984" target="_blank" rel="noreferrer noopener">205 terawatt-hours of electricity,</a> or 1% of all of the worldâ€™s electricity. Bitcoin accounts for half of that. </p>



<p>Can the worldâ€™s power grids tolerate this added demand for electricity in the midst of global warming? In the U.S., we are already seeing the impact of extreme weather on our power gridsâ€”millions in Texas <a href="https://www.nbcnews.com/news/weather/millions-texans-left-shivering-arctic-cold-without-power-n1257959" target="_blank" rel="noreferrer noopener">shivering in cold, dark homes</a> this week. And <a href="https://www.politico.com/states/california/story/2020/08/18/california-has-first-rolling-blackouts-in-19-years-and-everyone-faces-blame-1309757" target="_blank" rel="noreferrer noopener">rolling black outs in California</a> last year. In Iran last month, authorities blamed <a href="https://www.washingtonpost.com/world/2021/01/16/massive-blackouts-have-hit-iran-government-is-blaming-bitcoin/" target="_blank" rel="noreferrer noopener">massive blackouts on bitcoin mining.</a>  </p>



<h2><strong>Coal powered&nbsp;&nbsp;</strong></h2>



<p>And bitcoinâ€™s energy consumption isnâ€™t green eitherâ€”though bitcoiners like to say that it is. Bitcoin miners are tuned to profits. That means the fastest rigs and the cheapest energy available, mostly in the form of fossil fuels.&nbsp;</p>



<p>â€œCoal is fueling bitcoin,â€ Christian Stoll, an energy researcher at the Technical University of Munich, told <a href="https://www.wired.com/story/bitcoins-climate-impact-global-cures-local/?mbid=social_twitter&amp;mbid=social_twitter&amp;utm_brand=wired&amp;utm_brand=wired&amp;utm_campaign=wired&amp;utm_campaign=wired&amp;utm_medium=social&amp;utm_medium=social&amp;utm_social-type=owned&amp;utm_social-type=owned&amp;utm_source=twitter&amp;utm_source=twitter" target="_blank" rel="noreferrer noopener">Wired magazine</a> a few years ago.&nbsp;&nbsp;</p>



<p>In <a href="https://www.cell.com/joule/fulltext/S2542-4351(19)30255-7" target="_blank" rel="noreferrer noopener">a paper published in <em>Joule</em></a> in June 2019, Stoll and his researchers examined bitcoin mining based on where miners are located and the types of rigs they use. Two-thirds of all bitcoin mining is centered in China, 17% is in Europe, and 15% in North America, the researchers found.&nbsp;</p>



<p>In China, bitcoinâ€™s mining is spread throughout the countryâ€™s sprawling western provinces, Sichuan and Yunnan, and also in the north, in Xinjiang and Mongolia. In the Sichuan province, where about 58% of the worldâ€™s bitcoin mining takes place, miners take advantage of cheap hydroelectric powerâ€”but only during the rainy season, which lasts about six months.&nbsp;</p>



<p>Bitcoin is a 24/7 business, however, and when green energy isnâ€™t availableâ€”and the price of bitcoin is high enough to reap a profit in the dry seasonâ€”the miners in Sichuan turn to coal, the countryâ€™s most abundant energy source. <a href="https://www.iea.org/data-and-statistics?country=CHINA&amp;fuel=Energy%20supply&amp;indicator=ElecGenByFuel" target="_blank" rel="noreferrer noopener">Sixty-five percent of Chinaâ€™s electricity comes from coal.</a>&nbsp;Bitcoin miners in the Xinjiang province and inner Mongolia also rely heavily on coal-fired electricity.&nbsp;</p>



<p>Even when bitcoin uses clean energy, that pushes the use of dirty energy elsewhere. A few years ago, HyperBlock, a bitcoin mine in Missoula County, Montana, struck a deal with a nearby dam for cheap renewable power. They thought they were doing it right, until county officials noted that if energy from the dam went to bitcoin mining, the county as a whole would end up using more coal. </p>



<p>That was the end of that. <a href="https://www.wired.com/story/montana-county-crimp-bitcoin-save-the-earth/" target="_blank" rel="noreferrer noopener">In April 2019,</a> Missoula required all future mines to purchase or build their own renewable power. And soon after the price of bitcoin crashed in March 2020â€”slipping down to below $5,000â€”HyperBlock <a href="https://missoulian.com/news/local/bonner-bitcoin-company-ceases-operations/article_789d8594-f17c-5809-a8fe-918ad226266e.html" target="_blank" rel="noreferrer noopener">declared bankruptcy</a> because it could not pay its power bills.</p>



<h2><strong>Bitcoin mining and proof of work</strong></h2>



<p>Why is bitcoin so inefficient? It turns out that the system uses copious amounts energy not by accident but by design. </p>



<p>Satoshi Nakomoto, bitcoinâ€™s pseudonymous creator, had to figure out a way to solve the <a href="https://en.wikipedia.org/wiki/Double-spending" target="_blank" rel="noreferrer noopener">double-spend problem.</a> We donâ€™t have this problem with paper money. But with digital money, someone could copy the file and use it to spend the funds over and over, rendering the currency useless.&nbsp;</p>



<p>In a centralized system, a trusted third-party, like a bank, checks the digital money you spend against a central ledger to make sure thereâ€™s no funny business going on. But bitcoinâ€™s ledger (the blockchain) is decentralized, which makes the double-spend problem harder to solve.&nbsp;&nbsp;</p>



<p>The solution Satoshi came up with was a clever hack that involves bitcoin mining and proof-of-work. In bitcoin, mining is the process of adding new transactions to the blockchain, and proof-of-work secures the network so transactions canâ€™t be reversed. You would need more than half of all the computing power on the bitcoin network to double-spend a bitcoin.&nbsp;</p>



<p>It wasnâ€™t a perfect solution, but Satoshi solved what computer scientists had long thought was unsolvable: how to build a decentralized payment system. The irony is, unless you are collecting payments for <a href="https://news.bitcoin.com/ransomware-ryuk-rakes-in-150-million-in-bitcoin/" target="_blank" rel="noreferrer noopener">ransomware,</a> bitcoin has proven <a href="https://www.wsj.com/articles/why-bitcoin-hasnt-gained-traction-as-a-form-of-payment-11612886974" target="_blank" rel="noreferrer noopener">unusable as a payment system.</a> No merchant wants to risk their profit margin on bitcoinâ€™s volatility. </p>



<p>Today, bitcoin functions mainly as a <a href="https://www.coindesk.com/store-of-value-remains-cryptos-best-use-case" target="_blank" rel="noreferrer noopener">speculative investment,</a> getting scooped up by retailers and venture capitalistsâ€”and now big companies and <a href="https://cointelegraph.com/news/pension-funds-are-getting-in-on-bitcoin-according-to-grayscalehttps://www.hedgeweek.com/2021/01/19/294600/bitcoins-inefficiencies-are-creating-arbitrage-trades-crypto-hedge-funds" target="_blank" rel="noreferrer noopener">hedge funds</a>â€”in the hopes the price will go ever skyward.  &nbsp;</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">$250k by end of 2022. Just 5X from here. Looking a lot more likely than when I made the initial prediction three years ago, eh? <a href="https://twitter.com/hashtag/Bitcoin?src=hash&amp;ref_src=twsrc%5Etfw">#Bitcoin</a></p>â€” Tim Draper (@TimDraper) <a href="https://twitter.com/TimDraper/status/1362131856544702469?ref_src=twsrc%5Etfw">February 17, 2021</a></blockquote></div>
</div></figure>



<h2>Winning the lottery</h2>



<p>Bitcoin miners have their eyes feasted on the bitcoin block reward. </p>



<p>Every 10 minutes, the bitcoin network adds a new block to the blockchain, minting 900 new bitcoins a day in the process. That block reward is reduced by half every four years. Prior to May 2020, the bitcoin block reward was 12.5 bitcoinsâ€”double what it is nowâ€”and the network produced 1,800 new bitcoins per day. And around February 2024,* the block reward will be 3.125 bitcoins. </p>



<p>When you request a transaction on the bitcoin blockchain, your transaction goes into the <a rel="noreferrer noopener" href="https://www.blockchain.com/charts/mempool-size" target="_blank">bitcoin mempool,</a> a waiting area for unconfirmed bitcoin transactions. Miners select transactions from the poolâ€”usually the ones with the highest transaction feesâ€”and package those into a block ready to process as the next block in the blockchain. </p>



<p>Any server can produce a â€œcandidate block,â€ but if it were too easy to do, the network would be spammed. So there had to be a financial cost to creating a block, hence the work.&nbsp;</p>



<p>In the case of bitcoin, that work involves solving a hash puzzle; the cost is computing time and electricity. The hash puzzle is very difficult to solve, but easy for peers in the bitcoin network to verify, so they can prove you did the work and the block is valid.</p>



<p>Some people refer to this puzzle as a complex math problem, but itâ€™s really not. Working out a hash is easy, but in bitcoin, working out a hash that meets certain conditions is tricky. Finding the solution is a bit like winning a lottery.</p>



<h2>Solving the hash puzzle</h2>



<p>A <a href="https://en.wikipedia.org/wiki/Cryptographic_hash_function" target="_blank" rel="noreferrer noopener">hash</a> is a fixed-length output calculated from a piece of data. Whether you hash Herman Woukâ€™s â€œWar and Remembranceâ€ or a grocery store list, the resultant hash will always be the same length. And you will always get the same hash for the same string. But if even one letter changes in â€œWar and Remembrance,â€ the resultant hash will be different.</p>



<p>Bitcoin uses the <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Hashcash" target="_blank">hashcash proof-of-work,</a> originally developed by cryptographer Adam Back in 1997 as a way to prevent email spam and denial-of-service attacks, and the <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/SHA-2" target="_blank">SHA-256</a> hashing function, which has been around since 2001.</p>



<p>When you hash a bitcoin block, you also track the hash of the previous blockâ€”which â€œchainsâ€ a block to the one before it, and so on down the line to the first bitcoin block ever createdâ€”and a random number called a <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Cryptographic_nonce" target="_blank">nonce.</a> The idea is to produce a hash that is lower than the numeric value of the <a href="https://en.bitcoin.it/wiki/Target" target="_blank" rel="noreferrer noopener">network target.</a> (This target changes periodically to adjust the mining difficulty, thereby assuring only one block gets created every 10 minutes.) </p>



<p>When you mine bitcoin, you repeatedly hash the block while incrementing the nonce. Each time you change the nonce, you also change the value of the resultant hash. The number of hashes that a miner makes per second is called the hash rate; the higher your hash rate, the better your chance of solving the puzzle. A single bitcoin mining rig can make up to 14 trillion guesses per second.</p>



<p>If you discover a hash value that is small enough before anyone else does, you win! Your block is then transmitted to the rest of the network, and the other nodes begin work on the next block using the hash of the accepted block.&nbsp;</p>



<h2>Powerful computers</h2>



<p>As bitcoin went up in value over the years, miners found faster and faster ways to win the bitcoin lottery. When bitcoin was first introduced in 2009, you could mine bitcoin with the CPU on your own personal computer.</p>



<p>Those days are a distant memory. As bitcoin mining became more profitable, miners switched to graphic processing units (GPUs). And in 2011, they migrated to field-programmable gate arrays (FPGAs). But starting in 2013, the field was taken over by application-specific integrated circuit equipment (ASIC) rigsâ€”which is â€¦</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://amycastor.com/2021/02/17/proof-of-work-the-reason-behind-bitcoins-horrendous-energy-consumption/">https://amycastor.com/2021/02/17/proof-of-work-the-reason-behind-bitcoins-horrendous-energy-consumption/</a></em></p>]]>
            </description>
            <link>https://amycastor.com/2021/02/17/proof-of-work-the-reason-behind-bitcoins-horrendous-energy-consumption/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179585</guid>
            <pubDate>Thu, 18 Feb 2021 13:32:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenZFS â€“ dRAID, Finally]]>
            </title>
            <description>
<![CDATA[
Score 165 | Comments 47 (<a href="https://news.ycombinator.com/item?id=26179566">thread link</a>) | @throw0101a
<br/>
February 18, 2021 | https://klarasystems.com/articles/openzfs-draid-finally/ | <a href="https://web.archive.org/web/*/https://klarasystems.com/articles/openzfs-draid-finally/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>




<div>
<h3><em>This is part of our article series published as â€œOpenZFS in Depthâ€. <a href="https://klarasystems.com/articles/"><strong><span>Subscribe to our article series</span></strong> </a>to find out more about the secrets of OpenZFS</em></h3>



<hr>



<p><strong><em>Isaac Huangâ€™s <a href="https://www.youtube.com/watch?v=xPU3rIHyCTs">talk at the OpenZFS 2017 developers summit</a> witnessed the expansion of the ZFS storage endurance envelope for large installations.&nbsp; dRAID or distributed RAID is a new vdev type that complements existing ZFS data protection capabilities for very large storage arrays.&nbsp; Starting with the RAID-Z-like underpinnings, dRAID permutes, or mixes, disk blocks together in a way where accesses are evenly spread across all the drives. Fast spindle replacement is accomplished by using all members of the pool, using pre-allocated virtual spares, spread evenly over all the spindles. Contributors include Intel, Lawrence Livermore Labs, and HP Enterprise, which have material interest in storage at datacenter scale and high reliability. The OpenZFS user community are the benefactors of this enhancement if we apply it well.</em></strong></p>



<h3><strong>Avoiding the Death Spiral</strong></h3>



<p>Admins will often use wide RAID stripes to maximize usable storage given a number of spindles. RAID-Z deployments with large stripe widths, ten or larger, are subject to poor resilver performance for a number of reasons. Resilvering a full vdev means reading from every healthy disk and continuously writing to the new spare. This will saturate the replacement disk with writes while scattering seeks over the rest of the vdev. For 14 wide RAID-Z2 vdevs using 12TB spindles, rebuilds can take weeks. Resilver I/O activity is deprioritized when the system has not been idle for a minimum period. Full zpools get fragmented and require additional I/Oâ€™s to recalculate data during reslivering. A pool can degenerate into a never ending cycle of rebuilds or loss of the pool Aka: the Death Spiral.</p>



<p>As spindles age together, disks may fail in groups as defect counts and mechanical failure are not independent random processes with respect to age. SSDâ€™s further complicate this math as the wear leveling endurance will be very closely matched and clusters of devices under identical load may fail together.&nbsp; Manufacturer provided mean time to failure is a forward-looking statement and is not suitable for replenishment planning. One manufacturer claims 1.2 Million hour MTBF: a dubious 137 year commitment to quality. Itâ€™s poor planning to assume any drive isnâ€™t going to pick today to dramatically fail.&nbsp;</p>



<p>dRAID is an option providing rapid parity rebuild that can mitigate the death spiral behaviour of wide RAIDZ stripes, but as reflected in its default width setting of eight, it does not encourage wide stripes. Dedicating sufficient parity increases the durability of the ZFS pool and the investment in parity should be informed by the risk of losing the pool.</p>



<h3><strong>Distributed Spares?</strong></h3>



<p>Spare disks are a way of keeping a disk warm and ready to replace a failed member. Usually, a spareâ€™s life is leisurely idle until they are scrammed into action during a rebuild. That idleness is a wasted opportunity to do useful work. There are no specific spare disks in a dRAID. Rather, enough blocks are allocated throughout out the vdev to act as spares. The distributed spare is a clever redistribution of work so that all disks are always in use. A disk failure precipitates a rebuild into that dedicated space. After replacement disks are available, the vdev can be re-balanced to return the spare block and put the replacement disk in to use.</p>



<h3><strong><strong><strong>Fixed Stripe Width</strong></strong></strong></h3>



<p>Unlike RAID-Z, an entire stripe in dRAID is allocated at once, no matter how many disk blocks are needed to store the object. The stripe width is determined by the disk sector size multiplied by the number of data drives in the RAID group.</p>



<div data-columns="3" data-layout="50-25-25"><div>




<div><div>
<p>Did you know?</p>



<h2>You can maximize the <strong>power of your FreeBSD</strong> infrastructure with our <strong>Support Subscription!</strong></h2>




</div></div>




</div></div>



<p>RAID-Z has a method of optimizing block layout to minimize block allocations for small files. dRAID however priorities the speed of rebuilding parity and does not make the same space preserving attempt. If your files are a small fraction of the stripe size, dRAID will not be able to use all the disk blocks fully. For example, a default dRAID vdev has a stripe with of 32k (4k per disk, 8 disks); any allocation will require at least 32k. Internal padding is allocated to fill out the stripe width after the request object is stored. Using a smaller stripe width or providing a special mirror vdev will suit smaller allocations and improve drive utilization.</p>



<h3><strong>A Tale of Two Resilvers</strong></h3>



<p>After a failure, the real or distributed spare is written to in sequence, following only the parity layout in the space map to rebuild the drive according to parity data. Sequential reconstruction can be accomplished rapidly by issuing large I/O blocks, reducing seeks, and avoiding tree indirection overhead. The rebuilt diskâ€™s contents are not necessarily consistent with the Merkle tree that proves the zpools data is intact.&nbsp; Itâ€™s important to reconstruct this bitwise copy of the disk first, allowing the system to return to mostly intact state and return to service. That is to say, the sequential reconstruction process restores the redundancy level of the pool, but without being able to verify the checksums of the data. The advantage to this is that it can be completed much more quickly, reducing the window during which additional disk failures might put the pool at risk.</p>



<p>A healing resilver is triggered automatically after a sequential resilver, it is a final operation that verifies that all the contents of the drives match their initial checksums via block pointer traversal. The healing resilver has a number of optimizations to quickly find and reconstruct writes to the failed disk. When a replacement drive can be added to the pool, the rebalance operation is another sequential resilver followed by a healing resilver.</p>



<p>A scrub is the gold standard for a pool health; however, a scrub might be a prohibitive amount of work, visiting every block allocated in the pool. The healing resilver allows a practical return to operation in an environment where failures must be repaired routinely.</p>



<h3><strong><em>â€œAre We There Yet? When Can I Play With it?â€</em></strong></h3>



<p>According to a report from the January OpenZFS leadership meeting, OpenZFS 2.1 will support dRAID in early 2021. If you must have it now; the head branch of the OpenZFS build against recently supported operating systems: FreeBSD 12.1+, Linux 5.10+, Illumos, NetBSD et al. The OpenZFS regression test suite ztest is a good indication that dRAID satisfies the ZFS commitment to data protection. Corporate customers at IBM and Panasas have been flogging other distributed RAID systems for more than ten years. Itâ€™s a mature concept that complements the ZFS tool set.</p>



<h4><strong>Quick Start</strong></h4>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; There is no better way to learn software than to run headlong into mistakes.&nbsp;</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Weâ€™ll install ZFS head from source and gin up some â€˜mdâ€™ file backed disks.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; â€˜zpool create r2dRAID dRAID2:3d:1s:14c /dev/md1 /dev/md2 â€¦.&nbsp; /dev/md13 /dev/md14â€™</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; There it is, a zpool with a dRAID vdev, ready to go to work.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The OpenZFS wiki has a good description of <a href="https://openzfs.github.io/openzfs-docs/Basic%20Concepts/dRAID%20Howto.html">dRAID care, resilvering and rebalancing</a></p>



<p>Following the life cycle of failure and replacement in the documentation is recommended before those skills are tested in production.</p>



<h4><strong>dRAID Nomenclature</strong></h4>



<p>Letâ€™s decode the nomenclature that describes the geometry of a dRAID vdev. A string such as â€œdRAID2:3d:14c:1sâ€ encodes the following about a dRAID vdev.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -dRAID[&lt;parity&gt;][:&lt;data&gt;d][:&lt;children&gt;c][:&lt;spares&gt;s]</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -parity: Required, the number of spindles to use to store parity information. Eg: A dRAID3 can survive until a fourth disk failure without losing data. Parity may be 1,2 or 3.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -[d] data: (spindles per RAID group): Determines the width of the data stripe, 8 is the default. Larger values will increase the stripe width and reduce total parity.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -[c] children: This parameter should match the number of device entries that you feed to the vdev. A helpful check will warn you if you donâ€™t get the right number of disks named correctly: â€œinvalid number of dRAID children; 14 required but 13 providedâ€</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -[s] spares: The number of disk areas to mix in as distributed spares. No spares are created by default, a maximum of four are welcome. Each spare will remove a fraction of space from every disk.</p>



<h2><strong>Parting Short</strong></h2>



<p>The dRAID offers a solution for large arrays, vdevs with fewer than 20 spindles will have limited benefits from the new option. The performance and resilver result will be similar to RAIDZ for small numbers of spindles. Installations with many spindles will see the best results with regards to performance, fast spare activation and replacement. The benefits come with the associated cost of whole stripe at a time allocation for small objects in the pool. This overhead should be calculated in the design of the pool before itâ€™s an operational surprise.</p>



<p>There is no free lunch with dRAID for in saving parity or spare drives, they are your defense against data loss. As drives increase in size, their time to resilver increases and the amount of data they can destroy increases.</p>



<h2><strong>Like this article? Share it!</strong></h2>


</div>




</div></div>]]>
            </description>
            <link>https://klarasystems.com/articles/openzfs-draid-finally/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179566</guid>
            <pubDate>Thu, 18 Feb 2021 13:31:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nx (Numerical Elixir) is now publicly available]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26179373">thread link</a>) | @che_shr_cat
<br/>
February 18, 2021 | https://dashbit.co/blog/nx-numerical-elixir-is-now-publicly-available | <a href="https://web.archive.org/web/*/https://dashbit.co/blog/nx-numerical-elixir-is-now-publicly-available">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    
<ul>
  <li>
    <i></i> JosÃ© Valim
  </li>
  <li>
    <i></i> February 18th, 2021
  </li>
  <li>
    <i></i><a href="https://dashbit.co/blog/tags/nx">nx</a>, <a href="https://dashbit.co/blog/tags/defn">defn</a>
  </li>
</ul>
<p><img src="https://dashbit.co/images/posts/2021/nx.png" alt="Nx" width="400"></p>
<p>
Sean Moriarity and I are glad to announce that the project we have been working on for the last 3 months, Nx, is finally <a href="https://github.com/elixir-nx/nx">publicly available on GitHub</a>. Our goal with Nx is to provide the foundation for Numerical Elixir.</p>
<p>
In this blog post, I am going to outline the work we have done so far, some of the design decisions, and what we are planning to explore next. If you are looking for other resources to learn about Nx, you can <a href="https://thinkingelixir.com/podcast-episodes/034-jose-valim-reveals-project-nx/">hear me unveiling Nx on the ThinkingElixir podcast</a>.</p>
<h2>
  Nx</h2>
<p>
Nx is a multi-dimensional tensors library for Elixir with multi-staged compilation to the CPU/GPU. Letâ€™s see an example:</p>
<pre><code><span>iex&gt; </span><span>t</span><span> </span><span>=</span><span> </span><span>Nx</span><span>.</span><span>tensor</span><span data-group-id="4885761117-1">(</span><span data-group-id="4885761117-2">[</span><span data-group-id="4885761117-3">[</span><span>1</span><span>,</span><span> </span><span>2</span><span data-group-id="4885761117-3">]</span><span>,</span><span> </span><span data-group-id="4885761117-4">[</span><span>3</span><span>,</span><span> </span><span>4</span><span data-group-id="4885761117-4">]</span><span data-group-id="4885761117-2">]</span><span data-group-id="4885761117-1">)</span><span>
</span><span data-group-id="4885761117-5">#</span><span data-group-id="4885761117-5">Nx.Tensor</span><span data-group-id="4885761117-5">&lt;</span><span>
  </span><span>s64</span><span data-group-id="4885761117-6">[</span><span>2</span><span data-group-id="4885761117-6">]</span><span data-group-id="4885761117-7">[</span><span>2</span><span data-group-id="4885761117-7">]</span><span>
  </span><span data-group-id="4885761117-8">[</span><span>
    </span><span data-group-id="4885761117-9">[</span><span>1</span><span>,</span><span> </span><span>2</span><span data-group-id="4885761117-9">]</span><span>,</span><span>
    </span><span data-group-id="4885761117-10">[</span><span>3</span><span>,</span><span> </span><span>4</span><span data-group-id="4885761117-10">]</span><span>
  </span><span data-group-id="4885761117-8">]</span><span>
</span><span data-group-id="4885761117-5">&gt;</span></code></pre>
<p>
As you see, tensors have a type (s64) and a shape (2x2). Tensor operations are also done with the <code>Nx</code> module. To implement <a href="https://en.wikipedia.org/wiki/Softmax_function">the Softmax function</a>:</p>
<pre><code><span>iex&gt; </span><span>t</span><span> </span><span>=</span><span> </span><span>Nx</span><span>.</span><span>tensor</span><span data-group-id="2015320651-1">(</span><span data-group-id="2015320651-2">[</span><span data-group-id="2015320651-3">[</span><span>1</span><span>,</span><span> </span><span>2</span><span data-group-id="2015320651-3">]</span><span>,</span><span> </span><span data-group-id="2015320651-4">[</span><span>3</span><span>,</span><span> </span><span>4</span><span data-group-id="2015320651-4">]</span><span data-group-id="2015320651-2">]</span><span data-group-id="2015320651-1">)</span><span>
</span><span>iex&gt; </span><span>Nx</span><span>.</span><span>divide</span><span data-group-id="2015320651-5">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="2015320651-6">(</span><span>t</span><span data-group-id="2015320651-6">)</span><span>,</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="2015320651-7">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="2015320651-8">(</span><span>t</span><span data-group-id="2015320651-8">)</span><span data-group-id="2015320651-7">)</span><span data-group-id="2015320651-5">)</span><span>
</span><span data-group-id="2015320651-9">#</span><span data-group-id="2015320651-9">Nx.Tensor</span><span data-group-id="2015320651-9">&lt;</span><span>
  </span><span>f64</span><span data-group-id="2015320651-10">[</span><span>2</span><span data-group-id="2015320651-10">]</span><span data-group-id="2015320651-11">[</span><span>2</span><span data-group-id="2015320651-11">]</span><span>
  </span><span data-group-id="2015320651-12">[</span><span>
    </span><span data-group-id="2015320651-13">[</span><span>0.03205860328008499</span><span>,</span><span> </span><span>0.08714431874203257</span><span data-group-id="2015320651-13">]</span><span>,</span><span>
    </span><span data-group-id="2015320651-14">[</span><span>0.23688281808991013</span><span>,</span><span> </span><span>0.6439142598879722</span><span data-group-id="2015320651-14">]</span><span>
  </span><span data-group-id="2015320651-12">]</span><span>
</span><span data-group-id="2015320651-9">&gt;</span></code></pre>
<p>
The high-level features in Nx are:</p>
<ul>
  <li>
    <p>
Typed multi-dimensional tensors, where the tensors can be unsigned integers (<code>u8</code>, <code>u16</code>, <code>u32</code>, <code>u64</code>), signed integers (<code>s8</code>, <code>s16</code>, <code>s32</code>, <code>s64</code>), floats (<code>f32</code>, <code>f64</code>) and brain floats (<code>bf16</code>);    </p>
  </li>
  <li>
    <p>
<a href="http://nlp.seas.harvard.edu/NamedTensor">Named tensors</a>, allowing developers to give names to each dimension, leading to more readable and less error prone codebases;    </p>
  </li>
  <li>
    <p>
Automatic differentiation, also known as autograd. The <code>grad</code> function provides reverse-mode differentiation, useful for simulations, training probabilistic models, etc;    </p>
  </li>
  <li>
    <p>
Tensors backends, which enables the main <code>Nx</code> API to be used to manipulate binary tensors, GPU-backed tensors, sparse matrices, and more;    </p>
  </li>
  <li>
    <p>
Numerical definitions, known as <code>defn</code>, provide multi-stage compilation of tensor operations to multiple targets, such as highly specialized CPU code or the GPU. The compilation can happen either ahead-of-time (AOT) or just-in-time (JIT) with a compiler of your choice;    </p>
  </li>
</ul>
<p>
For Python developers, <code>Nx</code> currently takes its main inspirations from <a href="https://numpy.org/"><code>Numpy</code></a> and <a href="https://github.com/google/jax"><code>JAX</code></a> but packaged into a single unified library.</p>
<p>
Our initial efforts have focused on the underlying abstractions. For example, while Nx implements dense tensors out-of-the-box, we also want the same high-level API to be valid for sparse tensors. You should also be able to use all functions in the <code>Nx</code> module with tensors that are backed by Elixir binaries and with tensors that are stored directly in the GPU.</p>
<p>
By ensuring the underlying tensor backend is ultimately replaceable, we can build an ecosystem of libraries on top of Nx, and allow end-users to experiment with different backends, hardware, and approaches to run their software on.</p>
<p>
<em>Nxâ€™s mascot is the Numbat, a marsupial native to southern Australia. Unfortunately the Numbat are endangered and it is estimated to be fewer than 1000 left. If you are excited about Nx, consider donating to Numbat conservation efforts, such as <a href="https://www.numbat.org.au/">Project Numbat</a> and <a href="https://www.australianwildlife.org/">Australian Wildlife Conservancy</a>.</em></p>
<h2>
Numerical definitions</h2>
<p>
One of the most important features in <code>Nx</code> is the numerical definition, called <code>defn</code>. Numerical definitions are a subset of Elixir tailored for numerical computing. Here is the <code>softmax</code> formula above, now written with <code>defn</code>:</p>
<pre><code><span>defmodule</span><span> </span><span>Formula</span><span> </span><span data-group-id="4810618200-1">do</span><span>
  </span><span>import</span><span> </span><span>Nx.Defn</span><span>

  </span><span>defn</span><span> </span><span>softmax</span><span data-group-id="4810618200-2">(</span><span>t</span><span data-group-id="4810618200-2">)</span><span> </span><span data-group-id="4810618200-3">do</span><span>
    </span><span>inspect_expr</span><span data-group-id="4810618200-4">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="4810618200-5">(</span><span>t</span><span data-group-id="4810618200-5">)</span><span> </span><span>/</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="4810618200-6">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="4810618200-7">(</span><span>t</span><span data-group-id="4810618200-7">)</span><span data-group-id="4810618200-6">)</span><span data-group-id="4810618200-4">)</span><span>
  </span><span data-group-id="4810618200-3">end</span><span>
</span><span data-group-id="4810618200-1">end</span></code></pre>
<p>
The first difference we see with <code>defn</code> is that Elixirâ€™s built-in operators have been augmented to also work with tensors. Effectively, <code>defn</code> replaces Elixirâ€™s <code>Kernel</code> with <code>Nx.Defn.Kernel</code>.</p>
<p>
However, <code>defn</code> goes even further. When using <code>defn</code>, <code>Nx</code> builds a computation with all of your tensor operations. Letâ€™s inspect it:</p>
<pre><code><span>defn</span><span> </span><span>softmax</span><span data-group-id="0860724160-1">(</span><span>t</span><span data-group-id="0860724160-1">)</span><span> </span><span data-group-id="0860724160-2">do</span><span>
  </span><span>inspect_expr</span><span data-group-id="0860724160-3">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="0860724160-4">(</span><span>t</span><span data-group-id="0860724160-4">)</span><span> </span><span>/</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="0860724160-5">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="0860724160-6">(</span><span>t</span><span data-group-id="0860724160-6">)</span><span data-group-id="0860724160-5">)</span><span data-group-id="0860724160-3">)</span><span>
</span><span data-group-id="0860724160-2">end</span></code></pre>
<p>
Now when invoked, you will see this printed:</p>
<pre><code><span>iex(3)&gt; </span><span>Formula</span><span>.</span><span>softmax</span><span data-group-id="4848142189-1">(</span><span>Nx</span><span>.</span><span>tensor</span><span data-group-id="4848142189-2">(</span><span data-group-id="4848142189-3">[</span><span data-group-id="4848142189-4">[</span><span>1</span><span>,</span><span> </span><span>2</span><span data-group-id="4848142189-4">]</span><span>,</span><span> </span><span data-group-id="4848142189-5">[</span><span>3</span><span>,</span><span> </span><span>4</span><span data-group-id="4848142189-5">]</span><span data-group-id="4848142189-3">]</span><span data-group-id="4848142189-2">)</span><span data-group-id="4848142189-1">)</span><span>
</span><span data-group-id="4848142189-6">#</span><span data-group-id="4848142189-6">Nx.Tensor</span><span data-group-id="4848142189-6">&lt;</span><span>
  </span><span>f64</span><span data-group-id="4848142189-7">[</span><span>2</span><span data-group-id="4848142189-7">]</span><span data-group-id="4848142189-8">[</span><span>2</span><span data-group-id="4848142189-8">]</span><span>
  
  </span><span>Nx.Defn.Expr</span><span>
  </span><span>parameter</span><span> </span><span>a</span><span>                                 </span><span>s64</span><span data-group-id="4848142189-9">[</span><span>2</span><span data-group-id="4848142189-9">]</span><span data-group-id="4848142189-10">[</span><span>2</span><span data-group-id="4848142189-10">]</span><span>
  </span><span>b</span><span> </span><span>=</span><span> </span><span>exp</span><span> </span><span data-group-id="4848142189-11">[</span><span> </span><span>a</span><span> </span><span data-group-id="4848142189-11">]</span><span>                               </span><span>f64</span><span data-group-id="4848142189-12">[</span><span>2</span><span data-group-id="4848142189-12">]</span><span data-group-id="4848142189-13">[</span><span>2</span><span data-group-id="4848142189-13">]</span><span>
  </span><span>c</span><span> </span><span>=</span><span> </span><span>exp</span><span> </span><span data-group-id="4848142189-14">[</span><span> </span><span>a</span><span> </span><span data-group-id="4848142189-14">]</span><span>                               </span><span>f64</span><span data-group-id="4848142189-15">[</span><span>2</span><span data-group-id="4848142189-15">]</span><span data-group-id="4848142189-16">[</span><span>2</span><span data-group-id="4848142189-16">]</span><span>
  </span><span>d</span><span> </span><span>=</span><span> </span><span>sum</span><span> </span><span data-group-id="4848142189-17">[</span><span> </span><span>c</span><span>,</span><span> </span><span>axes</span><span>:</span><span> </span><span>nil</span><span>,</span><span> </span><span>keep_axes</span><span>:</span><span> </span><span>false</span><span> </span><span data-group-id="4848142189-17">]</span><span>  </span><span>f64</span><span>
  </span><span>e</span><span> </span><span>=</span><span> </span><span>divide</span><span> </span><span data-group-id="4848142189-18">[</span><span> </span><span>b</span><span>,</span><span> </span><span>d</span><span> </span><span data-group-id="4848142189-18">]</span><span>                         </span><span>f64</span><span data-group-id="4848142189-19">[</span><span>2</span><span data-group-id="4848142189-19">]</span><span data-group-id="4848142189-20">[</span><span>2</span><span data-group-id="4848142189-20">]</span><span>
</span><span data-group-id="4848142189-6">&gt;</span><span>
</span><span data-group-id="4848142189-21">#</span><span data-group-id="4848142189-21">Nx.Tensor</span><span data-group-id="4848142189-21">&lt;</span><span>
  </span><span>f64</span><span data-group-id="4848142189-22">[</span><span>2</span><span data-group-id="4848142189-22">]</span><span data-group-id="4848142189-23">[</span><span>2</span><span data-group-id="4848142189-23">]</span><span>
  </span><span data-group-id="4848142189-24">[</span><span>
    </span><span data-group-id="4848142189-25">[</span><span>0.03205860328008499</span><span>,</span><span> </span><span>0.08714431874203257</span><span data-group-id="4848142189-25">]</span><span>,</span><span>
    </span><span data-group-id="4848142189-26">[</span><span>0.23688281808991013</span><span>,</span><span> </span><span>0.6439142598879722</span><span data-group-id="4848142189-26">]</span><span>
  </span><span data-group-id="4848142189-24">]</span><span>
</span><span data-group-id="4848142189-21">&gt;</span></code></pre>
<p>
This computation graph can also be transformed programatically. The transformation is precisely how we implement automatic differentiation, also known as <code>autograd</code>, by traversing each node and computing their derivative:</p>
<pre><code><span>defn</span><span> </span><span>grad_softmax</span><span data-group-id="5969204985-1">(</span><span>t</span><span data-group-id="5969204985-1">)</span><span> </span><span data-group-id="5969204985-2">do</span><span>
  </span><span>grad</span><span data-group-id="5969204985-3">(</span><span>t</span><span>,</span><span> </span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5969204985-4">(</span><span>t</span><span data-group-id="5969204985-4">)</span><span> </span><span>/</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="5969204985-5">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5969204985-6">(</span><span>t</span><span data-group-id="5969204985-6">)</span><span data-group-id="5969204985-5">)</span><span data-group-id="5969204985-3">)</span><span>
</span><span data-group-id="5969204985-2">end</span></code></pre>
<p>
Finally, this computation graph can also be handed out to different compilers. As an example, we have implemented bindings for <a href="https://www.tensorflow.org/xla/">Googleâ€™s XLA</a> compiler, called EXLA. We can ask the <code>softmax</code> function to use this new compiler with a module attribute:</p>
<pre><code><span>@defn_compiler</span><span> </span><span data-group-id="5313365207-1">{</span><span>EXLA</span><span>,</span><span> </span><span>client</span><span>:</span><span> </span><span>:host</span><span data-group-id="5313365207-1">}</span><span>
</span><span>defn</span><span> </span><span>softmax</span><span data-group-id="5313365207-2">(</span><span>t</span><span data-group-id="5313365207-2">)</span><span> </span><span data-group-id="5313365207-3">do</span><span>
  </span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5313365207-4">(</span><span>t</span><span data-group-id="5313365207-4">)</span><span> </span><span>/</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="5313365207-5">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5313365207-6">(</span><span>t</span><span data-group-id="5313365207-6">)</span><span data-group-id="5313365207-5">)</span><span>
</span><span data-group-id="5313365207-3">end</span></code></pre>
<p>
Once <code>softmax</code> is called, <code>Nx.Defn</code> will invoke <code>EXLA</code> to emit a just-in-time and highly-specialized compiled version of the code, tailored to the tensor type and shape. By passing <code>client: :cuda</code> or <code>client: :rocm</code>, the code can be compiled for the GPU. For reference, here are some benchmarks of the function above when called with a tensor of one million random float values on different clients:</p>
<pre><code>Name                       ips        average  deviation         median         99th %
xla gpu f32 keep      15308.14      0.0653 ms    Â±29.01%      0.0638 ms      0.0758 ms
xla gpu f64 keep       4550.59        0.22 ms     Â±7.54%        0.22 ms        0.33 ms
xla cpu f32             434.21        2.30 ms     Â±7.04%        2.26 ms        2.69 ms
xla gpu f32             398.45        2.51 ms     Â±2.28%        2.50 ms        2.69 ms
xla gpu f64             190.27        5.26 ms     Â±2.16%        5.23 ms        5.56 ms
xla cpu f64             168.25        5.94 ms     Â±5.64%        5.88 ms        7.35 ms
elixir f32                3.22      311.01 ms     Â±1.88%      309.69 ms      340.27 ms
elixir f64                3.11      321.70 ms     Â±1.44%      322.10 ms      328.98 ms

Comparison:
xla gpu f32 keep      15308.14
xla gpu f64 keep       4550.59 - 3.36x slower +0.154 ms
xla cpu f32             434.21 - 35.26x slower +2.24 ms
xla gpu f32             398.45 - 38.42x slower +2.44 ms
xla gpu f64             190.27 - 80.46x slower +5.19 ms
xla cpu f64             168.25 - 90.98x slower +5.88 ms
elixir f32                3.22 - 4760.93x slower +310.94 ms
elixir f64                3.11 - 4924.56x slower +321.63 ms</code></pre>
<p>
Where <code>keep</code> indicates the tensor was kept on the device instead of being transferred back to Elixir. You can see the benchmark in the <a href="https://github.com/elixir-nx/nx/tree/main/exla/bench"><code>bench</code></a> directory and find some examples in the <a href="https://github.com/elixir-nx/nx/tree/main/exla/examples"><code>examples</code></a> directory of the EXLA project.</p>
<h3>
Compiling numerical definitions</h3>
<p>
Before moving forward, it is important for us to take a look at how numerical definitions are compiled. For example, take the <code>softmax</code> function:</p>
<pre><code><span>defn</span><span> </span><span>softmax</span><span data-group-id="5791259392-1">(</span><span>t</span><span data-group-id="5791259392-1">)</span><span> </span><span data-group-id="5791259392-2">do</span><span>
  </span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5791259392-3">(</span><span>t</span><span data-group-id="5791259392-3">)</span><span> </span><span>/</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="5791259392-4">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5791259392-5">(</span><span>t</span><span data-group-id="5791259392-5">)</span><span data-group-id="5791259392-4">)</span><span>
</span><span data-group-id="5791259392-2">end</span></code></pre>
<p>
One might think that Elixir takes the AST of the softmax function above and compiles it directly to the GPU. However, thatâ€™s not the case! Numerical definitions are first compiled to Elixir code that will emit the computation graph and this computation graph is then compiled to the GPU. The multiple stages go like this:</p>
<pre><code>Elixir AST
-&gt; compiles to .beam (Erlang VM bytecode)
   -&gt; executes into defn AST
      -&gt; compiles to GPU</code></pre>
<p>
This multi-stage programming is made possible thanks to Elixir macros. For example, when you see a conditional inside <code>defn</code>, that conditional looks exactly like Elixir conditionals, but it will be compiled to an accelerator:</p>
<pre><code><span>defn</span><span> </span><span>softmax</span><span data-group-id="8102420814-1">(</span><span>t</span><span data-group-id="8102420814-1">)</span><span> </span><span data-group-id="8102420814-2">do</span><span>
  </span><span>if</span><span> </span><span>Nx</span><span>.</span><span>any?</span><span data-group-id="8102420814-3">(</span><span>t</span><span data-group-id="8102420814-3">)</span><span> </span><span data-group-id="8102420814-4">do</span><span>
    </span><span>-</span><span>1</span><span>
  </span><span data-group-id="8102420814-4">else</span><span>
    </span><span>1</span><span>
  </span><span data-group-id="8102420814-4">end</span><span>
</span><span data-group-id="8102420814-2">end</span></code></pre>
<p>
In a nutshell, <code>defn</code> provides us with a subset of Elixir for numerical computations that can be compiled to specific hardware, such as CPU, GPU, and other accelerators. All of this was possible without making changes or forking the language.</p>
<p>
And while <code>defn</code> is a subset of the language, it is a considerable one. You will find support for:</p>
<ul>
  <li>
Mathematical operators  </li>
  <li>
Pipes (<code>|&gt;</code>), module attributes, the access syntax (i.e. <code>tensor[1][1..-1]</code>), etc  </li>
  <li>
Elixir macros constructs (imports, aliases, etc)  </li>
  <li>
Control-flow with conditionals (both <code>if</code> and <code>cond</code>), loops (coming soon), etc  </li>
  <li>
Transformations, an explicit mechanism to invoke Elixir code from a <code>defn</code> (which enables constructs such as <code>grad</code>)  </li>
</ul>
<p>
And more coming down the road.</p>
<h2>
Why functional programming?</h2>
<p>
At this point, you may be wondering: is functional programming a good fit for numerical computing? One of the main concerns is that immutability can be expensive when working with large blobs of memory. And thatâ€™s a valid concern! In fact, when using the default tensor backend, tensors will be backed by Elixir binaries which are copied on every operation. Thatâ€™s why it was critical for us to design <code>Nx</code> with pluggable backends from day one.</p>
<p>
However, as we move to higher-level abstractions, such as numerical definitions, we will start to reap the benefits of functional programming.</p>
<p>
For example, in order to build computation graphs, immutability becomes an indispensable tool both in terms of implementation and in terms of reasoning. The JAX library for Python, which has been one of the guiding lights for Nx design, also promotes functional and immutable principles:</p>
<blockquote>
  <p>
<em>JAX is intended to be used with a functional style of programming</em>  </p>
  <p>
â€” <a href="https://jax.readthedocs.io/en/latest/jax.ops.html?highlight=functional#indexed-update-operators">JAX Docs</a>  </p>
</blockquote>
<blockquote>
  <p>
<em>Unlike NumPy arrays, JAX arrays are always immutable</em>  </p>
  <p>
â€” <a href="https://jax.readthedocs.io/en/latest/notebooks/thinking_in_jax.html?highlight=immutable#JAX-vs.-NumPy">JAX Docs</a>  </p>
</blockquote>
<p>
Similarly, frameworks like <a href="https://thinc.ai/">Thinc.ai</a> argue that functional programming can provide better abstractions and more composable building blocks for deep learning libraries.</p>
<p>
We hope that, by exploring these ideas in a language that is functional by design, Elixir can bring new ideas and insights at the higher-level.</p>
<h2>
What is next?</h2>
<p>
There is a lot of work ahead of us â€¦</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashbit.co/blog/nx-numerical-elixir-is-now-publicly-available">https://dashbit.co/blog/nx-numerical-elixir-is-now-publicly-available</a></em></p>]]>
            </description>
            <link>https://dashbit.co/blog/nx-numerical-elixir-is-now-publicly-available</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179373</guid>
            <pubDate>Thu, 18 Feb 2021 13:08:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Split Keyboards Gallery]]>
            </title>
            <description>
<![CDATA[
Score 189 | Comments 106 (<a href="https://news.ycombinator.com/item?id=26179311">thread link</a>) | @Symbiote
<br/>
February 18, 2021 | https://aposymbiont.github.io/split-keyboards/ | <a href="https://web.archive.org/web/*/https://aposymbiont.github.io/split-keyboards/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://aposymbiont.github.io/split-keyboards/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179311</guid>
            <pubDate>Thu, 18 Feb 2021 13:01:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Moiva.io v3: a universal tool to Evaluate, Discover and Compare software]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26179252">thread link</a>) | @alexey2020
<br/>
February 18, 2021 | https://moiva.io/blog/universal-tool-to-evaluate-discover-compare-software | <a href="https://web.archive.org/web/*/https://moiva.io/blog/universal-tool-to-evaluate-discover-compare-software">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <div>
    <p><span>Feb 17 2021</span>
    <span>Â· written by</span>
    <a href="https://twitter.com/_aantipov" target="_blank">Alexey Antipov</a>
  </p></div>

  <p>Hi, Alexey is here. I have some exciting news for you!</p>
<p>I rewrote <a href="https://moiva.io/">Moiva.io</a> from scratch and made it a Universal and Flexible tool to suit a taste of every software developer be they a JavaScript, Python or [put your favorite language here] developer.</p>
<p>This article marks a third major release of Moiva.</p>
<p><img src="https://moiva.io/blog/images/universal-tool/full.png" alt="A screenshot of Moiva.io showing comparison of Vue and Svelte npm packages"></p>
<h2 id="whats-new-in-short">Whatâ€™s new (in short)</h2>
<ul>
<li>ability to search for and get data for any GitHub repository in addition to search and comparison of NPM packages.</li>
<li>possibility to bring (relatively easy) Search, Suggestion, and Comparison capabilities to other programming languages' package management systems like <a href="https://mvnrepository.com/">Maven</a> (Java), <a href="https://pypi.org/">PIP</a> (Python), or <a href="https://packagist.org/">Packagist</a> (PHP).</li>
<li>last but not least, Moiva got <a href="https://github.com/aantipov/moiva">open-sourced</a>.</li>
</ul>
<h2 id="why-i-did-it">Why I did it</h2>
<p>At first, I wanted to focus on JavaScript ecosystem, making npm packages first-class citizens in Moiva.io.</p>
<p>The goal was to provide developers with a good tool to evaluate and compare npm packages in different dimensions - Popularity, Maintenance, Security, etc.</p>
<p>But very soon I realized that there are many JavaScript-related projects which donâ€™t have any published npm packages.</p>
<p>Think of, for example, frameworks like <code>Meteor</code>.</p>
<p>Moiva.io could potentially be useful for the evaluation of those projects as well thanks to GitHub charts (Contributors, Issues, Commits Frequency, etc.), but search functionality was limited to npm packages only and everything was built around the concept of npm packages.</p>
<p>On the other hand, if Moiva gets opened up to the search, evaluation and comparison of <strong>any</strong> GitHub project, it will essentially convert Moiva into a universal tool and make it useful to many more developers.</p>
<p>So I got convinced that Moiva should become more Universal and Agile, I just need to come up with a good harmonious concept of how it should look, work and how to implement it.</p>
<h2 id="aha-moment">AHA moment</h2>
<p>In the beginning, the idea of supporting GitHub looked vague and blurred. I didnâ€™t have any good idea how to put together existing functionality for npm packages and the new one for GitHub repositories.</p>
<p>I could implement separate pages for npm and GitHub, but that was not ideal. Both have a lot in common when comparing JavaScript projects.</p>
<p>Then the <code>AHA</code> moment came - everything became clear, I realized how to put together different things and since then I was unstoppable.</p>
<p>Here is the essence of the solution.</p>
<h3 id="one-search-for-all">One Search for All</h3>
<p>The same single search field can be used to search for both npm packages and GitHub repositories. It can be easily achieved via search modifiers (prefixes).</p>
<p>The default search is for GitHub.</p>
<p>The search prefixed with <code>n:</code> is for npm packages.</p>
<p><img src="https://moiva.io/blog/images/universal-tool/search.gif" alt="A gif showing how Search field at Moiva.io works: search for NPM packages and GitHub repositories"></p>
<p>What I like about that solution is that it can be easily extended in the future to search for other things as well.</p>
<h3 id="show-only-relevant-charts">Show only relevant charts</h3>
<p>If a user selects only GitHub repositories without related npm packages, then we can just hide npm-related charts. No reason to show them.</p>
<p>Itâ€™s similar to how ThoughtWorks TechRadar and Developer Usage charts work - they are shown only when there is data for the selected npm packages.</p>
<p>At the same time, if the user selects a mix of npm and Github projects, we will show npm-related charts for the selected npm packages.</p>
<h3 id="how-about-urls">How about URLs</h3>
<p>Every comparison a user makes in Moiva should be easily reproducible via URL.</p>
<p>It means that Moiva should be able to derive from the URL what information to load, what to put into comparison.</p>
<p>When npm packages were the only citizens in the Moiva world, the task was solved easily - the selected npm packages' names were listed in a query parameter: <code>https://moiva.io/?compare=react+svelte+vue</code>.</p>
<p>Having 2 types of citizens, npm and Github, where one depends on the other, complicates things a bit. Moreover, we want to build a future-proof solution that can incorporate other types of citizens like PIP and Maven.</p>
<p>GitHub has a broader scope than npm and my first idea was to replace URL npm identifiers with GitHub identifiers. But there are 2 problems with it:</p>
<ul>
<li>itâ€™s not clear how to derive the npm package from the GitHub repository. At least I couldnâ€™t find the solution for that.</li>
<li>one GitHub repo can be a source of multiple npm packages. There is no 1:1 connection.</li>
</ul>
<p>It lead me to the conclusion that GitHub and npm should be referenced separately in the URL.</p>
<p>So I just decided to have separate query parameters: <code>https://moiva.io/?npm=svelte+vue&amp;github=meteor/meteor</code>.</p>
<h3 id="github-and-npm-reconciliation">GitHub and NPM reconciliation</h3>
<p>Imagine two situations:</p>
<ol>
<li>a user selects Vue as an npm package.</li>
<li>a user selects Vue as a GitHub repo.</li>
</ol>
<p>In the first situation Moiva shows npm-related data and charts like npm Downloads. In the second situation, it doesnâ€™t.</p>
<p>But is it fair? Most probably a user would expect to see the same set of information in both cases, right?</p>
<p>Could we still somehow derive information about the npm package from the GitHub repository? If yes, then we could show npm data for the selected GitHub repository.</p>
<p>Turns out we can make use of <a href="https://github.com/aantipov/moiva-catalog">Moiva Catalog</a> which was built to implement the Suggestions mechanism.
For every listed GitHub repository we can add a name of the npm package if there is one. It means we can solve the problem of the reconciliation for items listed in the catalog. And I think itâ€™s a good enough solution with which we can cover the most popular libraries.</p>
<p>We just need to take care of some details and edge cases.</p>
<ol>
<li>If a repository does have an npm package, but that package is just one of the repoâ€™s â€œby-productsâ€, then probably it doesnâ€™t make sense to show that npm package data when selecting the repository. To solve that problem, an additional flag <code>isNpmCoreArtifact</code> in the catalog can be used to indicate the â€œroleâ€ of the npm package.</li>
<li>If we successfully derive npm data from the GitHub repository, it means we essentially display the same information for both npm and GitHub and have different URL identifiers for the same page. Itâ€™s not good, especially in terms of SEO. So I decided to use npm packageâ€™s name as a URL identifier in such cases. Try load <code>https://moiva.io/?github=vuejs/vue</code> url and see what happens ;=)</li>
</ol>
<h3 id="data-model">Data model</h3>
<p>I mentioned just a few of the problems I had to solve. There were, of course, many others, like duplication handling, aliases, SEO, etc.</p>
<p>Most of the problems got a straightforward solution once I implemented a proper Data Model - I came up with a new abstraction called â€œLibraryâ€ and provided it with certain properties and behavior.</p>
<p>If you are interested, you can check the <a href="https://github.com/aantipov/moiva/">repositoryâ€™s readme</a> for more details about the Library concept.</p>
<h2 id="whats-next">Whatâ€™s next</h2>
<p>I clearly see a huge potential for <a href="https://moiva.io/">Moiva.io</a> to become a really useful tool to many developers.</p>
<p>It can grow and become better in different directions.
I will mention a few of them which look most important to me:</p>
<ul>
<li>enable search/suggestion/comparison for more languages' package systems (Maven, PIP, etc.).</li>
<li>add more useful charts and data, both generic and language/package-system specific.</li>
<li>improve significantly the alternatives suggestion system. Currently, itâ€™s based on <a href="https://github.com/aantipov/moiva-catalog">Moiva Catalog</a> and needs a lot of data to be put there. I see a way how the community could help and contribute there.</li>
</ul>
<hr>
<p>I hope I didnâ€™t waste your time and you found the reading and the project itself interesting.</p>
<p>Stay tuned and Subscribe to the newsletter. I want to publish more interesting content about Moiva development.</p>

</div></div>]]>
            </description>
            <link>https://moiva.io/blog/universal-tool-to-evaluate-discover-compare-software</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179252</guid>
            <pubDate>Thu, 18 Feb 2021 12:55:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taking a Stand in the War on General-Purpose Computing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26179176">thread link</a>) | @TLM275
<br/>
February 18, 2021 | http://cheapskatesguide.org/articles/war-on-gp-computing.html | <a href="https://web.archive.org/web/*/http://cheapskatesguide.org/articles/war-on-gp-computing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://cheapskatesguide.org/articles/war-on-gp-computing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179176</guid>
            <pubDate>Thu, 18 Feb 2021 12:47:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I am a heroin user. I do not have a drug problem]]>
            </title>
            <description>
<![CDATA[
Score 277 | Comments 651 (<a href="https://news.ycombinator.com/item?id=26179003">thread link</a>) | @CapitalistCartr
<br/>
February 18, 2021 | http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem | <a href="https://web.archive.org/web/*/http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			<p><span>C</span>arl Hart is a neuroscientist and Ziff Professor of Psychology at Columbia Universityâ€”he was the first tenured African-American professor of sciences at Columbia. His research focuses on the â€œbehavioral and neuropharmacological effects of psychoactive drugs in humans.â€ Hartâ€™s new book, <i>Drug Use For Grown-Ups</i>, is a bold and engaging effort to counter what he sees as generations of misinformation and moral grandstanding about drug use. Todayâ€™s â€œsensationalistic media coverage of the opioid crisis continues a long, awful tradition of exploiting ignorance and fear to vilify certain members of our society,â€ Hart writes. The media is not the only problem. Scientists, he states, â€œhave frequently overinterpreted and distortedâ€ drugsâ€™ effects on the brain.</p><p>Hart reports that more than 70 percent of drug usersâ€”whether they use alcohol, cocaine, prescription medications, or heroinâ€”do not meet the health criteria for drug addiction. In <i>Drug Use for Grown-Ups</i>, Hart strives to â€œpresent a more realistic image of the typical drug user: a responsible professional who happens to use drugs in his pursuit of happiness.â€ With genial candor, Hart presents himself as a model drug user. â€œI am now entering my fifth year as a regular heroin user,â€ he writes. â€œI do not have a drug-use problem. Never have. Each day, I meet my parental, personal, and professional responsibilities. I pay my taxes, serve as a volunteer in my community on a regular basis, and contribute to the global community as an informed and engaged citizen. I am better for my drug use.â€</p><p><i>Nautilus</i> caught up with Hart to discuss his drug use and his sharp points about science and society. He was as casually bold in conversation as he is in <i>Drug Use for Grown-Ups</i>.</p><figure data-alt="MacNamara_BREAKER"><img src="http://static.nautil.us/18174_0f004440ba0c8f1ccc5c355f3d77207f.png" width="733" alt=""><figcaption><span><strong>HABIT OF A HIGHLY EFFECTIVE PERSON:</strong> â€œMy heroin use is as rational as my alcohol use,â€ Carl Hart writes. â€œLike vacation, sex, and the arts, heroin is one of the tools that I use to maintain my work-life balance.â€</span><span>Courtesy of Carl Hart</span></figcaption></figure><p><b>You say â€œmost drug-use scenarios cause little or no harm and that some responsible drug-use scenarios are actually beneficial for human health and functioning.â€ How so?</b></p><p>Letâ€™s just talk about alcohol first. When youâ€™re at a wedding reception, alcohol serves as a social lubricant. People are more gregarious. They talk, they interact. The same is true with cocaine at parties, heroin among friends, or opium among friends, NDMA among lovers. It enhances empathy, openness, and forgiveness, all of these pro-social attributes.</p><p><b>Drug research, you write, is full of bad science. If you had to name one example, what would it be?</b></p><p>The notion that drug addiction is a brain disease. That encapsulates all thatâ€™s wrong with todayâ€™s science in this area. There is absolutely no data in humans to show that drug addiction is a brain disease. Yet the narrative, the dogma, the dominant perspective is that it does. Even though nobody will dispute that, thereâ€™s absolutely no data in humans to support that statement.</p><p><b>Yet opioids do change the brain biologically, do they not?</b></p><p>Yes, opioids bind to a class of receptors called endogenous opioids, which you find in endorphins, for example. Opioids bind to these receptorsâ€”just like natural chemicals doâ€”which results in a response. In some cases, because of decreased sensitivities and certain types of pain, they may enhance a sense of euphoria. So itâ€™s really just facilitating whatâ€™s already in the body naturally, a system that helps in our survival. Think of fructose or glucose. We add sugar to our tea, our coffee, whatever we have, we add more and more because we like it, it tastes good, and it enhances pleasure. It can give you energy. It can make life more interesting. Humans do not live on logic alone. And so sometimes we do these things, and thatâ€™s OK.</p><blockquote><p>People become addicted because they once had a middle-class-paying job that made them someone in their community.</p> </blockquote><p><b>How have scientists â€œoverinterpreted and distortedâ€ the effects of drugs on the brain?</b><br></p><p>Take brain imaging. People often show one image of someoneâ€™s brain. Letâ€™s say this person is addicted to methamphetamine, according to DSM criteria, versus the brain of someone whoâ€™s not addicted. If you see some difference, some researchers have a propensity to make more out of the differences than are there. Thereâ€™s a wide range of brain structural sizes, such that when we think about one personâ€™s size of their nucleus accumbens, it may be smaller or larger than somebody elseâ€™s nucleus accumbens. But both of the nucleus accumbens, despite their sizes, are within the normal range of human variability. Itâ€™s like height. One guy might be 5â€™10â€, another guy might be 6â€™2â€. But we donâ€™t say the guy whoâ€™s 5â€™10â€ is height deficient. We just say that heâ€™s in a normal range, and heâ€™s not as tall as the other guy. We wouldnâ€™t say one is deficient versus the other. In neuroscience, one of the things that has happened, particularly when it comes to drugs, people have over-interpreted the differences to mean pathology, when, in fact, both of the brain structures are within the normal range of human variability. The overinterpretation is to interpret it as being pathological.</p><p><b>You say the opioid crisis has been sensationalized, and write, â€œPeople are not dying because of opioids; they are dying because of ignorance.â€ What do you mean?</b></p><p>Some people donâ€™t know not to mix specific sedatives with opioids. For example, they donâ€™t know not to mix large amounts of alcohol or large amounts of antihistamines. Specific combinations can lead to respiratory depression, which can lead to death. Another point of ignorance involves people who buy street drugs and donâ€™t necessarily know if the drugs contain contaminants. Thatâ€™s the kind of ignorance Iâ€™m talking about.</p><div>
<article>
<p><a href="http://m.nautil.us/issue/101/In%20Our%20Nature/these-are-their-brains-on-silence-rd" data-trval="these-are-their-brains-on-silence-rd" data-trlbl="foc_rec" data-tract="internal_art">
<img src="http://static.nautil.us/4972_e32c51ad39723ee92b285b362c916ca7.png" alt="Sapolsky_TH-F1" width="314" height="177">
</a>
</p>


</article>
</div><p><b>So itâ€™s the mix of drugs that is the problem, not opioids like heroin themselves?&nbsp;</b></p><p>Yes, the majority of opioid deaths occur as a result of combining opioids with multiple sedatives. But there are certain opioids that do concern us if taken alone and the person isnâ€™t aware that they have this particular opioid. Those are fentanyl and the fentanyl analogs. These drugs are a lot more potent than something like heroin, meaning they require less of it to produce the effect. Most of the public arenâ€™t seeking fentanyl or its analogs, but people are tainting things like heroin and oxycodone pills with fentanyl or an analog.</p><p>One way to deal with this tainting, this contamination, is to have free drug-checking facilities, where people can submit samples of their drug and get a chemical readout of what is contained in the substance. That way theyâ€™ll know whether to take the substance or how much of it to take. The public also needs to know that most people who use these drugs are not addicts. If you understand that, then you know that for the people who do become addicted, we have to look beyond the drug and look at the personâ€™s environment, their life. Do they have co-occurring psychiatric illnesses? Do they have pain that is not treated? All of these kinds of issues become important.</p><p><b>At what point does biological change in the brain lead to physical addiction?</b></p><p>Physical addiction occurs as a result of opioidsâ€”or any other drug, alcohol tooâ€”being in the body for consecutive weeks or periods, in particularly high doses. And then the body tries to compensate. For example, with opioids, one of the things that happens is that your gut, your gastrointestinal system, slows down the receptors. Your body is trying to compensate by speeding up the gastrointestinal tract. So when the drug abruptly leaves after several weeks of constant administration of the opioid, now the body is unprepared for the drug not being there and it overcompensates. It really ramps up the motility of the gastrointestinal tract, which causes diarrhea, among other things.</p><blockquote><p>It can give you energy. It can make life more interesting. Humans do not live on logic alone.</p> </blockquote><p><b>Why do some people get addicted and not others?</b><br></p><p>The amount of drugs they take, the period at which they take it. Some people can take opioids for extended periods of time. As long as they keep the doses fairly low and they donâ€™t take multiple doses a day, they probably wonâ€™t experience physical dependence. Itâ€™s just like with alcohol. Most people drink alcohol on a regular basis, but they donâ€™t become physically dependent. Whereas others drink every day in large amounts, and they will become physically dependent.</p><p><b>Why canâ€™t people overcome addiction?</b></p><p>One of the major reasons people canâ€™t overcome it is because weâ€™re not very good at treating addiction in this country. Just think about why people become addicted. A large number become addicted because of co-occurring psychiatric illnesses, because of pain issues, because they once had a middle-class-paying job that made them someone in their home, someone in their community. Those jobs are gone. Then thereâ€™s no healthcare or thereâ€™s poor education. If your treatment is not addressing these issues, people are not going to overcome it. But if we have treatments that are holistic, and theyâ€™re looking at the individual, and not so much the drug, then weâ€™re good. But if weâ€™re just talking about the drug, then weâ€™re already behind the eight ball, then we will lose that battle.</p><p><b>Your definition of addiction follows the DSM-5, which refers to a â€œsubstance use disorderâ€ and values functioning over regular ingestion of a substance. How do you define â€œfunctioningâ€?</b></p><p>Functioning is determined by whether a user is happy in meeting their obligations, whatever they may be, whether theyâ€™re work-related, whether theyâ€™re family-related, or other social sorts of things. The person is not stressed out about their substance use. In fact, theyâ€™re cool with it. Thatâ€™s functioning. The personâ€™s happiness is more important. That supersedes any other thing.</p><p><b>You write that, contrary to the cultural myth, regular use of recreational drugs doesnâ€™t damage the brain. Whatâ€™s the frequency associated with recreational?</b></p><p>Yeah, Iâ€™m sorry. I couldnâ€™t think of a â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem">http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem</a></em></p>]]>
            </description>
            <link>http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179003</guid>
            <pubDate>Thu, 18 Feb 2021 12:23:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Why of Technology]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26178726">thread link</a>) | @mpereira
<br/>
February 18, 2021 | https://www.murilopereira.com/the-why-of-technology/ | <a href="https://web.archive.org/web/*/https://www.murilopereira.com/the-why-of-technology/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure><img src="https://www.murilopereira.com/man_on_a_bicycle.jpg"></figure><blockquote><p>I think one of the things that really separates us from the high primates
is that weâ€™re tool builders. I read a study that measured the efficiency of
locomotion for various species on the planet. The condor used the least
energy to move a kilometer. Humans came in with a rather unimpressive
showing about a third of the way down the list. It was not too proud a
showing for the crown of creation. So, that didnâ€™t look so good.</p><p>But then, somebody at Scientific American had the insight to test the
efficiency of locomotion for a man on a bicycle. And, a man on a bicycle, a
human on a bicycle, blew the condor away, completely off the top of the
charts.</p><p>And thatâ€™s what a computer is to me. What a computer is to me is itâ€™s the
most remarkable tool that weâ€™ve ever come up with.</p><p>Itâ€™s the equivalent of a bicycle for our minds.</p><p>â€” <a href="https://www.youtube.com/watch?v=0lvMgMrNDlg&amp;feature=youtu.be&amp;t=322">Steve Jobs (1980)</a></p></blockquote><p>* * *</p><p><a href="https://www.it-hiroshima.ac.jp/institution/library/pdf/research52%5F007-013.pdf">No one knows</a> when or how we, the human species, started talking to each
other. It is likely a natural progression from gesturing, but we can only
speculate about it.</p><p>Language allowed us to break out of our brains and reveal the inner
workings of our consciousness to others.</p><figure><img src="https://www.murilopereira.com/language_speech.jpg" alt="Figure 2: Scott H. Young"><figcaption><p>Figure 2: <a href="https://www.scotthyoung.com/blog/2018/12/04/25-thinking-tools/">Scott H. Young</a></p></figcaption></figure><p>Language is the vessel that carried us from the stone age through the
agricultural revolution, the development of written language, the
scientific and industrial revolutions, and now, the digital age.</p><p>Writing allowed us to <em>offload</em> memories to the physical worldâ€”outside of
our brains. Through our collective and external memories, each generation
has a head start on the previous one. Little by little, standing on the
shoulders of taller and taller giants, we accumulate knowledge about
ourselves and everything around us.</p><p>Weâ€™ve been for long using tools to help us think: notebooks help us
calculate formulas, reason geometrically and preserve our ideas. With
computers, our <em>thinking</em> is now occurring outside of our brains.</p><p>Computers are extensions of our minds in that they allow us to store,
process, and retrieve information from them. With the advent of the
internet we now have immediate access to not only almost all of the
information ever produced by humankind but also to reproducible <em>thinking</em>
encoded into these machines: algorithms.</p><p>Our brain is still a much more impressive device than any of today's
computers. Computers learn
<a href="https://www.davidsilver.uk/wp-content/uploads/2020/03/nfsp-1.pdf">mostly</a>
by finding patterns in massive
quantities of examples given by us. Teaching a young kid about carsâ€”how
to recognize one, what they are, what their purpose is, and how they're
related to other thingsâ€”requires little supervision. Noam Chomsky talks
about it in
<a href="https://www.youtube.com/watch?v=hdUbIlwHRkY&amp;t=1462">this interview</a>.</p><p>Each of these processesâ€”storing, processing and retrieving
informationâ€”have concrete effects on the physical world: if Iâ€™m in
Munich, saying â€œshow route to Hamburgâ€ to my phone will immediately show me
the distance, ETAs and paths for different types of transport to reach my
destination. Not only do I now suddenly know how to navigate across the
country to reach another city, Iâ€™m also able to follow through the exact
path via GPSâ€”a sixth sense giving me perfect geolocation!</p><p>These <em>things</em> that we createdâ€”computers, and the internetâ€”are literally
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6502424/">rewiring our brains</a>, right now, shaping how we think, and engage in social
relationships, changing not only our individual selves but the societies we
live in.</p><p>They started as mechanical machines that filled entire laboratories, turned
into beige boxes in our homes and places of work, and are now sleek slabs
of plastic, metal and glass in everyoneâ€™s pockets. Step by step they get
closer to our bodies, their interfaces more intuitive and natural.</p><p>The way we communicate with them is changing: before, we could only
interact with them by speaking their language. We have now taught them
ours. The torch of progress blazes on: itâ€™s a matter of <em>time</em> until theyâ€™re
connected directly with our brainsâ€”which is equally terrifying and
awe-inspiring.</p><figure><img src="https://www.murilopereira.com/neuralink.jpg" alt="Figure 3: Neuralink"><figcaption><p>Figure 3: <a href="https://neuralink.com/">Neuralink</a></p></figcaption></figure><p>Brain-computer interfaces present a monumental scientific and engineering
challenge, and brain-to-brain, a whole other category of difficulty.</p><p>First, we have no idea how information is encoded in the brain. That needs
to be understood. Second, even assuming weâ€™re able to take a perfect
snapshot of a piece of information in someoneâ€™s brainâ€”for example, how a
particular movie scene makes them feelâ€”we still need to be able to encode
it in a way that includes the full context of their subjective experiences.
Maybe the scene evokes unique memories of their childhood or is somehow
entangled with the smell of a particular cinemaâ€™s leather seats. Third, we
need to figure out how to safely write this perfect snapshot into someone
elseâ€™s brain in a way that can be perceived identically.</p><p>Which is to say, itâ€™s a difficult problem. But a worthwhile one: imagine
having the capability to suddenly become aware of answers for questions you
just thought about. To expertly control <a href="https://youtu.be/PLk8Pm%5FXBJE?t=13">truly integrated</a> prosthetics giving
you superhuman abilities. To give movement to the paralized, sound to the
deaf, and sight to the blind.</p><p>What would be the impacts on society if we were able to communicate an
order of magnitude more effectively? What if <em>everyone</em> was equipped with
the same undisputed basic knowledge of history and science?</p><p>There are internal thoughts that we can attempt to describe with a thousand
words, but ultimately fail to capture in a way thatâ€™s precise, much less
comprehensible by someone else. Words and sentences are an incomplete
representation of our internal thoughts. In the same way that 3D objects
cast 2D shadows (<a href="https://www.youtube.com/watch?v=N0WjV6MmCyM">and 4D, 3D</a>) communicating through language doesnâ€™t carry
all of our cultural and developmental contextâ€”transmitting all of that
along with every phrase would be impractical. Language is in this sense,
lossily compressed thought.</p><figure><img src="https://www.murilopereira.com/tesseract_shadow.jpg"></figure><p>Inert strings of words of ink and paper take a life of their own inside our
heads. Itâ€™s why the exact same information can be interpreted completely
differently by different people.</p><p>Before language, fire and cooking technology allowed us to reallocate
energy usage from the digestive system to the brain by outsourcing
digestion to outside of our bodies, making macronutrients more efficiently
absorbable. Almost all of a cooked meal is metabolized by the body, whereas
raw foods yield less than half of their nutrients.</p><p>Cooking is an extension of our digestive system, and enabled us to develop
large, calorie-hungry brains. It also gave us time to think: our primate
cousins spend half of their days chewing raw food to consume enough
calories to stay alive.</p><p>Brains can be seen as <em>survival machines</em>, locked inside dark skulls,
constantly building a model of the outside world by predicting and learning
through senses and memory. The biological human brain evolved to have the
necessary sophistication to not only expertly navigate and understand the
brute physical reality but also to construct <em>social</em> reality. Democracy,
religion, money: all made up by us, for us.</p><p>We remember the past so that we can predict the future, and by doing so, we
thrive.</p><p>We create technology, which functions as a non-biological extra layer to
our brains and bodies, augmenting, complementing, and sometimes replacing
our natural capabilities.</p><blockquote><p>The wheelâ€¦ is an extension of the foot.</p><p>The bookâ€¦ is an extension of the eyeâ€¦</p><p>Clothing, an extension of the skinâ€¦</p><p>Electric circuitry, an extension of the central nervous system.</p><p>â€”
<a href="https://en.wikipedia.org/wiki/Understanding_Media">Understanding Media: The Extensions of Man (1964)</a></p></blockquote><p>Relatively speaking, we are done evolving <em>biologically</em>. Further adaptations
and enhancements to our bodies and minds will come through technology.</p><figure><img src="https://www.murilopereira.com/brain_layers.jpg" alt="Figure 5: Check out &amp;ldquo;Neuralink and the Brain&amp;rsquo;s Magical Future&amp;rdquo; for a very entertaining primer on the brain."><figcaption><p>Figure 5: Check out â€œ<a href="https://waitbutwhy.com/2017/04/neuralink.html">Neuralink and the Brainâ€™s Magical Future</a>â€ for a very entertaining primer on the brain.</p></figcaption></figure><p>To be human is to have the ability to change the world around us. The shift
from hunting and gathering to farming allowed us to spend less energy to
acquire food while giving us a predictable calorie supply.</p><p>The resulting food surplus made it possible for populations to settle down
and grow quickly while supporting people not being directly involved in the
production of foodâ€”before agriculture that was everyoneâ€™s job. For one,
it allowed some to specialize and focus on developing better farming tools
and more resistant crops, starting a vicious cycle of improvement and
consumption that continues until today.</p><p>The transition from active foraging to a more sedentary lifestyle resulted
in worse health for the general population. The average farmer worked
harder than the average forager and got a worse diet in return. Our teeth,
bones and joints became more fragile, and we became afflicted by novel
diseases coming from newly domesticated animals, carriers of pathogens that
incubated in our new densely populated cities.</p><p>Owning land suddenly became really important. Agriculture and the concept
of private property reinforced each other and grew together, allowing us to
create value and secure the fruits of our labor. It also created the
circumstances for slavery to arise, and wars to be waged.</p><p>The groups of people growing the first crops could not have anticipated all
of the collateral effects of their breakthrough. They just wanted more
food.</p><p>If the past has taught us anything is that we have to be mindful of the
consequences of our progress. In an increasingly connected world, change is
often <a href="https://hbr.org/2017/05/linear-thinking-in-a-nonlinear-world">nonlinear</a> and unpredictable. Cars didnâ€™t just replace horsesâ€”they
forever changed the entire outlook of every city. Did Tim Berners-Lee
anticipate his invention adding to forces pulling whole countries apart?</p><p>Our progress will continue to bring us previously unimaginable challenges.
Against an unknowable future, it doesnâ€™t hurt to keep improving our
capabilities to adapt and, more difficultly, to cooperateâ€”especially at
scale.</p><figure><img src="https://www.murilopereira.com/humanity.jpg" alt="Figure 6: &amp;ldquo;Humanity&amp;rdquo; by Pawel Kuczynski"><figcaption><p>Figure 6: â€œ<a href="https://www.pictorem.com/24592/humanity.html">Humanity</a>â€ by Pawel Kuczynski</p></figcaption></figure><p>Computers are getting pretty good at driving carsâ€”even in the most
difficult situationsâ€”and can already instantly diagnose some diseases
better than human doctors. Technology has a way to <a href="https://www.thenewatlantis.com/publications/understanding-heidegger-on-technology">reveal</a> the potential of
our environment, and ourselves. We have to be careful not to look at â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.murilopereira.com/the-why-of-technology/">https://www.murilopereira.com/the-why-of-technology/</a></em></p>]]>
            </description>
            <link>https://www.murilopereira.com/the-why-of-technology/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26178726</guid>
            <pubDate>Thu, 18 Feb 2021 11:45:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The frame rate of the universe (2009)]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 64 (<a href="https://news.ycombinator.com/item?id=26178259">thread link</a>) | @codesections
<br/>
February 18, 2021 | https://www.librador.com/2009/01/16/The-frame-rate-of-the-universe/ | <a href="https://web.archive.org/web/*/https://www.librador.com/2009/01/16/The-frame-rate-of-the-universe/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
      
<div id="page-2009-2009-01-16-The-frame-rate-of-the-universe-">
  
  <p><abbr title="2009-01-16T01:04:00+01:00">16 Jan 2009</abbr></p><div>
    <p>

    I stumbled upon <a href="http://www.newscientist.com/article/mg20126911.300-our-world-may-be-a-giant-hologram.html?full=true">this
article</a> which presents the hypothesis that the universe is a 3D projection of a 2D
surface, like a giant hologram. I like to read about modern physics. It is so weird and I can't say
I really understand very much of it. But the descriptions provoke strange and fascinating images
and thoughts in my head. Like this one:</p><p>The article mentions the <a href="http://en.wikipedia.org/wiki/Planck_length">Planck length</a>, which as I understand it is
the smallest distance there is. It's extremely small: 1.6 Ã— 10<sup>-35</sup> meters, which makes
it billions and billions of times smaller than an atom (or even a proton). I'm used to thinking
about computer graphics, so I imagine the Planck length as the size of one "pixel" of the universe.
Nothing can be smaller than a pixel. (The pixels of the universe are small, I calculate the
resolution to correspond to 2.19 Ã— 10<sup>33</sup> DPI.) The radius of the observable universe is
4.4 Ã— 10<sup>26</sup> meters. If we want to fit the universe into a box, its sides would have to
be twice that size. That is 5.4 Ã— 10<sup>61</sup> Planck lengths. So that's the width, height and
depth of the universe in pixels. Quite a good resolution. (Actually since they are 3D cubes instead
of 2D squares, I should call them voxels instead of pixels. All 1.61 Ã— 10<sup>185</sup> of
them.)</p><p>There is also the <a href="http://en.wikipedia.org/wiki/Planck_time">Planck time</a>
which is the time it takes for light to travel one Planck length. As light is fast and the Planck
length is tiny (tiniest there is!), you can image that it's a very short period of time. Certainly.
The Planck time is 5.39 Ã— 10<sup>-44</sup> seconds. No measurable time can be shorter than that
according to quantum physics. Thinking about graphics again, this is like a limit on the frame rate
of the universe. Inverting the Planck time, I get 1.855 Ã— 10<sup>43</sup>. So by my surely
incorrect logic, we get the value of the universe's frame rate:</p><p>One thousand eight hundred
and fifty-five billion billion billion billion frames per second.</p><p>I'll say that
again:</p><p>18.55 septillion FPS!</p><p>Video cameras won't be perfect until they can record at
that speed.</p><p>I hope I got the calculations right, but I'm pretty sure my interpretation of the
quantum physics behind this are way off. It's still fascinating to think of the universe as a
computer simulation. Modern physics make it seem more like a video game than ever.<br>


</p>
  </div>
  
  
  <p><a href="http://disqus.com/">blog comments powered by </a>
</p></div>

    </div></div>]]>
            </description>
            <link>https://www.librador.com/2009/01/16/The-frame-rate-of-the-universe/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26178259</guid>
            <pubDate>Thu, 18 Feb 2021 10:37:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lithuania plans to hold drills in case of accident at the Belarus nuclear plant]]>
            </title>
            <description>
<![CDATA[
Score 156 | Comments 139 (<a href="https://news.ycombinator.com/item?id=26178235">thread link</a>) | @maury91
<br/>
February 18, 2021 | https://www.lrt.lt/en/news-in-english/19/1346034/lithuania-plans-to-hold-evacuation-drills-after-belarus-launches-nuclear-plant | <a href="https://web.archive.org/web/*/https://www.lrt.lt/en/news-in-english/19/1346034/lithuania-plans-to-hold-evacuation-drills-after-belarus-launches-nuclear-plant">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article id="article1346034">    

    
    
    <div>

        <div id="article_text1346034">
            <p>Lithuaniaâ€™s Interior Ministry plans to hold drills and assess the need to evacuate Vilniusâ€™ residents in case of an accident at the Astravyets nuclear plant in Belarus, located some 50 kilometres from the Lithuanian capital.</p>
            
            <p>"That will be one of the key questions during the drafting of the exercises schedule and probably going back to the scenarios: do we or do we not need to evacuate Vilnius residents,â€ Vitalij Dmitrijev, vice minister of the interior, told LRT RADIO.</p>
            <p>The so-called Astravyets drill was held in October 2019 in Vilnius and SvenÄionys districts, which are located close to the Belarusian border. During the exercises, authorities prepared to evacuate people from radiation-affected territories, distribute iodine pills, as well as simulated a resident cleanup and monitoring operation.</p>
            <p>The exercise involved around 300 officers, troops and civil servants from six municipalities and 24 institutions. Due to a dispute over the exercise scenario with the Vilnius authorities, officers from the capital did not take part in the drills.</p>
                

            <p><em>Read more: <a href="https://www.lrt.lt/en/news-in-english/19/1103053/lithuanians-stage-mock-evacuations-to-train-for-nuclear-accident-photos">Lithuanians stage mock evacuations to train for nuclear accident â€“ photos</a></em></p>
            <!--googleoff: all--><!--googleon: all-->            <p>Previously, the Vilnius authorities cancelled another exercise, planned in early September, to simulate an accident at the nuclear power plant in Belarus.</p>
            <p>Based on the information available to BNS, Vilnius Municipality faced resistance from the government at the time.</p>
            <p>Lithuanian officials say that the nuclear power plant built by the Russian state atomic corporation Rosatom and funded by a loan from the Kremlin was built in breach of international safety standards. Minsk denies all accusations.</p>
            <p>Estonia, Latvia, and Lithuania are also due to unplug from the Moscow-controlled energy grid that links them with Belarus. Vilnius says that the Kremlin may use the plant to derail the move.</p>
<!--googleoff: all--><div>
            
<div id="mlb2-1612938">
    <div>
        <div>
            <div>
                <div>
                    <p><img src="https://bucket.mlcdn.com/a/1239/1239192/templates/39/39540/5dcc95ea35753170c2955994a6fea7c948ffb283.png"></p><p>LRT English Newsletter<span><span><br></span><span><span>Every Friday morning.</span></span></span></p>
                    
                </div>
            </div>
            
        </div>
    </div>
</div>

<p><img src="https://track.mailerlite.com/webforms/o/1612938/i0s8k2?v4a60e9ef938a7fa0240ac9ba567062cb" width="1" height="1">
</p></div><!--googleon: all-->        </div>
    </div>
    <!--googleoff: all-->
        <!--googleon: all-->
        

<div data-id="gallery1346034"><div>
            <div>
                <div>
                    <div>
<p><img data-src="/img/2019/10/02/522637-581058-1287x836.jpg" alt="â€˜Astravyets drillâ€™ in Lithuania" title="â€˜Astravyets drillâ€™ in Lithuania" src="https://www.lrt.lt/img/2019/10/02/522637-581058-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>â€˜Astravyets drillâ€™ in Lithuania</p>            <p><span>1 / 5</span><span>D. Umbrasas / LRT</span></p>
        </div></div>
</div>
                    </div>
                    <div>
<p><img data-src="/img/2019/12/23/573047-835055-1287x836.jpg" alt="Lithuania has staged 'Astravyets drills' to prepare for nuclear emergencies" title="Lithuania has staged 'Astravyets drills' to prepare for nuclear emergencies" src="https://www.lrt.lt/img/2019/12/23/573047-835055-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>Lithuania has staged 'Astravyets drills' to prepare for nuclear emergencies</p>            <p><span>2 / 5</span><span>D. Umbrasas/LRT</span></p>
        </div></div>
</div>
                    </div>
                    <div>
<p><img data-src="/img/2019/10/02/522627-981621-1287x836.jpg" alt="â€˜Astravyets drillâ€™ in Lithuania" title="â€˜Astravyets drillâ€™ in Lithuania" src="https://www.lrt.lt/img/2019/10/02/522627-981621-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>â€˜Astravyets drillâ€™ in Lithuania</p>            <p><span>3 / 5</span><span>D. Umbrasas / LRT</span></p>
        </div></div>
</div>
                    </div>
                    <div>
<p><img data-src="/img/2019/10/02/522623-306261-1287x836.jpg" alt="â€˜Astravyets drillâ€™ in Lithuania" title="â€˜Astravyets drillâ€™ in Lithuania" src="https://www.lrt.lt/img/2019/10/02/522623-306261-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>â€˜Astravyets drillâ€™ in Lithuania</p>            <p><span>4 / 5</span><span>D. Umbrasas / LRT</span></p>
        </div></div>
</div>
                    </div>
                    <div>
<p><img data-src="/img/2019/10/02/522612-821132-1287x836.jpg" alt="â€˜Astravyets drillâ€™ in Lithuania" title="â€˜Astravyets drillâ€™ in Lithuania" src="https://www.lrt.lt/img/2019/10/02/522612-821132-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>â€˜Astravyets drillâ€™ in Lithuania</p>            <p><span>5 / 5</span><span>D. Umbrasas / LRT</span></p>
        </div></div>
</div>
                    </div>
                </div>
                
            </div>
        </div>
        
    </div>
 

    
    
</article>

        
    </div></div>]]>
            </description>
            <link>https://www.lrt.lt/en/news-in-english/19/1346034/lithuania-plans-to-hold-evacuation-drills-after-belarus-launches-nuclear-plant</link>
            <guid isPermaLink="false">hacker-news-small-sites-26178235</guid>
            <pubDate>Thu, 18 Feb 2021 10:34:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Urbit: The Good, the Bad, and the Insane]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26177720">thread link</a>) | @wcerfgba
<br/>
February 18, 2021 | https://wejn.org/2021/02/urbit-good-bad-insane/ | <a href="https://web.archive.org/web/*/https://wejn.org/2021/02/urbit-good-bad-insane/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  <p><span>Written</span>
    

    
      <span>on&nbsp;</span><time datetime="2021-02-17 19:02:00 +0100">2021-02-17</time>
    
    
  </p>

  

  

  

  <p>In this post Iâ€™m gonna be making all kinds of fun of <a href="https://urbit.org/">Urbit</a>.
And all that after spending just a few hours poking around it.</p>
<p>Originally, I wanted to write in the layout of the good, the bad, and the ugly,
but Iâ€™m not entirely sure how that would pan out.<sup><a href="#fn1" id="fnref1">1</a></sup></p>
<p>Before I begin, Iâ€™ll somewhat oversimplify and explain Urbit to those of you not
in the know.</p>
<p><em>And before I do that, hereâ€™s a PSA: thereâ€™s a <a href="#tldr">tl;dr at the end</a>. So you
donâ€™t need to read all this drivel. Youâ€™re welcome.</em></p>
<h2 id="urwhat">Urâ€¦what?</h2>
<p>According to its own webpage, Urbit is an â€œoverlay OSâ€ and network for the 21st
century.</p>
<p>What that means at the time of writing<sup><a href="#fn2" id="fnref2">2</a></sup> is that itâ€™s a single-threaded
interpreter running as a unix process that speaks udp protocol to a meshed
network (and http to your browser).</p>
<p>And all of that in the name of delivering you flaky, unreliable, and feature-poor
implementation of an internet forum. (in a nutshell)<sup><a href="#fn3" id="fnref3">3</a></sup></p>
<p>An additional component of Urbit is its â€œdistributedâ€ identity component, where
your identity is uniquely tied to a 32-bit integer. And to go with the zeitgeist,
itâ€™s backed by Ethereum blockchain. Naturally.</p>
<p>All we need is quantum computing and ML, and we have all the latest buzzwords.
<a href="https://groups.google.com/a/urbit.org/g/dev/c/a6hdQdzIgqo">Oh, wait.</a></p>
<p>But to better explain whatâ€™s going on, letâ€™s look atâ€¦</p>
<h2 id="a-bit-of-history">A bit of history</h2>
<p>Iâ€™m going to take Urbitâ€™s history page on authority here.</p>
<p>This project started in 2002 as a PhD thesis to reinvent computing. Over the
next 6 years the progress was a language specification (Nock) for
a turing-complete language with ~11 instructions.</p>
<p>Then, over 10+ years other people ran with it, took it further, and implemented:</p>
<ul>
<li>(more than one) VM interpreting that language</li>
<li>a higher level language â€“ Hoon (to make Nock â€œpracticalâ€)</li>
<li>an encrypted mesh protocol</li>
<li>a versioned control system</li>
<li>an application layer</li>
<li>a web frontend (several apps, actually)</li>
<li>an identity layer</li>
<li>â€¦</li>
</ul>
<p>If this smells like a bad case of <a href="https://en.wikipedia.org/wiki/Not_invented_here">NIH</a>,
itâ€™s probably because thatâ€™s exactly the case.</p>
<h2 id="urbit-as-an-ideal-good-and-insane-at-the-same-time">Urbit as an ideal: good and insane at the same time</h2>
<p>But letâ€™s talk about Urbit as an ideal for a moment.</p>
<p>Letâ€™s assume that when <a href="https://youtu.be/M04AKTCDavc">the marketing materials</a>
speak of</p>
<blockquote>
<p>defining an operating system on a single piece of paper</p>
</blockquote>
<p>and</p>
<blockquote>
<p>throwing away every line of code from the 1970s</p>
</blockquote>
<p>they mean well. Given some sort of hardware implementation of Nock (the low level
language) you theoretically <em>could</em> throw away everything and start from scratch.</p>
<p>And it would be all kinds of awesome, if you could have decent control over your
personal computing without all the cruft accumulated since â€™70s.</p>
<p>Onlyâ€¦ with Urbit this ideal would be so slow as to be useless. See, Nock has
one arithmetic operation, increment (<code>x+1</code>). So if you want to decrement <code>x</code>,
you have to loop from <code>0</code> to <code>x-1</code>. Or you can break your promise of throwing
away all the code from â€™70sâ€¦ and implement decrement in C.</p>
<p>And the same story (of replacing godawfully ineffective implementation of native
code with C implementation) goes pretty much for any reasonable functionality you
might expect. Crypto? Sorting? Basic math and string ops? All of it.</p>
<p>The entire frickinâ€™ peer to peer protocol is written in C, too. So are vast
swaths of the OS: db, ames, http, terminal, database, event processing, â€¦</p>
<p>Is it possible to truly throw away every line of code from the 1970s up until
nowâ€¦ and start from clean slate? Hell yeah. Only, probably not with Nock.</p>
<p>So we have the pivot to â€œoverlay OSâ€ (mentioned on urbit.org), in other words:
<strong>letâ€™s not throw away any lines of code, but instead build on top of them</strong>.
And then access the UI using a conventional browser over http, that will
interpret the React-based javascript (among other things).</p>
<p>So far so good.</p>
<p>Ubitâ€™s core promise:reality â€“ 0:1.</p>
<h2 id="hoon-as-a-language-amazing">Hoon as a language: amazing</h2>
<p>Letâ€™s move on to the Hoon language<sup><a href="#fn4" id="fnref4">4</a></sup>, the workhose of the platform.</p>
<p>Once you start diggin in, you will be constantly met with such <a href="https://github.com/urbit/urbit/blob/master/pkg/arvo/gen/cat.hoon">vomit inducing
beauty</a>:</p>
<pre><code>::  ConCATenate file listings
::
::::  /hoon/cat/gen
  ::
/?    310
/+    pretty-file, show-dir
::
::::
  ::
:-  %say
|=  [^ [arg=(list path)] vane=?(%g %c)]
=-  tang+(flop `tang`(zing -))
%+  turn  arg
|=  pax=path
^-  tang
=+  ark=.^(arch (cat 3 vane %y) pax)
?^  fil.ark
  ?:  =(%sched -:(flop pax))
    [&gt;.^((map @da cord) (cat 3 vane %x) pax)&lt;]~
  [leaf+(spud pax) (pretty-file .^(noun (cat 3 vane %x) pax))]
?-     dir.ark                                          ::  handle ambiguity
    ~
  [rose+[" " `~]^~[leaf+"~" (smyt pax)]]~
::
    [[@t ~] ~ ~]
  $(pax (welp pax /[p.n.dir.ark]))
::
    *
  =-  [palm+[": " ``~]^-]~
  :~  rose+[" " `~]^~[leaf+"*" (smyt pax)]
      `tank`(show-dir vane pax dir.ark)
  ==
==
</code></pre>
<p>that makes Perl the world champion of readable languages by comparison.</p>
<p>Iâ€™m not being entirely fair here, because Iâ€™m sure you can memorize the digraphs
in a few weeks<sup><a href="#fn5" id="fnref5">5</a></sup>, and eventually you get the hang of writing this.
But in the grand scheme of thingsâ€¦ why the heck would you want to?!</p>
<p>It is hard enough to write bug free code in a language that you can find
tens of thousands of top notch coders for (that would give you an honest
code review). Itâ€™s quite another thing doing basic reading of Hoon.</p>
<p>But letâ€™s say Iâ€™m biased, this is the future, and 5 years down the road it
will be the gold standard for personal computing dev<sup><a href="#fn6" id="fnref6">6</a></sup>.</p>
<p>What can you expect in terms of features, then?</p>
<p>Well, since youâ€™re essentially supposed to run on top of Nock, and itâ€™s
all supposed to be strictly deterministic on top of an event stream, my
imagination is failing me as to how itâ€™s going to support some sort of
parallel processing, because you probably donâ€™t want to be stuck humping
one core of your CPU.</p>
<p>Letâ€™s say you try to make it work in parallel using message passing.
Hmm, there goes determinism.</p>
<p>Or shared memory? There goes using â€œNockâ€ (as youâ€™re poking yet another
hole in the substrate).</p>
<p>Iâ€™m sure thereâ€™s a solution, but Iâ€™d bet you a doughnut itâ€™s not going
to be as pure as the marketing.</p>
<p>Hoon:reality â€“ draw (it works, but sigh)</p>
<h2 id="urbit-as-an-os--capable">Urbit as an OS â€“ capable?</h2>
<p>Do you remember how we were supposed to throw away all that code from â€™70s?</p>
<p>So thatâ€™s not happening (as described above).</p>
<p>But at least the OS is a shiny awesome thing capable of real tasks, yes?</p>
<p>Okay.</p>
<p>Given my short exposure to Urbit Iâ€™m sure Iâ€™m missing some dark corners
where clumps of awesome lurk, but if you expect more than a Weather app,
half-assed web forum, simple shared notebooks, and a weird ass terminal,
you will be sorely disappointed.</p>
<p>Again, this will be rectified in the future (of that Iâ€™m actually and
honestly sure).</p>
<p>There are already some third party Hoon implementations of bit torrent,
chat bots, etc.</p>
<p>And thereâ€™s some plans for bitcoin integration, 3rd party apps, etc.</p>
<p>So if the ecosystem takes off, it could be rich and wondrous.</p>
<p>Exceptâ€¦ most of it wonâ€™t be written in Hoon or Nock. Since Urbitians
are hard at work providing language bindings for well known languages.</p>
<p>So what are you gaining by using Urbit that you couldnâ€™t get elsewhere?
No, seriouslyâ€¦ I have yet to figure this one out.</p>
<p>Letâ€™s move onâ€¦</p>
<h2 id="hosted-urbit--only-if-you-want-to-wash-your-dirty-laundry-in-public">Hosted Urbit â€“ only if you want to wash your dirty laundry in public</h2>
<p>Now, letâ€™s think about hosting Urbit for just a moment.</p>
<p>You can run it on your Raspberry (and it will work). You even own your
data that way. <em>(duh? donâ€™t you always, in that case?)</em></p>
<p>But letâ€™s suppose you want to host it elsewhere. I mean, thereâ€™s this
awesome peer-to-peer encrypted protocol in Urbit, so itâ€™s secure, right?</p>
<p>Well, thereâ€™s encryption during transit, and then thereâ€™s encryption at
rest.</p>
<p>And the failboat comes in the latter case.</p>
<p><strong>Nothing in Urbit is encrypted at rest</strong>.</p>
<p>No, seriously, all the chat logs, events, everythingâ€¦ is dumped into
a journal on disk<sup><a href="#fn7" id="fnref7">7</a></sup> in cleartext form.</p>
<p>So, hey, also the whole â€œa vault for secretsâ€ from the marketing video?
Hmmâ€¦ are you going to risk it?</p>
<p>And are you going to risk storing your bitcoin wallet on Urbit,
unencrypted?</p>
<p>In other words, <strong>when hosting urbit at any 3rd party, you better be the
only one with access to the underlying OS</strong> (and have it fully encrypted),
lest you want your entire history worth of data readable by the company
running the instance for you. Or anyone with access to the system.</p>
<p>So, running this on GCP? Digital Ocean? Tlonâ€™s hosting? Only if youâ€™re
comfortable [potentially] washing your dirty laundry in public.</p>
<p>Urbit:real world â€“ 0:1</p>
<h2 id="lets-fail-together-over-the-air">Letâ€™s fail together over the air</h2>
<p>So say you run your Urbit securely on your Pi, you love the platform,
the UI, the whole shebang.</p>
<p>Great.</p>
<p>Nothing to fear then?</p>
<p>Yeah, maybe except the teeny tiny detail that if you want to stay up
to date, you need to configure OTA<sup><a href="#fn8" id="fnref8">8</a></sup>.</p>
<p>So you will be receiving updates to your Urbit instance from one of your
neighbors (one that you configure).</p>
<p>And you talk to your neighbors over an end to end encrypted channel.</p>
<p>Sounds great, since this is 2021, and surely the updates are signed.</p>
<p>Well, no. They are not. The transmission is, though. Big help!</p>
<p>So â€“ I guess it wouldnâ€™t be that hard for one rotten apple somewhere
on higher ranks of the network<sup><a href="#fn9" id="fnref9">9</a></sup> <em>(rogue operator, hacked machine, hacked
core devâ€™s machine)</em> to push a code update that exfiltrates all your data,
possibly including all your secrets (hey, remember the BTC integration)?</p>
<p>And imagine the fun of auditing Hoon for potential security holes in
an update, if you were paranoid. Just the thought is hilarious.</p>
<p>Urbit:security â€“ 0:1</p>
<h2 id="urbit-id--scarcity-creates-value-and-you-pay-a-premium-for-that">Urbit ID â€“ scarcity creates value, and you pay a premium for that</h2>
<p>So I watch in great amazement the booming ecosystem of cryptocurrencies
of different shapes and colors, and of all things blockchain.</p>
<p>Urbit ID is even better than all of them, though.</p>
<p>You see, the entire identity address space is artificially constrained
to 32bit integers<sup><a href="#fn10" id="fnref10">10</a></sup>.</p>
<p>And according to the Urbit promoters and backers, <em>scarcity creates value</em>.</p>
<p>Just like that.</p>
<p>No need for demand or anything. Itâ€™s scarce, hence it has value. Done<sup><a href="#fn11" id="fnref11">11</a></sup>.</p>
<p>The fact that a desperate enough person could do an equivalent of a hard
fork, and run it independently with a different Identity root isâ€¦
impossible?</p>
<p>Whatever.</p>
<p>But anyway, letâ€™s say you â€¦</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wejn.org/2021/02/urbit-good-bad-insane/">https://wejn.org/2021/02/urbit-good-bad-insane/</a></em></p>]]>
            </description>
            <link>https://wejn.org/2021/02/urbit-good-bad-insane/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26177720</guid>
            <pubDate>Thu, 18 Feb 2021 09:22:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reflections on Using Haskell for My Startup]]>
            </title>
            <description>
<![CDATA[
Score 124 | Comments 98 (<a href="https://news.ycombinator.com/item?id=26176940">thread link</a>) | @_query
<br/>
February 17, 2021 | https://alistairb.dev/reflections-on-haskell-for-startup/ | <a href="https://web.archive.org/web/*/https://alistairb.dev/reflections-on-haskell-for-startup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Almost exactly one year ago I quit my job to create a Haskell startup as a solo developer. I had about 20 ideas, but eventually settled on the idea of dependency project health tracking with <a href="https://deadpendency.com/" target="_blank" rel="noopener">Deadpendency</a>.</p>

<p>This post describes the experience and evaluates Haskell and its ecosystem.</p>

<p><small>Disclaimer: This blog post contains a bunch of memes. They are trying to be humorous, not accurate or fair ğŸ˜‰.</small></p>

<h2 id="why-haskell">Why Haskell?</h2>

<p>Since about 2016 I have had a strong <del>obsession</del> love of Haskell. Prior to learning Haskell, I was an experienced OO style developer but I didnâ€™t really know how to keep improving my raw programming ability. Haskell introduced me to the world of functional programming (FP) which has an almost infinite depth of concepts to learn, which do actually help improve code quality and application architecture.</p>

<p><img width="400" src="https://i.imgflip.com/4x9eeq.jpg" alt="I should learn functional programming meme"></p>

<p>Haskell is challenging to learn, but extremely fun to write. For my own learning and pleasure, if my startup succeeds, I want to be doing Haskell.</p>

<p>Additionally, I think Haskell is the best general purpose programming language (that you can use in production). In particular, Haskell excels at writing â€˜boringâ€™ business applications which is typically what I work on. <a href="https://www.foxhound.systems/blog/why-haskell-for-production/" target="_blank" rel="noopener">â€˜Why Haskell For Productionâ€™</a> goes into more detail on the benefits Haskell offers.</p>

<p><img width="400" src="https://i.imgflip.com/4x9fwz.jpg" alt="Haskell is the best change my mind meme"></p>

<h2 id="the-setup-phase">The Setup Phase</h2>

<p>Probably the most challenging part was building out a skeleton architecture to hang my business logic on. I decided to go with, even within Haskell, fairly advanced libraries of <a href="https://docs.servant.dev/en/stable/" target="_blank" rel="noopener"><code>servant</code></a> and <a href="https://hackage.haskell.org/package/fused-effects" target="_blank" rel="noopener"><code>fused-effects</code></a>.</p>

<p>I spent a fair amount of time banging my head against a wall trying to get these libraries to work nicely together. This was primarily from a lack of Haskell ability on my part. I had prepared as best I could, but Haskell is deep and I needed to learn more to work day to day with it. I was lucky enough to eventually find <a href="https://github.com/mitchellwrosen/hspolls" target="_blank" rel="noopener">an example</a> that marries these two libraries together, which was a life saver. Iâ€™m sure I would have gotten there eventually, but I was in a bit over my head at that point.</p>

<p><img width="400" src="https://i.imgflip.com/4x9j14.jpg" alt="Haskell with servant fused-effects is hard meme"></p>

<p>Haskell is awesome, but like most languages there is cruft and legacy to be avoided. Haskell has a standard library known as <a href="https://hackage.haskell.org/package/base" target="_blank" rel="noopener"><code>base</code></a> which unfortunately has a fair amount of unsafe or unperformant functions included. As such I went with an alternative standard library <a href="https://hackage.haskell.org/package/relude" target="_blank" rel="noopener"><code>relude</code></a> that builds on and improves <code>base</code>. On top of this, there are many core libraries that are not part of the standard library I wanted to use and have nice patterns around.</p>

<p>Additionally, I was <a href="https://alistairb.dev/haskell-on-google-cloud-is-great">deploying to google cloud</a> and so needed to figure out good patterns for that integration from Haskell.</p>

<p>This setup effort was quite challenging. I spent most of it squinting at compiler errors. Yet it only took about 2 weeks to have a good foundation of code to start building my business logic upon.</p>

<h2 id="building-it-out">Building it Out</h2>

<p>This is when it started to get really fun. I had my core patterns set out and I could focus on building a pipeline. The day in day out of writing out my logic as small pure functions that I composed together was very nice.</p>

<p>Haskell has such impressive auto-magic code generation techniques that you spend much more time focused on the interesting logic of your application rather than boilerplate.</p>

<div><div><pre><code><span>data</span> <span>HappinessLevel</span> <span>=</span>
    <span>Miserable</span>
  <span>|</span> <span>Sad</span>
  <span>|</span> <span>Average</span>
  <span>|</span> <span>Happy</span>
  <span>|</span> <span>HaskellDeveloper</span>
  <span>deriving</span> <span>(</span><span>Show</span><span>,</span> <span>Eq</span><span>,</span> <span>Ord</span><span>,</span> <span>Bounded</span><span>,</span> <span>Enum</span><span>,</span> <span>ToJSON</span><span>,</span> <span>FromJSON</span><span>)</span> <span>-- magic code generation</span>

<span>-- ok not really magic, think 'convention over configuration'</span>
<span>-- where you can have generated sane defaults, or customise if you like</span>
</code></pre></div></div>

<p>And personally I think Haskell is quite beautiful to read and write. #notbiased</p>

<h3 id="parsing-libraries">Parsing Libraries</h3>

<p>A lot of the logic of Deadpendency is parsing. Either parsing dependency files or parsing various API responses. Haskell has many excellent parsing libraries, most notably <a href="https://hackage.haskell.org/package/aeson" target="_blank" rel="noopener"><code>aeson</code></a> for JSON.</p>

<p>Why is this nice in Haskell? The â€˜monadâ€™ abstraction is excellent for dealing with code with a lot of failure conditions (ie. parsing) and avoids â€˜pyramid of doomâ€™ type code. Haskell worked out really well in this key area.</p>

<p><img width="400" src="https://alistairb.dev/images/hadouken.jpeg" alt="Pyramid of doom meme"></p>

<h3 id="testing">Testing</h3>

<p>Another strong positive for writing Deadpendency was testing. Haskell has a lesser-known style of testing libraries that do â€˜property based testingâ€™ (PBT).</p>

<p>PBT allows you to write value generators for your data types, which you use to generate 100s or 1000s of test cases. Then, you run these generated values against some function and check that certain properties hold.</p>

<p>For example, part of the Deadpendency logic is generating an HTML report at the end. I had some <code>toHtml :: Report -&gt; HTML</code> function that I wanted to test. So I wrote a <code>fromHtml :: HTML -&gt; Report</code> function where it goes the other way (ok writing that was pretty painful). Then my PBT test will generate 100s of <code>Report</code> values and check that <code>report == fromHtml (toHtml report)</code> (this is known as â€˜roundtrip testingâ€™). With this single test I was able to find many edge case bugs with my HTML report generation logic.</p>

<p><img width="400" src="https://i.imgflip.com/4x9tqj.jpg" alt="Haskell with servant fused-effects is hard meme"></p>

<p>PBT exists in some other languages, but it originated (I believe?) in Haskell so the libraries are excellent.</p>

<h3 id="not-actively-maintained-libraries">Not Actively Maintained Libraries</h3>

<p>A big challenge of working with Haskell was the lack of well-maintained libraries. Ironically, of the 75 (!) packages I depend upon 19 are flagged by Deadpendency as unhealthy (deprecated or inactive). This means I often donâ€™t have the luxury of asking library maintainers to fix bugs. Even if I PR a fix, sometimes that PR will be ignored for months.</p>

<p>This I think is the reality of using a niche language like Haskell. To be clear, I do not think library developers owe me anything, but it is nonetheless a downside when compared to more popular languages.</p>

<p><img width="400" src="https://i.imgflip.com/4x9xjq.jpg" alt="Haskell not actively maintained meme"></p>

<p>Thankfully Haskell build tools have good support for loading a package from git. This means you can PR some bug fix or feature and immediately use your fork to work around the problem.</p>

<h3 id="compile-times-were-fine">Compile Times.. Were Fine</h3>

<p>I thought Iâ€™d call this out as it is a common complaint I see around Haskell. I followed some <a href="https://www.parsonsmatt.org/2019/11/27/keeping_compilation_fast.html" target="_blank" rel="noopener">good advice</a> which kept compilation fast (aside from <a href="https://twitter.com/AlistairBuzz/status/1253507016242294784" target="_blank" rel="noopener">one interesting edge case I resolved</a>).</p>

<ul>
  <li>Number of modules (Haskell source files) - 509</li>
  <li>Number of lines of Haskell - 20090</li>
  <li>Number of dependencies - 75</li>
  <li>Dell 9570 XPS Laptop - (Hex core - 8th-gen Intel Core i7-8750H CPU), 32GB memory</li>
</ul>

<p>So what are the numbers?</p>

<h4 id="compile-dependencies-from-scratch">Compile dependencies from scratch</h4>

<p>Time: 17m44s</p>

<p>This is compiling all application dependencies, which needs to be done before you can compile your application code. Rebuilding all from scratch rarely happens as both my dev machines and CI will cache and only rebuild what has changed.</p>

<p>You do sometimes update a very core package which triggers a lot of dependent packages to recompile which can take a while. Although, I usually do dependency updates at the start of the day while Iâ€™m sipping my coffee, so usually donâ€™t notice.</p>

<h4 id="compile-app-including-tests-in-development">Compile app (including tests) in development</h4>

<p>Time: 1m1s</p>

<p>Likewise, due to caching a full recompilation rarely happens. As such, most code edits do not trigger many modules to be recompiled and it is fast.</p>

<p>Additionally, Haskell has nice â€˜continuous compilationâ€™ tools that fire on save. Usually by the time I actually look at my terminal compilation is already done.</p>

<h4 id="compile-app-for-deployment">Compile app for deployment</h4>

<p>with <a href="https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/using-optimisation.html" target="_blank" rel="noopener">full optimisations</a> (-02).</p>

<p>Time: 2m53s</p>

<p>This typically runs in CI. It runs in parallel with a host of other checks such as running my tests, which also take a few minutes. Due to this, the time doesnâ€™t really impact the build + deploy time too much.</p>

<p><img width="400" src="https://i.imgflip.com/4xp4zu.jpg" alt="Compile times meme"></p>

<h3 id="refactoring-pain">Refactoring Pain</h3>

<p>Deadpendency is relatively simple in what it does, but there is a lot of hidden complexity to the problem. Which is to say, it is like 99% of applications ğŸ˜‰. When developing it I was constantly realising I had modelled things a bit too simplistically and would need to refactor.</p>

<p>Haskell is very safe to refactor thanks to the type safety the compiler brings, which is probably the most important thing. However, Haskell does not have great tools to help with refactoring, at least in terms of the restructuring changes I kept making. The <a href="https://hackage.haskell.org/package/apply-refact" target="_blank" rel="noopener">existing</a> <a href="https://hackage.haskell.org/package/retrie" target="_blank" rel="noopener">tools</a> seem more geared towards complex rewriting of common code, not restructuring modules or renaming identifiers.</p>

<p>As such I did it all manually with text search replace, or just change something and fix all the new compiler errors. This was a bit of a grind and it caused me to delay needed refactoring sometimes.</p>

<p>Itâ€™s a pity Haskell doesnâ€™t have the refactoring tools to help in this situation. The dream would be these tools integrated into an IDE.</p>

<p><img width="400" src="https://i.redd.it/dbdshzzflgd31.jpg" alt="Haskell had an IDE meme"></p>

<p>(Stolen from <a href="https://www.reddit.com/r/ProgrammerHumor/comments/cjtbfj/society_if_haskell_has_ide/" target="_blank" rel="noopener">reddit</a>)</p>

<p>Having said that, it should be noted that Haskell does have an excellent IDE now in the form of <a href="https://github.com/haskell/haskell-language-server" target="_blank" rel="noopener">Haskell Language Server</a> (HLS). The momentum around the project is insane and I applaud the developers. One fixed pain point from HLS is it does auto imports now, which used to greatly contribute to the friction of working with Haskell. Iâ€™m sure Haskell will get there eventually.</p>

<h3 id="waiting-for-new-ghc-versions-to-be-usable">Waiting for New GHC Versions to be Usable</h3>

<p>This is mostly me complaining for the sake of it, but as someone pretty obsessed with both new shiny versions of things and Haskell, waiting for new GHC (GHC is the Haskell compiler) versions to be usable has been painful. There is a long tail of libraries and platforms that need to be updated before I can use a new GHC version. Sometimes these updates can drag a lot.</p>

<p>For example GHC 9 was just released, but I still havenâ€™t been able to upgrade to GHC 8.10 yet which was first released in March 2020.</p>

<p><img width="500" src="https://i.imgflip.com/4xebid.jpg" alt="GHC releases meme"></p>

<h2 id="launching">Launching</h2>

<p>So after about 8 months of work I was ready to start getting users. I slowly soft launched, promoting it in a few small channels. How did my Haskell fair in prod?</p>

<h3 id="very-few-logic-bugs">Very Few Logic Bugs</h3>

<p>My core Haskell had very few logic bugs. This is because Haskell is very safe by default and I had opted into strict types that help catch edge cases.</p>

<p>For example, I was using a lot of <a href="https://hackage.haskell.org/package/base-4.14.1.0/docs/Data-List-NonEmpty.html" target="_blank" rel="noopener"><code>NonEmpty</code></a> lists which the compiler will guarantee is not empty. To use them you must specify how to handle the empty case. ie. what do I do if Deadpendency canâ€™t find any dependencies to check?</p>

<p>And of course, I had â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://alistairb.dev/reflections-on-haskell-for-startup/">https://alistairb.dev/reflections-on-haskell-for-startup/</a></em></p>]]>
            </description>
            <link>https://alistairb.dev/reflections-on-haskell-for-startup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26176940</guid>
            <pubDate>Thu, 18 Feb 2021 07:17:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Americentrism]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26176606">thread link</a>) | @jlelse
<br/>
February 17, 2021 | https://jlelse.blog/thoughts/2021/02/americentrism | <a href="https://web.archive.org/web/*/https://jlelse.blog/thoughts/2021/02/americentrism">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Wikipedia has an article on a phenomenon I often observe on the Internet, such as on Hacker News: <a href="https://en.wikipedia.org/wiki/List_of_countries_in_the_Americas_by_population" target="_blank" rel="noopener">Americentrism</a>.</p><blockquote><p><strong>Americentrism</strong>, also known as <em>American-centrism</em> or <em>US-centrism</em>, is a tendency to assume the culture of the United States is more important than those of other countries or to judge foreign cultures based on American cultural standards. It refers to the practice of viewing the world from an overly US-focused perspective, with an implied belief, either consciously or subconsciously, in the preeminence of American culture.</p></blockquote><p>But even that word in itself, I think (as an European), contains U.S. bias: America is equated with the USA, but there are <a href="https://en.wikipedia.org/wiki/List_of_countries_in_the_Americas_by_population" target="_blank" rel="noopener">so many more countries in America</a>.</p><p>Is it just me who thinks like that?</p></div></div>]]>
            </description>
            <link>https://jlelse.blog/thoughts/2021/02/americentrism</link>
            <guid isPermaLink="false">hacker-news-small-sites-26176606</guid>
            <pubDate>Thu, 18 Feb 2021 06:22:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TLS certificates specifying hosts via the CommonName field is more or less gone]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 22 (<a href="https://news.ycombinator.com/item?id=26176448">thread link</a>) | @zdw
<br/>
February 17, 2021 | https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificateCNMostlyGone | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificateCNMostlyGone">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>TLS certificates specifying hosts via their CommonName field is more or less gone</h2>

	<p><small>February 17, 2021</small></p>
</div><div><p><a href="https://en.wikipedia.org/wiki/Transport_Layer_Security">TLS</a>
certificates for hosts and domains must somehow identify what
hostname (or names) they're for. Historically <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificatesNamingHosts">there have been two
ways to do this</a>. The first way was a
specific sub-field, the <em>CN</em> or CommonName, of the certificate's
overall <em>Subject Name</em>. This had the problem that it could only
have one name. When people started wanting to have TLS certificates
that covered more than one name, they invented another mechanism,
the <em>Subject Alternative Name</em> (SAN) extension.</p>

<p>As a practical matter, all vaguely modern software that wants to
properly validate TLS certificates has supported (and often preferred)
Subject Alternative Names for some time. A great many TLS certificates
in the wild are for multiple hosts and it's generally unlikely that the
host you're connecting to is the one name that the system chose to put
in the CN field; software that only supports CN cannot validate those
TLS certificates. As a matter of timing, SANs have been theoretically
mandatory since 2002 and checking only SANs has been theoretically
required since 2011 (which means that since 2011 or earlier, the CN was
supposed to always be one of the SANs).</p>

<p>These days, any remaining support for looking at TLS certificate
CommonName to validate TLS certificates is getting more and more
extinct (and more so than I expected when I started writing this
entry). In the browser realm, <a href="https://www.chromestatus.com/feature/4981025180483584">Chrome apparently turned it off in
58, released in 2017</a>, and then
threw out the option to check it again in Chrome 65 (from the comment
on <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificatesNamingHosts">my old entry</a>, which was ironically
written shortly before Chrome did this). Firefox is said to have
removed support in version 48, from August of 2016. <a href="https://support.apple.com/en-ca/HT210176">Safari
apparently stopped looking at CommonName in iOS 13 and macOS 10.15</a>, which I believe date
from late 2019. <a href="https://go-review.googlesource.com/c/go/+/231379">This Go change</a> also talks about
how browsers removed it in 2019 ('last year' for a mid 2020 change).</p>

<p>In non-browser TLS code, Go started ignoring CN by default in
Go 1.15 (released in August of 2020) and this will be the only
option starting in Go 1.17 (to be released in August of 2021),
per <a href="https://golang.org/doc/go1.16#crypto/x509">here</a>. Since
Firefox doesn't support CN any more, I assume that <a href="https://en.wikipedia.org/wiki/Network_Security_Services">NSS</a> doesn't
either, since NSS is basically Firefox's underlying TLS implementation.
I have no idea what other TLS libraries are doing, but I would expect
that many of them will support CommonName for some time to come; TLS
libraries are historically behind browser practices.  Hopefully they
are all following the 2011 requirement to check only SANs when SANs are
present (which they should always be in public certificates).</p>

<p>Probably TLS certificates will continue to contain CommonName fields
for a long time to come. Having a <em>Subject Name</em> in general is
common (although apparently not actually required) and the CN is a
standard (although not required) part of the Subject Name, so you
might as well throw it in. Even Mozilla and Let's Encrypt (still)
have TLS certificates with CNs. However, since I checked this now,
the current <a href="https://cabforum.org/">CA/Browser Forum</a> <a href="https://cabforum.org/baseline-requirements-documents/">baseline
requirements</a>
(version 1.7.3) allow but don't require CommonName (section 7.1.4.2.2,
which says that it's 'discouraged, but not prohibited'). Given how
conservative most Certificate Authorities are, I expect them to be
issuing TLS certificates with CommonName fields until they're
required to stop.</p>

<p>(An interested party could scan Certificate Transparency logs to see if
there were very many issued certificates without CNs. Probably there are
some; someone must have tried it out at some point through an official
CA.)</p>

<p>PS: <a href="https://no-common-name.badssl.com/">no-common-name.badssl.com</a>
has a TLS certificate without a CN, or at least it's supposed to
(<a href="https://community.letsencrypt.org/t/how-to-obtain-a-cert-without-a-common-name/72807/6">via</a>),
but the TLS certificate is expired right now as I write this entry
so it's hard to test how client software behaves. <a href="https://community.letsencrypt.org/t/compatibility-testing-of-no-common-name/72863">See also</a>,
which pointed me to <a href="https://no-subject.labs.vu.nl/">no-subject.labs.vu.nl</a>,
which has a currently valid TLS certificate with no <em>Subject Name</em> at all.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificateCNMostlyGone</link>
            <guid isPermaLink="false">hacker-news-small-sites-26176448</guid>
            <pubDate>Thu, 18 Feb 2021 05:54:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The questionable use of AI for job applications]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26175871">thread link</a>) | @shirappu
<br/>
February 17, 2021 | https://web.br.de/interaktiv/ki-bewerbung/en/ | <a href="https://web.archive.org/web/*/https://web.br.de/interaktiv/ki-bewerbung/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://web.br.de/interaktiv/ki-bewerbung/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26175871</guid>
            <pubDate>Thu, 18 Feb 2021 04:38:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Extract Tables by Docsumo]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26175273">thread link</a>) | @amitness
<br/>
February 17, 2021 | https://docsumo.com/free-tools/extract-tables-from-pdf-images | <a href="https://web.archive.org/web/*/https://docsumo.com/free-tools/extract-tables-from-pdf-images">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-tool"><div><div><p>Automated table extraction from pdf &amp; images</p><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>It doesn't support in mobile view. <br>You can copy the link and view it in your desktop.</p></div><div id="rating-section"><div id="rating-block"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div></div></div></div></div><div><p>How it works?</p><div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5faa7831743ca77a6aa3ee11_Choose%20File.png" loading="lazy" width="93" alt=""></p><div><p>1. Choose File</p><p>Select or drop the files you want to convert.<br></p></div></div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5faa628aeb96926ffa789a4f_edit%20%20and%20review.png" loading="lazy" width="101" alt=""></p><div><p>2. Edit &amp; Review</p><p>Review the extracted information in the review panel and make changes if needed.</p></div></div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5faa629ae8714b4bf57f0719_Convert%20%26%20Download.png" loading="lazy" width="101" alt=""></p><div><p>3. Convert &amp; Download</p><p>Download the converted file. Right after that, the input file is removed from our server.</p></div></div></div></div><div><p>Extract tables from PDF/Images</p><p>Save your crucial time and prevent any error from occurring with Docsumo's free table extraction from a PDF/Image tool. With this tool, extract tables from PDF documents and images in real-time with 100% accuracy.</p></div><div><p>Questions we often hear</p><p>Let's look at the answers</p><div><div role="list"><div role="listitem"><div><div><div><h4>Why do I need to extract tables from a PDF document?</h4></div><p>Tables are cleaner data format, and often you need only the data from tables embedded in a pdf document. That's why, businesses find it useful to extract tables from pdf documents and process the data.</p></div></div></div><div role="listitem"><div><div><div><h4>Do I need to train this free table extractor from pdf tool?</h4></div><p>The efficiency of Artificial Intelligence and Machine Learning technology improves with number of sample documents processed. So, it is highly recommended to have at least couple of sample documents ready for training.</p></div></div></div><div role="listitem"><div><div><div><h4>What fields does it capture?</h4></div><p>The tool lets you capture any text based field. The tool allows you to review the extracted data before downloading the output.</p></div></div></div><div role="listitem"><div><div><div><h4>Can I convert my document without installing the software?</h4></div><p>Documo's free online OCR tool is capable of processing any document online with complete accuracy. So, there is no need to install the tool on your system.</p></div></div></div><div role="listitem"><div><div><div><h4>Is my data secure with Docsumo?</h4></div><p>Docsumo doesn't sell or share your data to any third-party person or organization. Your data is completely secure and confidential.</p></div></div></div><div role="listitem"><div><div><div><h4>Is there any limit on using the tool?</h4></div><p>There's no usage limit on our free tool. No payment required and no credit card details needed. Sign up with us to get access to more of our resources.</p></div></div></div></div></div></div><div><h2>What Our Customers Are Saying</h2><div><div data-animation="slide" data-nav-spacing="4" data-duration="500" data-infinite="1"><div><div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5f61bd1ba58812799fe2bd13_paysense.svg" loading="lazy" height="" alt=""></p><p>â€œWe are using Docsumoâ€™s APIs for automating data capture from bank statements and identity cards while on-boarding customers. It has reduced the time our operations team spends on data entry by manifolds while providing a much better customer experience.â€</p><p>Prashanth Ranganathan</p><p>CEO, Paysense.com</p></div></div><div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5f61bd1b531b085edc6c1cbf_Onez.jpeg" loading="lazy" height="" width="25" alt=""></p><p>Since the very beginning everything was fine, they always say â€œAsk anything even if you need support from our developers. The support for initial user was exceptional, even for small users like me.</p><div><p>Dario G</p><p>Operations Manager, Onerz</p></div></div></div><div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5f61bd1bf817cf304f90e758_dhanwise.svg" loading="lazy" height="" alt=""></p><p>"With Docsumo we were able to automate invoice processing completely. It has reduced invoice processing time from hours to minutes. Since there is no data entry required, our data extraction accuracy has improved. We highly recommend Docsumo to everyone. "</p><p>Subodh Malgonde</p><p>CEO, DhanWise.com</p></div></div></div></div></div><a href="https://docsumo.com/case-studies"><p>View more Customers Stories</p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5f62f7ab382b1fa34db4108a_arrow.svg" loading="lazy" height="" alt=""></a></div><div id="free-trial-form"><div><div><div><h2>Start your free trial</h2><p>Weâ€™d love to show you how you can increase your productivity, process your documents faster and save operations cost!</p></div></div><div><div><div id="formId"><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://docsumo.com/free-tools/extract-tables-from-pdf-images</link>
            <guid isPermaLink="false">hacker-news-small-sites-26175273</guid>
            <pubDate>Thu, 18 Feb 2021 03:29:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[40 Year History of Opposition to Nuclear Power in California]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 40 (<a href="https://news.ycombinator.com/item?id=26175253">thread link</a>) | @Lammy
<br/>
February 17, 2021 | https://www.energy-net.org/01NUKE/CALIF.HTM | <a href="https://web.archive.org/web/*/https://www.energy-net.org/01NUKE/CALIF.HTM">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="49%"> 
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2" color="#CC6600"><b><span size="3" color="#000000">40 
		Year History of Opposition to Nuclear Power in California </span></b></span> 
		<br>
	  </p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">California 
		citizens have made a unique stand concerning the attempts by Nuclear proponents 
		to make the state a premiere model for commercial nuclear energy. California's major 
		utilities, in particular Pacific Gas and Electric (PG&amp;E) has spent an
		enormous amount of money and political muscle in attempts to build reactors 
		across California but have mostly failed. PG&amp;E was supposedly involved in 
		the Atoms for Peace proposal made in 1953 and was 
		part of a coalition of american utilities that investigated the technical 
		potentials for building nuclear reactors as a source of electricity.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The following 
		is a brief summary of the battles against nuclear power that started here 
		in California in 1958.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Northern 
		California is the home of the first successful opposition to the promotion 
		and development of commercial nuclear reactors in the U.S. In the 1950's 
		northern and central California's privately Owned utility company, PG&amp;E 
		was planning to be one of the giants in the new field of nuclear energy. 
		It had helped design and build the Dresden I reactor in Illinois with 
		a consortium of 5 major companies, including General Electric(GE).</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">In conjunction 
		with GE, it built the vallecitos nuclear complex south of San Francisco 
		and then went it alone with their Humboldt reactor near Arcata. But their 
		luck took a turn for the worse when they tried to build the world's largest 
		nuclear facility 1000 feet from the fault that caused the 1906 earthquake.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Yes, PG&amp;E 
		even said they could build a reactor in downtown San Francisco! In 
		fact they were planning the construction of 63 reactors in California 
		during the early 1960's, one every 25 miles along the coast They even 
		 planned to build a floating reactor!!</span></p>
	  <h2><span face="Verdana, Arial, Helvetica, sans-serif" size="2"><b>The 
		Bodega Bay Duck Pond</b><br>
		</span></h2>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">When PG&amp;E 
		started pushing plans to build the reactors at Bodega Pay in 1958 a literal 
		groundswell of opposition erupted during the next 6 years to stop them 
		dead cold. The site they had chosen near the San Andreas Fault Zone was 
		just a few miles from the epicenter of the Great San Francisco Quake where 
		ground shifts of over 20 feet had occurred in 1906.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">PG&amp;E's 
		unethical plans to build the reactor is not new for this company, as they 
		have a history of unfair tactics that goes back to the company's birth. 
		Upon deciding that the Bodega Headlands would be an excellent site for the largest nuclear 
		facility in the world, PG&amp;E simply beat the state out in its plans 
		to make the area a state park. </span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The battle 
		started in 1958 when the Santa Rosa Press Democrat published the first 
		story on PG&amp;E's plans. The company's ignored their own geologist, who had warned 
		that the area was likely to be effected by strong shaking during a quake. 
		Concerned citizens started getting involved as PG&amp;E refused to acknowledge 
		publicly that they were actually going to build nuclear reactors at the 
		proposed site.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The 1957 
		windscale accident in England, where a small reactor had burned out of 
		control for more than a day, helped focus concerns about safety on this 
		new idea of nuclear power.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">In 1961, 
		after nearly 3 years of pushing their plan behind the scenes, PG&amp;E 
		announced plans to build the Atomic Park at the Bodega site. The ensuing battle 
		and PG&amp;E's nasty style started to backfire though as public concerns 
		grew.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Major opposition 
		came from within the ranks of the Sierra Club, but the board refused to 
		allow its active members the right to oppose the reactors on the issue 
		of earthquakes. When it came out that PG&amp;E had doctored fault maps 
		of the site, all hell broke loose.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">One of PG&amp;E's 
		major claims at the time was that they could build reactors that would 
		survive a great Earthguake. At one point they said that the reactors could 
		survive a quake 50 per cent bigger than the O6' quake by floating the 
		reactors on 3 feet of compressable material but when the public and the 
		Atomic Energy Commission (AEC) got a close-up view of the devastation 
		from the air of the quake in Alaska during the spring of 1964, support 
		for the reactor complex dried up.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Opponents 
		had "infiltrated" the federal government and were pushing 
		for closure. With the disclosure of the AEC's WASH 740 report, which documented 
		potential dangers to the bay area residents in case of an accident, opposition 
		finally reached all government levels.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">California 
		governor Pat Brown asked that PG&amp;E abandon the reactors. Two days 
		later PG&amp;E caved in and called the project off. The battle ended in 
		1964 with a $7 million duck pond as a living monunent to the future. (It 
		is still there today)</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">This experience 
		gave PG&amp;E a deadly lesson on how to overcome public concerns at their 
		next reactor site--Diablo Canyon.</span></p>
	  <h2><span face="Verdana, Arial, Helvetica, sans-serif" size="2"><b>The 
		Diablo Canyon Nightmare:</b><br>
		</span></h2>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The 25 year 
		battle over Diablo Canyon is a classic case of courage in the face of 
		the political power this utility unleashed in its drive to build a major 
		nuclear facility in California.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">PG&amp;E's 
		plans to build a mega facility shifted south to the less populated coastal 
		area near San Luis Obispo. The company purchased the Nipomo Dunes and 
		told environmental leaders that unless an acceptable site was chosen that 
		they would go ahead and build a facility at the popular beach area. The 
		wife of the Sierra Club president was selected to come up with an acceptable 
		site in secrecy with the company. </span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The site 
		chosen, Diablo Canyon, was California's second to last coastal wilderness 
		area, an area that had been proposed as a National Park due to its beauty. 
		Besides being a sacred Chumash burial ground, it was the home of one of 
		a kind 1,000 year old Oak trees (the largest in the world). It was also 
		the home of one of the state's largest populations of abalone and sea 
		otters.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">In the process 
		of getting permission to go ahead with Diablo, PG&amp;E suceeded in selling 
		the site to key members of the Sierra Club's board of directors. The Utility 
		had sympathetic board members flown over the Diablo site in Frank Sinatra's 
		Lear jet, with entertainment by Danny Kaye (Danny later came out against 
		the reactors).</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The first 
		slam-dunk by PG&amp;E came against the local farmer who had the right 
		of way access rights over the Diablo property. The company went to court 
		and had his rights removed. The beligerant act made the man a life-long 
		opponent of PG&amp;E's plan.</span></p>
	  <h2><span face="Verdana, Arial, Helvetica, sans-serif" size="2"><b>PG&amp;E 
		gets Cozy with Sierra Club Board Members</b><br>
		</span></h2>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The biggest 
		tactical plan was to focus on the Sierra Club. The company and the electric 
		industry already had the board's ear with their claims that nuclear power 
		could reduce air pollution that was caused by coal power plants. The utility, 
		with inside help then sought official support for Diablo Canyon when club's 
		only board member who knew about the site's natural value was in Europe. 
		The board went along with PG&amp;E, and in fact voted to block any Club 
		members or chapters opposition to the facility. This move enraged David 
		Brower, eventually resulting in the split up of the club and the creation 
		of Friends of the Earth by embittered Sierra Club members who were angered 
		by the actions of key Sierra Club Board members.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">PG&amp;E's 
		success within the Sierra Club was the culmination of 2 years of behind 
		the scenes work by Doris Leonard. She was the wife of the president of 
		the club. Her role in exchanging the Nipomo Dunes site for Diablo Canyon 
		was rewarded later when she was elected to PG&amp;E's board of directors. 
		</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The Sierra 
		Club refused to allow its local chapter near Diablo to use the club nane 
		in opposing the five proposed reactors at the site. The group was forced 
		to take on another name in 1966, the Shoreline Preservation Conference.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The group 
		was concerned about earthquake faults along the coast as locals were fully 
		aware of the 1927 quake that completely destroyed a nearby city. They 
		called for a full investigation into potential fault areas. Their efforts 
		were ignored by the government and the media.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">News of the 
		reactor siting was poorly covered by the Bay area's conservative media, 
		a tactic that made the issue invisible to bay area residents who had stopped 
		PG&amp;E's Bodega reactor plans.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Oil companies 
		chart the Hosgri Fault The Hosgri fault had been mapped by Shell oil geologists 
		during the 1960's, but not published until 1970. PG&amp;E claims to have 
		not found out about the fault until late 1972. The information was finally 
		publicized in November 1973 by an investigative reporter in Los Angeles. 
		In a suspicious turn of events, the lawyer who had been fighting the case 
		since 1965 was found dead in his car just after the announcement. Authorities 
		claimed it was suicide, with no other investigation to follow up.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">P&amp;GE's 
		bad memories of Bodega Bay helped fuel their push to ignore earthquake 
		concerns at Diabl Canyon. The same Seismic experts who had been involved 
		with the Bodega Bay facility were brought in to review the site for seismicity. 
		They pointed out major flaws in PG&amp;E's own $2,000 seismic study. A 
		state of the art study at the time would have cost $100,000)</span></p>
	  <h2><span face="Verdana, Arial, Helvetica, sans-serif" size="2"><b>The 
		Hosgri Fault Forces PG&amp;E to Rebuild Diablo Again</b><br>
		</span></h2>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">A storm of 
		controversy erupted around the facility as one of the units was reaching 
		completion. Even with the help of the Nuclear Regulatory Commission's 
		(NRC) predecessor, the AEC, PG&amp;E was finally forced after 3 years 
		of federal in-fighting to rebuild seismic bracing in 1976.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">In attempts 
		to stop a seismic retrofit, PG&amp;E even coined the Tao Effect which 
		said that the bigger the structure, the less damage a quake would have.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Seismic experts 
		for the concerned activists remained uninpressed, â€¦</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.energy-net.org/01NUKE/CALIF.HTM">https://www.energy-net.org/01NUKE/CALIF.HTM</a></em></p>]]>
            </description>
            <link>https://www.energy-net.org/01NUKE/CALIF.HTM</link>
            <guid isPermaLink="false">hacker-news-small-sites-26175253</guid>
            <pubDate>Thu, 18 Feb 2021 03:28:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building products â€“ Things I wish I knew when I started building products]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26173963">thread link</a>) | @gmays
<br/>
February 17, 2021 | https://amiltonpaglia.com/writing/building-products | <a href="https://web.archive.org/web/*/https://amiltonpaglia.com/writing/building-products">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><main><header></header><div><p>Nov 7, 2020, 21:00<!-- --> <svg width="16" height="16" style="position:relative;top:2px"><line x1="4" y1="16" x2="12" y2="2" style="stroke:#ccc"></line></svg> <time datetime="1604782800000">3 months ago</time></p></div><p>It's not a step by step guide but rather an attempt to synthesize my thinking about what it really matters to build great products.</p><p>I've been building products for the last 12 years. On this journey, I have been fortunate to have the opportunity to wear a lot of different hats in the making of a digital product.&nbsp;</p><p>I've worked as Interface designer, Front-end developer, UX Designer, Product Designer and lastly, as a Product Manager. All along the way, I've always had a close relationship with engineers, learning everything I could about development and understanding all the effort and creativity necessary to bring products to life.</p><p>To keep this valuable for a wider audience and range of professionals, I've tried to extract the essence of I believe to be essential to keep in mind when building products.</p><p>Loading...</p><h2>Purpose</h2><p><strong>Everything starts with a clear purpose.</strong></p><p>When building products, you have to be an<!-- --> <strong>eternal optimist about your missionâ€Š</strong> â€“ â€Što help you get through the rough times, and<!-- --> <strong>very pessimist about executionâ€Š</strong> â€“ â€Šit always takes way more time and effort to nail it.</p><p><strong>Build great products takes time; it's a long-term commitment.</strong> <!-- -->It's almost impossible (in my experience) to immerse yourself in a work whose purpose isn't aligned with your beliefs.</p><p>Without a clear purpose for you (and your team), it's tough to find an intrinsic motivation to keep iterating your product on a problem space.</p><p>Loading...</p><h2>Constraints</h2><blockquote>"...Here is one of the few effective keys to the Design problem: the ability of the Designer to recognize as many of the constraints as possible; his willingness and enthusiasm for working within these constraints. Constraints of price, of size, of strength, of balance, of surface, of time, and so forth. Each problem has its own peculiar list."<p>Charles &amp; Ray Eames</p></blockquote><p>I love this excerpt from an<!-- --> <a href="https://www.hermanmiller.com/stories/why-magazine/design-q-and-a-charles-and-ray-eames/">interview with Charles and Ray Eames</a> <!-- -->in 1972 about Design. This quote stayed on my mind since the first time I've read it.</p><p><strong>Embracing constraints is essential to creativity.</strong> The primary fuel to your problem-solving is to identify what restrictions you're dealing with.</p><p>Your purpose is what drives your "willingness and enthusiasm for working within these constraints." Once you have a clear purpose and goal in mind, you have to "identify as many constraints as possible" to have a clear problem space to tackle, and sometimes you need to enforce additional constraints.</p><p>I like to think about constraints in two spectrums:</p><ul><li>From <strong>hard constraints</strong> to<!-- --> <strong>self-imposed constraints</strong>;</li><li>From <strong>under constraint</strong> to<!-- --> <strong>over constraint</strong>;</li></ul><h3>Hard &amp; Self-imposed constraints</h3><p><strong>Hard constraints</strong> are the ones that you have little to no influence under it. It's time, resources, team, skills, funding, knowledge, market conditions, laws, available technology, and so on. It's the constraints that you'll have to work within, no matter what.</p><p><strong>Self-imposed constraints</strong> are the ones you set to have a clear problem space and increase your focus. It could come in different shapes. It could be your values, product principles, strategy, and everything else you and your team agree on that helps you stay on the right path. It's your conscious trade-offs.</p><h3>Under &amp; Over Constraints</h3><p><strong>An under constrained problem space will be too broad and challenging to narrow down what really matters.</strong> <!-- -->You'll see yourself drowned in the endless possibilities to solve problems. When you find yourself in this scenario, it's better to enforce new constraints and make trade-offs to eliminate noise.</p><p>On the other hand,<!-- --> <strong>when you over constrain it, you won't leave room for improvisation, innovation, and adaption when it's needed.</strong> <!-- -->You have to find a sweet spot on this spectrum to have the freedom to experiment.</p><p><strong>Identifying the right constraints and balancing them is an ongoing challenge.</strong> <!-- -->Your team will grow, new technologies will enable new solutions, markets, and users will continuously evolve.</p><p>You have to keep your eyes open to see what stays true and what helps you stay focused on what matters.<!-- --> </p><p>Loading...</p><h3>Shaping friction</h3><p><strong>Your goal when designing a product is to shape friction.</strong> <!-- -->You'll have to shape as many frictions as possible from your user's journey to achieve the desired outcome. Here are some examples:</p><ul><li><strong>Optimize your user acquisitionâ€Š</strong> â€“ remove friction from each step of the funnel;</li><li><strong>Improve engagementâ€Š</strong> â€“ remove friction to make core actions more intuitive and accessible;</li><li><strong>Reduce churnâ€Š</strong> â€“ â€Šremove friction that is keeping users away from their goals;</li><li><strong>Avoid unintended behaviorsâ€Š</strong> â€“â€Š Instagram adding features to avoid users (adding friction) to pos offensive content;</li><li>You got the pointâ€¦</li></ul><p><mark><strong>To identify which friction worth solving/shaping, you have to have a deep understating of your product and the people using it.</strong></mark> <!-- -->You'll have to know product goals and the user's job-to-be-done (context, objectives, functional and emotional needs).</p><p>In essence, your job is to continuously iterate, shape, and balance the right amount of friction on each part of the product.</p><h3>Prioritization &amp;&nbsp;Judgment</h3><p>Loading...</p><p><strong><mark>Prioritization is one of the most essential subjects in building products.</mark></strong></p><p>There are endless techniques, frameworks, mental models, and tools to help you make the right decisions when prioritizing your next move.</p><p>The truth is that it's tough to make the "best" decisions, even when you have lots of qualitative and quantitative insights (not the case for early-stage products) to inform your prioritization.</p><p><strong>Confident decision making takes time</strong>. When working on a high-growth startup, you'll have to be comfortable with the uncertainty, lack of time, data, and resources to make the right call.</p><p>Another critical factor to keep in mind is your (and your team's) biases. Even when you have plenty of data at your disposal, you and your team are always influenced by some bias (<a href="https://en.wikipedia.org/wiki/List_of_cognitive_biases" title="Cognitive biases" target="_blank">confirmation bias and others</a>).</p><p>There will be times when you won't have enough data, other times you won't have enough time, and most of the time, you won't be aware of your biases.</p><p>That leads me to my last point, <strong>judgment</strong>. Good judgment is extremely underrated these days, but I find it one of the most valuable traits.</p><blockquote>"Good Judgment depends mostly on experience, and experience usually comes from poor judgment."<p>Old saying</p></blockquote><p>Good judgment is also impossible to measure upfront, but<!-- --> <strong>it will be your judgment</strong> to assess the risk and time needed to make each decision<strong>that will lead you towards the best possible outcomes</strong> <!-- -->in times of uncertainty.</p></main></div></div></div>]]>
            </description>
            <link>https://amiltonpaglia.com/writing/building-products</link>
            <guid isPermaLink="false">hacker-news-small-sites-26173963</guid>
            <pubDate>Thu, 18 Feb 2021 00:44:06 GMT</pubDate>
        </item>
    </channel>
</rss>
