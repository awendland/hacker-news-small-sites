<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 05 Nov 2020 12:26:24 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 05 Nov 2020 12:26:24 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[My game won't sell and that's ok]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24978084">thread link</a>) | @chr15m
<br/>
November 3, 2020 | https://chr15m.itch.io/asterogue/devlog/190653/my-game-wont-sell-and-thats-ok | <a href="https://web.archive.org/web/*/https://chr15m.itch.io/asterogue/devlog/190653/my-game-wont-sell-and-thats-ok">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper"><div id="inner_column"><div id="game_devlog_post_page_1219"><div><div><section id="video_embed_widget_60358"><iframe frameborder="0" allowfullscreen="" src="//www.youtube.com/embed/7efdmAJAUVY"></iframe></section><section><a href="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0ODg4MzYuZ2lm/original/HaqSXO.gif" target="_blank" data-image_lightbox=""><img src="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0ODg4MzYuZ2lm/x200/lnOYDd.gif" data-image_id="4488836" height="200"></a><a href="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0OTMzNDguZ2lm/original/0NaSBi.gif" target="_blank" data-image_lightbox=""><img src="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0OTMzNDguZ2lm/x200/ZLnRgb.gif" data-image_id="4493348" height="200"></a><a href="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0NDAxMDAuZ2lm/original/kTd%2Bi3.gif" target="_blank" data-image_lightbox=""><img src="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0NDAxMDAuZ2lm/x200/kCBUJY.gif" data-image_id="4440100" height="200"></a><a href="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0ODg4MzUuZ2lm/original/tRRdDT.gif" target="_blank" data-image_lightbox=""><img src="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0ODg4MzUuZ2lm/x200/bwgJDH.gif" data-image_id="4488835" height="200"></a></section><section><p>I discovered Nethack and Rogue some 25 years ago and ever since then I have wanted to make my own roguelike game. On Friday I followed through on that youthful dream and shipped Asterogue, yay!</p>
<p>This game won’t sell. I have been around the indie games scene long enough to know its a crap-shoot. To make a successful indie game you have to execute at peak performance, do everything right, and then you still roll the dice on success. I’ve seen stone cold geniuses build glorious works of art and watch them get zero downloads. A single tear rolls down their cheek one week after launch and tiny pixellated violins play a chiptune version of Mozart’s Requiem.</p>
<p>My game won’t sell and that’s ok. I am at peace with it after all of these years of game jams and side projects. It is the way of things. I’m just happy to have had the chance to fulfill this dream.</p>
<p>I had so much fun making Asterogue. I’ve never worked harder on a side project. I publically committed to an October 30th release, and I’ve done it. I built the thing I dreamed of making since I was a kid, and I am simply grateful to the universe that this opportunity was within my reach.</p>
<p>I want to thank the people who took a chance and bought the game. It’s amazing to me that our tiny club of people who like this kind of game has more than one member. You guys rock!</p>
<p>I also want to thank from the bottom of my heart the people who tested the game and gave me feedback. It’s an honor when somebody is willing to sacrifice their time to try out something you built, and I really appreciate it. It’s your feedback that made this the best possible game I could make in the time allocated. Thank you.</p>
</section><section><h2>Get Asterogue</h2></section></div></div></div></div></div></div>]]>
            </description>
            <link>https://chr15m.itch.io/asterogue/devlog/190653/my-game-wont-sell-and-thats-ok</link>
            <guid isPermaLink="false">hacker-news-small-sites-24978084</guid>
            <pubDate>Tue, 03 Nov 2020 09:50:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Math Keeps Changing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24978027">thread link</a>) | @vonadz
<br/>
November 3, 2020 | https://macwright.com/2020/02/14/math-keeps-changing.html | <a href="https://web.archive.org/web/*/https://macwright.com/2020/02/14/math-keeps-changing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>This is a written version of a talk that I gave at <a href="https://wafflejs.com/">WaffleJS</a> in February, which itself was an expansion of a <a href="https://twitter.com/tmcw/status/1187782634623000576">Twitter conversation</a> from October.</em></p><p><picture><source srcset="https://macwright.com/images/2020-02-14-math-keeps-changing-math-education.webp" type="image/webp"><img alt="Math education" src="https://macwright.com/images/2020-02-14-math-keeps-changing-math-education.jpg"></picture></p><p>Okay, so it starts with my delayed math education. As part of my Computer Science program, I had access to world-class math professors, access that I mostly wasted. I didn’t like math: the topics were so removed from practice, and I was already frustrated by the highly theoretical, and – I thought at the time and mostly still do – out-of-touch CS program.</p><p>Unfortunately, a few years after graduating, I got the hunger for math. Seeing how I could apply just a little bit of math knowledge to great effect in my work &amp; hobbies had me inspired. But I had no clear way of learning it.</p><p>So I <a href="https://macwright.com/2012/06/26/simple-statistics.html">started Simple Statistics in 2012</a> as a way to learn math, and ever since then, I’ve expanded and maintained the project. It now includes a lot of different algorithms, is one of the most ‘starred’ JavaScript math projects, and presumably is used by people.</p><p>But I started it in 2012. In tech years that’s a really long time ago. Between then and now, there have been 8 LTS releases of <a href="https://nodejs.org/en/">Node</a>. JavaScript and its environments have radically changed. 2012 was before the introduction of React or the first commit to Babel.</p><p><picture><source srcset="https://macwright.com/images/2020-02-14-math-keeps-changing-time-passing.webp" type="image/webp"><img alt="Time passing" src="https://macwright.com/images/2020-02-14-math-keeps-changing-time-passing.jpg"></picture></p><p>So what I noticed over the years was that tests kept breaking when I updated Node. I’d have a test like:</p><div><div><pre><code><span>t</span><span>.</span><span>equal</span><span>(</span><span>ss</span><span>.</span><span>gamma</span><span>(</span><span>11.54</span><span>),</span> <span>13098426.039156161</span><span>);</span>
</code></pre></div></div><p>That would work in Node v10 and break in Node v12. And this is not some complex method: gamma is implemented with arithmetic, Math.pow, Math.sqrt, and Math.sin.</p><h3 id="arithmetic">Arithmetic</h3><p>So I know what you might be thinking: arithmetic. JavaScript, on Twitter, gets a lot of heat for this behavior:</p><div><div><pre><code>0.1 + 0.2 = 0.30000000000000004
</code></pre></div></div><p>As I wrote in <a href="https://macwright.com/2017/07/29/javascript-wats-dissected.html#numbers-are-weird">JavaScript wats, dissected</a>, this is the behavior of every popular programming language, even stodgy pedantic ones like Haskell. Floating point arithmetic might be weird, but it’s very consistent and well-specified: the <a href="https://en.wikipedia.org/wiki/IEEE_754">IEEE 754</a> specification is rigorously implemented. So it’s not arithmetic: addition, subtraction, division, and multiplication are pretty set in stone.</p><h3 id="math">Math</h3><p>What it was, was Math. In particular, all of <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math">the methods that come after <code>Math.</code></a></p><p>Methods like Math.sin, Math.cos, Math.exp, Math.pow, Math.tan: <a href="https://macwright.com/2013/03/05/math-for-pictures.html">essential ingredients for geometry</a> and basic computation. I started isolating changes in basic function behavior between versions. For example:</p><p>Calculating Math.tanh(0.1)</p><div><div><pre><code>// Node 4
0.09966799462495590234
// Node 6
0.09966799462495581907
</code></pre></div></div><p>Calculating Math.pow(1/3, 3)</p><div><div><pre><code>// Node 10
0.03703703703703703498
// Node 12
0.03703703703703702804
</code></pre></div></div><p>To make matters worse, it’s not just Node’s behavior that’s changing: so are browsers and other places you use JavaScript.</p><p>So this led to the question: <strong>what is math?</strong></p><svg fill="none" viewBox="0 0 1105 572" width="100%" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1105v572H0z" fill="#fff"></path><path d="M551.933 460.719c92.311 0 167.143-74.833 167.143-167.143 0-92.311-74.832-167.143-167.143-167.143-92.31 0-167.143 74.832-167.143 167.143 0 92.31 74.833 167.143 167.143 167.143z" stroke="#000" stroke-width="3" stroke-linecap="round"></path><path d="M573.104 247.619a50.608 50.608 0 0129.506 45.71l-50.607.288 21.101-45.998z" fill="#fff"></path><path d="M551.933 478.638V93" stroke="#000" stroke-width="3"></path><path d="M573.104 247.619a50.608 50.608 0 0129.506 45.71" stroke="#000" stroke-width="3.58" stroke-linecap="round"></path><path d="M356 294.18h393.984m-197.951-1.075l69.694-151.216" stroke="#000" stroke-width="3"></path><path d="M621.601 142.175V293.47" stroke="#000" stroke-width="5" stroke-linecap="round" stroke-opacity=".941"></path><path d="M552.842 293.576h68.763" stroke="#000" stroke-width="5" stroke-linecap="round"></path><path d="M621.768 145.349a3 3 0 100-6 3 3 0 000 6zm-31.76 38.227h-2.498V167.02l-5.008 1.839v-2.256l7.116-2.672h.39v19.645zm-6.801 91.04c0 2.873-.528 5.071-1.584 6.593-1.057 1.513-2.583 2.269-4.579 2.269-1.961 0-3.474-.743-4.539-2.229-1.065-1.486-1.616-3.607-1.651-6.365v-2.752c0-2.838.528-5.004 1.584-6.499s2.583-2.243 4.579-2.243c1.987 0 3.504.725 4.552 2.176 1.056 1.45 1.602 3.549 1.638 6.297v2.753zm-9.869-2.162h7.371v-.739c0-2.032-.313-3.585-.939-4.659-.618-1.083-1.536-1.625-2.753-1.625-1.2 0-2.113.542-2.739 1.625-.627 1.074-.94 2.627-.94 4.659v.739zm7.371 2.041h-7.371v.524c0 2.05.326 3.634.98 4.753.653 1.119 1.562 1.679 2.726 1.679 1.163 0 2.059-.538 2.685-1.612.636-1.074.963-2.627.98-4.659v-.685zm54.214-5.38c0-.672-.256-1.191-.766-1.558-.501-.376-1.383-.698-2.645-.967-1.253-.268-2.251-.591-2.994-.967-.735-.376-1.281-.823-1.639-1.342-.349-.52-.523-1.137-.523-1.853 0-1.191.501-2.198 1.504-3.022 1.011-.823 2.3-1.235 3.867-1.235 1.647 0 2.981.425 4.001 1.276 1.03.85 1.544 1.938 1.544 3.263h-2.497c0-.681-.291-1.267-.873-1.759-.573-.493-1.298-.739-2.175-.739-.904 0-1.612.197-2.122.591-.51.394-.765.908-.765 1.544 0 .6.237 1.052.711 1.356.475.305 1.33.595 2.565.873 1.244.277 2.252.609 3.021.994.77.385 1.339.85 1.706 1.396.376.537.564 1.195.564 1.974 0 1.298-.519 2.341-1.558 3.129-1.038.778-2.386 1.168-4.042 1.168-1.163 0-2.193-.206-3.088-.618-.895-.412-1.598-.984-2.108-1.719-.501-.743-.752-1.544-.752-2.403h2.484c.045.832.376 1.495.994 1.987.626.484 1.45.725 2.47.725.94 0 1.692-.188 2.256-.564.573-.385.86-.895.86-1.53zm8.419 3.853h-2.484V258.44h2.484v14.528zm-2.686-18.382c0-.403.121-.743.363-1.021.25-.277.617-.416 1.101-.416.483 0 .85.139 1.101.416.251.278.376.618.376 1.021 0 .403-.125.738-.376 1.007-.251.268-.618.403-1.101.403-.484 0-.851-.135-1.101-.403-.242-.269-.363-.604-.363-1.007zm9.024 3.854l.08 1.826c1.11-1.397 2.56-2.095 4.351-2.095 3.07 0 4.619 1.732 4.646 5.196v9.601h-2.484v-9.614c-.009-1.047-.251-1.822-.725-2.323-.466-.501-1.195-.752-2.189-.752-.806 0-1.513.215-2.122.645a4.37 4.37 0 00-1.423 1.692v10.352h-2.484V258.44h2.35zm12.729 6.593c0-2.024.269-3.966.806-5.828a17.059 17.059 0 012.43-5.076c1.074-1.522 2.189-2.596 3.344-3.222l.51 1.638c-1.307 1.002-2.381 2.533-3.223 4.592-.832 2.059-1.289 4.364-1.369 6.915l-.014 1.142c0 3.455.631 6.454 1.894 8.996.76 1.522 1.665 2.713 2.712 3.572l-.51 1.517c-1.191-.662-2.328-1.772-3.411-3.33-2.113-3.043-3.169-6.682-3.169-10.916zm21.605-.658c0 2.873-.528 5.071-1.584 6.593-1.056 1.512-2.583 2.269-4.579 2.269-1.96 0-3.473-.743-4.539-2.229-1.065-1.486-1.615-3.608-1.651-6.365v-2.753c0-2.837.528-5.004 1.584-6.499 1.057-1.495 2.583-2.242 4.579-2.242 1.987 0 3.505.725 4.552 2.175 1.057 1.45 1.603 3.55 1.638 6.298v2.753zm-9.869-2.162h7.372v-.739c0-2.032-.313-3.585-.94-4.659-.618-1.083-1.535-1.625-2.753-1.625-1.199 0-2.112.542-2.739 1.625-.627 1.074-.94 2.627-.94 4.659v.739zm7.372 2.041h-7.372v.523c0 2.05.327 3.635.98 4.754.654 1.119 1.562 1.678 2.726 1.678s2.059-.537 2.686-1.611c.635-1.074.962-2.627.98-4.659v-.685zm11.776.913c0 1.996-.264 3.912-.792 5.747a16.802 16.802 0 01-2.404 5.062c-1.074 1.549-2.202 2.65-3.384 3.303l-.523-1.517c1.378-1.056 2.484-2.694 3.316-4.915.842-2.229 1.271-4.699 1.289-7.412v-.429c0-1.88-.197-3.626-.59-5.237-.394-1.62-.945-3.071-1.652-4.351-.698-1.28-1.486-2.278-2.363-2.994l.523-1.517c1.182.653 2.305 1.745 3.371 3.276a16.797 16.797 0 012.403 5.062c.537 1.844.806 3.818.806 5.922zm-128.345 52.119c.887 0 1.661-.269 2.323-.806.663-.537 1.03-1.208 1.101-2.014h2.35c-.044.832-.331 1.625-.859 2.377-.528.752-1.235 1.351-2.122 1.799a6.067 6.067 0 01-2.793.671c-1.978 0-3.554-.658-4.726-1.974-1.164-1.324-1.746-3.133-1.746-5.424v-.417c0-1.414.26-2.672.779-3.773s1.262-1.956 2.229-2.565c.976-.608 2.126-.913 3.451-.913 1.629 0 2.981.488 4.055 1.464 1.083.976 1.661 2.242 1.732 3.8h-2.35c-.071-.94-.429-1.71-1.074-2.31-.635-.608-1.423-.913-2.363-.913-1.262 0-2.242.457-2.941 1.37-.689.904-1.034 2.216-1.034 3.934v.47c0 1.674.345 2.963 1.034 3.868.69.904 1.674 1.356 2.954 1.356zm7.909-5.64c0-1.423.278-2.703.833-3.84.564-1.137 1.343-2.014 2.336-2.632 1.003-.618 2.144-.927 3.424-.927 1.979 0 3.577.685 4.794 2.055 1.226 1.369 1.84 3.191 1.84 5.465v.174c0 1.415-.273 2.686-.819 3.814-.538 1.119-1.312 1.992-2.323 2.618-1.003.627-2.158.94-3.465.94-1.969 0-3.567-.685-4.794-2.054-1.217-1.37-1.826-3.183-1.826-5.438v-.175zm2.498.295c0 1.612.371 2.905 1.114 3.881.752.976 1.755 1.464 3.008 1.464 1.262 0 2.265-.493 3.008-1.477.743-.994 1.114-2.382 1.114-4.163 0-1.593-.38-2.882-1.141-3.867-.752-.994-1.754-1.491-3.008-1.491-1.226 0-2.215.488-2.967 1.464-.752.976-1.128 2.372-1.128 4.189zm22.303 3.25c0-.671-.255-1.191-.765-1.558-.501-.376-1.383-.698-2.645-.966-1.254-.269-2.252-.591-2.995-.967-.734-.376-1.28-.824-1.638-1.343-.349-.519-.524-1.137-.524-1.853 0-1.191.502-2.198 1.504-3.021 1.012-.824 2.301-1.236 3.868-1.236 1.647 0 2.98.426 4.001 1.276 1.029.85 1.544 1.938 1.544 3.263h-2.497c0-.68-.291-1.267-.873-1.759-.573-.492-1.298-.739-2.175-.739-.905 0-1.612.197-2.122.591-.51.394-.765.909-.765 1.544 0 .6.237 1.052.711 1.357.475.304 1.33.595 2.565.872 1.244.278 2.251.609 3.021.994s1.338.85 1.705 1.397c.376.537.564 1.195.564 1.973 0 1.298-.519 2.341-1.557 3.129-1.039.779-2.386 1.168-4.042 1.168-1.164 0-2.193-.206-3.088-.617-.895-.412-1.598-.985-2.108-1.719a4.21 4.21 0 01-.752-2.404h2.484c.044.833.376 1.495.993 1.988.627.483 1.451.725 2.471.725.94 0 1.692-.188 2.256-.564.573-.385.859-.895.859-1.531zm5.627-4.082c0-2.023.268-3.966.805-5.828a17.02 17.02 0 012.431-5.075c1.074-1.522 2.188-2.596 3.343-3.223l.51 1.638c-1.307 1.003-2.381 2.534-3.222 4.592-.833 2.059-1.289 4.364-1.37 6.916l-.013 1.141c0 3.455.631 6.454 1.893 8.997.761 1.521 1.665 2.712 2.712 3.571l-.51 1.518c-1.19-.663-2.327-1.773-3.411-3.33-2.112-3.044-3.168-6.683-3.168-10.917zm21.605-.658c0 2.874-.528 5.071-1.585 6.593-1.056 1.513-2.582 2.269-4.579 2.269-1.96 0-3.473-.743-4.538-2.229-1.065-1.486-1.616-3.607-1.652-6.364v-2.753c0-2.838.528-5.004 1.585-6.499 1.056-1.495 2.582-2.243 4.579-2.243 1.987 0 3.504.726 4.552 2.176 1.056 1.45 1.602 3.549 1.638 6.297v2.753zm-9.87-2.162h7.372v-.738c0-2.032-.313-3.586-.94-4.66-.617-1.083-1.535-1.625-2.752-1.625-1.2 0-2.113.542-2.74 1.625-.626 1.074-.94 2.628-.94 4.66v.738zm7.372 2.041h-7.372v.524c0 2.05.327 3.634.981 4.753.653 1.119 1.562 1.679 2.725 1.679 1.164 0 2.059-.537 2.686-1.612.636-1.074.962-2.627.98-4.659v-.685zm11.776.913c0 1.996-.264 3.912-.792 5.747a16.781 16.781 0 01-2.403 5.063c-1.075 1.548-2.203 2.649-3.384 3.303l-.524-1.518c1.379-1.056 2.484-2.694 3.317-4.914.841-2.229 1.271-4.7 1.289-7.412v-.43c0-1.88-.197-3.625-.591-5.237-.394-1.62-.944-3.07-1.652-4.35-.698-1.28-1.486-2.279-2.363-2.995l.524-1.517c1.181.653 2.305 1.746 3.37 3.276a16.805 16.805 0 012.404 5.063c.537 1.844.805 3.818.805 5.921z" fill="#000"></path></svg><p>Trigonometry methods are easy to <em>show</em>: given a unit circle and a few months of high school, you know that cosine and sine will get you coordinates on the rim, and that they’ll draw little squigglies if plotted on X &amp; Y. Actually <em>deriving</em> those methods is what you’ll learn in advanced classes, but the method that you use - the <a href="https://en.wikipedia.org/wiki/Taylor_series">Taylor series</a> - relies on an <em>infinite</em> series, which would be rather laborious for a computer to solve.</p><blockquote><p>“There is no standard algorithm for calculating sine. IEEE 754-2008, the most widely used standard for floating-point computation, does not address calculating trigonometric functions such as sine.”</p></blockquote><p>-<a href="https://en.wikipedia.org/w/index.php?title=Sine&amp;oldid=939445047#Software_implementations">Wikipedia</a></p><p>Computers use a variety of different estimations and algorithms to do math, things like <a href="https://en.wikipedia.org/wiki/CORDIC">CORDIC</a> and various cheating algorithms and lookup tables. This heterogeny explains all of the <a href="https://github.com/search?q=fastmath">‘fastmath’</a> libraries you can find on GitHub: there’s more than one way to implement Math.sin. Famously, Quake III Arena used a <a href="https://en.wikipedia.org/w/index.php?title=Fast_inverse_square_root&amp;oldid=940101226">faster replacement for the inverse square root method</a> in order to speed up rendering.</p><p>So math is implemented as algorithms, and there are multiple common algorithms –&nbsp;and variations of those algorithms –&nbsp;used in practice.</p><p>Instead of telling implementations to pick an algorithm, the JavaScript specification grants them a <em>lot</em> of wiggle room in terms of how they implement these basic functions.</p><blockquote><p>The behaviour of the functions acos, acosh, asin, asinh, atan, atanh, atan2, cbrt, cos, cosh, exp, expm1, hypot, log,log1p, log2, log10, pow, random, sin, sinh, sqrt, tan, and tanh is not precisely specified here except to require specific results for certain argument values that represent boundary cases of interest.</p></blockquote><p>-<a href="https://www.ecma-international.org/ecma-262/10.0/index.html#sec-function-properties-of-the-math-object">ECMA-262, 10th edition, section 20.2.2 aka “JavaScript”</a></p><p>I don’t know the inner workings of the standards committees, but I imagine they wanted to make sure that just in case Intel or AMD introduce super-fast new math instructions in a new processor, JavaScript wouldn’t have a compatibility crisis.</p><p>Because there are a lot of JavaScript interpreters that are commonly used, because JavaScript is often used via web browsers and there still is some competition between web browsers, and because even popular JavaScript implementations are under pressure to evolve quickly to be the most performant…&nbsp;because of all that, this matters. You actually will encounter, on a regular basis, differences in math.</p><p>This doesn’t matter as much in other interpreted languages, because they tend to have ‘canonical’ interpreters: most of the time you use the Python interpreter of the Python language.</p><h3 id="where-math-happens">Where math happens</h3><p>Next let’s zoom into <em>where</em> these math implementations live. See, in JavaScript, there are three places where basic math can happen:</p><ol><li>The CPU</li><li>The language interpreter (the C++ and C code that underlies JavaScript implementations)</li><li>In software itself, as a library</li></ol><p><strong>1: The CPU</strong></p><p>This was my first guess: I assumed that since CPUs implement arithmetic, they might implement some higher-level math. It turns out that CPUs do have instructions to do trigonometry and other operations, but they’re rarely invoked. The CPU (x86) implementation of sine doesn’t get much love because it’s not reliably faster than an implementation in software (using arithmetic operations on the CPU), nor as accurate.</p><p>Intel also bears some blame for <a href="https://randomascii.wordpress.com/2014/10/09/intel-underestimates-error-bounds-by-1-3-quintillion/">overstating the accuracy of their trigonometric operations</a> by many magnitudes. That kind of mistake is especially tragic because, unlike software, you can’t patch chips.</p><p><strong>2: The language interpreter</strong></p><p>This is how most of the implementations do it, and they implement math in a variety of ways.</p><ul><li>V8 &amp; SpiderMonkey use (slightly different) ports of the <a href="http://www.netlib.org/fdlibm/">fdlibm</a> library for most operations. It has been passed down through the generations, originally written at Sun Microsystems.</li><li>JavaScriptCore (Safari) uses cmath for most operations.</li><li>Internet Explorer used some cmath, but <a href="https://github.com/microsoft/ChakraCore/blob/d86452259dd534718b7eb9ce024ed35aefd33036/lib/Runtime/Library/MathLibrary.cpp#L1028-L1047">also used some assembly instructions and actually <em>did</em> use CPU-provided trig methods</a> when it was compiled for CPUs that had them.</li></ul><p>Historically, all of these implementations have shifted: V8 used to use a homegrown solution for math, and then used <a href="https://github.com/v8/v8/blob/ff7975aa8d1ff6f0904f0f5112d17ea819466983/src/math.js">a port of fdlibm to JavaScript</a>, before finally settling on fdlibm in C.</p><h3 id="why-this-is-an-issue">Why this is an issue</h3><p>Here’s why this is a problem: it chips away at JavaScript’s ability to give consistent results to any problem including mathematics. And that especially hits <em>data science</em>. I want JavaScript to be a contender for data science in the browser, and – amongst some other issues, like number types and a confounding lack of a commonly-used data-frames library –&nbsp;an inability to produce replicable results means adding more crisis to the <a href="https://en.wikipedia.org/wiki/Replication_crisis">replication crisis</a> in the sciences.</p><h3 id="the-third-way">The third way</h3><p>There is a way out that we can use today. <a href="https://github.com/stdlib-js/stdlib">stdlib</a> is a JavaScript library that reimplements higher-level math using arithmetic alone. Arithmetic is fully-specified and standard, so the results that stdlib gives you are also fully consistent, across all the platforms.</p><p>This comes at the cost of complexity and speed: stdlib isn’t consistently as fast as built-in methods, and you’ll need to require a library ‘just’ to compute sine.</p><p>But in the wider view, this is pretty normal! WebAssembly, for example, doesn’t give you higher-level math methods at all and recommends you include a math implementation in your modules themselves:</p><blockquote><p>“WebAssembly doesn’t include its own math functions like sin, cos, exp, pow, and so on. WebAssembly’s strategy for such functions is to allow them to be implemented as library routines in WebAssembly itself (note that x86’s sin and cos instructions are slow and imprecise and are generally avoided these days anyway).”</p></blockquote><p>And this is the way that compiled languages have always worked: when you compile a C program, the methods you import from <code>math.h</code> are included in the compiled binary.</p><h3 id="using-an-epsilon">Using an epsilon</h3><p>If you don’t want to include stdlib to do math but you do want to test math-heavy code, you’ll probably have to do what simple-statistics does right now: use an epsilon. Of the <a href="https://en.wikipedia.org/w/index.php?title=Epsilon&amp;oldid=938802001#Symbol">5+ uses of epsilon in math</a>, the one I’m referring to is “an arbitrarily small positive quantity”. It’s a tiny number. Here’s <a href="https://github.com/simple-statistics/simple-statistics/blob/727eaed049af4f788fb2299e5c8263573618e78c/src/epsilon.js#L35">simple-statistics’s implementation</a>: the number 0.0001.</p><p>You then compare <code>Math.abs(result - expected) &lt; epsilon</code> to make sure you got within range of the desired value, with a little bit of wiggle room.</p><h3 id="the-moral-of-the-story">The moral of the story</h3><p>Here’s where I was a little short on time in person and have some room to expand.</p><p><em>First, what’s under the hood is rarely what you expect.</em> Our current tech stack is heavily optimized and a lot of optimizations are really just dirty tricks. For example, the number of hardware instructions it takes to solve <code>Math.sin</code> varies based on the input, because there are lots of special cases. When you get to more complex cases, like ‘sorting an array’, there are often multiple algorithms that the interpreter chooses between in order to give you your final result. Basically, the cost of anything you do in an interpreted language is variable.</p><p><em>Second, don’t trust the system too much.</em> What I was seeing between Node versions really <em>should</em> have been a bug in the testing library, or something in my code, or maybe in simple-statistics itself. But in this case, digging deeper revealed that what I was seeing was exactly what you don’t expect: a glitch in the language itself.</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://macwright.com/2020/02/14/math-keeps-changing.html">https://macwright.com/2020/02/14/math-keeps-changing.html</a></em></p>]]>
            </description>
            <link>https://macwright.com/2020/02/14/math-keeps-changing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24978027</guid>
            <pubDate>Tue, 03 Nov 2020 09:42:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Browser extension Honey also collects their user’s history data]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24977935">thread link</a>) | @n3wham
<br/>
November 3, 2020 | https://www.datarequests.org/blog/honey-data-collection/ | <a href="https://web.archive.org/web/*/https://www.datarequests.org/blog/honey-data-collection/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><strong>The free browser extension “Honey” wants to save their users money by automatically finding and applying coupon codes. They describe themselves as advocates for data protection and allegedly only collect history data on online shopping websites. Two of our members who have used Honey in the past, have asked for access to the data saved on them using the GDPR. Our analysis of the responses shows that Honey collects history data on a large scale, contrary to what their own privacy policy says. Thus, we have submitted complaints with the data protection authorities.</strong></p><p>“Stop wasting money – Honey helps you find some of the best coupon codes on 30,000+ sites.” That’s how Honey describe themselves on their homepage. The free browser extension is heavily advertised on YouTube and other websites. The idea behind it is nothing new. There have been websites that collect coupon codes for various online shops for a long time.</p><p>But Honey goes one step further and wants to make this process easier for their users. Sometimes, the coupon codes found on such websites are expired or only work for certain items. Trying the different coupons codes, that are often spread across many websites, can genuinely be quite frustrating. Honey promises to do that work for their users. Once installed in the browser, the addon automatically enters all coupons it knows on the shopping cart pages of supported websites. Afterwards, it applies the one that yields the biggest savings.</p><p>Honey then earn money through so-called “affiliate marketing”. The participating shops pay a commission to Honey for the coupons used.</p><p>So far, so good. But as a non-profit promoting data protection, we are mostly interested in one thing: How does Honey process their users’ data? As a browser extension, Honey could in theory record all internet traffic and thus log the entire browser history. This is especially problematic as Honey is run by a US company, <a href="https://www.datarequests.org/company/joinhoney/">Honey Science LLC</a>, that was recently <a href="https://help.joinhoney.com/article/302-what-does-honey-joining-paypal-mean-for-members">bought by PayPal</a>.</p><p>To find out what data Honey collects, we could first take a look at their privacy policy (and, of course, <a href="#honey-privacy-policy">we did</a>). But these unfortunately tend to be pretty general. They don’t really give users an idea on what data is actually collected on them. Luckily, the GDPR can help here. It grants users <a href="https://www.datarequests.org/blog/your-gdpr-rights/">extensive rights with regards to their data</a>. One of those is the so-called <em>right to data access</em>, which is defined in Art. 15 GDPR, and allows all consumers to demand a copy of the data companies have saved on them. This makes it possible to verify a company’s statements.</p><p>Two of our members, Benni and Malte, have made use of this right. They had both used the Honey extension in the past for a while. Benni had created an account and used that to log into the extension, while Malte has used the extension without an account. Both used our <a href="https://www.datarequests.org/generator/">generator</a> to send an access request to Honey.</p><p>We have then analysed the responses they received.</p><p>When logged into the extension with an account, accessing the data was very easy. The response containing the data arrived within a little more than two weeks. It contained various CSV files on different topics. The first couple contained details that one would expect: the data from the user profile, country and language, the <em>Honey Gold</em> balance, a list of transactions qualifying for Honey Gold, the IP addresses and browsers used at the time of registering for an account and installing the extension.</p><p>However, it also contained a file called <code>PageViews.csv</code> that was a lot more surprising. As the name implies, this file contains a list of page views. For Benni, who used the extension from mid February 2020 to mid May 2020, it contained a staggering 2591 entries.</p><p>To give an example, one of the lines in the file looks like this (displayed as a column here for better readability):</p><p>We can see: <strong>For every visit of a page in an online shop, Honey logs at least the following information</strong>: a timestamp, multiple <strong>unique IDs</strong> for user, session and device, the operation system, the browser and browser version, geolocation details, and the <strong>full URL of the visited page</strong>.<br>From that, the company gains an incredibly detailed insight into the shopping behaviour of its users. It knows not only the products that users buy but also all the products that they looked at but ultimately didn’t end up buying, as well as how long they looked at the product page.</p><p>We consider even this processing to be excessive. But it may be possible to barely justify it given that Honey’s purpose is to find coupon codes for the products that users look at. But Honey collects <em>a lot</em> more data.</p><p>Indeed, not only product pages from online shops are logged. Instead, Honey saves any visit to a page whose domain the company has classified as an “online shopping website”. But many shopping websites don’t just include the actual product pages. They often have a multitude of other content, like blog posts or login pages.<br>And Honey goes even further yet: They log page views even for subsites that are on different subdomains. Thus, the user’s browsing habits on countless forums, support pages and other sites are also documented. And for all of these pages, the full URL is saved, even including the document fragment that may allow reconstructing the precise position of the page the user looked at. The logged URLs and included parameters can also contain sensitive data but in any case they allow Honey to get a detailed view into the users’ browsing habits.</p><p>To demonstrate the scope of the profiles that Honey could create from this data, we have selected a few rows from Benni’s data export and will now describe what information could be inferred from this. The exact raw data of the corresponding rows is published below.</p><p>Honey knows, that on February 13, 2020 at 2:57 PM, Benni looked at an <a href="https://www.ifixit.com/Guide/Nintendo+Wii+DVD+Drive+Lens+Replacement/4491">iFixit guide</a> on how to swap the DVD lens on a Wii. He viewed the details for his AliExpress order <code>3002876007952992</code> a total of 13 times, starting on February 17 at 7:43 PM. He started a dispute for this order on February 25 at 10:01 AM. But before that, he went looking for an Airbnb in Berlin-Mitte on February 24 at 8:02 PM. He was looking for an entire accommodation or a hotel room for two adults for the period from March 04 to March 05. On March 01 at 6:46 PM, he looked at an <a href="https://support.apple.com/en-us/HT204306">Apple support page</a> describing how to reset an iPhone if you forgot the unlock code. The next day at 2:25 PM, he was interested in the <a href="https://creativecommons.org/licenses/by/4.0/">CC-by license</a> by Creative Commons and on March 10 at 9:04 PM, he looked at the <a href="https://developer.microsoft.com/en-us/fabric">Fabric UI Framework</a> by Microsoft. He is apparently also a member of a Microsoft family, as he added another member to his family the next day at 7:45 PM to share the benefits of his Office 365 subscription with them. On March 14 at 11:49 AM, he read an <a href="https://www.trustwave.com/en-us/resources/blogs/spiderlabs-blog/cve-2018-1000136-electron-nodeintegration-bypass/">article</a> on a security vulnerability in the Electron framework. On March 23 at 5 PM, he watched the documentary <a href="https://curiositystream.com/video/1984/scanning-the-pyramids">“Scanning The Pyramids”</a> via the streaming provider CuriosityStream. He signed up for the service only half an hour earlier, at 4:29 PM, having been recruited by YouTuber Tom Scott and registering via his affiliate link. On March 25 at 6:51 PM, he was again interested in a trip, this time via FlixBus. He planned the trip as a one-way trip between Berlin and Leipzig for an adult on May 01. But this trip never took place, as there are no further entries for FlixBus. On April 22 at 8:33 AM, Benni redeemed a game on Steam with the code <code>5HGP6-JVK5C-I92YW</code>. On May 11 at 9:04 PM, he then informed himself about the lack of support for exporting in the MKV format in Adobe Premiere on the <a href="https://community.adobe.com/t5/premiere-pro/premiere-pro-cc-doesn-t-support-mkv-anymore/td-p/10586989?page=1">Adobe support forum</a>. He has an AWS account and access to the S3 bucket named <code>dacdn-static</code>. This contains a file with the path <code>talks/subtitles/20200511-okl-berlin-en.vtt</code>, which he looked at on May 13 at 3:09 PM.</p><p><strong>Honey can infer all this information directly from the data they collected.</strong> And the examples we gave only represent a tiny fraction of the information that Honey has. The 27 lines that the examples are based on, only make up just over 1&nbsp;% of the entries Honey has collected on Benni. We have focussed on non-product related page views. But in addition, Honey also knows every product that Benni looked at while he had installed the extension. Further, they could use the data they have for even more conclusions and profiles. For example, they could infer sleep cycles from the timestamps or build interest profiles based on the sites that were visited.</p><div><summary>Raw data as saved by Honey for the events described above</summary><pre>ts,timestamp,store,extension,product,src,sub_src,user_id,device_id,visitor_id,session_id,platform,version,referrer_url,first_referrer_url,language,campaign,location,os,browser,group,is_logged_in,client_ts
2020-02-13T14:57:51.523Z,,"{country=US, id=7583916003951006414, label=i-fix-it, name=iFixit, session_id=1581602269900}","","",extension,,8291877052743772122,8291877052743758554,8291895932342390791,1581595975000,ff,11.11.4,https://www.ifixit.com/Guide/Nintendo+Wii+DVD+Drive+Lens+Replacement/4491,,en-US,"","{city=Bad Oldesloe, country=DE, region=SH}","{name=Windows, version=10}","{major=68, name=Firefox, version=68.0}",,,2020-02-13T13:57:51.4Z
2020-02-17T19:43:17.236Z,,"{country=US, id=7370049848889092396, label=aliexpress, name=AliExpress, session_id=1581968534100}","","",extension,,8291877052743772122,8281837226426454371,8281837231485163268,1581936825700,ff,11.11.4,https://trade.aliexpress.com/order_detail.htm?orderId=3002876007952992,,en-US,"","{city=Bad Oldesloe, country=DE, region=SH}","{name=Windows, version=10}","{major=68, name=Firefox, version=68.0}",,,2020-02-17T19:43:16.3Z
2020-02-24T20:02:12.145Z,,"{country=US, id=7587516493463718696, label=airbnb, name=Airbnb, session_id=1582574363800}","","",extension,,8291877052743772122,8281837226426454371,8281837231485163268,1582534687100,ff,11.11.4,https://www.airbnb.com/s/Berlin~Mitte--Berlin--Germany/homes?refinement_paths%5B%5D=%2Fhomes¤t_tab_id=home_tab&amp;selected_tab_id=home_tab&amp;place_id=ChIJjw3Y6t9RqEcR8jUVWEcgISY&amp;source=mc_search_bar&amp;search_type=filter_change&amp;screen_size=large&amp;hid…</pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.datarequests.org/blog/honey-data-collection/">https://www.datarequests.org/blog/honey-data-collection/</a></em></p>]]>
            </description>
            <link>https://www.datarequests.org/blog/honey-data-collection/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24977935</guid>
            <pubDate>Tue, 03 Nov 2020 09:24:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The free-range future of work]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24977860">thread link</a>) | @brokebroadbeat
<br/>
November 3, 2020 | https://visitmy.website/2020/11/02/free-range-future-of-work/ | <a href="https://web.archive.org/web/*/https://visitmy.website/2020/11/02/free-range-future-of-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>For organisations that use computers to get stuff done, the Internet means you can spread bits of your organisation out geographically and temporally.</p>

<p>Spreading a workforce geographically is usually called remote working or distributed working. That’s when workers aren’t necessarily close to the location of the main office, they live and work elsewhere. There’s also hybrid working, which is when people are expected to come into an office some times but can work from wherever they like the rest of the time.</p>

<p>Spreading a workforce temporally is usually called flexible working or asynchronous working. That’s when workers aren’t always required to be working at the same time as each other. Although more often than not, there’s usually some ‘core hours’ workers have to be present and available.</p>

<p>For various reasons, some groups of people have experimented with the opportunity the Internet has provided. It has allowed them to find new ways of doing things or new ways of living. And, for another variety of reasons, some people haven’t bothered.</p>

<p>Then, in March, that all changed. Anyone who could work online, usually from a computer, was forced to try this stuff out. If their company hadn’t tried out these new ways of working, they became a guinea pig overnight. A <a href="https://www.cliffsnotes.com/literature/f/flowers-for-algernon/character-analysis/algernon">mouse in a maze</a>, without a scientist overseeing the experiment.</p>

<p>That sucks because, as an organisation, you don’t know what works and what doesn’t. Your workers have been forced to try new things and will have reached their own conclusions. Some might like it, others might not be so keen. There will likely be some people for whom the experience has been traumatic, and those people are going to need our help.</p>

<p>So, ignoring whoever’s job it is to do this stuff, I think it’s time for people working on computers to look sideways (metaphorically) and help each other out. If you manage a team or you’re part of a team, it’s time to build your own New Normal.</p>

<p>Here’s some notes I’ve been making on free-range working<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>. And you might like to read about <a href="https://gds.blog.gov.uk/2020/10/07/what-happened-when-we-stopped-having-meetings-and-sending-emails/">this experiment we tried with meetings and emails</a>.</p>

<h2 id="notes-on-free-range-working">Notes on free-range working</h2>

<ol>
  <li>
    <p>We’re trying to create more serendipity for innovation, and make collaboration easier when we’re not in the same place. Show &amp; Tells don’t have to be polished. Share progress, ideas and half-finished thoughts; invite people to comment on your work before it’s completed. This helps replicate putting work up on the wall and giving people a chance to comment on things, especially if they’re not on your team.</p>
  </li>
  <li>
    <p>Check in on your colleagues’ home-working setup. Do they have space? Do they have a desk? Is it well-lit and comfortable? People with better working environments have a new kind of privilege, and so we should be equitable in our approach to free-range working.</p>
  </li>
  <li>
    <p>When everyone you work with is on a screen, everyone is more equal – it’s harder for people to dominate the room. Also, we tend to stop talking over each other and let people finish what they were saying. Cultivate that atmosphere, creating the space for diverse or unheard voices to come to the fore.</p>
  </li>
  <li>
    <p>Spontaneous socialising is a joy. Create a tea break channel and head in there when you’re going to make a cup of tea or coffee. Start a voice chat, either using your work laptop or some headphones connected to a phone.</p>
  </li>
</ol>

<hr>



  </div>
</article><div>
  
    <li>
      <span> 7 July 2019</span>

<h3>
  <a href="https://visitmy.website/2019/07/07/kicking-off-new-quarter-with-your-product-team/" onclick="window.fathom.trackGoal('3T2PDDS0', 0);">Kicking off a new quarter with your product team</a>
</h3>
<p>Here's how I frame what we've achieved so far, what's left to do and what's next with product teams at GOV.UK.</p>

    </li>
  
    <li>
      <span> 1 November 2020</span>

<h3>
  <a href="https://visitmy.website/2020/11/01/why-i-write-weeknotes/" onclick="window.fathom.trackGoal('3T2PDDS0', 0);">Why I write weeknotes</a>
</h3>
<p>Each weekend I spend around 2 hours writing about what I did in the ~38 hours I spent at work that week. Why? Good question.</p>

    </li>
  
    <li>
      <span>27 April 2019</span>

<h3>
  <a href="https://visitmy.website/2019/04/27/product-teams-deliver-outcomes-not-outputs/" onclick="window.fathom.trackGoal('3T2PDDS0', 0);">Product teams deliver outcomes, not outputs</a>
</h3>
<p>It's a change in mindset for leadership to manage outcomes or results, instead of the traditional way of managing effort and output. Here's how I turn 'Build this' into 'Realise that' on GOV.UK at the UK's Government Digital Service.</p>

    </li>
  
</div></div>]]>
            </description>
            <link>https://visitmy.website/2020/11/02/free-range-future-of-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24977860</guid>
            <pubDate>Tue, 03 Nov 2020 09:10:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Untimely Demise of Workstations]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24977652">thread link</a>) | @ingve
<br/>
November 3, 2020 | https://deprogrammaticaipsum.com/the-untimely-demise-of-workstations/ | <a href="https://web.archive.org/web/*/https://deprogrammaticaipsum.com/the-untimely-demise-of-workstations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<p>Last month’s news that <a href="https://arstechnica.com/information-technology/2020/10/ibm-to-split-into-two-companies-by-the-end-of-2021/">IBM would do a Hewlett-Packard</a> and divide into two—an IT consultancy and a buzzword compliance unit—marks the end of “business as usual” for yet another of the great workstation companies.</p>
<p>A quick aside on computing history. You can imagine personal computing being driven by two distinct schools of thought. The “top down” school, represented by research-led organisations including Xerox PARC, Bell Labs,academia and the military, asked “what would the world be like if everyone had their own minicomputer”? They took large, time-sharing systems like UNIX and installed them first under, then on, employees’ desks for their own personal use.</p>
<p>The “bottom up” school was made up of hobbyists who asked “can we make an interesting computer out of inexpensive components”? Thus companies like Apple and MITS in the US, Acorn and Sinclair Radionics in the UK, and others took chips that were usually used as peripherals controllers in “real” computers and built interactive programming systems around them. The microcomputer revolution came from the bottom-up school, as they made home computing affordable. The workstation revolution came from the top-down school, as they made powerful on-demand computing feasible.</p>
<p>The two schools came into very close proximity in the 1980s, when the Motorola 68000 family of CPUs (along with the 68881/68882 FPU and 68851 MMU) were the processors of choice in everything from entry-level PCs like the Atari 520ST, through games consoles like the Sega Mega Drive (Genesis in the US), to the most expensive UNIX workstations from NeXT Computer, Sun Microsystems, and Apollo Computer.</p>
<p>But then the workstation makers invested heavily in their own CPU architectures based on RISC design principles and again the two diverged. The workstation market became highly differentiated: RS/6000 from IBM (later PowerPC), Alpha from Digital Equipment Corp, MIPS from, well, MIPS, SPARC from Sun, PA-RISC from HP. The software on these workstations, while superficially very similar, was also differentiated and surprisingly incompatible. Take a program from HP-UX and you’ll have difficulty running it on NeXTSTEP, unless the authors shared the source code and used the nascent GNU autotools to support portable building. As Yoda said: begun, the <a href="https://www.livinginternet.com/i/iw_unix_war.htm">UNIX wars</a> have.</p>
<p>Of course we know that the (desktop) computing world today is mostly Intel and that workstations are mostly fancy PCs, rather than bespoke designs by vertically-integrated companies, Apple being the two trillion dollar outlier. How we got here was that the commodity parts got good enough that there was no evident advantage to workstation-grade hardware. A high-end PC could easily run a workstation OS like System V UNIX (Solaris was an early example), BSD (386BSD which later became FreeBSD, or NeXTSTEP) or Windows NT.</p>
<p>Along the way, the workstation companies consolidated (Apollo and eventually DEC got absorbed into HP; MIPS into SGI) or disappeared altogether (Sun became Oracle Hardware; SGI went bankrupt and sold its assets to sgi; Symbolics did similar—incidentally Symbolics was the first company with a .com domain). IBM long ago stopped even making its own brand PCs, and the news of its split means that there are now very few workstation companies trading in the same form they had “back in the day”. The only ones I can think of that have not had major changes to their corporate structures are Xerox and Sony, whose management may not even have known that they sold workstations.</p>
<p>What’s got lost alongside the death of the workstation is the business model where you sell expensive computers as part of an integrated solution into a particular vertical market, where that expensive solution will cost a lot less than cobbling something together out of cheap PCs. Why? I think people have a lower expectation and higher pain threshold when using computers now; they expect an amount of friction based on their own experience and translate that expectation into realms where it doesn’t belong. As I described way back in issue 2, <a href="https://deprogrammaticaipsum.com/the-various-meanings-of-quality/" target="_blank" rel="noopener noreferrer">computing is a lemon market</a>.</p>
<p>Organisations would go to the workstation vendors because they solved particular problems very well. If you’re in AI, you need Symbolics. Computer graphics, SGI. Telecoms, that’d be Sun. If you want to write software in Ada for the military-industrial complex, you’ll be buying a Rational workstation. Yes, the first IDE was a completely integrated package of hardware and software. And, of course, Apple for Desktop Publishing, the Mac being a workstation of sorts itself. People would buy computers <em>because</em> applications like AutoCAD, Quark or Mathematica ran well on them. They wouldn’t buy the computer then browse the App Store to see whether it could do anything useful.</p>
<p>And the strange thing is that catering to those vertical markets with integrated solutions is easier than ever now. The wide availability of free software means that the basic job of “being a desktop computer” is taken care of at zero cost, so business can focus on contributing valuable bespoke behaviour. And hardware costs are lower than ever: the availability of high-capability SoCs and single-board computers like the Raspberry Pi and Rock64 should make it a no-brainer to sell the computers as accessories for the applications, not the other way around.</p>
<p>In high-tech domains, an engineer could readily have a toolchest of suitable computers in the same way that a mechanic has different tools for their tasks. This one has an FPGA connected by both PCI-E and JTAG to allow for quick hardware prototyping. This one is connected to a high-throughput GPU for visualisations; that one to a high-capacity GPU for scientific simulations.</p>
<p>The general purpose hardware vendors want us to believe that an okay-at-anything computer is the best for everything: you don’t need a truck, so here’s a car. But when you’re hauling a ton of goods, you’ll find it cheaper and more satisfying to shell out more for a truck. Okay-at-anything is good for nothing.</p>
<p>Cover photo by <a href="https://unsplash.com/@serejahh">Serhii Butenko</a> on <a href="https://unsplash.com/photos/zx2Vc1zPDIs">Unsplash</a>.</p>
	</div></div>]]>
            </description>
            <link>https://deprogrammaticaipsum.com/the-untimely-demise-of-workstations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24977652</guid>
            <pubDate>Tue, 03 Nov 2020 08:34:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Security Hardening Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24977488">thread link</a>) | @robertwinter
<br/>
November 3, 2020 | https://elastisys.com/security-hardening-kubernetes/ | <a href="https://web.archive.org/web/*/https://elastisys.com/security-hardening-kubernetes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="7a49ff87" data-element_type="column"><div><div><div data-id="1b308d22" data-element_type="widget" data-widget_type="text-editor.default"><div><div><h2><span>Description</span></h2><p>Developers and operators in today’s digital world are facing an ever-increasing set of regulatory requirements, security challenges and privacy concerns. In addition to constant attacks on IT assets there is growing legal pressure to deliver and maintain regulatory guidelines in our networked world. Requirements such as PCI-DSS, HIPAA, GDPR or SOC2 are becoming the pre-requisite of any operation in various industries.</p><p>Modern cloud native architectures and Kubernetes provide tools to address these demands, but the knowledge of these tools and methods are not widely understood. Today what is needed most is guidance on what exists and how best to use the right resources to meet the security and compliance requirements while still benefiting from the speed and agility Cloud Native environments offer.</p><p>In this video Johan Tordsson, CTO of Elastisys, provides provide a deep dive on security development tools and open source Kubernetes services available to meet these growing needs.</p><h2>Follow us</h2><p>Elastisys is an active member of the cloud-native community and participates in public webinars and meetups. Keep up to date by <a href="https://www.linkedin.com/company/elastisys" target="_blank" rel="noopener">following Elastisys on LinkedIn</a>&nbsp;to never miss a public event. If you would like us to speak at your event, or conduct training in Kubernetes or related cloud-native technologies, don’t hesitate to&nbsp;<a href="https://elastisys.com/contact-us-contact-information-email-visit-us-social-media/">contact us</a>!</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://elastisys.com/security-hardening-kubernetes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24977488</guid>
            <pubDate>Tue, 03 Nov 2020 08:07:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning Rust as a Gopher, part 3]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24977373">thread link</a>) | @BookPage
<br/>
November 2, 2020 | https://levpaul.com/posts/rust-lesson-3-and-4/ | <a href="https://web.archive.org/web/*/https://levpaul.com/posts/rust-lesson-3-and-4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>Hello and welcome to the third post in my series about learning Rust. In case you want to hit it from the start, <a href="https://levpaul.com/posts/rust-lesson-1/">here’s</a> a link to the first one! This entire series covers my journey from being a completely land-locked Gopher to becoming (hopefully) a hardened Rustacean, able to skitter the hazardous seabed of any application safely.</p><p><em>Warning: Incoming opinion monologue; feel free to skip to <a href="#give-me-the-lessons">The Lesson Review</a> review if that’s what you’re after</em></p><h4 id="how-rust-is-makin-me-feel">How Rust is Makin' Me Feel</h4><p>Let me begin not by thwacking loosely about in concepts I know little yet of, as there’s plenty of time for that, but instead allow me to paint the landscapes I see for both Rust and Go. At quite the visceral it occurred to me that these modern languages are built not just to make our coding lives more delightful - but instead to shepherd us into particular engineering and organizational goals.</p><p>The needs for new general purpose languages no longer stem from the “simple” software problems. Take the problems of using variables (Assembly), using custom data types (C), cross-platform, cross-architecture compatibility (JVM languages) or even being dead simple (Python). Today’s languages can instead choose features from all the preceding and <em>then</em> apply engineering and organizational direction.</p><h4 id="the-coercion-of-go">The Coercion of Go</h4><p>I’ve been writing in Go as a hobby since 2014 but professionally only since 2018. As a hobbyist I’ll admit I used to think “Go is <em>opinionated</em>”. That seemed cool, because opinions mean something! Right? But <em>why</em> was it opinionated Levi, WHY? WAKE UP MAN!</p><p>Well today I have a completely different look on it. Go is simply a language that is very <em>safe</em> to share across engineers. This is because engineers don’t need to make a lot of decisions when they use Go. If an application has had its design completed in theory then in Go it often really is just a matter of whacking out the code to make it a reality.</p><p>Just look at how much of Go’s development tooling Google owns. With Java, I remember choosing between Ant or Maven for your build tooling. Go doesn’t let you chose. The closest we got to having a choice was with <code>dep</code> for dependency management. But finally Google caved and <code>gomod</code> was brought about as the standard. Go does its best to take choices away from you. You don’t need to chose between Tomcat or Jetty - the Go <code>net/http</code> package will handle 10kRPS for you no problem. Hell I’ve looked at apps serving 50kRPS, whilst <em>logging</em> a third of said requests simply using <code>fmt.Println</code>. You just don’t need to stray far from the standard library to scale and that is a huge plus of the language. (A large part of this is also comes from the fact that webservers haven’t changed a heck of a lot in the past 10 years so Go didn’t have to “keep up” - on the other hand my experience with http2 in Go has been far from ideal).</p><h5 id="_anyone_-can-pick-up-your-code-and-fix-it"><em>Anyone</em> can pick up your code and fix it</h5><p>This is by far the biggest selling point of using Go <em>in a company</em>. If you need to hire help you can find basically <em>anyone</em> with backend experience, and they will pick up 90% of Go in a week or two. You don’t need to worry at all if they have experience with Struts, JUnit or Spring - what’s in the standard library is plenty. I mean it. Do they need to know about passing pointers or values? Not really - general software engineering practices like peer review and simple unit testing will uncover those types of issues with ease.</p><p>Now on the other hand - who in their right mind would hire <em>me</em> to join their Rust team right now? Nobody - because I would be a gigantic liability to that team.</p><h5 id="gos-purpose-is-for-dev-shops-to-crank-out-web-services-that-are-scalable-easy-to-develop-and-do-not-require-mission-critical-performance">Go’s purpose is for dev shops to crank out web services that are scalable, easy to develop and do not require mission critical performance.</h5><h4 id="rust-no-rust">Rust no Rust</h4><p>I’m a noob. 100%. But even so, in my feeble mind I can already see what Rust is. I see a very sharp knife; but this knife is completely and utterly shrouded and encased in tamper-proof, child-proof, thief-proof hardened and sealed plastic shells. Yes shells as in the plural of shell. These shells are even adult-proof too, where the adult is a generic engineer trained generally in other languages only. The compiler is the packaging, and it will let you wield the knife when it knows exactly what your action plan is. -But oh no, not just any plan will do, your plan <em>must</em> adhere to each and every rule and regulation from the Knife Safety Measurement Act of 1938 and its associated amendments!! (This may not be strictly true as I’ve heard about an <code>unsafe</code> keyword).</p><p><em>But why so much plastic broseidon?</em> You know, and I know that it’s to keep mild-minded people like myself exactly, from nicking fingers with that very sharp knife. Warping back to a meta-level, those fingers don’t even necessarily belong to me the coder, but to the end users of the code. It is no secret to anybody even slightly interested in Rust that a major driving factor for the language was to be able to replace C++ code with something <em>as</em> efficient but much less susceptible to security exploits. Thus, the safety plastic aims not to protect individual coders, but the <em>coding organization</em>.</p><p>Okay, you’ve probably heard enough of my opinion, let’s move on before this analogy implodes and actually hurts someone.</p><hr><h2 id="give-me-the-lessons">Give Me The Lessons!</h2><h4 id="3-common-programming-conceptshttpsdocrust-langorgbookch03-00-common-programming-conceptshtml">3. <a href="https://doc.rust-lang.org/book/ch03-00-common-programming-concepts.html">Common Programming Concepts</a></h4><p>One of the first ‘huh’ moments in this lesson was this compiler message:</p><div><pre><code data-lang="rust"><span>compiler</span><span> </span><span>error</span>:
<span>For</span><span> </span><span>more</span><span> </span><span>information</span><span> </span><span>about</span><span> </span><span>this</span><span> </span><span>error</span><span>,</span><span> </span><span>try</span><span> </span><span>`</span><span>rustc</span><span> </span><span>--</span><span>explain</span><span> </span><span>E0384</span><span>`</span><span>.</span><span>
</span></code></pre></div><p>Naturally I ran the command listed, which took me to a <code>less</code> window (buffer?) containing the following:</p><div><pre><code data-lang="fallback">An immutable variable was reassigned.
Erroneous code example:
'''
fn main() {
    let x = 3;
    x = 5; // error, reassignment of immutable variable
}
'''
By default, variables in Rust are immutable. To fix this error, add the keyword
`mut` after the keyword `let` when declaring the variable. For example:
'''
fn main() {
    let mut x = 3;
    x = 5;
}
'''
</code></pre></div><p>…and this slightly let me down. There isn’t a whole lot of information in this “explanation”. I proceeded to allow <code>rustc</code> to “explain” some more random error codes to me, most of them seemed also to be quite small or to have been deprecated. I am hoping either A) I don’t have to use this feature much or B) I can make rustc/cargo/intellij just tell me the detailed stuff by default.</p><hr><div><pre><code data-lang="rust"><span>const</span><span> </span><span>MAX_POINTS</span>: <span>u32</span> <span>=</span><span> </span><span>100_000</span><span>;</span><span> </span><span>// wtf is this ugly numeric shit
</span></code></pre></div><p>For some reason this irked me when I first saw it (the comment taken verbatim from my lesson notes). On second look it actually seems really, really helpful for readability.</p><hr><h4 id="shadowinghttpsdocrust-langorgbookch03-01-variables-and-mutabilityhtmlshadowing"><a href="https://doc.rust-lang.org/book/ch03-01-variables-and-mutability.html#shadowing">Shadowing</a></h4><p>This seems like a really handy trick. You get to write code as if your variable was immutable, but the compiler does the switching for you. What is really messing my head up though is that you learn about Shadowing before you learn about Ownership. So does my naive understanding of shadowing change after this? I don’t think so … at least. Here’s something I wrote to verify my learnings:</p><div><pre><code data-lang="rust"><span>fn</span> <span>main</span><span>()</span><span> </span><span>{</span><span>
</span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>s</span><span> </span><span>=</span><span> </span><span>String</span>::<span>from</span><span>(</span><span>"hello"</span><span>);</span><span>
</span><span>    </span><span>let</span><span> </span><span>r1</span><span> </span><span>=</span><span> </span><span>&amp;</span><span>mut</span><span> </span><span>s</span><span>;</span><span>
</span><span>    </span><span>let</span><span> </span><span>r1</span><span> </span><span>=</span><span> </span><span>&amp;</span><span>mut</span><span> </span><span>s</span><span>;</span><span>
</span><span>    </span><span>println</span><span>!</span><span>(</span><span>"{}"</span><span>,</span><span> </span><span>r1</span><span>);</span><span>
</span><span></span><span>}</span><span>
</span></code></pre></div><p>…and it works. It also answers a question I had when originally learning ownership. For some reason when reading the examples in the book I came away thinking Rust could infer when immutable references' scopes end, but not mutable ones. I was puzzled by this and had a follow-up item but this little example proves I was wrong. Happy days!</p><hr><h5 id="small-nit">Small Nit?</h5><p>The <a href="https://doc.rust-lang.org/book/ch03-02-data-types.html#invalid-array-element-access">Invalid array element access example</a> didn’t work - it was supposed to produce a runtime error but instead it failed to compile:</p><div><pre><code data-lang="rust"><span>   </span><span>Compiling</span><span> </span><span>variables</span><span> </span><span>v0</span><span>.</span><span>1.0</span><span> </span><span>(</span><span>/</span><span>home</span><span>/</span><span>levi</span><span>/</span><span>rustprojs</span><span>/</span><span>variables</span><span>)</span><span>
</span><span></span><span>error</span>: <span>this</span><span> </span><span>operation</span><span> </span><span>will</span><span> </span><span>panic</span><span> </span><span>at</span><span> </span><span>runtime</span><span>
</span><span> </span><span>-</span>-&gt; <span>src</span><span>/</span><span>main</span><span>.</span><span>rs</span>:<span>5</span>:<span>19</span><span>
</span><span>  </span><span>|</span><span>
</span><span></span><span>5</span><span> </span><span>|</span><span>     </span><span>let</span><span> </span><span>element</span><span> </span><span>=</span><span> </span><span>a</span><span>[</span><span>index</span><span>];</span><span>
</span><span>  </span><span>|</span><span>                   </span><span>^^^^^^^^</span><span> </span><span>index</span><span> </span><span>out</span><span> </span><span>of</span><span> </span><span>bounds</span>: <span>the</span><span> </span><span>len</span><span> </span><span>is</span><span> </span><span>5</span><span> </span><span>but</span><span> </span><span>the</span><span> </span><span>index</span><span> </span><span>is</span><span> </span><span>10</span><span>
</span><span>  </span><span>|</span><span>
</span><span>  </span><span>=</span><span> </span><span>note</span>: <span>`</span><span>#[deny(unconditional_panic)]</span><span>`</span><span> </span><span>on</span><span> </span><span>by</span><span> </span><span>default</span><span>
</span></code></pre></div><p>I don’t even know if I should call this a nit or just straight up be impressed. Did Rust <em>evolve</em> to the point the <em>book</em> can no longer trick me into making a runtime panic?! This is some straight-jacket level packaging I swear to god. Much applause.</p><hr><h4 id="_a-smol-walk-in-the-woods_"><em>A smol walk in the woods</em></h4><p>Having picked up many a good pointer during this lesson I figured I had bumped myself up a couple of notches. Maybe white-belt, double-yellow-tip or something along those lines… “<em>Let’s go for a wander</em>” I thought to myself with quiet confidence. Looking left, and then looking right, under the shelter of a single raised eye-brow I chose to descend toward the belly of Rust.</p><p><em><strong><code>Ctrl + *click*</code></strong></em></p><p>I chose a simple avenue. I chose something concrete to all beginners. I chose the pinnacle of <code>Hello_World</code>…</p><p>I chose to dive into <code>println!</code></p><p>… and dive I did. Straight into the ground after clanking my head into a hard iron post of this macro. My eyes but glimpsed Sauron directly and from then on and always, I am blind:</p><div><pre><code data-lang="rust"><span>#[macro_export]</span><span>
</span><span></span><span>#[stable(feature = </span><span>"rust1"</span><span>, since = </span><span>"1.0.0"</span><span>)]</span><span>
</span><span></span><span>#[allow_internal_unstable(print_internals, format_args_nl)]</span><span>
</span><span></span><span>macro_rules</span><span>!</span><span> </span><span>println</span><span> </span><span>{</span><span>
</span><span>    </span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>(</span><span>$crate</span>::<span>print</span><span>!</span><span>(</span><span>"\n"</span><span>));</span><span>
</span><span>    </span><span>(</span><span>$($arg</span>:<span>tt</span><span>)</span><span>*</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>({</span><span>
</span><span>        </span><span>$crate</span>::<span>io</span>::<span>_print</span><span>(</span><span>$crate</span>::<span>format_args_nl</span><span>!</span><span>(</span><span>$($arg</span><span>)</span><span>*</span><span>));</span><span>
</span><span>    </span><span>})</span><span>
</span><span></span><span>}</span><span>
</span></code></pre></div><p>What in God’s sweet name is this acrid assault on all of my senses?</p><p>I am going to be honest here. There is no way in hell I will understand this macro by the end of my twentieth lesson. Will I?
I’m not sure actually. I guess there’s hope? Chapters <a href="https://doc.rust-lang.org/book/ch10-00-generics.html">10</a>, <a href="https://doc.rust-lang.org/book/ch14-00-more-about-cargo.html">14</a> and <a href="https://doc.rust-lang.org/book/ch19-00-advanced-features.html">19</a> all look they will be mandatory. <em>Hoping Intensifies … ?</em></p><hr><h4 id="expressions-versus-statements">Expressions versus Statements</h4><blockquote><p>If you add a semicolon to the end of an expression, you turn it into a statement, which will then not return a value. Keep this in mind as you explore function return values and expressions next.</p></blockquote><p>This was a mind fuck - about 10 minutes before reading this I thought to myself that semi-colons seemed optional and kind of pointless in rust. Boy was I well outside the woods.</p><p>A later thought did have me wondering though; do Rustaceans really just write expressions at the end of their getter functions or is it more common to explicitly <code>return</code>?</p><hr><blockquote><p>In Rust, the idiomatic comment style starts a comment with two slashes, and the comment continues until …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://levpaul.com/posts/rust-lesson-3-and-4/">https://levpaul.com/posts/rust-lesson-3-and-4/</a></em></p>]]>
            </description>
            <link>https://levpaul.com/posts/rust-lesson-3-and-4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24977373</guid>
            <pubDate>Tue, 03 Nov 2020 07:46:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FreeBSD Wall Display Computer – TykBlog]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24977319">thread link</a>) | @rodrigo975
<br/>
November 2, 2020 | https://blog.tyk.nu/blog/freebsd-wall-display-computer/ | <a href="https://web.archive.org/web/*/https://blog.tyk.nu/blog/freebsd-wall-display-computer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    

                    <!-- Author -->
                    <p>
                        by <a href="https://blog.tyk.nu/about/">Tykling</a>
                    </p>
                    <hr>
                    
                    <!-- Date/Time -->
                    <p><span></span> 10. oct 2020 16:22 UTC</p>

                    <hr>

                    <!-- Post Content -->
                    <p>I've recently added a wall mounted 30" monitor for Grafana in my home. I can highly recommend doing the same, especially in a world where more work from home is becoming the norm.</p>

<p>Having metrics visible at all times can be incredibly helpful in spotting trends and issues. This is the reason we all have wall mounted Grafanas in our workplaces! Since we are all going to be working from home for the foreseeable future it makes sense to have visible metrics at home as well. Also, much of the stuff I need metrics for is not work related at all - <a href="https://blog.uncensoreddns.org/">UncensoredDNS</a> for example, the <a href="https://bornhack.dk/bornhack-2020/">BornHack</a> infrastructure, and so on. I see no reason why projects run outside of $dayjob should receive any less attention, such as visualisation of metrics.</p>

<p>Sometime before summer I physically mounted the screen using <a href="https://vivo-us.com/collections/monitor-mounts/products/stand-v002l">this very nice</a> over/under 2 monitor stand, and then started considering which computer to use for it. Ideally something I already had lying around, and of course something with enough power to run some Grafana dashboards without choking.</p>

<p>Not for a moment had I anticipated that actually displaying the graphs in a browser that doesn't crash constantly would be the most time-consuming part of getting this up and running. I mean, I've spent hours playing with various Prometheus exporters for all the different servers I run (and Ansible roles for them). I've also spent hours fiddling with Grafana dashboards until they show the level of information I like. Both of these are complex jobs and and I am absolutely fine with spending time on them. But when I finally had nice working dashboards in my Firefox browser on my laptop I fully expected it to be trivial to put those on a monitor on the wall. It was not. This tale is left here for future metrics aficionados in the hopes that you will spend less time on this dreary task than I did.</p>

<p>I've documented the failed attempts as well as the final well-working solution. Feel free to skip over the first two sections if you are just here to learn what works :)</p>

<h3>First Attempt: ODROID-C2 with Ubuntu</h3>
<p>Originally I wanted to use an <a href="https://wiki.odroid.com/odroid-c2/odroid-c2">ODROID C2</a> which I had lying around because I used it as a mediacenter with <code>Kodi</code> provided by <code>Liberelec</code> previously. This seemed like a good choice, I mean if it can show a 1080p video without choking it should be able to render a few <code>Grafana</code> dashboards, right?</p>

<p>The <code>ODROID-C2</code> is an <code>Amlogic S905</code> SOC with a <code>Cortex A53</code> ARMv8 64bit CPU. It has 4 cores and 2GB RAM. It supports <code>eMMC</code> storage which is a nice and faster alternative to the SD cards used by many of the "Raspberry PI-sized" computers that exists today.</p>

<p>I tried to figure out wether it was possible to run <code>FreeBSD</code> on it, but the <a href="https://www.freebsd.org/platforms/arm.html">ARM Wiki page</a> seems to say that 64bit ARM support is still being worked on. I thought it was too much to hope for anyway.</p>

<p>Then I tried to go for a stock Debian, but that didn't boot at all. Turns out I need to use either the <a href="https://wiki.odroid.com/odroid-c2/os_images/ubuntu/ubuntu">Ubuntu</a> image provided by the ODROID people, or a <a href="https://wiki.odroid.com/odroid-c2/os_images/third_party">third party</a> OS image.</p>

<p>Once I got Ubuntu up and running and found a Firefox browser it quickly became apparent that it would not work. The browser kept freezing up, or crashing, or both. I tried using Chromium which annoyingly worked a bit better. It was not stable, but it would run for half a day or maybe a day and then stop working somehow. And this was with just one dashboard, If I opened another tab with another Grafana dashboard it made matters worse.</p>

<p>It wasn't immediately clear what the problem was, in hindsight it was probably RAM, but either way I decided to try something else.</p>

<h3>Second Attempt: Raspberry PI 3b+ with Raspbian</h3>
<p>I had an RPI3b lying around and decided to try that instead. I am not a big fan of the RPI platform in general, I've had way too many weird issues over the years, I guess I just prefer a more normal computer. But I needed something to show my graphs, so I launched <a href="https://www.raspberrypi.org/downloads/noobs/">NOOBS</a> and asked it to install <code>Rasbbian</code> and I was pretty soon up and running with graphs on my wall again.</p>

<p>The Raspberry PI 3b+ has a full 1GB of RAM, much more than previous PIs, but only half of what the <code>ODROID-C2</code> has. It still performed about the same as the <code>ODROID-C2</code>. It didn't work at all with Firefox, with Chromium it was okay with a single tab or two, but after 12-24 hours it would stop working. Sometimes it would be an "unresponsive tab" error from the browser, and sometimes the whole OS would freeze up completely.</p>

<p>Around this time the annual <a href="https://bornhack.dk/bornhack-2020/">BornHack</a> was approaching, so my attention was needed elsewhere. I made due with the unstable PI for a couple of months - daily reboot helped a little, but it isn't exactly a nice solution.</p>

<h3>Third Time is the Charm: A NUC with FreeBSD</h3>
<p>So last week I finally got around to taking another whack it. No more beating around the bush, I was going to buy something with enough power, and then some. I started looking around and soon found that a Danish shop with pickup service had an Intel <code>NUC8I7BEH</code> in stock. While physically larger than the Raspberry PI and ODROID-C2 (it is just under 12x12cm long and wide, and just under 6cm tall, including the VESA mount), it is still a pretty small computer.</p>

<p>I picked it up around along with 2 sticks of <code>Kingston 16GB DDR4 2400MHz SODIMM</code> non-ECC RAM, (the NUCs are delivered as a "kit" without RAM and storage) and a <code>Samsung 870 QVO MZ-77Q1T0BW</code> 1TB SATA SSD. Assembling it was really easy, four screws and and a couple of minutes later the RAM and SSD were in, and the NUC POST revealed it found all 32GB RAM and also the SSD. It refused to boot from the FreeBSD installer USB stick though. This was because secure boot was enabled in the BIOS. After disabling it the FreeBSD install was absolutely standard, no issues at all.</p>

<p>This was in the beginning of October 2020 so the latest <code>12-STABLE</code> was something like <code>12.2-BETA3</code> or so, it doesn't really matter since I upgrade to latest <code>12-STABLE</code> after installing anyway. As always I used the auto-ZFS option in the installer so I can use <code>bectl</code> to make nice boot environments for easy rollbacks in case of problems when upgrading.</p>

<p>A quick <code>pkg install xorg slim fluxbox firefox</code> and a bit of fiddling later I was looking at a very smoothly running Grafana dashboard in X. The rest of this blogpost is about the configuration of FreeBSD, X, Slim, Fluxbox and Firefox for an ideal wall-mounted Grafana screen. Much of this is done in Ansible, but not all of it. I've documented everything here for the sake of completeness, but a lot of basic configuration is done by my Ansible roles, and is not that relevant for this blogpost. Stuff like configuring syslog, monitoring, SSH keys and all the other sysadminy stuff that all machines need. This blogpost just focuses on what to do to go from a fresh FreeBSD machine to a well oiled Grafana wall display.</p>

<p>Finally: I realize that comparing a NUC to a Raspberry PI is not even close to a fair comparison, for starters the NUC is ten times more expensive. It has a powerful <code>CPU: Intel(R) Core(TM) i7-8559U CPU @ 2.70GHz (2712.12-MHz K8-class CPU)</code> and 32GB memory, so obviously it is going to perform a lot better. But overkill was the whole point of this exercise! I  had spent <i>far</i> too much time faffing about with insufficient hardware and at this point I was perfectly happy to throw money at the problem until it went away. YMMV.</p>

<h3>Dedicated User</h3>
<p>First off I added a dedicated user to show the graphs, since I intend to enable autologin for this setup. This user is not going to have <code>wheel</code> or <code>sudo</code> access, it really only has to be able to start X and Firefox. I also have another user with my regular SSH key which I used for debugging and whatever else is needed (rarely sysadm stuff though, since that is handled by Ansible).</p>


<h3>X Configuration</h3>
<p>On modern FreeBSD X mostly configures itself, but the <code>i7-8559U</code> inside the <code>NUC8i7BEH</code> is a Gen9 Intel Coffee Lake CPU, the integrated <code>Iris Plus Graphics 655</code> GPU inside it is too new to be supported by the <code>i915kms</code> module in FreeBSD base. This is the output from <code>pciconf -lv</code> concerning the GPU:</p>

<pre>vgapci0@pci0:0:2:0:     class=0x030000 card=0x20748086 chip=0x3ea58086 rev=0x01 hdr=0x00
    vendor     = 'Intel Corporation'
    device     = 'Iris Plus Graphics 655'
    class      = display
    subclass   = VGA
</pre>

<p>Fortunately there is a meta-port called <code>drm-fbsd12.0-kmod</code> (which also works on 12.2 it seems) which installs a newer <code>i915kms.ko</code> which supports the GPU. Since building the driver requires kernel sources it is not available from the official FreeBSD package builders, and since I needed to upgrade anyway I started a <code>buildworld</code> with the following beauty of a oneliner (run as root, not with sudo): <code>time (make -j$(sysctl -n hw.ncpu) buildworld &amp;&amp; make -j$(sysctl -n hw.ncpu) kernel &amp;&amp; mergemaster -pFUi &amp;&amp; make installworld &amp;&amp; mergemaster -FUi &amp;&amp; make BATCH_DELETE_OLD_FILES=yes delete-old &amp;&amp; make BATCH_DELETE_OLD_FILES=yes delete-old-libs) &amp;&amp; date</code>. Note that a reboot before the first <code>mergemaster</code> is recommended, but for small upgrades I usually don't bother. If <code>installworld</code> fails with weird errors try again after a reboot :)</p>

<p>Including a few minutes for some <code>mergemaster</code> fun near the end it took just 59 minutes before I had a newly built world and kernel. Then I could build the driver from ports, and add the line <code>kld_list="boot/modules/i915kms.ko"</code> to <code>/etc/rc.conf</code> and reboot. After the reboot X started with no issues at all. For reference this is a <code>dmesg(8)</code> from the NUC after the new driver was enabled (I've highlighed the GPU related stuff):</p>

<pre>[tykling@nuc1 ~]$ sudo cat /var/run/dmesg.boot 
---&lt;<boot>&gt;---
Copyright (c) 1992-2020 The FreeBSD Project.
Copyright (c) 1979, 1980, 1983, 1986, 1988, 1989, 1991, 1992, 1993, 1994
        The Regents of the University of California. All rights reserved.
FreeBSD is a …</boot></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.tyk.nu/blog/freebsd-wall-display-computer/">https://blog.tyk.nu/blog/freebsd-wall-display-computer/</a></em></p>]]>
            </description>
            <link>https://blog.tyk.nu/blog/freebsd-wall-display-computer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24977319</guid>
            <pubDate>Tue, 03 Nov 2020 07:35:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimization: what I did to make the game 300 times faster]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24977108">thread link</a>) | @Woseseltops
<br/>
November 2, 2020 | https://thesaplinggame.com/devlogs/optimization.html | <a href="https://web.archive.org/web/*/https://thesaplinggame.com/devlogs/optimization.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_column">
		<div id="main_area">
			
<div id="label_bar"><p>Announcement</p><p>Technical</p><p>Graphics</p><p>Music</p></div>
<p id="first_p">A major point of feedback for evolution simulator The Sapling is that the players wanted larger levels. To make this possible, I spent three months optimizing the underlying game engine. This article is an in-depth explanation of one of the main insights I had. There are several interactive simulations you can play with in your browser to get a deeper understanding of how everything works.</p>
<p><span id="first_character">T</span>he first major update for The Sapling, the flower update, was released in September. It adds pollination, flowers (obviously), a new scenario, a complete overhaul of the sandbox level, bioluminescence and much more. A number of scenes from the trailer:</p>
<video width="320" loop="" autoplay="" muted="">
  <source src="https://thesaplinggame.com/devlogs/optimization/flower_highlights.mp4" type="video/mp4">
</video>

<p>Importantly, it addresses a major point of feedback that kept coming back: players wanted more space for their creations to grow and evolve. I couldn't easily make the levels larger, however, because the game already had performance problems in the smaller levels and with each new spot where organisms could live this would get worse exponentially. The hard part is that there are not one, but two computationally heavy things going on at the same time: simulating an ecosystem where hundreds of organisms are all doing their own things (moving, eating, reproducing, mutating) AND visualizing these hundreds of objects. With larger levels, this would be thousands, essentially bringing the game to a halt with 1 frame per 5 seconds (FPS) instead of the regular 60 per 1 second. </p>
<p>Besides my obvious desire to please the players, having larger levels was also crucial for my own ambitions with the game, because a number of the simulation mechanics didn't really work with the smaller maps; for example, why evolve an instinct to run away from a predator if you have nowhere to go? Or for plants, why evolve things like bark or high leaves if the biggest reason that your offspring is dying is because all seeds are landing on spots that are already taken? In nearly 100% of the cases, all plants evolved to do was getting as much offspring as possible, in the hopes that at least one of them by accident landed in a spot that was free.</p>
<p>In other words, if there was going to be one major feature in the first big update, it should be larger maps. To make this possible, I spent 3 months in the beginning of 2020 with that one focus: optimize, optimize, optimize the game's code, so I could get that FPS up and shave off more of the milliseconds it takes to render a scene. It was frustrating at times, but the main feeling I remember was actually excitement, as this really forced me to investigate the major bottlenecks (when I close my eyes, I can still see the Unity profiler), and come up with several new creative solutions for them. During this period I was reading a book about how John Carmack, the brilliant programmer behind the first Doom engine, was doing endless optimizations to make first person shooters a reality in the 90s, which was a great help in keeping me motivated.</p>
<p>While I implemented all kinds of larger and smaller ideas that made significant positive contributions to the performance of the game, there is one insight that had the biggest impact for the visualization part of the problem (how do you show thousands of unique organisms on screen?), which is to <strong>fake it before you make it</strong>. Let's go through my thought process step by step to see what I mean by that in this context. For every step, there is an interactive simulation you can run in your browser, so you can play with the idea yourself.</p>
<h2>Step 1: the raw, unoptimized goal</h2>
<p>This is the basic idea, without any optimization: players can add their self created species somewhere in the world, and see whether it is strong enough to survive. In the interactive example below, you can add two species, 1 and 2, and then run the simulation. </p>








<p>The simulation and subsequent visualization should be instant in your browser, but this is of course a 2D table with precreated images. When we have to create fully animated 3D models in a 3D world instead, it quickly becomes too much. </p>
<hr>
<p>The main problem is that building an organism in 3D is expensive.</p>
<hr>
<p>The main problem is that <strong>building/visualizing an organism in 3D is expensive</strong>. While I have done major rewrites of the code that builds plants and animals, mostly focusing on not doing things twice and skipping parts of the procedure that are not 100% necessary (like building the roots of plants that are underground anyway), creating new organisms from scratch remained, and still is, expensive.</p>
<h2>Step 2: object pooling</h2>
<p>The textbook solution when a lot of objects need to be created and removed in a game is to use object pooling. The idea is that when an object dies (in The Sapling, quite literally), the game object is not destroyed but reincarnates as the next object that is created, instantly moving to the position of the newborn organism and resetting any animations it was showing. That is, you think you are looking at a large amount of objects being created and destroyed again, but in reality you are looking at a smaller amount of objects that are just changing locations quickly.</p>
<p>In the interactive example below, I have added a pool to the right. When plants die, their models are either immediately reused or are stored in the pool until they are needed again, so a lot less 3D models need to be created. Comparing this simulation to the one above, the difference becomes clear when you skip 10 days a few times; in the first simulation, the model identifier (the part below each plant were it says 'model 10', for example) gets higher and higher, while here it stays low, reflecting the small number of 3D models that needed to be created.</p>




<p>Object pooling greatly improves the FPS in a stable ecosystem, as you can simply reuse what you already have and there is no need to create new objects on the fly. Unfortunately, in practice ecosystems in the game are very frequently unstable, most notably in the beginning of every new scenario when there is empty land to colonize. In other words, an object pool is not going to help if that pool is empty... so we'll also need a faster way to fill it.</p>
<h2>Step 3: prebuilt organism library</h2>
<p>So far, when a plant was not available in the pool, we built it from scratch. If we are building a 3D model that we have built before, however, this is not necessary: why not store an example somewhere and just copy it? This is more expensive than taking an object from the pool, but way cheaper than building it from scratch. In the current example, there is a limited number of species (species 1 and species 2), so that would mean we only have to build a 3D model two times, and then be done with it.</p>




<p>At this point, we will get an acceptable FPS in an ecosystem with a small number of species, and no variation within a species... which is actually the case during the scenarios! In the sandbox mode, however, there is a <em>random mutations mode</em> that has a 30% chance of introducing a random change to a newborn plant or animal; that is, for 1 out of 3 newborn plants we won't have anything in the object pool AND the prebuilt organism library, so we're back to building from scratch.</p>
<h2>Step 4: faking it and showing ancestors instead</h2>
<p>I came up with this final step when actually playing around with the (then still sluggish) random mutations mode in larger levels. The main insight is that in random mutations mode the player has no idea of what something is supposed to look like. For example, if a new plant is a little taller than its ancestors, but this is not shown to the player, will the player ever know? Almost certainly not, in particular if you take into account that the player is often looking at hundreds of plants and animals simultaneously. On the other hand, will the player notice performance problems? Yes, for sure... so a 100% smooth experience should get a higher priority than a 100% accurate visualization.</p>
<hr>
<p>The player has no idea of what something is supposed to look like</p>
<hr>
<p>In practice, this means that if random mutation leads to a completely new organism, the game will not automatically build it from scratch, even though it is not in the pool or the library. Instead, it will look at what was shown for the parent and show this as a substitute. Later, when the game has time to breathe, the missing model might be added to the library. The game keeps track which organisms have a 'fake' appearance, and I can vary in how fast gaps in the library should be closed. Right now, I have settled on building a maximum of 1 organism per second. </p>
<p>In the simulation below, random mutations are turned on for the first time. This means that after some time you will not only see plants like the ones you added yourself (species 1 and species 2); instead, the number will go up each time a newborn plants changes a little bit from its parent, so after some time you will see species 3, species 4, species 5, etc. The accompanying model, however, will NOT change, meaning that the real plant and its 3D model go out of sync; the name will turn orange if this is the case. So you might see the model of a plant 1, while the text in orange tells you it is actually a plant 3. To catch up, you have to click the 'Add 1 model to library' button.</p>




<p>And this way, we have scaled back from building hundreds of 3D models per second to just one! Of course, there are a number of details, quirks and edge cases that I have left out of the explanation above to keep things simple. Two of them I want to mention to give you a more complete idea of the problem:</p>
<ul>
<li>In the simulation above, whenever you create a new 3D model, it's just the next one in line. In the real game, I'm trying to do this smarter by looking at which organisms are visually the most different from the 3D model they are using. That is, an animal that evolved an extra pair of feet is way more likely to get its model updated than a plant that evolved deeper underground roots.</li>
<li>When you leave the simulation running for a longer …</li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thesaplinggame.com/devlogs/optimization.html">https://thesaplinggame.com/devlogs/optimization.html</a></em></p>]]>
            </description>
            <link>https://thesaplinggame.com/devlogs/optimization.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24977108</guid>
            <pubDate>Tue, 03 Nov 2020 06:55:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Host Your Own Private Git Repos]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24976912">thread link</a>) | @deafcalculus
<br/>
November 2, 2020 | http://www.sagargv.com/blog/host-your-own-private-git-repos/ | <a href="https://web.archive.org/web/*/http://www.sagargv.com/blog/host-your-own-private-git-repos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p><em>Mar 31, 2018</em></p>
<p>Hosting git repos on your own server is actually quite easy.
Login to the server, create a new directory, and initialize a bare repo:</p>
<pre><code>mkdir foo.git
cd foo.git
git init --bare
</code></pre>

<p>That's it! Now, from the client, clone this repo with:</p>
<pre><code>git clone username@example.com:path/to/foo.git
</code></pre>

<p>Having a dedicated user for git repos on the server makes it easier share access to the repo.
Create a new user <code>git</code> with a login shell restricted to git commands:</p>
<pre><code>sudo adduser --shell $(which git-shell) git
</code></pre>

<p>Now create a repo in the home directory of the <code>git</code> user:</p>
<pre><code>cd /home/git
sudo -u git mkdir bar.git
cd bar.git
sudo -u git git init --bare
</code></pre>

<p>As before, clone the new repo from the client using:</p>
<pre><code>git clone git@example.com:bar
</code></pre>

<h2>Backup the repos</h2>
<p>This is my script to take daily backups of all the git repos on the server to Amazon S3.</p>
<pre><code>#!/bin/bash

set -e

GITDIR=/home/git
TMPDIR=/tmp/gitbackup

renice -n 15 $$

trap "rm -f /tmp/gitbackup/*.git.tar.gz" EXIT

mkdir -p ${TMPDIR}
cd ${TMPDIR}

for proj in ${GITDIR}/*.git; do
    base=$(basename $proj)
    tar -C $GITDIR -zcf ${base}.tar.gz $base
done

export AWS_ACCESS_KEY_ID=xxxxx
export AWS_SECRET_ACCESS_KEY=yyyyy
export AWS_DEFAULT_REGION=us-west-2

aws s3 cp ${TMPDIR}/*.git.tar.gz s3://mygitbucket/
</code></pre>

<p>If the repos are large, it might be worthwhile checking whether
the hash of the gzipped repo has changed before uploading.
It's also good idea to use <code>envdir</code> to manage the access keys rather
than putting them in the backup script.</p>
<h2>Web front-end using cgit and nginx</h2>
<p>Sometimes it's useful to view source code and commits on a
web browser. <code>cgit</code> is an awesome light-weight webapp for this.
Unlike heavy apps like GitLab, <code>cgit</code> needs no database, which
reduces the administrative burden.</p>
<p>Install cgit, nginx, fcgiwrap, and apache-tools (to create a <code>.htpasswd</code> file).</p>
<pre><code>sudo apt install cgit nginx fcgiwrap apache2-utils
</code></pre>

<p>Specify the location of the git repos and static assets in the 
<code>cgit</code> config at <code>/etc/cgitrc</code>.</p>
<pre><code>css=/cgit-static/cgit.css
logo=/cgit-static/cgit.png
favicon=/cgit-static/favicon.ico

#source-filter=/usr/lib/cgit/filters/syntax-highlighting.py

scan-path=/home/git/
</code></pre>

<p>To get syntax highlighting, install <code>python-pygments</code> and uncomment the source-filter option.</p>
<p>If you'd like to password protect access to <code>www.example.com/git/</code>, create a <code>.htpasswd</code> file:</p>
<pre><code>sudo htpasswd /etc/nginx/.htpasswd &lt;username&gt;
</code></pre>

<p>This is my <code>nginx</code> conf file to serve <code>cgit</code> from <code>www.example.com/git/</code>.</p>
<pre><code>server {
    listen 80;
    listen [::]:80;

    server_name www.example.com;

    location /.well-known/acme-challenge/ {
        root /var/www/www.example.com;
    }
    location / {
        return 301 https://www.example.com$request_uri;
    }
}

server {
    listen 443 ssl;
    listen [::]:443 ssl;

    server_name www.example.com;

    ssl_certificate /etc/letsencrypt/live/www.example.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/www.example.com/privkey.pem;

    location /cgit-static/ {
        alias /usr/share/cgit/;
    }

    location /cgit/ {
        auth_basic "Restricted";
        auth_basic_user_file /etc/nginx/.htpasswd;

        include fastcgi_params;
        fastcgi_split_path_info ^(/cgit)(.*)$;
        fastcgi_param   PATH_INFO        $fastcgi_path_info;
        fastcgi_param   SCRIPT_FILENAME  /usr/lib/cgit/cgit.cgi;
        fastcgi_param   QUERY_STRING     $args;
        fastcgi_param   HTTP_HOST        $server_name;
        fastcgi_pass    unix:/var/run/fcgiwrap.socket;
    }

    location / {
        root /var/www/www.example.com;
    }
}
</code></pre>

<p>You might also want to restrict repo access to only whitelisted IPs.</p>
<hr>
<p>
    <a href="http://www.sagargv.com/blog/">Archive</a> ·
    <a href="http://www.sagargv.com/blog/atom.xml">RSS</a> ·
    <a href="http://eepurl.com/doq18z" rel="nofollow" target="_blank">Mailing list</a>
</p>

        </div></div>]]>
            </description>
            <link>http://www.sagargv.com/blog/host-your-own-private-git-repos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24976912</guid>
            <pubDate>Tue, 03 Nov 2020 06:22:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nassim Taleb vs. Nate Silver: who is right about election forecasting?]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 101 (<a href="https://news.ycombinator.com/item?id=24976175">thread link</a>) | @probe
<br/>
November 2, 2020 | http://quant.am/statistics/2020/10/11/taleb-silver-feud/ | <a href="https://web.archive.org/web/*/http://quant.am/statistics/2020/10/11/taleb-silver-feud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Perhaps lost in the whirlwind of presidential name-calling, a lesser-known multi-year old feud has resurfaced on Twitter this election season. Nate Silver is the founder of <a href="https://fivethirtyeight.com/">FiveThirtyEight</a> and is a popular statistician frequently called upon by media members to give commentary and expertise on election forecasting. Nassim Taleb is a statistician/quant turned philosopher, perhaps most well known for authoring the book “The Black Swan”. He is second most well known for calling people names on Twitter. In this 2018 instance he seemed to take issue with FiveThirtyEight’s election forecasts, saying that <a href="https://twitter.com/nntaleb/status/1059202026184282113">“klueless Nate Silver” “doesn’t know how math works”</a>, among a host of other insults. Silver responded that Taleb was an <a href="https://twitter.com/NateSilver538/status/1062782704159256576">“intellectual-yet-idiot”</a>, an phrase coined by Taleb himself. Ouch. A litany of statisticans, mathematicians, and data scientists came out of the woodwork to take sides. Taleb himself <a href="https://twitter.com/nntaleb/status/1314902682570764288">doubled down</a> on Oct. 10, 2020, again calling Silver “totally clueless”.</p>

<p>In this article I take a look behind the mathematical premises of Taleb’s arguments, and give intuitive explanations of why or why not they hold up. In short, while Taleb’s math is sound, he still manages to miss the mark by ignoring the nuance of Silver’s forecasts.</p>

<p>Taleb’s main gripe is that forecasters change their opinion too much over time. Take a look at FiveThirtyEight’s forecast from the 2016 presidential election, where the probability of Clinton winning peaked at 90%, and hit a low of 50%. 
<img src="http://quant.am/assets/2016election.png" alt="2016 election"></p>

<p>Taleb insists that Clinton never should’ve received a probability of winning of 90%. Even if polls were heavily in favor of Clinton at the time, he says Silver should’ve taken into account the uncertainty that polls would change over the next few months leading up to the election, or the possibility of major news breaking. If Silver had factored in the “unknown unknowns” his forecast should’ve been closer to 50%. In essence, this single number should reflect all <em>current and future uncertainty</em>. Taleb constructs this argument by way of quantitative finance, which perhaps led to him and traditional statisticians talking past each other. In the following sections I step through his argument in intuitive terms.</p>


<p>A well known truth to economists, quants, and traders: if I tell you a number, I must be willing to transact at that number. If I tell you the fair value of this house is $500,000, I must be willing to buy AND sell at that price. Otherwise, the number I gave you is meaningless. Likewise, if I tell you the probability of Biden winning this election is 73%, I must be willing to pay $0.73 to make the following wager: if Biden wins I receive $1, if he loses I receive $0.</p>

<p>This is important because it turns the predicted probabilities into a tradeable financial instrument known as a binary option. If the prediction is 50%, I can buy the option at $0.50. If the prediction moves to 65%, I can now sell the option at $0.65, turning a $0.15 profit.</p>

<p>This brings us to another important principle known as the <em>no-arbitrage condition</em>. If the election predictions are accurate, there should be no way for a trader to make guaranteed money by trading this option. To give an illustrative example, let’s say that we live in an unchanging world where the probability of Candidate A winning is static at 50%. If a pollster does not report a static forecast day after day, he will create an arbitrage opportunity. We will sell when the prediction is above 50%, and buy below. 
<img src="http://quant.am/assets/arbitrage-pollster.jpeg" alt="Arbitrage condition"></p>

<p>OK, so now we’ve established that if an arbitrage condition exists, then the pollster is wrong and should not have made that prediction in the first place. Still, it’s not obvious that there’s an arbitrage condition within Silver’s predictions yet (remember, the trader doesn’t have access to an oracle, and only has the same information available to him as the pollster). There’s two more building blocks that we need in order to establish an arbitrage condition.</p>


<p>To paraphrase Taleb, if I tell you an event has a 0% chance of occurring, I cannot change my mind and tell you tomorrow it now has a 50% chance of occurring. Otherwise I shouldn’t have told you it has a 0% chance in the first place. Probability and confidence are inextricably linked, and the number a pollster predicts should encapsulate both. To go to the other extreme, if the uncertainty is extremely high (and therefore confidence low), <em>it does not matter what the polls today are saying</em>. I should give both candidates a 50% chance of winning, because I am admitting the extremely likely possibility that an external event will happen that will invalidate today’s polls. To put it in technical terms, maximum uncertainty implies maximum entropy, and the maximum entropy distribution on the [0, 1] interval is the uniform distribution, which has a mean at .5. The following figure (from <a href="https://arxiv.org/pdf/1703.06351.pdf">this paper</a>) shows the relationship between probability (x-axis) and volatility (y-axis) under a specific option pricing formulation.
<img src="http://quant.am/assets/confidence-probability.png" alt="Confidence vs volatility"></p>

<p>At this point we are suspecting something doesn’t look right with FiveThirtyEight’s predictions, as they seem to have both high volatility and high probability, which contradict each other. Where is the threshold though? How can we prove that the volatility is too high?</p>


<p>Now we’re going to go a little bit technical and show that a no-arbitrage condition was likely violated. The basic construction is as follows:</p>

<ol>
  <li>In order to satisfy the no-arbitrage condition, all information must be “priced in” into the pollster’s current prediction.</li>
  <li>Therefore, the time series of predictions must be a martingale.</li>
  <li>Martingales cannot show trending or mean-reverting behavior, therefore Silver’s predictions violated the martingale property, and therefore the no-arbitrage condition.</li>
</ol>

<p>The definition of a martingale is a stochastic process \(X_1, X_2, ... X_t\) that satisfies</p><p>

\[E[X_{t+1} | X_1, ... ,X_t] = X_t\]

</p><p>To quote <a href="https://www.researchgate.net/profile/Christopher_Wlezien/publication/344419648_Information_incentives_and_goals_in_election_forecasts/links/5f73c994a6fdcc0086484861/Information-incentives-and-goals-in-election-forecasts.pdf">Andrew Gelman</a>,</p>

<blockquote>
  <p>In non-technical terms, the martingale property says that knowledge of the past will be of no use in predicting the future…One implication of this is
that it should be unlikely for forecast probabilities to change too much during the campaign (Taleb, 2017). Big events can still lead to big changes in the forecast: for example, a series of polls with Biden or Trump doing much better than before will translate into an inference that public opinion has shifted in that candidate’s favor. The point of the martingale property is not that this cannot happen, but that the possibility of such shifts should be anticipated in the model, to an amount corresponding to their prior probability. If large opinion shifts are allowed with high probability, then there should be a correspondingly wide uncertainty in the vote share forecast a few months before the election, which in turn will lead to win probabilities closer to 50%.</p>
</blockquote>

<p>In other words, all information is already priced into the current market. If it were not so, a trader could make money by taking advantage of the information that is not priced in already. So last thing we need to check: is it likely that Silver’s predictions have the martingale property? It is not in dispute that the answer is no…it shows clear mean-reversion behavior and can be validated by a statistical test of the martingale hypothesis (for example, a <a href="http://www.planchet.net/EXT/ISFA/1226.nsf/9c8e3fd4d8874d60c1257052003eced6/35822efeb009804cc1257afe006b0063/$FILE/11park.pdf">Kolmogorov-Smirnov test</a>). It seems that Taleb’s math is sound here. So where did he go wrong?</p>


<p>I believe Nate Silver is answering a subtly different question with his election forecasts. Each data point that Silver produces is answering the question: <em>if the election were to happen today</em>, what is the probability of each candidate winning? I argue that this is a valid and useful formulation. To put it slightly differently: if the question is “Who will win the election on Nov. 3?”, which of the following answers is more satisfying?</p>

<ul>
  <li>“If nothing else changes between now and the election, Joe Biden has a 85% chance of winning.” (Silver’s argument)</li>
  <li>“I dunno, anything could happen between now and the election, I give neither candidate chances much more than 50%.” (Taleb’s argument)</li>
</ul>

<p>It is a valid criticism that perhaps Silver is not very clear on explaining what his numbers represent, and therefore the media misreports his predictions. Still, I wager that most people would find the first answer more useful. In this interpretation, the “financial instrument” is a binary option that expires every day. Thefore the time series of Silver’s predictions is not interpretable as a martingale, as it strings together the price of a completely different instrument every day.</p>

<p>It is also a valid criticism that Silver’s predictions prior to Nov. 3 mean absolutely nothing, whereas in the Taleb formulation it has a natural interpretation as the betting odds for each candidate. Silver has explicitly stated that he only judges his models based on his finalized prediction. To that end, his models are extremely well calibrated, i.e., when he says something has a 50% chance of happening it actually does happen 50% of the time.
<img src="http://quant.am/assets/538-calibration.png" alt="538 calibration"></p>

<p>In conclusion, Taleb and Silver should be having a philosophical debate on what pollsters’ numbers actually mean, and stay away from the useless distraction of calling each other names on Twitter.</p>

<h3 id="update-10122020">Update (10/12/2020)</h3>
<p>Andrew Gelman, Aubrey Clayton, Dhruv Madeka and many other statisticians respond and give their thoughts: <a href="https://statmodeling.stat.columbia.edu/2020/10/12/more-on-martingale-property-of-probabilistic-forecasts-and-some-other-issues-with-our-election-model/">https://statmodeling.stat.columbia.edu/2020/10/12/more-on-martingale-property-of-probabilistic-forecasts-and-some-other-issues-with-our-election-model/</a></p>

<h3 id="update-2-1132020">Update 2 (11/3/2020)</h3>
<ul>
  <li>Nassim Taleb responds to this post on <a href="https://twitter.com/nntaleb/status/1323594733797679104">Twitter</a></li>
  <li><a href="https://news.ycombinator.com/item?id=24976175">Hacker News discussion</a></li>
</ul>

		</div></div>]]>
            </description>
            <link>http://quant.am/statistics/2020/10/11/taleb-silver-feud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24976175</guid>
            <pubDate>Tue, 03 Nov 2020 04:04:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The State of ABAC on AWS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24975952">thread link</a>) | @arkadiyt
<br/>
November 2, 2020 | https://summitroute.com/blog/2020/11/02/state_of_abac_on_aws/ | <a href="https://web.archive.org/web/*/https://summitroute.com/blog/2020/11/02/state_of_abac_on_aws/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>Two years ago, in November 2018, AWS <a href="https://aws.amazon.com/blogs/security/add-tags-to-manage-your-aws-iam-users-and-roles/">announced</a> new conditions keys <code>aws:PrincipalTag</code> and <code>aws:RequestTag</code>, and <a href="https://aws.amazon.com/blogs/security/simplify-granting-access-to-your-aws-resources-by-using-tags-on-aws-iam-users-and-roles/">started to push</a> the concept of Attribute Based Access Control (ABAC).  This post will describe what this is, the difficulties with implementing this strategy, and what AWS needs to do for customers to be successful with this concept.</p>


<p>A long standing problem with AWS security has been that if you had two projects in a single AWS account, it was often impossible to ensure that some principals (meaning the users and roles there) could only interact with the resources of one project and not the other.  In order to implement a least privilege strategy, you want to isolate the actions each principal can take to only certain resources to ensure they cannot impact or exfil data from the other project.</p>

<p>The solution many customers have been forced to adopt is to isolate their projects into separate AWS accounts, but that’s not always ideal. For example, it can be difficult to take an existing account and move resources into another account as an account grows.  So AWS started focusing on tagging resources and restricting access via tags.  Over time, many privileges started to be able to work with the condition key <code>aws:ResourceTag</code> so that you could restrict who could interact with an existing resource. But what if you wanted the principal to create new resources, but restrict what tags they could use, so they couldn’t create a resource with the tag of another project?  For this AWS <a href="https://aws.amazon.com/blogs/security/add-tags-to-manage-your-aws-iam-users-and-roles/">released</a> <code>aws:RequestTag</code>.</p>

<p>What if you had many principals and projects and you didn’t want to create separate IAM policies for each one? You want a single policy that you can apply to all principals that says “Only interact with resources that match the same tag as you have” or the common request of “You can only interact with resources you created.”  To implement this concept, AWS released <code>aws:PrincipalTag</code>, so you could now use a conditions such as:</p>

<pre><code>StringEquals: { "aws:RequestTag/project": "${aws:PrincipalTag/project}" }
</code></pre>

<p>Attribute-based access control (ABAC) is an authorization strategy that defines permissions based on attributes, which on AWS means tags.  Two of the best resources on this concept are <a href="https://twitter.com/bjohnso5y">Brigid Johnson’s</a> re:Inforce talk <a href="https://www.youtube.com/watch?v=Iq_hDc385t4">Scale Permissions Management in AWS w/ Attribute-Based Access Control</a> and <a href="https://twitter.com/mchancloud">Michael Chan</a>’s blog post <a href="https://aws.amazon.com/blogs/security/working-backward-from-iam-policies-and-principal-tags-to-standardized-names-and-tags-for-your-aws-resources/">Working backward: From IAM policies and principal tags to standardized names and tags for your AWS resources</a>.</p>



<h2 id="lack-of-privilege-support">Lack of privilege support</h2>
<p>The first issue people ran into with ABAC was that not all resources supported tags. Of those resources that did, not all supported IAM conditions to restrict these tags. Of those that did, not all supported tag on create, so you could only restrict access to tag existing resources, leaving resources untagged.  Let’s get some stats on how much coverage AWS has today.  Using the IAM data from <a href="https://github.com/duo-labs/parliament/blob/main/parliament/iam_definition.json">Parliament</a> (which is just the AWS <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_actions-resources-contextkeys.html">docs</a> scraped into a json file), we find there are 869 privileges that contain the word <code>create</code>, which we can assume to be the privileges that grant permission to create a resource.</p>

<pre><code>$ cat parliament/iam_definition.json | jq '.[]|.prefix as $prefix|.privileges[]|.privilege as $privilege|select($privilege|ascii_downcase|contains("create"))|$prefix+":"+$privilege'  | sort | uniq | wc -l
     869
</code></pre>

<p>Next, we’ll find all the privileges of these that allow the <code>RequestTag</code> condition key:</p>

<pre><code>$ cat parliament/iam_definition.json | jq '.[]|.prefix as $prefix|.privileges[]|.privilege as $privilege|select($privilege|ascii_downcase|contains("create")).resource_types[].condition_keys[]|select(.|ascii_downcase |contains("requesttag"))|$prefix+":"+$privilege' | sort | uniq | wc -l
     381
</code></pre>

<p>We find that 381 of 869 (43%) privileges for creating resources on AWS allows you to both tag the new resources and to restrict what tags are used for that.  This search does miss some privileges that are used to create resources but do not include the word <code>create</code>, such as <code>ec2:RunInstances</code> that lets you create an EC2 and <code>route53:ChangeResourceRecordSets</code> that lets you create a subdomain.  It also misses situations where AWS has two privileges for creating a resource, where one privilege is used for creating the resource with tags and one without, such as <code>cloudfront:CreateDistribution</code> and <code>cloudfront:CreateDistributionWithTags</code>.  However, 43% seems roughly correct.</p>

<p>One might try to argue that the more widely used resources do support tag on create and restricting those tags, but there are some popular resources that do not.  For example, the following privileges are all unable to restrict tag on create: <code>lambda:CreateFunction</code>, <code>dynamodb:CreateTable</code>, <code>kms:CreateKey</code>, <code>logs:CreateLogGroup</code>, <code>s3:CreateBucket</code>, <code>sqs:CreateQueue"</code>, and <code>iam:CreateRole</code>.</p>

<p>As a hack, for resources that don’t support tag on create, you can use the names of the resources in a similar way as a tag, but this is awkward.</p>


<p>Given a resource in an AWS account, there is not much tooling available that can tell you who all has access to it.  Some tools (ex. <a href="https://github.com/FSecureLABS/awspx">awspx</a>) will tell you who has certain privileges, but they don’t understand conditions, among other details.  So for example, they can tell you who has <code>secretsmanager:CreateSecret</code>, but they won’t tell you who can create a secret with the tag <code>foo</code>.</p>

<p>I built some functionality into <a href="https://github.com/duo-labs/cloudmapper">CloudMapper</a> through it’s <code>access_check</code> command that tries to understand more IAM logic. It has some understanding of conditions and will also take IAM Boundaries into consideration, but it does not understand the existing tags on a resource, and lacks a lot of other functionality.  Its answers will be more correct than other tools for some questions, but will still be incorrect for a lot of cases.  The project <a href="https://github.com/nccgroup/PMapper">PMapper</a> also has some additional logic in it.</p>

<h3 id="simulateprincipalpolicy">SimulatePrincipalPolicy</h3>
<p>There is an API called <a href="https://docs.aws.amazon.com/IAM/latest/APIReference/API_SimulatePrincipalPolicy.html">SimulatePrincipalPolicy</a> that can be used to understand who has access to resources, but it is missing a lot of functionality you would expect.  For example, you can pass it the ARN of a principal, the ARN of a resource, and associated privilege to check for, but if there are any conditions, you then have to also include the condition values that should be used when checking this.  This means you have to figure out the tags of the resource and the resource policy to then pass to this call.</p>

<p>So for example, assume we have a principal that can call <code>secretsmanager:GetSecretValue</code> only on secrets that have been tagged with a <code>project</code> key that has a value <code>foo</code>, and we have a secret with that tag.  In order to check if our principal can access this secret, we can run:</p>

<pre><code>aws iam simulate-principal-policy \
  --policy-source-arn arn:aws:iam::123456789012:user/testuser \
  --action-names secretsmanager:getsecretvalue \
  --resource-arns arn:aws:secretsmanager:us-east-1:123456789012:secret:test-abcdef \
  --context-entries ContextKeyName=secretsmanager:ResourceTag/project,ContextKeyValues=foo,ContextKeyType=string
</code></pre>

<p>Notice in the last line, I have to tell it the value of the tag for the resource that I want it to check. The policy simulator does not figure that out for you.  So if you were to try to automate this, you would have to make a describe call, knowing where in the response to find the tag value, and how to format the call to <code>SimulatePrincipalPolicy</code> with this value.  Also, if the IAM policy has unrelated condition keys for other privileges, you have to provide context keys for those too. Next, you have to provide the resource policy if one exists, the IAM boundary if one exists, and potentially other data.</p>

<p>Because of these limitations, this API is not as useful as you might hope.</p>

<h3 id="zelkova">Zelkova</h3>
<p>Zelkova is an automated reasoning solution for IAM policies that was announced by AWS in 2017 and available for private beta.  When I talk to people about the problem of understanding who has access what, this project often comes up as a possible option by those who aren’t familiar with what exactly it does. Unfortunately, Zelkova is an engine that you still have to figure out the inputs to.  It can answer some IAM related questions, but for our goals of understanding who has access to what, it has all the same limitations as iam:SimulatePrincipalPolicy.</p>

<h2 id="limited-capabilities-of-tag-policies">Limited capabilities of Tag Policies</h2>
<p>An AWS Organization feature called <a href="https://aws.amazon.com/blogs/aws/new-use-tag-policies-to-manage-tags-across-multiple-aws-accounts/">Tag Policies</a> was supposed to help enforce tagging, but it is critically limited by only being able to enforce what tag values may be used when defined tag keys are used.  This means you cannot enforce that a resource is tagged. You can only enforce that when someone attempts to tag a resource with a certain key, that the value is one of a defined set.  In order to enforce tagging actually be used in an organization, you have to use SCPs as described <a href="https://aws.amazon.com/blogs/security/securing-resource-tags-used-for-authorization-using-service-control-policy-in-aws-organizations/">here</a>.</p>

<p><a href="https://summitroute.com/img/tag_policies_limitation.png">
<img src="https://summitroute.com/img/tag_policies_limitation.png" alt="Enforcement has no effect on resources that are created without tags." title="Enforcement has no effect on resources that are created without tags."></a></p>
<p>This warning is from the docs <a href="https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_tag-policies-enforcement.html">here</a>.</p>

<p>Further, Tag Policies do not have coverage across all resources that support tags.  The list of supported resources is <a href="https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_supported-resources-enforcement.html">here</a>.  An example of a resource that supports tags, but is not supported by Tag Policies, is S3 objects.</p>

<p>AWS needs to extend the functionality of this feature to support enforcement of using tag keys, as there is little value in it in its current form.</p>

<h2 id="lack-of-support-for-working-with-multiple-tag-values">Lack of support for working with multiple tag values</h2>
<p>People often work on multiple projects, but there is no way to tag a principal with a key that has multiple tag values.  As an example, imagine you have two projects, <code>foo</code> and <code>bar</code>, and you want to allow a person to work on just <code>foo</code> and all the resources they create should have a <code>Project</code> tag with value <code>foo</code>, and likewise you have another person who should only work on the <code>bar</code> projects.  AWS <a href="https://aws.amazon.com/blogs/security/simplify-granting-access-to-your-aws-resources-by-using-tags-on-aws-iam-users-and-roles/">has shown</a> how to create a single IAM policy that can be applied to both people, and you’d just need to make sure to apply a <code>Project</code> tag to the principals to define which project they can work on.</p>

<p>Now imagine that one of these employees needs to work on both projects. You cannot tag a principal with both <code>foo</code> and <code>bar</code>.  One solution is to have the person assume different IAM roles depending on …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://summitroute.com/blog/2020/11/02/state_of_abac_on_aws/">https://summitroute.com/blog/2020/11/02/state_of_abac_on_aws/</a></em></p>]]>
            </description>
            <link>https://summitroute.com/blog/2020/11/02/state_of_abac_on_aws/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24975952</guid>
            <pubDate>Tue, 03 Nov 2020 03:12:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create a Git Diff in Markdown]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24975629">thread link</a>) | @nilsandrey
<br/>
November 2, 2020 | https://blog.alispit.tel/create-a-git-diff-in-markdown/ | <a href="https://web.archive.org/web/*/https://blog.alispit.tel/create-a-git-diff-in-markdown/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>One of my favorite blogging tips is using diff formatting in GitHub flavored markdown. I use this to show what has changed in code snippets. This works for code snippets in most markdown packages and on Dev.to.</p>
<p>If I wanted to show that I was changing a function from one thing to another, I could add a snippet that looks like this!</p>
<div data-language="diff"><pre><code>function addTwoNumbers (num1, num2) {
<span><span>-</span><span>  return 1 + 2
</span></span><span><span>+</span><span>  return num1 + num2
</span></span>}</code></pre></div>
<p>First, instead of specifying the programming language, use <code>diff</code> after the backticks. Then at the beginning of any lines of code you want to show as removed, add a <code>-</code>. At the beginning of any lines of code you want to show as added, add a <code>+</code>.</p>
<p>The code would look like this:</p>
<div data-language="text"><pre><code>```diff
function addTwoNumbers (num1, num2) {
-  return 1 + 2
+  return num1 + num2
}
```</code></pre></div>
<p>I have used this in tons of my coding tutorials, such as <a href="https://welearncode.com/beginners-guide-react/" target="_blank" rel="nofollow noopener noreferrer">this</a> one. It makes it a lot easier for readers to see what is changing from snippet to snippet.</p>
</div></div>]]>
            </description>
            <link>https://blog.alispit.tel/create-a-git-diff-in-markdown/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24975629</guid>
            <pubDate>Tue, 03 Nov 2020 02:01:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Red Mill Burgers]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24975510">thread link</a>) | @koch
<br/>
November 2, 2020 | https://robko.ch/2020/10/31/red-mill-burgers.html | <a href="https://web.archive.org/web/*/https://robko.ch/2020/10/31/red-mill-burgers.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <div>  <blockquote> <p>Red Mill Burgers in Seattle has some great burgers. They make them quickly and they’re a good size. But I swear to God, Google doesn’t give me the correct damn search results when I go to Google them. I mean Jesus FUcking christ i just want to order their delicious burgers online.</p> </blockquote> <p><small><em>What I initially wrote when I started this blog post. Note the aggitated tone the author takes.</em></small></p> <h4 id="scenario-i-want-red-mill">Scenario: I want Red Mill</h4> <p>I google <code>red mill burgers</code> so that I can order online. What do I get? Behold:</p> <div> <p><img loading="lazy" src="https://lh3.googleusercontent.com/5svMZOQr5G8a9_87aJQyekUteEGRXChN-x-JUgtcenCoS6TRZ-0OOx0T9BQtnwWs13-xObl95lzqskyiHpb81oeL4KaMsCnaz3H0fyg2Lji9ELqP75TWCm0OIHyq7RkTM0ubFyC4izA=w2000"> </p> </div> <p>Ok, not bad. I have a few things to say about the results. But before we go any further, a disclaimer: I work at Google, though not on <a href="https://www.google.com/">Search</a>.</p> <p>Most of my issue with the results can be summed up by the first suggested search at the bottom:</p> <div> <p><img loading="lazy" src="https://lh3.googleusercontent.com/hCwfXBcsJIRdknNJfZHuDu7KF4yz_QTefaOJEWZXo8gsh0QdsO7AIl35cYF8LgqCKpjMvm3Ptc4KZ72mmwA9Ot7QIK8Gy7OWb43Jb2ozwyP5dccByA2f4VGiyKcP6psPM7J_LOWvz60=w2000"> </p> </div> <p><a href="https://www.redmillburgers.com/">Their website</a> is not a result of the query <code>red mill burgers</code>! You shouldn’t have to put “website” in your google query, we’re on the internet here folks. There’s yelp, facebook, toasttab, a wikipedia article ffs, but not their website.</p> <p>Now, the observant among you will notice that their website actually is here: where the map results are.</p> <div> <p><img loading="lazy" src="https://lh3.googleusercontent.com/tFdZw7QON4YpG2fD4p3WkfyR4MUrkwZ4JAk6iLFy1ANbEfk4iarT-Bm-tO9qRcbq3_2m35qW1WsQF3E-n8NjNLtohLhgSGlMiN7JsO7l3ohKJIpza6XOEwNl9fEtiKUf52GWlER64Yk=w2000"> </p> </div> <p>But I don’t trust these. Why? There’s a difference between a link that says “Red Mill Burgers” versus a button that says “Website.” And there’s no visible URL unlike the other results. It’s like I have no idea where it will take me; for all I know it will direct me to one of the top links above, of which, again, none are the restaurant’s site. This is more pronounced on mobile where you can’t hover above a link to see where it will take you.</p> <h4 id="other-search-engines">Other search engines</h4> <p>Bing and DuckDuckGo have the same problem, though Bing has more “Website” buttons, so that’s nice, I guess?</p> <div> <div> <p><img loading="lazy" src="https://lh3.googleusercontent.com/Gyn0irJSkaKY4g-2AnijIVnShO9b1xiRWjYn3DtBOG2wVQqft_yKdeM-QwNTe2bnpZMC1jd5_0vomt8wJTybX6dvZ2ONn-A9LsJxtlfc-a-kyexMqv5xW4Nl_GeSnRs99vDduEGGcjI=w2000"></p><p><em>This is what Bing results look like</em></p> </div> </div> <h4 id="question-whose-fault-is-this">Question: Whose fault is this?</h4> <p>Actually we have to answer another question first.</p> <h4 id="question-is-what-im-describing-even-an-issue">Question: Is what I’m describing even an issue?</h4> <p>Is what Google returned actually the information people are looking for? Am I the odd one out? Should I want to go to yelp or facebook or <code>places.singleplatform.com</code>, whatever that is? No. This is an issue to me. So back to the other question.</p> <h4 id="question-whose-fault-is-this-1">Question: Whose fault is this?</h4> <p>Couple possibilities:</p> <ul> <li> <h5 id="red-mill">Red Mill</h5> </li> </ul> <p><a href="https://www.redmillburgers.com/">Red Mill</a> could be doing more <a href="https://en.wikipedia.org/wiki/Search_engine_optimization">SEO</a>. I think this is stupid, most businesses shouldn’t have to cater to search engines or indexers, <em>unless</em> the query was <code>burgers</code> or <code>restaurants</code>. I searched for <code>red mill burgers</code> though.</p> <p>I understand that this is a naïve position. But it leads to our current problem, because obviously the other results on this page are doing <a href="https://en.wikipedia.org/wiki/Search_engine_optimization">SEO</a> to the detriment of the actual business in question and to those looking for it.</p>  <ul> <li> <h5 id="google">Google</h5> </li> </ul> <p>Google should know what the website is and return it.</p>  <ul> <li> <h5 id="the-other-results-on-the-page">The other results on the page</h5> </li> </ul> <p>These would be the Yelps and Facebooks and TripAdvisors of the world. They become less and less interesting to me over time, because they’re all the same - some questionable reviews, some pictures, contact information, all of which are at varying degrees of outdated-ness. And what do I end up looking for on these pages anyway? <strong>Their website.</strong></p> <h4 id="isnt-toast-what-they-use-for-online-ordering-isnt-that-the-first-result">Isn’t Toast what they use for online ordering? Isn’t that the first result?</h4> <p>Yeah that first result is for Phinney Ridge. I go to Interbay.</p> <h4 id="conclusion">Conclusion</h4> <p>In true software engineering fashion, writing this post has taken more time than I will ever spend trying to get to red mill’s website, and way more time than it would take to bookmark it.</p> <br> <hr> </div> </div></div>]]>
            </description>
            <link>https://robko.ch/2020/10/31/red-mill-burgers.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24975510</guid>
            <pubDate>Tue, 03 Nov 2020 01:42:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EME, CDM, AES, CENC, and Keys – Building Blocks of DRM]]>
            </title>
            <description>
<![CDATA[
Score 78 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24975487">thread link</a>) | @jayjohn436
<br/>
November 2, 2020 | https://ottverse.com/eme-cenc-cdm-aes-keys-drm-digital-rights-management/ | <a href="https://web.archive.org/web/*/https://ottverse.com/eme-cenc-cdm-aes-keys-drm-digital-rights-management/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure>
<img src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/08/eme-cdm-cenc-featured-image.png?resize=678%2C381&amp;ssl=1" alt="eme cdm cenc keys" title="eme-cdm-cenc-featured-image" data-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/08/eme-cdm-cenc-featured-image.png?resize=678%2C381&amp;ssl=1" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
</figure>


<p><strong>Anyone trying to understand DRM (Digital Rights Management) will be confronted with acronyms such as AES, CDM, CENC, EME, etc. This can get very confusing for a newcomer, but understanding them is important to get a good understanding of DRM. In this article, let’s take a gentle tour of the building blocks of DRM:- EME, CDM, AES, CENC, and the use of Keys &amp; Key Servers.</strong></p>








<h2 id="simplified-architecture-of-a-drm-system"><span id="Simplified_Architecture_of_a_DRM_System"></span>Simplified Architecture of a DRM System<span></span></h2>



<p>As we saw&nbsp;<a href="https://ottverse.com/what-is-drm-digital-rights-management/">in the previous article</a>,&nbsp;<strong>DRM is a combination of encryption and business rules to control access and consumption of digital content.</strong></p>



<p>Simply put, DRM is a system that,</p>



<ul><li>provides the tools and infrastructure to enable a content provider to encrypt their content, and</li><li>build an ecosystem around the encrypted content so that the content provider can control who/what can decrypt and consume their content.</li></ul>



<p><a href="https://ottverse.com/what-is-drm-digital-rights-management/">In the previous article of the series</a>, we saw Ram and Shyam sending coded messages to each other. At the same time, Hari maintained the codebooks and decided who got to read/write the notes – remember?</p>



<figure><img data-attachment-id="156" data-permalink="https://ottverse.com/with-drm/" data-orig-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?fit=1316%2C878&amp;ssl=1" data-orig-size="1316,878" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="with-drm" data-image-description="" data-medium-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?fit=300%2C200&amp;ssl=1" data-large-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?fit=1024%2C683&amp;ssl=1" loading="lazy" width="1024" height="683" src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?resize=1024%2C683&amp;is-pending-load=1#038;ssl=1" alt="aes-cenc-cdm-eme-keys" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?resize=1024%2C683&amp;ssl=1 1024w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?resize=300%2C200&amp;ssl=1 300w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?resize=768%2C512&amp;ssl=1 768w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?resize=1200%2C801&amp;ssl=1 1200w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?w=1316&amp;ssl=1 1316w" data-lazy-sizes="(max-width: 1000px) 100vw, 1000px" data-lazy-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?resize=1024%2C683&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Now, let’s take this simple system and replace it with the technology needed to secure and distribute video. What do we get?</p>



<figure><img data-attachment-id="138" data-permalink="https://ottverse.com/step-0/" data-orig-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?fit=1396%2C818&amp;ssl=1" data-orig-size="1396,818" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="step-0" data-image-description="" data-medium-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?fit=1024%2C600&amp;ssl=1" loading="lazy" width="1024" height="600" src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?resize=1024%2C600&amp;is-pending-load=1#038;ssl=1" alt="aes-cenc-cdm-eme-keys" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?resize=1024%2C600&amp;ssl=1 1024w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?resize=300%2C176&amp;ssl=1 300w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?resize=768%2C450&amp;ssl=1 768w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?resize=1200%2C703&amp;ssl=1 1200w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?w=1396&amp;ssl=1 1396w" data-lazy-sizes="(max-width: 1000px) 100vw, 1000px" data-lazy-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?resize=1024%2C600&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Let’s describe what we have here. There is a movie that we want to send to an authenticated user securely.</p>



<p>So,</p>



<ol><li>we ask a DRM company’s server for a codebook to encrypt our video,</li><li>then, we encrypt the video using that codebook</li><li>we send the movie to the user.</li><li>the user then asks the DRM company’s server for the codebook to unlock the video (decrypt it)</li><li>and then he watches the movie!</li></ol>



<p>Fantastic!</p>



<p>Is this all there is to know about DRM for video?</p>



<p>Nope! What we have here is a simple, toy-example of how to transfer movies securely using DRM. It captures the essence of DRM perfectly but wouldn’t work well in the real world.</p>



<p>In the rest of this article, let’s take each piece of this simple system, re-think it, re-design it, and see how it fits within the world of video delivery and DRM, shall we?</p>



<h2 id="step-0-lets-move-to-adaptive-bitrate-streaming"><span id="Step_0_Let%E2%80%99s_Move_to_Adaptive_Bitrate_Streaming"></span>Step 0: Let’s Move to Adaptive Bitrate Streaming<span></span></h2>



<p>Before we talk about the order, let’s modify our example to suit the ABR (<strong>A</strong>daptive&nbsp;<strong>B</strong>it<strong>R</strong>ate) model of video delivery.</p>



<p><strong>ABR Refresher:</strong>&nbsp;in ABR, a movie is encoded into different bitrate-resolution combinations&nbsp;<em>(a.k.a ladder)</em>&nbsp;and then split into&nbsp;<strong>chunks or segments</strong>. Each chunk represents a few seconds of video and it is independently decodable.</p>



<p><strong>“Packaging”</strong>&nbsp;refers to chunking or breaking up a movie into small pieces and describing it in a manifest or playlist document. When the user wants to play the movie, he needs to refer to this manifest.</p>



<p>Depending on the available bandwidth, the player requests a chunk/segment of a particular bitrate&nbsp;<em>(rendition, or rung of the ladder)</em>&nbsp;and a CDN (Content Delivery Network) responds with the requested chunk.</p>



<p>Popular methods of video delivery using ABR are MPEG DASH and HLS. For a deeper understanding, please refer to our articles on&nbsp;<a href="https://ottverse.com/what-is-ott-video-streaming/">OTT</a>&nbsp;and&nbsp;<a href="https://ottverse.com/what-is-abr-video-streaming/">ABR</a>&nbsp;video streaming.</p>



<p>Let’s change our block digram to reflect ABR video delivery.</p>



<figure><img data-attachment-id="139" data-permalink="https://ottverse.com/step-0-with-abr/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?fit=1476%2C868&amp;ssl=1" data-orig-size="1476,868" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="step-0-with-abr" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?fit=1024%2C602&amp;ssl=1" loading="lazy" width="1024" height="602" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?resize=1024%2C602&amp;is-pending-load=1#038;ssl=1" alt="aes-cenc-cdm-eme-keys" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?resize=1024%2C602&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?resize=300%2C176&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?resize=768%2C452&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?resize=1200%2C706&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?w=1476&amp;ssl=1 1476w" data-lazy-sizes="(max-width: 1000px) 100vw, 1000px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?resize=1024%2C602&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>The only changes here are the packaging and CDN-based delivery steps. That’s all.</p>



<p>Okay, let’s move on and start with the encryption process.</p>



<h2 id="step-1-video-encryption"><span id="Step_1_Video_Encryption"></span>Step 1: Video Encryption<span></span></h2>



<p>The whole idea of encryption is to ensure that when someone intercepts our data, they should not read it or watch it in the case of video.</p>



<p><strong>Encryption refresher:</strong>&nbsp;–&nbsp;<em>encryption is a technique used to keep data confidential and prevent unauthorized people from reading it. Encryption uses a “key” to convert input data (plaintext) into an alternate form called ciphertext. It is almost impossible to convert the ciphertext back to plaintext without the key.</em></p>



<p><em>However, practically speaking, decryption without the key is possible, and encryption algorithms are designed make reverse-engineering extremely expensive – in terms of time, money, and computing resources needed.</em></p>



<p>One of the most popular encryption techniques is the “Advanced Encryption Standard” or “AES” for short. It is also called Rijndael (after its inventor) and was established by the U.S. National Institute of Standards and Technology (NIST) in 2001 to encrypt electronic data.</p>



<p>Some important points to remember about AES:-</p>



<ul><li>It’s a&nbsp;<strong>symmetric-key algorithm</strong>: encryption and decryption are performed using the same key.</li><li>It has three variants based on the key-length: 128, 192, and 256 bits. The longer the key, the harder it is to crack.</li><li>Cracking the AES-128 without the key would require a “billion times a billion years” and a super-computer (<a href="https://www.eetimes.com/how-secure-is-aes-against-brute-force-attacks/" target="_blank" rel="noopener">source</a>).</li></ul>



<p>If you are interested in going deep into the AES standard, look at the&nbsp;<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard" target="_blank" rel="noopener">AES’s Wikipedia page</a>.&nbsp;<em>I am not an expert in cryptography and won’t be able to do justice to the AES.</em></p>



<p><strong>Note:</strong>&nbsp;Please remember that&nbsp;<strong>encryption is not encoding, and decryption is not decoding in the video space</strong>. For videos, encoding and decoding are words used to refer to compression and decompression, respectively. To learn more about encoding, decoding, and video codecs, please read our articles on&nbsp;<a href="https://ottverse.com/need-for-video-compression/">the need for compression</a>&nbsp;and a&nbsp;<a href="https://ottverse.com/what-is-a-video-codec/">simple introduction to video codecs</a>.</p>



<h3 id="is-aes-128-the-only-encryption-technique"><span id="Is_AES128_The_Only_Encryption_Technique"></span>Is AES-128 The Only Encryption Technique?<span></span></h3>



<p>No, it isn’t, and let’s think about the implication of this for a minute.</p>



<p>If a content provider decides to engage with three different DRM companies, and all three use different encryption techniques, then it means that the content provider needs to encrypt their videos three times, resulting in a waste of storage space and other resources.</p>



<p>That is why the CENC specification came into being – to reduce this encryption-driven fragmentation of the market and to reduce storage requirements.</p>



<p>Let’s learn about this next.</p>



<h3 id="cenc-or-common-encryption"><span id="CENC_or_Common_Encryption"></span>CENC or Common Encryption<span></span></h3>



<p><strong>Actually, before we dive into CENC, let’s step back and take a look at the state of OTT streaming protocols and CMAF in particular.</strong></p>



<p>There are primarily two protocols in use today – MPEG-DASH and HLS.&nbsp;<em>There are others such as MSS (Microsoft Smooth Streaming) and HDS, but, we’ll leave them aside for this discussion.</em></p>



<p>MPEG-DASH uses the&nbsp;<code>mp4</code>&nbsp;container format for its videos and HLS uses the MPEG-TS (<code>ts</code>) container for its files. If a content provider uses both MPEG-DASH and HLS, then they need to store a copy of their videos in both&nbsp;<code>mp4</code>&nbsp;and&nbsp;<code>ts</code>&nbsp;file formats.</p>



<p>Now, let’s add the DRM encryption problem to it. If our three hypothetical DRM providers use three different encryption standards, then a content providers needs to store&nbsp;<code>2 * 3</code>&nbsp;… six copies of each video! What a waste of storage space!!</p>



<p><strong>To combat the first problem posed by video streaming protocols, the&nbsp;<a href="https://mpeg.chiariglione.org/standards/mpeg-a/common-media-application-format" target="_blank" rel="noopener">CMAF</a>&nbsp;specification was created</strong> which said that videos can be stored in the&nbsp;<strong>fragmented mp4</strong>&nbsp;container format (<code>fmp4</code>). With support from both MPEG-DASH and HLS, you can now create only one set of videos, store it in&nbsp;<code>fmp4</code>&nbsp;format, and use a common set of files for both protocols. </p>



<p><strong>Just make sure you create two manifests (sigh!).</strong></p>



<h3><span id="How_About_Unifying_the_Encryption"></span><strong>How About Unifying the Encryption?</strong><span></span></h3>



<p>We still need to store multiple copies of each file if different DRM technologies use different encryption standards, right?</p>



<p>For this purpose, the MPEG developed the&nbsp;<a href="https://www.iso.org/standard/68042.html" target="_blank" rel="noopener">CENC or Common Encryption specification</a>, specifying that videos can be encrypted using either&nbsp;<code>cenc</code>&nbsp;(AES-128 CTR) or&nbsp;<code>cbcs</code>&nbsp;(AES-128 CBC).&nbsp;<em>CTR stands for Counter; and CBC stands for Cipher Block Chaining.</em></p>



<p>The implication of CENC is that a content provider needs to encrypt his videos only once and any decryption module can decrypt it.&nbsp;<em>Note: Exposing the encryption algorithm is not a problem as long as the keys are strongly protected.</em></p>



<p><strong>Well, CENC might sound like a magic wand for DRM-unification, but it is not.</strong></p>



<p>There are three primary DRM technologies in the market – Apple FairPlay, Google Widevine, and Microsoft PlayReady.</p>



<ul><li>Apple FairPlay supports only AES-CBC&nbsp;<code>cbcs</code>&nbsp;mode.</li><li>HLS supports only AES-CBC&nbsp;<code>cbcs</code>&nbsp;mode (irrespective of CMAF)</li><li>Widevine and PlayReady support both AES-128 CTR&nbsp;<code>cenc</code>&nbsp;or AES-128 CBC&nbsp;<code>cbcs</code>&nbsp;modes.</li><li>MPEG-DASH with CMAF supports both AES-128 CTR&nbsp;<code>cenc</code>&nbsp;or AES-128 CBC&nbsp;<code>cbcs</code>&nbsp;modes.</li><li>MPEG-DASH without CMAF supports only AES-128 CTR&nbsp;<code>cenc</code>&nbsp;mode.</li></ul>



<p>As you can see, the CMAF and CENC specs have lead to confusion and fragmentation in the streaming space. </p>



<p><strong>A possible convergence point is the universal use of CMAF and AES-CBC&nbsp;cbcs&nbsp;mode, but, how will these impact legacy devices that support only CTR or only MPEG-TS?</strong></p>



<p>That’s a discussion for another time.</p>



<h2 id="step-2-key-keyid-and-the-license-server"><span id="Step_2_Key,_KeyID,_and_the_License_Server"></span>Step 2: Key, KeyID, and the License Server<span></span></h2>



<p>By now, we have established that we will be encrypting or videos using AES-128 bit encryption. At this stage, a few questions that come up are –</p>



<ol><li>Where do we get the AES-128 Encryption Keys?</li><li>How do we associate an Encryption Key with a movie?</li><li>Where do we store the Encryption Keys?</li></ol>



<p>Let’s answer them one at a time.</p>



<h3 id="where-do-we-get-the-aes-128-bit-encryption-keys"><span id="Where_do_we_get_the_AES128_bit_encryption_keys"></span>Where do we get the AES-128 bit encryption keys?<span></span></h3>



<p>Any content provider can generate the encryption keys manually using specialized software. Alternatively, several DRM vendors provide the necessary tools and software to generate these keys.</p>



<h3 id="how-do-we-associate-an-encryption-key-with-a-movie"><span id="How_do_we_associate_an_encryption_key_with_a_movie"></span>How do we associate an encryption key with a movie?<span></span></h3>



<p>Let’s understand the “why” first. When you go to a hotel, you ask the receptionist for the keys to a particular room by mentioning the room number – right? You’re providing the association here between a key and a room by telling her the room number.</p>



<p>Similarly, when we encrypt a movie with a particular key, we need to create that association and provide that to the DRM license server&nbsp;<em>(our receptionist, if you will)</em>.</p>



<p>In DRM, a “<strong>KeyID</strong>” provides the association between an encryption key and a movie. It is a&nbsp;<strong>unique</strong>&nbsp;string of characters generated at the time of creating an encryption key for a particular movie.</p>



<p><em>And finally,</em></p>



<h3 id="where-do-we-store-the-encryption-key--its-keyid"><span id="Where_do_we_store_the_Encryption_Key_its_KeyID"></span>Where do we store the Encryption Key &amp; its KeyID?<span></span></h3>



<p><strong>The Encryption Key and the KeyID are stored in a secure server (Key Store) that works alongside a DRM license server</strong>.</p>



<p>When a client needs to play an encrypted movie, it requests the DRM license server for the decryption key by providing that …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ottverse.com/eme-cenc-cdm-aes-keys-drm-digital-rights-management/">https://ottverse.com/eme-cenc-cdm-aes-keys-drm-digital-rights-management/</a></em></p>]]>
            </description>
            <link>https://ottverse.com/eme-cenc-cdm-aes-keys-drm-digital-rights-management/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24975487</guid>
            <pubDate>Tue, 03 Nov 2020 01:38:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sales as a Core Competency in Your Company]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24975300">thread link</a>) | @neinasaservice
<br/>
November 2, 2020 | https://21-lessons.com/sales-as-a-core-competency-in-your-company/ | <a href="https://web.archive.org/web/*/https://21-lessons.com/sales-as-a-core-competency-in-your-company/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1361">
			
		<!-- .entry-media -->
	

	<div>

		<!-- .entry-header -->

		<div>
			
<p>Currently, you might not be actively selling (as in approaching leads). Or the product sells itself right now (people get in touch with you and buy).&nbsp;</p>



<p>You feel weird about cold-calling, approaching strangers about your offerings. It’s a valid concern.&nbsp;</p>



<p>When you look at your current customer base and revenues: Can you predict when you make a sale? Can you be confident if somebody will follow through with the purchase?&nbsp;</p>



<p>If you don’t have Sales People on staff, this is a challenge. Why should you care, though?</p>



<p>For starters, you might need to plan revenue for the next few months, to hire a new employee, or invest in that new project you’ve been anxious to kick off.</p>



<p>Whatever the motivation is in the end, you need to predict incoming revenue. And for that, you need to sell. As always, there are multiple approaches to this.</p>



<p>As a starting point, you can start to work off all inbound sales inquiries. Your Advantage: No cold outreach to anyone. You focus solely on incoming requests and work them off.&nbsp;</p>



<p>You increase your odds of closing deals with a well-defined sales process. A sales process helps you confidently walk a prospect through each step and increase the chance to become a paying customer.</p>



<p>It still might not allow you to increase revenue as you need it, but you can more effectively predict incoming revenue. This circumstance is already worth a lot because it provides you with a lot more financial stability.&nbsp;</p>



<p>Another circumstance should also make this process more comfortable for you: You are already selling to those who gave you permission. You are allowed to sell. These prospects got in touch with you because they need something from you. Now it’s on you to professionally handle the request and walk them through the process.</p>



<p>With this approach, you’re slowly building Sales Competency in your organization for a more stable revenue foundation.</p>

					</div><!-- .entry-content -->

		
			</div><!-- .entry-inner -->
</article></div>]]>
            </description>
            <link>https://21-lessons.com/sales-as-a-core-competency-in-your-company/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24975300</guid>
            <pubDate>Tue, 03 Nov 2020 01:07:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TLB hit: a podcast about systems and compilers – Episode 0: mov fp, sp]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24975206">thread link</a>) | @matt_d
<br/>
November 2, 2020 | https://tlbh.it/000_mov_fp_sp.html | <a href="https://web.archive.org/web/*/https://tlbh.it/000_mov_fp_sp.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<audio id="audioplayer" src="https://traffic.libsyn.com/secure/tlbhit/tlbhit0.mp3" controls="controls" preload="auto"></audio>
<h2>00:00:00 Intro</h2>
<ul>
<li>Website: <a href="https://tlbh.it/">tlbh.it</a></li>
<li>Twitter: <a href="https://twitter.com/tlbhit">@tlbhit</a></li>
<li><a href="https://podcasts.apple.com/us/podcast/mov-fp-sp/id1538369465?i=1000496866078">This episode on Apple podcast</a></li>
<li>The stack pretty much always TLB hits!</li>
</ul>
<h2>00:00:59 Disclaimer</h2>
<ul>
<li>We're lifelong learners, only know so much!</li>
<li>Will put errata up on <a href="https://tlbh.it/">the TLB Hit website</a></li>
<li><a href="https://en.wikipedia.org/wiki/Covert_channel">"Sidechannels"</a> via Twitter</li>
</ul>
<h2>00:01:42 What's the stack?</h2>
<ul>
<li>Episode is named <code>mov fp sp</code></li>
<li><code>mov fp sp</code> in the prologue of functions</li>
<li>Epilogue has "reverse" <code>mov sp fp</code></li>
<li>Instructions that manipulate <em>the stack</em>!</li>
<li>Compiler spills values that registers can't hold onto the stack</li>
<li>Functions do it a lot -- have their own [local] state, call functions that
have their own state</li>
<li>Because subroutines can recurse without bounds would need unbounded number of
registers</li>
<li>Often different kinds of registers: arithmetic value registers, floating
point registers</li>
<li>Registers contain fairly arbitrary "stuff": pointers to data, pointers to
code, return addresses, etc.</li>
<li>Stack is <em>usually</em> contiguous and allocated on a per-thread basis</li>
<li>Idea of "GPRs": general purpose registers, though some machines have
dedicated registers for floating point values as well, or SIMD for really
wide</li>
<li>Prologue moves stack pointer to base pointer, epilogue moves base pointer
back to stack pointer, "undoing", locally manipulating the stack pointer then
rolling things back to where they previously were</li>
</ul>
<h2>00:03:50 Mechanisms in the processor</h2>
<ul>
<li>Frame pointer/base pointer (bp/fp), stack pointer (sp)</li>
<li>Usual convention is that the frame pointer doesn't change during the course
of the function's execution</li>
<li>Generated code addresses "slots" relative (at offsets from) the frame
pointer; e.g. <code>+4</code>, <code>+8</code>, etc.</li>
<li>Stack is kind of like a linked list! Pointer of the stack that says "this is
where the frame pointer <em>used to be</em> before we came into this routine".</li>
</ul>
<h2>00:05:10 Comparison to an abstract stack machine</h2>
<ul>
<li>In CS class you may learn about machines where you push two operands onto a
stack then do an add operation that consumes the top two things on the stack</li>
<li>Compare to traditional processor we use today: expanding the stack as a
single operation that makes a bunch of slots at once</li>
<li>The slots don't need to be consumed in a strictly stack-order fashion</li>
<li>Distinction of "stack machine" vs scratchpad-area style frame areas
that happen in stack-like fashion for subroutine calls</li>
</ul>
<h2>00:06:05 Some instruction set considerations</h2>
<ul>
<li>Considerations on modern machines for frequency of these operations and how
they fit in our instruction cache; e.g. on x86 <code>push</code>/<code>pop</code> are single byte
opcodes</li>
<li>On ARM we may have a "push multiple values" instruction; little CISC-y but you
do so commonly it may make some sense</li>
<li>ARMv7 had instruction allowed to push 16 registers (all GPRs) and increment
stack pointer. Yay RISC!</li>
</ul>
<h2>00:07:09 Compiler optimizations and stackiness</h2>
<ul>
<li>By moving things onto the stack -- code is constantly working with the things
in its stack frame</li>
<li>Locality, but also avoiding memory allocation subroutines (100s or 1000s of
cycle depending)</li>
<li>In scratchpad area values are tracked precisely in dataflow sort of style</li>
<li>Bring them "in" to the compiler, values becomes more trackable</li>
<li>SSA values vs arbitrary memory references</li>
<li>When structs are brought onto the stack the individual fields inside can be
broken apart and the component fields can be tracked as individual values</li>
<li>Often called "scalar replacement of aggregates" (e.g. in LLVM)</li>
<li>When we home them on the stack we can do our common optimizations, CSE, DCE;
if on the heap, may be a lot harder to to do</li>
<li>In managed languages (e.g. JavaScript, Java) would do escape analysis to show
it doesn't escape via heap to an unknown subroutine -- once placed on the
stack you can eliminate whole objects and just track sub-fields inside of it</li>
<li>Allows you to just "explode" the object itself and think about its component
fields individually and get rid of whatever doesn't matter in there</li>
</ul>
<h2>00:09:17 Eliding heap allocations in C++</h2>
<ul>
<li>Some compilers can also sometimes optimize local heap allocations, turn them
into stacky allocation</li>
<li>C++ explicitly allows you to do that as of a few years ago, Clang does that</li>
<li>If you new an object no guarantee that you're actually going to put it on the
heap / call the underlying allocator</li>
<li>Can be surprising to people -- can do SRoA, other stuff, might get rid of the
entire computation</li>
<li>Neat, unless it's not what you're trying to do</li>
<li>But seems like a key optimization to do</li>
<li>If you're thinking about things as objects instead of raw bytes having higher
level understanding you can optimize based off of is pretty key it seems?</li>
</ul>
<h2>00:10:18 Frame pointer omission</h2>
<ul>
<li>When JF started programming there was "frame pointer omission" (FPO) which
was cool because optmizers weren't as good as they are now</li>
<li>Back when you only had 8 registers for x86 the extra register could go a long
way potentially -- stack is hot in cache but doing stores and loads to memory
locations</li>
<li>Was known to some as "that flag that makes the debugger way worse" -- debug
information has to be a lot more prescriptive when you can't simply describe
where things are as an offset from a canonical (assumed unchanging) register</li>
<li>Modern CPUs doing register renaming under the hood against a much bigger
micro-architectural register set -- not as worried about saving that one
register as much of the time -- although in hot code you still might</li>
</ul>
<h2>00:11:49 "Leaf" functions</h2>
<ul>
<li>When you inline things you make bigger regions for analysis, ideally make big
fat leaf functions</li>
<li>How much of program time is generally spent in leaf functions over some set
of applications?</li>
<li>Function at the end of the call tree</li>
<li>If your subroutine doesn't call any other subroutines that's a nice property,
because now you know that everything at the end of the stack belongs to you,
you're just doing your work and popping back up to whoever called you</li>
<li>Inlining really unlocks power of leaf -- inlining into non-leaf-functions can
<em>make</em> them become the leaf</li>
<li>So long as you don't over-inline and the working set doesn't become too big
-- the compiler can know everything it does and have a good amount of work to
do</li>
<li>Small region in which you can analyze <em>everything</em>, like tiny little whole
program analysis</li>
</ul>
<h2>00:13:10 Why do we have a stack again?</h2>
<ul>
<li>Why can't we inline everything?</li>
<li>Two main issues: 1) don't necessarily know call graph for the whole program
2) recursion</li>
<li>If you knew where all the calls went (virtual/indirect/etc in your
translation unit and other ones in your program), and without recursion, you
wouldn't need a stack, you know a perfect call graph</li>
<li>For some of these you could avoid having a stack -- virtual functions but
only a few actually implementations of it, could change to test-and-branch</li>
<li>If you have a fully analyzable virtual dispatch it effectively just becomes a
switch, can potentially inline what the targets are</li>
<li>Control flow analysis takes indirect branch that can go anywhere and
enumerate the real set of possibilities (devirtualization within a
translation unit)</li>
<li>Fully analyzeable call graph is an interesting computer history topic:
FORTRAN77 classically able to do this (programs were restricted enough you
could analyze it)</li>
<li>XLA ML/array programming machine learning compiler has the same property
where the whole call graph is analyzeable so you can create a slab that's the
giant frame for the whole program you're optimizing and all allocations are
known-fixed size</li>
<li>Whole program call graph analyzeability lives on in these niche use cases!</li>
<li>In stark contrast, sometimes we need multiple different kinds of stacks at
the same time!</li>
<li>The JS engine would sometimes recur from JS calls through the VM runtime to
other JS code, and that would need to potentially create a sub-stack (!) --
multi stack problems exist beyond even just needing to analyze/manage a
single stack</li>
<li>Programming in FORTRAN is cool, for scientific code often trying to
solve a specific physics problem don't <em>usually</em> need those tools like
recursion or virtual functions</li>
<li>When everything is "monomorphized" -- you have big arrays of
fixed-value-types you can know everything about the world and really optimize
everything based off of it -- fun mode to be in for scientific computing code</li>
</ul>
<h2>00:16:34 Considerations beyond recursion and indirect calls?</h2>
<ul>
<li>Some languages use the stack for fast thread switching? Things like full
stackful coroutines?</li>
<li>Stacks in Go for example are not contiguous: more like C++ deque: linked list
of lists instead of one contiguous stack -- clever x86 code sequence that
makes it fast to find previous and next frame</li>
<li>Allows Go stacks to be distinct allocations -- each page-wise is one frame
and the next function has another frame -- can put multiple functions in one
allocation</li>
<li>Used to have really bad perf if you were in a hot loop and happened to
straddle that boundary</li>
<li>Coroutines in some languages ended up having some "stackless" stuff like
this, where the closure is heap allocated instead</li>
<li>C++ coroutines try to do away with all the heap allocations, but depends on
optimization level whether it can do that or not</li>
<li>Kind of similar for Objective-C blocks -- until recently always heap
allocated, started being stack allocated in last few years where they could</li>
<li>Language doesn't say whether stuff lives on the heap or not</li>
<li>Because stack is less constrained can live in different places, e.g. in Go</li>
<li>In some cases you remove the allocation entirely</li>
</ul>
<h2>00:18:25 Scaling to millions of threads?</h2>
<ul>
<li>If you want to be able to scale your concurrency assumptions to millions of
threads, you don't want to have huge stacks</li>
<li>Each thread has a stack, and if you have millions of threads you don't want
to be allocating too much</li>
<li>And need to be able to switch between those threads quickly</li>
<li>So raises the question: how do you usually size those stacks in the
per-thread context you have?</li>
<li>If you're doing tiny little operations; e.g. if every operation in your
program was conceptually a thread, you wouldn't want to allocate 512KiB every
time you did a tiny atomic operation</li>
</ul>
<h2>00:19:10 Managed languages putting frames on the heap</h2>
<ul>
<li>On the term "stackless": one of the <a href="https://greenlet.readthedocs.io/en/latest/">Python
"greenlet"</a> ("lightweight thread"
terminology) attempts was called <a href="https://github.com/stackless-dev/stackless/wiki">Stackless
Python</a></li>
<li>In managed languages like Python the frames can be allocated …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tlbh.it/000_mov_fp_sp.html">https://tlbh.it/000_mov_fp_sp.html</a></em></p>]]>
            </description>
            <link>https://tlbh.it/000_mov_fp_sp.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24975206</guid>
            <pubDate>Tue, 03 Nov 2020 00:52:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New study finds deaths in Game of Thrones follow predictable rules]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24975083">thread link</a>) | @Bologo
<br/>
November 2, 2020 | https://www.psychnewsdaily.com/data-science-study-finds-that-deaths-in-game-of-thrones-are-not-random/ | <a href="https://web.archive.org/web/*/https://www.psychnewsdaily.com/data-science-study-finds-that-deaths-in-game-of-thrones-are-not-random/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4885" role="main"><div><div><div><p>A <a rel="noreferrer noopener" href="https://www.pnas.org/cgi/doi/10.1073/pnas.2006465117" target="_blank">new study by researchers from five universities</a> across the UK and Ireland has found that the overarching social structure and the distribution of deaths in <em>Game of Thrones </em>reflect the typical numbers found in real human societies. As such, the study “provides quantitative support, for example, for the widespread view that deaths appear to be randomly distributed throughout the narrative even though, in fact, they are not,” the authors write.<span data-ez-name="psychnewsdaily_com-medrectangle-3"></span></p><p>The new paper appeared on November 2 in the journal <a rel="noreferrer noopener" href="https://www.pnas.org/" target="_blank"><em>Proceedings of the National Academy of Sciences</em></a>.</p><h2><strong>Deaths in <em>Game of Thrones</em> are anything but random</strong></h2><p>The research team consisted of physicists, mathematicians, and psychologists. They used data science and network theory to analyze <em>A Song of Ice and Fire</em>, the acclaimed book series. These books, by George R.R. Martin, formed the basis for the mega-successful HBO television series <em>Game of Thrones</em>.</p><p>“A distinguishing feature of&nbsp;<em>Ice and Fire</em>&nbsp;,” the paper writes, “is that character deaths are perceived by many readers as random and unpredictable.” Indeed, it continues, “the storyteller has manipulated the timeline of the story in such a way as to make it continuously more appealing by making significant events seem random so as to heighten the reader’s engagement.”</p><p>Likewise, the study writes,<em> “A Song of Ice and Fire</em>&nbsp;is a prodigious modern epic of considerable complexity that remains accessible to a vast congregation of devotees. Among its appeals are the uncertainty and unpredictability of its storyline as characters, including important ones, can be killed off seemingly at random.” And not even the main characters “are guaranteed safe passage from one book to the next.”<span data-ez-name="psychnewsdaily_com-medrectangle-4"></span></p><p>But as the study points out, when the chronological sequence is reconstructed, the deaths are not random at all. Instead, they resemble how a wide range of common human activities are distributed for in the real world. &nbsp;&nbsp;&nbsp;</p><h2>Unravelling the sequence of deaths in Game of Thrones</h2><p>To analyze the evolution of the narrative, the authors use an approximate timeline of the events depicted in <em>Ice and Fire</em>&nbsp;based on the Westerosi calendar date. It has been compiled by fans, <a href="https://www.reddit.com/r/asoiaf/comments/1c07jw/spoilers_all_most_precise_asoiaf_timeline_in/" target="_blank" rel="noreferrer noopener">and is maintained</a> by the Reddit user identified as <a href="https://www.reddit.com/user/PrivateMajor/" target="_blank" rel="noreferrer noopener">PrivateMajor</a>. They use this timeline to assign an approximate date to each chapter of each book, which allows them to study events as they occur within the in-story timeline.</p><p>Their analysis considers only the deaths of significant characters, deemed to because they appeared in more than one chapter. They made this distinction to avoid including the deaths of “cannon-fodder” characters, “whose main purpose in the story is to die immediately after they are introduced.”</p><p>Past research has shown that inter-event time distributions for “many (nonviolent) human activities in the real world, including communication, entertainment, trading, and work, have power-law tails.” <span data-ez-name="psychnewsdaily_com-box-4"></span></p><p>The distribution of deaths in <em>Game of Thrones </em>and <em>A Song of</em>&nbsp;<em>Ice and Fire</em>&nbsp;are close to what we expect in real social networks, the study finds.</p><h2>“Almost” random intervals</h2><p>As the authors summarize, the way the deaths are distributed in the narrative makes the reader think that these deaths “occur almost at random intervals.” But then “analyzing deaths in terms of story time, this is not the case, with significant events occurring in a more natural way. Portraying significant events by discourse time instead of as they happen appears to maintain the reader’s suspense,” they write.</p><p>“These books are known for unexpected twists, often in terms of the death of a major character,” said <a rel="noreferrer noopener" href="https://www.ul.ie/dafinet/p%C3%A1draig-mac-carron" target="_blank">Pádraig MacCarron</a> of the University of Limerick. “It is interesting to see how the author arranges the chapters in an order that makes this appear even more random than it would be if told chronologically,” he said.</p><h2><strong>Thousands of characters, but Dunbar’s Number still applies</strong></h2><p>The more than 2,000 characters in <em>A Song of Ice and Fire</em> have about 41,000 interactions between them. That’s indeed a lot. But at the chapter-by-chapter level, these numbers average out to match what most people experience in real life.</p><p>Even the most predominant characters, the ones who narrate the story, have only about 150 other people to keep track of, on average. This is the same number that the average human brain has evolved to deal with. It is known as <a href="https://en.wikipedia.org/wiki/Dunbar%27s_number">Dunbar’s number</a>, named after the renowned British anthropologist <a href="https://en.wikipedia.org/wiki/Robin_Dunbar">Robin Dunbar</a>. Dunbar was also a co-author of this new study.</p><p>Despite the huge number of (new) characters and interactions, Martin manages to maintain a consistent social network structure. The number of these interactions is at the upper end of the <a href="https://www.psychnewsdaily.com/new-study-shows-that-bed-sharing-couples-sleep-better/">cognitive</a> capacity of an average reader. As the study’s authors write, “the social network a reader has to consider in order to follow the story is similar in scale to natural cognitive capacity.”</p><p>So, despite there being more than 2,000 characters, none has a social network of more than about 150 people, on average. Plus, there are only 14 major “point of view” characters narrating the story. “These are frequent numbers in the structure of real social networks,” the study writes, “and they allow the reader to work within natural templates.”</p><h2>Keeping cognitive load within realistic limits</h2><p>In other words, “the story reflects experiences in the everyday social world and therefore does not overtax cognitive abilities that are evolved to match these scales.”</p><p>Similar limits have been reported for <a href="https://link.springer.com/article/10.1007%2Fs12110-003-1013-1" target="_blank" rel="noreferrer noopener">Shakespeare’s plays</a>, and seem to “reflect natural limits on mentalizing competences — the cognitive skills that underpin our <a href="https://www.psychnewsdaily.com/why-are-americans-vocabulary-skills-stagnating/">ability</a> to handle social relationships in the virtual mental sphere of the everyday social world.”</p><p>The paper also finds that <em>A Song of Ice and Fire</em> is more similar to the Icelandic sagas than to mythological stories such as England’s Beowulf or Ireland’s Táin Bó Cúailnge.</p><h2><strong>Predicting tomorrow’s complex narratives</strong></h2><p>“People largely make sense of the world through narratives,” said co-author <a href="http://www.colmconnaughton.net/" target="_blank" rel="noreferrer noopener">Colm Connaughton</a> of the University of Warwick, “but we have no scientific understanding of what makes complex narratives relatable and comprehensible. The ideas underpinning this paper are steps towards answering this question.”&nbsp;&nbsp;&nbsp;&nbsp;</p><p>Studies like this one might even be used to map out book and film series that have yet to be created. “I am excited to see the use of network analysis grow in the future,” said <a href="http://www.complexity-coventry.org/people/single-view/detail/Yoseph_Jose/" target="_blank" rel="noreferrer noopener">Joseph Yose</a> of Coventry University. “Hopefully, combined with machine learning, we will be able to predict what an upcoming series may look like,” he said.</p><figure><img loading="lazy" width="1024" height="553" src="https://www.psychnewsdaily.com/wp-content/uploads/2020/11/game-of-thrones-social-1-1024x553.jpg" alt="" srcset="https://www.psychnewsdaily.com/wp-content/uploads/2020/11/game-of-thrones-social-1-1024x553.jpg 1024w, https://www.psychnewsdaily.com/wp-content/uploads/2020/11/game-of-thrones-social-1-300x162.jpg 300w, https://www.psychnewsdaily.com/wp-content/uploads/2020/11/game-of-thrones-social-1-768x414.jpg 768w, https://www.psychnewsdaily.com/wp-content/uploads/2020/11/game-of-thrones-social-1-360x194.jpg 360w, https://www.psychnewsdaily.com/wp-content/uploads/2020/11/game-of-thrones-social-1.jpg 1160w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>The social network at the end of the first book <em>A Game of Thrones</em>. Blue nodes represent male characters, red are female characters. Transparent grey are characters who are killed by the end of the first book.</figcaption></figure><p>For a weekly summary of the latest psychology news, subscribe to our <a href="https://www.psychnewsdaily.com/the-psych-news-weekly-newsletter/" target="_blank" rel="noreferrer noopener">Psych News Weekly newsletter</a>.</p></div></div></div></article></div>]]>
            </description>
            <link>https://www.psychnewsdaily.com/data-science-study-finds-that-deaths-in-game-of-thrones-are-not-random/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24975083</guid>
            <pubDate>Tue, 03 Nov 2020 00:32:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The perfect file server setup]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24974971">thread link</a>) | @geek_at
<br/>
November 2, 2020 | https://blog.haschek.at/2020/the-perfect-file-server.html | <a href="https://web.archive.org/web/*/https://blog.haschek.at/2020/the-perfect-file-server.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                    <div>
                        <div>
                            <div>
                            <p>If you've ever thought of building a file server, you probably had one or more of these thoughts</p>
<ul>
<li>Do I really need to <strong>waste one disk</strong> for the operating system?</li>
<li>I only have <strong>old hardware</strong> with limited RAM, can I still use it as a file server?</li>
<li>If someone <strong>steals my equipment</strong>, how can I make sure they won't have access to my data?</li>
<li>How can I set up a <strong>samba share</strong> that will allow my windows computers to access the data?</li>
<li>I don't have a display to connect to my file server. How can I do it all <strong>headless</strong>?</li>
<li>Is <strong>software raid</strong> any good? What about ZFS?</li>
</ul>
<p><strong>Well, wonder no more!</strong></p>
<p>We're going to build a system that will handle all those things!</p>

<ol>
<li><a href="#usbboot">Preparing the USB to boot</a></li>
<li><a href="#diskman">Managing the disks</a></li>
<li><a href="#fileshares">Creating file shares</a></li>
<li><a href="#docker">Docker and more</a></li>
<li><a href="#faq">FAQ</a></li>
</ol>
<p>My motivation for this was, that I inherited an HP Data Vault x312 <a href="https://www.reddit.com/r/DataHoarder/comments/jkb35f/neighbor_died_of_cancer_and_his_wife_told_me_shes/">from my neighbor who died</a> recently and this device is pretty old, has an Intel Atom d510 with only 2 GB of RAM and no display. It was meant to be used with Windows Home Server. My goal is to use it as an encrypted storage pool for backups running headless Alpine Linux.</p>
<figure><img loading="lazy" src="https://pictshare.net/6c1h06.png"><figcaption>HP Data Vault x312</figcaption></figure>
<hr>


<p>As in my <a href="https://blog.haschek.at/2019/build-your-own-datacenter-with-pxe-and-alpine.html">previous</a> server related <a href="https://blog.haschek.at/2020/the-encrypted-homelab.html">posts</a>, my choice of operating system for file servers is <a href="https://alpinelinux.org/about/">Alpine Linux</a> because it's so damn small (ram usage after boot will be ~100mb), fast and has a ton of up to date packages we're going to be using.</p>
<p>Also it can be configured to run from a RAM disk with configuration stored on a USB drive. Which is exactly what we're going to do.</p>
<h2>You're going to need 2 USB drives</h2>
<p>The size doesn't really matter, I'm using two 16G drives. They don't even have to be USB3, it won't make a difference.</p>
<figure><img loading="lazy" src="https://pictshare.net/800/3xiz7b.png"><figcaption>2 USB drives we'll be using</figcaption></figure>
<p>Why two?</p>
<p>We're going to put the ISO of Alpine Linux on one of them and boot it. Then we're using it to create the second one (which will be the one we're actually putting in our server).</p>
<h3>Flashing the USB</h3>
<p>Go to <a href="https://alpinelinux.org/downloads/">https://alpinelinux.org/downloads/</a> and download the latest x68_64 <strong>EXTENDED</strong> ISO and flash it <strong>to one of the USB drives</strong> using dd or some other etcher program.</p>
<p>Command if you're using dd like a pro: <code>dd if=/path/to/your/alpine-extended.iso of=/dev/sdx</code> where sdx is the device name of your USB drive. If unsure run <code>lsblk | grep disk</code> it will show you the device names and sizes for all connecte drives.</p>
<h2>Booting the install USB drive</h2>
<p>This can still be done on one of your devices and not on the file server. We're just preparing the USB installer here.</p>
<p>Plug your freshly flashed USB in a computer or laptop and boot it. You should see this screen</p>
<p>![Freshly booted Alpine Linux]()</p>
<p>Enter <code>root</code> and press enter, you're now logged in.</p>
<h2>Preparing the USB drive for the file server</h2>
<p>Now is a good time to look at the out put of <code>fdisk -l | grep Disk</code> to see which disks are found.</p>
<figure><img loading="lazy" src="https://pictshare.net/vf0ews.png"><figcaption>It should look something like this</figcaption></figure>
<p>Now plug in the second USB drive and run <code>fdisk -l | grep Disk</code> again to see which device name it has.</p>
<figure><img loading="lazy" src="https://pictshare.net/7ylr9z.png"><figcaption>USB drive is known as /dev/sdc</figcaption></figure>
<p>Great now we have to set up the new USB correctly: <code>fdisk /dev/sdc</code> (use the device name of your USB drive)</p>
<p>Now we're in fdisk. We'll empty the USB drive and create a partition that will host the image and configuration.</p>
<p>Press the following keys in fdisk:</p>
<pre><code>o -&gt; enter
n -&gt; enter
p -&gt; enter
1 -&gt; enter
enter (when asking for first sector)
enter (when asking for last sector)
a -&gt; enter
1 -&gt; enter
w -&gt; enter</code></pre>
<p>now if you run <code>fdisk -l /dev/sdc</code> you should see the new layout like this</p>
<figure><img loading="lazy" src="https://pictshare.net/gr1s3i.png"><figcaption>New USB layout</figcaption></figure>
<p>Now we format the new partition FAT32 and install the system from our booted USB drive</p>
<pre><code>mkdosfs -F32 /dev/sdc1
setup-bootable /media/sdb /dev/sdc1</code></pre>
<p>Note: <code>/media/sdb</code> should already be mounted, it's the file system of the live USB you're using. It might have a different name, check <code>df -h</code> to see what device is mounted to <code>/media/</code></p>
<figure><img loading="lazy" src="https://pictshare.net/0grvrm.png"><figcaption>Successful installation</figcaption></figure>
<h2>Let's prepare it for the fileserver</h2>
<p>If you want to install multiple servers, just plug in more USB drives, <code>fdisk</code> and <code>setup-bootable</code> them.</p>
<p>But now we want to set up the USB drive for our file server. Shut down the PC/Laptop/Server you were using, plug in only the second USB drive (the one you just installed Alpine to) and boot it.</p>
<p>It should look exactly like the first USB drive we were using but now we can save changes we make to the system.</p>
<p>The first thing we're going to run is <code>setup-alpine</code>. Here's a small guide what to enter/choose</p>
<pre><code>[your language code] us -&gt; enter
[probably the same code again] us -&gt; enter
[the hostname you want your machine to have] fileserver -&gt; enter
[eth0] -&gt; enter
[dhcp] -&gt; enter (or you can configure static IP here)
done -&gt; enter
[no] -&gt; enter
[your password] -&gt; enter
[password again] -&gt; enter
[your timezone] Europe/Vienna -&gt; enter
[none] -&gt; enter
[chrony] -&gt; enter
[1] -&gt; enter
[openssh] -&gt; enter
Which disks would you like to use: none -&gt; enter
Enter where to store configs: usb -&gt; enter
[/media/usb/cache] -&gt; enter
(ignore the last warning)</code></pre>
<p>Now you have successfully configured your image! To save changes you made to the system write .</p>
<p><code>lbu commit -d</code></p>
<p>To be able to connect to alpine from the network we need to either set up SSH to allow root logins (by editing <code>/etc/ssh/sshd_config</code> and setting <code>PermitRootLogin</code> to <code>yes</code>) or by adding your ssh keys to the authorized_keys file.</p>
<pre><code>ssh-keygen # press enter until it's done
nano .ssh/authorized_keys # and add your SSH public keys in here
lbu include /root/.ssh # we need to tell alpine that we want to include the .ssh folder to the saved config on the USB
lbu commit -d # and saving to USB</code></pre>
<p>You always need to run <code>lbu commit -d</code> after you changed any config file or installed a program otherwise it will be lost on reboot. To see which files are included run <code>lbu ls</code></p>
<p>The idea for this is that the USB has all the programs and config but all data is stored on the mounted drives.</p>
<p>To confirm it really works, reboot the system and boot from the same USB again. If it needs your new password at login everything worked.</p>
<p>Now it can be plugged into the file server and booted. If you already have other disks in your server, make sure it's set to boot from USB. For my Data Vault I didn't have to (or would have been able to) change anything in the BIOS because if it can't find a boot partition on any disk, it will go straight to USB boot. Neat!</p>
<p>If you didn't set a fixed IP address then you'll have to do a lan scan</p>
<hr>


<p>I did all the dirty benchmarking for you already. Here it is</p>
<figure><a href="https://pictshare.net/8l2o1b.png"><img loading="lazy" src="https://pictshare.net/8l2o1b.png"><figcaption>Graph that shows how slow/fast different disk configurations are. I have no idea what happend to the RAID 5 read speeds, they don't even match RAID0</figcaption></a></figure>
<p>Now that we have our system up and running it's time to add the drives and use them. But first let's install a few things that will make our lives easier.</p>
<p><code>apk add nano htop lsblk e2fsprogs</code></p>
<p>Let's look at the disk configuration we have: <code>lsblk | grep disk</code></p>
<figure><img loading="lazy" src="https://pictshare.net/x7l1qa.png"><figcaption>All disks that have been found. Data disks from sda to sdd</figcaption></figure>
<p>Awesome so we have 3x3TB and 1x 2.5TB disks (I'll change the smaller one when my new 3TB gets here)</p>
<p>From here it's basically a "choose your own adventure" thing. We have 4 drives so we can set them up in different ways.</p>
<p>My choice is: RAID 5 using <code>mdadm</code> and over the combined storage LUKS encryption. If you feel you won't need encryption you can just skip it. If your CPU is as old as mine and doesn't have the aes-ni extension, encryption will probably be bottlenecking file transfers but personally I just can't say no to an encrypted homelab.</p>
<h2>Side note: ZFS</h2>
<p>Alpine Linux fully supports ZFS. You can read <a href="https://wiki.alpinelinux.org/wiki/Setting_up_ZFS_on_LUKS">this guide</a> how to use it even with encryption on Alpine. Since ZFS requires a bit more CPU than mdadm I'll be using the latter but on my main file server at home I'm using ZFS as well.</p>
<h2>Settung up RAID 5</h2>
<p>First we'll going to need <code>mdadm</code>,  we can install it using <code>apk add mdadm</code></p>
<p>Then we`ll have to make sure it runs on boot using</p>
<pre><code>rc-update add mdadm boot
rc-update add mdadm-raid boot</code></pre>
<p>Let's create or RAID!</p>
<pre><code>mdadm --create /dev/md0 --level=5 --raid-devices=4 /dev/sda /dev/sdb /dev/sdc /dev/sdd</code></pre>
<p>Depending on your hardware and disk size it might take pretty long for the RAID to sync so you can watch it using <code>watch cat /proc/mdstat</code></p>
<figure><img loading="lazy" src="https://pictshare.net/va1pwf.png"><figcaption>Watching the raid getting made</figcaption></figure>
<p>After it's finished, we can save the raid configuration info using <code>mdadm --examine --scan &gt; /etc/mdadm.conf</code> and don't forget to <code>lbu commit -d</code> after doing so.</p>
<p>Ok so now you have to choose</p>
<h3>a) No encryption</h3>
<p>If you don't need encryption then you're almost done.</p>
<p>First we need to give the RAID device (<code>/dev/md0</code>) a file system and then mount it.</p>
<pre><code>mkfs.ext4 /dev/md0
mount -t ext4 /dev/md0 /mnt</code></pre>
<p>At this stage you should see the disk array when running <code>df -h</code>. Congratulations if you made it this far!</p>
<p>To automate mount on boot add the following to your <code>/etc/fstab</code></p>
<pre><code>/dev/md0    /mnt    ext4    rw  0   0</code></pre>
<h3>b) Using LUKS disk encryption</h3>
<p>For testing purposes I'll be using a password for encryption but if you want your server to automatically unlock after boot, see this post I wrote about the subject: <a href="https://blog.haschek.at/2020/the-encrypted-homelab.html">The encrypted homelab</a></p>
<p><code>openssl rand 512 | base64 -w 0 | tr -cd '[:alnum:]._-' | head -c 64</code></p>
<figure><img loading="lazy" src="https://pictshare.net/11ukk1.png"><figcaption>This should spit out a good password for us to use but you can use your own if you like</figcaption></figure>
<p>Now that we have our password, we encrypt the raid device</p>
<pre><code>cryptsetup -v -c serpent-xts-plain64 -s 512 --hash sha256 luksFormat /dev/md0</code></pre>
<p>Then we'll have to unlock it (after every boot too, see <a href="https://blog.haschek.at/2020/the-encrypted-homelab.html">my other post</a> on how to automate it)</p>
<pre><code>cryptsetup open /dev/md0 data</code></pre>
<p>The second parameter is now used as our new block device we can use. It creates <code>/dev/mapper/data</code> and we can now use it as if it were a normal hard disk.</p>
<p>So let's first give it a file system and then mount it</p>
<pre><code>mkfs.ext4 /dev/mapper/data
mount -t ext4 /dev/mapper/data /mnt</code></pre>
<p>Now you should see your fully encrypted data drive on <code>/mnt</code> (use <code>df -h</code> to check if it's mounted). Since you have to encrypt it before you can mount it, we can't add it to <code>/etc/fstab</code> but in <a href="https://blog.haschek.at/2020/the-encrypted-homelab.html">my other post</a> I explain how it can still be automated on boot.</p>
<hr>


<p>We're going with the obvious solution here: Samba. That's linux powered windows shares which can be accessed by basically all operating systems.</p>
<p>Fi…</p></div></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.haschek.at/2020/the-perfect-file-server.html">https://blog.haschek.at/2020/the-perfect-file-server.html</a></em></p>]]>
            </description>
            <link>https://blog.haschek.at/2020/the-perfect-file-server.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24974971</guid>
            <pubDate>Tue, 03 Nov 2020 00:15:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Leaving OCaml]]>
            </title>
            <description>
<![CDATA[
Score 191 | Comments 117 (<a href="https://news.ycombinator.com/item?id=24974907">thread link</a>) | @rbanffy
<br/>
November 2, 2020 | https://blog.darklang.com/leaving-ocaml/ | <a href="https://web.archive.org/web/*/https://blog.darklang.com/leaving-ocaml/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.darklang.com/content/images/size/w300/2020/11/skeleton-camel.jpg 300w,
                            https://blog.darklang.com/content/images/size/w600/2020/11/skeleton-camel.jpg 600w,
                            https://blog.darklang.com/content/images/size/w1000/2020/11/skeleton-camel.jpg 1000w,
                            https://blog.darklang.com/content/images/size/w2000/2020/11/skeleton-camel.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.darklang.com/content/images/size/w2000/2020/11/skeleton-camel.jpg" alt="Leaving OCaml">
            </figure>

            <section>
                <div>
                    <p><em>Part of a 3 part series. Followups on <a href="https://blog.darklang.com/new-backend-fsharp/">F#</a>, <a href="https://blog.darklang.com/why-dark-didnt-choose-rust/">Rust</a></em></p><p>I built the first demo of Dark in Python, in about two weeks. A few months later when I started productizing it, I rebuilt it in OCaml. Back in 2017, when I was considering the language and platform to use for Dark, OCaml was extremely compelling:</p><ul><li>it's a high-level language with static types, so easy to make large scale changes as we figure out what the language/product was</li><li>you mostly model data with sum types, which in my mind are the best way to model data</li><li>it's very similar to the language I wanted to build (in particular, we could reuse built-in immutable data structures for Dark's values)</li><li>it had a reputation for being high-performance, which meant that we could write an interpreter for Dark and not have it be terribly slow (vs writing an interpreter in python, which might be too slow)</li></ul><p>Unfortunately, as we've built Dark we've run into significant problems that have made it challenging to build in OCaml.</p><h2 id="lack-of-libraries">Lack of libraries</h2><p>When you bet on an off-mainstream language, one of the things you accept is that many libraries are not going to be available. When there is a small community, often there aren't enough people working in the language to make important libraries. This is especially true if few people are building business applications.</p><p>In OCaml there are many high quality libraries, especially for data structures and data manipulation. The annual<a href="https://opensource.janestreet.com/core/"> Jane Street code dump</a> has been quite useful and very high quality. However, we really felt the lack of several libraries. The most obvious of these is that we had to build a <a href="https://github.com/darklang/dark/blob/main/backend/libexecution/unicode_string.mli">Unicode string library</a> ourselves (built on top of the <a href="https://erratique.ch/software/uuseg">very impressive OCaml Unicode libraries</a> built by <a href="https://erratique.ch/contact.en">Daniel Bünzli</a>), but we needed many more libraries than that.</p><p>The lack of an SDK for Google Cloud has affected us greatly. When you're searching for product-market fit, you do the simplest, easiest thing. If you lack a good SDK for your cloud provider, the simplest, easiest thing is often a terrible architectural choice. We've built our own queue on top of our database rather than using the production-quality cloud queues available on GCP. Similarly, we barely use the Cloud Storage (GCP's version of S3), because we initially put things in the database <a href="https://blog.darklang.com/evolving-darks-tracing-system/">because it was easier</a>. We've built 3 services, 2 <a href="https://github.com/darklang/dark/tree/main/containers/stroller">in</a> <a href="https://github.com/darklang/dark/tree/main/containers/queue-scheduler">Rust</a>, and 1 in <a href="https://github.com/darklang/dark/tree/main/containers/postgres-honeytail">Go</a>, to workaround the challenges we've faced.</p><p>The biggest challenge here is our use of Postgres. Postgres is a great database and we're big fans, but Cloud SQL is not a great hosted database. GCP's position is that Cloud SQL is there to tick a box and we should be using Cloud Spanner. I would love to switch to Cloud Spanner, but we have no driver for it in OCaml. Given the Postgres driver in OCaml is not particularly mature, it's hard to expect that a Cloud Spanner driver would exist, and indeed it doesn't. We've had to contribute to the <a href="https://github.com/mmottl/postgresql-ocaml/commit/81a4ae5240decd8f483a90568257cfbc1558c7ed">OCaml Postgres driver</a>, and some parts of our codebase have been <a href="https://github.com/darklang/dark/blob/main/backend/libbackend/serialize.ml#L226">well and truly mangled</a> when working around features not supported in that driver.</p><p>We've also suffered from a lack of a high-level, production web stack (there are <a href="https://github.com/anmonteiro/ocaml-h2">low-level stacks with good reputations</a> that I've struggled to use, and a <a href="https://github.com/oxidizing/sihl">few</a> <a href="https://github.com/reason-native-web/morph">new</a> ones out there that look good), in particular lacking a user authentication module. We've been using <a href="https://auth0.com/">Auth0</a> to work around this for now, which has more moving pieces than I'd like, and a shockingly high cost (our 7000 users, most of whom never log in, costs us over $500/mo).</p><p>We've worked around other missing vendor SDKs by calling their HTTP endpoints directly and that's been mostly fine. However, for libraries like encryption we don't have that option - we <a href="https://github.com/darklang/dark/pull/1455/files">hacked around a missing encryption library</a>, but decided not to ship it to production until we audited it for security (which was never actually worth the cost).</p><p>At CircleCI, we bet on Clojure. That was also a non-mainstream language, but its ability to call Java SDKs meant we had a mature cloud library, which was essential for building CircleCI. Of course, in OCaml we could call C libraries (and <a href="https://github.com/darklang/dark/pull/1841">even Rust libraries</a>, perhaps), but it doesn't match having native libraries we can call directly.</p><h2 id="learnability">Learnability</h2><p>I'm mostly in the camp that anyone can learn any language, but I saw a team struggle with OCaml, and for good reason. Language tutorials are extremely poor in OCaml compared to other languages; they're mostly lecture notes from academic courses.</p><p>The compiler isn't particularly helpful, certainly compared to Rust or Elm (both of which have been in our stack at one point). Often it gives no information about an error. Syntax errors typically say "Syntax error"; though it will try to give a good error for a mismatched brace, often incorrectly. Type errors can be a real burden to read, even after 3 years of experience with it.</p><p>The docs in OCaml are often challenging to find. The <a href="https://ocaml.janestreet.com/ocaml-core/latest/doc/base/index.html">Jane Street docs</a> have improved significantly in the last few years, but it can be a challenge to even figure out what functions are available in a particular module for most libraries. Compare to the excellent <a href="https://docs.rs/">docs.rs</a> in Rust, which has comprehensive API docs for every package in Rust.</p><p>One of the ways I personally struggled in OCaml is around <code>Lwt</code>. Lwt is (one of!) OCaml's async implementations. I couldn't figure it out several years ago and so just built a single-threaded server. The amount of workarounds and downtime we've suffered from that single decision is immense. A tutorial around building high-performance (or even medium performance!) web servers would be very valuable. </p><p>Tooling is something I read would be good in OCaml. I remember reading there was a debugger that could go back in time! I don't know where that's gone but I've never heard of anyone using it.</p><p>We have struggled to make editor tooling work for us. This is partially because we also use ReasonML and this seems to break things. Unfortunately, this is common in programming, but even more so in small communities: you might be the first person to ever try to use a particular configuration.</p><p>Finally, the disconnect between the various tools is immense. You need to understand Opam, Dune, and Esy, to be able to get something working (you could also do it without Esy and just rely on Opam, but that's much worse). I talked about a bunch of these challenges <a href="https://blog.darklang.com/first-thoughts-on-rust-vs-ocaml/">here</a>.</p><h2 id="language-problems">Language problems</h2><p>Multicore is coming Any Day Now™️, and while this wasn't a huge deal for us, it was annoying. </p><h2 id="minor-annoyances">Minor annoyances</h2><p>One of my biggest annoyances was how often OCaml folks talk about Fancy Type System problems, instead of how to actually build products and applications. In other communities for similar languages (ReasonML, Elm, F#), people talk about building apps and solving their problems. In OCaml, it feels like people spend an awful lot of time discussing Functors. It's not quite at the level that I perceived in the Haskell world, but it pointed out that the people building the core of the ecosystem do not have the same problems that I do (which is building web-y stuff).</p><p>I honestly think OCaml was a great choice at the start. Being able to quickly and safely make large-scale changes to your app is something that staticly-typed functional languages excel at. I'm happy that we made the choice, and in retrospect, it still seems like the best choice of those we had at the time.</p><p>I'm working on building the next version of the backend. We have about 20k lines to be replaced, and they'll be rewritten in a new language while keeping the semantics the same. I plan to leave keep the frontend in ReasonML: it doesn't suffer from the same library problems as it can interface nicely to JS, and it's nearly 50k lines of code so it would be a much bigger undertaking.</p><p>Read <a href="https://blog.darklang.com/new-backend-fsharp/">the followup</a> to see what we picked!</p><hr><p><em><em><em><em><em><em><em><em>You can sign up for Dark </em></em></em></em></em></em></em></em><a href="https://darklang.com/signup" rel="noopener nofollow"><em><em><em><em><em><em><em><em>here</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>. For more info on Dark, follow our </em></em></em></em></em></em></em></em><a href="https://blog.darklang.com/rss" rel="noopener nofollow"><em><em><em><em><em><em><em><em>RSS</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>, follow </em></em></em></em></em></em></em></em><a href="https://twitter.com/darklang" rel="noopener nofollow"><em><em><em><em><em><em><em><em>us</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em> (or </em></em></em></em></em></em></em></em><a href="https://twitter.com/paulbiggar" rel="noopener nofollow"><em><em><em><em><em><em><em><em>me</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>) on Twitter, join our </em></em></em></em></em></em></em></em><a href="https://darklang.com/slack-invite" rel="noopener nofollow"><em><em><em><em><em><em><em><em>Slack Community</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>, watch our </em></em></em></em></em></em></em></em><a href="https://github.com/darklang/dark" rel="noopener nofollow"><em><em><em><em><em><em><em><em>GitHub repo</em></em></em></em></em></em></em></em></a><em>, or join our <a href="http://darklang.com/mailing-list">mailing list</a><em><em><em><em><em><em><em>.</em></em></em></em></em></em></em></em></p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.darklang.com/leaving-ocaml/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24974907</guid>
            <pubDate>Tue, 03 Nov 2020 00:03:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My collection of vintage PC cards]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24974504">thread link</a>) | @pabs3
<br/>
November 2, 2020 | https://vincent.bernat.ch/en/blog/2020-old-pc-cards | <a href="https://web.archive.org/web/*/https://vincent.bernat.ch/en/blog/2020-old-pc-cards">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="lf-text">
            <p>Recently, I have been gathering some old hardware at my parents’
house, notably PC extension cards, as they don’t take much room and
can be converted to a nice display item. Unfortunately, I was not very
concerned about keeping stuff around. Compared to all the hardware I
have acquired over the years, only a few pieces remain.</p>

<p>This SVGA graphics card was installed into a PC powered by a 386SX CPU
running at 16 MHz. This was a good card at the time as it was pretty
fast. It didn’t feature 2D acceleration, unlike the later ET4000/W32.
This version only features 512 KB of RAM. It can display 1024×768
images with 16 colors or 800×600 with 256 colors. It was also
compatible with CGA, EGA, VGA, MDA, and Hercules modes. No
contemporary games were using the SVGA modes but the higher
resolutions were useful with Windows 3.</p>
<p>This card was manufactured directly by Tseng Labs.</p>
<figure><p><span><img alt="Carte Tseng Labs ET4000AX ISA au-dessus de la boîte &quot;Planète Aventure&quot;" src="https://d1g3mdmxf8zbo9.cloudfront.net/images/pc-cards/et4000@1x.jpg" srcset="https://d1g3mdmxf8zbo9.cloudfront.net/images/pc-cards/et4000@2x.jpg 2x" width="900" height="780" loading="lazy"></span></p><figcaption>Tseng Labs ET4000 AX ISA card</figcaption></figure>

<p>My first sound card was an AdLib. My parents bought it in Canada
during the summer holidays in 1992. It uses a Yamaha OPL2 chip to
produce sound via FM synthesis. The first game I have tried is
<a href="https://en.wikipedia.org/wiki/Indiana_Jones_and_the_Last_Crusade:_The_Graphic_Adventure" title="Indiana Jones and the Last Crusade: The Graphic Adventure on Wikipedia">Indiana Jones and the Last Crusade</a>.</p>
<p>I think I gave this AdLib to a friend once I upgraded my PC with a
Sound Blaster Pro 2. Recently, I needed one for a side project, but
they are rare and expensive on eBay. Someone mentioned a cheap clone
on <a href="https://www.vogons.org/viewtopic.php?t=73429" title="Sun Moon Star Adlib Clone">Vogons</a>, so I bought it. It was sold by Sun Moon Star in 1992
and shipped with a CD-ROM of Doom shareware.</p>
<figure><p><span><img alt="AdLib clone on top of &quot;Alone in the Dark&quot; box" src="https://d1g3mdmxf8zbo9.cloudfront.net/images/pc-cards/adlib-clone@1x.jpg" srcset="https://d1g3mdmxf8zbo9.cloudfront.net/images/pc-cards/adlib-clone@2x.jpg 2x" width="700" height="619" loading="lazy"></span></p><figcaption>AdLib clone ISA card by Sun Moon Star</figcaption></figure>

<p>Later, I switched the AdLib sound card with a Sound Blaster Pro 2. It
features an OPL3 chip and was also able to output digital samples. At
the time, this was a welcome addition, but not as important as the FM
synthesis introduced earlier by the AdLib.</p>
<figure><p><span><img alt="Sound Blaster Pro 2 on top of &quot;Day of the Tentacle&quot; box" src="https://d1g3mdmxf8zbo9.cloudfront.net/images/pc-cards/sbpro@1x.jpg" srcset="https://d1g3mdmxf8zbo9.cloudfront.net/images/pc-cards/sbpro@2x.jpg 2x" width="900" height="794" loading="lazy"></span></p><figcaption>Sound Blaster Pro 2 ISA card</figcaption></figure>

<p>I bought this card mostly for the serial port. I was using a 486DX2
running at 66 MHz with a Creatix LC 288 FC external modem. The serial
port was driven by an 8250 UART with no buffer. Thanks to
<a href="http://www.terminate.com/" title="Terminate, a DOS terminal program">Terminate</a>, I was able to connect to <a href="https://en.wikipedia.org/wiki/Bulletin_board_system" title="Bulletin board system on Wikipedia">BBSes</a> with DOS, but this
was not possible with Windows 3 or OS/2. I needed one of these fancy
new cards with a 16550 UART, featuring a 16-byte buffer. At the time,
this was quite difficult to find in France. During a holiday trip, I
convinced my parent to make a short detour from Los Angeles to San
Diego to buy this <em>Promise EIDE 2300 Plus</em> controller card at a shop I
located through an advertisement in a local magazine!</p>
<p>The card also features an EIDE controller with multi-word DMA mode 2
support. In contrast with the older PIO modes, the CPU didn’t have to
copy data from disk to memory.</p>
<figure><p><span><img alt="Promise EIDE 2300 Plus next to an OS/2 Warp CD" src="https://d1g3mdmxf8zbo9.cloudfront.net/images/pc-cards/promise@1x.jpg" srcset="https://d1g3mdmxf8zbo9.cloudfront.net/images/pc-cards/promise@2x.jpg 2x" width="900" height="694" loading="lazy"></span></p><figcaption>Promise EIDE 2300 Plus VLB card</figcaption></figure>

<p>The 3dfx Voodoo2 was one of the first add-in graphics cards
implementing hardware acceleration of 3D graphics. I bought it from a
friend along with his Pentium II box in 1999. It was a big
evolutionary step in PC gaming, as games became more beautiful and
fluid. A traditional video controller was still required for 2D. A
pass-through VGA cable daisy-chained the video controller to the
Voodoo, which was itself connected to the monitor.</p>
<figure><p><span><img alt="3dfx Voodoo 2 Magic 3D II on top of &quot;Jedi Knight: Dark Forces II&quot; box" src="https://d1g3mdmxf8zbo9.cloudfront.net/images/pc-cards/3dfx@1x.jpg" srcset="https://d1g3mdmxf8zbo9.cloudfront.net/images/pc-cards/3dfx@2x.jpg 2x" width="900" height="718" loading="lazy"></span></p><figcaption>3dfx Voodoo2 Magic 3D II PCI card</figcaption></figure>

<p>In the early 2000s, in college, the Internet connection on the campus
was provided by a <a href="https://web.archive.org/web/20020327172921/http://www.crans.org/" title="Cachan Réseau @ Normale Sup'">student association</a> through a  100 Mbps Ethernet
cable. If you wanted to reach the maximum speed, the <em>3Com
3C905C-TX-M</em> PCI network adapter, nicknamed “Tornado”, was the card
you needed. We would buy it second-hand by the dozen and sell them to
other students for around 30 €.</p>
<figure><p><span><img alt="3COM 3C905C-TX-M on top of &quot;Red Alert&quot; box" src="https://d1g3mdmxf8zbo9.cloudfront.net/images/pc-cards/3com@1x.jpg" srcset="https://d1g3mdmxf8zbo9.cloudfront.net/images/pc-cards/3com@2x.jpg 2x" width="700" height="676" loading="lazy"></span></p><figcaption>3Com 3C905C-TX-M PCI card</figcaption></figure>        </div></div>]]>
            </description>
            <link>https://vincent.bernat.ch/en/blog/2020-old-pc-cards</link>
            <guid isPermaLink="false">hacker-news-small-sites-24974504</guid>
            <pubDate>Mon, 02 Nov 2020 23:02:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why your first customer is worth $10M]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24974108">thread link</a>) | @lpolovets
<br/>
November 2, 2020 | https://www.ejorgenson.com/blog/why-your-first-customer-is-worth-10000000 | <a href="https://web.archive.org/web/*/https://www.ejorgenson.com/blog/why-your-first-customer-is-worth-10000000">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-8cf3b1c6433ba9fe42a4"><div><p>Founders and early employees can earn orders of magnitude more than employees 50+. And there is a good reason for that. Early employees aren't travelers, they are cartographers. </p><p>"<a href="http://paulgraham.com/ds.html">Do things that don't scale</a>" is Paul Graham's advice to founders and early employees...</p><blockquote><p>"<em>The most common unscalable thing founders have to do at the start is to recruit users manually. Nearly all startups have to. You can't wait for users to come to you. You have to go out and get them."</em></p></blockquote><p>and while I've always <em>believed</em> this, I didn’t really <em>understand</em>.</p><p>After all, the first customer is the least profitable! They take the most effort, the most attention, the most support, and the most duct tape of any customer to come! Hundreds of hours of founder and early employee work go into building for, earning, and keeping those first customers. Those customers are wildly unprofitable on a unit economic (CAC / LTV) basis, and an accounting basis... and quite possibly even a morale basis.</p><p>There is this moment, when you have a few early customers, and you are feeling bruised and battered and exhausted just from getting those few... that you wonder if this will ever get easier.</p><p>If you spend too much time imagining that all of the customers to come will be AS challenging, slow, and expensive as this first customer — “well, we may as well shut the company down right now.”</p><p>However.</p><p>The math that made me <em>understand</em> "Do things that don't scale" was when I stopped looking at Unit Economics and started looking at Enterprise Value—thinking like an Investor.</p><blockquote><p>"<em>I am a better investor because I am a businessman, and a better businessman because I am an investor." - Warren Buffett</em></p></blockquote><p>I heard <a href="https://www.youtube.com/watch?v=KL97y2Of3cA">Jason Calacanis on Shane Parrish's</a> podcast say a company goes from uninvestable to investable when they go from zero customers to one customer. </p><p>That's when "Do things that don't scale" clicked to me.</p><p>The <strong>projected enterprise value</strong> change when a company goes from 0 customers to 1 customer is... approaching an infinite % increase, because at 0 customers a company is by default worth $0.</p><p>When you don't have any customers, the thing that will add the most value to your business is adding your first customer.</p><p>When a young company adds one customer, they aren't just adding the LTV of that customer. They are also adding the likelihood of winning other customers with similar problems. They gain some incremental credibility, some incremental scale, and lessons to carry forward.</p><p><strong>Think about early sales’ impact on projected enterprise value</strong>, and it is clear winning and keeping customer one is a company's most important job. Your first customer may be worth millions of dollars to your enterprise value<strong>.</strong> It may take you from uninvestable to investable.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603888246335_87688"><div><p>I don't think that trend stops at one. Next most valuable is winning and keeping customer 2. Then 3, etc.</p><p>It's not as obvious when the most important thing for the company is something <strong>other</strong> than winning the next customer, unless there is some critical constraint on serving the next customer.</p><p>The more customers you have, the more certainty, replicability, and economies of scale you gain.</p><p>The unit economics and the accounting profit from customer #100,000 will be better than customer #1... but #100,000's impact on enterprise value will be much lower. </p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603889398200_7697"><div><p>That is why "do things that don't scale" matters — because early customers are huge steps to turning a company from "default dead" ($0) to "default alive" ($1,000,000+). And the early team is rewarded for their high-risk, high-reward cartography work.</p><p>It is hard work. Sitting in front of a customer confused about what they need and whether you can help is uncomfortable. Selling a new product to new customers with no script is tough. Founders and early employees who bring in the first customers are playing a different game and earning different rewards than sales teams who come along later.</p><p><strong>Takeaway:</strong> Act like your first customer is worth $10 million. </p><p>When you look back on the early days from your perch at a $100+ million company value, it will feel true. And the heuristic will help you focus and prioritize early on.</p><p>Notes: </p><ul data-rte-list="default"><li><p>"Customer" implies paying. Other methods of validation are more waffle-y in this context and  you'd look at weekly usage, engagement, etc.</p></li><li><p>Numbers are just an example here. For a free social product, maybe multiply by 10 or 100. If you’re Palantir, you may only have 100 customers ever.</p></li></ul></div></div></div>]]>
            </description>
            <link>https://www.ejorgenson.com/blog/why-your-first-customer-is-worth-10000000</link>
            <guid isPermaLink="false">hacker-news-small-sites-24974108</guid>
            <pubDate>Mon, 02 Nov 2020 22:14:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Catch Breaking Changes by Watching API Traffic]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24974022">thread link</a>) | @jeanyang
<br/>
November 2, 2020 | https://www.akitasoftware.com/blog/2020/11/1/how-to-catch-breaking-changes-using-akita | <a href="https://web.archive.org/web/*/https://www.akitasoftware.com/blog/2020/11/1/how-to-catch-breaking-changes-using-akita">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5f9f5e25ff6048551e680216" data-item-id="5f9f5e25ff6048551e680216">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1604279881824" id="item-5f9f5e25ff6048551e680216"><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1604279471234_142490"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1604280685685-ZWFH7IB18XTYKDSWZNJW/ke17ZwdGBToddI8pDm48kAx-7VAVUrX83-TmKtI9GwFZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzjxOd1QqWVSDMmGb_7RWR-xbrRIPXdQRvPw48mQHlcKeFmwpAiuBpxGlYDuvh8_jg/dog_washing_car.gif" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1604280685685-ZWFH7IB18XTYKDSWZNJW/ke17ZwdGBToddI8pDm48kAx-7VAVUrX83-TmKtI9GwFZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzjxOd1QqWVSDMmGb_7RWR-xbrRIPXdQRvPw48mQHlcKeFmwpAiuBpxGlYDuvh8_jg/dog_washing_car.gif" data-image-dimensions="500x260" data-image-focal-point="0.5,0.5" alt="dog_washing_car.gif" data-load="false" data-image-id="5f9f6168ff6048551e687727" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-a2c285e8aefcd417da69"><div><p>As modern web apps shift to service-oriented architectures, it’s been getting more and more difficult to catch bugs before production. Because it’s hard to simulate production workloads beforehand, functionality that depends on service-service interactions often doesn’t get fully exercised until production. The result is that bugs don’t get uncovered until they are triggered by live user traffic.</p><p>As a developer who has also worked in devops, I understand the importance of finding and fixing bugs early in the development cycle. This is one of the reasons I’m excited to be working on change management at Akita. A few weeks ago, our team published a <a href="https://www.akitasoftware.com/blog/2020/9/22/faster-better-earlier-catch-breaking-changes-by-diffing-api-behavior">blog post talking about this at a high level</a>. In this blog post, I’m going to go into the nuts and bolts. I’ll show a bug that’s hard to catch with source diffs, linters, or static analysis. Then I’ll show how to use Akita to catch this bug, describing the entire setup from start to finish. Finally, I’ll explain how Akita works under the hood.</p><div><p>Something I’m particularly proud of about Akita is that you can use us without needing to proxy or to make any code changes—and we’ve been working hard so you can set up everything you need to catch breaking changes in just minutes. <a href="https://www.akitasoftware.com/get-invite?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_11_2_howto">Try out our private beta</a> to see for yourself!</p></div><h2>🕵🏻‍♀️ A particularly sneaky bug</h2><p><em>You can find the Go source code for this example on </em><a href="https://github.com/akitasoftware/akita-change-management-demo"><em>GitHub here</em></a><em>.</em></p><p>Let’s say you’re working on an API that returns information about users. To comply with regulations, you omit user phone numbers from the response to prevent callers of your API from storing this information in a scattered fashion that makes it hard to service deletion requests.&nbsp;</p><p>For example, your API might look like:&nbsp;</p></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1604279471234_65920"><div><!-- HTML generated using hilite.me --><div><pre><span>type</span> <span>User</span> <span>struct</span> <span>{</span>
  <span>ID</span> <span>string</span> <span>`json:”id”`</span>

  <span>// Don’t return phone number for regulation reasons!</span>
  <span>Phone</span> <span>string</span> <span>`json:”-”`</span>
<span>}</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
  <span>...</span>
  <span>http</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/users/json"</span><span>,</span> <span>func</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
    <span>w</span><span>.</span><span>Header</span><span>().</span><span>Set</span><span>(</span><span>"Content-Type"</span><span>,</span> <span>"application/json"</span><span>)</span>
    <span>w</span><span>.</span><span>WriteHeader</span><span>(</span><span>200</span><span>)</span>
    <span>enc</span> <span>:=</span> <span>json</span><span>.</span><span>NewEncoder</span><span>(</span><span>w</span><span>)</span>
    <span>enc</span><span>.</span><span>Encode</span><span>(</span><span>myUsers</span><span>)</span>
  <span>})</span>
  <span>...</span>
<span>}</span>
</pre></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604279471234_65988"><p>Testing your endpoint shows that phone numbers are omitted as expected:</p></div><div data-block-type="23" id="block-yui_3_17_2_1_1604279471234_70908"><div><!-- HTML generated using hilite.me --><div><pre><span>$</span> curl localhost:8080/users/json
<span>[{"id":"usr_295oDMFK8b1yS5dwlSTdgP"},{"id":"usr_6NiejyYEVpWfziUXJgovV6"}]</span>
</pre></div>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604279471234_70976"><p>One day, your colleague Aki adds a new version of the endpoint that returns YAML instead of JSON because they want to introduce some competition in the data serialization market.&nbsp; A very reasonable implementation of the YAML endpoint produces a PR <a href="https://github.com/akitasoftware/akita-change-management-demo/pull/4/files">like this</a>:</p></div><div data-block-type="23" id="block-yui_3_17_2_1_1604279471234_76302"><div><!-- HTML generated using hilite.me --><div><pre>  <span>http</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/users/yaml"</span><span>,</span> <span>func</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
    <span>w</span><span>.</span><span>Header</span><span>().</span><span>Set</span><span>(</span><span>"Content-Type"</span><span>,</span> <span>"application/x-yaml"</span><span>)</span>
    <span>w</span><span>.</span><span>WriteHeader</span><span>(</span><span>200</span><span>)</span>
    <span>enc</span> <span>:=</span> <span>yaml</span><span>.</span><span>NewEncoder</span><span>(</span><span>w</span><span>)</span>
    <span>defer</span> <span>enc</span><span>.</span><span>Close</span><span>()</span>
    <span>enc</span><span>.</span><span>Encode</span><span>(</span><span>myUsers</span><span>)</span>
  <span>})</span>
</pre></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604279471234_76370"><p>A code reviewer without insider knowledge is very likely to gloss over the fact that yaml.Encode(…) does something different than json.Encode. However, when someone actually uses this new endpoint, they get now users’ phone numbers in the response! 🙊</p></div><div data-block-type="23" id="block-yui_3_17_2_1_1604279471234_121010"><div><!-- HTML generated using hilite.me --><div><pre><span>$</span> curl localhost:8080/users/yaml
<span>- id: usr_295oDMFK8b1yS5dwlSTdgP</span>
<span>  phone: (123) 456-7890</span>
<span>- id: usr_6NiejyYEVpWfziUXJgovV6</span>
<span>  phone: (777) 888-9999</span>
</pre></div>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604279471234_121078"><div><p>It turns out that Aki forgot to add the YAML-specific struct tags to the User struct to omit phone numbers from serialization—and now your phone numbers are getting sent somewhere they’re not supposed to go! You don’t realize this until your security team alerts you that they detected this issue in production. By this time, you have to not only roll back the change, but also scrub logs and send out an apology to your users.</p><p>This was a particularly subtle bug because it’s very easy to miss by just looking at source diffs This is also something that linters and static analyses won’t be particularly helpful with, unless you’ve configured them with a rule for this exact change.</p><p>Akita’s change management would catch this by detecting a new data format:</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1604279471234_168191"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1604281011519-982FLZI37TQL9FETVZCA/ke17ZwdGBToddI8pDm48kOfhBKcXkUJv4Y40JSZTrS1Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIR2LMERMdn0vLCunBE33AJTKh9E5k17qCDnCsKwVXj_c/Pull+Request+highlighted.png" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1604281011519-982FLZI37TQL9FETVZCA/ke17ZwdGBToddI8pDm48kOfhBKcXkUJv4Y40JSZTrS1Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIR2LMERMdn0vLCunBE33AJTKh9E5k17qCDnCsKwVXj_c/Pull+Request+highlighted.png" data-image-dimensions="928x520" data-image-focal-point="0.5,0.5" alt="Pull Request highlighted.png" data-load="false" data-image-id="5f9f62b30991472cc53a4cee" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1604281011519-982FLZI37TQL9FETVZCA/ke17ZwdGBToddI8pDm48kOfhBKcXkUJv4Y40JSZTrS1Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIR2LMERMdn0vLCunBE33AJTKh9E5k17qCDnCsKwVXj_c/Pull+Request+highlighted.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604279471234_168490"><div><div><p>We’ll dig into this comment after we show you how to set this up for yourself. And this data leak is just one of <em>many</em> kinds of bugs that are hard to catch pre-production, but that you can catch if you have a better model of how your service is interacting with other services.</p></div><h2>⚡️ Setting up Akita to fix this bug</h2><p>To stop these bugs once and for all, we will show how to add Akita to your CI/CD pipeline, so that you get notified how every pull request changes our API. For our particular deployment, we are using CircleCI and GitHub to run Akita. You can easily modify the instructions for your CI/CD pipeline of choice.</p><p>The steps for getting up and running are:</p><ol data-rte-list="default"><li><p>Create a new service in Akita, if you don’t have one already.</p></li><li><p>Connect Akita to GitHub.</p></li><li><p>Update your CircleCI configuration.</p></li><li><p>Open a pull request with an API change.</p></li></ol><p>The first thing we need to do is head over to the Akita Console and create a new Akita service. You can do that by clicking on the “New Service” button on the left-hand menu. If you already have a service, you can skip this step.</p><p>Once we’ve created and named our new service, we need to connect Akita to Github. To do this, simply click on the “Integrations” menu and then “Integrate” under GitHub. This will take us to GitHub where we can give Akita permission to watch our pull requests.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1604279471234_215681"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1604281630496-C2E9J66LNQ0NPLZVPV3K/ke17ZwdGBToddI8pDm48kLHWjF32f0_zzQbqWTWhXQMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dgxIn2RMiOtJF70cDEvBvW_7FUHZBSRsPBe9uEPsGX4HCjLISwBs8eEdxAxTptZAUg/dd9e60a-Screen_Shot_2020-09-18_at_12.19.09_PM.png" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1604281630496-C2E9J66LNQ0NPLZVPV3K/ke17ZwdGBToddI8pDm48kLHWjF32f0_zzQbqWTWhXQMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dgxIn2RMiOtJF70cDEvBvW_7FUHZBSRsPBe9uEPsGX4HCjLISwBs8eEdxAxTptZAUg/dd9e60a-Screen_Shot_2020-09-18_at_12.19.09_PM.png" data-image-dimensions="1556x645" data-image-focal-point="0.5,0.5" alt="dd9e60a-Screen_Shot_2020-09-18_at_12.19.09_PM.png" data-load="false" data-image-id="5f9f651e5578154aa88f5d4b" data-type="image" src="https://www.akitasoftware.com/blog/2020/11/1/dd9e60a-Screen_Shot_2020-09-18_at_12.19.09_PM.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604279471234_215980"><div><p>Now that Akita can post to our GitHub projects, we need to complete the loop by adding Akita to our CI Pipeline. This is relatively straightforward: we just need to add a step to start the Akita Client and another one that stops the client after our tests have completed.</p><p>The code to start our client is pretty simple:</p></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1604279471234_229396"><div><!-- HTML generated using hilite.me --><div><pre>  <span>-</span> <span>run</span><span>:</span>
    <span>name</span><span>:</span> <span>Start Akita Client</span>
    <span>command</span><span>:</span> <span>|</span>
      <span>docker run --rm -d \</span>
        <span>--env CI="${CI}" \</span>
        <span>--env CIRCLECI="${CIRCLECI}" \</span>
        <span>--env CIRCLE_REPOSITORY_URL="${CIRCLE_REPOSITORY_URL}" \</span>
        <span>--env CIRCLE_BRANCH="${CIRCLE_BRANCH}" \</span>
        <span>--env CIRCLE_SHA1="${CIRCLE_SHA1}" \</span>
        <span>--env CIRCLE_PULL_REQUEST="${CIRCLE_PULL_REQUEST}" \</span>
        <span>--env CIRCLE_BUILD_URL="${CIRCLE_BUILD_URL}" \</span>
        <span>--env AKITA_API_KEY_ID=${AKITA_API_KEY_ID} \</span>
        <span>--env AKITA_API_KEY_SECRET=${AKITA_API_KEY_SECRET} \</span>
        <span>--network=host \</span>
        <span>--name akita \</span>
        <span>akitasoftware/cli:latest learn \</span>
        <span>--service [YOUR SERVICE NAME HERE] \</span>
        <span>--port [YOUR SERVICE PORT HERE]</span>
    <span>background</span><span>:</span> <span>true</span>
</pre></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604279471234_229464"><p>Then after you have run your integration test, simply add another step to stop the Akita Client, like this:</p></div><div data-block-type="23" id="block-yui_3_17_2_1_1604279471234_232955"><div><!-- HTML generated using hilite.me --><div><pre>  <span>-</span> <span>run</span><span>:</span>
    <span>name</span><span>:</span> <span>Stop Akita SuperLearn</span>
    <span>command</span><span>:</span> <span>docker kill --signal=SIGINT akita</span>
</pre></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604279471234_233023"><div><p>You can see a complete example of our CircleCI configuration <a href="https://github.com/akitasoftware/akita-change-management-demo/blob/master/.circleci/config.yml">here</a>.</p><p>Once you have merged in the CircleCI changes, you can now test things out by making a quick change to your codebase, commit the change and open a new pull request. If everything went according to plan, once your pipeline completes Akita will leave a comment detailing how your API has changed.</p><p>Below is the comment for the example we introduced in the last section.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1604279471234_316511"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1604283574162-FYJ8ODPDUEAIMJQSS72L/ke17ZwdGBToddI8pDm48kOfhBKcXkUJv4Y40JSZTrS1Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIR2LMERMdn0vLCunBE33AJTKh9E5k17qCDnCsKwVXj_c/Pull+Request+highlighted.png" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1604283574162-FYJ8ODPDUEAIMJQSS72L/ke17ZwdGBToddI8pDm48kOfhBKcXkUJv4Y40JSZTrS1Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIR2LMERMdn0vLCunBE33AJTKh9E5k17qCDnCsKwVXj_c/Pull+Request+highlighted.png" data-image-dimensions="928x520" data-image-focal-point="0.5,0.5" alt="Pull Request highlighted.png" data-load="false" data-image-id="5f9f6cb542433c0d822d70a4" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1604283574162-FYJ8ODPDUEAIMJQSS72L/ke17ZwdGBToddI8pDm48kOfhBKcXkUJv4Y40JSZTrS1Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIR2LMERMdn0vLCunBE33AJTKh9E5k17qCDnCsKwVXj_c/Pull+Request+highlighted.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604279471234_316810"><div><p>In this comment you can see:</p><ul data-rte-list="default"><li><p><strong>Endpoints Added by this pull request. </strong>In this case, we added the YAML endpoint.</p></li><li><p><strong>Endpoints Changed by this pull request. </strong>As we expected, we modified the JSON endpoint.</p></li><li><p><strong>Data Formats Added by this pull request. </strong>This is where the new US phone number data type appears. Akita <a href="https://www.akitasoftware.com/blog/2020/9/29/taking-types-to-the-next-level-stop-api-bugs-by-inferring-data-formats">automatically detects precise data formats</a> to make this as useful as possible.</p></li><li><p>﻿<strong>The Baseline Specification that was used for this comparison.</strong> Akita gives you the flexibility to compare against any other test or production spec, so we also show what spec we diffed against.</p></li></ul><h2>🌎 Akita across test and production</h2><p>Now that you’ve supercharged your pull requests with Akita, you’re probably saying to yourself “This is great for testing, but what if my tests don’t cover everything you’d see in production?”&nbsp;</p><p>Good news: Akita also allows you to compare test behavior against actual production behavior. To do this, you can use the same start and stop learning commands from your CI in your production environment to create a model of your production behavior. To use it as a baseline for pull requests comparisons, simply mark the production spec as stable in the Akita Console.</p><div><p>Talk to us if this is something you’re interested in!</p></div><h2>🔩 Akita nuts and bolts</h2><p>Under the hood, Akita works by building models of API behavior by watching API traffic.</p><p>What I just showed you works by:</p><ol data-rte-list="default"><li><p><strong>Reconstructing HTTP requests/responses from live packet captures. </strong>No code changes or proxies. And we only send metadata back to the Akita cloud!</p></li><li><p><strong>Building models of your API behavior.</strong> Expressed in the form of an API spec, annotated with <a href="https://www.akitasoftware.com/blog/2020/9/29/taking-types-to-the-next-level-stop-api-bugs-by-inferring-data-formats">data formats</a> and eventually, implicit API contracts.</p></li><li><p><strong>Diffing on API behavior.</strong> Once we have the API models, it’s straightforward to diff.</p></li></ol></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604279471234_374356"><div><div><p>And this doesn’t just have to be traffic that already exists in your environments. More on running Akita with automatically generated traffic in future blog posts!</p></div><h2>🐕 Try Akita for yourself!</h2><p>Akita is currently available in a private beta. And I’m working hard every day to help you catch problematic changes more easily. <a href="https://www.akitasoftware.com/get-invite?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_11_2_howto">Sign up here</a> to try it out!</p></div></div></div></div></div>

    

    

    <section id="comments-5f9f5e25ff6048551e680216">
      
  


    </section>

  </article>





  <nav>

    

    
      <a href="https://www.akitasoftware.com/blog/2020/10/20/no-spec-no-problem-how-i-autogenerated-an-api-spec-for-notion">
        <div>
          <p>Next</p>
      …</div></a></nav></section></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.akitasoftware.com/blog/2020/11/1/how-to-catch-breaking-changes-using-akita">https://www.akitasoftware.com/blog/2020/11/1/how-to-catch-breaking-changes-using-akita</a></em></p>]]>
            </description>
            <link>https://www.akitasoftware.com/blog/2020/11/1/how-to-catch-breaking-changes-using-akita</link>
            <guid isPermaLink="false">hacker-news-small-sites-24974022</guid>
            <pubDate>Mon, 02 Nov 2020 22:06:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to say “I don't know”]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24972952">thread link</a>) | @mooreds
<br/>
November 2, 2020 | https://letterstoanewdeveloper.com/2020/11/02/how-to-say-i-dont-know/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2020/11/02/how-to-say-i-dont-know/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Dear new developer, </p>



<p>The honest truth is that you won’t know everything. No one does. The CEO, CTO, the team lead, that really smart senior developer on your team, none of them know everything. In fact, I bet if you asked any one of them if they’d been stymied in the past week, they’d reveal that yes, they ran into something they didn’t know how to do or how to approach.</p>



<p>Encyclopedic knowledge isn’t a good goal. You need to know how to figure things out. But when someone asks you “can you do X?”, you need to be prepared with the right answer, even if you don’t know how to do X. For example, I was tasked with setting up a static IP for a heroku application. I didn’t know how to do this. Rather than say “I don’t know how to do that”, I said “let me do some research and get back to you.” I also asked about deadlines and how high a priority this was. </p>



<p>I did some research, read some docs and came up with a proposed solution. I discussed it at standup with my team, including my boss, and we came up with a path toward implementation. </p>



<p>When you don’t know something, and someone asks you about it, there are a few things you must do.</p>



<p>First, you should tell them you don’t know. They might have some clues for you, or pointers to documentation. These can all accelerate your ability to do what is asked of you.</p>



<p>Depending on the situation, they may assume you know, based on their experience. For example, I work in the authentication space right now, with standards like OAuth and OIDC. When I first started, I had to ask what every piece of jargon meant, but after a few months I got up to speed. Now when I talk to other audiences, <em>I</em> need to be careful not to use too much jargon or assume what others know. One favorite technique I use is repeating back what someone said: “Can I repeat back to you what said to make sure I understand it? What I heard is that the OAuth code grant redirects to the client application after the user authenticates. Is that right?”</p>



<p>When you say “I don’t know” don’t stop there. Say “I don’t know, but I’ll find out.” Again, they may point you in a direction, but by adding that second clause, you indicate that you’ll solve this problem. You should also ask about timeline and priority if that hasn’t been communicated (by story points, a task tracker or in some other fashion).</p>



<p>Finally, do what you say you’re going to do. Find out what you didn’t know. Don’t be afraid to ask questions of your team members, spend time on the internet searching, set up your dev environment and tweak settings, brainstorm, get frustrated, and write down hypotheses that you can test out. All of these are techniques I’ve used in trying to figure things out.</p>



<p>Saying I don’t know, honestly, with a plan to remedy your ignorance, is a key part of being a software developer.</p>



<p>Sincerely, </p>



<p>Dan</p>
	</div><div>
			<!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2020-11-02T11:13:00-07:00">November 2, 2020</time><time datetime="2020-10-18T09:20:00-06:00">October 18, 2020</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2020/11/02/how-to-say-i-dont-know/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24972952</guid>
            <pubDate>Mon, 02 Nov 2020 20:37:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DKIM: Show Your Privates]]>
            </title>
            <description>
<![CDATA[
Score 90 | Comments 42 (<a href="https://news.ycombinator.com/item?id=24972609">thread link</a>) | @ryan-c
<br/>
November 2, 2020 | https://rya.nc/dkim-privates.html | <a href="https://web.archive.org/web/*/https://rya.nc/dkim-privates.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"> <p>If you’re like most people, there’s a good chance that it’s been years since you’ve sent an email that wasn’t cryptographically signed. You don’t use PGP, you say? Well, even if <em>you</em> are not signing your email, your provider is almost certainly doing it for you. Plausible deniability has been tossed aside in the name of stopping spam, but it doesn’t have to be.</p> <p><span data-title="DomainKeys Identified Mail"><abbr title="DomainKeys Identified Mail">DKIM</abbr></span>, originally standardized in 2007 by <a href="http://tools.ietf.org/html/rfc4871.html">RFC 4871</a>, now has near universal<a href="#id4" id="id1">[1]</a> adoption. To quote the RFC, the goal behind the protocol is to “permit a signing domain to assert responsibility for a message, thus protecting message signer identity and the integrity of the messages they convey”. It’s one of several technologies used prevent the sender identity information in email from being spoofed<a href="#id5" id="id2">[2]</a>. Anti-spam systems use it to help determine whether to consider the reputation of a domain name when making a processing decision.</p> <p>While <abbr title="DomainKeys Identified Mail">DKIM</abbr> was designed to be useful for spam prevention, the cryptographic signatures it uses have quietly made a property called “<a href="https://en.wikipedia.org/wiki/Non-repudiation">non-repudiation</a>” the new normal for email. The term is used in in contract law — for example if someone claims “that’s not my signature”, they could be said to be “repudiating” the authenticity of the document. In the case of email, the impact is that if you have a copy of an email in its original format including full headers (for example, an email spool dump) you can check the signature. The extent to which this is a reliable means of verification varies depending on the circumstances — keys short enough to be cracked used to be common, and in some cases straight-up theft of the private keys is plausible.</p> <p>Meanwhile, secure messaging tools like <a href="https://en.wikipedia.org/wiki/Off-the-Record_Messaging">OTR</a> and its successors have taken the approach of explicitly providing “deniable encryption”. The <a href="https://signal.org/blog/simplifying-otr-deniability/#potential-simplifications-and-improvements">state of the art</a> allows a sender, given a recipient’s public key, to craft a fake transcript apparently between the two of them that will pass cryptographic checks. This is generally fine for users of these apps because they know what they said. To the best of my knowledge, there is nowhere this creates a legal “get out of jail free” card. All it really does is ensure the users of these tools aren’t <em>reducing</em> their deniability by using the tool. This is an issue where <abbr title="DomainKeys Identified Mail">DKIM</abbr> really fails its users, and I’m apparently not the only one that feels this way.</p> <blockquote> <p>Apropos of nothing, I really wish Gmail would start publishing its expired DKIM secret keys.</p> <p>—<a href="https://twitter.com/matthew_d_green/status/1323011619069321216">Matthew Green</a></p> </blockquote> <p>A little over three years ago, I started doing exactly that for my domain. Since then, I’ve had a <a href="https://gist.github.com/ryancdotorg/a8f565b9e4f0902eb7b5cd4cdefeea0f">key rotation script</a> running every day, generating a new key and adding the appropriate record (called a “selector”).</p> <div><pre><span></span><code>20170829-<wbr>b29b2444f764c222c3faf5c.<wbr>_domainkey.<wbr>ryanc.<wbr>org.<wbr> 5 <wbr>IN <wbr>TXT <wbr>"<wbr>v=<wbr>DKIM1;<wbr>t=<wbr>s;<wbr>h=<wbr>sha256;<wbr>p=<wbr>MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQDkOSIRW7R8a3e0J0lZqbBJSpHJYPk043/<wbr>OB3lcT2apKtnu7MLjIRqUAgRyYSVAGC10ID2Qlxmy1Ji3EBRB1qI2IsNKgC2C4qzGxx54ShpVR/<wbr>8yY9Qy1eyNtTF5Y/<wbr>XSoLWoRVO1oly+<wbr>WL+<wbr>4O2TRuyujEwoZcFUwXzuuuqJtzbI17wIDAQAB"<wbr>
</code></pre></div> <p>Each selector remains live for seven days, then is “revoked” by publishing an update blanking the public key portion of the record.</p> <div><pre><span></span><code>20170829-<wbr>b29b2444f764c222c3faf5c.<wbr>_domainkey.<wbr>ryanc.<wbr>org.<wbr> 5 <wbr>IN <wbr>TXT <wbr>"<wbr>v=<wbr>DKIM1;<wbr>t=<wbr>s;<wbr>p=<wbr>"<wbr>
</code></pre></div> <p>Once another three days pass, the minimal set of <a href="https://en.wikipedia.org/wiki/RSA_(cryptosystem)">RSA</a> parameters needed to recreate the public and private keys are published in the selector’s “notes” field.</p> <div><pre><span></span><code>20170829-<wbr>b29b2444f764c222c3faf5c.<wbr>_domainkey.<wbr>ryanc.<wbr>org.<wbr> 5 <wbr>IN <wbr>TXT <wbr>"<wbr>v=<wbr>DKIM1;<wbr>t=<wbr>s;<wbr>p=<wbr>;<wbr>n=<wbr>e:<wbr>AQAB,<wbr>p:<wbr>6o/<wbr>8upWykC5USot9Q2o5M89EO1qA7J/<wbr>ao/<wbr>FPc2TUJKat+<wbr>z4JXde2HWW/<wbr>8D3LJR4hGwSpgwLMq9drTzdjbzFTkQ=<wbr>=<wbr>,<wbr>q:<wbr>+<wbr>RTTux+<wbr>yMx0LPyXDkAQiEBcOt8xYrr60s1sXO/<wbr>5nQSQSZBlLtRJKHQpz65MnIxlOCB+<wbr>1umqLW8q78hHC3Asxfw=<wbr>=<wbr>"<wbr>
</code></pre></div> <p>The format here is non-standard, as a full RSA private key with all of the redundant data it includes would exceed the 255 character limit for strings stored in DNS<a href="#id6" id="id3">[3]</a>. A small Python script is enough to reconstitute everything, though.</p> <table><thead><tr><th colspan="2"><a href="https://rya.nc/dkim-privates_/attach/dkim-private.py" download="">dkim-private.py</a></th></tr></thead><tbody><tr><td unselectable="on">1</td><td> <code><span>import</span> <span>gmpy2</span><span>,</span> <span>sys</span><span>,</span> <span>dns.resolver</span></code> </td></tr><tr><td unselectable="on">2</td><td> <code><span>from</span> <span>Cryptodome.PublicKey</span> <span>import</span> <span>RSA</span></code> </td></tr><tr><td unselectable="on">3</td><td> <code><span>from</span> <span>base64</span> <span>import</span> <span>b64decode</span> <span>as</span> <span>b64d</span></code> </td></tr><tr><td unselectable="on">4</td><td> <code></code> </td></tr><tr><td unselectable="on">5</td><td> <code><span>def</span> <span>decode_dkim_private</span><span>(</span><span>txt</span><span>):</span></code> </td></tr><tr><td unselectable="on">6</td><td> <code>    <span>params</span> <span>=</span> <span>dict</span><span>()</span></code> </td></tr><tr><td unselectable="on">7</td><td> <code>    <span># Parse the DKIM selector record.</span></code> </td></tr><tr><td unselectable="on">8</td><td> <code>    <span>for</span> <span>key</span><span>,</span> <span>_</span><span>,</span> <span>val</span> <span>in</span> <span>map</span><span>(</span><span>lambda</span> <span>x</span><span>:</span> <span>x</span><span>.</span><span>partition</span><span>(</span><span>'='</span><span>),</span> <span>txt</span><span>.</span><span>split</span><span>(</span><span>';'</span><span>)):</span></code> </td></tr><tr><td unselectable="on">9</td><td> <code>        <span>if</span> <span>key</span> <span>==</span> <span>'n'</span><span>:</span></code> </td></tr><tr><td unselectable="on">10</td><td> <code>            <span>for</span> <span>k</span><span>,</span> <span>v</span> <span>in</span> <span>map</span><span>(</span><span>lambda</span> <span>x</span><span>:</span> <span>x</span><span>.</span><span>split</span><span>(</span><span>':'</span><span>),</span> <span>val</span><span>.</span><span>split</span><span>(</span><span>','</span><span>)):</span></code> </td></tr><tr><td unselectable="on">11</td><td> <code>                <span>params</span><span>[</span><span>k</span><span>]</span> <span>=</span> <span>int</span><span>.</span><span>from_bytes</span><span>(</span><span>b64d</span><span>(</span><span>v</span><span>),</span> <span>'big'</span><span>)</span></code> </td></tr><tr><td unselectable="on">12</td><td> <code>    <span># Compute rest of RSA keypair parameters (if possible).</span></code> </td></tr><tr><td unselectable="on">13</td><td> <code>    <span>if</span> <span>all</span> <span>(</span><span>k</span> <span>in</span> <span>params</span> <span>for</span> <span>k</span> <span>in</span> <span>(</span><span>'e'</span><span>,</span> <span>'p'</span><span>,</span> <span>'q'</span><span>)):</span></code> </td></tr><tr><td unselectable="on">14</td><td> <code>        <span>params</span><span>[</span><span>'n'</span><span>]</span> <span>=</span> <span>params</span><span>[</span><span>'p'</span><span>]</span> <span>*</span> <span>params</span><span>[</span><span>'q'</span><span>]</span></code> </td></tr><tr><td unselectable="on">15</td><td> <code>        <span>phi</span> <span>=</span> <span>(</span><span>params</span><span>[</span><span>'p'</span><span>]</span> <span>-</span> <span>1</span><span>)</span> <span>*</span> <span>(</span><span>params</span><span>[</span><span>'q'</span><span>]</span> <span>-</span> <span>1</span><span>)</span></code> </td></tr><tr><td unselectable="on">16</td><td> <code>        <span>params</span><span>[</span><span>'d'</span><span>]</span> <span>=</span> <span>int</span><span>(</span><span>gmpy2</span><span>.</span><span>invert</span><span>(</span><span>params</span><span>[</span><span>'e'</span><span>],</span> <span>phi</span><span>))</span></code> </td></tr><tr><td unselectable="on">17</td><td> <code>        <span>rsa</span> <span>=</span> <span>map</span><span>(</span><span>lambda</span> <span>x</span><span>:</span> <span>params</span><span>[</span><span>x</span><span>],</span> <span>'nedpq'</span><span>)</span></code> </td></tr><tr><td unselectable="on">18</td><td> <code>        <span>return</span> <span>RSA</span><span>.</span><span>construct</span><span>(</span><span>tuple</span><span>(</span><span>rsa</span><span>))</span></code> </td></tr><tr><td unselectable="on">19</td><td> <code>    <span>else</span><span>:</span></code> </td></tr><tr><td unselectable="on">20</td><td> <code>        <span>return</span> <span>None</span></code> </td></tr><tr><td unselectable="on">21</td><td> <code></code> </td></tr><tr><td unselectable="on">22</td><td> <code><span>if</span> <span>__name__</span> <span>==</span> <span>'__main__'</span> <span>and</span> <span>len</span><span>(</span><span>sys</span><span>.</span><span>argv</span><span>)</span> <span>==</span> <span>3</span><span>:</span></code> </td></tr><tr><td unselectable="on">23</td><td> <code>    <span>domain</span> <span>=</span> <span>sys</span><span>.</span><span>argv</span><span>[</span><span>1</span><span>]</span></code> </td></tr><tr><td unselectable="on">24</td><td> <code>    <span>selector</span> <span>=</span> <span>sys</span><span>.</span><span>argv</span><span>[</span><span>2</span><span>]</span></code> </td></tr><tr><td unselectable="on">25</td><td> <code>    <span>for</span> <span>answer</span> <span>in</span> <span>dns</span><span>.</span><span>resolver</span><span>.</span><span>query</span><span>(</span><span>selector</span> <span>+</span> <span>'._domainkey.'</span> <span>+</span> <span>domain</span><span>,</span> <span>'TXT'</span><span>):</span></code> </td></tr><tr><td unselectable="on">26</td><td> <code>        <span>txt</span> <span>=</span> <span>str</span><span>(</span><span>answer</span><span>)</span><span>.</span><span>strip</span><span>(</span><span>'"'</span><span>)</span></code> </td></tr><tr><td unselectable="on">27</td><td> <code>        <span>print</span><span>(</span><span>decode_dkim_private</span><span>(</span><span>txt</span><span>)</span><span>.</span><span>exportKey</span><span>()</span><span>.</span><span>decode</span><span>())</span></code> </td></tr></tbody></table><p>An example run:</p> <div><pre><span></span><code><span>$</span> ./dkim-private.py <span>'ryanc.org'</span> <span>'20170829-b29b2444f764c222c3faf5c'</span>
<span>-----BEGIN RSA PRIVATE KEY-----</span>
<span>MIICXQIBAAKBgQDkOSIRW7R8a3e0J0lZqbBJSpHJYPk043/OB3lcT2apKtnu7MLj</span>
<span>IRqUAgRyYSVAGC10ID2Qlxmy1Ji3EBRB1qI2IsNKgC2C4qzGxx54ShpVR/8yY9Qy</span>
<span>1eyNtTF5Y/XSoLWoRVO1oly+WL+4O2TRuyujEwoZcFUwXzuuuqJtzbI17wIDAQAB</span>
<span>AoGBAKClArD7PzExKGJcIQqHIjqEzdfVdbVfyc+JfUiX72h2bE78wzXDUIUMYnrs</span>
<span>nJ7gJeaO5ycG5ST29sQtAkVRwn1KTLaU9fYmGpbkKyOWWfmztppZIvwi9l4tU5h2</span>
<span>GJVw+HbhcWO6tYbTqR9Bc8IelXyVibwmJwImr0AoD8sBLryhAkEA6o/8upWykC5U</span>
<span>Sot9Q2o5M89EO1qA7J/ao/FPc2TUJKat+z4JXde2HWW/8D3LJR4hGwSpgwLMq9dr</span>
<span>TzdjbzFTkQJBAPkU07sfsjMdCz8lw5AEIhAXDrfMWK6+tLNbFzv+Z0EkEmQZS7US</span>
<span>Sh0Kc+uTJyMZTggftbpqi1vKu/IRwtwLMX8CQFT/ABGMlTvxzdGFYkq/fyLrBEqN</span>
<span>rRIRiuTFWIj0DHuLepgEDtjWhcN5T2f6vFYi6NQliFdU+F18ngICjCGKukECQHse</span>
<span>ClIyJpkRQB/kgLfM8zFU1FeRUDx/0z3cRq3G4C7Yr6Z+wmcsNSoJoqbMw8mblnB5</span>
<span>jBAq3dtvaFsM4G53se0CQQC9ocR9eQdXvq5ibwZAmgYcMLEaq7NeX//l6zdxLd52</span>
<span>NcVcuaAUzf5KdTRwA9gJ4Qdzwntc+UB2ElpI2AOj7AFV</span>
<span>-----END RSA PRIVATE KEY-----</span>
</code></pre></div> <p>When I originally set this up, I was a bit concerned that I’d run into issues with filtering systems trying to validate my sent emails significantly after delivery. Per the RFC:</p> <blockquote> A signer should not sign with a private key when the selector containing the corresponding public key is expected to be revoked or removed before the verifier has an opportunity to validate the signature. The signer should anticipate that verifiers may choose to defer validation, perhaps until the message is actually read by the final recipient. In particular, when rotating to a new key pair, signing should immediately commence with the new private key and the old public key should be retained for a reasonable validation interval before being removed from the key server.</blockquote> <p>In the process of writing this up, I went through the 24 months of query logs I have. With very few exceptions (most of which were probably my own testing) there were no lookups against selectors other than on the day they were being used, so this doesn’t seem to be a problem in practice.</p> <p>I alluded to it earlier, but I want to be clear — publishing <abbr title="DomainKeys Identified Mail">DKIM</abbr> private keys like this mainly addresses leaks as a threat model. In a legal dispute, mail server logs and/or stored mail can be subpoenaed if the authenticity of messages is in question. Even in my case, where I have my own mail server on dedicated hardware with full disk encryption at an undisclosed location, most mail I send will be delivered to a server operated by a third party with no incentive to alter logs at the behest of the recipient.</p> <p>It would make for a fascinating experiment for one of the privacy focused email providers to try deploying a key management strategy similar to the one I’ve described in this post.</p> <table id="id4"> <colgroup><col><col></colgroup> <tbody> <tr><td><a href="#id1">[1]</a></td><td>I can’t find any recent public data on this, but Google reported that 87.6% of non-spam emails received by Gmail users had valid DKIM signatures as of Febuary 2016. <a href="https://security.googleblog.com/2013/12/internet-wide-efforts-to-fight-email.html">https://security.googleblog.com/2013/12/internet-wide-efforts-to-fight-email.html</a></td></tr> </tbody> </table> <table id="id5"> <colgroup><col><col></colgroup> <tbody> <tr><td><a href="#id2">[2]</a></td><td>The core protocol behind email, <span data-title="Simple Mail Transfer Protocol"><abbr title="Simple Mail Transfer Protocol">SMTP</abbr></span> was designed in the early eighties, and one of the terms it uses is “envelope sender”. This is apt because it originally was not much harder to fake than the return address on a physical envelope.</td></tr> </tbody> </table> <table id="id6"> <colgroup><col><col></colgroup> <tbody> <tr><td><a href="#id3">[3]</a></td><td>The DNS standards provide for storing values longer than 255 characters in a TXT record by simply storing multiple strings in the record, but such records can be annoying to work with in some software.</td></tr> </tbody> </table> </div></div>]]>
            </description>
            <link>https://rya.nc/dkim-privates.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24972609</guid>
            <pubDate>Mon, 02 Nov 2020 20:10:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Remember What You've Read?]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24972568">thread link</a>) | @victorbreder
<br/>
November 2, 2020 | https://breder.org/3/ | <a href="https://web.archive.org/web/*/https://breder.org/3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>



<p>2020-11-01</p>

<p>Of the books that you have read in full more than a year ago, how much of their content can you remember on top of your head right now? As discussed in the <a href="https://freakonomics.com/podcast/nsq-books-influence/">No Stupid Questions Podcast</a>, we are more likely to remember how a book made us feel, where we bought that book, or even some special circumstance related to it (such as being gifted), than <em>its actual main points</em>.</p>

<p>While remembering plot points is arguably not important for books read for entertainment (the quote "I envy the ones who have not read book X, because they get to experience it for the first time" comes to mind), I would argue that the whole point of reading non-fiction books is to become more knowledgeable. This requires us, at the very least, to retrieve the facts we've learned and, hopefully, being able to articulate them with other facts we know or come to know.</p>

<p>Upon reading the <a href="https://www.amazon.com/dp/B06WVYW33Y">How to Take Smart Notes</a> book by Sonke Ahrens, which outlines the <em>Zettelkasten</em> method of note-taking for academic and non-fiction writing, and the <a href="https://www.amazon.com/dp/B07K6MF8MD">Ultralearning</a> book by Scott Young, which lays out the author's principles for mastery of a given subject through intense effort and focus, I've come to believe that the most important thing to remember what we've read is <em>writing</em>.</p>

<p>As the research into deliberate practice by Anders Ericsson has shown, we're terrible judges for how well we are learning something. We usually equate ease with performing well, so activities that require less effort, such as passively rereading, <em>feel</em> more productive than activities that require more effort, such as testing yourself on what you've learned. Systematic testing afterwards show that the former kind of practice, the <em>effortful</em> practice, performs much better than the latter.</p>

<p>I would argue that while reading through a 200-page book may <em>feel</em> productive, the upside afterwards, for which we set retrieval as the lowest bar, may be small, or smaller than it can be if we adopt some complementary techniques. By simply passively reading, we may fall prey to the <em>illusion of fluency</em>, which means that, while the information is still fresh in our minds, we <em>feel</em> like we master it.</p>

<p>The antidote to the illusion of mastery is, of course, <em>testing</em> yourself. But we can't make this too hard (or we will likely end up not doing it at all or for long). The simplest form of testing is, after you read a chapter, to <em>retrieve</em> from memory the gist of it and the most important points <em>for you</em>, ultimately <em>writing those down in your own words</em>.</p>

<p>By retrieving from memory instead of looking up in the book we practice <em><a href="https://en.wikipedia.org/wiki/Active_recall">active recall</a></em>, which doubles as a self-testing method and a way to strengthen our ability to retrieve that information later. If we fail to recall the main points of a chapter after we've just read it, we likely weren't paying that much attention and we won't be able to recall anything at all in the future.</p>

<p>By focusing on the points that are personally important <em>to you</em>, we ensure that we are not simply becoming able to summarize everything about a book (like a encyclopedia that can be looked up), but we are compounding upon our existing knowledge in ways that interest us and that are more likely to be useful for us in the future.</p>

<p>Finally, and arguably the most important, by writing down in our own words, instead of highlighting or copying quotes, we ensure that we are actively engaged in the concepts we are reading and we test that we are able to articulate those concepts in a coherent manner. By doing this, it is very hard to fool ourselves about our level of competency in that subject (or at least harder than it would be by doing all of this in our own mind).</p>

<p>So what do you remember from this blog post? How this may be important to you by shaping your actions in the future? Don't skip writing it down. :)</p>

</div></div>]]>
            </description>
            <link>https://breder.org/3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24972568</guid>
            <pubDate>Mon, 02 Nov 2020 20:07:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Convert Your eBook into an Audiobook]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24972185">thread link</a>) | @audionerd126
<br/>
November 2, 2020 | https://www.avocadoaudio.com/post/how-to-convert-your-ebook-into-an-audiobook-on-your-own | <a href="https://web.archive.org/web/*/https://www.avocadoaudio.com/post/how-to-convert-your-ebook-into-an-audiobook-on-your-own">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><p>‍</p><p>‍</p><p>‍</p><p>‍</p><p>Have you just read our post, <a href="https://www.avocadoaudio.com/post/why-you-should-turn-an-ebook-into-an-audiobook"><strong>Why You Should Turn An Ebook Into An Audiobook</strong></a><strong>, </strong>and now you want to know HOW to do so? If so, this article will tell you what you need to record your audiobook and the steps need to compete to be successful in the process. <br></p><h2><strong>What do you need to be successful?</strong></h2><ol role="list"><li><strong>A good microphone.</strong> If you’re looking for suggestions, we have an article on <a href="https://www.avocadoaudio.com/post/the-6-best-budget-microphones-under-100">budget microphones under $100 </a>and one for <a href="https://www.avocadoaudio.com/post/budget-does-not-matter-6-best-microphones-over-100">microphones over $100</a>. Find one that works for you at a price you can afford. No need to break the bank here.</li><li><strong>A computer or tablet that you can record your audio on.</strong> Your phone potentially could work. This would be dependent on how much storage you have and the quality of the microphone it has; this would take out the need for purchasing a microphone. If you personally don’t have a computer or tablet, think about who you know that does. Would you be able to borrow theirs? Another suggestion is your local library or if you’re in college, universities typically have a tech rental program.&nbsp;</li><li><strong>An editing and recording program.</strong> This is up to you and what operating system you have. Check out our article, <a href="https://www.avocadoaudio.com/post/10-free-audio-editing-softwares-mac-and-pc">10 Free Audio Editing Platforms</a> if you need suggestions!</li><li><strong>A quiet space. </strong>You don’t want to have sirens or children screaming while you are recording. Also note that AC units will sneak up on you as well--you may not think about them initially when recording, but you will hear them when you begin editing.&nbsp;<br></li></ol><h2><strong>Convert your Ebook into an audiobook in 3 steps</strong></h2><ol role="list"><li><strong>Record the audio. </strong>This may be the most time-consuming aspect of the entire process because you can’t speed through the reading. No one will be able to understand you if you talk a million miles a minute. Slow down and talk at a normal pace, unless the section of the book has you running for your life from a pack of wolves. You will also make mistakes as you go along. This is one hundred percent normal and okay. Take a few breaths and re-do the section. If you choose not to be the narrator, you can find alternatives listed below.</li><li><strong>Edit the audio. </strong>Get rid of the extra “ahs”, “ums”, and other unnecessary pauses you may have inserted as you read. Also, pay attention to the background noise and make sure the audio does not sound grainy with static constantly going off in the background.&nbsp;</li><li><strong>Choose a platform to sell your audiobook with.</strong> Our article <a href="https://www.avocadoaudio.com/post/the-best-5-ways-to-sell-your-audiobook">The Best 5 Ways To Sell Your Audiobook</a> will describe in more detail what platforms exist and the pros and cons of each. Pay close attention to what you want to gain from publishing your audiobook. Is it an additional source of income that you want to gain the most profit from? Or is just something extra to put out there--you are indifferent towards how much money it makes?&nbsp;<br></li></ol><h2><strong>How long will it take to narrate my Ebook?</strong></h2><p>According to <a href="https://audible-acx.custhelp.com/app/answers/detail/a_id/6646/~/how-long-does-it-usually-take-someone-to-produce-1-finished-hour-of-an">ACX</a>, it will take about two hours to narrate one hour of finished audio. For this stat, it’s important to note that ACX assumes the average rate of words narrated in an hour is 9,300 or 155 words per minute. Taking this into consideration, a 60,000-word novel would take 6.5 hours to complete at the rate previously mentioned. Books that are under 10,000 words (less than 40 pages) read at the same 9,300 words per hour, would take 1.1 hours to narrate.&nbsp;<br></p><h2><strong>How long will it take to edit my audiobook?</strong></h2><p>This will depend on a few factors. First, are you new to editing audio? If so, it may take a little bit to adjust to how to edit. Second, which platform are you using? Some platforms are more user-friendly than others. Play around with a few before deciding which one is best for you. Lastly, do you take 5-second pauses or have another method in place to denote in your waveforms when you’ve messed up and then restarted? If not, think about adding this in to make your life easier when editing. <a href="https://audible-acx.custhelp.com/app/answers/detail/a_id/6646/~/how-long-does-it-usually-take-someone-to-produce-1-finished-hour-of-an">ACX </a>found that in order to produce one hour of finished audio content, it will take the average editor three hours. Keep this in mind.&nbsp;<br></p><h2><strong>What format does my audio need to be in?</strong></h2><p>The most common audio formats are WAV, MP3, and M4B files. Some programs may vary in if they prefer one over the other, but generally speaking, these are acceptable formats. Quick tip, if using a program such as Audacity to edit and record, you will need to ‘export’ your audio to one of these formats. Audacity keeps files saved as .aup, which is not a format these programs can read.&nbsp;<br></p><h2><strong>How much will it cost me in total to produce my audiobook?</strong></h2><p>If you’re choosing to narrate and edit your course on your own, the total will come down to a whopping zero. This is assuming you already have a decent microphone, working computer (or access to one), and a quiet space to record. Other than these things, you don’t need much else in order to be successful in this process.&nbsp;<br></p><h2><strong>11 tips for recording the perfect audiobook</strong></h2><ul role="list"><li>Sit still<strong>. </strong>The microphone will capture the extra noise of you moving around or fidgeting with your pen.</li><li>Keep the microphone in one place and watch your positioning as you record.<strong> </strong>You don’t want to move further or closer throughout the recording to affect the audio sound volume.</li><li>Read from an electronic device so you don’t have to move papers.</li><li>Practice any tongue twister statements or words ahead of time that may cause you to stumble when recording.</li><li>Record for no more than 2.5-3 hours at a time. After this, most narrators will get tired and start to lose their voices. You will save yourself the headache of having to edit or re-do sections.&nbsp;</li><li>Read at a normal pace. Think about it as if you were having a conversation with someone.</li><li>Stand up while you’re recording. It will help you breathe better and causes you to be more energetic.</li><li>Have water, tea, or other clear liquids available to stay hydrated. Try and avoid carbonated beverages or those that may causes issues.</li><li>Start with a 10-second silence at the beginning of your recording. Helpful for filling in gaps later on or hearing the background noise that gets picked up by the microphone.</li><li>Use a system to mark your mistakes. For example, this could be a 5-second pause that allows you to easily edit the audio by denoting where you messed up and can easily snip it out.&nbsp;</li><li>Enunciate. Be sure the listener can understand what you’re saying.</li></ul></div></div><div><div><h5>Continue Reading</h5><div><div role="list"><div role="listitem"><a href="https://www.avocadoaudio.com/post/avocado-vs-audible-acx"><p><img src="https://uploads-ssl.webflow.com/5eb1831614ef9185bd452478/5fa2f3ed2c66e340bbbaddae_andre-hunter-EHLbBpuZWVQ-unsplash.jpg" alt=""></p></a></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.avocadoaudio.com/post/how-to-convert-your-ebook-into-an-audiobook-on-your-own</link>
            <guid isPermaLink="false">hacker-news-small-sites-24972185</guid>
            <pubDate>Mon, 02 Nov 2020 19:39:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenZFS – Understanding Transparent Compression]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24971396">thread link</a>) | @vermaden
<br/>
November 2, 2020 | https://klarasystems.com/articles/openzfs1-understanding-transparent-compression/ | <a href="https://web.archive.org/web/*/https://klarasystems.com/articles/openzfs1-understanding-transparent-compression/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>




<div>
<h3><em>This is part of our article series published as “OpenZFS in Depth”. <a href="https://klarasystems.com/articles/"><strong><span>Subscribe to our article series</span></strong> </a>to find out more about the secrets of OpenZFS</em></h3>



<hr>



<p>Transparent (inline) configurable compression is one of OpenZFS’ many compelling features—but it is also one of the more frequently misunderstood features. Although ZFS itself currently defaults to leaving compression off, we believe you should almost always use LZ4 compression on your datasets and zvols. There is such wide acceptance of this idea, that the default compression setting is likely to change in a future release of OpenZFS.</p>



<p>Compression is a per dataset/zvol property, not a pool level feature. This means that you can configure compression differently for groups of data in the same pool. For example, you might use “<em><strong>zfs set compression=lz4 tank</strong></em>” to set an inheritable default for the pool, but then “<em><strong>zfs set compression=gzip tank/textfiles</strong></em>” to get better compression ratios in a particular dataset which only contains highly compressible data.</p>



<p>ZFS has no problem dealing with a mix of uncompressed, LZ4 compressed, and gzip compressed records sitting side by side in the same dataset. ZFS does not need to immediately rewrite existing data if the setting changes.</p>



<p>After changing the “<em><strong>compression</strong></em>” value of a <strong>dataset</strong> or <strong>zvol</strong>, you may either let things continue as they are—in which case old data is stored under the old compression scheme, but new data is written using the new one—or you may recopy the existing data, then delete the original copies.</p>



<p><strong>So, operating ZFS compression is simple—but before we move on, we should talk a little bit about how it actually works. </strong></p>



<p>To do that, we’ll need to dive into some low-level basics about ZFS read and write operations. </p>



<h4><strong>Explaining <em>ashift</em> and <em>recordsize</em> / <em>volblocksize</em></strong></h4>



<p>The two most important configurables for ZFS storage parameters are <strong><em>“ashift”</em></strong> – a per-vdev option which should be set to correspond with the actual hardware blocksize of the underlying devices – and “<strong><em>recordsize</em></strong>” (or “<strong><em>volblocksize</em></strong>“, if we’re talking about ZVOLs).</p>



<p><strong><em>recordsize</em></strong> is a bit more difficult to explain than <strong><em>ashift</em></strong>. The smallest individually-operable block of data on a ZFS dataset is one record. This means that when you change a single byte of data within one record, ZFS makes a new copy of the entire record with your one byte change, and writes that newly modified record to disk.</p>



<p>With the newly modified record written to disk, ZFS unlinks the old record from the current version of the filesystem and replaces it with a link to the newly-written, modified record. ZVOLs work essentially the same way, only with volblocks—whose size is controlled by the <strong><em>“volblocksize</em></strong>” property—instead.</p>



<p>One final piece to the puzzle – ZFS can write undersized records if necessary. If you save a 1KiB text file in a dataset with “<strong><em>recordsize=1M</em></strong>” set, it does not consume the entire 1MiB maximum record size—your file is saved in an undersized, single-block record. With “<strong><em>ashift=12</em></strong>” – corresponding to a hardware block size of 2<sup>12</sup>, or 4K—that means your 1KiB file takes up 4KiB on disk, not 1MiB!</p>



<h4><strong>How OpenZFS Compression Works</strong></h4>



<p>Now that we understand the difference between “<strong><em>ashift</em></strong>” and “<strong><em>recordsize</em></strong>” (or “<strong><em>volblocksize</em></strong>“), we can more easily discuss how compression works. Let’s say you’ve got a dataset with OpenZFS’ current default of “<strong><em>recordsize=128K</em></strong>“, sitting atop a pool constructed of vdevs with “<strong><em>ashift=12</em></strong>“.</p>



<p>Our hardware blocksize is 4KiB, and our desired maximum record size is 128KiB – so a typical record, uncompressed, will be stored in thirty-two 4KiB blocks. What if we’ve got “<strong><em>compression=lz4</em></strong>” set, and the LZ4 algorithm can achieve a raw 1.32 compression ratio, compressing that 128KiB of data down to 97KiB?</p>



<p>You need twenty-five total 4KiB blocks to store 97KiB of data – so while we’re still looking at a single 128KiB record, that record now occupies twenty-five blocks on disk, not thirty-two—an on-disk “<strong><em>compressratio</em></strong>” of 1.28.</p>



<p>Assuming we’ve correctly set “<strong><em>ashift</em></strong>” to match our underlying hardware’s specifications, that means we can fetch that record about 22% more efficiently than we could have otherwise. That extra 22% we saved on this record means lower latency reading or writing it, and provides better overall throughput if it’s one of an entire stream of blocks we’re reading or writing at once.</p>



<h4><strong>Higher <em>recordsize</em> Means Better Compression Ratios</strong></h4>



<p>The larger your records or volblocks are, the better compression ratios you’ll get. The first reason is that the compression dictionary is per-record, so larger records can compress more efficiently.</p>



<p>The relationship between <em><strong>ashift</strong></em> and <strong><em>recordsize</em></strong> is even more important than the raw “<strong><em>recordsize</em></strong>” itself. Remember, we store each “<strong><em>record</em></strong>” in blocks determined by “<strong><em>ashift</em></strong>” – and if you can’t decrease the number of blocks required to store the record, you won’t get any compression on that record.</p>



<p>To demonstrate this, let’s examine a dataset with “<strong><em>recordsize=16K</em></strong>” sitting on a pool with vdevs set to “<strong><em>ashift=13</em></strong>“, or 8K hardware block size. If LZ4 gives us the same 1.32 raw compression ratio that we had in the last example on each record, we get no compression at all! Wait, what?</p>



<p>16KiB of data, compressed down to 78.1% of its original size, becomes 12.5KiB of data. Unfortunately, 12.5KiB of data still requires two 8KiB hardware blocks on-disk—which would result in an on-disk “<strong><em>compressratio</em></strong>” of 1.00x—meaning completely uncompressed. So, ZFS won’t actually store this record compressed at all, since there would be no savings.</p>



<p>It is still possible to achieve usable on-disk compression with “<strong><em>recordsize=16K</em></strong>” and “<strong><em>ashift=13</em></strong>“, of course—but only for individual records which can achieve raw compression ratios of 2.00 or better.</p>



<h4><strong>Compression ratios on small <em>recordsize</em> datasets</strong></h4>



<p>Consider a MySQL database, which we want to store on a pool with vdevs set “<strong><em>ashift=13</em></strong>“. Many commonly-used high-performance SSDs perform best with this high “<strong><em>ashift</em></strong>” value—and MySQL itself defaults to a tablespace page size of 16KiB.</p>



<p>This leaves us where we were in the previous section—hardware block size 8KiB, and recordsize of 16KiB. But in this scenario, we often see an on-disk “<strong><em>compressratio</em></strong>” higher than 1.00x, but (much) lower than 2.00x.</p>



<p>Although the MySQL database’s data may only be compressible to 1.32x when considered as a whole, individual 16KiB chunks of it may very well achieve 2.00x or better raw compression. Any individual record which compresses at 2.00x or better can be stored in a single 8KiB block.</p>



<p>So, if we have a 1GiB MySQL database in a dataset that reports 1.1x “<strong><em>compressratio</em></strong>“, that means that around 5,000 of the 65,536 ZFS records in the database compressed to 2.00 or better, and thus could be stored in single 8KiB hardware blocks.</p>



<p>On the other hand, what if we had <strong>“<em>recordsize=8K</em></strong>” and “<strong><em>ashift=13</em></strong>“? In this case, no on-disk compression is possible – because an uncompressed record already only requires a single block, and therefore can’t be stored in <em>fewer</em> blocks, no matter how high its “<strong><em>compressratio</em></strong>“.</p>



<h4><strong>ZFS Compression, Incompressible Data and Performance</strong></h4>



<p>You may be tempted to set “<strong><em>compression=off</em></strong>” on datasets which primarily have incompressible data on them, such as folders full of video or audio files. We generally recommend against this – for one thing, ZFS is smart enough not to keep trying to compress incompressible data, and to never store data compressed, if doing so wouldn’t save any on-disk blocks.</p>



<p>You might still not be convinced – so far, all we’re talking about is mitigating a performance decrease. Isn’t it better to avoid the decrease in the first place? Probably not. The performance “penalty” for working with incompressible data is minuscule, and the potential gains in working with compressible data are much larger.</p>



<pre><code>root@lab:/data/test# pv &lt; in.rnd &gt; lz4-compressed/out.rnd
7.81GB 0:00:22 [ 359MB/s] [==================================&gt;] 100%

root@lab:/data# zfs get compressratio data/test/lz4-compressed
NAME                 PROPERTY       VALUE  SOURCE
data/lz4-compressed  compressratio  1.00x  -
</code></pre>



<p>In the above example, we take previously-generated incompressible data stored on one high-performance SSD, and write it to another high-performance SSD, with “<strong><em>compression=lz4</em></strong>” and the default “<strong><em>recordsize=128K</em></strong>“. The source data is in the system cache, so the write speed is the only bottleneck here.</p>



<p>The data streams at 359MiB/s—but would it go any faster, if written to a dataset with “<strong><em>compression=off</em></strong>“?</p>



<pre><code>root@lab:/data# pv &lt; in.rnd &gt; uncompressed/out.rnd
7.81GB 0:00:21 [ 378MB/s] [==================================&gt;] 100% 
</code></pre>



<p>This time, we got 378MiB/sec. So while we did see a performance penalty—(378-359)/378=5.0%—it’s certainly not an enormous one. Now, what kind of benefits can we see in real-world scenarios, with a mix of compressible and incompressible data?</p>



<pre><code>root@lab:/data/test# pv &lt; win2012r2-gold.raw &gt; lz4/win2012r2-gold.raw
8.87GB 0:00:17 [ 515MB/s] [==================================&gt;] 100%

root@lab:/data# zfs get compressratio data/test/lz4-compressed
NAME                      PROPERTY       VALUE  SOURCE
data/test/lz4-compressed  compressratio  1.48x  -
</code></pre>



<p>In the above example, we’re saving a Windows Server 2012 R2 gold image to an LZ4 compressed dataset. The gold image is a fully-installed Windows Server 2012 R2 VM, with drivers and a few client-specific applications installed, which has then been `<strong><em>sysprep</em></strong>`ed for deployment to new virtual machines.</p>



<p>This is obviously not a “perfect” candidate for compression, like a directory full of text files. But it still achieved a 1.48x compression ratio—and a whopping (515-378)/378=36% performance improvement.</p>



<h4><strong>Conclusions</strong></h4>



<p>The potential performance benefits of compression are significant, and the worst-case penalties are quite small. There are almost always better places to focus a sysadmin or storage architect’s attention than picking and choosing which datasets to disable compression on, so we …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://klarasystems.com/articles/openzfs1-understanding-transparent-compression/">https://klarasystems.com/articles/openzfs1-understanding-transparent-compression/</a></em></p>]]>
            </description>
            <link>https://klarasystems.com/articles/openzfs1-understanding-transparent-compression/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24971396</guid>
            <pubDate>Mon, 02 Nov 2020 18:33:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Thoughts on Monorepo]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24971288">thread link</a>) | @shekhargulati
<br/>
November 2, 2020 | https://shekhargulati.com/2020/11/02/my-thoughts-on-monorepo/ | <a href="https://web.archive.org/web/*/https://shekhargulati.com/2020/11/02/my-thoughts-on-monorepo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-6395">
	<!-- .entry-header -->

	
	
	<div>
		
<p>Before we start let me give some context on my background so that you can better understand my thoughts on Monorepo.&nbsp;</p>



<p>I head technology at an IT services organization. Most of the products that I build are using Microservices architecture, have multiple frontends(web and mobile). The biggest product that I recently built had close to 30 microservices, 1 web client written in React,&nbsp; and native mobile app built using React Native. These numbers are nowhere near the numbers big product companies have shared.&nbsp;</p>



<blockquote><p>I prefer Macroservices over Microservices. I think most products don’t need more than 10 microservices.&nbsp;</p></blockquote>



<p>The reason I am clearly specifying I belong to the IT services world is because most of the stuff we consume on software development is written by engineers and senior tech people at the product companies. The stuff they write and share is based on the real problems and challenges they face at work. There are times when those problems resonate with problems other software engineers face at their work but there are times they are solutions to the problems we don’t have. So, we have to look at these solutions from the lens of our problems.</p>



<blockquote><p>The post is based on my experience building software, leading and managing software delivery teams, and learning from the great articles written by engineers using Monorepos. Please refer to the references section for good resources on monorepos.</p></blockquote>



<p>Let’s get back to the topic at hand.</p>



<h2>So, what is a Monorepo?</h2>



<p>A monorepo is a software development strategy where a single version control repository has source code for multiple projects, libraries, and applications irrespective of their programming language. Also, the organizations using Monorepo strategy often use a common build tool (like Bazel, Pants, Buck) to manage all the source code. Some of the popular examples of organizations that employ monorepo strategy are Google, Facebook, Twitter, Microsoft, and Uber.&nbsp;</p>



<p>The alternative to monorepo is polyrepo/multirepo. In multirepo, you have a separate version control repository for each component. This is the common strategy used by most organizations to structure their code. This in my view has been largely driven by Microservices architecture style and small modules movement.</p>



<p>As mentioned in the paper[1] (Advantages and Disadvantages of a Monolithic Repository – A case study at Google), Monorepos have following properties:</p>



<ul><li><strong>Centralization</strong>: The codebase is contained in a single repo encompassing multiple projects.</li><li><strong>Visibility</strong>: Code is viewable and searchable by all engineers in the organization.</li><li><strong>Synchronization</strong>: The development process is trunk-based; engineers commit to the head of the repo.</li><li><strong>Completeness</strong>: Any project in the repo can be built only from dependencies also checked into the repo. Dependencies are unversioned; projects must use whatever version of their dependency is at the repo head.</li><li><strong>Standardization</strong>: A shared set of tooling governs how engineers interact with the code, including building, testing, browsing, and reviewing code.</li></ul>



<p>My understanding is that to successfully use monorepo you will have to satisfy all the properties. Otherwise, you will not get benefits intended from monorepo.&nbsp;</p>



<h2>Advantages of Monorepos</h2>



<p>There are valid reasons why many big product organizations prefer Monorepo. Following are the main reasons:</p>



<h3>Reason 1: Simplified dependency management</h3>



<p>Monorepos make dependency management simple by:</p>



<ol><li>You can easily depend on other projects/modules in a monorepo without the need for artifact management tools like Nexus, Artifactory etc.</li><li>You avoid diamond dependency problem. Diamond dependences occur when a project has two dependencies which depend on the same underlying library. When a developer upgrades a dependency, they run the risk of breaking a diamond in the dependency graph.</li><li>It is easier to keep all dependencies on the same version by using a centralized way to manage version numbers.</li></ol>



<p>This is simplified further by using a single build tool. I have not used Bazel, Bucks, or Pants. I was watching a talk on Twitter monorepo journey where they talked about Gradle being too slow for their use case. For the size of applications I have built Gradle has worked just fine.</p>



<h3>Reason 2: Code sharing and reusability</h3>



<p>The second big benefit of Monorepo is that developers can share code across projects. It is easier to enforce best practices across the code base by using monorepo. Another related point is that with monorepo we don’t end up creating silos. This is important in an enterprise setup because it leads to passing the buck and bugs falling through the cracks of the boundaries. In my experience with multirepo setup people only care about their Microservice running fine. They miss the point that value is achieved by integrating the software and collaboration. In IT service organizations where there is more bureaucracy and uneven distribution of skilled developers the problem scales very quickly with multirepo setup. Yes, I know it is a culture problem but most IT service organizations can’t burn investor dollars to build the culture.</p>



<h3>Reason 3: Atomic changes</h3>



<p>This I didn’t realize before I read literature on Monorepo. There is a lot of benefit in seeing related changes in a single commit. If you are working on a story that requires changes in multiple components then in a multirepo scenario you will have to see changes in multiple repositories and merge the PRs in some sequence so that you are in a healthy state. WIth monorepo you save the pain of trying to coordinate commits across multiple repositories. Also, this leads to better code reviews as all the changes are in one place.</p>



<h3>Reason 4: Large-scale code refactoring</h3>



<p>This is related to reason 3. With a monorepo, you can refactor the API and all of its callers in one commit. You see all the usages of an API at a single place and it is much easier to do than with multirepo where you might not even have all the code checked out. In my experience with multirepo setup most developers don’t keep all the repos updated with the upstream changes. Monorepos enables continuous improvement on global level that multirepo you do at local level.</p>



<h3>Reason 5: Less bureaucracy</h3>



<p>With some organizations I have worked at, you have to create ServiceNow tickets to create a repository. It can take a couple of days before you get your empty repository. With monorepo you don’t have to go through this pain.&nbsp;</p>



<h2>Disadvantages of Monorepo</h2>



<p>Nothing comes for free. There are always trade offs involved. Your job as a software engineer is to figure out if advantages weigh more than trade offs or not.&nbsp;</p>



<p>In my view following are the downsides of monorepo:</p>



<ol><li>Monorepos could slow down developers because of slow build times, poor tooling, and merge conflicts.&nbsp;<ol><li>Most developers still in 2020 struggle to cleanly merge code.&nbsp;</li><li>Git is slow for projects with large numbers of files and history.</li></ol></li><li>There is cognitive overhead involved as developers have to get comfortable with a much larger code base than they would have with multirepo setup.</li><li>To do monorepo well require investment in tooling that most organization non-tech leadership will fail to understand</li></ol>



<h2>So, what’s my view on monorepos?</h2>



<p>Before I talk about my views on Monorepo let’s understand three main constraints of IT services organization.&nbsp;</p>



<ol><li>We work with multiple customers so we can’t keep code of all customers in the same repository even when we host their code in our version control for obvious reasons. Also, we can’t give access to all our repositories to all our developers because of security and IP related issues. So, we will keep our discussion focused on how to manage repos for a single customer.</li><li>IT services organizations have a high ratio of junior(&lt; 5 years) to senior engineers(&gt; 10 years) somewhere in the range of 10:1 to 100:1 or may be higher in bigger IT service organizations. The reason I am bringing this point is that monorepos requires discipline and it is tough to achieve without senior engineers driving it using a well-defined process.</li><li>People come and go at a faster rate.</li></ol>



<p>Given the above two constraints and the disadvantages of monorepos it might seem that monorepos will not work for us. But, I see real problems faced by software delivery teams that can be solved by monorepos.</p>



<p>We build products for different customers. These products usually follow Microservice architecture, have multiple frontends – web and mobile, functional tests, scripts for deployment automation. In the multirepo strategy, you will create at minimum 5 repositories – 1 for backend with all microservices, 1 for SPA frontend, 1 or 2 repo for mobile depending on whether you are building pure native or using some native framework like React Native or Flutter, 1 for functional tests, 1 for deployment automation scripts.&nbsp; More often than not your team will use one repo per Microservice then only god knows how many repos you end up creating.</p>



<blockquote><p>Let me tell you a real story. I was once working with a client that had more than 1000 repositories in their version control system. They were using the Gitlab version control platform. They had 5 products and each product was made up of multiple Microservices. The first question I asked them was to help us understand which all services and their respective code repositories were part of product A. Their chief architect had to spent a day figuring out all the repositories that made the product A. After spend a day still she was not sure if she has covered all the services.</p></blockquote>



<p>Let’s discuss problems that I face with software delivery teams using the multirepo strategy. Just to reiterate these problems are in the context of a single customer.</p>



<ol><li>Lack of accountability: Humans are good at creating boundaries and silos. They don’t care what happens outside those boundaries. They don’t care about the bigger picture.</li><li>Version drift. 10 different versions of Spring Boot, three different JDK versions, …</li></ol></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shekhargulati.com/2020/11/02/my-thoughts-on-monorepo/">https://shekhargulati.com/2020/11/02/my-thoughts-on-monorepo/</a></em></p>]]>
            </description>
            <link>https://shekhargulati.com/2020/11/02/my-thoughts-on-monorepo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24971288</guid>
            <pubDate>Mon, 02 Nov 2020 18:24:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[California tries to fix its enormous unemployment backlog with automation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24970759">thread link</a>) | @rhinoh
<br/>
November 2, 2020 | https://www.route-fifty.com/tech-data/2020/10/californias-unemployment-1-million-backlog-automation/169693/ | <a href="https://web.archive.org/web/*/https://www.route-fifty.com/tech-data/2020/10/californias-unemployment-1-million-backlog-automation/169693/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

    <div>

      <div>
        

        
          
        

        
  
    <div>
      


<div>
  
  <p>Connecting state and local government leaders</p>
</div>

    </div>
  


        
          

          
        

      </div>

      
      <div>

        <div>
          
          <p>
            
              
                
                  



  By


<span><span>
        Jacob Fischler
      </span></span>

                
              
            
          </p>

          
            <p><span>|</span>
          

          
            <time datetime="2020-10-30T18:31:00+00:00">
             October 30, 2020
            </time>
          
        </p></div>

        
          <h2>State unemployment agencies have started automating identity verification in the hopes of more quickly processing record numbers of new applications. But experts say more fixes to flawed systems are also necessary. </h2>
        

        
  <ul>
    
      <li>
        <a href="https://www.route-fifty.com/topic/california/?oref=rf-article-topics">
          <span>
            <span>
              <span>
                California
              </span>
            </span>
          </span>
        </a>
      </li>
    
      <li>
        <a href="https://www.route-fifty.com/topic/unemployment/?oref=rf-article-topics">
          <span>
            <span>
              <span>
                Unemployment
              </span>
            </span>
          </span>
        </a>
      </li>
    
      <li>
        <a href="https://www.route-fifty.com/topic/state-government/?oref=rf-article-topics">
          <span>
            <span>
              <span>
                State Government
              </span>
            </span>
          </span>
        </a>
      </li>
    
  </ul>


        





        

      </div>
      

    </div>
  </div><div>
<div>

<div>
<p>From May to June, the unemployment applications of 1.3 million out-of-work people in California were set aside for state workers to review, an arduous process that delayed benefits for weeks or even longer.&nbsp;</p><p>Now, California is among a growing number of states using software to automate more of the unemployment insurance application process, with the goal of more quickly getting payments to the people who need them.&nbsp;</p><p>The automated identity verification tool is just one step the state has taken in recent weeks to try and get the problem under control.</p><p>A “strike team” appointed by Gov. Gavin Newsom last month released <a href="https://www.govops.ca.gov/wp-content/uploads/sites/11/2020/09/Assessment.pdf" target="_blank">a 103-page report</a> with recommendations for the Employment Development Department. Most drastically, the agency followed advice to shut down new applications for two weeks in September, allowing employees&nbsp; to catch up on the growing backlog of cases that had been waiting for at least 21 days for resolution.&nbsp;</p><p>But even with that reset, EDD has a long way to go. Agency staff reported that during the two-week break they were able to go through 246,000 cases out of a backlog that climbed to 1.6 million by early fall, although <a href="https://edd.ca.gov/About_EDD/pdf/news-20-58.pdf" target="_blank">a recent report</a> shows they continue to make progress. The agency earlier this month told frustrated state lawmakers that it will need until January to fully clear out the rest.</p><p>California isn’t alone in dealing with <a href="https://www.route-fifty.com/management/2020/07/unemployment-states-problems-coronavirus-delays-benefits/166817/">massive unemployment system problems</a> that have resulted in people eligible for benefits just not getting them. As nationwide unemployment hit a high of nearly 15% in April and Congress created a new program to allow self-employed workers to receive assistance, agencies struggled to process applications and get checks to desperate families.&nbsp;</p><p>In March, as the pandemic was just starting to affect unemployment numbers, nearly 95% of unemployment applicants nationwide received payments within two weeks of applying—the U.S. Labor Department’s benchmark for timeliness for states like California that require a waiting week before applications receive benefits—but by June, the rate was less than 45%. In September, the nationwide average was 53%.&nbsp;</p><p>In California, the strike team report, written by Yolanda Richardson, the state’s government operations secretary, and Jennifer Pahlka, a former U.S. Deputy Chief Technology Officer under President Obama, found that manual reviews to confirm applicants’ identities created a bottleneck that slowed payments, without meaningfully preventing fraud. While about 60% of claims are approved automatically, the remaining claims that require manual reviews are the largest factor slowing payments well beyond federal standards for timeliness.</p><p>Of the applications that require manual review, 78% were due to a problem identifying the claimant’s identity, according to the report. Part of the issue in California and other states was just the volume of claims as the pandemic and associated shutdowns started to ripple through the economy. Nationally, initial claims for unemployment benefits rocketed from about 225,000 per week in March 2019 to 6.9 million in one week in March 2020.&nbsp;</p><p>“What states need is automation to deal with their backlogs,” said Waldo Jaquith, who leads the unemployment insurance team at U.S. Digital Response, a group that provides free technology assistance to governments across the country. “States have received more applications than they possibly have the staff to deal with. They can’t even staff up to the appropriate levels.”</p><p>The California EDD contracted the vendor ID.me to automate its system this month. When applicants file for benefits, the system will allow them to upload identification documents, as well as a photo they take through the system. The idea is to both make for a quicker process and curtail fraud, the<a href="https://edd.ca.gov/About_EDD/pdf/news-20-49.pdf" target="_blank"> agency has said</a>.&nbsp;</p><p>After the company’s first day operating in the state on Oct. 6, the agency processed 64% of applications automatically. The September report found the previous average to be about 60% and said a vendor could help that number reach 91%.&nbsp;</p><p>At a California Assembly hearing on Oct. 7, Democratic Assemblymember David Chiu said he remained concerned there is still a long way to go. But by Thursday, EDD reported that automatic verification was now processing 85% of claims.</p><p>ID.me did not return a message seeking comment. On its website, the company advertises recent work for Arizona, Georgia, Nevada and Pennsylvania in addition to California. Jaquith said ID.me is one of two or three companies providing a similar service.&nbsp;</p><p><strong>Fraud Failures</strong></p><p>Automation is not a panacea for all unemployment insurance problems.</p><p>Jennifer Kwart, a spokeswoman for Chiu, said in an interview that although Chiu has confidence in the authors of the report, the California EDD still needs to improve its outreach and accessibility. Non-native English speakers, disabled users and people who use only mobile devices for internet access have difficulty signing up for benefits, she said.&nbsp;&nbsp;</p><p>The strike team report also identified a significant EDD staffing problem. While the state went on a hiring binge, these new employees lack the training and expertise to tackle the stacked-up cases. On top of this, the team found that experienced staffers were being tasked with training the new employees, which meant the agency had actually become less productive.&nbsp;</p><p>Going forward, EDD has pledged to redirect experienced staff from training duties or answering phones, saying they would instead be focused on resolving past cases.&nbsp;</p><p>California’s automation efforts with ID.me also won’t itself be enough to stop the kind of systemic fraud that has plagued unemployment systems across the country during the pandemic, the report says.&nbsp;</p><p>In just one example, Arizona <a href="https://www.azcentral.com/story/money/business/consumers/2020/10/12/unemployment-fraud-arizona-freezes-43-000-accounts-second-action/5954064002/" target="_blank">has estimated</a> it paid out $500 million in fraudulent claims. Federal authorities also believe a criminal ring based out of Nigeria used stolen Social Security numbers and other pieces of information to submit fraudulent claims across the country. Washington state alone believes it made $576 million in payments to these scammers and have so far recovered $346 million, the <a href="https://www.nytimes.com/2020/10/01/business/economy/unemployment-benefits-fraud.html" target="_blank"><em>New York Times</em> reported.</a>&nbsp;</p><p>While automated systems seem to be at least as good as employees at catching such fraud, states are viewing them as tools to get through their backlogs. Improving fraud protection hasn’t “even been part of the calculus,” Jaquith said.&nbsp;</p><p>Along with creating headaches for agency staff, fraud is a major problem for the people who depend on unemployment insurance and other state benefits, said Jessica Bartholow, a policy advocate at the Sacramento-based legal advocacy group Western Center on Law and Poverty.</p><p>When fraudsters gain access to a claimant’s identity to secure unemployment payments, it robs the person who is entitled to that aid and can even cut off other benefits like food stamps, Bartholow said. It’s also more likely to hurt disabled people, homeless people and others who are in the greatest need.</p><p>In California, EDD this month <a href="https://www.latimes.com/california/story/2020-10-22/california-debit-cards-frozen-unemployment-benefits-fraud" target="_blank">froze 350,000 debit cards</a> containing benefits because of fraud concerns, including multiple applications at one address. For people with legitimate benefits caught up in the freeze, they will have to work out the problem with the bank or EDD, the <a href="https://edd.ca.gov/About_EDD/pdf/news-20-52.pdf" target="_blank">state agency said</a>.&nbsp;</p><p>“I would qualify that as a serious problem,” Bartholow said. “This is not pretend. This is real fraud.”</p><p>But existing systems just don’t have much of a response to these types of schemes. State unemployment systems generally have strong methods of catching individuals who lie about their own situation to boost their benefits, but are less prepared to stop the wide scale fraud efforts that are much more costly to states.&nbsp;</p><p>“The ‘gotcha’ approach to a lot of state UI systems is optimized to the mythical welfare queen and not to who is actually doing the stealing, which is organized crime rings stealing vast amounts of money,” Jaquith said.<svg>
<use xlink:href="/static/b/base/svg/spritesheet.svg#icon-rf-shield-alt"></use>
</svg></p></div></div>
</div></div>]]>
            </description>
            <link>https://www.route-fifty.com/tech-data/2020/10/californias-unemployment-1-million-backlog-automation/169693/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24970759</guid>
            <pubDate>Mon, 02 Nov 2020 17:41:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Submer MicroPod: Edge immersion cooled datacenter-in-a-box]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24970554">thread link</a>) | @polvs
<br/>
November 2, 2020 | https://submer.com/micropod | <a href="https://web.archive.org/web/*/https://submer.com/micropod">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"> <!-- End Google Tag Manager (noscript) -->   <!--[if IE]><div class="alert alert-warning"> You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div> <![endif]--> <a href="#content">Skip to content</a><!-- #masthead -->   <section id="id87759"><div><figure> <img uk-img="" data-src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-video-pre-1024x576.jpg" alt="" src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-video-pre-1024x576.jpg"> </figure><div><h2>Computing and Cooling <span>Where you Need them!</span></h2><p>Our <b>Edge-ready, plug-and-play, datacenter-in-a-box</b> solution delivers unprecedented <b>high density</b> and <b>efficient infrastructure</b> anywhere. Be it a warehouse, office building, in the heart of a city or in a remote area with harsh-climate conditions and far from the grid, the <b>MicroPod</b> will be fit for the job.</p></div></div></section><section id="blockfreecontent-48846"></section><section uk-img="" data-src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/07/5e2ecfd712d9359dcffb9443_thxpage-bg.jpg"><div><h2> The <span>benefits</span> of the MicroPod</h2><div uk-grid=""><ul><li uk-parallax="x:-60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="In a traditional datacenter, cooling is responsible for about 40% of the electricity consumption. With the MicroPod, Submer allows you to achieve a low energy footprint in any outdoor-only or outdoor-indoor configuration."><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/05/ic_pue.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Low energy footprint</p></div></li><li uk-parallax="x:-60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="Submer allows you to save 25%-40% on your TCO, that translates into substantial savings on CAPEX (Design, Real Estate, Construction, IT hardware, Cables, Cooling, Piping, etc.) and OPEX (Electricity &amp; Maintenance)."><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/05/ic_tco.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Save 25-40% on TCO</p></div></li><li uk-parallax="x:-60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="Thanks to their design and the use of a proprietary dielectric coolant specifically designed for single phase Immersion Cooling, Submer’s solutions guarantee unrivalled density. Deploying our MicroPod technology allows you to dissipate up to 6kW in an unprecedented compact space and with flexible IT gear (19-inch, 21-inch OCP, OpenEdge with depths up to 800 mm).
"><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/05/ic_density.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>6 kW of compute density in a compact space</p></div></li><li uk-parallax="x:-60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="Thanks to its modular design, Submer’s MicroPod can be deployed anywhere: in an already existing datacenter, at the Edge, in a warehouse, in an office or even outdoors. The all-in-one technology by Submer brings unprecedented IT density, high efficiency and low latency right were you need it. 
"><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/05/ic_speed.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Reduce latency and increase speed deployment</p></div></li><li uk-parallax="x:-60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="One of the most immediate benefits of Submer’s Immersion Cooling solutions is the prolonged life-span of the hardware. The SmartCoolant cools and protects the servers in a particulate-free environment, with no whiskers, no moving parts, etc."><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/05/ic_life.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>+30% in HW life-span</p></div></li></ul><ul><li uk-parallax="x:60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="The SmartCoolant, the dielectric proprietary fluid used in Submer’s solutions, apart from whisking heat away from the cores, protects the servers and their components from dust, particles, abrupt changes of temperature and moisture, prolonging the HW life-span."><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/05/ic_hwRate.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>-60% in HW failure rate</p></div></li><li uk-parallax="x:60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="Submer’s solutions are rapidly deployable in raw space without the need for raised floors. They can easily integrate into an already existing datacenter or warehouse or even in an office with minimum retrofitting. The MicroPod offers a self-contained, ruggedised and fully-sealed immersion enclosure.
"><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/06/ic_buildingCosts.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Save 50% on CAPEX building costs</p></div></li><li uk-parallax="x:60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="In a datacenter, about 40% of the electricity is used for the cooling system. Submer’s technology allows to save up to 95% on cooling OPEX (corresponding to about 50% of the electricity bill). With Submer’s solutions, you get highly efficient primary and secondary cooling systems. Besides, your servers consume less since they do not need fans. "><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/05/ic_cooling.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Save 95% on cooling OPEX</p></div></li><li uk-parallax="x:60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="Water is an essential resource for any datacenter operations as important as electricity. Submer’s MicroPod system guarantees zero water consumption as it does not need any connection to the secondary cooling system."><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/05/ic_waterWaste.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Zero water consumption</p></div></li><li uk-parallax="x:60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="Submer’s solutions are designed to be easily integrated into already existing facilities and to help your datacenter be more efficient and environmentally friendly. Submer’s technology has been conceived to not simply dissipate heat, but also to smartly recapture and reuse the heat dissipated for other purposes such as the heating of the building hosting the datacenter or the surrounding urban and industrial areas."><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/05/ic_heat.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Re-use of heat</p></div></li></ul></div></div></section><div id="icon-modal" uk-modal=""> <!----><div> <div><div> <p><img src="" alt=""></p></div></div></div></div>  <section id="technical-aspects-88370"><div><div><div><figure uk-sticky="media:768;bottom:true;offset:30"> <img uk-img="" data-src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/10/pod-render_micropod_open_zenital-e1603708195705.png" alt="" src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/10/pod-render_micropod_open_zenital-e1603708195705.png"></figure></div><div><div><div><div><p><img data-src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/07/specsicon.svg" uk-img="" alt=""></p></div></div><table><tbody><tr><td><span>Heat dissipation capacity (kW)</span></td><td><span>Outdoor configuration: 5000 W (in direct sunlight)<br> Indoor configuration: 6600 W</span></td></tr><tr><td><span>IT gear capacity (U, OU) </span></td><td><span>19 inch / 6U ,  600 mm max depth</span></td></tr><tr><td><span>Dimensions, L x W x H (cm, in) </span></td><td><span>130 (L) x 65 (W) x 90 (H) cm<br> 51.18 (L) x 25.59 (W) x 35.43 (H) in<br> Maximum height with lid open:<br>155 (H) cm 61.02 (H) in<br> </span></td></tr><tr><td><span>SmartCoolant capacity (l, gal) </span></td><td><span>96 l / 25.3 gal</span></td></tr><tr><td><span>Weight, empty (kg, lb) </span></td><td><span>approx 227kg / 500 lb</span></td></tr><tr><td><span>Weight, full of SmartCoolant weight (kg, lb) </span></td><td><span>approx 303 kg / 669 lb</span></td></tr><tr><td><span>Weight, full of Servers (kg, lb)</span></td><td><span>approx 340 kg / 749 lb</span></td></tr><tr><td><span>Footprint, L x W (m2, f2) </span></td><td><span>0.845 m2 / 9.1 f2</span></td></tr><tr><td><span>Power supply options </span></td><td><span>(CE) 380-400 V 50 Hz / (UL) 208-230 V 60 Hz</span></td></tr><tr><td><span>Power supply connection options </span></td><td><span>(CE) Industrial connector three phase 3P+E+N 16A IEC 60309<br> (UL) 20A NEMA plug L2120</span></td></tr><tr><td><span>Water Requirement</span></td><td><span>None</span></td></tr><tr><td><span>Communications</span></td><td><span>Multiple options for integrated pass-through patch panel and cable management / Ethernet port</span></td></tr><tr><td><span>Backup Power</span></td><td><span>Multiple options for integrated Battery Backup Units with up 40min active critical power</span></td></tr><tr><td><span>Ambient air temperature range, recommended less or equal to (°C, °F)</span></td><td><span>0°C - 50°C, 32°F - 122°F</span></td></tr><tr><td><span>Works under direct solar load</span></td><td><span>Yes</span></td></tr></tbody></table></div></div></div></div></section> <!-- This is the modal --><div id="modal-download-technical-aspects-88370" uk-modal=""><div> <p><h3>Download <span>MicroPod</span> - Technical specs</h3></p> <!--[if lte IE 8]> <script charset="utf-8" type="text/javascript" src="//js.hsforms.net/forms/v2-legacy.js"></script> <![endif]-->   </div></div><section><div><h2><span>Compatible with any</span> IT hardware</h2></div></section><section id="blockfreecontent-64969"><div uk-img="" data-src=""><div><div><p><img loading="lazy" src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-rooftop3-copy-1024x576.jpg" alt="" width="1024" height="576" srcset="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-rooftop3-copy-1024x576.jpg 1024w, https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-rooftop3-copy-1800x1013.jpg 1800w, https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-rooftop3-copy-768x432.jpg 768w, https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-rooftop3-copy-1536x864.jpg 1536w, https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-rooftop3-copy-2048x1152.jpg 2048w, https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-rooftop3-copy-scaled.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-rooftop3-copy-1024x576.jpg 1024w, https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-rooftop3-copy-1800x1013.jpg 1800w, https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-rooftop3-copy-768x432.jpg 768w, https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-rooftop3-copy-1536x864.jpg 1536w, https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-rooftop3-copy-2048x1152.jpg 2048w, https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-rooftop3-copy-scaled.jpg 2000w" data-src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-rooftop3-copy-1024x576.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><div><h2>Immersion Cooling at the Edge</h2><p>Submer’s MicroPod is the perfect Immersion Cooling solution for Edge applications, colocation datacenters, telcos and cloud computing. Thanks to its compact, <span>modular, plug-and-play, datacenter-in-a-box configuration</span>, the MicroPod allows for fast deployment in any location, including direct sunlight and an easy plug-and-play installation with an unrivalled energy footprint anywhere on the globe.</p></div></div></div></div></section><section uk-img="" data-src=""><div><h2> Submer <span>Services</span></h2><div uk-grid=""><ul><li uk-parallax="x:-60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="Submer’s team can help you assess if your facility meets the basic requirements for the installation of our solutions. One of the aspects of our technology is that it can be deployed practically anywhere. Nevertheless, there are some fundamental requirements for the proper installation and functioning of Submer’s solutions.
"><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/06/ic_facility.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Facility Analysis</p></div></li><li uk-parallax="x:-60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="Design together with our technicians your datacenter! Share with us your goals, and your facility characteristics, ask all your questions, and we will plan the best solution for your business needs."><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/06/ic_designPlanning.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Design &amp; Planning</p></div></li><li uk-parallax="x:-60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="Submer’s solution can be deployed anywhere: from harsh climate regions to warehouses, from Edge installations to office buildings. Our team of experts will work with you to better understand how to adapt our solutions to your spatial and geographic needs. We will also walk you through the whole set-up and activation process."><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/06/ic_deployment.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Deployment &amp; Activation</p></div></li><li uk-parallax="x:-60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="We offer immersion ready servers through our partners. Clearly, this is optional: our solution is universal and open to any off-the-shelf server, so our customers can choose their preferred OEM."><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/06/ic_certifiedCoolant.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Certified Immersion Hardware</p></div></li></ul><ul><li uk-parallax="x:60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="Submer complies with all the safety and quality rules and policies, as stated by various certifications. When you become one of our customers, you do not just get a product like many others. We listen to you and we offer a solution fit for your needs. And since quality and safety are two funding values of Submer, we want to share them with you as well."><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/06/ic_certifications.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>All Necessary Certifications</p></div></li><li uk-parallax="x:60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="Submer assists you in every step of your journey towards efficiency, better performance and sustainability. Our multi-talented team will guide you and support you sharing with you their experience in mechanics, engineering, thermodynamics, chemistry, etc. Before the installation of any Submer’s solution, during its operation and also after, Submer’s team will always be available for any preventive and corrective maintenance procedure. "><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/06/ic_maintenance.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Preventive and Corrective Maintenance</p></div></li><li uk-parallax="x:60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="We want our customers to be satisfied with our service and solutions. That’s why we guarantee that every single step of our customer’s journey toward a future of smart datacenters is taken having in mind all kinds of safety and quality measures. You will be in total control of the solution you decide to purchase and we will provide you with technical assistance and training and also with all the necessary warranties (from us, but also from our partners)."><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/06/ic_control.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Control and Warranties</p></div></li><li uk-parallax="x:60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="What if instead of just being one of our customers, you want to become a partner and share our vision of smart datacenters all over the globe? Get in touch with us and let’s build the basis for a solid, long-lasting partnership. And who knows, maybe along the way, we’ll also become best friends!"><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/06/ic_friendship.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Partnership and Friendship along the way (this is for free)</p></div></li></ul></div></div></section><div id="icon-modal" uk-modal=""> <!----><div> <div><div> <p><img src="" alt=""></p></div></div></div></div>  <section><div><p>Ask questions, tell us more about your upcoming datacenter/HPC or Hyperscale project. We're here to help.</p></div></section><main id="main"><!--  uk-container --></main><!-- #main --><!-- #colophon --> <!--googleoff: all--><div><div id="cookie-law-info-bar" data-cli-geo-loc="0"><p><span>This website uses cookies to improve your experience. We'll assume you're ok with this, but you can opt-out if you wish. <a href="https://submer.com/cookies-policy/" id="CONSTANT_OPEN_URL" target="_blank">Read More</a><a role="button" tabindex="0">Cookie settings</a> <a role="button" tabindex="0" data-cli_action="accept" id="cookie_action_close_header">ACCEPT</a> </span></p></div></div>  <!--googleon: all-->          <a uk-scroll="" href="#top" uk-icon="icon:arrow-up"></a> <!-- Start of HubSpot Embed Code -->  <!-- End of HubSpot Embed Code --></div>]]>
            </description>
            <link>https://submer.com/micropod</link>
            <guid isPermaLink="false">hacker-news-small-sites-24970554</guid>
            <pubDate>Mon, 02 Nov 2020 17:22:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Raspberry Pi 400 vs. ZX Spectrum]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24969935">thread link</a>) | @DSpinellis
<br/>
November 2, 2020 | https://www.spinellis.gr/blog/20201102/ | <a href="https://web.archive.org/web/*/https://www.spinellis.gr/blog/20201102/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <!-- Left content -->
  <p>The release of the <a href="https://www.raspberrypi.org/products/raspberry-pi-400/?resellerType=home">Raspberry Pi 400 personal computer</a> reminded me of a wildly popular home computer that was launched in a similar computer-in-a-keyboard format almost 40 years ago: the Sinclair Research <a href="https://en.wikipedia.org/wiki/ZX_Spectrum">ZX Spectrum</a>. I decided to compare the two, following the steps of an <a href="https://www.spinellis.gr/blog/20151129/">earlier comparison</a> I performed between the 2015 Rapsberry Pi Zero and the 1957 Elliott 405.</p>
<p><img src="https://www.spinellis.gr/blog/20201102/ZXSpectrum.jpg" alt="The 1982 ZX Spectrum home computer"> <a href="https://commons.wikimedia.org/w/index.php?curid=170050">ZX Spectrum picture by Bill Bertram — Own work, CC BY-SA 2.5</a></p>
<h3 id="comparison-table">Comparison table</h3>
<table>
<thead>
<tr>
<th></th>
<th>ZX Spectrum</th>
<th>Raspberry Pi 400</th>
</tr>
</thead>
<tbody>
<tr>
<td>Launch year</td>
<td>1982</td>
<td>2020</td>
</tr>
<tr>
<td>Price</td>
<td>£125</td>
<td>£ 94</td>
</tr>
<tr>
<td></td>
<td>(<a href="https://www.officialdata.org/uk/inflation/1982?amount=125">£440 in 2020 prices</a>)</td>
<td></td>
</tr>
<tr>
<td>Processor</td>
<td>Z80A</td>
<td>BCM2711 Cortex-A72 (ARM v8)</td>
</tr>
<tr>
<td>CPU register width</td>
<td>8 bit</td>
<td>64 bit</td>
</tr>
<tr>
<td>Clock frequency</td>
<td>3.5MHz</td>
<td>1.8GHz</td>
</tr>
<tr>
<td>Number of cores</td>
<td>1</td>
<td>4</td>
</tr>
<tr>
<td>Main memory</td>
<td>16 kB</td>
<td>4GB</td>
</tr>
<tr>
<td>Networking</td>
<td>None</td>
<td>Gigabit Ethernet &amp; WiFi</td>
</tr>
<tr>
<td>Secondary storage</td>
<td>Audio cassette tapes</td>
<td>16GB microSD card</td>
</tr>
<tr>
<td></td>
<td>(not included)</td>
<td>(included)</td>
</tr>
<tr>
<td>Video output</td>
<td>TV RF modulator</td>
<td>Two micro HDMI ports</td>
</tr>
<tr>
<td>Video resolution</td>
<td>256×192</td>
<td>3840×2160</td>
</tr>
<tr>
<td>Output colors</td>
<td>16</td>
<td>16 million</td>
</tr>
<tr>
<td>Graphics support</td>
<td>PLOT, DRAW</td>
<td>OpenGL ES 3.0</td>
</tr>
<tr>
<td>Video support</td>
<td>None</td>
<td>H.265 (decode); H.264 (decode, encode)</td>
</tr>
<tr>
<td>Keyboard</td>
<td>40 keys</td>
<td>78 keys</td>
</tr>
<tr>
<td>Board chips</td>
<td>11 VLSI, 7 SSI</td>
<td>7 VLSI, 3 MSI</td>
</tr>
<tr>
<td>Dimensions</td>
<td>233×144×30 mm</td>
<td>286 × 122 × 23 mm</td>
</tr>
</tbody>
</table>
<p><img src="https://www.spinellis.gr/blog/20201102/rpi400.jpg" alt="The 2020 Raspberry Pi 400 personal computer"> Photo Credit: Raspberry Pi Foundation</p>
<h3 id="summing-up">Summing up</h3>
<p>The remarkable hardware improvements apparent in the comparison of the two products, combined with the rise of open source software, allow the Raspberry Pi 400 to come with an industrial-strength operating system offering internet connectivity and free access to around fifty thousand software packages. The Raspberry Pi 400 showcases the amazing progress personal computing technology has made over the past 40 years.</p>

<p>
<!-- COMMENTS --> <a href="https://www.spinellis.gr/cgi-bin/comment.pl?date=20201102#comments">Read and post comments</a>, or share through&nbsp;&nbsp;&nbsp;
<!-- Go to www.addthis.com/dashboard to customize your tools -->
</p>

</div></div>]]>
            </description>
            <link>https://www.spinellis.gr/blog/20201102/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24969935</guid>
            <pubDate>Mon, 02 Nov 2020 16:36:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What 2001’s HAL can teach you about software quality testing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24969844">thread link</a>) | @CrankyBear
<br/>
November 2, 2020 | https://www.functionize.com/blog/what-2001s-hal-can-teach-you-about-software-quality-testing/ | <a href="https://web.archive.org/web/*/https://www.functionize.com/blog/what-2001s-hal-can-teach-you-about-software-quality-testing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><img width="1080" height="634" src="https://3laqvw22wekb3ykm8z4dbnq8-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/ft-hall9000.jpg" alt="What 2001’s HAL can teach you about software quality testing" srcset="https://www.functionize.com/wp-content/uploads/2020/10/ft-hall9000.jpg 1080w, https://www.functionize.com/wp-content/uploads/2020/10/ft-hall9000-300x176.jpg 300w, https://www.functionize.com/wp-content/uploads/2020/10/ft-hall9000-1024x601.jpg 1024w, https://www.functionize.com/wp-content/uploads/2020/10/ft-hall9000-768x451.jpg 768w" sizes="(max-width: 1080px) 100vw, 1080px">      </p>	  
    
        <blockquote><p>The pod bay doors didn’t open. Why didn’t someone test for that?</p></blockquote>
<p>One of the most famous bits of movie dialog, one that’s become part of popular culture, is in the film <a href="https://www.imdb.com/title/tt0062622/" target="_blank" rel="noopener noreferrer">2001: A Space Odyssey</a>. The protagonist, Dr. Dave Bowman, says to the voice-driven AI, “<a href="https://www.youtube.com/watch?v=dSIKBliboIo" target="_blank" rel="noopener noreferrer">Open the pod bay doors</a>, HAL.” To which HAL responds, “I’m sorry, Dave, I’m afraid I can’t do that.”</p>
<p>(<em>Spoilers abound. You’ve been warned.</em>)</p>
<p>Most people only pay attention to the story. But if you’re a software QA expert, what you heard was an obvious failure in software quality testing.</p>
<p>The AI should have obeyed the order immediately. But obviously, the HAL 9000 computer went off the rails. In the process, the computer killed all but one of the crew of Discovery, the space ship that HAL was operating, and it failed in its mission to discover more about a mysterious monolith. That qualifies as <a href="https://www.functionize.com/blog/from-the-qa-trenches-6-signs-of-project-success-or-failure/">a serious software failure</a> – though, happily, a fictional one; fortunately, in the real world, <a href="https://www.functionize.com/blog/how-nasa-does-software-testing-and-qa/">NASA does a better job</a>.</p>
<p>It’s equally obvious that thorough testing of the computer and its AI software had missed HAL’s homicidal bent.</p>
<p>If you accept the premise that HAL was a mission-critical application, then there are actual lessons one can learn about ensuring important software meets expectations – particularly in an environment with a lot of unknowns.</p>
<p>So what happened? One reason is that testing an AI is complex. It’s also likely that the makers of the HAL 9000 didn’t think testing was necessary. Why? <a href="https://www.youtube.com/watch?v=Be8Gbqdox68" target="_blank" rel="noopener noreferrer">Just ask HAL</a>. “The 9000 series is the most reliable computer ever made. No 9000 computer has ever made a mistake or distorted information,” HAL said as an introduction.</p>
<p><iframe title="2001 A Space Odyssey - Just The HAL 9000" width="500" height="281" src="https://www.youtube.com/embed/Be8Gbqdox68?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>HAL didn’t view its actions as a mistake. Its programming didn’t include sufficient safeguards to prevent things like, say, killing your passengers. This is clearly a programming failure, and while it’s unlikely that the programming would specifically allow such an action, such an error also must not have been seen as contrary to mission success.</p>
<p>However, there are also other issues. The HAL 9000 computer, and its AI software, clearly used machine learning to modify its programming. That meant that when news reached the computer about a potential alien civilization, the AI changed its programming to help achieve what it now viewed as mission success. But as in many cases of AI failures, it had insufficient data on which to base such a conclusion. Likewise, it had (and did not create) safeguards to prohibit some types of actions, regardless of what the machine learning indicated.</p>
<p>By now, science fiction fans are muttering about the “<a href="http://webhome.auburn.edu/~vestmon/robotics.html" target="_blank" rel="noopener noreferrer">Three Laws of Robotics</a>,” but those don’t apply in the universe where this movie happened. Those laws, governing how robots are to interact with humans, were invented by author Isaac Asimov, and were intended to prevent robots (or other AI devices) from hurting people. They may not have been part of Arthur C. Clarke’s <em>2001</em> premise. There is something to be said in favor of incorporating them into HAL’s programming, but if nothing else, that would have ruined the story.</p>
<h3>How not to test</h3>
<p>“If there’s one thing we’ve learned from HAL 9000 and other major software glitches in the automobile, health, and safety sectors, it is to improve testing procedures,” says Eric Carrell, a DevOps engineer at <a href="https://rapidapi.com/" target="_blank" rel="noopener noreferrer">RapidAPI</a>. “It may sound counter-intuitive, but the best way to minimize bugs in software is to make sure another machine is not doing the job.”</p>
<p>“Testing automation looks extremely profitable in terms of cost-effectiveness and high productivity levels for development teams,” Carrell explains. “However, the truth is that a machine can barely make sure that another machine can be passed as safe or complete.”</p>
<p>Carrell suggests that what’s really needed for testing an AI is a well-thought-out culmination of automated and manual techniques. “It is true that human bias also exists. But, for the most part, the learning activities and judgment of a human will still try to emotionally as well as practically vet a particular choice,” Carrell says.</p>
<h3>How to test</h3>
<p>“There is no single recipe to describe how to properly test an AI-based system, just like there isn’t a single right method for testing any kind of system,” says Denis Leclair, VP of engineering at <a href="https://gotrellis.com/" target="_blank" rel="noopener noreferrer">Trellis</a>. “The core principles that make for a successful QA program are the same, by and large, whether or not the product employs AI.”</p>
<p>“One such principle is the need for a thorough understanding of the system’s requirements,” Leclair says. “This must include a thorough understanding of tolerances and the pass/fail criteria. For example, an AI system designed to drive an autonomous vehicle must be bound to a much lower tolerance for error than a recommender system used to recommend the next series for you to watch on your favorite streaming service.”</p>
<p>In addition, you have to find a way to test the AI’s decision-making. Is it making the right choice given the information it has available? “The determination of the right decision in and of itself is not always as clear cut as one might think,” Leclair explains.</p>
<p>“Furthermore, the appropriate test strategy will depend on a lot of the AI and machine learning (ML) techniques used in the solution,” Leclair says. “With ML, we can broadly classify any system into one of the following groups: fully supervised learning systems, semi-supervised learning systems, unsupervised learning systems, and reinforcement learning systems. The differences between these groupings are fundamentally how much information is given to the algorithm for it to train and possibly even evaluate its own correctness.”</p>
<h3>Levels of authority</h3>
<p>A primary reason for using AI is so the machine can make decisions and take action based on the inputs it receives and the range of allowed responses contained in the AI programming. But in an AI that also uses machine learning, those allowed responses may be altered. So the question then is just how much can the AI change, or what are the limits of its authority?</p>
<p>“The ‘authority’ given to the AI system can be thought of as the range of possible output values that the black box [the AI] might emit under any conceivable set of inputs and then any follow-on effects that those outputs might be connected to,” explains Leclair.</p>
<p>“For many AI applications, particularly with deep learning systems, it won’t be practical to analyze every micro-calculation being performed by the algorithm.” Leclair says. “Instead, a more statistical approach to testing these algorithms is generally the way to go. The idea is to exercise the system across a range of inputs and verify that the system’s inferences are correct (within tolerances) for those inputs.”</p>
<p>“Even if the AI models employed are deeply nested, rendering them effectively opaque, the system designer can always apply limits on the model’s outputs, effectively shaping the output to ensure that the answers remain within acceptable bounds appropriate for the target application. The QA engineers, for their part, must exercise and validate those limit checks by conducting boundary testing at the inputs and outputs of the system,” Leclair says.</p>
<p>Finally, make sure that the AI is producing data and making decisions as it’s supposed to. Leclair says the way to do this is through cross-validation. “Cross-validation is the act of testing a trained AI model against a series of previously unseen input data and evaluating the level of correctness of the output coming from the algorithm. From the QA standpoint, the objective is to validate the algorithm across a sample of input data sets representative of the range of inputs the system might expect to see in production.”</p>
<h3>Into the wild</h3>
<p><em>“</em>We are talking about creating systems that will end up being smarter than their masters,” Carrell says, “and we’re doing this by feeding them data. And so, in order to fully control how they behave or evolve over time, the key is to optimize training data. How this data is regressed and classified by the AI system will then eventually be responsible for the machine’s behavior.”</p>
<p>Look for <a href="https://www.functionize.com/blog/the-impact-of-cognitive-bias-on-software-testing/">patterns that indicate bias</a>, including any human bias and then determine whether the machine is ready to process world data. “These are the questions we want to be looking at before the machine is pushed out into the wild, to process data and dish out an entirely new result,” Carrell explains. “And so, new QA tests need to take into account security and governance measures that make an AI model completely prepared for real-world situations.”</p>
<p>Some of those tests must take into account the type of work the AI is being tasked to perform. As Leclair mentions, there’s a big difference between an autonomous vehicle and recommendations for a streaming service. As the level of responsibility grows, so must the need to confirm the limits to what the AI can do without either intervention or approval. While it may be useful for a defense AI to determine when a missile launch might be hostile, it’s critical that the AI receive approval before launching a retaliatory strike.</p>
<p>This means that even though the AI may have great latitude to learn from its inputs, it must still have limits. Perhaps, for HAL, those limits might have included Asimov’s laws.</p>
<blockquote><p>Our testing software is built on AI and machine learning, and we’re awfully proud of it. For example, Functionize uses AI to <a href="https://www.functionize.com/test-maintenance/">learn how your UI really works</a>. Renaming or restyling a button, even moving it on the page won’t break your tests. And we promise to close the pod bay doors when requested to do so.</p></blockquote>
<div>
<div>
<p><img src="https://3laqvw22wekb3ykm8z4dbnq8-wpengine.netdna-ssl.com/wp-content/uploads/2020/02/WR-NBC-Photo-72DPI.jpg" alt="Wayne Rash"></p>
<div>
<p><span>by</span> Wayne Rash</p>
<p>Wayne Rash is based in Washington and has been writing about science and technology for nearly 40 years. He is a contributor to Forbes.com and a columnist for eWEEK. He is a frequent speaker on technology and has been a guest on NPR, NBC, PBS, CNN and Fox News.</p>
</div>

</div>
</div>
  </div></div>]]>
            </description>
            <link>https://www.functionize.com/blog/what-2001s-hal-can-teach-you-about-software-quality-testing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24969844</guid>
            <pubDate>Mon, 02 Nov 2020 16:29:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Litte Snitch 5 for macOS Big Sur]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24969831">thread link</a>) | @lorenz_li
<br/>
November 2, 2020 | https://www.obdev.at/products/littlesnitch/whatsnew.html | <a href="https://web.archive.org/web/*/https://www.obdev.at/products/littlesnitch/whatsnew.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>



<section>
    <p><img src="https://www.obdev.at/Images/littlesnitch/whats-new/configuration.png" srcset="https://www.obdev.at/Images/littlesnitch/whats-new/configuration@2x.png 2x" width="1004" height="613" alt="Configuration Interface">
    </p>

    <p>
        <en>A beautiful new design, improved traffic statistics, a brand new command line interface, simplified Drag and Drop installation and the seamless compatibility with macOS Big Sur are setting Little&nbsp;Snitch&nbsp;5 apart from its predecessor.</en>
    </p>

    <h3><en>Redesigned for macOS Big Sur</en><!--de>Neu gestaltet für macOS Big Sur</de--></h3>
    <p>
        <en>The main focus in the development of Little Snitch 5 was on the integration of the new network filter technologies introduced by Apple in macOS Big Sur. The underlying filter engine was re-built from ground up to replace the previous kernel extension based approach which is no longer supported by macOS.</en>
    </p>
    <p>
        <en>Furthermore, Little Snitch was adapted to the new, elegant design language of the operating system with great attention to detail. New design features, like a prominent search bar and a newly structured sidebar go beyond aesthetic choice and add a level of simplicity and intuitiveness to the user experience.</en>
    </p>

    <h3><en>Drag and Drop Installation</en><!--de>Drag und Drop Installation</de--></h3>
    <p>
        <en>The simplified Drag and Drop installation has been eagerly awaited by many users. Now it’s no longer necessary to restart the computer in order to install or update Little Snitch.</en>
    </p>

    <h3><en>Improved Traffic Monitoring</en><!--de>Verbesserte Netzwerkverkehrsüberwachung</de--></h3>
    <p><img src="https://www.obdev.at/Images/littlesnitch/whats-new/monitor.png" srcset="https://www.obdev.at/Images/littlesnitch/whats-new/monitor@2x.png 2x" width="1095" height="627" alt="Network Monitor">
    </p>
    <p>
        <en>Little Snitch now captures connection information efficiently in the background. It no longer requires the Network Monitor application to be running in order to collect this information, resulting in reduced memory and CPU consumption.</en>
    </p>
    <p>
        <en>The improved monitoring system is now capable of holding traffic information from up to a whole year, instead of only the last hour as before.</en>
    </p>

    <h3><en>Command Line Interface</en><!--de>Kommandozeilen-Schnittstelle</de--></h3>
    <p>
        <en>System administrators now have the ability to configure a variety of program settings via a command line interface, making Little Snitch scriptable for the very first time.</en>
    </p>
    <p>
        <en>This interface now also offers the possibility to report network connections in a log-based format for detailed and versatile traffic analysis.</en>
    </p>

    <h3><en>Free Upgrade</en><!--de>Kostenloses Upgrade</de--></h3>
    <p>
        <en>If you have purchased Little Snitch 4 after November 1, 2019, you can upgrade to Little Snitch 5 for free – just use your existing license key. If you purchased Little Snitch 4 before that period, you can <a href="https://www.obdev.at/shop/index.html#upgrades">get the upgrade at a reduced price</a>.</en>
    </p>

</section>

<section id="download">
    <a href="https://www.obdev.at/products/littlesnitch/download.html">
        <p><img src="https://www.obdev.at/Images/product-icons/littlesnitch_128.png" srcset="https://www.obdev.at/Images/product-icons/littlesnitch_128@2x.png 2x" width="128" height="128" alt="Little Snitch App Icon">
        </p>
        
        
    </a>
</section>

			</div></div>]]>
            </description>
            <link>https://www.obdev.at/products/littlesnitch/whatsnew.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24969831</guid>
            <pubDate>Mon, 02 Nov 2020 16:29:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Add, Remove, Extract, Replace Audio from Video Using FFmpeg]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24969796">thread link</a>) | @ponderingfish
<br/>
November 2, 2020 | https://ottverse.com/add-remove-extract-audio-from-video-using-ffmpeg/ | <a href="https://web.archive.org/web/*/https://ottverse.com/add-remove-extract-audio-from-video-using-ffmpeg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure>
<img src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/pexels-photo-1626481.jpeg?resize=678%2C381&amp;ssl=1" alt="black cassette tape on top of red and yellow surface" title="pexels-photo-1626481" data-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/pexels-photo-1626481.jpeg?resize=678%2C381&amp;ssl=1" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
<figcaption>Photo by Stas Knop on <a href="https://www.pexels.com/photo/black-cassette-tape-on-top-of-red-and-yellow-surface-1626481/" rel="nofollow">Pexels.com</a></figcaption>
</figure>


<p><strong>FFmpeg is a super-powerful tool to add, remove, extract, or replace the audio in your video files. If you have a copy of FFmpeg installed on your computer, then you have just the tool to help you add or remove an audio track from your movie. </strong></p>



<p>Let’s get to it and see how it’s done! </p>




<h2><span id="How_to_Remove_Audio_from_Video_using_FFmpeg"></span>How to Remove Audio from Video using FFmpeg<span></span></h2>



<p>Many people want to know how to remove or delete the audio track from a video they’ve recorded. This could be because of road-noise or background noise, etc. and they want to get rid of it.</p>



<p>The simplest way to <strong>remove or delete audio is to actually copy the video to a new file and discard the audio</strong> while doing this. This is a simple technique because it does not involve the re-encoding of the video while you are at it. Here is the command line for achieving this.</p>



<pre><code>ffmpeg.exe -i videoWithAudio.mp4 -c:v copy -an videoWithoutAudio.mp4</code></pre>



<ul><li><code>-c:v copy</code> copies the video track into <code>videoWithoutAudio.mp4</code></li><li><code>-an</code> tell FFmpeg to <strong>not copy the audio</strong></li></ul>



<p>Now this works great if you have only one audio track in your movie. But, what happens if you have three or four audio tracks and you want to remove only the second audio track? </p>



<p><strong>How do you remove a specific audio track using FFmpeg?</strong></p>



<p>Let’s take a look in the next section.</p>



<hr>



<h2><span id="How_to_Remove_a_Specific_Audio_Track_using_FFmpeg"></span>How to Remove a Specific Audio Track using FFmpeg<span></span></h2>



<p>For removing a specific audio track using FFmpeg, you can always use the <code>map</code> command. </p>



<p>The general syntax of the <code>map</code> command is <code>-map input_file_index:stream_type_specifier:stream_index</code>. </p>



<p>So, you could select the 2nd audio track of the video by saying <code><strong>-map 0:a:1</strong></code> because the numbering starts at 0. In our example, if your file has 1 video track and two audio tracks, then you can use <code>-map 0:a:1</code> to only select the second audio track and copy it to your final output. </p>



<p>Also, <code>-map 0</code> selects everything from the first input. So, basically, you are selecting everything and <strong>then</strong> de-selecting the audio.</p>



<pre><code>ffmpeg.exe -i videoWithAudio.mp4 -map 0 -map 0:a:1 -copy videoOutput.mp4</code></pre>



<p>If you have 5 audio tracks and you want to select all but the first one, then you can use the negative <code>map</code> command. By saying <code>-map -0:a:0</code> you are telling FFmpeg to ignore the first audio track. Negative <code>map</code> is very powerful! </p>



<p>Actually, in the previous section, we learned how to remove audio from your video using <code>-an</code>, right? You can do this using negative mapping as well as follows. </p>



<pre><code>ffmpeg -i videoWithAudio.mp4 -map 0 -map -0:a videoWithoutAudio.mp4 </code></pre>



<hr>



<h2><span id="How_to_Add_an_Audio_Track_using_FFmpeg"></span>How to Add an Audio Track using FFmpeg<span></span></h2>



<p>Now that you removed an audio track, you might want to add one too, right? Here’s how you add an audio track to your video using FFmpeg. </p>



<p>Since you have already read about the <code>map</code> command in the previous section, this should be very easy. Here is the command line</p>



<pre><code><code>ffmpeg \</code>
<code>-i video.mp4 \</code>
<code>-i audio.mp3 \</code>
<code>-c copy \</code>
<code>-map 0:v:0 \</code>
<code>-map 1:a:0 \</code>
<code>videoWithAudio.mp4 </code></code></pre>



<p>This is very easy to understand. What you’re doing is copying the audio and video from two different files using the <code>map</code> command to an output file. </p>



<ul><li><code>-map 0:v:0</code> selects the 0th track of the 0th input file (our video input).</li><li>–<code>map 1:a:0</code> selects the 0th track of the 1st input file (our audio input).</li><li><code>-c copy</code>` copies both the tracks (audio and video) to the output without re-encoding. If you want to re-encode, you can use the appropriate audio/video codecs with your choice of quality settings. </li></ul>



<hr>



<h2>How to Extract Audio from Video using FFMpeg?<span></span></h2>



<p>Another very useful and common operation is extracting audio from video using FFmpeg. You can do this with and without re-encoding the audio. </p>



<p>In the first case, let’s take a look at extracting the audio out of a media file and storing it without re-encoding it. </p>



<p>Extracting the audio involves discarding the video, right? And this is easily achieved using the <code>-vn</code> command that removes the video. The <code>-vn</code> command is similar to the <code>-an</code> command which removes the audio track. </p>



<p>Then, all you have to do is copy the audio from the source to the destination. This is done using the <code>-acodec copy</code> command that tells FFmpeg to only copy the audio and not re-encode it. </p>



<pre><code><code>ffmpeg -i videoWithAudio.mp4 -vn -acodec copy onlyAudio.aac </code></code></pre>



<p>Simple, right?</p>



<p>Now, let’s take a different use case where you might want to re-encode the audio after extracting it. Here’s how to extract the audio from the video using FFmpeg and then encoding it to a different quality level using <code>libmp3lame</code> and storing it as an mp3 file.</p>



<pre><code>ffmpeg.exe -i videoWithAudio.mp4 -vn -c:a libmp3lame -q:a 1 onlyAudio.mp3</code></pre>



<p><code>-q:a</code> uses quality presents defined in <a href="https://wiki.hydrogenaud.io/index.php/LAME" target="_blank" rel="noopener">LAME’s documentation</a> ranging from 0-6 where 0 is high-quality audio and 6 is on the lower end. </p>



<hr>



<figure><img data-attachment-id="1187" data-permalink="https://ottverse.com/pexels-photo-1261578-2/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/11/pexels-photo-1261578-edited.jpeg?fit=1880%2C1059&amp;ssl=1" data-orig-size="1880,1059" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Photo by Stas Knop on <a href=\&quot;https:\/\/www.pexels.com\/photo\/white-cassette-tape-1261578\/\&quot; rel=\&quot;nofollow\&quot;>Pexels.com<\/a>&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;white cassette tape&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="pexels-photo-1261578" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/11/pexels-photo-1261578-edited.jpeg?fit=300%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/11/pexels-photo-1261578-edited.jpeg?fit=1024%2C577&amp;ssl=1" loading="lazy" width="1880" height="1059" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/11/pexels-photo-1261578-edited.jpeg?resize=1880%2C1059&amp;is-pending-load=1#038;ssl=1" alt="add remove replace extract audio using ffmpeg
" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/11/pexels-photo-1261578-edited.jpeg?w=1880&amp;ssl=1 1880w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/11/pexels-photo-1261578-edited.jpeg?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/11/pexels-photo-1261578-edited.jpeg?resize=1024%2C577&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/11/pexels-photo-1261578-edited.jpeg?resize=768%2C433&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/11/pexels-photo-1261578-edited.jpeg?resize=1536%2C865&amp;ssl=1 1536w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/11/pexels-photo-1261578-edited.jpeg?resize=1200%2C676&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/11/pexels-photo-1261578-edited.jpeg?resize=678%2C381&amp;ssl=1 678w" data-lazy-sizes="(max-width: 1000px) 100vw, 1000px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/11/pexels-photo-1261578-edited.jpeg?resize=1880%2C1059&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Photo by Stas Knop on <a href="https://www.pexels.com/photo/white-cassette-tape-1261578/" rel="nofollow noopener" target="_blank">Pexels.com</a></figcaption></figure>



<h2><span id="How_to_Replace_Audio_in_a_Video_using_FFMpeg"></span>How to Replace Audio in a Video using FFMpeg?<span></span></h2>



<p>This is the final scenario that we will examine today. How do you replace the audio track of a video that already contains audio?</p>



<p>There is a two-step answer to this that we have already discussed which is to </p>



<ol><li>remove the audio </li><li>add the replacement audio. </li></ol>



<p>But, is there a better or quicker way to do this? Well, with FFmpeg, there is *always* a better way to do something 🙂 </p>



<p>The general syntax of the <code>map</code> command is <code>-map input_file_index:stream_type_specifier:stream_index</code>. So, you could select the 3rd audio track of the 2nd input by saying <code><strong>-map 1:a:2</strong></code> because the numbering starts at 0.</p>



<pre><code><code>ffmpeg -i video_with_audio.mp4 -i newAudio.wav \</code>
<code>-map 0:0 \</code>
<code>-map 1:0 </code>\
<code>-c:v copy \</code>
<code>-c:a libmp3lame -q:a 1 \</code>
<code>-shortest</code> \
video_with_newAudio<code>.mp4</code>
</code></pre>



<p>In our situation, we want to take the video from one file and the audio from another file. So, the <code>map</code> command comes in handy here as shown above. We are selecting the 0th track from the 1st input (our video), and the 0th track from the 2nd input (our audio).</p>



<p>Then we copy the video as is and re-encode the audio before putting them together in our new file. If you don’t want to re-encode the audio, you could simply say <code>-a:c copy</code> and the audio track will get copied and not re-encoded. </p>



<p>The <code>-shortest</code> command is used to ensure that the conversion stops when the length of the shorter of the two inputs is reached. You can discard this if it does not matter in your use case. </p>



<hr>



<h2><span id="Conclusion"></span>Conclusion<span></span></h2>



<p>There you have it – now you know how to add, remove, replace, or extract audio from a video using FFmpeg. </p>



<p>If you are interested in learning more about FFmpeg, <a href="https://ottverse.com/category/ffmpeg/"><span>check out our tutorials and deep-dives on FFmpeg.</span></a></p>



<p>A lot of these advanced options are discussed in FFmpeg’s <a href="https://ffmpeg.org/ffmpeg.html#Advanced-options" target="_blank" rel="noopener">documentation</a>.</p>

	</div></div>]]>
            </description>
            <link>https://ottverse.com/add-remove-extract-audio-from-video-using-ffmpeg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24969796</guid>
            <pubDate>Mon, 02 Nov 2020 16:25:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Launch HN: Fiddler – A Reliable Model Monitoring Tool for ML Operations]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24969735">thread link</a>) | @krishnagade
<br/>
November 2, 2020 | https://blog.fiddler.ai/2020/07/announcing-ml-monitoring-capabilities/ | <a href="https://web.archive.org/web/*/https://blog.fiddler.ai/2020/07/announcing-ml-monitoring-capabilities/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
<p><em><em>Today, at the VentureBeat Transform event, we launched our ML Monitoring feature set, inclusive of data drift detection, outlier detection, and data integrity. These capabilities are coupled with Fiddler’s industry-leading Explainable AI Platform to efficiently and effectively explain, analyze, and resolve MLOps production monitoring issues</em>.</em></p>



<h2><strong>Challenges in MLOps Monitoring&nbsp;</strong></h2>



<p>AI adoption is accelerating, with <a href="https://www.stateofai2019.com/">one in ten enterprises currently using ten or more AI applications</a> and <a href="https://www.gartner.com/document/3984974?ref=solrAll&amp;refval=256236044">75% of businesses expected to shift from piloting to operationalizing AI by 2024</a>. This trend has only been amplified by the pressure from Covid-19 to adopt automation to help cut costs. But the complexity of deploying ML has hindered the success of AI systems. Even beyond the challenge of amassing the right data to train models, model deployment and management present similar challenges to those that plagued software prior to the arrival of DevOps Monitoring.</p>



<h3><strong><strong>Challenge 1: Unreliable Inputs: feature drift, errors, and outliers</strong></strong></h3>



<p>Models are trained on historical data with the hope of generalizing to future examples. Unfortunately, trends and thus the data received by models often change, which in turn affect model performance. When such data drifts occur, data scientists must decide whether to act, often by retraining the model, or do nothing. Assessing the impact of a drift can help inform this decision, but today’s tools often inhibit the ability to attribute drift of one or more features to a shift in the model’s predictions.</p>



<p>Moreover, complex and brittle feature pipelines are liable to break at any moment. These breaks can range from virtually no effect to the model to a complete loss of functionality that causes the model to error out. Common types of feature pipeline errors include null or missing values, type mismatches, and range anomalies. Rapidly identifying and addressing these errors is paramount to ensuring reliability for deployed AI systems and the downstream applications and services they power.</p>



<p>Finally, deployed AI models may encounter seemingly valid data points containing values that fall outside the range of values within the training set. Detecting these outliers is important to ensure optimal performance of models and also best serve those who are impacted by these models. A decision to deny a loan to a fully viable applicant because the model detected this applicant as an outlier is bad for both the organization as well as the consumer.&nbsp; Today, such outliers often require anomaly detection systems on model inputs to identify.&nbsp;</p>



<h3><strong><strong><strong>Challenge 2: Uncertain feedback</strong></strong></strong></h3>



<p>After training a model, practitioners use the model’s target to assess the model’s performance. Production models, however, might not have access to the real-world results of their decisions until long after they’ve been made (for instance, a loan application system might not be notified of a default for months after the loan was approved). In this case, model metrics like AUC, precision, recall etc. cannot be calculated to assess real-time model performance. In the absence of live ground truth, ML practitioners must turn to proxy metrics, like prediction scores or intermediate model decisions, for model performance.&nbsp;</p>



<h3><strong><strong><strong><strong>Challenge 3: Tedious debugging&nbsp;</strong></strong></strong></strong></h3>



<p>In addition to merely tracking the aforementioned metrics and identifying when anomalies or issues arise, MLOps teams must then debug the issues as swiftly as possible. Given the complexity and black-box-nature of many AI systems, attribution of the symptom to its underlying cause–ie root cause analysis–is often incredibly difficult. If a specific feature is exhibiting issues, it may be straightforward to check the code and upstream systems used to generate that feature for changes or errors. But if the model’s overall performance begins to degrade, where do you start your investigation?</p>



<h2><strong><strong>Explainable AI + ML Monitoring = Comprehensive &amp; Actionable MLOps&nbsp;</strong></strong></h2>



<p>Today, at VB Transform, we launched our <a href="https://www.fiddler.ai/ml-monitoring">ML Monitoring suite</a>, to enable businesses of all sizes to monitor, explain, and analyze their AI in production and build more reliable, performant, and trustworthy AI models. Here’s an overview of capabilities available for use:&nbsp;</p>



<h3><strong><strong><strong><strong>Drift Detection</strong></strong></strong></strong></h3>



<p>With Fiddler’s drift detection capabilities, businesses are continuously alerted to changes in model feature or prediction distributions from their training baselines. This enables them to determine when it’s time to retrain models based on the impact of changes. Additionally, Fiddler attributes these changes to the underlying features causing them using AI Explainability. This enables practitioners to understand the ‘why’ and ‘how’ behind their model’s behavioral changes for faster problem resolution.&nbsp;</p>


	
	


<h3><strong><strong><strong><strong>Data Integrity</strong></strong></strong></strong></h3>



<p>Data inconsistencies can often go unnoticed in deployed AI systems. With Fiddler, teams can easily detect feature errors like missing values, type mismatch, and range anomalies, thereby reducing overall issue resolution time.</p>



<h3><strong><strong><strong><strong>Outlier Detection</strong></strong></strong></strong></h3>



<p>With the ability to detect outliers or anomalies in model predictions and features, users get a bird’s eye view into all anomalies to ensure they are catching these accurately and immediately. This can then be coupled with Fiddler’s AI explanations to quickly observe how the model is treating these outlying points.</p>


	
	


<h3><strong><strong><strong><strong><strong>Real-Time Alerting &amp; Explainable AI powered debugging</strong></strong></strong></strong></strong></h3>



<p>Alerts are critical to ensure teams catch things as they happen. Fiddler allows you to configure alerts for changes to model performance, prediction and feature drift, and service health, to be notified the moment something changes.&nbsp; When coupled with Explainable AI analytics, users can quickly identify the root cause of issues and troubleshoot them appropriately</p>



<p>If you’d like to learn more about the release and try it out today, <a href="https://www.fiddler.ai/learn-more?utm_campaign=Fiddler%20blog&amp;utm_source=monitoring-announce&amp;utm_medium=blog">sign-up for a demo</a>. </p>
</div>
    </div></div>]]>
            </description>
            <link>https://blog.fiddler.ai/2020/07/announcing-ml-monitoring-capabilities/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24969735</guid>
            <pubDate>Mon, 02 Nov 2020 16:20:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stumpy: Unleashing the Power of the Matrix Profile on Time Series Analysis]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24969704">thread link</a>) | @seanlaw
<br/>
November 2, 2020 | https://notamonadtutorial.com/stumpy-unleashing-the-power-of-the-matrix-profile-for-time-series-analysis-7c46af040adb | <a href="https://web.archive.org/web/*/https://notamonadtutorial.com/stumpy-unleashing-the-power-of-the-matrix-profile-for-time-series-analysis-7c46af040adb">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><h2 id="ce8e">An interview with Stumpy creator Sean Law</h2><div><div><div><p><a href="https://federicocarrone.medium.com/?source=post_page-----7c46af040adb--------------------------------" rel="noopener"><img alt="Federico Carrone" src="https://miro.medium.com/fit/c/56/56/2*p2NbnNI4sEc75QvzOZ1gaA.jpeg" width="28" height="28"></a></p></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2340/1*4Y5wJGqZM2AxKb7fmT9-og.png" width="1170" height="357" srcset="https://miro.medium.com/max/552/1*4Y5wJGqZM2AxKb7fmT9-og.png 276w, https://miro.medium.com/max/1104/1*4Y5wJGqZM2AxKb7fmT9-og.png 552w, https://miro.medium.com/max/1280/1*4Y5wJGqZM2AxKb7fmT9-og.png 640w, https://miro.medium.com/max/1400/1*4Y5wJGqZM2AxKb7fmT9-og.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*4Y5wJGqZM2AxKb7fmT9-og.png?q=20"></p></div></div></div><figcaption>Source: <a href="https://stumpy.readthedocs.io/en/latest/Tutorial_Time_Series_Chains.html" rel="noopener">Stumpy documentation</a></figcaption></figure><p id="2e87">In the mid-20th century the Information Age started. Everyday an astonishing amount of data is created and analysing it in an efficient way requires computational tools that combine novel and clever approaches attempting to take benefit from the cutting edge technology.</p><p id="364f">Time series are a particular kind of data: the points measu<span id="rmm">r</span>ed are related by time, and analysing them can often become quite difficult because time is not just like any other variable. More traditional methods like ARIMA or machine learning methods as LSTM employed for their analysis can quickly become computationally ineficient as the amount of points increase, and sometimes they can be too elaborated for simple results such as finding overall patterns in the data, not to mention the complications arising when finding more complex patterns in the data is the final goal.</p><p id="32d9">Stumpy is a library for analyzing time series, that tries to address the problems that appear when working with this kind of data, having in mind, since the beginning, high performance, simplicity, and to employ general purpose approaches for extracting meaningful information. We interviewed the team to learn more about this promising project.</p></div></div></section><section><div><p id="7d96"><em>Join the Not a Monad Tutorial Telegram </em><a href="https://t.me/notamonadtutorial" rel="noopener"><em>group</em></a><em> or </em><a href="https://t.me/channel_notamonadtutorial" rel="noopener"><em>channel</em></a><em> to talk about programming, computer science and papers. See you there!</em></p></div></section><section><div><p id="cb08"><em>If you are looking for good engineers send me an email to mail@fcarrone.com or you can also reach me via twitter at </em><a href="https://twitter.com/federicocarrone" rel="noopener"><em>@federicocarrone</em></a><em>.</em></p></div></section><section><div><div><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/822/1*NWV2vLKBciK49BAVfzvN4Q.png" width="411" height="136" srcset="https://miro.medium.com/max/552/1*NWV2vLKBciK49BAVfzvN4Q.png 276w, https://miro.medium.com/max/822/1*NWV2vLKBciK49BAVfzvN4Q.png 411w" sizes="411px" data-old-src="https://miro.medium.com/max/60/1*NWV2vLKBciK49BAVfzvN4Q.png?q=20"></p></div></div></figure><h2 id="5188">What is STUMPY? What are the goals of the project?</h2><p id="e0fa">Numerous classical methods exist for understanding and analyzing time series data, such as data visualization, summary statistics, ARIMA modeling, Markov modeling, anomaly detection, forecasting, machine learning, deep learning, etc. The list goes on. However, when a data practitioner is presented with new or unfamiliar time series data, many of the aforementioned approaches often fail to uncover any significant pattern, anomaly, or unique observation since it isn’t known, a priori, whether or not an interesting insight even exists. Of course, if a behavior is found to be conserved within your time series (though, this may not always be true), then there must have been a reason why it was conserved and teasing out those reasons or causes can often be very useful. Note that with time series analysis we are rarely interested in single point statistics (i.e., global max, global min, etc) and, instead, it is more valuable to discover interesting “subsequences” (i.e., a continuous run of values along your time series with a preset length). So, when starting with time series analysis, one should really be asking:</p><ol><li id="3acd">Do any conserved behaviors (i.e., repeating subsequences) exist in my time series data?</li><li id="2a2a">If there are conserved behaviors, what are they and where are they?</li></ol><p id="411b">A naive but straightforward approach that can help answer these questions (covered in more detail <a href="https://stumpy.readthedocs.io/en/latest/Tutorial_The_Matrix_Profile.html" rel="noopener">here</a>) could involve comparing the Euclidean distance for every subsequence within the time series in a pairwise fashion in order to identify subsequences that are either highly conserved or exceptionally rare. This seems intuitive at first and it provides an exact solution to our problem but, as the size of the dataset increases (&gt;10,000 data points), this brute force search can quickly become computationally intractable and reveals why approximate solutions (i.e., allowing for false positives and false negatives) or less interpretable solutions (above) have prevailed. Recently, <a href="https://www.cs.ucr.edu/~eamonn/MatrixProfile.html" rel="noopener">independent research conducted at UC Riverside</a> has spawned a collection of brand new ideas and they have developed scalable algorithms that directly addresses this hard computational problem. However, the knowledge and capabilities that have been transferred to the scientific Python community has been limited.</p><p id="01c6">And so, STUMPY was born. <a href="https://github.com/TDAmeritrade/stumpy" rel="noopener">STUMPY</a> is a powerful and scalable Python package that faithfully reproduces the aforementioned academic work and, at its core, efficiently computes something called a “matrix profile”, which can be used for a variety of time series data mining tasks. Essentially, a matrix profile is a vector that stores the Euclidean distance (and index location) between each subsequence within a time series and its nearest neighbor. And, with 100% code coverage and multi-CPU/multi-GPU support out of the box, the goal of STUMPY is to provide a highly reliable and user-friendly interface for modern time series analysis that can quickly and easily scale up to accommodate your ever-growing data needs.</p><h2 id="692d">What kind of time series analysis can be done with Stumpy? In what fields do you think it will help the most?</h2><p id="94c9">As mentioned above, STUMPY is focused on efficiently computing a simple-to-interpret but highly useful data structure called the “matrix profile”. Earlier, Eamonn Keogh, one of the original academic researchers, claimed that “Given the matrix profile, most time series data mining problems are easy or trivial to solve in a few lines of code.” In fact, Keogh and his colleagues have since published over 20 papers demonstrating the many things that can be done once you’ve computed the matrix profile and, below, are a just few examples:</p><ol><li id="c715">Motif discovery — identify conserved subsequences (related to pattern recognition)</li><li id="9b22">Discord discovery — uncover subsequences that are poorly conserved (related to anomaly detection)</li><li id="31e7">Time series chains — find related patterns that are evolving monotonically over time (related to forecasting)</li><li id="58fb">Semantic segmentation — automatically determine regime changes within your time series data (related to change point detection)</li><li id="b07f">Streaming data analysis</li><li id="1b98">Multi-dimensional matrix profiles</li><li id="0f0d">Time series clustering</li><li id="2da2">And more…</li></ol><p id="81be">One of the benefits of computing matrix profiles with STUMPY is that it is 100% domain agnostic. This means that it is completely generalizable and can be applied in any field where you need to analyze continuous sequential data! In addition to the previously published examples, STUMPY has been applied in analyzing the stock market, bettering server uptime and resiliency, investigating call center conversation flow, understanding IoT sensor data, improving cryptocurrency model predictions, and stabilizing ion acceleration at CERN, just to name a few. Today, time series data is ubiquitous in both academia as well as industry and so we believe that STUMPY is a new tool that is extremely well positioned to help researchers and data scientists explore their data in a systematic and focused way and, hopefully, allow them to discover new insights with much less frustration and time spent. If you already have Python installed then you should be able to get started with STUMPY in less time than it takes for you to make a cup of coffee.</p><h2 id="cc70">What are the benefits of computing the matrix profile in the context of analyzing a time series? What are the advantages over other methods?</h2><p id="2e1d">Matrix profiles are simple, intuitive, and interpretable. Basically, if you understand what Pythagorean theorem is then you’re all set! Whereas with other methods, if you step away from the analysis for six months and then come back to it, you often have to perform a lot of mental gymnastics in order to remember and understand what was going on. With a single line of STUMPY code, you can compute your matrix profile and <a href="https://stumpy.readthedocs.io/en/latest/Tutorial_STUMPY_Basics.html" rel="noopener">quickly identify motifs (conserved patterns) and discords (potential anomalies) by looking at the minima and maxima</a>, respectively. From there, a slew of rapid post-analyses can be performed using the matrix profile and the subsequent results can help you develop further hypotheses and questions about your data. Additionally, unlike other methods which may be riddled with false positives and false negatives, matrix profiles are exact and don’t require any “training” in order to find patterns. It just works right out-of-the-box!</p><h2 id="2da0">What is the general criteria when choosing a window size? Is there some indicator to look up when analysing a time series?</h2><p id="2f52">That’s a good question. Usually, the window size (i.e., the length of your subsequence or sliding window) should be chosen to be large enough to encompass a potential pattern. This usually requires a little bit of domain knowledge but the academic researchers have found that matrix profiles are not so sensitive to the choice of the window size so long as it isn’t smaller than the subsequence pattern. So, being in the rough ballpark is usually enough. However, since matrix profiles are pretty fast and cheap to compute, your best bet is to simply try several different window sizes, perhaps, by repeatedly doubling your window size and observing where there may be conserved minima/maxima across the set of matrix profiles. The academic researchers have also published a paper (which you can download <a href="https://www.cs.ucr.edu/~eamonn/PAN_SKIMP%20%28Matrix%20Profile%20XX%29.pdf" rel="noopener">here</a>) detailing a similar approach called a “pan matrix profile” that can help narrow down the search space. So, look out for this new STUMPY feature in an upcoming release!</p><h2 id="cbf0">What is semantic segmentation in the context of time series? What were the problems in the past with this method and how do you solve them?</h2><p id="253e">In the context of time series, “semantic segmentation” is “the division of a time series into internally consistent areas/regimes” or, sometimes, you can think of it as a “special type of clustering with the additional constraint that the elements in each cluster are contiguous in time”. Basically, if you have a time series where the values are repeating periodically within some range and then, in response to some external change or event, the time series shifts into another mostly periodic range so that you are left with two distinct “regimes”, then semantic segmentation may be useful for helping you identify the boundary in between the regimes. Now, methods like “change point detection” exist for detecting changes in various statistical properties of the time series (i.e., the mean or variance) but, fundamentally, we are interested in regimens which are defined by changes in the shapes of the …</p></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://notamonadtutorial.com/stumpy-unleashing-the-power-of-the-matrix-profile-for-time-series-analysis-7c46af040adb">https://notamonadtutorial.com/stumpy-unleashing-the-power-of-the-matrix-profile-for-time-series-analysis-7c46af040adb</a></em></p>]]>
            </description>
            <link>https://notamonadtutorial.com/stumpy-unleashing-the-power-of-the-matrix-profile-for-time-series-analysis-7c46af040adb</link>
            <guid isPermaLink="false">hacker-news-small-sites-24969704</guid>
            <pubDate>Mon, 02 Nov 2020 16:18:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Darklang: Leaving OCaml]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24969352">thread link</a>) | @areski
<br/>
November 2, 2020 | https://blog.darklang.com/leaving-ocaml/ | <a href="https://web.archive.org/web/*/https://blog.darklang.com/leaving-ocaml/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.darklang.com/content/images/size/w300/2020/11/skeleton-camel.jpg 300w,
                            https://blog.darklang.com/content/images/size/w600/2020/11/skeleton-camel.jpg 600w,
                            https://blog.darklang.com/content/images/size/w1000/2020/11/skeleton-camel.jpg 1000w,
                            https://blog.darklang.com/content/images/size/w2000/2020/11/skeleton-camel.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.darklang.com/content/images/size/w2000/2020/11/skeleton-camel.jpg" alt="Leaving OCaml">
            </figure>

            <section>
                <div>
                    <p><em>Part of a 3 part series. Followups on <a href="https://blog.darklang.com/new-backend-fsharp/">F#</a>, <a href="https://blog.darklang.com/why-dark-didnt-choose-rust/">Rust</a></em></p><p>I built the first demo of Dark in Python, in about two weeks. A few months later when I started productizing it, I rebuilt it in OCaml. Back in 2017, when I was considering the language and platform to use for Dark, OCaml was extremely compelling:</p><ul><li>it's a high-level language with static types, so easy to make large scale changes as we figure out what the language/product was</li><li>you mostly model data with sum types, which in my mind are the best way to model data</li><li>it's very similar to the language I wanted to build (in particular, we could reuse built-in immutable data structures for Dark's values)</li><li>it had a reputation for being high-performance, which meant that we could write an interpreter for Dark and not have it be terribly slow (vs writing an interpreter in python, which might be too slow)</li></ul><p>Unfortunately, as we've built Dark we've run into significant problems that have made it challenging to build in OCaml.</p><h2 id="lack-of-libraries">Lack of libraries</h2><p>When you bet on an off-mainstream language, one of the things you accept is that many libraries are not going to be available. When there is a small community, often there aren't enough people working in the language to make important libraries. This is especially true if few people are building business applications.</p><p>In OCaml there are many high quality libraries, especially for data structures and data manipulation. The annual<a href="https://opensource.janestreet.com/core/"> Jane Street code dump</a> has been quite useful and very high quality. However, we really felt the lack of several libraries. The most obvious of these is that we had to build a <a href="https://github.com/darklang/dark/blob/main/backend/libexecution/unicode_string.mli">Unicode string library</a> ourselves (built on top of the <a href="https://erratique.ch/software/uuseg">very impressive OCaml Unicode libraries</a> built by <a href="https://erratique.ch/contact.en">Daniel Bünzli</a>), but we needed many more libraries than that.</p><p>The lack of an SDK for Google Cloud has affected us greatly. When you're searching for product-market fit, you do the simplest, easiest thing. If you lack a good SDK for your cloud provider, the simplest, easiest thing is often a terrible architectural choice. We've built our own queue on top of our database rather than using the production-quality cloud queues available on GCP. Similarly, we barely use the Cloud Storage (GCP's version of S3), because we initially put things in the database <a href="https://blog.darklang.com/evolving-darks-tracing-system/">because it was easier</a>. We've built 3 services, 2 <a href="https://github.com/darklang/dark/tree/main/containers/stroller">in</a> <a href="https://github.com/darklang/dark/tree/main/containers/queue-scheduler">Rust</a>, and 1 in <a href="https://github.com/darklang/dark/tree/main/containers/postgres-honeytail">Go</a>, to workaround the challenges we've faced.</p><p>The biggest challenge here is our use of Postgres. Postgres is a great database and we're big fans, but Cloud SQL is not a great hosted database. GCP's position is that Cloud SQL is there to tick a box and we should be using Cloud Spanner. I would love to switch to Cloud Spanner, but we have no driver for it in OCaml. Given the Postgres driver in OCaml is not particularly mature, it's hard to expect that a Cloud Spanner driver would exist, and indeed it doesn't. We've had to contribute to the <a href="https://github.com/mmottl/postgresql-ocaml/commit/81a4ae5240decd8f483a90568257cfbc1558c7ed">OCaml Postgres driver</a>, and some parts of our codebase have been <a href="https://github.com/darklang/dark/blob/main/backend/libbackend/serialize.ml#L226">well and truly mangled</a> when working around features not supported in that driver.</p><p>We've also suffered from a lack of a high-level, production web stack (there are <a href="https://github.com/anmonteiro/ocaml-h2">low-level stacks with good reputations</a> that I've struggled to use, and a <a href="https://github.com/oxidizing/sihl">few</a> <a href="https://github.com/reason-native-web/morph">new</a> ones out there that look good), in particular lacking a user authentication module. We've been using <a href="https://auth0.com/">Auth0</a> to work around this for now, which has more moving pieces than I'd like, and a shockingly high cost (our 7000 users, most of whom never log in, costs us over $500/mo).</p><p>We've worked around other missing vendor SDKs by calling their HTTP endpoints directly and that's been mostly fine. However, for libraries like encryption we don't have that option - we <a href="https://github.com/darklang/dark/pull/1455/files">hacked around a missing encryption library</a>, but decided not to ship it to production until we audited it for security (which was never actually worth the cost).</p><p>At CircleCI, we bet on Clojure. That was also a non-mainstream language, but its ability to call Java SDKs meant we had a mature cloud library, which was essential for building CircleCI. Of course, in OCaml we could call C libraries (and <a href="https://github.com/darklang/dark/pull/1841">even Rust libraries</a>, perhaps), but it doesn't match having native libraries we can call directly.</p><h2 id="learnability">Learnability</h2><p>I'm mostly in the camp that anyone can learn any language, but I saw a team struggle with OCaml, and for good reason. Language tutorials are extremely poor in OCaml compared to other languages; they're mostly lecture notes from academic courses.</p><p>The compiler isn't particularly helpful, certainly compared to Rust or Elm (both of which have been in our stack at one point). Often it gives no information about an error. Syntax errors typically say "Syntax error"; though it will try to give a good error for a mismatched brace, often incorrectly. Type errors can be a real burden to read, even after 3 years of experience with it.</p><p>The docs in OCaml are often challenging to find. The <a href="https://ocaml.janestreet.com/ocaml-core/latest/doc/base/index.html">Jane Street docs</a> have improved significantly in the last few years, but it can be a challenge to even figure out what functions are available in a particular module for most libraries. Compare to the excellent <a href="https://docs.rs/">docs.rs</a> in Rust, which has comprehensive API docs for every package in Rust.</p><p>One of the ways I personally struggled in OCaml is around <code>Lwt</code>. Lwt is (one of!) OCaml's async implementations. I couldn't figure it out several years ago and so just built a single-threaded server. The amount of workarounds and downtime we've suffered from that single decision is immense. A tutorial around building high-performance (or even medium performance!) web servers would be very valuable. </p><p>Tooling is something I read would be good in OCaml. I remember reading there was a debugger that could go back in time! I don't know where that's gone but I've never heard of anyone using it.</p><p>We have struggled to make editor tooling work for us. This is partially because we also use ReasonML and this seems to break things. Unfortunately, this is common in programming, but even more so in small communities: you might be the first person to ever try to use a particular configuration.</p><p>Finally, the disconnect between the various tools is immense. You need to understand Opam, Dune, and Esy, to be able to get something working (you could also do it without Esy and just rely on Opam, but that's much worse). I talked about a bunch of these challenges <a href="https://blog.darklang.com/first-thoughts-on-rust-vs-ocaml/">here</a>.</p><h2 id="language-problems">Language problems</h2><p>Multicore is coming Any Day Now™️, and while this wasn't a huge deal for us, it was annoying. </p><h2 id="minor-annoyances">Minor annoyances</h2><p>One of my biggest annoyances was how often OCaml folks talk about Fancy Type System problems, instead of how to actually build products and applications. In other communities for similar languages (ReasonML, Elm, F#), people talk about building apps and solving their problems. In OCaml, it feels like people spend an awful lot of time discussing Functors. It's not quite at the level that I perceived in the Haskell world, but it pointed out that the people building the core of the ecosystem do not have the same problems that I do (which is building web-y stuff).</p><p>I honestly think OCaml was a great choice at the start. Being able to quickly and safely make large-scale changes to your app is something that staticly-typed functional languages excel at. I'm happy that we made the choice, and in retrospect, it still seems like the best choice of those we had at the time.</p><p>I'm working on building the next version of the backend. We have about 20k lines to be replaced, and they'll be rewritten in a new language while keeping the semantics the same. I plan to leave keep the frontend in ReasonML: it doesn't suffer from the same library problems as it can interface nicely to JS, and it's nearly 50k lines of code so it would be a much bigger undertaking.</p><p>Read <a href="https://blog.darklang.com/new-backend-fsharp/">the followup</a> to see what we picked!</p><hr><p><em><em><em><em><em><em><em><em>You can sign up for Dark </em></em></em></em></em></em></em></em><a href="https://darklang.com/signup" rel="noopener nofollow"><em><em><em><em><em><em><em><em>here</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>. For more info on Dark, follow our </em></em></em></em></em></em></em></em><a href="https://blog.darklang.com/rss" rel="noopener nofollow"><em><em><em><em><em><em><em><em>RSS</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>, follow </em></em></em></em></em></em></em></em><a href="https://twitter.com/darklang" rel="noopener nofollow"><em><em><em><em><em><em><em><em>us</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em> (or </em></em></em></em></em></em></em></em><a href="https://twitter.com/paulbiggar" rel="noopener nofollow"><em><em><em><em><em><em><em><em>me</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>) on Twitter, join our </em></em></em></em></em></em></em></em><a href="https://darklang.com/slack-invite" rel="noopener nofollow"><em><em><em><em><em><em><em><em>Slack Community</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>, watch our </em></em></em></em></em></em></em></em><a href="https://github.com/darklang/dark" rel="noopener nofollow"><em><em><em><em><em><em><em><em>GitHub repo</em></em></em></em></em></em></em></em></a><em>, or join our <a href="http://darklang.com/mailing-list">mailing list</a><em><em><em><em><em><em><em>.</em></em></em></em></em></em></em></em></p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.darklang.com/leaving-ocaml/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24969352</guid>
            <pubDate>Mon, 02 Nov 2020 15:48:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Survey shows bipartisan support for stronger consumer protections]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24969163">thread link</a>) | @encorekt
<br/>
November 2, 2020 | https://fairshake.com/consumer-news/survey-analysis-bipartisan-support-consumer-protections/ | <a href="https://web.archive.org/web/*/https://fairshake.com/consumer-news/survey-analysis-bipartisan-support-consumer-protections/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <h3><img src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/00-Header-1.jpg" alt="Header Image: White House Image with Title of Page" width="2022" height="1166" srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/00-Header-1.jpg 2022w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/00-Header-1-300x173.jpg 300w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/00-Header-1-1024x590.jpg 1024w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/00-Header-1-768x443.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/00-Header-1-1536x886.jpg 1536w" sizes="(max-width: 2022px) 100vw, 2022px" data-srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/00-Header-1.jpg 2022w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/00-Header-1-300x173.jpg 300w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/00-Header-1-1024x590.jpg 1024w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/00-Header-1-768x443.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/00-Header-1-1536x886.jpg 1536w" data-src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/00-Header-1.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></h3>
<h3>In this article:</h3>
<p><strong><a href="#survey-intro">Survey: Americans Agree on The Presidential Candidate They Think Will Protect Their Consumer Rights</a></strong></p>
<p><strong><a href="#survey-methodology">FairShake’s Survey Methodology</a></strong></p>
<p><strong><a href="#survey-consumer-protections">Across the Aisle, Americans Agree: We Need Stronger Consumer Protections</a></strong></p>
<p><strong><a href="#survey-biden-vs-trump">Respondents Think Joe Biden Cares More About Consumer Rights and Trump More About Corporate Rights</a></strong></p>
<p><strong><a href="#survey-trump-corporate-wrongdoing">President Donald Trump Voted “Most Likely” to Turn a Blind Eye to Corporate Wrongdoing</a></strong></p>
<h2><a id="survey-intro"></a>Survey: Americans Agree on The Presidential Candidate They Think Will Protect Their Consumer Rights</h2>
<p><span>With the ongoing threat of Coronavirus and all the difficulty it has introduced into day-to-day life, </span><a href="https://www.pewresearch.org/politics/2020/08/13/election-2020-voters-are-highly-engaged-but-nearly-half-expect-to-have-difficulties-voting/"><span>49% of registered voters in the U.S. report that they expect to have difficulties when it comes time to vote</span></a><span> for a presidential nominee. This is a major uptick from October 2018,&nbsp; when only 15% reported feeling the same way.&nbsp;</span></p>
<p><span>But, despite the uncertainties and hardships 2020 has wrought, the Pew Research Center found that engagement in this presidential election is the highest this country has seen in </span><i><span>decades</span></i><span>.&nbsp;</span></p>
<p><span>In fact, </span><a href="https://www.pewresearch.org/politics/2020/08/13/views-of-the-2020-campaign-and-voting-in-november/"><span>83% of voters say it “really matters” to them who wins the presidency</span></a><span> — the highest percentage since 2000.</span></p>
<p><span>And in a time when people feel more passionate about their politics than </span><i><span>ever</span></i><span>, it may come as a surprise that there is one very important issue upon which the majority of Americans agree: </span><b>Consumer rights</b><span>.&nbsp;</span></p>
<p><span>In this <a href="https://fairshake.com/consumer-news/survey-bipartisan-favor-stronger-consumer-protections/">representative survey of over 1,000 American adults that FairShake conducted in the fall of 2020</a>, we uncovered how the majority of U.S. citizens feel about their rights as consumers — and which of the leading presidential candidates they agree is more likely to protect these rights from being violated.</span></p>
<h2><span><a id="survey-methodology"></a>FairShake’s Survey Methodology</span></h2>
<p><span>For this survey, FairShake surveyed 1,003 American adults using a Pollfish.com survey that ran online from Sept. 21, 2020, to Oct. 5, 2020.</span></p>
<p><span>Results were stratified by Pollfish to match the gender and age distribution of the U.S. population, but before accounting for stratification…&nbsp;&nbsp;</span></p>
<p><span>Respondents were:</span></p>
<ul>
<li><span>60% female</span></li>
<li><span>40% male</span></li>
</ul>
<p><span>The age breakdown of survey respondents was:</span></p>
<ul>
<li><span>7% were aged 18-24</span></li>
<li><span>28% were aged 25-34</span></li>
<li><span>29% were aged 36-44</span></li>
<li><span>16% were aged 45-54</span></li>
<li><span>20% were aged 55 and up</span></li>
</ul>
<p><span>The self-identified party affiliation of respondents was:</span></p>
<ul>
<li><span>36% Democratic Party</span></li>
<li><span>33% Republican Party</span></li>
<li><span>31% reported “no party preference” or “other”</span></li>
</ul>
<p><span>Please keep in mind that totals may not add to 100% due to rounding and, finally, enjoy our synthesis of some of the most interesting results from our survey!&nbsp;</span></p>
<h2><span><a id="survey-consumer-protections"></a>Across the Aisle, Americans Agree: We Need Stronger Consumer Protections&nbsp;</span></h2>
<p><span>In the U.S., </span><a href="https://fairshake.com/guides/consumer-protection-laws/"><span>there are federal and state laws that outline consumer rights and protect customers</span></a><span> when they interact with companies that are in a position to take advantage of them.</span></p>
<p><span>Have you ever felt cornered into using the only </span><i><span>reasonable</span></i><span> internet service provider in your town? Or wished there was more you could’ve done to fight that unfair fee you had to pay before your provider would turn your cable back on?</span></p>
<p><span>If so, you’re not alone in feeling like your consumer rights have been violated by some of the companies that have the most impact on our lives.&nbsp;&nbsp;</span></p>
<p><span>In our survey, we found that — generally speaking — the majority of Americans don’t think the current consumer protections are strong enough when it comes to limiting monopolization by service providers, controlling companies that collect our personal data, and supporting people who work in the gig economy.&nbsp;</span></p>
<p><img src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/03-Image-1.jpg" alt="Graph showing the split between democrats and republicans on consumer protection issues." width="2022" height="2106" srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/03-Image-1.jpg 2022w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/03-Image-1-288x300.jpg 288w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/03-Image-1-983x1024.jpg 983w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/03-Image-1-768x800.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/03-Image-1-1475x1536.jpg 1475w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/03-Image-1-1966x2048.jpg 1966w" sizes="(max-width: 2022px) 100vw, 2022px" data-srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/03-Image-1.jpg 2022w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/03-Image-1-288x300.jpg 288w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/03-Image-1-983x1024.jpg 983w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/03-Image-1-768x800.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/03-Image-1-1475x1536.jpg 1475w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/03-Image-1-1966x2048.jpg 1966w" data-src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/03-Image-1.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>
<p><span>With the only plurality we’ll see when it comes to the section of our survey on consumer protections, 47% of Americans are in favor of stronger government laws and regulations around monopolization by service providers — such as cable and internet companies. Only 15% think government oversight should actively be made weaker here. To break it down further, 54% of respondents who identified as Democrats are in favor of more consumer rights protections while 37% of Republicans feel the same.&nbsp;</span></p>
<p><span>In our survey, Americans agree the most on stronger governance when it comes to companies that collect consumer data — think giants like Facebook and Google. In all, 63% of respondents favor stronger consumer rights laws for these companies while only 6% think such regulations should be weaker. This is the strongest area of bipartisan agreement in our entire survey, supported by 62% of Democrats and 59% of Republicans!&nbsp;</span></p>
<p><span>When it comes to government rules and regulations that protect workers who perform contracted “gig” jobs such as driving for Uber and food delivery services like Postmates, 54% of Americans support stronger legal protections for workers while 4% are for weakening these protections. With 60% of Democrats and only 42% of Republicans in favor of better safeguarding gig workers’ rights, this gap of 18 percentage points is the largest between parties when it comes to consumer rights protections.</span></p>
<h2><span><a id="survey-biden-vs-trump"></a>Respondents Think Former Vice President Joe Biden Cares More About Consumer Rights and President Donald Trump More About Corporate Rights</span></h2>
<p><span>Now, let’s drill down a little deeper to see how respondents feel about the leading presidential candidates — former Vice President Joe Biden and incumbent President Donald Trump — when it comes to protecting consumer rights.&nbsp;</span></p>
<p><span>Again, we see Americans reach across the aisle to agree: The majority opinion is that Joe Biden cares more about the rights of individual consumers while President Donald Trump cares more about the rights of corporations.&nbsp;</span></p>
<p><span>Specifically, 56% of all respondents say they perceive President Trump as caring more about corporations while 18% think he cares more about individual consumers.</span></p>
<p><span>Meanwhile, 39% of people say Joe Biden cares more about individual consumer rights while 31% think he cares more about corporations.<img src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/02-Image-1.jpg" alt="Graph shows respondents believe Trump will protect corporations over consumers" width="2022" height="1032" srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/02-Image-1.jpg 2022w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/02-Image-1-300x153.jpg 300w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/02-Image-1-1024x523.jpg 1024w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/02-Image-1-768x392.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/02-Image-1-1536x784.jpg 1536w" sizes="(max-width: 2022px) 100vw, 2022px" data-srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/02-Image-1.jpg 2022w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/02-Image-1-300x153.jpg 300w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/02-Image-1-1024x523.jpg 1024w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/02-Image-1-768x392.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/02-Image-1-1536x784.jpg 1536w" data-src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/02-Image-1.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></span></p>
<h2><span><a id="survey-trump-corporate-wrongdoing"></a>President Donald Trump Voted “Most Likely” to Turn a Blind Eye to Corporate Wrongdoing</span></h2>
<p><span>In light of the last section about consumer versus corporate rights, it shouldn’t be shocking to hear that the majority of Americans think Trump (51%) would be more likely than Biden (29%) to turn a blind eye if a corporation violated consumer rights. It’s interesting to note that a not-small percentage (20%) of Americans think both candidates would behave the same in this situation. <img src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/01-Image-1.jpg" alt="Graph shows respondents believe Trump is more likely to turn a blind eye to consumer rights violations" width="2022" height="1287" srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/01-Image-1.jpg 2022w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/01-Image-1-300x191.jpg 300w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/01-Image-1-1024x652.jpg 1024w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/01-Image-1-768x489.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/01-Image-1-1536x978.jpg 1536w" sizes="(max-width: 2022px) 100vw, 2022px" data-srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/01-Image-1.jpg 2022w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/01-Image-1-300x191.jpg 300w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/01-Image-1-1024x652.jpg 1024w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/01-Image-1-768x489.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/01-Image-1-1536x978.jpg 1536w" data-src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/01-Image-1.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></span></p>
<p><span>Interestingly, respondents replied as expected along party lines when asked which of these two presidential candidates would better protect their individual rights.&nbsp;</span></p>
<p><span>As for protecting consumer rights, 85% of Democrats say Biden would do a better job and 79% of Republicans think Trump would excel. When it comes to worker rights, 83% of Democrats think Biden would better preserve worker rights while 79% of Republicans say Trump would best protect workers.&nbsp;</span></p>
<h2><span>Do You Need Help Defending Your Consumer Rights?&nbsp;</span></h2>
<p><span>In an election year racked by a worldwide pandemic and a heightened level of political division, it’s comforting to know that Americans can generally agree on one thing: The importance of protecting consumers from predatory practices carried out by service provider monopolies, data-collecting giants, and the contractor-supported companies that power today’s gig economy.&nbsp;</span></p>
<p><span>If you’ve personally been taken advantage of by one of these or any </span><i><span>other</span></i><span> company, there’s finally something you can do about it.&nbsp;</span></p>
<p><a href="https://fairshake.com/start/"><span>Get in touch with FairShake today</span></a><span> and let us handle the </span><a href="https://fairshake.com/about-arbitration/"><span>arbitration process to get you the justice and compensation</span></a><span> you deserve.</span></p>
                    
                </div></div>]]>
            </description>
            <link>https://fairshake.com/consumer-news/survey-analysis-bipartisan-support-consumer-protections/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24969163</guid>
            <pubDate>Mon, 02 Nov 2020 15:33:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Open-source tool for rapid machine learning experimentation]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24968976">thread link</a>) | @brian_e_moore
<br/>
November 2, 2020 | https://voxel51.com/docs/fiftyone | <a href="https://web.archive.org/web/*/https://voxel51.com/docs/fiftyone">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article">
              
  <div id="fiftyone">

<p><em>“Rapidly experiment with your datasets”</em></p>
<p>If you are looking to boost the performance of your machine learning models,
chances are improving the quality of your dataset will provide the highest
return on your investment. <strong>Enter FiftyOne.</strong> FiftyOne is a Python-based tool
for machine learning/computer vision engineers and scientists that enables you
to curate better datasets. Work efficiently with FiftyOne to achieve better
models with dependable performance.</p>
<p><em>“Become one with your data”</em></p>
<p>FiftyOne does more than improve your dataset; it gets you closer to your data.
Rapidly gain insight by visualizing samples overlayed with dynamic and
queryable fields such as ground truth and predicted labels, dataset splits, and
much more!</p>
<p><img alt="Overview" src="https://voxel51.com/docs/_images/homepage1.png"></p>
<div id="core-capabilities">
<h2>Core Capabilities<a href="#core-capabilities" title="Permalink to this headline">¶</a></h2>
<p>FiftyOne provides advanced capabilities that will turbocharge your machine
learning workflows.</p>
<div>
    <div><div>
    <div>
        <h3>Finding annotation mistakes</h3>
        <p>Annotations mistakes create an artificial ceiling on the performance of your model. However, finding these mistakes by hand is not feasible! Use FiftyOne to automatically identify possible label mistakes in your datasets.</p>
        <p><a href="https://voxel51.com/docs/tutorials/label_mistakes.html">Check out the label mistakes tutorial</a>
    </p></div>
</div>
<div>
    <div>
        <h3>Removing redundant images</h3>
        <p>During model training, the best results will be seen when training on unique data. Use FiftyOne to automatically remove duplicate or near-duplicate images from your datasets and curate diverse training datasets from your raw data.</p>
        <p><a href="https://voxel51.com/docs/tutorials/uniqueness.html">Try the image uniqueness tutorial</a>
    </p></div>
</div>
<div>
    <div>
        <h3>Bootstrapping datasets from raw images</h3>
        <p>"What data should I select to annotate?" Use FiftyOne to automatically recommend unlabeled samples from your dataset to send for annotation, enabling you to bootsrap a training dataset that leads to demonstrably better model performance.</p>
        <p><a href="" onclick="return false;">Tutorial coming soon</a>
    </p></div>
</div>
<div>
    <div>
        <h3>Adding optimal samples to your dataset</h3>
        <p>"What new samples should I add to my training dataset to see the largest improvement in my model?" FiftyOne provides methods for mining hard samples from your datasets, a tried and true measure of mature machine learning processes.</p>
        <p><a href="" onclick="return false;">Tutorial coming soon</a>
    </p></div>
</div>
    </div>
</div></div>
<div id="core-concepts">
<h2>Core Concepts<a href="#core-concepts" title="Permalink to this headline">¶</a></h2>
<p>The FiftyOne tool has three components: the core library, the App, and the
Brain.</p>
<div id="fiftyone-core-library">
<h3><a href="https://voxel51.com/docs/user_guide/basics.html"><span>FiftyOne Core Library</span></a><a href="#fiftyone-core-library" title="Permalink to this headline">¶</a></h3>
<p>FiftyOne’s core library provides a structured yet dynamic representation to
explore your datasets. You can efficiently query and manipulate your dataset by
adding custom tags, model predictions and more.</p>

<div><table><tbody><tr><td><div><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14</pre></div></td><td><div><pre><span></span><span>import</span> <span>fiftyone</span> <span>as</span> <span>fo</span>

<span>dataset</span> <span>=</span> <span>fo</span><span>.</span><span>Dataset</span><span>(</span><span>name</span><span>=</span><span>"my_dataset"</span><span>)</span>

<span>sample</span> <span>=</span> <span>fo</span><span>.</span><span>Sample</span><span>(</span><span>filepath</span><span>=</span><span>"/path/to/image.png"</span><span>)</span>
<span>sample</span><span>.</span><span>tags</span><span>.</span><span>append</span><span>(</span><span>"train"</span><span>)</span>
<span>sample</span><span>[</span><span>"custom_field"</span><span>]</span> <span>=</span> <span>51</span>

<span>dataset</span><span>.</span><span>add_sample</span><span>(</span><span>sample</span><span>)</span>

<span>view</span> <span>=</span> <span>dataset</span><span>.</span><span>match_tag</span><span>(</span><span>"train"</span><span>)</span><span>.</span><span>sort_by</span><span>(</span><span>"custom_field"</span><span>)</span><span>.</span><span>limit</span><span>(</span><span>10</span><span>)</span>

<span>for</span> <span>sample</span> <span>in</span> <span>view</span><span>:</span>
    <span>print</span><span>(</span><span>sample</span><span>)</span>
</pre></div>
</td></tr></tbody></table></div>
<div>
<p>Note</p>
<p>FiftyOne is designed to be lightweight and flexible, making it easy to load
your datasets. FiftyOne supports loading datasets in a variety of common
formats out-of-the-box, and it also provides the extensibility to load
datasets in custom formats.</p>
<p>Check out <a href="https://voxel51.com/docs/user_guide/dataset_creation/index.html"><span>loading datasets</span></a> to see
how to load your data into FiftyOne!</p>
</div>
</div>
<div id="fiftyone-app">
<h3><a href="https://voxel51.com/docs/user_guide/app.html"><span>FiftyOne App</span></a><a href="#fiftyone-app" title="Permalink to this headline">¶</a></h3>
<p>The FiftyOne App is a graphical user interface (GUI) that makes it easy to
rapidly gain intuition into your datasets. You can visualize labels, bounding
boxes and segmentations overlayed on the samples; sort, query and slice your
dataset into any aspect you need; and more.</p>

<p><img alt="App" src="https://voxel51.com/docs/_images/homepage2.png">
</p></div>
<div id="fiftyone-brain">
<h3><a href="https://voxel51.com/docs/user_guide/brain.html"><span>FiftyOne Brain</span></a><a href="#fiftyone-brain" title="Permalink to this headline">¶</a></h3>
<p>The FiftyOne Brain is a library of powerful machine learning-powered
<a href="#core-capabilities"><span>capabilities</span></a> that provide insights into your
datasets and recommend ways to modify your datasets that will lead to
measurably better performance of your models.</p>

<div><table><tbody><tr><td></td><td><div><pre><span></span><span>import</span> <span>fiftyone.brain</span> <span>as</span> <span>fob</span>

<span>fob</span><span>.</span><span>compute_uniqueness</span><span>(</span><span>dataset</span><span>)</span>
<span>rank_view</span> <span>=</span> <span>dataset</span><span>.</span><span>sort_by</span><span>(</span><span>"uniqueness"</span><span>)</span>
</pre></div>
</td></tr></tbody></table></div>
<div>
<p>Note</p>
<p>The FiftyOne Brain is a separate Python package that is bundled with
FiftyOne. Although it is closed-source, it is licensed as freeware, and you
have permission to use it for commercial or non-commercial purposes. See
<a href="https://github.com/voxel51/fiftyone/blob/develop/LICENSE-BRAIN">the license</a>
for more details.</p>
</div>
</div>
</div>
<div id="what-s-next">
<h2>What’s Next?<a href="#what-s-next" title="Permalink to this headline">¶</a></h2>
<p>Where should you go from here? You could…</p>
<ul>
<li><p><a href="https://voxel51.com/docs/getting_started/install.html#installing-fiftyone"><span>Install FiftyOne</span></a></p></li>
<li><p>Try one of the <a href="https://voxel51.com/docs/tutorials/index.html"><span>tutorials</span></a> that demonstrate the unique
capabilities of FiftyOne</p></li>
<li><p>Explore <a href="https://voxel51.com/docs/recipes/index.html"><span>recipes</span></a> for integrating FiftyOne into
your current ML workflows</p></li>
<li><p>Consult the <a href="https://voxel51.com/docs/user_guide/index.html"><span>user guide</span></a> for detailed instructions on
how to accomplish various tasks with FiftyOne</p></li>
</ul>
</div>

</div>


             </article>
             
            </div></div>]]>
            </description>
            <link>https://voxel51.com/docs/fiftyone</link>
            <guid isPermaLink="false">hacker-news-small-sites-24968976</guid>
            <pubDate>Mon, 02 Nov 2020 15:18:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Turn any web page into a Twitter thread]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24968969">thread link</a>) | @kossnocorp
<br/>
November 2, 2020 | https://getchirrapp.com/extension | <a href="https://web.archive.org/web/*/https://getchirrapp.com/extension">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://getchirrapp.com/extension</link>
            <guid isPermaLink="false">hacker-news-small-sites-24968969</guid>
            <pubDate>Mon, 02 Nov 2020 15:18:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A new TypeScript Postgres query builder]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24968888">thread link</a>) | @jerodsanto
<br/>
November 2, 2020 | https://nullbyt.es/a-new-typescript-postgres-query-builder/ | <a href="https://web.archive.org/web/*/https://nullbyt.es/a-new-typescript-postgres-query-builder/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>It’s been almost 3 years since I started working on this query builder idea of mine. Today is finally the day Mammoth hits 1.0. Mammoth is a no-batteries-included type-safe Postgres query builder for TypeScript. Hooray!</p><figure><pre><code>db.with(
  `regionalSales`,
  () =&gt;
    db
      .select(db.orderLog.region, sum(db.orderLog.amount).as(`totalSales`))
      .from(db.orderLog)
      .groupBy(db.orderLog.region),
  `topRegions`,
  ({ regionalSales }) =&gt;
    db
      .select(regionalSales.region)
      .from(regionalSales)
      .where(
        regionalSales.totalSales.gt(
          db.select(sum(regionalSales.totalSales).divide(10)).from(regionalSales),
        ),
      ),
  ({ topRegions }) =&gt;
    db
      .select(
        db.orderLog.region,
        db.orderLog.product,
        sum(db.orderLog.quantity).as(`productUnits`),
        sum(db.orderLog.amount).as(`productSales`),
      )
      .from(db.orderLog)
      .where(db.orderLog.region.in(db.select(topRegions.region).from(topRegions)))
      .groupBy(db.orderLog.region, db.orderLog.product),
);</code></pre><figcaption>Example of a massive but type-safe query</figcaption></figure><p>The no-batteries-included part is a wink to Knex.js and hints at Mammoth’s opposing ideas. Knex.js supports many SQL dialects and bundles the approriate database drivers (as peer dependencies, yes). Mammoth, however, only supports one SQL dialect, Postgres, and bundles no database driver.</p><p>Creating a cross-database query builder like Knex.js is an amazing challenge, one that Knex.js set out to take on, but not me. To me, creating a cross-database query builder basically means constructing a new SQL dialect. For all the differences in the existing dialects you have to construct a new generic concept. But I like SQL. It's ubiquoutus and versatile. Especially Postgres. And this new language wouldn't be.</p><p>In Knex.js the INSERT INTO .. ON CONFLICT is nowhere to be found. This SQL clause is missing even though it's been released <a href="https://www.postgresql.org/docs/9.5/index.html">more than 4 years ago</a>. The problem? The contributors had to introduce a new concept and try to avoid anything database-specific. I think this is an example how hard it is to create this new cross-database language. Weighing the pros and cons without being database-specific. This challenge becomes clear in this <a href="https://github.com/knex/knex/pull/2197">pull request</a> discussing insert into on conflict.</p><p>An often touted benefit of a cross-database solution is to be able to easily switch between different databases. Not at runtime but if you later decide to migrate from one database to another. But a cross-database approach isn't the only option. Instead, I think, a multi-database solution is a good strategy when you're operating in a type-safe world. Where the former focusses on speaking to different databases using a single API, the latter offers a database-specific API, but type-safe, thus, multi. Meaning, you would still be able to switch between databases, and you would see breaking changes at compile time. Fix the errors and you can be confident you support the new database.</p><blockquote>Of course this ignores the whole topic of needing to actually migrate data from one database to another. This is why, in my opinion, you never really just switch from one database to another.</blockquote><p>Mammoth is sticking as close to SQL as possible. This comes with a set of challenges when building Mammoth, but it should make it easier to adopt Mammoth in a project or onboard new developers. I want a minimal abstraction, not a new generic SQL language, an ORM or something even more massive like Prisma. If you want to speak to your database, but it requires re-learning a lot you already know how to do in SQL, something is wrong. And all this re-learning is often not transferable to different languages or environment, which makes part of this learning wasteful.</p><p>As an alternative, there are amazing tools available which generate types by reading your queries and reading the remote database schema. While these do solve the type-safety challenges and stick to SQL, I feel requiring a watch on file changes so types can get re-generated isn't ideal. Instead, with an advanced enough type-safe query builder you can have the same features without this build step.</p><p>Mammoth aims to fix exactly that. Here are some examples that I think work great. All the result types are automatically inferred. </p><figure><pre><code>const rows = await db
    .select(db.foo.id, db.bar.name)
    .from(db.foo)
    .leftJoin(db.bar)
    .on(db.bar.fooId.eq(db.foo.id));</code></pre><figcaption>Left join — <code>name</code> automatically becomes optional</figcaption></figure><figure><pre><code>const [{count}] = await db.select(count()).from(db.foo);</code></pre><figcaption>Simple select with count(*)</figcaption></figure><figure><pre><code>const affectedCount = await db
  .insertInto(db.foo)
  .values({
    name: `Test`,
  })
  .onConflict(`id`)
  .doUpdateSet({
    name: `Test 2`,
  });</code></pre><figcaption>Insert into .. on conflict</figcaption></figure><figure><pre><code>const affectedCount = await db.update(db.foo).set({ name: `Test`, value: 123 });</code></pre><figcaption>Just an update returning the affected count</figcaption></figure><figure><pre><code>db
  .select(db.foo.id)
  .from(db.foo)
  .where(db.foo.id.in(db.select(db.bar.fooId).from(db.bar)));</code></pre><figcaption>Select with where in expression</figcaption></figure><p>Mammoth 1.0 is production-ready. I've been using it in a project for some time already. It's not feature-complete though but should support most use cases and give you automatic type safety in a lot of places. It also offers excellent autocomplete and Mammoth tries hard not to pullute the public API. The first version of the <a href="https://mammoth.tools/">Mammoth query builder documentation</a> is also up.</p><p>I created a couple of issues labeled with <em><a href="https://github.com/Ff00ff/mammoth/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22">good first issue</a>. </em>These issues are great for someone new to the codebase to pick up—and they really add value. I'm available to help you get started. Just claim the issue and let me know if you have any questions. If you always wanted to work on some open source, now is your time!</p><p>Last but no least, I started working on mammoth-cli to automatically generate migrations based on your table definitions. This is the next big piece to get right to make sure your database schema actually matches your table definitions. Also, this should make the developer experience of using Mammoth even better. <a href="https://github.com/Ff00ff/mammoth-cli">The first beta version is available now</a>.</p><p>Over &amp; out!</p><p>Martijn</p>
			</section></div>]]>
            </description>
            <link>https://nullbyt.es/a-new-typescript-postgres-query-builder/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24968888</guid>
            <pubDate>Mon, 02 Nov 2020 15:11:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell: The Good Parts]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24968676">thread link</a>) | @_query
<br/>
November 2, 2020 | https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55 | <a href="https://web.archive.org/web/*/https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>by Marc Scholten, 29.10.2020</em></p>

<p>
There’s been a recent blog post <a href="https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1" target="_blank"><q>Haskell: The Bad Parts</q></a> in the haskell community. To keep things in balance and to spread some positive vibes we should also talk about the good parts of the haskell programming language and it’s ecosystem.
</p>

<p>
Here are some of the best parts we encountered while using Haskell at digitally induced. We focus on the advantages in the web dev space because that is what we are currently working on.
</p>

<h2>Type Safety</h2>
<p>
Haskell has one of the most impressive type systems of any programming language in practical use. If you have used TypeScript or other type safe languages in the past, you should be aware of the great advantages of having a type-checked codebase. Now think TypeScript - but 10x better. That’s how Haskell feels like.
</p>

<p>
You save a lot of time debugging runtime errors. Once the compiler approved your code, you can be pretty sure that it is working. This kind of development process is usually a lot more fun than debugging why something is <code>null</code> or <code>undefined</code>.
</p>

<p>
Once your system has hit a certain size and when new feature requests are rolling in you will want to make changes and refactor some parts of your code base. With Haskell you feel empowered to make changes to any part of your codebase.
</p>

<p>
Compare this to the ruby ecosystem: When working with rails you usually need to have lots of tests or otherwise you cannot confidently refactor code after things are running in production. And even then things will break. With the power of the type safety provided by Haskell, we can make refactorings whenever we want.
</p>

<p>
It’s really a blessing.
</p>

<h2>Managed Side Effects</h2>
<p>The way you deal with the file system, external APIs and user input is way different in Haskell than in other less functional programming languages. Your program consists of a main routine that handles the side effects and calls all your pure functions that do the real business logic.</p>

<p>
Systems build this way scale really well because there are less moving parts. Additionally pure functions can be easily tested and changed later on.
</p>

<p>
Most other languages encourage you to do side effects in an unrestricted way. For example when working in Java, a call to an object method might indirectly change the state of many related objects. This means you cannot easily reason about what a method calls does. In Haskell most functions are pure and thus don't trigger side effects like this. And when they do you can see this already by the function's type signature.
</p>

<p>
Haskell forces you to manage your side effects in a more careful way. You can still do IO and have mutable state, you just need to make this explicit inside the type signature. This leads to a far more robust system in overall.
</p>

<h2>Performance</h2>
<p>
Out of the box the performance of Haskell based web applications is great. It just feels faster than your typical Rails or PHP application. Thanks to it’s highly optimized runtime system it can also <a href="https://www.yesodweb.com/blog/2011/03/preliminary-warp-cross-language-benchmarks" target="_blank">handle way more requests than a nodejs application</a>.
</p>

<p>
And you get all that without ever thinking about performance at all. 
</p>

<h2>Tooling</h2>
<p>In 2020 it’s finally good. Thanks to <a href="https://github.com/haskell/haskell-language-server" target="_blank">Haskell Language Server</a> there’s now an easy way to have type information, documentation on hover and smart refactorings inside your text editor.</p>

<p>
With nix, cabal and stack we have the best tools for managing Haskell dependencies. Cabal hell is a thing of the past.
</p>

<p>
Great things are also happening to the Haskell compiler itself. <a href="https://github.com/ghc-proposals/ghc-proposals/pull/282" target="_blank">We soon can write dot expressions as you know from most other programming languages:</a> <code>project.name</code> instead of <code>name project</code>.
</p>

<h2>Hiring Haskell Developers</h2>
<p>
Haskell is a secret super power in that regard. The Haskell community consists of many very smart and talented software engineers. Haskell developers usually learn about Haskell because they care about their craft and about building high quality software products instead of learning about it to get a high paying job. Exactly the kind of people you want in your team.
</p>

<h2>2020 Haskell is Ready for Prime Time</h2>
<p>
For years there has been this trend of growing use of type safety as well as the growing use of functional programming techniques. What language could fill this space better than Haskell. Haskell has really matured in the last years and in 2020 it feels like it’s finally ready to conquer the world.
</p>

<p>
If this post made you interested, <a href="https://ihp.digitallyinduced.com/" target="_blank">check out IHP, our batteries-included haskell web framework.</a>
</p></div></div>]]>
            </description>
            <link>https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55</link>
            <guid isPermaLink="false">hacker-news-small-sites-24968676</guid>
            <pubDate>Mon, 02 Nov 2020 14:49:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Going Faster Than TensorFlow on the GPU with Clojure (GTX 1080Ti)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24968394">thread link</a>) | @dragandj
<br/>
November 2, 2020 | https://dragan.rocks/articles/20/Going-faster-than-Tensorflow-on-GPU-with-Clojure | <a href="https://web.archive.org/web/*/https://dragan.rocks/articles/20/Going-faster-than-Tensorflow-on-GPU-with-Clojure">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
You can <a href="https://www.patreon.com/posts/22476035">adopt a pet function!</a>
Support my work <a href="https://patreon.com/draganrocks">on my Patreon page</a>, and access my <a href="https://www.patreon.com/posts/im-ditching-and-22476348">dedicated discussion server</a>. Can't afford to <a href="https://patreon.com/draganrocks">donate</a>? Ask for a free invite.
<p>November 2, 2020</p>
<p>
    Please share: .
</p>

<p>
    <a href="https://aiprobook.com/">New books are available for subscription.</a>
    </p><p><a href="https://aiprobook.com/deep-learning-for-programmers">
            <img src="http://aiprobook.com/img/dlfp-cover.png">
        </a>
        <a href="https://aiprobook.com/numerical-linear-algebra-for-programmers">
            <img src="http://aiprobook.com/img/lafp-cover.png">
        </a>
    </p>


<p>
A few weeks ago I've shown you how simple Clojure's
<a href="https://github.com/uncomplicate/deep-diamond">Deep Diamond</a>() is, even compared to Keras. I've also mentioned
that it's superfast. Here's how fast it is on the GPU!
</p>

<div id="outline-container-orgc0a2ae3">
<h2 id="orgc0a2ae3">TL;DR Much faster than Keras+TensorFlow on the GPU, too!</h2>
<div id="text-orgc0a2ae3">
<p>
In the <a href="https://dragan.rocks/articles/20/Going-faster-than-TensorFlow-with-Clojure">previous article</a>, we have only compared the libraries on the CPU.
Deep Diamond was considerably faster: 368 seconds vs 509 seconds. Most readers were intrigued,
but, being skeptical as they should be, they complained that CPU performance doesn't matter
anyway, since everybody uses GPU for training convolution networks;
let's do the GPU comparison then.
</p>

<p>
Both Deep Diamond, and Keras with TensorFlow, use <a href="https://developer.nvidia.com/cudnn">Nvidia's cuDNN</a> low level performance
library under the hood, and any difference is due to the higher-level implementation.
</p>

<p>
Deep Diamond completes this training in <b>21</b> seconds while Keras + TensorFlow takes <b>35</b> seconds.
The gap even increased in favor of Deep Diamond! Now the ratio is <b>1.67</b>, in place of 1.38 on the CPU.
</p>
</div>
</div>

<div id="outline-container-org0601d75">
<h2 id="org0601d75">Keras CNN in Python</h2>
<div id="text-org0601d75">
<p>
I repeat the relevant model code for reference. We're
interested in the running time of <code>model.fit</code>, with minimal verbosity,
for 12 epochs. I'm using Nvidia's GTX 1080Ti GPU. Keras code is taken from official Keras examples.
</p>

<div>
<pre>model = Sequential<span>()</span>
model.add<span>(</span>Conv2D<span>(</span>32, kernel_size=<span>(</span>3, 3<span>)</span>,
                 activation='relu',
                 input_shape=<span>(</span>28, 28, 1<span>)</span><span>)</span><span>)</span>
model.add<span>(</span>Conv2D<span>(</span>64, <span>(</span>3, 3<span>)</span>, activation='relu'<span>)</span><span>)</span>
model.add<span>(</span>MaxPooling2D<span>(</span>pool_size=<span>(</span>2, 2<span>)</span><span>)</span><span>)</span>
model.add<span>(</span>Dropout<span>(</span>0.25<span>)</span><span>)</span>
model.add<span>(</span>Flatten<span>()</span><span>)</span>
model.add<span>(</span>Dense<span>(</span>128, activation='relu'<span>)</span><span>)</span>
model.add<span>(</span>Dropout<span>(</span>0.5<span>)</span><span>)</span>
model.add<span>(</span>Dense<span>(</span>num_classes, activation='softmax'<span>)</span><span>)</span>

model.compile<span>(</span>loss=keras.losses.categorical_crossentropy,
              optimizer=Adam<span>(</span>learning_rate=0.01<span>)</span>,
              metrics=<span>[</span>'accuracy'<span>]</span><span>)</span>

s = time.time_ns<span>()</span>
model.fit<span>(</span>x_train, y_train,
          batch_size=128,
          verbose=2,
          epochs=12<span>)</span>
e = time.time_ns<span>()</span>
print<span>(</span><span>(</span>e-s<span>)</span>/<span>(</span>10**9<span>)</span>, <span>" seconds"</span><span>)</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-org7c1e24e">
<h2 id="org7c1e24e">Deep Diamond CNN in Clojure</h2>
<div id="text-org7c1e24e">
<p>
In Clojure, we're measuring the runtime of the <code>train</code> function.
</p>

<div>
<pre><span>(</span><span>defonce</span> <span>net-bp</span>
  <span>(</span>network <span>(</span>desc <span>[</span>128 1 28 28<span>]</span> <span>:float</span> <span>:nchw</span><span>)</span>
           <span>[</span><span>(</span>convo <span>[</span>32<span>]</span> <span>[</span>3 3<span>]</span> <span>:relu</span><span>)</span>
            <span>(</span>convo <span>[</span>64<span>]</span> <span>[</span>3 3<span>]</span> <span>:relu</span><span>)</span>
            <span>(</span>pooling <span>[</span>2 2<span>]</span> <span>:max</span><span>)</span>
            <span>(</span>dropout<span>)</span>
            <span>(</span>dense <span>[</span>128<span>]</span> <span>:relu</span><span>)</span>
            <span>(</span>dropout<span>)</span>
            <span>(</span>dense <span>[</span>10<span>]</span> <span>:softmax</span><span>)</span><span>]</span><span>)</span><span>)</span>

<span>(</span><span>defonce</span> <span>net</span> <span>(</span>init! <span>(</span>net-bp <span>:adam</span><span>)</span><span>)</span><span>)</span>

<span>(</span>time <span>(</span>train net train-images y-train <span>:crossentropy</span> 12 <span>[]</span><span>)</span><span>)</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-orgf9c6799">
<h2 id="orgf9c6799">The books</h2>
<div id="text-orgf9c6799">
<p>
The book <a href="https://aiprobook.com/deep-learning-for-programmers/">Deep Learning for Programmers: An Interactive Tutorial with
CUDA, OpenCL, DNNL, Java, and Clojure</a> teaches the nuts and bolts of neural networks and deep learning
by showing you how Deep Diamond is built, <b>from scratch</b>, in interactive sessions. Each line of code
can be executed and the results inspected in the plain Clojure REPL. The best way to master something is to build
it yourself!
</p>

<p>
It' simple. But fast and powerful!
</p>

<p>
Please subscribe, read the drafts, get the full book soon, and support my work on this free open source library.
</p>
</div>
</div>


    </article></div>]]>
            </description>
            <link>https://dragan.rocks/articles/20/Going-faster-than-Tensorflow-on-GPU-with-Clojure</link>
            <guid isPermaLink="false">hacker-news-small-sites-24968394</guid>
            <pubDate>Mon, 02 Nov 2020 14:25:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Better Done Than Perfect Podcast]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24968318">thread link</a>) | @daolf
<br/>
November 2, 2020 | https://userlist.com/podcast/ | <a href="https://web.archive.org/web/*/https://userlist.com/podcast/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
<section>  <div>
    <div>
      

      <p>Welcome to Better Done Than Perfect — a podcast for SaaS founders and product people. In the first season we talk about user onboarding with fellow founders and guest experts.</p>

        


      
    </div>

    <p><img src="https://d33wubrfki0l68.cloudfront.net/0ed65308e1a87711e359afe19086b4c54ad8a837/f507a/assets/better-done-than-perfect-logo.png" alt="Better Done Than Perfect" title="Better Done Than Perfect">
    </p>
  </div>
</section>
<section>  <div id="episodes">
    <h2>Latest episodes 🎙</h2>

    <p>
      This season is dedicated to user onboarding. Tune in to hear real-life stories from seasoned SaaS founders and SaaS Experts.
    </p>

    <div>
        <article>
    <a href="https://userlist.com/podcast/jtbd-for-user-onboarding-with-ramli-john/"><img src="https://d33wubrfki0l68.cloudfront.net/7b6e78b825cad84c106aedfabe001c762f7ea595/109a3/assets/bdtp_ramli_john.png" alt="JTBD for User Onboarding with Ramli John" title="JTBD for User Onboarding with Ramli John"></a>

  <h3><a href="https://userlist.com/podcast/jtbd-for-user-onboarding-with-ramli-john/">JTBD for User Onboarding with Ramli John</a></h3>
  <p>You’ll hear about Ramli’s EUREKA user onboarding framework based on Jobs to Be Done, as well as his insights on segmentation, minimizing friction, success metrics, analytic tools, and more.</p>

  <a href="https://userlist.com/podcast/jtbd-for-user-onboarding-with-ramli-john/">View episode</a>
</article>

        <article>
    <a href="https://userlist.com/podcast/carrots-sticks-measuring-success-with-adii-pienaar/"><img src="https://d33wubrfki0l68.cloudfront.net/3a05d1826dd0958a0766b901ae417483e916faee/252d4/assets/bdtp_adii_pienaar.png" alt="Carrots, Sticks &amp; Measuring Success with Adii Pienaar" title="Carrots, Sticks &amp; Measuring Success with Adii Pienaar"></a>

  <h3><a href="https://userlist.com/podcast/carrots-sticks-measuring-success-with-adii-pienaar/">Carrots, Sticks &amp; Measuring Success with Adii Pienaar</a></h3>
  <p>You’ll hear about Adii’s successes and failures in user onboarding, as well as his views on email marketing, task simplification, concierge onboarding, success metrics, segmentation, and much more.
</p>

  <a href="https://userlist.com/podcast/carrots-sticks-measuring-success-with-adii-pienaar/">View episode</a>
</article>

        <article>
    <a href="https://userlist.com/podcast/value-paths-fireballs-with-samuel-hulick/"><img src="https://d33wubrfki0l68.cloudfront.net/1834ebc7385231ed1ace6e4ed3c9459f2137b586/0fdeb/assets/bdtp-samuel-hulick.png" alt="Value Paths &amp; Fireballs with Samuel Hulick" title="Value Paths &amp; Fireballs with Samuel Hulick"></a>

  <h3><a href="https://userlist.com/podcast/value-paths-fireballs-with-samuel-hulick/">Value Paths &amp; Fireballs with Samuel Hulick</a></h3>
  <p>You'll learn Samuel's take on the "ideal" user onboarding experience, as well as his Mario-fireball concept, Value Paths, success metrics, Jobs to Be Done, segmentation, and his invaluable advice for SaaS founders.
</p>

  <a href="https://userlist.com/podcast/value-paths-fireballs-with-samuel-hulick/">View episode</a>
</article>

    </div>

    
  </div>
</section>

        <section>  <div>
    <p><img src="https://d33wubrfki0l68.cloudfront.net/9eae0f5cf8899eef3658e01546feeb73cd36b556/eccac/assets/better-done-than-perfect-tshirt.png" lazy="true" width="426" alt="">
    </p>

    <div>
        <h2>Subscribe to win your free shirt</h2>

        <p>Join our mailing list below, learn about new episodes as they go live, and win one of our custom-designed shirts from Cotton Bureau.</p>

      

    </div>
  </div>
</section>

  </div></div>]]>
            </description>
            <link>https://userlist.com/podcast/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24968318</guid>
            <pubDate>Mon, 02 Nov 2020 14:18:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cellular immunity to SARS-CoV2 found at 6 months in non-hospitalised individuals]]>
            </title>
            <description>
<![CDATA[
Score 177 | Comments 132 (<a href="https://news.ycombinator.com/item?id=24968034">thread link</a>) | @ageitgey
<br/>
November 2, 2020 | https://www.uk-cic.org/news/cellular-immunity-sars-cov-2-found-six-months-non-hospitalised-individuals | <a href="https://web.archive.org/web/*/https://www.uk-cic.org/news/cellular-immunity-sars-cov-2-found-six-months-non-hospitalised-individuals">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img alt="UK-CIC logo" data-entity-type="file" data-entity-uuid="8a702f0f-0ed4-43c4-b10a-d98dba34a018" src="https://www.uk-cic.org/sites/default/files/inline-images/UK-CIC%20logo%20square%20300pix.jpg">Cellular (T cell) immunity against SARS-CoV-2 is likely to be present within most adults six months after primary infection, a new pre-print on bioRxiv suggests. The research from the UK Coronavirus Immunology Consortium (UK-CIC), Public Health England and Manchester University NHS Foundation Trust&nbsp;demonstrates robust T cell responses to SARS-CoV-2 virus peptides at this timepoint in all participants following asymptomatic or mild/moderate COVID-19 infection.</p>

<p>A key question is whether previous infection with SARS-CoV-2 results in immunity to reinfection, and if so for how long. The immune system is extremely complex and there are many different potential routes whereby it can generate immunity to a disease post-infection. This study examines the role of T cells in contributing to immunity against SARS-CoV-2 at six months post infection.</p>

<p>As part of UK-CIC, researchers from the University of Birmingham, Public Health England, Manchester University NHS Foundation Trust (MFT) and&nbsp;NIHR Manchester Clinical Research Facility collected serum and blood samples from a cohort of more than 2,000 clinical and non-clinical healthcare workers including 100 individuals who tested sero-positive for SARS-CoV-2 in March/April 2020 (average age 41 (range 22–65); 23 men, 77 women). All 100 individuals experienced either mild/moderate symptoms or were asymptomatic (56 versus 44 people) and none were hospitalised for COVID-19. Serum samples were collected monthly to measure antibody levels, and blood samples were taken after six months to assess the cellular (T cell) response. A range of analyses were carried out to assess different aspects of the T cell response including the magnitude of response and the response to different proteins from SARS-CoV-2. Carrying out these cellular analyses is much more complex than antibody studies – but this study of 100 individuals is one of the largest in the world to date in this field.</p>

<p>T cell responses were present in all individuals at six months after SARS-CoV-2 infection. The cellular immune response was directed against a range of proteins from the virus, including the Spike protein that is being used in most vaccine studies. However, comparable immunity was present against additional proteins, such as nucleoprotein, which suggests that these may be of value for incorporation in future vaccine protocols. This indicates that a robust cellular memory against the virus persists for at least six months.</p>

<p>The size of T cell response differed between individuals, being considerably (50%) higher in people who had experienced symptomatic disease at the time of infection six months previously. Further research will be needed to determine the significance of this finding. It is possible that heightened cellular immunity might provide increased protection against re-infection in people with initial symptomatic infection, or that asymptomatic individuals are simply able to fight off the virus without the need to generate a large immune response.</p>

<p>Antibodies are also a crucial component of immune defence and cellular immunity was strongly correlated with the peak level of the antibody response. Furthermore, larger cellular responses appeared to protect against antibody ‘waning’ over time, again suggesting the need to ensure that cellular immune responses are elicited in vaccine regimens.</p>

<p>Overall, these findings indicate a robust cellular (T cell) immune response against SARS-CoV-2 at six months post-infection. These findings will feed not only into our understanding of how immunity to SARS-CoV-2 works but also help inform future vaccine strategies. Further research is now needed to assess whether this immune response is maintained over the longer term and to better understand how strength of cellular immune response corresponds to likelihood of reinfection.</p>



<p><b>Professor Paul Moss, UK Coronavirus Immunology Consortium lead from University of Birmingham, said:</b></p>

<blockquote>
<p>“Understanding what constitutes effective immunity to SARS-CoV-2 is extremely important, both to allow us to understand how susceptible individuals are to reinfection and to help us develop more effective COVID-19 vaccines.</p>

<p>“To our knowledge, our study is the first in the world to show robust cellular immunity remains at six months after infection in individuals who experienced either mild/moderate or asymptomatic COVID-19. Interestingly, we found that cellular immunity is stronger at this time point in those people who had symptomatic infection compared with asymptomatic cases. We now need more research to find out if symptomatic individuals are better protected against reinfection in the future.</p>

<p>“Our knowledge of SARS-CoV-2 infection is increasing all the time. While our findings cause us to be cautiously optimistic about the strength and length of immunity generated after SARS-CoV-2 infection, this is just one piece of the puzzle. There is still a lot for us learn before we have a full understanding of how immunity to COVID-19 works. While we increase our understanding, whether we think we have previously had COVID-19 or not, we all should still follow Government guidelines on social distancing to ensure we play our part in minimising the spread of COVID-19 within our communities.”</p>
</blockquote>



<p><b>Dr Shamez Ladhani, Consultant epidemiologist at Public Health England and the study’s author, said:</b></p>

<blockquote>
<p>“Cellular immunity is a complex but potentially very significant piece of the COVID-19 puzzle, and it’s important that more research be done in this area. However, early results show that T-cell responses may outlast the initial antibody response, which could have a significant impact on COVID vaccine development and immunity research.</p>

<p>“Our thanks go to the more than 2,000 staff who have volunteered to provide monthly blood samples since the beginning of the pandemic. Recruiting donors so early in 2020 allowed us significantly longer follow-up than many similar studies have achieved so far.”</p>


</blockquote>

<p><b>Professor Fiona Watt, Executive Chair of the Medical Research Council, part of UKRI, said: </b></p>

<blockquote>
<p>“This study shows the benefit of funding world-leading immunologists through the UK Coronavirus Immunology Consortium. Researchers investigated whether previous infection with SARS-CoV-2 results in immunity to reinfection. They found that a robust cellular memory against the virus persists for at least six months. This is promising news – if natural infection with the virus can elicit a robust T cell response then this may mean that a vaccine could do the same.”</p>
</blockquote>



<p><strong>Dr Shazaad Ahmad, Consultant Virologist at Manchester University NHS Foundation Trust (MFT) and Principal Investigator for the study at MFT, said:&nbsp;</strong></p>

<blockquote>
<p>“As one of the leading NHS trusts for research and innovation, known for our strong track record of recruiting to studies, we were selected to rapidly enlist a cohort of healthcare workers to take part in this important research – and 1,200 MFT staff swiftly answered the call.</p>

<p>“The study was delivered at the NIHR Manchester Clinical Research Facilities at Manchester Royal Infirmary and Wythenshawe Hospital (both part of MFT), which provide dedicated research space and highly-trained staff. I would like to say how grateful I am to my colleagues for continuing to deliver and participate in this study, as without them we would not be able to report the findings, which could have a huge global impact."<br>
&nbsp;</p>


</blockquote>

<p>Please note, this paper is a pre-print reporting preliminary data that has not yet been peer-reviewed.</p>

<p>----------Ends----------</p>

<p><u><strong>Notes for editors</strong></u><br>
This press release reports on findings in the following pre-print which is <a href="http://biorxiv.org/cgi/content/short/2020.11.01.362319">available to read on bioRxiv</a>:<br>
Zuo <em>et al. </em>2020 Robust SARS-CoV-2-specific T-cell immunity is maintained at 6 months following primary infection<br>
Journalists - please contact the press team for a copy of the preprint, or use the link above to find it directly.&nbsp;</p>

<p>The UK Coronavirus Immunology Consortium brings together UK 19 immunology centres of excellence to research how the immune system interacts with SARS-CoV-2 to help us improve patient care and develop better diagnostics, treatments and vaccines against COVID-19. It is jointly funded by UK Research and Innovation (UKRI) and National Institute for Health Research (NIHR) and supported by the British Society for Immunology.<br>
Website: <a href="https://www.uk-cic.org/news/www.uk-cic.org">www.uk-cic.org</a>&nbsp;<br>
Twitter: <a href="https://www.uk-cic.org/news/www.twitter.com/UKCICstudy">@UKCICstudy</a><br>
Email: <a href="mailto:uk-cic@immunology.org">uk-cic@immunology.org</a></p>

<p><strong>Press contacts</strong><br>
Gabriela De Sousa<br>
Email: <a href="mailto:g.desousa@immunology.org%C2%A0">g.desousa@immunology.org&nbsp;</a><br>
Jennie Evans<br>
Tel: 07703 807 444<br>
Email: <a href="mailto:j.evans@immunology.org">j.evans@immunology.org</a></p>
</div></div>]]>
            </description>
            <link>https://www.uk-cic.org/news/cellular-immunity-sars-cov-2-found-six-months-non-hospitalised-individuals</link>
            <guid isPermaLink="false">hacker-news-small-sites-24968034</guid>
            <pubDate>Mon, 02 Nov 2020 13:45:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comprehensive Guide to Lcevc (MPEG5 Part2) LowComplexity Enhancement VideoCoding]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24968007">thread link</a>) | @ponderingfish
<br/>
November 2, 2020 | https://ottverse.com/lcevc-mpeg5-part2-low-complexity-enhancement-video-coding-guide/ | <a href="https://web.archive.org/web/*/https://ottverse.com/lcevc-mpeg5-part2-low-complexity-enhancement-video-coding-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure>
<img src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc_mpeg5-part2.png?resize=678%2C381&amp;ssl=1" alt="lcevc mpeg5 part2 vnova" title="lcevc_mpeg5-part2" data-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc_mpeg5-part2.png?resize=678%2C381&amp;ssl=1" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
</figure>


<p><strong>The LCEVC Codec (MPEG-5 Part 2) or “Low Complexity Enhancement Video Coding” is one of the three new codecs being introduced by MPEG (others being Versatile Video Coding (VVC) and Essential Video Coding (EVC)) with the aim of increased compression efficiency for existing codecs at little to no increase in coding complexity by the use of a base bitstream and an enhancement bitstream.</strong></p>



<p>In&nbsp;<a href="https://www.itu.int/en/ITU-T/Workshops-and-Seminars/20191008/Documents/Guido_Meardi_Presentation.pdf" target="_blank" rel="noopener">this excellent presentation</a>&nbsp;at the ITU Workshop on the Future of Media in Geneva, Guido Meardi who is the CEO &amp; Co-Founder of&nbsp;<a href="https://www.v-nova.com/" target="_blank" rel="noopener">V-Nova</a>&nbsp;gave a detailed introduction to the LCEVC codec. And, he referred to LCEVC (MPEG-5 Part 2) as “a codec to improve other codecs” – which is actually quite true! For those who don’t know, V-Nova has been instrumental in driving the LCEVC standard through their research and work on the Perseus codec. More information on that&nbsp;<a href="https://www.v-nova.com/v-nova-video-compression-technology/" target="_blank" rel="noopener">here</a>.</p>



<p>In this article, let’s take a look at</p>



<ul><li>the “why” and “what” behind the LCEVC codec standardization</li><li>how the encoder and decoder work</li><li>theoritical complexity considerations</li><li>possible applications of the LCEVC codec</li></ul>




<h2 id="what-is-the-lcevc-codec-mpeg-5-part-2"><span id="What_is_the_LCEVC_Codec_(MPEG5_Part_2)"></span>What is the LCEVC Codec (MPEG-5 Part 2)?<span></span></h2>



<p>The LCEVC codec (Low Complexity Enhancement Video Coding) aims at being&nbsp;<strong>“a codec to improve other codecs”</strong>&nbsp;at a low complexity overhead. The LCEVC codec’s output is a combination of a “base bitstream” produced by an existing video codec such as AVC, HEVC, VP9, AV1, etc. along with enhancement layers that can be used conditionally to improve the quality of the video.</p>



<p>If the decoder/end-device supports LCEVC, the enhancement layers are decoded, else, the base codec alone is used to decode the bitstream and the video is rendered to the user. This ensures backward-compatibility and encourages roll-out of the LCEVC codec without the fear of breaking the end-user’s experience.</p>



<p>This concept is nicely captured in the figure below (taken from Guido Meardi’s Presentation at Geneva).</p>



<figure><img data-attachment-id="121" data-permalink="https://ottverse.com/lcevc-architecture-min/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-architecture-min.png?fit=800%2C294&amp;ssl=1" data-orig-size="800,294" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lcevc-architecture-min" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-architecture-min.png?fit=300%2C110&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-architecture-min.png?fit=800%2C294&amp;ssl=1" loading="lazy" width="800" height="294" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-architecture-min.png?resize=800%2C294&amp;is-pending-load=1#038;ssl=1" alt="lcevc ffmpeg v-nova" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-architecture-min.png?w=800&amp;ssl=1 800w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-architecture-min.png?resize=300%2C110&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-architecture-min.png?resize=768%2C282&amp;ssl=1 768w" data-lazy-sizes="(max-width: 800px) 100vw, 800px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-architecture-min.png?resize=800%2C294&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Architecture Diagram from Guido Meardi’s Presentation at Geneva</figcaption></figure>



<p>In the next few articles of our series on the LCEVC codec, let’s learn how to produce an LCEVC bitstream using FFmpeg, and dive more into the details of the filters used in LCEVC.</p>



<p>Without further ado, let’s get started, shall we?</p>



<h2 id="key-requirements-of-the-lcevc-codec"><span id="Key_Requirements_of_the_LCEVC_Codec"></span>Key Requirements of the LCEVC Codec<span></span></h2>



<p>The key requirements for the LCEVC project&nbsp;<a href="https://mpeg.chiariglione.org/standards/exploration/low-complexity-video-coding-enhancements/requirements-low-complexity-video" target="_blank" rel="noopener">were specified by MPEG</a>&nbsp;and here is a summary –</p>



<ul><li>when enhancing an n-th generation MPEG codec (e.g., AVC), the compression efficiency for the aggregate stream is appreciably higher than that of the n-th generation MPEG codec used at full resolution and as close as possible to that of the (n+1)-th generation MPEG codec (e.g., HEVC) used at full resolution, at bandwidths and operating conditions relevant to mass market distribution;</li><li>encoding and decoding complexity for the aggregate full resolution video (i.e., base plus enhancement) shall be comparable with that of the base encoder or decoder, respectively, when used alone at full resolution.</li></ul>



<p>In simpler terms, the aims of the LCEVC codec are –</p>



<ul><li>when the base codec is AVC for example, then the compression efficiency when using LCEVC (base and enhancement layers) should be higher than just using AVC to encode the full resolution video (else, what is the point of a new codec, right?)</li><li>when the base codec is AVC for example, then the complexity (both encoding and decoding) of the LCEVC codec should be comparable with the base codec’s complexity for encoding the full resolution video. In other words, LCEVC should not dramatically increase the complexity of the encoder/decoder for compression gains – if it did, it wouldn’t be low complexity, now would it?</li></ul>



<p>Further more, the&nbsp;<a href="https://mpeg.chiariglione.org/standards/exploration/low-complexity-video-coding-enhancements/requirements-low-complexity-video" target="_blank" rel="noopener">MPEG document</a>&nbsp;also talks about the “key implementation and non-technical requirements” and they are:-</p>



<ul><li>the video stream should be decodable without specific firmware or OS support by all devices capable to decode the base codec, with substantially same resource utilization (e.g., processing power, battery consumption, etc.) as the base decoder at full resolution decoded in hardware;</li><li>all web browsers should be able to decode high resolution video without plug-ins and/or browser upgrade, e.g. via HTML5 javascript;</li><li>the additional data stream should be compatible with the existing ecosystem, e.g. ad insertion, metadata management, CDNs, DRM/CA and network protocols such as DASH, HLS, MMT and SS;</li><li>the overall processing power requirement to encode a video stream should be comparable with that of the base codec when used alone at full resolution.</li></ul>



<p>All good! Ultimately, the aims of the LCEVC codec are to</p>



<ul><li>improve the compression efficiency of any other codec with little or no increase in coding complexity.</li><li>be backward compatible so that legacy devices and software can decode the bitstreams from the base codec if they do not have support for the LCEVC codec’s enhancement layers.</li></ul>



<p>With this understanding, let’s now dive into the architectural details of the LCEVC codec’s Encoder and Decoder.</p>



<h2 id="architecture-of-the-lcevc-mpeg-5-part-2-codec"><span id="Architecture_of_the_LCEVC_(MPEG5_Part_2)_Codec"></span>Architecture of the LCEVC (MPEG-5 Part 2) Codec<span></span></h2>



<h3 id="encoder"><span id="Encoder"></span>Encoder<span></span></h3>



<p>To understand the inner-workings of the LCEVC Encoder, let’s take a look at the block diagram from a&nbsp;<a href="https://www.itu.int/dms_pub/itu-s/opb/journal/S-JOURNAL-ICTS.V3I1-2020-12-PDF-E.pdf" target="_blank" rel="noopener">paper published in the ITU Journal</a>&nbsp;(<em>please take some time and read this – it has a good explanation of the LCEVC codec.</em>)</p>



<figure><img data-attachment-id="123" data-permalink="https://ottverse.com/lcevc-encoder/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-encoder.png?fit=800%2C447&amp;ssl=1" data-orig-size="800,447" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lcevc-encoder" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-encoder.png?fit=300%2C168&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-encoder.png?fit=800%2C447&amp;ssl=1" loading="lazy" width="800" height="447" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-encoder.png?resize=800%2C447&amp;is-pending-load=1#038;ssl=1" alt="lcevc ffmpeg v-nova" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-encoder.png?w=800&amp;ssl=1 800w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-encoder.png?resize=300%2C168&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-encoder.png?resize=768%2C429&amp;ssl=1 768w" data-lazy-sizes="(max-width: 800px) 100vw, 800px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-encoder.png?resize=800%2C447&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>LCEVC Encoder Block Diagram (ITU Journal Paper on LCEVC [Link in the References])</figcaption></figure>



<p>The&nbsp;<a href="https://www.itu.int/dms_pub/itu-s/opb/journal/S-JOURNAL-ICTS.V3I1-2020-12-PDF-E.pdf" target="_blank" rel="noopener">block diagram above</a>&nbsp;gives a very clear picture of the encoding process of the LCEVC codec and here is how it works –</p>



<ol><li><strong>Downsampling:</strong>&nbsp;There are two downsampler blocks that receive the full-resolution image as the input and produce two downsampled images (one each at the output of the first and second stage downsampling respectively).</li><li><strong>Compressing using the base codec</strong>: The base encoder takes the output of the second-stage downsampler and compresses it using a “base codec” which can be anything you choose (AVC, HEVC, AV1, VP9, etc.).</li><li><strong>Upsample and Compress at Level L1</strong><ol><li>Next, the base-image (downsampled two times) is upsampled once.</li><li>A difference image is computed using the upsampled image and the output of the first stage downsampler.</li><li>The difference image goes through transform, quantization, and entropy coding and the final output is transmitted as the “L1-Coefficient Layer”.</li></ol></li><li><strong>Prepare the Input for the L2 Stage</strong>: The encoded output of the L1 stage is reconstructed and then it is upsampled to produced a reconstructed image of the original resolution (because it has been upsampled two times now).</li><li><strong>Compression at Level L2</strong><ol><li>At level L2, you have the (1) original image and (2) the reconstructed image (<em>that started its life at the base layer</em>).</li><li>The difference of these two images is computed and then compressed to produce the L2 Coefficient Layers.</li><li>Optionally, temporal prediction can be performed and the resultant prediction coefficients can be compressed and transmitted to the end-device.</li></ol></li><li><strong>Encoding sparsely populated images</strong>: this is a huge technical challenge because the Discrete Cosine Transform (DCT) was designed to take advantage of spatial correlation between pixels. The LCEVC codec has worked around this problem by introducing small transform kernels (2×2 and 4×4) to avoid trying to compress large blocks of information.</li><li><strong>Entropy Coding of the Enhancement Layer Coefficients</strong>: Considering that the information is quite sparse to begin with and the use of small 2×2 and 4×4 kernels, the authors of LCEVC decided to use a Run Length Encoder (RLE) and a Prefix Coding Encoder. A Run-Length Encoder is a very simple method of entropy coding and has been used successfully in the past as the basis of CAVLC (H.264/AVC).</li><li><strong>Temporal prediction</strong>&nbsp;between the original full resolution image and the reconstructed full-resolution image. This results in the Layer 2 Enhancement Coefficients and the encoded Prediction Vectors.</li></ol>



<p><strong>Note:</strong>&nbsp;Using large transform kernels to compress sparse information is a bad idea e.g., if you have a 32×32 DCT applied on a 32×32 macroblock that is filled with mostly black pixels with 20 white pixels randomly distributed (2% white) and you decide to use DCT on it, its a safe bet that those white pixels will get lost during the DCT &amp; quantization process. This might be fine for normal image compression, but, when you are trying to compress “difference” images, then preserving sparse regions is very important.</p>



<p><strong>Note:</strong>&nbsp;The details of the transform kernels, upsampling and downsampling filters are too complex for this introductory article on LCEVC and will be covered in a future article in this series.&nbsp;<a href="https://ottverse.com/subscribe">Subscribe</a>&nbsp;to get notified of these articles directly in your inbox.</p>



<h3 id="decoder"><span id="Decoder"></span>Decoder<span></span></h3>



<p>Here is the&nbsp;<a href="https://www.itu.int/dms_pub/itu-s/opb/journal/S-JOURNAL-ICTS.V3I1-2020-12-PDF-E.pdf" target="_blank" rel="noopener">block diagram of the LCEVC codec’s decoder</a>&nbsp;from the ITU Journal publication. We won’t dive into it in detail because the decoder does the opposite of what the encoder does and the block diagram explains this process very well.</p>



<figure><img data-attachment-id="122" data-permalink="https://ottverse.com/lcevc-decoder/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-decoder.png?fit=800%2C408&amp;ssl=1" data-orig-size="800,408" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lcevc-decoder" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-decoder.png?fit=300%2C153&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-decoder.png?fit=800%2C408&amp;ssl=1" loading="lazy" width="800" height="408" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-decoder.png?resize=800%2C408&amp;is-pending-load=1#038;ssl=1" alt="lcevc ffmpeg v-nova" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-decoder.png?w=800&amp;ssl=1 800w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-decoder.png?resize=300%2C153&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-decoder.png?resize=768%2C392&amp;ssl=1 768w" data-lazy-sizes="(max-width: 800px) 100vw, 800px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-decoder.png?resize=800%2C408&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>LCEVC Decoder Block Diagram (ITU Journal Paper on LCEVC [Link in the References])</figcaption></figure>



<p>Rather, let’s take a look at the image below that shows the LCEVC decoding process (<a href="https://www.itu.int/en/ITU-T/Workshops-and-Seminars/20191008/Documents/Guido_Meardi_Presentation.pdf" target="_blank" rel="noopener">taken from this presentation</a>). It provides an intuitive understanding of how the LCEVC decoder works.</p>



<div><figure><img data-attachment-id="124" data-permalink="https://ottverse.com/lcevc-layers-video-coding/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?fit=800%2C354&amp;ssl=1" data-orig-size="800,354" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lcevc-layers-video-coding" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?fit=300%2C133&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?fit=800%2C354&amp;ssl=1" loading="lazy" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?resize=625%2C276&amp;is-pending-load=1#038;ssl=1" alt="lcevc mpeg5 part2" width="625" height="276" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?w=800&amp;ssl=1 800w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?resize=300%2C133&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?resize=768%2C340&amp;ssl=1 768w" data-lazy-sizes="(max-width: 625px) 100vw, 625px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?resize=625%2C276&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>A Great Visual Representation of How LCEVC Works</figcaption></figure></div>



<p>Here’s what is happening –</p>



<ul><li>The decoder get a small image as its initial input and upsamples it to produce the “Preliminary Intermediate Picture”</li><li>Then, the first Enhancement SubLayer is added to the Preliminary Intermediate Picture to produce the Combined Intermediate Picture. So, now, we have completed the first stage of decoding.</li><li>The “Combined Intermediate Picture” is upsampled to produce the “Preliminary Output Picture” – now this image is at full resolution.</li><li>Finally, the second Enhancement SubLayer is added to the Preliminary Output Picture to produce the Combined Output Picture. Optionally, if any temporal prediction exists in the Enhancement Layers, then that is combined to produce the final output picture.</li></ul>



<p>What is important to note however, is that,&nbsp;<strong>the output of the base codec is sent through two upsampling stages to produce the full resolution image</strong>. In the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ottverse.com/lcevc-mpeg5-part2-low-complexity-enhancement-video-coding-guide/">https://ottverse.com/lcevc-mpeg5-part2-low-complexity-enhancement-video-coding-guide/</a></em></p>]]>
            </description>
            <link>https://ottverse.com/lcevc-mpeg5-part2-low-complexity-enhancement-video-coding-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24968007</guid>
            <pubDate>Mon, 02 Nov 2020 13:41:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Little Snitch 5.0 is out]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24967796">thread link</a>) | @noja
<br/>
November 2, 2020 | https://www.obdev.at/products/littlesnitch/releasenotes.html | <a href="https://web.archive.org/web/*/https://www.obdev.at/products/littlesnitch/releasenotes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>



<section>
<div id="version-6142">
<p><span>November 2, 2020</span></p>
<div>
<h3 id="first-releasenotes-headline">Little Snitch 5.0 <span>(6142)</span></h3>
<div>
<h4>What’s new in Little Snitch 5?</h4>
<p>There has been quite a bit of public discussion recently about the deprecation of various types of kernel extension on macOS. Among them are Network Kernel Extensions (NKEs). You probably did not care so far, but Little Snitch 4 was based on an NKE to do its job. Since NKEs are now deprecated and no longer officially supported by Apple, we have spent the last year rewriting the core of Little Snitch to the Network Extension (NE) framework. While working on this core, we took the chance to revise some old design decisions and add some long anticipated features.</p>
<h4>So what are the benefits of the new version?</h4>
<ul>
<li>Compatibile with (and requires) macOS Big Sur.</li>
<li>Future-proof, because it is based on the new Network Extension and Endpoint Security frameworks.</li>
<li>Drag and Drop installation and upgrade, no reboot required.</li>
<li>Universal Binary which runs on both Intel and Apple Silicon Macs.</li>
<li>Little Snitch now comes with a command line interface for preferences editing, configuration import and export, debugging, logging and access to traffic history.</li>
<li>The time range available in Network Monitor’s traffic diagram has been extended from one hour to up to a year.</li>
<li>Rules can now specify a list of port numbers, not just one contiguous range as before.</li>
<li>The export format for backups is human readable normalized JSON.</li>
<li>Recording of network statistics is done independently of Network Monitor. You can quit Network Monitor and still have statistics recorded.</li>
<li>Live traffic logs via command line tool.</li>
<li>Ready for mass deployment installation in corporate environments.</li>
</ul>
<h4>Upgrade pricing</h4>
<p>If you have purchased Little Snitch 4 after November 1, 2019, you can upgrade to Little Snitch 5 for free – just use your existing license key. If you purchased Little Snitch 4 before that period, you can get the upgrade at a reduced price.</p>
</div></div></div>
<div id="version-6140">
<p><span>October 28, 2020</span></p>
<div>
<h3>Little Snitch 5 Beta 2 <span>(6140)</span></h3>
<div>
<h4>Improvements and new features</h4>
<ul>
<li>Optionally control access to <code>/dev/bpf</code> devices (Berkeley Packet Filter). These devices can be used to send and receive data with arbitrary network protocols. Requires installation of an Endpoint Security module in Little Snitch &gt; Preferences &gt; Advanced.</li>
</ul>
<h4>Bug Fixes</h4>
<ul>
<li>Improved recovery when reading broken configuration files.</li>
<li>Fixed a memory leak in the Little Snitch Network Extension.</li>
<li>Numerous other bug fixes.</li>
</ul>
</div></div></div>
<div id="version-6136">
<p><span>October 16, 2020</span></p>
<div>
<h3>Little Snitch 5 Beta 1 <span>(6136)</span></h3>
<div>
<h4>Improvements and new features</h4>
<ul>
<li>Lots of user interface refinements to match the new look of macOS Big Sur.</li>
<li>Rules can now be created for a list of port ranges, not just a single range.</li>
<li>Added command line interface for accessing connection history and traffic log data.</li>
<li>The traffic diagram in Network monitor can now display traffic data from up to one year (compared to the previous 1 hour).</li>
<li>The menu for selecting the time period that’s displayed by Network Monitor has been moved from the Filter menu in the search field to View menu in the menu bar.</li>
<li>Various performance improvements.</li>
</ul>
<h4>Bug Fixes</h4>
<ul>
<li>Fixed a bug where a connection alert would not go away after clicking allow or deny.</li>
<li>Fixed various crashes of Network Monitor.</li>
<li>Fixed a bug where Little Snitch complained about a code modification although the process was not modified.</li>
<li>Reduced the number of cases where connection alerts for Internet addresses instead of server names were shown.</li>
<li>Lots of other minor bug fixes.</li>
</ul>
</div></div></div>
<div id="version-6130">
<p><span>September 21, 2020</span></p>
<div>
<h3>Little Snitch Technology Preview <span>(6130)</span></h3>
<div>
<ul>
<li>Improved notification handling. All notifications are now generated by one single component (the “Little Snitch Agent”), which reduces the number of alerts shown by macOS for allowing the display of these notifications.</li>
<li>Code identity checks now provide information about a developer’s name, and not just the developer’s team identifier.</li>
<li>Improved information shown when the code signature of a process became invalid because a library with missing code signature was loaded.</li>
<li>Improved debug logging. Little Snitch no longer writes log messages to individual log files but uses the logging facilities of macOS.</li>
<li>Added a command line API for accessing log messages related to Little Snitch.</li>
<li>Removed menu items responsible for Network Monitor snapshots because snapshots are no longer available.</li>
<li>Fixed possible crashes when importing backups.</li>
<li>Various bug fixes and improvements.</li>
</ul>
</div></div></div>
<div id="version-6128">
<p><span>September 15, 2020</span></p>
<div>
<h3>Little Snitch Technology Preview <span>(6128)</span></h3>
<div>
<ul>
<li>This release brings back “Automatic Profile Switching”. Profiles can now be automatically activated when a network is joined.</li>
<li>Little Snitch is now scriptable. The app package contains a command line utility at <code>Contents/Components/littlesnitch</code> which can be used to control Little Snitch from scripts or via Terminal. Scriptability must be enabled in Little Snitch’s Security Preferences.</li>
<li>Improved detection of a remote computer’s domain name for connection alerts and for display in Network Monitor.</li>
<li>The debug interface for activation and deactivation of components is now password protected.</li>
<li>Various bug fixes and improvements.</li>
</ul>
</div></div></div>
<div id="version-6121">
<p><span>August 20, 2020</span></p>
<div>
<h3>Little Snitch Technology Preview <span>(6121)</span></h3>
<div>
<p><strong>This is a hotfix for a bug in macOS Big Sur Beta 5! Please install this version before upgrading to Beta 5! Otherwise you won’t be able to boot your computer!</strong></p>
<p>This version does not install an Endpoint Security System Extension because Big Sur Beta 5 suffers a kernel panic immediately after booting this System Extension is installed. During upgrade, an existing Endpoint Security System Extension is removed. Currently, the only function of the Endpoint Security System Extension is to detect access to Berkeley Packet Filter devices. This version can therefore not warn when a process tries to access the Berkeley Packet Filter.</p>
<p>The good news is that Big Sur Beta 5 fixes an other kernel panic which occurred on some computers when Little Snitch’s Network Extension was installed.</p>
</div></div></div>
<div id="version-6118">
<p><span>August 12, 2020</span></p>
<div>
<h3>Little Snitch Technology Preview <span>(6118)</span></h3>
<div>
<ul>
<li>Re-implemented process identity checks.</li>
<li>Re-implemented creation of Diagnostics Reports.</li>
<li>Various improvements and bug fixes in the user interface.</li>
</ul>
</div></div></div>
<div id="version-6112">
<p><span>July 20, 2020</span></p>
<div>
<h3>Little Snitch Technology Preview <span>(6112)</span></h3>
<div>
<ul>
<li>This version is now a Universal Binary which runs on both Intel and Apple Silicon Macs.</li>
<li>Import of rules and settings from previous versions. Choose <em>Little Snitch &gt; File &gt; Restore from Backup…</em> and select a previously created backup file or <code>/Library/Application Support/Objective Development/Little Snitch/configuration4.xpl</code> to import rules and settings from Little Snitch 4. This also works with configurations and backups from Little Snitch 3.</li>
<li>Export of rules and settings in JSON format. Choose <em>Little Snitch &gt; File &gt; Create Backup…</em></li>
<li>Various improvements and bug fixes in the user interface.</li>
</ul>
</div></div></div>
<div id="version-6109">
<p><span>July 8, 2020</span></p>
<div>
<h3>Little Snitch Technology Preview <span>(6109)</span></h3>
<div>
<ul>
<li>Improved upgrade procedure to work around an issue where macOS sometimes fails to start the newly installed network extension. If this problem occurs, the installer now completely uninstalls the previously installed extension before retrying to install the new one.</li>
<li>If a previous, incompatible version of Little Snitch is found, this version is now uninstalled automatically in the course of installing the new version. This uninstallation may require a restart of the computer in order to let macOS complete the removal of the kernel extension.</li>
<li>Several user interface refinements in the rules window.</li>
<li>Little Snitch now correctly identifies connections that were established by a Java process or a shell script.</li>
</ul>
</div></div></div>
<div id="version-6106">
<p><span>July 2, 2020</span></p>
<div>
<h3>Little Snitch Technology Preview <span>(6106)</span></h3>
<div>
<p>This version is primarily a test of the automatic software update. Please install this version using the automatic software update mechanism, not manually.</p>
<h4>Installation</h4>
<p>If you install this Technology Preview for the first time, please read the installation hints in the release notes of build 6104 below.</p>
<h4>Changes</h4>
<ul>
<li>Redesigned Rules window title bar.</li>
<li>Little Snitch specific log files are now created in a dedicated <code>Library/Logs/Little Snitch</code> subdirectory.</li>
</ul>
</div></div></div>
<div id="version-6104">
<p><span>June 30, 2020</span></p>
<div>
<h3>Little Snitch Technology Preview <span>(6104)</span></h3>
<div>
<p>This Technology Preview of Little Snitch is not yet feature complete. There are several known limitations you should be aware of before you install:</p>
<h4>Installation</h4>
<p>During the installation you will be asked to enable system extensions in System Preferences &gt; Security &amp; Privacy. After clicking on “Open Security Preferences”, the same dialog will appear once again. This is a bug in macOS Big Sur.</p>
<p><img src="https://www.obdev.at/Images/littlesnitch-big-sur/enable-system-extensions.png" alt="" srcset="https://www.obdev.at/Images/littlesnitch-big-sur/enable-system-extensions@2x.png 2x"></p>
<p>After clicking on “Allow…” in System Preferences &gt; Security &amp; Privacy, you will see a confirmation dialog containing two entries labeled “Placeholder Developer”. These incorrect labels are a bug in macOS Big Sur. The checkboxes for both of these entries must be checked.</p>
<h4>Known Limitations</h4>
<ul>
<li>Rules and settings from previous versions of Little Snitch are not yet imported. Little Snitch will therefore start with the default factory rule set.</li>
<li>Backup and restore of rules and settings is not yet implemented.</li>
<li>Code identity checks (usually based on code signature) are not yet implemented.</li>
<li>Automatic Profile Switching is not yet implemented.</li>
<li>Some UI components don’t yet have their final appearance and layout. </li>
</ul>
<h4>Tips and Tricks</h4>
<ul>
<li>All data files are encrypted with a password which is stored in the System Keychain (“Little Snitch Encryption Key”). When you make a backup of the files in <code>/Library/Application Support/Objective Development/Little Snitch/</code>, make sure you also backup this password.</li>
<li>Traffic history is now recorded by a background process, even when Network Monitor is not running.</li>
</ul>
<h4>Feedback</h4>
<p>If Little Snitch crashes or behaves in an unexpected way, please contact our support using the “Send Feedback” button above.</p>
<p>Make sure to include the following information:</p>
<ul>
<li>Version number of your Little Snitch app.</li>
<li>A textual description of the issue: What did you do, what would you have expected to happen and what did happen.</li>
<li>Crash logs of Little Snitch components, which can be found in Console.app sidebar under “Crash Reports”.</li>
<li>Logs from Little Snitch under <code>/Library/Logs/</code> and <code>~/Libra…</code></li></ul></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.obdev.at/products/littlesnitch/releasenotes.html">https://www.obdev.at/products/littlesnitch/releasenotes.html</a></em></p>]]>
            </description>
            <link>https://www.obdev.at/products/littlesnitch/releasenotes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24967796</guid>
            <pubDate>Mon, 02 Nov 2020 13:14:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If Sapiens were a blog post]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24967336">thread link</a>) | @neilkakkar
<br/>
November 2, 2020 | https://neilkakkar.com/sapiens.html | <a href="https://web.archive.org/web/*/https://neilkakkar.com/sapiens.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <map name="image-map">
    <area alt="Taming fire" title="Development of Brains" href="#development-of-brains" coords="0,77,115,77,80,150,0,150" shape="poly">
    <area alt="cognitive revolution" title="Cognitive Revolution" href="#cognitive-revolution" coords="115,77,230,77,195,150,80,150" shape="poly">
    <area alt="agriculture revolution" title="Agricultural Revolution" href="#agricultural-revolution" coords="230,77,345,77,310,150,195,150" shape="poly">
    <area alt="unificiation" title="Unification of Humanity" href="#unification-of-humankind" coords="345,77,460,77,415,150,310,150" shape="poly">
    <area alt="scientific revolution" title="Scientific Revolution" href="#scientific-revolution" coords="460,77,575,77,520,150,415,150" shape="poly">
    <area alt="industrial revolution" title="Industrial Revolution" href="#industrial-revolution" coords="575,77,690,77,635,150,540,150" shape="poly">
    <area alt="present" title="The Present" href="#the-end-of-homo-sapiens" coords="690,77,805,77,750,150,655,150" shape="poly">
</map>

<figure>
    
        <a target="_blank" href="https://amzn.to/2WWNsjq" rel="noopener">
    
    <img src="https://neilkakkar.com/assets/images/sapiens.jpg" alt="">
    
        </a>
    
    
    
</figure>

<p>I spent over 25 hours building a cut-down version of Sapiens. The goal? Future-me should be happy to read this once future-me forgets how we evolved. It’s massive for a blog post, just under 30 minutes, but that’s the best I could do, condensing 9 hours worth of material.</p>

<p>I’ve tried to keep editing to a minimum: It’s the original text, edited to ensure it still flows like the book.</p>

<p>You can get the book <a href="https://amzn.to/2WWNsjq" target="_blank" rel="noopener">here</a><sup id="fnref:2"><a href="#fn:2">1</a></sup></p>

<!-- 1: An Animal of No Significance -->

<p>The best way of navigating is clicking on the images. These are best experienced on a tablet or a laptop. I’ve also included the table of contents, which work well on every screen size.</p>





<nav>

  <h4>Table of Contents</h4>

<ul id="markdown-toc">
  <li><a href="#development-of-brains" id="markdown-toc-development-of-brains">Development of brains</a></li>
  <li><a href="#cognitive-revolution" id="markdown-toc-cognitive-revolution">Cognitive Revolution</a></li>
  <li>
<a href="#agricultural-revolution" id="markdown-toc-agricultural-revolution">Agricultural Revolution</a>    <ul>
      <li>
<a href="#imagined-realities---solving-the-co-ordination-problem" id="markdown-toc-imagined-realities---solving-the-co-ordination-problem">Imagined Realities - Solving the co-ordination problem</a>        <ul>
          <li><a href="#the-imagined-order-is-embedded-in-the-material-world" id="markdown-toc-the-imagined-order-is-embedded-in-the-material-world"><strong>The imagined order is embedded in the material world.</strong></a></li>
          <li><a href="#the-imagined-order-shapes-our-desires" id="markdown-toc-the-imagined-order-shapes-our-desires"><strong>The imagined order shapes our desires.</strong></a></li>
          <li><a href="#the-imagined-order-is-inter-subjective" id="markdown-toc-the-imagined-order-is-inter-subjective"><strong>The imagined order is inter-subjective.</strong></a></li>
        </ul>
      </li>
      <li><a href="#preserving-the-imagined-reality" id="markdown-toc-preserving-the-imagined-reality">Preserving the imagined reality</a></li>
      <li><a href="#more-individual-suffering" id="markdown-toc-more-individual-suffering">More individual suffering</a></li>
    </ul>
  </li>
  <li>
<a href="#unification-of-humankind" id="markdown-toc-unification-of-humankind">Unification of Humankind</a>    <ul>
      <li>
<a href="#money" id="markdown-toc-money">Money</a>        <ul>
          <li><a href="#how-money-works" id="markdown-toc-how-money-works">How Money Works</a></li>
          <li><a href="#proliferation-of-gold" id="markdown-toc-proliferation-of-gold">Proliferation of gold</a></li>
        </ul>
      </li>
      <li>
<a href="#empires" id="markdown-toc-empires">Empires</a>        <ul>
          <li><a href="#the-imperial-cycle" id="markdown-toc-the-imperial-cycle">The Imperial Cycle</a></li>
        </ul>
      </li>
      <li>
<a href="#religion" id="markdown-toc-religion">Religion</a>        <ul>
          <li><a href="#battle-between-good-and-evil-for-monotheism" id="markdown-toc-battle-between-good-and-evil-for-monotheism">Battle between good and evil for monotheism</a></li>
          <li><a href="#towards-principles-other-than-god" id="markdown-toc-towards-principles-other-than-god">Towards principles other than god</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
<a href="#scientific-revolution" id="markdown-toc-scientific-revolution">Scientific Revolution</a>    <ul>
      <li><a href="#imperialism-and-science" id="markdown-toc-imperialism-and-science">Imperialism and science</a></li>
      <li><a href="#capitalism-and-science" id="markdown-toc-capitalism-and-science">Capitalism and science</a></li>
    </ul>
  </li>
  <li>
<a href="#industrial-revolution" id="markdown-toc-industrial-revolution">Industrial Revolution</a>    <ul>
      <li>
<a href="#aftereffects-of-industry" id="markdown-toc-aftereffects-of-industry">Aftereffects of Industry</a>        <ul>
          <li><a href="#collapse-of-family" id="markdown-toc-collapse-of-family">Collapse of family</a></li>
          <li><a href="#movement-from-war-to-peace" id="markdown-toc-movement-from-war-to-peace">Movement from war to peace</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#the-end-of-homo-sapiens" id="markdown-toc-the-end-of-homo-sapiens">The End of Homo Sapiens</a></li>
</ul>

</nav>

<!-- works only once jQuery is loaded -->


<h2 id="development-of-brains">Development of brains</h2>

<figure>
    
    <img src="https://neilkakkar.com/assets/images/sapiens-timeline-1.jpg" alt="" usemap="#image-map">
    
    
    
</figure>

<p>What caused our brains to develop? We’re not sure.</p>

<p>It doesn’t seem likely. A larger brain needs more energy and thus reduces the chance you’ll survive. Getting more energy meant hunting more.</p>

<p>One contributing factor was the domestication of fire. Fire paved the way for cooking.</p>

<p>Whereas chimpanzees spend 5 hours a day chewing raw food, a single hour suffices for people eating cooked food. The advent of cooking enabled humans to eat more kinds of food, to devote less time to eating, and to make do with smaller teeth and shorter intestines. Some scholars believe there is a direct link between the advent of cooking, the shortening of the human intestinal track, and the growth of the human brain. Since long intestines and large brains are both massive energy consumers, it’s hard to have both. By shortening the intestines and decreasing their energy consumption, cooking inadvertently opened the way to the jumbo brains.</p>

<p>And, we weren’t alone. Competing with us were the Neanderthals, among other species. They were stronger, they had bigger brains, and they could survive the cold. How come, then, did we “win”?</p>

<p>We aren’t sure. The most likely answer is the very thing that makes the debate possible: Homo sapiens conquered the world thanks above all to its unique language.</p>

<h2 id="cognitive-revolution">Cognitive Revolution</h2>

<figure>
    
    <img src="https://neilkakkar.com/assets/images/sapiens-timeline-2.jpg" alt="" usemap="#image-map">
    
    
    
</figure>

<p>The appearance of new ways of thinking and communicating, between 70,000 and 30,000 years ago, constitutes the Cognitive Revolution. What caused it? We’re not sure. The most commonly believed theory argues that accidental genetic mutations changed the inner wiring of the brains of Sapiens, enabling them to think in unprecedented ways and to communicate using a new type of language. We might call it the Tree of Knowledge mutation.</p>

<!-- 
> All new humans are improvements over the past?
> As in, the de facto keeps rising.

>These mutated humans were praised for their initiative and were more successful
>Till everyone became like this and then even more better humans were praised and the previous became the normal -->

<p>What’s special about our language?</p>

<p>Our language is amazingly supple. We can connect a limited number of sounds and signs to produce an infinite number of sentences, each with a distinct meaning. We can thereby ingest, store and communicate a prodigious amount of information about the surrounding world. A monkey can yell to its comrades, ‘Careful! A lion!’ But a modern human can tell her friends that this morning, near the bend in the river, she saw a lion tracking a herd of bison. She can then describe the exact location, including the different paths leading to the area. With this information, the members of her band can put their heads together and discuss whether they ought to approach the river in order to chase away the lion and hunt the bison.</p>

<!-- Most likely, both the gossip theory (who can be trusted and who can't) and the there-is-a-lion-near-the-river theory are valid.  -->

<p>Yet the truly unique feature of our language is not its ability to transmit information about men and lions. Rather, it’s the ability to transmit information about things that do not exist at all. As far as we know, only Sapiens can talk about entire kinds of entities that they have never seen, touched or smelled.</p>

<!-- The alpha male usually wins his position not because he is physically stronger, but because he leads a large and stable coalition -->

<p>Using language, lots of humans could work together, form a tribe, help each other, and hunt together.</p>

<p>However, communicating with lots of people brings with it new co-ordination problems. The critical threshold for a group interacting together is 150 people.</p>

<!-- But once the threshold of 150 individuals is crossed, things can no longer work that way. You cannot run a division with thousands of soldiers the same way you run a platoon. Successful family businesses usually face a crisis when they grow larger and hire more personnel. If they cannot reinvent themselves, they go bust.  -->

<p>How did Homo sapiens manage to cross this critical threshold, eventually founding cities comprising tens of thousands of inhabitants and empires ruling hundreds of millions? The secret was probably the appearance of fiction. Large numbers of strangers can cooperate successfully by believing in common myths. This is an imagined reality.</p>

<!-- Ever since the Cognitive Revolution, Sapiens has thus been living in a dual reality. On the one hand, the objective reality of rivers, trees and lions; and on the other hand, the imagined reality of gods, nations and corporations.  -->

<!-- As time went by, the imagined reality became ever more powerful, so that today the very survival of rivers, trees and lions depends on the grace of imagined entities such as gods, nations and corporations. -->

<p>Unlike lying, an imagined reality is something that everyone believes in, and as long as this communal belief persists, the imagined reality exerts force in the world.</p>

<p>In other words, while the behaviour patterns of archaic humans remained fixed for tens of thousands of years, Sapiens could transform their social structures, the nature of their interpersonal relations, their economic activities and a host of other behaviours within a decade or two.</p>

<!-- > Because of the cognitive Revolution and the introduction of imagined reality -->

<p>For example, consider trade. Trade cannot exist without trust, and it is very difficult to trust strangers. The global trade network of today is based on our trust in such fictional entities as the dollar, the Federal Reserve Bank, and the totemic trademarks of corporations. When two strangers in a tribal society want to trade, they will often establish trust by appealing to a common god, mythical ancestor or totem animal.</p>

<!-- One on one, even ten on ten, we are embarrassingly similar to chimpanzees. Significant differences begin to appear only when we cross the threshold of 150 individuals, and when we reach 1,000–2,000 individuals, the differences are astounding -->

<!-- The real difference between us and chimpanzees is the mythical glue that binds together large numbers of individuals, families and groups. This glue has made us the masters of creation. -->

<p>Our Tree of Knowledge mutation was significant. However, it’s not just our biology that brought us where we are today.</p>

<ol>
  <li>
    <p>Biology sets the basic parameters for the behaviour and capacities of Homo sapiens. The whole of history takes place within the bounds of this biological arena.</p>
  </li>
  <li>
    <p>This arena is extraordinarily large, allowing Sapiens to play an astounding variety of games. Thanks to their ability to invent fiction, Sapiens create more and more complex games, which each generation develops and elaborates even further</p>
  </li>
  <li>
    <p>Consequently, in order to understand how Sapiens behave, we must describe the historical evolution of their actions.</p>
  </li>
</ol>

<!-- Referring only to our biological constraints would be like a radio sports-caster who, attending the World Cup football championships, offers his listeners a detailed description of the playing field rather than an account of what the players are doing. -->

<!-- There is some evidence that the size of the average Sapiens brain has actually decreased since the age of foraging. Survival in that era required superb mental abilities from everyone. When agriculture and industry came along people could increasingly rely on the skills of others for survival, and new ‘niches for imbeciles’ were opened up. You could survive and pass your unremarkable genes to the next generation by working as a water carrier or an assembly-line worker. -->

<h2 id="agricultural-revolution">Agricultural Revolution</h2>

<figure>
    
    <img src="https://neilkakkar.com/assets/images/sapiens-timeline-3.jpg" alt="" usemap="#image-map">
    
    
    
</figure>

<p>The currency of evolution is neither hunger nor pain, but rather copies of DNA helixes. Just as the economic success of a company is measured only by the number of dollars in its bank account, not by the happiness of its employees, so the evolutionary success of a species is measured by the number of copies of its DNA. If no more DNA copies remain, the species is extinct, just as a company without money is bankrupt. If a species boasts many DNA copies, it is a success, and the species flourishes. From such a perspective, 1,000 copies are always better than a hundred copies. This is the essence of the Agricultural Revolution: the ability to keep more people alive under worse conditions.</p>

<p>Rather than heralding a new era of easy living, the Agricultural Revolution left farmers with lives generally more difficult and less satisfying than those of foragers. Hunter-gatherers spent their time in more stimulating and varied ways, and were less in danger of starvation and disease. The Agricultural Revolution certainly enlarged the sum total of food at the disposal of humankind, but the extra food did not translate into a better diet or more leisure. Rather, it translated into population explosions and pampered elites. The average farmer worked harder than the average forager, and got a worse diet in return. The Agricultural Revolution was history’s biggest fraud.</p>

<!-- > The average person in Jericho of 8500 BC lived a harder life than the average person in Jericho of 9500 BC or 13,000 BC. But nobody realised what was happening. Every generation continued to live like the previous generation, making only small improvements here and there in the way things were done. Paradoxically, a series of ‘improvements’, each of which was meant to make life easier, added up to a millstone around the necks of these farmers -->
<!-- 
--- Way of life being lost over generations
    Like with the foundation.
    Also short sightedness.
    As, working harder here meant more food => can better feed children => even more people exist => You're back where you started, except you're working harder.
 -->

<p>Compared to foraging, working a bit harder on the farm meant more food. Settling down on the farm also meant greater freedom to reproduce - you’re not travelling all the time, so you can afford to have more children. This in turn, meant a higher population. And a higher population meant higher food requirements. Thus, the farmers were forced to work even harder.</p>

<p>Why didn’t humans abandon farming when the plan backfired? Partly because it took generations for the small changes to accumulate and transform society and, by then, nobody remembered that they had ever lived differently. And partly because population growth burned humanity’s boats. If the adoption of ploughing increased a village’s population from a hundred to 110, which ten people would have volunteered to starve so that the others could go back to the good old times? There was no going back. The trap snapped shut.</p>

<blockquote>
  <p>One of history’s few iron laws is that luxuries tend to become necessities and spawn new obligations</p>
</blockquote>

<p>This discrepancy between evolutionary success and individual suffering is perhaps the most important lesson we can draw from the Agricultural Revolution. When we study the narrative of plants such as wheat and maize, maybe the purely evolutionary perspective makes sense. Yet in the case of animals such as cattle, sheep and Sapiens, each with a complex world of sensations and emotions, we have to consider how evolutionary success translates into individual experience.</p>

<!-- In the following chapters we will see time and again how a dramatic increase in the collective power and ostensible success of our species went hand in hand with much individual suffering. -->

<!-- How the agricultural revolution led to individual suffering -> -->

<!-- 6: Building Pyramids -->

<!-- This was a far-reaching revolution, whose impact was psychological as much as architectural. Henceforth, attachment to ‘my house’ and separation from the neighbours became the psychological hallmark of a much more self-centered creature. -->

<h3 id="imagined-realities---solving-the-co-ordination-problem">Imagined Realities - Solving the co-ordination problem</h3>

<p>According to the science of biology, people were not ‘created’. They have evolved. And they certainly did not evolve to be ‘equal’. The idea of equality is inextricably intertwined with the idea of creation.</p>

<p>A natural order is a stable order. There is no chance that gravity will cease to function tomorrow, even if people stop believing in it. In contrast, an imagined order is always in danger of collapse, because it depends upon myths, and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://neilkakkar.com/sapiens.html">https://neilkakkar.com/sapiens.html</a></em></p>]]>
            </description>
            <link>https://neilkakkar.com/sapiens.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24967336</guid>
            <pubDate>Mon, 02 Nov 2020 12:23:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to get started with permaculture when all you have is a balcony]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24967225">thread link</a>) | @roboben
<br/>
November 2, 2020 | https://permapeople.org/blog/2020/10/12/get-started-with-permaculture-on-a-balcony.html | <a href="https://web.archive.org/web/*/https://permapeople.org/blog/2020/10/12/get-started-with-permaculture-on-a-balcony.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><img src="https://permapeople.org/blog/assets/permaculture-balcony.jpg" alt="Two potatoes in an Ikea bag"></p>

<p>First of all, thank you for everyone reaching out to me after my last blog post. It sparked many good conversations about permaculture in general and what people want to see on Permapeople specifically. This post is based on feedback I got, where someone reached out and asked: “I am interested in permaculture but only have a balcony!”</p>

<p>The idea of Permapeople is to create a better way to get information about growing your own plants in a <a href="https://medium.com/@designforsustainability/beyond-sustainability-we-are-living-in-the-century-of-regeneration-4f2b116a65d1"><del>sustainable</del>regenerative</a> way. Many people are hesitant because they live in apartments and don’t have access to some growing space.
When I got into permaculture, the available and actionable information was scattered and hard to use. Specific urban growing instructions on balconies or windowsills were almost nonexistent.
This is why I think it is a great idea to write about how you can start with permaculture, even if you only have a balcony.</p>

<p><strong>For this blog post, I used a new attribute in the database. If you <a href="https://permapeople.org/search?Good+for+containers=true">click here</a>, you’ll find all the plants that are great to be grown in a container and are perfect for the urban permaculture gardener.</strong></p>

<p>Permaculture is a design system with a few general principles, which you can use one a balcony too. I reinterpreted a few here and added some beginners’ tips. The goal is to get started, nothing more!</p>

<h3 id="observe-design--plan">Observe, Design &amp; Plan</h3>
<p>Every good project starts with a plan. The very first thing you want to think about is why you actually want to grow stuff: Is it because you want some fresh herbs or maybe you want to watch bees and butterflies on nice and beautiful smelling flowers, or maybe you want to grow for medicinal uses. Ensure you have a rough goal in mind, which will help you decide when designing your balcony.</p>

<p>Observe your balcony and look for light conditions, wind, and other factors, which might be important: Some plants don’t mind wind but need full sun so you can put them in front. Some cannot bear wind but need a lot of warmth, maybe but them in the back next to a wall, which can save heat overnight. Check if you have a drain to collect water or any other way to collect it. Think about how you can do the work you have to, where to get water from, etc.
Keep looking at your plants from day to day and try to understand: Do they need more water or less, more sun or less, or any other problems that may arise.</p>

<h3 id="keep-inputs-low">Keep Inputs Low</h3>
<p>When you can start setting up your baclony, please don’t check at first online all the things you need to buy. Rather check your basement and storage if you have old plastic boxes or anything else you can use to grow plants in. Garden tools can be lend from friends, family, or neighbors for the first time. Soil, compost, and seeds can be obtained from them too. Promise them a share of the yield if everything works out. Lookout for perennialplants, for example <a href="https://permapeople.org/plants/strawberry">Strawberries</a> since you only need to plant them one time. Only buy if you really have to.
Your own time and energy is another input most people forget, but you definitely want to keep it low. Only grow the plants you have the time to take care of and are resilient to a few days of neglect.</p>

<h3 id="chop-drop--only-add-to-the-top">Chop, Drop &amp; Only Add to the Top</h3>
<p>When it comes to the actual task of growing, I think this is the most and simple thing you can do to maintain good soil for your plants: Continuously add a lot of organic matter to the top of your containers.
Use your kitchen scraps, cut them small, and drop them directly on top of the soil. At the end of the season, chop away the old plants, cut them small, and drop them on top. Make sure to only cut away what is coming out of the soil and leave the soil undisturbed. Old roots in the soil are perfect organic matter when decomposing. <a href="https://permapeople.org/plants/tomato">Tomatoes</a> love being grown in the compost of old tomatoes.
Every organic matter you put on top of your containers will decompose by itself. There is no need to maintain a separate compost container.</p>

<h3 id="start-small">Start Small</h3>
<p>Another important thing is that you should start small not to get overwhelmed and drop everything before success. Even if you grow just a few plants initially, the amount of learning and reward will be huge. Go from there, learn from your experience, and extend your growing projects season by season.
It is more important to get any yield than a huge amount of yield at the end of the season, so focus on that!</p>

<h3 id="diversify-and-experiment">Diversify and Experiment</h3>
<p>While starting small is important, don’t only grow one plant and get disappointed when it fails. There can be many reasons why the plant didn’t grow. Remember to observe frequently and reiterate on your design. Start with 2-3 plants you like to eat or look at and see how they go. If you want, you can also try to grow one plant and different varieties and locations on your balcony. Remember: Always keep experimenting and maximize the learning!</p>

<p>I hope this helps a few people getting started with permaculture, even if they just have minimal space to grow in. If you have any questions or suggestions that you want to see in this blog, please reach out to hello at permaculture dot org. I will read and answer every email.
Also, make sure to join the newsletter below.</p>

<p>Happy growing 🌱✌️,</p>

<p>Ben</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://permapeople.org/blog/2020/10/12/get-started-with-permaculture-on-a-balcony.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24967225</guid>
            <pubDate>Mon, 02 Nov 2020 12:11:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Best Reinforcement Learning Tutorials, Examples, Projects, and Courses]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24967207">thread link</a>) | @patrycjaneptune
<br/>
November 2, 2020 | https://neptune.ai/blog/best-reinforcement-learning-tutorials-examples-projects-and-courses | <a href="https://web.archive.org/web/*/https://neptune.ai/blog/best-reinforcement-learning-tutorials-examples-projects-and-courses">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <article class="page">
	
<p>In reinforcement learning, your system learns how to interact intuitively with the environment by basically doing stuff and watching what happens – but obviously, there’s a lot more to it.</p>



<p>If you’re interested in RL, this article will provide you with a ton of new content to explore this concept. A lot of work has been done with reinforcement learning in the past few years, and I’ve collected some of the most interesting articles, videos, and use cases presenting different concepts, approaches, and methods.</p>



<p>In this list, you’ll find:&nbsp;</p>



<ul><li>reinforcement learning tutorials,&nbsp;</li><li>examples of where to apply reinforcement learning,</li><li>interesting reinforcement learning projects,</li><li>courses to master reinforcement learning.</li></ul>



<p>All this content will help you go from RL newbie to RL pro.</p>






<h2>Reinforcement learning tutorials</h2>



<p><strong>1. <a href="https://cai.tools.sap/blog/the-future-with-reinforcement-learning-part-1/" target="_blank" rel="noreferrer noopener nofollow">RL with Mario Bros</a></strong> – Learn about reinforcement learning in this unique tutorial based on one of the most popular arcade games of all time – Super Mario.</p>



<p><strong>2. <a href="https://medium.com/machine-learning-for-humans/reinforcement-learning-6eacf258b265" target="_blank" rel="noreferrer noopener nofollow">Machine Learning for Humans: Reinforcement Learning</a></strong> – This tutorial is part of an ebook titled ‘Machine Learning for Humans’. It explains the core concept of reinforcement learning. There are numerous examples, guidance on the next step to follow in the future of reinforcement learning algorithms, and an easy-to-follow figurative explanation.</p>



<p><strong>3. <a href="https://medium.com/free-code-camp/an-introduction-to-reinforcement-learning-4339519de419" target="_blank" rel="noreferrer noopener nofollow">An introduction to Reinforcement Learning</a></strong> – There’s a lot of knowledge here, explained with much clarity and enthusiasm. It starts with an overview of reinforcement learning with its processes and tasks, explores different approaches to reinforcement learning, and ends with a fundamental introduction of deep reinforcement learning.</p>



<p><strong>4. <a href="https://blog.insightdatascience.com/reinforcement-learning-from-scratch-819b65f074d8" target="_blank" rel="noreferrer noopener nofollow">Reinforcement Learning from scratch</a> </strong>– This article will take you through the author’s process of learning RL from scratch. The author has a lot of knowledge of deep reinforcement learning from working at Unity Technologies. Even beginners will be able to understand his overview of the core concepts of reinforcement learning.</p>



<p><strong>5. <a href="https://towardsdatascience.com/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02" target="_blank" rel="noreferrer noopener nofollow">Deep Reinforcement Learning for Automated Stock Trading</a> </strong>– Here you’ll find a solution to a stock trading strategy using reinforcement learning, which optimizes the investment process and maximizes the return on investment. The article includes a proper explanation of three combined algorithms: Proximal Policy Optimization (PPO), Advantage Actor-Critic (A2C), and Deep Deterministic Policy Gradient (DDPG). The best of each algorithm is coordinated to provide a solution to optimized stock trading strategies.</p>



<p><strong>6. <a href="https://towardsdatascience.com/applications-of-reinforcement-learning-in-real-world-1a94955bcd12" target="_blank" rel="noreferrer noopener nofollow">Applications of Reinforcement Learning in Real World</a> </strong>– Explore how reinforcement learning frameworks are undervalued when it comes to devising decision-making models. A detailed study of RL applications in real-world projects, explaining what a reinforcement learning framework is, and listing its use-cases in real-world environments. It narrows down the applications to 8 areas of learning, consisting of topics like machine learning, deep learning, computer games, and more. The author also explores the relationship of RL with other disciplines and discusses the future of RL.</p>



<p><strong>7. <a href="https://github.com/yandexdataschool/Practical_RL" target="_blank" rel="noreferrer noopener nofollow">Practical RL</a> </strong>– This GitHub repo is an open-source course on reinforcement learning, taught on several college campuses. The repo is maintained to support online students with the option of two locales – Russian and English. The course features services like chat rooms, gradings, FAQs, feedback forms, and a virtual course environment. The course syllabus covers everything from the basics of RL to discussing and implementing different models, methods, and much more.</p>



<p><strong>8.</strong><a href="https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0#.78km20i8r" target="_blank" rel="noreferrer noopener nofollow"><strong> Simple Reinforcement Learning with Tensorflow Part 0: Q-Learning with Tables and Neural Networks</strong></a> – The first part of a tutorial series about reinforcement learning with TensorFlow. The author explores Q-learning algorithms, one of the families of RL algorithms. The simple tabular look-up version of the algorithm is implemented first. The detailed guidance on the implementation of neural networks using the Tensorflow Q-algorithm approach is definitely worth your interest.</p>






<h2>Examples of where to apply reinforcement learning</h2>



<p><strong>1. <a href="https://blog.insightdatascience.com/using-reinforcement-learning-to-design-a-better-rocket-engine-4dfd1770497a" target="_blank" rel="noreferrer noopener nofollow">Rocket engineering</a></strong> – Explore how reinforcement learning is used in the field of rocket engine development. You’ll find a lot of valuable information on the use of machine learning in manufacturing industries. See why reinforcement learning is favored over other machine learning algorithms when it comes to manufacturing rocket engines.</p>



<p><strong>2. <a href="https://traffic-signal-control.github.io/" target="_blank" rel="noreferrer noopener nofollow">Traffic Light Control</a> </strong>– This site provides multiple research papers and project examples that highlight the use of core reinforcement learning and deep reinforcement learning in traffic light control. It has tutorials, datasets, and relevant example papers that use RL as a backbone so that you can make a new finding of your own.</p>



<p><strong>3. <a href="https://www.mlq.ai/ai-in-advertising/" target="_blank" rel="noreferrer noopener nofollow">Marketing and advertising</a></strong> – See how to make an AI system learn from a pre-existing dataset which may be infeasible or unavailable, and how to make AI learn in real-time by creating advertising content. This is where they have made use of reinforcement learning.<a href="https://medium.com/@deepthiraghvendra96/reinforcement-learning-in-marketing-2d5b29f3ed8c">&nbsp;</a></p>



<p><strong>4. <a href="https://medium.com/@deepthiraghvendra96/reinforcement-learning-in-marketing-2d5b29f3ed8c">Reinforcement Learning in Marketing | by Deepthi A R</a></strong> – This example focuses on the changing business dynamics to which marketers need to adapt. The AI equipped with a reinforcement learning scheme can learn from real-time changes and help devise a proper marketing strategy. This article highlights the changing business environment as a problem and reinforcement learning as a solution to it.</p>



<p><strong>5. <a href="https://www.youtube.com/watch?v=luzOblzznIc" target="_blank" rel="noreferrer noopener nofollow">Robotics</a></strong> – This video demonstrates the use of reinforcement learning in robotics. The aim is to show the implementation of autonomous reinforcement learning agents for robotics. A prime example of using reinforcement learning in robotics.</p>



<p><strong>6. <a href="https://medium.com/inside-machine-learning/recommendation-systems-using-reinforcement-learning-de6379eecfde" target="_blank" rel="noreferrer noopener nofollow">Recommendation</a> </strong>– Recommendation systems are widely used in eCommerce and business sites for product advertisement. There’s always a recommendation section displayed in many popular platforms such as YouTube, Google, etc. The ability of AI to learn from real-time user interactions, and then suggest them content, would not have been possible without reinforcement learning. This article shows the use of reinforcement learning algorithms and practical implementations in recommendation systems.</p>



<p><strong>7. <a href="https://www.mygreatlearning.com/blog/reinforcement-learning-in-healthcare/" target="_blank" rel="noreferrer noopener nofollow">Healthcare</a></strong> – Healthcare is a huge industry with many state-of-the-art technologies bound to it, where the use of AI is not new. The main question here is how to optimize AI in healthcare, and make it learn based on real-time experiences. This is where reinforcement learning comes in. Reinforcement learning has undeniable value for healthcare, with its ability to regulate ultimate behaviors. With RL, healthcare systems can provide more detailed and accurate treatment at reduced costs.</p>



<p><strong>8. <a href="https://venturebeat.com/2020/06/30/researchers-combine-reinforcement-learning-and-nlp-to-escape-a-grue-monster/" target="_blank" rel="noreferrer noopener nofollow">NLP</a> </strong>– This article shows the use of reinforcement learning in combination with Natural Language Processing to beat a question and answer adventure game. This example might be an inspiration for learners engaged in Natural Language Processing and gaming solutions.</p>



<p><strong>9. <a href="https://towardsdatascience.com/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02" target="_blank" rel="noreferrer noopener nofollow">Trading</a></strong> – Deep reinforcement learning is a force to reckon with when it comes to the stock trading market. The example here demonstrates how deep reinforcement learning techniques can be used to analyze the stock trading market, and provide proper investment reports. Only an AI equipped with reinforcement learning can provide accurate stock market reports.</p>






<h2>Interesting reinforcement learning projects</h2>



<p><strong>1. <a href="https://github.com/carla-simulator/carla" target="_blank" rel="noreferrer noopener nofollow">CARLA</a></strong><a href="https://github.com/carla-simulator/carla" target="_blank" rel="noreferrer noopener nofollow"> </a>– CARLA is an open-source simulator for autonomous driving research. The main objective of CARLA is to support the development, training, and validation of autonomous driving systems. With a package of open-source code and protocols, CARLA provides digital assets that are free to use. The CARLA eco-system also integrates code for running Conditional Reinforcement Learning models, with standalone GUI, to enhance maps with traffic lights and traffic signs information.</p>



<p><strong>2. <a href="https://github.com/yenchenlin/DeepLearningFlappyBird" target="_blank" rel="noreferrer noopener nofollow">Deep Learning Flappy Bird</a></strong> – If you want to learn about deep Q learning algorithms in an interesting way, then this GitHub repo is for you. The project uses a Deep Q-Network to learn how to play Flappy Bird. It follows the concept of the Deep Q learning algorithm which is in the family of reinforcement learning.</p>



<p><strong>3. <a href="https://github.com/tensorforce/tensorforce" target="_blank" rel="noreferrer noopener nofollow">Tensorforce</a></strong><a href="https://github.com/tensorforce/tensorforce" target="_blank" rel="noreferrer noopener nofollow"> </a>– This project delivers an open-source deep reinforcement learning framework specialized in modular flexible library design and direct usability for applications in research and practice. It is built on top of Google’s Tensorflow framework. It houses high-level design implementation such as modular component-based design, separation of RL algorithm and application, and full-on TensorFlow models.</p>



<p><strong>4. <a href="https://github.com/ray-project/ray" target="_blank" rel="noreferrer noopener nofollow">Ray</a></strong><a href="https://github.com/ray-project/ray" target="_blank" rel="noreferrer noopener nofollow"> </a>– Ray’s main objective is to provide universal APIs for building distributed applications. This project makes use of the RLlib package, which is a scalable Reinforcement Learning library that accelerates machine learning workloads.</p>



<p><strong>5. <a href="https://github.com/janhuenermann/neurojs" target="_blank" rel="noreferrer noopener nofollow">Neurojs</a> </strong>– JavaScript is popular, and a must for developing websites. What if you need to incorporate reinforcement learning in your JS web project? Say hello to Neurojs, a JavaScript framework for deep learning in the browser using reinforcement learning. It can also perform some neural network tasks as well.</p>



<p><strong>6. <a href="https://github.com/aleju/mario-ai" target="_blank" rel="noreferrer noopener nofollow">Mario AI</a> </strong>– This one will definitely grab your interest if you are looking for a project with reinforcement learning algorithms for simulating games. Mario AI&nbsp;offers a coding implementation to train a model that plays the first level of Super Mario World automatically, using only raw pixels as the input. The algorithm applied is a deep Q-learning algorithm in the family of reinforcement learning algorithms.</p>



<p><strong>7. <a href="https://github.com/samre12/deep-trading-agent" target="_blank" rel="noreferrer noopener nofollow">Deep Trading Agent</a> </strong>– Open-source project offering a deep reinforcement learning based trading agent for Bitcoin. The project makes use of the DeepSense Network for Q function approximation. The goal is to simplify the trading process using a reinforcement learning algorithm optimizing the Deep Q-learning agent. It can be a great source of knowledge.</p>



<p><strong>8. <a href="https://github.com/evilsocket/pwnagotchi" target="_blank" rel="noreferrer noopener nofollow">Pwnagotchi </a></strong>– This …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://neptune.ai/blog/best-reinforcement-learning-tutorials-examples-projects-and-courses">https://neptune.ai/blog/best-reinforcement-learning-tutorials-examples-projects-and-courses</a></em></p>]]>
            </description>
            <link>https://neptune.ai/blog/best-reinforcement-learning-tutorials-examples-projects-and-courses</link>
            <guid isPermaLink="false">hacker-news-small-sites-24967207</guid>
            <pubDate>Mon, 02 Nov 2020 12:09:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why you should study history in school]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24966824">thread link</a>) | @notcodingtoday
<br/>
November 2, 2020 | https://notcoding.today/blog/why-igcse-history | <a href="https://web.archive.org/web/*/https://notcoding.today/blog/why-igcse-history">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>2020-11-02</p><h2 id="tldr">TL;DR</h2><p>Studying IGCSE History makes you significantly more pleasant person to make discussions and relationships with. You can stop social networks from being <a href="https://metro.co.uk/2020/10/23/ex-google-ceo-calls-social-media-an-amplifier-for-idiots-13470970/">amplifiers for idiots</a>.</p><p>If you are studying IGCSE, study History regardless of what you plan to do with your future, thank me later.</p><h2 id="a-glimpse-at-igcse-subject-history">A glimpse at IGCSE subject: History</h2><p>Disclaimer: I studied IGCSE, followed by A levels, years ago. The information here might be dated, but the gist if it should still hold.</p><p><a href="https://www.cambridgeschool.eu/en/cambridge-igcse">IGCSE</a> is essentially a secondary/highschool program and examination by the University of Cambridge. There are a lot of different subjects to study, one of which is History.</p><p>In IGCSE History, on top of WW1, you get to choose which historic event(s) to dig deep into. I ended up studying WW1, WW2 and Cold War. I vaguely remember other topics you could study:</p><ul><li>China and Mao Tse-Tung (I somewhat wish I had kept my history book to study CCP history)</li><li>Russia and Stalin (or was it Rasputin?)</li></ul><p>The study focus is evaluating various sources of information gathered for you, then making a compelling argument for your statement or opinion.</p><p>For example, the question is "Did Hitler cause WW2?". By utilizing provided sources (ie. general media, such as news snippets, photographs and letters) and your knowledge of factual history, you create your own opinion. Your opinions needs justifications backed with facts and sources provided.</p><p>Depending on how you interpret the sources, interesting answers can arise, especially when the question demands subjectivity. Your claims can be in the grey area, as long as you make it clear <em>why</em> they are grey.</p><p>Side note: I blame majority on Britain - looking at you Chamberlain - and France.</p><h2 id="what-skills-do-you-learn-in-igcse-history">What skills do you learn in IGCSE History?</h2><p>These are the things I learnt (or became aware of) while studying IGCSE History:</p><ul><li>Understanding the context (surrounding political or economical events) behind various sources.</li><li>Filtering out bias from sources.</li><li>Constructing logic and arguments with evidence and facts (not emotions).</li><li>Discovering and understanding all sides of the argument.</li><li>Disagreeing and making constructive discussions with your peers (without being a cunt).</li><li>Naturally accepting your mistakes or invalid statements with introduction of new information (and not shaming others when such happens to them)</li></ul><h2 id="why-is-such-skill-set-important-in-2020">Why is such skill set important in 2020?</h2><p>In the past decade, I observed the following problems:</p><ul><li>Many people get trapped into reading hyper emotional <em>journalism</em> (usually makes them feel guilty). This usually makes them carried away in amplifying the message, without even an attempt to understand the other side of the story.</li><li>Political media sources are inevitably biased in certain direction of their own. In my book, objective journalism cannot exist unless journalist's opinions can't sway the words even in the slightest.</li><li>A lot of discussions (online and offline) end up being herded/dominated by vocal people trapped in echo chamber. This naturally leads to other information bias problems.</li><li>Adults seem to just hate accepting the fact that they are wrong. Adults also seem to shame others a lot for being wrong.</li></ul><p>All IGCSE History skills stated above will help you combat these problems.</p><p>If you studied IGCSE history,</p><ul><li>You know that nothing is black and white once it matters enough for you to care.</li><li>You know that the winners of wars got to paint the event in their taste and add subjectivity to the 'facts'. You know that this still remains true.</li><li>You set your emotions aside when you read anything on the internet.</li><li>You naturally seek all sides of the information and conclude your opinion of your own.</li></ul><p>IGCSE History makes you a real adult.</p><h2 id="gift-for-you-for-reading-this-far">Gift for you for reading this far</h2><p>Here are some of other titles I thought of for this post:</p><ul><li>Study history to reduce number of dumbfucks on Twitter.</li><li>Prevent yourself from becoming cancer of the internet.</li></ul></div></div>]]>
            </description>
            <link>https://notcoding.today/blog/why-igcse-history</link>
            <guid isPermaLink="false">hacker-news-small-sites-24966824</guid>
            <pubDate>Mon, 02 Nov 2020 11:19:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coral Griefs: Finding Hope Amidst Loss]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24966805">thread link</a>) | @dnetesn
<br/>
November 2, 2020 | http://oceans.nautil.us/feature/633/coral-griefs-finding-hope-amidst-loss | <a href="https://web.archive.org/web/*/http://oceans.nautil.us/feature/633/coral-griefs-finding-hope-amidst-loss">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><span>A</span>s smoke from the western North American megafires migrated across the Pacific in early September of 2020, Aziz Mulla flew with a small team of scientists to Lanyu, a remote island 40 miles off the southeastern coast of Taiwan. They were responding to reports of a different kind of wildfire. While no flames scorched forests, the hottest Northern Hemisphere summer on record caused dramatic increases in water temperature around the islandâ€™s renowned coral reefs.</p>

<p>Mulla and his team took a small diving boat out to a section of reef they have studied for years. He describes the location as one of the most gorgeous diving sites in the world. That morning the sea was as calm as a lake. Its turquoise waters glistened in the sunlight. In the distance, the steep hills of Lanyu, also known as Orchid Island, were covered in a shaggy emerald.</p>
<p>â€œI remember getting nervous about the dive while on the boat, which isnâ€™t something that usually happens,â€� says Mulla, a coral ecologist at Academia Sinica, Taiwanâ€™s national university, who has made thousands of dives all over the world. From the boat, Mulla says the destruction was obvious. Corals that should have been a palette of bright hues now glistened like bone. The heat had caused them to expel their color- and life-giving symbiotic algae, a phenomenon known as bleaching that can lead to the coralsâ€™ starvation and death.</p>
<p>Having developed an intimate bond with a particular species of coral, <em>Pocillopora verrucosa</em>, Mulla dove immediately to one of the animals for an up-close look. â€œThe tips of its branches were burnt,â€� he says.&nbsp; â€œIt was as if someone had taken a lighter to them.â€�</p>
<p>Lanyuâ€™s reef was bleached to depths as low as 100 feet. The shrimp, other crustaceans, and small fish who usually live on top of coral were noticeably absent. Larger fish like groupers and parrotfish were also eerily scarce. And the damage was not unique to just that section of reef. In fact, so many of Lanyuâ€™s formerly healthy reefs were bleached that a luminous halo had formed around the island.</p>

<p><span>T</span>he term <em>ecological grief</em> is relatively new in the scientific lexicon but the pain and despair it signifies have been heavily felt over the past few decades as climate change and destructive activities have erased ice shelves, forests, cherished species, and even killed humans. A related term is <em>solastalgia, </em>a neologism <a href="https://www.researchgate.net/publication/5820433_Solastalgia_The_Distress_Caused_by_Environmental_Change" target="_blank">coined by environmental philosopher Glenn Albrecht</a> to signify the existential distress caused by ecological destruction. Climate-induced changes cast a particularly dark shadow. Even as we look at beloved, still-intact landscapes and ecosystems, we know what could soon happen to them..&nbsp;</p>
<p>The terms ask us to consider not only the physical toll of climate change on the environment, but to assess how its decline affects our own mental health. Since scientists have a front-row seat, many bear the weight of this grief and anxiety; in response some communities of researchers have set up <a href="https://www.cbsnews.com/news/the-good-grief-network-support-group-helps-to-deal-with-psychological-effects-of-climate-change/" target="_blank">online support groups</a> to share their experiences and find comfort. Because the effects of climate change on corals can happen so quickly, as in the reefs off Lanyu, marine biologists may be especially traumatized.</p>
<p>â€œItâ€™s actually tragic,â€� says Charles Sheppard of the University of Warwick, who has studied coral reefs in the Chagos Archipelago for more than 40 years. â€œOn a dark night, I really grieve. In fact, some other scientists I know have actually shed tears underwater while scuba diving after seeing the rubble caused by a recent heat wave.â€�</p>
<p>The reefs he studies are some of the worldâ€™s finest. Due to their isolation and the territoryâ€™s ban on commercial fishing, Sheppard describes them as Earthâ€™s reef â€œlaboratoryâ€�—as close reefs now get to baseline perfection, that incredibly rare state of being unaffected by human interference. Sheppard recalls how, earlier in his career, he took other scientists diving for the first time in the Archipelago. They gushed about the reefsâ€™ nearly pristine condition, with thousands of species thriving alongside one another in a kaleidoscope of life.&nbsp;</p>
<p>Even so, many reefs in the Chagos Archipelago have been bleached, most recently during back-to-back extreme heat episodes in 2016 and 2017. In his latest paper, â€œ<a href="http://coralreefs.org/wp-content/uploads/2018/12/Reef_Encounter_Jul_2020_lo-res.pdf%252523page=28" target="_blank">Coral wreaths and the rise of phoenix coral</a>,â€�&nbsp;Sheppard describes a vicious feedback loop: not only are there fewer coral larvae, but less habitat for them to colonize. Much of the Archipelagoâ€™s reefs have turned into what he calls â€œliquid sandpaper.â€�&nbsp;â€œMy suggestion with this paper was that weâ€™ve reached a tipping point,â€� Sheppard says. â€œLess and less corals are being produced and they now have less space to settle on. Itâ€™s a slippery path to extinction, really.â€�</p>
<blockquote><strong>â€œ</strong>We can be optimistic, but we also have to be realistic.â€�</blockquote>
<p>Sheppard also grieves for the impact of coral deaths on humans. The people who are â€œgoing to suffer the most are not the tourists,â€� he says. â€œItâ€™s the people who harvest a living day by day and live a hand-to-mouth existence.â€� Nearly half a billion people rely on coral reefs for fish protein, says Sheppard, and climate change will kill many of them.</p>
<p>Nevertheless Sheppard finds ways to stay optimistic and keep moving. â€œI know Iâ€™ll be dead in 30 years,â€� he says, â€œbut I still will go to the doctor now if something is wrong with me. A human doesnâ€™t say, â€˜Well, whatâ€™s the point if Iâ€™m going to die anyway?â€™ Of course not, there are things to do!â€� He advocates for more research on reefs and outreach to the public—and despite his grim forecast, he wrote in that last paper that â€œa recovery is possible again.â€� It will require heat waves to be less extreme than predicted, and perhaps for people to take a hands-on approach to managing the reefs, and even then wonâ€™t be guaranteed, but thereâ€™s still a chance.&nbsp;</p>
<p>Back in Taiwan, Mulla deals with ecological grief primarily through teaching others, including the public but also friends and family, about what is happening to corals. â€œHaving them experience the same empathy I feel, helps a lot,â€� he says, â€œForest fires are extremely easy to see, but coral reefs are hidden below the surface—and most people think theyâ€™re rocks.â€� Education, Mulla believes, is a necessary step to decreasing greenhouse gases in the atmosphere.&nbsp;</p>
<p>Mulla still has hope. He points to a 2016 study, â€œ<a href="https://www.researchgate.net/publication/303980691_Bright_spots_among_the_world's_coral_reefs" target="_blank">Bright spots among the worldâ€™s coral reefs</a>,â€�&nbsp;which described 15 exceptionally vibrant reefs—some in remote, relatively pristine locations, but others flourishing near places where many people live. These reefs may hold lessons for protecting others, even in a rapidly changing world.&nbsp;</p>
<p>Among the bright spots were Taiwanâ€™s reefs, making this summerâ€™s catastrophic bleaching all the more tragic and also a pressing research subject for Mulla and his team, who are hurrying to understand which coral species will return and how they will respond to further warming events. Like Sheppard in the Indian Ocean, Mulla thinks Taiwanâ€™s reefs are reaching a tipping point. â€œIn 2050, I think weâ€™re going to be looking back at 2020 and think we had it pretty good,â€� he says. â€œWill we have coral reefs in 2050? Yes. Will they look the same? Probably not. We can be optimistic, but we also have to be realistic.â€�</p>

<p><span>I</span>tâ€™s difficult to imagine the grief Mulla and Sheppard must feel when witnessing the destruction of reefs theyâ€™ve studied so closely. I can, however, identify with their solastalgia, particularly this summer of 2020,&nbsp;as the West exploded into fires that <a href="https://www.nytimes.com/2020/09/15/us/oregon-fires-california.html" target="_blank">burned 5 million acres </a>and choked half the hemisphere with smoke.</p>
<p>Much of that smoke was the remnants of cherished trees, plants, animals, and fungi in places Iâ€™ve known well. While Iâ€™ve never been scuba diving, I imagine witnessing mass bleaching is like moping past the burn zone of a devastating wildfire, like I did after this yearâ€™s Dome Fire, which burned 43,248 acres in Californiaâ€™s Mojave National Preserve where stood the densest Joshua tree forest in the world. Instead of the bleached slopes of white Mulla described, I saw blackened stands of snags, charred ground cover, and the burnt corrals of a nearby ranch. Another fire this summer took a nearby canyon in my home state of Colorado, and I now breathe the smoke of one still aflame on treasured mountains above Los Angeles.</p>
<p>These forests will not regenerate in our lifetime. Perhaps they wonâ€™t even look the same for our great-great-grandchildren. It is a lot to take in: the worldâ€™s forests and oceans on fire at the same time. I find buoyancy, though, in every expert I interview who has dedicated their life to finding solutions. Itâ€™s proof that there are people who will put themselves on the front lines of environmental trauma to find knowledge that will help our planet and the people who rely upon it.</p>

<ul><li> is a freelance writer based in Los Angeles, California. His recent work has appeared in The New York Times,  Powder, and Outside. Follow him on Twitter <a href="https://twitter.com/mileswgriffis">@mileswgriffis</a> and see more of his work at <a href="http://www.confetti-westerns.com/">www.confetti-westerns.com</a>.
www.confetti-westerns.com</li></ul>
<p>Research by Charles Sheppard was funded by the Bertarelli Foundation.&nbsp;More information about its marine science programme can be found at&nbsp;<a href="http://www.marine.science/" target="_blank">www.marine.science</a></p>
<p>Lead image: At left, reefs in American Samoa in December 2014; at middle, those same reefs two months later, after a bleaching event; at right, the reefs in August 2015, after they've started to regenerate. Credit:&nbsp;The Ocean Agency / XL Catlin Seaview Survey</p>
    </article></div>]]>
            </description>
            <link>http://oceans.nautil.us/feature/633/coral-griefs-finding-hope-amidst-loss</link>
            <guid isPermaLink="false">hacker-news-small-sites-24966805</guid>
            <pubDate>Mon, 02 Nov 2020 11:16:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Efficient use of Apache Spark partitions: theory and use case]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24966769">thread link</a>) | @naifmeh
<br/>
November 2, 2020 | https://naifmehanna.com/2020-05-11-working-with-spark-partitions/ | <a href="https://web.archive.org/web/*/https://naifmehanna.com/2020-05-11-working-with-spark-partitions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="main">
        
          

<p>It’s been quite some time since my last article, but here is the second one of the Apache Spark serie. For those of you that are new to spark, please refer to the first part of my previous article which introduces the framework and its usages. In this article, I will show how to execute specific code on different partitions of your dataset. The use cases are various as it can be used to fit multiple different ML models on different subsets of data, or generate features that are group-specific, and more.</p>



<p>In this section, we aim to review how Spark is able to perform parallel operations on your dataset. For this purpose, we will first discuss how Spark represents your data and how this representation allows the framework to make the most of parallel computation. We will then review how Spark makes use of your cluster to distribute the data and perform actions on it. Finally, we will briefly go through how Spark organizes your actions and present some guidelines for avoiding OOMs and speed up your code.</p>

<h2 id="data-abstractions">Data abstractions</h2>

<p>Currently, Apache Spark offers three data abstractions, each with its set of pros and cons:</p>
<ul>
  <li><strong>RDDs</strong>: RDDs have been the main data abstraction on Spark since its release. It stands for Resilient Distributed Dataset. Behind these words hides the definition of what makes RDDs special: it is a <strong>resilient</strong>, <strong>partitioned</strong>, <strong>distributed</strong> and <strong>immutable collection of data</strong>.
    <ul>
      <li><strong>Resilient</strong> means that RDDs are able to recover quickly of a failure. This aspect is enforced by the immutability of the data structure (see below).</li>
      <li><strong>Immutable</strong> means that once an RDD is defined, it cannot be modified. Every action on an RDDs yields another RDD. This aspect helps RDDs be more resilient, since if one operation fails, it can revert to the previous created RDDs (to some extent).</li>
      <li><strong>Partitioned</strong>: Spark partitions your data into multiple little groups called partitions which are then distributed accross your cluster’s node. This enables parallelism.</li>
      <li>RDDs are a <strong>collection of data</strong>: quite obvious, but it is important to point that RDDs can represent any Java object that is serializable.</li>
    </ul>
  </li>
  <li><strong>Dataframe</strong>: the dataframe is based upon RDDs and has been introduced a bit later than RDDs, in Spark 1.3, with the purpose to serve for the Spark SQL module. <em>Dataframes</em> are organized into named columns and are quite close to Panda’s dataframes. Spark recommends the use of dataframes for development, but it should be noted that they offer a higher level of abstraction than RDDs and thus, their range of action is less broad. Dataframes, in the context of Spark SQL allow you to perform SQL like queries in order to play on your data.</li>
  <li><strong>Datasets</strong>: they were the latest introduction of Spark, making their grand entering in Spark 1.6. Datasets combine both the advantages of Dataframes and RDDs as one can run SQL like queries on them and also perform functional operations such as <em>mapPartitions</em> (which we will review later).</li>
</ul>

<p>So among these three data abstractions, which one should you use ?</p>

<p>Well it really depends on the level of control you want and the goal you want to achieve. Datasets are regularly a good choice to go with as it allows you to read and parallelize data the same way as RDDs and still want a structured (or semi-structured) representation of your data as Spark automatically infers your data’s representation. Plus, as we see next, Datasets emphasize both RDDs and Dataframes. For instance, a Dataframe is basically only a <em>Dataset[Row]</em><br>
Dataframes should be used if you need a high level of abstraction on your data and don’t want to mess too much with the optimization: Dataframes come with two powerful optimizers named <em>Catalyst</em> and <em>Tungsten</em>. Catalyst for instance takes your code and generates optimized physical and logical query plans. These optimizers delete by themselves useless queries, combine queries that can be executed together, etc… Going deep into these optimizers would be moving away from the subject.
Finally, I personally use RDDs only when I cannot perform my actions using Datasets or Dataframes. RDDs don’t have any optimizers to my knowledge, and can be a hassle managing as they suffer a lot of GC (Garbage Collection) issues (these issues are known to impact Datasets as well, but in a lesser way). <br></p>

<center>
<figure><img src="https://naifmehanna.com/assets/img/data_abstractions_spark.png"><figcaption>Summary of the three data abstractions and how they relate with each other</figcaption></figure>

</center>

<p>The previous picture summarizes how these three data abstractions relate to each others. Note how the Dataset seems to encapsulate both the advantages of RDDs and Dataframes. However, it also encapsulates most of their disadvantages. You can also note the reference to “encoders”: the Dataset API has this concept of <strong>encoders</strong> which can translate between JVM representations towards Spark’s internal binary format. (<a href="https://stackoverflow.com/questions/31508083/difference-between-dataframe-dataset-and-rdd-in-spark">see this SO thread for improved details</a>)</p>

<h2 id="spark-jobs">Spark jobs</h2>

<p>In this section we will rapidly review how Spark constructs its job processes and how they are effectively executed. 
Once Spark interprets and optimizes your code using Catalyst/Tungsten, containing multiple transformations leading to an action, it constructs a DAG, for Directed Acyclic Graph. This is the beginning of the Spark process.</p>

<h3 id="dags-directed-acyclic-graph">DAGs (Directed Acyclic Graph)</h3>

<p>The DAG is a graph that holds track of the operations applied to a RDD. It is a combination of edges and vertices that respectively indicate the operations and the RDDs. The DAG for each action can be seen in the SparkUI and looks this way :</p>
<center>
<figure><img src="https://naifmehanna.com/assets/img/DAG.png"><center><figcaption>DAG in the SparkUI</figcaption></center></figure>

</center>

<p>The DAG is an important scheduling layer in spark, as it converts the logical execution plan (generated by the <strong>Catalyst optimizer</strong>). 
The DAG is built following a series of lookup which (among many) separates the stages based on the transformation type:</p>
<ul>
  <li>A <strong>wide transformation</strong> involving a full shuffle of data accross partitions</li>
  <li>A <strong>narrow transformation</strong> performing map-side operations that do not require a shuffle of data.</li>
</ul>

<p>Once the DAG has performed his lookups, it genereates the <em>physical execution plan</em> containing the different tasks.</p>

<p>Among its advantages, the DAG allows for a better fault-tolerance of your application as we can recover the lost RDDs by looking up the graph.</p>

<p>But wait, we mentioned <strong>stages</strong> and <strong>tasks</strong>, but concretely, what are these ?</p>

<h3 id="stages">Stages</h3>

<p>Basically, one stage is a set of operation that does not involve a shuffle of data. As soon as a shuffle of data is needed, (when a wide transformation is performed), the DAG will yield a new stage.</p>

<center>
<figure><img src="https://naifmehanna.com/assets/img/stages.png"><center><figcaption>Stages</figcaption></center></figure>

</center>

<h3 id="tasks">Tasks</h3>

<p>A task is generated for each action performed on a partition. We can only have as many tasks running in parallel as cores we have. 
That’s all we need to know about Spark tasks for now !</p>

<h2 id="spark-partitions">Spark partitions</h2>

<p>Since we now know that Spark’s DataFrames and Datasets are both based on RDDs, our explanations will only focus on the latter.</p>

<h4 id="what-are-partitions-concretely-">What are partitions concretely ?</h4>

<p>Partitions are chunks of your original (huge) dataset which are distributed over different nodes. Basically, RDDs are a collection of multiple partitions. 
These partitions are quite easily customizable in number and in their constitution, as we will later see. <br>
By default, when an HDFS file is read, Spark creates a logical partition for every 64 MB of data but this number can be easily modified by forcing it when parallelizing your objects or by repartitioning an existing RDD, by calling the <em>.repartition()</em> or <em>.coalesce()</em> methods.</p>

<p>The <em>.repartition()</em> leads to a full shuffle of data between the executors, leading to aggressive network traffic in order to divide the data into the specified number of partitions. <br>
The <em>.coalesce()</em> operation is more optimized when it reduces the number of partitions, as it doesn’t trigger a full shuffle, but only a transfer of the data from partitions being removed to existing partitions.</p>

<p>Efficiently partitioning your data is important as a good partitioning can lead to huge speed improvement and fewer OOMs errors. This statement is even more true when your data is key-value oriented.</p>

<h4 id="how-does-rdds-become-key-value-oriented-">How does RDDs become key-value oriented ?</h4>

<p>The key-value paradigm is essential in efficient parallel data processing. Spark provides full implementation of key-value based RDD in the <em>PairRDD</em> and the <em>PairRDDFUnctions</em> classes. These classes are made available through implicit conversion, meaning that you only have to create a regular RDD of a tuple (in scala), such as RDD[(key, value)], in order to be able to take advantages of its methods. Spark also provides the <em>OrderedRDD</em> and <em>OrderedRDDFunctions</em> classes for key-value oriented RDDs for which the key is ordered. (Note that the key must either have an implicit ordering defined, or you should define your implicit ordering function).<br>
Needless to say that in order to exploit the full advantages of Spark parallelism, the partition must be created smartly, especially when we’re dealing with key-value RDDs. 
The partitioning will define how most wide transformations scale up as they mostly are key-value transformations.</p>

<h4 id="what-are-the-considerations-to-have-when-dealing-with-key-value-pairs-">What are the considerations to have when dealing with key-value pairs ?</h4>

<p>Dealing with key-value pairs should be well thought, before even starting to code as they can lead to numerous bottlenecks:</p>
<ul>
  <li>The most frequent cause of OOMs errors comes from ineficient use of key-value partitioning, either on the driver, or on the executors. For instance, a <em>.countByKey()</em> operation on a huge number of keys may lead to OOMs exceptions on the driver, while actions performed on partition belonging to keys with too much entries may lead to OOMs on the executors.</li>
  <li>Bottlenecks tasks which slow down the whole job. They happen when the dataset is very unbalanced.</li>
  <li>Shuffle failure, which are caused by wide transformation weighing on the network traffic (shuffle read/write too high).</li>
</ul>

<h4 id="can-these-problems-be-adressed-through-a-good-partitioning-">Can these problems be adressed through a good partitioning ?</h4>

<p>Totally. Well, mostly. A smart partitioning can lead to less shuffle, and a smaller toll on the executor’s memory.<br>
Also, a good architecture is essential in order to perform your actions in a smart way.</p>

<p>Having a good vision of your goal and a good …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://naifmehanna.com/2020-05-11-working-with-spark-partitions/">https://naifmehanna.com/2020-05-11-working-with-spark-partitions/</a></em></p>]]>
            </description>
            <link>https://naifmehanna.com/2020-05-11-working-with-spark-partitions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24966769</guid>
            <pubDate>Mon, 02 Nov 2020 11:12:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What if your Google account was blocked tomorrow?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24966728">thread link</a>) | @dusted
<br/>
November 2, 2020 | http://dusted.dk/pages/phlog/2020-11-02.txt | <a href="https://web.archive.org/web/*/http://dusted.dk/pages/phlog/2020-11-02.txt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://dusted.dk/pages/phlog/2020-11-02.txt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24966728</guid>
            <pubDate>Mon, 02 Nov 2020 11:05:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stressed by the News? Take a Break with the Calm News Network]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24966651">thread link</a>) | @tyayers
<br/>
November 2, 2020 | https://calmwatching.com/news | <a href="https://web.archive.org/web/*/https://calmwatching.com/news">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://calmwatching.com/news</link>
            <guid isPermaLink="false">hacker-news-small-sites-24966651</guid>
            <pubDate>Mon, 02 Nov 2020 10:53:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Finding hardcoded keys and Secrets in Mobile Apps for fun and profit]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24966263">thread link</a>) | @alaeddine
<br/>
November 2, 2020 | https://blog.ostorlab.co/hardcoded-secrets.html | <a href="https://web.archive.org/web/*/https://blog.ostorlab.co/hardcoded-secrets.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Hardcoded secret keys are a convenient target to Bug Bounty hunters and Attackers. They are easy to spot and they can
open a wide gate to sensitive data and privileged access.</p>
<p>Hardcoded secrets caused several high profile breaches in the past, notable ones are:</p>
<ul>
<li>
<p><strong>MyCar</strong>: MyCar is a vehicle telematics systems. The maker  left hardcoded credentials inside its Android and iOS
mobile apps. This left tens of thousands of cars vulnerable to hackers, who could locate car, identify them, unlock them,
start the car or trigger the alarm.</p>
</li>
<li>
<p><strong>Uber</strong>: An Uber employee published plaintext credentials within source code that was then posted on Github. 
An attacker found the embedded credentials on GitHub, then used them to gain privileged access on Uber’s Amazon
AWS Instances. The attacker then demanded a 100k$ ransom, that Uber did pay.
 The Uber breach resulted in the exposure of information of 57 million customers, plus roughly 600,000 drivers. Once the
 story became public, Uber paid a settlement of 148M$ and had to delay its IPO.</p>
</li>
<li>
<p><strong>Uniguest</strong>: Uniguest provides kiosks (PC, iMac, tablet) available in hotel lobbies (and other places). User can use
them to run simple tasks, such as browsing the web or printing boarding passes.
The API credentials were hardcoded within the application and were used to dump all the data in the Uniguest
cloud database. The data included admin credentials, router and BIOS passwords, product keys and various other sensitive information.</p>
</li>
</ul>
<p>Hardcoded secrets are also commonly reported by Bug Bounty hunters. If you check any of the different Bug Bounty programs, you will
find many disclosed reports pointing to the hardcoded keys in the <code>AndroidManifest.xml</code>, <code>Info.plist</code> or some resource file. </p>
<p>Depending on the permissions and use of the key, these vulnerabilities might be awarded up to 1k$. The severity ranges from
elevating privileges, accessing sensitive information, over-bill/theft of a service or conducting a denial of service attack.</p>
<h2>How to find and validate secrets?</h2>
<p>Secrets can be found either statically or dynamically. A common static approach is to search known patterns, for instance
searching for strings matching the following regular expression <code>AIza[0-9A-Za-z\\-_]{35}</code>:</p>
<div><pre><span></span><code>$ app8 egrep -r <span>'AIza[0-9A-Za-z\\-_]{35}'</span> . 
Binary file ./resources.arsc correspondant
Binary file ./app.apk correspondant
Binary file ./classes.dex correspondant                                
./assets/google-services-desktop.json:          <span>"current_key"</span>: <span>"AIzaSy....................."</span>
</code></pre></div>
<p>You can find in this repo <a href="https://github.com/l4yton/RegHex">l4yton/RegHex</a> a list of regular expressions to use.</p>
<p>Because not all API keys and secrets are bad or dangerous, and not all pattern outputs are correct; the keys must be checked and the
permissions, roles, scopes, and restrictions (more on that latter) must be enumerated and verified.
<code>streaak</code> published a repo <a href="https://github.com/streaak/keyhacks">streaak/keyhacks</a> listing <code>curl</code> commands to check a wide range of keys.</p>
<p>Below are some examples for Firebase keys and Facebook secrets:</p>
<div><pre><span></span><code>$ curl -s -X POST --header <span>"Authorization: key=AIzaS........."</span> --header <span>"Content-Type:application/json"</span> <span>'https://fcm.googleapis.com/fcm/send'</span> -d <span>'{"registration_ids":["1"]}'</span>
&lt;HTML&gt;
&lt;HEAD&gt;
&lt;TITLE&gt;INVALID_KEY_TYPE&lt;/TITLE&gt;
&lt;/HEAD&gt;
&lt;BODY <span>BGCOLOR</span><span>=</span><span>"#FFFFFF"</span> <span>TEXT</span><span>=</span><span>"#000000"</span>&gt;
&lt;H1&gt;INVALID_KEY_TYPE&lt;/H1&gt;
&lt;H2&gt;Error <span>401</span>&lt;/H2&gt;
&lt;/BODY&gt;
&lt;/HTML&gt;
</code></pre></div>
<div><pre><span></span><code>$ curl https://graph.facebook.com/oauth/access_token<span>\?</span>client_id<span>\=</span>51XXXX<span>\&amp;</span>client_secret<span>\=</span>0cbd4XXXXX<span>\&amp;</span>redirect_uri<span>\=\&amp;</span>grant_type<span>\=</span>client_credentials
<span>{</span><span>"access_token"</span>:<span>"5181XXXXXXXXXXXXXX"</span>,<span>"token_type"</span>:<span>"bearer"</span><span>}</span>% 
</code></pre></div>
<p>Once a key is found, the API documentation should be your best-friend to determine what permissions does it have and what
sort of actions can be performed. Take for instance instance a facebook application, you can then use the <code>https://graph.facebook.com/v8.0/{applicationId}/permissions</code> endpoint to list permissions:</p>
<div><pre><span></span><code>$ curl <span>"https://graph.facebook.com/v8.0/51XXXXXXXX/permissions?access_token=51XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"</span>
<span>{</span><span>"data"</span>:<span>[{</span><span>"permission"</span>:<span>"email"</span>,<span>"status"</span>:<span>"live"</span><span>}</span>,<span>{</span><span>"permission"</span>:<span>"pages_show_list"</span>,<span>"status"</span>:<span>"live"</span><span>}</span>,<span>{</span><span>"permission"</span>:<span>"pages_messaging"</span>,<span>"status"</span>:<span>"live"</span><span>}</span>,<span>{</span><span>"permission"</span>:<span>"groups_show_list"</span>,<span>"status"</span>:<span>"live"</span><span>}</span>,<span>{</span><span>"permission"</span>:<span>"pages_read_engagement"</span>,<span>"status"</span>:<span>"live"</span><span>}</span>,<span>{</span><span>"permission"</span>:<span>"public_profile"</span>,<span>"status"</span>:<span>"live"</span><span>}]}</span>%   
</code></pre></div>
<p>Another CLI friendly tool is Yelp's <code>detect-secret</code>: <a href="https://github.com/Yelp/detect-secrets">Yelp/detect-secrets</a>.
The tool detects a smaller subset of keys and implements validation for some a well.</p>
<p>Ostorlab automates the process of finding and checking keys and secrets and covers 53 secret types at time this article is written. 
A secret agent collects keys matching patterns or used dynamically by specific APIs or intercepted over the wire. The agent
then checks these keys to confirm if valid by iterating over all known services. </p>
<p>This a screenshot showing an example confirming a valid key and the matching service**.</p>
<p><img alt="Hardcoded secrets" src="https://blog.ostorlab.co/static/img/hardcoded_secret_keys/secret_finding.png" title="Ostorlab's report: Hardcoded Secret"></p>
<p>Just out of the last 10k apps scanned, we have reported over 200 valid secrets granting access to highly sensitive data
or critical services, like Payment or Source Code. Below are some statistics of the number of keys found per service:</p>
<table>
<thead>
<tr>
<th>Service Name</th>
<th>Count</th>
</tr>
</thead>
<tbody>
<tr>
<td>Firebase</td>
<td>35/1000</td>
</tr>
<tr>
<td>Google Cloud Platform</td>
<td>31/1000</td>
</tr>
<tr>
<td>Twitter</td>
<td>22/1000</td>
</tr>
<tr>
<td>Facebook</td>
<td>21/1000</td>
</tr>
<tr>
<td>Instagram</td>
<td>18/1000</td>
</tr>
<tr>
<td>AWS</td>
<td>18/1000</td>
</tr>
<tr>
<td>GitHub</td>
<td>14/1000</td>
</tr>
<tr>
<td>PayPal</td>
<td>5/1000</td>
</tr>
<tr>
<td>slack</td>
<td>1/1000</td>
</tr>
</tbody>
</table>
<h2>How to fix it?</h2>
<ul>
<li><strong>Embedding is Acceptable, nothing to do here</strong>: Most services provide best practices for how to use the API or secret. Some APIs are acceptable if embedded in an application. Firebase is an example:</li>
</ul>
<div><pre><span></span><code>Unlike how API keys are typically used, API keys for Firebase services are not used to control access to backend resources; 
that can only be done with Firebase Security Rules. 
Usually, you need to fastidiously guard API keys (for example, by using a vault service or setting the keys as environment variables); 
however, API keys for Firebase services are ok to include in code or checked-in config files.
</code></pre></div>
<ul>
<li><strong>Alternatives are encouraged, I should switch</strong>: Some services offer more secure alternatives to embedding credentials (such as Amazon and Google, example from <a href="https://docs.aws.amazon.com/general/latest/gr/aws-access-keys-best-practices.html">AWS recommendation</a>):</li>
</ul>
<div><pre><span></span><code>You have a mobile app. Do not embed access keys with the app, even in encrypted storage. 
Instead, use Amazon Cognito to manage user identities in your app. This service lets you authenticate users using Login with Amazon, Facebook, Google, or any OpenID Connect (OIDC)–compatible identity provider. 
You can then use the Amazon Cognito credentials provider to manage credentials that your app uses to make requests to AWS. For more information, see Using the Amazon Cognito Credentials Provider on the AWS Mobile Blog. 
</code></pre></div>
<ul>
<li><strong>Embedding is Dangerous, delegate the actions to the Server</strong>: For some services, embedding keys is an invitation to get hacked, see for instance <a href="https://stripe.com/docs/keys#safe-keys">Stripe documentation</a>. In these cases, having the server must perform the interaction with the service.</li>
</ul>
<div><pre><span></span><code>Your secret API key can be used to make any API call on behalf of your account, such as creating charges or performing refunds. 
Treat your secret API key as you would any other password. Grant access only to those who need it. 
Ensure it is kept out of any version control system you may be using. 
Control access to your key using a password manager or secrets management service.

In live mode, new secret keys are only visible the first time you access them. 
After that, the Dashboard redacts the API key. When the key is revealed, you can leave a note on the Dashboard describing the location on your own systems where you’ve copied it. 
If you lose your secret key, you can’t recover it from the Dashboard and must roll the key or create another one.
</code></pre></div>
<ul>
<li><strong>Hardening through Remote Key fetching and Key Pinning</strong>: For services that don't provide a per-user authentication service, and
need to be embedded in the application, it’s recommended to retrieve the
key from the server. It is also best practice to restrict the key's permissions (principle of least privilege).
Some service provide the possibility to PIN keys to an application or domain name. Because this 
protection is not perfect, rotating the keys is recommended to limit exposure.</li>
</ul>
<p><img alt="API Restrictions" src="https://blog.ostorlab.co/static/img/hardcoded_secret_keys/restrictions.png" title="API Restrictions"></p>
    </div></div>]]>
            </description>
            <link>https://blog.ostorlab.co/hardcoded-secrets.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24966263</guid>
            <pubDate>Mon, 02 Nov 2020 09:45:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: ML News, Like HN but for Machine Learning]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24966206">thread link</a>) | @timmyj
<br/>
November 2, 2020 | https://mln.dev/top/1 | <a href="https://web.archive.org/web/*/https://mln.dev/top/1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://mln.dev/top/1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24966206</guid>
            <pubDate>Mon, 02 Nov 2020 09:36:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HashiCorp Waypoint – End to end demo from Code to Kubernetes in minutes]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24966139">thread link</a>) | @saiyam911
<br/>
November 2, 2020 | https://www.civo.com/learn/waypoint-solving-the-build-deploy-and-release-problem | <a href="https://web.archive.org/web/*/https://www.civo.com/learn/waypoint-solving-the-build-deploy-and-release-problem">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            <div>
              <h2 id="introduction-hashicorp-waypoint">
  <a href="#introduction-hashicorp-waypoint"><i></i></a>
  Introduction - HashiCorp Waypoint
</h2>


<p>Yesterday (15 October 2020) HashiCorp launched an open source tool named Waypoint. Let us try to understand the problem statement and see how Waypoint aims to fix those. </p>

<p>HashiCorp Co-Founder and CTO Mitchell Hashimoto very rightly said during the 2020 HashiConf keynote that traditional software developer lifecycle includes different phases: Code, Test, Build, Deploy, Release, Operate and Measure. Out of this list, commonly-accepted tools for Code, Test, Operate and Measure exist, but the three areas of Build, Deploy and Relese have some challenges that Waypoint aims to solve.</p>

<p>Before we get in to the guide,I've also put together a video walkthrough which is well worth checking out...</p>

<iframe width="100%" height="420" src="https://www.youtube.com/embed/_FRiBVY1ZXI" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>On with the guide...</p>

<p>There are build systems that help you build and then deploy to specific platforms, but due to wide variety of platforms out there for application deployment, you will have to use and learn different build/deploy methods specific to the different platforms. The same goes for Release management. Now, in order to have a common workflow with ease of use across all platforms, Hashicorp has introduced <strong>Waypoint</strong>, with the aim of "providing a consistent workflow to build, deploy and release an application to any platform".</p>

<p>From the <a href="https://www.waypointproject.io/docs">docs</a> - "<strong>Waypoint</strong> is a tool that enables developers to describe how to get their applications from development to production in a single file and deploy using a single command: <code>waypoint up</code>".</p>

<p>Waypoint comes with logs and exec tools that helps you check if there are any issues with the proposed deployment. It is highly pluggable and extensible: in the image below below you can see some of the existing plugins for Docker and Kubernetes that are there by default - and the community can create and contribute more plugins.</p>

<p><img src="https://civo-com-assets.ams3.digitaloceanspaces.com/content_images/950.blog.png?1602826943" alt="Waypoint Plugins"></p>

<p>So, based on the plugins and with minimal configuration, Waypoint lets you build, deploy and release applications across platforms, saving you the hassle of having to write more lines of configuration files in different languages for different platforms.
Here are some of the resources to get you started - 
<a href="https://www.waypointproject.io/docs">Docs</a> 
<a href="https://github.com/hashicorp/waypoint/">Github</a></p>

<p>In this post I will show you how you can install and use Waypoint to build, deploy and release a sample application to a Civo Kubernetes cluster. If you have not yet signed up, you can <a href="https://www.civo.com/kube100">do so here</a> - you'll get $70 a month credit while the service is in beta.</p>

<h2 id="demo">
  <a href="#demo"><i></i></a>
  Demo
</h2>


<h3 id="deploying-a-cluster">
  <a href="#deploying-a-cluster"><i></i></a>
  Deploying a cluster
</h3>


<p>First, let's create a Civo cluster. It's easiest using the Civo <a href="https://github.com/civo/cli#set-up">CLI tool</a>, but you can also use the Kubernetes web UI in your Civo account to create it.</p>

<p>Download civo cli from <a href="https://github.com/civo/cli#set-up">here</a> </p>

<p>Configure to use by providing your API key, which you will find <a href="https://www.civo.com/account/security">here</a>.</p>

<p>Create cluster using the below command:</p>

<pre><code>civo k3s create --wait --save                           
The cluster polished-tree (6c8d2b30-496a-46d0-91bf-22124fc14f21) has been created in 2 min 53 sec
</code></pre>

<h3 id="installing-waypoint-onto-our-machine">
  <a href="#installing-waypoint-onto-our-machine"><i></i></a>
  Installing Waypoint onto our machine
</h3>


<p>You can download and install Waypoint on any platform. from your local machine to a virtual machine in the cloud. This example shows Waypoint installation on a CentOS7 box running on Civo. </p>

<p>Installing git, docker, and kubectl. Make sure you have downloaded the cluster configuration in the previous step to ~/.kube/config (if you used the command-line tool above, it will be saved in the correct place).</p>

<pre><code>yum install git -y

yum install docker -y
systemctl start docker 

curl -LO "https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl"
chmod +x kubectl 
mv kubectl /usr/local/bin/

#Check if cluster is runnning 
kubectl get nodes
NAME               STATUS     ROLES    AGE     VERSION
kube-node-1c23     Ready      &lt;none&gt;   110s    v1.18.6+k3s1
kube-node-3e04     Ready      &lt;none&gt;   110s    v1.18.6+k3s1
kube-master-5fdc   Ready      master   3m52s   v1.18.6+k3s1
</code></pre>

<p>Install and configure Waypoint for a sample repository:</p>

<pre><code>
sudo yum install -y yum-utils
sudo yum-config-manager --add-repo https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo
sudo yum -y install waypoint

git clone https://github.com/saiyam1814/waypoint-demo.git
cd waypoint-demo

waypoint install --platform=kubernetes -accept-tos
service/waypoint created
statefulset.apps/waypoint-server created
Waypoint server successfully installed and configured!

The CLI has been configured to connect to the server automatically. This
connection information is saved in the CLI context named "install-1602830444".
Use the "waypoint context" CLI to manage CLI contexts.

The server has been configured to advertise the following address for
entrypoint communications. This must be a reachable address for all your
deployments. If this is incorrect, manually set it using the CLI command
"waypoint server config-set".

Advertise Address: 91.211.154.49:9701
HTTP UI Address: 91.211.154.49:9702
</code></pre>

<h4 id="check-that-waypoint-is-running">
  <a href="#check-that-waypoint-is-running"><i></i></a>
  Check that Waypoint is Running
</h4>


<pre><code>kubectl get pods 
NAME                   READY   STATUS    RESTARTS   AGE
svclb-waypoint-qltwk   2/2     Running   0          93s
svclb-waypoint-cgvdb   2/2     Running   0          93s
svclb-waypoint-d2m4v   2/2     Running   0          93s
waypoint-server-0      1/1     Running   0          93s

</code></pre>

<h3 id="deploying-our-application">
  <a href="#deploying-our-application"><i></i></a>
  Deploying our application
</h3>


<p>Now that we have Wavpoint installed, let's initiate if for the application that is to be installed. </p>

<pre><code> waypoint init
Initial Waypoint configuration created!
No Waypoint configuration was found in this directory.

A sample configuration has been created in the file "waypoint.hcl". This
file is heavily commented to help you get started.

Once you've setup your initial configuration, run "waypoint init" again to
validate the configuration and initialize your project.
</code></pre>

<p>This creates a waypoint.hcl file with basic structure that needs to be configured as per the application. Now for our current example project, there is already a waypoint.hcl present in <code>waypoint-demo</code>directory</p>

<pre><code>project = "saiyam-waypoint"

app "saiyam-waypoint" {
  labels = {
      "service" = "saiyam-waypoint",
      "env" = "dev"
  }

  build {
   use "docker" {}
    registry {
        use "docker" {
          image = "saiyam911/cd-demo"
          tag = "1"
  }
    }
 }

  deploy { 
    use "kubernetes" {
        probe_path = "/"
        service_port = 8080
}
  }

  release {
    use "kubernetes" {
      node_port = 31769
      port = 8080
    }
  }
}
</code></pre>

<p>Let's run waypoint init </p>

<pre><code>waypoint init
âœ“ Configuration file appears valid
âœ“ Connection to Waypoint server was successful
âœ“ Project "example-nodejs" and all apps are registered with the server.
âœ“ Plugins loaded and configured successfully
âœ“ Authentication requirements appear satisfied.

Project initialized!

You may now call 'waypoint up' to deploy your project or
commands such as 'waypoint build' to perform steps individually.
</code></pre>

<p>Three main steps to notice here are build, deploy and release that have to be created and configured in order to install the application onto the cluster. You can also do customizations like provide the kubeconfig file etc. by checking the <a href="https://www.waypointproject.io/plugins">plugins documentation</a>.</p>

<p>To run all these steps, there is a simple command:</p>

<pre><code>waypoint up

Â» Building...
âœ“ Initializing Docker client...
âœ“ Building image...
 â”‚  ---&gt; f520a8e63f23
 â”‚ Step 2/4 : COPY . ./
 â”‚  ---&gt; 645a76511ab0
 â”‚ Step 3/4 : ENV PORT 8080
 â”‚  ---&gt; Running in 96cb40982097
 â”‚  ---&gt; 7f4e3ebf149d
 â”‚ Step 4/4 : CMD python name.py
 â”‚  ---&gt; Running in cbe6b9b11306
 â”‚  ---&gt; 17cc424bc5cd
 â”‚ Successfully built 17cc424bc5cd
âœ“ Injecting Waypoint Entrypoint...
âœ“ Tagging Docker image: waypoint.local/saiyam-waypoint:latest =&gt; saiyam911/cd-demo:1
âœ“ Pushing Docker image...
 â”‚ 7e453511681f: Layer already exists
 â”‚ b544d7bb9107: Layer already exists
 â”‚ baf481fca4b7: Layer already exists
 â”‚ 3d3e92e98337: Layer already exists
 â”‚ 8967306e673e: Layer already exists
 â”‚ 9794a3b3ed45: Layer already exists
 â”‚ 5f77a51ade6a: Layer already exists
 â”‚ e40d297cf5f8: Layer already exists
 â”‚ 1: digest: sha256:70f7663523f3aedf044561e079fcb27726132f40227c2da0319c475ecb20cc
 â”‚ 5b size: 6178

Â» Deploying...
âœ“ Kubernetes client connected to https://91.211.154.49:6443 with namespace default
âœ“ Creating deployment...
âœ“ Deployment successfully rolled out!

Â» Releasing...
âœ“ Kubernetes client connected to https://91.211.154.49:6443 with namespace default
âœ“ Creating service...
âœ“ Service is ready!

The deploy was successful! A Waypoint deployment URL is shown below. This
can be used internally to check your deployment and is not meant for external
traffic. You can manage this hostname using "waypoint hostname."

 Release URL: http://172.31.3.114:31769
Deployment URL: https://freely-obliging-pigeon--v1.waypoint.run
</code></pre>

<p>Boom!! The application is deployed to the Kubernetes cluster </p>

<pre><code>kubectl get pods
NAME                                                         READY   STATUS    RESTARTS   AGE
saiyam-waypoint-01emsbpmqebmamd0dvfacebf2e-849b964bc-rcw2n   1/1     Running   0          69s

kubectl get svc
NAME              TYPE        CLUSTER-IP        EXTERNAL-IP   PORT(S)          AGE
kubernetes        ClusterIP   192.168.128.1     &lt;none&gt;        443/TCP          172m
saiyam-waypoint   NodePort    192.168.174.167   &lt;none&gt;        8080:31769/TCP   35s

</code></pre>

<p>Access the Service via the URL generated - <a href="https://freely-obliging-pigeon--v1.waypoint.run/">https://freely-obliging-pigeon--v1.waypoint.run</a>
<img src="https://civo-com-assets.ams3.digitaloceanspaces.com/content_images/965.blog.png?1602875025" alt="Your Alt Text">
<img src="https://civo-com-assets.ams3.digitaloceanspaces.com/content_images/962.blog.png?1602874998" alt="Your Alt Text"></p>

<p>In just a matter of minutes Application got deployed to the cluster, make some changes in the templates/name.html file and again do  <code>waypoint up</code> and you would be able to see a new revision created. 
Let's check the waypoint UI to see more info and this is also helpful for debugging purposes -&gt; <a href="https://91.211.154.49:9702/">https://91.211.154.49:9702</a></p>

<p><img src="https://civo-com-assets.ams3.digitaloceanspaces.com/content_images/968.blog.png?1602876137" alt="Your Alt Text"></p>

<p>Click authenticate and generate temporary token:
<img src="https://civo-com-assets.ams3.digitaloceanspaces.com/content_images/971.blog.png?1602876238" alt="Your Alt Text"></p>

<pre><code>waypoint token new
bM152PWkXxfoy4vA51JFhR7LrQefsoZp5gRUr4j25i5Rrf8n3p9gceJg6WxDzXFpjqzY5Qda95b8T3zeBDaf2a38R3rZttABkeyDa
</code></pre>

<p><img src="https://civo-com-assets.ams3.digitaloceanspaces.com/content_images/974.blog.png?1602876362" alt="Your Alt Text"></p>

<p><img src="https://civo-com-assets.ams3.digitaloceanspaces.com/content_images/977.blog.png?1602876397" alt="Your Alt Text"></p>

<p>You can see all the build logs, …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.civo.com/learn/waypoint-solving-the-build-deploy-and-release-problem">https://www.civo.com/learn/waypoint-solving-the-build-deploy-and-release-problem</a></em></p>]]>
            </description>
            <link>https://www.civo.com/learn/waypoint-solving-the-build-deploy-and-release-problem</link>
            <guid isPermaLink="false">hacker-news-small-sites-24966139</guid>
            <pubDate>Mon, 02 Nov 2020 09:25:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is a billion dollars worth of server lying on the ground?]]>
            </title>
            <description>
<![CDATA[
Score 315 | Comments 307 (<a href="https://news.ycombinator.com/item?id=24966028">thread link</a>) | @george3d6
<br/>
November 2, 2020 | https://cerebralab.com/Is_a_billion-dollar_worth_of_server_lying_on_the_ground | <a href="https://web.archive.org/web/*/https://cerebralab.com/Is_a_billion-dollar_worth_of_server_lying_on_the_ground">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
        <p>Published on: 2020-11-02</p>
        
<p><em>Note: Some details of the stories in this article are slightly altered to protect the privacy of the companies I worked for</em></p>
<p>It's somewhat anecdotal, but in my work, I often encounter projects that seem to use highly inefficient infrastructure providers, from a cost perspective.</p>
<p>I usually point out that, based on a fairly unbiased hardware comparison, that they could save over half their budget by migrating, and am usually met with a series of almost canned answer about migrations being too difficult due to x,y,z.</p>
<h2>I - A representative comparison</h2>
<p>I will pick one of the "expensive" and one of the "cheap" server providers, chosen simply based on the fact that I've worked with them a lot, and compare two of their high~ish end servers.</p>
<p>I'm going to take 1 example from a cheap server provider OVH and a somewhat worst machine from AWS.</p>
<p>OVH offers <a href="https://us.ovh.com/us/order/dedicated/#/dedicated/configure-hg?product=~(dc~(gra~1)~planCode~%271901bhg~option~(~(planCode~%27cpu-2x6132-dual-2018v1~family~%27cpu~quantity~1)~(planCode~%27ram-768g-2666-dual-2018v1~family~%27ram~quantity~1)~(planCode~%27disk-960ssd-sata-2019~family~%27disk~quantity~8)))">this machine</a>:</p>
<ul>
<li>2x Intel Xeon Scalable Gold 6132 - 28c/56t - 2.6/3.7 GHz</li>
<li>768GB RAM DDR4 ECC 2666MHz</li>
<li>960GB SATA SSD</li>
<li>3 Gb/s internal and 1 Gb/s external free bandwidth</li>
</ul>
<p>For $15,800/year (though it can be paid monthly)</p>
<p>For a close comparison, AWS offers their <a href="https://aws.amazon.com/ec2/pricing/on-demand/">4.16xlarge</a>. I'll try to figure out the exact hardware specs on <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/memory-optimized-instances.html">this description</a>:</p>
<blockquote>
<p>R4 instances feature up to 64 vCPUs and are powered by two AWS-customized Intel XEON processors based on E5-2686v4 that feature high-memory bandwidth and larger L3 caches to boost the performance of in-memory applications.</p>
</blockquote>
<p>So basically let's call it 2x E5-2686v4, though the "real" E5-2686v4 seems to have more cores (both real and virtual) than the AWS version, I'll give AWS the benefit of the doubt and say that their version is more or less the same. I'll also assume AWS's RAM is the same 2666MHz DDR4 EEC2 (basically the best you can get right now) though they don't specify this, but I'll be generous here.</p>
<p>So we have:</p>
<ul>
<li>2x Intel Xeon E5-2686v4 - 36c/72t - 2.3/3.0 GHz</li>
<li>488GB RAM DDR4 ECC 2666MHz</li>
<li>Storage paid for separately</li>
<li>Bandwith paid for separately</li>
</ul>
<p>For $37,282/year (paid hourly) or $25,771/year (paid upfront)</p>
<p>The OVH server has more memory, it comes with 1TB of very fast storage, and adding more storage is much cheaper than AWS EBS prices (+ you get the option for NVME SSDs connected via PCIe on all servers).</p>
<p>I chose two processors which are <em>fairly</em> similar but running a comparison is still hard. Unlike e.g. RAM, processors are much more synergistic, you can't just look at parameters like nr cores, cache size, and frequency to figure out how well they perform.</p>
<p>Still, these two seem to be pretty close on those parameters and when looking at <a href="https://www.cpubenchmark.net/compare/Intel-Xeon-E5-2686-v4-vs-Intel-Xeon-Gold-6132/2870vs3227">the benchmarks</a>. It seems that the Gold 6132 is marginally better than the E5-2684-v4. Granted, benchmarking server CPUs is hard, but still, I think it's fair to say that the former has at least a tiny advantage, even if somehow the E5-2684 performs worst of benchmarks than on "real tasks".</p>
<p>So we have 2 servers:</p>
<ul>
<li>Both are in Paris</li>
<li>One has 768GB of RAM the other 488GB (58% of the first one) with the same specs</li>
<li>One has an extremely to slightly better CPU (let's say 10% better, a bit bellow the ~17% claimed by the benchmarks)</li>
<li>One has free bandwidth, the other one charges you for every single Kb of communication with the outside world (though at a fairly small sum)</li>
<li>One comes with 1TB of very fast NVME storage, for the other one you have to pay extra</li>
<li>One is paid monthly, the other one yearly or hourly.</li>
</ul>
<p>If the first server, the one that is better in literally every way, costs ~16k/year... how much should the other one cost? Well, maybe 10, maybe 12, maybe 14?</p>
<p>I don't know, but the answer certainly shouldn't be "Almost twice as much at 26k/year", that's the kind of answer that indicates something is broken.</p>
<p>In a worst-case scenario, AWS is ~1.6x times as expensive, but again, that's paid yearly. If we compare paid monthly to paid hourly (not exactly fair) we get 37k vs 16k, if we do some <a href="https://aws.amazon.com/ebs/pricing/">napkin math calculations</a> for equivalent storage cost (with equivalent speed via guaranteed iops) we easily get to ~3k/year extra. We have a 40k vs 16k difference, the AWS machine with the worst specs is 250% more expensive.</p>
<p>But whether the worst AWS machine is 160% or 250% as expensive as the OVH one is not the relevant question here, the question is why are we seeing those astronomical differences in terms of cost to being with.</p>
<p>We should consider there are hosting providers cheaper than OVH (e.g. scaleway, potentially online.net, and other such providers you never heard of). On the flip side of the coin, there are server providers such as digital oceans, GC, and Azure that can be more expensive than AWS.</p>
<p>Why?</p>
<h2>II - Vendor lock-in hypothesis</h2>
<p>The easiest thing to do here is to cry vendor lock-in.</p>
<p>The story goes that you end up using firebase for authentication, then you hire a sysadmin / DevOps guy that knows GC to create your infrastructure there. Then you make use of some fancy google ML service that integrates seamlessly with the GC storage... so on and so forth, until it would cost you a lot more manpower to move away from GC than to pay them a bit extra for whatever compute or storage you could get for less elsewhere.</p>
<hr>
<p>This is compounded by the fact that most of the time startups are oblivious to the cost of these services.</p>
<p>I switched my personal "infrastructure" from AWS since it ended up costing me over $100/month to maintain. Nowadays I pay $23/month and get a lot more leeway out of my current setup. But I haven't done that with some startups I've worked with or advised, even though the cost savings could have one or two additional zeros added to them. Why?</p>
<p>I can often call the shots regarding hardware at the startups I've worked with, yet I usually can't argue against using AWS or GC... because often enough, the first hit is free. AWS, GC, and Azure are throwing out 10k$ worth of credits like candy, and topping that off with 50-200k$ worth of credit for startups that they think have potential. The catch here is that the credits expire in 1 year, and once that year is done many are probably locked into the vendor.</p>
<p>The startup model is one of exponential growth, most fail and the winners have dozens or hundreds of millions from investments. So what is one or two hundred thousand a year on an IaaS bill?</p>
<p>Well, the answer is almost nothing. I believe the standard AWS offering for free credits is something like 100k$/year. So assuming a startup that uses that for a year gets 10mil in investment, it costs them 1% of their budget a year to maintain that.</p>
<p>The problem is that investment reflects future potential worth, a startup receiving a 10 mil investment is probably operating at a small fraction of the capacity those investors hope it will reach. For the shares to be worth 5x time that original investment, the company might have to scale its operations 20x or 50x, or 100x.</p>
<p>This becomes a problem since you can't run on investment forever, and scaling up 20x suddenly turns that 100k into 2 million a year spent on servers.</p>
<p>Of course, this is just a hypothetical, the numbers here are stand-ins to make a point, not a case-study. From my own experience, that the lock-in funnel looks something like:</p>
<ol>
<li>Free credits, let's use {expensive infrastructure provider}.</li>
<li>Loads of investment money, let's not waste time switching away from {expensive infrastructure provider}, it's &lt; 1% of our yearly budget.</li>
<li>Turns out that once the company grew, {expensive infrastructure provider} now consists of a double-digit percentage of our yearly expenditure, but it's too late to switch now.</li>
</ol>
<hr>
<p>This situation is exacerbated by consolidation (big fish buys little fish). I vividly remember a situation where I found an optimal hardware+software combination for a data processing platform, I think a conservative estimate would be that it was ~5 times cheaper than the vendor lock-in alternative being used at the time.</p>
<p>This happened to make it worth the switch since the startup lacked a generous credit offer for Google cloud. But, as soon as it was "consolidated", I was forced to switch the whole system back to Google cloud, granted a much better GC setup, but one that still involved costs ~2-3x times greater than the original solution.</p>
<p>Why? Well, boils down to the parent company using Google cloud, all their employees knowing how to work with GC, all their contracts having weird security-related clauses composed by many lawyers based on "official security audits" ran on their GC infrastructure, and so on.</p>
<p>However, this leads nicely into my second hypothesis.</p>
<h2>III - Employee lock-in hypothesis</h2>
<p>Employees end up deciding most of what a company is using internally, including infrastructure providers.</p>
<p>People aggregate <a href="https://slatestarcodex.com/2014/09/30/i-can-tolerate-anything-except-the-outgroup/">along weird lines</a>, to the extent that it wouldn't surprise me if a CTO hired initial engineers that favored his preferred infrastructure provider, even if he didn't actively seek that trait out.</p>
<p>Once the first few employees are fans of a given infrastructure provider, it starts making it into the job specs, because onboarding someone familiar with AWS when you use Azure is a huge pain in the ass. All other things being equal you'd rather have someone familiar with the technology you are already using.</p>
<p>This is compounded by the kind of employees that permeate a given field. If you are developing mobile apps or web apps, for example, it's likely that many engineers you will find will be familiar with Heroku and Digital Oceans. If you are developing whatever the heck people use C# for, I'd bet you'll find people that know how to use Azure. If you are doing machine learning, most people will know a thing or two about google cloud's offers regarding TPUs.</p>
<p>More broadly, this leaves no room for people that want to have a "multi-cloud" infrastructure or use a very little known platform. Either you get engineers that are very versed in the subject, but that will cost extra. Or you consign to having a few experts on the subject handle everything, with the rest of the team having no idea how to boot up a new VM without calling someone up.</p>
<p>Of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cerebralab.com/Is_a_billion-dollar_worth_of_server_lying_on_the_ground">https://cerebralab.com/Is_a_billion-dollar_worth_of_server_lying_on_the_ground</a></em></p>]]>
            </description>
            <link>https://cerebralab.com/Is_a_billion-dollar_worth_of_server_lying_on_the_ground</link>
            <guid isPermaLink="false">hacker-news-small-sites-24966028</guid>
            <pubDate>Mon, 02 Nov 2020 09:09:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build a Collaborative Chatbot with Google Sheets and TensorFlow]]>
            </title>
            <description>
<![CDATA[
Score 93 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24966013">thread link</a>) | @jonathanbgn
<br/>
November 2, 2020 | https://jonathanbgn.com/nlp/2020/09/29/chatbot-universal-sentence-encoder.html | <a href="https://web.archive.org/web/*/https://jonathanbgn.com/nlp/2020/09/29/chatbot-universal-sentence-encoder.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><img src="https://jonathanbgn.com/assets/images/taipei.jpg" alt="Taipei"></p>

<p>Currently living in Taiwan, I recently joined the <a href="https://github.com/taiwangoldcard/taiwan-bot">Taiwan Bot 🤖</a> project along with <a href="https://www.linkedin.com/in/shawn-lim-0a307550">Shawn</a> and <a href="https://erickhun.com/about/">Eric</a>. The idea is to build a go-to assistant to help foreigners answer their questions about moving to, working, and living in Taiwan (pro-tip: ask the bot where to find cheese or chocolate).</p>

<p>Building a functional and useful chatbot is a non-trivial project. Fortunately, there has been impressive progress in the fields of machine learning and <strong>natural language processing (NLP)</strong> in the past few years. Moreover, the democratization and open-source sharing of cutting-edge deep learning models from research work at large tech companies like Google or Facebook is making it possible for anyone to implement the latest state-of-the-art solutions.</p>

<p>The <a href="https://ai.googleblog.com/2018/05/advances-in-semantic-textual-similarity.html">Universal Sentence Encoder</a>, recently released by Google AI, is one of these new models available via <a href="https://tfhub.dev/google/universal-sentence-encoder/4">Tensorflow Hub</a>. Trained in a <strong>multi-tasking</strong> fashion, the model can encode sentences into meaningful continuous representations that work well on a range of different tasks. It is thus ideal for <strong>transfer learning</strong> and performs competitively with more complex models like <a href="https://en.wikipedia.org/wiki/BERT_(language_model)">BERT</a>. Moreover, it can run much faster than BERT or other similar <a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)">Transformer</a> models and is thus more applicable to real-world problems. There is even a <a href="https://tfhub.dev/google/universal-sentence-encoder-lite/2">Lite version</a> of the model, small enough to run in Javascript on the client-side.</p>

<h2 id="the-project">The project</h2>

<p>Despite being an amazing place to live, <strong>Taiwan is still misunderstood by most foreigners</strong>. We think that a fun and approachable chatbot could help people understand a lot more about all the great things this place has to offer, as well as answer most of the questions they might have about living here.</p>

<p>We decided to start with a limited scope first and to focus on answering practical questions about moving to and living in Taiwan. Specifically, we chose to focus on visa issues and the recently created <a href="https://taiwangoldcard.com/">Gold Card program</a>. We plan to expand the bot capabilities in future versions.</p>

<p>When it comes to chatbots, there are a lot of ways to go, and many tools and libraries out there to help you make your plan a reality. However, being just a small team of 3 doing this in our spare time, we didn’t have enough resources and time to build something very sophisticated. We also didn’t want to spend a lot of time to compile a large training dataset. So we looked for the best way to build a system that would be:</p>

<ul>
  <li>🧩 Easy and quick to build</li>
  <li>⚡️ Lightweight and runnable on a small server</li>
  <li>🔧 Iterable and easy to improve</li>
  <li>🧠 Focused on finding relevant answers</li>
</ul>

<p>We chose to build our bot with Microsoft’s <a href="https://github.com/microsoft/botframework-sdk">Bot Framework SDK</a> for easy development, user management and to be able to easily publish it to multiple platforms like Messenger or Line, the most popular messaging platform in Taiwan. <strong>The only thing remaining was to build the brain behind the messages.</strong></p>

<h2 id="understanding-the-meaning-behind-a-question">Understanding the meaning behind a question</h2>

<p>The main challenge when building a bot is <strong>relevancy</strong>, and this starts by having a clear understanding of what the user’s intention is. There are many approaches possible to make sense of what the user wants. At the most simple, one could simply look for some keywords such as <code>hello</code>, <code>restaurant</code>, or <code>visa</code>. However, this doesn’t take at all into account all the nuances of the language.</p>

<p>We didn’t have the resources to build a full-scale bot that could recognize the user intention among thousands of possibilities, yet we wanted to create something that could be relevant enough so that people would find it useful. So we needed to find an ideal middle ground between complexity and performance.</p>

<p>One of the most important concepts in NLP is one of <strong>distributed representations</strong>, inspired by the linguistic field of <a href="https://en.wikipedia.org/wiki/Distributional_semantics">distributional semantics</a>. The core idea is to encode linguistic items (words, sentences) into <strong>embeddings</strong> (vectors in a large dimensional space) such that items with similar properties should be closer in the resulting space.</p>

<blockquote>
  <p>You shall know a word by the company it keeps.</p>

  <p><em>- John Rupert Firth (1957)</em></p>
</blockquote>

<p>For example, similar words will cluster together in the vector space:</p>

<p><img src="https://jonathanbgn.com/assets/images/word-embeddings.png" alt="Word Embeddings"></p>

<p><em>Image from <a href="https://blog.tensorflow.org/2020/08/introducing-semantic-reactor-explore-nlp-sheets.html">TensorFlow Blog</a></em></p>

<p>You could do the same as the above but with sentences, effectively encoding them into large vectors which can be compared between themselves using <strong>similarity functions</strong>. Hence sentences with similar vector representations are sentences with similar meaning, topic, syntax…</p>

<h2 id="encoding-questions-with-the-universal-sentence-encoder">Encoding questions with the Universal Sentence Encoder</h2>

<p>The <a href="https://arxiv.org/abs/1803.11175">Universal Sentence Encoder</a> is a powerful Transformer model (in its large version) allowing to extract <a href="https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture">embeddings</a> directly from sentences instead of from individual words. It already powers some impressive Google projects such as <a href="https://books.google.com/talktobooks/">Talk to Books</a> or <a href="https://google.github.io/mysteryofthreebots/">Mystery of the Three Bots</a>.</p>

<p>For our chatbot project, we are first using the model to encode all the questions that we think users would want to ask to the bot. This can be done in a few lines of code thanks to the convenient TensorFlow Hub library:</p>

<div><div><pre><code><span>import</span> <span>tensorflow</span> <span>as</span> <span>tf</span>
<span>import</span> <span>tensorflow_hub</span> <span>as</span> <span>tfhub</span>

<span>model</span> <span>=</span> <span>tfhub</span><span>.</span><span>load</span><span>(</span><span>"https://tfhub.dev/google/universal-sentence-encoder/4"</span><span>)</span>

<span>questions</span> <span>=</span> <span>[</span> <span>...</span> <span>]</span>  <span># questions most likely to be asked to the bot
</span><span>answers</span> <span>=</span> <span>[</span> <span>....</span> <span>]</span>  <span># all answers to the questions above
</span>
<span>batch_size</span> <span>=</span> <span>10</span>
<span>embeddings</span> <span>=</span> <span>[]</span>
<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>0</span><span>,</span> <span>len</span><span>(</span><span>questions</span><span>),</span> <span>batch_size</span><span>):</span>
    <span>embeddings</span><span>.</span><span>append</span><span>(</span><span>model</span><span>(</span><span>questions</span><span>[</span><span>i</span><span>:</span><span>i</span><span>+</span><span>batch_size</span><span>]))</span>
<span>questions_embeddings</span> <span>=</span> <span>tf</span><span>.</span><span>concat</span><span>(</span><span>embeddings</span><span>,</span> <span>axis</span><span>=</span><span>0</span><span>)</span>
</code></pre></div></div>

<p>Then whenever a user asks a question, we can just extract its embedding and find the most similar question in our database of embeddings. In our case we use a simple vector dot product as a similary function:</p>

<div><div><pre><code><span>def</span> <span>find_best_answer</span><span>(</span><span>question</span><span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
    <span>embedding</span> <span>=</span> <span>model</span><span>([</span><span>question</span><span>,])</span>
    <span># compute dot product with each question:
</span>    <span>scores</span> <span>=</span> <span>questions_embeddings</span> <span>@</span> <span>tf</span><span>.</span><span>transpose</span><span>(</span><span>embedding</span><span>)</span>

    <span>return</span> <span>answers</span><span>[</span><span>np</span><span>.</span><span>argmax</span><span>(</span><span>tf</span><span>.</span><span>squeeze</span><span>(</span><span>scores</span><span>).</span><span>numpy</span><span>())]</span>
</code></pre></div></div>

<h2 id="google-sheets-as-a-collaborative-database">Google Sheets as a collaborative database</h2>

<p>We built our dataset using a simple Google spreadsheet with 2 columns: questions and answers. Whenever a user asks a question, we just find the most relevant question and return the appropriate answer.</p>

<p><img src="https://jonathanbgn.com/assets/images/taiwan-bot-database.png" alt="Questions Answers Dataset"></p>

<p>This approach, while relatively simple, is a flexible enough for efficiently working together. Querying the data is done once during startup with a few lines of code:</p>

<div><div><pre><code><span>client</span> <span>=</span> <span>gspread</span><span>.</span><span>authorize</span><span>(</span>
    <span>ServiceAccountCredentials</span><span>.</span><span>from_json_keyfile_dict</span><span>(</span><span>SERVICE_ACCOUNT_INFO_DICT</span><span>,</span>
        <span>[</span><span>'https://spreadsheets.google.com/feeds'</span><span>,</span><span>'https://www.googleapis.com/auth/drive'</span><span>])</span>
<span>)</span>
<span>sheet</span> <span>=</span> <span>client</span><span>.</span><span>open</span><span>(</span><span>SPREADSHEET_FAQ_FILE</span><span>).</span><span>worksheet</span><span>(</span><span>SPREADSHEET_SHEET_NAME</span><span>)</span>
<span>questions</span> <span>=</span> <span>list</span><span>(</span><span>map</span><span>(</span><span>str</span><span>.</span><span>strip</span><span>,</span> <span>sheet</span><span>.</span><span>col_values</span><span>(</span><span>1</span><span>)[</span><span>1</span><span>:]))</span>
<span>answers</span> <span>=</span> <span>list</span><span>(</span><span>map</span><span>(</span><span>str</span><span>.</span><span>strip</span><span>,</span> <span>sheet</span><span>.</span><span>col_values</span><span>(</span><span>2</span><span>)[</span><span>1</span><span>:]))</span>
</code></pre></div></div>

<p>Here is an example of a conversation with the bot:</p>

<p><img src="https://jonathanbgn.com/assets/images/taiwan-bot-conversation.jpg" alt="Conversation with the bot"></p>

<h2 id="continuous-improvement">Continuous improvement</h2>

<p>We did our best to think about what would be the most commonly asked questions but, of course, we cannot predict everything people will ask. This is why if you ask a question that is not present in our database, the bot can answer with something completely unrelated. To prevent this, we built a small logging system to be able to track the questions asked to the bot and which question it thought was the most similar (along with the similarity score).</p>

<p>For example, here is what happened behind the scenes during the small conversation above. The first column is the user message. The second column is the most similar question (as based on the embeddings similarity). The third column is the best answer and the last column the computed similarity score. If the similarity score is not good enough, the bot will answer with a generic reply <em>” Sorry, I cannot help with that yet “</em>.</p>

<p><img src="https://jonathanbgn.com/assets/images/taiwan-bot-logs.png" alt="Conversation Logs"></p>

<p>This logging system will also help us improve our answers as more people use the bot and new edge cases are found. Still, no chatbot is perfect, and we think the bot will be most useful in a context where humans can take over when the bot fails. For example, on Slack, we added the bot to a general FAQ channel where people can get assistance from both the bot and humans for more specific information.</p>

<p><img src="https://jonathanbgn.com/assets/images/taiwan-bot-slack.png" alt="Chatbot on Slack"></p>

<h2 id="conclusion">Conclusion</h2>

<p>Building an effective chatbot doesn’t have to be a complex project. As long as the scope is relatively narrow, it is possible to use a general encoder model like the Universal Sentence Encoder to build something useful. The hard part is collecting enough questions/answers for the bot to be able to answer most questions. It is also important to regularly monitor what users are asking and complement new data whenever the bot can’t find a relevant answer.</p>

<p>If you are also living or considering to move to Taiwan, you can <a href="https://m.me/thetaiwanbot">chat with Taiwan bot on Messenger here</a>!</p>

<h3 id="read-next">Read next</h3>

<p><a href="https://jonathanbgn.com/nlp/2020/08/30/gpt2-gpt3-creativity.html">Unleash GPT-2 (and GPT-3) Creativity through Decoding Strategies</a></p>

<p><a href="https://jonathanbgn.com/speech/2020/10/31/emotion-recognition-transfer-learning-wav2vec.html">Detecting Emotions from Voice with Very Few Training Data</a></p>

  </div>
  
  
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://jonathanbgn.com/nlp/2020/09/29/chatbot-universal-sentence-encoder.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24966013</guid>
            <pubDate>Mon, 02 Nov 2020 09:05:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You might not need to store plaintext email addresses]]>
            </title>
            <description>
<![CDATA[
Score 242 | Comments 155 (<a href="https://news.ycombinator.com/item?id=24965671">thread link</a>) | @danielskogly
<br/>
November 2, 2020 | https://blog.klungo.no/2020/11/01/you-might-not-need-to-store-plaintext-emails/ | <a href="https://web.archive.org/web/*/https://blog.klungo.no/2020/11/01/you-might-not-need-to-store-plaintext-emails/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Earlier this year, when I went from having only Facebook-login on <a href="https://wishy.gift/">Wishy.gift</a> to allow registrations with email address and password, one of my concerns was how to implement this is a way that protects the data and privacy of my users. I don’t have any ads or analytics on the site, the users can select whatever display name they want, and I never stored the email addresses I got from Facebook when a user registered or logged in - only a hashed<sup><a href="#fn1" id="fnref1">[1]</a></sup> version of the ID. Email addresses and passwords, on the other hand, are a whole other beast, and the consequences of a database breach much worse.</p>
<p>Considering that the only kind of emails I ever need to send out are transactional - no newsletters or other kinds of notifications - the only thing I need to store them for are as identifiers, and can safely be hashed.</p>
<p>For every transactional email I need to send out - registration, account recovery, and email change verification - the user always initiates this by submitting their email address, and it will at that time be available to the backend to perform the needed action.</p>
<p>In conclusion, if you only use email addresses for transactional emails, you might be able to only store hashed versions of them. For <a href="https://wishy.gift/">Wishy.gift</a> I use SHA512 with a fixed salt, and this has been working perfectly since implementation in June.</p>
<p>Thank you for reading this! I would love to hear your thoughts and ideas too. Join the discussion on <a href="https://news.ycombinator.com/item?id=24959734">Hacker News</a>, or feel free to email me at <code>daniel</code> at the domain this blog is on.</p>
<hr>
<section>
<ol>
<li id="fn1"><p>I discovered that, even though the ID was unique to my FB-app, it was still possible to go to <a href="http://facebook.com/%7Bid%7D">facebook.com/{id}</a> and be redirected to the user’s FB-profile. <a href="#fnref1">↩︎</a></p>
</li>
</ol>
</section>
</div></div>]]>
            </description>
            <link>https://blog.klungo.no/2020/11/01/you-might-not-need-to-store-plaintext-emails/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24965671</guid>
            <pubDate>Mon, 02 Nov 2020 08:11:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[As an older guy I've finally figured out weight-loss]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 112 (<a href="https://news.ycombinator.com/item?id=24965631">thread link</a>) | @RikNieu
<br/>
November 2, 2020 | https://www.riknieu.com/the-best-way-to-lose-weight/ | <a href="https://web.archive.org/web/*/https://www.riknieu.com/the-best-way-to-lose-weight/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>This post isn't really product or development related, but I think it applies to lots of us desk-job types. Hopefully it'll help someone else who's struggling just as much as I was.</p><h2 id="first-my-results-and-progress-so-far">First my results and progress so far</h2><p>I started getting serious about my diet at the end of September 2020. I weighed about 80kg/176lbs. </p><p>Today, on 1 Nov 2020, I weighed about 74kg/163lbs. </p><figure><img src="https://www.riknieu.com/content/images/2020/11/Screenshot-2020-11-01-at-17.09.12.png"><figcaption>My weight-loss chart 20 Sept - 1 Nov</figcaption></figure><p>That's a loss of 6kg/13lbs in a bit over a month! Insane! I would never have dreamt it possible for a middle-aged guy like me, who doesn't exercise too much and sits behind a computer all day to pull something like that off.</p><p>My journey is far from complete, but the progress I've had up to now is exciting enough to share. This would likely(hopefully) be the first in a series of posts detailing my weight-loss journey.</p><h2 id="the-backstory">The backstory</h2><p>I've never had a flat stomach in my entire life. Not when I was a kid, not when I was a young adult, and certainly not now, in my almost middle-age.</p><p>And I'm not even talking about having that shredded, six-pack look like the guys on the MensHealth covers, I'm just talking about a regular, flat tummy that doesn't bulge out in vague convex shape. I've always hovered between almost obese to dad-bod at best.</p><p>I've been self-conscious about my weight since forever. Being the fat kid in the 80s, when most kids weren't overweight yet left it's mark on my psyche and self-esteem. I got noticed and bullied for it, often. It also didn't help that my skin was pale enough to trip the sun when I took my shirt off on the beach.</p><p>All jokes aside, being able to swim in public without a shirt on has just never been in the realms of conceivability for me. The shame is too great.</p><p>Society, my community and my peers have made it very clear, since a young age, that nobody wants to see that shit. In fact, I don't think I've been in any form of public water without a shirt on since the age of 10. Maybe even earlier.</p><h2 id="when-the-dough-starts-to-rise">When the dough starts to rise</h2><p>I've learned to live with it, of course. The pale skin, the belly - it's not that bad. I mean, I've still managed to convince a poor, unsuspecting soul to be my wife. I still had fun outdoors. And getting older means nobody really cares about my appearance anymore, at least not to my face. Being doughy is not ideal but it's not that big a deal either.</p><p>I always assumed it's just the genetic cards I've been dealt, my unique biology or some sort of weird hormonal thing. This made sense to me because most of my extended family are overweight, and dangerously so. Maybe we're just built to look like this.</p><p>This idea might have a sliver of truth to it - I personally know people who look fit and fabulous without any seeming effort and who can eat whatever they like. </p><p>I, however, seem to gain weight by just looking at delicious food. But if I'm honest, declaring it impossible to slim down due to my genes might have just been a convenient excuse. </p><p>On my 38th birthday this year, I reflected on this, and the fact that my 40s were rapidly coming into view. I can see it emerging just over the horizon, arms and legs pumping as it's sprinting towards me. Soon.</p><p>I wasn't concerned with becoming unattractive with age(I've never been considered attractive anyway) but using my family history as a rough model for extrapolation suggested that the physical shape I was in then was past the point of good-as-it-would-ever-be. Other thoughts circled around, about getting older, about my losing my health, mobility and vitality. </p><p>And the signs were certainly there. My weight and pant size had already started creeping up over the last couple of years. </p><p>I wasn't obviously overweight, don't get me wrong. Most people would have considered my weight quite normal, perhaps even slim when compared to most of society. </p><p>But the trend in measurements suggested that my future would involve an ever-increasing waistline, with the eventual addition of tent-like shirts, feebly trying to conceal the obvious. </p><p>Yep, the coming years would see me getting rounder, wrinklier and unhealthier. Not paler though, that wouldn't be possible. This bun could never be baked, my genes won't allow for it.</p><h2 id="middle-age-is-looming-let-s-set-a-crazy-goal-">Middle-age is looming - let's set a crazy goal!</h2><p>To my credit though, I did realise that being middle-aged didn't mean it's game over yet. Perhaps I could still steer this ship around, if I just put my mind to it.</p><p>I won't ever become that tasty, handsome dish that turns heads, but perhaps I could aim for a relatively healthy, strong, utilitarian body? Like Sean Connery(RIP) in those first James Bond films. Old-school fit.</p><p>And with that musing, on the eve of my biological new year, I made the resolution to give it one last, genuine shot. </p><p>I would do my best to attempt a solid, last-ditch effort in getting my stomach flat. My goal is cultivating an appearance that I won't necessarily want to show off, but that I'd at least not feel the need to cover up and hide.</p><p>The idea is too sport, by the end of this year or early the next, a completely flat stomach without having to suck it in. And I would endeavour to keep it that way, perpetually, for the foreseeable future.</p><p>This will be hard, and I know it. I've been down this road before. Though I was comfortable plump my whole life, I am no stranger to diets and exercise. I know them well.</p><h2 id="the-revolving-door-of-fad-diets">The revolving door of fad diets </h2><p>In fact, I've tried almost every diet you can think of - keto, vegetarian, calorie counting, Fit-For-Life, caveman, paleo diet, slow carb... you name it, I probably tried it. And I've had various levels of success, but none left me with consistent, long-lasting results. Never mind washboard abs.</p><p>At best I'd maybe lose a couple of kilos, hit the inevitable plateau, and then give up out of frustration and resentment. Or I'd start feeling feeble and sick, suffer from weak concentration, or just feel generally miserable.</p><p>There was also the issue of inevitable birthdays and celebrations interfering, where I didn't want to be a party-pooper, or deny myself life's simple pleasures either, but which then would usually result in me falling off the bus. </p><p>And the cheat days too. Not often, maybe once or twice on weekends. Those, I told myself, would be needed to keep myself sane and motivated, to keep the cravings at bay. But they were a trap. Cheat day's may not add more weight, but they certainly stop any progress dead in its tracks.</p><p>Then there's exercise. Although my foray into the myriad of options available were not as extensive as with diets(due to some personal health limitations), my results - or lack thereof - were similar.</p><p>I tried to do some form of exercise at least 3 times a week. These included rollerblading with the wife, bodyweight routines, weight lifting, martial arts, walks and even the infernal torture that is running. </p><p>Exercise seemed to have <em>some</em> effect on sharpening my curves, but had no measurable effect on the scale.</p><p>Safe to say, it was pretty daunting to decide to commit to yet another version of this whole rigmarole again. When you feel you've tried everything before, you're skeptical this time would be different. Which diet would I be following this time, which training schedule?</p><p>I could feel that "it's just genetics" excuse looming just behind my shoulder, smugly waiting to tell me, "I told you so. It's pointless."</p><p>But this is what I wanted to do, so I decided to break it down and approach it from first principles, or at the very least keep it dead simple.</p><h2 id="best-way-of-losing-weight-science-simplicity-patience-and-discipline">Best way of losing weight? Science, simplicity, patience and discipline</h2><p>First principles suggested I stop faffing around with diets that operate on clever narratives, assumptions and "magic" rules, and just look at what the science said. And the science was pretty consistent - calories matter above all else. </p><p>The majority of studies suggested that for most people, the amount of calories consumed determines your weight. Hormonal factors exist, but they're either negligible or applicable to a very, very, VERY small part of the population. You're likely not it.</p><p>Exercise does help, but in the modern world with its convenient packaged foods one can easily consume way more calories in a single day than you could realistically burn off in a week of exercising. And if you're not cognisant of the calories in your meals and snacks, you won't even know it when you're over-consuming.</p><p>Now, of course I've tried calorie counting before, and it worked alright, but still lead to the inevitable plateau and quit cycle. This was something I'd need to be mindful of. I'd need to be strict to the max.</p><p>I decided that this time I was going to be <em>extremely</em> disciplined and committed. The only bending of rules would be cheat meals(not days) on birthdays or other rare and special occasions. Not weekly, like I weaselled about with before. No other cheating would be tolerated at all.</p><p>And for exercise it would be just as simple. I would do weight training 3x a week, ala <a href="https://startingstrength.com/">Starting Strength</a>, because it's the only form of exercise I actually enjoy doing. That's it. Beyond that would just be whatever recreational activities we did with friends over weekends.</p><h3 id="calories-energy-in-energy-out">Calories - energy in, energy out</h3><p>I'm not going to give you a lecture on calories and the intricacies behind their workings in this post, you can look it up yourself. </p><p>The <em>only</em> thing you need to know to successfully lose weight is that you need to consume less calories than your body requires to maintain its current weight. That's it. And, of course, you need to muster the discipline or come up with hacks to stick to it.</p><p>"Not all calories are equal!", I hear some of you seethe, and yes, I've considered that too. I took it into account for this experiment as well. It will be addressed below.</p><h2 id="weight-loss-plan">Weight-loss plan</h2><h4 id="5-steps-calculate-adjust-simplify-measure-patience">5 Steps - calculate, adjust, simplify, measure, patience</h4><p><strong>Calculate</strong> - Google and find a free calorie calculator online, enter your particular details, and calculate the amount of daily calories you need to maintain your current weight. </p><p><strong>Adjust</strong> - To lose weight you need to reduce the amount of daily calories you consume. Take the …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.riknieu.com/the-best-way-to-lose-weight/">https://www.riknieu.com/the-best-way-to-lose-weight/</a></em></p>]]>
            </description>
            <link>https://www.riknieu.com/the-best-way-to-lose-weight/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24965631</guid>
            <pubDate>Mon, 02 Nov 2020 08:02:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I Replaced Google Analytics with a Open-Source and Self-Hosted Alternative]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24965574">thread link</a>) | @mokkapps
<br/>
November 1, 2020 | https://www.mokkapps.de/blog/how-i-replaced-google-analytics-with-a-private-open-source-and-self-hosted-alternative/ | <a href="https://web.archive.org/web/*/https://www.mokkapps.de/blog/how-i-replaced-google-analytics-with-a-private-open-source-and-self-hosted-alternative/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>For me, it is important to see analytics about my portfolio website. This way, I can see which posts got the most views, which country my users are from, and which browser &amp; operating system they are using.
The simplest solution to add analytics to your site is <a href="https://analytics.google.com/analytics/web/" target="_blank" rel="noopener noreferrer">Google Analytics</a> as it is free and easy to set up. But as we all know, this service is only free
as we pay it indirectly by providing data to it. <a href="https://www.comparitech.com/blog/vpn-privacy/google-analytics-privacy/" target="_blank" rel="noopener noreferrer">What you need to know about Google Analytics and privacy</a>.</p>
<p>In this blog post, I will show you how I replaced <a href="https://analytics.google.com/analytics/web/" target="_blank" rel="noopener noreferrer">Google Analytics</a> with <a href="https://umami.is/" target="_blank" rel="noopener noreferrer">Umami</a> which is a simple, easy to use, self-hosted web analytics solution.</p>
<h2>Umami</h2>
<p>I chose <a href="https://umami.is/" target="_blank" rel="noopener noreferrer">Umami</a> because it </p>
<ul>
<li>is <a href="https://github.com/mikecao/umami" target="_blank" rel="noopener noreferrer">open-source</a></li>
<li>is privacy-focused</li>
<li>simple</li>
<li>easy to use</li>
<li>has a <a href="https://app.umami.is/share/ISgW2qz8/flightphp.com" target="_blank" rel="noopener noreferrer">beautiful UI</a></li>
<li>has <a href="https://umami.is/docs/about" target="_blank" rel="noopener noreferrer">good documentation</a> </li>
</ul>
<p><img src="https://umami.is/intro.jpg" alt="Umami Intro"></p>
<p>Umami does not provide a hosting solution. Therefore, we need to host the service on our own. All you need to get Umami up and running is a database (either MySQL or PostgreSQL) and a server that can run Node.js (10.13 or newer). Check the <a href="https://umami.is/docs/hosting" target="_blank" rel="noopener noreferrer">list of available hosting solutions</a>.</p>
<p>I will show you two different approaches I tried to host Umami.</p>
<h3>Running on Heroku</h3>
<blockquote>
<p>Heroku is a container-based cloud Platform as a Service (PaaS). Developers use Heroku to deploy, manage, and scale modern apps. The platform is elegant, flexible, and easy to use, offering developers the simplest path to getting their apps to market.</p>
</blockquote>
<p>You can read more about <a href="https://www.heroku.com/" target="_blank" rel="noopener noreferrer">Heroku</a> on their <a href="https://www.heroku.com/about" target="_blank" rel="noopener noreferrer">“What is Heroku?”</a> page.</p>
<p>We can host Umami and a corresponding database for free on Heroku. The setup is well described in the <a href="https://umami.is/docs/running-on-heroku" target="_blank" rel="noopener noreferrer">Umami documentation</a>.</p>
<p>To get it running, I just had to modify the npm <code>start</code> script command to include the Heroku port: </p>
<div data-language="bash"><pre><code><span>"start"</span><span>:</span> <span>"next start -p <span>$PORT</span>"</span></code></pre></div>
<p>Using Heroku is for sure the easiest &amp; fastest way to set up a running Umami instance but there is one drawback: It is expensive.</p>
<p>I collected analytics data from my website for about 2 days and I quickly realized that the free “Hobby Dev” <a href="https://elements.heroku.com/addons/heroku-postgresql#pricing" target="_blank" rel="noopener noreferrer">Heroku Postgres plan</a> will not be enough.</p>
<p><span>
      <a href="https://www.mokkapps.de/static/a89db01588a44caca356d39f5710b12a/70b07/heroku-postgres.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Heroku Postgres Ressources" title="Heroku Postgres Ressources" src="https://d33wubrfki0l68.cloudfront.net/ffef1e594a06c1435b1bd219186ce66f6fdd8b0d/7f633/static/a89db01588a44caca356d39f5710b12a/1e043/heroku-postgres.png" srcset="https://d33wubrfki0l68.cloudfront.net/498d7f1749345ecfcc3ea8c4e1981596b7e376d7/3b37b/static/a89db01588a44caca356d39f5710b12a/991de/heroku-postgres.png 173w,
https://d33wubrfki0l68.cloudfront.net/2e682de9294fd6c240c559e43d79088834f36468/d0ad1/static/a89db01588a44caca356d39f5710b12a/e4d6b/heroku-postgres.png 345w,
https://d33wubrfki0l68.cloudfront.net/ffef1e594a06c1435b1bd219186ce66f6fdd8b0d/7f633/static/a89db01588a44caca356d39f5710b12a/1e043/heroku-postgres.png 690w,
https://d33wubrfki0l68.cloudfront.net/4c61a75cb31c03152a3c76426bdb67493a973bce/c08ab/static/a89db01588a44caca356d39f5710b12a/e3189/heroku-postgres.png 1035w,
https://d33wubrfki0l68.cloudfront.net/8b6c399b6810378a3d93c08531266f13072eedce/4a446/static/a89db01588a44caca356d39f5710b12a/b1001/heroku-postgres.png 1380w,
https://d33wubrfki0l68.cloudfront.net/8c7ac999811bc0e33c45d14877c4129b92c4f146/3f638/static/a89db01588a44caca356d39f5710b12a/70b07/heroku-postgres.png 2906w" sizes="(max-width: 690px) 100vw, 690px" loading="lazy">
  </a>
    </span></p>
<p> This free plan includes 10,000 database rows and I filled ~1000 per day. So the free plan would be reached in about 10 days. The next “Hobby Basic” plan for 9$/month would include 10,000,000 rows which would last for approximately 27 years (assuming 1000 new rows per day, so no increasing traffic on my website). The “Standard 0” plan for 50$/month provides unlimited rows but this is way too much money I would spend for a self-hosted analytics solution.</p>
<h3>Running on DigitalOcean &amp; Vercel</h3>
<p> An alternative to Heroku is to host the database on <a href="https://m.do.co/c/833a8650eb62" target="_blank" rel="noopener noreferrer">Digital Ocean</a> and Umami on <a href="https://vercel.com/" target="_blank" rel="noopener noreferrer">Vercel</a>.</p>
<h4>DigitalOcean</h4>
<p><a href="https://m.do.co/c/833a8650eb62" target="_blank" rel="noopener noreferrer">Digital Ocean</a> is an affordable cloud hosting provider. Starting with 5$/month you get a cloud server for personal use and can scale it up as needed. Using <a href="https://m.do.co/c/833a8650eb62" target="_blank" rel="noopener noreferrer">this link</a> you get a $100 credit for the first 60 days.</p>
<p>I host a MySQL database on DigitalOcean which required these steps to set up:</p>
<ol>
<li><a href="https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-18-04" target="_blank" rel="noopener noreferrer">Initial setup the server with Ubuntu 18.04</a></li>
<li><a href="https://www.digitalocean.com/community/tutorials/how-to-install-mysql-on-ubuntu-18-04" target="_blank" rel="noopener noreferrer">Install MySQL on Ubuntu</a></li>
<li>Setup the MySQL database schema with the <a href="https://github.com/mikecao/umami/blob/master/sql/schema.mysql.sql" target="_blank" rel="noopener noreferrer">Umami MySQL schema</a></li>
<li><a href="https://www.digitalocean.com/community/questions/how-to-allow-remote-mysql-database-connection" target="_blank" rel="noopener noreferrer">Allow remote access to the database</a></li>
</ol>
<p><span>
      <a href="https://www.mokkapps.de/static/5c2dbade9f1c811d871b90d14d4bfbfc/739ee/digital-ocean-droplet.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Digital Ocean Droplet" title="Digital Ocean Droplet" src="https://d33wubrfki0l68.cloudfront.net/47e8034c8b576c8e948d6018aec77b1a7c69b752/07ebd/static/5c2dbade9f1c811d871b90d14d4bfbfc/1e043/digital-ocean-droplet.png" srcset="https://d33wubrfki0l68.cloudfront.net/5479e0d5ffe821793a8bc46b7c578b9fc1f37561/d2524/static/5c2dbade9f1c811d871b90d14d4bfbfc/991de/digital-ocean-droplet.png 173w,
https://d33wubrfki0l68.cloudfront.net/5a73946ff38cc6705557d9a833133c8a82d35975/e0a2f/static/5c2dbade9f1c811d871b90d14d4bfbfc/e4d6b/digital-ocean-droplet.png 345w,
https://d33wubrfki0l68.cloudfront.net/47e8034c8b576c8e948d6018aec77b1a7c69b752/07ebd/static/5c2dbade9f1c811d871b90d14d4bfbfc/1e043/digital-ocean-droplet.png 690w,
https://d33wubrfki0l68.cloudfront.net/34662d7068789a368d03f8e3ac51511e961bbf18/0419b/static/5c2dbade9f1c811d871b90d14d4bfbfc/e3189/digital-ocean-droplet.png 1035w,
https://d33wubrfki0l68.cloudfront.net/69f02d5d93a840c2bfe8a0657d2131a6dbc107e2/23e69/static/5c2dbade9f1c811d871b90d14d4bfbfc/b1001/digital-ocean-droplet.png 1380w,
https://d33wubrfki0l68.cloudfront.net/154388f0e76167b04c5a5212e172c9d94a704da0/af29b/static/5c2dbade9f1c811d871b90d14d4bfbfc/739ee/digital-ocean-droplet.png 3548w" sizes="(max-width: 690px) 100vw, 690px" loading="lazy">
  </a>
    </span></p>
<p>DigitalOcean also provides a <a href="https://www.digitalocean.com/community/questions/how-to-allow-remote-mysql-database-connection" target="_blank" rel="noopener noreferrer">Node.js</a> droplet template that comes with Node.js, Ubuntu, and Nginx to host the Umami frontend. We will instead use <a href="https://vercel.com/" target="_blank" rel="noopener noreferrer">Vercel</a> as it is completely free.</p>
<h4>Vercel</h4>
<p><a href="https://vercel.com/" target="_blank" rel="noopener noreferrer">Vercel</a> is the company behind the framework <a href="https://nextjs.org/" target="_blank" rel="noopener noreferrer">Next.js</a> which is used by Umami and they provide a free frontend hosting service. As you can imagine, it is really easy to deploy a <a href="https://nextjs.org/" target="_blank" rel="noopener noreferrer">Next.js</a> application on <a href="https://vercel.com/" target="_blank" rel="noopener noreferrer">Vercel</a> as both applications are developed by the same company. </p>
<p>The setup is described in the <a href="https://umami.is/docs/running-on-vercel" target="_blank" rel="noopener noreferrer">official documentation</a>.</p>
<p><span>
      <a href="https://www.mokkapps.de/static/204a23574e29810b58d1e54722f31131/d5a26/vercel.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Vercel Deployment" title="Vercel Deployment" src="https://d33wubrfki0l68.cloudfront.net/a823f38a33221e4297cd061f0d7d599785408019/c23c2/static/204a23574e29810b58d1e54722f31131/1e043/vercel.png" srcset="https://d33wubrfki0l68.cloudfront.net/eafcbdbaedb97757d6712e829146eeafb241f0be/f4c04/static/204a23574e29810b58d1e54722f31131/991de/vercel.png 173w,
https://d33wubrfki0l68.cloudfront.net/3aa90d2ff3a25e93445c32500869f2a6197a6948/4e42e/static/204a23574e29810b58d1e54722f31131/e4d6b/vercel.png 345w,
https://d33wubrfki0l68.cloudfront.net/a823f38a33221e4297cd061f0d7d599785408019/c23c2/static/204a23574e29810b58d1e54722f31131/1e043/vercel.png 690w,
https://d33wubrfki0l68.cloudfront.net/81857d4ec18f312c535444004d119f0b60df3ac4/e9b96/static/204a23574e29810b58d1e54722f31131/e3189/vercel.png 1035w,
https://d33wubrfki0l68.cloudfront.net/176498209c508ae9c1174a31e25153333affeec1/20d19/static/204a23574e29810b58d1e54722f31131/b1001/vercel.png 1380w,
https://d33wubrfki0l68.cloudfront.net/6cde88e23a091d4c3c36b34c327628a8b04e00ee/369b2/static/204a23574e29810b58d1e54722f31131/d5a26/vercel.png 3578w" sizes="(max-width: 690px) 100vw, 690px" loading="lazy">
  </a>
    </span></p>
<p>If you now open the deployed Vercel app at <code>&lt;app-name&gt;.vercel.app</code> you need to perform these steps </p>
<ul>
<li><a href="https://umami.is/docs/login" target="_blank" rel="noopener noreferrer">Login</a> </li>
<li><a href="https://umami.is/docs/add-a-website" target="_blank" rel="noopener noreferrer">Add your website to Umami</a></li>
<li><a href="https://umami.is/docs/collect-data" target="_blank" rel="noopener noreferrer">Add tracking code to your website</a></li>
<li>Optional: Umami is also able to <a href="https://umami.is/docs/track-events" target="_blank" rel="noopener noreferrer">track events</a> that occur on your website</li>
</ul>
<p>This should result in a working private, open-source, self-hosted analytics solution:</p>
<p><span>
      <a href="https://www.mokkapps.de/static/d213b59b89d1b58be16498cf7776d99e/d5a26/umami-dashboard.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Umami Dashboard" title="Umami Dashboard" src="https://d33wubrfki0l68.cloudfront.net/71d9bbf9564872f8b03d3c46662b43cd454a9355/bf3c1/static/d213b59b89d1b58be16498cf7776d99e/1e043/umami-dashboard.png" srcset="https://d33wubrfki0l68.cloudfront.net/953a991631da60997b269cc7ea9084205d140eb0/d2ecb/static/d213b59b89d1b58be16498cf7776d99e/991de/umami-dashboard.png 173w,
https://d33wubrfki0l68.cloudfront.net/ddf0704195b41e55a44f46f2c0a01b7bff7203f8/6b67e/static/d213b59b89d1b58be16498cf7776d99e/e4d6b/umami-dashboard.png 345w,
https://d33wubrfki0l68.cloudfront.net/71d9bbf9564872f8b03d3c46662b43cd454a9355/bf3c1/static/d213b59b89d1b58be16498cf7776d99e/1e043/umami-dashboard.png 690w,
https://d33wubrfki0l68.cloudfront.net/30817df19d523064d86a6cb7ccf922500f38c1ce/c6884/static/d213b59b89d1b58be16498cf7776d99e/e3189/umami-dashboard.png 1035w,
https://d33wubrfki0l68.cloudfront.net/3001744c0ae683f6b4512eb57e5f5fbb1b7a97cb/3c0de/static/d213b59b89d1b58be16498cf7776d99e/b1001/umami-dashboard.png 1380w,
https://d33wubrfki0l68.cloudfront.net/8cb7edcf834021a8c398ad0c2b414b91bedcde71/5c596/static/d213b59b89d1b58be16498cf7776d99e/d5a26/umami-dashboard.png 3578w" sizes="(max-width: 690px) 100vw, 690px" loading="lazy">
  </a>
    </span>
<span>
      <a href="https://www.mokkapps.de/static/d3105bb52b5804fa36bd436e00ba084f/679fb/umami-realtime.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Umami Realtime" title="Umami Realtime" src="https://d33wubrfki0l68.cloudfront.net/f097e988a221e9c8abcd974ca961492b9b66d4a3/6caaa/static/d3105bb52b5804fa36bd436e00ba084f/1e043/umami-realtime.png" srcset="https://d33wubrfki0l68.cloudfront.net/4ac615c2276a613f8c187efcf4be993eda69ed47/16f2d/static/d3105bb52b5804fa36bd436e00ba084f/991de/umami-realtime.png 173w,
https://d33wubrfki0l68.cloudfront.net/e9049bca69bf7c34bca999ff6d0ded1b2adfa098/dbc90/static/d3105bb52b5804fa36bd436e00ba084f/e4d6b/umami-realtime.png 345w,
https://d33wubrfki0l68.cloudfront.net/f097e988a221e9c8abcd974ca961492b9b66d4a3/6caaa/static/d3105bb52b5804fa36bd436e00ba084f/1e043/umami-realtime.png 690w,
https://d33wubrfki0l68.cloudfront.net/7b43c73ba31eb0fe2e1b9f8ec0b30fe6262ea3d0/27cad/static/d3105bb52b5804fa36bd436e00ba084f/e3189/umami-realtime.png 1035w,
https://d33wubrfki0l68.cloudfront.net/297c83d05c9579e697f071e93e9f7f2c714011e7/08d85/static/d3105bb52b5804fa36bd436e00ba084f/b1001/umami-realtime.png 1380w,
https://d33wubrfki0l68.cloudfront.net/c36d8462a63057f580dff81c8f9c136dd586042a/916a3/static/d3105bb52b5804fa36bd436e00ba084f/679fb/umami-realtime.png 3542w" sizes="(max-width: 690px) 100vw, 690px" loading="lazy">
  </a>
    </span></p>
<h2>Conclusion</h2>
<p>I can sleep better as I now know that no more data is sent from my website to Google. I still have the possibility to track
my website analytics but in a simpler and privacy-focused way. Setting up Umami is quite easy if you are familiar with
software like Ubuntu and MySQL/Postgres. </p>
<p>Of course, I know need to pay some money to store this analytics data on my server but for me, it is worth the money.</p></div></div>]]>
            </description>
            <link>https://www.mokkapps.de/blog/how-i-replaced-google-analytics-with-a-private-open-source-and-self-hosted-alternative/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24965574</guid>
            <pubDate>Mon, 02 Nov 2020 07:49:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Breaking the 3 GHz Barrier]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24965531">thread link</a>) | @ingve
<br/>
November 1, 2020 | https://deprogrammaticaipsum.com/breaking-the-3-ghz-barrier/ | <a href="https://web.archive.org/web/*/https://deprogrammaticaipsum.com/breaking-the-3-ghz-barrier/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<p>My first serious attempt at understanding computer hardware happened during college, in 1994. One of the labs consisted in wiring a 4-bit processor to a series of switches and a LED display. The objective was to make a very simple operation: starting from zero, make the display increment one digit every time the switch is activated. Or, as it is commonly know, to make a <a href="https://en.wikipedia.org/wiki/Adder_(electronics)" target="_blank" rel="noopener noreferrer">bare bones half adder</a>.</p>
<p>That CPU was intended for teaching purposes; a squared wafer of silicon about 30 cm wide and large, with big capacitors and a whole circuitry system easily viewable with the naked eye. We could plug and unplug components of different resistance, capacity and voltage. The teacher explained to us that this contraption was a much simplified component, loosely based on the architecture of the <a href="https://en.wikipedia.org/wiki/Intel_4004" target="_blank" rel="noopener noreferrer">Intel 4004</a>, the first commercially available microprocessor, released in <em>annus mirabilis </em>1971.</p>
<p>To be honest, I could not really wire everything properly without some help from my classmates. I was puzzled, wrongfully lost in the perception that computers could not be that simple. Yet, with a bit of wiring and patience, indeed, the LED displayed the required bits (no pun intended) of a very simple calculator in front of my eyes.</p>
<p>Seeing a set of wires and lights perform the simplest of all mathematical operations had quite an impact on me. Maths were no longer an abstract concept; with the proper hardware, maths could literally come to life. I felt the excitement and the wonder of those scientists who, in the 1940s and 1950s, discovered this fact and built a new science around it.</p>
<p>This CPU, as simple as it was, showed me what the soul of this new machine was made of.</p>
<h2>TANSTAAFL</h2>
<p>These days we read in the press about supercomputers built with CPUs featuring names seemingly borrowed from a science fiction novel. Take the <a href="https://en.wikipedia.org/wiki/POWER9" target="_blank" rel="noopener noreferrer">POWER9</a>, for example. According to Wikipedia, it is a “superscalar, multithreading, symmetric multiprocessor.” Not even <a href="https://en.wikipedia.org/wiki/HAL_9000" target="_blank" rel="noopener noreferrer">HAL 9000</a> received such attractive marketing buzzwords. The POWER9 is a real beast, used as the brains of one of the <a href="https://en.wikipedia.org/wiki/Summit_(supercomputer)" target="_blank" rel="noopener noreferrer">fastest supercomputers ever made</a>, at the time of this writing at least.</p>
<p>In 2004, Herb Sutter wrote “<a href="http://www.gotw.ca/publications/concurrency-ddj.htm" target="_blank" rel="noopener noreferrer">The Free Lunch Is Over</a>“, a seminal article announcing the end of the path for <a href="https://en.wikipedia.org/wiki/Moore%27s_law" target="_blank" rel="noopener noreferrer">Moore’s Law</a>. This quote stands out:</p>
<blockquote><p>That willingness is simply a clear indicator of the extreme pressure the chip designers face to deliver ever-faster CPUs; they’re under so much pressure that they’ll risk changing the meaning of your program, and possibly break it, in order to make it run faster.</p></blockquote>
<p>In the eyes of this author, three major changes followed this article.</p>
<p>The first was quite visible in computer magazines. Computer marketing had no other solution but to drop CPU speeds as a differentiating factor among competitors. After all, most CPUs have been capped at around 3 GHz, and for almost 20 years now. As Graham observed during the discussions around this edition of the magazine, Steve Jobs never got his 3 GHz PowerPC G5 CPU from IBM, so he jumped ship to Intel. But he still did not immediately get a 3 GHz CPU, but rather, something called a “Core Duo”.</p>
<p>The second visible effect, and quite dramatic this time, was <a href="https://meltdownattack.com/" target="_blank" rel="noopener noreferrer">Meltdown and Spectre</a>. Security vulnerabilities using <em>precisely</em> those advanced CPU features, as attack vectors of unprecedented risk and virulence.</p>
<p>But from the perspective of the programmer, the third visible effect was the spread of multicore CPUs, now commonplace even in smartphones and small boards like the <a href="https://www.raspberrypi.org/" target="_blank" rel="noopener noreferrer">Raspberry Pi</a>, abundant in the drawers and behind the TV sets of most software developers reading these lines.</p>
<h2>Multicore</h2>
<p>The PC revolution happened on single-core CPUs running first single-threaded, then multithreaded applications. Is cloud and smartphone revolution currently based on multiple-core CPUs running single-threaded applications?</p>
<p>The availability of multicore CPUs at the end of the first decade of this millenium unleashed a new era in the programming of multithreaded apps.</p>
<p>First, technologies such as <a href="https://www.openmp.org/" target="_blank" rel="noopener noreferrer">OpenMP</a> and <a href="https://apple.github.io/swift-corelibs-libdispatch/" target="_blank" rel="noopener noreferrer">libdispatch</a> simplified the conceptual work of designing and writing applications for multicore CPUs, avoiding the requirement to write threading code, dealing with race conditions, semaphores, shared data, and other concepts.</p>
<p>Second, event loop libraries and runtimes such as <a href="https://nodejs.org/en/" target="_blank" rel="noopener noreferrer">Node.js</a>, <a href="https://libuv.org/" target="_blank" rel="noopener noreferrer">libuv</a> and <a href="https://libevent.org/" target="_blank" rel="noopener noreferrer">libevent</a> provided a different solution to the problem, avoiding multiprocessing altogether, at least from the point of view of the developer. Single threading and event loops for everyone.</p>
<p>Third, there was a the functional programming renaissance. This led in turn to two interesting trends: on one side the rise, of new and old languages such as <a href="https://scala-lang.org/" target="_blank" rel="noopener noreferrer">Scala</a>, <a href="http://learnyouahaskell.com/" target="_blank" rel="noopener noreferrer">Haskell</a>, and <a href="https://fsharp.org/" target="_blank" rel="noopener noreferrer">F#</a>; on the other, “classical” programming languages including functional programming concepts. To name a few: <a href="https://en.cppreference.com/w/cpp/language/lambda" target="_blank" rel="noopener noreferrer">C++</a>, <a href="https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/operators/lambda-expressions" target="_blank" rel="noopener noreferrer">C#</a>, <a href="https://docs.oracle.com/javase/tutorial/java/javaOO/lambdaexpressions.html" target="_blank" rel="noopener noreferrer">Java</a>, <a href="https://www.php.net/manual/en/functions.anonymous.php" target="_blank" rel="noopener noreferrer">PHP</a>, <a href="https://developer.apple.com/library/archive/documentation/Cocoa/Conceptual/ProgrammingWithObjectiveC/WorkingwithBlocks/WorkingwithBlocks.html" target="_blank" rel="noopener noreferrer">Objective-C</a>; they all got lambdas and functional idioms retrofitted into them in one way or another.</p>
<p>The rising popularities of Python, Ruby and JavaScript during the Web 2.0 era are arguably also to blame in this evolution; not to mention the spread of the <a href="http://static.googleusercontent.com/media/research.google.com/es/us/archive/mapreduce-osdi04.pdf" target="_blank" rel="noopener noreferrer">MapReduce</a> processing model (2004) and the respective availability of <a href="https://hadoop.apache.org/" target="_blank" rel="noopener noreferrer">Hadoop</a> and other similar technologies.</p>
<h2>Virtualization</h2>
<p>Developers these days are quite detached from hardware considerations these days. I have made a career in a software world increasingly disconnected from that of hardware. Most of the time, I would say 90% of the time, the computers running my code were completely, absolutely, and hopelessly virtual.</p>
<p>Let us consider, for example, a canonical “full stack” web developer, with some knowledge of cloud native apps; quite a common resumé these days. The person will surely use a rather high-level programming language, most probably JavaScript, Java, PHP, or C#. They will create a Docker container out of that code, and this container would run inside some Kubernetes cluster, itself running inside a virtual machine running in some cloud provider. In the middle, maybe, a CI/CD pipeline running in yet another virtual machine; most probably <a href="https://docs.gitlab.com/ee/ci/docker/using_docker_build.html" target="_blank" rel="noopener noreferrer">GitLab running the “Docker-in-Docker” image</a>, building other images.</p>
<p>The actual hardware is, of course, nowhere to be seen. It is virtual machines all over, and legend has it that at some point there is an actual CPU executing those instructions. A CPU, you know, labeled with the 64 bits moniker, built with silicon, plugged to a socket, and hopelessly capped at 3 GHz.</p>
<p>Cover photo by <a href="https://unsplash.com/@spen?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Spencer</a> on <a href="https://unsplash.com/s/photos/circuit?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
	</div></div>]]>
            </description>
            <link>https://deprogrammaticaipsum.com/breaking-the-3-ghz-barrier/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24965531</guid>
            <pubDate>Mon, 02 Nov 2020 07:39:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Copying Objects in JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24965501">thread link</a>) | @wheresvic4
<br/>
November 1, 2020 | https://smalldata.tech/blog/2018/11/01/copying-objects-in-javascript | <a href="https://web.archive.org/web/*/https://smalldata.tech/blog/2018/11/01/copying-objects-in-javascript">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
  In this article we will look at the various ways an object can be copied in Javascript. We will take a look at both
  shallow and deep copying.
</p>

<p>
  Before we begin, it is worth mentioning a few basics: objects in Javascript are simply references to a location in
  memory. These references are mutable, i.e. they can be reassigned. Thus, simply making a copy of a reference only
  results in 2 references pointing to the same location in memory:
</p>

<pre>var foo = {
    a : "abc"
}
console.log(foo.a); // abc

var bar = foo;
console.log(bar.a); // abc

foo.a = "yo foo";
console.log(foo.a); // yo foo
console.log(bar.a); // yo foo

bar.a = "whatup bar?";
console.log(foo.a); // whatup bar?
console.log(bar.a); // whatup bar?    
</pre>

<p>
  As you see in the above example, both foo and bar are reflecting the change done in either object. Thus, making a copy
  of an object in Javascript requires some care depending upon your use case.
</p>

<h5>Shallow copy</h5>

<p>
  If your object only has properties which are value types, you can use the spread syntax or
  <code>Object.assign(...)</code>
</p>

<pre>var obj = { foo: "foo", bar: "bar" };

var copy = { ...obj }; // Object { foo: "foo", bar: "bar" }
</pre>

<pre>var obj = { foo: "foo", bar: "bar" };

var copy = Object.assign({}, obj); // Object { foo: "foo", bar: "bar" }
</pre>

<p>
  Note that both of the above methods can be used to copy property values from <i>multiple source objects</i> to a
  target object:
</p>

<pre>var obj1 = { foo: "foo" };
var obj2 = { bar: "bar" };

var copySpread = { ...obj1, ...obj2 }; // Object { foo: "foo", bar: "bar" }
var copyAssign = Object.assign({}, obj1, obj2); // Object { foo: "foo", bar: "bar" }
</pre>

<p>
  The problem with the above methods lies in the fact that for objects with properties which are themselves objects,
  only the references are copied over, i.e. it is the equivalent of doing <code>var bar = foo;</code> as in the first
  code example:
</p>

<pre>var foo = { a: 0 , b: { c: 0 } };
var copy = { ...foo };

copy.a = 1;
copy.b.c = 2;

console.dir(foo); // { a: 0, b: { c: 2 } }
console.dir(copy); // { a: 1, b: { c: 2 } }
</pre>

<h5>Deep copy (with caveats)</h5>

<p>
  In order to deep copy objects, a potential solution can be to serialize the object to a string and then deserialize it
  back:
</p>

<pre>var obj = { a: 0, b: { c: 0 } };
var copy = JSON.parse(JSON.stringify(obj));
</pre>

<p>
  Unfortunately, this method only works when the source object contains serializable value types and does not have any
  circular references. An example of a non-serializable value type is the <code>Date</code> object - even though it is
  printed in ISO format on stringification, <code>JSON.parse</code> only interprets it as a string and not as a
  <code>Date</code> object.
</p>

<h5>Deep copy (with fewer caveats)</h5>

<p>
  For more complex cases, one could make use of a newer HTML5 cloning algorithm called
  <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Structured_clone_algorithm">"structured clone"</a>. Unfortunately, at the time of writing it is still limited to certain built-in types but it supports many more types
  than what <code>JSON.parse</code> does: Date, RegExp, Map, Set, Blob, FileList, ImageData, sparse and typed Array. It
  also preserves references within the cloned data, allowing it to support cyclical and recursive structures that don't
  work with the above mentioned serialization method.
</p>

<p>
  Currently, there is no direct way of calling the structured clone algorithm but there are some newer browser features
  that use this algorithm under the hood. Thus, there are a couple of workarounds that could potentially be used to deep
  copy objects.
</p>

<p>
  <u>Via MessageChannels</u>: the idea behind this is to leverage the serialization algorithm used by a communication
  feature. Since this feature is event based, the resultant clone is also an asynchronous operation.
</p>

<pre>class StructuredCloner {
  constructor() {
    this.pendingClones_ = new Map();
    this.nextKey_ = 0;

    const channel = new MessageChannel();
    this.inPort_ = channel.port1;
    this.outPort_ = channel.port2;

    this.outPort_.onmessage = ({data: {key, value}}) =&gt; {
      const resolve = this.pendingClones_.get(key);
      resolve(value);
      this.pendingClones_.delete(key);
    };
    this.outPort_.start();
  }

  cloneAsync(value) {
    return new Promise(resolve =&gt; {
      const key = this.nextKey_++;
      this.pendingClones_.set(key, resolve);
      this.inPort_.postMessage({key, value});
    });
  }
}

const structuredCloneAsync = window.structuredCloneAsync =
    StructuredCloner.prototype.cloneAsync.bind(new StructuredCloner);


const main = async () =&gt; {
  const original = { date: new Date(), number: Math.random() };
  original.self = original;

  const clone = await structuredCloneAsync(original);

  // different objects:
  console.assert(original !== clone);
  console.assert(original.date !== clone.date);

  // cyclical:
  console.assert(original.self === original);
  console.assert(clone.self === clone);

  // equivalent values:
  console.assert(original.number === clone.number);
  console.assert(Number(original.date) === Number(clone.date));

  console.log("Assertions complete.");
};

main();
</pre>

<p>
  <u>Via the history API</u>: both <code>history.pushState()</code> and <code>history.replaceState()</code> create a
  structured clone of their first argument! Note that while this method is synchronous, manipulating browser history is
  not a fast operation and calling this method repeatedly can lead to browser unresponsiveness.
</p>

<pre>const structuredClone = obj =&gt; {
  const oldState = history.state;
  history.replaceState(obj, null);
  const clonedObj = history.state;
  history.replaceState(oldState, null);
  return clonedObj;
};
</pre>

<p>
  <u>Via the
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/Notification/Notification">notification API</a></u>: when creating a new notification, the constructor creates a structured clone of its associated data. Note that it
  also attempts to display a browser notification to the user, but this will silently fail unless the application has
  requested permissions to display notifications. In the case that permission was granted, the notification is
  immediately closed.
</p>

<pre>const structuredClone = obj =&gt; {
  const n = new Notification("", {data: obj, silent: true});
  n.onshow = n.close.bind(n);
  return n.data;
};
</pre>

<h5>Deep copy in Node.js</h5>

<p>
  As of version 8.0.0, Node.js provides a
  <a href="https://nodejs.org/api/v8.html#v8_serialization_api">serialization api</a> which is compatible with
  structured clone. Note that this API is marked as experimental at the time of writing:
</p>

<pre>const v8 = require('v8');
const buf = v8.serialize({a: 'foo', b: new Date()});
const cloned = v8.deserialize(buf);
cloned.b.getMonth();
</pre>

<p>
  For versions below 8.0.0 or for a more stable implementation, one can use lodash's
  <code><a href="https://lodash.com/docs#cloneDeep">cloneDeep</a></code> method, which is also loosely based on the
  structured clone algorithm.
</p>

<h5>Conclusion</h5>

<p>
  To sum up, the best algorithm for copying objects in Javascript is heavily dependent on the context and type of
  objects that you are looking to copy. While lodash is the safest bet for a generic deep copy function, you might get a
  more efficient implementation if you roll your own, the following is an example of a simple deep clone that works for
  dates as well:
</p>

<pre>function deepClone(obj) {
  var copy;

  // Handle the 3 simple types, and null or undefined
  if (null == obj || "object" != typeof obj) return obj;

  // Handle Date
  if (obj instanceof Date) {
    copy = new Date();
    copy.setTime(obj.getTime());
    return copy;
  }

  // Handle Array
  if (obj instanceof Array) {
    copy = [];
    for (var i = 0, len = obj.length; i &lt; len; i++) {
        copy[i] = deepClone(obj[i]);
    }
    return copy;
  }

  // Handle Function
  if (obj instanceof Function) {
    copy = function() {
      return obj.apply(this, arguments);
    }
    return copy;
  }

  // Handle Object
  if (obj instanceof Object) {
      copy = {};
      for (var attr in obj) {
          if (obj.hasOwnProperty(attr)) copy[attr] = deepClone(obj[attr]);
      }
      return copy;
  }

  throw new Error("Unable to copy obj as type isn't supported " + obj.constructor.name);
}
</pre>

<p>
  Personally, I'm looking forward to be able to use structured clone everywhere and finally put this issue to rest,
  happy cloning :)
</p>
<p><a href="https://news.ycombinator.com/submitlink?u=https%3A%2F%2Fsmalldata.tech%2Fblog%2F2018%2F11%2F01%2Fcopying-objects-in-javascript&amp;t=Copying%20objects%20in%20Javascript">HackerNews submission / discussion</a></p></div></div>]]>
            </description>
            <link>https://smalldata.tech/blog/2018/11/01/copying-objects-in-javascript</link>
            <guid isPermaLink="false">hacker-news-small-sites-24965501</guid>
            <pubDate>Mon, 02 Nov 2020 07:29:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build Your Own Bit.ly]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24965482">thread link</a>) | @marcacohen
<br/>
November 1, 2020 | https://mco.dev/build-your-own-bit.ly/ | <a href="https://web.archive.org/web/*/https://mco.dev/build-your-own-bit.ly/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
            <div>
              <p>In this article we’ll build a simple yet powerful short link service using two of my favorite Google Cloud technologies: Cloud Run and Firestore. The code can be found on <a href="https://github.com/marcacohen/mco.fyi">Github</a> and here’s a <a href="https://mco.fyi/links">slide version</a> of this story.</p>
<h2 id="introduction">Introduction</h2>
<p>I love building demos but sometimes they can feel a bit artificial, like you’re building a program that no one would actually want to use, just to illustrate some capability or technique. But if you choose carefully, you can find demos that are both simple and useful, which for me is the best possible vehicle for learning.</p>
<p><img src="https://mco.dev/img/SweetSpot.png" width="400" height="400"></p><h2 id="what-problem-are-we-trying-to-solve">What problem are we trying to solve?</h2>
<p>I always like to start any work with a problem statement because, as Lewis Carroll said, “if you don’t know where you’re going, any road will get you there”. Here’s my problem statement:</p>
<p>I want to share my teaching artifacts but I hate long, hard to remember URLs. In the past I’ve used a short link service, like <code>bit.ly</code>, but there are some problems with that approach:</p>

<p><img src="https://mco.dev/img/namespace.png" width="400" height="400"></p><ul>
<li><strong>globally shared namespace</strong> - Good luck getting your hands on <code>bit.ly/cloud</code>. Like the Internet Domain Name System, the gold rush is over and all the nice short names are gone.</li>
<li><strong>trust</strong> - Links you publicize can have a life of their own so you’re trusting this service to be a responsible, reliable, and secure custodian of your data.</li>
<li><strong>privacy</strong> - Allowing another party to manage your links means they have complete visibility over all of your traffic.</li>
<li><strong>branding</strong> - You turn over your branding to the company serving your links. Wouldn’t it be nice to have your own identity embedded in your short links?</li>
</ul>
<h2 id="requirements">Requirements</h2>
<p>What does it mean, to me, to solve this problem?</p>
<br>
<ul>
<li>I own the whole namespace so I get first crack at the shortest short links possible.</li>
<li>The service should use my domain name and branding.</li>
<li>I don’t want to spend much time maintaining this app so I’d like it to be simple and small (&lt;500 lines of code, please).</li>
<li>It must be scalable, so that it doesn’t crash under the intense weight of my wildly popular articles (ok, that’s never happened but I can dream, can’t I?).</li>
<li>I’d like a clean landing page providing a directory of all available short links.</li>
<li>I want some basic analytics so that I can see the relative popularity of each link.</li>
<li>I want to use 100% managed services. I don’t want to directly think about, or even be aware of, any servers.</li>
</ul>
<h2 id="design">Design</h2>
<p>Thanks to my last requirement, this program is so simple it hardly warrants a design diagram but old habits die hard, so here’s mine:</p>

<p><img src="https://mco.dev/img/sldesign.png" width="400" height="400"></p><h2 id="database---cloud-firestore">Database - Cloud Firestore</h2>
<p>I chose <a href="https://cloud.google.com/firestore">Cloud Firestore</a> for my database because it’s SIMPLE (Scalable, Intuitive, Managed, Pay-as-you-go, Language-agnostic, and Economical).</p>
<p>My data model is also quite simple: one document field per short link, each containing a map of these values:</p>
<ul>
<li><strong>key</strong> - a short link part of the URL (e.g. “foo” for <code>mco.fyi/foo</code>), naming the map</li>
<li><strong>url</strong> - the long link, i.e. where to redirect requests for a given short link</li>
<li><strong>count</strong> - keeps track of how many times a given short link was accessed</li>
<li><strong>desc</strong> - a human friendly description of where a given short link takes you</li>
<li><strong>private</strong> - a boolean value which hides the short link from the public list</li>
</ul>
<p>Here’s the data model in action as seen in the Google Cloud Console:</p>

<p><img src="https://mco.dev/img/firestore-console.png" width="400" height="400"></p><p>One thing I really like about Firestore is you can use the console to update your data as well as view it. It essentially gives me a database administration user interface for free. Less work for me!</p>
<h2 id="web-front-end---skeleton">Web Front End - Skeleton</h2>
<p>I’m using a styling package called <a href="http://getskeleton.com/">skeleton</a>, which I quite like because it’s simple, small, and responsive. Here’s an abbreviated copy of the HTML for my home page:</p>
<br>
<details>
  <summary>Click here to expand code</summary>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span><span>32
</span><span>33
</span><span>34
</span><span>35
</span><span>36
</span><span>37
</span><span>38
</span><span>39
</span><span>40
</span><span>41
</span><span>42
</span><span>43
</span><span>44
</span><span>45
</span><span>46
</span><span>47
</span><span>48
</span><span>49
</span><span>50
</span><span>51
</span><span>52
</span><span>53
</span><span>54
</span><span>55
</span><span>56
</span><span>57
</span><span>58
</span><span>59
</span><span>60
</span><span>61
</span><span>62
</span><span>63
</span><span>64
</span><span>65
</span></code></pre></td>
<td>
<pre><code data-lang="html"><span>&lt;!DOCTYPE html&gt;</span>
<span>&lt;</span><span>html</span> <span>lang</span><span>=</span><span>"en"</span><span>&gt;</span>
  <span>&lt;</span><span>head</span><span>&gt;</span>
    <span>&lt;</span><span>meta</span> <span>charset</span><span>=</span><span>"utf-8"</span> <span>/&gt;</span>
    <span>&lt;</span><span>title</span><span>&gt;</span>mco.fyi<span>&lt;/</span><span>title</span><span>&gt;</span>
    <span>&lt;</span><span>meta</span> <span>name</span><span>=</span><span>"Marc's Short Link Service"</span> <span>content</span><span>=</span><span>""</span> <span>/&gt;</span>
    <span>&lt;</span><span>meta</span> <span>name</span><span>=</span><span>"Marc Cohen"</span> <span>content</span><span>=</span><span>""</span> <span>/&gt;</span>
    <span>&lt;</span><span>meta</span> <span>name</span><span>=</span><span>"viewport"</span> <span>content</span><span>=</span><span>"width=device-width, initial-scale=1"</span> <span>/&gt;</span>
    <span>&lt;</span><span>link</span>
      <span>href</span><span>=</span><span>"//fonts.googleapis.com/css?family=Raleway:400,300,600"</span>
      <span>rel</span><span>=</span><span>"stylesheet"</span>
      <span>type</span><span>=</span><span>"text/css"</span>
    <span>/&gt;</span>
    <span>&lt;</span><span>link</span> <span>rel</span><span>=</span><span>"stylesheet"</span> <span>href</span><span>=</span><span>"css/normalize.css"</span> <span>/&gt;</span>
    <span>&lt;</span><span>link</span> <span>rel</span><span>=</span><span>"stylesheet"</span> <span>href</span><span>=</span><span>"css/skeleton.css"</span> <span>/&gt;</span>
    <span>&lt;</span><span>link</span> <span>rel</span><span>=</span><span>"icon"</span> <span>type</span><span>=</span><span>"image/png"</span> <span>href</span><span>=</span><span>"img/favicon.png"</span> <span>/&gt;</span>
  <span>&lt;/</span><span>head</span><span>&gt;</span>
  <span>&lt;</span><span>body</span><span>&gt;</span>
    <span>&lt;</span><span>div</span> <span>class</span><span>=</span><span>"container"</span><span>&gt;</span>
      <span>&lt;</span><span>div</span> <span>class</span><span>=</span><span>"row"</span><span>&gt;</span>
        <span>&lt;</span><span>div</span> <span>class</span><span>=</span><span>"twelve columns"</span> <span>style</span><span>=</span><span>"margin-top: 5%"</span><span>&gt;</span>
          <span>&lt;</span><span>h1</span><span>&gt;</span>
            <span>&lt;</span><span>font</span> <span>face</span><span>=</span><span>"courier"</span><span>&gt;</span>mco.fyi<span>&lt;/</span><span>font</span><span>&gt;</span> - Marc's short link service
          <span>&lt;/</span><span>h1</span><span>&gt;</span>
        <span>&lt;/</span><span>div</span><span>&gt;</span>
      <span>&lt;/</span><span>div</span><span>&gt;</span>
      <span>&lt;</span><span>div</span> <span>class</span><span>=</span><span>"row"</span><span>&gt;</span>
        <span>&lt;</span><span>div</span> <span>class</span><span>=</span><span>"four columns"</span><span>&gt;</span>
          <span>&lt;</span><span>img</span> <span>height</span><span>=</span><span>"300"</span> <span>width</span><span>=</span><span>"250"</span> <span>src</span><span>=</span><span>"/img/meiko.jpg"</span> <span>/&gt;</span>
          <span>&lt;</span><span>br</span> <span>/&gt;</span>
          This is Meiko. Whenever you visit one of my short links, his job is to
          fetch the long version and return it to your browser. Thanks to Meiko
          (and Google Cloud Run), mco.fyi is fast and reliable. If you'd like to
          try this code for yourself, it's available on
          <span>&lt;</span><span>a</span> <span>target</span><span>=</span><span>"_blank"</span> <span>href</span><span>=</span><span>"https://github.com/marcacohen/mco.fyi"</span>
            <span>&gt;</span>Github<span>&lt;/</span><span>a</span>
          <span>&gt;</span>. Also, here's a
          <span>&lt;</span><span>a</span> <span>target</span><span>=</span><span>"_blank"</span> <span>href</span><span>=</span><span>"https://mco.fyi/links"</span><span>&gt;</span>slide deck<span>&lt;/</span><span>a</span><span>&gt;</span> and a
          <span>&lt;</span><span>a</span> <span>target</span><span>=</span><span>"_blank"</span> <span>href</span><span>=</span><span>"https://mco.fyi/links"</span><span>&gt;</span>blog article<span>&lt;/</span><span>a</span><span>&gt;</span> about
          this service.
        <span>&lt;/</span><span>div</span><span>&gt;</span>
        <span>&lt;</span><span>div</span> <span>class</span><span>=</span><span>"eight columns"</span><span>&gt;</span>
          <span>&lt;</span><span>table</span> <span>width</span><span>=</span><span>"100%"</span><span>&gt;</span>
            <span>&lt;</span><span>thead</span><span>&gt;</span>
              <span>&lt;</span><span>tr</span><span>&gt;</span>
                <span>&lt;</span><span>th</span><span>&gt;</span>Count<span>&lt;/</span><span>th</span><span>&gt;</span>
                <span>&lt;</span><span>th</span><span>&gt;</span>Link<span>&lt;/</span><span>th</span><span>&gt;</span>
                <span>&lt;</span><span>th</span><span>&gt;</span>Description<span>&lt;/</span><span>th</span><span>&gt;</span>
              <span>&lt;/</span><span>tr</span><span>&gt;</span>
            <span>&lt;/</span><span>thead</span><span>&gt;</span>
            <span>&lt;</span><span>tbody</span><span>&gt;</span>
              {{ range . }}
              <span>&lt;</span><span>tr</span><span>&gt;</span>
                <span>&lt;</span><span>td</span><span>&gt;</span>{{.Count}}<span>&lt;/</span><span>td</span><span>&gt;</span>
                <span>&lt;</span><span>td</span><span>&gt;&lt;</span><span>a</span> <span>href</span><span>=</span><span>"{{.Url}}"</span><span>&gt;</span>mco.fyi/{{.Key}}<span>&lt;/</span><span>a</span><span>&gt;&lt;/</span><span>td</span><span>&gt;</span>
                <span>&lt;</span><span>td</span><span>&gt;</span>{{.Desc}}<span>&lt;/</span><span>td</span><span>&gt;</span>
              <span>&lt;/</span><span>tr</span><span>&gt;</span>
              {{ end }}
            <span>&lt;/</span><span>tbody</span><span>&gt;</span>
          <span>&lt;/</span><span>table</span><span>&gt;</span>
        <span>&lt;/</span><span>div</span><span>&gt;</span>
      <span>&lt;/</span><span>div</span><span>&gt;</span>
    <span>&lt;/</span><span>div</span><span>&gt;</span>
  <span>&lt;/</span><span>body</span><span>&gt;</span>
<span>&lt;/</span><span>html</span><span>&gt;</span>
</code></pre></td></tr></tbody></table>
</div>
</div></details>
<p>I wanted my home page to simply list all the available short links, dynamically, and that’s exactly what the <code>div</code> element starting at line 42 does. A bit later, we’ll visit my server code, which populates the data incorporated into this template.</p>
<p>Here’s an abbreviated copy of the HTML for my 404 page, which is needed for the case when a non-existent short link is requested. You can experience this page yourself by visiting <a target="_blank" href="https://mco.fyi/foo">mco.fyi/foo</a> (you may need to have seen a certain film in order to appreciate the joke):</p>
<br>
<details>
  <summary>Click here to expand code</summary>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span><span>32
</span><span>33
</span><span>34
</span><span>35
</span><span>36
</span></code></pre></td>
<td>
<pre><code data-lang="html"><span>&lt;!DOCTYPE html&gt;</span>
<span>&lt;</span><span>html</span> <span>lang</span><span>=</span><span>"en"</span><span>&gt;</span>
  <span>&lt;</span><span>head</span><span>&gt;</span>
    <span>&lt;</span><span>meta</span> <span>charset</span><span>=</span><span>"utf-8"</span> <span>/&gt;</span>
    <span>&lt;</span><span>title</span><span>&gt;</span>mco.fyi<span>&lt;/</span><span>title</span><span>&gt;</span>
    <span>&lt;</span><span>meta</span> <span>name</span><span>=</span><span>"Marc's Short Link Service"</span> <span>content</span><span>=</span><span>""</span> <span>/&gt;</span>
    <span>&lt;</span><span>meta</span> <span>name</span><span>=</span><span>"Marc Cohen"</span> <span>content</span><span>=</span><span>""</span> <span>/&gt;</span>
    <span>&lt;</span><span>meta</span> <span>name</span><span>=</span><span>"viewport"</span> <span>content</span><span>=</span><span>"width=device-width, initial-scale=1"</span> <span>/&gt;</span>
    <span>&lt;</span><span>link</span>
      <span>href</span><span>=</span><span>"//fonts.googleapis.com/css?family=Raleway:400,300,600"</span>
      <span>rel</span><span>=</span><span>"stylesheet"</span>
      <span>type</span><span>=</span><span>"text/css"</span>
    <span>/&gt;</span>
    <span>&lt;</span><span>link</span> <span>rel</span><span>=</span><span>"stylesheet"</span> <span>href</span><span>=</span><span>"css/normalize.css"</span> <span>/&gt;</span>
    <span>&lt;</span><span>link</span> <span>rel</span><span>=</span><span>"stylesheet"</span> <span>href</span><span>=</span><span>"css/skeleton.css"</span> <span>/&gt;</span>
    <span>&lt;</span><span>link</span> <span>rel</span><span>=</span><span>"icon"</span> <span>type</span><span>=</span><span>"image/png"</span> <span>href</span><span>=</span><span>"img/favicon.png"</span> <span>/&gt;</span>
  <span>&lt;/</span><span>head</span><span>&gt;</span>
  <span>&lt;</span><span>body</span><span>&gt;</span>
    <span>&lt;</span><span>div</span> <span>class</span><span>=</span><span>"container"</span><span>&gt;</span>
      <span>&lt;</span><span>div</span> <span>class</span><span>=</span><span>"row"</span><span>&gt;</span>
        <span>&lt;</span><span>div</span> <span>class</span><span>=</span><span>"ten columns"</span> <span>style</span><span>=</span><span>"margin-top: 5%"</span><span>&gt;</span>
          <span>&lt;</span><span>h1</span><span>&gt;</span>404 - short link not found<span>&lt;/</span><span>h1</span><span>&gt;</span>
          <span>&lt;</span><span>br</span> <span>/&gt;</span>
          <span>&lt;</span><span>iframe</span>
            <span>width</span><span>=</span><span>"560"</span>
            <span>height</span><span>=</span><span>"315"</span>
            <span>src</span><span>=</span><span>"https://www.youtube.com/embed/OEu4Iq5KL-Q"</span>
            <span>frameborder</span><span>=</span><span>"0"</span>
            <span>allow</span><span>=</span><span>"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"</span>
            <span>allowfullscreen</span>
          <span>&gt;&lt;/</span><span>iframe</span><span>&gt;</span>
        <span>&lt;/</span><span>div</span><span>&gt;</span>
      <span>&lt;/</span><span>div</span><span>&gt;</span>
    <span>&lt;/</span><span>div</span><span>&gt;</span>
  <span>&lt;/</span><span>body</span><span>&gt;</span>
<span>&lt;/</span><span>html</span><span>&gt;</span>
</code></pre></td></tr></tbody></table>
</div>
</div></details>
<h2 id="server---cloud-run">Server - Cloud Run</h2>
<p>For my web server, I chose <a href="https://cloud.google.com/run">Cloud Run</a> because, like Firestore, it’s SIMPLE (Scalable, Intuitive, Managed, Pay-as-you-go, Language-agnostic, and Economical). It doesn’t make me think about servers, or scaling, or any of the annoying system administration details I don’t want to deal with.</p>
<p>Of course, I want this service to live behind a nice short domain name so I snarfed up <code>mco.fyi</code> (the “fyi” top level domain feels just right for this kind of service). Cloud Run makes it super easy to assign your own domain name to a service and you get secure serving via SSL/TLS/https automatically and painlessly.</p>
<p>I chose to write my server in Go, because it’s my favorite system programming language. Because Cloud Run is language and environment agnostic, I could have just as easily used Python, Java, Ruby, or FORTRAN for that matter (ok, FORTRAN might be a challenge but wouldn’t that be fun?).</p>
<p>Here’s my server code, which is small enough to fit into one main.go source file:</p>
<br>
<details>
  <summary>Click here to expand code</summary>
<div><div>
<table><tbody><tr><td>
<pre><code><span>  1
</span><span>  2
</span><span>  3
</span><span>  4
</span><span>  5
</span><span>  6
</span><span>  7
</span><span>  8
</span><span>  9
</span><span> 10
</span><span> 11
</span><span> 12
</span><span> 13
</span><span> 14
</span><span> 15
</span><span> 16
</span><span> 17
</span><span> 18
</span><span> 19
</span><span> 20
</span><span> 21
</span><span> 22
</span><span> 23
</span><span> 24
</span><span> 25
</span><span> 26
</span><span> 27
</span><span> 28
</span><span> 29
</span><span> 30
</span><span> 31
</span><span> 32
</span><span> 33
</span><span> 34
</span><span> 35
</span><span> 36
</span><span> 37
</span><span> 38
</span><span> 39
</span><span> 40
</span><span> 41
</span><span> 42
</span><span> 43
</span><span> 44
</span><span> 45
</span><span> 46
</span><span> 47
</span><span> 48
</span><span> 49
</span><span> 50
</span><span> 51
</span><span> 52
</span><span> 53
</span><span> 54
</span><span> 55
</span><span> 56
</span><span> 57
</span><span> 58
</span><span> 59
</span><span> 60
</span><span> 61
</span><span> 62
</span><span> 63
</span><span> 64
</span><span> 65
</span><span> 66
</span><span> 67
</span><span> 68
</span><span> 69
</span><span> 70
</span><span> 71
</span><span> 72
</span><span> 73
</span><span> 74
</span><span> 75
</span><span> 76
</span><span> 77
</span><span> 78
</span><span> 79
</span><span> 80
</span><span> 81
</span><span> 82
</span><span> 83
</span><span> 84
</span><span> 85
</span><span> 86
</span><span> 87
</span><span> 88
</span><span> 89
</span><span> 90
</span><span> 91
</span><span> 92
</span><span> 93
</span><span> 94
</span><span> 95
</span><span> 96
</span><span> 97
</span><span> 98
</span><span> 99
</span><span>100
</span><span>101
</span><span>102
</span><span>103
</span></code></pre></td>
<td>
<pre><code data-lang="go"><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
        <span>"cloud.google.com/go/firestore"</span>
        <span>"context"</span>
        <span>"html/template"</span>
        <span>"log"</span>
        <span>"net/http"</span>
        <span>"sort"</span>
        <span>"strings"</span>
<span>)</span>

<span>var</span> <span>linkdata</span> <span>map</span><span>[</span><span>string</span><span>]</span><span>interface</span><span>{}</span>
<span>var</span> <span>doc</span> <span>*</span><span>firestore</span><span>.</span><span>DocumentRef</span>

<span>// key/value structure for short link data
</span><span></span><span>type</span> <span>kv</span> <span>struct</span> <span>{</span>
        <span>Key</span> <span>string</span>  <span>// short name
</span><span></span>        <span>Count</span> <span>int64</span> <span>// count
</span><span></span>        <span>Url</span> <span>string</span>  <span>// URL
</span><span></span>        <span>Desc</span> <span>string</span> <span>// description
</span><span></span><span>}</span>

<span>func</span> <span>redirect</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
        <span>ctx</span> <span>:=</span> <span>context</span><span>.</span><span>Background</span><span>()</span>
        <span>path</span> <span>:=</span> <span>strings</span><span>.</span><span>TrimLeft</span><span>(</span><span>r</span><span>.</span><span>URL</span><span>.</span><span>Path</span><span>,</span> <span>"/"</span><span>)</span>
        <span>if</span> <span>path</span> <span>==</span> <span>""</span> <span>||</span> <span>path</span> <span>==</span> <span>"/"</span> <span>{</span>
                <span>t</span><span>,</span> <span>err</span> <span>:=</span> <span>template</span><span>.</span><span>ParseFiles</span><span>(</span><span>"home.html"</span><span>)</span>
                <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
                        <span>log</span><span>.</span><span>Println</span><span>(</span><span>err</span><span>.</span><span>Error</span><span>())</span>
                        …</code></pre></td></tr></tbody></table></div></div></details></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mco.dev/build-your-own-bit.ly/">https://mco.dev/build-your-own-bit.ly/</a></em></p>]]>
            </description>
            <link>https://mco.dev/build-your-own-bit.ly/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24965482</guid>
            <pubDate>Mon, 02 Nov 2020 07:25:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why you should use a general purpose scripting language for build scripts (2014)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24965373">thread link</a>) | @AnonHP
<br/>
November 1, 2020 | https://jamesmckay.net/2014/10/why-you-should-use-a-general-purpose-scripting-language-for-your-build-scripts/ | <a href="https://web.archive.org/web/*/https://jamesmckay.net/2014/10/why-you-should-use-a-general-purpose-scripting-language-for-your-build-scripts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>For quite some time now, given the choice, I’ve opted to write my build scripts in plain Python using nothing but the standard libraries. I personally believe (with good reason) that build scripts are best served by a general purpose scripting language such as this, and that domain-specific languages or frameworks for build scripting have little if anything to offer. Most people use DSLs such as NAnt, MSBuild, Rake, Grunt or Gradle for their build scripts simply because they believe That Is How You Are Supposed To Do It, but in most cases it isn’t necessary, and in many cases it is even counterproductive.</p>



<p>In this post, I’d like to explain the reasons why I recommend using general purpose scripting languages and avoiding specialised build frameworks, and to address some commonly held misconceptions about build scripts in general. If I’m saying a lot about MSBuild, that’s because it’s the tool that I have the most experience with; however, many of my points apply to other tools as well, including those that aren’t XML-based.</p>



<h2>1. Build scripts are code, not configuration.</h2>



<p>Most build frameworks view build scripts as configuration first and code second. This is wrong. Badly wrong.</p>



<p>You see this in the way they adopt a declarative, rather than an imperative, approach, defining your script in terms of “targets” or “tasks” with dependencies between them. This approach can make sense in some situations — in particular, where you have a large number of similar tasks in a complex dependency graph, and you need to allow the build engine to determine the order in which they are run. This is the case, for example, with Visual Studio solutions that consist of a large number of projects.</p>



<p>But top level build scripts don’t work that way. At the topmost level, build scripts are inherently imperative in nature, so a declarative approach doesn’t make a whole lot of sense. Your typical build script consists of a sequence of diverse tasks which are run in an order that you define, or sometimes in a loop based on values in a collection. For example, it may look something like this:</p>



<ul><li>Fetch the latest version of your code from source control</li><li>Delete any leftover files from the previous build</li><li>Write a file to disk containing version information</li><li>Fetch your project’s dependencies (NuGet packages, for example)</li><li>Compile your project</li><li>Bundle and minify your assets</li><li>Run your unit tests</li><li>Run your integration tests</li><li>Prepare installation packages</li><li>Deploy your build to the appropriate servers</li><li>Prepare reports (e.g. code coverage)</li></ul>



<p>Writing your build script imperatively, with each of these steps as a function call in the top level of your code, allows you to see, at a glance, what your script is doing. On the other hand, writing them declaratively, with each task specifying its own dependencies, often requires you to jump around all over your build script just to get a handle on things.</p>



<p>One important thing that build scripts need is control flow structures — conditions, loops, iteration over arrays, parametrised subroutines, variables, and so on. You simply can’t represent these properly with a declarative language. Sure, you can define tasks to handle some of these requirements, such as regex-based find and replace, but that will never be as clear as a purely imperative approach.</p>



<p>I’ve never come across a definitive explanation why build frameworks should all be based around the declarative, configuration-like approach of tasks with dependencies, other than a vague, hand-waving and unsubstantiated claim that “people prefer it that way.” Personally I think it’s more likely that people just saw that this was how <a href="http://www.gnu.org/software/make/">make</a>, the granddaddy of build tools, was designed, assumed that it was a Best Practice, and blindly copied it without thinking.</p>



<h2>2. Build scripts need to be maintained.</h2>



<p>Build scripts don’t tend to change very often — perhaps once every three to six months or so. Consequently it’s tempting to view them as something that you write once and can forget about completely. However, they do change, so readability and maintainability are critical. A well written build script can make all the difference between a change taking half an hour and it taking half a sprint; between it working as intended and being riddled with bugs.</p>



<p>This means, of course, that XML-based build languages, such as MSBuild or NAnt, are a very bad idea. This is nothing to do with a lack of “cool” — it’s a lack of readability and maintainability, pure and simple. XML simply isn’t capable of expressing the kind of control flow structures that you need in a succinct, readable manner. MSBuild is particularly bad here. Its lack of support for looping, iteration or parametrised subroutines makes it difficult if not impossible to write anything more complex than the simplest of build scripts without resorting to painful amounts of copy and paste code. Since DRY is a vital discipline in keeping your code maintainable, anything that forces you to violate it as much as MSBuild does should be avoided with extreme prejudice.</p>



<p>To mitigate the problem, Ant, NAnt and MSBuild allow you to embed snippets of code in other languages, <a href="http://blogs.msdn.com/b/visualstudio/archive/2010/02/20/msbuild-task-factories-guest-starring-windows-powershell.aspx">such as PowerShell</a>. Besides the fact that the syntax to do so is so verbose and cumbersome that it’s scarcely worth it, this just raises the question: why not just use PowerShell end to end instead?</p>



<h2>3. Build scripts need to be run from the command line.</h2>



<p>It’s all too common to find build scripts that are very tightly integrated with the Continuous Integration server. This usually happens when you have vast swathes of configuration settings in TeamCity, TFS, Jenkins or what have you. This causes two problems: first, you have a lot of important and potentially breaking detail that isn’t checked into source control; second, it becomes very difficult if not impossible to run your build on your local machine, end to end, from the command line.</p>



<p>If you can’t run your build from the command line, debugging it will be painful. Every iteration of your edit-compile-test loop will require a separate check-in and a sit-on-your-hands wait for several minutes until it either completes or breaks. This is a very inefficient and wasteful way of doing things. It can also cause problems when you have to track down a regression with git bisect, because you’ll have a whole string of broken revisions to contend with.</p>



<h2>4. Build scripts have few other domain specific requirements, if any.</h2>



<p>Apart from this, there are only two other requirements that your build scripts have. Your build language needs to be interpreted rather than compiled (otherwise you’ll have a chicken-and-egg problem), and it needs to be able to run other programs: your compiler; NuGet to fetch your dependencies; your test runner; and so on. But that’s pretty much it. Just about any general purpose scripting language — Python, Ruby, PowerShell, bash, DOS batch files, heck even PHP if you’re that way inclined — will fit the bill.</p>



<p>What about the specific (N)Ant/MSBuild tasks that you need to call? Most of these can be implemented quite simply as calls to either the language’s standard library or a command line interface.</p>



<p>Some .NET developers don’t like this approach because they say that using, say, Python or PowerShell would mean having to learn a new language. Personally I find this a very strange argument, because if you’re using MSBuild, you’re doing that already anyway. Not only that, but the learning curve that you’re taking is actually steeper: the conceptual differences between, say, C# and Python are very superficial when compared to the conceptual differences between C# and MSBuild. Besides, learning a scripting language is a skill that can be transferred to other problem domains if necessary, whereas MSBuild is a very specialised and niche language that only ever gets used for build scripts for .NET projects.</p>



<p>Just because you are presented with something that describes itself as a build tool doesn’t mean to say you have to use it. Aim to choose tools and languages that allow you to write code that is easy to read, understand and maintain. You’ll be much more productive and much less stressed — and the people who have to maintain your code after you will thank you for it.</p>



<h2>For further reading</h2>



<ul><li>Martin Fowler: <a href="http://martinfowler.com/bliki/BuildLanguage.html">Build Language</a> and <a href="http://martinfowler.com/bliki/UseOfXml.html">Use of XML</a></li><li>Miller Medeiros: <a href="http://blog.millermedeiros.com/node-js-ant-grunt-and-other-build-tools/">Node.js, Ant, Grunt and other build tools</a></li><li>Ben Alman: <a href="http://benalman.com/news/2012/08/why-grunt/">Why grunt? Why not something else?</a></li><li>Kosei ABE: <a href="https://gist.github.com/kos59125/3615961">FizzBuzz in MSBuild</a> (all 39 lines of it!)</li><li>ThoughtWorks: <a href="http://www.thoughtworks.com/radar/tools/ant">Technology Radar – Ant</a></li></ul>

							
		
	</div></div>]]>
            </description>
            <link>https://jamesmckay.net/2014/10/why-you-should-use-a-general-purpose-scripting-language-for-your-build-scripts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24965373</guid>
            <pubDate>Mon, 02 Nov 2020 06:59:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The magic, details about the shebang mechanism on various Unix flavours]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24965325">thread link</a>) | @r4um
<br/>
November 1, 2020 | https://www.in-ulm.de/~mascheck/various/shebang/ | <a href="https://web.archive.org/web/*/https://www.in-ulm.de/~mascheck/various/shebang/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<a href="https://www.in-ulm.de/~mascheck/bourne/">Bourne</a>
| <a href="https://www.in-ulm.de/~mascheck/various/ash/">Ash</a>
| &nbsp;#!&nbsp;
| <a href="https://www.in-ulm.de/~mascheck/various/find/">find</a>
| <a href="https://www.in-ulm.de/~mascheck/various/argmax/"><code>ARG_MAX</code></a>
| <a href="https://www.in-ulm.de/~mascheck/various/shells/">Shells</a>
| <a href="https://www.in-ulm.de/~mascheck/various/whatshell/">whatshell</a>
| <a href="https://www.in-ulm.de/~mascheck/various/portability/">portability</a>
| <a href="https://www.in-ulm.de/~mascheck/various/permissions/">permissions</a>
| <a href="https://www.in-ulm.de/~mascheck/various/uuoc/">UUOC</a>
| <a href="https://www.in-ulm.de/~mascheck/various/ancient/">ancient</a>
| -
| <a href="https://www.in-ulm.de/~mascheck/various/">../Various</a>
| <a href="https://www.in-ulm.de/~mascheck/">HOME</a>
<br>
<a href="https://www.in-ulm.de/~mascheck/various/bourne_args">"<code>$@</code>"</a>
| <a href="https://www.in-ulm.de/~mascheck/various/echo+printf/">echo/printf</a>
| <a href="https://www.in-ulm.de/~mascheck/various/set-e/">set -e</a>
| <a href="https://www.in-ulm.de/~mascheck/various/test/">test</a>
| <a href="https://www.in-ulm.de/~mascheck/various/stty/">tty defs</a>
| <a href="https://www.in-ulm.de/~mascheck/various/ascii-tty/">tty chars</a>
| <a href="https://www.in-ulm.de/~mascheck/various/cmd-subst/"><code>$()</code> vs <code>)</code></a>
| <a href="https://www.in-ulm.de/~mascheck/various/ifs/">IFS</a>
| <a href="https://www.in-ulm.de/~mascheck/various/siginfo/">using siginfo</a>
| <a href="https://www.in-ulm.de/~mascheck/various/nanosleep_linux/">nanosleep</a>
| <a href="https://www.in-ulm.de/~mascheck/various/alternate_charset/">line charset</a>
| <a href="https://www.in-ulm.de/~mascheck/locale/">locale</a>

<hr>



<p><i>2001-08-13 .. 2017-04-23</i>  (see <a href="https://www.in-ulm.de/~mascheck/various/shebang/recent_changes.html">recent changes</a>)

</p><p> Here you'll find
</p><ul>
<li> <a href="#reading">More reading</a>
    <span size="2">
    <ul>
    <li> <a href="#origin">Origin</a>
    </li><li> Unix FAQ
    </li><li> Andries Brouwer's findings
    </li><li> Wikipedia
    </li></ul>
    </span>
</li><li> <a href="#details">Selected issues</a>
    <span size="2">
    <ul>
    <li> <a href="#blankrequired">Blank after <code>#!</code> required?</a>
    </li><li> <a href="#blankforbidden">Blank forbidden?</a>
    </li><li> <a href="#setuid">setuid support</a>
    </li><li> <a href="#interpreter-script">interpreter as <code>#!</code> script</a>
    </li><li> <a href="#splitting">splitting arguments</a>
    </li><li> <a href="#env">env utility</a>
    </li><li> <a href="#comments">comments</a>
    </li><li> <a href="#length">further history and maximum length</a>
    </li><li> <a href="#fancycode">fancy code</a>
    </li><li> <a href="#posix">POSIX.2/SUS</a>
    </li><li> <a href="#issues">what's special about <code>#!</code></a>
    </li><li> <a href="#errors">Possible errors</a>
    </li></ul>
    </span>
</li><li> <a href="#results"> A table with all the details </a> from numerous systems
</li></ul>

<hr>

<h4>More reading</h4>

<ul>
   <li> <a name="origin"><b>The Origin</b></a>
	<p> See an old mail from Dennis Ritchie introducing the new feature,
        quoted in 4.0 BSD <a href="https://www.in-ulm.de/~mascheck/various/shebang/4.0BSD_newsys_sys1.c.html">/usr/src/sys/<b>newsys</b>/sys1.c</a>.
	<br> The path component <code>newsys</code> was an option.
	<br>It is also mentioned as in 
        <a href="http://www.tuhs.org/cgi-bin/utree.pl?file=4BSD/usr/src/sys/sys/TODO">/usr/src/sys/<b>sys</b>/TODO</a> (that is, in the regular path),
	</p><pre>6. Exec fixes
	Implement dmr's #! feature; pass string arguments through faster.</pre>
        <p>So this <code>#!</code> mechanism origins from Bell Labs, between Version 7 and Version 8,
	<br> and was then available on 4.0BSD (~10/'80), although not activated per default.

	<br> Two important differences to current implementations are:
	<br>The length of the line was limited to 16 (Research Unix) or 32 (BSD) bytes.
	<br>"Arguments" were not delivered.

	</p><p> It was then implemented by default on 4.2BSD (~09/'83),
        <a href="https://www.in-ulm.de/~mascheck/various/shebang/42bsd_kern_exec.c.html">/usr/src/sys/sys/kern_exec.c</a>
	by <a href="http://mail-index.netbsd.org/netbsd-users/2008/11/10/msg002390.html">Robert Elz</a>.
	<br> This implementation delivered all #! arguments as a single one.

	</p><p> Less than a year after 4.0BSD, but more than two years before 4.2 BSD, <code>#!</code> was also added to
	<a href="https://www.in-ulm.de/~mascheck/various/shebang/2.8BSD_sys1.c.html">2.8BSD</a> (~07/'81), but not active by default.
	<br> 2.x BSD is a different development line, independent from 4 BSD.
	It's a 7th edition (V7) kernel with fixes activated by macros.
	<br> The macro for the <code>#!</code> code is not present in a makefile, so you had to activate it yourself.
	The code wording is slightly different from 4 BSD.
	<br> On 2.8 BSD, <code>#!</code> seems to come from the U.S. Geological Survey in Menlo Park, not from Berkeley.

       </p><p> <span size="1">(Thanks to Gunnar Ritter for pointing out the origins in 4.0 and 4.2BSD
       <a href="http://groups.google.com/groups?as_umsgid=3B5B0BA4.XY112IX2%40bigfoot.de">in de.comp.os.unix.shell</a>,
	to Jeremy C. Reed for mentioning Robert Elz,
	and to Richard Kettlewell for spotting 2.8BSD on TUHS mailing list.)</span>

	</p><p> In 4.3BSD Net/2 the code was removed due to the license war and had to be reimplemented for
	the descendants (e.g., NetBSD, 386BSD, BSDI).

	</p><p> In Version 8 (aka 8th edition), <code>#!</code> is implemented in
	<code>/usr/sys/sys/<a href="https://www.in-ulm.de/~mascheck/various/shebang/8thedition_sys1.c.html">sys1.c</a></code>
	and documented in <code><a href="https://www.in-ulm.de/~mascheck/various/shebang/8thedition_exec.2.html">exec(2)</a></code>.

	</p><p> Among the public releases from Bell Labs, <code>#!</code> was not added until SVR4 ('88) according to a 
	TUHS list <a href="http://minnie.tuhs.org/pipermail/tuhs/2011-January/003880.html">discussion</a>.
	System III and SVR1 definitely had not implemented it, yet.

	</p><p>According to Dennis M. Ritchie (<a href="https://www.talisman.org/~erlkonig/documents/dennis-ritchie-and-hash-bang.shtml">email answer</a> to Alex North-Keys) 
he got the idea from elsewhere, perhaps from one of the UCB conferences on BSD. 
	And it seems <code>#!</code> had no name originally.

	<br>Doug McIllroy <a href="http://minnie.tuhs.org/pipermail/tuhs/2017-April/009712.html">mentions</a> (TUHS mailing list), that the slang for <code>#</code> was "sharp" at the time at Bell Labs.

</p></li><li> The Unix FAQ
	<p>The paragraph
	"<a href="http://www.faqs.org/faqs/unix-faq/faq/part3/section-16.html">3.16)
	Why do some scripts start with #! ... ?</a>"
	(<a href="https://www.in-ulm.de/~mascheck/various/shebang/unix-faq.txt">local copy</a>),
	<br>
        emphasizes the history concerning <i>shells</i>, not the kernel.

	</p><p> That document is incorrect about two details (and it seems not to be actively maintained at the moment):
	</p><ul>
	<li> <code>#!</code> was not invented at Berkeley (but they implemented
	it first in widely distributed releases), see above.
	</li><li> Concerning the <code>#</code> csh-hack: the document explicitly states that only csh was modified
	on the BSDs.<br>
	However, with 3BSD (03/'80) the Bourne shell was modified likewise on BSDs as well.
	<br> See the first occurence in <a href="https://www.in-ulm.de/~mascheck/various/shebang/csh-hack.html">3BSD usr/src/cmd/sh/service.c</a>
	(and the first appearance <a href="https://www.in-ulm.de/~mascheck/bourne/csh/">in csh</a> on 2BSD 05/'79).
	</li></ul>

</li><li> There is also an
	<a href="http://www.cwi.nl/~aeb/std/hashexclam.html">
	article from Andries Brouwer</a>, which you shouldn't miss.
	It emphasizes some other things which are not explained here
	and follows a more generic approach (and it differs concerning
	a very few details).

</li><li> Wikipedia covers this topic with 
	<a href="http://en.wikipedia.org/wiki/Shebang_(Unix)">Shebang_(Unix)</a>.
	

<!-- differences: -->
<!-- "#! /" -->
<!-- BSDi == vendor != OS -->
<!-- Many Unix systems will consider a `\r' in a DOS-type line-ending (`\r\n') part of the interpreter arguments. (HP-UX, Solaris, UnixWare ignore trailing `\r'. AIX, BSD/OS,  -->
<!-- For FreeBSD and HPUX this argument is /scriptpath/script. -->

   </li></ul>

<hr>

<h4>Selected issues</h4>

<ul>
  <li> <a name="blankrequired"> <b>Blank after <code>#!</code> required?</b> </a>

	<p> There is a rumor, that a very few and very special, earlier
	Unix versions (particularly 4.2BSD derivatives) require you to
	separate the "<code>#!</code>" from the following path with a blank.
        <br>You may also read, that (allegedly) such a kernel parses
        "<code>#!&nbsp;/</code>" as a 32-bit (long) magic.

        But it turns out that it is virtually impossible to find
	a Unix which actually required this.

        </p><p> 4.2BSD in fact doesn't require it, although
	<a href="http://web.archive.org/web/20080118164924/http://www.gnu.org/software/autoconf/manual/autoconf-2.57/html_chapter/autoconf_10.html">previous versions</a>
	of the <i>GNU autoconf tutorial</i> wrongly claimed this
	("10. Portable Shell Programming", corrected with release 2.64, 2009-07-26).
<!-- http://www.gnu.org/manual/autoconf/html_chapter/autoconf_10.html -->
<!-- http://www.gnu.org/manual/autoconf/html_node/Portable-Shell.html -->

	<br> But instead, see 
        <a href="https://www.in-ulm.de/~mascheck/various/shebang/42bsd_kern_exec.c.html">4.2BSD,
        /usr/src/sys/sys/kern_exec.c</a> (the first regular occurence).
        A blank is accepted but not required.

        <br>All this pointed out by Gunnar Ritter in
	<a href="http://groups.google.com/groups?as_umsgid=3B5B0BA4.XY112IX2%40bigfoot.de">&lt;3B5B0BA4.XY112IX2@bigfoot.de&gt;</a>
        (and thanks to the new Caldera license, the code can be cited here now.)

        </p><p> Instead, the origin of this myth "of the required blank"
        <b>might</b> be a particular release of 4.1 BSD:
        There is a manpage in a "4.1.snap" snapshot of 4.1BSD
	<br>on the CSRG CDs, <a href="https://www.in-ulm.de/~mascheck/various/shebang/4.1BSD.snap.exec.2.html">/usr/man/man2/exec.2</a> (4/1/81),
        where a space/tab after the <code>#!</code> is mentioned as mandatory.
	However, this is not true: the source itself remained unchanged.
        <br>(Hint to the existence of such a manpage from Bruce Barnett in
        <a href="http://groups.google.com/groups?threadm=ae3m9l%24rti%240%40208.20.133.66&amp;prev=/groups%3Fas_umsgid%3Dae3m9l%2524rti%25240%2540208.20.133.66%26lr%3D%26hl%3Dde">&lt;ae3m9l$rti$0@208.20.133.66&gt;</a>).

	</p><p> It's not clear whether this is a bug or confusion in documentation
	or if Berkeley planned to modify the BSD source but eventually
	did not.

	</p><p>DYNIX is mentioned in the autoconf documentation, too.
	It's unclear if this variant might have implemented it in a few releases
	<br>(perhaps following the abovementioned manual page).

	At least <a href="https://www.in-ulm.de/~mascheck/various/shebang/Dynix-3.2.0-kern_exec.c.html">Dynix 3.2.0</a>
	or <a href="https://www.in-ulm.de/~mascheck/various/shebang/Dynix-PTX-1.2.0-kern_exec.c.html">Dynix PTS 1.2.0</a>
	were actually 4.2 BSD derived and did not require the blank.

	</p><p> I asked David MacKenzie, the author of the autoconf
	documentation, about the actual origin of the autoconf note.
	<br> But unfortunately neither the reporting author nor
	the very system are recorded anymore.

	</p><p> Even intensive search of usenet archives didn't reveal any
	further hints to me.

  </p></li><li> <a name="blankforbidden"> <b>Blank forbidden?</b> </a>

	<p>I found no evidence yet, that there's an implementation
	which <i>forbids</i> a blank after <code>#!</code>

   </p></li><li> <a name="setuid"><b>Setuid (set user id) support</b></a>

	<ul>
	<li> The setuid/gid-bit became ignored on many systems for security reasons.
	     This is mainly due to the race condition between the kernel starting
	     the interpreter and the interpreter starting the script.

	</li><li> SVR4 and 4.4BSD introduced a virtual filedescriptor filesystem which allows for avoiding this race:
	     Here the kernel can hand over an open filedescriptor (e.g. /dev/fd/n)
	     to the interpreter.
	     <p> 4.4BSD, however, didn't support setuid scripts, yet.
	     The <i>UNIX FAQ</i> claims this
	     (<i><a href="http://www.faqs.org/faqs/unix-faq/faq/part4/section-7.html">4.7. "How can I get setuid shell scripts to work?"</a></i>),
	     <br>but it's explicitly denied in <a href="https://www.in-ulm.de/~mascheck/various/shebang/44bsd_kern_exec.c.html">kern_exec.c</a>.
	     setuid for scripts had been disabled with 4.3BSD-Tahoe already.
	     <br>And the successor to 4.4BSD, 4.4BSD-Lite lost its <code>execve()</code>
	     implementation due to the license war.
	<br> Instead, a very early NetBSD release seems to be the origin concerning free BSDs
	<sup><span size="1">1</span></sup>.


	</p><table> <tbody><tr>
	   <td> <span size="1"><sup>[1]</sup></span>
	   </td><td> <span size="2">
	    NetBSD already implements it in the first cvs entry for
	    <a href="http://cvsweb.netbsd.org/bsdweb.cgi/src/sys/kern/exec_script.c"><code>exec_script.c</code></a>
	    (1994/01/16), some time before release 1.0.
	    <br>Earlier code has been removed from netbsd.org. The filedescriptor filesystem ("fdescfs") had been added with
	    <a href="ftp://ftp.netbsd.org/pub/NetBSD/NetBSD-archive/NetBSD-1.0/CHANGES">release 0.8</a> (04/93).
	    <br>NetBSD was influenced by 386BSD, but I couldn't find it there (including patchkit 0.2.4, 06/93).
	    <br>FreeBSD, which is a direct descendant of 386BSD, doesn't implement it either.
	    <br>OpenBSD forked off from NetBSD later (10/95) and thus implements it like NetBSD.

	    </span><p><span size="2">Jason Steven aka Neozeed meanwhile provides
	    NetBSD <a href="http://vpsland.superglobalmegacorp.com/install/NetBSD/NetBSD-0.8/">0.8</a>
	    and <a href="http://vpsland.superglobalmegacorp.com/install/NetBSD/NetBSD-0.9/">0.9</a> via cvsweb
	    (<a href="http://virtuallyfun.superglobalmegacorp.com/?p=317">announcement</a>)
	    <!-- formerly http://virtuallyfun.blogspot.com/2010/12/old-unix-trees.html -->
	    <br>and there, NetBSD 0.8 <a href="http://unix.superglobalmegacorp.com/NetBSD-0.8/newsrc/kern/kern_execve.c.html">kern_execve.c</a> doesn't provide setuid, but
	    NetBSD 0.9 <a href="http://unix.superglobalmegacorp.com/NetBSD-0.9/newsrc/kern/kern_exec.c.html">kern_exec.c</a> (1993/07/13) has all the bits
	    <br>(see e.g. the macros <code>SETUIDSCRIPTS</code> and <code>FDCSCRIPTS</code> at the head of the file).
	    
	</span></p></td></tr></tbody></table>

	<p>Set user id support is implemented by means of the fd filesystem for instance on:
	</p><ul>
	<li> Solaris (since birth)
        </li><li> Irix (at least since release 5)
	</li><li> UnixWare (since birth) <!-- A HREF="http://docsrv.sco.com/cgi-bin/man/man?chmod+1" -->
	</li><li> NetBSD (almost since birth; but only with the kernel option <code>SETUIDSCRIPTS</code> activated)
	</li><li> OpenBSD (since birth; but only with the kernel option <code>SETUIDSCRIPTS</code> activated)
	</li><li> MacOS X since 10.5 / xnu-1228 / Leopard, earlier releases came without the fd filesystem.
		<br>See the sysctl kernel variable <code>kern.sugid_scripts</code>.
	</li></ul>

	<p>Set user id support is also implemented on:
	</p><ul>
	<li> SCO OpenServer 6.0. The documentation doesn't tell whether it's implemented with
	the fd filesystem.
	<br>Although <a href="http://osr600doc.sco.com/en/SEC_admin/ssC.bitclearing.html">
	this document</a> ("SUID, SGID, and sticky bit clearing on writes",
	via Security online docs/Maintainig System Security)
	<br> states, that suid/sgid bit don't work on shell scripts (not explicitly mentioning
	the <code>#!</code> mechanism),
	<br><a href="http://osr600doc.sco.com/man/html.1/chmod.1.html">chmod(1)</a> and
	<a href="http://osr600doc.sco.com/en/man/html.S/exec.S.html">exec(s)</a>
	explicitly state that the bit works, if an <code>#!</code> interpreter file is used.
	<br>As Bela Lubkin points out: very basically, OpenServer 6 is an OSR 507 userland with
	an underlying UnixWare 7.1.4 kernel.
	</li></ul>

	</li><li> A sidenote: the <a href="http://www.in-ulm.de/~mascheck/bourne/#svr4">SVR4 shell</a>
		introduced the related flag <code>-p</code>.  Without this flag, the EUID is set back
		to the UID if different.
		<br> ksh88 and ksh93 in contrast activate this flag automatically
		if the euid/egid is not equal to the uid/gid.
		<br> bash-1 didn't know this flag; bash-2 ff. implement it and require it to be set.

	</li><li> Nowadays many systems still ignore the setuid-bit with the <code>#!</code> mechanism,
	     because you have to be aware of numerous issues.
	    <br>See also the Unix FAQ entry mentioned above. A collection of keywords is:
	    <ul>
	    <li> the abovementioned race condition about the actual script being called
		(symlink attack)
	    </li><li> some ksh88 (relevant on systems which do not use the /dev/fd mechanism) …</li></ul></li></ul></li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.in-ulm.de/~mascheck/various/shebang/">https://www.in-ulm.de/~mascheck/various/shebang/</a></em></p>]]>
            </description>
            <link>https://www.in-ulm.de/~mascheck/various/shebang/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24965325</guid>
            <pubDate>Mon, 02 Nov 2020 06:44:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Supabase.js 1.0 Released]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24965071">thread link</a>) | @awalias
<br/>
November 1, 2020 | https://supabase.io/blog/2020/10/30/improved-dx | <a href="https://web.archive.org/web/*/https://supabase.io/blog/2020/10/30/improved-dx">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p><time datetime="2020-10-30T00:00:00.000Z">October 30, 2020  · 3 min read</time></p><div><p><a href="https://github.com/kiwicopple" target="_blank" rel="noreferrer noopener"><img src="https://avatars2.githubusercontent.com/u/10214025?s=400&amp;u=c6775be2ae667e2acae3ccd347fed62bb3f5b3e7&amp;v=4" alt="Paul Copplestone"></a></p></div></header><section><p>Today we're releasing <a href="https://github.com/supabase/supabase-js" target="_blank" rel="noopener noreferrer">supabase-js</a> version 1.0, and it comes with some major Developer Experience improvements.</p><h3>New Docs</h3><p>Before digging into the improvements, we're excited to point out our new <a href="https://supabase.io/docs/client/supabase-client">developer docs</a>. While they're still a work in progress, here are some things we think you'll like:</p><ul><li>The <a href="https://supabase.io/docs/client/supabase-client">Reference Docs</a> are auto-generated from our Typescript definitions and then enriched with examples. This forces us to document our code and makes it easier to keep everything in sync.</li><li>We added placeholders for the other languages that the community is developing. They have already started with Python, C#, Dart, Rust, and Swift. Expect to see the docs filling up soon!</li><li>We've added sections for all of the open source tools we use, including <a href="https://supabase.io/docs/postgres/server/about">Postgres</a>, <a href="https://supabase.io/docs/postgrest/server/about">PostgREST</a>, <a href="https://supabase.io/docs/gotrue/server/about">GoTrue</a>, and <a href="https://supabase.io/docs/realtime/server/about">Realtime</a>. We'll be filling these with lots of valuable information including self-hosting, benchmarks, and simple guides.</li></ul><h3>Errors are returned, not thrown</h3><p>We attribute this improvement to community feedback. This has significantly improved the developer experience. Previously we would throw errors:</p><div><div><div><div><p><span>try</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>{</span><span> body </span><span>}</span><span> </span><span>=</span><span> supabase</span><span>.</span><span>from</span><span>(</span><span>'todos'</span><span>)</span><span>.</span><span>select</span><span>(</span><span>'*'</span><span>)</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>catch</span><span> </span><span>(</span><span>error</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>console</span><span>.</span><span>log</span><span>(</span><span>error</span><span>)</span><span></span></p><p><span></span><span>}</span></p></div></div></div></div><p>And now we simply return them:</p><div><div><div><div><p><span>const</span><span> </span><span>{</span><span> data</span><span>,</span><span> error </span><span>}</span><span> </span><span>=</span><span> supabase</span><span>.</span><span>from</span><span>(</span><span>'todos'</span><span>)</span><span>.</span><span>select</span><span>(</span><span>'*'</span><span>)</span><span></span></p><p><span></span><span>if</span><span> </span><span>(</span><span>error</span><span>)</span><span> </span><span>console</span><span>.</span><span>log</span><span>(</span><span>error</span><span>)</span><span></span></p></div></div></div></div><p>After testing this for a while we're very happy with this pattern. Errors are handled next to the offending function. Of course you can always rethrow the error if that's your preference.</p><h3>We created <code>gotrue-js</code></h3><p>Our goal for <code>supabase-js</code> is to tie together many sub-libaries. Each sub-library is a standalone implementation for a single external system. This is one of the ways we support existing open source tools.</p><p>To maintain this philosophy, we created <a href="https://github.com/supabase/gotrue-js" target="_blank" rel="noopener noreferrer"><code>gotrue-js</code></a>, a library for Netlify's GoTrue auth server. This libary includes a number of new additions, including third-party logins.</p><p>Previously:</p><div><div><div><div><p><span>const</span><span> </span><span>{</span><span></span></p><p><span>  body</span><span>:</span><span> </span><span>{</span><span> user </span><span>}</span><span>,</span><span></span></p><p><span></span><span>}</span><span> </span><span>=</span><span> </span><span>await</span><span> supabase</span><span>.</span><span>auth</span><span>.</span><span>signup</span><span>(</span><span></span></p><p><span>  </span><span>'someone@email.com'</span><span>,</span><span></span></p><p><span>  </span><span>'password'</span><span></span></p><p><span></span><span>)</span></p></div></div></div></div><p>Now:</p><div><div><div><div><p><span>const</span><span> </span><span>{</span><span> user</span><span>,</span><span> error </span><span>}</span><span> </span><span>=</span><span> </span><span>await</span><span> supabase</span><span>.</span><span>auth</span><span>.</span><span>signUp</span><span>(</span><span>{</span><span></span></p><p><span>  email</span><span>:</span><span> </span><span>'someone@email.com'</span><span>,</span><span></span></p><p><span>  password</span><span>:</span><span> </span><span>'password'</span><span></span></p><p><span></span><span>}</span><span>)</span></p></div></div></div></div><h3>Enhancements and fixes</h3><ul><li>Native Typescript. All of our libraries are now natively built with Typescript: <a href="https://github.com/supabase/supabase-js" target="_blank" rel="noopener noreferrer"><code>supabase-js</code></a>, <a href="https://github.com/supabase/postgrest-js" target="_blank" rel="noopener noreferrer"><code>postgrest-js</code></a>, <a href="https://github.com/supabase/gotrue-js" target="_blank" rel="noopener noreferrer"><code>gotrue-js</code></a>, and <a href="https://github.com/supabase/realtime-js" target="_blank" rel="noopener noreferrer"><code>realtime-js</code></a>.</li><li>Better realtime scalability: we only generate one socket connection per Supabase client. Previously we would create a connection for every subscription.</li><li>We've added support for OAuth providers.</li><li>60% of minor bugs outstanding for <code>supabase-js</code> have been <a href="https://github.com/supabase/supabase-js/pull/50" target="_blank" rel="noopener noreferrer">solved</a>.</li><li>You can use <code>select()</code> instead of <code>select(*)</code></li></ul><h3>Breaking changes</h3><p>We've bumped the major version because there are a number of breaking changes. We've detailed these in the <a href="https://github.com/supabase/supabase-js/releases/tag/v1.0.1" target="_blank" rel="noopener noreferrer">release notes</a>, but here are a few to be aware of:</p><ul><li><code>signup()</code> is now <code>signUp()</code> and <code>email</code> / <code>password</code> is passed as an object</li><li><code>logout()</code> is now <code>signOut()</code></li><li><code>login()</code> is now <code>signIn()</code></li><li><code>ova()</code> and <code>ovr()</code> are now just <code>ov()</code></li><li><code>body</code> is now <code>data</code></li></ul><p>Previously:</p><div><div><div><div><p><span>const</span><span> </span><span>{</span><span> body </span><span>}</span><span> </span><span>=</span><span> supabase</span><span>.</span><span>from</span><span>(</span><span>'todos'</span><span>)</span><span>.</span><span>select</span><span>(</span><span>'*'</span><span>)</span></p></div></div></div></div><p>Now:</p><div><div><div><div><p><span>const</span><span> </span><span>{</span><span> data </span><span>}</span><span> </span><span>=</span><span> supabase</span><span>.</span><span>from</span><span>(</span><span>'todos'</span><span>)</span><span>.</span><span>select</span><span>(</span><span>)</span></p></div></div></div></div><h3>Upgrading</h3><p>We have documented all of the changes in the <a href="https://github.com/supabase/supabase-js/releases/tag/v1.0.1" target="_blank" rel="noopener noreferrer">release notes</a>. </p><p>To summarise the steps:</p><ol><li>Install the new version: <code>npm install @supabase/supabase-js@latest</code></li><li>Update all your <code>body</code> constants to <code>data</code></li><li>Update all your <code>supabase.auth</code> functions with the new <a href="https://supabase.io/docs/client/auth-signup">Auth interface</a></li></ol><h3>Get started</h3><ul><li>Start using Supabase today: <a href="https://app.supabase.io/" target="_blank" rel="noopener noreferrer">app.supabase.io</a></li><li>Make sure to <a href="https://github.com/supabase/supabase" target="_blank" rel="noopener noreferrer">star us on GitHub</a></li><li>Follow us <a href="https://twitter.com/supabase_io" target="_blank" rel="noopener noreferrer">on Twitter</a></li><li>Become a <a href="https://github.com/sponsors/supabase" target="_blank" rel="noopener noreferrer">sponsor</a></li></ul></section></article></div>]]>
            </description>
            <link>https://supabase.io/blog/2020/10/30/improved-dx</link>
            <guid isPermaLink="false">hacker-news-small-sites-24965071</guid>
            <pubDate>Mon, 02 Nov 2020 05:36:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Does It Take to Resolve a Hostname]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24965056">thread link</a>) | @todsacerdoti
<br/>
November 1, 2020 | https://venam.nixers.net/blog/unix/2020/11/01/resolving-a-hostname.html | <a href="https://web.archive.org/web/*/https://venam.nixers.net/blog/unix/2020/11/01/resolving-a-hostname.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    <p><img src="https://venam.nixers.net/blog/assets/resolving_hostname/What_Does_It_Take_To_Resolve_A_Hostname.jpg" alt="slide1"></p>

<ul>
  <li><a href="#resolving-a-name-is-complex">Resolving A Name Is Complex</a></li>
  <li><a href="#nih">NIH</a></li>
  <li><a href="#historic">Historic</a></li>
  <li><a href="#resolver3">resolver(3)</a></li>
  <li><a href="#gethostbyname3-and-getaddrinfo3">gethostbyname(3) and getaddrinfo(3)</a></li>
  <li><a href="#nss5">nss(5)</a></li>
  <li><a href="#resolvconf8">resolvconf(8)</a></li>
  <li><a href="#caching">Caching</a></li>
  <li><a href="#how-to-debug">How To Debug</a></li>
  <li><a href="#big-picture">Big Picture</a></li>
  <li><a href="#references">References</a></li>
</ul>

<p>Can also be found in presentation format <a href="https://youtu.be/Hd8Nc8ZRkNM">here</a></p>



<p><img src="https://venam.nixers.net/blog/assets/resolving_hostname/What_Does_It_Take_To_Resolve_A_Hostname2.jpg" alt="slide2"></p>

<p>Resolving a domain name is complex.  It’s not limited to the DNS, the
Domain Name System — A decentralized and hierarchical system to associate
names and other information to IP addresses.<br>
It’s not something we, as users, usually pay attention to.  We notice
it only when we’re facing an issue. It normally works out of the box
but really nobody get the crux.<br>
You search online for clarifications but they barely help and add more
confusion.</p>

<p>Here are some schemas trying to decipher the mystery that domain name
resolution came to be.</p>

<p><img src="https://venam.nixers.net/blog/assets/resolving_hostname/What_Does_It_Take_To_Resolve_A_Hostname3.jpg" alt="slide3"></p>

<p>One, two, and three, I think you get me, it is not easy.  It’s never as
simple as taking a hostname as a string, getting the DNS address in the
<code>/etc/resolv.conf</code> config, then sending a request to the DNS on port 53
to be greeted back with the IP.<br>
Behind the scene there are ton of files and libraries involved, all of
this to get a domain name solved.</p>

<p>So in this talk we’ll try to create some order to try to understand thing
as an end-user. Let’s make sense and reason behind this mess even if I
have to say, I don’t get it much myself.<br>
I can’t assess I haven’t made mistakes but if I did, please correct me,
that would be great!</p>



<p><img src="https://venam.nixers.net/blog/assets/resolving_hostname/What_Does_It_Take_To_Resolve_A_Hostname4.jpg" alt="slide4"></p>

<p>Let’s start with the misfits, the ones that don’t follow the rules,
the not-invented-here syndrome found within our tools.<br>
When it comes to DNS resolution, there’s no one-size fit all
solution. Obviously, many of us don’t want to deal with all the
complexity, so we say, “let’s pack these bytes ourselves, and forget
the hassle”.<br>
That’s pure heresy though. We’d prefer everything to work the same way,
so that it’s easier to follow. It would be preferable that they all use
the same lib, to all have the same behavior. That is, in our case to rely
on the C standard lib, or the POSIX API our savior.</p>

<p>In all cases, let’s note some software that don’t rely on it, as we said,
all the misfits.</p>

<ul>
  <li>The ISC/BSD BIND tools: from host, to dig, to drill, to nslookup,
and more, used for debugging chores.</li>
  <li>Firefox/Chrome/Chromium: There are the browsers, because they are one
of a kind, bypassing libc and POSIX mechanism, implementing their own
DNS API for performance reasons and perfectionism.</li>
  <li>Any applications needing advanced DNS features, other than simple name to IP.</li>
  <li>Language that don’t wrap around a libc: The Go programming language
comes to mind. It implements it’s own resolver API.</li>
</ul>

<p>Fortunately, I can ease your mind by letting you know that all
of these will at least respect <code>/etc/resolv.conf</code> and <code>/etc/hosts</code>
configurations. Files that we’ll see in the next sections.</p>



<p><img src="https://venam.nixers.net/blog/assets/resolving_hostname/What_Does_It_Take_To_Resolve_A_Hostname5.jpg" alt="slide5"></p>

<p>I’ve taken a look at over a dozen different technologies and I think the
best way to understand them is through their archaeologies. There’s a
lot that can be explained about DNS resolution simply based on all the
historic reasons.<br>
The main thing you need to understand, is that there’s not a single
clean library call to resolve a hostname. Standards and new specs have
pilled up over the years, with some software that haven’t followed,
but risking to disappear.</p>

<p>Overall, libc and POSIX provide multiple resolution APIs:</p>

<ul>
  <li>There’s the historic, low level one provided by ISC/BSD BIND resolver
implementation within libc. Accessed though <code>libresolv/resolv.h</code>
incantation.</li>
  <li>The <code>gethostbyname(3)</code> and related functions, implementing an obsolete
POSIX C specification.</li>
  <li>The <code>getaddrinfo(3)</code>, that is the modern POSIX C API for name
resolution.</li>
</ul>

<p>All these combinations, ladies and gentlemen, are the standard ways
to resolve a name.<br>
Newer applications will use <code>getaddrinfo</code> while older ones will use
<code>gethostbyname</code>. Both of these 2 will often rely on something called
NSS and another part to manage <code>resolv.conf</code> access.</p>

<p>Now let’s dive into each of these and you’ll get them like a breeze.</p>



<p><img src="https://venam.nixers.net/blog/assets/resolving_hostname/What_Does_It_Take_To_Resolve_A_Hostname6.jpg" alt="slide6"></p>

<p>The resolver layer is the oldest and most stable in our quest. It
originates from 1983, today almost 37 years ago, at Berkeley university.</p>

<p>It comes from a project called BIND, Berkely Internet Name Domain, which
was sponsored by a DARPA grants. And like the Berkeley socket that gave
rise to the internet, it has now turned into much much pain.<br>
It was the very first implementation of the DNS specifications. It got
released in BSD4.3 and today the BIND project is maintained by the
Internet Systems Consortium, aka ISC.</p>

<p>It not only offers servers and clients, and the debug tools which we
mentioned earlier, but also offers a library called “libbind”. This
library is the defacto implementation, the standard resolver, the one
of a kind. It is initially based on all the original RFC discussions,
namely RFC 881, 882, and 883.<br>
The BSD people wrote technical papers assessing its feasibility, and
went on recommending and implementing it within BSD.</p>

<p>At that point BIND wasn’t a standard yet, it was an optionally-compiled
code for those who wanted to get their feet wet, those who wanted to
try DNS.<br>
Then it got part of the C standard library interface through <code>resolver</code>,
<code>libresolv</code>, <code>-lresolv</code>, <code>resolv.h</code>, and closed the case</p>

<p>If you take a look at most Unix-like systems today, from MacOS, to
OpenBSD, to Linux, and company, you’ll see clearly in <code>resolv.h</code>, the
copyright going back to 1983, to that very date. But obviously, it depends
on the choice of the implementer, a case by case</p>

<p>So then the code diverged, there’s the libresolv provided
by the C standardization and the libbind provided by the BIND
implementation. However, most Unix only add small specific changes to
their needs. For example, resolver in glibc is baselined off libbind
from BIND version 8.2.3.</p>

<p>This layer is normally used for low level DNS interactions because it’s
missing the goodies we’ll see later in this presentation.</p>

<p>Now let’s talk about environments and configurations.</p>

<p>The resolver configuration file</p>

<p>The resolver configuration files were mentioned in BIND first release,
in section 4.2.2.2 of “The Design and Implementation of ‘Domain Name
Resolver’” by Mark Painter based on RFC883, part of the DNS RFC series.</p>

<p>This particular file being <code>/etc/resolv.conf</code>, you’ll see it hardcoded in
<code>resolv.h</code> and if that file is missing, it’ll fall back to the localhost
as the DNS, just to be safe.<br>
Additionally, there’s <code>/etc/host.conf</code>, according to the manpage also
“the resolver configuration file”, it’s so appropriately named. It’s a
conf that dictates the working of <code>/etc/hosts</code>, the “static table lookup
for hostsnames”.</p>

<p>So what’s in these files.<br>
<code>resolv.conf</code> takes care of how to resolve names and which <code>nameserver</code>
to use for that, while <code>hosts</code> simply has a list of known host aliases,
ip + name, as simple as that.</p>

<p>Within <code>resolv.conf</code> you can also have a <code>search</code> list for domains.
That’s if a name you’re searching for doesn’t have the minimum number
of dots in it then it’ll add one of these TLD to it, top-level-domains,
and keep searching until it finds something that fits.<br>
This can also be manipulated in an environment variable <code>LOCALDOMAIN</code>.</p>

<figure><pre><code data-lang="shell"><span>$ </span><span>echo</span> <span>'example www.example.com'</span> <span>&gt;</span> ./host_aliases
<span>$ HOSTALIASES</span><span>=</span><span>"./host_aliases"</span> getent hosts example
93.184.216.34   www.example.com</code></pre></figure>

<p>There can also be a sortlist IP netmask, for when there’s many results
to match but you don’t want to give priority to the cloud VPS that lives
only for cash.</p>

<p>Finally, there’s the <code>option</code> field, also overriden on the command
line by the <code>RES_OPTIONS</code> environment variable. It manipulates the minimum
number of dots we mentioned and also if you want can set debug as enabled.</p>

<p>Meanwhile, the <code>hosts</code> file is but a key-value db, simply made of domain
names and IPs.</p>

<p>Its config also lets you change the order of results and for the rest
you have <code>host.conf</code> to consult.</p>

<p>So remember, that all of these are mostly used everywhere because it’s
the lowest layer.  So it’s used by libbind and libresolv but also the
custom NIH syndrome</p>

<p>Alright, so far that’s all classic clean stuff. Let’s move on to the
next sections, you’ll scratch your head until there’s no dandruff.</p>



<p><img src="https://venam.nixers.net/blog/assets/resolving_hostname/What_Does_It_Take_To_Resolve_A_Hostname7.jpg" alt="slide7"></p>

<p>The C library POSIX specs create a superset over the C standard
library. They add a few simpler calls to resolve hostnames and make it
easy. These focus on returning A and AAAA records only, ipV4 and ipV6
respsectively.<br>
There’s <code>gethostbyname(3)</code> which is deprecated, and there’s the newer
<code>getaddrinfo(3)</code> defined in IEEE Std 1003.1g-2000, which mainly adds
RFC3493 aka ipV6 is now supported.  So applications are recommended to
use this updated version unless they want to divert from mainland.</p>

<p>There are functions to resolve IP addresses to host names, but let’s
focus only on name to ip for today, I know it’s lame.</p>

<p>Apart from ipV6 support being added, some internal structures have been
updated as they weren’t so safe between subsequent calls and thus could
be your demise and your fall.</p>

<p>Obviously they both return different structures.</p>

<p><code>hostent</code> struct is returned to <code>gethostbyname</code> function caller.
while <code>getaddrinfo</code> returns an <code>addrinfo</code> structure.
Both being defined in the <code>netdb.h</code> header.</p>

<figure><pre><code data-lang="c"><span>struct</span> <span>hostent</span> <span>{</span>
	<span>char</span>  <span>*</span><span>h_name</span><span>;</span>            <span>/* official name of host */</span>
	<span>char</span> <span>**</span><span>h_aliases</span><span>;</span>         <span>/* alias list */</span>
	<span>int</span>    <span>h_addrtype</span><span>;</span>        <span>/* host address type */</span>
	<span>int</span>    <span>h_length</span><span>;</span>          <span>/* length of address */</span>
	<span>char</span> <span>**</span><span>h_addr_list</span><span>;</span>       <span>/* list of addresses */</span>
<span>}</span></code></pre></figure>

<figure><pre><code data-lang="c"><span>struct</span> <span>addrinfo</span> <span>{</span>
	<span>int</span>              <span>ai_flags</span><span>;</span>
	<span>int</span>              <span>ai_family</span><span>;</span>
	<span>int</span>              <span>ai_socktype</span><span>;</span>
	<span>int</span>              <span>ai_protocol</span><span>;</span>
	<span>socklen_t</span>        <span>ai_addrlen</span><span>;</span>
	<span>struct</span> <span>sockaddr</span> <span>*</span><span>ai_addr</span><span>;</span>
	<span>char</span>            <span>*</span><span>ai_canonname</span><span>;</span>
	<span>struct</span> <span>addrinfo</span> <span>*</span><span>ai_next</span><span>;</span>
<span>};</span></code></pre></figure>

<p>Some libc implementations will get fancy and add their own modified
versions of <code>gethostbyname</code>. For instance in glibc they add support for
ipV6 in their modified <code>gethostbyname2</code> for backward compatibility.</p>

<p>Regarding configuration files, <code>getaddrinfo</code> will consult <code>/etc/gai.conf</code>
which takes care of the precedence of the addresses returned in the
results. And now, you’re going to brandish your …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://venam.nixers.net/blog/unix/2020/11/01/resolving-a-hostname.html">https://venam.nixers.net/blog/unix/2020/11/01/resolving-a-hostname.html</a></em></p>]]>
            </description>
            <link>https://venam.nixers.net/blog/unix/2020/11/01/resolving-a-hostname.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24965056</guid>
            <pubDate>Mon, 02 Nov 2020 05:28:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rendering photo-realistic glass in the browser]]>
            </title>
            <description>
<![CDATA[
Score 375 | Comments 105 (<a href="https://news.ycombinator.com/item?id=24965005">thread link</a>) | @anonytrary
<br/>
November 1, 2020 | https://domenicobrz.github.io/webgl/projects/SSRefractionDepthPeeling/ | <a href="https://web.archive.org/web/*/https://domenicobrz.github.io/webgl/projects/SSRefractionDepthPeeling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://domenicobrz.github.io/webgl/projects/SSRefractionDepthPeeling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24965005</guid>
            <pubDate>Mon, 02 Nov 2020 05:13:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Leaders Need to Learn the Skill of Writing]]>
            </title>
            <description>
<![CDATA[
Score 118 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24964730">thread link</a>) | @mooreds
<br/>
November 1, 2020 | https://fromthegreennotebook.com/2020/10/03/why-leaders-need-to-learn-the-skill-of-writing/ | <a href="https://web.archive.org/web/*/https://fromthegreennotebook.com/2020/10/03/why-leaders-need-to-learn-the-skill-of-writing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main" role="main">

		
			<article id="post-6068">
	
	
		

	<div>
		<p><img data-attachment-id="6071" data-permalink="https://fromthegreennotebook.com/2020/10/03/why-leaders-need-to-learn-the-skill-of-writing/shutterstock_55915930-e1415052560114-2/" data-orig-file="https://i0.wp.com/fromthegreennotebook.com/wp-content/uploads/2020/10/shutterstock_55915930-e1415052560114-2.jpg?fit=3862%2C1974&amp;ssl=1" data-orig-size="3862,1974" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="shutterstock_55915930-e1415052560114-2" data-image-description="" data-medium-file="https://i0.wp.com/fromthegreennotebook.com/wp-content/uploads/2020/10/shutterstock_55915930-e1415052560114-2.jpg?fit=300%2C153&amp;ssl=1" data-large-file="https://i0.wp.com/fromthegreennotebook.com/wp-content/uploads/2020/10/shutterstock_55915930-e1415052560114-2.jpg?fit=723%2C369&amp;ssl=1" loading="lazy" src="https://i0.wp.com/fromthegreennotebook.com/wp-content/uploads/2020/10/shutterstock_55915930-e1415052560114-2.jpg?resize=715%2C365&amp;ssl=1" alt="" width="715" height="365" srcset="https://i0.wp.com/fromthegreennotebook.com/wp-content/uploads/2020/10/shutterstock_55915930-e1415052560114-2.jpg?w=3862&amp;ssl=1 3862w, https://i0.wp.com/fromthegreennotebook.com/wp-content/uploads/2020/10/shutterstock_55915930-e1415052560114-2.jpg?resize=300%2C153&amp;ssl=1 300w, https://i0.wp.com/fromthegreennotebook.com/wp-content/uploads/2020/10/shutterstock_55915930-e1415052560114-2.jpg?resize=1024%2C523&amp;ssl=1 1024w, https://i0.wp.com/fromthegreennotebook.com/wp-content/uploads/2020/10/shutterstock_55915930-e1415052560114-2.jpg?resize=768%2C393&amp;ssl=1 768w, https://i0.wp.com/fromthegreennotebook.com/wp-content/uploads/2020/10/shutterstock_55915930-e1415052560114-2.jpg?resize=1536%2C785&amp;ssl=1 1536w, https://i0.wp.com/fromthegreennotebook.com/wp-content/uploads/2020/10/shutterstock_55915930-e1415052560114-2.jpg?resize=2048%2C1047&amp;ssl=1 2048w, https://i0.wp.com/fromthegreennotebook.com/wp-content/uploads/2020/10/shutterstock_55915930-e1415052560114-2.jpg?w=1446&amp;ssl=1 1446w, https://i0.wp.com/fromthegreennotebook.com/wp-content/uploads/2020/10/shutterstock_55915930-e1415052560114-2.jpg?w=2169&amp;ssl=1 2169w" sizes="(max-width: 715px) 100vw, 715px" data-recalc-dims="1"></p>
<p>By Joe Byerly<span data-ez-name="fromthegreennotebook_com-box-3"></span></p>
<p>Anyone who has worked directly for a battalion commander or above probably has experience writing “ghost notes.” These are emails a subordinate writes and addresses for their boss to send to other people. Ghost notes can be weekly or monthly sitreps, updates on an ongoing situation or emails asking for additional resources. No matter the type, they are the “easy button” for the commander because all they have to do is hit “send.”</p>
<p>Recently, I worked for a senior Army leader who encouraged his subordinate commanders to own their communications—meaning, write their own emails. As I reflected on his guidance, I realized there are benefits to communications ownership. I witnessed many of these benefits firsthand as I watched him communicate with senior military leaders, senior civilian leaders and his own commanders.<span data-ez-name="fromthegreennotebook_com-medrectangle-3"></span></p>

<p><strong>Greatness and Writing</strong></p>
<p>One of the best ways to work through a problem is to write it down. Throughout history, leaders who found themselves in tough situations sat alone with their thoughts and worked through them using pen and paper.<span data-ez-name="fromthegreennotebook_com-medrectangle-4"></span></p>
<p>Marcus Aurelius, who served as Roman emperor for almost two decades, wrote his <em>Meditations</em> to work through daily leadership challenges, wars and a pandemic. In the week leading up to the D-Day landings, Gen. Dwight Eisenhower wrote himself letters to help work through risks, opportunities and necessities of operations.</p>
<p>Both Marcus and Eisenhower used writing to achieve clarity of thought. This point is underscored by author Stephen King, who has said writing is “refined thinking.” In our minds, our thoughts are clear, but real clarity doesn’t come until those thoughts are solidified in writing. The process of framing an email, capturing important points and discarding nonessential elements helps us gain more clarity.</p>
<p><strong>Sound Authentic</strong></p>
<p>Over the years, I have worked under multiple commanders while in staff positions, and the best ones never let me draft their intent for operations orders. They wanted to own those. At the time, I didn’t understand it—thinking it was one more staff drill I could handle for them. But as I gained experience, I realized they wanted that section of the operations order to reflect their voice.<span data-ez-name="fromthegreennotebook_com-box-4"></span></p>
<p>We all have a voice when we write. This voice is our certificate of authenticity. When commanders write their own correspondence, their voice comes through. When someone else drafts an email, using words and phrases the commander wouldn’t normally use, others can tell someone else wrote it.</p>
<p>Authenticity in communications is important for two reasons. First, subordinates will know if the intent, the guidance, the policy, etc., is the commander’s, or if it is another product produced by staff. They are more likely to follow it and adhere to it when they know it comes directly from the commander’s mind and is not a draft by a random staff officer.</p>
<p>Also, commanders who write their own communications tend to reinforce the message by repeating what they wrote. The senior Army leader I worked for occasionally wrote guidance that he sent out in an email. He then repeated key words and phrases from the document in meetings, during battlefield circulation and in one-on-one discussions. Everyone knew he wrote the email because he owned it and talked about it; his guidance didn’t become memorandums left on a bulletin board in a headquarters.</p>
<p>The second reason authenticity in communications is important is that it signals leader involvement in an issue. I have learned that many senior leaders can tell when a subordinate commander’s email is authentic or a staff-produced ghost note.</p>
<p>Every time there was a change or inflection point in the strategic situation, my boss would provide a one- or two-page update to his commanders. He always wrote these himself, for the reasons mentioned above. I found out from those commanders’ staff members that their bosses read these emails because they knew it was from him, and that if he took the time to write it, they should take the time to read it.</p>
<p>Communication can be frustrating. Sometimes it is like tapping out a song you have in your head and expecting another person to immediately know the tune. It is hard to convey an idea in your head to someone who may not have the same background or experiences as you, or who wasn’t in the same room when you had a conversation.</p>
<p>Communication is a skill that takes practice. We need repetition. Leaders who write their own emails gain needed communication experience when it matters. I have also learned that speed comes with practice. I can write in hours what used to take days.</p>
<p><strong>Honing the Skill</strong></p>
<p>I recognize that commanders have a lot on their plates, and it isn’t feasible for them to spend hours writing and responding to emails. There are many ghost notes best produced by staff in the interest of time. However, when it comes to communicating up or down the chain of command on key issues, or writing guidance on important topics, it is best for commanders to own those.</p>
<p>Great leaders are also great communicators, but the ability to communicate effectively and efficiently takes time to develop. By owning communications, commanders refine and hone this skill. They also have an opportunity to work through problems and refine their thinking through the process of writing. Finally, they gain authenticity in their communications—an important factor in ensuring that “message sent” is “message received.”</p>
<p>This article was first published in <a href="https://www.ausa.org/articles/leaders-subject-write-your-own-emails">ARMY Magazine</a> and reprinted with their permission.</p>



	





		
		
					</div><!-- .entry-content -->

	<!-- .entry-footer -->

</article><!-- #post-## -->

			
<!-- #comments -->

		
		</main><!-- #main -->
	</section><!-- #primary -->

	<!-- #secondary --></div></div>]]>
            </description>
            <link>https://fromthegreennotebook.com/2020/10/03/why-leaders-need-to-learn-the-skill-of-writing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24964730</guid>
            <pubDate>Mon, 02 Nov 2020 04:03:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[4 Billion USD ICO: Clues Found in Atlantic Ocean]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24964715">thread link</a>) | @npguy
<br/>
November 1, 2020 | https://doublespend.io/2020/10/28/breaking-object-floating-in-atlantic-could-be-carrying-funds-raised-in-eos-ico/ | <a href="https://web.archive.org/web/*/https://doublespend.io/2020/10/28/breaking-object-floating-in-atlantic-could-be-carrying-funds-raised-in-eos-ico/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Travelers aboard a luxury TransAtlantic cruise have shared pictures that many in the crypto community believe could provide clues on the missing 4 billion dollars raised during the EOS ICO. </p>



<p>DoubleSpend’s own analysis based on the size of the box show that it could very well contain the amount in USDs that was raised in the year-long ICO.</p>
<div><p><a href="https://twitter.com/share?url=https://doublespend.io/2020/10/28/breaking-object-floating-in-atlantic-could-be-carrying-funds-raised-in-eos-ico/&amp;text=Object%20Floating%20In%20Atlantic%20Ocean%20Could%20Contain%20EOS%E2%80%99%20ICO%20Funds%3A%20Sources" title="Share on Twitter" target="_blank" rel="nofollow noopener noreferrer" data-postid="409" data-social-network="Twitter" data-social-action="Tweet" data-social-target="https://doublespend.io/2020/10/28/breaking-object-floating-in-atlantic-could-be-carrying-funds-raised-in-eos-ico/"><span><span><svg version="1.1" xmlns="http://www.w3.org/2000/svg" width="29.71875" height="32" viewBox="0 0 951 1024"><path d="M925.714 233.143q-38.286 56-92.571 95.429 0.571 8 0.571 24 0 74.286-21.714 148.286t-66 142-105.429 120.286-147.429 83.429-184.571 31.143q-154.857 0-283.429-82.857 20 2.286 44.571 2.286 128.571 0 229.143-78.857-60-1.143-107.429-36.857t-65.143-91.143q18.857 2.857 34.857 2.857 24.571 0 48.571-6.286-64-13.143-106-63.714t-42-117.429v-2.286q38.857 21.714 83.429 23.429-37.714-25.143-60-65.714t-22.286-88q0-50.286 25.143-93.143 69.143 85.143 168.286 136.286t212.286 56.857q-4.571-21.714-4.571-42.286 0-76.571 54-130.571t130.571-54q80 0 134.857 58.286 62.286-12 117.143-44.571-21.143 65.714-81.143 101.714 53.143-5.714 106.286-28.571z"></path></svg></span><span>Tweet</span></span><span>0</span></a></p></div>		</div></div>]]>
            </description>
            <link>https://doublespend.io/2020/10/28/breaking-object-floating-in-atlantic-could-be-carrying-funds-raised-in-eos-ico/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24964715</guid>
            <pubDate>Mon, 02 Nov 2020 04:00:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exit Interview]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24964673">thread link</a>) | @todsacerdoti
<br/>
November 1, 2020 | https://www.heyheatheritsmeagain.com/blog/exit-interview | <a href="https://web.archive.org/web/*/https://www.heyheatheritsmeagain.com/blog/exit-interview">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
      <main><p>Hey Heather, it’s me again.</p>

<p>So I’ve been meaning to write for a while but it’s been difficult. For many
reasons which I won’t lament about here. At least not at the moment. That said,
today I’m writing about exit interviews. You can skip the context and go to <a href="#how-to-escape-the-interview">how
I handled the situation</a> if you just care about
that.</p>

<h2 id="context">Context</h2>

<p>A few years ago, I was asking myself a series of existential questions.
Eventually I decided I was unhappy with my current situation and had to leave my
job. Coincidentally, a colleague had decided the same a week prior (off by one
as developer logic dictates). This meant that I witnessed the process my
colleague went through beforehand and let me tell you, I did <em>not</em> want to go
through <em>that</em>. Let me explain what happened.</p>

<p>So when you work for a large boat institution™, the general process for leaving,
at least in my experience, is as follows:</p>

<ol>
  <li>You have a meeting with your manager to announce you’re leaving</li>
  <li>You hand them a letter or send an email specifying last day</li>
  <li>You have an exit interview with HR</li>
</ol>

<p>This all seemed fine to me until I saw the state my colleague was in after their
exit interview. Without going into specifics I’ll just say that during the
interview, HR persistently asked <a href="https://en.wikipedia.org/wiki/Leading_question">leading questions</a> so that the
answers would have it seem like the primary reason for leaving was a personal
matter and not organizational problems. …</p>

<p>what. the. hell. man.</p>

<p>What’s even the point of skewing this type of information? I don’t know what
type of incentives or motivations HR has but this type of institutional
behavior is insidious. Not only does this conceal internal problems, but it also
damages trust with current employees. People talk.</p>

<p>After seeing how distraught my colleague was after the meeting, I got anxious
and was not looking forward to the invitation. Once I received the invite, I
shared my concern with my manager who said something along the lines of “just do
it”. … <em>whoosh</em>.</p>

<p>This was not the support I needed. So this is what I did instead.</p>

<h2 id="how-to-escape-the-interview">How to escape the interview</h2>

<p>I reached out to HR by email asking them if it was necessary to have the exit
interview and if instead we could find another arrangement. No reply. Again
worried. Then I remembered:</p>

<p>I am an adult and you can’t make me.</p>

<p>The relationship I have with an organization is a professional relationship and
therefore that was how I approached my subsequent actions.</p>

<p>Since I didn’t get a reply to my questions, I declined the invitation and wrote
an email stating that I was not going to partake in the in-person exit interview
but that I would answer questions in writing if they wished to send any. Almost
immediately HR reached out saying they really preferred to talk. I reiterated
that I was declining and that I would answer questions in writing. They
eventually sent a link to an questionnaire. That was basically it.</p>

<h2 id="writing-as-evidence">Writing as evidence</h2>

<p>An important takeaway from this experience was that it’s better to have things
in writing. If the information is being filtered through another person, it’ll
probably have some of their interpretation injected into it. Leading questions
are also less likely to appear in questionnaires.</p>

<p>I’d also recommend keeping a copy of the questions and answers, as well as
copies of all your correspondence with HR and management. You can BCC and
forward emails to your personal inbox so that you have copies if you need to
refer to them after you’ve left.</p>


    
  </main>
</div></div>]]>
            </description>
            <link>https://www.heyheatheritsmeagain.com/blog/exit-interview</link>
            <guid isPermaLink="false">hacker-news-small-sites-24964673</guid>
            <pubDate>Mon, 02 Nov 2020 03:47:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Soil fungi act like a support network for trees, study shows]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24964445">thread link</a>) | @DoreenMichele
<br/>
November 1, 2020 | https://www.folio.ca/soil-fungi-act-like-a-support-network-for-trees-study-shows/ | <a href="https://web.archive.org/web/*/https://www.folio.ca/soil-fungi-act-like-a-support-network-for-trees-study-shows/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><h2 title="U of A research is first to show that growth rate of adult trees is linked to fungal networks colonizing their roots.">U of A research is first to show that growth rate of adult trees is linked to fungal networks colonizing their roots.</h2></p><div id="ppmodule_pressrelease"><div>
<div><p>Being highly connected to a strong social network has its benefits. Now a new University of Alberta study is showing the same goes for trees, thanks to their underground neighbours.</p>

<p>The study, published in the <a href="https://besjournals.onlinelibrary.wiley.com/doi/10.1111/1365-2745.13507"><em>Journal of Ecology</em></a>, is the first to show that the growth of adult trees is linked to their participation in fungal networks living in the forest soil.</p>

<ul>
<li><a href="https://www.folio.ca/wildfires-logging-affect-fungi-pine-forests-depend-on-for-survival-studies-show/"><strong>RELATED:</strong> Wildfires, logging affect fungi pine forests depend on for survival, studies show</a></li>
</ul>

<p>Though past research has focused on seedlings, these findings give new insight into the value of fungal networks to older trees—which are more environmentally beneficial for functions like capturing carbon and stabilizing soil erosion.</p>

<p>“Large trees make up the bulk of the forest, so they drive what the forest is doing,” said researcher Joseph Birch, who led the study for his PhD thesis in the <a href="https://www.ualberta.ca/index.html">Faculty of Agricultural, Life &amp; Environmental Sciences</a>.</p>

<p>When they colonize the roots of a tree, fungal networks act as a sort of highway, allowing water, nutrients and even the compounds that send defence signals against insect attacks to flow back and forth among the trees.</p>

<p>The network also helps nutrients flow to resource-limited trees “like family units that support one another in times of stress,” Birch noted.</p>

<p>Cores taken from 350 Douglas firs in British Columbia showed that annual tree ring growth was related to the extent of fungal connections a tree had with other trees. “They had much higher growth than trees that had only a few connections.”</p>

<p>The research also showed that trees with more connections to many unique fungi had much greater growth than those with only one or two connections.</p>

<p>“We found that the more connected an adult tree is, the more it has significant growth advantages, which means the network could really influence large-scale important interactions in the forest, like carbon storage. If you have this network that is helping trees grow faster, that helps sequester more carbon year after year.”</p>

<p>It’s also possible that if the trees grow faster, they’d have some ability to better survive drought that is expected to intensify with climate change, he added.</p>

<p>“These networks may help them grow more steadily even as conditions become more stressful, and could even help buffer trees against death.”</p>

<p>Birch hopes his findings lead to further studies in different kinds of forests in other geographical areas, because it’s likely that the connections among trees change from year to year, he said.</p>

<p>“It’s a very dynamic system that is probably being broken apart and re-formed quite a bit, like family relationships, so we don’t know how they will change under future climates either. Maybe a dry year or a beetle outbreak impacts the network.</p>

<p>“Knowing whether fungal networks are operating the same way in other tree species could factor into how we reforest areas after harvesting them, and it could inform how we want to plant trees to preserve these networks.”</p>

<p>The research was supported by the <a href="https://www.nserc-crsng.gc.ca/index_eng.asp">Natural Sciences and Engineering Research Council of Canada</a>.</p>
</div><!--[if IE]><script>pp_jquery(function() {if (window.PIE){pp_jquery('.pp_pie').each(function(){PIE.attach(this);});}});</script><![endif]-->
</div></div></div>]]>
            </description>
            <link>https://www.folio.ca/soil-fungi-act-like-a-support-network-for-trees-study-shows/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24964445</guid>
            <pubDate>Mon, 02 Nov 2020 02:53:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rendering Essentials in Unity, for Software Engineers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24964423">thread link</a>) | @Eyas
<br/>
November 1, 2020 | https://blog.eyas.sh/2020/10/unity-for-engineers-pt6-rendering/ | <a href="https://web.archive.org/web/*/https://blog.eyas.sh/2020/10/unity-for-engineers-pt6-rendering/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>While most Software Engineers interested in game development will be most
excited about the <em>programming</em> aspect of making a game, you’ll need <em>some</em>
familiarity with graphics, animation, and sound to be successful. This is
especially true if you’re trying to work solo. While a wealth of assets and
resources are available in the
<a href="https://assetstore.unity.com/top-assets/top-download?aid=1011leWs6">Asset Store</a>
(especially when it comes to reasonably-priced
<a href="https://assetstore.unity.com/top-assets/top-paid?aid=1011leWs6">paid assets</a>),
there’s a decent amount you <em>still</em> need to know to execute well when putting
these resources together. In this installment, we’ll discuss Rendering, Render
Pipelines, and Lighting in Unity.</p><p><em>This is <strong><a href="https://blog.eyas.sh/tag/unity-for-software-engineers">Unity for Software Engineers</a></strong>,
a series for those seeking an accelerated introduction to game development in
Unity. More is coming over the next few weeks, so
<a href="http://eepurl.com/gVgusL">consider subscribing</a> for updates.</em></p><h2>Shaders &amp; Materials</h2><p><strong>Shaders</strong> are programs that help transform a <strong>mesh</strong> (made out of <em>vertices</em>
and <em>faces</em>) into a 3D rendered image. Shaders are parameterized with any number
of properties, such as a <em>texture</em> image representing the surface’s appearance,
normal maps representing finer bumps on the mesh, and much more. The shader code
you write determines what kind of properties it receives if any.</p><p>In Unity, each <em>Rendering Pipeline</em> (discussed below) comes with its own set of
standard shaders. All rendering pipelines include a “Simple Lit” shader as the
most common shader, which helps render an object affected by lighting. In all
pipelines, the Simple Lit variation takes in a <em>base</em> color <em>or</em> texture, a
normal map, a smoothness map, and physically-based rendering inputs like
metallic and specular values as properties.1</p><p>A <strong>Material</strong> is effectively <em>an <strong>instance</strong> of a Shader</em>. It is an <em>Asset</em>
that uses a specific shader and defines all relevant input <em>properties</em> on that
Shader.</p><figure><p><span>
      <a href="https://blog.eyas.sh/static/fe9d1e7be6fc30a4aa01a23ccbcf4d26/b602d/materials-example.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.eyas.sh/static/fe9d1e7be6fc30a4aa01a23ccbcf4d26/28a80/materials-example.webp 400w,https://blog.eyas.sh/static/fe9d1e7be6fc30a4aa01a23ccbcf4d26/8d2ea/materials-example.webp 800w,https://blog.eyas.sh/static/fe9d1e7be6fc30a4aa01a23ccbcf4d26/e95e5/materials-example.webp 1067w" sizes="(max-width: 1067px) 100vw, 1067px" type="image/webp">
        <source srcset="https://blog.eyas.sh/static/fe9d1e7be6fc30a4aa01a23ccbcf4d26/a3397/materials-example.png 400w,https://blog.eyas.sh/static/fe9d1e7be6fc30a4aa01a23ccbcf4d26/a331c/materials-example.png 800w,https://blog.eyas.sh/static/fe9d1e7be6fc30a4aa01a23ccbcf4d26/b602d/materials-example.png 1067w" sizes="(max-width: 1067px) 100vw, 1067px" type="image/png">
        <img src="https://blog.eyas.sh/static/fe9d1e7be6fc30a4aa01a23ccbcf4d26/b602d/materials-example.png" alt="Three simple materials using the same Shader, and some of the same textures, to achieve very different looks." title="Three simple materials using the same Shader, and some of the same textures, to achieve very different looks." loading="lazy">
      </picture>
  </a>
    </span></p><figcaption>The inspector page of three different materials using the Universal Render Pipeline's _Simple Lit_ shader.<ul><li>The first material uses a custom <em>base</em> texture giving the shape its
characteristic color.</li><li>The first and second materials use a custom <em>normal map</em> texture giving the
shape a bumpy appearance.</li><li>The second and third materials use a simple white color as their <em>base
color</em>.</li><li>The second and third materials use a high <em>smoothness</em> value, this giving
their surfaces a shiny, reflective appearance.</li><li>While both have the same <em>smoothness</em> value, the rough normal map on the
second material makes it appear significantly less reflective.</li></ul></figcaption></figure><h2>Connecting Shaders to Game Objects</h2><p>For a component to be visible in a game (and in your Scene editor), it needs to
have a <em>Renderer</em> component. There are multiple renderer components available,
but in 3D game design, you’ll most often be using the <em>Mesh Renderer</em>.</p><figure><p><span>
      <a href="https://blog.eyas.sh/static/f3288c25be182d0953e5fc35cb45b328/b6793/renderer-component.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.eyas.sh/static/f3288c25be182d0953e5fc35cb45b328/28a80/renderer-component.webp 400w,https://blog.eyas.sh/static/f3288c25be182d0953e5fc35cb45b328/8d2ea/renderer-component.webp 800w,https://blog.eyas.sh/static/f3288c25be182d0953e5fc35cb45b328/f671c/renderer-component.webp 801w" sizes="(max-width: 801px) 100vw, 801px" type="image/webp">
        <source srcset="https://blog.eyas.sh/static/f3288c25be182d0953e5fc35cb45b328/a3397/renderer-component.png 400w,https://blog.eyas.sh/static/f3288c25be182d0953e5fc35cb45b328/a331c/renderer-component.png 800w,https://blog.eyas.sh/static/f3288c25be182d0953e5fc35cb45b328/b6793/renderer-component.png 801w" sizes="(max-width: 801px) 100vw, 801px" type="image/png">
        <img src="https://blog.eyas.sh/static/f3288c25be182d0953e5fc35cb45b328/b6793/renderer-component.png" alt="An example of a Cube in a scene, hooked up to a custom material." title="An example of a Cube in a scene, hooked up to a custom material." loading="lazy">
      </picture>
  </a>
    </span></p><figcaption><p>An example of a Cube in a scene hooked up to a custom material.</p></figcaption></figure><p>Objects created from the <em>Game Object &gt; 3D Object &gt;</em> menu, such as <em>Cube</em>,
<em>Sphere</em>, <em>Capsule</em>, and others will automatically include:</p><ul><li>A Mesh Renderer component, linked to a default <em>Simple Lit</em> material</li><li>An appropriate Collider component (“Box Collider” for a cube, “Sphere
Collider” for a sphere, etc.), sized precisely to the object, and</li><li>A <em>Mesh Filter</em> component, which defines the Mesh the Renderer should use.</li></ul><p>A <strong>Mesh</strong> is effectively Unity’s term for a 3D model. A Mesh is an <em>asset</em>
containing a description of an object’s <em>vertices</em> and <em>faces</em>. A mesh defines a
“swatch” of materials for each face. This way, you can have meshes (e.g., for an
entire building) where all exterior, floor, wall, and window materials are
described as separate materials. A Mesh doesn’t specify <em>what the materials are</em>
per se, but just that a given collection of faces have the same material.</p><p>When a mesh is selected in a Mesh Filter component, the Renderer’s <em>Materials</em>
array property can be used to hook up each material. If you mis-order your
materials in the above example, you can end up with a glass building and brick
windows. Unity’s primitive meshes only use a single material throughout all
faces of an object.</p><h2>Rendering Pipelines</h2><p>In Unity, a
<a href="https://docs.unity3d.com/Manual/render-pipelines.html">Render Pipeline</a> is the
system responsible for the end-to-end rendering of a scene. Historically, Unity
came with a single general-purpose system known as the <strong>Built-in Render
Pipeline</strong>. Starting with Unity 2018, Unity introduced the <strong>Scriptable Render
Pipeline</strong> (<strong>SRP</strong>) technology. Two SRP-based pipelines are included with
Unity:</p><ul><li>The <strong>Universal Render Pipeline</strong> (<strong>URP</strong>): A lightweight, high-performance
pipeline that is easy to use and broadly cross-platform. It is great for any
platform, including PC, Mobile, and Nintendo Switch. URP was previously
known as the <em>Lightweight Render Pipeline</em> (<em>LWRP</em>).</li><li>The <strong>High Definition Render Pipeline</strong> (<strong>HDRP</strong>): A high-quality pipeline
for high-end platforms. It is particularly great for highly photorealistic
games on beefier PCs and consoles.</li></ul><p>URP is intended to replace the Built-in Render Pipeline as Unity’s
out-of-the-box default. While URP has graduated out of beta, it’s <em>not quite
there yet</em> in terms of 1:1 feature parity. This may or may not matter to you.</p><h3>What Should I Start Using Today?</h3><p>The thing to note is that each rendering pipeline comes with <em>its own set of
shaders</em> (HDRP’s <em>Lit</em> shaders can be significantly more complex than URP’s, for
example). The SRP transition also changed how Unity shaders are written, meaning
that custom shaders written for the old Built-in render pipeline aren’t
compatible with SRP and must be manually ported to SRP. This means that Unity’s
<a href="https://assetstore.unity.com/top-assets/top-download?aid=1011leWs6">ecosystem of assets</a>
became fragmented and individual assets need to put work to support SRP. This is
fairly easy for assets that use simple shaders, but assets with custom shaders
will need to support URP and HDRP explicitly.</p><p>We’re at a point where:</p><ul><li>URP is the future and is <em>easier to use</em></li><li>The Built-in render pipeline is likely <em>good enough</em> and will give you a
more comprehensive selection of compatible assets</li><li>HDRP is hard to use for someone just starting, but probably a good platform
to invest time in if you’re interested in graphically striking games</li></ul><p>If you’re starting development today because you want to <strong>learn</strong> and
<strong>experiment</strong>, I suggest you start with <strong>URP</strong>. Other than limited assets, URP
<em>currently</em> has some limitations with <em>grass</em> and <em>trees</em>.</p><p>If you’re starting development today because you have a <strong>concrete game idea you
want to finish within the next year or so</strong>, I suggest you start with the
<strong>Built-in</strong> render pipeline. You’ll miss out on learning the ”<em>right way</em>” of
doing things in the future, but you’ll likely have a less frustrating
experience.</p><p>I recommend <strong>URP</strong> if you’re starting today with the primary goal of <em>learning</em>
because:</p><ul><li>SRP usually <em>makes sense</em> if you’re starting from scratch;</li><li>If there’s a way to do something in URP, it’s more likely to be fairly
obvious. If you find yourself trying to get something to work that doesn’t
seem to, chances are it’s just not yet supported.</li></ul><p>This advice is hotly contested, though, so your mileage may vary.</p><h2>Lighting</h2><p>When I started with Unity, I expected to spend approximately ~0 minutes worrying
about lighting. It turns out that I underestimated two things: (a) the
difference good lighting makes in what my scene can look like, and (b) how hard
it is to have lighting that is both <em>good</em> and <em>performant</em>. By the way, I
highly recommend
<a href="https://docs.unity3d.com/Manual/LightingInUnity.html">Unity’s Introduction to Lighting</a>
section of their user manual.</p><figure><p><span>
      <a href="https://blog.eyas.sh/static/1a427d6ba273bfa093931effe208e67a/ac795/no-lighting-baked.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.eyas.sh/static/1a427d6ba273bfa093931effe208e67a/28a80/no-lighting-baked.webp 400w,https://blog.eyas.sh/static/1a427d6ba273bfa093931effe208e67a/8d2ea/no-lighting-baked.webp 800w,https://blog.eyas.sh/static/1a427d6ba273bfa093931effe208e67a/43d96/no-lighting-baked.webp 1600w,https://blog.eyas.sh/static/1a427d6ba273bfa093931effe208e67a/03909/no-lighting-baked.webp 1753w" sizes="(max-width: 1600px) 100vw, 1600px" type="image/webp">
        <source srcset="https://blog.eyas.sh/static/1a427d6ba273bfa093931effe208e67a/a3397/no-lighting-baked.png 400w,https://blog.eyas.sh/static/1a427d6ba273bfa093931effe208e67a/a331c/no-lighting-baked.png 800w,https://blog.eyas.sh/static/1a427d6ba273bfa093931effe208e67a/1a152/no-lighting-baked.png 1600w,https://blog.eyas.sh/static/1a427d6ba273bfa093931effe208e67a/ac795/no-lighting-baked.png 1753w" sizes="(max-width: 1600px) 100vw, 1600px" type="image/png">
        <img src="https://blog.eyas.sh/static/1a427d6ba273bfa093931effe208e67a/1a152/no-lighting-baked.png" alt="Real-time Direct Light Only" title="Real-time Direct Light Only" loading="lazy">
      </picture>
  </a>
    </span>
<span>
      <a href="https://blog.eyas.sh/static/b633e7b3948655b90f8075df3c505a54/ac795/static-scene-baked-gi-realtime-direct.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.eyas.sh/static/b633e7b3948655b90f8075df3c505a54/28a80/static-scene-baked-gi-realtime-direct.webp 400w,https://blog.eyas.sh/static/b633e7b3948655b90f8075df3c505a54/8d2ea/static-scene-baked-gi-realtime-direct.webp 800w,https://blog.eyas.sh/static/b633e7b3948655b90f8075df3c505a54/43d96/static-scene-baked-gi-realtime-direct.webp 1600w,https://blog.eyas.sh/static/b633e7b3948655b90f8075df3c505a54/03909/static-scene-baked-gi-realtime-direct.webp 1753w" sizes="(max-width: 1600px) 100vw, 1600px" type="image/webp">
        <source srcset="https://blog.eyas.sh/static/b633e7b3948655b90f8075df3c505a54/a3397/static-scene-baked-gi-realtime-direct.png 400w,https://blog.eyas.sh/static/b633e7b3948655b90f8075df3c505a54/a331c/static-scene-baked-gi-realtime-direct.png 800w,https://blog.eyas.sh/static/b633e7b3948655b90f8075df3c505a54/1a152/static-scene-baked-gi-realtime-direct.png 1600w,https://blog.eyas.sh/static/b633e7b3948655b90f8075df3c505a54/ac795/static-scene-baked-gi-realtime-direct.png 1753w" sizes="(max-width: 1600px) 100vw, 1600px" type="image/png">
        <img src="https://blog.eyas.sh/static/b633e7b3948655b90f8075df3c505a54/1a152/static-scene-baked-gi-realtime-direct.png" alt="Baked Global Illumination in addition to real-time Direct Light" title="Baked Global Illumination in addition to real-time Direct Light" loading="lazy">
      </picture>
  </a>
    </span></p><figcaption>A simple scene constructed with primitive objects and a number of basic materials, shown under two lighting states.<!-- --> <strong>Above:</strong> Two angles showing a scene with only real-time lighting.<!-- --> <strong>Below:</strong> The same angles showing a scene with baked indirect lights, in addition to real-time lighting.</figcaption></figure><p>In the real world, light travels from its sources and onto objects in the world.
Some of it is absorbed, and some of it scatters. An object in the shade will
still be visible, even though no direct light shines on it from the sun.
Computers can simulate a very realistic rendering using <em>ray tracing</em>, which
imitates the physics of light. But rendering an entire scene with ray tracing is
quite expensive, and broadly speaking, it can not be done reliably in real-time.</p><p>In the real-time context of a game, there are different strategies to deal with
light. Let’s describe a few of these concepts:</p><h3><em>Direct</em> and <em>Indirect</em> Lighting</h3><p>If a light ray leaving its source bounces on an object exactly once and reaches
the camera, the light is <em>direct</em>. The part of the object that the light bounced
off of is directly lit. This light is easy to compute, given the color,
intensity, and distance of the light and the physical properties of the
material.</p><p>Direct lighting and shadows due to a direct light are reasonably quick to
compute. Depending on the rendering pipeline, however, an object lit by
<em>multiple lights</em> in real-time will be rendered over multiple passes (one for
each light). Unity, for instance, will limit the maximum number of direct lights
that can influence an object.</p><p>Indirect lighting, on the other hand, is any <em>other</em> light that reaches the
camera. This is light that has bounced off any number of surfaces before
reaching us. Light coming directly or indirectly from a 3D scene’s skybox, which
is somewhat emissive, (imitating the scattered light throughout the sky that
illuminates the world) will contribute to indirect lighting.</p><p>Indirect lighting is crucial in rendering a realistic scene. Imagine a cube in a
daylight 3D scene. The faces of the cube in shadow should <em>not</em> appear
completely black.</p><p>For example, in the figure above, the left side predominantly shows shaded faces
of our 3D objects. Only <em>direct</em> lights are accounted for in the top-left
corner, thus making the objects appear excessively dark and hard to tell apart.</p><h3>Global Illumination</h3><p>A scene’s <em>global illumination</em> (GI) represents the totality of light from all
sources. Unity offers no supported way to compute global illumination in real
time<sup id="fnref-1"><a href="#fn-1">1</a></sup>, and instead provides a <strong>Baked Global Illumination</strong> system that uses
a few techniques that work together to produce GI:</p><ol><li><strong>Lightmap…</strong></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.eyas.sh/2020/10/unity-for-engineers-pt6-rendering/">https://blog.eyas.sh/2020/10/unity-for-engineers-pt6-rendering/</a></em></p>]]>
            </description>
            <link>https://blog.eyas.sh/2020/10/unity-for-engineers-pt6-rendering/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24964423</guid>
            <pubDate>Mon, 02 Nov 2020 02:46:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rewire: A New Approach to Dependency Injection in Elixir]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24964122">thread link</a>) | @stephanos2k
<br/>
November 1, 2020 | https://blog.stephanbehnke.com/rewire-new-approach-to-dependency-injection-in-elixir/ | <a href="https://web.archive.org/web/*/https://blog.stephanbehnke.com/rewire-new-approach-to-dependency-injection-in-elixir/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
		<p><span>Written by</span>
        Stephan Behnke
        <br>
        <span>on&nbsp;</span><time datetime="2020-10-30 00:38:50 +0000 UTC">October 30, 2020</time>
</p>
		


		


		<p>I’ve been working with Elixir for 3 years full-time now and while I think it’s an exceptional language and development environment, the testing story always felt incomplete to me. Something was missing. In this post, I’ll explain what that is and how I attempted to fix it.</p>
<h2 id="injecting-mocks">Injecting Mocks</h2>
<p>While I strive to minimize the use of mocks, I find they are still quite useful in certain situations.</p>
<p>Before Elixir, I’ve mainly worked with Java. For better or worse, in Java you have a multitude of options to inject dependencies into your classes. Most notably, <code>@Autowired</code> that allows you to simply override annotated fields during testing with your mock. Could not be simpler.</p>
<p>In Elixir things are a little different. That’s because Elixir does not have classes or class fields. Modules are <em>stateless</em>. So how does one inject a dependency in Elixir?</p>
<p>Let’s look at this simplified example and explore our options:</p>
<div><pre><code data-lang="elixir"><span>defmodule</span> <span>Conversation</span> <span>do</span>
  <span>def</span> <span>start</span><span>(),</span> <span>do</span><span>:</span> <span>English</span><span>.</span><span>greet</span><span>()</span>
<span>end</span>
</code></pre></div><h2 id="-function-arguments">🛑 Function Arguments</h2>
<p>The easiest approach does not require any libraries: passing-in dependencies using the function arguments.</p>
<div><pre><code data-lang="elixir"><span>defmodule</span> <span>Conversation</span> <span>do</span>
  <span>def</span> <span>start</span><span>(</span><span>lang_mod</span> <span>\\</span> <span>English</span><span>),</span> <span>do</span><span>:</span> <span>lang_mod</span><span>.</span><span>greet</span><span>()</span>
<span>end</span>
</code></pre></div><div><pre><code data-lang="elixir"><span>defmodule</span> <span>MyTest</span> <span>do</span>
  <span>use</span> <span>ExUnit.Case</span><span>,</span> <span>async</span><span>:</span> <span>false</span>

  <span>test</span> <span>"start/0"</span> <span>do</span>
    <span>defmodule</span> <span>EnglishMock</span> <span>do</span>
      <span>def</span> <span>greet</span><span>(),</span> <span>do</span><span>:</span> <span>"g'day"</span>
    <span>end</span>
    <span>assert</span> <span>Conversation</span><span>.</span><span>start</span><span>(</span><span>EnglishMock</span><span>)</span> <span>==</span> <span>"g'day"</span>
  <span>end</span>
<span>end</span>
</code></pre></div><p>While many (including myself) find this to look “odd” at first, it is admittedly easy to do.</p>
<p>However, it comes with quite a few drawbacks:</p>
<ol>
<li>Your application code is now littered with testing concerns.</li>
<li>Navigation in your code editor doesn’t work as well.</li>
<li>Searches for usages of the module are more difficult.</li>
<li>The compiler is not able to warn you in case <code>greet/0</code> doesn’t exist on the <code>English</code> module.</li>
</ol>
<h2 id="-global-override">🛑 Global Override</h2>
<p>The Elixir library <a href="https://hex.pm/packages/mock">mock</a> (wrapping the Erlang library <a href="https://hex.pm/packages/meck">meck</a> under the hood) allows overriding any module globally.</p>
<div><pre><code data-lang="elixir"><span>defmodule</span> <span>MyTest</span> <span>do</span>
  <span>use</span> <span>ExUnit.Case</span><span>,</span> <span>async</span><span>:</span> <span>false</span>   <span># not concurrently!</span>

  <span>import</span> <span>Mock</span>

  <span>test</span> <span>"start/0"</span> <span>do</span>
    <span>with_mock</span> <span>English</span><span>,</span> <span>[</span><span>greet</span><span>:</span> <span>fn</span><span>()</span> <span>-&gt;</span> <span>"g'day"</span> <span>end</span><span>]</span> <span>do</span>
      <span>assert</span> <span>Conversation</span><span>.</span><span>start</span><span>()</span> <span>==</span> <span>"g'day"</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div><p>Here the <code>English</code> module is temporarily replaced with a mock that stubs out the <code>greet</code> function. So far so good - but it comes with a cost. One of ExUnit’s most valuable features is the ability to run tests <em>concurrently</em>. However, to stub out modules <em>globally</em> we have to exempt this test module from being run concurrently (notice the <code>async: false</code>). This might seem like a small price to pay but if your application grows you might soon find yourself with a slow test suite. This can easily be avoided!</p>
<h2 id="-configuration-lookup">🛑 Configuration Lookup</h2>
<p>The more or less official mocking library for Elixir is <a href="https://hex.pm/packages/mox">mox</a>.</p>
<div><pre><code data-lang="elixir"><span># in test_helper.exs</span>
<span>Mox</span><span>.</span><span>defmock</span><span>(</span><span>EnglishMock</span><span>,</span> <span>for</span><span>:</span> <span>English</span><span>)</span>
<span>Application</span><span>.</span><span>put_env</span><span>(</span><span>:myapp</span><span>,</span> <span>:english</span><span>,</span> <span>EnglishMock</span><span>)</span>
</code></pre></div><div><pre><code data-lang="elixir"><span>defmodule</span> <span>Conversation</span> <span>do</span>
  <span>def</span> <span>start</span><span>(),</span> <span>do</span><span>:</span> <span>english</span><span>()</span><span>.</span><span>greet</span><span>()</span>
  <span>defp</span> <span>english</span><span>(),</span> <span>do</span><span>:</span> <span>Application</span><span>.</span><span>get</span><span>(</span><span>:myapp</span><span>,</span> <span>:english</span><span>,</span> <span>English</span><span>)</span>
<span>end</span>
</code></pre></div><div><pre><code data-lang="elixir"><span>defmodule</span> <span>MyTest</span> <span>do</span>
  <span>use</span> <span>ExUnit.Case</span><span>,</span> <span>async</span><span>:</span> <span>true</span>  <span># concurrently!</span>

  <span>import</span> <span>Mox</span>

  <span>test</span> <span>"start/0"</span> <span>do</span>
    <span>stub</span><span>(</span><span>English</span><span>,</span> <span>:greet</span><span>,</span> <span>fn</span> <span>-&gt;</span> <span>"g'day"</span> <span>end</span><span>)</span>
    <span>assert</span> <span>Conversation</span><span>.</span><span>start</span><span>()</span> <span>==</span> <span>"g'day"</span>
  <span>end</span>
<span>end</span>
</code></pre></div><p><code>mox</code> provides a mock that is “injected” into the module under test by doing a lookup in the app’s configuration.</p>
<p>The advantage is that the “odd” function parameter is gone, but all of the other issues are still there. But at least it can be run concurrently since the mock is set up <em>per process</em> (and each test module is its own process in ExUnit).</p>
<h2 id="-rewire">🎉 rewire</h2>
<p>I wasn’t satisfied with any of these options. So I experimented a little with Elixir metaprogramming and the result was <a href="https://hex.pm/packages/rewire">rewire</a>.</p>
<p>It focuses purely on dependency injection and can be used with any mocking library, like <code>mox</code>.</p>
<div><pre><code data-lang="elixir"><span># in test_helper.exs</span>
<span>Mox</span><span>.</span><span>defmock</span><span>(</span><span>EnglishMock</span><span>,</span> <span>for</span><span>:</span> <span>English</span><span>)</span>
</code></pre></div><div><pre><code data-lang="elixir"><span>defmodule</span> <span>MyTest</span> <span>do</span>
  <span>use</span> <span>ExUnit.Case</span><span>,</span> <span>async</span><span>:</span> <span>true</span>  <span># concurrently!</span>

  <span>import</span> <span>Rewire</span>
  <span>import</span> <span>Mox</span>

  <span>rewire</span> <span>Conversation</span><span>,</span> <span>English</span><span>:</span> <span>EnglishMock</span>  <span># inject!</span>

  <span>test</span> <span>"start/0"</span> <span>do</span>
    <span>stub</span><span>(</span><span>EnglishMock</span><span>,</span> <span>:greet</span><span>,</span> <span>fn</span> <span>-&gt;</span> <span>"g'day"</span> <span>end</span><span>)</span>
    <span>assert</span> <span>Conversation</span><span>.</span><span>start</span><span>()</span> <span>==</span> <span>"g'day"</span>
  <span>end</span>
<span>end</span>
</code></pre></div><p>By following this approach, we keep our production code completely free of testing concerns and the test can still be run concurrently!</p>
<p>You can use it with any mocking library, not just <code>mox</code>. Or just stubs you defined yourself. It only cares about dependency injection.</p>
<h2 id="ehm-but-how-does-it-work">Ehm, But How Does it Work?</h2>
<p><code>rewire</code> is a macro, imported via <code>import Rewire</code>.</p>
<p>Let’s look at what code the macro generated here:</p>
<div><pre><code data-lang="elixir"><span>defmodule</span> <span>Conversation.R518</span> <span>do</span>
  <span>def</span> <span>start</span><span>(),</span> <span>do</span><span>:</span> <span>EnglishMock</span><span>.</span><span>greet</span><span>()</span>
<span>end</span>

<span>alias</span> <span>Conversation.R518</span><span>,</span> <span>as</span><span>:</span> <span>Conversation</span>
</code></pre></div><p>First, it generates a <em>copy</em> of the original module with the <code>English</code> reference <em>replaced</em> by <code>EnglishMock</code>. You might also notice that the module name has changed. Since the module might be rewired in multiple places, this is supposed to prevent naming collisions.</p>
<p>Then, it adds an alias to the rewired module under the <em>original</em> name.</p>
<p>You might wonder how it generates a new module from the original one. The library finds the module’s source file path by calling <code>module_info</code>, parses the code into an AST with <code>Code.string_to_quoted</code>, traverses the AST to replace any rewired dependencies using <code>Macro.traverse</code> and evaluates the result with <code>Code.eval_quoted</code>. Check out the <a href="https://github.com/stephanos/rewire/blob/master/lib/rewire">source code</a> for details.</p>
<h2 id="limitation">Limitation</h2>
<p>As far as I know, the only situation where you cannot use <code>rewire</code> to inject your dependencies is when you are dealing with a process that has been started <em>before</em> your test.</p>
<p>Take for example a <a href="https://www.phoenixframework.org/">Phoenix</a> controller test. Since you’ll be writing tests against the server (using <code>ConnCase</code>), a dependency in the controller cannot be rewired after the fact.</p>
<h2 id="la-fin">La Fin</h2>
<p>I hope you enjoyed this blog post. If you have any questions or feedback, please leave a comment. And if you’re curious, try out <a href="https://hex.pm/packages/rewire">rewire</a> yourself.</p>


		








<p><a href="https://disqus.com/">comments powered by </a>

	</p></div>

	
</div></div>]]>
            </description>
            <link>https://blog.stephanbehnke.com/rewire-new-approach-to-dependency-injection-in-elixir/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24964122</guid>
            <pubDate>Mon, 02 Nov 2020 01:31:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Developing a game using the tool I made]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24963979">thread link</a>) | @atum47
<br/>
November 1, 2020 | https://victorribeiro.com/kingdomClone/ | <a href="https://web.archive.org/web/*/https://victorribeiro.com/kingdomClone/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://victorribeiro.com/kingdomClone/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24963979</guid>
            <pubDate>Mon, 02 Nov 2020 00:59:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Names are not type safety]]>
            </title>
            <description>
<![CDATA[
Score 256 | Comments 121 (<a href="https://news.ycombinator.com/item?id=24963821">thread link</a>) | @azhenley
<br/>
November 1, 2020 | http://lexi-lambda.github.io/blog/2020/11/01/names-are-not-type-safety/ | <a href="https://web.archive.org/web/*/http://lexi-lambda.github.io/blog/2020/11/01/names-are-not-type-safety/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section role="main">
        <!-- Main column -->
        <div>



          <article>
  <header>
    
    
  </header>

<p>Haskell programmers spend a lot of time talking about <em>type safety</em>. The Haskell school of program construction advocates “capturing invariants in the type system” and “making illegal states unrepresentable,” both of which sound like compelling goals, but are rather vague on the techniques used to achieve them. Almost exactly one year ago, I published <a href="http://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/">Parse, Don’t Validate</a> as an initial stab towards bridging that gap.</p>

<p>The ensuing discussions were largely productive and right-minded, but one particular source of confusion quickly became clear: Haskell’s <code>newtype</code> construct. The idea is simple enough—the <code>newtype</code> keyword declares a wrapper type, nominally distinct from but representationally equivalent to the type it wraps—and on the surface this <em>sounds</em> like a simple and straightforward path to type safety. For example, one might consider using a <code>newtype</code> declaration to define a type for an email address:</p>

<div>
 <div>
  <pre><span></span><span>newtype</span> <span>EmailAddress</span> <span>=</span> <span>EmailAddress</span> <span>Text</span>
</pre></div>

</div>

<p>This technique can provide <em>some</em> value, and when coupled with a smart constructor and an encapsulation boundary, it can even provide some safety. But it is a meaningfully distinct <em>kind</em> of type safety from the one I highlighted a year ago, one that is far weaker. On its own, a newtype is just a name.</p>

<p>And names are not type safety.</p>
<!-- more-->



<p>To illustrate the difference between constructive data modeling (discussed at length in my <a href="http://lexi-lambda.github.io/blog/2020/08/13/types-as-axioms-or-playing-god-with-static-types/">previous blog post</a>) and newtype wrappers, let’s consider an example. Suppose we want a type for “an integer between 1 and 5, inclusive.” The natural constructive modeling would be an enumeration with five cases:</p>

<div>
 <div>
  <pre><span></span><span>data</span> <span>OneToFive</span>
  <span>=</span> <span>One</span>
  <span>|</span> <span>Two</span>
  <span>|</span> <span>Three</span>
  <span>|</span> <span>Four</span>
  <span>|</span> <span>Five</span>
</pre></div>

</div>

<p>We could then write some functions to convert between <code>Int</code> and our <code>OneToFive</code> type:</p>

<div>
 <div>
  <pre><span></span><span>toOneToFive</span> <span>::</span> <span>Int</span> <span>-&gt;</span> <span>Maybe</span> <span>OneToFive</span>
<span>toOneToFive</span> <span>1</span> <span>=</span> <span>Just</span> <span>One</span>
<span>toOneToFive</span> <span>2</span> <span>=</span> <span>Just</span> <span>Two</span>
<span>toOneToFive</span> <span>3</span> <span>=</span> <span>Just</span> <span>Three</span>
<span>toOneToFive</span> <span>4</span> <span>=</span> <span>Just</span> <span>Four</span>
<span>toOneToFive</span> <span>5</span> <span>=</span> <span>Just</span> <span>Five</span>
<span>toOneToFive</span> <span>_</span> <span>=</span> <span>Nothing</span>

<span>fromOneToFive</span> <span>::</span> <span>OneToFive</span> <span>-&gt;</span> <span>Int</span>
<span>fromOneToFive</span> <span>One</span>   <span>=</span> <span>1</span>
<span>fromOneToFive</span> <span>Two</span>   <span>=</span> <span>2</span>
<span>fromOneToFive</span> <span>Three</span> <span>=</span> <span>3</span>
<span>fromOneToFive</span> <span>Four</span>  <span>=</span> <span>4</span>
<span>fromOneToFive</span> <span>Five</span>  <span>=</span> <span>5</span>
</pre></div>

</div>

<p>This would be perfectly sufficient for achieving our stated goal, but you’d be forgiven for finding it odd: it would be rather awkward to work with in practice. Because we’ve invented an entirely new type, we can’t reuse any of the usual numeric functions Haskell provides. Consequently, many programmers would gravitate towards a newtype wrapper, instead:</p>

<div>
 <div>
  <pre><span></span><span>newtype</span> <span>OneToFive</span> <span>=</span> <span>OneToFive</span> <span>Int</span>
</pre></div>

</div>

<p>Just as before, we can provide <code>toOneToFive</code> and <code>fromOneToFive</code> functions, with identical types:</p>

<div>
 <div>
  <pre><span></span><span>toOneToFive</span> <span>::</span> <span>Int</span> <span>-&gt;</span> <span>Maybe</span> <span>OneToFive</span>
<span>toOneToFive</span> <span>n</span>
  <span>|</span> <span>n</span> <span>&gt;=</span> <span>1</span> <span>&amp;&amp;</span> <span>n</span> <span>&lt;=</span> <span>5</span> <span>=</span> <span>Just</span> <span>$</span> <span>OneToFive</span> <span>n</span>
  <span>|</span> <span>otherwise</span>        <span>=</span> <span>Nothing</span>

<span>fromOneToFive</span> <span>::</span> <span>OneToFive</span> <span>-&gt;</span> <span>Int</span>
<span>fromOneToFive</span> <span>(</span><span>OneToFive</span> <span>n</span><span>)</span> <span>=</span> <span>n</span>
</pre></div>

</div>

<p>If we put these declarations in their own module and choose not to export the <code>OneToFive</code> constructor, these APIs might appear entirely interchangeable. Naïvely, it seems that the newtype version is both simpler and equally type-safe. However—perhaps surprisingly—this is not actually true.</p>

<p>To see why, suppose we write a function that consumes a <code>OneToFive</code> value as an argument. Under the constructive modeling, such a function need only pattern-match against each of the five constructors, and GHC will accept the definition as exhaustive:</p>

<div>
 <div>
  <pre><span></span><span>ordinal</span> <span>::</span> <span>OneToFive</span> <span>-&gt;</span> <span>Text</span>
<span>ordinal</span> <span>One</span>   <span>=</span> <span>"first"</span>
<span>ordinal</span> <span>Two</span>   <span>=</span> <span>"second"</span>
<span>ordinal</span> <span>Three</span> <span>=</span> <span>"third"</span>
<span>ordinal</span> <span>Four</span>  <span>=</span> <span>"fourth"</span>
<span>ordinal</span> <span>Five</span>  <span>=</span> <span>"fifth"</span>
</pre></div>

</div>

<p>The same is not true given the newtype encoding. The newtype is opaque, so the only way to observe it is to convert it back to an <code>Int</code>—after all, it <em>is</em> an <code>Int</code>. An <code>Int</code> can of course contain many other values besides <code>1</code> through <code>5</code>, so we are forced to add an error case to satisfy the exhaustiveness checker:</p>

<div>
 <div>
  <pre><span></span><span>ordinal</span> <span>::</span> <span>OneToFive</span> <span>-&gt;</span> <span>Text</span>
<span>ordinal</span> <span>n</span> <span>=</span> <span>case</span> <span>fromOneToFive</span> <span>n</span> <span>of</span>
  <span>1</span> <span>-&gt;</span> <span>"first"</span>
  <span>2</span> <span>-&gt;</span> <span>"second"</span>
  <span>3</span> <span>-&gt;</span> <span>"third"</span>
  <span>4</span> <span>-&gt;</span> <span>"fourth"</span>
  <span>5</span> <span>-&gt;</span> <span>"fifth"</span>
  <span>_</span> <span>-&gt;</span> <span>error</span> <span>"impossible: bad OneToFive value"</span>
</pre></div>

</div>

<p>In this highly contrived example, this may not seem like much of a problem to you. But it nonetheless illustrates a key difference in the guarantees afforded by the two approaches:</p>

<ul>
 <li>
  <p>The constructive datatype captures its invariants in such a way that they are <em>accessible</em> to downstream consumers. This frees our <code>ordinal</code> function from worrying about handling illegal values, as they have been made unutterable.</p></li>
 <li>
  <p>The newtype wrapper provides a smart constructor that <em>validates</em> the value, but the boolean result of that check is used only for control flow; it is not preserved in the function’s result. Accordingly, downstream consumers cannot take advantage of the restricted domain; they are functionally accepting <code>Int</code>s.</p></li></ul>

<p>Losing exhaustiveness checking might seem like small potatoes, but it absolutely is not: our use of <code>error</code> has punched a hole right through our type system. If we were to add another constructor to our <code>OneToFive</code> datatype,<sup><a href="#2020-11-01-names-are-not-type-safety-footnote-1-definition" name="2020-11-01-names-are-not-type-safety-footnote-1-return">1</a></sup> the version of <code>ordinal</code> that consumes a constructive datatype would be immediately detected non-exhaustive at compile-time, while the version that consumes a newtype wrapper would continue to compile yet fail at runtime, dropping through to the “impossible” case.</p>

<p>All of this is a consequence of the fact that the constructive modeling is <em>intrinsically</em> type-safe; that is, the safety properties are enforced by the type declaration itself. Illegal values truly are unrepresentable: there is simply no way to represent <code>6</code> using any of the five constructors. The same is not true of the newtype declaration, which has no intrinsic semantic distinction from that of an <code>Int</code>; its meaning is specified extrinsically via the <code>toOneToFive</code> smart constructor. Any semantic distinction intended by a newtype is thoroughly invisible to the type system; it exists only in the programmer’s mind.</p>

<h2 id="revisiting-non-empty-lists">Revisiting non-empty lists</h2>

<p>Our <code>OneToFive</code> datatype is rather artificial, but identical reasoning applies to other datatypes that are significantly more practical. Consider the <code>NonEmpty</code> datatype I’ve repeatedly highlighted in recent blog posts:</p>

<div>
 <div>
  <pre><span></span><span>data</span> <span>NonEmpty</span> <span>a</span> <span>=</span> <span>a</span> <span>:|</span> <span>[</span><span>a</span><span>]</span>
</pre></div>

</div>

<p>It may be illustrative to imagine a version of <code>NonEmpty</code> represented as a newtype over ordinary lists. We can use the usual smart constructor strategy to enforce the desired non-emptiness property:</p>

<div>
 <div>
  <pre><span></span><span>newtype</span> <span>NonEmpty</span> <span>a</span> <span>=</span> <span>NonEmpty</span> <span>[</span><span>a</span><span>]</span>

<span>nonEmpty</span> <span>::</span> <span>[</span><span>a</span><span>]</span> <span>-&gt;</span> <span>Maybe</span> <span>(</span><span>NonEmpty</span> <span>a</span><span>)</span>
<span>nonEmpty</span> <span>[]</span> <span>=</span> <span>Nothing</span>
<span>nonEmpty</span> <span>xs</span> <span>=</span> <span>Just</span> <span>$</span> <span>NonEmpty</span> <span>xs</span>

<span>instance</span> <span>Foldable</span> <span>NonEmpty</span> <span>where</span>
  <span>toList</span> <span>(</span><span>NonEmpty</span> <span>xs</span><span>)</span> <span>=</span> <span>xs</span>
</pre></div>

</div>

<p>Just as with <code>OneToFive</code>, we quickly discover the consequences of failing to preserve this information in the type system. Our motivating use case for <code>NonEmpty</code> was the ability to write a safe version of <code>head</code>, but the newtype version requires another assertion:</p>

<div>
 <div>
  <pre><span></span><span>head</span> <span>::</span> <span>NonEmpty</span> <span>a</span> <span>-&gt;</span> <span>a</span>
<span>head</span> <span>xs</span> <span>=</span> <span>case</span> <span>toList</span> <span>xs</span> <span>of</span>
  <span>x</span><span>:</span><span>_</span> <span>-&gt;</span> <span>x</span>
  <span>[]</span>  <span>-&gt;</span> <span>error</span> <span>"impossible: empty NonEmpty value"</span>
</pre></div>

</div>

<p>This might not seem like a big deal, since it seems unlikely such a case would ever happen. But that reasoning hinges entirely on trusting the correctness of the module that defines <code>NonEmpty</code>, while the constructive definition only requires trusting the GHC typechecker. As we generally trust that the typechecker works correctly, the latter is a much more compelling proof.</p>



<p>If you are fond of newtypes, this whole argument may seem a bit troubling. It may seem like I’m implying newtypes are scarcely better than comments, albeit comments that happen to be meaningful to the typechecker. Fortunately, the situation is not quite that grim—newtypes <em>can</em> provide a sort of safety, just a weaker one.</p>

<p>The primary safety benefit of newtypes is derived from abstraction boundaries. If a newtype’s constructor is not exported, it becomes opaque to other modules. The module that defines the newtype—its “home module”—can take advantage of this to create a <em>trust boundary</em> where internal invariants are enforced by restricting clients to a safe API.</p>

<p>We can use the <code>NonEmpty</code> example from above to illustrate how this works. We refrain from exporting the <code>NonEmpty</code> constructor, and we provide <code>head</code> and <code>tail</code> operations that we trust to never actually fail:</p>

<div>
 <div>
  <pre><span></span><span>module</span> <span>Data.List.NonEmpty.Newtype</span>
  <span>(</span> <span>NonEmpty</span>
  <span>,</span> <span>cons</span>
  <span>,</span> <span>nonEmpty</span>
  <span>,</span> <span>head</span>
  <span>,</span> <span>tail</span>
  <span>)</span> <span>where</span>

<span>newtype</span> <span>NonEmpty</span> <span>a</span> <span>=</span> <span>NonEmpty</span> <span>[</span><span>a</span><span>]</span>

<span>cons</span> <span>::</span> <span>a</span> <span>-&gt;</span> <span>[</span><span>a</span><span>]</span> <span>-&gt;</span> <span>NonEmpty</span> <span>a</span>
<span>cons</span> <span>x</span> <span>xs</span> <span>=</span> <span>NonEmpty</span> <span>(</span><span>x</span><span>:</span><span>xs</span><span>)</span>

<span>nonEmpty</span> <span>::</span> <span>[</span><span>a</span><span>]</span> <span>-&gt;</span> <span>Maybe</span> <span>(</span><span>NonEmpty</span> <span>a</span><span>)</span>
<span>nonEmpty</span> <span>[]</span> <span>=</span> <span>Nothing</span>
<span>nonEmpty</span> <span>xs</span> <span>=</span> <span>Just</span> <span>$</span> <span>NonEmpty</span> <span>xs</span>

<span>head</span> <span>::</span> <span>NonEmpty</span> <span>a</span> <span>-&gt;</span> <span>a</span>
<span>head</span> <span>(</span><span>NonEmpty</span> <span>(</span><span>x</span><span>:</span><span>_</span><span>))</span> <span>=</span> <span>x</span>
<span>head</span> <span>(</span><span>NonEmpty</span> <span>[]</span><span>)</span>    <span>=</span> <span>error</span> <span>"impossible: empty NonEmpty value"</span>

<span>tail</span> <span>::</span> <span>NonEmpty</span> <span>a</span> <span>-&gt;</span> <span>[</span><span>a</span><span>]</span>
<span>tail</span> <span>(</span><span>NonEmpty</span> <span>(</span><span>_</span><span>:</span><span>xs</span><span>))</span> <span>=</span> <span>xs</span>
<span>tail</span> <span>(</span><span>NonEmpty</span> <span>[]</span><span>)</span>     <span>=</span> <span>error</span> <span>"impossible: empty NonEmpty value"</span>
</pre></div>

</div>

<p>Since the only way to construct or consume <code>NonEmpty</code> values is to use the functions in <code>Data.List.NonEmpty.Newtype</code>’s exported API, the above implementation makes it impossible for clients to violate the non-emptiness invariant. In a sense, values of opaque newtypes are like <em>tokens</em>: the implementing module issues tokens via its constructor functions, and those tokens have no intrinsic value. The only way to do anything useful with them is to “redeem” them to the issuing module’s accessor functions, in this case <code>head</code> and <code>tail</code>, to obtain the values contained within.</p>

<p>This approach is significantly weaker than using a constructive datatype, since it is theoretically possible to screw up and accidentally provide a means to construct an invalid <code>NonEmpty []</code> value. For this reason, the newtype approach to type safety does not on its own constitute a <em>proof</em> that a desired invariant holds. However, it restricts the “surface area” where an invariant violation can occur to the defining module, so reasonable confidence the invariant really does hold can be achieved by thoroughly testing the module’s API using fuzzing or property-based testing techniques.<sup><a href="#2020-11-01-names-are-not-type-safety-footnote-2-definition" name="2020-11-01-names-are-not-type-safety-footnote-2-return">2</a></sup></p>

<p>This tradeoff may not seem all that bad, and indeed, it is often a very good one! Guaranteeing invariants using …</p></article></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://lexi-lambda.github.io/blog/2020/11/01/names-are-not-type-safety/">http://lexi-lambda.github.io/blog/2020/11/01/names-are-not-type-safety/</a></em></p>]]>
            </description>
            <link>http://lexi-lambda.github.io/blog/2020/11/01/names-are-not-type-safety/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24963821</guid>
            <pubDate>Mon, 02 Nov 2020 00:27:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microservices – architecture nihilism in minimalism's clothes]]>
            </title>
            <description>
<![CDATA[
Score 226 | Comments 151 (<a href="https://news.ycombinator.com/item?id=24963742">thread link</a>) | @zdw
<br/>
November 1, 2020 | https://vlfig.me/posts/microservices | <a href="https://web.archive.org/web/*/https://vlfig.me/posts/microservices">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Some recent <a href="https://twitter.com/gergelyorosz/status/1247132806041546754" target="_blank" rel="nofollow noopener noreferrer">backtracking</a> <a href="https://twitter.com/copyconstruct/status/1247130488667394049" target="_blank" rel="nofollow noopener noreferrer">from</a> what we have been calling “Microservices” has sparked anew the debate around that software architecture pattern. It turns out that for increasingly more software people, having a backend with (<a href="https://www.infoq.com/presentations/monzo-microservices/" target="_blank" rel="nofollow noopener noreferrer">sometimes several</a>) hundreds of services wasn’t that great an idea after all. The debate has <a href="https://riak.com/posts/technical/microservices-please-dont/" target="_blank" rel="nofollow noopener noreferrer">been going on for a while</a> and much has already been said, but there are still a couple of things I’d like to say.</p>
<p><strong>TL;DR</strong> “Microservices” was a good idea taken too far and applied too bluntly. The fix isn’t just to dial back the granularity knob but instead to 1) focus on the split-join criteria as opposed to size; and 2) differentiate between the project model and the deployment model when applying them.</p>
<p>I explain. Allow me to rant a bit first.</p>


<p>There were three main reasons for the initial success of <em>microservices</em> as an architectural pattern for software: 1) forced modularisation, 2) weakened dependencies, and 3) an excuse for having no architecture. In order:</p>
<ol>
<li>In the monoliths of old, you could in theory enforce module boundaries. You could say that your <code>acme-helpers</code> or <code>acme-data-tools</code> could not depend on <code>acme-domain</code>, say, and you even had some tooling to enforce that, but it was fallible. Especially in big companies where these monoliths spanned more than a team’s cognitive horizon, violations of those boundaries were often a simple <code>import</code> away, and of course rife. Angry architects saw in microservices the promise of making those a thing of the past: now the developer is forced to only deal with the API. Codebases parted ways and calls were made to go down the network stack and back.</li>
<li>
<p>So then, one wouldn’t depend on a fellow service at build time, only at runtime. Great. Method calls became http calls. “Now we don’t need to care about dependencies” — actual people said this, as if the dependency wasn’t fundamental and instead just an accidental artifact of the build setup. Everybody brushed up on their HTTP and different server and client implementations, read all about REST and Soap (and RPC, RMI and CORBA while at it) and merrily created a layer of indirection between modules — now <em>services</em> — that was <em>very</em> loose. Typed APIs, granular network policies and contract testing came much later.</p>
<p>It felt liberating until the complexities of API versioning, delivery semantics, error propagation, distributed transaction management and the sprawl of client code in all callers of a service began to show up. This was a gigantic <strong>shift right</strong>, but hey, the build process was simpler.</p>
</li>
<li>
<p>More insidious perhaps was the validation that “doing microservices” brought to organisations that lacked a thesis about how their architecture should be. There was now a sanctioned answer to most architectural dilemmas: another microservice. Another entry in the service catalog for any and all interested parties to call. This ecology of interacting parties, each acting in their own interest for the common good spoke to an underlying, tacit belief that the emergent mesh of services would approximate the latent natural architecture of the domain.</p>
<p>So soft and convenient was the lure of not having to draw hard architectural lines that we got lazy where we weren’t and accepted our lazyness where we already were. If you didn’t subscribe to that belief, the problem was you and your lack of understanding of complex systems, you objectivist cretin.</p>
</li>
</ol>
<p>Yes, there was real pain in managing monoliths and sure, many systems were too monolithic (i.e. had deployables too large) but the zealotry of a newfound purity swung the pendulum too far, as they always do. Not only do we not need to run so many services so small, we also don’t benefit from isolating their codebases so much. To summarise:</p>
<ol>
<li>having a big flat permissive build is no good reason to split deployables;</li>
<li>weakening dependencies between different parts of our systems is a “shift-right” loan with high interest; and</li>
<li>having a ready answer when the thinking gets tough is a soothing lie that just moves complexity about. There is no substitute to the effortful application of cognitive power to a problem.</li>
</ol>

<p>Two things: focus on the right criteria for splitting a service instead of on its size, and apply those criteria more thoughtfully.</p>
<h2 id="size-is-not-the-answer"><a href="#size-is-not-the-answer" aria-label="size is not the answer permalink"></a>Size is not the answer</h2>
<p>The <em>micro</em> in microservices ought to be at best a prediction, never a goal. We may predict services <em>will be</em> micro but they don’t <em>have to be</em>. <a href="https://kalele.io/microservices-and-microservices/" target="_blank" rel="nofollow noopener noreferrer">Vaugh Vernon is right</a> when he speaks about “cohesion for a reason”.</p>
<p>There should be no prescribed <em>a priori</em> granularity of services. There <em>is</em> no prescribed size of a service. There are instead <strong>good and bad reasons to split</strong> parts of a software system.</p>
<p>So the heuristic is:</p>
<div data-language="text"><pre><code>                      Start one, split with a reason.</code></pre></div>
<p>Conversely, if a reason ceases to exist, consider joining them.</p>
<h2 id="the-missing-hinge"><a href="#the-missing-hinge" aria-label="the missing hinge permalink"></a>The missing hinge</h2>
<p>There are however different realms in which “software systems” exist: they exist both as artifacts we interact with and as artifacts computers interact with. Code and binary. We organise them in different ways: the <strong>project model</strong> (repositories, projects, modules and their dependencies) and the <strong>deployment model</strong> (what production environments look like and how deployables run in them).</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/6246a/monolith.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="A monolithic setup where one big repo builds one single big deployable." title="A monolithic setup where one big repo builds one single big deployable." src="https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/6a068/monolith.jpg" srcset="https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/09b79/monolith.jpg 240w,
https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/7cc5e/monolith.jpg 480w,
https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/6a068/monolith.jpg 960w,
https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/644c5/monolith.jpg 1440w,
https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/6246a/monolith.jpg 1463w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span>
    <figcaption><p>A monolithic setup where one big repo builds one single big deployable.</p></figcaption>
  </figure>
<p>In the process of going from coarse to granular (i.e. from monolith to microservices) however, little attention was paid to the difference — and possible indirection — between those two models. The hammer hit both fairly indiscriminately and made us split codebases because of runtime concerns and split deployables due to project concerns.</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/6c0a0/stiff-1-1.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="A set of repositories each building their own self-contained independent service." title="Excessive mirroring between the project and deployment models." src="https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/6a068/stiff-1-1.jpg" srcset="https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/09b79/stiff-1-1.jpg 240w,
https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/7cc5e/stiff-1-1.jpg 480w,
https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/6a068/stiff-1-1.jpg 960w,
https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/6c0a0/stiff-1-1.jpg 1062w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span>
    <figcaption><p>Excessive mirroring between the project and deployment models.</p></figcaption>
  </figure>
<p>Much like stiffness in a part of the human spine can result in pain in another, <strong>stiffness in our build DAGs is causing excessive mirroring between our project and deployment models</strong>; between our repositories and our services; between the way we organise our code and the way our services run. That mirroring is on the one hand preventing us from shifting left concerns about the relationships between modules that have often been made weak and fragile runtime dependencies, while on the other hand encouraging us to have more services than what the runtime reality would call for. That brings pain.</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/dc6ba/hinge.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="The build DAG as a hinge between the project model and the deployment model." title="A build DAG mediates the project and the deployment models, absorbing the impedance mismatch between what is human friendly and what is machine-friendly." src="https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/6a068/hinge.jpg" srcset="https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/09b79/hinge.jpg 240w,
https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/7cc5e/hinge.jpg 480w,
https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/6a068/hinge.jpg 960w,
https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/dc6ba/hinge.jpg 1335w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span>
    <figcaption><p>A build DAG mediates the project and the deployment models, absorbing the impedance mismatch between what is human friendly and what is machine-friendly.</p></figcaption>
  </figure>
<p>Central to resolving this stiffness is the realisation that the build flow, at least conceptually, is a DAG – Directed Acyclic Graph – where the nodes are <em>jobs</em> and <em>versioned artifacts</em> and the edges connect either a job to a versioned artifact (“produces”) or a versioned artifact to a jobs (“dependency_of”). Deployables are by definition the versioned artifacts that are consumed by the deployment jobs.</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/50066/dag.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="A graph of two types of nodes, jobs and versioned artifacts, connected by edges 'dependency_of' and 'produces'. Versioned artifacts can be further specialised." title="A graph of two types of nodes, jobs and versioned artifacts, connected by edges 'dependency_of' and 'produces'. Versioned artifacts can be further specialised." src="https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/6a068/dag.jpg" srcset="https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/09b79/dag.jpg 240w,
https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/7cc5e/dag.jpg 480w,
https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/6a068/dag.jpg 960w,
https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/50066/dag.jpg 1384w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span>
    <figcaption><p>A graph of two types of nodes, jobs and versioned artifacts, connected by edges ‘dependency_of’ and ‘produces’. Versioned artifacts can be further specialised.</p></figcaption>
  </figure>
<p>For too long we overlooked how much a flexible and frictionless build DAG allows us to improve our architecture on both sides. With moderately rich build patterns we can have our code where its intent is clearer and more constraints can be validated at build time and still have it deployed into its simplest viable form, running where its execution is cheaper, faster and safer.</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/a18e1/wedding-altar.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Cheesy cisgender, neurotypical westernised image of a wedding altar with the build dag marrying developer effectiveness with mechanical sympathy." title="Sorry. I had to." src="https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/a18e1/wedding-altar.jpg" srcset="https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/09b79/wedding-altar.jpg 240w,
https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/7cc5e/wedding-altar.jpg 480w,
https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/a18e1/wedding-altar.jpg 612w" sizes="(max-width: 612px) 100vw, 612px" loading="lazy">
  </a>
    </span>
    <figcaption><p>Sorry. I had to.</p></figcaption>
  </figure><p>.</p>
<h3 id="why-so-stiff-bro"><a href="#why-so-stiff-bro" aria-label="why so stiff bro permalink"></a>Why so stiff, bro?</h3>
<p>I’m not sure what the historically accurate account is that would explain the excessive simplicity of build patterns across the industry. I do know from experience that too many practices make do with very simple and linear flows where one repository builds independently one and only one service. Regardless of the legitimate argument about code duplication and its tradeoffs, there seems to be an aversion to build-time internal dependencies, even when these bring in clearly desirable data or logic such as message format definitions.</p>
<p>I suspect it might have something to do with how very few CI tools support composition natively (i.e. the outputs of jobs being able to be the inputs of others), how fallible semantic versioning in practice is and the difficulty of automating deterministic version propagation.</p>
<p>By that I mean keeping local copies in sync with CI, builds repeatable, and new upstream versions automatically used by their downstream dependents. It isn’t trivial and requires some versioning and build-fu that, to my knowledge, most practices end up shortcutting to either sacrifice repeatability by using <code>latest</code> or stifling the flow by requiring repeated manual work. Hence the pressure to have a simple build setup.</p>
<p>The exact cause is unimportant though. What is important is that overcoming this is crucial.</p>

<p>Many criteria for splitting or joining software systems, ranging from the social (teams, bounded contexts) to the mechanical (cpu or io boundedness) have been put forth, and they all make some form of sense. However, most of them are either a good reason to split projects or modules, or a good reason to split deployables, rarely both. Keeping that in mind will help us apply them more effectively.</p>
<p>Below are a few possible criteria and some comments about their application. I’m not trying to be exhaustive, just illustrating the kind of reasoning makes sense to me.</p>
<h2 id="runtime-deployment-side-criteria"><a href="#runtime-deployment-side-criteria" aria-label="runtime deployment side criteria permalink"></a>Runtime, deployment side criteria</h2>
<ul>
<li><strong>Different Runtime</strong> – If a part of the codebase compiles to a different runtime it becomes a different deployable and we call it a different service.</li>
<li><strong>Elasticity Profile</strong> – Some parts of the system may have a spikier load profile. It might pay off to have them scale in and out separately from the rest.</li>
<li><strong>Load Type</strong> – Some parts of a generally latency-oriented io-bound system may generate occasional peaks of cpu-bound load which can hurt response times. It might be better to put them in a …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vlfig.me/posts/microservices">https://vlfig.me/posts/microservices</a></em></p>]]>
            </description>
            <link>https://vlfig.me/posts/microservices</link>
            <guid isPermaLink="false">hacker-news-small-sites-24963742</guid>
            <pubDate>Mon, 02 Nov 2020 00:16:23 GMT</pubDate>
        </item>
    </channel>
</rss>
