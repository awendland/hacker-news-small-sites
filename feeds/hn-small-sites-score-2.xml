<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 29 Dec 2020 20:40:07 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 29 Dec 2020 20:40:07 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[We successfully pivoted a SaaS business to open-source MLOps tooling]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25558076">thread link</a>) | @benkoller
<br/>
December 28, 2020 | https://blog.maiot.io/a-most-unusual-year/ | <a href="https://web.archive.org/web/*/https://blog.maiot.io/a-most-unusual-year/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="post-content">
    <div id="blogpost">
        <p>As this is the end of the year, itâ€™s a great chance to remind yourself: how did we get here?</p>

<p>Let me beginn with a flashback to 2019. As a company, weâ€™re focussed on optimising remaining useful live of industrial assets through clever use of Machine Learning for predictive analysis, root-cause analysis and other forms of reasoning. We managed to secure a few big projects and very promising POCs, and across the board we were able to show good results. One of our projects even got government funding, providing a nice runway going forward.</p>

<p>We got the traditionally lengthy sales cycles with many leading industry players started, and we even hired our first full-time employee.</p>

<p>All was set up for first commercial success of our approach and our â€œasset optimisation platformâ€� in 2020.</p>

<p>Then the pandemic hit. Within a few weeks, all our sales leads fizzled away - millions of euros in deal sizes, disappeared in thin air. By March, we were looking at an empty sales funnel.</p>

<p>We had find a new path. We took stock, and we acted entrepreneurial.</p>

<h2 id="a-look-at-what-weve-got">A look at what weâ€™ve got</h2>

<p>Taking stock of what we actually had, in terms of intellectual property, was a great recap of our journey so far <a href="https://www.youtube.com/watch?v=UDfxoKmc8qc">(if youâ€™re interested, check out a talk I recently gave on what we learned about ML pipelines)</a>. To summarise, we had to our name:</p>

<ul>
  <li>A great team (experienced ML engineers, Ops expertise and a good entrepreneurial fit)</li>
  <li>A purpose-built tech stack for reproducible ML pipelines</li>
  <li>Experience running small and large projects</li>
  <li>A good network of other startups and developers in ML-related positions across the globe</li>
</ul>

<h2 id="talking-to-people">Talking to people</h2>

<p>We saw the economic effects of the pandemic very early - at least from an european perspective. After taking close stock, we had to understand how (and if) Machine Learning would continue to play a role for our leads and network. Taking a page out of the great UX researchers Iâ€™ve had the chance to work with over my career, we decided to do user interviews. Lo and behold, after doing ~30 early interviews, a picture emerged.</p>

<p>Teams engaged in ML projects lost significant chunks of time on unrepeatable projects as well as managing dysfunctional franken-infrastructures. Teams not yet engaged in ML feared it to be a black hole for time and effort to build up a reliable tech stack for getting experiments into production, as existing systems would need integration at many stages of the ML lifecycle.</p>

<p>An interesting side-fact became clear to us, too: there was a lot of scepticism towards ML-based SaaS products, but a lot of trust towards dev-tooling.</p>

<p>More importantly, however - we had solved exactly the problems our interviewees faced for ourselves. We were sitting on something commercially relevant, and we were looking at a great opportunity.</p>

<h2 id="understanding-your-market-part-one">Understanding your market, part one</h2>

<p>With this new-found confirmation we set out to transform our tech-stack from internal-facing supportive tooling to an actual product. Looking at the market, a split was noticeable.</p>

<p>On the one side, open-source tooling like Kubeflow and MLFlow was solving aspects of the MLOps problem space, but posed significant investments to the teams we were talking to in our interviews. Tooling was either missing the point of Data Scientists, or alienated product leads and DevOps teams with convoluted, messy or badly documented paths from experiment to production.</p>

<p>On the other side were very expensive commercial solutions, attempting to solve large chunks of the ML lifecycle with proprietary offerings.</p>

<h2 id="commercial-first">Commercial-first</h2>

<p>Given the layout of the MLOps market, we spotted an opportunity to flip the proverbial table. Donâ€™t get me wrong, weâ€™re not radical geniuses, we much rather are interested observers of entrepreneurial trends. Given the success of Stripe, Segment and others, this constellation of players screamed â€œtransactional business modelâ€� to us. A managed MLOps platform to train models easily in various public clouds, at linearly scaling prices, based on actual usage, not arbitrary license models or per-seat, and at a fraction of the going rates.</p>

<h2 id="understanding-the-market-part-two">Understanding the market, part two</h2>

<p>By now we know: Our hypothesis, teams are just waiting for a managed MLOps solution with usage-based pricing and reproducible pipelines as focus, was off. This was not immediately clear to us, of course.</p>

<p>One of our smartest plays saved us in the end - we never stopped doing user interviews. We demoâ€™ed our product status quo multiple times per week, we had two soft-launches and continuously engaged with the community on conferences, reddit, slack - you name it.</p>

<p>And people loved our take on MLOps. Our vision resonated deeply. All model trainings are guaranteed to be reproducible, tracking is deeply baked-in, integrations to popular tooling are easy and extensible - these are the key concerns of the teams we were talking to.</p>

<p>However, it would have been ludicrous to switch their tech-stacks to a commercial solution. No, if we wanted to drive adoption and actually have an impact on how the world dealt with MLOps, we had to give these teams the option to adopt our vision in their projects on their own terms. We had to open-source.</p>

<p>As Iâ€™ve written in the past, <a href="http://blog.maiot.io/open-source">we are huge proponents of open-source software</a>. Large parts of our own tooling would be possible without the work of open-source giants, on whose shoulders we can stand.</p>

<h2 id="the-jury-is-still-out">The jury is still out</h2>

<p>As of writing this, the jury is still out if weâ€™re leaving the dent in the universe that we want to leave behind. But, and this is a hugely rewarding feeling, we have all the right indications that we nailed it this time. Weâ€™ve breached 200 GitHub stars in less than a week of going public, weâ€™ve been on the front page of Hackernews, weâ€™ve been trending on GitHub, and ZenML is racing to 1000 <code>pip install</code>â€™s.</p>

<p>If youâ€™re running ML projects, or just personally got curious, head over to <a href="https://github.com/maiot-io/zenml">ZenMLâ€™s GitHub page</a> and get started with reproducible Machine Learning!</p>

    </div>
</section></div>]]>
            </description>
            <link>https://blog.maiot.io/a-most-unusual-year/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25558076</guid>
            <pubDate>Mon, 28 Dec 2020 10:17:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Celestial Navigation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25557669">thread link</a>) | @blewboarwastake
<br/>
December 28, 2020 | http://www.siranah.de/html/sail040a.htm | <a href="https://web.archive.org/web/*/http://www.siranah.de/html/sail040a.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.siranah.de/html/sail040a.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557669</guid>
            <pubDate>Mon, 28 Dec 2020 08:33:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine learning is going real-time]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25557412">thread link</a>) | @yoquan
<br/>
December 27, 2020 | https://huyenchip.com/2020/12/27/real-time-machine-learning.html | <a href="https://web.archive.org/web/*/https://huyenchip.com/2020/12/27/real-time-machine-learning.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>After talking to machine learning and infrastructure engineers at major Internet companies across the US, Europe, and China, I noticed two groups of companies. One group has made significant investments (hundreds of millions of dollars) into infrastructure to allow real-time machine learning and has already seen returns on their investments. Another group still wonders if there’s value in real-time ML.</p>

<p>There seems to be little consensus on what real-time ML means, and there hasn’t been a lot of in-depth discussion on how it’s done in the industry. In this post, I want to share what I’ve learned after talking to about a dozen companies that are doing it.</p>

<p>There are two levels of real-time machine learning that I’ll go over in this post.</p>
<ul>
  <li>Level 1: Your ML system makes predictions in real-time (online predictions).</li>
  <li>Level 2: Your system can incorporate new data and update your model in real-time (online learning).</li>
</ul>

<p>I use “model” to refer to the machine learning model and “system” to refer to the infrastructure around it, including data pipeline and monitoring systems.</p>

<hr>
<p><b>Table of contents</b><br>
…. <a href="#online_predictions">Level 1: Online predictions - your system can make predictions in real-time</a><br>
…….. <a href="#online_predictions_use_cases">Use cases</a><br>
………… <a href="#problems_batch_predictions">Problems with batch predictions</a><br>
…….. <a href="#online_predictions_solutions">Solutions</a><br>
………… <a href="#fast_inference">Fast inference</a><br>
………… <a href="#stream_pipeline">Real-time pipeline</a><br>
……………. <a href="#stream_processing_vs_batch_processing">Stream processing vs. batch processing</a><br>
……………. <a href="#event_driven_vs_request_driven">Event-driven vs. request-driven</a><br>
…….. <a href="#online_predictions_challenges">Challenges</a><br>
…. <a href="#online_learning">Level 2: Online learning - your system can incorporate new data and update in real-time</a><br>
…….. <a href="#online_learning_definition">Defining “online learning”</a><br>
…….. <a href="#online_learning_use_cases">Use case</a><br>
…….. <a href="#online_learning_solutions">Solutions</a><br>
…….. <a href="#online_learning_challenges">Challenges</a><br>
………… <a href="#online_learning_theoretical_challenges">Theoretical</a><br>
………… <a href="#online_learning_practical_challenges">Practical</a><br>
…. <a href="#mlops_china_vs_us">The MLOps race between the US and China</a><br>
…. <a href="#conclusion">Conclusion</a><br></p>

<hr>

<h2 id="online_predictions">Level 1: Online predictions - your system can make predictions in real-time</h2>
<p><em><b>Real-time</b> here is defined to be in the order of milliseconds to seconds.</em></p>

<h3 id="online_predictions_use_cases">Use cases</h3>
<p>Latency matters, especially for user-facing applications. In 2009, Google’s experiments demonstrated that <a href="https://services.google.com/fh/files/blogs/google_delayexp.pdf">increasing web search latency 100 to 400 ms reduces the daily number of searches per user by 0.2% to 0.6%</a>. In 2019, <a href="https://blog.acolyer.org/2019/10/07/150-successful-machine-learning-models/">Booking.com found that an increase of 30% in latency cost about 0.5% in conversion rates — “a relevant cost for our business.”</a></p>

<p>No matter how great your ML models are, if they take just milliseconds too long to make predictions, users are going to click on something else.</p>

<h4 id="problems_batch_predictions">Problems with batch predictions</h4>
<p>One non-solution is to avoid making predictions online. You can generate predictions in batch offline, store them (e.g. in SQL tables), and pull out pre-computed predictions when needed.</p>

<p>This can work when the input space is finite – you know exactly how many possible inputs to make predictions for. One example is when you need to generate movie recommendations for your users – you know exactly how many users there are. So you predict a set of recommendations for each user periodically, such as every few hours.</p>

<p>To make their user input space finite, many apps make their users choose from categories instead of entering wild queries. For example, if you go to TripAdvisor, you first have to pick a predefined metropolis area instead of being able to enter just any location.</p>

<p>This approach has many limitations. TripAdvisor results are okay within their predefined categories, such as <b>“Restaurants”</b> in <b>“San Francisco”</b>, but are pretty bad when you try to enter wild queries like <b>“high rating Thai restaurants in Hayes Valley”</b>.</p>

<center>
<figure>
<img alt="MLOps over time" src="https://huyenchip.com/assets/pics/real-time-ml/1_tripadvisor.png">
</figure>
</center>

<p>Limitations caused by batch predictions exist even in more technologically progressive companies like Netflix. Say, you’ve been watching a lot of horrors lately, so when you first log into Netflix, horror movies dominate recommendations. But you’re feeling bright today so you search “comedy” and start browsing the comedy category. Netflix should learn and show you more comedy in your list of their recommendations, right? But it can’t update the list until the next time batch recommendations are generated.</p>

<p>In the two examples above, batch predictions lead to decreases in user experience (which is tightly coupled with user engagement/retention), not catastrophic failures. Other examples are ad ranking, Twitter’s trending hashtag ranking, Facebook’s newsfeed ranking, estimating time of arrival, etc.</p>

<p>There are also many applications that, without online predictions, would lead to catastrophic failures or just wouldn’t work. Examples include high frequency trading, autonomous vehicles, voice assistants, unlocking your phones using face/fingerprints, fall detection for elderly care, fraud detection, etc. Being able to detect a fraudulent transaction that happened 3 hours ago is still better than not detecting it at all, but being able to detect it in real-time can prevent it from going through.</p>

<p>Switching from batch predictions to real-time predictions allows you to use dynamic features to make more relevant predictions. Static features are information that changes slowly or rarely – age, gender, job, neighborhood, etc. Dynamic features are features based on what’s happening right now – what you’re watching, what you’ve just liked, etc. Knowing a user’s interests right now will allow your systems to make recommendations much more relevant to them.</p>

<center>
<figure>
<img alt="MLOps over time" src="https://huyenchip.com/assets/pics/real-time-ml/2_google.png">
</figure>
</center>

<h3 id="online_predictions_solutions">Solutions</h3>
<p>For your system to be able to make online predictions, it has to have two components:</p>

<ol>
  <li>Fast inference: model that can make predictions in the order of milliseconds</li>
  <li>Real-time pipeline: a pipeline that can process data, input it into model, and return a prediction in real-time</li>
</ol>

<h4 id="fast_inference">Fast inference</h4>
<p>When a model is too big and taking too long to make predictions, there are three approaches:</p>

<p><b>1. Make models faster (inference optimization)</b></p>

<p>E.g. fusing operations, distributing computations, memory footprint optimization, writing high performance kernels targeting specific hardwares, etc.</p>

<p><b>2. Make models smaller (model compression)</b></p>

<p>Originally, this family of technique is to make models smaller to make them fit on edge devices. Making models smaller often makes them run faster. The most common, general technique for model compression is quantization, e.g. using 16-bit floats (half precision) or 8-bit integers (fixed-point) instead of 32-bit floats (full precision) to represent your model weights. In the extreme case, some have attempted 1-bit representation (binary weight neural networks), e.g. <a href="https://arxiv.org/abs/1511.00363">BinaryConnect</a> and <a href="https://arxiv.org/abs/1603.05279">Xnor-Net</a>. The authors of Xnor-Net spun off Xnor.ai, a startup focused on model compression which was <a href="https://www.geekwire.com/2020/exclusive-apple-acquires-xnor-ai-edge-ai-spin-paul-allens-ai2-price-200m-range/">acquired by Apple for a reported $200M</a>.</p>

<p>Another popular technique is <a href="https://arxiv.org/abs/1503.02531">knowledge distillation</a> – a small model (student) is trained to mimic a larger model or an ensemble of models (teacher). Even though the student is often trained with a pre-trained teacher, both may also be trained at the same time. One example of a distilled network used in production is <a href="https://arxiv.org/abs/1910.01108"><strong>DistilBERT</strong></a>, which reduces the size of a BERT model by 40%, while retaining 97% of its language understanding capabilities and being 60% faster.</p>

<p>Other techniques include pruning (finding parameters least useful to predictions and setting them to 0) and low-rank factorization (replacing the over-parametric convolution filters with compact blocks to both reduce the number of parameters and increase speed). See <strong><a href="https://arxiv.org/abs/1710.09282">A Survey of Model Compression and Acceleration for Deep Neural Networks</a></strong> (Cheng et al.. 2017) for a detailed analysis.</p>

<p>The number of research papers on model compression is growing. Off-the-shelf utilities are proliferating. Awesome Open Source has a list of <a href="https://awesomeopensource.com/projects/model-compression"><strong>The Top 40 Model Compression Open Source Projects</strong></a>.</p>

<p><b>3. Make hardware faster</b></p>

<p>This is another research area that is booming. Big companies and startups alike are in a race to develop hardware that allows large ML models to do inference, even training, faster both on the cloud and especially on devices. IDC forecasts that by 2020, the combination of edge and mobile devices doing inferencing will <a href="https://www.arm.com/-/media/global/solutions/artificial-intelligence/ai-ml-on-cpu-whitepaper.pdf?revision=17a2b30b-0f5a-4a42-8681-3d9f3f94e513">total 3.7 billion units, with a further 116 million units doing training</a>.</p>

<h4 id="stream_pipeline">Real-time pipeline</h4>
<p>Suppose you have a ride sharing app and want to detect fraudulent transactions e.g. payments using stolen credit cards. When the true credit owner discovers unauthorized payments, they’ll dispute with their bank and you’ll have to refund the charges. To maximize profits, fraudsters might call multiple rides either in succession or from multiple accounts. In 2019, merchants estimate fraudulent transactions account for an average of <a href="https://network.americanexpress.com/globalnetwork/dam/jcr:09c34553-b4a2-43ca-bf3e-47cbc911ea51/American%20Express%202019%20Digital%20Payments%20Survey_Insights%20Paper.pdf">27% of their annual online sales</a>. The longer it takes for you to detect the stolen credit card, the more money you’ll lose.</p>

<p>To detect whether a transaction is fraudulent, looking at that transaction alone isn’t enough. You need to at least look into the recent history of the user involved in that transaction, their recent trips and activities in-app, the credit card’s recent transactions, and other transactions happening around the same time.</p>

<p>To quickly access these types of information, you want to keep as much of them in-memory as possible. Every time an event you care about happens – a user choosing a location, booking a trip, contacting a driver, canceling a trip, adding a credit card, removing a credit card, etc. – information about that event goes into your in-memory storage. It stays there for as long as they are useful (usually in order of days) then either goes into permanent storage (e.g. S3) or is discarded. The most common tool for this is <a href="https://github.com/apache/kafka">Apache Kafka</a>, with alternatives such as Amazon Kinesis. Kafka is a stream storage: it stores data as it streams.</p>

<p>Streaming data is different from static data – data that already exists somewhere in its entirety, such as CSV files. When reading from CSV files, you know when the job is finished. Streams of data never finish.</p>

<p>Once you’ve had a way to manage streaming data, you want to extract features to input into your ML models. On top of features from streaming data, you might also need features from static data (when was this account created, what’s the user’s rating, etc.). You need a tool that allows you to process streaming data as well as static data and join …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://huyenchip.com/2020/12/27/real-time-machine-learning.html">https://huyenchip.com/2020/12/27/real-time-machine-learning.html</a></em></p>]]>
            </description>
            <link>https://huyenchip.com/2020/12/27/real-time-machine-learning.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557412</guid>
            <pubDate>Mon, 28 Dec 2020 07:21:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No, Vertical Farms Won’t Feed the World]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25557407">thread link</a>) | @hannob
<br/>
December 27, 2020 | https://globalecoguy.org/no-vertical-farms-wont-feed-the-world-5313e3e961c0 | <a href="https://web.archive.org/web/*/https://globalecoguy.org/no-vertical-farms-wont-feed-the-world-5313e3e961c0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><figure><div role="button" tabindex="0"><div><p><img alt="Image for post" src="https://miro.medium.com/max/8574/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg" width="4287" height="1673" srcset="https://miro.medium.com/max/552/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 276w, https://miro.medium.com/max/1104/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 552w, https://miro.medium.com/max/1280/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 640w, https://miro.medium.com/max/1456/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 728w, https://miro.medium.com/max/1632/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 816w, https://miro.medium.com/max/1808/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 904w, https://miro.medium.com/max/1984/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 992w, https://miro.medium.com/max/2160/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 1080w, https://miro.medium.com/max/2700/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 1350w, https://miro.medium.com/max/3240/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 1620w, https://miro.medium.com/max/3780/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 1890w, https://miro.medium.com/max/4320/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 2160w, https://miro.medium.com/max/4800/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 2400w" sizes="100vw" data-old-src="https://miro.medium.com/max/60/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg?q=20"></p></div></div><figcaption>Lettuce grown in my garden. Photograph © 2016 Jonathan Foley.</figcaption></figure></div><div><div><h2 id="f47c">While they are well-intentioned, new indoor “farms” won’t help feed the world or reduce the environmental impacts of agriculture. We would be better to focus our efforts elsewhere.</h2><div><div><div><div><a href="https://globalecoguy.medium.com/?source=post_page-----5313e3e961c0--------------------------------" rel="noopener"><div><p><img alt="Jonathan Foley" src="https://miro.medium.com/fit/c/96/96/1*9wBAcVM1jqF9OWCjCOGiuA.jpeg" width="48" height="48"></p></div></a></div></div></div></div></div></div></section><section><div><div><p id="bd54"><span>W</span>e’re beginning to see a new fad in agriculture — so-called “vertical farms” that grow food <em>indoors </em>with energy-intensive, artificial life support systems.</p><p id="498f">In the last few years, a number of tech companies have designed “farms” that utilize artificial lights, heaters, water pumps, and computer controls to grow crops inside. These systems glow with a fantastic magenta light — from LEDs that are specially tuned to provide optimal light for photosynthesis — often with stacked trays of plants, one on top of the other. Some of this technology is new, especially the LEDs, although pot growers have used tools like this for years.</p><p id="db29">Some of the more notable efforts to build indoor “farms” include <a href="http://www.freightfarms.com/" rel="noopener">Freight Farms</a> in Boston. And there is a group at MIT that is trying to create new high-tech platforms for growing food inside, including “<a href="http://openag.media.mit.edu/hardware/" rel="noopener">food computers</a>”. These folks are very smart, and have done a lot to perfect the technology.</p><p id="47bb">At first blush, these “farms” sound great. Why not <em>completely</em> eliminate food miles, and grow food right next to restaurants, cafeterias, or supermarkets? And why not grow crops inside closed systems, where water can be recycled, and pests can (in theory) be managed without chemicals.</p><p id="d5c4">It sounds great, doesn’t it? But there are many challenges.</p></div></div></section><section><div><div><p id="6ba8"><span>F</span><strong>irst, Vertical Farms Cost a Fortune</strong></p><p id="5f2b">But there are costs to these farms. <em>Huge</em> costs.</p><p id="f0bc">First, these systems are <em>really</em> expensive to build. The shipping container systems developed by <a href="http://www.freightfarms.com/faq/" rel="noopener">Freight Farms</a>, for example, cost between $82,000 and $85,000 <em>per container</em> — an astonishing sum for a box that just grows greens and herbs. Just one container costs as much as 10 entire acres of prime American farmland — which is a far better investment, both in terms of food production and future economic value. Just remember: farmland has the benefit of generally <em>appreciating</em> in <a href="http://www.forbes.com/sites/joshuarogers/2014/09/23/dirt-cheap-investors-are-plowing-into-farmland-heres-why" rel="noopener">value over time</a>, whereas a big metal box is likely to only decrease in value.</p><p id="24cf">Second, food produced this way is <em>very</em> expensive. For example, the Wall Street Journal <a href="http://www.wsj.com/articles/are-shipping-containers-the-future-of-farming-1465393797" rel="noopener">reports</a> that mini-lettuces grown by Green Line Growers costs more than <em>twice</em> as much as organic lettuce available in most stores. And this is typical for other indoor growers around the country: it’s very, very expensive, even compared to organic food. Instead of making food <em>more</em>available, especially to poorer families on limited budgets, these indoor crops are only available to the affluent. It might be fine for gourmet lettuce, or fancy greens for expensive restaurants, but regular folks may find it out of reach.</p><p id="e121">Finally, indoor farms use <em>a lot</em> of energy and materials to operate. The container farms from Freight Farms, for example, use about <a href="http://www.freightfarms.com/faq/" rel="noopener">80 kilowatt-hours of electricity a day</a> to power the lights and pumps. That’s nearly 2–3 times as much electricity as a typical (and still very inefficient) American home, or about 8 times the electricity used by an average San Francisco apartment. And on the average American electrical grid, this translates to emitting <em>44,000 pounds of CO2 per container per year</em>, from electricity alone, not counting any additional heating costs. This is <em>vastly</em> more than the emissions it would take to ship the food from someplace else.</p><p id="0e49">And none of it is necessary.</p></div></div></section><section><div><div><p id="1017"><span>B</span><strong>ut, Wait, Can’t Indoor Farms Use Renewable Energy?</strong></p><p id="5bbd">Proponents of indoor techno-farms often say that they can offset the enormous sums of electricity they use, by powering them with renewable energy — especially solar panels — to make the whole thing carbon neutral.</p><p id="5b5d">But just stop and think about this for a second.</p><p id="5f6a">These indoor “farms” would use solar panels to harvest naturally occurring sunlight, and convert it into electricity, so that they can power…<em>artificial sunlight</em>? In other words<em>, </em>they’re<em> trying to use the sun to replace the sun.</em></p><p id="0a0f">But we don’t need to replace the sun. Of all of the things we should worry about in agriculture, the availability of free sunlight is not one of them. Any system that seeks to replace the sun to grow food is probably a bad idea.</p></div></div></section><section><div><div><p id="e3d3"><span>B</span><strong>esides, “Food Miles” Aren’t a Big Climate Problem</strong></p><p id="29a5">Sometimes we hear that vertical farms help the environment by reducing “food miles” — the distance food items travel from farm to table — and thereby reduce fuel consumption and greenhouse gas emissions.</p><p id="0f7a">This sounds logical, but it turns out to be a red herring.</p><p id="c2ec">Strange as it might seem, local food typically uses about the same amount of energy — per pound — to transport as food grown far away. Why? Short answer: volume and method of transport. A larger food operator can ship food more efficiently — even if it travels longer distances — because of the gigantic volumes they work in. Plus, ships, trains, and even large trucks driving on Interstate highways use less fuel, per pound per mile, than small trucks driving around town.</p><p id="a654">Plus it turns out that “food miles” aren’t a very big source of CO2 emissions anyway, whether they’re local or not. In fact, they pale in comparison to emissions from deforestation, methane from cattle and rice fields, and nitrous oxide from over-fertilized fields. And local food systems — especially organic farms that use fewer fertilizers, and grass fed beef that sequesters carbon in the soil — can reduce these more critical emissions. At the end of the day, local food systems are generally better for the environment, including greenhouse gas emissions. Just don’t worry about emissions from food miles too much.</p></div></div></section><section><div><div><p id="6153"><span>A</span><strong>nd These Vertical “Farms” Can’t Grow Much</strong></p><p id="1ac1">A further problem with indoor farms is that a lot of crops could never develop properly in these artificial conditions. While LED lights provide the light needed for <em>photosynthesis</em> to occur, they don’t provide the proper mix of light and heat to trigger plant development stages — like those that tell plants when to put on fruit or seed. Moreover, a lot of crops need a bit of wind to develop tall, strong stalks, needed later when they are carrying heavy loads before harvest. As a result, indoor farms are severely limited, and have a hard time growing things besides simple greens.</p><p id="71b1">Indoor farms might be able to provide some <em>garnish</em> and <em>salads</em> to the world, but forget about them as a means of growing much other <em>food</em>.</p></div></div></section><section><div><div><p id="003c"><strong>A Better Way?</strong></p><p id="bf8f">I’m not the only critic of indoor, high-tech, energy-intensive agriculture. Other authors are starting to point out the problems with these systems too (read very good critiques <a href="http://www.salon.com/2016/02/17/enough_with_the_vertical_farming_partner/" rel="noopener">here</a>, <a href="http://www.counterpunch.org/2012/12/11/the-vertical-farming-scam/" rel="noopener">here</a>, <a href="https://www.theguardian.com/sustainable-business/2015/apr/10/indoor-farming-makes-no-economic-environmental-sense" rel="noopener">here</a>, and <a href="http://news.cornell.edu/stories/2014/02/indoor-urban-farms-called-wasteful-pie-sky" rel="noopener">here</a>).</p><p id="02f4">While I appreciate the enthusiasm and innovation put into developing indoor farms, I think these efforts are, at the end of the day, counterproductive.</p><p id="8dea">Instead, I think we should use the same investment of dollars, incredible technology, and amazing brains to solve other agricultural problems — like developing new methods for drip irrigation, better grazing systems that lock up soil carbon, and ways of recycling on-farm nutrients. Organic farming and high-precision agriculture are doing promising things, and need more help. We also need innovation and capital to help other parts of the food system, especially in tackling food waste, and getting people to shift their diets towards more sustainable directions.</p><p id="9534">An interconnected network of good farms —real farms that provide nutritious food, with social and environmental benefits to their communities — is the kind of innovation we really need.</p></div></div></section><section><div><p id="b135">NOTE: parts of this piece were adapted from an earlier blog article of mine called <em>“Local Food is Great, But Can It Go Too Far?”</em></p></div></section><section><div><div><p id="68aa"><em>Dr. </em><a href="http://globalecoguy.org/" rel="noopener"><em>Jonathan Foley</em></a><em> (@</em><a href="http://twitter.com/@globalecoguy" rel="noopener"><em>GlobalEcoGuy</em></a><em>) is a climate &amp; environmental scientist, writer, and speaker. He is also the Executive Director of </em><a href="http://drawdown.org/" rel="noopener"><em>Project Drawdown</em></a><em>, the world’s leading resource for climate solutions.</em></p><p id="10de"><em>These views are his own.</em></p><p id="db28">Copyright © 2015–2020, Jonathan Foley. All rights reserved.</p></div></div></section></div></div>]]>
            </description>
            <link>https://globalecoguy.org/no-vertical-farms-wont-feed-the-world-5313e3e961c0</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557407</guid>
            <pubDate>Mon, 28 Dec 2020 07:20:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We’re Rebranding PrestoSQL as Trino]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25557321">thread link</a>) | @addisonj
<br/>
December 27, 2020 | https://trino.io/blog/2020/12/27/announcing-trino.html | <a href="https://web.archive.org/web/*/https://trino.io/blog/2020/12/27/announcing-trino.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>We’re rebranding PrestoSQL as Trino. The software and the community you have come to love and depend on aren’t 
going anywhere, we are simply renaming. <strong>Trino is the new name for PrestoSQL</strong>, the project supported by the founders 
and creators of Presto® along with the major contributors – just under a shiny new name. And now you can find us here:</p>

<ul>
  <li>GitHub: <a href="https://github.com/trinodb/trino">https://github.com/trinodb/trino</a>. Please give it a star!</li>
  <li>Twitter: <a href="https://twitter.com/trinodb">@trinodb</a></li>
  <li>Slack: <a href="https://trino.io/slack.html">https://trino.io/slack.html</a></li>
</ul>

<p>If you want to learn why we’re doing this, read on…</p>

<!--more-->

<p>In 2012, Dain, David and Martin joined the Facebook data infrastructure team. Together with Eric Hwang, we created 
Presto® to address the problems of low latency interactive analytics over Facebook’s massive Hadoop data warehouse. 
One of our non-negotiable conditions was for Presto® to be an open source project. Open source is in our DNA - we had 
all used and participated in open source projects to various degrees in the past, and we recognized the power of open 
communities and developers coming together to build successful software that can stand the test of time.</p>

<p><img src="https://trino.io/assets/blog/trino-announcement/team.jpg" alt=""></p>

<p>Over the next six years, we worked hard to build a healthy open source community and ecosystem around the project. We 
worked with developers and users all over the world and welcomed them into the Presto® community. Presto® was on a path 
of increasing growth and success, in large part because of the contributions from developers across many fields and all 
over the world.</p>

<p>Unfortunately in 2018, it became clear that Facebook management wanted to have tighter control over the project and its 
future. This culminated with their decision to grant Facebook developers commit rights on the project without any prior 
experience in Presto®. We strongly believe that this kind of decision is not compatible with having a healthy, open 
community. Moreover, they made this decision by fiat without engaging the Presto® community. As a matter of principle, 
we had no choice but to leave Facebook in order to focus on making sure Presto® continued to be a successful project 
with an open, collaborative and independent community. In reality, the choice was easy.</p>

<p>We started the Presto Software Foundation in January 2019 as an independent entity to oversee the development of the 
software and community, continuing the meritocratic system that had been in place over the previous 6 years. The community 
quickly consolidated under this new home. We intentionally stayed unemployed over the next 10 months to focus on expanding 
and strengthening the community by working directly with major users and contributors, as well as reaching out to a wider 
group of users and developers across the globe. This resulted in new use cases and an injection of energy, making the 
project more vibrant than ever before as even more new users and developers became engaged. But, don’t take our word for 
it, let the data speak for itself:</p>

<p><img src="https://trino.io/assets/blog/trino-announcement/commits.png" alt=""></p>

<p>Months after this consolidation, Facebook decided to create a competing community using The Linux Foundation®. As a first 
action, Facebook applied for a trademark on Presto®. This was a surprising, norm-breaking move because up until that point, 
the Presto® name had been used without constraints by commercial and non-commercial products for over 6 years. In September 
of 2019, Facebook established the Presto Foundation at The Linux Foundation®, and immediately began working to enforce this 
new trademark. We spent the better part of the last year trying to agree to terms with Facebook and The Linux Foundation 
that would not negatively impact the community, but unfortunately we were unable to do so. The end result is that we must 
now change the name in a short period of time, with little ability to minimize user disruption.</p>

<p>On a personal note, and as the founders who named the project Presto® in the first place, this is an incredibly sad and 
disappointing turn of events. And while we will always have fondness for the name Presto®, we have come to accept that a 
name is just a name. To be frank, we’re tired of this endless distraction, and we intend to focus on what matters most 
and what we are best at doing – building high quality software everyone can rely on and fostering a healthy community 
of users and developers that build it and support it. We’re not going anywhere – we’re the same people, the same amazing 
software, under a new name: Trino.</p>

<p><strong>If you love this project, you already love Trino. ❤️</strong></p>


<p>Facebook is a registered trademark of Facebook Inc.  The Linux Foundation and Presto are trademarks of The Linux Foundation.</p>


  </div>

  
</article>

</div></div>]]>
            </description>
            <link>https://trino.io/blog/2020/12/27/announcing-trino.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557321</guid>
            <pubDate>Mon, 28 Dec 2020 06:55:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What the cyberoptimists got wrong – and what to do about it]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25557229">thread link</a>) | @pdkl95
<br/>
December 27, 2020 | https://media.ccc.de/v/rc3-11337-what_the_cyberoptimists_got_wrong_-_and_what_to_do_about_it | <a href="https://web.archive.org/web/*/https://media.ccc.de/v/rc3-11337-what_the_cyberoptimists_got_wrong_-_and_what_to_do_about_it">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<div>

<p>
<span></span>
<a href="https://media.ccc.de/search?p=doctorow">doctorow</a>

</p>


<!-- %h3 About -->
<p>They stole our future. Let's take it back.</p>

<p>Here at the end of the world, it's time to take stock. Is technology a force for good? Can it be? Was it ever? How did we end up with a world made up of "five websites, each filled with screenshots of text from the other four" (h/t Tom Eastman)? Should we worry that machine learning will take away our free will through A/B splitting and Big Five Personality Types? Where the fuck did all these Nazis come from? </p>

<h3>Download</h3>
<div>
<p>

Downloads will appear here, once final recordings are released.
</p></div>
<!-- %h3 Embed/Share -->

<h3>Tags</h3>

</div>





</div>]]>
            </description>
            <link>https://media.ccc.de/v/rc3-11337-what_the_cyberoptimists_got_wrong_-_and_what_to_do_about_it</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557229</guid>
            <pubDate>Mon, 28 Dec 2020 06:33:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HN Readers]]>
            </title>
            <description>
<![CDATA[
Score 105 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25556990">thread link</a>) | @lgats
<br/>
December 27, 2020 | https://blog.luke.lol/tech/15-hacker-news-alternatives/ | <a href="https://web.archive.org/web/*/https://blog.luke.lol/tech/15-hacker-news-alternatives/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
<h2>News.YCombinator.com Readers</h2>
<p>Ranked by Alexa popularity.</p>
<p><a href="https://hn.algolia.com/">hn.algolia.com</a><br>
HackerNews with a search function and 16.8+ million posts indexed.<br>
Alexa: 8.7k</p>
<p><a href="http://popurls.com/">popurls.com</a><br>
Several news sites combined into a single newspaper-like feed<br>
Alexa: 87k</p>
<p><a href="https://upstract.com/">upstract.com</a><br>
News aggregator with paid features, includes HN<br>
Alexa: 137k</p>
<p><a href="https://hckrnews.com/">hckrnews.com</a><br>
HN posts organized by rolling, quarter-daily timeslots.<br>
Alexa: 178k</p>
<p><a href="https://pxlet.com/">pxlet.com</a><br>
Culmination of HN, Reddit, SlashDot, and other Tech-News Sites<br>
Alexa: 330k</p>
<p><a href="https://hackernewsletter.com/">hackernewsletter.com</a><br>
HN delivered via email<br>
Alexa: 581k</p>
<p><a href="https://old.thenews.im/">thenews.im&nbsp;</a><br>
Designer News, Product Hunt and Hacker News Mashup with easy-access to individual feeds<br>
Alexa: 960k</p>
<p><a href="http://www.daemonology.net/hn-daily/">daemonology.net</a><br>
Daily list of the top HN posts.<br>
Alexa: 971k</p>
<p><a href="http://n-gate.com/%3En-gate.com%3C/a%3E%3Cbr%20/%3EA%20weekly%20[human?]%20annotated%20digest%20of%20the%20top%20%E2%80%9CHacker%E2%80%9D%20%E2%80%9CNews%E2%80%9D%20posts%3Cbr%20/%3EAlexa:%202.5m%3C/p%3E%3Cp%3E%3Ca%20href=" https:="" hn.premii.com"="">hn.premii.com</a><br>
HN Mirror integrated with an on-page reader<br>
Alexa: 3m</p>
<p><a href="http://hnrankings.info/">hnrankings.info</a><br>
HN Ranking Charts<br>
Alexa: 4m</p>
<p><a href="https://hnews.xyz/">hnews.xyz</a><br>
HN Mirror with Webpage Screenshots [similar to tiledhn.com (<a href="https://web.archive.org/web/20200120125632/http://www.tiledhn.com/">RIP</a>)]<br>
Alexa: 5m</p>
<p><a href="https://hnsince.com/">hnsince.com</a><br>
Top HN posts since you last visited<br>
Alexa: 5.4m</p>
<p><a href="https://hackerweb.app/">hackerweb.app</a><br>
More mobile-friendly HN<br>
Alexa: 6.3m</p>
<p><a href="https://fullhn.com/">fullhn.com</a><br>
Front page of HN in a single page loaded with all articles. Great for loading up before you jump on a flight without wireless access.<br>
Alexa: 7m</p>
<p><a href="https://hackurls.com/">hackurls.com</a><br>
HN, proggit, reddit, toptal, hackaday, slashdot, techmeme, wired as separate feeds on a single page<br>
Alexa: 8.5m</p>
<p><a href="https://hackernewsmobile.com/">hackernewsmobile.com</a><br>
More mobile-friendly HN<br>
Alexa: 9.5m</p>
<p><a href="https://lopespm.github.io/hackernews-daily/">lopespm HN Daily</a><br>
HackerNews Daily – Culmination of top posts for the day<br>
Alexa: Unavailable</p>
<p><a href="https://www.wolfgangfaust.com/project/paper-hn/">wolfgangfaust HN Newspaper</a><br>
Newspaper themed HN<br>
Alexa: Unavailable</p>
<p><a href="https://thn.rakhim.org/">thn.rakhim.org</a><br>
30 random good HN posts from the past<br>
Alexa: Unavailable</p>
<p><a href="https://zvoid.org/hn">zvoid.org/hn</a><br>
Dark-themed HN reader<br>
Alexa: Unavailable</p>
<p><a href="https://hn.svelte.dev/">hn.svelte.dev</a><br>
mobile and dark mode friendly reader for HN<br>
Alexa: None</p>
<p><a href="https://hackernews.betacat.io/">hackernews.betacat.io</a><br>
Modern HN theme with website preview screenshots<br>
Alexa: None</p>
<p><a href="https://read.hn/">read.hn</a><br>
Another HN Reader view<br>
Alexa: None</p>
<p><a href="https://hnapp.com/">hnapp.com</a><br>
HN Advanced Search and monitoring tool<br>
Alexa: None</p>
<p><a href="http://hnpaper.forge.partlab.io/">hnpaper.forge.partlab.io</a><br>
HNPaper – bootstrap theme simple HN interface<br>
Alexa: Unavailable</p>
<p><a href="https://hack.ernews.info/">hack.ernews.info</a><br>
More mobile-friendly HN<br>
Alexa: None</p>
<p><a href="https://progscrape.com/">progscrape.com</a><br>
HN, Reddit, and Lobste.rs aggregated and merged into a single feed<br>
Alexa: None</p>
<p><a href="http://hn.elijames.org/">hn.elijames.org</a><br>
“Less annoying hacker news” with an even simpler interface<br>
Alexa: None</p>
<p><a href="http://serializer.io/">seralizer.io</a><br>
HN + Related Subreddits + Lobsters + Mac Rumors + Arstechnica<br>
Alexa: None</p>
<p><a href="https://nerdmash.com/">nerdmash.com</a><br>
A nerd’s daily read. Top posts from every nerdy content aggregator.<br>
Alexa: None</p>
<h2>Other Tweaks / Interfaces</h2>
<p><a href="https://old.reddit.com/r/hackernews/">/r/hackernews</a><br>
Subreddit for HN<br>
51,450 readers</p>
<p><a href="https://hnreplies.com/">hnreplies.com</a><br>
Emails on replies to your comments<br>
Alexa: 3.2m</p>
<p><a href="https://apps.apple.com/us/app/id1308885491">Octal iOS App</a><br>
Full-featured HN client with support for posting/voting/comments – iOS only.<br>
4.8/5.0 – 1K Ratings</p>
<p><a href="https://hnrss.github.io/">hnrss.github.io</a><br>
HN RSS Feed<br>
Alexa: None</p>
<p><a href="https://hackerne.ws/">hackerne.ws</a><br>
HN Short Link – redirects to https://news.ycombinator.com<br>
Alexa: None</p>
<p><a href="https://chrome.google.com/webstore/detail/hacker-news-ux/chngbdmhgakoomomnnhfapkpbalpmhid">Hacker News UX</a><br>
Chrome Extension for Improved UI<br>
356 users</p>
<p><a href="https://f5bot.com/">f5bot.com</a><br>
Reddit / HN / Lobsters keyword mention watch tool.<br>
Alexa: 1.1m</p>

<h2>Graveyard</h2>
<p>hackermonthly.com [<a href="https://web.archive.org/web/20160731192600/http://hackermonthly.com/">defunct</a>]<br>
HN in print</p>
<p>quiethn.com [<a href="https://web.archive.org/web/20171001013212/https://quiethn.com/">defunct</a>]<br>
HN with less clutter </p>
<p>hackerblogs.com [<a href="https://web.archive.org/web/20110204021331/http://www.hackerblogs.com/">defunct</a>]<br>
2011-era mobile view</p>
<p>hackernews.im [defunct]<br>
now <a href="https://hackernews.betacat.io/">hackernews.betacat.io</a></p>
<p>tiledhn.com [<a href="https://web.archive.org/web/20200120125632/http://www.tiledhn.com/">defunct</a>]<br>
Windows 8-type view for HN</p>
<p>hackerbra.in [<a href="https://web.archive.org/web/20181105131330/http://hackerbra.in/">defunct</a>]<br>
HN with inline top comments </p>
<p>hnwatcher.com [<a href="https://web.archive.org/web/20201125052525/https://www.hnwatcher.com/">defunct</a>]<br>
user/keyword email notification service</p>
<p>hnmobile.herokuapp.com [<a href="https://web.archive.org/web/20180601000346/http://hnmobile.herokuapp.com/">defunct</a>]<br>
HN mobile friendly mirror</p>
<p>hackernewsemail.com [<a href="https://web.archive.org/web/20180826215821/https://hackernewsemail.com/">defunct</a>]<br>
Daily email for posts with minimum set number of points</p>
<p>hacker-newspaper.gilesb.com [<a href="https://web.archive.org/web/20180402131152/https://news.ycombinator.com/">defunct</a>]<br>
HN Mirror</p>
<p>react-hn.appspot.com [<a href="https://web.archive.org/web/20181115204207/https://react-hn.appspot.com/">defunct</a>]<br>
HN Mirror</p>
<p>hackeroo.co [<a href="https://web.archive.org/web/20181115204207/https://react-hn.appspot.com/">defunct</a>]<br>
HN Mirror </p>
</div></div>]]>
            </description>
            <link>https://blog.luke.lol/tech/15-hacker-news-alternatives/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556990</guid>
            <pubDate>Mon, 28 Dec 2020 05:37:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bloom Filter – Probability and Benchmarks]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25556713">thread link</a>) | @todsacerdoti
<br/>
December 27, 2020 | http://andybui01.github.io/bloom-filter/ | <a href="https://web.archive.org/web/*/http://andybui01.github.io/bloom-filter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Bloom filters are a data structure which allows you to test whether an element exists in a set, with lower memory usage and better access times than other hash table implementations. It is probabilistic, and while it can guarantee negative matches, there is a slight chance it returns a false positive match. Through clever mathematical assumptions, we can produce constraints to minimise the chance of a false positive.</p>





<p><strong>Contents</strong></p>
<ol>
  <li><a href="#description">Description</a></li>
  <li><a href="#proof">Proof</a></li>
  <li><a href="#implementation-and-benchmarks">Implementation and benchmarks</a></li>
</ol>



<h2 id="description">Description</h2>

<p>Let there be a set of elements $N$, and we wish to store each element $e \in N$ in the set $F$. To do this, we introduce the set $K$ which has $k$ number of hash functions which hash the same element to <em>different</em> values.</p>

<p>In the following example, elements $x$ and $y$ are hashed by $k = 3$ hash functions.</p>

<p><img src="http://andybui01.github.io/images/bloom-filter/figure1.png" width="200"></p>

<p>Next, we introduce the bit array $M$ which has $m$ bits. This bit array is the underlying data structure that represents $F$, and we say an element $e$ is in $F$ if all of its corresponding bits (after hashing) in the bit array are set.</p>

<p>In the following image, $x$ is in $F$ hence all of its hashed bits within $M$ are set. Only one of $y$â€™s hashed bits are set so it is not in $F$. $x$ and $y$ are also sharing a bit at $M[4]$.</p>

<p><img src="http://andybui01.github.io/images/bloom-filter/figure2.png" width="400"></p>

<p>As we hash more elements from $N$, more bits are set to 1 in $M$ and eventually we get a <em>false positive</em> when testing set membership. This occurs when all of an elementâ€™s bits are set, although it was never inserted.</p>

<p>Consider the following scenario: $x$ and $y$ are in $F$, $z$ is not. However, $z$â€™s hashed bits are all set, giving the (false) impression that $z$ is in $F$.</p>

<p><img src="http://andybui01.github.io/images/bloom-filter/figure3.png" width="500"></p>

<p>Once an element is placed in $F$, it will remain there, as flipping bits to remove an element introduces the possibility of false negatives. We will show that there exists optimal parameters, $k$ hash functions and $m$ length bit array, to lower the false positive rate $\epsilon$.</p>



<h2 id="proof">Proof</h2>
<p>Note: This section is pretty math heavy, if you just want to look at the cool tables and graphs then you can skip ahead to <a href="#implementation-and-benchmarks">here</a>.</p>

<p>$\newcommand{\pbrac}[1]{\left(#1\right)}$
$\newcommand{\sbrac}[1]{\left[#1\right]}$</p>

<h3 id="first-attempt">First attempt</h3>
<p>Assume that a hash function in $K$ maps to each array position with <em>equal probability</em>. The probability that a bit is not set by a hash function during the insertion of an element is:</p>

<p>\begin{align}
    1 - \frac{1}{m}.
\end{align}</p>

<p>The probability that every hash function in $K$ leaves a certain bit at 0 will be</p>

<p>\begin{align}
    \left( 1 - \frac{1}{m} \right)^k \approx \ e^{-k/m}.
\end{align}</p>

<p>Thus, after inserting $n$ elements, the probability that a bit is <em>still</em> 0 is</p>

<p>\begin{align}
    \left( 1 - \frac{1}{m} \right)^{kn} \approx \ e^{-kn/m} \ = \ p,
\end{align}</p>

<p>and the probability that a bit is 1 after $n$ insertions is</p>

<p>\begin{align}
    \left( 1 - \left[ 1 - \frac{1}{m} \right]^{kn} \right) \approx \left( 1 - p \right).
\end{align}</p>

<p>Next, we test set membership for an element NOT in the set. Following $n$ insertions, each bit in the array has a chance of being set to 1 with the probability above. The probability that $k$ bits are set to 1, which would lead to a false positive result for set membership, is often referred to as the error/false positive rate:</p>

<p>\begin{align}
    \epsilon = \left( 1 - \left[ 1 - \frac{1}{m} \right]^{kn} \right)^k \approx \left( 1 - p \right)^k.
\end{align}</p>

<p>There exists a major problem with this analysis, however. At the start we made an assumption that all bits would be set randomly and independently. <strong>This is not correct</strong> as we have established that <em>all</em> our hash functions in $K$ will not hash an element to the same array position. For example, if we have hashed an element $m-1$ times into $m-1$ different positions, then the remaining $1$ bit in the array is guaranteed to be chosen, if we wish to retain an even spread of hashed values. Concretely, the $k$ bit array positions for each element are in fact <em>dependent</em>.</p>

<h3 id="another-try-using-poisson-approximations">Another try using Poisson approximations</h3>

<p>Consider a â€œballs and binsâ€� scenario where each throw of a ball into a bin is equivalent to hashing an element to an array position.</p>

<p>We have the following 2 cases:</p>
<ul>
  <li><strong>Exact case:</strong> $n$ balls are thrown into $m$ bins independently and uniformly at random</li>
  <li><strong>Poisson case:</strong> number of balls in each bin are taken to be independent Poisson random variables with an expected value</li>
</ul>

<p>Weâ€™ll be using the following corollaries from the book <em>â€œProbability and computing: randomization and probabilistic techniques in algorithms and data analysisâ€�</em> by Mitzenmacher and Upfal.</p>

<p><strong>Corollary 4.6:</strong> Let $X_1,â€¦,X_n$ be independent Poisson trials such that $P(X_i = 1) = p_i$. Let $X = \sum_{i=1}^{n} \text{ and } \mu = E(X)$. For $0 &lt; \delta &lt; 1$. [p. 71]
\begin{align}
    P\left(\left|X - \mu\right| \geq \delta \mu\right) \leq 2\exp{\left(-\frac{\mu\delta^2}{3}\right)}
\end{align}</p>

<p><strong>Corollary 5.9:</strong> any event that takes place with probability $p$ in the Poisson case takes place with probability at most $p e \sqrt{n}$ in the exact case. [p. 109]</p>

<p>Each bin corresponds to an array position and thus a bit being set to 0 is equivalent to an empty bin in our scenario. The fraction of bits being set to 0 after $n$ insertions is therefore equivalent to the fraction of empty bins after $kn$ balls have been thrown into $m$ bins.</p>

<p>We define $X$ as the number of empty bins after the balls have been thrown into $n$ bins, such that</p><p>

\[\begin{align}
    X =&amp; \ \sum_{i=1}^{n} X_i, \\
    \text{where } X_i =&amp; \
    \begin{cases}
        1 &amp; \text{if bin is empty} \\
        0 &amp; \text{otherwise}
    \end{cases}
\end{align}\]

</p><p>then we can define</p><p>

\[\begin{align}
    p' =&amp; \ \left( 1 - \frac{1}{m}\right)^{kn}, \\
    E(X) =&amp; \ mp'.
\end{align}\]

</p><p>In the Poisson case, each bin can be thought of as an independent Poisson random variable with expected value $pâ€™$. Therefore, we can apply \textbf{corollary 4.6} and $E(X) = \ mpâ€™$ to obtain the following:</p>

<p>\begin{align}
    P\left( \left| X - mpâ€™\right| \geq \delta mpâ€™\right) \ \leq&amp; \ 2\exp{\left(-\frac{mpâ€™\delta^2}{3}\right)}
\end{align}
Let $\delta \ = \ \beta / pâ€™, \ $choose small$ \ \beta$
\begin{align}
    \therefore \ P\left( \left| X - mpâ€™\right| \geq \beta m\right) \ \leq&amp; \ 2\exp{\left(-\frac{m\beta^2}{3pâ€™}\right)}
\end{align}</p>

<p>We then apply <strong>corollary 5.9</strong> to obtain</p><p>

\[\begin{align}
    P\left( \left| X - mp'\right| \geq \beta m\right) \ \leq&amp; \ 2e\sqrt{kn} \exp{\left(-\frac{m\beta^2}{3p'}\right)}\\
    \leq&amp; \ 0.000001 \ \text{when $m$ sufficiently large.}
\end{align}\]

</p><p>Essentially, taking the probability of an event using a Poisson approximation for all of the bins and multiplying it by $e\sqrt{kn}$ gives an upper bound for the probability of the event when $kn$ balls are thrown into $m$ bins (the exact case where events are independent).</p>

<p>This result tells us that when $m$ is sufficiently large, the fraction of empty bins $X/m$ is <em>very</em> close to $pâ€™$. And since $pâ€™ \approx p$ we can use $p$ to continue predicting actual performance.</p>

<h3 id="optimal-k">Optimal <em>k</em></h3>

<p>The false positive rate is $\epsilon = (1-p)^k$ and we look for a $k$ that minimizes $\epsilon$. Rearranging $\epsilon$ gives us</p><p>

\[\begin{align}
    \epsilon \ =&amp; \ \pbrac{1-p}^k \\
    =&amp; \ \exp{\pbrac{\ln{\pbrac{\sbrac{1-p}^k}}}} \\
    =&amp; \ \exp{\pbrac{k\ln{\pbrac{\sbrac{1-p}}}}} \\
    =&amp; \ \exp{\pbrac{k\ln{\pbrac{\sbrac{1-e^{-kn/m}}}}}}.
\end{align}\]

</p><p>If we let $g = k\ln{\pbrac{1-e^{-kn/m}}}$ so that $\epsilon = e^g$, then minimizing the false positive $\epsilon$ is equivalent to minimizing $g$ with respect to $k$. We have</p>

<p>\begin{align}
    \frac{dg}{dk}\ =&amp; \ \ln \left(1-e^{-\frac{nk}{m}}\right)+\frac{kn \cdot e^{-\frac{nk}{m}}}{m\left(1-e^{-\frac{nk}{m}}\right)}.
\end{align}</p>

<p>Solving this derivative when it is 0 and finding the global minimum gives us</p>

<p>\begin{align}
    k = \frac{m}{n}\ln\pbrac{2}.
\end{align}</p>

<h3 id="optimal-m">Optimal <em>m</em></h3>
<p>To find an optimal length for our bit-array we substitute $k = \frac{m}{n}\ln\pbrac{2}$ into our false positive equation and get</p><p>

\[\begin{align}
    \epsilon \ =&amp; \ \pbrac{1-e^{-\ln 2}}^{\frac{m}{n}\ln 2} \\
    \ln\epsilon \ =&amp; \ \frac{m}{n}\ln\pbrac{2}\ln\pbrac{1-e^{-\ln 2}} \\
    =&amp; \ \frac{m}{n}\ln\pbrac{2}\ln{\frac{1}{2}} \\
    =&amp; \ -\frac{m}{n}\ln\pbrac{2}^2 \\
    \therefore m \ =&amp; \ \frac{-n\ln\epsilon}{\ln\pbrac{2}^2}.
\end{align}\]

</p><p>This effectively leaves $\epsilon$ as the only unknown variable left. However, when we consider the Bloom filter in a practical context, we will most likely have a false positive rate in mind, and can treat it as a constant.</p>



<h2 id="implementation-and-benchmarks">Implementation and benchmarks</h2>

<h3 id="overview">Overview</h3>
<p>We will be comparing the Bloom filter against 4 popular and efficient implementations of hash tables:</p>

<ul>
  <li>Google Dense Hash Set</li>
  <li>Google Sparse Hash Set</li>
  <li>TSL Robin Set</li>
  <li>STD Unordered Set</li>
</ul>

<p>Implementations were compared based on time performance (insert, read) and memory performance (inserts). Currently, only small strings (15 characters) and medium strings (50 characters) are used for input, with up to $n = 3\times10^6$ elements for each test. Each test was performed 5 times for each implementation and an average-of-5 was used in the final table/graph. The false positive rate is set to 0.01.</p>

<p>Benchmarking was done using gccâ€™s C++ compiler and the following command was run to compile: g++ -Iinclude -std=c++11 -O3. In addition, the tests were performed on a computer with the following specs:</p>

<ul>
  <li>AMD Ryzen 5 2600 3.4GHz 6 core</li>
  <li>8GB DDR4-2666 CL19</li>
</ul>

<p>The tests were run with the false positive rate $\epsilon = 0.01$</p>



<h3 id="insert-small-string-15-bytes">Insert small string (15 bytes)</h3>

<p>Before the test, we generate a vector of $n$ small strings and then insert each string as an entry into the sets, measuring the performance of said insert operation. The Bloom filterâ€™s only overhead during insertion is setting bits to 1.</p>

<p><img src="http://andybui01.github.io/images/bloom-filter/insert_small_string.png" width="700"></p>



<h3 id="read-small-string-15-bytes">Read small string (15 bytes)</h3>

<p>Before the test, we generate a vector of $n$ small strings and pre-load the strings into the hash tables. We then traverse the same vector of small strings, testing set membership and timing said read operation.</p>
</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://andybui01.github.io/bloom-filter/">http://andybui01.github.io/bloom-filter/</a></em></p>]]>
            </description>
            <link>http://andybui01.github.io/bloom-filter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556713</guid>
            <pubDate>Mon, 28 Dec 2020 04:35:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Study Demonstrates Seafood Contains the Heaviest Amount of Microplastics]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25556589">thread link</a>) | @voldemort1968
<br/>
December 27, 2020 | https://smosa.com/study-discovers-seafood-carries-the-most-microplastic/ | <a href="https://web.archive.org/web/*/https://smosa.com/study-discovers-seafood-carries-the-most-microplastic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

					<!-- .post-header -->


					<div>
						<p>In a review <a href="https://ehp.niehs.nih.gov/doi/full/10.1289/EHP7171">published in Environmental Health Perspectives</a>, Microplastics (MPs) are laid out as a serious problem in the marine environment as well as human food consumption.</p><p>The study analyzed 69 experiments across mollusks, crustaceans, fish and echinodermata. The data show that seafood is a major cause of human exposure to MPs. Levels of MP contamination vary significantly in different phylum of organisms. </p><p>Microplastics are tiny pieces of any kind of plastic found in the environment less than 5mm long according to NOAA and the European Chemicals Agency. They often end up in nature from cosmetics, clothing, and industrial processes.</p><figure><img src="https://images.unsplash.com/photo-1598557928058-3e432c97dc85?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDN8fG1pY3JvcGxhc3RpY3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="Plastic (PET) bottles collected from the river Tisza. They are ready to be transported and recycled." srcset="https://images.unsplash.com/photo-1598557928058-3e432c97dc85?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDN8fG1pY3JvcGxhc3RpY3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1598557928058-3e432c97dc85?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDN8fG1pY3JvcGxhc3RpY3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1598557928058-3e432c97dc85?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDN8fG1pY3JvcGxhc3RpY3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1600 1600w, https://images.unsplash.com/photo-1598557928058-3e432c97dc85?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDN8fG1pY3JvcGxhc3RpY3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2400 2400w" sizes="(min-width: 720px) 720px"><figcaption>Photo by <a href="https://unsplash.com/@mihaly_koles?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Mihály Köles</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>Two classifications of microplastics exist. Primary microplastics are smaller than 5mm. Polyester, nylon, and rayon fibers are also present (also known as nurdles). Secondary microplastics come from the micro degradation of larger plastic particles after their entrance into the environment through natural weathering processes.</p><p>"No-one yet fully understands the full impact of microplastics on the human body, but early evidence from other studies suggest they do cause harm." said study author, Evangelos Danopoulos, a postgraduate student at Hull York Medical School in an <a href="https://www.sciencedaily.com/releases/2020/12/201223091547.htm">article from Science Daily</a>.</p><p>"A critical step in understanding the full impact on human consumption is in first fully establishing what levels of microplastics humans are ingesting. We can start to do this by looking at how much seafood and fish is eaten and measuring the amount of MPs in these creatures."</p><figure><img src="https://smosa.com/content/images/2020/12/Screen-Shot-2020-12-22-at-2_38_24-PM-1.png" alt="" srcset="https://smosa.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-22-at-2_38_24-PM-1.png 600w, https://smosa.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-22-at-2_38_24-PM-1.png 1000w, https://smosa.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-22-at-2_38_24-PM-1.png 1600w, https://smosa.com/content/images/2020/12/Screen-Shot-2020-12-22-at-2_38_24-PM-1.png 1962w" sizes="(min-width: 720px) 720px"><figcaption>Source: <a href="https://pubs.acs.org/doi/abs/10.1021/acs.est.9b01517">American Chemical Society; Expert(s) (Cox et al)</a></figcaption></figure><p>The study concludes that there needs to be harmonization and standardization of methods and procedures.</p><!--kg-card-begin: html--><p><a href="https://twitter.com/smosadotcom?ref_src=twsrc%5Etfw" data-show-count="false">Follow @smosadotcom</a></p><!--kg-card-end: html-->
					</div><!-- .post-content -->

					<!-- .post-footer -->


				</article></div>]]>
            </description>
            <link>https://smosa.com/study-discovers-seafood-carries-the-most-microplastic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556589</guid>
            <pubDate>Mon, 28 Dec 2020 04:07:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cosmopolitan Libc: build-once run-anywhere C library]]>
            </title>
            <description>
<![CDATA[
Score 288 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25556286">thread link</a>) | @pantalaimon
<br/>
December 27, 2020 | https://justine.lol/cosmopolitan/index.html | <a href="https://web.archive.org/web/*/https://justine.lol/cosmopolitan/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header>
  <img width="196" height="105" src="https://storage.googleapis.com/justine/cosmopolitan/cosmopolitan.png" title="cosmopolitan honeybadger" alt="honeybadger">
  
  <span>build-once run-anywhere c without devops</span>
</header>

<nav>
  <ul>
    <li><a href="https://justine.lol/cosmopolitan/index.html">Intro</a>
    </li><li><a href="https://justine.lol/cosmopolitan/download.html">Download</a>
    </li><li><a href="https://justine.lol/cosmopolitan/documentation.html">Documentation</a>
    </li><li><a href="https://justine.lol/cosmopolitan/sources.html">Sources</a>
    </li><li><a href="https://github.com/jart/cosmopolitan">GitHub</a>
    </li><li><a href="https://justine.lol/cosmopolitan/license.html">License</a>
    </li><li><a href="https://justine.lol/index.html">» jart's web page</a>
  </li></ul>
</nav>

<p>
  Cosmopolitan makes C a build-once run-anywhere language, similar to
  Java, except it doesn't require interpreters or virtual machines be
  installed beforehand. Cosmo provides the same portability benefits as
  high-level languages like Go and Rust, but it doesn't invent a new
  language and you won't need to configure a CI system to build separate
  binaries for each operating system. What Cosmopolitan focuses on is
  fixing C by decoupling it from platforms, so it can be pleasant to use
  for writing small unix programs that are easily distributed to a much
  broader audience.

</p><h3>Getting Started</h3>

<p>
  Assuming you have GCC on Linux, then all you need are the five
  additional files which are linked below:

</p><pre><span># create simple c program on command line</span>
echo <span>'
  main() {
    printf("hello world\n");
  }
'</span> &gt;hello.c

<span># run gcc compiler in freestanding mode</span>
gcc -g -Os -static -fno-pie -mno-red-zone -nostdlib -nostdinc -o hello.com hello.c \
  -Wl,--oformat=binary -Wl,--gc-sections -Wl,-z,max-page-size=0x1000 \
  -Wl,-T,<a href="https://justine.lol/cosmopolitan/ape.lds">ape.lds</a> -include <a href="https://justine.lol/cosmopolitan/cosmopolitan.h">cosmopolitan.h</a> <a href="https://justine.lol/cosmopolitan/crt.o">crt.o</a> <a href="https://justine.lol/cosmopolitan/ape.o">ape.o</a> <a href="https://justine.lol/cosmopolitan/cosmopolitan.a">cosmopolitan.a</a>

<span># ~40kb static binary (can be ~16kb w/ MODE=tiny)</span>
./hello.com
</pre>

<p>
  The above command fixes GCC so it outputs portable binaries that will
  run on every Linux distro in addition to Mac OS X, Windows NT,
  FreeBSD, and OpenBSD too. For details on how this works, please read
  the <a title="Actually Portable Executable" href="https://justine.lol/ape.html">αcτµαlly pδrταblε εxεcµταblε</a> blog post. This
  novel binary format is also optional: conventional ELF binaries can be
  compiled too by removing the <code>-Wl,--oformat=binary</code> flag.

</p><p>
  Your program will also boot on bare metal too. In other words, you've
  written a normal textbook C program, and thanks to Cosmopolitan's
  low-level linker magic, you've effectively created your own operating
  system which happens to run on all the existing ones as well. Now
  that's something no one's done before.

</p><h3>Mailing List</h3>

<p>
  Please join
  the <a href="https://groups.google.com/g/cosmopolitan-libc">Cosmopolitan
  Cosmonauts</a> Google Group!

</p><h3>Performance</h3>

<p>
  Cosmopolitan has been optimized by hand for excellent performance on
  modern desktops and servers. Compared with glibc, you should expect
  Cosmopolitan to be almost as fast, but with an order of a magnitude
  tinier code size. Compared with Musl or Newlib, you can expect that
  Cosmopolitan will generally go much faster, while having roughly the
  same code size, if not tinier.

</p><p>
  In the case of the most important libc function, memcpy(),
  Cosmopolitan outperformed every other open source library tested. The
  chart below shows how quickly memory is transferred depending on the
  size of the copy. Since it's log scale, each grid square represents a
  2x difference in performance. What makes Cosmopolitan so fast here is
  it uses uses several different memory copying strategies. For small
  sizes it uses an indirect branch with overlapping moves; for medium
  sizes it uses simd vectors, and for large copies it uses nontemporal
  hints which prevent cache thrash. Other libraries usually fall short
  because they use a one-size-fits-all strategy. For example, Newlib
  goes 10x slower for the optimal block size (half L1 cache) because it
  always does nontemporal moves.

</p><p>
  <a href="https://justine.lol/cosmopolitan/memcpy.png">
    <img width="960" height="540" src="https://storage.googleapis.com/justine/cosmopolitan/memcpy.png" alt="memcpy() performance for varying n values"></a>

</p><h3>Trickle-Down Performance</h3>

<p>
  Performing the best on benchmarks isn't enough. Cosmopolitan also uses
  a second technique that the above benchmark doesn't measure, which we
  call "trickle-down performance". For an example of how that works,
  consider the following common fact about C which is often overlooked.
  External function calls such as the following:

</p><pre>memcpy(foo, bar, n);
</pre>

<p>
  Are roughly equivalent to the following assembly, which leads
  compilers to assume that most cpu state is clobbered:

</p><pre><span>asm volatile</span>(<span>"call memcpy"</span>
             : <span>"=a"</span>(rax), <span>"=D"</span>(rdi), <span>"=S"</span>(rsi), <span>"=d"</span>(rdx)
             : <span>"1"</span>(foo), <span>"2"</span>(bar), <span>"3"</span>(n)
             : <span>"rcx"</span>, <span>"r8"</span>, <span>"r9"</span>, <span>"r10"</span>, <span>"r11"</span>, <span>"memory"</span>, <span>"cc"</span>,
               <span>"xmm0"</span>, <span>"xmm1"</span>, <span>"xmm2"</span>, <span>"xmm3"</span>, <span>"xmm4"</span>, <span>"xmm5"</span>, <span>"xmm6"</span>);
</pre>

<p>
  In other words the compiler assumes that, in calling the function,
  fifteen separate registers and all memory will be overwritten. See
  the <a href="https://www.uclibc.org/docs/psABI-x86_64.pdf">System V
  ABI</a> for further details. This can be problematic for
  frequently-called functions such as memcpy, since it inhibits many
  optimizations and it tosses a wrench in the compiler register
  allocation algorithm, thus causing stack spillage which further
  degrades performance while bloating the output binary size.

</p><p>
  So what Cosmopolitan does for memcpy() and many other
  frequently-called core library leaf functions, is defining a simple
  macro wrapper, which tells the compiler the correct subset of the abi
  that's actually needed, e.g.

</p><pre><span>#define</span> memcpy(DEST, SRC, N) ({       \
  void *Dest = (DEST);                \
  void *Src = (SRC);                  \
  size_t Size = (N);                  \
  <span>asm</span>(<span>"call memcpy"</span>                   \
      : <span>"=m"</span>(*(<span>char</span>(*)[Size])(Dest))  \
      : <span>"D"</span>(Dest), <span>"S"</span>(Src), <span>"d"</span>(n),  \
        <span>"m"</span>(*(<span>char</span>(*)[Size])(Src))    \
      : <span>"rcx"</span>, <span>"xmm3"</span>, <span>"xmm4"</span>, <span>"cc"</span>); \
    Dest;                             \
  })
</pre>

<p>
  What this means, is that Cosmopolitan memcpy() is not simply fast, it
  also makes unrelated code in the functions that call it faster too as
  a side-effect. When this technique was first implemented for memcpy()
  alone, many of the functions in the Cosmopolitan codebase had their
  generated code size reduced by a third.

</p><p>
  For an example of one such function, consider <code>strlcpy</code>,
  which is the BSD way of saying <code>strcpy</code>:

</p><pre><span>/**
 * Copies string, the BSD way.
 *
 * <span>@param</span> d is buffer which needn't be initialized
 * <span>@param</span> s is a NUL-terminated string
 * <span>@param</span> n is byte capacity of d
 * <span>@return</span> strlen(s)
 * <span>@note</span> d and s can't overlap
 * <span>@note</span> we prefer memccpy()
 */</span>
<span>size_t</span> strlcpy(<span>char</span> *d, <span>const</span> <span>char</span> *s, <span>size_t</span> n) {
  <span>size_t</span> slen, actual;
  slen = strlen(s);
  if (n) {
    actual = MIN(n - 1, slen);
    memcpy(d, s, actual);
    d[actual] = <span>'\0'</span>;
  }
  <span>return</span> slen;
}
</pre>

<p>
  If we compile our <code>strlcpy</code> function, then here's the
  assembly code that the compiler outputs:

</p><table><tbody><tr><td>
<pre><span>/ compiled with traditional libc</span>
<span>strlcpy</span>:
	<span>push</span>	<span>%rbp</span>
	<span>mov</span>	<span>%rsp</span>,<span>%rbp</span>
	<span>push</span>	<span>%r14</span>
	<span>mov</span>	<span>%rsi</span>,<span>%r14</span>
	<span>push</span>	<span>%r13</span>
	<span>mov</span>	<span>%rdi</span>,<span>%r13</span>
	<span>mov</span>	<span>%rsi</span>,<span>%rdi</span>
	<span>push</span>	<span>%r12</span>
	<span>push</span>	<span>%rbx</span>
	<span>mov</span>	<span>%rdx</span>,<span>%rbx</span>
	<span>call</span>	strlen
	<span>mov</span>	<span>%rax</span>,<span>%r12</span>
	<span>test</span>	<span>%rbx</span>,<span>%rbx</span>
	<span>jne</span>	1f
	<span>pop</span>	<span>%rbx</span>
	<span>mov</span>	<span>%r12</span>,<span>%rax</span>
	<span>pop</span>	<span>%r12</span>
	<span>pop</span>	<span>%r13</span>
	<span>pop</span>	<span>%r14</span>
	<span>pop</span>	<span>%rbp</span>
	<span>ret</span>
1:	<span>cmp</span>	<span>%rbx</span>,<span>%rax</span>
	<span>mov</span>	<span>%r14</span>,<span>%rsi</span>
	<span>mov</span>	<span>%r13</span>,<span>%rdi</span>
	<span>cmovbe</span>	<span>%rax</span>,<span>%rbx</span>
	<span>mov</span>	<span>%rbx</span>,<span>%rdx</span>
	<span>call</span>	memcpy
	<span>movb</span>	$<span>0</span>,0(<span>%r13</span>,<span>%rbx</span>)
	<span>mov</span>	<span>%r12</span>,<span>%rax</span>
	<span>pop</span>	<span>%rbx</span>
	<span>pop</span>	<span>%r12</span>
	<span>pop</span>	<span>%r13</span>
	<span>pop</span>	<span>%r14</span>
	<span>pop</span>	<span>%rbp</span>
	<span>ret</span>
	<span>.endfn</span>	strlcpy,globl
</pre>
</td><td>
<pre><span>/ compiled with cosmopolitan libc</span>
<span>strlcpy</span>:
	<span>mov</span>	<span>%rdx</span>,<span>%r8</span>
	<span>mov</span>	<span>%rdi</span>,<span>%r9</span>
	<span>mov</span>	<span>%rsi</span>,<span>%rdi</span>
	<span>call</span>	strlen
	<span>test</span>	<span>%r8</span>,<span>%r8</span>
	<span>je</span>	1f
	<span>cmp</span>	<span>%r8</span>,<span>%rax</span>
	<span>lea</span>	<span>-1(%r8)</span>,<span>%rdx</span>
	<span>mov</span>	<span>%r9</span>,<span>%rdi</span>
	<span>cmova</span>	<span>%rax</span>,<span>%rdx</span>
	<span>call</span>	MemCpy
	<span>movb</span>	$<span>0</span>,(<span>%r9</span>,<span>%rdx</span>)
1:	<span>ret</span>
	<span>.endfn</span>	strlcpy,globl
</pre>
</td></tr></tbody></table>

<p>
  That's a huge improvement in generated code size. The above two
  compiles used the same gcc flags and no changes to the code needed to
  be made. All that changed was we used cosmopolitan.h (instead of the
  platform c library string.h) which contains ABI specialization macros
  for <code>memcpy</code> and <code>strlen</code>. It's a great example
  of how merely choosing a better C library can systemically eliminate
  bloat throughout your entire codebase.

</p>
</div>]]>
            </description>
            <link>https://justine.lol/cosmopolitan/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556286</guid>
            <pubDate>Mon, 28 Dec 2020 02:59:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Buzzword.engineering Tech Stack]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25556272">thread link</a>) | @todsacerdoti
<br/>
December 27, 2020 | https://buzzword.engineering/post/blog-tech-stack | <a href="https://web.archive.org/web/*/https://buzzword.engineering/post/blog-tech-stack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>I've been meaning to get around to setting up a blog for a long time. In the past, I've gotten as far as getting halfway through trying out different static site generators before getting depressed about my lack of frontend design chops and given up. </p>
<p>The perfect storm finally came: </p>
<ol>
<li>I took <strong>two weeks off</strong>. After recharging my batteries for a few days, I was ready for a little side project. </li>
<li>I recently discovered <a href="https://obsidian.md/" target="_blank" rel="nofollow noopener noreferrer">Obsidian</a>, which is a dope AF note-taking app. </li>
<li>I've tried a decent number of static site generators to build documentation for various projects and wanted to take a deeper dive into <a href="https://gatsbyjs.com/" target="_blank" rel="nofollow noopener noreferrer">Gatsby</a>. </li>
<li>I recently discovered <a href="https://pipedream.com/" target="_blank" rel="nofollow noopener noreferrer">Pipedream</a> and wanted to use it for something. </li>
</ol>
<p>I wanted to see if i could use Obsidian as a <a href="https://en.wikipedia.org/wiki/Content_management_system" target="_blank" rel="nofollow noopener noreferrer">content management system (CMS)</a> for a tech blog and Pipedream to automate tweeting out new blog posts. </p>
<div><p><h5><span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span><strong>Spoiler Alert</strong></h5></p><p>It was, in fact, possible.</p></div>
<p>Anyway, here's Buzzword Engineering's inaugural blog post. If you like it, go give me a github star on the <a href="https://github.com/steven-terrana/steven-terrana.github.io" target="_blank" rel="nofollow noopener noreferrer">blog repo</a> or something. It's a nice dopamine boost and fuels my self-worth. </p>

<p>Let's dive in. Here's a digram for those visual learners out there. </p>
<p><span>
      <a href="https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/45662/overview.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/8ac56/overview.webp 240w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/d3be9/overview.webp 480w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/e46b2/overview.webp 960w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/e97dc/overview.webp 1410w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/8ff5a/overview.png 240w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/e85cb/overview.png 480w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/d9199/overview.png 960w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/45662/overview.png 1410w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/d9199/overview.png" alt="This diagram shows an overview of buzzword.engineering tech stack and associated automation" title="This diagram shows an overview of buzzword.engineering tech stack and associated automation" loading="lazy">
      </picture>
  </a>
    </span></p>
<div><p><h5><span><svg xmlns="http://www.w3.org/2000/svg" width="12" height="16" viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span><strong>Excalidraw is Dope</strong></h5></p><p>If you haven't heard of it, stop reading this and go play with <a href="https://excalidraw.com/" target="_blank" rel="nofollow noopener noreferrer">Excalidraw</a> and then come back. It's the tool I used to sketch out this diagram.</p></div>
<h2 id="obsidian"><a href="#obsidian" aria-label="obsidian permalink"></a>Obsidian</h2>
<p>I'll keep this short.  Maybe a future blog post will talk about Obsidian in a lot more detail. For now, let me just say that I've tried to get into taking notes for... a long time. I could never do it in college. I struggle to do it for work. I've always found that taking notes takes away from my ability to absorb the content in the moment and make meaningful contributions. </p>
<p>Obsidian was the first app that actually made me <strong>want</strong> to take notes. The general idea is that all your notes are written in markdown. Jumping around is super easy with <code>CMD + O</code> (which also will create pages for you if they don't exist).  Linking between pages to build connections is really easy as can be with a syntax like <code>[[this]]</code>. Obsidian builds a visual graph of the relationships between pages (I'm a sucker for graphs). And finally, you can build templates and insert them with <code>CMD + T</code>. Templates dramatically simplified the boiler plate needed to capture who's attending a meeting, agenda, the date, etc. </p>
<p>Long story short, try it out.  (Or don't, whatever.)  I'm a fan and thought that maybe if I can use it as the interface for writing blog posts that I might <em>actually</em> write some. </p>
<h3 id="automated-backups"><a href="#automated-backups" aria-label="automated backups permalink"></a>Automated Backups</h3>
<p>Obsidian has some 3rd-party plugins that do nifty things.  One of these plugins is called <a href="https://github.com/denolehov/obsidian-git" target="_blank" rel="nofollow noopener noreferrer">Obsidian Git</a> which can automatically backup your notes to a Git repository.</p>
<p>I figured that had to be a way to fetch markdown content from a remote github repository and use it as a content source for Gatsby. There was.</p>
<h3 id="defining-post-information"><a href="#defining-post-information" aria-label="defining post information permalink"></a>Defining Post Information</h3>
<p>Blog post information is defined through the markdown frontmatter.  For example, the frontmatter for this blog post: </p>
<div data-language="yaml"><pre><code><span>---</span>
<span>title</span><span>:</span> The buzzword.engineering Tech Stack
<span>date</span><span>:</span> <span>"12/26/2020"</span>
<span>publish</span><span>:</span> <span>true</span>
<span>template</span><span>:</span> <span>"post"</span>
<span>slug</span><span>:</span> blog<span>-</span>tech<span>-</span>stack
<span>description</span><span>:</span> <span>"I finally got around to putting a blog together that uses Obsidian, Gatsby, and automates tweeting out new posts with Pipedream."</span>
<span>---</span></code></pre></div>
<h2 id="gatsby"><a href="#gatsby" aria-label="gatsby permalink"></a>Gatsby</h2>
<p>I think it's important to start here by saying that I'm <strong>not</strong> a frontend developer. Well, let's rephrase that. I'm writing a blog post that has Gatsby in it.  So it's probably more accurate to say that I'm a <em>very</em> junior frontend developer. </p>
<p>My mental model for Gatsby so far is that it's a framework for building static site generators. There might be a couple frontend purists or gatsby enthusiasts out there who take issue with that definition, please let me know if you've got a better one down in the comments. </p>
<p>There are two main components of Gatsby that drew me to it: </p>
<ol>
<li>It uses <a href="https://reactjs.org/" target="_blank" rel="nofollow noopener noreferrer">React</a>, which is a lot more powerful to me over something like <a href="https://handlebarsjs.com/" target="_blank" rel="nofollow noopener noreferrer">handlebars</a> or go-based html templating. </li>
<li>Gatsby is extensible with a rich plugin ecosystem that contribute to a shared <a href="https://graphql.org/" target="_blank" rel="nofollow noopener noreferrer">GraphQL</a> data layer. When developing your site, you can query the data layer to fetch content for particular pages/components.</li>
</ol>
<p>I like React and I think Gatsby's extensibility framework and GraphQL data layer is <strong>brilliant</strong>. </p>
<h3 id="the-starter"><a href="#the-starter" aria-label="the starter permalink"></a>The Starter</h3>
<p>Another great thing about Gatsby is their concept of Starters. For this blog, I kicked things off with the <a href="https://github.com/alxshelepenok/gatsby-starter-lumen" target="_blank" rel="nofollow noopener noreferrer">gatsby-starter-lumen</a>. </p>
<h3 id="fetching-content"><a href="#fetching-content" aria-label="fetching content permalink"></a>Fetching Content</h3>
<p>The first thing I had to customize was content sources. The Lumen starter fetches content from the same repository as the blog itself. Thankfully, there's a Gatsby plugin called <a href="https://www.gatsbyjs.com/plugins/gatsby-source-git" target="_blank" rel="nofollow noopener noreferrer"><code>gatsby-source-git</code></a> that allows you to fetch content from a remote Git repository. </p>
<p>During development, I wanted to be able to fetch content from the local copy of the Obsidian backup repository. Gatsby plugins are done by exporting a javascript object from a file called <code>gatsby-config.js</code>.  </p>
<p>Here, I toggle between using the <code>gatsby-source-git</code> plugin and the [<code>gatsby-source-filesystem</code>] based on whether a <code>GATSBY_PREVIEW</code> environment variable is set. </p>
<div data-language="js"><pre><code><span>if</span><span>(</span>process<span>.</span>env<span>.</span><span>GATSBY_PREVIEW</span> <span>==</span> <span>"true"</span><span>)</span><span>{</span>
  console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>using local vault path: </span><span><span>${</span>siteConfig<span>.</span>obsidian<span>.</span>vaultPath<span>}</span></span><span>`</span></span><span>)</span>
  config<span>.</span>plugins<span>.</span><span>unshift</span><span>(</span><span>{</span>
    resolve<span>:</span> <span>'gatsby-source-filesystem'</span><span>,</span>
    options<span>:</span> <span>{</span>
      path<span>:</span> siteConfig<span>.</span>obsidian<span>.</span>vaultPath<span>,</span>
      name<span>:</span> <span>'local_obsidian'</span><span>,</span>
      ignore<span>:</span> <span>[</span> <span>"**/.git/**/*"</span><span>,</span> <span>"**/.obsidian/**/*"</span><span>,</span> <span>"**/Templates/**/*"</span> <span>]</span>
    <span>}</span>
  <span>}</span><span>)</span>
<span>}</span> <span>else</span><span>{</span>
  console<span>.</span><span>log</span><span>(</span><span>"fetching from remote repo: "</span><span>,</span> siteConfig<span>.</span>obsidian<span>.</span>repo<span>)</span>
  config<span>.</span>plugins<span>.</span><span>unshift</span><span>(</span><span>{</span>
    resolve<span>:</span> <span><span>`</span><span>gatsby-source-git</span><span>`</span></span><span>,</span>
    options<span>:</span> <span>{</span>
      name<span>:</span> <span><span>`</span><span>obsidian</span><span>`</span></span><span>,</span>
      remote<span>:</span> siteConfig<span>.</span>obsidian<span>.</span>repo<span>,</span>
      patterns<span>:</span> <span>[</span> <span>"!**/Templates/**/*"</span><span>,</span> <span>"**/*"</span> <span>]</span>
    <span>}</span>
  <span>}</span><span>)</span>
<span>}</span></code></pre></div>

<p>Comments on blog posts are made possible through a nifty tool called <a href="https://utteranc.es/" target="_blank" rel="nofollow noopener noreferrer">utteranc.es</a>. It's a GitHub Application that uses GitHub Issue threads per blog post to track comments. </p>
<h3 id="post-filtering"><a href="#post-filtering" aria-label="post filtering permalink"></a>Post Filtering</h3>
<p>In the spirit of premature optimization, I wanted to integrate a way to filter blog posts with fuzzy-searching. To accomplish this, I integrated <a href="https://fusejs.io/" target="_blank" rel="nofollow noopener noreferrer">Fuse.js</a> and added a new <code>Filter</code> component to the blog. </p>
<p>Most of the logic for how this was accomplished can be seen in the <a href="https://github.com/steven-terrana/steven-terrana.github.io/blob/main/src/templates/index-template.js" target="_blank" rel="nofollow noopener noreferrer">Index Template</a>.</p>
<div><p><h5><span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>caution</h5></p><p>I wanted to insert a gif of the filtering taking place. Apparently that's easier said than done with Gatsby and<code>gatsby-transform-remark</code>.  I'll update this post once I get gifs working 🙄.</p></div>
<h2 id="automation"><a href="#automation" aria-label="automation permalink"></a>Automation</h2>
<p>With the site actually working how I wanted it to, I got to focus on the side of things I'm actually good at: digital duct tape. The goal is for changes in markdown content in the Obsidian backup repository to trigger a deployment of the site and if there is a new blog post, to send out a tweet letting you all know about it. </p>
<h3 id="step-1-github-action-on-the-obsidian-backup-repo"><a href="#step-1-github-action-on-the-obsidian-backup-repo" aria-label="step 1 github action on the obsidian backup repo permalink"></a>Step 1: GitHub Action on the Obsidian Backup Repo</h3>
<p>First things first, the content repository needs to trigger a deployment of the site. The easiest way I could think to accomplish this would be to a GitHub Action on the blog post repository that does the build/deploy logic. </p>
<p>This meant that I needed a way to invoke a GitHub Action on one repository as part of the execution of an Action on another repository. This is where the <a href="https://docs.github.com/en/free-pro-team@latest/actions/reference/events-that-trigger-workflows#repository_dispatch" target="_blank" rel="nofollow noopener noreferrer"><code>repository_dispatch</code></a> event comes in handy. Basically, it means that you can use the GitHub API to trigger an Action. </p>
<p>Here's what the GitHub Action workflow looks like for the obsidian repository: </p>
<div data-language="yaml"><pre><code><span>name</span><span>:</span> Trigger Build
<span>on</span><span>:</span>
  
  <span>push</span><span>:</span>
    <span>branches</span><span>:</span> <span>[</span> main <span>]</span>
  
  <span>workflow_dispatch</span><span>:</span>

<span>jobs</span><span>:</span>
  <span>trigger</span><span>:</span>
    <span>runs-on</span><span>:</span> ubuntu<span>-</span>latest
    <span>steps</span><span>:</span>
     <span>-</span> <span>name</span><span>:</span> Trigger Upstream Blog Action
        <span>run</span><span>:</span> <span>|</span><span>
          curl -XPOST \
          -u "${{ secrets.PAT_USERNAME}}:${{secrets.PAT_TOKEN}}" \
          -H "Accept: application/vnd.github.everest-preview+json" \
          -H "Content-Type: application/json" \
          https://api.github.com/repos/steven-terrana/steven-terrana.github.io/dispatches \
          --data '{"event_type": "blog"}'</span></code></pre></div>
<h3 id="step-2-github-action-on-the-blog-repo"><a href="#step-2-github-action-on-the-blog-repo" aria-label="step 2 github action on the blog repo permalink"></a>Step 2: GitHub Action on the Blog Repo</h3>
<p>Sweet. Now commits to the Obsidian backup repository will trigger actions on the blog repository. </p>
<p>The next step was to automate the build and deployment steps using a GitHub Action on the blog repository. Here's what that action looks like: </p>
<div data-language="yaml"><pre><code><span>name</span><span>:</span> Build and Publish
<span>on</span><span>:</span>
  <span>repository_dispatch</span><span>:</span>
  <span>workflow_dispatch</span><span>:</span>

<span>jobs</span><span>:</span>
  <span>build-deploy-notify</span><span>:</span>
    <span>runs-on</span><span>:</span> ubuntu<span>-</span>latest
    <span>steps</span><span>:</span>
      
      <span>-</span> <span>name</span><span>:</span> Checkout Code 🛎
        <span>uses</span><span>:</span> actions/checkout@v2
        <span>with</span><span>:</span> 
          <span>persist-credentials</span><span>:</span> <span>false</span>
       <span>-</span> <span>name</span><span>:</span> Install &amp; Build 🔧
        <span>run</span><span>:</span> <span>|</span><span>
          npm ci
          npm run build
          echo "buzzword.engineering" &gt; public/CNAME</span>
        <span>env</span><span>:</span> 
          <span>PAT_USER</span><span>:</span> $<span>{</span><span>{</span> secrets.PAT_USER <span>}</span><span>}</span>
          <span>PAT_TOKEN</span><span>:</span> $<span>{</span><span>{</span> secrets.PAT_TOKEN <span>}</span><span>}</span>
      <span>-</span> <span>uses</span><span>:</span> peaceiris/actions<span>-</span>gh<span>-</span>pages@v3
        <span>with</span><span>:</span>
          <span>github_token</span><span>:</span> $<span>{</span><span>{</span> secrets.GITHUB_TOKEN <span>}</span><span>}</span>
          <span>publish_dir</span><span>:</span> public
          <span>force_orphan</span><span>:</span> <span>true</span>  </code></pre></div>
<p>This blog is hosted using GitHub Pages, so you'll notice a few things:</p>
<ol>
<li>I add a custom <code>CNAME</code> file to the <code>public</code> directory so that GitHub Pages knows the custom domain for this blog.  (I should definitely incorporate this into an inherit part of the build of the site using the <code>onPostBuild</code> Gatsby Node API method or something). </li>
<li>I use the <code>peaceiris/actions-gh-pages</code> action to publish the site. </li>
</ol>
<p>All in all, this was a pretty painless setup. </p>
<h3 id="step-3-automating-tweets"><a href="#step-3-automating-tweets" aria-label="step 3 automating tweets permalink"></a>Step 3: Automating Tweets</h3>
<p>So at this point, we've got content changes automatically getting deployed to GitHub Pages. The whole process takes about <strong>three minutes</strong> from commit to publish. </p>
<p>The last piece was to automate letting all of you know about the whatever new insightful thing I had to say! </p>
<p>I had stumbled on <a href="https://pipedream.com/" target="_blank" rel="nofollow noopener noreferrer">Pipedream</a> before through targeted ads and sort of ignored it until I saw <a href="https://twitter.com/rawkode" target="_blank" rel="nofollow noopener noreferrer">David McKay</a> talk about how much he loves it on <a href="https://rawkode.live/" target="_blank" rel="nofollow noopener noreferrer">rawkode.live</a>. Here's a <a href="https://youtu.be/Q8ZJ_5zxfmo" target="_blank" rel="nofollow noopener noreferrer">link to the stream</a>!</p>
<p>I went into this adventure thinking I was going to have to do all kinds of fancy logic and scripting to make this possible. I was wrong. </p>
<p>After setting up a Pipedream account, starting looking at what event sources were available to trigger a workflow. Well, the Lumen gatsby …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://buzzword.engineering/post/blog-tech-stack">https://buzzword.engineering/post/blog-tech-stack</a></em></p>]]>
            </description>
            <link>https://buzzword.engineering/post/blog-tech-stack</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556272</guid>
            <pubDate>Mon, 28 Dec 2020 02:56:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What's the best strategy when playing HORSE? (basketball)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25556148">thread link</a>) | @rishicomplex
<br/>
December 27, 2020 | https://rishicomplex.github.io/2020/12/25/whats-the-best-strategy-when-playing-horse.html | <a href="https://web.archive.org/web/*/https://rishicomplex.github.io/2020/12/25/whats-the-best-strategy-when-playing-horse.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    

<p><strong>TL;DR</strong>: If you want to win at HORSE, it’s generally a much better strategy to attempt high percentage shots. It almost never makes sense to shoot crazy half-court shots or behind-the-back shots. As a general rule of thumb, never attempt shots that you can’t shoot at &gt;50%.</p>

<hr>

<p><br>
<a href="https://en.wikipedia.org/wiki/Variations_of_basketball#H-O-R-S-E">HORSE</a> is a popular basketball shooting game. The main choice a HORSE player must make is which spots on the basketball court to attempt shots from. What’s the best strategy to win at HORSE?</p>

<ul id="markdown-toc">
  <li><a href="#game-rules" id="markdown-toc-game-rules">Game rules</a></li>
  <li><a href="#expected-number-of-turns" id="markdown-toc-expected-number-of-turns">Expected number of turns</a>    <ul>
      <li><a href="#deriving-the-formula" id="markdown-toc-deriving-the-formula">Deriving the formula</a></li>
      <li><a href="#visualizing-the-expected-number-of-turns" id="markdown-toc-visualizing-the-expected-number-of-turns">Visualizing the expected number of turns</a></li>
      <li><a href="#verification-via-simulation" id="markdown-toc-verification-via-simulation">Verification via simulation</a></li>
    </ul>
  </li>
  <li><a href="#analyzing-some-special-cases" id="markdown-toc-analyzing-some-special-cases">Analyzing some special cases</a>    <ul>
      <li><a href="#both-players-are-equally-good-shooters" id="markdown-toc-both-players-are-equally-good-shooters">Both players are equally good shooters</a></li>
      <li><a href="#player-1-is-a-slightly-better-shooter-than-player-2" id="markdown-toc-player-1-is-a-slightly-better-shooter-than-player-2">Player 1 is a slightly better shooter than Player 2</a></li>
      <li><a href="#player-2-is-a-slightly-better-shooter-than-player-1" id="markdown-toc-player-2-is-a-slightly-better-shooter-than-player-1">Player 2 is a slightly better shooter than Player 1</a></li>
    </ul>
  </li>
  <li><a href="#real-world-strategies" id="markdown-toc-real-world-strategies">Real world strategies</a></li>
</ul>

<h3 id="game-rules">Game rules</h3>
<p>The version of HORSE I’m analysing here involves two players. In the beginning, it’s Player 1’s turn. The player whose turn it is will be called “C”, and the other player will be called “O”.</p>
<ol>
  <li>C picks a spot on the basketball court and attempts a shot.
    <ul>
      <li>If C misses the shot, it is O’s turn, and we go back to 1.</li>
    </ul>
  </li>
  <li>If C makes the shot, O must now attempt the same shot.
    <ul>
      <li>If O makes the shot, C’s turn continues, and we go back to 1.</li>
      <li>If O misses the shot, they get a letter. C’s turn continues, and we go back to 1.</li>
    </ul>
  </li>
  <li>Once any player has gotten 5 letters, ie HORSE, they lose the game.</li>
</ol>

<p>On Player 2’s turn, Player 1 has no real strategy - they must simply try their best to make the shots that Player 2 makes. The only strategy a player can control is which shots they attempt when it’s their turn.</p>

<h3 id="expected-number-of-turns">Expected number of turns</h3>

<h4 id="deriving-the-formula">Deriving the formula</h4>

<p>Let us calculate the optimal shot on Player 1’s turn. Note that a “turn” lasts as long as the player whose turn it is does not miss their shot. We will assume that Player 1 will shoot the same optimal shot each time it is their turn. Let \(p_1\) be the probability that Player 1 makes this shot, \(p_2\) be the probability that Player 2 makes the same shot, and \(e_N\) be the expected number of turns for Player 1 to win \(N\) letters.</p>

<p>If Player 1 misses the shot, the expected number of turns going forward is \(1 + e_N\), since Player 1 has used up the current turn, and must restart in the same position next turn. If Player 1 makes the shot, and Player 2 misses the shot, the expected number of turns is \(e_{N-1}\), since the turn continues with one less letter to win. Finally, if Player 1 and Player 2 both make the shot, the expected number of turns is simply \(e_N\). Putting these together, we have</p><p>

\[\begin{equation}
e_N = (1 - p_1) (1 + e_N) + p_1 (1 - p_2) e_{N - 1} + p_1 p_2 e_N
\end{equation}\]

</p><p>Re-arranging and expanding for \(e_{N-1},e_{N-2}\ldots e_0\), we get</p><p>

\[\begin{eqnarray}
e_N - e_{N - 1} &amp;= \frac{1 - p_1}{p_1 (1 - p_2)} \\
\vdots \\
e_1 - e_0 &amp;= \frac{1 - p_1}{p_1 (1 - p_2)}
\end{eqnarray}\]

</p><p>\(e_0\) must be \(1\), since \(p_1=1, p_2=0 \implies e_1=1\). Adding the equations above and re-arranging, we get</p><p>

\[e_N = 1 + N\frac{1 - p_1}{p_1 (1 - p_2)}\]

</p><p>For the game of HORSE, \(N=5\), and so the expected number of turns to win HORSE is</p><p>

\[e_5 = 1 + 5\frac{1 - p_1}{p_1 (1 - p_2)} \tag{1} \label{eq:one}\]

</p><p>Our goal is to minimize \(e_5\). \(e_5\) increases with the inverse of the quantities \(\frac{p_1}{1 - p_1}\) and \((1 - p_2)\). Since the former grows much faster than the latter, we can intuit that increasing \(p_1\) is a lot more important than decreasing \(p_2\).</p>

<h4 id="visualizing-the-expected-number-of-turns">Visualizing the expected number of turns</h4>

<p>Since this is a function of two variables, we can visualize it with a contour plot.</p>

<p><img src="https://rishicomplex.github.io/assets/formula.png" alt="Contour plot of function"></p>

<p>As the color gets darker, the expected number of turns decreases, ie we’re more likely to win. As we would expect, the plot gets darker for higher values of \(p_1\) and lower values of \(p_2\), ie to the right and bottom of the plot. What’s interesting to note is that the contour lines are “squeezed” more toward the right than the bottom, indicating that a high \(p_1\) has a stronger effect than a low \(p_2\). For example, if \(p_2=0\) and \(p_1=0.2\), \(\eqref{eq:one}\) gives us \(e_5=21\), whereas if \(p_1=1\) and \(p_2=0.8\) we get \(e_5=1\).</p>

<h4 id="verification-via-simulation">Verification via simulation</h4>

<p>Another way to calculate \(e_5\) empirically is to simulate \(G\) games for each value of \(p_1\) and \(p_2\), and then average the number of turns the game takes to finish over all the games. Doing this with \(G=1000\), I get this plot:</p>

<p><img src="https://rishicomplex.github.io/assets/simulation.png" alt="Contour plot of simulation"></p>

<p>which matches the previous plot. The squiggles are due to randomness.</p>

<h3 id="analyzing-some-special-cases">Analyzing some special cases</h3>

<p>In reality, \(p_1\) and \(p_2\) tend to be related to one another, since shots that are harder for one player tend to be harder for the other player as well.</p>

<p>Let us analyse some special cases, corresponding to the straight lines in the following plot.</p>

<p><img src="https://rishicomplex.github.io/assets/straight_lines.png" alt="Contour plot with straight lines"></p>

<h4 id="both-players-are-equally-good-shooters">Both players are equally good shooters</h4>
<p>This corresponds to the red line above. Here, \(p_1 = p_2\), and \(\eqref{eq:one}\) simplifies to</p><p>

\[e_5 = 1 + \frac{5}{p_1}\]

</p><p>To minimize this, we should pick shots with a \(p_1\) as high as possible. For example, if we keep making layups at a probability of \(0.9\) each, we’d expect the game to be over in less than \(7\) turns.</p>

<h4 id="player-1-is-a-slightly-better-shooter-than-player-2">Player 1 is a slightly better shooter than Player 2</h4>

<p>Let’s say Player 1 always shoots 10% better than Player 2 for any shot. That is, \(p_2 = min(p_1 - 0.1, 0)\) (yellow line above), and when \(p1&gt;0.1\), \(\eqref{eq:one}\) simplifies to</p><p>

\[e_5 = 1 + 5 \frac{1 - p_1}{p_1 (1.1 - p_1)}\]

</p><p>In the range \(p_1 \in [0, 1]\), this function looks like this:</p>

<p><img src="https://rishicomplex.github.io/assets/player_1_better.png" alt="Player 1 better"></p>

<p>It is minimized at \(p_1=1\), where \(e_5=1\), that is, the game ends in one turn. Again, Player 1 wants to pick their highest probability shot.</p>

<h4 id="player-2-is-a-slightly-better-shooter-than-player-1">Player 2 is a slightly better shooter than Player 1</h4>

<p>Here, we set \(p_2 = p_1 + 0.1\) (orange line above), which gives us for \(p_1 &lt; 0.9\)</p><p>

\[e_5 = 1 + 5 \frac{1 - p_1}{p_1 (0.9 - p_1)}\]

</p><p>In the range \(p_1 \in [0, 1]\), this function looks like this:</p>

<p><img src="https://rishicomplex.github.io/assets/player_1_worse.png" alt="Player 1 worse"></p>

<p>Interestingly, we cannot simply maximize \(p_1\) here, because once \(p_2\) gets closer to \(1\), we can never win. However, the optimal \(p_1\) is still pretty high, at around \(p_1=0.684\), giving \(e_5=11.7\). If Player 2 (for whom \(e_5\) looks like the previous section) shoots shots at \(p_2&lt;0.4\) (eg three-point shots), they will lose the game, despite being a better shooter.</p>

<h3 id="real-world-strategies">Real world strategies</h3>

<p>In the real world, winning is not the only objective. You don’t want the game to take indefinitely long, and you’d be ridiculed if you kept taking layups. You also have no concrete way to estimate \(p_1\) and \(p_2\) (unless you’ve been playing an opponent for a long time and are keeping a tab on their shooting percentages), and so have to rely on intuition. Some general points to keep in mind:</p>

<ul>
  <li>You’re generally better off taking high percentage shots, even if you’re much better at a low-percentage shot than an opponent. As an example, let’s say you’ve been practicing half-court shots all year, and you can shoot a half court shot at an impressive 20% (\(p_1=0.2\)). You’re sure your opponent can’t shoot that shot if you make it (\(p_2=0\)). Your expected number of turns to win is still \(e_5=21\). Compare that to you shooting a 60% shot which your opponent can also make at 60% (eg a free throw), which lets you win in \(e_5=9.3\) turns. This is more than twice as good as the half court shot! This is because if you and your opponent both make the shot, it’s still your turn. Whereas if you miss your shot by attempting a low percentage shot, your turn is over. You can always win the game in 6-7 turns simply by taking layups at the same percentage as your opponent (assuming \(p_1\) of 0.8-0.9). If we set \(p_2=0\), and solve for \(e_5=7\), we get \(p_1 = 0.45\). That is, even if your opponent can’t make the shot you make at all, there’s generally no point in taking shots that have \(p_1 &lt; 0.45\) - you’re better off shooting layups.</li>
  <li>If you can guess \(p_1\) and \(p_2\) for a bunch of candidate shots, plug them into \(\eqref{eq:one}\) to figure out which shots are your best bet to win.</li>
  <li>Instead of practicing low percentage shots (like behind the backboard arc shots), practice your high percentage shots (like free throws or left handed layups) instead. If you and your opponent can both make a behind the backboard arc shot at 10%, and you practice to push yourself to 20%, you still go from winning in 51 turns to 23 turns. Compare that with converting your free throw from 60% to 70% - that pushes your expected turns from 9.3 to 6.4.</li>
  <li>Find novel-looking high percentage shots so that you can use an effective strategy while not getting ridiculed for just attempting layups. Examples are left handed close up shots, floaters, bank shots.</li>
</ul>

<p>I’d also recommend playing HORSE with modified rules, eg</p>
<ul>
  <li>No shots from inside the paint.</li>
  <li>No repeated shots from the same spot in a turn.</li>
  <li>If both players make three shots in a row, it’s Player 2’s turn.</li>
</ul>

<p>This should reduce the effectiveness of the layup strategy and make the game more fun.</p>

<hr>

<p><br>
The code for the plots in this post is <a href="https://colab.research.google.com/drive/18yF27zs80UF9TgFm4p7I5U4cDYn1V6A3?usp=sharing">here</a>.</p>

  </div>
</article>
<!-- Mathjax Support -->


      </div>
    </div></div>]]>
            </description>
            <link>https://rishicomplex.github.io/2020/12/25/whats-the-best-strategy-when-playing-horse.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556148</guid>
            <pubDate>Mon, 28 Dec 2020 02:27:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Personal Websites and Internet Writing]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25555725">thread link</a>) | @healeycodes
<br/>
December 27, 2020 | https://healeycodes.com/personal-websites-and-internet-writing/ | <a href="https://web.archive.org/web/*/https://healeycodes.com/personal-websites-and-internet-writing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>I chose five personal websites out of the thirty or so I visit regularly and tried to understand what it is about them that utterly captures me.</p>
<p>Whether or not it is obvious to you, I have stolen many things from the following websites. Be it design tweaks, post ideas, or even turns of phrase. These websites are incredible and you should consume them.</p>
<p>Good artists borrow, great artists <del>steal</del> use the inspect tool.</p>

<p>I have been following Justin Duke’s writing for close to two years. His older page is now <a href="https://jmduke.com/">depreciated</a> and he posts to <em>arcana dot computer</em>, an <a href="https://github.com/jmduke/arcana.computer">open source</a> website filled with catalogs and footnotes and light-touch design. The main framework is Jekyll, with dynamic content powered by Airtable. The <a href="https://arcana.computer/miscellany/this-site.html">About</a> page of Justin’s website explains the development/design/ideas behind the website in rich detail. So in this section I’ll instead focus on how I <em>feel</em> about the website.</p>
<p><span>
      <a href="https://healeycodes.com/static/b8e7b3aa62f5210ac62bb4003ff06458/0f09e/arcana.computer.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The index page of arcana.computer." title="The index page of arcana.computer." src="https://healeycodes.com/static/b8e7b3aa62f5210ac62bb4003ff06458/0f09e/arcana.computer.png" srcset="https://healeycodes.com/static/b8e7b3aa62f5210ac62bb4003ff06458/a8a0d/arcana.computer.png 300w,
https://healeycodes.com/static/b8e7b3aa62f5210ac62bb4003ff06458/dface/arcana.computer.png 600w,
https://healeycodes.com/static/b8e7b3aa62f5210ac62bb4003ff06458/0f09e/arcana.computer.png 640w" sizes="(max-width: 640px) 100vw, 640px" loading="lazy">
  </a>
    </span></p>
<p>My philosophy towards personal websites matches Justin’s. He writes:</p>
<blockquote>
<p>Lastly, if there’s anything I can convince you of: you should build a personal site, you should obsess over it, you should meticulously document it, and you should have quite a bit of fun doing so. (It’s worth it.)</p>
</blockquote>
<p>The content throughout these pages is personal and reads true. Although it’s not a journal as such, as I read through the notes and reviews I get a secret feeling that I’m looking somewhere I shouldn’t be — like peeking in a hidden diary.</p>
<p>Justin writes about capturing his <a href="https://arcana.computer/catalogs/media-diet">media diet</a>:</p>
<blockquote>
<p>This started out as a lazy compulsion, but I’ve grown rather found of this habit over time. “You are what you eat”, and all that — I’ve realized that paying more attention to how I’m spending my consumptive time has made me more focused on consuming what I’m interested in, and not simply what’s easiest.</p>
</blockquote>
<p>He talks about reviewing older sections of his media diet and how it helps him recollect that time in his life — “suddenly I am taken back to my old apartment on Capitol Hill, and my three weeks of funemployment before Stripe”. When coming across old words that I have written, I’ve also experienced this almost-olfactory flashback of thoughts.</p>
<p><span>
      <a href="https://healeycodes.com/static/afac4baa0719fea86b4df3c67c83ee57/c9fe3/catalog.arcana.computer.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The catalog listing of arcana.computer." title="The catalog listing of arcana.computer." src="https://healeycodes.com/static/afac4baa0719fea86b4df3c67c83ee57/c9fe3/catalog.arcana.computer.png" srcset="https://healeycodes.com/static/afac4baa0719fea86b4df3c67c83ee57/c9fe3/catalog.arcana.computer.png 298w" sizes="(max-width: 298px) 100vw, 298px" loading="lazy">
  </a>
    </span></p>
<p>Overall, I am impressed with the breadth and depth of content on Justin’s website, as well as how he’s made Airtable work for him. I also like that sections are marked as in-progress. I like the personal structure to it. His methods for working on this website are similar to the goals of the <a href="https://en.wikipedia.org/wiki/Long_Now_Foundation">Long Now</a> and that gels with me.</p>

<p>Paul Stamatiou writes long form articles about his life and technology. If someone has a curiosity about a subject that he has covered (e.g. <a href="https://paulstamatiou.com/made-on-an-ipad-pro/">creating with the iPad Pro</a>, or <a href="https://paulstamatiou.com/building-a-windows-10-lightroom-photo-editing-pc/">building a lightroom PC</a>) I wouldn’t hesitate linking one of his articles to them — perhaps without even reading it — because of the consistent high quality I have come to expect.</p>
<p><span>
      <a href="https://healeycodes.com/static/ed6bc43b992468145fd897cc2925f6fd/e9985/paulstamatiou.com.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Paul Stamatiou's website." title="Paul Stamatiou's website." src="https://healeycodes.com/static/ed6bc43b992468145fd897cc2925f6fd/e9985/paulstamatiou.com.png" srcset="https://healeycodes.com/static/ed6bc43b992468145fd897cc2925f6fd/a8a0d/paulstamatiou.com.png 300w,
https://healeycodes.com/static/ed6bc43b992468145fd897cc2925f6fd/dface/paulstamatiou.com.png 600w,
https://healeycodes.com/static/ed6bc43b992468145fd897cc2925f6fd/e9985/paulstamatiou.com.png 750w" sizes="(max-width: 750px) 100vw, 750px" loading="lazy">
  </a>
    </span></p>
<p>However, this quality comes with a cost, as he describes in <a href="https://paulstamatiou.com/writing-more/">Writing more</a>:</p>
<blockquote>
<p>I’m going to try something different and write more short-form posts here.</p>
</blockquote>
<blockquote>
<p>Over the years my focus has been increasing the quality of my articles. They’ve ended up becoming increasingly time-consuming to create.</p>
</blockquote>
<p>Although these articles (which for now he seems to have dubbed “briefs”) are shorter and less researched than his other writing they read as complete entries to me. On another website, by another person, they would be complete blog posts.</p>
<p>The more things I write, the more hesitant I am to actually publish. So the way he talks about blogging in <em>Writing more</em> resonates with me:</p>
<blockquote>
<p>I want to get back to what blogging felt like when I started in 2005. Back when posting a few sentences and publishing it within the same computing session was so easy and fun. Where expectations were low and it didn’t have to be perfect.</p>
</blockquote>
<p>He has written 1210 posts since 2005. My first thought goes to the build times of such a website! In 2011, he migrated from <a href="https://paulstamatiou.com/how-to-wordpress-to-jekyll/">Wordpress to Jekyll</a>. This year he <a href="https://twitter.com/Stammy/status/1307347164599922689">tweeted</a> that he’s looking at moving again:</p>
<blockquote>
<p>really, really want to migrate my jekyll blog to Hugo + Netlify but I have so many weird jekyll hacks and collections and templates/includes that I’m sure the migration would take months of spare time.</p>
</blockquote>
<blockquote>
<p>probably faster to build a new site from the ground up, new CSS and all</p>
</blockquote>
<p>Also this year, he was interviewed about his work (he’s a designer at Twitter) and about his blog on <a href="https://www.thundernerds.io/2019/10/writing-a-blog-and-working-at-twitter-with-paul-stamatiou/">Thunder Nerds</a>. (More people should be interviewed about their technology blogs please.)</p>
<p>Paul is a photographer who generates fantastic photo sets and write ups with little animated maps of the location. His <a href="https://paulstamatiou.com/photos/">photos</a>, and the way they are arranged, is truly fantastic. He has of course written <a href="https://paulstamatiou.com/photos/gear/">thousands of words</a> about his camera gear.</p>

<p>Martin Tournoij is the creator of <a href="https://www.goatcounter.com/">Goat Counter</a> and has posts dating back to 2013. His personal website is Jekyll-based and <a href="https://github.com/arp242/arp242.net">open source</a>. I usually run into his writing on <a href="https://lobste.rs/">lobste.rs</a> (a computing-focused community).</p>
<p><span>
      <a href="https://healeycodes.com/static/bffb8b2be9678c53176ffceff4411c15/86b21/arp242-posts.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Posts by Martin Tournoij" title="Posts by Martin Tournoij" src="https://healeycodes.com/static/bffb8b2be9678c53176ffceff4411c15/86b21/arp242-posts.png" srcset="https://healeycodes.com/static/bffb8b2be9678c53176ffceff4411c15/a8a0d/arp242-posts.png 300w,
https://healeycodes.com/static/bffb8b2be9678c53176ffceff4411c15/86b21/arp242-posts.png 427w" sizes="(max-width: 427px) 100vw, 427px" loading="lazy">
  </a>
    </span></p>
<p>I like the one-page layout of the landing page. There’s a list of posts and projects, a picture, and a link to his CV. My favorite post of his is <a href="https://www.arp242.net/personal-analytics.html">Analytics on personal websites</a> — where he argues in part for vanity statistics:</p>
<blockquote>
<p>As for “vanity stats” or “stats to stroke your ego”: I think that’s actually a valid use case as well. After you spent quite a bit of your spare time writing an article it’s just nice to know people are actually reading it. There’s nothing wrong with being validated – it’s a basic psychological need and I’m not a fan of casually dismissing it.</p>
</blockquote>
<p>Later on, he wrestles with the fact that since he’s the creator of an analytics tool, he doesn’t want this website to turn into an advertising channel for it.</p>
<p>Martin doesn’t shy away from controversial subjects on his blog. He writes about freedom and democracy, he pushes for empathy towards those he disagrees with. He writes without restraint which is admirable in itself.</p>
<p>He uses his own CSS template (<a href="https://github.com/arp242/hello-css">arp242/hello-css</a>) which is worth a look. If you’ll allow me to use a vague statement, his website has a unique visual readability to it.</p>

<p>Joel Califa’s website has whimsy. It doesn’t take itself seriously.</p>
<p><span>
      <a href="https://healeycodes.com/static/661e12b5960abce128d537bca7de1fb1/44bb2/joel-buttons.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The third section of Joel Califa's website" title="The third section of Joel Califa's website" src="https://healeycodes.com/static/661e12b5960abce128d537bca7de1fb1/44bb2/joel-buttons.png" srcset="https://healeycodes.com/static/661e12b5960abce128d537bca7de1fb1/a8a0d/joel-buttons.png 300w,
https://healeycodes.com/static/661e12b5960abce128d537bca7de1fb1/dface/joel-buttons.png 600w,
https://healeycodes.com/static/661e12b5960abce128d537bca7de1fb1/44bb2/joel-buttons.png 636w" sizes="(max-width: 636px) 100vw, 636px" loading="lazy">
  </a>
    </span></p>
<p>Clicking this button makes text spawn and fly away and fade (the snippets are things from the old web like: <code>&lt;i&gt;</code>, <code>&lt;frameset&gt;</code>, <code>&lt;marquee&gt;</code>, etc). There’s an illustration of his head that hides away when you hover near. The writing in the section headers frizzles with energy.</p>
<p>Joel’s website successfully serves as both a work portfolio and a design blog. His <em>Work</em> page describes itself as a “A sample of text-heavy case studies for patient visitors.” The design blog has “Low frequency, high quality design articles.”</p>
<p>My favorite post is <a href="http://joelcalifa.com/blog/tiny-wins/">Tiny Wins</a>:</p>
<blockquote>
<p>I recently shipped two things at GitHub that had an impact beyond my wildest dreams.</p>
</blockquote>
<p>Where he discusses the work involved in designing dynamic favicons for the Pull Request page:</p>
<blockquote>
<p>Now browser tabs will always show a PR’s current build status.</p>
</blockquote>
<p>As well as adding an arrow that signals which branch your changes are “flowing” into:</p>
<blockquote>
<p>Before releasing this, people would regularly confuse which branch would be merged into which.</p>
</blockquote>
<p>He writes with authentic authority. He covers subjects that seem so obvious after you read them. Like in <a href="http://joelcalifa.com/blog/revisiting-visited/">Revisiting :Visited</a>, where research, the web specification, and its practical uses, are combined:</p>
<blockquote>
<p>A Nielsen study summed this up nicely over ten years ago, “People get lost and move in circles when websites use the same link color for visited and new destinations. To reduce navigational confusion, select different colors for the two types of links.”</p>
</blockquote>
<blockquote>
<p>Can’t we, as an industry, get behind that reasoning? A “visited” link isn’t that far off from a “read” email. They both provide the user with the tacit understanding of where they’ve been.</p>
</blockquote>
<p>Joel exists in the wonderful space between technology and design where he is addressing problems that directly relate to me. For example, his website is the first place I read <a href="http://joelcalifa.com/blog/unsolicited-dating-advice/">a serious defense</a> of the <code>month/day/year</code> date ordering system.</p>
<p>It fills me with joy that I have only read half of his content.</p>

<p>Rasmus Andersson has the prettiest website in this list. An elegant three-column layout that perfectly scales to the browser’s width — dropping to two columns then one column. When a page is selected from the top right menu, the background changes to a rich color and shifts the menu up or down. With a wide enough browser, gray bars frame the website on either side.</p>
<p><span>
      <a href="https://healeycodes.com/static/5eb9bc142adf81fa12688351b5855032/c3678/rasmus-menu.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="rsms.me main menu." title="rsms.me main menu." src="https://healeycodes.com/static/5eb9bc142adf81fa12688351b5855032/c3678/rasmus-menu.png" srcset="https://healeycodes.com/static/5eb9bc142adf81fa12688351b5855032/c3678/rasmus-menu.png 159w" sizes="(max-width: 159px) 100vw, 159px" loading="lazy">
  </a>
    </span></p>
<p>Rasmus is the creator of the <a href="https://rsms.me/inter/">Inter</a> font and uses it to great effect with bold hover colors.</p>
<p><span>
      <a href="https://healeycodes.com/static/3f98abac143b4a634a29dfb50c968083/d00c8/rasmus-hover.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="rsms.me hover effects." title="rsms.me hover effects." src="https://healeycodes.com/static/3f98abac143b4a634a29dfb50c968083/d00c8/rasmus-hover.png" srcset="https://healeycodes.com/static/3f98abac143b4a634a29dfb50c968083/d00c8/rasmus-hover.png 273w" sizes="(max-width: 273px) 100vw, 273px" loading="lazy">
  </a>
    </span></p>
<p>Even his <a href="https://rsms.me/bad-url">404 page</a> is sharp.</p>
<p>After looking around more, I found a <code>&lt;script&gt;</code> tag that includes <a href="https://rsms.me/res/main.js">main.js</a>, a debug tool that must have been used to develop the grid layout (which I think is based on <a href="https://rsms.me/raster/">rsms/raster</a>). Pressing alt+D or alt+G overlays a system of boxes and dots.</p>
<p><span>
      <a href="https://healeycodes.com/static/5277a17e627e19500b115f94e8664dd1/1075d/rasmus-boxes.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Debug boxes and dots over the post list." title="Debug boxes and dots over the post list." src="https://healeycodes.com/static/5277a17e627e19500b115f94e8664dd1/1075d/rasmus-boxes.png" srcset="https://healeycodes.com/static/5277a17e627e19500b115f94e8664dd1/a8a0d/rasmus-boxes.png 300w,
https://healeycodes.com/static/5277a17e627e19500b115f94e8664dd1/1075d/rasmus-boxes.png 376w" sizes="(max-width: 376px) 100vw, 376px" loading="lazy">
  </a>
    </span></p>
<p>Rasmus’s last post was in 2017 — <a href="https://rsms.me/wasm-intro">Introduction to WebAssembly</a> — but it’s one that I revisit often as it’s a clear and detailed explanation of the technology.</p>
<p>His use of the right arrow symbol (U+2192) as well as the rounded hover effect on titles (e.g. “Projects” and “Thoughts and ideas”) is something that I closely copied for my own website as it is just too perfect.</p>
<p>Like Paul Stamatiou, Rasmus has hundreds of articles and has been blogging for a long time – almost two decades. The earlier posts are more likely to be reblogs, quotes, links, and small thoughts. The kind of things that Twitter is now used for.</p>
<p>Unlike Twitter, the permanence of these small thoughts is poetic. Here, in 2002, a new font is announced next to something like a diary entry without a paragraph break in between:</p>
<blockquote>
<p>I’ve completed a new typeface. It’s a sweet little thing called Hovden Stitch. Yes your guess was correct. It looks like stitches, cross-stitches to be precise. Go get it for your mac or pc right here. Yesterday I hung out on a free festival here in Trollhättan. Laurel Music was great. Paola sucked. Laurel Music is playing …</p></blockquote></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://healeycodes.com/personal-websites-and-internet-writing/">https://healeycodes.com/personal-websites-and-internet-writing/</a></em></p>]]>
            </description>
            <link>https://healeycodes.com/personal-websites-and-internet-writing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25555725</guid>
            <pubDate>Mon, 28 Dec 2020 01:00:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GKE HTTPS Ingress with LetsEncrypt using cert-manager]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25555628">thread link</a>) | @motte
<br/>
December 27, 2020 | https://kosyfrances.github.io/ingress-gce-letsencrypt/ | <a href="https://web.archive.org/web/*/https://kosyfrances.github.io/ingress-gce-letsencrypt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <div> <nav> <ul> <li> <a href="https://kosyfrances.github.io/">Home</a> </li> <li> <a href="https://kosyfrances.github.io/blog">Blog</a> </li> <li> <a href="https://kosyfrances.github.io/memoirs">Memoirs</a> </li> <li> <a href="https://kosyfrances.github.io/about">About</a> </li> </ul> </nav>  <p><span> <time datetime="16-03-2020">Monday. March 16, 2020</time> - <span title="Estimated read time"> 10 mins </span> </span></p> <h2 id="introduction">Introduction</h2> <p><a href="https://cloud.google.com/kubernetes-engine">Google Kubernetes Engine (GKE)</a> provides a built-in and managed Ingress controller called GKE Ingress. When you create an Ingress object, the GKE Ingress controller creates a Google Cloud HTTP(S) load balancer and configures it according to the information in the Ingress and its associated Services.</p> <p>This article describes how to setup Ingress for External HTTP(S) Load Balancing, install cert-manager certificate provisioner and setup up a Let’s Encrypt certificate. This was written based on GKE <a href="https://cloud.google.com/kubernetes-engine/docs/release-notes-stable#february_11_2020">v1.14.10-gke.17</a>, <a href="https://cert-manager.io/">cert-manager</a> v0.13 and <a href="https://helm.sh/">Helm</a> v3.</p> <h2 id="prerequisites">Prerequisites</h2> <ul> <li><a href="https://cloud.google.com/kubernetes-engine/docs/how-to/creating-a-cluster">A GKE Kubernetes cluster</a></li> <li><a href="https://helm.sh/docs/intro/install/">Helm</a></li> <li><a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/">Kubectl</a></li> <li><a href="https://cloud.google.com/compute/docs/ip-addresses/reserve-static-external-ip-address">A global static IP</a> with <a href="https://cloud.google.com/kubernetes-engine/docs/tutorials/configuring-domain-name-static-ip#step_4_configure_your_domain_name_records">DNS configured</a> for your domain for example, as example.your-domain.com. Regional IP addresses do not work with GKE Ingress.</li> </ul> <p>Note that a Service exposed through an Ingress must respond to health checks from the load balancer. According to the <a href="https://cloud.google.com/kubernetes-engine/docs/concepts/ingress#health_checks">docs</a>, your app must either serve a response with an HTTP 200 status to GET requests on the / path, or you can configure an HTTP readiness probe, serving a response with an HTTP 200 status to GET requests on the path specified by the readiness probe.</p> <h2 id="create-a-deployment">Create a deployment</h2> <p>Here is an example of a sample deployment manifest.</p> <div><div><pre><code><span>apiVersion</span><span>:</span> <span>apps/v1</span>
<span>kind</span><span>:</span> <span>Deployment</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>sample-deployment</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>sampleApp</span>
<span>spec</span><span>:</span>
  <span>replicas</span><span>:</span> <span>1</span>
  <span>selector</span><span>:</span>
    <span>matchLabels</span><span>:</span>
      <span>app</span><span>:</span> <span>sampleApp</span>
  <span>template</span><span>:</span>
    <span>metadata</span><span>:</span>
      <span>labels</span><span>:</span>
        <span>app</span><span>:</span> <span>sampleApp</span>
    <span>spec</span><span>:</span>
      <span>containers</span><span>:</span>
      <span>-</span> <span>name</span><span>:</span> <span>sampleContainer</span>
        <span>image</span><span>:</span> <span>nginx:1.7.9</span>
        <span>ports</span><span>:</span>
        <span>-</span> <span>name</span><span>:</span> <span>http</span>
          <span>containerPort</span><span>:</span> <span>8080</span>
          <span>protocol</span><span>:</span> <span>TCP</span>
        <span>readinessProbe</span><span>:</span>
          <span>httpGet</span><span>:</span>
            <span>path</span><span>:</span> <span>/healthz</span>
            <span>port</span><span>:</span> <span>8080</span>
          <span>initialDelaySeconds</span><span>:</span> <span>5</span>
          <span>periodSeconds</span><span>:</span> <span>5</span>
</code></pre></div></div> <h2 id="create-a-service">Create a service</h2> <p>Here is an example of a sample service manifest.</p> <div><div><pre><code><span>apiVersion</span><span>:</span> <span>v1</span>
<span>kind</span><span>:</span> <span>Service</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>sampleApp-service</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>sampleApp</span>
<span>spec</span><span>:</span>
  <span>type</span><span>:</span> <span>NodePort</span>
  <span>selector</span><span>:</span>
    <span>app</span><span>:</span> <span>sampleApp</span>
  <span>ports</span><span>:</span>
    <span>-</span> <span>name</span><span>:</span> <span>http</span>
      <span>protocol</span><span>:</span> <span>TCP</span>
      <span>port</span><span>:</span> <span>8080</span>
      <span>targetPort</span><span>:</span> <span>8080</span>
</code></pre></div></div> <h2 id="install-cert-manager">Install cert-manager</h2> <p>cert-manager runs within your Kubernetes cluster as a series of deployment resources. It utilizes <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/">CustomResourceDefinitions</a> to configure Certificate Authorities and request certificates. The following steps <a href="https://cert-manager.io/docs/installation/kubernetes/">installs cert-manager</a> on your Kubernetes cluster.</p> <ul> <li>Install the CustomResourceDefinition resources separately. <div><div><pre><code>  kubectl apply <span>--validate</span><span>=</span><span>false</span> <span>\</span>
  <span>-f</span> https://raw.githubusercontent.com/jetstack/cert-manager/v0.13.1/deploy/manifests/00-crds.yaml
</code></pre></div> </div> </li> <li>Create the namespace for cert-manager. <div><div><pre><code>  kubectl create namespace cert-manager
</code></pre></div> </div> </li> <li>Add the Jetstack Helm repository. <div><div><pre><code>  helm repo add jetstack https://charts.jetstack.io
</code></pre></div> </div> </li> <li>Update your local Helm chart repository cache.  </li> <li>Install the cert-manager Helm chart. <div><div><pre><code>  helm <span>install</span> <span>\</span>
    cert-manager jetstack/cert-manager <span>\</span>
    <span>--namespace</span> cert-manager <span>\</span>
    <span>--version</span> v0.13.1
</code></pre></div> </div> </li> <li>Verify the installation. <div><div><pre><code>  <span>$ </span>kubectl get pods <span>--namespace</span> cert-manager
  NAME                                       READY   STATUS    RESTARTS   AGE
  cert-manager-5c6866597-zw7kh               1/1     Running   0          2m
  cert-manager-cainjector-577f6d9fd7-tr77l   1/1     Running   0          2m
  cert-manager-webhook-787858fcdb-nlzsq      1/1     Running   0          2m
</code></pre></div> </div> <p>You should see the cert-manager, cert-manager-cainjector, and cert-manager-webhook pod in a Running state. It may take a minute or so for the TLS assets required for the webhook to function to be provisioned.</p> </li> <li>Create an <a href="https://cert-manager.io/docs/concepts/issuer/">Issuer</a> to test the webhook works okay. <div><div><pre><code>  <span>cat &lt;&lt;EOF &gt; test-resources.yaml</span>
  <span>apiVersion</span><span>:</span> <span>v1</span>
  <span>kind</span><span>:</span> <span>Namespace</span>
  <span>metadata</span><span>:</span>
    <span>name</span><span>:</span> <span>cert-manager-test</span>
  <span>---</span>
  <span>apiVersion</span><span>:</span> <span>cert-manager.io/v1alpha2</span>
  <span>kind</span><span>:</span> <span>Issuer</span>
  <span>metadata</span><span>:</span>
    <span>name</span><span>:</span> <span>test-selfsigned</span>
    <span>namespace</span><span>:</span> <span>cert-manager-test</span>
  <span>spec</span><span>:</span>
    <span>selfSigned</span><span>:</span> <span>{}</span>
  <span>---</span>
  <span>apiVersion</span><span>:</span> <span>cert-manager.io/v1alpha2</span>
  <span>kind</span><span>:</span> <span>Certificate</span>
  <span>metadata</span><span>:</span>
    <span>name</span><span>:</span> <span>selfsigned-cert</span>
    <span>namespace</span><span>:</span> <span>cert-manager-test</span>
  <span>spec</span><span>:</span>
    <span>dnsNames</span><span>:</span>
      <span>-</span> <span>example.com</span>
    <span>secretName</span><span>:</span> <span>selfsigned-cert-tls</span>
    <span>issuerRef</span><span>:</span>
      <span>name</span><span>:</span> <span>test-selfsigned</span>
  <span>EOF</span>
</code></pre></div> </div> </li> <li>Create the test resources. <div><div><pre><code>  kubectl apply <span>-f</span> test-resources.yaml
</code></pre></div> </div> </li> <li>Check the status of the newly created certificate. You may need to wait a few seconds before cert-manager processes the certificate request. <div><div><pre><code>  <span>$ </span>kubectl describe certificate <span>-n</span> cert-manager-test

  ...
  Spec:
    Common Name:  example.com
    Issuer Ref:
      Name:       test-selfsigned
    Secret Name:  selfsigned-cert-tls
  Status:
    Conditions:
      Last Transition Time:  2020-01-29T17:34:30Z
      Message:               Certificate is up to <span>date </span>and has not expired
      Reason:                Ready
      Status:                True
      Type:                  Ready
    Not After:               2020-04-29T17:34:29Z
  Events:
    Type    Reason      Age   From          Message
    <span>----</span>    <span>------</span>      <span>----</span>  <span>----</span>          <span>-------</span>
    Normal  CertIssued  4s    cert-manager  Certificate issued successfully
</code></pre></div> </div> </li> <li>Clean up the test resources. <div><div><pre><code>  kubectl delete <span>-f</span> test-resources.yaml
</code></pre></div> </div> </li> </ul> <p>If all the above steps have completed without error, you are good to go!</p> <h2 id="create-issuer">Create issuer</h2> <p>The Let’s Encrypt production issuer has very strict <a href="https://letsencrypt.org/docs/rate-limits/">rate limits</a>. When you are experimenting and learning, it is very easy to hit those limits, and confuse rate limiting with errors in configuration or operation. Start with <a href="https://letsencrypt.org/docs/staging-environment/">Let’s Encrypt staging</a> environment and switch to Let’s Encrypt production after it works fine. In this article, we will be creating a <a href="https://docs.cert-manager.io/en/release-0.11/reference/clusterissuers.html">ClusterIssuer</a>.</p> <p>Create a clusterissuer definition and update the email address to your own. This email is required by Let’s Encrypt and used to notify you of certificate expiration and updates.</p> <div><div><pre><code><span>cat &lt;&lt;EOF &gt; clusterissuer.yaml</span>
<span>apiVersion</span><span>:</span> <span>cert-manager.io/v1alpha2</span>
<span>kind</span><span>:</span> <span>ClusterIssuer</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>letsencrypt-staging</span>
<span>spec</span><span>:</span>
  <span>acme</span><span>:</span>
    <span># The ACME server URL</span>
    <span>server</span><span>:</span> <span>https://acme-staging-v02.api.letsencrypt.org/directory</span>
    <span># Email address used for ACME registration</span>
    <span>email</span><span>:</span> <span>you@youremail.com</span> <span># Update to yours</span>
    <span># Name of a secret used to store the ACME account private key</span>
    <span>privateKeySecretRef</span><span>:</span>
      <span>name</span><span>:</span> <span>letsencrypt-staging</span>
    <span># Enable the HTTP-01 challenge provider</span>
    <span>solvers</span><span>:</span>
    <span>-</span> <span>http01</span><span>:</span>
        <span>ingress</span><span>:</span>
            <span>class</span><span>:</span> <span>ingress-gce</span>
<span>EOF</span>
</code></pre></div></div> <p>Once edited, apply the custom resource:</p> <div><div><pre><code>kubectl apply <span>-f</span> clusterissuer.yaml
</code></pre></div></div> <p>Check on the status of the clusterissuer after you create it:</p> <div><div><pre><code><span>$ </span>kubectl describe clusterissuer letsencrypt-staging

Name:         letsencrypt-staging
...
Status:
  Acme:
    Last Registered Email:  you@youremail.com
    Uri:                    https://acme-staging-v02.api.letsencrypt.org/acme/acct/123456
  Conditions:
    Last Transition Time:  2020-02-24T18:33:56Z
    Message:               The ACME account was registered with the ACME server
    Reason:                ACMEAccountRegistered
    Status:                True
    Type:                  Ready
Events:                    &lt;none&gt;
</code></pre></div></div> <p>You should see the issuer listed with a registered account.</p> <h2 id="deploy-a-tls-ingress-resource">Deploy a TLS Ingress Resource</h2> <p>Create an <a href="https://kubernetes.io/docs/concepts/services-networking/ingress/">ingress</a> definition.</p> <div><div><pre><code><span>cat &lt;&lt;EOF &gt; ingress.yaml</span>
<span>apiVersion</span><span>:</span> <span>extensions/v1beta1</span>
<span>kind</span><span>:</span> <span>Ingress</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>sampleApp-ingress</span>
  <span>annotations</span><span>:</span>
    <span># specify the name of the global IP address resource to be associated with the HTTP(S) Load Balancer.</span>
    <span>kubernetes.io/ingress.global-static-ip-name</span><span>:</span> <span>sampleApp-ip</span>
    <span># add an annotation indicating the issuer to use.</span>
    <span>cert-manager.io/cluster-issuer</span><span>:</span> <span>letsencrypt-staging</span>
    <span># controls whether the ingress is modified ‘in-place’,</span>
    <span># or a new one is created specifically for the HTTP01 challenge.</span>
    <span>acme.cert-manager.io/http01-edit-in-place</span><span>:</span> <span>"</span><span>true"</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>sampleApp</span>
<span>spec</span><span>:</span>
  <span>tls</span><span>:</span> <span># &lt; placing a host in the TLS config will indicate a certificate should be created</span>
  <span>-</span> <span>hosts</span><span>:</span>
    <span>-</span> <span>example.example.com</span>
    <span>secretName</span><span>:</span> <span>sampleApp-cert-secret</span> <span># &lt; cert-manager will store the created certificate in this secret</span>
  <span>rules</span><span>:</span>
  <span>-</span> <span>host</span><span>:</span> <span>example.example.com</span>
    <span>http</span><span>:</span>
      <span>paths</span><span>:</span>
      <span>-</span> <span>path</span><span>:</span> <span>sample/app/path/*</span>
        <span>backend</span><span>:</span>
          <span>serviceName</span><span>:</span> <span>sampleApp-service</span>
          <span>servicePort</span><span>:</span> <span>8080</span>
<span>EOF</span>
</code></pre></div></div> <p>Once edited, apply ingress resource.</p> <div><div><pre><code>kubectl apply <span>-f</span> ingress.yaml
</code></pre></div></div> <h2 id="verify">Verify</h2> <p>View certificate.</p> <div><div><pre><code><span>$ </span>kubectl get certificate
NAME                    READY     SECRET                AGE
sampleApp-cert-secret   True      sampleApp-cert-secret   6m34s
</code></pre></div></div> <p>Describe certificate.</p> <div><div><pre><code><span>$ </span>kubectl describe certificate sampleApp-cert-secret
Name:         sampleApp-cert-secret
...
Status:
  Conditions:
    Last Transition Time:  2020-03-02T16:30:01Z
    Message:               Certificate is up to <span>date </span>and has not expired
    Reason:                Ready
    Status:                True
    Type:                  Ready
  Not After:               2020-05-24T17:55:46Z
Events:                    &lt;none&gt;
</code></pre></div></div> <p>Describe secrets created by cert manager.</p> <div><div><pre><code><span>$ </span>kubectl describe secret sampleApp-cert-secret

Name:         sampleApp-cert-secret
...
Type:  kubernetes.io/tls

Data
<span>====</span>
ca.crt:   0 bytes
tls.crt:  3598 bytes
tls.key:  1675 bytes
</code></pre></div></div> <h2 id="switch-to-lets-encrypt-prod">Switch to Let’s Encrypt Prod</h2> <p>Now that we are sure that everything is configured correctly, you can update the annotations in the ingress to specify the production issuer:</p> <div><div><pre><code><span>apiVersion</span><span>:</span> <span>extensions/v1beta1</span>
<span>kind</span><span>:</span> <span>Ingress</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>sampleApp-ingress</span>
  <span>annotations</span><span>:</span>
    <span>kubernetes.io/ingress.global-static-ip-name</span><span>:</span> <span>sampleApp-ip</span>
    <span>cert-manager.io/cluster-issuer</span><span>:</span> <span>letsencrypt-prod</span>
    <span>acme.cert-manager.io/http01-edit-in-place</span><span>:</span> <span>"</span><span>true"</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>sampleApp</span>
<span>spec</span><span>:</span>
  <span>tls</span><span>:</span>
  <span>-</span> <span>hosts</span><span>:</span>
    <span>-</span> <span>example.example.com</span>
    <span>secretName</span><span>:</span> <span>sampleApp-cert-secret</span>
  <span>rules</span><span>:</span>
  <span>-</span> <span>host</span><span>:</span> <span>example.example.com</span>
    <span>http</span><span>:</span>
      <span>paths</span><span>:</span>
      <span>-</span> <span>path</span><span>:</span> <span>sample/app/path/*</span>
        <span>backend</span><span>:</span>
          <span>serviceName</span><span>:</span> <span>sampleApp-service</span>
          <span>servicePort</span><span>:</span> <span>8080</span>
</code></pre></div></div> <div><div><pre><code><span>$ </span>kubectl create <span>--edit</span> <span>-f</span> ingress.yaml
ingress.extensions <span>"sampleApp-ingress"</span> configured
</code></pre></div></div> <p>You will also need to delete the existing secret, which cert-manager is watching. This will cause it to reprocess …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kosyfrances.github.io/ingress-gce-letsencrypt/">https://kosyfrances.github.io/ingress-gce-letsencrypt/</a></em></p>]]>
            </description>
            <link>https://kosyfrances.github.io/ingress-gce-letsencrypt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25555628</guid>
            <pubDate>Mon, 28 Dec 2020 00:46:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mobile-First (and why it's a bad idea)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25555623">thread link</a>) | @taphangum
<br/>
December 27, 2020 | https://planflow.dev/blog/why-mobile-first-is-a-bad-idea | <a href="https://web.archive.org/web/*/https://planflow.dev/blog/why-mobile-first-is-a-bad-idea">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>(This article was originally published in </em><a target="_blank" title="https://gumroad.com/l/Debbg/z823cp8" href="https://gumroad.com/l/Debbg/z823cp8"><em>How To Debug CSS</em></a><em>)</em></p><p>While I could always understand the idea behind the mobile-first approach to developing websites. It always felt….off to me.</p><p>Mobile-first, which is a design approach that involves starting with the mobile version of a website before the desktop version, is a great idea in theory.&nbsp;</p><p>The problem comes when it meets reality.</p><p>There are countless stories of developers who, upon hearing about (and even learning how to design with) a mobile first approach, ultimately ended up reverting back to, and starting with the desktop versions of their sites.</p><p>According to a <a target="_blank" title="https://twitter.com/KevinJPowell/status/1244427032957784066" href="https://twitter.com/KevinJPowell/status/1244427032957784066">survey</a> conducted by Kevin Powell (a GREAT frontend tutorial maker), the majority (61.5%) of developers prefer to start with the desktop first:</p><p><img src="https://media.graphcms.com/gkrvHBiXR3ON7pcIkwSG" alt="Screenshot 2020-12-27 at 22.39.13.png" title="Screenshot 2020-12-27 at 22.39.13.png" width="597" height="413"></p><p><em><strong>(this after almost 8 years of the mobile-first approach being championed almost exclusively)</strong></em></p><p>This is a sentiment that I have also found to be true on many message boards and online discussions that I’ve seen around responsive web design.</p><p>It is interesting that despite this clear evidence that the majority of developers simply do not inherently want to design websites with a mobile-first approach, the idea is still being championed as the preferred methodology.</p><p>Let’s explore why this is.</p><h2>Why Mobile-First is often championed</h2><p>There are two main reasons why the mobile-first approach is often touted as the best approach to take for developing a responsive website:</p><p>	<strong>1.	Better UX, at every screen size </strong></p><p>The first is that it provides a better user experience at every screen size, because it best optimizes for the smaller screen sizes as well as the larger ones. The argument is that it does this by focusing on only the most important elements of the layout, as that is all that can fit on the smaller mobile screens. And that this focused approach ‘scales up’.</p><p>The trouble with this is that it simply does not seem to hold up to scrutiny.&nbsp;</p><p>What actually seems to end up happening with mobile-first is that the overall site just becomes less creative in general.&nbsp;</p><p>Most mobile sites (and their subsequent desktop sites) end up simply looking the same as every other website out there.</p><p>We’ll see why this is the case shortly (the diagram at the top of this post will give you an idea).</p><p>	<strong>2.	Better organized (and easier to create) CSS </strong></p><p>The second reason why mobile-first is often regarded as the best way to develop a responsive website is that on most sites, the ‘default’ CSS styles (i.e. the styles that are written outside of the scope of media queries) are often the ones that are aimed at the smaller, mobile screen sizes.&nbsp;</p><p><strong>Typical CSS file organization for a responsive website:</strong></p><p><img src="https://media.graphcms.com/output=format:png/resize=height:748,width:996/sPcNpTKARkKzOUO3KzZ4" alt="typical-css-responsive-file.png" title="typical-css-responsive-file.png" width="996" height="748"></p><p>Because the typical CSS workflow of a responsive website is to add the media query related styles after the fact (because media queries are supposed to be at the bottom of the page, as mentioned above), starting with what would be your ‘default’ styles, which would be your mobile styles, seems to make more sense.</p><p>We will also shortly see why this is not exactly correct.</p><p>Let’s dive into the key reasons why, despite these two decent arguments in favor of a mobile-first approach to responsive web design, it still is not the best way to approach it.</p><h2>Why mobile-first is good in theory but bad in practice</h2><h3>You are optimizing for the sub-optimal experience</h3><p>The mobile experience <em>is</em> sub-optimal. This is not a point that is really debated. The entire point of a mobile version of a site is to deliver a lesser, but still somewhat effective version of the optimal desktop experience.</p><p>The problem with optimizing for the mobile experience, is that it does not make the overall experience optimal. It only scales up sub-optimality. The compromises that start on the mobile experience ultimately become compromises on the desktop end.</p><p><strong>It only degrades the desktop experience.</strong></p><p>The desktop site is the ‘real’ site in most cases, <a target="_blank" title="https://www.reddit.com/r/webdev/comments/d7nj58/how_do_you_deal_with_mobile_first_and/" href="https://www.reddit.com/r/webdev/comments/d7nj58/how_do_you_deal_with_mobile_first_and/">most clients</a> expect to see a desktop site first.</p><p>Desktop-first focuses on the design problem that people actually care about, while mobile-first focuses on the CSS organization problem, which only developers do.</p><p>Instead of starting with the sub-optimal experience (that helps the developer), it’s much better overall to optimize for the optimal experience (that helps the user) and then scale down.</p><h3>It’s an unnatural way to design</h3><p>Because design is an intuitive process fundamentally, any design approach that requires you to have to ‘get over yourself’ is probably a bad idea.</p><p>Design is basically a process of guiding the user, by developing an interface based on what guides <em>you</em>, naturally.</p><p>For this to be effective, context is key, and being able to maximally utilize the scope of experience that the user has, gives you more ‘surface area’ with which to appropriately meet the context and guide the user.</p><p>For this reason, It’s better to start at the ‘largest’ possible context for this.&nbsp;</p><p>For example, for a professional sports match. What has a better chance of delivering the ‘fullest’, more complete experience to you?&nbsp;</p><p><strong>The actual, ‘bigger’, more natural, live game:</strong></p><p><img src="https://media.graphcms.com/p5ESEubnQNKm7eEPdLmR" alt="man-290186_1920.jpg" title="man-290186_1920.jpg" width="1920" height="1275"></p><p><strong>Or the TV experience?</strong></p><p><img src="https://media.graphcms.com/qUwYVApRW22XXnKOCOqd" alt="soccer-3496510_1920.jpg" title="soccer-3496510_1920.jpg" width="1920" height="1280"></p><p><em><strong>What should be optimized for first to deliver the best final result in both cases?</strong></em></p><p>The Desktop experience encompasses what is essential information within a mobile context. Mobile does not necessarily have what is essential to a desktop context.</p><p>This is why desktop-first <a target="_blank" title="https://www.reddit.com/r/webdev/comments/cy1xuk/do_you_feel_like_desktop_web_dev_is_fun_and/" href="https://www.reddit.com/r/webdev/comments/cy1xuk/do_you_feel_like_desktop_web_dev_is_fun_and/">seems to feel more natural</a> to most developers. It’s just enough constraint for the task of navigating a website, but not too much.</p><p>Leaving an ideal amount of room for creativity. Which mobile-first kills.</p><h3>Mobile-first kills creativity</h3><p>With mobile-first, there are too many unanswered questions.</p><p>Questions that should have been answered at the desktop level, ultimately never get answered.</p><p>At the desktop level, the challenges are often much bigger, and require more creativity to solve. Because the questions you need to ask at smaller screens are simply fractals (or subsets) of their larger counterparts, It’s much better to answer them first at the larger sizes, which then makes it easier to answer subsequent smaller size and mobile design questions.</p><p>With a mobile-first approach, you can fall into the trap of getting so fixated on the subsets that you fail in giving people the essence of the page. This essence is what the initial answers to the bigger design questions give you.</p><p>To get that essence, in the same way that you would have to crush grapes at scale, and then gradually go through a distillation process to finally achieve a wine. To get a mobile site that really gets to the core of a site, its best to start with the desktop version. And then gradually filter or scale down.</p><h3>Mobile-First makes design too formulaic</h3><p>Because of the degree of constraint in the mobile-first approach, and the lack of room for creativity that this engenders, developers naturally seek out tried and true patterns that they can follow.&nbsp;</p><p>This isn't a bad thing, as we all use inspiration to a degree. The issue is that, just as we’ve seen with frameworks like Bootstrap. Too much of a formulaic approach often leads to a level of sameness that literally bores everyone.</p><p>Mobile-first may be one the things contributing to the ever increasing ‘sameness’ of the web that we see nowadays.</p><p>This consequently reduces the kind of web activity that we want (such as conversions) across the board. People are simply less engaged, and tuning these websites out.</p><p>Imagine if those ever-quirky and endlessly interesting sites of the late 90’s, early 2000’s like the ones we used to find on GeoCities and Angelfire were thinking about ‘mobile first’.&nbsp;</p><p>Do you think they would have achieved the same level of uniqueness? I doubt it.</p><h2>An alternative (desktop-first) approach</h2><p>The mental shift that we should make is not desktop to mobile first.</p><p>It's not to simply squish things on the desktop either.</p><p>The correct mental shift is to say, once we have a desktop version, what do we need to resize, rearrange, or remove in order to have an optimal yet still equally informative experience on mobile?</p><p>We should be asking how we can make the mobile experience a good fractal of the desktop experience.&nbsp;</p><p>We should ask what we are trying to achieve with our desktop site, and how we can achieve (even if only a little bit) the same on smaller screens.</p><p>The way that we should design our websites should be to start with the desktop first, and then scale down with empathy, asking the big designs questions before we start to ask the smaller ones.</p><p>We should start our web design process at the bottom of the CSS file, with the desktop sized media query, instead of making those first global (mobile-first) styles.&nbsp;</p><p>After that, once we have answered our biggest design questions at the desktop level, we can scale down (and up in the code) with more media queries (in the case of the smaller sizes) and with the default global styles in the case of the absolute smallest mobile size. Taking out all but the necessary.&nbsp;</p><p>Ultimately, this feels like the most natural approach to take.</p><p>--</p><p><em>This is an excerpt from </em><a title="https://gumroad.com/l/Debbg/z823cp8" href="https://gumroad.com/l/Debbg/z823cp8"><em>How To Debug CSS</em></a><em>. A book that’s written to solve the problem outlined in this post. To help take you from a vague level of understanding with CSS, to an intuitive, know it like the back of your hand level of understanding. Enabling you to not only create layouts with ease, but to debug any issues that come up with them as you do so.</em></p><p><em>The book is currently available for pre-order with a temporary (40%!) pre-launch discount on the link above. You may purchase by clicking on the link above! Or by clicking here: </em><a title="https://gumroad.com/l/Debbg/z823cp8" href="https://gumroad.com/l/Debbg/z823cp8"><em>“How To Debug CSS”</em></a><em>.</em></p></div></div>]]>
            </description>
            <link>https://planflow.dev/blog/why-mobile-first-is-a-bad-idea</link>
            <guid isPermaLink="false">hacker-news-small-sites-25555623</guid>
            <pubDate>Mon, 28 Dec 2020 00:46:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NZBgeek Hack: Breached Passwords and Credit Cards]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25555165">thread link</a>) | @w3abhishek
<br/>
December 27, 2020 | https://innovativebeast.com/nzbgeek-hack-breached-passwords-and-credit-cards/ | <a href="https://web.archive.org/web/*/https://innovativebeast.com/nzbgeek-hack-breached-passwords-and-credit-cards/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-container">

<main id="main" itemscope="itemscope" itemtype="https://schema.org/CreativeWork">
<div data-sidebar="right" data-v-spacing="top:bottom" data-structure="classic:boxed">
<section>
<article id="post-3843">
<section data-type="type-1">

</section>
<div>
<p>NZBgeek is a very popular community-based indexer of Usenet posts. It is run by using the Newznab Interface. NZBgeek provides paid and free services for its own users, plus so they truly have been reasonable to think about.</p>
<p>On the evening of 27 December 2020, NZBgeek announced that they got hacked and the following details of their users are breached in this hacking attack on their community website:</p>
<ol>
<li>Username</li>
<li>Encrypted passwords</li>
<li>Email Address</li>
<li>Credit Card Numbers</li>
</ol>
<h3 id="rtoc-1">How this Attack was Performed?</h3>
<p>According to the announcement post by @Dangerous_Mummy and @jeeves in their Discord server, this attack and data breach happened because the attacker installed a Keylogger on the website of NZBgeek.</p>
<p>@Dangerous_Mummy written:</p>
<blockquote><p><span tabindex="-1" role="button">@everyone</span> Geeks, it’s with a heavy heart that we must admit that we have had a breach. If you have recently used your card or payment with us we suggest changing your credentials and card info as soon as possible. We still don’t know the extent of the damage but are working to find out and give our members the details as they become available.</p></blockquote>
<p>@jeeves written:</p>
<blockquote><p>@everyone</p>
<p>Hey Geeks,</p>
<p>IMPORTANT!</p>
<p>If you have used your card with us since the 20th November 2020 please take appropriate action.<br>
This includes reporting it to your card issuer as this protects you from any unlawful charges.</p>
<p>What We Know:</p>
<p>The hackers were able to place a keylogger on the website.<br>
The hackers obtained a copy of our database which includes your username, encrypted password, email address &amp; last connected ip address.<br>
During this time we had the hard drive on our indexer fail along with an api server.<br>
PayPal data is not at risk provding you do not use the same username/password for NZBgeek.</p>
<p>Advised Actions:</p>
<p>If you use the same userame/password combination on any other website please change them.<br>
You should use 2FA/two factor authticaition with all your online accounts.</p>
<p>Current Situation:</p>
<p>We have everything offline except for the API while we have external help to investigate.<br>
Additional updates will be made here on discord, including what changes to expect moving forward.</p>
<p>Thanks,<br>
jeeves</p></blockquote>
<p>It is one of the major data breaches because the payment information is breached and is available in the hands of attackers.</p>
<p><img loading="lazy" src="https://innovativebeast.com/wp-content/uploads/2020/12/IMG_20201228_113103.jpg" alt="" width="767" height="450" srcset="https://innovativebeast.com/wp-content/uploads/2020/12/IMG_20201228_113103.jpg 767w, https://innovativebeast.com/wp-content/uploads/2020/12/IMG_20201228_113103-300x176.jpg 300w" sizes="(max-width: 767px) 100vw, 767px"><br>
<img loading="lazy" src="https://innovativebeast.com/wp-content/uploads/2020/12/IMG_20201228_113116.jpg" alt="" width="767" height="311" srcset="https://innovativebeast.com/wp-content/uploads/2020/12/IMG_20201228_113116.jpg 767w, https://innovativebeast.com/wp-content/uploads/2020/12/IMG_20201228_113116-300x122.jpg 300w" sizes="(max-width: 767px) 100vw, 767px"></p>
<h3 id="rtoc-2">What actions users should take?</h3>
<ol>
<li>If you use the same password on multiple accounts, immediately change the passwords of all your accounts</li>
<li>Contact your credit card provider and block your card to stop further unauthorized transactions</li>
<li>Use 2FA on all of your websites/accounts whenever possible.</li>
</ol>
<p><span data-ez-name="innovativebeast_com-medrectangle-1"><span><span><a href="https://www.ezoic.com/what-is-ezoic/" target="_blank" rel="noopener noreferrer nofollow"><img src="https://go.ezoic.net/utilcave_com/img/ezoic.png" alt="Ezoic"></a></span></span></span>
</p> </div>

</article>
</section>

</div>


</main>
</div></div>]]>
            </description>
            <link>https://innovativebeast.com/nzbgeek-hack-breached-passwords-and-credit-cards/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25555165</guid>
            <pubDate>Sun, 27 Dec 2020 23:34:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons I’ve learned after 10 years and $10M in sales]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25555137">thread link</a>) | @rookhack
<br/>
December 27, 2020 | https://jamesclift.ca/7-things-ive-learned-after-10-years-of-trying-to-make-it-on-the-internet-2bbd8b60f5a?source=friends_link&sk=fe41337b9e6efa39a7ba9c297338c3b7 | <a href="https://web.archive.org/web/*/https://jamesclift.ca/7-things-ive-learned-after-10-years-of-trying-to-make-it-on-the-internet-2bbd8b60f5a?source=friends_link&sk=fe41337b9e6efa39a7ba9c297338c3b7">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><div><div><div><p><a href="https://jamesclift.medium.com/?source=post_page-----2bbd8b60f5a--------------------------------" rel="noopener"><img alt="James Clift" src="https://miro.medium.com/fit/c/96/96/1*Ax3-HNLKsss3ruWjpgvpXg.jpeg" width="48" height="48"></a></p></div></div></div></div><p id="9d97">I’ve been playing the technology company game for over a decade now.</p><p id="63cf">In that time, I went from a 20 year old kid who had no idea what he was doing to a man with a good beard who has no idea what he is doing that happened to sell millions of dollars of software.</p><p id="b011">I don’t often reflect on absurdity of it, but it is absurd.</p><p id="36c0">Weirder still, I’m the least impressive of my friends in this world — I’ve had the good fortune of being surrounded by people who started off exactly like I did build massive companies with hundreds of employees.</p><p id="ce22">As a kid, the only jobs I knew of that “rich” people had were doctor, lawyer, and that scary kid who’s dad was probably in the mob. Becoming a millionaire was not discussed, nor even imagined. Yet, here we are.</p><p id="acdf">Here are a few things I’ve learned from a decade of trying to make it on the internet.</p><p id="bcf1">The low point of (one of) my first companies was being so desperate for revenue that we adapted our<em> virtual job fair</em> platform to become a virtual business directory for a small town. For $2000/yr.</p><p id="6385">There is no upside to that. We essentially became a horribly paid consultant for an industry we didn’t care about with a product that didn’t add any value.</p><p id="f2cc">Limping along for years while eating ramen and pitching a VISION isn’t success — you’ll be much worse off than if you had just worked for a startup for a few years to improve your skills and peers.</p><p id="ce0b">To truly bet on yourself while starting a company, everything you do should accelerate any of the following:</p><ul><li id="bc69">Learning new skills: sales, product management, product development, engineering, marketing, design, fundraising</li><li id="12a6">Meeting great people — not in the “I shook Mark Cuban’s hand” sense, but in the “I have 5 equally motivated people in my corner building shit that I can text about the fact that we won’t make payroll next month.”</li><li id="c5c2">Making money on your own time</li><li id="00e0">Travelling or experiencing the world through a different lens (though in 2020 you should just get a remote job)</li></ul><p id="ae33">You don’t need mentors. You don’t need investors. You need 5 friends with similar ambitions trying to figure this shit out with you.</p><p id="537b">You want people that you can call when your world is falling apart. When you want to quit. When you hate your co-founders. When you’re questioning everything. When you’ve made the money, but don’t feel good about it.</p><p id="8018">It is a weird, un-relatable world that we’re playing in. To navigate it, you need people that understand. I’m so lucky I found my people.</p><p id="1451">I don’t have great advice on how to find your people.</p><p id="c46f">Join a co-working space? Get into a startup accelerator? Join a program like <a href="https://www.beondeck.com/" rel="noopener">On Deck</a>? Message people on Twitter?</p><p id="64cd">I know many people who are much more talented than I. They’ve got better ideas, more technical skills, and are just plain smarter.</p><p id="1d7d">What they don’t have is that forcing function that compels me to launch stuff.</p><p id="7bb3">The shamelessness. The not-give-a-fuckery.</p><p id="2ae5">To not quit when I want to quit. I’m not sure that “chip on the shoulder” is all positive, but it’s probably necessary.</p><p id="aaf9">It’s a learned behaviour. I don’t come by it naturally. I hate failing. I suck at getting feedback. I’m overly sensitive. And yet, here we are.</p><p id="cccf">Every successful individual I’ve seen has taken at least 3 years to create something with some hint of product market fit.</p><p id="1a79">Dig deeper into every company that takes off overnight — it’s probably a pivot from something else, the founder’s 8th attempt, or a hail mary. The one thing that truly worked for me was about 3.5 years in.</p><p id="8fb0">That specific thing worked in month 2, but it took 3.5 years of learning to get to that point.</p><p id="2606">My original goal when starting out (Thanks Tim Ferriss!) was to <em>“build a business making 10k a month so I could work from anywhere.”</em></p><p id="b9da">I got there, and enjoyed it — lived in multiple countries, didn’t work too much, drank great wine and ate incredible steak. It wasn’t enough.</p><p id="9d82">Financially, it didn’t matter. The cash was enough, but a life of leisure isn’t a great goal for a 30 year old. I stopped growing, learning.</p><p id="0969">Ironically, that guiding goal held me back. What seemed ambitious at the time led to unambitious decisions, like first building a below average web design company. It also led to coasting when cashflow was (very) good.</p><p id="cdd3">I somehow managed to reverse engineered my version of success, but unfortunately financial success is always a moving target — especially once you have something that works.</p><p id="0d0a">What would have been a better focus is building an exceptional product, an amazing team, and continuing to grow as a leader.</p><p id="65c1">If you can solve for those things, the score (and the cash) takes care of itself.</p><p id="6a9b">That said, if your goal is to build a company that makes 10k/mo that allows you to work from anywhere — go for it, goddamnit.</p><p id="38f1">Building something from scratch is hard, and having a job will often sound very appealing.</p><p id="9e48"><em>Here’s what you need to do today, and here’s your paycheque!</em></p><p id="a7a7">Starting a company has infinite variables. At the early stages, you’re pushing a boulder up every hill you can find. You’re trying to find that one thing that gathers enough momentum to allow you to survive another day.</p><p id="664a">If you’re lucky, you’ll get to a place where you’re no longer trying to survive — you’re trying not to die. There’s a difference.</p><p id="6c93">Every day you will have an infinite to-do list, none of which is certain.Take your best guess at what the most important thing you can work on is.</p><p id="6202">Do that thing, and try to ignore everything else.</p><p id="ee2b">Don’t forget to manage your psychology along the way. At the end of the day no one cares if you fail, and it’s not that important. Have grounding forces in your life (sports, family, knitting) to help keep you sane. Try not to build your whole identity around your company.</p><p id="950c">(You won’t do any of this, but I’m hopeful this will help you realize you’re not the only one.)</p><p id="6c90">Most people who reach unheard of levels of success are probably not that much smarter than you, and they probably don’t work that much harder.</p><p id="d7fd">Granted, there are ridiculously smart driven people that operate on another level (Elon Musk, The Collisons). They’re likely going to be trillionaires.</p><p id="7870">I’ve met many people who have built $100m+ companies that are very smart and work very hard — but probably not that much harder than a Senior Engineer at Amazon. Success is a result of talent, hard work, and luck.</p><p id="3b30">If you’re smart, want to work hard, and care about building a business one day — the best place to put that energy is into creating something new.</p><p id="7ac5">You can’t get lucky if you’re not in the game.</p></div></div></section></div>]]>
            </description>
            <link>https://jamesclift.ca/7-things-ive-learned-after-10-years-of-trying-to-make-it-on-the-internet-2bbd8b60f5a?source=friends_link&amp;sk=fe41337b9e6efa39a7ba9c297338c3b7</link>
            <guid isPermaLink="false">hacker-news-small-sites-25555137</guid>
            <pubDate>Sun, 27 Dec 2020 23:27:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacking German Elections [video]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25554963">thread link</a>) | @manfredz
<br/>
December 27, 2020 | https://media.ccc.de/v/rc3-11440-hacking_german_elections | <a href="https://web.archive.org/web/*/https://media.ccc.de/v/rc3-11440-hacking_german_elections">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>
<span></span>
<a href="https://media.ccc.de/search?p=Johannes">Johannes</a> and
<a href="https://media.ccc.de/search?p=Tobias">Tobias</a>

</p>

<p><a href="https://media.ccc.de/c/rc3/rC3" rel="tag">rC3</a>
<a href="https://media.ccc.de/c/rc3/IT-Security" rel="tag">IT-Security</a>
Playlists:
<a href="https://media.ccc.de/v/rc3-11440-hacking_german_elections/playlist">'rc3' videos starting here</a>
/
<a data-method="get" href="https://media.ccc.de/v/rc3-11440-hacking_german_elections/audio">audio</a></p>
<!-- %h3 About -->
<p>After the first unsuccessful deployment of voting machines in Germany about ten years ago, elements of electronic voting have reached elections again. Although there is now still a paper-trail, more and more essential steps, such as counting the votes, are moved into electronic systems. This change in the ballot-counting procedure took place mostly unnoticed by the public. We are two very concerned election workers who present our first-hand experience in this talk. We show that the current digital procedure is conceptually and practically flawed in terms of security. First, we give an insight into the role of computers and their interaction with humans during ballot-counting. We show that the underlying system concepts contradict IT-security best-practices. Next, we present an in-depth analysis of one ballot-counting software, deployed for the Bavarian municipal elections ("Kommunalwahlen"). We discovered several severe security vulnerabilities that allow an almost unnoticeable manipulation of local voting results. Finally, we conclude that there is an immediate need for action to re-establish election security and transparency - not only for the government but for everyone of us.</p>

<p>Elections are a key element of every democracy. However, many democratic countries in the world have to face attacks on them, be it by the government or by foreign countries. Even if ballot counting has been finished, election results are often not accepted but questioned due to alleged manipulations. All these aspects pose major threats to democracy as they try to undermine the actual and publicly perceived integrity of elections.</p>

<p>In Germany, elections are usually considered quite secure. Elections are paper-based and the subsequent ballot-counting is open to the public. The infamous introduction of electronic voting machines about ten years ago was finally stopped by the German Federal Constitutional Court. Thus, everything is human-controlled, transparent, and secure – isn’t it?</p>

<p>Unfortunately, these claims are questionable since the silent introduction of electronic vote counting. The election system in Germany is quite complex, for example in the "Kreistagswahlen" (~district elections) workers have to count up to 70 individual votes per ballot, while respecting a special rule set. This process is very labor-intensive and sufficient election workers are often hard to come by. Due to this, electronic systems were introduced that provide support during vote counting. Election workers are no longer required to fill tally sheets, count votes, and sum them up on their own. Each ballot is simply entered into a software that performs all the magic and finally emits a result.</p>

<p>This year, we volunteered again as election workers, but our trust in electronically-assisted elections has been vastly impacted. As IT-security researchers, we consider it our responsibility to share and discuss our concerns. We performed a thorough analysis of the concept and the hard- and software of the electronic vote counting system. We discovered several flaws on a conceptual and practical level, that can severely diminish the integrity of the election and makes it prone to manipulations. To underline the impact of the system’s vulnerabilities, we demonstrate an exemplary attack on an election.</p>

<p>Finally, we propose different options on how to make elections secure again. We do not consider this an entirely technical case, as there are significant legal and societal circumstances that led to the deployment of this insecure system.</p>

<h3>Download</h3>

<!-- %h3 Embed/Share -->

<h3>Tags</h3>

</div></div>]]>
            </description>
            <link>https://media.ccc.de/v/rc3-11440-hacking_german_elections</link>
            <guid isPermaLink="false">hacker-news-small-sites-25554963</guid>
            <pubDate>Sun, 27 Dec 2020 22:51:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why we write Elementary apps in Vala (2014)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25554949">thread link</a>) | @silasdb
<br/>
December 27, 2020 | https://blog.elementary.io/why-we-write-elementary-apps-in-vala/ | <a href="https://web.archive.org/web/*/https://blog.elementary.io/why-we-write-elementary-apps-in-vala/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  <header>
    
    
      <h2>



   A tremendously effective tool for our&nbsp;needs

</h2>
    

    






    


  </header>

  <section>
    <figure>
  <p><img src="https://cdn-images-1.medium.com/max/2000/1*zqydEido_Yipr0YiJv5hYg.png" alt=""></p>
</figure>

<p>If you follow elementary OS development, you may know that we do not write our applications on C or Python, but rather a language called <a rel="nofollow noopener noreferrer" target="_blank" href="https://wiki.gnome.org/Projects/Vala">Vala</a>. While it is true that a more mainstream language would lower the barrier to entry for new first-party and third-party developers, Vala has proven to be a tremendously effective tool for our needs.</p>

<p>Vala is an object-oriented programming language developed by the <a rel="nofollow noopener noreferrer" target="_blank" href="https://www.gnome.org/">GNOME Foundation</a>, which was first released in 2006. Syntax-wise, Vala looks and acts very similarly to Java or C#, which makes it easy for new contributors to leverage their knowledge and experience from other languages. Vala’s clear syntax and tight coupling with the strongly-typed GObject system promotes highly readable, expressive, and maintainable code, while preventing entire classes of crashes and bugs.</p>

<p>Since Vala compiles to C (and then into binary), we gain access to a large number of bindings for libraries written in C. This is extremely important given the number of C libraries available for the Linux desktop. All of our desktop applications are written using the <a rel="nofollow noopener noreferrer" target="_blank" href="https://www.gtk.org/">GTK</a> toolkit, and many rely heavily on related GObject-based libraries, including Gee, WebKitGTK, VTE, and GStreamer. Bindings for dozens of popular GObject C libraries exist, and writing new ones is easy.</p>

<p>Before we adopted Vala, we wrote our desktop applications in Python. As both a language and a platform, Python made developing apps quick and easy. However, this ease of development came at a serious cost — performance, binding support, and maintainability became major pain points for us with Python. Worse, the slow and fragmented adoption of Python 3 over Python 2, particularly across Linux distributions, made packaging our apps and developer tools for different environments tedious and challenging. Vala’s native binaries have proven to be a better fit for us.</p>

<figure>
  <p><img src="https://cdn-images-1.medium.com/max/2000/1*HjaeSVLblDtdCwOkBR2xcA.png" alt="A Simple GTK Application in&nbsp;Vala"></p>
  <figcaption>A Simple GTK Application in&nbsp;Vala</figcaption>
</figure>

<p>Because Vala is developed by the same incredible folks who make GTK, integration between Vala and GTK is tight. Extending GTK with Vala has also proven successful. In fact, we’ve crafted our own set of widgets that build on and complement what GTK provides by default. This super-set of GTK, called <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/elementary/granite">Granite</a>, is at the heart of nearly every elementary application, and Vala’s excellent object-oriented inheritance system, among other sophisticated language features, have been key to our development.</p>

<p>Vala has excellent documentation, be it in the form of <a rel="nofollow noopener noreferrer" target="_blank" href="https://chebizarro.gitbooks.io/the-vala-tutorial/content/">tutorials</a>, <a rel="nofollow noopener noreferrer" target="_blank" href="https://wiki.gnome.org/Projects/Vala/Examples">code samples</a> or a <a rel="nofollow noopener noreferrer" target="_blank" href="https://valadoc.org/">very easy-to-use API Reference</a>. So if you’re interested in <a rel="nofollow noopener noreferrer" target="_blank" href="https://elementary.io/get-involved">hacking on our projects</a> (which we very much appreciate — we are always looking for new contributors!), or are planning to release fantastic third-party desktop applications for elementary OS, we can’t recommend Vala enough. Dive in!</p>

  </section>

  
<div>
  <hr>

  <h2>Thank You</h2>
  <p>Thanks to all of our supporters, backers, and customers! Your contributions make elementary possible. If you’d like to help build and improve elementary OS, don’t hesitate to <a rel="nofollow noopener noreferrer" target="_blank" href="https://elementary.io/get-involved" onclick="plausible('Link: Get Involved')">Get Involved</a>.</p>

  
</div>




</article></div>]]>
            </description>
            <link>https://blog.elementary.io/why-we-write-elementary-apps-in-vala/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25554949</guid>
            <pubDate>Sun, 27 Dec 2020 22:49:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[2-Acre Vertical Farm Run by AI and Robots Out-Produces 720-Acre Flat Farm]]>
            </title>
            <description>
<![CDATA[
Score 234 | Comments 233 (<a href="https://news.ycombinator.com/item?id=25554941">thread link</a>) | @wrycoder
<br/>
December 27, 2020 | https://www.intelligentliving.co/vertical-farm-out-produces-flat-farm/ | <a href="https://web.archive.org/web/*/https://www.intelligentliving.co/vertical-farm-out-produces-flat-farm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<p><a href="https://www.plenty.ag/" target="_blank" rel="noopener">Plenty</a> is an ag-tech startup in San Francisco, co-founded by Nate Storey, that is reinventing farms and farming. Storey, who is also the company’s chief science officer, says the future of farms is vertical and indoors because that way, the food can grow anywhere in the world, year-round; and the future of farms employ robots and AI to continually improve the quality of growth for fruits, vegetables, and herbs. Plenty does all these things and uses 95% less water and 99% less land because of it.</p>
<p>In recent years, farmers on flat farms have been using new tools for making farming better or easier. They’re using drones and robots to improve crop maintenance, while artificial intelligence is also on the rise, with over 1,600 startups and total investments reaching tens of billions of dollars. Plenty is one of those startups. However, flat farms still use a lot of water and land, while a Plenty vertical farm can produce the same quantity of fruits and vegetables as a 720-acre flat farm, but on only 2 acres!</p>
<p>Storey said:</p>
<blockquote><p>Vertical farming exists because we want to grow the world’s capacity for fresh fruits and vegetables, and we know it’s necessary.</p></blockquote>
<p><span><iframe width="1400" height="788" src="https://www.youtube.com/embed/GO0fRU46ZHc?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en-GB&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span></p>
<p>Plenty’s climate-controlled indoor farm has rows of plants growing vertically, hung from the ceiling. There are sun-mimicking LED lights shining on them, <a href="https://www.intelligentliving.co/tiny-smart-robots-kill-weeds/">robots</a> that move them around, and artificial intelligence (AI) managing all the variables of water, temperature, and light, and continually learning and optimizing how to grow bigger, faster, better crops. These futuristic features ensure every plant grows perfectly year-round. The conditions are so good that the farm produces 400 times more food per acre than an outdoor flat farm.</p>

<p>Storey said:</p>
<blockquote><p>400X greater yield per acre of ground is not just an incremental improvement, and using almost two orders of magnitude less water is also critical in a time of increasing environmental stress and climate uncertainty. All of these are truly game-changers, but they’re not the only goals.</p></blockquote>
<p>Another perk of vertical farming is locally produced food. The fruits and vegetables aren’t grown 1,000 miles away or more from a city; instead, at a warehouse nearby. Meaning, many transportation miles are eliminated, which is useful for reducing millions of tons of yearly CO2 emissions and prices for consumers. Imported fruits and vegetables are more expensive, so society’s most impoverished are at an extreme nutritional disadvantage. Vertical farms could solve this problem.</p>
<p>Storey said:</p>
<blockquote><p>Supply-chain breakdowns resulting from COVID-19 and natural disruptions like this year’s California wildfires demonstrate the need for a predictable and durable supply of products can only come from vertical farming.</p></blockquote>
<figure id="attachment_39422" aria-describedby="caption-attachment-39422"><img loading="lazy" src="https://i2.wp.com/www.intelligentliving.co/wp-content/uploads/2020/12/Reuters.jpg?resize=1024%2C576&amp;ssl=1" alt="2-Acre Vertical Farm Run By AI And Robots Out-Produces 720-Acre' Flat Farm'" width="1024" height="576" srcset="https://i2.wp.com/www.intelligentliving.co/wp-content/uploads/2020/12/Reuters.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i2.wp.com/www.intelligentliving.co/wp-content/uploads/2020/12/Reuters.jpg?resize=300%2C169&amp;ssl=1 300w, https://i2.wp.com/www.intelligentliving.co/wp-content/uploads/2020/12/Reuters.jpg?resize=768%2C432&amp;ssl=1 768w, https://i2.wp.com/www.intelligentliving.co/wp-content/uploads/2020/12/Reuters.jpg?resize=960%2C540&amp;ssl=1 960w, https://i2.wp.com/www.intelligentliving.co/wp-content/uploads/2020/12/Reuters.jpg?resize=711%2C400&amp;ssl=1 711w, https://i2.wp.com/www.intelligentliving.co/wp-content/uploads/2020/12/Reuters.jpg?resize=585%2C329&amp;ssl=1 585w, https://i2.wp.com/www.intelligentliving.co/wp-content/uploads/2020/12/Reuters.jpg?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"><figcaption id="caption-attachment-39422">(Credit: Reuters)</figcaption></figure>
<p>Plenty’s farms grow non-GMO crops and don’t use herbicides or pesticides. They recycle all water used, even capturing the evaporated water in the air. The flagship farm in San Francisco is using 100% renewable energy too.</p>
<p>Furthermore, all the packaging is 100% recyclable, made of recycled plastic, and specially designed to keep the food fresh longer to reduce food waste.</p>
<p>Storey told <a href="https://www.forbes.com/sites/johnkoetsier/2020/11/20/this-2-acre-vertical-farm-out-produces-750-acre-flat-farms/" target="_blank" rel="noopener">Forbes</a>:</p>
<blockquote><p>The future will be quite remarkable. And I think the size of the global fresh fruit and vegetable industry will be multiples of what it is today.</p></blockquote>
<p>Plenty has already received $400 million in investment capital from SoftBank, former Google chairman Eric Schmidt, and Amazon’s Jeff Bezos. It’s also struck a deal with Albertsons stores in California to supply 430 stores with fresh produce.</p>
<p>Ideally, the company will branch out, opening vertical farms across the country and beyond. There can never be too many places graced by better food growing with a less environmental cost.</p>
<p>Here’s a <a href="https://anchor.fm/techfirst/episodes/The-future-of-farms-is-vertical-400X-more-yield--95-less-water--99-less-space-emesrq/a-a3sf2o5" target="_blank" rel="noopener">TechFirst podcast</a> about the story behind Plenty:</p>

<p><span><iframe width="1400" height="788" src="https://www.youtube.com/embed/0uXdnjXIGjI?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en-GB&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span></p>
<!-- AI CONTENT END 2 -->
</div></div>]]>
            </description>
            <link>https://www.intelligentliving.co/vertical-farm-out-produces-flat-farm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25554941</guid>
            <pubDate>Sun, 27 Dec 2020 22:47:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Resolving the Time Paradox Implied by Functional Programs]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25554907">thread link</a>) | @jbmilgrom
<br/>
December 27, 2020 | https://softwarefordays.com/post/resolving-the-fp-time-paradox/ | <a href="https://web.archive.org/web/*/https://softwarefordays.com/post/resolving-the-fp-time-paradox/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      

<p>Excerpted from <a href="https://softwarefordays.com/post/functional-programming-and-identity-state-and-time/#resolving-the-time-paradox">Functional Programming and the Semantics of Change, State &amp; Time</a>.</p>
<blockquote>
<p>“No man can ever cross the same river twice.” Because what’s a river? I mean, we love this idea of objects; like there’s this thing that changes. Right? There’s no river. Right? There’s water there at one point-in-time. And another point-in-time, there’s other water there. — Rich Hickey, <a href="https://github.com/matthiasn/talk-transcripts/blob/master/Hickey_Rich/AreWeThereYet.md">Are We There Yet</a>, quoting Heraclitus.</p>
</blockquote>
<p>From the perspective of a user, a functional program may appear stateful. Interact with <a href="https://softwarefordays.com/post/functional-programming-and-identity-state-and-time/#stateful-functional-programs">the functional ATM program above</a> and notice the program remembering previous encounters. On the one hand, this is not surprising. We included an imperative layer to remember previous states. Instead of decomposing the state of the program into distinct objects, like <code>bankAccount</code> and <code>withdrawalAmount</code>, we created a single global object, the <code>store</code>. On the other hand, focusing on the “object” portion of the program betrays an object-oriented predisposition. The imperative piece of the program is merely a construct used to facilitate a computation based asynchronously on another. One can even imagine a programming language where such a construct is built into the language itself, hiding any imperative implementation from the programmer’s view. In fact, such a language exists that compiles to JavaScript.<sup><a href="#fn1" id="fnref1">[1]</a></sup> In other words, it is syntax, not semantics. The semantics of the program better align with the semantics of a recursive, iterative function, having state <code>S</code> at a discrete step <code>i</code> — run the functional ATM program with the output of the previous run to produce the input for the next.</p>
<p>That a program with a functional, stateless and timeless core can maintain state is surprising, to say the least. Look around the room, bus, park or wherever you find yourself reading this sentence, and you will likely identify “a collection of distinct objects,” such as dogs, people, and trees, “whose behaviors may change over time.” Look around the functional ATM program, on the other hand, and there are no identifiable objects to be found. Yet, the program appears to have state just like any other object in the room.</p>
<p>However, the ostensible “paradox” dissipates when the augmentation of our conception of time extends beyond the functional program to include the rest of our physical reality.</p>
<blockquote>
<p>One way to resolve this paradox is to realize that it is the user’s temporal existence that imposes state on the system. If the user could step back from the interaction and think in terms of streams of balances rather than individual transactions, the system would appear stateless — <a href="https://web.mit.edu/alexmv/6.037/sicp.pdf">SICP</a> Section 3.5.5</p>
</blockquote>
<p>Instead of viewing the <em>world</em> as the sum of its objects, each reflecting its latest state as time elapses, we may also think in terms of discrete state histories. We may interpret the dog at the park as moving in discrete steps <code>S(i)</code> to <code>S(i+1)</code>, just as we interpret the state of our functional program as moving in discrete steps <code>S(i)</code> to <code>S(i+1)</code>.</p>
<p>Consider video media. To movie scenes, we may attribute the same object-oriented semantics. Character and inanimate objects shift, interact and evolve as time elapses.</p>
<video id="metavideo" poster="https://softwarefordays.com/media/metavideoposter.gif" preload="none" width="480" controls="">
    <source src="https://softwarefordays.com/media/metavideo.mp4" type="video/mp4; codecs=&quot;avc1.42E01E, mp4a.40.2&quot;">
    <img src="https://softwarefordays.com/media/metavideo.mp4" title="Your browser does not support the mp4 video codec.">
</video>
<p>While playing the above video, for example, we may conclude that “a cat is dancing.” Yet, videos are comprised of static frames stitched together in a certain sequence at discrete time intervals. Each frame corresponds to a state of the video at a moment in time and the frames, taken together, a time-denominated series of discrete states. The media chosen above is intentionally meta. The video includes a TV animation of a scene mirrored by a flip-book<sup><a href="#fn2" id="fnref2">[2]</a></sup>, showing static frames strung together at discrete time intervals, which itself is mirrored by a flip-book in “real” life, showing static frames strung together at discrete time intervals. Take another step back to notice that the above gif media (or mp4 if your browser supports html5) being played on <em>your</em> computer is comprised of static frames, strung together at discrete time intervals.</p>
<p>There is nothing stopping us from taking another step back and interpreting the real world in which your computer currently sits as static frames, strung together at discrete time intervals. We <em>may</em> attribute normal object-oriented semantics to the above gif, concluding that “a cat is dancing.” However, we may also attribute functional semantics, concluding that “a cat has arms above its head on frame fᵢ.” At a park in the real world, we may conclude that “a dog is chasing a squirrel.” However, we may also conclude that “a dog is in the running motion behind a squirrel in the running motion on frame fᵢ.” In both cases, we may identify a time-series of states instead of objects that change over time. The functional programming paradigm can be coherently applied to world and program alike.</p>
<p>With a model for discrete time in mind, it is less surprising that functional programs can appear stateful. A user of the program may be viewed as a series of states, just like the program itself. A specific series of user states, for example,</p>
<pre><code>U₀: "Open up this blog post"<br>U₁: “Select 20 option”<br>U₂: “Click withdraw”<br>...<br>U(i): Uᵢ</code></pre>
<p>directly precipitate a series of program states:</p>
<pre><code>S₀: balance:100, amount:10<br>S₁: balance:100, amount:20<br>S₂: balance:80, amount:20<br>...<br>S(i): program(Sᵢ₋₁, Eᵢ)</code></pre>
<p>In both cases, pieces of static information may be listed, one <em>after</em> another. Moreover, both lists can be plotted along the same discrete timeline <code>i</code>. User interactions come in a certain order <code>U(i)</code>, triggering a run of the program function against the result of the previous run <code>S(i-1)</code> and event data <code>E(i)</code>, in order to produce <code>S(i)</code>. Our reality can be viewed as a time-series of states, just as it can be viewed as a collection of objects. Functional programming models a time-series of states, just as as object-oriented programming models objects. When the program and world <em>alike</em> can be viewed as “streams of information that flow in the system,” (<a href="https://web.mit.edu/alexmv/6.037/sicp.pdf">SICP</a> Section 3) the world can flow into the program, and the program back into the world.</p>
<hr>
<section>
<ol>
<li id="fn1"><p><a href="https://guide.elm-lang.org/">Elm</a> programs are trivially made to be stateful, notwithstanding the exclusive use of pure functions <em>and</em> the asynchrony of user interactions! This counter program</p>
<pre><code><span><span>import</span> Browser</span><span><br><span>import</span> Html <span>exposing</span> </span><span>(</span><span>Html</span><span>,</span> <span>button</span><span>,</span> <span>div</span><span>,</span> <span>text</span><span>)</span><br><span><span>import</span> Html.Events <span>exposing</span> </span><span>(</span><span>onClick</span><span>)</span><p><span>main</span> <span>=</span><br><span>Browser.sandbox</span> <span>{</span> <span>init</span> <span>=</span> <span>0</span><span>,</span> <span>update</span> <span>=</span> <span>update</span><span>,</span> <span>view</span> <span>=</span> <span>view</span> <span>}</span></p><p><span>type</span> <span>Msg</span> <span>=</span> <span>Increment</span> <span>|</span> <span>Decrement</span></p><p><span>update</span> <span>msg</span> <span>model</span> <span>=</span><br><span>case</span> <span>msg</span> <span>of</span><br><span>Increment</span> <span>-&gt;</span><br>  <span>model</span> <span>+</span> <span>1</span></p><p><span>Decrement</span> <span>-&gt;</span><br>  <span>model</span> <span>-</span> <span>1</span></p><p><span>view</span> <span>model</span> <span>=</span><br><span>div</span> <span>[</span><span>]</span><br><span>[</span> <span>button</span> <span>[</span> <span>onClick</span> <span>Decrement</span> <span>]</span> <span>[</span> <span>text</span> <span>"-"</span> <span>]</span><br><span>,</span> <span>div</span> <span>[</span><span>]</span> <span>[</span> <span>text</span> <span>(</span><span>String.fromInt</span> <span>model</span><span>)</span> <span>]</span><br><span>,</span> <span>button</span> <span>[</span> <span>onClick</span> <span>Increment</span> <span>]</span> <span>[</span> <span>text</span> <span>"+"</span> <span>]</span><br><span>]</span></p></code></pre>
<p>can be seen <a href="https://elm-lang.org/examples/buttons">here</a> tracking counter state, even though a user may of course click the counter buttons asynchronously. Like garbage collection in JavaScript, Elm hides any imperative code dedicated to communication between asynchronous scripts from the programmer’s view. <a href="#fnref1">↩︎</a></p>
</li>
<li id="fn2"><p>A flip-book <a href="https://softwareengineering.stackexchange.com/a/245409/369472">has been suggested</a> as a valuable mental model for state in functional programming <a href="#fnref2">↩︎</a></p>
</li>
</ol>
</section>




    </div></div>]]>
            </description>
            <link>https://softwarefordays.com/post/resolving-the-fp-time-paradox/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25554907</guid>
            <pubDate>Sun, 27 Dec 2020 22:43:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Back to the Future: Data Engineering Trends 2020 and Beyond]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25554883">thread link</a>) | @vananth22
<br/>
December 27, 2020 | https://www.dataengineeringweekly.com/p/back-to-the-future-data-engineering | <a href="https://web.archive.org/web/*/https://www.dataengineeringweekly.com/p/back-to-the-future-data-engineering">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Welcome to the 23rd edition of data engineering weekly. This week's edition is a yearend special edition where we will take a more in-depth look at the trends and emerging patterns in data engineering 2020. I divided the trends into the following categories.</p><ul><li><p>Data Infrastructure</p></li><li><p>Data Architecture</p></li><li><p>Data Management</p></li></ul><p>I hope you enjoy the data engineering trends 2020, and please share your thoughts in the comments.</p><p>I know this is a long article with so many links and references. TL;DR If I had to make a top 3 prediction for 2021 and beyond, here are they.</p><ol><li><p><em><strong>Metadata management will become mainstream. The data lineage, data quality, and data discovery tools will merge into a unified data management platform.</strong></em></p></li><li><p><em><strong>Data Mesh principles will get adopted more and drive a unified data management platform.</strong></em></p></li><li><p><em><strong>Lakehouse systems like Hudi, Iceberg, Deltalake will play a significant role in shaping the data engineering architecture.</strong></em></p></li></ol><p>Now, let’s go deep into each category and see the trends and predictions. Happy reading.</p><h2><em><strong><code>Managed Data Infrastructure &amp; Serverless Computing</code></strong></em></h2><p>In 2020, We saw the cloud platforms continue adopting the open-source data infrastructure solutions—the adoption growing from AWS's EMR, Google Cloud data proc, and Azure HDInsight to the recent AWS managed Airflow.</p><p><a href="https://aws.amazon.com/blogs/aws/introducing-amazon-managed-workflows-for-apache-airflow-mwaa/"><code>Introducing Amazon Managed Workflows for Apache Airflow (MWAA)</code></a></p><p>Though opinions differ on cloud platforms packaging the opensource, the cloud-managed infrastructure certainly carry many advantages for the consumers to quickly adopt complex infrastructure and focus on the business problems.</p><h4>2021 &amp; Beyond</h4><p>The rise of serverless architecture particularly very interesting trend in data engineering. The article summarizes the serverless data ops trend</p><p><a href="https://medium.com/swlh/dawn-of-dataops-can-we-build-a-100-serverless-etl-following-ci-cd-principles-3ca587ba1ec0"><code>Dawn of DataOps: Can We Build a 100% Serverless ETL Following CI/CD Principles?</code></a></p><p>Google Cloud launched a Google Cloud Workflow as a serverless orchestration engine.</p><p><a href="https://cloud.google.com/blog/products/application-development/get-to-know-google-cloud-workflows"><code>Get to know Workflows, Google Cloud’s serverless orchestration engine</code></a></p><blockquote><p><em><code>In 2021, It is an exciting space to watch how managed data infrastructure and the rise of serverless computing merge. </code></em></p></blockquote><h2><em><strong><code>Cloud datawarehouse</code></strong></em></h2><p>At the beginning of 2010, tightly coupled computing and storage is a strategy to run large scale data processing engines. 2019 is when the industry finally declared the old way of thinking data processing no longer working and acknowledge the cloud datawarehouse system is the way to go.</p><p><a href="https://medium.com/@acmurthy/hadoop-is-dead-long-live-hadoop-f22069b264ac"><code>Hadoop is Dead. Long live Hadoop.</code></a></p><p>In 2020, Snowflake's successful IPO reassured the cloud datawarehouse systems are the future. The S3 strong read-after-write consistency guarantee is a significant step in adopting object storage for the cloud datawarehouse system, if not already.</p><p><a href="https://aws.amazon.com/blogs/aws/amazon-s3-update-strong-read-after-write-consistency/"><code>Amazon S3 Update – Strong Read-After-Write Consistency</code></a></p><h4>2021 &amp; Beyond</h4><blockquote><p><em><code>The cloud datawarehouse system will continue to dominate and increase the adoption in 2021 and beyond. It will be interesting to watch how the cloud datawarehouse systems are tightly integrating with the data management systems.</code></em></p></blockquote><h2><em><strong><code>Cost Optimization</code></strong></em></h2><p>The cloud datawarehouse systems and the managed data infrastructure adds pressure on optimizing the cost of operating the datawarehouse systems. Netflix writes about cost optimization strategies for its data warehouse system.</p><p><a href="https://netflixtechblog.com/byte-down-making-netflixs-data-infrastructure-cost-effective-fee7b3235032"><code>Byte Down: Making Netflix’s Data Infrastructure Cost-Effective</code></a></p><p>At the same time, the GPU accelerated workload can provide a strategic business advantage. Pinterest and NVIDIA shared how Pinterest using GPU acceleration for visual search.</p><p><a href="https://blogs.nvidia.com/blog/2020/12/16/pinterest-trains-visual-search-faster-nvidia-gpus/"><code>Pinterest Trains Visual Search Faster with Optimized Architecture on NVIDIA GPUs </code></a></p><h4>2021 &amp; Beyond</h4><p>I added cost optimization as a separate section since cost optimization is often an afterthought. The unpredictability of the object storage engines egress and storage cost, handling cold vs. hot data &amp; the need for specialized hardware for a specific workload will be the norm of 2021 and beyond. </p><p>Alluxio is one solution that I am aware of providing tiered data processing capabilities, though not tuned for cost optimization.</p><p><a href="https://hackernoon.com/accelerate-spark-and-hive-jobs-on-aws-s3-by-10x-with-alluxio-as-a-tiered-storage-solution-5c3s3yes"><code>Accelerate Spark and Hive Jobs on AWS S3 by 10x with Alluxio as a Tiered Storage Solution</code></a></p><blockquote><p><em><code>It will be interesting to see how data processing frameworks like Spark, Flink adopting cost optimization as the first class optimization model, cache frequently used datasets and aware of specialized workloads. </code></em></p></blockquote><h2><em><strong><code>Lakehouse</code></strong></em></h2><p>The separation of computing and storage and the scalable object storage like S3 increased the adoption of data lake principles in early 2019. One of the challenges remains to adopt object storage on the lack of transaction guarantees. The support for ACID transactions, data versioning, auditing, indexing, caching, and query optimization are vital characteristics to build large scale data systems. </p><p>In 2020, We noticed the emerging lakehouse frameworks like DataBricks Delta Lake, Apache Hudi, and Apache Iceberg.</p><p><a href="http://cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf"><code>Lakehouse: A New Generation of Open Platforms that Unify Data Warehousing and Advanced Analytics</code></a></p><p>Adobe shared its Iceberg adoption story <a href="https://medium.com/adobetech/iceberg-at-adobe-88cf1950e866"><code>Iceberg at Adobe</code></a></p><p>Uber writes about its journey with Apache Hudi, and EMR now offers Hudi part of EMR</p><p><a href="https://eng.uber.com/apache-hudi-graduation/"><code>Building a Large-scale Transactional Data Lake at Uber Using Apache Hudi</code></a></p><p><a href="https://aws.amazon.com/blogs/big-data/apply-record-level-changes-from-relational-databases-to-amazon-s3-data-lake-using-apache-hudi-on-amazon-emr-and-aws-database-migration-service/"><code>Apply record level changes from relational databases to Amazon S3 data lake using Apache Hudi on Amazon EMR and AWS Database Migration Service</code></a></p><h4>2021 &amp; Beyond</h4><p><a href="https://github.com/apache/iceberg/milestone/7"><code>Icerbeg’s version 2</code></a> to support row level upsert is another interesting development to watch in 2021.</p><blockquote><p><em><code>The Lakehouse systems continue to mature and will play a major role in shaping the data engineering architecture. It will be interesting to watch how lakehouse complement or compete with the likes of Snowflake and Redshift.</code></em></p></blockquote><h2><em><strong><code>Lambda vs. Kappa vs. Lambda-less</code></strong></em></h2><p>Managing the real-time and batch computing and providing one integrated dataset view remains the main challenge in data processing.</p><p>Pinterest writes about some of the complication of Lambda Architecture and its migration journey to the Kappa architecture</p><p><a href="https://medium.com/pinterest-engineering/pinterest-visual-signals-infrastructure-evolution-from-lambda-to-kappa-architecture-f8f58b127d98"><code>Pinterest Visual Signals Infrastructure: Evolution from Lambda to Kappa Architecture</code></a></p><p>LinkedIn took an interesting approach of Lambda-Less model</p><p><a href="https://engineering.linkedin.com/blog/2020/lambda-to-lambda-less-architecture"><code>From Lambda to Lambda-less: Lessons learned</code></a></p><h4>2021 &amp; Beyond</h4><blockquote><p><em><code>There is no real-time vs. batch, it is all about the window that we process, but that is easier to say than the reality. In 2021 and beyond, I hope we will have a more innovative solution in this space.</code></em></p></blockquote><p>Apache Beam is an excellent attempt to bring the model closer. The development of Spark Streaming and the recent Apache Flink’s&nbsp;<a href="https://flink.apache.org/2020/12/15/pipelined-region-sheduling.html"><code>batch computing support</code></a>&nbsp;are some of the trends to watch.</p><h2><em><strong><code>Streaming SQL Engines &amp; OLAP Engines</code></strong></em></h2><p>Real-time computing and insights are critical for many businesses. Event sourcing is a well-established design pattern, and that brings the question of the decade. Can we join streams and compute business metrics or feed everything into OLAP databases and query it?</p><p>Confluent writes about the KSQL materialization process.</p><p><a href="https://www.confluent.io/blog/how-real-time-materialized-views-work-with-ksqldb/"><code>How Real-Time Materialized Views Work with ksqlDB, Animated</code></a></p><p>Materialize writes about joins in detail</p><p><a href="https://materialize.com/joins-in-materialize/"><code>Joins in Materialize</code></a></p><p>On the OLAP engine space Druid, Click House and Pinot adding multiple OLAP features and improves the operational efficiency. Apache Pinot is an impressive OLAP engine gaining momentum in 2020. Uber shared its experience operating Apache Pinot at scale.</p><p><a href="https://eng.uber.com/operating-apache-pinot/"><code>Operating Apache Pinot @ Uber Scale</code></a></p><h4>2021 &amp; Beyond</h4><p>Though streaming SQL engines and OLAP engines solve similar problems, I think there is a fundamental difference. Streaming SQL engines are good for pre-defined analytics, write once, and run workloads continuously. OLAP engines are good for interactive analytics when analytical queries are unknown while building the datasets.</p><blockquote><p><em><code>In 2021 and beyond I expect tighter integration among the Streaming SQL like KSQL and OLAP engines like Pinot.</code></em></p></blockquote><h2><em><strong><code>Data Quality &amp; Metadata Management</code></strong></em></h2><p>The poor data quality costs an estimated $3.1 trillion per year in the USA alone, equating to 16.5% of the GDP.!! The data quality is critical for developing a data pipeline, and your ML model is as efficient as the quality of the data.</p><p><a href="https://medium.com/@expectgreatdata/why-data-quality-is-key-to-successful-ml-ops-a18d6e373ca9"><code>Why data quality is key to successful ML Ops</code></a></p><p>We’ve seen both Microsoft and Airbnb writes about how data quality effort improved its org decision-making process.</p><p><a href="https://medium.com/data-science-at-microsoft/partnering-for-data-quality-dc9123557f8b"><code>Partnering for data quality</code></a></p><p><a href="https://medium.com/airbnb-engineering/data-quality-at-airbnb-e582465f3ef7"><code>Data Quality at Airbnb - Part 1 — Rebuilding at Scale</code></a></p><p><a href="https://medium.com/airbnb-engineering/data-quality-at-airbnb-870d03080469"><code>Data Quality at Airbnb - Part 2 — A New Gold Standard</code></a></p><p>We have seen multiple tools and systems emerged on Data Quality, and this is a pretty good summarization f the data quality ecosystem.</p><p><a href="https://medium.com/memory-leak/data-quality-a-primer-f6a945915511"><code>Data Quality — A Primer</code></a></p><p> One of the most remarkable trends of 2020 in data engineering is the emerging tooling and infrastructure to manage metadata at scale. I shared some of my thoughts about the importance of metadata in the past.</p><p>In 2020, we have seen many great articles from companies across the industry that shared their data discovery and metadata management. Data Engineering Weekly dedicated a week’s edition to focus on metadata management.</p><p><a href="https://www.dataengineeringweekly.com/p/data-engineering-weekly-21-metadata"><code>Data Engineering Weekly #21: Metadata Edition</code></a></p><p>LinkedIn organized&nbsp;<a href="https://metadataday2020.splashthat.com/"><code>Metadata Day 2020 - Metaspeak Meetup</code></a>&nbsp;as an attempt to unify people working on metadata management. Datakin announced the&nbsp;<a href="https://datakin.com/2020/12/18/introducing-openlineage/"><code>Open Lineage initiative</code></a><code>&nbsp;</code>to standardize the data lineage and the discovery effects.</p><h4>2021 &amp; Beyond</h4><p>I’ve included the data quality and the metadata management in the same section for a reason. In 2020 we saw isolated solutions to solve data lineage, data quality, and data discovery. Data Pipeline is a complex inter-dependent creation process of one dataset from another. Data lineage and data quality are two tightly coupled metadata systems that power the data discovery system.</p><blockquote><p><em><code>In 2021 and beyond, I expect all three problem spaces to merge and emerge as one unified data management platform that can provide data quality, lineage, and discovery service out of the box.</code></em></p></blockquote><h2><em><strong><code>Data Mesh</code></strong></em></h2><p>In 2020, Data Mesh emerged as de-facto principles for scale data management as the organization grows. Thoughtworks writes about the data mesh principles in the past.</p><p><a href="https://martinfowler.com/articles/data-monolith-to-mesh.html"><code>How to Move Beyond a Monolithic Data Lake to a Distributed Data Mesh</code></a></p><p><a href="https://martinfowler.com/articles/data-mesh-principles.html"><code>Data Mesh Principles and Logical Architecture </code></a></p><p>We saw number of companies started to adopt the data mesh principles and wrote …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.dataengineeringweekly.com/p/back-to-the-future-data-engineering">https://www.dataengineeringweekly.com/p/back-to-the-future-data-engineering</a></em></p>]]>
            </description>
            <link>https://www.dataengineeringweekly.com/p/back-to-the-future-data-engineering</link>
            <guid isPermaLink="false">hacker-news-small-sites-25554883</guid>
            <pubDate>Sun, 27 Dec 2020 22:39:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A gentle intro to MVC frameworks]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25554784">thread link</a>) | @musikele
<br/>
December 27, 2020 | https://michelenasti.com/2020/12/27/a-guide-to-mvc-frameworks.html | <a href="https://web.archive.org/web/*/https://michelenasti.com/2020/12/27/a-guide-to-mvc-frameworks.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
			
			<p>In the last few years Iâ€™ve worked or played with a bunch of MVC frameworks: <strong>Laravel</strong>, <strong>Ruby on Rails</strong>, <strong>Django</strong>, and <strong>AdonisJS</strong>.</p>

<p>With two of them (Laravel and Dango) I also have some experience in production environments. Laravel is the one I know most.</p>

<p>So, what do they all share in common? Whatâ€™s the difference between them and Express, Flask, Sinatra? This article will try to explain the philosophy around those tools.</p>



<p>The web is not only a matter of serving the right file to the user; you usually also want to:</p>

<ul>
  <li>pass arguments, values, cookies, more generally data with the request;</li>
  <li>customize the output: not only in the format (plain html, or json, or â€¦ xml if you are kink enough), but also the data in it (if you are a logged user you may want to see more things than an anonymous user; etc)</li>
  <li>handle security, that is nowadays a first class citizen</li>
  <li>handle authorization, with one of the multiple authorization schemes hat have appeared in the last few years</li>
  <li>be able to scale: in the number of concurrent users, in the size of the handled data, and in the organization of the code itself.</li>
</ul>

<p>The key point here is,<strong>people got tired of solving the same problem over and over and invented a set of tools that standardized/simplified the developerâ€™s job</strong>, allowing to focus more on the business logic than on the details.</p>

<h2 id="so-whats-this-mvc-stuff">So whatâ€™s this MVC stuff?</h2>

<p>M stands for <strong>Model</strong>, and means the data that is manipulated by the framework. In current web frameworks the Model usually corresponds to classes that map to a database (E.g. <code>Person</code> class is linked to the <code>persons</code> table).</p>

<p>V stands for <strong>View</strong> and means the way the data is presented to the user. In my small dev life Iâ€™ve seen many ways to represent this part: JSON responses for example, or plain HTML. Usually, modern MVC tools offer a template system so you can write the <em>products.html</em> page once and then inject the data to be displayed.</p>

<p>C is for <strong>Controller</strong>, the part that will do the dirty job. When a request arrives, the controller will validate the input, fetch the database, apply business rules, and pass it to the right view. Or it will trigger some other systems. <em>This is the part youâ€™ll write in some programming language</em>.</p>

<h2 id="opinionated-vs-unopinionated">Opinionated vs Unopinionated</h2>

<p>Instead of referring to MVC vs Non-MVC frameworks, I think <strong>the best classification is between <em>Opinionated</em> vs <em>Unopinionated</em></strong>. Opinionated frameworks are those that are presented in this article; they give to the dev a lot of pre-made tools with sensible defaults that will do all the heavy lifting. Sad to say, but the developerâ€™s job is sometimes just to configure these tools to make them work as needed.</p>

<p>With <em>unopinionated frameworks</em>, you are alone with a tool that handles requests and responses. You may need to write all the tools you need, and end up creating a framework yourself. An example: you may need to decide how to access the database, or handle authenticationâ€¦ In this category I see <strong>Express</strong>, <strong>Flask</strong>, <strong>Sinatra</strong>.</p>

<h2 id="the-router-in-mvc">The router in MVC</h2>

<p>Almost all the opinionated frameworks expose a functionality called <em>router</em>. Similarly to phisical routers, these pieces of software will understand the URL of a request and will route to the right controller. One can create a route for <code>/products/123</code> and the router will send this request to <code>ProductController</code> calling the appropriate function and passing the parameter <code>123</code> as argument. Isnâ€™t this lovely?</p>

<p>So when I have to debug an application I usually start from here; I try to understand where the router configuration is (usually in <code>routes.php</code> or <code>urls.py</code>), and where the route Iâ€™m interested will point, and follow it.</p>

<h2 id="the-orms">The ORMs</h2>

<p><strong>ORM</strong> stands for <em>Object Relational Mapping</em> and is a framework that allows to express sql queries using class constructs. Almost every major framework ships an ORM that is perfect for simple and sometimes elaborated queries. Basically the Model classes will extend a base class that contains all the boilerplate to read from the DB table and perform queries. For example, in Laravel:</p>

<pre><code>&lt;?php

use Illuminate\Database\Eloquent\Model;

class Flight extends Model
{
    //
}
</code></pre>

<p>The class <code>Model</code> is the base class that will give to <code>Flight</code> all the fancy methods, like:</p>

<pre><code>// Retrieve a model by its primary key...
$flight = Flight::find(1);

// Retrieve the first model matching the query constraints...
$flight = Flight::where('active', 1)-&gt;first();
</code></pre>

<h2 id="template-systems">Template systems</h2>

<p>Almost every MVC framework use a template system, so you can create HTML files with lower effort, even though itâ€™s nowadays very easy to just respond with JSON. Usually it only depends on what you return from the controller.</p>

<h2 id="command-line-utilities">Command line utilities</h2>

<p>Laravel has <strong>artisan</strong>, Python has <strong>manage.py</strong>, Rails has <strong>rake</strong>. These three command line utilities do <em>a lot</em>. They can:</p>

<ul>
  <li><strong>create and execute migrations</strong>, that are operations that will change the structure of your database. You may create a migration to add a new table or change a column., for example. You can also rollback if something doesnâ€™t go as planned. All of that without writing SQLs directly on the DB server. We use this feature on a daily basis during development.</li>
  <li>Likewise the migrations, sometimes you only want to add data in tables, like the values of a select box. This process is called <strong>seeding</strong>.</li>
  <li>Put the server on <strong>maintenance mode</strong> and resume</li>
  <li><strong>create boilerplate</strong> (models, controllers, viewsâ€¦) from command line, so that you only have to fill those generated files</li>
  <li><strong>execute tests</strong></li>
  <li><strong>create custom commands</strong>; for example, we usually create commands for operations that should be triggered by cron, or long-lasting batch commands.</li>
  <li>â€¦and much more! Every tool exposes more or less capabilities.</li>
</ul>



<p>I cannot stress out how important is documentation when using those frameworks. Itâ€™s impossible to remember all the possible commands and configurations. You end up searching through docs, and if those are well written, you donâ€™t need to pay a visit on stack overflow right away. If you write an MVC tool and it doesnâ€™t have an <em>excellent</em> documentation, with a lot of examples, it will probably not be used by anyone.</p>

<h2 id="standardization">Standardization</h2>

<p>Another thing that pays off is that, no matter whoâ€™ll work on what, all the code will look the same, and will be organized the same way. This has some value, since those kind of systems must be maintained over a span of several years, while the average dev only works only 2 years in the same company :)</p>

<h2 id="conclusions">Conclusions</h2>

<p>I hope I donâ€™t have expressed concepts that are too trivial for the average reader; these are the basic info I wish somebody told me at the time.</p>
 
			
			


			<p>Tags: 
    
    
    <a href="https://michelenasti.com/tags/#mvc">mvc</a>
     â€¢ 
    
    <a href="https://michelenasti.com/tags/#web">web</a>
     â€¢ 
    
    <a href="https://michelenasti.com/tags/#laravel">laravel</a>
     â€¢ 
    
    <a href="https://michelenasti.com/tags/#django">django</a>
     â€¢ 
    
    <a href="https://michelenasti.com/tags/#rails">rails</a>
     â€¢ 
    
    <a href="https://michelenasti.com/tags/#artisan">artisan</a>
     â€¢ 
    
    <a href="https://michelenasti.com/tags/#orm">orm</a>
     â€¢ 
    
    <a href="https://michelenasti.com/tags/#documentation">documentation</a>
    
    
</p>

			<h4>Related Posts:</h4>


		</section></div>]]>
            </description>
            <link>https://michelenasti.com/2020/12/27/a-guide-to-mvc-frameworks.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25554784</guid>
            <pubDate>Sun, 27 Dec 2020 22:22:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Recaf – A modern Java bytecode editor]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25554497">thread link</a>) | @segfaultbuserr
<br/>
December 27, 2020 | https://www.coley.software/Recaf/ | <a href="https://web.archive.org/web/*/https://www.coley.software/Recaf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <div id="content">
        <h3>What is Recaf?</h3>
        <p>Recaf is an open-source Java bytecode editor that simplifies the process of editing compiled Java applications. To make things easier Recaf abstracts away much of the internal class file format. Difficult tasks such as updating stack-frames are done automatically. Along with additional features to assist in the process of editing classes, Recaf is the most feature-rich free bytecode editor available.</p>
        
        <h3>Useful Information</h3>
        <p>While Recaf makes bytecode editing a more simple process it does not mean you should dive head-first into editing compiled Java applications without understanding some basic programming concepts and the Java class file architecture. Here are some references for these topics:</p>
        <ul>
            <li><a href="https://docs.oracle.com/javase/specs/jvms/se14/html/jvms-2.html">Specification: Chapter 2. The Structure of the Java Virtual Machine</a></li>
            <li><a href="https://docs.oracle.com/javase/specs/jvms/se14/html/jvms-4.html">Specification: Chapter 4. The class File Format </a></li>
            <li><a href="https://blog.takipi.com/jvm-architecture-101-get-to-know-your-virtual-machine/">JVM Architecture 101: Get to Know Your Virtual Machine</a></li>
            <li>Java instructions:
                <ul>
                    <li><a href="https://www.coley.software/Recaf/doc-instructions.html">Recaf's simplified instruction format</a></li>
                    <li><a href="https://docs.oracle.com/javase/specs/jvms/se14/html/jvms-6.html">Standard Java instructions</a></li>
                </ul>
            </li>
        </ul>
        <h3>Download &amp; Building</h3>
        <p>Downloadable jar binaries are provided through Github's <a href="https://github.com/Col-E/Recaf/releases">release page</a>.<br>Alternatively you can build from the source by cloning <i>(or downloading)</i> the repository and using maven to build the executable.</p>
        <h3>Requirements</h3>
        <p>Recaf requires Java 8 to run but it is recommended you use Java 11 or higher. Some features require additional setup in Java 8 whereas the process is automatic in Java 11 and above</p>
        <h3>Usage Guide &amp; More Information</h3>
        <ul>
            <li><a href="https://www.coley.software/Recaf/documentation.html">Documentation &amp; usage</a></li>
        </ul>	
        <h3>Contact &amp; Support</h3>
        <p>For reporting bugs and suggesting new features please use the github repo's <a href="https://github.com/Col-E/Recaf/issues">issue page</a> and submit a new issue. For other inquiries, or if you'd just like to chat, join the discord server here: <a href="https://discord.gg/Bya5HaA">discord.gg/Bya5HaA</a></p>
    </div>
</article></div>]]>
            </description>
            <link>https://www.coley.software/Recaf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25554497</guid>
            <pubDate>Sun, 27 Dec 2020 21:40:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hyperbezier Pen Tool]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25554205">thread link</a>) | @raphlinus
<br/>
December 27, 2020 | https://www.cmyr.net/blog/hyperbezier.html | <a href="https://web.archive.org/web/*/https://www.cmyr.net/blog/hyperbezier.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <article>
        <h2 id="introduction">Introduction</h2>

<p>This post introduces a new model for a path drawing (pen) tool, with a particular focus on font design.</p>

<p>Although this tool works much like familiar pen tools (which are based on the manipulation of <a href="https://en.wikipedia.org/wiki/B%C3%A9zier_curve">Bézier curves</a>), it is actually based on a new family of two-control-point curves, which we’ve been calling the <em>hyperbezier</em>.</p>

<p>This work is still in its early stages, and the demo below is quite barebones; my goal here is to get a simple version of this tool into the hands of designers and design-tool makers, so that more people can start to play around and evaluate it.</p>

<h4 id="contents">Contents</h4>



<h3 id="-background--motivation"><a id="background"></a> Background &amp; motivation</h3>

<p>The basis of this tool is a new mathematical model for fitting a curve to a set of points; that work was done earlier in the year by my collaborator <a href="https://raphlinus.github.io/">Raph Levien</a>. For the past year or so Raph has been excitedly talking to me about about things like <em>splines</em> and <em>G2 continuity</em> and the elegance of the <em>Euler spiral</em>, and I have for the most part been smiling politely and nodding. In the last few weeks however I have started trying to implement a simple drawing app around his new model, and the excitement is catching: this new tool feels like the first I have used that is a compelling alternative to traditional Bézier-curve based drawing tools.</p>

<p>It is likely that if you have ever used a computer drawing application then you have, at some point, used a <em>pen tool</em>: a tool that allows you to place a small number of points, which are then connected with a series of curves, the exact curvature being a function of the position of the points.</p>

<p>Tools like this— which take some fixed number of points and calculate a curve based on them— are called <em>splines</em>. If you are curious about the topic (particularly in the context of interactive design tools), a very accessible overview is Raph’s <a href="https://levien.com/phd/thesis.pdf">dissertation</a>; I won’t go into too much detail here, except to say that Raph has been revisiting this subject recently, and the result is the <a href="https://github.com/linebender/spline"><em>hyperbezier spline</em></a>. Like traditional (cubic) Bézier paths, a hyperbezier path is comprised of segments, each defined by two <em>on-curve</em> and two <em>off-curve</em> (or <em>control</em>) points; the curve passes through the two on-curve points, and the curvature itself is determined by the position of the two off-curve points.</p>

<p><img id="simple-cubic" src="https://www.cmyr.net/assets/hyperbez/hyperbez-simple-cubic1.png" alt="A simple cubic Bézier"></p>
<p>A Bézier path, consisting of two segments</p>

<p>If you’re generally curious about Béziers, <a href="https://pomax.github.io/bezierinfo/">A Primer on Béziers Curves</a> is an excellent resource. For our purposes it is enough to note that splines based on direct manipulation of Bézier control points (most pen tools) provide a high degree of control, but are difficult to use well. In particular, it can be tricky to maintain consistent curvature between adjoining segments of a path, which can lead to a ‘lumpy’ look; the following example is  contrived, but in practice consistently getting smooth feeling curves with Béziers is challenging.</p>


<p>A lumpy path. Mouseover to see the filled outline.</p>

<h3 id="-the-hyperbezier"><a id="hyperbezier"></a> The hyperbezier</h3>

<p>The core idea of the hyperbezier is the use of <em>auto-points</em>. These control points are adjusted automatically by the tool in order to maintain a smooth curve between neighbouring curve segments.</p>

<p>Let’s look at an example. With the path below you can drag points around, and double-click points to toggle their type.</p>

<p>The two green squares are <em>corner</em> points; curve segments that join at these points are allowed to change direction sharply. The two blue circles are <em>smooth</em> points; changing the curve on one side of the point can cause changes in the <em>auto</em> points (and hence the curve) on the other side.</p>

<p>The auto-points are indicated with dashed lines and terminating ‘x’s. The manual control points are indicated with solid lines, and terminating ‘o’s.</p>




<h5 id="playing-around">Playing around</h5>
<p>To get a better understanding of the spline’s behaviour, here are some things to try <em>(this requires a mouse)</em>:</p>
<ul>
  <li><em>double-click the bottom point to make it smooth</em>. When this point is smooth, the auto points beside it are adjusted so that the two curve segments join smoothly.</li>
  <li><a href="#" onclick="reloadHeart();return false;">reset,</a> or double-click the bottom point to turn it back into a corner. Now <em>doubleclick the top-left smooth point</em>. Making the top-left point a corner will replace the curve between them with a straight line. Two adjacent corners with only auto-points between them will always form a straight line, because a line is maximally smooth.
    <ul>
      <li>You should notice two small ‘x’s on this line. <em>Drag one of these auto points somewhere to position it manually</em>. You will notice that the remaining auto-point is repositioned as you drag.</li>
      <li><em>Drag the other auto-point</em>. With both control points positioned manually, and with corners at either end, you have full control of this segment.</li>
    </ul>
  </li>
</ul>

<!--(TK: SIMPLIFY ME, JUST INTRODUCE AUTO POINTS)The principal goal of the hyperbezier is to make it easier to maintain consistent curvature between adjoining segments of a path. This is achieved by letting the designer choose to have certain control points positioned automatically. These *auto-points* are adjusted in response to changes in adjoining segments so as to form a [smooth][smoothness] curve.-->

<!--In addition, on-curve points can be either *smooth* points or *corners*; if a point is smooth (marked by a green circle) then any auto points on either side of that point will be adjusted to maintain curvature with the segment on the other side. If a point is a corner (marked by a blue square) then the segment on one side of the point is not influenced by the curvature on the other side.-->

<!--Moving any on-curve point can cause subtle changes to the position of multiple auto-points; the example below is interactive, and you can drag the various points around, or toggle their type. Notice how the behaviour of the auto points changes if you toggle a nearby on-curve point between smooth and corner;

<iframe class="embedded-toy"
    title="Interactive hyperbezier toy"
    width="400"
    height="400"
    src="https://www.cmyr.net/misc/hyperbez/#AAE=eJxVzL0JgDAUBOCcYO8IjvImsFTQMmIpuEGmcJtARnlDpA0ELpCfq46P42BKZjNGkxWWeMhUddk_argeQWPdbrL6t2f3n-TV2WHdXQNsyEpvEhM=">
</iframe>
<div class = "img-caption">This demo requires a fairly recent browser</div>
-->

<h3 id="-the-toy-pen-tool"><a id="the-toy"></a> The toy pen tool</h3>

<p>If you’re curious to try drawing with this tool, <a href="https://cmyr.net/misc/hyperbez">There is a simple web app available here</a> (and embedded below).</p>




<p>Below are some examples of letterforms I’ve sketched in the process of getting this working. These may offend the actual type designers in the room, but I hope they will be useful illustrations.</p>

<p><a href="https://www.cmyr.net/misc/hyperbez/#AAE=eJxlkj3OgUEUhWe-fHqFBSiVSuVdwhuFKBQjQUQk3viPv4y8oqBRKpVKpdISLMESLIG4J8xhmkmenDn33Hvn3-hJma_jhvK6pSJ_H-rbStNdsQEWiP2E8GWhONsnHFhb-6YZ83WkrjIXhwnMCKVK5BktFd-aYsJgCXCV1Nc1gnU42ApqxhGwaxC-o6S0gLWXK3Dc0zvnYTqi19mB4vyMsEfTY0_YYGTHJeE0kkVrwjG8y1s2KSo-sfrWQuCERmeqivecxNUU3-c8jFixm_L8Pzu09veP4dEhCTf8_BZqyTF3aOq8IVzAhs-sDqyNtRJWfQBl00gu" onclick="return reloadMain(event, 'g');"><img src="https://www.cmyr.net/assets/hyperbez/hyper-g-small-fill.png"></a>
<a href="https://www.cmyr.net/misc/hyperbez/#AAE=eJxt0TsKwkAQBuDZWGiZRrEKuYB9OucGRmJhlzQmNiq-QVCCBLFQsLbKUXKUHMDC0lJkJji7ZJssH39mZncbYKyOCUWEtBmhJXhKijEqVZnLOM4Q_jgh7F4Ewpwwugp8rAk9TjqvIHxaK-z1B05bq1kuKZnvBdoHQnchG5240VYmK8xQiTPlXLV1R_gx5SMu-7nRF_wzbexMHN1jdGUf_8i_JAIL7lLsahBibaL3hjmgiYxBcail0xlXDrV0mRCnelq8q7gu1QSxvvatM50=" onclick="return reloadMain(event, 'h');"><img src="https://www.cmyr.net/assets/hyperbez/hyper-h-small-fill.png"></a>
<a href="https://www.cmyr.net/misc/hyperbez/#AAE=eJxd0rEKwjAQBuCkk2PHjn2EPkJeQQQpqNCCYEWQIiJ0KFTbKuri6NhH6CPkERwdHR0zOgq5K_b3liMfuUtyxBEUnviLYqxsNpVyftrErAclLUu79JfEjz3laE35VijRq25T4qSrpjA1cYj8ZDYZsF5x7xzY3RD7C-CgJNYz4OjMPEe-MofA9wtxMQL-dLuHwIpZxDAjl49UPCtzohykMCOdc_UU38HPe22BQ76Z2uHojsReCdxmxO8aL5wQu7hbT7hJBdxExANs0vsvUgqMLzuHP6M=" onclick="return reloadMain(event, 's');"><img src="https://www.cmyr.net/assets/hyperbez/hyper-s-small-fill.png"></a>
<a href="https://www.cmyr.net/misc/hyperbez/#AAE=eJx1kquOAkEQRXs2K1auXNnrECv3A8pssjggEAgKSEgIgWQAA8EM4TEISHj8AgI5EjkSySfwCUgkj6qmq0jTpjInt27Vne539ep8PwMowL3qCrxZGuSRxkXwPANLdYSQAo9pdROxyjCtgccaKKY99hAHabLAhv8xWVSpi77jhuiGOeG0WCBaIfa7bIENwcNYaEdrxF-hwDPCUSgGJhZO_Ev4U5oklnbkY48fA_si8XaKWCWx6gnWoMV6PybODKfQOf5MeHetDwt_YCHTdgk__QYYOhKkhs4EQRux-qNKN659Nv52gbezlwn8tnO8sYx4ApWzkGnjrNOiVHYkMFB3ZFr79K2WzgVbDlNT" onclick="return reloadMain(event, 'm');"><img src="https://www.cmyr.net/assets/hyperbez/hyper-m-small-fill.png"></a>
<a href="https://www.cmyr.net/misc/hyperbez/#AAE=eJxt0b0OgjAQB_CrA2FkMXH0EXyEDg5OBI1x0YGZOIBGIxETjHysPgKTs4s7j8BkHImLr-Fwld6BXUh-XP-9a3uAy4DWKj2J36UUHdtLaNDyGxQ9vd85Ihdrxr6vY8Wfs0D0od3JDP_CXHcCG20k3Twr9hhXO2R5kEAYYuR7xKqlCjFTxq8EubqwkEmKPEgYXyNkJ_uFPN_GOLiFEqLis32cWDYEWO2G5FZqr0HooMWbG6qAIiO1I4VWTlLBVtPlpDK29XaSWq7UbCl9LIW1y0eYIscLHkEeT0V8Ab6RQUE=" onclick="return reloadMain(event, 'r');"><img src="https://www.cmyr.net/assets/hyperbez/hyper-r-small-fill.png"></a></p>
<p>Some example paths, drawn in the tool.</p>

<!--. This is very much a demo; the idea is to explore the interaction model, and to get a sense for how it feels to draw with the tool, compared to the standard Bézier curves used in most pen tools. Spoiler: I think it feels *really good*. You [can play around with it yourself][hypertoy]; it is pretty rough around the edges, but it works.-->

<h4 id="-using-the-toy-pen-tool"><a id="toy-guide"></a> Using the toy pen tool</h4>

<p>The toy is very rough: you have a select and a pen tool, but there are no rulers or measurement tools, no transforms, no ability to select multiple points. The pen works much like the familiar Bézier pen:</p>

<p>General:</p>

<ul>
  <li><code>V</code> key sets selection (arrow) tool, <code>P</code> key sets pen tool</li>
  <li>holding the space bar hides UI and shows filled path</li>
  <li>the current drawing is stored as part of the URL; copy this somewhere to “save”</li>
</ul>

<p>Pen tool:</p>

<ul>
  <li>click to add a line segment ending in a corner point</li>
  <li>alt + click to add an automatic curve segment ending in a smooth point</li>
  <li>click + drag to add a curve segment ending in a smooth point, with a manual control point</li>
  <li>click on a line segment to insert a point there; alt makes it a smooth point</li>
  <li>alt + click on any existing point to toggle the type of that point</li>
</ul>

<p>Select tool:</p>

<ul>
  <li>drag a control auto-point to move it, converting it to a manual point if necessary</li>
  <li>double-click will toggle an on-curve point between smooth and corner</li>
  <li>alt + click on a line segment to add two auto points</li>
  <li>deleting an off-curve point makes that curve segment into a line segment</li>
  <li>arrow keys nudge the current selection by 1 px; adding shift makes it 10px, and ctrl/cmd makes it 100px.</li>
  <li>shift + any of the above moves all of the points in the current outline (I’m sorry)</li>
</ul>

<h3 id="-next-steps"><a id="next-steps"></a> Next steps</h3>

<p>The code for the spline, including the demo, is <a href="https://github.com/linebender/spline">open source and available on github</a>.</p>

<p>The intent of this demo is twofold: firstly to test out how the curve feels to use, and to start playing around with the UX of the pen tool, and secondly to share this research with the broader community of designers and design-tool creators. Although this work is quite rough, my personal feeling is that this spline shows tremendous promise. Anecdotally, as a mere casual user of design tools, I find it <em>significantly</em> easier to make good looking curves with the hyperbezier than I do with traditional Bézier pen tools.</p>

<p>Perhaps the biggest question will be figuring out the best interaction model: what set of mouse clicks, key presses and modifiers the user issues in order to control the state of the points. This has been a challenge for other new splines; the interaction model we use with Béziers is <a href="https://youtu.be/sT8Y7o-zsVw?t=68">familiar and long-established</a>, and people (especially graphic designers) are deeply comfortable with it. The interaction model used here for the hyperbezier is intentionally designed to feel similar to these existing tools, but other interaction models may be worth exploring.</p>

<p>In the coming weeks I hope to integrating the spline into <a href="https://github.com/linebender/runebender">Runebender</a>, a font editor, which will provide a much richer editing experience and will let us better explore how well the spline is suited to real-world use. In addition, Raph intends to do a more detailed writeup of the spline itself and the associated math, which derives both from the earlier Spiro spline and the classic model of elastica under tension.</p>

<p>If you’re curious about the spline, there are more details in the <a href="https://github.com/linebender/spline">github repo</a>; if you have questions you can open an issue there, ask them in our <a href="https://xi.zulipchat.com/">zulip chat server</a> or reach out on <a href="https://twitter.com/cmyr">on twitter</a>.</p>

<h3 id="thanks">Thanks</h3>

<p>This work was funded by <a href="https://fonts.google.com/about">Google Fonts</a>.</p>

<!--- this is particularly useful for fonts
* fix bug with click-drag
* rebuild example
* revisit "next steps": we want to encourage other folks to adopt this
* explicitly mention that all of this is open source
-->


      </article>

    </div></div>]]>
            </description>
            <link>https://www.cmyr.net/blog/hyperbezier.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25554205</guid>
            <pubDate>Sun, 27 Dec 2020 20:59:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Heart Attack Survival Strongly Linked to Socioeconomic Background]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25554171">thread link</a>) | @bookofjoe
<br/>
December 27, 2020 | https://smosa.com/heart-attack-survival-strongly-linked-to-socioeconomic-background/ | <a href="https://web.archive.org/web/*/https://smosa.com/heart-attack-survival-strongly-linked-to-socioeconomic-background/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

					<!-- .post-header -->


					<div>
						<p>In patients with low socioeconomic status, heart resuscitation is heavily delayed and, according to a recent European Heart Journal report last week, victims of cardiac arrest in hospitals are less likely to recover.</p><p>Researchers analyzed data from the national Swedish cardiopulmonary resuscitation register for 24,217 cardiac arrests in Swedish hospitals between 2005 and 2018 in patients 40 and older. They collected socioeconomic data on patients from a second database and used the highest rate of education and annual income as a socioeconomic status (SES) measure.</p><p>"The good news is that for most of the cardiac arrest cases in this study, socioeconomic status didn't seem to matter." said Professor Jens Agerström of Linnaeus University in Kalmar and Växjö, Sweden, "Nevertheless, there seems to be a significant number of deaths that can still be attributed to socioeconomic factors, even when we take account of things that could affect the results such as gender, age, ethnicity, other health conditions, cause of the cardiac arrest, and the specific hospital providing the treatment."</p><p>Patients with higher SES were slightly better controlled for heart rhythm prior to cardiac arrest. This may partly explain the survival disparities. Most unrecovered combinations between patient SES and the findings studied are minimal. A disparity in SES-related survival chances of around 21 percent shouldn't be overlooked, authors say.</p><figure><img src="https://smosa.com/content/images/2020/12/ehaa954f3.png" alt="" srcset="https://smosa.com/content/images/size/w600/2020/12/ehaa954f3.png 600w, https://smosa.com/content/images/size/w1000/2020/12/ehaa954f3.png 1000w, https://smosa.com/content/images/size/w1600/2020/12/ehaa954f3.png 1600w, https://smosa.com/content/images/2020/12/ehaa954f3.png 1949w" sizes="(min-width: 720px) 720px"><figcaption>Credit: European Heart Journal</figcaption></figure><p>The study investigated several outcomes but looking at survival for 30 days after the cardiac arrest, approximately 280 people in 1000 from a low socioeconomic background will survive; however, for patients from a high socioeconomic background approximately 320 people may survive to 30 days.</p><p>The goal of the new retrospective registry was to investigate SES inequalities in IHCA care and survival. The study looked at significant demographic, clinical, and social problems.</p><figure><img src="https://smosa.com/content/images/2020/12/Screen-Shot-2020-12-22-at-4.33.11-PM.png" alt="" srcset="https://smosa.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-22-at-4.33.11-PM.png 600w, https://smosa.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-22-at-4.33.11-PM.png 1000w, https://smosa.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-22-at-4.33.11-PM.png 1600w, https://smosa.com/content/images/2020/12/Screen-Shot-2020-12-22-at-4.33.11-PM.png 2136w" sizes="(min-width: 720px) 720px"></figure><p>People with lower SES are less likely to survive a spontaneous heart arrest outside the hospital. Patients in higher-income hospitals and in school are slightly less likely. More likely to recover before hospital discharge and after heart arrest for 30 days.</p><p>"After having studied discrimination in the labour market for many years with Dr. Magnus Carlsson, one of my co-authors," said Prof. Agerström, "we thought that a natural next step would be to look at the health care system and possible treatment discrimination, which is much less researched. My own medical visits also played a role, as I got the impression that the staff often became more thorough after they had asked me about my profession."</p>
					</div><!-- .post-content -->

					<!-- .post-footer -->


				</article></div>]]>
            </description>
            <link>https://smosa.com/heart-attack-survival-strongly-linked-to-socioeconomic-background/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25554171</guid>
            <pubDate>Sun, 27 Dec 2020 20:55:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Short-Range vs. Long-Range Wireless Power Transmission]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25554015">thread link</a>) | @NaregK
<br/>
December 27, 2020 | https://emrod.energy/short-range-vs-long-range-wireless-power-transmission/ | <a href="https://web.archive.org/web/*/https://emrod.energy/short-range-vs-long-range-wireless-power-transmission/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Long-range wireless power transmission is a concept that has been a long time coming since Nikola Tesla obtained a patent for the Tesla coil over 120 years ago.&nbsp;&nbsp;</p>



<p>In the recent decade, wireless power has become more of a familiar term, with companies such as Powerbyproxi and WiTricity leading the way with innovation in short-range wireless technology. That is, the ability to transmit electrical power over short distances (up to a few metres), primarily to charge consumer devices like mobile phones. This technology enables us to charge devices without requiring wires within short range, e.g. at home or by driving up to an electric vehicle charging station.</p>



<p>The next evolution in freeing humanity from the restrictions of where wires can go is the ability to transmit large amounts of power over large distances. Instead of charging devices, long-range wireless transmission<strong> </strong>technology<strong> </strong>will allow us to power households, communities and send large quantities of power to places where it is too hard and expensive to reach using wire infrastructure. This is the technology Emrod is working on, which will support the uptake of sustainable energy and decentralizing electric grids.&nbsp;</p>



<p>In this article, we make a comparison between short-range and long-range power transmission, including the difference in technology and use cases.</p>



<p>First, let’s start with getting clear on what wireless power transmission is.</p>



<h3><strong>What is wireless power transmission?</strong></h3>



<p>Wireless power transmission is the act of delivering meaningful amounts of energy without moving or employing mass between transmitter and receiver. Electromagnetic fields convey power across space. It can replace the need for wires and batteries to provide a more convenient, mobile and safer way to provide energy.&nbsp;</p>



<p><em>According to early history, Heinrich Hertz was the first to prove the existence of electromagnetic waves. Hence the name “hertz” as the unit for frequency.</em></p>



<p>The difference between short and long-range power transmission can clearly be defined by the distance across which the power is transmitted. However, what determines the capabilities of these different types of technology?</p>



<figure><img loading="lazy" width="1024" height="576" src="https://secureservercdn.net/166.62.108.196/u1v.9ad.myftpupload.com/wp-content/uploads/2020/12/Short-Vs-Long-Thumbnail.003-1024x576.jpeg" alt="" srcset="https://secureservercdn.net/166.62.108.196/u1v.9ad.myftpupload.com/wp-content/uploads/2020/12/Short-Vs-Long-Thumbnail.003-1024x576.jpeg 1024w, https://secureservercdn.net/166.62.108.196/u1v.9ad.myftpupload.com/wp-content/uploads/2020/12/Short-Vs-Long-Thumbnail.003-300x169.jpeg 300w, https://secureservercdn.net/166.62.108.196/u1v.9ad.myftpupload.com/wp-content/uploads/2020/12/Short-Vs-Long-Thumbnail.003-768x432.jpeg 768w, https://secureservercdn.net/166.62.108.196/u1v.9ad.myftpupload.com/wp-content/uploads/2020/12/Short-Vs-Long-Thumbnail.003-1536x864.jpeg 1536w, https://secureservercdn.net/166.62.108.196/u1v.9ad.myftpupload.com/wp-content/uploads/2020/12/Short-Vs-Long-Thumbnail.003.jpeg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h3><strong>Short-range wireless power</strong></h3>



<p>Short-range is typically power transmission within centimetres and metres. The most common wireless power transmission technique is with Inductive Power Transfer, where power is transferred utilizing a magnetic field using inductive coupling between two coils of wire.&nbsp;</p>



<p>Examples of short-range power transmission by this definition include powering devices wirelessly within a house or building and charging electric cars using a resonant magnetic induction pad on the ground.</p>



<h3><strong>Long-range wireless power transmission</strong></h3>



<p>Long-range is typically power transmission of 100’s of metres or across kilometres. One technique of power transmission is using antennas to send electromagnetic beams, like microwaves or lasers. The limitation with using inductive coupling power transmission in long-range is that the magnetic field decays quite rapidly when the distance between the transmitter and receiver is increased. Therefore, electromagnetic beaming is more appropriate for this reason.&nbsp;</p>



<p>Long-range power transmission with antennas can be categorised into Near-Field or Far-Field. In the near-field, one can observe plane waves with very little to no beam divergence. Conversely, in the far-field there is significant beam divergence, and inverse squared decay for the power density with distance, something which is not observed in the near-field.&nbsp;</p>



<p>For Emrod’s purpose, we work in the near-field to produce a collimated beam with negligible loss.&nbsp;</p>



<p><br>The use cases for long-range transmission include beaming power from space to earth, charging unmanned aerial vehicles (without requiring the UAV to return to a base for charging) and transmitting power across difficult terrain instead of using wires, which is the problem we are solving at Emrod. Learn more about the use cases for Emrod’s technology <a href="https://emrod.energy/use-cases/">here.</a></p>



<h3><strong>Why are these new developments in long-range technology significant?</strong></h3>



<figure><img loading="lazy" width="1024" height="576" src="https://secureservercdn.net/166.62.108.196/u1v.9ad.myftpupload.com/wp-content/uploads/2020/12/Emrod-long-range-wireless-energy-transmission.png" alt="" srcset="https://secureservercdn.net/166.62.108.196/u1v.9ad.myftpupload.com/wp-content/uploads/2020/12/Emrod-long-range-wireless-energy-transmission.png 1024w, https://secureservercdn.net/166.62.108.196/u1v.9ad.myftpupload.com/wp-content/uploads/2020/12/Emrod-long-range-wireless-energy-transmission-300x169.png 300w, https://secureservercdn.net/166.62.108.196/u1v.9ad.myftpupload.com/wp-content/uploads/2020/12/Emrod-long-range-wireless-energy-transmission-768x432.png 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>For energy to be useful, it needs to move from where it is generated to where it is required. Energy is similar to communication in this sense. For communication services to be useful, they must be able to transmit a message from one person to another. At the moment, our methods for generating energy are dependent on the locations that can be accessed economically using wired infrastructure (lines and pylons, and underwater cables). Many of the best places to generate renewable energy are hard to reach areas, for example high up on hills or mountains or offshore locations, where there is lots of wind, and it’s well out of the way of people.&nbsp;</p>



<p>On the other hand, the people who have access to energy are dependent on the economics of connecting the household or community to a power source. Many communities and dwellings do not have reliable access to electricity because they are in remote, hard to access areas where it is not economically viable to put in and maintain power lines or cables.&nbsp;</p>



<p>By reducing the costs and ease of installing and maintaining the infrastructure that transmits power from one place to another, we can open up our access to and provision of energy.</p>



<h3><strong>Emrod’s long-range wireless technology use cases</strong></h3>



<p>At Emrod, we have developed technology that allows power to be transmitted over many kilometres.&nbsp; It is the worlds first long-range wireless power transmission technology that is commercially viable. We use passive relays to achieve power transmission over a long distance, without the losses that would otherwise make long distance transmissions inefficient and uneconomical for commercial purposes.&nbsp;</p>



<p>The application of Emrod’s technology is wide-reaching, but we are primarily focused on working with energy distribution companies and organizations driving sustainable energy and decentralized grid projects.&nbsp;</p>



<p>Emrod’s wireless system can provide a cost-effective solution for the transmission of power across terrain where it is difficult to lay and maintain power lines and cables. For example across forests or waterways, to alleviate right of passage issues or reduce the ecological impact of pylons, and to provide back up systems when power lines fail, for example, outages or disaster relief.&nbsp;</p>



<p>You can read more about the common use cases for Emrod’s technology on the <a href="https://emrod.energy/use-cases/">Use Cases page of our website</a>.</p>



<h3><strong>Conclusion</strong></h3>



<p>The early modern development of wireless transmission technology used magnetic induction charging pads, which required contact and careful alignment of the device, e.g. a phone. Subsequently, technology developed to charge smartphones and other devices from meters away that works like a strong WiFi. This technology has been considered long-range, in comparison to the previous wireless technology, which required the transmitting and receiving devices to be in contact with one another. We have now entered into the next era of wireless technology, which is the transmission of larger amounts of power over kilometres. It is an exciting next step towards Nikola Tesla’s vision of power everywhere.</p>
</div></div>]]>
            </description>
            <link>https://emrod.energy/short-range-vs-long-range-wireless-power-transmission/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25554015</guid>
            <pubDate>Sun, 27 Dec 2020 20:31:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WASM-STREAM, a virtual stage for digital artists]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25553839">thread link</a>) | @timdaub
<br/>
December 27, 2020 | https://timdaub.github.io/2020/12/27/wasm-stream/ | <a href="https://web.archive.org/web/*/https://timdaub.github.io/2020/12/27/wasm-stream/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p><strong>TL;DR:</strong> I built a <a target="_blank" rel="noopener" href="https://audio.daubenschuetz.de/assets/">synthesizer</a> that allows streaming directly to an <a target="_blank" rel="noopener" href="https://audio.daubenschuetz.de/">internet radio stream</a>. Below is the live stream:</p>
<p><audio controls="" autoplay="" preload="auto">
<source src="https://audio.daubenschuetz.de/stream.ogg" type="audio/ogg">
<source src="https://audio.daubenschuetz.de/stream" type="audio/mpeg">
<p>Your browser does not support the audio element. </p></audio></p>
<hr>
<p>It's that time between Christmas and new year again, where you can usually find me at Leipzig's Congress Zentrum on my computer hacking away. It's chaos congress time. Given this year's pandemic, the "37c3" however, was moved to the internet and renamed to <a target="_blank" rel="noopener" href="https://rc3.world/">"rc3", the Remote Chaos Communication Congress</a>.</p>
<p>Earlier this month, the iconic congress build-up started. This time around, building up didn't involve moving heavy crates of mate tea around. Instead, it meant that everyone started designing, drawing, and building their assembly maps for the "rc3.world". A <a target="_blank" rel="noopener" href="https://events.ccc.de/2020/09/04/rc3-remote-chaos-experience/">2D virtual space</a> that's supposed to replace this year's lack of physical space.</p>
<p>The rc3.world software is a fork of <a target="_blank" rel="noopener" href="https://workadventu.re/">workadventu.re</a>, a 2D game simulating a virtual work environment with avatars. Within this 2D map of the virtual congress, the organizers invited all assemblies to build their own spaces. And so, as the build-up for <a target="_blank" rel="noopener" href="https://www.dist0rtion.com/">Social Dist0rtion Protocol</a> assembly began, I had an idea for a project.</p>
<figure>
<img src="https://timdaub.github.io/assets/images/wasm-synth-screenshot.png" alt=""><figcaption><a target="_blank" rel="noopener" href="https://audio.daubenschuetz.de/assets/">wasm-synth</a>, the project I launched at last year's c3</figcaption>
</figure>
<p>At last year's congress in Leipzig, I had launched <a target="_blank" rel="noopener" href="https://audio.daubenschuetz.de/assets/">wasm-synth</a>, a synthesizer built in WebAssembly. Naturally, this time I was eager to take the project to the next stage. Hence, roughly a week ago, I started to work on a new project called "WASM-STREAM" - an extension to wasm-synth.</p>
<p><a target="_blank" rel="noopener" href="https://github.com/social-dist0rtion-protocol/wasm-stream">WASM-STREAM</a> is a virtual stage for digital artists. Using WASM-STREAM, an artist can broadcast their play with wasm-synth to an internet radio stream. More importantly, though, this means that they can take the stage on the <a target="_blank" rel="noopener" href="https://www.dist0rtion.com/">Social Dist0rtion Protocol</a>'s assembly and jam away to a virtually present audience.</p>
<figure>
<img src="https://timdaub.github.io/assets/images/wasm-stream.png" alt=""><figcaption>Social Dist0rtion Protocol's dance floor in the rc3.world</figcaption>
</figure>
<p>So how did I build it?</p>
<h2 id="a-first-little-demo">A First Little Demo</h2>
<p><a target="_blank" rel="noopener" href="https://audio.daubenschuetz.de/assets/">wasm-synth</a> is a project that I built deliberately to showcase the power of the web. At the beginning of the year, I wrote <a href="https://timdaub.github.io/2020/02/19/wasm-synth/">a blog post</a> outlining its technical details. It's using the <code>AudioWorklet</code> and some WebAssembly-transpiled code to render audio in real-time in the user's browser.</p>
<p>Now, workadventure, the software ccc uses to run their rc3.world, is also built on the web and allows embedding audio streams. So I thought, why not take the audio generated in wasm-synth and stream it to everyone in the rc3 world.</p>
<p>In a way, it sounds like not that big of a deal to build an audio streaming client within a website. But remember that a browser's networking ability is limited. While we've come a long way from the <code>XMLRequest</code> API to <code>fetch</code>, <code>WebSocket</code> and <code>WebRTC</code>, these concepts only allow talking upstream if their authors deliberately built their upstream application for supporting them.</p>
<p>Naive as I Am, I started by deploying <a target="_blank" rel="noopener" href="https://icecast.org/">icecast2</a> to a small Hetzner instance. I configured an authorized mount point that allows a streamer to connect using client software. Then I looked for a way to stream audio directly to icecast from a browser. And found... nothing.</p>
<p>Well, I did find something. It's called <a target="_blank" rel="noopener" href="https://webcast.github.io/">webcast</a>, and it's a <a target="_blank" rel="noopener" href="https://github.com/webcast/webcast.js/blob/master/SPECS.md">WebSocket-based subprotocol</a> that allows sending binary audio data between a client and a server. In their <a target="_blank" rel="noopener" href="https://github.com/webcast/webcast.js#server">README.md</a>, the authors also mention webcast's compatibility with <a target="_blank" rel="noopener" href="https://www.liquidsoap.info/">liquidsoap</a>, a DSL for audio stream processing.</p>
<p>So my first attempt at plugging these things together involved encoding the <code>Float32Array</code> data from the <code>AudioWorklet</code> into an mp3 stream using <a target="_blank" rel="noopener" href="https://github.com/toots/shine/">libshine</a> (that has a wasm JavaScript package) and then sending it to a <a target="_blank" rel="noopener" href="https://www.liquidsoap.info/doc-dev/harbor.html">liquidsoap "harbor"</a> via webcast. Liqidsoap would then convert the mp3 stream to ogg-vorbis, make it stereo, and forward it to the icecast server.</p>
<p>And, to my surprise, it worked. When I hit some keys on the wasm-synth, they got encoded and sent to the audio stream. With a bit of delay, I heard what I had just played. Cool!</p>
<p>Anyways, with my small little demo, I was galvanized and motivated enough to spend more time building something that would work for the congress.</p>
<h2 id="the-wasm-stream-architecture">The WASM-STREAM Architecture</h2>
<p>Ultimately, liquidsoap was not well-suited for my purpose. I also quickly realized that all I had to do was build a proxy between the <a target="_blank" rel="noopener" href="https://gist.github.com/ePirat/adc3b8ba00d85b7e3870">icecast protocol</a> and the <a target="_blank" rel="noopener" href="https://github.com/webcast/webcast.js/blob/master/SPECS.md">webcast protocol</a>. And that's what I ended up building. A small <a target="_blank" rel="noopener" href="https://github.com/webcast/webcast.js/blob/master/SPECS.md">JavaScript application</a> implementing two protocols. It listens for incoming WebSocket connections and calls icecast with a loooooonng PUT request to establish a stream.</p>
<p>WASM-STREAM itself doesn't do any encoding. It can, however, route an <code>audio/ogg</code> or an <code>audio/mpeg</code> stream from webcast to icecast. The encoding from WAV to mp3 takes place on the user's device already when the play the synthesizer.</p>
<h2 id="how-to-use-wasm-stream">How To Use WASM-STREAM</h2>
<p>Whether you have a ticket to rc3 or not, you can tune into the stream at <a target="_blank" rel="noopener" href="https://audio.daubenschuetz.de/stream">https://audio.daubenschuetz.de/stream</a>. It's an mp3-encoded stream, meaning it won't work in all browsers equally (Firefox works natively; Chrome et al. only support ogg/vorbis natively). If it doesn't, try a desktop application like iTunes or VLC.</p>
<p>The stream is continuously online. But if you don't hear anything then that's because nobody is currently playing the <a target="_blank" rel="noopener" href="https://audio.daubenschuetz.de/assets/">WASM-SYNTH</a>.</p>
<p>Finally, you're able to "dance" on the Social Dist0rtion Protocol's assembly dance floor. The rc3 orga was nice enough to allow us streaming audio on our map. <a target="_blank" rel="noopener" href="https://rc3.world/rc3/room/93840a8f-88f7-4f11-bb61-68800c4d4962/">Click here</a> to visit us directly on the rc3.world map.</p>

  </div></div>]]>
            </description>
            <link>https://timdaub.github.io/2020/12/27/wasm-stream/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25553839</guid>
            <pubDate>Sun, 27 Dec 2020 20:07:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Lucerne, a Twitter experience tailored to me]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25553815">thread link</a>) | @thesephist
<br/>
December 27, 2020 | https://thesephist.com/posts/lucerne/ | <a href="https://web.archive.org/web/*/https://thesephist.com/posts/lucerne/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>Over the last week, I’ve been working on <a href="https://github.com/thesephist/lucerne">Lucerne</a>, a Twitter “reader” app built to fit my personal needs from Twitter. It’s been an interesting exercise in <a href="https://thesephist.com/posts/tools/">building a tool around workflows</a>, so I wanted to tell you the story of how the design came to be, and what I’ve noticed using Lucerne for my daily escapades into the Twittersphere.</p>
<p><img src="https://thesephist.com/img/lucerne.png" alt="Lucerne in action"></p>
<p>Like many of my personal tools, Lucerne is built with my <a href="https://dotink.co/">Ink programming language</a> on the backend and my <a href="https://github.com/thesephist/torus">Torus</a> UI library on the frontend. It’s made just for me at the moment, but given the interest I’ve gotten about Lucerne online, I might make a version open for anyone to use.</p>
<h2 id="designing-myself-a-better-twitter">Designing myself a better Twitter</h2>
<p>For me, Twitter serves two purposes. First, it’s a <em>learning tool</em>. There are lots of smart folks talking to each other and sharing what they’re thinking about on Twitter from software to economics to writing, and I can find on Twitter opinions or perspectives I can’t find on blogs or books. Second, it’s a <em>place for me to share whatever I’m working on</em> on my blog or on my side projects with my audience. Lucerne is designed around these two primary workflows: learning and sharing.</p>
<p>Twitter’s main user interface, the algorithmic timeline, is bad for using Twitter as a learning tool. It feels like sticking a straw into a firehouse and hoping you’ll suck out enough interesting insights to be worth the effort. I wanted a better way for me to discover and keep track of interesting conversations happening on Twitter about any topic. Twitter does provide decent tools for me to share my work online – things like scheduled tweets, analytics, notifications, and search – but they’re not in one place, so I wanted to consolidate these tools.</p>
<p><img src="https://thesephist.com/img/lucerne-timeline.jpg" alt="A timeline view in Lucerne"></p>
<p>With these two goals in mind, I also wanted Lucerne to be a tool that could <a href="https://thesephist.com/posts/ivy/">grow with me as I used it</a>, so I could mold my experience of Twitter around what I found to be most useful to me over time. More than other tools, Twitter feels organic and constantly changing. I didn’t want to have to bake in all the tools and dials I might ever want to use from the get-go. Instead, I wanted to be able to stumble into interesting use cases as I used Lucerne over time.</p>
<p><img src="https://thesephist.com/img/lucerne-querybar.jpg" alt="Performing a search in Lucerne"></p>
<p>To make it possible to grow Lucerne as a tool gradually around my use cases like this, Lucerne is designed primarily around one important idea: <strong>filtered searches saved as “channels”</strong>. Feeding from the firehose of conversations on Twitter, a “channel” is a small filtered stream of tweets defined by a particular search query. Here are some examples of useful filters.</p>
<ul>
<li>“tweets between A and B about #topic” – <code>(from:A OR from:B) #topic</code></li>
<li>“tweets about abc.com with more than 100 likes” – <code>url:abc.com min_faves:100</code></li>
<li>“tweets by A that include images, but exclude retweets” – <code>from:A filter:images -filter:retweets</code></li>
</ul>
<p>With Lucerne, I can search for interesting conversations happening on Twitter by experimenting with these filters. When any filter seems particular useful, I can save it to check again later, by adding it to the left sidebar with a name. As I use the app, I end up curating an ever-changing personalized collection of these channels in my sidebar that provide multiple different views onto the firehose of Twitter.</p>
<p>“But Linus,” I hear you saying, “you can search and save them as timelines on Twitter’s app and Tweetdeck.” Yes, you’re right, and most of the search filters Lucerne uses are also available on Twitter. But the important thing about Lucerne isn’t just that you can search, but that <strong>playing with filters and saving the good ones is the primary user interface</strong>. On Twitter, you might search once or twice to find something useful, but you’re <em>mostly</em> interacting with a single timeline passively. With Lucerne, most of my use is exploring and adding to a curated list of filters, and exploration and consumption are one and the same activity. As I’ll explain later from my personal experience, this makes a big difference in how much I can get out of Twitter.</p>
<p>I think the most important design lessons in Lucerne is what I <em>didn’t</em> do: I could have made a list of features that I might have wanted in the beginning, and baked it all into the app. Features like “follow specific threads”, “see top tweets from a particular user”, “follow hashtags”, or “hide retweets from the timeline.” But instead of adding a million settings and toggles, I found what I would consider to be the “atoms”, the common building blocks, of all of these use cases, and baked it into the core of the app instead. All these use cases above can be performed just as easily as filtered searches, and because these filters can be saved and referenced later, Lucerne can grow around my exact use cases <em>as I continue using it</em>. I don’t have to design for all my use cases from the start. This is what I mean when I say <a href="https://thesephist.com/posts/ivy/">we need to design tools to grow with us</a>.</p>
<p>In addition to this main idea of channels, Lucerne has a few other design considerations to improve how Twitter works for me. All the engagement stats I care about are present in a single screen, so I don’t have to annoyingly load five different pages every time, but they’re out of the way of the main “timeline” view, because I don’t want them in my face all the time. There’s a small pane on the right showing me my most recent new followers, which is sometimes useful when I see someone particularly interesting and want to reach back out to them. This also saves me a few clicks every time. Lastly, I intentionally didn’t implement <em>infinite scrolling</em>, in lieu of a simple “load more” button. This makes endlessly scrolling a conscious enough action for me that I end up wasting less time scrolling through my timeline. It goes without saying, all of these experiences are also much better because I don’t serve myself ads in between my tweets. My timeline feels cleaner.</p>
<h2 id="how-im-using-lucerne">How I’m using Lucerne</h2>
<p>I reached an “MVP” stage with Lucerne a few days ago, and since then, I’ve used Lucerne more and Twitter’s website less for browsing through Twitter. Lucerne isn’t meant to be a Twitter <em>replacement</em>. Twitter’s web app is still great for writing and following threads, for example, and I don’t want to have to re-create something that’s already fine for my use. But for my two main workflows of <em>learning</em> and <em>tracking my progress</em> on Twitter, Lucerne works better for me.</p>
<p>The biggest change I’ve noticed from using the client is that it turns Twitter from a consumption experience into an exploratory experience. Instead of drinking from a firehose through a straw, the firehose feeds into an evolving castle of infinite fountains, and my job is to look around the castle for the fountains of information that seem more interesting or insightful. For the first time in a long time, I feel like I’m pulling from the firehose of Twitter instead of constantly poking straws into the stream to see what I luck out with.</p>
<p>The real fun of using Lucerne to explore Twitter isn’t just reading tweets in a timeline, but poking around in the <a href="https://en.wikipedia.org/wiki/The_Library_of_Babel">infinite library</a> that Twitter sometimes feels like, collecting the interesting streams of information into my pocket.</p>
<p>Here are a few use cases I stumbled into while using Lucerne that I otherwise couldn’t have.</p>
<p><strong>Following interesting threads.</strong> I often stumble into interesting threads of tweets that I want to track somehow. While using Lucerne, I ran into one tweet about <a href="https://twitter.com/geoffreylitt">@geoffreylitt</a> building a Twitter browser extension called Twemex, and another thread by <a href="https://twitter.com/TZhongg">@TZhongg</a> asking for book recommendations. Normally, I would probably just bookmark it and never check it again, but with Lucerne, I just saved filters for “replies to this tweet” as channels in my sidebar, and I’ve checked them regularly since to find interesting project updates and book recommendations.</p>
<p><strong>Following an account’s tweets on a topic.</strong> <a href="https://twitter.com/Noahpinion">@Noahpinion</a> is one of those accounts that have a lot of interesting ideas to share covering a huge range of topics. Sometimes about foreign policy, sometimes about fiscal policy and economics, sometimes about China. I wanted to be able to follow “just tweets about this account on Japan”, for example, and I could do this trivially by setting up a channel <code>from:Noahpinion Japan</code>.</p>
<p><img src="https://thesephist.com/img/lucerne-usercard.jpg" alt="Lucerne looking at tweets by @devonzuegel"></p>
<p><strong>Following an aesthetic.</strong> I noticed recently that a lot of <a href="https://twitter.com/devonzuegel">@devonzuegel</a>’s tweets about urban design either contain interesting quotes from books or inspiring historical photographs. I follow her, but thought it would be nice to have a separate channel to just keep track of these. So I made a filter for <code>from:devonzuegel filter:images</code>, for “tweets containing images from @devonzuegel” which I’ve been enjoying checking once every one or two days. Through this channel, I also discovered a couple of other accounts that share photographs of urban design that I otherwise would have missed.</p>
<p><strong>“Following” high-noise accounts without following.</strong> There are a few accounts, like @naval, @david_perell, or @paulg that occasionally tweet really interesting ideas, but whom I don’t follow because there’s a lot of noise. With Lucerne, I could create channels like <code>from:david_perell -filter:replies min_faves:100</code> to “follow” the most popular tweets from these accounts without actually following them into my home timeline. I’ve found this so useful that I added a “top” button to profile cards that lets me one-click search a filter for “popular tweets from this person”, which is much more helpful than what Twitter’s web app gets you on a profile page, which are just the latest tweets they happened to have sent.</p>
<p>Over time, I think my curated list of channels is going to become an interesting index into my own interests, perspective, and information consumption habits, which I find a really cool idea. I’m excited about how Lucerne can help me use Twitter to learn and share better going forward, and I"m also curious about how I could apply this idea of “tools that grow as you use it” to other parts of my life, like the web browser or my email experience.</p>
<p>And because I know you’re asking: while I don’t think I’m going to make this current version of Lucerne open for public …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thesephist.com/posts/lucerne/">https://thesephist.com/posts/lucerne/</a></em></p>]]>
            </description>
            <link>https://thesephist.com/posts/lucerne/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25553815</guid>
            <pubDate>Sun, 27 Dec 2020 20:03:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Golang basics – writing unit tests (2017)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25553779">thread link</a>) | @alexellisuk
<br/>
December 27, 2020 | https://blog.alexellis.io/golang-writing-unit-tests/ | <a href="https://web.archive.org/web/*/https://blog.alexellis.io/golang-writing-unit-tests/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section>
            <div><p>In the previous post titled <a href="http://blog.alexellis.io/golang-json-api-client/">"Grab JSON from an API"</a> we explored how to interact with a HTTP client and parse JSON. This post is a continuation of that theme, which covers unit testing.</p>
<p>I consider the following book as essential reference and reading for Golang, you can purchase it on Amazon: <a href="https://amzn.to/3biQrWJ">Go Programming Language, Addison-Wesley</a>. I'll cover some other recommendations at the end of the post.</p>
<blockquote>
<p>Book a 1:1 coaching session with me to learn more about Go, unit-testing and how to package your applications with Docker and Kubernetes. <a href="https://calendly.com/alexellis/1-1-discounted-coaching?month=2020-12">Book now</a></p>
</blockquote>
<h2 id="1testingingo">1. Testing in Go</h2>
<p>Go has a built-in testing command called <code>go test</code> and a package <code>testing</code> which combine to give a minimal but complete testing experience.</p>
<p>The standard tool-chain also includes benchmarking and statement-based code coverage similar to NCover (.NET) or Istanbul (Node.js).</p>
<p><strong>Share &amp; follow on Twitter:</strong></p>
<blockquote data-lang="en"><p lang="en" dir="ltr">Master unit testing in <a href="https://twitter.com/golang">@golang</a> - isolating dependencies, using fakes and checking code coverage with built-in tools. <a href="https://t.co/YiuAmrupGC">https://t.co/YiuAmrupGC</a></p>— Alex Ellis (@alexellisuk) <a href="https://twitter.com/alexellisuk/status/830059602742013953">February 10, 2017</a></blockquote> 
<h3 id="12writingtests">1.2 Writing tests</h3>
<p>Unit testing in Go is just as opinionated as any other aspect of the language like formatting or naming. The syntax deliberately avoids the use of assertions and leaves the responsibility for checking values and behaviour to the developer.</p>
<p>Here is an example of a method we want to test in the <code>main</code> package. We have defined an exported function called <code>Sum</code> which takes in two integers and adds them together.</p>
<pre><code>package main

func Sum(x int, y int) int {
    return x + y
}

func main() {
    Sum(5, 5)
}
</code></pre>
<p>We then write our test in a separate file. The test file can be in a different package (and folder) or the same one (<code>main</code>). Here's a unit test to check addition:</p>
<pre><code>package main

import "testing"

func TestSum(t *testing.T) {
    total := Sum(5, 5)
    if total != 10 {
       t.Errorf("Sum was incorrect, got: %d, want: %d.", total, 10)
    }
}
</code></pre>
<p>Characteristics of a Golang test function:</p>
<ul>
<li>The first and only parameter needs to be <code>t *testing.T</code></li>
<li>It begins with the word Test followed by a word or phrase starting with a capital letter.</li>
<li>(usually the method under test i.e. <code>TestValidateClient</code>)</li>
<li>Calls <code>t.Error</code> or <code>t.Fail</code> to indicate a failure (I called t.Errorf to provide more details)</li>
<li><code>t.Log</code> can be used to provide non-failing debug information</li>
<li>Must be saved in a file named <code>something_test.go</code> such as: <code>addition_test.go</code></li>
</ul>
<blockquote>
<p>If you have code and tests in the same folder then you cannot execute your program with <code>go run *.go</code>. I tend to use <code>go build</code> to create a binary and then I run that.</p>
</blockquote>
<p>You may be more used to using the <code>Assert</code> keyword to perform checking, but the authors of <a href="https://www.amazon.co.uk/Programming-Language-Addison-Wesley-Professional-Computing/dp/0134190440">The Go Programming Language</a> make some good arguments for Go's style over Assertions.</p>
<p>When using assertions:</p>
<ul>
<li>tests can feel like they're written in a different language (RSpec/Mocha for instance)</li>
<li>errors can be cryptic "assert: 0 == 1"</li>
<li>pages of stack traces can be generated</li>
<li>tests stop executing after the first assert fails - masking patterns of failure</li>
</ul>
<blockquote>
<p>There are third-party libraries that replicate the feel of RSpec or Assert. See also <a href="https://github.com/stretchr/testify">stretchr/testify</a>.</p>
</blockquote>
<p><strong>Test tables</strong></p>
<p>The concept of "test tables" is a set (slice array) of test input and output values. Here is an example for the <code>Sum</code> function:</p>
<pre><code>package main

import "testing"

func TestSum(t *testing.T) {
	tables := []struct {
		x int
		y int
		n int
	}{
		{1, 1, 2},
		{1, 2, 3},
		{2, 2, 4},
		{5, 2, 7},
	}

	for _, table := range tables {
		total := Sum(table.x, table.y)
		if total != table.n {
			t.Errorf("Sum of (%d+%d) was incorrect, got: %d, want: %d.", table.x, table.y, total, table.n)
		}
	}
}
</code></pre>
<p>If you want to trigger the errors to break the test then alter the <code>Sum</code> function to return <code>x * y</code>.</p>
<pre><code>$ go test -v
=== RUN   TestSum
--- FAIL: TestSum (0.00s)
	table_test.go:19: Sum of (1+1) was incorrect, got: 1, want: 2.
	table_test.go:19: Sum of (1+2) was incorrect, got: 2, want: 3.
	table_test.go:19: Sum of (5+2) was incorrect, got: 10, want: 7.
FAIL
exit status 1
FAIL	github.com/alexellis/t6	0.013s
</code></pre>
<p><strong>Launching tests:</strong></p>
<p>There are two ways to launch tests for a package. These methods work for unit tests and integration tests alike.</p>
<ol>
<li>Within the same directory as the test:</li>
</ol>
<pre><code>go test
</code></pre>
<p><em>This picks up any files matching packagename_test.go</em></p>
<p>or</p>
<ol start="2">
<li>By fully-qualified package name</li>
</ol>
<pre><code>go test github.com/alexellis/golangbasics1
</code></pre>
<p>You have now run a unit test in Go, for a more verbose output type in <code>go test -v</code> and you will see the PASS/FAIL result of each test including any extra logging produced by <code>t.Log</code>.</p>
<blockquote>
<p>The difference between unit and integration tests is that unit tests usually isolate dependencies that communicate with network, disk etc. Unit tests normally test only one thing such as a function.</p>
</blockquote>
<h2 id="13moreongotest">1.3 More on <code>go test</code></h2>
<p><strong>Statement coverage</strong></p>
<p>The <code>go test</code> tool has built-in code-coverage for statements. To try it with out example above type in:</p>
<pre><code>$ go test -cover
PASS
coverage: 50.0% of statements
ok  	github.com/alexellis/golangbasics1	0.009s
</code></pre>
<p>High statement coverage is better than lower or no coverage, but metrics can be misleading. We want to make sure that we're not only executing statements, but that we're verifying behaviour and output values and raising errors for discrepancies. If you delete the "if" statement from our previous test it will retain 50% test coverage but lose its usefulness in verifying the behaviour of the "Sum" method.</p>
<p><strong>Generating an HTML coverage report</strong></p>
<p>If you use the following two commands you can visualise which parts of your program have been covered by the tests and which statements are lacking:</p>
<pre><code>go test -cover -coverprofile=c.out
go tool cover -html=c.out -o coverage.html 
</code></pre>
<p>Then open coverage.html in a web-browser.</p>
<p><strong>Go doesn't ship your tests</strong></p>
<p>In addition, it may feel un-natural to leave files named <code>addition_test.go</code> in the middle of your package. Rest assured that the Go compiler and linker will not ship your test files in any binaries it produces.</p>
<p>Here is an example of finding the production vs test code in the net/http package we used in the previous Golang basics tutorial.</p>
<pre><code>$ go list -f={{.GoFiles}} net/http
[client.go cookie.go doc.go filetransport.go fs.go h2_bundle.go header.go http.go jar.go method.go request.go response.go server.go sniff.go status.go transfer.go transport.go]

$ go list -f={{.TestGoFiles}} net/http
[cookie_test.go export_test.go filetransport_test.go header_test.go http_test.go proxy_test.go range_test.go readrequest_test.go requestwrite_test.go response_test.go responsewrite_test.go transfer_test.go transport_internal_test.go]
</code></pre>
<p>For more on the basics read the <a href="https://golang.org/pkg/testing/">Golang testing docs</a>.</p>
<h3 id="14isolatingdependencies">1.4 Isolating dependencies</h3>
<p>The key factor that defines a unit test is isolation from runtime-dependencies or collaborators.</p>
<p>This is achieved in Golang through interfaces, but if you're coming from a C# or Java background, they look a little different in Go. Interfaces are implied rather than enforced which means that concrete classes don't need to know about the interface ahead of time.</p>
<p>That means we can have very small interfaces such as <a href="https://golang.org/src/io/io.go?s=4977:5022#L116">io.ReadCloser</a> which has only two methods made up of the Reader and Closer interfaces:</p>
<pre><code>        Read(p []byte) (n int, err error)
</code></pre>
<p><em>Reader interface</em></p>
<pre><code>        Close() error
</code></pre>
<p><em>Closer interface</em></p>
<p>If you are designing a package to be consumed by a third-party then it makes sense to design interfaces so that others can write unit tests to isolate your package when needed.</p>
<p>An interface can be substituted in a function call. So if we wanted to test this method, we'd just have to supply a fake / test-double class that implemented the Reader interface.</p>
<pre><code>package main

import (
	"fmt"
	"io"
)

type FakeReader struct {
}

func (FakeReader) Read(p []byte) (n int, err error) {
	// return an integer and error or nil
}

func ReadAllTheBytes(reader io.Reader) []byte {
	// read from the reader..
}

func main() {
	fakeReader := FakeReader{}
	// You could create a method called SetFakeBytes which initialises canned data.
	fakeReader.SetFakeBytes([]byte("when called, return this data"))
	bytes := ReadAllTheBytes(fakeReader)
	fmt.Printf("%d bytes read.\n", len(bytes))
}
</code></pre>
<p>Before implementing your own abstractions (as above) it is a good idea to search the Golang docs to see if there is already something you can use. In the case above we could also use the standard library in the <a href="https://golang.org/pkg/bytes/">bytes</a> package:</p>
<pre><code>    func NewReader(b []byte) *Reader
</code></pre>
<p>The Golang <a href="https://golang.org/pkg/testing/iotest/">testing/iotest</a> package provides some Reader implementations which are slow or which cause errors to be thrown half way through reading. These are ideal for resilience testing.</p>
<ul>
<li>Golang docs: <a href="https://golang.org/pkg/testing/iotest/">testing/iotest</a></li>
</ul>
<h3 id="15workedexample">1.5 Worked example</h3>
<p>I'm going to refactor the code example from the <a href="http://blog.alexellis.io/golang-json-api-client/">previous article</a> where we found out how many astronauts were in space.</p>
<p>We'll start with the test file:</p>
<pre><code>package main

import "testing"

type testWebRequest struct {
}

func (testWebRequest) FetchBytes(url string) []byte {
	return []byte(`{"number": 2}`)
}

func TestGetAstronauts(t *testing.T) {
	amount := GetAstronauts(testWebRequest{})
	if amount != 1 {
		t.Errorf("People in space, got: %d, want: %d.", amount, 1)
	}
}
</code></pre>
<p>I have an exported method called GetAstronauts which calls into a HTTP endpoint, reads the bytes from the result and then parses this into a struct and returns the integer in the "number" property.</p>
<p>My fake / test-double in the test only returns the bare minimum of JSON needed to satisfy the test, and to begin with I had it return a different number so that I knew the test worked. It's hard to be sure whether a test that passes first time has worked.</p>
<p>Here's the application code where we run our <code>main</code> function. The <code>GetAstronauts</code> function takes an interface as its first argument allowing us to isolate and abstract away any HTTP logic from this file and its import list.</p>
<pre><code>package main

import (
	"encoding/json"
	"fmt"
	"log"
)

func GetAstronauts(getWebRequest GetWebRequest) int {
	url := "http://api.open-notify.org/astros.json"
	bodyBytes := getWebRequest.FetchBytes(url)
	peopleResult := people{}
	jsonErr := json.Unmarshal(bodyBytes, &amp;peopleResult)</code></pre></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.alexellis.io/golang-writing-unit-tests/">https://blog.alexellis.io/golang-writing-unit-tests/</a></em></p>]]>
            </description>
            <link>https://blog.alexellis.io/golang-writing-unit-tests/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25553779</guid>
            <pubDate>Sun, 27 Dec 2020 19:59:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cory Doctorow (CCC): What the cyberoptimists got wrong – and what to do about it]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25553662">thread link</a>) | @aleclm
<br/>
December 27, 2020 | https://media.ccc.de/v/rc3-11337-what_the_cyberoptimists_got_wrong_-_and_what_to_do_about_it | <a href="https://web.archive.org/web/*/https://media.ccc.de/v/rc3-11337-what_the_cyberoptimists_got_wrong_-_and_what_to_do_about_it">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<div>

<p>
<span></span>
<a href="https://media.ccc.de/search?p=doctorow">doctorow</a>

</p>


<!-- %h3 About -->
<p>They stole our future. Let's take it back.</p>

<p>Here at the end of the world, it's time to take stock. Is technology a force for good? Can it be? Was it ever? How did we end up with a world made up of "five websites, each filled with screenshots of text from the other four" (h/t Tom Eastman)? Should we worry that machine learning will take away our free will through A/B splitting and Big Five Personality Types? Where the fuck did all these Nazis come from? </p>

<h3>Download</h3>
<div>
<p>

Downloads will appear here, once final recordings are released.
</p></div>
<!-- %h3 Embed/Share -->

<h3>Tags</h3>

</div>





</div>]]>
            </description>
            <link>https://media.ccc.de/v/rc3-11337-what_the_cyberoptimists_got_wrong_-_and_what_to_do_about_it</link>
            <guid isPermaLink="false">hacker-news-small-sites-25553662</guid>
            <pubDate>Sun, 27 Dec 2020 19:42:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Matrix: One Chat Protocol to Rule Them All]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25553235">thread link</a>) | @ohjeez
<br/>
December 27, 2020 | https://battlepenguin.com/tech/matrix-one-chat-protocol-to-rule-them-all/ | <a href="https://web.archive.org/web/*/https://battlepenguin.com/tech/matrix-one-chat-protocol-to-rule-them-all/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <section>

  

  <article>
    

    <figure>
  
  <img src="https://battlepenguin.com/images/tech/matrix/matrix.png" alt="Matrix Logo Surrounded by Logos for Hangouts, Telegram, Messenger and Signal pointing to it">
  
  
</figure>

<p>Once upon a time, there were many chat services. AOL Instant Messenger, Yahoo Messenger, ICQ and others. These messengers had their own desktop clients, and developers reverse engineered their protocol to build custom applications, both open and closed source. Trillian, Audium and Pidgin were applications that let people communicate across all these messengers with one program. Over time the old protocols died, and newer chat services like Facebook Messenger and Google Hangouts started storing your entire history on their servers. People started using the web interfaces and mobile apps, no longer caring about desktop programs.</p>

<p>Matrix is an open source communication protocol. It’s similar to XMPP (formerly Jabber) in the sense that anyone can set up a Matrix server and communicate to people on other Matrix servers. It’s a federated protocol, just like e-mail. Google Hangouts used to support XMPP federation, but silently removed support in 2014. Matrix supports bridging other chat services, so they can appear in a unified view. With my current setup of Matrix and appropriate bridges, I’ve combined my view of Facebook Messenger, Google Hangouts, Telegram and native Matrix chats into one convenient user interface. The path to get to that integration was not as simple.</p>

<!--more-->

<p>The dedicated server I use for <a href="https://battlepenguin.com/tech/a-history-of-personal-and-professional-websites/">this website</a> and other self-hosted web applications, is located in Germany. Logging in to Facebook or Google’s chat system from a country I’m not currently in, can raise all sorts of security flags and lock me out of my account. For those bridges, I purchased a small virtual machine in a Chicago data center. I installed a proxy on that server, accessible only via VPN, to view both Google and Facebook, so they record the IP address I’m connecting from with my web browser. This helps minimize security lockouts. Telegram isn’t hostile to third party developers, and has an official API. It doesn’t care my bridge is connecting to it from Germany, so I host it on the dedicated server.</p>

<figure>
  
  <img src="https://battlepenguin.com/images/tech/matrix/server-diagram.png" alt="Server Diagram of Matrix Homeserver and Bridges">
  
  
  <figcaption>
      

      Server Diagram of Matrix Homeserver and Bridges

      
  </figcaption>
  
</figure>

<p>The reference Matrix server is called Synapse. It, as well as the <a href="https://github.com/tulir/mautrix-telegram">mautrix-telegram</a>, <a href="https://github.com/tulir/mautrix-hangouts">mautrix-hangouts</a> and <a href="https://github.com/tulir/mautrix-facebook">mautrix-facebook</a> bridges all have official Docker containers built by their developers. Each bridge must be able to communicate with the Synapse homeserver. Their instructions go through generating configuration and key pairs that are copied over to Synapse in order to form their authentication bridge. The bridges provide chat robots that guide you through getting OAuth tokens or cookies for those respective services.</p>

<figure>
  
  <img src="https://battlepenguin.com/images/tech/matrix/element-screenshot.png" alt="Facebook and Hangouts Chats in Element">
  
  
  <figcaption>
      

      Facebook and Hangouts Chats in Element

      
  </figcaption>
  
</figure>

<p>The wiki for each bridge also has instructions for enabling double-puppeting, making each chat look seamless between myself and the accounts on the other side of each respective bridge. Without double-puppeting, each conversation will be in a three person group with the Matrix user, the bridge user (e.g my Google Hangouts user) and the person I’m talking to.</p>

<figure>
  
  <img src="https://battlepenguin.com/images/tech/matrix/no-double-puppet.png" alt="Chat Without Double-Puppeting Enabled">
  
  
  <figcaption>
      

      Chat Without Double-Puppeting Enabled

      
  </figcaption>
  
</figure>

<p>Enabling double-puppeting via the <code>curl</code> command in the bridge documentation and calling <code>login-matrix</code> on the bot, removes the creation of three person rooms. The bridged accounts will now show up as regular, two-person conversations.</p>

<p>I use the Element desktop app to connect to my matrix server, but I also have a web version of Element running from its own official Docker container in case I need to access chat from another computer. There are other clients, such as <a href="https://github.com/mirukana/mirage">Mirage</a> which is built using Qt and <a href="https://fluffychat.im/">Fluffychat</a> for mobile. Although I use Synapse for my homeserver, there are other servers that support the Matrix protocol that are in use and under active development.</p>

<p>Setting up all the Matrix components wasn’t too difficult, but it does require knowledge or experience with running services. It took a considerable amount of work and debugging to get each bridge operational, compounded slightly by my complex networking setup. Most people would probably just run all of this on a Raspberry Pi at home. I feel that using Matrix with bridges is still somewhat inaccessible to people who aren’t interested in development or server administration. Still, the satisfaction of having unified chat, plus one more layer of abstraction between myself and Google or Facebook, feels like it was wroth the overall effort.</p>


    

  </article>

</section>



    </div></div>]]>
            </description>
            <link>https://battlepenguin.com/tech/matrix-one-chat-protocol-to-rule-them-all/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25553235</guid>
            <pubDate>Sun, 27 Dec 2020 18:45:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A first look at Ghidra’s Debugger – Game Boy Advance Edition]]>
            </title>
            <description>
<![CDATA[
Score 153 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25553105">thread link</a>) | @mr_golyadkin
<br/>
December 27, 2020 | https://wrongbaud.github.io/posts/ghidra-debugger/ | <a href="https://web.archive.org/web/*/https://wrongbaud.github.io/posts/ghidra-debugger/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src=""></p><h2 id="overview">Overview</h2><p><a href="https://twitter.com/NSACyber/status/1339652646513291264">Yesterday</a> the NSA Twitter account announced that a new branch of Ghidra has been release with the long-awaited debugging capability. This will allow for single-step debugging of a program within <a href="https://hackaday.io/course/172292-introduction-to-reverse-engineering-with-ghidra">Ghidra</a> through a GDB stub or other various debug mechanisms. To celebrate this (and my being stuck at home quarantining…) I wanted to review how to build this version of Ghidra and give an example of how to use this debugger on a fun target.</p><p>This post will explain the following:</p><ul><li>How to build the latest (or any) version of Ghidra using a <a href="https://github.com/dukebarman/ghidra-builder">Docker Container</a></li><li>How to build the Ghidra Eclipse plugins</li><li>How to build a program <a href="https://github.com/SiD3W4y/GhidraGBA">loader</a> for Ghidra</li><li>Debugging a program with Ghidra using the GDB stub</li><li>Use the debugging capability to help us learn about how passwords are processed for a GBA game</li></ul><p>For this post, we’re going to be taking a look at the Game Boy Advance game Spiderman: Mysterio’s Menace. I’ve been very much inspired by all of the awesome work that <a href="https://youtu.be/VVbRe7wr3G4">stacksmashing and Liveoverflow have been doing regarding these topics</a>. This was a game that I spent a lot of time playing and it’s always fun revisiting childhood favorites from an RE perspective. The ultimate goal is to demonstrate how to properly load this ROM using a custom loader, and connect to an emulator’s GDB stub using Ghidra’s debugging features.</p><p><strong>RE Note/Tangent:</strong> When taking on a new reversing project, it’s important to try to compartmentalize goals and targets. For example, if we said we just want to <em>reverse</em> this game, that opens up endless possibilities. We could reverse engineer the collision detection, how enemy AI works, or how level maps are generated. For this post, we will pick a specific target and take a look at the password mechanism in use by this game.</p><p>I am doing all of this work on an Ubuntu 20.04 machine, with the latest updates.</p><h2 id="building-ghidra">Building Ghidra</h2><p>First things first, this debugger branch has not yet been included in an official release so we’re going to have to build it ourselves. Luckily for us <a href="https://github.com/dukebarman/ghidra-builder">dukebarman</a> has put together a docker container for us to do this, all we need to do is modify the <code>build_ghidra.sh</code> script to checkout the debugger branch, see the following line below:</p><div><p><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>git clone https://github.com/NationalSecurityAgency/ghidra -b debugger
</pre></td></tr></tbody></table></code></p></div><p>We are also going to build the Eclipse development extensions for this version of Ghidra, this will help us later on when we build a loader and write our analysis scripts. To do this we add the following line to the <code>build_ghidra.sh</code> script:</p><div><p><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>gradle prepDev
gradle eclipse -PeclipsePDE
</pre></td></tr></tbody></table></code></p></div><p>Next follow the instructions in the <code>README</code>:</p><div><p><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre>cd ghidra-builder
sudo docker-tpl/build
cd workdir
sudo ../docker-tpl/run ./build_ghidra.sh
</pre></td></tr></tbody></table></code></p></div><p>This will take some time, so maybe go grab a coffee or two and come back to your freshly built Ghidra. The resulting build can be found in <code>workdir/out</code>:</p><div><p><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>wrongbaud@wubuntu:~/blog/gba-re-gbd/ghidra-builder/workdir$ ls out/
ghidra_9.3_DEV_20201218_linux64.zip
</pre></td></tr></tbody></table></code></p></div><p>Unzip this file, and you can launch Ghidra via the <code>./ghidraRun</code> script. For this post, I will unzip this into the <code>ghidra-builder/workdir</code> directory because we’re going to be using the docker container to build a Ghidra loader for this version of Ghidra. If you’re following along, your workdir directory should look like this:</p><div><p><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>wrongbaud@wubuntu:~/blog/gba-re-gbd/ghidra-builder/workdir$ ls
build_ghidra.sh  ghidra  ghidra_9.3_DEV out  set_exec_flag.sh
</pre></td></tr></tbody></table></code></p></div><h2 id="building-eclipse-plugins">Building Eclipse Plugins</h2><p>Now that we have a new version of Ghidra built, we also need to build the GhidraDev plugin for Eclipse. The eclipse projects can be found in the <code>ghidra-builder/workdir/ghidra/GhidraBuild/EclipsePlugins/GhidraDev</code> directory.</p><ol><li>Install <a href="https://www.eclipse.org/downloads/packages/installer">Eclipse</a><ul><li>Select the Java IDE</li></ul></li><li>Install CDT, PyDev, and Plugin Development Environment<ul><li>This can be done from the Eclipse marketplace</li></ul></li><li>Import the GhidraDevFeature and GhidraDevPlugin projects<ul><li>These can be found in the <code>ghidra-builder/workdir/ghidra/GhidraBuild/EclipsePlugins/GhidraDev/</code> directory</li><li><code>File</code> -&gt; <code>Import</code> -&gt; <code>General</code> -&gt; <code>Existing Projects into Workspace</code></li><li>Add <code>ghidra-builder/workdir/ghidra/GhidraBuild/EclipsePlugins/GhidraDev</code></li><li>Select “Search for nested projects”</li><li>Import the projects!</li><li><strong>Note:</strong> you may see some build errors when these are imported, you can ignore these as you are just exporting the plugin!</li></ul></li><li>With these projects loaded, we can now <a href="https://github.com/NationalSecurityAgency/ghidra/blob/debugger/GhidraBuild/EclipsePlugins/GhidraDev/GhidraDevPlugin/build_README.txt">export the plugin</a><ul><li><code>File</code> -&gt; <code>Export</code></li><li><code>Plug-in Development</code> -&gt; <code>Deployable Features</code></li><li><code>ghidradev.ghidradev</code></li><li>Select an archive location for the plugin to be exported to</li><li>Click Finish!</li></ul></li></ol><p>Now we have our Ghidra plugin, built for our custom version of Ghidra that we can load via <code>Help</code>-&gt;<code>Install New Software</code>.</p><p>And with that, we have built Ghidra from the <code>debugger</code> branch, and have also built the Eclipse development extensions so we can build plugins for our new version of Ghidra!</p><p><strong>Note:</strong> I just want to take a second to outline just how incredible the <a href="https://github.com/NationalSecurityAgency/ghidra/blob/15c1f43fa51f210836cb451aff587b227dffe0a7/DevGuide.md">help docs</a> are for Ghidra. From the P-Code manuals to the instructions on building and exporting these plugins - the project is very well documented.</p><h2 id="building-the-rom-loader">Building the ROM Loader</h2><p>To properly analyze this ROM in Ghidra, we are going to need to define all of the <a href="https://problemkaputt.de/gbatek.htm#gbamemorymap">memory regions and peripherals</a> for the Game Boy Advance. Luckily for us, <a href="https://github.com/SiD3W4y/GhidraGBA">SiD3W4y</a> on GitHub has already written one.</p><p>If you are a regular reader of this blog, a <a href="https://wrongbaud.github.io/posts/writing-a-ghidra-loader/">ghidra loader</a> may be a familiar subject to you. If not, the purpose of a Ghidra loader is to set up all of the necessary memory regions, identify any debug information or symbols that may be present in the file, and provide as much information as possible about the target file. The loader that was mentioned before outlines all of the basic peripherals of the GBA and is an excellent example loader to work with, let’s start by cloning it into the <code>ghidra-builder/workdir</code> directory. We’re doing this because we’re going to use the same docker container we built Ghidra with to build this loader.</p><div><p><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
</pre></td><td><pre>cd ghidra-builder/workdir
git clone https://github.com/SiD3W4y/GhidraGBA
sudo ../docker-tpl/run /bin/bash
dockerbot@797eb43ce05f:/files/GhidraGBA$ export GHIDRA_INSTALL_DIR=/files/ghidra_9.3_DEV/
dockerbot@797eb43ce05f:/files/GhidraGBA$ gradle
dockerbot@797eb43ce05f:/files/GhidraGBA$ cp dist/ghidra_9.3_DEV_20201218_GhidraGBA.zip ../ghidra_9.3_DEV/Extensions/Ghidra/
dockerbot@797eb43ce05f:/files/GhidraGBA$ exit
exit
</pre></td></tr></tbody></table></code></p></div><p>In case the above steps are confusing, what we are doing is:</p><ol><li>Launching the docker container</li><li>Building the GhidraGBA extension, providing the path to our installation</li><li>Copying it to Ghidra’s extensions directory (so it will show up under the Install Extensions menu)</li><li>Exiting the docker container</li></ol><p>Launch Ghidra via <code>ghidraRun</code> and go to <code>File</code>-&gt; <code>Install Extensions</code>. Select the GhidraGBA loader and click <code>OK</code>. You will need to restart Ghidra for the change to take effect. Now when you load a GBA ROM you should see the following:</p><p><img data-src="https://wrongbaud.github.io/assets/img/ghidra-dbg/gba.png" alt="GBA" src="https://wrongbaud.github.io/assets/img/ghidra-dbg/gba.png"></p><p>After running the auto analysis, Ghidra seems to make a pretty quick sense of the ROM. There are a lot of functions defined and things are looking good. So the next step is to figure out some way to narrow down what we care about in this ROM image, in other words, we need to find our needle in the haystack. Let’s start by examining how the password system works in this game by entering a few passwords.</p><h2 id="analyzing-the-rom">Analyzing the Rom</h2><p>As mentioned before, our goal here is to try to understand the password system in use by this game. If we attempt to enter a password, the following screen is displayed:</p><p><img data-src="https://wrongbaud.github.io/assets/img/ghidra-dbg/rom-1.png" alt="ROM1" src="https://wrongbaud.github.io/assets/img/ghidra-dbg/rom-1.png"></p><p>Note that we have all of the consonants and no vowels and numbers “0-9”, and our passwords are only 5 characters long. This is a nice starting point for us as reverse engineers. We can use this information to help us narrow down functions of interest. For example- let’s look through the strings in the ROM and see if these values are represented in a string somewhere. If we open the strings window, <code>Window</code> -&gt; <code>Defined Strings</code>, and filter for the first 5 characters available to us as password characters we see the following:</p><p><img data-src="https://wrongbaud.github.io/assets/img/ghidra-dbg/strings-password-characters.png" alt="" src="https://wrongbaud.github.io/assets/img/ghidra-dbg/strings-password-characters.png"></p><p>So far so good - we only have two instances of this string in use. One is located at <code>0x804c11fc</code> and one at <code>0x84b86f0</code>. Upon examination of the first one, we see that this string gets passed to a function in the subroutine located at <code>0x8003358</code>, see below:</p><div><p><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre></td><td><pre><span>undefined4</span> <span>passwd_1</span><span>(</span><span>int</span> <span>param_1</span><span>,</span><span>int</span> <span>param_2</span><span>)</span>

<span>{</span>
  <span>int</span> <span>iVar1</span><span>;</span>
  <span>uint</span> <span>uVar2</span><span>;</span>
  <span>uint</span> <span>uVar3</span><span>;</span>
  <span>undefined4</span> <span>in_lr</span><span>;</span>
  <span>undefined</span> <span>auStack52</span> <span>[</span><span>36</span><span>];</span>
  <span>undefined4</span> <span>uStack4</span><span>;</span>
  
  <span>uStack4</span> <span>=</span> <span>in_lr</span><span>;</span>
  <span>FUN_080231f4</span><span>(</span><span>auStack52</span><span>,</span><span>"BCDFGHJKLMNPQRSTVWXYZ0123456789-"</span><span>,</span><span>0x21</span><span>);</span>
  <span>*</span><span>(</span><span>uint</span> <span>*</span><span>)(</span><span>param_1</span> <span>+</span> <span>0x8c</span><span>)</span> <span>=</span> <span>0</span><span>;</span>
  <span>FUN_080025f8</span><span>(</span><span>param_1</span><span>);</span>
  <span>FUN_08002674</span><span>(</span><span>param_1</span><span>);</span>
  <span>FUN_08002714</span><span>(</span><span>param_1</span><span>);</span>
  <span>FUN_0800282c</span><span>(</span><span>param_1</span><span>);</span>
  <span>iVar1</span> <span>=</span> <span>0</span><span>;</span>
  <span>uVar3</span> <span>=</span> <span>*</span><span>(</span><span>uint</span> <span>*</span><span>)(</span><span>param_1</span> <span>+</span> <span>0x8c</span><span>);</span>
  <span>uVar2</span> <span>=</span> <span>0</span><span>;</span>
  <span>do</span> <span>{</span>
    <span>*</span><span>(</span><span>undefined</span> <span>*</span><span>)(</span><span>param_2</span> <span>+</span> <span>iVar1</span><span>)</span> <span>=</span> <span>auStack52</span><span>[</span><span>uVar3</span> <span>&gt;&gt;</span> <span>(</span><span>uVar2</span> <span>&amp;</span> <span>0xff</span><span>)</span> <span>&amp;</span> <span>0x1f</span><span>];</span>
    <span>uVar2</span> <span>=</span> <span>uVar2</span> <span>+</span> <span>5</span><span>;</span>
    <span>iVar1</span> <span>=</span> <span>iVar1</span> <span>+</span> <span>1</span><span>;</span>
  <span>}</span> <span>while</span> <span>(</span><span>iVar1</span> <span>&lt;</span> <span>5</span><span>);</span>
  <span>return</span> <span>uStack4</span><span>;</span>
<span>}</span>
</pre></td></tr></tbody></table></code></p></div><p>Notice also the while loop that is looping while a variable is less than five, this is a good indicator that this function might be useful as we know that the password length is 5! Let’s label it <code>passwd_1</code> and move onto the other uses of our character string. The next one that we can see is in the function at <code>0x8002CEC</code>, the decompilation can be seen below:</p><div><p><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
</pre></td><td><pre><span>undefined8</span> <span>passwd_2</span><span>(</span><span>void</span><span>)</span>

<span>{</span>
  <span>int</span> <span>iVar1</span><span>;</span>
  <span>int</span> <span>iVar2</span><span>;</span>
  <span>uint</span> <span>uVar3</span><span>;</span>
  <span>undefined4</span> <span>in_lr</span><span>;</span>
  <span>undefined</span> <span>local_98</span> <span>[</span><span>5</span><span>];</span>
  <span>undefined</span> <span>local_93</span><span>;</span>
  <span>undefined</span> <span>auStack144</span> <span>[</span><span>36</span><span>];</span>
  <span>undefined</span> <span>auStack108</span> <span>[</span><span>8</span><span>];</span>
  <span>undefined</span> <span>auStack100</span> <span>[</span><span>72</span><span>];</span>
  <span>undefined4</span> <span>uStack4</span><span>;</span>
  
  <span>uStack4</span> <span>=</span> <span>in_lr</span><span>;</span>
  <span>FUN_08000b0c</span><span>(</span><span>0</span><span>,</span><span>1</span><span>,</span><span>0</span><span>,</span><span>0</span><span>);</span>
  <span>DAT_03001fd0</span><span>.</span><span>_0_2_</span> <span>=</span> <span>0x1444</span><span>;</span>
  <span>DISPCNT</span> <span>=</span> <span>0x1444</span><span>;</span>
  <span>FUN_0801e330</span><span>(</span><span>&amp;</span><span>DAT_0838277c</span><span>);</span>
  <span>iVar1</span> <span>=</span> <span>DAT_03001fe0</span><span>;</span>
  <span>FUN_080231f4</span><span>(</span><span>auStack144</span><span>,</span><span>"BCDFGHJKLMNPQRSTVWXYZ0123456789-"</span><span>,</span><span>0x21</span><span>);</span>
  <span>*</span><span>(</span><span>uint</span> <span>*</span><span>)(</span><span>iVar1</span> <span>+</span> <span>0x8c</span><span>)</span> <span>=</span> <span>0</span><span>;</span>
  <span>FUN_080025f8</span><span>(</span><span>iVar1</span><span>);</span>
  <span>FUN_08002674</span><span>(</span><span>iVar1</span><span>);</span>
  <span>FUN_08002714</span><span>(</span><span>iVar1</span><span>);</span>
  <span>FUN_0800282c</span><span>(</span><span>iVar1</span><span>);</span>
  <span>iVar2</span> <span>=</span> <span>0</span><span>;</span>
  <span>uVar3</span> <span>=</span> <span>0</span><span>;</span>
  <span>do</span> <span>{</span>
    <span>local_98</span><span>[</span><span>iVar2</span><span>]</span> <span>=</span> <span>auStack144</span><span>[</span><span>*</span><span>(</span><span>uint</span> <span>*</span><span>)(</span><span>iVar1</span> <span>+</span> <span>0x8c</span><span>)</span> <span>&gt;&gt;</span> <span>(</span><span>uVar3</span> <span>&amp;</span> <span>0xff</span><span>)</span> <span>&amp;</span> <span>0x1f</span>…</pre></td></tr></tbody></table></code></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wrongbaud.github.io/posts/ghidra-debugger/">https://wrongbaud.github.io/posts/ghidra-debugger/</a></em></p>]]>
            </description>
            <link>https://wrongbaud.github.io/posts/ghidra-debugger/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25553105</guid>
            <pubDate>Sun, 27 Dec 2020 18:29:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Cyberpunk 2077 Gets Wrong About the Genre]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25552923">thread link</a>) | @kiraleighleigh
<br/>
December 27, 2020 | https://blog.constelisvoss.ml/what-cyberpunk-2077-gets-wrong-about-the-genre/ | <a href="https://web.archive.org/web/*/https://blog.constelisvoss.ml/what-cyberpunk-2077-gets-wrong-about-the-genre/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <p>Though this is a blog for media critiques, side stories for <a href="https://constelisvoss.ml/">CONSTELIS VOSS</a>, news, art posts, etc, I feel like the only place this article can live is <em>here</em>.</p><p>Not on <a href="https://weebtrash.ga/">weebtrash</a>. Not on <a href="https://medium.com/@kiraIeigh">Medium</a>. Not on <a href="https://www.linkedin.com/in/kirakiraleighleigh">LinkedIn</a>. Here, in a space centered on a sci-fi trilogy about robots, corruption, tropes, and what it means to be a person.</p><p>Cyberpunk 2077 was initially framed as an ambitious stab at a genre often overlooked in popular media; this was a promise.</p><p>Sadly, Cyberpunk 2077 misses the mark, despite being an overall very enjoyable game. CD Projekt Red's treatment of the genre is worse than the buggy launch, and I'm going to explain how and why.</p><p>First, let's explore two IPs that do it right. Then, we'll compare Cyberpunk 2077 against their core messaging.</p><p>Let's begin.</p><h2 id="how-ghost-in-the-shell-tackles-cyberpunk">How Ghost in the Shell Tackles Cyberpunk</h2><h3 id="all-barriers-are-moot">All barriers are moot</h3><figure><img src="http://blog.constelisvoss.ml/content/images/2020/12/MOSHED-2020-12-4-13-22-6-2.gif" alt=""></figure><p>Wikipedia's explanation of the Cyberpunk genre:</p><blockquote><strong>Cyberpunk</strong> is a <a href="https://en.wikipedia.org/wiki/Subgenre">subgenre</a> of <a href="https://en.wikipedia.org/wiki/Science_fiction">science fiction</a> in a <a href="https://en.wikipedia.org/wiki/Dystopia">dystopian</a> <a href="https://en.wikipedia.org/wiki/Futurism">futuristic</a> setting that tends to focus on a "combination of <a href="https://en.wikipedia.org/wiki/Low-life">low-life</a> and <a href="https://en.wikipedia.org/wiki/High_tech">high tech</a>"<sup><a href="https://en.wikipedia.org/wiki/Cyberpunk#cite_note-1">[1]</a></sup> featuring advanced technological and scientific achievements, such as <a href="https://en.wikipedia.org/wiki/Artificial_intelligence">artificial intelligence</a> and <a href="https://en.wikipedia.org/wiki/Cybernetics">cybernetics</a>, juxtaposed with a degree of breakdown or radical change in the <a href="https://en.wikipedia.org/wiki/Social_order">social order</a>.</blockquote><p>But it's so much more than that. Look no further than <a href="https://en.wikipedia.org/wiki/Ghost_in_the_Shell">Ghost in the Shell</a> for a deeper examination.</p><p>Ghost in the Shell is about a lot of things, but what makes it a great overview of the genre itself is that Motoko Kusanagi—the protagonist—isn't limited by her physical body.</p><p>The body is a tool. The soul (Ghost) is what matters, and even that can be reconfigured, if one chooses.</p><figure><img src="http://blog.constelisvoss.ml/content/images/2020/12/OK6W_koKDTOqqqLDbIoPAvKwT3u7zGxQ6vZ1ij2uHr8.gif" alt=""></figure><p>Motoko moves through cyberspace, breaks her body to fight her opponents, and exists as a tour de force in a landscape of corruption.</p><p>As the IP has multiple iterations, different topics take the forefront in different mediums. However, Motoko is always the through-line; a cybernetic warrior who uses a canonically pleasure-district shell, augmented to beat the crap out of her opponents, regardless of the physical costs.</p><p>Furthermore, in the 90s movie, she meets a sentient AI who she merges with to yet again break human barriers (and touch on sentiency).</p><p>Barriers are no object, and choices are fathomless, despite being in a world of corruption. Cyberpunk technology affords this.</p><p>That is the backbone of the Cyberpunk genre, as explained by Ghost in the Shell. </p><h2 id="how-blade-runner-tackles-cyberpunk">How Blade Runner tackles Cyberpunk</h2><h3 id="what-is-sentiency-what-is-agency">What is sentiency? What is agency?</h3><figure><img src="http://blog.constelisvoss.ml/content/images/2020/12/f11157d2551ba0894c07a55b5f0dd9aa.gif" alt=""></figure><p>The original <a href="https://en.wikipedia.org/wiki/Blade_Runner">Blade Runner</a> film centers around synthetic beings (replicants) going rogue. Harrison Ford's Deckard is on a mission to reel-in misbehaving androids; that's the low media literacy baby-shit-brain reading.</p><p>You could also read Deckard as possibly being a synth himself. Or, you could read Deckard's attraction to Rachael—a replicant—as a question about love. Can androids truly love?</p><p>You could also read it as a commentary on sentiency via Pris and Roy's (both replicants) existential crises.</p><p>In the new film, <a href="https://en.wikipedia.org/wiki/Blade_Runner_2049">Blade Runner 2049</a>, you could read Gosling's K—another replicant—as experiencing true personhood through the juxtaposition of who he isn't.</p><p>By questioning his place in the narrative when he realizes his memories are fake, he explodes with emotion, and dies with the knowledge that he's challenged what he even is. That's sentiency, baby.</p><p>There are many concepts in the Blade Runner movies, and the <a href="https://en.wikipedia.org/wiki/Do_Androids_Dream_of_Electric_Sheep%3F">novel </a>they're based on, but all of them grapple with these topics:</p><p>Who gets to be a person, who gets to be free, who gets to feel, who gets to live, and who doesn't.</p><p>The backbone of the Blade Runner IP exists to question these aspects of sentiency and agency.</p><p>So what does Cyberpunk 2077 do with GiTS' and Blade Runner's hot-takes?</p><h2 id="cyberpunk-2077-fumbles-barriers-are-moot">Cyberpunk 2077 fumbles "barriers are moot"</h2><h3 id="the-body-is-not-sacred-game-director-adam-badowski">The body is not sacred, game director Adam Badowski</h3><figure><img src="http://blog.constelisvoss.ml/content/images/2020/12/MOSHED-2020-12-4-14-50-53-2.gif" alt=""></figure><blockquote>"This is cyberpunk, so people augment their body. So the body is no longer sacrum [sacred]; it's profanum [profane]. Because people modify everything, they are losing their connection to the body, to the meat. And that's why we need to use the nudity in many situations."</blockquote><p>The Cyberpunk genre is about the philosophy of personhood and human existence as juxtaposed to and twisted against technology, set upon a backdrop of corporate dystopia.</p><p>Not only are Badowski's statements ignorant of the genre, but the way Cyberpunk 2077 handles these topics is, too.</p><p>You cannot augment your character within an inch of their life. You cannot even cut their hair after the initial character generation screen. </p><p>You cannot become a 9 foot chrome-lacquered war-machine with a car engine for a crotch. You can't swap your consciousness into something else.</p><p>Because we know other characters <em><strong>can,</strong></em> Cyberpunk 2077 offers the illusion of choice by showing it exists, but barely gives it to the player.</p><p>Speaking of barely; though you can swap voice/junk gender, this doesn't break down gender barriers meaningfully.</p><p>You cannot blur the lines of sexuality, because your romance options are very limited. Have a male voice but a female body? Many routes are off the table. However, the problem isn't so much that characters [to reflect IRL people] have certain 'equipment' preferences. That's valid.</p><p>The problem is that players <em><strong>should</strong></em> be able to have a car engine for a crotch and see how that shakes things up, for example. If it does at all. </p><p>This is the one genre that <em>most</em> benefits from a predominantly bisexual romance roster, or at the very least, it benefits from having the balls to tackle the transhumanism topic.</p><p>When corporations plaster ads inside of your eyeballs, the only thing left is the ability to transform yourself beyond limits. One of those limits is the self. </p><p>The other is grappling with what the self means when you replace it with cyberware, and what flavor of human <em>other </em>people see you as.</p><p>Cyberpunk 2077 does make a stance on this, and it's not as expected; too much self-reconfiguration makes you a Cyberpsycho. NPCs lose their mind if they replace too many parts.</p><p>This shows us that the "flesh as sacrum" aspect is unavoidable. </p><p>Because of all this, Cyberpunk 2077 smacks into the "barriers are moot" genre-point like V's car barrels down roads with the finesse of a bull in a china shop.</p><p>It's nothing but barriers, with the veneer of choice.</p><h2 id="cyberpunk-2077-mishandles-the-sentiency-agency-question">Cyberpunk 2077 mishandles "the sentiency/agency question"</h2><h3 id="despite-the-attention-paid-to-johnny-invading-your-shell">Despite the attention paid to Johnny invading your shell</h3><figure><img src="http://blog.constelisvoss.ml/content/images/2020/12/cyberpunk2077-1.jpg" alt=""></figure><p>Does Cyberpunk 2077 address "the sentiency/agency question"? Keanu's Johnny Silverhands invades your shell, which suggests it does, but there's a problem.</p><p>In order to analyze this, we have to talk about the results. There are 5 endings, and all of them are a flavor of "you die because your body is beyond saving", "Johnny takes over" or "go to cyberjail while Arasaka figures out how to ya yeet you." </p><p>Only two routes shake things up, and one is "commit suicide" while the other is "fuck off somewhere to solve the problem, off-screen."</p><p>The issue? There are in-game lore "outs" to suggest personhood doesn't stop at meat suits. Lizzy Wizzy's download into a synth body comes to mind; is she not a person? The game thinks so, yet Johnny robs you of agency histrionically. </p><p>What of Alt, Johnny's past love-interest and now-sentient-AI? A missed opportunity to smash barriers, and also tackle the sentiency question. Alt has lost her "soul".</p><p>There are repercussions to digitization, even if Judy's route later explains she figured out how to dabble in recorded/shared emotions, via BD devices. Even if Arasaka <em>already</em> upgraded the engram system.</p><p>It's almost as though the cast's skills/game lore never applies breakthrough tech to your problem, until it's too late.</p><p>Can players invade the darkweb and chill with the rogue AIs? Yes, but we <em>can't</em> do it to save our own Ghost, because "the flesh is sacrum".</p><p>What of Delamain's rogue AI "children"? Surprisingly, you get to tackle the sentiency angle if you complete the Epistrophy side quests. You can honor the rogue AIs' wishes and merge them with Delamain's main personality.</p><p>Cyberpunk 2077 pretends all this technology is in its infancy to stop the player from questioning narrative choices. What it actually does is show what's possible, but <strong>not for you</strong>.</p><p>Why can't players live in the internet? Why can't they hop into a car? Why can't they download into a synth? Why can't they merge personalities with Johnny in a truly blended version, like Motoko in the GiTS 90s film?</p><p>Cyberpunk 2077 punishes players for the very concepts the Cyberpunk genre grapples with, and the game lore suggests it <em>can</em> tackle.</p><p>Who gets to be a person even if they're inside a fucking toaster? Cars, Lizzy Wizzy, and Johnny. Not the player.</p><h2 id="and-what-of-the-punk-aspect-of-cyberpunk">And what of the Punk aspect of Cyberpunk?</h2><h3 id="well-it-s-lip-service-is-the-thing">Well, it's lip-service, is the thing</h3><figure><img src="http://blog.constelisvoss.ml/content/images/2020/12/cyberpunk2077_hand_cmyk_wide-959129cd7f84b90547ac1c88d90ec6bae3b98186.jpg" alt=""></figure><p>As stated: in the genre you have body augmentation, boundary scuttling, and transhumanism as rebellion options. Another is fighting the corporatization of the self and others. That's where the Punk aspect comes in.</p><p>Though Johnny invading your shell is a nice thematic touch, he's mostly concerned with Big Corp Arasaka. He judges your character harshly if they care about plenty of <em>other</em> rebellions. </p><p>For instance, sentient AI cars get more sympathy from Johnny than the dolls of The Clouds (who are human sex workers). That's not very Punk, Johnny.</p><p>Somehow, Takemura's plot is more on-point here, as an examination of Arasaka as child-soldier creators, and yet I don't see him staging some mass "free the kids" rebellion.</p><p>To make matters worse, you can't defy the cops; killing criminals helps the police, as a feature not a bug. In order to get the gear/money you need to progress, this is basically unavoidable. If you do try to avoid it, this cuts a shitload of content out.</p><p>River Ward's side quest examines this, as the one good cop in Night City. However, his quest doesn't let you stage a rebellion against the corrupt police force. His plot-line is ripe for this aspect of Punk.</p><p>Even the 3 initial 'camps' you choose don't tango with the Punk aspect. After the first 20 minutes, all you get are dialog options. There should've been a way to join …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.constelisvoss.ml/what-cyberpunk-2077-gets-wrong-about-the-genre/">https://blog.constelisvoss.ml/what-cyberpunk-2077-gets-wrong-about-the-genre/</a></em></p>]]>
            </description>
            <link>https://blog.constelisvoss.ml/what-cyberpunk-2077-gets-wrong-about-the-genre/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25552923</guid>
            <pubDate>Sun, 27 Dec 2020 18:09:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building my own HomeKit Thermostat]]>
            </title>
            <description>
<![CDATA[
Score 175 | Comments 88 (<a href="https://news.ycombinator.com/item?id=25552889">thread link</a>) | @frenchie4111
<br/>
December 27, 2020 | https://www.staycaffeinated.com/2020/12/27/building-my-own-homekit-thermostat-v1 | <a href="https://web.archive.org/web/*/https://www.staycaffeinated.com/2020/12/27/building-my-own-homekit-thermostat-v1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content_area">
    <div>
        
            <h2 id="post_title">Building my own HomeKit Thermostat</h2>
        

        <p>Iâ€™m pretty obsessed with controlling most of the electronics in my house from my
phone. One of the last remaining devices was the thermostat. I donâ€™t want a Nest
because it doesnâ€™t work with HomeKit, and I canâ€™t use an EcoBee because I donâ€™t
have a neutral wire. So I resolved to build my own.</p>

<p>If you are building your own thermostat, or any hardware really, and want some
help or just want to show it off, feel free to shoot me an email at mdl0394@gmail.com. 
Also I plan to continue to expand this project to have a screen and some buttons,
if you want to hear about that signup to my email list and Iâ€™ll let you know when
I do it.</p>



<h2 id="figuring-out-hot-to-turn-on-the-heat">Figuring out hot to turn on the heat</h2>

<p>So I turns out my heater runs on a really simple control protocol. There are just
two wires run from the heater to the current thermostat, when you connect them it
turns on, and when you disconnect it turns off. The only unfortunate part of it is
that the wires are 24vac, so to be safe I need to use a solid state relay for
switching.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/5897a162a777067bc7469e501a50029f58c9efe6/cc305/images/homekit_thermostat/old_thermostat_closeup.jpeg" alt="Old Thermostat Closeup showing two pins that need to be connected"></p>



<h2 id="the-prototype">The prototype</h2>

<p>I am building this whole thing on an esp32, with a big overkill relay I got on
amazon prime. I will link the exact parts below. The current thermometer is an
old tmp102 sparkfun board I had lying around, but itâ€™s off by around 6 degrees,
so in v2 I will be replacing it with hopefully a more accurate one.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/ec16c9863aa710ab4101208bd7eebc89d316fecb/23983/images/homekit_thermostat/breadboard.jpeg" alt="Fully wired breadboard">
<img src="https://d33wubrfki0l68.cloudfront.net/81db446d96ed6124330e190aba1321f981d07adc/8d0da/images/homekit_thermostat/wall_taped.jpeg" alt="Breadboard taped to wall"></p>

<p>After wiring it all together, and taping it to my wall for a day or two, I was
satisfied with the components, and wanted to get started on prettying it up a bit.</p>



<h2 id="the-code">The code</h2>

<p>The thermostat control runs on a pretty simple state machine. I am a big fan of
drawing things out ahead of time, so I drew this diagram for myself before coding.
In C this is implemented as two enums (actions, states) and a bunch of switch case
statements.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/6d7680c909d72c389d076e0390408d1e44382733/c2055/images/homekit_thermostat/state_machine.png" alt="State machine for thermostat control"></p>

<p id="expand_model_code">Click Here to toggle the code</p>
<div id="model_code">
<pre><code>// Enums:

typedef enum {
    TC_HEATER_MODE_OFF,
    TC_HEATER_MODE_ON,
    TC_HEATER_MODE_AUTO_ON,
    TC_HEATER_MODE_AUTO_OFF
} tc_heater_mode_t;

typedef enum {
    TC_HEATER_ACTIONS_SET_TO_AUTO,
    TC_HEATER_ACTIONS_SET_TO_OFF,
    TC_HEATER_ACTIONS_SET_TO_ON,
    TC_HEATER_ACTIONS_TEMPERATURE_CHANGE,
    TC_HEATER_ACTIONS_THRESHOLD_CHANGE
} tc_heater_action_t;

// ... Somewhere else:

switch (s_current_heater_mode) {
    case TC_HEATER_MODE_OFF:
        switch(tc_action) {
            case TC_HEATER_ACTIONS_SET_TO_AUTO:
                s_current_heater_mode = TC_HEATER_MODE_AUTO_OFF;
                s_current_heater_mode = tc_update_auto_mode(s_current_heater_mode);
                break;
            case TC_HEATER_ACTIONS_SET_TO_OFF:
                break;
            case TC_HEATER_ACTIONS_SET_TO_ON:
                s_current_heater_mode = TC_HEATER_MODE_ON;
                break;
            case TC_HEATER_ACTIONS_TEMPERATURE_CHANGE:
                break;
            case TC_HEATER_ACTIONS_THRESHOLD_CHANGE:
                break;
        }
        break;
    case TC_HEATER_MODE_ON:
        switch(tc_action) {
            case TC_HEATER_ACTIONS_SET_TO_AUTO:
                s_current_heater_mode = TC_HEATER_MODE_AUTO_ON;
                s_current_heater_mode = tc_update_auto_mode(s_current_heater_mode);
                break;
            case TC_HEATER_ACTIONS_SET_TO_OFF:
                s_current_heater_mode = TC_HEATER_MODE_OFF;
                break;
            case TC_HEATER_ACTIONS_SET_TO_ON:
                break;
            case TC_HEATER_ACTIONS_TEMPERATURE_CHANGE:
                break;
            case TC_HEATER_ACTIONS_THRESHOLD_CHANGE:
                break;
        }
        break;
    case TC_HEATER_MODE_AUTO_ON:
    case TC_HEATER_MODE_AUTO_OFF:
        switch(tc_action) {
            case TC_HEATER_ACTIONS_SET_TO_AUTO:
                break;
            case TC_HEATER_ACTIONS_SET_TO_OFF:
                s_current_heater_mode = TC_HEATER_MODE_OFF;
                break;
            case TC_HEATER_ACTIONS_SET_TO_ON:
                s_current_heater_mode = TC_HEATER_MODE_ON;
                break;
            case TC_HEATER_ACTIONS_TEMPERATURE_CHANGE:
                s_current_heater_mode = tc_update_auto_mode(s_current_heater_mode);
                break;
            case TC_HEATER_ACTIONS_THRESHOLD_CHANGE:
                s_current_heater_mode = tc_update_auto_mode(s_current_heater_mode);
                break;
        }
        break;
}</code></pre>
</div>

<p>It was very important to me that the thermostat worked on homekit, thankfully
there are already great homekit (hap) resources for the esp32. After some digging
I decided on this homekit package, as itâ€™s a clean port of the expressif homekit
library to arduino. There are about 15 different homekit frameworks for arduino,
so at some point I just had to choose one and start running.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/09e7eb514a6c9878988e3897b1f9377a39d331c7/9fc55/images/homekit_thermostat/homekit.jpeg" alt="Homekit screenshot showing thermostat"></p>

<p>After a whole bunch of fucking around I managed to get my esp32 to show up as a thermostat from my phone.</p>

<p>A few gotchaâ€™s that I encountered along the way: (some specific to this library, some specific to homekit)</p>

<ul>
  <li>With this HomeKit library if you want to factory reset, you have to do it <em>after</em> you initialize. Also be sure to remove the device from homekit on your phone before factory resetting the device</li>
  <li>Be sure that you have unique id and pairing codes for your device, I have another esp32 on my homekit and they kept colliding</li>
  <li>Be sure that your device cid matches with the services you are providing, otherwise you will get annoying silent failures from homekit</li>
</ul>



<h2 id="making-things-pretty">Making things pretty</h2>

<p>After getting the code into a place I liked, all that was left was to make it
look less like a bomb strapped to my living room wall. I 3d printed an enclosure,
and soldered the correct wires in the correct places. Unfortunately my board
requires constant a 5V micro-usb power source, so as of right now I have it
powered off of a huge battery pack. Maybe in vN (for very large values of N)
I will go nest style with an internal LiPo and an AC-DC converter.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/da9845e5838dba97dbae170da8ae49eb191c9b6f/089ad/images/homekit_thermostat/soldered.jpeg" alt="Soldered together">
<img src="https://d33wubrfki0l68.cloudfront.net/a2686592824334db4590b4affc52e706eb1acd91/cfae7/images/homekit_thermostat/enclosure.jpeg" alt="3d printed enclosure">
<img src="https://d33wubrfki0l68.cloudfront.net/3d6c45942a18d64daa989a8b0baf0f3ab706a833/aa250/images/homekit_thermostat/pretty.jpeg" alt="Enclosure mounted to wall and plugged in"></p>



<h2 id="whats-next">Whatâ€™s Next?</h2>

<p>I have already bought a few parts for a planned v2, so stay tuned. In v2 I will be adding:</p>

<ul>
  <li>New thermometer board (Going to use this overpriced adafruit breakout here <a href="https://www.amazon.com/gp/product/B00OKCQX96/ref=ppx_yo_dt_b_asin_title_o00_s00?ie=UTF8&amp;psc=1">https://www.amazon.com/gp/product/B00OKCQX96/ref=ppx_yo_dt_b_asin_title_o00_s00?ie=UTF8&amp;psc=1</a>)</li>
  <li>Adding a small status display OLED screen <a href="https://www.amazon.com/gp/product/B0833PF7ML/ref=ppx_yo_dt_b_asin_title_o01_s03?ie=UTF8&amp;psc=1">https://www.amazon.com/gp/product/B0833PF7ML/ref=ppx_yo_dt_b_asin_title_o01_s03?ie=UTF8&amp;psc=1</a></li>
  <li>Add a few buttons to allow non-phone control of the device <a href="https://www.amazon.com/gp/product/B0722LBKV7/ref=ppx_yo_dt_b_asin_title_o01_s00?ie=UTF8&amp;psc=1">https://www.amazon.com/gp/product/B0722LBKV7/ref=ppx_yo_dt_b_asin_title_o01_s00?ie=UTF8&amp;psc=1</a></li>
</ul>

<div>
    <p>

    Thanks for reading! If you want to stay updated feel free to follow the <a href="https://staycaffeinated.com/feed.xml">RSS feed</a>, if you have any suggestions feel free to email me at <a href="mailto:mdl0394@gmail.com">mdl0394@gmail.com</a></p><p>
    

    You could also submit your email here, and I will personally email you whenever I post new things:

    </p>
</div>

<h2 id="parts-used--other-references">Parts used / Other references</h2>

<ul>
  <li>Way too big of a relay: <a href="https://www.amazon.com/gp/product/B07KXNCL91/ref=ppx_yo_dt_b_asin_title_o08_s00?ie=UTF8&amp;psc=1">https://www.amazon.com/gp/product/B07KXNCL91/ref=ppx_yo_dt_b_asin_title_o08_s00?ie=UTF8&amp;psc=1</a></li>
  <li>ESP32 Doit Devkit v1 boards: <a href="https://www.amazon.com/gp/product/B07Q576VWZ/ref=ppx_yo_dt_b_asin_title_o08_s01?ie=UTF8&amp;psc=1">https://www.amazon.com/gp/product/B07Q576VWZ/ref=ppx_yo_dt_b_asin_title_o08_s01?ie=UTF8&amp;psc=1</a></li>
  <li>HomeKit framework esp-homekit-arduino-sdk <a href="https://github.com/Brawrdon/esp-homekit-arduino-sdk?utm_source=platformio&amp;utm_medium=piohome">https://github.com/Brawrdon/esp-homekit-arduino-sdk?utm_source=platformio&amp;utm_medium=piohome</a></li>
</ul>

    </div>
</div></div>]]>
            </description>
            <link>https://www.staycaffeinated.com/2020/12/27/building-my-own-homekit-thermostat-v1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25552889</guid>
            <pubDate>Sun, 27 Dec 2020 18:06:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Java Gotchas: SortedSet ignores the equals method]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25552829">thread link</a>) | @excerionsforte
<br/>
December 27, 2020 | https://yesday.github.io/blog/2018/java-gotchas-sorted-set-ignores-the-equals-method.html | <a href="https://web.archive.org/web/*/https://yesday.github.io/blog/2018/java-gotchas-sorted-set-ignores-the-equals-method.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
  <p>Consider the below code which creates a <code>SortedSet</code> using a comparator based on string length</p> 
  <div> 
   <div> 
    <pre><code data-lang="java">public class SortedSetTest {
    public static void main(String[] args) {
        SortedSet&lt;String&gt; sortedSet = new TreeSet&lt;&gt;(Comparator.comparing(String::length));
        sortedSet.addAll(Set.of("aa", "bb"));
        System.out.println(sortedSet);
    }
}</code></pre> 
   </div> 
  </div> 
  <p>The output of the above is</p> 
   
  <p>While I would expect</p> 
   
  <p>or</p> 
   
  <p>The <code>bb</code> element disappears, breaking the <code>Set</code> contract. The comparator is supposed to only sort the elements and not distinguish them from one another, which is what equals does in all the collections.</p> 
  <p>On the other hand, if I enhance the comparator to always return non-zero for unequal items like below, only then do I get the correct results.</p> 
  <div> 
   <div> 
    <pre><code data-lang="java">public class SortedSetTest {
    public static void main(String[] args) {
        SortedSet&lt;String&gt; sortedSet = new TreeSet&lt;&gt;(Comparator.comparing(String::length)
            .thenComparing(String::toString));
        sortedSet.addAll(Set.of("aa", "bb"));
        System.out.println(sortedSet);
    }
}</code></pre> 
   </div> 
  </div> 
  <p>The output now is <code>[aa, bb]</code> as I would expect.</p> 
  <p>The question is, why does <code>SortedSet</code> ignore the <code>equals</code> method in first place and removes an unequal object from the set?</p> 
  <p>The <code>comparator</code> method inside the <code>SortedSet</code> interface is <a href="https://docs.oracle.com/javase/10/docs/api/java/util/SortedSet.html">documented</a> as follows:</p> 
  <div> 
   <blockquote>
     Returns the comparator used to order the elements in this set, or null if this set uses the natural ordering of its elements. 
   </blockquote> 
  </div> 
  <p>The above indicates that the comparator is only used to order the elements in the set and not to distinguish them from one another, which is what <code>equals</code> is for in all the collections.</p> 
  <p>Digging into the <a href="https://docs.oracle.com/javase/10/docs/api/java/util/SortedSet.html">javadoc</a> further, it turns out that the above javadoc comment is incorrect, because there is another side note that contradicts it:</p> 
  <div> 
   <blockquote>
     Note that the ordering maintained by a sorted set (whether or not an explicit comparator is provided) must be consistent with equals if the sorted set is to correctly implement the Set interface. (See the Comparable interface or Comparator interface for a precise definition of consistent with equals.) This is so because the Set interface is defined in terms of the equals operation, but 
    <strong>a sorted set performs all element comparisons using its compareTo (or compare) method, so two elements that are deemed equal by this method are, from the standpoint of the sorted set, equal</strong>. The behavior of a sorted set is well-defined even if its ordering is inconsistent with equals; it just 
    <strong>fails to obey the general contract of the Set</strong> interface. 
   </blockquote> 
  </div> 
  <p>Note that, <a href="https://docs.oracle.com/javase/10/docs/api/java/util/Comparator.html">by definition</a>, consistent with equals means:</p> 
  <div> 
   <blockquote>
     The ordering imposed by a comparator c on a set of elements S is said to be consistent with equals if and only if c.compare(e1, e2)==0 has the same boolean value as e1.equals(e2) for every e1 and e2 in S. 
   </blockquote> 
  </div> 
 </div></div>]]>
            </description>
            <link>https://yesday.github.io/blog/2018/java-gotchas-sorted-set-ignores-the-equals-method.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25552829</guid>
            <pubDate>Sun, 27 Dec 2020 17:58:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SaaS We Happily Pay For]]>
            </title>
            <description>
<![CDATA[
Score 367 | Comments 175 (<a href="https://news.ycombinator.com/item?id=25552342">thread link</a>) | @frankdilo
<br/>
December 27, 2020 | https://francescodilorenzo.com/saas-we-pay-for | <a href="https://web.archive.org/web/*/https://francescodilorenzo.com/saas-we-pay-for">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>We try to run a lean operation at <a href="https://mailbrew.com/">Mailbrew</a>, but we are suckers for great tools that improve our daily workflows, so we pay for quite a few of them each month.</p>
<p>Being small (just 3 people), the cost of switching services is almost negligible, so we try new stuff regularly and do switch when we see a clear improvement.</p>
<p>Here is a list of everything we <em>happily</em> pay for.</p>
<h3><a href="https://missiveapp.com/">Missive</a></h3>
<p><strong>$15/month ⨉ 3 = $45/month.</strong></p>
<p>Collaborative email on top of G Suite. The main thing we pay for is a comment box below each email thread. It allows us to quickly discuss emails without forwarding or copy/pasting in Slack. It also allows us to edit drafts collaboratively and have multiple team inboxes for invoices, support, and other stuff.</p>
<p>We pay for the Productive plan because of one feature: Rules. They allow us to automatically categorize emails and be more granular with notifications. </p>
<h3><a href="https://www.notion.so/product">Notion</a></h3>
<p><strong>$8/month ⨉ 3 = $24/month.</strong></p>
<p>It's our team wiki. We write memos, meeting notes, drafts for blog posts, and everything that needs to be shared async for feedback. We also used to put tasks here but recently moved to Linear (more on this below).</p>
<p>It's an amazing value, but we were close to ditching it because of how slow it has become. We still have to find something that delivers the same great feature set and flexibility while improving speed and reliability.</p>
<h3><a href="https://linear.app/">Linear</a></h3>
<p><strong>$8/month ⨉ 3 = $24/month.</strong></p>
<p>We put our tasks here. It's a newcomer, but it's so good that we have already committed to it for a year. </p>
<p>It completely revolutionized the way we work with its flexibility, speed, customizability, and great GitHub integration.</p>
<p>If you connect it to GitHub and open a pull request with a task-specific name, task and PR get linked. When the PR is merged, the task is automatically marked as done.</p>
<p>I would invest in this company if I had the chance. It's so much better than everything else I ever tried in this space.</p>
<h3><a href="https://vercel.com/">Vercel</a></h3>
<p><strong>$20/month ⨉ 3 = $60/month.</strong></p>
<p>Vercel deploys and hosts our frontends and serverless functions.</p>
<p>It's a bit pricier than we'd like, and the pricing does not really make sense. Why do we have to pay per team member instead of build minutes, bandwidth, and compute?</p>
<p>With all that being said, we love the product philosophy, simplicity, and integration with GitHub. Having automatic deploys for all commits, together with automatic task-linking to Linear for PRs, is code-review Nirvana.</p>
<h3><a href="https://savvycal.com/">SavvyCal</a></h3>
<p><strong>$12/month ⨉ 2 = $24/month.</strong></p>
<p>We use it to schedule our calls. It's a better Calendly, made by a solo indie developer that we're happy to support.</p>
<p>The product is super-intuitive, and its feature set is increasing at a great pace with features that massively improve our workflows.</p>
<h3><a href="https://plausible.io/">Plausible Analytics</a></h3>
<p><strong>$12/month.</strong></p>
<p>It's a privacy-focused website analytics tool that replaces Google Analytics.</p>
<p>The most impressive thing is how better the insights we get from it are, thanks to some great UX, despite its privacy-respecting stance.</p>
<p>No surprise, they have been <a href="https://www.indiehackers.com/product/plausible-insights">growing like crazy</a>.</p>
<h3><a href="https://mailbrew.com/">Mailbrew</a></h3>
<p><strong>$10/month.</strong></p>
<p>We pay for this, even if we are the ones making it, to test our Stripe Integration.</p>
<p>We use Mailbrew to receive a couple of digests with dedicated Twitter Searches that keep us updated on social mentions of our product.</p>
<h3><a href="https://super.so/">Super</a></h3>
<p><strong>$12/month.</strong></p>
<p>This turns Notion documents into their own websites with a dedicated domain. We use it for our <a href="https://mailbrew.com/press">press kit</a> and <a href="https://help.mailbrew.com/">support docs</a>.  </p>
</article></div>]]>
            </description>
            <link>https://francescodilorenzo.com/saas-we-pay-for</link>
            <guid isPermaLink="false">hacker-news-small-sites-25552342</guid>
            <pubDate>Sun, 27 Dec 2020 16:59:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remembering the Nanjing Massacre]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25552140">thread link</a>) | @Beggers1960
<br/>
December 27, 2020 | https://ramblinghistory.co.uk/2020/12/11/nanjing-massacre-remembered/ | <a href="https://web.archive.org/web/*/https://ramblinghistory.co.uk/2020/12/11/nanjing-massacre-remembered/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-449">

	<!-- .entry-header -->

	<div>
		


<p><img loading="lazy" data-attachment-id="464" data-permalink="https://ramblinghistory.co.uk/2020/12/11/nanjing-massacre-remembered/ija_10th_army_entering_nanking/" data-orig-file="https://rossk1992.files.wordpress.com/2020/12/ija_10th_army_entering_nanking.jpg" data-orig-size="950,633" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="IJA_10th_Army_entering_Nanking" data-image-description="" data-medium-file="https://rossk1992.files.wordpress.com/2020/12/ija_10th_army_entering_nanking.jpg?w=300" data-large-file="https://rossk1992.files.wordpress.com/2020/12/ija_10th_army_entering_nanking.jpg?w=748" src="https://rossk1992.files.wordpress.com/2020/12/ija_10th_army_entering_nanking.jpg" alt="Nanjing Massacre" width="748" height="498" srcset="https://rossk1992.files.wordpress.com/2020/12/ija_10th_army_entering_nanking.jpg?w=748&amp;h=498 748w, https://rossk1992.files.wordpress.com/2020/12/ija_10th_army_entering_nanking.jpg?w=150&amp;h=100 150w, https://rossk1992.files.wordpress.com/2020/12/ija_10th_army_entering_nanking.jpg?w=300&amp;h=200 300w, https://rossk1992.files.wordpress.com/2020/12/ija_10th_army_entering_nanking.jpg?w=768&amp;h=512 768w, https://rossk1992.files.wordpress.com/2020/12/ija_10th_army_entering_nanking.jpg 950w" sizes="(max-width: 748px) 100vw, 748px"></p>
<p>In 1937, before a shot was even fired in Europe, Imperial Japanese forces were engaged in a long, bloody conflict in China – and it is during this period that we catch a glimpse of the atrocities that would stain the 1940s.&nbsp;</p>
<p>The event, or series of events, we are looking at today is the Japanese occupation of Nanjing, commonly referred to as the ‘Rape of Nanjing’.</p>



<p>Anyone with a modicum of knowledge on the Second World War will know of the atrocities committed by Imperial Japanese forces. Their atrocious treatment of PoW’s and civilians throughout South East Asia, Oceania and China are well documented. Several years before those times however, when Japanese forces entered Nanjing, they let loose upon the people there.</p>
<h4>Crashing dominoes&nbsp;</h4>
<p>In the weeks preceding the Japanese occuptation of Nanjing, there had been bloody fighting between Chinese forces and Imperial Japanese troops. Indeed, for several years, the Imperial Japanese Army had been involved in a tit-for-tat conflict against both Communist and nationalist Chinese forces.</p>
<p>In August 1937, the <a href="https://en.wikipedia.org/wiki/Battle_of_Shanghai" target="_blank" rel="noopener">Battle of Shangai</a> set into motion a series of events that would lead to disaster for Chinese forces and civilians throughout the country. The Battle of Shanghai was a visceral, bloody engagement for both sides. However, by mid-November, Imperial Japanese forces had captured and subjugated the area.&nbsp;</p>
<figure data-shortcode="caption" id="attachment_462" aria-describedby="caption-attachment-462"><img loading="lazy" data-attachment-id="462" data-permalink="https://ramblinghistory.co.uk/2020/12/11/nanjing-massacre-remembered/japanese_marines_during_the_battle_of_shanghai_1937/" data-orig-file="https://rossk1992.files.wordpress.com/2020/12/japanese_marines_during_the_battle_of_shanghai_1937.jpg" data-orig-size="510,352" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Japanese_marines_during_the_Battle_of_Shanghai,_1937" data-image-description="" data-medium-file="https://rossk1992.files.wordpress.com/2020/12/japanese_marines_during_the_battle_of_shanghai_1937.jpg?w=300" data-large-file="https://rossk1992.files.wordpress.com/2020/12/japanese_marines_during_the_battle_of_shanghai_1937.jpg?w=510" src="https://rossk1992.files.wordpress.com/2020/12/japanese_marines_during_the_battle_of_shanghai_1937.jpg" alt="" width="510" height="352" srcset="https://rossk1992.files.wordpress.com/2020/12/japanese_marines_during_the_battle_of_shanghai_1937.jpg 510w, https://rossk1992.files.wordpress.com/2020/12/japanese_marines_during_the_battle_of_shanghai_1937.jpg?w=150&amp;h=104 150w, https://rossk1992.files.wordpress.com/2020/12/japanese_marines_during_the_battle_of_shanghai_1937.jpg?w=300&amp;h=207 300w" sizes="(max-width: 510px) 100vw, 510px"><figcaption id="caption-attachment-462">Japanese marines advance during the Battle of Shanghai.</figcaption></figure>
<p>Despite sustaining heavy casualities after weeks of fighting, Japanese forces of the Central China Area Army and 10th Army were ordered to capture the city of Nanjing and the surrounding area. The subsequent advance prompted hysteria among Chinese civilians and military forces, with thousands of the latter desperately trying to avoid capture.&nbsp;</p>
<h4>Cry havoc! and let slip the dogs of war</h4>







<p>Upon entering the city, Japanese forces appear to enter a feral state, abandoning all reason and humanity and embarking on a campaign of terror, abuse and murder against the people of the old Chinese capital.</p>



<p>A truly ghastly affair, and throughout we see sadistic methods and practices by Japanese troops. Groups of individuals were buried alive, some were burned alive, and the lucky ones were simply executed en-masse.</p>



<p>Beheadings were commonplace throughout this event, and there are accounts (although hotly debated) of ‘contests’ between Japanese officers to see who could behead 100 people in the shortest time.</p>





<p>In 1937, Japanese media covered the story of Toshiaki Mukai and Tsuyoshi Noda of the Japanese 16th Division, who were both vying to reach this goal of 100 beheadings. Throughout the course of the war these two men are alleged to have murdered over 300 people between them, and upon Japan’s surrender in 1945 the officers were tried and executed for war crimes.</p>



<p>While crimes were being committed against the civilian population, scores of Chinese prisoners of war were ruthlessly executed. The execution of prisoners of war were also particularly sadistic and brutal.</p>



<p>Countless PoW’s were hanged, shot and beheaded, with many more being buried alive alongside civilians. To this day the number of Chinese PoW’s executed is still unknown.</p>
<figure data-shortcode="caption" id="attachment_458" aria-describedby="caption-attachment-458"><img loading="lazy" data-attachment-id="458" data-permalink="https://ramblinghistory.co.uk/2020/12/11/nanjing-massacre-remembered/iwane_matsui_rides_into_nanjing/" data-orig-file="https://rossk1992.files.wordpress.com/2020/12/iwane_matsui_rides_into_nanjing.jpg" data-orig-size="498,360" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Iwane_Matsui_rides_into_Nanjing" data-image-description="" data-medium-file="https://rossk1992.files.wordpress.com/2020/12/iwane_matsui_rides_into_nanjing.jpg?w=300" data-large-file="https://rossk1992.files.wordpress.com/2020/12/iwane_matsui_rides_into_nanjing.jpg?w=498" src="https://rossk1992.files.wordpress.com/2020/12/iwane_matsui_rides_into_nanjing.jpg" alt="Nanking Massacre" width="498" height="360" srcset="https://rossk1992.files.wordpress.com/2020/12/iwane_matsui_rides_into_nanjing.jpg 498w, https://rossk1992.files.wordpress.com/2020/12/iwane_matsui_rides_into_nanjing.jpg?w=150&amp;h=108 150w, https://rossk1992.files.wordpress.com/2020/12/iwane_matsui_rides_into_nanjing.jpg?w=300&amp;h=217 300w" sizes="(max-width: 498px) 100vw, 498px"><figcaption id="caption-attachment-458">General Iwane Matsui rides into Nanjing.</figcaption></figure>
<h4>Accounts by westerners</h4>



<p>As hostilities had not yet erupted between western nations and Japan, there were a range of western civilians in the city during this event, and their accounts of the actions of Japanese soldiers are harrowing.</p>



<p>A surgeon, Robert O. Wilson, in the university hospital within the US safety zone, wrote home on several occasions detailing the events unfolding before his eyes.</p>



<p>“The slaughter of civilians is appalling. I could go on for pages telling of cases of rape and brutality almost beyond belief,” he wrote. “Two bayoneted corpses are the only survivors of seven street cleaners who were sitting in their headquarters when Japanese soldiers came in without warning and killed five of their number and wounded the two that found their way to the hospital.”</p>
<p>The Minnie Vautrin Diary detailing atrocities provides some of the most compelling and harrowing accounts of the Nanjing Massacre. Excerpts detailing what she witnessed can be found online, or the diary itself can be purchased.</p>



<p>In her diary she details the callous brutality of Japanese soldiers and, in particular, their treatment of Chinese women.</p>



<p>“A woman of almost 50 living down near San Pai Lou.&nbsp;She had three sons and two daughters-in-law. Four nights ago two soldiers came to the door at about 10pm, unable to push the door they forced their way in through a window and found themselves in Liu Lau Tai’s room.</p>





<p>“They demanded her daughters-in-law and when she refused and started to go for a military police they cut two gashes in her face and one in her heart.&nbsp;She died from these wounds.”</p>





<h4>Age old barbarism</h4>



<p>Japanese soldiers employed an age old weapon against the people of Nanjing, rape. Assault on women throughout the Nanjing Massacre were widespread and anywhere up to 20,000 women and girls were raped and brutalised.</p>







<p>John Rabe, leader of the Nanjing Safety Zone details his experiences in dealing with these cases during his time in the city.</p>



<p>“In one of the houses in the narrow street behind my garden wall, a woman was raped, and then wounded in the neck with a bayonet. I managed to get an ambulance so we can take her to Kulou Hospital.</p>





<p>“Last night up to 1,000 women and girls are said to have been raped, about 100 girls at Ginling College alone.</p>



<p>“You hear nothing but rape. If husbands or brothers intervene, they’re shot. What you hear and see on all sides is the brutality and bestiality of the Japanese soldiers.”</p>
<figure data-shortcode="caption" id="attachment_460" aria-describedby="caption-attachment-460"><img loading="lazy" data-attachment-id="460" data-permalink="https://ramblinghistory.co.uk/2020/12/11/nanjing-massacre-remembered/nanking_bodies_1937/" data-orig-file="https://rossk1992.files.wordpress.com/2020/12/nanking_bodies_1937.jpg" data-orig-size="800,559" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Nanking_bodies_1937" data-image-description="" data-medium-file="https://rossk1992.files.wordpress.com/2020/12/nanking_bodies_1937.jpg?w=300" data-large-file="https://rossk1992.files.wordpress.com/2020/12/nanking_bodies_1937.jpg?w=748" src="https://rossk1992.files.wordpress.com/2020/12/nanking_bodies_1937.jpg" alt="Nanjing Massacre" width="748" height="523" srcset="https://rossk1992.files.wordpress.com/2020/12/nanking_bodies_1937.jpg?w=748&amp;h=523 748w, https://rossk1992.files.wordpress.com/2020/12/nanking_bodies_1937.jpg?w=150&amp;h=105 150w, https://rossk1992.files.wordpress.com/2020/12/nanking_bodies_1937.jpg?w=300&amp;h=210 300w, https://rossk1992.files.wordpress.com/2020/12/nanking_bodies_1937.jpg?w=768&amp;h=537 768w, https://rossk1992.files.wordpress.com/2020/12/nanking_bodies_1937.jpg 800w" sizes="(max-width: 748px) 100vw, 748px"><figcaption id="caption-attachment-460">Bodies littered the shore of the Qinhuai River.</figcaption></figure>



<h4>Relenting troops</h4>



<p>In January of 1938, after several weeks of bloodletting, refugees within the safety zones were ordered to return to their homes.</p>



<p>Japanese officials claimed at the time that ‘order had been restored’ and that daily life were to continue as normal. For the people of Nanjing subjected to relentless bouts of violence, however, life would never be the same again.</p>



<p>As order was gradually restored, the frequency of attacks and atrocities did dissipate.</p>
<h4>Guilt</h4>



<p>General Iwane Matsui, leader of the Japanese Expeditionary Force in China, began to realise the extent of the atrocities being committed by his men in Nanjing – albeit too late.</p>



<p>Speaking of his knowledge on the atrocities being committed, he is claimed to have stated to an aide:</p>



<p>“I now realise that we have unknowingly wrought a most grievous effect on this city. When I think of the feelings and sentiments of many of my Chinese friends who have fled from Nanjing and of the future of the two countries, I cannot but feel depressed.</p>



<p>“I am very lonely and can never get in a mood to rejoice about this victory … I personally feel sorry for the tragedies to the people, but the Army must continue unless China repents.</p>



<p>“Now, in the winter, the season gives time to reflect. I offer my sympathy, with deep emotion, to a million innocent people.”</p>



<p>Although an apparent admission of guilt on his part, Matsui’s lack of action on the issue, his burying of the head in sand, simply allowed the ordeal to continue far longer than it did.</p>



<p>Matsui was recalled to Japan following the massacre and retired. Upon Japan’s surrender in 1945, he was tried by the International Military Tribunal for the Far East and is executed.</p>



<h4>Aftermath</h4>



<p>The death toll in Nanjing is debated. Contemporary Japanese statistics could be considered laughable, amounting to only several hundred dead. A range of sources estimate that anywhere between 30,000 to 300,000 people were murdered during this month-long tirade of violence.</p>
<p>Modern Chinese sources (in particular the Chinese Government) claim that these numbers range even higher and are, in fact, closer to half-a-million.</p>




<p>The Nanjing War Crimes Tribunal in 1947 stated:</p>



<p>“More than 190,000 mass slaughtered civilians and Chinese soldiers killed by machine gun by the Japanese army, whose corpses have been burned to destroy proof.</p>



<p>“Besides, we count more than 150,000 victims of barbarian acts buried by the charity organisations. We thus have a total of more than 300,000 victims.”</p>



<p>Researchers state that the death toll numbers between 40,000 and 60,000 based on a number of sources from the time, including Red Army statistics and the Nanjing Safety Zone committee.</p>



<p>Regardless of the true number of casualties, the barbarism and horrific nature of this event are beyond comprehension. The callous behaviour of Japanese soldiers is a stain on the tapestry of 20th century history, and this behaviour continued for another several years until Japanese capitulation in the wake of Hiroshima &amp; Nagasaki.</p>


			
			
						</div><!-- .entry-content -->

	<!-- .entry-footer -->

</article></div>]]>
            </description>
            <link>https://ramblinghistory.co.uk/2020/12/11/nanjing-massacre-remembered/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25552140</guid>
            <pubDate>Sun, 27 Dec 2020 16:36:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A New Google]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25552030">thread link</a>) | @smusamashah
<br/>
December 27, 2020 | https://dcgross.com/a-new-google | <a href="https://web.archive.org/web/*/https://dcgross.com/a-new-google">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>   <p>[TL;DR: Google has gotten bad; we all know it; ideas for a startup making a better Google.]</p> <p>In 2000, Google got popular because hackers realized it was better than Lycos or Excite. This effect is happening again. Early adopters aren’t using Google anymore.</p> <p>They aren’t using DuckDuckGo either. They’re still using Google.com, but differently. To make Google usable, users are adding faux-query modifiers that to supress the “garbage Internet”.</p> <p>You see this in the typeahead logs.</p> <p><img src="https://dcgross.com/assets/new-google/image6.png" alt=""> <em></em></p><center><em>Products (Reddit)</em></center> <p><img src="https://dcgross.com/assets/new-google/image4.png" alt=""> <em></em></p><center><em>Services (Reddit, Yelp)</em></center> <p><img src="https://dcgross.com/assets/new-google/image1.png" alt=""> <em></em></p><center><em>Movies (Rotten Tomatoes)</em></center> <p><img src="https://dcgross.com/assets/new-google/image5.png" alt=""> <em></em></p><center><em>Even code (Github)</em></center> <p>Interestingly, this doesn’t work for all categories. <img src="https://dcgross.com/assets/new-google/image3.png" alt=""> <img src="https://dcgross.com/assets/new-google/image2.png" alt=""> <em></em></p><center><em>Recipes don’t have a “Reddit” equivalent</em></center> <h3 id="query-operators-mean-somethings-broken">Query Operators Mean Something’s Broken</h3> <p>More advanced users use modifiers like <code>site: filetype: intitle:</code> because adding “reddit” isn’t strict enough, as spammy websites often manipulate content to win SEO.</p> <p>How about those websites that stuff the year in the title? “Reviews UPDATED JANUARY 2020” are exploiting the fact that customers suffix queries with the year. What those people are trying to command is freshness, not a title match.</p> <p>Something’s broken, and a tiny share of Google is open for the taking. Obviously attacking incumbents head-on doesn’t work. Here are two alternative ideas for bootstrapping next-generation search:</p> <h3 id="1-boogle-a-query-reformulator">#1 Boogle, A Query Reformulator</h3> <p>Introducing Boogle, a proxy for Google that’s just Better Google Search. It’s a query expander. We predict the correct operators for your query, proxy Google’s results, and serve. For example:</p> <p><code>query("stripe.js example") -&gt; query("stripe.js example (site:github.com OR site:gitlab.com OR site:..."))</code></p> <p><code>query("is anker charger") -&gt; query("is anker charger (inurl:forum OR site:reddit.com OR ...))"</code></p> <p>Query topic modeling is a rich science with plenty of examples.</p> <p>You’d almost as fast as Google, never worse, and occasionally better. This will help build the reflex to use you instead. This approach isn’t that hard to get started with, and might work for the high-end users.</p>  <p>You could go after this vertical by vertical – build the <em>best</em> site for electric product search, for travel, for code, etc. A key question is how to build habitual recall to use your product over Google. Amazon and Airbnb both enjoy a huge amount of direct traffic. Some learnings from those:</p> <ul> <li><strong>Stellar mobile destination.</strong> Using Airbnb directly feels more fluid and fun than using Google for Airbnb.</li> <li><strong>The 90% Rule.</strong> To build reflex you need to give me what I want most of the time.** **With Prime, Amazon made it such that we stopped price comparing across other sites; Amazon would get it to us fastest, and that turns out to matter more than price. Most of the time you open Amazon.app, it satisfies.</li> <li><strong>Come for search, stay for something else.</strong> I don’t think of Airbnb or Amazon as search apps. They help me get things or book homes. You might want to your search app to be a destination for something else. This is where I think community comes in.</li> </ul> <p>Picking a vertical that <em>doesn’t</em> have strong typeahead completions[1] would help you build community around your search engine. Recipes, fitness, fashion, etc. don’t have decacorn conglomerates like Github or Reddit. That might mean it’s easier to build community around them, and put your flagship search engine on top.</p> <hr> <p>If you’re working on this kind of stuff, try out <a href="https://pioneer.app/">Pioneer</a> or just shoot me an email – daniel@pioneer.app.</p> <hr> <p>[1] In reality I’d pick the vertical _I _love most. If you’re a guitar player start with music; a movie buff should build better Rotten Tomatos. Etc.</p> </article></div>]]>
            </description>
            <link>https://dcgross.com/a-new-google</link>
            <guid isPermaLink="false">hacker-news-small-sites-25552030</guid>
            <pubDate>Sun, 27 Dec 2020 16:23:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unexpected Bad Things Will Happen If You Don’t Read This]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25552016">thread link</a>) | @ropsii
<br/>
December 27, 2020 | https://www.petarperovic.com/blog/friction/ | <a href="https://web.archive.org/web/*/https://www.petarperovic.com/blog/friction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
                    <time datetime="2020-12-27T09:10:00+00:00" itemprop="datePublished">Dec 27, 2020
                    </time>
                    ·
                    
                    
                    2 min.
                     read
                </p><div itemprop="articleBody">
                    <p>One of the core ideas of interaction design is to enable users to glide smoothly to their destination with as little friction as possible. To make people experience the software as an extension of their brain, and not something to continually wrestle with and domesticate.</p>

<p>Great products ask nothing from you on the first interaction. They’ll let you in and experiment without requiring anything upfront, not even your email address. Usually, until you need to save something. Hoping that, by that moment, they succeeded at demonstrating their value. That’s how removing friction, or only slightly delaying it, gives you a head start on the competition.</p>

<p><img src="https://www.petarperovic.com/assets/friction-github_delete.png" alt="Delete repository on GitHub screen">
<em>This is the exact copy I borrowed from GitHub for the title of this article. When you try to delete a repository, GitHub will force you to correctly type its name, making sure you know what you’re doing.</em></p>

<p>However, there are situations where you deliberately want to make interaction less convenient for users’ benefit. When you purposely want to make them stop and think. Typically when they’re about to perform a potentially destructive action or/and an operation that affects other people in the system. For example, to prevent them from accidentally deleting a project shared between many people and forever losing everyone’s important work. That’s where adding friction saves you from shooting yourself in the foot. As a rule of thumb, whenever there’s a potential of users harming themselves — add friction.</p>

<p>Friction is, however, often abused to deliberately confuse and exploit human anxiety when interacting with computers. Airlines’ websites will routinely scare you into buying garbage services you don’t need. Facebook will emotionally manipulate you if you try to erase it from your life. They’ll try to change your mind through the multi-page process where they’ll show you photos of the family and friends you’ll be missing as if they’d all be dead the moment you delete the account. Likewise, it’s widespread for products to complicate subscription cancellation for no reason, foolishly making users even more aggravated. These are all examples of adding friction in bad faith.</p>

<p>Physical world is also full of deliberately added friction, usually to prevent people from making dumb mistakes. Streets around schools slow down traffic with physical obstacles and flashing signals to protect little humans from deadly, fast-moving machines. Modern cars will poke you with annoying noise to fasten your seatbelt, dramatically increasing your chances of survival in case of an accident. Automatic sliding doors remove friction to increase the flow of people in high traffic, commercial buildings. Preventing the formation of queues, but also helping to maintain the temperature of the building. And so on…</p>

<p>At every point of human interaction with digital or physical interfaces, there’s friction. I find it incredibly useful to think about interaction design as adjusting friction, thus controlling the heartbeat of communication between humans and machines.</p>

                </div></div>]]>
            </description>
            <link>https://www.petarperovic.com/blog/friction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25552016</guid>
            <pubDate>Sun, 27 Dec 2020 16:20:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Docker and Python]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25551892">thread link</a>) | @jajjarax
<br/>
December 27, 2020 | https://matteoguadrini.github.io/posts/containerized-python-development/ | <a href="https://web.archive.org/web/*/https://matteoguadrini.github.io/posts/containerized-python-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main" id="main">
        

<div>
  <div>
    <p>Containerized Python Development</p>
  </div>
  
</div>
<article>
  
  <section>
    <p><img src="https://i.morioh.com/9ccb7b143f.png" alt="docker and python"></p>

<p>When we develop more than one python project, we need to configure our development environment with the dependencies of all the projects. This becomes even more complicated when there are many people on the development of the project.
To do this, you need to create a development environment that is isolated from the others. We can do this thanks to <strong>docker</strong> containers.</p>
<h2 id="prepare-project">Prepare project</h2>
<p>Let’s imagine that our project has this structure:</p>
<pre><code data-lang="console">pydk
├─── requirements.txt
└─── src
     └─── server.py
</code></pre><p>We now think that our project may depend on some external libraries, such as <strong>Flask</strong>. Let’s prepare a file called <em>requirements.txt</em> with a line inside it: <code>Flask==1.1.2</code></p>
<p>While our <em>server.py</em> application, it will be a simple Flask application like the following:</p>
<div><pre><code data-lang="python"><span>from</span> <span>flask</span> <span>import</span> <span>Flask</span>
<span>server</span> <span>=</span> <span>Flask</span><span>(</span><span>__name__</span><span>)</span>

<span>@server.route</span><span>(</span><span>"/"</span><span>)</span>
<span>def</span> <span>hello_docker</span><span>():</span>
    <span>return</span> <span>"Hello docker!"</span>

<span>if</span> <span>__name__</span> <span>==</span> <span>"__main__"</span><span>:</span>
   <span>server</span><span>.</span><span>run</span><span>(</span><span>host</span><span>=</span><span>'0.0.0.0'</span><span>)</span>
</code></pre></div><p>Now, we can run and continue to develop this project locally, but if we had other projects with requirements that would conflict, we would break this or other projects.
So, let’s see how we can isolate this project inside a container that is the same for all the developers who are going to develop.</p>
<h2 id="prepare-dockerfile">Prepare dockerfile</h2>
<p>Now we need to create a <em>Dockerfile</em> (<code>pydk/Dockerfile</code>) that contains suitable instructions to build our container so that it can execute our python code.</p>
<div><pre><code data-lang="dockerfile"><span># base image</span><span>
</span><span></span><span>FROM</span><span> python:3.9</span><span>
</span><span>
</span><span></span><span># working directory in the container</span><span>
</span><span></span><span>WORKDIR</span><span> /pydk</span><span>
</span><span>
</span><span></span><span># copy the dependencies file to the working directory</span><span>
</span><span></span><span>COPY</span> requirements.txt .<span>
</span><span>
</span><span></span><span># install dependencies</span><span>
</span><span></span><span>RUN</span> pip install -r requirements.txt<span>
</span><span>
</span><span></span><span># copy the content of the local src directory to the working directory</span><span>
</span><span></span><span>COPY</span> src/ .<span>
</span><span>
</span><span></span><span># command to run on container start</span><span>
</span><span></span><span>CMD</span> <span>[</span> <span>"python"</span><span>,</span> <span>"./server.py"</span> <span>]</span><span>
</span></code></pre></div><p>Now we run the command to build our image. When docker builder kicks in, you can see all the steps we wrote in our dockerfile:</p>
<pre><code data-lang="console">$ docker build -t mypy .
Sending build context to Docker daemon  4.608kB
Step 1/6 : FROM python:3.9
3.9: Pulling from library/python
6c33745f49b4: Pull complete 
ef072fc32a84: Pull complete 
c0afb8e68e0b: Pull complete 
d599c07d28e6: Pull complete 
f2ecc74db11a: Pull complete 
26856d31ce86: Pull complete 
a463ae07b5f3: Pull complete 
54f24c50f14e: Pull complete 
168ee6df05fe: Pull complete 
Digest: sha256:39c16d1a064c0239939d4ed52923b736c25b389e6ea439d5652b8fc9564ede76
Status: Downloaded newer image for python:3.9
 ---&gt; d1eef6fb8dbe
Step 2/6 : WORKDIR /pydk
 ---&gt; Running in ab2f8923ad12
Removing intermediate container ab2f8923ad12
 ---&gt; bad3fb87e418
Step 3/6 : COPY requirements.txt .
 ---&gt; eade175d7095
Step 4/6 : RUN pip install -r requirements.txt
 ---&gt; Running in de2b7fcd2c6d
Collecting Flask==1.1.2
  Downloading Flask-1.1.2-py2.py3-none-any.whl (94 kB)
Collecting click&gt;=5.1
  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)
Collecting itsdangerous&gt;=0.24
  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)
Collecting Jinja2&gt;=2.10.1
  Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)
Collecting MarkupSafe&gt;=0.23
  Downloading MarkupSafe-1.1.1.tar.gz (19 kB)
Collecting Werkzeug&gt;=0.15
  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)
Building wheels for collected packages: MarkupSafe
  Building wheel for MarkupSafe (setup.py): started
  Building wheel for MarkupSafe (setup.py): finished with status 'done'
  Created wheel for MarkupSafe: filename=MarkupSafe-1.1.1-cp39-cp39-linux_x86_64.whl size=32240 sha256=6fbda6c15fe2abefc6c8f4ec2ac66c421b1cf997c1a53a532a39bbebc8083860
  Stored in directory: /root/.cache/pip/wheels/e0/19/6f/6ba857621f50dc08e084312746ed3ebc14211ba30037d5e44e
Successfully built MarkupSafe
Installing collected packages: MarkupSafe, Werkzeug, Jinja2, itsdangerous, click, Flask
Successfully installed Flask-1.1.2 Jinja2-2.11.2 MarkupSafe-1.1.1 Werkzeug-1.0.1 click-7.1.2 itsdangerous-1.1.0
Removing intermediate container de2b7fcd2c6d
 ---&gt; 595ceaa19d29
Step 5/6 : COPY src/ .
 ---&gt; 98294355a272
Step 6/6 : CMD [ "python", "./server.py" ]
 ---&gt; Running in 1fb2a61f97ce
Removing intermediate container 1fb2a61f97ce
 ---&gt; 09fd1053a1c1
Successfully built 09fd1053a1c1
Successfully tagged mypy:latest
</code></pre><p>Let’s check the newly created image.</p>
<pre><code data-lang="console">$ docker images
REPOSITORY                         TAG                 IMAGE ID            CREATED             SIZE
mypy                               latest              09fd1053a1c1        15 minutes ago      896MB
python                             3.9                 d1eef6fb8dbe        8 days ago          885MB
</code></pre><h2 id="test-flask-on-docker">Test Flask on docker</h2>
<p>Now we can launch our image and test our application.</p>
<pre><code data-lang="console">$ docker run -d -p 5000:5000 mypy
487c215ec0cc2b44c1612c0aadbd3f1f47c32a0b29273da3dabf77351717852c

$ docker ps
CONTAINER ID        IMAGE               COMMAND                CREATED             STATUS              PORTS                    NAMES
487c215ec0cc        mypy                "python ./server.py"   28 seconds ago      Up 27 seconds       0.0.0.0:5000-&gt;5000/tcp   crazy_hermann

$ curl http://localhost:5000
Hello docker!
</code></pre><h2 id="conclusion">Conclusion</h2>
<p>We have created a small development environment for <strong>python</strong> application. Now, we can connect to our image and continue the development of the application without affecting our local environment.</p>

  </section>

  
</article>

      </div></div>]]>
            </description>
            <link>https://matteoguadrini.github.io/posts/containerized-python-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25551892</guid>
            <pubDate>Sun, 27 Dec 2020 16:04:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[mRNA Vaccines Are Not Going to Affect Your DNA]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25551645">thread link</a>) | @DSingularity
<br/>
December 27, 2020 | https://www.deplatformdisease.com/blog/no-really-mrna-vaccines-are-not-going-to-affect-your-dna | <a href="https://web.archive.org/web/*/https://www.deplatformdisease.com/blog/no-really-mrna-vaccines-are-not-going-to-affect-your-dna">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page" role="main">
        
          <article data-page-sections="5f9e10d41e3be610d6196a01" id="sections">
  
    <section data-test="page-section" data-section-theme="white-bold" data-section-id="5f9e10d41e3be610d6196a07" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
&quot;imageOverlayOpacity&quot;: 0.15,
&quot;video&quot;: {
  &quot;playbackSpeed&quot;: 0.5,
  &quot;filter&quot;: 1,
  &quot;filterStrength&quot;: 0,
  &quot;zoom&quot;: 0
},
&quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
&quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
&quot;customSectionHeight&quot;: 10,
&quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
&quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
&quot;contentWidth&quot;: &quot;content-width--wide&quot;,
&quot;customContentWidth&quot;: 50,
&quot;sectionTheme&quot;: &quot;white-bold&quot;,
&quot;sectionAnimation&quot;: &quot;none&quot;,
&quot;backgroundMode&quot;: &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      
      
      <div data-content-field="main-content" data-item-id="">
  <article id="article-">
  
    <div>
      

      <div>
        <div><div data-layout-label="Post Body" data-type="item" id="item-5fbbdf03aa206c671633c9e0"><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1607217371950_14759"><p><strong>The short version: </strong>There is no plausible way that mRNA vaccines are going to alter your DNA. It would violate basically everything we know about cell biology. </p></div><div data-block-type="5" id="block-yui_3_17_2_1_1606186906941_17376"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <div><p>Lodish H, Berk A, Kaiser C, Krieger M, Bretscher A, Ploegh H, Amon A, Martin K. Molecular cell biology. 8th ed. New York: W.H. Freeman; 2016. Figure 5-1</p><p>This figure is useful because you can clearly see the two compartments we care about: the nucleus, which houses almost all of the DNA (exception discussed), and the cytosol, which is where translation happens. </p></div>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606169203989_12470"><p>Recently, I’ve gotten an influx of questions about how we can really be sure that mRNA vaccines will not affect our DNA. In my <a href="https://www.deplatformdisease.com/blog/mrna-vaccines-and-covid-19">prior post</a> on the subject I wrote:</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1606369575380_12279"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Lodish H, Berk A, Kaiser C, Krieger M, Bretscher A, Ploegh H, Amon A, Martin K. Molecular cell biology. 8th ed. New York: W.H. Freeman; 2016. Figure 13-37B which demonstrates the export of mRNA from the nucleus.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606369635264_11375"><div><blockquote><p>Another concern raised has been the idea that mRNA can somehow alter the host’s genome. That would actually be super cool and be huge for gene therapy (and I could finally give myself the giant bat wings I’ve always wanted) but this is not so. This is ordinarily impossible except if there is also a reverse transcriptase enzyme present that produces DNA from the RNA template, which is how retroviruses work. There is no such risk with any mRNA vaccine candidate. mRNA vaccines act entirely within the cytosol of the cell- they do not go near the nucleus where all the DNA is. That’s actually a major advantage of RNA-based vaccines over DNA ones.</p></blockquote></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606177725054_56388"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Flint S, Racaniello V, Rall G, Skalka A, Enquist L. Principles of virology. Washington, DC: ASM Press; 2015. Figure 5.23C which shows the nuclear import cycle with influenza ribonucleoproteins as an example. Nucleear localization signals are recognized by importin-α which then recruits importin-β which recruits a small GTPase called Ran. When binding GDP, Ran is able to transport the RNP across the nuclear pore complex. The complex of importins and Ran will then dissociate, and a guanine nucleotide exchange factor will exchange GDP for GTP, that allows Ran-GTP to be exported out of the nucleus. RanGAP-1 or RanBPI, 2 can then catalyze hydrolysis of GTP to GDP which allows Ran to bind another importin-β to initiate the import cycle once more. </p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606190121308_43147"><div><p>I gave this response in large part because I felt that the detailed discussion of reverse transcription, nuclear trafficking, the endocytic pathway, and the other 11 or so advanced cell biology topics that I would have to invoke to give this a rigorous answer was too complex to be of benefit to the average person wanting to know simply whether or not this is possible. However, I had a flurry of questions about “what ifs” relating to retroviruses or hepadnaviruses (hepatitis B), and I can grant that this response doesn’t address that, so here I will attempt to answer that as explicitly and with minimal complexity as I am capable. </p><p>To simplify the discussion so as to avoid having to explain the <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4377075/">phases of phospholipid bilayers</a> and the molecular composition of the lipid nanoparticle as it relates to stability (discussed in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5439223/pdf/tde-07-319.pdf">1</a>, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6383180/pdf/main.pdf">2</a>, <a href="https://www.cell.com/action/showPdf?pii=S1525-0016%2819%2930041-3">3</a>, <a href="https://www.cell.com/action/showPdf?pii=S1525-0016%2819%2930053-X">4</a>), I will ask readers take for granted that mRNA vaccines are endocytosed and <a href="https://www.nature.com/articles/3301506.pdf">liberated</a> (<a href="https://pubs.acs.org/doi/pdf/10.1021/acsami.8b21398">and this</a>) into the cytoplasm of the cell. </p><p>Firstly, for mRNA to affect your DNA, at a minimum we need to establish that it would need to gain access to the DNA in question. There are two subcellular compartments where this can be accomplished. The first is the nucleus, so let’s start with a discussion of the trafficking of cargo in the nucleus. The nucleus of the cell is an isolated compartment with pore complexes (NPCs) that impose limits on the size of the particles that can freely enter. RNA is readily transported out as transcription occurs within the nucleus but the ribosomes required to produce proteins are in the cytosol or on the rough endoplasmic reticulum. This process is mediated by several accessory proteins which you can see to your right. Note however that there isn’t any physiological circumstance in which one might need RNA from the cytosol to be transported back to the nucleus. RNA is synthesized within the nucleus. Viruses which have a nuclear phase in their replication cycle have to have various tricks to be able to allow their RNA payload to enter. Though RNA is not readily transported into cells, proteins can be. This occurs via a network of proteins called importins (see figure 5-23C on the right). Proteins containing an amino acid sequence called the nuclear localization sequence (NLS; there are 2 common ones) are able to bind the importins, which can then transport them across the nuclear pore complex as shown on the right. RNA viruses often have replication cycles that do not require access to the nucleus, but there are some exceptions. <a href="https://jvi.asm.org/content/jvi/84/3/1254.full.pdf">Influenza viruses for example are RNA viruses that have their genomes associated with ribonucleoproteins, and these ribonucleoproteins express nuclear localization signals that facilitates the entry of their genomic RNA into the nucleus</a>. mRNA vaccines, on the other hand, are not associated with any proteins. Once inside the cytosol, the mRNA is naked and exposed to the harsh environment of ribosomes and exonucleases which destroy the mRNA in a matter of hours (at most). There is no conceivable mechanism by which mRNA can spontaneously be trafficked into the nucleus. Being made of nucleotides, it cannot contain a nuclear localization sequence. </p><p>The other relevant compartment would be the mitochondrion. Mitochondria are actually vestigial bacteria with their own genomes, and it’s thought that billions of years ago an ancient cell (probably an archaean- the cousins of bacteria) tried to consume the ancestor of the mitochondria but lacked the machinery to actually do the digesting and the two established a symbiotic relationship. Since that instance, the mitochondria have been an essential feature of our cell’s biologies. This allowed the mitochondria to develop an extremely reduced genome containing only<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5215404/pdf/PATH-241-236.pdf"> 37 genes</a> (most of the genes relevant to mitochondrial function are still in the nucleus). Mitochondria have their <a href="https://www.pnas.org/content/pnas/116/17/8283.full.pdf">own ribosomes</a> and even their own <a href="https://www.nature.com/articles/282189a0">genetic code</a> (sort of). There is also a specialized process for the clearance of diseased mitochondria called <strong>mitophagy, </strong>which is the subject of many excellent reviews e.g. <a href="https://www.nejm.org/doi/full/10.1056/NEJMoa2001265">this</a>, <a href="https://www.nature.com/articles/s41556-018-0176-2">this</a>, and <a href="https://www.cell.com/current-biology/pdf/S0960-9822(18)30006-X.pdf">this</a>. </p><p>The collective conclusion from our understanding of these biological process is that a naked mRNA in the cytosol has no potential to end up in a cellular compartment that contains our own DNA means that, irrespective of the presence or absence of other factors, there is no chance of harm to the DNA from the mRNA vaccine. But still people wanted to ask me about reverse transcriptases so let’s discuss those.</p><p>The process of going from RNA to DNA (the exact opposite of what the central dogma of molecular biology dictates) is known as <strong>reverse transcription</strong>, and it is carried out with an enzyme called a <strong>reverse transcriptase </strong>(which are a really interesting group of enzymes). In general, reverse transcription is performed by a few different genetic entities: <strong>retroviruses</strong>, <strong>hepadnaviruses</strong>, <strong>telomeres</strong>, and <strong>retrotransposons</strong>. These are worth defining. </p><ul data-rte-list="default"><li><p>Retroviruses are viruses who have an RNA genome, from which they create a DNA copy through reverse transcription that then integrates into the cell of the host (by which I mean, literally inserts itself into the host cell’s genome and becomes a permanent part of it, in the form of a sequence called a <strong>provirus</strong>). The proviral sequence itself can then be transcribed in the host cell to produce viral proteins and particles that can go on to spread to the next cell. The most famous retrovirus is HIV-1. </p></li><li><p>Hepadnaviruses are DNA viruses which have gapped genomes (there is one complete DNA strand and another partial DNA strand which is linked to a pregenomic RNA), and unlike retroviruses, do not integrate into the genome of the host cell they infect. The most famous example is Hepatitis B virus, for which multiple effective vaccines exist. </p></li><li><p>Telomeres are structures present at the ends of human chromosomes which are maintained by a protein complex called telomerase that uses a reverse transcriptase called TERT to maintain them. The reasons this is necessary are discussed below. They are about 5-15 kilobases long normally, and shortening results in arrest of cell growth and replication (senescence), or can even trigger cell death by apoptosis. </p></li></ul></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606152858324_15060"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Hartwell L, Goldberg M, Fischer J, Hood L. Genetics. 6th ed. New York: McGraw Hill; 2018. Table 13-2</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606228770446_31321"><div><ul data-rte-list="default"><li><p>Retrotransposons are actually the most abundant component of our genome. The human genome contains about 21,000-27,000 genes (the number you get depends on how precisely you define a gene and which source you consult), which span 40-48 million base pairs, but this accounts for only about 1.5% of the 3.2 billion total base pairs. Retrotransposons account for about …</p></li></ul></div></div></div></div></div></div></div></div></article></div></div></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.deplatformdisease.com/blog/no-really-mrna-vaccines-are-not-going-to-affect-your-dna">https://www.deplatformdisease.com/blog/no-really-mrna-vaccines-are-not-going-to-affect-your-dna</a></em></p>]]>
            </description>
            <link>https://www.deplatformdisease.com/blog/no-really-mrna-vaccines-are-not-going-to-affect-your-dna</link>
            <guid isPermaLink="false">hacker-news-small-sites-25551645</guid>
            <pubDate>Sun, 27 Dec 2020 15:28:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making Digital Todo Lists Better than Pen and Paper]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25551638">thread link</a>) | @vuciv1
<br/>
December 27, 2020 | https://jerseyfonseca.com/projects/bujo | <a href="https://web.archive.org/web/*/https://jerseyfonseca.com/projects/bujo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://jerseyfonseca.com/projects/bujo</link>
            <guid isPermaLink="false">hacker-news-small-sites-25551638</guid>
            <pubDate>Sun, 27 Dec 2020 15:27:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Conversation with Bruce Schneier [video]]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25551599">thread link</a>) | @sasvari
<br/>
December 27, 2020 | https://media.ccc.de/v/rc3-11473-conversation_with_bruce_schneier | <a href="https://web.archive.org/web/*/https://media.ccc.de/v/rc3-11473-conversation_with_bruce_schneier">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<div>

<p>
<span></span>
<a href="https://media.ccc.de/search?p=Bruce+Schneier">Bruce Schneier</a> and
<a href="https://media.ccc.de/search?p=frank">frank</a>

</p><p>
No content found (yet?).
</p>
<!-- %h3 About -->
<p>Live Conversation with Bruce Schneier. Audience questions can be submitted via chat and have a chance to be asked by moderator Frank Rieger.</p>

<p>Topics:
<br>• Actual and perceived role of cryptography in our world
<br>• The recent latest chapter in the eternal CryptoWars
<br>• Core problems of IT-security and why nobody solves them
<br>• The digital sphere as a freefire battlefield for state and nonstate actors
<br>• Technological, legal and political leverages to prevent total surveillance</p>

<h3>Download</h3>

<!-- %h3 Embed/Share -->

<h3>Tags</h3>

</div>





</div>]]>
            </description>
            <link>https://media.ccc.de/v/rc3-11473-conversation_with_bruce_schneier</link>
            <guid isPermaLink="false">hacker-news-small-sites-25551599</guid>
            <pubDate>Sun, 27 Dec 2020 15:21:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Become an ETH2 Validator?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25551514">thread link</a>) | @shubidubi
<br/>
December 27, 2020 | https://sagivo.com/crypto/2020/12/27/Etherum2-validator.html | <a href="https://web.archive.org/web/*/https://sagivo.com/crypto/2020/12/27/Etherum2-validator.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Ethereum is one of the leading crypto projects (second to bitcoin). In December 2020 Ethereum released the first stage of Ethereum 2.0. The biggest difference is that there is no need for an expensive calculation to validate blockchain transactions, miners can earn money only by staking their coins. This is a shift from proof-of-work to <a href="https://ethereum.org/en/eth2/staking">proof-of-stake</a>. You can read more on the vision <a href="https://ethereum.org/en/eth2/vision">here</a>.</p>

<h3 id="what-does-it-mean-for-you">What does it mean for you?</h3>

<p>If you want to “mine” eth you don’t need to invest in an expensive server farm anymore, all you need is to stake at least 32ETH and run the eth2 clients for as little as $10/month. In return you will earn passive income - currently, <a href="https://docs.google.com/spreadsheets/d/15tmPOvOgi3wKxJw7KQJKoUe-uonbYR6HF7u83LR5Mj4/edit#gid=842896204">around 10%</a>. The more people stake their eth the lower the interest rate will be. You can find the latest rate <a href="https://launchpad.ethereum.org/">here</a>.
In case you have at least 32ETH and you are OK to stake it for at least a year, probably more, until Ethereum reach their <a href="https://docs.ethhub.io/ethereum-roadmap/ethereum-2.0/eth-2.0-phases">next phase</a>, you can use this guide to learn how to do it.
This solution is great if you want to hold your ETH coins for 1-2 years and earn passive income by doing so.
<strong>This guide is for educational purposes only.</strong></p>

<h3 id="install-metamask">Install Metamask</h3>

<p>We will use Metamask as our ethereum wallet. You can install it from <a href="https://metamask.io/">here</a>. Do not lose the password and paraphrase for your wallet.<br>
After you finished installing your wallet, make sure you select the <code>goerli</code> (test) network.
<img src="https://sagivo.com/assets/ethereum-11.png" alt="Metamask Goerli"></p>

<h3 id="get-goerli">Get Goerli</h3>

<p>Since we are using the Goerli test network, we will need some coins to play with. To be a validator you will need ether. You can get test ether coins from <a href="https://faucet.goerli.mudit.blog/">here</a>. All you need is to tweet your <strong>goerli</strong> wallet address. Make sure you ask for at least 32 eth (the minimum for a validator node).</p>

<h3 id="become-eth2-validator">Become eth2 validator</h3>

<p>Go to the Ethereum 2.0 pyrmont (test) <a href="https://pyrmont.launchpad.ethereum.org/">launchpad site</a> and click on <code>GET STARTED</code>. Read all the warnings and information, make sure you understand them all.<br>
The next step is to <a href="https://pyrmont.launchpad.ethereum.org/select-client">select your client</a> - choose <a href="https://github.com/sigp/lighthouse">lighthouse</a>.<br>
Select how much eth you want to stake, 32 eth is the minimum.
You will also need to <a href="https://pyrmont.launchpad.ethereum.org/generate-keys">select your local machine’s operating system</a> to <a href="https://github.com/ethereum/eth2.0-deposit-cli/releases/">download the CLI</a>. In this post I use Mac, but you can choose whatever OS you use. Open and extract the CLI folder you downloaded from GitHub. Inside that folder, you will find a <code>deposit</code> file. Run this file using: <code>/path/to/deposit new-mnemonic --num_validators 1 --chain pyrmont</code>. Please note:<br>
<code>/path/to/deposit</code> is whenever your downloaded <code>deposit</code> file is.<br>
<code>--num_validators</code> has the number of validators you want to have. Each validator is 32ETH.<br>
<code>pyrmont</code> is the test network. You should change it if you want to work on the main network (aka real money).</p>

<p>Here is example of the output you will have:</p>

<div><div><pre><code><span>&gt;</span> /Users/sagivo/Desktop/eth2deposit-cli-ed5a6d3-darwin-amd64/deposit new-mnemonic <span>--num_validators</span> 1 <span>--chain</span> pyrmont
Please choose your mnemonic language <span>(</span>czech, chinese_traditional, chinese_simplified, english, spanish, italian, korean<span>)</span> <span>[</span>english]: english
Type the password that secures your validator keystore<span>(</span>s<span>)</span>:
Repeat <span>for </span>confirmation:
</code></pre></div></div>

<p>You will be asked to choose a validator password. Do not lose this password, you will need it to get your money back at some point. <strong>This is not your wallet password</strong>, select a new password just for the validator client. After selecting the password you will get a seed phrase to store in case you lost your validator password. Store the seed phase in a secure location as well.<br>
If everything went well you should see a hippo(?) image.<br>
<img src="https://sagivo.com/assets/ethereum-4.png" alt="Ethereum CLI validator"></p>

<p>Open the folder with the keys. In this folder you will find a few files:<br>
<code>deposit_data-[some number].json</code> - this is the information for your deposit.<br>
<code>keystore-[some number].json</code> - you will have one or more files based on the number of validators you selected.
In this stage, you have all you need to install the local clients. Keep this window open, we will get back to it after we install the clients.</p>

<h3 id="ethereum-client-components">Ethereum client components</h3>

<p>Now that you staked your eth, you will need 3 nodes to become ETH 2.0 validator:</p>

<ul>
  <li><strong>ETH 1.0 client</strong>: this client will listen to the Ethereum 1.0 network. You can either run a local client or use a free 3rd party node. To save resources and keep this post simple, I’m using a free <a href="https://dashboard.alchemyapi.io/signup?referral=5f4b22ad-1a24-46af-ab1c-4475e8fe177d">alchemyapi.io</a> node. You can find more 3rd party options <a href="https://ethereumnodes.com/">here</a>.</li>
  <li><strong>Beacon node</strong>: ethereume 2.0 client.</li>
  <li><strong>Validator client</strong>: to validate eth2 transactions.</li>
</ul>

<h3 id="create-eth1-client">Create eth1 client</h3>

<p>You can either create a local eth1 client or use a 3rd party node instead. Let’s use a 3rd party today. Open a free <a href="https://dashboard.alchemyapi.io/signup?referral=5f4b22ad-1a24-46af-ab1c-4475e8fe177d">alchemyapi.io</a> and <a href="https://dashboard.alchemyapi.io/apps">create an app</a>. Make sure you select the <code>Goerli</code> network for your eth1 node.</p>

<p><img src="https://sagivo.com/assets/ethereum-9.png" alt="Alchemyapi node"></p>

<p>After the app has been created go to the app’s page and click on <code>VIEW KEY</code>, you will need to copy the HTTP URL for the beacon node.
<img src="https://sagivo.com/assets/ethereum-10.png" alt="Alchemyapi address"></p>

<h3 id="hosting-your-beacon-node-and-validator-client">Hosting your beacon node and validator client</h3>

<p>You can run your beacon node and validator client on a local computer. Beacon nodes are intended to be high-performance, highly available platforms that can support connections to numerous validator clients and maintain ongoing p2p connectivity with other beacon nodes. As such, their hardware requirements are anticipated to be server-grade CPU/SSD/networking connections.<br>
Your server needs to be available 24/7 or you will accrue penalties and lose ETH. This is why I prefer running my nodes on a hosted cloud server. In this tutorial, I choose <a href="https://m.do.co/c/29d9028f31d1">Digitalocean</a>. After playing with multiple specs, I’ve found that you can run your beacon node and validator client for just $10/month. Use <a href="https://m.do.co/c/29d9028f31d1">this link</a> to sign up for digitalocean and get $100 credit! This should cover your Ethereum staking expenses a while :)</p>

<h3 id="creating-a-digitalocean-droplet">Creating a digitalocean Droplet</h3>

<p>From your Digitalocean account, create a <a href="https://cloud.digitalocean.com/droplets/new">new droplet</a>.<br>
Choose the <code>Ubuntu</code> droplet. This will create a UNIX server running Ubuntu. <img src="https://sagivo.com/assets/ethereum-1.png" alt="Ubunto droplet"></p>

<p>Select the $10/mo plan. The $10/month spec is the bare minimum you should choose. If you want to choose a stronger instance go for it.</p>

<p><img src="https://sagivo.com/assets/ethereum-2.png" alt="10 dollar plan"></p>

<p>Setup SSH access under the <code>Authentication</code> section. This is important to be able to access your server from your terminal.<br>
You can leave the other settings as-is.<br>
Once your droplet setup is completed copy the ip address from the dashboard.<br>
<img src="https://sagivo.com/assets/ethereum-3.png" alt="copy ip"></p>

<h3 id="setting-up-your-cloud-server">Setting up your cloud server</h3>

<p>By now you should have a running digital ocean server and you should have generated <code>validator_keys</code> locally using the CLIt. Now let’s access your digital ocean machine to set it up.
First, let’s copy your local <code>validator_keys</code> folder to your hosted server.</p>

<div><div><pre><code>scp <span>-pr</span> /path/to/your/local/validator_keys <a href="https://sagivo.com/cdn-cgi/l/email-protection" data-cfemail="e2908d8d96a2868b858b96838e">[email&nbsp;protected]</a>_ocean_ip:/validator_keys
</code></pre></div></div>

<ul>
  <li><code>/path/to/your/local/validator_keys</code>: the path for your local folder containing the generated validator keys.</li>
  <li><code>digital_ocean_ip</code>: your digitalocean machine’s IP.</li>
</ul>

<p>Now that we copied the keys to the droplet (digitalocean instance), let’s SSH into this machine.</p>



<ul>
  <li><code>digital_ocean_ip</code>: your new machine’s IP.</li>
</ul>

<p>The first (optional) step is to enable better metrics on the machine to track later in digitalocean. This will let you inspect CPU, memory, disk I/O, and other metrics in the digitalocean dashboard.</p>

<div><div><pre><code>curl <span>-sSL</span> https://repos.insights.digitalocean.com/install.sh | <span>sudo </span>bash
</code></pre></div></div>

<h3 id="install-lighthouse">Install Lighthouse</h3>

<p>In this step, we will install lighthouse on your new server. <a href="https://github.com/sigp/lighthouse">Lighouse</a> is an open-source Ethereum 2.0 client, written in <a href="https://www.rust-lang.org/">Rust</a> and maintained by Sigma Prime.</p>

<ol>
  <li>Go to the <a href="https://github.com/sigp/lighthouse/releases">Lighthouse releases page</a> and select the latest linux release.</li>
  <li>Download the portable binary <code>wget lighthouse-${VERSION}-x86_64-unknown-linux-gnu-portable.tar.gz</code>.</li>
  <li>Extract the archive: <code>tar -xvf lighthouse-${VERSION}-x86_64-unknown-linux-gnu.tar.gz</code></li>
  <li>Test the binary with <code>./lighthouse --version</code> (it should print the version).</li>
  <li>Move the lighthouse binary to a location in your PATH, so the lighthouse command can be called from anywhere: <code>cp lighthouse /usr/bin</code></li>
  <li>
    <p>Clean your downloaded files</p>

    <div><div><pre><code><span>rm </span>lighthouse
<span>rm </span>lighthouse-<span>${</span><span>VERSION</span><span>}</span><span>-x86_64-unknown-linux-gnu</span>.tar.gz
</code></pre></div>    </div>
  </li>
</ol>

<h3 id="import-validator-keys">Import validator keys</h3>

<p>We will import the validator keys so we can use them by the validator.</p>

<div><div><pre><code><span>mkdir</span> <span>-p</span> /var/lib/lighthouse
lighthouse account validator import <span>--directory</span> /validator_keys <span>--datadir</span> /var/lib/lighthouse
</code></pre></div></div>

<ul>
  <li><code>/var/lib/lighthouse</code>: this folder will store our lighthouse data.</li>
  <li><code>--directory /validator_keys</code>: our imported <code>validator_keys</code> folder locaiton.</li>
</ul>

<p>You will be prompted to insert a password. Insert the password for your validator client again.</p>

<h3 id="run-beacon-node">Run beacon node</h3>

<p>We will run the beacon node as a daemon service. This way it will auto-restart if there’s an error. It’s important to have your eth 2.0 service running 24/7 to not accrue penalties and lose eth.</p>

<div><div><pre><code>nano /etc/systemd/system/lighthousebeacon.service
</code></pre></div></div>

<p>Paste this text:</p>

<div><div><pre><code>[Unit]
Description=Lighthouse Eth2 Client Beacon Node
Wants=network-online.target
After=network-online.target

[Service]
Type=simple
Restart=always
RestartSec=5
ExecStart=/usr/bin/lighthouse bn --network pyrmont --staking --datadir /var/lib/lighthouse --eth1-endpoints https://eth-goerli.alchemyapi.io/v2/[your token]

[Install]
WantedBy=multi-user.target
</code></pre></div></div>

<p>This is a new service that will re-start if it fails.</p>

<ul>
  <li><code>--network pyrmont</code>: we use the test network</li>
  <li><code>--eth1-endpoints</code>: comma-separated http addresses of your eth1 client nodes.</li>
</ul>

<p>To reload the daemon use</p>



<p>Now let’s start the beacon daemon service:</p>

<div><div><pre><code>systemctl start lighthousebeacon
</code></pre></div></div>

<p>You can inspect the output using (safe to ctr+c once you’re done):</p>

<div><div><pre><code>journalctl <span>-fu</span> lighthousebeacon.service
</code></pre></div></div>

<p>Also, let’s enable the service to start on server restart:</p>

<div><div><pre><code>systemctl <span>enable </span>lighthousebeacon
</code></pre></div></div>

<h3 id="validator-client">Validator client</h3>

<p>Let’s create a validator service</p>

<div><div><pre><code>nano /etc/systemd/system/lighthousevalidator.service
</code></pre></div></div>

<p>Paste this:</p>

<div><div><pre><code>[Unit]
Description=Lighthouse Eth2 Client Validator Node
Wants=network-online.target
After=network-online.target

[Service]
Type=simple
Restart=always
RestartSec=5
ExecStart=/usr/bin/lighthouse vc --network pyrmont --datadir /var/lib/lighthouse --graffiti "YOLO"

[Install]
WantedBy=multi-user.target
</code></pre></div></div>

<p>This is a new service that will re-start if it fails.</p>

<ul>
  <li><code>--network pyrmont</code>: we use the test network</li>
  <li><code>--graffiti</code>: an optional message you want to include in your validation blocks.</li>
</ul>

<p>To reload the daemons use</p>



<p>Start the validator daemon service.</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sagivo.com/crypto/2020/12/27/Etherum2-validator.html">https://sagivo.com/crypto/2020/12/27/Etherum2-validator.html</a></em></p>]]>
            </description>
            <link>https://sagivo.com/crypto/2020/12/27/Etherum2-validator.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25551514</guid>
            <pubDate>Sun, 27 Dec 2020 15:08:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flatbuffers in Unity – A 40x Gain]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25550974">thread link</a>) | @todsacerdoti
<br/>
December 27, 2020 | http://extrawurst.github.io/gamedev/unity/programming/rust/2020/12/26/unity-flatbuffers.html | <a href="https://web.archive.org/web/*/http://extrawurst.github.io/gamedev/unity/programming/rust/2020/12/26/unity-flatbuffers.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>We recently switched from downloading and parsing JSON in our Unity client to a binary format based on Flatbuffers.
In this this article you are going to learn:</p>

<ul>
  <li><em>why</em> we did that</li>
  <li><em>what</em> Flatbuffers is anyway</li>
  <li><em>how</em> you can do that yourself</li>
  <li>what <em>benefit</em> we gained</li>
</ul>

<p><strong>TL;DR</strong></p>

<p>You are looking to simplify your life integrating Flatbuffers in Unity? Look no further: <a href="https://github.com/gameroasters/flatbuffers-unity-docker">gameroasters/flatbuffers-unity</a></p>



<p>Our recent game <em>Wheelie Royale</em> (<a href="https://apps.apple.com/US/app/id1518264893">Appstore</a> / <a href="https://play.google.com/store/apps/details?id=com.gameroasters.wheelieroyale&amp;hl=en&amp;gl=US">Playstore</a>) downloads a lot of replay data by other players. Replay data was transmitted in JSON format. In the most extreme cases up to 15mb of JSON for a single level.
While this is already a problem just because of mobile data usage it manifests even more severly in mid- to low-end devices when deserializing the JSON data.</p>

<p>After digging out my low-end test device (Galaxy S4) it took <a href="https://www.newtonsoft.com/json">Newtonsoft.JSON</a> <strong>20 sec</strong> to deserialize the 15mb. This is bad and for some players it even went up to a minute - an absolute dealbreaker.</p>

<p>Obviously we had to find a better method entirely.</p>



<blockquote>
  <p>FlatBuffers is an efficient cross platform serialization library (<a href="https://google.github.io/flatbuffers/">Flatbuffers website</a>)</p>
</blockquote>

<p>Initially a Google internal project for game development it received some fame when Facebook announced massive performance gains by utilizing it on their mobile app (<a href="https://engineering.fb.com/2015/07/31/android/improving-facebook-s-performance-on-android-with-flatbuffers/">article</a>).</p>

<p>Using Flatbuffers gives us two main advantages:</p>

<ol>
  <li>Data is stored in binary form making it easy on the bandwidth</li>
  <li>Accessing Data is very fast since it is just a lookup from contiguous memory</li>
</ol>

<p>The following graphic visualizes this:</p>

<p><img src="http://extrawurst.github.io/assets/flatbuffers/fb.jpeg" alt="fb"></p>

<p>Flatbuffers store data in a <strong>contiguous</strong> chunk of memory making it also easy on the garbage collector that especially in our use case was trashed with a lot of small allocations.
If you mainly read your data from a buffer and do not need to alter it (our exact use case) it escentially reduces allocations to zero (reusing a static buffer).</p>

<p>Aside the compact memory layout Flatbuffers reduces the memory consumption by expecting both parties to know the schema. We later see how we generate code for client and backend to be able to speak the same <em>language</em>.</p>

<h2 id="comparison">Comparison</h2>

<ul>
  <li><strong>Before</strong>: Deserializing 15mb of Json in <strong>20 secs</strong></li>
  <li><strong>After</strong>: Parsing the same data but using Flatbuffers (4mb) in <strong>0,5 sec</strong></li>
</ul>

<p>This is a speed improvement of <strong>40x</strong>.</p>

<p><strong>Disclaimer</strong>: Of course this is not a proper scientific benchmarking method but it holds true even on our modern iPhones (albeit on a much smaller scale). I leave the more scientific methods of benchmarking to people smarter than me: 
<a href="https://google.github.io/flatbuffers/flatbuffers_benchmarks.html">benchmark</a></p>



<p>Here is a simplified version of our schema file. Keep in mind that we are dealing with playbacks (ghosts) of other players. Each ghost consists of a TON of deltas (Sample) that allow us to replay them.</p>

<pre><code>struct Sample {
  //...
  r: int16;
}

table GhostRecording {
  //...
  deltas: [Sample] (required);
}

table Ghost {
  //...
  recording: [GhostRecording] (required);
}

table Ghosts {
  //...
  items:[Ghost] (required);
}

root_type Ghosts;
</code></pre>

<p>Here you can see why our use case was particularly tough for the garbage collector in Unity since we are dealing with a lot of small individually allocated objects.</p>

<p>If you want to to more about the differences of <code>table</code> and <code>struct</code> you can find all details about the schema here: <a href="https://google.github.io/flatbuffers/flatbuffers_guide_writing_schema.html">Flatbuffers Schema</a></p>

<h2 id="code-generation">Code generation</h2>

<p>When it comes to the pipeline required to get this working I was disappointed at how little was available: no easy docker container to get <code>flatc</code> (the schema transpiler) working cross platform, no ready built .net library for Unity to get started.</p>

<p>So I built this and open sourced it on our company github: <a href="https://github.com/gameroasters/flatbuffers-unity-docker">gameroasters/flatbuffers-unity</a></p>

<p>Using this docker container it is easy to create your serialization/deserialization code using the following snippet:</p>

<div><div><pre><code>docker run <span>-it</span> <span>-v</span> <span>$(</span>shell <span>pwd</span><span>)</span>:/fb gameroasters/flatbuffers-unity:v1.12.0 /bin/bash <span>-c</span> <span>"cd /fb &amp;&amp; </span><span>\</span><span>
	flatc -n --gen-onefile schema.fbs &amp;&amp; </span><span>\</span><span>
	flatc -r --gen-onefile schema.fbs"</span>
</code></pre></div></div>

<p>This will mount your current working directory into the container, it is expecting to find a <code>schema.fbs</code> file in here and generate the necessary code for <em>Rust</em> and <em>CSharp</em> for you in two files called <code>schema.rs</code> and <code>schema.cs</code>.</p>



<p>Flatbuffers is not going to make your code more readable. Here is an example how we read in our ghosts from it:</p>

<div><div><pre><code><span>var</span> <span>fb_ghosts</span> <span>=</span> <span>GR</span><span>.</span><span>WR</span><span>.</span><span>Schema</span><span>.</span><span>Ghosts</span><span>.</span><span>GetRootAsGhosts</span><span>(</span><span>new</span> <span>ByteBuffer</span><span>(</span><span>data</span><span>));</span>

<span>var</span> <span>res</span> <span>=</span> <span>new</span> <span>List</span><span>&lt;</span><span>Ghost</span><span>&gt;(</span><span>fb_ghosts</span><span>.</span><span>ItemsLength</span><span>);</span>
<span>for</span> <span>(</span><span>var</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>fb_ghosts</span><span>.</span><span>ItemsLength</span><span>;</span> <span>i</span><span>++)</span>
<span>{</span>
    <span>var</span> <span>e</span> <span>=</span> <span>fb_ghosts</span><span>.</span><span>Items</span><span>(</span><span>i</span><span>);</span>
    <span>if</span> <span>(!</span><span>e</span><span>.</span><span>HasValue</span><span>)</span> <span>continue</span><span>;</span>
    <span>var</span> <span>recording</span> <span>=</span> <span>e</span><span>.</span><span>Value</span><span>.</span><span>Recording</span><span>.</span><span>Value</span><span>;</span>

    <span>var</span> <span>deltas</span> <span>=</span> <span>new</span> <span>List</span><span>&lt;</span><span>Sample</span><span>&gt;(</span><span>recording</span><span>.</span><span>DeltasLength</span><span>);</span>
    <span>for</span> <span>(</span><span>var</span> <span>j</span> <span>=</span> <span>0</span><span>;</span> <span>j</span> <span>&lt;</span> <span>recording</span><span>.</span><span>DeltasLength</span><span>;</span> <span>j</span><span>++)</span>
    <span>{</span>
        <span>var</span> <span>delta</span> <span>=</span> <span>recording</span><span>.</span><span>Deltas</span><span>(</span><span>j</span><span>);</span>
        <span>var</span> <span>r</span> <span>=</span> <span>delta</span><span>.</span><span>Value</span><span>.</span><span>R</span><span>;</span>
        <span>deltas</span><span>.</span><span>Add</span><span>(</span><span>new</span> <span>Sample</span><span>(</span><span>r</span><span>));</span>
    <span>}</span>

    <span>var</span> <span>ghost</span> <span>=</span> <span>new</span> <span>Ghost</span><span>();</span>
    <span>ghost</span><span>.</span><span>recording</span> <span>=</span> <span>new</span> <span>GhostRecording</span><span>();</span> 
    <span>ghost</span><span>.</span><span>recording</span><span>.</span><span>deltas</span> <span>=</span> <span>deltas</span><span>;</span>
  
    <span>res</span><span>.</span><span>Add</span><span>(</span><span>ghost</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>Unlike some alternatives to Flatbuffers it does not create the Plain-Old-Data (POD) objects for you and deserialize into those. But that is by design. You could actually go without them when you only need to access it for reading.</p>

<p>We only create those to keep the code compatible with the previous approach that deserialized JSON into POD objects.</p>



<p>Of course there are alternatives that I do not want to hide:</p>

<ul>
  <li><a href="https://developers.google.com/protocol-buffers">protobuf</a></li>
  <li><a href="https://github.com/capnproto/capnproto">cap’n’proto</a></li>
</ul>

<p>Here is a very nice comparison matrix: https://capnproto.org/news/2014-06-17-capnproto-flatbuffers-sbe.html</p>

<p>The main benefit for <strong>protobuf</strong> is that it does the extra step of creating POD objects for you bringing it even closer to what you are used to in regular JSON deserialization. It is a good tradeoff between speed (Flatbuffers) and convenience (JSON). Another nice thing is: protobuf also speaks JSON which simplifies debugging a lot.</p>

<p>The other alternative - <strong>cap’n’proto</strong> - is actually made by the <a href="https://stackoverflow.com/a/25370932/1397367">same guy</a> who made protobuf and uses the same zero-allocation approach Flatbuffers uses. <strong>cap’n’proto</strong> does not support as many languages yet - thats the only reason I did not consider giving it a try (yet).</p>

<p>Ultimately there is no <em>best</em> solution, everything comes at a cost. If you need raw speed there is not much more you can get compared to Flatbuffers.</p>



<ul>
  <li><a href="https://www.youtube.com/watch?v=YsiQDX20lXI">Bringing FlatBuffers Zero-Copy Serialization to Rust by Robert Winslow</a> (Meetup Video)</li>
</ul>

      </div></div>]]>
            </description>
            <link>http://extrawurst.github.io/gamedev/unity/programming/rust/2020/12/26/unity-flatbuffers.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25550974</guid>
            <pubDate>Sun, 27 Dec 2020 13:44:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stack Based Virtual Machines]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25550776">thread link</a>) | @signa11
<br/>
December 27, 2020 | https://andreabergia.com/stack-based-virtual-machines/ | <a href="https://web.archive.org/web/*/https://andreabergia.com/stack-based-virtual-machines/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
            

            <div id="container">


<div>
    <article itemscope="" itemtype="http://schema.org/BlogPosting">
        

        <div itemprop="articleBody">
    

    

<p>In this series we’re going to delve a bit into stack based virtual machines. First we’re going to see an overview, then we’ll build our own toy VM. Next, we’re going to see how what we’ll build maps to a real CPU. Finally, we’ll discuss the most famous of all: the JVM.</p>

<h3 id="introduction">Introduction</h3>

<p>What’s a <em>stack based virtual machine</em> then? It’s an abstraction of a computer, that emulates a real machine. Generally it is built as an interpreter of a special <em>bytecode</em>, that translates its in real time for execution on the CPU.</p>

<p>Let’s start with a trivial example: suppose your program needs to add two numbers. To do that in a stack VM, the program will <em>push</em> the first number to the stack, <em>push</em> the second and then execute some form of the special instruction <em>add</em>, that will <em>pop</em> the first two elements of the stack and replace them with their sum. Let’s see it step by step:</p>

<p><img src="https://andreabergia.com/images/2015/03/Stack_1.png" alt="At the beginning"></p>

<p>The <code>SP</code> is the <em>stack pointer</em>, which refers to the head of the stack. The <code>IP</code> is the <em>instruction pointer</em>, which points to the address of the current instruction to execute. Let’s now execute the first instruction:</p>

<p><img src="https://andreabergia.com/images/2015/03/Stack_2.png" alt="After the first instruction"></p>

<p>You can see that the stack now contains <code>1</code> and that the instruction pointer has been moved to the next instruction. Let’s now simulate the second instruction:</p>

<p><img src="https://andreabergia.com/images/2015/03/Stack_3.png" alt="After the second instruction"></p>

<p>Finally we can execute the <code>add</code> instruction:</p>

<p><img src="https://andreabergia.com/images/2015/03/Stack_4.png" alt="After the add"></p>

<p>The head of the stack and the previous element have been popped and replaced with their sum.</p>

<h3 id="centrality-of-the-stack">Centrality of the stack</h3>

<p>As you have seen from the example, the main two data structures for a stack VM are the code listing, with the instruction pointer, and the stack data, which is accessed only via the stack pointer. While these two data structures seem trivial, they are more than enough to implement a lot of complex programs. By adding some external memory area (what is generally known as “memory on the heap”), this structure will become complex enough to form the basis of a real language such as Java or Scala.</p>

<p>The stack will be the central structure. From what we hve seen above you should have some idea on how to use it to implement the basic arithmetic, but it is also going to be the basis of implementing loops and conditional execution (if) and even function calls! We’re going to discuss all of this while building our toy VM.</p>

<h3 id="register-based-virtual-machines">Register based virtual machines</h3>

<p>Closely related to stack based VM are <em>register based virtual machines</em>. They are also interpreters of bytecode, but their design is quite different, since they don’t use the stack for the operands but rather a set of registers. While they tend to be more complex, they are also generally faster at runtime, since they map much more closely to the CPU (which, as we’ll see later, is actually an hardware register machine) and thus they tend to generate and execute better efficient code.</p>

<p>However stack based virtual machines are not just a learning toy. The most successful VM ever, the <a href="https://en.wikipedia.org/wiki/Java_virtual_machine">Java Virtual Machine</a>, is a stack-based virtual machine (and so is the <a href="https://en.wikipedia.org/wiki/Common_Language_Runtime">CLR</a>, the basis of .NET). Furthermore the JVM is <em>extremely</em> high performant, while still quite simple - although that has been achieved more by the <em>immense</em> amount of money that has flown into its development than by some special characteristic of its architecture.</p>

<p>The most famous example of a register based virtual machine is probably <a href="http://www.lua.org/">LUA</a>, which can achieve <a href="http://luajit.org/performance.html">amazing performances</a> and is used in <a href="https://en.wikipedia.org/wiki/Category:Lua-scripted_video_games">many videogames</a> as a scripting language.</p>

<h3 id="links">Links</h3>

<p>I hope this short introduction has stimulated your curiosity. Here are a few links in case you wish to start reading something more:</p>

<ul>
<li><a href="https://en.wikipedia.org/wiki/Stack_machine">Wikipedia page for stack based virtual machines</a></li>
<li><a href="https://en.wikipedia.org/wiki/Comparison_of_application_virtualization_software">Comparision of common VM</a></li>
<li><a href="http://www.lua.org/doc/jucs05.pdf">Design document for LUA</a></li>
</ul>

<p>About the JVM:</p>

<ul>
<li><a href="https://en.wikipedia.org/wiki/Java_bytecode">JVM bytecode introduction</a></li>
<li><a href="https://en.wikipedia.org/wiki/Java_bytecode_instruction_listings">JVM bytecode instructions</a></li>
<li><a href="http://download.forge.objectweb.org/asm/asm4-guide.pdf">Introduction to ASM, a JVM bytecode manipulation library</a></li>
</ul>

<p><strong>Update:</strong> part two is <a href="https://andreabergia.com/stack-based-virtual-machines-2">online</a>.</p>

</div>

        

        
    </article>
</div>

            </div>
        </div></div>]]>
            </description>
            <link>https://andreabergia.com/stack-based-virtual-machines/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25550776</guid>
            <pubDate>Sun, 27 Dec 2020 13:12:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Central Bank Digital Currencies Are a Bad Idea]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 164 (<a href="https://news.ycombinator.com/item?id=25550443">thread link</a>) | @simonebrunozzi
<br/>
December 27, 2020 | https://www.forgac.me/blog/2020/11/17/three-reasons-why-central-bank-digital-currencies-are-a-bad-idea | <a href="https://web.archive.org/web/*/https://www.forgac.me/blog/2020/11/17/three-reasons-why-central-bank-digital-currencies-are-a-bad-idea">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" data-updated-on="1605643941671" id="item-5fb42c70669e655a2de5be01"><div><div><div data-block-type="2" id="block-36140108062efd62704e"><div><p><em>This text was published at </em><a href="https://mises.org/wire/why-central-bank-digital-currencies-are-bad-idea"><em>Mises Institute</em></a></p><p>The Central Banking Digital Currencies (CBDC) are being sold with the narrative of protecting consumers who are increasingly moving to cashless payments and as a result, robbing themselves of the privacy advantages of cash and exposing themselves to bank runs, payment network blackouts, and to foreign financial adversaries.</p><p>While these risks are real, they would be negligible had it not been for the central banking and financial regulators’ interventions into the market (more on that in the last couple of paragraphs), and CBDCs if anything make them worse and introduce some new, much bigger ones.</p><p>While the stated intention behind their design is to keep the commercial banks in the picture, CBDCs will bring the end-users of the future tokens closer to the central banks. This is because blockchains and blockchain-inspired distributed ledger technologies are built on a single, common, ledger, which is distributed either in a permissionless or permissioned manner. The permissionless distribution exposes a lot of information about the network participants, but in combination with proof-of-work verification makes it very difficult for an adversary to attack and overtake the network and e.g. change the inflation rate.</p><p>Permissioned network with no proof-of-work or similar consensus algorithm not only doesn’t provide the immutability feature but by having a single permissioned ledger gives potential control to those who grant the network privileges. As a result, the central bank as the ultimate permission issuer would have much stronger control over the monetary system and payment network than they have right now. This gives the central banks three very dangerous capabilities.</p><h2>Helicopter Money</h2><p>The reason why we’ve seen such an elevated business cycle over the past century is the central banking fiat money system. Unnatural expansion of the money supply causes booms, which are unsustainable and markets try to clear them when they are exposed as such.</p><p>Economists of the Austrian school understand, that the boom is the real problem and the economic crisis is the necessary and positive cleansing mechanism. Unfortunately, the (neo)Keynesian response to such an event is to prop the markets up by further monetary interventions.</p><p>However, the current design of the banking system requires the intermediary role of commercial banks in issuing credit to businesses. Central banks get frustrated when the commercial banks exercise caution in an economy, which hasn’t fully cleared the previous misallocations and hasn’t brought prices of capital goods to more sustainable levels.</p><p>Furthermore, since the predominant Keynesian narrative is that spending drives the economy (hint: it doesn’t - capital investments do), the central banks would like to spur more consumer spending by issuing money supply directly to consumers. Needless to say, commercial banks’ cautious approach to consumer credit in a period of growing unemployment doesn’t align well with the central bank’s goals either. During the COVID crisis, the governments managed to an extent to get around these hurdles by issuing benefits en masse, but those are complicated by logistics, bureaucracy, or legislation.</p><p>By closer integration of the monetary spigot to the end consumers and businesses, the central bank can much more easily issue credit, or just outright cashouts to the private individuals and commercial entities by simply “airdropping” new tokens to the existing token identities. They would not even compromise their stated intention of keeping the commercial banks in the picture - those would still serve as custodians of the token keys, and even have the ability to issue credit along the traditional lines.</p><p>This would lead to disastrous consequences. Economies get easily addicted to central banks’ money dope. With every new crisis, the chief monetarists had to increase intervention doses the same way as junkies have to do with their drug of choice. As with every addiction, the longer it lasts and the stronger it grows, the more difficult it is to cure it. And while monetary overdose such as we’ve seen in Zimbabwe or Venezuela might not come for a long time, if ever, junkies don’t perform well, as Japan’s three lost decades of BOJ’s interventions have demonstrated.</p><h2>Negative Interest Rates</h2><p>Hoarding is evil - or so the modern monetarists’ narrative goes. In the Keynesian framework, there is no space for the function of cash as a hedge in times of uncertainty. Savings accounts, in their minds, are just money that doesn’t work in spurring the miracles of spending- and monetary-driven economic growth. Negative interest rates are then potentially the most effective method of preventing hoarding by incentivizing account holders to spend their depreciating balances.</p><p>Currently, the central banks have to rely on commercial banks to pass the negative interest rates on their customers. Commercial banks instead are trying to convince the account holders to move their deposits from negative yielding accounts to interest yielding products and are consuming the negative rates on most of the outstanding cash balances.</p><p>With the central bank tokens being tied more tightly with their issuance authority, it would be much easier for the monetary interventionists to impose negative interest rates on all tokens in circulation. This would on a margin certainly increase the consumers’ and businesses’ propensity to spend and would also drive asset prices up as people would try to offload their cash savings. But to think of it as something beneficial is foolish. It was massive spending, record-low savings, and unsustainable asset valuations that led to the credit bubbles and crises of the past decades. To think that more of the same recipe would lead to a different, let alone better outcome is ludicrous.</p><h2>Financial Surveillance</h2><p>Third and final major implication of cash tokenization is the potential it creates for financial surveillance. The central banks are ostensibly introducing digital tokens to protect people’s privacy in the face of those reducing their anonymous cash usage. But the idea that any branch of government, let alone the one that imposes KYC/AML rules on the existing crypto token platforms, limits physical cash use to prevent tax avoidance, and uses financial surveillance to catch non-violent “criminals” cares about our privacy is laughable.</p><p>They’re not even hiding the fact, that tokenization of money would allow them to run what they call “data analytics”, but to think that they would not make the leap from aggregate analytics to individual data processing would be naive.</p><p>Of course, it’s not a coincidence, that China is the global leader in CBDCs. The surveillance potential of centralized tokenization is extremely attractive to the government that tries to keep tabs on every aspect of the lives of their underlings.</p><p>The proponents of the central banking tokens argue, that consumers need to be protected against targeted attacks on a country’s payment network. While such a risk exists - for example, if a country like Switzerland tried to provide anonymity for foreign depositors as it used to and as a result Visa and Mastercard would be pressured to shut down their payment networks for the country - if it materializes, the economy can always temporarily revert back to cash, supported by a vast network of local ATMs and bank branches.</p><p>If anything, the biggest attacks on the monetary exchange in the western world came from the governments themselves suspending or limiting cash withdrawals in times of liquidity crises as was the case in Cyprus or Greece, not to mention that those crises themselves were caused by central banking credit bubbles of the preceding periods.</p><p>Finally as was already mentioned, the argument about the protection of consumer privacy doesn’t pass the laugh test considering the history of continuous erosion of financial privacy by central banks and financial regulators.</p><p>In conclusion, the same characteristics for which people should oppose the transition to CDBCs give central banks the strongest reason to champion and implement them. And while the pretense of an investigation into the fiat money tokenization gives an impression of a debate on the topic, the reality is, there will be no debate and the digital currencies will go through and give central banks more control than they had before with all the disastrous consequences such control brings.</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.forgac.me/blog/2020/11/17/three-reasons-why-central-bank-digital-currencies-are-a-bad-idea</link>
            <guid isPermaLink="false">hacker-news-small-sites-25550443</guid>
            <pubDate>Sun, 27 Dec 2020 11:57:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Multi Tenant Node-Red Using Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25550132">thread link</a>) | @hardillb
<br/>
December 27, 2020 | https://www.hardill.me.uk/wordpress/2020/12/27/multi-tenant-node-red-with-kubernetes/ | <a href="https://web.archive.org/web/*/https://www.hardill.me.uk/wordpress/2020/12/27/multi-tenant-node-red-with-kubernetes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4193">
	
	<!-- .entry-header -->

	<div>
		
<p>Having built a working example of <a href="https://www.hardill.me.uk/wordpress/2020/10/01/multi-tenant-node-red/" data-type="post" data-id="3981">Multi Tenant Node-RED </a>using Docker I thought I’d have a look at how to do the same with Kubernetes as a Christmas project.</p>



<p>I started with installing the 64bit build of Ubuntu Server on a fresh Pi4 with 8gb RAM and then using snapd to install <a href="https://microk8s.io/">microk8s</a>. I had initially wanted to use the 64bit version of Raspberry Pi OS, but despite microk8s <a href="https://microk8s.io/docs">claiming</a> to work on any OS that support snapd, I found that containerd just kept crashing on Raspberry Pi OS.</p>



<p>Once installed I enabled the dns and ingress plugins, this got me a minimal viable single node Kubernetes setup working. <br></p>



<figure><img data-attachment-id="4196" data-permalink="https://www.hardill.me.uk/wordpress/2020/12/27/multi-tenant-node-red-with-kubernetes/screenshot-from-2020-12-23-20-19-32/" data-orig-file="https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?fit=1468%2C976&amp;ssl=1" data-orig-size="1468,976" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot-from-2020-12-23-20-19-32" data-image-description="" data-medium-file="https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?fit=300%2C199&amp;ssl=1" data-large-file="https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?fit=660%2C439&amp;ssl=1" loading="lazy" width="660" height="439" src="https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?resize=660%2C439&amp;ssl=1" alt="" srcset="https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?resize=1024%2C681&amp;ssl=1 1024w, https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?resize=300%2C199&amp;ssl=1 300w, https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?resize=768%2C511&amp;ssl=1 768w, https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?w=1468&amp;ssl=1 1468w, https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?w=1320&amp;ssl=1 1320w" sizes="(max-width: 660px) 100vw, 660px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?resize=1024%2C681&amp;ssl=1 1024w, https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?resize=300%2C199&amp;ssl=1 300w, https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?resize=768%2C511&amp;ssl=1 768w, https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?w=1468&amp;ssl=1 1468w, https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?w=1320&amp;ssl=1 1320w" data-lazy-src="https://i0.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-19-32.png?resize=660%2C439&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>







<p>I also had to stand up a private docker registry to hold the containers I’ll be using. That was just a case of running <code>docker run -d -p 5000:5000 --name registry registry</code> on a local machine e.g <code>private.example.com</code> . This also means adding the URL for this to microk8s as described <a href="https://microk8s.io/docs/registry-private">here</a>.</p>



<p>Since Kubernetes is another container environment I can reuse most of the parts I previously created. The only bit that really needs to change is the Manager application as this has to interact with the environment to stand up and tear down containers.</p>



<h2>Architecture</h2>



<p>As before the central components are a MongoDB database and a management web app that stands up and tears down instances. The MongoDB instance holds all the flows and authentication details for each instance. I’ve deployed the database and web app as a single pod and exposed them both as services</p>


<pre title="">apiVersion: apps/v1
kind: Deployment
metadata:
  name: node-red-multi-tenant
  labels:
    app: nr-mt
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nr-mt
  template:
    metadata:
      labels:
        app: nr-mt
    spec:
      containers:
      - name: node-red-manager
        image: private.example.com/k8s-manager
        ports:
        - containerPort: 3000
        volumeMounts:
        - name: secret
          mountPath: /usr/src/app/config
        env:
        - name: MONGO_URL
          value: mongodb://mongo/nodered
        - name: ROOT_DOMAIN
          value: example.com
      - name: mongodb
        image: mongo
        ports:
        - containerPort: 27017
        volumeMounts:
        - name: mongo-data
          mountPath: /data/db
      - name: registry
        image: verdaccio/verdaccio
        ports:
        - containerPort: 4873
        volumeMounts:
        - name: registry-data
          mountPath: /verdaccio/storage
        - name: registry-conf
          mountPath: /verdaccio/conf
      volumes:
      - name: secret
        secret:
          secretName: kube-config
      - name: mongo-data
        hostPath:
          path: /opt/mongo-data
          type: Directory
      - name: registry-data
        hostPath:
          path: /opt/registry-data
          type: Directory
      - name: registry-conf
        secret:
          secretName: registry-conf

</pre>


<p>This Deployment descriptor basically does all the heavy lifting. It sets up the mangment app, MongoDB and the private NPM registry.</p>



<p>It also binds 2 sets of secrets, the first holds holds the authentication details to interact with the Kubernetes API (the <code>~/.kube/config</code> file) and the <code>settings.js</code> for the management app. The second is the config for the Veraccio NPM registry.</p>



<p>I’m using the <a href="https://kubernetes.io/docs/concepts/storage/volumes/#hostpath">HostPath</a> volume provider to store the MongoDB and the Veraccio registry on the filesystem of the Pi, but for a production deployment I’d probably use the NFS provider or a Cloud Storage option like AWS S3.</p>



<h2>Manager</h2>



<p>This is mainly the same as the <a href="https://github.com/hardillb/multi-tenant-node-red-manager">docker version</a>, but I had to swap out <a href="https://npmjs.com/package/dockerode">dockerode</a> for <a href="https://www.npmjs.com/package/kubernetes-client">kubernetes-client</a>.</p>



<p>This library exposes the full kubernetes API allowing the creation/modification/destructions of all entities.</p>



<p>Standing up a new instance is a little more complicated as it’s now a multi step process.</p>



<ol><li>Create a Pod with the custom-node-red container</li><li>Create a Service based on that pod</li><li>Expose that service via the Ingress addon</li></ol>



<figure><img data-attachment-id="4197" data-permalink="https://www.hardill.me.uk/wordpress/2020/12/27/multi-tenant-node-red-with-kubernetes/screenshot-from-2020-12-23-20-31-29/" data-orig-file="https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?fit=1552%2C382&amp;ssl=1" data-orig-size="1552,382" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot-from-2020-12-23-20-31-29" data-image-description="" data-medium-file="https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?fit=300%2C74&amp;ssl=1" data-large-file="https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?fit=660%2C162&amp;ssl=1" loading="lazy" width="660" height="162" src="https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?resize=660%2C162&amp;ssl=1" alt="" srcset="https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?resize=1024%2C252&amp;ssl=1 1024w, https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?resize=300%2C74&amp;ssl=1 300w, https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?resize=768%2C189&amp;ssl=1 768w, https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?resize=1536%2C378&amp;ssl=1 1536w, https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?w=1552&amp;ssl=1 1552w, https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?w=1320&amp;ssl=1 1320w" sizes="(max-width: 660px) 100vw, 660px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?resize=1024%2C252&amp;ssl=1 1024w, https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?resize=300%2C74&amp;ssl=1 300w, https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?resize=768%2C189&amp;ssl=1 768w, https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?resize=1536%2C378&amp;ssl=1 1536w, https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?w=1552&amp;ssl=1 1552w, https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?w=1320&amp;ssl=1 1320w" data-lazy-src="https://i1.wp.com/www.hardill.me.uk/wordpress/wp-content/uploads/2020/12/Screenshot-from-2020-12-23-20-31-29.png?resize=660%2C162&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>I also removed the Start/Stop buttons since stopping pods is not really a thing in Kubernetes.</p>



<p>All the code for this version of the app is on github <a href="https://github.com/hardillb/multi-tenant-node-red-k8s-manager">here</a>.</p>



<h2>Catalogue</h2>



<p>In the Docker-Compose version the custom node `catalogue.json` file is hosted by the management application and had to be manually updated each time a new or updated node was push to the repository. For this version I’ve stood up a separate container.</p>



<p>This container runs a small web app that has 2 endpoints.</p>



<ul><li><code>/catalogue.json</code> – which returns the current version of the catalogue</li><li><code>/update</code> – which is triggered by the the notify function of the Verdaccio private npm registry</li></ul>



<p>The registry has this snippet added to the end of the <code>config.yml</code></p>


<pre title="">notify:
  method: POST
  headers: [{'Content-Type': 'application/json'}]
  endpoint: http://catalogue/update
  content: '{"name": "{{name}}", "versions": "{{versions}}", "dist-tags": "{{dist-tags}}"}'
</pre>


<p>The code for this container can be found <a href="https://github.com/hardillb/node-red-private-catalogue-builder">here</a>. </p>



<h2>Deploying</h2>



<p>First clone the project from github</p>


<pre title="">$ github clone https://github.com/hardillb/multi-tenant-node-red-k8s.git
</pre>


<p>Then run the <code>setup.sh</code> script, passing in the base domain for instances and the host:port combination for the local container registry.</p>


<pre title="">$ ./setup.sh example.com private.example.com:5000
</pre>


<p>This will update some of the container locations in the deployment and build the secrets needed to access the Kubernetes API (reads the content of <code>~/.kube/config</code>)</p>



<p>With all the configuration files updated the containers need building and pushing to the local container registry.</p>


<pre title="">$ docker build ./manager -t private.example.com:5000/k8s-manager
$ docker push private.example.com:5000/k8s-manager
$ docker build ./catalogue -t private.example.com:5000/catalogue
$ docker push private.example.com:5000/catalogue
$ docker build ./custom-node-red -t private.example.com:5000/custom-node-red
$ docker push private.example.com:5000/custom-node-red
</pre>


<p>Finally trigger the actual deployment with <code>kubectl</code></p>


<pre title="">$ kubectl apply -f ./deployment
</pre>


<p>Once up and running the management app should be available on <code>http://manager.example.com</code>, the private npm registry on <code>http://registry.example.com</code> and an instance called “r1” would be on <code>http://r1.example.com</code>.</p>



<p>A wildcard DNS entry needs to be setup to point all <code>*.example.com</code> hosts to the Kubernetes clusters Ingress IP addresses.</p>



<p>As usual the whole solution can be found on github <a href="https://github.com/hardillb/multi-tenant-node-red-k8s">here</a>.</p>



<h2>What’s Next</h2>



<p>I need to work out how to set up Avahi CNAME entries for each deployment as I had working with both <a href="https://www.hardill.me.uk/wordpress/2020/09/22/nginx-proxy-avahi-helper/" data-type="post" data-id="4040">nginx</a> and <a href="https://www.hardill.me.uk/wordpress/2020/10/05/traefik-avahi-helper/" data-type="post" data-id="4107">traefik</a> so I can run it all nicely on my LAN without having to mess with <code>/etc/hosts</code> or the local DNS. This should be possible by using a <code>watch</code> call one the Kubernetes Ingress endpoint.</p>



<p>I also need to back port the new catalogue handling to the docker-compose version.</p>



<p>And finally I want to have a look at generating a Helm chart for all this to help get rid of needing the <code>setup.sh</code> script to modify the deployment YAML files.</p>



<p>p.s. If anybody is looking for somebody to do this sort of thing for them drop me a <a href="https://www.hardill.me.uk/wordpress/about/curriculum-vitae/" data-type="URL" data-id="https://www.hardill.me.uk/wordpress/about/curriculum-vitae/">line</a>.</p>

	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

</article></div>]]>
            </description>
            <link>https://www.hardill.me.uk/wordpress/2020/12/27/multi-tenant-node-red-with-kubernetes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25550132</guid>
            <pubDate>Sun, 27 Dec 2020 10:29:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DDC/CI monitor control on Linux (2019)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25550112">thread link</a>) | @todsacerdoti
<br/>
December 27, 2020 | http://blog.tcharles.fr/ddc-ci-screen-control-on-linux/ | <a href="https://web.archive.org/web/*/http://blog.tcharles.fr/ddc-ci-screen-control-on-linux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <!--kg-card-begin: markdown--><p>DDC/CI is a protocol for controlling monitor features like brightness, contrast, color temperature, input source, ... over the display cable (VGA, DVI, HDMI, Display port, ...).</p>
<p>It's a quite old protocol that is well supported across many different devices.</p>
<p>I'm currently using it to:</p>
<ul>
<li>Adjust brightness of my two monitors depending on how the room is lighted</li>
<li>Switch monitor inputs between the VM-dedicated graphics card and the host graphics card, replacing the need of a very expensive KVM switch that can WQHD @144Hz.</li>
</ul>

<h2 id="requiredpackages">Required packages</h2>
<p>You must install <code>ddcutil</code> package. The <a href="http://www.ddcutil.com/">official website</a> contains extensive information for troubleshooting.</p>
<h2 id="kernelmodules">Kernel modules</h2>
<p>Ddcutil connects to your screen over an I2C connection, and requires the <code>i2c-dev</code> kernel module to be loaded.</p>
<p>You can load the module at runtime using <code>sudo modprobe i2c-dev</code>.</p>
<p>To make it persistent across reboots, you need to add the module to <code>/etc/modules-load.d/i2c-dev.conf</code>:</p>
<pre><code>i2c-dev
</code></pre>
<p>Once the module is loaded, you should see some files in <code>/dev/i2c-*</code>.</p>
<h2 id="allowtheusertouseddc">Allow the user to use DDC</h2>
<p>By default the i2c dev files are owned by root, and can't be used by other users. One solution to allow your user to control DDC without using sudo is to add a custom udev rule:</p>
<p><code>/etc/udev/rules.d/45-ddcutil-i2c.rules</code></p>
<pre><code>KERNEL=="i2c-[0-9]*", GROUP="your-user", MODE="0660", PROGRAM="/usr/bin/ddcutil --bus=%n getvcp 0x10"
</code></pre>
<p>This rule automatically detects which i2c devices are DDC-capable, and allows members of the group "your-user" to control the file.</p>
<p>You can reload udev rules without rebooting by executing <code>sudo udevadm trigger</code></p>
<p>If you have multiple users, you can create a new group and add your user to the group:</p>
<pre><code>groupadd ddc
usermod -aG ddc $USER
</code></pre>
<h2 id="identifyyourmonitorinfo">Identify your monitor info</h2>
<h3 id="howtoaddressyourmonitor">How to address your monitor</h3>
<p>There are multiple ways to address your monitor, like display number (<code>--display</code>), model name (<code>--model</code>), serial number (<code>--sn</code>), i2c bus ID (<code>--bus</code>).</p>
<p>The bus ID method is way faster than the others, but may be unreliable if your hardware changes often.</p>
<pre><code>ddcutil detect
# You should see entries like:
# Display 1
#    I2C bus:             /dev/i2c-0
#    EDID synopsis:
#       Mfg id:           DEL
#       Model:            DELL U2419H
#       Serial number:    751L2N4
#       Manufacture year: 2018
#       EDID version:     1.4
#    VCP version:         2.1
</code></pre>
<h3 id="whichfeaturescanbecontrolled">Which features can be controlled</h3>
<ul>
<li>Get feature value: <code>ddcutil --bus=0 getvcp $FEAT_ID</code></li>
<li>Set feature value: <code>ddcutil --bus=0 setvcp $FEAT_ID $VALUE</code></li>
</ul>
<pre><code>ddcutil capabilities --bus=0
# You should see something like:
# MCCS version: 2.1
# Commands:
#    Command: 01 (VCP Request)
#    Command: 02 (VCP Response)
#    Command: 03 (VCP Set)
#    Command: 07 (Timing Request)
#    Command: 0c (Save Settings)
#    Command: e3 (Capabilities Reply)
#    Command: f3 (Capabilities Request)
# VCP Features:
#    Feature: 10 (Luminosity)
#    Feature: 12 (Contrast)
#    Feature: 14 (Select color preset)
#       Values:
#          04: 5000 K
#          05: 6500 K
#          06: 7500 K
#          08: 9300 K
#          09: 10000 K
#          0b: User 1
#          0c: User 2
#    Feature: 16 (Video gain: Red)
#    Feature: 18 (Video gain: Green)
#    Feature: 1A (Video gain: Blue)
#    Feature: 60 (Input Source)
#       Values:
#          0f: DisplayPort-1
#          11: HDMI-1
#    Feature: AA (Screen Orientation)
#       Values:
#          01: 0 degrees
#          02: 90 degrees
#          03: 180 degrees
#          04: 270 degrees
</code></pre>
<h2 id="scriptexamples">Script examples</h2>
<h3 id="changebrightness">Change brightness</h3>
<p><code>ddc-setbrightness</code></p>
<pre><code>#!/bin/bash
# Usage: ddc-setbrightness 50
ddcutil --bus=0 setvcp 10 $1 &amp;
ddcutil --bus=1 setvcp 10 $1 &amp;
wait
</code></pre>
<h3 id="switchinputsources">Switch input sources</h3>
<p>Very useful when you need to change input sources very often, and don't have a dedicated button on the monitor (or for automating it).</p>
<p><code>ddc-switch-inputs</code></p>
<pre><code>#!/bin/bash
# Usage: ddc-switch-inputs 1
case $1 in
   1 )
      # Config 1: Main PC
      OUT=("0x0f" "0x20")
      ;;
   2 )
      # Config 2: Virtual machine
      OUT=("0x11" "0x21")
      ;;
   * )
      echo "Unknown input '$1'"
      exit 1
      ;;
esac

ddcutil --bus=0 setvcp 60 ${OUT[0]} &amp;
ddcutil --bus=1 setvcp 60 ${OUT[1]} &amp;
wait
</code></pre>
<h3 id="reduceeyestrain">Reduce eyestrain</h3>
<p><code>ddc-daylight</code></p>
<pre><code>#!/bin/bash
# Usage: ddc-daylight night
case $1 in
   "day" )
      BRIGHTNESS=100
      TEMPERATURE=0x09
      ;;
   "evening" | "morning" )
      BRIGHTNESS=60
      TEMPERATURE=0x06
      ;;
   "night" )
      BRIGHTNESS=30
      TEMPERATURE=0x04
      ;;
   "dark" )
      BRIGHTNESS=0
      TEMPERATURE=0x04
      ;;
   * )
      echo "Unknown time of day '$1'"
      exit 1
      ;;
esac

ddcutil --bus=0 setvcp 10 $BRIGHTNESS &amp;
ddcutil --bus=1 setvcp 10 $BRIGHTNESS &amp;
ddcutil --bus=0 setvcp 14 $TEMPERATURE &amp;
ddcutil --bus=1 setvcp 14 $TEMPERATURE &amp;
wait
</code></pre>
<!--kg-card-end: markdown-->
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>http://blog.tcharles.fr/ddc-ci-screen-control-on-linux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25550112</guid>
            <pubDate>Sun, 27 Dec 2020 10:24:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SciHub commits in court to not upload content from Indian publishers till Jan 6 [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25550058">thread link</a>) | @ghoul2
<br/>
December 27, 2020 | https://www.livelaw.in/pdf_upload/pdf_upload-386427.pdf | <a href="https://web.archive.org/web/*/https://www.livelaw.in/pdf_upload/pdf_upload-386427.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.livelaw.in/pdf_upload/pdf_upload-386427.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25550058</guid>
            <pubDate>Sun, 27 Dec 2020 10:06:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Should we say stop to the syntactical growth of Python?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25550052">thread link</a>) | @treesciencebot
<br/>
December 27, 2020 | https://tree.science/syntactical-growth-of-python.html | <a href="https://web.archive.org/web/*/https://tree.science/syntactical-growth-of-python.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
            <p>The language has been literally 'evolving' since the version
that many of us have begun (maybe since the initial day, if you
are Guido). I'm not talking about any features in specific,
but rather the whole language. If you compare a code fragment
that you wrote 5 years ago, with the 'refactored' version that
you would write if it were today the difference is obvious. </p>
<p>We've seen a lot of new syntax popping into our lives, in just the
last 5 years (starting from 3.5):</p>
<ul>
<li><a href="https://www.python.org/dev/peps/pep-0448/">PEP 448</a></li>
</ul>
<div><pre><span></span><code><span>&gt;&gt;&gt;</span> <span>*</span><span>range</span><span>(</span><span>4</span><span>),</span> <span>4</span>
<span>(</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>)</span>
<span>&gt;&gt;&gt;</span> <span>[</span><span>*</span><span>range</span><span>(</span><span>4</span><span>),</span> <span>4</span><span>]</span>
<span>[</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>]</span>
<span>&gt;&gt;&gt;</span> <span>{</span><span>*</span><span>range</span><span>(</span><span>4</span><span>),</span> <span>4</span><span>}</span>
<span>{</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>}</span>
<span>&gt;&gt;&gt;</span> <span>{</span><span>'x'</span><span>:</span> <span>1</span><span>,</span> <span>**</span><span>{</span><span>'y'</span><span>:</span> <span>2</span><span>}}</span>
<span>{</span><span>'x'</span><span>:</span> <span>1</span><span>,</span> <span>'y'</span><span>:</span> <span>2</span><span>}</span>
</code></pre></div>

<ul>
<li><a href="https://www.python.org/dev/peps/pep-0465/">PEP 465</a>, a.k.a matrix operator</li>
</ul>
<div><pre><span></span><code><span>S</span> <span>=</span> <span>(</span><span>H</span> <span>@</span> <span>beta</span> <span>-</span> <span>r</span><span>)</span><span>.</span><span>T</span> <span>@</span> <span>inv</span><span>(</span><span>H</span> <span>@</span> <span>V</span> <span>@</span> <span>H</span><span>.</span><span>T</span><span>)</span> <span>@</span> <span>(</span><span>H</span> <span>@</span> <span>beta</span> <span>-</span> <span>r</span><span>)</span>
</code></pre></div>

<ul>
<li><a href="https://www.python.org/dev/peps/pep-0492/">PEP 492</a>, a.k.a native async syntax</li>
</ul>
<div><pre><span></span><code><span>async</span> <span>def</span> <span>commit</span><span>(</span><span>session</span><span>,</span> <span>data</span><span>):</span>
<span>...</span>

<span>async</span> <span>with</span> <span>session</span><span>.</span><span>transaction</span><span>():</span>
    <span>...</span>
    <span>await</span> <span>session</span><span>.</span><span>update</span><span>(</span><span>data</span><span>)</span>
    <span>...</span>
</code></pre></div>

<ul>
<li><a href="https://www.python.org/dev/peps/pep-0498/">PEP 498</a>, a.k.a f-strings</li>
</ul>
<div><pre><span></span><code><span>&gt;&gt;&gt;</span> <span>f</span><span>'The value is </span><span>{</span><span>value</span><span>}</span><span>.'</span>
<span>'The value is 80.'</span>
</code></pre></div>

<ul>
<li><a href="https://www.python.org/dev/peps/pep-0526/">PEP 526</a></li>
</ul>
<div><pre><span></span><code><span>primes</span><span>:</span> <span>List</span><span>[</span><span>int</span><span>]</span> <span>=</span> <span>[]</span>

<span>captain</span><span>:</span> <span>str</span>  <span># Note: no initial value!</span>

<span>class</span> <span>Starship</span><span>:</span>
    <span>stats</span><span>:</span> <span>ClassVar</span><span>[</span><span>Dict</span><span>[</span><span>str</span><span>,</span> <span>int</span><span>]]</span> <span>=</span> <span>{}</span>
</code></pre></div>

<ul>
<li><a href="https://www.python.org/dev/peps/pep-0570/">PEP 570</a></li>
</ul>
<div><pre><span></span><code><span>def add(x, y, /):</span>
<span>    return x + y</span>
</code></pre></div>

<ul>
<li><a href="https://www.python.org/dev/peps/pep-0572/">PEP 572</a>, a.k.a walrus</li>
</ul>
<div><pre><span></span><code><span># Handle a matched regex</span>
<span>if</span> <span>(</span><span>match</span> <span>:=</span> <span>pattern</span><span>.</span><span>search</span><span>(</span><span>data</span><span>))</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
    <span># Do something with match</span>

<span># A loop that can't be trivially rewritten using 2-arg iter()</span>
<span>while</span> <span>chunk</span> <span>:=</span> <span>file</span><span>.</span><span>read</span><span>(</span><span>8192</span><span>):</span>
    <span>process</span><span>(</span><span>chunk</span><span>)</span>

<span># Reuse a value that's expensive to compute</span>
<span>[</span><span>y</span> <span>:=</span> <span>f</span><span>(</span><span>x</span><span>),</span> <span>y</span><span>**</span><span>2</span><span>,</span> <span>y</span><span>**</span><span>3</span><span>]</span>
</code></pre></div>

<p>This huge list contains some of the (major~) changes that have been implemented since 3.5, there
are also quite a few minor ones (like <code>_</code> separator for numbers, <code>1_000_00</code> or <a href="https://www.python.org/dev/peps/pep-0530/">PEP 530</a>
for async comprehensions or even a new one for 3.9 to extend the decorator syntax, <a href="https://www.python.org/dev/peps/pep-0614/">PEP 614</a>.)</p>
<p>Well, since we all refreshed our memories, let's try to imagine a world where these features don't exist. Imagine
not having access to f-strings, writing weird stuff to deal with your coroutines, or repeating yourself 2 times whenever
you want to read chunks from a file, writing utility functions to merge 2 mappings and more awful cases. Except for maybe
PEP 465 (I never needed it, probably because I don't do scientific programming. But from what I saw by looking at the examples
in the PEP, it is quite good for people who work with data on a daily basis.) every feature in that list literally changed and
actively affected how I write my Python code, right now.</p>
<p>Seems like syntactical additions sounds great, why don't we add everything to the language? Let's start with
adding regex literals, and then move forward to call pipeline operator, blah blah blah. If you are subscribed
to the Python-ideas, then get ready to see tons of different, redundant new syntax proposals (even I, probably
proposed a couple of very obscure and stupid ideas in the past). Though this brings me back to the point of,
whether we should stop the syntactical growth at all or not. </p>
<p>In the last 6 month, 3 different major syntax changes were proposed. I guess everyone is somewhat familiar
with the pattern matching PEPs, PEP 622 (PEP 634, PEP 635, PEP 636). Also, there is PEP 637 for allowing keyword arguments
on the subscript syntax <code>[x=y, z=q]</code> and PEP 638, for syntactic macros. I am not going to criticize any of these PEPs, but
I'd like to ask you to think about them. Think of how they could affect you in 5 years. Think about whether your
coding styles would change because of them, think about how good fit they are to the language, and most importantly think about
whether you 'ACTUALLY' need them. Is there any 'ESSENTIAL' case that would be much better when you pass keyword arguments through
slices instead of just making a call to some sort of <code>get()</code> function? Or can't we have syntactical customization without having an
official definition of it? Does the syntax for 'patterns' (described by PEP 634) is a good fit for the Python language?</p>
<p>There are a lot of blog posts, <a href="https://discuss.python.org/t/gauging-sentiment-on-pattern-matching/5770">poll</a>s and maybe
hundreds of emails out there related to these proposals. I won't expect anyone to read them all, but if you want to get a 
general idea just check some of them out.</p>
<p>Have to say that, I'm extremely overwhelmed by seeing this amount of change proposals every day, in various
places. No one is forcing me to read them, though it is just a burden that I am intentionally or unintentionally taking to see what are people looking for in the language that I (myself) probably will be stuck
with for the next decade. Trying to comprehend what people are aiming with making language so complex with
growing the syntax more and more every day.</p>
<p>Don't forget that adding syntax is much more serious than adding a functionality to the runtime. That syntax
will be the face of the language, and you won't be able to alter it even a little bit. We all saw what happened
when the syntax was changed in a backwards-incompatible manner, and no one wants to go through that again. This
is why I am just asking you to think about whether do you believe these would be good fits for the language, whether
they will worth to their imponderable cost. </p>
<p>This is just me, throwing a bunch of questions into the void. If you want to talk more about these, feel free to
send me an email (batuhan [at] python [dot] org) or reach me through twitter (open DM for all, @isidentical).</p>


             
 
                <hr>
            
        </div></div>]]>
            </description>
            <link>https://tree.science/syntactical-growth-of-python.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25550052</guid>
            <pubDate>Sun, 27 Dec 2020 10:03:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Seeing the New Covid Variant Smoke]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25549909">thread link</a>) | @imartin2k
<br/>
December 27, 2020 | https://putanumonit.com/2020/12/26/seeing-the-new-covid-variant-smoke/ | <a href="https://web.archive.org/web/*/https://putanumonit.com/2020/12/26/seeing-the-new-covid-variant-smoke/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>There is evidence of a new highly-infectious strain of COVID-19 emerging in the UK and other countries. This post is an elaboration of my current model of it, as promised in my <a rel="noreferrer noopener" href="https://putanumonit.com/2020/12/26/lesswrong-2018-epistemology/" target="_blank">review of LessWrong’s collection on <em>Epistemology</em></a>. Most of the information I have on this new COVID variant comes from <a rel="noreferrer noopener" href="https://www.lesswrong.com/posts/CHtwDXy63BsLkQx4n/covid-12-24-we-re-f-ed-it-s-over" target="_blank">this post by Zvi</a>, the links from it, and comments. Read those if you haven’t yet.</p>



<p>Though I usually strive to have timeless content on my blog, I’m making another COVID exception. Ten months ago I write <em><a rel="noreferrer noopener" href="https://putanumonit.com/2020/02/27/seeing-the-smoke/" target="_blank">Seeing The Smoke</a></em> and dozens of people told me it flipped the switch for them and let them prepare for COVID in time; this post may end up even timelier. I anticipate both my model and the evidence that feeds into it to change rapidly, everything below is a snapshot of what I believe as of Christmas Day 2020. Reminder: I am not an expert on any of this, just the Putanumonit guy putting a num on it.</p>



<hr>



<p>The median prediction on <a rel="noreferrer noopener" href="https://www.lesswrong.com/posts/CHtwDXy63BsLkQx4n/covid-12-24-we-re-f-ed-it-s-over" target="_blank">Zvi’s LW post</a> is around 60% that the new variant is at least 50% more transmissible and same for there being a third COVID wave in the US:</p>



<figure><a href="https://putanumonit.files.wordpress.com/2020/12/covid-predictions.png"><img data-attachment-id="30901" data-permalink="https://putanumonit.com/covid-predictions/" data-orig-file="https://putanumonit.files.wordpress.com/2020/12/covid-predictions.png" data-orig-size="971,328" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="covid-predictions" data-image-description="" data-medium-file="https://putanumonit.files.wordpress.com/2020/12/covid-predictions.png?w=300" data-large-file="https://putanumonit.files.wordpress.com/2020/12/covid-predictions.png?w=900" src="https://putanumonit.files.wordpress.com/2020/12/covid-predictions.png?w=971" alt="" srcset="https://putanumonit.files.wordpress.com/2020/12/covid-predictions.png 971w, https://putanumonit.files.wordpress.com/2020/12/covid-predictions.png?w=150 150w, https://putanumonit.files.wordpress.com/2020/12/covid-predictions.png?w=300 300w, https://putanumonit.files.wordpress.com/2020/12/covid-predictions.png?w=768 768w" sizes="(max-width: 971px) 100vw, 971px"></a></figure>



<p>I would add a few things without straying too far from the crowd’s wisdom. </p>



<p>First, I would revise the crowd’s estimate for the first question down for no other reason than that the poll came at the end of a post titled <em>We’re Fucked, It’s Over</em>. If ever there was going to be a framing effect pushing estimates upwards, this would be it. There are also <a rel="noreferrer noopener" href="https://twitter.com/CupOfjoe1986/status/1342386338717458432" target="_blank">more alternative explanations</a> for the information coming out of the UK than Zvi accounted for.</p>



<p>Instead of just saying that that there’s a 60% chance it has a 50% higher transmissibility, I would break it down something like this:</p>



<ul><li>35% that the new strain is a nothingburger.</li><li>30% that it’s <em>slightly </em>more transmissible, say with an effective reproduction rate (r<sub>t</sub>) 20% higher.</li><li>30% that it’s <em>significantly </em>more transmissible, e.g. 70% higher.</li><li>5% in the Captain Malcolm Reynolds probability bucket.</li></ul>



<p>I also believe it very likely that new variant is already present in the US, given that a dozen flights from London have landed in NYC just in the last week. Travel from the UK has been restricted on Christmas eve but the dust from the bolting horse has already settled by the barn door.</p>



<p>A variant that’s just 20% more infectious will still take over exponentially from the old variant resulting in a chart like the one we see.</p>



<figure><a href="https://putanumonit.files.wordpress.com/2020/12/uk-strain-chart.png"><img data-attachment-id="30903" data-permalink="https://putanumonit.com/uk-strain-chart/" data-orig-file="https://putanumonit.files.wordpress.com/2020/12/uk-strain-chart.png" data-orig-size="701,491" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="uk-strain-chart" data-image-description="" data-medium-file="https://putanumonit.files.wordpress.com/2020/12/uk-strain-chart.png?w=300" data-large-file="https://putanumonit.files.wordpress.com/2020/12/uk-strain-chart.png?w=701" src="https://putanumonit.files.wordpress.com/2020/12/uk-strain-chart.png?w=701" alt="" srcset="https://putanumonit.files.wordpress.com/2020/12/uk-strain-chart.png 701w, https://putanumonit.files.wordpress.com/2020/12/uk-strain-chart.png?w=150 150w, https://putanumonit.files.wordpress.com/2020/12/uk-strain-chart.png?w=300 300w" sizes="(max-width: 701px) 100vw, 701px"></a></figure>



<p>Several people have tried to explain away the growth of the new variant as being due to things like catching a superspreader, but it doesn’t have to be one or the other. It could have r<sub>t</sub>=1.2 <em>and</em> catch a superspreader event to make it look like r<sub>t</sub>=1.5-1.7. This is why I am giving extra weight to the hypothesis of slightly higher transmissibility.</p>



<p>I also think there’s a <strong>huge </strong>difference between r<sub>tnew</sub>=1.2 and r<sub>tnew</sub>=1.7 (here I mean r<sub>t</sub> relative to the old strain given the same measures of containment) in terms of outcomes. </p>



<p>In the first case, to keep the virus suppressed (i.e. r&lt;1) we need to take measures that would have yielded r<sub>t</sub>=0.8 for the old strain. <a rel="noreferrer noopener" href="https://rt.live/us/NY" target="_blank">New York sustained that number</a> (albeit never dipping below 0.7) for two months running in the spring. Given that ~30% of the state has already been infected, that makes this all the more doable. Gyms and restaurants will close and people will grumble, but we’ll probably survive till the vaccine.</p>



<p>r<sub>tnew</sub>=1.7 is an entirely different case. Suppressing it would require the sort of lockdown that would yield r<sub>t</sub>=0.6 for the old strain, a number that <a rel="noreferrer noopener" href="https://rt.live/" target="_blank"><strong>has never been reached by any US state for any amount of time</strong></a>. I see no way in hell that Americans would agree to a lockdown <em>much stricter than any we’ve had so far,</em> especially after they’ve been promised that the worst is behind them.</p>



<p>Rural red tribers will not agree because Biden is in the White House. Urban blue tribers because containment in cities is much harder anyway. Young people will not agree because the virus harms them less than the lockdown. Dumb people will not agree because they will not understand the science and math and smart people, seeing that, will try to get infected early before the hospitals are overwhelmed.</p>



<p>No one will believe any of the “experts” at the CDC or WHO or Dr. Fauci because they have all repeatedly lied and tried to manipulate people and reversed their positions without admitting that they have. They all have <em>negative </em>credibility at this point with many Americans.</p>



<p>If the new virus is 1.7 times as infectious I believe that Americans will most likely simply give up on containment, the populace if not the government. We’ll have time to vaccinate the most vulnerable 10-20% of the population by April-May, at which point the majority of everyone else will get the new strain. </p>



<p>There is a small chance that the US will get its shit together vaccine-wise and beat the new strain in a race. <a rel="noreferrer noopener" href="https://twitter.com/yashkaf/status/1342569735884517379" target="_blank">Israel, for example</a>, has a simple system in place to vaccinate the vast majority of its 9-million strong population by the end of March. On this timetable, even a virus with r<sub>t</sub>=1.7 will not have time to explode before herd immunity kills it.</p>



<p>The same is not true of the US, which is currently projected to reach majority immunization no earlier than the late summer by refusing to do <a rel="noreferrer noopener" href="https://twitter.com/yashkaf/status/1342546177288527872" target="_blank">basic things to rush the process</a>.</p>



<p>And what’s the Captain Mal bucket?</p>



<figure><div>
<p><span><iframe width="900" height="507" src="https://www.youtube.com/embed/MnQaYGJ5oYs?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span></p>
</div></figure>



<p>The new variant being more virulent in addition to being more infectious. Another newer strain that’s even worse. Or, in a nightmare scenario, a highly-transmissible mutation that also renders the Pfizer and Moderna vaccines ineffective. </p>



<p>If COVID has taught us one thing, it’s that it’s all usually worse than we thought.</p>



<p>So the bottom line is that I currently estimate a 30-35% chance of us being truly fucked, in the sense of dozens of millions more Americans getting COVID in 2021 and hundreds of thousands more dead, along with local attempts at extreme lockdowns. I’m not going to speculate on the further implications of this for things like financial markets or the fabric of our civilization. I also anticipate that I’ll be revising these numbers in the next few days. </p>



<p>But rationalists are seeing the smoke again.</p>
		</div><div>
				<p><img alt="" src="https://1.gravatar.com/avatar/7fcedca31995992a0647e573ea62de1a?s=60&amp;d=monsterid&amp;r=G" height="60" width="60">		</p><!-- .author-avatar -->
		
		<!-- .author-heading -->

		<p>
			I tried to be a magazine writer, mathematician, and stand up comedian. Now I just write a blog with math and jokes.			<a href="https://putanumonit.com/author/putanumonit/" rel="author">
				View all posts by Jacob Falkovich			</a>
		</p><!-- .author-bio -->
	</div></div>]]>
            </description>
            <link>https://putanumonit.com/2020/12/26/seeing-the-new-covid-variant-smoke/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25549909</guid>
            <pubDate>Sun, 27 Dec 2020 09:27:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remote Chaos Communication Congress – Streams]]>
            </title>
            <description>
<![CDATA[
Score 211 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25549762">thread link</a>) | @doener
<br/>
December 27, 2020 | https://streaming.media.ccc.de/rc3/ | <a href="https://web.archive.org/web/*/https://streaming.media.ccc.de/rc3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://streaming.media.ccc.de/rc3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25549762</guid>
            <pubDate>Sun, 27 Dec 2020 08:42:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Two Why You Found Learning Haskell Hard]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25549742">thread link</a>) | @schooloffp
<br/>
December 27, 2020 | https://schooloffp.co/2020/12/27/two-reasons-why-you-found-learning-haskell-hard.html | <a href="https://web.archive.org/web/*/https://schooloffp.co/2020/12/27/two-reasons-why-you-found-learning-haskell-hard.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Haskell is notoriously famous for having a steep learning curve. A situation that frustrates newcomers to the language, especially newcomers who are experienced developers using other programming languages.</p>

<p>It is not uncommon to see seasoned developers express their frustration by making the point that all of the other languages they have picked up, they have been able to get productive within a reasonable amount of time, but Haskell only manages to remain an impenetrable wall of Egyptian glyphs after the same period of time.</p>

<p>A reason often cited for Haskell’s steep learning curve is the fact that <em>“Haskell is different”</em>. The argument goes: Haskell is not all that difficult, it is just different, and because of this, it is unfamilair. But most of the time, when this argument is made, it is not mentioned how exactly Haskell is different.</p>

<p>Sure, there could be other reasons why learning Haskell may be considered difficult, but we think the <em>difference</em> argument is an interesting one worth exploring. This is exactly what this post is about. The idea is to do more than just mention that Haskell is different but to show how. The hope is that doing this, will prepare newcomers to the language, hence preventing Haskell’s difference from being a stumbling block to learning the language.</p>

<p>So in what ways is Haskell different?</p>

<!--end_excerpt-->

<h2 id="two-axes-of-difference-syntax-and-computation-model">Two Axes of Difference: Syntax and Computation Model</h2>

<p>There are two axes where Haskell is fundamentally different: <em>The syntax and the computation model</em>.</p>

<p>Haskell has a syntax that is different from languages most experienced developers are familiar with. Also, Haskell’s computation model is based on a different paradigm when compared with most mainstream languages. Understanding this will help in developing a better learning strategy.</p>

<p>Most mainstream programming languages inherit the C-like syntax and have imperative semantics. Haskell syntax is not derived from C, and it is not an imperative language, instead, it is a functional language.</p>

<p>This means a programmer who is experienced with an imperative language with a C-like syntax will find it easy to pick up another imperative language with C-like syntax. Attempting to pick up Haskell in such a similar fashion will be harder and if not aware of these differences, Haskell will feel needlessly hard.</p>

<h3 id="syntax-difference-haskell-is-not-a-c-like-language">Syntax Difference: Haskell is not a C-like language</h3>

<p>Most, if not all current mainstream programming languages have a syntax inspired or derived from C. To illustrate this, let’s take a coding problem from <a href="https://www.codewars.com/">Codewars</a> and see the solutions in the first top <a href="https://www.tiobe.com/tiobe-index/">5 programming languages</a> as rated by the Tiobe programming index, which at the moment of writing this post are: C, Java, Python, C++ and C#. <br></p>

<hr>
<p><br>
<em>Problem Statement: Multiples of 3 or 5</em> <a href="https://www.codewars.com/kata/514b92a657cdc65150000006/">source</a></p>

<p>If we list all the natural numbers below 10 that are multiples of 3 or 5, we get 3, 5, 6, and 9. The sum of these multiples is 23.</p>

<p>Finish the solution so that it returns the sum of all the multiples of 3 or 5 below the number passed in.</p>

<p>Note: If the number is a multiple of both 3 and 5, only count it once. Also, if a number is negative, return 0(for languages that do have them)
<br></p>
<hr>


<p><strong>Solution in C</strong>. <a href="https://www.codewars.com/kata/reviews/59721a02e3383171bf000057/groups/5974d6018a6e59f62b0001a9">source</a></p>

<div><div><pre><code><span>int</span> <span>solution</span><span>(</span><span>int</span> <span>number</span><span>)</span> <span>{</span>
    <span>int</span> <span>total</span> <span>=</span> <span>0</span><span>;</span>
    <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>number</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
      <span>if</span> <span>(</span><span>i</span> <span>%</span> <span>3</span> <span>==</span> <span>0</span> <span>||</span> <span>i</span> <span>%</span> <span>5</span> <span>==</span> <span>0</span><span>)</span> <span>{</span>
        <span>total</span> <span>=</span> <span>total</span> <span>+</span> <span>i</span><span>;</span>
      <span>}</span>
    <span>}</span>
    <span>return</span> <span>total</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p><strong>Solution in Java</strong>. <a href="https://www.codewars.com/kata/reviews/553a8e47f3cc94c58c000123/groups/553adaa02d1cacbea9000048">source</a></p>

<div><div><pre><code><span>public</span> <span>class</span> <span>Solution</span> <span>{</span>

  <span>public</span> <span>int</span> <span>solution</span><span>(</span><span>int</span> <span>number</span><span>)</span> <span>{</span>
    <span>int</span> <span>sum</span><span>=</span><span>0</span><span>;</span>
    <span>for</span> <span>(</span><span>int</span> <span>i</span><span>=</span><span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>number</span><span>;</span> <span>i</span><span>++)</span> <span>{</span>
      <span>if</span> <span>(</span><span>i</span><span>%</span><span>3</span><span>==</span><span>0</span> <span>||</span> <span>i</span><span>%</span><span>5</span><span>==</span><span>0</span><span>)</span> <span>{</span>
        <span>sum</span><span>+=</span><span>i</span><span>;</span>
      <span>}</span>
    <span>}</span>
    <span>return</span> <span>sum</span><span>;</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p><strong>Solution in Python</strong>. <a href="https://www.codewars.com/kata/reviews/54a5ebd237f4350faf00006c/groups/54a7a58272ad2b8b9600055c">source</a></p>

<div><div><pre><code><span>def</span> <span>solution</span><span>(</span><span>number</span><span>):</span>
    <span>sum</span> <span>=</span> <span>0</span>
    <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>number</span><span>):</span>
        <span>if</span> <span>(</span><span>i</span> <span>%</span> <span>3</span><span>)</span> <span>==</span> <span>0</span> <span>or</span> <span>(</span><span>i</span> <span>%</span> <span>5</span><span>)</span> <span>==</span> <span>0</span><span>:</span>
            <span>sum</span> <span>+=</span> <span>i</span>
    <span>return</span> <span>sum</span>
</code></pre></div></div>

<p><strong>Solution in C++</strong>. <a href="https://www.codewars.com/kata/reviews/578538457e3a78630c000166/groups/5799efd74be91294190003ac">source</a></p>

<div><div><pre><code><span>int</span> <span>solution</span><span>(</span><span>int</span> <span>number</span><span>)</span> 
<span>{</span>
  <span>int</span> <span>sum</span> <span>=</span> <span>0</span><span>;</span>
  <span>for</span> <span>(</span><span>int</span> <span>n</span> <span>=</span> <span>3</span><span>;</span> <span>n</span> <span>&lt;</span> <span>number</span><span>;</span> <span>n</span><span>++</span><span>)</span> <span>{</span>
    <span>if</span> <span>((</span><span>n</span><span>%</span><span>3</span> <span>==</span> <span>0</span><span>)</span> <span>||</span> <span>(</span><span>n</span><span>%</span><span>5</span> <span>==</span> <span>0</span><span>))</span>
      <span>sum</span> <span>+=</span> <span>n</span><span>;</span>
  <span>}</span>
  <span>return</span> <span>sum</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p><strong>Solution in C#</strong>. <a href="https://www.codewars.com/kata/reviews/550b09270681519ec1001768/groups/550b0c865951388d45000bd1">source</a></p>

<div><div><pre><code><span>public</span> <span>static</span> <span>class</span> <span>Kata</span>
<span>{</span>
  <span>public</span> <span>static</span> <span>int</span> <span>Solution</span><span>(</span><span>int</span> <span>value</span><span>)</span>
  <span>{</span>
    <span>var</span> <span>sum</span> <span>=</span> <span>0</span><span>;</span>
    <span>for</span><span>(</span><span>int</span> <span>i</span> <span>=</span> <span>3</span><span>;</span> <span>i</span> <span>&lt;</span> <span>value</span><span>;</span> <span>i</span><span>++)</span>
    <span>{</span>
      <span>if</span><span>(</span><span>i</span> <span>%</span> <span>3</span> <span>==</span> <span>0</span> <span>||</span> <span>i</span> <span>%</span> <span>5</span> <span>==</span> <span>0</span><span>)</span> <span>sum</span> <span>+=</span> <span>i</span><span>;</span>
    <span>}</span>
    <span>return</span> <span>sum</span><span>;</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>You see the pattern here? Even in Python, a language that uses whitespace instead of curly braces, the structure of the solutions are all similar. It is not then difficult to see how someone who is proficient in one of the languages can easily make sense of any of the other languages because the structure of their syntax are the same.</p>

<p>Note that some of these imperative languages above now have constructs that makes it possible to emulate functional syntax. For example iterations and operations usually performed via <code>for loops</code> can now be done using construncts like streams and lambdas. This only shows the influence of functional programming on mainstream imperative languages. Infact these functional style is often seen as unnatural to the original languages. The creator of Python, Guido van Rossum, shared a similar sentiment about functional programming style in Python:</p>

<blockquote>
  <p>Python probably has the reputation of supporting functional programming based on the inclusion of lambda, map, filter, and reduce in the language, but in my eyes these are just syntactic sugar, and not the fundamental building blocks that they are in functional languages.</p>
</blockquote>

<ul>
  <li><a href="https://books.google.nl/books?id=yB1WwURwBUQC&amp;pg=PA26&amp;lpg=PA26&amp;dq=Python+probably+has+the+reputation+of+supporting+functional+programming+based+on+the+inclusion+of+lambda,+map,+filter,+and+reduce+in+the+language,+but+in+my+eyes+these+are+just+syntactic+sugar,+and+not+the+fundamental+building+blocks+that+they+are+in+functional+languages&amp;source=bl&amp;ots=-FON4zmkcC&amp;sig=ACfU3U0t3fD8IgnwdRoOLWbMvdRsqmMMOg&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwizwPvo0O_tAhVH4aQKHWrJDuUQ6AEwAHoECAEQAg#v=onepage&amp;q=Python%20probably%20has%20the%20reputation%20of%20supporting%20functional%20programming%20based%20on%20the%20inclusion%20of%20lambda%2C%20map%2C%20filter%2C%20and%20reduce%20in%20the%20language%2C%20but%20in%20my%20eyes%20these%20are%20just%20syntactic%20sugar%2C%20and%20not%20the%20fundamental%20building%20blocks%20that%20they%20are%20in%20functional%20languages&amp;f=false">source</a></li>
</ul>

<p>Now let us see the solution in Haskell:</p>

<p><strong>Solution in Haskell</strong>. <a href="https://www.codewars.com/kata/reviews/5546614c0240a76900000188/groups/5a42ff9c2d59e1e85a0035e0">source</a></p>

<div><div><pre><code><span>module</span> <span>MultiplesOf3And5</span> <span>where</span>
<span>import</span> <span>Data.List</span>

<span>solution</span> <span>::</span> <span>Integer</span> <span>-&gt;</span> <span>Integer</span>
<span>solution</span> <span>n</span> <span>=</span> <span>sum</span> <span>$</span> <span>[</span><span>3</span><span>,</span><span>6</span><span>..</span><span>n</span><span>-</span><span>1</span><span>]</span> <span>`</span><span>union</span><span>`</span> <span>[</span><span>5</span><span>,</span><span>10</span><span>..</span><span>n</span><span>-</span><span>1</span><span>]</span>
</code></pre></div></div>

<p>This looks very different from the previous solutions. The syntax is different and that is because Haskell’s syntax is not inspired by C. <strong>More importantly, this syntax is native to Haskell, and not just a style</strong>. This highlights how Haskell is different when it comes to the axis of syntax.</p>

<blockquote>
  <div><p>An analogy:
Imagine you understand British English, and you want to learn how to write American English. Such a task would be pretty straight forward since you can more or less apply the bulk of the knowledge you already have. What you will then need to learn consists of knowing where to tweak things like the grammar and spelling and idioms that are peculiar to American English. Now contrast that to learning how to write Russian. To do that successfully you will need to be able to set aside what you already know in English and be ready to pick up new grammar rules, new alphabets, new spellings, new idioms, etc.</p><p>
Learning yet another of the mainstream C-family like languages once you know one, is like learning how to speak American English if you already know any variant of English Languages. Learning Haskell on the other hand is similar to already knowing English but wanting to learn Russian. You have to appreciate and understand the fact that the process cannot be approached with a strategy that involves applying what you already know and tweaking one or two things here and there, it has to be approached with the intention to pick up a totally different set of rules about computation and programming. If you are not aware of this fact, then it would become easy to get frustrated and make statements like: I am a senior programmer and in my 10 years of programming I have been able to pick up a new language in 2 weeks tops! I can’t do that with Haskell, hence Haskell is impenetrable. Nope Haskell is not impenetrable, you have just been applying the wrong learning technique. Being aware of this is part of the first steps in learning Haskell successfully.</p></div>
</blockquote>

<h2 id="computation-model-difference-haskell-is-not-an-imperative-language">Computation Model Difference: Haskell is not an imperative language</h2>

<p>The other axis where Haskell is different is its computation model it is based on. This difference is not as obvious as the syntax difference but is a more important difference to appreciate.</p>

<p>Programming languages are based on <a href="https://en.wikipedia.org/wiki/Model_of_computation">Models of computation</a>. This is not difficult to appreciate, as programming languages can be seen as a mechanism to express computations.</p>

<p>The theory of computation and the different possible models have a rich mathematical and academic background, with sequential models, functional models, and concurrent models being the three broad categories.</p>

<p>Most mainstream programming languages are imperative in nature. This means their semantic is derived from the sequential model of computation. To be specific, most imperative languages are implementations of <a href="https://en.wikipedia.org/wiki/Random-access_machine">Random access machines</a>/<a href="https://en.wikipedia.org/wiki/Turing_machine">Turing machines</a>, which are just two examples of the sequential model of computation.</p>

<p>The essence of this model involves expressing computation as a sequential step that involves data mutation together with control structures that control how data is accessed and updated as part of the computation.</p>

<p>This model is the basis of the imperative programming paradigm.</p>

<p>Haskell on the other hand is not based on a sequential model of computation hence it is not an imperative programming language. Haskell is based on the functional model of computation. To be specific, Haskell is an implementation of the <a href="https://en.wikipedia.org/wiki/Lambda_calculus">Lambda calculus</a>, which is one example of a functional model of computation.</p>

<p>The essence of Lambda Calculus involves expressing computation based on function abstraction and application using variable binding and substitution. Haskell, at its core is nothing but an implementation of Lambda Calculus.</p>

<p>These computation models then dictate the mental model that would be required when working with a programming language based on them. A sequential model that involves data mutation requires a different model than a functional model that is an implementation of lambda calculus which requires function abstraction and application.</p>

<p>Hence this is why it is beneficial, especially for seasoned developers picking up Haskell to understand a bit of Lambda Calculus, not to the level required of a mathematician or a computer scientist, but enough to understand why Haskell is the way it is. If not for any other reason but the fact that it will help to appreciate what we mean by function in a mathematical sense and how that is …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://schooloffp.co/2020/12/27/two-reasons-why-you-found-learning-haskell-hard.html">https://schooloffp.co/2020/12/27/two-reasons-why-you-found-learning-haskell-hard.html</a></em></p>]]>
            </description>
            <link>https://schooloffp.co/2020/12/27/two-reasons-why-you-found-learning-haskell-hard.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25549742</guid>
            <pubDate>Sun, 27 Dec 2020 08:38:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust in a KDE Project]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25549727">thread link</a>) | @lukastyrychtr
<br/>
December 27, 2020 | https://jbbgameich.github.io/misc/2020/12/21/rust-in-a-kde-project.html | <a href="https://web.archive.org/web/*/https://jbbgameich.github.io/misc/2020/12/21/rust-in-a-kde-project.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<p>While trying to implement a long planned feature, an ad block in Angelfish, the Plasma Mobile webbrowser,
I was looking for a mostly complete and performant library that provides this functionality.</p>

<p>First I found libadblockplus, which is a C++ library providing the AdblockPlus core functionality.
Sounds great, right? Well, not quite. It includes it’s own v8 java script engine,
and since we are talking about a webbrowser with a QML interface here,
including a third java script engine and a second copy of v8 was absolutely not an option.
Even if this wasn’t a webbrowser,
running a java script engine as implementation detail of a library is at least … problematic.</p>

<p>The other option I found is <a href="https://github.com/brave/adblock-rust">adblock-rust</a>,
which is the built-in ad block of the Brave browser. As the name tells, it is written in Rust,
and I was originally looking for a C++ library. But it turned out this was not much of a problem,
since Rust features excellent C interoperability, just like C++.
Based on this common ground, bindings can be created to use Rust code from C++ (and the other way around if needed).</p>

<h2 id="approach-1">Approach 1</h2>
<p>My first approach was to use raw ffi. That means essentially building a C API featuring the typical C primitive types in rust,
and telling the rust compiler to represent structs in memory the same way that C would do.
Thanks to cbindgen, which automatically generates a header file with the information for the C compiler to know which fields a struct has and were they are,
we directly get something we can include in our C++ project.</p>

<p>The rust build system cargo is capable of running custom code at build time, and we can use that to run cbindgen on our rust code, by adding a file named <code>build.rs</code>:</p>
<pre><code>extern crate cbindgen;

use std::env;

fn main() {
    let crate_dir = env::var("CARGO_MANIFEST_DIR").unwrap();

    cbindgen::generate(&amp;crate_dir)
        .unwrap()
        .write_to_file("bindings.h");
}
</code></pre>

<p>Our core data structure for the ad block looks like this:</p>
<pre><code>#[repr(C)]
pub struct Adblock {
    blocker: *mut Engine,
}
</code></pre>
<p>It stores a pointer to the rust Engine type in a C compatible struct.
The struct can not be created directly from C / C++, since we don’t know anything about the Engine type there.</p>

<p>So we need a function on the rust side that creates and initializes the Engine for us and packs it into an <code>Adblock</code> struct.
Since the code in angelfish is doing a bit more than only that, the function takes two C string arguments, and returns a pointer to a mutable (non-const) Adblock object.</p>
<pre><code>#[no_mangle]
pub extern "C" fn new_adblock(
    list_dir: *const c_char,
    public_domain_suffix_file: *const c_char,
) -&gt; *mut Adblock
</code></pre>
<p>A few more thigs in this function signature are unusual, but they are all related to the FFI / C compatibility we need here:</p>
<ul>
  <li><code>#[no_mangle]</code> tells the rust compiler not to apply its rust specific function name mangling</li>
  <li><code>extern "C"</code> tells that this function should use the C calling conventions.</li>
</ul>

<p>Every time we interact with data from C, the rust compiler is unable to run its usual safety checks.
For that reason we need unsafe blocks around those lines of code.
If anything unexpectedly segfaults, it’s likely to be in our unsafe blocks.
To get a string that we can feed into a usual rust API, we can use <code>unsafe { CStr::from_ptr(public_domain_suffix_file).to_str() }</code>.</p>

<p>For more examples of how to interact with the C / C++ side, feel free to have a look at <a href="https://invent.kde.org/plasma-mobile/plasma-angelfish/-/blob/20e166c0fe2e38be63824b957c02fa58865ac67c/src/rs/adblock/src/adblock.rs">some real code in Angelfish</a>.
I’m by no means an expert on this, but it should help you get started.</p>

<p>Using this approach, the ad block could successfully be implemented in about 140 lines of rust code, of which only half is FFI code, and the rest actual logic.</p>

<h2 id="approach-2">Approach 2</h2>
<p>The second approach is to use the cxx crate (library), which can generate most of the boilerplate FFI code automatically, and provides a modern API on the C++ side.
To do that, it implements its own wrapper types, each wrapping the functionality of one type of one of the languages. Those wrapper types are implemented in both languages, and allow easily passing more advanced types than pointers and number types through the FFI boundary.
On the rust side, the wrapper types are not really visible, because a macro generates everything for us.</p>

<p>The only unusual thing on the rust side will be a small ffi module, declaring which types and functions we want to expose to C++:</p>
<pre><code>#[cxx::bridge]
mod ffi {
    extern "Rust" {
        type Adblock;
        type AdblockResult;

        fn new_adblock(list_dir: &amp;str, suffix_file: &amp;str) -&gt; Box&lt;Adblock&gt;;
        fn should_block(
            self: &amp;Adblock,
            url: &amp;str,
            source_url: &amp;str,
            request_type: &amp;str,
        ) -&gt; Box&lt;AdblockResult&gt;;
    }
}
</code></pre>

<p>All objects are returned as smart pointers, like <code>Box</code>.
On the C++ side, this will result in a <code>rust::Box&lt;Adblock&gt;</code>, which is a type generated by the cxx_build crate, which is doing something slightly similar to cbindgen.</p>

<p>With the cxx crate, our build.rs will look like this:</p>
<pre><code>extern crate cxx_build;

fn main() {
    cxx_build::bridge("src/adblock.rs").compile("angelfish-adblock")
}
</code></pre>

<p>You may wonder, if the cxx crate makes everything so easy, why did I start with approach 1 at all?
I had had a look at the cxx crate a few month ago, when it was still too minimal to do what I needed. Luckily I had another look, since it has become really useful in the meantime.
However learning the raw ffi way was important to understand what actually happens in the background, and I’d almost recommend everyone to have a look at that first before using the cxx crate. Using <code>cargo expand</code> you can then understand what cxx generated for you.</p>

<p>Given the cxx crate makes this so much easier, I initially feared it might add tons of new dependencies and increase the build time, but to my surprise it actually has a lot less dependencies than cbindgen. Even though cbindgen only uses those at build time (they don’t end up in the binary), they take some time to build.</p>

<p>Angelfish has recently switched to using the cxx crate, so you find usage examples in the <a href="https://invent.kde.org/plasma-mobile/plasma-angelfish/-/blob/d92e48e392303deda6cf3c1552f9f7b5189e2953/src/rs/adblock/src/adblock.rs">current version of the ad block code</a>.</p>

<h2 id="build-system">Build system</h2>
<p>After we have written the FFI, we need to build the Rust code as part of our project, most likely using CMake. This could be very annoying and complicated, but luckily <a href="https://github.com/AndrewGaspar/corrosion">Corrosion</a> exists to make this very easy for us.
It can build our rust code using the cargo build system, and create CMake targets for the library we built, so its easy to link against it.</p>

<h2 id="usage-in-kde">Usage in KDE</h2>
<p>Now that the implementation part is explained,
it makes sense to look into where this can be useful and where not.
Unfortunately the truth is that some distros are still not fully happy with having to package rust code,
because the rust community has a different approach to sharing code than known from the C / C++ world.
While Qt re-implements some functionality also found in other C++ libraries, to only make it necessary to package Qt and not one library for json, one for xml, for http and so on, the rust community likes to split everything into small packages, so no unnecessary code is included.</p>

<p>In Angelfish, all the rust code is optional, and Angelfish can of course still be built without Rust.</p>

<p>Possible areas in KDE that could profit from using Rust are icon and SVG theme rendering code, which could profit from using rsvg or resvg.
I can imagine it could also be useful for document thumbnailers, when a rust implementation of the file type already exists. A similar case could be KIO workers, and pretty much any other project that can profit from optional plugins.</p>

<h2 id="conclusion">Conclusion</h2>
<p>This approach to using Rust in KDE allows to make use of the many libraries and language features the ecosystem provides, without running into the infamous “rewrite it in Rust” reflex. It avoids having to create rust bindings for all KDE Frameworks and Qt only to make use of Rust, and still produces readable code.</p>



	</div><p>The comment feature is still experimental! Comments may be deleted at any time.</p></div>]]>
            </description>
            <link>https://jbbgameich.github.io/misc/2020/12/21/rust-in-a-kde-project.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25549727</guid>
            <pubDate>Sun, 27 Dec 2020 08:34:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Infinite Pizza]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25549523">thread link</a>) | @colinprince
<br/>
December 26, 2020 | https://tocogames.itch.io/infinitepizza | <a href="https://web.archive.org/web/*/https://tocogames.itch.io/infinitepizza">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="community_topic_posts_widget_63542"><div><div data-post="{&quot;user_id&quot;:201665,&quot;id&quot;:2357351}" id="post-2357351"><div><a href="https://itch.io/profile/blancokix"></a><div><div><p>This game was amazing. I’m going to get my friend to play it as well. It’s been a while since I played a game that tested me visually in this way.&nbsp;<br></p></div></div></div></div><div data-post="{&quot;user_id&quot;:1656824,&quot;id&quot;:2355504}" id="post-2355504"><div><a href="https://itch.io/profile/bearson"></a><div><p>i really like this game. i have played it for quite a bit. this is my highest record so far and therefore i want to see if its the highest record ever. please anyone reply if they beat it.&nbsp;<img src="https://img.itch.zone/aW1nLzQ4ODIzMzUucG5n/original/T9ALdU.png"><span></span><span></span><br></p></div></div></div><div data-post="{&quot;user_id&quot;:1375852,&quot;id&quot;:2344699}" id="post-2344699"><div><a href="https://itch.io/profile/spaceadmirallaika"></a><div><div><p>I hate how this game makes my brain feel</p><p>plz add VR support</p></div></div></div></div><div data-post="{&quot;user_id&quot;:1891340,&quot;id&quot;:2344514}" id="post-2344514"><div><a href="https://itch.io/profile/poukitoe"></a><div><div><p>That was so much fun, awesome game!&nbsp;</p></div></div></div></div><div data-post="{&quot;user_id&quot;:1889759,&quot;id&quot;:2341541}" id="post-2341541"><div><a href="https://itch.io/profile/usedsoup"></a><div><p>Great game I love falling down this pizza hell but I wish there was a ost download so I can have this hellish feeling cutting a normal pizza.</p></div></div></div><div data-post="{&quot;user_id&quot;:1252386,&quot;id&quot;:2337156}" id="post-2337156"><div><a href="https://itch.io/profile/42ama"></a><div><p>Freaking loved it, even the tension and difficult. But can you introduce auto-play mode into game, I think it will benefit greatly from it.</p></div></div></div><div data-post="{&quot;user_id&quot;:3742989,&quot;id&quot;:2334729}" id="post-2334729"><div><a href="https://itch.io/profile/phonehome"></a><div><p>Small bug: This likes to launch as a VR game in oculus, totally black screen in the headset but still funny. Not sure why it does this. Would like a fix though as it is kind of annoying to have oculus software launch every time the game does.</p></div></div></div><div data-post="{&quot;user_id&quot;:42105,&quot;id&quot;:2331970}" id="post-2331970"><div><a href="https://itch.io/profile/saltire"></a><div><p>Most cyberpunk game of 2020.</p></div></div></div><div data-post="{&quot;user_id&quot;:155990,&quot;id&quot;:2330760}" id="post-2330760"><div><a href="https://itch.io/profile/mortalmercury"></a><div><div><p>I would change 3 things, the tomato splash causes severe lag (like half a second of lags), so an option to disable the splashes would be great, the second thing is a button to speed up the panning up after dying, the third is that sometimes in a circle with two openings, one of them leads to a wall only.</p><p>But apart from that, GREAT</p></div></div></div></div><div data-post="{&quot;user_id&quot;:172283,&quot;id&quot;:2330278}" id="post-2330278"><div><a href="https://itch.io/profile/bodro"></a><div><div><p>Where am I?</p><p><img src="https://img.itch.zone/aW1nLzQ4Mzg0MjQucG5n/original/JBYQHG.png"></p></div></div></div></div><div><div data-post="{&quot;user_id&quot;:155990,&quot;id&quot;:2330748}" id="post-2330748"><div><a href="https://itch.io/profile/mortalmercury"></a><div><div><p>Pizza Hell</p><p>Pineapple pizza</p></div></div></div></div></div><div data-post="{&quot;user_id&quot;:2212832,&quot;id&quot;:2329898}" id="post-2329898"><div><a href="https://itch.io/profile/relevant-tangent"></a><div><p>This was excellent, the slow pan (pizza) up after you die was a great idea.</p></div></div></div><div data-post="{&quot;user_id&quot;:1606160,&quot;id&quot;:2328689}" id="post-2328689"><div><a href="https://itch.io/profile/toasterstrooder"></a><div><div><p>A strange concept, realized very well!&nbsp;</p>
<p>I'm impressed with how well this is optimized. I&nbsp;expected this to make my little laptop explode but it ran totally fine! The only performance hitch I had was some dips when tomatoes and tomato cans would burst after being shot.&nbsp;</p></div></div></div></div><div data-post="{&quot;user_id&quot;:2057754,&quot;id&quot;:2328450}" id="post-2328450"><div><a href="https://itch.io/profile/fraktal0"></a><div><p>Incredible concept with a mouthwatering art style. I would love to traverse further into pizzaspace in an expanded release. Maybe let us order a pizza from a list of ingredients and it generates the level with those ingredients?</p></div></div></div><div data-post="{&quot;user_id&quot;:2227392,&quot;id&quot;:2327278}" id="post-2327278"><div><a href="https://itch.io/profile/sswaffen"></a><div><p>I loooovee non-euclidean geometrical games!!!</p></div></div></div><div data-post="{&quot;user_id&quot;:689115,&quot;id&quot;:2327237}" id="post-2327237"><div><a href="https://itch.io/profile/angelsolodev"></a><div><p>Dude, I want to live in the pizza</p></div></div></div><div data-post="{&quot;user_id&quot;:88329,&quot;id&quot;:2322768}" id="post-2322768"><div><a href="https://itch.io/profile/harderyoufools"></a><div><p>Very good pizza, would traverse again.&nbsp;👍</p></div></div></div><div data-post="{&quot;user_id&quot;:2782444,&quot;id&quot;:2317998}" id="post-2317998"><div><a href="https://itch.io/profile/seventhsentinel"></a><div><p>Trippy. My eyes feel funny. Cool idea.</p></div></div></div><div data-post="{&quot;user_id&quot;:129555,&quot;id&quot;:2314964}" id="post-2314964"><div><a href="https://itch.io/profile/novaprima"></a><div><p>Very Super Hexagon, which means I only played it a few times, haha. But I can still appreciate it.</p></div></div></div><div data-post="{&quot;user_id&quot;:3105432,&quot;id&quot;:2311195}" id="post-2311195"><div><a href="https://itch.io/profile/massive-monk"></a><div><p>This game is a one of a kind experience. I love it!</p></div></div></div><div data-post="{&quot;user_id&quot;:335606,&quot;id&quot;:2310228}" id="post-2310228"><div><a href="https://itch.io/profile/730"></a><div><p>would be nice to see a writeup about this, cool job<br></p></div></div></div><div data-post="{&quot;user_id&quot;:20387,&quot;id&quot;:2310045}" id="post-2310045"><div><a href="https://itch.io/profile/lauramichet"></a><div><p>This game is completely wild. Amazing job</p></div></div></div><div data-post="{&quot;user_id&quot;:102217,&quot;id&quot;:2308291}" id="post-2308291"><div><a href="https://itch.io/profile/secretstage"></a><div><div><p>Psychedelic &amp; delicious! Great visual style and fitting sound!</p>
<p>Can't wait to eat that pizza... as soon as I can get to the other end. :)</p></div></div></div></div><div data-post="{&quot;user_id&quot;:88490,&quot;id&quot;:2308008}" id="post-2308008"><div><a href="https://itch.io/profile/gsantos"></a><div><p>Amazing idea but the game is really too hard, I think colliders could be a little smaller to make it more forgiving.</p></div></div></div><div data-post="{&quot;user_id&quot;:509169,&quot;id&quot;:2306217}" id="post-2306217"><div><a href="https://itch.io/profile/terminusest13"></a><div><p>This was a lot of fun. The sound effects were wonderful, too. Sometimes there were walls that popped up too fast for me to react, but I think I need to acquire proficiency.</p></div></div></div><div data-post="{&quot;user_id&quot;:1961337,&quot;id&quot;:2305217}" id="post-2305217"><div><a href="https://itch.io/profile/fluxsauce"></a><div><p>That was SO WEIRD, love it!</p></div></div></div></div></div></div>]]>
            </description>
            <link>https://tocogames.itch.io/infinitepizza</link>
            <guid isPermaLink="false">hacker-news-small-sites-25549523</guid>
            <pubDate>Sun, 27 Dec 2020 07:36:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A New Google]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25549502">thread link</a>) | @p2pai
<br/>
December 26, 2020 | https://dcgross.com/a-new-google?src=t | <a href="https://web.archive.org/web/*/https://dcgross.com/a-new-google?src=t">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>   <p>[TL;DR: Google has gotten bad; we all know it; ideas for a startup making a better Google.]</p> <p>In 2000, Google got popular because hackers realized it was better than Lycos or Excite. This effect is happening again. Early adopters aren’t using Google anymore.</p> <p>They aren’t using DuckDuckGo either. They’re still using Google.com, but differently. To make Google usable, users are adding faux-query modifiers that to supress the “garbage Internet”.</p> <p>You see this in the typeahead logs.</p> <p><img src="https://dcgross.com/assets/new-google/image6.png" alt=""> <em></em></p><center><em>Products (Reddit)</em></center> <p><img src="https://dcgross.com/assets/new-google/image4.png" alt=""> <em></em></p><center><em>Services (Reddit, Yelp)</em></center> <p><img src="https://dcgross.com/assets/new-google/image1.png" alt=""> <em></em></p><center><em>Movies (Rotten Tomatoes)</em></center> <p><img src="https://dcgross.com/assets/new-google/image5.png" alt=""> <em></em></p><center><em>Even code (Github)</em></center> <p>Interestingly, this doesn’t work for all categories. <img src="https://dcgross.com/assets/new-google/image3.png" alt=""> <img src="https://dcgross.com/assets/new-google/image2.png" alt=""> <em></em></p><center><em>Recipes don’t have a “Reddit” equivalent</em></center> <h3 id="query-operators-mean-somethings-broken">Query Operators Mean Something’s Broken</h3> <p>More advanced users use modifiers like <code>site: filetype: intitle:</code> because adding “reddit” isn’t strict enough, as spammy websites often manipulate content to win SEO.</p> <p>How about those websites that stuff the year in the title? “Reviews UPDATED JANUARY 2020” are exploiting the fact that customers suffix queries with the year. What those people are trying to command is freshness, not a title match.</p> <p>Something’s broken, and a tiny share of Google is open for the taking. Obviously attacking incumbents head-on doesn’t work. Here are two alternative ideas for bootstrapping next-generation search:</p> <h3 id="1-boogle-a-query-reformulator">#1 Boogle, A Query Reformulator</h3> <p>Introducing Boogle, a proxy for Google that’s just Better Google Search. It’s a query expander. We predict the correct operators for your query, proxy Google’s results, and serve. For example:</p> <p><code>query("stripe.js example") -&gt; query("stripe.js example (site:github.com OR site:gitlab.com OR site:..."))</code></p> <p><code>query("is anker charger") -&gt; query("is anker charger (inurl:forum OR site:reddit.com OR ...))"</code></p> <p>Query topic modeling is a rich science with plenty of examples.</p> <p>You’d almost as fast as Google, never worse, and occasionally better. This will help build the reflex to use you instead. This approach isn’t that hard to get started with, and might work for the high-end users.</p>  <p>You could go after this vertical by vertical – build the <em>best</em> site for electric product search, for travel, for code, etc. A key question is how to build habitual recall to use your product over Google. Amazon and Airbnb both enjoy a huge amount of direct traffic. Some learnings from those:</p> <ul> <li><strong>Stellar mobile destination.</strong> Using Airbnb directly feels more fluid and fun than using Google for Airbnb.</li> <li><strong>The 90% Rule.</strong> To build reflex you need to give me what I want most of the time.** **With Prime, Amazon made it such that we stopped price comparing across other sites; Amazon would get it to us fastest, and that turns out to matter more than price. Most of the time you open Amazon.app, it satisfies.</li> <li><strong>Come for search, stay for something else.</strong> I don’t think of Airbnb or Amazon as search apps. They help me get things or book homes. You might want to your search app to be a destination for something else. This is where I think community comes in.</li> </ul> <p>Picking a vertical that <em>doesn’t</em> have strong typeahead completions[1] would help you build community around your search engine. Recipes, fitness, fashion, etc. don’t have decacorn conglomerates like Github or Reddit. That might mean it’s easier to build community around them, and put your flagship search engine on top.</p> <hr> <p>If you’re working on this kind of stuff, try out <a href="https://pioneer.app/">Pioneer</a> or just shoot me an email – daniel@pioneer.app.</p> <hr> <p>[1] In reality I’d pick the vertical _I _love most. If you’re a guitar player start with music; a movie buff should build better Rotten Tomatos. Etc.</p> </article></div>]]>
            </description>
            <link>https://dcgross.com/a-new-google?src=t</link>
            <guid isPermaLink="false">hacker-news-small-sites-25549502</guid>
            <pubDate>Sun, 27 Dec 2020 07:30:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using GNU Stow to manage your dotfiles (2012)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25549462">thread link</a>) | @matthberg
<br/>
December 26, 2020 | http://brandon.invergo.net/news/2012-05-26-using-gnu-stow-to-manage-your-dotfiles.html | <a href="https://web.archive.org/web/*/http://brandon.invergo.net/news/2012-05-26-using-gnu-stow-to-manage-your-dotfiles.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	   

<p>I accidentally stumbled upon something yesterday that I felt like
sharing, which fell squarely into the "why the hell didn’t I know about this
before?" category. In this post, I’ll describe how to manage
the various configuration files in your GNU/Linux home directory (aka
"dotfiles" like <code>.bashrc</code>) using GNU Stow.</p>

<p>The difficulty is that it would be helpful to manage one’s
configuration files with a version control system like Git, Mercurial
or Bazaar, but many/most dotfiles reside at the top-level of your home
directory, where it wouldn’t be a good idea to initialize a VCS
repository. Over time I’ve come across various programs which aim to
manage this for you by keeping all the files in a subdirectory and
then installing or linking them into their appropriate places. None of
those programs ever really appealed to me.  They would require a ton
of dependencies (like Ruby and a ton of libraries for it) or they
would require me to remember how to use them, which is difficult when
really for such a task you rarely use the program.</p>

<p>Lately I’ve been using <a href="http://www.gnu.org/software/stow">GNU Stow</a> to manage
programs I install from source to <code>/usr/local/</code>. Basically, in this typical
usage, you install locally built packages to
<code>/usr/local/stow/${PKGNAME}-{PKGVERSION}</code> and then from <code>/usr/local/stow/</code> you run
<code># stow ${PKGNAME}-${PKGVERSION}</code> and the program generates symbolic links to
all the programs' files into the appropriate places under <code>/usr/local/</code>. Then,
when you uninstall a program via Stow, you don’t have to worry about any stray
files that you or a provide Makefile may have missed. It also makes handling
alternate versions of a program quite easy (i.e. when I’m experimenting with
different configurations of <a href="http://dwm.suckless.org/">dwm</a> or
<a href="http://st.suckless.org/">st</a>).</p>

<p>Some time ago I happened across a mailing list posting where someone described
using Stow to manage the installation of their dotfiles. I didn’t pay much
attention to it but my brain must have filed it away for later. Yesterday I
decided to give it a try and I have to say that it is so much more convenient
than those other dedicated dotfile-management programs, even if it wasn’t an
immediately obvious option.</p>

<p>The procedure is simple. I created the <code>${HOME}/dotfiles</code> directory and then
inside it I made subdirectories for all the programs whose cofigurations I
wanted to manage. Inside each of those directories, I moved in all the
appropriate files, maintaining the directory structure of my home directory. So,
if a file normally resides at the top level of your home directory, it would go
into the top level of the program’s subdirectory. If a file normally goes in the
default <code>${XDG_CONFIG_HOME}/${PKGNAME}</code> location (<code>${HOME}/.config/${PKGNAME}</code>),
then it would instead go in <code>${HOME}/dotfiles/${PKGNAME}/.config/${PKGNAME}</code> and
so on. Finally, from the <code>dotfiles</code> directory, you just run <code>$ stow $PKGNAME</code>
and Stow will symlink all the package’s configuration files to the appropriate
locations. It’s then easy to make the <code>dotfiles</code> a VCS repository so you can
keep track of changes you make (plus it makes it so much easier to share
configurations between different computers, which was my main reason to do it).</p>

<p>For example, let’s say you want to manage the configuration for Bash, VIM and
Uzbl. Bash has a couple files in the top-level directory; VIM typically has your
.vimrc file on the top-level and a .vim directory; and Uzbl has files in
<code>${XDG_CONFIG_HOME}/uzbl</code> and <code>${XDG_DATA_HOME}/uzbl</code>. So, your home directory
looks like this:</p>

<pre><code>home/
    brandon/
        .config/
            uzbl/
                [...some files]
        .local/
            share/
                uzbl/
                    [...some files]
        .vim/
            [...some files]
        .bashrc
        .bash_profile
        .bash_logout
        .vimrc
</code></pre>

<p>You would then create a <code>dotfiles</code> subdirectory and move all the files there:</p>

<pre><code>home/
    /brandon/
        .config/
        .local/
            .share/
        dotfiles/
            bash/
                .bashrc
                .bash_profile
                .bash_logout
            uzbl/
                .config/
                    uzbl/
                        [...some files]
                .local/
                    share/
                        uzbl/
                            [...some files]
            vim/
                .vim/
                    [...some files]
                .vimrc
</code></pre>

<p>Then, perform the following commands:</p>

<pre><code>$ cd ~/dotfiles
$ stow bash
$ stow uzbl
$ stow vim
</code></pre>

<p>And, voila, all your config files (well, symbolic links to them) are
all in the correct place, however disorganized that might be, while
the actual files are all neatly organized in your <code>dotfiles</code>
directory, which is easily turned into a VCS repo. One handy thing is
that if you use multiple computers, which may not have the same
software installed on them, you can pick and choose which
configurations to install when you need them. All of your dotfiles are
always available in your <code>dotfiles</code> directory, but if you don’t need
the configuration for one program, you simply don’t Stow it and thus
it does not clutter your home directory.</p>

<p>Well, that’s all there is to it. Hopefully someone else out there
finds this useful! I know I’ve found it to be a huge help.</p>

<p><a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/deed.en_US"><img alt="Creative Commons License" src="http://i.creativecommons.org/l/by-sa/3.0/88x31.png"></a><br><span xmlns:dct="http://purl.org/dc/terms/" property="dct:title">Using GNU Stow to Manage Your Dotfiles</span> by <a xmlns:cc="http://creativecommons.org/ns#" href="http://brandon.invergo.net/" property="cc:attributionName" rel="cc:attributionURL">Brandon Invergo</a> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/deed.en_US">Creative Commons Attribution-ShareAlike 3.0 Unported License</a>.</p>


             
	   </article></div>]]>
            </description>
            <link>http://brandon.invergo.net/news/2012-05-26-using-gnu-stow-to-manage-your-dotfiles.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25549462</guid>
            <pubDate>Sun, 27 Dec 2020 07:19:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Not Being Bullish Enough on Bitcoin Is a Mistake]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25549230">thread link</a>) | @alwillis
<br/>
December 26, 2020 | https://www.ministryofnodes.com.au/2020/12/19/not-being-bullish-enough-on-bitcoin-is-a-mistake/ | <a href="https://web.archive.org/web/*/https://www.ministryofnodes.com.au/2020/12/19/not-being-bullish-enough-on-bitcoin-is-a-mistake/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<figure><img loading="lazy" width="1024" height="731" src="https://www.ministryofnodes.com.au/wp-content/uploads/2020/12/Not-being-bullish-enough-1024x731.png" alt="" srcset="https://www.ministryofnodes.com.au/wp-content/uploads/2020/12/Not-being-bullish-enough-1024x731.png 1024w, https://www.ministryofnodes.com.au/wp-content/uploads/2020/12/Not-being-bullish-enough-300x214.png 300w, https://www.ministryofnodes.com.au/wp-content/uploads/2020/12/Not-being-bullish-enough-768x548.png 768w, https://www.ministryofnodes.com.au/wp-content/uploads/2020/12/Not-being-bullish-enough-1536x1097.png 1536w, https://www.ministryofnodes.com.au/wp-content/uploads/2020/12/Not-being-bullish-enough-1200x857.png 1200w, https://www.ministryofnodes.com.au/wp-content/uploads/2020/12/Not-being-bullish-enough-1980x1414.png 1980w, https://www.ministryofnodes.com.au/wp-content/uploads/2020/12/Not-being-bullish-enough-600x428.png 600w, https://www.ministryofnodes.com.au/wp-content/uploads/2020/12/Not-being-bullish-enough.png 2000w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Not Being Bullish Enough on Bitcoin is a big mistake. Why? You’ll sell too early, and not grasp Bitcoin well enough to get the big picture here. You might not secure the coins well enough, and you might not actually realise the societal implications of Bitcoin. </p>



<h2>Not Being Bullish Enough On Bitcoin Means Selling too early</h2>



<p>Fundamentally, a lot of people did not truly peer into <a href="http://stephanlivera.com/185">what Bitcoin is</a>, and this made them not bullish enough. This is a big error, as it pushes them to sell bitcoin too early. While they think they’re being clever timing a top, Bitcoin proceeds to humble them a few years later after another cycle. </p>



<p>Lopp has a great example here: </p>



<figure></figure>



<p>At time of writing in Dec 2020, Bitcoin is now around $23,000 USD. Selling early is penny wise, pound foolish. </p>



<p>Many people wish they had bought bitcoin earlier, but truth be told: that’s only half the challenge. The other half is actually HODLing it through the long term and not selling it out. </p>



<p>As bitcoin old-timers in the space will tell you, you could have bought early… but then you probably would have also sold early. It takes understanding and conviction.</p>



<h2>Not Being Bullish Enough On Bitcoin Means Not Securing it Correctly</h2>



<p>It’s a wild roller-coaster. Bitcoin can 10x in the space of a few months, and you can be left <em>very</em> exposed if you’re not careful. A $10k bitcoin stack can quickly become $100k, a $100k stack can quickly become $1M and so on. </p>



<p>Consider the worth of your stack currently, and think about if Bitcoin were to 10x or 20x over a few months or a year. Would you be comfortable with the level of security you have? </p>



<p>If you aren’t bullish enough, and you’re only looking for a 2x and then flip for fiat profits, you aren’t thinking big enough. You should be looking to learn about bitcoin security by listening to SLP such as <a href="http://stephanlivera.com/97">SLP97</a> and <a href="http://stephanlivera.com/215">SLP215</a> with Michael Flaxman. You should be looking at ways to: </p>



<ul><li>Ensure appropriate entropy in your bitcoin seed generation </li><li>Minimise single points of failure</li><li>Consider multi signature</li><li>In the ideal case, use open source hardware and software that has been vetted from a security perspective</li><li>Learn about how to verify signatures for software you use</li><li>Learn hardware wallet best practices</li></ul>



<h2>Not learning enough about how to use Bitcoin the right way</h2>



<p>When we talk about using Bitcoin, we mean using it in a self sovereign way. You shouldn’t be in a situation where you are exclusively trusting or relying on your service provider to give you your bitcoins. </p>



<p>This is not stocks or dollars in your bank account. This is Bitcoin. Use it the self sovereign way. </p>



<p>In practice this means: </p>



<ul><li>Don’t leave your coins in custodial accounts. Use sovereign bitcoin wallets where you hold the private keys. Or at least, a quorum of private keys (e.g. you hold 2 of 3 keys, or 4 of 5 keys). </li><li>Ideally, perform your own validation by running your own underlying bitcoin node. This is easy with <a href="https://www.ministryofnodes.com.au/2020/09/28/cost-effective-bitcoin-use-hardware-wallet-own-node/">Specter Desktop + Bitcoin Core</a>, or with <a href="https://www.ministryofnodes.com.au/2020/03/26/mynode-video-tutorials/">myNode</a>, or other projects e.g. Umbrel, <a href="http://raspiblitz.com/">RaspiBlitz</a>, <a href="http://ronindojo.io/">Ronin Dojo</a>, <a href="http://btcpayserver.org/">BTCPay Server</a>, <a href="http://nodl.it/">nodl</a> etc. </li></ul>



<h2>Not realising the societal implications of Bitcoin</h2>



<p>Fiat money has cultural consequences that many simply do not understand right now. It’s like we’re fish swimming in the water without realising what we’re swimming in. We’ve grown up in an environment of cheap debt, facing incentives to go into debt or lose. </p>



<p>This drives all kinds of changes in our society that weren’t so obvious pre-1971. Increased welfare statism, increased debt, higher time preference, increased centralisation into managerial superstates, to name a few. </p>



<p>As Bitcoin becomes more widely adopted, society’s return to hard money will drive significant cultural shifts that align with the return to hard money. Listen to <a href="http://stephanlivera.com/51">SLP51 with Guido Hulsmann</a> to know more.</p>



<h2>Conclusion</h2>



<p>Fundamentally, it takes knowledge, conviction, and dedication to do this. There are many pitfalls along the way, and it takes work from the HODLer to methodically and skilfully avoid these pitfalls. Of course, we can lament the difficulty and push it off til the future when it’ll be easier. But that is also giving up the huge return potential, and also the freedom and moral imperative of bringing about a Bitcoin Standard. </p>



<p>Do your research and learning, be methodical in your approach, and you’ll be in with a good shot. </p>



<h2>Help With Being Bullish Enough</h2>



<p>See our <a href="https://www.ministryofnodes.com.au/store/">web store</a> for guides and products. For many readers of this blog, you’d probably benefit from using Coldcard + Specter Desktop + Bitcoin Core, for which we offer an in depth video guide <a href="https://www.ministryofnodes.com.au/product/bitcoin-starter-guide-how-to-hold-intermediate/">here</a>. </p>



<p>Or otherwise, if you’re not sure where to start, or want other assistance, we offer zoom call consulting <a href="https://www.ministryofnodes.com.au/consulting/">here</a>. Zoom consults are offered on a ‘pay what you think it was worth’ basis. Book a call, then <a href="https://www.ministryofnodes.com.au/support/">pay us here afterwards</a>.</p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://www.ministryofnodes.com.au/2020/12/19/not-being-bullish-enough-on-bitcoin-is-a-mistake/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25549230</guid>
            <pubDate>Sun, 27 Dec 2020 06:07:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DiamonDie's ASCII Art Tutorial]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25549054">thread link</a>) | @thedookmaster
<br/>
December 26, 2020 | https://www.ludd.ltu.se/~vk/q/asciitutorials/Maija_Haavisto.html#:~:text=ASCII%20art%20is%20always%20done,programs%20for%20making%20ASCII%20art. | <a href="https://web.archive.org/web/*/https://www.ludd.ltu.se/~vk/q/asciitutorials/Maija_Haavisto.html#:~:text=ASCII%20art%20is%20always%20done,programs%20for%20making%20ASCII%20art.">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><i>This tutorial is written by Maija Haavisto (<a href="http://www.angelfire.com/mn/Maija/asciiart.html">old homepage</a>, and <a href="http://diamondie.deviantart.com/">another homepage</a>)</i></p>
<hr>




<h2>Table of contents</h2>
<p>
1 Introduction<br>
2 Types of ASCII art<br>
&nbsp; 2.1 Lineart<br>

&nbsp; 2.2 Solid<br>
&nbsp; 2.3 Grayscale<br>
&nbsp; 2.4 Camelized<br>
&nbsp; 2.5 Others<br>
3 Drawing ASCII art<br>
&nbsp; 3.1 Starting out<br>

&nbsp; 3.2 Lineart<br>
&nbsp; 3.3 Solid art<br>
&nbsp; 3.4 Grayscale<br>
&nbsp; 3.5 Antialiasing<br>
&nbsp; 3.6 Tracing<br>
&nbsp; 3.7 Aspect ratio<br>

&nbsp; 3.8 Difficulties and limitations<br>
&nbsp; 3.9 Perspective, 3D and isometric ASCII<br>
&nbsp; 3.10 Textures and materials<br>
&nbsp; 3.11 Lighting and shadow<br>
&nbsp; 3.12 Uses for different characters<br>
4 Fixed-width fonts<br>

&nbsp;&nbsp;&nbsp; 4.1 Courier New<br>
&nbsp;&nbsp;&nbsp; 4.2 DOS font<br>
&nbsp;&nbsp;&nbsp; 4.3 Topaz New<br>
&nbsp;&nbsp;&nbsp; 4.4 Lucida Console<br>
&nbsp;&nbsp;&nbsp; 4.5 Fixedsys<br>
&nbsp;&nbsp;&nbsp; 4.6 Arial Alternative<br>

&nbsp;&nbsp;&nbsp; 4.7 MS Gothic<br>
&nbsp;&nbsp;&nbsp; 4.8 Andale Mono (aka Monotype.com)<br>
5 ASCII art software<br>
&nbsp;&nbsp; 5.1 JavE<br>
&nbsp;&nbsp; 5.2 FIGlet<br>
&nbsp;&nbsp; 5.3 TheDraw/Aciddraw<br>

&nbsp;&nbsp; 5.4 Acidview<br>
&nbsp;&nbsp; 5.5 PabloDraw<br>
6 Other stuff<br>
&nbsp; 6.1 ASCII map<br>
&nbsp; 6.2 Displaying ASCII art on web pages<br>
&nbsp; 6.3 Coloring ASCII art<br>

&nbsp; 6.4 Demoscene ASCII art<br>
&nbsp; 6.5 ASCII art culture and etiquette

</p><h2>1 Introduction</h2>

<p>ASCII is an acronym of "American Standard Code for Information
Interchange". ASCII art means art made out of different characters in
the ASCII map and can thus be represented in plain text format. It
cannot include extended characters or text formatting such as bold or
italics. ASCII art is always done on a fixed-width font like Courier
New or Fixedsys, never on a proportional font like Arial or Times New
Roman. It can be made in Notepad or MS-DOS Edit, but there are also
some specific programs for making ASCII art. And no, I'm not talking
about ASCII converters.</p><p>
People often comment on ASCII art by saying "Wow, that is so amazing,
I'd never have the patience to make something like that". I don't get
it. Why do they think ASCII art requires so much patience? I can make a
decent fullscreen ASCII in an hour (even if it sometimes takes ten
hours). It takes me at least fifteen hours to draw a decent fullscreen
CG picture.</p><p>
ASCII art isn't easy and it does require skill, but you don't have to
care about things like brush strokes or colors and usually not about
shading either. In a way it is a lot like pixel art. When I started
pixeling it felt very familiar due to my ASCII and ANSI experience.
Pixel artists will probably experience a similar reaction when they
start drawing ASCII. You don't have to have great drawing skills to be
a good ASCII artist. I, for instance, suck at drawing, I can paint but
I can't do the sketch like thing at all. ASCII sketching is practically
something non-existant, but if this interests you, nothing stops you
from trying this new style.</p><p>
Some people wonder what's the point. What's the point in making art in
general? I think limitations are what makes art interesting and feeds
the creative mind. ASCII art probably isn't something that you
encounter in an art museum (which is regrettable), it's more like
everyday art. I guess it has something in common with pop art. ASCII
art can be sent via email or to Usenet newsgroups, it can be
used on IRC and many chatrooms (do that with caution, though). You can
include ASCII art in your signature or login screen or print it out
with your old matrix printer. It can be used for representing game
situations, graphs or molecular models.</p><p>
I've heard opinions of ASCII art not being art but graphical design,
but I disagree with that. Design is usually considered to be something
functional, such as advertisements or interfaces, while visual art is
something you can hang on your walls. ASCII art usually isn't
functional but aesthetical. I know people who have ASCII pictures
hanging on their walls.</p><p>

There are other ASCII tutorials, but I decided there's still room
for another one. Many of the others are outdated, some are even more
than 10 years old. They also feature slightly different techniques and
lack some of the parts that my tutorial focuses on. This turned out
perhaps more like a ASCII drawing/culture FAQ than an actual tutorial,
but I hope it will still be useful.

</p><h2>2 Types of ASCII art</h2>

<h4>2.1 Lineart</h4>

<div><p>Lineart is just what its name implies, things are represented with
(usually thin) outlines, sometimes dotty, sometimes consisting mostly
of slashes, underscores and pipes. Lineart also includes most FIGlet
fonts and demoscene logos. Suitable for both huge images and tiny
pictures.</p></div><pre>            .-"""-.
           '       \
          |,.  ,-.  |
          |()L( ()| |
          |,'  `".| |
          |.___.',| `
         .j `--"' `  `.
        / '        '   \
       / /          `   `.
      / /            `    .
     / /              l   |
    . ,               |   |
    ,"`.             .|   |
 _.'   ``.          | `..-'l
|       `.`,        |      `.
|         `.    __.j         )
|__        |--""___|      ,-'
   `"--...,+""""   `._,.-' mh

Penguin by DiamonDie (2002?)</pre>

<h4>2.2 Solid</h4>

<div><p>Solid art is the "opposite" of lineart, it's not outlined but filled
and flat-shaded.
It's often best fit on mid-sized and large pictures, though it can also
work for small pieces, such as the heart here. Often it looks better
than lineart, simply for the fact that it's not as "thin". Solid art is
often used for logos, ornament designs and text, but it fits almost any
kind of subject. It's not very well suited for faces though.</p></div><pre>  ,o8o, ,o8o,
,888888,888888,
888888888888888
888888888888888
`8888888888888'
  `888888888'
    `88888'
      `8'

Heart by DiamonDie (1997)</pre>

<h4>2.3 Grayscale</h4>

<div><p>Grayscale is like solid art, but it consists of many different
characters that are used to portrays lighter and darker areas, making
it the most suitable kind of ASCII for picturing faces. It is usually
best viewed white on black, such as the example below (people using
most graphical browsers can select it with a mouse or press Ctrl-A to
see it in inverse color). Most converters create grayscale art, though
rather messy kind with often no antialiasing. Grayscale could be
considered the most difficult of all ASCII techniques.</p></div><pre>                           .,,,yyyy@@yyyyy,,,                                  
                      ,ytS$$CCCCCCCCCCCCCCC?III;,.                             
                   .yt$$$$$$$$CCCCCCCCCCCCCCCCIIIIII;.                         
                 ,4$$$$$$$$$$$$$$SCCCCCCCCCCCCCCC?IIIII;                       
               y$$$$$$$$$$$$$$$$$$$$CCCCCCCCCCCCCCCIIII,                       
             ,$$$$$$$$$$$$$$$$$$$$$$$$CCCCCCCCCCCCCCIIII:                      
            l$$$$$$$$$$$$$$$$$$$$$$$$$$$CCCCCCCCCCCCIIIIi                      
           t$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCCCCCCCCCCCIIII:                      
         .l$$$$$$$$$$$$$$$$$$$$$$$$$$$SCCCCCCCCCCCCCIIII,  i                   
         d$$$$$$$$$$$$$$$$$$$$$$$$$$$SCCCCCCCCCCCCCIIIII. ;I,                  
         $$$$$$$$$$$$$$$$$$$$$$$$$$SSCCCCCCCCCCCCCIIIIIII .III                 
        j$$$$$$$$$$$$$$$$$$$$$$$$$SSCCCCCCCCCCCCCCIIIIIIIi.II;                 
        ]$$$$$$$$$$$$$$$$$$$$P"'   `"^?CCCCCCCCCCIIIIIIIIIIIII                 
        l$$$$$$$$$$$$$$$$P"''    .,..   `;?CCCCCCC?IIIIIIIIII;     .y%*        
        l$$$$$$$$$$$$SP"     ,yS$$$$$$Shy..`"IICCCCCCII:  ::      4C7;  \      
        $$$$$$$$$$$SP.   .;;$$$SCCCCCSSCCCCSb: ICCCCCCCII; ''  liC$ClCC;;l     
        $$$$$$$$$$$$I::lIIIICCSSSSSSCCCCCCCCCCIICCCCCCCI       ICCC$lCC??;b    
        P"^^^48$$$$$$SSIII' `Ii :   y,"ICCCS$SCCCCCCCCCCI      ICl"l "7SSbl.   
       :        l$$8888II66 ,?$b,yySIIICC$$$$$$$$SCCCCCCCI     ?CCb l JCC$il   
       :  .    ,$$$$$$CCCC$$$$$$$$$$$$$$$$$$$$$$$$$CCCCCCI     ICS$li$$SCC?l   
        `SS",+.$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCCCCCI     !?S$ ;I$$SCCP   
         "' : S$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCCCCCI      ICSCS$$$$$I    
          ;:6$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCCCCCI        `?C$$$$P     
            `$$$$$$$$$$S$$$$$$$$$$$$$$$$$$$$$$$$$$$CCCCCCI         `""""'      
            j$$$$$$$$$SCCS$$$$$$$$$$$$$$$$$$$$$$$$$CCCCCI                      
            $$$$$$$$$$$$$CI$$$$$$$$$$$$$$$$$$$$$$$SCCCCCI;                     
           j$$$$$$$$$$SS$CI$$$$$$$$$$$$$$$$$$$$$$SSCCCCCIi                     
           7$$$$T7"`,yyiIIC$$$$$$$$$$$$$$$$$$$$$SSSSCCCC?i                     
            "4$SC**7"""-:47$$$$$$$$$$$$$$$$$$$$$SSSSCCCCCI                     
              7I       . ,';' ";7ICS$$$$$$$$$C$S$$$$$CCCCl                     
              : jy.,jyyjCCCCi ..i."7C$$$$$$C$CS$S$$$SCCC?'      ;              
             : d$$$$CCC7?"""""?7CiiCS$$$$SCCCC$S$$$$CCCC;       i,             
              .CC,]CCSSSCCSCCCIiIiICS$$$SSCCCCS$$$$SCC?        .|              
              :`j$$$$$$$$SCCCC$$$CICS$$SCCCCCCCC$CC?;          iI.             
               :l$$$$$$$CCCCCS$$$$C?iCCCCCCCCC7"'.,          .iII,             
                :C?"~~    ,CCC$$$IiIiCCCCCCC?   '           ,IIIII             
                 :$7  ,_,jS$$$$CIiIi?iCCC??                iI?CCCII            
                .;  :;i:;;?S???iiIiIi?i'                iII?CCCCCII.           
                ;  ';'    ?lCi??i;i;;                  iI?CCCCCCCCIIi          
               :            ;? ;I"                  iIIICCSCCCCCCCCIIl         
                ;                             .,iiI?CCCC$$$$$SSCCCCCCIi I, II; 
                 '.                 _,.   ,i,IIII?CCCCCS$$$$$$SSSCCCCIIIIIIIII'
                   ' ~  + =- - ' ~ ` SCCIIIIII???CCCCS$$$$$$$$$$$SCCCCCCC?I"   
                                     l$$CCCCCCCCCCCCS$$$$$$$$$$$$$$$$SCCC"`    

It Figures by `nemoorange</pre>

<h4>2.4 Camelized</h4>

<p>Camelized ASCII art isn't very popular, even though it already appeared
in
the book Alice in Wonderland. It is usually poetry (sometimes prose)
made into the shape of an object, often an animal. There are a couple
of different techniques for making the shapes. Some people use extra
spacing to achieve lines of required length, others wrap words from the
middle or use extra characters. JavE has a feature for camelized ASCII.

</p><h4>2.5 Others</h4>

<p>There are variations of the previously listed styles, such as</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ludd.ltu.se/~vk/q/asciitutorials/Maija_Haavisto.html#:~:text=ASCII%20art%20is%20always%20done,programs%20for%20making%20ASCII%20art.">https://www.ludd.ltu.se/~vk/q/asciitutorials/Maija_Haavisto.html#:~:text=ASCII%20art%20is%20always%20done,programs%20for%20making%20ASCII%20art.</a></em></p>]]>
            </description>
            <link>https://www.ludd.ltu.se/~vk/q/asciitutorials/Maija_Haavisto.html#:~:text=ASCII%20art%20is%20always%20done,programs%20for%20making%20ASCII%20art.</link>
            <guid isPermaLink="false">hacker-news-small-sites-25549054</guid>
            <pubDate>Sun, 27 Dec 2020 05:17:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Startup Working Hours: Burnout, Pacing, and Hustle Culture]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25548423">thread link</a>) | @mooreds
<br/>
December 26, 2020 | https://www.karllhughes.com/posts/working-hours | <a href="https://web.archive.org/web/*/https://www.karllhughes.com/posts/working-hours">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<article>
<div>
<p><img src="https://www.karllhughes.com/assets/img/startup-working-hours.png" alt="Startup Working Hours: Burnout, Pacing, and Hustle Culture">
</p> 

<p>
2020, Dec 16&nbsp;&nbsp;&nbsp;—&nbsp;
8 minute read
</p>
<section id="mc_embed_signup">

</section>
<p>When I joined my first startup almost ten years ago, most of the prevailing wisdom about startups said that you should be ready for an 80-hour per week grind. So, I made it my mission to work longer and harder than anyone else on the path to success.</p>
<p>At that time, I didn’t have a family, significant other, or many hobbies outside of work, plus I liked my job, so it was relatively easy to put in long hours and work weekends. While I did a lot of tasks in those early days, looking back, I realize that <em>I didn’t actually accomplish much.</em></p>
<p>After working for three early-stage startups and <a href="https://www.karllhughes.com/posts/cto-writer">founding my own in 2020</a>, I’ve talked to countless founders about startup hours, pacing, burnout, and hustling. I’ve since seen a lot of founders fall into the trap of working more hours instead of working smarter, so in this post, I’ll give you my perspective on why this happens. Finally, I’ll share a few things that I’ve learned about maintaining balance in a startup from both an employee’s and founder’s perspective.</p>
<h2 id="typical-startup-hours">“Typical” Startup Hours</h2>
<p>One of the challenging things about joining a startup is that there are rarely “typical” work hours. Some startups expect employees to be in the office from 8 am to 8 pm every day and answer emails on the weekend, while others might allow complete flexibility with very little concern over hours worked.</p>
<p><strong>While it’s <a href="https://www.karllhughes.com/posts/myths-working-engineer-startup">a myth that every startup requires you to work overtime every week</a>, most startup employees put in 50-60 hours per week, and many founders put in 60-100 per week.</strong></p>
<p>The problem with long hours is that they’re counterproductive:</p>
<blockquote>
<p>“John Pencavel found that productivity per hour declines sharply when a person works more than 50 hours a week. After 55 hours, productivity drops so much that putting in any more hours would be pointless. And, those who work up to 70 hours a week are only getting the same amount of work done as those who put in the 55 hours.” - <a href="https://www.cnbc.com/2019/03/20/stanford-study-longer-hours-doesnt-make-you-more-productive-heres-how-to-get-more-done-by-doing-less.html">CNBC Report on Standford Productivity Study</a></p>
</blockquote>
<p><a href="https://amzn.to/2WjbkL5"><img src="https://i.imgur.com/Vn2qohv.jpg" alt="Bored and Brilliant book cover"></a></p>
<p>Your body ultimately needs sleep, food, relaxation, and <a href="https://www.gq.com/story/how-and-why-you-should-be-bored"><em>even boredom</em></a> to function properly. This is especially true for those of us who do <a href="https://www.wired.com/story/eight-hour-workday-is-a-lie/">high-concentration, creative work</a> (like writing, programming, and strategic thinking).</p>
<p>One of my favorite reads in 2019 was <em><a href="https://amzn.to/2WjbkL5">Bored and Brilliant</a></em> because it reminded me of the need to put down my phone and just think every once in a while. Regular introspection leads to clarity, focus, and prioritization that is extremely valuable as a startup founder.</p>
<p><em>Looking for more good startup books? I’ve listed <a href="https://www.karllhughes.com/posts/startup-books">a few dozen of my favorites here</a>.</em></p>
<h2 id="why-are-startup-hours-so-long">Why Are Startup Hours so Long?</h2>
<p>So if the research is against long hours for most people, why do startup founders work so much? And, why do they, in turn, expect their employees to do the same?</p>
<p>There are four factors I see at play in defining startup working hours:</p>
<h3 id="1-hustle-culture">1. Hustle Culture</h3>
<blockquote>
<p>“I don’t think it’s fair for people to say that they work 100 hours. That’s just a PR move, like when Elon Musk sleeps on a hard couch in a meeting room. Why couldn’t he have a nice bed delivered to his office?” - <a href="https://www.quora.com/How-many-hours-per-day-do-startup-employees-work-compared-to-those-at-a-regular-company/answer/Nope-Nope-351">Anonymous opinion on Quora</a></p>
</blockquote>
<p>You might think of startup founders as original, free-thinking, creative people, but most of them are just as vulnerable to peer pressure and cultural norms as any of us. So, when high-profile startup founders report that they <a href="https://www.businessinsider.com/elon-musk-sleeps-under-desk-as-tesla-faces-model-3-production-goals-2018-6">slept at the office</a>, other founders see this as a template for success. Some even <a href="https://hbr.org/2015/04/why-some-men-pretend-to-work-80-hour-weeks">lie about the number of hours they work</a> because of the cultural pressure to put in more time.</p>
<h3 id="2-work-life-separation-is-dwindling">2. Work-Life Separation is Dwindling</h3>
<p>It’s even harder to “unplug” from work when your office is six feet away from your bedroom, and your phone goes to bed with you at night. Now that more companies are going remote, employees <a href="https://www.cbsnews.com/news/covid-19-lockdown-work-from-home-day-one-hour-longer/">are working longer hours</a> and having more meetings in what would be off-hours.</p>
<p>The problem is even more pronounced for startup founders. They are often betting their financial future on their new business or so wildly passionate about the problem they solve that it’s next to impossible to “turn it off.”</p>
<h3 id="3-external-pressure">3. External Pressure</h3>
<p>Building a business requires making promises to a lot of people. As a founder, you’re telling employees that they’ll have a job, you’re telling customers that you’ll deliver value, and you’re promising your family that all this sacrifice will be worth it someday. These pressures are amplified when startups raise money because venture-funded startups have a board who might watch the founders closely to make sure they’re working as hard as possible to get them the return they expect.</p>
<p>Once these external pressures are internalized, companies tend to build a culture that encourages long hours. Managers then reward employees who put in the most time, and employees come to expect these working conditions. You can see this vicious cycle most prominently in <a href="https://abovethelaw.com/2019/12/the-biglaw-firm-where-associates-are-putting-in-the-most-working-hours/">law and consulting</a> where billable hours are a badge of honor.</p>
<h3 id="4-gatekeeping">4. Gatekeeping</h3>
<p>This might be controversial, but I believe that part of the reason startups tout their commitments to long hours is as a form of gatekeeping.</p>
<p>When you require everyone in your company to work 60+ hour weeks, you exclude people who have a family at home, kids they need to pick up from school, or mental health issues. This disproportionately hurts minorities, single parents, older workers, and <a href="https://www.telegraph.co.uk/news/2016/06/16/working-long-hours-harms-women-but-protects-men-study-shows/">women</a>, and it’s part of the reason we see fewer underrepresented groups in startups.</p>
<p>This isn’t always the case though. I remember meeting a CTO at another startup early in my career who quit work at 3 pm every day to pick up his kids. This <a href="https://www.karllhughes.com/posts/startup-culture">set a culture at the company</a>, which was totally different from my experience.</p>
<p><img src="https://i.imgur.com/ApmhcQ1.png" alt="Long hours is a form of gatekeeping"></p>
<h2 id="you-need-appropriate-pacing">You Need Appropriate Pacing</h2>
<p>All this pressure will eventually lead to burnout somewhere within your startup. Whether the founder cracks under pressure or you can’t retain employees because of the rigorous pace, it often hurts the organization in the long run.</p>
<p>Short sprints of long hours are possible - and in my experience, often necessary in a startup - but growing a successful company takes years, not months. No number of hours worked can shortcut this fact.</p>
<blockquote>
<p>“If you really look closely, most overnight successes took a long time.” – Steve Jobs</p>
</blockquote>
<p>The problem is that many founders get pressured into thinking short-term. Whether it’s investors pushing them to show traction required for future funding rounds or unfulfilled promises to customers, founders often overcommit themselves to a point where a sustainable pace is impossible.</p>
<h2 id="tips-for-startup-founders">Tips for Startup Founders</h2>
<p>At different stages of a company’s life, different levels of commitment are required. But, no matter what you’re working on, it’s not productive to keep grinding away month after month without giving yourself a break.</p>
<p>Similarly, if you have employees, <strong>you can’t expect them to selflessly spend their lives working long hours and holidays just to help you fulfill your dream.</strong> You <em>can</em> push people to a certain point, but learning how to do so in a productive and worthwhile way is one of the best things you can learn if you want to retain your best employees.</p>
<p>Here are four things I’ve learned about startup work hours and pacing as a founder:</p>
<h3 id="1-dont-push-people-without-a-purpose">1. Don’t Push People Without a Purpose</h3>
<p>It’s tempting as an entrepreneur to always want more from your employees, but just because you feel a sense of urgency in managing your business doesn’t mean every one of your employees will feel the same. <strong>One of the most frustrating things for employees is being pushed to work harder, longer hours without a clear purpose that ties directly into their performance.</strong></p>
<p>Similarly, if you do expect employees to work 60+ hours per week, be upfront with them about this expectation. There are plenty of young go-getters (I was one of them) who don’t mind putting in long hours but be aware that you might be missing some highly-qualified, experienced candidates with this approach.</p>
<h3 id="2-more-work-is-not-a-solution-to-poor-planning">2. More Work is Not a Solution to Poor Planning</h3>
<p>If one department in your company is behind on a deadline, figure out how you can work with them to either adjust expectations, change their requirements, or estimate better next time. Just because you or someone in your organization planned poorly does not mean it’s a good idea to push everyone else to the breaking point.</p>
<h3 id="3-listen-to-your-employees">3. Listen to Your Employees</h3>
<p>Even more important than avoiding situations that stress your employees is listening to them when they are feeling the pressure. If you’re cultivating the right atmosphere at the office, don’t be surprised when someone shows up to tell you that they can’t keep up the pace for another 60 hour week.</p>
<h3 id="4-trust-your-people">4. Trust Your People</h3>
<p>Finally, as an entrepreneur, you have to be able to trust your employees. If you don’t, you need to ask yourself why you hired them or find a way to replace them. When you trust your employees, you’ll know that when they insist they’re working too much, they really are.</p>
<p><em>Note: I’ve added a few books on this topic in <a href="https://www.karllhughes.com/posts/startup-books">my list of the best startup books for founders here</a>.</em></p>
<h2 id="questions-for-potential-startup-employees">Questions for Potential Startup Employees</h2>
<p>While the bulk of an early-stage startup’s culture is defined by the founders, employees and managers have a lot of influence on working hours and pacing too. If you’re being hired by a startup and you’re not sure about what the culture is like, here are some questions you can ask to get a better sense:</p>
<h3 id="1-how-many-hours-per-week-is-typical">1. How Many Hours Per Week is Typical?</h3>
<p>You can ask this question without sounding lazy. I always tell employees this expectation, but if you’re in an interview with a startup and they don’t say it explicitly, it’s better to know what they expect than to be surprised on your first day.</p>
<h3 id="2-do-you-have-typical-working-hours">2. Do You Have Typical Working Hours?</h3>
<p>Again, with more companies going remote, many are also giving employees the option to work their own hours. I have customers in Europe, Australia, Asia, and the US, so even though I try not to work more than 40 hours per week, I don’t have a very “typical” schedule.</p>
<h3 id="3-do-people-hang-out-outside-of-work-much">3. Do People Hang Out Outside of Work Much?</h3>
<p>I asked this question in interviews with startups because I wanted to know the dynamic of …</p></div></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.karllhughes.com/posts/working-hours">https://www.karllhughes.com/posts/working-hours</a></em></p>]]>
            </description>
            <link>https://www.karllhughes.com/posts/working-hours</link>
            <guid isPermaLink="false">hacker-news-small-sites-25548423</guid>
            <pubDate>Sun, 27 Dec 2020 02:57:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google’s API Design Standard]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25548258">thread link</a>) | @dkharrat
<br/>
December 26, 2020 | https://google.aip.dev/general | <a href="https://web.archive.org/web/*/https://google.aip.dev/general">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="jump-content">
          


<section id="aip-main">
  
  <h3 id="meta">Meta</h3>
  <table>
    <thead>
      <tr>
        <th>Number</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
    <tr>
        <td>1</td>
        <td>
          <a href="https://google.aip.dev/1">AIP Purpose and Guidelines</a>
          </td>
      </tr>
      <tr>
        <td>2</td>
        <td>
          <a href="https://google.aip.dev/2">AIP Numbering</a>
          </td>
      </tr>
      <tr>
        <td>200</td>
        <td>
          <a href="https://google.aip.dev/200">Precedent</a>
          </td>
      </tr>
      <tr>
        <td>8</td>
        <td>
          <a href="https://google.aip.dev/8">AIP Style guide</a>
          </td>
      </tr>
      <tr>
        <td>9</td>
        <td>
          <a href="https://google.aip.dev/9">Glossary</a>
          </td>
      </tr>
      </tbody>
  </table>
  <h3 id="process">Process</h3>
  <table>
    <thead>
      <tr>
        <th>Number</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
    <tr>
        <td>100</td>
        <td>
          <a href="https://google.aip.dev/100">API Design Review FAQ</a>
          </td>
      </tr>
      <tr>
        <td>205</td>
        <td>
          <a href="https://google.aip.dev/205">Beta-blocking changes</a>
          </td>
      </tr>
      </tbody>
  </table>
  <h3 id="resource-design">Resource Design</h3>
  <table>
    <thead>
      <tr>
        <th>Number</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
    <tr>
        <td>121</td>
        <td>
          <a href="https://google.aip.dev/121">Resource-oriented design</a>
          </td>
      </tr>
      <tr>
        <td>122</td>
        <td>
          <a href="https://google.aip.dev/122">Resource names</a>
          </td>
      </tr>
      <tr>
        <td>123</td>
        <td>
          <a href="https://google.aip.dev/123">Resource types</a>
          </td>
      </tr>
      <tr>
        <td>124</td>
        <td>
          <a href="https://google.aip.dev/124">Resource association</a>
          </td>
      </tr>
      <tr>
        <td>126</td>
        <td>
          <a href="https://google.aip.dev/126">Enumerations</a>
          </td>
      </tr>
      <tr>
        <td>128</td>
        <td>
          <a href="https://google.aip.dev/128">Declarative-friendly interfaces</a>
          <span>
            Reviewing
          </span>
          </td>
      </tr>
      <tr>
        <td>156</td>
        <td>
          <a href="https://google.aip.dev/156">Singleton resources</a>
          </td>
      </tr>
      </tbody>
  </table>
  <h3 id="operations">Operations</h3>
  <table>
    <thead>
      <tr>
        <th>Number</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
    <tr>
        <td>131</td>
        <td>
          <a href="https://google.aip.dev/131">Standard methods: Get</a>
          </td>
      </tr>
      <tr>
        <td>132</td>
        <td>
          <a href="https://google.aip.dev/132">Standard methods: List</a>
          </td>
      </tr>
      <tr>
        <td>133</td>
        <td>
          <a href="https://google.aip.dev/133">Standard methods: Create</a>
          </td>
      </tr>
      <tr>
        <td>134</td>
        <td>
          <a href="https://google.aip.dev/134">Standard methods: Update</a>
          </td>
      </tr>
      <tr>
        <td>135</td>
        <td>
          <a href="https://google.aip.dev/135">Standard methods: Delete</a>
          </td>
      </tr>
      <tr>
        <td>136</td>
        <td>
          <a href="https://google.aip.dev/136">Custom methods</a>
          </td>
      </tr>
      <tr>
        <td>151</td>
        <td>
          <a href="https://google.aip.dev/151">Long-running operations</a>
          </td>
      </tr>
      <tr>
        <td>231</td>
        <td>
          <a href="https://google.aip.dev/231">Batch methods: Get</a>
          </td>
      </tr>
      <tr>
        <td>233</td>
        <td>
          <a href="https://google.aip.dev/233">Batch methods: Create</a>
          </td>
      </tr>
      <tr>
        <td>234</td>
        <td>
          <a href="https://google.aip.dev/234">Batch methods: Update</a>
          </td>
      </tr>
      <tr>
        <td>235</td>
        <td>
          <a href="https://google.aip.dev/235">Batch methods: Delete</a>
          </td>
      </tr>
      </tbody>
  </table>
  <h3 id="fields">Fields</h3>
  <table>
    <thead>
      <tr>
        <th>Number</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
    <tr>
        <td>140</td>
        <td>
          <a href="https://google.aip.dev/140">Field names</a>
          </td>
      </tr>
      <tr>
        <td>203</td>
        <td>
          <a href="https://google.aip.dev/203">Field behavior documentation</a>
          </td>
      </tr>
      <tr>
        <td>141</td>
        <td>
          <a href="https://google.aip.dev/141">Quantities</a>
          </td>
      </tr>
      <tr>
        <td>142</td>
        <td>
          <a href="https://google.aip.dev/142">Time and duration</a>
          </td>
      </tr>
      <tr>
        <td>143</td>
        <td>
          <a href="https://google.aip.dev/143">Standardized codes</a>
          </td>
      </tr>
      <tr>
        <td>144</td>
        <td>
          <a href="https://google.aip.dev/144">Repeated fields</a>
          </td>
      </tr>
      <tr>
        <td>145</td>
        <td>
          <a href="https://google.aip.dev/145">Ranges</a>
          </td>
      </tr>
      <tr>
        <td>146</td>
        <td>
          <a href="https://google.aip.dev/146">Generic fields</a>
          </td>
      </tr>
      <tr>
        <td>147</td>
        <td>
          <a href="https://google.aip.dev/147">Sensitive fields</a>
          </td>
      </tr>
      <tr>
        <td>148</td>
        <td>
          <a href="https://google.aip.dev/148">Standard fields</a>
          <span>
            Reviewing
          </span>
          </td>
      </tr>
      <tr>
        <td>216</td>
        <td>
          <a href="https://google.aip.dev/216">States</a>
          </td>
      </tr>
      </tbody>
  </table>
  <h3 id="design-patterns">Design Patterns</h3>
  <table>
    <thead>
      <tr>
        <th>Number</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
    <tr>
        <td>152</td>
        <td>
          <a href="https://google.aip.dev/152">Jobs</a>
          </td>
      </tr>
      <tr>
        <td>153</td>
        <td>
          <a href="https://google.aip.dev/153">Import and export</a>
          </td>
      </tr>
      <tr>
        <td>154</td>
        <td>
          <a href="https://google.aip.dev/154">Resource freshness validation</a>
          </td>
      </tr>
      <tr>
        <td>155</td>
        <td>
          <a href="https://google.aip.dev/155">Request identification</a>
          </td>
      </tr>
      <tr>
        <td>157</td>
        <td>
          <a href="https://google.aip.dev/157">Partial responses</a>
          </td>
      </tr>
      <tr>
        <td>158</td>
        <td>
          <a href="https://google.aip.dev/158">Pagination</a>
          </td>
      </tr>
      <tr>
        <td>159</td>
        <td>
          <a href="https://google.aip.dev/159">Reading across collections</a>
          </td>
      </tr>
      <tr>
        <td>160</td>
        <td>
          <a href="https://google.aip.dev/160">Filtering</a>
          </td>
      </tr>
      <tr>
        <td>162</td>
        <td>
          <a href="https://google.aip.dev/162">Resource Revisions</a>
          </td>
      </tr>
      <tr>
        <td>163</td>
        <td>
          <a href="https://google.aip.dev/163">Change validation</a>
          </td>
      </tr>
      <tr>
        <td>164</td>
        <td>
          <a href="https://google.aip.dev/164">Soft delete</a>
          <span>
            Reviewing
          </span>
          </td>
      </tr>
      <tr>
        <td>165</td>
        <td>
          <a href="https://google.aip.dev/165">Criteria-based delete</a>
          </td>
      </tr>
      <tr>
        <td>210</td>
        <td>
          <a href="https://google.aip.dev/210">Unicode</a>
          </td>
      </tr>
      <tr>
        <td>214</td>
        <td>
          <a href="https://google.aip.dev/214">Resource expiration</a>
          </td>
      </tr>
      <tr>
        <td>217</td>
        <td>
          <a href="https://google.aip.dev/217">Unreachable resources</a>
          </td>
      </tr>
      </tbody>
  </table>
  <h3 id="compatibility">Compatibility</h3>
  <table>
    <thead>
      <tr>
        <th>Number</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
    <tr>
        <td>180</td>
        <td>
          <a href="https://google.aip.dev/180">Backwards compatibility</a>
          </td>
      </tr>
      <tr>
        <td>181</td>
        <td>
          <a href="https://google.aip.dev/181">Stability levels</a>
          </td>
      </tr>
      </tbody>
  </table>
  <h3 id="polish">Polish</h3>
  <table>
    <thead>
      <tr>
        <th>Number</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
    <tr>
        <td>191</td>
        <td>
          <a href="https://google.aip.dev/191">File and directory structure</a>
          </td>
      </tr>
      <tr>
        <td>192</td>
        <td>
          <a href="https://google.aip.dev/192">Documentation</a>
          </td>
      </tr>
      <tr>
        <td>193</td>
        <td>
          <a href="https://google.aip.dev/193">Errors</a>
          </td>
      </tr>
      <tr>
        <td>194</td>
        <td>
          <a href="https://google.aip.dev/194">Automatic retry configuration</a>
          </td>
      </tr>
      </tbody>
  </table>
  <h3 id="protobuf">Protocol buffers</h3>
  <table>
    <thead>
      <tr>
        <th>Number</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
    <tr>
        <td>127</td>
        <td>
          <a href="https://google.aip.dev/127">HTTP and gRPC Transcoding</a>
          </td>
      </tr>
      <tr>
        <td>213</td>
        <td>
          <a href="https://google.aip.dev/213">Common components</a>
          </td>
      </tr>
      <tr>
        <td>215</td>
        <td>
          <a href="https://google.aip.dev/215">Common component versions</a>
          </td>
      </tr>
      </tbody>
  </table>
  
</section>

        </section></div>]]>
            </description>
            <link>https://google.aip.dev/general</link>
            <guid isPermaLink="false">hacker-news-small-sites-25548258</guid>
            <pubDate>Sun, 27 Dec 2020 02:19:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reflecting on London Underground's Overheating]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25548128">thread link</a>) | @CalvinBarrows
<br/>
December 26, 2020 | https://www.railbusinessdaily.com/a-reflective-perspective-the-whys-and-wherefores-of-metro-overheating/ | <a href="https://web.archive.org/web/*/https://www.railbusinessdaily.com/a-reflective-perspective-the-whys-and-wherefores-of-metro-overheating/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content" role="main">
	
<article id="post-32595">

<section>
	<img width="1000" height="580" src="https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/RB-Calvin-1000x580.jpg" alt="Calvin Barrows">	     
<section>
<span>3rd August 2020</span>
</section>   
	
            <!-- Share buttons by mashshare.net - Version: 3.7.2--><p>Calvin Barrows has written an article for railbusinessdaily.com about the root cause(s) of overheating in certain metro systems, using London Underground’s ‘Tube’ Network as an example.</p>
<p>Calvin is a Chartered Engineer, latterly retired. His work focused on forensic engineering, to establish the mechanisms of structural and mechanical failures; then continuing as an engineering manager, within the rail industry.</p>
<p>Sylvia Telatycka is co-author and linguist, who with Calvin runs a small but successful property development and rental business.</p>
<p>“This guest article aims to encourage a wider discussion around our hypothesis as to the root cause(s) of overheating in certain metro systems, using London Underground’s ‘Tube’ Network as an example.</p>
<p>Rather than go into complicated thermodynamic formulae to demonstrate the credible science upon which this theory is based, we have described in simple terms the comparable heat generation and heat exchange processes at work, to clarify how these affect this historic Tube network. This is important because, in the earliest days of the London Tube, overheating was simply not an issue…. but WHY….?</p>
<p>In the first instance, we need to understand clearly what the problem is. Paraphrasing Charles Kettering: a problem well defined is half solved and mindful of that, we took the basic premise of the Tube overheating and framed a series of questions to help identify the problem.</p>
<p>1. When does overheating happen?</p>
<p>2. Do ALL metros/subways overheat?</p>
<p>3. Why might some metros/subways overheat, and some might not?</p>
<p>4. And why are these questions relevant to London’s network?</p>
<p>5. How can this overheating be mitigated?</p>
<p>Few would disagree that the Tube overheats but understanding WHEN and WHERE it happens is most revealing. In winter passengers mainly travel bundled up in their winter coats and the saloons are heated. In summer, heavy clothing is shed – indeed some passengers have been known to travel in swimwear.</p>
<p><img src="https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/Screenshot-2020-08-03-at-14.20.35.png" alt="" width="598" height="320" srcset="https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/Screenshot-2020-08-03-at-14.20.35.png 598w, https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/Screenshot-2020-08-03-at-14.20.35-300x161.png 300w" sizes="(max-width: 598px) 100vw, 598px"></p>
<p>In the above graph i, London’s mean surface ambient air temperatures, averaged over a 30 year period, show a clear increase from approximately -5°C in the winter to around +30°C in the summer.</p>
<p>Interestingly, the following graph ii represents the results of TfL’s temperature monitoring within the underground network, for both the deep tube and sub-surface lines. The TfL temperature variations not only confirm passengers’ subjective perception, they also mimic the curve of temperature data above and demonstrate conclusively that underground network temperatures align with the external seasonal temperatures.</p>
<p><img src="https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/Screenshot-2020-08-03-at-14.22.17.png" alt="" width="587" height="298" srcset="https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/Screenshot-2020-08-03-at-14.22.17.png 587w, https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/Screenshot-2020-08-03-at-14.22.17-300x152.png 300w" sizes="(max-width: 587px) 100vw, 587px"></p>
<p>In the course of our research we looked at different types of rail networks, categorising them as follows because they all perform differently in relation to overheating:-</p>
<p>1. Metro train networks – which run ONLY underground.</p>
<p>2. Trains networks – which run predominately overground.</p>
<p>3. Metro train networks – which run both overground and underground.</p>
<p>Underground-only networks like Glasgow’s or Warsaw’s are not affected by the overground conditions, so there is little seasonal variation in train and network temperatures. Their ambient underground temperature remains about 16°C – unlike the wide temperature range the TfL data above show for London’s Tube network. Underground-only networks irrefutably demonstrate that operational heat such as braking, being generated year-round, is NOT a significant cause of metro networks overheating. Furthermore, since passengers are not being exposed to overheating they remain comfortable and safe.</p>
<p>Overground-only trains are cool in winter and therefore heated. However, in summer they will overheat, unless they are proactively cooled, usually by air-conditioning, though AC deals with the symptoms, not underlying causes, and it is environmentally unfriendly. Whilst AC is technically sound as long as it can discharge the exhaust heat to free air, if it does not work for some reason…. What then? There have been at least three incidents over the last 15 years where power failures compromised the AC, triggering saloon temperature rises to 46°C; with distressed passengers fainting from heat exhaustion, and others desperate enough to smash windows and even to try and break through emergency doors.</p>
<p>Which brings us neatly to MIXED metro networks like London’s Tube, which run both overground and underground, to see why this overheating is NOT restricted to the overground areas of these networks. The reason behind this apparent contradiction is that these mixed networks are, thermodynamically speaking, open systems – ones that freely exchange energy and matter with their surroundings – where:-</p>
<p>1. The free exchange of energy is a regular transfer of air in and out of the tunnels; and</p>
<p>2. The free exchange of mass is a regular travel of hot, loaded trains in and out of the tunnel.</p>
<p>TfL engineers continue to focus on ‘base load’, aka the operational heat, which by definition is year-round, so this can never explain the seasonal nature of the problem. Saloon AC is not a viable solution here, expelling more heat into an already overheated tunnel. We need to be thinking more holistically: rather than the ‘Cooling the Tube Project’ it should be the ‘Cooling the Whole Tube Network in the Summer Project’.</p>
<p>Clearly the root cause of this 100+ year old seasonal problem is the SUN. However, its sheer power to affect every aspect of a network like London’s Tube has been significantly underestimated. In a thermodynamic nutshell:-</p>
<p>1. Radiation from the sun is short wave energy in the form of light, which on striking the earth or a solid object increases their internal energy.</p>
<p>2. This internal energy is in the form of heat and is then re-radiated from the surface of the earth (and solid objects) as long wave heat energy, which in turn warms the ambient air.</p>
<p>The unintentional consequence of the above process in a thermodynamically open system is that hot ambient air plus heat from solar irradiated trains travelling on the surface is carried into the tunnels.</p>
<p>In the context of mixed metro networks, when overground, all external surfaces of the train exposed to the sun, including wheels and bogies, are being directly irradiated. Like any heat conductive surface, the irradiated train body get hot. The sun’s shortwave radiation readily shines through the window glass; then striking the internal surfaces is converted into heat within those materials. However, heat being longwave radiation and, struggling to pass back out through the window glass, is trapped – an unintended ‘greenhouse’ effect. Finally, the undercarriage components consist of massive chunks of metal – usually black – with the ability to absorb immense amounts of heat.</p>
<p>Furthermore, while rail buckling is a familiar problem, the knock-on effects of the sun on the track beds have never really figured in the context of the network overheating. The whole of the track bed including the rails is absorbing and reflecting heat. So, when trains pass over it, this heat is then reflected outwards and upwards into the wheels, bogies, underside of the carriages, the brakes and traction motors. These get super-heated, not so much through operation, but principally because they are in an overheated environment.</p>
<p><img src="https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/Screenshot-2020-08-03-at-14.22.34.png" alt="" width="548" height="282" srcset="https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/Screenshot-2020-08-03-at-14.22.34.png 548w, https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/Screenshot-2020-08-03-at-14.22.34-300x154.png 300w" sizes="(max-width: 548px) 100vw, 548px"></p>
<p>The above concept graph predicts the build-up of solar irradiation acting on a train, starting early in the day and repeatedly travelling (in this example) the length of the Central Line. The train is irradiated when overground and dissipates a large proportion of that heat load during the underground sections of the journey. However, each irradiated train movement passing throughout the entire network compounds the effect of previous trains, elevating tunnel temperatures even more as the day progresses – rudimentary monitoring has shown saloon temperatures overground typically increase by up to 6°C in 30 mins between Leyton and Epping around 4.30-5.00pm on a summer afternoon.</p>
<p>While the piston-drag effect as the train passes in and out of the tunnel portals will draw in hot ambient air, probably contributing a small amount of heat to the underground sections, compared to the storage-radiator capacity of the train itself, cumulatively dissipating within the tunnel, it is unlikely to be that significant.</p>
<p>Having identified the root causes of overheating and the contributing factors, the task of managing the overheating in the tunnels is actually quite simple – deal with the overheating of the trains on the surface BEFORE THEY ENTER THE TUNNELS.</p>
<p>There are four obvious radiant barrier measures. These are solar-reflective paints (typical surface temperature reductions of 20⁰C) and Low E glass (absorbing some 80% less solar radiation than standard glass), both of which could be easily retroactively applied to existing trains and become the standard for new rolling stock. Then there is green planting on tracks, with its low heat absorption properties compared to ballast and rails. Once in place maintenance costs should be minimal and the benefits considerable. Lastly effective stabling of off-peak trains, providing appropriate solar shade AND ventilation, is imperative.</p>
<p>In conclusion, and most importantly, it should not be forgotten that overheating saloons will adversely affect passenger health and safety. In London’s Tube, this problem would be exacerbated in a ‘stalled-train event’ underground. Passengers overheated in a carriage, within an overheated tunnel, is a potentially fatal matter, especially when temperatures rise, as they often do in summer, to 40°C or higher and where passengers can do nothing but wait until LU staff can direct their escape.”</p>
<p>i Meteoblue (2020) Climate London Basel Switzerland www.meteoblue.com https://www.meteoblue.com/en/weather/historyclimate/climatemodelled/london_united-kingdom_2643743</p>
<p>ii Transport for London (July 2018) Average monthly evening peak temperatures by line London: Transport for London …</p></section></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.railbusinessdaily.com/a-reflective-perspective-the-whys-and-wherefores-of-metro-overheating/">https://www.railbusinessdaily.com/a-reflective-perspective-the-whys-and-wherefores-of-metro-overheating/</a></em></p>]]>
            </description>
            <link>https://www.railbusinessdaily.com/a-reflective-perspective-the-whys-and-wherefores-of-metro-overheating/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25548128</guid>
            <pubDate>Sun, 27 Dec 2020 01:49:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Start Contributing to Open Source Software]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25547724">thread link</a>) | @fagnerbrack
<br/>
December 26, 2020 | https://markushatvan.com/blog/why-you-should-start-contributing-to-open-source-software-right-now | <a href="https://web.archive.org/web/*/https://markushatvan.com/blog/why-you-should-start-contributing-to-open-source-software-right-now">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><figure> <figcaption>I know you want to. - Photo by Author </figcaption></figure> <p>You might not be aware of it, but you use some form of open source software every single day.</p> <p>Every time you start an app on your phone or launch a program on your computer, you profit from the code that someone has written for free.</p> <p>WordPress, the largest and most well-known content management system, is used by <a href="https://w3techs.com/technologies/details/cm-wordpress" rel="nofollow">38% of all websites</a> worldwide. It is open source and free to use.</p> <p>Linux is powering <a href="https://w3techs.com/technologies/details/os-linux" rel="nofollow">30% of all websites</a> globally. It is open source and free to use.</p> <p>These are just two examples out of a myriad of projects which were created to solve a problem or serve a use case.</p> <p>These projects became highly popular as communities formed around them. They tried to deliver the best product possible in terms of user experience, stability, security, and more.</p> <p>But not only the usage of open source projects is rising. The participation in the open source movement as a whole is growing as well.</p> <p>According to the <a href="https://octoverse.github.com/" rel="nofollow">State of the Octoverse report</a> by GitHub, out of more than 40 million developers on GitHub, 10 million new&nbsp;users joined in 2019 alone!</p> <p>The open source movement is growing quickly and you should become a part of it too.</p> <p>Whenever I see a new update for my operating system or new software releases of tools that I actively use every day, it makes me smile. I enjoy the thought of products continuously getting better and more sophisticated.</p> <p>Do you feel the same way?</p> <p>Here is why I am convinced that you should start contributing to open source software right now.</p> <h2>You can learn a lot from the source code</h2> <p>Since the source code in open source projects is available for anyone to read, that means that a large number of developers can battle-test and improve a project.</p> <p>Developers point out privacy or security issues, update the documentation, and improve source code to the newest web development standards all the time.</p> <p>Especially when you go through the code of projects with hundreds or even thousands of contributors, you can gain immense knowledge about best practices and code quality.</p> <p>Not only is reviewing the code itself a learning experience, but also the structure and folder hierarchy in larger projects is well thought-out and works well in the long run.</p> <h2>You will work with the smartest people</h2> <p>Compared to a company that has a limited number of employees to work on feature requests and bug fixes, you have the brightest minds working in open source development.</p> <p>In my imagination, I see it as swarm intelligence, which can solve every problem that arises.</p> <p>The more people that join a community, the better a project can scale. It can be like a buzzing beehive, where you could have pull requests to a codebase from users all around the world 24/7, non-stop.</p> <p>A good example is the well-known code editor <a href="https://github.com/microsoft/vscode" rel="nofollow">Visual Studio Code</a> which got very popular with a total of 1,200+ contributors on GitHub.</p> <p>You won’t see a single day without any pull requests on GitHub and the monthly release cycles always bring out new amazing features.</p> <p>When you participate in a project and submit a pull request, you will receive extremely helpful feedback from highly experienced maintainers. You can then implement that feedback to grow as a developer.</p> <h2>Your own code could be used globally</h2> <p>Since some software development projects are used by millions of users daily, it can be very rewarding to see your own code helping so many people.</p> <p>I wrote lint rules for the JavaScript projects called <a href="https://github.com/sindresorhus/eslint-plugin-unicorn" rel="nofollow">eslint-plugin-unicorn</a> and <a href="https://github.com/sveltejs/svelte" rel="nofollow">svelte</a>. It’s a great feeling knowing that my pull request will improve the code quality of many developers all around the world.</p> <p>From my personal experience, it is also motivating to get positive feedback in the form of a thankful comment.</p> <h2>Open source projects are inclusive</h2> <p>A great advantage of free open source software is that no one is excluded from using the product because they can’t afford it.</p> <p>While some open source projects cost money to use, most do not.</p> <p>Also, when you’re contributing to a project on GitHub, many of the bigger repositories have a code of conduct. These make sure that every contributor feels welcome and accepted in a project.</p> <h2>Projects are starting to become sustainable</h2> <p>The main goal of a company is to become profitable - which often leads to questionable decisions. But open source software focuses on solving the needs of its users as the highest priority.</p> <p>Most projects are entirely volunteer-supported, and project maintainers will unfortunately never see any financial reward. But there are great ways nowadays that you can help make these projects sustainable.</p> <p>With websites like <a href="https://opencollective.com/" rel="nofollow">OpenCollective</a>&nbsp;or <a href="https://github.com/sponsors" rel="nofollow">GitHub Sponsors</a>, you can donate to speed up the development of projects that you like.</p> <p>Personally, I think that it would be great if every company donated at least a small sum to open source software projects because they profit from these tools daily. Such support would reduce the stress for a lot of maintainers and some could even take up the work full-time.</p> <h2>How to contribute to open source</h2> <p>Contributing to open source development sounds more scary than it really is. There are plenty of projects out there on GitHub which encourage first time contributors and newbies to take action by labeling issues as “Good first issue”, “Beginner friendly” or “Help wanted”.</p> <p>Don’t know where to start?</p> <p>Ask yourself: what is an application that you enjoy using every day and where you would want to give back?</p> <p>It can be as simple as searching for that application on GitHub and looking through the open issues.</p> <p>It doesn’t have to be a code contribution, either - you can also help out by creating a pull request to update the documentation, fix typos that you find, or by doing a thorough code review.</p> <p>The <code>README.md</code> file of a project usually includes a passage of how to contribute.</p> <p>If you decide to contribute to a project, I recommend reading my article about&nbsp;<a href="https://markushatvan.com/blog/contributing-to-open-source-projects-the-right-way">Contributing To Open Source Projects The Right Way</a>. It’s a detailed step-by-step guide about the contribution workflow.</p> <p>I wrote it to be very beginner friendly, so don’t worry about becoming overwhelmed. You will be able to find your first project and submit a contribution in no time!</p> <h2>Wrapping up</h2> <p>It always impressed me that everyone in the world can join an open source software project and work on it.</p> <p>And open source software only works as a collaborative effort. The goal is to produce the best product or service without compromising on important factors like stability, security, or user privacy.</p> <p>I hope you understand the importance of open source software and that you value its benefits. No matter what your reasons are for giving back to the open source community, just know that you are highly appreciated!</p> <p>Many projects can only thrive with support and contributions from developers like you.</p> <h2>Helpful resources</h2> <ul><li><a href="https://octoverse.github.com/" rel="nofollow">The State of the Octoverse</a></li> <li><a href="https://opensource.com/resources/what-open-source" rel="nofollow">What is open source?</a></li> <li><a href="https://clearcode.cc/blog/why-developers-contribute-open-source-software/" rel="nofollow">What Motivates a Developer to Contribute to Open-Source Software?</a></li></ul> <div><p><b>If you liked this post, share it:</b></p> <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fmarkushatvan.com%2Fblog%2Fwhy-you-should-start-contributing-to-open-source-software-right-now" rel="noopener noreferrer" target="_blank" title="Share on Facebook"><svg height="24" role="presentation" style="font-size:1.5em" version="1.1" viewBox="0 0 512 512" width="24"> <path d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z" key="path-0"></path> </svg></a> <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fmarkushatvan.com%2Fblog%2Fwhy-you-should-start-contributing-to-open-source-software-right-now&amp;title=Why%20You%20Should%20Start%20Contributing%20to%20Open%20Source%20Software%20Right%20Now&amp;summary=The%20open%20source%20movement%20is%20growing%20quickly%20and%20you%20should%20become%20a%20part%20of%20it%20too.&amp;source=LinkedIn" rel="noopener noreferrer" target="_blank" title="Share on LinkedIn"><svg height="24" role="presentation" style="font-size:1.5em" version="1.1" viewBox="0 0 448 512" width="21"> <path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z" key="path-0"></path> </svg></a> <a href="https://twitter.com/intent/tweet?text=Why%20You%20Should%20Start%20Contributing%20to%20Open%20Source%20Software%20Right%20Now&amp;url=https%3A%2F%2Fmarkushatvan.com%2Fblog%2Fwhy-you-should-start-contributing-to-open-source-software-right-now" rel="noopener noreferrer" target="_blank" title="Share on Twitter"><svg height="24" role="presentation" style="font-size:1.5em" version="1.1" viewBox="0 0 512 512" width="24"> <path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z" key="path-0"></path> </svg></a> <a href="https://www.reddit.com/submit?url=https%3A%2F%2Fmarkushatvan.com%2Fblog%2Fwhy-you-should-start-contributing-to-open-source-software-right-now&amp;title=Why%20You%20Should%20Start%20Contributing%20to%20Open%20Source%20Software%20Right%20Now" rel="noopener noreferrer" target="_blank" title="Share on Reddit"><svg height="24" role="presentation" style="font-size:1.5em" version="1.1" viewBox="0 0 512 512" width="24"> <path d="M201.5 305.5c-13.8 0-24.9-11.1-24.9-24.6 0-13.8 11.1-24.9 24.9-24.9 13.6 0 24.6 11.1 24.6 24.9 0 13.6-11.1 24.6-24.6 24.6zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-132.3-41.2c-9.4 0-17.7 3.9-23.8 10-22.4-15.5-52.6-25.5-86.1-26.6l17.4-78.3 55.4 12.5c0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.3 24.9-24.9s-11.1-24.9-24.9-24.9c-9.7 0-18 5.8-22.1 13.8l-61.2-13.6c-3-.8-6.1 1.4-6.9 4.4l-19.1 86.4c-33.2 1.4-63.1 11.3-85.5 26.8-6.1-6.4-14.7-10.2-24.1-10.2-34.9 0-46.3 46.9-14.4 62.8-1.1 5-1.7 10.2-1.7 15.5 0 52.6 59.2 95.2 132 95.2 73.1 0 132.3-42.6 132.3-95.2 0-5.3-.6-10.8-1.9-15.8 31.3-16 19.8-62.5-14.9-62.5zM302.8 331c-18.2 18.2-76.1 17.9-93.6 0-2.2-2.2-6.1-2.2-8.3 0-2.5 2.5-2.5 6.4 0 8.6 22.8 22.8 87.3 22.8 110.2 0 2.5-2.2 2.5-6.1 0-8.6-2.2-2.2-6.1-2.2-8.3 0zm7.7-75c-13.6 0-24.6 11.1-24.6 24.9 0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.1 24.9-24.6 0-13.8-11-24.9-24.9-24.9z" key="path-0"></path> </svg></a> <a href="https://pinterest.com/pin/create/button/?url=https%3A%2F%2Fmarkushatvan.com%2Fblog%2Fwhy-you-should-start-contributing-to-open-source-software-right-now" rel="noopener noreferrer" target="_blank" title="Share on Pinterest"><svg height="24" role="presentation" style="font-size:1.5em" version="1.1" viewBox="0 0 496 512" width="23.25"> <path d="M496 256c0 137-111 248-248 248-25.6 0-50.2-3.9-73.4-11.1 10.1-16.5 25.2-43.5 30.8-65 3-11.6 15.4-59 15.4-59 8.1 15.4 31.7 28.5 56.8 28.5 74.8 0 128.7-68.8 128.7-154.3 0-81.9-66.9-143.2-152.9-143.2-107 0-163.9 71.8-163.9 150.1 0 36.4 19.4 81.7 50.3 96.1 4.7 2.2 7.2 1.2 8.3-3.3.8-3.4 5-20.3 6.9-28.1.6-2.5.3-4.7-1.7-7.1-10.1-12.5-18.3-35.3-18.3-56.6 0-54.7 41.4-107.6 112-107.6 60.9 0 103.6 41.5 103.6 100.9 0 67.1-33.9 113.6-78 113.6-24.3 0-42.6-20.1-36.7-44.8 7-29.5 20.5-61.3 20.5-82.6 0-19-10.2-34.9-31.4-34.9-24.9 0-44.9 25.7-44.9 60.2 0 22 7.4 36.8 7.4 36.8s-24.5 103.8-29 123.2c-5 21.4-3 51.6-.9 71.2C65.4 450.9 0 361.1 0 256 0 119 111 8 248 8s248 111 248 248z" key="path-0"></path> </svg></a></div>   </article></div>]]>
            </description>
            <link>https://markushatvan.com/blog/why-you-should-start-contributing-to-open-source-software-right-now</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547724</guid>
            <pubDate>Sun, 27 Dec 2020 00:40:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[API pagination design]]>
            </title>
            <description>
<![CDATA[
Score 338 | Comments 128 (<a href="https://news.ycombinator.com/item?id=25547716">thread link</a>) | @fagnerbrack
<br/>
December 26, 2020 | https://solovyov.net/blog/2020/api-pagination-design/ | <a href="https://web.archive.org/web/*/https://solovyov.net/blog/2020/api-pagination-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><p>Returning all results for a given query could be a challenge for an API, especially if there are thousands of results. It puts a load on a server, on a client, on a network, and often is unnecessary. Thus people invented pagination.</p>
<p>The usual way to paginate is an offset or a page number. So you make a request like that:</p>
<pre><code>GET /api/products?page=10
{"items": [...100 products]}
</code></pre>
<p>and to continue you make a request like that:</p>
<pre><code>GET /api/products?page=11
{"items": [...another 100 products]}
</code></pre>
<p>In case of a simple offset it’ll look like <code>?offset=1000</code> and <code>?offset=1100</code> — it’s the same old soup, just reheated. It’ll either go straight into SQL query like <code>OFFSET 1000 LIMIT 100</code> or will be multiplied by page size (that <code>LIMIT</code> value). In any case, it’s a suboptimal solution, since every database has to skip that 1000 rows. And to skip them it needs to identify them. It does not matter if it’s PostgreSQL, or ElasticSearch, or MongoDB, it’ll have to order them, count them, and throw them away.</p>
<p>This is a kind of work which no one needs. But it repeats over and over again since it’s <em>easy</em> to implement — you directly map your API onto your query to a database.</p>
<p>What do you do then? We could look at what databases do! They have this concept, called <a href="https://en.wikipedia.org/wiki/Cursor_(databases)">cursor</a> — it’s a pointer to a row. So you can say to a database “return me 100 rows after <strong>that</strong> one”. And it’s much easier for a database to do since there is a good chance that you’ll identify the row by a field with an index. And suddenly you don’t need to fetch and skip those rows, you’ll go directly past them.</p>
<p>An example:</p>
<pre><code>GET /api/products
{"items": [...100 products],
 "cursor": "qWe"}
</code></pre>
<p>API returns an (opaque) string, which you can use then to retrieve the next page:</p>
<pre><code>GET /api/products?cursor=qWe
{"items": [...100 products],
 "cursor": "qWr"}
</code></pre>
<p>Implementation-wise there are many options. Generally, you have some ordering criteria, for example, product id. In this case, you’ll encode your product id with some reversible algorithm (let’s say <a href="https://hashids.org/">hashids</a>). And on receiving a request with the cursor you decode it and generate a query like <code>WHERE id &gt; :cursor LIMIT 100</code>.</p>
<p>Just a little performance comparison, look at how offsets work:</p>
<pre><code>=# explain analyze select id from product offset 10000 limit 100;
                                                           QUERY PLAN                                                            
---------------------------------------------------------------------------------------------------------------------------------
 Limit  (cost=1114.26..1125.40 rows=100 width=4) (actual time=39.431..39.561 rows=100 loops=1)
   -&gt;  Seq Scan on product  (cost=0.00..1274406.22 rows=11437243 width=4) (actual time=0.015..39.123 rows=10100 loops=1)
 Planning Time: 0.117 ms
 Execution Time: 39.589 ms
</code></pre>
<p>And how where works:</p>
<pre><code>=# explain analyze select id from product where id &gt; 10000 limit 100;
                                                          QUERY PLAN                                                          
------------------------------------------------------------------------------------------------------------------------------
 Limit  (cost=0.00..11.40 rows=100 width=4) (actual time=0.016..0.067 rows=100 loops=1)
   -&gt;  Seq Scan on product  (cost=0.00..1302999.32 rows=11429082 width=4) (actual time=0.015..0.052 rows=100 loops=1)
         Filter: (id &gt; 10000)
 Planning Time: 0.164 ms
 Execution Time: 0.094 ms
</code></pre>
<p>That is a difference of several orders of magnitude! Of course, the actual numbers depend on a size of a table, on your filters and on a store implementation. There <a href="https://use-the-index-luke.com/no-offset">a great article</a> with more technical information - there are slides embedded, see slide 42 for performance comparison.</p>
<p>Of course, nobody orders products by an id — you usually order them by some relevancy (and then by id as a <a href="https://stackoverflow.com/a/17330992/46854">tie breaker</a>). In the real world, you’ll have to look at your data to determine what to do. Orders can be ordered by id (as it’s monotonically increasing). Wishlist items can be ordered like that as well — by wishlisting time. In our case products come from ElasticSearch, which naturally supports this cursor stuff.</p>
<p>One deficiency you can see is that it’s impossible to generate a “previous page” link with a stateless API. So in case of a user-facing pagination, if it’s important to have prev/next and “go directly to page 10” buttons there is no way around this offset/limit stuff. But in other cases using cursor-based pagination can greatly improve performance, especially on really big tables with really deep pagination.</p>
</div></div>]]>
            </description>
            <link>https://solovyov.net/blog/2020/api-pagination-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547716</guid>
            <pubDate>Sun, 27 Dec 2020 00:38:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to backup and decrypt Signal for iPhone message history]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25547699">thread link</a>) | @jonnytran
<br/>
December 26, 2020 | https://cight.co/backup-signal-ios-jailbreak/ | <a href="https://web.archive.org/web/*/https://cight.co/backup-signal-ios-jailbreak/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>I started using Signal 5 years ago as I became increasingly conscious of my data footprint. Around the same time, I closed my Facebook and Instagram accounts, and later, my Google Account.</p><h2 id="the-problem-with-signal">The problem with Signal</h2><p>Signal makes it very difficult, and in most cases, impossible, for one to back up, export, or migrate message data. The Signal team insists these restrictions are meant to protect users’ privacy. However, backup and migration policies differ for each official Signal client and sometimes contradict each other.</p><p>For example, while iOS offers no official backups process, Android backups are built into the app. At the same time, iOS users can migrate their data to a new device (as long as their phone number hasn’t changed), but this is impossible on Android. Meanwhile, decrypting messages from the desktop client is trivial, but linking one’s phone and desktop client only syncs messages forward in time.</p><h2 id="why-export-signal-s-message-history">Why export Signal's message history</h2><p>Because it’s my fucking data.</p><p>The road to exporting my data was long, frustrating and filled with dead ends – it took over a year to get here. What's paradoxical is that someone else's phone turned out to be the key to my data. </p><p>In recent years, I moved most of my conversations to Signal, including those with family and close friends. Shortly after we started dating, I asked my partner to switch to Signal, and we’ve used it exclusively ever since. At some point, I thought it would be nice to export our conversation history – a sort of time capsule of our relationship. “Easy,” I thought. I was wrong.</p><p>Since we started dating, I had switched from a OnePlus 2 to an iPhone XS Max. And since migrating from Android to iOS isn’t possible, part of our conversation history was locked on my old phone. Jailbreaking the iPhone was out of the question since my version of iOS had not been jailbreaken. The Signal Desktop client could have offered an easy avenue to decrypt our chat history, but there was a period of several months during which I had not linked my iPhone to the Signal desktop client.</p><p>I opened a <a href="https://community.signalusers.org/t/ios-backups-through-the-desktop-client/8123">thread about this in the Signal Community Forum</a> in June of 2019. It quickly became apparent that backing up my Signal data would be an uphill battle. </p><p>Luckily, my partner had an iPhone 7, which she recently replaced with a company phone. Her old iPhone contained our entire message history in one place and was easy to jailbreak. Jackpot.</p><p>One important lesson I learned during this process:<strong> to ensure access to your conversation history, install the Desktop client and link it to your mobile device as soon as you start using Signal. </strong>The Signal database and encryption key are both accessible on your computer, allowing for easy decryption. Linking the desktop client later will only sync messages forward in time from the moment the devices are linked.</p><h2 id="tips-to-increase-your-chances-of-exporting-your-signal-database">Tips to increase your chances of exporting your Signal database</h2><p>If you haven’t linked the desktop client and extracting the iOS database is your only option, this guide is for you. If you've decided to embark upon this journey, here's some advice. </p><h3 id="stop-updating-ios">Stop updating iOS</h3><p>Your best chance of jailbreaking iOS is on older firmware versions. Turn off automatic updates and decline prompts to update iOS.</p><h3 id="backup-shsh-blobs-with-every-new-ios-update">Backup SHSH blobs with every new iOS update</h3><p><a href="https://en.wikipedia.org/wiki/SHSH_blob">SHSH blobs</a> are the digital signatures that Apple generates and uses to personalize iOS firmware files for each iOS device. Apple only signs firmware updates for a limited time after release. Having these signatures handy allows one to install versions of iOS after Apple stops signing them – like when a jailbreak becomes available for that version. In some cases, you may be able to downgrade iOS to a previous version.</p><p>Backup SHSH blobs every time Apple releases a new version of iOS (e.g., 14.0, 14.1, 14.1.1). I personally use the <a href="https://github.com/airsquared/blobsaver">blobsaver</a> app, but <a href="https://tsssaver.1conan.com/v2/">TSS Saver</a> is a popular alternative.</p><h3 id="learn-about-jailbreaking-and-stay-up-to-date-on-developments">Learn about jailbreaking and stay up to date on developments</h3><p>Developers and hackers are constantly working to break the security of iOS, and new methods to jailbreak iPhones are frequently made public. Stay informed on jailbreak releases by following the <a href="https://www.reddit.com/r/jailbreak/">/r/jailbreak subreddit</a>.</p><p>This <a href="https://docs.google.com/spreadsheets/d/11DABHIIqwYQKj1L83AK9ywk_hYMjEkcaxpIg6phbTf0/edit#gid=1014970938">exhaustive list of jailbreak compatibility</a> by device and iOS version is also a great resource.</p><p>It's also useful to understand the difference between <a href="https://www.theiphonewiki.com/wiki/Untethered_jailbreak">untethered</a>, <a href="https://www.theiphonewiki.com/wiki/Semi-untethered_jailbreak">semi-untethered</a>, <a href="https://www.theiphonewiki.com/wiki/Semi-tethered_jailbreak">semi-tethered</a>, and <a href="https://www.theiphonewiki.com/wiki/Tethered_jailbreak">tethered</a> jailbreaks.</p><h3 id="recognize-that-this-may-not-work">Recognize that this may not work</h3><p>Depending on your iPhone, you might never be able to jailbreak it or extract Signals decryption key from the iOS Keychain. Apple is making it increasingly difficult to jailbreak iOS devices – improvements to hardware and software are leaving fewer cracks for hackers to exploit.</p><p>Ok, let's get our hands dirty. </p><h2 id="how-to-maybe-backup-signal-for-iphone">How to (maybe) backup Signal for iPhone </h2><p>This guide explains how I was able to backup and extract data from Signal's encrypted SQLite database on an iPhone 7 with iOS 13.6.1. </p><h3 id="prerequisites">Prerequisites </h3><ul><li>Physical access to the iPhone with Signal still installed</li><li>An original iPhone cable</li><li>A Mac or Linux computer</li><li>Patience and a bit of luck</li></ul><p>Shell environments will be differentiated as such. </p><pre><code>// Host machine
$ &lt;command&gt;

// iPhone 
root# &lt;command&gt;</code></pre><h3 id="step-1-jailbreak-ios">Step 1: Jailbreak iOS</h3><p>For iOS 13.6.1 on an iPhone 7, I used <strong>checkra1n</strong> which offers a straight forward semi-tethered jailbreak. Depending on the iPhone device and version of iOS, a jailbreak may or may not be available. </p><p>See this <a href="https://docs.google.com/spreadsheets/d/11DABHIIqwYQKj1L83AK9ywk_hYMjEkcaxpIg6phbTf0/edit#gid=1014970938">updated list of iOS jailbreaks</a> for device compatibility and instructions. </p><h3 id="step-2-ssh-into-the-iphone">Step 2: SSH into the iPhone </h3><p>Cydia usually comes with OpenSSH installed and enabled, allowing shell access over IP or USB. If SSH access isn't activated, launch Cydia and install OpenSSH. </p><p><strong>As always, the root password on iOS is <code>alpine</code>.</strong></p><p>If the iPhone and the host machine are on the same network, SSH into the phone using its IP address. It may be found in the phone's WiFi settings. </p><pre><code>$ ssh root@[iphone ip] -p 22</code></pre><p>If SSH over the air isn't possible, USB may be an alternative. However, this involves enabling a proxy service on the host machine.</p><p>First, install <em><em>libimobiledevice</em></em> on the host machine. </p><pre><code>$ brew install libimobiledevice</code></pre><p>Then, edit <em><em>com.usbmux.iproxy.plist</em></em> and append the following XML to the file. </p><pre><code>$ nano ~/Library/LaunchAgents/com.usbmux.iproxy.plist</code></pre><pre><code>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd"&gt;
&lt;plist version="1.0"&gt;
&lt;dict&gt;
&lt;key&gt;Label&lt;/key&gt;
&lt;string&gt;com.usbmux.iproxy&lt;/string&gt;
&lt;key&gt;ProgramArguments&lt;/key&gt;
&lt;array&gt;
&lt;string&gt;/usr/local/bin/iproxy&lt;/string&gt;
&lt;string&gt;2222&lt;/string&gt;
&lt;string&gt;22&lt;/string&gt;
&lt;/array&gt;
&lt;key&gt;RunAtLoad&lt;/key&gt;
&lt;true/&gt;
&lt;key&gt;KeepAlive&lt;/key&gt;
&lt;true/&gt;
&lt;/dict&gt;</code></pre><p>And finally, launch the proxy on the host machine. </p><pre><code>$ launchctl load ~/Library/LaunchAgents/com.usbmux.iproxy.plist</code></pre><p>It should now be possible to SSH into the iPhone over USB on port <code>2222</code>.</p><pre><code>$ ssh root@localhost -p 2222</code></pre><h3 id="step-3-install-required-packages">Step 3: Install required packages </h3><p>Once logged into to the iPhone's shell, install the following packages as they will come in handy. </p><pre><code>root# apt install zip unzip nano wget</code></pre><h3 id="step-4-backup-the-signal-data-directory">Step 4: Backup the Signal data directory</h3><p><strong>Locate Signal's data directory</strong></p><p>Much like macOS, iOS stores application data in a <em>Library</em>-like directory. In iOS&nbsp;13, its located here <code>/private/var/mobile/Containers/Shared/AppGroup/</code>. </p><p>Signal's data directory contains the encrypted SQLite database file in <code>./grdb/signal.sqilte</code> and attachments, such as images and videos in <code>./Attachments</code>.</p><p>The data directory may be found by searching the filesystem for Signal's encrypted database file, <code>signal.sqlite</code>.</p><pre><code>root# find / -type f -iname "signal.sqlite"</code></pre><p>That should return something which looks like this:<br><code>/private/var/mobile/Containers/Shared/AppGroup/01484069-3446-4CC0-8BE7-7464E7D08FDF/grdb/signal.sqlite</code> </p><p>The Signal directory is: <code>/private/var/mobile/Containers/Shared/AppGroup/01484069-3446-4CC0-8BE7-7464E7D08FDF/</code></p><p><strong>Zip the Signal directory</strong></p><p>It is recommended to zip the entire directory, not only the database file, as it also contains images and other message attachments. This archive can reach several gigabytes.</p><pre><code>root# cd /private/var/mobile/Containers/Shared/AppGroup/
root# zip -r signal-backup.zip &lt;Signal directory&gt;

# ex: zip -r signal-backup.zip /private/var/mobile/Containers/Shared/AppGroup/01484069-3446-4CC0-8BE7-7464E7D08FDF/</code></pre><p><strong>Retrieve the backup on the host machine</strong></p><p>In a new terminal session on the host machine, use <code>scp</code> to copy the backup. </p><pre><code>$ scp -P 22 root@localhost:/private/var/mobile/Containers/Shared/AppGroup/signal-backup.zip ~/</code></pre><p>Once complete, verify that the backup has fully transferred by unpacking it.</p><p>This is the most complex part of this operation and it helps to have a basic understanding of core iOS development concepts.</p><p><strong>Understanding iOS Entitlements </strong></p><p>From the <a href="https://developer.apple.com/documentation/bundleresources/entitlements">Apple Developer Documentation</a>: </p><blockquote>An entitlement is a right or privilege that grants an executable particular capabilities. For example, an app needs the HomeKit Entitlement — along with explicit user consent — to access a user’s home automation network. An app stores its entitlements as key-value pairs embedded in the code signature of its binary executable.</blockquote><p><strong>Enter Keychain Dumper</strong></p><p>We will use <a href="https://github.com/ptoomey3/Keychain-Dumper"><strong>Keychain-Dumper</strong></a> to attempt extracting the Signal encryption key. It requires entitlements to access Keychain data for any particular app. </p><p>Reading through Keychain-Dumper's GitHub issues, I learned that entitlements changed in iOS 13.5 – prior to this version, an application <a href="https://github.com/ptoomey3/Keychain-Dumper/issues/52#issuecomment-638174691">could be given wildcard entitlements</a>. Changes in 13.5 made it such that apps need specific entitlements. Thankfully, it's possible to update an executable's entitlements, even as a binary.</p><p>The <code>keychain_dumper</code> binary included in its <a href="https://github.com/ptoomey3/Keychain-Dumper">GitHub repo</a> has wildcard entitlements. We'll need to update them in order to give it permission to decrypt the Signal key.</p><p><strong>Install Keychain Dumper on the iPhone</strong></p><p>Back on the iPhone, download and extract the <a href="https://github.com/ptoomey3/Keychain-Dumper/releases/tag/1.0.0">keychain_dumper binary</a>, and move it to <code>/usr/bin</code>.</p><pre><code>root# wget https://github.com/ptoomey3/Keychain-Dumper/releases/download/1.0.0/keychain_dumper-1.0.0.zip
root# unzip keychain_dumper-1.0.0.zip
root# mv keychain_dumper /usr/bin</code></pre><p><strong>Update <em>keychain_dumper</em>'s …</strong></p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cight.co/backup-signal-ios-jailbreak/">https://cight.co/backup-signal-ios-jailbreak/</a></em></p>]]>
            </description>
            <link>https://cight.co/backup-signal-ios-jailbreak/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547699</guid>
            <pubDate>Sun, 27 Dec 2020 00:36:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data Is Lying to You and You're Listening]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25547602">thread link</a>) | @haltingproblem
<br/>
December 26, 2020 | https://www.younglingfeynman.com/essays/misleadingdata | <a href="https://web.archive.org/web/*/https://www.younglingfeynman.com/essays/misleadingdata">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-d54917c3f4c66758a8bd"><div><p>I really believe you have to be careful with data.</p><p>There’s this assumption that if you split test, the data tells you what’s better.</p><p>But that’s clearly not always the case.</p><p>Why?</p><p>This is actually a bigger idea than it seems.</p><p>Many companies that have a data-first approach don’t realize they’re reasoning off of an assumption and treat it like an axiom. [1]</p><p>But optimize long enough and everything becomes the equivalent of BuzzFeed or porn.</p><p>Clickbait, sex, drama, and superficialness. Being everything to everyone and nothing to no one.</p><p>Groupon’s quality went down the drain because Mason’s employees told him sending more emails per day increased revenue.</p><p>The deals became ever lower in quality and users got annoyed.</p><p>There was a time where people<strong> could not wait</strong> to get an email from Groupon. They had killer deals. They had hilarious copywriters. Even if you didn’t buy, getting an email was a treat. But now that it has been properly sterilized to please spineless, risk-averse shareholders, and optimized for maximum quarterly revenue, can you think of a single person that feels that way anymore? Not one person? Groupon clearly has lost its soul, its essence. Mason said in an interview (can’t recall the source) that he wondered if Groupon was meant to be an extraordinary company, just for a smaller market. It certainly would have made it easier to build the company according to his vision rather than something that needed to please the shareholders that needed an IPO to get a return.</p><p>In the early days you had the GOATS like Reid Hoffman (founder LinkedIn), Max Levchin (Paypal and Affirm), and the likes answering questions. Now it’s some 14yr old telling you about the opportunity of a lifetime: screencasting stories from Reddit, having the speech to text tool read them, turn it into a video and put it on YouTube. And then…? Millions I guess?</p><p>It went from THE place to get high-quality courses from knowledgeable instructors to the flea-market of cheap knock-offs and fake guru business opportunity courses. While you can find quality courses there, the overall quality has badly degraded. The best instructors aren’t incentivized to create a course because your $1000 course containing 3 decades of experience will sell for $9.99 of which you’ll get $2.50. So if you actually have something to offer, you’ll go somewhere else, leaving mainly the type of people that game the system in order to make a quick buck.</p><p>People used to LOVE Facebook with a vengeance. Now I have 80 notifications, 40 of which are new friend suggestions of people I’ve never met, 20 are strangers that sent out a blast to get likes for their new page, 17 are events, and 3 are birthdays. [2]</p><p>Oh yeah… and not 1 is actually relevant to me.&nbsp;You can fool a user only so many times before you’ve essentially trained them to ignore you.</p><p><em>They started implementing the same dark patterns with their DM. You get notifications for being friends for a certain time and when you accept a new friend.</em></p><p>In its search for endless optimization, the platform has become bloated and just plain annoying. I can’t think of a single person in my cohort (and younger cohorts) that use FB as much or more as 10 years ago.&nbsp;</p><p>The current demographic appears to be the same type of people that use Bing over Google, or Explorer over Chrome. Late adopters that are sticky to defaults.</p><p>So be careful when optimizing. Remember the quantification bias! </p><p><em>Discussed in </em><a href="https://www.younglingfeynman.com/essays/paradigm"><em>Paradigm Shift: Drastically Increase The Odds of Success</em></a></p><p>Just because something is easy to measure doesn’t mean it’s insightful. Just because something can’t be measured easily doesn’t mean it isn’t.</p><p>Remember that business is part art part science: <a href="https://www.younglingfeynman.com/essays/artofbusiness" target="_blank">The Art Of Business, Where Science And Business Depart</a>.</p><p>[1]  I <a href="https://www.younglingfeynman.com/essays/comedy">made the point before</a> when it comes to certain areas that are sufficiently complex (e.g. statistics, data science, economics), you either want no one or a person with extraordinarily deep expertise. </p><p>Interesting piece on the fraud that’s going on in Data Science: <a href="https://logicmag.io/intelligence/interview-with-an-anonymous-data-scientist/"><em>The Smart, the Stupid, and the Catastrophically Scary: An Interview with an Anonymous Data Scientist</em></a></p><p>What you don’t want is someone that knows enough to bullshit you but not enough to get it right. An indicator that you might have the right person is the phrase: ‘‘I’m not sure’’ or ‘‘ it depends on…’’. In these fields, the vast majority of so-called experts add no value at best or negative value at worst.</p><p>[2] This is what I admired so much about Systrom’s and Krieger’s Instagram. Their almost zen-like essentialism. No bloating, no fluff, trying very hard to take away things as they did about adding things. How many new features did they launch in a month before their Facebook acquisition? How many new features does IG launch now per month? </p><p>I’m not saying adding new features is bad. I’m also not saying that a company shouldn’t scale. The point I’m making is that entropy is real. It’s much easier for your product to become worse, than it is to become better. So if that’s not a core focus, it probably won’t happen by accident.</p><p>But scale and improvements in user love (which follow from a better service/product) are not mutually exclusive. Apple provides a data point. Especially during the Jobs reign. </p><p><em>More on this in the essay series: </em><a href="https://www.younglingfeynman.com/essays/deeplove"><em>Do You Have Customers Who Deeply Love You?</em></a><em> </em></p></div></div></div>]]>
            </description>
            <link>https://www.younglingfeynman.com/essays/misleadingdata</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547602</guid>
            <pubDate>Sun, 27 Dec 2020 00:20:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The cost of a Ruby threads leakage]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25547555">thread link</a>) | @mooreds
<br/>
December 26, 2020 | https://mensfeld.pl/2020/12/the-hidden-cost-of-a-ruby-threads-leakage/ | <a href="https://web.archive.org/web/*/https://mensfeld.pl/2020/12/the-hidden-cost-of-a-ruby-threads-leakage/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://mensfeld.pl/2020/12/the-hidden-cost-of-a-ruby-threads-leakage/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547555</guid>
            <pubDate>Sun, 27 Dec 2020 00:10:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kit FUI – User interfaces found in films]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 25 (<a href="https://news.ycombinator.com/item?id=25547352">thread link</a>) | @ChrisArchitect
<br/>
December 26, 2020 | https://www.saji8k.com/kit-fui/ | <a href="https://web.archive.org/web/*/https://www.saji8k.com/kit-fui/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<div>
				
				<p>User interfaces from film, television, video games and the designers that created them.</p>
				<p>Keep track of updates to Kit FUI on my <a href="https://www.saji8k.com/blog/">blog</a> or by following me on <a href="https://twitter.com/saji8k">Twitter</a> or <a href="https://www.facebook.com/saji8k">Facebook</a>.</p>
				<p>If you have suggestions for the site or would like to submit your work, send me a <a href="https://twitter.com/saji8k">tweet</a>.</p>
			</div>
		</div><div>
			<div>
				<h3>What is FUI?</h3>
				<p>Fantasy User Interfaces, Fictional User Interfaces, Fake User Interfaces, Futuristic User Interfaces, Film User Interfaces, Future User Interfaces. Regardless of what the F stands for, they all represent the same thing, the user interfaces (UIs) and heads up displays (HUDs) found in many popular movies and television shows.</p>
				<p>Most FUIs are not actual computer programs but simply animations being played back at the correct time or added in post production. These graphics and animations are designed in applications like Adobe Illustrator, Adobe After Effects and Maxon Cinema 4D.</p>
			</div>
		</div></div>]]>
            </description>
            <link>https://www.saji8k.com/kit-fui/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547352</guid>
            <pubDate>Sat, 26 Dec 2020 23:34:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Run More Stuff in Docker]]>
            </title>
            <description>
<![CDATA[
Score 190 | Comments 270 (<a href="https://news.ycombinator.com/item?id=25547205">thread link</a>) | @psxuaw
<br/>
December 26, 2020 | https://jonathan.bergknoff.com/journal/run-more-stuff-in-docker/ | <a href="https://web.archive.org/web/*/https://jonathan.bergknoff.com/journal/run-more-stuff-in-docker/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
	
	<h6>
		<span>2020-03-10</span>

		
		<span>
			
			<a href="https://jonathan.bergknoff.com/tags/tech/">tech</a>
			
			<a href="https://jonathan.bergknoff.com/tags/programming/">programming</a>
			
		</span>
		
	</h6>
	<hr>
	<p>In 2020, <strong>Docker is the best medium for distributing and running most developer-facing software</strong>. It’s widely accepted that Docker is great for building and deploying the artifacts for your enterprise web app, but this is less well known when it comes to things like developer tools. However, running tools in containers has many benefits over installing and running them in the conventional way, and we should all start doing it more.</p>
<h2 id="why">Why?</h2>
<p>I install very few things on either my personal or work computer. I don’t have <code>terraform</code>, <code>aws</code>, <code>node</code>, or <code>pip</code> installed, but I use them all the time. I have a Docker image for each, and I run them in containers with minimal privileges. I’m definitely <a href="https://github.com/jessfraz/dockerfiles">not the only one</a>, but it’s not as popular as it should be. None of these tools actually need full access to my computer to do their work, but that is normally how they’re run.</p>
<p>Here are some benefits of running these tools in Docker.</p>
<h4 id="cross-platform">Cross-platform</h4>
<p>At this point in time, Docker is ubiquitous and you get cross-platform support for free, thanks to Docker Inc’s investments in that area (Docker for Mac &amp; Windows). This is useful both for people developing/distributing tools, and for people working on a team that needs to share tooling. You have one Docker image and it will run pretty much everywhere. OS package managers can be great, but they’re very much not cross-platform. Things like <code>pip install</code> will sometimes work cross-platform, but have other serious drawbacks.</p>
<p>While every platform has its own sandboxing mechanisms, running with Docker lets you specify runtime context and enforce a sandbox in a cross-platform way, which is useful when you expect anybody else to run the same command as you.</p>
<h4 id="sandboxed">Sandboxed</h4>
<p>When you <code>docker run</code>, you have to be explicit about privileges. A container is mostly sandboxed and unprivileged by default. It doesn’t have access to ambient environment variables. It doesn’t have access to the host system’s disk. A tool like <code>jq</code> just needs to read stdin and print to stdout. It doesn’t need access to my shell’s environment variables (or, if it does, I explicitly pass those through to the container). <code>yarn</code> should be fine operating on just the working directory, and maybe a cache directory. I don’t want it to have access to my ~/.aws directory (for <a href="https://securityboulevard.com/2020/01/malicious-npm-package-exfiltrating-data-from-unix-systems/">obvious reasons</a>).</p>
<p>Some tools do need access to things. I want my <code>aws</code> CLI to be able to read ~/.aws, so I grant that explicitly. This makes running the tool more verbose but less magical.</p>
<h4 id="simple-uniform-interface">Simple, uniform interface</h4>
<p>Running a program in a container is a lot like running it normally, but the user doesn’t need to jump through hoops to configure the system, build and install. The developer of the image jumps through those hoops and produces a runnable artifact with a simple interface. That interface is the same whether the tool was written in Python or Rust or C or anything else.</p>
<p>Downloading a pre-compiled binary is almost like this, except with worse odds. Maybe there’s a build for your architecture. If it was statically linked, you’re golden. Otherwise, use <code>ldd</code> to reverse engineer the fact that you need to install <code>libjpeg</code>.</p>
<p>A Docker image “just works”. It comes bundled with what it needs to run.</p>
<p>If you think about it, it’s pretty strange to execute <a href="https://github.com/aws/aws-cli/tree/0b3d9a4260fdda5c6a8b736439e0776bc2252f41#installation"><code>pip install awscli</code></a>. It’s immaterial to an end user that the tool is written in Python, and requiring him or her to set up and use Python tooling doesn’t make sense. I don’t mean to pick on <code>pip</code> or <code>awscli</code> in particular, but this is a poor mechanism for distributing non-library software. It leaves <a href="https://github.com/aws/aws-cli/issues?q=is%3Aissue+pip">far too much to chance</a>. It’s a clumsy and leaky interface for tool distribution. So is <code>npm install</code>. So is telling somebody to install your tool by installing golang, and then running <code>go build</code>. No, thanks. If I’m hacking on the project, then by all means. But don’t foist that on end users.</p>
<h4 id="facilitates-version-pinning">Facilitates version pinning</h4>
<p>When collaborating, it’s important that people run the same versions of software to get consistent results. Version pinning is essential to that. Pinning dependency manifests is good, but it’s not enough: it only covers the one situation of installing things with a language package manager. It may not cover using the same linter version, or the same version of <code>node</code>, <code>aws</code>, <code>ansible</code>, <code>terraform</code>, or any libraries installed at the OS level. Invoking <code>docker run node:13.10.1</code>, instead of whatever the user happens to have installed as <code>node</code>, solves this problem in general. Having the ability to specify the versions at the point of use, rather than out-of-band as part of some other installation process, is also convenient and tidy.</p>
<p>It’s easy to run different versions of a tool side by side with Docker. Docker solves this more generally than things like virtualenv for Python, rvm for Ruby, etc. You specify what version of the tool to use when you’re invoking it, and it pins a whole lot of context more than just the tool’s version, which is always preferable for reproducibility.</p>
<p>In one recent situation at work, we had a test case start failing when we upgraded our runtime from Python 3.6.5 to Python 3.6.8. Having the ability to easily run the tests with any version of Python made it easy to bisect and identify a change in 3.6.7 as the cause. This could have been debugged without Docker, but it was particularly natural and easy with Docker.</p>
<h4 id="reproducible">Reproducible</h4>
<p>Invoking a tool with <code>docker run</code> should specify everything needed to reproducibly run it somewhere else. It’s running some specific version of the tool? Okay. It needs my AWS credentials? Okay. It needs some specific combination of environment variables set? Okay.</p>
<p>I cringe when I see a Makefile or build instructions saying to run <code>yarn</code> or <code>terraform</code> or <code>go</code>. What version? What’s being assumed about my environment? Maybe this worked on your <a href="https://martinfowler.com/bliki/SnowflakeServer.html">unique snowflake of a machine</a> 18 months ago, but good luck with it now. (My laptop is a unique snowflake too. Everyone’s is, until we all figure out how to use NixOS.)</p>
<p>Running tools in Docker, there are few expectations of the runtime environment beyond having Docker installed. All the other requirements should be made explicit in the <code>docker run</code> command. The command that you’re running locally will work the same on your colleague’s machine, and in any CI with minimal configuration (or none). This is absolutely critical, especially when working on a team. This is a far more robust approach than expecting (requiring) anybody’s system, or a CI slave, to be set up “just so”.</p>
<h4 id="minimizes-global-state">Minimizes global state</h4>
<p>I have very few things installed on my host system beyond the base OS. There’s less to remember when setting up a new machine, fewer things to go wrong during upgrades, and fewer opportunities for conflicts over shared libraries.</p>
<h2 id="examples">Examples</h2>
<h4 id="one-offs">One-offs</h4>
<p>I have bash aliases for a bunch of tools that I run all the time. These are just for my own convenience. For anything shared with other people, I’d use a project’s Makefile (see below).</p>
<ul>
<li>
<p><strong>Some basics</strong></p>
<pre><code>alias aws='docker run --rm -v ~/.aws:/.aws -v "$(pwd)":"$(pwd)" -w "$(pwd)" -u 1000:1000 -e AWS_PROFILE mikesir87/aws-cli:1.18.11 aws'
alias jq='docker run -i --rm jess/jq jq'
alias terraform='docker run -it --rm -v ~/.aws:/.aws -v "$(pwd)":"$(pwd)" -w "$(pwd)" -u 1000:1000 hashicorp/terraform:0.12.23'
</code></pre><p>With these aliases, I can <code>AWS_PROFILE=... aws sts get-caller-identity | jq -r .Arn</code> as if they were “really” installed.</p>
</li>
<li>
<p><strong>zoom</strong></p>
<p>Here’s zoom (video conferencing):</p>
<pre><code>alias zoom='xhost +local:docker \
    &amp;&amp; docker run -it --rm -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY \
    --device /dev/video0 --device /dev/snd:/dev/snd --device /dev/dri -v /dev/shm:/dev/shm \
    -v ~/.config/zoom/.zoom:/root/.zoom -v ~/.config/zoom/.config/zoomus.conf:/root/.config/zoomus.conf \
    jess/zoom-us'
</code></pre><p>Notice that <a href="https://medium.com/bugbountywriteup/zoom-zero-day-4-million-webcams-maybe-an-rce-just-get-them-to-visit-your-website-ac75c83f4ef5">port 19421</a> remains stubbornly closed unless we explicitly let the container claim it on the host.</p>
</li>
<li>
<p><strong>Snes9x</strong></p>
<p>I do this with other stuff, too. Here’s Snes9x (can you imagine <a href="http://www.snes9x.com/phpbb3/viewtopic.php?t=23603">installing it</a>?):</p>
<pre><code>alias snes9x='docker run -it --rm -u 1000:1000 -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY \
    -v /run/dbus:/run/dbus -v /dev/shm:/dev/shm \
    --device /dev/snd --device /dev/dri --device /dev/input/js0 \
    -e PULSE_SERVER=unix:$XDG_RUNTIME_DIR/pulse/native -v $XDG_RUNTIME_DIR/pulse/native:$XDG_RUNTIME_DIR/pulse/native \
    --group-add $(getent group audio | cut -d: -f3) \
    -v ~/.config/snes9x:/.snes9x/ -v ~/Games/SNES:/SNES -v ~/.local/share:/.local/share \
    danniel/snes9x'
</code></pre></li>
</ul>
<h4 id="projects">Projects</h4>
<p>For things that are project-specific, or in a team setting, all useful commands should be codified in something like a Makefile. This wraps the complexity and verbosity of the <code>docker run</code> incantations, makes it possible to share them easily, and makes them passably ergonomic.</p>
<ul>
<li>
<p><strong>hugo</strong></p>
<p>When I’m writing an article for this site, I run <code>make hugo-watch</code> and load http://localhost:1313 in a web browser:</p>
<pre><code>hugo = docker run --rm -u $$(id -u):$$(id -g) -v "$$(pwd)":/src -v "$$(pwd)"/output:/target $(2) klakegg/hugo:0.54.0-ext-alpine $(1)

hugo-watch:
    mkdir -p output
    $(call hugo, server, -it -p 1313:1313)
</code></pre></li>
<li>
<p><strong>prettier</strong></p>
<p>To format a JavaScript project, we might have the make targets</p>
<pre><code>prettier = docker run -i --rm -v "$$(pwd)":"$$(pwd)" -w "$$(pwd)" elnebuloso/prettier:1.19.1 $(1) "src/**/*.js"

format:
    $(call prettier)

format-check:
    $(call prettier, --check)
</code></pre><p>We would run <code>make format</code> to format the code and <code>make format-check</code> to check the style. It runs on my Linux box, it runs on my colleague’s Mac, and it runs in any Docker-equipped CI. None of those machines need to have <code>node</code>, <code>npm</code>, or <code>prettier</code> installed. We completely trivialize the issues of versioning and of synchronizing our environments: the version is specified once, here in the Makefile, and it’s obeyed everywhere.</p>
<p>In a language like Python, where libraries are forced to fight to the death for control of transitive dependency versions, lifting a tool like <code>black</code> or <code>flake8</code> out of the project’s requirements.txt, and into a self-contained Docker image, can be a big …</p></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jonathan.bergknoff.com/journal/run-more-stuff-in-docker/">https://jonathan.bergknoff.com/journal/run-more-stuff-in-docker/</a></em></p>]]>
            </description>
            <link>https://jonathan.bergknoff.com/journal/run-more-stuff-in-docker/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547205</guid>
            <pubDate>Sat, 26 Dec 2020 23:10:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lost nuclear device atop of Nanda Devi]]>
            </title>
            <description>
<![CDATA[
Score 204 | Comments 117 (<a href="https://news.ycombinator.com/item?id=25547123">thread link</a>) | @hudvin
<br/>
December 26, 2020 | https://www.livehistoryindia.com/cover-story/2020/09/18/nanda-devi-nuclear-device | <a href="https://web.archive.org/web/*/https://www.livehistoryindia.com/cover-story/2020/09/18/nanda-devi-nuclear-device">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <section>
                        <div id="container">
                          
  <div>
    


<div id="story-f889b712-c891-4d7d-b740-a08c112f512d" data-public-preview="">
  <article data-story-url="" data-story-content-id="f889b712-c891-4d7d-b740-a08c112f512d" data-story-version-id="f2394ab5-e6e4-492d-a5d0-8de23eb757bc" data-story-headline="Nanda Deviâ€™s Nuclear Secret and a Botched CIA Operation" data-loader="story">
    
          <div>
    <figure>
        <img src="https://images.assettype.com/indynetwork%2F2020-09%2Fde00724b-9ea2-4f38-82dc-ca78b3e6dee0%2FImage_9.jpg?w=1500">
    </figure>
</div>
<div>
  <div>
    
    <div itemprop="articleBody" data-story-content-id="f889b712-c891-4d7d-b740-a08c112f512d" data-story-version-id="f2394ab5-e6e4-492d-a5d0-8de23eb757bc">
      
                        
              <div data-card-content-id="efdfb573-ba3e-4852-b9ee-0486b7498411" data-card-version-id="49dda451-df77-4ea6-9f9b-3d28a0f6cf13">
        
      <div id="inf-card-b26a2f55-462c-4ea2-bbd2-fa63429051da" data-story-element-id="b26a2f55-462c-4ea2-bbd2-fa63429051da" data-story-element-type="text">
          <div>
    <p>The past few months have seen a rise in volatility along the Indo-Tibetan border, with the forces of both India and China coming to blows. While these events are extraordinary in present times, the border has witnessed far more heated exchanges, most notably during the 1962 <a href="https://www.livehistoryindia.com/in-the-news/2020/06/21/across-the-karakorams">Indo-China</a> War.</p><p>The unforgiving terrain that marks the frontier creates an additional dimension to the already complex nature of these clashes, whether in regard to more conventional manoeuvres, or other irregular military activity which is far more frequent. This is the story of the latter kind of action, that of daring espionage against Communist China, played for the highest stakes with the greatest risks.</p>
  </div>
</div>



      <div id="inf-card-33d483b8-2c77-4958-ae3b-52863623292b" data-story-element-id="33d483b8-2c77-4958-ae3b-52863623292b" data-story-element-type="text">
          <div>
    <p>Cold, harsh, inviolate. Straddling between the <a href="https://www.livehistoryindia.com/snapshort-histories/2017/06/21/kumaon-echoes-of-the-past">Kumaon</a> and Garhwal districts of Uttarakhand, deep in the Himalayas, stands Nanda Devi. The second-highest mountain in India, towering at an astonishing 25,646 feet, it is named after the patron goddess of Uttarakhandâ€” the mountain being her temporal manifestation.</p><p>Its unique topographical environment makes it one of the most inaccessible places on Earth. Surrounded on three sides by massive mountain rampartsâ€”its natural fortifications measuring at no point below 17,000 feetâ€” only the narrow and dangerously steep Rishi Ganga river gorge allows access to it. The mountain in itself is a citadel of rock and ice, with steep, angled faces and avalanche-prone ridges guarding its summit. Its immense proportions make it far tougher to climb than Everest. It is at once a supremely magnificent and terrifyingly intimidating mountain.</p>
  </div>
</div>



      <div id="inf-card-67773953-dcf2-46a7-97f1-a20310e389b8" data-story-element-id="67773953-dcf2-46a7-97f1-a20310e389b8" data-story-element-type="image">
  <div>
  <figure>
    <img alt="Map of the Nanda Devi Sanctuary, the thick hachures marking the semi-circular natural fortifications in the form of mountains that surround most of the Nanda Devi" src="https://images.assettype.com/indynetwork%2F2020-09%2F65d1a1da-2c67-4059-aeb0-c5437f7f191d%2FImage_3.jpg?w=1170">
  </figure>
              
  
</div></div>



      <div id="inf-card-ec4beaa1-a291-4fc9-9b8c-2d33f3d21e38" data-story-element-id="ec4beaa1-a291-4fc9-9b8c-2d33f3d21e38" data-story-element-type="text">
          <div>
    <p>For much of the 19th and early 20th century, before it was finally summited in 1936, it was considered to be the third pole â€“ a point of virtual inaccessibility. However, this awe-inspiring creation of nature shelters a device, abhorrent to nature, manufactured by man. Somewhere high on the harrowing slopes of Nanda Devi, buried deep in snow, lies a lost nuclear listening device slowly depleting its plutonium cores. Containing 5kg of plutonium â€“ 1 kg less than the nuclear bomb dropped on Nagasaki â€“ with a predicted lifespan of 900 years, this nuclear trespasser has been forfeited to the mountain forever.</p><p>This is the story behind one of the most audacious acts of espionage in the 20th century.</p>
  </div>
</div>



  </div>

              <div data-card-content-id="5350a04d-7e5b-48a5-9ccc-0c0b06771394" data-card-version-id="b82a93e5-a227-4175-b91c-b1fe616b5c7c">
        
      <div id="inf-card-d8876be2-71a7-431c-833b-2d0c39d14b6e" data-story-element-id="d8876be2-71a7-431c-833b-2d0c39d14b6e" data-story-element-type="text">
          <div>
    <p><strong>Cold War In High Places</strong></p><p>The year was 1965, and the Cold War was reaching its apogee, with America stretching its geopolitical reach to all corners of the world in order to counter the communist influence. Closer to home, the War of â€™62 had left India intensely wary of its neighbour, China. To add fuel to simmering embers, China carried out its first nuclear test in 1964 in Xinjiang, a province that borders the northern tip of India. In this atmosphere of intense mutual suspicion and paranoia, the Pentagon began concocting a plan that would help both India and America keep a closer eye on China, especially with regard to its nuclear programme.</p><p>With satellites that could gather useful photographic intelligence still a few years away, Americaâ€™s Central Intelligence Agency (CIA) along with the Indian Intelligence Bureau (IB) planned on placing a powerful listening device at a point of extreme prominence along the Indo-Tibetan border. The site where the device would be placed was key as it would need to have uninterrupted access in order to intercept Chinese radio signals. This meant it would have to be positioned on a mountain that was high as well as close to the Tibetan plateau. With an unparalleled height advantage and an unobstructed view of China from its summit, there was no better choice than Nanda Devi.</p>
  </div>
</div>



      <div id="inf-card-21631012-ab2e-4940-a233-267421b9382d" data-story-element-id="21631012-ab2e-4940-a233-267421b9382d" data-story-element-type="text">
        <div>
     <hr>
  <div>
    <blockquote>To ensure the longevity and endurance of the device, which was supposed to work at an altitude of nearly 26,000 feet, it was decided that it would be nuclear-powered. </blockquote>
  </div>
  <hr>
</div>
  </div>



      <div id="inf-card-ac913b24-39b9-4cc4-9553-78b1b163d63d" data-story-element-id="ac913b24-39b9-4cc4-9553-78b1b163d63d" data-story-element-type="text">
          <div>
    <p>A System for Nuclear Auxiliary Power (SNAP) generator was designed so that it would power the telemetry functions of the device, a power unit similar to the ones being used in space at the time.</p><p>It was within the SNAP that seven plutonium fuel rods would be stored, made from a compound of Pu-238 and Pu-239. Once activated, the SNAP would constantly be converting radioactive heat energy created by the rods into electricity, which would power the multiple-sensor device as well as its six-foot-long antenna.</p><p>With the technical aspect settled, the question of who would carry and set up all this equipment remained. Only two expeditions had summited the mountain up until then, and more than a few climbers had died. There was no doubt that only the very best mountaineers could be trusted to carry a nuclear payload up one of the most difficult mountains in the world.</p>
  </div>
</div>



  </div>

              <div data-card-content-id="5aeaa671-5f93-450a-971d-b5690e92888f" data-card-version-id="58f0cfc2-71cc-46c3-a836-d90e638e4071">
        
      <div id="inf-card-a3cc2b9a-78bd-4006-bf8a-64632fc034d2" data-story-element-id="a3cc2b9a-78bd-4006-bf8a-64632fc034d2" data-story-element-type="text">
          <p><strong>League of Extraordinary Climbers</strong></p>
</div>



      <div id="inf-card-44cd66b4-c4c0-4956-b7f2-a5354b09a54c" data-story-element-id="44cd66b4-c4c0-4956-b7f2-a5354b09a54c" data-story-element-type="image">
  <div>
  <figure>
    <img alt="Captain MS Kohli AVSM, leader of the covert climbing expeditions, now at the ripe old age of 88. " src="https://images.assettype.com/indynetwork%2F2020-09%2Faea6959e-2270-436f-bbd2-426467f4f81b%2FImage_8.jpg?w=1170">
  </figure>
              
  
</div></div>



      <div id="inf-card-9a85c853-4586-48c3-95f7-70072afd02f2" data-story-element-id="9a85c853-4586-48c3-95f7-70072afd02f2" data-story-element-type="text">
          <div>
    <p>A group of 14 American and four Indian mountaineers was assembled. In totality, they represented the cream of a mountaineering generation. Among the Americans, some of the more famous climbers were Dr Robert Schaller, Tom Frost and Jim McCarthy. The Indian contingent consisted of Captain M S Kohli, Sonam Wangyal, H C S Rawat and G S Bhangu. All four had been members of the successful 1965 Indian Everest Expedition, which had put a record nine climbers on the summit. They were in fact enlisted for this covert expedition just a few days after returning from Everest. Together, the entire group was no less than a mountaineering dream team.</p><p>After having sworn their respective oaths of secrecy, the climbing team was flown to Mount McKinley in Alaska, the highest mountain in North America, to prepare for the arduous expedition ahead. While all of them were without doubt among the most experienced climbers at the time, they were rather new to the more idiosyncratic aspect of the expedition â€“ that of dealing with nuclear material.</p><p>American climber Jim McCarthy was appointed as the designated member of the team who would handle the plutonium rods. Through the summer of 1965, officials from Americaâ€™s Atomic Energy Commission trained McCarthy to load and unload the device without disturbing its deadly occupant. Other team members were briefed on the dangers of their special load as well, and ways to ensure minimum exposure to the deadly radioactive isotopes.</p><p>All climbers were going to be paid $1,000 per month, a hefty amount in the 1960s. While there would be personal gratification from having been of service to their respective nations, they were on no account to tell anyone about the nature of their expedition. The cover for the entire team was that they were a joint Indo-American mountaineering team conducting research for high-altitude flight for the American Air Force. Before departing for India, the covert operation was finally given its official codename: Operation Hat.</p>
  </div>
</div>



      <div id="inf-card-368b8863-5e90-4a6b-8a7e-47a26beda04f" data-story-element-id="368b8863-5e90-4a6b-8a7e-47a26beda04f" data-story-element-type="image">
  <div>
  <figure>
    <img alt="A Nanda Devi Temple at Munsiyari. This particular temple, and itâ€™s idol inside, is among the oldest of Uttarakhand" src="https://images.assettype.com/indynetwork%2F2020-09%2F49dfca8c-132b-43f5-b063-81b86f25e855%2FImage_5.jpg?w=1170">
  </figure>
              
  
</div></div>



      <div id="inf-card-5a316079-59a0-4a73-9dd2-5edab677f0f6" data-story-element-id="5a316079-59a0-4a73-9dd2-5edab677f0f6" data-story-element-type="text">
          <div>
    <p><strong>Into the Sanctuary of the Goddess</strong></p><p>In an effort to attract minimal attention, most of the mountaineers were flown into base camp by helicopter in September 1965. However, the climbing equipment, rations, and of course the listening device itself â€” stored inside a solid lead casket â€” were transported in the time-honoured fashion, carried by nearly 150 <em>dotial</em> porters through the Rishi Ganga gorge. The special load did not go unnoticed among the porters, and apart from its unusual weight, many of them alleged to have felt heat emanating from the casket. Mounted on poles, some climbers later noted its uncanny resemblance to the Biblical Ark of the Covenant, in the manner it was transported as well as the supreme power it possessed.</p><p>After having established themselves at the base of the mountain, the mountaineers methodically began making their way up Nanda Devi. Establishing a series of camps along the climbing route, the team was finally positioned to make an attempt on the summit in the middle of October. It was then that catastrophe struck.</p><p>A violent storm hit the mountain and made it impossible to continue. The summit team, along with the device, was encamped just 2,000 feet below their objective. The extreme conditions, however, greatly endangered their position. Keeping in mind the extreme volatility of such storms, Captain Kohli â€” the leader of the climbing team â€” called for an immediate retreat.</p>
  </div>
</div>



  </div>

              <div data-card-content-id="65e7e1e4-a3b0-4ec4-9aaa-c4696502703a" data-card-version-id="344b6037-e7b7-4181-b199-8bea1745da05">
        
      <div id="inf-card-6d7e221c-28e2-4bd3-ac8f-475267b102e9" data-story-element-id="6d7e221c-28e2-4bd3-ac8f-475267b102e9" data-story-element-type="text">
          <div>
    <p>Carrying the 56 kg listening device in deteriorating weather conditions at 23,000 feet was going to be a Herculean task. Prioritising the need for a quick descent to minimise the risk to the lives of his fellow climbers, Kohli decided to ditch the equipment in the high camp. He reasoned that another expedition could always be mounted when weather conditions improved, in order to retrieve the device. On the other hand, the life of a fellow climber was irreplaceable.</p><p>Thus, with all the climbers having safely descended, the expedition came to an end. Being late in the year, the weather window to climb Nanda Devi was now closed. Any new expedition would have to bide their time till the following year. The nuclear device too, abandoned on a high precipice of the mountain, would have to wait.</p><p><strong>Plan B</strong></p><p>With the arrival of spring in 1966, a second expedition was launched to locate the equipment, and most importantly the nuclear device, that had been left the previous autumn. The composition of the climbing team was more or less the same, and soon they were scouring the slopes of Nanda Devi, trying to find their highly valuable and potentially dangerous belongings. But it was all …</p></div></div></div></div></div></div></article></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.livehistoryindia.com/cover-story/2020/09/18/nanda-devi-nuclear-device">https://www.livehistoryindia.com/cover-story/2020/09/18/nanda-devi-nuclear-device</a></em></p>]]>
            </description>
            <link>https://www.livehistoryindia.com/cover-story/2020/09/18/nanda-devi-nuclear-device</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547123</guid>
            <pubDate>Sat, 26 Dec 2020 22:58:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A New Google]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25547085">thread link</a>) | @tosh
<br/>
December 26, 2020 | https://dcgross.com/a-new-google?src=t | <a href="https://web.archive.org/web/*/https://dcgross.com/a-new-google?src=t">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>   <p>[TL;DR: Google has gotten bad; we all know it; ideas for a startup making a better Google.]</p> <p>In 2000, Google got popular because hackers realized it was better than Lycos or Excite. This effect is happening again. Early adopters aren’t using Google anymore.</p> <p>They aren’t using DuckDuckGo either. They’re still using Google.com, but differently. To make Google usable, users are adding faux-query modifiers that to supress the “garbage Internet”.</p> <p>You see this in the typeahead logs.</p> <p><img src="https://dcgross.com/assets/new-google/image6.png" alt=""> <em></em></p><center><em>Products (Reddit)</em></center> <p><img src="https://dcgross.com/assets/new-google/image4.png" alt=""> <em></em></p><center><em>Services (Reddit, Yelp)</em></center> <p><img src="https://dcgross.com/assets/new-google/image1.png" alt=""> <em></em></p><center><em>Movies (Rotten Tomatoes)</em></center> <p><img src="https://dcgross.com/assets/new-google/image5.png" alt=""> <em></em></p><center><em>Even code (Github)</em></center> <p>Interestingly, this doesn’t work for all categories. <img src="https://dcgross.com/assets/new-google/image3.png" alt=""> <img src="https://dcgross.com/assets/new-google/image2.png" alt=""> <em></em></p><center><em>Recipes don’t have a “Reddit” equivalent</em></center> <h3 id="query-operators-mean-somethings-broken">Query Operators Mean Something’s Broken</h3> <p>More advanced users use modifiers like <code>site: filetype: intitle:</code> because adding “reddit” isn’t strict enough, as spammy websites often manipulate content to win SEO.</p> <p>How about those websites that stuff the year in the title? “Reviews UPDATED JANUARY 2020” are exploiting the fact that customers suffix queries with the year. What those people are trying to command is freshness, not a title match.</p> <p>Something’s broken, and a tiny share of Google is open for the taking. Obviously attacking incumbents head-on doesn’t work. Here are two alternative ideas for bootstrapping next-generation search:</p> <h3 id="1-boogle-a-query-reformulator">#1 Boogle, A Query Reformulator</h3> <p>Introducing Boogle, a proxy for Google that’s just Better Google Search. It’s a query expander. We predict the correct operators for your query, proxy Google’s results, and serve. For example:</p> <p><code>query("stripe.js example") -&gt; query("stripe.js example (site:github.com OR site:gitlab.com OR site:..."))</code></p> <p><code>query("is anker charger") -&gt; query("is anker charger (inurl:forum OR site:reddit.com OR ...))"</code></p> <p>Query topic modeling is a rich science with plenty of examples.</p> <p>You’d almost as fast as Google, never worse, and occasionally better. This will help build the reflex to use you instead. This approach isn’t that hard to get started with, and might work for the high-end users.</p>  <p>You could go after this vertical by vertical – build the <em>best</em> site for electric product search, for travel, for code, etc. A key question is how to build habitual recall to use your product over Google. Amazon and Airbnb both enjoy a huge amount of direct traffic. Some learnings from those:</p> <ul> <li><strong>Stellar mobile destination.</strong> Using Airbnb directly feels more fluid and fun than using Google for Airbnb.</li> <li><strong>The 90% Rule.</strong> To build reflex you need to give me what I want most of the time.** **With Prime, Amazon made it such that we stopped price comparing across other sites; Amazon would get it to us fastest, and that turns out to matter more than price. Most of the time you open Amazon.app, it satisfies.</li> <li><strong>Come for search, stay for something else.</strong> I don’t think of Airbnb or Amazon as search apps. They help me get things or book homes. You might want to your search app to be a destination for something else. This is where I think community comes in.</li> </ul> <p>Picking a vertical that <em>doesn’t</em> have strong typeahead completions[1] would help you build community around your search engine. Recipes, fitness, fashion, etc. don’t have decacorn conglomerates like Github or Reddit. That might mean it’s easier to build community around them, and put your flagship search engine on top.</p> <hr> <p>If you’re working on this kind of stuff, try out <a href="https://pioneer.app/">Pioneer</a> or just shoot me an email – daniel@pioneer.app.</p> <hr> <p>[1] In reality I’d pick the vertical _I _love most. If you’re a guitar player start with music; a movie buff should build better Rotten Tomatos. Etc.</p> </article></div>]]>
            </description>
            <link>https://dcgross.com/a-new-google?src=t</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547085</guid>
            <pubDate>Sat, 26 Dec 2020 22:51:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You're Allowed to Make Your Own Tools]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25547008">thread link</a>) | @janniks
<br/>
December 26, 2020 | https://www.swyx.io/make-your-own-tools/ | <a href="https://web.archive.org/web/*/https://www.swyx.io/make-your-own-tools/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>I read a list of <a href="https://milan.cvitkovic.net/writing/things_youre_allowed_to_do/">Things You're Allowed To Do</a> on Hacker News recently. These are useful reminders for a well paid, technical audience, but one thing stuck out to me: <strong>It didn't mention making your own tools</strong>. Not even once.</p>
<p>Even the greatest software has parts that aren't so great for you. But the difference between you and everyone else is that you can code.</p>
<p>Here's a list of tools (<em>that you don't need anyone's permission</em>) to code for yourself:</p>
<ul>
  <li><strong>You can make your own Stylesheet</strong>: Long before <a href="https://twitter.com/swyx/status/1336363173838909441">GitHub got Dark Mode</a>, developers had been making their own with the <a href="https://github.com/openstyles/stylus">Stylus Userstyles Manager</a>.</li>
  <li>
    <strong>You can make your own Query Generator</strong>: Most platforms have advanced features that are poorly documented and don't have good UIs. You can make your own. I made my own <a href="https://twitter.com/swyx/status/1328086859356913664?s=20">Advanced Twitter Search UI</a> embedding all the little tips and tricks that people pass around by word of mouth. I know of two ongoing attempts to <a href="https://twitter.com/swyx/status/1335627133956153344">do the same for Google's advanced operators</a>.
    
    <img src="https://dev-to-uploads.s3.amazonaws.com/i/jntu0l1zk2o3xz8bu5fz.png" alt="Alt Text">
  </li>
  <li><strong>You can make an Inspo Generator</strong>: Projects like <a href="https://whattotweet.com/">What to Tweet</a>, <a href="https://components.ai/">Components.ai</a> and <a href="https://www.doodlestrudel.com/">Doodle Strudel</a> get ridiculously popular compared to their technical complexity - because inspiration loves combinatorial explosions!</li>
  <li><strong>You can make your own scripts</strong>: <a href="https://github.com/NARKOZ/hacker-scripts#hacker-scripts">Like this guy</a>. Developers have apparently been automating coffee machines for so long that I recently learned that the infamous <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/418">HTTP Error 418</a> was inspired by an actual real life situation.</li>
  <li><strong>You can make your own CLIs</strong>: CLIs are essentially interactive scripts. If you do JavaScript, I made a course on Egghead about <a href="https://egghead.io/courses/build-custom-command-line-interface-cli-tooling-with-oclif-and-typescript?af=95qfq1">building custom CLIs with oclif and TypeScript</a>!</li>
  <li>
    <strong>You can make personal proxies</strong>: Frustrated with slow searches (I am often on mobile 3G), <a href="https://news.ycombinator.com/item?id=25538586">gamed search results</a>, and <a href="https://twitter.com/shanselman/status/1341583883947544578?s=20">assorted crap in my URLs</a>, I recently <a href="https://twitter.com/swyx/status/1342625544320339969">made my own Google Search proxy</a>. A proxy is different from "just the UI", because it involves setting up a server or serverless function to process data for you. Because you have total control of server data, you have the ability to postprocess, combine, persist, and optimize it for your specific preferences. <a href="https://www.reuters.com/article/dataprivacy-linkedin-datascraping-idUSL2N2GM1ZV">Scraping public data is probably legal</a>, but personal means personal - Be careful about sharing it with others and definitely do not sell it. But this is ethically no different than setting up your own <a href="https://pi-hole.net/">Pi-hole</a>.
    <img src="https://dev-to-uploads.s3.amazonaws.com/i/56r2dhdtgq8qw3qsi3jo.png" alt="Alt Text">
    <blockquote>
      <p>My personal <a href="https://github.com/sw-yx/automation/">cheatsheet of automation resources is available here</a>.</p>
    </blockquote>
  </li>
</ul>
<p>These ideas are great, scoped projects that let you try out new languages and frameworks and improve your quality of life as a side effect. Always wanted to <a href="https://www.swyx.io/svelte-why/">try Svelte</a>? Make a query generator! Want a new CLI? <a href="https://deno.land/posts/v1.6">Deno ships binaries now!</a> <a href="https://supabase.io/">Supabase</a> claims to be an Open Source Firebase Alternative? Put it to the test!</p>
<p>And there's a compounding effect to these as you make them. More often than not, the lessons you learn from making a tool for yourself will find their way into your work. If you get <em>really</em> lucky - <a href="https://medium.com/who-what-why/how-side-projects-saved-our-startup-a83a80f3b3ae">your side projects might even become your life's work</a>.</p>
<p>Don't take it from me. Here's <a href="https://twitter.com/dan_abramov/status/1140259247680315393?s=20">Dan Abramov</a>:</p>
<blockquote>
  <p>Here’s a thing that I learned at FB that I wish I knew much earlier. Invest in building custom tools!</p>
</blockquote>
<blockquote>
  <p>You might think only bigcos make custom tools. But a tool doesn’t have to be sophisticated. It can be a script you could write in a day. And at small and medium companies, even a little effort can yield a huge return. Because <strong>nobody optimized anything yet</strong>.</p>
</blockquote>
<p>The beauty of specializing in moving bits instead of atoms is that we can iterate in minutes, rather than months. That's a skill that customers pay us handsomely for, and we should remember that we can simply be our own customers too.</p>
<blockquote>
  <p>Author's Note: I wrote a longer treatment of the benefits of, and ideas for, Side Projects in <a href="https://www.learninpublic.org/">The Coding Career Handbook</a>. I also commented in <a href="https://www.thekeycuts.com/dear-analyst-50-walking-through-a-vba-script-for-trading-billions-of-dollars-worth-of-derivatives-with-shawn-wang/">the KeyCuts podcast</a> on how all young finance traders make their own pricing tools as a rite of passage — like how <a href="https://starwars.fandom.com/wiki/Knighting_ceremony/Legends#New_Jedi_Order">Jedi make their own lightsabers</a> before becoming Jedi Knights.</p>
</blockquote>
<blockquote>
  <p>If you are making a DevTools startup, I am <a href="https://codingcareer.circle.so/c/devtools">incubating a small community in DX Circle</a>, my proto-blog for investing in Developer Tools and Developer Communities.</p>
</blockquote>
</div></div>]]>
            </description>
            <link>https://www.swyx.io/make-your-own-tools/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547008</guid>
            <pubDate>Sat, 26 Dec 2020 22:41:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Made a Covid-19 Vaccine in My Kitchen and It Worked – Science Still Sucks]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25546796">thread link</a>) | @emre
<br/>
December 26, 2020 | http://www.josiahzayner.com/2020/12/i-made-covid-19-vaccine-in-my-kitchen.html | <a href="https://web.archive.org/web/*/http://www.josiahzayner.com/2020/12/i-made-covid-19-vaccine-in-my-kitchen.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-9192139371851934751" itemprop="description articleBody">
<p><b><span><p><a href="https://1.bp.blogspot.com/-LHnH4HuYWBY/X9OyNLp5gfI/AAAAAAAAhjE/vuWyJAJ93qw38EegX5RH5_IaFtAXABxLgCLcBGAsYHQ/s2048/logo1.png"><img data-original-height="1809" data-original-width="2048" height="283" src="https://1.bp.blogspot.com/-LHnH4HuYWBY/X9OyNLp5gfI/AAAAAAAAhjE/vuWyJAJ93qw38EegX5RH5_IaFtAXABxLgCLcBGAsYHQ/w320-h283/logo1.png" title="Central Dogma Collective" width="320"></a></p><br>I hate science. It's so elitist.&nbsp;</span></b></p><p>I have an internal dialogue going all the time trying to convince myself that I don't want my work to be called science. What I do is completely different, more sacred, honest and open and yes sometimes flawed. Sometimes I hide the fact that I have a Ph.D. because I don’t want it to be a symbol of authority or intelligence for myself. It also feels douchey to tell people I have a Ph.D. I want to be judged by my actions, not where I went to school, which can be primarily determined by your parents financial status and education level. I grew up on a farm in rural Indiana. We ate eggs from our chickens and drank dehydrated milk. Up until even high school my family was dirt poor. We had our electricity shut-off and had to take cold showers. When we couldn't afford the phone bill, I walked to 7-11 and used the payphone to call my friends. Violence, evictions, car repossessions — you name it, I’ve lived it. Starting undergrad at SIU I was homeless and lived out of my car and slept on the dorm room floors of people I knew.&nbsp;</p><p>When I was in graduate school, 99% of my peers did not come from a similar background. It was abundantly clear that the practice of science and medicine is only accessible to the upper crust. That’s an issue in itself, but the <b><i>f</i></b><i><b>ucking humongous gigantic bigger problem</b></i> is that cutting-edge medicines are also only available to the societal elite. Time and time again throughout this pandemic, we’ve watched as the wealthy and powerful get all the unapproved drugs to treat their covid, while all of us peasants sit back and do our best not to die without them. The 108 Regeneron antibody cocktails all went to Washington DC.</p><p>That’s why I left academia. Why I quit my job at NASA and started doing science as a biohacker. I want everyone to be able to do science without any gatekeepers. The single greatest impediment to diversity in science is access to knowledge and information that is being held tighter than Ric Flair’s Figure Four Leg Lock.</p><p><b><span>Biohackers are setting knowledge free.</span></b></p><p>In May 2020, an article came out in <a href="https://science.sciencemag.org/content/369/6505/806">science magazine</a> where researchers showed that by using a DNA vaccine that codes for the SARS-COV2 spike protein, they could create antibodies that provide protection from covid-19 in macaque monkeys without harmful side-effects. Getting good monkey data is basically the best pre-human data you can ever hope to get. Most people only have experimental data from mouse tests. When I see a paper like this the gears in my brain begin to spin because there is a good chance the FDA would approve this for human testing.</p><p>So, I decided to test it myself. The project perfectly fit a niche where biohackers have an experimental advantage over academia and industry. With enough knowledge and skill, we could perform quick but data-laden experiments to show whether the same DNA vaccine tested on monkeys would be promising in humans. And instead of taking months or years we could have results in as little as a few weeks.&nbsp;</p><p>I brought up the idea with David Ishee and Dariia Dantseva, fellow members of the biohacking group the <a href="http://the-cdc.com/" target="_blank">Central Dogma Collective (CDC)</a>. They also thought that based on the data this would be a fucking crazy project. We decided <a href="https://youtube.com/playlist?list=PLNAhY1w2w78rSeNQo_e0dQ2w8mmGEg7Mr">we would live-stream</a> every step so that people could learn how to do advanced biomedical research like this in their own home. If one were to replicate the experiment from scratch, the total individual cost would end up being around $3500, the major costs being $1600 for DNA synthesis and $1200 for the kits to measure coronavirus spike protein antibodies.</p><p>What I really wanted was to show people how to do the science. I didn't really care if it worked or not but I tend to be pessimistic about my own experiments anyway. While testing and creating a successful coronavirus vaccine would send a powerful message to the world, teaching people how to do advanced biomedical research will change it.&nbsp;</p><p>In the end, the experiment worked. All three of us developed SARS-CoV2 spike protein neutralizing antibodies. I still can't fucking believe it. Not only did we create and test a successful vaccine, we showed that we could get a gene therapy to work (a DNA vaccine changes the DNA in your cells and so is a gene therapy also). <a href="https://docs.google.com/document/d/1WTuRBuy74KlaBzLrd0aTZl852nhPNCWL06aB7wY1JKk/edit?usp=sharing" target="_blank">Here is a summary of the experimental details and results</a> if you are interested. We didn't create the vaccine to sell it. We made the <a href="https://drive.google.com/drive/folders/1SracILuRbiZt4f7EVH2JBvefaHmsOUsC?usp=sharing" target="_blank">nucleotide sequence and genetic design data open and free</a> so that anyone can easily recreate it. All in a state-of-the-art lab. I'm kidding, my lab is a tiny bedroom in a house in West Oakland, David's is in a shed in rural Mississippi and Dariia's is an old building she converted in Ukraine. If your mind isn't blown, you either already knew about the project or you don't understand what I just told you.&nbsp;</p><p><b><span>If you want to know why I created and tested a coronavirus vaccine on myself, it’s because I am at War.&nbsp;</span></b></p><p>I know it sounds a bit dramatic but there really is a class war going on. There is a group of people who are actively making choices that cause a disproportionate amount of deaths among those in lower social classes. New gene therapies cost over a million dollars. That’s right. Your life, your child’s life, your mother, your loved one depends on how much money you make. The government and Pharma companies aren’t going to help you when you can’t afford it either. Most of these gene therapies aren't even available outside the US either because most countries with socialized medicine won't pay for them. So don't tell me how your country's healthcare is better.</p><p>Considering that if you are reading this there is a 99% chance you are not part of the top 1%, let me ask you this — why are we letting the wealthy and powerful get away with this?&nbsp;</p><p>Those who have a monopoly on the understanding and use of biotechnology have all the power. If I, if we can teach people how do it themselves then we win back power.</p><p>This is why biohackers are needed in society.&nbsp;</p><p>Now in Dec. 2020, many people are still holed up waiting for a vaccine. The problem is when a vaccine for covid comes around it won't be the 99% that receive it first. Your life isn't worth that much. You're not important or wealthy or powerful. The people who will receive it first are the same people who can sit out a pandemic in the comfort of their home and have their necessities delivered by the working class. They tell everyone else to social distance and wear a mask but won’t do it themselves. Fucking Gavin Newsom.</p><p>Still, we are losing this class war as people continue to fight against their best interest. They believe lying politicians, lying scientists, and are manipulated by the news media. We are told to wait and trust while hundreds of thousands of people in the US die. While small businesses close at an unprecedented rate, but large corporations make billions.</p><p>What the fuck. They are killing us and taken what we own. Why are we still putting up with this?</p><p><b><span>We can take back what belongs to us by creating for ourselves.&nbsp;</span></b></p><p><b><span>Science and medicine belong to us not them.&nbsp;</span></b><b><span>Biohack the fucking planet</span></b></p>

</div></div>]]>
            </description>
            <link>http://www.josiahzayner.com/2020/12/i-made-covid-19-vaccine-in-my-kitchen.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25546796</guid>
            <pubDate>Sat, 26 Dec 2020 22:03:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Dunning-Kruger Effect Is Probably Not Real]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 65 (<a href="https://news.ycombinator.com/item?id=25546787">thread link</a>) | @ingve
<br/>
December 26, 2020 | https://www.mcgill.ca/oss/article/critical-thinking/dunning-kruger-effect-probably-not-real | <a href="https://web.archive.org/web/*/https://www.mcgill.ca/oss/article/critical-thinking/dunning-kruger-effect-probably-not-real">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>I want the Dunning-Kruger effect to be real. First described in<a href="https://doi.apa.org/doiLanding?doi=10.1037%2F0022-3514.77.6.1121"> a seminal 1999 paper</a> by David Dunning and Justin Kruger, this effect has been the darling of journalists who want to explain why dumb people don’t know they’re dumb. There’s even<a href="https://youtu.be/BdnH19KsVVc"> video of a fantastic pastiche</a> of Turandot’s famous aria, <i>Nessun dorma,</i> explaining the Dunning-Kruger effect. “They don’t know,” the opera singer belts out at the climax, “that they don’t know.”</p>

<p>I was planning on writing a very short article about the Dunning-Kruger effect and it felt like shooting fish in a barrel. Here’s the effect, how it was discovered, what it means. End of story.</p>

<p>But as I double-checked the academic literature, doubt started to creep in. While trying to understand the criticism that had been leveled at the original study, I fell down a rabbit hole, spoke to a few statistics-minded people, corresponded with Dr. Dunning himself, and tried to understand if our brain really was biased to overstate our competence in activities at which we suck... or if the celebrated effect was just a mirage brought about by the peculiar way in which we can play with numbers.</p>

<p>Have we been overstating our confidence in the Dunning-Kruger effect?</p>

<h5><b>A misunderstood effect</b></h5>

<p>The most important mistake people make about the Dunning-Kruger effect, according to Dr. Dunning, has to do with who falls victim to it. “The effect is about us, not them,” he wrote to me. “The lesson of the effect was always about how we should be humble and cautious about ourselves.” The Dunning-Kruger effect is not about dumb people. It’s mostly about all of us when it comes to things we are not very competent at.</p>

<p>In a nutshell, the Dunning-Kruger effect was originally defined as a bias in our thinking. If I am terrible at English grammar and am told to answer a quiz testing my knowledge of English grammar, this bias in my thinking would lead me, according to the theory, to believe I would get a higher score than I actually would. And if I excel at English grammar, the effect dictates I would be likely to slightly underestimate how well I would do. I might predict I would get a 70% score while my actual score would be 90%. But if my actual score was 15% (because I’m terrible at grammar), I might think more highly of myself and predict a score of 60%. This discrepancy is the effect, and it is thought to be due to a specific problem with our brain’s ability to assess its skills.</p>

<p>This is what student participants went through for Dunning and Kruger’s research project in the late 1990s. There were assessments of grammar, of humour, and of logical reasoning. Everyone was asked how well they thought they did and everyone was also graded objectively, and the two were compared.</p>

<p>Since then, many studies have been done that have reported this effect in other domains of knowledge. Dr. Dunning tells me he believes the effect “has more to do with being <i>misinformed</i> rather than uninformed.” If I am asked the boiling point of mercury, it is clear my brain does not hold the answer. But if I am asked what is the capital of Scotland, I may think I know enough to say Glasgow, but it turns out it’s Edinburgh. That’s misinformation and it’s pushing down on that confidence button in my brain.</p>

<p>So case closed, right? On the contrary. In 2016 and 2017, two papers were published in a mathematics journal called <i>Numeracy</i>. In them, the authors argued that the Dunning-Kruger effect was a mirage. And I tend to agree.</p>

<h5><b>The effect is in the noise</b></h5>

<p>The<a href="https://scholarcommons.usf.edu/numeracy/vol9/iss1/art4/"> two</a><a href="https://scholarcommons.usf.edu/numeracy/vol10/iss1/art4/"> papers</a>, by Dr. Ed Nuhfer and colleagues, argued that the Dunning-Kruger effect could be replicated by using random data. “We all then believed the [1999] paper was valid,” Dr. Nuhfer told me via email. “The reasoning and argument just made so much sense. We never set out to disprove it; we were even fans of that paper.” In Dr. Nuhfer’s own papers, which used both computer-generated data and results from actual people undergoing a science literacy test, his team disproved the claim that most people that are unskilled are unaware of it (“a small number are: we saw about 5-6% that fit that in our data”) and instead showed that both experts and novices underestimate and overestimate their skills with the same frequency. “It’s just that experts do that over a narrower range,” he wrote to me.</p>

<p>Wrapping my brain around all this took weeks. I recruited a husband-and-wife team, Dr. Patrick E. McKnight (from the Department of Psychology at George Mason University, also on the advisory board of Sense About Science and STATS.org) and Dr. Simone C. McKnight (from Global Systems Technologies, Inc.), to help me understand what was going on. Patrick McKnight not only believed in the existence of the Dunning-Kruger effect: he was teaching it to warn his students to be mindful of what they actually knew versus what they thought they knew. But after replicating Dr. Nuhfer’s findings using a different platform (the statistical computing language R instead of Nuhfer’s Microsoft Excel), he became convinced the effect was just an artefact of how the thing that was being measured was indeed measured.</p>

<p>We had long conversations over this as I kept pushing back. As a skeptic, I am easily enticed by stories of the sort “everything you know about this is wrong.” That’s my bias. To overcome it, I kept playing devil’s advocate with the McKnights to make sure we were not forgetting something. Every time I felt my understanding crystallize, doubt would creep in the next day and my discussion with the McKnights would resume.</p>

<p>I finally reached a point where I was fairly certain the Dunning-Kruger effect had not been shown to be a bias in our thinking but was just an artefact. Here then is the simplest explanation I have for why the effect appears to be real.</p>

<p>For an effect of human psychology to be real, it cannot be rigorously replicated using random noise. If the human brain was predisposed to choose heads when a coin is flipped, you could compare this to random predictions (heads or tails) made by a computer and see the bias. A human would call more heads than the computer would because the computer is making random bets whereas the human is biased toward heads. With the Dunning-Kruger effect, this is not the case. Random data actually mimics the effect really well.</p>

<p>The effect as originally described in 1999 makes use of a very peculiar type of graph. “This graph, to my knowledge, is quite unusual for most areas of science,” Patrick McKnight told me. In the original experiment, students took a test and were asked to guess their score. Therefore, each student had two data points: the score they thought they got (self-assessment) and the score they actually got (performance). In order to visualize these results, Dunning and Kruger separated everybody into quartiles: those who performed in the bottom 25%, those who scored in the top 25%, and the two quartiles in the middle. For each quartile, the average performance score and the average self-assessed score was plotted. This resulted in the famous Dunning-Kruger graph.</p>

<p><img height="627" width="725" src="https://www.mcgill.ca/oss/files/oss/figure_1_3.png" alt=""></p>

<p>Plotted this way, it looks like those in the bottom 25% thought they did much better than they did, and those in the top 25% underestimated their performance. This observation was thought to be due to the human brain: the unskilled are unaware of it. But if we remove the human brain from the equation, we get this:</p>

<p><img height="451" width="1086" src="https://www.mcgill.ca/oss/files/oss/figure_2_1.png" alt=""></p>

<p>The above Dunning-Kruger graph was created by Patrick McKnight using computer-generated results for both self-assessment and performance. The numbers were random. There was no bias in the coding that would lead these fictitious students to guess they had done really well when their actual score was very low. And yet we can see that the two lines look eerily similar to those of Dunning and Kruger’s seminal experiment. A<a href="https://www.sciencedirect.com/science/article/pii/S019188690100174X"> similar simulation</a> was done by Dr. Phillip Ackerman and colleagues three years after the original Dunning-Kruger paper, and the results were similar.</p>

<p>Measuring someone’s perception of anything, including their own skills, is fraught with difficulties. How well I think I did on my test today could change if the whole thing was done tomorrow, when my mood might differ and my self-confidence may waver. This measurement of self-assessment is thus, to a degree, unreliable. This unreliability--sometimes massive, sometimes not--means that any true psychological effect that does exist will be measured as smaller in the context of an experiment. This is called attenuation due to unreliability. “Scores of books, articles, and chapters highlight the problem with measurement error and attenuated effects,” Patrick McKnight wrote to me. In his simulation with random measurements, the so-called Dunning-Kruger effect actually becomes <i>more</i> visible as the measurement error increases. “We have no instance in the history of scientific discovery,” he continued, “where a finding improves by increasing measurement error. None.”</p>

<h5><b>Breaking the spell</b></h5>

<p>When I plug “Dunning-Kruger effect” into Google News, I get over 8,500 hits from media outlets like <i>The New York Times</i>, <i>New Scientist</i>, and the CBC. So many simply endorse the effect as a real bias of the brain, so it’s no wonder that people are not aware of the academic criticism that has existed since the effect was first published. It’s not just Dr. Nuhfer and his <i>Numeracy </i>papers. Other academic critics have pointed the finger, for example, at regression to the mean.</p>

<p>But as Patrick McKnight points out, regression to the mean occurs when the same measure is taken over time and we track its evolution. If I take my temperature every morning and one day spike a fever, that same measure will (hopefully) go down the next day and return to its mean value as my fever abates. That’s regression to the mean. But in the context of the Dunning-Kruger effect, nothing is measured over time, and self-assessment and performance are different measures entirely, so regression to the mean should not apply. The unreliability of the self-assessment …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mcgill.ca/oss/article/critical-thinking/dunning-kruger-effect-probably-not-real">https://www.mcgill.ca/oss/article/critical-thinking/dunning-kruger-effect-probably-not-real</a></em></p>]]>
            </description>
            <link>https://www.mcgill.ca/oss/article/critical-thinking/dunning-kruger-effect-probably-not-real</link>
            <guid isPermaLink="false">hacker-news-small-sites-25546787</guid>
            <pubDate>Sat, 26 Dec 2020 22:02:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interview with David Harris: I've never been a businessman]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25546626">thread link</a>) | @lhoff
<br/>
December 26, 2020 | https://www.golem.de/news/interview-with-david-harris-i-ve-never-been-a-businessman-2012-152533.html | <a href="https://web.archive.org/web/*/https://www.golem.de/news/interview-with-david-harris-i-ve-never-been-a-businessman-2012-152533.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="screen">

<div>
<div>
    
    <section>
        <h2>Mit Werbung weiterlesen</h2>
        <p>Besuchen Sie Golem.de wie gewohnt mit Werbung und Tracking, indem Sie der Nutzung aller Cookies zustimmen.
            Details zum Tracking finden Sie
            <!-- in der <a target="_blank" href="https://www.golem.de/sonstiges/Datenschutz.html">Datenschutz&shy;erkl&auml;rung</a> und -->
            im <span id="gsptextpc1">Privacy Center</span>.
        </p>
        <p id="loadhint">
                Skript wurde nicht geladen. Informationen zur Problembehandlung finden Sie
                <a href="https://www.golem.de/sonstiges/techinfo.html" target="_blank">hier</a>.
        </p>
        <div>
            
            <p id="gspcookiehint">Um der Nutzung von Golem.de mit Werbung zustimmen zu können,
                müssen Cookies in Ihrem Browser aktiviert sein. Weitere Informationen finden Sie
                <a href="https://www.golem.de/sonstiges/techinfo.html" target="_blank">hier</a>.
            </p>
            <p id="gspiframehint">Die Zustimmung in einem iFrame ist nicht möglich.<br>
                <a href="#" onclick="GolemConsent.redirectBack(true);">Seite in eigenem Fenster öffnen</a>.
            </p>
            <p id="fallbackhint">Der Zustimmungs-Dialog konnte nicht korrekt geladen werden,
                eine Zustimmung gilt nur vorläufig. Informationen zur Problem­behandlung finden Sie
                <a href="https://www.golem.de/sonstiges/techinfo.html" target="_blank">hier</a>.
            </p>
        </div>
        <p>
            Die Möglichkeit zum Widerruf finden Sie
            in unserer <a target="_blank" href="https://www.golem.de/sonstiges/Datenschutz.html#Widerruf">Datenschutz­erklärung</a>
            oder über den Link <span id="gsptextpc2">Cookies &amp; Tracking</span> am Ende jeder Seite.
        </p>
    </section>
    
    <section>
        <h2>… oder Golem pur bestellen</h2>
        <p>Mit Golem pur ab 3 Euro pro Monat können Sie Golem.de ohne Analyse- und
            Werbe­cookies nutzen, es kommen nur für unser Angebot erforderliche Cookies zum Einsatz.
        </p>
        <a target="_blank" href="https://redirect.golem.de/nl.php?id=account_cta_cmp">Zu Golem pur</a>
        <p id="loginhint">
        Bereits Pur-Leser?
        <a href="https://account.golem.de/user/login?redirect=https://www.golem.de/news/interview-with-david-harris-i-ve-never-been-a-businessman-2012-152533.html">Hier anmelden</a>.            <span id="nosubhint">Kein aktives Abo vorhanden.</span>
        </p>
    </section>
    <div>
        
        <div>
            <details>
                <summary>Informationen auf einem Gerät speichern und/oder abrufen</summary>
                <p>Für die Ihnen angezeigten Verarbeitungszwecke können Cookies, Geräte-Kennungen
                    oder andere Informationen auf Ihrem Gerät gespeichert oder abgerufen werden.
                </p>
            </details>
            <details>
                <summary>Personalisierte Anzeigen und Inhalte, Anzeigen- und Inhaltsmessungen, Erkenntnisse über Zielgruppen und Produktentwicklungen</summary>
                <p>Anzeigen und Inhalte können basierend auf einem Profil personalisiert werden.
                    Es können mehr Daten hinzugefügt werden, um Anzeigen und Inhalte besser zu personalisieren.
                    Die Performance von Anzeigen und Inhalten kann gemessen werden.
                    Erkenntnisse über Zielgruppen, die die Anzeigen und Inhalte betrachtet haben, können abgeleitet werden.
                    Daten können verwendet werden, um Benutzerfreundlichkeit, Systeme und Software aufzubauen oder zu verbessern.
                </p>
            </details>
            <details>
                <summary>Genaue Standortdaten verwenden</summary>
                <p>Es können genaue Standortdaten verarbeitet werden,
                    um sie für einen oder mehrere Verarbeitungszwecke zu nutzen.
                </p>
            </details>
        </div>
    </div>
    
</div><!-- c2_content -->
</div><!-- c2_wrapper -->

</div></div>]]>
            </description>
            <link>https://www.golem.de/news/interview-with-david-harris-i-ve-never-been-a-businessman-2012-152533.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25546626</guid>
            <pubDate>Sat, 26 Dec 2020 21:35:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quantifying the self – Why I track 80 metrics about my life every day]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25546516">thread link</a>) | @thefedoration
<br/>
December 26, 2020 | https://dailyvis.com/posts/quantified-self-why-i-track-my-life-in-data/ | <a href="https://web.archive.org/web/*/https://dailyvis.com/posts/quantified-self-why-i-track-my-life-in-data/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><h2>Self-tracking is an investment.</h2><p>Every day since April 2017, I spend a couple of minutes before I go to sleep to log the day's activities. </p><p>Until today, I haven't really thought of the time that it takes to do this. Some back of the napkin math brings that time spent (at 5 minutes a day) to 6675 minutes, which is 111.25 hours, or <strong>4.64 whole days</strong> of me looking at a screen and doing manual data entry.</p><p>That's <em>absolutely insane</em>, you could do so much else with that amount of time! Why would someone choose to spend their precious time in that fashion?</p><p>I'll tell you why I do it, and why I don't see myself stopping this evening ritual anytime soon.</p><h2>How I began quantifying my life</h2><p>It started out with trying to build a good habit, meditation in particular. I wanted to make sure that I met my goals, and it's like they say - you can't improve what you don't track.</p><p>So like any good data nerd, I started a spreadsheet. That spreadsheet contained a cell for every day where I would indicate if I meditated or not.</p><p>Pretty simple, right?</p><p>Maybe for the first couple of weeks. What started out as an innocent little spreadsheet eventually turned into something that had 80 columns, all kinds of values (numbers, letters, time durations), formula calculations, and yes even <em>conditional formatting</em>. If you looked over my shoulder and saw it you'd probably think I was some sort of genius hedge fund guy making millions in the stock market. Nope, making zero money, and if you subscribe to the idea that time is money, making negative money in fact.</p><p><span>
      <a href="https://dailyvis.com/static/73a617e1031f7ac13e15d4a863e4726d/8126d/spreadsheet-screenshot.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Self Tracking Spreadsheet" title="Self Tracking Spreadsheet" src="https://dailyvis.com/static/73a617e1031f7ac13e15d4a863e4726d/c1b63/spreadsheet-screenshot.png" srcset="https://dailyvis.com/static/73a617e1031f7ac13e15d4a863e4726d/5a46d/spreadsheet-screenshot.png 300w,https://dailyvis.com/static/73a617e1031f7ac13e15d4a863e4726d/0a47e/spreadsheet-screenshot.png 600w,https://dailyvis.com/static/73a617e1031f7ac13e15d4a863e4726d/c1b63/spreadsheet-screenshot.png 1200w,https://dailyvis.com/static/73a617e1031f7ac13e15d4a863e4726d/d61c2/spreadsheet-screenshot.png 1800w,https://dailyvis.com/static/73a617e1031f7ac13e15d4a863e4726d/8126d/spreadsheet-screenshot.png 2316w" sizes="(max-width: 1200px) 100vw, 1200px" loading="lazy">
  </a>
    </span>
<em>What my spreadsheet looked like at some point (before I stepped up my tech game)</em></p><h2>The aspects of my life that I keep track of</h2><h3>Fitness, Diet, Sleep</h3><p>The basic things to track, and I do it for obvious reasons like seeing my progress towards fitness goals and making sure that I'm not telling lies when my mom asks if I've been eating my veggies. </p><p>Health data is a big focus of the quantified self community (the online society of folks that track, share, and analyze their personal data), but even if you've never heard the term "Quantified Self" you're probably automatically tracking some sort of health data if you have a modern cell phone or electronic watch.</p><h3>Good habits &amp; things I want to learn</h3><p>Anything I want to improve on actively, I try to keep track of. I find that I get motivated by streaks and especially if it's a new habit, I'm more likely to keep it going when I visually see the momentum I have.</p><p>When I'm trying to get better at something new, I track it. It's been interesting to see the habits that stick around, and those that fizzle out. Sadly, my meditation practice that started this all isn't doing so well these days. Ironically though, I've found that the actual process of self-tracking has been a meditation of sorts, and a time for me to check in with myself.</p><h3>Bad habits</h3><p>Most people just celebrate good habits and try to brush their bad ones under the rug. I've found that tracking bad habits can be eye-opening, insightful, and opens the door to changing those habits if you wish to.</p><p>Like most people my age, "I don't have a drinking problem, but I could probably drink less". Sound familiar?</p><p>Humans are really bad at estimating, and most life decisions more than a day old are bundled up into the past and forgotten. It's one thing to know that you could drink less, and a completely other one to know exactly how many drinks you had this week, how that affects your sleep, mood, productivity and all of the other positive ambitions you have for your life.</p><p>There's also the reverse effect of the good habit streak. When you see that you've drank the past 2 nights, you're more likely to be a bit more conscious of taking today off from the sauce.</p><p><strong>Your memory will lie to you, but your data won't.</strong></p><h3>Time spend</h3><p>Time is the most precious resource, so it makes sense to keep track of it. Not that we need to be productive for every second of every day, but it does help to have a general idea of what you're spending your time on, and how that affects the other parts of your life that you care about.</p><p>I'm always working on a couple of different projects at the same time, and think of my time as an investment as there's always something else I could be doing. It helps to be able to zoom out and really see how I'm choosing to spend my time and compare that with what I'm getting out of it. I also find it fascinating to see the impact of what I'm working on and my mood, sleep, diet, and overall life choices.</p><p>Another time-related thing I track is who I spend my time with. Nothing too precise, just if I see a particular friend that day or not. This one is more just for curiosity (both myself and my friends), they always get a kick out of seeing the correlations between the days that we hang out and the rest of my tracked metrics.</p><h3>How I feel</h3><p>This one's big, as how we feel about ourselves is often times the key driver behind our life choices and day to day actions.</p><p>Call me crazy, but I want to be happy. I want to start my day in a good mood, and even more, I want to end my day in a good mood. I want to feel worry-free, confident, kind, decisive, and humble.</p><p>Unfortunately, I was born the old fashioned way and not in some sort of human positivity lab. I don't get to feel those things every single day. That's fine, I've accepted the human condition.</p><p>However, the daily actions I take do impact my mood (and the reverse is also true), and I'd like to be in touch with that. So I keep track of both, and every once in a while look at the relationships. I want to be able to answer questions like "What can I do to feel less anxious today?" or "Will eating this ice cream actually make me happy?"</p><p>These tracked metrics I keep close to myself, and the insights I get from them are my gold bars in the bank for a future rainy day.</p><h2>Datapoints tracked over time</h2><h2>So why bother doing all of this?</h2><p>The million dollar question, and the answer has evolved over time. To sum it up though:</p><ul><li><strong>Goals</strong> - Keeping myself accountable and reinforcing good habits</li><li><strong>Awareness</strong> - Not hiding from my bad habits, but acknowledging them in order to make decisions with data when it makes sense</li><li><strong>Mindfulness</strong> - This daily check-in lets me reflect on the day and set goals for tomorrow</li><li><strong>Insights</strong> - What starts as a one-way street of putting data in, turns into a two-way highway that gives me information about my life that goes beyond the obvious and has the potential to even surprise me</li><li><strong>I can't stop...</strong> - A joke but also not really. Is there a name for this type of addiction?</li></ul><h2>Is it worth it?</h2><p>I can only speak for myself, but I'd say absolutely. Those 5 minutes every night are not only not a "waste" because I reap the benefits of the data at some future point in time, but the forced moment of self-reflection is one that can be quite valuable.</p><p><em>The human lifespan is an adventure that can't simply be reduced to numbers, but I've found that using quantified self data about the day to day can enrich your life experience, answer interesting questions, and provide confidence in the actions that are taken every day.</em></p><p>What I will say though is that it doesn't need to be this extreme. For those interested in quantifying certain aspects of their life, it's easy to start small &amp; focused to help yourself with your goals. I'll warn you though, it can be addictive. </p><h2>The Quantified Self movement</h2><p>This concept of self-tracking is not one that I made up. There is a set of <a href="https://quantifiedself.com/">awesome</a> <a href="https://www.reddit.com/r/QuantifiedSelf/">online</a> <a href="https://www.openhumans.org/">communities</a> of people who quantify aspects of their life in different ways, and share their methods, reasons, conclusions, and insights with others.</p><p>However robust those communities are though, I think that QS is only getting started. Every year more and more wearables, devices, applications, and services that track personal data are coming out for a variety of use cases (health, wellness, financial, and medical are just the initial ones). This data needs to be handled in an ethical manner and with the upmost respect for what it stands for, in order for humans to fully trust &amp; adopt this technology. But if that can happen, our day to day data can be used for some incredible applications to really enhance the human experience.</p><h2>What I learned about myself</h2><p>Thanks for getting this far, but I think it's time for a break. In my next post I'll share the top insights that I've learned about myself from tracking all of this data every day.</p><p>If you enjoyed this post and want to get notified of the next one, feel free to <a href="https://dailyvis.com/subscribe/">subscribe</a></p></section></div>]]>
            </description>
            <link>https://dailyvis.com/posts/quantified-self-why-i-track-my-life-in-data/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25546516</guid>
            <pubDate>Sat, 26 Dec 2020 21:18:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting rid of NPM scripts]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 52 (<a href="https://news.ycombinator.com/item?id=25546460">thread link</a>) | @efortis
<br/>
December 26, 2020 | https://blog.uidrafter.com/engineering/getting-rid-of-npm-scripts | <a href="https://web.archive.org/web/*/https://blog.uidrafter.com/engineering/getting-rid-of-npm-scripts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">

<article>
<header>


</header>
<p>
In 2016, Sam Saccone <a rel="noopener" target="_blank" href="https://www.kb.cert.org/vuls/id/319816">discovered a vulnerability</a> that
allows adversaries to run arbitrary scripts when installing an NPM package of
theirs. As mitigation, NPM co-founder Laurie Voss <a rel="noopener" target="_blank" href="https://blog.npmjs.org/post/141702881055/package-install-scripts-vulnerability">
suggests</a>:
</p>
<ul>
<li>
<b>Option 1</b>: adding <code>--ignore-scripts</code> when running <code><span>npm</span>
install</code>
</li>
<li>
<b>Option 2</b>: permanently adding <code>ignore-scripts=true</code> to <code>.npmrc</code>
</li>
</ul>
<p>
UI Drafter uses the latter because it avoids having to
remember the flag everytime. But that option disables NPM
<code>"scripts"</code>. Therefore, we end up with two alternatives:
</p>
<ul>
<li>
<b>Option A</b>: overriding: <code><span>npm</span> run --ignore-scripts=false
<b>test</b></code>
</li>
<li>
<b>Option B</b>: using this shell script or a <a href="#-Makefile">Makefile</a>:
</li>
</ul>
<pre><span>#!/bin/sh</span>

<span>case</span> <span>$1</span> <span>in</span>
  <b>dev</b>)   ./make-dev.js <span>;;</span>
  <b>test</b>)  mocha <span>"src/**/*.test.js"</span><span></span> <span>;;</span>
  <b>lint</b>)  eslint src <span>;;</span>
  <b>slint</b>) stylelint <span>"src/**/*.css"</span><span></span> <span>;;</span>

  <b>prod</b>)  <span>time</span> ./make-production.js <span>;;</span>
  <b>all</b>)   <span>$0</span> <b>test</b> &amp;&amp; <span>$0</span> <b>lint</b> &amp;&amp; <span>$0</span> <b>slint</b> &amp;&amp; <span>$0</span> <b>prod</b> <span>;;</span>

  *)     <span>echo</span> <span>"Invalid task: <span>$1</span>"</span><span>;</span> <span>exit</span> <span>1</span> <span>;;</span>
<span>esac</span>
</pre>
<p>Which can be ran as:</p>
<pre>./<span>make</span> <b>test</b>
</pre>
<p>
If the package is not globally installed, prefix the path. For example:
</p>
<pre><b>lint</b>) <span>node_modules/.bin/</span>eslint src <span>;;</span>
</pre>
<h3>Overriding at installation</h3>
<p>
If you need to install packages that install binary dependencies, or rely
on running an NPM script, override the <code>.npmrc</code>:
</p>
<pre><span>npm</span> install <span>--ignore-scripts=false</span> <i>package-name</i>
</pre>

<p>
EDIT: (Dec/27/2020) As suggested in the <a rel="noopener" target="_blank" href="https://news.ycombinator.com/item?id=25546460">Hacker News thread</a>:
</p>
<a id="-Makefile"></a>
<details>
<summary>
<h3>
Makefile
</h3>
</summary>
<pre><b>dev</b>:
	./make-dev.js
<b>test</b>:
	mocha <span>"src/**/*.test.js"</span>
<b>lint</b>:
	eslint src
<b>slint</b>:
	stylelint <span>"src/**/*.css"</span>

<b>prod</b>:
	sh -c 'time ./make-production.js'

<b>all</b>: test lint slint prod

<span>.PHONY: dev test lint slint prod all</span>
</pre>
<pre><span>make</span> <b>test</b>
</pre>
</details>
</article>
<article>
<hr>
<h2>Engineering Blog</h2>
<ul>
<li><a rel="noopener" href="https://blog.uidrafter.com/engineering/isolated-tls-certificate-creation">Isolated Creation of Let's Encrypt TLS Certificates</a></li>
<li><a rel="noopener" href="https://blog.uidrafter.com/engineering/bitwise-table-lookup">Bitwise Table Lookup</a></li>
<li><a rel="noopener" href="https://blog.uidrafter.com/engineering">More…</a></li>
</ul>
</article>
</div></div>]]>
            </description>
            <link>https://blog.uidrafter.com/engineering/getting-rid-of-npm-scripts</link>
            <guid isPermaLink="false">hacker-news-small-sites-25546460</guid>
            <pubDate>Sat, 26 Dec 2020 21:06:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mastering Pinterest SEO: An insider's guide]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 64 (<a href="https://news.ycombinator.com/item?id=25546430">thread link</a>) | @jmilinovich
<br/>
December 26, 2020 | https://blog.aesthetic.com/blog/pinterest-guide/ | <a href="https://web.archive.org/web/*/https://blog.aesthetic.com/blog/pinterest-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><div><div><div><p>Pinterest is an extraordinarily powerful tool for consumers, but is still misunderstood by marketers. I worked at Pinterest for 2 years helping build their core content understanding technology, and learned a lot about what makes for a successful Pinterest marketing strategy. I hope this guide helps demystify how marketers can get the most from Pinterest as a marketing channel. </p><p>If you have any questions, please <a href="https://twitter.com/intent/tweet?text=Hey%20@jmilinovich">Tweet @jmilinovich</a>! </p><ol><li><a href="#Why-is-Pinterest-marketing-important">Why is Pinterest marketing important?</a></li><li><a href="#How-does-Pinterest-marketing-work">How does Pinterest marketing work?</a></li><li><a href="#How-to-create-a-Pinterest-marketing-plan">How to create a Pinterest marketing plan?</a></li><li><a href="#How-to-make-Pinterest-pins">How to make Pinterest pins?</a></li><li><a href="#How-to-make-Pinterest-Pins-popular">How to make Pinterest Pins popular?</a></li><li><a href="#Conclusion">Conclusion</a></li></ol><h2>Pinterest as a distribution channel</h2><p>Pinterest is a powerful tool that helps people all over the world discover ideas for things to do in their lives. Whether it’s finding recipes, figuring out what to wear, finding new beauty tips or literally any other use case imaginable… people are doing it on Pinterest.</p><p>While search engines like Google focus on the bottom of the purchase funnel (ie, once someone knows that they have a need and are actively looking for it) and social networks like Facebook and Instagram focus on the top of the funnel (ie, when customers are passively looking to consume content with no intent), Pinterest is the only place on the internet that lets marketers reach consumer in the consideration phase. </p><p><img src="https://d33wubrfki0l68.cloudfront.net/2514c6be4877df4b7599580c5af4d1c3c2f54f86/453eb/img/posts/pinterest-guide/consideration.png" alt="The marketing consideration funnel"></p><p>This creates a big opportunity for businesses to get their products, goods and services in front of potential buyers while they’re deciding what they want to buy, but haven’t made the decision yet. That’s one of the most powerful things about Pinterest- people go there to find ideas, not just to make purchasing decisions. This means that marketers are able to reach consumers before they’ve made up their mind on what they’re looking to do.</p><h2>Pinterest as a source of inbound links</h2><p>While the most clear first-order effect to a strong Pinterest presence is creating a powerful new referral traffic source, there’s also a misunderstood but very powerful second-order effect: creating more inbound links to your website. </p><p>Have you noticed how no matter what you search for, it seems that you almost always see Pinterest results on the first page of Google? Pinterest’s core growth strategy has been about getting excellent at SEO, or search engine optimization. Practically speaking this means that the company has spent a lot of effort creating millions of high quality landing pages with the explicit purpose of being indexed by Google. Each of these landing pages shows dozens of Pins, and each contains a link to that Pin’s page on Pinterest. </p><p>As your content becomes more popular, it will begin showing up on more of Pinterest’s SEO pages, which means that it will be more readily indexed by Google. Since Google gives Pinterest’s domain a high authority and quality score, this means that over time you will start to accumulate some of this authority if your Pins are shown in prominent places. So, getting good at Pinterest doesn’t just help improve your Pinterest referral traffic, it can also improve your traffic from places like Google! </p><p><img src="https://d33wubrfki0l68.cloudfront.net/bbc3082cbd708936207fcc8fed30415b5077ee03/32add/img/posts/pinterest-guide/pinterest-results.png" alt="Example of Pinterest landing pages"></p><h2>Pinterest is a search engine</h2><p>The most important thing to understand about Pinterest is that at its core it’s a search engine, not a social network.  People don’t use Pinterest to “follow” specific brands but rather to follow interests and search for ideas. A “Pin” is simply a visual bookmark to a webpage, and under the hood Pinterest’s technology stack is focused on figuring out what interests a Pin is about, and which users are interested in which interests. Content on Pinterest isn’t temporal like other social networks, but evergreen like on Google.</p><h2>Help Pinterest understand your content</h2><p>This means that the most important thing to get right for Pinterest marketing is helping Pinterest understand what interests your Pins are about. This means that the key underlying concept for Pinterest marketing is to create Pins for all of your web content, and then make sure that Pinterest has a clear understanding of what interests they align to. </p><p>Once Pinterest understands what a given Pin is about, it can start showing it to users to see how they interact with it. If they engage with it (ie, Save it to one of their boards or Click on it to see the underlying content), Pinterest uses this as a positive sign that this is quality content and will begin showing it to more people. </p><p>As such, one of the most important things to get right is having a clear strategy for how to communicate to Pinterest what your Pins are about and getting engagement signals on the Pins early. </p><p><img src="https://d33wubrfki0l68.cloudfront.net/db6e047a9650880cd7f0be4c4718c0791790c2e0/18ef8/img/posts/pinterest-guide/pinterest-interests.png" alt="Example of Pinterest interests"></p><h2>Choose your Interests</h2><p>The most critical thing to get right in your Pinterest marketing plan is determining what Interests are most important to your business. There are <a href="https://docs.google.com/spreadsheets/d/1HxL-0Z3p2fgxis9YBP2HWC3tvPrs1hAuHDRtH-NJTIM/edit#gid=118370875">over 10,000 interests on Pinterest today</a>, ranging from highly broad to highly specific. Start by brainstorming what interests your target audience has today, as well as what interests your content is actually about. Look for the overlap of these two sets and choose the 10-15 that have the most promise to focus in on first. </p><h2>Create your Boards</h2><p>Once you’ve chosen the interests that you want to focus on, the next step is to decide on the architecture of your Pinterest for Business account. Pinterest accounts for users and businesses alike are defined by the boards that they create and post Pins to. You can think of a board as a folder of visual bookmarks that are public by default. When someone looks at your Pinterest account, the fastest way that they will understand what you’re about is by the names of the boards that you create. </p><p>Start by creating boards whose names are the same as the 10-15 interests you chose to focus on. It’s OK if they have more words in them as well, but make sure that the Interest name itself is very prominent. Make sure that each board has a very specific description that explains the core ideas that you’ll be pinning to the board.</p><p><img src="https://d33wubrfki0l68.cloudfront.net/dadf2e2890dde22bbff64a7ded8e0dcf6b592fe9/31afa/img/posts/pinterest-guide/boards.png" alt="Example of Pinterest boards"></p><p>Next, you need to decide what content to start posting onto these boards. </p><h2>Pinning existing content</h2><p>There are only two kinds of Pins on Pinterest: Pins from your own website, and Pins from other people’s websites. Both are equally important to a strong Pinterest strategy. The first thing you should do is to fill your boards with Pins that are already on Pinterest and were created by other people. Spend some time saving 20-30 Pins to each of your boards. As you do this, Pinterest will also begin recommending new Pins in your homefeed that are related to what you’ve been Pinning. </p><p>The reason you’re seeing the Pins that Pinterest is recommending to you is because Pinterest already knows a lot about them and has a high confidence that users like you will find them interesting. When you save them to your boards, you’re giving Pinterest even more signal about what your board is about. This is extremely important, because Pinterest learns a lot about new Pins based on the other Pins that it shows up on boards with. </p><p><img src="https://d33wubrfki0l68.cloudfront.net/a3580f834d291668bd22cae46f7854ddb0106853/de8da/img/posts/pinterest-guide/existing-pin.png" alt="Example of Pinterest pins"></p><p>Each week you should also continue to save new, existing content to your boards to keep giving Pinterest more signal and context for what your Pins are about. </p><h2>Pinning your own content</h2><p>Once you create a good base of existing Pins on your boards, you can start to plan your strategy for getting your own original content into Pinterest. First, go through all of your existing website content and map out what content would be relevant for the Pinterest audience. Generally speaking, the best content will be things like blog posts or eCommerce product landing pages. You should skip things like your homepage, about page, contact us page or other informational pages that don’t provide highly specific and useful content about a specific concept. </p><p>On social networks, it’s important that you have a steady pace of posting content into your feed so that you stay top of mind and also don’t inundate followers by posting 100 things at once. Pinterest is much more like Google, however, where you want them to know about your content upfront and all at once. </p><p>You should post all of your existing, relevant content to Pinterest upfront and then consistently add new content as it’s published online. Save it to the most relevant board to give Pinterest a clear understanding of what your content’s about. You can also post it to more than one board if it’s relevant to multiple categories. </p><p>The Pins that perform best on Pinterest have been created specifically for Pinterest following their <a href="https://business.pinterest.com/en-gb/content/creative-best-practices/">creative best practices</a>. Practically speaking this means that each Pin will require some editing work within a graphics editor tool. Generally speaking, each Pin can take anywhere from 5-20 minutes to create by hand if using a tool like Photoshop, Canva or Adobe Spark. This can be quite burdensome, especially if you’re trying to create dozens or hundreds of Pins for your site. </p><p><a href="https://www.aesthetic.com/?utm_source=blog&amp;utm_medium=post&amp;utm_campaign=pinterest-guide">Aesthetic’s software</a> is able to generate on-brand Pinterest Pins from a company’s website automatically. Simply enter a URL, and our app will create dozens of variations of graphics to promote that webpage, including several that follow Pinterest’s best practices guide. We’ve seen our users cut down the time it takes to create a Pin by 95% using our tool. </p><p>Once you’ve created your Pin graphics, you can upload them into the Pinterest system. Add the URL for each Pin along with a detailed description that touches upon what the Pins about and ideally mentions the specific interests that it’s related to. Post these to the right boards, and you’re off to the races! </p><p><img src="https://d33wubrfki0l68.cloudfront.net/4ab1dd02738de6695f0118fd169a78c4e10d21bb/09e8b/img/posts/pinterest-guide/aesthetic-pins.png" alt="Example of Pinterest pins made with Aesthetic"></p><p>Once you’ve uploaded your content to Pinterest, you will see the impressions slowly start to trickle in as the system understands more about what your content’s about. Generally speaking it can take months for new content on Pinterest to get enough exposure for Pinterest to determine whether it’s sufficiently interesting enough for it to be promoted more widely within the system.</p><p>Another option to fast track the distribution of your Pins is to run small budget ads for your own Pins, targeting the Interests that they’re related …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.aesthetic.com/blog/pinterest-guide/">https://blog.aesthetic.com/blog/pinterest-guide/</a></em></p>]]>
            </description>
            <link>https://blog.aesthetic.com/blog/pinterest-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25546430</guid>
            <pubDate>Sat, 26 Dec 2020 21:01:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fun with IP address parsing]]>
            </title>
            <description>
<![CDATA[
Score 491 | Comments 144 (<a href="https://news.ycombinator.com/item?id=25545967">thread link</a>) | @mr_tyzic
<br/>
December 26, 2020 | https://blog.dave.tf/post/ip-addr-parsing/ | <a href="https://web.archive.org/web/*/https://blog.dave.tf/post/ip-addr-parsing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
		<p><span>Written by</span>
        David Anderson
        <br>
        <span>on&nbsp;</span><time datetime="2020-12-25 00:00:00 +0000 UTC">December 25, 2020</time>
</p>
		


		

		<p>In my quest to write a fast IPv4+6 parser, I wrote a
slow-but-I-think-correct parser, to use as a base of comparison. In
doing so, I discovered more cursed IP address representations that I
was previously unaware of. Let’s explore together!</p>

<p>We start out simple, with IPv4 and IPv6 in what I’ll call their
“canonical form”: <code>192.168.0.1</code> and <code>1:2:3:4:5:6:7:8</code>. Various specs
call these “dotted quad” (more specifically, “dotted decimal”),
dot-separated fields each representing 1 byte; and “colon-hex”,
colon-separated fields each representing 2 bytes.</p>

<p>The first bits of complexity come from IPv6. In canonical form, common
addresses would end up with long runs of zeros in the middle. So, <code>::</code>
allows you to elide 1 or more 16-bit blocks of zeros: <code>1:2::3:4</code> means
<code>1:2:0:0:0:0:3:4</code></p>

<p>Next up, for cursed historical reasons, IPv6 permits you to write the
final 32 bits of the address in dotted quad form. Effectively, you can
splat an IPv4 address onto the end of IPv6 addresses!
<code>1:2:3:4:5:6:77.77.88.88</code> means <code>1:2:3:4:5:6:4d4d:5858</code>.</p>

<p>And of course, you can combine the two! <code>fe80::1.2.3.4</code> means <code>fe80:0:0:0:0:0:102:304</code></p>

<p>The existence of <code>::</code> introduces an annoying edge case in parsing: the
<code>::</code> can be at the start or end of the address, and the “empty” side
of the address is not one of the 16-bit fields. <code>::1</code> means
<code>0:0:0:0:0:0:0:1</code>, <code>1::</code> means <code>1:0:0:0:0:0:0:0</code>, and <code>::</code> means
<code>0:0:0:0:0:0:0:0</code>. This is a natural consequence of the <code>::</code> rule, but
it makes the parser slightly more annoying to write.</p>

<p>One final rule for IPv6: technically, each colon-hex field is 4 hex
digits, but you can elide leading zeros, as I’ve been doing so
far. Fully canonically, <code>::</code> is
<code>0000:0000:0000:0000:0000:0000:0000:0000</code>. My apologies to trypophobic
readers.</p>

<p>That’s it for IPv6, mostly. Now, on to IPv4!</p>

<p>Fun fact, the textual representation of IPv4 was never standardized in
any document before IPv6 needed a grammar for its weirdo “trailing
dotted quad” notation. So, it’s a de-facto standard that boils down to
mostly “what did 4.2BSD understand?”, and “what did other OSes keep
when they copied 4.2BSD?”</p>

<p>And hoo boy, strap yourselves in, because 4.2BSD sure had some whacky
opinions! Let’s use <code>192.168.140.255</code> as an example. That’s an IPv4
address that people would look at and go “yes, that sure is an IPv4
address.” How else can we write that exact same address?</p>

<p>This is the same IP address: <code>3232271615</code>. You get that by
interpreting the 4 bytes of the IP address as a big-endian unsigned
32-bit integer, and print that. This leads to a classic parlor trick:
if you try to visit <a href="http://192.168.140.255/">http://3232271615</a> , Chrome will load
<a href="http://192.168.140.255/">http://192.168.140.255</a>.</p>

<p>Okay, but that’s sort-of sensible, right? An IPv4 address is 4 bytes,
so printing it as a single number is a bit human-unfriendly, but
broadly plausible, right?</p>

<p>How about <code>0300.0250.0214.0377</code> ? That’s still the same
address. Dotted quad, except each field is written out in octal.</p>

<p>And if octal is supported, you might be wondering about hex. And you’d
be right! <code>192.168.140.255</code> is also <code>0xc0.0xa8.0x8c.0xff</code>, according
to 4.2BSD.</p>

<p>Now, remember before we had CIDR (Classless Inter-Domain Routing) ?
IPv4 addresses were Class A, Class B or Class C. It was a weird time.</p>

<p>And that weird time made it into IP addresses! The familiar
<code>192.168.140.255</code> notation is technically the “Class C” notation. You
can also write that address in “class B” notation as <code>192.168.36095</code>,
or in “Class A” notation as <code>192.11046143</code>. What we’re doing is
coalescing the final bytes of the address into either a 16-bit or a
24-bit integer field.</p>

<p>This, by the way, is why utilities like <code>ping</code> will accept weird
looking addresses like <code>127.1</code> for <code>127.0.0.1</code>. Unlike IPv6, it’s not
doing some kind of “missing fields are zero” expansion. <code>127.1</code> is the
Class A notation for “host 1 of network 127”, where the 1 is a 24-bit
number.</p>

<p>And finally, we come to one last bit of unspecified behavior: do IPv4
addresses permit an unlimited number of leading zeros in each quad? Or
is there a maximum of 3 digits? <code>001.002.003.004</code> is universally
recognized as valid. What about
<code>0000000001.0000000002.0000000003.000000004</code>?</p>

<p>You might also be wondering if either of these numbers should be read
in as octal, since we said earlier that a leading zero might be
interpreted as octal. It depends! There are implementations that do
both, but <em>most</em> modern implementations have abandoned the octal and
hex notation, and treat leading 0s as decimal.</p>

<p>The leading zero debate also infects IPv6, to some extent. Is
<code>000001::00001.00002.00003.00004</code> is a valid IPv6 address (“common”
form <code>1::1.2.3.4</code>, or <code>1::102:304</code>)? Most modern parsers seem to allow
an unlimited amount of leading zeros in their representations,
probably because they’re leaning on some “parse integer” library that
implements that behavior.</p>

<p>And so, we reach the bitter end. If you want to <em>truly</em> parse IP
addresses, this is the bullshit you have to put up with.</p>

<p>Currently, my slow reference parser jettisons a lot of old baggage,
and sticks to what I think is a sensible subset of these
possibilities. It understands:</p>

<ul>
<li>Classic v4 dotted decimal, with any number of leading zeros.</li>
<li>It does not process Class A/B notation, or hex or octal notation.</li>
<li>It does not process the “uint32 to the knee” representation.</li>
<li>For IPv6, it understands canonical colon-hex form, as well as ::
and trailing-IPv4 style (where the trailing IPv4 follows the same
rules as the previous tweet). Each field is allowed any number of
leading zeros.</li>
</ul>

<p>I’m on the fence about that last one, the “IPv6 with an embedded
dotted decimal” form. My reference parser (Go’s <code>net.ParseIP</code>)
understands it, but it’s not really that useful any more in the real
world. At the dawn of IPv6, the idea was that you could upgrade an
address to IPv6 by prepending a pair of colons, as in <code>::1.2.3.4</code>, but
modern transition mechanisms no longer offer anything as clear-cut as
this, so the notation doesn’t really show up in the wild.</p>

		
	</div>

	
</div></div>]]>
            </description>
            <link>https://blog.dave.tf/post/ip-addr-parsing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25545967</guid>
            <pubDate>Sat, 26 Dec 2020 19:56:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Partial order and non-Boolean logic]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25545543">thread link</a>) | @okaleniuk
<br/>
December 26, 2020 | https://wordsandbuttons.online/partial_order_and_non_boolean_logic.html | <a href="https://web.archive.org/web/*/https://wordsandbuttons.online/partial_order_and_non_boolean_logic.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	

	<p>
Numbers. Numbers are easy. All you need to know to sort them out is that
	</p>
	<ul>
	<li>
if 1 ≤ 2 and 2 ≤ 3 then 1 ≤ 3;
	</li>
	<li>
either 4 ≤ 5 or 5 ≤ 4...
	</li>
	<li>
...or both, but if 6 ≤ 6 and 6 ≤ 6 then 6 = 6.
	</li>
	</ul>
	<p>
Oh, shit! I forgot to put a smart face on. Let's start over.
	</p>
	<p>
A <b><span id="index_total_order">total order</span></b>, also known as <b><span id="index_linear_order">linear order</span></b> is a relation “≤” on a set <span>S</span>. For <span>a, b, c ∈ S</span>, the three properties hold.
	</p>
	<p>
The first one is called <b><span id="index_transitivity">transitivity</span></b>.
	</p>
	<p>
a ≤ b ∧ b ≤ c ⇒ a ≤ c.
	</p>
	<p>
The second one is <b><span id="index_connexity">connexity</span></b>.
	</p>
	<p>
a ≤ b ∨ b ≤ a
	</p>
	<p>
And the third one is <b><span id="index_antisymmetry">antisymmetry</span></b>.
	</p>
	<p>
a ≤ b ∧ b ≤ a ⇒ a = b
	</p>
	<p>
With rules established for <span>≤</span>, we can also tell either <span>a &lt; b</span> or <span>a &gt; b</span> or <span>a = b</span> for every <span>a</span> and <span>b</span>.
	</p>
	
	
<br>

<table>
<tbody><tr><th>Predicate</th><th>Result</th></tr>
<tr><td>a = b</td>		<td id="e"></td></tr>
<tr><td>a &lt; b</td>	<td id="l"></td></tr>
<tr><td>a &gt; b</td>	<td id="g"></td></tr>
<tr><td>a ≠ b</td>	<td id="ne"></td></tr>
<tr><td>a ≤ b</td>	<td id="le"></td></tr>
<tr><td>a ≥ b</td>	<td id="ge"></td></tr>
</tbody></table>
	<p>
Real numbers are comparable. That implies that you can sort them. Of course, not only numbers are comparable. Names are comparable and sortable in alphabetical order. Skyscrapers are comparable and sortable by height. A lot of things are comparable and sortable.
	</p>
	<p>
But a few things aren't. Like the <a href="https://wordsandbuttons.online/yet_another_alternative_to_floating_point_numbers.html">intervals, we use to represent numbers with errors</a>. We use them when we don't know the exact number <span>x</span> but we know its error <span>ε</span> and therefore have all the reasons to believe that it's jammed somewhere between <span>x<sub>1</sub></span> and <span>x<sub>2</sub></span> where
	</p>
	<p>
x<sub>1</sub> = x − ε
<br>
x<sub>2</sub> = x + ε
	</p>
	<p>
These intervals are helpful when we want to measure a computational error of some calculation or to see if some algorithm is stable enough. They aren't comparable or truly sortable though.
	</p>
	<p>
Consider two overlapping intervals. Let's say, <span>[3, 6]</span> and <span>[5, 8]</span>. We know that the fist interval actually means a number between  <span>3</span> and  <span>6</span>. The second — another number between <span>5</span> and <span>8</span>. Intuitively, the latter should be greater than the former. But what if it is  <span>5</span> and the former is  <span>6</span>? Then it's obviously less. There is a chance they are even equal. 
	</p>
	<p>
So there is some kind of order, for instance, <span>[6, 8]</span> is definitely greater than  <span>[3, 5]</span>. But this order doesn't hold for every possible pair of intervals.
	</p>
	<p>
This makes things unpleasant. For the very least, we can't now use binary logic since all the comparisons now return three states. E. g. <span>a ≤ b</span> can now be <span>true</span>, <span>false</span> or <span>none of the above</span>.
	</p>
	<p>
Consequently, this means the conventional <span>if... else</span> statement now has to be redesigned. And all the algorithms that use it.
	</p>
	<p>
We wouldn't have to give up binary logic completely if we agree to “split” the semantics of the predicates into two. For every predicate on the two intervals, we can still say whether the numbers they represent definitely suffice the predicate, or whether they possibly do so.
	</p>
	<p>
For instance, <span>[3, 5]</span> is definitely less than <span>[6, 8]</span>, and <span>[3, 6]</span> is possibly less than <span>[5, 8]</span>. The most unpleasant case for us is when intervals overlap. Everything is indefinite, and everything is possible then.
	</p>
<br>
	
	
<br>

<table>
<tbody><tr><th>Predicate</th><th>Deffinitely</th><th>Possibly</th></tr>
<tr><td>a = b</td>		<td id="de"></td>		<td id="pe"></td></tr>
<tr><td>a &lt; b</td>	<td id="dl"></td>		<td id="pl"></td></tr>
<tr><td>a &gt; b</td>	<td id="dg"></td>		<td id="pg"></td></tr>
<tr><td>a ≠ b</td>	<td id="dne"></td>	<td id="pne"></td></tr>
<tr><td>a ≤ b</td>	<td id="dle"></td>	<td id="ple"></td></tr>
<tr><td>a ≥ b</td>	<td id="dge"></td>	<td id="pge"></td></tr>
</tbody></table>

	<p>
Still, every <span>if... else</span> works. Within its semantics that is. However, the algebra behind the logic isn't yet Boolean. Now <span>¬ (a &lt; b) ≢ a ≥ b</span>. Computational algorithms may be technically built using the same building blocks as if the intervals were numbers but that's it.
	</p>

	<p>
Speaking of building stuff. Let's talk about programming. Programming non-Boolean interval logic in C++ or Python is fairly easy. You have to reimplement every predicate for the interval type — and you're golden!
	</p>
	<pre id="code_1">struct Interval {
    Number lb; // lower bound
    Number ub; // upper bound
}

// Interval-specific predicates.
bool coincide(const Interval&amp; l, const Interval&amp; r){
    return l.lb == r.lb &amp;&amp; l.ub == r.ub;
}

bool intersect(const Interval&amp; l, const Interval&amp; r){
    return (l.ub &gt;= r.lb &amp;&amp; l.lb &lt;= r.ub)
        || (r.ub &gt;= l.lb &amp;&amp; r.lb &lt;= l.ub);
}

// The "definite" interval logic.
// The relation should keep for every number in l and in r.
bool operator==(const Interval&amp; l, const Interval&amp; r){
    return l.lb == l.ub &amp;&amp; coincide(l, r);
}

bool operator&lt;(const Interval&amp; l, const Interval&amp; r){
    return l.ub &lt; r.lb;
}

bool operator&gt;(const Interval&amp; l, const Interval&amp; r){
    return r &lt; l;
}

bool operator&lt;=(const Interval&amp; l, const Interval&amp; r){
    return l.lb &lt; r.ub &amp;&amp; l.ub == r.lb;
}

bool operator&gt;=(const Interval&amp; l, const Interval&amp; r){
    return r &lt;= l;
}

bool operator!=(const Interval&amp; l, const Interval&amp; r){
    return r &lt; l || l &lt; r;
}</pre>
	<p>
Nobody cares about the relationship between predicates being Boolean-ish. They are all just some arbitrary functions so with them, you can easily define either the “definite” logic or the “possible” one. You can have both if you define them for different but interchangeable types. It's all a little verbose but doable.
	</p>
	<p>
It gets a little bit more tricky in Rust which relies on the notion of order pretty much.
	</p>
	<p>
The comparison operators for a custom type are usually introduced using an <a href="https://doc.rust-lang.org/std/cmp/trait.Ord.html">std::cmp::Ord</a> trait. It requires that:
	</p>
	<p>
∀ a, b: (a &lt; b) ⊕ (a = b) ⊕ (a &gt; b)
<br>
a ≤ b ∧ b ≤ c ⇒ a ≤ c.
	</p>
	<p>
The first reads as for every <span>a</span> and <span>b</span>, one and only one is true: either <span>(a &lt; b)</span> or <span>(a = b)</span> or <span>(a &gt; b)</span>. This doesn't work for us. When intervals intersect, in “definite” logic none of the predicates are true. And in the “possible” logic, they all are.
	</p>
	<p>
Luckily, there is another more relaxed trait that represents not total order, but <span id="index_partial_order">partial order</span>: <a href="https://doc.rust-lang.org/std/cmp/trait.PartialOrd.html">std::cmp::PartialOrd</a>. Which only requires <b><span id="index_asymmetry">asymmetry</span></b> (not even antisymmetry) and transitivity (we've seen it before):
	</p>
	<p>
a &lt; b ⇒ ¬(a &gt; b)
<br>
a ≤ b ∧ b ≤ c ⇒ a ≤ c.
	</p>
	<p>
Аnd for the “definite” logic, this works.
	</p>
	<pre id="code_2">impl std::cmp::PartialEq for RB32{
    // the same as operator == in C++ or __eq__(self, other) in Python
    fn eq(&amp;self, other: &amp;Self) -&gt; bool {
        self.lb == other.lb &amp;&amp; self.ub == other.ub
    }
}

impl std::cmp::PartialOrd for RB32{
    // this is usually enough to replace all the rest
    fn partial_cmp(&amp;self, other: &amp;Self) -&gt; Option&lt;std::cmp::Ordering&gt; {
        if self.ub &lt; other.lb {
            Some(std::cmp::Ordering::Less)
        } else if self.lb &gt; other.ub {
            Some(std::cmp::Ordering::Greater)
        } else if self.lb == other.lb &amp;&amp; self.ub == other.ub {
            Some(std::cmp::Ordering::Equal)
        } else {
            None // this is what differentiates Ord and PartialOrd
        }
    }

    // but since in out logic, (a &lt; b) ∨ (a = b) ≢ a ≤ b,
    // we have to define ≤ and ≥ explicitly.
    fn le(&amp;self, other: &amp;Self) -&gt; bool {
        (self.lb == other.lb &amp;&amp; self.lb == self.ub) ||
        (self.ub == other.ub &amp;&amp; other.lb == other.ub)
    }
    fn ge(&amp;self, other: &amp;Self) -&gt; bool {
        (self.ub == other.ub &amp;&amp; self.lb == self.ub) ||
        (self.lb == other.lb &amp;&amp; other.lb == other.ub)
    }
}</pre>

	<p>
The code is less verbose than in C++ or Python, and it would have been even less so if we were relying on Boolean algebra. With it, you don't even have to write <span>le</span> or <span>ge</span> methods explicitly, <span>cmp</span> is enough. With Boolean algebra, Rust can deduce the rest for you.
	</p>
	<p>
Ok, but that was the “definite” logic. But what about the “possible”?
	</p>
	<p>
I'm afraid, for this particular task, Rust comes short. In the “possible” interval logic, the intersecting intervals may be <span>a &lt; b</span>, and <span>a = b</span>, and <span>a &gt; b</span>, all at the same time. Every predicate is true since everything is possible. You can't program that with Rust <a href="https://doc.rust-lang.org/std/cmp/enum.Ordering.html">Ordering</a>. However, this is not a flaw, this is a design choice.
	</p>
	<p>
Non-Boolean logics are rare, and relations more general than partial order are almost never useful. If you really really want this kind of logic, you can still implement it using functions and not operators. At the same time, you can expect that if a class implements the <span>std::cmp::Ord</span> trait, then all the sorting algorithms will work with it correctly. While in C++, a sorting algorithm will run on anything with the <span>operator&lt;</span> reloaded with no correctness guaranteed or even pinky-promised.
	</p>
	<h2>
Conclusion
	</h2>
	<p>
Non-Boolean logics are rare but not extinct. Interval logic is one example. Sometimes, you can implement a logic you want within total order or partial order but sometimes even that isn't enough and you need an even more general relation. With operator overloading, you have the freedom to go there but you also have less assurance when working within the total order.
	</p>

	


	
	</div></div>]]>
            </description>
            <link>https://wordsandbuttons.online/partial_order_and_non_boolean_logic.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25545543</guid>
            <pubDate>Sat, 26 Dec 2020 19:02:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thermopolium found intact with food residues, animal bones]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25545160">thread link</a>) | @jdright
<br/>
December 26, 2020 | https://weirditaly.com/2020/12/26/extraordinary-discovery-in-pompeii-thermopolium-found-intact-with-food-residues-animal-bones/ | <a href="https://web.archive.org/web/*/https://weirditaly.com/2020/12/26/extraordinary-discovery-in-pompeii-thermopolium-found-intact-with-food-residues-animal-bones/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p><strong>The skeleton of a small dog and human remains were also found in the street food shop.</strong></p><p><strong>The Thermopolium of Regio V, one of the snack bars at Pompeii,&nbsp;&nbsp;</strong>complete with an image of a Nereid riding a sea-horse, which had previously been partially excavated in 2019,&nbsp;<strong>re-emerges in its entirety, with other rich decorative still lifes, food residues, animal bones and victims of the eruption.</strong></p><p><strong>Related articles:</strong> <a href="https://weirditaly.com/2014/03/13/30-amazing-pictures-of-pompeii/" data-type="post" data-id="35">30 Amazing pictures of Pompeii</a>, <a href="https://weirditaly.com/2018/05/30/archaeologists-found-in-pompeii-the-skeleton-of-a-man-fleeing-from-the-fury-of-the-volcano/" data-type="post" data-id="2824">Archaeologists found in Pompeii the skeleton of a man fleeing from the fury of the Volcano</a></p><p>According to the Massimo Osanna, director of the Archaeological Park Of Pompeii, the discovery “provides an incredible snapshot of the day of the eruption”.</p><div><figure><img title="Thermopolium-found-intact-with-food-residues-animal-bones-intro-1024x784 Extraordinary discovery in Pompeii: Thermopolium found intact with food residues, animal bones " src="https://weirditaly.com/wp-content/plugins/lazy-load/images/1x1.trans.gif" data-lazy-src="https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-intro-1024x784.jpg" loading="lazy" width="1024" height="784" alt="Weird Italy Thermopolium-found-intact-with-food-residues-animal-bones-intro-1024x784 Extraordinary discovery in Pompeii: Thermopolium found intact with food residues, animal bones Featured Italian History  Pompeii  " srcset="https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-intro-1024x784.jpg 1024w, https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-intro-300x230.jpg 300w, https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-intro-768x588.jpg 768w, https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-intro.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div><p>The commercial structure had only been partially studied in 2019, during the interventions of the Great Pompeii Project aimed at stabilizing and consolidating the historic excavation fronts.</p><p>Considering the exceptional nature of the decorations, and to restore the complete layout of the restaurant, which is located in the clearing between Vicolo delle Nozze d’Argento and Vicolo dei Balconi, it was decided to broaden the project and complete the excavation of the entire area.</p><div><figure><img title="Thermopolium-found-intact-with-food-residues-animal-bones-10 Extraordinary discovery in Pompeii: Thermopolium found intact with food residues, animal bones " src="https://weirditaly.com/wp-content/plugins/lazy-load/images/1x1.trans.gif" data-lazy-src="https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-10.jpg" loading="lazy" width="623" height="666" alt="Weird Italy Thermopolium-found-intact-with-food-residues-animal-bones-10 Extraordinary discovery in Pompeii: Thermopolium found intact with food residues, animal bones Featured Italian History  Pompeii  " srcset="https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-10.jpg 623w, https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-10-281x300.jpg 281w" sizes="(max-width: 623px) 100vw, 623px"></figure></div><p>In the small square in front of the&nbsp;<em>Thermopolium</em>,works had already revealed a cistern, a fountain and a water tower, which were all located a short distance from the shop which features the famed fresco of gladiators in combat.</p><figure><p> <iframe id="_ytid_79977" width="877.5" height="493" data-origwidth="877.5" data-origheight="493" src="https://www.youtube.com/embed/gg-DypTyY4M?enablejsapi=1&amp;autoplay=0&amp;cc_load_policy=0&amp;cc_lang_pref=&amp;iv_load_policy=1&amp;loop=0&amp;modestbranding=0&amp;rel=1&amp;fs=1&amp;playsinline=0&amp;autohide=2&amp;theme=dark&amp;color=red&amp;controls=1&amp;" title="YouTube player" allow="autoplay; encrypted-media" allowfullscreen="" data-no-lazy="1" data-skipgform_ajax_framebjll=""></iframe></p></figure><p>The decorations on the counter – which were the first to emerge during the excavation&nbsp; – comprise the image of a Nereid riding a sea-horse in a marine setting on the front, while the shorter side features an illustration which is probably of the shop itself, like a kind of trademark. It was not by chance that the discovery during the excavation of amphorae, located in front of the counter, reflected the painted image.</p><div><figure><img title="Thermopolium-found-intact-with-food-residues-animal-bones-3 Extraordinary discovery in Pompeii: Thermopolium found intact with food residues, animal bones " src="https://weirditaly.com/wp-content/plugins/lazy-load/images/1x1.trans.gif" data-lazy-src="https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-3.jpg" loading="lazy" width="498" height="543" alt="Weird Italy Thermopolium-found-intact-with-food-residues-animal-bones-3 Extraordinary discovery in Pompeii: Thermopolium found intact with food residues, animal bones Featured Italian History  Pompeii  " srcset="https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-3.jpg 498w, https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-3-275x300.jpg 275w" sizes="(max-width: 498px) 100vw, 498px"></figure></div><p>In this new phase of excavation, the last section of the counter to be unearthed revealed other exquisite scenes of still life, with depictions of animals which were likely butchered and sold here. Bone fragments belonging to the same animals were also discovered inside containers embedded in the counter, which held foodstuffs intended for sale, such as in the case of the&nbsp;<strong>two mallard ducks shown upside down</strong>, ready to be cooked and eaten;&nbsp;<strong>a rooster</strong>; and&nbsp;<strong>a dog on a lead</strong>, the latter serving almost as a warning in the manner of the famed&nbsp;<em>Cave Canem</em>.</p><p><strong>A mocking inscription can be found scratched&nbsp;</strong>onto the frame which surrounds the painting of the dog:&nbsp;<strong>NICIA CINAEDE CACATOR –&nbsp;</strong>literally<strong>&nbsp;“<em>Nicias</em></strong>(probably a freedman from Greece)&nbsp;<strong><em>Shameless Shitter!”&nbsp;</em></strong>This was probably left by a prankster who sought to poke fun at the owner, or by someone who worked in the&nbsp;<em>Thermopolium</em>.</p><div><figure><img title="Thermopolium-found-intact-with-food-residues-animal-bones-2 Extraordinary discovery in Pompeii: Thermopolium found intact with food residues, animal bones " src="https://weirditaly.com/wp-content/plugins/lazy-load/images/1x1.trans.gif" data-lazy-src="https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-2.jpg" loading="lazy" width="780" height="519" alt="Weird Italy Thermopolium-found-intact-with-food-residues-animal-bones-2 Extraordinary discovery in Pompeii: Thermopolium found intact with food residues, animal bones Featured Italian History  Pompeii  " srcset="https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-2.jpg 780w, https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-2-300x200.jpg 300w, https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-2-768x511.jpg 768w" sizes="(max-width: 780px) 100vw, 780px"></figure></div><p>“<em>As well as being another insight into daily life at Pompeii, the possibilities for study of this&nbsp;</em>Thermopolium&nbsp;<em>are exceptional, because for the first time an area of this type has been excavated in its entirety, and it has been possible to carry out all the analyses that today’s technology permits,”</em>&nbsp;–&nbsp;<strong>declares Massimo Osanna, Interim Director General of the Archaeological Park of Pompeii</strong>&nbsp;– “<em>the materials which have been discovered have indeed been excavated and studied from all points of view by an interdisciplinary team composed of professionals in the fields of physical anthropology, archaeology, archaeobotany, archaeozoology, geology and vulcanology. The finds will be further analysed in the laboratory, and in particular those remains found in the&nbsp;</em>dolia<em>&nbsp;(terracotta containers) of the counter are expected to yield exceptional data for informing an understanding of what was sold and what the diet was like”.</em></p><p>Another observation of note is the discovery of&nbsp;<strong>human bones</strong>, albeit found sadly dispersed as a result of the tunnels which were dug in the 17th century by illegal excavators, who were searching for precious objects.</p><div><figure><img title="Thermopolium-found-intact-with-food-residues-animal-bones Extraordinary discovery in Pompeii: Thermopolium found intact with food residues, animal bones " src="https://weirditaly.com/wp-content/plugins/lazy-load/images/1x1.trans.gif" data-lazy-src="https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones.jpg" loading="lazy" width="713" height="402" alt="Weird Italy Thermopolium-found-intact-with-food-residues-animal-bones Extraordinary discovery in Pompeii: Thermopolium found intact with food residues, animal bones Featured Italian History  Pompeii  " srcset="https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones.jpg 713w, https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-300x169.jpg 300w" sizes="(max-width: 713px) 100vw, 713px"></figure></div><p>Several belong to an individual of at least fifty years of age, who at the moment when the pyroclastic current arrived, was most likely on some kind of bed, as evidenced by the space set aside for storing the bed, and a series of nails and wood residues found under the body.</p><p>Other bones, which are yet to be investigated, belong to another individual, and were found inside a large&nbsp;<em>dolium,&nbsp;</em>possibly where they were placed by the first excavators.</p><p>Furthermore, in the&nbsp;<em>Thermopolium</em>,&nbsp;<strong>various pantry and transport materials&nbsp;</strong>were discovered, including:&nbsp;<strong>nine amphorae, a bronze patera, two flasks and a common ceramic table olla.&nbsp;</strong>The flooring of the entire room consisted of a layer of&nbsp;<em>cocciopesto&nbsp;</em>(a waterproof covering made of terracotta fragments), into which fragments of polychrome marble (alabaster,&nbsp;<em>portasanta</em>, green brecciaand bardiglio) were inserted in several areas.</p><p>The&nbsp;<em>Thermopolia</em>, where drinks and hot foods were served, (as indicated by the name of Greek origin), and stored in large&nbsp;<em>dolia&nbsp;</em>(jars) embedded in the masonry counter, were widespread in the Roman world, where it was typical to consume the&nbsp;<em>prandium</em>&nbsp;(the meal)outside the house. In Pompeii alone there are eighty of them.</p><div><figure><img title="Thermopolium-found-intact-with-food-residues-animal-bones-intro-400 Extraordinary discovery in Pompeii: Thermopolium found intact with food residues, animal bones " src="https://weirditaly.com/wp-content/plugins/lazy-load/images/1x1.trans.gif" data-lazy-src="https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-intro-400.jpg" loading="lazy" width="600" height="451" alt="Weird Italy Thermopolium-found-intact-with-food-residues-animal-bones-intro-400 Extraordinary discovery in Pompeii: Thermopolium found intact with food residues, animal bones Featured Italian History  Pompeii  " srcset="https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-intro-400.jpg 600w, https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-intro-400-300x226.jpg 300w" sizes="(max-width: 600px) 100vw, 600px"></figure></div><p><strong><em>THE INITIAL LABORATORY ANALYSIS</em></strong><strong><em>&nbsp;(Valeria Amoretti –&nbsp;</em></strong><strong><em>Anthropologist</em></strong><strong><em>)</em></strong></p><div><p>The first analyses confirm that the paintings on the counter depict, at least in part, the foodstuffs and drinks which were actually sold inside the&nbsp;<em>Thermopolium</em>. The paintings on the counter include two mallard ducks, and indeed a fragment of duck bone was in fact found inside one of the containers, alongside swine, goats, fish and land snails, indicating the great variety of products of animal origin used in the preparation of the dishes.</p><p>On the other hand, the first archaeobotanical analyses have allowed us to identify fragments of deciduous oak, which probably belonged to structural elements of the counter. At the bottom of a&nbsp;<em>dolium</em>&nbsp;– which has been identified as a container for wine on the basis of the bottle for drawing the liquid that was found inside it – the presence of beans was detected, which had been intentionally broken apart or ground. In his&nbsp;<em>De re Coquinaria&nbsp;</em>(I,5), Apicius explains the reason for this, asserting that they were used in order to modify the taste and colour of the wine, bleaching it.</p></div><p>The complete skeleton of a dog was found in the corner between the two doors of the&nbsp;<em>Thermopolium&nbsp;</em>(in the northwestern corner of the room). It was not a large and muscular dog like the one depicted on the counter, but an extremely small specimen, about 20-25cm high at the shoulder despite being an adult dog. Although quite rare, dogs of such small size indicate that intentional selection took place in the Roman age in order to obtain such a result.</p><p>Inside the room – and particularly behind the counter where they were dragged by the first excavators – a significant number of human bones were found, belonging to a mature-senescent individual, of at least 50 years of age. An initial analysis made it possible to link these dispersed bones with what remained of an individual who was discovered in the innermost corner of the shop, and who, at the time the pyroclastic current arrived, was most likely on top of some kind of bed, as evidenced by the space set aside for storing the bed, and a series of nails and wood residues found under the body.</p><p>The bones belonging to at least one other individual, which were discovered inside a large&nbsp;<em>dolium</em>, and were probably positioned in this way by the first excavators, are still to be investigated.</p><p>This is merely the initial macroscopic data yielded by the ongoing excavation, but it will surely not be the last. Indeed, the finds collected and brought to the laboratory will be analysed further, through specific studies in departments and universities with whom we have an agreement, which will allow us to further refine the data at our disposal, and therefore also our knowledge of the&nbsp;<em>Thermopolium&nbsp;</em>and the site.</p><p><a href="http://pompeiisites.org/" target="_blank" rel="noreferrer noopener">SOURCE</a></p></div></div>]]>
            </description>
            <link>https://weirditaly.com/2020/12/26/extraordinary-discovery-in-pompeii-thermopolium-found-intact-with-food-residues-animal-bones/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25545160</guid>
            <pubDate>Sat, 26 Dec 2020 18:08:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Adding BPF target support to the Rust compiler]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25545048">thread link</a>) | @lukastyrychtr
<br/>
December 26, 2020 | https://confused.ai/posts/rust-bpf-target | <a href="https://web.archive.org/web/*/https://confused.ai/posts/rust-bpf-target">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><section><div><article><div><p>When I created this blog back in September my goal was to post at least once
a month. It's December now and you're reading my second post, so I'm not exactly
off to a great start. 🤔</p><p>Things have been busy on the Rust BPF front though! At the end of October I
began working on a blog about the current state of things, exactly one year
after I started getting involved. While doing that I finally started feeling
inspired enough to try and add a BPF target to rustc, something that had been
on my todo list for a very long time but never managed to find the time to work
on.  (<em>Aah... if only someone wanted to sponsor all this work... wink wink!</em>)</p><p>A couple of weeks ago I finally sent a <a href="https://github.com/rust-lang/rust/pull/79608">pull request</a>
to get the new target(s) merged. The changes were pretty straightforward, with the
only unexpected thing being that I ended up having to write
<a href="https://github.com/alessandrod/bpf-linker">https://github.com/alessandrod/bpf-linker</a> - a partial linker needed to enable
rustc to output BPF bytecode.</p><p>I'm going to tell you why I had to write the linker in a moment, but first,
let's start with looking at how clang - the de facto standard BPF compiler -
compiles C code to BPF.</p><h2>How BPF projects are compiled with clang</h2><p>BPF doesn't have things like shared libraries and executables. Programs are
compiled as object files, then at run-time they're relocated and loaded in the
kernel where they get JIT-ted and executed.</p><p>Because of that, and because for a long time function calls were not allowed so
everything had to be inlined, BPF programs written in C are typically compiled
as a <strong>single compilation unit</strong>, with library code written in <a href="https://github.com/cilium/cilium/tree/master/bpf/lib">header
files</a> and included with
<code>#include</code> directives.</p><p><img alt="clang BPF compilation model" src="https://confused.ai/static/bpf-linker-clang.svg"></p><p>This compilation model is simple and effective: <strong>one compilation unit</strong> goes
in, <strong>one object file</strong> comes out. Because BPF programs tend to be small,
recompiling the whole source code on every change is generally not an issue.
Since everything gets compiled together, there's <strong>no need for linking</strong>
separate compilation artifacts. <em>(You see where this is going?)</em></p><h2>How Rust projects are compiled</h2><p>Rust uses a different compilation model. Code is split into crates. Crates
can't be lumped together with <code>#include</code> directives, they are always compiled
independently as <strong>one or more compilation units</strong>.</p><p>Consider the following example:</p><pre><code><span>alessandro@ubvm:~/src/app$ cargo tree
</span>app v0.1.0 (/home/alessandro/src/app)
<!-- -->└── dep v0.1.0 (/home/alessandro/src/dep)
<!-- -->
<!-- -->alessandro@ubvm:~/src/app$ cargo build
<!-- -->   Compiling dep v0.1.0 (/home/alessandro/src/dep)
<!-- -->   Compiling app v0.1.0 (/home/alessandro/src/app)
<!-- -->    Finished dev [unoptimized + debuginfo] target(s) in 0.19s
</code></pre><p><code>app</code> is an application crate that depends on a library <code>dep</code>. When building,
the following happens:</p><p><img alt="Rust compilation model" src="https://confused.ai/static/bpf-linker-rustc.svg"></p><p>The rust compiler is invoked twice: first to compile the <code>dep</code> crate as a rust
library, then to compile the <code>app</code> crate as an executable. When the <code>app</code> crate
is compiled, the <strong>pre-compiled</strong> <code>dep</code> crate is provided as input to the
compiler via the <code>--extern</code> option.</p><p>This compilation model always produces <strong>multiple object files</strong>, which then
must be <strong>linked</strong> together to produce the final output. The rust compiler uses an
internal linker abstraction, whose implementations spawn to external linkers
like <code>ld</code>, <code>lld</code>, <code>link.exe</code> and
<a href="https://doc.rust-lang.org/rustc/codegen-options/index.html#linker-flavor">others</a>.</p><p>Therefore, to add a new target with this model we need a linker for the target.
Since clang never links anything when targeting BPF though, it turns out that <code>lld</code> -
the LLVM linker - can't link BPF at all. So I wrote a new linker.</p><h2>A new (partial) BPF linker</h2><p><a href="https://github.com/alessandrod/bpf-linker">bpf-linker</a> takes LLVM bitcode as
input, optionally applies target-specific optimizations, and outputs a single
BPF object file. The inputs can be bitcode files (<code>.bc</code>), object files
with embedded bitcode (eg <code>.o</code> files produced compiling with
<a href="https://doc.rust-lang.org/rustc/codegen-options/index.html#embed-bitcode">-C embed-bitcode=yes</a>),
or archive files (<code>.a</code> or <code>.rlib</code>).</p><p>The linker works with anything that can output LLVM bitcode, including clang.
There are a couple of reasons for taking bitcode as input instead of object
files.</p><p>Only a subset of Rust (just like only a subset of C) can be compiled to BPF
bytecode. Therefore bpf-linker tries to push code generation as late as
possible in the compilation process, after link-time optimizations have been
applied and dead code has been eliminated. This avoids hitting potential
failures generating bytecode for unsupported Rust code that is actually
unused (eg, parts of the <code>core</code> crate that are never used in a BPF context).</p><p>Another reason is that the linker might need to apply extra optimizations like
<a href="https://github.com/alessandrod/bpf-linker/blob/d890b113ffe612dcba51cc7d23a14fabd8198318/src/bin/bpf-linker.rs#L104">--unroll-loops</a>
and
<a href="https://github.com/alessandrod/bpf-linker/blob/d890b113ffe612dcba51cc7d23a14fabd8198318/src/bin/bpf-linker.rs#L108">--ignore-inline-never</a>
when targeting older kernel versions that don't support loops and calls.</p><h2>Not one but two BPF targets!</h2><p>The rustc fork at <a href="https://github.com/alessandrod/rust/tree/bpf">https://github.com/alessandrod/rust/tree/bpf</a> includes two new
targets, <code>bpfel-unknown-none</code> and <code>bpfeb-unknown-none</code> which generate little
endian and big endian BPF respectively. The targets automatically invoke
bpf-linker so with that fork, compiling a BPF project with Rust is finally as
easy as:</p><pre><code><span>alessandro@ubvm:~/src/app$ cargo build --target=bpfel-unknown-none
</span>   Compiling dep v0.1.0 (/home/alessandro/src/dep)
<!-- -->   Compiling app v0.1.0 (/home/alessandro/src/app)
<!-- -->    Finished dev [unoptimized + debuginfo] target(s) in 1.98s
<!-- -->alessandro@ubvm:~/src/app$ file target/bpfel-unknown-none/debug/app
<!-- -->target/bpfel-unknown-none/debug/app: ELF 64-bit LSB relocatable, eBPF, version 1 (SYSV), not stripped
</code></pre><p>Getting the targets merged will probably take a while, but worry not! With a
little trick, you can use the linker to <em>compile BPF code with stable Rust
already today!</em></p><p>I made bpf-linker implement a <code>wasm-ld</code> compatible command line. Since rustc
already knows how to invoke <code>wasm-ld</code> when targeting webassembly, it can be
made to use <code>bpf-linker</code> with the following options:</p><pre><code><span>alessandro@ubvm:~/src/app$ cargo rustc -- \
</span>        -C linker-flavor=wasm-ld \
<!-- -->        -C linker=bpf-linker \
<!-- -->        -C linker-plugin-lto 
<!-- -->   Compiling dep v0.1.0 (/home/alessandro/src/dep)
<!-- -->   Compiling app v0.1.0 (/home/alessandro/src/app)
<!-- -->    Finished dev [unoptimized + debuginfo] target(s) in 0.68s
<!-- -->alessandro@ubvm:~/src/app$ file target/debug/app
<!-- -->target/debug/app: ELF 64-bit LSB relocatable, eBPF, version 1 (SYSV), not stripped
</code></pre><p>Let's see what those options do:</p><ul><li><a href="https://doc.rust-lang.org/rustc/codegen-options/index.html#linker-flavor">-C linker-flavor=wasm-ld</a>
tells the compiler that the linker supports the same command line options as <code>wasm-ld</code></li><li><a href="https://doc.rust-lang.org/rustc/codegen-options/index.html#linker">-C linker=bpf-linker</a>
configures bpf-linker as the linker to spawn</li><li><a href="https://doc.rust-lang.org/rustc/linker-plugin-lto.html#linker-plugin-lto">-C linker-plugin-lto</a>
tells rustc to pass LLVM bitcode to the linker</li></ul><p>And voilà! Go compile some BPF with stable rust now 🎉</p><h2>What's next</h2><p>bpf-linker is obviously new and needs more testing. Over the next few weeks I'm
going to add more unit tests and try it on more Rust code. I'm also thinking of
trying to link the whole Cilium BPF code with it just to test with a large,
complex code base.</p><p>While working on the rustc target, at some point I went off on a bit of a
tangent and ended up making some changes to LLVM and the kernel so I'm going to
try and finish those off. They are needed to implement the
<a href="https://llvm.org/docs/LangRef.html#llvm-trap-intrinsic">llvm.trap</a> intrinsic
so <code>panic!()</code> can be implemented in a generic way, instead of having to resort
to program-specific hacks like jumping to an empty program with
<code>bpf_tail_call()</code>. I'll probably do a whole separate post about that.</p><p>Finally, after my <a href="https://confused.ai/posts/intercepting-zoom-tls-encryption-bpf-uprobes">last post</a> I
received some truly great feedback! I was especially pleased to hear from a
couple of companies that are using BPF and that are considering using it with
Rust.</p><p>I was equally pleased to see that there's a group of people developing BPF in C
that feel strongly that I'm wasting my time and that Rust brings nothing over
C, being BPF statically verified, not needing the borrow checker etc.  They gave
me inspiration for a post I'm hoping to publish soon, which will cover why I
think that Rust has the potential to become as central to the BPF ecosystem as it
is central to WebAssembly development today. Until next time!</p></div></article></div></section></div></div>]]>
            </description>
            <link>https://confused.ai/posts/rust-bpf-target</link>
            <guid isPermaLink="false">hacker-news-small-sites-25545048</guid>
            <pubDate>Sat, 26 Dec 2020 17:53:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What’s the best non-smart TV sold today?]]>
            </title>
            <description>
<![CDATA[
Score 220 | Comments 257 (<a href="https://news.ycombinator.com/item?id=25544831">thread link</a>) | @thomas
<br/>
December 26, 2020 | https://helpatmyhome.com/best-non-smart-tv/ | <a href="https://web.archive.org/web/*/https://helpatmyhome.com/best-non-smart-tv/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main id="genesis-content"><article aria-label="What’s The Best Non-Smart TV Sold Today?"><div itemprop="text">
<p>With the industry-wide transition to smart TVs many of us have felt like there is no option but to get one. And the walls are closing in — it seems like almost every TV sold today is a smart one, which means a lack of control of what’s happening on our device, the possibility of the company deciding one day to show us ads (as Samsung as done), and the certainty that our viewing and usage data is being sent off to all sorts of third parties. </p>



<p>The solution? Buy a dumb TV!</p>



<h2><span id="What_Is_A_Dumb_TV">What Is A Dumb TV?</span></h2>



<p>The alternative to Smart TVs are, of course, non-smart TVs or, as people have taken to calling them, dumb TVs. These are televisions without an internet connection, without built-in HBO Max or Disney, without Amazon Alexa, and lacking apps of any kind. A dumb TV is the television equivalent of a flip phone. </p>



<p>Just because your TV is dumb doesn’t mean you can’t use Roku or Apple TV, etc. In this case you are simply opting to plug those devices into your TV via HDMI rather than having them built in. In almost all cases the plugged in device is better than having the software version built into your TV, so you are making your TV be smart instead of being forced to have one. </p>



<h2><span id="Why_Not_Buy_An_Old_TV">Why Not Buy An Old TV?</span></h2>



<p>You can definitely buy an old TV to solve this problem instead of hunting around for an increasingly rare non-smart in 2021. Televisions age pretty well, so as long as you can find something relatively high quality and made in the last 8 (or so) years you are good to go. </p>



<p>You’ll mainly need to ensure that your older model is in good physical condition, has enough HDMI ports to suit a current user, has no burn-in or wear issues, has a working remote, doesn’t have cracked or wrecked speakers, and that the color hasn’t gone crazy over time. You’ll also want to make sure your TV is an LED TV, so it’s power efficient and looks great, instead of using an outdated technology (like plasma). </p>



<p>For example, I have a Samsung dumb TV from 2012 (or so) that works perfectly well, has sufficient volume, and completely gets the job done. It was a good TV when I bought it, and it’s a great TV now, because it doesn’t have any of the features that I don’t want — and can’t avoid — today. </p>



<h2><span id="Just_Dont_Connect_It_To_the_Internet">Just Don’t Connect It To the Internet</span></h2>



<p>A smart TV can’ the smart without an internet connection so one thing you can do to get a dumb TV is to simply not connect it to your WiFi network. Your TV will will work since it’s connect through coax but the rest of the data cannot flow because the television doesn’t have an internet connection!</p>



<p>You can then go ahead and add a Nvidia Shield or Apple TV and connect that to the internet. This way the auxiliary devices will have internet connection <em>while you are using them</em>, but the TV itself (the hypervisor in this scenario) stays blissfully unaware of that internet connection. </p>



<p>Note, there have been scattered reports of some TVs, including those from Samsung, simply searching for open WiFi signals and attempting to connect to them, but this is an extreme and user-hostile example that hopefully won’t be repeated (assuming its true in the first place).</p>



<p>Some smart TV will force you to connect them to the internet for firmware updates and will resort to frequent nagging to get you to do this, but very few will force you to do it or not work entirely without the connection (yet). </p>



<h2><span id="Best_Dumb_TVs">Best Dumb TVs</span></h2>



<p>Here are some intelligent picks in non-smart TVs. </p>



<figure><img loading="lazy" src="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter-1024x606.jpg" alt="" width="433" height="256" srcset="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter-1024x606.jpg 1024w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter-350x207.jpg 350w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter-768x454.jpg 768w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter-1536x908.jpg 1536w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter.jpg 1782w" sizes="(max-width: 433px) 100vw, 433px"></figure><h2><span id="Sceptre_50-inch_4K_LED_TV">Sceptre 50-inch 4K LED TV</span></h2>



<p>Sceptre has generally been considered a mid-tier TV company, but they have done a good job of not transitioning entirely to Smart TVs. The <a href="https://amzn.to/3mZUDAp" target="_blank" rel="noreferrer noopener nofollow external" title="https://amzn.to/3mZUDAp" data-wpel-link="external">Sceptre U518CV-UM</a> is a 50-inch 4K that’s completely non-smart TV that is from the 2019 model year, so you are getting recent tech without the connectivity features that you don’t want.</p>



<ul><li>4K Television (3840×2160, UHD resolution)</li><li>Dimensions: 44.6 x 28.5 x 10.8 inches</li><li>Weight: 29.3 pounds</li></ul><p>Sceptre has the same non-smart TV in larger sizes as well, <a href="https://amzn.to/2VGHSyD" target="_blank" rel="noreferrer noopener nofollow external" title="https://amzn.to/2VGHSyD" data-wpel-link="external">up to 65-inches</a> if you need the extra size or have a big room to fill. </p>



<div><figure><img loading="lazy" src="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/insing-1024x622.jpg" alt="" width="341" height="207" srcset="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/insing-1024x622.jpg 1024w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/insing-350x213.jpg 350w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/insing-768x466.jpg 768w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/insing.jpg 1258w" sizes="(max-width: 341px) 100vw, 341px"></figure></div>



<h3><span id="Insignia_55-inch_Class_LED">Insignia 55-inch Class LED</span></h3>



<p>If you live near a Best Buy then you will have access to their house brand, Insignia. The Insignia 55-inch (NS-55D420NA20) is a LED-lit 1080p television that sells for about $300. It’s devoid of smart features but it has three HDMI ports and was first released in 2019. </p>



<p>This line of Insignia dumb TVs is sold from 19 inches up to 58 inches so there will be a TV for every room size. </p>



<div><figure><img loading="lazy" src="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/smasungbuns-1024x625.jpg" alt="" width="451" height="275" srcset="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/smasungbuns-1024x625.jpg 1024w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/smasungbuns-350x214.jpg 350w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/smasungbuns-768x469.jpg 768w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/smasungbuns.jpg 1170w" sizes="(max-width: 451px) 100vw, 451px"></figure></div>



<h2><span id="Samsung_Business_BER_43-Inch">Samsung Business BER 43-Inch </span></h2>



<p>This <a href="https://amzn.to/2VFc4di" target="_blank" rel="noreferrer noopener nofollow external" title="https://amzn.to/2VFc4di" data-wpel-link="external">Samsung Business line TV</a> (model BE43R) is a full HD (1080p) LED TV that is part of Samsung’s commercial line, but doesn’t have the crazy price tag to reflect it. Commercial TV’s can get super experience for what seems like a normal TV — and for what will function like a normal TV if you are simply using it like one! The smartest feature this TV has is the ability to play images from a USB stick.</p>



<p>This TV has all the features you’d expect from a normal television, like HDMI input, and isn’t missing anything obvious. For example it still has integrated speakers and 1080p (1920×1080) resolution.</p>



<p>If you are open to commercial TVs there <a href="https://amzn.to/3gdIm8R" target="_blank" rel="noreferrer noopener nofollow external" title="https://amzn.to/3gdIm8R" data-wpel-link="external">are a huge number to explore</a>.</p>



<h2><span id="Dumb_TV_Alternatives">Dumb TV Alternatives</span></h2>



<p>Of course there are other ways to avoid a smart TV. Here are some bright ideas…</p>



<ul><li><strong>Projector:</strong> The smart device revolution has really come to projectors yet, so you can watch your TV and movies through a projector without having to worry about your privacy or ads</li><li><strong>Monitor:</strong> Computer monitors haven’t gotten smart (since they are connected to something smart) so if you watch television on a computer monitor you’ll have no need to worry about built-in Alexa or Google Home</li><li><strong>Business TV (aka Commercial Display):</strong> A <a href="https://www.neweggbusiness.com/s/commercial-tvs/id-3672" target="_blank" rel="noreferrer noopener nofollow external" title="https://www.neweggbusiness.com/s/commercial-tvs/id-3672" data-wpel-link="external">business-focused TV</a> (something you’d see hung in an office or airport and playing CNN all day on mute) is designed for simplicity and long-lasting performance. These haven’t yet gotten smart and will likely stay dumb for years as they need to have error- and update-free operation for years on end</li><li><strong>Outdoor TV:</strong> For some reason outdoor and weatherproof televisions have yet to go smart. Here is a <a href="https://amzn.to/3lMr0B0" target="_blank" rel="noreferrer noopener nofollow external" title="https://amzn.to/3lMr0B0" data-wpel-link="external">good example of one from Furrion</a>.</li></ul><h2><span id="FAQs">FAQs</span></h2>


<div><ol><li><strong>Can I use PiHole or a similar device to block the ads and privacy leaks from my smart TV?</strong><p>You'd think this would work, but manufacturers have gotten wise to the PiHole and other methods of blocking tracking and advertising injection so, no, you really can't. At this point many manufacturers will take measures like building ads into the core technology of their software so blocking ads will break other features. Also many manufacturers will hardcode their DNS to their preferred vendor, not allowing you to override their option with your PiHole. </p></li></ol></div></div></article></main></div></div></div>]]>
            </description>
            <link>https://helpatmyhome.com/best-non-smart-tv/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25544831</guid>
            <pubDate>Sat, 26 Dec 2020 17:26:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is PHP still relevant in 2021?]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25544627">thread link</a>) | @karakanb
<br/>
December 26, 2020 | https://saasstarterkit.app/blog/is-php-still-relevant-2021 | <a href="https://web.archive.org/web/*/https://saasstarterkit.app/blog/is-php-still-relevant-2021">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main" role="main">
<div>
<article>

<figure>
</figure>
<section>
<div>
<p>As one of the poster childs for bad programming languages, PHP has always been in the top 5 “worst programming languages”; however, as of 2021, is that still a thing?</p>

<p>PHP was developed by <a href="https://en.wikipedia.org/wiki/Rasmus_Lerdorf">Rasmus Lerdorf</a> in 1994. Lerdorf developed a bunch of scripts to track the visits to his online resume, and named them as “Personal Home Page Tools”, which then evolved into being called as “PHP Tools”. He kept adding more tools to this suite, and at some point pulled off a rewrite of the tools, including added functionality for database interactions and more, turning it into a more complete framework. From that point on, the tools have evolved into a more complex primitives and kept gaining more users after it is <a href="https://groups.google.com/g/comp.infosystems.www.authoring.cgi/c/PyJ25gZ6z7A/m/M9FkTUVDfcwJ?pli=1">open-sourced</a> in 1995. A more detailed history of the language can be found in <a href="https://www.php.net/manual/en/history.php.php">the official PHP website</a>.</p>
<p>As of now, the latest version of the PHP language is 8.0.</p>

<p>The language has had a target on its back for years now, and people are rightfully calling out the bad taste they have with the language, especially with the older versions. The language has been developed with the intention of being a templating language, rather than being a full-blown programming language; therefore, there are some downsides with it that made it especially harder to maintain larger apps.</p>
<h2 id="weak-typing">Weak Typing</h2>
<p>One part of the language that I personally dislike is the weak typing that allows combining different types and casts them implicitly. Consider the following example:</p>
<div><div><pre><code><span>echo</span> <span>"1"</span> <span>+</span> <span>3</span><span>;</span>
<span>echo</span> <span>1</span> <span>+</span> <span>"3"</span><span>;</span>
<span>echo</span> <span>"1"</span> <span>+</span> <span>"3"</span><span>;</span>
</code></pre></div></div>
<p>The results of all these operations are <code>4</code>, which means the language casts the numbers in the string to integers in the context of the addition operator. This might be desirable in some cases or it might save a few lines of code here and there, but the larger a project gets, the harder it becomes to maintain it.</p>
<p>The more recent versions of the language have started introducing warnings for these kinds of weird and invalid operations, which means that they are either deprecated or already on their way to be deprecated.</p>
<h2 id="lack-of-namespaces">Lack of Namespaces</h2>
<p>The support for namespaces has been introduced in PHP by the version 5.3, which means that all the older projects have had to build their own kind of namespacing, which usually relied on adding namespaces to the class and method names, requiring absurdly long names everywhere. For projects that were developed with the prior versions, it is very common to see classes named like <code>Payments_Provider_ProcessorProvider_SomeExternalServiceProvider</code> whereas it could have been named like <code>SomeExternalServiceProvider</code> simply. This results in very verbose code in most of the cases, and it makes it harder to read and skim through the code.</p>
<p>The more recent versions of the language doesn’t have this problem though.</p>
<h2 id="inconsistent-standard-library-functions">Inconsistent Standard Library Functions</h2>
<p>I am not saying the standard library of the language is bad, but one could argue that it could have been better. To be fair, the language has been improving quite a lot, but the early versions of the standard library, which is already being used, referenced and supported due to backwards compatibility results, were lacking consistency. Although a small disturbance, this meant that many of the standard library functions had different naming conventions, argument names and ordering, making it harder to assume the defaults and the behavior.</p>
<p>Here are some naming inconsistencies with the string methods:</p>
<ul>
<li><a href="https://www.php.net/manual/en/function.strpos.php"><code>strpos(string $haystack, string $needle, int $offset = 0): int|false</code></a>: Find the position of the first occurrence of a substring in a string.</li>
<li><a href="https://www.php.net/manual/en/function.str-split.php"><code>str_split(string $string, int $length = 1): array</code></a>: Convert a string to an array.</li>
<li><a href="https://www.php.net/manual/en/function.explode.php"><code> explode(string $separator, string $string, int $limit = PHP_INT_MAX): array</code></a>: Split a string by a string.</li>
</ul>
<p>Three different functions, one with a <code>str</code> prefix, another with <code>str_</code> prefix, and the third with no prefix. The <code>$string</code> argument is the first argument for <code>str_split</code>, but the second one for the <code>explode</code> one. You can check out all the string methods <a href="https://www.php.net/manual/en/ref.strings.php">in the documentation</a>, and each of these patterns have many functions following similar patterns, meaning that there is not much of a consistency with these functions.</p>
<h2 id="superglobals">Superglobals</h2>
<p>More of personal choice, but I hate the use of the globals, and consequently <a href="https://www.php.net/manual/en/language.variables.superglobals.php">superglobals</a>. Especially if you run into some home-baked old projects, it is highly likely that you’ll run into the famous variables like <code>$_SERVER</code> or <code>$_REQUEST</code>. Don’t get me wrong, these are very helpful sometimes and will need to be used eventually; however, encapsulating these into reusable classes should be done as one of the first steps in order to be able to use these values safely. If not, touching these values or doing any change in a slightly larger project gets a very complicated experience where there are many hidden dependencies on these values.</p>

<p>Even though it had left a bad taste in many people’s mouth, the language itself has been improving quite a lot in the last few years. With the release of PHP 7, the language has gone through a modernization process where many nice features were introduced to the language basics, the speed was improved, and the usability has increased quite a lot.</p>
<h2 id="type-hints">Type-hints</h2>
<p>This is one of my favorite ways of modernizing legacy PHP code: using non-enforced type-hints that handle type casting as well as providing documentation for the code. Check out the following simple function:</p>
<div><div><pre><code><span>function</span> <span>isValueSomething</span><span>(</span><span>$value</span><span>)</span> <span>{}</span>
</code></pre></div></div>
<p>If you include the type hints, it becomes something like this:</p>
<div><div><pre><code><span>function</span> <span>isValueSomething</span><span>(</span><span>string</span> <span>$value</span><span>)</span><span>:</span> <span>bool</span> <span>{}</span>
</code></pre></div></div>
<p>Just by looking at the signature, we are able to tell it expects a string value, and it will return a boolean result. One could claim that the naming convention could have been useful here as well, but these type-hints reassure that the values will be of those types, as well as giving the IDE a lot of power for auto-complete and static analysis with warnings and stuff.</p>
<p>Since PHP 7.4, PHP allows defining typed properties for classes as well:</p>
<div><div><pre><code><span>class</span> <span>Person</span> <span>{</span>
    <span>public</span> <span>string</span> <span>$firstName</span><span>;</span>

    <span>public</span> <span>string</span> <span>$lastName</span><span>;</span> 

    <span>public</span> <span>int</span> <span>$age</span><span>;</span>

    <span>public</span> <span>?</span><span>string</span> <span>$job</span><span>;</span>
<span>}</span>
</code></pre></div></div>
<p>This means your <code>Person</code> objects will have string first and last names, an integer age, and a nullable string value for the job. Being able to define this becomes very useful the more classes you have.</p>
<h2 id="syntax-improvements">Syntax Improvements</h2>
<p>PHP now has bunch of syntactical improvements:</p>
<ul>
<li><a href="https://www.php.net/manual/en/functions.arrow.php">Arrow functions</a>: <code>fn ($x, $y) =&gt; $x + $y;</code></li>
<li>Null coalescing operator: <code>$value = $array['key'] ?? 'default value';</code></li>
<li>Null coalescing assignment: <code>return $cache['key'] ??= computeSomeValue('key')</code>;</li>
<li>Array spreading: <code>$first = ['a', 'b']; $second = ['c', 'd']; $final = [...$first, ...$second];</code></li>
<li><a href="https://www.php.net/manual/en/functions.arguments.php#functions.named-arguments">Named arguments</a>: <code>array_fill(start_index: 0, num: 100, value: 50);</code></li>
<li>Numeric literal separator: <code>299_792_458</code></li>
</ul>
<p>In addition to these syntactical improvements, it also includes stuff for more complex improvements.</p>
<h3 id="constructor-promotion"><a href="https://www.php.net/manual/en/language.oop5.decon.php#language.oop5.decon.constructor.promotion">Constructor Promotion</a></h3>
<p>Look at the following Person class:</p>
<div><div><pre><code><span>class</span> <span>Person</span> <span>{</span>
    <span>private</span> <span>string</span> <span>$firstName</span><span>;</span>

    <span>private</span> <span>string</span> <span>$lastName</span><span>;</span> 

    <span>protected</span> <span>int</span> <span>$age</span><span>;</span>

    <span>public</span> <span>?</span><span>string</span> <span>$job</span><span>;</span>

    <span>public</span> <span>function</span> <span>__construct</span><span>(</span>
        <span>string</span> <span>$firstName</span><span>,</span>
        <span>string</span> <span>$lastName</span><span>,</span>
        <span>int</span> <span>$age</span><span>,</span>
        <span>?</span><span>string</span> <span>$job</span>
    <span>){</span>
        <span>$this</span><span>-&gt;</span><span>firstName</span> <span>=</span> <span>$firstName</span><span>;</span>
        <span>$this</span><span>-&gt;</span><span>lastName</span> <span>=</span> <span>$lastName</span><span>;</span>
        <span>$this</span><span>-&gt;</span><span>age</span> <span>=</span> <span>$age</span><span>;</span>
        <span>$this</span><span>-&gt;</span><span>job</span> <span>=</span> <span>$job</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>
<p>Instead of having this unnecessarily verbose code, PHP 8 supports writing the following code:</p>
<div><div><pre><code><span>class</span> <span>Person</span> <span>{</span>
    <span>public</span> <span>function</span> <span>__construct</span><span>(</span>
        <span>private</span> <span>string</span> <span>$firstName</span><span>,</span>
        <span>private</span> <span>string</span> <span>$lastName</span><span>,</span>
        <span>protected</span> <span>int</span> <span>$age</span><span>,</span>
        <span>public</span> <span>?</span><span>string</span> <span>$job</span>
    <span>){}</span>
<span>}</span>
</code></pre></div></div>
<h3 id="nullsafe-operator"><a href="https://www.php.net/manual/en/language.oop5.basic.php#language.oop5.basic.nullsafe">Nullsafe Operator</a></h3>
<p>This is something that had existed in some other languages like Javascript but PHP didn’t have the support for this. Take a look at the following code which I grabbed from the PHP docs:</p>
<div><div><pre><code><span>if</span> <span>(</span><span>is_null</span><span>(</span><span>$repository</span><span>))</span> <span>{</span>
    <span>$result</span> <span>=</span> <span>null</span><span>;</span>
<span>}</span> <span>else</span> <span>{</span>
    <span>$user</span> <span>=</span> <span>$repository</span><span>-&gt;</span><span>getUser</span><span>(</span><span>5</span><span>);</span>
    <span>if</span> <span>(</span><span>is_null</span><span>(</span><span>$user</span><span>))</span> <span>{</span>
        <span>$result</span> <span>=</span> <span>null</span><span>;</span>
    <span>}</span> <span>else</span> <span>{</span>
        <span>$result</span> <span>=</span> <span>$user</span><span>-&gt;</span><span>name</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>
<p>This was how the logic would be written with the older PHP versions with respect to null-checks. The new nullsafe operator allows converting this to simply:</p>
<div><div><pre><code><span>$result</span> <span>=</span> <span>$repository</span><span>?-&gt;</span><span>getUser</span><span>(</span><span>5</span><span>)</span><span>?-&gt;</span><span>name</span><span>;</span>
</code></pre></div></div>
<p>Isn’t it gorgeous?</p>
<h3 id="union-types"><a href="https://www.php.net/manual/en/language.types.declarations.php#language.types.declarations.union">Union Types</a></h3>
<p>Even though this is a less favorite feature of mine, it is still valuable for the cases where there is already multiple possible types and we don’t type-hint anything. Union types simply allow defining multiple types for a value as options. Thanks to the union types, the following code becomes valid:</p>
<div><div><pre><code><span>function</span> <span>doSomething</span><span>(</span><span>int</span><span>|</span><span>string</span> <span>$value</span><span>)</span><span>:</span> <span>bool</span><span>|</span><span>array</span> <span>{}</span>
</code></pre></div></div>
<p>Usually having multiple return types indicate an opportunity for improvement, but previous versions of PHP didn’t allow us to define types for cases like these at all, so having this is still an improvement.</p>
<h2 id="performance">Performance</h2>
<p>I don’t have any hard numbers compared to other languages, but PHP has improved significantly over time compared to the previous versions. In addition to the jump PHP 7 brought over PHP 5.6, all the consecutive releases have brought several percent-point improvements at least and the trend is continuing. Some benchmarks <a href="https://www.phoronix.com/scan.php?page=article&amp;item=php-74-benchmarks&amp;num=2">done by Phoronix</a> show that the latest PHP 8 is more than 3x faster than PHP 5.6. There are more detailed tests in the original posts, make sure to give it a look.</p>
<p><img src="https://saasstarterkit.app/blog/assets/images/posts/is-php-still-relevant/php-benchmark-1.png" alt="PHP Benchmark 1"></p>
<p>In addition to those benchmarks, Kinsta has also conducted some real-world benchmarks with tools like Wordpress, <a href="https://kinsta.com/blog/php-benchmarks/#">full article here</a>. Here’s the result for Wordpress 5.3:</p>
<p><img src="https://saasstarterkit.app/blog/assets/images/posts/is-php-still-relevant/php-benchmark-2.png" alt="PHP Benchmark 2"></p>
<p>The numeric results they have shared are:</p>
<ul>
<li>WordPress 5.3 PHP 5.6 benchmark: <code>97.71 req/sec</code></li>
<li>WordPress 5.3 PHP 7.0 benchmark results: <code>256.81 req/sec</code></li>
<li>WordPress 5.3 PHP 7.1 benchmark results: <code>256.99 req/sec</code></li>
<li>WordPress 5.3 PHP 7.2 benchmark results: <code>273.07 req/sec</code></li>
<li>WordPress 5.3 PHP 7.3 benchmark results: <code>305.59 req/sec</code></li>
<li>WordPress 5.3 PHP 7.4 benchmark results: <code>313.42 req/sec</code></li>
</ul>
<p>These benchmarks do not include PHP 8 yet, but the 7.4 is capable of handling 3x requests of 5.6, which is a pretty significant improvement.</p>

<p>Overall, PHP has improved quite a lot over …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://saasstarterkit.app/blog/is-php-still-relevant-2021">https://saasstarterkit.app/blog/is-php-still-relevant-2021</a></em></p>]]>
            </description>
            <link>https://saasstarterkit.app/blog/is-php-still-relevant-2021</link>
            <guid isPermaLink="false">hacker-news-small-sites-25544627</guid>
            <pubDate>Sat, 26 Dec 2020 16:59:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Turbo Pascal Internals]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25544567">thread link</a>) | @lelf
<br/>
December 26, 2020 | http://direct.turbopascal.org/turbo-pascal-internals | <a href="https://web.archive.org/web/*/http://direct.turbopascal.org/turbo-pascal-internals">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="100%">
<tbody><tr>
	<td colspan="2">
				<p>Turbo Pascal compiler functions are grouped into several categories/units according to their role in the compiler. This grouping is done only to have a better overview on the individual parts of the compiler. On the other hand, functions from one group usually share common types and variables and therefore it makes sense to place them in separate units.</p>
<h2>Basic facts about Turbo Pascal</h2>
<div><p>Unit files in Turbo Pascal (tpu extension) are actually <a href="http://direct.turbopascal.org/symbol-tables">symbol tables</a> that are <a href="http://direct.turbopascal.org/compacting-symbol-tables">compacted</a> and <a href="http://direct.turbopascal.org/creating-unit-file">saved</a> as individual files. The <a href="http://direct.turbopascal.org/system-unit">System unit</a> is implicitly used in every program or unit. It contains the boot-strap symbol table and compiler procedures. The definition order of these compiler procedures is important because compiler calls them by id number. To compile <a href="http://direct.turbopascal.org/system-unit">System unit</a> you need bootstrap symbol table (SYSTEM.TPS).</p></div>
<p>Boot-strap symbol table contains <a href="http://direct.turbopascal.org/system-type-definitions">system types</a> like Byte, Char, Boolean, port identifiers, memory identifiers, system functions and system procedures.</p>
<div><p>Turbo Pascal library (extension tpl) is simple binary concatenation of one or more units. It is loaded at the compiler start. It should contain at least the system unit. You can create unit with console command copy:</p></div>
<div><pre>copy /b  system.tpu  unit1.tpu  unit2.tpu  turbo.tpl
</pre></div>
<div><p>Turbo Pascal uses low-level <a href="http://direct.turbopascal.org/intermediate-code">intermediate code</a>. Each record can contain target instruction with reference data,  intermediate code instruction for  subroutines or special meta instruction.</p><p>Turbo Pascal relies heavily on the <a href="http://en.wikipedia.org/wiki/Intel_8086#Segmentation" target="_blank">segment:offset</a> architecture of the x86 family in the real mode. In many cases this is a limiting factor because many data structures are limited to 64 KB. But on the other hand this comes very convenient when dealing with addresses and offsets.</p></div>		</td>
</tr>
<tr>
	<td colspan="2">
		<ul>
					<li>
      <a href="http://direct.turbopascal.org/compiler">
        Compiler</a>
									<br>
			<div>
<div><p>Here is located the main program, common variables, and everything else that does not belong into other categories.</p></div>
</div>					</li>
					<li>
      <a href="http://direct.turbopascal.org/scanner">
        Scanner</a>
									<br>
			<div><p>Scanner contains functions that processes source files, <a href="http://direct.turbopascal.org/extracting-tokens">extracts tokens</a> and processes compiler directives.</p></div>					</li>
					<li>
      <a href="http://direct.turbopascal.org/symbol-tables">
        Symbol Tables</a>
									<br>
			<div><p>Symbol tables are core part of every compiler. Turbo Pascal uses linked lists and hasing to effectively store and retrieve identifiers. Functions in this unit take care for data storing, identifier searching and various symbol table management.</p></div>					</li>
					<li>
      <a href="http://direct.turbopascal.org/parser">
        Parser</a>
									
			<p>Parser processes main program and units, checks syntax, processes stream of tokens and generates intermediate code. This is where the core compiler functions are located.</p>
<br>					</li>
					<li>
      <a href="http://direct.turbopascal.org/expressions">
        Expressions</a>
									<br>
			<div><p>Expression in Turbo Pascal is everything from constant, variable, calculation or just identifier. This unit contains over 100 functions to process every possible Turbo Pascal expression.</p></div>					</li>
					<li>
      <a href="http://direct.turbopascal.org/calculator">
        Calculator</a>
									
			<p>This unit is used by the Expressions unit and contains functions that process calculations with one or two operands and calculation operation. This unit actually generates code for addition, subtraction, multiplication, division, shifts, etc.</p>
<br>					</li>
					<li>
      <a href="http://direct.turbopascal.org/statements">
        Statements</a>
									<br>
			<div><p>This unit contains files that process each Pascal statement: If, While, For, Repeat, Case, With, GoTo, Inline, Asm block, or system procedure.</p></div>					</li>
					<li>
      <a href="http://direct.turbopascal.org/assembler">
        Assembler</a>
									
			<p>Assembler unit processes assembly instuctions in the Asm-end block and generates code for them.</p>
<br>					</li>
					<li>
      <a href="http://direct.turbopascal.org/system-functions">
        System Functions</a>
									
			<p>This is another unit that is used by the Expressions unit which processes system functions like <a href="http://direct.turbopascal.org/system-function-abs">Abs</a>, <a href="http://direct.turbopascal.org/system-function-upcase">UpCase</a>, <a href="http://direct.turbopascal.org/system-function-sqr">Sqr</a>, <a href="http://direct.turbopascal.org/system-functions-succ-and-pred">Succ</a>, <a href="http://direct.turbopascal.org/system-functions-succ-and-pred">Pred</a>, etc.</p>
<br>					</li>
					<li>
      <a href="http://direct.turbopascal.org/system-procedures">
        System Procedures</a>
									
			<p>This unit contains functions to process system procedures like Write, Writeln, Assign, Dispose, Delete, etc.</p>
<br>					</li>
					<li>
      <a href="http://direct.turbopascal.org/type-definitions">
        Type Definitions</a>
									<br>
			<div><p>Type definitions unit defines data structures for basic types and contains few functions to process type&nbsp;<span>definitions.</span></p></div>					</li>
					<li>
      <a href="http://direct.turbopascal.org/object-files">
        Object Files</a>
									<br>
			<div>
<div><p>This unit imports and processes object files and generates intermediate code for OMF records.</p></div>
</div>					</li>
					<li>
      <a href="http://direct.turbopascal.org/code-generator">
        Code Generator</a>
									<br>
			<div><p>This unit processes intermediate code and generates executable code and reference records for Linker.</p></div>					</li>
					<li>
      <a href="http://direct.turbopascal.org/linker">
        Linker</a>
									<br>
			<div><p>Linker joins code from all used units, determines addresses of variables, functions and procedures, resolves references and generates executable file.</p></div>					</li>
					<li>
      <a href="http://direct.turbopascal.org/io-utilities">
        I/O Utilities</a>
									<br>
			<div><p>Turbo Pascal contains many functions that read or write files, handle error messages and take care for compiler operation.</p></div>					</li>
		</ul>
		</td>
</tr>
</tbody></div></div>]]>
            </description>
            <link>http://direct.turbopascal.org/turbo-pascal-internals</link>
            <guid isPermaLink="false">hacker-news-small-sites-25544567</guid>
            <pubDate>Sat, 26 Dec 2020 16:51:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An open letter to my friends with fuck you money]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25544168">thread link</a>) | @rishabhd
<br/>
December 26, 2020 | https://www.spakhm.com/p/an-open-letter-to-my-friends-with | <a href="https://web.archive.org/web/*/https://www.spakhm.com/p/an-open-letter-to-my-friends-with">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I've been living in Silicon Valley for ten years. During this time I've had the privilege to meet many gifted, benevolent, indefatigable people. You've always graciously offered me your time and resources, for no reason other than your love of the startup world. Thank you for paying it forward and sorry I was a pain in the ass.</p><p>We need to talk. Something's rotten in the state of tech. I know it, you know it, everyone who has any sense at all knows it. Facebook, Twitter and YouTube are quasi-monopolies programming our brains, and we have no access to the source code. Our institutions are captured by agents who do not share our values, and will not stop until they remake the world in their gruesome image. No one is coming to fix this. No one is in control.</p><p>The turbulence has spilled over onto the national arena. In June, Chairman of the Joint Chiefs of Staff Mark Milley wrote a <a href="https://www.jcs.mil/Portals/36/Documents/CJCS%20Memo%20to%20the%20Joint%20Force%20(02JUN2020).pdf">memo</a> to the troops reminding them to uphold the constitution. This is not creative destruction as usual. Here be dragons. But to me the <em>human</em> aspect of this situation is woefully familiar. I try to avoid clichés, but in this case one is eminently appropriate. Social media quasi-monopolies and erosion of our institutions are two sides of the same coin.</p><p>So let's talk about coins. Many of you have house-in-san-francisco-live-off-capital-gains fuck you money. I feel your pain. I really do. You're capable of so much more. Are those take-my-jet-to-south-of-france-while-this-all-blows-over assholes really that much more talented than you? Ok, maybe Zuck is, but he's an exception. Maybe a couple of others, but they're exceptions too. But other than that? No way! Why do they get to sit at the secret tables, pull the secret strings, and live in the future while you're stuck in the present running into your employees at brunch as if you were an ordinary middle manager at Geek Squad?</p><p>I understand your reasoning. You should be at the secret tables! You should be in the South of France! Sit out this political kerfuffle. Live to fight another day. You'll make up for it later, when you finally get to one of those coveted seats. You're a good person. No reason to risk it all now. Better be patient and wait until your time finally comes— that's when you can do the most good.</p><p>This next part is awkward, but some of you <em>are</em> the take-my-jet-to-south-of-france-while-this-all-blows-over assholes. (Is South of France still where assholes with private jets go while everything is falling apart?) I don't understand your world nearly as well, but hey, we're all white males. How different can it be? I'm guessing you have many families depending on you. You plant seeds to improve the world every day— through your investments, your board seats, your philanthropy. You educate politicians and government officials. You coach your kids's middle school football team. Most of America’s taxes come from your pocket. Hell, you probably plant literal trees!</p><p>But between you and me, hanging out with university presidents and having authorized biographers is pretty cool too, isn't it? Some day, say, a century and a half from now, a young entrepreneur somewhere is going to pick up one of those biographies. Can anyone blame you for wanting to live a model life so this kid from the future is properly inspired by your example?</p><p>Let me tell you a less illustrious inspirational story. When I was a kid in Ukraine, I was taking a public bus to get to school. One time a mentally ill man got on. (In that distant world we had no dedicated school buses; this episode was surprising because severely mentally ill people were actually institutionalized.) He began walking up to people's seats and screaming obscenities. I must have been no more than twelve years old, but I vividly remember that scene as if it were yesterday. I can still feel the contrast of this man screaming and the otherwise deathly silence with everyone pretending to look out the window or read their newspapers as if nothing out of the ordinary was happening.</p><p>But Ukraine isn't America. An old babushka looked over the men on the bus and exclaimed: "Are you men or dogshit? Why do you avert your eyes like a bunch of cowards? Did you forget your balls in a jar when you walked out the door this morning the way I sometimes forget my dentures? There are women and children here! Do something!"</p><p>And that was the end of it. The bus driver pulled over, a couple of people forced the man out, and everyone went about their day, shaken, but with this particular problem out of their lives forever.</p><p>I don't mean to sound like an old babushka. I am on your side. I must unwittingly be using hundreds of pieces of software and hardware you've created, just to publish this post. I know the magic you're capable of. I want more of it! Much more! I want AR and VR and civil supersonic aviation and robots and AI and abundant energy and affordable trips to Mars and underwater cities and new physics and space elevators and organ regeneration and an antidote to aging and a thousand other innovations you're going to create that I can't begin to dream of.</p><p>None of that is going to happen without you. But it also isn’t going to happen if you keep hiding in dark corners, whispering your private thoughts when you think no one is listening. If America falls, it is the end. There will be no houses in San Francisco, no seats to covet, no strings to pull, no private jets, and no South of France. Not for you, anyway. And there will be no AR or VR or new physics or space elevators or organ regeneration for me. If she falls, it's back to the dark ages for all of us.</p><p>I don’t know what bewilders me more, your inaction or your performative over-intellectualization, as if reality were a Clubhouse cocktail party. Kuran’s <a href="https://www.amazon.com/Private-Truths-Public-Lies-Falsification/dp/0674707583/">book</a> (or more likely the <a href="https://en.wikipedia.org/wiki/Preference_falsification">wikipedia article</a>) isn’t a grimoire, and <em>preference cascade</em> isn’t a magic spell that absolves you of social responsibility every time you utter it. America has given you your houses and your jets, and has asked very little of you in return. It’s <em>still</em> asking very little— you can discharge your civic duty while eating cupcakes in your pajamas.</p><p>So pretty, please, with sugar on top. Make the announcements. Tweet the tweets. Pay off Jack's dealer to slip him placebo strips so he stops microdosing and pretending he's Steve Jobs. Use the photos you took of Zuck and Sundar at the shapeshifter brothel. Hire whoever you have to hire, fire whoever you have to fire, and do whatever you have to do to get this fucking thing off the bus. Make it your singular purpose. Because if you don't, it will be Dick Costolo's livestream <a href="https://www.forbes.com/sites/abrambrown/2020/10/01/some-business-leader-should-face-a-firing-squad-former-twitter-ceo-dick-costolo-suggests-in-angry-tweet/">commentary</a> all the way to the bitter end.</p><p>P.S. All you ordinary folks reading, don't come after me with pitchforks. I could maaaybe ask for a favor or two, but only if they're small and only on a good day and probably not after this post. It's not like we get tested for COVID with secret instantaneous diagnostics only accessible to the elites and go to the shapeshifter brothel together. I don't get invited to those parties. Which is ok by me because parties make me anxious and shapeshifters creep me out.</p></div></div>]]>
            </description>
            <link>https://www.spakhm.com/p/an-open-letter-to-my-friends-with</link>
            <guid isPermaLink="false">hacker-news-small-sites-25544168</guid>
            <pubDate>Sat, 26 Dec 2020 15:59:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Leader Election Best Practices]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25543923">thread link</a>) | @parsecs
<br/>
December 26, 2020 | https://robertovitillo.com/leader-election-best-practices/ | <a href="https://web.archive.org/web/*/https://robertovitillo.com/leader-election-best-practices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p>December 26, 2020</p></header><p>Sometimes a single process in a system needs to have special powers, like being the only one that can access a shared resource or assign work to others. To grant a process these powers, the system needs to elect a <em>leader</em> among a set of <em>candidate processes</em>, which remains in charge until it crashes or becomes otherwise unavailable. When that happens, the remaining processes detect that the leader is no longer available and elect a new one.</p><p>Leader election can be implemented without any external dependency like the <a href="https://raft.github.io/raft.pdf">Raft algorithm</a> does. Doing so is far from trivial, though, and it’s best avoided unless you have a very good reason to.</p><p>In practice, you can leverage an external <a href="https://robertovitillo.com/what-every-developer-should-know-about-database-consistency/#strong-consistency">linearizable</a> key-value store, like etcd or Zookeeper, which offer abstractions that make it easy to implement leader election. The abstractions span from basic primitives like compare-and-swap to fully-fledged distributed mutexes.</p><p>Ideally, the external store needs to offer atomic compare-and-swap and expiration times (TTL) for keys. A compare-and-swap operation updates the value of a key if and only if the value matches the expected one, while an expiration time defines the time to live for a key, after which the key expires and is removed from the store if the lease hasn’t been extended. Each process tries to acquire a “lease” by creating a new key with a specific TTL using compare-and-swap. The first process to succeed becomes the leader and remains such until it stops renewing the lease, after which another process can become the leader.</p><p>The TTL expiry logic can also be implemented on the client-side, like this <a href="https://aws.amazon.com/blogs/database/building-distributed-locks-with-the-dynamodb-lock-client/">locking library</a> for DynamoDB does, but the implementation is more complex, and it still requires the data store to offer a compare-and-swap operation.</p><p>You might think that’s enough to guarantee there can’t be more than one leader in your application. Unfortunately, that’s not the case.</p><p>To see why, suppose there are multiple processes that need to update a file on a shared blob store, and you want to guarantee that only a single process at a time can do so to avoid race conditions. To achieve that, you decide to use a distributed mutex - a form of leader election. Each process tries to acquire the lock, and the one that does so successfully reads the file, updates it in memory, and writes it back to the store:</p><div data-language="python"><pre><code><span>if</span> lock<span>.</span>acquire<span>(</span><span>)</span><span>:</span>
    <span>try</span><span>:</span>
        content <span>=</span> store<span>.</span>read<span>(</span>blob_name<span>)</span>
        new_content <span>=</span> update<span>(</span>content<span>)</span>
        store<span>.</span>write<span>(</span>blob_name<span>,</span> new_content<span>)</span>
    <span>except</span><span>:</span>
        lock<span>.</span>release<span>(</span><span>)</span></code></pre></div><p>The problem here is that by the time the process writes the content to the store, it might no longer be the leader - a lot might have happened since it was elected. For example, the operating system might have preempted and stopped the process, and several seconds will have passed by the time it’s running again. So how can the process ensure that it’s still the leader then? It could check one more time before writing to the store, but that doesn’t eliminate the race condition, it just makes it less likely.</p><p>To avoid this issue, the data store downstream needs to verify that the request has been sent by the current leader. One way to do that is by using a fencing token. A <a href="https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html">fencing token</a> is a number that increases every time that a distributed lock is acquired - in other words, it’s a logical clock. When the leader writes to the store, it passes down the fencing token to it. The store remembers the value of the last token and accepts only writes with a greater value:</p><div data-language="python"><pre><code>success<span>,</span> token <span>=</span> lock<span>.</span>acquire<span>(</span><span>)</span>
<span>if</span> success<span>:</span>
    <span>try</span><span>:</span>
        content <span>=</span> store<span>.</span>read<span>(</span>blob_name<span>)</span>
        new_content <span>=</span> update<span>(</span>content<span>)</span>
        store<span>.</span>write<span>(</span>blob_name<span>,</span> new_content<span>,</span> token<span>)</span>
    <span>except</span><span>:</span>
        lock<span>.</span>release<span>(</span><span>)</span></code></pre></div><p>This approach adds complexity as the downstream consumer - in our case, the blob store - needs to support fencing tokens. If it doesn’t, you are out of luck, and you will have to design your system around the fact that occasionally there will be more than one leader. For example, if there are momentarily two leaders and they both perform the same idempotent operation, no harm is done.</p><p>Although having a leader election can simplify the design of a system as it eliminates concurrency, it can become a scaling bottleneck if the number of operations performed by the leader increase to the point where it can no longer keep up. When that happens, you might be forced to re-design the whole system. </p><p>Also, having a leader introduces a single point of failure with a large blast radius - if the election process stops working or the leader isn’t working as expected, it can bring down the entire system with it.</p><p>You can mitigate some of these downsides by introducing partitions and assigning a different leader per partition, but that comes with additional complexity. This is the solution many distributed data stores use.</p><p>Before considering the use of a leader, check whether there other are ways of achieving the desired functionality without it. For example, optimistic locking is one way to guarantee mutual exclusion at the cost of wasting some computing power. Or perhaps high availability is not a requirement for your application, in which case having just a single process that occasionally is restarted after failure is not a big deal. </p><p>As a rule of thumb, if you must use leader election, you have to minimize the work it performs and be prepared to occasionally have more than one leader if you can’t support fencing tokens end-to-end.</p><hr></article></div>]]>
            </description>
            <link>https://robertovitillo.com/leader-election-best-practices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25543923</guid>
            <pubDate>Sat, 26 Dec 2020 15:16:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lawyers automate this, so why don't airlines?]]>
            </title>
            <description>
<![CDATA[
Score 187 | Comments 150 (<a href="https://news.ycombinator.com/item?id=25543861">thread link</a>) | @leejo
<br/>
December 26, 2020 | https://leejo.github.io/2020/12/26/EZY1952/ | <a href="https://web.archive.org/web/*/https://leejo.github.io/2020/12/26/EZY1952/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>
				<center>Lawyers Automate This, So Why Don't Airlines?</center>
			</p>
			<div>
				<center>
				
				
				

				December 26, 2020 (
				
				
					<a href="https://leejo.github.io/2020/11/19/some_kind_of_paypal_refund_scam/">Prev</a>
				
				/
				
					Next
				
			)

			
				</center>
			</div>
			<p>My working title for this blog post was “Why I’ll Never Fly With easyJet Again”, but that was far too clickbaity. Also it’s probably worth prefixing this post with two things. The first being the caveat that whether or not i ever fly with easyJet again is immaterial to their business, given that the model of budget airlines is one of opportunistic sales. Their loyalty programmes are minimal to non-existent<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> (although that may change in the near future<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>) because the nature of their passengers is not one of loyalty. When you’re looking for a short haul cheap flight you’re unlikely to be attracted to schemes that only benefit you after years, or hundreds of thousands of air miles, worth of loyalty.</p>

<p>The reality of the budget airlines is they don’t have to worry about losing future passengers, thousands of them even, because there will always be enough replacement passengers. Budget airlines’ flights average above a 90% occupancy rate<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>.</p>

<p>So the point of me never flying with easyJet again is not because i am under any illusion that it will be detrimental to their business, it won’t, but rather to protect <em>myself</em> should the situation happen again. They’re not the first airline to make my “list”, but the others have reasons that aren’t interesting enough to require a blog post.</p>

<p>What i am hoping with this post is that it gives the reader enough information that, should they find themselves in a similar situation, they are more informed as to their options and the potential ramifications of the choice they make. This is going to affect more travelers when the UK leaves the EU.</p>

<p>The second prefix is that easyJet recently posted their first year of losses<sup id="fnref:10" role="doc-noteref"><a href="#fn:10">4</a></sup>, due to the current global situation. I started writing this post sometime in 2019, way before the pandemic royally fucked the airline industry. It’s arguable that the airline industry being royally fucked was only a matter of time, and the consequences of <em>that</em> could mean the details here are now even more relevant - It may become even harder to claim refunds and compensation from them in the future. Airline companies will probably double down on their approach to handling compensation claims to avoid yet more financial loss.</p>

<p><strong>EZY1952</strong></p>

<p>On 23rd December 2018 my partner and I were due to fly from Geneva to Manchester on easyJet flight EZY1952, aircraft registration G-EZRU, which was scheduled to depart at 16:50 CET and arrive at 17:50 GMT. I had booked these flights a couple of months earlier, which combined with the date of our departure and return lead to a total cost of 619.38 CHF.</p>

<p>The 600+ CHF didn’t include any of the optional extras, priority boarding, seat choice, checked bags, etc. It was the “basic” cost of the “cheap” flights. This cost is four to five times more than the normal cost of this route, as I said due to the relatively late booking (two months in advance) and the dates of the flights. This route is normally far cheaper:</p>

<p><img width="625px" src="https://leejo.github.io/images/2020/EZY1952/typical_cost.png"></p>

<p>Anyway, given the alternatives and the limited options for our dates these were the flights we settled on and decide the cost was worth it to spend Xmas with the family. The flight was delayed by just a few minutes, which isn’t unusual for this route, but then took off as normal at 17:14:05 CET.</p>

<p>A few moments after take off, the literal wheels no longer being on the ground part of it, I felt my ears pop quite suddenly. That might not be taken as unusual either, but I live at altitude and my ears don’t normally pop on flights. The plane then spent several minutes in low cloud, another unusual thing given the cloud line is normally cut through quicker. I turned to my partner and suggested that something was off.</p>

<p>A couple of minutes later the pilot informed us that the flight would be returning to Geneva airport as the cabin pressure system, and its backup, had failed. Given the potentially catastrophic consequences of the cabin pressure system failing at cruising altitude, I considered that everyone on the plane had been very lucky.</p>

<p>The plane landed safely at Geneva airport at 17:41:00 CET, meaning a total flight time of about 25 minutes<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">5</a></sup>. I contacted my parents to let them know we wouldn’t be arriving as planned and would keep them informed as to any updates:</p>

<p><img width="625px" src="https://leejo.github.io/images/2020/EZY1952/messages_to_mum.png"></p>

<p>We remained on the plane, after the pilot informed us that the technical crew were going to look into the issue. We were then told the parts would be replaced/fixed and this would take three to four hours. At this point I knew that we would not be flying until the next day as a) it was now 19:00 and Geneva airport has strict limitations on flights after 22:00, and b) it would be massively irresponsible of the airline to let this plane fly without a more comprehensive test that would probably take longer than the three to four hour estimate<sup id="fnref:6" role="doc-noteref"><a href="#fn:6">6</a></sup>.</p>

<p>Since it was going to take a few hours all passengers disembarked and returned to the departure gate. I’m not sure how long we were on the plane, while it was on the ground, but looking at the evidence I kept afterwards it appears that we were on it for approximately one hour fifteen minutes. This is from the time it landed to receiving a text message from easyJet apologising for the delay:</p>

<p><img width="625px" src="https://leejo.github.io/images/2020/EZY1952/sorry_for_delay.png"></p>

<p>As soon as we got back into the gate I sat down and checked to see if there were any other flights available. Sure enough there was: we could get a one way easyJet flight to Liverpool, so I booked two seats for a total of 189.26 CHF. This flight would depart at 21:25 CET and arrive at 22:20 GMT, four hours and thirty minutes after our original arrival time.</p>

<p>It should be said at this point I was reasonably confident of a few things:</p>

<ul>
  <li>It was highly unlikely the original fight was going to depart that night</li>
  <li>In fact, it would probably be delayed until the next afternoon</li>
  <li>We would have all the inconvenience of that, and lose one third of our time in the UK</li>
  <li>Given the original arrival time was delayed by more than three hours we were covered by EU Regulation 261/2004</li>
  <li>So the airline would have to compensate €250 for each of us, which would at least cover the alternate flights I had booked</li>
</ul>

<p>I was correct on four out of five of these:</p>

<p><img width="625px" src="https://leejo.github.io/images/2020/EZY1952/delayed_overnight.png"></p>

<p>Our flight to Liverpool went without issue, and we weren’t the only people to have rebooked from the delayed flight as we overheard some other passengers explaining their situation to the cabin crew<sup id="fnref:7" role="doc-noteref"><a href="#fn:7">7</a></sup>.</p>

<p><strong>Contacting easyJet Customer Service</strong></p>

<p>The next day I used easyJet’s contact form to submit a claim under EC261/2004 regulations. I knew this was going to take a long time so figured I may as well start the process as soon as possible. My claim was made on the basis that the original flight had been delayed overnight and I had booked alternate travel arrangements to get to my destination.</p>

<p>I considered the cost of the original flights a sunk cost. I wasn’t actually interested in compensation and I just wanted the cost of the alternate flights refunded, which came in at less than half the amount of compensation EC261/2004 would give considering the length of the delay to the original flight.</p>

<p>The response from easyJet came back quickly, the next day: <em>As you were a no show on the flight we would not be able t reimburse the costs for alternate transport.</em> - well that didn’t read like a response by someone/thing that had actually looked into the details. We had shown up for the flight, given we were on it when the pressure systems failed, and clearly we wouldn’t show up for the <em>rescheduled</em> flight if we arranged alternate transport as we can’t be in two places at once.</p>

<p>I assumed this was just a first level response of “refuse all claims, through a semantic dispute, because this will cause a not insignificant number of people to give up”<sup id="fnref:8" role="doc-noteref"><a href="#fn:8">8</a></sup>. The contact form doesn’t have a place to describe the reason for the claim in detail so I needed to call easyJet to explain.</p>

<p><strong>EU Regulation 261/2004</strong></p>

<p>I’ll spare you too much detail, as you can search for it if you want to (or read a summary on <a href="https://en.wikipedia.org/wiki/Flight_Compensation_Regulation">Wikipedia</a>). Essentially - EU 261/2004 allows compensation if your flight is from or to an EU/EAA area and is either delayed or cancelled [less than one week before the flight date]. The level of compensation depends on the distance of the flight.</p>

<p>In this particular case the delay was more than four hours, and the flight was less than 1,500km, so would qualify for €250 compensation (per passenger).</p>

<p>The regulation also says the passengers must be given assistance, and in this particular case of the flight being delayed overnight would mean hotel accommodation and transport between the airport and the hotel. This was Geneva two days from Xmas, so that would probably mean another €250.</p>

<p>So a reasonable estimate is easyJet would be paying in the region of €750 per passenger on this delayed flight. Given it was full (at least to my recollection) easyJet were looking at a bill of at least €100,000 for compensation + accommodation expenses<sup id="fnref:9" role="doc-noteref"><a href="#fn:9">9</a></sup>.</p>

<p>To go off on a tangent slightly - all of this is going to be up in the air when the UK leaves the EU. Of course that depends what the UK government <a href="https://en.wikipedia.org/wiki/Flight_Compensation_Regulation#Brexit_and_British_Consumers">decide to do about it</a>. Given everything else on their plate don’t be surprised if this one gets forgotten about until the claims start to appear.</p>

<p><strong>Contacting easyJet Customer Service Again</strong></p>

<p>As my claim, via easyJet’s web form, was rejected relatively quickly I decided to pick up the phone and see if speaking to someone would make a difference. I explained the situation and they agreed to pass this on to someone who would look at it in more detail, given the time of year this would take a few days at the least.</p>

<p>A couple of weeks later I received an email stating “Unfortunately as you were a no show on the transferred flight there is no reimbursement for EUC216 Compensation”. But also “As a goodwill gesture I have created a flight voucher to the value of the 51.90 GBP”.</p>

<p>Slightly odd - no …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leejo.github.io/2020/12/26/EZY1952/">https://leejo.github.io/2020/12/26/EZY1952/</a></em></p>]]>
            </description>
            <link>https://leejo.github.io/2020/12/26/EZY1952/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25543861</guid>
            <pubDate>Sat, 26 Dec 2020 15:08:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[They want us to be compliant, not secure]]>
            </title>
            <description>
<![CDATA[
Score 196 | Comments 171 (<a href="https://news.ycombinator.com/item?id=25543818">thread link</a>) | @_wldu
<br/>
December 26, 2020 | https://www.go350.com/posts/they-want-us-to-be-compliant-not-secure/ | <a href="https://web.archive.org/web/*/https://www.go350.com/posts/they-want-us-to-be-compliant-not-secure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Some years ago, I worked for an organization that was involved in federally funded research. Occasionally, government IT auditors (or contractors that they hired) would visit our facilities to audit our systems.</p><p>We used a wide variety of operating systems on several different hardware platforms. Windows, Mac, Linux and Unix systems were scattered throughout our buildings running on desktops, laptops, workstation, servers and embedded devices. We ran several different Linux distributions, multiple Unixes and had standardized on <a href="https://en.wikipedia.org/wiki/Bcrypt">bcrypt</a> hashes to store user passwords.</p><p>Bcrypt was released in 1999 and is based on <a href="https://www.schneier.com/academic/blowfish/">Blowfish</a>. Blowfish is a fast, unpatented block cipher that was developed by <a href="https://en.wikipedia.org/wiki/Bruce_Schneier">Bruce Schneier</a> in 1993. It’s been in the mainline Linux kernel since the 2.6 release.</p><p>Bcrypt is a fast and efficient password hash yet strong and hard to attack. At the time, it was the strongest password hash that we could use and as an added bonus, it worked on all of our Linux and Unix systems.</p><p>One particular year, the IT auditors realized that we were using bcrypt hashes to store user passwords. They said that it was not a <a href="https://csrc.nist.gov/publications/detail/fips/180/4/final">FIPS approved algorithm</a> and by using bcrypt hashes, we were noncompliant. They insisted that we switch to a SHA-2 based hash function right away.</p><p>We ran several tests that demonstrated how the SHA-2 hashes were much easier to crack than the bcrypt hashes (see below for a performance comparison on a semi-modern GPU). But the auditors were adamant. They did not care that the approved algorithms were weaker. Nothing would change their decision.</p><p>In their minds, it was a simple matter. Bcrypt was not on the list. It was not an approved hashing function. They would not discuss it further.</p><p>To satisfy the auditors, we switched all the systems to an approved SHA-2 hash function. This action probably made our systems more vulnerable to cyber attacks.</p><p>A colleague said, <em>“They want us to be compliant, not secure.”</em></p><div><pre><code data-lang="bash">$ hashcat -b -m <span>1800</span>
hashcat <span>(</span>v5.1.0<span>)</span> starting in benchmark mode...

OpenCL Platform <span>#1: NVIDIA Corporation</span>
<span>======================================</span>
* Device <span>#1: GeForce GTX 1060 6GB, 1519/6077 MB allocatable, 10MCU</span>

Benchmark relevant options:
<span>===========================</span>
* --optimized-kernel-enable

Hashmode: <span>1800</span> - sha512crypt $6$, SHA512 <span>(</span>Unix<span>)</span> <span>(</span>Iterations: 5000<span>)</span>

Speed.#1.........:    <span>78810</span> H/s <span>(</span>51.36ms<span>)</span> @ Accel:512 Loops:128 Thr:32 Vec:1
</code></pre></div><div><pre><code data-lang="bash">$ hashcat -b -m <span>3200</span>
hashcat <span>(</span>v5.1.0<span>)</span> starting in benchmark mode...

OpenCL Platform <span>#1: NVIDIA Corporation</span>
<span>======================================</span>
* Device <span>#1: GeForce GTX 1060 6GB, 1519/6077 MB allocatable, 10MCU</span>

Benchmark relevant options:
<span>===========================</span>
* --optimized-kernel-enable

Hashmode: <span>3200</span> - bcrypt $2*$, Blowfish <span>(</span>Unix<span>)</span> <span>(</span>Iterations: 32<span>)</span>

Speed.#1.........:     <span>7570</span> H/s <span>(</span>41.13ms<span>)</span> @ Accel:16 Loops:8 Thr:8 Vec:1
</code></pre></div><ul><li><a href="https://www.go350.com/tags/compliance">compliance</a></li><li><a href="https://www.go350.com/tags/passwords">passwords</a></li></ul></div></div>]]>
            </description>
            <link>https://www.go350.com/posts/they-want-us-to-be-compliant-not-secure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25543818</guid>
            <pubDate>Sat, 26 Dec 2020 14:56:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Paying Medieval Taxes Using Eels]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25543802">thread link</a>) | @mkmk
<br/>
December 26, 2020 | https://historiacartarum.org/eel-rents-project/ | <a href="https://web.archive.org/web/*/https://historiacartarum.org/eel-rents-project/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="description">

		<p>Project Manager: <a href="https://www.jwgreenlee.net/" target="_blank" rel="noopener noreferrer">Dr. John Wyatt Greenlee, PhD</a><br>
Find on Twitter: <a href="https://twitter.com/greenleejw" target="_blank" rel="noopener">The Surprised Eel Historian</a></p>
<hr>
<div id="attachment_584"><p><img aria-describedby="caption-attachment-584" loading="lazy" src="https://historiacartarum.org/wp-content/uploads/2018/03/1325_Luttrell-Psalter-Eel-Weir-300x176.jpg" alt="" width="384" height="225"></p><p id="caption-attachment-584">Eel Weir from the 1325 Luttrell Psalter. BL Add MS 42130 fol. 181r.</p></div>
<p>One of the peculiar aspects of the Domesday register of 1086 are the range of taxes that the English paid in-kind. &nbsp;Domesday records payments in pigs, in fish, in ale, and in many other types of food. &nbsp;Of these in-kind payments, the one that stands out most to modern viewers is likely the eel-rents. &nbsp;This is in part because, in Europe and the Americas, we have generally moved away from eating eel on anything like a regular basis. Consequently, the idea of eels having any type of social or economic value appears less normal to us the thought of other animals or commodities having negotiable value. &nbsp;We still eat pigs and drink ale. &nbsp;But the eel-rents also stand out for the sometimes excessive numbers of animals at play — the village of Harmston, for example, owed the Earl Hugh 75,000 eels per year, and fishermen in Wisbech needed to pay various local monasteries a combined total of almost 35,000 per year.</p>
<p>Eel-rents usually only find passing mention in history books, and when they do it is these types of rents, with their eye-popping numbers,&nbsp; that dominate. It is worth noting, though, that these numbers, while high, are not out of the range of normal. &nbsp;Domesday and subsequent documents show that rents of multiple thousands of eels a year were common for single fisheries or mills. &nbsp;All told, at the time of the Great Survey in 1086 people living in England owed more than 500,000 eels in taxes each year to their landlords.</p>
<p>The purpose of this project is to map and present the role of eel-rents in the medieval and early modern English economy. From at least the tenth century onward, the English all across the island paid some taxes in eel (live and dead). English eel-rents have long been understudies and misunderstood, and this project demonstrates both the breadth, and the depth, of the rents in English history.</p>
<p>Most studies that discuss eel-rents tend to focus on their role only the economy of the Fens in East Anglia, but in truth renters all across the island paid their taxes in the fish. And while eel-rents did slowly vanish as coins became more common, they did not wholly vanish. Rather, eel-rents remained a wide-spread and viable part of the English economy into the fifteenth century, with scattered rents remaining active for another two hundred years after that.</p>
<hr>
<h4><span><strong>Project Contents</strong></span></h4>
<p><span><strong>〉</strong><a href="https://historiacartarum.org/eel-rents-project/english-eel-rents-10th-17th-centuries/"><strong>Interactive Map</strong></a></span></p>
<p>A map of England showing all known eel-rents from the 10th through the 17th centuries. Sortable by century, and including all relevant information including citations.</p>
<p><span><strong>〉<a href="https://historiacartarum.org/eel-rents-project/what-does-a-stick-of-eels-get-you/">The Value of a Stick of Eels</a></strong></span></p>
<p>Dried eels were often counted in sticks, with each stick being 25 eels. But what is the actual value of a stick of eels? This is an effort to find a rough equivalence in modern monetary terms. So what does a stick of eels get you these days? You might be surprised!</p>
<p><span><strong>〉<a href="https://historiacartarum.org/eel-rents-project/distances-traveled-by-eel-rents/">Eels on the Roads…How Far is too Far?</a></strong></span></p>
<p>So how far were eel-rents traveling around England? Here is a (highly caveated) attempted to work out just how many miles a stick of eels was likely to go between its point of capture and its destination.</p>
<p><span><strong>〉<a href="http://eels.historiacartarum.org/" target="_blank" rel="noopener noreferrer">More Eels and More Eel History</a></strong></span></p>
<p>It you’re really enjoying learning about eels and history, and you want even more, you can visit my site dedicated to the English history with the fish beyond eel-rents and maps.</p>
<p><span><strong>〉<a href="https://twitter.com/greenleejw" target="_blank" rel="noopener noreferrer">Eel History on Twitter</a></strong></span></p>
<p>For daily tidbits of eel history, complete with fun memes and bad eel puns, you can follow me at <a href="https://twitter.com/greenleejw" target="_blank" rel="noopener">The Surprised Eel Historian (@greenleejw)</a> on Twitter.</p>
<blockquote data-secret="FhHQZBeXLv"></blockquote>



    </div></div>]]>
            </description>
            <link>https://historiacartarum.org/eel-rents-project/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25543802</guid>
            <pubDate>Sat, 26 Dec 2020 14:53:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Talking out loud to yourself is a technology for thinking]]>
            </title>
            <description>
<![CDATA[
Score 373 | Comments 117 (<a href="https://news.ycombinator.com/item?id=25543656">thread link</a>) | @headalgorithm
<br/>
December 26, 2020 | https://psyche.co/ideas/talking-out-loud-to-yourself-is-a-technology-for-thinking | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/talking-out-loud-to-yourself-is-a-technology-for-thinking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>This week, a woman</strong> was strolling in my street, walking in circles and speaking out loud to herself. People were looking at her awkwardly, but she didnâ€™t particularly mind, and continued walking vigorously and speaking.</p>
<p>Yes, that woman was me.</p>
<p>Like many of us, I talk to myself out loud, though Iâ€™m a little unusual in that I often do it in public spaces. Whenever I want to figure out an issue, develop an idea or memorise a text, I turn to this odd work routine. While itâ€™s definitely earned me a reputation in my neighbourhood, itâ€™s also improved my thinking and speaking skills immensely. Speaking out loud is not only a medium of communication, but a technology of thinking: it encourages the formation and processing of thoughts.</p>
<p>The idea that speaking out loud and thinking are closely related isnâ€™t new. It emerged in Ancient Greece and Rome, in the work of such great orators as Marcus Tullius Cicero. But perhaps the most intriguing modern development of the idea appeared in the essay â€˜On the Gradual Formation of Thoughts During Speechâ€™ (1805) by the German writer Heinrich von Kleist. Here, Kleist describes his habit of using speech as a thinking method, and speculates that if we canâ€™t discover something just by thinking about it, we might discover it in the process of free speech. He writes that we usually hold an abstract beginning of a thought, but active speech helps to turn the obscure thought into a whole idea. Itâ€™s not thought that produces speech but, rather, speech is a creative process that in turn generates thought. Just as â€˜appetite comes with eatingâ€™, Kleist argues, â€˜ideas come with speakingâ€™.</p>
<p>A lot of attention has been given to the power of spoken self-affirmation as a means of self-empowerment, in the spirit of positive psychology. However, as Kleist says, talking to oneself is also a cognitive and intellectual tool that allows for a wider array of possible use cases. Contemporary theories in cognition and the science of learning reaffirm Kleistâ€™s speculations, and show how self-talk contributes not only to motivation and emotional regulation, but also to some higher cognitive functions such as developing metacognition and reasoning.</p>
<p>If self-talk is so beneficial, why arenâ€™t we talking to ourselves all the time? The dynamic between self-talk and inner speech might explain the dubious social status of the former. Self-talk is often seen as the premature equivalent of <a href="https://aeon.co/essays/our-inner-narrator-gives-us-continuity-and-a-sense-of-self" rel="noopener">inner speech</a> â€“ the silent inner voice in our mind, which has prominent cognitive functions in itself. The tendency to express our inner thoughts in actual self-talk, typical of children, is internalised, and transforms to voiceless inner speech in adulthood, as the developmental psychologist Lev Vygotsky already speculated in the 1920s.</p>
<p>Self-talk is deemed legitimate only when done in private, by children, by people with intellectual disabilities, or in Shakespearean soliloquies</p>
<p>Vygotskyâ€™s view stood in opposition to a competing one from the psychological school known as behaviourism, which saw childrenâ€™s self-talk as a byproduct of (supposedly) less competent minds. But Vygotsky claimed that self-talk has an active mental role. He observed children performing tasks while speaking to themselves out loud, and reached the conclusion that their â€˜private-talkâ€™ is a crucial stage in their mental development. Gradually, a childâ€™s interaction with others turns into an uttered conversation with the self â€“ self-talk â€“ until it becomes muted inner speech in adulthood. Vygotskyâ€™s successors, such as the psychologist Charles Fernyhough, have <a href="https://charlesfernyhoughcom.wordpress.com/the-voices-within/" rel="nofollow noreferrer noopener">demonstrated</a> that inner speech goes on to facilitate an array of cognitive functions including problem solving, activating working memory and preparation for social encounters. It is inner speech rather than self-talk, then, that has been the focus of <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4538954/" rel="nofollow noreferrer noopener">research</a> in adults.</p>
<p>However, the internalisation of self-talk isnâ€™t necessarily evidence of cognitive maturity: rather, it could represent the degeneration of an essential cognitive skill in the face of social pressure. The sociologist Erving Goffman noted that self-talk is taboo because it is a â€˜threat to intersubjectivityâ€™ and violates the social assumption that speech is communicative. As he wrote in his <a href="https://www.upenn.edu/pennpress/book/715.html" rel="nofollow noreferrer noopener">book</a> <em>Forms of Talk</em> (1981): â€˜There are no circumstances in which we can say: â€œIâ€™m sorry, I canâ€™t come right now, Iâ€™m busy talking to myselfâ€�.â€™ Self-talk is deemed legitimate only when done in private, by children, by people with intellectual disabilities, or in Shakespearean soliloquies.</p>
<p><strong>Yet self-talk enjoys</strong> certain advantages over inner speech, even in adults. First, silent inner speech often appears in a â€˜condensedâ€™ and partial, form; as Fernyhough has <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4538954/" rel="nofollow noreferrer noopener">shown</a>, we often tend to speak to ourselves silently using single words and condensed sentences. Speaking out loud, by contrast, allows the retrieval of our thoughts in full, using rhythm and intonation that emphasise their pragmatic and argumentative meaning, and encourages the creation of developed, complex ideas.</p>
<p>Not only does speech retrieve pre-existing ideas, it also creates new information in the retrieval process, just as in the process of writing. Speaking out loud is inventive and creative â€“ each uttered word and sentence doesnâ€™t just bring forth an existing thought, but also triggers new mental and linguistic connections. In both cases â€“ speech and writing â€“ the materiality of language undergoes a transformation (to audible sounds or written signs) which in turn produces a mental shift. This transformation isnâ€™t just about the translation of thoughts into another set of signs â€“ rather, it adds new information to the mental process, and generates new mental cascades. Thatâ€™s why the best solution for creative blocks isnâ€™t to try to think in front of an empty page and simply wait for thoughts to arrive, but actually to continue to speak and write (anything), trusting this generative process.</p>
<p>Speaking out loud to yourself also increases the dialogical quality of our own speech. Although we have no visible addressee, speaking to ourselves encourages us to actively construct an image of an addressee and activate oneâ€™s â€˜theory of mindâ€™ â€“ the ability to understand other peopleâ€™s mental states, and to speak and act according to their imagined expectations. Mute inner speech can appear as an inner dialogue as well, but its truncated form encourages us to create a â€˜secretâ€™ abbreviated language and deploy mental shortcuts. By forcing us to articulate ourselves more fully, self-talk summons up the image of an imagined listener or interrogator more vividly. In this way, it allows us to question ourselves more critically by adopting an external perspective on our ideas, and so to consider shortcomings in our arguments â€“ all while using our own speech.</p>
<p>You might have noticed, too, that self-talk is often intuitively performed while the person is moving or walking around. If youâ€™ve ever paced back and forth in your room while trying to talk something out, youâ€™ve used this technique intuitively. Itâ€™s no coincidence that we walk when we need to think: evidence <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4879139/" rel="nofollow noreferrer noopener">shows</a> that movement enhances thinking and learning, and both are activated in the same centre of motor control in the brain. In the influential subfield of cognitive science concerned with â€˜embodiedâ€™ cognition, one prominent claim is that actions themselves are constitutive of cognitive processes. That is, activities such as playing a musical instrument, writing, speaking or dancing donâ€™t start in the brain and then emanate out to the body as actions; rather, they entail the mind and body working in concert as a creative, integrated whole, unfolding and influencing each other in turn. Itâ€™s therefore a significant problem that many of us are trapped in work and study environments that donâ€™t allow us to activate these intuitive cognitive muscles, and indeed often even encourage us to avoid them.</p>
<p>Technological developments that make speaking seemingly redundant are also an obstacle to embracing our full cognitive potential. Recently, the technology entrepreneur Elon Musk declared that we are marching towards a near future without language, in which weâ€™ll be able to communicate directly mind-to-mind through neural links. â€˜Our brain spends a lot of effort compressing a complex concept into words,â€™ he said in a recent interview, â€˜and thereâ€™s a lot of loss of information that occurs when compressing a complex concept into words.â€™ However, what Musk chalks up as â€˜effortâ€™, friction and information loss also involves cognitive gain. Speech is not merely a conduit for the transmission of ideas, a replaceable medium for direct communication, but a generative activity that enhances thinking. Neural links might ease intersubjective communication, but they wonâ€™t replace the technology of thinking-while-speaking. Just as Kleist realised more than 200 years ago, there are no pre-existing ideas, but rather the heuristic process by which speech and thought co-construct each other.</p>
<p>So, the next time you see someone strolling and speaking to herself in your street, wait before judging her â€“ she might just be in the middle of intensive work. She might be wishing she could say: â€˜Iâ€™m sorry, I canâ€™t chat right now, Iâ€™m busy talking to myself.â€™ And maybe, just maybe, you might find yourself doing the same one day.</p></div></div></div>]]>
            </description>
            <link>https://psyche.co/ideas/talking-out-loud-to-yourself-is-a-technology-for-thinking</link>
            <guid isPermaLink="false">hacker-news-small-sites-25543656</guid>
            <pubDate>Sat, 26 Dec 2020 14:27:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Emacs is the 2D Command-line Interface]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25543611">thread link</a>) | @susam
<br/>
December 26, 2020 | http://hongchao.me/cli-and-emacs/ | <a href="https://web.archive.org/web/*/http://hongchao.me/cli-and-emacs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>One of the most popular arguments against Emacs is that it is “a great
operating system, lacking only a decent editor”. The promotion of the
idea of “Living in Emacs” by some of the hardcore Emacs users only
make this argument more compelling. At the first glance, using a
single program for “everything” does seem to contradict the <a href="https://en.wikipedia.org/wiki/Unix_philosophy">Unix
philosophy</a>, which
favors single-purposed programs that compose really well instead of
monolithic systems that try to solve many complex problems at the same
time. In this article, I’d like to argue that Emacs largely follows
the Unix philosophy in its problem domain: <em>working with text</em>, and
can be seen as a two dimentional version of the <a href="https://en.wikipedia.org/wiki/Command-line_interface">command-line
interface</a>
(CLI).</p>

<blockquote>
  <p>This is the Unix philosophy: Write programs that do one thing and do
it well. Write programs to work together. Write programs to handle
text streams, because that is a universal interface.</p>

  <p>McIlroy, head of the Bell Labs Computing Sciences Research Center</p>
</blockquote>

<p>Many CLI tools stood the test of time. Programs like <em>find</em>, <em>grep</em>,
<em>awk</em>, etc have been indispensable for IT professionals for
decades. They are effective, sometimes more so than their GUI
counterparts, because command line interpreters such as
<a href="https://en.wikipedia.org/wiki/Bourne_shell">Bash</a> provides an
environment where they can be composed together to accomplish tasks
that the original designer of the individual program have never
thought about. For example, through the composition of <em>kubectl</em>,
<em>grep</em>, <em>awk</em> and <em>base64</em>, the following command displays the content
of the <em>tls.crt</em> certificate in a Kubernetes secret called
<em>nioctib-tech-it-tls</em>:</p>

<p><img src="http://hongchao.me/images/compose-cli.png" alt="compose cli"></p>

<p>The following two things are quintessential to the composibility and
extensibility of the CLI programs:</p>

<ul>
  <li>Text streams as the univeral interface</li>
  <li>Command line interpreter as a programming environment</li>
</ul>

<p>There are definitely disadvantages to use text streams as the
universal interface between programs due to its lack of structure. But
the timelessness of many of the programs following this pattern and
the prosperity that it brings to the CLI ecosystem proved its
effectiveness as a design choice. Text can be read by both human and
programs. It can be manipulated, printed, stored, trasferred, version
controlled with the tools of your choice. For programs that do not
inheritantly require structured data, using text streams as interface
provides the most flexibility and composibility.</p>

<p>However, the flip side is that for programs that do require structured
data, such as browsers, image viewers, music players, etc. Their text
based versions usually become the toys of the hobbyists with
neglectable impact.</p>

<p><img src="http://hongchao.me/images/lynx-browser.png" alt="lynx browser">
<span>Lynx: a text based browser with tiny user base</span></p>

<p>Another important contributor to the success of many of the CLI
programs is the fact that they live in a programmable environment. In
Bash, programs can be written from scratch or glued together using
Bash script. This makes the CLI environment infinitely extensible. By
enabling smaller programs that “do one thing and do it well” work
together to accomplish more complex tasks, it becomes an environment
that boosts synergy, productivity and creativity.</p>

<p>The word “line” in the CLI (Command-line interface) environment
indicates its one dimentional nature. For programs that potentially
need to interact with (two-dimentional) text files, Emacs offers an
environment with similiar characteristics that makes CLI enviornment
successful: A universal text interface and a programming environment
which enables infinite extensibility.</p>

<p>Self described as “an extensible, customizable, free/libre text
editor”, <a href="https://en.wikipedia.org/wiki/GNU_Emacs">GNU Emacs</a>’s
infinite extensibility is enabled by a Turing-complete language called
<a href="https://en.wikipedia.org/wiki/Emacs_Lisp">Elisp</a>, which also is used
to write most of Emacs itself. This is similiar to how for example
Bash achieves its extensibility through Bash script. Just like most of
the programs that thrives under the Bash environment are inheritantly
text focused, most of the popular Emacs programs are text focused as
well, such as <a href="https://magit.vc/">Magit</a> and
<a href="https://orgmode.org/">Org-mode</a>. They also tend to integrate very
well with other Emacs programs, creating synergy similiar to that of
the CLI programs. For example, you can look at the commit history of a
Git repository using Magit, jump directly to the diff of a commit, and
then jump straight to the source code in the diff. In the following
example, the source code is written in Scala, you can then edit the
code with Emacs’s exellent Scala support thanks to
<a href="https://github.com/emacs-lsp/lsp-mode">lsp-mode</a> and
<a href="https://github.com/emacs-lsp/lsp-metals">lsp-metals</a>, which are
programs in the Emacs ecosystem that Magit is not aware of at all.</p>

<p><img src="http://hongchao.me/images/magit-code.png" alt="magit">
<span>Magit: jumping from commit to diff to source code</span></p>

<p>If Emacs is an environment for programs that focus on two dimensional
text, it is also more than capable of running programs that deal with
one dimensional text. In fact, many CLI tools such as <em>grep</em>, <em>find</em>
and many file system management utilities
(<a href="https://en.wikipedia.org/wiki/Dired">Dired</a>) are implemented in
Elisp and thus integrated into the Emacs ecosystem as well. This is
one of the reasons that if your main workflow is text focused, “Living
in Emacs” is probably not a terrible idea due to the synergy many of
these Emacs programs produce.</p>

<p>However, that doesn’t mean that <em>everything</em> should be run in
Emacs. Emacs is probably not the best tool for browsing web
(<a href="https://www.gnu.org/software/emacs/manual/html_mono/eww.html">EWW</a>)
or listening to music
(<a href="https://en.wikipedia.org/wiki/EMMS_(media_player)">EMMS</a>), just like
CLI tools such as Lynx will never have significant impact because they
are fundamentally not text focused. The argument that Emacs is “a
great operating system, lacking only a decent editor” tries to paint
Emacs as a monolithic swiss army knife ambitious enough to run any
programs. In fact, Emacs is more like a two dimensional CLI
environment that embraces the same Unix philosophy: enable simple,
elegant programs interacting with each other using an univeral
interface.</p>

<hr>

<p>Edit: <a href="https://www.reddit.com/r/emacs/comments/kk1voo/emacs_is_the_two_dimensional_commandline_interface/">Reddit Discussion</a></p>

  </div></div>]]>
            </description>
            <link>http://hongchao.me/cli-and-emacs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25543611</guid>
            <pubDate>Sat, 26 Dec 2020 14:21:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Executable PNGs]]>
            </title>
            <description>
<![CDATA[
Score 230 | Comments 39 (<a href="https://news.ycombinator.com/item?id=25543191">thread link</a>) | @todsacerdoti
<br/>
December 26, 2020 | https://djharper.dev/post/2020/12/26/executable-pngs/ | <a href="https://web.archive.org/web/*/https://djharper.dev/post/2020/12/26/executable-pngs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article>

<p>
<time datetime="2020-12-26">Saturday, December 26, 2020</time>
</p>
<figure>
<a href="https://djharper.dev/img/peek.webm"><video src="https://djharper.dev/img/peek.webm" loop="true" width="100%" title="The pixels have been adjusted in colour slightly." autoplay=""></video></a>
<figcaption><br>It's an image <i>and</i> a program</figcaption>
</figure>
<p>A few weeks ago I was reading about <a href="https://www.lexaloffle.com/pico-8.php">PICO-8</a>, a fantasy games console with limited constraints. What really piqued my interest about it was the novel way games are distributed, you encode them into a PNG image. This includes the game code, assets, everything. The image can be whatever you want, screenshots from the game, cool artwork or just text. To load them you pass the image as input to the PICO-8 program and start playing.</p>
<p>This got me thinking, wouldn’t it be cool if you could do that for programs on Linux? No! I hear you cry, that’s a dumb idea, but whatever, herein lies an overview of possibly the dumbest things I’ve worked on this year.</p>
<h2 id="encoding">Encoding</h2>
<p>I’m not entirely sure what PICO-8 is actually doing, but at a guess it’s probably use <a href="https://en.wikipedia.org/wiki/Steganography">Steganography</a> techniques to ‘hide’ the data within the raw bytes of the image. There are a lot of resources out there that explain how Steganography works, but the crux of it is quite simple, your image your want to hide data into is made up of bytes, an image is made up of pixels. Pixels are made up of 3 Red Green and Blue (RGB) values, represented as 3 bytes. To hide your data (the “payload”) you essentially “mix” the bytes from your payload with the bytes from the image.</p>
<p>If you just replaced each byte in your cover image with the bytes from your payload, you would end up with sections of the image looking distorted as the colours probably wouldn’t match with what your original image was. The trick is to be as subtle as possible, or <em>hide in plain sight</em>. This can be achieved by <em>spreading</em> your payload bytes over the bytes of the cover image by using the <em>least significant bits</em> to hide them in. In other words, make subtle adjustments to the byte values so the colour changes are not drastic enough to be perceptive by the human eye.</p>
<p>For example if your payload was the letter <code>H</code>, represented as <code>01001000</code> in binary (72), and your image contained a series of black pixels</p>
<figure>
<a href="https://djharper.dev/img/byte-replace1.png"><img src="https://djharper.dev/img/byte-replace1.png" title="The bits from the input bytes are spread across 8 output bytes by hiding them in the least significant bit"></a>
<figcaption><br>The bits from the input bytes are spread across 8 output bytes by hiding them in the least significant bit</figcaption>
</figure>
<p>The output is two-and-a-bit pixels that are slightly less black than before, but can you tell the difference?</p>
<figure>
<a href="https://djharper.dev/img/pixels1.png"><img src="https://djharper.dev/img/pixels1.png" title="The pixels have been adjusted in colour slightly."></a>
<figcaption><br>The pixels have been adjusted in colour slightly.</figcaption>
</figure>
<p>Well, an exceptionally trained colour connoisseur might be able to, but in reality these subtle shifts can really only be noticed by a machine. Retrieving your super secret <code>H</code> is just a matter of reading 8 bytes from the resulting image and re-assembling them back into 1 byte. Obviously hiding a single letter is lame, but this can scale to anything you want, a super secret sentence, a copy of <em>War and Peace</em>, a link to your soundcloud, the go compiler, the only limit is the amount of bytes available in your cover image as you’ll require at least 8x whatever your input is.</p>
<h2 id="hiding-programs">Hiding programs</h2>
<p>So, back to the whole linux-executables-in-an-image thing, that old chestnut. Well, seeing as executables are just bytes, they can be hidden in images. Just like in the PICO-8 thing.</p>
<p>Before I could achieve this I decided to write my own <a href="https://github.com/djhworld/steg">Steganography library</a> and <a href="https://github.com/djhworld/stegtool">tool</a> to support encoding and decoding data into PNGs. Yes, there are lots of steganography libraries and tools out there but I learn better by building.</p>
<figure>
<div><pre><code data-lang="bash">$ stegtool encode <span>\
</span><span></span>--cover-image htop-logo.png <span>\
</span><span></span>--input-data /usr/bin/htop <span>\
</span><span></span>--output-image htop.png
$
$ <span>echo</span> <span>"Super secret hidden message"</span> | stegtool encode <span>\ </span>
--cover-image image.png <span>\
</span><span></span>--output-image image-with-hidden-message.png
$ stegtool decode --image image-with-hidden-message.png
Super secret hidden message</code></pre></div>
</figure>
<p>As it’s all written in <a href="https://www.rust-lang.org/">Rust</a> it wasn’t that difficult to compile to WASM, so feel free to play with it here:</p>

<p>Anyway, now that can embed data, including executables into an image, how do we run them?</p>
<h2 id="get-it-running">Get it running</h2>
<p>The simple option would be to just run the tool above, <code>decode</code> the data into a new file, <code>chmod +x</code> it and then run it. It works but that’s not fun enough. What I wanted was something similar to the PICO-8 experience, you pass something a PNG image and it takes care of the rest.</p>
<p>However, as it turns out, you can’t just load some arbitrary set of bytes into memory and tell Linux to jump to it. Well, not in a direct way anyway, but you <em>can</em> use some cheap tricks to fudge it.</p>
<h2 id="memfd-create">memfd_create</h2>
<p>After reading <a href="https://magisterquis.github.io/2018/03/31/in-memory-only-elf-execution.html">this blogpost</a> it became apparent to me you can create an in-memory file and mark it as executable</p>
<blockquote>
<p>Wouldn’t it be cool to just grab a chunk of memory, put our binary in there, and run it without monkey-patching the kernel, rewriting execve(2) in userland, or loading a library into another process?</p>
</blockquote>
<p>This method uses the syscall <a href="https://man7.org/linux/man-pages/man2/memfd_create.2.html">memfd_create(2)</a> to create a file under the <code>/proc/self/fd</code> namespace of your process and load any data you want in it using <code>write</code>. I spent quite a while messing around with the <a href="https://crates.io/crates/libc">libc</a> bindings for Rust to get this to work, and had a lot of trouble understanding the data types you pass around, the documentation for these Rust bindings doesn’t help much.</p>
<p>I got something working eventually though</p>
<figure>
<div><pre><code data-lang="rust"><span>unsafe</span><span> </span>{<span>
</span><span>    </span><span>let</span><span> </span>write_mode<span> </span><span>=</span><span> </span><span>119</span>;<span> </span><span>// w
</span><span></span><span>    </span><span>// create executable in-memory file
</span><span></span><span>    </span><span>let</span><span> </span>fd<span> </span><span>=</span><span> </span>syscall(libc::SYS_memfd_create,<span> </span><span>&amp;</span>write_mode,<span> </span><span>1</span>);<span>
</span><span>    </span><span>if</span><span> </span>fd<span> </span><span>==</span><span> </span><span>-</span><span>1</span><span> </span>{<span>
</span><span>        </span><span>return</span><span> </span><span>Err</span>(<span>String</span>::from(<span>"memfd_create failed"</span>));<span>
</span><span>    </span>}<span>
</span><span>
</span><span>    </span><span>let</span><span> </span>file<span> </span><span>=</span><span> </span>libc::fdopen(fd,<span> </span><span>&amp;</span>write_mode);<span> 
</span><span>
</span><span>    </span><span>// write contents of our binary
</span><span></span><span>    </span>libc::fwrite(<span>
</span><span>        </span>data.as_ptr()<span> </span><span>as</span><span> </span><span>*</span><span>mut</span><span> </span>libc::c_void,<span> 
</span><span>        </span><span>8</span><span> </span><span>as</span><span> </span><span>usize</span>,<span>
</span><span>        </span>data.len()<span> </span><span>as</span><span> </span><span>usize</span>,<span>
</span><span>        </span>file,<span>
</span><span>    </span>);<span>
</span><span></span>}<span>
</span></code></pre></div>
</figure>
<p>Invoking <code>/proc/self/fd/&lt;fd&gt;</code> as a child process from the parent that created it is enough to run your binary.</p>
<figure>
<div><pre><code data-lang="rust"><span>let</span><span> </span>output<span> </span><span>=</span><span> </span>Command::new(format<span>!</span>(<span>"/proc/self/fd/{}"</span>,<span> </span>fd))<span>
</span><span>    </span>.args(args)<span>
</span><span>    </span>.stdin(std::process::Stdio::inherit())<span>
</span><span>    </span>.stdout(std::process::Stdio::inherit())<span>
</span><span>    </span>.stderr(std::process::Stdio::inherit())<span>
</span><span>    </span>.spawn();<span>
</span></code></pre></div>
</figure>
<p>Given these building blocks, I wrote <a href="https://github.com/djhworld/pngrun">pngrun</a> to run the images. It essentially…</p>
<ol>
<li>Accepts an image that has had our binary embedded in it from the steganography tool, and any arguments</li>
<li>Decodes it (i.e. extracts and re-assembles the bytes)</li>
<li>Creates an in-memory file using <code>memfd_create</code></li>
<li>Puts the bytes of the binary into the in-memory file</li>
<li>Invokes the file <code>/proc/self/fd/&lt;fd&gt;</code> as a child process, passing any arguments from the parent</li>
</ol>
<p>So you can run it like this</p>
<figure>
<div><pre><code data-lang="bash">$ pngrun htop.png
&lt;htop output&gt;
$ pngrun go.png run main.go
Hello world!</code></pre></div>
</figure>
<p>Once <code>pngrun</code> exits the in-memory file is destroyed.</p>
<h2 id="binfmt-misc">binfmt_misc</h2>
<p>It’s annoying having to type <code>pngrun</code> every time though, so my last cheap trick to this pointless gimmick was to use <a href="https://en.wikipedia.org/wiki/Binfmt_misc">binfmt_misc</a>, a system that allows you to “execute” files based on its file types. I think it was mainly designed for interpreters/virtual machines, like Java. So instead of typing <code>java -jar my-jar.jar</code> you can just type <code>./my-jar.jar</code> and it will invoke the <code>java</code> process to run your JAR. The caveat is your file <code>my-jar.jar</code> needs to be marked as executable first.</p>
<p>So adding an entry to binfmt_misc for <code>pngrun</code> to attempt to run any <code>png</code> files that have the <code>x</code> flag set was as simple as</p>
<figure>
<div><pre><code data-lang="bash">$ cat /etc/binfmt.d/pngrun.conf
:ExecutablePNG:E::png::/home/me/bin/pngrun:
$ sudo systemctl restart binfmt.d
$ chmod +x htop.png
$ ./htop.png
&lt;output&gt;</code></pre></div>
</figure>
<h2 id="what-s-the-point">What’s the point</h2>
<p>Well, there isn’t one really. I was seduced by the idea of making PNG images run programs and got a bit carried away with it, but it was fun none the less. There’s something amusing to me about distributing programs as an image, remember the ridiculous cardboard boxes PC software used to come in with artwork on the front, why not bring that back! (lets not)</p>
<p>It’s really dumb though and comes with a lot of caveats that make it completely pointless and impractical, the main one being needing the stupid <code>pngrun</code> program on your machine. But I also noticed some weird stuff around programs like <code>clang</code>. I encoded it into this fun LLVM logo and while it runs OK, it fails when you try to compile something.</p>
<figure>
<a href="https://djharper.dev/img/DragonMedium.png"><img src="https://djharper.dev/img/DragonMedium.png" title="Clang/LLVM logo"></a>
</figure>
<figure>
<div><pre><code data-lang="bash">$ ./clang.png --version
clang version <span>11</span>.0.0 <span>(</span>Fedora <span>11</span>.0.0-2.fc33<span>)</span>
Target: x86_64-unknown-linux-gnu
Thread model: posix
InstalledDir: /proc/self/fd
$ ./clang.png main.c
error: unable to execute command: Executable <span>""</span> doesn<span>'</span>t exist!</code></pre></div>
</figure>
<p>This is probably a product of the anonymous file thing, which can probably be overcome if I could be bothered to investigate.</p>
<h3 id="additional-reasons-why-this-is-dumb">Additional reasons why this is dumb</h3>
<p>A lot of binaries are quite large, and given the constraints of needing to fit them into an image, sometimes these need to be <em>big</em>, meaning you end up with comically large files.</p>
<p>Also most software isn’t just one executable so the dream of just distributing a PNG kinda falls flat for more complex software like games.</p>
<h2 id="conclusion">Conclusion</h2>
<p>This is probably the dumbest project I’ve worked on all year but it’s been fun, I’ve learned about Steganography, <code>memfd_create</code>, <code>binfmt_misc</code> and played a little more with Rust.</p>
</article>
</div></div>]]>
            </description>
            <link>https://djharper.dev/post/2020/12/26/executable-pngs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25543191</guid>
            <pubDate>Sat, 26 Dec 2020 13:04:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[China vs. Democracy: A Handbook for Democracies]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25542990">thread link</a>) | @tillulen
<br/>
December 26, 2020 | https://halifaxtheforum.org/china-handbook/en/ | <a href="https://web.archive.org/web/*/https://halifaxtheforum.org/china-handbook/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">

	<div id="content">





	<div id="fullwidth">
		<main id="main" role="main">

<article id="post-6532" class="page">
	<!-- .entry-header -->


<div>
<div>

<h3>A HANDBOOK FOR DEMOCRACIES</h3>

<p>Modern-day China has emerged as the most powerful authoritarian state in the history of the world.</p>
<p>The HFX Handbook for Democracies contributes to building a common understanding of the serious challenge that China poses.</p>
<p>The handbook features the <em><a href="https://hfxchinahandbook.s3.amazonaws.com/EN_HFX+China+Principles.pdf">HFX China Principles</a> </em>that defend the values that underpin democratic societies.</p>
<blockquote><p><strong><em>“THE REAL CHINA CHALLENGE FOR THE WORLD’S DEMOCRACIES IS HOW TO COOPERATE EFFECTIVELY WITH EACH OTHER.”</em></strong></p></blockquote>
<p><strong><a href="https://halifaxtheforum.org/china-handbook/cn/">点击这里查看中文</a> | <a href="https://halifaxtheforum.org/china-handbook/fr/">Cliquez ici pour le français</a></strong></p>
<h2>7/8 Campaign</h2>
<h3><b>Help HFX defend democratic values.</b></h3>
<p>Support the 7 HFX China Principles with a donation of $8 and together we will strengthen your government’s resolve to stand up to China.</p>
<p><a href="https://halifaxtheforum.org/china-handbook/donate-en">Donate $8</a></p>
</div>





</div></article></main></div>






	
	
	
					<!-- #main -->
	</div><!-- #primary -->
	
	


	</div></div>]]>
            </description>
            <link>https://halifaxtheforum.org/china-handbook/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25542990</guid>
            <pubDate>Sat, 26 Dec 2020 12:15:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Install Node.js]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25542906">thread link</a>) | @loige
<br/>
December 26, 2020 | https://www.nodejsdesignpatterns.com/blog/5-ways-to-install-node-js/ | <a href="https://web.archive.org/web/*/https://www.nodejsdesignpatterns.com/blog/5-ways-to-install-node-js/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><main><p>In this article, we will explore some of the most common ways to install Node.js in your development system. We will see how to install Node.js using the official installer for various platforms, how to use a Node.js version manager such as <code>n</code> or <code>nvm</code> and, finally, we will also see how to compile and install Node.js from source. Along the way, we will try to disclose one or two tips to get you even more productive with Node.js!</p><p>Let's get started!</p><h2 id="which-option-should-i-pick%3F">Which option should I pick?</h2><p>There are many different ways to install Node.js and every one of them comes with its own perks and drawbacks. In this article, we will try to explore the most common ones and by the end of it, you should have a good understanding of which ones should be more suitable for you.</p><h3 id="tldr%3B">TLDR;</h3><ul><li>Use <code>nvm</code> or <code>n</code> if you develop with Node.js frequently and you expect to be needing to switch Node.js version while moving from one project to another or to debug potential compatibility issues in your project or library.</li><li>Use the system package manager like <code>apt</code>, <code>brew</code> or <code>winget</code> if you tend to install all your software this way and if you don't expect to be needing to switch or upgrade Node.js version too often.</li><li>Install Node.js from source if you are an advanced user and if you want to contribute back to Node.js itself.</li><li>Use the official Node.js installer if you don't fall in any of the previous options...</li></ul><h3 id="what-other-people-seem-to-like">What other people seem to like</h3><p>Before writing this article, I was actually curious to find out what are the options that most folks in my network prefer. For this reason, I run a <a href="https://twitter.com/loige/status/1340999569807712257">poll on Twitter</a>. In this poll I asked how you prefer to install Node.js and provided 4 options:</p><ul><li>Official Installer</li><li>Version manager (<code>nvm</code> or <code>n</code>)</li><li>Package Manager (<code>apt</code>, <code>brew</code>, etc.)</li><li>From source</li></ul><p>The results are quite interesting:</p><a href="https://twitter.com/loige/status/1340999569807712257" rel="nofollow noreferrer"><span><picture><source type="image/png" srcset="https://www.nodejsdesignpatterns.com/img/poll-results-e006cbcf-64.png 64w, https://www.nodejsdesignpatterns.com/img/poll-results-e006cbcf-128.png 128w, https://www.nodejsdesignpatterns.com/img/poll-results-e006cbcf-256.png 256w, https://www.nodejsdesignpatterns.com/img/poll-results-e006cbcf-512.png 512w, https://www.nodejsdesignpatterns.com/img/poll-results-e006cbcf-593.png 593w" sizes="(max-width: 593px) 100vw, 593px"><source type="image/webp" srcset="https://www.nodejsdesignpatterns.com/img/poll-results-e006cbcf-64.webp 64w, https://www.nodejsdesignpatterns.com/img/poll-results-e006cbcf-128.webp 128w, https://www.nodejsdesignpatterns.com/img/poll-results-e006cbcf-256.webp 256w, https://www.nodejsdesignpatterns.com/img/poll-results-e006cbcf-512.webp 512w, https://www.nodejsdesignpatterns.com/img/poll-results-e006cbcf-593.webp 593w" sizes="(max-width: 593px) 100vw, 593px"><img loading="lazy" decoding="async" alt="Install Node.js Twitter poll results" src="https://www.nodejsdesignpatterns.com/img/poll-results-e006cbcf-64.png" width="64" height="37"></picture></span></a><p>It seems quite obvious that people in my network, mostly fellow software engineers, prefer to use version managers such as <code>nvm</code> or <code>n</code>.</p><p>The second place (actually very tight with the third one) is the official installer, followed by a system package manager and, last one, installing Node.js from source.</p><h3 id="lts-and-stable-releases">LTS and stable releases</h3><p>Before moving on and exploring all the different installation options, it is definitely worth spending few words to learn about the types of release the Node.js project maintains.</p><p>Node.js offers 2 main release lines:</p><ul><li><strong>Stable</strong> (or <em>Current</em>): every new major Node.js release is considered "Current" for the first 6 months after the publish date. The idea is to give library authors the time to test their compatibility with the new release and do any necessary change. After the 6 months period, all the odd release numbers (9, 11, 13, 15, etc.) move to the state of <em>Unsupported</em>, while even releases (10, 12, 14, etc.) are promoted to <em>Long Term Support</em> (or "LTS").</li><li><strong>LTS</strong>: releases marked as "Long Term Support" get critical bug fixes for a total of 30 months since the initial publish date. This makes LTS releases particularly suitable for production deployments. The most recent LTS is also called <em>Active LTS</em>, while previous LTS versions (still under the 30 months support timeframe) are called <em>Maintenance LTS</em>.</li></ul><p>Finally, the release coming from the current <em>master</em> branch is considered <strong>Unstable</strong>. This is generally a release dedicated to people maintaining Node.js or developers who want to explore new experimental features that haven't been yet included in any of the major releases.</p><p>Node.js publishes an <a href="https://nodejs.org/en/about/releases/">official timeline of current and future releases</a>. At the time of writing (December 2020), this how the timeline looks like:</p><a href="https://nodejs.org/en/about/releases/" target="_blank" rel="noreferrer noopener"><p><img loading="lazy" decoding="async" alt="Node.js release timeline" src="https://www.nodejsdesignpatterns.com/img/nodejs-release-schedule_9b4bf060.svg" width="760" height="396"></p></a><p>If you are still wondering which release should you use, going with the <em>Active LTS</em> is almost always the best choice, especially if you are building production applications.</p><h2 id="install-node.js-using-n">Install Node.js using n</h2><p>Since installing Node.js using a version manager seems to be the favourite option (and it's also my personal favourite!) let's start with it.</p><p>My favourite Node.js version manager is <a href="https://github.com/tj/n"><code>n</code> by TJ Holowaychuk</a>. The reason why I like it is because it is quite simple to install and use and it is generally up to date with the latest releases of Node.js. The main issue with it is that it does not support Windows, so if Windows is your operative system, this is not an option for you!</p><p>Let's see how to install <code>n</code>:</p><p>If you are on macOS and you have <code>brew</code> (Homebrew) installed, the simplest way to install <code>n</code> is to just do it with <code>brew</code>:</p><pre><code>brew <span>install</span> n</code></pre><p>Alternatively, you can use the custom install script:</p><pre><code><span>curl</span> -L https://git.io/n-install <span>|</span> <span>bash</span></code></pre><p>If all goes well, you should now be able to use the <code>n</code> executable from your shell.</p><p>These are some of the commands you can run:</p><pre><code><br>n --version<p><br>n lts</p><p><br>n list</p><p><br>n <span>&lt;</span>some_version<span>&gt;</span></p></code></pre><p>Or you can simply run:</p><pre><code>n</code></pre><p>For an interactive prompt that will show you all the available versions, highlight the ones you have already installed and let you pick the version you want to switch to.</p><p><img loading="lazy" decoding="async" alt="n Node.js version manager in action" src="https://www.nodejsdesignpatterns.com/img/n_ac172e26.gif" width="640" height="428"></p><p>In summary, this is where <code>n</code> shines or falls short:</p><ul><li>ðŸ‘Ž No official support for Windows</li><li>ðŸ‘� Very easy to install on macOS and unix systems</li><li>ðŸ‘� Very easy to keep your Node.js install up to date and switch version on demand</li><li>ðŸ‘� It keeps all the installed versions cached, so you can switch quickly between versions (no full re-install)</li><li>ðŸ‘� Allows to keep the setup local to the user so you don't have to use admin permission to install global packages</li></ul><h2 id="install-node.js-using-nvm">Install Node.js using nvm</h2><p>With more than 45 thousand stars on GitHub, <a href="https://github.com/nvm-sh/nvm"><code>nvm</code></a>, which stands for "Node.js Version Manager" (no surprises!), is probably the most famous Node.js version manager currently available.</p><p><code>nvm</code> works on any POSIX-compliant shell (<code>sh</code>, <code>dash</code>, <code>ksh</code>, <code>zsh</code>, <code>bash</code>, etc.) and it has been strongly tested against the following systems: unix, macOS, and windows WSL.</p><p>The easiest way to install <code>nvm</code> on your system is to use the official installer script:</p><pre><code><span>VERSION</span><span>=</span>v0.37.2<br><span>curl</span> -o- <span>"https://raw.githubusercontent.com/nvm-sh/nvm/<span>${VERSION}</span>/install.sh"</span> <span>|</span> <span>bash</span></code></pre><p><strong>Note</strong>: At the time of writing, version <code>v0.37.2</code> is the latest version available. Make sure to check out if there is any new version available if you are installing <code>nvm</code> following this tutorial.</p><p>Once <code>nvm</code> is installed in your system, here are some examples showing what you can do with it:</p><pre><code><br>nvm <span>install</span> node<p><br>nvm <span>install</span> --lts</p><p><br>nvm <span>install</span> <span>"10.10.0"</span></p><p><br>nvm use <span>"8.9.1"</span></p><p><br>nvm <span>exec</span> <span>"4.2"</span> node somescript.js</p><p><br>nvm <span>which</span> <span>"4.2"</span></p><p><br>nvm <span>ls</span></p></code></pre><p>One great thing about <code>nvm</code> is that it allows to specify the Node.js version you want to use for a given project.</p><p>For instance, if you are working on a project that requires you to use Node.js <code>10.10</code> you can do the following (in the root folder of the project):</p><pre><code><span>echo</span> <span>"10.10"</span> <span>&gt;</span> .nvmrc</code></pre><p>Then every time you work on that project, you only need to run:</p><pre><code>nvm use</code></pre><p>Which should print something like this:</p><pre><code>Found '/path/to/project/.nvmrc' with version &lt;10.10&gt;
Now using node v10.10.1 (npm v6.7.3)
</code></pre><p>At this point, you can be sure that you working using the correct Node.js version for your project.</p><p>If you don't want to do manually, you can enable <a href="https://github.com/nvm-sh/nvm#deeper-shell-integration">deeper shell integration</a> to make this happen automatically when you <code>cd</code> into a folder that has a <code>.nvmrc</code> file.</p><p><strong>PRO tip</strong>: You can also do that by using <a href="https://asdf-vm.com/"><code>asdf</code></a>, a <em>meta</em> version manager that offers a unified interface for various programming languages and version managers (including Node.js, of course).</p><p>Finally, here are some pros and cons of <code>nvm</code>:</p><ul><li>ðŸ‘� Most popular version manager for Node.js with a large community of users.</li><li>ðŸ‘� Very easy to install on POSIX systems.</li><li>ðŸ‘� It allows for easy (and even automated) switch of Node.js version based on the project you are working on.</li><li>ðŸ‘� It keeps all the installed versions cached, so you can switch quicly between versions (no full re-install)</li><li>ðŸ‘� You can run once off commands on a given version of Node.js without having to switch the entire system to that version.</li><li>ðŸ‘Ž You might have to take a bit of time to go through the documentation and make sure you install it and use it correctly.</li></ul><h2 id="install-node.js-using-the-official-installer">Install Node.js using the official installer</h2><p>The second most common way to install Node.js is through one of the official installers or the pre-compiled binaries.</p><p><a href="https://nodejs.org/en/download/">Official installers</a> are available on the official Node.js website for Windows and macOS and they cover the latest <em>Active LTS</em> release and the latest <em>Current</em> release.</p><p>The installer for Windows is an executable <em>.msi</em> installer, while the one for macOS is a <em>.pkg</em> one.</p><p>These installers behave and look like most of the installers you see while installing software on Windows or macOS. You will be presented with clickable UI which will allow you to customise and install Node.js into your system.</p><span><picture><source type="image/png" srcset="https://www.nodejsdesignpatterns.com/img/node-js-macos-installer-screenshot-477753f7-64.png 64w, https://www.nodejsdesignpatterns.com/img/node-js-macos-installer-screenshot-477753f7-128.png 128w, https://www.nodejsdesignpatterns.com/img/node-js-macos-installer-screenshot-477753f7-256.png 256w, https://www.nodejsdesignpatterns.com/img/node-js-macos-installer-screenshot-477753f7-512.png 512w, https://www.nodejsdesignpatterns.com/img/node-js-macos-installer-screenshot-477753f7-732.png 732w" sizes="(max-width: 732px) 100vw, 732px"><source type="image/webp" srcset="https://www.nodejsdesignpatterns.com/img/node-js-macos-installer-screenshot-477753f7-64.webp 64w, https://www.nodejsdesignpatterns.com/img/node-js-macos-installer-screenshot-477753f7-128.webp 128w, https://www.nodejsdesignpatterns.com/img/node-js-macos-installer-screenshot-477753f7-256.webp 256w, https://www.nodejsdesignpatterns.com/img/node-js-macos-installer-screenshot-477753f7-512.webp 512w, https://www.nodejsdesignpatterns.com/img/node-js-macos-installer-screenshot-477753f7-732.webp 732w" sizes="(max-width: 732px) 100vw, 732px"><img loading="lazy" decoding="async" alt="Install Node.js using the official macOS installer" src="https://www.nodejsdesignpatterns.com/img/node-js-macos-installer-screenshot-477753f7-64.png" width="64" height="48"></picture></span><p>This is probably the easiest way to install Node.js as you don't need to be a POSIX expert or do any kind of manual configuration. The installer will suggest sensible defaults to you and allow you to customise the main parameters (e.g. installation path).</p><p>If you are running a unix system, there is no official graphical installer available, but the <a href="https://nodejs.org/dist/">official Node.js download page</a> offers a set of pre-compiled binaries for most architectures (32-bit, 64-bit, ARMv7 and ARMv8) for Linux, Windows and macOS.</p><span><picture><source type="image/png" srcset="https://www.nodejsdesignpatterns.com/img/node-js-macos-precompiled-binary-bd4ce1d0-64.png 64w, https://www.nodejsdesignpatterns.com/img/node-js-macos-precompiled-binary-bd4ce1d0-128.png 128w, https://www.nodejsdesignpatterns.com/img/node-js-macos-precompiled-binary-bd4ce1d0-256.png 256w, https://www.nodejsdesignpatterns.com/img/node-js-macos-precompiled-binary-bd4ce1d0-512.png 512w, https://www.nodejsdesignpatterns.com/img/node-js-macos-precompiled-binary-bd4ce1d0-1077.png 1077w" sizes="(max-width: 700px) 100vw, 700px"><source type="image/webp" srcset="https://www.nodejsdesignpatterns.com/img/node-js-macos-precompiled-binary-bd4ce1d0-64.webp 64w, https://www.nodejsdesignpatterns.com/img/node-js-macos-precompiled-binary-bd4ce1d0-128.webp 128w, https://www.nodejsdesignpatterns.com/img/node-js-macos-precompiled-binary-bd4ce1d0-256.webp 256w, https://www.nodejsdesignpatterns.com/img/node-js-macos-precompiled-binary-bd4ce1d0-512.webp 512w, https://www.nodejsdesignpatterns.com/img/node-js-macos-precompiled-binary-bd4ce1d0-1077.webp 1077w" sizes="(max-width: 700px) 100vw, 700px"><img loading="lazy" decoding="async" alt="Install Node.js using the official macOS installer" src="https://www.nodejsdesignpatterns.com/img/node-js-macos-precompiled-binary-bd4ce1d0-64.png" width="64" height="26"></picture></span><p>With the binary distribution, it is up to you to copy the necessary files in the right place. A version manager tool such as <code>nvm</code> and <code>n</code> makes things simple, because it takes care of downloading the correct binary release for the desired version (and for your system), then it places the files in the correct folder as expected by your operative system. If you choose to download the binaries manually, all the wiring is up to you.</p><p>While installing Node.js using the official installers is probably the simplest option, doing it using the binaries is a lot more complicated and definitely more complicated than using a version manager.</p><p>If you still want to go down this path, make sure to check out the <a href="https://github.com/nodejs/help/wiki/Installation">official tutorial for installing from Node.js pre-compiled binaries</a>.</p><p>It is definitely worth mentioning that the official installer is not the only option. <a href="https://nodesource.com/">NodeSource</a> maintains alternative installers for Debian, Red Hat, macOS and Windows. If you are interested in this approach checkout <a href="https://node.dev/node-binary">NodeSource Node.js Binary distributions page</a>.</p><p>To summarise, these are the main pros and cons of Node.js installers and …</p></main></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.nodejsdesignpatterns.com/blog/5-ways-to-install-node-js/">https://www.nodejsdesignpatterns.com/blog/5-ways-to-install-node-js/</a></em></p>]]>
            </description>
            <link>https://www.nodejsdesignpatterns.com/blog/5-ways-to-install-node-js/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25542906</guid>
            <pubDate>Sat, 26 Dec 2020 11:56:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Embrace the Splinternet Without Flinching]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25542844">thread link</a>) | @URfejk
<br/>
December 26, 2020 | https://cheapskatesguide.org/articles/splinternet.html | <a href="https://web.archive.org/web/*/https://cheapskatesguide.org/articles/splinternet.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://cheapskatesguide.org/articles/splinternet.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25542844</guid>
            <pubDate>Sat, 26 Dec 2020 11:45:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Matlab vs. Julia vs. Python (2019)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25542594">thread link</a>) | @blewboarwastake
<br/>
December 26, 2020 | https://tobydriscoll.net/blog/matlab-vs.-julia-vs.-python/ | <a href="https://web.archive.org/web/*/https://tobydriscoll.net/blog/matlab-vs.-julia-vs.-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>I’ve used 
<a href="https://www.mathworks.com/matlab" target="_blank" rel="noopener">MATLAB</a> for over 25 years. (And before that, I even used 
<a href="https://www.sciencedirect.com/science/article/pii/S1474667017616793" target="_blank" rel="noopener">MATRIXx</a>, a late, unlamented attempt at a spinoff, or maybe a ripoff.) It’s not the 
<a href="https://en.wikipedia.org/wiki/BASIC" target="_blank" rel="noopener">first language I learned to program in</a>, but it’s the one that I came of age with mathematically. Knowing MATLAB has been very good to my career.</p>
<p>However, it’s impossible to ignore the rise of Python in scientific computing. MathWorks must feel the same way: not only did they add the ability to 
<a href="https://www.mathworks.com/help/matlab/call-python-libraries.html" target="_blank" rel="noopener">call Python directly from within MATLAB</a>, but they’ve adopted borrowed some of its language features, such as more aggressive 
<a href="https://www.mathworks.com/help/matlab/matlab_prog/compatible-array-sizes-for-basic-operations.html" target="_blank" rel="noopener">broadcasting</a> for operands of binary operators.</p>
<p>It’s reached a point where I have been questioning my continued use of MATLAB in both research and teaching. Yet so much comes easily to me there, and I have so much invested in materials for it, that it was hard to rally motivation to really learn something new.</p>
<p>Enter the MATLAB-based 
<a href="https://tobydriscoll.net/FNC" target="_blank" rel="noopener">textbook</a> I’ve co-written for introductory computational math. The book has over 40 functions and 160 computational examples, and it covers what I think is a thorough grounding in the use of MATLAB for numerical scientific computing. So partly as self-improvement, and partly to increase the usefulness of the book, I set out this year to translate the codes into 
<a href="https://github.com/tobydriscoll/fnc-extras/tree/master/julia" target="_blank" rel="noopener">Julia</a> and 
<a href="https://github.com/tobydriscoll/fnc-extras/tree/master/python" target="_blank" rel="noopener">Python</a>. This experience has led me to a particular perspective on the three languages in relation to scientific computing, which I attempt to capture below.</p>
<p>I will mostly set aside the issues of cost and openness. MATLAB, unlike Python and Julia, is neither beer-free nor speech-free. This is indeed a huge distinction—for some, a dispositive one–but I want to consider the technical merits. For many years, MATLAB was well beyond any free product in a number of highly useful ways, and if you wanted to be productive, then cost be damned. It’s a separate consideration from the Platonic appeal of a language and ecosystem.</p>
<p>When you do set cost aside, a useful frame for a lot of the differences among these languages lies in their origins. MATLAB, the oldest of the efforts, prioritized math, particularly numerically oriented math. Python, which began in earnest in the late 1980s, made computer science its central focus. Julia, which began in 2009, set out to strike more of a balance between these sides.</p>
<h2 id="matlab">MATLAB</h2>
<p>Originally, every value in MATLAB was an array of double-precision floating point numbers. Both aspects of this choice, arrays and floating point, were inspired design decisions.</p>
<p>The IEEE 754 standard for floating point wasn’t even adopted until 1985, and memory was measured in K, not G. Floating point doubles weren’t the most efficient way to represent characters or integers, but they were what scientists, engineers, and, increasingly, mathematicians wanted to use most of the time. Furthermore, variables did not have to declared and memory did not have to be explicitly allocated. Letting the computer handle those tasks, and whisking data types out of the way, freed up your brain to think about the algorithms that would operate on the data.</p>
<p>Arrays were important because numerical algorithms in linear algebra were coming into their own, in the form of 
<a href="https://en.wikipedia.org/wiki/LINPACK" target="_blank" rel="noopener">LINPACK</a> and 
<a href="https://en.wikipedia.org/wiki/EISPACK" target="_blank" rel="noopener">EISPACK</a>. But accessing them with the standard bearer in scientific computing, FORTRAN 77, was a multistep process that involved declaring variables, calling cryptically named routines, compiling code, and then examining data and output files. Writing a matrix multiplication as <code>A*B</code> and getting the answer printed out right away was a game-changer.</p>
<p>MATLAB also made graphics easy and far more accessible. No fiddly machine-specific libraries with low-level calls, just <code>plot(x,y)</code> and you saw pretty much what anyone else with MATLAB would see. There were more innovations, like baked-in complex numbers, sparse matrices, tools to build cross-platform graphical user interfaces, and a leading-edge suite of ODE solvers, that made MATLAB <em>the</em> place to do scientific computing at the speed of thought.</p>
<p>However, design that was ideal for interactive computations, even lengthy ones, was not always conducive to writing good and performant software. Moving data around between many functions required juggling lots of variables and frequent consultation of documentation about input and output arguments. One function per disk file in a flat namespace was refreshingly simple for a small project, but a headache for a large one. Certain programming patterns (vectorization, memory preallocation) had to be applied if you wanted to avoid speed bottlenecks. Scientific computing was now being applied to far more domains, with vast amounts of different native types of data. Etc.</p>
<p>MathWorks responded by continuing to innovate within MATLAB: inline functions, nested functions, variable closures, numerous data types, object-oriented features, unit testing frameworks, and on and on. Each innovation was probably the solution to an important problem. But the accumulation of 40 years of these changes has had the side effect of eroding the simplicity and unity of concept. In 2009 I wrote a 
<a href="https://tobydriscoll.net/project/learning-matlab/" target="_blank" rel="noopener">book</a> that pretty well covered what I considered the essentials of MATLAB in less than 100 pages. As far as I know, all of those things are still available. But you need to know a lot more now to call yourself proficient.</p>
<h2 id="python">Python</h2>
<p>In a sense the history of Python seems to be almost a mirror image of MATLAB’s. Both featured an interactive command line (now widely called a REPL, for “read-eval-print loop”) and freedom from variable declarations and compilation. But MATLAB was created as a playground for numerical analysts, while Python was created with hackers in mind. Each then grew toward the other audience through revisions and extensions.</p>
<p>To my eye, Python still lacks mathematical appeal. You have ugliness and small annoyances such as <code>**</code> instead of <code>^</code>, <code>@</code> for matrix multiplication (a recent innovation!), a <code>shape</code> rather than size of a matrix, row-oriented storage, etc. If you believe that <code>V.conj().T@D**3@V</code> is an elegant way to write $V^*D^3V$, then you may need to see a doctor. And there’s zero-indexing (as opposed to indexes that start at 1). I’ve 
<a href="https://www.cs.utexas.edu/users/EWD/transcriptions/EWD08xx/EWD831.html" target="_blank" rel="noopener">read the arguments</a>, and I don’t find them decisive. It’s clearly a matter of preference—the stuff of online holy wars—because you can cite ungainly examples for either convention. What I find decisive is that we have decades of mathematical practice indexing vectors and matrices from one, and most pseudocode makes that assumption.</p>
<p>Beyond the petty annoyances, I find the Python+NumPy+SciPy ecosystem to be kludgy and inconsistent. Exhibit A is the fact that despite the language being rather devoted to object orientation, there exists a matrix class, and yet its use is 
<a href="https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html" target="_blank" rel="noopener">discouraged and will be deprecated</a>. Perhaps MATLAB has simply corrupted me, but I find matrices to be an important enough type of object to keep around and promote. Isn’t a major selling point of OOP that you can have <code>*</code> do different things for arrays and matrices? There are many other infelicities in this regard. (Why do I need a command called 
<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.spsolve.html#scipy.sparse.linalg.spsolve" target="_blank" rel="noopener">spsolve</a>? Can’t I just call <code>solve</code> on a sparse matrix? And on and on.)</p>
<p>There are also places where the numerical ecosystem looks a little thin to me. For instance, the 
<a href="https://docs.scipy.org/doc/scipy/reference/integrate.html" target="_blank" rel="noopener">quadrature and ODE solvers</a> look like a minimal set in 2019. AFAICT there are no methods for DAEs, DDEs, symplectic solvers, or implicit solvers that allow inner Krylov iterations. Have a look at the references for these functions; they’re mostly 30 or more years old—still good, but very far from complete. The Matplotlib package is an amazing piece of work, and for a while it looked better than MATLAB, but I find it quite lacking in 3D still.</p>
<p>Some experts argue that there are deep reasons why Python code struggles to keep up in execution speed with compiled languages. I’m amused by the results of searching for 
<a href="https://www.google.com/search?q=python+is+too+slow&amp;oq=python+is+too+slow" target="_blank" rel="noopener">“python is too slow”</a>. The champions of Python make a lot of the same arguments/apologies that folks did for MATLAB back in the day. That doesn’t mean they’re wrong, but 
<a href="https://modelingguru.nasa.gov/docs/DOC-2676" target="_blank" rel="noopener">there’s more than just a perception problem</a>.</p>
<p>I think I get why Python has been so exciting to many people in scientific computing. It has a some MATLAB-ish syntax and power, available from a REPL. It has great tools around it and plays well with other languages and areas of computing. It offered that at no cost and with much better long-term reproducibility. Clearly, it works well for a lot of people who probably see little reason to change.</p>
<p>But for the things I know how to do in scientific computing, Python feels much more like a chore to learn and use than I’m used to. We won’t know for a while whether it will continue to sweep through the community or has already neared its peak. I have no special predictive powers, but I’m bearish.</p>
<h2 id="julia">Julia</h2>
<p>Julia has the advantages and disadvantages of being a latecomer. I applaud the Julia creators for 
<a href="https://julialang.org/blog/2012/02/why-we-created-julia" target="_blank" rel="noopener">thinking they could do better</a>:</p>
<blockquote>
<p>We want a language that’s open source, with a liberal license. We want the speed of C with the dynamism of Ruby. We want a language that’s homoiconic, with true macros like Lisp, but with obvious, familiar mathematical notation like Matlab. We want something as usable for general programming as Python, as easy for statistics as R, as natural for string processing as Perl, as powerful for linear algebra as Matlab, as good at gluing programs together as the shell. Something that is dirt simple to learn, yet keeps the most serious hackers happy. We want it interactive and we want it compiled.</p>
</blockquote>
<p>To a great extent, I believe they have succeeded. Late along the road to version 1.0 they seemed to downplay the REPL a bit, and there were some almost gratuitous lurches away from MATLAB. (How exactly is <code>LinRange</code> better than <code>linspace</code>?) These are quibbles, though.</p>
<p>This is the first language I’ve used that goes beyond ASCII. I still get an unreasonable amount of satisfaction from using variables like <code>ϕ</code> and operators like <code>≈</code>. It’s more than cosmetic; being able to look more like the mathematical expressions we …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tobydriscoll.net/blog/matlab-vs.-julia-vs.-python/">https://tobydriscoll.net/blog/matlab-vs.-julia-vs.-python/</a></em></p>]]>
            </description>
            <link>https://tobydriscoll.net/blog/matlab-vs.-julia-vs.-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25542594</guid>
            <pubDate>Sat, 26 Dec 2020 10:39:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Johnny Depp Titles Removed from Netflix US]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25542552">thread link</a>) | @smsm42
<br/>
December 26, 2020 | https://www.thegeekbuzz.com/the-basement/johnny-depp-titles-removed-from-netflix/ | <a href="https://web.archive.org/web/*/https://www.thegeekbuzz.com/the-basement/johnny-depp-titles-removed-from-netflix/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div>

	
			<p>Netflix no longer has any Johnny Depp films streaming in their American library. Coincidence or reaction to his legal loss?</p>
	
					
	<p>Though there has been no official statement from <em>Netflix</em>, the streaming giant has apparently removed all <em>Johnny Depp</em> titles from its American library. This news comes on the heels of actor <strong>Shia LaBeouf</strong> being removed from Netflix’s award consideration website&nbsp;and publicity materials following&nbsp;recent allegations&nbsp;of&nbsp;physical, emotional, and mental abuse. As of this writing, several titles with LaBeouf were still on Netflix. Likewise, Depp titles can still be accessed on Netflix outside the United States.</p>
<p>Depp <a href="https://www.thegeekbuzz.com/the-basement/johnny-depp-loses-to-the-sun-amber-heard-in-gripping-uk-court-case/" target="_blank" rel="noopener noreferrer">lost a high-profile libel case</a> in the UK last month against the Sun who called the fading former A-lister a wifebeater. In his decision, <strong>Judge Nicol</strong> said, “taking all evidence together, I accept [<strong>Amber Heard</strong>] was the victim of sustained and multiple assaults by Depp. I accept her evidence of the nature of the assaults he committed against her. They must have been terrifying.”</p>
<p>This may have been a delayed reaction to the results of that trial, timed to correspond with their actions on LaBeouf, or it may just be part of Netflix’s standard cycling of titles in and out of their library.</p>
<p>The former Captain Jack Sparrow was also featured in a <a href="https://www.thegeekbuzz.com/the-basement/the-hollywood-reporters-devastating-expose-on-johnny-depp/" target="_blank" rel="noopener noreferrer">scathing article</a> by <em>The Hollywood Reporter</em> earlier this month in which several Hollywood insiders portrayed him as toxic.</p>
<p>According to satista.com, Netflix had 195.15 million paid subscribers worldwide as of the third quarter&nbsp;<b>of 2020</b>. Most Netflix subscribers are based in the United States, with the U.S. accounting for over&nbsp;<b>73 million</b> of Netflix’s total global subscriber base.&nbsp; They’re not likely to be intimidated by threats of boycotts from fans of Johnny Depp. Disney + still has several available to stream, but they’re under a boycott by Depp fans already.</p>
<p>UPDATE: <a href="https://www.whats-on-netflix.com/news/did-netflix-remove-johnny-depp-movies/" rel="noopener noreferrer" target="_blank">What’s On Netflix</a>, a Netflix fansite, says the removal of Depp titles is as we mentioned above: “part of Netflix’s standard cycling of titles in and out of their library.” It also states this rumor began with Johnny Depp fans.</p>
<p>RELATED: <a href="https://www.thegeekbuzz.com/rumors/see-leonardo-dicaprio-as-johnny-depps-replacement-in-pirates-of-the-caribbean-6/">See Leonardo DiCaprio as Johnny Depp’s Replacement</a> in Pirates of the Caribbean 6!</p>

	
	
				</div>			</div></div>]]>
            </description>
            <link>https://www.thegeekbuzz.com/the-basement/johnny-depp-titles-removed-from-netflix/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25542552</guid>
            <pubDate>Sat, 26 Dec 2020 10:28:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Still Rusting – One Year Later]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25542280">thread link</a>) | @lukastyrychtr
<br/>
December 26, 2020 | https://deislabs.io/posts/still-rusting-one-year-later/ | <a href="https://web.archive.org/web/*/https://deislabs.io/posts/still-rusting-one-year-later/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<p>It has been about a year since the DeisLabs team starting using Rust in a “serious” project. About this time last year, we started work on what became the <a href="https://github.com/deislabs/krustlet">Krustlet</a> project. Since then, we have been using Rust extensively across our projects and have learned a ton more about the language’s strengths and weaknesses. As “Rust After the Honeymoon” posts currently seem to be all the rage, we thought we could contribute a little to the discussion with our experiences writing applications for the cloud world.</p>

<p>This post is organized using the classic (if not tired) good, bad, and ugly structure. In the bad and ugly sections, everything is stated as points of feedback and is not meant as a complaint. The whole point of this post is to go beyond the more superficial parts of the language and into things that really make a difference in our day-to-day programming work. Spoiler alert: We still <em>really</em> like Rust, so all of this is intended as helpful data for those working on the language, to give people new to the language a good idea of some of the things they might run into, and to help others evaluate Rust for their own use. We have tried to incorporate ideas of possible solutions, no matter how vague, to the problems we bring up.</p>

<p>At the very end, we also have a bonus feature about Go and Rust. Given the team’s background in many Go projects, we often hear something like this: “Well, what about Go? Do you regret moving to Rust? What do you miss from Go?” Addressing this in the context of our discussion of Rust felt like a smart decision. If you don’t care about that topic or it doesn’t interest you, feel free to skip it.</p>

<p>Now with that out of the way, let’s get going!</p>

<h2 id="the-good">The Good</h2>

<h3 id="traits">Traits</h3>

<p>First up, let’s talk about traits. We have absolutely loved the trait system in Rust. In particular, we really enjoy the conversion and reference traits (e.g. <code>TryFrom</code>/<code>From</code>, <code>AsRef</code>, <code>FromStr</code>, <code>Deref</code>, etc.). These are great examples of why traits are better than most other interface-style types – because the type itself doesn’t have to implement an interface to be used as another type. <code>FromStr</code> allows any type to implement a way to parse a bare string into a type (really useful for APIs). Another simple example can be found in the many types that implement <code>AsRef&lt;[u8]&gt;</code> or <code>Deref&lt;Type = [u8]&gt;</code>. Instead of having some sort of <code>Bytes</code> interface that all the types have to implement to be able to do operations as if it was a slice of bytes, you can just automatically pick up the methods from the underlying type. Yes, I know you could embed types or use inheritance, but the elegance of this is quite nice. This also allows me to write custom types and have easy/cheap conversions or references to them from other external types. It leads to generic parameters that look like this:</p>

<pre><code>// A function that can write anything that can be accessed as bytes:
// write_all("hello!")
// write_all(String::from("hello!"))
// write_all(b"hello!")
fn write_all&lt;T: AsRef&lt;[u8]&gt;&gt;(data: T)

// Or, I can take anything that can be converted to my custom type
fn do_something&lt;T: Into&lt;MyType&gt;&gt;(thing: T)
</code></pre>

<p>Basically, traits allow you to design flexible APIs for users that allow them to latch on to and/or extend the functionality of your code. This leads to my next point – <a href="https://serde.rs/">Serde</a>.</p>

<h3 id="a-love-letter-to-serde">A Love Letter to Serde</h3>

<p>Allow us to indulge in a brief love letter to Serde, the much-used serialization/deserialization library leveraged across the Rust ecosystem. To us, it is a first-rate product of Rust’s unique combination of features. It leverages macros, traits, and Rust’s emphasis on zero-cost abstractions to create a library that is powerful, easy to use, and performant. Developers can easily add serialization or deserialization with a simple <code>#[derive(Serialize, Deserialize)]</code> and then customize deserialization behaviors with attributes. Even if you have to implement it manually, there are plenty of docs to read. Once those traits are implemented, any serialization format that has a Serde implementation (like JSON, YAML, etc.) can then serialize or deserialize that data.</p>

<h3 id="error-handling-option-and-iter">Error handling, <code>Option</code>, and <code>Iter</code></h3>

<p>Another thing high on our “impressive Rust features” list is an amazing set of mapping, unwrapping, and iteration tools. The built in <code>Result</code> and <code>Option</code> types combined with their various mapping methods (and <code>if let</code> or <code>let thing = match {...}</code>) makes it easy to handle errors/missing data in an easy to read way. It also nudges you towards clean and readable error handling patterns (like the try <code>?</code> operator), which is helpful for people new to the language. On top of the error handling, we have the <code>Iterator</code> trait and its associated methods. There are a whole suite of chainable filters, maps, splitting, and zipping methods (similar to how LINQ and functional programming languages handle collections) along with the all-powerful <code>collect</code> method. Below is an example from Krustlet that shows unwrapping an optional value and then mapping and filtering from a collection of data:</p>

<pre><code>fn mount_setting_for(key: &amp;str, items_to_mount: &amp;Option&lt;Vec&lt;KeyToPath&gt;&gt;) -&gt; ItemMount {
    match items_to_mount {
        None =&gt; ItemMount::MountAt(key.to_string()),
        Some(items) =&gt; ItemMount::from(
            items
                .iter()
                .find(|kp| kp.key == key)
                .map(|kp| kp.path.to_string()),
        ),
    }
}
</code></pre>

<h3 id="enums">Enums</h3>

<p>We’ve found Rust enums really expressive and convenient. Rust enums aren’t just single values: they can carry associated data. What’s more, each variant can have a different data structure (like discriminated unions from other languages), and you can work with these different cases using pattern matching. They’re also full-blown types, so you can implement functions and traits on them.</p>

<p>The value of this is that you can bundle a bunch of possible cases into a single type to pass into (or return from) and function. Working with the cases is safe because you don’t need to have optional fields that only may apply to certain cases, and you can only access a case’s data when the enum matches that case. The case structure also encourages code that processes enums to adopt a clear, regular layout, making for some quite beautiful code:</p>

<pre><code>pub enum ClientError {
    /// The item already exists
    AlreadyExists,
    /// The error returned when the request is invalid. Contains the underlying HTTP status code and
    /// any message returned from the API
    InvalidRequest {
        status_code: reqwest::StatusCode,
        message: Option&lt;String&gt;,
    },
    /// A server error was encountered. Contains an optional message from the server
    ServerError(Option&lt;String&gt;),
}

pub fn handle_error(e: ClientError) {
    match e {
        ClientError::AlreadyExists =&gt; {
            println!("Item already exists")
        }
        ClientError::InvalidRequest { status_code, message } =&gt; {
            println!("Invalid request. HTTP code: {}, message: {}", status_code, message.unwrap_or_default())
        }
        ClientError::ServerError(Some(message)) =&gt; {
            println!("Server error: {}", message)
        },
        ClientError::ServerError(None) =&gt; {
            println!("Server error")
        },
        
    }
}
</code></pre>

<p>In this example, we created a simple error type and then unwrapped it according to the data contained inside of each variant. The Rust compiler makes sure we handle all variants of the enum, preventing programmer error (likely from getting distracted by a meme someone posted in chat).</p>

<h3 id="grab-bag">Grab Bag</h3>

<ul>
<li>Macros are awesome and allow you to do some powerful things (and clean up code)</li>
<li>Cargo still has our hearts. It is hands down one of the top dependency manager and build tools we’ve used</li>
<li>To quote a coworker: “NO DAMN NULL POINTERS” (emphasis theirs). You explicitly have to label code as <code>unsafe</code> to even get them</li>
</ul>

<h2 id="the-bad">The Bad</h2>

<h3 id="docs-and-clarity">Docs and Clarity</h3>

<p>As we have been using various crates across the ecosystem, we’ve found some interesting patterns in the documentation. Docs are sometimes unclear on what is happening in the actual code. They describe the functionality well, but we generally have to go digging through the code to find out whether it is truly a zero cost abstraction or if there are possible side effects to what we are doing. When you first start on projects, generally these kinds of details don’t matter. But as you start doing things that require more advanced usage, you end up digging under the hood to see what exactly is going on. For example, if we are using a library that writes data to disk, make sure to clarify which methods flush data or close things down.</p>

<p>Related to this, but slightly different, is trait documentation. As users, if we are trying to find out how we can customize behavior, we always end up jumping through a million functions, looking at all the trait bounds, before we can figure out what we need to implement (It also seems to always be a trait imported from <em>another</em> crate). An example of this from some recent work on Krustlet. We were using the <a href="https://docs.rs/tonic/0.3.1/tonic/"><code>tonic</code></a> crate and implementing a socket listener for the server. We ended up at one of the functions that allows for a custom handler, but that had 3-4 distinct bounds, 2 of which were traits from external crates. We eventually found an example in the crate repo and it wasn’t too difficult, but there was no clear documentation what needed to be implemented without digging more. This experience is <em>really really frustrating</em> for new Rust developers and we’ve seen this in multiple crates. The suggestion here would be to put a little more polish into describing what precisely needs to be implemented (even if just linking to an example) on functions with multiple trait bounds.</p>

<h3 id="missing-pieces">Missing Pieces</h3>

<p>Something to be aware of coming into the Rust ecosystem is that a lot of crates are still missing features. A recent example of this was finding out that there isn’t much support for <code>multipart</code> content types in HTTP requests except for <code>multipart/form-data</code>. This is not meant to be a complaint against any developer of any crate. We …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://deislabs.io/posts/still-rusting-one-year-later/">https://deislabs.io/posts/still-rusting-one-year-later/</a></em></p>]]>
            </description>
            <link>https://deislabs.io/posts/still-rusting-one-year-later/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25542280</guid>
            <pubDate>Sat, 26 Dec 2020 09:11:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Hacker News Daily – Lightweight glance over the past best stories]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25542226">thread link</a>) | @lopespm
<br/>
December 26, 2020 | https://lopespm.github.io/hackernews-daily | <a href="https://web.archive.org/web/*/https://lopespm.github.io/hackernews-daily">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<div>
						<a href="https://news.ycombinator.com/item?id=25558587">
						
							
								<p>"Oakland relaxed a lot of zoning, and permitting regulations about 5 years ago, and so now you're starting to really see production sky rocket. This article [0] mentions 2019 was had 15x more units completed than 2018. And 3x the total units from 2013-2018 combined. Anecdotally, I have several friends who've all moved to Oakland in the last year or so. It will be interesting to see how this plays out, and maybe, hopefully, SF will take the hint.[0] - https://www.city-journal.org/oakland-rezoning-california-hou..."</p>
							
						
							
								<p>"Don't ask, Don't get.Everyone I know who has asked for a discount has got the discount.After several months of the pandemic, and noticing the adjacent apartment being relisted by my landlord at a discount I emailed my landlord and asked if I could have my rent adjusted by the same discount. They said yes, if I committed to another years lease.Saving 5% of rent, at the cost of a one year commitment didn't seem like a win, so I politely declined explaining my reasoning, and suggested we leave things as they are.A week or so later, out of the blue by my rent got adjusted by 10%+ instead of 5% with no need to commit to stay.Sufficed to say, if their intention was for me to stay put, it worked!"</p>
							
						
							
								<p>"&gt; the weighted average asking rent for an apartment in the city, which currently measures around 2.3 bedrooms when counting a studio as having one, has dropped to $3,100 a month.Still too high. Was checking into apartment prices earlier in the year and it is amazing the number of landlords that will try and sell you on a “kitchen” that is a mini-fridge, tiny sink, microwave and a hot plate whilst still charging you full rent.San Francisco’s rental market is a good lesson in how supply and demand informs pricing that the residents and the Board of Supervisors alike continuously and willfully ignore."</p>
							
						
						</a>
					</div>
				</div></div>]]>
            </description>
            <link>https://lopespm.github.io/hackernews-daily</link>
            <guid isPermaLink="false">hacker-news-small-sites-25542226</guid>
            <pubDate>Sat, 26 Dec 2020 08:51:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WebGL Shader Experiment]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25542101">thread link</a>) | @germanka
<br/>
December 26, 2020 | https://gyro851.github.io/webgl-shader-experiment/ | <a href="https://web.archive.org/web/*/https://gyro851.github.io/webgl-shader-experiment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://gyro851.github.io/webgl-shader-experiment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25542101</guid>
            <pubDate>Sat, 26 Dec 2020 08:08:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Curl Year 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25542012">thread link</a>) | @sandebert
<br/>
December 25, 2020 | https://daniel.haxx.se/blog/2020/12/24/the-curl-year-2020/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/12/24/the-curl-year-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
		
	
	<!-- #masthead -->

	<div id="main">

	<div id="primary">
		<div id="content" role="main">
			
<article id="post-15375">
	
		<p><img width="672" height="372" src="https://daniel.haxx.se/blog/wp-content/uploads/2017/12/fireworks-180553_1920-672x372.jpg" alt="" loading="lazy" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2017/12/fireworks-180553_1920-672x372.jpg 672w, https://daniel.haxx.se/blog/wp-content/uploads/2017/12/fireworks-180553_1920-1038x576.jpg 1038w" sizes="(max-width: 672px) 100vw, 672px">		</p>

		
	<!-- .entry-header -->

		<div>
		
<p>As we’re approaching the end of the year, I just want to sum up the curl year with a few words.</p>



<p>2020 has been another glorious year in the curl project. We’ve seen a series of accomplishments and introductions of new things during this the year of the plague.</p>



<h2>Accomplishments</h2>



<p>I personally have done more commits in the git repository since any year after 2004 (890 so far).</p>



<p>The total number of commits done in git is the largest since 2014 (1445 plus some).</p>



<p>The number of published curl related CVEs is the lowest since 2013 (6). For the ones we announced, we could reward record amounts in our bug bounty program!</p>



<p>139 authors wrote commits that were merged (so far).</p>



<p>We did nine curl releases, out of which two unfortunately were quicker “panic releases” that patched up problems in the previous release.</p>



<h2>Seven changes to remember</h2>



<p>We’ve logged no less than <strong>905 bug-fixes</strong> and <strong>30 changes</strong> in the releases of this year, but the seven perhaps most memorable things we’ve introduced in 2020 are…</p>



<ul><li><a href="https://daniel.haxx.se/blog/2019/07/22/curl-goez-parallel/" data-type="post" data-id="12568">Parallel transfers</a> with curl</li><li><a href="https://daniel.haxx.se/blog/2020/04/14/curl-mqtt-true/" data-type="post" data-id="13836">MQTT</a>://</li><li><a href="https://daniel.haxx.se/blog/2020/11/03/hsts-your-curl/" data-type="post" data-id="11415">HSTS</a></li><li><a href="https://daniel.haxx.se/blog/2020/09/04/curl-help-remodeled/" data-type="post" data-id="14601"><code>--help</code> refined</a></li><li><a href="https://daniel.haxx.se/blog/2020/08/19/curl-7-72-0-more-compression/" data-type="post" data-id="14463">Zstd</a></li><li><a href="https://daniel.haxx.se/blog/2020/03/17/curl-write-out-json/" data-type="post" data-id="13740">JSON output</a> in -w</li><li><a href="https://daniel.haxx.se/blog/2020/01/12/curl-even-more-wolfed/" data-type="post" data-id="13130">wolfSSH backend</a></li></ul>



<h2>Videos</h2>



<p>This year I’ve introduced the concept of doing a “release presentation” for every release. Those are videos where I go through and discuss the changes, the security releases and some interesting bug-fixes. Each release links to those from <a href="https://curl.se/changes.html">the changelog page</a> on the website.</p>



<h2>New home</h2>



<p>This is the year when we finally got ourselves a curl domain. <a href="https://daniel.haxx.se/blog/2020/11/04/the-journey-to-a-curl-domain/" data-type="post" data-id="14930">curl.se is our new home</a>.</p>



<h2>What didn’t happen</h2>



<p>We cancelled curl up 2020 due to Covid-19. It was planned to happen in Berlin. We did it purely online instead. We’re not planning any new physical curl up for 2021 either. Let’s just wait and see what happens with the pandemic next year and hope that we might be able to go back and have a physical meetup in 2022…</p>



<h2>It is a curl world</h2>



<figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2020/12/slide-a-curl-world-2020.jpg"><img loading="lazy" width="2000" height="1125" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/12/slide-a-curl-world-2020.jpg" alt=""></a></figure>




	</div><!-- .entry-content -->
	
	</article><!-- #post-15375 -->
		<nav role="navigation">
		
		<!-- .nav-links -->
		</nav><!-- .navigation -->
		
<!-- #comments -->
		</div><!-- #content -->
	</div><!-- #primary -->

<!-- #content-sidebar -->
<div id="secondary">
		<h2>tech, open source and networking</h2>
	
	
		<!-- #primary-sidebar -->
	</div><!-- #secondary -->

		</div><!-- #main -->

		<!-- #colophon -->
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/12/24/the-curl-year-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25542012</guid>
            <pubDate>Sat, 26 Dec 2020 07:35:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Manga Guide to Lisp]]>
            </title>
            <description>
<![CDATA[
Score 135 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25541919">thread link</a>) | @joubert
<br/>
December 25, 2020 | http://lambda.bugyo.tk/cdr/mwl/ | <a href="https://web.archive.org/web/*/http://lambda.bugyo.tk/cdr/mwl/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://lambda.bugyo.tk/cdr/mwl/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25541919</guid>
            <pubDate>Sat, 26 Dec 2020 06:57:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Japanese Sentence Structure Intro]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25541124">thread link</a>) | @sova
<br/>
December 25, 2020 | https://japanesecomplete.com/articles/?p=1265 | <a href="https://web.archive.org/web/*/https://japanesecomplete.com/articles/?p=1265">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-1265">

	

	
			<figure>
				<img width="1568" height="1045" src="https://japanesecomplete.com/articles/wp-content/uploads/2020/12/lanterns.jpg" alt="" loading="lazy">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p>Aside from always having a verb at the end, Japanese does not depend on sequence.  Japanese is a grammar defined by <em>grammar particles</em>, functional “words” that glue on to nouns to indicate what purpose the noun serves.</p>



<p>Here we highlight some common Japanese particles in a slice of the ひらがな [hiragana] syllabary.</p>



<figure><img loading="lazy" width="1069" height="834" src="https://japanesecomplete.com/articles/wp-content/uploads/2020/12/japanese-particles.png" alt=""></figure>



<p>You can practice your 🎵 listening comprehension👂 of the ひらがな 🎎 <a href="http://japanesecomplete.com/hiragana">here</a>.  But we digress, Japanese relies on <em>grammatical particles</em> to indicate the <strong>who, what, when,  where, and how</strong> of a sentence.</p>



<h2><strong>Who, what, when, where, and how</strong>.</h2>



<h2>で  (de) <strong>where and how</strong></h2>



<p>For example, で [“deh”] implies <em>manner of accomplishment</em> or <em>setting-locality where something takes place.</em> Mapping to English, we cover the <strong>where</strong> [setting] and <strong>how</strong> [means] with で。</p>



<figure><img loading="lazy" width="246" height="142" src="https://japanesecomplete.com/articles/wp-content/uploads/2020/12/Screen-Shot-2020-12-19-at-4.34.24-PM.png" alt=""></figure>



<hr>



<h2>に (ni) where and when</h2>



<p>For destinations, or specific times, or precise physical points of existence (being), Japanese relies on the use of the <em>grammatical particle</em> に [“ni” as in, <a href="https://www.youtube.com/watch?v=zIV4poUZAQo">“we are the knights who say…”</a>].  に [“knee!”] therefore covers <strong>where</strong> [destination] and <strong>when</strong> [moment].</p>



<figure><img loading="lazy" width="648" height="446" src="https://japanesecomplete.com/articles/wp-content/uploads/2020/12/Screen-Shot-2020-12-19-at-4.36.55-PM.png" alt=""></figure>



<hr>



<h2>が  (ga) who and what</h2>



<p>The <em>grammatical particle</em> が [“ga”] is used to explain <strong>who</strong> and <strong>what</strong> when used as the <strong>grammatical subjects</strong> of a sentence.  </p>



<p>For example: Vegetables are delicious.  Candy is sweet.<br>  (Veggies are <strong>what</strong> is delicious)<br>  (The candy is <strong>what</strong> is sweet)</p>



<figure><img loading="lazy" width="366" height="295" src="https://japanesecomplete.com/articles/wp-content/uploads/2020/12/Screen-Shot-2020-12-19-at-4.38.46-PM.png" alt=""></figure>



<hr>



<p>Finally, in this brief primer, we want to show the concept of <strong>bunsetsu jar</strong> which we have featured on our <a href="http://japanesecomplete.com/reverse-engineer/">“Reverse Engineer Some Japanese”</a> page.</p>



<figure><img loading="lazy" width="737" height="138" src="https://japanesecomplete.com/articles/wp-content/uploads/2020/12/Screen-Shot-2020-12-19-at-4.41.05-PM.png" alt=""></figure>



<p>Within a <strong>bunsetsu jar</strong>, we place a noun and cap off the <strong>jar</strong> with a <strong>lid</strong> containing a <em>grammatical particle</em> such as が、に、で or one of the many others.  </p>



<p>In total, there is an estimated 233 + particles (some are multi-mora, that is, multiple letters) and we teach them in a gradual and comprehensible way in <a href="https://japanesecomplete.com/articles/?p=83">Japanese Complete</a>.</p>



<p>Finally, a sentence-final verb is placed at the end of a sentence.  In English, this would be akin to moving the “is/are” or “be/exists” verb to the end of every sentence.  Japanese fun is.  Grammar easy is.  Japanese-about thinking = interesting is.</p>



<p>So that’s it. You pick your nouns, you pick the <em>grammatical particles</em> to match based on the meaning of <strong>who, what, when, where, and how</strong>, and you figure out the sentence-final verb element.  Now you’re thinking in Japanese.</p>



<p>Of course, developing the reflex and intuition around this takes some practice, which is why we devised quizzes for Japanese Complete that help train your intuition on the particles, one-by-one.  You can watch a brief video showing some of the quizzes in action on our <a href="https://japanesecomplete.com/guide">free guide page</a>.</p>



<hr>



<h2>Kanji in English Context</h2>



<p>In order to accelerate Kanji comprehension into English context, as you can see in a sonnet by Shakespeare on <a href="http://japanesecomplete.com/learning-to-read">this page</a>.  This pattern follows a similar pattern of adoption that native Japanese took: grab kanji from mainland Asia for their ideographic value and smash them together with your native syllabary to add helpful meaning, nuance, and context.</p>



<figure><img loading="lazy" width="496" height="177" src="https://japanesecomplete.com/articles/wp-content/uploads/2020/12/Screen-Shot-2020-12-19-at-4.46.27-PM.png" alt=""></figure>



<p><strong>Temple NI arrive.</strong> [unstated subjects arrive to the temple]</p>



<p><strong>Enter-before NI, hands OH let’s wash, NE.</strong> [before entering, let’s wash our hands, right?]</p>



<p>We’ve created a substack newsletter to share <em>Kanji in English Context </em>once or twice a month, you can <a href="https://japanesecomplete.substack.com/p/coming-soon">sign up for it here</a> if you’re interested in getting interesting <em>Kanji in English Context</em> lessons to your inbox.</p>



<hr>



<p>One great thing about Japanese grammar is that the <strong>bunsetsu jars</strong> can be arranged in any sequence before the final verb, provided each noun has its appropriately matching <em>grammar particle</em> glued on and intact.  This leads to great fun with parsing, as one can create a <a href="https://japanesecomplete.com/articles/?p=811">rudimentary Japanese grammar parser</a> from a 5-line EBNF grammar.</p>



<figure><img loading="lazy" width="1080" height="1349" src="https://japanesecomplete.com/articles/wp-content/uploads/2020/12/osaka-castle.jpg" alt=""></figure>



<p>Hopefully this post made the inner mechanics of Japanese more clear.  Developing intuition and unlocking the language takes study, practice, and determination!  If you’re looking for a program to break the language down logically <strong>and</strong> provide practice and training to help your newfound understanding become intuitive and fast, might we humbly suggest <a href="https://japanesecomplete.com/">Japanese Complete</a>.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://japanesecomplete.com/articles/?p=1265</link>
            <guid isPermaLink="false">hacker-news-small-sites-25541124</guid>
            <pubDate>Sat, 26 Dec 2020 03:25:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Disabled snap store in Linux Mint 20]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25540780">thread link</a>) | @backing
<br/>
December 25, 2020 | https://linuxmint-user-guide.readthedocs.io/en/latest/snap.html#disabled-snap-store-in-linux-mint-20 | <a href="https://web.archive.org/web/*/https://linuxmint-user-guide.readthedocs.io/en/latest/snap.html#disabled-snap-store-in-linux-mint-20">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div id="snap-store">

<p>The <a href="https://snapcraft.io/">Snap Store</a>, also known as the <cite>Ubuntu Store</cite>, is a commercial centralized software store operated by <a href="https://canonical.com/">Canonical</a>.</p>
<p>Similar to AppImage or Flatpak the Snap Store is able to provide up to date software no matter what version of Linux you are running and how old your libraries are.</p>
<div id="criticism">
<h2>Criticism<a href="#criticism" title="Permalink to this headline">¶</a></h2>
<div id="centralized-control">
<h3>Centralized control<a href="#centralized-control" title="Permalink to this headline">¶</a></h3>
<p>Anyone can create APT repositories and distribute software freely. Users can point to multiple repositories and define priorities. Thanks to the way APT works, if a bug isn’t fixed upstream, Debian can fix it with a patch. If Debian doesn’t, Ubuntu can. If Ubuntu doesn’t Linux Mint can. If Linux Mint doesn’t, anyone can, and not only can they fix it, they can distribute it with a PPA.</p>
<p>Flatpak isn’t as flexible. Still, anyone can distribute their own Flatpaks. If Flathub decides they don’t want to do this or that, anyone else can create another Flatpak repository. Flatpak itself can point to multiple sources and doesn’t depend on Flathub.</p>
<p>Although it is open-source, Snap on the other hand, only works with the Ubuntu Store. Nobody knows how to make a Snap Store and nobody can. The Snap client is designed to work with only one source, following a protocol which isn’t open, and using only one authentication system. Snapd is nothing on its own, it can only work with the Ubuntu Store.</p>
<p>This is a store we can’t audit, which contains software nobody can patch. If we can’t fix or modify software, open-source or not, it provides the same limitations as proprietary software.</p>
</div>
<div id="backdoor-via-apt">
<h3>Backdoor via APT<a href="#backdoor-via-apt" title="Permalink to this headline">¶</a></h3>
<p>When Snap was introduced Canonical promised it would never replace APT. This promise was broken. Some APT packages in the Ubuntu repositories not only install snap as a dependency but also run snap commands as root without your knowledge or consent and connect your computer to the remote proprietary store operated by Canonical.</p>
</div>
</div>
<div id="disabled-snap-store-in-linux-mint-20">
<h2>Disabled Snap Store in Linux Mint 20<a href="#disabled-snap-store-in-linux-mint-20" title="Permalink to this headline">¶</a></h2>
<p>Following the decision made by Canonical to replace parts of APT with Snap and have the Ubuntu Store install itself without users knowledge or consent, the Snap Store is forbidden to be installed by APT in Linux Mint 20.</p>

</div>
<div id="how-to-install-the-snap-store-in-linux-mint-20">
<h2>How to install the Snap Store in Linux Mint 20<a href="#how-to-install-the-snap-store-in-linux-mint-20" title="Permalink to this headline">¶</a></h2>
<p>Recommended or not, if you want to use the Snap Store, re-enabling and installing it is very easy.</p>
<div><div><pre><span></span>sudo rm /etc/apt/preferences.d/nosnap.pref
apt update
apt install snapd
</pre></div>
</div>
</div>
</div>


           </div>
           
          </div></div>]]>
            </description>
            <link>https://linuxmint-user-guide.readthedocs.io/en/latest/snap.html#disabled-snap-store-in-linux-mint-20</link>
            <guid isPermaLink="false">hacker-news-small-sites-25540780</guid>
            <pubDate>Sat, 26 Dec 2020 02:10:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VPN – A Precarious Narrative]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25540314">thread link</a>) | @aminozuur
<br/>
December 25, 2020 | https://schub.wtf/blog/2019/04/08/very-precarious-narrative.html | <a href="https://web.archive.org/web/*/https://schub.wtf/blog/2019/04/08/very-precarious-narrative.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content">
        
        <p>
  
  <span><i aria-label="This item was published on:"></i> 2019-04-08</span>
  <span><i aria-label="This item was updated on:"></i> 2019-04-22</span>
  <span><i aria-label="This item was tagged with:"></i> privacy, security</span>
</p>


        





        

        <section id="main_content">
          <p>I just watched a <em>great</em> YouTube video, touching technical, political, and philosophical questions around the whole “who controls the algorithm” topic, from one of those multi-million subscriber channels, spending lots and lots of time and resources on researching and producing. The video was perfect, but the end did upset me slightly. In the end, the sponsoring message was read, and the sponsor was one of those VPN companies, with their usual marketing lingo. You surely know what I am talking about, but let me quote the sponsoring message here for context:</p>

<blockquote>
  <p>Your internet connection, right now, is broadcasting your IP address, which is the way people track you online. Check this out [shows a screencap of a website displaying the IP and GeoLocation information], when I go to this website, it tests everything that my internet connection is leaking. You can see my IP address, but you can also see where I am. Your internet connection is doing this right now. Here is how [VPN company] works: It is a Virtual Private Network, you turn it on with one click. My internet traffic is now encrypted, and going through [VPN company]s servers located throughout the world, so people can no longer figure out where I am located. I protect myself online with [VPN company]. […] There is a 30-day money back guarantee which I am confident you are not going to use, because I feel comforted knowing that my personal information is protected on the internet.</p>
</blockquote>

<p>Here is another one, from a different channel:</p>

<blockquote>
  <p>With all the recent news about online security breaches, it is hard not to worry about where my data goes. Make an online purchase or simply accessing your email puts your private information at risk. You are being tracked online all the time by social media sites, marketing companies, and mobile internet providers. That is why you need to take your internet privacy back right now. Use [VPN company]! [VPN company] has the easiest apps that run seamlessly in the background of any computer, phone, and tablet. Turning on [VPN company] protection only takes one click. I am going to tell you what takes more than one click: getting your identity and data back after it’s been lost. Try getting back the money from your stolen credit cards. Do one click now. [VPN company] secures and anoymizes your internet browsing by encrypting your data and hiding your public IP address.</p>
</blockquote>

<p>The popularity of those services and the way they are recommended and promoted is bad. So bad that I feel impelled to write this article on it, to explain two problematic points. Those are:</p>

<ol>
  <li>In most circumstances, <strong>VPNs do very little to enhance your data security or privacy</strong> unless paired with other changes.</li>
  <li>Acting as they do, and <strong>promoting commercial VPN providers</strong> as a solution to potential issues <strong>does more harm than good</strong>.</li>
</ol>

<p>Just stick around for a bit, and I will explain everything. Before I start, though, let me clarify that I am writing this post with non-technical, but curious people in mind. This means that I will be using simplified terms and sometimes generalize a bit. However, I can assure you that all information is still very accurate. Sometimes, using technical words is necessary to avoid this post becoming inaccurate. If you do not understand something, just read on, the next paragraph might be more apparent.</p>

<h2 id="what-a-vpn-is-and-what-it-is-not">What a VPN is, and what it is not.</h2>

<blockquote>
  <p>[…] another worrying aspect of today’s market of VPN services is the large misinformation end users are exposed to, which makes it hard for them to properly tell apart vague and bold claims typical of product advertisement campaigns with actual facts.</p>

  <p>- <em>a <a href="https://www.degruyter.com/downloadpdf/j/popets.2015.1.issue-1/popets-2015-0006/popets-2015-0006.pdf" target="_blank" rel="noopener">paper published in 2015</a></em>.</p>
</blockquote>

<p><img src="https://schub.wtf/statics/blog/20190408/vpn-banner.png" alt="VPN - a Very Precarious Narrative"></p>

<p>To start, <a href="https://en.wikipedia.org/wiki/Virtual_private_network" target="_blank" rel="noopener">Wikipedia</a> has a very nice summary of what a VPN is:</p>

<blockquote>
  <p>A virtual private network (VPN) extends a private network across a public network, and enables users to send and receive data across shared or public networks as if their computing devices were directly connected to the private network.</p>
</blockquote>

<p>A VPN is a <em>tunnel</em> connecting two different networks. You throw traffic into one end of the tunnel, and it will come out somewhere else, even if the destination might not be reachable on the public internet. VPNs are popular in company environments: Imagine a large company running their servers with private sale data on them. The company does not want those servers to be reachable via the internet for security reasons, but at the same time, salespeople need to be able to access those datasets, even if they are on the road. The salesperson can use the company’s VPN to “move their laptop into the company network”, without the need to physically be there, so they have access to that information. In addition, network traffic sent over VPNs is generally encrypted, so even if the salesperson is using a maybe insecure network, the data is probably safe, if everything is configured correctly.</p>

<p>The VPNs that get advertised at the end of YouTube videos are different. They are not used to access protected, internal infrastructure. Instead, they are used to tunnel <em>all</em> network traffic into a datacenter you neither know nor can control in any way. To understand why this might be a bad idea and is absolutely not necessary in most cases, let’s look at the marketing claims.</p>

<h2 id="your-ip-is-used-for-tracking-and-leaks-private-information-you-should-hide-it">“Your IP is used for tracking and leaks private information. You should hide it.”</h2>

<p>One thing that most VPN advertisements have in common is some babble around IP addresses. Providers claim that your IP address leaks tons of private information, even your physical location, and they also claim that IP addresses are used for tracking. I call that fearmongering and deliberate misinformation.</p>

<p><img src="https://schub.wtf/statics/blog/20190408/vpn-check.jpg" alt="Two screenshots from VPN websites showing my &quot;unprotected&quot; IP address"></p>

<p>I am sure you have seen notices like these on VPN provider’s websites before. They claim that your IP can be used to track you, and they even show a map of where you are located to make it look scarier.</p>

<p>Before I address those two things, let me say something more generic. Notice how both sites show my IP, claim that my connection is “unprotected”, and one is even showing a map? Well. In reality, I am actually <em>using a VPN</em> in those screenshots, I just happened to use <a href="https://protonvpn.com/" target="_blank" rel="noopener">ProtonVPN</a> for this example, so I should be protected very well, right? How come they claim I am unprotected?</p>

<p>That is because those “tests” do not do anything useful. The only check these things are doing is a simple “is the user currently connected via one of our IPs, and thus is using our VPN? If yes, say the user is protected, otherwise, act like the world is on fire”. Not very productive.</p>

<h3 id="ip-addresses-for-user-identification">IP addresses for user identification</h3>

<p>One of the sponsor messages I quoted earlier explicitly claims that IP addresses are how you “are being tracked online all the time by social media sites and marketing companies”. But is that so? We all know that Facebook is pretty big in the whole “tracking people” business, so if you have an active subscription at one of those VPN providers and a Facebook account, let’s do a test together!</p>

<ol>
  <li>Open a new Private Window/Incognito Window in your favorite browser.</li>
  <li>In that window, open two tabs: Facebook, and the “What is my IP?” page of your VPN provider, like <a href="https://www.expressvpn.com/what-is-my-ip" target="_blank" rel="noopener">this one from ExpressVPN</a>.</li>
  <li>Log in to your Facebook account.</li>
  <li>With the VPN disabled, verify that the “test” site shows “you are unprotected”, like in my screenshots above.</li>
  <li>Connect to your VPN. Refresh the VPN test page, which should now say that your IP is hidden and your connection is protected. Right?</li>
  <li>Now, switch over to the Facebook tab, and hit reload.</li>
</ol>

<p>So, what happened? Did Facebook forget who you are, and boot you back out to the login form? No, of course not. Even though your IP address changed, Facebook still knew <em>exactly</em> who you are. So do marketing companies and other tracking parties.</p>

<p>The reality here is that your IP address is only a tiny piece of your trackable profile and a pretty unreliable one as such. Tracking companies are interested in tracking <em>you</em>, not a specific device or a specific browsing session. Your IP changes all the time, take your mobile phone as an example: You may be connected to your home WiFi, to your mobile connection, the network at work, … and you will have a different IP in each network. Moreover, these IPs are not even unique to you in most cases: most mobile phone networks share their public IPs to hundreds, sometimes thousands of mobile phones in a process called <a href="https://en.wikipedia.org/wiki/Network_address_translation" target="_blank" rel="noopener">NAT</a>. Tracking companies have to distinguish between all those people - their profiles would be useless otherwise.</p>

<p>Tracking companies have far more advanced methods. One well-known identification method is <em>Cookies</em>, little portions of data in your browser or mobile client. However, since Cookies can easily be altered or removed by users, trackers came up with far more advanced technologies like browser fingerprinting and even running behavioral pattern recognition to uniquely identify users. All these things cannot be influenced or altered in any way by a VPN.</p>

<p>If you are worried about these things, then use a browser with integrated tracking protection features. In Firefox, <a href="https://blog.mozilla.org/firefox/facebook-container-extension/" target="_blank" rel="noopener">Multi-Account Containers and the Facebook Container Extension</a> for example help by locking those tracking sites into their isolated sandbox, so they cannot track you when you are not actively using them. The whole “a VPN makes you browse anonymously” thing is just marketing.</p>

<h3 id="location-leaking">Location leaking</h3>

<p>Another very effective method these VPN marketing people are using is showing your location on their sites. This is very effective at scaring people since those sites hit either your actual hometown or a city nearby. Nobody wants to share their location publicly.</p>

<p>“Your IP address” is not leaking your home address.</p>

<p>You see, your modem is not connected to a cable that leads directly to your ISPs main router. Instead, your internet data is <em>merged together</em> with other peoples data on the way. ISPs split up their network into multiple segments to make their network more manageable, …</p></section></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://schub.wtf/blog/2019/04/08/very-precarious-narrative.html">https://schub.wtf/blog/2019/04/08/very-precarious-narrative.html</a></em></p>]]>
            </description>
            <link>https://schub.wtf/blog/2019/04/08/very-precarious-narrative.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25540314</guid>
            <pubDate>Sat, 26 Dec 2020 00:30:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“A helpful (Python) cheat sheet, quite long.” ― Brian Kernighan]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25540171">thread link</a>) | @zombiemama
<br/>
December 25, 2020 | https://gto76.github.io/python-cheatsheet/ | <a href="https://web.archive.org/web/*/https://gto76.github.io/python-cheatsheet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <header>
    
    
  </header>

  <span><i></i></span>
   <div><br><div><h2 id="toc"><a href="#toc" name="toc">#</a>Contents</h2><pre><code><strong>ToC</strong> = {
    <strong><span><span>'1. Collections'</span></span></strong>: [<a href="#list">List</a>, <a href="#dictionary">Dictionary</a>, <a href="#set">Set</a>, <a href="#tuple">Tuple</a>, <a href="#range">Range</a>, <a href="#enumerate">Enumerate</a>, <a href="#iterator">Iterator</a>, <a href="#generator">Generator</a>],
    <strong><span><span>'2. Types'</span></span></strong>:       [<a href="#type">Type</a>, <a href="#string">String</a>, <a href="#regex">Regular_Exp</a>, <a href="#format">Format</a>, <a href="#numbers">Numbers</a>, <a href="#combinatorics">Combinatorics</a>, <a href="#datetime">Datetime</a>],
    <strong><span><span>'3. Syntax'</span></span></strong>:      [<a href="#arguments">Args</a>, <a href="#inline">Inline</a>, <a href="#closure">Closure</a>, <a href="#decorator">Decorator</a>, <a href="#class">Class</a>, <a href="#ducktypes">Duck_Type</a>, <a href="#enum">Enum</a>, <a href="#exceptions">Exception</a>],
    <strong><span><span>'4. System'</span></span></strong>:      [<a href="#exit">Exit</a>, <a href="#print">Print</a>, <a href="#input">Input</a>, <a href="#commandlinearguments">Command_Line_Arguments</a>, <a href="#open">Open</a>, <a href="#path">Path</a>, <a href="#oscommands">OS_Commands</a>],
    <strong><span><span>'5. Data'</span></span></strong>:        [<a href="#json">JSON</a>, <a href="#pickle">Pickle</a>, <a href="#csv">CSV</a>, <a href="#sqlite">SQLite</a>, <a href="#bytes">Bytes</a>, <a href="#struct">Struct</a>, <a href="#array">Array</a>, <a href="#memoryview">Memory_View</a>, <a href="#deque">Deque</a>],
    <strong><span><span>'6. Advanced'</span></span></strong>:    [<a href="#threading">Threading</a>, <a href="#operator">Operator</a>, <a href="#introspection">Introspection</a>, <a href="#metaprograming">Metaprograming</a>, <a href="#eval">Eval</a>, <a href="#coroutines">Coroutine</a>],
    <strong><span><span>'7. Libraries'</span></span></strong>:   [<a href="#progressbar">Progress_Bar</a>, <a href="#plot">Plot</a>, <a href="#table">Table</a>, <a href="#curses">Curses</a>, <a href="#logging">Logging</a>, <a href="#scraping">Scraping</a>, <a href="#web">Web</a>, <a href="#profiling">Profile</a>,
                       <a href="#numpy">NumPy</a>, <a href="#image">Image</a>, <a href="#audio">Audio</a>, <a href="#pygame">Games</a>, <a href="#pandas">Data</a>, <a href="#pysimplegui">GUI</a>]
}
</code></pre></div></div>






<div><h2 id="main"><a href="#main" name="main">#</a>Main</h2><pre><code><span>if</span> __name__ == <span>'__main__'</span>:     
    main()
</code></pre></div>

<div><h2 id="list"><a href="#list" name="list">#</a>List</h2><pre><code>&lt;list&gt; = &lt;list&gt;[from_inclusive : to_exclusive : ±step_size]
</code></pre></div>

<pre><code>&lt;list&gt;.append(&lt;el&gt;)            
&lt;list&gt;.extend(&lt;collection&gt;)    
</code></pre>
<pre><code>&lt;list&gt;.sort()
&lt;list&gt;.reverse()
&lt;list&gt; = sorted(&lt;collection&gt;)
&lt;iter&gt; = reversed(&lt;list&gt;)
</code></pre>
<pre><code>sum_of_elements  = sum(&lt;collection&gt;)
elementwise_sum  = [sum(pair) <span>for</span> pair <span>in</span> zip(list_a, list_b)]
sorted_by_second = sorted(&lt;collection&gt;, key=<span>lambda</span> el: el[<span>1</span>])
sorted_by_both   = sorted(&lt;collection&gt;, key=<span>lambda</span> el: (el[<span>1</span>], el[<span>0</span>]))
flatter_list     = list(itertools.chain.from_iterable(&lt;list&gt;))
product_of_elems = functools.reduce(<span>lambda</span> out, el: out * el, &lt;collection&gt;)
list_of_chars    = list(&lt;str&gt;)
</code></pre>
<ul>
<li><strong>Module <a href="#operator">operator</a> provides functions itemgetter() and mul() that offer the same functionality as <a href="#lambda">lambda</a> expressions above.</strong></li>
</ul>
<pre><code>&lt;int&gt; = &lt;list&gt;.count(&lt;el&gt;)     
index = &lt;list&gt;.index(&lt;el&gt;)     
&lt;list&gt;.insert(index, &lt;el&gt;)     
&lt;el&gt; = &lt;list&gt;.pop([index])     
&lt;list&gt;.remove(&lt;el&gt;)            
&lt;list&gt;.clear()                 
</code></pre>
<div><h2 id="dictionary"><a href="#dictionary" name="dictionary">#</a>Dictionary</h2><pre><code>&lt;view&gt; = &lt;dict&gt;.keys()                          
&lt;view&gt; = &lt;dict&gt;.values()                        
&lt;view&gt; = &lt;dict&gt;.items()                         
</code></pre></div>

<pre><code>value  = &lt;dict&gt;.get(key, default=<span>None</span>)          
value  = &lt;dict&gt;.setdefault(key, default=<span>None</span>)   
&lt;dict&gt; = collections.defaultdict(&lt;type&gt;)        
&lt;dict&gt; = collections.defaultdict(<span>lambda</span>: <span>1</span>)     
</code></pre>
<pre><code>&lt;dict&gt; = dict(&lt;collection&gt;)                     
&lt;dict&gt; = dict(zip(keys, values))                
&lt;dict&gt; = dict.fromkeys(keys [, value])          
</code></pre>
<pre><code>&lt;dict&gt;.update(&lt;dict&gt;)                           
value = &lt;dict&gt;.pop(key)                         
{k <span>for</span> k, v <span>in</span> &lt;dict&gt;.items() <span>if</span> v == value}    
{k: v <span>for</span> k, v <span>in</span> &lt;dict&gt;.items() <span>if</span> k <span>in</span> keys}  
</code></pre>
<div><h3 id="counter">Counter</h3><pre><code><span>&gt;&gt;&gt; </span><span>from</span> collections <span>import</span> Counter
<span>&gt;&gt;&gt; </span>colors = [<span>'blue'</span>, <span>'blue'</span>, <span>'blue'</span>, <span>'red'</span>, <span>'red'</span>]
<span>&gt;&gt;&gt; </span>counter = Counter(colors)
<span>&gt;&gt;&gt; </span>counter[<span>'yellow'</span>] += <span>1</span>
Counter({<span>'blue'</span>: <span>3</span>, <span>'red'</span>: <span>2</span>, <span>'yellow'</span>: <span>1</span>})
<span>&gt;&gt;&gt; </span>counter.most_common()[<span>0</span>]
(<span>'blue'</span>, <span>3</span>)
</code></pre></div>



<pre><code>&lt;set&gt;.add(&lt;el&gt;)                                 
&lt;set&gt;.update(&lt;collection&gt; [, ...])              
</code></pre>
<pre><code>&lt;set&gt;  = &lt;set&gt;.union(&lt;coll.&gt;)                   
&lt;set&gt;  = &lt;set&gt;.intersection(&lt;coll.&gt;)            
&lt;set&gt;  = &lt;set&gt;.difference(&lt;coll.&gt;)              
&lt;set&gt;  = &lt;set&gt;.symmetric_difference(&lt;coll.&gt;)    
&lt;bool&gt; = &lt;set&gt;.issubset(&lt;coll.&gt;)                
&lt;bool&gt; = &lt;set&gt;.issuperset(&lt;coll.&gt;)              
</code></pre>
<pre><code>&lt;el&gt; = &lt;set&gt;.pop()                              
&lt;set&gt;.remove(&lt;el&gt;)                              
&lt;set&gt;.discard(&lt;el&gt;)                             
</code></pre>
<div><h3 id="frozenset">Frozen Set</h3><ul>
<li><strong>Is immutable and hashable.</strong></li>
<li><strong>That means it can be used as a key in a dictionary or as an element in a set.</strong></li>
</ul><pre><code>&lt;frozenset&gt; = frozenset(&lt;collection&gt;)
</code></pre></div>


<div><h2 id="tuple"><a href="#tuple" name="tuple">#</a>Tuple</h2><p><strong>Tuple is an immutable and hashable list.</strong></p><pre><code>&lt;tuple&gt; = ()
&lt;tuple&gt; = (&lt;el&gt;, )
&lt;tuple&gt; = (&lt;el_1&gt;, &lt;el_2&gt; [, ...])
</code></pre></div>


<div><h3 id="namedtuple">Named Tuple</h3><p><strong>Tuple's subclass with named elements.</strong></p><pre><code><span>&gt;&gt;&gt; </span><span>from</span> collections <span>import</span> namedtuple
<span>&gt;&gt;&gt; </span>Point = namedtuple(<span>'Point'</span>, <span>'x y'</span>)
<span>&gt;&gt;&gt; </span>p = Point(<span>1</span>, y=<span>2</span>)
Point(x=<span>1</span>, y=<span>2</span>)
<span>&gt;&gt;&gt; </span>p[<span>0</span>]
<span>1</span>
<span>&gt;&gt;&gt; </span>p.x
<span>1</span>
<span>&gt;&gt;&gt; </span>getattr(p, <span>'y'</span>)
<span>2</span>
<span>&gt;&gt;&gt; </span>p._fields  
(<span>'x'</span>, <span>'y'</span>)
</code></pre></div>


<div><h2 id="range"><a href="#range" name="range">#</a>Range</h2><pre><code>&lt;range&gt; = range(to_exclusive)
&lt;range&gt; = range(from_inclusive, to_exclusive)
&lt;range&gt; = range(from_inclusive, to_exclusive, ±step_size)
</code></pre></div>

<pre><code>from_inclusive = &lt;range&gt;.start
to_exclusive   = &lt;range&gt;.stop
</code></pre>
<div><h2 id="enumerate"><a href="#enumerate" name="enumerate">#</a>Enumerate</h2><pre><code><span>for</span> i, el <span>in</span> enumerate(&lt;collection&gt; [, i_start]):
    ...
</code></pre></div>

<div><h2 id="iterator"><a href="#iterator" name="iterator">#</a>Iterator</h2><pre><code>&lt;iter&gt; = iter(&lt;collection&gt;)                 
&lt;iter&gt; = iter(&lt;function&gt;, to_exclusive)     
&lt;el&gt;   = next(&lt;iter&gt; [, default])           
&lt;list&gt; = list(&lt;iter&gt;)                       
</code></pre></div>

<div><h3 id="itertools">Itertools</h3><pre><code><span>from</span> itertools <span>import</span> count, repeat, cycle, chain, islice
</code></pre></div>

<pre><code>&lt;iter&gt; = count(start=<span>0</span>, step=<span>1</span>)             
&lt;iter&gt; = repeat(&lt;el&gt; [, times])             
&lt;iter&gt; = cycle(&lt;collection&gt;)                
</code></pre>
<pre><code>&lt;iter&gt; = chain(&lt;coll_1&gt;, &lt;coll_2&gt; [, ...])  
&lt;iter&gt; = chain.from_iterable(&lt;collection&gt;)  
</code></pre>
<pre><code>&lt;iter&gt; = islice(&lt;coll&gt;, to_exclusive)       
&lt;iter&gt; = islice(&lt;coll&gt;, from_inclusive, …)  
</code></pre>
<div><h2 id="generator"><a href="#generator" name="generator">#</a>Generator</h2><ul>
<li><strong>Any function that contains a yield statement returns a generator.</strong></li>
<li><strong>Generators and iterators are interchangeable.</strong></li>
</ul><pre><code><span><span>def</span> <span>count</span><span>(start, step)</span>:</span>
    <span>while</span> <span>True</span>:
        <span>yield</span> start
        start += step
</code></pre></div>


<pre><code><span>&gt;&gt;&gt; </span>counter = count(<span>10</span>, <span>2</span>)
<span>&gt;&gt;&gt; </span>next(counter), next(counter), next(counter)
(<span>10</span>, <span>12</span>, <span>14</span>)
</code></pre>
<div><h2 id="type"><a href="#type" name="type">#</a>Type</h2><ul>
<li><strong>Everything is an object.</strong></li>
<li><strong>Every object has a type.</strong></li>
<li><strong>Type and class are synonymous.</strong></li>
</ul><pre><code>&lt;type&gt; = type(&lt;el&gt;)                          
&lt;bool&gt; = isinstance(&lt;el&gt;, &lt;type&gt;)            
</code></pre></div>


<pre><code><span>&gt;&gt;&gt; </span>type(<span>'a'</span>), <span>'a'</span>.__class__, str
(&lt;<span><span>class</span> '<span>str</span>'&gt;, &lt;<span>class</span> '<span>str</span>'&gt;, &lt;<span>class</span> '<span>str</span>'&gt;)
</span></code></pre>
<div><h4 id="sometypesdonothavebuiltinnamessotheymustbeimported">Some types do not have built-in names, so they must be imported:</h4><pre><code><span>from</span> types <span>import</span> FunctionType, MethodType, LambdaType, GeneratorType
</code></pre></div>

<div><h3 id="abstractbaseclasses">Abstract Base Classes</h3><p><strong>Each abstract base class specifies a set of virtual subclasses. These classes are then recognized by isinstance() and issubclass() as subclasses of the ABC, although they are really not. ABC can also manually decide whether or not a specific class is its virtual subclass, usually based on which methods the class has implemented (Collection, Iterable).</strong></p><pre><code><span>&gt;&gt;&gt; </span><span>from</span> collections.abc <span>import</span> Sequence, Collection, Iterable
<span>&gt;&gt;&gt; </span>isinstance([<span>1</span>, <span>2</span>, <span>3</span>], Iterable)
<span>True</span>
</code></pre></div>


<pre><code>┏━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━┯━━━━━━━━━━━━┯━━━━━━━━━━━━┓
┃                  │  Sequence  │ Collection │  Iterable  ┃
┠──────────────────┼────────────┼────────────┼────────────┨
┃ list, range, str │     ✓      │     ✓      │     ✓      ┃
┃ dict, set        │            │     ✓      │     ✓      ┃
┃ iter             │            │            │     ✓      ┃
┗━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━┷━━━━━━━━━━━━┷━━━━━━━━━━━━┛
</code></pre>
<pre><code><span>&gt;&gt;&gt; </span><span>from</span> numbers <span>import</span> Integral, Rational, Real, Complex, Number
<span>&gt;&gt;&gt; </span>isinstance(<span>123</span>, Number)
<span>True</span>
</code></pre>
<pre><code>┏━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┓
┃                    │ Integral │ Rational │   Real   │ Complex  │  Number  ┃
┠────────────────────┼──────────┼──────────┼──────────┼──────────┼──────────┨
┃ int                │    ✓     │    ✓     │    ✓     │    ✓     │    ✓     ┃
┃ fractions.Fraction │          │    ✓     │    ✓     │    ✓     │    ✓     ┃
┃ float              │          │          │    ✓     │    ✓     │    ✓     ┃
┃ complex            │          │          │          │    ✓     │    ✓     ┃
┃ decimal.Decimal    │          │          │          │          │    ✓     ┃
┗━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┛
</code></pre>
<div><h2 id="string"><a href="#string" name="string">#</a>String</h2><pre><code>&lt;str&gt;  = &lt;str&gt;.strip()                       
&lt;str&gt;  = &lt;str&gt;.strip(<span>'&lt;chars&gt;'</span>)              
</code></pre></div>

<pre><code>&lt;list&gt; = &lt;str&gt;.split()                       
&lt;list&gt; = &lt;str&gt;.split(sep=<span>None</span>, maxsplit=<span>-1</span>)  
&lt;list&gt; = &lt;str&gt;.splitlines(keepends=<span>False</span>)    
&lt;str&gt;  = &lt;str&gt;.join(&lt;coll_of_strings&gt;)       
</code></pre>
<pre><code>&lt;bool&gt; = &lt;sub_str&gt; <span>in</span> &lt;str&gt;                  
&lt;bool&gt; = &lt;str&gt;.startswith(&lt;sub_str&gt;)         
&lt;bool&gt; = &lt;str&gt;.endswith(&lt;sub_str&gt;)           
&lt;int&gt;  = &lt;str&gt;.find(&lt;sub_str&gt;)               
&lt;int&gt;  = &lt;str&gt;.index(&lt;sub_str&gt;)              
</code></pre>
<pre><code>&lt;str&gt;  = &lt;str&gt;.replace(old, new [, count])   
&lt;str&gt;  = &lt;str&gt;.translate(&lt;table&gt;)            
</code></pre>
<pre><code>&lt;str&gt;  = chr(&lt;int&gt;)                          
&lt;int&gt;  = ord(&lt;str&gt;)                          
</code></pre>
<ul>
<li><strong>Also: <code><span>'lstrip()'</span></code>, <code><span>'rstrip()'</span></code>.</strong></li>
<li><strong>Also: <code><span>'lower()'</span></code>, <code><span>'upper()'</span></code>, <code><span>'capitalize()'</span></code> and <code><span>'title()'</span></code>.</strong></li>
</ul>
<div><h3 id="propertymethods">Property Methods</h3><pre><code>┏━━━━━━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┓
┃               │ [ !#$%…] │ [a-zA-Z] │  [¼½¾]   │  [²³¹]   │  [0-9]   ┃
┠───────────────┼──────────┼──────────┼──────────┼──────────┼──────────┨
┃ isprintable() │    ✓     │    ✓     │    ✓     │    ✓     │    ✓     ┃
┃ isalnum()     │          │    ✓     │    ✓     │    ✓     │    ✓     ┃
┃ isnumeric()   │          │          │    ✓     │    ✓     │    ✓     ┃
┃ isdigit()     │          │          │          │    ✓     │    ✓     ┃
┃ isdecimal()   │          │          │          │          │    ✓     ┃
┗━━━━━━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┛
</code></pre></div>

<ul>
<li><strong>Also: <code><span>'isspace()'</span></code> checks for <code><span>'[ \t\n\r\f\v…]'</span></code>.</strong></li>
</ul>
<div><h2 id="regex"><a href="#regex" name="regex">#</a>Regex</h2><pre><code><span>import</span> re
&lt;str&gt;   = re.sub(&lt;regex&gt;, new, text, count=<span>0</span>)  
&lt;list&gt;  = re.findall(&lt;regex&gt;, text)            
&lt;list&gt;  = re.split(&lt;regex&gt;, text, maxsplit=<span>0</span>)  
&lt;Match&gt; = re.search(&lt;regex&gt;, text)             
&lt;Match&gt; = re.match(&lt;regex&gt;, text)              
&lt;iter&gt;  = re.finditer(&lt;regex&gt;, text)           
</code></pre></div>

<ul>
<li><strong>Search() and match() return None if they can't find a match.</strong></li>
<li><strong>Argument <code><span>'flags=re.IGNORECASE'</span></code> can be used with all functions.</strong></li>
<li><strong>Argument <code><span>'flags=re.MULTILINE'</span></code> makes <code><span>'^'</span></code> and <code><span>'$'</span></code> match the start/end of each line.</strong></li>
<li><strong>Argument <code><span>'flags=re.DOTALL'</span></code> makes dot also accept the <code><span>'\n'</span></code>.</strong></li>
<li><strong>Use <code><span>r'\1'</span></code> or <code><span>'\\1'</span></code> for backreference.</strong></li>
<li><strong>Add <code><span>'?'</span></code> after an operator to make it non-greedy.</strong></li>
</ul>
<div><h3 id="matchobject">Match Object</h3><pre><code>&lt;str&gt;   = &lt;Match&gt;.group()                      
&lt;str&gt;   = &lt;Match&gt;.group(<span>1</span>)                     
&lt;tuple&gt; = &lt;Match&gt;.groups()                     
&lt;int&gt;   = &lt;Match&gt;.start()                      
&lt;int&gt;   = &lt;Match&gt;.end()                        
</code></pre></div>

<div><h3 id="specialsequences">Special Sequences</h3><ul>
<li><strong>By default digits, alphanumerics and whitespaces from all alphabets are matched, unless <code><span>'flags=re.ASCII'</span></code> argument is used.</strong></li>
<li><strong>Use a capital letter for negation.</strong></li>
</ul><pre><code><span>'\d'</span> == <span>'[0-9]'</span>                                
<span>'\w'</span> == <span>'[a-zA-Z0-9_]'</span>                         
<span>'\s'</span> == <span>'[ \t\n\r\f\v]'</span>                        
</code></pre></div>


<div><h2 id="format"><a href="#format" name="format">#</a>Format</h2><pre><code>&lt;str&gt; = <span>f'<span>{&lt;el_1&gt;}</span>, <span>{&lt;el_2&gt;}</span>'</span>
&lt;str&gt; = <span>'{}, {}'</span>.format(&lt;el_1&gt;, &lt;el_2&gt;)
</code></pre></div>

<div><h3 id="attributes">Attributes</h3><pre><code><span>&gt;&gt;&gt; </span><span>from</span> collections <span>import</span> namedtuple
<span>&gt;&gt;&gt; </span>Person = namedtuple(<span>'Person'</span>, <span>'name height'</span>)
<span>&gt;&gt;&gt; </span>person = Person(<span>'Jean-Luc'</span>, <span>187</span>)
<span>&gt;&gt;&gt; </span><span>f'<span>{person.height}</span>'</span>
<span>'187'</span>
<span>&gt;&gt;&gt; </span><span>'{p.height}'</span>.format(p=pers…</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gto76.github.io/python-cheatsheet/">https://gto76.github.io/python-cheatsheet/</a></em></p>]]>
            </description>
            <link>https://gto76.github.io/python-cheatsheet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25540171</guid>
            <pubDate>Sat, 26 Dec 2020 00:03:30 GMT</pubDate>
        </item>
    </channel>
</rss>
