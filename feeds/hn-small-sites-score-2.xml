<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 27 Nov 2020 01:01:28 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 27 Nov 2020 01:01:28 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Asking a Tech Recruiter]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25207447">thread link</a>) | @lawik
<br/>
November 25, 2020 | https://underjord.io/asking-a-tech-recruiter.html | <a href="https://web.archive.org/web/*/https://underjord.io/asking-a-tech-recruiter.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <small>2020-11-25</small>
        <p>Since I left my comfy job as the tech lead for a SaaS product and went into running my own business I took a closer look at my relationship with recruiters. While working I mostly found the attention of recruiters slightly reassuring but often annoying. I think that annoyance is fairly common, usually built up from countless LinkedIn drive-by attempts from unreading keyword-hunting recruiters. I thought that now, out on my own, maybe this legion of recruiters can be my sales department. And they have been, to an extent.</p>
<p>During my first few days as a free agent I did reach out to one recruiter in particular. This was the one that had been closest to dislodging me from my previous position and I had a feeling he was a sharp one. I had also thrown my cousin at him and he had helped him land his first real ops gig. When I got in touch this recruiter quite swiftly landed me my first client. In parallel I started to accept more recruiter connections and had a lot more conversations with assorted recruitment agencies. It has netted a fair bit of work. But I dare say the hit-rate is mostly low.</p>
<p>The recruiters that I’ve found to give the best results also give recurring results. They are the people that follow up, consider your needs, balance them with client needs and make things happen. It is my feeling that there remains a large cultural gap between the majority of recruiters and developers. I’ve been thinking about how to usefully bridge that. I don’t particularly need it right now but I want to help junior developers find their way into work and more experienced developers find their way to what they actually want. I think recruiters could help there. But I think we’re still quite far off from that.</p>
<p>I reached out  about this to my network on LinkedIn (where the recruiters live). I got a response from Emy Wennerberg Kristoffersson who was willing to take a chance and reach some new developers. Emy works mostly in Sweden around Gothenburg and Helsingborg, so while she might not work in your particular area I think the information and exchange is widely applicable. We figured a good first step is to tackle some of the common skepticisms that developers tend to have around recruiters and recruitment. I hope this will be helpful. The post is not sponsored, I asked her to answer a bunch of uncomfortable and nuanced questions which I think she does gracefully. Let’s get into it.</p>
<p><strong>For some background, can you introduce yourself and tell us a little bit about your professional experience?</strong></p>
<p>Emy: My name is Emy Wennerberg Kristoffersson. I was born and raised in Helsingborg (south of Sweden), but moved to Gothenburg back in 2016. I am passionate about tech, human beings and business development. I settled on tech-recruitment because it gives me the opportunity to combine all of these areas. For the last three years, I have been working in the recruitment industry. I work for Bonsai Consulting, a Gothenburg-based company that specializes in tech recruitment.</p>
<p>I have always had a huge tech-interest. Though, this wasn’t something that I seized back in my younger years, at least not to a greater extent (apart from when loved ones encountered technical problems and I wanted to impress – hah!). My father has always been in the IT sector so I’m quite sure that his tech skills have influenced me. I am a people-person at heart, so I eventually decided to study Human Resources in Gothenburg. In time, I got in touch with Bonsai Consulting whereupon I started to work as a researcher, and my main task was to build a network of candidates who were open to new opportunities. After a couple of months, I leveled up to a position as a recruiter and got a bigger responsibility within the company. Back then we worked broadly in recruitment and recruited to many different industries, but due to my tech-interest, the positions that related to IT and tech always ended up on my desk. One and a half years ago, we decided to work exclusively with tech recruitment due to the enormous demand within the industry.</p>
<p>One of the most interesting things in my profession is the potential for improvement in the recruitment industry. Today, I am aware that there is a lot of frustration against the recruitment profession and I do think that this is a misconception. Many jobseekers consider recruiters as an annoying part of the job search. Generally speaking, we have a pretty bad reputation (let’s talk more about this later). But the thing is, in fact, that we are an asset in a candidate’s job search and in a company’s recruiting process. My vision is to get fewer people out there to see us as an annoying piece of the puzzle, and instead see the value of taking our help as a job coach.</p>
<p><strong>Finding and hiring experienced developers has been a challenging proposition for a while due simply to enormous demand, how does this affect your job?</strong></p>
<p>Emy: The first thing that comes to my mind, is the challenge of getting the companies to understand the market and the developers’ situation. It is a bitter pill to swallow for many recruiters and companies, but today many developers have at least 4-5 opportunities available for him or her. Unfortunately, not all companies understand how coveted many developers are, and therefore they don’t understand the necessity of offering a great deal to potential employees. Not just the salary has been rising during the last years, other requirements have changed considerably as well. Today, many developers expect to be able to work remotely, having flexibility in their working day, good opportunities to develop within the company and to be able to develop their own skills (and so on…). Outstanding developers know their value on the market, and if a company’s position doesn’t sound interesting or profitable, they will go on to their next available opportunity. Many companies lack the understanding of how many offers a developer can have on their table and are therefore unable (or even unwilling) to match their needs. This is a tough nut to crack.</p>
<p>Another thing that comes top of mind is the art of standing out as a recruiter. Due to the enormous demand, many developers are likely to get contacted by a countless number of recruiters every day. The old-fashioned way of sending an email to a developer saying “Hi, here’s a job I’d like you to consider” doesn’t work today. Why? Because that developer has probably received multiple requests from other recruiters already, and my message is likely to disappear somewhere in all that noise. Over the years that I have worked as a recruiter, I have come to understand the importance of understanding the developers needs and desires before sending them multiple job descriptions, preferably even before I contact him or her. It is my duty, as a recruiter, to do my research before I expect a developer to take his or her time to talk with me. For example, If I check their Github I may find out that this developer prefers back-end development in C#/.Net, then I know that it won’t be necessary for me to contact him or her in order to talk about a front-end position where your main focus is in React and Typescript. If I don’t do my research, I’m likely to waste the person’s time. If I don’t find anything on Github or similar, then I think it is pure decency of me to first of all ask if they are interested in having a conversation with me and if they are, I can’t just throw a job description in their face without first understanding what this person is interested in.</p>
<p><strong>Has everything changed with the pandemic? Is development work hard to find now?</strong></p>
<p>Emy: A lot has changed with the pandemic. From my experience, I think that the biggest challenge for recruiters right now is that developers in general are unwilling to take on a new job, even though they might know that their current position isn’t exactly what they want. I think it’s a result of the uncertainty with the pandemic, that no one knows how it will develop and what will happen next. Since the pandemic seriously shook the market during spring and summer, many developers are worried that it will put them in a situation where they’ve left a permanent employment and the safety that it entails, to be the “last man/woman in, first out”.</p>
<p>In the beginning of the pandemic the market was disastrous, from March until September it was clear that even the IT-industry (despite the great demand) suffered from the pandemic. Many start-ups had to end their businesses and bigger companies were prohibited from hiring, many were even forced to dismiss employees in order to survive. Since August until today it has eased, and more companies dare to hire today. With that said though, companies take precautions when hiring and the processes might include more steps than normally in order to be really sure that it’s a good fit for the position.</p>
<p>I’d say that there are many opportunities on the market by now, but of course we are far from “normal”. Unfortunately, many companies demand more senior developers today, in order to fill the positions that they dismissed during spring. So, for junior developers it may still be a challenge to find their first or next position. Many companies can hire junior developers as a short-term consultant-assignment, so it is advantageous to be open to these opportunities as a junior developer.</p>
<p><strong>Is the poor reputation of the recruitment profession in tech among developers deserved or overstated?</strong></p>
<p>Emy: Sadly, I do think that it is deserved. I think that many recruiters have the wrong approach when recruiting for developer-positions. I have talked to many, many, many developers about this, and my understanding of the situation is that developers experience that recruiters don’t understand them nor their industry. And above all, many developers think that recruiters are a bit ignorant and uninterested in understanding it.</p>
<p>Recruiters and developers communicate differently, which is natural due to very different professions. …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://underjord.io/asking-a-tech-recruiter.html">https://underjord.io/asking-a-tech-recruiter.html</a></em></p>]]>
            </description>
            <link>https://underjord.io/asking-a-tech-recruiter.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25207447</guid>
            <pubDate>Wed, 25 Nov 2020 09:36:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An opinionated list of best practices for textual websites]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25207055">thread link</a>) | @dijit
<br/>
November 25, 2020 | https://seirdy.one/2020/11/23/website-best-practices.html | <a href="https://web.archive.org/web/*/https://seirdy.one/2020/11/23/website-best-practices.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	<p><em>The following applies to minimal websites that focus primarily on text. It does not
apply to websites that have a lot of non-textual content. It also does not apply to
websites that focus more on generating revenue or pleasing investors than being good
websites.</em></p>
<p>This is a “living document” that I add to as I receive feedback. See the
<a href="https://git.sr.ht/~seirdy/seirdy.one/log/master/content/posts/website-best-practices.md">changelog</a>.</p>
<p>I realize not everybody’s going to ditch the Web and switch to Gemini or Gopher today
(that’ll take, like, a month at the longest). Until that happens, here’s a
non-exhaustive, highly-opinionated list of best practices for websites that focus
primarily on text:</p>
<ul>
<li>Final page weight under 50kb without images, and under 200kb with images.</li>
<li>Works in Lynx, w3m, links (both graphics and text mode), Netsurf, and Dillo</li>
<li>Works with popular article-extractors (e.g.&nbsp;Readability) and HTML-to-Markdown
converters. This is a good way to verify that your site uses simple HTML and works
with most non-browser article readers (e.g.&nbsp;ebook converters, PDF exports).</li>
<li>No scripts or interactivity (preferably enforced at the CSP level)</li>
<li>No cookies</li>
<li>No animations</li>
<li>No fonts–local or remote–besides <code>sans-serif</code> and <code>monospace</code>. More on this
below.</li>
<li>No referrers</li>
<li>No requests after the page finishes loading</li>
<li>No 3rd-party resources (preferably enforced at the CSP level)</li>
<li>No lazy loading (more on this below)</li>
<li>No custom colors OR explicitly set the both foreground and background colors. More
on this below.</li>
<li>A maximum line length for readability</li>
<li>Server configured to support compression (gzip, optionally zstd as well). It’s a
free speed boost.</li>
<li>Supports dark mode via a CSS media feature and/or works with most “dark mode”
browser addons. More on this below.</li>
<li>A good score on Mozilla’s <a href="https://observatory.mozilla.org/">HTTP Observatory</a></li>
<li>Optimized images.</li>
<li>Maybe HTTP/2. There are some cases in which HTTP/2 can make things slower. Run some
tests to find out.</li>
</ul>
<p>I’d like to re-iterate yet another time that this only applies to websites that
primarily focus on text. If graphics, interactivity, etc. are an important part of
your website, less (possibly none) of this article applies.</p>
<p>Earlier revisions of this post generated some responses I thought I should address
below. Special thanks to the IRC and <a href="https://lobste.rs/s/akcw1m">Lobsters</a> users who
gave good feedback!</p>
<h2 id="about-fonts">About fonts</h2>
<p>If you <em>really</em> want, you could use <code>serif</code> instead of <code>sans-serif</code>, but serif fonts
tend to look worse on low-res monitors. Not every screen’s DPI has three digits.</p>
<p>To ship custom fonts is to assert that branding is more important than user choice.
That might very well be a reasonable thing to do; branding isn’t evil! It isn’t
<em>usually</em> the case for textual websites, though. Beyond basic layout and optionally
supporting dark mode, authors generally shouldn’t dictate the presentation of their
websites; that is the job of the user agent. Most websites are not important enough
to look completely different from the rest of the user’s system.</p>
<p>A personal example: I set my preferred fonts in my computer’s fontconfig settings.
Now every website that uses <code>sans-serif</code> will have my preferred font. Sites with
<code>sans-serif</code> blend into the users' systems instead of sticking out.</p>
<h3 id="but-most-users-dont-change-their-fonts">But most users don’t change their fonts…</h3>
<p>The “users don’t know better and need us to make decisions for them” mindset isn’t
without merits; however, in my opinion, it’s overused. Using system fonts doesn’t
make your website harder to use, but it does make it smaller and stick out less to
the subset of users who care enough about fonts to change them. This argument isn’t
about making software easier for non-technical users; it’s about branding by
asserting a personal preference.</p>
<h3 id="cant-users-globally-override-stylesheets-instead">Can’t users globally override stylesheets instead?</h3>
<p>It’s not a good idea to require users to automatically override website stylesheets.
Doing so would break websites that use fonts such as Font Awesome to display vector
icons. We shouldn’t have these users constantly battle with websites the same way
that many adblocking/script-blocking users (myself included) already do when there’s
a better option.</p>
<p>That being said, many users <em>do</em> actually override stylesheets. We shouldn’t
<em>require</em> them to do so, but we should keep our pages from breaking in case they do.
Pages following this article’s advice will probably work perfectly well in these
cases without any extra effort.</p>
<h3 id="but-wouldnt-that-allow-a-website-to-fingerprint-with-fonts">But wouldn’t that allow a website to fingerprint with fonts?</h3>
<p>I don’t know much about fingerprinting, except that you can’t do font enumeration
without JavaScript. Since text-based websites that follow these best-practices don’t
send requests after the page loads and have no scripts, fingerprinting via font
enumeration is a non-issue on those sites.</p>
<p>Other websites can still fingerprint via font enumeration using JavaScript. They
don’t need to stop at seeing what sans-serif maps to; they can see all the available
fonts on a user’s system, the user’s canvas fingerprint, window dimensions, etc. Some
of these can be mitigated with Firefox’s <code>privacy.resistFingerprinting</code> setting, but
that setting also understandably overrides user font preferences.</p>
<p>Ultimately, surveillance self-defense on the web is an arms race full of trade-offs.
If you want both privacy and customizability, the web is not the place to look; try
Gemini or Gopher instead.</p>
<h2 id="about-lazy-loading">About lazy loading</h2>
<p>For users on slow connections, lazy loading is often frustrating. I think I can speak
for some of these users: mobile data near my home has a number of “dead zones” with
abysmal download speeds, and my home’s Wi-Fi repeater setup occasionally results in
packet loss rates above 60% (!!).</p>
<p>Users on poor connections have better things to do than idly wait for pages to load.
They might open multiple links in background tabs to wait for them all to load at
once, or switch to another window/app and come back when loading finishes. They might
also open links while on a good connection before switching to a poor connection; I
know that I often open 10-20 links on Wi-Fi before going out for a walk in a
mobile-data dead-zone.</p>
<p>Unfortunately, pages with lazy loading don’t finish loading off-screen images in the
background. To load this content ahead of time, users need to switch to the loading
page and slowly scroll to the bottom to ensure that all the important content appears
on-screen and starts loading. Website owners shouldn’t expect users to have to jump
through these ridiculous hoops.</p>
<h3 id="wouldnt-this-be-solved-by-combining-lazy-loading-with-pre-loadingpre-fetching">Wouldn’t this be solved by combining lazy loading with pre-loading/pre-fetching?</h3>
<p>A large number of users with poor connections also have capped data, and would prefer
that pages don’t decide to predictively load content ahead-of-time for them. Some go
so far as to disable this behavior to avoid data overages. Savvy privacy-conscious
users also generally disable pre-loading because they don’t have reason to trust that
linked content doesn’t practice dark patterns like tracking without consent.</p>
<p>Users who click a link <em>choose</em> to load a full page. Loading pages that a user hasn’t
clicked on is making a choice for that user.</p>
<h3 id="cant-users-on-poor-connections-disable-images">Can’t users on poor connections disable images?</h3>
<p>I have two responses:</p>
<ol>
<li>If an image isn’t essential, you shouldn’t include it inline.</li>
<li>Yes, users could disable images. That’s <em>their</em> choice. If your page uses lazy
loading, you’ve effectively (and probably unintentionally) made that choice for a
large number of users.</li>
</ol>
<h2 id="about-custom-colors">About custom colors</h2>
<p>Some users' browsers set default page colors that aren’t black-on-white. For
instance, Linux users who enable GTK style overrides might default to having white
text on a dark background. Websites that explicitly set foreground colors but leave
the default background color (or vice-versa) end up being difficult to read. Here’s
an example:</p>
<picture>
<source srcset="https://seirdy.one/misc/website_colors.webp" type="image/webp">
<img src="https://seirdy.one/misc/website_colors.png" alt="This page with a grey background, a header with unreadable black/grey text, and unreadable white-on-white code snippets">
</picture>
<p>If you do explicitly set colors, please also include a dark theme using a media
query: <code>@media (prefers-color-scheme: dark)</code>. For more info, read the relevant docs
<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-color-scheme">on
MDN</a></p>
<h2 id="image-optimization">Image optimization</h2>
<p>Some image optimization tools I use:</p>
<ul>
<li><a href="http://pngquant.org/">pngquant</a> (lossy)</li>
<li><a href="https://github.com/shssoichiro/oxipng">Oxipng</a> (lossless)</li>
<li><a href="https://github.com/tjko/jpegoptim">jpegoptim</a> (lossless or lossy)</li>
<li><a href="https://developers.google.com/speed/webp/docs/cwebp">cwebp</a> (lossless or lossy)</li>
</ul>
<p>I put together a <a href="https://git.sr.ht/~seirdy/dotfiles/tree/3b722a843f3945a1bdf98672e09786f0213ec6f6/Executables/shell-scripts/bin/optimize-image">quick
script</a>
to losslessly optimize images using these programs in my dotfile repo.</p>
<p>You also might want to use the HTML <code>&lt;picture&gt;</code> element, using JPEG/PNG as a fallback
for more efficient formats such as WebP or AVIF. More info in the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/picture">MDN
docs</a></p>
<p>Most of my images will probably be screenshots that start as PNGs. My typical flow:</p>
<ol>
<li>Lossy compression with <code>pngquant</code></li>
<li>Losslessly optimize the result with <code>oxipng</code> and its Zopfli backend (slow)</li>
<li>Also create a lossless WebP from the lossy PNG, using <code>cwebp</code></li>
<li>Include the resulting WebP in the page, with a fallback to the PNG using a <code>&lt;picture&gt;</code> element.</li>
</ol>
<p>It might seem odd to create a lossless WebP from a lossy PNG, but I’ve found that it’s the best way to get the smallest possible image at the minimum acceptable quality for screenshots with solid backgrounds.</p>
<h2 id="other-places-to-check-out">Other places to check out</h2>
<p>The <a href="https://250kb.club/">250kb club</a> gathers websites at or under 250kb, and also
rewards websites that have a high ratio of content size to total size.</p>
<p>Also see <a href="https://motherfuckingwebsite.com/">Motherfucking Website</a>. Motherfucking
Website inspired several unofficial sequels that tried to gently improve upon it. My
favorite is <a href="https://bestmotherfucking.website/">Best Motherfucking Website</a>.</p>
</article></div>]]>
            </description>
            <link>https://seirdy.one/2020/11/23/website-best-practices.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25207055</guid>
            <pubDate>Wed, 25 Nov 2020 08:24:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to get lots of ideas for side projects and writing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25206661">thread link</a>) | @thesephist
<br/>
November 24, 2020 | https://linus.coffee/note/having-ideas/ | <a href="https://web.archive.org/web/*/https://linus.coffee/note/having-ideas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>People ask me how I get so many <a href="https://thesephist.com/projects/">ideas for interesting side projects</a> and <a href="https://thesephist/posts/">blog posts</a>.</p>
<p>I think the best way to describe my growth as a writer/maker over time is that I’ve become more efficient at discovering and refining my own ideas.</p>
<p>There are always ideas floating around in your brain. Sometimes, it comes to you out of the blue in the shower. Sometimes, you’re reading the news over dinner and a particular combination of words sets off a lightbulb. Sometimes, you’re reading and a metaphor resonates with you, so you contemplate on it in the hopes that it leads to an interesting perspective on something else. The key is to <strong>pay attention to your own wandering mind</strong>, notice when good ideas pass by in your mind for a split second, and grab a hold of it and pin it down on your mental desk and don’t let go, until you can expand that idea into something more interesting or valuable.</p>
<hr>
<p>There are fundamentally two knobs you can turn in the imaginary faucet of ideas.</p>
<p>The first is your <strong>creative input</strong>. This is a measure of the diversity and volume of interesting stories, knowledge, music, ideas, and advice you hear regularly. More and more, interesting ideas come to me as a combination of something I read or learned before, and an interesting metaphor or perspective I hear in the moment. The more quality, creative content you consume, the more source material you have from which your brain can synthesize new creative ideas. The diversity of content matters here. You’re going to have much better luck producing creative ideas when you combine knowledge or stories about completely different, unrelated topics, than by combining related existing ideas with each other.</p>
<p>The second knob is your <strong>creative efficiency</strong>, which I define as the fraction of interesting ideas that may occur to you, that you capitalize on. The human mind has tens of thousands of thoughts a day. Because of that staggering volume, most of the time, we’re trained to tune things out and dismiss internal mental side-conversations. But I think prolific creatives are able to counteract that urge to stay focused and hook onto an interesting ideas whenever it passes them by, and then learn to develop it into an insight or a piece of work. Lots of writers I talk to who are starting out tell me that they have ideas that are “mildly interesting” – not completely obvious, but not insightful. The best writers and artists and storytellers have a <em>skill</em> of developing these mildly-interesting ideas and stories into something more profound or valuable, and I think this is a skill that comes only with practice.</p>

        <hr>
        <p>
            
            ←
            <a href="https://linus.coffee/note/writing-growth/"><em>Growth as a writer</em></a>
            
        </p>
        
    </article></div>]]>
            </description>
            <link>https://linus.coffee/note/having-ideas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25206661</guid>
            <pubDate>Wed, 25 Nov 2020 07:08:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Banned for Security Research]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25206462">thread link</a>) | @arkadiyt
<br/>
November 24, 2020 | https://nedwill.github.io/blog/jekyll/update/2020/11/25/banned-for-research.html | <a href="https://web.archive.org/web/*/https://nedwill.github.io/blog/jekyll/update/2020/11/25/banned-for-research.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>Note that this post does not reflect the opinions of my employer nor my colleagues, and I conducted this research on my own time.</em></p>

<p>About a week ago, Activision banned me from Call of Duty: Modern Warfare/Warzone (2019) for attempting to study the security of its networking code.</p>

<p>As a user, I think I ought to be able to research vulnerabilities when I may be at risk. Multiplayer games do a great deal of networked communication, both between the user and the vendor (e.g., for fetching stats or user configuration) and between users (when hosting a private game or communicating over the microphone). A user should be able to trust that playing the game in a typical manner should not lead to a compromise. Some initial background research revealed that other security researchers, like me, have reverse engineered previous iterations of the game to discover and report vulnerabilities. There is already a precedent for both the validity of the security risk and Activision’s demonstrated openness to vulnerability reports [<a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-20817">1</a>, <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-10718">2</a>, <a href="https://github.com/momo5502/cod-exploits/tree/master/huffman">3</a>, <a href="https://github.com/momo5502/cod-exploits/tree/master/steam-auth">4</a>].</p>

<p>To do this research, I needed to reverse engineer the networking code in the game’s executable, as this would allow me to review the code for memory corruption vulnerabilities. Unfortunately, the executable was heavily obfuscated, and IDA was unable to analyze it. Therefore, I had to dump the unobfuscated code from the memory of a running game process. I believe it was at this point where the developers flagged me as a suspected cheater. I did two things to try to read memory from the process while I was in the main menu to avoid affecting any players. First, I attached WinDbg, and the game exited (probably the flagging event). Next, I tried pausing the process before dumping memory from it. I simply dumped an image of the game from memory in the main menu and then exited normally.</p>

<p>After spending a few days reviewing the binary, I decided that the binary was so large and unwieldy to deal with that I would table the project for a later date. But unfortunately, I was banned about a month later, losing over a year of progress on my account. The ban saddens me on a personal level as I’ve reconnected with family and friends from throughout my life playing this game during the pandemic. But more importantly, this sends a clear signal: this research is not welcome. I believe I had a reasonable expectation that it would be. I had done similar work during a CTF, where I reverse engineered and fuzzed CS:GO without ever risking a ban. Valve regularly accepts bug reports, and in one case, they paid a researcher $18000 for <a href="https://hackerone.com/reports/470520">reporting a vulnerability</a>.</p>

<p>Cheating is one of the biggest threats to the experience of gamers online. I understand that the developers shoulder an impressive burden in preventing cheat development and use. They need to leverage a variety of signals to detect cheat development and use. I’m guessing that because they may not have seen security researchers reviewing their platform before, they interpret any attempt to reverse engineer as a sign of malicious behavior. No typical player would attach a debugger to the game, and therefore they probably assume they don’t need much more evidence beyond this to issue a ban. Let me be clear: at no point did I intend to develop or use a cheat, and at no point did I manipulate any aspect of the game for another player or even myself. To this day, I don’t know what exactly caused the ban, and there’s no process to appeal it. What if using a reversing tool as part of my job gets me flagged? This fear is in the back of my mind for all games with anti-cheat, not just Warzone.</p>

<p>Where do we go from here? Obviously, I’d appreciate it if Activision unbanned my account. More importantly, I think they should provide a way for security researchers to have a place in the ecosystem by carving out exemptions for security research and establishing a point of contact (even a bug bounty) for vulnerability reports. The task of managing cheaters on the PC platform is growing both in difficulty and <a href="https://www.pcgamer.com/the-controversy-over-riots-vanguard-anti-cheat-software-explained/">controversy</a> - and I believe that Activision should join Valve and other publishers in fostering a symbiotic relationship with security researchers rather than an adversarial one. Together we can make games safer from cheaters and malicious users alike.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://nedwill.github.io/blog/jekyll/update/2020/11/25/banned-for-research.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25206462</guid>
            <pubDate>Wed, 25 Nov 2020 06:23:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overengineering. Predicting the future does not work]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25206269">thread link</a>) | @DevTalker
<br/>
November 24, 2020 | https://ddimitrov.dev/2020/11/24/overengineering-predicting-the-future-does-not-work/ | <a href="https://web.archive.org/web/*/https://ddimitrov.dev/2020/11/24/overengineering-predicting-the-future-does-not-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


			
<p>This one will be short.</p>



<p>Yesterday, while I was browsing a programming forum, I came across a statement like this:</p>



<p>â€œâ€¦ and currently, I am creating some neat abstractions if I need something more in the futureâ€¦â€�.</p>



<p>This is so wrong! And let me tell you why.</p>



<h2>Overengineering</h2>



<p>Overengineering in software development means creating something that is not needed. Something that brings overhead to the development process and inefficiency to the end product.</p>



<p>An elementary example of overengineering is if all your applications data can be saved in a 10 line XML file, but you use a SQL database.</p>



<h2>Predicting the future</h2>



<p>One of the reasons overengineering happens is because of a lack of information.</p>



<p>Often developers want to predict the future, so they are ready when new requirements come, or requirements change.</p>



<p>The practice and statistics show that they are tragically bad at that.</p>



<p>In fact, even business people donâ€™t know how requirements will change.</p>



<p>Thatâ€™s why <a href="https://en.wikipedia.org/wiki/Agile_software_development">agile methodologies</a> were born.</p>



<p>In the modern world of software development, it often happens during one sprint to create functionality, and in the next one, to change it so drastically that it is better to start all over again.</p>



<p>Do you believe that you will have the right estimate and create the right thing from the first time with all this uncertainty and change? I believe not.</p>



<p>Predicting the future is a waste of <a href="https://ddimitrov.dev/2020/06/29/software-development-is-about-being-effective-and-efficient/">resources</a>, so donâ€™t do it.</p>



<h2>Inexperienced developers</h2>



<p>Inexperienced developers tend to create overengineered things by default ðŸ˜Š. And thatâ€™s is normal for their level.</p>



<p>They do it mainly because of two reasons.<br>1) They want to create something complicated and â€œcoolâ€�, trying new practices, patterns, and technologies.</p>



<p>2) They donâ€™t see a simple way of doing it.</p>



<p>Only gaining experience can solve the second one, but inexperienced developers should intentionally avoid the first one.</p>



<p>Donâ€™t get me wrong. <a href="https://ddimitrov.dev/2020/10/18/how-to-learn-to-become-a-good-software-developer/">New things should be tested</a>, but not directly on paying customerâ€™s projects.</p>
				
		</div></div>]]>
            </description>
            <link>https://ddimitrov.dev/2020/11/24/overengineering-predicting-the-future-does-not-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25206269</guid>
            <pubDate>Wed, 25 Nov 2020 05:29:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Graphical Output from Our Custom RISC-V Operating System in Rust]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25206221">thread link</a>) | @azhenley
<br/>
November 24, 2020 | https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/ | <a href="https://web.archive.org/web/*/https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
								
								<div>
									
<p>An operating system is used to make our job easier when using graphics. In our instance, in addition to everything else. In this post, we will be writing a GPU (graphics processing unit) driver using the VirtIO specification. In here, we will allow user applications to have a portion of the screen as RAM–with what is commonly known as a <em>framebuffer</em>.</p>



<hr>



<h2>Contents</h2>



<ol><li><a href="#overview">Overview</a></li><li><a href="#pixels">Pixels and Resolution</a></li><li><a href="#virtio">The GPU VirtIO Device</a></li><li><a href="#init">Initialization</a></li><li><a href="#invalid">Invalidation and Transfer</a></li><li><a href="#response">Device Responses</a></li><li><a href="#user">User Space</a></li><li><a href="#api">Simple Graphics API</a></li><li><a href="#conclusion">Conclusions and Further Reading</a></li></ol>



<hr>



<h2 id="overview">Overview</h2>



<p>We command the virtual GPU (virtio-gpu) by sending certain commands to the host (the device). The guest (the OS driver) has an allocation of RAM that becomes the framebuffer. The driver then tells the device, “hey, here’s the RAM that we’re going to use to store pixel information.”</p>



<p>The RAM is contiguous in our OS, but according to the specification, this isn’t strictly required. We will give the driver a rectangle. Everything that falls within that rectangle will be copied to the host. We don’t want to keep copying the entire buffer over and over again.</p>



<p>We will be using the virtio protocol that we used for the block driver here, so I won’t rehash the general virtio protocol. However, the device-specific structures are a bit different, so we’ll cover that part more in depth.</p>



<hr>



<h2 id="pixels">Pixels and Resolution</h2>



<p>A framebuffer must be large enough to store \(\text{width}\times\text{height}\times\text{pixel size}\) number of bytes. There are \(\text{width}\times\text{height}\) number of pixels. Each pixel has a 1-byte red, green, blue, and alpha channels. So, each pixel is exactly 4 bytes with the configuration we’re going to specify.</p>



<p>The framebuffer for our junior GPU driver is going to support a fixed resolution of \(640\times 480\). If you’re a child of the 90s, you saw this resolution a lot. In fact, my first computer, a Laser Pal 386, had a 16-color monitor with a resolution of 640 pixels wide with 480 pixels tall.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png" alt="" width="458" height="281" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png 611w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13-300x184.png 300w" sizes="(max-width: 458px) 100vw, 458px"></a></figure></div>



<p>There are red, green, and blue pixels so close together that by varying the intensity of these three channels, we can change the color. The closer we get to our monitors, the easier a pixel is to see.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png" alt="" width="285" height="288" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png 380w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14-297x300.png 297w" sizes="(max-width: 285px) 100vw, 285px"></a><figcaption>Pixels on a Viewsonic VX2770SMH-LED monitor.</figcaption></figure></div>



<p>You can see these little squares. If you squint enough, you can see that they aren’t pure white. Instead, you can see bits of red, blue, and green. That’s because each one of these little squares is subdivided into three colors: yep, red, green, and blue! To make white, these pixels are turned up to 11 (get the joke?). To make black, we turn off all three channels of that pixel.</p>



<p>The resolution refers to how many of these squares are on our monitor. This is a 1920×1080 monitor. That means that there are 1920 of these squares going left to right, and there are 1080 of these squares from top to bottom. All in all, we have \(1920\times 1080=2,073,600\) number of pixels. Each one of these pixels is expressed using 4 bytes in the framebuffer, meaning we need \(2,073,600\times 4=8,294,400\) bytes in RAM to store the pixel information.</p>



<p>You can see why I limited our resolution to 640×480, which only requires \(640\times 480\times 4=1,228,800\) bytes–a bit over a megabyte.</p>



<hr>



<h2 id="virtio">The GPU VirtIO Device</h2>



<p>The GPU device requires us to read a more up-to-date VirtIO specification. I’ll be reading from version 1.1, which you can get a copy here: <a href="https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html">https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html</a>. Specifically, chapter 5.7 “GPU Device”. This is an <em>unaccelerated</em> 2D device, meaning that we must use the CPU to actually form the framebuffer, then we transfer our CPU formulated memory location to the host GPU, which is then responsible for drawing it to the screen.</p>



<p>The device uses a request/response system, where we the driver make a command to request something from the host (the GPU).  We add a bit of extra memory into our request so that the host can formulate its response. When the GPU interrupts us, we can take a look at this response memory location to see what the GPU told us. This is much like the <em>status</em> field on the block driver, where the block device tells us the status of our last request.</p>



<p>Each request starts with a <em>Command Header</em>, which in Rust looks as follows:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(C)]
struct CtrlHeader {
	ctrl_type: CtrlType,
	flags: u32,
	fence_id: u64,
	ctx_id: u32,
	padding: u32
}</pre>



<p>The header is common for all requests and all responses. We can differentiate by the CtrlType enumeration, which is:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum CtrlType {
	/* 2d commands */
	CmdGetDisplayInfo = 0x0100,
	CmdResourceCreate2d,
	CmdResourceUref,
	CmdSetScanout,
	CmdResourceFlush,
	CmdTransferToHost2d,
	CmdResourceAttachBacking,
	CmdResourceDetachBacking,
	CmdGetCapsetInfo,
	CmdGetCapset,
	CmdGetEdid,
	/* cursor commands */
	CmdUpdateCursor = 0x0300,
	CmdMoveCursor,
	/* success responses */
	RespOkNoData = 0x1100,
	RespOkDisplayInfo,
	RespOkCapsetInfo,
	RespOkCapset,
	RespOkEdid,
	/* error responses */
	RespErrUnspec = 0x1200,
	RespErrOutOfMemory,
	RespErrInvalidScanoutId,
	RespErrInvalidResourceId,
	RespErrInvalidContextId,
	RespErrInvalidParameter,
}</pre>



<p>I took this directly from the specification, but Rust-ified the names to avoid getting yelled at by the linter.</p>



<h3>Pixel Formats</h3>



<p>Recall that the framebuffer is just a bunch of bytes in memory. We need to put a structure behind the framebuffer so the host (the GPU) knows how to interpret your sequence of bytes. There are several formats, but all-in-all, they just re-arrange the red, green, blue, and alpha channels. All are exactly 4 bytes, which makes the <em>stride</em> the same. The stride is the spacing from one pixel to another–4 bytes.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum Formats {
	B8G8R8A8Unorm = 1,
	B8G8R8X8Unorm = 2,
	A8R8G8B8Unorm = 3,
	X8R8G8B8Unorm = 4,
	R8G8B8A8Unorm = 67,
	X8B8G8R8Unorm = 68,
	A8B8G8R8Unorm = 121,
	R8G8B8X8Unorm = 134,
}</pre>



<p>The type, <em>unorm</em>, is an 8-bit (1-byte) unsigned value from 0 through 255, where 0 represents no intensity and 255 represents full intensity, and a number in between is a linear-interpolation between no and full intensity. Since there are three color (and one alpha), that gives us \(256\times 256\times 256=16,776,216\) different colors or levels of colors.</p>



<p>For this tutorial, I selected <code>R8G8B8A8Unorm = 67</code>, which has red first, green second, blue third, and alpha fourth. This is a common ordering, so I’ll select it to make it easy to follow along.</p>



<p>Our selected format makes the pixel structure look as follows:</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png" alt="" width="512" height="307" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png 1024w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-300x180.png 300w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-768x461.png 768w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1536x921.png 1536w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-2048x1228.png 2048w" sizes="(max-width: 512px) 100vw, 512px"></a></figure></div>



<p>Recall that each individual component R, G, B, and A are each one byte a piece, so each Pixel referred to by (x, y) is 4 bytes. This is why our memory pointer is a Pixel structure instead of a byte.</p>



<hr>



<h2 id="init">Initialization</h2>



<p>Just like all other virtio devices, we set up the virtqueues first and then we work on device-specific initialization. In my code, I just directly copied-and-pasted from the block driver into the gpu driver. The only thing I added to the Device structure was the framebuffer and dimensions of the framebuffer.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">pub struct Device {
	queue:        *mut Queue,
	dev:          *mut u32,
	idx:          u16,
	ack_used_idx: u16,
	framebuffer:  *mut Pixel,
	width:        u32,
	height:       u32,
}</pre>



<p>The specification tells us to do the following in order to initialize the device and get things ready to draw. I Rust-ified some of the content to match our enumerations.</p>



<h4>Create a framebuffer and configure scanout</h4>



<ol><li>Create a host resource using <code>CmdResourceCreate2d</code>.</li><li>Allocate a framebuffer from guest ram, and attach it as backing storage to the resource just created, using <code>CmdResourceAttachBacking</code>.</li><li>Use <code>CmdSetScanout</code> to link the framebuffer to a display scanout.</li></ol>



<h3>A Request Structure</h3>



<p>Recall that our request and response come packaged together. We will put them in separate descriptors, but whenever we get a response back from the device, it is going to be easier if we free just once to free both the request and response. So, in Rust, I created the Request structure to support doing this.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">struct Request&lt;RqT, RpT&gt; {
	request: RqT,
	response: RpT,
}
impl&lt;RqT, RpT&gt; Request&lt;RqT, RpT&gt; {
	pub fn new(request: RqT) -&gt; *mut Self {
		let sz = size_of::&lt;RqT&gt;() + size_of::&lt;RpT&gt;();
		let ptr = kmalloc(sz) as *mut Self;
		unsafe {
			(*ptr).request = request;
		}
		ptr
	}
}</pre>



<h4>Step 1: Create host resource</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request::new(ResourceCreate2d {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceCreate2d,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	format: Formats::R8G8B8A8Unorm,
	width: dev.width,
	height: dev.height,
});
let desc_c2d = Descriptor {
	addr: unsafe { &amp;(*rq).request as *const ResourceCreate2d as u64 },
	len: size_of::&lt;ResourceCreate2d&gt;() as u32,
	flags: VIRTIO_DESC_F_NEXT,
	next: (dev.idx + 1) % VIRTIO_RING_SIZE as u16,
};
let desc_c2d_resp = Descriptor {
	addr: unsafe { &amp;(*rq).response as *const CtrlHeader as u64 },
	len: size_of::&lt;CtrlHeader&gt;() as u32,
	flags: VIRTIO_DESC_F_WRITE,
	next: 0,
};
unsafe {
	let head = dev.idx;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d_resp;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).avail.ring[(*dev.queue).avail.idx as usize % VIRTIO_RING_SIZE] = head;
	(*dev.queue).avail.idx = (*dev.queue).avail.idx.wrapping_add(1);
}</pre>



<p>All we’re really telling the GPU here is our resolution and the format of the framebuffer. When we create this, the host gets to configure itself, such as allocating an identical buffer to make transfers from our OS.</p>



<h4>Step 2: Attach framebuffer backing.</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request3::new(AttachBacking {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceAttachBacking,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	nr_entries: 1,
},
MemEntry {
	addr: dev.framebuffer as u64,
	length: dev.width * dev.height * size_of::&lt;Pixel&gt;() as u32,
	…</pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/">https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/</a></em></p>]]>
            </description>
            <link>https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25206221</guid>
            <pubDate>Wed, 25 Nov 2020 05:14:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automatic Content Recognition (ACR) – How Does It Work?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25206054">thread link</a>) | @ponderingfish
<br/>
November 24, 2020 | https://ottverse.com/acr-automatic-content-recognition-how-does-it-work/ | <a href="https://web.archive.org/web/*/https://ottverse.com/acr-automatic-content-recognition-how-does-it-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><strong>Automatic Content Recognition (ACR) refers to technology embedded into OTT applications or SmartTVs that recognizes the content that you are watching by sampling small portions of the video/audio and comparing it with a large database. </strong></p>



<p>ACR is prevalent in SmartTVs and hand-held devices and plays a major role in the audience measurement and ad-tracking industry. </p>



<p>In this article, let’s take a look at how Automatic Content Recognition or ACR works and some use-cases for this technology. </p>



<hr>



<h2>Firstly, how is Data Gathered from OTT Applications?</h2>



<p>Before we look at ACR, let’s first take a quick look into the field of analytics and data gathering in OTT. </p>



<p>Typically, an SDK or library is integrated into an OTT application (HTML5, Android, iOS, SmartTV app, etc.) and then released to the public. Once it’s installed on a phone, or TV, the application can track the user’s actions, the content being watched, etc. at a very granular level. </p>



<p>Each time the user presses play/pause/stop/etc., the SDK records the action and reports it back to a server. Similarly, data points from millions of users are gathered, cleaned, and then presented in a useable format in dashboards back to the OTT content provider. </p>



<p>In most cases, it’s usually the publisher (aka content provider) who is the consumer of this information and the publisher uses it to improve their QoE, content offering, advertising strategies, etc. </p>



<p>You may think that this level of data-gathering is intrusive, but, the fact of the matter is that you agreed to this by pressing “Yes” on the consent form when you installed the app which in all likelihood, you didn’t read! </p>



<p>With that introduction to data-gathering (which is rather common in today’s world), let’s switch over to another form of intelligence-gathering – Automatic Content Recognition (ACR).</p>



<hr>



<h2>What is Automatic Content Recognition?</h2>



<p>Automatic Content Recognition refers to technology that samples the audio or video that a user is consuming, creates a fingerprint from that sample, and compares this against an extensive database of fingerprints to automatically recognize what was being watched or listened to. In some instances of ACR, the recorded sample might be directly transmitted to a server for processing and further information extraction.</p>



<hr>



<h2>How Does Automatic Content Recognition Work?</h2>



<p>As we’ve already seen, ACR works by sampling the video and/or audio and using that information to determine the content being consumed. This leads us to <strong>Acoustic (or Audio) Fingerprinting</strong> and <strong>Video Fingerprinting.</strong></p>



<p>Here’s a visual explanation of ACR works. Simply put, </p>



<ul><li>fingerprints are generated for the media that needs to be recognized (using either audio or video fingerprinting techniques). These fingerprints are stored in a database. </li><li>ACR-enabled SmartTVs, phones, or other devices generate similar fingerprints and transmit them to a server that compares these device-generated fingerprints with the main database to find a match. </li><li>Based on database-match, metrics or data are generated that provide insights into media consumption. </li></ul>







<div><figure><img loading="lazy" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/image-3.png?resize=622%2C370&amp;ssl=1" alt="ACR Automatic Content Recognition
" width="622" height="370" srcset="https://889329.smushcdn.com/2063466/wp-content/uploads/2020/11/image-3.png?size=240x143&amp;lossy=1&amp;strip=1&amp;webp=1 240w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/image-3.png?resize=300%2C178&amp;ssl=1 300w, https://889329.smushcdn.com/2063466/wp-content/uploads/2020/11/image-3.png?size=480x286&amp;lossy=1&amp;strip=1&amp;webp=1 480w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/image-3.png?resize=768%2C457&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/image-3.png?resize=1024%2C609&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/image-3.png?resize=1200%2C713&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/image-3.png?w=1396&amp;ssl=1 1396w" sizes="(max-width: 622px) 100vw, 622px" data-recalc-dims="1" data-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/image-3.png?resize=622%2C370&amp;ssl=1" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure></div>







<p>That’s fundamentally how fingerprinting and ACR works. Now, let’s take a look at the different techniques used in ACR.</p>



<h3>Acoustic Fingerprinting</h3>



<p>Quoting from Wikipedia, <strong><em>an acoustic fingerprint is a condensed digital summary, a fingerprint, deterministically generated from an audio signal, that can be used to identify an audio sample or quickly locate similar items in an audio database.</em></strong></p>



<p>Certain metrics such as frequency, amplitude, tempo, spectrum (i.e., characteristics in the frequency domain), etc. are used in building a fingerprint or signature of the audio signal. </p>



<p>Another reason why this is important is that audio is generally compressed before transmission. And compression algorithms generally remove characteristics of an audio signal that are not perceptible to humans. Hence, the acoustic fingerprinting algorithm that are you building should also take these sources of distortion and noise into account. </p>



<h3>Video Fingerprinting</h3>



<p>Similar to Audio Fingerprinting, in Video Fingerprinting, small video clips are made from the original video, and certain characteristics are extracted from it. These techniques take care to ensure that image manipulation technologies like compression, or resizing do not affect these fingerprints and the content can be recognized nonetheless. </p>



<h3>Digital Watermarking</h3>



<p>Watermarking is the process of embedding data into video/audio <strong>covertly </strong>such that the embedded information is not ordinarily or easily detected. The watermark can be detected only by specialized and authorized <strong>watermark&nbsp;detecting software</strong>. Watermarking allows publishers to track piracy and establish authenticity.  In the case of Automatic Content Recognition, one can use Watermarking as a method of detecting if someone has engaged with or watched a content. </p>



<hr>



<h2>Uses of ACR</h2>



<p>There are several uses of ACR technology. Some of the more prominent ones are – </p>



<ol><li><strong>Detection of copyright infringement: </strong>Copyrighted material such as video and audio are often used indiscriminately without attributing or paying royalties to the original content creators. If a database of copyrighted content exists, then large UGC platforms such as YouTube, TikTok, Vimeo, etc. could check to see if user-uploaded content contains copyrighted material or not. </li><li><strong>Ad-tracking</strong>: ACR has found a lot of use in the advertising industry and for good reason. Here’s why –<ol><li>Unless you have the <strong>ability to determine if an ad was played and watched by the end-user </strong>(instead of being buried at the end of a long landing page), then your metrics don’t make a lot of sense and it could lead to inflated data with respect to ad impressions, plays, and completion rates. This requires SDKs and changes to the players that can consume a lot of effort and development cycles. </li><li>However, ACR has the ability to recognize the content that is being played by sampling certain pixels of video, or by recognizing the audio. This enables ACR to provide a better picture to the advertisers and publishers on the ad delivery and engagement. </li></ol></li><li><strong>Collating information from different sources</strong>: This is a very interesting use-case of ACR. In most homes, there is one big TV in the living room where people gather to watch movies. However, the content streaming to the TV could come from an STB, Chromecast, Roku, FireStick, or an Xbox. Instead of embedding code inside all these devices, SmartTVs with ACR can recognize the content being played (from the “glass”) and report on it. This allows for content attribution and normalization across a variety of sources. </li><li><strong>Understanding Audiences and their preferences</strong>: Similar to other methods of gathering usage analytics, ACR allows broadcasters and content providers to know how their audience is responding to their content, marketing, strategies, etc. By having fine-grained information about their audience and their usage patterns, broadcasters can better invest their dollars and get a much higher ROI. </li><li><strong>Ad Retargeting by OEMs</strong>: Samsung includes ACR technology in their SmartTVs and sells ad inventory and provides<a href="https://www.samsung.com/us/business/samsungads/resources/tv-ad-retargeting/" target="_blank" rel="noopener"> ad-retargeting services</a>. According to their website, “<em>Samsung Ads offers TV Ad Retargeting that empowers brands to identify audiences who saw or missed their TV spots and reconnect with them via mobile, tablet, desktop or OTT</em>.” And, <em>“Samsung Smart TVs have built-in Automated Content Recognition (ACR) technology that can understand viewing behavior and usage including programs, movies, ads, gaming content and OTT apps in real-time”</em>. You can read more about Samsung’s Privacy Policy <a href="https://www.samsung.com/sg/info/privacy/" target="_blank" rel="noopener">here</a> where they are pretty open about recording your video and audio to understand “you” better! </li></ol>











<hr>



<h2>Controversies Surrounding ACR</h2>



<p>The bone of contention around ACR is due to the fact that audio and/or video are recorded, fingerprinted, and often stored for future use. Some devices might be able to generate the fingerprints on-device, but some might send the audio recordings to the cloud for further processing. </p>



<p>So what happens if your private conversations are in those recordings? Who is listening on the other end?</p>



<p>Samsung got into one of these sticky situations and had to clarify in a <a href="https://news.samsung.com/global/samsung-smart-tvs-do-not-monitor-living-room-conversations" target="_blank" rel="noopener">press release</a>. Their initial privacy policy stated –</p>



<p><em>“Please be aware that if your spoken words include personal or other sensitive information, that information will be among the data captured and transmitted to a third party through your use of Voice Recognition.”</em></p>



<p>This spooked a lot of people and Samsung had to backtrack and <a href="https://news.samsung.com/global/samsung-smart-tvs-do-not-monitor-living-room-conversations" target="_blank" rel="noopener">release a clarifying note</a> that said – </p>



<p><em>If you enable Voice Recognition, you can interact with your Smart TV using your voice. To provide you the Voice Recognition feature,&nbsp;some interactive voice commands may be transmitted (along with information about your device, including device identifiers) to a third-party service provider (currently, Nuance Communications, Inc.) that converts your interactive voice commands to text and to the extent necessary to provide the Voice Recognition features to you. In addition, Samsung may collect and your device may capture voice commands and associated texts so that we can provide you with Voice Recognition features and evaluate and improve the features. Samsung will collect your interactive voice commands only when you make a specific search request to the Smart TV by clicking the activation button either on the remote control or on your screen and speaking into the microphone on the remote control.</em></p>



<p>And, please don’t think that I am picking on Samsung. Another TV manufacturer, Vizio was fined by the FTC for not being forthright with its data-tracking policies. (<a href="https://www.ftc.gov/news-events/press-releases/2017/02/vizio-pay-22-million-ftc-state-new-jersey-settle-charges-it" target="_blank" rel="noopener">link to the notice on the FTC website</a>). </p>



<p>And, here’s an interesting <a href="https://www.consumerreports.org/privacy/how-to-turn-off-smart-tv-snooping-features/" target="_blank" rel="noopener">article from consumerreports.org</a> on how to turn off “snooping” features on Android TVs,&nbsp;Amazon Fire TV Edition,&nbsp;LG,&nbsp;Roku,&nbsp;Samsung,&nbsp;Sony, and&nbsp;Vizio.</p>



<p>All of this constitutes a weird situation, I …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ottverse.com/acr-automatic-content-recognition-how-does-it-work/">https://ottverse.com/acr-automatic-content-recognition-how-does-it-work/</a></em></p>]]>
            </description>
            <link>https://ottverse.com/acr-automatic-content-recognition-how-does-it-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25206054</guid>
            <pubDate>Wed, 25 Nov 2020 04:30:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Great software engineers are never actively looking for a job on job boards]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25205830">thread link</a>) | @karlhughes
<br/>
November 24, 2020 | https://www.karllhughes.com/posts/hiring-process | <a href="https://web.archive.org/web/*/https://www.karllhughes.com/posts/hiring-process">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<article>
<div>
<p><img src="https://www.karllhughes.com/assets/img/hiring.png" alt="Recruiting and Hiring Software Engineers">
</p> 

<p>
2020, Nov 13&nbsp;&nbsp;&nbsp;—&nbsp;
13 minute read
</p>
<section id="mc_embed_signup">

</section>
<p>When I took my first real management role as <a href="https://www.karllhughes.com/posts/packback-engineering">Packback’s Head of Engineering back in 2015</a>, I inherited a great team of engineers who were hired before my promotion. Later that year, when the time came for me to do some of my own hiring, I had to quickly adopt a process for finding and onboarding new software engineers.</p>
<p>I started with the framework my predecessor used and brought in some heavy influences from <em><a href="https://www.karllhughes.com/posts/peopleware">Peopleware</a></em> and Josh Tyler’s <em><a href="https://amzn.to/1XQAfT7">Building Great Software Engineering Teams</a></em>. Over the years, I’ve refined my hiring process - mostly through trial and error - to come up with the iteration described here.</p>
<p>My approach is a little unconventional, but I hope it inspires you to think outside the box. This is going to be a long read, so I’ve broken it down into five sections:</p>
<ol>
<li><a href="#the-problem-with-hiring-software-engineers">The Problem with Hiring</a></li>
<li><a href="#skills-i-look-for-in-software-engineers">Skills I Look For</a></li>
<li><a href="#how-i-find-software-engineers">How I Find Candidates</a></li>
<li><a href="#how-i-hire-software-engineers">How I Hire Engineers</a></li>
<li><a href="#mistakes-ive-made-when-hiring-software-engineers">The Mistakes I’ve Made</a></li>
</ol>
<p><em>Note: If you’re looking for some books to help you on your journey as a software engineering manager, <a href="https://www.karllhughes.com/posts/reading-for-engineering-managers">here are some of my favorites</a>.</em></p>
<h2 id="the-problem-with-hiring-software-engineers">The Problem with Hiring Software Engineers</h2>
<p>Any <a href="https://www.karllhughes.com/posts/engineering-manager">engineering manager</a> who’s hired people in the past will tell you that it’s hard.</p>
<p>There are lots of constraints, no way to fairly compare two candidates, and suitable candidates for one team may be horrible for another. Because it’s so hard, the process has evolved to favor people who think like the interviewers, who know someone at the company, or who perform well in high-pressure interviews. It leaves people with non-traditional backgrounds struggling, often works against diverse candidates, and is nothing like the day-to-day work that most engineers do.</p>
<p>For example, a typical interview may require a phone screen with a recruiter who tests for “soft skills.” Next, an engineering manager may screen for baseline technical skills, and then the candidate may be asked to complete an independent project or come into the office for a whiteboarding session. In either case, <strong>the interview is nothing like a typical day working as an engineer</strong> (although the “take-home” project may be the closest in some environments).</p>
<p>Soft skills are important, but “tell me about a time when…” questions favor people who are quick to make things up, and they <a href="https://www.forbes.com/sites/lizryan/2014/03/04/why-i-hate-behavioral-interviewing/#7229c954693c">don’t demonstrate real judgment or problem-solving skills</a>. It’s impossible to assess someone’s character in a 30-minute phone screen, so at best, you can weed people out who are completely unreliable or have poor verbal communication skills.</p>
<p>Similarly, it’s very hard to judge a person’s technical ability in all things during a 1-hour tech screening. The field of web development (and software engineering in general) is so vast that nobody is going to match your requirements perfectly. You can ask them what technologies they’re familiar with and see if they can have a coherent conversation about technical topics, but you probably can’t bump up against the edges of all of their knowledge, especially if it doesn’t overlap with your own.</p>
<p>Finally, I’ve never done whiteboarding or live coding sessions with candidates, but <a href="https://theoutline.com/post/1166/programmers-are-confessing-their-coding-sins-to-protest-a-broken-job-interview-process">a lot of people really hate them</a>, and I think there’s a good reason for that. In the real world, programmers pushed in front of an audience to solve a problem with an obscure algorithm, no time for independent research, and no access to resources. I would never do this job if that were my day-to-day.</p>
<p>Testing programmers at something they don’t need to be good at and expecting to learn something about how they would work at your company is delusional. These kinds of interviews only serve to make the hiring team feel superior and ensure better outcomes for engineers with traditional CS backgrounds.</p>
<h2 id="skills-i-look-for-in-software-engineers">Skills I Look for in Software Engineers</h2>
<p><img src="https://i.imgur.com/FfOzjCZ.jpg" alt="Software Engineering Skills"></p>
<p>In an effort to redesign our hiring process around the skills that actually matter in software engineering, I took the problem down to <a href="https://fpt.guide/">first principles</a>. What skills do I need in a team of software engineers?</p>
<h3 id="initiative">Initiative</h3>
<p>I have never liked micromanaging people. I remember being a team lead at a restaurant in college and getting irrationally annoyed with people who would stand around while customers were lining up at the register. “Go, take an order or something!”</p>
<p>I digress.</p>
<p>Most software engineers who are looking for a job have a certain level of initiative, but great software engineering candidates go the extra mile all the time. For example, I worked with a guy at Packback who had built a website and extremely popular Twitter account to follow the chatter on police scanners. He did all this to learn new things for fun.</p>
<p>Software engineers who take initiative don’t wait for the hiring manager to email them back, they ask about next steps, and they read about the company before they show up for an interview. It’s not really that hard, but it does take time, and very few candidates do it.</p>
<h3 id="reliability">Reliability</h3>
<p>Initiative is a start, but <a href="https://www.karllhughes.com/posts/hero-myth">I don’t want a hero</a>. I want to build a team of consistently reliable engineers who improve over time.</p>
<p>Candidates with a history of staying in jobs for a long time, strong references, and commitment to projects usually make it to the top of my list when hiring.</p>
<h3 id="competency">Competency</h3>
<p>When I was a new engineering manager, I over-indexed on technical skills. It’s easy to fall into the trap of grading engineers based purely on their technical knowledge (whole companies like <a href="https://www.toptal.com/">Toptal</a> and <a href="https://triplebyte.com/">Triplebyte</a> are built on this fallacy), but arcane trivia does not make a sound engineer.</p>
<p>I’ll talk more about how I gauge a candidate’s competency later in this post, but the key question I ask is, <strong>do I think this engineer can learn to solve the problems we are facing?</strong></p>
<p>It’s not about whether they know all the answers on day one, but instead, I look for curious people who are lifelong learners with a drive to improve themselves. If they have that, I’ll find a way to get them the information they need to succeed in this role.</p>
<h3 id="interest-in-the-mission">Interest in the Mission</h3>
<p>I used to call this “passion,” but after a <a href="https://www.listennotes.com/podcasts/exceptions-welcome/building-a-resilient-career-dea4tx69g32/">lively conversation on the Exceptions Welcome podcast</a> I decided to rebrand this skill.</p>
<p>Ultimately, I only want to hire software engineers who care about our industry, the problems we’re solving, and the method we’re using to get there. If we aren’t pointing in the same direction before they join, I don’t want to spend the first six weeks convincing them.</p>
<p>While I don’t want unquestioning loyalty or people who live at the office, I do think it’s important that software engineers are actually interested in the work they will be doing. It’ll make them happier, and that positivity rubs off on everyone.</p>
<h2 id="how-i-find-software-engineers">How I Find Software Engineers</h2>
<p><img src="https://i.imgur.com/bTlxNvy.jpg" alt="Finding Software Engineers"></p>
<p>I’ve used several methods for finding and recruiting software engineers over the years. While I don’t have a ton of data to back up these methods, here’s what I’ve found works for me.</p>
<h3 id="job-listings">Job Listings</h3>
<p>Job listings are the <em><a href="https://unbounce.com/landing-page-articles/what-is-a-landing-page/">landing page</a></em> for job hunters.</p>
<p>A compelling job listing should outline the tools and languages the candidate should know, the projects the candidate will work on, and as much information about day-to-day expectations as is reasonable. I try to make job listings interesting and creative, so I typically use a GitHub repository with lots of information about our team, our company, and the job interview process (<a href="https://github.com/thegraidenetwork/job-openings">here’s an example of the repo I set up for The Graide Network</a>).</p>
<p>Remember that you won’t just share this listing with candidates. You’ll also be emailing it out to everyone in your network, sharing it on social media, and linking to it from your website. It’s a public-facing document that should be good looking and functional.</p>
<h3 id="networking">Networking</h3>
<p>I’ve never paid money to promote a job listing, but I doubt it’s worth it, and here’s why:</p>
<p><strong>The best software engineers are never <em>actively</em> looking for a job on job boards.</strong></p>
<p>They’re locked away behind gatekeepers called “their network,” which includes former managers and coworkers, friends, and people who know them from professional organizations. They jump ship when someone they trust tells them about a great opportunity or when they decide to ask around. Senior software engineers often laugh about how many Linkedin messages we get from naive recruiters.</p>
<p>So, what’s the trick to building a network full of software engineers?</p>
<p>Time.</p>
<p>People are surprised when I tell them that <a href="https://www.karllhughes.com/posts/the-key-to-networking-keeping-in-touch">I spend 4-8 hours per week building and maintaining my network</a>, but the dividends on that investment have been enormous. Whenever I have a new job opening, I write up a job listing and start passing it around. I keep a huge list of people I’d like to work with someday, so I go through it and find an excuse to get lunch.</p>
<p>If you’re not actively building your network right now, start <a href="https://ctocraft.com/blog/how-to-use-writing-to-build-a-solid-talent-pipeline/">writing</a>, <a href="https://www.karllhughes.com/posts/speaking-guide">speaking</a>, and taking meetings with interesting people. It’s the best investment you can make in your career.</p>
<h3 id="cold-outreach">Cold Outreach</h3>
<p>Another unpopular recruiting tool for finding software engineers is cold outreach. I’ve found that it can work, but you have to be careful. It’s easy to come off as spammy or annoying.</p>
<p>Treat cold outreach as an excuse to grow your network rather than jumping straight to “the ask.” Reach out to people, ask them genuine questions; do some research on their background; get to know them. You’re just having a conversation, and eventually, you might slide in a mention that you’re keeping an eye out for software engineers.</p>
<p>End each call by asking if you can follow up in a few months and (shocker!) actually do it. I’ve met some outstanding people this way, even if we never ended up working together.</p>
<h3 id="recruiters">Recruiters</h3>
<p>Recruiters get a bad name in the software engineering world because they can be pretty annoying. I’ve had junior recruiters cold call me at work or send job requests to my company email. Not a good look.</p>
<p>On the flip side, there are a few well-networked and honest tech recruiters out there. Just be ready to pay big bucks as the best likely work on a <a href="https://theundercoverrecruiter.com/contingency-vs-retained-recruiters-what-difference/">retainer rather than contingency</a>.</p>
<p>Even if you do get a recruiter, you need to keep recruiting too. If your recruiter doesn’t have any luck, you don’t want all your leads to dry up with them.</p>
<h2 id="how-i-hire-software-engineers">H…</h2></div></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.karllhughes.com/posts/hiring-process">https://www.karllhughes.com/posts/hiring-process</a></em></p>]]>
            </description>
            <link>https://www.karllhughes.com/posts/hiring-process</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205830</guid>
            <pubDate>Wed, 25 Nov 2020 03:42:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[4 V's of Good Data Engineering]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25205610">thread link</a>) | @apex-consulting
<br/>
November 24, 2020 | https://theapex.io/4-vs-big-data | <a href="https://web.archive.org/web/*/https://theapex.io/4-vs-big-data">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                    <p>When talking about scalable data engineering there are four broad categories of questions that we like to start with. I like to call these the four V’s of Good Data Engineering: Volume, Velocity, Variety and Veracity.</p>

<h3 id="overview">Overview</h3>
<ol>
  <li><a href="#volume">Volume</a>
    <ul>
      <li><a href="#current">Current</a></li>
      <li><a href="#desired">Desired</a></li>
      <li><a href="#anticipated">Anticipated</a></li>
    </ul>
  </li>
  <li><a href="#velocity">Velocity</a>
    <ul>
      <li><a href="#input">Input Velocity</a></li>
      <li><a href="#output">Output Velocity</a></li>
      <li><a href="#intra">Intra Velocity</a></li>
      <li><a href="#pressure">Pressure</a></li>
    </ul>
  </li>
  <li><a href="#variety">Variety</a>
    <ul>
      <li><a href="#flexibility">Flexibility</a></li>
      <li><a href="#discoverability">Discoverability</a></li>
      <li><a href="#useability">Useability</a></li>
    </ul>
  </li>
  <li><a href="#veracity">Veracity</a>
    <ul>
      <li><a href="#traceability">Traceability</a></li>
      <li><a href="#expl">Explainability</a></li>
      <li><a href="#expl">Auditability</a></li>
      <li><a href="#security">Security</a></li>
    </ul>
  </li>
</ol>


<p><img src="https://theapex.io/assets/images/volume.png" width="600"></p>
<p>Volume is simply a measure of how much data you wish to process. This is usually a discussion of gross numbers and timelines associated with them, and gives a rough idea of some architecture constraints and guidelines. For volume the discussion is a straightforward one about business goals and aspirations. Usually the discussion breaks down as follows:</p>
<h3 id="-current-volume"><a name="current"></a> Current Volume:</h3>
<p>What is the current volume of data that a particular data pipeline or system is processing. You can also discuss the current architecture and any bottlenecks it may be facing. When looking at current volume of data some considerations that may matter are:</p>
<ol>
  <li><strong><em>Volumes per access level</em></strong>: What volumes of data currently in terms of access patterns. In other words, there may be 10 PB worth of data, but 9 PB of that may be “cold data” or archive data and only 1 PB is regularly accessed or used for any analytics. Further than that it could be that only 1 TB is “hot data” or data that is frequently accessed. This will also impact how data estimates could be affected, for example archive data may be compressed or stored in columnar or analytical formats which would not give an accurate comparison to row based serial data.</li>
  <li><strong><em>Data Retention</em></strong> Companies may not be keeping all the data they wish to currently keep and have imposed retention policies which they may choose to remove if they have a more scalable data strategy in place. Data Retention can also be used to estimate the amount of data flowing through a system regardless of persistence for data processing purposes.</li>
  <li><strong><em>Record/Message size</em></strong> For each current dataset, how big is a record, and at a static point in time how many records of that size are there? In a streaming context this can impose hard limitations on what technologies can be used (Kafka vs. Kinesis for example), in a static data warehousing context it may give ideas about current suboptimal data model design or heavy denormalization patterns along low latency paths in the data pipeline.</li>
  <li><strong><em>Data Footprint</em></strong>  The amount of data a company stores may not be reflective of the total data footprint the company has especially when taking into consideration data retention policies, data that is ephemeral or not stored anywhere, or query patterns which adopt patterns of heavy denormalization. In well-designed systems some denormalization will lend itself towards better separation between write and read latencies, but will result in a lot of duplicate data. Another example of necessary duplicate data is in RAID configurations or replication such as with HDFS, and backups. In other cases there may be unnecessary duplicate data. Its important to suss out instances of heavy data duplication, necessary or not, in order to get a sense for the total data footprint and distinguish between “raw” system data and derived data that the company has synthesized for various reasons.</li>
  <li><strong><em>Key Datasets</em></strong>  It may also be helpful to get a sense for what are the largest datasets a company deals with and the most frequently changing. Sometimes you can infer key elements about how that dataset may change over time, and thus the right strategy for designing around that dataset. For example if they say their largest dataset is “users” and they are a B2C retail company then you can infer that table is most likely to see heavy growth as the business grows, and will have higher demands for read and write latency.</li>
</ol>

<h3 id="desired-volume"><a name="desired"></a>Desired Volume:</h3>
<p>What is the volume of data the company “wishes” to be able to process in the system. “As much as possible” is not an option, it must be finite and realistic. Over provisioning data processing capacity can get expensive really quickly, especially on the higher ends. More open-ended needs and requirements around scaling can be approached using autoscaling or adaptive scheduling. If the answer is “we dont know” an effort should at least be made to help the company try to estimate.</p>
<h3 id="-anticipated-volume"><a name="anticipated"></a> Anticipated Volume:</h3>
<p>This is meant to bookend the previous point. Whereas as the desired volume is where the company wants to be in X years, the anticipated volume is where the company is most likely going to be within that time. This serves as a lower bound where the desired volume forms a rough upper bound. A less jarring way to discuss desired and anticipated volume (because after all what business is going to admit they aren’t going to grow as fast as they want, even though for most businesses the amount of data being handled is a bad vanity metric) is to simply discuss upper and lower bounds of needed capacity.</p>


<p><img src="https://theapex.io/assets/images/velocity.png" width="800"></p>
<p>Velocity is a measure of how quickly the data is moving over time regardless of the volume of data. Normally it’s hard to talk about data velocity without talking about its desired latencies or limits of time that you have in order to process the data which is usually imposed by external technical or business requirements. You can talk about roughly 3 types of velocity:</p>
<h3 id="input-velocity"><a name="input"></a>Input Velocity:</h3>
<p>How quickly is data coming into the system and how does the system need to accommodate that. This can be as simple as knowing that you only have batch access to the data (daily data dumps) vs stream access to a particular subset of the data, thus can only in best case scenario provide batch analytics on it. Or it can be as complex as planning very tailored distributed stream systems to get a specific input consumption rate.</p>
<h3 id="output-velocity"><a name="output"></a>Output Velocity:</h3>
<p>How quickly does the data need to be accessed or read. Typically this is tied to the front end of the process and the business use cases of how the data is being used. Limits on the associated output latency may vary for different subsets of the data, and may also make exchanges between consistency and availability (in the spirit of the <a href="https://en.wikipedia.org/wiki/CAP_theorem">CAP theorem</a>).  In plain terms, you may be willing to sacrifice accuracy of the data for getting it quicker, or you may opt to scale out further in order to get tighter control over both speed and accuracy.</p>
<h3 id="intra-velocity"><a name="intra"></a>Intra Velocity</h3>
<p>Intra latency is the amount of latency that is permissible between input and output velocity, or you can think of it between the various components of a data pipeline. Intra velocity in a data pipeline is a little harder to tack down. Usually this is either an operational metric, or something that is observed and optimized post-hoc. However, this doesn’t mean it isn’t important as it can have cascading effects on other parts of a data pipeline, sometimes in unexpected ways. In streaming systems back pressure engineering is one way to observe and respond dynamically to changes and levels of intra velocity.</p>

<p><img src="https://theapex.io/assets/images/cascading.gif" width="400"></p>
<p>Cascading failures are familiar to those that have designed tightly coupled stream systems</p>
<h4 id="end-to-end-latency">End to End Latency</h4>
<p>Putting together the three latencies associated with each of these and you arrive at what people typically refer to as “end to end” latency requirements, ie once a piece of data hits your system, how much time do you have before your analytics or end users will see the impact of that data. Keep in mind that varying business use cases may have varying requirements around end to end latency. It is not a universal metric. However, multiple data pipelines may end up affecting one particular end to end latency and may require you to more carefully engineer a particular pipeline to “keep pace” with other parts of the pipeline.</p>



<p>Before going onto Variety, I want to make a quick note about the relationship between Volume and Velocity as they don’t exist in isolation but in terms of planning are heavily dependent on one another. In order to do so I want to introduce the idea of “data pressure”.</p>

<p>You can think of Data Pressure as follows:</p>

<div><div><pre><code>Data Pressure = Data Volume x Data Velocity 
</code></pre></div></div>

<p><img src="https://theapex.io/assets/images/pressure.png" width="300"></p>

<p>In other words a relatively low desired data velocity might be offset by higher data volume and vice versa. This basically expresses the data volume in terms of total amount of data needed to be processed per unit time. It is interesting to look at the limits of data pressure. For example, a really low data volume but high input velocity may lend itself towards stream processing. However, if the needed output velocity on the opposite end of the process velocity is very low, say daily, then it may lend itself towards buffering and then batch processing. In short, the pressure expresses how much strain is put on particular parts of a system and what extra parts of the system may need to be designed intermediately in order to marry front and backend pressure demands gracefully. Those parts that feel more pressure than may need to be given special attention, for example, horizontal scaling, or other strategies such as breaking up the data pipeline stages differently.</p>

<p><img src="https://theapex.io/assets/images/dataflow.png" width="800"></p>
<p>Thinking in terms of total data volume per unit time</p>

<p>In some instances certain processes may not decrease the total data pressure but simply exchange one type of pressure for another. For example, batch processing may be slower, but will allow for processing much higher volumes efficiently, whereas you can avoid processing larger volumes by simply micro batch or stream processing at lower frequencies. One is not better than the other, one may simply be more strategically convenient than the other when you take the whole picture into account.</p>

<p><img src="https://theapex.io/assets/images/pressure2.png" width="800"></p>
<p>You can think of a query over larger dataset but same latency similarly to higher pressure demand on a physical system</p>

<p>The other useful aspect of thinking in terms of pressure is that you can also think in terms of pressure differentials, for example, suppose that you have a very large dataset which you need to query with low latency. In …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://theapex.io/4-vs-big-data">https://theapex.io/4-vs-big-data</a></em></p>]]>
            </description>
            <link>https://theapex.io/4-vs-big-data</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205610</guid>
            <pubDate>Wed, 25 Nov 2020 03:09:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Letters from Alaska]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25205393">thread link</a>) | @DoreenMichele
<br/>
November 24, 2020 | https://www.gabrielzzarate.com/blog/alaska | <a href="https://web.archive.org/web/*/https://www.gabrielzzarate.com/blog/alaska">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" id="gatsby-focus-wrapper"><div><section><article><p><em>The following are selections from letters I wrote to my fiancé in the summer of 2014 while working for a commercial salmon fishing company in Kodiak, Alaska.</em></p><h3 id="14-May-2014---Kodiak-Harbor"><a href="#14-May-2014---Kodiak-Harbor" aria-label="14 May 2014   Kodiak Harbor permalink"></a>14 May 2014 - Kodiak Harbor</h3><p>Here in the harbor, there are probably about a hundred large commercial fishing boats docked. Just about every evening, we have seen sea lions come swim amongst the boats! They will surface from time to time. They're huge and entertaining to watch.</p><p>I was a little frustrated while we were working today. James and I have been helping another guy named Jeff. I'm frustrated because both of them have more experience with construction work. Sometimes I'll show my inexperience, and become the joke on the job site. It doesn't bother me too much, but being on the bottom of the totem pole isn't where I like to be. It just gives me the incentive to learn the fishing knots quickly.</p><figure>
  <span>
      <span></span>
  <picture>
        <source srcset="https://www.gabrielzzarate.com/static/7ac0ee8fb1779975df4997c9e927bb9e/f3a60/4778D69B-63AB-4EE9-9F65-DE23C81EE62D_1_105_c.webp 375w,https://www.gabrielzzarate.com/static/7ac0ee8fb1779975df4997c9e927bb9e/08b4d/4778D69B-63AB-4EE9-9F65-DE23C81EE62D_1_105_c.webp 750w,https://www.gabrielzzarate.com/static/7ac0ee8fb1779975df4997c9e927bb9e/2b317/4778D69B-63AB-4EE9-9F65-DE23C81EE62D_1_105_c.webp 1074w" sizes="(max-width: 1074px) 100vw, 1074px" type="image/webp">
        <source srcset="https://www.gabrielzzarate.com/static/7ac0ee8fb1779975df4997c9e927bb9e/bf173/4778D69B-63AB-4EE9-9F65-DE23C81EE62D_1_105_c.jpg 375w,https://www.gabrielzzarate.com/static/7ac0ee8fb1779975df4997c9e927bb9e/acb04/4778D69B-63AB-4EE9-9F65-DE23C81EE62D_1_105_c.jpg 750w,https://www.gabrielzzarate.com/static/7ac0ee8fb1779975df4997c9e927bb9e/edd00/4778D69B-63AB-4EE9-9F65-DE23C81EE62D_1_105_c.jpg 1074w" sizes="(max-width: 1074px) 100vw, 1074px" type="image/jpeg">
        <img src="https://www.gabrielzzarate.com/static/7ac0ee8fb1779975df4997c9e927bb9e/edd00/4778D69B-63AB-4EE9-9F65-DE23C81EE62D_1_105_c.jpg" alt="Kodiak Harbor" title="Kodiak Harbor" loading="lazy">
      </picture>
    </span>
  <figcaption>Kodiak Harbor, Kodiak AK</figcaption></figure><h3 id="26-May-2014---Arriving-on-the-Island"><a href="#26-May-2014---Arriving-on-the-Island" aria-label="26 May 2014   Arriving on the Island permalink"></a>26 May 2014 - Arriving on the Island</h3><p>We arrived on Bear Island today. We took a flight from Kodiak to Larsen Bay, then hopped in the skiff to Bear. The scenery is beautiful, but our Island itself isn't much to look at. We got here and immediately started mending nets. A guy named Peter showed me how to tie the knots to mend the nets, and I'm getting the hang of it. Also, it turns out that our cook is great <!-- -->—<!-- --> what fantastic news! James and I were able to get a room together, just the two of us, which is nice.</p><figure>
  <span>
      <span></span>
  <picture>
        <source srcset="https://www.gabrielzzarate.com/static/f89410ff96af6f091d8634e81884f97b/f3a60/BF8E47A7-EB6F-42F0-9EF8-00FE9E405794_1_105_c.webp 375w,https://www.gabrielzzarate.com/static/f89410ff96af6f091d8634e81884f97b/08b4d/BF8E47A7-EB6F-42F0-9EF8-00FE9E405794_1_105_c.webp 750w,https://www.gabrielzzarate.com/static/f89410ff96af6f091d8634e81884f97b/a9a89/BF8E47A7-EB6F-42F0-9EF8-00FE9E405794_1_105_c.webp 1024w" sizes="(max-width: 1024px) 100vw, 1024px" type="image/webp">
        <source srcset="https://www.gabrielzzarate.com/static/f89410ff96af6f091d8634e81884f97b/bf173/BF8E47A7-EB6F-42F0-9EF8-00FE9E405794_1_105_c.jpg 375w,https://www.gabrielzzarate.com/static/f89410ff96af6f091d8634e81884f97b/acb04/BF8E47A7-EB6F-42F0-9EF8-00FE9E405794_1_105_c.jpg 750w,https://www.gabrielzzarate.com/static/f89410ff96af6f091d8634e81884f97b/72e01/BF8E47A7-EB6F-42F0-9EF8-00FE9E405794_1_105_c.jpg 1024w" sizes="(max-width: 1024px) 100vw, 1024px" type="image/jpeg">
        <img src="https://www.gabrielzzarate.com/static/f89410ff96af6f091d8634e81884f97b/72e01/BF8E47A7-EB6F-42F0-9EF8-00FE9E405794_1_105_c.jpg" alt="Bear Island" title="Bear Island" loading="lazy">
      </picture>
    </span>
  <figcaption>Bear Island</figcaption></figure><h3 id="28-May-2014---Hiking"><a href="#28-May-2014---Hiking" aria-label="28 May 2014   Hiking permalink"></a>28 May 2014 - Hiking</h3><p>Because the season doesn't begin till the 9th, we can't send out mail every day like we will be able to. Today was my second full day on the Island. I mend nets most of the day. The nice thing is I get a break after lunch, and I have been reading and napping. Maybe this summer I can learn to sleep so I can enjoy many long naps next to you. </p><p>I think a big part of passing the time and not going crazy will be the friendships. Tonight after dinner James, Luke, Micah, and I hiked up to the highest point on the Island. It's not that far, but there is a good view up there. Luke challenged us to sprint to the top, but we only got 3/4 of the way before we almost passed out breathless.</p><h3 id="31-May-2014---The-Bana"><a href="#31-May-2014---The-Bana" aria-label="31 May 2014   The Bana permalink"></a>31 May 2014 - The Bana</h3><p>The last two days have been challenging as far as work goes. The weather has been pretty bad, a gale came in yesterday (when the wind blows hard), and it was cold and rainy. But even though it hasn't been the best working conditions, we've kept our spirits up.</p><p>Last night was my first shower here. But they don't just shower; they use what they call a Bana. It's a giant sauna. We sit in there and sweat out all the nasty stuff, then rinse off. It is super relaxing, and I haven't felt so clean in my entire time here.</p><figure>
  <span>
      <span></span>
  <picture>
        <source srcset="https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/f3a60/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.webp 375w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/08b4d/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.webp 750w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/293e0/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.webp 1500w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/9a8a1/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.webp 2250w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/e72c3/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.webp 3000w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/c67aa/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.webp 4000w" sizes="(max-width: 1500px) 100vw, 1500px" type="image/webp">
        <source srcset="https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/bf173/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.jpg 375w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/acb04/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.jpg 750w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/c58a3/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.jpg 1500w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/bd53b/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.jpg 2250w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/12609/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.jpg 3000w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/93719/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.jpg 4000w" sizes="(max-width: 1500px) 100vw, 1500px" type="image/jpeg">
        <img src="https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/c58a3/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.jpg" alt="Mike Falcochio" title="Mike Falcochio" loading="lazy">
      </picture>
    </span>
  <figcaption>Mike Falcochio</figcaption></figure><h3 id="6-June-2014---The-Season-Begins"><a href="#6-June-2014---The-Season-Begins" aria-label="6 June 2014   The Season Begins permalink"></a>6 June 2014 - The Season Begins</h3><p>Today is the second day of the season. Yesterday we got the nets out, and our first pick was pretty big. We only picked the nets once and brought in around 8,000 lbs, equal to like $16,000. Not bad for the first day. </p><p>When we put the nets out, I didn't take any medicine for sea-sickness, and we were out there in 36 mph winds with some pretty rocky seas. I threw up on three different occasions several times and now have those lovely broken blood vessel spots on my face. Now I've been taking Dramamine, and I've been fine. Unfortunately, a few guys are still getting sick even though they are taking medicine, including James.</p><p>This morning I was picking with Calvin, a 6' 5" guy with long curly blond hair that goes past his shoulders. He's super chill, goofy, and a prankster. Anyway, we had a great time. We were picking in one of the roughest nets, and I was in the front reaching to grab a rope over the side. A big wave came, pulling the rope away from me, and I didn't let go. I fell right over the side into the ocean. In a flash, Calvin ran to the front of the skiff to pull me back in. Haha, what a fun, cold dip in the ocean.</p><p>Being out amongst the weather and rough seas has reminded me of a fair bit of the boating accident, but not necessarily in a negative way. I think about it and thank God for using that experience to make me stronger and for allowing me to be back out there without fear. On the back of my orange rain jacket I wrote in Sharpie: "Joy follows suffering and life follows death" with Dad's and Earl's initials underneath. It's a proclamation to the ocean and the waves that even though that day on the Gulf was hard, God has made me stronger and brought me joy. The joy that comes from being in a love relationship with the King of the Universe, who calmed the seas and gives me hope that I will see both my Dads again.</p><figure>
  <span>
      <span></span>
  <picture>
        <source srcset="https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/f3a60/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.webp 375w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/08b4d/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.webp 750w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/293e0/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.webp 1500w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/9a8a1/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.webp 2250w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/e72c3/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.webp 3000w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/c67aa/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.webp 4000w" sizes="(max-width: 1500px) 100vw, 1500px" type="image/webp">
        <source srcset="https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/bf173/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.jpg 375w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/acb04/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.jpg 750w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/c58a3/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.jpg 1500w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/bd53b/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.jpg 2250w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/12609/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.jpg 3000w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/93719/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.jpg 4000w" sizes="(max-width: 1500px) 100vw, 1500px" type="image/jpeg">
        <img src="https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/c58a3/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.jpg" alt="Calvin" title="Calvin" loading="lazy">
      </picture>
    </span>
  <figcaption>Calvin Bulthuis</figcaption></figure><h3 id="10-June-2014"><a href="#10-June-2014" aria-label="10 June 2014 permalink"></a>10 June 2014</h3><p>We had an extended break today because of the weather, so I've been getting extra rest. My back and hands are very sore, so much so that I have to take breaks as I write this letter. They say that the soreness goes away after a few more weeks.</p><h3 id="11-June-2014---Heads-or-Tails"><a href="#11-June-2014---Heads-or-Tails" aria-label="11 June 2014   Heads or Tails permalink"></a>11 June 2014 - Heads or Tails</h3><p>Yesterday I was picking with Luke when we caught a herring in the net (a herring is a small salmon, a little longer than my hand). He picked it up and said, "Heads or tails, Gabe?" I didn't understand what he meant but replied, "tails." He bit off the head, spit it out, and handed me the rest! So I bit off the tail. Nasty stuff! Guys on the crew said the tail is worse because it's where...well, I'll let you imagine what comes out near the tail.</p><h3 id="12-June-2014"><a href="#12-June-2014" aria-label="12 June 2014 permalink"></a>12 June 2014</h3><p>How long is it taking my letters to arive in Greenville? If the weather is good, your letters have been getting here in five to six days, which is quicker than I expected.</p><figure>
  <img src="https://www.gabrielzzarate.com/4e23b322945544755406648171c24d28/low_quality_day_on_the_job-3.gif" alt="A Nice Day on the Job">
  <figcaption>A day on the job. Heavy on the sunshine, light on the fish.</figcaption></figure><h3 id="14-June-2014"><a href="#14-June-2014" aria-label="14 June 2014 permalink"></a>14 June 2014</h3><p>There's not much new to tell here. We've done well as far as the amount of fish we've caught. I think we are close to me the 100,000 lbs mark.</p><p>Can you send me an update on the World Cup? You can probably print out what the scores have been and who scored during the games. That would be awesome.</p><h3 id="17-June-2014"><a href="#17-June-2014" aria-label="17 June 2014 permalink"></a>17 June 2014</h3><p>It's been storming here for the past few days, so we haven't been able to pick the nets three times a day. It seems like we've been fishing for a long time, but we are just getting started in reality. It can be too overwhelming to dwell on how much time I still have to be on this Island. I prefer to take the days one at a time.</p><p>You asked about who I am close to up here. I get along decently well with everyone. Luke is from Charleston. He's a loner and a wild one; he's hiked the Appalachian Trail by himself. In the off-season, he lives in Hawaii and surfs every day. Calvin is also another guy I like. I can't say I am close to anyone yet, though.</p><p>I was so glad to receive your letters today. I love you, Caitlyn. There's a guy named Mike who has a pretty pessimistic view of marriage. He has made a few jokes about getting married to the first girl I started dating, saying that I don't know if there is something else out there better. My response is that I know plenty of girls, and they all represent confirmation after confirmation that what I have is far better. xo :)</p><h3 id="21-June-2014---Summer-Solistice"><a href="#21-June-2014---Summer-Solistice" aria-label="21 June 2014   Summer Solistice permalink"></a>21 June 2014 - Summer Solistice</h3><p>Today is the summer solstice, and they say that the sun won't set until 1 am. The closure was two days long and was a nice break from fishing. The sun has been out for the last two days as well. We haven't seen the sunshine very much.</p><p>I want to hear from you. How did the wedding dress shopping go?</p><figure>
  <span>
      <span></span>
  <picture>
        <source srcset="https://www.gabrielzzarate.com/static/531ac5d8181fcf31e455f32509daf307/f3a60/9C2D88F8-2EBA-4ADE-AFBC-CD8F4507161D_1_105_c.webp 375w,https://www.gabrielzzarate.com/static/531ac5d8181fcf31e455f32509daf307/08b4d/9C2D88F8-2EBA-4ADE-AFBC-CD8F4507161D_1_105_c.webp 750w,https://www.gabrielzzarate.com/static/531ac5d8181fcf31e455f32509daf307/8b983/9C2D88F8-2EBA-4ADE-AFBC-CD8F4507161D_1_105_c.webp 768w" sizes="(max-width: 768px) 100vw, 768px" type="image/webp">
        <source srcset="https://www.gabrielzzarate.com/static/531ac5d8181fcf31e455f32509daf307/bf173/9C2D88F8-2EBA-4ADE-AFBC-CD8F4507161D_1_105_c.jpg 375w,https://www.gabrielzzarate.com/static/531ac5d8181fcf31e455f32509daf307/acb04/9C2D88F8-2EBA-4ADE-AFBC-CD8F4507161D_1_105_c.jpg 750w,https://www.gabrielzzarate.com/static/531ac5d8181fcf31e455f32509daf307/212bf/9C2D88F8-2EBA-4ADE-AFBC-CD8F4507161D_1_105_c.jpg 768w" sizes="(max-width: 768px) 100vw, 768px" type="image/jpeg">
        <img src="https://www.gabrielzzarate.com/static/531ac5d8181fcf31e455f32509daf307/212bf/9C2D88F8-2EBA-4ADE-AFBC-CD8F4507161D_1_105_c.jpg" alt="The Crew" title="The Crew" loading="lazy">
      </picture>
    </span>
  <figcaption>The Crew (left to right): Luke Yarborough, Josh Krohn, Evan Dundas, Adam Wilson, Calvin Bulthus, James Peery, Micah Glassman, Gabriel Zarate, Casey Furnish, Mike Falcochio, Moreno, Mark Barnes</figcaption></figure><h3 id="24-June-2014---The-Crew"><a href="#24-June-2014---The-Crew" aria-label="24 June 2014   The Crew permalink"></a>24 June 2014 - The Crew</h3><p>There are 12 crewmen in total. Mike is from Louisiana and has been coming up to work for the Fields for the last seven years! He is given a lot of responsibility for the crew and is a nice guy. Adam, Casey, and Mark are all from Florida. Adam is a big guy with lots of tattoos and is a big, fat southern teddy bear. Casey annoys me the most probably. He likes to talk a lot and try to tell me what to do when he doesn't know what he's doing himself. Mark is interesting. He has done some pretty hard drugs and tells some wild stories. Micah and Evan are the young guys from Idaho. They are both eighteen and are farm boys. Peter is from California but lives in Tennessee. He's a climber, and we have some great conversations. He wants to go to seminary and seems to love people. Luke is a surfer from Charleston and is a relaxed but funny guy. Then there's Calvin, who is the long, curly-haired giant who has the most infectious smile. What a goofball. Josh is also from California and is not my favorite.</p><p>Kelsey is the cook. She makes delicious food and has a no-nonsense attitude that is good for a girl in her position. Overall it is a great group. We laugh a lot.</p><p>So you found the dress! I could feel your excitement even through the letter, so I know it must be the right one. I'm so curious about it now!</p><p>The sun has been shining here for the past few days. It's been so great to have better weather. I got stung by some jellyfish this afternoon. It's no big deal, just an irritating stinging sensation. </p><figure>
  <span>
      <span></span>
  <picture>
        <source srcset="https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/f3a60/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.webp 375w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/08b4d/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.webp 750w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/293e0/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.webp 1500w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/9a8a1/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.webp 2250w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/e72c3/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.webp 3000w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/c67aa/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.webp 4000w" sizes="(max-width: 1500px) 100vw, 1500px" type="image/webp">
        <source srcset="https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/bf173/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.jpg 375w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/acb04/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.jpg 750w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/c58a3/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.jpg 1500w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/bd53b/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.jpg 2250w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/12609/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.jpg 3000w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/93719/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.jpg 4000w" sizes="(max-width: 1500px) 100vw, 1500px" type="image/jpeg">
        <img src="https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/c58a3/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.jpg" alt="Bear Island at Sunset" title="Bear Island at Sunset" loading="lazy">
      </picture>
    </span>
  <figcaption>Backside of Bear at Sunset</figcaption></figure><h3 id="26-June-2014"><a href="#26-June-2014" aria-label="26 June 2014 permalink"></a>26 June 2014</h3><p>I keep coming back to the concept of contentment. Sometimes I try to count the days, and I can get discouraged. Not just a little down, like really discouraged. I can't wait to return.</p><h3 id="27-June-2014"><a href="#27-June-2014" aria-label="27 June 2014 permalink"></a>27 June 2014</h3><p>I think the most significant prayer request would be endurance to keep going. It's long hours and long days here, and there's a long way to go. Some mornings it's tough to get up and get going. Once I get up and eat breakfast, things get better.</p><h3 id="3-July-2014"><a href="#3-July-2014" aria-label="3 July 2014 permalink"></a>3 July 2014</h3><p>After every morning pick, there is usually a couple of hours for shore work before lunch (depending on how long the pick takes). For the last two days, I've been working in the …</p></article></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.gabrielzzarate.com/blog/alaska">https://www.gabrielzzarate.com/blog/alaska</a></em></p>]]>
            </description>
            <link>https://www.gabrielzzarate.com/blog/alaska</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205393</guid>
            <pubDate>Wed, 25 Nov 2020 02:33:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Origin of the Name Posix]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25205384">thread link</a>) | @wooby
<br/>
November 24, 2020 | https://stallman.org/articles/posix.html | <a href="https://web.archive.org/web/*/https://stallman.org/articles/posix.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<h2><a href="https://stallman.org/">https://stallman.org</a></h2>
<p>
For current political commentary, see
the <a href="https://stallman.org/archives/polnotes.html">daily
political notes</a>.
</p>
<p>
<a href="https://stallman.org/biographies.html#serious">RMS's Bio</a> |
<a href="http://gnu.org/">The GNU Project</a>
</p>

<hr>



<h2>2011-05-11</h2>

<p>
In the 1980s I was in the IEEE committee that wrote the standard that
ultimately became known as POSIX.  The committee set itself the task
of standardizing interface specs for a Unix-like system, but had no
short name for its work.  When the first part of the specification was
ready, someone gave it the name "IEEEIX", with a subtitle that
included "Portable Operating System" — perhaps "Specifications
for a Portable Operating System".
</p>
<p>
It seemed to me that nobody would ever say "IEEEIX", since the
pronunciation would sound like a shriek of terror; rather, everyone
would call it "Unix".  That would have boosted AT&amp;T, the GNU
Project's rival, an outcome I did not want.  So I looked for another
name, but nothing natural suggested itself to me.
</p>
So I put the initials of "Portable Operating System" together with the
same suffix "ix", and came up with "POSIX".  It sounded good and I saw
no reason not to use it, so I suggested it.  Although it was just
barely in time, the committee adopted it.

<p>
I think the administrators of the committee were as relieved as I was
to give the standard a pronounceable name.
</p>
<p>
Copyright (c) 2011 Richard Stallman
Verbatim copying and redistribution of this entire page are
permitted provided this notice is preserved.
</p>


</div>]]>
            </description>
            <link>https://stallman.org/articles/posix.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205384</guid>
            <pubDate>Wed, 25 Nov 2020 02:33:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C is not a subset of C++: A simple program to show differences in the standards]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25205170">thread link</a>) | @abqexpert
<br/>
November 24, 2020 | https://abqexpert.com/2020/11/24/c-is-not-a-subset-of-c-a-simple-program-to-show-differences-in-the-c-and-c-standards/ | <a href="https://web.archive.org/web/*/https://abqexpert.com/2020/11/24/c-is-not-a-subset-of-c-a-simple-program-to-show-differences-in-the-c-and-c-standards/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-883">

    

	<div>

		
<p>The following is a bit of a write up of a program I wrote for a presentation to a bunch of Java programmers(really this was part of a workshop on Qt for Android Programmers) to illustrate that C and C++ are very different languages, and the differences between standards can be large even if the program compiles.  So I tried making this as straightforward as possible.  A ton of people have written up similar things. Hopefully the value here is in the simplicity of the presentation(I tried making it accessible to people with only Java programming experience). I was heavily inspired by <a href="http://ioccc.org/2015/yang/prog.c">Don Yang’s 2015 IOCC entry</a>(Some commentary <a href="http://ioccc.org/2015/yang/hint.html">here</a>, and a fun video of him making it <a href="http://ioccc.org/2015/yang/spoiler.html">here</a>).</p>



<p>Imagine we would like to create a single program which when compiled would tell us how which standard of C or C++ it was compiled with.  Obviously we cannot use any features not common to both C and C++, so no template magic, and so we won’t be able to distinguish between C++98 and C++03 or between C++11,C++14, C++17, or C++20. Obviously we won’t try to tell the difference between C89 and C90 as well. And we will only consider C after C89 since it was not always implemented consistently prior, and K &amp; R function signatures are ugly.   We will try to not use the C preprocessor as much as possible, but in order to tell post-C11 from pre-C11 we need to introduce some macros.</p>



<p>One of the first and simplest differences is between C and C++. In C a character literal like ‘a’ is the same size as an int.  In C++ it is the same size as a char.  Now if you are on a platform where an int and char are the same size, then you will need a different test(In this day and age Fall 2020, even most embedded chips are moving to 32bit ARM/RISC-V/whatever else(I believe most 16bit chips in common use have an int with distinct size from char), where we wouldn’t expect this to be the case). So our first function is:</p>


<pre title="">static int is_C(void){
    int a=0; char b='\0';
    assert(sizeof(a)!=sizeof(b)); /*bail out early on unusual archs.*/
    return (sizeof ('\0') == sizeof(a));
}
</pre>


<p>The next major difference is between C before C99 and C after C99.  The big change was that C++ style inline comments were allowed.  So instead of just ‘/* whatever */’ you could use ‘// whatever’. This leads us to:</p>


<pre title="">static int is_post_ANSI_C(void){
    return 1//**/2
            ;
}
</pre>


<p>So if we have C++ style inline comments we return 1 since the rest of the line is a comment.  If we don’t then we have a ‘/’ followed by a comment followed by 2, so after comment and whitespace removal we get ‘return 1/2;’ which we know by the rules of integer division is 0.</p>



<p>Next in-order to differentiate versions of C and C++ after 2011, and ones before we will need to use a C Preprocessor macro.  After the C11 and C++11 revisions the language changed somewhat dramatically by adding some new prefixes for string literals to allow for the use of Unicode in strings(see <a href="https://en.cppreference.com/w/cpp/language/string_literal">this page</a> for a good reference to what the various prefixes mean, in general cppreference.com is a good source of information on either C or C++).  Here is our macro and function:</p>


<pre title="">#define test(U) U"1"
static int is_post_11(void){
    return (sizeof(test()[0]) &gt;1);
}
</pre>


<p>This uses a trick from Don Yang’s entry, in that in prior versions of the standard the preprocessor would view the ‘U’ in the definition as the value of the argument given to the ‘test’ function-type macro.  In the return statement we pass in no argument so the ‘U’ is replaced by nothing, and we just get ‘sizeof(“1″[0]) &gt;1’ which is just ‘sizeof(char) &gt;1’ which is always false.  In later editions of the standards the ‘U’ is parsed as a prefix to a string literal, in this case a 32bit wide unicode string, so each element in the string that follows the ‘U’ character must be at least 32 bits wide.  As long as we aren’t on an architecture with &gt;=32 bit chars this will lead to ‘sizeof(something at least 32bit) &gt;1’ which will be true for this case.</p>



<p>If proposal N2231 for the C2x standard goes through then both C++20 and C2x will have a char8_t datatype which will be the type of ‘u8’ prefixed string literal which would be another test we could do.</p>







<p>The final program is here:</p>


<pre title="">#include &lt;stdio.h&gt;
#include &lt;assert.h&gt;
 
static int is_post_ANSI_C(void){
    return 1//**/2
            ;
}
 
static int is_C(void){
    int a=0; char b='\0';
    assert(sizeof(a)!=sizeof(b)); 
    return (sizeof ('\0') == sizeof(a));
}
 
#define test(U) U"1"
static int is_post_11(void){
    return (sizeof(test()[0]) &gt;1);
}
 
int main(int argc, char *argv[])
{
    int C = is_C();
    int post_11 = is_post_11();
    int post_ANSI_C = is_post_ANSI_C();
 
    if(C &amp;&amp; post_ANSI_C &amp;&amp; post_11){
        printf("This is C11 or later!\n");
    }
    if(C &amp;&amp; post_ANSI_C &amp;&amp; !post_11){
        printf("This is C99!\n");
    }
    if(C &amp;&amp; !post_ANSI_C &amp;&amp; !post_11){
        printf("This is C89 or C90\n");
    }
    if(!C &amp;&amp; post_11){
        printf("This is C++11 or later\n");
    }
    if(!C &amp;&amp; !post_11){
        printf("This is C++98 or C++03\n");
    }
 
    return 0;
}
</pre>


<p>Which can be compiled with:</p>


<pre title="">gcc -std=c89 main.c
</pre>


<p>Or</p>


<pre title="">g++ -std=c++98 main.c
</pre>


<p>Then it can be run as:</p>


<pre title="">./a.out
</pre>


<p>valid values of the ‘std’ option to try are ‘c90’, ‘c99’, ‘c11’, ‘c++03’, ‘c++11’, etc. More given <a href="https://gcc.gnu.org/onlinedocs/gcc/C-Dialect-Options.html#C-Dialect-Options">here</a>.</p>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://abqexpert.com/2020/11/24/c-is-not-a-subset-of-c-a-simple-program-to-show-differences-in-the-c-and-c-standards/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205170</guid>
            <pubDate>Wed, 25 Nov 2020 01:56:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remember when you could reboot your computer without rebooting your phone first?]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 54 (<a href="https://news.ycombinator.com/item?id=25205031">thread link</a>) | @mdoms
<br/>
November 24, 2020 | https://annoying.technology/posts/7b574a72da90e5cd/ | <a href="https://web.archive.org/web/*/https://annoying.technology/posts/7b574a72da90e5cd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/31a8603310fa498ae382fe6140ad8db20c277711/6bc2e/media/neustartdoeswell.png"></p><p>Remember when you could reboot your computer without rebooting your phone first?</p><p>I’m not even kidding: I needed to reboot my Mac because I was unable to navigate character by character using the arrow keys when composing new iMessages in Big Sur, but Finder refused to quit during the reboot with the above error message. It was still syncing my iPhone. (Remember when we thought the iTunes rewrite would be a good thing? <a href="https://twitter.com/manu_faktur/status/1260099839511212032">Good Times</a>!) I tried quite a few things on both devices, but was unable to cancel said sync in any other way than to reboot the phone.</p></div></div>]]>
            </description>
            <link>https://annoying.technology/posts/7b574a72da90e5cd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205031</guid>
            <pubDate>Wed, 25 Nov 2020 01:30:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BIT joins OpenNebula's Managed Service Provider (MSP) Program]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203765">thread link</a>) | @amarti
<br/>
November 24, 2020 | https://opennebula.io/bit-joins-opennebula-msp-program/ | <a href="https://web.archive.org/web/*/https://opennebula.io/bit-joins-opennebula-msp-program/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			    <!-- .entry-header -->

				
					
<article id="post-28713">

    <!-- .entry-header -->

    <div>

		
<p>Managed Service Providers are out to meet the needs of many organizations, and Managed Private Clouds offer a suitable alternative for those looking to reap the benefits of a private cloud environment without the hassle of managing and administering it on their own. And <a href="https://opennebula.io/opennebula-managed-service-provider-partnership/">OpenNebula announced</a> that it is opening the doors to its Solution Provider Partner Program, making way for qualified MSP’s. Our <a href="https://support.opennebula.pro/hc/en-us/articles/115005959343-Solution-Provider-Partner-Program-Guide">Partner Program</a> makes it easy for MSP’s not only to offer private clouds to their customers that are backed by official OpenNebula Systems support, but also having the security and comfort to deploy these clouds with the OpenNebula Enterprise Edition.&nbsp;</p>



<p><a href="https://www.bit.nl/opennebula" target="_blank" rel="noreferrer noopener">BIT</a> has been a long time user of OpenNebula, as well as an avid contributor to its development and evolution over the years. Now, they have joined our Partner Program as an official OpenNebula MSP, offering a comprehensive private cloud service to their customers that reaps the benefits of an OpenNebula subscription and the official backing and support of the OpenNebula Systems team.</p>







<blockquote><p>“<em><em>With OpenNebula’s feature-rich and stable software, along with its extensibility, flexibility, and integration of third-party tools, we have a platform and a partner which allows us to create a dependable platform for BIT and our customers.</em></em>”&nbsp;</p><cite>– Stefan Kooman, System Administrator, BIT</cite></blockquote>







<p>If you are an MSP using OpenNebula, and you would like to ensure that you are equipped to offer the best managed private cloud and support to your customers, reach out to our <a href="mailto:partners@opennebula.io">Partners Manager</a>, and inquire about how you can partner with us as an OpenNebula MSP Solution Provider Partner.&nbsp;&nbsp;</p>
		
		


        <div>
            <p><img alt="" src="https://secure.gravatar.com/avatar/a1737e9efc6920480d8a1abc8d21fd64?s=96&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/a1737e9efc6920480d8a1abc8d21fd64?s=192&amp;d=mm&amp;r=g 2x" height="96" width="96">            </p>
            <div>
                <p><span id="autorblog">Michael Abdou</span></p><p>Customer Success Manager at OpenNebula</p>
            </div>
        </div>
	</div><!-- .entry-content -->

</article><!-- #post-## -->

					
<!-- #comments -->

				
			</div></div>]]>
            </description>
            <link>https://opennebula.io/bit-joins-opennebula-msp-program/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203765</guid>
            <pubDate>Tue, 24 Nov 2020 22:30:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vim Sessions]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203660">thread link</a>) | @RMPR
<br/>
November 24, 2020 | https://rmpr.xyz/Vim-Session/ | <a href="https://web.archive.org/web/*/https://rmpr.xyz/Vim-Session/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Even though I prefer to use one buffer at a time to be more focused. I sometimes needed to have multiple buffers 
open in splits (Terminal, Netrw, …). And when for whatever reason, I needed to close them or shutdown my computer. I didn’t like loosing my context. Enter Vim sessions.</p>

<p>They are quite simple, if you want to save your layout as it is, just type <code>:mksession</code>  or for short <code>:mks</code> 
(yay! 6 strokes saved) and a file named Session.vim will be created. All you have to do the next time you open 
your project folder is <code>vim -S</code>.</p>

<p>P.S.</p>
<ul>
  <li>If there’s already a session file you will need to append ! at the end of the command to overwrite</li>
  <li>You can eventually specify the session filename, for more info <code>:help :mks</code></li>
</ul>

<p>In almost one year of Vim usage, I always wanted to do this, but somehow tutorials address mostly plugins installation and usage. No, I want the real, rough Vim, please.</p>

<p><a href="https://www.youtube.com/watch?v=jPPozzOCyIw"><img src="https://rmpr.xyz/images/sessions.gif" alt="Vim sessions"></a></p>


  </div></div>]]>
            </description>
            <link>https://rmpr.xyz/Vim-Session/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203660</guid>
            <pubDate>Tue, 24 Nov 2020 22:19:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Build a Production Grade Workflow with SQL Modelling]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203365">thread link</a>) | @oedmarap
<br/>
November 24, 2020 | https://shopify.engineering/build-production-grade-workflow-sql-modelling | <a href="https://web.archive.org/web/*/https://shopify.engineering/build-production-grade-workflow-sql-modelling">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p><strong>By Michelle Ark and Chris Wu</strong></p>
<p>In January of 2014, Shopify built a data pipeline platform for the data science team called Starscream. Back then, we were a smaller team and needed a tool that could deal with everything from ad hoc explorations to machine learning models. We chose to build with PySpark to get the power of a generalized distributed computer platform, the backing of the industry standard, and the ability to tap into the Python talent market.&nbsp;</p>
<p>Fast forward six years and our data needs have changed. Starscream now runs 76,000 jobs and writes 300 terabytes a day! As we grew, some types of work went away, but others (like simple reports) became so commonplace we do them every day. While our Python tool based on PySpark was computationally powerful, it wasn’t optimized for these commonplace tasks. If a product manager needed a simple rollup for a new feature by country, pulling it, and modeling it wasn’t a fast task.</p>
<p>We’ll show you how we moved to a SQL modelling workflow by leveraging <a href="https://www.getdbt.com/" target="_blank" title="Analytics engineering is the data transformation work that happens between loading data into your warehouse and analyzing it. dbt allows anyone comfortable with SQL to own that workflow." rel="nofollow noopener noreferrer">dbt</a> (data build tool) and created tooling for testing and documentation on top of it. All together, these features provide Shopify’s data scientists with a robust, production-ready workflow to quickly build straightforward pipelines.</p>

<p>When we interviewed our users to understand their workflow on Starscream, there were two issues we discovered: <em>development time</em> and <em>thinking</em>.</p>
<p><em>Development time</em> encompasses the time data scientists use to prototype the data model they’d like to build, run it, see the outcome,and iterate. The PySpark platform isn’t ideal for running straightforward reporting tasks, often forcing data scientists to write boilerplate and it yields long runtimes. This led to long iteration cycles when trying to build models on unfamiliar data.</p>
<p>The second issue, <em>thinking</em>, is more subtle and deals with the way the programming language forces you to look at the data. Many of our data scientists prefer SQL to python because its structure forces consistency in business metrics. When interviewing users, we found a majority would write out a query in SQL then translate it to Python when prototyping. Unfortunately, query translation is time consuming and doesn’t add value to the pipeline.</p>
<p>To understand how widespread these problems were, we audited the jobs run and surveyed our data science team for the use cases. We found that 70% or so of the PySpark jobs on Starscream were full batch queries that didn’t require generalized computing. We viewed this as an opportunity to make a kickass optimization for a painful workflow.&nbsp;</p>

<p>Our goal was to create a SQL pipeline for reporting that enables data scientists to create simple reporting data faster, while still being production ready. After exploring a few alternatives, we felt that the dbt library came closest to our needs. Their tagline “deploy analytics code faster with software engineering practices” was <em>exactly</em> what we were looking for in a workflow. We opted to pair it with Google BigQuery as our data store and dubbed the system and its tools, Seamster.</p>
<p>We knew that any off-the-shelf system wouldn’t be one size fits all. In moving to dbt, we had to implement our own:</p>
<ul>
<li>source and model structure to modularize data model development</li>
<li>unit testing to increase the types of testable errors</li>
<li>continuous integration (CI) pipelines to provide safety and consistency guarantees.</li>
</ul>
<h2>Source Independence and Safety</h2>
<p>With dozens of data scientists making data models in a shared repository, a great user experience would</p>
<ul>
<li>maximize focus on work&nbsp;</li>
<li>minimize the impact of model changes by other data scientists.</li>
</ul>
<p>By default, dbt declares raw sources in a central <code>sources.yml</code>. This quickly became a very large file as it included the schema for each source, in addition to the source name. It creates a huge bottleneck for teams editing the same file across multiple PRs.&nbsp;</p>

<p>To mitigate the bottleneck, we leveraged the flexibility of dbt and created a top-level ‘sources’ directory to represent each raw source with its own source-formatted yaml file. This way, data scientists can parse only the source documentation that’s relevant for them and contribute to the <code>sources.yml</code> file without stepping on each other’s toes.</p>

<p><em>Base models are one-to-one interfaces to raw sources.</em></p>
<p>We also created a Base layer of models using the <a href="https://discourse.getdbt.com/t/how-we-structure-our-dbt-projects/355" target="_blank" rel="nofollow noopener noreferrer">‘</a><a href="https://discourse.getdbt.com/t/how-we-structure-our-dbt-projects/355" target="_blank" title="How we structure our dbt projects" rel="nofollow noopener noreferrer">staging’ concept from dbt</a> to implement their best practice of <a href="https://docs.getdbt.com/docs/guides/best-practices/#limit-references-to-raw-data" target="_blank" title="Limit references to raw data - dbt" rel="nofollow noopener noreferrer">limiting references to raw data</a>. Our Base models serve as a one-to-one interface to raw sources. They don’t change the grain of the raw source, but do apply renaming, recasting, or any other cleaning operation that relates to the source data collection system.&nbsp;</p>
<p>The Base layer serves to protect users from breaking changes in raw sources. Raw external sources are by definition out of the control of Seamster and can introduce breaking changes for any number of reasons at any point in time. If and when this happens, you only need to apply the fix to the Base model representing the raw source, as opposed to every individual downstream model that depends on the raw source.&nbsp;</p>
<h2>Model Ownership for Teams</h2>
<p>We knew that the tooling improvements of Seamster would be only one part of a greater data platform at Shopify. We wanted to make sure we’re providing mechanisms to support good dimensional modelling practices and support data discovery.</p>
<p>In dbt, a model is simply a .sql file. We’ve extended this definition in Seamster to define a model as a directory consisting of four files:&nbsp;</p>
<ul>
<li><code>model_name.sql</code></li>
<li><code>schema.yml</code></li>
<li><code>README.md</code></li>
<li><code>test_model_name.py</code></li>
</ul>
<p>You can further organize models into directories that indicate a data science team at Shopify like ‘finance’ or ‘marketing’.&nbsp;</p>
<p>To support a clean data warehouse we’ve also organized data models into these rough layers that differentiate between:</p>
<ul>
<li>
<strong>base</strong>: data models that are one-to-one with raw data, but cleaned, recast and renamed</li>
<li>
<strong>application-ready</strong>: data that isn’t dimensionally modelled but still transformed and clean for consumption by another tool (for example,&nbsp; training data for a machine learning algorithm)</li>
<li>
<strong>presentation</strong>: shareable and reliable data models that follow dimensional modelling best practices and can be used by data scientists across different domains.</li>
</ul>
<p>With these two changes, a data consumer can quickly understand the data quality they can expect from a model and find the owner in case there is an issue. We also pass this metadata upstream to <a href="https://shopify.engineering/solving-data-discovery-challenges-shopify" target="_blank" title="How We’re Solving Data Discovery Challenges at Shopify" rel="nofollow noopener noreferrer">other tools</a> to help with the data discovery workflow.</p>
<h2>More Tests</h2>
<p>dbt has native support for ‘schema tests’, which are encoded in a model’s schema.yml file. These tests run against production data to validate data invariants, such as the presence of null values or the uniqueness of a particular key. This feature in dbt serves its purpose well, but we also want to enable data scientists to write unit tests for models that run against fixed input data (as opposed to production data).</p>
<p>Testing on fixed inputs allows the user to test edge cases that may not be in production yet. In larger organizations, there can and will be frequent updates and many collaborators for a single model. Unit tests give users confidence that the changes they’re making won’t break existing behaviour or introduce regressions.&nbsp;</p>
<p>Seamster provides a Python-based unit testing framework. Data scientists write their unit tests in the <code>test_model_name.py</code> file in the model directory. The framework enables constructing ‘mock’ input models from fixed data. The central object in this framework is a ‘mock’ data model, which has an underlying representation of a Pandas dataframe. You can pass fixed data to the mock constructor as either a csv-style string, Pandas dataframe, or a list of dictionaries to specify input data.&nbsp;</p>
<p><img alt="Input and expected MockModels are built from static data. The actual MockModel is built from input MockModels by BigQuery. Actual and expected MockModels can assert equality or any Great Expectations expectation" data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/input-expected-mock-models.jpg?v=1605811967" src="https://cdn.shopify.com/s/files/1/0779/4361/files/input-expected-mock-models.jpg?v=1605811967"><br><em>Input and expected MockModels are built from static data. The actual MockModel is built from input MockModels by BigQuery. Actual and expected MockModels can assert equality or any Great Expectations expectation.</em></p>
<p>A constructor creates a test query where a common table expression (CTE) represents each input mock data model, and any references to production models (identified using dbt’s ‘ref’ macro) are replaced by references to the corresponding CTE. Once you execute a query, you can compare the output to an expected result. In addition to an equality assertion, we extended our framework to support all expectations from the open-source <a href="https://github.com/great-expectations/great_expectations" target="_blank" title="Great Expectations - Always know what to expect from your data." rel="nofollow noopener noreferrer">Great Expectations</a> library to provide more granular assertions and error messaging.&nbsp;</p>
<p>The main downside to this framework is that it requires a roundtrip to the query engine to construct the test data model given a set of inputs. Even though the query itself is lightweight and processes only a handful of rows, these roundtrips to the engine add up. It becomes costly to run an entire test suite on each local or CI run. To solve this, we introduced tooling both in development and CI to run the minimal set of tests that could potentially break given the change. This was straightforward to implement with accuracy because of dbt’s lineage tracking support; we simply had to find all downstream models (direct and indirect) for each changed model and run their tests.&nbsp;</p>
<h2>Schema and Directed Acyclic Graph Validation on the Cheap</h2>
<p>Our objective in Seamster’s CI is to give data scientists peace of mind that their changes won’t introduce production errors the next time the warehouse is built. They shouldn’t have to wonder whether removing a column will cause downstream dependencies to break, or whether they made a small typo in their SQL model definition.</p>
<p>To achieve this accurately, we would need to build and tear down the entire warehouse on every commit. This isn’t feasible from both a time and cost perspective. Instead, on every commit we materialize every model as a view in a temporary BigQuery dataset which is created at the start of the validation process and removed as soon as the validation finishes. If we can’t build a view because its upstream model doesn’t provide a certain column, or if the SQL is invalid for any reason, BigQuery fails to build the view and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shopify.engineering/build-production-grade-workflow-sql-modelling">https://shopify.engineering/build-production-grade-workflow-sql-modelling</a></em></p>]]>
            </description>
            <link>https://shopify.engineering/build-production-grade-workflow-sql-modelling</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203365</guid>
            <pubDate>Tue, 24 Nov 2020 21:52:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Conducto – Use Python to write, run, view and debug DevOps pipelines]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25203326">thread link</a>) | @jonsolo
<br/>
November 24, 2020 | https://www.conducto.com/app/sandbox/github/conducto/examples?dir=cicd%2Fflask_microservice&preview_file=pipeline.py | <a href="https://web.archive.org/web/*/https://www.conducto.com/app/sandbox/github/conducto/examples?dir=cicd%2Fflask_microservice&preview_file=pipeline.py">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.conducto.com/app/sandbox/github/conducto/examples?dir=cicd%2Fflask_microservice&amp;preview_file=pipeline.py</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203326</guid>
            <pubDate>Tue, 24 Nov 2020 21:48:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[US internet speeds 91% faster in 2020 according to user speed tests]]>
            </title>
            <description>
<![CDATA[
Score 161 | Comments 203 (<a href="https://news.ycombinator.com/item?id=25203256">thread link</a>) | @mootothemax
<br/>
November 24, 2020 | https://fairinternetreport.com/research/usa-vs-europe-internet-speed-analysis | <a href="https://web.archive.org/web/*/https://fairinternetreport.com/research/usa-vs-europe-internet-speed-analysis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><ul><li>US broadband speeds <strong>increased 91%</strong> from 2019-2020, <strong>nearly doubling</strong> YoY, as measured by annual speed test medians</li><li>US average broadband speeds overtook western EU countries like the UK, France, and Germany for the first time in 5 years</li><li>Broadband speeds in the EU overall rose 57% from 2019–2020, 34% lower than the 91% performance increase in the US</li></ul><p>American internet users have had a very good 2020: according to research performed by FairInternetReport, median US internet speeds in 2020 doubled to 33.16mbps, up from 17.34mbps in 2019. Covering the five years of 2016, 2017, 2018, 2019, and 2020, this is the largest speed increase seen in the US, with speeds staying essentially the same in 2016 and 2017 (8.91mbps and 9.08mbps respectively), and 2018 recording a median speed of 12.83mbps.</p><p>The US stills lags behind many European and developed nations worldwide, and its major cities also often lag behind their European equivalents. That said, there is cause for celebration in Dallas, Seattle and Austin, after our analysis has shown that these cities are performing extremely well relative to most European capital cities.</p></div></div></div>]]>
            </description>
            <link>https://fairinternetreport.com/research/usa-vs-europe-internet-speed-analysis</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203256</guid>
            <pubDate>Tue, 24 Nov 2020 21:38:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A 10x better way to manage your job search]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203150">thread link</a>) | @jacobdpeters
<br/>
November 24, 2020 | https://www.tealhq.com/job-tracker | <a href="https://web.archive.org/web/*/https://www.tealhq.com/job-tracker">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="w-node-c72cce9215f1-2656f85e"><div><h2>Save any job listing <br>on the internet.</h2><p>Teal's Chrome Extension will scrape job descriptions from all the most popular listing sites — from LinkedIn to Glassdoor. If it doesn’t recognize a site, you can also add the job posting manually.<br></p></div></div></div>]]>
            </description>
            <link>https://www.tealhq.com/job-tracker</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203150</guid>
            <pubDate>Tue, 24 Nov 2020 21:24:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Emacs Speed Up 1000%]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25202942">thread link</a>) | @tartoran
<br/>
November 24, 2020 | https://blog.binchen.org/posts/emacs-speed-up-1000.html | <a href="https://web.archive.org/web/*/https://blog.binchen.org/posts/emacs-speed-up-1000.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
<p>
I'm still <b>NOT</b> satisfied with my Emacs performance after applying below tricks:
</p>

<ul>
<li>autoload packages</li>
<li>idle-load packages</li>
<li>compiling *.el to  *.elc</li>
</ul>
<p>
After some research, I found I could make my Emacs 1000% fast <b>in 1 minute</b>.
</p>

<p>
Please note I'm talking about the <b>general performance</b> not just startup time.
</p>

<p>
The solution is really simple.
</p>

<p>
Since I'm a Linux guy and my computer got enough (24G) memory. I can place my setup into <a href="http://en.wikipedia.org/wiki/Tmpfs">memory</a>.
</p>

<p>
<b>Step 1</b>, insert below line into /etc/fstab and restart computer:
</p>

<div>

<pre><code>tmpfs       /tmp        tmpfs       nodev,nosuid,size=8G    0   0
</code></pre>

</div>

<p>
<b>Step 2</b>, run the script "emacs2ram":
</p>

<div>

<pre><code>#!/bin/sh

if [ -z "$1" ];then
    echo "Usage:"
    echo "  emacs2ram start"
    echo "  emacs2ram restore"
    exit 1
fi

if [ "$1" == "start" ];then
    backup=emacs.d-backup
    link=.emacs.d
    volatile=/tmp/.emacs.d-$USER

    IFS=
    set -efu

    cd ~/

    if [ ! -r $volatile ]; then
        mkdir -m0700 $volatile
    fi

    # link -&gt; volatie does not exist
    if [ "$(readlink $link)" != "$volatile" ]; then
        # backup project at first
        mv $link $backup
        # create the link
        ln -s $volatile $link
    fi

    if [ -e $link/.unpacked ]; then
        echo "Sync .emacs.d from memory to backup ..."
        rsync -avq --delete --exclude .unpacked ./$link/ ./$backup/
        echo "DONE!"
    else
        echo "Sync .emacs.d from disk to memory ..."
        rsync -avq ./$backup/ ./$link/
        touch $link/.unpacked
        echo "DONE!"
    fi
else
    echo "Moving .emacs.d back to disk ..."
    backup=$2-backup
    link=$2
    volatile=/tmp/$2-$USER
    cd ~/projs
    rm $link &amp;&amp; mv $backup $link &amp;&amp; rm -rf $volatile
    echo "DONE!"
fi
</code></pre>

</div>

<p>
That's all! Please enjoy Emacs as usual.
</p>

<p>
The original script is from ArchLinux Wiki. I learned this technique eight years ago. I'm just wondering why I need eight years to apply it?
</p>

<p>
BTW, I've also moved <b>all my projects into memory</b>, using similar scripts.
</p>

<p>
<b>UPDATE 1:</b>
I also publicize my project-managing script at <a href="https://gist.github.com/redguardtoo/596b1a9fd3eac1cedd13#file-proj2ram">gist</a>. It's almost same as emacs2ram. 
</p>

<p>
<b>UPDATE 2:</b>
Now I use <a href="https://hoytech.com/vmtouch/">vmtouch</a> which is easier to use and more light weight. Run <code>vmtouch -vt ~/.emacs.d</code> to place the directory into memory.
</p>

<p>
Unfortunately, <code>vmtouch</code> doesn't support Windows. You can convert my bash script to DOS batch script. Basically the script copies the directory into ram disk and create a link to the directory in memory. You can use <a href="https://sourceforge.net/projects/imdisk-toolkit/">ImDisk Toolkit</a> to create ram disk.</p>
</div>
        </div></div>]]>
            </description>
            <link>https://blog.binchen.org/posts/emacs-speed-up-1000.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202942</guid>
            <pubDate>Tue, 24 Nov 2020 20:58:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If other engineers in your team are more productive]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25202907">thread link</a>) | @_elergy_
<br/>
November 24, 2020 | https://evgenii.info/faster-pacers/ | <a href="https://web.archive.org/web/*/https://evgenii.info/faster-pacers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://evgenii.info/content/images/size/w300/2020/11/wolfgang-hasselmann-mBccivEQvlk-unsplash--1-.jpg 300w,
                            https://evgenii.info/content/images/size/w600/2020/11/wolfgang-hasselmann-mBccivEQvlk-unsplash--1-.jpg 600w,
                            https://evgenii.info/content/images/size/w1000/2020/11/wolfgang-hasselmann-mBccivEQvlk-unsplash--1-.jpg 1000w,
                            https://evgenii.info/content/images/size/w2000/2020/11/wolfgang-hasselmann-mBccivEQvlk-unsplash--1-.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://evgenii.info/content/images/size/w2000/2020/11/wolfgang-hasselmann-mBccivEQvlk-unsplash--1-.jpg" alt="Not as Productive as Others?">
            </figure>

            <section>
                <div>
                    <blockquote>This is another article about pacers – people whom we use as an example to adjust our behaviour, mostly unconsciously.</blockquote><h2 id="surrounded-by-faster-pacers">Surrounded by faster pacers</h2><p>In this part, we will talk about problems that may occur when <em>you feel </em>that a lot of people in your team are much more productive than you. <br>In many cases, it doesn't lead to any problems – people happily work together and achieve great results. But sometimes their mutual influence can be destructive, and people would feel demotivated and discouraged.</p><p>Several symptoms are indicating that you're affected by faster pacers:</p><ul><li>You feel guilty seeing that colleagues have achieved more than you</li><li>You are afraid of taking challenging tasks which can make you stuck for a while</li><li>You feel like you have to work longer hours to keep up with others</li></ul><p>Daily standups or any other form of sync with colleagues is the perfect time to diagnose this problem:</p><ul><li>Are you nervous about sharing your progress?</li><li>Do those meetings make you feel like you have not done enough? </li><li>Do you find it challenging to describe your results and plans?</li></ul><p>If any of these describes you, a closer look is needed.</p><h2 id="five-actions-to-solve-the-problem">Five actions to solve the problem</h2><p>The most popular advice I heard in this situation is to take it easy. It is normal to have somebody more productive than you, left alone the fact that nobody can be a top performer in all situations.</p><p>Even though I fully understand the reasoning behind this suggestion, I do not think it is helpful. If somebody is nervous about attending standups, you cannot fix it by suggesting not to worry.</p><p>Instead, you can face this problem, find out the reasons and prepare an improvement plan, even if the problem exists only in your imagination. Then, it's going to be up to you whether to follow this plan or not, but at least you will take matters into your own hands – that alone can be sufficient to address most of the symptoms.</p><p>Let's talk about the five things which you can do to get out of this unpleasant situation. </p><h3 id="action-one-demystify-top-performers">Action one: demystify top performers<br></h3><blockquote>no two writers are the same, like snowflakes and fingerprints. No one will ever write in just the way that you do, or in just the way that anyone else does. Because of this fact, there is no real competition between writers. &lt;...&gt; Writing is a matter strictly of developing oneself. You compete only with yourself. You develop yourself by writing.<p>– John McPhee</p></blockquote><p>In time, everyone develops their areas of expertise. No matter how broad or narrow they are, one is the same — people are much more productive when their job overlaps with those areas.</p><p>Before bringing up your own expertise, I would recommend you you to think about your more productive colleagues. <strong>Every time they do something great, ask yourself what helped them to achieve those results.</strong></p><p>Something that could sound self-deprecating at first:</p><blockquote>Mark finished this giant feature for a week. That one would take more than a month for me!</blockquote><p>Can be rephrased and cleansed of magic:</p><blockquote>Mark finished this giant feature in a week because he's been building similar ones for the past three years.<br>He did more than ten last year – now he's extremely good at it.</blockquote><p>Now you can see that Mark's fast pace didn't appear overnight – it required years of deliberate practice. Moreover, you know that doing more things in this area can help you to close this gap.</p><p>That is not the only way of reframing achievements. It could be something like this:</p><blockquote>Mark finished it in a week because he wrote the whole system since the beginning and he knows every line of code by heart.</blockquote><p>or even this:</p><blockquote>... because he did not have the internet at home and spent all his free time working in the office.</blockquote><p>No matter the situation, your goal should be to stop seeing people as <em>just productive</em> and start noticed the reasons behind their results. Most of the time, those reasons are ordinary and achievable by anybody.</p><h3 id="action-two-find-your-comfort-zone">Action two: find your comfort zone</h3><p>Simply put, there are three types of activities:</p><ul><li>Something you enjoy the most</li><li>Something you are good at</li><li>Most important things for the company at the moment</li></ul><figure><img src="https://evgenii.info/content/images/2020/11/Three-types-niche.png" alt=""><figcaption>Three types of activities at work</figcaption></figure><p>The intersection of all three circles is your <em>niche </em>in the team, but finding and expanding your niche deserves a separate article. For this topic, I will focus only on the comfort zone (highlighted in green).</p><p>Everybody has ups and downs, and you will have many periods of not being at your best.<br>One of the smartest things you can do is to prepare something that can give you a little boost when needed — a type of work you like to be doing or an area where you can be very productive.</p><p>If you do not have a comfort zone right now — build one:</p><ul><li>Familiarize yourself with plans of your team.</li><li>Pick an area which will require work in the future.</li><li>Start building expertise there to capitalize on it when the time comes.</li></ul><h3 id="action-three-define-expectations-and-track-achievements">Action three: define expectations and track achievements</h3><p>The easiest way to not meet expectations is is to have no expectations at all. No matter what you achieve, you can always find a room for improvement.</p><p>The simplest way of coping with that is to formulate your goals before you start working towards them. I find daily plans most precise and helpful for this purpose; here is one of my recent ones:</p><figure><img src="https://evgenii.info/content/images/2020/11/image.png" alt=""></figure><p>The expectations were clear and realistic, but I ended up not finishing half of what I planned to do.</p><p>Was it a problem? No, because I knew that I had done more important things instead, and there was absolutely no reason to feel sad about my initial plan.</p><h3 id="action-four-keep-expectations-reasonable">Action four: keep expectations reasonable</h3><p>Sometimes results are noticeably small in comparison to goals:</p><figure><img src="https://evgenii.info/content/images/2020/11/image-1.png" alt=""><figcaption>planned: 7; finished: 1</figcaption></figure><p>While this is a call to think about what can be improved, I would recommend checking your expectations for feasibility first.</p><p>There is a simple exercise to figure out if you are unrealistic in your estimations:</p><ul><li>Take some tasks your team plans to work on and imagine how much time each of them would take for you. Can you complete a particular task one day? In a week? Or maybe you can do five of those in an hour?</li><li>Write it somewhere.</li><li>When <em>other people</em> complete those tasks, check how their results match your estimations. <br>Were they working within their niches or tried something new? How did it impact them?</li></ul><p>This exercise is also helpful when your plans are unambitious and require correction:</p><figure><img src="https://evgenii.info/content/images/2020/11/image-2.png" alt=""><figcaption>100% done!</figcaption></figure><h3 id="action-five-analyse-and-improve">Action five: analyse and improve</h3><p>Detailed plans can be beneficial even when everything looks good:</p><figure><img src="https://evgenii.info/content/images/2020/11/image-3.png" alt=""><figcaption>Perfect plan and execution</figcaption></figure><p>Even though the result matched your expectation, a picky perfectionist can find some food for reflection:</p><figure><img src="https://evgenii.info/content/images/2020/11/image-4.png" alt=""><figcaption>Digging deeper</figcaption></figure><p>I rarely use this method – maybe once every two or three months, but it always helps to take control and find something I can change.</p><h2 id="prove-it-works">Prove it works</h2><p>At the beginning of this article, I mentioned that the best way of noticing this problem is to pay attention to your behaviour when you need to share your progress and describe the plans.</p><p>Feeling that you have not done enough can contribute to the demotivation, which will prevent you from working at your best, which will cause dissatisfaction of not achieving enough, which will incur even more demotivation, which will further decrease your productivity, which will make it even harder to get out of this loop.</p><p>The good news is that the actions above can help you to</p><ul><li>Understand if your expectations are realistic and how to adjust them if they are not</li><li>Find the quick way to get back on track after a period of dissatisfaction</li><li>Figure out what is the exact reason for dissatisfaction and how to improve it</li></ul><p>If anything, it doesn't leave too many reasons to worry.</p><hr><p>As always, you can <a href="https://evgenii.info/faster-pacers#subscribe">subscribe to Resilient Systems</a> and receive new articles by email if you haven't done it yet. <br>You also can <a href="https://twitter.com/_elergy_">find me on Twitter</a> or somewhere else – I am always happy to chat :-) &nbsp;</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to Resilient Systems</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://evgenii.info/faster-pacers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202907</guid>
            <pubDate>Tue, 24 Nov 2020 20:54:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The war we forgot in our embrace of streaming]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25202726">thread link</a>) | @mattbierner
<br/>
November 24, 2020 | https://blog.mattbierner.com/the-war-we-forgot/ | <a href="https://web.archive.org/web/*/https://blog.mattbierner.com/the-war-we-forgot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="main">
    

    <p>I listened to Spotify for somewhere around 650 hours in 2019. That works out to a little over 27 solid days. That’s a lot of music!</p>

<p>I’m from the iPod generation, so the novelty of millions of songs in my pocket for $10 a month hasn’t entirely worn off. Spotify has changed my life. That’s only a minor exaggeration. In the old world of record stores and $0.99 iTunes singles, I never would have discovered artists like <a href="https://jeremiahkane.bandcamp.com/">Jeremiah Kane</a> or subgenres like <a href="https://giallodiscorecords.bandcamp.com/album/apocalypse-domani">Italian Horror Disco</a> which have had big impacts on both my day-to-day life and my creative work. The other great thing about streaming services like Spotify is that they let me focus on what I actually care about: the music! No more hours spent ripping CDs or scouring Limewire, no more nights wasted managing a media library and transferring songs between devices. It’s been so freeing.</p>

<p>Those 650 hours were on just one streaming service too. For a few bucks more a month, I can also stream tens of thousands of movies and shows through services such as Amazon or Netflix. And that’s all without even touching on services such as YouTube! If anything, the biggest problem facing consumers today is that there’s far too much content to choose from.</p>

<p>I’ve been happy gorging myself at this media buffet for years, until a recent project got me thinking about what shifting to a streaming only world means. Because while services such as Spotify or Netflix are in many ways better than what came before, it’s still worth trying to understand what we risk losing in this transition.</p>

<p>I have rarely seen this topic discussed in terms that I connect with. In this post, I want to go beyond typical concerns such as losing access to your library when your subscription lapses, to instead focus on how streaming can effect culture, and specifically remix culture. For, despite the flashy apps and all the billions and billions of dollars spent on new content, I’ve come to believe that streaming services take user control away and are actually quite regressive in many respects.</p>

<p>Ultimately, I feel that the biggest threat of streaming is its view that media is meant only for consumption. This view would be dangerous enough if it were restricted to the domain of streaming, but with streaming currently busy eating the world, I fear it will also come to dominate how we think about our media more broadly. This won’t happen overnight. In fact, we may not even realize that it is happening. The convenience and selection that streaming media promises has blinded us and made us forget a war that we (or at least the most nerdy ones among us) used to care deeply about: the war on DRM. By abandoning this war, we risk losing not only practical control over our media, but also our ability to imagine what our media could be and imagine how we could relate to it differently.</p>



<p>Before we continue though, a word about me: I’m not a musician, I’m not a video producer, and I’m certainly not a copyright lawyer. I’m just a nerd who likes music.</p>

<p>So what inspired this post? Well, to be perfectly honest, it was born from self interest. Streaming and DRM weren’t subjects I had ever given much thought to, let alone wanted to spend a weekend writing about. I was pretty happy with the status quo. That starting changing when I ran into a problem a few months back while building a new app.</p>

<p>You see, for the longest time I’ve wanted to use technology to somehow make the world dance along to my music. This year I finally figured out how to pull this off well. So for the past few months, I’ve been working off and on to create an augmented reality music visualizer iOS app. The app uses music to distort your walls/floors, creating wave patterns and other fun visualizations that look like they are distorting the real world’s geometry. It’s pretty neat!</p>

<p>During prototyping, I used a hardcoded audio file which let me focus on building the basic AR effects. To actually ship the app though, I wanted to let users select their own music. It sounded simple. However, I quickly hit a number of roadblocks.</p>

<p>Here’s an abridged version of my quest to add a music selector to my iOS app. Again my goal was simple: let users play their music with my app’s visualizer. On the technical side, the only important note is that the visualizer is driven by raw audio data.</p>

<ol>
  <li>
    <p>Try adding a media selector to the app using Apple’s built-in media picker UI: <a href="https://developer.apple.com/documentation/mediaplayer/mpmediapickercontroller"><code>MPMediaPickerController</code></a>.</p>

    <p>Discover that <code>MPMediaPickerController</code> shows nothing because I don’t actually have any songs in my phone’s music library.</p>
  </li>
  <li>
    <p>Remember that all of “my music” is actually in Spotify. Remember that Spotify has <a href="https://developer.spotify.com/documentation/">an API</a>!</p>

    <p>Discover that Spotify’s API is really more for remote control style apps. There is no way to access the raw audio data I needed for the visualizer.</p>
  </li>
  <li>
    <p>Check if Apple Music has an API I can use.</p>

    <p><a href="https://developer.apple.com/musickit/">Same issue</a>.</p>
  </li>
  <li>
    <p>Try downloading a song that I purchased on iTunes 10+ years ago.</p>

    <p>Discover that while the song now shows up in <code>MPMediaPickerController</code>, my app can’t access the raw audio data because the old song still has DRM.</p>
  </li>
  <li>
    <p>Go to Bandcamp, download a DRM free song, copy it over to my phone.</p>

    <p>Finally <code>MPMediaPickerController</code> works! Except I don’t own many of the songs I’d like to try in the app. Plus, now I have to manually copy music around like it’s 2003?</p>
  </li>
  <li>
    <p>Suspect that many users will be in the same boat, so see if my app can use a low level audio API to access the currently playing audio on the device.</p>

    <p>Discover that this also does not seem possible, likely for content protection reasons. (Although I won’t go so far as to say it is completely impossible. It may be possible if the music app your app tries to listen to consents or if you are some sort of iOS audio wizard.)</p>
  </li>
</ol>

<p>The only way I’ve found to let users easily visualize their music is by recording from the microphone while music plays over the speaker. Existing music visualizer apps that I’ve found on the App Store seem to have similar limitations. This just seems crazy to me!</p>

<p>So that’s where this post came from: I wanted to build a silly app about making walls dance, and streaming/DRM got in my way. The motivation is not exactly noble sounding when I put it in those terms.</p>

<p>But the app development problems I ran into aren’t nearly as interesting as the thinking they inspired. These problems got me thinking about big concepts like ownership and remixing. And this helped me realize that streaming takes away user control. Understanding all this got me wondering not only about the consequences of this loss of control, but why we mostly all have been just fine with this.</p>



<p>To watch Netflix, you have to use the Netflix app. To watch HBO, you have to use the HBO Max app. To watch Disney, you have to use the Disney Plus app.</p>

<p>Seems obvious enough. But why?</p>

<p>Why do I need apps from these providers at all? It’s not like using the Netflix app is some magical experience. 95% of the time, it’s just a fullscreen video. Any html <code>&lt;video&gt;</code> tag can do that!</p>

<p>So as long as my Netflix subscription is valid, shouldn’t I be able to load up Netflix content in any number of third party apps? Who knows, some of these third party apps might work on older or more niche devices that the official app doesn’t support. They may even have some neat UI ideas or unique features. After all, if anyone could develop a Netflix viewing app, then developers would have to work to make their app stand out from the pack. Having a vibrant app ecosystem seems like it would be a plus for these streaming providers, right?</p>

<p>But this gets to one of the fundamental misunderstandings that I had about streaming services. This misunderstanding explains why I just kind of assumed that it would be simple to hook my AR music visualizer up to a service like Spotify or Apple music.</p>

<p>Let’s take Netflix for example. When I first subscribed, I imagined that my $12 a month was buying me unlimited access to a huge library of Netflix content. However that’s not strictly accurate. Instead, my subscription lets me use sanctioned Netflix apps to view Netflix content. And while this distinction may seem like splitting hairs—especially when Netflix sanctioned apps exist for just about every modern device—I believe understanding it is a key first step in seeing the limitations of our current crop of streaming services.</p>

<p>Stepping back, I can sort of understand why streaming providers do this. If I were feeling particularly generous—or, if I were in marketing—I could probably even BS together justifications about how this setup actually benefits consumers too. Something about how the Disney app is specially designed and optimized for Disney content, and how all this vertical integration provides customers with the best end-to-end user experience. After all, we’re not just talking about apps here, but entertainment experiences! On the technical side, I also know that if you control both the frontend and backend, development and maintenance are simpler.</p>

<p>But seeing as my generosity reserves are now thoroughly depleted, I must also bring up three little letters: DRM. For controlling the entire pipeline also lets streaming providers control how their content can be shared and interacted with. That sounds a whole lot like DRM to me, even if it’s not explicitly called such. The fact that the streamed media itself is also encrypted is more of an implementation detail.</p>

<hr>

<p>So what’s the impact of linking content to an app? Well, simply put, it limits user control. Any control users have must be granted by streaming providers, who currently have little incentive to grant users anything meaningful.</p>

<p>The best analogy I can think of for this setup is that of a jukebox. A jukebox lets you play a large library of songs on demand, however browsing and selecting a song is basically all the control a jukebox grants to you. You certainly aren’t allowed to take some of the records out of the machine and play them on your own record player. Nor …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.mattbierner.com/the-war-we-forgot/">https://blog.mattbierner.com/the-war-we-forgot/</a></em></p>]]>
            </description>
            <link>https://blog.mattbierner.com/the-war-we-forgot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202726</guid>
            <pubDate>Tue, 24 Nov 2020 20:34:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Holiday Torture – VCard/vcf to CSV Converter for Address Labels]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25202644">thread link</a>) | @semireg
<br/>
November 24, 2020 | https://label.live/post/print-address-labels-using-vcard-vcf | <a href="https://web.archive.org/web/*/https://label.live/post/print-address-labels-using-vcard-vcf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://label.live/post/print-address-labels-using-vcard-vcf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202644</guid>
            <pubDate>Tue, 24 Nov 2020 20:27:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Being-in-the-Room Privilege: Elite Capture and Epistemic Deference]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25202553">thread link</a>) | @Reedx
<br/>
November 24, 2020 | https://www.thephilosopher1923.org/essay-taiwo | <a href="https://web.archive.org/web/*/https://www.thephilosopher1923.org/essay-taiwo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="PAGES_CONTAINER"><div id="SITE_PAGES"><div id="r36i2"><div><div id="Containerr36i2"><div data-mesh-id="Containerr36i2inlineContent" data-testid="inline-content"><div data-mesh-id="Containerr36i2inlineContent-gridContainer" data-testid="mesh-container-content"><section id="comp-khunkqfk"><div data-testid="columns"><div id="comp-khunkqgo1"><div data-mesh-id="comp-khunkqgo1inlineContent" data-testid="inline-content"><div data-mesh-id="comp-khunkqgo1inlineContent-gridContainer" data-testid="mesh-container-content"><div id="comp-khunkqgq2" data-testid="richTextElement"><p><span><span>Original Article:</span></span></p>

<p><span><span><span><span><span>Being-in-the-Room Privilege:</span></span></span></span></span></p>

<p><span><span><span><span><span>Elite Capture and Epistemic Deference </span></span></span></span></span></p>

<p><br>
<span><span><span>Olúfémi O. Táíwò </span></span></span></p></div></div></div></div></div></section><p><span><span><span><span><span>© Melody Overstreet</span></span></span></span></span></p><div id="comp-khunkqh71" data-testid="richTextElement"><div><p>“I abandoned the pitch because I don’t think I’m the right person to write this story – I have no idea what it’s like to be Black... I can send you the Google doc with my notes, too?”</p><p>

I flinched inwardly. It was an innocent and properly motivated offer: Helen, a freelance journalist, was offering to give up something for me, stemming from her concern to live out an ethos of racial justice. But I worried that it was also a trap.</p></div>



<p>Even setting aside the mistake about the power dynamics of the conversation (I am Black, but also a tenure-track professor), there was a problem here that I had seen many times before. Behind the assumption that I had experiential insight she lacked was the recognizable cultural imprint of a much discussed, polarizing perspective on knowledge and politics: standpoint epistemology.</p>



<p>If you consider a textbook definition of standpoint epistemology, it may be hard to see the controversy around this idea. The <span>International Encyclopedia of Philosophy</span> boils it down to three innocuous-sounding contentions:</p>



<p>1)&nbsp;&nbsp;&nbsp;&nbsp; Knowledge is socially situated</p>

<p>2)&nbsp;&nbsp;&nbsp;&nbsp; Marginalized people have some positional advantages in gaining some forms of knowledge</p>

<p>3)&nbsp;&nbsp;&nbsp;&nbsp; Research programs ought to reflect these facts.</p>



<p>Liam Kofi Bright argues persuasively that these contentions are derivable from a combination of 1) basic empiricist commitments, and 2) a minimally plausible account of how the social world affects what knowledge groups of people are likely to seek and find.</p>



<p>So, if the problem isn’t the basic idea, what is it?</p>



<p>I think it’s less about the core ideas and more about the prevailing norms that convert them into practice. The call to “listen to the most affected” or “centre the most marginalized” is ubiquitous in many academic and activist circles. But it’s never sat well with me. In my experience, when people say they need to “listen to the most affected”, it isn’t because they intend to set up Skype calls to refugee camps or to collaborate with houseless people. Instead, it has more often meant handing conversational authority and attentional goods to those who most snugly fit into the social categories associated with these ills – regardless of what they actually do or do not know, or what they have or have not personally experienced. In the case of my conversation with Helen, my racial category tied me more “authentically” to an experience that neither of us had had. She was called to defer to me by the rules of the game as we understood it. Even where stakes are high – where potential researchers are discussing how to understand a social phenomenon, where activists are deciding what to target – these rules often prevail.</p></div><section id="comp-khunkqh91"><div data-testid="columns"><div id="comp-khunkqhc1"><div data-mesh-id="comp-khunkqhc1inlineContent" data-testid="inline-content"><div data-mesh-id="comp-khunkqhc1inlineContent-gridContainer" data-testid="mesh-container-content"><p id="comp-khunkqhe2" data-testid="richTextElement"><h2><span>THE NORMS OF PUTTING STANDPOINT EPISTEMOLOGY INTO PRACTICE CALL FOR PRACTICES OF DEFERENCE: GIVING OFFERINGS, PASSING THE MIC, BELIEVING</span></h2></p></div></div></div></div></section><div id="comp-khunkqhg" data-testid="richTextElement"><p>The trap wasn’t <span>that</span> standpoint epistemology was affecting the conversation, but <span>how</span>. Broadly, the norms of putting standpoint epistemology into practice call for practices of deference: giving offerings, passing the mic, believing. These are good ideas in many cases, and the norms that ask us to be ready to do them stem from admirable motivations: a desire to increase the social power of marginalized people identified as sources of knowledge and rightful targets of deferential behaviour. But deferring in this way as a rule or default political orientation can actually work counter to marginalized groups’ interests, especially in elite spaces.</p>



<p>Some rooms have outsize power and influence: the Situation Room, the newsroom, the bargaining table, the conference room. Being in these rooms means being in a position to affect institutions and broader social dynamics by way of deciding what one is to say and do. Access to these rooms is itself a kind of social advantage, and one often gained through some prior social advantage. From a societal standpoint, the “most affected” by the social injustices we associate with politically important identities like gender, class, race, and nationality are disproportionately likely to be incarcerated, underemployed, or part of the 44 percent of the world’s population without internet access – and thus both left out of the rooms of power and largely ignored by the people in the rooms of power. Individuals who make it past the various social selection pressures that filter out those social identities associated with these negative outcomes are most likely to be in the room. That is, they are most likely to be in the room precisely because of ways in which they are systematically <span>different from</span> (and thus potentially unrepresentative of) the very people they are then asked to represent in the room.</p>



<p>I suspected that Helen’s offer was a trap. She was not the one who set it, but it threatened to ensnare us both all the same. Broader cultural norms – the sort set in motion by prefacing statements with “As a Black man…” – cued up a set of standpoint-respecting practices that many of us know consciously or unconsciously by rote. However, the forms of deference that often follow are ultimately self-undermining and only reliably serve “elite capture”: the control over political agendas and resources by a group’s most advantaged people. If we want to use standpoint epistemology to challenge unjust power arrangements, it’s hard to imagine how we could do worse.</p>

<p><br>
***</p></div><div id="comp-khunkqhr" data-testid="richTextElement"><p>To say what’s wrong with the popular, deferential applications of standpoint epistemology, we need to understand what makes it popular. A number of cynical answers present themselves: some (especially the more socially advantaged) don’t genuinely want social change – they just want the <span>appearance</span> of it. Alternatively, deference to figures from oppressed communities is a performance that sanitizes, apologizes for, or simply distracts from the fact that the deferrer has enough “in the room” privilege for their “lifting up” of a perspective to be of consequence.</p>



<p>I suspect there is some truth to these views, but I am unsatisfied. Many of the people who support and enact these deferential norms are rather like Helen: motivated by the right reasons, but trusting people they share such rooms with to help them find the proper practical expression of their joint moral commitments. We don’t need to attribute bad faith to all or even most of those who interpret standpoint epistemology deferentially to explain the phenomenon, and it’s not even clear it would help. Bad “roommates” aren’t the problem for the same reason that Helen being a good roommate wasn’t the solution: the problem emerges from how the rooms themselves are constructed and managed.</p>



<p>To return to the initial example with Helen, the issue wasn’t merely that I hadn’t grown up in the kind of low-income, redlined community she was imagining. The epistemic situation was much worse than this. Many of the facts about me that made my life chances different from those of the people she was imagining were the very same facts that made me likely to be offered things on their behalf. If I<span> had</span> grown up in such a community, we probably wouldn’t have been on the phone together.</p>



<p>***</p></div><div id="comp-khunkqhs" data-testid="richTextElement"><p>Many aspects of our social system serve as filtering mechanisms, determining which interactions happen and between whom, and thus which social patterns people are in a position to observe. For the majority of the 20th century, the U.S. quota system of immigration made legal immigration with a path to citizenship almost exclusively available to Europeans (earning Hitler’s regard as the obvious “leader in developing explicitly racist policies of nationality and immigration”). But the 1965 Immigration and Nationality Act opened up immigration possibilities, with a preference for “skilled labour”.</p>



<p>My parents’ qualification as skilled labourers does much to explain their entry into the country and the subsequent class advantages and monetary resources (such as wealth) that I was born into. We are not atypical: the Nigerian-American population is one of the country’s most successful immigrant populations (what no one mentions, of course, is that the 112,000 or so Nigerian-Americans with advanced degrees is utterly dwarfed by the 82 million Nigerians who live on less than a dollar a day, or how the former fact intersects with the latter). The selectivity of immigration law helps explain the rates of educational attainment of the Nigerian diasporic community that raised me, which in turn helps explain my entry into the exclusive Advanced Placement and Honours classes in high school, which in turn helps explain my access to higher education...and so on, and so on.</p>

<p><span>​</span></p>

<p>It is easy, then, to see how this deferential form of standpoint epistemology contributes to elite capture at scale. The rooms of power and influence are at the end of causal chains that have selection effects. As you get higher and higher forms of education, social experiences narrow – some students are pipelined to PhDs and others to prisons. Deferential ways of dealing with identity can inherit the distortions caused by these selection processes.&nbsp;</p>

<p><span>​</span></p>

<p><span>​</span>But it’s equally easy to see locally – in this room, in this academic literature or field, in this conversation – why this deference seems to make sense. It is often an improvement on the epistemic procedure that preceded it: the person deferred to may well be better epistemically positioned than the others in the room. It may well be the best we can do while holding fixed most of the facts about the rooms themselves: what power resides in them, who is admitted.</p></div><div id="comp-khunkqht1" title=""><div data-testid="linkElement"><wix-image id="img_comp-khunkqht1" data-image-info="{&quot;containerId&quot;:&quot;comp-khunkqht1&quot;,&quot;displayMode&quot;:&quot;fill&quot;,&quot;imageData&quot;:{&quot;width&quot;:500,&quot;height&quot;:692,&quot;uri&quot;:&quot;53a28d_d7a507c6115d4060a217e2377ff9c717~mv2.jpg&quot;,&quot;name&quot;:&quot;Vessel I.jpg&quot;,&quot;displayMode&quot;:&quot;fill&quot;}}" data-bg-effect-name="" data-is-svg="false" data-is-svg-mask="false" data-image-zoomed=""><img alt="Vessel I.jpg"></wix-image></div></div><p id="comp-khunkqhu2" data-testid="richTextElement"><h6><span>© Melody Overstreet</span></h6></p><div id="comp-khunkqhw" data-testid="richTextElement"><p>But these are the last facts we should want to hold fixed. Doing better than the epistemic norms we’ve inherited from a history of explicit global apartheid is an awfully low bar to set. The facts that explain who ends up in which room shape our world much more powerfully than the squabbles for comparative prestige …</p></div></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thephilosopher1923.org/essay-taiwo">https://www.thephilosopher1923.org/essay-taiwo</a></em></p>]]>
            </description>
            <link>https://www.thephilosopher1923.org/essay-taiwo</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202553</guid>
            <pubDate>Tue, 24 Nov 2020 20:16:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating a Terraform Provider for Plausible]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25202260">thread link</a>) | @kurtmc
<br/>
November 24, 2020 | https://mcalpinefree.co.nz/blog/Technical/terraform-plausible | <a href="https://web.archive.org/web/*/https://mcalpinefree.co.nz/blog/Technical/terraform-plausible">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://mcalpinefree.co.nz/blog/Technical/terraform-plausible</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202260</guid>
            <pubDate>Tue, 24 Nov 2020 19:45:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Silicon M1: Black Magic Fuckery]]>
            </title>
            <description>
<![CDATA[
Score 714 | Comments 669 (<a href="https://news.ycombinator.com/item?id=25202147">thread link</a>) | @singhkays
<br/>
November 24, 2020 | https://www.singhkays.com/blog/apple-silicon-m1-black-magic/ | <a href="https://web.archive.org/web/*/https://www.singhkays.com/blog/apple-silicon-m1-black-magic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<blockquote>
<p>Black. Magic. Fuckery.</p>
</blockquote>
<p>These are the words used by the user <a href="https://www.reddit.com/r/apple/comments/jx360c/for_context_m1_macbook_air/gcvn0oy/">holdagold on reddit</a> to describe their experience with the new Apple Silicon M1 Macbook Air. Rarely does a product leave people effusing to the extent Apple Silicon M1 has done this week. At best, you get the people who really care about a system’s internals very excited like we saw with Zen 3’s launch recently. For everyday users who just want to browse the web, stream some Netflix, maybe edit some documents, computers have been “perfectly fine” for the last decade. We’ve seen incremental year over year improvements with slightly more performance, slightly more battery life, marginally faster SSD, somewhat thinner design, etc. But something genuinely new, something revolutionary, something once in a generation has been missing. I believe the Apple M1 represents something we can truly call “revolutionary”.</p>
<p>Before we proceed, it’s essential to set the context that I’ve only used two Apple devices in my entire life - <em>a personal 2013 MacBook Air and a 2019 MacBook Pro that I got through work</em>. Everything else has been either a custom-built PC, Windows laptop, or an Android/Windows Mobile smartphone. Even for a “PC/Android Guy”, I have to admit what I saw this week is something special. I believe it’ll go down as a significant milestone in computing history on par with some industry-defining chips like Intel’s 8086, 386, 486, Pentium, Conroe or AMD’s K8, Zen, etc. I hope for the return of Moore’s law and awakening of the x86 manufacturers from their slumber as this will be the “<em>slowest</em>” CPU Apple will ever make. <em>As Henry Clay once said</em>,</p>
<blockquote>
<p>Of all human powers operating on the affairs of mankind, none is greater than that of competition.</p>
</blockquote>
<p>This blog is then my observation of the excitement around this significant launch and captures some of the user and reviewer commentary.</p>

<p>Apple launched its own M1 SoC that integrates an 8-core CPU, 8-core GPU, 16-core Neural Engine, Media encode and decode engines, RAM - all on a single-chip. By including the RAM on the SoC, Apple is marketing this as a Unified Memory Architecture (UMA), central to the performance improvements M1 brings.</p>
<figure>
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_480x0_resize_q75_box.jpg 480w,
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_800x0_resize_q75_box.jpg 800w,
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_1200x0_resize_q75_box.jpg 1200w,
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_1500x0_resize_q75_box.jpg 1500w,
                " src="https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_800x0_resize_q75_box.jpg" alt="Apple Silicon M1 summary capabilities">
</figure>
<p>The first products and price points the M1 will be going into are:</p>
<ol>
<li>Mac Mini - $699</li>
<li>MacBook Air 13" - $999</li>
<li>MacBook Pro 13" - $1299</li>
</ol>
<p>Apple promises its new chip is much more energy-efficient than its Intel counterparts, so the battery life promises have gone up across the board:</p>
<ol>
<li>On the MacBook Air - up to 18 hours of video on a single charge (<em>up from 12 hours on this year’s Intel-powered MacBook Air</em>) and offers up to 15 hours of wireless web browsing per charge (<em>up from 11 hours previously</em>)</li>
<li>On the MacBook Pro - up to 17 hours of wireless web browsing (<em>up from 10 hours with this year’s Intel-powered MacBook Pro</em>), and 20 hours of video playback (<em>up from 10 hours before</em>).</li>
</ol>
<p>To showcase that energy efficiency, Apple is shipping the Macbook Air without any fan! It will be passively cooled like all iPhones and iPads.</p>


<p>Surprisingly no! Apple included Rosetta 2 ahead-of-time binary translation technology that translates code designed to run on Intel/x86 CPUs for the Apple Silicon CPUs. The performance is much better than expected and ranges between 70-80% of native code, which is surprising compared to Microsoft’s struggles in emulating x86 Windows apps on ARM CPUs. Apple’s answer might lie in something called TSO, aka. total store ordering as explained by <a href="https://www.reddit.com/r/hardware/comments/i0mido/apple_silicon_has_a_runtime_toggle_for_tso_to/">u/Veedrac and and u/ShaidarHaran2 on reddit</a>:</p>
<blockquote>
<p>TSO, aka. total store ordering, is a type of memory ordering, and affects how cores see the operations performed in other cores. Total store ordering is a strong guarantee provided by x86, that very roughtly means that all stores from other processors are ordered the same way for every processor, and in a reasonably consistent order, with exceptions for local memory.</p>
<p>In contrast, Arm architectures favour weaker memory models, that allows a lot of reordering of loads and stores. This has the advantage that in general there is less overhead where these guarantees are not needed, but it means that when ordering is required for correctness, you need to explicitly run instructions to ensure it. Emulating x86 would require this on practically every store instruction, which would slow emulation down a lot. That’s what the hardware toggle is for.</p>
<blockquote>
<p>In other words, Apple has, of course, been playing the very long game. TSO is quite a large benefit to emulating x86, hence why Rosetta 2 appears to put out a very decent 70% of native chip performance, that and install time translation for everything but JIT features. That’s on a chip not even meant to be a mac chip, so with further expanded caches, a wider, faster engine, perhaps applying the little cores to emulation which they’re not currently, and so on, x86_64 performance should be very very decent. I’m going to dare upset some folks and say perhaps even be faster in emulation than most contemporary x86 chips of the time, if you only lose 20% of native performance when it’s all said and done, it doesn’t take much working backwards to figure where they’d need to be, and Gurman said they were aiming for over 50% faster than Intel.</p>
</blockquote>
</blockquote>

<p>There have been numerous professional reviews and YouTube videos enumerating how Apple’s new products are better than their previous Intel counterparts. In the end, though, it comes down to how these products fit into the core workflows of the consumer who’s spending their money on them. There have been plenty of real-world experiences that I’ve seen in my filter bubble, mostly Reddit and Twitter. I will share some of these throughout this blog.</p>
<h2 id="the-speed">The Speed</h2>
<blockquote><p lang="en" dir="ltr">I pray that Intel, AMD, and Qualcomm is letting the M1 give them ideas, take them in new directions. Because this level of sorcery is too damn powerful to be held by a single company. Especially a monopolizing conglomerate like Apple. But fucking kudos to those chip wizards 👏</p>— DHH (@dhh) <a href="https://twitter.com/dhh/status/1330903542463422469?ref_src=twsrc%5Etfw">November 23, 2020</a></blockquote>
<blockquote><div lang="en" dir="ltr"><p>Purchased a new MacBook Air w/ Apple's M1 chip. </p><p>Holy crap. </p><p>Everything is WICKED fast.</p><p>Windows and prompts pop up instantly. Slowdown NEVER happens — even w/ numerous apps going. </p><p>Evernote, always a resources hog for me, is now a non-issue.</p><p>Huge props, Apple. 👍</p></div>— JP Mangalindan (@JPManga) <a href="https://twitter.com/JPManga/status/1329265657796390914?ref_src=twsrc%5Etfw">November 19, 2020</a></blockquote>
<blockquote><p lang="en" dir="ltr">Have had my M1 MacBook for about a week now... and have been blown away by the performance. Battery just last and lasts, and either the fan never runs or is inaudible. Everything seems faster, even the stuff not yet compiled for Apple Silicon.</p>— Blake Scholl 🛫 (@bscholl) <a href="https://twitter.com/bscholl/status/1331084298451963904?ref_src=twsrc%5Etfw">November 24, 2020</a></blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/the_macbook_air_is_once_again_the_benchmark_by/gczfgs9">u/MagneticGray on reddit</a>:</p>
<blockquote>
<p>Definitely don’t get near one! I have the 12.9” iPad Pro, new Max iPhone, older 13”MBP, and a beastly gaming PC. Our IT guy got the new MacBook Pro today and after playing with it for 10 minutes I was already rearranging my finances in my head.</p>
<p>People keep saying this but it’s eerily fast and silent, like alien technology. I exported a 5 minute clip in unoptimized Premiere Pro and I swear it did it faster than my PC with a 2070 ever has. The MBP wasn’t even warm to the touch afterwards either.</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jx360c/for_context_m1_macbook_air/gctzgic/">u/leach4_pikes on reddit</a>:</p>
<blockquote>
<p>&gt; It’s honestly the best purchase I’ve made in the last 10 years.</p>
<p>This is exactly how I feel. Feels like I’m holding a magical device that shouldn’t exist. Haven’t felt that in a long long time</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxu58m/apple_m1_arm_performance_with_a_2020_mac_mini/gd082ng/">u/lawrencejuliano and u/havaloc on reddit</a>:</p>
<blockquote>
<p>I have a 2018 15” MacBook Pro which is used almost exclusively in clamshell mode these days and attached to an ultrawide monitor. I use it mainly for photoshop and Lightroom for my photography work, and it’s been painful to say the least. It’s quick for all of two minutes until the fan kicks in with the thermal throttling, at which point the machine chugs to a crawl. I’ve been wanting to get a desktop in replacement, eyeing the previous gen Mac Minis but unable to make the move due to the lack of discrete GPU and an inability to push my monitor’s resolution.</p>
<p>In comes the M1 Mac Mini - I ordered right away and received it Tuesday, and my god has it been a breath of fresh air. First impressions were insanely positive, even hooked to my 5120x1440 display it was lightning fast. But yesterday I put it through the paces with edits from a recent shoot, and it was beyond stellar. More photoshop tabs open than ever before, Lightroom CC and classic open together, nothing could slow it down.</p>
<p>To say I’m impressed with this first gen is a massive understatement, this is shaping up to be one of the most enjoyable devices I’ve ever owned. First computer that hasn’t had some feeling of compromise in a long time.</p>
</blockquote>

<h2 id="buyers-remorse-is-real">Buyers remorse is real</h2>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/_/gcyyfjl">u/afelzz and u/WizardSleeveLoverr on reddit</a>:</p>
<blockquote>
<p>I feel so fucking stupid for ordering a Macbook Air in April this year.</p>
<blockquote>
<p>Same. I’m mad at myself. I ordered a MacBook Pro around the same time and of course this comes out. Trade in value is a joke too.</p>
</blockquote>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/_/gd0n94p">u/2shizhtzu4u on reddit</a>:</p>
<blockquote>
<p>I was stupid to by [sic] the early 2020 model. Sent it back today in exchange for this one. The performance on the M1 is far more than what I expected</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/_/gczjpa8">u/kelev on reddit</a>:</p>
<blockquote>
<p>As someone who got an entry level 2020 MBP in June… fuck.</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jx360c/_/gcu471l">u/hijusthappytobehere, u/CanadianMapleBacon and u/takesthebiscuit on reddit</a>:</p>
<blockquote>
<p><em>cries in 2020 MBP</em></p>
<blockquote>
<p>2020 MacBook Air purchased in August :(:(:(</p>
</blockquote>
<blockquote>
<p>Ha my dad is 5 months into his MBP gutted</p>
</blockquote>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jx360c/for_context_m1_macbook_air/gcvvtju/">u/mraheem on reddit</a>:</p>
<blockquote>
<p>Sucks cause i just bought a MacBook 3 years ago. And that battery is super super appealing.</p>
</blockquote>
<h2 id="battery-life-is-insane">Battery life is insane!</h2>
<blockquote><div lang="en" dir="ltr"><p>I haven’t plugged in this M1 Mac in almost 2 days. It’s only half dead. lol. What is this sorcery? 🔋 </p><p>Apple Silicon Macs are the future, man. Competing laptops are gonna have a hard time catching up. <a href="https://t.co/FmX5uVKkFd">pic.twitter.com/FmX5uVKkFd</a></p></div>— Computer Clan (📌M1) (@thecomputerclan) <a href="https://twitter.com/thecomputerclan/status/1329611818847891460?ref_src=twsrc%5Etfw">November 20, 2020</a></blockquote>

<blockquote><div lang="en" dir="ltr"><p>The battery life on the new MacBook Pro with M1 chip is INSANE</p><p>I've been doing work on this for several hours, and it's still at 87% 🤯🤯🤯</p><p>I guess it was a good thing I got my 3 week old laptop stolen? Lol<a href="https://twitter.com/hashtag/AppleM1?src=hash&amp;ref_src=twsrc%5Etfw">#AppleM1</a> <a href="https://t.co/fENYDS235O">pic.twitter.com/fENYDS235O</a></p></div>— William Lex Ham ✊🏽🧢 #TheyCantBurnUsAll (@WillLexHam) <a href="https://twitter.com/WillLexHam/status/1329906722845188097?ref_src=twsrc%5Etfw">November 20, 2020</a></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.singhkays.com/blog/apple-silicon-m1-black-magic/">https://www.singhkays.com/blog/apple-silicon-m1-black-magic/</a></em></p>]]>
            </description>
            <link>https://www.singhkays.com/blog/apple-silicon-m1-black-magic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202147</guid>
            <pubDate>Tue, 24 Nov 2020 19:36:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Grinch Bots Will Steal the Best Deals This Holiday Season]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25202140">thread link</a>) | @mch82
<br/>
November 24, 2020 | https://www.softwarepundit.com/industry-research/grinch-bots-steal-holiday-deals | <a href="https://web.archive.org/web/*/https://www.softwarepundit.com/industry-research/grinch-bots-steal-holiday-deals">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Grinch bots, also known as scalper bots, have won deals at super-human speeds that consumers can't match in previous holiday seasons. However, due to the development of bots in the sneaker industry and COVID-19, the 2020 holiday season will see software bots complete a record number of online transactions.</p>
<p>In 2018, members of Congress drafted <a rel="nofollow noopener" target="_blank" title="a bill" href="https://tonko.house.gov/uploadedfiles/grinch_bots_fact_sheet.pdf">a bill</a> to outlaw grinch bots, stating that "Allowing grinch bots to rig prices and squeeze consumers during the holiday season hurts American families, small business owners, product makers and entrepreneurs. We will not allow this market manipulation to go unchecked."</p>
<p>This holiday season, grinch bots will purchase over $100 million of sneakers. In addition, this fast-growing software trend will impact clothing, collectibles, computers, electronics, gaming, and any attractive deal where demand outweighs supply. As a result, consumers will either miss out on the hottest holiday gifts, or be forced to purchase them from reseller platforms like eBay at steep markups.</p>
<p>Below, we outline what grinch bots are, how they work, and share details on the industries that are expected to be hardest hit.</p>
<p><strong>Table of Contents</strong></p>
<ul>
<li><a href="#what-are-grinch-bots">What Are Grinch Bots?</a></li>
<li><a href="#how-do-grinch-bots-work">How Do Grinch Bots Work?</a></li>
<li><a href="#grinch-bots-over-500-million">Grinch Bots Will Purchase Over $100 Million of Sneakers During the 2020 Holidays</a></li>
<li><a href="#grinch-bots-in-other-industries">Grinch Bots Are Increasingly Popular In Other Industries</a></li>
<li><a href="#grinch-bots-cost-10000-dollars">The Leading Grinch Bots Are Now Being Sold for Almost $10,000</a></li>
<li><a href="#what-holiday-deals-will-grinch-bots-target-2020">What Holiday Merchandise Will Grinch Bots Target in 2020?</a></li>
</ul>

<h2>What Are Grinch Bots?</h2>
<p>Grinch bots, otherwise known as scalper bots, are software programs built to rapidly purchase scarce goods from websites before humans have the chance to do so. In other words, they automate the checkout process on eCommerce websites. Some grinch bots are programmed and owned by individual hackers. Others, like those mentioned below, are built and sold to consumers known as 'botters.'</p>
<p>The typical features found in grinch bots are: </p><div>
<div>
<ul>
<li>Retailer website compatibility</li>
<li>Captcha solvers</li>
<li>Automated checkout</li>
<li>Restock checking</li>
<li>Proxy integrations</li>
<li>Mobile applications</li>
<li>Customer support</li>
</ul>
</div>
</div>
<p>Botters use technologies in addition to the bots to scalp merchandise. The two most common are proxies and servers. Proxies, offered by companies like <a rel="nofollow noopener" target="_blank" title="Oculus" href="https://oculusproxies.com/index">Oculus</a> and <a rel="nofollow noopener" target="_blank" title="Surge" href="https://www.surgeproxies.com/">Surge</a>, are entered into the bots so that each checkout can use a unique IP address. Servers, managed by companies like <a rel="nofollow noopener" target="_blank" title="Amazon Web Services" href="https://aws.amazon.com/">Amazon Web Services</a> or <a rel="nofollow noopener" target="_blank" title="10xServers" href="https://10xservers.com/">10xServers</a>, are used to increase bot speed. Botters host virtual servers in the same locations as the websites they are botting to reduce the physical distance that the data needs to travel.</p>
<h2>How Do Grinch Bots Work?</h2>
<p>When botters purchase their bot, they program it with their personal information – shipping &amp; billing addresses, credit card info, usernames &amp; passwords. The botters' proxies are also added to the bot.</p>
<p>In anticipation of a sale, botters enter the specific merchandise they hope to purchase from a given retailer. As you can see below, these are stored as tasks in the software.</p>
<div>
<p><img alt="Cybersole task screenshot" src="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/prismbot-tasks" srcset="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/prismbot-tasks 1x, https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_2.0,f_auto,h_1600,q_auto,w_1600/v1/software/prismbot-tasks 2x">
</p>
</div>
<p>Once the sale goes live on the target retailer website, the bot begins the checkout process. Botters can manually complete any necessary actions that the retailer requires during checkout, such as completing a CAPTCHA.</p>
<h2>Grinch Bots Will Purchase Over $100 Million of Sneakers During the 2020 Holidays</h2>
<p>Grinch bots will purchase over $100 million of sneakers during the 2020 holidays. This is consistent with the current size of the U.S. sneaker resale market, which is <a rel="nofollow noopener" target="_blank" title="estimated at $2 billion" href="https://finance.yahoo.com/news/global-sneaker-resale-market-could-reach-30-billion-by-2030-cowen-191003371.html">estimated at $2 billion</a>.</p>
<p>To calculate this figure, we completed a bottoms-up analysis using publicly available data shared by the bots. Many, but not all of the bots, share their transaction volume for each successful sale on Twitter. Cybersole's <a rel="nofollow noopener" target="_blank" title="Twitter account" href="https://twitter.com/Cybersole">Twitter account</a> is a good example, where you can find several posts a month celebrating the purchase of thousands of pairs of shoes.</p>
<p>The estimated 2020 holiday sales of the seven bots below is $70 million. This does not include sales from several other leading bots that do not publicly share their transaction volumes.</p>
<div>
<div>
<div>
<table><thead><tr><th colspan="" rowspan="">Bot</th><th colspan="" rowspan="">Est. Monthly Transactions</th><th colspan="" rowspan="">Est. Monthly Sales</th><th colspan="" rowspan="">Est. Holiday Sales</th><th colspan="" rowspan="">Annual Run Rate</th></tr></thead><tbody><tr><td colspan="" rowspan="">Kodai</td><td colspan="" rowspan="">50,000</td><td colspan="" rowspan="">$10 million</td><td colspan="" rowspan="">$24 million</td><td colspan="" rowspan="">$120 million</td></tr><tr><td colspan="" rowspan="">Cybersole</td><td colspan="" rowspan="">45,000</td><td colspan="" rowspan="">$9 million</td><td colspan="" rowspan="">$22 million</td><td colspan="" rowspan="">$108 million</td></tr><tr><td colspan="" rowspan="">Prism</td><td colspan="" rowspan="">25,000</td><td colspan="" rowspan="">$5 million</td><td colspan="" rowspan="">$12 million</td><td colspan="" rowspan="">$60 million</td></tr><tr><td colspan="" rowspan="">Project Destroyer</td><td colspan="" rowspan="">15,000</td><td colspan="" rowspan="">$3 million</td><td colspan="" rowspan="">$7.2 million</td><td colspan="" rowspan="">$36 million</td></tr><tr><td colspan="" rowspan="">Polaris</td><td colspan="" rowspan="">5,000</td><td colspan="" rowspan="">$1 million</td><td colspan="" rowspan="">$2.4 million</td><td colspan="" rowspan="">$12 million</td></tr><tr><td colspan="" rowspan="">AIO Bot</td><td colspan="" rowspan="">5,000</td><td colspan="" rowspan="">$1 million</td><td colspan="" rowspan="">$2.4 million</td><td colspan="" rowspan="">$12 million</td></tr><tr><td colspan="" rowspan=""><strong>Total</strong></td><td colspan="" rowspan=""><strong>145,000</strong></td><td colspan="" rowspan=""><strong>$29 million</strong></td><td colspan="" rowspan=""><strong>$70 million</strong></td><td colspan="" rowspan=""><strong>$348 million</strong></td></tr></tbody></table>
</div>
</div>

</div>
<h2>Grinch Bots Are Increasingly Popular In Other Industries</h2>
<p>While bots have the deepest penetration in footwear, they are becoming increasingly popular in several other industries. There are several recent high-profile reports of bots outdueling humans to secure valuable in-demand merchandise, for example: </p><div>
<div>
<ul>
<li>In November, resellers used bots to purchase the majority of PlayStation 5s from top online retailers like GAME, John Lewis and Tesco (<a rel="nofollow noopener" target="_blank" title="source" href="https://metro.co.uk/2020/11/20/ps5-retail-websites-crashed-due-to-scalper-bots-13627423/#:~:text=It's%20believed%20that%20scalpers%20were,each%20other%20for%20late%20deliveries.">source</a>)</li>
<li>In September, resellers used bots to purchase the majority of Nvidia's RTX3080 video card (<a rel="nofollow noopener" target="_blank" title="source" href="https://www.extremetech.com/gaming/315210-resellers-used-bots-to-dominate-the-rtx-3080-launch">source</a>)</li>
<li>In April, resellers used bots to exacerbate shortages of the Nintendo Switch (<a rel="nofollow noopener" target="_blank" title="source" href="https://www.ign.com/articles/nintendo-switch-shortages-exacerbated-by-resellers-using-auto-buying-bots">source</a>)</li>
</ul>
</div>
</div>
<p>One of the largest online forums for botters is Reddit, and more specifically the community <a rel="nofollow noopener" target="_blank" title="r/shoebots" href="https://www.reddit.com/r/shoebots/">r/shoebots</a>. While this community started out focused on shoes, many recent threads are about CPUs, electronics, sports cards, and video games. As you can see below, the community has grown exponentially as botting has grown in popularity. It started 2020 at 9,630 members and has 22,400 members as of November 21, 2020.</p>
<div>
<p><img alt="r/shoebots reddit user growth over time" src="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/rshoebots-user-growth" srcset="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/rshoebots-user-growth 1x, https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_2.0,f_auto,h_1600,q_auto,w_1600/v1/software/rshoebots-user-growth 2x">
</p>
</div>
<p>The sneaker market and COVID-19 are two of the largest catalysts of grinch bot adoption. COVID-19 impacted the market in two ways –&nbsp;it increased unemployment, and shifted retail spend online. These forces led to more individuals looking for a new source of income online.</p>
<p>Bots have also begun advertising their ability to operate on websites outside of the footwear industry. On November 12, Prism <a rel="nofollow noopener" target="_blank" title="announced" href="https://twitter.com/PrismAIO/status/1326920747625885698">announced</a> that its bot works on Walmart.com. In fact, there are several bots that work on both <a rel="nofollow noopener" target="_blank" title="Target and Walmart's websites" href="https://www.reddit.com/r/shoebots/comments/jyrwnb/best_walmart_and_target_bot_for_mac/">Target and Walmart's websites</a>. Cybersole's website advertises the ability to use its bot on over 270 websites.</p>
<h2>The Leading Grinch Bots Are Now Being Sold for Almost $10,000</h2>
<p>The market for grinch bots has become increasingly competitive as more software products have entered the market. However, finding and purchasing a copy of the best bots is difficult –&nbsp;bot creators typically limit the number of instances they sell in an effort to prevent their bots from becoming too popular, and obsolete.</p>
<p>As a result, many of the top bots must be purchased through resale themselves. The bot resale website BotBroker.io has sold over 31,000 bots. The pricing data below was recorded from its website in November 2020.</p>
<div>
<div>
<div>
<table><thead><tr><th colspan="" rowspan="">Bot</th><th colspan="" rowspan="">Last Sale Price</th><th colspan="" rowspan="">Bot Creation Date</th></tr></thead><tbody><tr><td colspan="" rowspan="">Wrath</td><td colspan="" rowspan="">$8,299</td><td colspan="" rowspan="">February, 2018</td></tr><tr><td colspan="" rowspan="">CyberAIO</td><td colspan="" rowspan="">$5,600</td><td colspan="" rowspan="">April, 2016</td></tr><tr><td colspan="" rowspan="">Prism</td><td colspan="" rowspan="">$3,998</td><td colspan="" rowspan="">October, 2018</td></tr><tr><td colspan="" rowspan="">SwftAIO</td><td colspan="" rowspan="">$3,750</td><td colspan="" rowspan="">January, 2019</td></tr><tr><td colspan="" rowspan="">Polaris</td><td colspan="" rowspan="">$3,300</td><td colspan="" rowspan="">November, 2019</td></tr><tr><td colspan="" rowspan="">Balko</td><td colspan="" rowspan="">$2,400</td><td colspan="" rowspan="">August, 2018</td></tr><tr><td colspan="" rowspan="">MekAIO</td><td colspan="" rowspan="">$2,400</td><td colspan="" rowspan="">October, 2020</td></tr><tr><td colspan="" rowspan="">Nebula</td><td colspan="" rowspan="">$2,399</td><td colspan="" rowspan="">March, 2018</td></tr><tr><td colspan="" rowspan="">TohruAIO</td><td colspan="" rowspan="">$2,065</td><td colspan="" rowspan="">October, 2019
</td></tr></tbody></table>
</div>
</div>

</div>
<p>Wrath is currently the most expensive bot on BotBroker.io. As you can see below, its price has been steadily increasing the past year.</p>
<div>
<p><img alt="Wrath bot price over time" src="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/wrath-price-over-time" srcset="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/wrath-price-over-time 1x, https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_2.0,f_auto,h_1600,q_auto,w_1600/v1/software/wrath-price-over-time 2x">
</p>
</div>
<h2>What Holiday Merchandise Will Grinch Bots Target in 2020?</h2>
<p>The development of bots in the sneaker industry and COVID-19 mean that the holiday season of 2020 will see a record level of grinch bot transactions. The merchandise categories that will see the greatest bot transaction volume will be: </p><div>
<div>
<ul>
<li>Clothing</li>
<li>Collectibles</li>
<li>Computers</li>
<li>Electronics</li>
<li>Gaming</li>
<li>Sneakers</li>
<li>Toys</li>
</ul>
</div>
</div>
<p>In addition, resellers will almost certainly target flash sales of any high-demand item. Botters have formed 'cook groups' on Discord, where they share the latest information about promising upcoming 'drops' and sales. These groups provide botters an additional advantage over the average consumer.</p>
<p>Unfortunately for these consumers, it's likely that they will be forced to pay a significant premium to purchase the hottest items of the 2020 holiday season. It's hard to compete with the botters and their bots.</p>
</div></div>]]>
            </description>
            <link>https://www.softwarepundit.com/industry-research/grinch-bots-steal-holiday-deals</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202140</guid>
            <pubDate>Tue, 24 Nov 2020 19:35:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Email a Dumpster Fire]]>
            </title>
            <description>
<![CDATA[
Score 920 | Comments 249 (<a href="https://news.ycombinator.com/item?id=25201798">thread link</a>) | @bschne
<br/>
November 24, 2020 | https://hey.science/dumpster-fire/ | <a href="https://web.archive.org/web/*/https://hey.science/dumpster-fire/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>What's this experiment all about?</p>
    <p>Well, 2020's been a rough year. An absolute dumpster fire of a year for a lot of people.</p>
    <p>That's when it came to us. Can email be a conduit for catharsis? If you could type out an email, press send, and see it being consumed in an actual dumpster fire, would it help reclaim a little bit of what we've lost?</p>
    <p>Let's find out.</p>
    <p>P.S. We'll only use your email address to notify you about your burn. That's it, the end.</p>
    <p>P.P.S. We're offsetting by 3x every bit of CO2 this creates via <a href="https://www.cooleffect.org/content/project/native-alaskans-saving-lands" target="_blank" rel="noopener nofollow">Cool Effect</a>.</p>
  </div></div>]]>
            </description>
            <link>https://hey.science/dumpster-fire/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201798</guid>
            <pubDate>Tue, 24 Nov 2020 19:04:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Rainbow Tables Work]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25201513">thread link</a>) | @susam
<br/>
November 24, 2020 | http://kestas.kuliukas.com/RainbowTables/ | <a href="https://web.archive.org/web/*/http://kestas.kuliukas.com/RainbowTables/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><h6><a href="http://kestas.kuliukas.com/">kestas.kuliukas.com</a></h6>
<h3>How Rainbow Tables work</h3>
<p>I found the creator of Rainbow Table's paper, aimed at cryptanalysts,
was pretty inaccessible considering the simplicity and elegance of
Rainbow Tables, so this is an overview of it for a layman.</p>

<hr>

<p>Hash functions map plaintext to hashes so that you can't tell a
plaintext from its hash.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/1.png"></center>

<p>If you want to find a given plaintext for a certain hash there are two
simple methods:<br>
- Hash each plaintext one by one, until you find the hash.<br>
- Hash each plaintext one by one, but store each generated hash in a
sorted table so that you can easily look the hash up later without
generating the hashes again</p>

<p>Going one by one takes a very long time, and storing each hash takes an
amount of memory which simply doesn't exist (for all but the smallest of
plaintext sets). Rainbow tables are a compromise between pre-computation
and low memory usage.</p>

<p>The key to understanding rainbow tables is understanding the
(unhelpfully named) reduction function.<br>
A hash function maps plaintexts to hashes, the reduction function maps
hashes to plaintexts.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/2.png"></center>


<p>It's important to note that it does the reverse of a hash function
(mapping hashes to plaintexts), but it is /not/ an inverse hash
function. The whole purpose of hash functions is that inverse hash
functions can't be made. If you take the hash of a plaintext, and take
the reduction of the hash, it will not give you the original plaintext;
but some other plaintext.</p>

<p>If the set of plaintexts is [0123456789]{6} (we want a rainbow table of
all numeric passwords of length 6), and the hashing function is MD5(), a
hash of a plaintext might be MD5("493823") -&gt;
"222f00dc4b7f9131c89cff641d1a8c50".<br>
In this case the reduction function R() might be as simple as taking the
first six numbers from the hash; R("222f00dc4b7f9131c89cff641d1a8c50")
-&gt; "222004".<br>
We now have generated another plaintext from the hash of the previous
plaintext, this is the purpose of the reduction function.</p>


<p>Hashes are one-way functions, and so are reduction functions. The chains
which make up rainbow tables are chains of one way hash and reduction
functions starting at a certain plaintext, and ending at a certain hash.
A chain in a rainbow table starts with an arbitrary plaintext, hashes
it, reduces the hash to another plaintext, hashes the new plaintext, and
so on. The table only stores the starting plaintext, and the final hash
you choose to end with, and so a chain "containing" millions of hashes
can be represented with only a single starting plaintext, and a single
finishing hash.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/3.png"></center>


<p>After generating many chains the table might look something like:<br>
iaisudhiu -&gt; 4259cc34599c530b1e4a8f225d665802<br>
oxcvioix -&gt; c744b1716cbf8d4dd0ff4ce31a177151<br>
9da8dasf -&gt; 3cd696a8571a843cda453a229d741843<br>
[...]<br>
sodifo8sf -&gt; 7ad7d6fa6bb4fd28ab98b3dd33261e8f</p>

<hr>

<p>The chains are now ready to be used. We have a certain hash with an
unknown plaintext, and we want to check to see whether it is inside any
of the generated chains.</p>

<p>The algorithm is:<br>
</p><ul><li>Look for the hash in the list of final hashes, if it is there break
out of the loop.</li>
<li>If it isn't there reduce the hash into another plaintext, and hash the
new plaintext.</li>
<li>Goto the start.</li>
<li>If the hash matches one of the final hashes, the chain for which the
hash matches the final hash contains the original hash.</li></ul>
You can now get that chain's starting plaintext, and start hashing and
reducing it, until you come to the known hash along with its secret
plaintext.

<p>In this way you check through the hashes in the chains, which aren't
actually stored anywhere on disk, by iterating column by column through
the table of chains, backwards from the last column in the chain, to the
starting plaintext.</p>

<hr>
<p>If you wanted to check whether the hash exists in the last column of any 
of the chains you reduce and hash the given hash once, then check the 
generated hash against the chain end hashes.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a1.png"></center>

<p>You can check the second last column by reducing and hashing twice, 
then check the generated hash against the chain end hashes.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a2.png"></center>

<p>And the third is checked by reducing and hashing three times, 
then check the generated hash against the chain end hashes.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a3.png"></center>

<p>Supposing
a chain ending matches the generated hash the matching chain end might
contain the hash. The starting plaintext which was stored with the ending 
hash can be reduced and hashed until the correct plaintext is found within 
the chain.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a4.png"></center>

<hr>

<p>Collisions are the only problem with Rainbow Tables. Ironically
collisions are seen as a bad thing for hashing algorithms, but in the
case of Rainbow Tables a hashing algorithm which generates collisions
fairly regularly will be more secure.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/5.png"></center><br>
A given hash may be generated by multiple plaintexts (this is called a
collision), which is a big problem for chains because it causes chains
which start different to converge into one. Also you get loops, which
are caused when a hash is reduced to a plaintext that was hashed at a
previous point in the chain.<br>
<center><img src="http://kestas.kuliukas.com/RainbowTables/6.png"></center>


<p>Because of these collision problems there is no guarantee that there
will be a hash of a plaintext that will reduce to some other given
plaintext.<br>
If you have a simple list of hashes and corresponding plaintexts for
every plaintext in a set you will know that if you have not found the
hash in the generated hashes the plaintext that generated the hash is
not in the set.<br>
If you have a table of chains where the reduction function reduces
hashes into the set of plaintexts you could have trillions of chains
generated but you still may not have generated every plaintext in the
set you want to check. You can only say how probable it is that a table
of chains contains a certain plaintext, and this can approach 1 but will
probably never reach 1.<br>
If you have a rainbow table with 10 chains of length 100 you have hashed
1000 plaintexts, but even if there are only 100 plaintexts in the set of
desired plaintexts the 1000 hashes you have in the chains may not
contain all the desired hashes.</p>

<hr>

<p>The way collisions are handled is what sets Rainbow Tables apart from
its predecessor which was developed in 1980.</p>

<p>The predecessor solved the problem of certain plaintexts never being
reduced to by using many small tables. Each small table uses a different
reduction function. This doesn't solve the problem completely, but it
does help.<br>
To solve chain merges and loops each chain ended at a "distinct point";
a hash which was unique in some way, eg hashes where the first 4
characters are 0. The chains keep on going until it reaches a distinct
point. If two chains end up at the same distinct point then there has
been a collision somewhere in the chain, and one of the chains is
discarded. If a chain is generated for an unusually long time without
reaching a distinct point a loop is suspected (where a chain of hashes
ends up reducing and hashing to a previous hash in the chain).
The problem with this is that if there is a collision there is
potentially a whole branch which has to be cut off and won't make it
into the chains, and a loop will cause all the hashes which came before
the loop in the chain to be discarded.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/7.png"></center><br>
Also all the time spend generating that chain will be wasted, and by
ending only at distinct points you have chains of variable length. This
means that you may have to keep checking for a hash within especially
long chains long after the other chains have ended.

<hr>

<p>Rainbow tables differ in that they don't use multiple tables with
different reduction functions, they only use one table. However in
Rainbow Tables a different reduction function is used for each column.
This way different tables with different reduction functions aren't
needed, because different reduction functions are used within the same
table. It is still unlikely that all plaintexts in the desired set will
be hashed, but the chances are higher for a given number of chains.
Chain merges are much, much rarer, because collisions have to occur on
the same column. For a chain of length l the chance of a collision
causing a merge is reduced to 1/l. Loops are also solved, because if a
hash in a chain is the same as a previous hash it won't reduce to the
same plaintext.</p>

<p>The reason they're called Rainbow Tables is because each column uses a
different reduction function. If each reduction function was a different
color, and you have starting plaintexts at the top and final hashes at
the bottom, it would look like a rainbow (a very vertically long and
thin one).<br>
By using Rainbow Tables the only problem that remains is that you can
never be certain that the chains contain all the desired hashes, to get
higher success rates from a given Rainbow Table you have to generate
more and more chains, and get diminishing returns.</p>


<hr>

<p>I hope by explaining the Rainbow Table I haven't made them any less 
wonderful ...</p>

<hr>

<a name="improving"></a>
<h4>An easy way to improve on the "rainbowcrack" Rainbow Tables implementation</h4>
<p>This section probably goes a bit beyond where a layman would be comfortable, 
but if you're interested in the practical applications of the above theory or have some 
interest in cryptography read on..</p>

<p>The rainbowcrack application is how most people come to learn 
about Rainbow Tables, because it is the application which puts the 
theory above into code. It has been very successful, with many websites 
dedicated to generating rainbowcrack hash tables and letting users search them.</p>

<p>However there is a pretty clear way this application could be improved, 
very easily, in the sense that the generated tables would take up a lot less
disk space, but be equally as effective for breaking hashes:</p>

<p>Remember above that when you want to generate a certain chain 
you start from an arbitrary hash. This just means it doesn't matter where 
you choose to start from. The rainbowcrack application starts from a randomly 
generated 64-bit number. This number is then used to generate a chain which 
ultimately ends with a 128-bit hash, which is reduced to another 64-bit number.</p>

<p>Why use a randomly generated number as the starting point? A …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://kestas.kuliukas.com/RainbowTables/">http://kestas.kuliukas.com/RainbowTables/</a></em></p>]]>
            </description>
            <link>http://kestas.kuliukas.com/RainbowTables/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201513</guid>
            <pubDate>Tue, 24 Nov 2020 18:43:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What does it mean to “reconcile to cash”?]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25201471">thread link</a>) | @qin
<br/>
November 24, 2020 | https://www.moderntreasury.com/journal/what-is-automatic-reconciliation | <a href="https://web.archive.org/web/*/https://www.moderntreasury.com/journal/what-is-automatic-reconciliation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Businesses that manage payments at scale face the complex challenge of reliably monitoring cash. Most of us have experienced the time delays inherent to ACH, wires, and checks. These delays make it difficult to tie a payment you’ve made or expect to receive to the actual transaction that posts to your bank account. This process is called reconciliation and it is essential for a business to understand how completed and in-progress transactions add up to the cash balance in its bank account.&nbsp;<br></p><p>Most finance teams try to solve the reconciliation problem with spreadsheets, email and manual examination of bank statements — processes that are inefficient and error-prone. At Modern Treasury, we’ve built a better solution that helps finance teams save time and minimize errors. We call it Automatic Reconciliation.&nbsp;<br></p><p>With Automatic Reconciliation, Modern Treasury automatically matches your payments and returns to transactions as they are made available by your bank. Reconciled transactions are reflected in the previous day and intra-day balances available through the API and dashboard, allowing you to reliably monitor cash across all your business bank accounts.&nbsp;</p><p>‍<br></p><h4>How Does Reconciliation Help With Monitoring Cash?<br></h4><p>Let’s say you run a marketplace for artisanal coffee that lets coffee aficionados buy coffee from artisanal coffee roasters anywhere in the country. You collect payments from the buyer, deduct your platform fee and pay the seller. You also need to handle other types of transactions, like refunds and bonus payments to your top performing sellers. Business is going well so you’re processing thousands of orders a week.&nbsp;<br></p><p>To reliably monitor cash, you need to be able to match every single payment you’ve made or received to the corresponding transaction in your bank statement. At scale, this quickly gets very complicated for three reasons.&nbsp;</p><p>‍</p><h4>1. Banks Don’t Move Money as Fast as Your Business <br></h4><p>The time it takes for your transaction to settle depends on which payment method you use. Here’s a list of business payment methods used in the US and their typical settlement times. Because of these settlement timeframes, the rate at which you move money is slower than your business activities.&nbsp;<br></p><figure id="w-node-260693cab140-b8df1e0f"><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/5fbc098771bac937c487c98a_AutomaticReconciliationTable.png" loading="lazy" alt=""></p></figure><p><br>Let’s say you pay coffee sellers on a daily basis. If you initiate a number of ACH credits on Monday, they are likely to settle by Tuesday. But by the time they settle, you have already initiated a new batch of payments on Tuesday that will settle on Wednesday.&nbsp;<br></p><p>Without reconciliation, it’s hard to keep track of the cash available in your bank account, what transactions are processing versus complete, and when different sets of transactions are likely to settle.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><h4>2. Banks Process Transactions in Batches</h4><p>Let’s say you need to pay 10 coffee roasters $1000 each at the end of the week. You initiate 10 ACH credit transactions, each for $1000 on Friday before the day’s cut-off. These transactions will likely post to your bank statement Monday evening or Tuesday morning next week.&nbsp;<br></p><p>When you ask your bank to make a payment, it’s placed into a queue that’s sent to the network for processing after a certain cut-off time for the day. Any transactions submitted after the cut-off time are queued up to be processed the next business day. Different banks have different <a href="https://docs.moderntreasury.com/reference#ach-timings" target="_blank">cut-off times</a> for processing transactions.<br></p><p>The next day, instead of seeing 10 separate transactions next week, you’ll see one transaction for $10,000 on your statement. Because ACH transactions take place in batches, your bank directly debits your account for the total amount even though it represents 10 separate payments. Reconciliation helps you tie each payment to the appropriate transaction on your bank statement.&nbsp;</p><h4>3. Monitoring Incoming Payments and Returns is Difficult</h4><p>Let’s say you’re also expecting 100 payments of $20 each from your buyers. You need to know when they hit your bank account to predict cash accurately. You also need to tie each payment to an order. Similar to when you make bulk payments, your bank may record all or some of those payments as a single transaction on your statement.&nbsp;<br></p><p><a href="https://www.moderntreasury.com/journal/what-happens-when-you-ach-a-dead-person" target="_blank">Payment returns</a> also complicate monitoring cash flow. For example, ACH credits will fail due to incorrect account or routing numbers and ACH debits will fail if the counterparty doesn’t have sufficient funds in their account. In both scenarios, your bank will post a return transaction to your bank statement that needs to be reconciled with the original payment.</p><h4>Automatic Reconciliation<br></h4><p>Until now, many companies have relied on manual reconciliation processes that typically involve exporting transactions from the bank portal to a spreadsheet and manually matching them with payments. In addition to being time consuming, the need to email multiple spreadsheets back and forth makes collaboration painful.&nbsp;<br></p><p>With Automatic Reconciliation, Modern Treasury instantly reconciles every single payment with transactions in your bank statement. We <a href="https://www.moderntreasury.com/journal/tentative-reconciliation" target="_blank">tentatively reconcile</a> the transaction when it’s pending and complete the process when it posts. Because ACH processes transactions in batches, a large number of transactions on your bank statement are likely to represent multiple distinct payments. If the transaction aggregates multiple Payment Orders, we automatically create matching <a href="https://docs.moderntreasury.com/reference#transaction-line-item-object" target="_blank">Transaction Line Items</a>.&nbsp;<br></p><p>When you see a Payment Order marked as completed, you can click into it in the web application to see the matching transaction.&nbsp;<br>‍<br></p><figure id="w-node-bb5fd7410dc0-b8df1e0f"><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/5fbc08ea82af2f7050239826_Payment%20Orders%20-%20640%20px.gif" loading="lazy" alt=""></p></figure><p><br>The Expected Payments feature allows you to monitor your bank account for payments you do not initiate. When the transaction is made available by your bank, it is automatically reconciled with the Expected Payment. You can choose to be notified by <a href="https://docs.moderntreasury.com/reference#expected-payments">webhook</a> or email about its status.&nbsp;&nbsp;&nbsp;<br></p><figure id="w-node-6bf8f8776d0d-b8df1e0f"><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/5fbc08fdea9cc07dcb14b23c_Expected%20Payments%20-%20640%20px.gif" loading="lazy" alt=""></p></figure><p><br>The Returns feature automatically matches returned payments to transactions and the original Payment Order, making identifying, correcting and redrafting returns a breeze.&nbsp;<br></p><figure id="w-node-2fa9dd183a06-b8df1e0f"><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/5fbc0910f4c807451c4b685e_Returns%20-%20640%20px.gif" loading="lazy" alt=""></p></figure><p><br>All the data you see in the app is also available through the API, allowing you to further automate and streamline reconciliation by integrating Modern Treasury directly into your business systems or platform.&nbsp;<br></p><p>We also have direct integrations with QuickBooks and NetSuite through our <a href="https://www.moderntreasury.com/journal/introducing-continuous-accounting" target="_blank">Continuous Accounting</a> product. It syncs Modern Treasury directly with your general ledger, allowing you to tag payments with accounting categories. When you’re closing out the books, all you need to do is click a few buttons in the web app to transfer payments that have been Automatically Reconciled to your accounting software.<br></p><p>Finally, because we connect to <a href="https://docs.moderntreasury.com/docs/banks" target="_blank">multiple banks</a>, you can use Modern Treasury to reconcile transactions and monitor cash across all your business bank accounts.&nbsp;</p><h4>Get Started With Automatic Reconciliation</h4><p><a href="https://www.moderntreasury.com/product-demo" target="_blank">Get in touch</a> if you’re interested in exploring Automatic Reconciliation for your business. We’d love to discuss your use case in detail.</p></div></div></div>]]>
            </description>
            <link>https://www.moderntreasury.com/journal/what-is-automatic-reconciliation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201471</guid>
            <pubDate>Tue, 24 Nov 2020 18:39:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to stream your data in Apache Kafka with SQL]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25201407">thread link</a>) | @Natasha_Fll
<br/>
November 24, 2020 | https://lenses.io/blog/2020/11/apache-kafka-with-streaming-sql-from-real-time-data/ | <a href="https://web.archive.org/web/*/https://lenses.io/blog/2020/11/apache-kafka-with-streaming-sql-from-real-time-data/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><img alt="SELECT ApacheKafka WITH StreamingSQL FROM RealTimeData" src="https://images.ctfassets.net/tnuaj0t7r912/14MI0c1G0o6YM0jWb68az7/2623be6f9a8c8b47f72e878b351b604f/Mattero-KOH-Blog-v02.jpg?w=800&amp;q=100"></p><div><p>In another life, I taught the <i>Book of</i> <i>Genesis</i> to high school students, including The Tower of Babel excerpt. It struck me ironic that God’s wrath strikes down the tower, cofounds the universal language and scatters humans around the globe to teach King Nimrod a lesson in hubris; meanwhile, the boys in my class were texting their girlfriends across the country and playing video games with friends in Europe and Asia.&nbsp;</p><p>Technology allows us to form a new Tower; in particular, the ability to stream real-time events. For this technology to be built and managed, a common language is necessary, and more often than not, SQL is the common tongue of developers, architects and analysts. Recently, Matteo De Martino, Senior Scala Engineer at Lenses.io&nbsp; presented on the benefits of streaming SQL to react to real-time data for business critical decisions.&nbsp;</p><p>Anyone competent enough to build a pivot table on Excel understands how to act on data. You take a snapshot or data table and make an active query to parse out distribution and trends. While this is an important retrospective task, it does not allow for you to make business critical decisions in real-time.&nbsp;</p><p>The streaming SQL processors that Matteo explored in his <i>Kafka Office Hours </i>allow for users to process real-time data. As infinite amounts of data stream through an Apache Kafka cluster, users can model the transformations of data and write back to Kafka.</p><p>Lenses SQL Engine takes it a step further with SQL Processors. Not only can you model transformations, you can execute them as well. Users are able to scale, manage and govern their data with <a href="https://lenses.io/dataops/">DataOps</a>. </p><p>This activates data, allowing <a href="https://lenses.io/customers/">Lenses.io customers</a> to process data as it arrives and update the running state automatically.</p><p>Streaming SQL focuses on future data, so businesses can make time critical decisions. Matteo’s presentation outlines the advantages of Lenses Streaming SQL &amp; SQL processors. Watch his video below and then try SQL for yourself using <a href="https://lenses.io/box/">the Lenses Box, a self contained Apache Kafka environment.&nbsp;&nbsp;&nbsp;</a></p><p><iframe src="https://player.vimeo.com/video/483029806" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p>


</div></div></div></div>]]>
            </description>
            <link>https://lenses.io/blog/2020/11/apache-kafka-with-streaming-sql-from-real-time-data/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201407</guid>
            <pubDate>Tue, 24 Nov 2020 18:33:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Expensive Security Fails in Healthcare Apps]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25201335">thread link</a>) | @_Tata_
<br/>
November 24, 2020 | https://www.ego-cms.com/post/most-expensive-healthcare-app-security-fails-in-2018-2019 | <a href="https://web.archive.org/web/*/https://www.ego-cms.com/post/most-expensive-healthcare-app-security-fails-in-2018-2019">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><a href="https://www.ego-cms.com/tags/healthcare"><p>Healthcare</p></a><h2>Most Expensive Healthcare App Security Fails in 2018–2019</h2><p>MyFitnessPal, PumpUp, and Strava all were unable to avoid data breaches. Find out why and what you can learn from these cases to make your app more secure.
</p></div></div><article><div target="_blank"><p>In 2018, the average cost for a corporate data breach reached almost <a href="https://igniteoutsourcing.com/healthcare/healthcare-security-breaches/">$4 million</a>.&nbsp;</p><p>Let’s take a look at a few of these attacks to learn what went wrong and secure your business from such risks.</p><h2>1 MyFitnessPal</h2><p>MyFitnessPal is a typical fitness application. It allows users to log cardio and strength exercises, connects with more than 50 devices and other apps, tracks steps, counts calories, and so on. Released in 2009, MyFitnessPal quickly gained popularity — it was chosen as the number one health and fitness app four years in a row. But everything changed in February 2018.</p><figure id="w-node-9fe8c2a22398-7a0a8b78"><p><iframe allowfullscreen="true" frameborder="0" scrolling="no" src="https://www.youtube.com/embed/KRcvSWvR0kc"></iframe></p></figure><p>The MyFitnessPal data breach was probably one of the most publicized in the healthcare industry. Hackers accessed the personal data of almost <strong>150 million users</strong>, stealing their names, hashed passwords, IP addresses, and email addresses. Fortunately, the criminals couldn’t get to users’ credit card and social security numbers, as this data was collected and stored separately.&nbsp;<br></p><p><a href="https://www.underarmour.com/en-us?&amp;cid=PS%7Cgoogle%7CTrademark%7CUA%7CIP%7CExact%7Cunder%20armour%7CSRnf0L2T&amp;gclid=CjwKCAjw1_PqBRBIEiwA71rmtbPVRSTc31VHHLODl9D2ZnA-9HiTBv4xxSkBkyeWl8Z7kAJldUZ_QhoCaG8QAvD_BwE">Under Armour</a>, the company which acquired MyFitnessPal in 2015, became aware of the data breach at the end of March 2018. Four days later, users started to receive notifications and emails requiring them to change their passwords and offering recommendations on how to safeguard their accounts. In February 2019, the stolen personal details appeared on the dark web.&nbsp;<br></p><p>Other apps owned by Under Armour were not affected, but the company still <strong>lost 4.6% of its market</strong> <strong>value</strong> because of the data breach. However, the company and the app survived. MyFitnessPal still has a lot of users and pretty high ratings in the app stores (4.5 on Google Play).</p><h4><strong>What to learn from this case:</strong></h4><ul role="list"><li>MyFitnessPal should have been equipped with <strong>two-factor authentication</strong>. For a mobile application, we would recommend using biometric authentication or at least push notifications.&nbsp;</li></ul><ul role="list"><li>Reliable <strong>encryption</strong> is a must for companies that are serious about privacy and security.</li><li>For the majority of passwords, Under Armour used the <a href="https://content.myfitnesspal.com/security-information/FAQ.html">Bcrypt</a> hashing function. This is a reliable mechanism. But for the remaining passwords, the company used the <strong>rather weak </strong><a href="https://content.myfitnesspal.com/security-information/FAQ.html"><strong>SHA-1</strong></a>. Using Bcrypt for all passwords could have reduced the scope of the breach.</li></ul><ul role="list"><li>Collecting and <strong>storing</strong> the most important <strong>data separately</strong> is a great practice — it kept credit card data safe. Otherwise, Under Armour could have faced a much more serious loss in market value.</li></ul><ul role="list"><li>If a breach happens, it’s essential to <strong>notify users as fast as possible</strong> — keeping silent will simply destroy your company’s reputation. Under Armour did well here.</li></ul><h2>2 PumpUp</h2><p><a href="https://www.pumpup.com/#home">PumpUp</a> positions itself as the world’s most positive fitness community. It offers users numerous workouts and programs, an opportunity to learn more about fitness and get support from other members, and other features. After the app was released in 2012, it became rather popular.<br></p><p>The PumpUp data breach took place in May 2018, when personal data of more than <a href="https://www.zdnet.com/article/fitness-app-pumpup-leaked-health-data-private-messages/"><strong>6 million users</strong></a><strong> </strong>stopped being private. Data compromised included information on users’ locations, email addresses, gender, and dates of birth, full-resolution profile photos, workout data, health information (for instance, weight and height), device data, and private messages. In certain cases, even credit card data was exposed.&nbsp;<br></p><p>The incident happened because the core backend server hosted on the Amazon Cloud was left without a password for an indefinite amount of time. Anyone could see the private content of the app’s users.</p><figure><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5fb7cdf1127270466b858d20_5d78d2e9cd001218b4a025f0_eb187d1d-170d-44e4-8ab7-2aa08946fd06.png" loading="lazy" alt=""></p></figure><p>The exposed server wasn’t even found by the company — it was discovered by security researcher Oliver Hough who then contacted <a href="https://www.zdnet.com/article/fitness-app-pumpup-leaked-health-data-private-messages/">ZDNet</a>, a business technology news website, to investigate the case. ZDNet spent a week trying to get in touch with PumpUp, but there was no reply. However, in the end, the server was secured.<br></p><p>Since there were no comments from PumpUp after the breach, we can’t tell exactly how much money they lost. But their reputation was definitely affected.&nbsp;<br></p><h4><strong>What to learn from this case:</strong></h4><ul role="list"><li>To avoid this problem, PumpUp had at least to protect their data with a password. Ideally, this would have been combined with <strong>two-factor authentication</strong> to keep users’ data safe.&nbsp;</li></ul><ul role="list"><li>It seems that the company didn’t run any security tests — <strong>regular security scanning</strong> would have helped them notice the problem much earlier. EGO recommends performing such tests on a regular basis.</li><li>Another mistake PumpUp made was ignoring<strong> communications</strong> from ZDNet and ignoring the incident. If a breach happens, a company should stay in touch to show users that it cares.</li></ul><h2>Strava</h2><p><a href="https://www.strava.com/mobile">Strava</a> is a fitness app for tracking running, cycling, swimming, and other activities. It allows users to map and record their routes, analyze their activities, participate in challenges, etc. The app was released in 2009, and since then it has been installed more than 10 million times on Android OS alone (according to <a href="https://play.google.com/store/apps/details?id=com.strava&amp;hl=en">Google Play</a>; no data on iOS downloads is available).<br></p><p>The story of the Strava failure began in November 2017, when the company released a global heat map showing running routes for all users who opted to make their data publicly available. To create the map, Strava used GPS data from smartphones and fitness tracking devices on <strong>1 billion</strong> activities. This data was collected from 2015 to 2017. Over <strong>27 million</strong> users tracked their routes during this time, and due to confusing privacy settings, some of them didn’t even know that they were sharing sensitive data.&nbsp;<br></p><p>This map was the brainchild of Strava. But in January 2018, Nathan Ruser, an Australian student, noticed that by analyzing the map, it was possible to determine the whereabouts of military bases and other sensitive locations.</p><figure><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5fb7c54a7adc793c1f5f41b3_5d78d3ce1f37d12d04642dcc_Artboard.png" loading="lazy" alt=""></p></figure><p>Strava and its map got a lot of criticism. In response, the company didn’t delete the map, but rather changed it significantly.&nbsp;<br></p><p>First of all, the data isn’t available to everyone anymore — to zoom in and see street-level detail, users now have to log in with their Strava account.&nbsp;<br></p><p>Second, the map is now updated monthly, which means that if a user changes their privacy settings and doesn’t want to provide data for the heat map anymore, their data won’t be included in the next month’s map.&nbsp;<br></p><p>Third, all roads and paths with little activity aren’t shown on the map until they’re used by different users (not only runners, for example) for different activities.<br></p><p>To develop the heat map, Strava had to collect, analyze, and put together loads of data, which took money and a lot of time. Then the company had to update the map significantly, which meant unexpected additional expenses.&nbsp;<br></p><h4><strong>What to learn from this case:</strong></h4><ul role="list"><li>In the case of Strava, there were no hackers or other criminals — the company gave out important information on its own. There was not even some kind of social engineering, as no fraud was involved. Strava simply didn’t pay enough attention to the potential outcome, and that was their main mistake — they didn’t anticipate the consequences. Explaining the importance of security and privacy to the entire team and <strong>training staff</strong> on a regular basis probably couldn’t have prevented this incident fully. But if the Strava staff would have thought about possible implications, they would have noticed that something was wrong during the map development phase.&nbsp;</li><li><strong>Privacy settings</strong> should not be confusing. Users must be able to set everything up easily and quickly. If privacy settings had been clearer, most users would have been able to prevent their private data from being published.</li></ul><h2>The Bottom Line</h2><p>To protect your healthcare app from security mistakes and failures, you have to pay attention not only to encryption and multi-factor authentication. As you can see from the Strava case, it’s also crucial to plan updates and new releases very carefully.&nbsp;<br></p><p>Follow these simple rules: run security tests and staff trainings on a regular basis, secure your app with multi-factor authentication and encryption, keep privacy settings simple, and analyze all potential outcomes.&nbsp;<br></p><p>And, obviously, if something does go wrong, stay in touch with your users. </p><figure><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5fb7c533a29d5b2035e7ec00_5f6cbf011fddb44501d8d28d_5d3042f66324e92dec2018cb_Business%20Insights.png" loading="lazy" alt=""></p></figure><p>‍<br></p></div></article><section><div><div><p>LIKE THIS ARTICLE? Help us SPREAD THE WORD.</p></div></div></section></div>]]>
            </description>
            <link>https://www.ego-cms.com/post/most-expensive-healthcare-app-security-fails-in-2018-2019</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201335</guid>
            <pubDate>Tue, 24 Nov 2020 18:26:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Error codes are far slower than exceptions]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25201269">thread link</a>) | @vips7L
<br/>
November 24, 2020 | https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/ | <a href="https://web.archive.org/web/*/https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
TL;DR On modern 64-bit PC architectures, C++ exceptions only add unreachable code with destructor calls into functions and their effect on performance is below 1%, but such low values are difficult to measure. Handling rare errors with return values requires additional branching that slows down the program in realistic scenarios by about 5% and are also less convenient. If an exception is actually thrown, stack unwinding costs about 2 µs per stack frame.
</p>

<p>C is considered to be the fastest programming language. C++ has features that only make C more convenient without an effect on performance and features that do impact performance. They help a lot to improve code quality, so they are often used anyway. Runtime polymorphism is virtually ubiquitous, exceptions less so.</p>



<p>A completely valid reason not to use exceptions is when the executable’s size is or is expected to be tightly constrained by the platform’s limitations. A questionable reason not to use them is performance, as it’s unlikely for completely new functionality to work without compromises. Also, using exceptions in wrong cases can completely ruin performance because handling a thrown exception is known to be very expensive.</p>



<p>But how significant is the performance impact? On most modern 64-bit platforms, exceptions are implemented in a way that minimises their cost as long as they are not thrown. There are no checks for exceptions being thrown in the generated functions, the execution switches to special functions and special data when handling an exception. However, not using exceptions is not free either. Rare errors have to be handled somehow. One possibility is to have the program simply abort, leaving any broken state on the disk, leading to very annoying user experience (done for example in Unreal Engine and Unity Engine, where incorrect API usage in code causes the editor to crash and keep crashing until the incorrect binaries are manually erased). Another alternative are error codes, when functions report they failed and the calling code is supposed to react appropriately, which is less convenient for the programmer and requires the program an additional check after returning from functions, however, it’s often done for performance reasons.</p>



<p>But actually, how do these approaches affect performance? I have tested this on realistic examples that simulate use cases typical for video games.</p>



<h2>Reminder – where not to use exceptions?</h2>



<p>An exception, as its name suggests, is supposed to deal with <em>exceptional</em> cases. An exception is a case when a rule doesn’t apply. In software, that means something isn’t going as intended. Not a part of a use case. A failure. Invalid user input, connection failure, corrupted data, invalid packet, failure to initialise a device, missing file, programmer errors…</p>



<p>In many of these cases, the program shouldn’t just abort. Invalid user input stopping the program is super annoying because it causes all unsaved data to be lost and forcing the user to wait until the program restarts. Connection failure is a very recoverable problem, usually solvable by simply reconnecting. Invalid packet causing a program to crash is an open door to sabotage, as anyone can send invalid packets to cause the program to crash. And that is what can be solved by exceptions. Throwing them is slow, but the code does not need to be optimised to what isn’t its use case.</p>



<p>Examples of incorrect use of exceptions is when they’re thrown when everything works as it should. Breaking from a double loop, handling the end of a container, checking if a number can be deserialised in order to use a default value otherwise…</p>



<p>Modern 64 bit architectures use a model called <em>zero-cost exceptions</em> that optimises error handling with exceptions strongly in favour of the happy path when no exception is thrown at the cost of very bad performance of exceptions when they are actually thrown.</p>



<p>In other words, it should be possible to run the program in a debugger with the stop on exception function enabled.</p>



<p>Although not all error handling can be efficiently handled with exceptions, error codes can handle all of it. The question is, should they?</p>



<h2>Test 1 – XML parsing</h2>



<p>For the purpose of this test, I have written an XML parser. I chose to write a parser because it can fail at many locations and does not depend on I/O. It’s definitely not standard-compliant or guaranteed to fail on every possible invalid input, but it can parse a usual XML configuration file and should end with an error in most cases where the file is syntactically incorrect. The code is quite low level and should be relatively fast (about 150 MiB/s), but I did not optimise it and used STL containers to make it convenient to use (as opposed to in-situ parsing). I wrote it with a lot of <code>#ifdef</code> checks to switch between exceptions, error codes and abort on error just with compiler arguments and thus ensure that the only differences between the variants would be what is necessary for different error handling.</p>



<p>I benchmarked it with <a href="https://gist.github.com/Dugy/5fee1b49777054d01f12e22ce9f986e5">an XML file that imitates the configuration of a video game</a>. Its size is 32 kiB and is loaded into memory before the benchmarks start. The parsing was repeated 10000 times and the duration was averaged, then repeated 10 times to test that its imprecision was below 1%.</p>



<p>The code was compiled with GCC 9, on Ubuntu 20.04, with an Intel i7-9750H processor with maximum single threaded frequency 4.5 GHz. I ran all experiments that I wanted to compare at a similar time, without doing anything in between, in order to equalise the influence of other programs occupying cache. Anyway, there were still outliers that took noticeably more than average. I removed these.</p>



<p>The version that aborted on error was as fast as the version with exceptions. The version with error codes was 5% slower.</p>



<p>For some reasons, if failures were handled by a special function that printed the error and exited the program, it was for some reasons slightly (about 1%) slower than the version with exceptions. I had to use a macro to make it comparable to the speed of code using exceptions. This behaviour was repeated in the other tests.</p>



<h2>Test 2 – filling classes with the parsed XML</h2>



<p>For this test, I’ve written several classes meant to represent the structures in the XML file and code for filling the data with the parsed XML structure. This part was about 10 times faster, probably because there was much less dynamic allocation.</p>



<p>The error margins of the code with exceptions and the code with no proper error handling overlapped, but the times were 0.6% higher for exceptions. In the case of error codes, the program was 4% slower. I achieved a similar slowdown by forgetting to use move semantics.</p>



<h2>Test 3 – Updating with data from a binary stream</h2>



<p>This test imitates the usage of an asynchronous API for reading data from a TCP socket (such as Boost Asio or Unix Sockets). These APIs are used in a way that always a certain number of bytes is read from the stream, have to be processed and then more data is read. For faster processing and reduced bandwidth, the data are in binary form. Because network data in video games are streamed continuously, waiting for the end is not feasible.</p>



<p>The communication is represented by three message types that identify different possible updates. Because the messages have different lengths, it’s not possible to exactly determine whether all of the message’s length is available, so the function that identifies the message and calls appropriate parsing code will fail often even if everything is running correctly – so exceptions cannot be used to handle this type of failure. Other failures, like unidentifiable message types, wrong identification of objects or large sudden changes of values (either cheating or data corruption) are still handled by exceptions (in the case where they are used).</p>



<p>The data were read from memory in order to prevent networking from influencing the tests. The data were generated by <a href="https://gist.github.com/Dugy/d3d851ab4826cc3121fc00b79cb5124d">this script</a>.</p>



<p>The result of the test was similar to previous tests – the code using exceptions for error handling was 0.8% slower than the code that aborted on error, which was within the margin of error, while the code using error codes to handle errors was 6% slower.</p>



<h2>The results</h2>



<p>The times taken by the benchmarks are summarised in the following table, scaled so that the time needed by the version that aborts when an error happens is 100%.</p>



<figure><table><thead><tr><th>Test</th><th>Abort</th><th>Exception</th><th>Error code</th></tr></thead><tbody><tr><td>Parsing</td><td>100%</td><td>100%</td><td>106.2%</td></tr><tr><td>Filling</td><td>100%</td><td>100.6%</td><td>104.2%</td></tr><tr><td>Updating</td><td>100%</td><td>100.8%</td><td>106.2%</td></tr></tbody></table></figure>



<p>The imprecision was around 1%, so the version using exceptions might not really be slightly slower and the difference might be the result of chance or some invisible compiler decisions, like inlining. The time needed by the version using error codes was consistently higher.</p>



<p>The entire source code is <a href="https://gist.github.com/Dugy/2532c810bb232b8ff1603cfa679bdf28">here</a>.</p>



<h2>Error handling and clean code</h2>



<p>When an exception is not handled in a block, the execution exits the block automatically until it finds a piece of code that can catch it. Any other type of handling does not support this and requires writing additional logic to handle the failure, although in almost all cases the appropriate reaction is to abort the operation the program is performing (the test with reading from a stream is an example where this does not apply). This can significantly lengthen the code even if the reaction to any failure in a function being called is to return the error code to the caller’s caller.</p>



<p>This is a line from the initialisation sector of a constructor in test 2:</p>



<pre data-enlighter-language="cpp" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">	animation(*source.getChild("animation")),</pre>



<p>It forwards the child XML tag called <code>animation</code> of its argument to the constructor of a member class called&nbsp;<code>animation</code>. The constructor may fail due to incorrect content of the XML tag, or <code>getChild</code> function can fail because the entire tag is missing. This aborts the creation of the structure, or some other process in the program that’s in the <code>catch</code> block.</p>



<p>If the errors …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/">https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/</a></em></p>]]>
            </description>
            <link>https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201269</guid>
            <pubDate>Tue, 24 Nov 2020 18:20:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taking Back DevOps]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25201166">thread link</a>) | @semicolon
<br/>
November 24, 2020 | https://www.opslevel.com/2020/11/18/taking-back-devops/ | <a href="https://web.archive.org/web/*/https://www.opslevel.com/2020/11/18/taking-back-devops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <h2 id="lets-get-devops-to-mean-service-ownership-again">Let’s get DevOps to mean Service Ownership again.</h2>
<h3 id="we-broke-devops-and-its-preventing-us-from-building">We broke DevOps. And it’s preventing us from building.</h3>
<p>When the first cloud providers emerged in the mid-2000s, they unlocked a new superpower: the ability to near-instantly provision hardware. Service-oriented architecture and microservices developed as a new architectural pattern. As a result, DevOps emerged as a practice to organize engineering teams around those new services - combining development and operations responsibilities onto the same team.</p>

<p>In 2006, Werner Vogels, CTO at Amazon, described DevOps as: “You build it, you run it.” Fast forward to today and DevOps is a far cry from these origins. Code is no longer deployed efficiently, and the practice of DevOps has weakened. Here’s how this happened:</p>

<h4 id="1-we-rendered-the-term-devops-meaningless">1. We rendered the term DevOps meaningless.</h4>

<p>Over the last several years, DevOps has become simultaneously a practice, a culture, a team, a job title, and a vendor product. You can hire some DevOps, buy some DevOps, adopt DevOps, and sprinkle a little bit of DevOps on top for good measure.</p>
<ul>
  <li><strong>‘DevOps’ is a team</strong>, responsible for horizontal engineering concerns like standardized CI/CD and observability.</li>
  <li><strong>‘DevOps’ is a trendy job title</strong>, merely renamed from “Operations”.</li>
  <li><strong>‘DevOps’ is a vendor product</strong>, like “Azure DevOps”, “ServiceNow Enterprise DevOps”, and “IBM DevOps”.</li>
</ul>

<h4 id="2-we-spent-way-too-much-time-debating-microservices-vs-monolith">2. We spent way too much time debating microservices vs monolith.</h4>

<p>This is the wrong debate. And it’s distracted teams from focusing on how to own and operate code efficiently. For some companies, a monolith works just fine. For others, microservices is the way to go. For many, it’s a hybrid of fat services or serverless or applications or some other mix. The more important question is: <em>How do you get your team to a place where engineers own the code they write so everyone can ship faster and safer?</em></p>

<h4 id="3-we-built-some-devops-tools-but-for-crucial-needs-were-stuck-in-spreadsheets">3. We built some DevOps tools, but for crucial needs we’re stuck in spreadsheets.</h4>

<p>DevOps tools are siloed around monitoring, logging, tracing, incident management, CI/CD, etc. But there is nothing that unifies the information from those tools to answer broad questions about production architecture. Companies with the best DevOps cultures use this set of siloed tools, but they have also spent millions of dollars to <em>build their own</em> tools and systems–everything from lists of owners to full-fledged internal tools. We’ve seen teams with:</p>
<ul>
  <li><strong>Giant wikis of services</strong> that answer basic questions about architecture, including simply who owns what.</li>
  <li><strong>Spreadsheets of services</strong> that are painstakingly created (and later tossed away) during engineering initiatives like upgrades or security improvements across a large and complex architecture.</li>
  <li>Eventually spreadsheets and wikis are thrown away and <strong>complex internal tools</strong> are created that require a lot of engineering resources to build and maintain.</li>
</ul>

<p>Building these stop-gap solutions are a huge barrier to entry; there needs to be a way for <em>all</em> teams to adopt DevOps culture.</p>

<h3 id="lets-take-back-devops">Let’s take back DevOps.</h3>
<p><strong>If we want to get back to shipping code even faster, more securely, and with less risk, we need to reset DevOps so that it’s synonymous with <em>Service Ownership</em>.</strong></p>

<p>When DevOps = Service ownership, teams get:</p>
<ul>
  <li><strong>Autonomy:</strong> Teams fully control how their systems are built and run in production. Architecture becomes less prescriptive.</li>
  <li><strong>Speed:</strong> As long as your team’s SLOs are being met, there should be nothing stopping you from shipping quickly.</li>
  <li><strong>Resiliency:</strong> Shifting reliability and security concerns to dev teams naturally increases risk, but ownership involves educating/measuring teams against critical practices so that they can still deploy with low risk.</li>
  <li><strong>Accountability:</strong> People are no longer paged because a service goes haywire - or, worse yet, has a security breach - and learn that nobody owns the service, wants to touch it, or even knows anything about it.</li>
</ul>

<p>We’ve underinvested in tools to make DevOps actually work. There’s a lot we still need to build to help engineering teams adopt service ownership and unlock the full power of DevOps.</p>

<hr>

<h3 id="opslevel-enables-service-ownership-its-the-future-of-devops">OpsLevel enables Service Ownership. It’s the future of DevOps.</h3>

<p>OpsLevel helps DevOps teams own, operate, and understand their entire production infrastructure. You can easily catalog all your services, tools, ownership, and changes, while you continuously measure and improve how you build and operate your software. Teams ship faster, with confidence.</p>

<p>Forward-thinking engineering teams at Segment, Zapier, Auth0, Convoy, Under Armour, Chegg, and more use OpsLevel to drive service ownership. <strong>We’re proud to announce we’ve raised $5M in funding led by Vertex Ventures, with participation from S28 Capital, Webb Investment Network, Union Capital, and a number of angels</strong> including:</p>
<ul>
  <li>Alex Solomon, Andrew Miklas, and Baskar Puvanathasan (founders of PagerDuty)</li>
  <li>Anne Raimondi (CCO of Guru, Board member Asana, Gusto, Patreon)</li>
  <li>Frederic Kerrest (Executive Vice Chairman, COO, and co-founder of Okta)</li>
  <li>Jean-Michel Lemieux (CTO of Shopify)</li>
  <li>Maynard Webb (ex-COO of eBay)</li>
  <li>Yuri Sagalov (co-founder of AeroFS)</li>
  <li>Evan Weaver (CTO and co-founder of Fauna)</li>
  <li>Paul Judge (co-founder of Pindrop Security)</li>
  <li>Bill Clerico (co-founder of WePay)</li>
</ul>

<p>If you’re interested in joining our mission to take back DevOps and empower cultures of service ownership, <a href="https://www.opslevel.com/careers/">check out our open roles</a>.</p>

<p><em><a href="https://www.linkedin.com/in/john-laban/">John Laban</a> and <a href="https://www.linkedin.com/in/klprose/">Ken Rose</a> are co-founders of OpsLevel. John was previously PagerDuty’s first engineer and the pair of them bring senior technical expertise from Shopify, Amazon, and more.  They’ve spent the last decade scaling engineering teams and helping them transition to DevOps and service ownership.</em></p>

                </div></div>]]>
            </description>
            <link>https://www.opslevel.com/2020/11/18/taking-back-devops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201166</guid>
            <pubDate>Tue, 24 Nov 2020 18:11:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[P² quantile estimator – estimating the median without storing values]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 41 (<a href="https://news.ycombinator.com/item?id=25201093">thread link</a>) | @ciprian_craciun
<br/>
November 24, 2020 | https://aakinshin.net/posts/p2-quantile-estimator/ | <a href="https://web.archive.org/web/*/https://aakinshin.net/posts/p2-quantile-estimator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span><time datetime="2020-11-24">November 24, 2020</time>
&nbsp;&nbsp;
<i></i>&nbsp;
<a href="https://aakinshin.net/tags/statistics/">Statistics</a>
<a href="https://aakinshin.net/tags/quantiles/">Quantiles</a>
<a href="https://aakinshin.net/tags/performance-telemetry/">Performance Telemetry</a></span></p><p>Imagine that you are implementing performance telemetry in your application.
There is an operation that is executed millions of times, and you want to get its “average” duration.
It’s not a good idea to use the arithmetic mean because the obtained value can be easily spoiled by outliers.
It’s much better to use the median which is one of the most robust ways to describe the average.</p><p>The straightforward median estimation approach requires storing all the values.
In our case, it’s a bad idea to keep all the values because it will significantly increase the memory footprint.
Such telemetry is harmful because it may become a new bottleneck instead of monitoring the actual performance.</p><p>Another way to get the median value is to use a sequential quantile estimator
(also known as an online quantile estimator or a streaming quantile estimator).
This is an algorithm that allows calculating the median value (or any other quantile value)
using a fixed amount of memory.
Of course, it provides only an approximation of the real median value,
but it’s usually enough for typical telemetry use cases.</p><p>In this post, I will show one of the simplest sequential quantile estimators that is called the P² quantile estimator
(or the Piecewise-Parabolic quantile estimator).</p><h3 id="the-p-quantile-estimator">The P² quantile estimator</h3><p>This algorithm was initially suggested in <a href="#Jain1985">[Jain1985]</a>.
Below you can find a short overview of this approach,
notes about typos in the original paper,
numerical simulation,
and a C# implementation.</p><h4 id="the-main-idea">The main idea</h4><p>Let’s say we have a stream of observations <span>\(\{ x_0, x_1, x_2, x_3, x_4, \ldots \}\)</span>
and we want to estimate p-quantile.
The suggested approach introduces five markers that correspond to the estimations of</p><ul><li><span>\(q_0\)</span>: The minimum</li><li><span>\(q_1\)</span>: The (p/2)-quantile</li><li><span>\(q_2\)</span>: The p-quantile</li><li><span>\(q_3\)</span>: The ((1+p)/2)-quantile</li><li><span>\(q_4\)</span>: The maximum</li></ul><p>The <span>\(q_i\)</span> values are known as the marker heights.</p><p>Also, we have to maintain the marker positions <span>\(\{ n_0, n_1, n_2, n_3, n_4 \}\)</span>.
These integer values describe actual marker indexes across obtained observations at the moment.</p><p>Next, we have to define the marker desired positions <span>\(\{ n'_0, n'_1, n'_2, n'_3, n'_4 \}\)</span>.
For the first <span>\(n\)</span> observations, these real values are defined as follows:</p><ul><li><span>\(n'_0 = 0\)</span></li><li><span>\(n'_1 = (n - 1) p / 2\)</span></li><li><span>\(n'_2 = (n - 1) p\)</span></li><li><span>\(n'_3 = (n - 1) (1 + p) / 2\)</span></li><li><span>\(n'_4 = (n - 1)\)</span></li></ul><p>In order to speed up the algorithm, we can precalculate increments of the desired positions which
should be added to the current values after each new observation:</p><ul><li><span>\(dn'_0 = 0\)</span></li><li><span>\(dn'_1 = p / 2\)</span></li><li><span>\(dn'_2 = (n - 1) p\)</span></li><li><span>\(dn'_3 = (n - 1) (1 + p) / 2\)</span></li><li><span>\(dn'_4 = (n - 1)\)</span></li></ul><p>Note that in the original paper, the authors use one-based indexing.
I decided to adapt it to the zero-based indexing which is more convenient from the implementation point of view.</p><h4 id="initialization">Initialization</h4><p>Once we collected the first five elements, we should perform initialization logic:</p><p><span>\[\left\{
\begin{array}{llll}
q_0 = x_{(0)}, &amp; n_0 = 0, &amp; n'_0 = 0,      &amp; dn'_0 = 0,\\
q_1 = x_{(1)}, &amp; n_1 = 1, &amp; n'_1 = 2p,     &amp; dn'_1 = p/2,\\
q_2 = x_{(2)}, &amp; n_2 = 2, &amp; n'_2 = 4p,     &amp; dn'_2 = p,\\
q_3 = x_{(3)}, &amp; n_3 = 3, &amp; n'_3 = 2 + 2p, &amp; dn'_3 = (1+p)/2,\\
q_4 = x_{(4)}, &amp; n_4 = 4, &amp; n'_4 = 4,      &amp; dn'_4 = 1.
\end{array}
\right.
\]</span></p><h4 id="marker-invalidation">Marker invalidation</h4><p>For each <span>\(x_j\)</span> for <span>\(j \geq 5\)</span>, we should invalidate our markers.</p><p>Firstly, we should adjust extreme marker heights
(if <span>\(x_j &lt; q_0\)</span>, we should update <span>\(q_0\)</span>; if <span>\(x_j &gt; q_4\)</span>, we should update <span>\(q_4\)</span>) and
find <span>\(k\)</span> such that <span>\(q_k \leq x_j &lt; q_{k+1}\)</span>
(or <span>\(q_k \leq x_j \leq q_{k+1}\)</span> for <span>\(k=3\)</span>):</p><table><thead><tr><th>Condition</th><th><span>\(q_i\)</span> update</th><th>k</th></tr></thead><tbody><tr><td><span>\(\phantom{q_0 \leq~} x_j &lt; q_0\)</span></td><td><span>\(q_0 = x_j\)</span></td><td>0</td></tr><tr><td><span>\(q_0 \leq x_j &lt; q_1\)</span></td><td></td><td>0</td></tr><tr><td><span>\(q_1 \leq x_j &lt; q_2\)</span></td><td></td><td>1</td></tr><tr><td><span>\(q_2 \leq x_j &lt; q_3\)</span></td><td></td><td>2</td></tr><tr><td><span>\(q_3 \leq x_j &lt; q_4\)</span></td><td></td><td>3</td></tr><tr><td><span>\(q_4 \leq x_j\)</span></td><td><span>\(q_4 = x_j\)</span></td><td>3</td></tr></tbody></table><p>Secondly, we should update the marker positions and the marker desired positions:</p><p><span>\[\begin{array}{lcl}
n_i = n_i + 1 &amp; \textrm{for} &amp; i = k + 1, \ldots, 4; \\
n'_i = n'_i + dn'_i &amp; \textrm{for} &amp; i = 0, \ldots, 4. \\
\end{array}
\]</span></p><p>Finally, we should adjust non-extreme marker heights (<span>\(q_i\)</span>) and positions (<span>\(n_i\)</span>) for <span>\(i \in \{ 1, 2, 3\} \)</span>
in the following way:</p><div><pre><code data-lang="cs"><span>for</span> <span>(</span><span>i</span> <span>=</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>3</span><span>;</span> <span>i</span><span>++)</span>
<span>{</span>
    <span>d</span> <span>=</span> <span>nꞌ</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span>
    <span>if</span> <span>(</span><span>d</span> <span>&gt;=</span>  <span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&gt;</span>  <span>1</span> <span>||</span>
        <span>d</span> <span>&lt;=</span> <span>-</span><span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&lt;</span> <span>-</span><span>1</span><span>)</span>
    <span>{</span>
        <span>d</span> <span>=</span> <span>sign</span><span>(</span><span>d</span><span>)</span>
        <span>qꞌ</span> <span>=</span> <span>Parabolic</span><span>(</span><span>i</span><span>,</span> <span>d</span><span>)</span>
        <span>if</span> <span>(!(</span><span>q</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>&lt;</span> <span>qꞌ</span> <span>&amp;&amp;</span> <span>qꞌ</span> <span>&lt;</span> <span>q</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]))</span>
            <span>qꞌ</span> <span>=</span> <span>Linear</span><span>(</span><span>i</span><span>,</span> <span>d</span><span>)</span>
        <span>q</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>qꞌ</span>
        <span>n</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>d</span>
    <span>}</span>
<span>}</span>
</code></pre></div><p>The core equation of the algorithm is a piecewise-parabolic prediction (P²) formula
that adjusts marker heights for each observation:</p><p><span>\[q'_i = q_i + \dfrac{d}{n_{i+1}-n_{i-1}} \cdot
\Bigg(
(n_i-n_{i-1}+d)\dfrac{q_{i+1}-q_i}{n_{i+1}-n_i} +
(n_{i+1}-n_i-d)\dfrac{q_i-q_{i-1}}{n_i-n_{i-1}}
\Bigg).
\]</span></p><p>Once we calculated <span>\(q'_i\)</span>, we should check that <span>\(q_{i-1} &lt; q'_i &lt; q_{i+1}\)</span>.
If this condition is false, we should ignore the parabolic prediction and use the linear prediction instead:</p><p><span>\[q'_i = q_i + d \dfrac{q_{i+d}-q_i}{n_{i+d}-n_{i}}.
\]</span></p><h4 id="the-result">The result</h4><p>Once you need the requested quantile estimation value, we should just take the value of <span>\(q_2\)</span>.</p><h4 id="typos-in-the-original-paper">Typos in the original paper</h4><p>A find a few typos in the original paper which may confuse readers who want to implement the algorithm from scratch:</p><ul><li>Page 1079, Box 1, B2:
<code>$i = k, \ldots, 5$</code>
should be replaced by
<code>$i = k + 1, \ldots, 5$</code></li><li>Page 1079, Box 1, B3:
<code>$\textbf{THEN}\; q_i \leftarrow q_i$</code>
should be replaced by
<code>$\textbf{THEN}\; q_i \leftarrow q'_i$</code></li></ul><h3 id="numerical-simulation">Numerical simulation</h3><p>It’s time to check how it works.
I decided to visualize sequential values of the following quantiles estimator:</p><ul><li><strong>The P² quantile estimator</strong><br>A sequential estimator that is described above.</li><li><strong>The Type 7 quantile estimator</strong><br>It’s the most popular quantile estimator which is used by default in
R, Julia, NumPy, Excel (<code>PERCENTILE</code>, <code>PERCENTILE.INC</code>), Python (<code>inclusive</code> method).
We call it “Type 7” according to notation from <a href="#Hyndman1996">[Hyndman1996]</a>,
where Rob J. Hyndman and Yanan Fan described nine quantile algorithms which are used in statistical computer packages.</li><li><strong>The Harrell-Davis quantile estimator</strong><br>It’s my favorite option in real life for non-sequential cases because
it’s more robust than classic quantile estimators based on linear interpolation,
and it provides more reliable estimations on small samples.
This quantile estimator is described in <a href="#Harrell1982">[Harrell1982]</a>.</li><li><strong>Actual</strong><br>The true median value which is taken from the underlying distribution.</li></ul><p>Below, you can find several plots for the following distributions:</p><ul><li><strong>Normal distribution</strong> <span>\(\mathcal{N}(0, 1)\)</span></li><li><strong>Gumbel distribution</strong> for <span>\(\mu = 0, \beta = 1\)</span></li><li><strong>Beta distribution</strong> <span>\(\textrm{Beta}(10, 2)\)</span></li><li><strong>Uniform distribution</strong> <span>\(\mathcal{U}(0, 1)\)</span></li><li><strong>Bimodal distribution</strong> (mixture of <span>\(\mathcal{N}(10, 1)\)</span> and <span>\(\mathcal{N}(20, 1)\)</span>)</li></ul><p>Here are the results:</p><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-light.svg" target="_blank" alt="normal"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-light.svg" target="_blank" alt="gumbel"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-light.svg" target="_blank" alt="beta"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-light.svg" target="_blank" alt="uniform"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-light.svg" target="_blank" alt="bimodal"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-light.svg"></picture></a></div></div><p>As you can see, The P² quantile estimator produces reasonable median estimates.
I also checked how it works on a considerable number of real data sets and
I’m pretty satisfied with the results.
You can also find a discussion about accuracy and the equation for the mean squared error in the original paper.</p><h3 id="reference-implementation">Reference implementation</h3><p>Below you can find a C# implementation of the discussed algorithm.
Also, you can use it via
the latest nightly version (0.3.0-nightly.64+) of <a href="https://github.com/AndreyAkinshin/perfolizer">perfolizer</a>.</p><div><pre><code data-lang="cs"><span>public</span> <span>class</span> <span>P2QuantileEstimator</span>
<span>{</span>
    <span>private</span> <span>readonly</span> <span>double</span> <span>p</span><span>;</span>
    <span>private</span> <span>readonly</span> <span>int</span><span>[]</span> <span>n</span> <span>=</span> <span>new</span> <span>int</span><span>[</span><span>5</span><span>];</span> <span>// marker positions
</span><span></span>    <span>private</span> <span>readonly</span> <span>double</span><span>[]</span> <span>ns</span> <span>=</span> <span>new</span> <span>double</span><span>[</span><span>5</span><span>];</span> <span>// desired marker positions
</span><span></span>    <span>private</span> <span>readonly</span> <span>double</span><span>[]</span> <span>dns</span> <span>=</span> <span>new</span> <span>double</span><span>[</span><span>5</span><span>];</span>
    <span>private</span> <span>readonly</span> <span>double</span><span>[]</span> <span>q</span> <span>=</span> <span>new</span> <span>double</span><span>[</span><span>5</span><span>];</span> <span>// marker heights
</span><span></span>    <span>private</span> <span>int</span> <span>count</span><span>;</span>

    <span>public</span> <span>P2QuantileEstimator</span><span>(</span><span>double</span> <span>p</span><span>)</span>
    <span>{</span>
        <span>p</span> <span>=</span> <span>probability</span><span>;</span>
    <span>}</span>

    <span>public</span> <span>void</span> <span>AddValue</span><span>(</span><span>double</span> <span>x</span><span>)</span>
    <span>{</span>
        <span>if</span> <span>(</span><span>count</span> <span>&lt;</span> <span>5</span><span>)</span>
        <span>{</span>
            <span>q</span><span>[</span><span>count</span><span>++]</span> <span>=</span> <span>x</span><span>;</span>
            <span>if</span> <span>(</span><span>count</span> <span>==</span> <span>5</span><span>)</span>
            <span>{</span>
                <span>Array</span><span>.</span><span>Sort</span><span>(</span><span>q</span><span>);</span>

                <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>5</span><span>;</span> <span>i</span><span>++)</span>
                    <span>n</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>i</span><span>;</span>

                <span>ns</span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>0</span><span>;</span>
                <span>ns</span><span>[</span><span>1</span><span>]</span> <span>=</span> <span>2</span> <span>*</span> <span>p</span><span>;</span>
                <span>ns</span><span>[</span><span>2</span><span>]</span> <span>=</span> <span>4</span> <span>*</span> <span>p</span><span>;</span>
                <span>ns</span><span>[</span><span>3</span><span>]</span> <span>=</span> <span>2</span> <span>+</span> <span>2</span> <span>*</span> <span>p</span><span>;</span>
                <span>ns</span><span>[</span><span>4</span><span>]</span> <span>=</span> <span>4</span><span>;</span>

                <span>dns</span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>0</span><span>;</span>
                <span>dns</span><span>[</span><span>1</span><span>]</span> <span>=</span> <span>p</span> <span>/</span> <span>2</span><span>;</span>
                <span>dns</span><span>[</span><span>2</span><span>]</span> <span>=</span> <span>p</span><span>;</span>
                <span>dns</span><span>[</span><span>3</span><span>]</span> <span>=</span> <span>(</span><span>1</span> <span>+</span> <span>p</span><span>)</span> <span>/</span> <span>2</span><span>;</span>
                <span>dns</span><span>[</span><span>4</span><span>]</span> <span>=</span> <span>1</span><span>;</span>
            <span>}</span>

            <span>return</span><span>;</span>
        <span>}</span>

        <span>int</span> <span>k</span><span>;</span>
        <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>0</span><span>])</span>
        <span>{</span>
            <span>q</span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>x</span><span>;</span>
            <span>k</span> <span>=</span> <span>0</span><span>;</span>
        <span>}</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>1</span><span>])</span>
            <span>k</span> <span>=</span> <span>0</span><span>;</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>2</span><span>])</span>
            <span>k</span> <span>=</span> <span>1</span><span>;</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>3</span><span>])</span>
            <span>k</span> <span>=</span> <span>2</span><span>;</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>4</span><span>])</span>
            <span>k</span> <span>=</span> <span>3</span><span>;</span>
        <span>else</span>
        <span>{</span>
            <span>q</span><span>[</span><span>4</span><span>]</span> <span>=</span> <span>x</span><span>;</span>
            <span>k</span> <span>=</span> <span>3</span><span>;</span>
        <span>}</span>

        <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>k</span> <span>+</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;</span> <span>5</span><span>;</span> <span>i</span><span>++)</span>
            <span>n</span><span>[</span><span>i</span><span>]++;</span>
        <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>5</span><span>;</span> <span>i</span><span>++)</span>
            <span>ns</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>dns</span><span>[</span><span>i</span><span>];</span>

        <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>3</span><span>;</span> <span>i</span><span>++)</span>
        <span>{</span>
            <span>double</span> <span>d</span> <span>=</span> <span>ns</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>];</span>
            <span>if</span> <span>(</span><span>d</span> <span>&gt;=</span> <span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&gt;</span> <span>1</span> <span>||</span> <span>d</span> <span>&lt;=</span> <span>-</span><span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&lt;</span> <span>-</span><span>1</span><span>)</span>
            <span>{</span>
                <span>int</span> <span>dInt</span> <span>=</span> <span>Math</span><span>.</span><span>Sign</span><span>(</span><span>d</span><span>);</span>
                <span>double</span> <span>qs</span> <span>=</span> <span>Parabolic</span><span>(</span><span>i</span><span>,</span> <span>dInt</span><span>);</span>
                <span>if</span> <span>(</span><span>q</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>&lt;</span> <span>qs</span> <span>&amp;&amp;</span> <span>qs</span> <span>&lt;</span> <span>q</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>])</span>
                    <span>q</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>qs</span><span>;</span>
                <span>else</span>
                    <span>q</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>Linear</span><span>(</span><span>i</span><span>,</span> <span>dInt</span><span>);</span>
                <span>n</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>dInt</span><span>;</span>
            <span>}</span>
        <span>}</span>

        <span>count</span><span>++;</span>
    <span>}</span>
    
    <span>private</span> <span>double</span> <span>Parabolic</span><span>(</span><span>int</span> <span>i</span><span>,</span> <span>double</span> <span>d</span><span>)</span>
    <span>{</span>
        <span>return</span> <span>q</span><span>[</span><span>i</span><span>]</span> <span>+</span> <span>d</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>])</span> <span>*</span> <span>(</span>
            <span>(</span><span>n</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>+</span> <span>d</span><span>)</span> <span>*</span> <span>(</span><span>q</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>q</span><span>[</span><span>i</span><span>])</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>])</span> <span>+</span>
            <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>d</span><span>)</span> <span>*</span> <span>(</span><span>q</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>q</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>])</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>])</span>
        <span>);</span>
    <span>}</span>

    <span>private</span> <span>double</span> <span>Linear</span><span>(</span><span>int</span> <span>i</span><span>,</span> <span>int</span> <span>d</span><span>)</span>
    <span>{</span>
        <span>return</span> <span>q</span><span>[</span><span>i</span><span>]</span> <span>+</span> <span>d</span> <span>*</span> <span>(</span><span>q</span><span>[</span><span>i</span> <span>+</span> <span>d</span><span>]</span> <span>-</span> <span>q</span><span>[</span><span>i</span><span>])</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>d</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]);</span>
    <span>}</span>

    <span>public</span> <span>double</span> <span>GetQuantile</span><span>()</span>
    <span>{</span>
        <span>if</span> <span>(</span><span>count</span> <span>&lt;=</span> <span>5</span><span>)</span>
        <span>{</span>
            <span>Array</span><span>.</span><span>Sort</span><span>(</span><span>q</span><span>,</span> <span>0</span><span>,</span> <span>count</span><span>);</span>
            <span>int</span> <span>index</span> <span>=</span> <span>(</span><span>int</span><span>)</span> <span>Math</span><span>.</span><span>Round</span><span>((</span><span>count</span> <span>-</span> <span>1</span><span>)</span> <span>*</span> <span>p</span><span>);</span>
            <span>return</span> <span>q</span><span>[</span><span>index</span><span>];</span>
        <span>}</span>

        <span>return</span> <span>q</span><span>[</span><span>2</span><span>];</span>
    <span>}</span>
<span>}</span>
</code></pre></div><h3 id="conclusion">Conclusion</h3><p>The P² quantile estimator allows estimating quantile values on a stream of numbers without storing individual …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aakinshin.net/posts/p2-quantile-estimator/">https://aakinshin.net/posts/p2-quantile-estimator/</a></em></p>]]>
            </description>
            <link>https://aakinshin.net/posts/p2-quantile-estimator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201093</guid>
            <pubDate>Tue, 24 Nov 2020 18:06:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to layer sales onto a bottom-up self-serve product]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25200913">thread link</a>) | @jcs87
<br/>
November 24, 2020 | https://www.lennyrachitsky.com/p/sales-bottom-up | <a href="https://web.archive.org/web/*/https://www.lennyrachitsky.com/p/sales-bottom-up">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>👋 Hello, I’m&nbsp;<a href="https://twitter.com/lennysan">Lenny</a>&nbsp;and welcome to a ✨&nbsp;<strong>once-a-month-free-edition&nbsp;</strong>✨ of my newsletter. Each week I humbly tackle reader questions about product, growth, working with humans, and anything else that’s stressing them out at the office.</em></p><p><em>If you’re not a paid subscriber, here’s what you missed this month:</em></p><ol><li><p><a href="https://www.lennyrachitsky.com/p/magical-growth-loops">Magical growth loops</a></p></li><li><p><a href="https://www.lennyrachitsky.com/p/managing-up">How to manage up</a></p></li><li><p><a href="https://www.lennyrachitsky.com/p/product-management-startup-big-company">Startup PM vs. big company PM</a></p></li></ol><blockquote><h2>Q: I have a self-serve bottom-up SaaS product, and I'm trying to decide if, when, and how I should hire my first full-time salesperson.</h2></blockquote><p>One of the most surprising takeaways from <a href="https://www.lennyrachitsky.com/p/how-todays-fastest-growing-b2b-businesses-b11">my research into early B2B growth</a> was that <strong>100% of the bottom-up B2B companies ended up layering on a sales team</strong>. It’s rarely a question of if — it’s a question of when, and how.</p><p>Since I don’t have a lot of depth in sales myself, I went straight to my go-to person for all things sales: <a href="https://twitter.com/Kazanjy">Pete Kazanjy</a>. If you don’t know of Pete, he wrote <a href="https://www.foundingsales.com/">THE book on startup sales</a>, which he recently released as a physical book. This tweet was not an exaggeration:</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F7c5ce225-1f4f-47eb-afe6-1da59ed276f5_1190x756.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F7c5ce225-1f4f-47eb-afe6-1da59ed276f5_1190x756.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/7c5ce225-1f4f-47eb-afe6-1da59ed276f5_1190x756.png&quot;,&quot;height&quot;:756,&quot;width&quot;:1190,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1236090,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>Pete generously agreed to write a guest post, and unsurprisingly, <strong>below you’ll find the most in-depth and tactical guide for adding sales into your org. </strong>Including<strong>:</strong></p><ol><li><p>Should I start with a self-serve product?</p></li><li><p>Should I ever involve salespeople?</p></li><li><p>When should I add a salesperson to the mix?</p></li><li><p>How do I set myself up for success during The Transition?</p></li><li><p>Common pitfalls to avoid</p></li></ol><p>Let’s dive in!</p><p><em>A bit more about Pete: In addition to authoring <a href="https://www.foundingsales.com/">Founding Sales</a>, Pete Kazanjy is also the founder of <a href="https://www.atriumhq.com/">Atrium</a>, makers of <a href="https://www.atriumhq.com/">data-driven management software for sales teams</a>, and founder of <a href="https://modernsaleshq.com/">Modern Sales</a> (the world’s largest peer-education community for sales operations and leadership professionals). He previously started and sold TalentBin (a recruiting software startup) to Monster Worldwide. You can find him on <a href="https://twitter.com/Kazanjy">Twitter</a> and <a href="https://www.linkedin.com/in/kazanjy/">LinkedIn</a>.</em></p><h2><strong>The Transition: </strong>Layering Sales onto a Bottom-Up Self-Serve Product</h2><p><em>By Pete Kazanjy</em></p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F91b85976-c55f-4f8a-9d16-2b3807f40e6a_2150x1171.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F91b85976-c55f-4f8a-9d16-2b3807f40e6a_2150x1171.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/91b85976-c55f-4f8a-9d16-2b3807f40e6a_2150x1171.png&quot;,&quot;height&quot;:793,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:180377,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>“Bottom-up” (or “product-led”) B2B growth is a hot topic in early-stage circles these days, and it makes sense why. A self-serve (“easy-in”) entry motion, that’s later combined with a strong direct sales motion, can make for explosive revenue growth as shown by IPO’d exemplars Zoom, Slack, Datadog, and private market dynamos like Airtable, Figma, and others. The combination of bottom-up self-serve plus direct sales can simultaneously lower CACs and power larger contract values (with expansion into enterprise contracts). This would never be possible in a pure self-serve model.</p><p><strong>The crux of this article is that waiting too long to add sales-involvement often leads to a large opportunity cost.</strong> Many successful self-serve applications saw their market position usurped by competitors who adopted a sales-assisted motion and effectively firewalled the self-serve-only products out of lucrative enterprise segments (e.g. Dropbox).</p><p>Below, I’ll help you understand if layering in sales is right for your business, when to take the leap, and how to navigate this critical transition successfully:</p><h2>First of all, should I even start with a self-serve product?</h2><p>Self-serve has a lot going for it, but it’s not necessarily a slam dunk decision for every product. Below are four questions to take into consideration before building a self-serve product (many of which can be answered before you launch):</p><h4><strong>1. Is the product simple enough for self-serve?&nbsp;</strong></h4><p>Successful self-service is about allowing a user to get to success and have that “aha” activation moment on their own. So the question that follows from this is how easy is it for users to get to that <em>aha</em> moment? Zoom is not complicated. Send someone a link or join someone’s link, and boom, you’re talking to them. Dropbox is pretty straight forward – download this client, and tell it what folders to sync. Airtable is a bit more advanced, but you can start simple, and they’ve invested heavily in a content catalog of templates and recipes to allow for self-served advancement.</p><p>Note, “complexity” is audience contingent. Tableau is not an easy product to use by any stretch of the imagination, but it’s self-serviceable by the technical data analysts for whom it was designed, and as such started self-serve with a desktop client download. Similarly, Stripe, Datadog, Twilio, New Relic, and other developer tools have all started self-serve, in that their technical audience has the capacity to self-serve even these more involved products. Some offerings are really just too complex to start self-serve, such as enterprise-grade marketing automation platforms like <a href="https://www.marketo.com/">Marketo</a>,&nbsp; and software targeting massive financial enterprises like <a href="https://blend.com/">Blend</a>.</p><h4><strong>2. Is this truly new and differentiated?&nbsp;</strong></h4><p>If your offering is truly new and differentiated, self-serve can be fantastic. When <a href="https://www.yesware.com/">Yesware</a> and <a href="https://www.mixmax.com/">Mixmax</a> first launched, most organizations didn’t have any sort of sales engagement email offerings for their salespeople. The notion of sending someone a link to a public calendar with which to book time was crazy talk when <a href="https://calendly.com/">Calendly</a> first launched. Software that proactively monitors your revenue stack’s automations and linkages for errors has never existed, which is why <a href="https://seesonar.com/">Sonar</a> can be self-serviced by sales and marketing operations staff. Personal business cloud app search has never existed before, and thus there’s no reason for a given user in an organization to not download and give <a href="https://getcommande.com/">Command E</a> a try.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8bdaeb77-d849-4833-aeb9-3add8098b57c_1017x574.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8bdaeb77-d849-4833-aeb9-3add8098b57c_1017x574.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/8bdaeb77-d849-4833-aeb9-3add8098b57c_1017x574.png&quot;,&quot;height&quot;:574,&quot;width&quot;:1017,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><h4><strong>3. Can this co-exist with a (less good) incumbent in a given company’s stack?</strong></h4><p>Conversely, if your offering can coexist alongside inferior incumbents, self-serve can also work. Most organizations where Slack was adopted early-on already had Gmail and thus GChat. Organizations that start using <a href="https://www.getguru.com/">Guru</a> may have antiquated knowledge bases in Sharepoint or in Confluence wikis. This is where my company, <a href="https://www.atriumhq.com/">Atrium</a> lives. Customers will frequently have legacy analytics infrastructure, like Tableau or Looker, in place, but its complexity underserves the needs of the sales organization, leaving open an opportunity for Atrium to enable data-driven management for sales managers and sales operations staff in a way they’re currently not doing. Tableau and Looker still end up existing in the organization, but for more advanced analytics run by a data or analytics team.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4948801-3ec0-4078-9e3e-ef583adfe8d8_1017x575.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4948801-3ec0-4078-9e3e-ef583adfe8d8_1017x575.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/a4948801-3ec0-4078-9e3e-ef583adfe8d8_1017x575.png&quot;,&quot;height&quot;:575,&quot;width&quot;:1017,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>By contrast, an “end to end” offering like a Human Resource Information System (e.g. Workday) or email sending platforms (e.g. Iterable) are not something you have “two of” in an organization. As such, even though <a href="https://www.saplinghr.com/">Sapling</a> makes delightful modern HRIS software, they don’t have a self-serve offering. <a href="https://iterable.com/">Iterable</a> makes great, modern customer engagement software, but it’s highly unlikely an organization would run a legacy system like <a href="https://www.oracle.com/cx/marketing/campaign-management/">Responsys</a> and Iterable side by side. Self-serve would likely not work for them.&nbsp;</p><h4><strong>4. Will you focus on small organizations?</strong></h4><p>If none of the above apply, you can still target smaller orgs that have not yet adopted a legacy provider with a self-service offering. <a href="https://stripe.com/">Stripe</a> is a great example here. Payments providers already existed when Stripe first came on the scene, so it was less likely for a mature e-commerce provider with an existing payments provider to switch to a new upstart. But because legacy providers were clunky with poorly documented APIs, Stripe was the obvious choice for new internet businesses who didn’t yet have a payments provider.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F57067d98-1583-4066-9827-5d27fffba73e_1012x569.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F57067d98-1583-4066-9827-5d27fffba73e_1012x569.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/57067d98-1583-4066-9827-5d27fffba73e_1012x569.png&quot;,&quot;height&quot;:569,&quot;width&quot;:1012,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p><a href="https://www.revops.io/">RevOps</a> makes fantastic quoting software for sales organizations that can be self-setup, but there’s no way anyone who already has Salesforce CPQ or Apttus is going to switch over to them. But for a 10 person sales organization that wants to systemize the creation of quotes and sending proposals, the idea of solving that problem in less than 5 minutes (rather than 3 months, like a standard Salesforce CPQ deployment) is really attractive. Which is why self-serve works for RevOps, specifically targeting this down-market segment.</p><h2><strong>Should I</strong> ever involve salespeople?&nbsp;</h2><p>Once you’ve determined whether self-serve is right for you, growth is going well, and you’re on your merry way (i.e. people are self-serving, getting to “aha”, transacting, and retaining), the next question would be “OK, well, should we get some salespeople involved here?” Well, that depends.</p><p>There are two primary reasons to add salespeople to a self-serve commercial motion:</p><ol><li><p>To facilitate the <strong>penetration or expansion</strong> of your solution into an organization where it has an initial foothold, and/or&nbsp;</p></li><li><p>To help <strong>raise conversion</strong> rates of your self-serve offer&nbsp;</p></li></ol><p>It turns out, humans are <em>really<strong> </strong></em>helpful when it comes to smoothing over weird edge cases, communicating complicated concepts, and persuading other people to surmount their inertia and try a new thing. They’re good at, you know, selling! But there’s a downside. Humans are expensive, and can only do so many tasks in a given amount of time - as compared to software which, once written, is really cheap to run, and can be scaled up to do as many tasks as you like. </p><p>So the question of “should I add sales to the mix?” is one of “will it help?” and “will the juice be worth the squeeze?”</p><h4><strong>1. Facilitating the penetration or expansion into an organization</strong></h4><p>This is the approach Slack and Zoom’s early sales motions helped with. It <em>wasn’t</em> about a salesperson showing up to an organization and saying “Hi, you need intra-organizational communication assistance, you should check out Slack.” Rather, teams within organizations might start using Slack to communicate amongst themselves, and the addition of an “Account Manager” (psssst...it’s a salesperson) helped unify those various pods into a single contract, while potentially adding more pods, was powerful. Similarly, in a more “single-player” offering, like <a href="https://getcommande.com/">Command E</a>, a handful of sales people in a 200 person sales organization might start using it to search their Salesforce opportunities, their Google Docs, and their Gmail, but a “Customer Success Specialist” (psssst...it’s a salesperson) offering to “give a personalized tour to the rest of the sales organization” could also be quite powerful (for expansion).</p><h4><strong>2. Helping with conversion</strong></h4><p>Sometimes even supposedly simplistic offerings …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lennyrachitsky.com/p/sales-bottom-up">https://www.lennyrachitsky.com/p/sales-bottom-up</a></em></p>]]>
            </description>
            <link>https://www.lennyrachitsky.com/p/sales-bottom-up</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200913</guid>
            <pubDate>Tue, 24 Nov 2020 17:50:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How do people find bugs?]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25200893">thread link</a>) | @bitwizzle
<br/>
November 24, 2020 | https://cryptologie.net/article/511/how-do-people-find-bugs/ | <a href="https://web.archive.org/web/*/https://cryptologie.net/article/511/how-do-people-find-bugs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>You might wonder how people find bugs. Low-hanging fruit bugs can be found via code review, static analysis, dynamic analysis (like fuzzing), and other techniques. But what about deep logic bugs. Those you can’t find easily. Perhaps the protocol implemented is quite complicated, or correctness is hard to define, and edge-cases hard to detect. One thing I’ve noticed is that re-visiting protocols are an excellent way to find logic bugs.</p>
<p>Ian Miers once said something like that: "you need time, expertise, and meaningful engagement”. I like that sentence, although one can point out that these traits are closely linked--you can’t have meaningful engagement without time and expertise--it does show that finding bugs take "effort".</p>
<p>OK. Meaningful engagement can lead to meaningful bugs, and meaningful bugs can be found at different levels.
So you're here, seating in your undies in the dark, with a beer on your side and some uber eats lying on the floor.
Your computer is staring back at you, blinking at a frequency you can't notice, and waiting for you to find a bug in this protocol.
What do you do?
Perhaps the protocol doesn't have a proof, and this leads you to wonder if you can write one for it...</p>
<p>It worked for Ariel Gabizon, who in 2018 <a href="https://electriccoin.co/blog/zcash-counterfeiting-vulnerability-successfully-remediated/">found a subtle error</a> in a <a href="https://eprint.iacr.org/2013/879">2013 zk-SNARK paper</a> used by the Zcash cryptocurrency he was working on.
He found it by trying to write a proof for the paper he was reading, realizing that the authors had winged it.
While protocols back in the days could afford to wing it, these days people are more difficult--they demand proofs.
The bug Ariel found could have allowed anyone to forge an unlimited amount of money undetected.
It was silently fixed months later in an upgrade to the network.</p>
<blockquote>
<p>Ariel Gabizon, a cryptographer employed by the Zcash Company at the time of discovery, uncovered a soundness vulnerability. The key generation procedure of [BCTV14], in step 3, produces various elements that are the result of evaluating polynomials related to the statement being proven. Some of these elements are unused by the prover and were included by mistake; but their presence allows a cheating prover to circumvent a consistency check, and thereby transform the proof of one statement into a valid-looking proof of a different statement. This breaks the soundness of the proving system.</p>
</blockquote>
<p>What if the protocol already had a proof though?
Well that doesn't mean much, people enjoy writing unintelligible proofs, and people make errors in proofs all the time.
So the second idea is that reading and trying to understand a proof might lead to a bug in the proof.
Here's some meaningful engagement for you.</p>
<p>In 2001, Shoup revisited some proofs and <a href="https://eprint.iacr.org/2000/060.pdf">found some darning gaps in the proofs for RSA-OAEP</a>, leading to a newer scheme OAEP+ which was never adopted in practice.
Because back then, as I said, we really didn't care about proofs.</p>
<blockquote>
<p>[BR94] contains a valid proof that OAEP satisfies a certain technical property which they call “plaintext awareness.” Let us call this property PA1. However, it is claimed without proof that PA1 implies security against chosen ciphertext attack and non-malleability. Moreover, it is not even clear if the authors mean adaptive chosen ciphertext attack (as in [RS91]) or indifferent (a.k.a. lunchtime) chosen ciphertext attack (as in [NY90]).</p>
</blockquote>
<p>Later in 2018, a series of discoveries on the proofs for the OCB2 block cipher quickly led to <a href="https://eprint.iacr.org/2019/311">practical attacks breaking the cipher</a>.</p>
<blockquote>
<p>We have presented practical forgery and decryption attacks against OCB2, a high-profile ISO-standard authenticated encryption scheme. This was possible due to the discrepancy between the proof of OCB2 and the actual construction, in particular the interpretation of OCB2 as a mode of a TBC which combines XEX and XE.</p>
</blockquote>
<blockquote>
<p>We comment that, due to errors in proofs, ‘provably-secure schemes’ sometimes still can be broken, or schemes remain secure but nevertheless the proofs need to be fixed. Even if we limit our focus to AE, we have many examples for this, such as NSA’s Dual CTR [37,11], EAX-prime [28], GCM [22], and some of the CAESAR submissions [30,10,40]. We believe our work emphasizes the need for quality of security proofs, and their active verification.</p>
</blockquote>
<p>Now, reading and verifying a proof is always a good idea, but it’s slow, it’s not flexible (if you change the protocol, good job changing the proof), and it’s limited (you might want to prove different things re-using parts of the proofs, which is not straight forward).
Today, we are starting to bridge the gap between pen and paper proofs and computer science: it is called formal verification.
And indeed, formal verification is booming, with a number of papers in the recent years finding issues here and there just by describing protocols in a formal language and verifying that they withstand different types of attacks.</p>
<p><a href="https://eprint.iacr.org/2019/526">Prime, Order Please! Revisiting Small Subgroup and Invalid Curve Attacks on Protocols using Diffie-Hellman</a>:</p>
<blockquote>
<p>We implement our improved models in the Tamarin prover. We find a new attack on the Secure Scuttlebutt Gossip protocol, independently discover a recent attack on Tendermint’s secure handshake, and evaluate the effectiveness of the proposed mitigations for recent Bluetooth attacks.</p>
</blockquote>
<p><a href="https://eprint.iacr.org/2019/779">Seems Legit: Automated Analysis of Subtle Attacks on Protocols that Use Signatures</a>:</p>
<blockquote>
<p>We implement our models in the Tamarin Prover, yielding the first way to perform these analyses automatically, and validate them on several case studies. In the process, we find new attacks on DRKey and SOAP’s WS-Security, both protocols which were previously proven secure in traditional symbolic models.</p>
</blockquote>
<p><img alt="tamarin" src="https://cryptologie.net/upload/tamarin-obseq-lemma-attack.jpg"></p>
<p>But even this kind of techniques has limitation! (OMG David when will you stop?)</p>
<p>In 2017 <a href="https://blog.cryptographyengineering.com/2017/10/16/falling-through-the-kracks/">Matthew Green wrote</a>: </p>
<blockquote>
<p>I don’t want to spend much time talking about KRACK itself, because the vulnerability is pretty straightforward. Instead, I want to talk about&nbsp;why&nbsp;this vulnerability continues to exist so many years after WPA was standardized. And separately, to answer a question: how did this attack slip through, despite the fact that the 802.11i handshake was&nbsp;formally proven secure?</p>
</blockquote>
<p>He later writes:</p>
<blockquote>
<p>The critical problem is that while people looked closely at the two components — handshake and encryption protocol —&nbsp;in isolation, apparently nobody looked closely at the two components as they were connected together. I’m pretty sure there’s an entire&nbsp;geek meme&nbsp;about this.</p>
</blockquote>
<p>pointing to the "2 unit tests. 0 integration tests." joke.</p>
<p><img alt="meme" src="https://cryptologie.net/upload/ezgif-3-a0aa048a0c79.gif"></p>
<p>He then recognizes that it’s a hard problem:</p>
<blockquote>
<p>Of course, the reason nobody looked closely at this stuff is that doing so is just&nbsp;plain&nbsp;hard. Protocols have an exponential number of possible cases to analyze, and we’re just about at the limit of the complexity of protocols that human beings can truly reason about, or that peer-reviewers can verify. The more pieces you add to the mix, the worse this problem gets.
In the end we all know that the answer is for humans to stop doing this work. We need machine-assisted verification of protocols, preferably tied to the&nbsp;actual source code that implements them. This would ensure that the protocol actually does what it says, and that implementers don’t further screw it up, thus invalidating the security proof.</p>
</blockquote>
<p>Well, Matthew, we do have formally generated code! <a href="https://hacl-star.github.io/">HACL*</a> and <a href="http://adam.chlipala.net/papers/FiatCryptoSP19/FiatCryptoSP19.pdf">fiat-crypto</a> are two examples.
Anybody has heard of that failing? I’d be interested…</p>
<p>In any case, what’s left for us? A lot! Formally generated code is hard, and generally covers small parts of your protocol (e.g. field arithmetic for elliptic curves).
So what else can we do?
Implementing the protocol, if it hasn’t been implemented before, is a no-brainer.
In 2016, Taylor Hornby an engineer at Zcash <a href="https://electriccoin.co/blog/fixing-zcash-vulns/">wrote about a bug he found</a> while implementing the zerocash paper into the Zcash cryptocurrency:</p>
<blockquote>
<p>In this blog post, we report on the security issues we’ve found in the Zcash protocol while preparing to deploy it as an open, permissionless financial system.
Had we launched Zcash without finding and fixing the InternalH Collision vulnerability, it could have been exploited to counterfeit currency. Someone with enough computing power to find 128-bit hash collisions would have been able to double-spend money to themselves, creating Zcash out of thin air.</p>
</blockquote>
<p>Perhaps re-implementing the protocol in a different language might work as well?</p>
<p><img alt="" src="https://cryptologie.net/upload/Screen_Shot_2020-11-23_at_10.16_.18_PM_.png"></p>
<p>One last thing, most of the code out there is not formally verified.
So of course, reviewing code works, but you need time, expertise, money, etc.
So instead, what about testing?
This is what <a href="https://github.com/google/wycheproof">Wycheproof</a> does by implementing a number of test vectors that are known to cause issues:</p>
<blockquote>
<p>These observations have prompted us to develop Project Wycheproof, a collection of unit tests that detect known weaknesses or check for expected behaviors of some cryptographic algorithm. Project Wycheproof provides tests for most cryptographic algorithms, including RSA, elliptic curve crypto and authenticated encryption. Our cryptographers have systematically surveyed the literature and implemented most known attacks. We have over 80 test cases which have uncovered more than&nbsp;40 bugs. For example, we found that we could recover the private key of widely-used DSA and ECDHC implementations.</p>
</blockquote>
<p>In all of that, I didn't even talk about the benefits of writing a specification... that's for another day.</p>
</article><p>Well done! You've reached the end of my post. Now you can <a href="">leave a comment</a> or read something else.</p></div>]]>
            </description>
            <link>https://cryptologie.net/article/511/how-do-people-find-bugs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200893</guid>
            <pubDate>Tue, 24 Nov 2020 17:49:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ruby on Rails: Still the Best Web App Framework for Most Teams]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25200799">thread link</a>) | @sairamkunala
<br/>
November 24, 2020 | https://naildrivin5.com/blog/2020/11/23/rails-is-the-best-choice-for-most-teams.html | <a href="https://web.archive.org/web/*/https://naildrivin5.com/blog/2020/11/23/rails-is-the-best-choice-for-most-teams.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>Earlier this year, I was in the position to choose the framework for the startup at which I’m now the CTO. I
could’ve chosen anything. I went with Rails.  And you should, too. It still is the best framework for getting up
and running <em>and</em> for continued iteration and development.</p>

<!-- more -->

<p>Writing a web app requires many moving pieces.  If you use something like Spring, Node, Express, or any other basic
library, you have a <em>lot</em> of decisions to make:</p>

<ul>
  <li>How are URLs routed to code?</li>
  <li>How are headers, params, and request bodies parsed?</li>
  <li>Where does the code live to manage this?</li>
  <li>How are responses created?</li>
  <li>How do we generate dynamic HTML?</li>
  <li>How do we mitigate against common security vulnerabilities such as cross-site scripting?</li>
</ul>

<p>Of course, web apps almost always have a database, which leads to more decisions:</p>

<ul>
  <li>How will we access the database?</li>
  <li>How is the database schema managed?</li>
  <li>What conventions will we use for table and column names?</li>
</ul>

<p>Then, there are concerns around the development environment:</p>

<ul>
  <li>How do we write tests?</li>
  <li>How can we execute a test using a web browser?</li>
  <li>How do we manage the data needed for our tests?</li>
  <li>How do we manage data needed to run the app locally?</li>
</ul>

<p>Finally, there are concerns around deployment and production:</p>

<ul>
  <li>How do I get JavaScript packaged for the browser?</li>
  <li>How do I manage CSS?</li>
  <li>How do I create cacheable bundles for CDNs?</li>
</ul>

<h2 id="the-cost-of-making-so-many-decisions">The Cost of Making So Many Decisions</h2>

<p>These decisions are only the beginning.  I’ve worked on web apps that used libraries only—no frameworks—and all of
these decisions plus more had to be made. Many had to be made before the team could start working.  But as time
went by and the team’s composition changed, managing these decisions was a constant tax.</p>

<p>…managing these decisions was a constant tax</p>

<p>Because <em>we</em> made these decisions and <em>we</em> configured our libraries to work in a particular way, it was not
uncommon for developers to want to know why we did it that way, and could we change it?  Many of these decisions
amount to conventions not enforceable with code, so a good chunk of our code reviews required making sure everyone
followed the conventions.</p>

<p>And then we would update our libraries to find out they were suddenly incompatible.  Because we’d hand-selected
libraries to solve each problem, we had no way to guarantee they all worked together other than making sure our app
still worked.  It was hard to see the value in the series of decisions that led to this architecture.</p>

<h2 id="stop-making-so-many-decisions">Stop Making So Many Decisions</h2>

<p>With Rails, you don’t have to make <em>any</em> of the decisions above. None.  Once you type <code>rails new</code> all of those
decisions are made.  True, there are more decisions you will have to make, but Rails will have eliminated a huge number of ultimately pointless decisions.</p>

<p>Rails will have eliminated a huge number of ultimately pointless decisions</p>

<p>It simply doesn’t matter how JavaScript is packaged, what your database naming conventions are, or how HTTP requests are routed to code. You need answers and conventions for all of that, yes, but the actual conventions don’t matter.</p>

<p>What you also need are the conventions to be enforced or managed in code, not documentation. That way, everyone is
incentivized to focus on the problems specific to their domain instead of the plumbing of their app.</p>



<p>This has been the value proposition for Rails since its inception over 15 year ago.  In that time, Rails and its
ecosystem have matured, improved, and continued moving forward.  The value Rails brings is still needed, and it is
<em>still</em> the best framework for most teams.</p>

<p>Engineers without Rails experience may continue to believe the fantasy that Rails does not scale or that it can’t
be used for “serious” problems.  Those of us <em>with</em> Rails experience know this isn’t true.  But what we also worry
about is that Rails apps can become unmaintainable.</p>

<h2 id="rails-helps-maintainability">Rails Helps Maintainability</h2>

<p>Hopefully, it’s obvious that no framework or set of libraries can ensure maintainability.  I would argue that Rails
gives you a better chance.  Rails—and its ecosystem—tend to evolve together, so you can rely on the stability of
your core tools over many years.</p>

<p>Rails basis in conventions also means that there are generally fewer parts of an app to get crufty as time goes by.
But, it’s still up to the team to establish conventions and ways of working to capitalize on that.  As it would be
on any team.</p>

<p>So what happens when the team stops making pointless decisions, worrying about library compatibility, and spending
code-review time on conventions?  They start thinking about the problems they need to solve. That’s why Rails is
the best web framework for most teams.</p>

  </section></div>]]>
            </description>
            <link>https://naildrivin5.com/blog/2020/11/23/rails-is-the-best-choice-for-most-teams.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200799</guid>
            <pubDate>Tue, 24 Nov 2020 17:40:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No surprises here – On the absence of information in today’s media]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 78 (<a href="https://news.ycombinator.com/item?id=25200732">thread link</a>) | @s3v
<br/>
November 24, 2020 | https://www.turningchaos.com/essays/no-surprises-here | <a href="https://web.archive.org/web/*/https://www.turningchaos.com/essays/no-surprises-here">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-4a3121594376e73eb592"><div><h2>The absence of information in today’s press</h2><p>"<em>Nobody goes to a newspaper for news.</em>" —Martin Gurri</p><p>We're told we live in the information age. Statements like this often quote the mind-boggling amount of data produced on the internet using exotic-sounding words like zettabytes per day as proof. To function in this sea of data, we're supposed to find signals in the noise and read from credible sources of news and other information. With news media taking political stances, it's not that easy.</p><p>My assertion, paradoxically, is that polarization has greatly diminished the <em>quantity of information</em> being produced and consumed via today's press despite the sea of content they produce. The result is a loss of the press's effectiveness in their two functions within a healthy democracy, as a check on government and promoter of informed debate.</p><h2>Information</h2><p>It's important to define terms. What is information?</p><p>In the <a href="https://en.wikipedia.org/wiki/Information_theory">information theory</a> definition, the quantity of information in a message is related to the amount of <em>surprise</em> it contains. This idea of surprise is key so I'm going to spend some time on it.</p><p>Let's imagine you're receiving messages about some set of data and you're trying to determine its distribution. Each message contains one data point. Early on, as you receive messages, the information provided by each piece of data is high because you know very little about the data itself. With each new piece of information, you start to construct a representation of the overall data set like the one shown in the image below.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606176449103_6575"><div><p>After some number of points, you realize the data is a normal distribution or bell-curve and you can make some determination about its structure. In this case, the mean or average value as well as its width (or standard deviation). Let's say the average value is 0 and the standard deviation is 1. This means that 68% of the values will be between -1 and 1, 95% will be between -2 and 2, and &gt;99% will be between -3 and 3.</p><p>Great! Let's say the next set of messages that you get are 0, 0.1, and 1. Those numbers are completely within the expected range we calculated earlier. There's nothing particularly surprising about them, and as a result, <strong>there is almost no information</strong> contained within them.</p><p>What if you get a message of 10? Now there's a problem. There's almost no chance that the distribution we described above should include a value of 10. Getting 10 is very surprising. So surprising that it may mean the model we had for this data is entirely wrong. That's a lot of information contained in one message of 10, way more than the other messages we got earlier.</p><p>Why does 10 have so much information? It's because it's surprising. It causes us to challenge the model we had built. It could be that the message was a mistake, a fluke. But it could also be that the conclusions we held were wrong. <strong>The more high-information messages like this we get, the more we should start to challenge the beliefs we previously held.</strong> Now let's get back to media.</p><h2>News media</h2><p>In today's polarized media, each side of the media discourse has established its perspective, and the content they publish conforms to this perspective. When you go to a news outlet with a particular leaning, you may not know exactly what stories they'll be writing about, but you do know what <em>kind</em> of stories will be covered and from what perspective. Your knowledge about that outlet's outlook was built up over time as you encountered what they publish.</p><p>When one outlet consistently publishes pieces that align with their perspective, the information content provided by each article starts to diminish. When the theme of each article aligns within the expected distribution, there's no surprise and thus no information.</p><p>It's important to take a moment to distinguish surprise from shock. As you may be familiar, it's common for media to publish stories that have a shock value as they compete with other organizations for your attention. What I'm discussing in this essay isn't the shock value or the particular event that the news media is writing about, it's the perspective of the news organization and the degree of surprise that they published it. For example, you might be shocked at the behavior of one political party's behavior, but are you surprised by it, and more importantly, are you surprised that a news organization that takes the opposite position is publishing a story about it? Shock and surprise can be related, but there's a distinction here between headlines that are attention-grabbing and whether the content fits the mold of the news organization's narrative.</p><h2>Implications</h2><p>The danger of this is two-fold. First, if you only read from one source or a set of sources with similar outlooks, the media source's perspective can start to become yours. You end up with a world-view that aligns with the publisher's view. Since that source never prints anything which disputes that view, your perspective on the world becomes insulated and unchallenged. It's like the example above where we thought we knew the distribution was a bell-curve until we got a few message outliers. Those outliers demanded we reconsider our earlier conclusions. Except this time, <strong>the outliers exist but we never receive them</strong>. We go about our days oblivious to information that would challenge our world-view because it doesn't get published anywhere we look.</p><p>"<em>A free press is one of the pillars of democracy</em>." - Nelson Mandela</p><p>The second danger involves the media's role as a check on government. The branches of government exist to prevent the abuse of power by one another. <strong>The press exists to prevent the abuse of information by the government.</strong> It should question and investigate claims by the government to inform voters and further civic discourse.</p><p>However, this function requires the press to be viewed as impartial, truth-seeking, and without advancing an opinion except where explicitly noted (i.e. the opinion section). If the average voter comes to distrust the press, this function is lost. Articles that would normally inform the voter, providing surprise and evidence that would counter a particular world-view, instead go unread or dismissed. Voters either write off the press entirely or read solely from outlets with views that align with their own further solidifying their own beliefs. In either case, we end up with tribes of perspectives unwilling to seek a compromise that can allow the country to proceed collectively.</p><p>I'm not claiming that all reporters are like this. There are excellent reporters that seek truth regardless of politics. Unfortunately, this independent perspective is increasingly difficult to find. Well-reasoned, objective reporting doesn't generate the same attention as partisan emotion.</p><p>Instead, our press needs to promote information and surprise without bias. By only publishing from one narrative, they insulate the public (and themselves!) from information that could lead to honest debate and discovery. Likewise, our opinions should be formed from a careful examination of arguments and evidence on each side of the issue, <strong>reading from only one perspective is akin to not reading at all.</strong></p></div></div></div>]]>
            </description>
            <link>https://www.turningchaos.com/essays/no-surprises-here</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200732</guid>
            <pubDate>Tue, 24 Nov 2020 17:35:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparison of Email Hosting Possibilities]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25200588">thread link</a>) | @Wronnay
<br/>
November 24, 2020 | https://blog.m5e.de/post/comparison-of-email-hosting-possibilities/ | <a href="https://web.archive.org/web/*/https://blog.m5e.de/post/comparison-of-email-hosting-possibilities/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
        <p>I’ve hosted my own Mailserver in various configurations since more than 6 years now. Since then I’ve taken multiple breaks from hosting it myself and explored other solutions for hosting emails with your own domain names.</p>
<p>Because my own Mailserver has lately problems (downtimes) I wanna explore other possibilities of hosting my email addresses.</p>
<p>So let’s take a look…</p>

<p>You simply setup a Mailserver with software like Mailcow, Mailu or Mail-in-a-Box on a virtual Server and manage it yourself.</p>
<p>Pros:</p>
<ul>
<li>You have the control</li>
<li>Unlimited domains</li>
<li>Unlimited mailboxes</li>
<li>Cheaper than most alternatives if you don’t look at the time you need for setup and maintenance</li>
</ul>
<p>Cons:</p>
<ul>
<li>Most cheap VPS don’t offer a lot of space and if you subtract the OS and installed software, then your space for mail is very limited</li>
<li>You need to invest a lot of time</li>
<li>You need a good spec VPS because Mailserver software and SPAM protection are performance intensive</li>
<li>Small VPS are often targeted by criminals and protection isn’t very easy</li>
</ul>
<p>This is what I’ve done the most of the time.</p>
<p>In the past this was very straightforward if you know how to setup and secure a mailserver but I’ve lately problems with things like DDoS and Brute Force Attacks.</p>
<p>A <a href="https://news.ycombinator.com/item?id=24154524">question</a> from me on Hacker News was even so heavily voted that it was for a short time on the front page of HN - so this seems to be a problem for other people too.</p>
<h2 id="pawnmail">Pawnmail<a href="#pawnmail" arialabel="Anchor">⌗</a> </h2>
<p>This service doesn’t exist anymore but I wanna mention it because it was one of the few free providers where you can get mailboxes for your own domains.</p>
<p>AFAIK that service doesn’t exist anymore because it was targeted by spammers and had problems with attacks.</p>
<h2 id="zoho-mail">Zoho Mail<a href="#zoho-mail" arialabel="Anchor">⌗</a> </h2>
<p>The free plan supports one domain with up to five users and has a 5GB/User and 25MB attachment limit.</p>
<p>Unusable for me because IMAP/ POP/ Active Sync are not included in the free plan.</p>
<p>Indian company, the CEO seems to support Hindu nationalism.</p>
<h2 id="yandex-mail">Yandex Mail<a href="#yandex-mail" arialabel="Anchor">⌗</a> </h2>
<p>The biggest player in my comparison. Offers 10 GB of storage, up to 1000 users and support for custom domains for free.</p>
<p>It seems like the only problem is that you have to trust a Russian company.</p>
<h2 id="mxroute">MXroute<a href="#mxroute" arialabel="Anchor">⌗</a> </h2>
<p>Has various plans for custom Domain Email Hosting. All plans include support for unlimited Domains and unlimited Email Accounts.</p>
<p>Especially the Black Friday deals seem to be pretty good every year.</p>
<p>US company, interestingly the Founder has worked for Christian Institutions - so both - the CEOs of Zoho and MXroute seem to be religious persons.</p>
<h2 id="mailcheapco">Mailcheap.co<a href="#mailcheapco" arialabel="Anchor">⌗</a> </h2>
<p>Cheap Hosting Provider for custom Domain Email, comparable to MXroute but it has more bad reviews than MXroute.</p>
<h2 id="migadu">Migadu<a href="#migadu" arialabel="Anchor">⌗</a> </h2>
<p>On the HN Post to this Article <a href="https://news.ycombinator.com/item?id=25201493">someone mentioned</a> Migadu.</p>
<p>Migadu is the only provider on this comparison from Switzerland and the pricing is more expensive compared to the US providers…</p>
<p>So you pay more but your data is probably also more secure.</p>
<h2 id="postaleio">postale.io<a href="#postaleio" arialabel="Anchor">⌗</a> </h2>
<p>French provider, offers a free plan which includes one domain, 2 mailboxes, 3 aliases and 1 GB per mailbox.</p>
<h2 id="conclusion">Conclusion<a href="#conclusion" arialabel="Anchor">⌗</a> </h2>
<p>Unfortunately it seems like the cheapest hosting possibilities are either trusting a Russian company which government maybe spies on you, trusting a US company which is also obliged to let the government spy on you or to go to an Indian company which is run by a Hindu nationalism supporter…</p>
<p>Hosting your own server isn’t the cheapest option but you are more in control.</p>
<p>I know there are privacy focused providers like ProtonMail or Fastmail out there but the cost of those services are way higher than the providers I mentioned at the time of this writing. (Especially if you want more than one mailbox. Most popular services are on a pay per-user basis, but MXroute, Mailcheap, Yandex and your own VPS are more on a pay per-storage / resources plan)</p>
<p>So I think I will split my domains to various services - in that way no government has all of my information and I am more immune to downtimes.</p>

      </div></div></div>]]>
            </description>
            <link>https://blog.m5e.de/post/comparison-of-email-hosting-possibilities/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200588</guid>
            <pubDate>Tue, 24 Nov 2020 17:22:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitcoin 2021 Probabilistic Forecast]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25200220">thread link</a>) | @refrigerator
<br/>
November 24, 2020 | https://my.causal.app/models/21522 | <a href="https://web.archive.org/web/*/https://my.causal.app/models/21522">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://my.causal.app/models/21522</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200220</guid>
            <pubDate>Tue, 24 Nov 2020 16:52:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Neural Networks for Option Pricing]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199972">thread link</a>) | @jptitus
<br/>
November 24, 2020 | https://samuellee19.github.io/CSCI145_Option_Pricing/ | <a href="https://web.archive.org/web/*/https://samuellee19.github.io/CSCI145_Option_Pricing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<h2 id="project-overview">Project Overview</h2>
<h3 id="background">Background</h3>
<p><strong>The Black Scholes model</strong> is used to price put and call options by estimating the variation over time said financial instruments. The model is based on the assumption that the markets are highly efficient (i.e., Efficient Market Hypothesis), which suggests that stock prices are uncorrelated to one another across time. As a result, Geometric Brownian Motion (GBM) also has been assumed. However, the assumption is often violated in practice, leading to numerous variations of the Black-Scholes model.</p>
<p>The <strong>Black-Scholes formula for European call and put options</strong> are:</p>
<p><span>\[C(S_0,t)=S_0N(d_1)-Ke^{-r(T-t)}N(d_2)\]</span> <span>\[P(S_0,t)=Ke^{-r(T-t)}N(-d_2)-S_0N(-d_1)\]</span> where<br>
- <span>\(S_0\)</span>: Stock Price<br>
- <span>\(C(S_0,t)\)</span>: Price of the Call Option<br>
- <span>\(K\)</span>: Exercise Price<br>
- <span>\((T-t)\)</span>: Time to Maturity, where T is Exercise Date<br>
- <span>\(\sigma\)</span>: Underlying Volatility (a standard deviation of log returns)<br>
- <span>\(r\)</span>: Risk-free Interest Rate (i.e., T-bill Rate)<br>
</p>
<p>The <span>\(d_i\)</span> variables are defined as: <span>\[d_1=\frac{\ln\frac{S_0}{K}+(r+\frac{\sigma^2}{2})(T-t)}{\sigma\sqrt{T-t}}\]</span> <span>\[d_2=d_1-\sigma\sqrt{T-t}=\frac{\ln\frac{S_0}{K}+(r-\frac{\sigma^2}{2})(T-t)}{\sigma\sqrt{T-t}}\]</span></p>
<p>Finally, <span>\(N(x)\)</span> is cumulative distribution function for the standard normal distribution.</p>
<h3 id="project-objectives">Project Objectives</h3>
<p>In this project, we aim to do the following:<br>
1. Recreate Culkin and Das’ work<br>
2. See whether fitted simulated model performs well on actual data<br>
3. Observe if the model can perform better based on different datasets</p>
<h2 id="methodologies">Methodologies</h2>
<h3 id="data">Data</h3>
<p>To recreate Culkin and Das’ work we utilized the same simulated data used in the paper to train and validate the neural network.</p>
<p>Aditionally, we queried UKX options data and the options’ underlying stock infromation from Bloomberg (see Bloomberg Query File). We also created another dataset by <a href="https://github.com/jknaudt21/Option-Scraper-BlackScholes">scraping</a> information for S&amp;P500 companies from Yahoo Finance and AlphaQuery.</p>
<h4 id="culkin-and-das-2017">1. Culkin and Das (2017)</h4>
<p>To train a neural network to learn the call option pricing equation, Culkin and Das (2017) simulated a range of call option prices with ranges of different parameters<span data-cites="Culkin_Das_2017">(Culkin and Das <a href="#ref-Culkin_Das_2017">2017</a>)</span>:</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Range</th>
</tr>
</thead>
<tbody>
<tr>
<td>Stock Price <span>\((S)\)</span></td>
<td>$10 — $50</td>
</tr>
<tr>
<td>Strike Price <span>\((K)\)</span></td>
<td>$7 — $650</td>
</tr>
<tr>
<td>Maturity <span>\((T-t)\)</span></td>
<td>1 day to 3 years</td>
</tr>
<tr>
<td>Dividend Rate <span>\((q)\)</span></td>
<td>0% — 3%</td>
</tr>
<tr>
<td>Risk Free Rate <span>\((r)\)</span></td>
<td>1% — 3%</td>
</tr>
<tr>
<td>Volatility <span>\((\sigma)\)</span></td>
<td>5% — 90%</td>
</tr>
<tr>
<td>Call Price <span>\((C)\)</span></td>
<td>$0 — $328</td>
</tr>
</tbody>
</table>
<p>In total, the dataset contains 300,000 observations.</p>
<h4 id="ukx-bloomberg-data">2. UKX Bloomberg Data</h4>
<p>This data is consisted of call options for stocks in the UKX 100 from Bloomberg Terminal. As Bloomberg Terminal has an upper bound for queries, this data only consists of 1600+ observations.</p>
<h4 id="sp-500-scraped-data">3. S&amp;P 500 Scraped Data</h4>
<p>To address a limited number of observations on the above data, we collected additional data through web scraping. Although web data may be imperfect, it can still hold useful information. For this dataset there are 57,000+ observations and we evaluate it separately from the addendum of UKX data.</p>
<h2 id="code">Code</h2>
<p>We used following dependencies and <code>scikit-learn</code>’s prebuilt models to train and visualize our results:</p>
<div data-layout="l-body">
<pre><code>
import numpy as np
from sklearn.neural_network import MLPRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import pandas as pd
import matplotlib.pyplot as plt
import pickle
from scipy import stats
import matplotlib
matplotlib.rcParams['figure.dpi'] = 300</code></pre>
</div>
<h3 id="importing-and-preparing-training-data">Importing and Preparing Training Data</h3>
<table>
<colgroup>
<col>
<col>
<col>
<col>
<col>
<col>
<col>
<col>
</colgroup>
<thead>
<tr>
<th>Index</th>
<th>Stock Price</th>
<th>Strike Price</th>
<th>Maturity</th>
<th>Dividends</th>
<th>Volatility</th>
<th>Risk-free</th>
<th>Call Price</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>206.484</td>
<td>194.386</td>
<td>1.093</td>
<td>0.006</td>
<td>0.863</td>
<td>0.059</td>
<td>79.434</td>
</tr>
<tr>
<td>1</td>
<td>79.582</td>
<td>73.926</td>
<td>0.844</td>
<td>0.020</td>
<td>0.760</td>
<td>0.081</td>
<td>24.976</td>
</tr>
<tr>
<td>2</td>
<td>130.957</td>
<td>154.101</td>
<td>1.326</td>
<td>0.019</td>
<td>0.606</td>
<td>0.042</td>
<td>28.928</td>
</tr>
<tr>
<td>3</td>
<td>53.021</td>
<td>58.598</td>
<td>0.792</td>
<td>0.028</td>
<td>0.573</td>
<td>0.037</td>
<td>8.574</td>
</tr>
<tr>
<td>4</td>
<td>455.191</td>
<td>529.570</td>
<td>0.501</td>
<td>0.009</td>
<td>0.091</td>
<td>0.044</td>
<td>0.210</td>
</tr>
</tbody>
</table>
<p>The original dataset contains an unnecessary index column, so we dropped it from the data frame.</p>
<h4 id="normalizing-the-data-as-done-in-culkin-and-das">Normalizing the data (as done in Culkin and Das)</h4>
<p>As we know that the Black-Scholes formula is linear homogeneous in <span>\(C(S,K)\)</span>, we can normalize our data as: <span>\(C(S,K)/K=C(S/K,1)\)</span></p>
<p>Hence, the results are shown below:</p>
<table>
<colgroup>
<col>
<col>
<col>
<col>
<col>
<col>
<col>
<col>
</colgroup>
<thead>
<tr>
<th>Index</th>
<th>Stock Price</th>
<th>Strike Price</th>
<th>Maturity</th>
<th>Dividends</th>
<th>Volatility</th>
<th>Risk-free</th>
<th>Call Price</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>1.062</td>
<td>1.0</td>
<td>1.093</td>
<td>0.006</td>
<td>0.863</td>
<td>0.059</td>
<td>0.409</td>
</tr>
<tr>
<td>1</td>
<td>1.077</td>
<td>1.0</td>
<td>0.844</td>
<td>0.020</td>
<td>0.760</td>
<td>0.081</td>
<td>0.338</td>
</tr>
<tr>
<td>2</td>
<td>0.850</td>
<td>1.0</td>
<td>1.326</td>
<td>0.019</td>
<td>0.606</td>
<td>0.042</td>
<td>0.188</td>
</tr>
<tr>
<td>3</td>
<td>0.905</td>
<td>1.0</td>
<td>0.792</td>
<td>0.028</td>
<td>0.573</td>
<td>0.037</td>
<td>0.146</td>
</tr>
<tr>
<td>4</td>
<td>0.860</td>
<td>1.0</td>
<td>0.501</td>
<td>0.009</td>
<td>0.091</td>
<td>0.044</td>
<td>0.000</td>
</tr>
</tbody>
</table>
<h3 id="training-the-model">Training the model</h3>
<p>To remain as faithful to Culkin and Das, we trained the neural network with the following parameters:<br>
- 4 hidden fully connected layers, each with 100 neurons<br>
- Batch size of 64<br>
- 10 training epochs<br>
- 80-20 train-validation split<br>
- Mean Squared error as loss function</p>
<p>The main difference between our model and the paper’s model is that our network uses ReLU as the activation function for every layer, instead of using LeakyReLU, ELU, ReLU, and ELU for the four layers respectively. We also did not employ dropout regularization. Lastly, we opted to use “Adam” as our optimizer rather than stochastic gradient descent.</p>
<div data-layout="l-body">
<pre><code>
np.random.seed(32)
X_train, X_test, y_train, y_test = train_test_split(df.drop('Call Price', axis=1), 
                                                    df['Call Price'], test_size=0.2)

mlp = MLPRegressor(hidden_layer_sizes=(100,100,100,100), 
                   solver='adam', shuffle = False, batch_size=64, verbose=True,
                   max_iter= 10
                    ) </code></pre>
</div>
<h2 id="analysis-and-visualization">Analysis and Visualization</h2>
<p>We started by exploring the most basic performance metric for every regression problem: <span>\(R^2\)</span></p>
<div data-layout="l-body">
<pre><code>
print("Training set score: %f" % mlp.score(X_train, y_train))
print("Test set score: %f" % mlp.score(X_test, y_test))</code></pre>
</div>
<p>We received <span>\(R^2\)</span> values (training and test) of 0.999476 and 0.999474.</p>
<p>We can see that the model produced very promising results from the simulated data. While the results show that the algorithm is able to learn option pricing mechanism, we cannot draw any significant conclusion that it can produce meaningful results in real life situation.</p>
<p>We can visualize the succes of the model in the graph below:</p>
<p><img src="https://samuellee19.github.io/CSCI145_Option_Pricing/BS_Model_draft/output_27_0.png" width="257"></p>
<p>We can also explore the distribution of both the in-sample and out of sample error:</p>
<p><img src="https://samuellee19.github.io/CSCI145_Option_Pricing/BS_Model_draft/output_29_0.png" width="268"></p>
<p><img src="https://samuellee19.github.io/CSCI145_Option_Pricing/BS_Model_draft/output_30_0.png" width="268"></p>
<div data-layout="l-body">
<pre><code>
rmse = mean_squared_error(preds_test, y_test)**0.5; rmse # root mean squared error
print("RMSE: %.4f" % rmse)</code></pre>
</div>
<p>Root Mean Square Error of the prediction is 0.0041. Hence, the pricing error in the training set can be summarized as below:</p>
<table>
<thead>
<tr>
<th>Number of Observations</th>
<th>minmax</th>
<th>mean</th>
<th>variance</th>
<th>skewness</th>
<th>kurtosis</th>
</tr>
</thead>
<tbody>
<tr>
<td>240,000</td>
<td>(-0.045, 0.039)</td>
<td>-0.003</td>
<td>0.000007</td>
<td>-0.400</td>
<td>12.084</td>
</tr>
</tbody>
</table>
<p>The pricing error in the test set can be summarized as below:</p>
<table>
<thead>
<tr>
<th>Number of Observations</th>
<th>minmax</th>
<th>mean</th>
<th>variance</th>
<th>skewness</th>
<th>kurtosis</th>
</tr>
</thead>
<tbody>
<tr>
<td>11,841</td>
<td>(-1.407,204.185)</td>
<td>0.091</td>
<td>10.957</td>
<td>54.036</td>
<td>3,074.578</td>
</tr>
</tbody>
</table>
<h2 id="validating-with-real-data">Validating with real data</h2>
<p>So far, we have observed the behavior of the model using the synthetic data. Though the use of synthetic data has allowed us to learn the Black-Scholes model quite accurately, we have yet to see how the model performs using real data. Plus, we could also gauge whether models trained in real data are able to better price options in the market.</p>
<p>Nonetheless, it is worth noting that a common option trading strategy is to determine whether an option is undervalued or fairly valued with respect to the market’s price and the price outputed by Black-Scholes. With this in mind, if our model misprices an option with a higher price, it could be an indicator that said option is undervalued.</p>
<p><strong>Important</strong>: by the time the data for this article was collected, the current risk-free rate was 0.88%.</p>
<h3 id="ukx-bloomberg-data-1">UKX Bloomberg Data</h3>
<p>To start the validation, we pulled options data using a Bloomberg terminal. To limit the size of query, we extracted the data for around ~1600 calls on stocks in the UKX100.</p>
<table>
<thead>
<tr>
<th></th>
<th>Stock Price</th>
<th>Strike Price</th>
<th>Maturity</th>
<th>Dividends</th>
<th>Volatility</th>
<th>Risk-free</th>
<th>Call Price</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>4,732.0</td>
<td>1.0</td>
<td>0.09</td>
<td>0.000000</td>
<td>0.392</td>
<td>0.0088</td>
<td>4,731.0</td>
</tr>
<tr>
<td>1</td>
<td>4,732.0</td>
<td>1.0</td>
<td>0.34</td>
<td>11.949099</td>
<td>0.392</td>
<td>0.0088</td>
<td>4,731.0</td>
</tr>
<tr>
<td>2</td>
<td>4,732.0</td>
<td>1.0</td>
<td>0.02</td>
<td>0.000000</td>
<td>0.392</td>
<td>0.0088</td>
<td>4,731.0</td>
</tr>
<tr>
<td>3</td>
<td>2,094.0</td>
<td>1.0</td>
<td>0.09</td>
<td>0.000000</td>
<td>0.530</td>
<td>0.0088</td>
<td>2,093.0</td>
</tr>
<tr>
<td>4</td>
<td>2,094.0</td>
<td>1.0</td>
<td>0.34</td>
<td>4.424667</td>
<td>0.530</td>
<td>0.0088</td>
<td>2,093.0</td>
</tr>
</tbody>
</table>
<p>Though it might seem that this data is normalized already, such is not the case. Therfore, we normalize the data by dividing by the strike.</p>
<p>We proceeded with dropping <code>Call Price</code> column on the data and predicted to see how the model performs.</p>
<p><img src="https://samuellee19.github.io/CSCI145_Option_Pricing/BS_Model_draft/output_40_0.png" width="263"></p>
<p>From a quick glance, there seems to be some minor deviations. In fact, we got <span>\(R^2\)</span> value of 0.8699. We can also see the distribution of the errors. Since the simulated data were not generated under a normal distribution, it would not be surprising to observe a skewed distribution:</p>
<p><img src="https://samuellee19.github.io/CSCI145_Option_Pricing/BS_Model_draft/output_44_0.png" width="263"></p>
<p>While the model performed worse relative to previous sample, it still achieved a high R-squared value considering that the training data and the test data came from different sources. Hence, the above graph is summarized as below:</p>
<table>
<thead>
<tr>
<th>Number of Observations</th>
<th>minmax</th>
<th>mean</th>
<th>variance</th>
<th>skewness</th>
<th>kurtosis</th>
</tr>
</thead>
<tbody>
<tr>
<td>1,685</td>
<td>(-3,088.616,0.352)</td>
<td>-28.828</td>
<td>44,608.131</td>
<td>-10.457</td>
<td>123.588</td>
</tr>
</tbody>
</table>
<p>It makes sense that a model trained from the simulated data would perform relatively bad. However, a real question is whether neural network can perform well given real data that is not normally distributed.</p>
<p>To mitigate the effect of having less data, we increased the number of epochs:</p>
<div data-layout="l-body">
<pre><code>
np.random.seed(32)
X_train_ukx, X_test_ukx, y_train_ukx, y_test_ukx = train_test_split(ukx.drop('Call Price', axis=1), 
                                                    ukx['Call Price'], test_size=0.2)

mlp_u = MLPRegressor(hidden_layer_sizes=(100,100,100,100), 
                   solver='adam', shuffle = False, batch_size=64, verbose=True,
                   max_iter= 20
                    )

mlp_u.fit(X_train_ukx, y_train_ukx)</code></pre>
</div>
<p>Hence, the model achieved <span>\(R^2\)</span> values of 0.999998 and 0.999998 for training and testing sets.</p>
<p><img src="https://samuellee19.github.io/CSCI145_Option_Pricing/BS_Model_draft/output_51_0.png" width="259"></p>
<table>
<thead>
<tr>
<th>Number of Observations</th>
<th>minmax</th>
<th>mean</th>
<th>variance</th>
<th>skewness</th>
<th>kurtosis</th>
</tr>
</thead>
<tbody>
<tr>
<td>337</td>
<td>(-0.316,9.836)</td>
<td>0.164</td>
<td>0.804</td>
<td>7.901</td>
<td>69.226</td>
</tr>
</tbody>
</table>
<p>From the above, we can see that the model was able to perform very well, given that there were only 1,685 observations used for training the model. However, one thing to note is that the result exhibits a very <strong>high kurtosis</strong>: while the model is consistent in most cases, it could lead to a severe gain/loss (long tails) from time to time. In real-life application, such model will not be preferred by the practitioners as …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://samuellee19.github.io/CSCI145_Option_Pricing/">https://samuellee19.github.io/CSCI145_Option_Pricing/</a></em></p>]]>
            </description>
            <link>https://samuellee19.github.io/CSCI145_Option_Pricing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199972</guid>
            <pubDate>Tue, 24 Nov 2020 16:33:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Quicklang.net – A Simple Programming Language That Runs in the Browser]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199865">thread link</a>) | @chkas
<br/>
November 24, 2020 | https://quicklang.net/ide/ | <a href="https://web.archive.org/web/*/https://quicklang.net/ide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://quicklang.net/ide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199865</guid>
            <pubDate>Tue, 24 Nov 2020 16:24:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My EOY Reflection Checklist]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25199785">thread link</a>) | @opsgal
<br/>
November 24, 2020 | https://boringstartupstuff.com/newsletter/nov-24th-2020-finish-the-year-strong | <a href="https://web.archive.org/web/*/https://boringstartupstuff.com/newsletter/nov-24th-2020-finish-the-year-strong">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em><strong>The End-of-Year Checklist</strong><span>&nbsp;</span></em><em><span></span></em></p>
<p><span>I like starting the year with an empty to-do list and a fresh perspective. As an obsessive list maker, this process naturally starts with another list. Some of the questions can be treated as action items, but many require deeper reflection (perfect for the quiet week at the end of the year). I hope that you find it useful as you close out 2020!</span></p>

<h5><strong>As a Company</strong></h5>
<ul>
<li><span>What actions most moved the company forward and how can we double down on them? What should we have spent less time doing?&nbsp;</span></li>
<ul>
<li><span>Using the </span><a href="https://www.forbes.com/sites/kevinkruse/2016/03/07/80-20-rule/?sh=15a5959d3814"><span>Pareto Principle</span></a><span>, the return on certain actions will significantly outweigh others.</span></li>
</ul>
<li><span>Did our actions reflect our values? Did we call out times that employees personified our values? Do we need to add or subtract values?</span></li>
<li><span>Which relationships are most important to our success (e.g. customers, investors, partners) and what can we be doing to provide them with more value?</span></li>
</ul>

<h5><strong>As a Manager</strong><span>&nbsp;</span></h5>
<ul>
<li><span>Do we have the </span><a href="https://www.jimcollins.com/concepts/first-who-then-what.html"><span>right people on the bus</span></a><span>?</span></li>
<li><span>Are the right people owning the right things or are there better ways that we can be distributing the work?</span><br><span></span><span></span></li>
</ul>

<p><span>I keep a Trello board to manage this; <a data-cke-saved-href="https://trello.com/b/v6lu8Xpc" href="https://trello.com/b/v6lu8Xpc" target="_blank" rel="noopener">steal my template here</a>.</span></p>
<p><img src="https://cdn.buttercms.com/j9hSXZluRBG3S2HjajIu" alt="trello chart" width="683" height="158"></p>
<ul>
<li><span>How were my 1:1s? Did my reports walk away feeling that I had removed blockers, clarified vagueness, and given clear instructions?</span></li>
<li><span>Do my reports know their metrics for success?</span></li>
<li><span>How connected is the team overall?</span><strong></strong><span></span></li>
</ul>
<h5><strong>Meetings</strong><span>&nbsp;</span></h5>
<ul>
<li><span>Is every meeting on my calendar still relevant and useful?</span></li>
<li><span>Have I invited the right people to each one?</span></li>
<li><span>Are the major meetings for the upcoming year already scheduled? Mine are:</span>
<ul>
<li><span>Off-sites</span></li>
<li><span>Customers business reviews</span></li>
<li><span>Employee reviews</span></li>
<li><span>Team town halls</span></li>
<li><span>Quarterly kickoffs</span></li>
<li><span>Annual trainings</span></li>
</ul>
</li>
<li><span>Do I like the cadence and timing of my recurring meetings?</span>
<ul>
<li><span>Can I schedule any back-to-back to minimize distractions?</span></li>
<li><span>Are meetings optimized to my energy peaks?</span>
<ul>
<li><span>I’m fresh and driven in the mornings and do my best work then. Mentally challenging meetings are best during this window.</span></li>
<li><span>My mind is more relaxed and able to freely brainstorm in the afternoons; I shift most meetings to this time.</span>&nbsp;</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5><strong>Tools</strong></h5>
<ul>
<li><span><span>Are we using the right tools (software, banking, equipment, etc.) to accomplish our goals? Can we eliminate any?</span></span></li>
</ul>
<figure><img src="https://cdn.buttercms.com/exgcpuvKRdmBDDBzKUvF" alt="saas-list" width="772" height="101">
<figcaption>
<p><span>This number balloons quickly, so I keep a spreadsheet of all our tools to track which are still in use and who has access.</span></p>
</figcaption>
</figure>
<ul>
<li><span>Do the right people have access to each tool? Has admin access been given to the logical person?</span></li>
<li><span>Do we have the right tier of service for our size?</span></li>
<li><span>Are there more effective tools available that could reduce or combine the efforts of others?&nbsp;</span></li>
</ul>
<h5><strong>Finance</strong></h5>
<ul>
<li><span>Are our finances generally in order? This can include:</span></li>
<ul>
<li><span>Outstanding invoices</span></li>
<li><span>Unpaid bills</span></li>
<li><span>Sales commissions</span></li>
<li><span>Expense reconciliation</span></li>
<li><span>Credit card charges</span></li>
</ul>
<li><span>Are there areas that we could cut costs next year?</span></li>
<li><span>Is billing set to preferred person and method? (I like to see every charge come through and to optimize points based on spend.)</span></li>
</ul>

<h5><strong>Operations</strong></h5>
<ul>
<li><span>Where can we automate tasks?</span></li>
<li><span>Are the company files clean and organized? What about mine?</span></li>
<ul>
<li><span>If a company file no longer seems relevant, I dump it into an archive folder rather than delete anything.</span></li>
<li><span>I run an inbox-zero on my file downloads and desktop, forcing myself to put any important files somewhere safe in case something happens to my computer.</span></li>
</ul>
<li><span>Are our templated documents up to date?</span></li>
<ul>
<li><span>Check company address, point of contact, and legalese on contracts, mNDAs, etc.</span></li>
</ul>
<li><span>How are our processes? Which ones are sloppy, overly prescriptive, or begging to be eliminated entirely?</span></li>
</ul>

<h5><strong>Performance</strong></h5>
<ul>
<li><span>How did I perform against my job description?</span></li>
<ul>
<li><span>I keep my job description as a living document to capture what I take on and hand off over time. When I doubt where my time is being spent, I discuss this document with my boss and adjust accordingly.</span></li>
</ul>
<li><span>How were my 1:1s with my boss? Did I come to the meeting with thoughtful questions and specific to-dos?&nbsp;</span></li>
<li><span>Did I listen to and incorporate feedback effectively?</span></li>
<li><span>Did I step up when I needed to? Did I delegate my areas of weakness?</span></li>
</ul>
<h5><strong>Role</strong></h5>
<ul>
<li><span>How do I want my job description to change in the next year based on what the company needs and on my own strengths and weaknesses?</span></li>
<li><span>Which relationships within the company are most important to my efficacy? Can I do anything to improve upon those relationships?</span></li>
<li><span>Which tasks I should be taking on or offloading?</span></li>
</ul>
<h5><strong>Time</strong></h5>
<ul>
<li><span>Am I spending time on </span><a href="https://www.nfx.com/post/time-management-for-founders/"><span>the most valuable things</span></a><span> and letting the unimportant things fall through the cracks?</span></li>
<li><span>What have I been putting off?&nbsp;</span>
<ul>
<li><span>Can I eliminate it or delegate it?</span></li>
<li><span>Can I give it more clarity?</span></li>
</ul>
</li>
<ul>
<li><span>I tend to dread tasks that either feel pointless or excessively vague, so I ask:&nbsp;&nbsp;</span></li>
</ul>
<li><span>What can I stop doing altogether?</span></li>
</ul>
<h5><strong>Personal</strong></h5>
<ul>
<li><span>Do I like my personal systems for keeping track of to-dos?</span></li>
<li><span>Do I know what I bring to the table when I join a meeting?</span></li>
<li><span>Am I maintaining a network of people I can turn to for advice?</span></li>
<li><span>Am I making time outside of work for activities that keep me healthy and happy?</span></li>
</ul>
</div></div>]]>
            </description>
            <link>https://boringstartupstuff.com/newsletter/nov-24th-2020-finish-the-year-strong</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199785</guid>
            <pubDate>Tue, 24 Nov 2020 16:16:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Harmful Biases in Performance Reviews]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199752">thread link</a>) | @ochronus
<br/>
November 24, 2020 | https://ochronus.online/biases-in-performance-reviews/ | <a href="https://web.archive.org/web/*/https://ochronus.online/biases-in-performance-reviews/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div itemprop="text">

<p>We are all prone to biases. We cannot help but evaluate and assess people and situations through the lens of our own prejudices. When it comes to performance reviews this can have a huge unwanted impact as it influences compensation, promotion decisions, and even firing.</p>
<p>When you give a performance review for a colleague, you’re very directly impacting their career trajectory. Even so, if you’re their manager. Given the weight of this kind of influence, it’s our responsibility to make sure the reviews are as fair and objective as possible.&nbsp;</p>
<p>Not all is lost, though. Once you’re aware of the existence of these biases and the way they work, you can utilize certain strategies (and a good amount of self-awareness) to minimize their effect.</p>
<p>Below, I break down the most common performance review biases and share advice on how to deal with them both as the giver and the recipient of performance reviews.&nbsp;</p>

<h4 id="0-general-advice-for-managers-"><strong>General advice for managers</strong></h4>
<p>One of the best ways to counter bias in reviews is to come up with a great review format that guides people and doesn’t magnify bias effects. Phrasing matters a lot. Setting the tone, being clear about the purpose and scope of the feedback form is key.</p>
<p>Another very important point is to understand that giving quality feedback takes time, a certain kind of focus, and is a considerable effort. Make sure you proactively prepare your engineers for the feedback season and plan for it – one thing that worked pretty well for me is to represent feedback tasks as cards on the team board and even set them as sprint goals. Nothing makes feedback quality deteriorate more than rushing and feeling that you don’t have enough time for it. You can organize feedback training, too, with our without your HR peers.</p>
<h4 id="1-general-advice-for-everyone-"><strong>General advice for everyone</strong></h4>
<p>On the flip side of the above – expect that giving feedback is not a trivial task. Take your time, make sure you have a quiet corner, don’t do it in one go, take notes, work on your wording, look at email/slack/pull request history too and treat your peers as customers of your feedback.</p>
<p><a href="https://ochronus.online/thoughts-on-feedback/">My article on feedback</a> might help in that.</p>
<hr>
<h2 id="2-recency-bias">Recency bias</h2>
<p>Alice had a very strong year, she had great contributions to the projects her team was working on, achieved most of her goals, mastered a new language, and a framework. In the past month though, due to personal issues, she kept her involvement to the bare minimum. In his feedback to Alice, Bob highlights that he expects more from her and that she feels distant from the team. Bob completely fails to call out the amazing job Alice did earlier and the growth she had had.</p>
<p>Recency bias is when recent events weigh much more heavily in your performance review than older, possibly even more significant events. This is partly due to how our memory works and is a completely natural thing, yet its impact can be really bad and can bias your review in either direction depending on what people remember about you recently.&nbsp;</p>
<h3 id="3-how-to-deal-with-recency-bias">How to deal with recency bias</h3>
<p>The best way is to collect feedback more frequently – for example, do a 360 each quarter even if you only have the performance review once a year. Project-level retrospectives can be helpful as well. Some managers keep ‘files’ on their engineers to counter this bias, but honestly, that can easily backfire – it can feel like a shady practice to their teams. Prefer transparent and open frequent feedback instead.</p>
<p>Some people find it useful to keep a personal achievement log, which helps with their self-assessment or calling out things missing from their feedback. If you feel there are important bits missing from the feedback you’ve been given, call those out. If your manager doesn’t encourage more frequent feedback you can still ask for informal ones from your peers at any time.</p>
<hr>
<h2 id="4-similarity-bias-and-affinity-bias">Similarity bias and Affinity bias</h2>
<p>Alice and Bob graduated from the same university and are both huge Star Trek fans – they talk about it all the time, they get along really well and connect outside work, too. Bob’s feedback to Alice is always overly positive and he’s prone to overlooking seemingly obvious gaps in her performance.&nbsp;</p>
<p>We subconsciously tend to rate people similar to us higher. Similarity can mean many things – personality, looks, way of thinking, etc. Affinity bias occurs when we work with someone we feel we have an affinity with; maybe we attended the same college, we grew up in the same town, or they remind us of someone we know and like.</p>
<h3 id="5-how-to-deal-with-similarity-and-affinity-bias">How to deal with similarity and affinity bias</h3>
<p>A clear, and transparent performance evaluation system helps a lot here. Such a system is clear and well-understood level definitions, which can guide your focus while thinking about others’ performance. That said, levels are usually not public information in companies, so this won’t help too much with peer review.</p>
<p>Getting feedback from multiple peers can help mitigate the effect of this bias.</p>
<hr>
<h2 id="6-halo-effect-and-horn-effect">Halo effect and horn effect</h2>
<p>Alice is really great at debugging and fixing notoriously tricky bugs others usually struggle with. Because of this, she saved the day multiple times. That said, she barely meets her level’s expectations if we look at the wider spectrum. Alice gets really positive feedback from her team highlighting how grateful they are for her being the ‘bug hunter’ and omitting any gaps she might have elsewhere.</p>
<p>Bob meets his level’s expectations in general and is great to work with. That said, he has the tendency to be impatient and cut discussions short because of that, which really hurts his ability to effectively work with others in these situations. Bob gets negative feedback highlighting that he should really work on his temper and communication – not mentioning any of the amazing work he’s done otherwise.</p>
<p>In the halo effect, a single positive event or attribute lifts your review up, and in the horn effect similarly a single negatively perceived action or trait ‘poisons’ your whole review.</p>
<p>This gets even worse if your manager is biased. A classic example of the manager having a halo bias is when they see one of their engineers as the “hero” or the “10x engineer”, being blind about any gaps they might have (btw. check out my older post about <a href="https://ochronus.online/kill-your-heroes/">hero engineers</a>). An example of a manager having the horn bias is when they stigmatize an engineer as e.g. “unreliable” or “not smart enough” based on a one-off event.</p>
<h3 id="7-how-to-counter-the-halo-or-horn-effects">How to counter the halo or horn effects</h3>
<p>You might ask “why would I want to counter the halo effect if it results in positive reviews about me?”. True, it might momentarily be even helpful for you, but not having a clear picture of your gaps ultimately does more damage than good to your career. It hinders your potential to grow and if you change teams, managers, or companies you might be suddenly underperforming and you won’t necessarily understand what happened.</p>
<p>To counter the effect of these biases you first need to understand what the main positive or negative thing is in your feedback and have a heart-to-heart about it with yourself. Again, a proper level definition system helps a lot. If you feel that people are generalizing a one-off negative event, ask them to provide more examples of that behavior. You can actually call out that you feel stigmatized by that single event or trait. If you can, highlight counterexamples.</p>
<p>Sometimes phrasing of rating scale points helps mitigate these biases, e.g. if you call the two extremes of the scales “consistently underperforming” and “top performer”.</p>
<hr>
<h2 id="8-idiosyncratic-rater-bias">Idiosyncratic rater bias</h2>
<p>Bob is an engineering manager leading a mobile developer team. Bob has deep experience in project management but almost none in mobile development. Bob seems to consistently rate the development skills of his engineers much higher than they really are, while he rates the project management performance of the lead developer lower than it is.</p>
<p>Idiosyncratic rater bias happens when people evaluate skills they’re not good at, higher. Sometimes they rate others lower in things they’re great at. This is rooted in lower standards we have for things we don’t have deep knowledge about and higher standards for things we’re experienced at. In other words, our feedback reflects more on our own skills than the person’s we’re reviewing.</p>
<h3 id="9-how-to-counter-the-idiosyncratic-rater-bias">How to counter the idiosyncratic rater bias</h3>
<p>To overcome this bias as a manager, try rephrasing your performance evaluation questions for yourself from a different perspective, e.g.:</p>
<p>If this engineer wanted to resign I would try to retain them.</p>
<p>I would want this engineer on my team at any time.</p>
<p>I would hire this engineer again at any time.&nbsp;</p>
<p>Research shows that people are much more accurate when rating their own intentions compared to rating other people.</p>
<p>Also, having a diverse set of feedback from peers can mitigate this (there’s a low probability for every reviewer to be biased the same way).</p>
<hr>
<h2 id="10-centrality-bias">Centrality bias</h2>
<p>Alice is the manager of a team. She hands in her annual performance evaluations, and you notice that almost everyone on her team scored near the middle of the scale. Now you wonder if that’s actually a realistic image or not.</p>
<p>Many managers don’t like being extreme and tend to be moderate in their reviews. When everyone is receiving a rating of 3 out of 5 across the board, there’s no distinguishing the low-performing and high-performing employees. This will result in unfair reviews and people being pissed by lack of recognition and that nothing happens to low performers.&nbsp;</p>
<h3 id="11-how-to-counter-the-centrality-bias">How to counter the centrality bias</h3>
<p>Well, an easy hack is to remove the middle of the rating scale, the ‘neutral’ option, e.g. have a scale of 4 instead of 5 to force managers to decide. If you received one of the ‘meh’ reviews, have a heart-to-heart with your manager and highlight where you disagree. For example, if you feel you’ve been doing better in a certain area ask for explicit examples of how you could do better and cross-check it with your data points. Rating on multiple skills and axes can help, too, compared to a single, unified rating.&nbsp;</p>
<h2 id="12-contrast-bias">Contrast bias</h2>
<p>Alice is really good at project management. Bob is …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ochronus.online/biases-in-performance-reviews/">https://ochronus.online/biases-in-performance-reviews/</a></em></p>]]>
            </description>
            <link>https://ochronus.online/biases-in-performance-reviews/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199752</guid>
            <pubDate>Tue, 24 Nov 2020 16:14:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ham Radio Needs to Embrace the Hacker Community Now More Than Ever]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25199686">thread link</a>) | @parsecs
<br/>
November 24, 2020 | https://www.kj7nzl.net/blog/ham-radio-needs-to-embrace-the-hacker-community-now-more-than-ever/ | <a href="https://web.archive.org/web/*/https://www.kj7nzl.net/blog/ham-radio-needs-to-embrace-the-hacker-community-now-more-than-ever/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content-pane">
  <div>
    
    <h2 id="an-open-letter-to-all-ham-radio-operators">An Open Letter To All Ham Radio Operators</h2>
<p>“Ham Radio is dying!” A phrase all to often uttered that it’s become cliché, but it’s partly true. You can’t deny a considerable section of the ham radio operators in the world are in the latter part of their lives.They won’t be around forever so naturally new people must assume their place. The good news is amateur radio licenses are on the rise. The bad news is the people induced to ham radio these days aren’t interested in pushing the limits of RF technology. To be blunt I’m talking about preppers and those solely interested in emergency communications. Neither of which have any desire to explore ham radio beyond a disaster fetish in which they use their $25 BaoFeng HT to save the world. So what can ham radio operators do? Easy, reach out to the hacker community! First, allow me define the word hacker since there are nefarious connotations of the word’s meaning. When I use the word hacker, I’m talking about the type of individual who wants to comprehend how a given technology works and who explores all the possibilities that technology has to offer. These are the people who grew up dismantling electronics just to appreciate how they work, the people who stayed up late into the night teaching themselves to code, and these are the people ham radio needs to propel it further into the future. To attract and retain hackers within the ham community there are a few things that we need to do.</p>
<h3 id="1-stop-primarly-promoting-emergency-communications">1. Stop Primarly Promoting Emergency Communications</h3>
<p>Every day I see on the <a href="https://www.reddit.com/r/amateurradio/">r/amateurradio</a> subreddit a number of people who solely promote ham radio’s role in emergency communications. Does it have a place within the hobby and community? Certainly, however, there is little interest from the hacker community in relaying messages about the state of the weather during a thunderstorm. Ham radio offers so much morel. You do it a disservice when you either dismiss the other areas of the hobby as secondary to emergency communications or fail to mention them at all. For crying out loud, we launch our own communications satellites and utilize them every day. Satellite communications, the blending of RF and VoIP to communicate around the world, software defined radio represent the things we need to promote to the hacker community. To effectively communicate, identify your audience.</p>
<h3 id="2-start-promoting-software-defined-radio">2. Start Promoting Software Defined Radio</h3>
<figure>
    <img src="https://www.kj7nzl.net/img/radios/hackrf-one-sdr-001.webp" alt="Will SDRs like the HackRF One be the future of ham radio?"> <figcaption>
            <p>Will SDRs like the HackRF One be the future of ham radio?</p>
        </figcaption>
</figure>

<p>There is a lot of interesting work that’s currently being done within the hacker community with RF. Most of this work is currently centered around WiFi, LoRa, IoT networks. It not difficult to imagine someone who has an interest in these communication technologies wouldn’t be open to software defined radio. They just need to be presented with easy to understand examples and a little encouragement to become licensed. Kelly Albrink’s 2020 DerpCon talk <em>Ham Hacks: Breaking into the World of Software Defined Radio</em> does just that.</p>

<p>
  <iframe src="https://www.youtube.com/embed/LIcE0frWtLo" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<p>Software Defined Radio is here and we as hams need to explore all the potential the technology has to offer. Currently full SDR transceivers are available from Flex Radio, and the major ham radio manufactures are beginning to produce hybrid SDR transceivers. With SDRs such as the BladeRF 2.0, LimeSDR and the HackRF One the entry point into software defined radio is relatively low. These lowcost SDRs make excellent platforms for experimentation within the VHF/UHF bands. The <a href="https://www.youtube.com/c/TechMindsOfficial">YouTube channel Tech Minds</a> has some excellent videos of what these little radios can do.</p>

<p>
  <iframe src="https://www.youtube.com/embed/qx_orXHiQk8" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<h3 id="3-provide-communities-that-foster-technical-discussion-and-exploration">3. Provide Communities That Foster Technical Discussion and Exploration</h3>
<p>It’s been my experience that local radio club are more focused on emergency communications rather than the more technical aspects of ham radio (Seriously, why so much obsession with emergency communications?). Most of the anecdotal evidence I’ve collected has suggested this is a common occurrence around the United States. This type of focus doesn’t foster an environment of learning and exploration. Why would the hacker community want to participate, in discussions about who’s going provide communications “support” on the corner of Elm and Main St. during the annual Forth of July parade? You need to create the type of environment where the discussion is focused on RF technology. If you can’t do that locally in person or over the air, then it’s time to turn to the digital voice modes. That’s right, DStar, DMR, and System Fusion provide an opportunity to essentially create local communities of common interest. Access to these communities are as easy as connecting to one’s hotspot; I guess you could present the argument that some repeaters are connected to these digital networks and blah blah blah. Hotspots! That’s what the cool kids are doing these days. As an aside, <a href="https://www.kj7nzl.net/blog/building-my-own-lonestar-electronics-mmdvm-hotspot/">check out my new hotspot</a>.</p>
<h4 id="introducing-the-radio-hackers-ysf-reflector">Introducing the Radio Hackers YSF Reflector</h4>
<p>In my efforts to better understand the System Fusion and WiresX Network and how they relate to each other, I created a YSF Reflector called Radio Hackers. As you may have guessed this is the beginning stages of the hacker community, I’m fostering among ham radio operators. This is by nowhere complete and I welcome you to assist me in any way that you can. The most significant thing you can do is inform others and join in on the discussion on the reflector.</p>
<ul>
<li>ID: 33360</li>
<li>Name: Radio Hackers</li>
<li>Dashboard: <a href="http://hackers.ysf.kj7nzl.net/">http://hackers.ysf.kj7nzl.net</a></li>
<li>Bridged Networks: TBD</li>
</ul>
<p>If anyone knows more about bridging networks together with XLX please reach out to me. I’d love to speak with you more. My contact information is provided on the <a href="https://www.kj7nzl.net/">home page</a> of this site.</p>

  </div>
</section></div>]]>
            </description>
            <link>https://www.kj7nzl.net/blog/ham-radio-needs-to-embrace-the-hacker-community-now-more-than-ever/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199686</guid>
            <pubDate>Tue, 24 Nov 2020 16:09:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Aurora 7 Prototype – 7 Screen Laptop]]>
            </title>
            <description>
<![CDATA[
Score 180 | Comments 171 (<a href="https://news.ycombinator.com/item?id=25199499">thread link</a>) | @882542F3884314B
<br/>
November 24, 2020 | https://expanscape.com/the-aurora-7-prototype/the-story-of-the-aurora-7/ | <a href="https://web.archive.org/web/*/https://expanscape.com/the-aurora-7-prototype/the-story-of-the-aurora-7/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="Actual_Page_Container">

<!-- REVOLUTION SLIDER -->

<!-- /REVOLUTION SLIDER --><!-- -->

<section>
<div>





<h2>Prototype Objective Summary:</h2>

<p>Very simple :) - Design and build a proper mobile Security Operations Center.</p>

<p>I always knew this would be an ambitious undertaking. Power considerations, structural rigidity, actual portability and the ability to be easily and quickly compactible were priorities. For a further break down of the objectives please read on.</p>



<h2>Prototype Objective Breakdown and Achievement percentage:</h2>

<p>This is a breakdown of the objectives. It also shows how much of the objective in percentage was achieved with the Aurora 7 Prototype.</p>

<div>


<div><p><label><span>100%</span> 6 Cores or more at 5GHZ capability </label></p>
</div>

<div><p><label><span>100%</span> Fully integrated Multi Touch Screen in Palm rest </label></p>
</div>

<div><p><label><span>100%</span> 4 x 17.3 UHD/4K Screens </label></p>
</div>

<div><p><label><span>70%</span> Ability to easily replace parts </label></p>
</div>

<div><p><label><span>70%</span> Ability to swap wiring and parts with easily attainable parts </label></p>
</div>

<div><p><label><span>90%</span> Rechargeable battery system fully self contained </label></p>
</div>

<div><p><label><span>70%</span> Easily Replaceable batteries </label></p>
</div>



<div><p><label><span>100%</span> NVIDIA GTX 10 Series Graphics </label></p>
</div>

<div><p><label><span>100%</span> Separate Programmable System Monitor LCD </label></p>
</div>

<div><p><label><span>100%</span> User/Arduino accessible Embedded Microcontroller. </label></p>
</div>





<div><p><label><span>100%</span> Ability to fold down compactly to facilitate travel </label></p>
</div>

<div><p><label><span>100%</span> Full NO-NONSENSE 104 Key tactile backlit Keyboard. </label></p>
</div>

<div><p><label><span>80%</span> Overall Structural Rigidity </label></p>
</div>



<div><p><label><span>100%</span> Everything folds or swivels out of the primary chassis (NO appendages) </label></p>
</div>



<div><p><label><span>100%</span> Out of band always visible battery gauge </label></p>
</div>



<div><p><label><span>100%</span> More than 16TB SSD Storage potential </label></p>
</div>
</div>

</div>
</section>

</div></div>]]>
            </description>
            <link>https://expanscape.com/the-aurora-7-prototype/the-story-of-the-aurora-7/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199499</guid>
            <pubDate>Tue, 24 Nov 2020 15:50:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Don't Work With Startups (Or FAANGs)]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25199374">thread link</a>) | @elliotbnvl
<br/>
November 24, 2020 | https://devcareer.elliotbonneville.com/no-startups-or-faangs | <a href="https://web.archive.org/web/*/https://devcareer.elliotbonneville.com/no-startups-or-faangs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article id="block-no-startups-or-faangs"><p><span><span>This chapter is not a hard and fast set of rules you should always abide by, but is some reasoning and facts that I’ve found to be true about picking a company to work for, while optimizing for a high rate, freedom, and flexibility.</span></span></p><p><span><span>The tl;dr version is that you shouldn’t work with startups, because they are high pressure and don’t pay well, and you shouldn’t work with household names (Facebook, Amazon, Google, Netflix, and their ilk) because they don’t provide as much flexibility.</span></span></p><p><span><span>Instead, you should target a sweet spot right in the middle, working with companies who have enough money to pay you well, but aren’t large enough and well-run enough that they can afford to be extremely exclusive and demanding of their employees.</span></span></p><p><span><span>As a side effect of their size, these companies often have pressing technical issues that are growing pains which haven’t been resolved yet that you can be of real value in solving. Working with them leads to doing high-value, satisfying work that pays well and affords you freedoms you wouldn’t otherwise find.</span></span></p><p><span><span>We’ll clear up some common misunderstandings and establish our reasoning by tackling this topic from first principles, as per usual.
</span></span></p><p><span><span><em>This post is an early release chapter of </em></span><span><em><a href="https://devcareer.elliotbonneville.com/">a book I'm writing in public</a></em></span><span><em>, working title of </em></span><span>Refactor Your Career</span><span><em>. If you're interested in following along for more prerelease chapters and other info, you can sign up for the newsletter below:</em></span></span></p><h2 id="block-b97dcd7b406e467b87a25fbcb87546ba"><span id="b97dcd7b406e467b87a25fbcb87546ba"></span><span><span>Don’t work with startups</span></span></h2><p><span><span>The definition of a startup is “a company prioritizing fast growth over everything else.”</span></span></p><p><span><span>Given the current economic incentive structure of the venture capital model, startups often take outside investment to grow more quickly.</span></span></p><p><span><span>As a result, startups typically optimize to get as much done with as little money and in as little time as possible, because they are not cash-flow positive and have limited financial runway.</span></span></p><p><span><span>Therefore, they are incentivized to find extremely high return-on-investment employees who will work long hours for little money. To find these employees, they will use a number of strategies:</span></span></p><ul><li id="block-53700a214aaf4831be4625f6876e0ed7"><span><span>Offer equity instead of cash compensation</span></span></li><li id="block-2b21919a7bb64e3e962a21fd7d352e42"><span><span>Offer “fun” benefits (beer, ping pong table, catered lunches, free movie tickets, etc.)</span></span></li><li id="block-bb36db0b8db44966b9505bbb5ec4ea1a"><span><span>Target young, talented, and hardworking engineers who are new to the industry and don’t have connections</span></span></li></ul><p><span><span>An extremely high return-on-investment employee is always getting the short end of the stick. The money has to come from somewhere, and in this case the money is coming from the employees’ pockets.</span></span></p><p><span><span>As an aside, your employer wins when they get the most bang for their buck, but the more bang they get for their buck, the less bang you get in return for the most valuable resource you possess -- your time.</span></span></p><p><span><span>At its core, hourly billing is a profoundly adversarial relationship, and you need to understand the rules by which it operates in order to not be taken advantage of. If you don’t know the rules of the game, you will lose. If you know the rules of the game and don’t play to them, you will lose. If you want to win, you must play intelligently, intentionally, and aggressively.</span></span></p><p><span><span>Hourly billing is just the beginning. As you grow in skill and “career capital” (c.f. </span><span><a href="https://www.amazon.com/Good-They-Cant-Ignore-You-ebook/dp/B0076DDBJ6" target="_blank" rel="noopener noreferrer"><em>So Good They Can’t Ignore You</em></a></span><span>, Cal Newport), you’ll want to explore ways to move away from hourly billing to a better way of billing, i.e. separating time worked from results delivered. Big benefits to you and your clients all the way around. Jonathan Stark writes eloquently on the issues with hourly billing </span><span><a href="https://jonathanstark.com/the-moral-dilemma-of-hourly-billing" target="_blank" rel="noopener noreferrer">here</a></span><span>.</span></span></p><p><span><span>Let’s take a deeper look at the strategies startups use to find employees, and why that means working for one is usually a bad strategy.</span></span></p><h3 id="block-5b675128f52f4bc7ae0ffadf51c842d9"><span id="5b675128f52f4bc7ae0ffadf51c842d9"></span><span><span>Taking equity is becoming a micro venture capitalist</span></span></h3><p><span><span>Venture capitalism is a bet on the future. Even the best venture capitalists lose money on most of their investments. They only turn a profit because they invest at scale and need just a couple of big wins per batch of investments in order to make up for that extremely high percentage of losses. They also study investing all day, every day, and are surrounded by people all doing the exact same thing.</span></span></p><p><span><span>Second, time is fungible. If you want, you can trade time for money directly (that’s what hourly billing is, after all). Therefore, an investment of time is an investment of your personal funds.</span></span></p><p><span><span>As a result, if you take equity compensation instead of cash when working at a startup, you are investing your money directly into that startup.</span></span></p><p><span><span>Given all of the above and bearing in mind that venture capitalism is a high risk bet that only works at scale for people who exclusively study how to invest, the odds that you are going to make a return on your investment with the limited amount of resources that you have to invest is vanishingly low.</span></span></p><p><span><span>Don’t try to play venture capitalist with the most valuable thing you have -- your time.</span></span></p><p><span><span><a href="https://www.jwz.org/about.html" target="_blank" rel="noopener noreferrer">Jamie Zawinski</a></span><span> (OG programmer, one of the founders of Netscape and Mozilla.org, the guy who probably wrote your screensaver, and now a dance club proprietor [yes, really]) has this to say about working for startups:</span></span></p><blockquote id="block-bf5cc1f488d24661902d79343aefc830"><span><span>Follow the... money. When a VC tells you what's good for you, check your wallet, then count your fingers.

He's telling you the story of, "If you bust your ass and don't sleep, you'll get rich" because the only way that people in his line of work get richer is if young, poorly-socialized, naive geniuses believe that story! Without those coat-tails to ride, VCs might have to work for a living. Once that kid burns out, they'll just slot a new one in.</span></span></blockquote><p><span><span>You can read the full post from 2011 </span><span><a href="https://www.jwz.org/blog/2011/11/watch-a-vc-use-my-name-to-sell-a-con/" target="_blank" rel="noopener noreferrer">here</a></span><span> and I highly encourage you to do so. It’s a zinger.</span></span></p><h3 id="block-ffa7baffd6a6461a9f9db8658d9237c6"><span id="ffa7baffd6a6461a9f9db8658d9237c6"></span><span><span>Empirically, equity is not as valuable as it seems</span></span></h3><p><span><span>Backing up the logic above, loose empirical analysis shows that if you look at total startup compensation as income combined with equity </span><span><em>adjusted for likelihood of realizing that equity’s value</em></span><span>, statistically you end up making less money in the end.</span></span></p><p><span><span>Patrick McKenzie, a well-known entrepreneur and prolific writer, and currently working at Stripe to “increase the GDP of the internet,” has this to say on the topic of valuing equity grants:</span></span></p><blockquote id="block-f861c0e363034719a6aa4cf4032f0005"><span><span>Roll d100. (Not the right kind of geek? Sorry. rand(100) then.)

0~70: Your equity grant is worth nothing.

71~94: Your equity grant is worth a lump sum of money which makes you about as much money as you gave up working for the startup, instead of working for a megacorp at a higher salary with better benefits.

95~99: Your equity grant is a lifechanging amount of money. You won’t feel rich — you’re not the richest person you know, because many of the people you spent the last several years with are now richer than you by definition — but your family will never again give you grief for not having gone into $FAVORED_FIELD like a proper $YOUR_INGROUP.

100: You worked at the next Google, and are rich beyond the dreams of avarice. Congratulations.

Perceptive readers will note that 100 does not actually show up on a d100 or rand(100).</span></span></blockquote><p><span><span>Dan Luu, another well-known developer and blogger, has this to say on the subject:</span></span></p><blockquote id="block-841b5199ddf14a02af23c89b2adf0131"><span><span>For a more serious take that gives approximately the same results, 80000 hours finds that the average value of a YC founder after 5-9 years is $18M. That sounds great! But there are a few things to keep in mind here. First, YC companies are unusually successful compared to the average startup. Second, in their analysis, 80000 hours notes that 80% of the money belongs to 0.5% of companies. Another 22% are worth enough that founder equity beats working for a big company, but that leaves 77.5% where that's not true.

If you're an employee and not a founder, the numbers look a lot worse. If you're a very early employee you'd be quite lucky to get 1/10th as much equity as a founder. If we guess that 30% of YC startups fail before hiring their first employee, that puts the mean equity offering at $1.8M / .7 = $2.6M. That's low enough that for 5-9 years of work, you really need to be in the 0.5% for the payoff to be substantially better than working at a big company unless the startup is paying a very generous salary.</span></span></blockquote><p><span><span>You can read the rest of Patrick’s post </span><span><a href="https://www.kalzumeus.com/2011/10/28/dont-call-yourself-a-programmer/" target="_blank" rel="noopener noreferrer">here</a></span><span>, and the rest of Dan’s post </span><span><a href="https://danluu.com/startup-tradeoffs/" target="_blank" rel="noopener noreferrer">here</a></span><span>. I highly recommend that you do so; they are erudite writers with a lot of insight into the industry.</span></span></p><h3 id="block-886c6f74b682471f90e8c002e01f09c9"><span id="886c6f74b682471f90e8c002e01f09c9"></span><span><span>Startup benefits are the cheese in the mousetrap</span></span></h3><p><span><span>While it might seem rather cynical, the benefits at a startup are just the cheese in the mousetrap. If you calculate the actual cash value of the benefits that many startups offer, you’ll find that they’re laughably low. Free beer, access to the company ping pong table (that never gets used), free movie tickets and a two hundred dollar per month business learning stipend actually work out to a relatively low amount of cold, </span><span><del>hard</del></span><span> mildly wrinkled Franklins.</span></span></p><p><span><span>Even things that are seemingly inherent to the unpurchasable, intangible benefits of startup culture like an open desk plan, brilliant and intense coworkers, and technically cutting-edge work can all be had elsewhere for a fraction of the time-cost of working at a startup if you’re willing to think outside the box.</span></span></p><p><span><span>Given that remaining within this particular box is so expensive, I highly encourage you not to do so without full understanding of what you’re doing.</span></span></p><p><span><span>If you can make $80/hr at a startup and $130/hr at a regular company, you are paying the startup $50/hr for the privilege of working there. For $50/hr, you can figure out a way to get most of the same benefits and come out way, way ahead.</span></span></p><p><span><span>Do what makes you happy, but do it with your eyes open. Also, if you really want to work at a startup, you might be better served by starting one.</span></span></p><h2 id="block-aebdc986fc9a4a39917e802441860771"><span id="aebdc986fc9a4a39917e802441860771"></span><span><span>Don’t work with household names</span></span></h2><p><span><span>There’s a word that gets tossed around a lot in the communities where developers that talk about their careers hang out (Hacker News, Reddit, et. al.) -- FAANG. It’s an acronym that refers to Facebook, Apple, Amazon, Netflix, and Google.</span></span></p><p><span><span>People talk about these companies (which pretty much are all out in Silicon Valley or in Seattle) so much that an acronym evolved as a catchall to refer to them. When I say “household name,” these are the companies …</span></span></p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://devcareer.elliotbonneville.com/no-startups-or-faangs">https://devcareer.elliotbonneville.com/no-startups-or-faangs</a></em></p>]]>
            </description>
            <link>https://devcareer.elliotbonneville.com/no-startups-or-faangs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199374</guid>
            <pubDate>Tue, 24 Nov 2020 15:35:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Disc as Dongle]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25199286">thread link</a>) | @mortenjorck
<br/>
November 24, 2020 | https://interuserface.net/2020/11/the-disc-as-dongle/ | <a href="https://web.archive.org/web/*/https://interuserface.net/2020/11/the-disc-as-dongle/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
          <!-- <style>
        body.single {
          background-color: #;
        }
      </style> -->
      <h3>November 23, 2020</h3>
      
      <p>One possible future of digital distribution is already here – in the guise of an existing format.</p>
      
<p><span>The industrial design</span> of the just-released Playstation 5 may be <a href="http://interuserface.net/2020/06/the-regressive-design-of-the-playstation-5/" data-type="post" data-id="633">regressive</a>, but it looks to the future in one critical way: Judging by the ungainly grafting-on of its disc drive, its original conception as a digital-only console is unmistakable.</p>



<p>For many, digital-only is a conflicting proposition. It curtails long-established freedoms of lending and resale, yet most would agree that it is also inevitably the future. But it doesn’t have to be the former. There is a solution – and it already exists.</p>



<p>The physical discs included with the retail versions of console games have served an increasingly marginal utility over the past console generation. Ever-larger day-one patches weigh in in the gigabytes. Triple-A games already require tens of gigabytes of data to be copied from the disc to the hard drive in order to manage load times, and the Playstation 5’s reliance on a super-fast SSD architecture only formalizes this. </p>



<hr>



<p><span>This leaves the disc</span> with precious little to actually do – it’s too slow to be played from, its data is often outdated by the time it’s installed, and as broadband speeds continue to inch upward, the read speed of even a modern Blu-ray drive is already slower than some fiber connections. Yet despite all this, the lowly disc still has one ace in the hole.</p>



<p>Even stripped of its value as a storage mechanism for game data, the disc serves a critical purpose: It is the physical manifestation of a license, an unencumbered and freely transferable token with which ownership of a game is immutably entangled. Future games could well ship with an essentially empty disc, relying on the network for everything else, yet the advantage of the disc-anchored license would remain undisputed. The disc allows one to, as memorably demonstrated in Sony’s 2013 response to Microsoft’s aborted digital-only Xbox play, simply <a href="https://www.polygon.com/2013/6/10/4417490/playstations-one-step-tutorial-on-sharing-used-games">hand that license to someone else.</a></p>



<hr>



<p><span>All this then invites the question:</span> Why does it have to be a <em>disc?</em> Why does a console need a noisy, mechanically complex, and expensive optical drive just to read a license? Professional software has long used USB peripherals, or dongles as they are semi-affectionately known, as the physical manifestation of licenses. The disc has become a dongle, so why not just use a dongle?</p>



<p>A few kilobytes and an encryption scheme are all that’s required to tie licenses to a physical device today. A tiny, inexpensive USB device could serve as the retail form factor for future games, ushering in an all-download future that retains nearly all the benefits of physical legacy formats. It could perhaps even, via firmware update, add “physical media” support to both the digital-only Playstation 5 and Xbox Series S.</p>
      <!-- <p class="metadata">
        Clayton Miller&ensp;&bull;&ensp;      </p> -->
      </article></div>]]>
            </description>
            <link>https://interuserface.net/2020/11/the-disc-as-dongle/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199286</guid>
            <pubDate>Tue, 24 Nov 2020 15:27:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interim analysis shows 91.4% efficacy for the Russian Sputnik vaccine]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199213">thread link</a>) | @yread
<br/>
November 24, 2020 | https://sputnikvaccine.com/newsroom/pressreleases/second-interim-analysis-of-clinical-trial-data-showed-a-91-4-efficacy-for-the-sputnik-v-vaccine-on-d/ | <a href="https://web.archive.org/web/*/https://sputnikvaccine.com/newsroom/pressreleases/second-interim-analysis-of-clinical-trial-data-showed-a-91-4-efficacy-for-the-sputnik-v-vaccine-on-d/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<ul>
<li>
<p>
<b><i>The efficacy of the Sputnik V vaccine is 91.4%, based on the second interim analysis of data obtained 28 days after administering the first dose</i></b> (7 days after the second dose).
</p>
<ul>
<li>
<p>
<b><i>Calculation was based on the analysis of data on volunteers (n = 18,794) who received both the first and second doses</i></b><i> of the Sputnik V vaccine or placebo at the second control point (39 confirmed cases as of November 23, 2020) in accordance with the clinical trial protocol. </i>
</p>
</li>
</ul>
</li>
<li>
<p>
<b><i>Preliminary data from volunteers obtained 42 days after the first dose</i></b><i> (corresponds with 21 days after the second dose) <b>indicates an efficacy of the vaccine above 95%.</b> </i>
</p>
</li>
<li>
<p>
<i>The <b>interim research data will be published by the Gamaleya Center team in one of the leading international peer-reviewed medical journals.</b> Following the completion of Phase III clinical trials of the Sputnik V vaccine, Gamaleya Center will provide access to the full clinical trial report.</i>
</p>
</li>
  
<li>
<p>
<i>Currently, 40,000 volunteers are taking part in the Phase III double-blind, randomized, placebo-controlled clinical post-registration study of the Sputnik V vaccine in Russia, of whom more than <b>22,000 volunteers were vaccinated with the first dose and more than 19,000 volunteers with the first and second doses</b>.</i>
</p>
</li>
<li>
<p>
<i>There were <b>no unexpected adverse events during the trials</b>. Monitoring of the participants is ongoing.</i>
</p>
</li>
<li>
<p>
<b><i>The Sputnik V vaccine is based on a well-studied human adenoviral vector platform that has proven safe and effective with no long-term side effects </i></b><i>in more than 250 clinical trials globally conducted during the past two decades - while the history of the use of human adenoviruses in vaccine development began in 1953. More than 100,000 people have received approved and registered drugs based on human adenoviral vectors.</i>
</p>
</li>
<li>
<p>
<b><i>The uniqueness of the Russian vaccine lies in the use of two different human adenoviral vectors</i></b><i> which allows for a stronger and longer-term immune response as compared to the vaccines using one and the same vector for two doses.</i>
</p>
</li>
</ul>
<p>
<b>Moscow, November 24, 2020 –</b><b> </b>The National Research Center for Epidemiology and Microbiology named after N.F. Gamaleya of the Ministry of Health of the Russian Federation (Gamaleya Center) and the Russian Direct Investment Fund (RDIF, Russia’s sovereign wealth fund), announce positive results obtained during the second interim data analysis of the largest double-blind, randomized, placebo-controlled Phase III clinical trials in Russia’s history involving 40,000 volunteers. Gamaleya Center experts have once again confirmed the high efficacy of the Sputnik V vaccine, the world’s first registered vaccine against coronavirus based on a well-studied platform of human adenoviral vectors. <b>Evaluation of efficacy was carried out among volunteers (n = 18,794) 28 days after receiving the first dose (7 days after the second dose) of the vaccine or placebo upon reaching the second check point of the trial in compliance with the clinical trial protocol. The analysis demonstrated a 91.4% efficacy rate for the Sputnik V vaccine. </b>
</p>
<div>
<center><img width="90%" alt="table_eng_spu.jpg" data-src="/upload/medialibrary/70b/70bc3db939ed55ad755e935e8ae26df3.jpg" data-crc="5b1b93c0b54d98c83dc2e94e48f68aad" height="auto" title="table_eng_spu.jpg" src="https://sputnikvaccine.com/newsroom/pressreleases/second-interim-analysis-of-clinical-trial-data-showed-a-91-4-efficacy-for-the-sputnik-v-vaccine-on-d/table_eng_spu.jpg"></center>
</div>
<p>
According to the protocol of Phase III clinical trials of the Sputnik V vaccine, its interim efficacy is calculated at three statistically significant representative check points - upon reaching 20, 39 and 78 cases of novel coronavirus infection among volunteers both in the placebo group and in the group that received the vaccine. The second interim analysis of the Sputnik V vaccine efficacy was carried out on the basis of 39 confirmed cases identified in the placebo group (31 cases) and in the vaccine group (8 cases). The ratio of the placebo group to the vaccinated group is 1 to 3.
</p>
<p>
The uniqueness of the Russian vaccine lies in the use of two different vectors based on the human adenovirus, which allows for a stronger and longer-term immune response as compared to vaccines using one and same vector for two doses. <b>So, preliminary data on volunteers on the 42nd day after the first dose (equivalent to 21 days after the second dose), when they have already formed a stable immune response, indicates the efficacy rate of the vaccine is above 95%.</b>
</p>
<p>
The next interim data analysis will be conducted upon reaching the third check point of 78 confirmed coronavirus cases among the study participants. Final data analysis will be available by the end of Phase III clinical trials.
</p>
<p>
The interim research data will be published by the Gamaleya Center team in one of the leading international peer-reviewed medical journals. Following the completion of Phase III clinical trials of the Sputnik V vaccine, Gamaleya Center will provide access to the full clinical trial report.
</p>
  
<p>
As of November 24 more than 22,000 volunteers were vaccinated with the first dose and more than 19,000 volunteers with the first and the second dose of the vaccine at 29 medical centers in Russia as part of the ongoing clinical trials. Currently Phase III clinical trials are approved and are ongoing in Belarus, the UAE, Venezuela and other countries, as well as Phase II-III in India.
</p>
<p>
As of November 24, no unexpected adverse events were identified as part of the research. Some of those vaccinated had short-term minor adverse events such as pain at the injection point and flu-like symptoms including fever, weakness, fatigue, and headache.
</p>
<p>
During the clinical trials, the safety of the vaccine is constantly being monitored; information is analyzed by the Independent Monitoring Committee comprising leading Russian scientists. Collection, quality control and data processing is conducted in line with ICH GCP standards and involves the active participation of Moscow’s Health Department and Crocus Medical, the contract research organization (CRO).
</p>
<p>
<b>Mikhail Murashko, Minister of Health of the Russian Federation,</b> said:
</p>
<p>
“The data demonstrating high efficacy of the Sputnik V vaccine give us hope that we will soon obtain the most important tool in the fight against the pandemic of the novel coronavirus infection”.
</p>
<p>
<b>Alexander Gintsburg, Gamaleya Center Director,</b> said:
</p>
<p>
“It is very important that the second interim efficacy analysis of Sputnik V has confirmed our findings from the first stage and shown its efficacy at 91-92%. Let me stress that the second analysis was conducted a week after volunteers got the second dose, meaning that their bodies have partially reacted to both doses. We expect the efficacy rate to be even higher based on the data three weeks after the second immunization when the body’s strongest and most stable response is achieved. We plan to conduct the third interim data analysis after 78 confirmed coronavirus cases among volunteers and we have every reason to believe that the results will exceed our initial expectations. The drug’s final efficacy assessment will be made available after Phase III clinical trials are concluded.”
</p>
<p>
<b>Denis Logunov, Gamaleya Center Deputy Director,</b> commented:
</p>
<p>
“Results from the second interim analysis of the Sputnik V vaccine are in line with our expectations and predictions. The vaccine’s high efficacy rate is an important indication that a stable immune response to the coronavirus infection is formed among the study’s participants. We expect that the next interim results will demonstrate Sputnik V’s positive traits, moving us closer to the study’s completion and the beginning of a mass vaccination of our fellow citizens.”
</p>
<p>
<b>Kirill Dmitriev, CEO, Russian Direct Investment Fund,</b> said:
</p>
<p>
“Gamaleya Center has developed one of the most efficient vaccines against coronavirus in the world with an efficacy rate of more than 90% and a price that is two times lower than that of other vaccines with similar efficacy rate. The uniqueness of the Russian vaccine lies in the use of two different human adenoviral vectors which allows for a stronger and longer-term immune response as compared to the vaccines using one and the same vector for two doses.”
</p>
<p>
***
</p>
<p>
The safety of vaccines based on human adenoviruses has been confirmed in more than 75 international publications and more than 250 clinical trials conducted during the past two decades - while the history of use of human adenoviruses in vaccine development started in 1953. Adenovirus vectors are genetically modified viruses of the regular flu that cannot reproduce in a human body. When the Sputnik V vaccine is used, the coronavirus itself does not enter the body as the vaccine only contains genetic information about part of its outer protein coat, the so called "spikes" forming its crown. This completely eliminates the possibility of getting infected as a result of vaccination while also causing the body's stable immune response.
</p>
<p>
On September 4, The Lancet, one of world’s leading medical journals, published a research paper on the results of Phase I and Phase II clinical trials of the vaccine that showed no serious adverse events and an effective immune response of those vaccinated.
</p>
<p>
Requests for more than 1.2 billion doses of Sputnik V vaccine came from more than 50 countries. The vaccine supplies for the global market will be produced by RDIF’s international partners in India, Brazil, China, South Korea and other countries.
</p>
<p>
On August 11, the Sputnik V vaccine developed by the Gamaleya Center was registered by Russia’s Health Ministry and became the world’s first registered vaccine against COVID-19. Detailed information on the Sputnik V vaccine, its human adenoviral vectors technological platform, and other details are available at&nbsp;<a href="https://sputnikvaccine.com/" target="_blank">sputnikvaccine.com</a>
</p>
<p>
<b>Be the first to learn about Sputnik V on social networks:</b>
</p>
<p>
<a href="https://twitter.com/sputnikvaccine" target="_blank">Twitter</a>
</p>
<p>
<a href="https://www.facebook.com/sputnikvaccine" target="_blank">Facebook</a>
</p>
<p>
<a href="https://www.instagram.com/sputnik_vaccine/" target="_blank">Instagram</a>
</p>
<p>
<a href="https://www.youtube.com/channel/UCLvQuKL3Nn7NnT9Jyi_dlgQ" target="_blank">Youtube</a>
</p>
<p>
***
</p>
<p>
<b>Russian Direct Investment Fund (RDIF)</b> is Russia's sovereign wealth fund established in 2011 to make equity co-investments, primarily in Russia, alongside reputable international financial and strategic investors. RDIF acts as a catalyst for direct investment in the Russian economy. RDIF’s management company is based in Moscow. Currently, RDIF has experience of the successful joint implementation of more than 80 projects …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sputnikvaccine.com/newsroom/pressreleases/second-interim-analysis-of-clinical-trial-data-showed-a-91-4-efficacy-for-the-sputnik-v-vaccine-on-d/">https://sputnikvaccine.com/newsroom/pressreleases/second-interim-analysis-of-clinical-trial-data-showed-a-91-4-efficacy-for-the-sputnik-v-vaccine-on-d/</a></em></p>]]>
            </description>
            <link>https://sputnikvaccine.com/newsroom/pressreleases/second-interim-analysis-of-clinical-trial-data-showed-a-91-4-efficacy-for-the-sputnik-v-vaccine-on-d/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199213</guid>
            <pubDate>Tue, 24 Nov 2020 15:20:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A lesson in creating and using niche business DSLs at scale]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198991">thread link</a>) | @rhnvrm
<br/>
November 24, 2020 | https://zerodha.tech/blog/a-lesson-in-niche-business-dsls-at-scale/ | <a href="https://web.archive.org/web/*/https://zerodha.tech/blog/a-lesson-in-niche-business-dsls-at-scale/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>At Zerodha, we process millions of trades in real-time, where each trade comes
into the system as concurrent high throughput HTTP requests. Each trade
increases the latency for subsequent orders in the queue that are under
processing at the same time at our OMS (Order Management System). When a single
order comes through to the OMS, it goes through a bunch of computationally
intensive validations and adds to the latency. To reduce the latency of orders,
we decided to offload some of these business validations from the OMS into an
external component called Veto, which pre-validates incoming orders based on
custom dynamic rules set by our Risk Management team. Rejected orders never go
through to the OMS thereby reducing significant load on the OMS. This is the
story of how we incrementally built this engine to keep up with the changing
business and regulatory environment starting with a custom DSL (Domain Specific
Language) and ending up with writing a framework to manage rules written in Go
and embedded inside Go plugins.</p><h2 id="overview">Overview</h2><p>Our goal with Veto was to build a dynamic evaluation engine framework capable of
hot-reloads. This framework would provide a generic environment to manage, track
and audit rules and filters on an easily accessible dashboard. The engine should
have support for custom data-stores related to the orders. Rules in this
framework are business validations on orders placed by our clients. These
validations range from simple checks like validating the limit prices to be
within circuit limits, to complex beasts, which <a href="https://support.zerodha.com/category/trading-and-markets/kite-web-and-mobile/articles/why-did-my-bank-nifty-option-order-get-rejected">validate fresh buy
orders</a>
in Nifty/BankNifty strikes due to exchange OI restrictions.</p><p><img src="https://zerodha.tech/static/images/bnf-veto-rejection.png" alt="banknifty-rejection-example"></p><p>Our first solution utilized our research from the
<a href="https://sentinel.zerodha.com/">Sentinel</a> project. We combined
<a href="https://github.com/Knetic/govaluate">knetic/govaluate</a>, which is an expression
evaluation engine, along with a filter manager and a hot reload mechanism with
an HTTP server which would either respond with an appropriate rejection to
the incoming order or proxy to the upstream OMS, thereby acting as a reverse
proxy with validations. The expression language was similar to Excel formulas,
which was familiar to our RMS Team that managed and operated it through custom
management dashboard built using <a href="https://frappe.io/">Frappe/ERPNext</a>.</p><h2 id="problems-with-dsls">Problems with DSLs</h2><p>After taking it live, we realized a bunch of issues that
cropped up and became pain points for us over time. These were not really technical,
but more or less, human usability issues.</p><ul><li><p>Since the underlying engine was a simple expression evaluator, the operators
would end up spending hours trying to write complex rules, and similarly the
developers, who are supposed to approve the rule to be production ready, spent
time reviewing it.</p><ul><li><p>This was due to how unreadable the expressions would become beyond a certain
complexity. Simple rules were indeed faster to write, but anything beyond
it would be beyond human capability to comprehend, which would cause
unnecessary and difficult debugging sessions in the office.</p></li><li><p>Unlike a regular language with branching, the operator writing the
rule would be stuck on writing logic defined with bracket matching
and <code>AND/OR</code> statements. Also, missing support for variables would not
allow us to reuse values.</p></li><li><p>To write a single complex rule, operators would depend on writing the rules
into manageable chunks. For example, a single spread (shown below) the rule would be broken
into <code>spread_ce_buy</code>, <code>spread_ce_sell</code>, <code>spread_pe_buy</code>, <code>spread_pe_sell</code>
rules.</p><p><img src="https://zerodha.tech/static/images/veto-govaluate-example.png" alt="Veto Govaluate Sample"></p></li></ul></li><li><p>Custom error messages and any non-boolean behaviour were not possible, as the
expression can only evaluate to a boolean. Switching to a proper language, we
could use early returns in the rule and return custom messages alongside the
evaluation result.</p></li><li><p>Implementing new functions and adding new variables was a pain.</p><ul><li>This meant that if you were to add a new function, you would have to bundle
it within the engine, defeating the purpose of the rules being dynamic.</li><li>This also meant the developer had to always be involved in writing the rules, defying the whole purpose of having a DSL for business folks.</li></ul></li></ul><h2 id="new-beginnings">New beginnings</h2><p>Our learnings from these issues made us reflect if it would be worth it for the
operators to keep using a simple expression language. The way we were going, we were
essentially building a DSL (Domain Specific Language) on top of <code>govaluate</code>,
that would keep getting more complex with time.</p><p>We finally decided that a solution to the problem was to use Go-like language as
the DSL instead of <code>govalute</code> and distribute the dynamic rules as Go plugins, as
Veto was written in Go in the first place, just like the rest of the Kite stack.
It is simple, easy to learn, and has good tooling around it.</p><p>We debated heavily on the best approach to solve the problems that we were
facing with veto rules and shortlisted a few candidates. We picked a complex rule in production written using govaluate and wrote that in the following to benchmark the performance of the rules in the alternatives.</p><ul><li><a href="https://github.com/Knetic/govaluate">Govaluate</a> - evaluates arbitrary C-like expressions</li><li><a href="https://github.com/containous/yaegi">Yaegi</a> - embedded go interpreter</li><li><a href="https://www.openpolicyagent.org/docs/latest/policy-language/">Rego</a> - open-policy-agent DSL</li><li><a href="https://github.com/hashicorp/go-plugin">Hashicorp Plugins</a> - plugin system over RPC.</li><li><a href="https://golang.org/pkg/plugin/">go-plugins</a> - native go plugins</li></ul><p>Benchmark Results:</p><div><pre><code data-lang="fallback">govaluate:
1319773 907 ns/op
go-plugins:
2745398 503 ns/op
yaegi:
202173 11091 ns/op
rego:
83476 13796 ns/op
</code></pre></div><p>We considered govaluate to be the baseline for our experiments. In our
benchmarks, native plugins outperformed other solutions and brought the power of
the entire Go runtime into independent plugins. We discarded Hashicorp plugins,
as they were slower. Yaegi was nice, but not as fast as govaluate. Govaluate and
Yaegi provide a simpler way to distribute rules, when compared to native plugins
which need a bit of orchestration.</p><h2 id="veto-v2">Veto v2</h2><p>Considering all the facts, we decided to go ahead with native Go plugins. They
are as fast as native code once loaded, and given enough tooling, act just like
regular Go code, along with all its niceties like type safety and none of the
baggage of other alternatives.</p><p>Veto v2 would be a web server which loads rules from native Go plugins on boot
and behave like a reverse proxy accepting incoming orders as HTTP requests,
either rejecting them in place or proxying them to the upstream OMS.</p><p>Since there are
<a href="#overcoming-go-plugin-caveats">problems</a> associated with building and
distributing plugins due to dependency issues, requiring in-tree building and
compilation, we decided to first work on writing a framework to abstract the
caveats associated with go plugins.</p><h3 id="a-framework-for-writing-rules">A framework for writing rules</h3><p>Rules in Veto v2 are now written in plain Go by the operators. A rule looks similar
to the following sample rule.</p><p>Each rule is expected to provide three functions.</p><p>Rules are contained in the <code>Validate</code> functions that are expected to accept an
interface and return a <code>rule.Result</code>. The contexts contain the controllers and
data needed for validating the rule, and are passed by the host to the rule
manager which iterates over all the rules. The host can then interpret the result
and do what it needs to, in our case render a response to the user with a custom
message, or proxy to the upstream.</p><p>Another added benefit of having written a custom go plugin based framework for
rules, is that we can implement our own testing framework for validation of the
rules. Every rule is expected to return its own testcases as a
<code>map[interface{}]e.Result</code> where the interface is the context. This way if a
rule implements all the testcases, we are sure that any minor refactor will be
also correct in the future. This reduces the need for constant developer
oversight and the testing needed for the rules. Also, the testcases provide
extra documentation for the future.</p><p>The following rule contains a sample circuit limit rule for illustration.</p><div><pre><code data-lang="go"><span>package</span> main

<span>import</span> (
    <span>...</span>
)

<span>// Slug is the identifier for the rule. Used in statistics and logging.
</span><span></span><span>func</span> <span>Slug</span>() <span>string</span> {
    <span>return</span> <span>"a_sample_ckt_limit_rule"</span>
}

<span>// Validate, is where the validation logic resides.
</span><span></span><span>func</span> <span>Validate</span>(data <span>interface</span>{}) (e.Result, <span>error</span>) {
    d, err <span>:=</span> m.<span>SetupOrderData</span>(data)
	<span>if</span> err <span>!=</span> <span>nil</span> {
		<span>return</span> e.Result{}, err
	}

    <span>...</span>

    <span>// Get the market for the incoming order
</span><span></span>    s, err <span>:=</span> d.Ticker.<span>GetSnapForOrder</span>(d.OrderData.Order)
	<span>if</span> err <span>!=</span> <span>nil</span> {
		<span>return</span> e.Result{}, err
	}

    <span>...</span>

	<span>// Check limits
</span><span></span>	<span>if</span> d.Order.Price &gt; s.UpperCircuitLimit {
		<span>return</span> e.Result{
			Result: <span>true</span>,
			Message: fmt.<span>Sprintf</span>(
				<span>"Your order price is higher than the current [upper circuit limit](https://support.zerodha.com/category/trading-and-markets/trading-faqs/articles/what-does-circuit-limits-i-e-price-bands-mean) of %g. You can place an order within the range or [use GTT](https://support.zerodha.com/category/trading-and-markets/gtt/articles/what-is-the-good-till-triggered-gtt-feature) for long-standing orders."</span>,
				s.UpperCircuitLimit),
		}, <span>nil</span>
	}

	<span>if</span> s.LowerCircuitLimit &gt; d.Order.Price {
		<span>return</span> e.Result{
			Result: <span>true</span>,
			Message: fmt.<span>Sprintf</span>(
				<span>"Your order price is lower than the current [lower circuit limit](https://support.zerodha.com/category/trading-and-markets/trading-faqs/articles/what-does-circuit-limits-i-e-price-bands-mean) of %g. You can place an order within the range or [use GTT](https://support.zerodha.com/category/trading-and-markets/gtt/articles/what-is-the-good-till-triggered-gtt-feature) for long-standing orders."</span>,
				s.LowerCircuitLimit),
		}, <span>nil</span>
	}

    <span>return</span> e.Result{}, <span>nil</span>
}

<span>// TestData is expected to be provided by the rule,
</span><span>// so it can be validated before it is allowed to be published.
</span><span></span><span>func</span> <span>TestData</span>() <span>map</span>[<span>interface</span>{}]e.Result {
	tckr <span>:=</span> <span>&amp;</span>ticker.Ticker{
		Data: <span>map</span>[<span>string</span>]<span>interface</span>{}{
			<span>"NSE:INFY"</span>: snaps.Snap{
				LastPrice:         <span>12.34</span>,
				UpperCircuitLimit: <span>15.0</span>,
				LowerCircuitLimit: <span>10.0</span>,
			},
		},
	}

	<span>return</span> <span>map</span>[<span>interface</span>{}]e.Result{
		<span>&amp;</span>m.OrderContext{
			Controllers: m.Controllers{
				Ticker:      tckr,
			},
			OrderData: m.OrderData{
				Order: oms.OrderParams{
					Exchange:      <span>"NSE"</span>,
					Tradingsymbol: <span>"INFY"</span>,
					Price:         <span>20.34</span>,
					OrderType:     <span>"LIMIT"</span>,
				},
			},
		}: e.Result{
			Result:  <span>true</span>,
			Message: <span>"Your order price is higher than the …</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zerodha.tech/blog/a-lesson-in-niche-business-dsls-at-scale/">https://zerodha.tech/blog/a-lesson-in-niche-business-dsls-at-scale/</a></em></p>]]>
            </description>
            <link>https://zerodha.tech/blog/a-lesson-in-niche-business-dsls-at-scale/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198991</guid>
            <pubDate>Tue, 24 Nov 2020 14:58:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Homemade recycling rig turns plastic waste into new products]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198780">thread link</a>) | @lysp
<br/>
November 24, 2020 | https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/ | <a href="https://web.archive.org/web/*/https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-26604">
<h3>Homemade recycling rig turns plastic waste into new products</h3>
<p> — <span>November 24th, 2020</span>
</p>
<div>
<figure><p><img src="https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6.jpg" alt="" srcset="https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6.jpg 1024w, https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6-300x225.jpg 300w, https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6-385x289.jpg 385w, https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6-768x576.jpg 768w" sizes="(max-width: 1024px) 100vw, 1024px"></p></figure>
<p>While that plastic cup, bag, dish, or other item may have served its purpose, more than likely it could be formed into something new. With this in mind, the SOTOP-Recycling team of Manuel Maeder, Benjamin Krause, and Nadina Maeder developed <a href="https://www.instructables.com/Automated-Injection-Molding-Machine-for-Plastic-Re/">an automated injection molding machine</a> that can be built at home and is small enough to allow you to run your own recycling operation!</p>
<figure><p><img src="https://blog.arduino.cc/wp-content/uploads/2020/11/Plastic-Shredder.png" alt="" srcset="https://blog.arduino.cc/wp-content/uploads/2020/11/Plastic-Shredder.png 1024w, https://blog.arduino.cc/wp-content/uploads/2020/11/Plastic-Shredder-300x218.png 300w, https://blog.arduino.cc/wp-content/uploads/2020/11/Plastic-Shredder-768x558.png 768w" sizes="(max-width: 1024px) 100vw, 1024px"></p></figure>
<p>The “Smart Injector” receives shredded pieces of plastic in a small hopper, then transports them down an extrusion pipe where heat is applied. This material is clamped together via a pair of stepper motors, with screws and timing belts implemented to apply sufficient pressure. Everything is controlled by an <a href="https://store.arduino.cc/mega-2560-r3">Arduino Mega</a>. </p>
<figure><p><img src="https://blog.arduino.cc/wp-content/uploads/2020/11/FEFM6F6KHKK52GD.jpg" alt="" srcset="https://blog.arduino.cc/wp-content/uploads/2020/11/FEFM6F6KHKK52GD.jpg 1024w, https://blog.arduino.cc/wp-content/uploads/2020/11/FEFM6F6KHKK52GD-300x200.jpg 300w, https://blog.arduino.cc/wp-content/uploads/2020/11/FEFM6F6KHKK52GD-768x512.jpg 768w" sizes="(max-width: 1024px) 100vw, 1024px"></p></figure>
<p>As shown in the video, the plastic waste is converted into phone covers in just minutes, though other things could also be made depending on the form tooling used.</p>
<figure><p>
<iframe title="Injection molding machine for recycling plastic" width="500" height="281" src="https://www.youtube.com/embed/Eq9IbetsLB4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>
<section>


<p>
<small>

You can follow any responses to this entry through the <a href="https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/feed/">RSS 2.0</a> feed.
You can <a href="#respond">leave a response</a>, or <a href="https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/trackback/" rel="trackback">trackback</a> from your own site.
</small>
</p>
</section>
</div>
</div></div>]]>
            </description>
            <link>https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198780</guid>
            <pubDate>Tue, 24 Nov 2020 14:39:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making 8500 plants available to you]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25198771">thread link</a>) | @roboben
<br/>
November 24, 2020 | https://permapeople.org/blog/2020/11/23/making-8500-plants-available.html | <a href="https://web.archive.org/web/*/https://permapeople.org/blog/2020/11/23/making-8500-plants-available.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><img src="https://permapeople.org/blog/assets/making-8500-plants-available-on-permapeople.jpg" alt="8500 plants available on Permapeople"></p>

<p><strong>tl;dr We made ~8500 plants available to you by importing the Plant For a Future dataset. You can use it now to create lists, guilds and help improving that data.</strong></p>

<p>The first thing I did when I started Permapeople was to look at other plant databases and platforms with a similar focus. If you ever were in the situation to try to get some information about specific plants, especially attributes which are important for a Permaculture style of gardening, there is a high chance you found <a href="https://pfaf.org/">Plants for a Future</a> (PFAF). It is a database started by Addy and Ken Fern, later turned into a not for profit organization operated by a handful of trustees. In recent years, they refocused their work on plants’ role in fighting climate change through carbon sequestration. If you don’t know them, you should definitely check them out.</p>

<p>I put a lot of consideration into importing the PFAF database into Permapeople, but decided against it in the beginning. The more I talked to people and our first users, I figured that using existing datasets saves contributors a lot of time and provides an immediate value. Most people I talked to are beginners or people running larger gardening operations, and I wanted to create something that could help them immediately in their projects. I think the PFAF database is one of the best resources available, but I found some problems with it, limiting its usefulness.</p>

<h2 id="data-quality">Data Quality</h2>

<p>While the PFAF dataset is probably the biggest by numbers and completeness, it has a few problems: Many things are outdated, incorrect, ambiguous, or incoherent. Some might think that plant data and its field, <em><a href="https://en.wikipedia.org/wiki/Botany">botany</a></em> is a static field. Actually, it is really the opposite: New discoveries, nomenclature changes, and fresh scientific research comes in weekly. Keeping track of this with a tiny circle of paid workers is a tough job to do. Even if you could contribute a fix, there is no way of doing that. Crowdsourcing this problem by letting anyone change the data could be very helpful. This is one of the main reasons I started Permapeople: I wanted to have one place to find up-to-date, correct, peer-reviewed information on the plants I want to grow. If I miss some info or find something incorrect, I can easily edit it and help everyone who needs this information after me. Think Wikipedia, but specifically for plants.</p>

<h2 id="no-clear-roadmap">No clear roadmap</h2>

<p>What makes working with PFAF data more challenging is that there is no information on if and when data gets corrected, updated, or added to PFAF. We do not know if and when new features will be added and if the organization will shift its focus to other projects in the future.</p>

<h2 id="unstructured-data">Unstructured Data</h2>

<p>While this is related to the data quality, the PFAF data is not structured and rather a full-text description of the plant. This makes it hard to find or sort through specific info because many attributes are not filterable and searchable. For example, while PFAF has great information on <em>companion planting</em>, it’s impossible to search based on these connections. You are left with searching through many plant profiles, reading long paragraphs, and scanning for the required information.</p>

<h2 id="missing-features">Missing features</h2>

<p>Having a database is great, but information seekers and contributors need some functionality to work with it. PFAF doesn’t provide any of that, and this is why we already added some of these missing features to Permapeople.</p>

<h3 id="see-the-editing-history-and-sources">See the editing history and sources</h3>

<p>A huge factor of why Wikipedia is so trustworthy is that every change is public and can be easily reviewed by anyone. This lets a user easily gauge any meta-information about a plant: Is this info credible or just a myth created by the hive-mind of the internet? Do many people agree with that info? Are there sources proving the correctness of the information? If yes, how many? Or how are people working within a similar climate to you faring with that plant?</p>

<h3 id="create-plant-connections-and-guilds">Create plant connections and guilds</h3>

<p>Companion planting and the more advanced <a href="http://www.neverendingfood.org/b-what-is-permaculture/permaculture-guilds/">concept of guilds</a> are a huge part of the success of Permaculture. At Permapeople, you can create explicit plant connections (may they be beneficial or adversary) and organize plants into guilds. This info can be fed back to the database and give users even better information: If two plants are used in many user-generated guilds, there is a high chance that these plants go well together.</p>

<p>Much of this functionality is in a very early stage, and we need your help and feedback to improve these features and the data itself. I hope this post helped you understand why I imported the PFAF dataset into Permapeople and how we plan to improve on the hard work PFAF and its contributors have already accomplished. In the best case, we can contribute our changes back to PFAF.</p>

<p>If you are interested, I suggest you try to <a href="https://permapeople.org/search">search for some plants</a> and <a href="https://permapeople.org/users/sign_up">sign up</a> to create your first list or guild.</p>

<p>Happy growing 🌱✌️,</p>

<p>Ben</p>

<p>PS: If you work for PFAF (or know someone who does), please reach out to us at hello at permapeople org - we’d love to talk about the future!</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://permapeople.org/blog/2020/11/23/making-8500-plants-available.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198771</guid>
            <pubDate>Tue, 24 Nov 2020 14:38:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A heat map and a new styling for Indoor= (Openstreetmap indoor mapping)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198621">thread link</a>) | @liotier
<br/>
November 24, 2020 | https://2metz.fr/blog/indoorequal-style-heatmap/ | <a href="https://web.archive.org/web/*/https://2metz.fr/blog/indoorequal-style-heatmap/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <article lang="en">
  
  <p><time datetime="2020-11-24 00:00:00 +0000">24 November 2020</time> - François</p>

  <p><em>For those who are not familiar with <a href="https://indoorequal.org/">indoor=</a>, I recommend consulting the <a href="https://2metz.fr/blog/indoorequal-openstreetmap-indoor-viewer/">introductory post</a>. In short, it’s a map that displays the interior spaces of OpenStreetmap with a level selector.</em></p>

<p>A new version is available with improvements such as the heat map and a new styling.</p>

<h2 id="heat-map">Heat map</h2>

<p>To rapidly visualize locations that are indoor mapped, <a href="https://indoorequal.org/">indoor=</a> can now display a low zoom heat map.</p>

<figure>
<img alt="A heat map to locate indoor mapped locations in OpenStreetMap" src="https://2metz.fr/assets/blog/indoorequal-heatmap-2adfe009e4cc18dda707f9c67f30822aaa9214b5c70c5bfcf4138a891d099a2e.png" integrity="sha256-Kt/gCeTMGN2nB/nGfzCCKqqSFLXHDFv89BOKiR0Jmi4=" crossorigin="anonymous">
<figcaption>A heat map to locate indoor mapped locations in OpenStreetMap</figcaption>
</figure>

<p>It will therefore be much easier to locate indoor mapped locations. Here are a few places that I discovered:</p>

<ul>
  <li><a href="https://indoorequal.org/#map=17.29/41.97637/-87.905125&amp;level=1">Chicago Airport, IL, USA</a></li>
  <li><a href="https://indoorequal.org/#map=17/1.360945/103.990497&amp;level=1">Singapore Airport, Singapor</a></li>
  <li><a href="https://indoorequal.org/#map=17.39/51.499368/-0.12456&amp;level=1">House of Commons, London, UK</a></li>
  <li><a href="https://indoorequal.org/#map=18.77/38.8977124/-77.0365066">The White House, Washington D.C., USA</a></li>
</ul>

<p>This work was carried out by <a href="https://pavie.info/">Adrien Pavie</a>.</p>

<h2 id="new-styling">New styling</h2>

<p>In order to clearly distinguish the different interior spaces, the styling has been largely revised.</p>

<ul>
  <li>Rooms with interest points are in blue</li>
  <li>The other rooms are in yellow</li>
  <li>Traffic areas are in white</li>
  <li>A specific icon set to make the click more explicit has been added</li>
</ul>

<p><img alt="" src="https://2metz.fr/assets/blog/indoorequal-style-15cf917174f4ade9112135a4eba075741fa9f425d2773012ee4f2b99425bbc02.png" integrity="sha256-Fc+RcXT0rekRITWk66B1dB+p9CXSdzAS7k8rmUJbvAI=" crossorigin="anonymous"></p>

<p>In addition to the indispensable vending machines for drinks and other delicacies, you will also be able to see the ping-pong and foosball tables.</p>

<figure>
<img alt="" src="https://2metz.fr/assets/blog/indoorequal-table-tennis-ffbf484050c0f460f56fbc6b970e06ccff738699c48a81a081d003dcc66eee08.png" integrity="sha256-/79IQFDA9GD1b7xrlw4GzP9zhpnEioGggdAD3MZu7gg=" crossorigin="anonymous">
<figcaption><a href="https://indoorequal.org/#map=20.38/48.8520471/2.2868159&amp;level=1&amp;poi=node:2741751144">A ping-pong table at the École Centrale d'Électronique, Paris, France</a></figcaption>
</figure>

<figure>
<img alt="" src="https://2metz.fr/assets/blog/indoorequal-table-soccer-3b34b8ab0cda0ff16fc9d67d2656656f7bc4a8e053bf50a1988002ef4caa6d5e.png" integrity="sha256-OzS4qwzaD/FvydZ9JlZlb3vEqOBTv1ChmIAC70yqbV4=" crossorigin="anonymous">
<figcaption><a href="https://indoorequal.org/#map=20.03/48.9024495/2.4005376&amp;level=0">A foosball table in Arkose, Pantin, France</a></figcaption>
</figure>

<p>This work was carried out by <a href="https://www.jawg.io/">Jawg</a>.</p>

<h2 id="other-improvements">Other improvements</h2>

<ul>
  <li>Multiple interest points have been added</li>
  <li>The display of the interior doors has been corrected</li>
</ul>

<h2 id="integrate-indoor-in-your-map">Integrate indoor= in your map</h2>

<p>Do you want to add interior spaces to your map? Use the <a href="https://github.com/indoorequal/mapbox-gl-indoorequal">mapbox-gl-indoorequal</a> library and create your free API key on <a href="https://indoorequal.com/">indoorequal.com</a>.</p>

<p>If you are not using mapbox-gl, the schema has been updated so you can make your own integration: <a href="https://indoorequal.com/schema">indoorequal.com/schema</a>.</p>

<hr>

<p>Thanks to everyone who contributed to this version.</p>

<p>To have a look at all of this, you can go on <a href="https://indoorequal.org/">indoor=</a>.</p>

<p>And to learn more about mapping indoor spaces, please visit the <a href="https://wiki.openstreetmap.org/wiki/Simple_Indoor_Tagging">wiki page Simple Indoor Tagging</a>.</p>


</article>

    </div></div>]]>
            </description>
            <link>https://2metz.fr/blog/indoorequal-style-heatmap/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198621</guid>
            <pubDate>Tue, 24 Nov 2020 14:19:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Always leave the code better than you found it]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25198597">thread link</a>) | @mooreds
<br/>
November 24, 2020 | https://letterstoanewdeveloper.com/2020/11/23/always-leave-the-code-better-than-you-found-it/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2020/11/23/always-leave-the-code-better-than-you-found-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Dear new developer,</p>



<p>I’ve spent a lot of my time maintaining working code. I think that is more typical of software developers than working in greenfield development. Yes, there are definitely jobs where you are writing more new code than maintaining, upgrading, bug fixing and improving old code (startups without product market fit being one, consulting being another) but in general code is expensive and folks want to run it for a long time. </p>



<p>Often you’ll jump into code to fix a bug, investigate an issue or answer a question.</p>



<p>When you do so, improve it. This doesn’t mean you rewrite it, or upgrade all the libraries it depends on, or rename all the variables. </p>



<p>You don’t need to transform it. </p>



<p>But you should make it better. Just clean it up a bit. Doing so makes everyone’s lives just a bit better, helps the codebase in a sustainable way, and assists the business by making its supporting infrastructure more flexible.</p>



<p>What are some ways to improve the code when you are in it?</p>



<p><strong>Document</strong></p>



<p>Whether that is a comment that explains something tricky, a larger piece of documentation external to the code which explains how to interact with it, or fixing a typo, trustworthy documentation is key to interacting with code. This is a good way to start improving a codebase because it has minimal impact on the actual code. Therefore it is low risk. But if you’ve ever had a great comment explain a confusing bit of code, you’ll appreciate the time this effort can save.</p>



<p>You can also help documentation by removing old, crufty docs. If you see a comment that doesn’t apply, remove it. If there’s cut and paste documentation which doesn’t apply, get rid of it. That cleans up the code for the next person to come along (who might be you).</p>



<p><strong>Write a test or improve a test</strong> </p>



<p>Tests help you write maintainable, extensible code that others can change fearlessly. If you run across code that isn’t tested and you have time and the supporting framework to write one, do so. </p>



<p>Even if it tests simple functionality such as “can I instantiate this object” or “how does this function react when I pass it two null values”, an additional test will help the robustness of the code. </p>



<p><strong>Refactor it</strong></p>



<p>This is one of the most flexible improvements. Refactoring code can range from renaming a variable to be more true to its nature to an overhaul of an entire module. Start small and don’t get wrapped up in perfection. Make the code clearer in intent. </p>



<p>It’s easy with refactoring to get wound around an axle and make too many changes and end up with broken things. Timeboxing is one technique I use to avoid, or at least minimize, my tendencies toward this when refactoring. If all I have is 30 minutes, I’ll make my changes smaller in scope.</p>



<p>A warning about refactoring. Don’t refactor what you don’t understand. Don’t drive by refactor. Discuss your plan with someone more familiar with the code; <code>git blame</code> is your friend. Especially if the code is not well tested, you want to make sure you don’t do more harm than good.</p>



<p><strong>Upgrade a dependency</strong></p>



<p>It’s sometimes a winding path, but upgrading your dependencies regularly is a good way to maintain the code. I remember working in a fork of struts. It was an important application for the company, but we didn’t spend the time upgrading the dependencies, because it was too painful. Eventually, parts of the code became harder to update. The entire application couldn’t benefit from newer technologies and paradigms because of the older dependencies holding it back. </p>



<p>It never feels good to spend time updating a dependency; to me this always feels like running in place. But if you don’t do so, eventually dependencies will end of life and you’ll be forced to update. That’ll be even less pleasant. </p>



<p>All of these actions not only help others because they improve the quality of the code, they also provide examples to other developers on how to do so. For example, it is far easier to write the second test in a suite than the first. You can cut and paste a lot of the setup code and tweak only what is different. The first bit of documentation will inspire more.</p>



<p>Code isn’t everything, but it is an important work output. Whenever you touch it, you should strive to leave it in a better place that it was before you did so.</p>



<p>Sincerely,</p>



<p>Dan</p>
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2020/11/23/always-leave-the-code-better-than-you-found-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198597</guid>
            <pubDate>Tue, 24 Nov 2020 14:16:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Common Lisp Iteration]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198573">thread link</a>) | @wooby
<br/>
November 24, 2020 | https://tailrecursion.com/~alan/Lisp/CommonLispIteration.html | <a href="https://web.archive.org/web/*/https://tailrecursion.com/~alan/Lisp/CommonLispIteration.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<p>
Created Monday 23 November 2020
</p>

<p>
Each of the following definitions of a <a href="https://en.wikipedia.org/wiki/Factorial" title="factorial">factorial</a> function demonstrate a way to <a href="https://en.wikipedia.org/wiki/Iteration#Computing" title="iterate">iterate</a> in <a href="https://en.wikipedia.org/wiki/Common_Lisp" title="Common Lisp">Common Lisp</a>, with brief notes. I hope that by demonstrating many different ways that the same thing can be written, you can develop a sense for the character of the constructs afforded by the language, and of the variety of possible styles. Common Lisp is famously syntactically extensible via <a href="https://en.wikipedia.org/wiki/Common_Lisp#Macros" title="macros">macros</a>, so keep in mind that my examples are by no means the <i>only</i> ways to iterate.
</p>

<p>
For further reading on the iteration and control structures of Common Lisp, I heartily recommend:
</p>

<ul>
<li><a href="http://www.gigamonkeys.com/book/macros-standard-control-constructs.html" title="Chapter 7">Chapter 7</a> and <a href="http://www.gigamonkeys.com/book/loop-for-black-belts.html" title="Chapter 22">Chapter 22</a> of <a href="https://amzn.to/3nOWKa2" title="Practical Common Lisp">Practical Common Lisp</a> by Peter Siebel.</li>
<li>A reasonably-priced used copy of <a href="https://amzn.to/2UUTfm3" title="ANSI Common Lisp">ANSI Common Lisp</a> by Paul Graham.</li>
</ul>


<p>
<i>Note: several of the examples return nonsensical results for negative inputs. The addition of <tt>(assert (not (minusp n)) </tt>or similar is a good idea, but I have omitted it here for clarity.</i>
</p>

<h2>DOTIMES</h2>

<pre>(defun factorial-dotimes (n &amp;aux (prod 1))
  (dotimes (i n prod)
    (setq prod (* prod (1+ i)))))
</pre>

<ul>
<li><a href="http://www.lispworks.com/documentation/HyperSpec/Body/03_dae.htm" title="&amp;aux lambda list keyword"><tt>&amp;aux</tt> lambda list keyword</a> names a local variable <tt>prod</tt>. <a href="http://www.lispworks.com/documentation/HyperSpec/Body/s_let_l.htm" title="LET"><tt>LET</tt></a> could also be used for this purpose, but at the cost of more indentation.</li>
<li><a href="http://www.lispworks.com/documentation/lw50/CLHS/Body/m_dotime.htm" title="DOTIMES"><tt>DOTIMES</tt></a> binds <tt>i</tt> successively from 0 to 1-n and finally evaluates to <tt>prod</tt>.</li>
</ul>


<h2>DO</h2>

<pre>(defun factorial-do (n)
  (do ((i 1 (1+ i))
       (prod 1 (* prod i)))
      ((&gt; i n) prod)))
</pre>

<ul>
<li><a href="http://www.lispworks.com/documentation/lw50/CLHS/Body/m_do_do.htm" title="DO"><tt>DO</tt></a> binds <tt>i</tt> to 1 and then to (1+ i) in subsequent iterations. <tt>prod</tt> is bound first to 1 and then to <tt>(* prod i)</tt> in subsequent iterations.</li>
<li>When the test clause <tt>(&gt; i n)</tt> becomes true, <tt>prod</tt> is returned. Contrast with the test clause of <tt>for</tt> loops in other languages, which terminate the loop when they become <i>false</i>.</li>
<li>I like the way Paul Graham explains <tt>DO </tt>and<tt> DO*</tt> in <a href="https://amzn.to/2UUTfm3" title="ANSI Common Lisp">ANSI Common Lisp</a>.</li>
</ul>


<h2>LOOP</h2>

<pre>(defun factorial-loop (n)
  (loop
     for i from 1 to n
     for prod = 1 then (* prod i)
     finally (return prod)))
</pre>

<ul>
<li><tt>i</tt> is bound from 1 to <tt>n</tt> inclusive.</li>
<li><tt>prod</tt> is bound to 1 and then <tt>(* prod i)</tt> in subsequent iterations in a manner similar to <tt>DO</tt>.</li>
<li>In the <tt>finally</tt> clause, <tt>prod</tt> is returned by <a href="http://www.lispworks.com/documentation/lw60/CLHS/Body/m_return.htm#return" title="RETURN"><tt>RETURN</tt></a> once iteration is complete. The <a href="http://www.lispworks.com/documentation/lw60/CLHS/Body/s_block.htm#block" title="BLOCK"><tt>BLOCK</tt></a> named NIL established by <tt>LOOP</tt> is the point of return.</li>
<li><a href="http://www.lispworks.com/documentation/lw50/CLHS/Body/m_loop.htm" title="LOOP"><tt>LOOP</tt></a> supports a comprehensive iteration and accumulation <a href="https://en.wikipedia.org/wiki/Domain-specific_language" title="DSL">DSL</a>. <a href="http://www.gigamonkeys.com/book/loop-for-black-belts.html" title="Chapter 22">Chapter 22</a> of <a href="https://amzn.to/3nOWKa2" title="Practical Common Lisp">Practical Common Lisp</a> offers a great introduction.</li>
</ul>


<h2>Recursion</h2>

<pre>(defun factorial-recursive (n)
  (if (zerop n)
      1
      (* n (factorial-recursive (1- n)))))
</pre>

<ul>
<li><tt>FACTORIAL-RECURSIVE</tt> calls itself, but when <tt>n</tt> exceeds the maximum stack size supported by the implementation, an error is signaled.</li>
</ul>


<pre>(defun factorial-tail-recursive (n)
  (labels ((recur (n prod)
             (if (zerop n)
                 prod
                 (recur (1- n) (* n prod)))))
    (recur n 1)))
</pre>

<ul>
<li><tt>FACTORIAL-TAIL-RECURSIVE </tt>does not call itself directly.</li>
<li>Instead, it defines with <a href="http://www.lispworks.com/documentation/HyperSpec/Body/s_flet_.htm" title="LABELS"><tt>LABELS</tt></a> an internal and recursive helper function, <tt>recur</tt>.</li>
<li>recur <a href="https://en.wikipedia.org/wiki/Tail_call" title="calls itself in tail position">calls itself in tail position</a> and the stack never overflows in implementations that implement tail-call elimination.</li>
</ul>


<h2>TAGBODY</h2>

<pre>(defun factorial-tagbody (n &amp;aux (i 0) (prod 1))
  (tagbody
     begin
     (when (eql i n)
       (return-from factorial-tagbody prod))
     (setq prod (* prod (incf i)))
     (go begin)))
</pre>

<ul>
<li><a href="http://www.lispworks.com/documentation/HyperSpec/Body/s_tagbod.htm" title="TAGBODY"><tt>TAGBODY</tt></a> is the most general but also the lowest-level and most verbose iteration construct.</li>
<li><a href="http://www.lispworks.com/documentation/HyperSpec/Body/03_dae.htm" title="&amp;aux lambda list keyword"><tt>&amp;aux</tt> lambda list keyword</a> names local variables <tt>i</tt> and <tt>prod</tt>, initializing them to 0 and 1, respectively.</li>
<li><tt>begin</tt> names a label within the <tt>TAGBODY</tt> that may be jumped to.</li>
<li><a href="http://www.lispworks.com/documentation/HyperSpec/Body/m_when_.htm" title="WHEN"><tt>WHEN</tt></a> <tt>i</tt> is <a href="http://www.lispworks.com/documentation/HyperSpec/Body/f_eql.htm" title="EQL"><tt>EQL</tt></a> to <tt>n</tt>, <a href="http://www.lispworks.com/documentation/lw60/CLHS/Body/s_ret_fr.htm" title="RETURN-FROM"><tt>RETURN-FROM</tt></a> returns <tt>prod</tt> from the <a href="http://www.lispworks.com/documentation/lw60/CLHS/Body/s_block.htm#block" title="BLOCK"><tt>BLOCK</tt></a> named after the function by <a href="http://www.lispworks.com/documentation/lw60/CLHS/Body/m_defun.htm" title="DEFUN"><tt>DEFUN</tt></a>.</li>
<li><a href="http://www.lispworks.com/documentation/HyperSpec/Body/s_go.htm" title="GO"><tt>GO</tt></a> jumps to <tt>begin</tt>.</li>
</ul>


</div></div>]]>
            </description>
            <link>https://tailrecursion.com/~alan/Lisp/CommonLispIteration.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198573</guid>
            <pubDate>Tue, 24 Nov 2020 14:14:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Digitizing Old 8mm Tapes]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25198435">thread link</a>) | @todsacerdoti
<br/>
November 24, 2020 | https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/ | <a href="https://web.archive.org/web/*/https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-660">
	<!-- .entry-header -->

	<div>
		
		<p>It’s astounding to think back and consider how much technological progress has occurred in just the past 15 years. Most folks today carry a smartphone in their pocket everywhere they go, and a great many of those smartphones have powerful cameras built in capable of recording multiple hours in high definition. Pair this ability with low-cost video editing software—<a href="https://www.blackmagicdesign.com/products/davinciresolve/" rel="noopener noreferrer" target="_blank">some of which comes at no cost at all</a>—and far more people today have the tools to practice shooting, editing, compositing, and rendering professional-looking videos on a modest budget.</p>
<p>My personal experience with photography began around age 7 shooting on <a href="https://en.wikipedia.org/wiki/110_film" rel="noopener noreferrer" target="_blank">110 film</a> using a small “spy” camera I got as a gift. My dad’s <a href="https://www.sony.com/electronics/support/product/ccd-v5" rel="noopener noreferrer" target="_blank">Sony CCD-V5</a> was bulky, heavy, and probably expensive when he bought it around 1987, so he was reluctant to let me or my sister operate it under his supervision, let alone borrow it to make our own films by ourselves. As a consequence, my sister and I kept ourselves entertained by making audio recordings on much cheaper audio cassette hardware and tapes—we produced an episodic “radio show” starring our stuffed animals long before the podcast was invented. Though my sister and I took good care of our audio equipment, Dad stuck to his guns when it came to who got to use the camcorder, but he would sometimes indulge us when we had a full production planned, scripted, and rehearsed. <a href="https://en.wikipedia.org/wiki/8_mm_video_format#Video8" rel="noopener noreferrer" target="_blank">Video8</a> tapes were expensive, too, and for the most part Dad reserved their use for important events like concerts, school graduations, birthdays, and family holidays.</p>
<figure id="attachment_706" aria-describedby="caption-attachment-706"><img data-attachment-id="706" data-permalink="https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/ccd-v5/" data-orig-file="https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?fit=528%2C390&amp;ssl=1" data-orig-size="528,390" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ccd-v5" data-image-description="" data-medium-file="https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?fit=300%2C222&amp;ssl=1" data-large-file="https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?fit=528%2C390&amp;ssl=1" loading="lazy" src="https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?resize=528%2C390&amp;ssl=1" alt="Sony CCD-V5 camcorder" width="528" height="390" srcset="https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?w=528&amp;ssl=1 528w, https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?resize=300%2C222&amp;ssl=1 300w, https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?resize=210%2C155&amp;ssl=1 210w" sizes="(max-width: 528px) 100vw, 528px" data-recalc-dims="1"><figcaption id="caption-attachment-706">I remember it being a lot bigger.</figcaption></figure>
<p>I went off to college and spent a <em>lot</em> of time lurking the <a href="https://originaltrilogy.com/" rel="noopener noreferrer" target="_blank">originaltrilogy.com forums</a>. It was here that not only did I learn a lot about the making and technical background of the Star Wars films (a topic I could blog about ad nauseum), but I also picked up a lot about video editing, codecs, post-production techniques, and preservation. OT.com was and still is home to a community of video hobbyists and professionals, most of whom share a common love for the <a href="https://starwarsviscomp.wordpress.com/" rel="noopener noreferrer" target="_blank">unreleased “original unaltered” versions</a> of the Star Wars trilogy. As such, many tips were/are shared as to how to produce the best “fan preservations” of Star Wars and other classic films given the materials available, sacrificing the least amount of quality.</p>
<p>I bought my dad a <a href="https://www.sony.com/electronics/support/product/hdr-cx100" rel="noopener noreferrer" target="_blank">Sony HDR-CX100</a> camcorder some years ago to supplement his by that time affinity for digital still cameras—he took it to Vienna and Salzburg soon after and has since transitioned to shooting digital video mostly on his iPhone. But the 8mm tapes chronicling my family’s milestones over the first 25 years of my life continued to sit, undisturbed, in my folks’ cool, dry basement. My dad has recordings on them going as far back as 1988 that I’ve found so far. These recordings are over 30 years old, so the tapes must be at least that age. </p>
<p>8mm video tape <a href="https://fstoppers.com/diy/unlocking-memories-8mm-tapes-324466" rel="noopener noreferrer" target="_blank">does not last forever</a>, but making analog copies of video tape incurs generational loss each time a copy is dubbed. On the other hand, a digital file can be copied as many times as one wants without any quality loss. All I need is the right capture hardware, appropriate capture software, enough digital storage, and a way to play back the source tapes, and I can preserve one lossless digital capture of each tape indefinitely. The last 8mm camcorder my dad bought—a <a href="https://www.sony.com/electronics/support/product/ccd-tr917" rel="noopener noreferrer" target="_blank">Sony CCD-TR917</a>—still has clean, working heads and can route playback of our existing library of tapes through its S-video and stereo RCA outputs. This provides me with the best possible quality given how they were originally shot.</p>
<hr>
<p>Generally with modern analog-to-digital preservation, you want to losslessly capture the raw source at a reasonably high sample rate with as little processing done to the source material as possible, from the moment it hits the playback heads to the instant it’s written to disk. Any cleanup can be done in post-production software; in fact, as digital restoration technology improves, it is ideal to have a raw, lossless original available to revisit with improved techniques. For this project, I am using my dad’s aforementioned <a href="https://www.sony.com/electronics/support/product/ccd-tr917" rel="noopener noreferrer" target="_blank">Sony CCD-TR917</a> camcorder attached directly to the S-video and stereo audio inputs of a <a href="https://web.archive.org/web/20150128124027/https://www.blackmagicdesign.com/products/intensity/models" rel="noopener noreferrer" target="_blank">Blackmagic Intensity Pro</a> PCIe card. The capturing PC is running Debian Linux and is plugged into the same circuit as the camcorder to avoid possible ground loop noise.</p>
<p>Since my Debian box is headless, I’m not interested in bringing up a full X installation just to grab some videos. Therefore I use the open source, command-line based <a href="https://github.com/lu-zero/bmdtools" rel="noopener noreferrer" target="_blank">bmdtools</a> suite—specifically bmdcapture—to do the raw captures from my Intensity Pro card. I do have to pull down the <a href="https://www.blackmagicdesign.com/developer/product/capture-and-playback" rel="noopener noreferrer" target="_blank">DeckLink SDK</a> in order to build bmdcapture, which does have some minor X-related dependencies, but I have to pull down the DeckLink software anyway for Linux drivers. I invoke the following from a shell before starting playback on the camcorder:</p>
<p><code>$ ./bmdcapture -C 0 -m 0 -M 4 -A 1 -V 6 -d 0 -n 230000 -f &lt;output&gt;.nut</code></p>
<p>The options passed to bmdcapture configure the capture as follows:</p>
<ul>
<li><code>-C 0</code>: Use the one Intensity Pro card I have installed (ID 0)</li>
<li><code>-m 0</code>: Capture using mode 0; that is, 525i59.94 NTSC, or 720×486 pixels at 29.97 FPS</li>
<li><code>-M 4</code>: Set a queue size of up to 4GB. Without this, bmdcapture can run out of memory before the entire tape is captured to disk.</li>
<li><code>-A 1</code>: Use the “Analog (RCA or XLR)” audio input. In my case, stereo RCA.</li>
<li><code>-V 6</code>: Use the “S-Video” video input. The S-video input on the Intensity Pro is provided as <a href="https://web.archive.org/web/20150122212738im_/https://images.blackmagicdesign.com/media/products/intensity/models/connections-intensitypro.png" rel="noopener noreferrer" target="_blank">an RCA pair</a> for chroma (“B-Y In”) and luma/sync (“Y In”); <a href="https://www.amazon.com/dp/B07K768YD1/" rel="noopener noreferrer" target="_blank">an adapter cable</a> is necessary to convert to the standard miniDIN-4 connector.</li>
<li><code>-d 0</code>: Fill in dropped frames with a black frame. The Sony CCD-TR917 has a built-in <a href="https://en.wikipedia.org/wiki/Time_base_correction" rel="noopener noreferrer" target="_blank">TBC</a> (which I leave enabled since I don’t own a separate TBC), but owing to the age of the tapes, there is an occasional frame drop.</li>
<li><code>-n 230000</code>: Capture 230000 frames. At 29.97 FPS, that’s almost 7675 seconds, which is a little over two hours. Should be enough even for full tapes.</li>
<li><code>-f &lt;output&gt;.nut</code>: Write to <code>&lt;output&gt;.nut</code> in the <a href="https://wiki.multimedia.cx/index.php/NUT" rel="noopener noreferrer" target="_blank">NUT container format</a> by default, substituting the tape’s label for <code>&lt;output&gt;</code>. The <a href="https://github.com/lu-zero/bmdtools/blob/master/README.md" rel="noopener noreferrer" target="_blank">README.md provided with bmdtools</a> suggests sticking with the default, and since FFmpeg has no trouble converting from NUT and I’ve had no trouble capturing to that format, I leave the output file format alone.</li>
</ul>
<p>Once I have my lossless capture, I compress the .nut file using bzip2, getting the file size down to up to a quarter of the original size depending on how much of the tape is filled. I then create parity data on the .bz2 archive <a href="https://en.wikipedia.org/wiki/Parchive" rel="noopener noreferrer" target="_blank">using the par2 utility</a>, and put my compressed capture and parity files somewhere safe for long-term archival storage. 🙂</p>
<p>My Windows-based Intel NUC is where I do most of my video post-production work. It lacks a PCIe slot, so I can’t capture there, but that’s fine because at this point my workflow is purely digital and I only have to worry about moving files around. My tools of choice here are AviSynth 2.6 and VirtualDub 1.10.4, but since AviSynth/VirtualDub are designed to work with AVI containers, I first convert my capture from the NUT container to the AVI container using FFmpeg:</p>
<p><code>$ ffmpeg.exe -i &lt;output&gt;.nut -vcodec copy -acodec copy &lt;output&gt;.avi</code></p>
<p>The options passed to FFmpeg are order-dependent and direct it to do the following:</p>
<ul>
<li><code>-i &lt;output&gt;.nut</code>: Use <code>&lt;output&gt;.nut</code> as the input file. FFmpeg is smart and will auto-detect its file format when opened.</li>
<li><code>-vcodec copy</code>: Copy the video stream from the input file’s container to the output file’s container; do not re-encode.</li>
<li><code>-acodec copy</code>: Likewise for the audio stream, copy from the input file’s container to the output file; do not re-encode.</li>
<li><code>&lt;output&gt;.avi</code>: Write to <code>&lt;output&gt;.avi</code>, again substituting my tape’s label for <code>&lt;output&gt;</code> in both the input and output filenames.</li>
</ul>
<div id=""><div>
<h2>A note about video containers vs. video formats</h2>
<p>Pop quiz! Given a file with the .mov extension, do you know for sure whether it will play in your media player?</p>
<p>Files ending with .mov, .avi, .mkv, and even the .nut format mentioned above are “container” files. When you save a digital video as a QuickTime .mov file, the .mov file is just a wrapper around your media, which must be encoded using one or more “codecs.” Codecs are small programs that can en<strong>co</strong>de and/or <strong>dec</strong>ode audio or video. These codecs must be specified at the same time as when you save your movie. QuickTime files can wrap among a great many codecs: Motion JPEG, MPEG, H.264, and Cinepak just to name a few. They’re a bit like Zip files, except that instead of files inside you have audio and/or video tracks, and there’s no compression other than what’s already done by the tracks’ codecs. Though Apple provides support in QuickTime for a number of modern codecs, older formats have been dropped over time and so any particular .mov file may or may not play… even using Apple’s own QuickTime software! Asking for a “QuickTime movie” is terribly vague—a QuickTime .mov file may not play properly on a given piece of hardware if support for a containing <em>codec</em> is missing.</p>
<p>AVI, MKV, and MP4 are containers, too—MP4 is in fact based on Apple’s own QuickTime format. But these are still just <em>containers</em>, and a movie file is nothing without some media inside that can be decoded. Put another way, when I buy a book I’m often offered the option of PDF, hardcover, or paperback form. But if the words contained therein are in Klingon, I still won’t be able to read it. When asked to provide a movie in QuickTime or AVI “format,” get the specifics—what codecs should be inside?</p></div></div>
<p>Now that I have an AVI source file, I can open it in VirtualDub. Owing to its namesake, VirtualDub’s interface is reminiscent of a dual cassette deck ready to “dub” from one container to another. It isn’t as user-friendly as, say, Premiere or Resolve when it comes to editing and compositing, but what it lacks in usability it gains in flexibility. In particular, VirtualDub is designed to run a designated range of source video through one or more “filters,” encoding to one of several output codecs available at …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/">https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/</a></em></p>]]>
            </description>
            <link>https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198435</guid>
            <pubDate>Tue, 24 Nov 2020 13:59:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gleam and Static Types with Louis Pilfold]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198388">thread link</a>) | @crowdhailer
<br/>
November 24, 2020 | https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold/ | <a href="https://web.archive.org/web/*/https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="fl-main-content" itemprop="mainContentOfPage" role="main">

		
<div>
	<div>

		
		<div>
			<article id="fl-post-6124" itemscope="" itemtype="https://schema.org/BlogPosting">

	
	<header role="banner">
		
		<meta itemscope="" itemprop="mainEntityOfPage" itemtype="https://schema.org/WebPage" itemid="https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold/" content="#023 Gleam and Static Types with Louis Pilfold"><meta itemprop="datePublished" content="2020-11-24"><meta itemprop="dateModified" content="2020-11-24"><div itemprop="publisher" itemscope="" itemtype="https://schema.org/Organization"><meta itemprop="name" content="Thinking Elixir"></div>	</header><!-- .fl-post-header -->

	
	
	<div itemprop="text">
		<p>
We talk with Louis Pilfold about how he created Gleam, a static typed language that runs on the BEAM. Louis explains some of the challenges with bringing static types to the BEAM and shares ideas on what can possibly be done about it. We learn how Gleam got started, how it works, and how Elixir and Erlang can interop with it. We cover the recently released Gleam OTP work, talk about Type Driven Development and much more!
</p>

<p>
  Show Notes online – <a href="https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold">https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold</a><br>
  
</p>
<p><strong>Elixir Community News</strong></p>

<ul>
<li><a href="http://devonestes.com/announcing_muzak" target="_blank" rel="noopener noreferrer">http://devonestes.com/announcing_muzak</a> – Devon Estes’ Muzak mutation testing library</li>
<li><a href="https://blog.appsignal.com/2020/11/17/announcing-appsignal-for-elixir-integration-2-0.html" target="_blank" rel="noopener noreferrer">https://blog.appsignal.com/2020/11/17/announcing-appsignal-for-elixir-integration-2-0.html</a> – AppSignal released 2.0 of their reporting tool</li>
<li><a href="https://github.com/phoenixframework/phoenix_live_view/pull/1223" target="_blank" rel="noopener noreferrer">https://github.com/phoenixframework/phoenix_live_view/pull/1223</a> – Phoenix LiveView file upload fix for components</li>
<li><a href="https://github.com/rrrene/credo" target="_blank" rel="noopener noreferrer">https://github.com/rrrene/credo</a> – Happy 5th birthday Credo!</li>
<li><a href="https://elixir-lang.org/blog/2020/11/17/real-time-collaboration-with-elixir-at-slab/" target="_blank" rel="noopener noreferrer">https://elixir-lang.org/blog/2020/11/17/real-time-collaboration-with-elixir-at-slab/</a> – New Elixir case-study looks at the collaborative wiki product Slab</li>
<li><a href="https://github.com/teamon/tesla/releases/tag/v1.4.0" target="_blank" rel="noopener noreferrer">https://github.com/teamon/tesla/releases/tag/v1.4.0</a> – Tesla v1.4.0 released – an Elixir HTTP client</li>
<li><a href="https://elixirforum.com/t/introducing-elixirls-the-elixir-language-server/5857/119" target="_blank" rel="noopener noreferrer">https://elixirforum.com/t/introducing-elixirls-the-elixir-language-server/5857/119</a> – ElixirLS version 0.6.2 released.</li>
<li><a href="https://dashbit.co/blog/you-may-not-need-redis-with-elixir" target="_blank" rel="noopener noreferrer">https://dashbit.co/blog/you-may-not-need-redis-with-elixir</a> – Jose Valim wrote a blog post addressing the idea of people saying “you don’t need Redis when you use Elixir”.</li>
<li><a href="https://baremessages.org/" target="_blank" rel="noopener noreferrer">https://baremessages.org/</a> – A new “binary serialization library” called “bare”. Aims to make Erlang data structures serialize easier in <em>other</em> languages</li>
<li><a href="https://sr.ht/~hauleth/BARE-Erlang/" target="_blank" rel="noopener noreferrer">https://sr.ht/~hauleth/BARE-Erlang/</a></li>
</ul>
<p>Do you know some Elixir news we don’t? Tell us at <a href="https://twitter.com/ThinkingElixir">@ThinkingElixir</a></p>
<p><strong>Discussion Resources</strong></p>

<ul>
<li><a href="https://github.com/gleam-lang/gleam" target="_blank" rel="noopener noreferrer">https://github.com/gleam-lang/gleam</a></li>
<li><a href="https://gleam.run/" target="_blank" rel="noopener noreferrer">https://gleam.run/</a></li>
<li><a href="https://gleam.run/news/gleam-v0.12-and-gleam-otp-v0.1-released/" target="_blank" rel="noopener noreferrer">https://gleam.run/news/gleam-v0.12-and-gleam-otp-v0.1-released/</a></li>
<li><a href="https://thinkingelixir.com/podcast-episodes/016-gleam-games-and-types-with-quinn-wilton/" target="_blank" rel="noopener noreferrer">https://thinkingelixir.com/podcast-episodes/016-gleam-games-and-types-with-quinn-wilton/</a></li>
<li><a href="https://github.com/gleam-lang/gleam/graphs/contributors" target="_blank" rel="noopener noreferrer">https://github.com/gleam-lang/gleam/graphs/contributors</a></li>
<li><a href="https://www.embark-studios.com/" target="_blank" rel="noopener noreferrer">https://www.embark-studios.com/</a></li>
<li><a href="https://racket-lang.org/" target="_blank" rel="noopener noreferrer">https://racket-lang.org/</a></li>
<li><a href="https://akka.io/" target="_blank" rel="noopener noreferrer">https://akka.io/</a></li>
<li><a href="https://developers.google.com/protocol-buffers/" target="_blank" rel="noopener noreferrer">https://developers.google.com/protocol-buffers/</a></li>
<li><a href="https://github.com/lalrpop/lalrpop" target="_blank" rel="noopener noreferrer">https://github.com/lalrpop/lalrpop</a></li>
<li><a href="http://www.elixir.london/2016/louis-pilfold" target="_blank" rel="noopener noreferrer">http://www.elixir.london/2016/louis-pilfold</a></li>
<li><a href="https://www.youtube.com/watch?v=IONWi9hayEA&amp;index=13&amp;list=PLWbHc_FXPo2ivlIjzcaHS9N_Swe_0hWj0" target="_blank" rel="noopener noreferrer">https://www.youtube.com/watch?v=IONWi9hayEA&amp;index=13&amp;list=PLWbHc_FXPo2ivlIjzcaHS9N_Swe_0hWj0</a></li>
<li><a href="https://gleam.run/community/" target="_blank" rel="noopener noreferrer">https://gleam.run/community/</a> – Join the Gleam Discord server</li>
<li><a href="https://twitter.com/louispilfold" target="_blank" rel="noopener noreferrer">https://twitter.com/louispilfold</a> – on Twitter</li>
<li><a href="https://github.com/lpil/" target="_blank" rel="noopener noreferrer">https://github.com/lpil/</a> – on Github</li>
<li><a href="https://lpil.uk/" target="_blank" rel="noopener noreferrer">https://lpil.uk</a> – Blog</li>
</ul>
<p><strong>Find us online</strong></p>
<ul>
<li>Message the show – <a href="https://twitter.com/ThinkingElixir" target="_blank" rel="noopener noreferrer">@ThinkingElixir</a></li>
<li>Mark Ericksen – <a href="https://twitter.com/brainlid" target="_blank" rel="noopener noreferrer">@brainlid</a></li>
<li>David Bernheisel – <a href="https://twitter.com/bernheisel" target="_blank" rel="noopener noreferrer">@bernheisel</a></li>
<li>Cade Ward – <a href="https://github.com/cadebward" target="_blank" rel="noopener noreferrer">Github</a></li>
</ul>
<div itemscope="" itemtype="http://schema.org/AudioObject"><meta itemprop="name" content="#023 Gleam and Static Types with Louis Pilfold"><meta itemprop="uploadDate" content="2020-11-24T04:15:45-07:00"><meta itemprop="encodingFormat" content="audio/mpeg"><meta itemprop="duration" content="PT48M57S"><meta itemprop="description" content="We talk with Louis Pilfold about how he created Gleam, a static typed language that runs on the BEAM. Louis explains some of the challenges with bringing static types to the BEAM and shares ideas on what can possibly be done about it. We learn how Gleam got started, how it works, and how Elixir and Erlang can interop with it. We cover the recently released Gleam OTP work, talk about Type Driven Development and much more!



Show Notes online - https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold"><meta itemprop="contentUrl" content="https://media.blubrry.com/thinkingelixir/s/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3"><meta itemprop="contentSize" content="67.4"><div id="powerpress_player_5041"><!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
<p><audio id="audio-6124-1" preload="none" controls="controls"><source type="audio/mpeg" src="https://media.blubrry.com/thinkingelixir/p/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3?_=1"><a href="https://media.blubrry.com/thinkingelixir/p/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3">https://media.blubrry.com/thinkingelixir/p/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3</a></audio></p></div></div><p>Podcast: <a href="https://media.blubrry.com/thinkingelixir/s/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3" title="Download" rel="nofollow" download="023-gleam-louis-pilfold.mp3">Download</a></p>	</div><!-- .fl-post-content -->

	
	<div></div>		
</article>


<!-- .fl-post -->
		</div>

		
	</div>
</div>


	</div></div>]]>
            </description>
            <link>https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198388</guid>
            <pubDate>Tue, 24 Nov 2020 13:52:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Htmx 1.0.0 Release]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25198287">thread link</a>) | @crbelaus
<br/>
November 24, 2020 | https://htmx.org/posts/2020-11-24-htmx-1.0.0-is-released/ | <a href="https://web.archive.org/web/*/https://htmx.org/posts/2020-11-24-htmx-1.0.0-is-released/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <h2>htmx 1.0.0 Release</h2>
<p>I'm happy to announce the <a href="https://unpkg.com/browse/htmx.org@1.0.0/">1.0.0 release</a> of htmx.</p>
<p>htmx is now mature enough that I can recommend it as a general replacement for intercooler.js
projects.  I <strong>don't</strong> think there is a strong reason to port an existing intercooler project to
htmx.  I have several large intercooler apps and will not be moving them over any time soon. I can, however, recommend using htmx over intercooler for new projects.</p>
<p>htmx is a different sort of javascript library.  It is an HTML &amp; hypertext-oriented reply to the current dominance of javascript-based SPA libraries.  It is a response to Tom MacWright's question:
<a href="https://macwright.com/2020/10/28/if-not-spas.html">"If not SPAs, What?"</a>.</p>
<p>As the <a href="https://htmx.org/">homepage says</a>:</p>
<ul>
<li>Why should only <code>&lt;a&gt;</code> and <code>&lt;form&gt;</code> be able to make HTTP requests?</li>
<li>Why should only <code>click</code> &amp; <code>submit</code> events trigger them?</li>
<li>Why should only GET &amp; POST be available?</li>
<li>Why should you only be able to replace the entire screen?</li>
</ul>
<p>HTML-oriented web development was abandoned not because hypertext was a bad idea, but rather because HTML didn't have sufficient expressive power.  htmx aims to fix that &amp; allows you to implement <a href="https://htmx.org/examples/">many common modern web UI patterns</a> using the original hypertext model of the web.</p>
<h3>History &amp; Thanks</h3>
<p>htmx began life as <a href="https://intercoolerjs.org/">intercooler.js</a> back in <a href="https://github.com/bigskysoftware/intercooler-js/commit/62d3dbdb5c056ee866aba3575e148de649fc3efe">2013</a>.</p>
<p>In <a href="https://github.com/bigskysoftware/htmx/commit/e38dea64dd1065003a0e833d7b469d24e6bc2919">april</a> of this year I began work on a jQuery-indepenent &amp; improved version of intercoolerjs, renamed
to htmx.  I chose to rename the library because, in working on intercooler, I had come to appreciate that intercooler &amp; htmx were completing HTML as a hypertext rather than just some funky, idiosyncratic javascript libraries.</p>
<p>In <a href="https://github.com/bigskysoftware/htmx/releases/tag/v0.0.1">May</a> htmx reached 0.0.1.  Soon thereafter I had the good fortune of being contacted by <a href="https://twitter.com/ben_pylo">Ben Croker</a>
who was interested in htmx as a base for his new reactive library, <a href="https://putyourlightson.com/plugins/sprig">Sprig</a>.  Ben was willing to be an early adopter of htmx and pushed the library along
much faster than it would have gone otherwise.</p>
<p>I have been very lucky to the have help and feedback from many contributors in <a href="https://github.com/bigskysoftware/htmx/graphs/contributors">Github</a> and on <a href="https://htmx.org/discord">Discord</a>.  I'd like to thank, in particular, <a href="https://github.com/benpate">Ben Pate</a>, <a href="https://github.com/rschroll">Robert Schroll</a> &amp; <a href="https://github.com/jreviews">Alejandro Schmeichler</a> for contributing code as well as new ideas and discussions.</p>
<p>I would like to thank <a href="https://devmode.fm/">Devmode.fm</a> for having me on to <a href="https://devmode.fm/episodes/dynamic-html-with-htmx">talk about htmx</a> and for cleaning up all my "uhhs" and "umms".</p>
<p>Finally, I would like to thank <a href="https://github.com/jsampson">Justin Sampson</a>, who took a lot of time to explain REST &amp; HATEOAS to me and how intercooler (and now htmx) fit into that model for web development.</p>
<h3>Changes</h3>
<ul>
<li>I bumped the version number :)</li>
</ul>
<p>Enjoy!</p>

</div></div>]]>
            </description>
            <link>https://htmx.org/posts/2020-11-24-htmx-1.0.0-is-released/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198287</guid>
            <pubDate>Tue, 24 Nov 2020 13:38:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to use Reddit to get your first users]]>
            </title>
            <description>
<![CDATA[
Score 197 | Comments 131 (<a href="https://news.ycombinator.com/item?id=25198280">thread link</a>) | @xavier_
<br/>
November 24, 2020 | https://blog.spreadtheworld.net/posts/get-first-users-reddit/ | <a href="https://web.archive.org/web/*/https://blog.spreadtheworld.net/posts/get-first-users-reddit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>As an indie hacker, we all struggle to validate our ideas, get our first users, and get some traffic. I played a lot with <a href="https://www.reddit.com/user/xAvi_r">Reddit</a> for the last few months, and I can tell you: it’s a gold mine!</p><p>Reddit is super powerful:&nbsp;there are millions of users on the platform, each subreddit is very segmented by niche, and it’s free to use!</p><p>We sometimes see it as an intimidating platform, but it’s not that hard.</p><p>Here is how I&nbsp;use it:</p><h2 id="validate-your-idea">Validate your idea</h2><p>The first step of your indie hacker journey is to validate your idea. You don’t want to spend weeks building something nobody wants. But it can be hard to find your potential customers to validate your product idea.</p><p>With Reddit, you can do it easily. There are subreddits dedicated to Ideas’ feedback. You can post your idea there and you will get some responses within 24hrs. The feedback can be pretty generic as the people in these subs are mostly entrepreneurs and not your potential customer.</p><p>To validate my product idea I prefer to post directly on the sub I&nbsp;want to target. Let’s say you create a tool for developers then I’d post to /r/webdev. You don’t need to have a working MVP, just make some screenshot (or a video) and ask for feedback. Or, even better show them a landing page with a pre-order button or an email form and wait for their reactions.</p><p><em>(For the idea validation step, don’t be afraid to post on a big subreddit with hundreds of thousands of users, the more people see your idea the stronger your validation will be)</em></p><p>Within 24hrs you’ll know if that idea is worth pushing! If you get positive feedback - or even pre-orders - you can build your MVP. If you’re ignored or trashed, then find another way or get another idea!</p><h2 id="get-your-first-users">Get your first users</h2><p>Once your MVP is ready you need a bunch of beta testers to give you some feedback.
Reddit can also help you with that.</p><p>But this time I’d go with a small subreddit, and a super targeted one. Let’s say you created a no-code tool for startups, I’ll try to get my early adopters from /r/nocode (3.7k members) instead of posting on /r/startups (517k members) for instance. It’s a small subreddit, very niche. Then, once you have the first feedback you can iterate on it and post on some bigger subs.</p><p>The idea of “incremental launches” is to start small, build an audience, get some feedback, and grow step by step. Once the super-targeted subreddit loves your product you can start to post on big subreddit and get some traction.</p><p><em>PS: Small subreddit are super powerful if you choose them wisely. I got more than <a href="https://twitter.com/AngeZanetti/status/1325847913466048516">400 visits</a> in 48hrs from my last post on /r/nocode!</em></p><h2 id="get-some-traffic">Get some traffic</h2><p>Last step of the process: your MVP is ready, you need some traffic. And you want a lot of it!</p><p>The strategy here is to create some content around your product and share it with big subreddits. The secret is to provide as much value as you can. Share your secrets, how you grow your product, share your analytics, how much money you make, what did you learn during your journey, etc… It needs to be valuable and targeted to an audience.</p><p>Post your content to the biggest subreddits like /r/Entrepreneur, /r/Programming, or /r/Marketing and add a link to your product/blog at the end (Check the rules of the sub first, but most of them are ok with it)</p><p>If your content is well-targeted and brings some serious value you can get thousands of visitors in a day! And it’s totally repeatable. As long as you can provide value you’ll get some free traffic!</p><p>Do you want to launch on Reddit? DM me on Twitter, I’ll be happy to help → <a href="https://twitter.com/angezanetti">Twitter</a></p></div></div>]]>
            </description>
            <link>https://blog.spreadtheworld.net/posts/get-first-users-reddit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198280</guid>
            <pubDate>Tue, 24 Nov 2020 13:36:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EC2 Origin]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198157">thread link</a>) | @ashishsheth
<br/>
November 24, 2020 | http://blog.b3k.us/2009/01/25/ec2-origins.html | <a href="https://web.archive.org/web/*/http://blog.b3k.us/2009/01/25/ec2-origins.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>I was trying to avoid writing this post and had succeeded at that goal for almost 2 years. After some recent exchanges, I see the wisest move is the opposite. so, here goes.</p>
<p>In 2003 I was working at Amazon for the best manager I’ve ever had, Chris Pinkham. Chris had hired me the previous year as a network engineer, quickly promoting me to manager for the (ridiculously awesome) team. Chris was always pushing me to change the infrastructure, especially driving better abstraction and uniformity, essential for efficiently scaling. He wanted an all IP network instead of the mess of VLANs Amazon had at the time, so we designed it, built it, and worked with developers so their applications would work with it. He wanted anycast <span>DNS</span>, so we hacked up some routing software and put it out there (great idea at the time, but in hindsight we probably should’ve taken a different approach). Chris asked for something, we figured out how, and did it.</p>
<p>Sorry for the digression, back to what I was saying about 2003: Chris and I wrote a short paper describing a vision for Amazon infrastructure that was completely standardized, completely automated, and relied extensively on web services for things like storage. We drew on the work of a number of other folks internally who had been thinking and writing (and sometimes even coding) in the storage services space, and we combined it with our own thinking and experience in infrastructure. Near the end of it, we mentioned the possibility of selling virtual servers as a service.</p>
<p>We presented the paper to Bezos (he doesn’t do slides), he liked a lot of it, and we went back to work.</p>
<p>A few months later, in early 2004, I was told Jeff was interested in the virtual server as a service idea and asked for a more detailed write up of it. This I did, also incorporating a couple of requests Jeff had, like the idea of a “universe” of virtuals, which I translated into network-speak as a distributed firewall to isolate groups of servers. This first cut at it looked almost nothing like the production EC2 service, and, in my view, every change made by the team who built EC2 was for the better. As just one example, that first paper called for a system manifest from which a server would be built. This is similar to how much systems automation works, but is actually terrible for the sort of dynamism desired for EC2.</p>
<p>After presenting the “executive brief” paper to Jeff, the realities of turning this hare-brained scheme into a real service meant involving the smartest folks around (i.e., not me). In the Amazon style of “starting from the customer and working backwards”, we produced a “press release” and a <span>FAQ</span> to further detail the how and why of what would become EC2. At this point attention turned from these paper pushing exercises to specifics of getting it built. Most importantly, who would lead the effort?</p>
<p>Everyone seemed to leap at once to the same conclusion: Pinkham. And so it was that Pinkham returned to South Africa, taking a stellar lead developer with him, and they built the EC2 team, then built EC2. That last part seems awfully compressed, doesn’t it? Well, that’s because I had almost no interaction with the EC2 team. They went off and kicked a lot of ass and the rest is history.</p>
<p>The end.</p>
<p>Want more data? Here’s Jeff in a 2008 interview with Om Malik…</p>

<time datetime="2009-01-25">
  —Jan 25, 2009
</time>
</article></div>]]>
            </description>
            <link>http://blog.b3k.us/2009/01/25/ec2-origins.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198157</guid>
            <pubDate>Tue, 24 Nov 2020 13:18:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An opinionated list of best practices for textual websites]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197950">thread link</a>) | @kkoncevicius
<br/>
November 24, 2020 | https://seirdy.one/2020/11/23/website-best-practices.html | <a href="https://web.archive.org/web/*/https://seirdy.one/2020/11/23/website-best-practices.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	<p><em>The following applies to minimal websites that focus primarily on text. It does not
apply to websites that have a lot of non-textual content. It also does not apply to
websites that focus more on generating revenue or pleasing investors than being good
websites.</em></p>
<p>This is a “living document” that I add to as I receive feedback. See the
<a href="https://git.sr.ht/~seirdy/seirdy.one/log/master/content/posts/website-best-practices.md">changelog</a>.</p>
<p>I realize not everybody’s going to ditch the Web and switch to Gemini or Gopher today
(that’ll take, like, a month at the longest). Until that happens, here’s a
non-exhaustive, highly-opinionated list of best practices for websites that focus
primarily on text:</p>
<ul>
<li>Final page weight under 50kb without images, and under 200kb with images.</li>
<li>Works in Lynx, w3m, links (both graphics and text mode), Netsurf, and Dillo</li>
<li>Works with popular article-extractors (e.g.&nbsp;Readability) and HTML-to-Markdown
converters. This is a good way to verify that your site uses simple HTML and works
with most non-browser article readers (e.g.&nbsp;ebook converters, PDF exports).</li>
<li>No scripts or interactivity (preferably enforced at the CSP level)</li>
<li>No cookies</li>
<li>No animations</li>
<li>No fonts–local or remote–besides <code>sans-serif</code> and <code>monospace</code>. More on this
below.</li>
<li>No referrers</li>
<li>No requests after the page finishes loading</li>
<li>No 3rd-party resources (preferably enforced at the CSP level)</li>
<li>No lazy loading (more on this below)</li>
<li>No custom colors OR explicitly set the both foreground and background colors. More
on this below.</li>
<li>A maximum line length for readability</li>
<li>Server configured to support compression (gzip, optionally zstd as well). It’s a
free speed boost.</li>
<li>Supports dark mode via a CSS media feature and/or works with most “dark mode”
browser addons. More on this below.</li>
<li>A good score on Mozilla’s <a href="https://observatory.mozilla.org/">HTTP Observatory</a></li>
<li>Optimized images.</li>
<li>Maybe HTTP/2. There are some cases in which HTTP/2 can make things slower. Run some
tests to find out.</li>
</ul>
<p>I’d like to re-iterate yet another time that this only applies to websites that
primarily focus on text. If graphics, interactivity, etc. are an important part of
your website, less (possibly none) of this article applies.</p>
<p>Earlier revisions of this post generated some responses I thought I should address
below. Special thanks to the IRC and <a href="https://lobste.rs/s/akcw1m">Lobsters</a> users who
gave good feedback!</p>
<h2 id="about-fonts">About fonts</h2>
<p>If you <em>really</em> want, you could use <code>serif</code> instead of <code>sans-serif</code>, but serif fonts
tend to look worse on low-res monitors. Not every screen’s DPI has three digits.</p>
<p>To ship custom fonts is to assert that branding is more important than user choice.
That might very well be a reasonable thing to do; branding isn’t evil! It isn’t
<em>usually</em> the case for textual websites, though. Beyond basic layout and optionally
supporting dark mode, authors generally shouldn’t dictate the presentation of their
websites; that is the job of the user agent. Most websites are not important enough
to look completely different from the rest of the user’s system.</p>
<p>A personal example: I set my preferred fonts in my computer’s fontconfig settings.
Now every website that uses <code>sans-serif</code> will have my preferred font. Sites with
<code>sans-serif</code> blend into the users' systems instead of sticking out.</p>
<h3 id="but-most-users-dont-change-their-fonts">But most users don’t change their fonts…</h3>
<p>The “users don’t know better and need us to make decisions for them” mindset isn’t
without merits; however, in my opinion, it’s overused. Using system fonts doesn’t
make your website harder to use, but it does make it smaller and stick out less to
the subset of users who care enough about fonts to change them. This argument isn’t
about making software easier for non-technical users; it’s about branding by
asserting a personal preference.</p>
<h3 id="cant-users-globally-override-stylesheets-instead">Can’t users globally override stylesheets instead?</h3>
<p>It’s not a good idea to require users to automatically override website stylesheets.
Doing so would break websites that use fonts such as Font Awesome to display vector
icons. We shouldn’t have these users constantly battle with websites the same way
that many adblocking/script-blocking users (myself included) already do when there’s
a better option.</p>
<p>That being said, many users <em>do</em> actually override stylesheets. We shouldn’t
<em>require</em> them to do so, but we should keep our pages from breaking in case they do.
Pages following this article’s advice will probably work perfectly well in these
cases without any extra effort.</p>
<h3 id="but-wouldnt-that-allow-a-website-to-fingerprint-with-fonts">But wouldn’t that allow a website to fingerprint with fonts?</h3>
<p>I don’t know much about fingerprinting, except that you can’t do font enumeration
without JavaScript. Since text-based websites that follow these best-practices don’t
send requests after the page loads and have no scripts, fingerprinting via font
enumeration is a non-issue on those sites.</p>
<p>Other websites can still fingerprint via font enumeration using JavaScript. They
don’t need to stop at seeing what sans-serif maps to; they can see all the available
fonts on a user’s system, the user’s canvas fingerprint, window dimensions, etc. Some
of these can be mitigated with Firefox’s <code>privacy.resistFingerprinting</code> setting, but
that setting also understandably overrides user font preferences.</p>
<p>Ultimately, surveillance self-defense on the web is an arms race full of trade-offs.
If you want both privacy and customizability, the web is not the place to look; try
Gemini or Gopher instead.</p>
<h2 id="about-lazy-loading">About lazy loading</h2>
<p>For users on slow connections, lazy loading is often frustrating. I think I can speak
for some of these users: mobile data near my home has a number of “dead zones” with
abysmal download speeds, and my home’s Wi-Fi repeater setup occasionally results in
packet loss rates above 60% (!!).</p>
<p>Users on poor connections have better things to do than idly wait for pages to load.
They might open multiple links in background tabs to wait for them all to load at
once, or switch to another window/app and come back when loading finishes. They might
also open links while on a good connection before switching to a poor connection; I
know that I often open 10-20 links on Wi-Fi before going out for a walk in a
mobile-data dead-zone.</p>
<p>Unfortunately, pages with lazy loading don’t finish loading off-screen images in the
background. To load this content ahead of time, users need to switch to the loading
page and slowly scroll to the bottom to ensure that all the important content appears
on-screen and starts loading. Website owners shouldn’t expect users to have to jump
through these ridiculous hoops.</p>
<h3 id="wouldnt-this-be-solved-by-combining-lazy-loading-with-pre-loadingpre-fetching">Wouldn’t this be solved by combining lazy loading with pre-loading/pre-fetching?</h3>
<p>A large number of users with poor connections also have capped data, and would prefer
that pages don’t decide to predictively load content ahead-of-time for them. Some go
so far as to disable this behavior to avoid data overages. Savvy privacy-conscious
users also generally disable pre-loading because they don’t have reason to trust that
linked content doesn’t practice dark patterns like tracking without consent.</p>
<p>Users who click a link <em>choose</em> to load a full page. Loading pages that a user hasn’t
clicked on is making a choice for that user.</p>
<h3 id="cant-users-on-poor-connections-disable-images">Can’t users on poor connections disable images?</h3>
<p>I have two responses:</p>
<ol>
<li>If an image isn’t essential, you shouldn’t include it inline.</li>
<li>Yes, users could disable images. That’s <em>their</em> choice. If your page uses lazy
loading, you’ve effectively (and probably unintentionally) made that choice for a
large number of users.</li>
</ol>
<h2 id="about-custom-colors">About custom colors</h2>
<p>Some users' browsers set default page colors that aren’t black-on-white. For
instance, Linux users who enable GTK style overrides might default to having white
text on a dark background. Websites that explicitly set foreground colors but leave
the default background color (or vice-versa) end up being difficult to read. Here’s
an example:</p>
<picture>
<source srcset="https://seirdy.one/misc/website_colors.webp" type="image/webp">
<img src="https://seirdy.one/misc/website_colors.png" alt="This page with a grey background, a header with unreadable black/grey text, and unreadable white-on-white code snippets">
</picture>
<p>If you do explicitly set colors, please also include a dark theme using a media
query: <code>@media (prefers-color-scheme: dark)</code>. For more info, read the relevant docs
<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-color-scheme">on
MDN</a></p>
<h2 id="image-optimization">Image optimization</h2>
<p>Some image optimization tools I use:</p>
<ul>
<li><a href="http://pngquant.org/">pngquant</a> (lossy)</li>
<li><a href="https://github.com/shssoichiro/oxipng">Oxipng</a> (lossless)</li>
<li><a href="https://github.com/tjko/jpegoptim">jpegoptim</a> (lossless or lossy)</li>
<li><a href="https://developers.google.com/speed/webp/docs/cwebp">cwebp</a> (lossless or lossy)</li>
</ul>
<p>I put together a <a href="https://git.sr.ht/~seirdy/dotfiles/tree/3b722a843f3945a1bdf98672e09786f0213ec6f6/Executables/shell-scripts/bin/optimize-image">quick
script</a>
to losslessly optimize images using these programs in my dotfile repo.</p>
<p>You also might want to use the HTML <code>&lt;picture&gt;</code> element, using JPEG/PNG as a fallback
for more efficient formats such as WebP or AVIF. More info in the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/picture">MDN
docs</a></p>
<p>Most of my images will probably be screenshots that start as PNGs. My typical flow:</p>
<ol>
<li>Lossy compression with <code>pngquant</code></li>
<li>Losslessly optimize the result with <code>oxipng</code> and its Zopfli backend (slow)</li>
<li>Also create a lossless WebP from the lossy PNG, using <code>cwebp</code></li>
<li>Include the resulting WebP in the page, with a fallback to the PNG using a <code>&lt;picture&gt;</code> element.</li>
</ol>
<p>It might seem odd to create a lossless WebP from a lossy PNG, but I’ve found that it’s the best way to get the smallest possible image at the minimum acceptable quality for screenshots with solid backgrounds.</p>
<h2 id="other-places-to-check-out">Other places to check out</h2>
<p>The <a href="https://250kb.club/">250kb club</a> gathers websites at or under 250kb, and also
rewards websites that have a high ratio of content size to total size.</p>
<p>Also see <a href="https://motherfuckingwebsite.com/">Motherfucking Website</a>. Motherfucking
Website inspired several unofficial sequels that tried to gently improve upon it. My
favorite is <a href="https://bestmotherfucking.website/">Best Motherfucking Website</a>.</p>
</article></div>]]>
            </description>
            <link>https://seirdy.one/2020/11/23/website-best-practices.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197950</guid>
            <pubDate>Tue, 24 Nov 2020 12:46:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The German Elon of the 70s]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197941">thread link</a>) | @revolucien
<br/>
November 24, 2020 | https://www.muellerfreitag.com/essays/the-german-elon-of-the-70s | <a href="https://web.archive.org/web/*/https://www.muellerfreitag.com/essays/the-german-elon-of-the-70s">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-nc-base="header" data-controller="AncillaryLayout">
      

      

      <div>

        

        <div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5f18775b30d9fd6c1ed21e6a" data-item-id="5f18775b30d9fd6c1ed21e6a">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1595439165510" id="item-5f18775b30d9fd6c1ed21e6a"><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1595439201816_6409"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1595439277525-N1KY1FTDNW9EB1P2KT6U/ke17ZwdGBToddI8pDm48kKtijf5x5S0rIV7X_qDH3dB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UaZbTVdO5VSPAOxIcVIbmIFLIFeVDbQiz7iBIgNCzklBDD2o6CESiqIlH5ssNFrtmA/Lutz_Kayser.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1595439277525-N1KY1FTDNW9EB1P2KT6U/ke17ZwdGBToddI8pDm48kKtijf5x5S0rIV7X_qDH3dB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UaZbTVdO5VSPAOxIcVIbmIFLIFeVDbQiz7iBIgNCzklBDD2o6CESiqIlH5ssNFrtmA/Lutz_Kayser.jpg" data-image-dimensions="2400x1600" data-image-focal-point="0.5,0.5" alt="Meet Lutz Kayser, the pioneering rocket engineer and founder of OTRAG  (Source:    OTRAG   )" data-load="false" data-image-id="5f18789af192c5616c553b96" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1595439277525-N1KY1FTDNW9EB1P2KT6U/ke17ZwdGBToddI8pDm48kKtijf5x5S0rIV7X_qDH3dB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UaZbTVdO5VSPAOxIcVIbmIFLIFeVDbQiz7iBIgNCzklBDD2o6CESiqIlH5ssNFrtmA/Lutz_Kayser.jpg">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Meet Lutz Kayser, the pioneering rocket engineer and founder of OTRAG<em> (Source: </em><a href="http://otrag.com/" target="_blank"><em>OTRAG</em></a><em>)</em></p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-1f175e5db5ee82782e37"><div><p>It’s 1977 and you’re standing on a rocky plateau overlooking the dense jungle of Zaire in what is now modern-day Congo. You and a group of maverick engineers work for OTRAG, a West German rocket startup that is sponsored by Zaire’s dictator, Mobutu Sese Seko. After many months of toil in the African bushland, you’re ready to launch the world’s first privately developed rocket booster––a 9-meter (30 ft) tall juggernaut which, from a distance, looks like a bundle of aluminum pencils with a nose cone. The countdown proceeds smoothly. Then finally, there’s liftoff: The rocket leaves the launch pad with a deafening roar and climbs to an altitude of 12 km (7.5 miles) before plummeting back to Earth. The plateau erupts in jubilation.</p><p>Wait, what? This unlikely scene from the jungle might sound crazy to you. A private rocket company from West Germany that is attempting to make it into space in the late seventies? That’s more than three decades before Elon Musk’s <a href="https://en.wikipedia.org/wiki/SpaceX" target="_blank">SpaceX</a> successfully launched its first rocket, the <a href="https://www.youtube.com/watch?v=dLQ2tZEH6G0" target="_blank">Falcon 1</a>, into orbit. But this incredible and long-forgotten tale is entirely true and forms the plot of the documentary<em> </em><a href="https://vimeo.com/300738920" target="_blank"><em>Fly Rocket Fly</em></a><em>, </em>which premiered at the Munich Film Festival in 2018. The film is now available to stream on <a href="https://www.amazon.com/Fly-Rocket-Lutz-Keyser/dp/B082H4WJJG" target="_blank">Amazon Prime</a> and <a href="https://vimeo.com/ondemand/flyrocketfly" target="_blank">Vimeo</a>.</p><p>The rise and fall of OTRAG is one of the strangest, and most remarkable, startup tales I’ve encountered to date. It’s an almost surreal story of entrepreneurial adventure and ambition that bears an astonishing resemblance to Werner Herzog’s<em> </em><a href="https://en.wikipedia.org/wiki/Fitzcarraldo" target="_blank"><em>Fitzcarraldo</em></a><em>. </em>In Herzog’s 1982 movie, Klaus Kinski plays an obsessive dreamer who manually drags his massive steamship over a steep hill in the Amazon jungle. Unfortunately for Fitzcarraldo, this astonishing engineering feat doesn’t translate into his mission’s overall success (Herzog later went so far as to call it a “<a href="https://www.nytimes.com/2009/08/02/books/review/Harris-t.html" target="_blank">conquest of the useless</a>”). The same could be said about OTRAG. Despite a number of successful test launches, OTRAG was a spectacular failure. The company burned through massive amounts of funding and eventually ran afoul of Cold War politics. Its demise is a case study in what happens to startups when their timing is wrong, their technology speculative, and their market unwilling to embrace disruptive innovation.</p><h3><strong>The Emperor of OTRAG</strong></h3><p>All startups are a reflection of their founders. The man behind the rocket-building adventure in the jungle was Lutz Kayser, a German aerospace engineer who was something of a 20th-century Elon Musk. Kayser began pursuing his dream of a low-cost rocket launcher in the 1960s. As a student of rocket pioneer <a href="https://en.wikipedia.org/wiki/Eugen_S%C3%A4nger" target="_blank">Eugen Sänger</a>, he experimented with new propulsion systems using industrially available components and low-cost fuels. The initial work with Sänger carried over into Kayser’s first startup, Technology Research Ltd., which he founded in 1970. The company received several million Deutschmark in research grants and was hired by the West German government to explore a low-cost alternative to the ailing <a href="https://en.wikipedia.org/wiki/Europa_(rocket)" target="_blank">Europa II</a> rocket program.&nbsp;</p><p>It was during this time that Kayser developed his vision for a low-cost, modular rocket system that could transport satellites into orbit<em>.</em> The idea was as simple as it was revolutionary: it involved the parallel clustering of many standard fuel tank and engine modules <em>(Bündelrakete)</em>. The smallest flight-worthy rocket module consisted of four clustered tank units and four identical engines. Bigger, more powerful boosters could be constructed by bundling together larger quantities of these tank-and-engine modules. The largest configuration on paper had as many as 600 individual engines! And there was another idiosyncrasy to the design: instead of being stacked <em>atop</em> one another, the stages would be nested <em>inside</em> one another and shed like layers of an onion as they burned out. This arrangement didn’t make for a particularly handsome vehicle and the rocket’s design was frequently compared to a<em> </em>bundle of asparagus. But aesthetics weren’t the point; “low cost, not high tech” was the North Star.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606063350099_13600"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064185347-VN7XY7VCBE5NGAOK3N04/ke17ZwdGBToddI8pDm48kJmhqGN-mSClKRKwJ41evzEUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dt65uYDq5wjmpAbzmJV4EKyPzCeG_9Y6bPguKi4sPluTCjLISwBs8eEdxAxTptZAUg/1.png" data-image="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064185347-VN7XY7VCBE5NGAOK3N04/ke17ZwdGBToddI8pDm48kJmhqGN-mSClKRKwJ41evzEUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dt65uYDq5wjmpAbzmJV4EKyPzCeG_9Y6bPguKi4sPluTCjLISwBs8eEdxAxTptZAUg/1.png" data-image-dimensions="1988x966" data-image-focal-point="0.5,0.5" alt="Lutz Kayser with a prototype of his “cluster rocket” (left), next to a design sketch by Klaus Bürgle (right).  Source:    OTRAG" data-load="false" data-image-id="5fba982f2b4bfe31fd69b8dc" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064185347-VN7XY7VCBE5NGAOK3N04/ke17ZwdGBToddI8pDm48kJmhqGN-mSClKRKwJ41evzEUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dt65uYDq5wjmpAbzmJV4EKyPzCeG_9Y6bPguKi4sPluTCjLISwBs8eEdxAxTptZAUg/1.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Lutz Kayser with a prototype of his “cluster rocket” (left), next to a design sketch by Klaus Bürgle (right). <em>Source: </em><a href="http://otrag.com/" target="_blank"><em>OTRAG</em></a></p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606063350099_15492"><div><p>The key to holding down the rocket’s cost lay in three simple design principles, some of which have been rediscovered by the current crop of “<a href="https://en.wikipedia.org/wiki/Private_spaceflight#NewSpace_terminology" target="_blank">NewSpace</a>” companies. The first principle was rooted in the modular platform architecture itself. Building a whole family of launch vehicles around the same tank-and-engine modules simplified the vehicle configuration and saved millions in development costs. It also meant lots of tanks and engines in production, generating both economies of scale and lower prices. SpaceX applies the same design philosophy today: its main rocket, the <a href="https://en.wikipedia.org/wiki/Falcon_9" target="_blank">Falcon 9</a>, employs nine identical engines (plus another one to power the second stage), while the <a href="https://en.wikipedia.org/wiki/Falcon_Heavy" target="_blank">Falcon Heavy</a> uses 27 units of the same engine. This creates a virtuous cycle whereby the operating model helps drive the business model: being the cheapest launch provider in the market translates into a greater number of launch contracts, which in turn drives higher volumes and scale efficiencies. Once this flywheel is in motion, it becomes easier to run the business as it continues to operate.</p><p>The second design principle was to use mass produced, commercially available components instead of expensive “space grade” equipment from government contractors. The tank units, for example, were made of long pipeline tubes that were manufactured by the German steelmaker Krupp. Amusingly, a Volkswagen windshield-wiper motor was used to open and close the valves that controlled the propellant flow to the engines. Complex and trouble-prone components, like <a href="https://en.wikipedia.org/wiki/Turbopump" target="_blank">turbopumps</a> or <a href="https://en.wikipedia.org/wiki/Gimbaled_thrust" target="_blank">gimbals</a>, were avoided altogether. Instead, the fuel tanks were partially filled with compressed air that forced the propellant into the engines, and the rocket was steered by throttling back individual engines on the side where less thrust was desired. SpaceX would later use components from existing supply chains as well: The Falcon 1 used readily available car wash valves with modified seals to feed propellant into the engine, while the first <a href="https://en.wikipedia.org/wiki/SpaceX_Dragon" target="_blank">Dragon</a> spacecraft utilized a modified bathroom stall latch for securing the cargo lockers.</p><p>The third design principle was a simplified rocket engine that could run on extremely low-cost fuels. The<em> </em>basic job of rocket fuel is to burn steadily and intensely when combined with an oxidizer. Once the fuel and oxidizer are fed through an injector into the combustion chamber, they produce a hot gas that shoots out of the bell-shaped exhaust nozzle at the bottom. This creates the necessary thrust to launch the rocket upwards. The most common rocket propellant in use today is a mix of ultra-refined kerosene (RP-1) and liquid oxygen (LOX). SpaceX, <a href="https://en.wikipedia.org/wiki/Rocket_Lab" target="_blank">Rocket Lab</a>, and many other launch providers work with this fuel mix. Kayser, in contrast, opted for a much cheaper propellant combination: regular diesel oil as fuel and nitric acid as oxidizer. Though providing less thrust per pound than RP-1/LOX and being extremely toxic, this combination cost only 5% as much and was readily available.&nbsp;</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606063350099_27594"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064291685-VEMSFLQL8VPXVMHIP4SE/ke17ZwdGBToddI8pDm48kFhaRfXD0sHRzS4HFtXwQmMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dnuqrDbxeiwpNrWn4d5W-MeZh_NIeMKNsMLkG5wAFm5KCjLISwBs8eEdxAxTptZAUg/2.png" data-image="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064291685-VEMSFLQL8VPXVMHIP4SE/ke17ZwdGBToddI8pDm48kFhaRfXD0sHRzS4HFtXwQmMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dnuqrDbxeiwpNrWn4d5W-MeZh_NIeMKNsMLkG5wAFm5KCjLISwBs8eEdxAxTptZAUg/2.png" data-image-dimensions="1986x962" data-image-focal-point="0.5,0.5" alt="Kayser in the control center at the German Aerospace Center in Lampoldshausen.  Source:    OTRAG" data-load="false" data-image-id="5fba9899317ba5146213cb17" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064291685-VEMSFLQL8VPXVMHIP4SE/ke17ZwdGBToddI8pDm48kFhaRfXD0sHRzS4HFtXwQmMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dnuqrDbxeiwpNrWn4d5W-MeZh_NIeMKNsMLkG5wAFm5KCjLISwBs8eEdxAxTptZAUg/2.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Kayser in the control center at the German Aerospace Center in Lampoldshausen. <em>Source: </em><a href="http://otrag.com/" target="_blank"><em>OTRAG</em></a></p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606063350099_29089"><div><p>Much of the early work on this novel rocket concept was done at a test stand rented from the German Aerospace Center in <a href="https://www.dlr.de/content/en/articles/sites/lampholdshausen/about-lampoldhausen.html" target="_blank">Lampoldshausen</a>, north of Stuttgart. Over a period of four years, Kayser’s team went through hundreds of test firings to perfect the diesel oil/nitric acid cocktail. The biggest challenge around getting the engine to work was the “<a href="https://en.wikipedia.org/wiki/Hypergolic_propellant" target="_blank">hypergolic</a>” nature of the fuel mix: diesel oil and nitric acid ignite immediately upon contact and are subject to <a href="https://en.wikipedia.org/wiki/Combustion_instability" target="_blank">unstable burning</a>. Just getting the engine started was difficult: if ignition happened too late, a pool of almost-ready to burn propellant had already accumulated in the combustion chamber, triggering an explosion that would demolish the engine and its immediate surroundings. The group eventually achieved a breakthrough by inventing a radial fuel injection system that provided the right vapor mixture of fuel and oxidizer.</p><p>Then came an unexpected setback. By 1974, the West German government had lost interest in the project and decided to concentrate its rocket research efforts on a new, pan-European launch vehicle, the <a href="https://en.wikipedia.org/wiki/Ariane_1" target="_blank">Ariane 1</a>. Technology Research Ltd.’s fiscal tap<em> </em>was shut off. Kayser was undeterred. He began looking for private funding to bring his rocket to market but it was difficult. Venture capital as we know it today didn’t exist in 1974. Venerable firms like <a href="https://www.kleinerperkins.com/our-history/" target="_blank">Kleiner Perkins</a> and <a href="https://www.sequoiacap.com/article/remembering-don-valentine/" target="_blank">Sequoia</a>, both founded in 1972, were still in their infancy and unavailable to a little-known entrepreneur from West Germany. Kayser’s only option was a highly unorthodox crowdfunding strategy: he decided to raise money from wealthy individuals who wrote off their investment through tax deductions <em>(Abschreibungsgesellschaft). </em>Few investors believed that Kayser’s company would actually succeed, but that …</p></div></div></div></div></div></article></section></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.muellerfreitag.com/essays/the-german-elon-of-the-70s">https://www.muellerfreitag.com/essays/the-german-elon-of-the-70s</a></em></p>]]>
            </description>
            <link>https://www.muellerfreitag.com/essays/the-german-elon-of-the-70s</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197941</guid>
            <pubDate>Tue, 24 Nov 2020 12:45:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ask Your Coworkers What They Make. You’ll Earn More]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197935">thread link</a>) | @Fiveplus
<br/>
November 24, 2020 | https://civicskunk.works/ask-your-coworkers-what-they-make-youll-earn-more-46efb2daf63e | <a href="https://web.archive.org/web/*/https://civicskunk.works/ask-your-coworkers-what-they-make-youll-earn-more-46efb2daf63e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2 id="1842">Lack of wage transparency is a real factor in suppressing American wages.</h2><div><div><div><p><a href="https://medium.com/@Nick_Cassella?source=post_page-----46efb2daf63e--------------------------------" rel="noopener"><img alt="Nick Cassella" src="https://miro.medium.com/fit/c/96/96/0*1ojfl3YBepASbp5C.jpg" width="48" height="48"></a></p></div></div></div><p id="1bb9">I remember the uneasiness of asking for my first raise—only to have my boss tell me the number I had in mind would make me the “highest paid employee.” It was a startling admission. I was asking for $44,000 a year, which seemed reasonable to me. But I didn’t know how my pay compared to the business’ other five employees. So I didn’t call my boss’ bluff. I settled for $42,000.</p><p id="b7d1">You probably don’t know how much your coworkers make either. I get it. It’s an awkward conversation to have. It’s taboo. Plus, do you really want to discover that Stephen makes $20,000 more than you? No. So you don’t ask. You skirt around the issue, only talking about your pay in the privacy of your own home.</p><p id="4ac1">There is a serious price to pay for keeping your salary secret, though: it benefits your boss. Their asymmetric knowledge of who earns what enables them to pay you “<a href="http://www.hamiltonproject.org/people/benjamin_harris" rel="noopener">less than [your] economic value</a>” demands, as my experience illustrates.</p><p id="208c">Now, standard economic theory suggests that this shouldn’t happen. In a competitive labor market, a worker’s pay is determined by the economic value of their labor. If a business underpays its employees, then they should expect to have their workforce leave for better jobs. But one of the features of a competitive market is “<a href="http://www.economicsdiscussion.net/market/features-of-a-perfectly-competitive-market/7108" rel="noopener">perfect knowledge</a>”; that is, both businesses and employees possess the same information.</p><p id="7b27">However, that’s not the case in America today. While websites like Glassdoor supply people with greater awareness of salaries and benefits, these “<a href="http://www.hamiltonproject.org/papers/information_is_power_fostering_labor_market_competition_through_transparent" rel="noopener">data sources all have considerable weaknesses when it comes to gaining a precise understanding of prevailing wages</a>.” To get a leg up over their employees, more than half of employers <a href="http://www.hamiltonproject.org/papers/information_is_power_fostering_labor_market_competition_through_transparent" rel="noopener">conduct their own salary surveys</a>. These employers generally don’t share their findings with the employees. Instead, they say, “Trust us, we offer competitive compensation.”</p><p id="0e4e">Is it any wonder America suffers from decades of stagnant wages?</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2432/1*uVgy2c4ZV8MuzgXQM1xcoQ.png" width="1216" height="1149" srcset="https://miro.medium.com/max/552/1*uVgy2c4ZV8MuzgXQM1xcoQ.png 276w, https://miro.medium.com/max/1104/1*uVgy2c4ZV8MuzgXQM1xcoQ.png 552w, https://miro.medium.com/max/1280/1*uVgy2c4ZV8MuzgXQM1xcoQ.png 640w, https://miro.medium.com/max/1400/1*uVgy2c4ZV8MuzgXQM1xcoQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*uVgy2c4ZV8MuzgXQM1xcoQ.png?q=20"></p></div></div></div></figure><p id="53b6">This feature of the modern workplace is totally avoidable, too. When <a href="https://www.npr.org/sections/money/2015/02/23/385843576/50-years-of-shrinking-union-membership-in-one-map" rel="noopener">unions represented the majority of American workers</a>, there was greater “<a href="https://www.brookings.edu/research/information-is-power-fostering-labor-market-competition-through-transparent-wages/" rel="noopener">familiarity with the distribution of wages in a given market</a>.” In turn, this put “<a href="https://www.brookings.edu/research/information-is-power-fostering-labor-market-competition-through-transparent-wages/" rel="noopener">workers in a stronger position during negotiations</a>”—which could help explain why wage growth was stronger when more people belonged to a union.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1600/1*NZWJ934hjczCSDt0Wx1Qvg.jpeg" width="800" height="459" srcset="https://miro.medium.com/max/552/1*NZWJ934hjczCSDt0Wx1Qvg.jpeg 276w, https://miro.medium.com/max/1104/1*NZWJ934hjczCSDt0Wx1Qvg.jpeg 552w, https://miro.medium.com/max/1280/1*NZWJ934hjczCSDt0Wx1Qvg.jpeg 640w, https://miro.medium.com/max/1400/1*NZWJ934hjczCSDt0Wx1Qvg.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*NZWJ934hjczCSDt0Wx1Qvg.jpeg?q=20"></p></div></div></div></figure><p id="a62f"><a href="https://www.nytimes.com/2018/02/22/us/politics/supreme-court-unions.html" rel="noopener">Unions aren’t coming back</a>, though. So in a post-union economy, how do we empower workers to negotiate for higher wages?</p><p id="939b">Benjamin Harris of Northwestern University has compiled <a href="https://www.brookings.edu/research/information-is-power-fostering-labor-market-competition-through-transparent-wages/" rel="noopener">a report</a> enumerating five remedies to improving wage transparency. Quickly, Harris’ points are:</p><ul><li id="ad8d">Enact state laws to protect workers who discuss pay</li><li id="1dd6">Require large firms to disclose pay trends to the Equal Employment Opportunity Commission</li><li id="ec04">Amend the safe harbor for compensation surveys</li><li id="f822">Change state law to facilitate reciprocal pre-hiring wage disclosure</li><li id="9ce6">Allocate funds for the Department of Labor to study transparency</li></ul><p id="141b">The logic behind these wonky prescriptions is compelling. If businesses are forced to be transparent about wages, they will have a harder time suppressing them. You’d think whether you’re conservative or progressive, that is an outcome worth working towards.</p><p id="05c4">Alas, Republicans have blocked legislation that aims to provide workers with more information on compensation. They have filibustered and condemned the Paycheck Fairness Act—a labor law that, among other provisions, would punish “<a href="http://thehill.com/blogs/floor-action/senate/203064-senate-gop-blocks-paycheck-fairness-bill" rel="noopener">employers for retaliating against workers who share wage information</a>.”</p><p id="7c09">Their arguments against the Act are ridiculous. Ever the critical thinker, Marco Rubio summed up his party’s attitude towards greater wage transparency when he claimed that “<a href="https://thinkprogress.org/marco-rubio-explains-his-opposition-to-equal-pay-law-3c3924506778/" rel="noopener">all [the Paycheck Fairness Act] really did is just help lawyers sue</a>.” Ah, yes. Astute point, Marco.</p><p id="9f61">If history has taught us anything, it is that businesses will not pay people what they are worth until they are forced to. That’s why some employers <a href="https://www.classaction.org/blog/can-i-be-fired-for-discussing-wages-at-work" rel="noopener">retaliate against workers for even <em>discussing</em> wages</a> with each other. So while <a href="https://www.inman.com/2018/03/09/the-week-in-financial-markets-why-arent-wages-growing-faster-in-this-booming-economy/" rel="noopener">everyone</a> <a href="https://www.washingtonpost.com/news/posteverything/wp/2017/10/09/why-arent-wages-growing-more-quickly-a-graphical-analysis/" rel="noopener">keeps</a> <a href="https://www.nationalreview.com/2017/09/growth-stagnant-economists-disagree-reasons-automation-offshoring-demographic-change/" rel="noopener">asking</a> “<a href="http://theweek.com/articles/760002/why-arent-wages-growing-faster" rel="noopener">why aren’t wages growing</a>?,” keep in mind that there is a <em>very simple fix</em> which could improve workers’ bargaining position.</p><p id="1f13">Enforcing greater wage transparency is not a silver bullet. It’s not going to completely erase all wage stagnation. But it is a powerful remedy to a labor market that favors the employer. If Americans want to see bigger paychecks, they should start by figuring out what their coworkers are making.</p><p id="64c2">Think about <em>that</em> the next time you ask for a raise.</p></div></div></div>]]>
            </description>
            <link>https://civicskunk.works/ask-your-coworkers-what-they-make-youll-earn-more-46efb2daf63e</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197935</guid>
            <pubDate>Tue, 24 Nov 2020 12:44:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everything Curl – Trace Options]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197836">thread link</a>) | @kristianpaul
<br/>
November 24, 2020 | https://ec.haxx.se/usingcurl/usingcurl-verbose/usingcurl-trace | <a href="https://web.archive.org/web/*/https://ec.haxx.se/usingcurl/usingcurl-verbose/usingcurl-trace">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div data-editioncontainer="true"><div data-slate-editor="true" data-key="a6ef002b560e4352b590a3456afb72f4" autocorrect="on" spellcheck="true" data-gramm="false"><p data-key="19ab964dd5104d0e96746d1e9325ab76"><span><span data-key="c47a63eb63b94ec497e15ed367a3313b"><span data-offset-key="c47a63eb63b94ec497e15ed367a3313b:0">There are times when </span><span data-offset-key="c47a63eb63b94ec497e15ed367a3313b:1"><code spellcheck="false" data-slate-leaf="true">-v</code></span><span data-offset-key="c47a63eb63b94ec497e15ed367a3313b:2"> is not enough. In particular, when you want to store the complete stream including the actual transferred data.</span></span></span></p><p data-key="ebacf752bc4a4890967ec23222938013"><span><span data-key="79f7332dd6bf466aacd76677ded40423"><span data-offset-key="79f7332dd6bf466aacd76677ded40423:0">For situations when curl does encrypted file transfers with protocols such as HTTPS, FTPS or SFTP, other network monitoring tools (like Wireshark or tcpdump) will not be able to do this job as easily for you.</span></span></span></p><p data-key="58ba64ab45d8412da695e15d71709c8a"><span><span data-key="388656d103e64ea080c159503ff14673"><span data-offset-key="388656d103e64ea080c159503ff14673:0">For this, curl offers two other options that you use instead of </span><span data-offset-key="388656d103e64ea080c159503ff14673:1"><code spellcheck="false" data-slate-leaf="true">-v</code></span><span data-offset-key="388656d103e64ea080c159503ff14673:2">.</span></span></span></p><p data-key="da7a8717ac1c470eae69cbe4790ce6ce"><span><span data-key="971b082de53d4f43b1fbd479951ad5dd"><span data-offset-key="971b082de53d4f43b1fbd479951ad5dd:0"><code spellcheck="false" data-slate-leaf="true">--trace [filename]</code></span><span data-offset-key="971b082de53d4f43b1fbd479951ad5dd:1"> will save a full trace in the given file name. You can also use '-' (a single minus) instead of a file name to get it passed to stdout. You would use it like this:</span></span></span></p><div><pre data-key="4cbf6e9356b64ff484fb8d13de5929bc" spellcheck="false"><p><span data-key="b9ee5fdba4e84b738b41fa1c7f15fff2"><span data-offset-key="b9ee5fdba4e84b738b41fa1c7f15fff2:0">$ curl --trace dump http://example.com</span></span></p></pre></div><p data-key="405e863d115f431dadbf90deed491cf9"><span><span data-key="005bd2da5cdc4f1485025d85c8f20bf3"><span data-offset-key="005bd2da5cdc4f1485025d85c8f20bf3:0">When completed, there's a 'dump' file that can turn out pretty sizable. In this case, the 15 first lines of the dump file looks like:</span></span></span></p><div><pre data-key="0e0c49cd57b2442fac8b95477d19da3f" spellcheck="false"><p><span data-key="44ae1b41de7f46f991bf292597d73863"><span data-offset-key="44ae1b41de7f46f991bf292597d73863:0">== Info: Rebuilt URL to: http://example.com/</span></span></p><p><span data-key="6fed896d67624b529a0fdd3edf7203d2"><span data-offset-key="6fed896d67624b529a0fdd3edf7203d2:0">== Info:   Trying 93.184.216.34...</span></span></p><p><span data-key="4404aae5e0284eca86045739a019584a"><span data-offset-key="4404aae5e0284eca86045739a019584a:0">== Info: Connected to example.com (93.184.216.34) port 80 (#0)</span></span></p><p><span data-key="a91c13b6fb19420899f0ba554ad791c0"><span data-offset-key="a91c13b6fb19420899f0ba554ad791c0:0">=&gt; Send header, 75 bytes (0x4b)</span></span></p><p><span data-key="c6f46dbe7f4f488f92bb4a297ef5052a"><span data-offset-key="c6f46dbe7f4f488f92bb4a297ef5052a:0">0000: 47 45 54 20 2f 20 48 54 54 50 2f 31 2e 31 0d 0a GET / HTTP/1.1..</span></span></p><p><span data-key="3c91a889a2fe43a0a667319325baa522"><span data-offset-key="3c91a889a2fe43a0a667319325baa522:0">0010: 48 6f 73 74 3a 20 65 78 61 6d 70 6c 65 2e 63 6f Host: example.co</span></span></p><p><span data-key="2e97d4ff01da467d85992911f65474a3"><span data-offset-key="2e97d4ff01da467d85992911f65474a3:0">0020: 6d 0d 0a 55 73 65 72 2d 41 67 65 6e 74 3a 20 63 m..User-Agent: c</span></span></p><p><span data-key="5ef52f20d4114d228d1bf5d3c67708a1"><span data-offset-key="5ef52f20d4114d228d1bf5d3c67708a1:0">0030: 75 72 6c 2f 37 2e 34 35 2e 30 0d 0a 41 63 63 65 url/7.45.0..Acce</span></span></p><p><span data-key="3984e066f33645678f4330fce9d9658b"><span data-offset-key="3984e066f33645678f4330fce9d9658b:0">0040: 70 74 3a 20 2a 2f 2a 0d 0a 0d 0a                pt: */*....</span></span></p><p><span data-key="393ecd26a68e4a88998c7e654e2b8fdb"><span data-offset-key="393ecd26a68e4a88998c7e654e2b8fdb:0">&lt;= Recv header, 17 bytes (0x11)</span></span></p><p><span data-key="8b97f7554ac14ffa92725f4d1ce50791"><span data-offset-key="8b97f7554ac14ffa92725f4d1ce50791:0">0000: 48 54 54 50 2f 31 2e 31 20 32 30 30 20 4f 4b 0d HTTP/1.1 200 OK.</span></span></p><p><span data-key="48514fc4c23648779fcbd53d72ae53df"><span data-offset-key="48514fc4c23648779fcbd53d72ae53df:0">0010: 0a                                              .</span></span></p><p><span data-key="7118cb05b71540edbdd422769bb1d41c"><span data-offset-key="7118cb05b71540edbdd422769bb1d41c:0">&lt;= Recv header, 22 bytes (0x16)</span></span></p><p><span data-key="eedfedbbe314499f904e81cad9e260c6"><span data-offset-key="eedfedbbe314499f904e81cad9e260c6:0">0000: 41 63 63 65 70 74 2d 52 61 6e 67 65 73 3a 20 62 Accept-Ranges: b</span></span></p><p><span data-key="7a13f50dcfd74da5aff6f4598e00f943"><span data-offset-key="7a13f50dcfd74da5aff6f4598e00f943:0">0010: 79 74 65 73 0d 0a                               ytes..</span></span></p></pre></div><p data-key="e1381af0207e449a94931cb2b99773da"><span><span data-key="40a899c38f7b4a98a7387c1526a19730"><span data-offset-key="40a899c38f7b4a98a7387c1526a19730:0">Every single sent and received byte get displayed individually in hexadecimal numbers.</span></span></span></p><p data-key="3be1a1fe222a45b39a27341b6371848c"><span><span data-key="aa4dc13ee63040aab0c0303f6f7e5650"><span data-offset-key="aa4dc13ee63040aab0c0303f6f7e5650:0">If you think the hexadecimals are not helping, you can try </span><span data-offset-key="aa4dc13ee63040aab0c0303f6f7e5650:1"><code spellcheck="false" data-slate-leaf="true">--trace-ascii [filename]</code></span><span data-offset-key="aa4dc13ee63040aab0c0303f6f7e5650:2"> instead, also this accepting '-' for stdout and that makes the 15 first lines of tracing look like:</span></span></span></p><div><pre data-key="22868136a84e4e15810fefe740495ec8" spellcheck="false"><p><span data-key="9e299d2991d6426ba442339ee9e9f139"><span data-offset-key="9e299d2991d6426ba442339ee9e9f139:0">== Info: Rebuilt URL to: http://example.com/</span></span></p><p><span data-key="80b9bc8a91c2435bb40fba6cb5dfa9ff"><span data-offset-key="80b9bc8a91c2435bb40fba6cb5dfa9ff:0">== Info:   Trying 93.184.216.34...</span></span></p><p><span data-key="149c766c24ed40f386d75b401156ae33"><span data-offset-key="149c766c24ed40f386d75b401156ae33:0">== Info: Connected to example.com (93.184.216.34) port 80 (#0)</span></span></p><p><span data-key="2eb4b3433be241cf9d8eb7187f2f7e0b"><span data-offset-key="2eb4b3433be241cf9d8eb7187f2f7e0b:0">=&gt; Send header, 75 bytes (0x4b)</span></span></p><p><span data-key="19e16419fc4a4a18967d864bd04c66c0"><span data-offset-key="19e16419fc4a4a18967d864bd04c66c0:0">0000: GET / HTTP/1.1</span></span></p><p><span data-key="e1bda71508224e9fb07f75c1910e48ab"><span data-offset-key="e1bda71508224e9fb07f75c1910e48ab:0">0010: Host: example.com</span></span></p><p><span data-key="b2b1088640fd4ae5ab0cc1b6ca6483be"><span data-offset-key="b2b1088640fd4ae5ab0cc1b6ca6483be:0">0023: User-Agent: curl/7.45.0</span></span></p><p><span data-key="d6d0ce807724460789e6ebb6f6e892ec"><span data-offset-key="d6d0ce807724460789e6ebb6f6e892ec:0">003c: Accept: */*</span></span></p><p><span data-key="a78aa7be8d554fa6a96f7c9d6ffbfa23"><span data-offset-key="a78aa7be8d554fa6a96f7c9d6ffbfa23:0">0049:</span></span></p><p><span data-key="39c0feb1902f44e1a5510b833f89f811"><span data-offset-key="39c0feb1902f44e1a5510b833f89f811:0">&lt;= Recv header, 17 bytes (0x11)</span></span></p><p><span data-key="872de778b8e54a4ca78408bb59ad8477"><span data-offset-key="872de778b8e54a4ca78408bb59ad8477:0">0000: HTTP/1.1 200 OK</span></span></p><p><span data-key="7219088e0db041a686b8de990b9ce04c"><span data-offset-key="7219088e0db041a686b8de990b9ce04c:0">&lt;= Recv header, 22 bytes (0x16)</span></span></p><p><span data-key="fb7b2cac706844fabd0b49ed2853a9b4"><span data-offset-key="fb7b2cac706844fabd0b49ed2853a9b4:0">0000: Accept-Ranges: bytes</span></span></p><p><span data-key="73d1394550f4418c8c83309c8fe64c6c"><span data-offset-key="73d1394550f4418c8c83309c8fe64c6c:0">&lt;= Recv header, 31 bytes (0x1f)</span></span></p><p><span data-key="f69380f0d894401199a175232fb1082d"><span data-offset-key="f69380f0d894401199a175232fb1082d:0">0000: Cache-Control: max-age=604800</span></span></p></pre></div><p data-key="21a030a4b3934ff086e961b01bacf8c5"><span><span data-key="45a9708d34fa4752b596d88b6c328371"><span data-offset-key="45a9708d34fa4752b596d88b6c328371:0">This options prefixes all verbose/trace outputs with a high resolution timer for when the line is printed. It works with the regular </span><span data-offset-key="45a9708d34fa4752b596d88b6c328371:1"><code spellcheck="false" data-slate-leaf="true">-v / --verbose</code></span><span data-offset-key="45a9708d34fa4752b596d88b6c328371:2"> option as well as with </span><span data-offset-key="45a9708d34fa4752b596d88b6c328371:3"><code spellcheck="false" data-slate-leaf="true">--trace</code></span><span data-offset-key="45a9708d34fa4752b596d88b6c328371:4"> and </span><span data-offset-key="45a9708d34fa4752b596d88b6c328371:5"><code spellcheck="false" data-slate-leaf="true">--trace-ascii</code></span><span data-offset-key="45a9708d34fa4752b596d88b6c328371:6">.</span></span></span></p><p data-key="7dbd3d9e6be64569ae4ebfea8bdc44bf"><span><span data-key="d1a95ff5f69a4df297db6d12ca769d30"><span data-offset-key="d1a95ff5f69a4df297db6d12ca769d30:0">An example could look like this:</span></span></span></p><div><pre data-key="f3da03e1fe2f4e2dac6c9f1e40521e40" spellcheck="false"><p><span data-key="cacf73c781794099a94f5b902e53b860"><span data-offset-key="cacf73c781794099a94f5b902e53b860:0">$ curl -v --trace-time http://example.com</span></span></p><p><span data-key="1276cd54ea564f18b7a06b52900c17c6"><span data-offset-key="1276cd54ea564f18b7a06b52900c17c6:0">23:38:56.837164 * Rebuilt URL to: http://example.com/</span></span></p><p><span data-key="b13c21a8314e458baeee201b73f970e2"><span data-offset-key="b13c21a8314e458baeee201b73f970e2:0">23:38:56.841456 *   Trying 93.184.216.34...</span></span></p><p><span data-key="5ef410ea4c8a4361bf582f6d3a529375"><span data-offset-key="5ef410ea4c8a4361bf582f6d3a529375:0">23:38:56.935155 * Connected to example.com (93.184.216.34) port 80 (#0)</span></span></p><p><span data-key="0217c735977049c1a784a28bf069dfce"><span data-offset-key="0217c735977049c1a784a28bf069dfce:0">23:38:56.935296 &gt; GET / HTTP/1.1</span></span></p><p><span data-key="3e04d627753b4d09a993df6cffa6957f"><span data-offset-key="3e04d627753b4d09a993df6cffa6957f:0">23:38:56.935296 &gt; Host: example.com</span></span></p><p><span data-key="4bcff79e2b814cce8580b3e7b6bdd83b"><span data-offset-key="4bcff79e2b814cce8580b3e7b6bdd83b:0">23:38:56.935296 &gt; User-Agent: curl/7.45.0</span></span></p><p><span data-key="a36dc28f81b44594bb976f8fcccf8f88"><span data-offset-key="a36dc28f81b44594bb976f8fcccf8f88:0">23:38:56.935296 &gt; Accept: */*</span></span></p><p><span data-key="fe46ebea85294730aa0343db560b267e"><span data-offset-key="fe46ebea85294730aa0343db560b267e:0">23:38:56.935296 &gt;</span></span></p><p><span data-key="84569ebfbf29412baf4978628e7be2ce"><span data-offset-key="84569ebfbf29412baf4978628e7be2ce:0">23:38:57.029570 &lt; HTTP/1.1 200 OK</span></span></p><p><span data-key="4fea7818e129445397f0d80923b92786"><span data-offset-key="4fea7818e129445397f0d80923b92786:0">23:38:57.029699 &lt; Accept-Ranges: bytes</span></span></p><p><span data-key="924e7f8c5f434d6288a907642f83342b"><span data-offset-key="924e7f8c5f434d6288a907642f83342b:0">23:38:57.029803 &lt; Cache-Control: max-age=604800</span></span></p><p><span data-key="c05e4aa2dae740dc955924488c78a2f0"><span data-offset-key="c05e4aa2dae740dc955924488c78a2f0:0">23:38:57.029903 &lt; Content-Type: text/html</span></span></p><p><span data-key="479f1288467c414a92097deb991b5fa5"><span data-offset-key="479f1288467c414a92097deb991b5fa5:0">---- snip ----</span></span></p></pre></div><p data-key="6fa17657da7c4b9fb344c095331193e5"><span><span data-key="4c19bbee96c14e618d2e5b80ae437f5b"><span data-offset-key="4c19bbee96c14e618d2e5b80ae437f5b:0">The lines are all the local time as hours:minutes:seconds and then number of microseconds in that second.</span></span></span></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://ec.haxx.se/usingcurl/usingcurl-verbose/usingcurl-trace</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197836</guid>
            <pubDate>Tue, 24 Nov 2020 12:31:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Serverless Cloud Platform for Building Chat Apps with Node.js]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197365">thread link</a>) | @aaronnwabuoku
<br/>
November 24, 2020 | https://www.chatkitty.com/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/ | <a href="https://web.archive.org/web/*/https://www.chatkitty.com/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>In <a href="https://www.chatkitty.com/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/">this tutorial series</a>
, I'll be showing you how to build a functional and secure chat app using 
the latest React Native libraries, the Expo framework, and Firebase, powered by the ChatKitty platform.</p><div>
          <p>This is the first article of this series. After reading this article, you will be able to:</p>
<ol>
<li><p>Create an Expo React Native application</p>
</li>
<li><p>Create a Firebase project for user authentication</p>
</li>
<li><p>Create a ChatKitty project and connect to ChatKitty to provide real-time chat functionality</p>
</li>
<li><p>Use Firebase Authentication and ChatKitty Chat Functions to securely implement user login</p>
</li>
</ol>
<h2 id="what-is-react-native">What is React Native?</h2>
<p><a href="https://reactnative.dev/">React Native</a> is a great way to develop both web and mobile applications very 
quickly, while sharing a lot of code when targeting multiple platforms. With a mature ecosystem of libraries 
and tooling, using React Native is not only fast but also reliable. Trusted by organizations like Facebook, 
Shopify, and Tesla - React Native is a stable framework for building both iOS and Android apps.</p>
<h2 id="what-is-expo">What is Expo?</h2>
<p>The <a href="https://expo.io/">Expo</a> framework builds on top of React Native to allow developers to build universal 
React applications in minutes. With Expo, you can develop, build, deploy and quickly iterate on iOS, Android and web 
apps from the same JavaScript code. Expo has made creating both web and mobile applications very accessible, 
handling would-be complex workflows like multi-platform deployment and advanced features like push notifications.</p>
<h2 id="what-is-firebase">What is Firebase?</h2>
<p><a href="https://firebase.google.com/">Firebase</a> is a <a href="https://www.cloudflare.com/learning/serverless/glossary/backend-as-a-service-baas/">Backend-as-a-Service</a> 
offering by Google. It provides developers a wide array of tools and services to develop quality apps 
without having to manage servers. Firebase provides key features like authentication, a real-time database, and hosting.</p>
<h2 id="what-are-chatkitty-chat-functions">What are ChatKitty Chat Functions?</h2>
<p>ChatKitty provides <strong>Chat Functions</strong>, <a href="https://www.cloudflare.com/learning/serverless/what-is-serverless/">serverless</a> 
cloud functions that allow you to define custom logic for complex tasks like user authentication, and respond 
to chat events that happen within your application. With ChatKitty Chat Functions, there's no need for you 
to build a backend to develop chat apps. ChatKitty Chat Functions auto-scale for you, and only cost you when they run.
Chat Functions lower the total cost of maintaining your chat app, enabling you to build more logic, faster.</p>
<h2 id="prerequisites">Prerequisites</h2>
<p>To develop apps with Expo and React Native, you should be able to write and understand JavaScript or 
TypeScript code. To define ChatKitty Chat Functions, you'll need to be familiar with basic JavaScript.</p>
<p>You'll need a version of <a href="https://nodejs.org/en/download/">Node.js</a> above <code>10.x.x</code> installed on your local machine 
to build this React Native app.</p>
<p>You'll need to install the <a href="https://docs.expo.io/workflow/expo-cli/">Expo CLI tool</a> through npm or npx.</p>
<p>For a complete walk-through on how to set up a development environment for Expo, you can go through 
<a href="https://docs.expo.io/get-started/installation/">the official documentation here</a>.</p>
<p>You can checkout our Expo React Native sample code any time <a href="https://github.com/ChatKitty/chatkitty-example-react-native/">on GitHub</a>.</p>
<h2 id="creating-project-and-installing-libraries">Creating project and installing libraries</h2>
<p>First, initialize a new Expo project with the <strong>blank managed</strong> workflow. To do so, you're going to 
need to open a terminal window and execute:</p>
<pre><code>expo init chatkitty-example-react-native</code></pre>


<p>After creating the initial application. You can enter the app root directory and run the app:</p>
<pre><code># navigate inside the project directory
cd chatkitty-example-react-native

# for android
expo start --android

# for ios
expo start --ios

# for web 
expo start --web</code></pre>


<p>If you run your newly created React Native application using Expo, you should see:</p>
<p><img src="https://www.chatkitty.com/images/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/screenshot-created-project.png" alt="Screenshot: Created Project">  </p>
<p>Now we have our blank project, we can install the React Native libraries we'll need:</p>
<pre><code># install following libraries for React Native and Firebase
yarn add @react-navigation/native @react-navigation/stack react-native-reanimated react-native-gesture-handler react-native-screens react-native-safe-area-context @react-native-community/masked-view react-native-paper react-native-vector-icons firebase</code></pre>
<h2 id="creating-reusable-form-elements">Creating reusable form elements</h2>
<p>We'll be creating Login and Signup screens soon which share similar logic. To prevent us from violating 
the <a href="https://thevaluable.dev/dry-principle-cost-benefit-example/">DRY principle</a>, let's create some 
reusable form components that we can share across these two screens. We'll also create a loading spinner 
component to provide a good user experience whenever a user waits for a long screen transition.</p>
<p>We'll create reusable <code>FormInput</code>, <code>FormButton</code>, and <code>Loading</code> UI components. At the root of this Expo
React Native app, create a <code>src/</code> directory and inside it create another new <code>components/</code> directory.</p>
<p>Inside the <code>src/components/</code> directory, create a new JavaScript file <code>FormInput.js</code>. In this file, we'll 
define a <a href="https://reactjs.org/docs/react-component.html">React component</a> to provide a text input field 
for our Login and Signup screens to use for the user to enter their credentials.</p>
<p>The <code>FormInput.js</code> file should contain the following code snippet:</p>
<pre><code>import React from 'react';
import { StyleSheet, Dimensions } from 'react-native';
import { TextInput } from 'react-native-paper';

const { width, height } = Dimensions.get('screen');

export default function FormInput({ labelName, ...rest }) {
  return (
    &lt;TextInput
      label={labelName}
      style={styles.input}
      numberOfLines={1}
      {...rest}
    /&gt;
  );
}

const styles = StyleSheet.create({
  input: {
    marginTop: 10,
    marginBottom: 10,
    width: width / 1.5,
    height: height / 15,
  },
});</code></pre>


<p>Our next reusable component is going to be in another file <code>FormButton.js</code>. We use it to display a button 
for a user to confirm their credentials.</p>
<p>The <code>FormButton.js</code> file should contain:</p>
<pre><code>import React from 'react';
import { StyleSheet, Dimensions } from 'react-native';
import { Button } from 'react-native-paper';

const { width, height } = Dimensions.get('screen');

export default function FormButton({ title, modeValue, ...rest }) {
  return (
    &lt;Button
      mode={modeValue}
      {...rest}
      style={styles.button}
      contentStyle={styles.buttonContainer}
    &gt;
      {title}
    &lt;/Button&gt;
  );
}

const styles = StyleSheet.create({
  button: {
    marginTop: 10,
  },
  buttonContainer: {
    width: width / 2,
    height: height / 15,
  },
});</code></pre>


<p>Finally, create a <code>Loading.js</code> file. We'll use it to display a loading spinner when a user waits for a 
screen transition.</p>
<p>The <code>Loading.js</code> file should contain:</p>
<pre><code>import React from 'react';
import { View, ActivityIndicator, StyleSheet } from 'react-native';

export default function Loading() {
  return (
    &lt;View style={styles.loadingContainer}&gt;
      &lt;ActivityIndicator size="large" color="#5b3a70" /&gt;
    &lt;/View&gt;
  );
}

const styles = StyleSheet.create({
  loadingContainer: {
    flex: 1,
    alignItems: 'center',
    justifyContent: 'center',
  },
});</code></pre>


<p>Now we have our reusable form components, we can create a Login screen for users to enter our chat app.</p>
<h2 id="creating-a-login-screen">Creating a login screen</h2>
<div><p>The first screen we'll be creating is the login screen. We'll ask an existing user for their email and 
password to authenticate and provide a link to a future sign up form for new users to register with our app.
</p><p>
The login screen should look like this after you're done:</p></div>
<p><img src="https://www.chatkitty.com/images/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/screenshot-login-screen.png" alt="Screenshot: Login screen">  </p>
<p>Inside the <code>src/</code>, create a <code>screens/</code> directory, inside this directory create a <code>LoginScreen.js</code> file.</p>
<p>The <code>LoginScreen.js</code> file should contain:</p>
<pre><code>import React, { useState } from 'react';
import { View, StyleSheet } from 'react-native';
import { Title } from 'react-native-paper';
import FormInput from '../components/FormInput';
import FormButton from '../components/FormButton';

export default function LoginScreen({ navigation }) {
  const [email, setEmail] = useState('');
  const [password, setPassword] = useState('');

  return (
    &lt;View style={styles.container}&gt;
      &lt;Title style={styles.titleText}&gt;Welcome!&lt;/Title&gt;
      &lt;FormInput
        labelName="Email"
        value={email}
        autoCapitalize="none"
        onChangeText={(userEmail) =&gt; setEmail(userEmail)}
      /&gt;
      &lt;FormInput
        labelName="Password"
        value={password}
        secureTextEntry={true}
        onChangeText={(userPassword) =&gt; setPassword(userPassword)}
      /&gt;
      &lt;FormButton
        title="Login"
        modeValue="contained"
        labelStyle={styles.loginButtonLabel}
        onPress={() =&gt; {
          // TODO
        }}
      /&gt;
      &lt;FormButton
        title="Sign up here"
        modeValue="text"
        uppercase={false}
        labelStyle={styles.navButtonText}
        onPress={() =&gt; navigation.navigate('Signup')}
      /&gt;
    &lt;/View&gt;
  );
}

const styles = StyleSheet.create({
  container: {
    backgroundColor: '#f5f5f5',
    flex: 1,
    justifyContent: 'center',
    alignItems: 'center',
  },
  titleText: {
    fontSize: 24,
    marginBottom: 10,
  },
  loginButtonLabel: {
    fontSize: 22,
  },
  navButtonText: {
    fontSize: 16,
  },
});</code></pre>


<p>Later, you'll hook up this login screen to ChatKitty to log in users into your app. We've also configured 
the <code>navigation</code> prop to navigate the user to the Signup screen you'll soon be creating. For now, 
let's add a stack navigator to direct users to the initial login route.</p>
<p>Create a new directory <code>src/navigation/</code>. This will contain all the routes and components needed to build 
the app's navigation. Inside this directory, create a <code>AuthStack.js</code> file.</p>
<p>The <code>AuthStack.js</code> file should contain:</p>
<pre><code>import React from 'react';
import { createStackNavigator } from '@react-navigation/stack';
import LoginScreen from '../screens/LoginScreen';

const Stack = createStackNavigator();

export default function AuthStack() {
  return (
    &lt;Stack.Navigator initialRouteName="Login" headerMode="none"&gt;
      &lt;Stack.Screen name="Login" component={LoginScreen} /&gt;
    &lt;/Stack.Navigator&gt;
  );
}</code></pre>


<p>Later, you'll be adding another route for the Signup screen to our navigator.</p>
<p>Next, you'll need a navigation container to hold the app's stacks, starting with the auth stack. 
Create a <code>Routes.js</code> file inside the <code>src/navigation/</code> directory.</p>
<p>The <code>Routes.js</code> file should contain:</p>
<pre><code>import React from 'react';
import { NavigationContainer } from '@react-navigation/native';
import AuthStack from './AuthStack';

export default function Routes() {
  return (
    &lt;NavigationContainer&gt;
      &lt;AuthStack /&gt;
    &lt;/NavigationConta…</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.chatkitty.com/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/">https://www.chatkitty.com/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/</a></em></p>]]>
            </description>
            <link>https://www.chatkitty.com/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197365</guid>
            <pubDate>Tue, 24 Nov 2020 11:05:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Virtual Experiences for Teams]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197289">thread link</a>) | @joalavedra
<br/>
November 24, 2020 | https://onsite.fun/activities | <a href="https://web.archive.org/web/*/https://onsite.fun/activities">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div mb="2"><div><div><p>Connecting teams through personalized and curated virtual activities.</p></div></div><div><div><ul><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f96c0c35e980c07219862d7"><div><div><div><div width="0"><p><img alt="4" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJhcmNoZW9sb2d5X29mX2xlYXZlczA1LmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJhcmNoZW9sb2d5X29mX2xlYXZlczAxLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJhcmNoZW9sb2d5X29mX2xlYXZlczAyLnBuZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJhcmNoZW9sb2d5X29mX2xlYXZlczAzLkpQRyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJhcmNoZW9sb2d5X29mX2xlYXZlczA0LnBuZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="4" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJhcmNoZW9sb2d5X29mX2xlYXZlczA1LmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJhcmNoZW9sb2d5X29mX2xlYXZlczAxLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div></div></div></div><div><p><h6>Archaeology of Leaves</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>Serbian</span></p><p><span> English</span></p><p><span> Spanish</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f96e639d43a3b033484d677"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ2aXJ0dWFsX3N0cmVldF9hcnRfYWR2ZW50dXJlMy5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ2aXJ0dWFsX3N0cmVldF9hcnRfYWR2ZW50dXJlMC5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ2aXJ0dWFsX3N0cmVldF9hcnRfYWR2ZW50dXJlMS5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ2aXJ0dWFsX3N0cmVldF9hcnRfYWR2ZW50dXJlMi5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ2aXJ0dWFsX3N0cmVldF9hcnRfYWR2ZW50dXJlMy5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ2aXJ0dWFsX3N0cmVldF9hcnRfYWR2ZW50dXJlMC5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div></div></div></div><div><p><h6>The Lisbon Street Art Adventure</h6></p><div><p>From 75€</p><p> / 5 people</p></div><div><div><p><span>English</span></p><p><span>Portuguese</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f96eab3d43a3b033484d678"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJkaXNjb3Zlcl92aXN1YWxfdGhpbmtpbmcwNC5qcGVnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJkaXNjb3Zlcl92aXN1YWxfdGhpbmtpbmcwMS5qcGVnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJkaXNjb3Zlcl92aXN1YWxfdGhpbmtpbmcwMi5qcGVnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJkaXNjb3Zlcl92aXN1YWxfdGhpbmtpbmcwMy5qcGVnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJkaXNjb3Zlcl92aXN1YWxfdGhpbmtpbmcwNC5qcGVnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJkaXNjb3Zlcl92aXN1YWxfdGhpbmtpbmcwMS5qcGVnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div></div></div></div><div><p><h6>Discover Visual Thinking</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>Greek</span></p><p><span>English</span></p><p><span>Spanish</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f96f32bd43a3b033484d679"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJtYWdpY19zaG93MDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJtYWdpY19zaG93MDMuanBlZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJtYWdpY19zaG93MDQuanBlZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJtYWdpY19zaG93MDIuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJtYWdpY19zaG93MDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJtYWdpY19zaG93MDMuanBlZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div></div></div></div><div><p><h6>Magic Show with a Professional Magician</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>English</span></p><p><span>French</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f970a2ed43a3b033484d67a"><div><div><div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJjb2NrdGFpbF9tYXN0ZXJjbGFzczA0LmpwZWciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJjb2NrdGFpbF9tYXN0ZXJjbGFzczAxLmpwZWciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJjb2NrdGFpbF9tYXN0ZXJjbGFzczAyLmpwZWciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJjb2NrdGFpbF9tYXN0ZXJjbGFzczA0LmpwZWciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJjb2NrdGFpbF9tYXN0ZXJjbGFzczAxLmpwZWciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div></div></div></div><div><p><h6>Cocktail Workshop and Masterclass</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>English</span></p><p><span>Portuguese</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f970dc8d43a3b033484d67b"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ0aGVfc2VjcmV0c19zY2FuZGFsMDQuSlBHIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ0aGVfc2VjcmV0c19zY2FuZGFsMDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ0aGVfc2VjcmV0c19zY2FuZGFsMDIuSlBHIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ0aGVfc2VjcmV0c19zY2FuZGFsMDMuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ0aGVfc2VjcmV0c19zY2FuZGFsMDQuSlBHIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ0aGVfc2VjcmV0c19zY2FuZGFsMDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div></div></div></div><div><p><h6>The Secrets and Scandal of art at the Borghese</h6></p><div><p>From 75€</p><p> / 5 people</p></div><div><div><p><span>English</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f989d667c1a08065afb4615"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJlc3BhZHJpbGxhMDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJlc3BhZHJpbGxhMDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJlc3BhZHJpbGxhMDIuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJlc3BhZHJpbGxhMDMuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJlc3BhZHJpbGxhMDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJlc3BhZHJpbGxhMDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div></div></div></div><div><p><h6>Create Your Own Espadrilles Workshop</h6></p><div><p>From 350€</p><p> / 5 people</p></div><div><div><p><span>English</span></p><p><span>Spanish</span></p><p><span>French</span></p></div></div></div><div><div><div><div><p><span>Material included</span></p></div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f9e8c9d758ef0033ec1c532"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJvbmxpbmVfc2NhcGVfcm9vbTA0LmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJvbmxpbmVfc2NhcGVfcm9vbTAxLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJvbmxpbmVfc2NhcGVfcm9vbTAyLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJvbmxpbmVfc2NhcGVfcm9vbTAzLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJvbmxpbmVfc2NhcGVfcm9vbTA0LmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJvbmxpbmVfc2NhcGVfcm9vbTAxLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div></div></div></div><div><p><h6>Online Live Escape Room</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>English</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5fa47a42ccb5fb037cbcc1e6"><div><div><div><div width="0"><p><img alt="4" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJsYXRpbl9hbWVyaWNhbl9kYW5jZV9jbGFzczA1LmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJsYXRpbl9hbWVyaWNhbl9kYW5jZV9jbGFzczAxLlBORyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJsYXRpbl9hbWVyaWNhbl9kYW5jZV9jbGFzczAyLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJsYXRpbl9hbWVyaWNhbl9kYW5jZV9jbGFzczAzLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJsYXRpbl9hbWVyaWNhbl9kYW5jZV9jbGFzczA0LmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="4" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJsYXRpbl9hbWVyaWNhbl9kYW5jZV9jbGFzczA1LmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJsYXRpbl9hbWVyaWNhbl9kYW5jZV9jbGFzczAxLlBORyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div></div></div></div><div><p><h6>Unlock your body with some dance moves</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>English</span></p><p><span>Russian</span></p><p><span>Spanish</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5fa482163f481803d20dd8f7"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJnbm9jY2hpX3BhcnR5MDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJnbm9jY2hpX3BhcnR5MDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJnbm9jY2hpX3BhcnR5MDIuanBlZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJnbm9jY2hpX3BhcnR5MDMuanBlZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJnbm9jY2hpX3BhcnR5MDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJnbm9jY2hpX3BhcnR5MDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div></div></div></div><div><p><h6>Have a Gnocchi Party with your team</h6></p><div><p>From 125€</p><p> / 5 people</p></div><div><div><p><span>English</span></p><p><span>Italian</span></p><p><span>Portuguese</span></p><p><span>Spanish</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5fad1a07687d9703518bcd6c"><div><div><div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ5b2dhX2Zsb3cwMy5wbmciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ5b2dhX2Zsb3cwMS5wbmciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ5b2dhX2Zsb3cwMi5wbmciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ5b2dhX2Zsb3cwMy5wbmciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ5b2dhX2Zsb3cwMS5wbmciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div></div></div></div><div><p><h6>Unwind your body with yoga flow </h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>Spanish</span></p><p><span>English</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5fb548072af9a4030c9e0969"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJibHVlX21lbW9yaWVzMDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJibHVlX21lbW9yaWVzMDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJibHVlX21lbW9yaWVzMDIuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJibHVlX21lbW9yaWVzMDMuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJibHVlX21lbW9yaWVzMDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJibHVlX21lbW9yaWVzMDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div></div></div></div><div><p><h6>Drawing Memories With Blue Ink</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>Spanish</span></p><p><span>English</span></p><p><span>Greek</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5fbae89ecd4d220339f54148"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJmcmVuY2hfcGFzdHJ5MDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJmcmVuY2hfcGFzdHJ5MDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJmcmVuY2hfcGFzdHJ5MDIuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJmcmVuY2hfcGFzdHJ5MDMuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJmcmVuY2hfcGFzdHJ5MDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJmcmVuY2hfcGFzdHJ5MDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div></div></div></div><div><p><h6>Sweet French Pastry</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>English</span></p><p><span>Spanish</span></p></div></div></div><div><p><span>NEW</span></p></div><div><div><div></div></div></div><span></span></a></div></div></div></li></ul></div></div></div></div></div>]]>
            </description>
            <link>https://onsite.fun/activities</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197289</guid>
            <pubDate>Tue, 24 Nov 2020 10:54:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Goodbye breakfast: 6 months of Intermittent Fasting]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25197199">thread link</a>) | @beatlevic
<br/>
November 24, 2020 | https://beatletech.com/2020/11/24/goodbye-breakfast | <a href="https://web.archive.org/web/*/https://beatletech.com/2020/11/24/goodbye-breakfast">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            
            

            <p>Tuesday, 24 November 2020.</p>

            <p><img src="https://s3-eu-west-1.amazonaws.com/eu-west-1.beatletech.com/images/intermittent-fasting-mogwai-16-8-blue.png" alt="Intermittent Fasting 16/8" width="70%" title="Intermittent Fasting 16/8"></p>

<p><em><strong>DISCLAIMER:</strong> I’m not an MD, so please read this blog post only as an interesting starting point for your own research and always check with your own doctor or dietician if you want to try this at home. You are responsible for your own health.</em></p>

<hr>

<p>For the past 6 months I have been doing <code>intermittent fasting</code> (IF) by eating daily only during an 8 hour window: between noon and 8pm. On top of that I had three water-only fasts where I didn’t eat anything for multiple days (4-5) in a row.</p>

<p>That’s madness you might say! Why would you starve yourself? Breakfast is the most important meal of the day and you are skipping it!</p>

<p>Well, I currently believe that it would be madness NOT to fast, and have both scientific and 6 months of anecdotal evidence to back that up. When I was just a few weeks into intermittent fasting, I was already so positively surprised by the initial results that I wanted to tell everybody about my “discovery”, especially because I believed I could also explain why and how it works after reading into the physiology and research behind it. I decided to first see if I could stick with it for a couple of months and then write about my experiences. So here I am, 6 months later, ready to tell you all about my journey and “why” intermittent fasting is so interesting.</p>

<h3 id="benefits">Benefits</h3>

<p>Before we dive in, what’s in it for you? What kind of benefits are we talking about? There are the following immediate known and lasting benefits that I experienced:</p>
<ul>
  <li>Weight loss</li>
  <li>Higher levels of energy</li>
  <li>Feeling stronger (due to increase in human growth hormone)</li>
  <li>Better focus</li>
  <li>Decrease in hay fever symptoms (to be fair, I could have been lucky with a mild season)</li>
</ul>

<p>And there are (potential) long term benefits (<a href="https://www.nejm.org/doi/full/10.1056/nejmra1905136">1</a>, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3106288/">2</a>, <a href="https://www.healthline.com/nutrition/10-health-benefits-of-intermittent-fasting">3</a>):</p>
<ul>
  <li>Cellular repair (Autopaghy)</li>
  <li>Decreased <a href="https://www.webmd.com/diabetes/insulin-resistance-syndrome">insulin resistance</a></li>
  <li>Decreased incidence of diseases, including cancers, obesity, neurological disorders and cardiovascular disease.</li>
  <li>Increased stress resistance</li>
  <li>Increased longevity and quality of life</li>
</ul>

<p>Fasting sounds like a miracle drug doesn’t it? You don’t even have to pay money for it! That’s also probably why you won’t see any fasting ads on your timeline or tv commercials (e.g., “Stop buying our cornflakes and just skip breakfast now!”). It is essentially free and available for you to try out.</p>

<p>Without further ado, let’s explore intermittent fasting and why it works.</p>

<h3 id="intermittent-fasting">Intermittent Fasting</h3>

<p>People have been actively fasting, i.e., periods of consciously not eating, since ancient times (<a href="https://thefastingmethod.com/fasting-a-history-part-i/">4</a>) and it has, unwillingly, been part of the eating pattern of our ancestors when food wasn’t always around (e.g. hunting on an empty stomach), although strictly speaking you would call it starvation if you don’t know when you will get your next meal. It just shows, that our bodies have been evolutionary adapted to handle feast and famine. It’s being exposed to stress, variability, volatility and randomness (up to a point and not continuously), that makes us stronger (i.e., <a href="https://en.wikipedia.org/wiki/Antifragile">antifragile</a>).</p>

<p>Recently intermittent fasting has become a more popular form of fasting, which can be defined as <strong>an eating pattern in which you cycle between periods of eating and fasting</strong>, where you stretch each fasting period long enough to force your body into switching from burning glucose (sugar) and glycogen (stored sugar) to fat burning. This is what is called <code>metabolic flexibility</code>, where your body makes use of whatever fuel is available. As a bonus, it seems that ketosis (i.e., the metabolic state running on fat for fuel) is the main driver for fat burning in the abdomen region, belly fat!</p>

<p><strong>So how long do you have to NOT eat to switch to fat burning?</strong> Apparently, energy intake restriction for 10 to 14 hours results in depletion of liver glycogen stores (<a href="https://www.nejm.org/doi/full/10.1056/nejmra1905136">1</a>, <a href="https://www.semanticscholar.org/paper/Fuel-metabolism-in-starvation.-Cahill/a8bb8327226d35259e68ecd8edcc17a3a1380f4a">5</a>) after which fat, fatty acids, are freed to form <code>ketones</code> that are used to fuel your body (as opposed to glucose). The more <code>fat adapted</code> you are, the quicker your body will switch to fat burning, something you get more adapted to as a result of prolonged intermittent fasting.</p>

<p>Given the required minimum of 10 to 14 hours of fasting to start producing ketones, you have different patterns for intermittent fasting you could follow:</p>
<ul>
  <li><strong>16/8</strong>: A daily window of 8 hours, often from noon to 8pm (so no breakfast), for eating and 16 hours of fasting (during the night and morning).</li>
  <li><strong>5:2</strong>: 5 days eating, 2 days fasting.</li>
  <li><strong>Alternate day</strong>: Alternate days of eating and fasting</li>
  <li><strong>One Meal a Day (OMAD)</strong>: Sticking to one meal a day, often dinner, and fast the rest of the day.</li>
</ul>

<p>I chose <strong>16/8</strong>, because it fits nicely with having kids that are not on a fasting schedule (nor should they ever be when they are young and still growing), having lunch and dinner together. I also like the consistency of following the same schedule every day, apart from sporadic multi-day periods of water-only fasts (more on that later).</p>

<p><strong>Aren’t you also burning up your muscles during fasting?</strong> Nope. Your body is naturally preserving your muscles by increasing <code>human growth hormone</code> (HGH), which also helps building muscles after the fasting period as HGH levels remain high.</p>

<p><strong>So all the benefits come from fat burning and the increase in human growth hormone?</strong> Actually those account for only part of the benefits. The third and arguable the most interesting process during fasting is called <code>autophagy</code>, which literally translates to “self eating”, an apt description for the cellular repair and rejuvenation that will happen in your body.</p>

<h4 id="autophagy">Autophagy</h4>

<p>Your body continuously needs amino acids, the building blocks for new cells, and when you are not eating you are not taking in new amino acids (proteins). The body already recycles your old and damaged cells to harvest these building blocks, but during fasting has to work harder to get enough of this material. It does this by increasing your immune system in order to “scavenge” in all the nooks and crannies of your body for cells to break down. Cells that otherwise would be “good enough yet mediocre” are now also recycled.</p>

<p>This is the only process known to rejuvenate neural pathways when you are getting older, and you will be safeguarding and protecting yourself against neurological and auto-immune disorders (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3106288/">2</a>).</p>

<p>The importance of autophagy has also been clearly demonstrated by Japanese cell biologist Yoshinori Ohsumi, who won, in 2016, the Nobel Prize in Medicine for his research on this very topic, showing how autophagy helps slow down the aging process (<a href="https://www.nobelprize.org/prizes/medicine/2016/press-release/">6</a>).</p>

<h4 id="key-concepts">Key concepts</h4>

<p>Now that we covered what intermittent fasting is, how it works and benefits you, by going over some of the key concepts: the metabolic switch to fat burning, the increase in human growth hormone and autophagy. I like to move on to sharing my experience of putting intermittent fasting into practice.</p>

<h3 id="my-6-month-journey">My 6 Month Journey</h3>

<p>During the first Coronavirus lockdown in April (in the Netherlands), I spent most of my time homeschooling my three kids and working for <a href="https://rekall.ai/">rekall.ai</a>, while neglecting sporting activities and not eating healthy consistently (e.g., more snacks). So when the kids were allowed to go back to school again in May, I stepped on the scale and found myself nearing 100 kg. This for me, being 1.98m tall (6’6”), meant I was being borderline overweight according to my <a href="https://www.nhlbi.nih.gov/health/educational/lose_wt/BMI/bmicalc.htm">BMI</a> calculation (&gt;25). I have never seen myself weigh more than 100 kg (220 lb) and didn’t want to see that happen, so it was time for action!</p>

<p>I set a weight goal to lose 8 kg in 6 weeks and weigh no more than 90 kg (200 lb) on my birthday (June 26th). In order to get there I wanted to follow a low-carb Paleo diet (<a href="https://www.mayoclinic.org/healthy-lifestyle/nutrition-and-healthy-eating/in-depth/paleo-diet/art-20111182">Caveman diet</a>), which I had followed 10 years prior with great <a href="https://about.me/beatlevic">results</a>. Doing some online research and catching up on Youtube with low-carb and Keto diets, is when I stumbled upon intermittent fasting videos (<a href="https://youtu.be/thZFIPOAGNQ">7</a>, <a href="https://youtu.be/thgVz3837l0">8</a>, <a href="https://youtu.be/LLVf3d0rqqY">9</a>). As you know by reading this far, the benefits of IF sounded amazing, so I decided, under the medical supervision of my wife, who is an actual MD, to go all in.</p>

<h4 id="weight-loss-results">Weight loss results</h4>

<p>In the following annotated graph you can view my weight over the course of the past 6 months. I’ll provide you with more context in the next sections.</p>







<h4 id="first-2-weeks">First 2 weeks</h4>

<p>I started May 13th weighing <strong>97.9 kg</strong> (A). To keep track of my eating window I set two alarms, one at 12.30pm labeled ‘lunch’ and the other at 8pm ‘no more eating’. For my exercise routine I started to play tennis on Monday mornings, and I tried to run 6-7 km twice a week.</p>

<p>I switched to a low-carb diet (Paleo): eating more meat, salads, fruits (primarily berries), vegetables and nuts. No longer eating bread, pasta, rice and oatmeal.</p>

<p>After one week I already lost 2 kg, and another 1 kg after the second week. I found it very easy to stick to the 8 hour eating window and I was not experiencing hunger sensations in the morning or late evenings. Probably because I was already used to skipping breakfast quite often, and because a low-carb diet also helps lowering your insulin spikes and cravings for more sugar. With lower insulin levels, as a result of lower overall blood sugar, you are also quicker in switching to fat burning!</p>

<h4 id="water-only-fasting">Water-only Fasting</h4>

<p>With this great start, I was feeling bullish about the changes and progression I had made, but I wanted to push fasting a bit harder. So I decided to try water-only fasting, i.e., eating nothing for a couple of days and only consuming water and some minerals (salt for electrolytes). In theory, your body should just switch to fat burning after 12 hours, increase your level of human growth hormone and increase your adrenaline and metabolism.</p>

<p><strong>So what about water-only fasting in practise?</strong> If you would have asked me a year ago, I would have guessed you would continuously feel very hungry and tired. Now I can tell you from experience that it is nothing like that, and that I continued to have plenty of energy throughout the 5 days that I fasted (B-C). Yes, you will feel a bit hungry around the times you would normally eat, but that feeling passes quickly. I believe being on IF together …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://beatletech.com/2020/11/24/goodbye-breakfast">https://beatletech.com/2020/11/24/goodbye-breakfast</a></em></p>]]>
            </description>
            <link>https://beatletech.com/2020/11/24/goodbye-breakfast</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197199</guid>
            <pubDate>Tue, 24 Nov 2020 10:36:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Posting JSON with an HTML Form (2016)]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25197155">thread link</a>) | @graderjs
<br/>
November 24, 2020 | https://systemoverlord.com/2016/08/24/posting-json-with-an-html-form.html | <a href="https://web.archive.org/web/*/https://systemoverlord.com/2016/08/24/posting-json-with-an-html-form.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>A coworker and I were looking at an application today that, like so many other
modern web applications, offers a RESTful API with JSON being used for
serialization of requests/responses.  She noted that the application didn’t
include any sort of CSRF token and didn’t seem to use any of the headers
(X-Requested-With, Referer, Origin, etc.) as a “poor man’s CSRF token”, but
since it was posting JSON, was it really vulnerable to CSRF?  <strong>Yes, yes,
definitely yes!</strong></p>

<p>Interestingly, this is reminiscent of many of the confusions between server and
browser that are described in Michal Zalewski’s <a href="https://amzn.to/2QyTUaH">The Tangled
Web</a>.</p>

<p>The idea that the use of a particular encoding is a security boundary is, at
worst, a completely wrong notion of security, and at best, a stopgap until W3C,
browser vendors, or a clever attacker gets hold of your API.  Let’s examine JSON
encoding as a protection against CSRF and demonstrate a mini-PoC.</p>

<h3 id="the-application">The Application</h3>

<p>We have a basic application written in Go.  Authentication checking is elided
for post size, but this is <em>not</em> just an unauthenticated endpoint.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td><pre><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
	<span>"encoding/json"</span>
	<span>"fmt"</span>
	<span>"net/http"</span>
<span>)</span>

<span>type</span> <span>Secrets</span> <span>struct</span> <span>{</span>
	<span>Secret</span> <span>int</span>
<span>}</span>

<span>var</span> <span>storage</span> <span>Secrets</span>

<span>func</span> <span>handler</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
	<span>if</span> <span>r</span><span>.</span><span>Method</span> <span>==</span> <span>"POST"</span> <span>{</span>
		<span>json</span><span>.</span><span>NewDecoder</span><span>(</span><span>r</span><span>.</span><span>Body</span><span>)</span><span>.</span><span>Decode</span><span>(</span><span>&amp;</span><span>storage</span><span>)</span>
	<span>}</span>
	<span>fmt</span><span>.</span><span>Fprintf</span><span>(</span><span>w</span><span>,</span> <span>"The secret is %d"</span><span>,</span> <span>storage</span><span>.</span><span>Secret</span><span>)</span>
<span>}</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
	<span>http</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/"</span><span>,</span> <span>handler</span><span>)</span>
	<span>http</span><span>.</span><span>ListenAndServe</span><span>(</span><span>":8080"</span><span>,</span> <span>nil</span><span>)</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>As you can see, it basically serves a secret number that can be updated via
HTTP POST of a JSON object.  If we attempt a URL-encoded or multipart POST, the
JSON decoding fails miserably and the secret remains unchanged.  We must POST
JSON in order to get the secret value changed.</p>

<h3 id="exploring-options">Exploring Options</h3>

<p>So let’s explore our options here.  The site can locally use AJAX via the
XMLHTTPRequest API, but due to the <a href="https://developer.mozilla.org/en-US/docs/Web/Security/Same-origin_policy">Same-Origin
Policy</a>,
an attacker’s site cannot use this.  For most CSRF, the way to get around this
is plain HTML forms, since form submission is not subject to the Same-Origin
Policy.  The W3C had a <a href="https://www.w3.org/TR/html-json-forms/">draft specification for JSON
forms</a>, but that has been abandoned
since late 2015, and isn’t supported in any browsers.  There are probably some
techniques that can make use of Flash or other browser plugins (aren’t there
always?) but it can even be done with basic forms, it just takes a little work.</p>

<h3 id="json-in-forms">JSON in Forms</h3>

<p>Normally, if we try to POST JSON as, say, a form value, it ends up being URL encoded,
not to mention including the field name.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre><span>&lt;form</span> <span>method=</span><span>'POST'</span><span>&gt;</span>
  <span>&lt;input</span> <span>name=</span><span>'json'</span> <span>value=</span><span>'{"foo": "bar"}'</span><span>&gt;</span>
  <span>&lt;input</span> <span>type=</span><span>'submit'</span><span>&gt;</span>
<span>&lt;/form&gt;</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Results in a POST body of:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>json=%7B%22foo%22%3A+%22bar%22%7D
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Good luck decoding that as JSON!</p>

<p>Doing it as the form field name doesn’t get any better.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>%7B%22foo%22%3A+%22bar%22%7D=value
</pre></td></tr></tbody></table></code></pre></div></div>

<p>It turns out you can set the enctype of your form to <code>text/plain</code> and avoid the
URL encoding on the form data.  At this point, you’ll get something like:</p>



<p>Unfortunately, we still have to contend with the form field name and the
separator (<code>=</code>).  This is a simple matter of splitting our payload across both
the field name and value, and sticking the equals sign in an unused field.  (Or
you can use it as part of your payload if you need one.)</p>

<h3 id="putting-it-all-together">Putting it All Together</h3>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre><span>&lt;body</span> <span>onload=</span><span>'document.forms[0].submit()'</span><span>&gt;</span>
  <span>&lt;form</span> <span>method=</span><span>'POST'</span> <span>enctype=</span><span>'text/plain'</span><span>&gt;</span>
    <span>&lt;input</span> <span>name=</span><span>'{"secret": 1337, "trash": "'</span> <span>value=</span><span>'"}'</span><span>&gt;</span>
  <span>&lt;/form&gt;</span>
<span>&lt;/body&gt;</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This results in a request body of:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>{"secret": 1337, "trash": "="}
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This parses just fine and updates our secret!</p>

  </div><p>This post contains affiliate links.  If you click on
a link, I may earn a small commission at no cost to you.</p></div>]]>
            </description>
            <link>https://systemoverlord.com/2016/08/24/posting-json-with-an-html-form.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197155</guid>
            <pubDate>Tue, 24 Nov 2020 10:26:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Curl Web Infrastructure]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197053">thread link</a>) | @virde
<br/>
November 24, 2020 | https://daniel.haxx.se/blog/2020/11/24/the-curl-web-infrastructure/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/11/24/the-curl-web-infrastructure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>The purpose of the <a href="https://curl.se/">curl web site</a> is to inform the world about what curl and libcurl are and provide as much information as possible about the project, the products and everything related to that.</p>



<p>The web site has existed in some form for as long as the project has, but it has of course developed and changed over time.</p>



<h2>Independent</h2>



<p>The curl project is completely independent and stands free from influence from any parent or umbrella organization or company. It is not even a legal entity,  just a bunch of random people  cooperating over the Internet. And a bunch of <a href="https://curl.se/sponsors.html">awesome sponsors</a> to help us.</p>



<p>This means that we have no one that provides the infrastructure or marketing for us. We need to provide, run and care for our own servers and anything else we think we should offer our users.</p>



<div><figure><a href="https://www.wolfssl.com/"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo.png" alt="" width="187" height="144" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo.png 1011w, https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo-200x155.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo-450x348.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo-768x594.png 768w" sizes="(max-width: 187px) 100vw, 187px"></a></figure></div>



<p>I still do a lot of the work in curl and the curl web site and I work full time on curl, for <a href="https://www.wolfssl.com/">wolfSSL</a>. This might of course “taint” my opinions and views on matters, but doesn’t imply ownership or control. I’m sure we’re all colored by where we work and where we are in our lives right now.</p>



<h2>Contents</h2>



<p>Most of the web site is static content: generated HTML pages. They are served super-fast and very lightweight by any web server software.</p>



<p>The web site source exists in the <a href="https://github.com/curl/curl-www/">curl-www</a> repository (hosted on GitHub) and the web site syncs itself with the latest repository changes several times per hour. The parts of the site that aren’t static are mostly consisting of smaller scripts that run either on demand at the time of a request or on an interval in a cronjob in the background. That is part of the reason why pushing an update to the web site’s repository can take a little while until it shows up on the live site.</p>



<p>There’s a deliberate effort at not duplicating information so a lot of the web pages you can find on the web site are files that are converted and “HTMLified” from the source code git repository.</p>



<h2>“Design”</h2>



<p>Some people say the curl web site is “retro”, others that it is plain ugly. My main focus with the site is to provide and offer all the info, and have it be accurate and accessible. The look and the design of the web site is a constant battle, as nobody who’s involved in editing or polishing the web site is really interested in or particularly good at design, looks or UX. I personally have done most of the editing of it, including CSS etc and I can tell you that I’m not good at it and I don’t enjoy it. I do it because I feel I have to.</p>



<p>I get occasional offers to “redesign” the web site, but the general problem is that those offers almost always involve rebuilding the entire thing using some current web framework, not just fixing the looks, layout or hierarchy. By replacing everything like that we’d get a lot of problems to get the existing information in there – and again, the information is more important than the looks.</p>



<div><figure><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-1200x459.png" alt="" width="379" height="145" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-1200x459.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-200x76.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-450x172.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-768x294.png 768w" sizes="(max-width: 379px) 100vw, 379px"></figure></div>



<p>The <a href="https://daniel.haxx.se/blog/2016/05/27/a-new-curl-logo/" data-type="post" data-id="8817">curl logo</a> is designed by a proper designer however (Adrian Burcea).</p>



<p>If you want to help out designing and improving the web site, you’d be most welcome!</p>



<h2>Who</h2>



<p>I’ve already touched on it: the web site is mostly available in git so “anyone” can submit issues and pull-requests to improve it, and we are around twenty persons who have push rights that can then make a change on the live site. In reality of course we are not that many who work on the site any ordinary month, or even year.  During the last twelve month period, 10 persons authored commits in the web repository and I did 90% of those.</p>



<h2>How</h2>



<p>Technically, we build the site with traditional makefiles and we generate the web contents mostly by preprocessing files using a C-like preprocessor called <a href="https://daniel.haxx.se/projects/fcpp/">fcpp</a>. This is an old and rather crude setup that we’ve used for over twenty years but it’s functional and it allows us to have a mostly static web site that is also fairly easy to build locally so that we can work out and check improvements before we push them to the git repository and then out to the world.</p>



<p>The web site is of course only available over HTTPS.</p>



<h2>Hosting</h2>



<div><figure><a href="https://www.haxx.se/"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010.png" alt="" width="288" height="97" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010.png 1046w, https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010-200x68.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010-450x152.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010-768x260.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010-1038x354.png 1038w" sizes="(max-width: 288px) 100vw, 288px"></a></figure></div>



<p>The <a href="https://daniel.haxx.se/blog/2020/10/23/a-server-transition/" data-type="post" data-id="14836">curl web site is hosted</a> on an origin VPS server in Sweden. The machine is maintained by primarily by me and is paid for by <a href="https://www.haxx.se/">Haxx</a>. The exact hosting is not terribly important because users don’t really interact with our server directly… (Also, as they’re not sponsors we’re just ordinary customers so I won’t mention their name here.)</p>



<h2>CDN</h2>



<p>A few years ago we experienced repeated server outages simply because our own infrastructure did not handle the load very well, and in particular not the traffic spikes that could occur when I would post a blog post that would suddenly reach a wide audience.</p>



<div><figure><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-1200x630.png" alt="" width="242" height="127" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-200x105.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-450x236.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-768x403.png 768w" sizes="(max-width: 242px) 100vw, 242px"></figure></div>



<p>Enter <a href="https://www.fastly.com/">Fastly</a>. Now, when you go to <a href="https://curl.se/">curl.se</a> (or <a href="https://daniel.haxx.se/">daniel.haxx.se</a>) you don’t actually reach the origin server we admin, you will instead  reach one of Fastly’s servers that are distributed across the world. They then fetch the web contents from our origin, cache it on their edge servers and send it to you when you browse the site. This way, your client speaks to a server that is likely (much) closer to you than the origin server is and you’ll get the content faster and experience a “snappier” web site. And our server only gets a tiny fraction of the load.</p>



<p>Technically, this is achieved by the name <strong>curl.se</strong> resolving to a number of IP addresses that are <a href="https://en.wikipedia.org/wiki/Anycast">anycasted</a>. Right now, that’s 4 IPv4 addresses and 4 IPv6 addresses.</p>



<p>The fact that the CDN servers cache content “a while” is another explanation to why updated contents take a little while to “take effect” for all visitors.</p>



<h2>DNS</h2>



<p>When we just recently switched the site over to <a href="https://daniel.haxx.se/blog/2020/11/04/the-journey-to-a-curl-domain/" data-type="post" data-id="14930">curl.se</a>, we also adjusted how we handle DNS.</p>



<div><figure><a href="https://www.kirei.se/"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/kirei.png" alt="" width="265" height="117"></a></figure></div>



<p>I run our own main DNS server where I control and admin the zone and the contents of it.  We then have four secondary servers to help us really up our reliability. Out of those four secondaries, three are sponsored by <a href="https://www.kirei.se/">Kirei</a> and are anycasted. They should be both fast and reliable for most of the world.</p>



<p>With the help of fabulous friends like Fastly and Kirei, we hope that the curl web site and services shall remain stable and available.</p>



<p>DNS enthusiasts have remarked that we don’t do DNSSEC or registry-lock on the curl.se domain. I think we have reason to consider and possibly remedy that going forward.</p>



<h2>Traffic</h2>



<p>The curl web site is just the home of our little open source project. Most users out there in the world who run and use curl or libcurl will not download it from us. Most curl users get their software installation from their Linux distribution or operating system provider. The git repository and all issues and pull-requests are done on GitHub.</p>



<p>Relevant here is that we have no logging and we run no ads or any analytics. We do this for maximum user privacy and partly because of laziness, since handling logging from the CDN system is work. Therefore, I only have aggregated statistics.</p>



<p>In this autumn of 2020, over a normal 30 day period, the web site serves almost 11 TB of data to 360 million HTTP requests. The traffic volume is up from 3.5 TB the same time last year. 11 terabytes per 30 days equals about 4 megabytes per second on average.</p>



<p>Without logs we cannot know what people are downloading – but we can guess! We know that the <a href="https://curl.haxx.se/docs/caextract.html">CA cert bundle</a> is popular and we also know that in today’s world of containers and CI systems, a lot of things out there will download the same packages repeatedly. Otherwise the web site is mostly consisting of text and very small images.</p>



<p>One interesting specific pattern on the server load that’s been going on for months: every morning at 05:30 UTC, the site gets over 50,000 requests within that single minute, during which 10 gigabytes of data is downloaded. The clients are distributed world wide as I see the same pattern on access points all over. The minute before and the minute after, the average traffic rate remains at 200MB/minute. It makes for a fun graph:</p>



<figure><img loading="lazy" width="1525" height="471" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-24-Fastly-Stats-curl.png" alt=""><figcaption>An eight hour zoomed in window of bytes transferred from the web site. UTC times.</figcaption></figure>



<p>Our servers suffer somewhat from being the target of weird clients like <a href="https://daniel.haxx.se/blog/2020/04/09/a-qqgamehall-storm/" data-type="post" data-id="13880">qqgamehall</a> that continuously “hammer” the site with requests at a high frequency many months after we started always returning error to them. An effect they have is that they make the admin dashboard to constantly show a very high error rate.</p>



<h2>Software</h2>



<p>The origin server runs Debian Linux and Apache httpd. It has a reverse proxy based on nginx. The DNS server is bind. The entire web site is built with free and open source. Primarily: fcpp, make, roffit, perl, curl, hypermail and enscript.</p>



<p>If you curl the curl site, you can see in response headers that <a href="https://www.fastly.com/blog/benefits-using-varnish">Fastly uses Varnish</a>.</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/11/24/the-curl-web-infrastructure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197053</guid>
            <pubDate>Tue, 24 Nov 2020 10:09:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Enterprise UX Design: Make me think]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25197041">thread link</a>) | @Dmytro_Trotsko
<br/>
November 24, 2020 | https://adamfard.com/blog/enterprise-ux | <a href="https://web.archive.org/web/*/https://adamfard.com/blog/enterprise-ux">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="article-content"><p>“Don’t make me think” is a renowned mantra in the world of design, coined by Steve Krug. It has served as a guiding principle in the world of design and UX for twenty&nbsp;years. It teaches us how to create great experiences in a straightforward and accessible manner.&nbsp;</p><p>In today’s article, we’d like to look into enterprise design and its peculiarities. It’s essential to underline that the very nature of enterprise UX slightly differs from consumer UX. As a result, some of Krug’s principles must be adjusted when designing enterprise software.&nbsp;</p><p>This article is by no means a refutation of the design principle. Please treat it as a mere asterisk with a fine print at the bottom.</p><h2><strong>Learning curves aren’t inherently bad</strong></h2><p>According to Krug, products that make people think also make people unhappy. <a href="https://uxdesign.cc/the-learning-curve-design-problem-4d4dc2965098">Products with steep learning curves</a> very rarely succeed in the modern business ecosystem. Customers will pretty much always choose the path of least resistance. This isn’t necessarily true of enterprise products.</p><p>Enterprise users are power users — and it’s imperative that we take this into account when designing products for them. They interact with niche software on a daily basis and quite possibly for many years. They know their way around the logic of the products they use.&nbsp;</p><p>Creating an interface that demands some learning results in a steeper learning curve isn’t inherently wrong. It allows users to work more efficiently once they’ve invested a certain amount of time into training and learning.&nbsp;</p><figure><img src="https://www.datocms-assets.com/16499/1606137908-figma-shortcuts-cheatsheet-1014x487.jpg?w=900&amp;auto=compress"><figcaption><a href="https://www.figmacrush.com/figma-shortcuts-cheatsheet/">Source</a></figcaption></figure><p>Take, for instance, products like Figma, Sketch, Adobe Pro, or any other professional software — most of them have a wide array of shortcuts. Features such as shortcuts may take a while to master, but they’ll ensure a significant boost in productivity once learned.&nbsp;</p><h2>Simplify cautiously&nbsp;</h2><p>We’re very well aware of the importance of keeping interfaces simple and obvious. However, it’s essential to keep in mind the complexity of the tasks typically performed in enterprise software. The pursuit for a clean UI could rid users of the vital context necessary to get work done.&nbsp;</p><p>Plus, it can be argued that by making the interface too simple, we risk generating friction rather than eliminating it. Let’s envision an interface of a product that displays a wide array of charts and data, like a trading platform.&nbsp;</p><p><img src="https://www.datocms-assets.com/16499/1606138044-image2.png?w=900&amp;auto=compress"></p><p>A professional that regularly interacts with visual data needs immediate access to it at all times. Having to perform extra actions to access vital features is both frustrating and unproductive. And here lies one of the most significant differences between consumer UX and enterprise UX (eUX).&nbsp;</p><p>Consumer UX is really passionate about sleek UIs, while enterprise software must ensure that users are able to do their work comfortably. Therefore, simplified, minimalistic interfaces aren’t really what eUX designers are after.&nbsp;</p><h2>Wizards are cool, but…</h2><p><a href="https://adamfard.com/blog/ux-onboarding">Onboarding your users</a> is a vital step aimed at ensuring optimal user experience. However, while Wizards and guided tours are an excellent solution for casual users, it’s not necessarily the case for power users.&nbsp;</p><p>In both consumer and enterprise UX, designers must aim to develop products that require <a href="https://adamfard.com/blog/stickiness">as little hand-holding as possible</a>. However, simplistic product tours can be… well, simplistic. They often fail to uncover the entire functionality of a product, which is especially relevant for experienced users.&nbsp;</p><p>After running a series of tests, we found out that enterprise users tend to prefer to leave the app or platform for instructions. While this does seem somewhat disruptive to the experience of a product — it is understandable.&nbsp;</p><p><img src="https://www.datocms-assets.com/16499/1606210515-initiative-alladded1-1.png?w=900&amp;auto=compress"></p><p>Off-page instructions can provide more in-depth explanations rather than the ones that are placed on the screen. Compare, for instance, a tool-tip and an article dedicated to a particular function.&nbsp;</p><h2>Plan for non-linear flows&nbsp;</h2><p>When it comes to designing eUX UIs, designers face a truly arduous task of creating complex, non-linear flows. These flows often involve a variety of roles, profile types, responsibilities, kinds of security, and much more. Our goal is to create a consistent and recognizable experience throughout all of these variables.&nbsp;</p><p>The complicated part, however, is not to force users into flows and scenarios. Experts and professional users need that freedom to make decisions and use the platform as they see fit.</p><p>Think of a person that is deeply versed in Microsoft Excel. They’ve been using this software for nearly a decade, and they know it like the back of their hand. More importantly, they have their style of working and solving problems. Limiting such users via linear and rigid flows could defeat the purpose of boosting their productivity.&nbsp;</p><h2>Don’t fix it if it’s not broken</h2><p>Innovation is a crucial element of UX design. We strive to continuously seek new and creative solutions to old problems. Often, we can even choose to be bold and put forth experimental solutions.&nbsp;</p><p>However, when it comes to eUX, we have to be somewhat more conservative and experiment with caution. Enterprise software isn’t quite receptive to design solutions that go against the grain.&nbsp;</p><p>Since the central purpose of such software is to deliver quality work in short amounts of time, “reinventing the wheel” isn’t always a great idea.&nbsp;</p><p>When designing for enterprise, keeping an eye on your competition is even more relevant than in consumer software.&nbsp;</p><p>Let’s go back to Excel once more — imagine <a href="https://adamfard.com/blog/website-redesign">you’re trying to reinvent</a> a complex, spreadsheet-based product. You’re looking to change the ways it represents data, or certain actions are performed. While this does sound like a laudable task, the critical question is — why?&nbsp;</p><p>In eUX, the real value of a product is in its unique selling point that is translated via a design that looks familiar and intuitive.&nbsp;</p><p>That is not to say that the light of innovation never shines on enterprise products, but user expectations often trim the lengths we can go.&nbsp;</p><h2>In conclusion</h2><p>In order to reward you, our beloved reader, for making it till the end, we’ve designed a picture that summarizes the arguments in this article. We hope it will come in handy.</p><p><img src="https://www.datocms-assets.com/16499/1606138895-enterprise-ux-summary.png?w=900&amp;auto=compress"></p><p>While the principles of “don’t make me think” will most likely outlive us, it’s crucial to outline the situations where they can be somewhat amended.&nbsp;</p><p>Enterprise user experience is a slightly more conservative field in terms of design, yet these limitations push us to become even more creative. By operating within these constraints, we have the power to make the future of work exciting and even more promising.&nbsp;</p><p>Meta: In this article, we explore the peculiarities of enterprise user experience design (eUX) through the lens of the “Don’t make me think” principle.&nbsp;</p></article></div>]]>
            </description>
            <link>https://adamfard.com/blog/enterprise-ux</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197041</guid>
            <pubDate>Tue, 24 Nov 2020 10:07:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Any hope of keeping Earth habitable requires sucking CO2 out of the atmosphere]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197019">thread link</a>) | @jeremylevy
<br/>
November 24, 2020 | https://www.businessinsider.fr/us/climate-change-too-late-carbon-capture-needed-2020-11 | <a href="https://web.archive.org/web/*/https://www.businessinsider.fr/us/climate-change-too-late-carbon-capture-needed-2020-11">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
                                <h2>Even if greenhouse-gas emissions stop now, global warming will continue for centuries, a study shows. The solution: removing carbon from the air.</h2>
                            </p><div>
                                <ul><li>Even if the world were to stop emitting greenhouse gases right now, the Earth would keep warming for centuries, a new study shows.</li>
<li>The researchers suggest <a href="https://www.businessinsider.com.au/how-to-stop-gobal-warming-plan-carbon-capture-2018-10">sucking carbon dioxide out of the atmosphere</a> and storing it underground — a solution known as carbon capture and storage.</li>
<li>That's considered a type of <a href="https://www.businessinsider.com/geoengineering-how-to-reverse-climate-change-2019-4">geoengineering</a>. Other <a href="https://www.businessinsider.com/geoengineering-how-to-reverse-climate-change-2019-4">climate-hacking</a> proposals in the same category are far riskier.</li>
<li><a href="https://www.businessinsider.com/?hprecirc-bullet">Visit Business Insider's homepage for more stories</a>.</li></ul><p>Even if we stopped emitting greenhouse gas today, the Earth would continue warming for centuries. Arctic ice and permafrost are already on an irreversible path of melting.</p><p><a href="https://www.nature.com/articles/s41598-020-75481-z">That's the finding of new research</a> published Thursday in the journal Scientific Reports. The model suggests that even if emissions were to drop to zero this year, global temperatures would ultimately rise to be 5.4 degrees Fahrenheit higher in 2500 than they were in 1850 (that's 3 degrees Celsius).</p><p>"The tundra will continue to melt over the next 500 years — irrespective of how quickly humanity cuts its greenhouse-gas emissions," Jørgen Randers, the lead author of the new study, told Business Insider.</p><p>That's because climate change is a vicious, self-sustaining cycle: As permafrost thaws, it releases more greenhouse gases, like methane and carbon dioxide, which sustains warming over time. To stop that cycle, Randers said, we'll need to suck carbon dioxide back out of the atmosphere.</p><h2>8 feet of sea-level rise</h2><p>Randers' study modeled the effect of various emissions-reductions scenarios on Earth's climate between 1850 and 2500.</p><p>The data showed that if emissions stopped for good in 2020, sea levels in 2500 would still be more than 8 feet (2.5 meters) higher than in 1850.</p><figure><img src="https://i.insider.com/5fac2eb9b09abb0018626059?format=jpeg" alt="FILE - In this Aug. 16, 2019, photo, large Icebergs float away as the sun rises near Kulusuk, Greenland. The Trump administration is poised to announce an expanded diplomatic presence in Greenland and a new assistance package for the vast island aimed at thwarting growing Chinese and Russian influence in the Arctic. The announcement, expected Thursday, April 23, 2020, will come less than a year after President Donald Trump drew derision for expressing an interest in buying Greenland. (AP Photo/Felipe Dana, File)" height="2665" width="3557" charset=""><figcaption>Large icebergs float away as the sun rises near Kulusuk, Greenland, August 16, 2019.
<span>Felipe Dana/AP</span>
</figcaption></figure><p>To prevent the projected 3-degree-Celsius temperature increase, greenhouse-gas emissions would need to have ceased entirely between 1960 and 1970, the model found. In that sense, Earth blew by a climactic point of no return 50 years ago — before much of the public understood the realities of climate change.</p><p>"Yes, that is an irony," Randers said. "But of course the scientific community knew about global warming already in the 1960s."</p><h2>We need to suck carbon out of the atmosphere</h2><p>The Paris climate agreement was created with the intention to cut greenhouse-gas emissions enough to keep the world's temperature from rising more than 2 degrees Celsius by 2100. But even if all emissions stopped by 2100, according to Randers' model, sea levels in 2500 would be nearly 10 feet (3 meters) higher than they were in 1850.</p><p>Earth's temperatures are already on track to blow past the Paris agreement's goals. Last year was the <a href="https://www.ncei.noaa.gov/news/projected-ranks#:~:text=The%20warmest%20years%20globally%20have,Courtesy%20of%20NOAA%20NCEI.">second warmest on record</a> for surface temperatures and <a href="https://time.com/5765489/ocean-temperatures-warmest-ever/">the hottest ever for oceans</a>. Polar melting is <a href="https://www.businessinsider.com/sea-level-rise-3-feet-in-80-years-un-report-2019-9" data-analytics-module="body_link" data-analytics-post-depth="40">on track to raise seas 3 feet by 2100</a> and threatens to displace hundreds of millions of people.</p><p>What's needed, Randers said, is for companies and governments to "start developing the technologies for large-scale removal of greenhouse gases from the atmosphere."</p><p>In technical terms, that strategy is known as carbon capture and storage (CCS). To prevent further warming after emissions have stopped, the new study found, at least 33 gigatonnes (36.5 billion tons) of carbon dioxide would need to be sucked out of the atmosphere each year. That's roughly the total amount of carbon dioxide the global fossil-fuel industry emitted in 2018 (<a href="https://www.wri.org/blog/2018/12/new-global-co2-emissions-numbers-are-they-re-not-good#:~:text=Record%20Carbon%20Dioxide%20Emissions%20in%202018&amp;text=This%20year's%20numbers%20confirm%20their,2017%20to%2036.2%20gigatonnes%20CO20CO2">36 gigatonnes</a>).</p><p>Power plants in the US, Canada, and Switzerland have already started utilizing CCS to lower their emissions. In 2014, the Boundary Dam Power Station in Saskatchewan became one of the first in the world to successfully use the technology.</p><p>In total, 21 commercial-scale carbon-capture projects are operating around the world, and 22 more are in development, <a href="https://www.c2es.org/content/carbon-capture/">according to the Center for Climate and Energy Solutions</a>. These projects typically store carbon deep underground in depleted oil and gas fields or in bioreactor containers filled with algae that eats carbon dioxide.</p><figure><img src="https://i.insider.com/5fac4783b09abb001862611c?format=jpeg" alt="bioreactor" height="3744" width="4992" charset=""><figcaption>Bioreactors filled with green algae that eats carbon dioxide in Costa de la Luz, Spain.
<span>Santiago Urquijo/Getty Images</span>
</figcaption></figure><p>Two US carbon-capture completed in 2017 — <a href="https://www.c2es.org/content/carbon-capture/">one in Illinois, one in Texas</a> — can capture 1.1 million and 1.6 million tons of carbon dioxide, respectively, per year. But the amount of CO2 that needs to be removed from the atmosphere requires far more plants than any current plans call for.</p><p>"In other words, building 33,000 big CCS plants and keep them running for ever," the study authors wrote.</p><h2>The pros and cons of geoengineering</h2><p>Carbon capture is becoming widely accepted as a safe and potentially effective form of geoengineering. This and other climate interventions are increasingly being floated <a href="https://www.nature.com/articles/d41586-018-03036-4">by scientists</a> and politicians alike; Andrew Yang, a 2020 Democratic presidential candidate, suggested <a href="https://www.businessinsider.com/andrew-yang-thinks-geoengineering-could-lead-to-war-2019-4">budgeting $800 million</a> for further geoengineering research in the US.</p><p>But most climate-hacking proposals would be far riskier than CCS. Take solar geoengineering, for example, which involves injecting aerosols into the sky to reflect sunlight back into space. Critics of this idea point out that <a href="https://www.nature.com/articles/s41467-017-01606-0">most models predict</a> the effects of solar geoengineering wouldn't stay localized. If a country decided to independently deploy such measures, varying and unpredictable effects would likely be seen in other spots around the globe.</p><p>Aerosol injections deployed in the southern hemisphere, for instance, could impact ocean temperatures and wind speeds, leading to more hurricanes in the northern hemisphere.&nbsp;</p><figure><img src="https://i.insider.com/5c76a74726289812e8235523?format=jpeg" alt="Clouds above earth" height="2848" width="3797" charset=""><figcaption>Subtropical stratocumulus clouds above Earth.
<span>Aleksandar Georgiev/Getty Images</span>
</figcaption></figure><p>"Solar geoengineering has geopolitical ramifications, unlike carbon capture," Juan Moreno-Cruz, an associate professor at the University of Waterloo who studies geoengineering, previously told Business Insider.</p><p>Randers said his study advocates just for carbon capture, not other more experimental forms of geoengineering.&nbsp;</p><p>"I am generally against geoengineering because of its unintended side effects. But if the world continues to delay meaningful and feasible action to phase out fossil fuels, we may have to resort to geoengineering," Randers said.&nbsp;</p><p>As an immediate priority, he added, countries should invest equally in efforts to cut emissions and build more CCS plants.</p><p>"This would be a wonderful task for a government-financed <a href="https://www.businessinsider.com/alexandria-ocasio-cortez-green-new-deal-2019-1">Green New Deal</a>," he said.</p>
                            </div></div>]]>
            </description>
            <link>https://www.businessinsider.fr/us/climate-change-too-late-carbon-capture-needed-2020-11</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197019</guid>
            <pubDate>Tue, 24 Nov 2020 10:03:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparing iPhone OS 1.0 with iOS 14 using tree maps]]>
            </title>
            <description>
<![CDATA[
Score 197 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25196720">thread link</a>) | @yankcrime
<br/>
November 24, 2020 | https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/ | <a href="https://web.archive.org/web/*/https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>If you followed the recent Apple events, you probably saw a picture of the A14 and M1 dies… that got me thinking about what you would see if you could pass iOS under X-Rays…</p>
<p>In my previous article about the <a href="https://blog.timac.org/2020/1019-evolution-of-the-programming-languages-from-iphone-os-to-ios-14/">evolution of the programming languages from iPhone OS 1.0 to iOS 14</a>, I analyzed iOS based on the number of binaries and their programming languages. As I pointed out in this past post, the size of the binaries were not taken in account. In this new article, I look at iPhone OS 1.0 and iOS 14 from a size perspective using tree maps.</p>

<p>To produce the images in this article, I extracted the root filesystem (including the dyld shared cache) of each major iOS release:</p>
<table>
<thead>
<tr>
<th>Version</th>
<th>Device</th>
</tr>
</thead>
<tbody>
<tr>
<td>iOS&nbsp;14.0 (18A373)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;13.1 (17A844)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;12.0 (16A366)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;11.1 (15B93)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;10.1 (14B72)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;9.0 (13A344)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;8.0 (12A365)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;7.0.1 (11A470a)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;6.0 (10A403)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iOS&nbsp;5.0 (9A334)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iOS&nbsp;4.0 (8A293)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iPhone&nbsp;OS&nbsp;3.0 (7A341)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iPhone&nbsp;OS&nbsp;2.0 (5A347)</td>
<td>iPhone 2G</td>
</tr>
<tr>
<td>iPhone&nbsp;OS&nbsp;1.0 (1A543a)</td>
<td>iPhone 2G</td>
</tr>
</tbody>
</table>
<p>I then created a tree map. You might be familiar with tree maps as they are often used to visualize a file hierarchy to give you a graphical overview of the structure. One key characteristic is that each file is shown as a rectangle with an area proportional to the file's size. The tree maps displayed in this article have been created using the awesome <a href="http://grandperspectiv.sourceforge.net/">GrandPerspective</a> and annotated with <a href="https://www.pixelmator.com/">Pixelmator</a>.</p>

<p>Let's look at what you would see if you could scan iPhone OS 1.0 using X-Rays:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS1.png" alt=""></p>
<p>The diagram below highlights some of the major functional blocks:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS1_structures.png" alt=""></p>
<p>We can already notice that:</p>
<ul>
<li>The structure is quite simple and has similarities to macOS</li>
<li>Frameworks are taking more than a third of the size</li>
<li>Fonts are taking more than 25% of the whole operating system</li>
</ul>
<p>We can go one level deeper and identify all the components:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS1_details.png" alt=""></p>
<p>From the list of components, we can clearly determine all the main features of iPhone OS 1.0:</p>
<ul>
<li>Phone</li>
<li>SMS</li>
<li>Weather</li>
<li>Clock</li>
<li>Mail</li>
<li>Safari + Web</li>
<li>Calendar</li>
<li>Maps</li>
<li>Wallpaper</li>
<li>Ringtones</li>
<li>Office support</li>
<li>Audio player</li>
<li>Video player</li>
<li>…</li>
</ul>
<p>A couple of components worth mentioning:</p>
<ul>
<li>The UIKit framework is taking more than 13 % of the total size</li>
<li>The wallpapers and ringtones count for 6 %</li>
<li>ICU (International Components for Unicode) takes more than 5 %</li>
<li>SpringBoard is roughly 2 %</li>
</ul>

<p>On popular demand, I added this section to provide more info about the fonts.
The huge <code>Fonts</code> block is composed of 2 parts:</p>
<ul>
<li>the fonts representing 2/3 of the size</li>
<li>some caches (visible at the top of the area and representing a third of the size)</li>
</ul>
<p>For the font lovers, here is the complete list of fonts in iPhone OS 1.0:</p>
<pre><code>AmericanTypewriter.ttf
AmericanTypewriterBold.ttf
AmericanTypewriterCondensed.ttf
AmericanTypewriterCondensedBold.ttf
AmericanTypewriterCondensedLight.ttf
AmericanTypewriterLight.ttf
Arial.ttf
ArialBold.ttf
ArialBoldItalic.ttf
ArialItalic.ttf
ArialRoundedMTBold.ttf
arialuni.ttf
CourierBoldOblique.ttf
CourierNew.ttf
CourierNewBold.ttf
CourierNewBoldItalic.ttf
CourierNewItalic.ttf
CourierOblique.ttf
DB_LCD_Temp-Black.ttf
Georgia.ttf
GeorgiaBold.ttf
GeorgiaBoldItalic.ttf
GeorgiaItalic.ttf
Helvetica.ttf
HelveticaBold.ttf
HelveticaBoldOblique.ttf
HelveticaOblique.ttf
LockClock.ttf
MarkerFeltThin.ttf
MarkerFeltWide.ttf
PhonepadTwo.ttf
TimesNewRoman.ttf
TimesNewRomanBold.ttf
TimesNewRomanBoldItalic.ttf
TimesNewRomanItalic.ttf
TrebuchetMS.ttf
TrebuchetMSBold.ttf
TrebuchetMSBoldItalic.ttf
TrebuchetMSItalic.ttf
Verdana.ttf
VerdanaBold.ttf
VerdanaBoldItalic.ttf
VerdanaItalic.ttf
Zapfino.ttf
</code></pre>
<p>The cache contains info for all these fonts and includes the 2 extra files:</p>
<ul>
<li>HelveLTMM.ps</li>
<li>TimesLTMM.ps</li>
</ul>

<p>I won't give details about each iOS release but you can inspect the tree maps from iPhone OS 2.0 to iOS 13.1:</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>iPhone OS 2.0</td>
<td>iPhone OS 3.0</td>
<td>iOS 4.0</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS2.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS2_small.png" alt="" title="iPhone OS 2.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS3.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS3_small.png" alt="" title="iPhone OS 3.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS4.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS4_small.png" alt="" title="iOS 4.0"></a></td>
</tr>
<tr>
<td>iOS 5.0</td>
<td>iOS 6.0</td>
<td>iOS 7.0.1</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS5.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS5_small.png" alt="" title="iOS 5.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS6.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS6_small.png" alt="" title="iOS 6.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS7.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS7_small.png" alt="" title="iOS 7.0.1"></a></td>
</tr>
<tr>
<td>iOS 8.0</td>
<td>iOS 9.0</td>
<td>iOS 10.1</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS8.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS8_small.png" alt="" title="iOS 8.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS9.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS9_small.png" alt="" title="iOS 9.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS10.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS10_small.png" alt="" title="iOS 10.1"></a></td>
</tr>
<tr>
<td>iOS 11.1</td>
<td>iOS 12.0</td>
<td>iOS 13.1</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS11.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS11_small.png" alt="" title="iOS 11.1"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS12.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS12_small.png" alt="" title="iOS 12.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS13.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS13_small.png" alt="" title="iOS 13.1"></a></td>
</tr>
</tbody>
</table>
<p>Note that the number of building blocks increased with each new iOS release and the components are becoming smaller.</p>

<p>We are now in 2020 and iOS 14 is available. Without a surprise, iOS 14 is way more complex than iPhone OS 1.0:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS14.png" alt=""></p>
<p>Here is the diagram highlighting the functional blocks in iOS 14:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS14_structures.png" alt=""></p>
<p>We can note that the main structure is still fairly similar to the original iPhone OS 1.0 version: the fonts, frameworks, applications, library, /usr, … are still there.</p>
<p>There are however a couple of big differences:</p>
<ul>
<li>iOS 14 contains a lot of <code>Preinstalled Assets</code> and <code>Linguistic Data</code>. As far as I can tell, these components are used for on-device machine learning: language detector, voices, tokenizers, vocalizers, …</li>
<li>The dyld shared cache, a caching mechanism introduced in iPhone OS 3.1, causes the Frameworks and Private Frameworks to be split in several areas. The dyld shared cache has been marked with the red box in the diagram.</li>
<li>Health is clearly an important feature of iOS 14.</li>
</ul>
<p>There are so many components in iOS 14 that it is way more complex to identify all of them. I gave it a try nonetheless:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS14_details.png" alt=""></p>
<p>Although it is now difficult to list all the features, there are some clear trends:</p>
<ul>
<li>iOS 14 is packed with on-device machine learning technologies: Face Detection, Deep Convolutional Networks, Vision frameworks, Text Recognition, Neural Network, …</li>
<li>A lot of components are related to the camera and photos: Effects, Memories, video processing, photo library, …</li>
<li>Siri and voices are clearly visible.</li>
<li>As we already mentioned, Health is an important feature.</li>
<li>We can identify a couple of features added over the years: HomeKit, Watch, CarPlay, Spotlight, Emoji 🤟, News, iWork, Wallet, Shortcuts, ARKit, …</li>
</ul>
<p>More statistics:</p>
<ul>
<li>Fonts are now counting for less than 6 % of the size</li>
<li>Linguistic Data represent almost 8 % of the size</li>
<li>Although the ICU size was multiplied by more than 3 since iPhone OS 1.0, it now represents approximatively 0.5% of the total</li>
</ul>

<p>For readability the previous tree maps in this article were all displayed using the same size. If we present iPhone OS 1.0 next to iOS 14 with a proportional area, you would see that the whole iPhone OS 1.0 is basically taking the size of the iOS 14 wallpapers:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/Compare-iOS1-iOS14.png" alt=""></p>

<p>When iPhone OS 1.0 was released in 2007, it redefined the smartphone with a limited set of core features. Nowadays iOS 14 contains an incredible amount of components. By looking at them based on their size, we can determine the most important features. We thus distinctly see Apple's AI push into on-device machine learning with technologies like object detection in images and video, language analysis, sound classification and text recognition.</p>

<p><strong>Update 24.11.2020:</strong></p>
<ul>
<li>Added fonts in the iPhone OS 1.0 tree map</li>
<li>Added fonts in the iOS 14 tree map</li>
<li>Add section with fonts info for iPhone OS 1.0</li>
</ul>
</div></div>]]>
            </description>
            <link>https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196720</guid>
            <pubDate>Tue, 24 Nov 2020 09:18:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is carbon capture a viable solution?]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 326 (<a href="https://news.ycombinator.com/item?id=25196633">thread link</a>) | @scottbucks
<br/>
November 24, 2020 | https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis | <a href="https://web.archive.org/web/*/https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.5.0"><div dir="ltr"><div><h3 id="viewer-foo"><span><strong><span>Is this technology a viable solution to beating the climate crisis or <!-- -->can it cause more harm than good?</span></strong></span></h3><p id="viewer-efp47"><span>With the climate crisis continuously getting worse, businesses and governments need to find solutions to reduce the amount of carbon going into the atmosphere. To beat the crisis, the world can't simply rely on renewable energy, governments will need to include carbon capture, usage and storage (CCUS) into the mix if they want to <span>hit their climate targets.</span></span></p><p id="viewer-4uch7"><span>According to the International Energy Agency (IEA), CCUS could <a href="https://www.iea.org/reports/transforming-industry-through-ccus" target="_blank" rel="noopener"><u>reduce carbon emissions by almost a fifth</u></a>, but can this technology deliver on its promises or is it too good to be true?</span></p><h3 id="viewer-5vpth"><span>What is <!-- -->Carbon capture, usage and storage?</span></h3><p id="viewer-pi2c"><span>Carbon capture, usage and storage (CCUS) refers to <!-- -->a chain of different technologies aimed at capturing waste <!-- -->carbon dioxide<!-- --> (<!-- -->CO2<!-- -->), usually from large <!-- -->point sources of pollution like power plants, <!-- -->transporting it to a storage site, and depositing it where it will not enter the atmosphere. Some could be used to help grow greenhouse plants, make plastics, or even carbonate fizzy drinks. The first step is to fit factory chimneys with solvent filters, which trap carbon emissions before they escape, then the gas can be piped to locations to be used or stored. For the moment, t<span>here are about 30 CCUS projects operating around the world, which is nowhere near enough to clean up all of our emissions. </span></span></p><h3 id="viewer-fds85"><span><span>Why is CCUS needed?</span></span></h3><p id="viewer-7vj3h"><span><span>Nowadays, </span>Industrial production <span>accounts for one-quarter of CO</span>2﻿<span> emissions from energy and industrial processes. With the demand for cement, steel and chemicals remaining strong to support a growing and increasingly urbanised global population, the future production of these materials will have to be more efficient and emit much less CO</span>2<span> if governments want to meet their climate goals.</span></span></p><p id="viewer-8ofv8"><span><span>In the </span><a href="https://www.iea.org/reports/material-efficiency-in-clean-energy-transitions" target="_blank" rel="noopener"><u>IEA's "Clean Technology Scenario"</u></a>, <span>more than 28 GtCO</span>2<span>﻿ could be captured from industrial facilities between now and 2060.</span></span></p><p id="viewer-5eiqn"><span><span>Carbon capture, usage and storage also offers several other potential benefits:</span></span></p><ul><li id="viewer-63jb1"><p><span>The ability to generate additional power thanks to </span><span>geologically stored CO</span>2 which<span> could be used to extract geothermal heat from the same locations in which it’s injected, producing renewable geothermal energy.</span></p></li><li id="viewer-bcq59"><p><span>CO2 can technically be turned into fuel, although it is rather difficult to achieve.</span></p></li><li id="viewer-dru7v"><p><span>Captured CO</span>2<span> could also be used to strengthen concrete, leading to increased infrastructure durability.</span></p></li></ul><div id="viewer-den6h"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis" data-pin-media="https://static.wixstatic.com/media/f361a8_220f0481ef95495b80fcd23b618197f0~mv2.jpg/v1/fit/w_1000%2Ch_853%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/f361a8_220f0481ef95495b80fcd23b618197f0~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><h3 id="viewer-e8ds9"><span><span><strong>Suggested Articles:</strong></span></span></h3><ul><li id="viewer-apsbb"><p><strong>🚄 </strong><a href="https://www.thedetechtor.com/post/hyperloop-the-future-of-travel" target="_blank" rel="noopener"><strong><u>Hyperloop, the future of travel?</u></strong></a></p></li><li id="viewer-8crgb"><p><strong>⌚️ </strong><a href="https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget" target="_blank" rel="noopener"><strong><u>Fitness Trackers: Helping us Get Fit or Just Another Gadget?</u></strong></a></p></li><li id="viewer-4jk2p"><p><strong>📱 </strong><a href="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" target="_blank" rel="noopener"><strong><u>Smartphones: The True Cost of Upgrades</u></strong></a><strong> ♻️ </strong></p></li></ul><h3 id="viewer-9j318"><span>What's the catch?</span></h3><p id="viewer-89c60"><span>CCUS has always been controversial, m<!-- -->ost people are either heavily in favour of CCUS technology or heavily against. There are several reasons why this technology might not be the best solution.</span></p><p id="viewer-3g635"><span>Environmentalists<!-- --> tend to see CCUS as a distraction from the need to convert to <!-- -->renewable energy as quickly as possible<!-- -->. Some argue that investing in carbon capture wasting money that could be put to better use, like perfecting <!-- -->solar energy<!-- -->, <!-- -->building insulation<!-- -->, <!-- -->wind turbines or even <!-- -->tidal power. </span></p><p id="viewer-bts9g"><span>Another drawback of carbon capture, usage and storage, is the considerable amount of extra power it requires, which would increase the cost of electricity. Talking of cost, CCUS technology is said to be very expensive, however, new methods for capturing and extracting CO2 are constantly being developed, always with the aim to become cheaper.</span></p><h3 id="viewer-3q94h"><span>Where is CCUS in place?</span></h3><p id="viewer-2ukm3"><span>There are currently almost 30 carbon capture, usage and storage projects in place around the world namely in the <span>US, Canada, Norway, China and the UK.</span></span></p><p id="viewer-4rv4i"><span><span>Here are some of the biggest projects:</span></span></p><ul><li id="viewer-65sfn"><p><span>The Century natural gas processing facility in West Texas, US. The capturing plant began operations in November 2010 and is now the world’s single biggest CCS plant.</span></p></li><li id="viewer-3iluh"><p>The Boundary Dam Carbon Capture and Storage (CCS) project located in Saskatchewan, Canada. Owned by SaskPower, the <span>Boundary Dam coal-fired plant located in Estevan, Saskatchewan began operations in 2014.</span></p></li><li id="viewer-3uhge"><p><span>The Shute Creek gas processing plant, located in Wyoming, US. The CCS facility, built near LaBarge, Lincoln County, is owned by ExxonMobil and captures approximately 365 million cubic feet per day of CO</span>2<span>, which is equivalent to removing more than 1.5 million cars off the road.</span></p></li></ul><div id="viewer-eol67"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label="Photo of fumes, CO2 from an industrial plant."><p><img data-pin-url="https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis" data-pin-media="https://static.wixstatic.com/media/f361a8_e6bddda6d2d54b038510cf9aec5bc37a~mv2.jpg/v1/fit/w_1000%2Ch_851%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/f361a8_e6bddda6d2d54b038510cf9aec5bc37a~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg" alt="Photo of fumes, CO2 from an industrial plant."></p></div></div></div></div><h3 id="viewer-4dtjt"><span><span>The bottom line</span></span></h3><p id="viewer-1abo"><span><span>Despite the controversy, it seems that </span>carbon capture, usage and storage technology will become an important part of tackling the climate crisis. I think that if future projects aren't too expensive, it could definitely be a solution to this ever-growing problem, so long as it isn't to the expense of investing in renewable energy and other methods of reducing our CO2 emissions.</span></p><h3 id="viewer-6af0g"><span><span><strong>More from The Detechtor:</strong></span></span></h3><ul><li id="viewer-8a6vc"><p><strong>🚄 </strong><a href="https://www.thedetechtor.com/post/hyperloop-the-future-of-travel" target="_blank" rel="noopener"><strong><u>Hyperloop, the future of travel?</u></strong></a></p></li><li id="viewer-63fca"><p><strong>⌚️ </strong><a href="https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget" target="_blank" rel="noopener"><strong><u>Fitness Trackers: Helping us Get Fit or Just Another Gadget?</u></strong></a></p></li><li id="viewer-anbaq"><p><strong>📱 </strong><a href="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" target="_blank" rel="noopener"><strong><u>Smartphones: The True Cost of Upgrades</u></strong></a><strong> ♻️</strong></p></li></ul><h3 id="viewer-4ja8h"><span><span>Stay updated:</span></span></h3><ul><li id="viewer-6j517"><p>📩 Want the latest on the impact of tech? <strong>Subscribe</strong> to our <strong>newsletter</strong>!</p></li><li id="viewer-91ucr"><p>🎙 <strong>NEW</strong>! <a href="http://thedetechtor.com/" target="_blank" rel="noopener"><u>The Detechtor Podcast</u></a> is now available on all podcast players!                                                      <strong>Subscribe</strong> on <a href="https://podcasts.apple.com/fr/podcast/the-detechtor-podcast/id1537457578?l=en" target="_blank" rel="noopener"><u>Apple Podcasts</u></a> | <a href="https://open.spotify.com/show/5kc8WA6nZC69bQ1sbOrlNi?si=CwAuAtpfRpe7WmLu1PlO8w" target="_blank" rel="noopener"><u>Spotify</u></a> | <a href="https://podcasts.google.com/search/The%20detechtor%20Podcast" target="_blank" rel="noopener"><u>Google Podcasts</u></a> | <a href="https://www.stitcher.com/show/the-detechtor-podcast" target="_blank" rel="noopener"><u>Stitcher</u></a> | <a href="https://tunein.com/podcasts/Technology-Podcasts/The-Detechtor-Podcast-p1377296/?topicid=158813573" target="_blank" rel="noopener"><u>Tunein</u></a></p></li><li id="viewer-3sf88"><p>📲 Let's connect! <strong>Follow</strong> <strong>us</strong> on <a href="https://twitter.com/the_detechtor" target="_blank" rel="noopener"><u>Twitter</u></a> | <a href="https://www.instagram.com/thedetechtor/" target="_blank" rel="noopener"><u>Instagram</u></a> | <a href="https://www.facebook.com/thedetechtor" target="_blank" rel="noopener"><u>Facebook</u></a> | <a href="https://www.youtube.com/channel/UCAW--4_mML4A86W3670ix3w" target="_blank" rel="noopener"><u>Youtube</u></a></p></li></ul></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196633</guid>
            <pubDate>Tue, 24 Nov 2020 09:04:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I went from $2k in a year to $2k in a week]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25196434">thread link</a>) | @jakeprins
<br/>
November 24, 2020 | https://jakeprins.com/blog/how-i-went-from-2k-in-a-year-to-2k-in-a-week | <a href="https://web.archive.org/web/*/https://jakeprins.com/blog/how-i-went-from-2k-in-a-year-to-2k-in-a-week">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p>After many hours of work, it was finally time to give people access to my new project, a SaaS boilerplate. In the first 5 days of early access, I almost made $2k in sales ($1,901.40 to be exact).</p><p>I have made and sold a React boilerplate before, <a href="https://www.reactmilkshake.com/">React Milkshake</a>. In the week after launching React Milkshake I made just 29 dollars. I, later on, created upgraded versions of the boilerplate. Every new version sold a bit better than the previous one, but with my completely new project <a href="https://serverless.page/">Serverless SaaS</a> I have made more in one week than with all the previous projects combined in a year.</p><p>This didn’t just happen because I just got luckier this time. Here is what I did differently.</p><h3>Landing page before product building</h3><p>The first mistake I made in the previous projects was working by myself until it was time to launch. This meant I didn’t have an audience.</p><p>Inspired by the #BuildInPublic movement, I decided for my new project to first build <a href="https://serverless.page/">the landing page</a> and open up a mailing list so people could subscribe and follow the progress of me building the product. Every now and then I shared some updates and slowly grew the mailing list to over 100 people that were sincerely interested in what I was making.</p><h3>Blogging</h3><p>In the past, I had written some articles on Medium before, but I decided to at least write one or two new blog posts every month. In total, I have at least 10 new blog posts that are related to some of the technologies that are being used in <a href="https://serverless.page/">Serverless SaaS</a>. Most of them are tutorials like <a href="https://medium.com/better-programming/how-to-set-up-next-js-with-tailwind-css-b93ccd2d4164">How to setup Next.js with Tailwind</a> or <a href="https://medium.com/better-programming/how-to-implement-netlify-cms-with-next-js-4b8721bdec45">How to implement Netlify CMS with Next.js</a>, but also a series called <em>stack choices</em> in which I compare different frameworks or technologies with each other as <a href="https://codeburst.io/stack-choices-react-vs-vue-vs-angular-vs-svelte-49aa0170c634">Angular vs React vs Vue vs Svelte</a>.</p><p>Writing these blog posts had multiple purposes and ended up with benefits:</p><ul><li>Learned a lot about these subjects</li><li>Provided value for other people learning about these subject</li><li>Earned some money with the <a href="https://help.medium.com/hc/en-us/articles/115011694187-Getting-started-with-the-Medium-Partner-Program#h_01EECWD3WWHZTJMF5PTK7AAM2C">Medium Partner Program</a></li><li>Gave me the ability to drop a link to my new project</li><li>Gave me the ability to drop a link to my personal site and Twitter</li><li>Increased my followings on Medium</li></ul><p>The people who read my blog posts could also be future customers because the starter-kit is mainly for developers (or people who work with developers).</p><h3>Mailing list</h3><p>This time I had built up a mailing list with around 100 subscribers, all with people who were interested in the boilerplate. Around 50% opened the emails I had to send and around 30% clicked the links to the site. This list is still growing because I still allow people to sign up to get regular updates.</p><p>Besides that, I already had a personal mailing list of people who had signed up for previous products I have to build like <a href="https://codestash.co/">codestash</a>, <a href="https://www.makermove.com/">makermove</a>, and <a href="https://www.raterfox.com/">raterfox</a>.</p><p>Because I started blogging more I updated <a href="https://jakeprins.com/">my personal site</a> and also added a signup field for this personal mailing list to stay informed about blog posts or product updates. In total, I had around 1000 people on this list to send out an announcement, but just 20% of that list opened the email and only 2.5% clicked the link. Those numbers are not great, but most of these subscribers come from <a href="http://raterfox.com/">raterfox.com</a>, a social platform for entertainment, which is clearly not my target audience.</p><h3>Twitter</h3><p>Twitter is a great platform for talking in public about the process and updates on your products. I wasn’t very active on Twitter and mainly used it to stay informed about tech-related stuff. I decided to be more active and did manage to gain some more Twitter followers. I think the slow growth is caused mostly by being more active on not just Twitter, but also on Indie Hackers and mentioning <a href="https://twitter.com/jakeprins_nl">my handle</a> in blog posts.</p><p>With the current 581 followers, I do not believe this had a very big impact on my launch. Twitter seems great for people with a couple of thousands of followers, but with &lt; 1k followers it sometimes feels like you are talking to a black hole of nothing.</p><p>I still think it’s a great way to share your work and be reachable by others. Some people started to DM me with questions about the boilerplate. This was already a good sign. Also, people told me they were excited about the upcoming launch, even better! Besides that, someone reached out to say my guides online were really helpful, which is always great to hear.</p><h3>Building a better product</h3><p>The first boilerplate I had build, <a href="https://www.reactmilkshake.com/">React Milkshake</a>, was a bit of an experiment. I was using it myself and wasn’t sure if other people were going to pay for it. It was very basic and doesn’t have a lot of features when it launched, but the fact that people started to buy it was super exciting for me. It proved that people are willing to pay money for a starter-kit that helped them save time.</p><p>For my next project, <a href="https://serverless.page/">Serverless SaaS</a>, I decided to spend more time on it and take it to the next level. I had some proof of the market, but the product needed to provide more value.</p><p>Most Indiehackers and developers I met online were building SaaS apps. I also had some ideas for building a SaaS, so a boilerplate that could help me build new SaaS apps faster was very helpful. If the boilerplate wouldn’t sell, I could still use it myself. So I decided to implement multiple SaaS features, like a billing integration with Stripe, and market the product as a way to build SaaS apps faster.</p><p>This would be more aligned with the need for most of my target audience and also allows me to ask for a higher price. It provides much more value than my other boilerplates and people are also more willing to pay for products that help them save time or make money. This project could potentially do both.</p><p>Instead of rushing to market and going with a full-on MVP approach, I figured I should take my time and craft a product to be proud of. After that, I could soft launch it as “Early Access”, so I could ask my first customers for feedback and improve the product while it’s being used by actual paying customers. In this soft launch period, I made more money than I did in the last year of my old project, so I guess I’m doing something right.</p><h2>Conclusion</h2><p>After years of indie hacking, I have learned a lot of valuable lessons. Looking back at the months leading to the “soft” launch of my new product, I can tell that certain activities will highly increase your chances of a successful launch.</p><p>Building in public, by sharing your progress and thoughts on social platforms, could definitely help a lot.</p><p>Taking time to write articles and provide value to others helps you in building an audience and to connect with people that might end up being a customer.</p><p>Also, don’t rush the process of building a product. It can be helpful to launch fast and validate your idea as quickly as possible, but if you want to provide real value that could mean you need to put in some extra time. Once you have seen some proof of evidence that people are willing to pay for your product I think it’s good to not rush your project. Don’t put too much pressure on yourself. But, when you think that MVP is ready, just ship it.</p><p>Thanks for reading! You can find me on Twitter (<a href="https://twitter.com/jakeprins_nl">@jakeprins_nl</a>) or read more at <a href="https://jakeprins.com/blog">jakeprins.com/blog</a>.</p></article></div></div>]]>
            </description>
            <link>https://jakeprins.com/blog/how-i-went-from-2k-in-a-year-to-2k-in-a-week</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196434</guid>
            <pubDate>Tue, 24 Nov 2020 08:26:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[5th UberEats cyclist killed in Sydney in 3 months: Analysis and photos]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25196375">thread link</a>) | @jakecopp
<br/>
November 24, 2020 | https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/ | <a href="https://web.archive.org/web/*/https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Last updated: November 24th, 2020. Please leave comments on <a href="https://news.ycombinator.com/item?id=25196375">Hacker News</a> (&gt;6 comments).</p>

<p><strong>Content warning</strong>: Description of a death, and photos of the cleaned site of death.</p>
<p>After <a href="https://www.theguardian.com/business/2020/nov/23/death-of-sydney-uber-eats-rider-the-fourth-food-delivery-fatality-in-two-months">four cyclists were killed by car drivers in Sydney in the last 2 months</a>, a <a href="https://www.abc.net.au/news/2020-11-24/uber-eats-vows-to-improve-safety-cyclist-killed-in-inner-sydney/12913840">37-year-old man from Malaysia</a> was killed at ~6:40pm last night - on my street, 200 metres from my front door, at an intersection I cycle through 2-4 times a day. I would have gone through that intersection within 15 minutes of that time if I didn’t skip a class. If you know me, I’m usually quite outspoken about the dangers cyclists face, but this was absolutely brutal to hear.</p>
<p>They cleaned up the body, but didn’t completely clean up the UberEats meal the man was delivering. The man likely died while earning less than minimum wage - A survey conducted by the Transport Workers’ Union in September <a href="https://www.theguardian.com/business/2020/nov/23/death-of-sydney-uber-eats-rider-the-fourth-food-delivery-fatality-in-two-months">found</a> that food deliverers earned an average of just $10.42 an hour after costs. 73% said they were worried about being “seriously hurt or killed” at work.</p>
<p><em>Content warning: Image of scattered food on road, blue glove likely from police investigation.</em></p>
</div><div>
<p>An <a href="https://www.reddit.com/r/sydney/comments/jzewgi/fifth_food_delivery_rider_dies_following_truck/gdbm0s4/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3">eyewitness account on Reddit</a>:</p>
<blockquote>
<p>…I was driving along Cleveland st, and only had a glimpse of what happened: for those of you arguing about PPE - I think there was a helmet - and a crushed head and body, and a twisted bicycle, and, yes, one of those grey food delivery bags all in the middle of Chalmers st. I am crying tonight, because that was someone’s child, friend … a person - who is no more… .</p>
</blockquote>
<p><em>Content warning: Image of fragment of the helmet of the cyclist in the road gutter.</em></p>
</div><div>
<h2 id="contributing-causes">Contributing causes</h2>
<p>This is a tragedy in itself, but there are also a number of contributing causes at play here:</p>
<ul>
<li><p>In NSW, cycling on a footpath <a href="https://bicyclensw.org.au/who-can-ride-on-a-footpath-in-nsw/">is illegal and carries a fine of $114</a> for those above 15 years of age. Footpath cycling is <a href="https://www.bykbikes.com.au/blogs/bike-riding-tips/riding-bikes-on-the-footpath-the-laws-for-kids-and-adults-in-australia">legal in</a> Queensland, Tasmania, the ACT, the Northern Territory and South Australia.</p>
<ul>
<li>In the UK in 2017, there is a cyclist/pedestrian collision every <a href="https://www.cyclingweekly.com/news/rise-pedestrians-hit-cyclists-not-cause-leap-conclusions-396047">~9.9 million kilometres walked by a pedestrian</a>, or 531 in total. Of these 531 collisions 3 people were killed.</li>
</ul></li>
<li><p>Gig economy workers have little training and often no insurance. California recently proposed a law to force Uber and other platforms to treat their workers like employees. It narrowly failed to pass after <a href="https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/Uber,%20Lyft,%20and%20DoorDash%20poured%20over%20$200%20million%20into">Uber, Lyft and Doordash spent &gt; US$200m</a> campaigning against the law.</p></li>
<li><p>Dedicated infrastructure for cyclists is rare in Sydney. Not only are separated bicycle lanes hard to come by, a state government <a href="https://concreteplayground.com/sydney/design-style/sustainability/state-goverment-moves-to-rip-up-college-street-cycleway">actively removed</a> a cycleway in 2015 (which <a href="https://www.dailytelegraph.com.au/newslocal/central-sydney/college-st-syclists-four-times-as-likely-to-be-involved-in-a-crash-since-cycleway-removed/news-story/98ebe30e5c649407e45fd1aa7f023049">increased accidents by 400%</a>) <a href="https://www.bicyclenetwork.com.au/newsroom/2019/03/12/planned-removal-of-alexandra-canal-cycleway/">and in 2019</a>. Walking and cycling infrastructure typically receives <a href="https://theconversation.com/cycling-and-walking-can-help-drive-australias-recovery-but-not-with-less-than-2-of-transport-budgets-142176">0.1-2% of transport budgets</a>. Clover Moore is pushing hard on adding new dedicated cycle infrastructure in the City of Sydney - <a href="https://www.cityofsydney.nsw.gov.au/building-new-infrastructure/creating-pop-up-cycleways-in-sydney">Six pop-up cycleways</a> have been added, which may remain if their is popular support.</p></li>
<li><p>Australian car drivers have a <a href="https://www.abc.net.au/triplej/programs/hack/mythbusting-the-reasons-why-people-hate-cyclists/8689058">unique hatred of cyclists</a>. Cyclists <a href="https://www.smh.com.au/lifestyle/youre-a-cyclist-so-its-your-fault-20140205-321np.html">attract a level of vitriol</a>, if not outright malice, reserved for few subjects in the laid back Aussie’s mind. Even Tour de France winner Cadel Evans, a self described “car guy” who has a number of classic and sports cars, said <a href="https://www.smh.com.au/entertainment/books/even-tour-de-france-winner-cadel-evans-finds-cycling-in-sydney-too-intimidating-20161118-gss316.html">he doesn’t cycle in Sydney</a> due to the culture. Cyclists want to be on the road even less than car drivers want them there, but as stated earlier it is illegal to cycle on the footpath.</p></li>
</ul>
<p><em>Content warning: Image of the street where event took place, recognisable to those who live in Sydney.</em></p>
</div><div>
<h2 id="reasons-for-change">Reasons for change</h2>
<h3 id="public-safety">Public safety</h3>
<p>Car crashes are one of the <a href="https://www.seattletimes.com/life/lifestyle/the-most-dangerous-activity-driving/">leading causes of death in western countries</a>, and air pollution due to cars killed <a href="https://www.smh.com.au/politics/federal/road-death-toll-should-include-victims-of-vehicle-emissions-report-20190628-p522a8.html">two times</a> as many people as <a href="https://roadsafety.transport.nsw.gov.au/statistics/index.html">crashes do</a> in NSW each year - and they didn’t even have a choice. <a href="http://publications.jrc.ec.europa.eu/repository/bitstream/JRC89231/jrc89231-online%20final%20version%202.pdf">Half of PM10 particle emissions come from tire wear, suspended road dust and brake wear</a>- electric cars (even with regen braking) won’t fix this. In the US, drivers of cars <a href="http://vpc.org/regulating-the-gun-industry/gun-deaths-compared-to-motor-vehicle-deaths/">kill more people</a> than guns each year.</p>
<p>NSW has a program called <a href="https://towardszero.nsw.gov.au/">Towards Zero</a>, with the aim of reducing road fatalities to zero. One of the few cities to achieve this goal is Oslo, which <a href="https://twitter.com/andershartmann/status/1212465415743512576">reduced pedestrian and cyclist deaths in 2019 to 0</a> by making the <em>city centre</em> <a href="https://www.fastcompany.com/90294948/what-happened-when-oslo-decided-to-make-its-downtown-basically-car-free">effectively car free</a>, replacing more than 700 parking spots with bike lanes, plants, parks and benches, increasing business.</p>
<p><em>Content warning: Image of food on the tarmac, and diffracted reflection from fluid likely used to clean the road.</em></p>
</div><div>
<h3 id="cars-are-heavily-subsidised-in-australia">Cars are heavily subsidised in Australia</h3>
<p>By the most generous measure, drivers only contribute <a href="https://www.ptua.org.au/myths/petroltax/">two-thirds of the cost of the road system</a> through rego and petrol taxes. The damage to a road is proportional to the <em>fourth power</em> of axle weight. Many cyclists also own a car and already pay rego. Contrary to popular belief, cyclists are likely subsidising car users.</p>
<h3 id="investing-in-cycle-infrastructurereducing-car-usage-makes-economic-sense">Investing in cycle infrastructure/reducing car usage makes economic sense</h3>
<p>In one study, for each dollar of investment in cycle focused infrastructure, the best practice policy returns 24 dollars in health, congestion, and air and noise pollution related benefits (<a href="https://ec.europa.eu/environment/integration/research/newsalert/pdf/378na1_en.pdf">Macmillan, A., Connor, J., Witten, K., et al.&nbsp;(2014). The Societal Costs and Benefits of Commuter Bicycling: Simulating the Effects of Specific Policies Using System Dynamics Modeling</a>)</p>
<p>A paper submitted to Infrastructure Australia estimated the value of commuter cycling in Australian capital cities as worth approximately <a href="https://www.infrastructureaustralia.gov.au/sites/default/files/2019-06/Cycling_Infrastructure_Background_Paper_16Mar09_WEB.pdf">$0.76 per kilometre travelled</a>, equating to $2,667 for each regular commuter. Another paper <a href="https://www.infrastructureaustralia.gov.au/sites/default/files/2019-06/Cycling_Infrastructure_Background_Paper_16Mar09_WEB.pdf">estimated</a> that converting drivers to cycling in Sydney &amp; Brisbane is worth $0.74 per kilometre, $1,920 per person annually in inner Sydney.</p>
<p>Banning cars on a street in Rome led to <a href="https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/www.theguardian.com/cities/2015/mar/13/pedestrianisation-rome-italy-car-parking-ban">30% increase</a> in retail spending in that street.</p>
<p>There are <a href="https://cityobservatory.org/ten-things-more-inequitable-that-road-pricing/">a lot of things</a> in our current system more inequitable than road pricing in urban areas.</p>
<h3 id="a-lot-of-other-cities-are-reducing-car-usage">A lot of other cities are reducing car usage</h3>
<p>I know this argumentum ad populum, but hey.</p>
<p>The following cities have a <a href="https://en.wikipedia.org/wiki/Congestion_pricing">congestion tax</a> in their urban core:</p>
<ul>
<li><a href="https://theconversation.com/london-congestion-charge-what-worked-what-didnt-what-next-92478">London</a></li>
<li><a href="https://en.wikipedia.org/wiki/Congestion_pricing_in_New_York_City">New York</a> (soon)</li>
<li>Stockholm</li>
<li>Singapore</li>
<li>Milan</li>
<li>Gothenburg</li>
</ul>
<p>Other efforts to reduce car usage:</p>
<ul>
<li><p>Oslo (population 673k) <a href="https://twitter.com/andershartmann/status/1212465415743512576">reduced pedestrian and cyclist deaths in 2019 to 0</a> by making the city centre <a href="https://www.fastcompany.com/90294948/what-happened-when-oslo-decided-to-make-its-downtown-basically-car-free">effectively car free</a>, replacing more than 700 parking spots with bike lanes, plants, parks and benches. Amsterdam, New York, and San Francisco are <a href="https://www.citylab.com/perspective/2019/12/car-free-streets-plans-sf-market-street-new-york-europe-us/603391/">banning cars from their major streets</a>.</p></li>
<li><p>Madrid banned cars from its city centre during the 2018 Christmas period, <a href="https://copenhagenize.eu/news-archive/2019/3/14/the-benefits-of-car-free-streets">increasing retail profit by 9.5%</a>, and they are planning to ban cars from <a href="https://www.businessinsider.com.au/cities-going-car-free-ban-2018-12?r=US&amp;IR=T">500 acres of the city centre this year</a>.</p></li>
<li><p>In <a href="https://www.businessinsider.com.au/cities-going-car-free-ban-2018-12?r=US&amp;IR=T">Paris</a>, the first Sunday of every month is free of cars.</p></li>
</ul>
<p><em>Content warning: Image of food in the gutter of the road.</em></p>
</div><div>







<div><p>Disagree with my argument? Have I missed something or is there a mistake? I'd love to hear, please
contact me at <a href="https://jakecoppinger.blog/cdn-cgi/l/email-protection#066c676d63466c676d63656976766f686163742865696b"><span data-cfemail="90faf1fbf5d0faf1fbf5f3ffe0e0f9fef7f5e2bef3fffd">[email&nbsp;protected]</span></a>. I'm open changing my views if presented with new evidence.
</p></div></div></div>]]>
            </description>
            <link>https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196375</guid>
            <pubDate>Tue, 24 Nov 2020 08:14:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[India's WhiteHat Jr is startup hell]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25195938">thread link</a>) | @mihir6692
<br/>
November 23, 2020 | https://themorningcontext.com/internet/indias-whitehatjr-is-startup-hell | <a href="https://web.archive.org/web/*/https://themorningcontext.com/internet/indias-whitehatjr-is-startup-hell">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><p><strong><span>S</span>haarif Ansari got the call on 11 November</strong> at around 9 in the morning. On the phone was a police officer from Powai police station, in the suburbs of Mumbai. “Ansari please come to the police station,” said the officer. “We have received a complaint from your employer WhiteHat Jr. The company officials are here at the station already. We are waiting for you.”&nbsp;</p> <p>Ansari was taken aback. It is not everyday that you have a police officer call you. Almost immediately he clarified that he did not work at WhiteHat Jr anymore. That he was fired by the company in the first week of September and had had no contact with them since, so what was all this about? The person was in no mood to explain or chat. He cut Ansari off, and asked him to turn up at the station immediately. Caught completely by surprise and with no idea about what was in store for him, Ansari said he was on his way.</p> <p>Once he reached the station, Ansari found two people waiting for him</p></div></div></div></div></div>]]>
            </description>
            <link>https://themorningcontext.com/internet/indias-whitehatjr-is-startup-hell</link>
            <guid isPermaLink="false">hacker-news-small-sites-25195938</guid>
            <pubDate>Tue, 24 Nov 2020 06:41:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Kakoune – The quest for a better code editor]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25195467">thread link</a>) | @imran3740
<br/>
November 23, 2020 | https://kakoune.org/why-kakoune/why-kakoune.html | <a href="https://web.archive.org/web/*/https://kakoune.org/why-kakoune/why-kakoune.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Up to now, I have used vi as an example for modal text editor, mostly because
I expect most programmers have at least heard of it. However, I don’t believe
vi and clones are the best modal text editor out there.</p>
<p>I have been working, for the last 5 years, on a new modal editor called
Kakoune. It first started as a reimplementation of Vim (the most popular vi
clone) whose source code is quite dated. But, I soon realized that we could
improve a lot on vi editing model.</p>
<div>
<h3 id="_improving_on_the_editing_model">Improving on the editing model</h3>
<p>vi basic grammar is <strong>verb</strong> followed by <strong>object</strong>; it’s nice because it matches
well with the order we use in English, "delete word". On the other hand,
it does not match well with the nature of what we express: There is only
a handful of <strong>verbs</strong> in text editing (<strong>d</strong>elete, <strong>y</strong>ank, <strong>p</strong>aste,
<strong>i</strong>nsert…​), and they don’t compose, contrarily to <strong>objects</strong> which can be
arbitrarily complex, and difficult to express. That means that errors are
not handled well. If you express your object wrongly with a delete verb,
the wrong text will get deleted, you will need to undo, and try again.</p>
<p>Kakoune’s grammar is <strong>object</strong> followed by <strong>verb</strong>, combined with instantaneous
feedback, that means you always see the current object (In Kakoune we call
that the selection) before you apply your change, which allows you to correct
errors on the go.</p>
<p>Kakoune tries hard to fix one of the big problems with the vi model: its
lack of interactivity. Because of the <strong>verb</strong> followed by <strong>object</strong> grammar,
vi changes are made in the dark, we don’t see their effect until the whole
editing <strong>sentence</strong> is finished. <code>5dw</code> will delete to next five words, if
you then realize that was one word too many, you need to undo, go back to
your initial position, and try again with <code>4dw</code>. In Kakoune, you would do
<code>5W</code>, see immediately that one more word than expected was selected, type
<code>BH</code> to remove that word from the selection, then <code>d</code> to delete.  At each
step you get visual feedback, and have the opportunity to correct it.</p>
<p>At the lower level, the problem is that vi treats moving around and selecting
an object as two different things. Kakoune unifies that, moving <strong>is</strong> selecting.
<code>w</code> does not just go to the next word, it selects from current position to
the next word. By convention, capital commands tend to expand the selection,
so <code>W</code> would expand the current selection to the next word.</p>
</div>
<div>
<h3 id="_multiple_selections">Multiple selections</h3>
<p>Another particular feature of Kakoune is its support for, and emphasis
towards the use of multiple selections. Multiple selections in Kakoune
are not just one additional feature, it is the central way of interacting
with your text. For example there is no such thing as a "global replace" in
Kakoune. What you would do is select the whole buffer with the <code>%</code> command,
then select all matches for a regex in the current selections (that is the
whole buffer here) with the <code>s</code> command, which prompts for a regex. You would
end up with one selection for each match of your regex and use the insert
mode to do your change. Globally replacing foo with bar would be done with
<code>%sfoo&lt;ret&gt;cbar&lt;esc&gt;</code> which is just the combination of basic building blocks.</p>
<div>
<p>Global replace</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/global-replace.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Multiple selections provides us with a very powerful to express structural
selection: we can subselect matches inside the current selections, keep
selections containing/not containing a match, split selections on a regex,
swap selections contents…​</p>
<p>For example, convert from <code>snake_case_style</code> to <code>camelCaseStyle</code> can be done
by selecting the word (with <code>w</code> for example) then subselecting underscores
in the word with <code>s_&lt;ret&gt;</code>, deleting these with <code>d</code>, then upper casing the
selected characters with <code>~</code>. The inverse operation could be done by selecting
the word, then subselecting the upper case characters with <code>s[A-Z]&lt;ret&gt;</code>
lower casing them with ` and then inserting an underscore before them with
<code>i_&lt;esc&gt;</code> This operation could be put in a macro, and would be reusable
easily to convert any identifier.</p>
<div>
<p>Camel case to snake case</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/camel.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Another example would be parameter swapping, if you had <code>func(arg2, arg1);</code>
you could select the contents of the parenthesis with <code>&lt;a-i&gt;(</code>, split the
selection on comma with <code>S, &lt;ret&gt;</code>, and swap selection contents with <code>&lt;a-)&gt;</code>.</p>
<div>
<p>Swapping arguments</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/args-swap.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>It is as well easy to use multiple selections for alignment, as the <code>&amp;</code>
command will align all selection cursors by inserting blanks before
selection start</p>
<div>
<p>Aligning variables</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/align.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Or to use multiple selections as a way to gather some text from different
places and regroup it in another place, thanks to a special form of pasting
<code>&lt;a-p&gt;</code> that will paste every yanked selections instead of the first one.</p>
<div>
<p>Regrouping manager objects together</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/regroup.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
</div>
<div>
<h3 id="_interactive_predictable_and_fast">Interactive, predictable and fast</h3>
<p>A design goal of Kakoune is to beat vim at its own game, while providing a
cleaner editing model. The combination of multiple selections and cleaned up
grammar shows that it’s possible to have text edition that is interactive,
predictable, and fast at the same time.</p>
<p>Interactivity comes from providing feedback on every command, made possible by
the inverted <strong>object</strong> then <strong>verb</strong> grammar. Every selection modification
has direct visual feedback; regex-based selections incrementally show what
will get selected, including when the regular expression is invalid; and even
yanking some text displays a message notifying how many selections were yanked.</p>
<p>Predictability comes from the simple effect of most commands. Each command is
conceptually simple, doing one single thing. <code>d</code> deletes whatever is selected,
nothing more. <code>%</code> selects the whole buffer. <code>s</code> prompts for a regex and
selects matches in the previous selection. It is the combination of these
building blocks that allows for complex, but predictable, actions on the text.</p>
<p>Being fast, as in requiring fewer keystrokes, is provided by carefully designing
the set of editing commands so that they interact well together, and by sometimes
sacrificing beauty for useability. For example, <code>&lt;a-s&gt;</code> is equivalent to
<code>S^&lt;ret&gt;</code>: they both split on new lines, but this is such a common use case that
it deserves to have its own key shortcut. As shown in <a href="http://github.com/mawww/golf">http://github.com/mawww/golf</a>,
Kakoune manages to beat Vim at the keystroke count game in most cases,
using much more idiomatic commands.</p>
</div>
<div>
<h3 id="_discoverability">Discoverability</h3>
<p>Keyboard oriented programs tend to be at a disadvantage compared to GUI
applications because they are less discoverable; there is no menu bar on
which to click to see the available options, no tooltip appearing when you
hover above a button explaining what it does.</p>
<p>Kakoune solves this problem through the use of two mechanisms: extensive
completion support, and auto-information display.</p>
<p>When a command is written in a prompt, Kakoune will automatically open a menu
providing you with the available completions for the current parameter. It
will know if the parameter is supposed to be a word against a fixed set
of word, the name of a buffer, a filename, etc…​ Actually, as soon as <code>:</code>
is typed, entering command prompt mode, the list of existing commands will
be displayed in the completion menu.</p>
<p>Additionally, Kakoune will display an information box, describing what the
command does, what optional switches it can take, what they do…​</p>
<div>
<p>Command discoverability</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/discoverability.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>That information box gets displayed in other cases, for example if the <code>g</code>
key is hit, which then waits for another key (<code>g</code> is the <strong>goto</strong> commands
prefix), an information box will display all the recognized keys, informing
the user that Kakoune is waiting on a keystroke, and listing the available
options.</p>
<p>To go even further in discoverability, the auto information system can
be set to display an information box after each normal mode keystroke,
explaining what the key pressed just did.</p>
</div>
<div>
<h3 id="_extensive_completion_support">Extensive completion support</h3>
<p>Keyboard oriented programs are much easier to work with when they provide
extensive completion support. For a long time, completion has been prefix
based, and that has been working very well.</p>
<p>More recently, we started to see more and more programs using the so called
fuzzy completion. Fuzzy completion tends to be subsequence based, instead
of prefix based, which means the typed query needs to be a subsequence of
a candidate to be considered matching, instead of a prefix. That will generate
more candidates (all prefix matches are also subsequence matches), so it
needs a good ranking algorithm to sort the matches and put the best ones first.</p>
<p>Kakoune embraces fuzzy matching for its completion support, which kicks in both
during insert mode, and prompt mode.</p>
<div>
<p>Word completion support</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/completion.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Insert mode completion provides completion suggestions while inserting in the
buffer, it can complete words from the buffer, or from all buffers, lines,
filenames, or get completion candidates from an external source, making it
possible to implement intelligent code completion.</p>
<div>
<p>Language specific completion support</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/cpp-completion.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Prompt completion is displayed whenever we enter command mode, and provides
completion candidates that are adapted to the command being entered, and to
the current argument being edited.</p>
</div>
<div>
<h3 id="_a_better_unix_citizen">A better unix citizen</h3>
<p>Easily making programs cooperate with each others is one of the main strength
of the Unix environment. Kakoune is designed to integrate nicely with a POSIX
system: various text editing commands give direct access to the power of POSIX
tools, like <code>|</code>, which prompts for a shell command and pipe selections through
it, replacing their contents with the command output, or <code>$</code> that prompts for
a command, and keeps selections for which the command returned success.</p>
<div>
<p>Using external commands as filters</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/filters.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>This is only the tip of the iceberg. Kakoune is very easily controllable from</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kakoune.org/why-kakoune/why-kakoune.html">https://kakoune.org/why-kakoune/why-kakoune.html</a></em></p>]]>
            </description>
            <link>https://kakoune.org/why-kakoune/why-kakoune.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25195467</guid>
            <pubDate>Tue, 24 Nov 2020 05:07:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Love Ed on CP/M]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25195420">thread link</a>) | @todsacerdoti
<br/>
November 23, 2020 | https://techtinkering.com/articles/i-love-ed-on-cpm/ | <a href="https://web.archive.org/web/*/https://techtinkering.com/articles/i-love-ed-on-cpm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p>I love ED on CP/M.  It's often derided but I think it's just misunderstood and with a little practise its true value can shine through.  It's elegant, easy to learn and only has about 25 commands but these can be combined.  Once you get used to it most editing tasks are pretty quick.  If I'm editing text that is made up of separate lines, ideally not more than the width of the terminal, I find it excellent.  It does have a line limit of 128 characters so for continuous prose I will switch to something like Wordstar, but for editing source code and config files on CP/M, it's my first choice.</p>
<p>ED came as standard with CP/M and is only 7k for CP/M 2.2 and 10k for CP/M Plus.  One advantage of ED is that it will work both with teleprinters and video terminals without having to be configured for each device.  It is also good at manipulating large files even when the system is short of memory.</p>
<p><img src="https://techtinkering.com/img/articles/cpm_ed_copy_paste.png" title="Copying and Pasting with ED"></p><p>Like many early editors, ED is a modal editor which you start in command mode and while in this mode you can view existing text, move between lines and points in the line.  It allows you to do standard operations such as copy and paste, inserting text from other files, searching for and replacing text, etc.  When we want to enter input mode, we can use the 'I' command.  This is much like VI, except that you can only enter text in the non-command mode but not edit it.  To exit data input mode and return to command mode you use ^Z (CTRL-Z).  These commands can be combined together and one of the most powerful facilities that ED has is the 'M' Macro command to repeat sequences of commands.</p>
<p>Upon executing ED it creates a temporary output file and as you write out from ED it goes to this temporary file.  When editing a file we append text from it into the memory buffer and save to the temporary output file as we go or at the end.</p>
<p>ED keeps track of a number of values such as where it is in the source file,  the line number in the memory buffer and the character pointer (CP) on the line.  These are altered as you move around the file and memory buffer.</p>
<p>I'm not going to give a fuller explanation of how to use ED here because the CP/M 2.2 Operating Manual has a good section on the <a href="http://www.gaby.de/cpm/manuals/archive/cpm22htm/ch2.htm">CP/M Editor</a>.  I do, however, want to show it being used properly in the video below.  Further down in this article I have highlighted some useful command sequences.</p>
<h2>An Example Macro</h2>
<p>ED has a macro facility which allows you to repeat a sequence of commands as many times as you like.  This makes it a good example of the power of ED and the following is a typical macro which searches through the memory buffer and displays any occurrences of the text 'CPM', pauses in case you want to stop the macro and then replaces it with 'CP/M'.</p>
<pre><code>MFCPM^Z0TT6Z-3CSCPM^ZCP/M^Z
</code></pre>
<p>The 'M' command will run the sequences of commands that follows it until an error is raised, such as end of file.  If we wanted to we could prepend 'M' with a number to indicate the number of times we want it to run.  I'll break down each command in the sequence below:</p>
<table>
  <tbody><tr><td><code>M</code></td><td>Run the following command sequence until an error</td></tr>
  <tr><td><code>FCPM^Z</code></td><td>Find 'CPM' and leave Character Pointer (CP) after it</td></tr>
  <tr><td><code>0T</code></td><td>Display the line up to CP</td></tr>
  <tr><td><code>T</code></td><td>Display the rest of the line from CP to end </td></tr>
  <tr><td><code>6Z</code></td><td>Pause</td></tr>
  <tr><td><code>-3C</code></td><td>Move CP back 3 characters</td></tr>
  <tr><td><code>SCPM^ZCP/M^</code></td><td>Substitute 'CPM' for 'CP/M'</td></tr>
</tbody></table>
<p><code>^Z</code> in the above is CTRL-Z and indicates the end of an argument for a command.</p>
<p>The above macro could also be written:</p>
<pre><code>MFCPM^Z0TT6Z-3DICP/M^Z
</code></pre>
<p>In which case:</p>
<table>
  <tbody><tr><td><code>-3D</code></td><td>Delete the 3 previous characters</td></tr>
  <tr><td><code>ICPM^Z</code></td><td>Insert the text 'CP/M'</td></tr>
</tbody></table>
<h2>Video</h2>
<p>The video below shows ED being used properly and some of the things that make it great, including searching and replacing text, copying and pasting, macros and handling files bigger than the available memory.</p>
<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/7pqaj050X7g" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
<h2>Common Command Sequences</h2>
<p>Below are some useful command command sequences which may be overlooked when reading the manual for ED.</p>
<div><table>
  <tbody><tr><th>Sequence</th><th>Explanation</th></tr>
  <tr><td>#A</td><td>Load whole file into buffer</td></tr>
  <tr><td>0A</td><td>Load enough of the file to fill half the buffer.  This is great for large files</td></tr>
  <tr><td>#W0A</td><td>Save entire buffer and load more of the source file, enough to fill half of the buffer.  Useful to move through large files.</td></tr>
  <tr><td>0W</td><td>Write half of the buffer to the new file.  Useful to make room of the buffer is full.</td></tr>
  <tr><td>-B</td><td>Move to end of the last line in the buffer</td></tr>
  <tr><td>0L</td><td>Move CP to beginning of line</td></tr>
  <tr><td>L-2C</td><td>Move to end of line before the &lt;cr&gt;&lt;lf&gt; sequence</td></tr>
  <tr><td>0P</td><td>Display page from CP without moving CP</td></tr>
  <tr><td>0LT</td><td>Move CP to beginning of line and display line (Should this be +/-n ??)</td></tr>
  <tr><td>0T</td><td>Type line up to but not including CP</td></tr>
  <tr><td>0TT</td><td>Type whole line without moving CP</td></tr>
  <tr><td>0T&lt;cr&gt;T</td><td>Type whole line without moving CP.  Display up to CP on first list and from CP on next line.  This is useful to see where CP is on line.</td></tr>
  <tr><td>B#T</td><td>Display the whole buffer</td></tr>
  <tr><td>KI</td><td>Replace a line</td></tr>
  <tr><td>0K</td><td>Delete up to CP on current line</td></tr>
  <tr><td>S^L^Z</td><td>Join current line with next</td></tr>
  <tr><td>I^L^Z</td><td>To split a line at CP</td></tr>
  <tr><td>0V</td><td>Print free/total memory buffer stats</td></tr>
  <tr><td>0X</td><td>Empties the temporary default exchange file: X$$$$$$$.LIB, used by the <em>X</em> command</td></tr>
</tbody></table></div>
<p>In the table above the following holds true:</p>
<dl>
  <dt>#</dt><dd>Represents the highest value for n</dd>
  <dt>^L</dt><dd>CTRL-L - Stands for carriage return sequence &lt;cr&gt;&lt;lf&gt;</dd>
  <dt>^Z</dt><dd>CTRL-Z - Indicates the end of a command's argument</dd>
  <dt>&lt;cr&gt;</dt><dd>Carriage Return - Actually pressing the <em>Return</em> key</dd>
</dl>
<br>
<h2>Do You Like ED Too?</h2>
<p>I know that I'm in the minority, but I'm sure there must be other people who also like ED.  I'd love to hear if I'm not alone in this.  You can leave comments via the links below or via the YouTube video above.</p>
      </div></div>]]>
            </description>
            <link>https://techtinkering.com/articles/i-love-ed-on-cpm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25195420</guid>
            <pubDate>Tue, 24 Nov 2020 04:59:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quest to Disable LAN LEDs of an Intel NUC]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25194316">thread link</a>) | @hiq
<br/>
November 23, 2020 | https://pwmon.org/p/1900/quest-disable-lan-leds-intel-nuc/ | <a href="https://web.archive.org/web/*/https://pwmon.org/p/1900/quest-disable-lan-leds-intel-nuc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<h2>Introduction</h2>
<p>The Intel NUC <a href="http://ark.intel.com/products/76978/">D34010WYK</a> has a LAN port with two integrated LEDs. Both are permanently on when a connection is established, with one LED blinking on network activity. This can be rather distracting, particularly at night. So I went on to figure out how to disable the LEDs. It's a general solution that should work with every OS, every NUC, and every somewhat recent Intel NIC (Network Interface Card). Perhaps most devices with an Intel Ethernet controller.</p>
<p>The most obvious and low-tech solution is to tape the LEDs. I haven't tried as an observation led me on a different path. I noticed that a few seconds into booting Ubuntu, the LEDs are briefly switched off. I concluded this must be done through software somehow. This didn't turn out to be entirely correct or useful, as the driver (kernel module) merely resets the controller when it loads, but made me curious enough to proceed.</p>
<p>First, a step back to know the controller used in the NUC.</p>
<p>$ lspci | grep Ethernet
00:19.0 Ethernet controller: Intel Corporation Ethernet Connection I218-V (rev 04)</p>
<p>Intel ARK has <a href="http://ark.intel.com/products/71305/">more information</a>, including a very detailed 262-pages datasheet, which will prove essential.</p>
<h2>Kernel</h2>
<p>I wondered if the option to disable LEDs is perhaps provided through a kernel module parameter. I already knew the  module name for recent Intel Ethernet devices: <i>e1000e</i>. If I hadn't, <a href="https://downloadcenter.intel.com/search?keyword=I218">searching</a> the Intel Download Center for <i>I218</i> and filtering for <i>Linux</i> tells the same. And sure enough, the module is loaded.</p>
<p>$ lsmod | grep e1000e
e1000e                226396  0
ptp                    19395  1 e1000e</p>
<p>Many parameters, but none to change the behavior of LEDs. As confirmed by the <a href="https://www.kernel.org/doc/Documentation/networking/e1000e.txt">documentation</a>.</p>
<p>$ modinfo -p e1000e
debug:Debug level (0=none,...,16=all) (int)
copybreak:Maximum size of packet that is copied to a new buffer on receive (uint)
TxIntDelay:Transmit Interrupt Delay (array of int)
TxAbsIntDelay:Transmit Absolute Interrupt Delay (array of int)
RxIntDelay:Receive Interrupt Delay (array of int)
RxAbsIntDelay:Receive Absolute Interrupt Delay (array of int)
InterruptThrottleRate:Interrupt Throttling Rate (array of int)
IntMode:Interrupt Mode (array of int)
SmartPowerDownEnable:Enable PHY smart power down (array of int)
KumeranLockLoss:Enable Kumeran lock loss workaround (array of int)
WriteProtectNVM:Write-protect NVM [WARNING: disabling this can lead to corrupted NVM] (array of int)
CrcStripping:Enable CRC Stripping, disable if your BMC needs the CRC (array of int)</p>
<p>It turns out such a parameter was <a href="https://sourceforge.net/p/e1000/feature-requests/2/">requested</a> years ago, but denied by Intel with the following explanation.</p>
<p><span></span><span>I'm sorry, but this feature request was evaluated and denied because the majority of our customers require the LEDs to function as-is, and module parameters of this type are unacceptable.</span><span></span></p>
<p>So I downloaded the kernel model <a href="https://downloadcenter.intel.com/download/15817">source</a>, hoping to modify it, and eventually noticed a promising function.</p>
<p>
static s32 e1000_led_off_pchlan(struct e1000_hw *hw)
{
    u16 data = (u16)hw-&gt;mac.ledctl_mode1;
    u32 i, led;

    
    if (!(er32(STATUS) &amp; E1000_STATUS_LU)) {
        for (i = 0; i &lt; 3; i++) {
            led = (data &gt;&gt; (i * 5)) &amp; E1000_PHY_LED0_MASK; 
            if ((led &amp; E1000_PHY_LED0_MODE_MASK) !=
                E1000_LEDCTL_MODE_LINK_UP)
                continue;
            if (led &amp; E1000_PHY_LED0_IVRT)
                data &amp;= ~(E1000_PHY_LED0_IVRT &lt;&lt; (i * 5));
            else
                data |= (E1000_PHY_LED0_IVRT &lt;&lt; (i * 5));
        }
    }

    return e1e_wphy(hw, HV_LED_CONFIG, data);
}</p><p>Perhaps more complex than you'd expect such a simple task to be. Many constants and bit operations. Lots more in related functions. I figured this must be documented, presumably in the <a href="http://www.intel.com/content/dam/www/public/us/en/documents/datasheets/i218-ethernet-connection-datasheet.pdf">datasheet</a>. Browsing it cut my plans to modify the kernel module short, as it spells out a better alternative: NVM (Non-Volatile Memory).</p>
<p><span></span><span>The PHY has three LED outputs that can be configured via the NVM. The default values for the PHY (based on the LED NVM word 0x18 of the LAN region) are listed in the table below.</span><span></span></p>
<picture>
<source type="image/webp" media="(min-resolution:2dppx)" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/182.x2.webp?201707100332 2x">
<img src="https://storage.googleapis.com/cdn.pwmon.org/1900/182.x1.png?201706071857" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/182.x2.png?201706071857 2x">
</picture>
<p>If you're wondering why the table mentions 3 LEDs when the LAN port only has 2: the second LED is bi-colored and can switch state to either green (LED2) or amber (LED1).</p>
<p>As a closing note on the kernel module: the code does not do what it appears to. Its only purpose is to provide an interface for blinking a single LED on request, in order to identify a NIC or LAN port. It's unrelated to LEDs blinking on network activity or otherwise, which is done in hardware.</p>
<h2>NVM</h2>
<p>Writeable flash memory, which holds configuration, like the MAC address or power management settings, detailed in the table below. The LED configuration is stored in the previously mentioned word <span>0x18</span>.</p>
<picture>
<source type="image/webp" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/143+144.x1.webp?201707100332, https://storage.googleapis.com/cdn.pwmon.org/1900/143+144.x2.webp?201707100332 2x">
<img src="https://storage.googleapis.com/cdn.pwmon.org/1900/143+144.x1.png?201706071857" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/143+144.x2.png?201706071857 2x">
</picture>
<p>A minor detour first to explain the term <i>word</i>. It refers to a 2-byte (16-bit) value in little-endian order, meaning in reverse byte order. So value <span>0x1c10</span> is written <span>0x101c</span> to NVM. Very simple to do manually, by just swapping bytes, but can be done programmatically too. (These will be useful later.)</p>
<p>
def swap(value):
    return hex(value &gt;&gt; 8 | (value &amp; 0xFF) &lt;&lt; 8)

&gt;&gt;&gt; swap(0x1c10)
'0x101c'</p>
<p>
function swap(value) {
    return '0x' + ((value &gt;&gt; 8 | (value &amp; 0xFF) &lt;&lt; 8)).toString(16);
};

&gt; swap(0x1c10)
"0x101c"</p>
<p>Word <span>0x18</span> is encoded as follows.</p>
<picture>
<source type="image/webp" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/149.x1.webp?201707100332, https://storage.googleapis.com/cdn.pwmon.org/1900/149.x2.webp?201707100332 2x">
<img src="https://storage.googleapis.com/cdn.pwmon.org/1900/149.x1.png?201706071857" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/149.x2.png?201706071857 2x">
</picture>
<p>It's a bit sequence with 5 bits each per LED. The first 3 bits on each LED set the mode, detailed in the second table. The remaining 2 bits invert and blink the LED. Below is a visual explanation on how to read this, using the default values.</p>
<p><img src="https://storage.googleapis.com/cdn.pwmon.org/1900/f418.x1.png?201706071858" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/f418.x2.png?201706071858 2x"></p><p>Such a sequence can be used directly with the <span>swap</span> function defined earlier, with <span>0b</span> prefix to indicate bits.</p>
<p>&gt; swap(0b0001100011110100)
"0xf418"</p>
<p>Now to construct a bit sequence to turn LEDs off permanently. As you notice, there is no mode to just flat disable an LED. It's still possible to get effectively the same result. There are two solutions.</p>
<p><span>1</span><span>Set the mode of each LED to <span>010</span>, so LEDs are on on any connection, and set the invert bit on each LED. Ergo, LEDs are off on any connection. With a minor side effect: in case of no connection, LEDs are on. (When the network cable is pulled, or when the opposite side is off.)</span></p>
<picture>
<source type="image/webp" media="(min-resolution:2dppx)" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/4a29.x2.webp?201707100332 2x">
<img src="https://storage.googleapis.com/cdn.pwmon.org/1900/4a29.x1.png?201706071858" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/4a29.x2.png?201706071858 2x">
</picture>
<p>&gt; swap(0b0010100101001010)
"0x4a29"</p>
<p><span>2</span><span>Set the mode of each LED to <span>101</span>, so LEDs are on <b>only</b> on a 10Mbps connection. Ergo, LEDs are off for either a 100Mbps or 1Gbps connection. Without side effect, as LEDs stay off in case of no connection.</span></p>
<picture>
<source type="image/webp" media="(min-resolution:2dppx)" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/a514.x2.webp?201707100333 2x">
<img src="https://storage.googleapis.com/cdn.pwmon.org/1900/a514.x1.png?201706071858" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/a514.x2.png?201706071858 2x">
</picture>
<p>&gt; swap(0b0001010010100101)
"0xa514"</p>
<p>There are two additional variants to the second solution, which exclude the other link speed combinations each. I'll leave constructing the bit sequence for both as an exercise to the reader. Of both solutions I prefer the second due to lack of side effect when a link speed can be excluded. Usually either 10Mbps or 1Gbps definitely can be. A way to get the negotiated link speed is to use <i>dmesg</i>.</p>
<p>$ dmesg -t | grep e1000e
...
e1000e: eth0 NIC Link is Up 100 Mbps Full Duplex, Flow Control: Rx/Tx</p>
<p>So <span>0xa514</span> it is. Ready to write to NVM. The datasheet tells how.</p>
<p><span></span><span>Intel has an MS-DOS* software utility called EEupdate that is used to program the SPI Flash images in development or production line environments. A copy of this program can be obtained through your Intel Field Service representative.</span><span></span></p>
<p>That's no good. <i>EEupdate</i> is not publicly available. A bit of research reveals another Intel tool named <i>LANConf</i>, available for DOS, Linux, and Windows, which can also write to NVM, but can only be obtained by applying for a <a href="https://www-ssl.intel.com/content/www/us/en/my-intel/design-center-privileged-access-required.html">privileged account</a> and signing a Non-Disclosure Agreement. Fortunately, <i><a href="https://www.kernel.org/pub/software/network/ethtool/">ethtool</a></i> can handle NVM too.</p>
<p>To read from NVM, use as follows. (EEPROM and NVM are used interchangeably from here on.)</p>
<p>% ethtool -e|--eeprom-dump devname [raw on|off] [offset N] [length N]</p>
<p>As per the NVM Address Map, word <span>0x18</span> is at NVM byte offset <span>0x30</span>.</p>
<p>$ sudo ethtool -e eth0 offset 0x30 length 2
Offset      Values
------      ------
0x0030:     f4 18</p>
<p>It matches the default value constructed earlier. Now to the important part: writing to NVM.</p>
<p>% ethtool -E|--change-eeprom devname [magic N] [offset N] [length N] [value N]</p>
<p>So <i>offset</i>, <i>length</i>, and <i>value</i> are obvious, but what does <i>magic</i> refer to? The manual knows.</p>
<p><span></span><span>Because of the persistent nature of writing to the EEPROM, a device-specific magic key must be specified to prevent the accidental writing to the EEPROM.</span><span></span></p>
<p>Where the device-specific magic key can be obtained from isn't documented anywhere. It appears to be kept somewhat secret on purpose. Only the file <i>ethtool.c</i> in the kernel module source code explains it.</p>
<p>eeprom-&gt;magic = adapter-&gt;pdev-&gt;vendor | (adapter-&gt;pdev-&gt;device &lt;&lt; 16);</p>
<p>Here <i>vendor</i> and <i>device</i> refer to <a href="https://pcisig.com/membership">PCI IDs</a>. There are numerous ways to get them, with the easiest perhaps being <i>lspci</i>.</p>
<p>$ lspci -nnq | grep Ethernet
00:19.0 Ethernet controller [0200]: Intel Corporation Ethernet Connection I218-V [<b>8086</b>:<b>1559</b>] (rev 04)</p>
<p>The bold numbers are the <i>vendor</i> and <i>device</i> ID respectively, in hex. So this should give the magic key.</p>
<p>
&gt; '0x' + (0x8086 | (0x1559 &lt;&lt; 16)).toString(16)
"0x15598086"</p>
<p>Very simple. Alright, commence writing.</p>
<p>$ sudo ethtool -E eth0 magic 0x15598086 offset 0x30 length 2 value 0xa514
ethtool: bad command line argument(s)</p>
<p>The value of <i>value</i> can only be a single byte. The <i>length</i> parameter repeats that byte. (This isn't documented.) Both bytes must hence be written separately. </p>
<p>$ sudo ethtool -E eth0 magic 0x15598086 offset 0x30 value 0xa5
Cannot set EEPROM data: Invalid argument</p>
<p>This rather non-descriptive error took me quite a while to figure out. The <i>e1000e</i> kernel module included with the default kernel of Ubuntu 14.04.2 does not support writing to NVM, in this case at least. Intel has <a href="http://www.intel.com/content/www/us/en/support/network-and-i-o/ethernet-products/000005480.html">instructions</a> for compiling and installing the latest kernel module from source. Now it should work.</p>
<p>$ sudo ethtool -E eth0 magic 0x15598086 offset 0x30 value 0xa5
$ sudo ethtool -E eth0 magic 0x15598086 offset 0x31 value 0x14</p>
<p>And it does. Note: the LEDs remain unchanged until either the NUC is reset or the kernel module is reloaded.</p>
<h2>Windows / Mac</h2>
<p>I have not verified, but modifying NVM should also work for other OSes, unless the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pwmon.org/p/1900/quest-disable-lan-leds-intel-nuc/">https://pwmon.org/p/1900/quest-disable-lan-leds-intel-nuc/</a></em></p>]]>
            </description>
            <link>https://pwmon.org/p/1900/quest-disable-lan-leds-intel-nuc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25194316</guid>
            <pubDate>Tue, 24 Nov 2020 01:44:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quantization for Neural Networks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25194218">thread link</a>) | @keyboardman
<br/>
November 23, 2020 | https://leimao.github.io/article/Neural-Networks-Quantization/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/article/Neural-Networks-Quantization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Quantization refers to techniques for performing computations and storing tensors at lower bitwidths than floating point precision. A quantized model executes some or all of the operations on tensors with integers rather than floating point values. This allows for a more compact model representation and the use of high performance vectorized operations on many hardware platforms. This technique is in particular useful at the inference time since it saves a lot of inference computation cost without sacrificing too much inference accuracies.</p>



<p>So far, major deep learning frameworks, such as TensorFlow and PyTorch, have supported quantization natively. The users have been using the built-in quantization modules successfully without knowing how it works exactly. In this article, I would like to elucidate the mathematics of quantization for neural networks so that the developers would have some ideas about the quantization mechanisms.</p>

<h3 id="quantization">Quantization</h3>

<h4 id="quantization-mapping">Quantization Mapping</h4>

<p>Quantization maps a floating point value $x \in [\alpha, \beta]$ to a $b$-bit integer $x_q \in [\alpha_q, \beta_q]$.</p>



<p>Mathematically, the de-quantization process is defined as</p><p>

\[x = c (x_q + d)\]

</p><p>and the quantization process is defined as</p><p>

\[x_q = \text{round}\big(\frac{1}{c} x - d\big)\]

</p><p>where $c$ and $d$ are variables.</p>



<p>In order to derive $c$ and $d$, we have to make sure that $\alpha$ maps to $\alpha_q$ and $\beta$ maps to $\beta_q$. So we would just have to solve the linear system</p><p>

\[\begin{align}
\beta &amp;= c (\beta_q + d) \\
\alpha &amp;= c (\alpha_q + d) \\
\end{align}\]

</p><p>The solutions is</p><p>

\[\begin{align}
c &amp;= \frac{\beta - \alpha}{\beta_q - \alpha_q} \\
d &amp;= \frac{\alpha \beta_q - \beta \alpha_q}{\beta - \alpha} \\
\end{align}\]

</p><p>In practice, we would have to ensure that $0$ in floating point is represented exactly with no error after quantization.</p>



<p>Mathematically, we need to ensure</p><p>

\[\begin{align}
x_q &amp;= \text{round}\big(\frac{1}{c} 0 - d\big) \\
&amp;= \text{round}(- d) \\
&amp;= - \text{round}(d) \\
&amp;= - d \\
\end{align}\]

</p><p>This means that</p><p>

\[\begin{align}
d &amp;= \text{round}(d) \\
&amp;= \text{round}\big(\frac{\alpha \beta_q - \beta \alpha_q}{\beta - \alpha}\big) \\
\end{align}\]

</p><p>By convention, we denote $c$ as the scale $s$ and $-d$ as the zero point $z$.</p>



<p>To summarize, the de-quantization process is defined as</p><p>

\[x = s (x_q - z)\]

</p><p>and the quantization process is defined as</p><p>

\[x_q = \text{round}\big(\frac{1}{s} x + z\big)\]

</p><p>The value of scale $s$ and zero point $z$ are</p><p>

\[\begin{align}
s &amp;= \frac{\beta - \alpha}{\beta_q - \alpha_q} \\
z &amp;= \text{round}\big(\frac{\beta \alpha_q - \alpha \beta_q}{\beta - \alpha}\big) \\
\end{align}\]

</p><p>Note that $z$ is an integer and $s$ is a <em>positive</em> floating point number.</p>

<h4 id="value-clipping">Value Clipping</h4>

<p>In practice, the quantization process will have chance to have $x$ that is outside the range of $[\alpha, \beta]$, thus the quantized value $x_q$ will also be outside the range of $[\alpha_q, \beta_q]$. If the integer type is signed <code>INTb</code> and $(\alpha_q, \beta_q) = (-2^{b-1}, 2^{b-1}-1)$, or unsigned <code>UINTb</code> and $(\alpha_q, \beta_q) = (0, 2^{b}-1)$, programming languages that have fixed type-precisions will clip the values that are outside the range.</p>



<p>More concretely, the quantization process will have an additional clip step.</p><p>

\[x_q = \text{clip}\Big( \text{round}\big(\frac{1}{s} x + z\big), \alpha_q, \beta_q \Big)\]

</p><p>where $\text{clip}(x, l, u)$ function is defined as</p><p>

\[\begin{align}
\text{clip}(x, l, u) &amp;= 
    \begin{cases}
      l &amp; \text{if $x &lt; l$}\\
      x &amp; \text{if $l \leq x \leq u$}\\
      u &amp; \text{if $x &gt; u$}\\
    \end{cases} 
\end{align}\]

</p><h4 id="affine-quantization-mapping">Affine Quantization Mapping</h4>

<p>The quantization mapping we discussed above is also called affine quantization mapping.</p>

<h4 id="scale-quantization-mapping">Scale Quantization Mapping</h4>

<p>If the integer type is signed <code>INTb</code>, $(\alpha_q, \beta_q) = (-2^{b-1} + 1, 2^{b-1}-1)$ and we force $z = 0$.</p>



<p>Mathematically, we have</p><p>

\[\begin{gather}
\alpha_q = -\beta_q \\
\text{round}\big(\frac{\beta \alpha_q - \alpha \beta_q}{\beta - \alpha}\big) = 0 \\
\end{gather}\]

</p><p>This results in $\alpha = -\beta$. Therefore, we are mapping between the floating point range $[\alpha, -\alpha]$ and the integer range $[\alpha_q, -\alpha_q]$. Because it is exactly symmetric around $0$, we also call it symmetric quantization mapping.</p>



<p>Note that scale quantization mapping is just a special case of the affine quantization mapping, and we have an unused bit in the integer range.</p>

<h4 id="summary">Summary</h4>

<p>The quantization function is defined as</p><p>

\[f_q(x, s, z) = \text{clip}\Big( \text{round}\big(\frac{1}{s} x + z\big), \alpha_q, \beta_q \Big)\]

</p><p>and the de-quantization function is defined as</p><p>

\[f_d(x_q, s, z) = s (x_q - z)\]

</p><h3 id="quantized-matrix-multiplication">Quantized Matrix Multiplication</h3>

<h4 id="quantized-matrix-multiplication-mathematics">Quantized Matrix Multiplication Mathematics</h4>

<p>Suppose we have to perform the matrix multiplication $Y = XW + b$, where $X \in \mathbb{R}^{m \times p}$, $W \in \mathbb{R}^{p \times n}$, and $b \in \mathbb{R}^{n}$ resulting in $Y \in \mathbb{R}^{m \times n}$.</p><p>

\[\begin{align}
Y_{i, j} = b_j + \sum_{k=1}^{p} X_{i,k} W_{k,j}
\end{align}\]

</p><p>We would need to do $p$ floating number multiplications and $p$ floating number additions to compute one single entry in $Y$. To complete the full matrix multiplication, given there are $mn$ entries in $Y$, we would need to do $mpn$ floating number multiplications and $mpn$ floating number additions.</p>



<p>Depending on the floating number precision, such the speed of such floating point matrix multiplication might not be favored. So the question becomes can we complete the same matrix multiplication using quantized values.</p>



<p>Here we apply the de-quantization equation.</p><p>

\[\begin{align}
Y_{i, j} &amp;= b_j + \sum_{k=1}^{p} X_{i,k} W_{k,j} \\
&amp;= s_b (b_{q, j} - z_b) + \sum_{k=1}^{p} s_X(X_{q,i,k} - z_X) s_W(W_{q, k,j} - z_W)\\
&amp;= s_b (b_{q, j} - z_b) + s_X s_W \sum_{k=1}^{p} (X_{q,i,k} - z_X) (W_{q, k,j} - z_W)\\
&amp;= s_b (b_{q, j} - z_b) + s_X s_W \Bigg[ \bigg( \sum_{k=1}^{p} X_{q,i,k} W_{q, k,j} \bigg) - \bigg( z_W \sum_{k=1}^{p} X_{q,i,k} \bigg) - \bigg( z_X \sum_{k=1}^{p} W_{q, k,j} \bigg) + p z_X z_W\Bigg]\\
&amp;= s_Y(Y_{q,i,j} - z_Y)\\
\end{align}\]

</p><p>where $X_q$, $W_q$, $b_q$ and $Y_q$ are the quantized matrix for $X$, $W$, $b$ and $Y$, respectively, $s_X$, $s_W$, $s_b$, and $s_Y$ are the scales for $X$, $W$, $b$ and $Y$, respectively, and $z_X$, $z_W$, $z_b$ and $z_Y$ are the zero points for $X$, $W$, $b$ and $Y$, respectively.</p>



<p>Therefore,</p><p>

\[Y_{q,i,j} = z_Y + \frac{s_b}{s_Y} (b_{q, j} - z_b) + \frac{s_X s_W}{s_Y} \Bigg[ \bigg( \sum_{k=1}^{p} X_{q,i,k} W_{q, k,j} \bigg) - \bigg( z_W \sum_{k=1}^{p} X_{q,i,k} \bigg) - \bigg( z_X \sum_{k=1}^{p} W_{q, k,j} \bigg) + p z_X z_W\Bigg]\]

</p><p>Note that in the above equation the following terms are constants during inference and therefore could be computed offline before inference.</p>

<ul>
  <li>$z_Y$</li>
  <li>$\frac{s_b}{s_Y} (b_{q, j} - z_b)$</li>
  <li>$z_X \sum_{k=1}^{p} W_{q, k,j}$</li>
  <li>$p z_X z_W$</li>
</ul>

<p>Term $\sum_{k=1}^{p} X_{q,i,k} W_{q, k,j}$ suggests that we could just do the integer matrix multiplication for $X_q$ and $W_q$. Such integer matrix multiplication could employ special hardware and algorithms, such as <a href="https://www.nvidia.com/en-us/data-center/tensor-cores/">NVIDIA Tensor Core</a> and <a href="https://docs.nvidia.com/cuda/ampere-tuning-guide/index.html#tensor-operations">Tensor Core IMMA operations</a>, and runs much faster than conventional integer matrix multiplication.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/article/2020-11-01-Neural-Networks-Quantization/tensor-core.png">
    <figcaption>NVIDIA Tensor Core Operations</figcaption>
</figure>
</div>

<p>One additional thing to note is that $s_X$, $s_W$, $s_Y$, $z_X$, $z_W$, and $z_Y$ are floating point and integer constants, instead of variables. So there could be some special compile-time optimizations for those multiplications.</p>



<p>This could be retrieved from the resulting integer matrix from $X_q$ and $W_q$ multiplication, which is much faster than the floating number matrix multiplication for the same sizes.</p>



<p>The significance of such quantized matrix multiplication is that the product integer matrix could be converted back to floating point matrix using the scale and the zero point of the product integer matrix and it is almost numerically equivalent. If we have to do a sequence of matrix multiplications whose inputs and outputs are floating point numbers, for example</p><p>

\[\begin{align}
X_1 &amp;= X_0 W_0 + b_0\\
X_2 &amp;= X_1 W_1 + b_1\\
&amp;\vdots \\
X_n &amp;= X_n W_n + b_n\\
\end{align}\]

</p><p>We could convert the math to the followings using quantized matrices.</p><p>

\[\begin{align}
X_{0, q} &amp;= f_q(X_0, s_{X_0}, z_{X_0})\\
X_{1, q} &amp;= f_m(X_{0, q}, W_{0, q}, b_{0, q}, s_{X_0}, z_{X_0}, s_{W_0}, z_{W_0}, s_{b_0}, z_{b_0}, s_{X_1}, z_{X_1}) \\
X_{2, q} &amp;= f_m(X_{1, q}, W_{1, q}, b_{1, q}, s_{X_1}, z_{X_1}, s_{W_1}, z_{W_1}, s_{b_1}, z_{b_1}, s_{X_2}, z_{X_2}) \\
&amp;\vdots \\
X_{n, q} &amp;= f_m(X_{n-1, q}, W_{n-1, q}, b_{n-1, q}, s_{X_{n-1}}, z_{X_{n-1}}, s_{W_{n-1}}, z_{W_{n-1}}, s_{b_{n-1}}, z_{b_{n-1}}, s_{X_n}, z_{X_n}) \\
X_n &amp;= f_d(X_{n, q}, s_{X_n}, z_{X_n})
\end{align}\]

</p><p>where $f_q$ is the quantization function, $f_m$ is the quantized matrix multiplication function, and $f_d$ is the de-quantization function.</p>

<h4 id="examples">Examples</h4>

<p>In the following example, we simulated the quantization matrix multiplication of $Y = XW + b$ using random matrix $X$, $W$ and $b$.</p>

<div><div><pre><code><span># gemm.py
</span><span>import</span> <span>numpy</span> <span>as</span> <span>np</span>

<span>def</span> <span>quantization</span><span>(</span><span>x</span><span>,</span> <span>s</span><span>,</span> <span>z</span><span>,</span> <span>alpha_q</span><span>,</span> <span>beta_q</span><span>):</span>

    <span>x_q</span> <span>=</span> <span>np</span><span>.</span><span>round</span><span>(</span><span>1</span> <span>/</span> <span>s</span> <span>*</span> <span>x</span> <span>+</span> <span>z</span><span>,</span> <span>decimals</span><span>=</span><span>0</span><span>)</span>
    <span>x_q</span> <span>=</span> <span>np</span><span>.</span><span>clip</span><span>(</span><span>x_q</span><span>,</span> <span>a_min</span><span>=</span><span>alpha_q</span><span>,</span> <span>a_max</span><span>=</span><span>beta_q</span><span>)</span>

    <span>return</span> <span>x_q</span>

<span>def</span> <span>quantization_int8</span><span>(</span><span>x</span><span>,</span> <span>s</span><span>,</span> <span>z</span><span>):</span>

    <span>x_q</span> <span>=</span> <span>quantization</span><span>(</span><span>x</span><span>,</span> <span>s</span><span>,</span> <span>z</span><span>,</span> <span>alpha_q</span><span>=-</span><span>128</span><span>,</span> <span>beta_q</span><span>=</span><span>127</span><span>)</span>
    <span>x_q</span> <span>=</span> <span>x_q</span><span>.</span><span>astype</span><span>(</span><span>np</span><span>.</span><span>int8</span><span>)</span>

    <span>return</span> <span>x_q</span>

<span>def</span> <span>dequantization</span><span>(</span><span>x_q</span><span>,</span> <span>s</span><span>,</span> <span>z</span><span>):</span>

    <span>x</span> <span>=</span> <span>s</span> <span>*</span> <span>(</span><span>x_q</span> <span>-</span> <span>z</span><span>)</span>
    <span>x</span> <span>=</span> <span>x</span><span>.</span><span>astype</span><span>(</span><span>np</span><span>.</span><span>float32</span><span>)</span>

    <span>return</span> <span>x</span>

<span>def</span> <span>generate_quantization_constants</span><span>(</span><span>alpha</span><span>,</span> <span>beta</span><span>,</span> <span>alpha_q</span><span>,</span> <span>beta_q</span><span>):</span>

    <span># Affine quantization mapping
</span>    <span>s</span> <span>=</span> <span>(</span><span>beta</span> <span>-</span> <span>alpha</span><span>)</span> <span>/</span> <span>(</span><span>beta_q</span> <span>-</span> <span>alpha_q</span><span>)</span>
    <span>z</span> <span>=</span> <span>int</span><span>((</span><span>beta</span> <span>*</span> <span>alpha_q</span> <span>-</span> <span>alpha</span> <span>*</span> <span>beta_q</span><span>)</span> <span>/</span> <span>(</span><span>beta</span> <span>-</span> <span>alpha</span><span>))</span>

    <span>return</span> <span>s</span><span>,</span> <span>z</span>

<span>def</span> <span>generate_quantization_int8_constants</span><span>(</span><span>alpha</span><span>,</span> <span>beta</span><span>):</span>

    <span>b</span> <span>=</span> <span>8</span>
    <span>alpha_q</span> <span>=</span> <span>-</span><span>2</span> <span>**</span> <span>(</span><span>b</span><span>-</span><span>1</span><span>)</span>
    <span>beta_q</span> <span>=</span> <span>2</span> <span>**</span> <span>(</span><span>b</span><span>-</span><span>1</span><span>)</span> <span>-</span> <span>1</span>

    <span>s</span><span>,</span> <span>z</span> <span>=</span> <span>generate_quantization_constants</span><span>(</span><span>alpha</span><span>=</span><span>alpha</span><span>,</span> <span>beta</span><span>=</span><span>beta</span><span>,</span> <span>alpha_q</span><span>=</span><span>alpha_q</span><span>,</span> <span>beta_q</span><span>=</span><span>beta_q</span><span>)</span>

    <span>return</span> <span>s</span><span>,</span> <span>z</span>

<span>def</span> <span>quantization_matrix_multiplication_int8</span><span>(</span><span>X_q</span><span>,</span> <span>W_q</span><span>,</span> <span>b_q</span><span>,</span> <span>s_X</span><span>,</span> <span>z_…</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/article/Neural-Networks-Quantization/">https://leimao.github.io/article/Neural-Networks-Quantization/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/article/Neural-Networks-Quantization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25194218</guid>
            <pubDate>Tue, 24 Nov 2020 01:30:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A fully public domain, highly portable first person shooter running on 32kb RAM]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25193953">thread link</a>) | @ClawsOnPaws
<br/>
November 23, 2020 | https://drummyfish.gitlab.io/anarch/ | <a href="https://web.archive.org/web/*/https://drummyfish.gitlab.io/anarch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <a href="https://drummyfish.gitlab.io/anarch"><img src="https://drummyfish.gitlab.io/anarch/media/logo_big.png" alt="logo"></a>

    <span><i>suckless, anticapitalist, public domain game for everyone</i></span>

    

    <span><a href="https://drummyfish.itch.io/anarch">itch.io</a></span>

    <dl>
      <dt> <a href="https://forum.freegamedev.net/viewtopic.php?f=22&amp;t=14771#p95387">Easily the most plain and boring FPS I've ever played.</a> </dt> <dd> Onpon4, libre game developer </dd>
      <dt> <a href="https://talk.pokitto.com/t/anarch-doom-clone-fps/2008/70">Technically the most impressive game on Pokito yet.</a> </dt> <dd> Jonne, the creator of Pokitto </dd>
      <dt> <a href="https://archive.li/tFWrL#84%">Kill yourself.</a> </dt> <dd> Anonymous on 4chan </dd>
    </dl>

    <span>THIS IS SPECIAL</span>

    <ul>
      <li>needs only <b>200 KB</b>, <b>32 KB RAM</b>, <b>40 MHz CPU</b>!</li>
      <li><b>suckless</b>, pure C, <b>no dependencies</b>, no FPU, GPU or file I/O needed</li>
      <li>10 levels, 6 weapons, 7 enemy types, 3 ammo types</li>
      <li>varying floor/ceiling oldschool SW ray casting engine with mouse support</li>
      <li><b>100% public domain</b> CC0 free software and culture</li>
      <li>100% original work, no third party assets</li>
      <li>well documented, hackable, <b>extremely portable</b></li>
      <li>completely <b>gratis</b>, without ads, DRM or similar bullshit</li>
    </ul>

    <p>
      This isn't a 90s style retro shooter, this <b>is</b> a 90s shooter.
    </p>

    <p>
      This game runs everywhere and adheres to great <a href="https://suckless.org/">simplicity</a>.
      It is much more efficient and portable than Doom and has completely
      <b>no dependencies</b>. Not even floating point is used, in case your
      computer doesn't have the HW unit. The game can fit into <b>200 KB</b>
      (including assets!) and can run with just <b>32 KB RAM</b>. No build system,
      library, internet connection or package manager is inherently required for
      compilation as the whole game is written in pure C language.
    </p>

    <p>
      This is an experiment and art that categorically rejects capitalist
      technology.
    </p>
 
   <img src="https://drummyfish.gitlab.io/anarch/media/3screens.png" alt="screenshots">

    <span>MORE THAN A GAME</span>

    <p>
      This is not a mere entertainment or toy meant for killing time or pursuing
      low goals such as making profit or something to put on portfolio, this is
      much more. Anarch is completely <b>gratis and free as in freedom</b> and
      besides entertainment can also be used for education, research, hacking, media
      creation, as a benchmark, as a test, as an environment, as an engine, as
      a basis for something greater. You are not limited by anything, there are
      no conditions to agree to. Nothing is hidden, everything is allowed, no
      burdens are imposed. The best motivation for creating anything is only
      the <b>pure love of creation for its own sake</b>, unburdened by any other
      goal than creating something truly useful. 
    </p>

    <img src="https://upload.wikimedia.org/wikipedia/commons/8/83/Anarch_Devices.jpg" alt="screenshots">

    <span>NO ONE OWNS THIS</span>

    <p>
      Not even I, the creator, own any part of this game.
      I&nbsp;have purposefully created everything myself from scratch,
      including the engine, graphics, sounds, music, even the font and palette,
      so that I could eventually give up all my rights and
      dedicate this game fully and <b>completely to the public domain</b>,
      to you, my dear fellow human being. No one should be allowed to own
      information and art.
    </p>

    <p>
      I've done my best to ensure this is 100% free as in freedom software and
      culture, well understandable and documented. This isn't made for any
      profit. This is made out of <b>love</b>, for you and for the greater good.
    </p>

    <h2>Download</h2>

    <ul>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_linux64_sdl_elf_1-0?inline=false">GNU/Linux SDL</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_LQ_linux64_sdl_elf_1-0?inline=false">GNU/Linux SDL LQ</a></li>
      <li><a href="https://drummyfish.gitlab.io/anarch/bin/web/anarch.html">play in browser</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_pokitto_1-0.pop?inline=false">Pokitto</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_gbmeta_1-0.zip?inline=false">GB Meta</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_winshitxp_sdl_1-0.zip?inline=false">M$ Win$hit XP SDL</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/archive/master/anarch-master.zip">source code</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/tree/master/bin">more downloads</a></li>
    </ul>

    <h2>Explore</h2>

    <ul>
      <li><a href="https://gitlab.com/drummyfish/sucklessfps">source code</a></li>
      <li><a href="https://www.tastyfish.cz/">author's website</a></li>
      <li><a href="https://libregamewiki.org/Anarch">libre game wiki</a></li>
      <li><a href="">OGA assets</a></li>
    </ul>

    <h2><a href="https://gitlab.com/drummyfish/anarch#faq">FAQ in readme</a></h2>

    

  

</div>]]>
            </description>
            <link>https://drummyfish.gitlab.io/anarch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25193953</guid>
            <pubDate>Tue, 24 Nov 2020 00:56:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top Resources for Product Managers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25193345">thread link</a>) | @enigmatic02
<br/>
November 23, 2020 | https://www.sachinrekhi.com/top-resources-for-product-managers | <a href="https://web.archive.org/web/*/https://www.sachinrekhi.com/top-resources-for-product-managers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.sachinrekhi.com/top-resources-for-product-managers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25193345</guid>
            <pubDate>Mon, 23 Nov 2020 23:45:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cheat sheet for using Go everywhere you might use JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25193112">thread link</a>) | @azhenley
<br/>
November 23, 2020 | http://alltom.com/pages/goweb/ | <a href="https://web.archive.org/web/*/http://alltom.com/pages/goweb/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header>
  <a href="http://alltom.com/">← <span>alltom.com</span></a>
</header>







<p>I haven't written straight JavaScript in years. I use <a href="https://golang.org/">Go</a> for everything, including DOM manipulation, integrating with audio libraries and TensorFlow models, and using graphics libraries like <a href="https://threejs.org/">Three.js</a>.

</p><p>This page explains how.

</p><h2>Pros and Cons of Go for web programming</h2>

<p>The good: Go is a great glue language, and most web programming is gluing things together. Even though Go doesn't have a complicated type system, most code I write works the first time. Go compiles to every architecture and platform that I've ever cared about, including web browsers, so I can usually reuse my packages regardless of where the code runs.

</p><p>On the other hand, the syscall/js syntax is annoyingly verbose, particularly when it comes to callbacks, and particularly when those callbacks are used with Promises. I mitigate these issues by isolating usage of syscall/js in shared packages, <a href="https://research.swtch.com/deps#abstract_the_dependency">as you might for any other dependency</a>.

</p><p>The <em>motivation</em> for me to write this article is that I feel very productive writing web sites with Go and I want to share that secret superpower with you. However, the <em>point</em> of writing this article is to make writing Go on the web easy by showing you the hard parts up front. Since I try to illustrate every roadblock with as little code as possible, it might look like Go web development is all roadblocks, but that's not true. Please don't be discouraged! It gets easier as your code base scales.

</p><h2>Scaffolding</h2>



<p>There's one entry point for the server, and one for the code that runs in the browser. It just takes these four files to get off the ground:

</p><ul>
<li>project/server/main.go
</li><li>project/server/public/index.html
</li><li>project/browser/main.go
</li><li>project/browser/generate.go (only needed for convenience)
</li></ul>

<p>Inititalize the project by running <tt>go mod init yourproject</tt> in the project/ directory. <a href="https://blog.golang.org/using-go-modules">This is good Go hygeine these days</a>; it creates a file in your project directory that tracks version numbers and hashes of all your dependencies.

</p><hr>

<h3>project/server/main.go</h3>



<p>Until you add more server-side features, project/server/main.go just serves the static files in the public/ directory:

</p><pre><code>package main

import (
	"flag"
	"net/http"
)

var httpAddress = flag.String("http_address", "localhost:8080", "Address for serving HTTP")

func main() {
	http.Handle("/", http.FileServer(http.Dir("public")))
	http.ListenAndServe(*httpAddress, nil)
}
</code></pre>

<hr>

<h3>project/server/public/index.html</h3>



<p>index.html just needs to invoke the compiled Go code:

</p><pre><code>&lt;!doctype html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;meta charset="utf-8"&gt;
&lt;title&gt;yourproject&lt;/title&gt;

&lt;script src="wasm_exec.js"&gt;&lt;/script&gt;
&lt;script&gt;
if (!WebAssembly.instantiateStreaming) {
	// Polyfill, required for Safari.
	WebAssembly.instantiateStreaming = async (resp, importObject) =&gt; {
		const source = await (await resp).arrayBuffer();
		return await WebAssembly.instantiate(source, importObject);
	};
}

const go = new Go();
WebAssembly.instantiateStreaming(fetch("main.wasm"), go.importObject).then((result) =&gt; {
	go.run(result.instance);
});
&lt;/script&gt;
</code></pre>

<p>The section below about generate.go explains where wasm_exec.js and main.wasm come from.

</p><hr>

<h3>project/browser/main.go</h3>

<p>This is the entry-point for the Go code that runs in the browser, including some examples of how to access global JavaScript objects (which is the same for <tt>document.body</tt> and the rest of the DOM):

</p><pre><code>// +build js,wasm

package main

import (
	"syscall/js"
)

func main() {
	js.Global().Get("console").Call("log", "Hello, World!")

	var cb js.Func
	cb = js.FuncOf(func(this js.Value, args []js.Value) interface{} {
		js.Global().Call("alert", "Hello, World!")
		cb.Release()
		return nil
	})
	js.Global().Call("setTimeout", cb, 2000)

	&lt;-(make(chan bool))
}</code></pre>

<p>I told you the syscall/js syntax was awful.

</p><p>I end with <tt>&lt;-(make(chan bool))</tt> because otherwise, the Go program exits, and any DOM callbacks you've registered (click handlers, timers, etc) that call into Go code will fail.

</p><hr>

<h3>project/browser/generate.go</h3>

<p>index.html refers to two files that you don't write by hand: wasm_exec.js ships with Go, and main.wasm is compiled from project/browser/main.go.

</p>

<p>I put <a href="https://blog.golang.org/generate">go:generate</a> directives in generate.go, which allows you to run <tt>go generate</tt> to put both files into the public/ directory:

</p><pre><code>package main

//go:generate cp $GOROOT/misc/wasm/wasm_exec.js ../server/public/
//go:generate env GOOS=js GOARCH=wasm go build -o ../server/public/main.wasm</code></pre>

<hr>

<h3>Development</h3>

<p>Start the server in one terminal:

</p><pre><code>$ cd project/server/
$ go run main.go</code></pre>



<p>Re-compile the code that runs in the browser whenever you make a change:

</p><pre><code>$ cd project/browser/
$ go generate</code></pre>

<p>View your new, fancy web site by visiting <a href="http://localhost:8080/" target="_blank">http://localhost:8080/</a>

</p><h2>Miscellaneous notes</h2>

<h3><tt>foo == null</tt></h3>

<p>When I wrote JavaScript, I avoided having to care about the difference between JavaScript's <tt>null</tt> and <tt>undefined</tt> by always coercing them to the same value with <tt>==</tt>. For example, <tt>foo == null</tt> is true regardless of whether foo is <tt>null</tt> or <tt>undefined</tt>.

</p><p>That option isn't available with Go's <tt>js.Null()</tt> and <tt>js.Undefined()</tt>, so be prepared to care about the difference, or write a helper.

</p><h3>Promises and async functions</h3>

<p>As you saw above, Go functions that are used as JavaScript callbacks are not automatically garbage-collected and have elaborate syntax. That makes Promises and <tt>async</tt> functions hard to deal with.

</p>

<p>So I use this helper to convert Promises to idiomatic Go return values:

</p><pre><code>func UnwrapPromise(promise js.Value) (js.Value, error) {
	retc := make(chan js.Value)
	errc := make(chan error)

	var release func()
	success := js.FuncOf(func(this js.Value, args []js.Value) interface{} {
		retc &lt;- args[0]
		release()
		return nil
	})
	failure := js.FuncOf(func(this js.Value, args []js.Value) interface{} {
		errc &lt;- fmt.Errorf("%v", args[0])
		release()
		return nil
	})
	release = func() {
		success.Release()
		failure.Release()
	}

	promise.Call("then", success).Call("catch", failure)
	select {
	case ret := &lt;-retc:
		return ret, nil
	case err := &lt;-errc:
		return js.Undefined(), err
	}
}</code></pre>






</div>]]>
            </description>
            <link>http://alltom.com/pages/goweb/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25193112</guid>
            <pubDate>Mon, 23 Nov 2020 23:20:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Starting a Startup Starting Now]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25192991">thread link</a>) | @davefreiburger
<br/>
November 23, 2020 | https://gradually.co/what-you-need-to-know-when-you-are-starting-a-startup/ | <a href="https://web.archive.org/web/*/https://gradually.co/what-you-need-to-know-when-you-are-starting-a-startup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

																					<div>
								<p><a href="https://giphy.com/gifs/spongebob-spongebob-squarepants-season-6-3oKHWmGt1743ofhnHi" target="_blank">
									[Image source: Giphy]								</a></p><h5>
									<a href="https://foundersatwork.posthaven.com/startups-the-very-beginning" target="_blank">
										Startups: The Very Beginning									</a>
									 &nbsp;by Jessica Livingston									<br>
								</h5>
								
								<p>
									Takeaways
								</p>
								<div>
									<p><span>Founders and co-founders alike are the foundation of any startup.&nbsp;</span></p>
<p><span>“You can always change the idea you are working on, but it’s much harder to get rid of a cofounder. So you want to choose cofounders very carefully.” — Jessica Livingston</span></p>
<p><span>This person should be someone you know. You’ve already worked with this person. You know they are effective, reliable, and share similar ambitions/moral outlooks as you.&nbsp;</span></p>
<p><span>Jessica suggests that these 3 qualities should make up the founding team as a whole:</span></p>
<ol>
<li><b><i>Determination</i></b><span>: “Startups are really hard and take a really long time. There has to be at least one founder who’s just a tower of strength. Part of being determined is being able to withstand rejection. People will think your idea is lame, customers won’t be interested, investors will say no, reporters won’t care. And they might not be polite about it either. But you can’t let rejection discourage you.” — Jessica Livingston</span></li>
<li><b><i>Domain expertise</i></b><span>: “At least one of the founders should be an expert in what you’re working on” — Jessica Livingston</span></li>
<li><b><i>Ability/willingness to sell</i></b><span>: “Someone has to be the face of the company—to sell the product to customers, and sell the company itself to investors, the press, and potential hires. At least one of you is going to have to sell.” — Jessica Livingston</span></li>
</ol>
<p><span>If you know you want to start a startup one day, but you’re not ready now, start working on smaller projects with friends or potential future co-founders. You’ll be able to filter out who fits the criteria above vs. who doesn’t.&nbsp;</span></p>
<p><span>“A good way to ensure that you make something people want is to make something you yourself want. But remember that making something for yourself is just a heuristic to guide you in finding an idea. In the actual execution, you need to focus on users. You need to understand what they want, and be fanatically dedicated to making them happy. One very important piece of advice we give startups is to ‘do things that don’t scale.’ That means to do so much for your early users that you couldn’t possibly keep doing that much if you were bigger.” — Jessica Livingston</span></p>
<p><span>All in all, Jessica finishes with “if you can make something people want, if you can focus on delighting users, and you measure how much you delight them in revenue, then you can start a startup. That’s the standard to hold yourself to, not the stock character founder you see in the press.”</span></p>
								</div>
								<p><img src="https://gradually.co/wp-content/themes/gradually/img/two-cents.png">
								</p><!-- end half sqaure arrow -->
								<p><b><i>My two cents</i></b><span>: A thing that I’ve somewhat figured out is that there’s no secret playbook for building a company. There are obviously certain things you need to know (that I’m still figuring out), but it seems to essentially boil down to Jessica’s final quote above. </span></p>
								<p>
								<span>Share</span> (if you're an OG)  &nbsp;  <span></span><span><span>
									</span><span>


							</span></span></p></div><!-- end newsletter wrap content -->
													
						</div></div>]]>
            </description>
            <link>https://gradually.co/what-you-need-to-know-when-you-are-starting-a-startup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25192991</guid>
            <pubDate>Mon, 23 Nov 2020 23:06:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Loblaw to launch Canada's first autonomous delivery fleet]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25192900">thread link</a>) | @imheretolearn
<br/>
November 23, 2020 | https://www.bnnbloomberg.ca/loblaw-to-launch-canada-s-first-autonomous-delivery-fleet-in-december-1.1526410 | <a href="https://web.archive.org/web/*/https://www.bnnbloomberg.ca/loblaw-to-launch-canada-s-first-autonomous-delivery-fleet-in-december-1.1526410">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                                    <div>
                                                <p><img alt="Columnist image" src="https://tsnimages.tsn.ca/ImageProvider/AssetImage?seoId=davidgeorgecosh&amp;width=165"></p>
                    </div>
                                <p>Loblaw Companies Ltd. plans to roll out its first autonomous delivery service in January, as Canada's largest retailer explores new ways of shipping goods to customers amid a broad increase in online shopping.&nbsp;</p>

<p>Loblaw partnered with Palo Alto, Calif.-based software startup Gatik AI for the delivery service. Gatik, which also has offices in Toronto, was founded in 2017 and focuses on the "middle mile" of logistics where it hauls goods over short distances for retailers and distributors. The company raised $4.5 million in seed funding in 2018 and counts Walmart Inc. as a customer in the U.S.&nbsp;</p>

<p>Loblaw said the new service includes five Ford Transit 350 box trucks outfitted with Gatik's self-driving system, which will drive on five fixed routes across the Toronto area for seven days a week, 12 hours a day.&nbsp;</p>

<p>The vehicles will provide a contactless delivery solution for transporting goods from Loblawâ€™s automated picking facility to retail locations, the retailer said.</p>

<p>"As more Canadians are turning to online grocery shopping, we need to continue to identify new ways to make our supply chain more efficient," said Lauren Steinberg, senior vice president of Loblaw Digital, in a phone interview. "And 'middle mile' autonomous delivery is a great example of one way we think we can achieve that."</p>

<div>



<section>
	
	<div>
		<!-- Poll Image -->
				    


<p><img title="poll image" height="2250" alt="poll image" width="3000" src="https://www.bnnbloomberg.ca/polopoly_fs/1.1526534.1606144368!/fileimage/httpImage/image.jpg_gen/derivatives/default/grocery-store.jpg"></p><!-- Poll Question -->
		<h4>Are you using grocery delivery services during the pandemic?</h4>
		<!-- Poll selections -->
		
		<!-- Poll results -->
		
		<ul></ul>

		<!-- Poll results button -->
		<!-- Poll result count -->
		<p>Total Results: <span>0</span></p>
		<!-- Sponsor -->
		
	</div>
</section>




				

</div>

<p>While the number of autonomous trucks remains small in the U.S. and Canada, they have the potential to radically disrupt how merchandise is moved. A 2018 report by McKinsey &amp; Co. found that if trucking companies shifted entirely to autonomous vehicles, it would help cut operating costs by 45 per cent, saving the industry as much as US$125 billion a year.</p>

<p>Loblaw said earlier this month its e-commerce sales climbed 175 per cent in the third quarter, driven by shoppers turning to online shopping to avoid physical bricks-and-mortar stores during the pandemic.&nbsp;</p>

<p>To abide by Canadian regulations, all of Loblaw's self-driving trucks will have a safety driver as a co-pilot. It marks the first autonomous delivery fleet in commercial operation in Canada, according to Gatik.</p>

<p>Steinberg said Loblaw began talks with Gatik for about a year before launching the service, which is expected to handle about 1,000 orders a day. The pilot program will operate for two years, after which Loblaw will determine whether it will expand the service.</p>

<p>"To move these orders autonomously helps us get them there faster, more frequently, and keep up with the increase in demand that we're seeing in the online grocery space generally," Steinberg said.</p>

<p>Oshoma Momoh, chief technical advisor at MaRS Discovery District, said that it should take another seven to 10 years for vehicles to operate fully autonomously and without the need for a safety pilot on Canadian roads. But until then, any driverless cars on the road will be able to collect valuable data on a variety of weather and traffic conditions.&nbsp;&nbsp;</p>

<p>"The way all of this works is that companies build up more common use cases or examples of how driving works in real life, and train their software to become more self-sufficient," Momoh said in a phone interview.&nbsp;</p>

<p><em>Editor's Note: A previous version of this story&nbsp;included incorrect information about when&nbsp;the service would begin. BNN Bloomberg regrets this error.&nbsp;</em></p>


                                                
                            </div></div>]]>
            </description>
            <link>https://www.bnnbloomberg.ca/loblaw-to-launch-canada-s-first-autonomous-delivery-fleet-in-december-1.1526410</link>
            <guid isPermaLink="false">hacker-news-small-sites-25192900</guid>
            <pubDate>Mon, 23 Nov 2020 22:54:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Guide to OOMKill Alerting in Kubernetes Clusters]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25192733">thread link</a>) | @draganm
<br/>
November 23, 2020 | https://www.netice9.com/blog/guide-to-oomkill-alerting-in-kubernetes-clusters | <a href="https://web.archive.org/web/*/https://www.netice9.com/blog/guide-to-oomkill-alerting-in-kubernetes-clusters">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>   <span>Monday 23 Nov 2020, 18:30</span> <h2>Intro</h2> <p>RAM is most likely the scarcest resource that is first exhausted on your servers. If you’re serious about running software under Linux/Unix, you’re certainly aware of what an OOMKill is.</p> <p>Short refresher: when a program requests a new memory page from the kernel two things can happen.</p> <ul><li>There is a free memory page: The kernel page assigns the page to the process and everything is great.</li> <li>The system is Out Of Memory (OOM): The kernel chooses a process based on its ‘badness’ (mainly by how much ram it uses). It sends a SIGKILL to the process. This forces the receiving process to exit with exit code <code>137</code>. All the memory pages belonging to that process are free and now the kernel can fulfill the memory request.</li></ul> <p>Lately, I had a task to add alerting to a sizeable Kubernetes cluster. The cluster has ~100 active Deployments with autoscaling of nodes up to ~50 nodes at peak times. The cluster is well maintained and has a robust autoscaling strategy. All deployments have resource limits defined. Sometimes, some of the deployed pods would breach the memory limits. In those cases, it would be nice to find out when that happens and investigate the cause of it.</p> <p>Prometheus and Alertmanager were already deployed. So I’ve thought that alerting on OOMKills will be as easy. I just had to find the right metric(s) indicating that OOMKill has happened and write an alerting rule for it. Given the length of this post, you could imagine how wrong I was!</p> <h2>First Attempt</h2> <p>A brief Google search has led me to the <a href="https://github.com/kubernetes/kube-state-metrics/blob/master/docs/pod-metrics.md" rel="nofollow">kube pod state metric</a>. It turns out it has a metric called <code>kube_pod_container_status_last_terminated_reason</code>. The value of the metric is <code>1</code> when a container in a pod has terminated with an error. Based on the exit code, the <code>reason</code> label will be set to <code>OOMKilled</code> if the exit code was <code>137</code>. That sounded promising! So I’ve created an alert for that.</p> <p>As usual, things are rarely straightforward. As soon as the container restarts, the value of this metric will be <code>1</code>. For alerting purposes, one has to combine it with another metric that will change when a pod restarts. <code>kube_pod_container_status_restarts_total</code> does that. Combine the two - and Bingo! It Worked!</p> <h2>“Invisible” OOMKills</h2> <p>For a brief moment, I’ve thought that I was done. I was about to declare victory over OOMKills in production! But then a puzzle came my way: One of our software developers has come forward. He claimed that one of his pods was running out of memory and he couldn’t see any alerts for it.</p> <p>At first, I wasn’t inclined to believe that his diagnosis of running out of memory was correct. Mainly because his Pod didn’t even restart! But then I looked at the graph of the memory use of the Pod. It did show the usual pattern: Memory usage would grow, reach its peak at the memory limit, and then suddenly drop.</p> <p>I’ve asked the developer for the gory details of the implementation. It turned out that the init process in the container would start a child process and wait for the result of it. If the child process would exit with an error, it would return an error to the requester and not terminate (because - why should it?).</p> <p>That is when it dawned to me - my alerting is effective only if container exits. This is usually the case when the init process of the container is OOMKilled. But there is no guarantee this will happen if a child of the init is OOMKilled. In the case where the container’s init tries to handle OOMKill by itself, my alerting is not triggering!</p> <h2>Trying the Existing Solutions</h2> <p>Given that OOMKills are as old as Unix, I thought: surely someone will have a solution for this already.</p> <p>I’ve ensued onto a frantic search for some kind of metric exporter for this. I just needed the number of OOMKill events in a pod, or at least in a Docker container. Here is what I’ve found:</p> <h3>cAdvisor</h3> <p>My first stop was cAdvisor itself. It turns out that cAdvisor is <a href="https://github.com/google/cadvisor/issues/1837" rel="nofollow">getting the OOMKill events, but not exporting them as a Prometheus metric and no one really seems to care.</a> So that was a dead-end.</p> <h3>kubernetes-oomkill-exporter</h3> <p>My second stop was <a href="https://github.com/sapcc/kubernetes-oomkill-exporter" rel="nofollow">kubernetes-oomkill-exporter</a>. A very promising-sounding project with two huge disadvantages:</p> <ul><li>There is really no documentation for it, literally anywhere.</li> <li>It does not work.</li></ul> <p>I’ve tried the latest version of <a href="https://hub.docker.com/layers/sapcc/kubernetes-oomkill-exporter/0.3.0/images/sha256-b80875b903635f0336ea0b122b332e086da51ec5cd797de5d682dd14c3910b9f?context=explore" rel="nofollow">the Docker image</a>, but once started it crashes and burns with:</p> <pre><code>standard_init_linux.go:211: exec user process caused "no such file or directory"</code></pre> <p>Going <a href="https://hub.docker.com/layers/sapcc/kubernetes-oomkill-exporter/0.2.0/images/sha256-5e1b57f4ac0b57406ef067da3e83f743d70ff89aa1db717d41af2c699dc12f3a?context=explore" rel="nofollow">back one minor version</a> one gets the following output:</p> <pre><code>F1120 22:04:21.571246       1 main.go:73] Could not create log watcher
I1120 22:04:21.572066       1 main.go:64] Starting prometheus metrics</code></pre> <p>As it seems no one has committed any code to in over a year. It has a low number of stars (14). All that meant that I was back to square one.</p> <h2>Rolling my Own: <code>missing-container-metrics</code></h2> <p>Having a hard time finding an existing solution meant only one thing: I will have to write my own.</p> <p>A cursory look at <a href="https://docs.docker.com/engine/reference/commandline/events/" rel="nofollow">Docker’s events</a> delivered everything I needed. There is an event called <code>oom</code>. Docker emits this event every time the OOMKiller process gets active in the container. Now I was only missing a piece of code that will listen to those events and export them as Prometheus metrics.</p> <p>This is how <a href="https://github.com/draganm/missing-container-metrics" rel="nofollow">missing-container-metrics</a> was born. What it does is to connect to a local Docker instance (via <code>/var/run/docker.sock</code>). It lists all existing containers as a starting point. And then it listens to Docker events. Using those events, it keeps track of the currently running containers. It also gathers the basic stats of each container it knows about:</p> <ul><li>Number of restarts</li> <li>Last exit code</li> <li>Number of OOMKills</li></ul> <p>By design, it is not Kubernetes specific. This means it can be used with a plain Docker. But it also has a couple of very convenient Kubernetes specific features.</p> <p>Whenever it finds a container label for the pod name or namespace, it adds them as a label to the exported metrics. Also, label naming is compatible with <code>kube-state-metrics</code>.</p> <p>This keeps things simple for metric joins in PromQL.</p> <h2>Running it in the Cluster</h2> <p>In a Kubernetes cluster, <code>missing-container-metrics</code> needs to run on every node. The simplest way to achieve this is to use a daemon-set. The source code comes with an example <a href="https://github.com/draganm/missing-container-metrics#kubernetes" rel="nofollow">daemon set</a> deployment.</p> <h2>An Interesting Find Using <code>missing-container-metrics</code></h2> <p>The most interesting issue I’ve found was where I’ve least expected it: Fluentd!</p> <p>Fluentd log forwarder for node/pod/kubelet logs to the log aggregator. When the volume of logs was very high, Fluentd is OOMKilled.</p> <p>Looking at the details of how Fluentd works, it becomes clear what is going on.</p> <p>Fluentd has one main process (that ends up being init process in the container). This main process forks a worker process that forwards the logs. When the worker process dies for some reason (for example OOMKill), the main process starts a new one. This leads to an endless loop of spawn/OOMKill.</p> <p>The fact that Fluentd is the log forwarder is very unfortunate. OOMKill loop would stop the log forwarding, so you could not ‘see’ what is going on by inspecting the logs.</p> <h2>Epilogue</h2> <p>If you want to make sure that your Kubernetes cluster is healthy, it is essential to alert on OOMKills. This enables you to know when processes hit their memory limits. Be it because of memory leaks or wrongly configured memory limits.</p> <p>It turns out that monitoring for OOMKills in Kubernetes is not as an easy task as one might think. Using <a href="https://github.com/draganm/missing-container-metrics" rel="nofollow">missing-container-metrics</a> makes it much easier though.</p> <p>So go ahead, deploy <a href="https://github.com/draganm/missing-container-metrics" rel="nofollow">missing-container-metrics</a> to your cluster. You might be surprised how many of OOMKills you have not been noticing.</p> <p>I hope that it will be useful to you, and will save you the time that I’ve spent searching for the solution.</p></article></div>]]>
            </description>
            <link>https://www.netice9.com/blog/guide-to-oomkill-alerting-in-kubernetes-clusters</link>
            <guid isPermaLink="false">hacker-news-small-sites-25192733</guid>
            <pubDate>Mon, 23 Nov 2020 22:31:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Demystifying the second law of thermodynamics]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25191832">thread link</a>) | @akakievich
<br/>
November 23, 2020 | https://erischel.com/demystifying-the-second-law-of-thermodynamics/ | <a href="https://web.archive.org/web/*/https://erischel.com/demystifying-the-second-law-of-thermodynamics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <main id="main">
        




<i data-feather="calendar"></i> <time datetime="2020-11-22">Nov 22, 2020</time>

  <br>
  <i data-feather="tag"></i>
  
  
  <a href="https://erischel.com/tags/physics">physics</a>
  
  
  <a href="https://erischel.com/tags/math">math</a>
  

<p>Thermodynamics is really weird. Most people have probably encountered a bad explanation of the basics at some point in school, but probably don’t remember more than</p>
<ul>
<li>Energy is conserved</li>
<li>Entropy increases</li>
<li>There’s something called the ideal gas law/ideal gas equation.</li>
</ul>
<p>Energy conservation is not very mysterious. Apart from some weirdness around defining energy in general, it’s just a thing you can prove from whatever laws of motion you’re using.</p>
<p>But <em>entropy</em> is very weird. You’ve heard that it measures “disorder” in some vague sense.
Maybe you’ve heard that it’s connected to the <a href="https://en.wikipedia.org/wiki/Entropy%5F(information%5Ftheory)">Shannon entropy</a> of a probability distribution \(H(p) = \sum_x - p(x)\ln p(x)\).
Probably the weirdest thing about it is the law it obeys: It’s not conserved, but rather it <em>increases</em> with time.
This is more or less the only law like that in physics.</p>
<p>It gets even weirder when you consider that at least classical Newtonian physics is <em>time-symmetric</em>.
Roughly speaking, this means if you have a movie of things interacting under the laws of Newton, and you play it backwards, they’re still obeying the laws of Newton. An orbiting moon just looks like it’s orbiting in the other direction, which is perfectly consistent. A stone which is falling towards earth and accelerating looks like it’s flying away from earth and decelerating - exactly as gravity is supposed to do.</p>
<p>But if there’s some “entropy” quality out there that only increases, then that’s obviously impossible! When you played the movie backwards, you’d be able to tell that entropy was decreasing, and if entropy always increases, some law is being violated.
So what, is entropy some artefact of quantum mechanics? No, as it turns out. Entropy is an artefact of the fact that you can’t measure all the particles in the universe at once. And the fact that it seems to always increase is a consequence of the fact that matter is stable at large scales.</p>
<p>The points in this post are largely from E.T. Jaynes' <a href="https://bayes.wustl.edu/etj/articles/macroscopic.prediction.pdf">Macroscopic Prediction</a>.</p>
<h2 id="a-proof-that-entropy-doesn-t-always-increase">A proof that entropy doesn’t always increase</h2>
<p>Let \(X\) be the set of states of some physical system. Here I will assume that there is a finite number of states and time advances in discrete steps - there is some function \(T: X \to X\) which steps time forward one step. We assume that these dynamics are time-reversible in the weak sense that \(T\) is a bijection - every state is the future of exactly one “past” state.
Let \(S: X \to \mathbb{R}\) be some function. Assume \(S(x) \leq S(Tx)\) - in other words, \(S\) can never decrease.
Then \(S\) is constant, i.e \(S(x) = S(Tx)\).</p>
<p>Proof: Assume for contradiction \(S(x) &lt; S(Tx)\) for some \(x\). Since \(X\) is finite, let \(\sum_x S(x)\) be the sum of \(S\) over all states. Then clearly \(\sum_x S(x) = \sum_x S(Tx)\), since \(Tx\) just ranges over all the \(x\)s.
But on the other hand, we have \(S(x) \leq S(Tx)\) for all \(x\), and \(S(x) &lt; S(Tx)\) in at least one case. So we must have \(\sum_x S(x) &lt; \sum_x S(Tx)\) - contradiction.</p>
<p>This proof can be generalized to the continuous time and space case without too much trouble, for the types of dynamics that actually show up in physics (using <a href="https://en.wikipedia.org/wiki/Liouville%27s%5Ftheorem%5F(Hamiltonian)">Liouville’s Theorem</a>). The proof above still requires a <em>bounded</em> phase volume (corresponding to the finiteness of \(X\)). To generalize to other situations we need some more assumptions - the easiest thing is to assume that the dynamics are time-reversible in a stronger sense, and that this is compatible with the entropy in some way.</p>
<p>(You can find easy counterexamples in general, e.g. if \(X=\mathbb{Z}\) and the dynamics are \(T(x) = x+1\), then obviously we really do have that \(S(x) =x\) is increasing. Nothing to do about that.)</p>
<p>Anyways the bounded/finite versions of the theorems do hold for a toy thermodynamic system like particles in a (finite) box - here the phase volume really is bounded.</p>
<h2 id="the-true-meaning-of-entropy">The true meaning of entropy</h2>
<p>Okay, so what the hell is going on? Did your high school physics textbook lie to you about this?
Well, yes. But you’re probably never going to observe entropy going down in your life, so you can maybe rest easy.</p>
<p>Let \(X\) be the physical system under consideration again. But suppose now that we can’t observe \(x \in X\), but only some “high-level description \(p(x) \in Y\). Maybe \(x\) is the total microscopic state of every particle in a cloud of gas - their position and momentum - while \(p(x)\) is just the average energy of the particles (roughly corresponding to the temperature).
\(x\) is called a <em>microstate</em> and \(y = p(x)\) is called a <em>macrostate</em>.
Then the <em>entropy</em> of \(y \in Y\) is \(S(y) = \ln (p^{-1}(\{y\})\) - the logarithm of the number of microstates \(x\) where \(p(x) = y\). We say these are the microstates that <em>realize</em> the macrostate \(y\).</p>
<p>The connection with Shannon entropy is now that this is exactly the Shannon entropy of the uniform distribution over \(p^{-1}(y)\). This is the distribution you should have over microstates if you know nothing except the microstate.
In other words, the entropy measures your uncertainty about the microstate given that you know nothing except the macrostate.</p>
<p>There are more sophisticated versions of this definition in general, to account for the fact that</p>
<ul>
<li>In general, your microstates are probably sets of real numbers, and there are probably infinitely many compatible with the macrostate, so we need a notion of “continuous entropy” (usually called differential entropy, I think)</li>
<li>Your measurement of the macrostate is probably not that certain (but this turns out to matter surprisingly little for thermodynamic systems),</li>
</ul>
<p>but this is the basic gist.</p>
<h2 id="why-entropy-usually-goes-up">Why entropy usually goes up</h2>
<p>Okay, so why does entropy go up?
<em>Because there are more high-entropy states than low-entropy states</em>. That’s what entropy <em>means</em>.
If you don’t know anything about what’s gonna happen to \(x\) (in reality, you usually understand the dynamics \(T\) themselves, but have absolutely no information about \(x\) except the macrostate), it’s more likely that it will transfer to a macrostate with a higher number of representatives than to one with a low number of representatives.</p>
<p>This also lets us defuse our paradox from above. In reality, entropy doesn’t go down for literally every microstate \(x\).
It’s not true that \(S(p(Tx)) &gt; S(p(x))\) for all \(x\) - I proved that impossible above.
What <em>can</em> be true is this: given a certain macrostate, it’s more probable that entropy increases than that it decreases.</p>
<p>We can consider an extreme example where we have two macrostates \(L\) and \(H\), corresponding to low and high entropy.
Clearly the number of low-entropy states that go to a high-entropy state is exactly the same as the number of high-entropy states that go to a low-entropy state. That’s combinatorics.
But the <em>fraction</em> of low-entropy states that go to high-entropy is then necessarily larger than the fraction of high-entropy states that go to low-entropy states.</p>
<p>In other words, \(P(H(x_{t+1})|L(x_t)) &gt; P(L(x_{t+1})|H(x_t))\)</p>
<h2 id="why-entropy--almost--always-goes-up">Why entropy (almost) always goes up</h2>
<p>Okay, but that’s a lot weaker than “entropy always increases”! How do we get from here to there?
I could say some handwavy stuff here about how the properties of thermodynamic systems mean that the differences in the number of representatives between high-entropy and low-entropy states are massive - and that means the right-hand probability above can’t possibly be non-neglible. And that in general this works out so that entropy is almost guaranteed to increase.</p>
<p>But that’s very unsatisfying. It just happened to work out that way? I have a much more satisfying answer: entropy almost always increases because matter is stable at large scales.</p>
<p>Wait, what? What does that mean?</p>
<p>By “matter is stable at large scales”, I mean that the macroscopic behaviour of matter is predictable only from macroscopic observations. When a bricklayer builds a house, they don’t first go over them with a microscope to make sure the microstate of the brick isn’t going to surprise us later. And as long as we know the temperature and pressure of a gas, we can pretty much predict what will happen if we compress it with a piston.</p>
<p>What this means is that, if \(p(x) = p(x')\), then <em>with extremely high probability</em>, \(p(Tx) = p(Tx')\). It might not be literally certain, but it’s sure enough.</p>
<p>Now, let’s say we’re in the macrostate \(y\). Then there is some macrostate \(y'\) which is <em>extremely likely</em> to be the next one. For very nearly all \(x\) so that \(p(x) = y\), we have \(p(Tx) = y'\).
But this means that \(y'\) must have at least that many microstates representing it, since \(T\) is a bijection.
So the entropy of \(y'\) can at most be a <em>tiny</em> bit smaller than the entropy of \(y\) - this difference would be as tiny as the fraction of \(x\) with \(p(Tx) \neq y'\), so we can ignore it.</p>
<p>So unless something super unlikely happens and \(p(Tx) \neq y'\), entropy goes up.</p>
<p>By the way, this also explains what goes wrong with time-reversibility, and why in reality, you can easily tell that a video is going backwards. The “highly probably dynamics” \(Y \to Y\), which takes each macrostate the the most probable next state, don’t have to be time-reversible. For instance, let’s return to the two-macrostate system above.
Suppose that with 100% certainty, low-entropy states become high-entropy.
Let there be \(N_L\) low-entropy states and \(N_H\) high-entropy states.
Then, just because \(T\) is a bijection, there must be \(N_L\) high-entropy states that become low-entropy.
Now if \(N_H \gg N_L\), then practically all high-entropy states go to other high-entropy states.
So \(L \mapsto H\) but \(H \mapsto H\).</p>
<p>Of course in reality, if you start with a low-entropy state and watch this unfold for a <em>really</em> long time, you’ll eventually see it become a low-entropy state again. It’s just extremely unlikely to happen in a short amount of time.</p>
<h2 id="entropy-is-not-exactly-your-uncertainty-about-the-microstate">Entropy is not exactly your uncertainty about the microstate</h2>
<p>The entropy of a given macrostate is the uncertainty …</p></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://erischel.com/demystifying-the-second-law-of-thermodynamics/">https://erischel.com/demystifying-the-second-law-of-thermodynamics/</a></em></p>]]>
            </description>
            <link>https://erischel.com/demystifying-the-second-law-of-thermodynamics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25191832</guid>
            <pubDate>Mon, 23 Nov 2020 21:02:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Behavioral Economics to Build Better Products]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25191745">thread link</a>) | @alanbr
<br/>
November 23, 2020 | https://lightit.io/blog/behavioral-economics-for-ux-conversions-scarcity/ | <a href="https://web.archive.org/web/*/https://lightit.io/blog/behavioral-economics-for-ux-conversions-scarcity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://lightit.io/blog/content/images/size/w300/2020/11/behavioral-1.png 300w,
                            https://lightit.io/blog/content/images/size/w600/2020/11/behavioral-1.png 600w,
                            https://lightit.io/blog/content/images/size/w1000/2020/11/behavioral-1.png 1000w,
                            https://lightit.io/blog/content/images/size/w2000/2020/11/behavioral-1.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://lightit.io/blog/content/images/size/w2000/2020/11/behavioral-1.png" alt="Boost Conversions with Behavioral Science. P1: Scarcity">
            </figure>

            <section>
                <div>
                    <h2 id="ux-behavioral-economics">UX &amp; Behavioral Economics</h2><p>No matter how mature your digital platform is, there's always space for improvement. We've talked plenty about UX on this blog, understanding it as designing based on your users' insights. However, it's important to <strong>complement UX with behavioral science.</strong> This is a series of insights about human behavior that are <strong>true of all users.</strong> In the following blog posts, I'll reveal some behavioral insights that might help boost your conversions... <strong>Let's start with the first one: scarcity.</strong></p><h2 id="scarcity-motivates-conversions">Scarcity Motivates Conversions</h2><figure><img src="https://lightit.io/blog/content/images/2020/11/image.png" alt="Scarcity example booking"></figure><p>Have you ever booked a hotel on Booking? If you did, it would probably be easy for you to understand the scarcity heuristic.</p><p>Scarcity is<strong> </strong>the event where a product/service is perceived as more attractive because it's presented as limited in availability. Limitation gives people a sense of quality, exclusivity and even gives them the famous FOMO (fear of missing out) on a great product or discount. <strong>The scarcity heuristic can be used to pressure people into taking action</strong></p><p>Booking's example is pretty straightforward. While you're making your reservation, Booking tells you <strong>how many rooms are still available</strong> and even the <strong>number of people that are looking at the hotel simultaneously</strong> as you (and might steal the room you wish!) This last one isn't only a scarcity strategy, but also a social norm we'll look into in the next blog post. This information pressures people into reserving quickly before the other people book the last room.</p><p>I'm not saying Booking's strategy is effective (personally, I believe it's a little exaggerated to the point it looks fake). Still, it's a clear example of using scarcity to <strong>rush customers to make their decision</strong>. </p><p>Another famous example is from a grocery store in Iowa that did an exciting experiment with the discount they offered for Campbell's soups. They always provided the same discount, though some days, they hanged a sign next to the cans that read "Limit 12 Per Person", while other days they didn't have a limit. Take a look at these impressive results.<strong> Customers bought 7 cans on average when the limit was imposed, compared to an average of 3 cans on days with no limit.</strong></p><h3 id="so-how-can-i-take-this-to-my-digital-platform"><br>So... how can I take this to my digital platform?</h3><p>There are several strategies you might try; the key is on<strong> trying different alternatives and tracking down the metrics</strong> so that you figure out which one works. <strong>Remember not to over-do it</strong>; no one trusts sites with discounts and deals that last forever. The typical "subscribe now and get 20% off on your first order" isn't that attractive if it has no time limit. Though, if it has, it might motivate people to make up their minds faster. Benefits must be perceived "here and now" to be more valuable.</p><figure><img src="https://lightit.io/blog/content/images/2020/11/image-4.png" alt="Amazon scarcity example"></figure><p>Bear in mind these strategies aren't only useful for e-commerces, they can be used for other business models too. For example on social networks or communities, creating <strong>waiting lists, deadlines, asking for qualifications to join or limiting invites </strong>can really boost interest by giving a sense of &nbsp;<strong>exclusivity</strong> and FOMO. It's no news that exclusive things are more attractive... but have you ever wondered what came first? Attractiveness or exclusivity?</p><hr><p><strong>Stay tuned for the next post of this collection, </strong>Insights on Behavioral Economics to Improve Your Platform's Results. <strong>Part 2: Social Norms. </strong></p><!--kg-card-begin: markdown--><p>Subscribe to our newsletter &amp; follow us on <a href="https://www.linkedin.com/company/lightit//" target="_blank">Linkedin</a>.</p>
<!--kg-card-end: markdown--><hr><!--kg-card-begin: markdown--><p>Shoutout to  <a href="https://collectiveacademy.com///" target="_blank">Collective Academy</a>, where I took my course on Behavioral Economics and learned everything written in this article &lt;3</p>
<!--kg-card-end: markdown-->
                </div>
            </section>

                <section>
    <h3>Subscribe to Light-it Blog</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>
            

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://lightit.io/blog/behavioral-economics-for-ux-conversions-scarcity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25191745</guid>
            <pubDate>Mon, 23 Nov 2020 20:56:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cracks in the Great Stagnation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25191733">thread link</a>) | @jseliger
<br/>
November 23, 2020 | https://www.agglomerations.tech/cracks-in-the-great-stagnation | <a href="https://web.archive.org/web/*/https://www.agglomerations.tech/cracks-in-the-great-stagnation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1602611061438-ca00df2a4319?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 300w,
                            https://images.unsplash.com/photo-1602611061438-ca00df2a4319?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 600w,
                            https://images.unsplash.com/photo-1602611061438-ca00df2a4319?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1000w,
                            https://images.unsplash.com/photo-1602611061438-ca00df2a4319?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1602611061438-ca00df2a4319?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="Cracks in the Great Stagnation">
            </figure>

            <section>
                <div>
                    <p>For the last 60 years, we’ve seen consistently low productivity growth rates in the US and across the Western world. Meanwhile, recent scientific discoveries seem to be <a href="https://www.theatlantic.com/science/archive/2018/11/diminishing-returns-science/575665/">less fundamental</a> to our understanding of the world than previous breakthroughs have been. While the growth of digital technology has been tremendous since the 1990s, it’s the only significant part of our world that seems to have been changing. To look up from our smartphones is to see a physical environment that looks basically the same as it did in 1970. Innovation has been constrained to the world of bits and left the world of atoms mostly untouched.</p><p>This might finally be changing. Last month, the economist Tyler Cowen <a href="https://www.bloomberg.com/opinion/articles/2020-10-05/how-much-worse-can-things-get-that-question-may-be-a-good-sign">speculated</a> that we may be seeing signs that this <a href="https://www.amazon.com/Great-Stagnation-Low-Hanging-Eventually-eSpecial-ebook/dp/B004H0M8QS">Great Stagnation</a> is ending. Since his article was published, we’ve already seen almost a dozen announcements that have only driven home the point further. There seem to be cracks in the Great Stagnation and light is peeking through on the other end. </p><p><strong>Innovation in the physical world</strong><br>Most obviously, the recent announcement of the <a href="https://www.statnews.com/2020/11/09/covid-19-vaccine-from-pfizer-and-biontech-is-strongly-effective-early-data-from-large-trial-indicate/">successful development of several vaccines</a> to the novel coronavirus are a sign that America (with some help from Germany) is still capable of achieving Big Things when we are pushed to it. Despite consistent failings of the US regulatory state in <a href="https://slatestarcodex.com/2020/04/14/a-failure-but-not-of-prediction/">delaying the adoption</a> of face masks and in <a href="https://thedispatch.com/p/timeline-the-regulationsand-regulatorsthat">slowing the rollout</a> of mass testing, the US essentially bet the farm that our strong biotech clusters would be able to create a vaccine to a new disease in record time, and it looks like we’re going to be able to do it in under a year! </p><p>It’s worth highlighting just how speedy this development timeline is when compared to the vaccines for diseases like polio and measles. </p><figure><img src="https://www.agglomerations.tech/content/images/2020/11/Vaccination-innovation-chart.png" alt="" srcset="https://www.agglomerations.tech/content/images/size/w600/2020/11/Vaccination-innovation-chart.png 600w, https://www.agglomerations.tech/content/images/size/w1000/2020/11/Vaccination-innovation-chart.png 1000w, https://www.agglomerations.tech/content/images/size/w1600/2020/11/Vaccination-innovation-chart.png 1600w, https://www.agglomerations.tech/content/images/size/w2400/2020/11/Vaccination-innovation-chart.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>https://ourworldindata.org/vaccination</figcaption></figure><p>And not only did we develop a new vaccine, we developed a new *type* of vaccine. mRNA vaccines have long been speculated to work, but this is the <a href="https://www.bostonherald.com/2020/11/20/pfizer-and-moderna-vaccines-showing-potential-success-of-mrna-platform-a-first/">first instance</a> of a successful vaccine application in humans using this technique. </p><p>In transportation, the promise of driverless cars has long been a centerpiece for a tech-optimistic vision of safer roads, better-designed cities, and eliminating the drudgery of a morning commute through traffic. But the technical delays of the last few years (when compared to the most optimistic timelines) have become a rallying cry for the <a href="https://blog.piekniewski.info/2018/05/28/ai-winter-is-well-on-its-way/">tech-skeptic</a> as well. </p><p>It seems like they may finally be getting here. A few weeks ago, <a href="https://arstechnica.com/cars/2020/10/waymo-finally-launches-an-actual-public-driverless-taxi-service/">Waymo announced</a> that their long-running pilot program in Arizona is going to be open to the public <a href="https://twitter.com/jjricks_/status/1316318196375330816">without any safety driver</a> in the front seat. Days later, Elon Musk and Tesla rolled out a new self-driving beta program. </p><figure><blockquote data-width="550"><p lang="en" dir="ltr">These two guys used a drone to make a video of Tesla's new "full self-driving" software in action. The drone, the self-driving car, and the global video-steaming service were all been science fiction when I was born. Living in the future is neat. <a href="https://t.co/4QqGcjFXsc">https://t.co/4QqGcjFXsc</a></p>— Timothy B. Lee (@binarybits) <a href="https://twitter.com/binarybits/status/1321102111883579397?ref_src=twsrc%5Etfw">October 27, 2020</a></blockquote>

</figure><p>This is a remarkable engineering feat, especially on Waymo’s end. It shows the company can successfully lead product development in an industry that relies on more stringent safety-critical engineering instead of the release-and-iterate model that its parent company grew up with. Waymo is evidence that Silicon Valley can “move at a moderate pace and not break things” when it needs to.</p><p>Granted, it’s unclear how long until and at what pace deployment of AVs to the rest of the country and the world will happen. If the Waymo model looks to be successful, it will be a steady, resource-intensive process of region-by-region expansion as the cars learn to handle new operational design domains and are rigorously validated in each city before the keys are turned over to the AI. In other words, expansion could look more like a cell phone coverage map than a software update that is instantaneously available everywhere. </p><p>But still, this is a significant, tangible mile marker that the industry has passed. AVs are operating in the wild now. We get to talk about *when* we reach the driverless future, not *if*. </p><p>In addition to the almost ho-hum daily progress in solar, wind, and battery technology where prices have fallen <a href="https://www.greentechmedia.com/articles/read/solar-pv-has-become-cheaper-and-better-in-the-2010s-now-what">90</a>, <a href="https://www.forbes.com/sites/energyinnovation/2020/01/21/renewable-energy-prices-hit-record-lows-how-can-utilities-benefit-from-unstoppable-solar-and-wind/?sh=491f10ec2c84">70</a>, and <a href="https://about.bnef.com/blog/battery-pack-prices-fall-as-market-ramps-up-with-market-average-at-156-kwh-in-2019">87</a> percent over the last ten years, we’ve also started to hear very promising reports about the development of more fundamental breakthroughs. The NYT reports that a compact nuclear fusion reactor is “<a href="https://www.nytimes.com/2020/09/29/climate/nuclear-fusion-reactor.html?action=click&amp;module=News&amp;pgtype=Homepage">Very Likely to Work</a>” after a major theoretical advancement. There was also a fantastic David Robert’s <a href="https://www.vox.com/energy-and-environment/2020/10/21/21515461/renewable-energy-geothermal-egs-ags-supercritical">deep dive into geothermal energy</a> and the promise of advanced geothermal (whereby water pumped into the ground through a closed loop reaches a high enough temperature that it becomes “supercritical” and can carry 10x more energy per unit mass), in particular. Either technology, if perfected, would provide abundant, zero-carbon, baseload energy that is available anywhere around the world. </p><p>Cowen mentions briefly the huge market growth we’ve seen in lab-grown meat and plant-based alternatives. A few weeks ago it was announced that Impossible Foods, one of the largest actors in the industry is <a href="https://venturebeat.com/2020/10/20/impossible-foods-will-double-rd-to-eliminate-animal-farming/">doubling their R&amp;D team</a> as they seek to take on plant-based milk, steak, and fish as well as improve the supply chains for plant proteins. In tandem, McDonald’s <a href="https://www.washingtonpost.com/food/2020/11/10/mcdonalds-mcplant-sandwich/">just announced</a> that in 2021 they are going to be testing out a new McPlant menu.</p><p><strong>Digital innovation continues apace</strong></p><p>Not to be left out, in the digital world we’ve been seeing impressive progress as well. AI techniques like deepfakes which have been heralded as the <a href="https://www.sundayguardianlive.com/opinion/deepfakes-destroy-democracy">death knell for democracy</a> are now being <a href="https://arstechnica.com/gadgets/2020/11/nvidia-used-neural-networks-to-improve-video-calling-bandwidth-by-10x/">deployed by NVIDIA</a> to increase video fidelity while cutting bandwidth transmission for video calls by a factor of 10. In general, techniques to reduce bandwidth use are greatly underrated, and it’s going to be exciting to see the ways in which smarter compression can perhaps bring similar efficiency gains across the board. </p><p>And now factor in the steady rollout of 5G network technologies which promise to increase the raw bandwidth available to all mobile devices. With the combination of smarter compression and vastly increased bandwidth we could be looking at a baseline 50x increase in network capacity over the next decade. It’s hard to predict ahead of time what new applications will be enabled by all this new capacity, but in retrospect it could look like another example of <a href="https://diff.substack.com/p/how-bubbles-and-megaprojects-parallelize">parallel innovation</a> that both enables and is driven by the growth of VR/AR, driverless vehicles, and telehealth.*</p><p><em>*For those who are skeptical that increased capacity will generate new applications because a few cities have tried gigabit broadband<a href="https://www.wsj.com/graphics/faster-internet-not-worth-it/"> without much effect</a>, I would argue that both hardware and app developers are optimizing for the baseline user experience and we won’t see a ton of investment in new applications until we’ve changed the baseline capacity that developers can expect a sizeable user base to have. </em></p><p>Equally as impressive, Apple’s new M1 chip that was launched on November 10th seems to have taken the world by storm. As John Gruber <a href="https://daringfireball.net/2020/11/the_m1_macs">summarizes</a>: “To acknowledge how good they are — and I am here to tell you they are astonishingly good — you must acknowledge that certain longstanding assumptions about how computers should be designed, about what makes a better computer better, about what good computers need, are wrong.” Just as interesting is <a href="https://medium.com/pcmag-access/what-is-the-apple-m1-chip-613935ea0903">how they did it</a>. By miniaturizing the whole system architecture and integrating it onto a single chip (no discrete RAM, graphics card, etc.) Apple has managed to pump out massive efficiency gains both in processing power and in battery life. (There’s perhaps a metaphor here for the <a href="https://www.wsj.com/articles/breaking-up-big-tech-is-hard-to-do-1532290123">value of integration</a> for large tech firms as well…)</p><figure><img src="https://lh5.googleusercontent.com/tXP4ZnW93TIsJ_dJe3NVmevfz5eMUnNC6CS40Dz_S0568BDiQKr8K8LqT5Ja-kLnXUKnS1UkDQf_6WYzBhfGa4c99lQDfqudhQaDF-XCYBEkxNoP3Vo3FlGtLl3sGFQcdtHBlGbv" alt=""><figcaption>https://techcrunch.com/2020/11/17/yeah-apples-m1-macbook-pro-is-powerful-but-its-the-battery-life-that-will-blow-you-away/</figcaption></figure><p>Finally, the virtual reality space has seen its most impressive entrant in years with the arrival of the Quest 2 from Facebook on October 13th. There is no VR headset that matches it on a performance/cost basis, and the relative simplicity and elegance of the system makes it an ideal entry point. The deliberately low entry barrier of $299 is meant to entice a large enough user base that it kickstarts the virtuous cycle of having a significant enough market for dedicated VR developers to make significant investments in new applications, which then drives new user growth. Facebook believes we finally have a minimum viable product for VR that means this kind of two-sided market is possible, and it is betting billions of dollars to make it happen. Early signs seem to show that it is working as intended with <a href="https://www.theverge.com/2020/10/30/21541535/oculus-quest-2-preorders-sales-developers-zuckerberg">pre-orders reportedly 5x</a> larger than the original Quest, popular applications like Beat Saber seeing record growth, and all this with the upcoming holiday rush and a massive advertising blitz to come. </p><p>Notably, all of these announcements/developments I’ve outlined have occurred in just the last few months. This is by no means a comprehensive look at the exciting progress being made in many other fields. But the sheer scope and pace of tangible changes to our physical and digital words is something to be excited about.</p><p><strong>A few caveats </strong></p><p>Some of these innovations will boost productivity in the traditional ways that show up in economic growth statistics. We should strive for and celebrate those achievements. But some of these innovations won’t necessarily, instead they make human civilization more durable and sustainable in a variety of ways. In response, we should start to think of increased sustainability as a type of productivity. </p><p>A vaccine to the COVID pandemic is the most obvious example. While economic statistics won’t show a boost in productivity compared to the pre-COVID economy because of the vaccine, the ability to return to trend is itself incredibly valuable. In fact, measured labor productivity from the vaccine will likely fall as lower-wage …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.agglomerations.tech/cracks-in-the-great-stagnation">https://www.agglomerations.tech/cracks-in-the-great-stagnation</a></em></p>]]>
            </description>
            <link>https://www.agglomerations.tech/cracks-in-the-great-stagnation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25191733</guid>
            <pubDate>Mon, 23 Nov 2020 20:55:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting lucky with posting on Hacker News]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25191157">thread link</a>) | @reconquestio
<br/>
November 23, 2020 | https://samizdat.dev/getting-lucky-with-posting-on-hacker-news/ | <a href="https://web.archive.org/web/*/https://samizdat.dev/getting-lucky-with-posting-on-hacker-news/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article>
    <p>You know the feeling of watching your post quickly drowning in the Newest section of Hacker News, right?
It seems like pure, chaotic luck. Or is it?</p>
<p>I tried to crack the code of successful submissions.</p>
<p>I built a tool that parses Hacker News every two minutes and logs the state into the
database. The program has been working for <strong>14 days</strong> so far.</p>
<p>For the latest two weeks, there were <strong>13846</strong> stories, and only <strong>1403</strong> of them reached the first
page of Hacker News.</p>
<p>It’s <strong>10.1329</strong> percents. It doesn’t sound too bad, does it? It turns out <strong>every tenth story
hits the first page</strong>.</p>
<p><em>All time values are in UTC.</em></p>
<h2 id="stories-and-chances-to-hit-the-first-page">Stories and chances to hit the first page</h2>

<p>It seems like Saturday and Sunday are the least active days when it comes to new stories.
But it means you have the biggest chance to hit the first page during these days.</p>
<h2 id="total-number-of-stories-and-chances-by-hour">Total number of stories and chances by hour</h2>
<p>Let’s take a look what about best hours to publish then.</p>

<ul>
<li>I wouldn’t post at 15:00 - 16:00 since it’s the lowest chance to hit the first page. Too many
submissions during these hours.</li>
<li>11:00 - 12:00 looks like a good spot, everyone is getting awake and your post is already waiting
them on the first page.</li>
</ul>
<h2 id="votes-and-overall-activity">Votes and overall activity</h2>
<p>The watcher continuously checks Hacker News and logs the current position and the score of every
story into the database.</p>
<p>Let’s see what the most active days and hours were.</p>

<ul>
<li>Saturday and Sunday are the least active days.</li>
<li>Monday is the most active day.</li>
</ul>

<ul>
<li>00:00 - 10:00 are the least active hours</li>
<li>14:00 - 21:00 (UTC) are the most active hours on Hacker News.</li>
<li>15:00 - 19:00 (UTC) are the best hours.</li>
</ul>
<h2 id="finally-fun-facts">Finally, fun facts</h2>
<ul>
<li>48 stories hit the first page with literally 1 score point (you get it by default).</li>
<li>4 stories hit the first page with literally 2 score points.</li>
<li>590 stories needed 3 score points to appear on the first page.</li>
<li>318 stories needed 4 points.</li>
<li>143 stories needed 5 points.</li>
</ul>
<p>The longest living posts on the first page:</p>
<ul>
<li>65h13m56s  <a href="https://news.ycombinator.com/item?id=25154128">Flash Animations Live Forever at the Internet Archive </a></li>
<li>63h34m18s  <a href="https://news.ycombinator.com/item?id=25074959">macOS unable to open any non-Apple application</a></li>
<li>49h17m45s  <a href="https://news.ycombinator.com/item?id=25044254">Zoom lied to users about end-to-end encryption for years, FTC says</a></li>
<li>45h29m29s  <a href="https://news.ycombinator.com/item?id=25031491">Japan’s Onryō Spirits Inhabit a Purgatory of Revenge and Cosmic Rage </a></li>
<li>45h26m48s  <a href="https://news.ycombinator.com/item?id=25042002">Large-scale multilingual audio visual dubbing </a></li>
</ul>
<p>I’m going to analyze the statistics even further, it’s just a matter of time.</p>
<p><strong>Follow me on Twitter to get updates: <a href="https://twitter.com/reconquestio">@reconquestio</a></strong></p>
<p>Have an idea or want to contribute? Tweet/Email me.</p>
<h2 id="missing-charts">Missing charts</h2>
<ul>
<li>
<p>The watcher records the position of stories on the page and this data is not illustrated on the charts.</p>
</li>
<li>
<p>There is enough data to come up with a specific interval of time required to get the first upvotes to
get to the first page.</p>
<p>For instance, 3 upvotes in 12 hours will not get you to the first page, but will 3 upvotes
in 5 minutes get you there?</p>
</li>
<li>
<p>How long do posts live on the first page on average?</p>
</li>
</ul>
<h2 id="other-researches">Other researches</h2>
<ul>
<li><a href="https://antontarasenko.com/2015/04/23/best-time-to-post-its-irrelevant/">2015, Best Time to Post? It’s Irrelevant</a></li>
<li><a href="https://www.reddit.com/r/Entrepreneur/comments/5451l4/findings_on_the_optimal_time_to_post_to_hacker/">2016, /r/Enterpreneur: Findings on the optimal time to post to Hacker News</a></li>
<li><a href="https://medium.com/@mi.schaefer/what-is-the-best-time-to-post-to-hacker-news-829fad3eac71">2017, What is the best time to post to Hacker News?</a></li>
<li><a href="https://chanind.github.io/2019/05/07/best-time-to-submit-to-hacker-news.html">2019, The Best Time to Submit to Hacker News</a></li>
</ul>
<p>Thanks to <a href="https://twitter.com/ivmirx">Ivan Mir</a> for reading drafts of this.</p>


<hr>
    <b>Comments</b>
    
    
</article>

        </div></div>]]>
            </description>
            <link>https://samizdat.dev/getting-lucky-with-posting-on-hacker-news/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25191157</guid>
            <pubDate>Mon, 23 Nov 2020 20:10:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Install the XFCE desktop on your Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25191105">thread link</a>) | @URfejk
<br/>
November 23, 2020 | https://www.pragmaticlinux.com/2020/11/install-the-xfce-desktop-on-your-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://www.pragmaticlinux.com/2020/11/install-the-xfce-desktop-on-your-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>In this article you’ll learn how to install the XFCE desktop on your Raspberry PI. We’ll take a minimal install of the Raspberry PI operating system as a starting point. The XFCE installation on your Raspberry PI includes setting up all necessary building blocks, such as: display server, display manager, session manager, window manager and desktop environment.</p>
<h2>Background</h2>
<p>When you install the default Raspberry PI operating system, it presents you with the PIXEL desktop. The Raspberry PI foundation developed and maintains the PIXEL desktop. It offers a user-friendly desktop, with all basic features and applications included. For example: an application menu, a file manager, a text editor, etc. PIXEL is lightweight, meaning that it doesn’t consume a lot of RAM and CPU resources. This makes it run smoothly, even on a Raspberry PI Zero with only 512 MB of RAM.</p>
<p>So why would you want to switch to another desktop, such as XFCE? I can think of a few reasons:</p>
<ul><li>As a Linux desktop user, you probably did your fair share of desktop environment hopping. You might have settled on the XFCE desktop. Consequently, you prefer to run the XFCE desktop also on your Raspberry PI.</li><li>Your Raspberry PI serves as a Linux learning platform. You would like to find out what it takes to install a desktop environment from scratch.</li></ul>
<h3>The new Raspberry PI 400</h3>
<p>Over the years the Raspberry PI has gotten ever more powerful. It’s no longer just an embedded Linux board. Especially the Raspberry PI 4 packs enough CPU power and RAM for usage as you daily desktop computer. The Raspberry PI foundation thinks so too. Just look at the <a href="https://www.raspberrypi.org/products/raspberry-pi-400/">Raspberry PI 400</a> model they recently released. They market it as a “complete personal computer, built into a compact keyboard”:</p>
<figure><img loading="lazy" width="900" height="365" src="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/raspi400.png" alt="Image of the Raspberry PI 400. It's a Raspberry PI 4 build into a keyboard. Marketed as a complete personal computer, built into a compact keyboard." srcset="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/raspi400.png 900w, https://www.pragmaticlinux.com/wp-content/uploads/2020/11/raspi400-300x122.png 300w, https://www.pragmaticlinux.com/wp-content/uploads/2020/11/raspi400-768x311.png 768w" sizes="(max-width: 900px) 100vw, 900px"></figure>
<p>You no longer need to restrict yourself to the PIXEL desktop. The Raspberry PI 4 comes a quad-core 64-bit CPU and 2, 4 or 8 GB RAM. More than sufficient to run a ‘real’ Linux desktop such as XFCE, KDE or Gnome.</p>
<h3>Why the XFCE desktop</h3>
<p>So why did I select the XFCE desktop for this article? In my opinion the XFCE desktop sits nicely between the PIXEL desktop and the more resource intensive desktops such as Gnome and KDE. It offers a full desktop experience, while still being lightweight and with snappy responsiveness. The XFCE desktop is stable, well maintained and available in all major Linux distributions. It’s the desktop environment I personally select, when installing a Linux desktop on older hardware or in a virtual machine.</p>
<h2>What do you need</h2>
<p>To complete the steps in this article and install the XFCE desktop on your Raspberry PI, you need the following:</p>
<ul><li>Any Raspberry PI 4 board, including the new Raspberry PI 400.</li><li>A power supply for the Raspberry PI board.</li><li>A micro-SD card of 8 GB or more in size.</li><li>A USB mouse</li><li>A USB keyboard (not needed for the Raspberry PI 400).</li><li>A computer monitor or TV.</li><li>A cable for connecting the HDMI output to your monitor or TV.</li></ul>
<p>Throughout this article, I assume you already installed the Raspberry PI operating system. I recommend the <em>Lite</em> edition. The <em>Lite</em> edition of the Raspberry PI operating system does not include a graphical desktop environment. That way you start with a clean slate.</p>
<p>I’ll be using my Raspberry PI 4 with 4 GB RAM to install the XFCE desktop. I already installed the <em>Lite</em> edition of the Raspberry PI operating system on it. Furthermore, I added a new user account for user <code>pragmalin</code> and removed the default <code>pi</code> user account, for security purposes. Although not necessary, I recommend that you start with the same foundation. Refer to the previously published tutorial on how to <a href="https://www.pragmaticlinux.com/2020/11/perform-a-minimal-install-on-your-raspberry-pi/">perform a minimal install on your Raspberry PI</a> for step-by-step instructions.</p>
<h2>Graphical desktop components</h2>
<p>Before diving right into the installation of XFCE on your Raspberry PI, I would like to present a brief overview of all the components that go into a Linux graphical desktop. This theoretical background information is optional. Feel free to skip to the next section to continue with the hands-on XFCE installation part on your Raspberry PI.</p>
<p>Refer to the following illustration for an overview of all components:</p>
<figure><img loading="lazy" width="410" height="269" src="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/component_layers.png" alt="Illustration showing all the components that go into a graphical desktop on Linux. To install the XFCE desktop on a Raspberry PI we need these components: Xorg, lightdm, xfce4-session, xfwm4 and xfce4." srcset="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/component_layers.png 410w, https://www.pragmaticlinux.com/wp-content/uploads/2020/11/component_layers-300x197.png 300w" sizes="(max-width: 410px) 100vw, 410px"></figure>
<p>Note the added text after the arrow in the illustration. These are the specific components we’ll install for our XFCE desktop. For a Linux graphical desktop, the specific components can differ. For example, a Gnome desktop environment typically uses the <em>gdm</em> display manager instead of <em>lightdm</em>.</p>
<h3>Display server</h3>
<p>In order to do anything graphically, as opposed to just the basic command line, you need a display server. It provides the foundation needed by all the other components. It handles outputting pixels on the display and detecting input events from the mouse and keyboard.</p>
<h3>Display manager</h3>
<p>Think of the display manager as the login screen. It is the first thing that gets started if the operating system supports a graphical desktop. On this screen you enter your username and password to login. Furthermore, it offers you a choice of the desktop session to start.</p>
<h3>Session manager</h3>
<p>After logging in, the display manager hands control over to the session manager. Simply put, the session manager manages the state of the desktop of the logged in user(s). So which applications are running and what their window state and position is. Furthermore, the session manager makes it possible to save your desktop when you logout. Upon the next login it can automatically restore your desktop for you.</p>
<h3>Window manager</h3>
<p>The window manager controls the placement, movement and look of all windows and their controls (button, check box, etc). Its the one that draws the border around each window and adds the title bar. Additionally, the window manager enables you to tile, stack and move windows around.</p>
<h3>Desktop environment</h3>
<p>To have a fully functional graphical desktop you still need a bit more. For example an application menu, a task-bar panel showing running applications and notification icons. And then your basic suite of applications such as a file manager, terminal program, text editor, etc. The desktop environment combines all these parts. Its goal is to provide you with a cohesive and productive graphical user experience.</p>
<h2>Install the XFCE desktop components</h2>
<p>At this point you have a good understanding of what components you need, to install the XFCE desktop on your Raspberry PI. Time to get our hands dirty. We’ll install all the XFCE desktop components in one go on your Raspberry PI. This includes:</p>
<ul><li><em>Xorg</em> display server</li><li><em>lightdm</em> display manager</li><li><em>xfce4-session</em> session manager</li><li><em>xfwm4</em> window manager</li><li><em>xfce4</em> desktop environment</li></ul>
<p>Power up your Raspberry PI and login with your username and password at the console. Next, run the following command to install the XFCE desktop components on your Raspberry PI:</p>
<p><code>sudo apt install -y xserver-xorg xfce4 xfce4-goodies</code></p>
<figure><img loading="lazy" width="769" height="569" src="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/apt_xfce_install.png" alt="Terminal screenshot of installing the XFCE desktop related packages on the Raspberry PI. The following command is used: sudo apt install -y xserver-xorg xfce4 xfce4-goodies." srcset="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/apt_xfce_install.png 769w, https://www.pragmaticlinux.com/wp-content/uploads/2020/11/apt_xfce_install-300x222.png 300w" sizes="(max-width: 769px) 100vw, 769px"></figure>
<p>As you can see in the last line of the screenshot, all XFCE desktop components consume about 1 GB of disk space. With all the XFCE desktop components installed on your Raspberry PI, we continue with setting them up.</p>
<h2>Setup the XFCE desktop components</h2>
<p>In the previous section, we installed all XFCE desktop components on your Raspberry PI. As a next step we make sure the right desktop components are selected. If you started with a minimal install of the Raspberry PI operating system, this will most likely be the case already. However, if you previously installed a different desktop environment, we need to double-check this selection, to make sure it works for an XFCE desktop.</p>
<h3>Select the display server</h3>
<p>You probably only have one display server installed (<em>Xorg</em>), so you do not have to explicitly select one. However, it could be that you didn’t have a display sever installed before. In this case we need to verify that the display server gets started during boot.</p>
<p>Systemd should handle this for us. Without the presence of a display server, Systemd’s default boot target is the multi user shell. Also called <code>multi-user.target</code>. When installing a display server, Systemd’s default boot target should change to a graphical multi user shell. This one is called <code>graphical.target</code>.</p>
<p>To determine Systemd’s default boot target, run this command:</p>
<p><code>sudo systemctl get-default</code></p>
<figure><img loading="lazy" width="713" height="33" src="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/systemd_get_default.png" alt="Terminal screenshot that shows the output of running the &quot;sudo systemctl get-default&quot; command. It should output &quot;&quot;graphical.target&quot;." srcset="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/systemd_get_default.png 713w, https://www.pragmaticlinux.com/wp-content/uploads/2020/11/systemd_get_default-300x14.png 300w, https://www.pragmaticlinux.com/wp-content/uploads/2020/11/systemd_get_default-700x33.png 700w" sizes="(max-width: 713px) 100vw, 713px"></figure>
<p>It should output <code>graphical.target</code>. If it doesn’t, then you can set it manually by running the command:</p>
<p><code>sudo systemctl set-default graphical.target</code>.</p>
<h3>Select the display manager</h3>
<p>The following component to select is the display manager. We want to select <em>lightdm</em> as the display manager. Easily achieved by running the following command:</p>
<p><code>sudo dpkg-reconfigure lightdm</code></p>
<figure><img loading="lazy" width="416" height="23" src="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/select_display_manager.png" alt="Terminal screenshot that shows what command to run for selecting the lightdm display manager." srcset="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/select_display_manager.png 416w, https://www.pragmaticlinux.com/wp-content/uploads/2020/11/select_display_manager-300x17.png 300w" sizes="(max-width: 416px) 100vw, 416px"></figure>
<h3>Select the session manager</h3>
<p>Next we’ll go ahead and select the session manager. Type this command in the terminal:</p>
<p><code>sudo update-alternatives --config x-session-manager</code></p>
<figure><img loading="lazy" width="764" height="153" src="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/select_session_manager.png" alt="Terminal screenshot that shows how to select the session manager, with the help of the update-alternatives command. Make sure to select startxfce4 here and not xfce4-session." srcset="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/select_session_manager.png 764w, https://www.pragmaticlinux.com/wp-content/uploads/2020/11/select_session_manager-300x60.png 300w" sizes="(max-width: 764px) 100vw, 764px"></figure>
<p>On this screen we need to make sure <em>startxfce4</em> is selected as the session manager. Press <kbd>Enter</kbd> if startxfce4 is already selected, otherwise enter the number of the <em>startxfce4</em> session.</p>
<p>A bit odd, right? In an earlier section I mentioned that we want the <em>xfce4-session</em> session manager. The selection menu lists <em>xfce4-session</em>, so why not pick it? The <em>startxfce4</em> file consists of a script that initializes the XFCE session and under the hood calls the <em>xfce4-session</em> executable for us. This makes <em>startxfce4</em> the better option here.</p>
<h3>Select the window manager</h3>
<p>Continue with the selection of the window manager. Run the following command:</p>
<p><code>sudo update-alternatives --config x-window-manager</code></p>
<figure><img loading="lazy" width="805" height="55" src="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/select_window_manager.png" alt="Terminal screenshot that shows the update-alternatives command for selecting the xfwm4 window manager." srcset="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/select_window_manager.png 805w, https://www.pragmaticlinux.com/wp-content/uploads/2020/11/select_window_manager-300x20.png 300w, https://www.pragmaticlinux.com/wp-content/uploads/2020/11/select_window_manager-768x52.png 768w" sizes="(max-width: 805px) 100vw, 805px"></figure>
<p>On my Raspberry PI, <em>xfwm4</em> is the only available window manager. Therefore no additional configuration is needed.</p>
<h3>Select the desktop environment</h3>
<p>You select the desktop environment on the login screen. So now would be the right time to reboot our Raspberry PI and wait for the login screen to show up. On the top right corner of the screen, there is a little icon you can click. Select <em>Xfce Session</em> from the drop-down menu:</p>
<figure><img loading="lazy" width="200" height="96" src="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/select_desktop_environment.png" alt="Screenshot of the lightdm session manager that shows how to select Xfce Session on the login screen."></figure>
<h2>Configure the XFCE desktop</h2>
<p>At this point we completed installing and selecting the right components for the XFCE desktop on our Raspberry PI. In this section we’ll make some final configurations for our XFCE desktop. If you …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pragmaticlinux.com/2020/11/install-the-xfce-desktop-on-your-raspberry-pi/">https://www.pragmaticlinux.com/2020/11/install-the-xfce-desktop-on-your-raspberry-pi/</a></em></p>]]>
            </description>
            <link>https://www.pragmaticlinux.com/2020/11/install-the-xfce-desktop-on-your-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25191105</guid>
            <pubDate>Mon, 23 Nov 2020 20:06:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Speech Recognition and Audio Summarization API]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25190585">thread link</a>) | @robgehring
<br/>
November 23, 2020 | https://speechtext.ai/speech-recognition-api | <a href="https://web.archive.org/web/*/https://speechtext.ai/speech-recognition-api">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <h2>Quick and Simple Integration</h2>
            <p>Build accurate speech recognition applications in minutes. We take care of the complexity behind and wrap it in a few lines of code.</p>
        </div><div>
            <div>
                
            <div id="samples-content">
                
                <div id="one" role="tabpanel" aria-labelledby="one-tab">
                    <pre><code>
import requests
import json

secret_key = "SECRET_KEY"

# loads the audio into memory
with open("/path/to/your/file.mp3", mode="rb") as file:
  post_body = file.read()

API_URL = "https://api.speechtext.ai/recognize?"
header = {'Content-Type': "application/octet-stream"}

options = {
  "key" : secret_key,
  "language" : "en-US",
  "punctuation" : True,
  "speaker_detection": True,
  "format" : "mp3"
}
# send an audio file to SpeechText.AI
r = requests.post(API_URL, headers = header, params = options, data = post_body)
                      </code></pre>
                </div>
                <div id="two" role="tabpanel" aria-labelledby="two-tab">
                    <pre><code>
# create transcription task
curl -H "Content-Type:application/octet-stream" --data-binary @/path/to/your/file.m4a "https://api.speechtext.ai/recognize?key=SECRET_KEY&amp;language=en-US&amp;punctuation=true&amp;speaker_detection=true&amp;format=m4a"

# retrieve transcription results
curl -X GET "https://api.speechtext.ai/results?key=SECRET_KEY&amp;task=TASK_ID&amp;summary=true&amp;summary_size=15&amp;highlights=true&amp;max_keywords=10"

# get captions
curl -X GET "https://api.speechtext.ai/results?key=SECRET_KEY&amp;task=TASK_ID&amp;output=srt&amp;max_caption_words=10"

# process public URL
curl -X GET "https://api.speechtext.ai/recognize?key=SECRET_KEY&amp;url=PUBLIC_URL&amp;language=en-US&amp;punctuation=true&amp;speaker_detection=true&amp;format=mp3"
                    </code></pre>
                </div>
                <div id="three" role="tabpanel" aria-labelledby="three-tab">
                    <pre><code>
&lt;?php

$secret_key = "SECRET_KEY";

# loads the audio
$filesize = filesize('/path/to/your/file.m4a');
$fp = fopen('/path/to/your/file.m4a', 'rb');
// read the entire file into a binary string
$binary = fread($fp, $filesize);

# endpoint and options to start a transcription task
$endpoint = "https://api.speechtext.ai/recognize?key=".$secret_key."&amp;language=en-US&amp;punctuation=true&amp;speaker_detection=true&amp;format=m4a";
$header = array('Content-type: application/octet-stream');

# curl connection initialization
$ch = curl_init();

# curl options
curl_setopt_array($ch, array(
    CURLOPT_URL =&gt; $endpoint,
    CURLOPT_RETURNTRANSFER =&gt; true,
    CURLOPT_POST =&gt; true,
    CURLOPT_HEADER =&gt; false,
    CURLOPT_HTTPHEADER =&gt; $header,
    CURLOPT_POSTFIELDS =&gt; $binary,
    CURLOPT_FOLLOWLOCATION =&gt; true
));

# send an audio transcription request
$body = curl_exec($ch);

curl_close($ch);
                    </code></pre>
                </div>
                <div id="four" role="tabpanel" aria-labelledby="four-tab">
                    <pre><code>
import java.net.*;
import java.io.*;
import java.util.concurrent.TimeUnit;
import org.json.*;


public class Transcriber {

    public static void main(String[] args) throws Exception {
        String secret_key = "SECRET_KEY";
        HttpURLConnection conn;
        
        // endpoint and options to start a transcription task
        URL endpoint = new URL("https://api.speechtext.ai/recognize?key=" + secret_key +"&amp;language=en-US&amp;punctuation=true&amp;speaker_detection=true&amp;format=m4a");
        
        // loads the audio into memory
        File file = new File("/path/to/your/file.m4a");
        RandomAccessFile f = new RandomAccessFile(file, "r");
        long sz = f.length();
        byte[] post_body = new byte[(int) sz];
        f.readFully(post_body);
        f.close();
        
        // send an audio transcription request
        conn = (HttpURLConnection) endpoint.openConnection();
        conn.setRequestMethod("POST");
        conn.setRequestProperty("Content-Type", "application/octet-stream");
        
        conn.setDoOutput(true);
        conn.connect();
        OutputStream os = conn.getOutputStream();
        os.write(post_body);
        os.flush();
        os.close();
        
    }
}
                    </code></pre>
                </div>
            </div>
            </div>
        </div></div>]]>
            </description>
            <link>https://speechtext.ai/speech-recognition-api</link>
            <guid isPermaLink="false">hacker-news-small-sites-25190585</guid>
            <pubDate>Mon, 23 Nov 2020 19:22:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Saying “No” to Unethical Tasks]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25190536">thread link</a>) | @stargrave
<br/>
November 23, 2020 | https://emersion.fr/blog/2020/saying-no-to-unethical-tasks/ | <a href="https://web.archive.org/web/*/https://emersion.fr/blog/2020/saying-no-to-unethical-tasks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
	<nav><a href="https://emersion.fr/">home</a> ·
	<a href="https://emersion.fr/blog">blog</a> ·
	<a rel="me" href="https://github.com/emersion">github</a> ·
	<a rel="me" href="https://sr.ht/~emersion">sourcehut</a> ·
	<a href="https://emersion.fr/.well-known/openpgpkey/hu/dj3498u4hyyarh35rkjfnghbjxug6b19" title="PGP key 34FF9526CFEF0E97A340E2E40FDE7BE0E88F5E48" download="emersion.pgp">pgp</a> ·
	<a rel="me" href="https://octodon.social/@emersion">mastodon</a> ·
	<a href="https://sourcehut.org/consultancy/">consulting</a> ·
	<a rel="me" href="http://emersion-fr.deviantart.com/">deviantart</a>
</nav>


	<main>


<article lang="en">
	<header>
		
		<time datetime="2020-11-23T00:00:00+02:00">2020-11-23</time>
	</header>

	<p>Back in spring 2019, I was a student working as an intern at the Intel Open
Source Graphics Center in Finland. I was mainly focused on improving
<a href="https://gitlab.freedesktop.org/drm/igt-gpu-tools/">igt-gpu-tools</a>, the test suite that runs each time a patch is submitted for
the i915 kernel driver. I really liked the work I was doing there, and enjoyed
interacting with all of the people on site. While I was there, I had an
opportunity to say “no” to an assigned task that I considered unethical.</p>
<p>Naturally, lots of Intel kernel developers were working on fixing bugs and
implementing new features. When a developer wants to add a new feature to their
kernel driver, they also need to provide a patch for a user-space program to
exercise the feature in a real-world scenario and prove that the new user-space
API is sensible<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. For instance, when adding HDR support to i915, the kernel
developers worked with the Kodi team.</p>
<p>At that time, I had just been nominated as release manager for the Wayland and
Weston projects. Additionally, some Intel engineers were working on upstreaming
Weston patches to add a new feature to their driver. In fact, the kernel
patches were ready to be merged and only blocked by the user-space
requirements. Some deadlines were set too, so it was important to get the
patches merged in a timely manner. My manager asked me to help with the
upstreaming process. That was a pretty good idea – because my experience could
help Intel developers to learn how to contribute to Weston, and because I like
mentoring people. So what was the catch?</p>
<p>It turned out the feature being developed was <a href="https://en.wikipedia.org/wiki/High-bandwidth_Digital_Content_Protection">HDCP</a>. It’s a form of <abbr title="Digital Restrictions Management">DRM</abbr> that encrypts the video
stream between the GPU and the screen. I’m personally not okay with DRM in
general, and I find DRM to be unethical. I’m not going to start to argue why I
feel this way, because it doesn’t really matter in the context of this article.
Feel free to replace DRM with whatever you find unethical.</p>
<p>So, I started participating in meetings and discussing how to get the
HDCP patches merged. I wasn’t very comfortable with the whole situation, and
tried to stay away from it when possible. I considered saying “no”, but I was
scared. I was only working at Intel for a few weeks, I was still a student, I
didn’t know my teammates and managers too well, and I was interested in
eventually getting a job offer. I just continued as if nothing was wrong.</p>
<p>At some point, after asking advice and discussing with some friends, I realized
that I ought to speak up. If I didn’t say “no” this time, it would get a lot
more difficult to say “no” the next time. So I ignored the anxiety and clumsily
explained to my manager that I’d like to stop working on HDCP.</p>
<p>To my surprise, my manager just said that it was fine, that there was no
problem. After this event, absolutely nothing else changed, and at some point I
even got an employment offer. When I recall it now, I can only tell myself that
it was a lot of fuss for nothing. In hindsight, I should’ve been less scared
and said no earlier, but in these situations it’s easy to imagine nightmare
scenarios in your head!</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>See <a href="https://dri.freedesktop.org/docs/drm/gpu/drm-uapi.html#open-source-userspace-requirements">the kernel docs</a> for more info. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>


	
	
	
</article>

	</main>

	
</div></div>]]>
            </description>
            <link>https://emersion.fr/blog/2020/saying-no-to-unethical-tasks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25190536</guid>
            <pubDate>Mon, 23 Nov 2020 19:19:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Queue for Effectful Breadth-First Traversals]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25190094">thread link</a>) | @headalgorithm
<br/>
November 23, 2020 | https://doisinkidney.com/posts/2020-11-23-applicative-queue.html | <a href="https://web.archive.org/web/*/https://doisinkidney.com/posts/2020-11-23-applicative-queue.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            

            <p>
    Posted on November 23, 2020
</p>



<p>We pick up the story again at the question of a breadth-first (Applicative) traversal of a rose tree <span data-cites="gibbons_breadthfirst_2015">(Gibbons <a href="#ref-gibbons_breadthfirst_2015" role="doc-biblioref">2015</a>)</span>. In the last post, I finally came up with an implementation I was happy with:</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>data</span> <span>Tree</span> a <span>=</span> a <span>:&amp;</span> [<span>Tree</span> a]</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span>bft ::</span> <span>Applicative</span> f <span>=&gt;</span> (a <span>-&gt;</span> f b) <span>-&gt;</span> <span>Tree</span> a <span>-&gt;</span> f (<span>Tree</span> b)</span>
<span id="cb1-4">bft f (x <span>:&amp;</span> xs) <span>=</span> liftA2 (<span>:&amp;</span>) (f x) (bftF f xs)</span>
<span id="cb1-5"></span>
<span id="cb1-6"><span>bftF ::</span> <span>Applicative</span> f <span>=&gt;</span> (a <span>-&gt;</span> f b) <span>-&gt;</span> [<span>Tree</span> a] <span>-&gt;</span> f [<span>Tree</span> b]</span>
<span id="cb1-7">bftF t <span>=</span> <span>fmap</span> <span>head</span> <span>.</span> <span>foldr</span> (<span>&lt;*&gt;</span>) (<span>pure</span> []) <span>.</span> <span>foldr</span> f [<span>pure</span> ([]<span>:</span>)]</span>
<span id="cb1-8">  <span>where</span></span>
<span id="cb1-9">    f (x <span>:&amp;</span> xs) (q <span>:</span> qs) <span>=</span> liftA2 c (t x) q <span>:</span> <span>foldr</span> f (p qs) xs</span>
<span id="cb1-10">    </span>
<span id="cb1-11">    p []     <span>=</span> [<span>pure</span> ([]<span>:</span>)]</span>
<span id="cb1-12">    p (x<span>:</span>xs) <span>=</span> <span>fmap</span> (([]<span>:</span>)<span>.</span>) x <span>:</span> xs</span>
<span id="cb1-13"></span>
<span id="cb1-14">    c x k (xs <span>:</span> ks) <span>=</span> ((x <span>:&amp;</span> xs) <span>:</span> y) <span>:</span> ys</span>
<span id="cb1-15">      <span>where</span> (y <span>:</span> ys) <span>=</span> k ks</span></code></pre></div>
<p>It has the correct semantics and asymptotics.</p>
<div id="cb2"><pre><code><span id="cb2-1">tree <span>=</span></span>
<span id="cb2-2">    <span>1</span> <span>:&amp;</span></span>
<span id="cb2-3">      [ <span>2</span> <span>:&amp;</span></span>
<span id="cb2-4">          [ <span>5</span> <span>:&amp;</span></span>
<span id="cb2-5">              [ <span>9</span>  <span>:&amp;</span> []</span>
<span id="cb2-6">              , <span>10</span> <span>:&amp;</span> []]</span>
<span id="cb2-7">          , <span>6</span> <span>:&amp;</span> []]</span>
<span id="cb2-8">      , <span>3</span> <span>:&amp;</span> []</span>
<span id="cb2-9">      , <span>4</span> <span>:&amp;</span></span>
<span id="cb2-10">          [ <span>7</span> <span>:&amp;</span></span>
<span id="cb2-11">              [ <span>11</span> <span>:&amp;</span> []</span>
<span id="cb2-12">              , <span>12</span> <span>:&amp;</span> []]</span>
<span id="cb2-13">          , <span>8</span> <span>:&amp;</span> []]]</span>
<span id="cb2-14">          </span>
<span id="cb2-15"><span>&gt;&gt;&gt;</span> bft <span>print</span> tree</span>
<span id="cb2-16"><span>1</span></span>
<span id="cb2-17"><span>2</span></span>
<span id="cb2-18"><span>3</span></span>
<span id="cb2-19"><span>4</span></span>
<span id="cb2-20"><span>5</span></span>
<span id="cb2-21"><span>6</span></span>
<span id="cb2-22"><span>7</span></span>
<span id="cb2-23"><span>8</span></span>
<span id="cb2-24"><span>9</span></span>
<span id="cb2-25"><span>10</span></span>
<span id="cb2-26"><span>11</span></span>
<span id="cb2-27"><span>12</span></span>
<span id="cb2-28">() <span>:&amp;</span></span>
<span id="cb2-29">   [ () <span>:&amp;</span></span>
<span id="cb2-30">        [ () <span>:&amp;</span></span>
<span id="cb2-31">             [ () <span>:&amp;</span> []</span>
<span id="cb2-32">             , () <span>:&amp;</span> []]</span>
<span id="cb2-33">        , () <span>:&amp;</span> []]</span>
<span id="cb2-34">   , () <span>:&amp;</span>   []</span>
<span id="cb2-35">   , () <span>:&amp;</span></span>
<span id="cb2-36">        [ () <span>:&amp;</span></span>
<span id="cb2-37">             [ () <span>:&amp;</span> []</span>
<span id="cb2-38">             , () <span>:&amp;</span> []]</span>
<span id="cb2-39">        , () <span>:&amp;</span> []]]</span></code></pre></div>
<p>But it’s quite difficult to understand, and doesn’t lend much insight into what’s going on with the whole “breadth-first” notion. The technique the function uses also isn’t reusable.</p>
<p>A much nicer function uses the <code>Phases</code> Applicative <span data-cites="easterly_functions_2019">(Easterly <a href="#ref-easterly_functions_2019" role="doc-biblioref">2019</a>)</span>:</p>
<div id="cb3"><pre><code><span id="cb3-1"><span>bft ::</span> <span>Applicative</span> f <span>=&gt;</span> (a <span>-&gt;</span> f b) <span>-&gt;</span> <span>Tree</span> a <span>-&gt;</span> f (<span>Tree</span> b)</span>
<span id="cb3-2">bft f <span>=</span> runPhases <span>.</span> go</span>
<span id="cb3-3">  <span>where</span></span>
<span id="cb3-4">    go (x <span>:&amp;</span> xs) <span>=</span> liftA2 (<span>:&amp;</span>) (<span>Lift</span> (f x)) (later (<span>traverse</span> go xs))</span></code></pre></div>
<p>But this function is quadratic.</p>
<p>So the task for this post today is to derive a type like the <code>Phases</code> type with a <code>later</code> operation, but which has the appropriate performance characteristics. At the end I’ll look into what the theoretical properties of this type are.</p>

<p>At its core, the <code>Phases</code> type is basically a free Applicative <span data-cites="capriotti_free_2014">(Capriotti and Kaposi <a href="#ref-capriotti_free_2014" role="doc-biblioref">2014</a>)</span>. I’ll reimplement it here as a slightly different free Applicative (one that’s based on <code>liftA2</code> rather than <code>&lt;*&gt;</code>):</p>
<div id="cb4"><pre><code><span id="cb4-1"><span>data</span> <span>Free</span> f a <span>where</span></span>
<span id="cb4-2">  <span>Pure</span><span> ::</span> a <span>-&gt;</span> <span>Free</span> f a</span>
<span id="cb4-3">  <span>Lift</span><span> ::</span> (a <span>-&gt;</span> b <span>-&gt;</span> c) <span>-&gt;</span> f a <span>-&gt;</span> <span>Free</span> f b <span>-&gt;</span> <span>Free</span> f c</span>
<span id="cb4-4">  </span>
<span id="cb4-5"><span>lower ::</span> <span>Applicative</span> f <span>=&gt;</span> <span>Free</span> f a <span>-&gt;</span> f a</span>
<span id="cb4-6">lower (<span>Pure</span> x) <span>=</span> <span>pure</span> x</span>
<span id="cb4-7">lower (<span>Lift</span> f x xs) <span>=</span> liftA2 f x (lower xs)</span></code></pre></div>
<p>The key with the <code>Phases</code> type is to observe that there’s actually two possible implementations of <code>Applicative</code> for the <code>Free</code> type above: one which makes it the “correct” free applicative:</p>
<div id="cb5"><pre><code><span id="cb5-1"><span>instance</span> <span>Applicative</span> (<span>Free</span> f) <span>where</span></span>
<span id="cb5-2">  <span>pure</span> <span>=</span> <span>Pure</span></span>
<span id="cb5-3"></span>
<span id="cb5-4">  liftA2 c (<span>Pure</span> x) ys <span>=</span> <span>fmap</span> (c x) ys</span>
<span id="cb5-5">  liftA2 c (<span>Lift</span> f x xs) ys <span>=</span> <span>Lift</span> (\x (y,z) <span>-&gt;</span> c (f x y) z) x (liftA2 (,) xs ys)</span></code></pre></div>
<p>And then one which <em>zips</em> effects together:</p>
<div id="cb6"><pre><code><span id="cb6-1"><span>instance</span> <span>Applicative</span> f <span>=&gt;</span> <span>Applicative</span> (<span>Free</span> f) <span>where</span></span>
<span id="cb6-2">  <span>pure</span> <span>=</span> <span>Pure</span></span>
<span id="cb6-3">  </span>
<span id="cb6-4">  liftA2 c (<span>Pure</span> x) ys <span>=</span> <span>fmap</span> (c x) ys</span>
<span id="cb6-5">  liftA2 c xs (<span>Pure</span> y) <span>=</span> <span>fmap</span> (<span>flip</span> c y) xs</span>
<span id="cb6-6">  liftA2 c (<span>Lift</span> f x xs) (<span>Lift</span> g y ys) <span>=</span> </span>
<span id="cb6-7">    <span>Lift</span> </span>
<span id="cb6-8">      (\(x,y) (xs,ys) <span>-&gt;</span> c (f x xs) (g y ys)) </span>
<span id="cb6-9">      (liftA2 (,) x y) </span>
<span id="cb6-10">      (liftA2 (,) xs ys)</span></code></pre></div>
<p>This second instance makes the <code>Free</code> type into not a free Applicative at all: instead it’s some kind of Applicative transformer which we can use to reorder effects. Since effects are combined only when they’re at the same point in the list, we can use it to do our breadth-first traversal.</p>
<p>As an aside, from this perspective it’s clear that this is some kind of <code>FunList</code> <span data-cites="vanlaarhoven_nonregular_2009">(van Laarhoven <a href="#ref-vanlaarhoven_nonregular_2009" role="doc-biblioref">2009</a>)</span>: this opens up a lot of interesting curiosities about the type, since that type in particular is quite well-studied.</p>
<p>Anyway, we’re able to do the <code>later</code> operation quite simply:</p>
<div id="cb7"><pre><code><span id="cb7-1"><span>later ::</span> <span>Free</span> f a <span>-&gt;</span> <span>Free</span> f a</span>
<span id="cb7-2">later <span>=</span> <span>Lift</span> (<span>const</span> <span>id</span>) (<span>pure</span> ())</span></code></pre></div>

<p>The problem at the moment is that the Applicative instance has an <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="script"><mi>𝒪</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>n</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{O}(n)</annotation></semantics></math> <code>liftA2</code> implementation: this translates into an <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="script"><mi>𝒪</mi></mstyle><mo stretchy="false" form="prefix">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{O}(n^2)</annotation></semantics></math> traversal overall.</p>
<p>If we were working in a more simple context of just enumerating the contents of the tree, we might at this point look to something like difference lists: these use the cayley transform on the list monoid to turn the append operation from <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="script"><mi>𝒪</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>n</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{O}(n)</annotation></semantics></math> to <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="script"><mi>𝒪</mi></mstyle><mo stretchy="false" form="prefix">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{O}(n^2)</annotation></semantics></math>. It turns out that there is a similar cayley transformation for Applicative functors <span data-cites="rivas_notions_2014 rivas_monoids_2015">(Rivas and Jaskelioff <a href="#ref-rivas_notions_2014" role="doc-biblioref">2014</a>; Rivas, Jaskelioff, and Schrijvers <a href="#ref-rivas_monoids_2015" role="doc-biblioref">2015</a>)</span>:</p>
<div id="cb8"><pre><code><span id="cb8-1"><span>newtype</span> <span>Day</span> f a <span>=</span> <span>Day</span> {<span> runDay ::</span> <span>∀</span> b<span>.</span> f b <span>-&gt;</span> f (a, b) }</span>
<span id="cb8-2"></span>
<span id="cb8-3"><span>instance</span> <span>Functor</span> f <span>=&gt;</span> <span>Functor</span> (<span>Day</span> f) <span>where</span></span>
<span id="cb8-4">  <span>fmap</span> f xs <span>=</span> <span>Day</span> (<span>fmap</span> (first f) <span>.</span> runDay xs)</span>
<span id="cb8-5">  </span>
<span id="cb8-6"><span>instance</span> <span>Functor</span> f <span>=&gt;</span> <span>Applicative</span> (<span>Day</span> f) <span>where</span></span>
<span id="cb8-7">  <span>pure</span> x <span>=</span> <span>Day</span> (<span>fmap</span> ((,) x))</span>
<span id="cb8-8">  liftA2 c xs ys <span>=</span></span>
<span id="cb8-9">    <span>Day</span> (<span>fmap</span> (\(x,(y,z)) <span>-&gt;</span> (c x y, z)) <span>.</span> runDay xs <span>.</span> runDay ys)</span></code></pre></div>
<p>And with this type we can implement our queue of applicative effects:</p>
<div id="cb9"><pre><code><span id="cb9-1"><span>type</span> <span>Queue</span> f <span>=</span> <span>Day</span> (<span>Free</span> f)</span>
<span id="cb9-2"></span>
<span id="cb9-3"><span>runQueue ::</span> <span>Applicative</span> f <span>=&gt;</span> <span>Queue</span> f a <span>-&gt;</span> f a</span>
<span id="cb9-4">runQueue <span>=</span> <span>fmap</span> <span>fst</span> <span>.</span> lower <span>.</span> <span>flip</span> runDay (<span>Pure</span> ())</span>
<span id="cb9-5"></span>
<span id="cb9-6"><span>now ::</span> <span>Applicative</span> f <span>=&gt;</span> f a <span>-&gt;</span> <span>Queue</span> f a</span>
<span id="cb9-7">now xs <span>=</span> <span>Day</span> \<span>case</span></span>
<span id="cb9-8">  <span>Pure</span> x      <span>-&gt;</span> <span>Lift</span> (,) xs (<span>Pure</span> x)</span>
<span id="cb9-9">  <span>Lift</span> f y ys <span>-&gt;</span> <span>Lift</span> (\(x,y) z <span>-&gt;</span> (x, f y z)) (liftA2 (,) xs y) ys</span>
<span id="cb9-10"></span>
<span id="cb9-11"><span>later ::</span> <span>Applicative</span> f <span>=&gt;</span> <span>Queue</span> f a <span>-&gt;</span> <span>Queue</span> f a</span>
<span id="cb9-12">later xs <span>=</span> <span>Day</span> \<span>case</span></span>
<span id="cb9-13">  <span>Pure</span> x      <span>-&gt;</span> <span>Lift</span> (<span>const</span> <span>id</span>) (<span>pure</span> ()) (runDay xs (<span>Pure</span> x))</span>
<span id="cb9-14">  <span>Lift</span> f y ys <span>-&gt;</span> <span>Lift</span> (\x (y,z) <span>-&gt;</span> (y, f x z)) y (runDay xs ys)</span></code></pre></div>
<p>As expected, this gives us the clean implementation of a breadth-first traversal with the right asymptotics (I think):</p>
<div id="cb10"><pre><code><span id="cb10-1"><span>bft ::</span> <span>Applicative</span> f <span>=&gt;</span> (a <span>-&gt;</span> f b) <span>-&gt;</span> <span>Tree</span> a <span>-&gt;</span> f (<span>Tree</span> b)</span>
<span id="cb10-2">bft f <span>=</span> runQueue <span>.</span> go</span>
<span id="cb10-3">  <span>where</span></span>
<span id="cb10-4">    go (x <span>:&amp;</span> xs) <span>=</span> liftA2 (<span>:&amp;</span>) (now (f x)) (later (<span>traverse</span> go xs))</span></code></pre></div>
<p>(it’s worth pointing out that we haven’t actually used the applicative instance on the free applicative at any point: we have inlined all of the “zipping” to make it absolutely clear that everything has stayed linear).</p>

<p>I have yet to really dive deep on any of the theory involved in this type, I just quickly wrote up this post when I realised I was able to use the cayley transform from the mentioned papers to implement the proper breadth-first traversal. It certainly seems worth looking at more!</p>



        </div></div>]]>
            </description>
            <link>https://doisinkidney.com/posts/2020-11-23-applicative-queue.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25190094</guid>
            <pubDate>Mon, 23 Nov 2020 18:45:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[John Kerry, Biden's special envoy on climate was a leading anti-nuclear force [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25190008">thread link</a>) | @rllearneratwork
<br/>
November 23, 2020 | http://www.thesciencecouncil.com/pdfs/PlentifulEnergy.pdf | <a href="https://web.archive.org/web/*/http://www.thesciencecouncil.com/pdfs/PlentifulEnergy.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>üDHYN2ä�°�´ä3ZH˜P¯HÔØo]Ž	oÍœ=;„–çYžk·úä”¯…v¯ŽH@VÍg)'u
KËÎ	kX�rd
ÈŠï·ËÏ½g‹¹‹2•$0¡AË
*éín¡ejêukÐäd,3�¢÷=ÏU„9ƒ7&amp;S¿òÌS"”q	¢ëòæÔL²B\Çêc­
ï“‹\´böWó&gt;†·–®±¥:máÛl•'&gt;.!³Å
êˆˆ£¦þ9”ëkzLN�u‹¶Î�hFÄ}8ƒ/ƒD=+Bò|aäy9*°¡ˆî÷9Dò¹¸´ìÊêæ-2(¢ˆôÔv²°-É”¸FÈµ+›¸ø¨&nbsp;8Di‰™,gP“ôyG˜•$ÕOŽN"Ú&amp;xy¦6—Ö×jž¬a†æ‡qQ€‚ÆB\Þæ»ˆ.]P.Þ‘ZS}Î]ˆS‰¨ òaÙsŒìUØ«±Wb®Å]Š»l
à%WäUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUpªìUØ«±Wb®Å]Š»v*ØèqV2
rÕov$+�¦E]„*á·\iW�ìBÛ
¶*ÞWaVë¾jW�ò*ìU°0ªà1A_L
í±Kª1VëíŠ®›®*Þø«·ÅZ©ñÅmÛøŸ»wßŠµþ}qWŠi¿£·÷b­WåŠ\UÕÅ]SŠ»|VÝ÷â¶ï¿·}ø­»ïÅmÕ¦*êâ®®*ßÝŠµôb–þœUªVÛßkèÅ]ôb—mŠ7u1KT8¡±p-¯ãLPÙZR„áŠµCãŠ»qÓvþª­¹ýâJ	¯€ÀSºc.¦·ÊHmÇáÛä2&lt;4Øei…¬_Y³ºôáVéñ*¢•ÜÑg`Ò…„²Æ
‡ø‡ÄÃéÛˆÉ�Üyq–sqWf$½NÂ•×¶@dm8væÇf¾¼�@YÉPÝWj‘ãã“á
&amp;D!/u½ôù¢+ §%Zî|p�H”ø�ˆ!�5&nbsp;÷®ô?)ù‚àI"M%"êXmCNÿ&lt;£$¼OVuaæÕŠS„²hr£�ÉŽ¢ŠeúnÒwhÊò
×gâƒ“Ëvw2úà=˜($wï’!‰Â	µ+�&amp;k‰•âmãj†'zwçˆ•"P$£ÓPhÃÃ"�AÜûŸá‚™‰ÖÈ[›9®Ê±�2�Ï°Â
112Zmæµ#‰&nbsp;n˜óZ!‚ùËQ%#·zò�§l»\]Lú0hu­øúmöNÕËLmÅ!4Ï;´’³“’˜“jXPìUØ«±Wb®Å]Š®Ç"J®À®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±WR¸ªð)Š·Š»v*ìUØ«±Wb®Å]Š¶:U‹LµUøªÒqV†xÀ‹vH!°iŠ¯ÈÚ»
®ëóÀ«†*ì*ìi@]Z|°ÒipÈ¡v(l}8m6ØÀ‚¿kZn¸ÒZ¯¾UÀŒi�%ÕÒ]\	j¸i
õí�-}¡½üqK¾œiZÛßwÑŠº¿,UÕÅ[©ÅZßvø«±Wb®ßWoŠº§uqWWåŠ»lUÛxâ­ïãŠ»VÝ_ž*êûâ®®*ÝqWSÛ·Ç-ÔÅm¼Uß~(u}ÿRêûâ­ïìqWT÷ÒmÕñ¤ÚàiÐ‘_¢¸)W™\ðøÏÁö}±M²»_5ÏÄ¥ÀFPû=r³ŒtoŽsÕ_ëú]ú˜�}3½(¼W—Cïƒ„„ñFLRí#†gº×jƒ,´Kb†4®Ý1b¹’&nbsp;1õ8²m}%´œ�Ä;ƒ€ÆÙ	S;Ñ¤iÙJš‡ZŠœª[98Í½#Oª
Å|+”ÉÌ…¦ñÄ–a¤w?ûöÈól…réxÞ’Ò½yR¸FÌdx¶J×N»·wd î7¯l<a‡ tÒÝ],¬¨ËÀ�ytb?®k`À’^gæx™&ç)ÝgÀãéÌŒeÁÌ7Ý‹å­Å]Š»v*ìuØ«±uàs"j·�]Š»v*ìuØ«±wb®Å]Š»v*ìuØ«±wb®Å]Š»v*ìuØ«±wb®Å]Š»v*ìuØ«±wb­�\u})Š»v*ìuØ«±wb®Å]Š»v*Øèqv-–«\±uÀb®Å¸…ø«°Ú®˜)wwzv*ß]ñk�®+mâ«…*Ø4í�!u|+n&˜­º¾øv×w97Šm½¼1¥ke7zxci^4Å²k‹&±e:žØ¦�l­â–±wb‹oµŠÅ-ac±¥owÑŠµŠ»w`vð««�]Š»lußn)v*ìuÕÅ[¯Ëu}±w}¡¾˜«`â®®n¸rî]6À®¨ðÂ­ôí�4ŸÁå�béu¢�ø±j‰ßa�3¸`‘ä·ü="|C•‹™CBâ?…vÇŒ#Á(7Ò¯PU­&amp;´¯ý0ñ'îD.“¨K" e¼¦?;ü°qør!eÖ…{c="" \k="" tn›Ôý#¶0vx¥em¬Ç“Ô�p–1Ý0¾Ó¡‚$xå-zÔÒ«ýr1“9@�€m,="">&nbsp;Œ²)âXŸ:a,h‘hR
á¶.®Vúâ�SXgºÓÕ‰	ËcØüŽB�l³Ú/3\¢¡f?k±¥0a˜ÎCØm/â½´�äañ b	Þ‡1H¢ìc! ™[›rJDÃ•:dK8×ER“
l:õ']Ð÷RzjDŒ'D‹Ä|á kÒ§—%úq;æ^.N³PwbYkŽìUØ«±Wb®Å[¸-W…ðÈ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØªà1UØ«±Wb®Å]Š»v*ìUØ«±Wb®Å[*Ä¹W-Wb«�ÅŠìUØªàpR·Š·…W�+«Š·R1Vúï\QkÆØk«ŠµSãŠWãŠ)v6®Åm±…mv
E·ŠmØ­µÓ¾(µÀûáO5Ã!¼SNÀ—b—uÃHuq¥·cKnÆ–ÝŠÂ­×v(k®*ê{œUßN)vþ8¡¼RÕ}±Vê0RÛ±¤Û±Wb®Å[Å]¾wÑŠÛ¾ŒVÛÛ¶ëŠÛ�oj˜­7Š¸mŠipr:©ö‘¡=RÒB¡ˆµ*}»ä%][q‰L’7_Ð‘ÞÜ+Æä–0·"	Ç]¾YY”eÍ¼C&amp;&gt;J¾Uó&amp;£-ÃC&lt;†tU,ÂAV^Û¸ä€èœäMÞ§Ãp©'¦Ë]ÅiOžùŽ\ðA]sci¨BÐJŠÈÛ�E1²ÄHQJž+;HVÉ&gt;1Àµ${œ–å�;RC«yJÎxä{6=jÁëAò§L”r‘Í§&amp;y1½;O½±w¶1,±Újÿ3–Hƒ»L!(ì’ëZcZ^ëÄ0jÐûŒœ%myaL\¡^»m\±&nbsp;®…KÈŠ©Ì±/‰=±)¯VÓ¤Óm£våNê¥^ª	ß§ZøåQ•�œœ�á±¨¢ÉKÕ˜ß®Ytã�{=Yt	­=0²¨&nbsp;W‘ßïþŒgn„Bo§C»3MÉ�Ø
©L‰l€GÝùŽZG!åã¾ã…³–`6C
VßQNU­
=ððÓ1&amp;æ­#mF	~*�"·sØ�é–ãŸG&gt;0GyÞd8nÅ]Š»\Š–Ðu8-4¾(šSEÄ•Ñ)e4…BFÍ]¶•ÈZDIFÁ¥;0*§zP“ø`2d1¬“Kq4±«rµ�kÐ|ñâGék+!£�É1[ŠŠ»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUxÅ[Å]Š»v*ìUØ«±Wb®Å]Š»v*ìU±Ðâ¬@e©\q`ìUx5Å[Å]Š®
‚•ß†laUààC{ckk«L¶ëL+mà¤:¸U¼R¸ØÒ¯¾*ê�UÀâ›\(]_li]_lUÕöÅ[Òðq[okok¦4†ª1Mº¸¡Ûâ­b­â­mŠ»lUÛb®Å]Š·¾*êâ­õÅ6ìUÕ8­:¸«x
mØÒÛ±VÀÀ‹]LU¯óëŠ»sÜb¥ßF*î½Ž*ØÅ!u1K†Ä+íã�Y&gt;•gi«¹FOM€ø¨W"bßŽ"läêQhÑ ø™�6Ê¸x·._&nbsp;¯oæ±"�Ö&nbsp;î
âI=pi�$ÚÞ].êO\ÛzrRÊhÇçN¹a°“t…Õµ·à°’tðÃÛ“®HEÔn	+AÓ¾<e–Øê)z¡ cu¬Šr#="">%ì³G!•HéBûTÅH6‹Ajªçs��¤‹XÑÒö7d‘A¡â}òq•5dÇÄ+I++ª‡CÄ�kZf\C«Ÿ4N�f×WšñPã“@=ðLÐN8Ùz-ÚAþƒxIïâ&gt;@Ûpç–ÅUNÒáX.¡‡	À£õ¨ÜxwñÁ¼¹-F�Í”4Ë¨&nbsp;ôœz}�ˆÈro¾.Lzî5ÓËI»©ÜW®HnÓ!Âó½GRúÌü�‡§ß—Æ49ÎÊ…†©-¼‡‰Øœ2�¢!“Ïpu4H›ábA»r÷ÊÀ¦òx¶N%ò¢Ïõ5”)ÂÐ{íÜdFFÃ§°óû½4é×
k,lå�ÂËÝ|E?¼J÷q%EÖrzo F¤dsÿ&amp;½ÈáâaÂSÿ-h±ê2º"âHíSóÈd�rnÃ‹‹›3ŸÉ‘NPÃEJ

Àñ¦R2Ó�t×É}—•9$3Ä¾Ÿ‚Ôbrw,pW4ÌýVÇŠ'ÙZÒ½A9Ë=¢å™J1×¹â7Å ¤rÜÁk*½Äh)^ÕÉ|šŒ€;¥÷�i~ÃàVð;d…†"LNúÖ(‹q¨¡5éí–Ñ(€”dš�Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š¶qUàSv*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å[*ÃÎZÄ–Á®)]ŠŠ¯v*ï–\n¸¢Ûs^7_|*à}±VëŠ®¯¾*Õp«uÅm°k�[ÅÝq[n¸iy®À¶ìVÛ±KuÅBêûâ¥¼U¼U¬UØ««ŠµË
µ\UÛâ®ßW}8«©ïŠº‡ÇWoŠº¸ªêàWb®Å[®*ØÅ]ŠmØ­º˜«€À®À†ñWWn¸¥ÕÅ[ëŠº¸­·Šmºâ©Å•òXE'ï\P´Èm°—C-Û9i%vfo~¸i�RºÚþHÛw ×­11LgLšÇSæûµ[ç×+1nŒÙ-¼ÁÃ,‹Us•�ßŒhL

�»llê”d¹–À• Ð¯|5ÞÄ’9"l|Â×RzN­
ˆqO§å‰…2†kÙ1�èŽ2(p+×¨È
™ÈZE},º[ªÎßT–¨¨ê¿†XT‰�7›\F—SH-•�ÙÉFÔ9x47pÈ³³-òŽ�ûÇrò±×ÔŒÔ~ó¶þVIÖÎFŸ–ïSº{+&gt;!ã�àPÕëNÝzæ8²ç"&nbsp;'Ó5�°LQë¿{ŒwŠÜg±E
"�X§Aƒ‹½&gt;žsæ{Hì”&nbsp;rÌzï^¹~3nxð¼Ü‚�P2÷	Oâ��î
p«:Òîmõ"Š[„&nbsp;
½ÆQ C•		½$HÆ4GnÃ)§6Ô^K{F…f+öˆ©N&lt;ÐH[‹K9íîJ¯8
Ä}Õú0‚CD|Õ´ÍêEª²ñý¥Ø\�¬1ð„ÚI,AÛ"ÌšA]j*Upi„2›Ïu§2’Ç/ˆq$wVÓµ|nGÏ¦	E”'L‘DZ¼%Uî§üö9_&amp;í¦v^Zµ†F•j@èˆùäŽBXÇ±íkI�ÆTP¿.tblœdÓ—h�IR¤2õk‹JX¡Ø«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ØªüUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ØèqV–±o\*»j¸ªþ¸UÕÀ‡á…U¦.®n¸«uÀ‹vlØªá¶Ø«xì)·W
WÔ`¤:¸««Š®_Ë†«í�]\*ØlUuq¤7SáŠ]¾*ê{â®¦(¶ñ[j¸­º¸«UÆ•ºûãKM�-7\i]\mm¼VÚ§†)uqUÕÅ\p%Ø¡ºœUÜ±WrÁJÝ}±WTøb‹vþ¦Ý¿†*êûb«�]·ŽÛ±¥¶€¦)v+KÑøÐž,ûð¡±¾)´ÃLt[”.h£©ùdeÉž3»8·×ôûC@Îæ½ú|¤À—(eˆL-üÃo|áOæî0tÌfP—Ì6ñ&nbsp;Z©¦Ûáà(9€bóë¿é
è%
A=k–4K.ìëJK{øã¹–èòPQM²©ØÙËÇRÜ”×V³µžÝ�ÍP¹&lt;‘SË1¤Ý¢ÈH„µy~Ð1Ó2.Ã‚z+j0XÁ[Ç­ö� *OË¾P#|ÜÎ1³×íní�\3±Sµ+^#,�
9A±u	b�H¬AµËm¤L†_gæ»¢¥ur£Œ7Ç9S–)575¯‰Â
 Ž%í&nbsp;ÅÚmúÓø@$Ú�ªFÜTvë“‰kœT,¬_yÐ®â�p’ˆA•Újò˜JÈ5Ûnß&lt;¨Å¾9
'öÖë|ŠY¸°=òÓhIÄ:hC8ý²Ø �B`ŽŠõ§|¹0�OT�ÝÓ²�ÈËcs,mï$%˜¾YÂÒd•Ks']é’�“PjB#ñ¥q1@�"¢ÖÍ›ó€•&gt;íƒ‚ù²xy#fó�Äª€ù	‘Ô’€—Ì2NjÀÔt5É09‰S–æ€ÒÆCßÇS wH˜Ô““j[ŠŠ»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØªà1UØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«c¡ÅXXËX¯Å]Š¶]�Z­1Bþ¸VéØ±n¸ªìPìB·Ë
%up1w\RØðÂ«¾x«†[}0­¶+k¾ünúqVë…6¸T¯®·W·WuqH+‡Ó…fë�]ZcKNÆ•¯§
-ªâ¶êâ®©Æ�êœi.©Æ�Ø8¦ÛÅ6ì­ãkm\RáŠ·Š®À›u1A]‹v)§A¡ÅiØ¥Ø¢Ñ¶ZmÎ¢H·‰ž�Hè&gt;œŒ¥Lá&gt;J—Må¢––UM6‰‚“ŒŽjÚKi)‰½6
M¼1‘ºod˜·¸À­ò¯\U½°%Ýq¥·cI¶ˆ¯¾*Ø4Åigc5ëp‰kü1$Â&amp;\“h´‹ˆ™ƒ%Jì|2A´c)c7ï‚KB&nbsp;îI…ïº�Å=Fâß¶(“I+ÆC#N”8&nbsp;d^³4S#HK€5ßo–BPo†R4‡E±ó‹‹d0šš¯fñëÓ*21æåqÉ¸ÙYü­cfñ‰•›€,
¹¥Fý0x„¯��Ø®½­Í?(¿a†Ã½Y4eÊNÌ7-hW†^öËR°ß¦W(·C%+Üë/#–KIç¿izœ�‹\§nµ¼š?µ‰ŠÆD"ÿLÊÔBÈð²ñJ%|Çq�ï¾Ÿ„tþj–HÕC{ö0Èç4¶ÛÌÓ7ÀÌTxŒN5ŽbŠŠõ%�ÆònÞý}°S!+]u%¼D|¼zâ*	$—ð\ª…WÀÓõä€¦£0PwÑ¢)ÐŒ�c0•ákv*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»u+Š¯˜«x«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±VÇCŠ°¬µŠêâ­Ö½1W{áUÀ×b‹]Ó7Š\*Ø8ªìVÝ\B-°qUÕ8¡Ûâ««ï¾)n£
º£Ã˜UuqKuöÀ¶ß,VÝ\+k…<qo%û`[vØ­»lvÜñÂ·kª<1g'w»®§sv*êâ¶Ö wwvëí…]ŠµÓ.ëƒ’avbìb†©�$»¦*¼="" µq6áiú0&œ‘<­Å™¼�$áµ«oâÑ¢�kË¤aqû¥½|a•™_&áˆ="" Éo¯´õÖí«g¬°�Ø3-:w½;d"xní³‡ˆ6èÁ'‚[g1Ë#Ž¡…\‡(‘±q�áµ§£ùynl£zè¯qøf<è¹Øn!›.£Ô"i"vrajî<r®r„Á="" |}zé^Ðbv99­iò="Æí;žc}§\iÎRhÙw4'¡ËÁ¾N" àcÍˆÏ²‚~c%l)i<p¹3djÞø$="" “8hiÍ¥•„‡“hàím¾ü�%¶1‰uÔt«oee´™�kn¿,—zgŒuÅŒ–ÓŽÞ(u†="" y¨]tw$âveÓd¾]="">7H	äãíV¿†G†Ûx¸FÉy¼��L­_žk*–ÜõÅZÅ[ê1UÈÅ×½Ë:÷§�Ýy© .õjû{e æ`Ë³ ’S"z’¿ò
;×+¦âošEw`$E2€y
˜Š“j”•Î�*+HˆÅëL³‰¤ã*Ö:Pºß¸ê12¥Ž;GÏåº/8¥SN&nbsp;dFFGr�¾ŠyjXR¿®&amp;kN—Dc1
´O¼ãÆ§ë­ô`îÑ’9PÑ«Jbd�ŽØõÕ³ZHÑ·c×Ç$
µJ4i…‹±VÁ#¦)k/æÕ­OßŠmtrún€Ð×&nbsp;Ò.êén!8’vÀ3”­/ÂÖìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»l
â«ñWb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š¶:U…e¬]‡š[ñÅ
×Ã}7Â‹]\PÖ6)]Ój¸ªàqRÞ(upÒ®¹UÔ8UßN*»n¸«u«uÀ–ÁÂ¶º¾8¥vØ¢Û&nbsp;Å.Å4Þ4Æ—Ð`¤Ó©�-:”Â´ØÅi°iŠ-ÕÅZÅÅ]Š»»
»v*ß\
×L*¼oƒ’AwLšoµÔª RƒÛ%Òõ
¥�s¸§¾BBÛñÎ™&lt;÷‘I (ÎzøiôŒ¬ó C½Vg!»eÁÄ–å’èº¼¶‘U¢­z·Ú&gt;Þù	FÛñd1ôŽHqn€qõõzo”räæÐ—0‘Ëå£’@8°ª¹ìkí“ñZN˜riqH”í¶Ø8™øaEJ­îÄûàH¾”•™8*5v#±Àb‘$³VÓŒÊ©-Yi»±&gt;Þù(É†H_4ŠOª‡�"×&nbsp;¥HÉ“m"5³Õ¬Þ'é¯nÃîÉÄ´d�!a†â?�Wá’‚¤l+†Ø€B–�ŠÔ«|—6&lt;”øâÛ[®]×8â�áŠ•Ã'`VÆ*˜éúdšˆE�ºôŒ×“äm‘2¦pÆeÉ›èóØ!�¬¨ÁÏ)Ýª6¥z•LÛ•„Š¤émâÕ
Hµ…•¨ÊÛ«xÓÃ!tÝ\[¦Ž ·ÕRÊ½yoÓ#Í™¡Í(Õ&lt;Á¨ñEAA°®3ÌÌIµˆ¢‰ŠÓ“)¥6ß-àqŽ@K]ZkbO"A­rf6Õ„2o7Éi"D	©&gt;ç+8Û†¢ƒkæd›Ôi"9ßá©}ðp#Ç´žMe™
„‘N]ÆO…¬äJW–œØšt®I¬›SÅÅ]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUpªìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å[*Âk\µ‹Ž*ØÂP¸m�Ý\(u{áVë\PêáE¶*[ë…ÅW�WWuNUà×»pÛ
¯®·ŠŠ®¶)]Š»¦(\)µã…ÔÅ�O|VÝÓµ¤×®¸SÍ¼XÛ±W`WcJÞ4­cJì*ìUØ«x9%®˜UxÁkm��
â—WÛª|q¤Ú¼3˜Øni‚’%IÏ&nbsp;·C’Ÿˆän›*Ð«jðH¯Ö†£ç†í4Ècó-ÝªŠ®Ç|¯Ã¸g1d¶¾gŽöêÉÁ†Ä‡ qÓ|s‰
ÓKÌmé8$Ö›í‘–Í�¢ÂõmQãy ±ë–Æ..L•²N½�œza‰=7Ã Æ,þÕnæ@&amp;`­ë”šs#gšKq¥ßÛLÍú‰Æ�‡Ú§†HH5rf5¬NÑ¢7§*²¶ìÄ�_
ÙdCFB•Ûj×s&nbsp;oQ°$`×„)êJÓ2Ê&nbsp;*(WvYïºWºäš×uÅVô8§šüP×|Yð
÷À®¥œèÄq*&lt;ýµ=�r™ÆÜ¼9C"2O*(·põ%hÔ©&gt;�½·Æ$l¥ô°Ñ¥
›ÉNç^:K5O3zƒÑP8Ó­:ä£�†L÷³w.Å‰$žç®]N-­Â«€È’…ØØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUxÅ[Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«c¡ÅX6\Åxß}1C«L(vb®­0©n¸†.é…+�®4†ð¢ÝŠmx5À‹o¶Åq+j€W®&nbsp;¢Ú®)ºâšov^†ñRìP½qUàâËšìX¬;â­b®Å[¿\M0«T'u(·Pb›vãnµÅ]Š»\ŽJ»VúàWtÅZÅ]Š·Cá�*‰#GÑˆÅ7\‘kt¬&gt;\�Ø×o§2âµ­vÏPÔÛ¦4¦V²9}&amp;©Já¤IÕ¦¬päcÙØä@j—ëvÃ‚�CRÝØÓ©ÃÓ“âYe¨½�YÅÚ½°˜Ú!“…™Øù°2\qjR&nbsp;õÊN.ç.ŽöWcæ8nR»¸åg9Ì
íkH]v@¥Z¥i×%ÀW.?0É4Uåû°k?Ú§/âqŽ$½Ub…—ˆ¥ø«„°¶êî�¢KoM×nJz�qã’šå z!%HU‚ÆÕ
ûGj!º!�8ÔTw£Kh@©b¤4qPÞ¡¿�.Å+˜’MOlVÑ¶7kjÄ²’
:|plã.ñõ8äm¤ª·POõÊø[¸í!¼‘Èˆ’ƒ¥ra¦G¹0¨^R»Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb­�\UxÅ]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb­Ž‡`ùko¥p&nbsp;®­p)hœ!
V¸U°qCUÂ†Á¦*ÞIì«Á®+MáG'V˜O5A¾+À¦*Þ)ukŠ9-Å“`Ólb«±Wb«Á®)¼T…ã¦(o¯.k1bìUØ«±H_ZbÄ¸o¾)¶ñG6·Å.Å]ŠÓ±E¶7Å+©L-â&nbsp;·ƒ’]‡š¶
0Rº¿,i]S�+UÆ•Ø«±WWKu8«UÆ•¾¸¡¬Ux&gt;ö×¯_²EÈÊž…§y©-ÕD€Wj‘”Ë¹°ÔR®¡æk5%¡V© Sqž«&lt;ñèÇn5˜&amp;œH-p9`‰i–PM¥3ÉmyÊŽÂG¦äm·m»á¢ÉJ^Ý–»N»l2VÖB˜5P‰··šè•Œ3S}°0¹)ÍDJ¸£wñ´UsRÂŽ«°%¬	]áŠ»¶*\Â¸¤8np)T"ƒ‡.EWb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØªà1UØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«c¡ÅX8ßïËX8øâ‡LT¸ákCxT»®,]\U±†Õv4‹lcI_×„
ƒC�*¼±E-®š\$*ì
Õ1UÃ}±UÃÃowLUxñÅ!Pâ¥®XªìUjâ’».Å]�\N–Áé…‰½ð%i8i]Š¸iW�^˜]Š€„·ÓAo
Aur4–öÅ]O|m]¶j´ÃIvV©…m¼‡cjìy«]1¤®Àá†•w|Y6øàWT‘Zâ¥¡×–ñ*ˆY��RÄl›Q]«Š
JM9˜&nbsp;—P|{dLm²áBÏ3\9‘ÍI=p€Ä›)¾‹§Ãr%–äb€NL{jdg.æÜprÉ­´½`¢GxÜî@b@ö©í•I¼c�nóC³Ô€[{¨–áMB2öÀûâ&amp;BeˆK‘Ý…_é÷d�Äe�ìŸ‘ï–F@òqgE2L]BF)xØlôÅ!¥È¥v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®ÅWŠ®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š¶:U‚ƒJe¬V&nbsp;b†±CUÂ¥¼(k
\U¼‘Cy­òÉ"›¸R½M«²*ì%[UøÙ Up8UØØUw\
ØÂ­àVÁ¦*¸|±eÍ}G\X´MqWLR×.Å
àU½ð«xB†É®  ÀÄ©-ãHu+�Alm‹.mŸX¸b«°

±Vð¤;Mà¤5LRÞ*ìmÀ®ÆÕØÚ»vI\¸]‰BóŠZþ¸½¾ÃV­ÄZtìq)M&nbsp;Ðï'·¢Ê�ÑˆÚ™0Ø1–Í@íŠ49 m�²ÕÅ{âª�I©íŠ@NñdX
úH	¯…rÚeÑ»—‚žƒ³(Õéô`	‘’Û{š7R
j)‰ËaóCD†¨–áHèûÓ*8ûœ�ž¶;£çÓô«øÒâxÖ]øÃAÌìÈñ³9F2v÷$3ù&gt;v%­dGˆîµ?�ÉŒ½í'Lz ­|³s5VSè0n�Ü{a9cóÙ|�:«1¹Š�¶&amp;¿vGÅeùcÞÅ¦µ–Ýä�Ð†ŒüT,»k1­”1`ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±VÀ®*¸
b­â®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š¶:U‚Lµƒ�¥1Bî¸¡flÙ%.Å‹XPØÆÕ²p£›`b–éŠ¯óUõÈ¥Ç8tÉªàr$*üUÕÂ­†®E+«íŠ\U_ž*Ø5Å[Å[˜ªüYsv,]Š»
ªðk�+±Bß|T»|)\!‚ü$«±æ®È$60©hb…êl&nbsp;“íŠiY­fV¡‰ëJô9SÂWýRjWÒz|±´˜”?L•±·cknÆÖÝ‚Ô;$»"®Å‹±d…]…\¸¤»/®)rüD‹'¢ZivEä@ TW©÷Ìs"æGZo-G«ÀÜ¢?iH©¥qñà­Â£k/nóE×&nbsp;QáL¾)%7zUö¯v§Ñ+•¨6ÎÙ1!ÂXå2›Éå;%d„\8�×¸5ö¥6Èx¥°é£ÊÔ—È¬Œ]+
Ôü=¾ü|eü¥ueÚZÄIUh&gt;M¿®VIoŒG$Æ‹gr
*úm×¥i÷á!Œ±D¥ùdª†í’Î-;MŠ98«MÉ¯L2’1ÀMÞ“owµ±@ÝA¦DLŽi–1.ICi÷,Še`�M=éòÉq³Õ™iNb…¦ªö§‡¾U''&nbsp;¿R¹ˆ€XŽ=<h#c)È0ÙuikühÇ-áqŒ÷v¸ÖÓu#�cÅ©ÜÇÇ3“dŽöÐ‡f†&�;ò§�nh™g¹-É5»v*ìuØ«±wb®Å]Š»v*ìuØ«±wb®Å]Š»v*ìuØ«±wb®Å]Š»l â«úb®Å]Š»v*ìuØ«±wb®Å]Š»v*ìuØ«±wb®Å]Š»v*ìuØ«±wb®Å]Š»v*Øèqv\µƒg®(­0¡Ç="" µ„!Ã¾(!Øb«c="" ­.«½Ærâlj[;¦="" «uup="²)¥ÔÅ" ôÂ«Á®ov*»ß]Š»lrº´ëŠ·Š�[sk‰®(v(.¤-\%jªâ»x�€[Â]‘p¹qir¯& tÒ§¦(z.�kognxzo#="" Úµå˜ó$—?dbä˜,ÃÔ£á‚�êú…ü0Àâ5©±¦s˜æŒÜ‰'¹ËÝqkv*ì,ƒ°•ve]ŠÓ²@+°«Ž)="" ôÃok—í="" y42jpÑh:öy="" ÂÓË}yâŠez�aúvcmÃ%¯m„\ÝpÐ–®û™Ø0€³»Ðäº#"²�†ƒ|Ç«sl©,0­rz€ÃöºÔäí®“¸Ú="" ”’qÈõ="" ä9¶Špcm˜èÇš95+gõd pq ÷¥“kpÐŽ@sÃ$="" Äå,w 4eƒ1Ç“]ñru¼©lÌ�aáßºƒhéhÕt«�w="" Ð×®g“3ëc7:›c)@Àsb¨9`�´™Ò_t¡£õí_!Œ»Ðé!p7ÂkmÓú3@$çmÛörnÅÎŠ®»¦µ�)-e-lvµ?íc="" _5Ël^2Ÿ="" ·jÔå�yã…c|_*="" ð°v*ìuØ«±wb®Å]Š»v*ìuØ«±wb®Å]Š»v*ìuØ«±wb®ÅwŠ®Å]Š»v*ìuØ«±wb®Å]Š»v*ìuØ«±wb®Å]Š»v*ìuØ«±wb®Å]Š»v*ìuØ«c¡Åxz7…="" ±c�Â®Å‹Ži-Ö¸†.ÅwlrØÂ="" lhwtÁÍ*ƒzâpÖ^*ê="" u¼*¼="" »ui†•w,="" Ýf*Ø8Ò·Ó|r»lupðÅ[¤®Û4nhxáæ•pk��pÅ]‹'bÅx5É‚Àj‚Œµ·v’2pÒµ©d="" m„sýki‚Ú1r*š€w«á�Œ¯fÜ˜ÀÝ4†¸<£ØðñÓŠÝõ{«a*}±°ybžy¤‚œûýùÎ="" ªëqªÛ1¡@ÁË( Á2êp©Øi4ìiiØ)]„»wb»="" »kwpØÅ!¼rÉ´�Ôf’p*wÃ*”éÈÇˆi’›»m9*pø÷'éÊêÛ¸„4ÛØ&i¤}Øšr‚‚¸dt©¸ú¥ãjí…¯®Éuåû¹ s^ûäÀkœÐböqþíjsÇ2©¡<gí“ó8="" y="" ”rkw¸l="" ¼r²}zâáx3 ãÂrpbv#â5ø±_ë�Åb’§Øãiâx—r$±;o]ñ¥n—qe‹pÓ="" �‹wi,ž¬Œô¥r]îÖ¬ŒØöÄ­«%Ëª•s@{`!m6:Ùª*�ãö¼r="" Þ&Èy5i&#‘4ï„e�Éiy5'$ÖÖ*ìuØ«±wb®Å]Š»v*ìuØ«±wb®Å]Š»v*ìuØ«±wb®Å]Š¯˜«x«±wb®Å]Š»v*ìuØ«±wb®Å]Š»v*ìuØ«±wb®Å]Š»v*ìuØ«±wb®Å]Š»v*Øèqv\´0uhn8�°!ªä•°p µáŠé…iqé¶!]„!°p]…[Àbw="" Ž…Ø«±uà×on´ÃjÝk�-Ón´Â•ûdpí±[lm…mºâ›]¿Ž·o…mp©À¶ß^ø«`b­á%pÄ¢×`wb�]Š[®(¤]˜¬ŠizvÀyf="" c°µúÂuÔsÃ(‘§2ÂíbæqaéŽƒì³ì¿dÒ®72‚v¦="" È'3Õ•§—žb="">÷eG%9
¢Ã~�	SƒÄeà(ëZ“Z40€¬Â€‘°Ã	ïhË„‘Aäº§–îôÇãÁ¤ZWš®Ù•‚N»&amp;…”¡£¾NÚˆ¥þŒ�yðn&gt;4ÆÖ”°¡£‚•–hÞSºÕHG?yÊç”EÉÅ§3ÝœÁä(]Bº�¼:ý9IÎ\¨èÂÿòú5¢‘£§Žãs±žŒty�Ý¿Õ&amp;’ÁŠ1Ù’
¸�CŒP]ŠwÅ�o¢¢ºx@H§¾D„‰R£]¼¿ÞHÍ¶
OóPY™*ˆ
"é±+�NG^"§LPâiŠZëŠ¯o‚Ø¸`dÙÅ-Ž˜«~8¸bR\:œJC—VÇLJ·‹ ì]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±VÀ®*¼</h#c)è0ùuikühç-áqœ÷v¸öóu#�cå©üçç3“džöð‡f†&�;ò§�nh™g¹-é5»v*ìuø«±wb®å]š»v*ìuø«±wb®å]š»v*ìuø«±wb®å]š»l></qo%û`[vø­»lvüñâ·kª<1g'w»®§sv*êâ¶ö></e–øê)z¡></a‡></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.thesciencecouncil.com/pdfs/PlentifulEnergy.pdf">http://www.thesciencecouncil.com/pdfs/PlentifulEnergy.pdf</a></em></p>]]>
            </description>
            <link>http://www.thesciencecouncil.com/pdfs/PlentifulEnergy.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25190008</guid>
            <pubDate>Mon, 23 Nov 2020 18:39:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A list with 200+ companies sponsoring tech newsletters and websites]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25189975">thread link</a>) | @thikari
<br/>
November 23, 2020 | https://sponsorgap.com/companies-buying-ads-and-sponsorships | <a href="https://web.archive.org/web/*/https://sponsorgap.com/companies-buying-ads-and-sponsorships">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Sponsorgap makes it easy to get a sponsor for your product. <br> </p></div></div>]]>
            </description>
            <link>https://sponsorgap.com/companies-buying-ads-and-sponsorships</link>
            <guid isPermaLink="false">hacker-news-small-sites-25189975</guid>
            <pubDate>Mon, 23 Nov 2020 18:36:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Synthetic-Aperture Radar Imaging]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25189860">thread link</a>) | @parsecs
<br/>
November 23, 2020 | https://hforsten.com/synthetic-aperture-radar-imaging.html | <a href="https://web.archive.org/web/*/https://hforsten.com/synthetic-aperture-radar-imaging.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <div>
    <section id="content">
        <article>
            
            <div>
                
                
<p>Few years ago I did some <a href="https://hforsten.com/homemade-synthetic-aperture-radar.html">simple synthetic-aperture radar (SAR) imaging
experiments</a> with the second version of my homemade
FMCW radar. Since then I made a much improved <a href="https://hforsten.com/third-version-of-homemade-6-ghz-fmcw-radar.html">third version of the
radar</a> but didn't do any SAR measurements due to the
amount of effort it would have required. I did have plans to do some SAR
experiments afterwards but it took until now to have enough time and
motivation.</p>
<p>Synthetic aperture radar (SAR) imaging is a way to synthesize very large antenna
array by moving single antenna on a known path. If there are no moving targets
in the scene then one radar taking many measurements along a path gives the same
result as one ridiculously large radar that is as long as the movement path.</p>
<div id="centered">
    <p><img src="https://hforsten.com/img/fmcw3-sar/xsar_imaging.png.pagespeed.ic.MP13OL2L7B.png" width="40%/"></p><p>SAR imaging of a single target. As the radar
    moves the measured distance follows a parabola.</p>
</div>

<p>If we move on a straight path while radar pointing 90 degrees from the direction
of the path measures a distance to the single target, we will find that the
measured distance follows a parabola. This follows directly from the Pythagorean
theorem. The SAR imaging problem is finding out the target position from the
measured distance data. Of course in a real scene we have multiple targets and
the solution isn't as simple as looking where the closest approach is as could
be done in the picture above.</p>

<p>There are few different algorithms for solving this problem, but the one I'm
going to use is called Omega-k algorithm. It is a fast imaging algorithm
utilizing FFT which also makes it efficient to calculate on GPU. The derivation
mostly follows <a href="https://ieeexplore.ieee.org/document/7878107">a paper by Guo and
Dong</a>.</p>
<p>The radar I have is a frequency modulated constant wave (FMCW) radar. It
transmits a short frequency sweep. The transmitted waveform can be modeled as: </p>
<p>$$ s_t(\tau) = \exp(j 2 \pi f_c \tau + \pi \gamma \tau^2),\quad -T_s/2 &lt; \tau &lt; T_s/2 $$</p>
<p>, where <span>\(j&nbsp;= \sqrt{-1}\)</span>, <span>\(f_c =\)</span> RF carrier frequency, <span>\(\tau =\)</span> time variable,
<span>\(\gamma = B/T_s =\)</span> sweep bandwidth / sweep length <span>\(=\)</span> sweep rate.</p>
<p>The transmitted wave reflects off a target at some distance and is received after
time <span>\(t_d\)</span>. Ignoring the amplitude, the received wave is a time-delayed copy
of the transmitted signal: <span>\(s_r(\tau) = s_t(\tau - t_d)\)</span>. Signals from multiple
targets are summed.</p>
<p>The receiver mixes the received signal with the transmitted signal. This mixing
is called dechirping and it removes the high frequency RF component. The result
is a low frequency signal, usually some few kHz to MHz and is easy to digitize
with low-cost ADC. With the complex signals we take complex conjugate of the
transmitted signal to get the low-pass product and the resulting mixing product is:</p>
<p>$$ s_{\text{IF}}(\tau) = s_t(\tau - t_d) s_t^*(\tau) = \exp(-j 2 \pi f_c t_d
- j 2 \pi \gamma t_d \tau + j \pi \gamma \tau^2) $$</p>
<p>During SAR measurement the radar repeats this measurement while moving on
a straight path with a constant speed. The position of the radar on the path is:
<span>\(x = v \tau + x_n\)</span>, where <span>\(v\)</span> is speed of the radar platform and <span>\(x_n
= v n T_p\)</span>. <span>\(n\)</span> is the index for measurements and <span>\(T_p\)</span> is the transmit
repetition interval.</p>
<p>If the radar target is at position <span>\((x_0, y_0)\)</span> the distance to the target can
be written as:</p>
<p>$$ R(x) = \sqrt{y_0^2 + (x_0 - x)^2}&nbsp;$$</p>
<p>We set the y-coordinate of the path to be 0 and x position is limited to <span>\(-L/2
&lt; x &lt; L/2\)</span>, where <span>\(L\)</span> is length of the path.</p>
<p>Since electromagnetic waves travel at the speed of light and radar signal needs
to travel to the target and back to the radar, we get expression
for received signal time delay <span>\(t_d = 2R(x)/c\)</span>, where <span>\(c\)</span> is the speed of light.</p>
<p>The recorded signal can be written as:</p>
<p>$$ s_{\text{IF}}(\tau, x) = \exp\left(-j \frac{4 \pi}{c} (f_c + \gamma \tau) R(x)\right)
\exp\left(j \frac{4 \pi \gamma^2}{c^2} R^2(x)\right) $$</p>
<p>The last term in the above expression is called residual video phase term and
it's an undesirable by-product from dechirping operation. It should be removed
before further processing by multiplying by <span>\(\exp(-j \frac{4 \pi \gamma^2}{c^2}
R^2(x))\)</span>.  However this form is inconvenient because it depends on <span>\(R(x)\)</span>. Using
the fact that <span>\(R(x) = c t_d / 2\)</span> and that <span>\(t_d\)</span> can be expressed in terms of
frequency of the IF signal: <span>\(f = -2 \gamma R(x) / c = -\gamma t_d \Rightarrow
t_d = -\frac{f}{\gamma}\)</span> we can write the correction term as <span>\(\exp(-j \pi f^2
/ \gamma)\)</span>. This form can be applied easily to the Fourier transformed signal.</p>
<p>With RVP term removed the signal is:</p>
<p>$$ s(\tau, x_n) = \exp\left(-j \frac{4 \pi}{c} (f_c + \gamma \tau) \sqrt{y_0^2 + (x_n - x_0 + v \tau)^2}\right) $$</p>
<p>Ideally we would like to have the signal in form <span>\(\exp(-j 2 \pi f_y y_0)\exp(-j
2\pi f_x x_0)\)</span>, then we could apply two dimensional inverse Fourier transform to
get a delta function centered at <span>\((x_0, y_0)\)</span> focusing the image. Currently the
signal <span>\(s(\tau, x_n)\)</span> is not in this form and inverse Fourier transform doesn't
give anything interesting. We need to find some processing steps to apply to the
signal to get it to the required form so that inverse Fourier transform can be
applied. The reason to look specifically for this kind of form is that FFT can
be performed very efficiently.</p>
<p>As a first step, note that <span>\(\gamma\)</span> has units of Hz/s and <span>\(\tau\)</span> has units of s.
The product <span>\(\gamma \tau\)</span> has units of Hz so it's a frequency. This product is actually
instantenous modulation frequency of the sweep. We do substitution <span>\(\gamma
\tau \rightarrow f_\tau\)</span> to get rid of the time variable. <span>\(\tau\)</span> range was <span>\(-T/2
\ldots T/2\)</span> and the new range for <span>\(f_\tau\)</span> is <span>\(-B/2 \ldots B/2\)</span>.</p>
<p>$$ S(f_\tau, x_n) = \exp\left(-j \frac{4 \pi}{c} (f_c + f_\tau) \sqrt{y_0^2 + (x_n - x_0 + \frac{v f_\tau}{\gamma} )^2}\right) $$</p>
<p>Also instead of using frequency the math is cleaner and the implementation of
the algorithm is easier when using wavenumbers instead. We define range
wavenumber <span>\(K_r = K_{rc} + \Delta K_r\)</span>. <span>\(K_{rc} = \frac{4\pi f_c}{c}\)</span>, <span>\(\Delta
K_r = \frac{4\pi f_\tau}{c} = -\frac{2\pi B}{c} \ldots \frac{2\pi B}{c}\)</span>.</p>
<p>$$ S(K_r, x_n) = \exp\left(-j K_r \sqrt{y_0^2 + (x_n - x_0 + \frac{v c \Delta K_r}{4 \pi \gamma} )^2}\right) $$</p>
<p>Next step is to do Fourier transform in azimuth direction (direction of the
movement) to move also the <span>\(x_n\)</span> variable to frequency domain.</p>
<p>$$ S(K_r, K_x) = \int_{-\infty}^\infty S(K_r, x_n) \exp(-j K_x x_n)\, dx_n  = \int_{-\infty}^\infty \exp(j\Phi(x_n))\, dx_n $$</p>
<p><span>\(K_x = 2\pi f_x\)</span> is wavenumber in the azimuth direction. This integral doesn't have
exact solution, but there is a method to calculate quite accurate approximation
using a method called principle of stationary phase (PSOP). Phase of the
function being integrated can be written as:</p>
<p>$$ \Phi(x_n) = -K_r \sqrt{y_0^2 + \left(x_n - x_0 + \frac{v c \Delta K_r}{4 \pi \gamma} \right)^2} - K_x x_n $$</p>
<p>If we plot the phase <span>\(\Phi(x_n)\)</span> for some realistic values we get a plot that
looks something like below:</p>
<div id="centered">
    <p><img src="https://hforsten.com/img/fmcw3-sar/xphi_plot.png.pagespeed.ic.0z1VF8YpRH.png" width="40%/"></p><p>Phase and real part of the function being
    integrated.</p>
</div>

<p>There is one point where derivative of the phase is zero (stationary point) and
the function varies slowly, but away from that point the function is highly
oscillatory. As we integrate the function the oscillations far away from the
stationary point cancel out and mainly the area around the stationary point
contributes to the result of the integral.</p>
<p>We can expand the function around the stationary point <span>\(\frac{d}{dx_n}\Phi(x_n) \rvert_{x_n=x_n^\star} = 0\)</span>, as
<span>\(\Phi(x_n) = \Phi(x_n^\star) + 0 + \frac{1}{2}\Phi^{''}(x_n - x_n^\star)^2\)</span>.</p>
<p>Plugging the Taylor expansion in to the integral we get:</p>
<p>$$ \begin{aligned}S(K_r, K_x) &amp;\approx \exp(j\Phi(x_n^\star)) \int_{-\infty}^\infty \exp\left(j\frac{1}{2}\Phi^{''}(x_n^\star)(x_n-x_n^\star)^2\right)\, d x_n \\
&amp;= \exp(j\Phi(x_n^\star)) \int_{-\infty}^\infty \exp\left(j\frac{1}{2}\Phi^{''}(x_n^\star)s^2\right)\, d s \\
&amp;= \exp(j\Phi(x_n^\star)) \sqrt{\frac{2\pi j}{\Phi^{''}(x_n^\star)}} \end{aligned}
$$</p>
<p>Since <span>\(\Phi(x_n)\)</span> is purely real function, if <span>\(\mu\)</span> is sign of the
<span>\(\Phi(x_n^\star)\)</span>, then the square root term can be written as
<span>\(\sqrt{\frac{2\pi}{|\Phi^{''}(x_n^\star)|}} exp(j\pi \mu/4)\)</span>. The second
derivative contributes amplitude term and constant phase term, neither of them
which is important for focusing image which mainly depends on aligning the
phases. We have ignored the amplitude since beginning and it ends up being slowly
varying function so we will just approximate it away.</p>
<p>The stationary point of the function <span>\(\frac{d}{dx_n}\Phi(x_n)
\rvert_{x_n=x_n^\star} = 0\)</span> can be solved to be:</p>
<p>$$ x_n^\star = x_0 - \frac{K_x y_0}{\sqrt{K_r^2 - K_x^2}} - \frac{c \Delta K_r
v}{4\pi\gamma} $$</p>
<p>Plugging in the stationary point to the <span>\(S(K_r, K_x)\)</span> equation above we get the
solution of the integral:</p>
<p>$$ S(K_r, K_x) \approx \exp\left(j(-y_0 \sqrt{K_r^2 - K_x^2} - K_x x_0 + \frac{c \Delta K_r K_x
v}{4\pi\gamma})\right) $$</p>
<p>The last term is phase offset caused by the movement of the radar during the
sweep. It can be removed by multiplying with exponential in the opposite phase.</p>
<p><span>\(x_0\)</span> term is already in the correct form as it is multiplied only by <span>\(K_x\)</span>, but
<span>\(y_0\)</span> term depends on both <span>\(K_r\)</span> and <span>\(K_x\)</span>. <span>\(K_r, K_x\)</span> dependence can be fixed
by making a substitution <span>\(\sqrt{K_r^2 - K_x^2} \rightarrow K_y\)</span>. This step is
called Stolt interpolation as it is implemented by interpolating the data to
a new grid.</p>
<p>After the Stolt interpolation the signal is in form:</p>
<p>$$ S(K_y, K_x) = \exp(j(-K_y y_0 - K_x x_0)) $$</p>
<p>Taking 2D inverse Fourier transform gives the focused image with delta function
centered at <span>\((x_0, y_0)\)</span>.</p>

<p>The Omega-k algorithm is mainly large FFTs and interpolation. Both can be
implemented well on GPU which requires large parallelism from the program. Well
written GPU implementation should be several times faster than CPU
implementation. For convenience I'll implement the algorithm using Tensorflow
library. Although it's …</p></div></article></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hforsten.com/synthetic-aperture-radar-imaging.html">https://hforsten.com/synthetic-aperture-radar-imaging.html</a></em></p>]]>
            </description>
            <link>https://hforsten.com/synthetic-aperture-radar-imaging.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25189860</guid>
            <pubDate>Mon, 23 Nov 2020 18:26:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A practical introduction to container security]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25189778">thread link</a>) | @jerodsanto
<br/>
November 23, 2020 | https://cloudberry.engineering/article/practical-introduction-container-security/ | <a href="https://web.archive.org/web/*/https://cloudberry.engineering/article/practical-introduction-container-security/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        <div>
            <p>Securing containers is a complex task.  The problem space is broad, vendors are on fire, there are tons of checklists and best practices and it’s hard to prioritize solutions. So if you had to <strong>implement a container security strategy</strong> where would you start?</p>

<p>I suggest to start from the basics: understanding <strong>what container security is about</strong> and build a model to navigate risks.</p>

<h2 id="follow-the-devops-life-cycle">Follow the DevOps Life Cycle</h2>

<p>Every security initiative is eventually constrained by where security controls can be implemented, so I find practical to just follow the standard DevOps life cycle to <em>surface patterns™</em> and <em>unlock synergies™</em>.</p>

<p>The DevOps Lifecycle is an infinite iteration of:</p>

<ul>
<li>Plan</li>
<li>Code</li>
<li>Build</li>
<li>Test</li>
<li>Release</li>
<li>Deploy</li>
<li>Operate</li>
<li>Monitor</li>
</ul>

<p><img src="https://cloudberry.engineering/devops-lifecycle.jpg" alt="DevOps Lifecycle - source: ryadel.com"></p>

<p>Containers are included in the application in the form of a Dockerfiles but are not really part of it. As such they don’t interest the planning and coding phase.</p>

<p><em>(no, writing Dockerfiles is not coding.)</em></p>

<p>Every other step is in scope from a security point of view, and I would group them like this:</p>

<ul>
<li><strong>Build Time</strong>: build, test and release.</li>
<li><strong>Container Infrastructure</strong>: deploy and operate.</li>
<li><strong>Runtime</strong>: monitor.</li>
</ul>

<p>Why? Every security strategy is only effective if it can be implemented. And every step in each group share a common facility where security controls can be injected without adding much friction:</p>

<ul>
<li>Build Time: The CI/CD infrastructure, the container registry</li>
<li>Container Infrastructure: the container orchestrator</li>
<li>Runtime: the production environment</li>
</ul>

<p>Now we have three macro areas we can use as a starting point to do our risk assessments.</p>

<h2 id="security-at-build-time">Security at Build Time</h2>

<p>At build time we have in input a bunch of source files and a Dockerfile, and we get as output a Docker image.</p>

<p>This is where most vendors tend to cluster while trying to sell you the narrative of the importance of scanning container images and calling it a day.  Container security scanning is important, yes, but it’s not enough.</p>


<div>
<p><strong>This stage goal</strong>:</p>

<ul>
<li>minimize the risk of supply chain attacks.</li>
</ul>
</div>


<h3 id="container-images-hygiene">Container Images Hygiene</h3>

<p>First, decide how your images should look like, with a focus on how software dependencies are introduced:</p>

<ul>
<li>what base images are developers allowed to use?</li>
<li>are software dependencies pinned? From where are they pulled?</li>
<li>are there any labels that are needed to simplify governance and compliance?</li>
<li>lint the Dockerfile</li>
<li>follow <a href="https://cloudberry.engineering/article/dockerfile-security-best-practices/">Docker security best practices</a> when writing Dockerfiles</li>
</ul>

<p>All of these checks are static and can be implemented for cheap as a step in the build pipelines.</p>

<h3 id="container-images-scanning">Container Images Scanning</h3>

<p>Then we can move into scanning the container image.</p>

<p><strong>Do not scan the image as a step in the build pipeline</strong>, instead setup continuous scanning in the container registry.</p>

<p>Why? Vulnerabilities are continuously discovered while your services are not necessarily continuously built. Secondly, builds are additive: every build will generate a new image. So, assuming  your container orchestrator trust your registry, every tag you publish can always be deployed and need to be assessed.</p>

<p><em>(It’s also very slow to scan at build time)</em></p>

<p>This is where you start thinking about defining <strong>patch management</strong> and <strong>shelf life</strong> processes:</p>

<ul>
<li>patch management: results from the scanning will feed a patching process that will result in a new version of the image</li>
<li>shelf life: unpatched/old/unsafe images are deleted from the registry</li>
</ul>

<p><em>(next article will be about how to choose a container scanning solution, if you are facing the dilemma right now feel free to <a href="mailto:hello@clouberry.engineering">ping me</a>)</em></p>

<h2 id="container-infrastructure-security">Container Infrastructure Security</h2>

<p>The container infrastructure is comprised of all the moving parts that are in charge of pulling your images from the registry and run them as containers in production.</p>

<p>It’s mostly going to be the container orchestrator – <em>*cough* kubernetes *cough*</em>.</p>


<div>
<p><strong>This stage goals</strong>:</p>

<ul>
<li>Avoid platform misconfigurations with security implications</li>
<li>Minimize the <strong>breadth</strong> of an attack from a compromised container</li>
</ul>
</div>


<h3 id="security-of-the-infrastructure-misconfigurations">Security OF the Infrastructure: Misconfigurations</h3>

<p>Container orchestrators are complex, Kubernetes in particular. As of now they fail the promise of DevOps and I think we are still an abstraction layer (or two) away from being a mainstream solution without too much operational overhead.</p>

<p>Every complex platforms is prone to be misconfigured, and this is the part you want to focus on.</p>

<p>You have to threat model your infrastructure to <strong>ensure it can’t be abused</strong>.
This particular thread model should focus on every actor but a compromised container (we will cover that next).</p>

<p>I can’t go into details here, because it really depends on what you are running. For Kubernetes a good starting point for threat modelling is <a href="https://www.marcolancini.it/2020/blog-kubernetes-threat-modelling/">this</a>.</p>

<p>Additionally, if you are not doing it yet, this is also a <strong>good argument in favour of using a managed platform</strong>: the complexity is reduced if you can leverage a shared responsibility model with your (trusted) provider.</p>

<h3 id="security-in-the-infrastructure-lateral-movements">Security IN the infrastructure: Lateral Movements</h3>

<p>Next we can talk about what happens when a container is compromised.</p>

<p>You want to minimize the <a href="https://cloudberry.engineering/article/lateral-movement-cloud/">attacker’s ability to move laterally</a>, focusing on these two layers:</p>

<ul>
<li>The network layer</li>
<li>The Identity and Access management (IAM) layer</li>
</ul>

<p><strong>The network should not be flat</strong>. You can start by brutally segment everything into subnetworks and work your way up to a full fledge service meshes.</p>

<p>On the IAM layer work your way toward having a <strong>single identity for each container</strong> in order to fine tune the authorization grants. This is particularly important in multi tenant platforms: without granular identities it’s impossible to achieve least privilege.</p>

<p><em>(Google Kubernetes Engine (GKE) has a nifty feature for this called <a href="https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity">Workload Identity</a>)</em></p>

<p>Finally, since they are supposed to be immutable, a wonderful strategy would be to <strong>reduce the amount of time containers can run</strong>: the window of opportunity for attackers to move laterally and gain persistence is as long as the container running lifetime. Continously shut down and spin up your containers.</p>

<p>And this final consideration allow me to smoothly move into the next area.</p>

<h2 id="runtime-security">Runtime Security</h2>

<p>The last piece of the puzzle is the security of your running workloads.
At this point most of the hardening is done and here is when we move into the realm of reactive security controls, the grim land of <strong>post-fail</strong>.</p>


<div>
<p><strong>This stage goal</strong>:</p>

<ul>
<li>is to minimize the <strong>impact</strong> of an attack from a compromised container.</li>
</ul>
</div>


<h3 id="detection-and-incident-response">Detection and Incident Response</h3>

<p>The best way to control the impact of an attack is to minimize the time between the breach to when the security team is alerted.</p>

<p>Detecting an ongoing breach is another area where vendors are scrambling to find a silver bullet. There are many approaches, most of them will require side cars and/or daemon sets actively monitoring pod’s traffic and system calls.</p>

<p>Most solutions will provide some value but my advice is to start simple and iterate: use your existing SIEM, ingest your platform, application and audit logs.</p>

<p><strong>Incidents will happen</strong>, and it’s fine: have an incident response process.</p>

<p>The first bullet point of every post-mortem should be: <em>“how can we detect this quicker next time?”</em> answering will allow you to identify your blind spots, which you can then use to understand what signals you are missing and what makes sense to buy.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Container security is a broad problem and it is not just about scanning images.</p>

<p>This is the model I built and used to reason about container risks and solutions. It’s very high level and of course, as with every model, <strong>it’s not necessarily the right one</strong>.</p>

<p>We all know that in reality each infrastructure is a snowflake: so start with your own threat model and use this one <strong>as an inspiration</strong>.</p>
        </div>
        
    </div>
</section></div>]]>
            </description>
            <link>https://cloudberry.engineering/article/practical-introduction-container-security/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25189778</guid>
            <pubDate>Mon, 23 Nov 2020 18:18:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Walmart Exclusive Wi-Fi Router Contains Backdoor to Control Devices]]>
            </title>
            <description>
<![CDATA[
Score 283 | Comments 13 (<a href="https://news.ycombinator.com/item?id=25189673">thread link</a>) | @wikus
<br/>
November 23, 2020 | https://hfet.org/walmart-exclusive-wi-fi-router-contains-backdoor-to-control-devices/ | <a href="https://web.archive.org/web/*/https://hfet.org/walmart-exclusive-wi-fi-router-contains-backdoor-to-control-devices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

			
	<main id="main" role="main">

		
<article id="post-1238">

	<!-- .entry-header -->

	
		<figure>
			<img width="1080" height="540" src="https://hfet.org/wp-content/uploads/2020/11/wallmart_router_backdoor_humans_for_ethical_technology_hfet-1080x540.jpg" alt="" loading="lazy" srcset="https://hfet.org/wp-content/uploads/2020/11/wallmart_router_backdoor_humans_for_ethical_technology_hfet-1080x540.jpg 1080w, https://hfet.org/wp-content/uploads/2020/11/wallmart_router_backdoor_humans_for_ethical_technology_hfet-20x11.jpg 20w" sizes="(max-width: 1080px) 100vw, 1080px">		</figure>

		
	
<div>

	<h4>A Walmart-exclusive Wi-Fi router, and others sold on Amazon &amp; eBay contain hidden backdoors to control devices <a href="https://cybernews.com/security/walmart-exclusive-routers-others-made-in-china-contain-backdoors-to-control-devices/" target="_blank" rel="noopener noreferrer">reports CyberNews</a>.</h4>
<ul>
<li>Researchers discovered that many low cost, Chinese-made Wi-Fi routers contain a hidden backdoor which is being actively exploited to create botnet attacks.</li>
</ul>
<p>CyberNews researchers discovered suspicious backdoors in a Chinese made router sold under the name ‘Jetstream’. This router is part of Walmart’s new line of affordable Wi-Fi routers.</p>
<blockquote><p>This backdoor would allow an attacker the ability to remotely control not only the routers, but also any devices connected to that network.</p></blockquote>
<p><img loading="lazy" src="https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-1024x681.jpg" alt="" width="800" height="532" srcset="https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-1024x681.jpg 1024w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-300x199.jpg 300w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-768x511.jpg 768w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-20x13.jpg 20w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-36x24.jpg 36w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-48x32.jpg 48w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-272x182.jpg 272w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232.jpg 1280w" sizes="(max-width: 800px) 100vw, 800px"></p>
<p>The researchers contacted Walmart to get a statement, and a Walmart spokesperson had this to say:</p>
<blockquote><p>“Thank you for bringing this to our attention. We are looking into the issue to learn more. The item in question is currently out of stock and we do not have plans to replenish it.”</p></blockquote>
<p>CyberNews researchers also discovered that ‘Wavlink’ branded routers, often sold on Amazon or eBay, <a href="https://cybernews.com/security/walmart-exclusive-routers-others-made-in-china-contain-backdoors-to-control-devices/" target="_blank" rel="noopener noreferrer">contain similar backdoors</a>.</p>
<p>Worryingly, they also discovered that these <strong>backdoors are being actively exploited</strong>, and there have been attempts to add the routers to a botnet with malware that allows them to be used in large scale DDoS attacks, which have <a href="https://cybernews.com/security/walmart-exclusive-routers-others-made-in-china-contain-backdoors-to-control-devices/" target="_blank" rel="noopener noreferrer">in the past taken down major websites</a> such as Reddit, Netflix, CNN, GitHub, Twitter, AirBnb and more.</p>
<h4><strong>Read more of the <a href="https://cybernews.com/security/walmart-exclusive-routers-others-made-in-china-contain-backdoors-to-control-devices/" target="_blank" rel="noopener noreferrer">full report on CyberNews</a>.</strong></h4>
<p><strong><a href="https://james-clee.com/2020/04/18/multiple-wavlink-vulnerabilities/" target="_blank" rel="noopener noreferrer">James Clee’s Report</a> on ‘Wavlink’ routers’ backdoors.<br>
</strong></p>
<p><a href="https://hfet.org/feed/"><img src="https://hfet.org/wp-content/uploads/2020/11/rss_button_hfet-1.png" alt="" width="219" height="30"></a><a href="https://hfet.org/support/"><img src="https://hfet.org/wp-content/uploads/2020/11/support_button_hfet.png" alt="" width="165" height="30"></a></p>
    <div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img width="100" height="100" src="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg" alt="" loading="lazy" srcset="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg 150w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-300x300.jpg 300w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-20x20.jpg 20w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-36x36.jpg 36w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-48x48.jpg 48w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-24x24.jpg 24w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-96x96.jpg 96w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel.jpg 640w" sizes="(max-width: 100px) 100vw, 100px"></p><div><p>I’m an AI &amp; Robotics Student interested in FOSS, Tech Sustainability and Data Rights. I’m also the founder of Humans For Ethical Technology.</p></div></div>	
</div><!-- .entry-content -->


</article>

	</main><!-- #main -->

	


	</div></div>]]>
            </description>
            <link>https://hfet.org/walmart-exclusive-wi-fi-router-contains-backdoor-to-control-devices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25189673</guid>
            <pubDate>Mon, 23 Nov 2020 18:10:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cert-Manager Now Part of the CNCF Sandbox Family as Jetstack Completes Donation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25189211">thread link</a>) | @AnnieNma
<br/>
November 23, 2020 | https://thechief.io/c/news/cert-manager-now-part-cncf-sandbox-family-jetstack-completes-donation/ | <a href="https://web.archive.org/web/*/https://thechief.io/c/news/cert-manager-now-part-cncf-sandbox-family-jetstack-completes-donation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><p>Jetstack is mainly a Kubernetes professional services company founded in 2015 and recently acquired by Venafi, a security company specialized in different areas mainly machine identity. According to the <a href="https://www.venafi.com/blog/why-venafi-acquisition-good-jetstack-community">Venafi</a>:</p><blockquote>The combination of speed and security creates an interesting dilemma. How do you build software quick enough to compete, without the risk of being exploited? This is the challenge that Jetstack and Venafi will solve.</blockquote><p>Back to cert-manager, Jetstack recently announced the release of the v1 API for this tool, which made the technology more mature and powerful. This release allows developers to have greater visibility and control over their certificates.</p><p>Currently, the Venafi+Jetsack team has been working towards integrating Google's new Certificate Authority Service (CAS) with cert-manager. This will offer developers private CA keys as a service, using HSMs, which are validated at FIPS 140-2 Level 3.</p></div></section><section><section><div><blockquote>
                Itâ€™s exciting to see cert-manager join the CNCF Sandbox. Itâ€™s been several years in the making to get to 1.0, and weâ€™re hugely thankful to a community of over 250 contributors, and many end-users, to get it to where it is today. This is a foundational add-on to many Kubernetes and OpenShift clusters, and the project will benefit from being part of the CNCF and its ecosystem. We look forward to attracting a diverse contributor base and extending our partnership and cooperation with many other projects to further enhance the developer and operator experience.
                <br></blockquote></div></section></section></div>]]>
            </description>
            <link>https://thechief.io/c/news/cert-manager-now-part-cncf-sandbox-family-jetstack-completes-donation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25189211</guid>
            <pubDate>Mon, 23 Nov 2020 17:31:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Selling to unicorns from my parents basement]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25188716">thread link</a>) | @timjones
<br/>
November 23, 2020 | https://www.themvpsprint.com/p/selling-to-unicorns-from-my-parents | <a href="https://web.archive.org/web/*/https://www.themvpsprint.com/p/selling-to-unicorns-from-my-parents">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>⚔️ David selling to Goliath</h2><p><strong>Me</strong> - a <a href="https://www.themvpsprint.com/about">bootstrapped solopreneur</a> with a laptop and a dream.</p><p><strong>Them</strong> - a billion dollar unicorn with 10,000+ employees.</p><h4><strong>Will I really be able to sell into their corporate web of bureaucracy?</strong></h4><h2>💸 From idea to revenue</h2><p><em><a href="https://www.themvpsprint.com/about">I’m a solo, bootstrapped founder</a></em> building a SaaS startup in public.</p><p>Over the last 4 weeks, I’ve <a href="https://mvpsprint.substack.com/p/choose-a-problem">chosen a problem to solve</a>, <a href="https://mvpsprint.substack.com/p/step-2-even-unicorns-walk-before-they-run">picked a niche</a>, <a href="https://www.themvpsprint.com/p/step-3-seeking-validation">validated my problem</a>, and <a href="https://www.themvpsprint.com/p/how-and-when-to-acquire-saas-users">created a top-of-the-funnel distribution strategy</a>.</p><p>This week I create a strategy for selling <a href="https://www.hellohailey.io/">HelloHailey</a> into companies of all sizes - from small startups to billion dollar unicorns.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff35cb8c0-fa57-49c8-8fbf-07073ac66533_971x2774.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff35cb8c0-fa57-49c8-8fbf-07073ac66533_971x2774.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/f35cb8c0-fa57-49c8-8fbf-07073ac66533_971x2774.png&quot;,&quot;height&quot;:2774,&quot;width&quot;:971,&quot;resizeWidth&quot;:368,&quot;bytes&quot;:277261,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>I’m sharing all my product decisions, metrics, successes, and failures in public.</p><p><strong>Next Monday, I’ll (finally) describe the product I’m building.</strong> Want to read it in your inbox?</p><p data-attrs="{&quot;url&quot;:&quot;https://www.themvpsprint.com/subscribe&quot;,&quot;text&quot;:&quot;Get my real-time case study&quot;,&quot;class&quot;:null}"><a href="https://www.themvpsprint.com/subscribe"><span>Get my real-time case study</span></a></p><h2>🚀 Land and expand</h2><p>The traditional SaaS sales process follows a <strong>top-down approach</strong>. A sales rep targets a high-level decision maker for a high-priced deal.</p><p>After a long sales process, a company slowly integrates a piece of software. <strong>The command comes from high in the org chart and makes its way down.</strong></p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F2651c983-567a-4996-b90d-6c2eef084537_2692x2200.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F2651c983-567a-4996-b90d-6c2eef084537_2692x2200.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/2651c983-567a-4996-b90d-6c2eef084537_2692x2200.png&quot;,&quot;height&quot;:1190,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:303429,&quot;alt&quot;:&quot;Top-down sales strategy&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt="Top-down sales strategy"></a><figcaption>A top-down sales approach targets the top of the org chart.</figcaption></figure></div><h3><strong>But I’ll be selling bottom-up</strong> </h3><p><strong>I’ll scale the corporate walls via product managers (PMs) and engineering managers (EMs)</strong>. </p><p>I’ll look unintimidating - a low price product that eats up a small chunk of a budget these team leads control.</p><p><strong>Then I’ll spread through the company like wildfire </strong>via growth mechanisms built into the product.</p><p>One team will adopt me.</p><p>Then two.</p><p>Then the entire department. </p><p>Then the entire company.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4bc6903c-6bbd-488c-b89f-516ba14a08a8_2057x3006.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4bc6903c-6bbd-488c-b89f-516ba14a08a8_2057x3006.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/4bc6903c-6bbd-488c-b89f-516ba14a08a8_2057x3006.png&quot;,&quot;height&quot;:2128,&quot;width&quot;:1456,&quot;resizeWidth&quot;:546,&quot;bytes&quot;:348487,&quot;alt&quot;:&quot;\&quot;Land and Expand\&quot; sales strategy&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt="&quot;Land and Expand&quot; sales strategy"></a><figcaption>A “Land and Expand” strategy starts at the bottom of the org chart; then expands via growth mechanisms built into the product.</figcaption></figure></div><p>I know what you’re thinking - <em>all this sounds great on paper. But how are you so confident it will work?</em></p><p><strong>I’m not </strong>😳</p><p><strong>Honestly, I don’t even know if I’ll be able to “land”, much less expand</strong>.</p><h3>It’s time to test out my landing gear</h3><p>…so I don’t build a product that crashes and burns on the runway.</p><p><strong>In <a href="https://www.themvpsprint.com/p/how-and-when-to-acquire-saas-users">last week’s article</a>, I outlined my top-of-the-funnel strategy</strong> - how to get PM and EM eyeballs on <a href="https://www.hellohailey.io/">HelloHailey</a>.</p><p><strong>This week I’m focusing on the bottom of the funnel</strong> - converting those eyeballs into paid users.</p><p><strong>Here’s what that funnel looks like for a PM or EM:</strong></p><ol><li><p><strong>Discover</strong> through top-of-the-funnel distribution channels.</p></li><li><p><strong>Try for free</strong> with their team.</p></li><li><p><strong>Get value - </strong>signaled by high engagement and retention.</p></li><li><p><strong>Convert to paid tier</strong> - to unlock premium features or exceed maximum number of seats (users) in free tier.</p></li><li><p><strong>Expand </strong>- add more seats within their company.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5d8f40ce-fff5-494d-b754-e0696f648de6_2329x2815.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5d8f40ce-fff5-494d-b754-e0696f648de6_2329x2815.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/5d8f40ce-fff5-494d-b754-e0696f648de6_2329x2815.png&quot;,&quot;height&quot;:1760,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:308211,&quot;alt&quot;:&quot;HelloHailey user acquisition funnel&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt="HelloHailey user acquisition funnel"></a><figcaption>HelloHailey user acquisition funnel</figcaption></figure></div></li></ol><h4><strong>My go-to-market strategy fails if I can’t convert free users into paid users.</strong></h4><p>But I know very little about B2B purchasing processes for low-ticket ($25-$50 / month) SaaS products:</p><ol><li><p><em>Will users have to fight tooth and nail for approval?</em></p></li><li><p><em>Who has a company credit card?</em></p></li><li><p><em>What budget will the money come from?</em></p></li></ol><p>To avoid this suc-SaaS story turning into a dis-SaaS-ter (🙄 sorry, couldn’t resist), <strong>I’m going to invest a few days now into understanding what the purchasing process will look like.</strong></p><h2>💰 How low-ticket SaaS products get purchased</h2><p>I probed into my network of EMs and PMs for answers. </p><p><em>Big shoutout to all those who helped me! </em>🙏</p><p>It turns out that my fears of a long chain of approvals with stringent criteria were unfounded.</p><h3><strong>The approval and purchase process is just two steps:</strong></h3><h4>1. Ask a manager</h4><p>Approval is loose and informal. PMs and EMs briefly mention it to their managers over email or their regular check-in.</p><p>Managers won’t require much justification for approval. Why? Its an immaterial amount of money and they trust their employees’ judgment.</p><h4>2. Find a credit card</h4><p>With very few exceptions, PMs and EMs (at the levels I’m targeting) don’t have company credit cards. So how do they pay after getting approval?</p><h5>Pay with personal credit card</h5><p>This is a common practice for team meals, social events, and one-off software purchases. A senior team member will pay with a personal card and file an expense report.</p><p>But people are more hesitant to pay for a <em><strong>recurring</strong></em> team subscription with a personal card.</p><h5>Find a company credit card</h5><p>This varies from company to company, but the most common places people go are:</p><ol><li><p><strong>Finance</strong> (manages budgets)</p></li><li><p><strong>IT</strong> (manages access to company subscriptions)</p></li><li><p><strong>Lowest person above them in the org chart with a company card</strong> (usually a Director or VP, depending on company size)</p></li></ol><h2>😁 Why my strategy will work</h2><h5>✅  Loose approval process</h5><p>I mentioned this before, but it’s worth restating. <strong>This means that the PM or EM using <a href="https://www.hellohailey.io/">HelloHailey</a> is the primary decision maker.</strong></p><p>No bureaucracy. No long, complex sales cycles.</p><p><strong>I just need to build a great product.</strong></p><h5>✅  Fits into an existing budget</h5><p>It’s my hypothesis that teams will pay for HelloHailey using their team “social” budgets. These budgets cover expenses like meals, games, or team events.</p><h5>✅  Takes a small percentage of that budget</h5><p>Team social budgets range from $10-$100 / person / month, with a median somewhere in the middle.</p><p>With a price of $2-$3 / person / month, HelloHailey would eat up only 5% of that budget on average.</p><h5>✅  Social budgets have been underutilized with sudden shift to remote work</h5><p>Half the people I talked to haven’t used their social budgets at all since being forced into remote work.</p><p>Most of the other half has used it sparingly for virtual team events.</p><h2>😢 Why it might not work</h2><p>Until companies <em>actually</em> start paying me, my strategy will be full of uncertainty.</p><p>Here are some ways it might fail:</p><h5>💩  Doesn’t fit into an existing budget</h5><p>Maybe companies don’t think it’s appropriate to pull from team social budgets for this kind of purchase.</p><p>If it doesn’t fit nicely into <em>any</em> existing category, it’ll be much harder for companies to buy it.</p><h5>💩  Hard to budget for a product with expanding price</h5><p><a href="https://www.hellohailey.io/">HelloHailey</a> will get more expensive as more users and teams are added within a company. </p><h5>💩  <strong>What happens when a product purchased with Team A’s social budget adds users from Team B and gets more expensive? </strong></h5><p>I don’t know 🤷‍♂️ (<em>Do you? <a href="https://twitter.com/AnotherTimJones">Share your wisdom and help me out</a> </em>🙂 ).</p><p>But I’m not the first person to face this problem. There are precedents in place and I’m confident I’ll figure it out.</p><h5>💩  Approval process is more difficult than expected</h5><p>The people I interviewed could be outliers. Maybe a typical manager requires more convincing to approve this kind of purchase.</p><h2>What about expanding?</h2><p>I now feel confident about landing. <strong>So how will I expand?</strong></p><p>I have some ideas for how I can build growth mechanisms into a product like this.</p><p>But if I’m being honest, I’m not sure yet 🤷‍♂️. And I’m OK with that.</p><p><strong>With a successful “land” strategy, and low to moderate expansion revenue, I can build a great business.</strong></p><p>Intra-company virality would be a must if I wanted to become a VC-backed rocket ship.</p><p><strong>But that’s not my goal.</strong></p><p><strong>I want to build a small, profitable company that solves a problem I’m passionate about.</strong></p><p>I can sell to unicorns. But I don’t want to <em>become</em> one.</p><h2>What did I get wrong?</h2><p>I learned a lot this week, but I’ve never done this before. </p><p><strong>Do you have SaaS sales experience?</strong></p><p>Don’t pull your punches! Help me out on my Twitter thread:</p><p>Don’t have any tips for me? <strong>Maybe you could help me out with a like or a retweet.</strong></p><p><strong>As a solopreneur with no funding or income, I’ll take all the help I can get 😁</strong></p><h2>🤔 Reducing uncertainty one week at a time</h2><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fcac3da08-e921-4064-b421-eebf46ef563b_920x248.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fcac3da08-e921-4064-b421-eebf46ef563b_920x248.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/cac3da08-e921-4064-b421-eebf46ef563b_920x248.png&quot;,&quot;height&quot;:248,&quot;width&quot;:920,&quot;resizeWidth&quot;:490,&quot;bytes&quot;:29061,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd00e39b8-5136-450c-b442-675c0cd2fd7f_478x184.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd00e39b8-5136-450c-b442-675c0cd2fd7f_478x184.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/d00e39b8-5136-450c-b442-675c0cd2fd7f_478x184.png&quot;,&quot;height&quot;:184,&quot;width&quot;:478,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:23531,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>I’m finally feeling confident about my go-to-market strategy. Now it’s time to define the product I’ll be going to market with…</p><p><strong>Over the next two weeks, I’ll define my product vision and finalize requirements for an MVP (minimum viable product).</strong></p><p><strong>Curious to find out what I’ll be building?</strong> </p><p>I’ll tell you next Monday:</p><p data-attrs="{&quot;url&quot;:&quot;https://www.themvpsprint.com/subscribe&quot;,&quot;text&quot;:&quot;Send me next week's update&quot;,&quot;class&quot;:null}"><a href="https://www.themvpsprint.com/subscribe"><span>Send me next week's update</span></a></p><p><em>I’ll be documenting my startup journey from idea to paying users over the coming weeks and months. I’d love to have you along for the ride.</em></p><p><em>Icons made by&nbsp;<a href="https://www.freepik.com/">Freepik</a>,&nbsp;<a href="https://www.flaticon.com/authors/icongeek26">Icongeek26</a>, and&nbsp;<a href="https://www.flaticon.com/authors/pixel-perfect">Pixel perfect</a>&nbsp;from&nbsp;<a href="https://www.flaticon.com/">Flaticon</a></em></p></div></div>]]>
            </description>
            <link>https://www.themvpsprint.com/p/selling-to-unicorns-from-my-parents</link>
            <guid isPermaLink="false">hacker-news-small-sites-25188716</guid>
            <pubDate>Mon, 23 Nov 2020 16:53:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do Your Emails Need BIMI?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25188559">thread link</a>) | @todsacerdoti
<br/>
November 23, 2020 | https://blog.mailtrap.io/bimi-email/ | <a href="https://web.archive.org/web/*/https://blog.mailtrap.io/bimi-email/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2526">
	<div>
		<!-- .entry-header -->

		<div>
			
<p>Here we go again. Just when you figured out what all these weird abbreviations (DKIM, SPF, DMARC) are, one more pops up on the horizon. Weren’t you safe enough already? Weren’t the spoofers, seeing your robust DNS records, quietly running away? Not all of them. The bad news is that you need to become familiar with the new kids on the block –&nbsp; BIMI records. Good news – we’ve got them covered for you. Read on!<br></p>



<h2><span id="What_is_a_BIMI_Record">What is a BIMI Record?</span></h2>



<p>BIMI stands for <strong>Brand Indicator for Message Identification</strong>. It’s a new approach that aims to prevent spoofing attempts but also increases the credibility of email senders. When fully implemented, hackers will have a very hard time trying to impersonate brands in emails, and maybe in a lot of other places too.<br></p>



<p><strong>A BIMI record is a DNS TXT record indicating what a brand’s logo is</strong>. When properly certified and authenticated, brands will be able to display their logo next to each message in an inbox, just like in the example below.<br></p>



<figure><img data-attachment-id="2551" data-permalink="https://blog.mailtrap.io/bimi-email/bimi-before-after/" data-orig-file="https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?fit=1360%2C680&amp;ssl=1" data-orig-size="1360,680" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="BIMI-before-after" data-image-description="" data-medium-file="https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?fit=300%2C150&amp;ssl=1" data-large-file="https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?fit=640%2C320&amp;ssl=1" loading="lazy" width="1360" height="680" src="https://i1.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?fit=640%2C320&amp;ssl=1" alt="" srcset="https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?w=1360&amp;ssl=1 1360w, https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?resize=300%2C150&amp;ssl=1 300w, https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?resize=1024%2C512&amp;ssl=1 1024w, https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?resize=768%2C384&amp;ssl=1 768w, https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?resize=900%2C450&amp;ssl=1 900w, https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?resize=1280%2C640&amp;ssl=1 1280w" sizes="(max-width: 640px) 100vw, 640px" data-lazy-srcset="https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?w=1360&amp;ssl=1 1360w, https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?resize=300%2C150&amp;ssl=1 300w, https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?resize=1024%2C512&amp;ssl=1 1024w, https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?resize=768%2C384&amp;ssl=1 768w, https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?resize=900%2C450&amp;ssl=1 900w, https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?resize=1280%2C640&amp;ssl=1 1280w" data-lazy-src="https://i1.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?fit=640%2C320&amp;ssl=1&amp;is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure><p>When it’s well adopted and more logos start popping up in inboxes, users will be able to quickly spot when something’s not right. They’ll also learn to recognize the brand they know and like, coming with obvious benefits for the companies. We will cover more about that later.<br></p>



<p>BIMI email authentication is developed as an open standard and it is possible that not only email clients will adopt it. Among the most likely candidates, messaging and social media apps are mentioned. Companies present there could also benefit from additional security. The platforms will probably be eager to get verified accounts on board. BIMI records could make a lot of difference.<br></p>



<p>We’ll see how it all plays out. At the time of writing (Dec. 2019), BIMI is in a pilot stage with Verizon Media Group (Yahoo!, AOL). Google recently also <a href="https://www.prnewswire.com/news-releases/google-joins-authindicators-working-group-and-commits-to-bimi-pilot-300890074.html" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">announced that they will be trialing BIMI in 2020.</a> If everything works out as expected, we can see BIMI records being adopted more in the coming years.<br></p>



<h2><span id="What_are_the_requirements_to_join_the_BIMI_club">What are the requirements to join the BIMI club?</span></h2>



<p>For BIMI to work, several conditions need to be met:</p>



<ul><li>The sender’s domain needs to be DMARC-authenticated, with either ‘reject’ or ‘quarantine’ policy set up</li><li>The domain’s owner needs to obtain the right certification</li><li>A good sending history needs to be built</li></ul><p>Let’s discuss these conditions one-by-one.<br></p>



<h3><span id="Be_DMARC-certified">Be DMARC-certified</span></h3>



<p>We already discussed DMARC on our blog, but if you wish to read more about it, check out our <a href="https://blog.mailtrap.io/dmarc-explained/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">DMARC Explained</a> article, along with our tips on <a href="https://blog.mailtrap.io/dmarc-setup/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">how to set up DMARC record</a>.<br></p>



<p>Long story short, DMARC is an authentication method that works on top of SPF and/or DKIM.<br></p>



<p><a href="https://blog.mailtrap.io/spf-records-explained/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">SPF</a> is used to specify which IP addresses are allowed to send emails on behalf of a given domain. <a href="https://blog.mailtrap.io/dkim/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">DKIM</a>, on the other hand, allows incoming servers to verify the headers and body of a message, so that they look just like they did when they were leaving the sender’s inbox.</p>



<p>DMARC runs either check (or both) and performs a separate domain alignment test for the methods used. Finally, a policy assigned with DMARC can suggest an incoming server if emails that fail a test should be:</p>



<ul><li>Reject -&gt; discarded and not delivered to the recipient’s inbox</li><li>Quarantine -&gt; sent to the spam folder</li><li>None -&gt; treated as though no check was made (good for testing)</li></ul><p>As we mentioned earlier, to qualify for BIMI, the policy needs to be set to either ‘quarantine’ or ‘reject’. Of course, the DMARC record needs to be properly configured.<br></p>



<p>DMARC doesn’t require both DKIM and SPF to be set up (though it’s a smart thing to do). For the BIMI record to have any effect, either of these methods should be in place, along with DMARC, of course. A check will be performed every time a message is due to be delivered, so it’s worth triple-checking if everything is intact.<br></p>



<h3><span id="Obtain_a_certification">Obtain a certification</span></h3>



<p>To add an additional layer of security, bodies governing BIMI, referred to as Mark Verifying Authorities (MVA), will ask for additional proof of domain ownership.&nbsp;<br></p>



<p>To get in, you’ll need to obtain an <a href="https://en.wikipedia.org/wiki/Extended_Validation_Certificate" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">EV (Extended Validation) certificate</a> and meet several additional requirements:</p>



<ul><li>Prove the ownership or the right to use a registered trademark</li><li>Have this trademark registered in a competent jurisdiction</li><li>Make sure the logo from the BIMI record matches the trademark</li><li>Assure the owner of a trademark is also a registrant of a given domain name (alternative, those using a trademark under a license must be registered as licensees of a domain)</li></ul><p>Only if all of these conditions are met, the MVA will proceed to issue a respective certification.<br></p>



<p>Keep in mind that these rules may change at any point. CNN was the first company to obtain a certificate from MVA and <a href="https://martechtoday.com/cnn-com-receives-first-verified-mark-certificate-in-preparation-for-bimi-email-standard-236255" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">it happened only in October 2019</a>. Before the program is rolled out to the public, the rules will likely be re-evaluated a number of times and some tweaks might be introduced. We’ll do our best to update this article if any of these happen.<br></p>



<h3><span id="Maintain_a_good_sending_history">Maintain a good sending history</span></h3>



<p>The last requirement is rather vague, but is important to keep in mind. In order to qualify for BIMI, you’ll need to have a good sending reputation, both for your domain and IP address.&nbsp;<br></p>



<p>This means having a healthy, engaged list of subscribers. Of course, you should avoid <a href="https://blog.mailtrap.io/soft-vs-hard-bounce/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">email bounces</a> and spam reports, but the fact that your emails are regularly opened by the recipients will also play a significant role.&nbsp;<br></p>



<p>You also will need to have a track record of sending a significant volume of emails. Smaller senders may also be granted access to BIMI at some point but for now, only bigger brands will have a shot.</p>



<div data-id="1" data-render-id="0" data-tracking="enabled" data-intro="no_animation" data-sub-type="shortcode"><div><div><div><div><div><div><div><p><span>Join our newsletter</span><span>Only the best content, delivered once a month. Unsubscribe anytime.</span></p></div></div></div></div></div></div></div></div>



<h2><span id="How_to_implement_BIMI_records">How to implement BIMI records?</span></h2>



<p>Once you meet all the requirements and obtain respective certifications, you can go on and add a proper record to your Domain Name System (DNS).<br></p>



<p>Then, you’ll need to upload your logo, necessarily in SVG format to a public HTTPS address. It’s recommended that it’s square-shaped and transparent. You may also want to avoid any unnecessary text as the logo displayed will be really small, making reading nearly impossible.<br></p>



<p>Finally, you will add a TXT record for <em>default._bimi.DomainAddress</em> in the following format: </p>



<pre><code>v=BIMI1; l=logoURL;</code></pre>



<p>For example, for Mailtrap it could be:</p>



<pre><code>v=BIMI1; l=https://www.mailtrap.io/logo123.svg;</code></pre>



<p>(it’s not really a valid address but if you wish to use our logo, let us know!)<br></p>



<p>That’s all. If you’re approved into the program and everything was configured properly, you should see the first effects within a few days.<br></p>



<h2><span id="Where_can_BIMI_authentication_make_a_difference">Where can BIMI authentication make a difference?</span></h2>



<p>When talking about BIMI authentication and its impact, the first thing that comes up is email security. After all, that’s precisely what BIMI record was introduced for. We also can’t underestimate the marketing impact it can have on brands. Let’s talk about these two aspects.<br></p>



<h3><span id="Security_impact">Security impact</span></h3>



<p>While DKIM and SPF help prevent spoofing, skillful fraudsters can bypass these measures, especially if only one of them is set up. DMARC is much more difficult, as domain alignment is also checked. Chances are someone will pass through.<br></p>



<p>That’s when BIMI comes very handy. Most users don’t check email addresses of the senders and email clients don’t display them right away. Instead, all users see is the display name of a sender, sometimes with company initials.<br></p>



<p>This can be easily spoofed. <strong>When a BIMI record is in place, a brand’s missing logo may raise a yellow flag </strong>for those used to seeing the branding displayed for each email.<br></p>



<p>Popularizing BIMI will also directly <strong>impact the adoption rate of DMARC</strong>. Even after several years since the release, most companies still don’t use this technology and, according to <a href="https://www.agari.com/insights/ebooks/2018-q4-report/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Agari’s research</a>, only 8% of Fortune 500 companies have ‘reject’ or ‘quarantine’ policies in place. All the others are vulnerable to attacks, most of which can be easily prevented with the more sophisticated tools.<br></p>



<p>It’s in the best interest of both users and email service providers to drive the adoption of DMARC. BIMI has a chance to finally move the numbers in the right direction.<br></p>



<h3><span id="Marketing_impact">Marketing impact</span></h3>



<p>BIMI implementation can have a major impact on marketing efforts. Since BIMI is and will be free to participate in, brands will get <strong>free exposure with almost no effort</strong>. Users will learn to recognize their logos right on the spot.<br></p>



<p>Emails signed with logos will also <strong>build users’ trust</strong>, especially if the content that follows is valuable. They will certainly feel safer opening emails from familiar sources.<br></p>



<p>BIMI will likely expand at some point to other forms of online communication. Those that participate will be able to continuously develop brand awareness and quickly gain recognition.<br></p>



<p>Since the BIMI logo for an email is fetched from a DNS every time a message is delivered, <strong>rebranding will also run smoother than it usually does</strong>. All it will take is updating an SVG file in the domain’s DNS and changes will be applied with the next email delivered.<br></p>



<h2><span id="Wrapping_up">Wrapping up</span></h2>



<p>All of this sounds really exciting and we’ll be watching closely how this all evolves. Many companies will surely take advantage of this opportunity and once the pilots wrap up, many more will follow their steps.&nbsp;<br></p>



<p>Chances are that a few years from now, we’ll be looking suspiciously at emails coming in without company logos. Or who knows, maybe a completely different approach will take over by then and change the way we think about email authentication.<br></p>



<p>Whether you’re eligible for the program or not, you likely have a vital interest in making your emails better, and rightly so. On the Mailtrap blog, we write a lot about email authentication and other related topics. We share tips for improving your campaigns and warn of the mistakes many marketers make. Explore our blog and become an email testing expert in no time!<br></p>
		<!-- END .ss-inline-share-wrapper -->
					
		</div><!-- .entry-content -->

		<!-- .entry-footer -->
	</div>
</article></div>]]>
            </description>
            <link>https://blog.mailtrap.io/bimi-email/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25188559</guid>
            <pubDate>Mon, 23 Nov 2020 16:39:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Small Games]]>
            </title>
            <description>
<![CDATA[
Score 192 | Comments 88 (<a href="https://news.ycombinator.com/item?id=25188542">thread link</a>) | @polm23
<br/>
November 23, 2020 | https://lorenzo.itch.io/on-small-games | <a href="https://web.archive.org/web/*/https://lorenzo.itch.io/on-small-games">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><em>I wanted to write a Small Games Manifesto for the Manifesto Jam, but I&nbsp;was too tired, so I collected&nbsp;other people's thoughts about small games instead.</em></p>

<p><em>See also: <a href="http://ebeth.itch.io/small-games-manifesto" target="_blank">Small Games Manifesto</a> by Ebeth.</em><br></p>

<p><em>Looking for some small games to play? Check out my <a href="https://itch.io/c/6160/small-is-beautiful" target="_blank">Small is Beautiful</a> and&nbsp;<a href="https://itch.io/c/232207/bitsy-faves-pt2-20192020" target="_blank">Bitsy Faves</a>&nbsp;collections.</em></p>

<p><em>Follow me on Twitter <a href="https://twitter.com/LorenzoPilia" target="_blank" rel="nofollow noopener">@LorenzoPilia</a></em></p>

<p>• • • • •</p>

<p>Make short and intense games:<br>think haiku, not epic.<br>Think poetry, not prose.<br><strong>— Auriea Harvey &amp; Michaël Samyn: Realtime Art Manifesto</strong><br><a href="http://tale-of-tales.com/tales/RAM.html" rel="nofollow noopener">http://tale-of-tales.com/tales/RAM.html</a></p>

<p>• • • • •<br></p>

<p>things i will never do in this lifetime:&nbsp;<br>play a game for a few straight hours<br>play a game with more than a few hours worth of content<br><strong>— @moshboy</strong><br><a href="https://twitter.com/moshboy/status/607408540496465922" rel="nofollow noopener">https://twitter.com/moshboy/status/607408540496465922</a></p>

<p>• • • • •<br></p>

<p>Hell, you'd be surprised at how many people buy games with a moderate length and never finish them. On PC over 50 percent of the people who bought the latest Wolfenstein, a game you can beat in under 15 hours, never earned the achievement for finishing the story. Only 31 percent of Dishonored players on the PC beat the game. People think game length is mandatory, but even shorter games aren't finished by the majority of players.
<br><strong>— Ben Kuchera: To hell with longer games, tell me how SHORT your game is</strong><br><a href="https://www.polygon.com/2014/10/14/6974791/short-games-review" rel="nofollow noopener">https://www.polygon.com/2014/10/14/6974791/short-games-review</a></p>

<p>• • • • •<br></p>

<p>Especially if you're starting out, try to do small projects and don't worry too much about polishing them, don't worry about shipping the perfect game, embrace the messiness of getting into games for the first time, embrace not knowing what you're doing exactly yet. (...) If you just put your heart into it in that way, and embrace the messiness of small games, people will really connect with that.<br><strong>— Nina Freeman: Keynote at A MAZE. / Johannesburg 2017<br></strong><a href="https://twitter.com/AMazeFest/status/908032352953217038" rel="nofollow noopener">https://twitter.com/AMazeFest/status/908032352953217038</a></p>

<p>• • • • •<br></p>

<p>Duration doesn't need to be a burden. It can be a tool to wield.<br><strong>— Thomas McMullan: Inside and the rise of short games</strong><br><a href="http://www.alphr.com/games/1003958/inside-and-the-rise-of-short-games" rel="nofollow noopener">http://www.alphr.com/games/1003958/inside-and-the-rise-of-short-games</a></p>

<p>• • • • •<br></p>

<p>Small-scale works are often derided for feeling embryonic or unfinished, throwaway motifs or fledgling ideas that the artist failed to integrate into a sufficiently ambitious whole. Game designer Jake Elliott, who drew the title of his Ruins from Schumann’s appraisal of Chopin’s preludes, defended their proportion in an interview: “Maybe [Chopin] felt like they were complete objects, but there wasn’t a vocabulary for talking about pieces of music that were short at the time. Their length is what drew me … there is a lot that’s unspoken.” Having conventionally privileged length, magnitude, and formal unity, games too have left critics bereft of a clear rubric for evaluating intentionally abbreviated, serialized, even disorderly exercises in interactive design.<br><strong>— Peter Lido: Undertale, one year later</strong><br><a href="https://killscreen.com/articles/undertale-one-year-later/" rel="nofollow noopener">https://killscreen.com/articles/undertale-one-year-later/</a></p>

<p>• • • • •<br></p>

<p>The final idea that we brought over as gamers, the final idea that we had to let go of, was that a longer game makes a better game. We felt that the sense of completion and catharsis that you get when you watch our ending was so critical to the experience, that we decided that we had to help as many people as possible to complete Monument Valley. And that was more important than making the game longer or more difficult.<br><strong>— Ken Wong: Games Without Gamers (#DICE2014 Europe)</strong><br><a href="http://youtu.be/YdSClYHDow0?t=13m37s" rel="nofollow noopener">https://youtu.be/YdSClYHDow0?t=13m37s</a></p>

<p>• • • • •<br></p>

<p>I value games being short, it makes them easier to fit into life, they get to the point sooner, it's possible to play them more times, trying out different possibilities, there's a clearer connection between decisions and outcome.<br><strong>— Michael Brough: imbroglio notes 6 - meditation</strong><br><a href="http://mightyvision.blogspot.de/2016/08/imbroglio-notes-6-meditation.html?m=1" rel="nofollow noopener">http://mightyvision.blogspot.de/2016/08/imbroglio-notes-6-meditation.html?m=1</a></p>

<p>• • • • •<br></p>

<p>Small games must be protected from their own defenders!! They must be defended against a rhetoric of convenience, as if fitting helpfully into the meagre free time allotted us by rentiers was something to be proud of rather than something to grind against - they must be defended against the meagre virtues of "minimalism", parsimony, elegance, the values of those with enough cultural cachet that they can afford to speak softly, and which hold the same relation to an actual human economy of wants and needs as does a millionaire who doesn't tip.<br><strong>— thecathamites: Small Game Manifesto (part of&nbsp;Buttertown, 10 manifestos for groups of no people)</strong><br><a href="https://thecatamites.itch.io/buttertown">https://thecatamites.itch.io/buttertown</a></p>


</div></div>]]>
            </description>
            <link>https://lorenzo.itch.io/on-small-games</link>
            <guid isPermaLink="false">hacker-news-small-sites-25188542</guid>
            <pubDate>Mon, 23 Nov 2020 16:38:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Started with Firecracker on Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 25 (<a href="https://news.ycombinator.com/item?id=25187965">thread link</a>) | @sairamkunala
<br/>
November 23, 2020 | https://dev.l1x.be/posts/2020/11/22/getting-started-with-firecracker-on-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://dev.l1x.be/posts/2020/11/22/getting-started-with-firecracker-on-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="abstract">Abstract</h2><p>Traditionally services were deployed on bare metal and in the last decades we have seen the rise of virtualisation (running additional operating systems in a operating system process) and lately containerisation (running an operating system process in a separate security context from the rest of processes on the same host). Virtualisation and containerisation offers different levels of isolation by moving some operating system functionality to the guest systems.</p><p>The following chart illustrates that pretty well:</p><p><img src="https://dev.l1x.be/img/isolation.png" alt="OS functionality location"></p><p>Source: <a href="https://research.cs.wisc.edu/multifacet/papers/vee20_blending.pdf">https://research.cs.wisc.edu/multifacet/papers/vee20_blending.pdf</a></p><p>In this article, I perform a deep dive into Firecracker and how it can be used for deploying services on Raspberry Pi (4B).</p><h2 id="getting-started">Getting started</h2><p>There are few paths to take here. First I am going to try the easy one, using Ubuntu. Later on we can investigate the use of Alpine Linux which is much more lightweight than Ubuntu, ideal for devices like RPI.</p><h3 id="installing-the-image-on-a-microsd-card">Installing the image on a microSD card</h3><p>We need a 64 bit Ubuntu image and a microsd card. For the imaging I use <a href="https://www.balena.io/etcher/">Balena Etcher</a> that makes the imaging process super easy.</p><p>Getting the pre-installed image:</p><div><pre><code data-lang="bash">wget https://cdimage.ubuntu.com/releases/20.04/release/<span>\
</span><span></span>ubuntu-20.04.1-preinstalled-server-arm64+raspi.img.xz
</code></pre></div><p>Preinstalled means that we get a fully working operating system and there is no need for additional installation steps after booting up. With Balena Etcher it is super easy to write the compressed image file to the sd card and boot the system up once ready. SSHD starts up after the installation and we can log in via ssh if we know the IP address that the DHCP server issues to our device (assuming DHCP server is present in our LAN).</p><p>There are few mildly annoying things with Ubuntu (snaps, unattended-upgrades) that I usually remove. I also prefer to use Chrony over the systemd equivalent. Ansible repo for these is available here: <a href="https://github.com/l1x/rpi/blob/main/ubuntu.20/ansible/roles/os/tasks/main.yml">https://github.com/l1x/rpi/blob/main/ubuntu.20/ansible/roles/os/tasks/main.yml</a></p><h3 id="installing-firecracker-jailer-and-firectl">Installing Firecracker, Jailer and Firectl</h3><ul><li>Firecracker: The main component, it is a virtual machine monitor (VMM) that uses the Linux Kernel Virtual Machine (KVM) to create and run microVMs.</li><li>Jailer: For starting Firecracker in production mode, applies a cgroup/namespace isolation barrier and then drops privileges. There</li><li>Firectl: A command line utility for convenience</li></ul><h4 id="getting-firecracker-and-jailer">Getting Firecracker and Jailer</h4><p>For the first two it is possible to download the release binaries from Github.</p><div><pre><code data-lang="bash"><span>version</span><span>=</span><span>'v0.23.0'</span>

wget https://github.com/firecracker-microvm/firecracker/<span>\
</span><span></span>releases/download/<span>${</span><span>version</span><span>}</span>/firecracker-<span>${</span><span>version</span><span>}</span>-aarch64
wget https://github.com/firecracker-microvm/firecracker/<span>\
</span><span></span>releases/download/<span>${</span><span>version</span><span>}</span>/jailer-<span>${</span><span>version</span><span>}</span>-aarch64

mv firecracker-<span>${</span><span>version</span><span>}</span>-aarch64 firecracker
mv jailer-<span>${</span><span>version</span><span>}</span>-aarch64 jailer

chmod +x firecracker jailer

./firecracker --help
./jailer --help
</code></pre></div><h4 id="firectl">Firectl</h4><p>Firectl is a bit trickier to install because there is no release binary and it requires Golang 1.14 to compile. We can do these in two steps.</p><div><pre><code data-lang="bash">wget https://golang.org/dl/go1.14.12.linux-arm64.tar.gz
tar xzvf go1.14.12.linux-arm64.tar.gz
</code></pre></div><p>After getting go we can get the source of firectl and compile it:</p><div><pre><code data-lang="bash">git clone https://github.com/firecracker-microvm/firectl.git
<span>cd</span> firectl/
 ~/go/bin/go build -x
</code></pre></div><p>Testing Firectl:</p><p>We have all the tools we need for running our first microVM the only thing is missing: something to run.</p><h3 id="downloading-our-first-image">Downloading our first image</h3><p>For a microVM there are two things necessary to have:</p><ul><li>an uncompressed linux kernel (vmlinux)</li><li>a filesystem</li></ul><p>Later on we are going to investigate how we could create our own version of these, but for now we are going to use images from</p><div><pre><code data-lang="bash">wget https://s3.amazonaws.com/spec.ccfc.min/<span>\
</span><span></span>img/aarch64/ubuntu_with_ssh/kernel/vmlinux.bin
wget https://s3.amazonaws.com/spec.ccfc.min/<span>\
</span><span></span>img/aarch64/ubuntu_with_ssh/fsfiles/xenial.rootfs.ext4
</code></pre></div><h3 id="configuring-network">Configuring network</h3><p>For the microVM to function properly we need a networking device. For this scenario we are going to use tap and create a device:</p><div><pre><code data-lang="bash">sudo ip tuntap add dev tap0 mode tap
sudo ip addr add 172.16.0.1/24 dev tap0
sudo ip link <span>set</span> tap0 up
ip addr show dev tap0
</code></pre></div><p>If we want to give access to our VM we have to enable IP forwarding:</p><div><pre><code data-lang="bash"><span>DEVICE_NAME</span><span>=</span>eth0
sudo sh -c <span>"echo 1 &gt; /proc/sys/net/ipv4/ip_forward"</span>
sudo iptables -t nat -A POSTROUTING -o <span>$DEVICE_NAME</span> -j MASQUERADE
sudo iptables -A FORWARD -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
sudo iptables -A FORWARD -i tap0 -o <span>$DEVICE_NAME</span> -j ACCEPT
</code></pre></div><h3 id="running-our-first-microvm">Running our first microVM</h3><p>This is how we can start up our first microVM. I usually start it in screen so I can open a new session easily because it will use the standard input and output for the newly started of console (unless you redirect it).</p><p>This is for debug mode, starting with sudo:</p><div><pre><code data-lang="bash">sudo ./firectl/firectl <span>\
</span><span></span>--firecracker-binary<span>=</span>./firecracker <span>\
</span><span></span>--kernel<span>=</span>vmlinux.bin <span>\
</span><span></span>--tap-device<span>=</span>tap0/aa:fc:00:00:00:01 <span>\
</span><span></span>--kernel-opts<span>=</span><span>\
</span><span></span><span>"console=ttyS0 reboot=k panic=1 pci=off \
</span><span>ip=172.16.0.42::172.16.0.1:255.255.255.0::eth0:off"</span> <span>\
</span><span></span>--root-drive<span>=</span>./xenial.rootfs.ext4
</code></pre></div><p>If everything went well you can see something like this:</p><pre><code>Ubuntu 18.04.2 LTS fadfdd4af58a ttyS0

fadfdd4af58a login:
</code></pre><p>User and password is root:root.</p><h3 id="testing-networking">Testing networking</h3><p>For this we need to have a bit bigger image.</p><div><pre><code data-lang="bash">dd <span>if</span><span>=</span>/dev/zero <span>bs</span><span>=</span>1M <span>count</span><span>=</span><span>800</span> &gt;&gt; xenial.rootfs.ext4
resize2fs -f xenial.rootfs.ext4
</code></pre></div><p>After starting up the usual way and logging in we need to fix few things:</p><p>Adding some working nameserver:</p><div><pre><code data-lang="bash"><span>echo</span> <span>'nameserver 1.1.1.1'</span> &gt;  /etc/resolv.conf
</code></pre></div><p>Now trying to update:</p><div><pre><code data-lang="bash">root@fadfdd4af58a:~# apt update
Get:1 http://ports.ubuntu.com/ubuntu-ports bionic InRelease <span>[</span><span>242</span> kB<span>]</span>
Get:2 http://ports.ubuntu.com/ubuntu-ports bionic-updates InRelease <span>[</span>88.7 kB<span>]</span>
Hit:3 http://ports.ubuntu.com/ubuntu-ports bionic-backports InRelease
Hit:4 http://ports.ubuntu.com/ubuntu-ports bionic-security InRelease
Get:5 http://ports.ubuntu.com/ubuntu-ports bionic/universe arm64 Packages <span>[</span>11.0 MB<span>]</span>
Get:6 http://ports.ubuntu.com/ubuntu-ports bionic/multiverse arm64 Packages <span>[</span><span>153</span> kB<span>]</span>
Get:7 http://ports.ubuntu.com/ubuntu-ports bionic/main arm64 Packages <span>[</span><span>1285</span> kB<span>]</span>
Get:8 http://ports.ubuntu.com/ubuntu-ports bionic/restricted arm64 Packages <span>[</span><span>572</span> B<span>]</span>
Get:9 http://ports.ubuntu.com/ubuntu-ports bionic-updates/universe arm64 Packages <span>[</span><span>1865</span> kB<span>]</span>
Get:10 http://ports.ubuntu.com/ubuntu-ports bionic-updates/restricted arm64 Packages <span>[</span><span>2262</span> B<span>]</span>
Get:11 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 Packages <span>[</span><span>1431</span> kB<span>]</span>
Get:12 http://ports.ubuntu.com/ubuntu-ports bionic-updates/multiverse arm64 Packages <span>[</span><span>5758</span> B<span>]</span>
Fetched 16.1 MB in 6s <span>(</span><span>2543</span> kB/s<span>)</span>
Reading package lists... Error!
E: flAbsPath on /var/lib/dpkg/status failed - realpath <span>(</span>2: No such file or directory<span>)</span>
E: Could not open file  - open <span>(</span>2: No such file or directory<span>)</span>
E: Problem opening
E: The package lists or status file could not be parsed or opened.
</code></pre></div><p>Fixing the apt issues:</p><div><pre><code data-lang="bash">mkdir -p /var/lib/dpkg/<span>{</span>info,alternatives<span>}</span>
touch /var/lib/dpkg/status
apt install apt-utils -y
</code></pre></div><p>Enjoy!</p><p>Next time we can go through how to compile a new kernel and have a different rootfs (potentially using Alpine).</p></div></div>]]>
            </description>
            <link>https://dev.l1x.be/posts/2020/11/22/getting-started-with-firecracker-on-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25187965</guid>
            <pubDate>Mon, 23 Nov 2020 15:48:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Somfy blinds automated via MQTT and Home Assistant]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25187945">thread link</a>) | @ggambetta
<br/>
November 23, 2020 | https://mwitkow.me/posts/2020-11-08_somfy/ | <a href="https://web.archive.org/web/*/https://mwitkow.me/posts/2020-11-08_somfy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In this post I’ll show you how to use a Raspberry Pi and some soldering skills to automate old Somfy blinds via the MQTT protocol exposed to Home Assistant and Google Home.</p><p>We’ve moved to a new apartment and one of its features are external blinds (a.k.a. covers) that are controlled through a dedicated remote of the Somfy brand. However, just like with a TV, finding the remote is often tricky, so I decided to try and automate the external blind movements through Home Assistant and further voice commands of Google Home.</p><p>The system in place is a Somfy’s Telis 4 RTS Pure remote, with two remotes, each being able to program 5 channels (4 individual ones and combined). The system uses a legacy, proprietary radio protocol called <a href="https://service.somfy.com/downloads/nam_v4/rts_pocket_guide_dec_2017.pdf">RTS</a>, which only Somfy and Telis use.</p><p>Somfy offers a RTS bridge called <a href="https://www.somfysystems.com/en-us/products/1811403/mylink">Somfy MyLink</a> for a wooping ~300CHF, which is a little steep for something that is not necessary and just scratching an itch. Also, there’s not much fun in that.</p><p>Turns out, <a href="https://github.com/Nickduino/">Nickduino</a> had a similar itch to scratch. Using 3-4 CHF-worth of hardware components, it is quite easy to build a software radio that will immitate a Somfy Telis remote and control the blinds.</p><p>There’s an bare-bones <a href="https://github.com/Nickduino/Somfy_Remote/blob/master/Somfy_Remote.ino">Somfy Remote Arduino sketch</a> that shows how the protocol works. I originally wanted make the blind controller as small as possible and base it on an <a href="https://en.wikipedia.org/wiki/ESP32">ESP32</a>, taking that sketch and controlling it via <a href="https://github.com/256dpi/arduino-mqtt">arduino-mqtt</a>.</p><p>Turns out there is a full MQTT/web interface script <a href="https://github.com/Nickduino/Pi-Somfy">Nickduino/Pi-Somfy</a> that also only goes into the details of how to solder things, and connect things onto a Raspberry Pi. Laziness won the day, especially as I wanted to use my spare Pi for something anyway.</p><h2 id="the-hardware">The hardware</h2><p>Usually for 433MHz signals you could easily use a ready-made module such us <a href="https://www.berrybase.ch/raspberry-pi-co/raspberry-pi/module-sensoren/433mhz-sender-empf-228-nger-superregeneration-modul-fs1000a-xy-fst-xy-mk-5v">this 2CHF sender-receiver pair</a>. However, in order for Somfy to make their RTS even more proprietary than it already was, it is not using the typical <code>433.93MHz</code> frequency but <code>433.42MHz</code> 🤦‍♂️. This means one will need to do some soldering.</p><p>The PiSomfy <a href="https://github.com/Nickduino/Pi-Somfy#2-hardware">hardware guide</a> is excellent in telling you what you need. I got:</p><ul><li><a href="https://www.ebay.com/itm/5x-433Mhz-RF-transmitter-and-receiver-kit-Module-Arduino-ARM-WL-MCU-Raspberry-Fc-/254607185239?hash=item3b47c55557">5 ready <code>433.93MHz</code> sender circuits</a></li><li><a href="https://www.ebay.com/itm/10pcs-433-42m-433-42mhz-r433-f433-saw-resonator-crystals-to-39-/331637441887?hash=item4d3721c55f">10 pieces of the <code>433.42MHz</code> oscilator</a> - because my soldering is terrible</li><li><a href="https://www.ebay.com/itm/40PCS-20cm-2-54MM-FF-FM-MM-Dupont-wire-jumper-cables-male-to-female-For-Arduino/312724733910?hash=item48cfd8bfd6:g:05sAAOSwlbZdSZ6E">male-male jumper cables</a> - to avoid soldering 😉</li><li>(already had it) a solid copper cable to use as an antenna</li></ul><p>After 4 weeks, all the eBay items were in place, and I could start soldering. Turns out de-soldering things off is much harder than soldering things on. I managed to peel away the original oscillator with by applying leverage underneath it using a swiss army knife and heating its connectors one by one. Soldering the new one was quite easy in comparison.</p><figure><img src="https://mwitkow.me/posts/2020-11-08_somfy/soldering.jpg" alt="It&amp;rsquo;s not pretty but it worked." width="600"><figcaption><p>It’s not pretty but it worked.</p></figcaption></figure><p>I then took a 17cm piece of solid copper cable, and wrapped it into a small coil. Turns out soldering a think 1mm cable to a tiny connector was the trickiest bit, but with the right amount of patience, things will stick eventually.</p><p>Eventually, the fully connected sender fits nicely into a Raspberry Pi enclosure after connecting everything to the GPIO 4 pin:</p><figure><img src="https://mwitkow.me/posts/2020-11-08_somfy/final_side_by_side.jpg" alt="All fits nicely into a standard Pi enclosure. The remote we&amp;rsquo;ll be replacing are on the left." width="700"><figcaption><p>All fits nicely into a standard Pi enclosure. The remote we’ll be replacing are on the left.</p></figcaption></figure><h2 id="programming">Programming</h2><p>Installing Pi-Somfy is super easy, just follow <a href="https://github.com/Nickduino/Pi-Somfy#3-software">these steps</a>. It assume you install it under the default <code>pi</code> user in <code>/home/pi</code>, and comes with a handy <code>systemctl</code> service for auto-starting the system.</p><p>By default it will come up on port <code>:80</code> of your Pi. Programming the blinds takes a little bit of time. The procedure is as follows:</p><ul><li>Set the right channel (individual blind, or all) on the remote you’re programming from.</li><li>Measure the time in seconds it takes for each blind to come fully down.</li><li>Click <em>Add new</em> to put in the name (this will be your MQTT name by the way) and add in the time.</li><li>Using a pen, press the “hole” on the other side of the remote. This sends the signal to the blind to accept programming a new remote.</li><li>Press <em>Save</em> and follow the instructions. The blind should “wiggle” once programmed.</li></ul><p><strong>Note</strong>: The system relies on time to figure out where the blind is percentage-wise. It can often get things wrong (e.g. if you stopped it mid-through), or on the all-channel if blinds have different lengths (e.g. balcony). But in practice it works remarkably well.</p><figure><img src="https://mwitkow.me/posts/2020-11-08_somfy/pi_remote.png" alt="Fully programmed blinds." width="700"><figcaption><p>Fully programmed blinds.</p></figcaption></figure><p><a href="https://en.wikipedia.org/wiki/MQTT">MQTT</a> is a standard protocol for message brokers, and finds a lot of use in home IoT. For most use cases, it has a simple publish-subscribe mechanic based on topics.</p><h2 id="installing-mosquitto">Installing Mosquitto</h2><p>Home Assistant has an embedded MQTT broker, but it is <em>highly advised</em> to use an external one, such as Mosquitto. You should install it on the same machine that runs Home Assistant, as it will act as a hub for other MQTT-connected services. To do that on Ubuntu:</p><div><pre><code data-lang="bash">sudo apt-get update
sudo apt-get install mosquitto mosquitto-clients
</code></pre></div><p>Now let’s set up a password file in <code>/etc/mosquitto/passwd</code> with a user for <code>homeassistant</code> and <code>pisomfy</code>.</p><pre><code>sudo mosquitto_passwd -c /etc/mosquitto/passwd homeassistant
Password: YourHomeAssistantPassword
sudo mosquitto_passwd -c /etc/mosquitto/passwd pisomfy
Password: YourPiSomfyPassword
</code></pre><p>Then, enforce use of passwords in mosquitto by editing <code>/etc/mosquitto/conf.d/default.conf</code> and changing it to:</p><pre><code>allow_anonymous false
password_file /etc/mosquitto/passwd
</code></pre><p>For debugging purposes, open a separate tab on the same machine and subscribe to all messages under the <code>home-assistant/#</code> topic via:</p><pre><code>mosquitto_sub -u homeassistant -P YourHomeAssistantPassword -p 1883 -h 127.0.0.1 -v -t "home-assistant/#"
</code></pre><p>This will come in handy to check things are working.</p><h2 id="configuring-home-assistant">Configuring Home Assistant</h2><p>Update your <code>/etc/homeassistant/configuration.yaml</code> to add:</p><div><pre><code data-lang="yaml"><span>mqtt</span><span>:</span><span>
</span><span>  </span><span>broker</span><span>:</span><span> </span><span>127.0.0.1</span><span>
</span><span>  </span><span>username</span><span>:</span><span> </span><span>homeassistant</span><span>
</span><span>  </span><span>password</span><span>:</span><span> </span><span>"YourHomeAssistantPassword"</span><span>
</span><span>  </span><span>discovery</span><span>:</span><span> </span><span>true</span><span>
</span></code></pre></div><p>Restart Home Assistant</p><pre><code>sudo systemctl restart homeassistant
</code></pre><h3 id="configure-pisomfy">Configure PiSomfy</h3><p>On your Pi machine, open <code>/home/pi/operateShutters.conf</code> and edit the `[MQTT] section to look as follows</p><div><pre><code data-lang="ini"><span>[MQTT]</span>
<span># Location (IP Address of DNS Name) of the MQTT Server</span>
<span>MQTT_Server</span> <span>=</span> <span>myHAmachine # or hostname of your home assistant machine</span>
<span># Port of the MQTT Server</span>
<span>MQTT_Port</span> <span>=</span> <span>1883</span>
<span># Username for the MQTT Server</span>
<span>MQTT_User</span> <span>=</span> <span>pisomfy</span>
<span># Password of the MQTT Server</span>
<span>MQTT_Password</span> <span>=</span> <span>YourPiSomfyPassword</span>
<span># Enable auto discovery</span>
<span>EnableDiscovery</span> <span>=</span> <span>true</span>
</code></pre></div><p>And restart the service:</p><pre><code>sudo systemctl restart shutters.conf`
</code></pre><p>At this point the tab with the subscriptions should be full of messages. These are auto-discovery messages over MQTT for each of the programmed covers. This will cause Home Assistant to automatically add the entities.</p><p>They should show up with the same names as in PiSomfy.</p><figure><img src="https://mwitkow.me/posts/2020-11-08_somfy/home_assistant_entities.png" alt="Home Assistant Entities auto discovered via MQTT." width="800"><figcaption><p>Home Assistant Entities auto discovered via MQTT.</p></figcaption></figure><p>Adding them to a dashboard is relatively trivial, for example:</p><div><pre><code data-lang="yaml"><span>type</span><span>:</span><span> </span><span>entities</span><span>
</span><span></span><span>entities</span><span>:</span><span>
</span><span>  </span>- <span>entity</span><span>:</span><span> </span><span>cover.lr_all</span><span>
</span><span>    </span><span>name</span><span>:</span><span> </span><span>Living Room Covers</span><span>
</span></code></pre></div><p>In order to simplify things, I wanted to only expose the <code>_all</code> blinds (a.k.a. covers) to Google Home/Assistant. For that I added an explicit section in the <code>/etc/homeassistant/configuration.yaml</code> section of <code>google_assistant</code>:</p><div><pre><code data-lang="yaml"><span>google_assistant</span><span>:</span><span>
</span><span>  </span><span># ...</span><span>
</span><span>  </span><span>exposed_domains</span><span>:</span><span>
</span><span>    </span>- <span>fan</span><span>
</span><span>  </span><span>entity_config</span><span>:</span><span>
</span><span>    </span><span>cover.br_all</span><span>:</span><span>
</span><span>      </span><span>expose</span><span>:</span><span> </span><span>true</span><span>
</span><span>      </span><span>aliases</span><span>:</span><span>
</span><span>        </span>- <span>"Bedroom Covers"</span><span>
</span><span>    </span><span>cover.lr_all</span><span>:</span><span>
</span><span>      </span><span>expose</span><span>:</span><span> </span><span>true</span><span>
</span><span>      </span><span>aliases</span><span>:</span><span>
</span><span>        </span>- <span>"Living Room Covers"</span><span>
</span></code></pre></div><p>After restarting Home Assistant, and uttering the magical <em>Ok Google, Sync All Devices</em>, the covers will show up in your Home App:</p><figure><img src="https://mwitkow.me/posts/2020-11-08_somfy/google_home.jpg" alt="Looks like a blind, acts as a blind." width="300"><figcaption><p>Looks like a blind, acts as a blind.</p></figcaption></figure><p>This means you can controll it using keywords:</p><ul><li><em>Ok Google, close Bedroom covers</em></li><li><em>Ok Google, open Bedroom covers</em></li><li><em>Ok Google, set Bedroom covers to 50%</em></li></ul><p>The killer feature is setting this up as a routine to open/close the blind as you wake up, go to sleep.</p><p>Happy hacking :)</p></div></div>]]>
            </description>
            <link>https://mwitkow.me/posts/2020-11-08_somfy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25187945</guid>
            <pubDate>Mon, 23 Nov 2020 15:46:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Testing MAYHEM the open source RF hacking Portapack firmware]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25187801">thread link</a>) | @wolframio
<br/>
November 23, 2020 | https://telescope.ac/petazzoni/mayhem-the-rf-pentesting-hackrf-portapack-firmware | <a href="https://web.archive.org/web/*/https://telescope.ac/petazzoni/mayhem-the-rf-pentesting-hackrf-portapack-firmware">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>This article – the first in a series – will walk you through the basics of Portapack MAYHEM firmware, installation and some hands-on testing of RF spoofing, DoS and Replay Attacks.</p><p>The <a href="https://bit.ly/2UUKgRG" target="_blank" rel="nofollow noopener">PortaPack is a HackRF software defined radio plus screen/keypad under $200</a> which allows you to go portable with the HackRF and a battery pack. It features a small touchscreen LCD and an iPod like control wheel that is used to control custom HackRF firmware which includes an audio receiver, several built in digital decoders and transmitters too. With the PortaPack no PC is required to receive or transmit with the HackRF.</p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/7edf36e9aaecaea695b6914190d5ec2ad2cb49d7c4d8bb94ae8535996ba0931f.jpeg"></p><p>The functionality of your portapack depends on the software you run on it. There are several options but running the MAYHEM firmware will then give you some a really amazing amount of cool features. While listening to transmissions from ships, planes or emergency services is hardly news to police scanner owners using the Portapack is as easy as entering the correct frequency. </p><p>Channel information for almost any Police/Fire Deparment Radio could be found on RadioReference Wiki, sample <a href="https://wiki.radioreference.com/index.php/New_York_Times_Square_New_Year's_Eve_ball_drop" target="_blank" rel="nofollow noopener">Scanner frequencies for the annual Times Square New Years Celebration</a>.</p><p>But where the MAYHEM firmware stands out is in the ability to receive and transmit data from digital messaging systems, remote controls, smart car sensors and others. It can even spoof critical beacon signals as those from aircraft transponders or GPS satellites. </p><p>As of the time of this post the currently available decoders and transmit options can be seen in the screenshots below.  Note that for the transmitter options, there are some there that could really land you in trouble with the law so be very careful to exercise caution and only transmit what you are legally allowed to.</p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/37de762b5b6f97bb464fdd6179ce9f37cdd05785731fee0b8d461eb55bf0f84c.png"></p><p>The PortaPack add-on hardware to the HackRF was released several years ago  but the firmware was not developed very far beyond listening to audio and implementing a few transmitters. For a time this interesting device was forgotten compared to its brother HackRF. After some years the third party 'Havoc' firmware by 'furrtek' greatly expanded the list of  decoders and transmit options. Unfortunately the havok firmware is no longer maintained so we're now looking at the open-source <a href="https://github.com/eried/portapack-mayhem" target="_blank" rel="nofollow noopener">MAYHEM firmware</a> by ’eried’, an active fork with even more features.</p><p>Another reason why the Portapack is becoming more popular is because of its dropping price. Both the Portapack and the HackRF are open source hardware, anyone can produce their own device based on the code and available designs. Therefore a "clone" of Portapack is just as good as an original one. With open source code hardware there is no such thing as genuine hardware. For this reason, right now it is possible to find a complete <a href="https://bit.ly/2UUKgRG" target="_blank" rel="nofollow noopener">HackRF and Portapack kits offers from China</a>, for half the $500 which is what it initially cost when it was released years ago.</p><p><strong>Installation</strong></p><p>There are two versions of the portapack: the Portapack H1 and the Portapack H2, the only difference is the screen size. Both are fully compatible with MAYHEM, in my case I choose the H1 because is cheaper.</p><p>Installing the firmware is really easy. One of the characteristics of the HackRF along with the Portapack is that it is practically impossible to brick, so there is no need to worry about this process. It is always recommended to update the firmware with the latest realease of the project, since although some vendors even include the old Havoc or even the new Mayhem firmware, they are rarely the latest version since it is a project that adds constant improvements.</p><p>Download last release from <a href="https://github.com/eried/portapack-mayhem/releases" target="_blank" rel="nofollow noopener">https://github.com/eried/portapack-mayhem/releases</a></p><h4>Windows</h4><ol><li>Connect the device via USB</li><li>Switch to HackRF mode via the on-screen option (in the PortaPack)</li><li>Double click <code>flash_portapack_mayhem.bat</code> and follow the instructions</li><li>Reboot the device</li></ol><h4>Linux</h4><ol><li>Connect the device via USB</li><li>Switch to HackRF mode via the on-screen option (in the PortaPack)</li><li>Upload the firmware with <code>hackrf_spiflash -w new_firmware_file.bin</code></li><li>Reboot the device</li></ol><h2><strong>Hands-on Testing</strong></h2><p>The list of supported radio protocols on MAYHEM is impressive: Police Scanner, IQ file replay,  Microphone FM transmit with CTCSS, CTCSS decoder, Frequency manager (save &amp; load from SD card, with categories and notes), "Soundboard" wave file player from  files in SD card , ADS-B receiver with map view, ADS-B transmitter (aircraft spoof), SSTV transmitter, Fully configurable jammer, POCSAG transmitter, POCSAG receiver/decoder, Morse transmitter (FM tone and CW), OOK transmitter for common remote encoders (PT2262, doorbells, remote outlets, some garage doors, ...), RDS (Radio Data System) PSN, RadioText and Time groups transmitter, Meteorological ballon radiosonde receiver (M10, M2K2, ...) , AFSK receiver, AFSK transmitter (Bell202, ...) , Nuoptix DTMF sync transmitter, French LCR (Language de Commande Routier) message generator,  Street lighting control transmitter (CCIR tones), Fully configurable RF signal generator, car TPMS decoder, car keyfoob spoofer (Subaru), Nordic NRF decoder, APRS decoder and transmitter, RSSI audio output as pitch (for direction finding), BurgerPager Spoofer, and more. </p><p>For audio RX/TX you need a TRRS (3 ring) jack plug with the Left-Right-Mic-Ground arrangement. I believe that's the most common arrangement for android headsets. </p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/b7ff4035575a53c56352e6e1fa60fceb9ba25dd832de6bd7b85683110f779607.png"></p><p>There are so many that I would not have time or means to test all the functions, but I can attest all the ones I have tried work perfectly, here are some examples.</p><p><strong>RF REPLAY ATTACKS</strong></p><p>Our Portapack has the ability to capture broadcasts in IQ format and subsequently re-broadcast them over the air. Quadrature signals, also called IQ signals, IQ data or IQ samples, are often used in RF applications. They form the basis of complex RF signal modulation and demodulation, both in hardware and in software, as well as in complex signal analysis. </p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/e1e529faea7da42ebc0d3c7482281688438d438bd58d75248778ff1c9ffa95d7.png"></p><p>For simplicity, you can consider that an IQ capture is a raw capture without any type of demodulation applied and that holds enough information to later be able to analyze its content and decode. Conversely, if we encode a RF signal in IQ format, it will be very easy to send it to the air.</p><p>Black Hills Infosec has a great introduction to RF Replay attacks over their blog. <a href="https://www.blackhillsinfosec.com/how-to-replay-rf-signals-using-sdr/" target="_blank" rel="nofollow noopener">https://www.blackhillsinfosec.com/how-to-replay-rf-signals-using-sdr/</a></p><p>The best thing about the Portapack is that you do not need practically any RF knowledge or work to launch this attack, therefore it is very easy to check whether a system is vulnerable or not, before taking the time to analyzing the protocol in more depth.</p><p><strong>REMOTE CONTROLS</strong></p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/9622d19919fe2d8c3271835fea7fb2ccf707994339c8d3d0b433f910ca416ee7.jpeg"></p><p>Many of the remote-control systems we use today still use insecure protocols without any encryption or spread spectrum. Furthermore, systems based on fixed codes are still extensively used. That make basic wireless remote control rather easy to implement, but also utterly insecure. They are commonly used in inexpensive wireless devices to control garage doors, fans, toys and even some alarm systems.</p><p>Our Portapack supports sending command through various remote-control protocols. Among them the PT2262/PT2272. These ICs utilize fixed address codes and no inherent encryption so they are not high security devices.</p><p>PT2272 presents 4 bits of data and uses 8 bits address. Keep in mind that these are tri-state bits, so they can have low, float and high states. Capturing these codes from the air is incredibly easy with an SDR and software like rtl_433.  Addressing is often implemented with solder pads but, occasionally with jumpers and rarely with tri-state dip switches.  And a special note, as we have said the floating value (without any soldering) is totally valid and would work fine. Therefore in the world there are possibly thousands or tens of thousands  PT2272 devices installed by default where no code was configured so are working using the FFFFFF address.</p><p><strong>POCSAG</strong></p><p>A pager (also known as a beeper) is a wireless telecommunications device that receives and displays alphanumeric or voice messages. Pagers became widely used by the 1980s. In the 21st century, the widespread availability of cellphones and smartphones has greatly diminished the pager industry. Nevertheless, pagers continue to be used by some emergency services and public safety personnel, because pager systems reliability in some cases, including during natural and man-made disasters. This resilience has led public safety agencies to still adopt pagers over cellular and other commercial services for critical messaging.</p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/36d41b79f69415348d802e12e78e7ccc8d4922b4a522414a135a3823baa01405.png"></p><p>Although there are several protocols for Pagers the most common is POCSAG. This protocol dates from the 80s and although there are more modern alternatives, it has become the de facto standard in the industry. <a href="https://techcrunch.com/2019/10/30/nhs-pagers-medical-health-data/?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAACZR9IHPYbq7SUYuzrM7Fs-IXdOi6U2iEmmte1ckW9sdBkKjXuwog8HTVBNTPTJd0gxyb-Xr68nClGiopHSYFVhgBXZbrgWOd0L88OyPaGncTCA77v55GXcwGY99gQHiwhq3H2t4vLRPViqJVlY9aoKlTfO89v6SBfTo8hNXaf9W" target="_blank" rel="nofollow noopener">Pagers have been under the scrutiny of information security experts for some time now as it is common for hospital pagers to spew out unencrypted patient data into the air for anyone with a radio and computer to decode</a>. Another use of POCSAG is remote control of industrial systems using text messages.</p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/2219729e356476cb65155b609cf5983e42489407459def3e8ec8906b6b50eab7.jpeg"></p><p>Using the portapack it is really easy to spoof POCSAG messages. We only need to know the Freq, RIC address and the speed expected by the destination pager. All of this information could be easly be sniffed using the POCSAG sniffer or with  HackRF running software like <a href="https://github.com/EliasOenal/multimon-ng" target="_blank" rel="nofollow noopener">Multimon-ng</a>. It's easy to think of the harm this capability could do in the wrong hands.</p><p><strong>ADS-B</strong></p><p>Automatic dependent surveillance–broadcast (ADS–B) is a surveillance technology in which an aircraft determines its position via satellite navigation and periodically broadcasts it, enabling it to be tracked. The information can be received by air traffic control ground stations as a replacement for older surveillance radar data, as no interrogation signal is needed from the ground.</p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/9ae5de693eb186657e03fb2aec34ec632092ec0fab4857edaee3a6bb9d48503e.jpeg"></p><p>ADS-B lack of any encryption or authentication within the standard. <a href="https://www.flightradar24.com/" target="_blank" rel="nofollow noopener">Flightradar24</a> a Swedish internet-based service that shows real-time aircraft flight tracking information on a map mostly from crowdsourced information gathering by volunteers with ADS-B receivers and satellite-based ADS-B …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://telescope.ac/petazzoni/mayhem-the-rf-pentesting-hackrf-portapack-firmware">https://telescope.ac/petazzoni/mayhem-the-rf-pentesting-hackrf-portapack-firmware</a></em></p>]]>
            </description>
            <link>https://telescope.ac/petazzoni/mayhem-the-rf-pentesting-hackrf-portapack-firmware</link>
            <guid isPermaLink="false">hacker-news-small-sites-25187801</guid>
            <pubDate>Mon, 23 Nov 2020 15:35:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decentralizing Agriculture Production in the United States]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25187624">thread link</a>) | @kickout
<br/>
November 23, 2020 | https://thinkingagriculture.io/decentralizing-agriculture-production/ | <a href="https://web.archive.org/web/*/https://thinkingagriculture.io/decentralizing-agriculture-production/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p><em>Why do we only grow certain crops in certain areas?</em></p>



<p>One observation of agriculture production is the difference in species adaptation of various places around the world: bananas grown Central America, nuts and vegetables in California, citrus fruits in Florida, apples in Washington or New York, peanuts from the Southeast, etc. The is mostly a product of economic realities and efficiency: It is easier and cheaper to manage production (of whatever) when things are located physically near each other. This isn’t unique to agriculture, as many supply chains coalesce around centralized regions (electronic device productions, automobiles, etc.). Agriculture and food production supply chain occupy a different place on humanities priority list however, and despite applying a similar ethos to essential and luxury items, there have been few catastrophic consequences from these decisions. Agriculture and the food supply chain has mostly <em>found a way</em> over the past ~100 years. It may be time to rethink or start planning for a different strategy. One possible strategy to overcome disease and pest issues that currently reduce or harm our food production systems is to <em>decentralize</em> the areas we produce many of these crops. This would potentially alleviate several problems: 1) if a pest or pathogen infests one area, the entire crop is not lost 2) transportation costs can be reduced to the consumer resulting in 3) faster delivery from harvest to consumer (thereby increasing quality and taste).</p>



<p>To be clear, decentralization is catching on in various industries (e.g. finance technology platforms), but the concept has always been baked into agriculture without much fanfare. Residents of the United States that have travelled to Hawaii may remember <a rel="noreferrer noopener" href="https://www.aphis.usda.gov/aphis/home/" data-type="URL" data-id="https://www.aphis.usda.gov/aphis/home/" target="_blank">USDA APHIS</a> having an interest in certain plant species you may may brought along (or are trying to remove). All of that paperwork and questionnaire’s are to mitigate unintended introductions of invasive species or pathogens. One of the most economically devastating pests to harm soybean production (in the United States) is the <a rel="noreferrer noopener" href="https://www.apsnet.org/edcenter/disandpath/nematode/pdlessons/Pages/SoyCystNema.aspx" data-type="URL" data-id="https://www.apsnet.org/edcenter/disandpath/nematode/pdlessons/Pages/SoyCystNema.aspx" target="_blank">soybean cyst nematode</a>. This pathogen was not native to the United States and was <em>introduced</em> ~75 years ago. Any mitigations to prevent its spread were ineffective due to its pathogenicity and the sheer scale of soybean production in the United States. Major rows crops such as maize, soybean, wheat, and cotton reside in a different tier regarding scale of production compared to ‘specialty’ crops (namely fruits, vegetables, nuts, spices, etc.) and are not candidates for decentralizing strategies.</p>



<p>There are several high level strategies for optimizing production and profitability of the food we eat. For example, over the past ~125 years we have been optimizing maize production for the Midwest region of the United States via technological (tractors, chemical) and scientific (adapted hybrids) means. We have been successful doing this because maize was already able to be grown in Midwest thanks to the thousands of years of gradual adaptation to the United States from a plant native to Mexico (that plant being: <a rel="noreferrer noopener" href="https://blog.nationalgeographic.org/2009/03/23/corn-domesticated-from-mexican-wild-grass-8700-years-ago/" data-type="URL" data-id="https://blog.nationalgeographic.org/2009/03/23/corn-domesticated-from-mexican-wild-grass-8700-years-ago/" target="_blank">teosinte</a>). For as ubiquitous as maize is to the Midwest region of the United States, mother nature did not produce that outcome, man did. It took a long time, but humans successfully shifted the areas of adaptation of maize and indeed many other crops to what we currently see today. Tomatoes are another good example of humans bending plants to our will: Italy <a rel="noreferrer noopener" href="https://www.fas.usda.gov/data/italy-italian-processed-tomato-overview-2018#:~:text=Italy%20is%20a%20world%20leading,more%20than%20%E2%82%AC3.1%20billion.&amp;text=Italy%20is%20both%20a%20leading%20exporter%20and%20importer%20of%20tomato%20products." data-type="URL" data-id="https://www.fas.usda.gov/data/italy-italian-processed-tomato-overview-2018#:~:text=Italy%20is%20a%20world%20leading,more%20than%20%E2%82%AC3.1%20billion.&amp;text=Italy%20is%20both%20a%20leading%20exporter%20and%20importer%20of%20tomato%20products." target="_blank">produces around 50% of European and ~15% processed tomatoes</a> despite tomatoes not being introduced until the <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Age_of_Discovery" data-type="URL" data-id="https://en.wikipedia.org/wiki/Age_of_Discovery" target="_blank">Age of Discovery</a>. Bending or manipulating useful plants to grow in non-native areas is as old as farming (~10,000 BCE). Better yet, all of this adaptation was accomplished using <em>existing, </em>or native, genetic variation within their own species.</p>



<p>The theme of these examples is: ‘<em>It is possible</em>‘. With modern genomic information, we now have the tooling to do this for innumerable species. We need to start doing the same for more high value crops–namely species that are grown in geographically concentrated areas (<a rel="noreferrer noopener" href="https://www.nass.usda.gov/Charts_and_Maps/graphics/orgmap.png" data-type="URL" data-id="https://www.nass.usda.gov/Charts_and_Maps/graphics/orgmap.png" target="_blank">citrus</a>, <a rel="noreferrer noopener" href="https://ipad.fas.usda.gov/rssiws/al/crop_production_maps/us/USA_Peanut_Total_Lev2_Prod.png" data-type="URL" data-id="https://ipad.fas.usda.gov/rssiws/al/crop_production_maps/us/USA_Peanut_Total_Lev2_Prod.png" target="_blank">nuts</a>, vegetables, etc.). Modern tools (genome editing, genomic sequence data, phylogeny trees, <a rel="noreferrer noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3189332/" data-type="URL" data-id="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3189332/" target="_blank">mutagenesis</a>) could allow us to make these species adapted to more diverse growing regions via photoperiod sensitivity changes, cold tolerance, heat tolerance, altitude sensitivity, flowering time and length, growth habitat, and many more traits that define ‘adaptation’ to a given geographical unit. Many scientific studies focus on utilizing natural diversity to make production greater in <em>existing</em> areas of adaptation. This makes sense (despite being short-sighted on rare occasions): growing crops is a for-profit industry so it makes sense to harness the species that are already well-adapted to the region maximize those efficiencies. But again, food production cannot be exclusively dominated by this myopic view; after all many government would deem food supply and production as a national security topic. Clearly, the United States government acts as if they believe this to some degree as well, with heavily subsidies buoying maize, soybean, cotton, and wheat production (along with several other meat and dairy industries).</p>



<p>There are other reasons to look into decentralizing production of key species though. If we had citrus that was adapted to Kansas, Colorado, Utah, Michigan, these growing regions could avoid the <a rel="noreferrer noopener" href="https://www.aphis.usda.gov/aphis/resources/pests-diseases/hungry-pests/the-threat/citrus-greening/citrus-greening-hp" data-type="URL" data-id="https://www.aphis.usda.gov/aphis/resources/pests-diseases/hungry-pests/the-threat/citrus-greening/citrus-greening-hp" target="_blank">citrus greening problems</a> of the Southeast United States by sheer physical isolation. To be clear this problem does not have an all or none solution. We need strategies to circumvent disease and pathogens <em>in</em> their current areas of production and even if production of most fruits, vegetables <em>could</em> be done in dozens of decentralized regions it adds overhead to research and development programs as they might have to tackle 5 small problems versus 1 big problem. These are known problems in centralized structures versus decentralized structures. Since food production has unique value to humans, it worth exploring whether the costs outweigh the benefits. Fruit species in particular are extremely perishable, so while the consumers values taste and quality, the producer and supplier values transportability and storage. If we remove the logistics of long distance transport via increasing production centers, scientists could focus on improving taste and quality.</p>



<p>An obvious argument against pursuing a decentralized strategy in specialty crops is the potential rise of indoor/vertical (and de-facto isolated) farms. This is an interesting proposition but I maintain the scale of production for many species of interest is simply too large to be handled in a cost effective manner in a indoor operation. Remember, outdoor grown crops have free energy in the sun and free nutrients from the soil. Indoor agriculture has to supply these somehow (and they are not free). That’s not to dismiss indoor agriculture as a supplementary component as it already is for several crops, <a rel="noreferrer noopener" href="https://www.ers.usda.gov/data-products/chart-gallery/gallery/chart-detail/?chartId=92604" data-type="URL" data-id="https://www.ers.usda.gov/data-products/chart-gallery/gallery/chart-detail/?chartId=92604" target="_blank">as about ~25% of tomatoes non-outdoor origins</a>. I continue to maintain indoor agriculture production systems can only even be sustainable for extremely high-value, low utilization specialty crops that cannot harness outdoor production systems (think spices, niche vegetables). It should be an active goal to get fruit, vegetables, and nut production decentralized in an outdoor setting that can harness soil and sunlight that are already prevalent.</p>



<p>High level movements like this are needed in agriculture to secure the food supply and add some shock absorbers to any potential pest or pathogen disruption. There is to much technology at our fingertips to not get something going. It simply appears the marker is ignoring this segment while most of the focus remains on <em>current</em> production regions.</p>



<p><em>Author can be reached at admin [at] thinkingagriculture.io</em></p>
		</div></div>]]>
            </description>
            <link>https://thinkingagriculture.io/decentralizing-agriculture-production/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25187624</guid>
            <pubDate>Mon, 23 Nov 2020 15:21:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Django refactoring game – can you fix all the Models anti-patterns?]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 53 (<a href="https://news.ycombinator.com/item?id=25187507">thread link</a>) | @rikatee
<br/>
November 23, 2020 | https://django.doctor/challenge | <a href="https://web.archive.org/web/*/https://django.doctor/challenge">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://django.doctor/challenge</link>
            <guid isPermaLink="false">hacker-news-small-sites-25187507</guid>
            <pubDate>Mon, 23 Nov 2020 15:11:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advent of Code in Haskell Preparation Part 2: Where We Build a Computer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25187350">thread link</a>) | @todsacerdoti
<br/>
November 23, 2020 | https://www.bulters.dev/posts/where-we-build-a-computer/ | <a href="https://web.archive.org/web/*/https://www.bulters.dev/posts/where-we-build-a-computer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
			
<p>So day one went fairly smooth. Nothing too difficult to implement, as you can
expect from a first challenge. Since I’ve done some of the challenges last year
(implemented them in Go), I know that there will be a rapid ramp-up in
difficulty and that a number of challenges build “on top of each other”.
Perfect opportunities to start exploring how to write reuseable Haskell code.</p>
<p>But we’ll tackle that when the opportunity actually presents itself and not
make things more difficult than needed.</p>

<p>I will not describe the entire problem again, Advent of Code is way better at
that. But to make things simple: read numbers from a file, start at the first
number, execute an action based on the number and write the result of the
action somewhere.</p>
<p>In the first “note” (I wouldn’t call these ramblings articles) I started out
with some boilerplate by setting up the required files for Cabal, but lets not
do that this time, since I realised we don’t really need it (just yet).</p>
<p>I’ll just create a directory, create a Main.hs file and run stuff from GHCi to
get things working. In the end I’ll try to modify the program to take the input
program (intcode program) from the standard input, just as a challenge.</p>

<p>Lets get our environment setup.</p>
<div><pre><code data-lang="shell">jeroen@DESKTOP:~/taoc19$ cd day2
jeroen@DESKTOP:~/taoc19/day2$ touch Main.hs
jeroen@DESKTOP:~/taoc19/day2$ ghci
GHCi, version 8.6.5: http://www.haskell.org/ghc/  :? <span>for</span> help
Prelude&gt; :load Main.hs
<span>[</span><span>1</span> of 1<span>]</span> Compiling Main             <span>(</span> Main.hs, interpreted <span>)</span>
Ok, one module loaded.
*Main&gt;
</code></pre></div><p>Great, that worked. The <code>Main.hs</code> file is still empty, but it works, no Cabal
or Stack needed to get something done. Now to open the editor from GHCi (with
<code>:edit</code> or <code>:e</code>) and start implementing this intcode machine.</p>
<div><pre><code data-lang="shell">*Main&gt; :e
editor not set, use :set editor
*Main&gt; :set editor vim
*Main&gt;
</code></pre></div><p>Oops, let make a mental note to actually set <code>$EDITOR</code> in my environment, guess
I don’t use it as often as thought.</p>
<p>So filling the Main.hs file with the same boilerplate as last time:</p>
<div><pre><code data-lang="haskell"><span>module</span> Main <span>where</span>

<span>main</span> <span>::</span> <span>IO</span> ()
<span>main</span> <span>=</span> <span>do</span>
        raw <span>&lt;-</span> readFile <span>"input.txt"</span>
				        print raw
</code></pre></div><p>Running the <code>main</code> function in GHCi does exactly as expected, it outputs the contents of the <code>input.txt</code> file. No big deal.</p>
<p>So after stubbing out the general outline of the program this is what I came up with:</p>
<div><pre><code data-lang="haskell"><span>module</span> Main <span>where</span>

<span>main</span> <span>::</span> <span>IO</span> ()
<span>main</span> <span>=</span> <span>do</span>
        raw <span>&lt;-</span> readFile <span>"input.txt"</span>
        <span>-- split the input up into instructions (split on ,)</span>
        <span>let</span> input <span>=</span> parseInput raw
        <span>-- run the program</span>
        <span>let</span> output <span>=</span> runProgram input
        <span>-- get the value from first position in memory</span>
        <span>let</span> solution <span>=</span> output <span>!!</span> <span>0</span>
        print solution

<span>-- parseInput takes a string as input and outputs</span>
<span>-- an array of integers</span>
<span>parseInput</span> <span>=</span> id

<span>-- runProgram takes a piece of memory and returns</span>
<span>-- the state of memory after the program has completed</span>
<span>runProgram</span> <span>=</span> id
</code></pre></div><p>So we have two high level functions to define, sounds doable.</p>
<p>First challenge is to find a way to split the input string on the comma’s
separating the individual memory values. I heard “real Haskell programmers” use
<a href="https://hoogle.haskell.org/">Hoogle</a> to find the functions they are looking for
based on the type signature they think “should get the job done”.</p>
<p>Since we’re looking to split a string based on a different string, the required
type signature should look something like <code>String -&gt; String -&gt; [String]</code>. But
after <a href="https://hoogle.haskell.org/?hoogle=String+-%3E+String+-%3E+%5BString%5D&amp;scope=set%3Ahaskell-platform">searching Hoogle for
it</a> I couldn’t find anything that looks like it might do the job. Of course I could
have just searched for a function called split, or some variation of it, but I wanted
to do it “the real way"TM. Luckily, after reading an article on <a href="https://mmhaskell.com/blog/2017/5/15/untangling-haskells-strings">Monday Morning Haskell</a>
I remembered that Haskell also has a <code>Text</code> type, offering some additional string handling
abilities.</p>

<div>
	<p>
    💡 I remain blisfully unaware of other benefits of using the `Text` type, please enlighten me if you want to.
  </p>
</div>
<p>Re-running the search with <a href="https://hoogle.haskell.org/?hoogle=Text+-%3E+Text+-%3E+%5BText%5D&amp;scope=set%3Ahaskell-platform"><code>Text -&gt; Text -&gt; [Text]</code></a> yielded exactly the result I was looking for: <code>splitOn</code>. So feeding the <code>raw</code> data into <code>splitOn</code> and splitting on <code>,</code> gives us a <code>[String]</code> which we only need to convert into a <code>[Int]</code>. The <code>splitOn</code> function is included in the <code>Data.Text</code> package, so we’ll have to import that as well. But then, the <code>readFile</code> we use to load the data gives us a <code>String</code>, so we’ll have to import <code>Data.Text.IO</code> as well to be able to utilize the <code>readFile</code> function from that (all found by using Hoogle).</p>
<p>At this point, let’s reconsider our solution of using the <code>splitOn</code> function as provided by <code>Data.Text</code> and research Hoogle for a different <code>splitOn</code> function. Turns out, there is a <code>splitOn</code> variant in <a href="https://hackage.haskell.org/package/split-0.2.3.4/docs/Data-List-Split.html#v:splitOn"><code>Data.List.Split</code></a> that is generic (i.e. it accepts anything of the type <code>Eq a =&gt; [a] -&gt; [a] -&gt; [[a]]</code>) so will probably accept a <code>String</code> as well. Let’s try it out in GHCi.</p>
<div><pre><code data-lang="shell">GHCi, version 8.6.5: http://www.haskell.org/ghc/  :? <span>for</span> help
Prelude&gt; :m + Data.List.Split
Prelude Data.List.Split&gt; splitOn <span>","</span> <span>"1,2,3,4,5"</span>
<span>[</span><span>"1"</span>,<span>"2"</span>,<span>"3"</span>,<span>"4"</span>,<span>"5"</span><span>]</span>
Prelude Data.List.Split&gt; :t splitOn <span>","</span> <span>"1,2,3,4,5"</span>
splitOn <span>","</span> <span>"1,2,3,4,5"</span> :: <span>[[</span>Char<span>]]</span>
</code></pre></div><p>Awesome, we get something back that looks like a <code>[String]</code> (since a <code>String</code> is a <code>[Char]</code>). So we’ll be good to go to use this.</p>
<p>So let’s write a simple function to do this, iterate (<code>map</code>) over all the individual items and <code>read</code> them into a <code>[Int]</code>.</p>
<div><pre><code data-lang="haskell"><span>-- parseInput takes a string as input and outputs</span>
<span>-- an array of integers</span>
<span>-- parseInput :: String -&gt; [Int]</span>
<span>parseInput</span> <span>::</span> <span>String</span> <span>-&gt;</span> [<span>Int</span>]
<span>parseInput</span> x <span>=</span> map read <span>$</span> splitOn <span>","</span> x
</code></pre></div><p>That takes care of getting our input ready. The second step involves a small nuance in the challenge:</p>
<pre><code>    Once you have a working computer, the first step is to restore the gravity
    assist program (your puzzle input) to the "1202 program alarm" state it had
    just before the last computer caught fire. To do this, before running the
    program, replace position 1 with the value 12 and replace position 2 with the
    value 2. What value is left at position 0 after the program halts?
</code></pre>
<p>So we have to set the first value of the program to 12, and the second value to 2. This calls for a function
to replace a certain index in a <code>List</code>. At this point we could choose to replace the usage of <code>List</code> with <code>Data.Vector</code> which
offers this functionality by default. But for simplicity sake, let’s stay with our current solution and create a <code>replace</code> function
that takes an <code>Int</code> (the index), another <code>Int</code> (the new value) and a <code>List</code>, and returns a <code>List</code>. To build this function we use the <code>splitAt</code> function
provided by <code>Data.List.Split</code>, which we imported in the previous step anyway.</p>
<div><pre><code data-lang="haskell"><span>replace</span> <span>::</span> <span>Int</span> <span>-&gt;</span> <span>Int</span> <span>-&gt;</span> [<span>Int</span>] <span>-&gt;</span> [<span>Int</span>]
<span>replace</span> i v xs <span>=</span> <span>let</span> (hxs, <span>_</span><span>:</span>txs) <span>=</span> splitAt i xs <span>in</span>
								   hxs <span>++</span> v <span>:</span> txs
</code></pre></div><p>which, when tested in GHCi, yields exactly what we want:</p>
<div><pre><code data-lang="shell"><span>[</span><span>1</span> of 1<span>]</span> Compiling Main             <span>(</span> Main.hs, interpreted <span>)</span>
Ok, one module loaded.
*Main&gt; replace <span>2</span> <span>99</span> <span>[</span>1,2,3,4,5<span>]</span>
<span>[</span>1,2,99,4,5<span>]</span>
</code></pre></div><p>So we can construct our actual program with <code>replace 1 12 $ replace 2 2 input</code>, store it in a variable and use that to run the actual program.</p>

<div>
	<p>
    💡 Turns out, `Data.List.Index` has a function called `setAt` which does EXACTLY the same as our `replace` function. Unfortunately, this is only available as an external library, so I choose not to use it.
  </p>
</div>

<p>We have a list of numbers, which somehow translates to instructions to be executed by a virtual computer, mutating memory. Sounds easy right?</p>
<p>IMO, this is actually the easy part, it involves us creating a function that takes 4 numbers from the list, applying a certain mutation to memory based on the values in those four numbers, taking the next four numbers, etc. Untill we find the number 99.</p>
<div><pre><code data-lang="haskell"><span>runProgramAt</span> <span>::</span> <span>Int</span> <span>-&gt;</span> [<span>Int</span>] <span>-&gt;</span> [<span>Int</span>]
<span>runProgramAt</span> pc m <span>=</span> <span>let</span> opcode <span>=</span> m <span>!!</span> pc
												left <span>=</span> m <span>!!</span> (m <span>!!</span> (pc <span>+</span> <span>1</span>))
												right <span>=</span> m <span>!!</span> (m <span>!!</span> (pc <span>+</span> <span>2</span>))
												result <span>=</span> m <span>!!</span> (pc <span>+</span> <span>3</span>)
												next <span>=</span> pc <span>+</span> <span>4</span> <span>in</span>
										<span>case</span> opcode <span>of</span>
												<span>-- 99 signals the end of the program, just return</span>
												<span>-- the entire memory</span>
												<span>99</span> <span>-&gt;</span> m
												<span>-- 1 indicates addition (left + right -&gt; result), continue</span>
												<span>-- with the next operation at pc + 4</span>
												<span>1</span> <span>-&gt;</span> runProgramAt next <span>$</span> replace result (left <span>+</span> right) m
												<span>-- 2 indicates multiplication (left * right -&gt; result), continue</span>
												<span>-- with the next operation at pc + 4</span>
												<span>2</span> <span>-&gt;</span> runProgramAt next <span>$</span> replace result (left <span>*</span> right) m
												<span>-- and to satisfy the compiler, give it a fallback case</span>
												<span>-- which just returns the entire memory and stops</span>
												otherwise <span>-&gt;</span> m
</code></pre></div><p>Now when I change my <code>runProgram</code> function to use this function to run the program starting at position 0 by changing it into
<code>runProgram = runProgramAt 0</code>, and running this from GHCi I get my correct answer:</p>

<p>Really typical, part 2 of the challenge involves us finding a set of input that yields a certain output. This reeks like a standard brute-force search. These can be done really efficiently in Haskell by using <a href="https://dev.to/awwsmm/relearn-you-a-haskell-part-2-list-comprehensions-tuples-and-types-g29">list comprehensions</a>. So probably we’ll end up with something like:</p>
<div><pre><code data-lang="haskell"><span>findSolution</span> <span>::</span> <span>Int</span> <span>-&gt;</span> [<span>Int</span>] <span>-&gt;</span> <span>Int</span>
<span>findSolution</span> s m <span>=</span> head [noun <span>*</span> <span>100</span> <span>+</span> verb <span>|</span> 
                    noun <span>&lt;-</span> [<span>0</span><span>..</span><span>99</span>], 
                    verb <span>&lt;-</span> [<span>0</span><span>..</span><span>99</span>], 
                    runProgram (replace <span>1</span> noun <span>$</span> replace <span>2</span> verb m) <span>!!</span> <span>0</span> <span>==</span> s]

</code></pre></div><p>When calling this function with the input supplied by the challenge:</p>
<div><pre><code data-lang="haskell"><span>-- get the required input to complete part 2</span>
<span>let</span> nounverb <span>=</span> findSolution <span>19690720</span> input
<span>print</span> nounverb
</code></pre></div><p>it yields the correct solution, right away:</p>
<div><pre><code data-lang="shell"><span>[</span><span>1</span> of 1<span>]</span> Compiling Main             <span>(</span> Main.hs, interpreted <span>)</span>
Ok, one module loaded.
*Main&gt; main
<span>3101844</span>
<span>8478</span>
</code></pre></div><p>where the second answer is the answer for part 2. Given that I ran this in GHCi I expected it to be a bit slower, so let’s see if that’s the case:</p>
<pre><code>*Main&gt; :set +s
*Main&gt; main
3101844
8478
(1.04 secs, 3,337,885,928 bytes)
*Main&gt;
</code></pre><p>That seems about right, let’s try compiling and timing this as a standalone binary:</p>
<div><pre><code data-lang="shell">jeroen@DESKTOP:~/taoc19/day2$ ghc Main.hs
<span>[</span><span>1</span> of 1<span>]</span> Compiling Main             <span>(</span> Main.hs, Main.o <span>)</span>
Linking Main ...
jeroen@DESKTOP:~/taoc19/day2$ time ./Main
<span>3101844</span>
<span>8478</span>

real    0m0.567s
user    …</code></pre></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.bulters.dev/posts/where-we-build-a-computer/">https://www.bulters.dev/posts/where-we-build-a-computer/</a></em></p>]]>
            </description>
            <link>https://www.bulters.dev/posts/where-we-build-a-computer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25187350</guid>
            <pubDate>Mon, 23 Nov 2020 14:59:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Productivity Advice]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25186897">thread link</a>) | @shubhamjain
<br/>
November 23, 2020 | https://www.spakhm.com/p/productivity-advice | <a href="https://web.archive.org/web/*/https://www.spakhm.com/p/productivity-advice">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Do the work.</p><p>That's all the productivity advice you need, and the only <em>useful</em> productivity advice you're ever going to get. You can direct your attention to a million optimizations— email, meetings, notes, calendar, time tracking, goals, todo lists, time estimates, prioritization frameworks, quantified self sensors, analytics, apps, documents, journaling. But don't. Ignore all this, and do the work. When you do the work, everything else optimizes itself.</p><p>If the only thing you must do is the work, why is there so much productivity advice? Blog posts, courses, seminars, software? Because when there is demand, there is supply. Work is hard. People will latch onto anything to avoid doing it. The market is happy to oblige.</p><p>Work means sitting down, getting through that calculus chapter, and doing the exercises. No amount of productivity hacking will make that easier. You don't need pomodoro alarms, bullet journals, time tracking apps, animated explainer videos, or different color highlighters. Everyone doesn't learn differently. Everyone learns calculus in the same way— by doing the work. You need Rudin's book, a pen, paper, and time. More tools give you negative utility. They won't make the work go faster. But they will consume as much time as you are willing to waste.</p><p>Building a new startup? Same thing. Talk to users all day. Then sit down and write the code. Get others to join you. Repeat. People do new founders a disservice by constantly proselytizing how complex startups are. In one sense they are. But in another sense they're surprisingly simple. For a long time you're doing the same three things over and over. Sell. Code. Recruit. Then do it all over again tomorrow. Startups don't get built by watching startup advice videos on YouTube. They get built by doing the work. All you need is a laptop and a metrocard.</p><p>I read a lot of biographies. People who have biographies written about them have two things in common. First, they are obsessed. Second, they never stray from doing the work. John Carmack was obsessed with game engines. Orville and Wilbur Wright were obsessed with manned flight. Leonardo da Vinci was obsessed with the structure of things. So they would code, construct, and paint. That's not to say they did no meta thinking. Carmack published plan files, the Wright brothers maintained extensive correspondence detailing their experiments, and Leonardo da Vinci is known for his magnificent notebooks. But you'd be hard pressed to find them writing letters about writing letters. They were busy doing the work.</p><p>An important ingredient for doing the work is boredom. That's how I got into programming. School was boring. We had three channels of television, and they were almost always boring. I had computer games, but I sucked at gaming and games quickly got frustrating. I read all the books that we had laying around. The only thing left was BASIC. So I started there and never stopped. The simple reason is that programming computers was the most interesting activity around.</p><p>If boredom is a necessary ingredient, then portable internet is a disaster for doing the work. How are you supposed to get excited about anything if you're never bored? I don't know if I ever would have learned to program if I had modern internet. Why would I, if something more interesting was always a click away? This is true to this day. I can't get anything done when I'm online. There is always something on the internet that's locally more interesting or more important than writing the next paragraph, or threading a flag through a series of function calls, or reading a book. The only way I can get anything done is to turn the internet off.</p><p>So I do. I have a work computer, and a router with parental controls that blocks every possible internet distraction on it. No Twitter, no Hacker News, no YouTube. Router administration is set up so I can't make changes over WiFi. If I want to unblock something, I have to physically get to the router and plug in a cable to change the settings. I power off every other device. No silent mode, no do not disturb, no hibernation. Power off. Recently a reader suggested putting my phone in a <a href="https://amzn.to/3fmBx4n">kSafe</a> (thanks Robert!) It works great, and now I’m doing that too. All this constructs enough physical barriers between me and temptation that the internet loses and my laziness wins.</p><p>Then I get properly bored. And then I do the work.</p></div></div>]]>
            </description>
            <link>https://www.spakhm.com/p/productivity-advice</link>
            <guid isPermaLink="false">hacker-news-small-sites-25186897</guid>
            <pubDate>Mon, 23 Nov 2020 14:11:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things that will go wrong in a distributed system]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25186443">thread link</a>) | @evuez
<br/>
November 23, 2020 | https://liftm.io/posts/things-that-will-go-wrong-in-a-distributed-system.html | <a href="https://web.archive.org/web/*/https://liftm.io/posts/things-that-will-go-wrong-in-a-distributed-system.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
        <time datetime="2020-11-22">2020-11-22</time>
      <p>A (very) incomplete list of things that will go wrong in any distributed system.</p>
<p>Feel free to <a href="https://github.com/evuez/evuez.github.io/blob/master/posts/things-that-will-go-wrong-in-a-distributed-system.md">submit a PR</a> to add more failure cases to this list.</p>

<ul>
<li>The network will be partitioned</li>
<li>Latency will grow more than expected</li>
<li>Timeouts will happen on nodes that are alive</li>
<li>Your network bandwidth is limited, and you will hit that limit</li>
</ul>

<ul>
<li>Clocks will go backward</li>
<li>Monotonic clocks will go backward <a href="https://rachelbythebay.com/w/2020/10/20/ticktock/">[1]</a>, <a href="https://github.com/rust-lang/rust/pull/56988">[2]</a></li>
<li>Clocks will be out of sync, by more than a few seconds sometimes</li>
<li>Your NTP server will die</li>
<li>You will have timezone issues</li>
</ul>

<ul>
<li><a href="http://static.googleusercontent.com/media/research.google.com/en//archive/disk_failures.pdf">HDDs will fail</a></li>
<li><a href="https://arxiv.org/pdf/1901.03401.pdf">RAMs will fail</a></li>
<li><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/eurosys84-nightingale.pdf">CPUs will fail</a></li>
</ul>

<ul>
<li>Without <a href="https://wiki.postgresql.org/wiki/SSI">SSI</a>, you will have inconsistencies</li>
<li>Without <a href="https://wiki.postgresql.org/wiki/SSI">SSI</a>, you will lose data</li>
<li>Without a proper consensus, you will have more than one leader</li>
<li>Without <a href="https://en.wikipedia.org/wiki/Linearizability">linearizability</a>, clients will time travel</li>
<li>Without <a href="https://en.wikipedia.org/wiki/Two-phase_commit_protocol">2PC</a>, you will have inconsistencies</li>
</ul>

    </article></div>]]>
            </description>
            <link>https://liftm.io/posts/things-that-will-go-wrong-in-a-distributed-system.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25186443</guid>
            <pubDate>Mon, 23 Nov 2020 13:20:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Tech Stack of a One-Man SaaS]]>
            </title>
            <description>
<![CDATA[
Score 466 | Comments 245 (<a href="https://news.ycombinator.com/item?id=25186342">thread link</a>) | @amzans
<br/>
November 23, 2020 | https://panelbear.com/blog/tech-stack/ | <a href="https://web.archive.org/web/*/https://panelbear.com/blog/tech-stack/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Being an engineer at heart, each time I see a company write about their tech stack, I brew a fresh cup of coffee, sit back and enjoy reading the newfound little treat.</p><p>There’s just something fascinating about getting to know what’s under the hood of other people’s businesses. It’s like gossip, but about software.</p><p>A couple of months ago I started working on <a href="https://panelbear.com/blog/why-panelbear/" target="_blank" rel="noopener">yet another private analytics service</a>, a project which has gone through numerous iterations, and I feel lucky that 400+ websites have already integrated with it, even though it's still in the early stages.</p><p>That’s why, in the same spirit as Jake Lazaroff’s <a href="https://jake.nyc/words/tools-and-services-i-use-to-run-my-saas/" target="_blank" rel="noopener">Tools and Services I Use to Run My SaaS</a>, I thought it’s now my turn to do a short write up of the technologies I’m using to run this new service.</p><h2>Languages</h2><p>Over the years I have added many programming languages to my toolbelt, but for solo projects I have converged to two in particular that strike a good balance of productivity and reliability.</p><ul><li><p><a href="https://python.org/" target="_blank" rel="noopener">Python</a>: Most of the backend code is in Python. Which has enabled me to ship features incredibly fast. Additionally, I use <a href="http://mypy-lang.org/" target="_blank" rel="noopener">mypy</a> for optional type hints, which helps keep the codebase manageable.</p></li><li><p><a href="https://www.typescriptlang.org/" target="_blank" rel="noopener">Typescript</a>: I used to avoid working on the frontend as much as I could. That is until I discovered Typescript about 4 years ago. It just makes the whole experience a lot better, and I now use it for all my projects together with React.</p></li></ul><h2>Frameworks and libraries</h2><p>This list could have been huge, as I stand on the shoulders of giants who have published the vast amount of open-source code which I rely on. But I'd like to highlight only a handful due to their major role in the stack:</p><ul><li><a href="https://www.djangoproject.com/" target="_blank" rel="noopener">Django</a>: It's like a superpower for solo developers. The longer you work in this industry, the more you appreciate not having to reinvent the wheel for the 100th time. A monolithic framework can get you <a href="https://instagram-engineering.com/web-service-efficiency-at-instagram-with-python-4976d078e366" target="_blank" rel="noopener">really</a>, <a href="https://github.com/getsentry/sentry" target="_blank" rel="noopener">really</a> <a href="https://djangostars.com/blog/10-popular-sites-made-on-django/" target="_blank" rel="noopener">far</a>. To me, it's about predictable software that's fast in every way that matters. In case you're interested, I talk more about this topic on <a href="https://panelbear.com/blog/boring-tech/" target="_blank" rel="noopener">Choose Boring Technology</a>.</li><li><a href="https://reactjs.org/" target="_blank" rel="noopener">React</a>: The web app for the dashboards is built using React + Webpack. After using Angular for a long time, I switched to React because it's just a pluggable view layer that doesn't get in the way. I use the fantastic <a href="https://github.com/Frojd/django-react-templatetags" target="_blank" rel="noopener">django-react-templatetags</a> to embed the React components in my Django templates.</li><li><a href="https://nextjs.org/" target="_blank" rel="noopener">NextJS</a>: I use it for the landing pages, documentation and the blog which you are currently reading. It enables me to re-use various React components, and still reap the performance and SEO benefits of a statically generated site.</li><li><a href="https://docs.celeryproject.org/" target="_blank" rel="noopener">Celery</a>: I use it for any kind of background/scheduled tasks. It does have a learning curve for more advanced use-cases, but it's quite reliable once you understand how it works, and more importantly when it fails.</li><li><a href="https://getbootstrap.com/" target="_blank" rel="noopener">Bootstrap 4</a>: I built a custom theme on top of Bootstrap. It has saved me a lot of time, and there's lots of documentation around it. That's why I picked it.</li></ul><h2>Databases</h2><p>I originally stored all data in a single SQLite database, doing backups meant making a copy of this file to an object storage like S3. At the time, it was more than enough for the small sites I tested Panelbear with. But as I added more features and websites, I needed more specialized software to support those features:</p><ul><li><a href="https://clickhouse.tech/" target="_blank" rel="noopener">Clickhouse</a>: I believe this is one of those technologies that over time will become ubiquitous. It's honestly a fantastic piece of software that enabled me to build features that initially seemed impossible on low-cost hardware. I do intend to write a future blog post on some lessons learned from running Clickhouse on Kubernetes. So stay tuned!</li><li><a href="https://www.postgresql.org/" target="_blank" rel="noopener">PostgreSQL</a>: My go-to relational database. Sane defaults, battle-tested, and deeply integrated with Django. For Panelbear, I use it for all application data that is not analytics related. For the analytics data, I instead wrote a simple interface for querying Clickhouse within Django.</li><li><a href="https://redis.io/" target="_blank" rel="noopener">Redis</a>: I use it for many things: caching, rate-limiting, as a task queue, and as a key/value store with TTL for various features. Rock-solid, and great documentation.</li></ul><h2>Deployment</h2><p>I treat my infrastructure as <a href="https://joachim8675309.medium.com/devops-concepts-pets-vs-cattle-2380b5aab313" target="_blank" rel="noopener">cattle instead of pets</a>, things like servers and clusters are meant to come and go. So if one server gets "sick", I just replace it with another one. That means everything is described as code in a git repo, and I do not change things by SSH'ing into the servers. You can think of it like a template to clone my entire infrastructure with one command into any AWS region/environment.</p><p>This also helps me in case of disaster recovery. I just run a few commands, and some minutes later my stack has been re-created. This was particularly useful when I moved from DigitalOcean, to Linode, and recently to AWS. Everything is described in code, so it's easy to keep track of what components I own, even years later (all companies have some AWS IAM policy or VPC subnet lurking around which was created via clicky-clicky on the UI, and now everyone depends on it).</p><ul><li><a href="https://www.terraform.io/" target="_blank" rel="noopener">Terraform</a>: I manage most of my cloud infrastructure with Terraform. Things like EKS clusters, S3 buckets, roles, and RDS instances are declared in my Terraform manifests. The state is synced to an encrypted S3 bucket to avoid getting in trouble in case something happens to my development laptop.</li><li><a href="https://www.docker.com/" target="_blank" rel="noopener">Docker</a>: I build everything as Docker images. Even stateful components like Clickhouse or Redis are packaged and shipped as Docker containers to my cluster. It also makes my stack very portable, as I can run it anywhere I can run Docker.</li><li><a href="https://kubernetes.io/" target="_blank" rel="noopener">Kubernetes</a>: Allowed me to simplify the operational aspects tremendously. However, I wouldn’t bindly recommend it to everyone, as I already felt comfortable working with it after having the pleasure of putting down multiple production fires for my employer over the years. I also rely on managed offerings, which helps reduce the burden too.</li><li><a href="https://github.com/features/actions" target="_blank" rel="noopener">GitHub Actions</a>: Normally I’d use <a href="https://circleci.com/" target="_blank" rel="noopener">CircleCI</a> in the past (which is also great), but for this project I prefer to use GitHub Actions as it removes yet another service which needs to have access to my repositories, and deployment secrets. However, CircleCI has plenty of good features, and I still recommend it.</li></ul><h2>Infrastructure</h2><p>I started in a single $5/mo instance in DigitalOcean, then moved to the managed Kubernetes offering as I was reinventing the wheel for a lot of things Kubernetes already gives me out of the box (service discovery, TLS certs, load balancing, log rotation, rollout, scaling, fault-tolerance, among others).</p><p>Unfortunately, I had <a href="https://www.digitalocean.com/community/questions/kubernetes-unable-to-connect-to-the-server" target="_blank" rel="noopener">reliability issues</a> with DigitalOcean's Kubernetes offering, even on larger instances. The cluster API would often go down randomly and no longer recover, this disrupted a lot of cluster services including the load balancer, which translated into downtime for me. I had to create a new cluster each time this happened, and while Terraform made it trivial, this was not something that inspired a lot of confidence about their managed service. I suspect their control plane was underprovisioned, which would be kind of understandable given the price tag.</p><p>Unfortunately I was not able to resolve the issue after several weeks. That's why I decided to move to <a href="https://www.linode.com/" target="_blank" rel="noopener">Linode</a>, and had exactly 0 problems during the 1.5 month-long honeymoon that followed.</p><p>However, I recently moved once again, this time to AWS due to a pretty good deal I received. It also enabled me to use managed services like RDS to offload managing PostgreSQL, which is a big plus. What made all these migrations relatively easy, was that all my infrastructure was described via Terraform and Kubernetes manifests. The migrations essentially consisted of an evening, some tea, and patience. But that's for another post.</p><ul><li><a href="https://aws.amazon.com/" target="_blank" rel="noopener">AWS</a>: Predictable, and lots of managed services. However, I use it at my full-time job, so I didn't have to spend too much time figuring things out. The main services I use are EKS, ELB, S3, RDS, IAM and private VPCs. I might also add Cloudfront and Kinesis in the future.</li><li><a href="https://www.cloudflare.com/" target="_blank" rel="noopener">Cloudflare</a>: I mainly use it for DDoS protection, serving DNS, and offloading edge caching of various static assets (currently shaves off 80% of the egress charges from AWS - their bandwidth pricing is insane!).</li><li><a href="https://letsencrypt.org/" target="_blank" rel="noopener">Let’s Encrypt</a>: Free SSL certificate authority. I use cert-manager in my Kubernetes cluster to automatically issue and renew certificates based on my ingress rules.</li><li><a href="https://www.namecheap.com/" target="_blank" rel="noopener">Namecheap</a>: My domain name registrar of choice. Allows MFA for login which is an important security feature. Unlike other registrars, they haven't surprised me with an expensive renewal every few years. I like them.</li></ul><h2>Kubernetes components</h2><p>The following components automate most of the devops work for me. I use several others too, but some of the main ones I use are:</p><ul><li><a href="https://github.com/kubernetes/ingress-nginx/" target="_blank" rel="noopener">ingress-nginx</a>: Rock-solid ingress controller for Kubernetes using NGINX as a reverse proxy, and load balancer. Sits behind the NLB which controls ingress to the cluster nodes.</li><li><a href="https://github.com/jetstack/cert-manager" target="_blank" rel="noopener">cert-manager</a>: Automatically issue/renew TLS certs as defined in my ingress rules.</li><li><a href="https://github.com/kubernetes-sigs/external-dns" target="_blank" rel="noopener">external-dns</a>: Synchronizes exposed Kubernetes Services and Ingresses with DNS providers (such as Cloudflare).</li><li><a href="https://github.com/prometheus-operator/prometheus-operator" target="_blank" rel="noopener">prometheus-operator</a>: Automatically monitors most of my services, and exposes dashboards via Grafana.</li><li><a href="https://fluxcd.io/" target="_blank" rel="noopener">flux</a>: GitOps way to do continuous delivery in Kubernetes. Basically pulls and deploys new Docker images when I release them.</li></ul><h2>CLI tools</h2><p>There’s plenty here, but frequently used include:</p><ul><li><a href="https://kubernetes.io/" target="_blank" rel="noopener">kubectl</a>: To interact with the Kubernetes cluster to watch logs, pods and services, SSH into a running container, and so on.</li><li><a href="https://github.com/wercker/stern" target="_blank" rel="noopener">stern</a>: Multi pod log tailing for Kubernetes. Really handy.</li><li><a href="https://htop.dev/" target="_blank" rel="noopener">htop</a>: Interactive system process viewer. Better than “top” if you ask me.</li><li><a href="https://curl.se/" target="_blank" rel="noopener">cURL</a>: Issue HTTP requests locally, inspect headers.</li><li><a href="https://httpie.io/" target="_blank" rel="noopener">HTTPie</a>: Like cURL, but simpler for JSON APIs.</li><li><a href="https://github.com/rakyll/hey" target="_blank" rel="noopener">hey</a>: Load testing HTTP endpoints. Gives a nice latency distribution summary.</li></ul><h2>Monitoring</h2><ul><li><a href="https://prometheus.io/" target="_blank" rel="noopener">Prometheus</a>: Efficient storage of time series data for monitoring. Tracks all the cluster and app metrics. It was a lot cheaper than using Cloudwatch for app metrics.</li><li><a href="https://grafana.com/" target="_blank" rel="noopener">Grafana</a>: Nice dashboards for the Prometheus monitoring data. All dashboards are described in JSON files and versioned in the …</li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://panelbear.com/blog/tech-stack/">https://panelbear.com/blog/tech-stack/</a></em></p>]]>
            </description>
            <link>https://panelbear.com/blog/tech-stack/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25186342</guid>
            <pubDate>Mon, 23 Nov 2020 13:06:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GitHub co-founder is building a full-stack, serverless framework – RedwoodJS]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25186261">thread link</a>) | @oczek
<br/>
November 23, 2020 | https://blog.graphqleditor.com/redwoodjs/ | <a href="https://web.archive.org/web/*/https://blog.graphqleditor.com/redwoodjs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Jamstack is a new architectural approach with the core principle of pre-rendering aiming to make web applications to:</p>
<ul>
<li>run faster,</li>
<li>be more secure,</li>
<li>be easier to scale.</li>
</ul>
<p>All that achieved with the use of many modern tools to bring productivity to the maximum. Sounds interesting right? This approach is gaining a lot of popularity which makes a market for new tooling supporting the Jamstack approach. RedwoodsJS is one of the new shining stars, its team believes that JAMstack is a huge leap forward in web development and they are doing their best to make it even more pleasant to work with.</p>
<h2>RedwoodJS</h2>
<p>Redwood is an open-source project initiated by <strong>Tom Preston-Werner, the co-founder of GitHub &amp; creator of Jekyll</strong> - one of the first static site generators. So what is Redwood?</p>
<blockquote>
<p><em>Imagine a React frontend, statically delivered by CDN, that talks via GraphQL to your backend running on AWS Lambdas around the world, all deployable with just a git push—that’s Redwood.</em></p>
</blockquote>
<p>RedwoodJS is a highly opinionated, full-stack, serverless web application framework that aims to make building and deploying JAMstack apps as easy as possible. </p>
<h2>The stack</h2>
<p>RedwoodJS uses some of the most popular cutting-edge technologies and by giving up the freedom of choosing your tech stack, you are gaining a significant reduction of the level of complexity of setting up all services to make your infrastructure work as intended:</p>
<ul>
<li><strong>Frontend</strong> - this part is covered by React supported by Apollo and it has a lot of code generators involved which let you create everything i.e. routes, pages, cells (even with already pre-configured tests) out of the box.</li>
<li><strong>Backend</strong> - it’s becoming difficult to talk about cutting-edge technologies without putting GraphQL into the equation. Redwood uses Prisma for its GraphQL backend, enabling quick creation of backends with graphical interfaces.</li>
<li><strong>Deployment</strong> - Redwood’s development team has support for several deployment targets on their roadmap with a top-priority to make deployment strategies in a way that makes it easy for additional targets to be added, as well as to make it easy to adjust to user’s own deployment strategy. Right now it offers out of the box deployment to Netlify and Vercel, with AWS and Google Cloud Run high on their road map.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/107a55dd3ef68a5e3709cb776c31e41d/a3767/redwood_structure.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Diagram presenting RedwoodJS structure" title="Diagram presenting RedwoodJS structure" src="https://blog.graphqleditor.com/static/107a55dd3ef68a5e3709cb776c31e41d/fcda8/redwood_structure.png" srcset="https://blog.graphqleditor.com/static/107a55dd3ef68a5e3709cb776c31e41d/12f09/redwood_structure.png 148w,
https://blog.graphqleditor.com/static/107a55dd3ef68a5e3709cb776c31e41d/e4a3f/redwood_structure.png 295w,
https://blog.graphqleditor.com/static/107a55dd3ef68a5e3709cb776c31e41d/fcda8/redwood_structure.png 590w,
https://blog.graphqleditor.com/static/107a55dd3ef68a5e3709cb776c31e41d/efc66/redwood_structure.png 885w,
https://blog.graphqleditor.com/static/107a55dd3ef68a5e3709cb776c31e41d/c83ae/redwood_structure.png 1180w,
https://blog.graphqleditor.com/static/107a55dd3ef68a5e3709cb776c31e41d/a3767/redwood_structure.png 1210w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://redwoodjs.com/">redwoodjs.com</a></h5>
<h2>Concepts &amp; features</h2>
<p>Redwood features a lot of new interesting concepts as well as brings a breath of fresh air to well-known ones. One of the most interesting ones are definitely:</p>
<ul>
<li><strong>Cells</strong> - they are one of the signature modes of abstraction in Redwood. Cells represent a declarative approach to data fetching which creates space (by providing conventions around data fetching) in between the request and the response which Redwood can utilize to perform its optimizations. All of this without writing a line of imperative code.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/55fbb6196d36823b27369fe2634057dd/00d43/cells.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="RedwoodJS cells concept" title="RedwoodJS cells concept" src="https://blog.graphqleditor.com/static/55fbb6196d36823b27369fe2634057dd/fcda8/cells.png" srcset="https://blog.graphqleditor.com/static/55fbb6196d36823b27369fe2634057dd/12f09/cells.png 148w,
https://blog.graphqleditor.com/static/55fbb6196d36823b27369fe2634057dd/e4a3f/cells.png 295w,
https://blog.graphqleditor.com/static/55fbb6196d36823b27369fe2634057dd/fcda8/cells.png 590w,
https://blog.graphqleditor.com/static/55fbb6196d36823b27369fe2634057dd/efc66/cells.png 885w,
https://blog.graphqleditor.com/static/55fbb6196d36823b27369fe2634057dd/00d43/cells.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://redwoodjs.com/">redwoodjs.com</a></h5>
<ul>
<li><strong>Redwood Router</strong> -  Redwood features its own router that took inspiration from React Router, Ruby on Rails and Reach Router. It brings some awesome innovation to this crucial part of your app.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/de333840fbfc693cbad484ca4193032a/00d43/router.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Router in RedwoodJS" title="Router in RedwoodJS" src="https://blog.graphqleditor.com/static/de333840fbfc693cbad484ca4193032a/fcda8/router.png" srcset="https://blog.graphqleditor.com/static/de333840fbfc693cbad484ca4193032a/12f09/router.png 148w,
https://blog.graphqleditor.com/static/de333840fbfc693cbad484ca4193032a/e4a3f/router.png 295w,
https://blog.graphqleditor.com/static/de333840fbfc693cbad484ca4193032a/fcda8/router.png 590w,
https://blog.graphqleditor.com/static/de333840fbfc693cbad484ca4193032a/efc66/router.png 885w,
https://blog.graphqleditor.com/static/de333840fbfc693cbad484ca4193032a/00d43/router.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://redwoodjs.com/">redwoodjs.com</a></h5>
<p>If you interested in more detailed information about Redwood’s concepts and its implementation make sure to visit <a href="https://redwoodjs.com/docs/introduction">the official docs</a>.</p>
<h2>Not a 1.0 version</h2>
<p>RedwoodJS software has not reached a stable version 1.0 yet.
Its team put Redwood in the later stages of the “make it work” phase in the “make it work; make it right; make it fast” paradigm. Although this makes it not suitable for production use, Redwood is a concept that is definitely worth following.</p></div><p>The GraphQL Editor is a supportive tool for both advanced GraphQL users as well as those taking their first steps with GraphQL APIs. Our all-in-one development environment for GraphQL will help you build, manage &amp; deploy your GraphQL API much faster thanks to dozens of built-in micro features. Its graphical interface will also fix communication within your product team. Visualization is the key!</p></div>]]>
            </description>
            <link>https://blog.graphqleditor.com/redwoodjs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25186261</guid>
            <pubDate>Mon, 23 Nov 2020 12:57:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use Netlify Functions and the Twitter API v2 as a CMS for Your Gatsby Blog]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25186006">thread link</a>) | @pauliescanlon
<br/>
November 23, 2020 | https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/ | <a href="https://web.archive.org/web/*/https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://res.cloudinary.com/www-paulie-dev/image/upload/v1605613346/paulie.dev/2020/11/gatsby-netlify-twitterjpg_ok1k0q.jpg"></p><div><div><div><p>Date published: </p><!-- --><p>17-Nov-2020</p></div></div></div><hr><p>JavaScript</p><p>React</p><p>Gatsby</p><p>Netlify Functions</p><p>Twitter API v2</p><hr><p>Apologies in advance for the rather long-winded blog title but as it suggests in this post i'm going to explain how you can use <a href="https://www.netlify.com/products/functions/">Netlify Functions</a> to access your Twitter profile data using the <a href="https://developer.twitter.com/en/docs/twitter-api/early-access">Twitter v2 API</a> and display it on your Gatsby blog.</p><h2>A rather unique requirement</h2><p>This might be a specific to me but I wanted to solve a little problem I was having with my "digital footprint". As you can see I have this blog: <a href="https://paulie.dev/">https://paulie.dev</a> and a commercial portfolio: <a href="https://www.pauliescanlon.io/">https://www.pauliescanlon.io</a></p><p>Both sites are built on top of my Gatsby theme: <a href="https://gatsby-theme-terminal.netlify.app/">gatsby-theme-terminal</a> which is Open source and can be found on my <a href="https://github.com/PaulieScanlon/gatsby-theme-terminal">GitHub</a></p><p>Using a Gatsby Theme solves one of my issues as I'm able to have two sites that look and work pretty much the same way and any changes I make to the theme are inherited by both my sites. It's kind of like managing your own multi brand design system, but just for yourself.</p><p>There was one other problem though. 🤔</p><p>I wanted both sites to have the same "intro" section, but every time I made a change to one I had to make the same change to the other site to ensure they were both displaying the same intro text.</p><p>This might be fine if I weren't a developer but doing something twice is one time too many IMO.</p><p>It was also a little frustrating because I also wanted my Twitter profile description to be in sync with both the sites so, again another place to remember to update my personal blurb.</p><p>One option I considered would have been to hook up a Content Management System, and this would have been fine and it would have kept both my sites in sync but it wouldn't have been able to update my Twitter profile blurb...</p><p>So, I've decided to reverse engineer the Twitter API and use that as a CMS to populate both my sites. The idea is quite simple. I'll use the Twitter profile description as though it were a field from a CMS. Naturally any changes I make to this will appear on my Twitter profile and below is how I pull that same info into both of my sites.</p><h2>Demo</h2><p>Here's what I'll be showing you how to build:</p><ul><li>App / API <a href="https://gatsby-netlify-twitter.netlify.app/">https://gatsby-netlify-twitter.netlify.app</a></li><li>GitHub repo <a href="https://github.com/PaulieScanlon/gatsby-netlify-twitter">https://github.com/PaulieScanlon/gatsby-netlify-twitter</a></li></ul><p>... but the actual API I use for my blog and site is here: <a href="https://paulie-api.netlify.app/">https://paulie-api.netlify.app</a></p><h2>Tech</h2><h3>Netlify Functions</h3><p>"Power your site without managing servers" is how Netlify describe Functions and for all intents and purposes thats exactly what they are. Similar to how you might create an <a href="https://expressjs.com/">Express</a> app and deploy it somewhere but without the hassle of having to setup server side environments and more crucially any really dweeby server uptime monitoring.</p><h3>Twitter API v2</h3><p>A set of endpoints that can be used to get data from Twitter. Any Twitter requests must be done server side and use a set of keys and tokens. You can't unfortunately hit the Twitter API from the browser so we need a "server" or as mentioned above, a Netlify Function</p><p>Using both of the above i've made my own API endpoint which goes off and hits the Twitter API and returns my Profile information which I can then display in the intro section of my blog and site. I've deployed this API to Netlify and it's completely de-coupled from either of my sites but will return data which can be fetched from client side "fetch" request from within my site and blog. That url again is here: <a href="https://paulie-api.netlify.app/">https://paulie-api.netlify.app</a></p><h2>Before we start</h2><p>Before we get started there's a couple of things you'll need to have in place.</p><h3>Twitter API v2</h3><p>Apply for access to the <a href="https://developer.twitter.com/en/products/twitter-api">Twitter API</a>. This is quite a lengthy process so strap in and also bookmark this post as it might take a few days for Twitter to accept your application.</p><p>Once you have access you can head over to the <a href="https://developer.twitter.com/en/portal/dashboard">Developer Portal</a> and create a new project, and within the project you can create an "app", I called mine "paulie-api".</p><p>In here you'll find all the API keys and tokens required to access the Twitter API. Make a note of them somewhere as we'll be using them later.</p><h3>Netlify CLI</h3><p>To run Netlify Functions we'll be using <code>netlify dev</code> rather than <code>gatsby develop</code> or <code>yarn develop</code> so you'll need to install the <a href="https://docs.netlify.com/cli/get-started/">Netlify CLI</a></p><h2>The Build</h2><p>In order to develop you own API I found it easiest to have some kind of "site" running at the same time which will access the API endpoint and render the response on the page. In the demo repo you'll see i've set up a really simple Gatsby Site with one page that uses "fetch" to, er fetch and then render the data.</p><p>I've used <a href="https://theme-ui.com/home">Theme UI</a> for the style but naturally you can choose whatever you like to do this.</p><p>Whether you're starting from scratch or adding Netlify Functions to an existing project you'll need to start by adding a <code>functions</code> dir to the root of your project.</p><hr><pre><p><span>|</span><span>-- functions</span></p><p><span>  </span><span>|</span><span>-- package.json</span></p><p><span></span><span>|</span><span>-- src</span></p><p><span>package.json</span></p></pre><hr><p><code>functions</code> is kind of it's own application so it'll need it's own <code>package.json</code> and will have one dependency on <a href="https://github.com/HunterLarco/twitter-v2">twitter-v2</a></p><hr><pre><p><span></span><span>{</span><span></span></p><p><span>  </span><span>"name"</span><span>:</span><span> </span><span>"gatsby-netlify-twitter-api"</span><span>,</span><span></span></p><p><span>  </span><span>"version"</span><span>:</span><span> </span><span>"1.0.0"</span><span>,</span><span></span></p><p><span>  </span><span>"description"</span><span>:</span><span> </span><span>"An api for the Twitter v2 api"</span><span>,</span><span></span></p><p><span>  </span><span>"main"</span><span>:</span><span> </span><span>"index.js"</span><span>,</span><span></span></p><p><span>  </span><span>"scripts"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>"test"</span><span>:</span><span> </span><span>"echo \"Error: no test specified\" &amp;&amp; exit 1"</span><span></span></p><p><span>  </span><span>}</span><span>,</span><span></span></p><p><span>  </span><span>"keywords"</span><span>:</span><span> </span><span>[</span><span>]</span><span>,</span><span></span></p><p><span>  </span><span>"author"</span><span>:</span><span> </span><span>""</span><span>,</span><span></span></p><p><span>  </span><span>"license"</span><span>:</span><span> </span><span>"ISC"</span><span>,</span><span></span></p><p><span>  </span><span>"dependencies"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>"twitter-v2"</span><span>:</span><span> </span><span>"^0.1.2"</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span></p></pre><hr><p>Next have a look at <a href="https://github.com/PaulieScanlon/gatsby-netlify-twitter/blob/main/.env.example">.env.example</a>. You'll need to create your own <code>.env</code> file and add the environment variables as seen in the <code>.env.example</code>. Naturally you'll want to change the <code>GATSBY_TWITTER_USERNAME</code> to your own Twitter username and the Twitter keys and tokens will be what I referenced earlier which are provided by the Twitter Developer Portal</p><hr><pre><p><span></span><span>GATSBY_API_URL</span><span>=</span><span>.</span><span>/</span><span>.</span><span>netlify</span><span>/</span><span>functions</span></p><p><span></span><span>GATSBY_TWITTER_USERNAME</span><span>=</span><span></span></p><p><span></span><span>TWITTER_API_KEY</span><span>=</span><span></span></p><p><span></span><span>TWITTER_API_KEY_SECRET</span><span>=</span><span></span></p><p><span></span><span>TWITTER_ACCESS_TOKEN</span><span>=</span><span></span></p><p><span></span><span>TWITTER_ACCESS_TOKEN_SECRET</span><span>=</span></p></pre><hr><p>Next create a Twitter client, this is what we'll use to pass the keys and tokens onto the Twitter API when we make a request</p><hr><pre><p><span></span><span>const</span><span> </span><span>Twitter</span><span> </span><span>=</span><span> </span><span>require</span><span>(</span><span>"twitter-v2"</span><span>)</span><span></span></p><p><span>module</span><span>.</span><span>exports</span><span> </span><span>=</span><span> </span><span>{</span><span></span></p><p><span>  client</span><span>:</span><span> </span><span>new</span><span> </span><span>Twitter</span><span>(</span><span>{</span><span></span></p><p><span>    consumer_key</span><span>:</span><span> process</span><span>.</span><span>env</span><span>.</span><span>TWITTER_CONSUMER_KEY</span><span>,</span><span></span></p><p><span>    consumer_secret</span><span>:</span><span> process</span><span>.</span><span>env</span><span>.</span><span>TWITTER_CONSUMER_KEY_SECRET</span><span>,</span><span></span></p><p><span>    access_token</span><span>:</span><span> process</span><span>.</span><span>env</span><span>.</span><span>TWITTER_ACCESS_TOKEN</span><span>,</span><span></span></p><p><span>    access_token_secret</span><span>:</span><span> process</span><span>.</span><span>env</span><span>.</span><span>TWITTER_ACCESS_TOKEN_SECRET</span><span>,</span><span></span></p><p><span>  </span><span>}</span><span>)</span><span>,</span><span></span></p><p><span></span><span>}</span></p></pre><hr><p>You should now be looking at something similar to the below</p><hr><pre><p><span>..</span><span>.</span></p><p><span></span><span>|</span><span>-- functions</span></p><p><span>  </span><span>|</span><span>-- client.js</span></p><p><span>  </span><span>|</span><span>-- package.json</span></p><p><span></span><span>|</span><span>-- src</span></p><p><span>package.json</span></p><p><span>.env</span></p><p><span></span><span>..</span><span>.</span></p></pre><hr><p>Now we need to create the "endpoint" that our frontend will hit, which in turn goes off and grabs the data from the Twitter API.</p><p>I created a dir called <code>twitter-user</code> and inside I create a new file and called it <code>twitter-user.js</code></p><hr><pre><p><span>..</span><span>.</span></p><p><span></span><span>|</span><span>-- functions</span></p><p><span>  </span><span>|</span><span>-- client.js</span></p><p><span>  </span><span>|</span><span>-- twitter-user</span></p><p><span>    </span><span>|</span><span>-- twitter-user.js</span></p><p><span>  </span><span>|</span><span>-- package.json</span></p><p><span></span><span>|</span><span>-- src</span></p><p><span>package.json</span></p><p><span>.env</span></p><p><span></span><span>..</span><span>.</span></p></pre><hr><p>It's in here where we can use the <code>client.js</code> to hit a Twitter API endpoint and pass with it the required keys and tokens from the <code>client</code></p><hr><pre><p><span></span><span>const</span><span> </span><span>{</span><span> client </span><span>}</span><span> </span><span>=</span><span> </span><span>require</span><span>(</span><span>"../client"</span><span>)</span><span></span></p><p><span>exports</span><span>.</span><span>handler</span><span> </span><span>=</span><span> </span><span>async</span><span> </span><span>(</span><span>event</span><span>,</span><span> context</span><span>,</span><span> callback</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>{</span><span> data </span><span>}</span><span> </span><span>=</span><span> </span><span>await</span><span> client</span><span>.</span><span>get</span><span>(</span><span></span></p><p><span>    </span><span>`</span><span>users/by/username/</span><span>${</span><span>process</span><span>.</span><span>env</span><span>.</span><span>GATSBY_TWITTER_USERNAME</span><span>}</span><span>`</span><span>,</span><span></span></p><p><span>    </span><span>{</span><span></span></p><p><span>      user</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>        fields</span><span>:</span><span></span></p><p><span>          </span><span>"created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,public_metrics,url,username,verified,withheld"</span><span>,</span><span></span></p><p><span>      </span><span>}</span><span>,</span><span></span></p><p><span>    </span><span>}</span><span></span></p><p><span>  </span><span>)</span><span></span></p><p><span>  </span><span>callback</span><span>(</span><span>null</span><span>,</span><span> </span><span>{</span><span></span></p><p><span>    headers</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>      </span><span>"Access-Control-Allow-Origin"</span><span>:</span><span> </span><span>"*"</span><span>,</span><span></span></p><p><span>    </span><span>}</span><span>,</span><span></span></p><p><span>    statusCode</span><span>:</span><span> </span><span>200</span><span>,</span><span></span></p><p><span>    body</span><span>:</span><span> </span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span><span> user</span><span>:</span><span> data </span><span>}</span><span>)</span><span>,</span><span></span></p><p><span>  </span><span>}</span><span>)</span><span></span></p><p><span></span><span>}</span></p></pre><hr><p>In the above you can see we use our <code>client</code> to hit the <code>users/by/username</code> Twitter API endpoint which you can read more about <a href="https://developer.twitter.com/en/docs/twitter-api/users/lookup/introduction">here</a>, which returns a <code>data</code> object which I pass on to the callback body as <code>{ user: data }</code></p><p>This is the object that'll we receive in our frontend</p><p>The next bit will greatly depend on how you've set up your frontend but in the <a href="https://github.com/PaulieScanlon/gatsby-netlify-twitter/blob/main/src/pages/index.js">Demo</a> I have one <code>page</code> called <code>index.js</code> which uses a <code>useEffect</code> to "fetch" the data from the Netlify Function.</p><p>The example file contains a few extra bits for <code>isLoading</code> and <code>hasError</code> but the below should be enough to allow you hit to the Netlify Function which in turn hits the Twitter API and returns your profile information data.</p><hr><pre><p><span></span><span>import</span><span> </span><span>React</span><span>,</span><span> </span><span>{</span><span> useState </span><span>}</span><span> </span><span>from</span><span> </span><span>"react"</span><span></span></p><p><span></span><span>const</span><span> </span><span>IndexPage</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>[</span><span>response</span><span>,</span><span> setResponse</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>(</span><span>{</span><span> user</span><span>:</span><span> </span><span>null</span><span> </span><span>}</span><span>)</span><span></span></p><p><span>  </span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>fetch</span><span>(</span><span>`</span><span>${</span><span>process</span><span>.</span><span>env</span><span>.</span><span>GATSBY_API_URL</span><span>}</span><span>/twitter-user</span><span>`</span><span>)</span><span></span></p><p><span>      </span><span>.</span><span>then</span><span>(</span><span>(</span><span>response</span><span>)</span><span> </span><span>=&gt;</span><span> response</span><span>.</span><span>text</span><span>(</span><span>)</span><span>)</span><span></span></p><p><span>      </span><span>.</span><span>then</span><span>(</span><span>(</span><span>response</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>        </span><span>console</span><span>.</span><span>log</span><span>(</span><span>JSON</span><span>.</span><span>parse</span><span>(</span><span>response</span><span>)</span><span>)</span><span></span></p><p><span>        </span><span>setResponse</span><span>(</span><span>JSON</span><span>.</span><span>parse</span><span>(</span><span>response</span><span>)</span><span>)</span><span></span></p><p><span>      </span><span>}</span><span>)</span><span></span></p><p><span>      </span><span>.</span><span>catch</span><span>(</span><span>(</span><span>error</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>        </span><span>console</span><span>.</span><span>error</span><span>(</span><span>{</span><span> error </span><span>}</span><span>)</span><span></span></p><p><span>      </span><span>}</span><span>)</span><span></span></p><p><span>  </span><span>}</span><span>,</span><span> </span><span>[</span><span>]</span><span>)</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>{</span><span> user </span><span>}</span><span> </span><span>=</span><span> response</span></p><p><span>  </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>    </span><span>&lt;</span><span>pre</span><span>&gt;</span><span></span></p><p><span>      </span><span>&lt;</span><span>code</span><span>&gt;</span><span>{</span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>user</span><span>,</span><span> </span><span>null</span><span>,</span><span> </span><span>2</span><span>)</span><span>}</span><span>&lt;</span><span>/</span><span>code</span><span>&gt;</span><span></span></p><p><span>    </span><span>&lt;</span><span>/</span><span>pre</span><span>&gt;</span><span></span></p><p><span>  </span><span>)</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>export</span><span> </span><span>default</span><span> </span><span>IndexPage</span></p></pre><hr><p><code>process.env.GATSBY_API_URL</code> is the path to the Netlify Function we added earlier to <code>.env</code> and i've hard-coded <code>/twitter-user</code> in the component / page as you might want to create different endpoints that return different data on different pages.</p><p>You might be wondering why this environment variable is prefixed with <code>GATSBY_</code>. This is so Gatsby can access it from the frontend. You can read more about Gatsby environment variables <a href="https://www.gatsbyjs.com/docs/environment-variables/#client-side-javascript">here</a></p><h3>IMPORTANT</h3><p>In order for Netlify Functions to work both locally and when deployed we need to ensure we've got <code>netlify-lambda</code> installed and have added both a <code>"start"</code> and <code>"postinstall"</code> script to the root <code>package.json</code> (not the <code>package.json</code> in <code>./functions</code>)</p><hr><pre><p><span>npm</span><span> </span><span>install</span><span> netlify-lambda --save -dev</span></p></pre><hr><pre><p><span>// ./package.json</span></p><p><span>...</span></p><p><span></span><span>  "scripts": {</span></p><p><span>    "develop": "gatsby develop",</span></p><p><span>    "build": "gatsby build",</span></p><p><span>    "clean": "gatsby clean",</span></p><p><span>    "serve": "gatsby serve",</span></p><p><span></span><span>+    "start": "npm run develop",</span></p><p><span>+    "postinstall": "netlify-lambda install"</span></p><p><span></span><span>  },</span></p><p><span>   "devDependencies": {</span></p><p><span></span><span>+   "netlify-lambda": "^1.6.3",</span></p><p><span></span><span>  }</span></p><p><span></span><span>...</span></p></pre><hr><p>Before we get too carried away, it's important to note that we'll no longer be using <code>gatsby develop</code> or <code>yarn develop</code> to start the Gatsby app, if you do that our Netlify Function won't be running and you'll get an error.</p><p>Instead, run <code>netlify dev</code> this is so both the Gatsby site and the Netlify Function are run at the same time.</p><p>Instead of visiting the usual <code>http://localhost:8000/</code> we'll now be visiting <code>http://localhost:8888/</code></p><p>And to ensure when we deploy everything works as it should you'll need to modify your <a href="https://github.com/PaulieScanlon/gatsby-netlify-twitter/blob/main/netlify.toml"><code>netlify.toml</code></a></p><p>For …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/">https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/</a></em></p>]]>
            </description>
            <link>https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25186006</guid>
            <pubDate>Mon, 23 Nov 2020 12:27:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Detective Game Design Problems]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25185571">thread link</a>) | @jsnell
<br/>
November 23, 2020 | https://digitales.games/blog/detective-game-design-problems | <a href="https://web.archive.org/web/*/https://digitales.games/blog/detective-game-design-problems">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="blog">
            <div>
                <div>
					
                    <div>

                        <div>


    <div>

                    <p>Game design is such a wide and varied discipline that job titles in the field have become increasingly granular over the years – and ever since we started working on our debut title Lacuna, I've become more and more convinced that "detective game designer" merits its own denomination as well. Detective gameplay (or "investigation gameplay") poses a number of unique challenges centered around two main problems: the <strong>struggle between story and puzzles</strong> (or "cases") as well as <strong>communication between the player and the game</strong>.</p>
<p>Since some of the explanations will be using our own game as an example, let me give you a quick rundown: Lacuna is a story-driven adventure with platformer controls and investigation elements. Its four fundamental gameplay types are dialogs (with choices), moving around, examining objects, and solving puzzles. All of them are staples of the point &amp; click genre, but their execution is quite unique; I don't want to go into more detail here because it's not pertinent to the topic, but you can <a href="http://lacuna.game/">check out the game on Steam</a> if you want to know more.</p>
<p><img alt="Gameplay" src="https://digitales.games/user/pages/03.blog/detective-game-design-problems/gameplay-movement.gif"><br>
<em>This is what the game looks like</em></p>
<h2>Story vs. puzzles</h2>
<p>A handful of abstract game design principles lie at Lacuna's core. For instance, "no takebacks" dictates that the player only get one shot at every decision, dialog, and puzzle. The game auto-saves and doesn't allow you to go back if you performed poorly or regret an earlier decision. There's also "limited feedback", which means that the player often isn't told immediately whether a solution was correct and what the consequences of their actions and decisions will be.</p>
<p>However, there's one in particular I want to highlight here because it concerns the above mentioned divide between story and puzzling in detective games: <strong>No getting stuck.</strong></p>
<p>The thought process behind it was simple: In games with both a story and puzzles (e.g. most P&amp;C games), story progress is almost always tied directly to puzzle progress. Until you solve the puzzle at hand, you don't get to see the next part of the story. For some players, especially those most interested in the story, this can become a problem. If they're stuck for too long, there's a chance they'll just drop out and never pick the game up again. Even if that doesn't happen, hard puzzles always run the risk of messing up the story's pacing and interrupting your immersion in the game – because you're becoming frustrated or, even worse, because you decide to tab out and Google the solution. To avoid people getting stuck, we considered a number of solutions:</p>
<p><strong>Solution 1: Make the puzzles very easy?</strong><br>
This isn't our favorite since it somewhat defeats the purpose of puzzles. They'd still play a role as a change of pace now and then, but if puzzles aren't a little hard, nobody will feel like a detective solving them. Some early puzzles in Lacuna are easy, but most aren't.</p>
<p><strong>Solution 2: Provide hints?</strong><br>
Hint systems can be found in many adventures featuring puzzles. Unfortunately, they often take the player out of the experience in one of three ways: In some cases, the hint is provided by extradiegetic UI (e.g. in the pause menu) and therefore seems to come out of nowhere in the game world. In other cases, the player character is the one giving the hint, disconnecting the player from their avatar’s perspective. The third option of NPCs providing hints is a little better; however, it is often hard to justify <em>why</em> an NPC would be able to point the player in the right direction without possessing the rest of the solution to the ongoing puzzle (and why they didn't volunteer it in the first place). The two types of (sort-of) hint systems we went with in Lacuna are <em>Highlight Mode</em>, which displays optional outlines around objects and NPCs that hold new information, and <em>redundant information</em>, meaning that sometimes the player is given two ways of obtaining an important clue.</p>
<p><img alt="Hints" src="https://digitales.games/user/pages/03.blog/detective-game-design-problems/solutions-hints.png"><br>
<em>"YOU ARE PLAYING A GAME RIGHT NOW"</em></p>
<p><strong>Solution 3: Decouple story progress from puzzle progress?</strong><br>
Why not simply make a story-driven game throughout which the player can solve the occasional puzzle if they feel like it? Well, because it would require that puzzles be somewhat detached from the story. As a result, they run the risk of feeling meaningless since solving them is not rewarding and failing is not punishing. However, this <em>can</em> work quite well when combined with...</p>
<p><strong>Solution 4: Make branching content for different solutions?</strong><br>
Instead of impeding the player’s progress, wrong or missing puzzle solutions could lead to a less desirable continuation and/or outcome of the story. Unfortunately, creating a new story branch for each and every wrong solution to a puzzle is hardly feasible. However, there are less extreme ways of realizing this. For instance, the game could account for the player’s <em>overall</em> puzzling performance at certain points in the game, e.g. trigger the “good” finale to an act if they got more than x% of the puzzles right, and the “bad” one if not. There could also be cascading consequences of sorts, e.g. solving one case correctly may give the player an edge in a later one. These approaches have similar downsides as optional puzzles do, but to a lesser degree; puzzle success no longer being required for progress makes them feel more detached from the story and removes immediate feedback. Regardless, we have found this to be the best solution, which is why we employ it quite a bit in Lacuna (while trying to avoid all the pitfalls). By the way, if all of this is becoming too abstract for you, bear with us! The second half of this post is all about a real example from the game.</p>
<p><img alt="Detroit: Become Human" src="https://digitales.games/user/pages/03.blog/detective-game-design-problems/solutions-branching-content.jpg"><br>
<em>Detroit: Become Human offers an astonishing number of different outcomes depending on player action, but not everybody has that kind of money to burn</em></p>
<p>Despite all of these measures being taken to make sure that the player won't get stuck, Lacuna can still be called a hard game. While it's not difficult to get <em>to</em> the end, it's pretty difficult to get a <em>good</em> ending and not mess things up on your way there. In other words, rushing through the whole story is possible if you don't mind bringing it to a terrible conclusion.</p>
<h2>Communicating with the game</h2>
<p>While the previous chapter only concerns detective games that also prominently feature a story, this next one is relevant to pretty much every detective game every made. It addresses the topic of communication between the player and the game, and especially how the player can express their thoughts to it. Several principles have proven to make for a good experience across countless approaches to this problem over the years:</p>
<p><strong>Principle 1: Many channels out, few channels back in.</strong><br>
If the game conveys information to the player on many different channels and in many different ways, the process of piecing the solution together tends to feel more interesting and rewarding. In Lacuna, the player picks up clues from dialogs, objects, environments, the news, and e-mails (with all sorts of attachments). At the same time, the channels via which the player communicates that solution back to the game are kept to a minimum, namely cloze texts we like to call "Case Sheets" and (to a lesser degree) dialog choices. Having one or two central mechanics for player input makes the experience more coherent and transparent and facilitates designing the mysteries around it.</p>
<p><img alt="Obra Dinn" src="https://digitales.games/user/pages/03.blog/detective-game-design-problems/solutions-obra-dinn.jpg"><br>
<em>Return of the Obra Dinn by Lucas Pope provides a bunch of different sources of information, but just one central mechanic for the player to communicate back to the game</em></p>
<p><strong>Principle 2: Have the player communicate only the solution.</strong><br>
It is near impossible to create a system through which the player communicates to the game <em>how</em> they arrived at a solution. Luckily, this is not necessary. A well-designed puzzle provides all the information, then moves the entire solution process solely <em>into the player’s head</em>, and finally prompts the player to input only their answer. The player’s objective should be stated clearly, but in a very general way at the start of a case (e.g. “find the culprit”).</p>
<p><strong>Principle 3: Give the player maximum freedom in communicating the solution.</strong><br>
The way in which the player communicates the answer to the game is the most crucial part to get right. One aspect is to give the player many choices (or a large combination of choices) to pick from. Two things should be avoided: 1. Giving the player a high probability to succeed by picking a random answer. 2. Making it easy for the player to guess correctly because only one or a few of the available answers appear plausible. An example for a bad solution like this would be to give the player three dialog choices to solve the puzzle; even worse would be if one of them obviously made the most sense. A better approach would be to give the player a cloze text with a bunch of plausible options for each gap. Another possibility is to have the solution be an unguessable string of characters that the player needs to enter manually. Both ideas utilize combinatorial explosion to make guessing and brute-forcing nearly impossible.</p>
<p><img alt="Detective Grimoire" src="https://digitales.games/user/pages/03.blog/detective-game-design-problems/solutions-case-sheets.jpg"><br>
<em>Good luck brute-forcing your way through Detective Grimoire's cloze texts</em></p>
<h2>Puzzle example</h2>
<p>Hopefullly all this will become crystal clear when put to concrete use! The following is an early level in Lacuna. It doesn't contain some of the difficulties added later (like a large number of channels communicating potential evidence). In harder cases, the player will need to have paid attention to testimonies, news articles etc. from earlier levels to arrive at the correct conclusion, and some cases span multiple levels. Not this one, though; all the information required to solve it is directly contained in the clues and dialogs of the one level where it starts and ends.</p>
<p>This chapter won't reveal much of importance about the story, but it will spoil the solution to this one puzzle, so consider yourself warned.</p>
<h3>The puzzle</h3>
<p>Here's what happens: Our protagonist Neil is called to a …</p></div></div></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://digitales.games/blog/detective-game-design-problems">https://digitales.games/blog/detective-game-design-problems</a></em></p>]]>
            </description>
            <link>https://digitales.games/blog/detective-game-design-problems</link>
            <guid isPermaLink="false">hacker-news-small-sites-25185571</guid>
            <pubDate>Mon, 23 Nov 2020 11:11:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WhiteHat Jr is a startup hell]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25185492">thread link</a>) | @jatins
<br/>
November 23, 2020 | https://themorningcontext.com/indias-whitehatjr-is-startup-hell/# | <a href="https://web.archive.org/web/*/https://themorningcontext.com/indias-whitehatjr-is-startup-hell/#">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><p><strong><span>S</span>haarif Ansari got the call on 11 November</strong> at around 9 in the morning. On the phone was a police officer from Powai police station, in the suburbs of Mumbai. “Ansari please come to the police station,” said the officer. “We have received a complaint from your employer WhiteHat Jr. The company officials are here at the station already. We are waiting for you.”&nbsp;</p> <p>Ansari was taken aback. It is not everyday that you have a police officer call you. Almost immediately he clarified that he did not work at WhiteHat Jr anymore. That he was fired by the company in the first week of September and had had no contact with them since, so what was all this about? The person was in no mood to explain or chat. He cut Ansari off, and asked him to turn up at the station immediately. Caught completely by surprise and with no idea about what was in store for him, Ansari said he was on his way.</p> <p>Once he reached the station, Ansari found two people waiting for him</p></div></div></div></div></div>]]>
            </description>
            <link>https://themorningcontext.com/indias-whitehatjr-is-startup-hell/#</link>
            <guid isPermaLink="false">hacker-news-small-sites-25185492</guid>
            <pubDate>Mon, 23 Nov 2020 10:57:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tauri – desktop applications with a web front end]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25185376">thread link</a>) | @dsego
<br/>
November 23, 2020 | https://tauri.studio/en/ | <a href="https://web.archive.org/web/*/https://tauri.studio/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__docusaurus">
<nav></nav><div><main><section><div><div><div><div><div><p><img src="https://tauri.studio/en/img/undraw_brownfield.svg" alt="Brownfield"></p><h3>Brownfield</h3><p>compatibility with any front-end framework means you don't have to change your stack</p></div></div></div><div><div><div><p><img src="https://tauri.studio/en/img/undraw_open_source.svg" alt="FLOSS"></p><h3>FLOSS</h3><p>relicensing is possible with Tauri</p></div></div></div><div><div><div><p><img src="https://tauri.studio/en/img/undraw_takeout_boxes.svg" alt="Bundle"></p><h3>Bundle</h3><p>size of a Tauri App can be less than 600KB</p></div></div></div></div><div><div><div><div><p><img src="https://tauri.studio/en/img/undraw_security.svg" alt="Security"></p><h3>Security</h3><p>is the Tauri-Team's biggest priority and drives our innovation</p></div></div></div><div><div><div><p><img src="https://tauri.studio/en/img/undraw_patterns.svg" alt="Patterns"></p><h3>Patterns</h3><p>are here to help you choose important features with simple configuration</p></div></div></div><div><div><div><p><img src="https://tauri.studio/en/img/undraw_cross_platform.svg" alt="Cross-platform"></p><h3>Cross-platform</h3><p>compilation allows to bundle binaries for major desktop platforms (mobile &amp; WASM coming soon)</p></div></div></div></div></div></section><section><div id="roadmap"><h2>Roadmap</h2><p>Notice: This roadmap is subject to change.</p><ul><li><span></span> To Do</li><li><span></span> Milestone</li><li><span></span> Ready</li></ul><ul><li><div><p>CLI</p><p>Generate, develop and build Tauri apps from the command line.</p></div><p>Q4 2019</p></li><li><div><p>API</p><p>Finalize, audit, write documentation and create examples for the smoke-tests.</p></div><p>Q4 2019</p></li><li><div><p>Testing &amp; CI</p><p>Implement CI with testing and bundle-pipeline validation.</p></div><p>Q4 2019</p></li><li><div><p>Desktop Bundler</p><p>Bundle for all major desktops from native systems.</p></div><p>Q4 2019</p></li><li><div><p>Alpha Release</p><p>Technical Release Candidate for desktop, edge cases and bugs acceptable.</p></div><p>Q4 2019</p></li><li><div><p>Sideloader</p><p>Integrate and instrument other binaries.</p></div><p>Q1 2020</p></li><li><div><p>Splashscreen</p><p>Use a splashscreen while the main content is loading.</p></div><p>Q1 2020</p></li><li><div><p>App Storage</p><p>Use a canonical location to store userdata.</p></div><p>Q2 2020</p></li><li><div><p>Native Notifications</p><p>Cross-platform notifications using polyfilled WEB API.</p></div><p>Q2 2020</p></li><li><div><p>GH Action for Building Apps</p><p>Build your Web application as a Tauri binary for MacOS, Linux and Windows</p></div><p>Q3 2020</p></li><li><div><p>VS Code Extension</p><p>Commands and validate tauri.conf.json</p></div><p>Q3 2020</p></li><li><div><p>Core Plugin System</p><p>Build reusable plugins to extend Tauri core.</p></div><p>Q3 2020</p></li><li><div><p>CLI Updater</p><p>Update core dependencies automatically from the CLI.</p></div><p>Q3 2020</p></li><li><div><p>Self Updater</p><p>Update Tauri Apps from within Tauri.</p></div><p>Q3 2020</p></li><li><div><p>Clipboard</p><p>Enable programmatic and keyboard access to clipboard.</p></div><p>Q3 2020</p></li><li><div><p>Keyboard Shortcuts</p><p>Hook and react to keypresses.</p></div><p>Q3 2020</p></li><li><div><p>Channel API</p><p>Send messages through a channel.</p></div><p>Q3 2020</p></li><li><div><p>One-Time Commands</p><p>Run a command that is no longer available after first run.</p></div><p>Q3 2020</p></li><li><div><p>WASM Bundler</p><p>Manufacture WASM bundler for use in websites.</p></div><p>Q3 2020</p></li><li><div><p>App Tray</p><p>Desktop Cross-platform Icon Tray.</p></div><p>Q3 2020</p></li><li><div><p>Webview Bindings</p><p>Use official Webview bindings.</p></div><p>Q3 2020</p></li><li><div><p>Multi Window</p><p>Run multiple window instances in Tauri.</p></div><p>Q3 2020</p></li><li><div><p>Transparent Window</p><p>Have transparent windows.</p></div><p>Q3 2020</p></li><li><div><p>Rust-based CLI</p><p>Create rust CLI with DENO bindings and binary.</p></div><p>Q3 2020</p></li><li><div><p>DENO Bindings</p><p>Use Deno to build your App's backend.</p></div><p>Q3 2020</p></li><li><div><p>Beta Release</p><p>Generally stable on Desktop, API locked down.</p></div><p>Q4 2020</p></li><li><div><p>Security Audit</p><p>3rd party security audit of core libraries.</p></div><p>Q4 2020</p></li><li><div><p>Mobile Bundler</p><p>Bundle to all major mobile device operating systems.</p></div><p>Q4 2020</p></li><li><div><p>Cross Compiler</p><p>Generate bundled binaries from select operating system environments.</p></div><p>Q4 2020</p></li><li><div><p>PureOS App Store</p><p>Verified builds for PureOS.</p></div><p>Q1 2021</p></li><li><div><p>Stable Release</p><p>Stable on On all Platforms.</p></div><p>Q1 2021</p></li><li><div><p>Other Bindings</p><p>Go, Nim, Python, C++ and other bindings are possible with the stable API.</p></div><p>Q1 2021</p></li><li><div><p>Alternative Renderer</p><p>Candidate presentation for Webview Alternatives, including GL windowing.</p></div><p>Q1 2021</p></li><li><div><p>Tauri-Frida</p><p>A decompiler and threat analyzer for Tauri Apps, using Frida.</p></div><p>Q1 2021</p></li><li><div><p>The Future</p><p>Something missing? Got a great idea? We want you to help us make it happen.</p></div><p>&amp; BEYOND</p></li></ul></div></section></main></div></div></div>]]>
            </description>
            <link>https://tauri.studio/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25185376</guid>
            <pubDate>Mon, 23 Nov 2020 10:36:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Command-line Utilities to Improve your Workflows]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25184970">thread link</a>) | @nithishr
<br/>
November 23, 2020 | https://blog.nithishr.com/6-command-line-utilities-to-improve-your-workflows | <a href="https://web.archive.org/web/*/https://blog.nithishr.com/6-command-line-utilities-to-improve-your-workflows">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1606122057930/WRgEmsDV8.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><p>We spend a lot of time as engineers on our terminals. Here is a list of 6 command-line utilities that can help you boost your productivity on the terminal. </p>
<h3 id="1-autojump-j">1. Autojump (j)</h3>
<p>Autojump is a fast way to navigate your filesystem. It keeps track of the directories that you access &amp; their usage frequency. </p>
<p><strong>Usage: </strong></p>
<ul>
<li>To navigate to a directory that contains <code>Downloads</code> from any directory in the filesystem<pre><code><span>j</span> Downloads
</code></pre></li>
</ul>
<p><a target="_blank" href="https://github.com/wting/autojump">Link</a></p>
<h3 id="2-bat">2. bat</h3>
<p>Bat is a <code>cat</code> clone with support for syntax highlighting for the commonly used programming languages &amp; markup formats.</p>
<p><strong>Usage:</strong></p>
<pre><code><span>bat</span> filename
</code></pre><p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1606077167750/-lbEqzpcQ.png?auto=format&amp;q=60" alt="bat highlighting the syntax of Python"> </p>
<p><a target="_blank" href="https://github.com/sharkdp/bat">Link</a></p>
<h3 id="3-fuzzy-finder-fzf">3. Fuzzy Finder (fzf)</h3>
<p>Fuzzy Finder is an interactive command-line tool for fuzzy search. You can use it to find the files by typing a few characters of the file with instant feedback. </p>
<p>You can also use it to search any list on the terminal such as command history, git logs, processes, etc.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1606079217983/mXFlK5pfe.gif?auto=format,compress&amp;gif-q=60" alt="Demo of fzf"></p>
<p><a target="_blank" href="https://github.com/junegunn/fzf">Link</a></p>
<h3 id="4-tldr">4. tldr</h3>
<p>Have you felt that the man pages are too verbose when you are looking for an option for a command? </p>
<p>Try <code>tldr</code> which gives you community-maintained help pages for command-line tools. </p>
<p><strong>Usage</strong></p>
<pre><code><span>tldr</span> command_or_utility
</code></pre><p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1606079807478/HgaLUvow2.png?auto=format&amp;q=60" alt="tldr for man pages"></p>
<p><a target="_blank" href="https://github.com/tldr-pages/tldr">Link</a></p>
<h3 id="5-cal">5. cal</h3>
<p><code>cal</code> shows you the calendar in your terminal. </p>
<p>For those times when you do not remember today's day or date!</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1606080750469/YqjLJJKqD.png?auto=format&amp;q=60" alt="cal showing the calendar on the terminal"></p>
<h3 id="6-sudo">6. sudo !!</h3>
<p>Did you have to run the last command as a superuser instead of your normal user? <code>sudo !!</code> can come to your rescue. It runs the last command as a superuser. </p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1606081057127/25y4wZmjn.png?auto=format&amp;q=60" alt="Example of running previous command as superuser"></p>
<p>Let me know which one you use or would use in the comments!</p>
<p>Do you have any additions to this list? Share it in the comments.</p>
</div></div></section></div>]]>
            </description>
            <link>https://blog.nithishr.com/6-command-line-utilities-to-improve-your-workflows</link>
            <guid isPermaLink="false">hacker-news-small-sites-25184970</guid>
            <pubDate>Mon, 23 Nov 2020 09:18:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Achieving exactly-once message processing with Ably]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25184774">thread link</a>) | @kiyanwang
<br/>
November 23, 2020 | https://www.ably.io/blog/achieving-exactly-once-message-processing-with-ably/ | <a href="https://web.archive.org/web/*/https://www.ably.io/blog/achieving-exactly-once-message-processing-with-ably/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<section>
<div>
<p>Exactly-once is a desirable (if not critical) message delivery guarantee and a remarkably complex engineering challenge to solve. In this blog post, we will look at what exactly-once means in the context of distributed pub/sub systems, and the exactly-once guarantees that the <a href="https://www.ably.io/">Ably</a> realtime pub/sub messaging platform provides. Ably often acts as the broker in data streaming pipelines: publishers send messages to our platform, and we deliver these messages to subscribers. As a broker, Ably provides regional &amp; global fault tolerance, which ensures message availability and survivability. We also offer a set of capabilities via SDKs that enable clients to use idempotent publishing, and recover in the event of a failure while resuming precisely where they left off, with no lost or duplicate messages.</p>
<figure><img src="https://files.ably.io/ghost/prod/2020/11/4-pillars-exactly-once-semantics-cover.png"></figure><h2 id="exactly-once-delivery-is-one-of-the-hardest-engineering-challenges">Exactly-once delivery is one of the hardest engineering challenges<br>
</h2>
<p>In the context of distributed <a href="https://www.ably.io/topic/pub-sub">pub/sub</a> systems, exactly-once is a popular concept and a desirable, if not critical, system property. It also leads to confusion and diverging opinions within the development community. On the one hand, some argue that <a href="https://bravenewgeek.com/you-cannot-have-exactly-once-delivery/">exactly-once is simply unachievable.</a> On the other hand, there are systems such as <a href="https://kafka.apache.org/documentation/#semantics">Kafka that claim to support exactly-once semantics</a>. </p>
<p>We believe that a lot of the confusion around the concept has to do with the fact that there's no clear definition of what exactly-once actually means. It's arguably impossible to come up with a definition to satisfy everyone and every use case. That's because exactly-once can mean different things for different systems and different use cases. Regardless of how you look at it, though, exactly-once is, without a doubt, a distinctively complex engineering challenge. </p>
<p>Let’s now define what exactly-once means for Ably in particular. In our case, exactly-once is a guarantee that once acknowledged, a message published to Ably is <strong>delivered</strong> to a consumer precisely once, even in the context of individual system components failing. Note that most often, Ably is used to deliver messages in real time directly to end-user devices.</p>
<p>It’s crucial to mention that exactly-once is a system-wide property, and you only achieve it if all the constituent components play their part. This doesn’t mean that all the components must display exactly-once characteristics. For example, in our case, you can have a publisher that displays at-least-once behaviour. However, Ably provides an idempotent interface, which cancels out the fact that the producer may occasionally publish messages more than once. As long as at the other end of the pub/sub pipeline each message is delivered to subscribers precisely once, exactly-once behaviour is achieved as a whole.</p>
<h3 id="types-of-messaging-semantics">Types of messaging semantics<br>
</h3>
<p>Before we dive deeper into exactly-once delivery, let’s review the main types of messaging semantics. When a system is fully operational and working as intended, exactly-once delivery is the behaviour you generally expect. However, we must also consider how faults in the pub/sub system or, indeed, clients affect this behaviour. While most components fail independently in a distributed pub/sub system, without directly impacting other components, the overall quality of service can be affected. Depending on how the system behaves when failures do occur, you get several different types of messaging semantics:</p>
<ul>
<li>
<strong>At-most-once semantics</strong>. The easiest type of semantics to achieve, from an engineering complexity perspective, since it can be done in a fire-and-forget way. There's rarely any need for the components of the system to be stateful. While it's the easiest to achieve, at-most-once is also the least desirable type of messaging semantics. It provides no absolute message delivery guarantees since each message is delivered once (best case scenario) or not at all.</li>
<li>
<strong>At-least-once semantics. </strong>This is an improvement on at-most-once semantics. There might be multiple attempts at delivering a message, so at least one attempt is successful. In other words, there's a chance messages may be duplicated, but they can't be lost. While not ideal as a system-wide characteristic, at-least-once semantics are good enough for use cases where duplication of data is of little concern, or scenarios where deduplication is possible on the consumer side.</li>
<li>
<strong>Exactly-once semantics</strong>. The ultimate message delivery guarantee and the optimal choice in terms of data integrity. As its name suggests, exactly-once semantics means that each message is delivered precisely once. The message can neither be lost nor delivered twice (or more times). Exactly-once is by far the most dependable message delivery guarantee. It’s also the hardest to achieve.</li>
</ul>
<figure><img src="https://files.ably.io/ghost/prod/2020/11/exactly-once-semantics-messaging-semantics-overview.gif" alt="Overview of message delivery semantics: at-most-once delivery, at-least-once delivery, exactly-once delivery."><figcaption>High-level overview of message delivery semantics</figcaption></figure><p>What most distributed pub/sub systems can genuinely guarantee is <strong>mostly-once </strong>delivery. This means that when the system is functioning as intended, messages are delivered exactly once. However, when failures are involved, there’s always a chance some messages will be delivered either at-most-once or at-least-once.</p>
<h3 id="failures-that-prevent-exactly-once-delivery">Failures that prevent exactly-once delivery<br>
</h3>
<p>To demonstrate just how hard it is for distributed <a href="https://www.ably.io/topic/pub-sub">pub/sub</a> systems to achieve exactly-once semantics, we must talk about failures—specifically, components that can fail and how these failures can be mitigated.<br></p>
<p><strong>Publisher failure</strong></p>
<p>When a publisher fails, some sort of recovery process takes place. Depending on its design, after recovery, the publisher may reattempt to publish a message that has already been sent to and acknowledged by the broker. In such an event, the publisher failure causes at-least-once behaviour. Another scenario is that the publisher’s recovery procedure fails to realise that the publish attempt failed, which leads to at-most-once behaviour. </p>
<p>A strategy often used after a publish failure is to retry publishing the same message a fixed number of times. This is a pragmatic approach, but unsatisfactory in the context of exactly-once. Imagine that the publisher recovers and unsuccessfully tries to republish the same message five times, and then gives up. Practically none of the three semantics is achieved. To mitigate publisher failures Ably supports <a href="https://www.ably.io/topic/idempotency">idempotent publishing</a>, which ensures that regardless of how many times the same message is published to Ably, it will be delivered to subscribers exactly-once. <br></p>
<p><strong>Broker failure</strong></p>
<p>A broker failure has the potential to lead to all sorts of issues, including data loss. That’s why it’s recommended to design your system around the idea of mitigating or preventing loss of data. From a producer perspective, this could mean having the ability to publish messages at-least-once, so they can be resent to the broker if needed. </p>
<p>From a broker perspective (Ably included), let’s start by reviewing what a message ACK means. Obviously, it’s an acknowledgment that a published message has been received. Additionally, it should also imply that no subsequent failure will result in that message not being delivered to subscribers. In other words, it should be an acknowledgment that the broker provides sufficient redundancy to ensure continuity of service and onwards processing, even in the context of multiple infrastructure failures. Of course, nothing can be done to prevent or mitigate certain types of critical failures. When that happens, the sensible thing for the broker to do is to respond with a failure response (with HTTP, this is typically a 5xx status code), indicating clearly to the producer that the publish attempt was unsuccessful. </p>
<p><strong>Subscriber failure</strong></p>
<p>The most common subscriber failure that prevents exactly-once delivery involves short disconnections. For example, a client app on a mobile device will disconnect and quickly reconnect when the user switches from a mobile data network to a Wi-Fi network or goes through a tunnel. To counter this scenario and ensure exactly-once behaviour, the stream of messages must resume precisely where it left off when the subscriber recovers. For this to be possible, the connection state must be persisted and resynced when the subscriber reconnects.</p>
<p>If the broker is the one keeping track of the last message sent, you are unlikely to provide exactly-once semantics. That’s because a broker might send a message, and the subscriber might successfully receive it and then disconnect before sending an ACK to the broker. In such a case, once the subscriber reconnects, the broker will resend the respective message (at-least-once semantics) since it has no way of knowing that the subscriber had received it before disconnecting.</p>
<p>To ensure exactly-once behaviour, the responsibility of keeping track of the last message received should sit with the subscriber - something we also do at Ably, via serial numbers. This way, when the subscriber reconnects, it notifies the broker of the last message it has received so that the stream can be accurately resumed from a point in time.</p>
<h3 id="exactly-once-semantics-use-cases">Exactly-once semantics use cases</h3>
<p>In the world of distributed pub/sub systems, exactly-once semantics has been and continues to be extremely hard to achieve. Equally, almost everywhere you look in software development, exactly-once is a highly desirable system-wide property, if not an essential one. For example, exactly-once is crucial for most transactional messaging use cases. At its core, a transactional message is triggered by a consumer action, and it usually includes necessary or high-priority info, e.g., a bank balance inquiry or an order confirmation. </p>
<p>Ordered operations represent another use case where exactly-once is fundamental. Let’s say you want to use <a href="https://www.ably.io/blog/message-delta-compression/">delta compression</a> to only stream changes from the previous message to subscribers each time there’s an update. To achieve this, you need to use a transport that ensures data integrity through guaranteed message ordering and exactly-once semantics.</p>
<p>If not crucial, exactly-once is at least highly desirable, because it improves overall system predictability and provides better experiences to users in general. For example, …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ably.io/blog/achieving-exactly-once-message-processing-with-ably/">https://www.ably.io/blog/achieving-exactly-once-message-processing-with-ably/</a></em></p>]]>
            </description>
            <link>https://www.ably.io/blog/achieving-exactly-once-message-processing-with-ably/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25184774</guid>
            <pubDate>Mon, 23 Nov 2020 08:44:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Instructions for the Age of Emergency (2018)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25184662">thread link</a>) | @klunger
<br/>
November 23, 2020 | https://monicacatherine.com/2018/02/08/instructions-for-the-age-of-emergency/ | <a href="https://web.archive.org/web/*/https://monicacatherine.com/2018/02/08/instructions-for-the-age-of-emergency/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-3572">
			
			<p><small><span><b>Posted:</b> February 8, 2018</span>  <span>|</span> <span><b>Filed under:</b> <a href="https://monicacatherine.com/category/uncategorized/" rel="category tag">Uncategorized</a></span> <span></span> <span></span> <span>|</span></small></p><p><img data-attachment-id="3573" data-permalink="https://monicacatherine.com/2018/02/08/instructions-for-the-age-of-emergency/img_5890-1/" data-orig-file="https://monicacatherine.files.wordpress.com/2018/02/img_5890-1.jpg" data-orig-size="4032,3021" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 6s&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1517591142&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.15&quot;,&quot;iso&quot;:&quot;320&quot;,&quot;shutter_speed&quot;:&quot;0.066666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="IMG_5890 (1)" data-image-description="" data-medium-file="https://monicacatherine.files.wordpress.com/2018/02/img_5890-1.jpg?w=300" data-large-file="https://monicacatherine.files.wordpress.com/2018/02/img_5890-1.jpg?w=590" src="https://monicacatherine.files.wordpress.com/2018/02/img_5890-1.jpg?w=590" alt="IMG_5890 (1)" srcset="https://monicacatherine.files.wordpress.com/2018/02/img_5890-1.jpg?w=590 590w, https://monicacatherine.files.wordpress.com/2018/02/img_5890-1.jpg?w=1180 1180w, https://monicacatherine.files.wordpress.com/2018/02/img_5890-1.jpg?w=150 150w, https://monicacatherine.files.wordpress.com/2018/02/img_5890-1.jpg?w=300 300w, https://monicacatherine.files.wordpress.com/2018/02/img_5890-1.jpg?w=768 768w, https://monicacatherine.files.wordpress.com/2018/02/img_5890-1.jpg?w=1024 1024w" sizes="(max-width: 590px) 100vw, 590px"></p>
<p>Halbert W. Hall Speaker’s Series on Science Fiction and Fantasy,&nbsp;Texas A&amp;M University</p>
<p>February 2, 2018</p>
<p><a href="https://drive.google.com/open?id=1vZQXkxJ9FVwCmhHZTBGkuxMHGF8hoWK_">Full Audio</a></p>
<p>~</p>
<p>Thank you so much to Texas A&amp;M for hosting me, and especially to the Science Fiction Archivist, Jeremy Brett, who invited me and orchestrated everything. He’s been a supporter of my work for years, and I’m so delighted to finally meet him, and to have the chance to address all of you. I’d also like to thank TAMU Libraries, the Glasscock Center for Humanities Research and its Science Fiction Studies Working Group, the Department of English, the Department of International Studies, and the Department of Visualization. I’m so honored by such an intersectional effort to bring me here. So thank you.</p>
<p>As Jeremy said, I write a lot of things, but when people ask me what I am, the first thing I say is that I’m a science fiction writer. I gave Jeremy a name for this talk before I wrote any of it, because I was still finishing my next novel. It’s called <em>The Actual Star. </em>It’s taken me six years to write. My agent is reading it as we speak. It jumps back and forth from the distant past, during the collapse of ancient Maya civilization; to the present, specifically the year 2012; to the far future, when a new global religion has brought lasting peace to humankind. So I spent a lot of the past year in the year 3012, in my head, imagining what the world will look like a thousand years from now. I want to talk to you about it because, like all science fiction, even though it’s set in the future, it’s a response to our present moment. My talk is called “Instructions for the Age of Emergency,” which is the time period we’re living in right now. In the far future, there are entire fields of study devoted to it, and to the people who lived in it, and what we must have been thinking.</p>
<p>During the last year, I locked myself out of social media for months at a time. I had to concentrate on work and, to be honest, protect my mental health after the election. I only read <em>The Washington Post</em> on my phone in bed in the morning—I still do—and that was enough. Everything I read, I asked myself, “How did we get here? What are the root causes? How can things be different?” And then I would try to answer those questions in the day’s writing.</p>
<p>The possibility I wanted to explore is that things didn’t start going astray after 9/11, or because of Nixon, or with the Industrial Revolution, or even with the invention of race that enabled the Native American genocide and the Trans-Atlantic slave trade. I wanted to explore the possibility that humanity lost its way in the Neolithic Era. We regard the Neolithic as the beginning of history, and if we mean written history, maybe. But humans lived for two hundred thousand years before that—before the fall of Troy, before permanent settlements, before the invention of surplus and property and money and agriculture. All of that is only about twelve thousand years old, or, 6% of our history. The fact that we don’t have newspapers from the other 94% of our history doesn’t mean it didn’t happen. It also doesn’t make it any less important when thinking about the range of human possibility, and the range of possible human futures.</p>
<p>Much of science fiction deals with imagining dystopia. I’ll talk about why that is later, but I strongly believe that, at this moment in time, we need to remember that one of the highest callings of science fiction is imagining utopia. I don’t mean starry-eyed visions of a fairyland that drops out of the sky. I also don’t mean a static society built on some fundamental irony like panopticon or the suppression of free will. I mean honest, earnest engagement with the question of what a better world looks like.</p>
<p>In the <em>Earthseed </em>trilogy, Octavia Butler’s characters go through hell in their struggle to establish a utopian community. In the <em>Mars </em>trilogy, Kim Stanley Robinson’s characters go through several revolutions and constitutions in building a better world than the one they came from (Earth). Ursula K. Le Guin—who died while I was composing this talk—is the leader of us all in this regard. Her work engages the idea of realistic utopia over and over again—through Hain, Anarres, Gethen, Earthsea, and of course, Omelas.</p>
<p>My novel <em>The Actual Star </em>is an attempt to work in that same tradition. The distant past—the collapse of Maya civilization—takes place amid the failure of monarchy. The present—our age, the “Age of Emergency”—takes place amid the failure of capitalism. So, what does the year 3012 look like? I’ll first describe it, and then describe how I got there, extrapolating from this moment in time.</p>
<p>~</p>
<p>In 3012, the world operates by the twin philosophy of accumulation and dispersion. Put as simply as possible, The Law of Accumulation states that accumulation of any human property ultimately leads to human suffering. For example, accumulation of capital leads to inequality. Accumulation of family ties leads to feuds. Accumulation of feuds leads to war. Accumulation of population leads to disease. Accumulation of territory and power leads to war. Not necessarily at first, or even for centuries—but eventually, always.</p>
<p>The antidote is the Law of Dispersion. Put as simply as possible, it states that lasting peace can only result from the constant temporal and spatial dispersion of all human properties. In other words, we build a society that flows with, not against, the entropic nature of the universe.</p>
<p>In 3012, there are no borders. There are no nations. There are no families, aside from the human family. We call every other person “carnala,” a Mexican Spanish term meaning “a blood relation.” The average life expectancy is 130 years. The world population is steady at one billion. We roam the earth as permanent nomads, and, by common agreement, only own as much as we can carry—this is why the system is called Laviaja, a feminized form of “El Viaje,” Spanish for “the journey.” Those of us who cannot move or walk are accommodated so radically by mutual aid, artificial intelligence, and augmented reality that the very concept of disability no longer exists. In fact, many of us <em>choose </em>to have what we think of as disabilities, and call them “gifts,” because they are ways of creating community.</p>
<p>We eat primarily by foraging, a practice now aided by advanced artificial intelligence and augmented reality. No one eats animals, since we began learning their languages. Where there isn’t much to be foraged, our photosynthetic skin takes over. When we want home-cooked food, we go to a wayhouse. Wayhouses are places where we can rest for up to a period of nine days, in exchange for a few hours of work a day. We gather for two daily meals plus, in many areas of the world, teatime. Agribots—farming robots—do the majority of farming and gardening, strictly on a subsistence basis, near wayhouses. In other words, no one goes hungry. Food security is simply not an issue. This is because, at a certain point, around the 23<sup>rd</sup> century, all technology was built to serve humankind, not profit.</p>
<p>None of us stay in the same place for more than nine days. None of us even stay with the same people for more than nine days. But whomever we lose, we regain. With whomever we meet on the road, we fall into any number of familiar roles—sister and sister, lover and lover, mother and child, aunt and niece, elder and youth—and one of the greatest joys of life is that dance of discovery, of what each new person is to the other. If we give birth, we gladly give up our baby within nine days; assured that our child will come back to us again and again in the form of other children, throughout our lives.</p>
<p>There is no space travel, since space programs were dependent on capitalism. There are aliens, but they’re so far away that we have to wait a few hundred years every time we want to say anything, so it doesn’t affect our lives very much. There are no weapons; the very idea is strange. Crime is very rare; when it does happen, in the worst cases, the crime is made public and the perpetrator is marked for others to see and avoid if they wish, but the criminal is still allowed free movement in the world. Their exile is social.</p>
<p>There’s no currency or system of money; there’s a worldwide, perpetual gift exchange. Objects have no value beyond their practical use; a plastic bowl is as good as a porcelain bowl. There’s no manufacturing because there’s no need for material goods. Everything is used on a recycled basis.</p>
<p>There are approximately fifteen hundred genders. Anyone who wants to bear a child can do so. No pregnancy is unplanned. There’s no correlation between genitalia and gender. Some of the genders are in fact the descendants of nationalist and ethnic identities, as there have long ceased to be nations or ethnic groups in any meaningful way, given the Law of Dispersion. Identity is completely voluntary and mutable.</p>
<p>The system of government, such as it is, is a worldwide sortition democracy, which is actually a very old form of democracy. A legislature is randomly selected from a pool of all available citizens, from the age of seven years old. This legislature is in session twenty-four hours a day, its members refreshed every hour, on the hour, mostly just to re-ratify a basic Bill of Rights, but also to take up whatever special questions apply on the global scale. As a citizen, you’re called to serve for about one hour every year or two. For local matters, moving clusters of people are governed by algorithms called “umbrellas” that take into account each person’s needs and preferences. An umbrella may govern a single wayhouse, or an area of a hundred square kilometers, depending on the number of people present, which is always changing.</p>
<p>A person can opt out of this system. They aren’t punished. They aren’t banned. They’re never refused food or shelter, care or companionship, wherever they go. The highest law is the rule of the road, which is radical …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://monicacatherine.com/2018/02/08/instructions-for-the-age-of-emergency/">https://monicacatherine.com/2018/02/08/instructions-for-the-age-of-emergency/</a></em></p>]]>
            </description>
            <link>https://monicacatherine.com/2018/02/08/instructions-for-the-age-of-emergency/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25184662</guid>
            <pubDate>Mon, 23 Nov 2020 08:25:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facebook Condemned for Providing Platform to Neo-Nazi Network]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25184311">thread link</a>) | @wikus
<br/>
November 22, 2020 | https://hfet.org/facebook-condemned-for-providing-platform-to-neo-nazi-network/ | <a href="https://web.archive.org/web/*/https://hfet.org/facebook-condemned-for-providing-platform-to-neo-nazi-network/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

			
	<main id="main" role="main">

		
<article id="post-1222">

	<!-- .entry-header -->

	
		<figure>
			<img width="1080" height="540" src="https://hfet.org/wp-content/uploads/2020/11/pexels-brett-jordan-5426402-e1606077190468-1080x540.jpg" alt="" loading="lazy" srcset="https://hfet.org/wp-content/uploads/2020/11/pexels-brett-jordan-5426402-e1606077190468-1080x540.jpg 1080w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-jordan-5426402-e1606077190468-20x11.jpg 20w" sizes="(max-width: 1080px) 100vw, 1080px">		</figure>

		
	
<div>

	<h3>Facebook is facing a new wave of criticism for providing a platform for a white supremacist network with over 80,000 online followers.</h3>
<ul>
<li>Facebook only removed these pages after being contacted by large media organisation the <em>Observer</em>. The Center for Countering Digital Hate claim they were made aware of this two years ago.</li>
</ul>
<p>The Guardian reports this Neo-Nazi network also has ties to the UK far right, <a href="https://www.theguardian.com/technology/2020/nov/22/facebook-condemned-for-hosting-neo-nazi-network-with-uk-links" target="_blank" rel="noopener noreferrer">including a student facing terrorism charges</a>. Imran Ahmed, CEO of the Center for Countering Digital Hate, said:</p>
<blockquote>
<p>&nbsp;“Facebook’s leadership endangered public safety by letting Neo-Nazis finance their activities through Facebook and Instagram. Facebook was first told about this problem two years ago and failed to act.”</p>
</blockquote>
<p><img loading="lazy" src="https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-1024x683.jpg" alt="" width="800" height="534" srcset="https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-1024x683.jpg 1024w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-300x200.jpg 300w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-768x512.jpg 768w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-1536x1024.jpg 1536w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-2048x1365.jpg 2048w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-20x13.jpg 20w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-36x24.jpg 36w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-48x32.jpg 48w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-272x182.jpg 272w" sizes="(max-width: 800px) 100vw, 800px"></p>
<p>After the <em>Observer</em> contacted Facebook, they began taking down the material with a Facebook spokesperson stating:</p>
<blockquote><p>“We have removed the content which violates our policies prohibiting dangerous organisations. We regularly work to improve our technology to find and remove this content faster, and, while there is more work to do, we are making progress. We’ve banned over 250 white supremacist organisations from Facebook and Instagram.”</p></blockquote>
<h4>Read more of the <a href="https://www.theguardian.com/technology/2020/nov/22/facebook-condemned-for-hosting-neo-nazi-network-with-uk-links" target="_blank" rel="noopener noreferrer">full report on The Guardian</a>.</h4>
<hr>
<p><strong>Author’s Note: </strong>I highly recommend reading <a href="https://hfet.org/opinion-grading-facebooks-homework/"><strong>Grading Facebook’s Homework</strong></a>, which is an opinion piece on Facebook’s response to criticism.</p>
<p><a href="https://hfet.org/feed/"><img src="https://hfet.org/wp-content/uploads/2020/11/rss_button_hfet-1.png" alt="" width="219" height="30"></a><a href="https://hfet.org/support/"><img src="https://hfet.org/wp-content/uploads/2020/11/support_button_hfet.png" alt="" width="165" height="30"></a></p>
    <div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img width="100" height="100" src="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg" alt="" loading="lazy" srcset="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg 150w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-300x300.jpg 300w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-20x20.jpg 20w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-36x36.jpg 36w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-48x48.jpg 48w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-24x24.jpg 24w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-96x96.jpg 96w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel.jpg 640w" sizes="(max-width: 100px) 100vw, 100px"></p><div><p>I’m an AI &amp; Robotics Student interested in FOSS, Tech Sustainability and Data Rights. I’m also the founder of Humans For Ethical Technology.</p></div></div>	
</div><!-- .entry-content -->


</article>

	</main><!-- #main -->

	


	</div></div>]]>
            </description>
            <link>https://hfet.org/facebook-condemned-for-providing-platform-to-neo-nazi-network/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25184311</guid>
            <pubDate>Mon, 23 Nov 2020 07:22:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn Elixir by making 5 small games]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25183869">thread link</a>) | @AlchemistCamp
<br/>
November 22, 2020 | https://alchemist.camp/little-potions/hello-world | <a href="https://web.archive.org/web/*/https://alchemist.camp/little-potions/hello-world">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="alert"><p>You don't have access to that page. Do you have a <a href="https://alchemist.camp/little-potions/redeem">license to redeem</a>?</p></div></div>]]>
            </description>
            <link>https://alchemist.camp/little-potions/hello-world</link>
            <guid isPermaLink="false">hacker-news-small-sites-25183869</guid>
            <pubDate>Mon, 23 Nov 2020 05:30:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data structures: The linear non-primitives]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25183818">thread link</a>) | @Marv101
<br/>
November 22, 2020 | https://thegreencodes.com/data-structures-the-linear-non-primitives | <a href="https://web.archive.org/web/*/https://thegreencodes.com/data-structures-the-linear-non-primitives">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>On our first set of data structures, we get into the definition and scope of non-primitive structures. Have a look at the previous read on  <a target="_blank" href="https://thegreencodes.com/the-power-of-data-structures">The Power of Data structures</a> in case you feel a little lost. Right off the batt, we define what it means to be a non-primitive set, and how this can be further broken down.</p>
<p>Let's get right into it. A non-primitive structure is what happens when you combine two or more primitives. What we mean is simple. A <code>char</code> and  <code>int</code> , for instance,  are primitives. The simplest representations of data. </p>
<p>Broadly speaking, linear non-primitives can be grouped further as below:</p>
<h2 id="linear-non-primitives">Linear non-primitives</h2>
<ul>
<li>Stacks</li>
<li>Queues</li>
<li>LInked lists</li>
<li>Arrays</li>
</ul>
<p>Here, as stated before, data is sequential - one after another. Some of these structures might <a target="_blank" href="https://thegreencodes.com/memory-management-deep-and-shallow-copying">ring a bell</a>, stackify, is that you?. </p>
<h3 id="arrays">Arrays</h3>
<p>These are what we call stores of homogenous (meaning similar) data. So one might have an array like this:</p>
<pre><code><span>my_array</span> = [<span>1</span>,<span>2</span>,<span>3</span>,<span>4</span>,<span>5</span>,<span>6</span>,<span>7</span>,<span>8</span>,<span>9</span>] 

<span>vowels</span> = [<span>' a'</span>, <span>'e'</span>, <span>'i'</span> , <span>'o'</span>, <span>'u'</span> ] 
</code></pre><p>Note how <code>my_array</code> has only integers while <em>vowels</em> has <em>char</em>. In both instances, our array has a collection of primitives - <strong>one type of primitive per array</strong>. </p>
<p>Arrays are of a fixed size. Once declared, the computer knows the amount of memory reserved for items to be stored there.  You might ask:</p>
<p><em>"But what if the type of data I have changes in size greater than the array?" </em></p>
<p>Well, you might need to consider a different type of structure to store this data. 
Use arrays, for instance, to store months of the year. We will not be changing this count anytime.</p>
<p>Above declared, the sizes of the arrays are inferred. Meaning the types, since not defined per se, are  'figured out' based on the values and how we use them.</p>
<p>We might as well have this:</p>
<p>For python.</p>
<pre><code>
<span>import</span> array

count_down = array.array(<span>'i'</span>, [<span>5</span>,<span>4</span>,<span>3</span>,<span>2</span>,<span>1</span>])


</code></pre>
<p>Types may go on as:</p>
<p><code>c</code> for <em>char</em>
<code>f</code> for <em>float</em>
<code>d</code> for <em>double</em>
<code>u</code> for <em>unicode</em> and so forth.</p>
<p>Have a look at the <a target="_blank" href="https://docs.python.org/3/library/array.html?highlight=arrays">documentation</a> for more insight into this. AS well, take note that the <code>array module</code> has different functions to enable array manipulation.</p>
<p>Rust:</p>
<pre><code>
<span>let</span> count_down: [<span>i32</span>; <span>5</span>] = [<span>5</span>,<span>4</span>,<span>3</span>,<span>2</span>,<span>1</span>];


</code></pre>
<blockquote>
<p>Important pointer:
    Python lists and arrays are not the same!</p>
</blockquote>
<p>Operations on an array will be based on the <code>index</code> of the array element, with indexing starting from <em>0</em>. Hence, the first item, in either case, would be:</p>
<pre><code><span>count_down</span><span>[0]</span>
</code></pre><p>The result from the above is 5 (the semi-colon has been left out for brevity but should be used based on the language you are using).</p>
<p>Let's take a look at another structure that looks similar, but is not the same - <strong>Linked lists</strong>.</p>
<h3 id="linked-lists">Linked lists</h3>
<p>Unlike arrays, linked lists store data in a non-contiguous form. This implies one piece of data is not placed side by side to the other as: <code>[1,2,3,4,5]</code>, rather it is stored in form of nodes with pointers to the next as so:</p>
<pre><code>
<span>[data1, pointer_to_data2]</span> ...  <span>[data1, pointer_to_data3]</span> ... <span>and</span> <span>so</span> <span>on</span>
</code></pre><p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605257211148/M0hJg9a9v.png?auto=format&amp;q=60" alt="linked_list.png"></p>
<p>The last item in our linked list, since there is no pointer to the next, would have <code>null</code>. </p>
<p>As well, linked lists are dynamic-  their size is not fixed at initialization. </p>
<p>Linked lists will be further broken to:</p>
<p>a) Singular linked lists (used in the elaboration of linked lists above)</p>
<p>b) Circular linked lists</p>
<p>c) Doubly linked lists</p>
<h4 id="circular-linked-lists">Circular linked lists</h4>
<p>These have three items in a node: the previous data, the data, and finally, the next data in the sequence.</p>
<pre><code><span>[null, data1, pointer_to_data2]</span> ...  <span>[pointer_to_data_1 ,data1, pointer_to_data3]</span>
</code></pre><p>The first item (the head), has a <code>null</code> as the previous pointer while the last node has <code>null</code> on the next pointer.</p>
<h4 id="doubly-linked-lists">Doubly linked lists</h4>
<p>Similar to circular linked lists, these have two pointers as well. The only difference would be the last node, instead of a <code>null</code>, has a pointer back to the first item in the list. 1 + 1 = circular.</p>
<p>In most of what we implement through code, we have implementations of linked lists. You will hardly get yourself doing this manually, but understanding that some of the things we call 'mutable arrays ' are actually implementations or wrappers around more complex structures.</p>
<p><strong>Example:</strong>
If navigating through my directory, my computer needs to know where I am, where I'm from, and possibly have the correct link/structure to the nested directory I'm navigating to. So to the top-level directory, I cannot go any higher, no previous node. Likewise to the last directory or file, there is no 'next' option.</p>
<p>Till now, we have come to understand the importance of data structures, the groups they have been placed into, and we have an idea of what some of the linear data structures involved. We could go on and on on the details of each, but that is a tale for another day. A breather for us both at this point.  Go read something non-algorithm-like for a moment. We'll still meet here, same time,  same drive. </p>
</div></div>]]>
            </description>
            <link>https://thegreencodes.com/data-structures-the-linear-non-primitives</link>
            <guid isPermaLink="false">hacker-news-small-sites-25183818</guid>
            <pubDate>Mon, 23 Nov 2020 05:17:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Platforms to create a landing page for your business]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25183182">thread link</a>) | @startupcheckr
<br/>
November 22, 2020 | https://www.startupcheckr.com/lead-capture-landing-pages | <a href="https://web.archive.org/web/*/https://www.startupcheckr.com/lead-capture-landing-pages">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.startupcheckr.com/lead-capture-landing-pages</link>
            <guid isPermaLink="false">hacker-news-small-sites-25183182</guid>
            <pubDate>Mon, 23 Nov 2020 02:56:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Who Plays the Stradivarius in Interstellar Space?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25183046">thread link</a>) | @paulorlando
<br/>
November 22, 2020 | https://unintendedconsequenc.es/who-plays-the-stradivarius-in-interstellar-space/ | <a href="https://web.archive.org/web/*/https://unintendedconsequenc.es/who-plays-the-stradivarius-in-interstellar-space/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-947">
		<!-- .entry-header -->

	
	<div>
		<p>This is a piece about the loss of skills — even ones that are marks of great beauty and mastery — due to a change in environment.</p>
<p>It’s an extreme example but a fun one to think through: who would play a Stradivarius violin in interstellar space?</p>
<p>As a way to think through an extreme environmental (not meaning climate here) change, I make the assumption that in coming centuries, whether one, five, or 10, humans will become an interstellar or extrasolar species. That is, some part of humanity will cease living in this solar system, and will instead live on other planets, space ships, or other artificial homes. <strong>I count that assumption as the less interesting part of this post and instead focus on the unintended consequences caused by a dramatic change in environment.</strong></p>
<p>Let’s think through what happens to a specific type of human mastery (and by extension, a framework to apply to many others) as humans make extreme choices (like leaving earth).</p>
<p><em>Q: Who will play the Stradivarius in interstellar space or on extrasolar planets? A: No one. Longer answer below.</em> <span id="more-947"></span></p>
<p>Today, on earth, many people achieve mastery in some skill.</p>
<p>We can include “common” skills such as learning your native language to fluency and skills that are innate, like learning to walk. The rarer skills I consider here require more concerted effort to acquire.</p>
<p>Types of skills in demand are plentiful but change over time. Some skills used to be mainstream but are now niche or largely lost except in small isolated groups, such as navigation by stars, foraging, or making clothing from scratch. Bringing those skills back to an <a href="https://unintendedconsequenc.es/acquiring-ignorance/">ignorant</a> larger population would not make sense today. Some skills are preserved by small niches of people within families or initiates (such as Chinese <a href="https://www.youtube.com/watch?v=KwfGdJIzYZs">“face changing” or bian lian</a>). Some are preserved widely by those who opt in by putting in the work, such as chess, forms of painting and ceramics, and musical performance.</p>
<p><strong>For some of the skills with modern masters, leaving earth will mean that future humans will neither preserve those skills, nor be able to acquire them even if they wanted to.</strong></p>
<p>I chose music because it is an enduring human behavior, unlikely to disappear. I chose Stradivarius violins because they represent mastery in physical instrument construction and rarity.</p>
<p>With only 650 instruments remaining (around 500 violins) and <a href="http://www.stradivarius.org/price/">often sold</a> for prices in the millions, I make the assumption that people who typically play a Stradivarius violin are violin masters whether or not they own the instrument themselves.</p>
<p>Here are examples related to the acquisition and maintenance of skill mastery, as demonstrated on a Stradivarius. In interstellar space.</p>

<p>Acquiring mastery in an uncommon skill takes uncommon effort.</p>
<p>It takes so much effort that acquiring an uncommon skill often also requires family and economic support. A small percentage of those who play the violin will pursue the instrument for over a decade of focused study and practice to have a chance to attain a level of mastery.</p>
<p>Those future interstellar humans’ new environment may not allow for them to put in that uncommon effort. Or, just as dangerous, where today there is a community of masters to practice and play with, in the future interstellar state, there may be so few masters that a string quartet is never possible. Less humans to practice and play with is probably assured.</p>

<p>A <a href="https://infogalactic.com/info/The_Dark_Forest">ravine-like</a> global crash that eliminates all violin players, teachers, and even knowledge of classical music is a possibility. What happens when there is no place to which the players can escape, survive, and continue until the situation improves? The ravine impacts violinists regardless of location.</p>
<p>Without a continual string of teachers and students, mastery becomes mystery and impossible to acquire. With effort put on making humans interstellar, will there be energy left for mastery of the violin?</p>

<p>Life in interstellar environments may not allow people to maintain an extreme practice regimen or to build excellent finger dexterity. There’s just no excess capacity to do so. They could in theory acquire the skills but never have time or physical capability.</p>

<p><a href="https://en.wikipedia.org/wiki/Baumol%27s_cost_disease">Baumol’s Cost Disease</a> explains why certain types of work become more expensive over time. “<a href="https://web.archive.org/web/20110724151936/http://publishing.eur.nl/ir/repub/asset/782/TOWSE%20EBOOK_pages0103-0113.pdf">It takes four musicians as much playing time to perform a Beethoven string quartet today as it did in 1800</a>.” That’s without considering the amount of time to acquire mastery in playing the instruments.</p>
<p>In an interstellar society, while people may have excess free time, learning to play with mastery excludes people from other, more productive activities. Spending years to become a violinist has an opportunity cost that could be more extreme than today. Longer lifespans might shift that somewhat.</p>

<p>It’s possible that skill acquisition advances beyond current imagination make it possible for novices to become masters overnight. If that happens and future humans value violin mastery, then perhaps it is more likely to see violin masters in the future, whether in interstellar environments or earth.</p>

<p>It will certainly be possible to build a robot with equal or better manual dexterity to a human. So in the future, even if there is a ravine, perhaps the robots will be preferred as violinists and will play every Strad. Why risk the instruments in human hands?</p>

<p>Why listen to live performances if, at least for classical music, there are no masters around to play live or they are worse than high-quality immersive recordings (or robots)?</p>
<p>It’s possible that future violinists play mostly for themselves.</p>

<p>Music has a shelf life. It’s long for some genres and pieces and short for others. The status quo of the classical repertoire can only be preserved for so long.</p>

<p>Consider what happened to music in the 20th century. The development of good quality microphones and electronic effects led to many new forms of music including the broad types of rock, disco, and rap. Those musical genres were created in part when musicians learned how to apply new technology. The same thing will happen again, as musicians (human or otherwise) apply music technology in new ways.</p>
<p>It’s possible that classical music will no longer be all that good in comparison to future music. Classical music’s popularity has been falling for the past 100 years since the genre stopped being pop music.</p>

<p>It’s worth considering that the original Stradivarius violins will eventually be <a href="https://www.nytimes.com/2019/01/17/arts/music/stradivarius-sound-bank-recording-cremona.html">too fragile to play</a>. Cremona, Italy (where Stradivari worked) has been recording at high-quality the sound of each potential note of its Stradivarius violins in order to preserve that sound for posterity. Can anyone really expect to play a 1,000 year old violin?</p>

<p>Future humans may prevent Stradivarius violins and many other other examples of earth’s artistic mastery from leaving earth. Then again, future humans may want a certain number of Strads to leave as a hedge against future destruction.</p>

<p>Humans are not objective in their appraisal of violins. A double-blind <a href="https://www.pnas.org/content/114/21/5395">study of violinists</a> (they wore goggles) playing modern and Stradivarius violins challenges the belief that Stradivarius is the best. The Strads are often valued in the millions because of their history, and most would claim, their sound. But the overwhelming majority of the violinists in the experiment preferred the modern violins. This is not to say that humans should just accept a forced preference in violin. An argument for why Strads sound (or seem to sound) better has been made from a <a href="http://www.brandstoryonline.com/stradivarius-violins-better/">brand perspective</a>, of all things. It’s the same argument made for fine (expensive) art: that part of the value, maybe most of the value, comes from things that are not objective. Story and history have a big impact on value.</p>

<ul>
<li>Some skills will become impossible to acquire when humans make a large environmental change. These skills are not transferable across vastly different environments and are lost.</li>
<li>Skill loss happens all the time in human history, though certain events speed it up.</li>
<li>Some events make skill loss impossible to undo.</li>
<li>Future humans will deal with different unintended consequences if they build an interstellar society.</li>
<li>Can we build a set of rules to help us assess unintended consequences from dramatic environmental changes?</li>
</ul>
	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://unintendedconsequenc.es/who-plays-the-stradivarius-in-interstellar-space/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25183046</guid>
            <pubDate>Mon, 23 Nov 2020 02:28:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notion + Super Blogging]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25182992">thread link</a>) | @qrush
<br/>
November 22, 2020 | https://quaran.to/notion-super-blogging | <a href="https://web.archive.org/web/*/https://quaran.to/notion-super-blogging">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article id="block-notion-super-blogging"><p><span><span><span>Nov 22, 2020</span></span><span> </span></span></p><p><span><span>My blog has now had 3 phases over</span><span><em> </em></span><span><strong><em>13 years </em></strong></span><span>(😱):</span></span></p><h2 id="block-2151df51dfc445268aff9b7df8fe6284"><span id="2151df51dfc445268aff9b7df8fe6284"></span><span><span>Wordpress (2007-2009)</span></span></h2><div id="block-edd40c18fd20479e8846a4462730ae86"><picture><source srcset="https://api.super.so/asset/quaran.to/02106789-446f-4eef-8750-21a8075e5f87.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/quaran.to/02106789-446f-4eef-8750-21a8075e5f87.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/quaran.to/02106789-446f-4eef-8750-21a8075e5f87.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/quaran.to/02106789-446f-4eef-8750-21a8075e5f87.png?w=1500" alt="Not sure what the stylesheet looked like, but it's long gone now." loading="lazy"></picture><figcaption><span><span>Not sure what the stylesheet looked like, but it's long gone now.</span></span></figcaption></div><h2 id="block-769ce70c084145d8b9c78e4e10c5eeee"><span id="769ce70c084145d8b9c78e4e10c5eeee"></span><span><span>Jekyll / GitHub Pages (2009-2020)</span></span></h2><div id="block-5ceedc994220402ba8bc7d88159726fd"><picture><source srcset="https://api.super.so/asset/quaran.to/3e66cb5c-a9ba-4284-95a5-3c106ebbcf74.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/quaran.to/3e66cb5c-a9ba-4284-95a5-3c106ebbcf74.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/quaran.to/3e66cb5c-a9ba-4284-95a5-3c106ebbcf74.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/quaran.to/3e66cb5c-a9ba-4284-95a5-3c106ebbcf74.png?w=1500" alt="I miss subtle patterns tiled backgrounds." loading="lazy"></picture><figcaption><span><span>I miss subtle patterns tiled backgrounds.</span></span></figcaption></div><h3 id="block-d2868af2e39d4fa7a4474c1d63027a3c"><span id="d2868af2e39d4fa7a4474c1d63027a3c"></span><span><span>Notion / Super (2020-?)</span></span></h3><div id="block-aacab40bc97c46679ae56efec394ec3b"><picture><source srcset="https://api.super.so/asset/quaran.to/2921f0b0-f782-4273-8699-7e853a4f5981.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/quaran.to/2921f0b0-f782-4273-8699-7e853a4f5981.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/quaran.to/2921f0b0-f782-4273-8699-7e853a4f5981.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/quaran.to/2921f0b0-f782-4273-8699-7e853a4f5981.png?w=1500" alt="Woof!" loading="lazy"></picture><figcaption><span><span>Woof!</span></span></figcaption></div><p><span><span>My writing tapered off immensely in recent years, and I didn't find </span><span><a href="https://github.com/qrush/qrush.github.com" target="_blank" rel="noopener noreferrer">my old site built with Jekyll</a></span><span> to be interesting to work on anymore. I've now swung back to the land of a managed platform that frees me from:</span></span></p><ul><li id="block-157db9bac7834326b77508840cb8c7db"><span><span>Worrying about Ruby dependency updates </span><span><span><span><em>(No JavaScript, what a concept!)</em></span></span></span></span></li><li id="block-ce9a3e9596cb4f8195e394a8baf10083"><span><span>An ancient CSS template that still uses 960.css </span><span><span><span><em>(and fully learning flexbox still, sorry I haven't done this yet)</em></span></span></span></span></li><li id="block-e8a503b4352841ffac0c4cf9e366a325"><span><span>Needing to think about mobile design / accessibility </span><span><span><span><em>(I hope Notion is doing so...)</em></span></span></span></span></li><li id="block-7a796ada75a14444951a3d656d64faf3"><span><span>Having to jump to GitHub (or my editor) to make changes. </span><span><span><span><em>(Now it's all in browser!)</em></span></span></span></span></li></ul><div id="block-6fceb34582d043c6bd40721cb0046f24"><p><span><span>I haven't switched my entire blog over, as most of my </span><span><span><a id="block-block-/cdca0dcdd3894bd6a33725aae7a87e20" href="https://quaran.to/cdca0dcdd3894bd6a33725aae7a87e20"></a></span></span></span></p><p><span> is hosted on other sites. Since the majority of the posts were on external sites I didn't feel beholden to correct URLs that may be broken, but I may do that too soon!</span></p></div><p><span><span>I've been using </span><span><a href="https://demo.super.so/" target="_blank" rel="noopener noreferrer">Super</a></span><span> to host my site off </span><span><a href="https://www.notion.so/" target="_blank" rel="noopener noreferrer">Notion</a></span><span>, which is only $4/month and allows me to stop worrying about all of the above. I get a great little writing and note-taking platform that allows for HTML import + export, and then Super scrapes all of that and wraps it up in a beautiful CDN-enabled package for any internet denizen to browse. </span></span></p><p><span><span>The Super setup is quite straightforward! Here's the basic steps once you sign up for Notion, and then sign up for Super:</span></span></p><h3 id="block-f4a63ce046bb43adb414346f87460def"><span id="f4a63ce046bb43adb414346f87460def"></span><span><span>Site Method</span></span></h3><p><span><span>Do you want suped-up pages for SEO or just publish your Notion document on the web? I've been using </span><span><strong>Super Static </strong></span><span>and it works quite wonderfully.</span></span></p><div id="block-378daa64ade44a8da70c8486a0d7d7a3"><picture><source srcset="https://api.super.so/asset/quaran.to/138a747c-0a3a-49f5-a047-4f444ad99222.png?w=432&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/quaran.to/138a747c-0a3a-49f5-a047-4f444ad99222.png?w=432" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/quaran.to/138a747c-0a3a-49f5-a047-4f444ad99222.png?w=432&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/quaran.to/138a747c-0a3a-49f5-a047-4f444ad99222.png?w=432" alt="image" loading="lazy"></picture></div><h3 id="block-5216e0858999452f8ee5c906f58f0f43"><span id="5216e0858999452f8ee5c906f58f0f43"></span><span><span>Site Settings</span></span></h3><p><span><span>The basics and the "root" of your site.</span></span></p><div id="block-9daaf9a7bef04348b742ea80bb79dbcf"><picture><source srcset="https://api.super.so/asset/quaran.to/f90cfade-4e16-4f9c-a718-3b61537e3e00.png?w=432&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/quaran.to/f90cfade-4e16-4f9c-a718-3b61537e3e00.png?w=432" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/quaran.to/f90cfade-4e16-4f9c-a718-3b61537e3e00.png?w=432&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/quaran.to/f90cfade-4e16-4f9c-a718-3b61537e3e00.png?w=432" alt="image" loading="lazy"></picture></div><h3 id="block-f9c8c75974d947a493bfd0fe65354a94"><span id="f9c8c75974d947a493bfd0fe65354a94"></span><span><span>Pretty URLs</span></span></h3><p><span><span>This section needs some work. It would be nice to use Notion itself for this via a "database" page, or use tags on pages to create their pretty URLs. This is a bit annoying to make for every post, and I hope this gets fixed soon. If I was moving over a blog with 100s of entries this would be a nonstarter, or I'd have to choose a new domain. For now, I punted on the old posts.</span></span></p><div id="block-1ab7f0cd79994ccdb3a348a35cefd016"><picture><source srcset="https://api.super.so/asset/quaran.to/b257bac1-11b0-44ee-bd3f-20e2787bcd8e.png?w=432&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/quaran.to/b257bac1-11b0-44ee-bd3f-20e2787bcd8e.png?w=432" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/quaran.to/b257bac1-11b0-44ee-bd3f-20e2787bcd8e.png?w=432&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/quaran.to/b257bac1-11b0-44ee-bd3f-20e2787bcd8e.png?w=432" alt="image" loading="lazy"></picture></div><h3 id="block-f824fd57c96a4e0997bf1d96f971c00c"><span id="f824fd57c96a4e0997bf1d96f971c00c"></span><span><span>DNS Records</span></span></h3><p><span><span>There's nice walkthroughs for the "big" DNS providers, but setting this up with </span><span><a href="https://dnsimple.com/r/35d1afbfe92d46" target="_blank" rel="noopener noreferrer">DNSimple</a></span><span> was pretty easy to do.</span></span></p><div id="block-1c2b641343b948fc9de5a251d071f964"><picture><source srcset="https://api.super.so/asset/quaran.to/cd971f81-f3af-4e67-8f69-964553749454.png?w=432&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/quaran.to/cd971f81-f3af-4e67-8f69-964553749454.png?w=432" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/quaran.to/cd971f81-f3af-4e67-8f69-964553749454.png?w=432&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/quaran.to/cd971f81-f3af-4e67-8f69-964553749454.png?w=432" alt="image" loading="lazy"></picture></div><h3 id="block-1992c6d4c62e40b4a7f605e67e00bfaf"><span id="1992c6d4c62e40b4a7f605e67e00bfaf"></span><span><span>Super Options</span></span></h3><p><span><span>I've decided to not track visits/readership via analytics for now but it's nice that there's an option. I'd rather have readers engage me </span><span><a href="https://twitter.com/qrush" target="_blank" rel="noopener noreferrer">via Twitter</a></span><span> instead of a comments feed anyhow, and I'm not sure what I would learn from analytics on my blog other than it gets less traffic than I'd like.</span></span></p><div id="block-f65868bd015e42f084c8c905177c381d"><picture><source srcset="https://api.super.so/asset/quaran.to/b5e3e1c3-40d0-464f-a684-66797e0c0f55.png?w=432&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/quaran.to/b5e3e1c3-40d0-464f-a684-66797e0c0f55.png?w=432" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/quaran.to/b5e3e1c3-40d0-464f-a684-66797e0c0f55.png?w=432&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/quaran.to/b5e3e1c3-40d0-464f-a684-66797e0c0f55.png?w=432" alt="image" loading="lazy"></picture></div><h2 id="block-fd8b6bebb3634ae994ca02dde02aa0fe"><span id="fd8b6bebb3634ae994ca02dde02aa0fe"></span><span><span>The end game</span></span></h2><p><span><span>So one might think: what happens when Super, or Notion, breaks this setup or disallows publishing? Yes, that's a risk I have assumed with this project. I can export any Notion document as HTML or Markdown, so once this setup stops working I'll just move on, just like I did twice before. This time it'll cost $4/mo for the time being, but honestly that's motivation to get me to write more. I guess we'll see in a few years!</span></span></p><p><span><span>The TL;DR:</span></span></p><blockquote id="block-f202c639bec24c5c8ac7f2352f767bc8"><span><span>1. Sign up for both Notion + Super
2. Configure DNS
3. Don't stop writing</span></span></blockquote><p><span><span><em>If you enjoyed this, you can use my referral link to sign up for Super and that'd just lovely:</em></span></span></p></article></div></div></div>]]>
            </description>
            <link>https://quaran.to/notion-super-blogging</link>
            <guid isPermaLink="false">hacker-news-small-sites-25182992</guid>
            <pubDate>Mon, 23 Nov 2020 02:19:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a scalable Machine Learning feature store for DoorDash]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25182692">thread link</a>) | @maxpert
<br/>
November 22, 2020 | https://doordash.engineering/2020/11/19/building-a-gigascale-ml-feature-store-with-redis/ | <a href="https://web.archive.org/web/*/https://doordash.engineering/2020/11/19/building-a-gigascale-ml-feature-store-with-redis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span>
										<div id="author86">
						<div>
							<p><img width="96" height="96" src="https://i1.wp.com/doordash.engineering/wp-content/uploads/2020/07/Screen-Shot-2020-07-17-at-6.09.31-PM.png?fit=96%2C96&amp;ssl=1" alt="" loading="lazy" srcset="https://i1.wp.com/doordash.engineering/wp-content/uploads/2020/07/Screen-Shot-2020-07-17-at-6.09.31-PM.png?w=512&amp;ssl=1 512w, https://i1.wp.com/doordash.engineering/wp-content/uploads/2020/07/Screen-Shot-2020-07-17-at-6.09.31-PM.png?resize=300%2C300&amp;ssl=1 300w, https://i1.wp.com/doordash.engineering/wp-content/uploads/2020/07/Screen-Shot-2020-07-17-at-6.09.31-PM.png?resize=150%2C150&amp;ssl=1 150w, https://i1.wp.com/doordash.engineering/wp-content/uploads/2020/07/Screen-Shot-2020-07-17-at-6.09.31-PM.png?resize=70%2C70&amp;ssl=1 70w, https://i1.wp.com/doordash.engineering/wp-content/uploads/2020/07/Screen-Shot-2020-07-17-at-6.09.31-PM.png?resize=24%2C24&amp;ssl=1 24w, https://i1.wp.com/doordash.engineering/wp-content/uploads/2020/07/Screen-Shot-2020-07-17-at-6.09.31-PM.png?resize=48%2C48&amp;ssl=1 48w, https://i1.wp.com/doordash.engineering/wp-content/uploads/2020/07/Screen-Shot-2020-07-17-at-6.09.31-PM.png?resize=96%2C96&amp;ssl=1 96w" sizes="(max-width: 96px) 100vw, 96px" data-attachment-id="1822" data-permalink="https://doordash.engineering/screen-shot-2020-07-17-at-6-09-31-pm/" data-orig-file="https://i1.wp.com/doordash.engineering/wp-content/uploads/2020/07/Screen-Shot-2020-07-17-at-6.09.31-PM.png?fit=512%2C512&amp;ssl=1" data-orig-size="512,512" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Arbaz Khan" data-image-description="" data-medium-file="https://i1.wp.com/doordash.engineering/wp-content/uploads/2020/07/Screen-Shot-2020-07-17-at-6.09.31-PM.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i1.wp.com/doordash.engineering/wp-content/uploads/2020/07/Screen-Shot-2020-07-17-at-6.09.31-PM.png?fit=512%2C512&amp;ssl=1"></p>
							<div>
								<h4>Arbaz Khan</h4><p>Arbaz Khan is a ML Platform engineer at DoorDash with a background in building end-to-end ML systems. Arbaz attended Indian Institute of Technology Kanpur (IITK) where he did his Bachelors and Masters in Computer Science.</p>
							</div>
													</div>
					</div>
					
										<div id="author29">
						<div>
							<p><img width="96" height="96" src="https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?fit=96%2C96&amp;ssl=1" alt="" loading="lazy" srcset="https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?w=506&amp;ssl=1 506w, https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?resize=296%2C300&amp;ssl=1 296w, https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?resize=150%2C150&amp;ssl=1 150w, https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?resize=70%2C70&amp;ssl=1 70w, https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?resize=24%2C24&amp;ssl=1 24w, https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?resize=48%2C48&amp;ssl=1 48w, https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?resize=96%2C96&amp;ssl=1 96w, https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?resize=300%2C300&amp;ssl=1 300w" sizes="(max-width: 96px) 100vw, 96px" data-attachment-id="2547" data-permalink="https://doordash.engineering/screen-shot-2020-09-25-at-7-21-00-pm/" data-orig-file="https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?fit=506%2C512&amp;ssl=1" data-orig-size="506,512" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Zohaib Sibte Hassan" data-image-description="" data-medium-file="https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?fit=296%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?fit=506%2C512&amp;ssl=1"></p>
							<div>
								<h4>Zohaib Sibte Hassan</h4><p>Zohaib is the engineering lead on the Platform Engineering team, focused on craftsmanship, performance, intelligent systems, hacking, and system architecture.</p>
							</div>
													</div>
					</div>
					<a href="#" data-href="author29">
						<img width="96" height="96" src="https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?fit=96%2C96&amp;ssl=1" alt="" loading="lazy" srcset="https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?w=506&amp;ssl=1 506w, https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?resize=296%2C300&amp;ssl=1 296w, https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?resize=150%2C150&amp;ssl=1 150w, https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?resize=70%2C70&amp;ssl=1 70w, https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?resize=24%2C24&amp;ssl=1 24w, https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?resize=48%2C48&amp;ssl=1 48w, https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?resize=96%2C96&amp;ssl=1 96w, https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?resize=300%2C300&amp;ssl=1 300w" sizes="(max-width: 96px) 100vw, 96px" data-attachment-id="2547" data-permalink="https://doordash.engineering/screen-shot-2020-09-25-at-7-21-00-pm/" data-orig-file="https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?fit=506%2C512&amp;ssl=1" data-orig-size="506,512" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Zohaib Sibte Hassan" data-image-description="" data-medium-file="https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?fit=296%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?fit=506%2C512&amp;ssl=1">Zohaib Sibte Hassan					</a>
									</span></p><div>
					
<p>When a company with millions of consumers such as DoorDash builds machine learning (ML) models, the amount of feature data can grow to billions of records with millions actively retrieved during model inference under low latency constraints. These challenges warrant a deeper look into selection and design of a feature store — the system responsible for storing and serving feature data. The decisions made here can prevent overrunning cost budgets, compromising runtime performance during model inference, and curbing model deployment velocity.</p>



<p>Features are the input variables fed to an ML model for inference. A feature store, simply put, is a <a href="https://aws.amazon.com/nosql/key-value/">key-value store</a> that makes this feature data available to models in production. At DoorDash, our existing feature store was built on top of <a href="https://redis.io/">Redis</a>, but had a lot of inefficiencies and came close to running out of capacity. We ran a full-fledged benchmark evaluation on five different key-value stores to compare their cost and performance metrics. Our benchmarking results indicated that Redis was the best option, so we decided to optimize our feature storage mechanism, tripling our cost reduction. Additionally, we also saw a 38% decrease in Redis latencies, helping to improve the runtime performance of serving models.</p>



<p>Below, we will explain the challenges posed in the task of operating a large scale feature store. Then, we will review how we were able to quickly identify Redis as the right key-value store for this task. We will then dive into the optimizations we did on Redis to triple its capacity, while also uplifting read performance by choosing a custom serialization scheme around strings, <a href="https://developers.google.com/protocol-buffers">protocol buffers</a>, and <a href="https://github.com/google/snappy">Snappy</a> compression algorithm.</p>



<h2>Requirements of a gigascale feature store</h2>



<p>The challenges of supporting a feature store that needs a large storage capacity and high read/write throughput are similar to the challenges of supporting any high-volume key-value store. Let’s elaborate upon the requirements before we discuss the challenges faced when meeting these requirements specifically with respect to a feature store.</p>



<h3>Persistent scalable storage: support billions of records</h3>



<p>The number of records in a feature store depends upon the number of entities involved and the number of ML use cases employed on these entities. At DoorDash, our ML practitioners work with millions of entities such as consumers, merchants, and food items. These entities are associated with features and used in many dozens of ML use cases such as <a href="https://doordash.engineering/2020/10/01/integrating-a-scoring-framework-into-a-prediction-service/">store ranking</a> and cart item recommendations. Even though there is an overlap in features used across these use cases, the total number of <em>feature-value</em> pairs exceeds billions.</p>



<p>Additionally, since feature data is used in model serving, it needs to be backed up to disk to enable recovery in the event of a storage system failure.</p>



<h3>High read throughput: serve millions of feature lookups per second</h3>



<p>A hit rate of millions of requests per second is a staggering requirement for any data storage system. The request rates on a feature store are directly driven by the number of predictions served by the corresponding system. At DoorDash, one of our high volume use cases, <a href="https://doordash.engineering/2020/10/01/integrating-a-scoring-framework-into-a-prediction-service/">store ranking</a>, makes more than one million predictions per second and uses dozens of features per prediction. Thus, our feature store needs to support tens of millions of reads per second.</p>



<h3>Fast batch writes: enable full data refresh in a nightly run</h3>



<p>Features need to be periodically refreshed to make use of the latest real world data. These writes can typically be done in batches to exploit batch write optimizations of a key-value store. At DoorDash, almost all of the features get updated every day, while real time features, such as “average delivery time for orders from a store in the past 20 minutes”, get updated uniformly throughout the day.</p>



<h2>Specific design challenges in building a feature store</h2>



<p>When designing a feature store to meet the scale expectations described above, we have to deal with complexities that are specific to a feature store. These complexities involve issues such as supporting batch random reads, storing multiple kinds of data types, and enabling low-latency serving.</p>



<h3>Batch random reads per request add to read complexity</h3>



<p>Feature stores need to offer batch lookup operations because a single prediction needs multiple features. All key-value stores support unit lookup operations such as Redis’s <a href="https://redis.io/commands/get">GET command</a>. However, batch lookups are not a standard especially when keys are in no particular sequence. For example, <a href="https://cassandra.apache.org/">Apache Cassandra</a> doesn’t support batch random lookups.</p>



<h3>Heterogeneous data types require non-standardized optimizations</h3>



<p>Features can either be simple data types such as integers, floats, and strings, or compound types such as <a href="https://doordash.engineering/2018/04/02/personalized-store-feed-with-vector-embeddings/">vector embeddings</a> or lists. We use integers or strings for categorical features such as <em>order protocol,</em> for whether an order was received by merchants via email, text, or iPad. We use lists for features such as a <em>list of cuisines chosen by a customer in the past 4 weeks.</em> Each one of these data types needs to be individually treated for optimizing storage and performance efficiency.</p>



<h3>Low read latency but loose expectations on write latency</h3>



<p>A feature store needs to guarantee low-latency reads. Latency on feature stores is a part of model serving, and model serving latencies tend to be in the low milliseconds range. Thus, read latency has to be proportionately lower. Also, typically, writes and updates happen in the background and are much less frequent than reads. For DoorDash, when not doing the batch refresh, writes are only 0.1% of reads. Low-latency requirements on reads and loose expectations with writes gives a direction for building towards a read-heavy key-value store but one that is fast enough for large batch writes.</p>



<h2>Identifying the right key-value store by benchmarking key performance metrics&nbsp;</h2>



<p>The choice for an appropriate storage technology helps greatly in increasing the performance and reducing the costs of a feature store. Using Yahoo’s cloud serving benchmark tool, <a href="https://github.com/brianfrankcooper/YCSB">YCSB</a>, we were able to identify Redis as a key-value store option that best fit our needs.</p>



<h3>What we need from a benchmarking platform</h3>



<p>Before we lay out our benchmarking setup, it is worthwhile to emphasize key requirements of a benchmarking platform. The four major required capabilities of a benchmarking setup are:&nbsp;</p>



<ul><li>Data generation using preset distributions</li></ul>



<p>Using data generation is a faster and more robust approach to benchmarking than ingesting real data because it accounts for possible values that a system’s random variables can take and doesn’t require moving data around to seed a target database.</p>



<ul><li>Ability to simulate characteristic workloads</li></ul>



<p>The workload on a database can be defined by the rate of requests, nature of operations, and proportions of these operations. As long as we can guarantee the same fixed request rate across tests, we can enable a fair comparison between the different databases.</p>



<ul><li>Fine-grained performance reporting</li></ul>



<p>The suite should be able to capture performance with appropriate statistical measures such as averages, 95th percentile, and 99th percentiles.</p>



<ul><li>Reproduction of results on demand</li></ul>



<p>Without reproducibility, there is no benchmark, it’s merely a random simulated event. For this reason, any benchmark platform needs to be able to provide a consistent environment where the results can be reproduced when running the same test over and over.</p>



<h3>Using YCSB to do a rapid comparison of key-value stores</h3>



<p>YCSB is one of the best benchmarking tools out there for analysing key-value stores. So much so that it not only meets all of the needs we described above but also provides sample code to benchmark a vast number of key-value stores. This setup ensures we have a flexible playground for rapid comparisons. Below, we describe our approach of using YCSB to validate our selection of Redis as the best choice for a feature store. We will first describe our experiment setup and then report the results with our analysis.</p>



<h2>Experiment setup</h2>



<p>When setting up the benchmarking experiment, we need to start with the set of key-value stores that we believe can meet the large scale expectations reliably and have a good industry presence. Also, our experiment design is centered around Docker and aims to optimize the speed of iterations when benchmarking by removing infrastructure setup overheads.</p>



<h3>Candidate set of key-value stores</h3>



<p>The key-value stores that we experimented on in this article are listed in Table 1, below. <a href="https://cassandra.apache.org/">Cassandra</a>, <a href="https://www.cockroachlabs.com/">CockroachDB</a>, and <a href="https://redis.io/">Redis</a> have a presence in the DoorDash infrastructure, while we selected <a href="https://www.scylladb.com/">ScyllaDB</a> and <a href="https://www.yugabyte.com/">YugabyteDB</a> based on market reports and our team’s prior experience with these databases. The intention was to compare Redis as an in-memory store with other disk-based key-value stores for our requirements.</p>



<figure><table><tbody><tr><td><strong>Database name</strong></td><td><strong>Version</strong></td></tr><tr><td>Cassandra</td><td>3.11.4</td></tr><tr><td>CockroachDB</td><td>20.1.5</td></tr><tr><td>Redis</td><td>3.2.10</td></tr><tr><td>ScyllaDB</td><td>4.1.7</td></tr><tr><td>YugabyteDB</td><td>2.3.1.0-b15</td></tr></tbody></table><figcaption><em>Table 1.</em> We considered five<em> data stores for benchmarking, three that were in current use at DoorDash and two others that showed promise in external market reports.</em></figcaption></figure>



<h3>Data schema</h3>



<p>For data storage, we chose following patterns:</p>



<ul><li>SQL/Cassandra</li></ul>



<pre><code lang="sql">CREATE TABLE table (key varchar primary key, value varchar)</code></pre>



<ul><li>Redis</li></ul>



<pre><code lang="bash">SET key-value
GET key</code></pre>



<h3>Input data …</h3></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://doordash.engineering/2020/11/19/building-a-gigascale-ml-feature-store-with-redis/">https://doordash.engineering/2020/11/19/building-a-gigascale-ml-feature-store-with-redis/</a></em></p>]]>
            </description>
            <link>https://doordash.engineering/2020/11/19/building-a-gigascale-ml-feature-store-with-redis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25182692</guid>
            <pubDate>Mon, 23 Nov 2020 01:25:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Water-cooled Raspberry Pi 4 at 2 GHz]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25182414">thread link</a>) | @fortran77
<br/>
November 22, 2020 | https://www.the-diy-life.com/water-cooled-raspberry-pi-4-totally-unnecessary-but-pretty-awesome/ | <a href="https://web.archive.org/web/*/https://www.the-diy-life.com/water-cooled-raspberry-pi-4-totally-unnecessary-but-pretty-awesome/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-7987" itemscope="" itemtype="http://schema.org/CreativeWork">

	
	<div itemprop="text">
		
<p>Today I’m going to see if I can use a PC water cooling kit to make a water cooled Raspberry Pi 4. I’ve seen a couple of people try this on older model Pi’s, using reducers and adapters to get to a small cooling block onto the CPU, but I’m going to try and make an adapter to fit a larger 30mm cooling block onto a Pi 4.</p>



<p><span data-ez-name="the_diy_life_com-box-3"></span>Just to be clear, this is totally unnecessary and is more of a let’s do it because we can, not because we should type of project.  But we’ll have fun building it anyway, and hopefully it works well in the end!</p>



<p>Here’s a video of the build and the test, read on for the write-up:</p>



<figure><div>
<p><iframe title="Water Cooled Raspberry Pi 4 - Totally Unnecessary, But Pretty Awesome" width="758" height="426" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" data-ezsrc="https://www.youtube.com/embed/fW3VeVe-FJg?feature=oembed"></iframe></p>
</div></figure>



<h2>What You Need For A Water Cooled Raspberry Pi</h2>



<ul><li>Raspberry Pi 4 – <a href="https://amzn.to/3dYeVqg">Buy Here</a></li><li>Pi Power Supply – <a href="https://amzn.to/3jxqMfU">Buy Here</a></li><li>120mm Water Cooling Kit (Not From Amazon) – <a href="https://bit.ly/2ICX64f">Buy Here</a></li><li>240mm Water Cooling Kit (Larger, But From Amazon) – <a href="https://amzn.to/38HForr">Buy Here</a></li><li>CPU Cooling Block (Not From Amazon) – <a href="https://bit.ly/38KIwTb">Buy Here</a></li><li>Adjustable 12V Power Supply – <a href="https://amzn.to/36H6Xyr">Buy Here</a></li></ul>



<p><em>Note: Some of the above parts are affiliate links. By purchasing products through the above links, you’ll be supporting this site, at no additional cost to you.</em></p>



<figure><img data-attachment-id="8006" data-permalink="https://www.the-diy-life.com/pc-water-cooling-kit/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="PC Water Cooling Kit" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit-1024x576.jpg" alt="PC Water Cooling Kit" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit.jpg 1920w"></figure>



<p>I bought a kit that included a 120mm fan and a radiator, a 12V pump, a reservoir and some tubing. These kits are commonly available online for significantly less than the name brand components sold for high-end PCs, but it’s still quite expensive just to mess around with.</p>



<figure><img data-attachment-id="8009" data-permalink="https://www.the-diy-life.com/full-sized-cpu-cooling-water-block/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Full Sized CPU Cooling Water Block" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block-1024x576.jpg" alt="Full Sized CPU Cooling Water Block" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block.jpg 1920w"></figure>



<p>The kit also included a full size CPU cooling block. It looks quite cool (excuse the pun) but is way too big to try and fit onto the Pi, so I’m going to be using one of these smaller 30 x 30mm blocks which can accommodate a half-inch or 12mm tubing.</p>



<figure><img data-attachment-id="8007" data-permalink="https://www.the-diy-life.com/cpu-cooling-water-block/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="CPU Cooling Water Block" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block-1024x576.jpg" alt="CPU Cooling Water Block" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block.jpg 1920w"></figure>



<h2>Building The Water Cooled Raspberry Pi 4</h2>



<h3>Mounting The Cooling Block To The Pi</h3>



<p>I’m going to start out by making a bracket to hold the cooling block in place on the Pi over the CPU. </p>



<figure><img data-attachment-id="8010" data-permalink="https://www.the-diy-life.com/designing-a-bracket-to-hold-the-cpu-block/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Designing A Bracket To Hold The CPU Block" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block-1024x576.jpg" alt="Designing A Bracket To Hold The CPU Block" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block.jpg 1920w"></figure>



<p>We’ll need a square section to locate the block and hold it down onto the CPU and then some legs off to the four mounting holes to hold it in place. I’ve tried to avoid covering the GPIO pins and the major components, the bracket will be quite high up, so won’t interfere with any of the surface mount components.</p>



<figure><img data-attachment-id="8011" data-permalink="https://www.the-diy-life.com/laser-cutting-the-cpu-mounting-bracket/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Laser Cutting The CPU Mounting Bracket" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket-1024x576.jpg" alt="Laser Cutting The CPU Mounting Bracket" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket.jpg 1920w"></figure>



<p>I cut the two parts for the bracket out on my laser cutter from 3mm fluorescent green acrylic.</p>



<figure><img data-attachment-id="8012" data-permalink="https://www.the-diy-life.com/gluing-the-retaining-ring-in-place/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Gluing The Retaining Ring In Place" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place-1024x576.jpg" alt="Gluing The Retaining Ring In Place" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place.jpg 1920w"></figure>



<p>&nbsp;Then glued the pieces together using some acrylic cement.</p>



<figure><img data-attachment-id="8013" data-permalink="https://www.the-diy-life.com/cooling-water-block-bracket/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Cooling Water Block &amp; Bracket" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket-1024x576.jpg" alt="Cooling Water Block &amp; Bracket" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket.jpg 1920w"></figure>



<p>Now that we’ve got a bracket to hold the heat sink in place, lets fit it to the Pi.</p>



<figure><img data-attachment-id="7988" data-permalink="https://www.the-diy-life.com/cant-mount-the-block-directly/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Can’t Mount The Block Directly" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly-1024x576.jpg" alt="Can't Mount The Block Directly" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly.jpg 1920w"></figure>



<p>The cooling block can’t be mounted straight onto the CPU as the display connector is too high. We’ll need to put a spacer in between the CPU and cooling block to lift it above the display connector, with enough room for the tubes. </p>



<figure><img data-attachment-id="7989" data-permalink="https://www.the-diy-life.com/cut-a-sqaure-of-aluminium-spacer-block/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Cut A Sqaure Of Aluminium Spacer Block" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block-1024x576.jpg" alt="Cut A Sqaure Of Aluminium Spacer Block" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block.jpg 1920w"></figure>



<p><span data-ez-name="the_diy_life_com-box-4"></span>I’ve cut a section of 4mm aluminium to fit on top of the CPU to space the cooling block away so that it clears the display connector.</p>



<figure><img data-attachment-id="7990" data-permalink="https://www.the-diy-life.com/add-standoffs-for-the-cooling-block/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Add Standoffs For The Cooling Block" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block-1024x576.jpg" alt="Add Standoffs For The Cooling Block" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block.jpg 1920w"></figure>



<p>Next, I’m going to use some nylon standoff mounts for the screws which hold the cooling block bracket to screw into. I’ll hold these in place with some shorter nylon standoffs underneath the Pi.</p>



<figure><img data-attachment-id="7991" data-permalink="https://www.the-diy-life.com/put-thermal-paste-onto-cpu/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Put Thermal Paste Onto CPU" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU-1024x576.jpg" alt="Put Thermal Paste Onto CPU" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU.jpg 1920w"></figure>



<p>I’ll use some thermal paste between the CPU and the spacer and then again between the spacer and the cooling block.</p>



<figure><img data-attachment-id="7992" data-permalink="https://www.the-diy-life.com/secure-with-m3-screws/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Secure With M3 Screws" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws-1024x576.jpg" alt="Secure With M3 Screws" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws.jpg 1920w"></figure>



<p>The acrylic bracket is then clamped down onto the CPU using some M3 x 12mm button head screws.</p>



<figure><img data-attachment-id="7993" data-permalink="https://www.the-diy-life.com/cooling-block-mounted/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Cooling Block Mounted" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted-1024x576.jpg" alt="Cooling Block Mounted on Water Cooled Raspberry Pi" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted.jpg 1920w"></figure>



<h2>Making The Cooling Circuit Stand</h2>



<p>Now that we’ve got our cooling block mounted onto our Pi, we can start working on mounting the rest of the cooling circuit. </p>



<figure><img data-attachment-id="7994" data-permalink="https://www.the-diy-life.com/water-cooling-stand/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Water Cooling Stand" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand-1024x576.jpg" alt="Water Cooling Stand" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand.jpg 1920w"></figure>



<p>Rather than just connecting all of the components together on a desk, I decided to design a stand to mount the water cooling components and Raspberry Pi, so that it looks more complete.</p>



<p>I’m going to use clear acrylic for the stand with some fluorescent green legs to match the cooling block bracket. The water cooling components should just bolt straight onto this sheet once it’s been cut out.</p>



<figure><img data-attachment-id="7995" data-permalink="https://www.the-diy-life.com/laser-cutting-the-water-cooling-stand/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Laser Cutting The Water Cooling Stand" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand-1024x576.jpg" alt="Laser Cutting The Water Cooling Stand" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand.jpg 1920w"></figure>



<p>Again, I cut this stand out on my laser cutter from 3mm acrylic, this time clear.</p>



<p>Now that we’ve got our stand components made, lets start putting them together. </p>



<figure><img data-attachment-id="7996" data-permalink="https://www.the-diy-life.com/mount-water-cooling-components-to-test-stand/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Mount Water Cooling Components To Test Stand" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand-1024x576.jpg" alt="Mount Water Cooling Components To Test Stand" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand.jpg 1920w"></figure>



<p>I’ll start by mounting the reservoir, pump and radiator onto the stand.</p>



<figure><img data-attachment-id="7997" data-permalink="https://www.the-diy-life.com/glue-raspberry-pi-stand-together/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Glue Raspberry Pi Stand Together" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together-1024x576.jpg" alt="Glue Raspberry Pi Stand Together" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together.jpg 1920w"></figure>



<p>Next, I need to glue the Raspberry Pi stand components onto the main cooling water stand. I clamped the components in place and allowed the cement to cure for a couple of hours before trying to mount the Pi.</p>



<figure><img data-attachment-id="7998" data-permalink="https://www.the-diy-life.com/mount-pi-to-stand/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Mount Pi To Stand" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand-1024x576.jpg" alt="Mount Pi To Stand" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand.jpg 1920w"></figure>



<p>Once the glued had properly cured, I put two lengths of tubing onto the heat sink so that I didn’t have to try push them on in the tight space between the Pi and the pump, and then mounted the Pi onto the stand using four nylon M3 nuts on the bottom of the standoffs.</p>



<figure><img data-attachment-id="7999" data-permalink="https://www.the-diy-life.com/connect-remaining-tubing/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Connect Remaining Tubing" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing-1024x576.jpg" alt="Connect Remaining Tubing on Water Cooled Raspberry Pi 4" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing.jpg 1920w"></figure>



<p>I then added the fittings and finished off the tubing.</p>



<p>One side of the cooling block goes to the pump and the other to the radiator. We also need a section of tube from the radiator to the top of the reservoir.</p>



<p>The last thing to do is to add a small acrylic block to the base of the pump to hold the weight of the pump and reservoir. The legs on the stand are not strong enough to support all of the cooling components and I didn’t want to make them bigger as I like the look of the thinner sections. You’ll also hardly notice the block under the pump if it’s clear.</p>



<figure><img data-attachment-id="8000" data-permalink="https://www.the-diy-life.com/fill-up-circuit-with-cooling-water/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Fill Up Circuit With Cooling Water" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water-1024x576.jpg" alt="Fill Up Circuit With Cooling Water" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water.jpg 1920w"></figure>



<p>Our water cooled Pi is now complete, we just need to fill it up with water or cooling liquid and try it out. The system took around 300ml of cooling liquid to fill.</p>



<h2>Testing The Water Cooled Raspberry Pi 4</h2>



<p>The fan and pump are actually quite quiet when running, the system is a lot quieter than some of the small case fans I’ve used on a Raspberry Pi.</p>



<figure><img data-attachment-id="8003" data-permalink="https://www.the-diy-life.com/fan-running-on-radiator/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Fan Running On Radiator" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator-1024x576.jpg" alt="Fan Running On Radiator on Water Cooled Raspberry Pi" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator.jpg 1920w"></figure>



<p>Now let’s try and do a stress test on the water cooled Raspberry Pi to see how well this cooling system works.</p>



<h3>CPU Test At 1.5GHz</h3>



<p>With the CPU clock frequency set to the default 1.5Ghz, we start out with a temperature of around 28°C. This was in a room of around 25°C, so it was done with quite a warm ambient temperature. </p>



<figure><img data-attachment-id="8023" data-permalink="https://www.the-diy-life.com/water-cooled-raspberry-pi-4-totally-unnecessary-but-pretty-awesome/start-of-run-1-5ghz/#main" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz.png" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Start of run 1.5Ghz" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz-300x169.png" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz-1024x576.png" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz-1024x576.png" alt="Start of run 1.5Ghz" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz-1024x576.png" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz-1024x576.png 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz-300x169.png 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz-768x432.png 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz-1536x864.png 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz.png 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz-1024x576.png 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz-300x169.png 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz-768x432.png 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz-1536x864.png 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz.png 1920w"></figure>



<p>I then did a 5-minute stress test at full CPU load.</p>



<figure><img data-attachment-id="8020" data-permalink="https://www.the-diy-life.com/water-cooled-raspberry-pi-4-totally-unnecessary-but-pretty-awesome/end-of-run-1-5ghz/#main" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz.png" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="End of Run 1.5Ghz" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz-300x169.png" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz-1024x576.png" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz-1024x576.png" alt="End of Run 1.5Ghz" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz-1024x576.png" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz-1024x576.png 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz-300x169.png 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz-768x432.png 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz-1536x864.png 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz.png 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz-1024x576.png 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz-300x169.png 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz-768x432.png 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz-1536x864.png 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz.png 1920w"></figure>



<p>There was a small spike initially where the temperature went up to 31°C but it stayed between 31°C and 33°C for the rest of the test and dropped off quickly when the test was stopped. </p>



<figure><img data-attachment-id="8021" data-permalink="https://www.the-diy-life.com/water-cooled-raspberry-pi-4-totally-unnecessary-but-pretty-awesome/full-run-1-5ghz/#main" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz.png" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Full Run 1.5GHz" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz-300x169.png" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz-1024x576.png" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz-1024x576.png" alt="Full Run 1.5GHz" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz-1024x576.png" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz-1024x576.png 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz-300x169.png 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz-768x432.png 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz-1536x864.png 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz.png 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz-1024x576.png 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz-300x169.png 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz-768x432.png 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz-1536x864.png 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz.png 1920w"></figure>



<p>Here’s a graph of the CPU temperature for the duration of the test.</p>



<h3>CPU Test At 2.0GHz</h3>



<p>Now I’m going to try overclocking the Pi to test it at a higher CPU frequency. </p>



<figure><img data-attachment-id="8022" data-permalink="https://www.the-diy-life.com/water-cooled-raspberry-pi-4-totally-unnecessary-but-pretty-awesome/overclocking/#main" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking.png" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Overclocking to 2.0Ghz" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking-300x169.png" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking-1024x576.png" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking-1024x576.png" alt="Overclocking to 2.0Ghz" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking-1024x576.png" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking-1024x576.png 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking-300x169.png 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking-768x432.png 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking-1536x864.png 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking.png 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking-1024x576.png 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking-300x169.png 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking-768x432.png 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking-1536x864.png 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking.png 1920w"></figure>



<p>I set the CPU frequency to 2.0Ghz for this test.</p>



<p>Let’s try doing a stress test and see what we get.</p>



<figure><img data-attachment-id="8016" data-permalink="https://www.the-diy-life.com/water-cooled-raspberry-pi-4-totally-unnecessary-but-pretty-awesome/start-run-2ghz/#main" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz.png" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Start Run 2Ghz" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz-300x169.png" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz-1024x576.png" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz-1024x576.png" alt="Start Run 2Ghz" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz-1024x576.png" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz-1024x576.png 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz-300x169.png 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz-768x432.png 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz-1536x864.png 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz.png 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz-1024x576.png 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz-300x169.png 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz-768x432.png 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz-1536x864.png 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz.png 1920w"></figure>



<p>For this test we started out with a temperature of around 29°C, which then quickly spiked to 39°C when the test was started.</p>



<figure><img data-attachment-id="8017" data-permalink="https://www.the-diy-life.com/water-cooled-raspberry-pi-4-totally-unnecessary-but-pretty-awesome/almost-complete-2ghz/#main" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz.png" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Almost Complete 2Ghz" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz-300x169.png" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz-1024x576.png" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz-1024x576.png" alt="Almost Complete 2Ghz" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz-1024x576.png" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz-1024x576.png 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz-300x169.png 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz-768x432.png 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz-1536x864.png 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz.png 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz-1024x576.png 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz-300x169.png 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz-768x432.png 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz-1536x864.png 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz.png 1920w"></figure>



<p>The temperature the stayed around 36°C to 37°C for the rest of the test.</p>



<figure><img data-attachment-id="8019" data-permalink="https://www.the-diy-life.com/water-cooled-raspberry-pi-4-totally-unnecessary-but-pretty-awesome/end-2ghz/#main" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz.png" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="End 2Ghz" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz-300x169.png" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz-1024x576.png" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz-1024x576.png" alt="End 2Ghz" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz-1024x576.png" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz-1024x576.png 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz-300x169.png 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz-768x432.png 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz-1536x864.png 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz.png 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz-1024x576.png 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz-300x169.png 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz-768x432.png 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz-1536x864.png 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz.png 1920w"></figure>



<p>Here’s a graph of the CPU temperature for the duration of the 2Ghz test.</p>



<h2>Conclusion</h2>



<p>The water cooling system on this Pi works really well at keeping the CPU cool. Even when overclocked to 2.0Ghz, the  Raspberry Pi 4’s CPU temperature never went above 40°C. I wasn’t able to test the Pi at the maximum 2.147Ghz as my Pi wouldn’t boot up at this frequency, probably due to under-voltage. I’ll try and get this fixed and do a test at the maximum frequency as well at some stage.</p>



<p>To get an idea of whether this is worthwhile, I’m going to be comparing this water cooling system to an <a href="https://www.the-diy-life.com/diy-raspberry-pi-4-desktop-case-with-oled-stats-display/">Ice Tower</a>, a standard acrylic case and fan and then just a Pi with a static heat sink on it in the next week or two. So make sure that you check back here, or subscribe to my Youtube channel and turn on notifications so that you don’t miss out on that.</p>



<p>Let me know what you think of this water cooled Raspberry Pi 4 in the comments section below!</p>
<div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><a href="https://www.the-diy-life.com/author/mklementsme-com/"><img src="https://www.the-diy-life.com/wp-content/uploads/2019/12/Michael-Klements.jpg" alt="Michael-Klements" itemprop="image" ezimgfmt="rs rscb1 src ng ngcb1" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2019/12/Michael-Klements.jpg"></a></p><div><p>Hi, my name is Michael and I started this blog in 2016 to share my DIY journey with you. I love tinkering with electronics, making, fixing, and building – I’m always looking for new projects and exciting DIY ideas. If you do too, grab a cup of coffee and settle in, I’m happy to have you here.</p></div></div>
			</div><!-- .entry-content -->

	<!-- .entry-meta -->

</article></div>]]>
            </description>
            <link>https://www.the-diy-life.com/water-cooled-raspberry-pi-4-totally-unnecessary-but-pretty-awesome/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25182414</guid>
            <pubDate>Mon, 23 Nov 2020 00:33:50 GMT</pubDate>
        </item>
    </channel>
</rss>
